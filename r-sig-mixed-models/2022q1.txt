From cm|o500 @end|ng |rom york@@c@uk  Thu Jan  6 02:10:42 2022
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Thu, 6 Jan 2022 01:10:42 +0000
Subject: [R-sig-ME] lmer - individual slopes
Message-ID: <CACw+TfccqXaGjEpjcBcv1q-a9XmdTwL7Hm=mVX6ZJkZwMpo3TA@mail.gmail.com>

Hello,

I hope you had a lovely winter break.
I am interested in extracting the individual slopes for an experimental
design where individuals are asked to do a task with two conditions -
congruent and incongruent. These participants are also divided into groups
- sleep or awake. Should I consider group allocation in the model? The
individual slopes are extracted so that we can check whether the rate of
learning is stable across sessions.
Should we use:

a) lmer(Response times ~ Congruency + Group + (Congruency| Participant)

Or is it ok to just have it as:

b) lmer(Response times ~ Congruency + (Congruency| Participant)

Thanks

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jan  6 02:23:21 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 5 Jan 2022 20:23:21 -0500
Subject: [R-sig-ME] lmer - individual slopes
In-Reply-To: <CACw+TfccqXaGjEpjcBcv1q-a9XmdTwL7Hm=mVX6ZJkZwMpo3TA@mail.gmail.com>
References: <CACw+TfccqXaGjEpjcBcv1q-a9XmdTwL7Hm=mVX6ZJkZwMpo3TA@mail.gmail.com>
Message-ID: <689de883-2a3f-dbe6-79c5-1760c32dad48@gmail.com>



On 1/5/22 8:10 PM, C?tia Ferreira De Oliveira via R-sig-mixed-models wrote:
> Hello,
> 
> I hope you had a lovely winter break.
> I am interested in extracting the individual slopes for an experimental
> design where individuals are asked to do a task with two conditions -
> congruent and incongruent. These participants are also divided into groups
> - sleep or awake. Should I consider group allocation in the model? The
> individual slopes are extracted so that we can check whether the rate of
> learning is stable across sessions.
> Should we use:
> 
> a) lmer(Response times ~ Congruency + Group + (Congruency| Participant)
> 
> Or is it ok to just have it as:
> 
> b) lmer(Response times ~ Congruency + (Congruency| Participant)
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

   I don't see why you wouldn't use Congruency*Group as your fixed 
effect?  The more accurately you can estimate the population-level 
effects in the fixed-effect part of the model, the less is left for the 
random effects component to explain, which in turn makes it more likely 
that the distribution will conform to the assumption of normality.

   For example, suppose (retreating from a random-slopes model to a 
random-intercept model) that you had a treatment, ttt, with two levels 
and  a large effect, with subjects allocated to one treatment or the 
other (a nested design).  If you fitted

   lmer(response ~ 1 + (1|subject)

the distribution of subject-level effects would be strongly bimodal, 
since it would have to account for the treatment effect as well, whereas

   lmer(response ~ ttt + (1|subject)

would move the signal into the fixed effect and allow the random effect 
to capture the smaller (and possibly Normal) subject-level effects.


From ji@verissimo m@iii@g oii gm@ii@com  Thu Jan  6 08:25:37 2022
From: ji@verissimo m@iii@g oii gm@ii@com (ji@verissimo m@iii@g oii gm@ii@com)
Date: Thu, 06 Jan 2022 08:25:37 +0100
Subject: [R-sig-ME] lmer - individual slopes
In-Reply-To: <689de883-2a3f-dbe6-79c5-1760c32dad48@gmail.com>
References: <CACw+TfccqXaGjEpjcBcv1q-a9XmdTwL7Hm=mVX6ZJkZwMpo3TA@mail.gmail.com>
 <689de883-2a3f-dbe6-79c5-1760c32dad48@gmail.com>
Message-ID: <d8463cd93bfe4e1255f151b59bdb3e4b23cadb99.camel@gmail.com>

Hi C?tia,

To follow-up on Ben's answer,

Note that in the model Ben suggested (with the interaction), the by-
Participant random effects for Congruency will be deviations relative
to the mean Congruency effect in each group, I believe.
So similar random-effect adjustments (from ranef) for participants in
different groups may actually correspond to different predicted
individual slopes, depending on the effect of Congruency in each group.

In contrast, in your models (both a and b, I think), the by-Participant 
random effects for Congruency will be deviations from the mean
Congruency effect estimated across all participants.
(the two models would differ in the interpretation of their random
intercept adjustments, though)

Jo?o

On Wed, 2022-01-05 at 20:23 -0500, Ben Bolker wrote:
> On 1/5/22 8:10 PM, C?tia Ferreira De Oliveira via R-sig-mixed-models
> wrote:
> > Hello,
> > I hope you had a lovely winter break.I am interested in extracting
> > the individual slopes for an experimentaldesign where individuals
> > are asked to do a task with two conditions -congruent and
> > incongruent. These participants are also divided into groups- sleep
> > or awake. Should I consider group allocation in the model?
> > Theindividual slopes are extracted so that we can check whether the
> > rate oflearning is stable across sessions.Should we use:
> > a) lmer(Response times ~ Congruency + Group + (Congruency|
> > Participant)
> > Or is it ok to just have it as:
> > b) lmer(Response times ~ Congruency + (Congruency| Participant)
> > Thanks
> > 	[[alternative HTML version deleted]]
> > _______________________________________________R-sig-mixed-
> > models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
>    I don't see why you wouldn't use Congruency*Group as your fixed
> effect?  The more accurately you can estimate the population-level
> effects in the fixed-effect part of the model, the less is left for
> the random effects component to explain, which in turn makes it more
> likely that the distribution will conform to the assumption of
> normality.
>    For example, suppose (retreating from a random-slopes model to a
> random-intercept model) that you had a treatment, ttt, with two
> levels and  a large effect, with subjects allocated to one treatment
> or the other (a nested design).  If you fitted
>    lmer(response ~ 1 + (1|subject)
> the distribution of subject-level effects would be strongly bimodal,
> since it would have to account for the treatment effect as well,
> whereas
>    lmer(response ~ ttt + (1|subject)
> would move the signal into the fixed effect and allow the random
> effect to capture the smaller (and possibly Normal) subject-level
> effects.
> _______________________________________________R-sig-mixed-models at r-
> project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From k|m@co|yv@@ @end|ng |rom newc@@t|e@edu@@u  Sun Jan  9 00:29:19 2022
From: k|m@co|yv@@ @end|ng |rom newc@@t|e@edu@@u (Kim Colyvas)
Date: Sat, 8 Jan 2022 23:29:19 +0000
Subject: [R-sig-ME] glmmTMB spatial model - modified distance calculation
Message-ID: <SY4P282MB1915DFE575981A6B5AF184D7D64E9@SY4P282MB1915.AUSP282.PROD.OUTLOOK.COM>

I am assisting a researcher investigating the number of species with deficient data (conservation assessors are unable to allocate a species to a threat status category) for many countries around the world and examining covariates that might explain some of the variation between countries. I have been fitting a negative binomial (nb) model using glmmTMB with a spatial term based on (longitude,latitude) coordinates.

The default distance function in R is dist (from the stats package) is satisfactory for most work where relatively smaller distances were involved. Our country data however covers the whole globe and the default cartesian distance calculation used by the dist function I think differs too much from the more correct great circle distance approach that takes spherical geometry into account.
See Fig 1 in the cloud folder at the link below for a comparison of the two methods. The upper half of the sideways V shape pattern in the graph is because the default cartesian calculation doesn't allow for points on the globe being more than 180 deg of longitude apart in which case the shorter of the two possible distances between two points should be used. The great circle approach does this as well as allowing for the curvature of the earth's surface.

I decided to write an alternative distance function that mimicked the built-in dist function hoping it would be used by glmmTMB and the spatial correlation function would be determined on the great circle distances. I am writing because I don't think this has worked. I would appreciate suggestions for how to get glmmTMB to use the alternative distances in determining the spatial correlation function.

At this link I have provided the essentials of my code to allow replication of my work.
https://1drv.ms/u/s!AhpuyzHadR1ag_tZI15yXnkuFJL9Yw?e=s6tAZq
It contains
- my code for the replacement distance function which draws on the great circle distance functions provided in the geosphere package (dist_gc.R)
- the code for calculating the distances by the two methods and comparing them and then fitting the nb models by both methods and how I evaluated the correlograms for the models by both methods which was part of what led me to think that glmmTMB was not using the alternative distance function (dist_repex.R)
- 3 figures - Fig 1 showing the comparison between methods, and Fig 2,3 the correlograms from the two models.

Re how I implemented the replacement of the built-in distance method with the great circle calculations.
The comparison between methods in Fig 1 was part of satisfying myself that the method I was using was replacing the default distance function with my own. Although this worked in this simple test I am wondering what more I need to do to get glmmTMB to pick up the new function.

> # Built in distance function in R - from the stats package
> d1=dist(lonlat1)
> # Replacement distance function to calculate great circle distances using the Cosine formula
> dist = function(x) {
+   dist_gc(x,columns_to_retain=10)
+ }
> # Confirm presence of 2 functions with name dist
> getAnywhere(dist)
2 differing objects matching 'dist' were found
in the following places
  .GlobalEnv
  package:stats
  namespace:stats
Use [] to view one of them
> # Now try the replacement function as if it was the built-in function using the built-in function name
> # It takes precedence over the dist function in the stats module
> d7 = dist(lonlat1)
> #  They don't agree in that there is no straight line
This is the plot in Figure 1
> plot(d1 ~ d7,main="Compare replacement distance function with built in",
+      xlab="Great circle",ylab="Cartesian")


I then fitted the same model twice as follows - first step - remove my new function
> rm(dist, envir=.GlobalEnv)
>
> # Confirm presence of only 1 function with name dist
> getAnywhere(dist)
A single object matching 'dist' was found
It was found in the following places
  package:stats
  namespace:stats

Fitted the model and as the only distance function present was the default this model should have used cartesian coordinates.
# Fit spatial model using the default distance function
nb2_cart <- glmmTMB(total ~ log_pop + I(log_pop^2) + exp(pos + 0 | group), data=species1, family = nbinom1())

> summary(nb2_cart)$coefficients$cond
                Estimate  Std. Error   z value     Pr(>|z|)
(Intercept)   4.15405063 0.515443090  8.059184 7.680550e-16
log_pop      -0.24664756 0.072544883 -3.399930 6.740300e-04
I(log_pop^2)  0.01558456 0.002724543  5.720062 1.064851e-08

I then changed the distance calculation method
> # Redefine the distance function to calculate great circle distances
> dist = function(x) {
+   dist_gc(x,columns_to_retain=10)
+ }
>
> # Confirming that 2 dist functions are present again
> getAnywhere(dist)
2 differing objects matching 'dist' were found
in the following places
  .GlobalEnv
  package:stats
  namespace:stats
Use [] to view one of them
> getAnywhere(dist)[1]
function(x) {
  dist_gc(x,columns_to_retain=10)
}

I expected that as had occurred in my simple comparison of distance functions above that glmmTMB would use the new distance function in the modelling. The summary of the model coefficients however was exactly the same. I would have expected with a different spatial function that the estimates and SEs would differ. They didn't so I assumed that my replacement distance function was not being used by glmmTMB.

> summary(nb2_gc)$coefficients$cond
                Estimate  Std. Error   z value     Pr(>|z|)
(Intercept)   4.15405063 0.515443090  8.059184 7.680550e-16
log_pop      -0.24664756 0.072544883 -3.399930 6.740300e-04
I(log_pop^2)  0.01558456 0.002724543  5.720062 1.064851e-08

I used some very helpful code at this link to plot the correlograms from the 2 models.
https://datascienceplus.com/spatial-regression-in-r-part-1-spamm-vs-glmmtmb/
Fig 2 was as expected and if my new distance function had worked Fig 3 should have been similar - a perfect curve with no points deviating from the smooth function, except the function might have had a different shape.

I checked the call to the distance function in the glmmTMB R code and there was no specific call like stats::dist, so I thought my replacement function should have worked.
# Lines 748-750 in glmmTMB source code show the distance function being used
#   else if(ss[i] %in% c("exp", "gau", "mat")){
#   coords <- parseNumLevels(reTrms$cnms[[i]])
#   tmp$dist <- as.matrix( dist(coords) )

A couple of other questions.

a) When fitting the nb model the warning below was given.
An interpretation of this would be appreciated.

Warning message:
In (function (start, objective, gradient = NULL, hessian = NULL,  :
  NA/NaN function evaluation

b) Is there any way to obtain the parameters of the fitted spatial correlation function?

Thanks for reading this long email,
Mr Kim Colyvas
Casual research assistant specialising in statistical help
University of Newcastle
AUSTRALIA




	[[alternative HTML version deleted]]


From Adr|@@n@de@Jong @end|ng |rom @|u@@e  Wed Jan 12 11:30:36 2022
From: Adr|@@n@de@Jong @end|ng |rom @|u@@e (Adriaan de Jong)
Date: Wed, 12 Jan 2022 10:30:36 +0000
Subject: [R-sig-ME] How to include multiple temporal processes in one model?
Message-ID: <f0ac42759a024455bed9e020b531cf21@Exch2-3.slu.se>

Hi,

Present:
a 25 year series of count data of individuals of one migratory bird species observed from my driver's seat (2815 counts from the same c. 20 km road transect). The dataset includes the variables: Year, Month, Day, Hour, Minute (5 min precision), (driving)Direction and Count(result) (sample below).

Objectives:
1. Has there been a trend in the numbers over the years?
2. How do the numbers generally vary over the breeding season? (I live in northern Sweden and the breeding/observation season is April-August)
I have no intentions to make predictions for neither future developments (temporal extrapolation) nor other transects (spatial extrapolation).

Problems/limitations:
a. The sampling has been opportunistic (which was a main point because no extra effort was needed) and thus, unevenly spread over the hours of the day with more counts in the morning and late afternoon (most are from commuting to work).
b. The distribution of the timing over the day has varied over the years.
c. The dataset contains a significant proportion (43%) of zero counts, especially during the early and late parts of the breeding season.
d. The number of transect counts has varied over the years (range 66-167, but no clear trend over the years)
e. The direction of driving has an impact on what can be seen (non-flat landscape) and thus, needs to be included as a covariate (random effect?)
(I can provide graphs of frequency distributions if needed)

My question is:
How should I include the three temporal factors (year, time of season and time of day) and driving direction in the logistic models for the two different objectives?

Thanks in advance for your suggestions and comments.
Cheers,
Adjan

Adriaan "Adjan" de Jong
Associate professor
Dept of Wildlife, Fish, and Environmental Studies
Swedish University of Agricultural Sciences

Data structure (fake numbers)
YearMonthDayHourMinuteDirectionCount
199742591505
1997514153510
1997515745016
.
.
20218281000

PS. I understand I have to combine the Mont and Day, and the Hour and Minute variables into two new variables for Time of season and Time of day..

---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Jan 12 13:51:43 2022
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 12 Jan 2022 13:51:43 +0100
Subject: [R-sig-ME] 
 How to include multiple temporal processes in one model?
In-Reply-To: <f0ac42759a024455bed9e020b531cf21@Exch2-3.slu.se>
References: <f0ac42759a024455bed9e020b531cf21@Exch2-3.slu.se>
Message-ID: <CAJuCY5wU-Zdag-0DZToC1ELDPgFDHO8tnuHEb2bzCy1-agyLfQ@mail.gmail.com>

Dear Adriaan,

You could get some inspiration from our analysis on the breeding bird
survey data. The report is in Dutch. Your name increases my posterior
belief that you understand Dutch ;-)

a/b/e) I expect a strong correlation between time of day and direction. I'd
only keep the direction. Time of day probably won't provide that much more
information and requires a more complex model.
c) We tried to avoid structural zeros as much as possible by defining a
relevant subset of location and within the season. E.g. if we hardly
ever find a species in forests, then exclude the forested sites for that
species. Or ignore the first period of the season when the species is known
to arrive late in the season.
d) This shouldn't be a big issue. It will affect the uncertainty on the
year estimates.

We modeled the year effect as a first order random walk per stratum. In
your case I'd consider a first order random walk along the year and a
second order random walk along the day of year.

Onkelinx, T. *et al.* (2021). Trends op basis van de Algemene
Broedvogelmonitoring Vlaanderen (ABV). Rapporten van het Instituut voor
Natuur- en Bosonderzoek 2021 (14). Instituut voor Natuur- en Bosonderzoek,
Brussel. DOI: <https://inbo.github.io/abv-rapport/2020/#>
https://doi.org/10.21436/inbor.34162521

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 12 jan. 2022 om 11:31 schreef Adriaan de Jong <Adriaan.de.Jong at slu.se
>:

> Hi,
>
> Present:
> a 25 year series of count data of individuals of one migratory bird
> species observed from my driver's seat (2815 counts from the same c. 20 km
> road transect). The dataset includes the variables: Year, Month, Day, Hour,
> Minute (5 min precision), (driving)Direction and Count(result) (sample
> below).
>
> Objectives:
> 1. Has there been a trend in the numbers over the years?
> 2. How do the numbers generally vary over the breeding season? (I live in
> northern Sweden and the breeding/observation season is April-August)
> I have no intentions to make predictions for neither future developments
> (temporal extrapolation) nor other transects (spatial extrapolation).
>
> Problems/limitations:
> a. The sampling has been opportunistic (which was a main point because no
> extra effort was needed) and thus, unevenly spread over the hours of the
> day with more counts in the morning and late afternoon (most are from
> commuting to work).
> b. The distribution of the timing over the day has varied over the years.
> c. The dataset contains a significant proportion (43%) of zero counts,
> especially during the early and late parts of the breeding season.
> d. The number of transect counts has varied over the years (range 66-167,
> but no clear trend over the years)
> e. The direction of driving has an impact on what can be seen (non-flat
> landscape) and thus, needs to be included as a covariate (random effect?)
> (I can provide graphs of frequency distributions if needed)
>
> My question is:
> How should I include the three temporal factors (year, time of season and
> time of day) and driving direction in the logistic models for the two
> different objectives?
>
> Thanks in advance for your suggestions and comments.
> Cheers,
> Adjan
>
> Adriaan "Adjan" de Jong
> Associate professor
> Dept of Wildlife, Fish, and Environmental Studies
> Swedish University of Agricultural Sciences
>
> Data structure (fake numbers)
> YearMonthDayHourMinuteDirectionCount
> 199742591505
> 1997514153510
> 1997515745016
> .
> .
> 20218281000
>
> PS. I understand I have to combine the Mont and Day, and the Hour and
> Minute variables into two new variables for Time of season and Time of day..
>
> ---
> N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina
> personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <
> https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
> E-mailing SLU will result in SLU processing your personal data. For more
> information on how this is done, click here <
> https://www.slu.se/en/about-slu/contact-slu/personal-data/>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From zp@|mp@o @end|ng |rom gm@||@com  Wed Jan 12 20:06:50 2022
From: zp@|mp@o @end|ng |rom gm@||@com (Zach Simpson)
Date: Wed, 12 Jan 2022 11:06:50 -0800
Subject: [R-sig-ME] 
 How to include multiple temporal processes in one model?
Message-ID: <CAJByKzrQy3UXwr7Sk8ZszLxyD3OyyR-PCosLr91jT+ncWsgQTg@mail.gmail.com>

On Wed, 12 Jan 2022, Adriaan de Jong wrote:

Hi,
>
> Present:
> a 25 year series of count data of individuals of one migratory bird
> species observed from my driver's seat (2815 counts from the same c. 20 km
> road transect). The dataset includes the variables: Year, Month, Day, Hour,
> Minute (5 min precision), (driving)Direction and Count(result) (sample
> below).
>
> Objectives:
> 1. Has there been a trend in the numbers over the years?
> 2. How do the numbers generally vary over the breeding season? (I live in
> northern Sweden and the breeding/observation season is April-August)
> I have no intentions to make predictions for neither future developments
> (temporal extrapolation) nor other transects (spatial extrapolation).
>
> Problems/limitations:
> a. The sampling has been opportunistic (which was a main point because no
> extra effort was needed) and thus, unevenly spread over the hours of the
> day with more counts in the morning and late afternoon (most are from
> commuting to work).
> b. The distribution of the timing over the day has varied over the years.
> c. The dataset contains a significant proportion (43%) of zero counts,
> especially during the early and late parts of the breeding season.
> d. The number of transect counts has varied over the years (range 66-167,
> but no clear trend over the years)
> e. The direction of driving has an impact on what can be seen (non-flat
> landscape) and thus, needs to be included as a covariate (random effect?)
> (I can provide graphs of frequency distributions if needed)
>
> My question is:
> How should I include the three temporal factors (year, time of season and
> time of day) and driving direction in the logistic models for the two
> different objectives?
>
> Thanks in advance for your suggestions and comments.
> Cheers,
> Adjan
>
> Adriaan "Adjan" de Jong
> Associate professor
> Dept of Wildlife, Fish, and Environmental Studies
> Swedish University of Agricultural Sciences
>
> Data structure (fake numbers)
> YearMonthDayHourMinuteDirectionCount
> 199742591505
> 1997514153510
> 1997515745016
> .
> .
> 20218281000
>
> PS. I understand I have to combine the Mont and Day, and the Hour and
> Minute variables into two new variables for Time of season and Time of day..
>
> ---
> N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina
> personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <
> https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
> E-mailing SLU will result in SLU processing your personal data. For more
> information on how this is done, click here <
> https://www.slu.se/en/about-slu/contact-slu/personal-data/>


Hi Adjan,

At the moment, I can offer some suggestions on how to include the different
temporal trends (the first part of your question) for such a model via a
GAM. It could go something like the following:

library(tidyverse)
library(lubridate) # helps with time objects
library(hms) # for time of day objects
library(mgcv) # all things GAM

## fake data -- not entirely sure I parsed it correctly
fake_data <- tibble(
  date_time = ymd_hm(c(
    "1997-4-25 09:15", "1997-5-14 15:35",
    "1997-5-15 7:45", "2021-8-28 10:00"
  )),
  direction = c(0, 1, 1, 0),
  count = c(5, 0, 6, 0)
)

## create new time variables, in numeric form but still interpretable

# helper function to convert Date's to decimal years (e.g. June 2021 ~=
2021.5)
dec_year_from_date <- function(date){
  require(lubridate)
  dec_year = year(date) + (yday(date)/(ifelse(leap_year(date), 366, 365)))
  return(dec_year)
}

fake_data <- fake_data %>%
  mutate(
    DOY = yday(date_time), # day-of-year variable (1 to 366)
    time_of_day_s = as.numeric(as_hms(date_time)), # time-of-day variable
    time_of_day_h = time_of_day_s / (60 * 60), # in decimal h
    dec_year = dec_year_from_date(date_time)
  ) %>%
  select(date_time, dec_year, DOY, time_of_day_h, direction, count)

# structure now looks like:
head(fake_data)

## # A tibble: 4 x 6
##   date_time           dec_year   DOY time_of_day_h direction count
##   <dttm>                 <dbl> <dbl>         <dbl>     <dbl> <dbl>
## 1 1997-04-25 09:15:00    1997.315   115          9.25         0     5
## 2 1997-05-14 15:35:00    1997.367  134         15.6          1     0
## 3 1997-05-15 07:45:00    1997.370   135          7.75         1     6
## 4 2021-08-28 10:00:00    2022.658   240         10            0     0

Then you could use some different smooth terms within a GAM for each of the
temporal trends: a default smooth term for the long term trend and
cubic-cyclic splines (bs = 'cc') for the cyclical terms (season and time of
day). The following could be something to get started with:

# # GAM formula for yearly trend
# gam(count ~ direction +
#       s(dec_year) + # long-term trend
#       s(DOY, bs = 'cc') + # seasonal trend
#       s(time_of_day_h, bs = 'cc') # time of day trend
#     knots = list(DOY = c(1, 366), time_of_day_h = c(0, 24))
#     family = ??
#     data = fake_data
#     )

I've no expertise with count data (particularly with lots of zeros), so I
leave the family and link function up to you and the list.
Other terms (e.g., a random-effect for transect? - via s(transect, bs =
're')) and interactions could be built in. Perhaps seasonal trend varies
across years. Driving direction could be included as a 'by' variable in the
smooth terms as well to create factor smooth interactions. E.g. s(DOY, by =
direction, bs = 'cc') would create a seasonal smooth term that is
conditional on the driving direction.

Hope this helps,
Zach

-- 
Zach Simpson
Post-doc, Dept. Agronomy
Iowa State University

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Fri Jan 14 03:25:09 2022
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 13 Jan 2022 20:25:09 -0600
Subject: [R-sig-ME] nlme::gls() outputting behavior for missing data
Message-ID: <CACgv6yVhoDkYg2y6yf91Ba9_cULXhjs8OLnqtayWJSFEE+yZ2Q@mail.gmail.com>

Dear All,

In my `data` below, some combinations of `teaching_level:time` are missing.

When I use `nlme::gls()`, such missingness causes singularity, hence an
error stopping the entire model from being fit.

When I use `lm()`, such missingness causes NA only for the missing
combinations, but the model fits fine.

I wonder which behavior is more reasonable, specifically, assuming the
model specification is 100% accurate:

1- Is the `gls()` error really related to singularity or missingness?
2- NA coefficients aside, are the non-NA coefficients of `lm()` valid?
3- Is there a way for `gls()` to output the results like lm() and not stop?

Thank you,
Simon

######## Reproducible code:

library(nlme)

data <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/1.csv")

res1 <- lm(gi ~ 0 + teaching_level*time, data = data, na.action = "na.omit")

summary(res1)
Coefficients: (3 not defined because of singularities)
                                          Estimate Std. Error t value
Pr(>|t|)
.
.
.
teaching_levelelementary:timePost-test 2        NA         NA      NA
NA
teaching_levelmixed:timePost-test 2             NA         NA      NA
NA
teaching_levelsecondary:timePost-test 3        NA         NA      NA
NA


res2 <- gls(gi ~ 0 + teaching_level:time, data = data, na.action =
"na.omit")

Error: computed "gls" fit is singular, rank 10

	[[alternative HTML version deleted]]


From hu@ng@jcc @end|ng |rom gm@||@com  Tue Jan 18 17:09:36 2022
From: hu@ng@jcc @end|ng |rom gm@||@com (Sijia Huang)
Date: Tue, 18 Jan 2022 11:09:36 -0500
Subject: [R-sig-ME] Mixed effect model with lme4
Message-ID: <CAPmBuzH7nWHfhKjb685fKS0k8ih0zTq_Evi2iU2L+RipfOpKyA@mail.gmail.com>

Hi everyone,

I am trying to fit a mixed effect model using lme4. The random effect part
of the model is kind of tricky:

delta_{1s}*(alpha_i + beta_i * d_{t=0,i=1})

In which *delta_1s* is the random effect and are multiplied by the
quantities in the parentheses. The *alpha_i* and *beta_i* are parameters
that need to be estimated, while the d_t=0,i=1 is a dummy variable.

I wonder if this model can be specified with lme4 syntax. Thank you!


Best,
Sijia

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Jan 19 08:50:31 2022
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 19 Jan 2022 08:50:31 +0100
Subject: [R-sig-ME] Mixed effect model with lme4
In-Reply-To: <CAPmBuzH7nWHfhKjb685fKS0k8ih0zTq_Evi2iU2L+RipfOpKyA@mail.gmail.com>
References: <CAPmBuzH7nWHfhKjb685fKS0k8ih0zTq_Evi2iU2L+RipfOpKyA@mail.gmail.com>
Message-ID: <CAJuCY5ygzSYzE+0a531FpVeMu9WN-LTzD-HsPhSYgkiCVn2-JA@mail.gmail.com>

Dear Sijia,

I think you want (1 + d | delta). Keep in mind that this will fit a
different alpha_i and beta_i for every level of the random effect.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 18 jan. 2022 om 17:10 schreef Sijia Huang <huangsjcc at gmail.com>:

> Hi everyone,
>
> I am trying to fit a mixed effect model using lme4. The random effect part
> of the model is kind of tricky:
>
> delta_{1s}*(alpha_i + beta_i * d_{t=0,i=1})
>
> In which *delta_1s* is the random effect and are multiplied by the
> quantities in the parentheses. The *alpha_i* and *beta_i* are parameters
> that need to be estimated, while the d_t=0,i=1 is a dummy variable.
>
> I wonder if this model can be specified with lme4 syntax. Thank you!
>
>
> Best,
> Sijia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mek @end|ng |rom eco@@@u@dk  Thu Jan 20 10:29:45 2022
From: mek @end|ng |rom eco@@@u@dk (Mathias Emil Kaae)
Date: Thu, 20 Jan 2022 09:29:45 +0000
Subject: [R-sig-ME] Problems with warnings
Message-ID: <AM0PR01MB38128036BC224463DC75E58D985A9@AM0PR01MB3812.eurprd01.prod.exchangelabs.com>

To whom it concerns,

I am using the package glmmTMB to fit a mixed model with interactions using the beta-binomial distribution. I am trying to model plant cover data for specific species in a habitat using a randomized block design with five blocks and 16 plots within them. The question is: are this plant species increasing/decreasing its cover within different plots as a result of different treatments?

As I see it, I only get non-significant results (which is fine). However, I do get this warning when using the package glmmTMB:

Warning message:
In getReStruc(reTrms, ss, aa, reXterms, fr) :
AR1 not meaningful with intercept

Should I worry, and how can I solve this?

I have attached the code and a subset of the data.

Mathias Emil Kaae
PhD student, Aarhus University
Institut for Ecoscience
Vejls?vej 25, 8600 Silkeborg
Mobil nr.: + 45 61 72 14 01
E-mail: mek at bios.au.dk<mailto:mek at bios.au.dk>



From mo|||eebrook@ @end|ng |rom gm@||@com  Fri Jan 21 14:19:26 2022
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Fri, 21 Jan 2022 14:19:26 +0100
Subject: [R-sig-ME] Problems with warnings
In-Reply-To: <AM0PR01MB38128036BC224463DC75E58D985A9@AM0PR01MB3812.eurprd01.prod.exchangelabs.com>
References: <AM0PR01MB38128036BC224463DC75E58D985A9@AM0PR01MB3812.eurprd01.prod.exchangelabs.com>
Message-ID: <6C66E809-152A-491B-8A6B-B6ACB755B6DA@gmail.com>

Your attachments were removed by the system, so I can?t see the code. 

It sounds like you might need to add `+0` in your random effect specification.
Have you looked at the AR(1) documentation in this vignette?
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>
There it shows the term ar1(times + 0 | group)

cheers,
Mollie

> On 20 Jan 2022, at 10.29, Mathias Emil Kaae <mek at ecos.au.dk> wrote:
> 
> To whom it concerns,
> 
> I am using the package glmmTMB to fit a mixed model with interactions using the beta-binomial distribution. I am trying to model plant cover data for specific species in a habitat using a randomized block design with five blocks and 16 plots within them. The question is: are this plant species increasing/decreasing its cover within different plots as a result of different treatments?
> 
> As I see it, I only get non-significant results (which is fine). However, I do get this warning when using the package glmmTMB:
> 
> Warning message:
> In getReStruc(reTrms, ss, aa, reXterms, fr) :
> AR1 not meaningful with intercept
> 
> Should I worry, and how can I solve this?
> 
> I have attached the code and a subset of the data.
> 
> Mathias Emil Kaae
> PhD student, Aarhus University
> Institut for Ecoscience
> Vejls?vej 25, 8600 Silkeborg
> Mobil nr.: + 45 61 72 14 01
> E-mail: mek at bios.au.dk<mailto:mek at bios.au.dk>
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From Dr|e@@Debeer @end|ng |rom UGent@be  Tue Jan 25 18:04:53 2022
From: Dr|e@@Debeer @end|ng |rom UGent@be (Dries Debeer)
Date: Tue, 25 Jan 2022 17:04:53 +0000
Subject: [R-sig-ME] compare fit of GLMM with different link/family
Message-ID: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>

Dear,


I have a question about comparing the fit of GLMM with different link functions/families.

For instance, can the deviance or the AIC be used to compare the fit of probit and logit with the same parametrization?

probit_model <- glmer(Y ~ A + B + C*D + (A | subjects), data = data, family = binomial(link = "probit"))
logit_model <- glmer(Y ~ A + B + C*D + (A | subjects), data = data, family = binomial(link = "logit"))


And is this also possible when the distributional assumptions are different? For instance:

gamma_model <- glmer(X ~ A + B + C*D + (A | subjects), data = data, family = Gamma(link = "inverse"))
inverse_gauss <- glmer(X ~ A + B + C*D + (A | subjects), data = data, family = inverse.gaussian(link = "1/mu^2"))


Thank you!
Dries Debeer






	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Tue Jan 25 18:56:15 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 25 Jan 2022 11:56:15 -0600
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
Message-ID: <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>


On 25/1/22 11:04 am, Dries Debeer via R-sig-mixed-models wrote:
> Dear,
> 
> 
> I have a question about comparing the fit of GLMM with different link functions/families.
> 
> For instance, can the deviance or the AIC be used to compare the fit of probit and logit with the same parametrization?
> 
> probit_model <- glmer(Y ~ A + B + C*D + (A | subjects), data = data, family = binomial(link = "probit"))
> logit_model <- glmer(Y ~ A + B + C*D + (A | subjects), data = data, family = binomial(link = "logit"))

This is a surprisingly tough question, in my opinion. Neither the AIC
nor the deviance depend on the link itself, so in theory, you could
compare them ... but these models are not nested, and comparing
non-nested models is generally a tricky problem.  That said, probit and
logit models will tend to give very similar results in terms of
predictions/fit to the data. The bigger difference is how you interpret
coefficients, so I would chose between probit and logit based on desired
interpretation.

For other families/links, the comparison can get even more difficult.
For example, if you compare an inverse link with an identity link, then
you are comparing two very different albeit related quantities -- like
comparing a model of "speed" vs "time".

> 
> 
> And is this also possible when the distributional assumptions are different? For instance:
> 
> gamma_model <- glmer(X ~ A + B + C*D + (A | subjects), data = data, family = Gamma(link = "inverse"))
> inverse_gauss <- glmer(X ~ A + B + C*D + (A | subjects), data = data, family = inverse.gaussian(link = "1/mu^2"))

Not really, no. Both the deviance and the AIC are functions of the log
likelihood and the choice of family corresponds to a choice of
likelihood, so you're comparing different things.

Depending on what you're going for, looking at predictive power of the
models directly -- such as looking at mean squared or mean absolute
error computed with cross validation -- might work.

That said, the choice of family is a statement about your assumptions
and prior beliefs about the data. In a Bayesian context, McElreath has
described this as a "prior about the data" in Statistical Rethinking.
Gelman et al have also noted that the prior can only be understood in
the context of the likelihood -- all hinting at the core idea here,
namely that the family is an assumption about the conditional
distribution of your data (or equivalently, about the the distribution
of the error/noise in your data).

My previous point about the choice of link changing interpretation also
holds for changes in link accompanying changes in family -- the
statements you can make about your data based on an inverse link vs an
inverse square link are different.

I would be happy to hear other opinions here.

Hope that helps,
Phillip

> 
> Thank you!
> Dries Debeer
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From v|n|c|u@2042 @end|ng |rom hotm@||@com  Tue Jan 25 23:56:41 2022
From: v|n|c|u@2042 @end|ng |rom hotm@||@com (=?iso-8859-1?Q?Vin=EDcius_Carneiro_de_Souza?=)
Date: Tue, 25 Jan 2022 22:56:41 +0000
Subject: [R-sig-ME] Fitting linear mixed-effects models
Message-ID: <BL0PR02MB553731643D7D7A0822883498DF5F9@BL0PR02MB5537.namprd02.prod.outlook.com>

I am trying to fit a linear model using the lmer function from data collected from literature from multiple studies.
The response variable is the average daily gain of swine and the predictor is the different methionine sources in the different diets, which is a factor with 4 levels (4 different methionine sources)

My original model is below, which includes a random intercept for study effect:

#Z_ADG_g is the average daily gain
#MM_Type_met is the methionine source factor
#CO_Intra_Trial is the publication ID

ADGmod <- lmer(Z_ADG_g~MM_Type_met+(1|CO_Intra_Trial), data=ErmDat3, weight=ADG_wt, REML = FALSE)

summary(ADGmod)

I would like to look what would be the effect of considering that each methionine source tested has a different/separate intercept. I was reading a book chapter from Bates et al. and found a table with some syntaxes that could work to specifying different intercepts for each methionine source, but it is not working. The model still has only one intercept.

I tried the following model:

ADGmod <- lmer(Z_ADG_g~MM_Type_met+(1|CO_Intra_Trial)+(1|CO_Intra_Trial:MM_Type_met), data=ErmDat3, weight=ADG_wt, REML = FALSE)

summary(ADGmod)

Does anyone know if it is even possible what I am trying to do?


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Jan 26 03:09:09 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 25 Jan 2022 21:09:09 -0500
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
Message-ID: <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>

   I mostly agree.

   I would say that in general it's OK to compare models with different 
links, families, etc. via AIC *as long as you don't explicitly transform 
the response variable* -- i.e. you have to be careful comparing

  lm(log(y) ~ ....)

with

   lm(y ~ ...)

(you need a Jacobian term in the AIC expression to account for the 
change in scaling of the density), but comparing basically

   glm(y ~ ... , family = <anything>)

should be OK. That said, there is a strong minority view (Phillip may 
belong to this group) that says that using AIC to compare non-nested 
models is *not* OK: e.g. see 
https://stats.stackexchange.com/questions/116935/comparing-non-nested-models-with-aic/116951#116951
https://mathoverflow.net/questions/249448/use-of-akaike-information-criterion-with-nonnested-models

  (Unfortunately, really understanding why this should or should not 
work depends, I think, on understanding the rates of convergence of 
certain asymptotic expressions ...)

   I completely agree with Phillip on the rest, though, which is to say 
that you should think about **why** you want to test all these different 
cases. It's unlikely you're going to be able to frame *scientific* 
hypotheses in terms of these different models ("is it better to measure 
consumption in gallons per mile or miles per gallon?"). If you're purely 
interested in prediction, then I think AIC will often be an adequate 
approximation to something based on cross-validation (but it would be 
good to check with CV). On the other hand, if you're purely interested 
in prediction you might want to move in the direction of nonparametric 
models such as GAMs, which should make many of the distinctions between 
links irrelevant ...




On 1/25/22 12:56 PM, Phillip Alday wrote:
> 
> On 25/1/22 11:04 am, Dries Debeer via R-sig-mixed-models wrote:
>> Dear,
>>
>>
>> I have a question about comparing the fit of GLMM with different link functions/families.
>>
>> For instance, can the deviance or the AIC be used to compare the fit of probit and logit with the same parametrization?
>>
>> probit_model <- glmer(Y ~ A + B + C*D + (A | subjects), data = data, family = binomial(link = "probit"))
>> logit_model <- glmer(Y ~ A + B + C*D + (A | subjects), data = data, family = binomial(link = "logit"))
> 
> This is a surprisingly tough question, in my opinion. Neither the AIC
> nor the deviance depend on the link itself, so in theory, you could
> compare them ... but these models are not nested, and comparing
> non-nested models is generally a tricky problem.  That said, probit and
> logit models will tend to give very similar results in terms of
> predictions/fit to the data. The bigger difference is how you interpret
> coefficients, so I would chose between probit and logit based on desired
> interpretation.
> 
> For other families/links, the comparison can get even more difficult.
> For example, if you compare an inverse link with an identity link, then
> you are comparing two very different albeit related quantities -- like
> comparing a model of "speed" vs "time".
> 
>>
>>
>> And is this also possible when the distributional assumptions are different? For instance:
>>
>> gamma_model <- glmer(X ~ A + B + C*D + (A | subjects), data = data, family = Gamma(link = "inverse"))
>> inverse_gauss <- glmer(X ~ A + B + C*D + (A | subjects), data = data, family = inverse.gaussian(link = "1/mu^2"))
> 
> Not really, no. Both the deviance and the AIC are functions of the log
> likelihood and the choice of family corresponds to a choice of
> likelihood, so you're comparing different things.
> 
> Depending on what you're going for, looking at predictive power of the
> models directly -- such as looking at mean squared or mean absolute
> error computed with cross validation -- might work.
> 
> That said, the choice of family is a statement about your assumptions
> and prior beliefs about the data. In a Bayesian context, McElreath has
> described this as a "prior about the data" in Statistical Rethinking.
> Gelman et al have also noted that the prior can only be understood in
> the context of the likelihood -- all hinting at the core idea here,
> namely that the family is an assumption about the conditional
> distribution of your data (or equivalently, about the the distribution
> of the error/noise in your data).
> 
> My previous point about the choice of link changing interpretation also
> holds for changes in link accompanying changes in family -- the
> statements you can make about your data based on an inverse link vs an
> inverse square link are different.
> 
> I would be happy to hear other opinions here.
> 
> Hope that helps,
> Phillip
> 
>>
>> Thank you!
>> Dries Debeer
>>
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From Dr|e@@Debeer @end|ng |rom UGent@be  Wed Jan 26 08:29:49 2022
From: Dr|e@@Debeer @end|ng |rom UGent@be (Dries Debeer)
Date: Wed, 26 Jan 2022 07:29:49 +0000
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
 <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
Message-ID: <AM7PR09MB40713E81B4504BDB10EDF424E8209@AM7PR09MB4071.eurprd09.prod.outlook.com>

Dear Ben and Philliip, 

Thank you for your response and the pointers to the discussion! 

The reason for asking was finding the best fitting model for response times in an experimental setting. I agree that theoretical/scientific arguments for choosing models can outweigh purely maximizing the fit.

Dries

> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Ben Bolker
> Sent: woensdag 26 januari 2022 3:09
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] compare fit of GLMM with different link/family
> 
>    I mostly agree.
> 
>    I would say that in general it's OK to compare models with different links,
> families, etc. via AIC *as long as you don't explicitly transform the response
> variable* -- i.e. you have to be careful comparing
> 
>   lm(log(y) ~ ....)
> 
> with
> 
>    lm(y ~ ...)
> 
> (you need a Jacobian term in the AIC expression to account for the change in
> scaling of the density), but comparing basically
> 
>    glm(y ~ ... , family = <anything>)
> 
> should be OK. That said, there is a strong minority view (Phillip may belong to
> this group) that says that using AIC to compare non-nested models is *not*
> OK: e.g. see
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.
> stackexchange.com%2Fquestions%2F116935%2Fcomparing-non-nested-
> models-with-
> aic%2F116951%23116951&amp;data=04%7C01%7CDries.Debeer%40ugent.be
> %7Cc4b9f930b96b4395259808d9e070fd71%7Cd7811cdeecef496c8f91a178624
> 1b99c%7C1%7C0%7C637787598905000528%7CUnknown%7CTWFpbGZsb3d8e
> yJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D
> %7C3000&amp;sdata=5hbi6AF92Duw953axcH%2FMBHtjd9piahD7lk5mUdSH
> wU%3D&amp;reserved=0
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fmath
> overflow.net%2Fquestions%2F249448%2Fuse-of-akaike-information-
> criterion-with-nonnested-
> models&amp;data=04%7C01%7CDries.Debeer%40ugent.be%7Cc4b9f930b96
> b4395259808d9e070fd71%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0
> %7C637787598905000528%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjA
> wMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;s
> data=MmI5p%2Bq8Is9MwO86Jtp2q5Aq0KsAspYIwpLMWlBud%2F8%3D&am
> p;reserved=0
> 
>   (Unfortunately, really understanding why this should or should not work
> depends, I think, on understanding the rates of convergence of certain
> asymptotic expressions ...)
> 
>    I completely agree with Phillip on the rest, though, which is to say that you
> should think about **why** you want to test all these different cases. It's
> unlikely you're going to be able to frame *scientific* hypotheses in terms of
> these different models ("is it better to measure consumption in gallons per
> mile or miles per gallon?"). If you're purely interested in prediction, then I
> think AIC will often be an adequate approximation to something based on
> cross-validation (but it would be good to check with CV). On the other hand,
> if you're purely interested in prediction you might want to move in the
> direction of nonparametric models such as GAMs, which should make many
> of the distinctions between links irrelevant ...
> 
> 
> 
> 
> On 1/25/22 12:56 PM, Phillip Alday wrote:
> >
> > On 25/1/22 11:04 am, Dries Debeer via R-sig-mixed-models wrote:
> >> Dear,
> >>
> >>
> >> I have a question about comparing the fit of GLMM with different link
> functions/families.
> >>
> >> For instance, can the deviance or the AIC be used to compare the fit of
> probit and logit with the same parametrization?
> >>
> >> probit_model <- glmer(Y ~ A + B + C*D + (A | subjects), data = data,
> >> family = binomial(link = "probit")) logit_model <- glmer(Y ~ A + B +
> >> C*D + (A | subjects), data = data, family = binomial(link = "logit"))
> >
> > This is a surprisingly tough question, in my opinion. Neither the AIC
> > nor the deviance depend on the link itself, so in theory, you could
> > compare them ... but these models are not nested, and comparing
> > non-nested models is generally a tricky problem.  That said, probit
> > and logit models will tend to give very similar results in terms of
> > predictions/fit to the data. The bigger difference is how you
> > interpret coefficients, so I would chose between probit and logit
> > based on desired interpretation.
> >
> > For other families/links, the comparison can get even more difficult.
> > For example, if you compare an inverse link with an identity link,
> > then you are comparing two very different albeit related quantities --
> > like comparing a model of "speed" vs "time".
> >
> >>
> >>
> >> And is this also possible when the distributional assumptions are
> different? For instance:
> >>
> >> gamma_model <- glmer(X ~ A + B + C*D + (A | subjects), data = data,
> >> family = Gamma(link = "inverse")) inverse_gauss <- glmer(X ~ A + B +
> >> C*D + (A | subjects), data = data, family = inverse.gaussian(link =
> >> "1/mu^2"))
> >
> > Not really, no. Both the deviance and the AIC are functions of the log
> > likelihood and the choice of family corresponds to a choice of
> > likelihood, so you're comparing different things.
> >
> > Depending on what you're going for, looking at predictive power of the
> > models directly -- such as looking at mean squared or mean absolute
> > error computed with cross validation -- might work.
> >
> > That said, the choice of family is a statement about your assumptions
> > and prior beliefs about the data. In a Bayesian context, McElreath has
> > described this as a "prior about the data" in Statistical Rethinking.
> > Gelman et al have also noted that the prior can only be understood in
> > the context of the likelihood -- all hinting at the core idea here,
> > namely that the family is an assumption about the conditional
> > distribution of your data (or equivalently, about the the distribution
> > of the error/noise in your data).
> >
> > My previous point about the choice of link changing interpretation
> > also holds for changes in link accompanying changes in family -- the
> > statements you can make about your data based on an inverse link vs an
> > inverse square link are different.
> >
> > I would be happy to hear other opinions here.
> >
> > Hope that helps,
> > Phillip
> >
> >>
> >> Thank you!
> >> Dries Debeer
> >>
> >>
> >>
> >>
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >>
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsta
> >> t.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-
> models&amp;data=04%7C01%
> >>
> 7CDries.Debeer%40ugent.be%7Cc4b9f930b96b4395259808d9e070fd71%7Cd7
> 811c
> >>
> deecef496c8f91a1786241b99c%7C1%7C0%7C637787598905000528%7CUnkno
> wn%7CT
> >>
> WFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLC
> JXVC
> >>
> I6Mn0%3D%7C3000&amp;sdata=TMlKe3iOp2AqihyZIUF31KM7Tk%2B%2FkFq
> tL6Xbb1D
> >> dVl4%3D&amp;reserved=0
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> > .ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-
> models&amp;data=04%7C01%7C
> >
> Dries.Debeer%40ugent.be%7Cc4b9f930b96b4395259808d9e070fd71%7Cd781
> 1cdee
> >
> cef496c8f91a1786241b99c%7C1%7C0%7C637787598905000528%7CUnknown
> %7CTWFpb
> >
> GZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI
> 6Mn0
> >
> %3D%7C3000&amp;sdata=TMlKe3iOp2AqihyZIUF31KM7Tk%2B%2FkFqtL6Xb
> b1DdVl4%3
> > D&amp;reserved=0
> >
> 
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.e
> thz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-
> models&amp;data=04%7C01%7CDries.Debeer%40ugent.be%7Cc4b9f930b96
> b4395259808d9e070fd71%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0
> %7C637787598905000528%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjA
> wMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;s
> data=TMlKe3iOp2AqihyZIUF31KM7Tk%2B%2FkFqtL6Xbb1DdVl4%3D&amp;re
> served=0


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Jan 26 17:01:11 2022
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 26 Jan 2022 17:01:11 +0100
Subject: [R-sig-ME] Fitting linear mixed-effects models
In-Reply-To: <BL0PR02MB553731643D7D7A0822883498DF5F9@BL0PR02MB5537.namprd02.prod.outlook.com>
References: <BL0PR02MB553731643D7D7A0822883498DF5F9@BL0PR02MB5537.namprd02.prod.outlook.com>
Message-ID: <CAJuCY5wi30J7PeqXwLA-x23UdFz58bPqfzyVqZAgsc4Nxvms6g@mail.gmail.com>

Do you want a random effect for methionine source at the study level? That
could work with the alternative model you specified. However, that assumes
that you have multiple records for every combination of study and
methionine source. I would expect that you have only one record for each of
those combinations.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 25 jan. 2022 om 23:57 schreef Vin?cius Carneiro de Souza <
vinicius2042 at hotmail.com>:

> I am trying to fit a linear model using the lmer function from data
> collected from literature from multiple studies.
> The response variable is the average daily gain of swine and the predictor
> is the different methionine sources in the different diets, which is a
> factor with 4 levels (4 different methionine sources)
>
> My original model is below, which includes a random intercept for study
> effect:
>
> #Z_ADG_g is the average daily gain
> #MM_Type_met is the methionine source factor
> #CO_Intra_Trial is the publication ID
>
> ADGmod <- lmer(Z_ADG_g~MM_Type_met+(1|CO_Intra_Trial), data=ErmDat3,
> weight=ADG_wt, REML = FALSE)
>
> summary(ADGmod)
>
> I would like to look what would be the effect of considering that each
> methionine source tested has a different/separate intercept. I was reading
> a book chapter from Bates et al. and found a table with some syntaxes that
> could work to specifying different intercepts for each methionine source,
> but it is not working. The model still has only one intercept.
>
> I tried the following model:
>
> ADGmod <-
> lmer(Z_ADG_g~MM_Type_met+(1|CO_Intra_Trial)+(1|CO_Intra_Trial:MM_Type_met),
> data=ErmDat3, weight=ADG_wt, REML = FALSE)
>
> summary(ADGmod)
>
> Does anyone know if it is even possible what I am trying to do?
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jan 27 01:12:43 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 26 Jan 2022 19:12:43 -0500
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <25073.33190.950579.366630@chmusic.org>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
 <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
 <25073.33190.950579.366630@chmusic.org>
Message-ID: <55fb8647-b184-0bba-3e5c-f399342ce63d@gmail.com>



On 1/26/22 12:15 PM, Don Cohen wrote:
> 
> not sure this should be sent to r-sig-mixed-models at r-project.org,
> feel free to post it there if so
> 
>   >    I would say that in general it's OK to compare models with different
>   > links, families, etc. via AIC *as long as you don't explicitly transform
>   > the response variable* -- i.e. you have to be careful comparing
>   >
>   >   lm(log(y) ~ ....)
>   >
>   > with
>   >
>   >    lm(y ~ ...)
>   >
>   > (you need a Jacobian term in the AIC expression to account for the
>   > change in scaling of the density), but comparing basically
> 
> This doesn't make any sense to me.
> There are only two parts to AIC, log liklihood and a parameter
> correction.  What does this transform have to do with either?
> If you get a better loglik for the transformed version I'd just
> say that model fits the data better.
> (Whereas the parameter correction has to do with what you think
> makes a model better outside of fit to data, and is more subjective.)
> 
> Actually I do have a complaint about loglik -- I think it would
> be fixed by really computing the probability of response given
> inputs, and that this could be done pretty easily by simply
> admitting that the responses are not exact measurements, and
> changing them to ranges or at worst distributions.  Could THAT
> be related to the transform problem?  If so then this seems like
> a solution.
> 
> Perhaps you can give me a reference to what I'm missing.
> I also don't see what nested models have to do with this.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From me @end|ng |rom ph||||p@|d@y@com  Thu Jan 27 06:58:17 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 26 Jan 2022 23:58:17 -0600
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <55fb8647-b184-0bba-3e5c-f399342ce63d@gmail.com>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
 <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
 <25073.33190.950579.366630@chmusic.org>
 <55fb8647-b184-0bba-3e5c-f399342ce63d@gmail.com>
Message-ID: <6c9236cf-6b3b-37bb-43ce-b1a33b40cf81@phillipalday.com>

(resending without a digital signature)

@Don: I think the part you're missing is that the likelihood depends on
the data and if you transform the data (e.g. via log), then you've
changed the data and now have a different likelihood. A little bit more
precisely: the likelihood of the model is the probability of the
parameters _conditional_ on the data.[*] For linear transformations of
the data, everything is fine, but for nonlinear transformations, you
need to take into account the distortion they introduce on the parameter
space, which is what the Jacobian does. Digging down a bit deeper, the
likelihood is ultimately an integral and any transformation of the data
corresponds to a change of variables in that integral. For nonlinear
transformations, that means you now have a Jacobian to deal with. (For
linear transformations, you can still be off by a multiplicative
constant, but that doesn't matter for finding the location of the
optimum, i.e. the parameters corresponding to the maximum likelihood.)

The "exact measurements" issue is, in the usual interpretation,
typically taken to be handled by treating the response as a distribution
and the inexactness there is part of the probability. There are some
types of models that can take estimated uncertainties around the
response into account -- this is more uncommon in the physical sciences
where measurements instruments have a well-calibrated uncertainty. But
this does come up in things like meta-analysis, where the response is
actually previous estimates and associated uncertainty. (For the
predictor variables, erorrs-within-measurement is a very different
story, at least on the frequentist side of things.) Your proposal of
changing everything to be a distribution corresponds well to the
Bayesian idea that basically everything is a random variable in the
technical sense, and you can chose many levels down you to model that. 

My apologies to the math stats crowd; I know I've been not particularly
rigorous, but I was hoping to convey the general intuition.

[*] There's some fine print here if we're talking about the likelihood
as a score function or a conditional probability, but the fine print
doesn't matter for the argument at hand.

On 1/26/22 18:12, Ben Bolker wrote:
>
>
> On 1/26/22 12:15 PM, Don Cohen wrote:
>>
>> not sure this should be sent to r-sig-mixed-models at r-project.org,
>> feel free to post it there if so
>>
>> ? >??? I would say that in general it's OK to compare models with
>> different
>> ? > links, families, etc. via AIC *as long as you don't explicitly
>> transform
>> ? > the response variable* -- i.e. you have to be careful comparing
>> ? >
>> ? >?? lm(log(y) ~ ....)
>> ? >
>> ? > with
>> ? >
>> ? >??? lm(y ~ ...)
>> ? >
>> ? > (you need a Jacobian term in the AIC expression to account for the
>> ? > change in scaling of the density), but comparing basically
>>
>> This doesn't make any sense to me.
>> There are only two parts to AIC, log liklihood and a parameter
>> correction.? What does this transform have to do with either?
>> If you get a better loglik for the transformed version I'd just
>> say that model fits the data better.
>> (Whereas the parameter correction has to do with what you think
>> makes a model better outside of fit to data, and is more subjective.)
>>
>> Actually I do have a complaint about loglik -- I think it would
>> be fixed by really computing the probability of response given
>> inputs, and that this could be done pretty easily by simply
>> admitting that the responses are not exact measurements, and
>> changing them to ranges or at worst distributions.? Could THAT
>> be related to the transform problem?? If so then this seems like
>> a solution.
>>
>> Perhaps you can give me a reference to what I'm missing.
>> I also don't see what nested models have to do with this.
>


From me @end|ng |rom ph||||p@|d@y@com  Thu Jan 27 07:09:14 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 27 Jan 2022 00:09:14 -0600
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <AM7PR09MB40713E81B4504BDB10EDF424E8209@AM7PR09MB4071.eurprd09.prod.outlook.com>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
 <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
 <AM7PR09MB40713E81B4504BDB10EDF424E8209@AM7PR09MB4071.eurprd09.prod.outlook.com>
Message-ID: <16b0c567-a763-0d2f-ba92-e8cf9033453e@phillipalday.com>

Oh, have you been reading the Lo and Andrews paper
(https://doi.org/10.3389/fpsyg.2015.01171)? I've developed a little bit
of a reputation for my skepticism regarding that paper. :)

(On a purely practical point, I'll note that that paper discusses using
a gamma family model with identity link, but those often have
convergence issues in my experience, even beyond my philosophical points
below.)

To refine my previous comments a bit: I think AIC is as good as anything
else for comparing non-nested models, but that it's generally just very
hard to compare non-nested models without a domain- or even
problem-specific notion about what's "better". For nested models, we
can often ignore the difficulty of "how much better is a meaningful
difference?" by using the likelihood-ratio test and the conventional
significance framework, but that's not without problems. In other words,
my whole skepticism here is a mixture of "what do we mean by 'better'?"
and "are we doing anything that my inner mathematician would be
uncomfortable with?".

There is a fair amount of work looking for the "ideal" model of response
time -- what family, what link function, should we transform the
response time (e.g. log transform), etc. For me, it really depends on
what your hypothesis is like -- each of these choices corresponds to
different hypotheses and different assumptions. For example, if you
assume that your experimental manipulation will have multiplicative
effects, then log-transforming your responses times seems reasonable
because additive effects on the log scale correspond to multiplicative
effects on the original scale. But this goes both ways: if you're
log-transforming "just" to address skew (e.g. the long right tail you
often see in RT experiments), then you're still changing the precise
hypothesis being tested. If you're using a non-identity link function,
then there is still a transformation going on, just in a different place
(which impacts whether the residual error is also transformed).
Similarly, your choice of model family reflects both an assumption about
the general shape of the conditional (~error) distribution and how you
weigh errors. (This point also ties into the use of e.g. the Student-t
distribution as a model family in robust statistics.)

To bring it back around, the questions I would ask myself are:
- What model structure best encodes my hypotheses?
- After fitting that model, does that model capture the overall
structure of my data? If not, then that's already a rejection of the
exact formulation of my hypotheses, but it might still be good to some
explorative work looking at other model formulations as a way to update
my hypotheses for the next experiment.

This is also where people worry about violating model assumptions --
whether a particular violation is bad depends on what you're looking at.
For example, heavier than normal tails will make your standard errors a
bit misleading, but usually won't mess up your estimates too much. But a
strong skew might mean that your estimates aren't good representations
of your data -- much in the same that the mean is often not a good
summary of strongly skewed data (e.g., mean vs. median income as
measures of typical incomes).

If's not already very clear, I often think of models as quantitative
summaries of data. A good summary depends on pulling out the important
bits and the important bits are always dependent on your ultimate
(inferential) goals. :)

Also, since you're looking at RT, two more specific hints/tips. :)
- Reinhold Kliegl has pointed me towards using speed (i.e. 1/RT) instead
of reaction time (I think he's basing this on Box-Cox transformations),
and I've often been quite happily surprised by how well this works. The
inversion handles the long tails nicely and speed is easier to interpret
than log RT. And we often speak of things in terms of speed anyway,
e.g., we expect participants to be faster in one condition than another.

- Check out Jonas Lindel?v's great write-up on RT distribution:
http://lindeloev.net/shiny/rt/. It also really covers a few different
types of common hypotheses and how these can appear as distributions. I
would also like to note that I've had some RT experiments where the RT
was -- to the disbelief of the reviewers -- well represented by a normal
distribution when the right covariates were included. :)

I hope that helps!
Best,
Phillip



On 26/1/22 1:29 am, Dries Debeer via R-sig-mixed-models wrote:
> Dear Ben and Philliip, 
> 
> Thank you for your response and the pointers to the discussion! 
> 
> The reason for asking was finding the best fitting model for response times in an experimental setting. I agree that theoretical/scientific arguments for choosing models can outweigh purely maximizing the fit.
> 
> Dries
> 
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
>> Behalf Of Ben Bolker
>> Sent: woensdag 26 januari 2022 3:09
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] compare fit of GLMM with different link/family
>>
>>    I mostly agree.
>>
>>    I would say that in general it's OK to compare models with different links,
>> families, etc. via AIC *as long as you don't explicitly transform the response
>> variable* -- i.e. you have to be careful comparing
>>
>>   lm(log(y) ~ ....)
>>
>> with
>>
>>    lm(y ~ ...)
>>
>> (you need a Jacobian term in the AIC expression to account for the change in
>> scaling of the density), but comparing basically
>>
>>    glm(y ~ ... , family = <anything>)
>>
>> should be OK. That said, there is a strong minority view (Phillip may belong to
>> this group) that says that using AIC to compare non-nested models is *not*
>> OK: e.g. see
>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.
>> stackexchange.com%2Fquestions%2F116935%2Fcomparing-non-nested-
>> models-with-
>> aic%2F116951%23116951&amp;data=04%7C01%7CDries.Debeer%40ugent.be
>> %7Cc4b9f930b96b4395259808d9e070fd71%7Cd7811cdeecef496c8f91a178624
>> 1b99c%7C1%7C0%7C637787598905000528%7CUnknown%7CTWFpbGZsb3d8e
>> yJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D
>> %7C3000&amp;sdata=5hbi6AF92Duw953axcH%2FMBHtjd9piahD7lk5mUdSH
>> wU%3D&amp;reserved=0
>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fmath
>> overflow.net%2Fquestions%2F249448%2Fuse-of-akaike-information-
>> criterion-with-nonnested-
>> models&amp;data=04%7C01%7CDries.Debeer%40ugent.be%7Cc4b9f930b96
>> b4395259808d9e070fd71%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0
>> %7C637787598905000528%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjA
>> wMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;s
>> data=MmI5p%2Bq8Is9MwO86Jtp2q5Aq0KsAspYIwpLMWlBud%2F8%3D&am
>> p;reserved=0
>>
>>   (Unfortunately, really understanding why this should or should not work
>> depends, I think, on understanding the rates of convergence of certain
>> asymptotic expressions ...)
>>
>>    I completely agree with Phillip on the rest, though, which is to say that you
>> should think about **why** you want to test all these different cases. It's
>> unlikely you're going to be able to frame *scientific* hypotheses in terms of
>> these different models ("is it better to measure consumption in gallons per
>> mile or miles per gallon?"). If you're purely interested in prediction, then I
>> think AIC will often be an adequate approximation to something based on
>> cross-validation (but it would be good to check with CV). On the other hand,
>> if you're purely interested in prediction you might want to move in the
>> direction of nonparametric models such as GAMs, which should make many
>> of the distinctions between links irrelevant ...
>>
>>
>>
>>
>> On 1/25/22 12:56 PM, Phillip Alday wrote:
>>>
>>> On 25/1/22 11:04 am, Dries Debeer via R-sig-mixed-models wrote:
>>>> Dear,
>>>>
>>>>
>>>> I have a question about comparing the fit of GLMM with different link
>> functions/families.
>>>>
>>>> For instance, can the deviance or the AIC be used to compare the fit of
>> probit and logit with the same parametrization?
>>>>
>>>> probit_model <- glmer(Y ~ A + B + C*D + (A | subjects), data = data,
>>>> family = binomial(link = "probit")) logit_model <- glmer(Y ~ A + B +
>>>> C*D + (A | subjects), data = data, family = binomial(link = "logit"))
>>>
>>> This is a surprisingly tough question, in my opinion. Neither the AIC
>>> nor the deviance depend on the link itself, so in theory, you could
>>> compare them ... but these models are not nested, and comparing
>>> non-nested models is generally a tricky problem.  That said, probit
>>> and logit models will tend to give very similar results in terms of
>>> predictions/fit to the data. The bigger difference is how you
>>> interpret coefficients, so I would chose between probit and logit
>>> based on desired interpretation.
>>>
>>> For other families/links, the comparison can get even more difficult.
>>> For example, if you compare an inverse link with an identity link,
>>> then you are comparing two very different albeit related quantities --
>>> like comparing a model of "speed" vs "time".
>>>
>>>>
>>>>
>>>> And is this also possible when the distributional assumptions are
>> different? For instance:
>>>>
>>>> gamma_model <- glmer(X ~ A + B + C*D + (A | subjects), data = data,
>>>> family = Gamma(link = "inverse")) inverse_gauss <- glmer(X ~ A + B +
>>>> C*D + (A | subjects), data = data, family = inverse.gaussian(link =
>>>> "1/mu^2"))
>>>
>>> Not really, no. Both the deviance and the AIC are functions of the log
>>> likelihood and the choice of family corresponds to a choice of
>>> likelihood, so you're comparing different things.
>>>
>>> Depending on what you're going for, looking at predictive power of the
>>> models directly -- such as looking at mean squared or mean absolute
>>> error computed with cross validation -- might work.
>>>
>>> That said, the choice of family is a statement about your assumptions
>>> and prior beliefs about the data. In a Bayesian context, McElreath has
>>> described this as a "prior about the data" in Statistical Rethinking.
>>> Gelman et al have also noted that the prior can only be understood in
>>> the context of the likelihood -- all hinting at the core idea here,
>>> namely that the family is an assumption about the conditional
>>> distribution of your data (or equivalently, about the the distribution
>>> of the error/noise in your data).
>>>
>>> My previous point about the choice of link changing interpretation
>>> also holds for changes in link accompanying changes in family -- the
>>> statements you can make about your data based on an inverse link vs an
>>> inverse square link are different.
>>>
>>> I would be happy to hear other opinions here.
>>>
>>> Hope that helps,
>>> Phillip
>>>
>>>>
>>>> Thank you!
>>>> Dries Debeer
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>>
>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsta
>>>> t.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-
>> models&amp;data=04%7C01%
>>>>
>> 7CDries.Debeer%40ugent.be%7Cc4b9f930b96b4395259808d9e070fd71%7Cd7
>> 811c
>>>>
>> deecef496c8f91a1786241b99c%7C1%7C0%7C637787598905000528%7CUnkno
>> wn%7CT
>>>>
>> WFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLC
>> JXVC
>>>>
>> I6Mn0%3D%7C3000&amp;sdata=TMlKe3iOp2AqihyZIUF31KM7Tk%2B%2FkFq
>> tL6Xbb1D
>>>> dVl4%3D&amp;reserved=0
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
>>> .ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-
>> models&amp;data=04%7C01%7C
>>>
>> Dries.Debeer%40ugent.be%7Cc4b9f930b96b4395259808d9e070fd71%7Cd781
>> 1cdee
>>>
>> cef496c8f91a1786241b99c%7C1%7C0%7C637787598905000528%7CUnknown
>> %7CTWFpb
>>>
>> GZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI
>> 6Mn0
>>>
>> %3D%7C3000&amp;sdata=TMlKe3iOp2AqihyZIUF31KM7Tk%2B%2FkFqtL6Xb
>> b1DdVl4%3
>>> D&amp;reserved=0
>>>
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> (Acting) Graduate chair, Mathematics & Statistics
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.e
>> thz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-
>> models&amp;data=04%7C01%7CDries.Debeer%40ugent.be%7Cc4b9f930b96
>> b4395259808d9e070fd71%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0
>> %7C637787598905000528%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjA
>> wMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;s
>> data=TMlKe3iOp2AqihyZIUF31KM7Tk%2B%2FkFqtL6Xbb1DdVl4%3D&amp;re
>> served=0
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From p@ych@o||u @end|ng |rom gm@||@com  Thu Jan 27 19:00:00 2022
From: p@ych@o||u @end|ng |rom gm@||@com (Chao Liu)
Date: Thu, 27 Jan 2022 13:00:00 -0500
Subject: [R-sig-ME] Simulate type I error
Message-ID: <CACCU-vOHJAA2+qdtoZwO4wZZs+OUZX3n6asrjMpC3a36RfFJ8w@mail.gmail.com>

Dear R-sig-mixed-models community,

I would like to simulate type I error for a random-effects model I
generated.

The statistic of interest is standard deviations of the random intercept
and random slope. Specifically, for random intercept, H_{0}: lambda_{0} =2
and H_{1}: lambda_{0} not equal to 2; for random slope, H_{0}: lambda_{1}
=1 and H_{1}: lambda_{1} not equal to 1. I assume the test would be a
likelihood ratio test but please correct me if I am wrong. How do I assess
type I error for the random-effects model I specified below:

set.seed(323)
#The following code is to specify the structure and parameters of the
random-effects model
dtfunc = function(nsub){
  time = 0:9
  rt = c()
  time.all = rep(time, nsub)
  subid.all = as.factor(rep(1:nsub, each = length(time)))

  # Step 1:  Specify the lambdas.
  G = matrix(c(2^2, 0, 0, 1^2), nrow = 2)
  int.mean = 251
  slope.mean = 10
  sub.ints.slopes = mvrnorm(nsub, c(int.mean, slope.mean), G)
  sub.ints = sub.ints.slopes[,1]
  time.slopes = sub.ints.slopes[,2]

  # Step 2:  Use the intercepts and slopes to generate RT data
  sigma = 30
  for (i in 1:nsub){
    rt.vec = sub.ints[i] + time.slopes[i]*time + rnorm(length(time), sd =
sigma)
    rt = c(rt, rt.vec)
  }

  dat = data.frame(rt, time.all, subid.all)
  return(dat)
}

#Here I run one random-effects model
set.seed(10)
dat = dtfunc(16)
lmer(rt~time.all + (1+time.all |subid.all), dat)

Assuming the test for significance is likelihood ratio test and so in the
end, I want to see if I run the test 1000 times, what is the probability of
rejecting the null hypothesis when it is TRUE. Also, how do I plot the
behavior of type I error if I change the values of standard deviations?

Any help is appreciated!

Best,

Chao

	[[alternative HTML version deleted]]


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Thu Jan 27 22:46:08 2022
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Thu, 27 Jan 2022 21:46:08 +0000
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <9271f2f3-058c-e545-58b5-44b17c51752a@phillipalday.com>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
 <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
 <25073.33190.950579.366630@chmusic.org>
 <55fb8647-b184-0bba-3e5c-f399342ce63d@gmail.com>
 <9271f2f3-058c-e545-58b5-44b17c51752a@phillipalday.com>
Message-ID: <25075.4768.580057.25339@chmusic.org>

Phillip Alday writes:

 > @Don: I think the part you're missing is that the likelihood
 > depends on the data and if you transform the data (e.g. via log),
 > then you've changed the data and now have a different likelihood.

I'm not sure what you mean by changing the data, but the fact that
you change the likelihood seems to be just as true for any other 
change to the model.
 log(output) ~ input
and
 output ~ input
are two different models just like they're both different from
 output ~ input^2

 > precisely: the likelihood of the model is the probability of the
 > parameters _conditional_ on the data.[*]

[I assume by parameters you mean what I call the output (dependent variable)
and by the data you mean what I call the inputs - the independent variables)]
But this gets back to my argument below that the likelihood is not really
the same as probability...

 > For linear transformations of the data, everything is fine,

But my example above with input^2 was not a linear transformation of the 
data, was it?  You don't think it's fair to compare loglik of
 output ~ input  with that of  ouput ~ input^2  ?
Oh, I guess not - that's your argument about nested models.
But I also don't understand that.

It seems to me that conditional probability of output given model and
input is a measure of how well the output fits the input+model and it
makes sense even to compare that even for different combinations of
input, output, model.  I see that more rows of data will inevitably
reduce that probability, so perhaps a good measure would be to divide
log of prob by #rows, i.e., average log of probability per row.

 > but for nonlinear transformations, you need to take into account
 > the distortion they introduce on the parameter space, which is what
 > the Jacobian does. Digging down a bit deeper, the likelihood is
 > ultimately an integral and any transformation of the data

I thought the likelihood was computed by just evaluating the PDF.
Is that necessarily an integral ?  Is that related to your 
description of treating the response as a distribution?

What you write above does not convey to me exactly what problem is
being solved or how it's being solved, but I get the feeling that your
transformation might be the same thing I was complaining about.
See what you think:

My complaint is illustrated by the fact that the loglik can be
positive - because the pdf can be > 1.  Whereas the actual probability
could be computed by changing the output value to a range and taking
the difference between the values of the cdf at the two ends of the
range (maybe you'd call that integration).  If you did that, say, for
an output of 1.23, which I'd require you to change to an interval, say
[1.225 - 1.235], then in order to compare the REAL probability (rather
than the likelihood) of this model to that of another model using
log(output), the interval would become [log(1.225) - log(1.235)],
right?  Does that seem to correspond to your correction?

 > (For linear transformations, you can still be off by a
 > multiplicative constant, but that doesn't matter for finding the
 > location of the optimum, i.e. the parameters corresponding to the
 > maximum likelihood.)

Again I might not be following you, but I think this may be related to
the fact that loglik can be positive -- which means to me that even
though you've found the optimal estimates, your loglik is NOT a
reasonable estimate of the PROBABILITY of the output given the input +
model.  And for model comparison I would want the log of the
probability, not something that could be off by some (arbitrarily
large) constant that might be different for different models.

So if loglik is computed as I think it is, then it's questionable
whether it can be compared between different models at all, whereas
if log prob were computed as I describe, then it would make sense to
compare it for any two models, even if the output were transformed.

I hope that makes sense?

Or, of course, tell me where I've gone wrong.


From jhw||@on@nb @end|ng |rom gm@||@com  Tue Feb  1 14:13:58 2022
From: jhw||@on@nb @end|ng |rom gm@||@com (John Wilson)
Date: Tue, 1 Feb 2022 09:13:58 -0400
Subject: [R-sig-ME] glmmTMB model specification - autocorrelation
Message-ID: <CABdA5Q0QxtXTKk3EsJ=kGexPNjP0XVdEEHH7tfJPFzVB_DXmQA@mail.gmail.com>

Dear list,

I'm working on a large spatiotemporal dataset. It's a grid of 20  fixed
cells, laid out as A-E, 1-4 (think chessboard), and animals are counted in
each cell, about once an hour (but can change), during daylight, for about
one month a year. So lots of temporally adjacent samples, separated by ~10
h overnight, and separated by 11 months between years. Each hourly-ish
sampling, which goes over as many cells in the grid as possible given
weather, has a unique identifier (say, SamplingRound). There is a spatial
gradient of animals north-south (A-E) and also east-west (1-4).

I'm trying to run this using either temporal or spatial autocorrelation, to
see whether either one resolves the autocorrelation issues. Most of the
examples I've seen set up the autocorrelation within the random factor
group, and I can't figure out whether that applies here or how to do it. So
I have three questions - one per paragraph below.

I'm using glmmTMB so that I can use a negbin (potentially zero-inflated,
still sorting that out) while using an autocorrelation structure. I assume
that the random intercept is the individual cell (so, A1, A2, A3, A4, A5,
B1, ..., E5), since they're measured repeatedly. Assuming that's correct -
question #1) given the gradient across A-E and across 1-4, is it possible
to have 2 main fixed effects (one for A-E and one for 1-4) in addition to
the random effect of individual cell? I know that factors generally can't
be used for both, but in this case the fixed effects only have A-E OR 1-4
whereas the random effect has the individual cell ID.

Is it correct that temporal autocorrelation would need to be expressed
between sampling times within each sampling day, within each cell? This
results in a total of 6,000 groups (20 cells times 30 sampling days per
year, times 10 sampling years), and trying to run this gives a memory
error. Question #2: is this the correct specification  and my computer just
can't handle it, or is it wrong? This is the setup of the random portion:
(1|Cell) + ou(time.within.day + 0 | YearDayF_Cell), where times.within.day
are a numFactor.

For spatial autocorrelation, I _think_ that I would need to express it
across all cells within each sampling round, so question #3: is it correct
to have the random portion be (1|Cell) + exp(pos + 0 | SamplingRound),
where pos is numFactor(data$Easting, data$Northing)?

Any advice would be very much appreciated!
John

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Feb  2 03:05:27 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 1 Feb 2022 21:05:27 -0500
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <25075.4768.580057.25339@chmusic.org>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
 <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
 <25073.33190.950579.366630@chmusic.org>
 <55fb8647-b184-0bba-3e5c-f399342ce63d@gmail.com>
 <9271f2f3-058c-e545-58b5-44b17c51752a@phillipalday.com>
 <25075.4768.580057.25339@chmusic.org>
Message-ID: <6fa6458e-96d5-3ee2-909f-a569852f8f36@gmail.com>

   Getting back to this late.

On 1/27/22 4:46 PM, Don Cohen wrote:
> Phillip Alday writes:
> 
>   > @Don: I think the part you're missing is that the likelihood
>   > depends on the data and if you transform the data (e.g. via log),
>   > then you've changed the data and now have a different likelihood.
> 
> I'm not sure what you mean by changing the data, but the fact that
> you change the likelihood seems to be just as true for any other
> change to the model.
>   log(output) ~ input
> and
>   output ~ input
> are two different models just like they're both different from
>   output ~ input^2
> 
>   > precisely: the likelihood of the model is the probability of the
>   > parameters _conditional_ on the data.[*]
> 
> [I assume by parameters you mean what I call the output (dependent variable)
> and by the data you mean what I call the inputs - the independent variables)]
> But this gets back to my argument below that the likelihood is not really
> the same as probability...
> 
>   > For linear transformations of the data, everything is fine,
> 
> But my example above with input^2 was not a linear transformation of the
> data, was it?  You don't think it's fair to compare loglik of
>   output ~ input  with that of  ouput ~ input^2  ?
> Oh, I guess not - that's your argument about nested models.
> But I also don't understand that.

   I think Phillip meant "transform the *response variable*" specifically.

> 
> It seems to me that conditional probability of output given model and
> input is a measure of how well the output fits the input+model and it
> makes sense even to compare that even for different combinations of
> input, output, model.  I see that more rows of data will inevitably
> reduce that probability, so perhaps a good measure would be to divide
> log of prob by #rows, i.e., average log of probability per row.
> 
>   > but for nonlinear transformations, you need to take into account
>   > the distortion they introduce on the parameter space, which is what
>   > the Jacobian does. Digging down a bit deeper, the likelihood is
>   > ultimately an integral and any transformation of the data
> 
> I thought the likelihood was computed by just evaluating the PDF.
> Is that necessarily an integral ?  Is that related to your
> description of treating the response as a distribution?

> 
> What you write above does not convey to me exactly what problem is
> being solved or how it's being solved, but I get the feeling that your
> transformation might be the same thing I was complaining about.
> See what you think:
> 
> My complaint is illustrated by the fact that the loglik can be
> positive - because the pdf can be > 1.  Whereas the actual probability
> could be computed by changing the output value to a range and taking
> the difference between the values of the cdf at the two ends of the
> range (maybe you'd call that integration).  If you did that, say, for
> an output of 1.23, which I'd require you to change to an interval, say
> [1.225 - 1.235], then in order to compare the REAL probability (rather
> than the likelihood) of this model to that of another model using
> log(output), the interval would become [log(1.225) - log(1.235)],
> right?  Does that seem to correspond to your correction?
> 
>   > (For linear transformations, you can still be off by a
>   > multiplicative constant, but that doesn't matter for finding the
>   > location of the optimum, i.e. the parameters corresponding to the
>   > maximum likelihood.)
> 
> Again I might not be following you, but I think this may be related to
> the fact that loglik can be positive -- which means to me that even
> though you've found the optimal estimates, your loglik is NOT a
> reasonable estimate of the PROBABILITY of the output given the input +
> model.  And for model comparison I would want the log of the
> probability, not something that could be off by some (arbitrarily
> large) constant that might be different for different models.
> 
> So if loglik is computed as I think it is, then it's questionable
> whether it can be compared between different models at all, whereas
> if log prob were computed as I describe, then it would make sense to
> compare it for any two models, even if the output were transformed.
> 
> I hope that makes sense?
> 
> Or, of course, tell me where I've gone wrong.
> 

   I think this all basically makes sense.  I would phrase it as saying 
that what we are doing when we calculate the "(log)likelihood" of a 
*continuous* response is in practice calculating a (log) likelihood 
*density* (that's why the value can be >1); as Phillip suggests, if we 
write it out as a likelihood then there is an implicit 'delta-x' in the 
expression that makes it a probability.  When we take the log that turns 
into an additive constant, and we know that we can drop additive 
constants without affecting the inferential machinery.
    Put another way, as long as our implicit dx is the *same* throughout 
our equations, we can ignore it.

    The other complication is that the likelihood of a mixed model 
*does* involve an integral (but it's an integral over the random 
effects, and doesn't come into the argument above).

   Hope that helps.

   Ben Bolker


From me @end|ng |rom ph||||p@|d@y@com  Wed Feb  2 03:44:50 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 1 Feb 2022 20:44:50 -0600
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <6fa6458e-96d5-3ee2-909f-a569852f8f36@gmail.com>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
 <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
 <25073.33190.950579.366630@chmusic.org>
 <55fb8647-b184-0bba-3e5c-f399342ce63d@gmail.com>
 <9271f2f3-058c-e545-58b5-44b17c51752a@phillipalday.com>
 <25075.4768.580057.25339@chmusic.org>
 <6fa6458e-96d5-3ee2-909f-a569852f8f36@gmail.com>
Message-ID: <b78fae57-9a2b-7d91-9565-d6af2f68f764@phillipalday.com>

I've also not had time to try to clarify what I was writing. It was a
little bit garbled (that's what I get for replying quickly and late in
the evening) -- my apologies! And thanks, Ben, for helping to clear up
my garbled responses. :)

1. Yep, I was referring to the response ("output").

2. The integral I was getting at was that the conditional mean (roughly,
the predicted response) is an expectation and expectations of continuous
random variables are integrals. But perhaps the better way to think
about why transformation of the _response_ makes things not comparable
is to think about means. At their heart, (both mixed and classical OLS)
regression models make statements about conditional means. Let's look at
a concrete example.

In general log(mean(y)) != mean(log(y)), and this creates the
incompatibility between the model y ~ x and log(y) ~ x. So if you try to
minimize the mean squared error (i.e. maximize the likelihood) relative
to log(y), that will in general not occur at the same point in parameter
space as minimizing the mean squared error relative to y. In other
words, can't simply take the predictions from y ~ x and log-transform
them to get the predictions from log(y) ~ x.

Does that make things a little bit clearer?


On 1/2/22 8:05 pm, Ben Bolker wrote:
>    Getting back to this late.
> 
> On 1/27/22 4:46 PM, Don Cohen wrote:
>> Phillip Alday writes:
>>
>>   > @Don: I think the part you're missing is that the likelihood
>>   > depends on the data and if you transform the data (e.g. via log),
>>   > then you've changed the data and now have a different likelihood.
>>
>> I'm not sure what you mean by changing the data, but the fact that
>> you change the likelihood seems to be just as true for any other
>> change to the model.
>>   log(output) ~ input
>> and
>>   output ~ input
>> are two different models just like they're both different from
>>   output ~ input^2
>>
>>   > precisely: the likelihood of the model is the probability of the
>>   > parameters _conditional_ on the data.[*]
>>
>> [I assume by parameters you mean what I call the output (dependent variable)
>> and by the data you mean what I call the inputs - the independent variables)]
>> But this gets back to my argument below that the likelihood is not really
>> the same as probability...
>>
>>   > For linear transformations of the data, everything is fine,
>>
>> But my example above with input^2 was not a linear transformation of the
>> data, was it?  You don't think it's fair to compare loglik of
>>   output ~ input  with that of  ouput ~ input^2  ?
>> Oh, I guess not - that's your argument about nested models.
>> But I also don't understand that.
> 
>    I think Phillip meant "transform the *response variable*" specifically.
> 
>>
>> It seems to me that conditional probability of output given model and
>> input is a measure of how well the output fits the input+model and it
>> makes sense even to compare that even for different combinations of
>> input, output, model.  I see that more rows of data will inevitably
>> reduce that probability, so perhaps a good measure would be to divide
>> log of prob by #rows, i.e., average log of probability per row.
>>
>>   > but for nonlinear transformations, you need to take into account
>>   > the distortion they introduce on the parameter space, which is what
>>   > the Jacobian does. Digging down a bit deeper, the likelihood is
>>   > ultimately an integral and any transformation of the data
>>
>> I thought the likelihood was computed by just evaluating the PDF.
>> Is that necessarily an integral ?  Is that related to your
>> description of treating the response as a distribution?
> 
>>
>> What you write above does not convey to me exactly what problem is
>> being solved or how it's being solved, but I get the feeling that your
>> transformation might be the same thing I was complaining about.
>> See what you think:
>>
>> My complaint is illustrated by the fact that the loglik can be
>> positive - because the pdf can be > 1.  Whereas the actual probability
>> could be computed by changing the output value to a range and taking
>> the difference between the values of the cdf at the two ends of the
>> range (maybe you'd call that integration).  If you did that, say, for
>> an output of 1.23, which I'd require you to change to an interval, say
>> [1.225 - 1.235], then in order to compare the REAL probability (rather
>> than the likelihood) of this model to that of another model using
>> log(output), the interval would become [log(1.225) - log(1.235)],
>> right?  Does that seem to correspond to your correction?
>>
>>   > (For linear transformations, you can still be off by a
>>   > multiplicative constant, but that doesn't matter for finding the
>>   > location of the optimum, i.e. the parameters corresponding to the
>>   > maximum likelihood.)
>>
>> Again I might not be following you, but I think this may be related to
>> the fact that loglik can be positive -- which means to me that even
>> though you've found the optimal estimates, your loglik is NOT a
>> reasonable estimate of the PROBABILITY of the output given the input +
>> model.  And for model comparison I would want the log of the
>> probability, not something that could be off by some (arbitrarily
>> large) constant that might be different for different models.
>>
>> So if loglik is computed as I think it is, then it's questionable
>> whether it can be compared between different models at all, whereas
>> if log prob were computed as I describe, then it would make sense to
>> compare it for any two models, even if the output were transformed.
>>
>> I hope that makes sense?
>>
>> Or, of course, tell me where I've gone wrong.
>>
> 
>    I think this all basically makes sense.  I would phrase it as saying 
> that what we are doing when we calculate the "(log)likelihood" of a 
> *continuous* response is in practice calculating a (log) likelihood 
> *density* (that's why the value can be >1); as Phillip suggests, if we 
> write it out as a likelihood then there is an implicit 'delta-x' in the 
> expression that makes it a probability.  When we take the log that turns 
> into an additive constant, and we know that we can drop additive 
> constants without affecting the inferential machinery.
>     Put another way, as long as our implicit dx is the *same* throughout 
> our equations, we can ignore it.
> 
>     The other complication is that the likelihood of a mixed model 
> *does* involve an integral (but it's an integral over the random 
> effects, and doesn't come into the argument above).
> 
>    Hope that helps.
> 
>    Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Wed Feb  2 10:15:10 2022
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Wed, 2 Feb 2022 09:15:10 +0000
Subject: [R-sig-ME] glmmTMB model specification - autocorrelation (John
 Wilson)
In-Reply-To: <mailman.19572.1529.1643769920.912.r-sig-mixed-models@r-project.org>
References: <mailman.19572.1529.1643769920.912.r-sig-mixed-models@r-project.org>
Message-ID: <62ea7083-967a-1620-0ace-ba7c9da48366@highstat.com>


Dear list,

I'm working on a large spatiotemporal dataset. It's a grid of 20 fixed
cells, laid out as A-E, 1-4 (think chessboard), and animals are counted in
each cell, about once an hour (but can change), during daylight, for about
one month a year. So lots of temporally adjacent samples, separated by ~10
h overnight, and separated by 11 months between years. Each hourly-ish
sampling, which goes over as many cells in the grid as possible given
weather, has a unique identifier (say, SamplingRound). There is a spatial
gradient of animals north-south (A-E) and also east-west (1-4).

I'm trying to run this using either temporal or spatial autocorrelation, to
see whether either one resolves the autocorrelation issues. Most of the
examples I've seen set up the autocorrelation within the random factor
group, and I can't figure out whether that applies here or how to do it. So
I have three questions - one per paragraph below.

I'm using glmmTMB so that I can use a negbin (potentially zero-inflated,
still sorting that out) while using an autocorrelation structure. I assume
that the random intercept is the individual cell (so, A1, A2, A3, A4, A5,
B1, ..., E5), since they're measured repeatedly. Assuming that's correct -
question #1) given the gradient across A-E and across 1-4, is it possible
to have 2 main fixed effects (one for A-E and one for 1-4) in addition to
the random effect of individual cell? I know that factors generally can't
be used for both, but in this case the fixed effects only have A-E OR 1-4
whereas the random effect has the individual cell ID.

Is it correct that temporal autocorrelation would need to be expressed
between sampling times within each sampling day, within each cell? This
results in a total of 6,000 groups (20 cells times 30 sampling days per
year, times 10 sampling years), and trying to run this gives a memory
error. Question #2: is this the correct specification and my computer just
can't handle it, or is it wrong? This is the setup of the random portion:
(1|Cell) + ou(time.within.day + 0 | YearDayF_Cell), where times.within.day
are a numFactor.

For spatial autocorrelation, I _think_ that I would need to express it
across all cells within each sampling round, so question #3: is it correct
to have the random portion be (1|Cell) + exp(pos + 0 | SamplingRound),
where pos is numFactor(data$Easting, data$Northing)?

Any advice would be very much appreciated!
John




John...you may want to have a look at R-INLA. It is relatively easy to 
implement a spatial-temporal GLM (and it can do a range of distributions 
for count data) in INLA. And you may need some smoothers of time as 
well. It can do all that.


Alain


-- 
Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Wed Feb  2 18:36:18 2022
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Wed, 2 Feb 2022 17:36:18 +0000
Subject: [R-sig-ME] compare fit of GLMM with different link/family
In-Reply-To: <6fa6458e-96d5-3ee2-909f-a569852f8f36@gmail.com>
References: <AM7PR09MB4071367C2403250F0E3C712BE85F9@AM7PR09MB4071.eurprd09.prod.outlook.com>
 <c70ab33d-f723-9a5b-e3bd-8e279c0f5b24@phillipalday.com>
 <897f0d62-1868-b987-45b7-d06f1fb7733a@gmail.com>
 <25073.33190.950579.366630@chmusic.org>
 <55fb8647-b184-0bba-3e5c-f399342ce63d@gmail.com>
 <9271f2f3-058c-e545-58b5-44b17c51752a@phillipalday.com>
 <25075.4768.580057.25339@chmusic.org>
 <6fa6458e-96d5-3ee2-909f-a569852f8f36@gmail.com>
Message-ID: <25082.49426.310017.590008@chmusic.org>

Ben Bolker writes:
 >    Getting back to this late.

Thanks for getting back to it.

 > I think this all basically makes sense.  I would phrase it as
 > saying that what we are doing when we calculate the
 > "(log)likelihood" of a *continuous* response is in practice
 > calculating a (log) likelihood *density* (that's why the value can
 > be >1); as Phillip suggests, if we write it out as a likelihood
 > then there is an implicit 'delta-x' in the expression that makes it
 > a probability.  When we take the log that turns into an additive
 > constant, and we know that we can drop additive constants without
 > affecting the inferential machinery.

Do you include AIC as part of inferential machinery?  
To me AIC makes sense if loglik is really log of a probability 
(which would make it a measure of information).
And the probability depends on these deltas.  Which are not 
necessarily the same for all values of the response variable.
I can see the AIC reported as a sort of "AIC density" which
has to be multiplied by the size of a neighborhood representing
the intervals for all the outputs.

 > Put another way, as long as our implicit dx is the *same*
 > throughout our equations, we can ignore it.

Equations?  I think it's ok, at least for this argument, to 
imagine that the independent variables are exact and that the 
model is exact, but if you want to compute a probability of the
output (dependent variable) then considering the output values 
exact would mean a probability of zero for any continuous 
distribution.  The probability of the output makes sense if
the outputs are all changed to ranges reflecting measurement
error (and for that matter the information content of the
outputs).  If all of the values of the dependent variable have 
the same delta (which would be unusual if the measurements 
cover several orders of magnitude), and assuming that delta
is small enough so that the PDF doesn't change much over
any of those ranges then the probability would be
 your "density" likelihood function * (delta ^ #datapoints).
Your loglik density could be viewed as the probability if all 
of the deltas = 1, and when loglik>0 then clearly the pdf 
changes a lot over that delta.

So you're assuming several conditions that are not always met.
Or making several approximations that can sometimes be good and 
other times be bad.  (I guess you'll say, yes, and a lot more
assumptions/approximations besides!)

Especially when the output values range over several orders of
magnitude it seems unlikely that they represent intervals of
the same size and much more likely that the logs represent
intervals of similar sizes.  
In any case, the intervals can't be the same sizes for both 
the original outputs and their logs.

It occurs to me that your approximation of just measuring the 
pdf at one point assumes the same value for the entire interval, 
which makes all of the deltas independent - the formula above 
could be claimed to account for different deltas by changing
delta ^ #datapoints with the product of the deltas.  
But really each interval should be evaluated on the CDF to 
account for the fact that the PDF changes over the interval.

Do you agree that the probabilities I would compute with 
ranges of outputs would be comparable to those I'd compute
with log transformed ranges in another model?  I had the
impression before that this was the same correction as the 
one you've referred to (not quite described).  But it now
occurs to me that your correction may only be correcting for
the size of the intervals, and not also for the changes in
the PDF over the intervals.  

Where can I find more details on the correction for 
transformation of the output variable?

 >  The other complication is that the likelihood of a mixed model
 > *does* involve an integral (but it's an integral over the random
 > effects, and doesn't come into the argument above).

I think I understand that random effects involve an integral,
but I don't yet see the complication that introduces.
Perhaps it's related to how that integral is evaluated?


From md_p@rvezqure@h| @end|ng |rom hotm@||@com  Wed Feb  2 17:17:33 2022
From: md_p@rvezqure@h| @end|ng |rom hotm@||@com (Parvez Qureshi)
Date: Wed, 2 Feb 2022 16:17:33 +0000
Subject: [R-sig-ME] How to generate P value for each level in lmer package
Message-ID: <BM1PR0101MB187447CF5514C690CAA5E937F2279@BM1PR0101MB1874.INDPRD01.PROD.OUTLOOK.COM>

Hi All,

This is regarding a query regarding lmer package where I am trying to generate price elasticities for different level in mixed data. Although I am getting coefficients using coef () function for each level specified in equation but wanted to generate P Value for each level along with coefficient.

Coud anyone please suggest how can we generate P value for each level.

Regards,
Parvez


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Feb  3 00:43:51 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 2 Feb 2022 18:43:51 -0500
Subject: [R-sig-ME] 
 How to generate P value for each level in lmer package
In-Reply-To: <BM1PR0101MB187447CF5514C690CAA5E937F2279@BM1PR0101MB1874.INDPRD01.PROD.OUTLOOK.COM>
References: <BM1PR0101MB187447CF5514C690CAA5E937F2279@BM1PR0101MB1874.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <726c3433-2843-5644-f98c-9c45c86cce1a@gmail.com>

   This doesn't really give enough details for me (us) to understand 
what you want.

   car::Anova() will give you a p-value for each term.

   emmeans will give you expected marginal means and p-values for 
various combinations of levels

   multcomp::glht can be helpful too.

   If these don't answer your question, please reply with a bit more 
detail/a simple example.

   cheers
    Ben Bolker



On 2/2/22 11:17 AM, Parvez Qureshi wrote:
> Hi All,
> 
> This is regarding a query regarding lmer package where I am trying to generate price elasticities for different level in mixed data. Although I am getting coefficients using coef () function for each level specified in equation but wanted to generate P Value for each level along with coefficient.
> 
> Coud anyone please suggest how can we generate P value for each level.
> 
> Regards,
> Parvez
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From |@|@n @end|ng |rom vu@n|  Thu Feb  3 20:45:47 2022
From: |@|@n @end|ng |rom vu@n| (Fan, L.)
Date: Thu, 3 Feb 2022 19:45:47 +0000
Subject: [R-sig-ME] Post-hoc analysis for the effect of a lower-order
 interaction
In-Reply-To: <mailman.19557.3.1642590002.18669.r-sig-mixed-models@r-project.org>
References: <mailman.19557.3.1642590002.18669.r-sig-mixed-models@r-project.org>
Message-ID: <9F587FF1-E8A3-4820-AAEB-E671B61FC974@vu.nl>

Hi everyone,

I recently got stuck in the post-hoc analysis for my model?s interactions. 

Let?s say the interaction in the model is A:B:C, with the three variables being all two-level factors. I want to check if the effect of A:B varies across the two levels of C (getting a t-test between C?s two levels, as what we get from the pairs() function for getting the difference of marginal means/slopes in a 2-way interaction).

I?ve tried both emmeans and emtrends functions but failed. It always ended up expanding the higher-order interaction of all the three variables into basic cell contrasts (i.e. on specific levels of A and B), but not provided the overall contrast of how the lower-order interaction (A:B) performs in general on the two different levels of C. I also tried the joint_test function, but there is only the output of coefficients but not a between-level comparison on C. I am looking for the estimations of A:B on the two levels of C, and a t-test between these two estimations at the same time. Is this possible only using the emmeans package? Can I have some hints from you guys?

Thanks a lot!

Cheers,
Lei

From j@kob@@@ch@uer @end|ng |rom un|-kon@t@nz@de  Fri Feb  4 11:15:04 2022
From: j@kob@@@ch@uer @end|ng |rom un|-kon@t@nz@de (Jakob Aschauer)
Date: Fri, 4 Feb 2022 11:15:04 +0100
Subject: [R-sig-ME] Emmeans Effectsizes and Equivalence Tests
Message-ID: <8608B720-F178-4FEF-9A66-DDB3A8B1217A@uni-konstanz.de>

Hello everyone,

Here?s another set of emmeans-related problems or uncertainties. I?m using a beta-bionomial model to analyze a set of correctly vs. incorrectly given answers in a psychological experiment. Although the first is more a statistical question, i?ll give it a try here. Guess there should be some experts for all of this among you.

To compare experimental conditions, i defined some custom emmeans contrasts (using contrast(method = list(c(?))). For beta-binomial GLMs, emmeans calculates comparisons on the logit scale, thus provides logs of odds ratios. Additionally i?m using the eff_size() function to determine standardized mean differences (with sigma = stats::sigma(model), edf = df.residual(model)). This should give me Cohen?s d as calculated via d = b/?.  However, i?m a little confused since on the internet i?ve also seen the formula d = b ? ?3/? to convert logits to Cohen?s d. So how comes this contradiction? And in general i wonder which makes more sense in this case, reporting OR, or d, or both of them?
For the analysis i also need equivalence tests, and i?m using two one-sided tests for that via emmeans::contrast(delta = 0.3 * stats::sigma(model)), in order to classify all differences with less than a small effectsize (d = 0.3) as equal (using the Cohen?s d to logits conversion formula used by emmeans itself). I found that suggestion somewhere, but in case you?re having different suggestions, please let me know. However, i can?t implement the ?equivalence? side argument since the output always states that p values are left-tailed, not two-sided. I?ve been playing around with placing the side argument within contrast() or summary(), also with method ?pairwise? instead of my custom contrasts, but it won?t work. In the emmeans vignette on p. 70 it says ?The misc slot in object may contain default values for by, calc, infer, level, adjust, type, null, side, and delta?, which might be the reason. But i don?t arrive to change anything about that using the update method as suggested. Does anyone know a solution? 
Thanks a lot for helping out!

Cheers
Jakob




	[[alternative HTML version deleted]]


From v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com  Fri Feb  4 12:10:58 2022
From: v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com (Vinicius Maia)
Date: Fri, 4 Feb 2022 08:10:58 -0300
Subject: [R-sig-ME] 
 How to generate P value for each level in lmer package
In-Reply-To: <726c3433-2843-5644-f98c-9c45c86cce1a@gmail.com>
References: <BM1PR0101MB187447CF5514C690CAA5E937F2279@BM1PR0101MB1874.INDPRD01.PROD.OUTLOOK.COM>
 <726c3433-2843-5644-f98c-9c45c86cce1a@gmail.com>
Message-ID: <CAMXcYmbJe-yZFoZ3=eNPEbEnAxPYCvh7fhyWdJoS1OA53aKNyA@mail.gmail.com>

Hi,

If I understand correctly, you can get the p-values using lmerTest. Load
the package before running the model and the p-values will appear in the
model summary.

Best regards,
Vin?cius Maia

Em qua., 2 de fev. de 2022 ?s 20:51, Ben Bolker <bbolker at gmail.com>
escreveu:

>    This doesn't really give enough details for me (us) to understand
> what you want.
>
>    car::Anova() will give you a p-value for each term.
>
>    emmeans will give you expected marginal means and p-values for
> various combinations of levels
>
>    multcomp::glht can be helpful too.
>
>    If these don't answer your question, please reply with a bit more
> detail/a simple example.
>
>    cheers
>     Ben Bolker
>
>
>
> On 2/2/22 11:17 AM, Parvez Qureshi wrote:
> > Hi All,
> >
> > This is regarding a query regarding lmer package where I am trying to
> generate price elasticities for different level in mixed data. Although I
> am getting coefficients using coef () function for each level specified in
> equation but wanted to generate P Value for each level along with
> coefficient.
> >
> > Coud anyone please suggest how can we generate P value for each level.
> >
> > Regards,
> > Parvez
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From y@@hree19 @end|ng |rom gm@||@com  Fri Feb  4 15:03:21 2022
From: y@@hree19 @end|ng |rom gm@||@com (Yashree Mehta)
Date: Fri, 4 Feb 2022 15:03:21 +0100
Subject: [R-sig-ME] lmer estimation with repeated identifiers
Message-ID: <CAOE=hqJMyR69+0FnikO6ya13R=uwAK+9++uX0HVgHLS_Z9_Jsw@mail.gmail.com>

Hi,

I am working with a random intercept model on a cluster dataset (Repeated
measurements of plots per household). I have the usual "X" vector
of covariates and one id variable which will make up the random
intercept. For example,

Response variable: Production of a crop
Covariates: Size, input quantities, soil fertility dummies etc..
ID variable: Household_ID

Now one aspect of my data is that for some cases, the same plot is repeated
within a household due to different seasons. So this would leave me with
duplicate occurrence of the combination of household ID and plot ID.

My question is: Is the treatment of such data different than the
traditional panel data random effects (because to specify random effects
one has to specify a unique combination of household and plot for every
observation). Is the MLE of lmer different than random effects in such a
case? I tried to compare the two but random effects estimation cannot be
implemented with such data.

Thank you,

Regards,
Yashree

	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Fri Feb  4 21:34:08 2022
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Fri, 4 Feb 2022 20:34:08 +0000
Subject: [R-sig-ME] Post-hoc analysis for the effect of a lower-order
 interaction
Message-ID: <DM6PR04MB4474BE9F393BAE5A0DF8E367F1299@DM6PR04MB4474.namprd04.prod.outlook.com>

Please refer to the package's vignette on interactions:
    https://cran.r-project.org/web/packages/emmeans/vignettes/interactions.html

The simple way is to use the 'interaction' argument in 'contrast()' to generate interaction contrasts. For example:

    > library(emmens)

    > noise.lm <- lm(noise/10 ~ size * type * side, data = auto.noise)
    > EMM <- emmeans(noise.lm, ~ size*side*type)

    > contrast(EMM, interaction = "pairwise")
     size_pairwise side_pairwise type_pairwise estimate    SE df t.ratio p.value
     S - M         L - R         Std - Octel       0.50 0.624 24   0.802  0.4305
     S - L         L - R         Std - Octel       2.67 0.624 24   4.276  0.0003
     M - L         L - R         Std - Octel       2.17 0.624 24   3.474  0.0020

It is possible to do this manually by using 'contrast()' (or 'pairs()' method for pairwise comparisons) to create contrasts for one factor, calling 'contrast()' on the result to obtain contrasts of contrasts, etc. Here is the same example (with a multiplicity adjustment added) done manually:

> PR1 = pairs(EMM, by = c("side", "type"), name = "size.diff")
> PR2 = pairs(PR1, by = c("size.diff", "type"), name = "side.diff")
> PR3 = pairs(PR2, by = c("size.diff", "side.diff"), name = "type.diff")

> test(PR3, by = NULL, adjust = "sidak")
 type.diff   size.diff side.diff estimate    SE df t.ratio p.value
 Std - Octel S - M     L - R         0.50 0.624 24   0.802  0.8153
 Std - Octel S - L     L - R         2.67 0.624 24   4.276  0.0008
 Std - Octel M - L     L - R         2.17 0.624 24   3.474  0.0059

P value adjustment: sidak method for 3 tests

Russ Lenth

> Hi everyone,
>
> I recently got stuck in the post-hoc analysis for my model's interactions. 
>
>Let's say the interaction in the model is A:B:C, with the three variables being all two-level factors. I want to check if the effect of A:B varies across the two levels of C (getting a t-test between C's two levels, as what we get from the pairs() function for getting the difference of marginal means/slopes in a 2-way interaction).
>
> I've tried both emmeans and emtrends functions but failed. It always ended up expanding the higher-order interaction of all the three variables into basic cell contrasts (i.e. on specific levels of A and B), but not provided the overall contrast of how the lower-order interaction (A:B) performs in general on the two different levels of C. I also tried the joint_test function, but there is only the output of coefficients but not a between-level comparison on C. I am looking for the estimations of A:B on the two levels of C, and a t-test between these two estimations at the same time. Is this possible only using the emmeans package? Can I have some hints from you guys?


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Fri Feb  4 21:51:21 2022
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Fri, 4 Feb 2022 20:51:21 +0000
Subject: [R-sig-ME] Emmeans Effectsizes and Equivalence Tests
Message-ID: <DM6PR04MB44744910DDB2FC1BBFED01AAF1299@DM6PR04MB4474.namprd04.prod.outlook.com>


I will answer the part about equivalence tests.

If you do not specify a side, you *do* obtain a two-sided test of equivalence. As documented in the help page for 'summary.emmGrid' (in the section on noninferiority, nonsuperiority, and equivalence, the test statistic is 

    t = (|estimate - null| - delta) / SE

and that the P value is the left-tailed probability. This is equivalent to the TOST method because the absolute value in there makes it test the less significant of the two tests. You can confirm this by looking at the separate cases where estimate < null and estimate > null.

Russ Lenth

-----Original Message-----

Hello everyone,

Here?s another set of emmeans-related problems or uncertainties. I?m using a beta-bionomial model to analyze a set of correctly vs. incorrectly given answers in a psychological experiment. Although the first is more a statistical question, i?ll give it a try here. Guess there should be some experts for all of this among you.

To compare experimental conditions, i defined some custom emmeans contrasts (using contrast(method = list(c(?))). For beta-binomial GLMs, emmeans calculates comparisons on the logit scale, thus provides logs of odds ratios. Additionally i?m using the eff_size() function to determine standardized mean differences (with sigma = stats::sigma(model), edf = df.residual(model)). This should give me Cohen?s d as calculated via d = b/?.  However, i?m a little confused since on the internet i?ve also seen the formula d = b ? ?3/? to convert logits to Cohen?s d. So how comes this contradiction? And in general i wonder which makes more sense in this case, reporting OR, or d, or both of them?
For the analysis i also need equivalence tests, and i?m using two one-sided tests for that via emmeans::contrast(delta = 0.3 * stats::sigma(model)), in order to classify all differences with less than a small effectsize (d = 0.3) as equal (using the Cohen?s d to logits conversion formula used by emmeans itself). I found that suggestion somewhere, but in case you?re having different suggestions, please let me know. However, i can?t implement the ?equivalence? side argument since the output always states that p values are left-tailed, not two-sided. I?ve been playing around with placing the side argument within contrast() or summary(), also with method ?pairwise? instead of my custom contrasts, but it won?t work. In the emmeans vignette on p. 70 it says ?The misc slot in object may contain default values for by, calc, infer, level, adjust, type, null, side, and delta?, which might be the reason. But i don?t arrive to change anything about that using the update method as suggested. Does anyone know a solution? 
Thanks a lot for helping out!

Cheers
Jakob


From j@kob@@@ch@uer @end|ng |rom un|-kon@t@nz@de  Sat Feb  5 12:00:55 2022
From: j@kob@@@ch@uer @end|ng |rom un|-kon@t@nz@de (Jakob Aschauer)
Date: Sat, 5 Feb 2022 12:00:55 +0100
Subject: [R-sig-ME] Emmeans Effectsizes and Equivalence Tests
In-Reply-To: <DM6PR04MB44744910DDB2FC1BBFED01AAF1299@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <DM6PR04MB44744910DDB2FC1BBFED01AAF1299@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <DFCC71E1-9FB4-4C24-8A09-B03C354C3618@uni-konstanz.de>

Hello Russ,

thanks a lot for the response, that clarifies my uncertainties about the equivalence tests. I was already hoping a bit what you said, but wasn?t quite sure.

So in your eyes, does it also make sense to define delta as depending on sigma, following the Cohen?s d calculation used by eff_size()? I wonder wether it applies to GLMs as well. Maybe i?ll just play around with the other formula i mentioned and see what that changes (d = b ? ?3/?). Only problem is that i think it assumes equal group sizes.

Cheers
Jakob 



> Am 04.02.2022 um 21:51 schrieb Lenth, Russell V <russell-lenth at uiowa.edu>:
> 
> 
> I will answer the part about equivalence tests.
> 
> If you do not specify a side, you *do* obtain a two-sided test of equivalence. As documented in the help page for 'summary.emmGrid' (in the section on noninferiority, nonsuperiority, and equivalence, the test statistic is 
> 
>    t = (|estimate - null| - delta) / SE
> 
> and that the P value is the left-tailed probability. This is equivalent to the TOST method because the absolute value in there makes it test the less significant of the two tests. You can confirm this by looking at the separate cases where estimate < null and estimate > null.
> 
> Russ Lenth
> 
> -----Original Message-----
> 
> Hello everyone,
> 
> Here?s another set of emmeans-related problems or uncertainties. I?m using a beta-bionomial model to analyze a set of correctly vs. incorrectly given answers in a psychological experiment. Although the first is more a statistical question, i?ll give it a try here. Guess there should be some experts for all of this among you.
> 
> To compare experimental conditions, i defined some custom emmeans contrasts (using contrast(method = list(c(?))). For beta-binomial GLMs, emmeans calculates comparisons on the logit scale, thus provides logs of odds ratios. Additionally i?m using the eff_size() function to determine standardized mean differences (with sigma = stats::sigma(model), edf = df.residual(model)). This should give me Cohen?s d as calculated via d = b/?.  However, i?m a little confused since on the internet i?ve also seen the formula d = b ? ?3/? to convert logits to Cohen?s d. So how comes this contradiction? And in general i wonder which makes more sense in this case, reporting OR, or d, or both of them?
> For the analysis i also need equivalence tests, and i?m using two one-sided tests for that via emmeans::contrast(delta = 0.3 * stats::sigma(model)), in order to classify all differences with less than a small effectsize (d = 0.3) as equal (using the Cohen?s d to logits conversion formula used by emmeans itself). I found that suggestion somewhere, but in case you?re having different suggestions, please let me know. However, i can?t implement the ?equivalence? side argument since the output always states that p values are left-tailed, not two-sided. I?ve been playing around with placing the side argument within contrast() or summary(), also with method ?pairwise? instead of my custom contrasts, but it won?t work. In the emmeans vignette on p. 70 it says ?The misc slot in object may contain default values for by, calc, infer, level, adjust, type, null, side, and delta?, which might be the reason. But i don?t arrive to change anything about that using the update method as suggested. Does anyone know a solution? 
> Thanks a lot for helping out!
> 
> Cheers
> Jakob
> 


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Sat Feb  5 15:51:52 2022
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Sat, 5 Feb 2022 14:51:52 +0000
Subject: [R-sig-ME] 
 [External] Re: Emmeans Effectsizes and Equivalence Tests
In-Reply-To: <DFCC71E1-9FB4-4C24-8A09-B03C354C3618@uni-konstanz.de>
References: <DM6PR04MB44744910DDB2FC1BBFED01AAF1299@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DFCC71E1-9FB4-4C24-8A09-B03C354C3618@uni-konstanz.de>
Message-ID: <F60262DA-4433-4EE0-8E14-B2020E396117@uiowa.edu>

I guess the people who like standardized effect sizes might also go for standardized equivalence thresholds. I'm not one of those people, though I can understand that there are narrow contexts that dictate working in terms of norms.

Russ Lenth

Russ Lenth

Sent from my iPad

> On Feb 5, 2022, at 5:01 AM, Jakob Aschauer <jakob.aschauer at uni-konstanz.de> wrote:
> 
> ?Hello Russ,
> 
> thanks a lot for the response, that clarifies my uncertainties about the equivalence tests. I was already hoping a bit what you said, but wasn?t quite sure.
> 
> So in your eyes, does it also make sense to define delta as depending on sigma, following the Cohen?s d calculation used by eff_size()? I wonder wether it applies to GLMs as well. Maybe i?ll just play around with the other formula i mentioned and see what that changes (d = b ? ?3/?). Only problem is that i think it assumes equal group sizes.
> 
> Cheers
> Jakob 
> 
> 
> 
>> Am 04.02.2022 um 21:51 schrieb Lenth, Russell V <russell-lenth at uiowa.edu>:
>> 
>> 
>> I will answer the part about equivalence tests.
>> 
>> If you do not specify a side, you *do* obtain a two-sided test of equivalence. As documented in the help page for 'summary.emmGrid' (in the section on noninferiority, nonsuperiority, and equivalence, the test statistic is 
>> 
>>   t = (|estimate - null| - delta) / SE
>> 
>> and that the P value is the left-tailed probability. This is equivalent to the TOST method because the absolute value in there makes it test the less significant of the two tests. You can confirm this by looking at the separate cases where estimate < null and estimate > null.
>> 
>> Russ Lenth
>> 
>> -----Original Message-----
>> 
>> Hello everyone,
>> 
>> Here?s another set of emmeans-related problems or uncertainties. I?m using a beta-bionomial model to analyze a set of correctly vs. incorrectly given answers in a psychological experiment. Although the first is more a statistical question, i?ll give it a try here. Guess there should be some experts for all of this among you.
>> 
>> To compare experimental conditions, i defined some custom emmeans contrasts (using contrast(method = list(c(?))). For beta-binomial GLMs, emmeans calculates comparisons on the logit scale, thus provides logs of odds ratios. Additionally i?m using the eff_size() function to determine standardized mean differences (with sigma = stats::sigma(model), edf = df.residual(model)). This should give me Cohen?s d as calculated via d = b/?.  However, i?m a little confused since on the internet i?ve also seen the formula d = b ? ?3/? to convert logits to Cohen?s d. So how comes this contradiction? And in general i wonder which makes more sense in this case, reporting OR, or d, or both of them?
>> For the analysis i also need equivalence tests, and i?m using two one-sided tests for that via emmeans::contrast(delta = 0.3 * stats::sigma(model)), in order to classify all differences with less than a small effectsize (d = 0.3) as equal (using the Cohen?s d to logits conversion formula used by emmeans itself). I found that suggestion somewhere, but in case you?re having different suggestions, please let me know. However, i can?t implement the ?equivalence? side argument since the output always states that p values are left-tailed, not two-sided. I?ve been playing around with placing the side argument within contrast() or summary(), also with method ?pairwise? instead of my custom contrasts, but it won?t work. In the emmeans vignette on p. 70 it says ?The misc slot in object may contain default values for by, calc, infer, level, adjust, type, null, side, and delta?, which might be the reason. But i don?t arrive to change anything about that using the update method as suggested. Does anyone know a solution? 
>> Thanks a lot for helping out!
>> 
>> Cheers
>> Jakob
>> 
> 

From m|tr@@ghotb| @end|ng |rom gm@||@com  Fri Feb  4 15:16:47 2022
From: m|tr@@ghotb| @end|ng |rom gm@||@com (Mitra Ghotbi)
Date: Fri, 4 Feb 2022 15:16:47 +0100
Subject: [R-sig-ME] Ecological model
Message-ID: <CALRBZG5Qn1cMscVoZdY9v2jjh4EySWeTbfiQOL9pTZwckzBs3w@mail.gmail.com>

Dear Dr. Benjamin Bolker,
This is Mitra. I am following your wonderful GitHub page and your papers.
I attended and fully enjoyed your great presentation on the Ecological
Forecasting webinar series, on Nov 1st, 2021. Actually, I am the one who
asked tons of questions (my apologies for that).

To cut the story short, I am writing to request your direction for choosing
the correct model for my data set (I appreciate you have a busy schedule
and I apologize for adding extra work to it). I am working on soil biotic
abiotic data set, which all transformed. The data I am dealing with was
collected from hilly experimental farmland (ith strip-split plot layout).

I have considered slope position*Tillage*Rotation*Fertilizer levels as the
fixed factors while the random effects are replications and replication:
rotation  (1 | rep) + (1 | rep: rotation) (explanation for choosing the
fixed and random effects -> Slope position was considered as a fixed factor
since each transect was representative of different soils in our hilly
field. The amount of residue returned to each plot was dependent upon the
biomass that accrued from the previous cropping season, which could provoke
the inter-individual differences in our rotation subplots. Besides we were
interested in both between-group effects of rotation and pure rotation
impact).

I tested collinearity, homogeneity of residuals and etc everything looks
fine, then I have also tested various models with different nested random
factors to find the best fit for my data (AIC, effect size), (the linear
mixed effect models were fitted by RMEL)

Sorry for the long description I thought it's necessary to begin with an
introduction, *my question is which of these models, considering the AIC
and my explanation can be the adequate model for my data set?*

*I highly appreciate your answer and your time*
Best regards
Mitra

Models:



lmeModel1: pH ~ slope * Till * Rotation * Fert + (1 | rep) + (1 |
rep:Rotation)

lmeModel2: pH ~ slope * Till * Rotation * Fert + (1 | rep) + (1 |
rep:Rotation:Fertilizer)



lmeModel3: MW.N ~ slope * Till * Rotation * Fert + (1 | rep) + (1 |
rep:Till:Rotation:Fertilizer)

npar

AIC

BIC

logLik

deviance

Chisq

Df

Pr(>Chisq)



lmeModel1

27

272.4301

341.0991

-109.215

218.4301



lmeModel1

27

288.7502

357.4210

-117.383

234.7501

0

0





lmeModel3

27

290.3459

359.0148

-118.173

236.3459

0

0

	[[alternative HTML version deleted]]


From cm|o500 @end|ng |rom york@@c@uk  Wed Feb  9 20:31:56 2022
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Wed, 9 Feb 2022 19:31:56 +0000
Subject: [R-sig-ME] random effects - multiple sessions
Message-ID: <CACw+TfcRzUzuQRsj1wzN0qgbe1u6biEOP3w=M95xmNDQDuSMug@mail.gmail.com>

Hello,

I am interested in modeling a learning effect per session and per
participant and then extracting the random effects per participant so I can
use them for correlations. How can I do that?

If I have one contrast between 2 sessions (1 vs 2) I would do:

model_all = lmer(rt ~ group * prob * session + (1+prob*session|subj),
data=session, REML=FALSE)

df_all = data.frame(coef(model_all$subj))

df$session_1 = df$prob

df$session_2 = df$prob + df$session + df[, "prob:session"] # add up the
main-effects and the interaction to get the other session
But how can I extend this if I have 3 sessions and I want to contrast them
sequentially - 1 vs 2 and then 2 vs 3?

Thank you,

Catia

-- 
C?tia Margarida Ferreira de Oliveira
Psychology PhD Student
Department of Psychology, Room A105
University of York, YO10 5DD
Twitter: @CatiaMOliveira
pronouns: she, her

	[[alternative HTML version deleted]]


From ji@verissimo m@iii@g oii gm@ii@com  Wed Feb  9 21:28:43 2022
From: ji@verissimo m@iii@g oii gm@ii@com (ji@verissimo m@iii@g oii gm@ii@com)
Date: Wed, 09 Feb 2022 20:28:43 +0000
Subject: [R-sig-ME] random effects - multiple sessions
In-Reply-To: <CACw+TfcRzUzuQRsj1wzN0qgbe1u6biEOP3w=M95xmNDQDuSMug@mail.gmail.com>
References: <CACw+TfcRzUzuQRsj1wzN0qgbe1u6biEOP3w=M95xmNDQDuSMug@mail.gmail.com>
Message-ID: <177ff9591d8b15c9f9b76188beba22cc712f4596.camel@gmail.com>

Hi C?tia,
This depends on the contrasts of session AND prob.With treatment
contrasts for session and session 2 as the reference level (for
example), you'd get the 1vs.2 and 2vs.3 comparisons, and  you could
simply do the same kinds of sums that you already did to get all three
effects.
Alternatively,rt ~ 1 + session + prob:session + (1 + session +
prob:session | subj)would give you the prob effect in each of the three
sessions, as well as by-participant random adjustments on those.
Perhaps this is a more direct way of getting what you're after.
To bring group in.... not sure. Maybe:
1 + group * (session + prob:session)
Jo?o
On Wed, 2022-02-09 at 19:31 +0000, C?tia Ferreira De Oliveira via R-
sig-mixed-models wrote:
> Hello,
> I am interested in modeling a learning effect per session and
> perparticipant and then extracting the random effects per participant
> so I canuse them for correlations. How can I do that?
> If I have one contrast between 2 sessions (1 vs 2) I would do:
> model_all = lmer(rt ~ group * prob * session +
> (1+prob*session|subj),data=session, REML=FALSE)
> df_all = data.frame(coef(model_all$subj))
> df$session_1 = df$prob
> df$session_2 = df$prob + df$session + df[, "prob:session"] # add up
> themain-effects and the interaction to get the other sessionBut how
> can I extend this if I have 3 sessions and I want to contrast
> themsequentially - 1 vs 2 and then 2 vs 3?
> Thank you,
> Catia

	[[alternative HTML version deleted]]


From cm|o500 @end|ng |rom york@@c@uk  Thu Feb 10 19:36:18 2022
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Thu, 10 Feb 2022 18:36:18 +0000
Subject: [R-sig-ME] random effects - multiple sessions
In-Reply-To: <177ff9591d8b15c9f9b76188beba22cc712f4596.camel@gmail.com>
References: <CACw+TfcRzUzuQRsj1wzN0qgbe1u6biEOP3w=M95xmNDQDuSMug@mail.gmail.com>
 <177ff9591d8b15c9f9b76188beba22cc712f4596.camel@gmail.com>
Message-ID: <CACw+TffJgEh2uV_OeLdt9RVRbUikoU1UoJjvh_8YKH3DDYGSqg@mail.gmail.com>

Dear Dr. Jo?o Ver?ssimo,

Why did you remove the random slope for prob in your example? When that's
the learning effect I'm interest in?
rt ~ 1 + session + prob:session + (1 + session + prob:session | subj)

Best wishes,

C?tia

A quarta, 9/02/2022, 20:28, <jl.verissimo at gmail.com> escreveu:

> Hi C?tia,
>
> This depends on the contrasts of session AND prob.
> With treatment contrasts for session and session 2 as the reference level
> (for example), you'd get the 1vs.2 and 2vs.3 comparisons, and  you could
> simply do the same kinds of sums that you already did to get all three
> effects.
>
> Alternatively,
> rt ~ 1 + session + prob:session + (1 + session + prob:session | subj)
> would give you the prob effect in each of the three sessions, as well as
> by-participant random adjustments on those. Perhaps this is a more direct
> way of getting what you're after.
>
> To bring group in.... not sure. Maybe:
> 1 + group * (session + prob:session)
>
> Jo?o
>
> On Wed, 2022-02-09 at 19:31 +0000, C?tia Ferreira De Oliveira via
> R-sig-mixed-models wrote:
>
> Hello,
>
>
> I am interested in modeling a learning effect per session and per
>
> participant and then extracting the random effects per participant so I can
>
> use them for correlations. How can I do that?
>
>
> If I have one contrast between 2 sessions (1 vs 2) I would do:
>
>
> model_all = lmer(rt ~ group * prob * session + (1+prob*session|subj),
>
> data=session, REML=FALSE)
>
>
> df_all = data.frame(coef(model_all$subj))
>
>
> df$session_1 = df$prob
>
>
> df$session_2 = df$prob + df$session + df[, "prob:session"] # add up the
>
> main-effects and the interaction to get the other session
>
> But how can I extend this if I have 3 sessions and I want to contrast them
>
> sequentially - 1 vs 2 and then 2 vs 3?
>
>
> Thank you,
>
>
> Catia
>
>
>

	[[alternative HTML version deleted]]


From ji@verissimo m@iii@g oii gm@ii@com  Thu Feb 10 20:22:46 2022
From: ji@verissimo m@iii@g oii gm@ii@com (ji@verissimo m@iii@g oii gm@ii@com)
Date: Thu, 10 Feb 2022 19:22:46 +0000
Subject: [R-sig-ME] random effects - multiple sessions
In-Reply-To: <CACw+TffJgEh2uV_OeLdt9RVRbUikoU1UoJjvh_8YKH3DDYGSqg@mail.gmail.com>
References: <CACw+TfcRzUzuQRsj1wzN0qgbe1u6biEOP3w=M95xmNDQDuSMug@mail.gmail.com>
 <177ff9591d8b15c9f9b76188beba22cc712f4596.camel@gmail.com>
 <CACw+TffJgEh2uV_OeLdt9RVRbUikoU1UoJjvh_8YKH3DDYGSqg@mail.gmail.com>
Message-ID: <a4e940172b982da94aa762b18f4fe3516d2437c6.camel@gmail.com>


On Thu, 2022-02-10 at 18:36 +0000, C?tia Ferreira De Oliveira wrote:
> Dear Dr. Jo?o Ver?ssimo,
> Why did you remove the random slope for prob in your example? When
> that's the learning effect I'm interest in?rt ~ 1 + session +
> prob:session + (1 + session + prob:session | subj)

If session and prob are both factors, this formula should give you
estimates for the effect of prob in session 1, effect of prob in
session 2, and effect of prob in session 3 (if I'm seeing this
right).So the random slopes for prob are still there - in fact, the
model contains random slopes for prob in each of the sessions.

> Best wishes,
> 
> C?tia
> 
> A quarta, 9/02/2022, 20:28,  <jl.verissimo at gmail.com> escreveu:
> > Hi C?tia,
> > This depends on the contrasts of session AND prob.With treatment
> > contrasts for session and session 2 as the reference level (for
> > example), you'd get the 1vs.2 and 2vs.3 comparisons, and  you could
> > simply do the same kinds of sums that you already did to get all
> > three effects.
> > Alternatively,rt ~ 1 + session + prob:session + (1 + session +
> > prob:session | subj)would give you the prob effect in each of the
> > three sessions, as well as by-participant random adjustments on
> > those. Perhaps this is a more direct way of getting what you're
> > after.
> > To bring group in.... not sure. Maybe:
> > 1 + group * (session + prob:session)
> > Jo?o
> > On Wed, 2022-02-09 at 19:31 +0000, C?tia Ferreira De Oliveira via
> > R-sig-mixed-models wrote:
> > > Hello,
> > > I am interested in modeling a learning effect per session and
> > > perparticipant and then extracting the random effects per
> > > participant so I canuse them for correlations. How can I do that?
> > > If I have one contrast between 2 sessions (1 vs 2) I would do:
> > > model_all = lmer(rt ~ group * prob * session +
> > > (1+prob*session|subj),data=session, REML=FALSE)
> > > df_all = data.frame(coef(model_all$subj))
> > > df$session_1 = df$prob
> > > df$session_2 = df$prob + df$session + df[, "prob:session"] # add
> > > up themain-effects and the interaction to get the other
> > > sessionBut how can I extend this if I have 3 sessions and I want
> > > to contrast themsequentially - 1 vs 2 and then 2 vs 3?
> > > Thank you,
> > > Catia

	[[alternative HTML version deleted]]


From @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk  Tue Feb 15 16:04:50 2022
From: @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk (Alex Waldman)
Date: Tue, 15 Feb 2022 15:04:50 +0000
Subject: [R-sig-ME] Truncated Negative Binomial Model Unexpected Marginal
 Means
Message-ID: <D0D0DE0C-7511-424E-887B-C2EE4D1DAF72@OX.AC.UK>

Dear All,

Hope all is well! This may be a na?ve question but I am running a hurdle negative binomial model to look at the differences in counts of differing types in different locations. My major interest is the conditional model (ie when counts are above 0).

I run the following code:

model<-glmmTMB(Count ~ Location*Type + (1 | ID), zi=~Location*Type + (1|ID), data=data, family="truncated_nbinom1",control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

var.corr <-VarCorr(model)

Conditional model:
Groups Name        Std.Dev.
ID     (Intercept) 0.37105

Zero-inflation model:
Groups Name        Std.Dev.
ID     (Intercept) 1.3207

emmeans <- emmeans(model, ~ Location*Type, type="response", sigma=0.37105, bias.adjust=TRUE)

Location Type response    SE  df lower.CL upper.CL
0     0             1.117 0.277 631    0.687     1.82
1     0             0.940 0.251 631    0.556     1.59
2     0             0.893 0.266 631    0.498     1.60
0     1             1.325 0.254 631    0.909     1.93
1     1             1.090 0.248 631    0.698     1.70
2     1             1.452 0.300 631    0.967     2.18

Confidence level used: 0.95
Intervals are back-transformed from the log scale
Bias adjustment applied based on sigma = 0.37105

However, I?m not sure why the estimated means and confidence intervals will include values below 1 in the conditional model as I anticipated these values would represent the average number of non-zero counts? Is there something I may be doing wrong or not understanding?

Thanks in advance for your help!

Warm Regards,
Alex

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Feb 15 17:06:58 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 15 Feb 2022 11:06:58 -0500
Subject: [R-sig-ME] 
 Truncated Negative Binomial Model Unexpected Marginal Means
In-Reply-To: <D0D0DE0C-7511-424E-887B-C2EE4D1DAF72@OX.AC.UK>
References: <D0D0DE0C-7511-424E-887B-C2EE4D1DAF72@OX.AC.UK>
Message-ID: <4e31e1e9-b56b-2ebd-f83f-924c73981f72@gmail.com>

A quick test suggests that emmeans is predicting the response based on 
the mean of the *un*truncated distribution (I don't remember and/or 
haven't looked into all of the guts of emmeans).  Don't know if Russ 
Lenth (emmeans maintainer) is reading ...

n <- 1000
dd <- data.frame(f = factor(rep(1:2, each = n)))
gb <- log(c(2,4))
set.seed(101)
dd <- transform(dd, y = rnbinom(2*n, mu = exp(gb[f]), size = 2))
dd2 <- subset(dd, y > 0)

## un-truncated means
aggregate(y ~ f, data = dd, FUN = mean)
##   f        y
## 1 1 2.047
## 2 2 3.917

## truncated means
aggregate(y ~ f, data = dd2, FUN = mean)
##   f        y
## 1 1 2.781250
## 2 2 4.446084

library(glmmTMB)
library(emmeans)
m1 <- glmmTMB(y ~ f, family = truncated_nbinom2, data = dd2)

## doesn't match exactly but close to untruncated means
emmeans(m1, ~ f, type = "response")
##  f response     SE   df lower.CL upper.CL
##  1     2.15 0.0891 1614     1.99     2.34
##  2     3.98 0.1262 1614     3.74     4.23

## matches means exactly
m2 <- glmmTMB(y ~ f, family = nbinom2, data = dd)
emmeans(m2, ~ f, type = "response")
##  f response     SE   df lower.CL upper.CL
##  1     2.05 0.0651 1997     1.92     2.18
##  2     3.92 0.1094 1997     3.71     4.14


On 2/15/22 10:04 AM, Alex Waldman wrote:
> Dear All,
> 
> Hope all is well! This may be a na?ve question but I am running a hurdle negative binomial model to look at the differences in counts of differing types in different locations. My major interest is the conditional model (ie when counts are above 0).
> 
> I run the following code:
> 
> model<-glmmTMB(Count ~ Location*Type + (1 | ID), zi=~Location*Type + (1|ID), data=data, family="truncated_nbinom1",control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
> 
> var.corr <-VarCorr(model)
> 
> Conditional model:
> Groups Name        Std.Dev.
> ID     (Intercept) 0.37105
> 
> Zero-inflation model:
> Groups Name        Std.Dev.
> ID     (Intercept) 1.3207
> 
> emmeans <- emmeans(model, ~ Location*Type, type="response", sigma=0.37105, bias.adjust=TRUE)
> 
> Location Type response    SE  df lower.CL upper.CL
> 0     0             1.117 0.277 631    0.687     1.82
> 1     0             0.940 0.251 631    0.556     1.59
> 2     0             0.893 0.266 631    0.498     1.60
> 0     1             1.325 0.254 631    0.909     1.93
> 1     1             1.090 0.248 631    0.698     1.70
> 2     1             1.452 0.300 631    0.967     2.18
> 
> Confidence level used: 0.95
> Intervals are back-transformed from the log scale
> Bias adjustment applied based on sigma = 0.37105
> 
> However, I?m not sure why the estimated means and confidence intervals will include values below 1 in the conditional model as I anticipated these values would represent the average number of non-zero counts? Is there something I may be doing wrong or not understanding?
> 
> Thanks in advance for your help!
> 
> Warm Regards,
> Alex
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From hedyeh@h @end|ng |rom u@c@edu  Tue Feb 15 19:51:28 2022
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Tue, 15 Feb 2022 18:51:28 +0000
Subject: [R-sig-ME] Glmer Stack Imbalance Warning
Message-ID: <BYAPR07MB5094087C1365F926BEE2F274D1349@BYAPR07MB5094.namprd07.prod.outlook.com>

Hello all,
I'm running a glmer model and I'm getting a "stack imbalance" warning. When I searched for explanations, it looks like it's a programing bug.

Here is a link with some information (that might be relevant) that I don't fully understand:
https://stackoverflow.com/questions/6779530/what-is-a-stack-imbalance

I was wondering if you can help me understanding this warning in general. Any help would be appreciated and thank you in advance.

Best,

Hedyeh



	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Feb 15 20:02:05 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 15 Feb 2022 14:02:05 -0500
Subject: [R-sig-ME] Glmer Stack Imbalance Warning
In-Reply-To: <BYAPR07MB5094087C1365F926BEE2F274D1349@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB5094087C1365F926BEE2F274D1349@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <882f0f3d-f3a1-79b4-64f4-38679593e9ba@gmail.com>

   This is surprising; I don't recall ever seeing this error in 
conjunction with lme4, although there is a brief discussion of it (but 
without a reproducible example) in this mailing list thread from 12 
years ago.

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002851.html
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002857.html

  If it's reproducible, this would definitely constitute a bug in lme4. 
  At the very least, we would need the output of sessionInfo().  As an 
attempt at a "turn it off and back on again"-style solution, I would 
suggest reinstalling Rcpp, RcppEigen, and lme4 (in that order), 
preferably from source ...

   cheers
    Ben Bolker

On 2/15/22 1:51 PM, Hedyeh Ahmadi wrote:
> Hello all,
> I'm running a glmer model and I'm getting a "stack imbalance" warning. When I searched for explanations, it looks like it's a programing bug.
> 
> Here is a link with some information (that might be relevant) that I don't fully understand:
> https://stackoverflow.com/questions/6779530/what-is-a-stack-imbalance
> 
> I was wondering if you can help me understanding this warning in general. Any help would be appreciated and thank you in advance.
> 
> Best,
> 
> Hedyeh
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk  Tue Feb 15 20:20:02 2022
From: @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk (Alex Waldman)
Date: Tue, 15 Feb 2022 19:20:02 +0000
Subject: [R-sig-ME] 
 Truncated Negative Binomial Model Unexpected Marginal Means
In-Reply-To: <4e31e1e9-b56b-2ebd-f83f-924c73981f72@gmail.com>
References: <D0D0DE0C-7511-424E-887B-C2EE4D1DAF72@OX.AC.UK>
 <4e31e1e9-b56b-2ebd-f83f-924c73981f72@gmail.com>
Message-ID: <423AFBCA-327D-4586-BDC1-ADFF336125CB@OX.AC.UK>

Thanks, Ben!

I've copied a response from Russ:

Support for emmeans for glmmTMB models is in the glmmTMB package. However, I believe those estimates are based on the linear predictor for the conditional model only. That is, these are estimates of the mean of the fitted negative binomial distribution before it is truncated. Perhaps Ben can confirm this.

I think estimated means for hurdle and zero-inflated models are very difficult to interpret without taking into account both parts of the model; and, unfortunately, it is a somewhat complicated matter to do so that is not currently implemented. Seems worthwhile to try, though. One would have to include all the factors that affect both models; then from the truncated part, estimate its mean M and its probability of zero PT0. And from the ZI part, estimate its probability of zero PZ0. Then the estimated mean of the response is M * (1 - PZ0) / (1 - PT0), unless I made some kind of stupid mistake. The tricky part is estimating the SE of this result.

In addition, here is some example data attached. I ran the following code:

data<-read.csv("Example.csv",header=T)
as.factor(data$ID)->data$ID
as.factor(data$Location)->data$Location
as.factor(data$Type)->data$Type
model<-glmmTMB(Count ~ LocationType + (1 | ID), zi=~LocationType + (1|ID), data=data, family="truncated_nbinom1",control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

var.corr <-VarCorr(model)

Conditional model:
Groups Name Std.Dev.
ID (Intercept) 0.37105

Zero-inflation model:
Groups Name Std.Dev.
ID (Intercept) 1.3207

emmeans <- emmeans(model, ~ Location*Type, type="response", sigma=0.37105, bias.adjust=TRUE)

Location Type response SE df lower.CL upper.CL
0 0 1.117 0.277 631 0.687 1.82
1 0 0.940 0.251 631 0.556 1.59
2 0 0.893 0.266 631 0.498 1.60
0 1 1.325 0.254 631 0.909 1.93
1 1 1.090 0.248 631 0.698 1.70
2 1 1.452 0.300 631 0.967 2.18

Confidence level used: 0.95
Intervals are back-transformed from the log scale
Bias adjustment applied based on sigma = 0.37105

Interestingly, I tabulated the mean for location0/type1 including 0s and without 0s. Including 0s=1.05 and without 0s=1.88. The emmeans output seems to be in the middle of those two.

Does anyone have any workaround suggestions on how to tabulate the means of the conditional model above a threshold (ie above 0)? This page seemed to be relevant: https://www.theanalysisfactor.com/getting-accurate-predicted-counts-when-there-are-no-zeros-in-the-data/ but I wasn't sure what R package would fit my needs.

Thanks for your help!

Warm Regards,
Alex 

?On 2/15/22, 4:08 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:

    A quick test suggests that emmeans is predicting the response based on 
    the mean of the *un*truncated distribution (I don't remember and/or 
    haven't looked into all of the guts of emmeans).  Don't know if Russ 
    Lenth (emmeans maintainer) is reading ...

    n <- 1000
    dd <- data.frame(f = factor(rep(1:2, each = n)))
    gb <- log(c(2,4))
    set.seed(101)
    dd <- transform(dd, y = rnbinom(2*n, mu = exp(gb[f]), size = 2))
    dd2 <- subset(dd, y > 0)

    ## un-truncated means
    aggregate(y ~ f, data = dd, FUN = mean)
    ##   f        y
    ## 1 1 2.047
    ## 2 2 3.917

    ## truncated means
    aggregate(y ~ f, data = dd2, FUN = mean)
    ##   f        y
    ## 1 1 2.781250
    ## 2 2 4.446084

    library(glmmTMB)
    library(emmeans)
    m1 <- glmmTMB(y ~ f, family = truncated_nbinom2, data = dd2)

    ## doesn't match exactly but close to untruncated means
    emmeans(m1, ~ f, type = "response")
    ##  f response     SE   df lower.CL upper.CL
    ##  1     2.15 0.0891 1614     1.99     2.34
    ##  2     3.98 0.1262 1614     3.74     4.23

    ## matches means exactly
    m2 <- glmmTMB(y ~ f, family = nbinom2, data = dd)
    emmeans(m2, ~ f, type = "response")
    ##  f response     SE   df lower.CL upper.CL
    ##  1     2.05 0.0651 1997     1.92     2.18
    ##  2     3.92 0.1094 1997     3.71     4.14


    On 2/15/22 10:04 AM, Alex Waldman wrote:
    > Dear All,
    > 
    > Hope all is well! This may be a na?ve question but I am running a hurdle negative binomial model to look at the differences in counts of differing types in different locations. My major interest is the conditional model (ie when counts are above 0).
    > 
    > I run the following code:
    > 
    > model<-glmmTMB(Count ~ Location*Type + (1 | ID), zi=~Location*Type + (1|ID), data=data, family="truncated_nbinom1",control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
    > 
    > var.corr <-VarCorr(model)
    > 
    > Conditional model:
    > Groups Name        Std.Dev.
    > ID     (Intercept) 0.37105
    > 
    > Zero-inflation model:
    > Groups Name        Std.Dev.
    > ID     (Intercept) 1.3207
    > 
    > emmeans <- emmeans(model, ~ Location*Type, type="response", sigma=0.37105, bias.adjust=TRUE)
    > 
    > Location Type response    SE  df lower.CL upper.CL
    > 0     0             1.117 0.277 631    0.687     1.82
    > 1     0             0.940 0.251 631    0.556     1.59
    > 2     0             0.893 0.266 631    0.498     1.60
    > 0     1             1.325 0.254 631    0.909     1.93
    > 1     1             1.090 0.248 631    0.698     1.70
    > 2     1             1.452 0.300 631    0.967     2.18
    > 
    > Confidence level used: 0.95
    > Intervals are back-transformed from the log scale
    > Bias adjustment applied based on sigma = 0.37105
    > 
    > However, I?m not sure why the estimated means and confidence intervals will include values below 1 in the conditional model as I anticipated these values would represent the average number of non-zero counts? Is there something I may be doing wrong or not understanding?
    > 
    > Thanks in advance for your help!
    > 
    > Warm Regards,
    > Alex
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

    -- 
    Dr. Benjamin Bolker
    Professor, Mathematics & Statistics and Biology, McMaster University
    Director, School of Computational Science and Engineering
    (Acting) Graduate chair, Mathematics & Statistics

    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From kev|n@thorpe @end|ng |rom utoronto@c@  Tue Feb 15 20:21:06 2022
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Tue, 15 Feb 2022 19:21:06 +0000
Subject: [R-sig-ME] Glmer Stack Imbalance Warning
In-Reply-To: <882f0f3d-f3a1-79b4-64f4-38679593e9ba@gmail.com>
References: <BYAPR07MB5094087C1365F926BEE2F274D1349@BYAPR07MB5094.namprd07.prod.outlook.com>
 <882f0f3d-f3a1-79b4-64f4-38679593e9ba@gmail.com>
Message-ID: <FF767BF3-8E3D-4A42-9CB6-9D422A01E63D@utoronto.ca>

A colleague recently experienced this error (don?t remember if it was a mixed model or not) but re-startinf R fixed it.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael?s Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

> On Feb 15, 2022, at 2:02 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>  This is surprising; I don't recall ever seeing this error in conjunction with lme4, although there is a brief discussion of it (but without a reproducible example) in this mailing list thread from 12 years ago.
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002851.html
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002857.html
> 
> If it's reproducible, this would definitely constitute a bug in lme4.  At the very least, we would need the output of sessionInfo().  As an attempt at a "turn it off and back on again"-style solution, I would suggest reinstalling Rcpp, RcppEigen, and lme4 (in that order), preferably from source ...
> 
>  cheers
>   Ben Bolker
> 
> On 2/15/22 1:51 PM, Hedyeh Ahmadi wrote:
>> Hello all,
>> I'm running a glmer model and I'm getting a "stack imbalance" warning. When I searched for explanations, it looks like it's a programing bug.
>> Here is a link with some information (that might be relevant) that I don't fully understand:
>> https://stackoverflow.com/questions/6779530/what-is-a-stack-imbalance
>> I was wondering if you can help me understanding this warning in general. Any help would be appreciated and thank you in advance.
>> Best,
>> Hedyeh
>> 	[[alternative HTML version deleted]]
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -- 
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From hedyeh@h @end|ng |rom u@c@edu  Tue Feb 15 21:39:27 2022
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Tue, 15 Feb 2022 20:39:27 +0000
Subject: [R-sig-ME] Using nAGQ = 0 in glmer or lmer
Message-ID: <BYAPR07MB5094F08B4A8F1914F7A3F0AFD1349@BYAPR07MB5094.namprd07.prod.outlook.com>

Hello All,
I have used the option nAGQ=0 in many of lme models and I have read about it, my understanding is that the difference between the default, which nAGQ=1 vs nAGQ=0 is the estimation process in the background.

My question is that, in general if we use nAGQ=0, is our estimation still trustworthy?

Does it make it more accurate/trustworthy if our sample size is large?

Are there scenarios that we should absolutely not use nAGQ=0?

Thank you in advcance.

Best,

Hedyeh Ahmadi



	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Thu Feb 17 19:32:19 2022
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 17 Feb 2022 12:32:19 -0600
Subject: [R-sig-ME] measuring carry-over effects in mixed models
Message-ID: <CACgv6yWxs1GSAwq8K0tv4=WZ+ObEu66XMBSMeECOt+6r=oMCrQ@mail.gmail.com>

Hello All,

I'm analyzing the data from my longitudinal study whose design can be
depicted as (view the following in plain text):

O1  X1  O2  X2  O3  X3  O4
O1      O2      O3      O4

where Xs denote subtitled videos given to the treatment group and Os
denote measurement occasions.

My current model is:  lmer(y ~ time*group + [covariates] + (1 | student))

However, I'm also interested in measuring the "carry-over effects" of
watching subtitled videos at each occasion to the subsequent
occasions.

For instance, I want to know how much watching the subtitled video at
the first occasion (O1) impacts the treated students' performance at
later occasions (O2 and O3) etc.

I wonder if any changes to my model can enable me to measure these
carry-over effects or if any other R package may provide such
functionality?

Many thanks,
Simon


From j@kob@@@ch@uer @end|ng |rom un|-kon@t@nz@de  Thu Feb 17 09:39:20 2022
From: j@kob@@@ch@uer @end|ng |rom un|-kon@t@nz@de (Jakob Aschauer)
Date: Thu, 17 Feb 2022 09:39:20 +0100
Subject: [R-sig-ME] 
 [External]  Emmeans Effectsizes and Equivalence Tests
In-Reply-To: <F60262DA-4433-4EE0-8E14-B2020E396117@uiowa.edu>
References: <DM6PR04MB44744910DDB2FC1BBFED01AAF1299@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DFCC71E1-9FB4-4C24-8A09-B03C354C3618@uni-konstanz.de>
 <F60262DA-4433-4EE0-8E14-B2020E396117@uiowa.edu>
Message-ID: <D5F36917-918D-4D34-8181-BB843AF58119@uni-konstanz.de>

Hello Russ,

it?s been a while now, but i finally got back to those tests and realized some remaining issues.

When specifying delta = 0.2 * pi / sqrt(3), as suggested (which equals 0.36 on the logit scale, thus an odds ratio of 1.44), i obtain the following results:



As you can see, the estimate is lower than the threshold, but still the p values are not significant. Is that possible?

I?m using a beta-binomial model:



Since i have a long list of comparisons I calculate the contrast via the following function:




Many thanks for having a look!

Cheers
Jakob Aschauer



> Am 05.02.2022 um 15:51 schrieb Lenth, Russell V <russell-lenth at uiowa.edu>:
> 
> I guess the people who like standardized effect sizes might also go for standardized equivalence thresholds. I'm not one of those people, though I can understand that there are narrow contexts that dictate working in terms of norms.
> 
> Russ Lenth
> 
> Russ Lenth
> 
> Sent from my iPad
> 
>> On Feb 5, 2022, at 5:01 AM, Jakob Aschauer <jakob.aschauer at uni-konstanz.de> wrote:
>> 
>> ?Hello Russ,
>> 
>> thanks a lot for the response, that clarifies my uncertainties about the equivalence tests. I was already hoping a bit what you said, but wasn?t quite sure.
>> 
>> So in your eyes, does it also make sense to define delta as depending on sigma, following the Cohen?s d calculation used by eff_size()? I wonder wether it applies to GLMs as well. Maybe i?ll just play around with the other formula i mentioned and see what that changes (d = b ? ?3/?). Only problem is that i think it assumes equal group sizes.
>> 
>> Cheers
>> Jakob 
>> 
>> 
>> 
>>> Am 04.02.2022 um 21:51 schrieb Lenth, Russell V <russell-lenth at uiowa.edu>:
>>> 
>>> 
>>> I will answer the part about equivalence tests.
>>> 
>>> If you do not specify a side, you *do* obtain a two-sided test of equivalence. As documented in the help page for 'summary.emmGrid' (in the section on noninferiority, nonsuperiority, and equivalence, the test statistic is 
>>> 
>>>  t = (|estimate - null| - delta) / SE
>>> 
>>> and that the P value is the left-tailed probability. This is equivalent to the TOST method because the absolute value in there makes it test the less significant of the two tests. You can confirm this by looking at the separate cases where estimate < null and estimate > null.
>>> 
>>> Russ Lenth
>>> 
>>> -----Original Message-----
>>> 
>>> Hello everyone,
>>> 
>>> Here?s another set of emmeans-related problems or uncertainties. I?m using a beta-bionomial model to analyze a set of correctly vs. incorrectly given answers in a psychological experiment. Although the first is more a statistical question, i?ll give it a try here. Guess there should be some experts for all of this among you.
>>> 
>>> To compare experimental conditions, i defined some custom emmeans contrasts (using contrast(method = list(c(?))). For beta-binomial GLMs, emmeans calculates comparisons on the logit scale, thus provides logs of odds ratios. Additionally i?m using the eff_size() function to determine standardized mean differences (with sigma = stats::sigma(model), edf = df.residual(model)). This should give me Cohen?s d as calculated via d = b/?.  However, i?m a little confused since on the internet i?ve also seen the formula d = b ? ?3/? to convert logits to Cohen?s d. So how comes this contradiction? And in general i wonder which makes more sense in this case, reporting OR, or d, or both of them?
>>> For the analysis i also need equivalence tests, and i?m using two one-sided tests for that via emmeans::contrast(delta = 0.3 * stats::sigma(model)), in order to classify all differences with less than a small effectsize (d = 0.3) as equal (using the Cohen?s d to logits conversion formula used by emmeans itself). I found that suggestion somewhere, but in case you?re having different suggestions, please let me know. However, i can?t implement the ?equivalence? side argument since the output always states that p values are left-tailed, not two-sided. I?ve been playing around with placing the side argument within contrast() or summary(), also with method ?pairwise? instead of my custom contrasts, but it won?t work. In the emmeans vignette on p. 70 it says ?The misc slot in object may contain default values for by, calc, infer, level, adjust, type, null, side, and delta?, which might be the reason. But i don?t arrive to change anything about that using the update method as suggested. Does anyone know a solution? 
>>> Thanks a lot for helping out!
>>> 
>>> Cheers
>>> Jakob
>>> 
>> 


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Fri Feb 25 09:23:25 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Fri, 25 Feb 2022 10:23:25 +0200
Subject: [R-sig-ME] Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
Message-ID: <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>

Dear John (and anyone else qualified to comment),

I fit lots of mixed-effects multinomial models in my research, and I would
like to see some (multi)collinearity diagnostics on the fixed effects, of
which there are over 30. My models are fit using the Bayesian *brms*
package because I know of no frequentist packages with multinomial GLMM
compatibility.

With continuous or dichotomous outcomes, my go-to function for calculating
multicollinearity diagnostics is of course *vif()* from the *car* package.
As expected, however, this function does not report sensible diagnostics
for multinomial models -- not even for standard ones fit by the *nnet*
package's *multinom()* function. The reason, I presume, is because a
multinomial model is not really one but C-1 regression models  (where C is
the number of response categories) and the *vif()* function is not designed
to deal with this scenario.

Therefore, in order to obtain meaningful collinearity metrics, my present
plan is to write a simple helper function that uses *vif() *to calculate
and present (generalized) variance inflation metrics for the C-1
sub-datasets to which the C-1 component binomial models of the overall
multinomial model are fit. In other words, it will partition the data into
those C-1 subsets, and then apply *vif()* to as many linear regressions
using a made-up continuous response and the fixed effects of interest.

Does this seem like a sensible approach?

Best,

Juho




ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Simon,
>
> I believe that Russ's point is that the fact that the additive model
> allows you to estimate nonsensical quantities like a mean for girls in
> all-boys' schools implies a problem with the model. Why not do as I
> suggested and define two dichotomous factors: sex of student
> (male/female) and type of school (coed, same-sex)? The four combinations
> of levels then make sense.
>
> Best,
>   John
>
> On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> > Thanks, Russ! There is one thing that I still don't understand. We
> > have two completely empty cells (boys in girl-only & girls in boy-only
> > schools). Then, how are the means of those empty cells computed (what
> > data is used in their place in the additive model)?
> >
> > Let's' simplify the model for clarity:
> >
> > library(R2MLwiN)
> > library(emmeans)
> >
> > Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> > model3 <- lm(Form3, data = tutorial)
> >
> > emmeans(model3, pairwise~sex+schgend)$emmeans
> >
> >   sex  schgend   emmean     SE   df lower.CL upper.CL
> >   boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
> >   girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
> >   boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
> >   girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
> >   boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
> >   girl girlsch   0.1460 0.0267 4055   0.0938  0.19829
> >
> >
> >
> >
> >
> > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> > <russell-lenth at uiowa.edu> wrote:
> >>
> >> By the way, returning to the topic of interpreting coefficients, you
> ought to have fun with the ones from the model I just fitted:
> >>
> >> Fixed effects:
> >>                 Estimate Std. Error t value
> >> (Intercept)    -0.18882    0.05135  -3.677
> >> standlrt        0.55442    0.01994  27.807
> >> schgendboysch   0.17986    0.09915   1.814
> >> schgendgirlsch  0.17482    0.07877   2.219
> >> sexgirl         0.16826    0.03382   4.975
> >>
> >> One curious thing you'll notice is that there are no coefficients for
> the interaction terms. Why? Because those terms were "thrown out" of the
> model, and so they are not shown. I think it is unwise to not show what was
> thrown out (e.g., lm would have shown them as NAs), because in fact what we
> see is but one of infinitely many possible solutions to the regression
> equations. This is the solution where the last two coefficients are
> constrained to zero. There is another equally reasonable one where the
> coefficients for schgendboysch and schgendgirlsch  are constrained to zero,
> and the two interaction effects would then be non-zero. And infinitely more
> where all 7 coefficients are non-zero, and there are two linear constraints
> among them.
> >>
> >> Of course, since the particular estimate shown consists of all the main
> effects and interactions are constrained to zero, it does demonstrate that
> the additive model *could* have been used to obtain the same estimates and
> standard errors, and you can see that by comparing the results (and
> ignoring the invalid ones from the additive model). But it is just a lucky
> coincidence that it worked out this way, and the additive model did lead us
> down a primrose path containing silly results among the correct ones.
> >>
> >> Russ
> >>
> >> -----Original Message-----
> >> From: Lenth, Russell V
> >> Sent: Sunday, September 26, 2021 7:43 PM
> >> To: Simon Harmel <sim.harmel at gmail.com>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> I guess correctness is in the eyes of the beholder. But I think this
> illustrates the folly of the additive model. Having additive effects
> suggests a belief that you can vary one factor more or less independently
> of the other. In his comments, John Fox makes a good point that escaped my
> earlier cursory view of the original question, that you don't have data on
> girls attending all-boys' schools, nor boys attending all-girls' schools;
> yet the model that was fitted estimates a mean response for both those
> situations. That's a pretty clear testament to the failure of that model ?
> and also why the coefficients don't make sense. And finally why we have
> estimates of 15 comparisons (some of which are aliased with one another),
> when only 6 of them make sense.
> >>
> >> If instead, a model with interaction were fitted, it would be a
> rank-deficient model because two cells are empty. Perhaps there is some
> sort of nesting structure that could be used to work around that. However,
> it doesn't matter much because emmeans assesses estimability, and the two
> combinations I mentioned above would be flagged as non-estimable. One could
> then more judiciously use the contrast function to test meaningful
> contrasts across this irregular array of cell means. Or even injudiciously
> asking for all pairwise comparisons, you will see 6 estimable ones and 9
> non-estimable ones. See output below.
> >>
> >> Russ
> >>
> >> ----- Interactive model -----
> >>
> >>> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> >> fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> >>>
> >>> emmeans(model, pairwise~schgend+sex)
> >>
> >> ... messages deleted ...
> >>
> >> $emmeans
> >>   schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
> >>   mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
> >>   boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
> >>   girlsch  boy    nonEst     NA  NA        NA        NA
> >>   mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
> >>   boysch   girl   nonEst     NA  NA        NA        NA
> >>   girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> >>
> >> Degrees-of-freedom method: asymptotic
> >> Confidence level used: 0.95
> >>
> >> $contrasts
> >>   contrast                     estimate     SE  df z.ratio p.value
> >>   mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
> >>   mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
> >>   mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
> >>   mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
> >>   mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
> >>   boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
> >>   boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
> >>   boysch boy - boysch girl       nonEst     NA  NA      NA      NA
> >>   boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
> >>   girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
> >>   girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
> >>   girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
> >>   mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
> >>   mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
> >>   boysch girl - girlsch girl     nonEst     NA  NA      NA      NA
> >>
> >> Degrees-of-freedom method: asymptotic
> >> P value adjustment: tukey method for comparing a family of 6 estimates
> >>
> >>
> >> ---------------------------------------------------------
> >> From: Simon Harmel <sim.harmel at gmail.com>
> >> Sent: Sunday, September 26, 2021 3:08 PM
> >> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> Dear Russ and the List Members,
> >>
> >> If we use Russ' great package (emmeans), we see that although
> meaningless, but "schgendgirl-only" can be interpreted using the logic I
> mentioned here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
> >>
> >> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys
> in girl-only vs. mixed schools*** just like it can meaningfully mean:
> ***diff. bet. girls in girl-only vs. mixed schools***
> >>
> >> Russ, have I used emmeans correctly?
> >>
> >> Simon
> >>
> >> Here is a reproducible code:
> >>
> >> library(R2MLwiN) # For the dataset
> >> library(lme4)
> >> library(emmeans)
> >>
> >> data("tutorial")
> >>
> >> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> >> model <- lmer(Form, data = tutorial, REML = FALSE)
> >>
> >> emmeans(model, pairwise~schgend+sex)$contrast
> >>
> >> contrast                     estimate     SE  df z.ratio p.value
> >> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> >> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef. equals
> >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> >> mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
> >> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> >> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> >> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> >> boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
> >> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> >> girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
> >> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> >> girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
> >> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef.
> >> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From stevedrd m@iii@g oii y@hoo@com  Fri Feb 25 14:04:09 2022
From: stevedrd m@iii@g oii y@hoo@com (stevedrd m@iii@g oii y@hoo@com)
Date: Fri, 25 Feb 2022 13:04:09 +0000 (UTC)
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
 <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
Message-ID: <943078633.1040414.1645794249936@mail.yahoo.com>

 This seems odd to me, but then I don't usually analyze multinomial models.? Is there an issue with collinearity in the response variable in a multinomial model?? I would think that the levels are collinear by definition.? So then the issue, it seems to me, is whether there is collinearity in the fixed effects - and that should be independent of the response variables.? Could you use the vif() function with a standard response (say = 1) to check collinearity in the fixed effects?? I would think that your method on the sub datasets may not capture all of the collinearity in the full model.
But I could be waaaaaaay off base on this.
SteveDenham
    On Friday, February 25, 2022, 03:24:15 AM EST, Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com> wrote:  
 
 Dear John (and anyone else qualified to comment),

I fit lots of mixed-effects multinomial models in my research, and I would
like to see some (multi)collinearity diagnostics on the fixed effects, of
which there are over 30. My models are fit using the Bayesian *brms*
package because I know of no frequentist packages with multinomial GLMM
compatibility.

With continuous or dichotomous outcomes, my go-to function for calculating
multicollinearity diagnostics is of course *vif()* from the *car* package.
As expected, however, this function does not report sensible diagnostics
for multinomial models -- not even for standard ones fit by the *nnet*
package's *multinom()* function. The reason, I presume, is because a
multinomial model is not really one but C-1 regression models? (where C is
the number of response categories) and the *vif()* function is not designed
to deal with this scenario.

Therefore, in order to obtain meaningful collinearity metrics, my present
plan is to write a simple helper function that uses *vif() *to calculate
and present (generalized) variance inflation metrics for the C-1
sub-datasets to which the C-1 component binomial models of the overall
multinomial model are fit. In other words, it will partition the data into
those C-1 subsets, and then apply *vif()* to as many linear regressions
using a made-up continuous response and the fixed effects of interest.

Does this seem like a sensible approach?

Best,

Juho




ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Simon,
>
> I believe that Russ's point is that the fact that the additive model
> allows you to estimate nonsensical quantities like a mean for girls in
> all-boys' schools implies a problem with the model. Why not do as I
> suggested and define two dichotomous factors: sex of student
> (male/female) and type of school (coed, same-sex)? The four combinations
> of levels then make sense.
>
> Best,
>? John
>
> On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> > Thanks, Russ! There is one thing that I still don't understand. We
> > have two completely empty cells (boys in girl-only & girls in boy-only
> > schools). Then, how are the means of those empty cells computed (what
> > data is used in their place in the additive model)?
> >
> > Let's' simplify the model for clarity:
> >
> > library(R2MLwiN)
> > library(emmeans)
> >
> > Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> > model3 <- lm(Form3, data = tutorial)
> >
> > emmeans(model3, pairwise~sex+schgend)$emmeans
> >
> >? sex? schgend? emmean? ? SE? df lower.CL upper.CL
> >? boy? mixedsch -0.2160 0.0297 4055? -0.2742 -0.15780
> >? girl mixedsch? 0.0248 0.0304 4055? -0.0348? 0.08437
> >? boy? boysch? ? 0.0234 0.0437 4055? -0.0623? 0.10897
> >? girl boysch? ? 0.2641 0.0609 4055? 0.1447? 0.38360<-how computed?
> >? boy? girlsch? -0.0948 0.0502 4055? -0.1931? 0.00358<-how computed?
> >? girl girlsch? 0.1460 0.0267 4055? 0.0938? 0.19829
> >
> >
> >
> >
> >
> > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> > <russell-lenth at uiowa.edu> wrote:
> >>
> >> By the way, returning to the topic of interpreting coefficients, you
> ought to have fun with the ones from the model I just fitted:
> >>
> >> Fixed effects:
> >>? ? ? ? ? ? ? ? Estimate Std. Error t value
> >> (Intercept)? ? -0.18882? ? 0.05135? -3.677
> >> standlrt? ? ? ? 0.55442? ? 0.01994? 27.807
> >> schgendboysch? 0.17986? ? 0.09915? 1.814
> >> schgendgirlsch? 0.17482? ? 0.07877? 2.219
> >> sexgirl? ? ? ? 0.16826? ? 0.03382? 4.975
> >>
> >> One curious thing you'll notice is that there are no coefficients for
> the interaction terms. Why? Because those terms were "thrown out" of the
> model, and so they are not shown. I think it is unwise to not show what was
> thrown out (e.g., lm would have shown them as NAs), because in fact what we
> see is but one of infinitely many possible solutions to the regression
> equations. This is the solution where the last two coefficients are
> constrained to zero. There is another equally reasonable one where the
> coefficients for schgendboysch and schgendgirlsch? are constrained to zero,
> and the two interaction effects would then be non-zero. And infinitely more
> where all 7 coefficients are non-zero, and there are two linear constraints
> among them.
> >>
> >> Of course, since the particular estimate shown consists of all the main
> effects and interactions are constrained to zero, it does demonstrate that
> the additive model *could* have been used to obtain the same estimates and
> standard errors, and you can see that by comparing the results (and
> ignoring the invalid ones from the additive model). But it is just a lucky
> coincidence that it worked out this way, and the additive model did lead us
> down a primrose path containing silly results among the correct ones.
> >>
> >> Russ
> >>
> >> -----Original Message-----
> >> From: Lenth, Russell V
> >> Sent: Sunday, September 26, 2021 7:43 PM
> >> To: Simon Harmel <sim.harmel at gmail.com>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> I guess correctness is in the eyes of the beholder. But I think this
> illustrates the folly of the additive model. Having additive effects
> suggests a belief that you can vary one factor more or less independently
> of the other. In his comments, John Fox makes a good point that escaped my
> earlier cursory view of the original question, that you don't have data on
> girls attending all-boys' schools, nor boys attending all-girls' schools;
> yet the model that was fitted estimates a mean response for both those
> situations. That's a pretty clear testament to the failure of that model ?
> and also why the coefficients don't make sense. And finally why we have
> estimates of 15 comparisons (some of which are aliased with one another),
> when only 6 of them make sense.
> >>
> >> If instead, a model with interaction were fitted, it would be a
> rank-deficient model because two cells are empty. Perhaps there is some
> sort of nesting structure that could be used to work around that. However,
> it doesn't matter much because emmeans assesses estimability, and the two
> combinations I mentioned above would be flagged as non-estimable. One could
> then more judiciously use the contrast function to test meaningful
> contrasts across this irregular array of cell means. Or even injudiciously
> asking for all pairwise comparisons, you will see 6 estimable ones and 9
> non-estimable ones. See output below.
> >>
> >> Russ
> >>
> >> ----- Interactive model -----
> >>
> >>> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> >> fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> >>>
> >>> emmeans(model, pairwise~schgend+sex)
> >>
> >> ... messages deleted ...
> >>
> >> $emmeans
> >>? schgend? sex? ? emmean? ? SE? df asymp.LCL asymp.UCL
> >>? mixedsch boy? -0.18781 0.0514 Inf? -0.2885? -0.0871
> >>? boysch? boy? -0.00795 0.0880 Inf? -0.1805? ? 0.1646
> >>? girlsch? boy? ? nonEst? ? NA? NA? ? ? ? NA? ? ? ? NA
> >>? mixedsch girl -0.01955 0.0521 Inf? -0.1216? ? 0.0825
> >>? boysch? girl? nonEst? ? NA? NA? ? ? ? NA? ? ? ? NA
> >>? girlsch? girl? 0.15527 0.0632 Inf? ? 0.0313? ? 0.2792
> >>
> >> Degrees-of-freedom method: asymptotic
> >> Confidence level used: 0.95
> >>
> >> $contrasts
> >>? contrast? ? ? ? ? ? ? ? ? ? estimate? ? SE? df z.ratio p.value
> >>? mixedsch boy - boysch boy? ? -0.1799 0.0991 Inf? -1.814? 0.4565
> >>? mixedsch boy - girlsch boy? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>? mixedsch boy - mixedsch girl? -0.1683 0.0338 Inf? -4.975? <.0001
> >>? mixedsch boy - boysch girl? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>? mixedsch boy - girlsch girl? -0.3431 0.0780 Inf? -4.396? 0.0002
> >>? boysch boy - girlsch boy? ? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>? boysch boy - mixedsch girl? ? 0.0116 0.0997 Inf? 0.116? 1.0000
> >>? boysch boy - boysch girl? ? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>? boysch boy - girlsch girl? ? -0.1632 0.1058 Inf? -1.543? 0.6361
> >>? girlsch boy - mixedsch girl? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>? girlsch boy - boysch girl? ? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>? girlsch boy - girlsch girl? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>? mixedsch girl - boysch girl? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>? mixedsch girl - girlsch girl? -0.1748 0.0788 Inf? -2.219? 0.2287
> >>? boysch girl - girlsch girl? ? nonEst? ? NA? NA? ? ? NA? ? ? NA
> >>
> >> Degrees-of-freedom method: asymptotic
> >> P value adjustment: tukey method for comparing a family of 6 estimates
> >>
> >>
> >> ---------------------------------------------------------
> >> From: Simon Harmel <sim.harmel at gmail.com>
> >> Sent: Sunday, September 26, 2021 3:08 PM
> >> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> Dear Russ and the List Members,
> >>
> >> If we use Russ' great package (emmeans), we see that although
> meaningless, but "schgendgirl-only" can be interpreted using the logic I
> mentioned here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
> >>
> >> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys
> in girl-only vs. mixed schools*** just like it can meaningfully mean:
> ***diff. bet. girls in girl-only vs. mixed schools***
> >>
> >> Russ, have I used emmeans correctly?
> >>
> >> Simon
> >>
> >> Here is a reproducible code:
> >>
> >> library(R2MLwiN) # For the dataset
> >> library(lme4)
> >> library(emmeans)
> >>
> >> data("tutorial")
> >>
> >> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> >> model <- lmer(Form, data = tutorial, REML = FALSE)
> >>
> >> emmeans(model, pairwise~schgend+sex)$contrast
> >>
> >> contrast? ? ? ? ? ? ? ? ? ? estimate? ? SE? df z.ratio p.value
> >> mixedsch boy - boysch boy? ? -0.17986 0.0991 Inf -1.814? 0.4565
> >> mixedsch boy - girlsch boy? -0.17482 0.0788 Inf -2.219? 0.2287
>? <--This coef. equals
> >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975? <.0001
> >> mixedsch boy - boysch girl? -0.34813 0.1096 Inf -3.178? 0.0186
> >> mixedsch boy - girlsch girl? -0.34308 0.0780 Inf -4.396? 0.0002
> >> boysch boy - girlsch boy? ? ? 0.00505 0.1110 Inf? 0.045? 1.0000
> >> boysch boy - mixedsch girl? ? 0.01160 0.0997 Inf? 0.116? 1.0000
> >> boysch boy - boysch girl? ? -0.16826 0.0338 Inf -4.975? <.0001
> >> boysch boy - girlsch girl? ? -0.16322 0.1058 Inf -1.543? 0.6361
> >> girlsch boy - mixedsch girl? 0.00656 0.0928 Inf? 0.071? 1.0000
> >> girlsch boy - boysch girl? ? -0.17331 0.1255 Inf -1.381? 0.7388
> >> girlsch boy - girlsch girl? -0.16826 0.0338 Inf -4.975? <.0001
> >> mixedsch girl - boysch girl? -0.17986 0.0991 Inf -1.814? 0.4565
> >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219? 0.2287
>? <--This coef.
> >> boysch girl - girlsch girl? ? 0.00505 0.1110 Inf? 0.045? 1.0000
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
  
	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Feb 25 14:18:57 2022
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 25 Feb 2022 13:18:57 +0000
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <943078633.1040414.1645794249936@mail.yahoo.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
 <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
 <943078633.1040414.1645794249936@mail.yahoo.com>
Message-ID: <MN2PR03MB51676543244823BCDE56239EE23E9@MN2PR03MB5167.namprd03.prod.outlook.com>

I would agree with Steven. Collinearity is problem with the predictor variables, not the outcome variable. Given a multinomial model y = f(x1, x2, x3, . . . xn), one could run a simple linear regression x1 = f(x2,x3, . . .,xn) and look at vif to determine if x2 . . . xn are colinear and perhaps an additional regression x2=f(x1,x3, . . .xn) to determine if x1, x3, . . . xn are colinear. If I am missing something, I hope someone will correct me.
John (but not John Fox)

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows

From: stevedrd--- via R-sig-mixed-models<mailto:r-sig-mixed-models at r-project.org>
Sent: Friday, February 25, 2022 8:07 AM
To: John Fox<mailto:jfox at mcmaster.ca>; Juho Kristian Ruohonen<mailto:juho.kristian.ruohonen at gmail.com>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Collinearity diagnostics for (mixed) multinomial models

This seems odd to me, but then I don't usually analyze multinomial models.  Is there an issue with collinearity in the response variable in a multinomial model?  I would think that the levels are collinear by definition.  So then the issue, it seems to me, is whether there is collinearity in the fixed effects - and that should be independent of the response variables.  Could you use the vif() function with a standard response (say = 1) to check collinearity in the fixed effects?  I would think that your method on the sub datasets may not capture all of the collinearity in the full model.
But I could be waaaaaaay off base on this.
SteveDenham
    On Friday, February 25, 2022, 03:24:15 AM EST, Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com> wrote:

 Dear John (and anyone else qualified to comment),

I fit lots of mixed-effects multinomial models in my research, and I would
like to see some (multi)collinearity diagnostics on the fixed effects, of
which there are over 30. My models are fit using the Bayesian *brms*
package because I know of no frequentist packages with multinomial GLMM
compatibility.

With continuous or dichotomous outcomes, my go-to function for calculating
multicollinearity diagnostics is of course *vif()* from the *car* package.
As expected, however, this function does not report sensible diagnostics
for multinomial models -- not even for standard ones fit by the *nnet*
package's *multinom()* function. The reason, I presume, is because a
multinomial model is not really one but C-1 regression models  (where C is
the number of response categories) and the *vif()* function is not designed
to deal with this scenario.

Therefore, in order to obtain meaningful collinearity metrics, my present
plan is to write a simple helper function that uses *vif() *to calculate
and present (generalized) variance inflation metrics for the C-1
sub-datasets to which the C-1 component binomial models of the overall
multinomial model are fit. In other words, it will partition the data into
those C-1 subsets, and then apply *vif()* to as many linear regressions
using a made-up continuous response and the fixed effects of interest.

Does this seem like a sensible approach?

Best,

Juho




ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Simon,
>
> I believe that Russ's point is that the fact that the additive model
> allows you to estimate nonsensical quantities like a mean for girls in
> all-boys' schools implies a problem with the model. Why not do as I
> suggested and define two dichotomous factors: sex of student
> (male/female) and type of school (coed, same-sex)? The four combinations
> of levels then make sense.
>
> Best,
>  John
>
> On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> > Thanks, Russ! There is one thing that I still don't understand. We
> > have two completely empty cells (boys in girl-only & girls in boy-only
> > schools). Then, how are the means of those empty cells computed (what
> > data is used in their place in the additive model)?
> >
> > Let's' simplify the model for clarity:
> >
> > library(R2MLwiN)
> > library(emmeans)
> >
> > Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> > model3 <- lm(Form3, data = tutorial)
> >
> > emmeans(model3, pairwise~sex+schgend)$emmeans
> >
> >  sex  schgend  emmean    SE  df lower.CL upper.CL
> >  boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
> >  girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
> >  boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
> >  girl boysch    0.2641 0.0609 4055  0.1447  0.38360<-how computed?
> >  boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
> >  girl girlsch  0.1460 0.0267 4055  0.0938  0.19829
> >
> >
> >
> >
> >
> > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> > <russell-lenth at uiowa.edu> wrote:
> >>
> >> By the way, returning to the topic of interpreting coefficients, you
> ought to have fun with the ones from the model I just fitted:
> >>
> >> Fixed effects:
> >>                Estimate Std. Error t value
> >> (Intercept)    -0.18882    0.05135  -3.677
> >> standlrt        0.55442    0.01994  27.807
> >> schgendboysch  0.17986    0.09915  1.814
> >> schgendgirlsch  0.17482    0.07877  2.219
> >> sexgirl        0.16826    0.03382  4.975
> >>
> >> One curious thing you'll notice is that there are no coefficients for
> the interaction terms. Why? Because those terms were "thrown out" of the
> model, and so they are not shown. I think it is unwise to not show what was
> thrown out (e.g., lm would have shown them as NAs), because in fact what we
> see is but one of infinitely many possible solutions to the regression
> equations. This is the solution where the last two coefficients are
> constrained to zero. There is another equally reasonable one where the
> coefficients for schgendboysch and schgendgirlsch  are constrained to zero,
> and the two interaction effects would then be non-zero. And infinitely more
> where all 7 coefficients are non-zero, and there are two linear constraints
> among them.
> >>
> >> Of course, since the particular estimate shown consists of all the main
> effects and interactions are constrained to zero, it does demonstrate that
> the additive model *could* have been used to obtain the same estimates and
> standard errors, and you can see that by comparing the results (and
> ignoring the invalid ones from the additive model). But it is just a lucky
> coincidence that it worked out this way, and the additive model did lead us
> down a primrose path containing silly results among the correct ones.
> >>
> >> Russ
> >>
> >> -----Original Message-----
> >> From: Lenth, Russell V
> >> Sent: Sunday, September 26, 2021 7:43 PM
> >> To: Simon Harmel <sim.harmel at gmail.com>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> I guess correctness is in the eyes of the beholder. But I think this
> illustrates the folly of the additive model. Having additive effects
> suggests a belief that you can vary one factor more or less independently
> of the other. In his comments, John Fox makes a good point that escaped my
> earlier cursory view of the original question, that you don't have data on
> girls attending all-boys' schools, nor boys attending all-girls' schools;
> yet the model that was fitted estimates a mean response for both those
> situations. That's a pretty clear testament to the failure of that model ?
> and also why the coefficients don't make sense. And finally why we have
> estimates of 15 comparisons (some of which are aliased with one another),
> when only 6 of them make sense.
> >>
> >> If instead, a model with interaction were fitted, it would be a
> rank-deficient model because two cells are empty. Perhaps there is some
> sort of nesting structure that could be used to work around that. However,
> it doesn't matter much because emmeans assesses estimability, and the two
> combinations I mentioned above would be flagged as non-estimable. One could
> then more judiciously use the contrast function to test meaningful
> contrasts across this irregular array of cell means. Or even injudiciously
> asking for all pairwise comparisons, you will see 6 estimable ones and 9
> non-estimable ones. See output below.
> >>
> >> Russ
> >>
> >> ----- Interactive model -----
> >>
> >>> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> >> fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> >>>
> >>> emmeans(model, pairwise~schgend+sex)
> >>
> >> ... messages deleted ...
> >>
> >> $emmeans
> >>  schgend  sex    emmean    SE  df asymp.LCL asymp.UCL
> >>  mixedsch boy  -0.18781 0.0514 Inf  -0.2885  -0.0871
> >>  boysch  boy  -0.00795 0.0880 Inf  -0.1805    0.1646
> >>  girlsch  boy    nonEst    NA  NA        NA        NA
> >>  mixedsch girl -0.01955 0.0521 Inf  -0.1216    0.0825
> >>  boysch  girl  nonEst    NA  NA        NA        NA
> >>  girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> >>
> >> Degrees-of-freedom method: asymptotic
> >> Confidence level used: 0.95
> >>
> >> $contrasts
> >>  contrast                    estimate    SE  df z.ratio p.value
> >>  mixedsch boy - boysch boy    -0.1799 0.0991 Inf  -1.814  0.4565
> >>  mixedsch boy - girlsch boy    nonEst    NA  NA      NA      NA
> >>  mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
> >>  mixedsch boy - boysch girl    nonEst    NA  NA      NA      NA
> >>  mixedsch boy - girlsch girl  -0.3431 0.0780 Inf  -4.396  0.0002
> >>  boysch boy - girlsch boy      nonEst    NA  NA      NA      NA
> >>  boysch boy - mixedsch girl    0.0116 0.0997 Inf  0.116  1.0000
> >>  boysch boy - boysch girl      nonEst    NA  NA      NA      NA
> >>  boysch boy - girlsch girl    -0.1632 0.1058 Inf  -1.543  0.6361
> >>  girlsch boy - mixedsch girl    nonEst    NA  NA      NA      NA
> >>  girlsch boy - boysch girl      nonEst    NA  NA      NA      NA
> >>  girlsch boy - girlsch girl    nonEst    NA  NA      NA      NA
> >>  mixedsch girl - boysch girl    nonEst    NA  NA      NA      NA
> >>  mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
> >>  boysch girl - girlsch girl    nonEst    NA  NA      NA      NA
> >>
> >> Degrees-of-freedom method: asymptotic
> >> P value adjustment: tukey method for comparing a family of 6 estimates
> >>
> >>
> >> ---------------------------------------------------------
> >> From: Simon Harmel <sim.harmel at gmail.com>
> >> Sent: Sunday, September 26, 2021 3:08 PM
> >> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> Dear Russ and the List Members,
> >>
> >> If we use Russ' great package (emmeans), we see that although
> meaningless, but "schgendgirl-only" can be interpreted using the logic I
> mentioned here:
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2021q3%2F029723.html&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=kUR%2BudOSdu9gHZCsdimDJGEuheQLyI5pBlwqNctQu4A%3D&amp;reserved=0 .
> >>
> >> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys
> in girl-only vs. mixed schools*** just like it can meaningfully mean:
> ***diff. bet. girls in girl-only vs. mixed schools***
> >>
> >> Russ, have I used emmeans correctly?
> >>
> >> Simon
> >>
> >> Here is a reproducible code:
> >>
> >> library(R2MLwiN) # For the dataset
> >> library(lme4)
> >> library(emmeans)
> >>
> >> data("tutorial")
> >>
> >> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> >> model <- lmer(Form, data = tutorial, REML = FALSE)
> >>
> >> emmeans(model, pairwise~schgend+sex)$contrast
> >>
> >> contrast                    estimate    SE  df z.ratio p.value
> >> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> >> mixedsch boy - girlsch boy  -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef. equals
> >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> >> mixedsch boy - boysch girl  -0.34813 0.1096 Inf -3.178  0.0186
> >> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> >> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> >> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> >> boysch boy - boysch girl    -0.16826 0.0338 Inf -4.975  <.0001
> >> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> >> girlsch boy - mixedsch girl  0.00656 0.0928 Inf  0.071  1.0000
> >> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> >> girlsch boy - girlsch girl  -0.16826 0.0338 Inf -4.975  <.0001
> >> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef.
> >> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=%2BAvoQotl3QBMkVTOWiHJtHPJ%2B79wFLAMF39m6Cgb01A%3D&amp;reserved=0
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0
>

    [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0


	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Fri Feb 25 14:49:49 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Fri, 25 Feb 2022 15:49:49 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <MN2PR03MB51676543244823BCDE56239EE23E9@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
 <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
 <943078633.1040414.1645794249936@mail.yahoo.com>
 <MN2PR03MB51676543244823BCDE56239EE23E9@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <CAG_dBVdJy=gK6xDdh8pB5jMxtOaZ=rbca0tN2p-bDKvdWsDeVg@mail.gmail.com>

I am indeed talking about collinearity of the predictors, not the response.
A multinomial model consists of C-1 binary submodels, so it arguably
doesn't make sense to measure collinearity in the entire dataset at once
but, rather, it should be measured separately in the C-1 subdatasets to
which the C-1 submodels are fit. My question is whether the way I propose
to do this (in the original post) is sensible.

Best,

Juho

pe 25. helmik. 2022 klo 15.19 Sorkin, John (jsorkin at som.umaryland.edu)
kirjoitti:

> I would agree with Steven. Collinearity is problem with the predictor
> variables, not the outcome variable. Given a multinomial model y = f(x1,
> x2, x3, . . . xn), one could run a simple linear regression x1 = f(x2,x3, .
> . .,xn) and look at vif to determine if x2 . . . xn are colinear and
> perhaps an additional regression x2=f(x1,x3, . . .xn) to determine if x1,
> x3, . . . xn are colinear. If I am missing something, I hope someone will
> correct me.
>
> John (but not John Fox)
>
>
>
> Sent from Mail <https://go.microsoft.com/fwlink/?LinkId=550986> for
> Windows
>
>
>
> *From: *stevedrd--- via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org>
> *Sent: *Friday, February 25, 2022 8:07 AM
> *To: *John Fox <jfox at mcmaster.ca>; Juho Kristian Ruohonen
> <juho.kristian.ruohonen at gmail.com>
> *Cc: *r-sig-mixed-models at r-project.org
> *Subject: *Re: [R-sig-ME] Collinearity diagnostics for (mixed)
> multinomial models
>
>
>
> This seems odd to me, but then I don't usually analyze multinomial
> models.  Is there an issue with collinearity in the response variable in a
> multinomial model?  I would think that the levels are collinear by
> definition.  So then the issue, it seems to me, is whether there is
> collinearity in the fixed effects - and that should be independent of the
> response variables.  Could you use the vif() function with a standard
> response (say = 1) to check collinearity in the fixed effects?  I would
> think that your method on the sub datasets may not capture all of the
> collinearity in the full model.
> But I could be waaaaaaay off base on this.
> SteveDenham
>     On Friday, February 25, 2022, 03:24:15 AM EST, Juho Kristian Ruohonen <
> juho.kristian.ruohonen at gmail.com> wrote:
>
>  Dear John (and anyone else qualified to comment),
>
> I fit lots of mixed-effects multinomial models in my research, and I would
> like to see some (multi)collinearity diagnostics on the fixed effects, of
> which there are over 30. My models are fit using the Bayesian *brms*
> package because I know of no frequentist packages with multinomial GLMM
> compatibility.
>
> With continuous or dichotomous outcomes, my go-to function for calculating
> multicollinearity diagnostics is of course *vif()* from the *car* package.
> As expected, however, this function does not report sensible diagnostics
> for multinomial models -- not even for standard ones fit by the *nnet*
> package's *multinom()* function. The reason, I presume, is because a
> multinomial model is not really one but C-1 regression models  (where C is
> the number of response categories) and the *vif()* function is not designed
> to deal with this scenario.
>
> Therefore, in order to obtain meaningful collinearity metrics, my present
> plan is to write a simple helper function that uses *vif() *to calculate
> and present (generalized) variance inflation metrics for the C-1
> sub-datasets to which the C-1 component binomial models of the overall
> multinomial model are fit. In other words, it will partition the data into
> those C-1 subsets, and then apply *vif()* to as many linear regressions
> using a made-up continuous response and the fixed effects of interest.
>
> Does this seem like a sensible approach?
>
> Best,
>
> Juho
>
>
>
>
> ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca) kirjoitti:
>
> > Dear Simon,
> >
> > I believe that Russ's point is that the fact that the additive model
> > allows you to estimate nonsensical quantities like a mean for girls in
> > all-boys' schools implies a problem with the model. Why not do as I
> > suggested and define two dichotomous factors: sex of student
> > (male/female) and type of school (coed, same-sex)? The four combinations
> > of levels then make sense.
> >
> > Best,
> >  John
> >
> > On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> > > Thanks, Russ! There is one thing that I still don't understand. We
> > > have two completely empty cells (boys in girl-only & girls in boy-only
> > > schools). Then, how are the means of those empty cells computed (what
> > > data is used in their place in the additive model)?
> > >
> > > Let's' simplify the model for clarity:
> > >
> > > library(R2MLwiN)
> > > library(emmeans)
> > >
> > > Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> > > model3 <- lm(Form3, data = tutorial)
> > >
> > > emmeans(model3, pairwise~sex+schgend)$emmeans
> > >
> > >  sex  schgend  emmean    SE  df lower.CL upper.CL
> > >  boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
> > >  girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
> > >  boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
> > >  girl boysch    0.2641 0.0609 4055  0.1447  0.38360<-how computed?
> > >  boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
> > >  girl girlsch  0.1460 0.0267 4055  0.0938  0.19829
> > >
> > >
> > >
> > >
> > >
> > > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> > > <russell-lenth at uiowa.edu> wrote:
> > >>
> > >> By the way, returning to the topic of interpreting coefficients, you
> > ought to have fun with the ones from the model I just fitted:
> > >>
> > >> Fixed effects:
> > >>                Estimate Std. Error t value
> > >> (Intercept)    -0.18882    0.05135  -3.677
> > >> standlrt        0.55442    0.01994  27.807
> > >> schgendboysch  0.17986    0.09915  1.814
> > >> schgendgirlsch  0.17482    0.07877  2.219
> > >> sexgirl        0.16826    0.03382  4.975
> > >>
> > >> One curious thing you'll notice is that there are no coefficients for
> > the interaction terms. Why? Because those terms were "thrown out" of the
> > model, and so they are not shown. I think it is unwise to not show what
> was
> > thrown out (e.g., lm would have shown them as NAs), because in fact what
> we
> > see is but one of infinitely many possible solutions to the regression
> > equations. This is the solution where the last two coefficients are
> > constrained to zero. There is another equally reasonable one where the
> > coefficients for schgendboysch and schgendgirlsch  are constrained to
> zero,
> > and the two interaction effects would then be non-zero. And infinitely
> more
> > where all 7 coefficients are non-zero, and there are two linear
> constraints
> > among them.
> > >>
> > >> Of course, since the particular estimate shown consists of all the
> main
> > effects and interactions are constrained to zero, it does demonstrate
> that
> > the additive model *could* have been used to obtain the same estimates
> and
> > standard errors, and you can see that by comparing the results (and
> > ignoring the invalid ones from the additive model). But it is just a
> lucky
> > coincidence that it worked out this way, and the additive model did lead
> us
> > down a primrose path containing silly results among the correct ones.
> > >>
> > >> Russ
> > >>
> > >> -----Original Message-----
> > >> From: Lenth, Russell V
> > >> Sent: Sunday, September 26, 2021 7:43 PM
> > >> To: Simon Harmel <sim.harmel at gmail.com>
> > >> Cc: r-sig-mixed-models at r-project.org
> > >> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one
> > fixed-effect coefficient
> > >>
> > >> I guess correctness is in the eyes of the beholder. But I think this
> > illustrates the folly of the additive model. Having additive effects
> > suggests a belief that you can vary one factor more or less independently
> > of the other. In his comments, John Fox makes a good point that escaped
> my
> > earlier cursory view of the original question, that you don't have data
> on
> > girls attending all-boys' schools, nor boys attending all-girls' schools;
> > yet the model that was fitted estimates a mean response for both those
> > situations. That's a pretty clear testament to the failure of that model
> ?
> > and also why the coefficients don't make sense. And finally why we have
> > estimates of 15 comparisons (some of which are aliased with one another),
> > when only 6 of them make sense.
> > >>
> > >> If instead, a model with interaction were fitted, it would be a
> > rank-deficient model because two cells are empty. Perhaps there is some
> > sort of nesting structure that could be used to work around that.
> However,
> > it doesn't matter much because emmeans assesses estimability, and the two
> > combinations I mentioned above would be flagged as non-estimable. One
> could
> > then more judiciously use the contrast function to test meaningful
> > contrasts across this irregular array of cell means. Or even
> injudiciously
> > asking for all pairwise comparisons, you will see 6 estimable ones and 9
> > non-estimable ones. See output below.
> > >>
> > >> Russ
> > >>
> > >> ----- Interactive model -----
> > >>
> > >>> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> > >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> > >> fixed-effect model matrix is rank deficient so dropping 2 columns /
> > coefficients
> > >>>
> > >>> emmeans(model, pairwise~schgend+sex)
> > >>
> > >> ... messages deleted ...
> > >>
> > >> $emmeans
> > >>  schgend  sex    emmean    SE  df asymp.LCL asymp.UCL
> > >>  mixedsch boy  -0.18781 0.0514 Inf  -0.2885  -0.0871
> > >>  boysch  boy  -0.00795 0.0880 Inf  -0.1805    0.1646
> > >>  girlsch  boy    nonEst    NA  NA        NA        NA
> > >>  mixedsch girl -0.01955 0.0521 Inf  -0.1216    0.0825
> > >>  boysch  girl  nonEst    NA  NA        NA        NA
> > >>  girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> > >>
> > >> Degrees-of-freedom method: asymptotic
> > >> Confidence level used: 0.95
> > >>
> > >> $contrasts
> > >>  contrast                    estimate    SE  df z.ratio p.value
> > >>  mixedsch boy - boysch boy    -0.1799 0.0991 Inf  -1.814  0.4565
> > >>  mixedsch boy - girlsch boy    nonEst    NA  NA      NA      NA
> > >>  mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
> > >>  mixedsch boy - boysch girl    nonEst    NA  NA      NA      NA
> > >>  mixedsch boy - girlsch girl  -0.3431 0.0780 Inf  -4.396  0.0002
> > >>  boysch boy - girlsch boy      nonEst    NA  NA      NA      NA
> > >>  boysch boy - mixedsch girl    0.0116 0.0997 Inf  0.116  1.0000
> > >>  boysch boy - boysch girl      nonEst    NA  NA      NA      NA
> > >>  boysch boy - girlsch girl    -0.1632 0.1058 Inf  -1.543  0.6361
> > >>  girlsch boy - mixedsch girl    nonEst    NA  NA      NA      NA
> > >>  girlsch boy - boysch girl      nonEst    NA  NA      NA      NA
> > >>  girlsch boy - girlsch girl    nonEst    NA  NA      NA      NA
> > >>  mixedsch girl - boysch girl    nonEst    NA  NA      NA      NA
> > >>  mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
> > >>  boysch girl - girlsch girl    nonEst    NA  NA      NA      NA
> > >>
> > >> Degrees-of-freedom method: asymptotic
> > >> P value adjustment: tukey method for comparing a family of 6 estimates
> > >>
> > >>
> > >> ---------------------------------------------------------
> > >> From: Simon Harmel <sim.harmel at gmail.com>
> > >> Sent: Sunday, September 26, 2021 3:08 PM
> > >> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> > >> Cc: r-sig-mixed-models at r-project.org
> > >> Subject: [External] Re: [R-sig-ME] Help with interpreting one
> > fixed-effect coefficient
> > >>
> > >> Dear Russ and the List Members,
> > >>
> > >> If we use Russ' great package (emmeans), we see that although
> > meaningless, but "schgendgirl-only" can be interpreted using the logic I
> > mentioned here:
> >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2021q3%2F029723.html&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=kUR%2BudOSdu9gHZCsdimDJGEuheQLyI5pBlwqNctQu4A%3D&amp;reserved=0
> .
> > >>
> > >> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys
> > in girl-only vs. mixed schools*** just like it can meaningfully mean:
> > ***diff. bet. girls in girl-only vs. mixed schools***
> > >>
> > >> Russ, have I used emmeans correctly?
> > >>
> > >> Simon
> > >>
> > >> Here is a reproducible code:
> > >>
> > >> library(R2MLwiN) # For the dataset
> > >> library(lme4)
> > >> library(emmeans)
> > >>
> > >> data("tutorial")
> > >>
> > >> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> > >> model <- lmer(Form, data = tutorial, REML = FALSE)
> > >>
> > >> emmeans(model, pairwise~schgend+sex)$contrast
> > >>
> > >> contrast                    estimate    SE  df z.ratio p.value
> > >> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> > >> mixedsch boy - girlsch boy  -0.17482 0.0788 Inf -2.219  0.2287
> >  <--This coef. equals
> > >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> > >> mixedsch boy - boysch girl  -0.34813 0.1096 Inf -3.178  0.0186
> > >> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> > >> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> > >> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> > >> boysch boy - boysch girl    -0.16826 0.0338 Inf -4.975  <.0001
> > >> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> > >> girlsch boy - mixedsch girl  0.00656 0.0928 Inf  0.071  1.0000
> > >> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> > >> girlsch boy - girlsch girl  -0.16826 0.0338 Inf -4.975  <.0001
> > >> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> > >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287
> >  <--This coef.
> > >> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
> > >>
> > >>
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0
> > >
> > --
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > web:
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=%2BAvoQotl3QBMkVTOWiHJtHPJ%2B79wFLAMF39m6Cgb01A%3D&amp;reserved=0
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0
> >
>
>     [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
>
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
>
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0
>
>
>

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Feb 25 15:18:39 2022
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 25 Feb 2022 14:18:39 +0000
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAG_dBVdJy=gK6xDdh8pB5jMxtOaZ=rbca0tN2p-bDKvdWsDeVg@mail.gmail.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
 <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
 <943078633.1040414.1645794249936@mail.yahoo.com>
 <MN2PR03MB51676543244823BCDE56239EE23E9@MN2PR03MB5167.namprd03.prod.outlook.com>
 <CAG_dBVdJy=gK6xDdh8pB5jMxtOaZ=rbca0tN2p-bDKvdWsDeVg@mail.gmail.com>
Message-ID: <MN2PR03MB5167467057A768AEC62EDD40E23E9@MN2PR03MB5167.namprd03.prod.outlook.com>

Juko,
It is my understanding, perhaps incorrect understanding, that collinearity of the independent variables is accessed independent of the nature of the dependent variable. Collinearity leads to inferential problems, i.e. determining if the predictors variables are independent predictors of the dependent variable. When the independent variables are collinear, the shared variance among the independent variables makes it difficult, or impossible, to determine (1) if the predictors variables are independent predictors of the dependent variable and (2) the magnitude of the contribution each independent variable makes to the prediction of the dependent variable?s value, regardless of the class of the dependent variable (continuous, binary, multinomial, etc.). On the other hand collinearity does not generally effect prediction. A set of collinear independent variables can predict a dependent variable accurately even if one can not separate the contribution of each of the collinear independent variables to the prediction of the dependent variable. I do not see why collinearity among independent variables would have a different effect on, or be looked for in multinomial models any differently than one would look for collinearity in the ?usual? linear regression where the dependent variable is continuous.  I would be happy to be disabused of an error in my understanding of collinearity.
John

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows

From: Juho Kristian Ruohonen<mailto:juho.kristian.ruohonen at gmail.com>
Sent: Friday, February 25, 2022 8:50 AM
To: Sorkin, John<mailto:jsorkin at som.umaryland.edu>
Cc: stevedrd at yahoo.com<mailto:stevedrd at yahoo.com>; John Fox<mailto:jfox at mcmaster.ca>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Collinearity diagnostics for (mixed) multinomial models

I am indeed talking about collinearity of the predictors, not the response. A multinomial model consists of C-1 binary submodels, so it arguably doesn't make sense to measure collinearity in the entire dataset at once but, rather, it should be measured separately in the C-1 subdatasets to which the C-1 submodels are fit. My question is whether the way I propose to do this (in the original post) is sensible.

Best,

Juho

pe 25. helmik. 2022 klo 15.19 Sorkin, John (jsorkin at som.umaryland.edu<mailto:jsorkin at som.umaryland.edu>) kirjoitti:
I would agree with Steven. Collinearity is problem with the predictor variables, not the outcome variable. Given a multinomial model y = f(x1, x2, x3, . . . xn), one could run a simple linear regression x1 = f(x2,x3, . . .,xn) and look at vif to determine if x2 . . . xn are colinear and perhaps an additional regression x2=f(x1,x3, . . .xn) to determine if x1, x3, . . . xn are colinear. If I am missing something, I hope someone will correct me.
John (but not John Fox)

Sent from Mail<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgo.microsoft.com%2Ffwlink%2F%3FLinkId%3D550986&data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C0f6e1d2cffb8442c60f308d9f865ba36%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813938549646032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=YOdb6JICQeEleTBmEc8uU0GR6n5Hsq5TEf8Zd8FAQYQ%3D&reserved=0> for Windows

From: stevedrd--- via R-sig-mixed-models<mailto:r-sig-mixed-models at r-project.org>
Sent: Friday, February 25, 2022 8:07 AM
To: John Fox<mailto:jfox at mcmaster.ca>; Juho Kristian Ruohonen<mailto:juho.kristian.ruohonen at gmail.com>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Collinearity diagnostics for (mixed) multinomial models

This seems odd to me, but then I don't usually analyze multinomial models.  Is there an issue with collinearity in the response variable in a multinomial model?  I would think that the levels are collinear by definition.  So then the issue, it seems to me, is whether there is collinearity in the fixed effects - and that should be independent of the response variables.  Could you use the vif() function with a standard response (say = 1) to check collinearity in the fixed effects?  I would think that your method on the sub datasets may not capture all of the collinearity in the full model.
But I could be waaaaaaay off base on this.
SteveDenham
    On Friday, February 25, 2022, 03:24:15 AM EST, Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com<mailto:juho.kristian.ruohonen at gmail.com>> wrote:

 Dear John (and anyone else qualified to comment),

I fit lots of mixed-effects multinomial models in my research, and I would
like to see some (multi)collinearity diagnostics on the fixed effects, of
which there are over 30. My models are fit using the Bayesian *brms*
package because I know of no frequentist packages with multinomial GLMM
compatibility.

With continuous or dichotomous outcomes, my go-to function for calculating
multicollinearity diagnostics is of course *vif()* from the *car* package.
As expected, however, this function does not report sensible diagnostics
for multinomial models -- not even for standard ones fit by the *nnet*
package's *multinom()* function. The reason, I presume, is because a
multinomial model is not really one but C-1 regression models  (where C is
the number of response categories) and the *vif()* function is not designed
to deal with this scenario.

Therefore, in order to obtain meaningful collinearity metrics, my present
plan is to write a simple helper function that uses *vif() *to calculate
and present (generalized) variance inflation metrics for the C-1
sub-datasets to which the C-1 component binomial models of the overall
multinomial model are fit. In other words, it will partition the data into
those C-1 subsets, and then apply *vif()* to as many linear regressions
using a made-up continuous response and the fixed effects of interest.

Does this seem like a sensible approach?

Best,

Juho




ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca<mailto:jfox at mcmaster.ca>) kirjoitti:

> Dear Simon,
>
> I believe that Russ's point is that the fact that the additive model
> allows you to estimate nonsensical quantities like a mean for girls in
> all-boys' schools implies a problem with the model. Why not do as I
> suggested and define two dichotomous factors: sex of student
> (male/female) and type of school (coed, same-sex)? The four combinations
> of levels then make sense.
>
> Best,
>  John
>
> On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> > Thanks, Russ! There is one thing that I still don't understand. We
> > have two completely empty cells (boys in girl-only & girls in boy-only
> > schools). Then, how are the means of those empty cells computed (what
> > data is used in their place in the additive model)?
> >
> > Let's' simplify the model for clarity:
> >
> > library(R2MLwiN)
> > library(emmeans)
> >
> > Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> > model3 <- lm(Form3, data = tutorial)
> >
> > emmeans(model3, pairwise~sex+schgend)$emmeans
> >
> >  sex  schgend  emmean    SE  df lower.CL upper.CL
> >  boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
> >  girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
> >  boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
> >  girl boysch    0.2641 0.0609 4055  0.1447  0.38360<-how computed?
> >  boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
> >  girl girlsch  0.1460 0.0267 4055  0.0938  0.19829
> >
> >
> >
> >
> >
> > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> > <russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu>> wrote:
> >>
> >> By the way, returning to the topic of interpreting coefficients, you
> ought to have fun with the ones from the model I just fitted:
> >>
> >> Fixed effects:
> >>                Estimate Std. Error t value
> >> (Intercept)    -0.18882    0.05135  -3.677
> >> standlrt        0.55442    0.01994  27.807
> >> schgendboysch  0.17986    0.09915  1.814
> >> schgendgirlsch  0.17482    0.07877  2.219
> >> sexgirl        0.16826    0.03382  4.975
> >>
> >> One curious thing you'll notice is that there are no coefficients for
> the interaction terms. Why? Because those terms were "thrown out" of the
> model, and so they are not shown. I think it is unwise to not show what was
> thrown out (e.g., lm would have shown them as NAs), because in fact what we
> see is but one of infinitely many possible solutions to the regression
> equations. This is the solution where the last two coefficients are
> constrained to zero. There is another equally reasonable one where the
> coefficients for schgendboysch and schgendgirlsch  are constrained to zero,
> and the two interaction effects would then be non-zero. And infinitely more
> where all 7 coefficients are non-zero, and there are two linear constraints
> among them.
> >>
> >> Of course, since the particular estimate shown consists of all the main
> effects and interactions are constrained to zero, it does demonstrate that
> the additive model *could* have been used to obtain the same estimates and
> standard errors, and you can see that by comparing the results (and
> ignoring the invalid ones from the additive model). But it is just a lucky
> coincidence that it worked out this way, and the additive model did lead us
> down a primrose path containing silly results among the correct ones.
> >>
> >> Russ
> >>
> >> -----Original Message-----
> >> From: Lenth, Russell V
> >> Sent: Sunday, September 26, 2021 7:43 PM
> >> To: Simon Harmel <sim.harmel at gmail.com<mailto:sim.harmel at gmail.com>>
> >> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> >> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> I guess correctness is in the eyes of the beholder. But I think this
> illustrates the folly of the additive model. Having additive effects
> suggests a belief that you can vary one factor more or less independently
> of the other. In his comments, John Fox makes a good point that escaped my
> earlier cursory view of the original question, that you don't have data on
> girls attending all-boys' schools, nor boys attending all-girls' schools;
> yet the model that was fitted estimates a mean response for both those
> situations. That's a pretty clear testament to the failure of that model ?
> and also why the coefficients don't make sense. And finally why we have
> estimates of 15 comparisons (some of which are aliased with one another),
> when only 6 of them make sense.
> >>
> >> If instead, a model with interaction were fitted, it would be a
> rank-deficient model because two cells are empty. Perhaps there is some
> sort of nesting structure that could be used to work around that. However,
> it doesn't matter much because emmeans assesses estimability, and the two
> combinations I mentioned above would be flagged as non-estimable. One could
> then more judiciously use the contrast function to test meaningful
> contrasts across this irregular array of cell means. Or even injudiciously
> asking for all pairwise comparisons, you will see 6 estimable ones and 9
> non-estimable ones. See output below.
> >>
> >> Russ
> >>
> >> ----- Interactive model -----
> >>
> >>> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> >> fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> >>>
> >>> emmeans(model, pairwise~schgend+sex)
> >>
> >> ... messages deleted ...
> >>
> >> $emmeans
> >>  schgend  sex    emmean    SE  df asymp.LCL asymp.UCL
> >>  mixedsch boy  -0.18781 0.0514 Inf  -0.2885  -0.0871
> >>  boysch  boy  -0.00795 0.0880 Inf  -0.1805    0.1646
> >>  girlsch  boy    nonEst    NA  NA        NA        NA
> >>  mixedsch girl -0.01955 0.0521 Inf  -0.1216    0.0825
> >>  boysch  girl  nonEst    NA  NA        NA        NA
> >>  girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> >>
> >> Degrees-of-freedom method: asymptotic
> >> Confidence level used: 0.95
> >>
> >> $contrasts
> >>  contrast                    estimate    SE  df z.ratio p.value
> >>  mixedsch boy - boysch boy    -0.1799 0.0991 Inf  -1.814  0.4565
> >>  mixedsch boy - girlsch boy    nonEst    NA  NA      NA      NA
> >>  mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
> >>  mixedsch boy - boysch girl    nonEst    NA  NA      NA      NA
> >>  mixedsch boy - girlsch girl  -0.3431 0.0780 Inf  -4.396  0.0002
> >>  boysch boy - girlsch boy      nonEst    NA  NA      NA      NA
> >>  boysch boy - mixedsch girl    0.0116 0.0997 Inf  0.116  1.0000
> >>  boysch boy - boysch girl      nonEst    NA  NA      NA      NA
> >>  boysch boy - girlsch girl    -0.1632 0.1058 Inf  -1.543  0.6361
> >>  girlsch boy - mixedsch girl    nonEst    NA  NA      NA      NA
> >>  girlsch boy - boysch girl      nonEst    NA  NA      NA      NA
> >>  girlsch boy - girlsch girl    nonEst    NA  NA      NA      NA
> >>  mixedsch girl - boysch girl    nonEst    NA  NA      NA      NA
> >>  mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
> >>  boysch girl - girlsch girl    nonEst    NA  NA      NA      NA
> >>
> >> Degrees-of-freedom method: asymptotic
> >> P value adjustment: tukey method for comparing a family of 6 estimates
> >>
> >>
> >> ---------------------------------------------------------
> >> From: Simon Harmel <sim.harmel at gmail.com<mailto:sim.harmel at gmail.com>>
> >> Sent: Sunday, September 26, 2021 3:08 PM
> >> To: Lenth, Russell V <russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu>>
> >> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> >> Subject: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> Dear Russ and the List Members,
> >>
> >> If we use Russ' great package (emmeans), we see that although
> meaningless, but "schgendgirl-only" can be interpreted using the logic I
> mentioned here:
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2021q3%2F029723.html&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=kUR%2BudOSdu9gHZCsdimDJGEuheQLyI5pBlwqNctQu4A%3D&amp;reserved=0<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2021q3%2F029723.html&data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C0f6e1d2cffb8442c60f308d9f865ba36%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813938549646032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=76bZe32xc%2FpHHb%2F26RpjZ9Pdri4F5ExSefe2giZ3IgU%3D&reserved=0> .
> >>
> >> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys
> in girl-only vs. mixed schools*** just like it can meaningfully mean:
> ***diff. bet. girls in girl-only vs. mixed schools***
> >>
> >> Russ, have I used emmeans correctly?
> >>
> >> Simon
> >>
> >> Here is a reproducible code:
> >>
> >> library(R2MLwiN) # For the dataset
> >> library(lme4)
> >> library(emmeans)
> >>
> >> data("tutorial")
> >>
> >> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> >> model <- lmer(Form, data = tutorial, REML = FALSE)
> >>
> >> emmeans(model, pairwise~schgend+sex)$contrast
> >>
> >> contrast                    estimate    SE  df z.ratio p.value
> >> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> >> mixedsch boy - girlsch boy  -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef. equals
> >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> >> mixedsch boy - boysch girl  -0.34813 0.1096 Inf -3.178  0.0186
> >> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> >> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> >> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> >> boysch boy - boysch girl    -0.16826 0.0338 Inf -4.975  <.0001
> >> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> >> girlsch boy - mixedsch girl  0.00656 0.0928 Inf  0.071  1.0000
> >> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> >> girlsch boy - girlsch girl  -0.16826 0.0338 Inf -4.975  <.0001
> >> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef.
> >> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> > https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C0f6e1d2cffb8442c60f308d9f865ba36%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813938549646032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=rwAL1mmsx9aToNsg67XbvZf4G8FnPt21I29JnrBdiww%3D&reserved=0>
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=%2BAvoQotl3QBMkVTOWiHJtHPJ%2B79wFLAMF39m6Cgb01A%3D&amp;reserved=0<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C0f6e1d2cffb8442c60f308d9f865ba36%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813938549646032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=V1%2FOZcoGRDJJk4jax%2BVcX%2FijE9KmusqCdoGBNzrYbrs%3D&reserved=0>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C0f6e1d2cffb8442c60f308d9f865ba36%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813938549646032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=rwAL1mmsx9aToNsg67XbvZf4G8FnPt21I29JnrBdiww%3D&reserved=0>
>

    [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C0f6e1d2cffb8442c60f308d9f865ba36%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813938549646032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=rwAL1mmsx9aToNsg67XbvZf4G8FnPt21I29JnrBdiww%3D&reserved=0>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C5fb7bcf6b8824a3109f708d9f85fa6f1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813912584894963%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0&amp;sdata=VXBlGoxZ5iq3OWpGhpxjVbAn9w4OUUTtSp8BARHFQW0%3D&amp;reserved=0<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cjsorkin%40som.umaryland.edu%7C0f6e1d2cffb8442c60f308d9f865ba36%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637813938549646032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=rwAL1mmsx9aToNsg67XbvZf4G8FnPt21I29JnrBdiww%3D&reserved=0>



	[[alternative HTML version deleted]]


From johnw|||ec @end|ng |rom gm@||@com  Fri Feb 25 18:22:29 2022
From: johnw|||ec @end|ng |rom gm@||@com (John Willoughby)
Date: Fri, 25 Feb 2022 09:22:29 -0800
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
Message-ID: <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>

Have you tried the check_collinearity() function in the performance
package? It's supposed to work on brms models, but whether it will work on
a multinomial model I don't know.  It works well on mixed models generated
by glmmTMB().

John Willoughby


On Fri, Feb 25, 2022 at 3:01 AM <r-sig-mixed-models-request at r-project.org>
wrote:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Collinearity diagnostics for (mixed) multinomial models
>       (Juho Kristian Ruohonen)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 25 Feb 2022 10:23:25 +0200
> From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
> To: John Fox <jfox at mcmaster.ca>
> Cc: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Collinearity diagnostics for (mixed) multinomial
>         models
> Message-ID:
>         <
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Dear John (and anyone else qualified to comment),
>
> I fit lots of mixed-effects multinomial models in my research, and I would
> like to see some (multi)collinearity diagnostics on the fixed effects, of
> which there are over 30. My models are fit using the Bayesian *brms*
> package because I know of no frequentist packages with multinomial GLMM
> compatibility.
>
> With continuous or dichotomous outcomes, my go-to function for calculating
> multicollinearity diagnostics is of course *vif()* from the *car* package.
> As expected, however, this function does not report sensible diagnostics
> for multinomial models -- not even for standard ones fit by the *nnet*
> package's *multinom()* function. The reason, I presume, is because a
> multinomial model is not really one but C-1 regression models  (where C is
> the number of response categories) and the *vif()* function is not designed
> to deal with this scenario.
>
> Therefore, in order to obtain meaningful collinearity metrics, my present
> plan is to write a simple helper function that uses *vif() *to calculate
> and present (generalized) variance inflation metrics for the C-1
> sub-datasets to which the C-1 component binomial models of the overall
> multinomial model are fit. In other words, it will partition the data into
> those C-1 subsets, and then apply *vif()* to as many linear regressions
> using a made-up continuous response and the fixed effects of interest.
>
> Does this seem like a sensible approach?
>
> Best,
>
> Juho
>
>
>

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Fri Feb 25 20:52:55 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Fri, 25 Feb 2022 21:52:55 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <63b44aed-cfcf-cfc3-99ba-fc7e7c85a0fb@mcmaster.ca>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
 <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
 <63b44aed-cfcf-cfc3-99ba-fc7e7c85a0fb@mcmaster.ca>
Message-ID: <CAG_dBVe+Ovcae-RoDWRz8cDJLTQx3aLZ9ZZ8Debkz0V3xud5Zw@mail.gmail.com>

Dear John (Fox, and other list members),

Could we achieve the invariance Professor Fox refers to by altering my
initial approach in the following ways:

   1. Instead of fitting a *linear* model with a mock continuous response
   to each subdataset and applying *vif() *to that, we fit to each
   subdataset an actual binary GLM with a real pairing of two response
   categories as LHS.
   2. Instead of fitting only C-1 binary sub-GLMs for which to calculate
   GVIF diagnostics, we fit *choose(C, 2) *such submodels, i.e. *one for
   every possible pairing of response categories*.
   3. Finally, for each coefficient, we average the GVIF statistic
over the *choose(C,
   2)* submodels in order to obtain a summary statistic.

What do you gentlemen think?

Best,

Juho



pe 25. helmik. 2022 klo 19.40 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juhu,
>
> Apologies for my slow response -- I had a busy morning.
>
> I hadn't thought about generalizing VIFs to multinomial regression
> models, and I haven't thought the question through now, but I don't
> think that what you propose makes sense.
>
> For a linear model, the vif() function in the car packages computes
> generalized VIFs, as proposed by Fox and Monette in the paper referenced
> in ?vif. That is, for the linear model y ~ 1 + X, where X is a matrix of
> regressors, the generalized VIF associated with the regression
> coefficients for a column subset of X, say X_j, is GVIF_j = det R_{jj}
> det R_{-j, -j}/det R, which is interpretable as the size (hypervolume)
> of a confidence ellipsoid for the coefficients of X_j relative to the
> size of the confidence ellipsoid for similar "utopian" data in which X_j
> and X_{-j} are uncorrelated. Here, det R_{jj} is the determinant of the
> correlation matrix among the columns of X_j, det R_{-j, -j} is the
> determinant of the correlation matrix among the remaining columns of X,
> and det R is the correlation matrix among all of the columns of X.
>
> This has the nice property that the bases for the subspaces spanned by
> the columns of X_j and X_{-j} are irrelevant, and thus, e.g., it doesn't
> matter what kind of contrasts one uses for a factor. Also when X_j is
> just one column of X, the GVIF specializes to the usual VIF.
>
> Actually, vif() uses the correlation matrix of the coefficients R_{bb}
> rather than the correlations of the variables R, but that turns out to
> be equivalent, and also suggests a generalization to other regression
> models, such as GLMs. More generally, however (that is, beyond linear
> models), the correlations of the coefficients involve y as well as X,
> and so there's some slippage in interpretation -- now the utopian data
> are no longer necessarily for uncorrelated Xs. This is true as well for
> some other diagnostics generalized beyond linear models, such as
> hatvalues, which, e.g., for GLMs, depend on the ys as well as the Xs.
>
> Analogously, in generalizing GVIFs further to a model such as a
> multinomial regression one would want a result that doesn't depend on
> the arbitrary parametrization of the LHS of the model -- for example,
> which level of the response is taken as the reference level. As I said,
> I haven't tried to think that through, but your solution isn't invariant
> in this way.
>
> I hope this helps,
>   John
>
> On 2022-02-25 3:23 a.m., Juho Kristian Ruohonen wrote:
> > Dear John (and anyone else qualified to comment),
> >
> > I fit lots of mixed-effects multinomial models in my research, and I
> > would like to see some (multi)collinearity diagnostics on the fixed
> > effects, of which there are over 30. My models are fit using the
> > Bayesian *brms* package because I know of no frequentist packages with
> > multinomial GLMM compatibility.
> >
> > With continuous or dichotomous outcomes, my go-to function for
> > calculating multicollinearity diagnostics is of course *vif()* from the
> > /car/ package. As expected, however, this function does not report
> > sensible diagnostics for multinomial models -- not even for standard
> > ones fit by the /nnet/ package's *multinom()* function. The reason, I
> > presume, is because a multinomial model is not really one but C-1
> > regression models  (where C is the number of response categories) and
> > the *vif()* function is not designed to deal with this scenario.
> >
> > Therefore, in order to obtain meaningful collinearity metrics, my
> > present plan is to write a simple helper function that uses *vif() *to
> > calculate and present (generalized) variance inflation metrics for the
> > C-1 sub-datasets to which the C-1 component binomial models of the
> > overall multinomial model are fit. In other words, it will partition the
> > data into those C-1 subsets, and then apply *vif()* to as many linear
> > regressions using a made-up continuous response and the fixed effects of
> > interest.
> >
> > Does this seem like a sensible approach?
> >
> > Best,
> >
> > Juho
> >
> >
> >
> >
> > ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Simon,
> >
> >     I believe that Russ's point is that the fact that the additive model
> >     allows you to estimate nonsensical quantities like a mean for girls
> in
> >     all-boys' schools implies a problem with the model. Why not do as I
> >     suggested and define two dichotomous factors: sex of student
> >     (male/female) and type of school (coed, same-sex)? The four
> >     combinations
> >     of levels then make sense.
> >
> >     Best,
> >        John
> >
> >     On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> >      > Thanks, Russ! There is one thing that I still don't understand. We
> >      > have two completely empty cells (boys in girl-only & girls in
> >     boy-only
> >      > schools). Then, how are the means of those empty cells computed
> (what
> >      > data is used in their place in the additive model)?
> >      >
> >      > Let's' simplify the model for clarity:
> >      >
> >      > library(R2MLwiN)
> >      > library(emmeans)
> >      >
> >      > Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt |
> school)
> >      > model3 <- lm(Form3, data = tutorial)
> >      >
> >      > emmeans(model3, pairwise~sex+schgend)$emmeans
> >      >
> >      >   sex  schgend   emmean     SE   df lower.CL upper.CL
> >      >   boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
> >      >   girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
> >      >   boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
> >      >   girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how
> computed?
> >      >   boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how
> computed?
> >      >   girl girlsch   0.1460 0.0267 4055   0.0938  0.19829
> >      >
> >      >
> >      >
> >      >
> >      >
> >      > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> >      > <russell-lenth at uiowa.edu <mailto:russell-lenth at uiowa.edu>> wrote:
> >      >>
> >      >> By the way, returning to the topic of interpreting coefficients,
> >     you ought to have fun with the ones from the model I just fitted:
> >      >>
> >      >> Fixed effects:
> >      >>                 Estimate Std. Error t value
> >      >> (Intercept)    -0.18882    0.05135  -3.677
> >      >> standlrt        0.55442    0.01994  27.807
> >      >> schgendboysch   0.17986    0.09915   1.814
> >      >> schgendgirlsch  0.17482    0.07877   2.219
> >      >> sexgirl         0.16826    0.03382   4.975
> >      >>
> >      >> One curious thing you'll notice is that there are no
> >     coefficients for the interaction terms. Why? Because those terms
> >     were "thrown out" of the model, and so they are not shown. I think
> >     it is unwise to not show what was thrown out (e.g., lm would have
> >     shown them as NAs), because in fact what we see is but one of
> >     infinitely many possible solutions to the regression equations. This
> >     is the solution where the last two coefficients are constrained to
> >     zero. There is another equally reasonable one where the coefficients
> >     for schgendboysch and schgendgirlsch  are constrained to zero, and
> >     the two interaction effects would then be non-zero. And infinitely
> >     more where all 7 coefficients are non-zero, and there are two linear
> >     constraints among them.
> >      >>
> >      >> Of course, since the particular estimate shown consists of all
> >     the main effects and interactions are constrained to zero, it does
> >     demonstrate that the additive model *could* have been used to obtain
> >     the same estimates and standard errors, and you can see that by
> >     comparing the results (and ignoring the invalid ones from the
> >     additive model). But it is just a lucky coincidence that it worked
> >     out this way, and the additive model did lead us down a primrose
> >     path containing silly results among the correct ones.
> >      >>
> >      >> Russ
> >      >>
> >      >> -----Original Message-----
> >      >> From: Lenth, Russell V
> >      >> Sent: Sunday, September 26, 2021 7:43 PM
> >      >> To: Simon Harmel <sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com>>
> >      >> Cc: r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting
> >     one fixed-effect coefficient
> >      >>
> >      >> I guess correctness is in the eyes of the beholder. But I think
> >     this illustrates the folly of the additive model. Having additive
> >     effects suggests a belief that you can vary one factor more or less
> >     independently of the other. In his comments, John Fox makes a good
> >     point that escaped my earlier cursory view of the original question,
> >     that you don't have data on girls attending all-boys' schools, nor
> >     boys attending all-girls' schools; yet the model that was fitted
> >     estimates a mean response for both those situations. That's a pretty
> >     clear testament to the failure of that model ? and also why the
> >     coefficients don't make sense. And finally why we have estimates of
> >     15 comparisons (some of which are aliased with one another), when
> >     only 6 of them make sense.
> >      >>
> >      >> If instead, a model with interaction were fitted, it would be a
> >     rank-deficient model because two cells are empty. Perhaps there is
> >     some sort of nesting structure that could be used to work around
> >     that. However, it doesn't matter much because emmeans assesses
> >     estimability, and the two combinations I mentioned above would be
> >     flagged as non-estimable. One could then more judiciously use the
> >     contrast function to test meaningful contrasts across this irregular
> >     array of cell means. Or even injudiciously asking for all pairwise
> >     comparisons, you will see 6 estimable ones and 9 non-estimable ones.
> >     See output below.
> >      >>
> >      >> Russ
> >      >>
> >      >> ----- Interactive model -----
> >      >>
> >      >>> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt |
> >     school)
> >      >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> >      >> fixed-effect model matrix is rank deficient so dropping 2
> >     columns / coefficients
> >      >>>
> >      >>> emmeans(model, pairwise~schgend+sex)
> >      >>
> >      >> ... messages deleted ...
> >      >>
> >      >> $emmeans
> >      >>   schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
> >      >>   mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
> >      >>   boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
> >      >>   girlsch  boy    nonEst     NA  NA        NA        NA
> >      >>   mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
> >      >>   boysch   girl   nonEst     NA  NA        NA        NA
> >      >>   girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> >      >>
> >      >> Degrees-of-freedom method: asymptotic
> >      >> Confidence level used: 0.95
> >      >>
> >      >> $contrasts
> >      >>   contrast                     estimate     SE  df z.ratio
> p.value
> >      >>   mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814
> 0.4565
> >      >>   mixedsch boy - girlsch boy     nonEst     NA  NA      NA
> NA
> >      >>   mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975
> <.0001
> >      >>   mixedsch boy - boysch girl     nonEst     NA  NA      NA
> NA
> >      >>   mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396
> 0.0002
> >      >>   boysch boy - girlsch boy       nonEst     NA  NA      NA
> NA
> >      >>   boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116
> 1.0000
> >      >>   boysch boy - boysch girl       nonEst     NA  NA      NA
> NA
> >      >>   boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543
> 0.6361
> >      >>   girlsch boy - mixedsch girl    nonEst     NA  NA      NA
> NA
> >      >>   girlsch boy - boysch girl      nonEst     NA  NA      NA
> NA
> >      >>   girlsch boy - girlsch girl     nonEst     NA  NA      NA
> NA
> >      >>   mixedsch girl - boysch girl    nonEst     NA  NA      NA
> NA
> >      >>   mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219
> 0.2287
> >      >>   boysch girl - girlsch girl     nonEst     NA  NA      NA
> NA
> >      >>
> >      >> Degrees-of-freedom method: asymptotic
> >      >> P value adjustment: tukey method for comparing a family of 6
> >     estimates
> >      >>
> >      >>
> >      >> ---------------------------------------------------------
> >      >> From: Simon Harmel <sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com>>
> >      >> Sent: Sunday, September 26, 2021 3:08 PM
> >      >> To: Lenth, Russell V <russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu>>
> >      >> Cc: r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >> Subject: [External] Re: [R-sig-ME] Help with interpreting one
> >     fixed-effect coefficient
> >      >>
> >      >> Dear Russ and the List Members,
> >      >>
> >      >> If we use Russ' great package (emmeans), we see that although
> >     meaningless, but "schgendgirl-only" can be interpreted using the
> >     logic I mentioned here:
> >     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html
> >     <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html> .
> >      >>
> >      >> That is, "schgendgirl-only" can meaninglessly mean: ***diff.
> >     bet. boys in girl-only vs. mixed schools*** just like it can
> >     meaningfully mean:  ***diff. bet. girls in girl-only vs. mixed
> >     schools***
> >      >>
> >      >> Russ, have I used emmeans correctly?
> >      >>
> >      >> Simon
> >      >>
> >      >> Here is a reproducible code:
> >      >>
> >      >> library(R2MLwiN) # For the dataset
> >      >> library(lme4)
> >      >> library(emmeans)
> >      >>
> >      >> data("tutorial")
> >      >>
> >      >> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt |
> >     school)
> >      >> model <- lmer(Form, data = tutorial, REML = FALSE)
> >      >>
> >      >> emmeans(model, pairwise~schgend+sex)$contrast
> >      >>
> >      >> contrast                     estimate     SE  df z.ratio p.value
> >      >> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> >      >> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287
> >       <--This coef. equals
> >      >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> >      >> mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
> >      >> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> >      >> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> >      >> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> >      >> boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
> >      >> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> >      >> girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
> >      >> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> >      >> girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
> >      >> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> >      >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287
> >       <--This coef.
> >      >> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
> >      >>
> >      >>
> >      >
> >      > _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sat Feb 26 08:15:55 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sat, 26 Feb 2022 09:15:55 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <66ad680e-e531-f948-3cc6-c68250636ac9@mcmaster.ca>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
 <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
 <63b44aed-cfcf-cfc3-99ba-fc7e7c85a0fb@mcmaster.ca>
 <CAG_dBVe+Ovcae-RoDWRz8cDJLTQx3aLZ9ZZ8Debkz0V3xud5Zw@mail.gmail.com>
 <66ad680e-e531-f948-3cc6-c68250636ac9@mcmaster.ca>
Message-ID: <CAG_dBVd4_zsWReefSdrhKH8XXn9Lb2p-ecFBxk9DEWmQTuU+5g@mail.gmail.com>

Many thanks, John. This is rather unfortunate news as it leaves me with no
way to present statistics on the degree to which my multinomial models are
affected by collinearity. But it's good to hear it directly from a
consummate expert.

Best,

Juho


la 26. helmik. 2022 klo 1.16 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juho,
>
> For some reason, my previous response to you (shown below your most
> recent message) doesn't seem to have made it to the list. Let's hope
> that this reply does:
>
> On 2022-02-25 2:52 p.m., Juho Kristian Ruohonen wrote:
> > Dear John (Fox, and other list members),
> >
> > Could we achieve the invariance Professor Fox refers to by altering my
> > initial approach in the following ways:
> >
> >  1. Instead of fitting a _linear_ model with a mock continuous response
> >     to each subdataset and applying *vif() *to that, we fit to each
> >     subdataset an actual binary GLM with a real pairing of two response
> >     categories as LHS.
> >  2. Instead of fitting only C-1 binary sub-GLMs for which to calculate
> >     GVIF diagnostics, we fit *choose(C, 2) *such submodels, i.e. _one
> >     for every possible pairing of response categories_.
> >  3. Finally, for each coefficient, we average the GVIF statistic over
> >     the *choose(C, 2)* submodels in order to obtain a summary statistic.
> >
> > What do you gentlemen think?
>
> This ad-hoc solution doesn't seem to me a good idea. The starting point
> should be a criterion for what should be invariant with respect to
> reparametrizations of the LHS of the model that leave the fitted
> probabilities unchanged. I think that it would be natural to require
> that the relative sizes of the joint confidence regions for all of the
> coefficients of a term in the data and the utopian data be invariant.
>
> I don't know the answer to the question posed in this manner, but I
> suspect that it is the application of the formula for the GVIF to the
> subset of coefficients representing the term in question for all of the
> levels of the response in an arbitrary parametrization.
>
> I may think about this a bit more when I have some time.
>
> Best,
>   John
>
> >
> > Best,
> >
> > Juho
> >
> >
> >
> > pe 25. helmik. 2022 klo 19.40 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Juhu,
> >
> >     Apologies for my slow response -- I had a busy morning.
> >
> >     I hadn't thought about generalizing VIFs to multinomial regression
> >     models, and I haven't thought the question through now, but I don't
> >     think that what you propose makes sense.
> >
> >     For a linear model, the vif() function in the car packages computes
> >     generalized VIFs, as proposed by Fox and Monette in the paper
> >     referenced
> >     in ?vif. That is, for the linear model y ~ 1 + X, where X is a
> >     matrix of
> >     regressors, the generalized VIF associated with the regression
> >     coefficients for a column subset of X, say X_j, is GVIF_j = det
> R_{jj}
> >     det R_{-j, -j}/det R, which is interpretable as the size
> (hypervolume)
> >     of a confidence ellipsoid for the coefficients of X_j relative to the
> >     size of the confidence ellipsoid for similar "utopian" data in which
> >     X_j
> >     and X_{-j} are uncorrelated. Here, det R_{jj} is the determinant of
> the
> >     correlation matrix among the columns of X_j, det R_{-j, -j} is the
> >     determinant of the correlation matrix among the remaining columns of
> X,
> >     and det R is the correlation matrix among all of the columns of X.
> >
> >     This has the nice property that the bases for the subspaces spanned
> by
> >     the columns of X_j and X_{-j} are irrelevant, and thus, e.g., it
> >     doesn't
> >     matter what kind of contrasts one uses for a factor. Also when X_j is
> >     just one column of X, the GVIF specializes to the usual VIF.
> >
> >     Actually, vif() uses the correlation matrix of the coefficients
> R_{bb}
> >     rather than the correlations of the variables R, but that turns out
> to
> >     be equivalent, and also suggests a generalization to other regression
> >     models, such as GLMs. More generally, however (that is, beyond linear
> >     models), the correlations of the coefficients involve y as well as X,
> >     and so there's some slippage in interpretation -- now the utopian
> data
> >     are no longer necessarily for uncorrelated Xs. This is true as well
> for
> >     some other diagnostics generalized beyond linear models, such as
> >     hatvalues, which, e.g., for GLMs, depend on the ys as well as the Xs.
> >
> >     Analogously, in generalizing GVIFs further to a model such as a
> >     multinomial regression one would want a result that doesn't depend on
> >     the arbitrary parametrization of the LHS of the model -- for example,
> >     which level of the response is taken as the reference level. As I
> said,
> >     I haven't tried to think that through, but your solution isn't
> >     invariant
> >     in this way.
> >
> >     I hope this helps,
> >        John
> >
> >     On 2022-02-25 3:23 a.m., Juho Kristian Ruohonen wrote:
> >      > Dear John (and anyone else qualified to comment),
> >      >
> >      > I fit lots of mixed-effects multinomial models in my research,
> and I
> >      > would like to see some (multi)collinearity diagnostics on the
> fixed
> >      > effects, of which there are over 30. My models are fit using the
> >      > Bayesian *brms* package because I know of no frequentist packages
> >     with
> >      > multinomial GLMM compatibility.
> >      >
> >      > With continuous or dichotomous outcomes, my go-to function for
> >      > calculating multicollinearity diagnostics is of course *vif()*
> >     from the
> >      > /car/ package. As expected, however, this function does not report
> >      > sensible diagnostics for multinomial models -- not even for
> standard
> >      > ones fit by the /nnet/ package's *multinom()* function. The
> >     reason, I
> >      > presume, is because a multinomial model is not really one but C-1
> >      > regression models  (where C is the number of response categories)
> >     and
> >      > the *vif()* function is not designed to deal with this scenario.
> >      >
> >      > Therefore, in order to obtain meaningful collinearity metrics, my
> >      > present plan is to write a simple helper function that uses
> >     *vif() *to
> >      > calculate and present (generalized) variance inflation metrics
> >     for the
> >      > C-1 sub-datasets to which the C-1 component binomial models of the
> >      > overall multinomial model are fit. In other words, it will
> >     partition the
> >      > data into those C-1 subsets, and then apply *vif()* to as many
> >     linear
> >      > regressions using a made-up continuous response and the fixed
> >     effects of
> >      > interest.
> >      >
> >      > Does this seem like a sensible approach?
> >      >
> >      > Best,
> >      >
> >      > Juho
> >      >
> >      >
> >      >
> >      >
> >      > ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
> >      >
> >      >     Dear Simon,
> >      >
> >      >     I believe that Russ's point is that the fact that the
> >     additive model
> >      >     allows you to estimate nonsensical quantities like a mean for
> >     girls in
> >      >     all-boys' schools implies a problem with the model. Why not
> >     do as I
> >      >     suggested and define two dichotomous factors: sex of student
> >      >     (male/female) and type of school (coed, same-sex)? The four
> >      >     combinations
> >      >     of levels then make sense.
> >      >
> >      >     Best,
> >      >        John
> >      >
> >      >     On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> >      >      > Thanks, Russ! There is one thing that I still don't
> >     understand. We
> >      >      > have two completely empty cells (boys in girl-only & girls
> in
> >      >     boy-only
> >      >      > schools). Then, how are the means of those empty cells
> >     computed (what
> >      >      > data is used in their place in the additive model)?
> >      >      >
> >      >      > Let's' simplify the model for clarity:
> >      >      >
> >      >      > library(R2MLwiN)
> >      >      > library(emmeans)
> >      >      >
> >      >      > Form3 <- normexam ~ schgend + sex ## + standlrt +
> >     (standlrt | school)
> >      >      > model3 <- lm(Form3, data = tutorial)
> >      >      >
> >      >      > emmeans(model3, pairwise~sex+schgend)$emmeans
> >      >      >
> >      >      >   sex  schgend   emmean     SE   df lower.CL upper.CL
> >      >      >   boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
> >      >      >   girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
> >      >      >   boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
> >      >      >   girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how
> >     computed?
> >      >      >   boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how
> >     computed?
> >      >      >   girl girlsch   0.1460 0.0267 4055   0.0938  0.19829
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> >      >      > <russell-lenth at uiowa.edu <mailto:russell-lenth at uiowa.edu>
> >     <mailto:russell-lenth at uiowa.edu <mailto:russell-lenth at uiowa.edu>>>
> >     wrote:
> >      >      >>
> >      >      >> By the way, returning to the topic of interpreting
> >     coefficients,
> >      >     you ought to have fun with the ones from the model I just
> fitted:
> >      >      >>
> >      >      >> Fixed effects:
> >      >      >>                 Estimate Std. Error t value
> >      >      >> (Intercept)    -0.18882    0.05135  -3.677
> >      >      >> standlrt        0.55442    0.01994  27.807
> >      >      >> schgendboysch   0.17986    0.09915   1.814
> >      >      >> schgendgirlsch  0.17482    0.07877   2.219
> >      >      >> sexgirl         0.16826    0.03382   4.975
> >      >      >>
> >      >      >> One curious thing you'll notice is that there are no
> >      >     coefficients for the interaction terms. Why? Because those
> terms
> >      >     were "thrown out" of the model, and so they are not shown. I
> >     think
> >      >     it is unwise to not show what was thrown out (e.g., lm would
> have
> >      >     shown them as NAs), because in fact what we see is but one of
> >      >     infinitely many possible solutions to the regression
> >     equations. This
> >      >     is the solution where the last two coefficients are
> >     constrained to
> >      >     zero. There is another equally reasonable one where the
> >     coefficients
> >      >     for schgendboysch and schgendgirlsch  are constrained to
> >     zero, and
> >      >     the two interaction effects would then be non-zero. And
> >     infinitely
> >      >     more where all 7 coefficients are non-zero, and there are two
> >     linear
> >      >     constraints among them.
> >      >      >>
> >      >      >> Of course, since the particular estimate shown consists
> >     of all
> >      >     the main effects and interactions are constrained to zero, it
> >     does
> >      >     demonstrate that the additive model *could* have been used to
> >     obtain
> >      >     the same estimates and standard errors, and you can see that
> by
> >      >     comparing the results (and ignoring the invalid ones from the
> >      >     additive model). But it is just a lucky coincidence that it
> >     worked
> >      >     out this way, and the additive model did lead us down a
> primrose
> >      >     path containing silly results among the correct ones.
> >      >      >>
> >      >      >> Russ
> >      >      >>
> >      >      >> -----Original Message-----
> >      >      >> From: Lenth, Russell V
> >      >      >> Sent: Sunday, September 26, 2021 7:43 PM
> >      >      >> To: Simon Harmel <sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com>
> >      >     <mailto:sim.harmel at gmail.com <mailto:sim.harmel at gmail.com>>>
> >      >      >> Cc: r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >> Subject: RE: [External] Re: [R-sig-ME] Help with
> interpreting
> >      >     one fixed-effect coefficient
> >      >      >>
> >      >      >> I guess correctness is in the eyes of the beholder. But I
> >     think
> >      >     this illustrates the folly of the additive model. Having
> additive
> >      >     effects suggests a belief that you can vary one factor more
> >     or less
> >      >     independently of the other. In his comments, John Fox makes a
> >     good
> >      >     point that escaped my earlier cursory view of the original
> >     question,
> >      >     that you don't have data on girls attending all-boys'
> >     schools, nor
> >      >     boys attending all-girls' schools; yet the model that was
> fitted
> >      >     estimates a mean response for both those situations. That's a
> >     pretty
> >      >     clear testament to the failure of that model ? and also why
> the
> >      >     coefficients don't make sense. And finally why we have
> >     estimates of
> >      >     15 comparisons (some of which are aliased with one another),
> when
> >      >     only 6 of them make sense.
> >      >      >>
> >      >      >> If instead, a model with interaction were fitted, it
> >     would be a
> >      >     rank-deficient model because two cells are empty. Perhaps
> >     there is
> >      >     some sort of nesting structure that could be used to work
> around
> >      >     that. However, it doesn't matter much because emmeans assesses
> >      >     estimability, and the two combinations I mentioned above
> would be
> >      >     flagged as non-estimable. One could then more judiciously use
> the
> >      >     contrast function to test meaningful contrasts across this
> >     irregular
> >      >     array of cell means. Or even injudiciously asking for all
> >     pairwise
> >      >     comparisons, you will see 6 estimable ones and 9
> >     non-estimable ones.
> >      >     See output below.
> >      >      >>
> >      >      >> Russ
> >      >      >>
> >      >      >> ----- Interactive model -----
> >      >      >>
> >      >      >>> Form <- normexam ~ 1 + standlrt + schgend * sex +
> >     (standlrt |
> >      >     school)
> >      >      >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> >      >      >> fixed-effect model matrix is rank deficient so dropping 2
> >      >     columns / coefficients
> >      >      >>>
> >      >      >>> emmeans(model, pairwise~schgend+sex)
> >      >      >>
> >      >      >> ... messages deleted ...
> >      >      >>
> >      >      >> $emmeans
> >      >      >>   schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
> >      >      >>   mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
> >      >      >>   boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
> >      >      >>   girlsch  boy    nonEst     NA  NA        NA        NA
> >      >      >>   mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
> >      >      >>   boysch   girl   nonEst     NA  NA        NA        NA
> >      >      >>   girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> >      >      >>
> >      >      >> Degrees-of-freedom method: asymptotic
> >      >      >> Confidence level used: 0.95
> >      >      >>
> >      >      >> $contrasts
> >      >      >>   contrast                     estimate     SE  df
> >     z.ratio p.value
> >      >      >>   mixedsch boy - boysch boy     -0.1799 0.0991 Inf
> >     -1.814  0.4565
> >      >      >>   mixedsch boy - girlsch boy     nonEst     NA  NA
> >     NA      NA
> >      >      >>   mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf
> >     -4.975  <.0001
> >      >      >>   mixedsch boy - boysch girl     nonEst     NA  NA
> >     NA      NA
> >      >      >>   mixedsch boy - girlsch girl   -0.3431 0.0780 Inf
> >     -4.396  0.0002
> >      >      >>   boysch boy - girlsch boy       nonEst     NA  NA
> >     NA      NA
> >      >      >>   boysch boy - mixedsch girl     0.0116 0.0997 Inf
> >       0.116  1.0000
> >      >      >>   boysch boy - boysch girl       nonEst     NA  NA
> >     NA      NA
> >      >      >>   boysch boy - girlsch girl     -0.1632 0.1058 Inf
> >     -1.543  0.6361
> >      >      >>   girlsch boy - mixedsch girl    nonEst     NA  NA
> >     NA      NA
> >      >      >>   girlsch boy - boysch girl      nonEst     NA  NA
> >     NA      NA
> >      >      >>   girlsch boy - girlsch girl     nonEst     NA  NA
> >     NA      NA
> >      >      >>   mixedsch girl - boysch girl    nonEst     NA  NA
> >     NA      NA
> >      >      >>   mixedsch girl - girlsch girl  -0.1748 0.0788 Inf
> >     -2.219  0.2287
> >      >      >>   boysch girl - girlsch girl     nonEst     NA  NA
> >     NA      NA
> >      >      >>
> >      >      >> Degrees-of-freedom method: asymptotic
> >      >      >> P value adjustment: tukey method for comparing a family
> of 6
> >      >     estimates
> >      >      >>
> >      >      >>
> >      >      >> ---------------------------------------------------------
> >      >      >> From: Simon Harmel <sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com>
> >      >     <mailto:sim.harmel at gmail.com <mailto:sim.harmel at gmail.com>>>
> >      >      >> Sent: Sunday, September 26, 2021 3:08 PM
> >      >      >> To: Lenth, Russell V <russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu>
> >      >     <mailto:russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu>>>
> >      >      >> Cc: r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >> Subject: [External] Re: [R-sig-ME] Help with interpreting
> one
> >      >     fixed-effect coefficient
> >      >      >>
> >      >      >> Dear Russ and the List Members,
> >      >      >>
> >      >      >> If we use Russ' great package (emmeans), we see that
> although
> >      >     meaningless, but "schgendgirl-only" can be interpreted using
> the
> >      >     logic I mentioned here:
> >      >
> >     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html
> >     <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html>
> >      >
> >       <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html>> .
> >      >      >>
> >      >      >> That is, "schgendgirl-only" can meaninglessly mean:
> ***diff.
> >      >     bet. boys in girl-only vs. mixed schools*** just like it can
> >      >     meaningfully mean:  ***diff. bet. girls in girl-only vs. mixed
> >      >     schools***
> >      >      >>
> >      >      >> Russ, have I used emmeans correctly?
> >      >      >>
> >      >      >> Simon
> >      >      >>
> >      >      >> Here is a reproducible code:
> >      >      >>
> >      >      >> library(R2MLwiN) # For the dataset
> >      >      >> library(lme4)
> >      >      >> library(emmeans)
> >      >      >>
> >      >      >> data("tutorial")
> >      >      >>
> >      >      >> Form <- normexam ~ 1 + standlrt + schgend + sex +
> (standlrt |
> >      >     school)
> >      >      >> model <- lmer(Form, data = tutorial, REML = FALSE)
> >      >      >>
> >      >      >> emmeans(model, pairwise~schgend+sex)$contrast
> >      >      >>
> >      >      >> contrast                     estimate     SE  df z.ratio
> >     p.value
> >      >      >> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814
> >     0.4565
> >      >      >> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219
> >     0.2287
> >      >       <--This coef. equals
> >      >      >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975
> >     <.0001
> >      >      >> mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178
> >     0.0186
> >      >      >> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396
> >     0.0002
> >      >      >> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045
> >     1.0000
> >      >      >> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116
> >     1.0000
> >      >      >> boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975
> >     <.0001
> >      >      >> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543
> >     0.6361
> >      >      >> girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071
> >     1.0000
> >      >      >> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381
> >     0.7388
> >      >      >> girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975
> >     <.0001
> >      >      >> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814
> >     0.4565
> >      >      >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219
> >     0.2287
> >      >       <--This coef.
> >      >      >> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045
> >     1.0000
> >      >      >>
> >      >      >>
> >      >      >
> >      >      > _______________________________________________
> >      >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >      >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >      >     --
> >      >     John Fox, Professor Emeritus
> >      >     McMaster University
> >      >     Hamilton, Ontario, Canada
> >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >
> >      >     _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Feb 26 16:36:56 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 26 Feb 2022 10:36:56 -0500
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAG_dBVd4_zsWReefSdrhKH8XXn9Lb2p-ecFBxk9DEWmQTuU+5g@mail.gmail.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
 <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
 <63b44aed-cfcf-cfc3-99ba-fc7e7c85a0fb@mcmaster.ca>
 <CAG_dBVe+Ovcae-RoDWRz8cDJLTQx3aLZ9ZZ8Debkz0V3xud5Zw@mail.gmail.com>
 <66ad680e-e531-f948-3cc6-c68250636ac9@mcmaster.ca>
 <CAG_dBVd4_zsWReefSdrhKH8XXn9Lb2p-ecFBxk9DEWmQTuU+5g@mail.gmail.com>
Message-ID: <7d8ed440-691f-d831-2e57-5081eac837de@mcmaster.ca>

Dear Juho,

On 2022-02-26 2:15 a.m., Juho Kristian Ruohonen wrote:
> Many thanks, John. This is rather unfortunate news as it leaves me with 
> no way to present statistics on the degree to which my multinomial 
> models are affected by collinearity. But it's good to hear it directly 
> from a consummate expert.

First, thank you for the compliment.

Your conclusion is probably pessimistic. In my experience, collinearity 
problems are relatively rare -- do you have a reason to believe that you 
have a collinearity problem? Also, as an approximation, you'd likely do 
well just to look at the VIFs or GVIFs based only on the model matrix, 
as would be appropriate for a linear model.

Best,
  John

> 
> Best,
> 
> Juho
> 
> 
> la 26. helmik. 2022 klo 1.16 John Fox (jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>) kirjoitti:
> 
>     Dear Juho,
> 
>     For some reason, my previous response to you (shown below your most
>     recent message) doesn't seem to have made it to the list. Let's hope
>     that this reply does:
> 
>     On 2022-02-25 2:52 p.m., Juho Kristian Ruohonen wrote:
>      > Dear John (Fox, and other list members),
>      >
>      > Could we achieve the invariance Professor Fox refers to by
>     altering my
>      > initial approach in the following ways:
>      >
>      >? 1. Instead of fitting a _linear_ model with a mock continuous
>     response
>      >? ? ?to each subdataset and applying *vif() *to that, we fit to each
>      >? ? ?subdataset an actual binary GLM with a real pairing of two
>     response
>      >? ? ?categories as LHS.
>      >? 2. Instead of fitting only C-1 binary sub-GLMs for which to
>     calculate
>      >? ? ?GVIF diagnostics, we fit *choose(C, 2) *such submodels, i.e. _one
>      >? ? ?for every possible pairing of response categories_.
>      >? 3. Finally, for each coefficient, we average the GVIF statistic over
>      >? ? ?the *choose(C, 2)* submodels in order to obtain a summary
>     statistic.
>      >
>      > What do you gentlemen think?
> 
>     This ad-hoc solution doesn't seem to me a good idea. The starting point
>     should be a criterion for what should be invariant with respect to
>     reparametrizations of the LHS of the model that leave the fitted
>     probabilities unchanged. I think that it would be natural to require
>     that the relative sizes of the joint confidence regions for all of the
>     coefficients of a term in the data and the utopian data be invariant.
> 
>     I don't know the answer to the question posed in this manner, but I
>     suspect that it is the application of the formula for the GVIF to the
>     subset of coefficients representing the term in question for all of the
>     levels of the response in an arbitrary parametrization.
> 
>     I may think about this a bit more when I have some time.
> 
>     Best,
>      ? John
> 
>      >
>      > Best,
>      >
>      > Juho
>      >
>      >
>      >
>      > pe 25. helmik. 2022 klo 19.40 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
>      >
>      >? ? ?Dear Juhu,
>      >
>      >? ? ?Apologies for my slow response -- I had a busy morning.
>      >
>      >? ? ?I hadn't thought about generalizing VIFs to multinomial
>     regression
>      >? ? ?models, and I haven't thought the question through now, but I
>     don't
>      >? ? ?think that what you propose makes sense.
>      >
>      >? ? ?For a linear model, the vif() function in the car packages
>     computes
>      >? ? ?generalized VIFs, as proposed by Fox and Monette in the paper
>      >? ? ?referenced
>      >? ? ?in ?vif. That is, for the linear model y ~ 1 + X, where X is a
>      >? ? ?matrix of
>      >? ? ?regressors, the generalized VIF associated with the regression
>      >? ? ?coefficients for a column subset of X, say X_j, is GVIF_j =
>     det R_{jj}
>      >? ? ?det R_{-j, -j}/det R, which is interpretable as the size
>     (hypervolume)
>      >? ? ?of a confidence ellipsoid for the coefficients of X_j
>     relative to the
>      >? ? ?size of the confidence ellipsoid for similar "utopian" data
>     in which
>      >? ? ?X_j
>      >? ? ?and X_{-j} are uncorrelated. Here, det R_{jj} is the
>     determinant of the
>      >? ? ?correlation matrix among the columns of X_j, det R_{-j, -j}
>     is the
>      >? ? ?determinant of the correlation matrix among the remaining
>     columns of X,
>      >? ? ?and det R is the correlation matrix among all of the columns
>     of X.
>      >
>      >? ? ?This has the nice property that the bases for the subspaces
>     spanned by
>      >? ? ?the columns of X_j and X_{-j} are irrelevant, and thus, e.g., it
>      >? ? ?doesn't
>      >? ? ?matter what kind of contrasts one uses for a factor. Also
>     when X_j is
>      >? ? ?just one column of X, the GVIF specializes to the usual VIF.
>      >
>      >? ? ?Actually, vif() uses the correlation matrix of the
>     coefficients R_{bb}
>      >? ? ?rather than the correlations of the variables R, but that
>     turns out to
>      >? ? ?be equivalent, and also suggests a generalization to other
>     regression
>      >? ? ?models, such as GLMs. More generally, however (that is,
>     beyond linear
>      >? ? ?models), the correlations of the coefficients involve y as
>     well as X,
>      >? ? ?and so there's some slippage in interpretation -- now the
>     utopian data
>      >? ? ?are no longer necessarily for uncorrelated Xs. This is true
>     as well for
>      >? ? ?some other diagnostics generalized beyond linear models, such as
>      >? ? ?hatvalues, which, e.g., for GLMs, depend on the ys as well as
>     the Xs.
>      >
>      >? ? ?Analogously, in generalizing GVIFs further to a model such as a
>      >? ? ?multinomial regression one would want a result that doesn't
>     depend on
>      >? ? ?the arbitrary parametrization of the LHS of the model -- for
>     example,
>      >? ? ?which level of the response is taken as the reference level.
>     As I said,
>      >? ? ?I haven't tried to think that through, but your solution isn't
>      >? ? ?invariant
>      >? ? ?in this way.
>      >
>      >? ? ?I hope this helps,
>      >? ? ? ? John
>      >
>      >? ? ?On 2022-02-25 3:23 a.m., Juho Kristian Ruohonen wrote:
>      >? ? ? > Dear John (and anyone else qualified to comment),
>      >? ? ? >
>      >? ? ? > I fit lots of mixed-effects multinomial models in my
>     research, and I
>      >? ? ? > would like to see some (multi)collinearity diagnostics on
>     the fixed
>      >? ? ? > effects, of which there are over 30. My models are fit
>     using the
>      >? ? ? > Bayesian *brms* package because I know of no frequentist
>     packages
>      >? ? ?with
>      >? ? ? > multinomial GLMM compatibility.
>      >? ? ? >
>      >? ? ? > With continuous or dichotomous outcomes, my go-to function for
>      >? ? ? > calculating multicollinearity diagnostics is of course *vif()*
>      >? ? ?from the
>      >? ? ? > /car/ package. As expected, however, this function does
>     not report
>      >? ? ? > sensible diagnostics for multinomial models -- not even
>     for standard
>      >? ? ? > ones fit by the /nnet/ package's *multinom()* function. The
>      >? ? ?reason, I
>      >? ? ? > presume, is because a multinomial model is not really one
>     but C-1
>      >? ? ? > regression models? (where C is the number of response
>     categories)
>      >? ? ?and
>      >? ? ? > the *vif()* function is not designed to deal with this
>     scenario.
>      >? ? ? >
>      >? ? ? > Therefore, in order to obtain meaningful collinearity
>     metrics, my
>      >? ? ? > present plan is to write a simple helper function that uses
>      >? ? ?*vif() *to
>      >? ? ? > calculate and present (generalized) variance inflation metrics
>      >? ? ?for the
>      >? ? ? > C-1 sub-datasets to which the C-1 component binomial
>     models of the
>      >? ? ? > overall multinomial model are fit. In other words, it will
>      >? ? ?partition the
>      >? ? ? > data into those C-1 subsets, and then apply *vif()* to as many
>      >? ? ?linear
>      >? ? ? > regressions using a made-up continuous response and the fixed
>      >? ? ?effects of
>      >? ? ? > interest.
>      >? ? ? >
>      >? ? ? > Does this seem like a sensible approach?
>      >? ? ? >
>      >? ? ? > Best,
>      >? ? ? >
>      >? ? ? > Juho
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
>      >? ? ? >
>      >? ? ? >? ? ?Dear Simon,
>      >? ? ? >
>      >? ? ? >? ? ?I believe that Russ's point is that the fact that the
>      >? ? ?additive model
>      >? ? ? >? ? ?allows you to estimate nonsensical quantities like a
>     mean for
>      >? ? ?girls in
>      >? ? ? >? ? ?all-boys' schools implies a problem with the model.
>     Why not
>      >? ? ?do as I
>      >? ? ? >? ? ?suggested and define two dichotomous factors: sex of
>     student
>      >? ? ? >? ? ?(male/female) and type of school (coed, same-sex)? The
>     four
>      >? ? ? >? ? ?combinations
>      >? ? ? >? ? ?of levels then make sense.
>      >? ? ? >
>      >? ? ? >? ? ?Best,
>      >? ? ? >? ? ? ? John
>      >? ? ? >
>      >? ? ? >? ? ?On 2021-09-27 12:09 p.m., Simon Harmel wrote:
>      >? ? ? >? ? ? > Thanks, Russ! There is one thing that I still don't
>      >? ? ?understand. We
>      >? ? ? >? ? ? > have two completely empty cells (boys in girl-only
>     & girls in
>      >? ? ? >? ? ?boy-only
>      >? ? ? >? ? ? > schools). Then, how are the means of those empty cells
>      >? ? ?computed (what
>      >? ? ? >? ? ? > data is used in their place in the additive model)?
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Let's' simplify the model for clarity:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > library(R2MLwiN)
>      >? ? ? >? ? ? > library(emmeans)
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Form3 <- normexam ~ schgend + sex ## + standlrt +
>      >? ? ?(standlrt | school)
>      >? ? ? >? ? ? > model3 <- lm(Form3, data = tutorial)
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > emmeans(model3, pairwise~sex+schgend)$emmeans
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ?sex? schgend? ?emmean? ? ?SE? ?df lower.CL upper.CL
>      >? ? ? >? ? ? >? ?boy? mixedsch -0.2160 0.0297 4055? -0.2742 -0.15780
>      >? ? ? >? ? ? >? ?girl mixedsch? 0.0248 0.0304 4055? -0.0348? 0.08437
>      >? ? ? >? ? ? >? ?boy? boysch? ? 0.0234 0.0437 4055? -0.0623? 0.10897
>      >? ? ? >? ? ? >? ?girl boysch? ? 0.2641 0.0609 4055? ?0.1447 
>     0.38360<-how
>      >? ? ?computed?
>      >? ? ? >? ? ? >? ?boy? girlsch? -0.0948 0.0502 4055? -0.1931 
>     0.00358<-how
>      >? ? ?computed?
>      >? ? ? >? ? ? >? ?girl girlsch? ?0.1460 0.0267 4055? ?0.0938? 0.19829
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
>      >? ? ? >? ? ? > <russell-lenth at uiowa.edu
>     <mailto:russell-lenth at uiowa.edu> <mailto:russell-lenth at uiowa.edu
>     <mailto:russell-lenth at uiowa.edu>>
>      >? ? ?<mailto:russell-lenth at uiowa.edu
>     <mailto:russell-lenth at uiowa.edu> <mailto:russell-lenth at uiowa.edu
>     <mailto:russell-lenth at uiowa.edu>>>>
>      >? ? ?wrote:
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> By the way, returning to the topic of interpreting
>      >? ? ?coefficients,
>      >? ? ? >? ? ?you ought to have fun with the ones from the model I
>     just fitted:
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Fixed effects:
>      >? ? ? >? ? ? >>? ? ? ? ? ? ? ? ?Estimate Std. Error t value
>      >? ? ? >? ? ? >> (Intercept)? ? -0.18882? ? 0.05135? -3.677
>      >? ? ? >? ? ? >> standlrt? ? ? ? 0.55442? ? 0.01994? 27.807
>      >? ? ? >? ? ? >> schgendboysch? ?0.17986? ? 0.09915? ?1.814
>      >? ? ? >? ? ? >> schgendgirlsch? 0.17482? ? 0.07877? ?2.219
>      >? ? ? >? ? ? >> sexgirl? ? ? ? ?0.16826? ? 0.03382? ?4.975
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> One curious thing you'll notice is that there are no
>      >? ? ? >? ? ?coefficients for the interaction terms. Why? Because
>     those terms
>      >? ? ? >? ? ?were "thrown out" of the model, and so they are not
>     shown. I
>      >? ? ?think
>      >? ? ? >? ? ?it is unwise to not show what was thrown out (e.g., lm
>     would have
>      >? ? ? >? ? ?shown them as NAs), because in fact what we see is but
>     one of
>      >? ? ? >? ? ?infinitely many possible solutions to the regression
>      >? ? ?equations. This
>      >? ? ? >? ? ?is the solution where the last two coefficients are
>      >? ? ?constrained to
>      >? ? ? >? ? ?zero. There is another equally reasonable one where the
>      >? ? ?coefficients
>      >? ? ? >? ? ?for schgendboysch and schgendgirlsch? are constrained to
>      >? ? ?zero, and
>      >? ? ? >? ? ?the two interaction effects would then be non-zero. And
>      >? ? ?infinitely
>      >? ? ? >? ? ?more where all 7 coefficients are non-zero, and there
>     are two
>      >? ? ?linear
>      >? ? ? >? ? ?constraints among them.
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Of course, since the particular estimate shown
>     consists
>      >? ? ?of all
>      >? ? ? >? ? ?the main effects and interactions are constrained to
>     zero, it
>      >? ? ?does
>      >? ? ? >? ? ?demonstrate that the additive model *could* have been
>     used to
>      >? ? ?obtain
>      >? ? ? >? ? ?the same estimates and standard errors, and you can
>     see that by
>      >? ? ? >? ? ?comparing the results (and ignoring the invalid ones
>     from the
>      >? ? ? >? ? ?additive model). But it is just a lucky coincidence
>     that it
>      >? ? ?worked
>      >? ? ? >? ? ?out this way, and the additive model did lead us down
>     a primrose
>      >? ? ? >? ? ?path containing silly results among the correct ones.
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Russ
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> -----Original Message-----
>      >? ? ? >? ? ? >> From: Lenth, Russell V
>      >? ? ? >? ? ? >> Sent: Sunday, September 26, 2021 7:43 PM
>      >? ? ? >? ? ? >> To: Simon Harmel <sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com>
>      >? ? ?<mailto:sim.harmel at gmail.com <mailto:sim.harmel at gmail.com>>
>      >? ? ? >? ? ?<mailto:sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com> <mailto:sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com>>>>
>      >? ? ? >? ? ? >> Cc: r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >> Subject: RE: [External] Re: [R-sig-ME] Help with
>     interpreting
>      >? ? ? >? ? ?one fixed-effect coefficient
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> I guess correctness is in the eyes of the
>     beholder. But I
>      >? ? ?think
>      >? ? ? >? ? ?this illustrates the folly of the additive model.
>     Having additive
>      >? ? ? >? ? ?effects suggests a belief that you can vary one factor
>     more
>      >? ? ?or less
>      >? ? ? >? ? ?independently of the other. In his comments, John Fox
>     makes a
>      >? ? ?good
>      >? ? ? >? ? ?point that escaped my earlier cursory view of the original
>      >? ? ?question,
>      >? ? ? >? ? ?that you don't have data on girls attending all-boys'
>      >? ? ?schools, nor
>      >? ? ? >? ? ?boys attending all-girls' schools; yet the model that
>     was fitted
>      >? ? ? >? ? ?estimates a mean response for both those situations.
>     That's a
>      >? ? ?pretty
>      >? ? ? >? ? ?clear testament to the failure of that model ? and
>     also why the
>      >? ? ? >? ? ?coefficients don't make sense. And finally why we have
>      >? ? ?estimates of
>      >? ? ? >? ? ?15 comparisons (some of which are aliased with one
>     another), when
>      >? ? ? >? ? ?only 6 of them make sense.
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> If instead, a model with interaction were fitted, it
>      >? ? ?would be a
>      >? ? ? >? ? ?rank-deficient model because two cells are empty. Perhaps
>      >? ? ?there is
>      >? ? ? >? ? ?some sort of nesting structure that could be used to
>     work around
>      >? ? ? >? ? ?that. However, it doesn't matter much because emmeans
>     assesses
>      >? ? ? >? ? ?estimability, and the two combinations I mentioned
>     above would be
>      >? ? ? >? ? ?flagged as non-estimable. One could then more
>     judiciously use the
>      >? ? ? >? ? ?contrast function to test meaningful contrasts across this
>      >? ? ?irregular
>      >? ? ? >? ? ?array of cell means. Or even injudiciously asking for all
>      >? ? ?pairwise
>      >? ? ? >? ? ?comparisons, you will see 6 estimable ones and 9
>      >? ? ?non-estimable ones.
>      >? ? ? >? ? ?See output below.
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Russ
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> ----- Interactive model -----
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >>> Form <- normexam ~ 1 + standlrt + schgend * sex +
>      >? ? ?(standlrt |
>      >? ? ? >? ? ?school)
>      >? ? ? >? ? ? >>> model <- lmer(Form, data = tutorial, REML = FALSE)
>      >? ? ? >? ? ? >> fixed-effect model matrix is rank deficient so
>     dropping 2
>      >? ? ? >? ? ?columns / coefficients
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> emmeans(model, pairwise~schgend+sex)
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> ... messages deleted ...
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> $emmeans
>      >? ? ? >? ? ? >>? ?schgend? sex? ? emmean? ? ?SE? df asymp.LCL
>     asymp.UCL
>      >? ? ? >? ? ? >>? ?mixedsch boy? -0.18781 0.0514 Inf? ?-0.2885 
>      ?-0.0871
>      >? ? ? >? ? ? >>? ?boysch? ?boy? -0.00795 0.0880 Inf? ?-0.1805   
>     0.1646
>      >? ? ? >? ? ? >>? ?girlsch? boy? ? nonEst? ? ?NA? NA? ? ? ? NA     
>      ? NA
>      >? ? ? >? ? ? >>? ?mixedsch girl -0.01955 0.0521 Inf? ?-0.1216   
>     0.0825
>      >? ? ? >? ? ? >>? ?boysch? ?girl? ?nonEst? ? ?NA? NA? ? ? ? NA     
>      ? NA
>      >? ? ? >? ? ? >>? ?girlsch? girl? 0.15527 0.0632 Inf? ? 0.0313   
>     0.2792
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Degrees-of-freedom method: asymptotic
>      >? ? ? >? ? ? >> Confidence level used: 0.95
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> $contrasts
>      >? ? ? >? ? ? >>? ?contrast? ? ? ? ? ? ? ? ? ? ?estimate? ? ?SE? df
>      >? ? ?z.ratio p.value
>      >? ? ? >? ? ? >>? ?mixedsch boy - boysch boy? ? ?-0.1799 0.0991 Inf
>      >? ? ?-1.814? 0.4565
>      >? ? ? >? ? ? >>? ?mixedsch boy - girlsch boy? ? ?nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>? ?mixedsch boy - mixedsch girl? -0.1683 0.0338 Inf
>      >? ? ?-4.975? <.0001
>      >? ? ? >? ? ? >>? ?mixedsch boy - boysch girl? ? ?nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>? ?mixedsch boy - girlsch girl? ?-0.3431 0.0780 Inf
>      >? ? ?-4.396? 0.0002
>      >? ? ? >? ? ? >>? ?boysch boy - girlsch boy? ? ? ?nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>? ?boysch boy - mixedsch girl? ? ?0.0116 0.0997 Inf
>      >? ? ? ?0.116? 1.0000
>      >? ? ? >? ? ? >>? ?boysch boy - boysch girl? ? ? ?nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>? ?boysch boy - girlsch girl? ? ?-0.1632 0.1058 Inf
>      >? ? ?-1.543? 0.6361
>      >? ? ? >? ? ? >>? ?girlsch boy - mixedsch girl? ? nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>? ?girlsch boy - boysch girl? ? ? nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>? ?girlsch boy - girlsch girl? ? ?nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>? ?mixedsch girl - boysch girl? ? nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>? ?mixedsch girl - girlsch girl? -0.1748 0.0788 Inf
>      >? ? ?-2.219? 0.2287
>      >? ? ? >? ? ? >>? ?boysch girl - girlsch girl? ? ?nonEst? ? ?NA? NA
>      >? ? ?NA? ? ? NA
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Degrees-of-freedom method: asymptotic
>      >? ? ? >? ? ? >> P value adjustment: tukey method for comparing a
>     family of 6
>      >? ? ? >? ? ?estimates
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >>
>     ---------------------------------------------------------
>      >? ? ? >? ? ? >> From: Simon Harmel <sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com>
>      >? ? ?<mailto:sim.harmel at gmail.com <mailto:sim.harmel at gmail.com>>
>      >? ? ? >? ? ?<mailto:sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com> <mailto:sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com>>>>
>      >? ? ? >? ? ? >> Sent: Sunday, September 26, 2021 3:08 PM
>      >? ? ? >? ? ? >> To: Lenth, Russell V <russell-lenth at uiowa.edu
>     <mailto:russell-lenth at uiowa.edu>
>      >? ? ?<mailto:russell-lenth at uiowa.edu <mailto:russell-lenth at uiowa.edu>>
>      >? ? ? >? ? ?<mailto:russell-lenth at uiowa.edu
>     <mailto:russell-lenth at uiowa.edu>
>      >? ? ?<mailto:russell-lenth at uiowa.edu
>     <mailto:russell-lenth at uiowa.edu>>>>
>      >? ? ? >? ? ? >> Cc: r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >> Subject: [External] Re: [R-sig-ME] Help with
>     interpreting one
>      >? ? ? >? ? ?fixed-effect coefficient
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Dear Russ and the List Members,
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> If we use Russ' great package (emmeans), we see
>     that although
>      >? ? ? >? ? ?meaningless, but "schgendgirl-only" can be interpreted
>     using the
>      >? ? ? >? ? ?logic I mentioned here:
>      >? ? ? >
>      >
>     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html
>     <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html>
>      >   
>      ?<https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html>>
>      >? ? ? >
>      >     
>      ?<https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html>>> .
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> That is, "schgendgirl-only" can meaninglessly
>     mean: ***diff.
>      >? ? ? >? ? ?bet. boys in girl-only vs. mixed schools*** just like
>     it can
>      >? ? ? >? ? ?meaningfully mean:? ***diff. bet. girls in girl-only
>     vs. mixed
>      >? ? ? >? ? ?schools***
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Russ, have I used emmeans correctly?
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Simon
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Here is a reproducible code:
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> library(R2MLwiN) # For the dataset
>      >? ? ? >? ? ? >> library(lme4)
>      >? ? ? >? ? ? >> library(emmeans)
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> data("tutorial")
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> Form <- normexam ~ 1 + standlrt + schgend + sex +
>     (standlrt |
>      >? ? ? >? ? ?school)
>      >? ? ? >? ? ? >> model <- lmer(Form, data = tutorial, REML = FALSE)
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> emmeans(model, pairwise~schgend+sex)$contrast
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> contrast? ? ? ? ? ? ? ? ? ? ?estimate? ? ?SE? df
>     z.ratio
>      >? ? ?p.value
>      >? ? ? >? ? ? >> mixedsch boy - boysch boy? ? -0.17986 0.0991 Inf
>     -1.814
>      >? ? ?0.4565
>      >? ? ? >? ? ? >> mixedsch boy - girlsch boy? ?-0.17482 0.0788 Inf
>     -2.219
>      >? ? ?0.2287
>      >? ? ? >? ? ? ?<--This coef. equals
>      >? ? ? >? ? ? >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf
>     -4.975
>      >? ? ?<.0001
>      >? ? ? >? ? ? >> mixedsch boy - boysch girl? ?-0.34813 0.1096 Inf
>     -3.178
>      >? ? ?0.0186
>      >? ? ? >? ? ? >> mixedsch boy - girlsch girl? -0.34308 0.0780 Inf
>     -4.396
>      >? ? ?0.0002
>      >? ? ? >? ? ? >> boysch boy - girlsch boy? ? ? 0.00505 0.1110 Inf 
>     0.045
>      >? ? ?1.0000
>      >? ? ? >? ? ? >> boysch boy - mixedsch girl? ? 0.01160 0.0997 Inf 
>     0.116
>      >? ? ?1.0000
>      >? ? ? >? ? ? >> boysch boy - boysch girl? ? ?-0.16826 0.0338 Inf
>     -4.975
>      >? ? ?<.0001
>      >? ? ? >? ? ? >> boysch boy - girlsch girl? ? -0.16322 0.1058 Inf
>     -1.543
>      >? ? ?0.6361
>      >? ? ? >? ? ? >> girlsch boy - mixedsch girl? ?0.00656 0.0928 Inf 
>     0.071
>      >? ? ?1.0000
>      >? ? ? >? ? ? >> girlsch boy - boysch girl? ? -0.17331 0.1255 Inf
>     -1.381
>      >? ? ?0.7388
>      >? ? ? >? ? ? >> girlsch boy - girlsch girl? ?-0.16826 0.0338 Inf
>     -4.975
>      >? ? ?<.0001
>      >? ? ? >? ? ? >> mixedsch girl - boysch girl? -0.17986 0.0991 Inf
>     -1.814
>      >? ? ?0.4565
>      >? ? ? >? ? ? >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf
>     -2.219
>      >? ? ?0.2287
>      >? ? ? >? ? ? ?<--This coef.
>      >? ? ? >? ? ? >> boysch girl - girlsch girl? ? 0.00505 0.1110 Inf 
>     0.045
>      >? ? ?1.0000
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > _______________________________________________
>      >? ? ? >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>      >? ? ? >? ? ? >
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ?--
>      >? ? ? >? ? ?John Fox, Professor Emeritus
>      >? ? ? >? ? ?McMaster University
>      >? ? ? >? ? ?Hamilton, Ontario, Canada
>      >? ? ? >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>
>      >? ? ? >
>      >? ? ? >? ? ?_______________________________________________
>      >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >
>      >? ? ?--
>      >? ? ?John Fox, Professor Emeritus
>      >? ? ?McMaster University
>      >? ? ?Hamilton, Ontario, Canada
>      >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
> 
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sat Feb 26 17:39:50 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sat, 26 Feb 2022 18:39:50 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <7d8ed440-691f-d831-2e57-5081eac837de@mcmaster.ca>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
 <CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw@mail.gmail.com>
 <63b44aed-cfcf-cfc3-99ba-fc7e7c85a0fb@mcmaster.ca>
 <CAG_dBVe+Ovcae-RoDWRz8cDJLTQx3aLZ9ZZ8Debkz0V3xud5Zw@mail.gmail.com>
 <66ad680e-e531-f948-3cc6-c68250636ac9@mcmaster.ca>
 <CAG_dBVd4_zsWReefSdrhKH8XXn9Lb2p-ecFBxk9DEWmQTuU+5g@mail.gmail.com>
 <7d8ed440-691f-d831-2e57-5081eac837de@mcmaster.ca>
Message-ID: <CAG_dBVeea6E5i8=YhaZkhfr90+ns94oH0YoyiRsrNo=P8qviGw@mail.gmail.com>

Dear John,


> In my experience, collinearity
> problems are relatively rare -- do you have a reason to believe that you
> have a collinearity problem?


This is observational linguistic data, where it is thought to be very
common. True or not, the research community expects to see the risk
acknowledged somehow.

Also, as an approximation, you'd likely do
> well just to look at the VIFs or GVIFs based only on the model matrix,
> as would be appropriate for a linear model.
>

Great, thanks a lot!

Best,

Juho


la 26. helmik. 2022 klo 17.37 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juho,
>
> On 2022-02-26 2:15 a.m., Juho Kristian Ruohonen wrote:
> > Many thanks, John. This is rather unfortunate news as it leaves me with
> > no way to present statistics on the degree to which my multinomial
> > models are affected by collinearity. But it's good to hear it directly
> > from a consummate expert.
>
> First, thank you for the compliment.
>
> Your conclusion is probably pessimistic. In my experience, collinearity
> problems are relatively rare -- do you have a reason to believe that you
> have a collinearity problem? Also, as an approximation, you'd likely do
> well just to look at the VIFs or GVIFs based only on the model matrix,
> as would be appropriate for a linear model.
>
> Best,
>   John
>
> >
> > Best,
> >
> > Juho
> >
> >
> > la 26. helmik. 2022 klo 1.16 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Juho,
> >
> >     For some reason, my previous response to you (shown below your most
> >     recent message) doesn't seem to have made it to the list. Let's hope
> >     that this reply does:
> >
> >     On 2022-02-25 2:52 p.m., Juho Kristian Ruohonen wrote:
> >      > Dear John (Fox, and other list members),
> >      >
> >      > Could we achieve the invariance Professor Fox refers to by
> >     altering my
> >      > initial approach in the following ways:
> >      >
> >      >  1. Instead of fitting a _linear_ model with a mock continuous
> >     response
> >      >     to each subdataset and applying *vif() *to that, we fit to
> each
> >      >     subdataset an actual binary GLM with a real pairing of two
> >     response
> >      >     categories as LHS.
> >      >  2. Instead of fitting only C-1 binary sub-GLMs for which to
> >     calculate
> >      >     GVIF diagnostics, we fit *choose(C, 2) *such submodels, i.e.
> _one
> >      >     for every possible pairing of response categories_.
> >      >  3. Finally, for each coefficient, we average the GVIF statistic
> over
> >      >     the *choose(C, 2)* submodels in order to obtain a summary
> >     statistic.
> >      >
> >      > What do you gentlemen think?
> >
> >     This ad-hoc solution doesn't seem to me a good idea. The starting
> point
> >     should be a criterion for what should be invariant with respect to
> >     reparametrizations of the LHS of the model that leave the fitted
> >     probabilities unchanged. I think that it would be natural to require
> >     that the relative sizes of the joint confidence regions for all of
> the
> >     coefficients of a term in the data and the utopian data be invariant.
> >
> >     I don't know the answer to the question posed in this manner, but I
> >     suspect that it is the application of the formula for the GVIF to the
> >     subset of coefficients representing the term in question for all of
> the
> >     levels of the response in an arbitrary parametrization.
> >
> >     I may think about this a bit more when I have some time.
> >
> >     Best,
> >        John
> >
> >      >
> >      > Best,
> >      >
> >      > Juho
> >      >
> >      >
> >      >
> >      > pe 25. helmik. 2022 klo 19.40 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
> >      >
> >      >     Dear Juhu,
> >      >
> >      >     Apologies for my slow response -- I had a busy morning.
> >      >
> >      >     I hadn't thought about generalizing VIFs to multinomial
> >     regression
> >      >     models, and I haven't thought the question through now, but I
> >     don't
> >      >     think that what you propose makes sense.
> >      >
> >      >     For a linear model, the vif() function in the car packages
> >     computes
> >      >     generalized VIFs, as proposed by Fox and Monette in the paper
> >      >     referenced
> >      >     in ?vif. That is, for the linear model y ~ 1 + X, where X is a
> >      >     matrix of
> >      >     regressors, the generalized VIF associated with the regression
> >      >     coefficients for a column subset of X, say X_j, is GVIF_j =
> >     det R_{jj}
> >      >     det R_{-j, -j}/det R, which is interpretable as the size
> >     (hypervolume)
> >      >     of a confidence ellipsoid for the coefficients of X_j
> >     relative to the
> >      >     size of the confidence ellipsoid for similar "utopian" data
> >     in which
> >      >     X_j
> >      >     and X_{-j} are uncorrelated. Here, det R_{jj} is the
> >     determinant of the
> >      >     correlation matrix among the columns of X_j, det R_{-j, -j}
> >     is the
> >      >     determinant of the correlation matrix among the remaining
> >     columns of X,
> >      >     and det R is the correlation matrix among all of the columns
> >     of X.
> >      >
> >      >     This has the nice property that the bases for the subspaces
> >     spanned by
> >      >     the columns of X_j and X_{-j} are irrelevant, and thus, e.g.,
> it
> >      >     doesn't
> >      >     matter what kind of contrasts one uses for a factor. Also
> >     when X_j is
> >      >     just one column of X, the GVIF specializes to the usual VIF.
> >      >
> >      >     Actually, vif() uses the correlation matrix of the
> >     coefficients R_{bb}
> >      >     rather than the correlations of the variables R, but that
> >     turns out to
> >      >     be equivalent, and also suggests a generalization to other
> >     regression
> >      >     models, such as GLMs. More generally, however (that is,
> >     beyond linear
> >      >     models), the correlations of the coefficients involve y as
> >     well as X,
> >      >     and so there's some slippage in interpretation -- now the
> >     utopian data
> >      >     are no longer necessarily for uncorrelated Xs. This is true
> >     as well for
> >      >     some other diagnostics generalized beyond linear models, such
> as
> >      >     hatvalues, which, e.g., for GLMs, depend on the ys as well as
> >     the Xs.
> >      >
> >      >     Analogously, in generalizing GVIFs further to a model such as
> a
> >      >     multinomial regression one would want a result that doesn't
> >     depend on
> >      >     the arbitrary parametrization of the LHS of the model -- for
> >     example,
> >      >     which level of the response is taken as the reference level.
> >     As I said,
> >      >     I haven't tried to think that through, but your solution isn't
> >      >     invariant
> >      >     in this way.
> >      >
> >      >     I hope this helps,
> >      >        John
> >      >
> >      >     On 2022-02-25 3:23 a.m., Juho Kristian Ruohonen wrote:
> >      >      > Dear John (and anyone else qualified to comment),
> >      >      >
> >      >      > I fit lots of mixed-effects multinomial models in my
> >     research, and I
> >      >      > would like to see some (multi)collinearity diagnostics on
> >     the fixed
> >      >      > effects, of which there are over 30. My models are fit
> >     using the
> >      >      > Bayesian *brms* package because I know of no frequentist
> >     packages
> >      >     with
> >      >      > multinomial GLMM compatibility.
> >      >      >
> >      >      > With continuous or dichotomous outcomes, my go-to function
> for
> >      >      > calculating multicollinearity diagnostics is of course
> *vif()*
> >      >     from the
> >      >      > /car/ package. As expected, however, this function does
> >     not report
> >      >      > sensible diagnostics for multinomial models -- not even
> >     for standard
> >      >      > ones fit by the /nnet/ package's *multinom()* function. The
> >      >     reason, I
> >      >      > presume, is because a multinomial model is not really one
> >     but C-1
> >      >      > regression models  (where C is the number of response
> >     categories)
> >      >     and
> >      >      > the *vif()* function is not designed to deal with this
> >     scenario.
> >      >      >
> >      >      > Therefore, in order to obtain meaningful collinearity
> >     metrics, my
> >      >      > present plan is to write a simple helper function that uses
> >      >     *vif() *to
> >      >      > calculate and present (generalized) variance inflation
> metrics
> >      >     for the
> >      >      > C-1 sub-datasets to which the C-1 component binomial
> >     models of the
> >      >      > overall multinomial model are fit. In other words, it will
> >      >     partition the
> >      >      > data into those C-1 subsets, and then apply *vif()* to as
> many
> >      >     linear
> >      >      > regressions using a made-up continuous response and the
> fixed
> >      >     effects of
> >      >      > interest.
> >      >      >
> >      >      > Does this seem like a sensible approach?
> >      >      >
> >      >      > Best,
> >      >      >
> >      >      > Juho
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      > ma 27. syysk. 2021 klo 19.26 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
> >      >      >
> >      >      >     Dear Simon,
> >      >      >
> >      >      >     I believe that Russ's point is that the fact that the
> >      >     additive model
> >      >      >     allows you to estimate nonsensical quantities like a
> >     mean for
> >      >     girls in
> >      >      >     all-boys' schools implies a problem with the model.
> >     Why not
> >      >     do as I
> >      >      >     suggested and define two dichotomous factors: sex of
> >     student
> >      >      >     (male/female) and type of school (coed, same-sex)? The
> >     four
> >      >      >     combinations
> >      >      >     of levels then make sense.
> >      >      >
> >      >      >     Best,
> >      >      >        John
> >      >      >
> >      >      >     On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> >      >      >      > Thanks, Russ! There is one thing that I still don't
> >      >     understand. We
> >      >      >      > have two completely empty cells (boys in girl-only
> >     & girls in
> >      >      >     boy-only
> >      >      >      > schools). Then, how are the means of those empty
> cells
> >      >     computed (what
> >      >      >      > data is used in their place in the additive model)?
> >      >      >      >
> >      >      >      > Let's' simplify the model for clarity:
> >      >      >      >
> >      >      >      > library(R2MLwiN)
> >      >      >      > library(emmeans)
> >      >      >      >
> >      >      >      > Form3 <- normexam ~ schgend + sex ## + standlrt +
> >      >     (standlrt | school)
> >      >      >      > model3 <- lm(Form3, data = tutorial)
> >      >      >      >
> >      >      >      > emmeans(model3, pairwise~sex+schgend)$emmeans
> >      >      >      >
> >      >      >      >   sex  schgend   emmean     SE   df lower.CL
> upper.CL
> >      >      >      >   boy  mixedsch -0.2160 0.0297 4055  -0.2742
> -0.15780
> >      >      >      >   girl mixedsch  0.0248 0.0304 4055  -0.0348
> 0.08437
> >      >      >      >   boy  boysch    0.0234 0.0437 4055  -0.0623
> 0.10897
> >      >      >      >   girl boysch    0.2641 0.0609 4055   0.1447
> >     0.38360<-how
> >      >     computed?
> >      >      >      >   boy  girlsch  -0.0948 0.0502 4055  -0.1931
> >     0.00358<-how
> >      >     computed?
> >      >      >      >   girl girlsch   0.1460 0.0267 4055   0.0938
> 0.19829
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> >      >      >      > <russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu> <mailto:russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu>>
> >      >     <mailto:russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu> <mailto:russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu>>>>
> >      >     wrote:
> >      >      >      >>
> >      >      >      >> By the way, returning to the topic of interpreting
> >      >     coefficients,
> >      >      >     you ought to have fun with the ones from the model I
> >     just fitted:
> >      >      >      >>
> >      >      >      >> Fixed effects:
> >      >      >      >>                 Estimate Std. Error t value
> >      >      >      >> (Intercept)    -0.18882    0.05135  -3.677
> >      >      >      >> standlrt        0.55442    0.01994  27.807
> >      >      >      >> schgendboysch   0.17986    0.09915   1.814
> >      >      >      >> schgendgirlsch  0.17482    0.07877   2.219
> >      >      >      >> sexgirl         0.16826    0.03382   4.975
> >      >      >      >>
> >      >      >      >> One curious thing you'll notice is that there are
> no
> >      >      >     coefficients for the interaction terms. Why? Because
> >     those terms
> >      >      >     were "thrown out" of the model, and so they are not
> >     shown. I
> >      >     think
> >      >      >     it is unwise to not show what was thrown out (e.g., lm
> >     would have
> >      >      >     shown them as NAs), because in fact what we see is but
> >     one of
> >      >      >     infinitely many possible solutions to the regression
> >      >     equations. This
> >      >      >     is the solution where the last two coefficients are
> >      >     constrained to
> >      >      >     zero. There is another equally reasonable one where the
> >      >     coefficients
> >      >      >     for schgendboysch and schgendgirlsch  are constrained
> to
> >      >     zero, and
> >      >      >     the two interaction effects would then be non-zero. And
> >      >     infinitely
> >      >      >     more where all 7 coefficients are non-zero, and there
> >     are two
> >      >     linear
> >      >      >     constraints among them.
> >      >      >      >>
> >      >      >      >> Of course, since the particular estimate shown
> >     consists
> >      >     of all
> >      >      >     the main effects and interactions are constrained to
> >     zero, it
> >      >     does
> >      >      >     demonstrate that the additive model *could* have been
> >     used to
> >      >     obtain
> >      >      >     the same estimates and standard errors, and you can
> >     see that by
> >      >      >     comparing the results (and ignoring the invalid ones
> >     from the
> >      >      >     additive model). But it is just a lucky coincidence
> >     that it
> >      >     worked
> >      >      >     out this way, and the additive model did lead us down
> >     a primrose
> >      >      >     path containing silly results among the correct ones.
> >      >      >      >>
> >      >      >      >> Russ
> >      >      >      >>
> >      >      >      >> -----Original Message-----
> >      >      >      >> From: Lenth, Russell V
> >      >      >      >> Sent: Sunday, September 26, 2021 7:43 PM
> >      >      >      >> To: Simon Harmel <sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com>
> >      >     <mailto:sim.harmel at gmail.com <mailto:sim.harmel at gmail.com>>
> >      >      >     <mailto:sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com> <mailto:sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com>>>>
> >      >      >      >> Cc: r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >> Subject: RE: [External] Re: [R-sig-ME] Help with
> >     interpreting
> >      >      >     one fixed-effect coefficient
> >      >      >      >>
> >      >      >      >> I guess correctness is in the eyes of the
> >     beholder. But I
> >      >     think
> >      >      >     this illustrates the folly of the additive model.
> >     Having additive
> >      >      >     effects suggests a belief that you can vary one factor
> >     more
> >      >     or less
> >      >      >     independently of the other. In his comments, John Fox
> >     makes a
> >      >     good
> >      >      >     point that escaped my earlier cursory view of the
> original
> >      >     question,
> >      >      >     that you don't have data on girls attending all-boys'
> >      >     schools, nor
> >      >      >     boys attending all-girls' schools; yet the model that
> >     was fitted
> >      >      >     estimates a mean response for both those situations.
> >     That's a
> >      >     pretty
> >      >      >     clear testament to the failure of that model ? and
> >     also why the
> >      >      >     coefficients don't make sense. And finally why we have
> >      >     estimates of
> >      >      >     15 comparisons (some of which are aliased with one
> >     another), when
> >      >      >     only 6 of them make sense.
> >      >      >      >>
> >      >      >      >> If instead, a model with interaction were fitted,
> it
> >      >     would be a
> >      >      >     rank-deficient model because two cells are empty.
> Perhaps
> >      >     there is
> >      >      >     some sort of nesting structure that could be used to
> >     work around
> >      >      >     that. However, it doesn't matter much because emmeans
> >     assesses
> >      >      >     estimability, and the two combinations I mentioned
> >     above would be
> >      >      >     flagged as non-estimable. One could then more
> >     judiciously use the
> >      >      >     contrast function to test meaningful contrasts across
> this
> >      >     irregular
> >      >      >     array of cell means. Or even injudiciously asking for
> all
> >      >     pairwise
> >      >      >     comparisons, you will see 6 estimable ones and 9
> >      >     non-estimable ones.
> >      >      >     See output below.
> >      >      >      >>
> >      >      >      >> Russ
> >      >      >      >>
> >      >      >      >> ----- Interactive model -----
> >      >      >      >>
> >      >      >      >>> Form <- normexam ~ 1 + standlrt + schgend * sex +
> >      >     (standlrt |
> >      >      >     school)
> >      >      >      >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> >      >      >      >> fixed-effect model matrix is rank deficient so
> >     dropping 2
> >      >      >     columns / coefficients
> >      >      >      >>>
> >      >      >      >>> emmeans(model, pairwise~schgend+sex)
> >      >      >      >>
> >      >      >      >> ... messages deleted ...
> >      >      >      >>
> >      >      >      >> $emmeans
> >      >      >      >>   schgend  sex    emmean     SE  df asymp.LCL
> >     asymp.UCL
> >      >      >      >>   mixedsch boy  -0.18781 0.0514 Inf   -0.2885
> >       -0.0871
> >      >      >      >>   boysch   boy  -0.00795 0.0880 Inf   -0.1805
> >     0.1646
> >      >      >      >>   girlsch  boy    nonEst     NA  NA        NA
> >        NA
> >      >      >      >>   mixedsch girl -0.01955 0.0521 Inf   -0.1216
> >     0.0825
> >      >      >      >>   boysch   girl   nonEst     NA  NA        NA
> >        NA
> >      >      >      >>   girlsch  girl  0.15527 0.0632 Inf    0.0313
> >     0.2792
> >      >      >      >>
> >      >      >      >> Degrees-of-freedom method: asymptotic
> >      >      >      >> Confidence level used: 0.95
> >      >      >      >>
> >      >      >      >> $contrasts
> >      >      >      >>   contrast                     estimate     SE  df
> >      >     z.ratio p.value
> >      >      >      >>   mixedsch boy - boysch boy     -0.1799 0.0991 Inf
> >      >     -1.814  0.4565
> >      >      >      >>   mixedsch boy - girlsch boy     nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>   mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf
> >      >     -4.975  <.0001
> >      >      >      >>   mixedsch boy - boysch girl     nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>   mixedsch boy - girlsch girl   -0.3431 0.0780 Inf
> >      >     -4.396  0.0002
> >      >      >      >>   boysch boy - girlsch boy       nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>   boysch boy - mixedsch girl     0.0116 0.0997 Inf
> >      >       0.116  1.0000
> >      >      >      >>   boysch boy - boysch girl       nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>   boysch boy - girlsch girl     -0.1632 0.1058 Inf
> >      >     -1.543  0.6361
> >      >      >      >>   girlsch boy - mixedsch girl    nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>   girlsch boy - boysch girl      nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>   girlsch boy - girlsch girl     nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>   mixedsch girl - boysch girl    nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>   mixedsch girl - girlsch girl  -0.1748 0.0788 Inf
> >      >     -2.219  0.2287
> >      >      >      >>   boysch girl - girlsch girl     nonEst     NA  NA
> >      >     NA      NA
> >      >      >      >>
> >      >      >      >> Degrees-of-freedom method: asymptotic
> >      >      >      >> P value adjustment: tukey method for comparing a
> >     family of 6
> >      >      >     estimates
> >      >      >      >>
> >      >      >      >>
> >      >      >      >>
> >     ---------------------------------------------------------
> >      >      >      >> From: Simon Harmel <sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com>
> >      >     <mailto:sim.harmel at gmail.com <mailto:sim.harmel at gmail.com>>
> >      >      >     <mailto:sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com> <mailto:sim.harmel at gmail.com
> >     <mailto:sim.harmel at gmail.com>>>>
> >      >      >      >> Sent: Sunday, September 26, 2021 3:08 PM
> >      >      >      >> To: Lenth, Russell V <russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu>
> >      >     <mailto:russell-lenth at uiowa.edu <mailto:
> russell-lenth at uiowa.edu>>
> >      >      >     <mailto:russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu>
> >      >     <mailto:russell-lenth at uiowa.edu
> >     <mailto:russell-lenth at uiowa.edu>>>>
> >      >      >      >> Cc: r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >> Subject: [External] Re: [R-sig-ME] Help with
> >     interpreting one
> >      >      >     fixed-effect coefficient
> >      >      >      >>
> >      >      >      >> Dear Russ and the List Members,
> >      >      >      >>
> >      >      >      >> If we use Russ' great package (emmeans), we see
> >     that although
> >      >      >     meaningless, but "schgendgirl-only" can be interpreted
> >     using the
> >      >      >     logic I mentioned here:
> >      >      >
> >      >
> >     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html
> >     <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html>
> >      >
> >       <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html>>
> >      >      >
> >      >
> >       <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html> <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html>>> .
> >      >      >      >>
> >      >      >      >> That is, "schgendgirl-only" can meaninglessly
> >     mean: ***diff.
> >      >      >     bet. boys in girl-only vs. mixed schools*** just like
> >     it can
> >      >      >     meaningfully mean:  ***diff. bet. girls in girl-only
> >     vs. mixed
> >      >      >     schools***
> >      >      >      >>
> >      >      >      >> Russ, have I used emmeans correctly?
> >      >      >      >>
> >      >      >      >> Simon
> >      >      >      >>
> >      >      >      >> Here is a reproducible code:
> >      >      >      >>
> >      >      >      >> library(R2MLwiN) # For the dataset
> >      >      >      >> library(lme4)
> >      >      >      >> library(emmeans)
> >      >      >      >>
> >      >      >      >> data("tutorial")
> >      >      >      >>
> >      >      >      >> Form <- normexam ~ 1 + standlrt + schgend + sex +
> >     (standlrt |
> >      >      >     school)
> >      >      >      >> model <- lmer(Form, data = tutorial, REML = FALSE)
> >      >      >      >>
> >      >      >      >> emmeans(model, pairwise~schgend+sex)$contrast
> >      >      >      >>
> >      >      >      >> contrast                     estimate     SE  df
> >     z.ratio
> >      >     p.value
> >      >      >      >> mixedsch boy - boysch boy    -0.17986 0.0991 Inf
> >     -1.814
> >      >     0.4565
> >      >      >      >> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf
> >     -2.219
> >      >     0.2287
> >      >      >       <--This coef. equals
> >      >      >      >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf
> >     -4.975
> >      >     <.0001
> >      >      >      >> mixedsch boy - boysch girl   -0.34813 0.1096 Inf
> >     -3.178
> >      >     0.0186
> >      >      >      >> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf
> >     -4.396
> >      >     0.0002
> >      >      >      >> boysch boy - girlsch boy      0.00505 0.1110 Inf
> >     0.045
> >      >     1.0000
> >      >      >      >> boysch boy - mixedsch girl    0.01160 0.0997 Inf
> >     0.116
> >      >     1.0000
> >      >      >      >> boysch boy - boysch girl     -0.16826 0.0338 Inf
> >     -4.975
> >      >     <.0001
> >      >      >      >> boysch boy - girlsch girl    -0.16322 0.1058 Inf
> >     -1.543
> >      >     0.6361
> >      >      >      >> girlsch boy - mixedsch girl   0.00656 0.0928 Inf
> >     0.071
> >      >     1.0000
> >      >      >      >> girlsch boy - boysch girl    -0.17331 0.1255 Inf
> >     -1.381
> >      >     0.7388
> >      >      >      >> girlsch boy - girlsch girl   -0.16826 0.0338 Inf
> >     -4.975
> >      >     <.0001
> >      >      >      >> mixedsch girl - boysch girl  -0.17986 0.0991 Inf
> >     -1.814
> >      >     0.4565
> >      >      >      >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf
> >     -2.219
> >      >     0.2287
> >      >      >       <--This coef.
> >      >      >      >> boysch girl - girlsch girl    0.00505 0.1110 Inf
> >     0.045
> >      >     1.0000
> >      >      >      >>
> >      >      >      >>
> >      >      >      >
> >      >      >      > _______________________________________________
> >      >      >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >      >      >      >
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >      >     --
> >      >      >     John Fox, Professor Emeritus
> >      >      >     McMaster University
> >      >      >     Hamilton, Ontario, Canada
> >      >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >      >
> >      >      >     _______________________________________________
> >      >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >      >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >
> >      >     --
> >      >     John Fox, Professor Emeritus
> >      >     McMaster University
> >      >     Hamilton, Ontario, Canada
> >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sat Feb 26 21:45:04 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sat, 26 Feb 2022 22:45:04 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
Message-ID: <CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>

Dear John W,

Thank you very much for the tip-off! Apologies for not responding earlier
(gmail apparently decided to direct your email right into the junk folder).
I am very pleased to note that the package you mention does indeed work
with *brms* multinomial models! Thanks again!

Best,

Juho

pe 25. helmik. 2022 klo 19.23 John Willoughby (johnwillec at gmail.com)
kirjoitti:

> Have you tried the check_collinearity() function in the performance
> package? It's supposed to work on brms models, but whether it will work on
> a multinomial model I don't know.  It works well on mixed models generated
> by glmmTMB().
>
> John Willoughby
>
>
> On Fri, Feb 25, 2022 at 3:01 AM <r-sig-mixed-models-request at r-project.org>
> wrote:
>
> > Send R-sig-mixed-models mailing list submissions to
> >         r-sig-mixed-models at r-project.org
> >
> > To subscribe or unsubscribe via the World Wide Web, visit
> >         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > or, via email, send a message with subject or body 'help' to
> >         r-sig-mixed-models-request at r-project.org
> >
> > You can reach the person managing the list at
> >         r-sig-mixed-models-owner at r-project.org
> >
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of R-sig-mixed-models digest..."
> >
> >
> > Today's Topics:
> >
> >    1. Collinearity diagnostics for (mixed) multinomial models
> >       (Juho Kristian Ruohonen)
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Fri, 25 Feb 2022 10:23:25 +0200
> > From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
> > To: John Fox <jfox at mcmaster.ca>
> > Cc: "r-sig-mixed-models at r-project.org"
> >         <r-sig-mixed-models at r-project.org>
> > Subject: [R-sig-ME] Collinearity diagnostics for (mixed) multinomial
> >         models
> > Message-ID:
> >         <
> > CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> > Content-Type: text/plain; charset="utf-8"
> >
> > Dear John (and anyone else qualified to comment),
> >
> > I fit lots of mixed-effects multinomial models in my research, and I
> would
> > like to see some (multi)collinearity diagnostics on the fixed effects, of
> > which there are over 30. My models are fit using the Bayesian *brms*
> > package because I know of no frequentist packages with multinomial GLMM
> > compatibility.
> >
> > With continuous or dichotomous outcomes, my go-to function for
> calculating
> > multicollinearity diagnostics is of course *vif()* from the *car*
> package.
> > As expected, however, this function does not report sensible diagnostics
> > for multinomial models -- not even for standard ones fit by the *nnet*
> > package's *multinom()* function. The reason, I presume, is because a
> > multinomial model is not really one but C-1 regression models  (where C
> is
> > the number of response categories) and the *vif()* function is not
> designed
> > to deal with this scenario.
> >
> > Therefore, in order to obtain meaningful collinearity metrics, my present
> > plan is to write a simple helper function that uses *vif() *to calculate
> > and present (generalized) variance inflation metrics for the C-1
> > sub-datasets to which the C-1 component binomial models of the overall
> > multinomial model are fit. In other words, it will partition the data
> into
> > those C-1 subsets, and then apply *vif()* to as many linear regressions
> > using a made-up continuous response and the fixed effects of interest.
> >
> > Does this seem like a sensible approach?
> >
> > Best,
> >
> > Juho
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Feb 28 01:23:48 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sun, 27 Feb 2022 19:23:48 -0500
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
Message-ID: <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>

Dear Juho,

I've now had a chance to think about this problem some more, and I 
believe that the approach I suggested is correct. I also had an 
opportunity to talk the problem over a bit with Georges Monette, who 
coauthored the paper that introduced generalized variance inflation 
factors (GVIFs). On the other hand, the results produced by 
performance::check_collinearity() for multinomial logit models don't 
seem to be correct (see below).

Here's an example, using the nnet::multinom() function to fit a 
multinomial logit model, with alternative parametrizations of the LHS of 
the model:

--------- snip -----------

 > library(nnet) # for multinom()
 > library(carData) # for BEPS data set

 > # alternative ordering of the response levels:
 > BEPS$vote1 <- factor(BEPS$vote, levels=c("Labour", "Liberal 
Democrat", "Conservative"))
 > levels(BEPS$vote)
[1] "Conservative"     "Labour"           "Liberal Democrat"
 > levels(BEPS$vote1)
[1] "Labour"           "Liberal Democrat" "Conservative"

 > m <- multinom(vote ~ . - vote1, data=BEPS)
# weights:  33 (20 variable)
initial  value 1675.383740
iter  10 value 1345.935273
iter  20 value 1150.956807
iter  30 value 1141.921662
iter  30 value 1141.921661
iter  30 value 1141.921661
final  value 1141.921661
converged
 > m1 <- multinom(vote1 ~ . - vote, data=BEPS)
# weights:  33 (20 variable)
initial  value 1675.383740
iter  10 value 1280.439304
iter  20 value 1165.513772
final  value 1141.921662
converged

 > rbind(coef(m), coef(m1)) # compare coefficients
                  (Intercept)          age economic.cond.national 
economic.cond.household
Labour             0.9515214 -0.021913989              0.5575707 
      0.15839096
Liberal Democrat   1.4119306 -0.016810735              0.1810761 
     -0.01196664
Liberal Democrat   0.4604567  0.005102666             -0.3764928 
     -0.17036682
Conservative      -0.9514466  0.021912305             -0.5575644 
     -0.15838744
                       Blair       Hague    Kennedy      Europe 
political.knowledge
Labour            0.8371764 -0.90775585  0.2513436 -0.22781308 
-0.5370612
Liberal Democrat  0.2937331 -0.82217625  0.6710567 -0.20004624 
-0.2034605
Liberal Democrat -0.5434408  0.08559455  0.4197027  0.02776465 
0.3336068
Conservative     -0.8371670  0.90778068 -0.2513735  0.22781092 
0.5370545
                   gendermale
Labour            0.13765774
Liberal Democrat  0.12640823
Liberal Democrat -0.01125898
Conservative     -0.13764849

 > c(logLik(m), logLik(m1)) # same fit to the data
[1] -1141.922 -1141.922

 > # covariance matrices for coefficients:
 > V <- vcov(m)
 > V1 <- vcov(m1)
 > cbind(colnames(V), colnames(V1)) # compare
       [,1]                                       [,2] 

  [1,] "Labour:(Intercept)"                       "Liberal 
Democrat:(Intercept)"
  [2,] "Labour:age"                               "Liberal Democrat:age" 

  [3,] "Labour:economic.cond.national"            "Liberal 
Democrat:economic.cond.national"
  [4,] "Labour:economic.cond.household"           "Liberal 
Democrat:economic.cond.household"
  [5,] "Labour:Blair"                             "Liberal 
Democrat:Blair"
  [6,] "Labour:Hague"                             "Liberal 
Democrat:Hague"
  [7,] "Labour:Kennedy"                           "Liberal 
Democrat:Kennedy"
  [8,] "Labour:Europe"                            "Liberal 
Democrat:Europe"
  [9,] "Labour:political.knowledge"               "Liberal 
Democrat:political.knowledge"
[10,] "Labour:gendermale"                        "Liberal 
Democrat:gendermale"
[11,] "Liberal Democrat:(Intercept)" 
"Conservative:(Intercept)"
[12,] "Liberal Democrat:age"                     "Conservative:age" 

[13,] "Liberal Democrat:economic.cond.national" 
"Conservative:economic.cond.national"
[14,] "Liberal Democrat:economic.cond.household" 
"Conservative:economic.cond.household"
[15,] "Liberal Democrat:Blair"                   "Conservative:Blair" 

[16,] "Liberal Democrat:Hague"                   "Conservative:Hague" 

[17,] "Liberal Democrat:Kennedy"                 "Conservative:Kennedy" 

[18,] "Liberal Democrat:Europe"                  "Conservative:Europe" 

[19,] "Liberal Democrat:political.knowledge" 
"Conservative:political.knowledge"
[20,] "Liberal Democrat:gendermale" 
"Conservative:gendermale"

 > int <- c(1, 11) # remove intercepts
 > colnames(V)[int]
[1] "Labour:(Intercept)"           "Liberal Democrat:(Intercept)"

 > colnames(V1)[int]
[1] "Liberal Democrat:(Intercept)" "Conservative:(Intercept)"
 > V <- V[-int, -int]
 > V1 <- V1[-int, -int]

 > age <- c(1, 10) # locate age coefficients
 > colnames(V)[age]
[1] "Labour:age"           "Liberal Democrat:age"
 > colnames(V1)[age]
[1] "Liberal Democrat:age" "Conservative:age"

 > V <- cov2cor(V) # compute coefficient correlations
 > V1 <- cov2cor(V1)

 > # compare GVIFs:
 > c(det(V[age, age])*det(V[-age, -age])/det(V),
+   det(V1[age, age])*det(V1[-age, -age])/det(V1))
[1] 1.046232 1.046229

--------- snip -----------

For curiosity, I applied car::vif() and 
performance::check_collinearity() to these models to see what they would 
do. Both returned the wrong answer. vif() produced a warning, but 
check_collinearity() didn't:

--------- snip -----------

 > car::vif(m1)
                     age  economic.cond.national economic.cond.household
               15.461045               22.137772               16.693877
                   Blair                   Hague                 Kennedy
               14.681562                7.483039               15.812067
                  Europe     political.knowledge                  gender
                6.502119                4.219507                2.313885
Warning message:
In vif.default(m1) : No intercept: vifs may not be sensible.

 > performance::check_collinearity(m)
# Check for Multicollinearity

Low Correlation

                     Term  VIF Increased SE Tolerance
                      age 1.72         1.31      0.58
   economic.cond.national 1.85         1.36      0.54
  economic.cond.household 1.86         1.37      0.54
                    Blair 1.63         1.28      0.61
                    Hague 1.94         1.39      0.52
                  Kennedy 1.70         1.30      0.59
                   Europe 2.01         1.42      0.50
      political.knowledge 1.94         1.39      0.52
                   gender 1.78         1.33      0.56
 > performance::check_collinearity(m1)
# Check for Multicollinearity

Low Correlation

                     Term  VIF Increased SE Tolerance
                      age 1.19         1.09      0.84
   economic.cond.national 1.42         1.19      0.70
  economic.cond.household 1.32         1.15      0.76
                    Blair 1.50         1.22      0.67
                    Hague 1.30         1.14      0.77
                  Kennedy 1.19         1.09      0.84
                   Europe 1.34         1.16      0.75
      political.knowledge 1.30         1.14      0.77
                   gender 1.23         1.11      0.81

--------- snip -----------

I looked at the code for vif() and check_collinearity() to see where 
they went wrong. Both failed to handle the two intercepts in the model 
correctly -- vif() thought there was no intercept and 
check_collinearity() just removed the first intercept but not the second.

In examining the code for check_collinearity(), I discovered a couple of 
additional disconcerting facts. First, part of the code seems to be 
copied from vif.default(). Second, as a consequence, 
check_collinearity() actually computes GVIFs rather than VIFs (and 
doesn't reference either the Fox and Monette paper introducing GVIFs or 
the car package) but doesn't seem to understand that, and, for example, 
takes the squareroot of the GVIF (reported in the column marked 
"Increased SE") rather than the 2p root (when there are p > 1 
coefficients in a term).

Here's the relevant code from the two functions (where . . . denotes 
elided lines) -- the default method for vif() and .check_collinearity(), 
which is called by check_collinearity.default():

--------- snip -----------

 > car:::vif.default
function (mod, ...)
{
     . . .
     v <- vcov(mod)
     assign <- attr(model.matrix(mod), "assign")
     if (names(coefficients(mod)[1]) == "(Intercept)") {
         v <- v[-1, -1]
         assign <- assign[-1]
     }
     else warning("No intercept: vifs may not be sensible.")
     terms <- labels(terms(mod))
     n.terms <- length(terms)
     if (n.terms < 2)
         stop("model contains fewer than 2 terms")
     R <- cov2cor(v)
     detR <- det(R)
     . . .
     for (term in 1:n.terms) {
         subs <- which(assign == term)
         result[term, 1] <- det(as.matrix(R[subs, subs])) * 
det(as.matrix(R[-subs,
             -subs]))/detR
         result[term, 2] <- length(subs)
     }
     . . .
}

 > performance:::.check_collinearity
function (x, component, verbose = TRUE)
{
     v <- insight::get_varcov(x, component = component, verbose = FALSE)
     assign <- .term_assignments(x, component, verbose = verbose)
     . . .
     if (insight::has_intercept(x)) {
         v <- v[-1, -1]
         assign <- assign[-1]
     }
     else {
         if (isTRUE(verbose)) {
             warning("Model has no intercept. VIFs may not be sensible.",
                 call. = FALSE)
         }
     }
         . . .
         terms <- labels(stats::terms(f[[component]]))
         . . .
     n.terms <- length(terms)
     if (n.terms < 2) {
         if (isTRUE(verbose)) {
             warning(insight::format_message(sprintf("Not enough model 
terms in the %s part of the model to check for multicollinearity.",
                 component)), call. = FALSE)
         }
         return(NULL)
     }
     R <- stats::cov2cor(v)
     detR <- det(R)
     . . .
     for (term in 1:n.terms) {
         subs <- which(assign == term)
             . . .
             result <- c(result, det(as.matrix(R[subs, subs])) *
                 det(as.matrix(R[-subs, -subs]))/detR)
             . . .
     }
     . . .
}

--------- snip -----------

So, the upshot of all this is that you should be able to do what you 
want, but not with either car::vif() or 
performance::check_collinearity(). Instead, either write your own 
function or do the computations in a script.

There's also a lesson here about S3 default methods: The fact that a 
default method returns a result rather than throwing an error or a 
warning doesn't mean that the result is the right answer.

I hope this helps,
  John


On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen wrote:
> Dear John W,
> 
> Thank you very much for the tip-off! Apologies for not responding earlier
> (gmail apparently decided to direct your email right into the junk folder).
> I am very pleased to note that the package you mention does indeed work
> with *brms* multinomial models! Thanks again!
> 
> Best,
> 
> Juho
> 
> pe 25. helmik. 2022 klo 19.23 John Willoughby (johnwillec at gmail.com)
> kirjoitti:
> 
>> Have you tried the check_collinearity() function in the performance
>> package? It's supposed to work on brms models, but whether it will work on
>> a multinomial model I don't know.  It works well on mixed models generated
>> by glmmTMB().
>>
>> John Willoughby
>>
>>
>> On Fri, Feb 25, 2022 at 3:01 AM <r-sig-mixed-models-request at r-project.org>
>> wrote:
>>
>>> Send R-sig-mixed-models mailing list submissions to
>>>          r-sig-mixed-models at r-project.org
>>>
>>> To subscribe or unsubscribe via the World Wide Web, visit
>>>          https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> or, via email, send a message with subject or body 'help' to
>>>          r-sig-mixed-models-request at r-project.org
>>>
>>> You can reach the person managing the list at
>>>          r-sig-mixed-models-owner at r-project.org
>>>
>>> When replying, please edit your Subject line so it is more specific
>>> than "Re: Contents of R-sig-mixed-models digest..."
>>>
>>>
>>> Today's Topics:
>>>
>>>     1. Collinearity diagnostics for (mixed) multinomial models
>>>        (Juho Kristian Ruohonen)
>>>
>>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Fri, 25 Feb 2022 10:23:25 +0200
>>> From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
>>> To: John Fox <jfox at mcmaster.ca>
>>> Cc: "r-sig-mixed-models at r-project.org"
>>>          <r-sig-mixed-models at r-project.org>
>>> Subject: [R-sig-ME] Collinearity diagnostics for (mixed) multinomial
>>>          models
>>> Message-ID:
>>>          <
>>> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
>>> Content-Type: text/plain; charset="utf-8"
>>>
>>> Dear John (and anyone else qualified to comment),
>>>
>>> I fit lots of mixed-effects multinomial models in my research, and I
>> would
>>> like to see some (multi)collinearity diagnostics on the fixed effects, of
>>> which there are over 30. My models are fit using the Bayesian *brms*
>>> package because I know of no frequentist packages with multinomial GLMM
>>> compatibility.
>>>
>>> With continuous or dichotomous outcomes, my go-to function for
>> calculating
>>> multicollinearity diagnostics is of course *vif()* from the *car*
>> package.
>>> As expected, however, this function does not report sensible diagnostics
>>> for multinomial models -- not even for standard ones fit by the *nnet*
>>> package's *multinom()* function. The reason, I presume, is because a
>>> multinomial model is not really one but C-1 regression models  (where C
>> is
>>> the number of response categories) and the *vif()* function is not
>> designed
>>> to deal with this scenario.
>>>
>>> Therefore, in order to obtain meaningful collinearity metrics, my present
>>> plan is to write a simple helper function that uses *vif() *to calculate
>>> and present (generalized) variance inflation metrics for the C-1
>>> sub-datasets to which the C-1 component binomial models of the overall
>>> multinomial model are fit. In other words, it will partition the data
>> into
>>> those C-1 subsets, and then apply *vif()* to as many linear regressions
>>> using a made-up continuous response and the fixed effects of interest.
>>>
>>> Does this seem like a sensible approach?
>>>
>>> Best,
>>>
>>> Juho
>>>
>>>
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Mon Feb 28 08:06:35 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Mon, 28 Feb 2022 09:06:35 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
Message-ID: <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>

Dear Professor Fox and other list members,

Profuse thanks for doing that detective work for me! I myself thought the
inflation factors reported by check_collinearity() were suspiciously high,
but unlike you I lacked the expertise to identify what was going on.

As for your suggested approach, have I understood this correctly:

Since there doesn't yet exist an R function that will calculate the (G)VIFS
of multinomial models correctly, my best bet for now is just to ignore the
fact that such models partition the data into C-1 subsets, and to calculate
approximate GVIFs from the entire dataset at once as if the response were
continuous? And a simple way to do this is to construct a fake continuous
response, call *lm(fakeresponse ~.)*, and apply *car::vif()* on the result?

Best,

Juho

ma 28. helmik. 2022 klo 2.23 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juho,
>
> I've now had a chance to think about this problem some more, and I
> believe that the approach I suggested is correct. I also had an
> opportunity to talk the problem over a bit with Georges Monette, who
> coauthored the paper that introduced generalized variance inflation
> factors (GVIFs). On the other hand, the results produced by
> performance::check_collinearity() for multinomial logit models don't
> seem to be correct (see below).
>
> Here's an example, using the nnet::multinom() function to fit a
> multinomial logit model, with alternative parametrizations of the LHS of
> the model:
>
> --------- snip -----------
>
>  > library(nnet) # for multinom()
>  > library(carData) # for BEPS data set
>
>  > # alternative ordering of the response levels:
>  > BEPS$vote1 <- factor(BEPS$vote, levels=c("Labour", "Liberal
> Democrat", "Conservative"))
>  > levels(BEPS$vote)
> [1] "Conservative"     "Labour"           "Liberal Democrat"
>  > levels(BEPS$vote1)
> [1] "Labour"           "Liberal Democrat" "Conservative"
>
>  > m <- multinom(vote ~ . - vote1, data=BEPS)
> # weights:  33 (20 variable)
> initial  value 1675.383740
> iter  10 value 1345.935273
> iter  20 value 1150.956807
> iter  30 value 1141.921662
> iter  30 value 1141.921661
> iter  30 value 1141.921661
> final  value 1141.921661
> converged
>  > m1 <- multinom(vote1 ~ . - vote, data=BEPS)
> # weights:  33 (20 variable)
> initial  value 1675.383740
> iter  10 value 1280.439304
> iter  20 value 1165.513772
> final  value 1141.921662
> converged
>
>  > rbind(coef(m), coef(m1)) # compare coefficients
>                   (Intercept)          age economic.cond.national
> economic.cond.household
> Labour             0.9515214 -0.021913989              0.5575707
>       0.15839096
> Liberal Democrat   1.4119306 -0.016810735              0.1810761
>      -0.01196664
> Liberal Democrat   0.4604567  0.005102666             -0.3764928
>      -0.17036682
> Conservative      -0.9514466  0.021912305             -0.5575644
>      -0.15838744
>                        Blair       Hague    Kennedy      Europe
> political.knowledge
> Labour            0.8371764 -0.90775585  0.2513436 -0.22781308
> -0.5370612
> Liberal Democrat  0.2937331 -0.82217625  0.6710567 -0.20004624
> -0.2034605
> Liberal Democrat -0.5434408  0.08559455  0.4197027  0.02776465
> 0.3336068
> Conservative     -0.8371670  0.90778068 -0.2513735  0.22781092
> 0.5370545
>                    gendermale
> Labour            0.13765774
> Liberal Democrat  0.12640823
> Liberal Democrat -0.01125898
> Conservative     -0.13764849
>
>  > c(logLik(m), logLik(m1)) # same fit to the data
> [1] -1141.922 -1141.922
>
>  > # covariance matrices for coefficients:
>  > V <- vcov(m)
>  > V1 <- vcov(m1)
>  > cbind(colnames(V), colnames(V1)) # compare
>        [,1]                                       [,2]
>
>   [1,] "Labour:(Intercept)"                       "Liberal
> Democrat:(Intercept)"
>   [2,] "Labour:age"                               "Liberal Democrat:age"
>
>   [3,] "Labour:economic.cond.national"            "Liberal
> Democrat:economic.cond.national"
>   [4,] "Labour:economic.cond.household"           "Liberal
> Democrat:economic.cond.household"
>   [5,] "Labour:Blair"                             "Liberal
> Democrat:Blair"
>   [6,] "Labour:Hague"                             "Liberal
> Democrat:Hague"
>   [7,] "Labour:Kennedy"                           "Liberal
> Democrat:Kennedy"
>   [8,] "Labour:Europe"                            "Liberal
> Democrat:Europe"
>   [9,] "Labour:political.knowledge"               "Liberal
> Democrat:political.knowledge"
> [10,] "Labour:gendermale"                        "Liberal
> Democrat:gendermale"
> [11,] "Liberal Democrat:(Intercept)"
> "Conservative:(Intercept)"
> [12,] "Liberal Democrat:age"                     "Conservative:age"
>
> [13,] "Liberal Democrat:economic.cond.national"
> "Conservative:economic.cond.national"
> [14,] "Liberal Democrat:economic.cond.household"
> "Conservative:economic.cond.household"
> [15,] "Liberal Democrat:Blair"                   "Conservative:Blair"
>
> [16,] "Liberal Democrat:Hague"                   "Conservative:Hague"
>
> [17,] "Liberal Democrat:Kennedy"                 "Conservative:Kennedy"
>
> [18,] "Liberal Democrat:Europe"                  "Conservative:Europe"
>
> [19,] "Liberal Democrat:political.knowledge"
> "Conservative:political.knowledge"
> [20,] "Liberal Democrat:gendermale"
> "Conservative:gendermale"
>
>  > int <- c(1, 11) # remove intercepts
>  > colnames(V)[int]
> [1] "Labour:(Intercept)"           "Liberal Democrat:(Intercept)"
>
>  > colnames(V1)[int]
> [1] "Liberal Democrat:(Intercept)" "Conservative:(Intercept)"
>  > V <- V[-int, -int]
>  > V1 <- V1[-int, -int]
>
>  > age <- c(1, 10) # locate age coefficients
>  > colnames(V)[age]
> [1] "Labour:age"           "Liberal Democrat:age"
>  > colnames(V1)[age]
> [1] "Liberal Democrat:age" "Conservative:age"
>
>  > V <- cov2cor(V) # compute coefficient correlations
>  > V1 <- cov2cor(V1)
>
>  > # compare GVIFs:
>  > c(det(V[age, age])*det(V[-age, -age])/det(V),
> +   det(V1[age, age])*det(V1[-age, -age])/det(V1))
> [1] 1.046232 1.046229
>
> --------- snip -----------
>
> For curiosity, I applied car::vif() and
> performance::check_collinearity() to these models to see what they would
> do. Both returned the wrong answer. vif() produced a warning, but
> check_collinearity() didn't:
>
> --------- snip -----------
>
>  > car::vif(m1)
>                      age  economic.cond.national economic.cond.household
>                15.461045               22.137772               16.693877
>                    Blair                   Hague                 Kennedy
>                14.681562                7.483039               15.812067
>                   Europe     political.knowledge                  gender
>                 6.502119                4.219507                2.313885
> Warning message:
> In vif.default(m1) : No intercept: vifs may not be sensible.
>
>  > performance::check_collinearity(m)
> # Check for Multicollinearity
>
> Low Correlation
>
>                      Term  VIF Increased SE Tolerance
>                       age 1.72         1.31      0.58
>    economic.cond.national 1.85         1.36      0.54
>   economic.cond.household 1.86         1.37      0.54
>                     Blair 1.63         1.28      0.61
>                     Hague 1.94         1.39      0.52
>                   Kennedy 1.70         1.30      0.59
>                    Europe 2.01         1.42      0.50
>       political.knowledge 1.94         1.39      0.52
>                    gender 1.78         1.33      0.56
>  > performance::check_collinearity(m1)
> # Check for Multicollinearity
>
> Low Correlation
>
>                      Term  VIF Increased SE Tolerance
>                       age 1.19         1.09      0.84
>    economic.cond.national 1.42         1.19      0.70
>   economic.cond.household 1.32         1.15      0.76
>                     Blair 1.50         1.22      0.67
>                     Hague 1.30         1.14      0.77
>                   Kennedy 1.19         1.09      0.84
>                    Europe 1.34         1.16      0.75
>       political.knowledge 1.30         1.14      0.77
>                    gender 1.23         1.11      0.81
>
> --------- snip -----------
>
> I looked at the code for vif() and check_collinearity() to see where
> they went wrong. Both failed to handle the two intercepts in the model
> correctly -- vif() thought there was no intercept and
> check_collinearity() just removed the first intercept but not the second.
>
> In examining the code for check_collinearity(), I discovered a couple of
> additional disconcerting facts. First, part of the code seems to be
> copied from vif.default(). Second, as a consequence,
> check_collinearity() actually computes GVIFs rather than VIFs (and
> doesn't reference either the Fox and Monette paper introducing GVIFs or
> the car package) but doesn't seem to understand that, and, for example,
> takes the squareroot of the GVIF (reported in the column marked
> "Increased SE") rather than the 2p root (when there are p > 1
> coefficients in a term).
>
> Here's the relevant code from the two functions (where . . . denotes
> elided lines) -- the default method for vif() and .check_collinearity(),
> which is called by check_collinearity.default():
>
> --------- snip -----------
>
>  > car:::vif.default
> function (mod, ...)
> {
>      . . .
>      v <- vcov(mod)
>      assign <- attr(model.matrix(mod), "assign")
>      if (names(coefficients(mod)[1]) == "(Intercept)") {
>          v <- v[-1, -1]
>          assign <- assign[-1]
>      }
>      else warning("No intercept: vifs may not be sensible.")
>      terms <- labels(terms(mod))
>      n.terms <- length(terms)
>      if (n.terms < 2)
>          stop("model contains fewer than 2 terms")
>      R <- cov2cor(v)
>      detR <- det(R)
>      . . .
>      for (term in 1:n.terms) {
>          subs <- which(assign == term)
>          result[term, 1] <- det(as.matrix(R[subs, subs])) *
> det(as.matrix(R[-subs,
>              -subs]))/detR
>          result[term, 2] <- length(subs)
>      }
>      . . .
> }
>
>  > performance:::.check_collinearity
> function (x, component, verbose = TRUE)
> {
>      v <- insight::get_varcov(x, component = component, verbose = FALSE)
>      assign <- .term_assignments(x, component, verbose = verbose)
>      . . .
>      if (insight::has_intercept(x)) {
>          v <- v[-1, -1]
>          assign <- assign[-1]
>      }
>      else {
>          if (isTRUE(verbose)) {
>              warning("Model has no intercept. VIFs may not be sensible.",
>                  call. = FALSE)
>          }
>      }
>          . . .
>          terms <- labels(stats::terms(f[[component]]))
>          . . .
>      n.terms <- length(terms)
>      if (n.terms < 2) {
>          if (isTRUE(verbose)) {
>              warning(insight::format_message(sprintf("Not enough model
> terms in the %s part of the model to check for multicollinearity.",
>                  component)), call. = FALSE)
>          }
>          return(NULL)
>      }
>      R <- stats::cov2cor(v)
>      detR <- det(R)
>      . . .
>      for (term in 1:n.terms) {
>          subs <- which(assign == term)
>              . . .
>              result <- c(result, det(as.matrix(R[subs, subs])) *
>                  det(as.matrix(R[-subs, -subs]))/detR)
>              . . .
>      }
>      . . .
> }
>
> --------- snip -----------
>
> So, the upshot of all this is that you should be able to do what you
> want, but not with either car::vif() or
> performance::check_collinearity(). Instead, either write your own
> function or do the computations in a script.
>
> There's also a lesson here about S3 default methods: The fact that a
> default method returns a result rather than throwing an error or a
> warning doesn't mean that the result is the right answer.
>
> I hope this helps,
>   John
>
>
> On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen wrote:
> > Dear John W,
> >
> > Thank you very much for the tip-off! Apologies for not responding earlier
> > (gmail apparently decided to direct your email right into the junk
> folder).
> > I am very pleased to note that the package you mention does indeed work
> > with *brms* multinomial models! Thanks again!
> >
> > Best,
> >
> > Juho
> >
> > pe 25. helmik. 2022 klo 19.23 John Willoughby (johnwillec at gmail.com)
> > kirjoitti:
> >
> >> Have you tried the check_collinearity() function in the performance
> >> package? It's supposed to work on brms models, but whether it will work
> on
> >> a multinomial model I don't know.  It works well on mixed models
> generated
> >> by glmmTMB().
> >>
> >> John Willoughby
> >>
> >>
> >> On Fri, Feb 25, 2022 at 3:01 AM <
> r-sig-mixed-models-request at r-project.org>
> >> wrote:
> >>
> >>> Send R-sig-mixed-models mailing list submissions to
> >>>          r-sig-mixed-models at r-project.org
> >>>
> >>> To subscribe or unsubscribe via the World Wide Web, visit
> >>>          https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>> or, via email, send a message with subject or body 'help' to
> >>>          r-sig-mixed-models-request at r-project.org
> >>>
> >>> You can reach the person managing the list at
> >>>          r-sig-mixed-models-owner at r-project.org
> >>>
> >>> When replying, please edit your Subject line so it is more specific
> >>> than "Re: Contents of R-sig-mixed-models digest..."
> >>>
> >>>
> >>> Today's Topics:
> >>>
> >>>     1. Collinearity diagnostics for (mixed) multinomial models
> >>>        (Juho Kristian Ruohonen)
> >>>
> >>> ----------------------------------------------------------------------
> >>>
> >>> Message: 1
> >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
> >>> From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
> >>> To: John Fox <jfox at mcmaster.ca>
> >>> Cc: "r-sig-mixed-models at r-project.org"
> >>>          <r-sig-mixed-models at r-project.org>
> >>> Subject: [R-sig-ME] Collinearity diagnostics for (mixed) multinomial
> >>>          models
> >>> Message-ID:
> >>>          <
> >>> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >>> Content-Type: text/plain; charset="utf-8"
> >>>
> >>> Dear John (and anyone else qualified to comment),
> >>>
> >>> I fit lots of mixed-effects multinomial models in my research, and I
> >> would
> >>> like to see some (multi)collinearity diagnostics on the fixed effects,
> of
> >>> which there are over 30. My models are fit using the Bayesian *brms*
> >>> package because I know of no frequentist packages with multinomial GLMM
> >>> compatibility.
> >>>
> >>> With continuous or dichotomous outcomes, my go-to function for
> >> calculating
> >>> multicollinearity diagnostics is of course *vif()* from the *car*
> >> package.
> >>> As expected, however, this function does not report sensible
> diagnostics
> >>> for multinomial models -- not even for standard ones fit by the *nnet*
> >>> package's *multinom()* function. The reason, I presume, is because a
> >>> multinomial model is not really one but C-1 regression models  (where C
> >> is
> >>> the number of response categories) and the *vif()* function is not
> >> designed
> >>> to deal with this scenario.
> >>>
> >>> Therefore, in order to obtain meaningful collinearity metrics, my
> present
> >>> plan is to write a simple helper function that uses *vif() *to
> calculate
> >>> and present (generalized) variance inflation metrics for the C-1
> >>> sub-datasets to which the C-1 component binomial models of the overall
> >>> multinomial model are fit. In other words, it will partition the data
> >> into
> >>> those C-1 subsets, and then apply *vif()* to as many linear regressions
> >>> using a made-up continuous response and the fixed effects of interest.
> >>>
> >>> Does this seem like a sensible approach?
> >>>
> >>> Best,
> >>>
> >>> Juho
> >>>
> >>>
> >>>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Feb 28 16:08:06 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 28 Feb 2022 10:08:06 -0500
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
Message-ID: <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>

Dear Juho,

On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen wrote:
> Dear Professor Fox and other list members,
> 
> Profuse thanks for doing that detective work for me! I myself thought 
> the inflation factors reported by check_collinearity() were suspiciously 
> high, but unlike you I lacked the expertise to identify what was going on.
> 
> As for your suggested approach, have I understood this correctly:
> 
> Since there doesn't yet exist an R function that will calculate the 
> (G)VIFS of multinomial models correctly, my best bet for now is just to 
> ignore the fact that such models partition the data into C-1 subsets, 
> and to calculate approximate GVIFs from the entire dataset at once as if 
> the response were continuous? And a simple way to do this is to 
> construct a fake continuous response, call *lm(fakeresponse ~.)*, and 
> apply *car::vif()* on the result?

No, you misunderstand my suggestion, which perhaps isn't surprising 
given the length of my message. What you propose is what I suggested as 
a rough approximation *before* I confirmed that my guess of the solution 
was correct.

The R code that I sent yesterday showed how to compute the GVIF for a 
multinomial regression model, and I suggested that you write either a 
script or a simple function to do that. Here's a function that will work 
for a model object that responds to vcov():

GVIF <- function(model, intercepts, term){
   # model: regression model object
   # intercepts: row/column positions of intercepts in the coefficient 
covariance matrix
   # term: row/column positions of the coefficients for the focal term
   V <- vcov(model)
   term <- colnames(V)[term]
   V <- V[-intercepts, -intercepts]
   V <- cov2cor(V)
   term <- which(colnames(V) %in% term)
   gvif <- det(V[term, term])*det(V[-term, -term])/det(V)
   c(GVIF=gvif, "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
}

and here's an application to the multinom() example that I showed you 
yesterday:

 > colnames(vcov(m)) # to get coefficient positions
  [1] "Labour:(Intercept)"                       "Labour:age" 

  [3] "Labour:economic.cond.national" 
"Labour:economic.cond.household"
  [5] "Labour:Blair"                             "Labour:Hague" 

  [7] "Labour:Kennedy"                           "Labour:Europe" 

  [9] "Labour:political.knowledge"               "Labour:gendermale" 

[11] "Liberal Democrat:(Intercept)"             "Liberal Democrat:age" 

[13] "Liberal Democrat:economic.cond.national"  "Liberal 
Democrat:economic.cond.household"
[15] "Liberal Democrat:Blair"                   "Liberal Democrat:Hague" 

[17] "Liberal Democrat:Kennedy"                 "Liberal 
Democrat:Europe"
[19] "Liberal Democrat:political.knowledge"     "Liberal 
Democrat:gendermale"

 > GVIF(m, intercepts=c(1, 11), term=c(2, 12)) # GVIF for age
           GVIF GVIF^(1/(2*p))
       1.046232       1.011363


Finally, here's what you get for a linear model with the same RHS (where 
the sqrt(VIF) should be a rough approximation to GVIF^(1/4) reported by 
my GVIF() function):

 > m.lm <- lm(as.numeric(vote) ~ . - vote1, data=BEPS)
 > sqrt(car::vif(m.lm))
                     age  economic.cond.national economic.cond.household 
                   Blair
                1.006508                1.124132                1.075656 
                1.118441
                   Hague                 Kennedy                  Europe 
     political.knowledge
                1.066799                1.015532                1.101741 
                1.028546
                  gender
                1.017386


John

> 
> Best,
> 
> Juho
> 
> ma 28. helmik. 2022 klo 2.23 John Fox (jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>) kirjoitti:
> 
>     Dear Juho,
> 
>     I've now had a chance to think about this problem some more, and I
>     believe that the approach I suggested is correct. I also had an
>     opportunity to talk the problem over a bit with Georges Monette, who
>     coauthored the paper that introduced generalized variance inflation
>     factors (GVIFs). On the other hand, the results produced by
>     performance::check_collinearity() for multinomial logit models don't
>     seem to be correct (see below).
> 
>     Here's an example, using the nnet::multinom() function to fit a
>     multinomial logit model, with alternative parametrizations of the
>     LHS of
>     the model:
> 
>     --------- snip -----------
> 
>      ?> library(nnet) # for multinom()
>      ?> library(carData) # for BEPS data set
> 
>      ?> # alternative ordering of the response levels:
>      ?> BEPS$vote1 <- factor(BEPS$vote, levels=c("Labour", "Liberal
>     Democrat", "Conservative"))
>      ?> levels(BEPS$vote)
>     [1] "Conservative"? ? ?"Labour"? ? ? ? ? ?"Liberal Democrat"
>      ?> levels(BEPS$vote1)
>     [1] "Labour"? ? ? ? ? ?"Liberal Democrat" "Conservative"
> 
>      ?> m <- multinom(vote ~ . - vote1, data=BEPS)
>     # weights:? 33 (20 variable)
>     initial? value 1675.383740
>     iter? 10 value 1345.935273
>     iter? 20 value 1150.956807
>     iter? 30 value 1141.921662
>     iter? 30 value 1141.921661
>     iter? 30 value 1141.921661
>     final? value 1141.921661
>     converged
>      ?> m1 <- multinom(vote1 ~ . - vote, data=BEPS)
>     # weights:? 33 (20 variable)
>     initial? value 1675.383740
>     iter? 10 value 1280.439304
>     iter? 20 value 1165.513772
>     final? value 1141.921662
>     converged
> 
>      ?> rbind(coef(m), coef(m1)) # compare coefficients
>      ? ? ? ? ? ? ? ? ? (Intercept)? ? ? ? ? age economic.cond.national
>     economic.cond.household
>     Labour? ? ? ? ? ? ?0.9515214 -0.021913989? ? ? ? ? ? ? 0.5575707
>      ? ? ? 0.15839096
>     Liberal Democrat? ?1.4119306 -0.016810735? ? ? ? ? ? ? 0.1810761
>      ? ? ?-0.01196664
>     Liberal Democrat? ?0.4604567? 0.005102666? ? ? ? ? ? ?-0.3764928
>      ? ? ?-0.17036682
>     Conservative? ? ? -0.9514466? 0.021912305? ? ? ? ? ? ?-0.5575644
>      ? ? ?-0.15838744
>      ? ? ? ? ? ? ? ? ? ? ? ?Blair? ? ? ?Hague? ? Kennedy? ? ? Europe
>     political.knowledge
>     Labour? ? ? ? ? ? 0.8371764 -0.90775585? 0.2513436 -0.22781308
>     -0.5370612
>     Liberal Democrat? 0.2937331 -0.82217625? 0.6710567 -0.20004624
>     -0.2034605
>     Liberal Democrat -0.5434408? 0.08559455? 0.4197027? 0.02776465
>     0.3336068
>     Conservative? ? ?-0.8371670? 0.90778068 -0.2513735? 0.22781092
>     0.5370545
>      ? ? ? ? ? ? ? ? ? ?gendermale
>     Labour? ? ? ? ? ? 0.13765774
>     Liberal Democrat? 0.12640823
>     Liberal Democrat -0.01125898
>     Conservative? ? ?-0.13764849
> 
>      ?> c(logLik(m), logLik(m1)) # same fit to the data
>     [1] -1141.922 -1141.922
> 
>      ?> # covariance matrices for coefficients:
>      ?> V <- vcov(m)
>      ?> V1 <- vcov(m1)
>      ?> cbind(colnames(V), colnames(V1)) # compare
>      ? ? ? ?[,1]? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?[,2]
> 
>      ? [1,] "Labour:(Intercept)"? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>     Democrat:(Intercept)"
>      ? [2,] "Labour:age"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>     Democrat:age"
> 
>      ? [3,] "Labour:economic.cond.national"? ? ? ? ? ? "Liberal
>     Democrat:economic.cond.national"
>      ? [4,] "Labour:economic.cond.household"? ? ? ? ? ?"Liberal
>     Democrat:economic.cond.household"
>      ? [5,] "Labour:Blair"? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>     Democrat:Blair"
>      ? [6,] "Labour:Hague"? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>     Democrat:Hague"
>      ? [7,] "Labour:Kennedy"? ? ? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>     Democrat:Kennedy"
>      ? [8,] "Labour:Europe"? ? ? ? ? ? ? ? ? ? ? ? ? ? "Liberal
>     Democrat:Europe"
>      ? [9,] "Labour:political.knowledge"? ? ? ? ? ? ? ?"Liberal
>     Democrat:political.knowledge"
>     [10,] "Labour:gendermale"? ? ? ? ? ? ? ? ? ? ? ? "Liberal
>     Democrat:gendermale"
>     [11,] "Liberal Democrat:(Intercept)"
>     "Conservative:(Intercept)"
>     [12,] "Liberal Democrat:age"? ? ? ? ? ? ? ? ? ? ?"Conservative:age"
> 
>     [13,] "Liberal Democrat:economic.cond.national"
>     "Conservative:economic.cond.national"
>     [14,] "Liberal Democrat:economic.cond.household"
>     "Conservative:economic.cond.household"
>     [15,] "Liberal Democrat:Blair"? ? ? ? ? ? ? ? ? ?"Conservative:Blair"
> 
>     [16,] "Liberal Democrat:Hague"? ? ? ? ? ? ? ? ? ?"Conservative:Hague"
> 
>     [17,] "Liberal Democrat:Kennedy"? ? ? ? ? ? ? ? ?"Conservative:Kennedy"
> 
>     [18,] "Liberal Democrat:Europe"? ? ? ? ? ? ? ? ? "Conservative:Europe"
> 
>     [19,] "Liberal Democrat:political.knowledge"
>     "Conservative:political.knowledge"
>     [20,] "Liberal Democrat:gendermale"
>     "Conservative:gendermale"
> 
>      ?> int <- c(1, 11) # remove intercepts
>      ?> colnames(V)[int]
>     [1] "Labour:(Intercept)"? ? ? ? ? ?"Liberal Democrat:(Intercept)"
> 
>      ?> colnames(V1)[int]
>     [1] "Liberal Democrat:(Intercept)" "Conservative:(Intercept)"
>      ?> V <- V[-int, -int]
>      ?> V1 <- V1[-int, -int]
> 
>      ?> age <- c(1, 10) # locate age coefficients
>      ?> colnames(V)[age]
>     [1] "Labour:age"? ? ? ? ? ?"Liberal Democrat:age"
>      ?> colnames(V1)[age]
>     [1] "Liberal Democrat:age" "Conservative:age"
> 
>      ?> V <- cov2cor(V) # compute coefficient correlations
>      ?> V1 <- cov2cor(V1)
> 
>      ?> # compare GVIFs:
>      ?> c(det(V[age, age])*det(V[-age, -age])/det(V),
>     +? ?det(V1[age, age])*det(V1[-age, -age])/det(V1))
>     [1] 1.046232 1.046229
> 
>     --------- snip -----------
> 
>     For curiosity, I applied car::vif() and
>     performance::check_collinearity() to these models to see what they
>     would
>     do. Both returned the wrong answer. vif() produced a warning, but
>     check_collinearity() didn't:
> 
>     --------- snip -----------
> 
>      ?> car::vif(m1)
>      ? ? ? ? ? ? ? ? ? ? ?age? economic.cond.national
>     economic.cond.household
>      ? ? ? ? ? ? ? ?15.461045? ? ? ? ? ? ? ?22.137772             
>      ?16.693877
>      ? ? ? ? ? ? ? ? ? ?Blair? ? ? ? ? ? ? ? ? ?Hague               
>      ?Kennedy
>      ? ? ? ? ? ? ? ?14.681562? ? ? ? ? ? ? ? 7.483039             
>      ?15.812067
>      ? ? ? ? ? ? ? ? ? Europe? ? ?political.knowledge                 
>     gender
>      ? ? ? ? ? ? ? ? 6.502119? ? ? ? ? ? ? ? 4.219507               
>     2.313885
>     Warning message:
>     In vif.default(m1) : No intercept: vifs may not be sensible.
> 
>      ?> performance::check_collinearity(m)
>     # Check for Multicollinearity
> 
>     Low Correlation
> 
>      ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE Tolerance
>      ? ? ? ? ? ? ? ? ? ? ? age 1.72? ? ? ? ?1.31? ? ? 0.58
>      ? ?economic.cond.national 1.85? ? ? ? ?1.36? ? ? 0.54
>      ? economic.cond.household 1.86? ? ? ? ?1.37? ? ? 0.54
>      ? ? ? ? ? ? ? ? ? ? Blair 1.63? ? ? ? ?1.28? ? ? 0.61
>      ? ? ? ? ? ? ? ? ? ? Hague 1.94? ? ? ? ?1.39? ? ? 0.52
>      ? ? ? ? ? ? ? ? ? Kennedy 1.70? ? ? ? ?1.30? ? ? 0.59
>      ? ? ? ? ? ? ? ? ? ?Europe 2.01? ? ? ? ?1.42? ? ? 0.50
>      ? ? ? political.knowledge 1.94? ? ? ? ?1.39? ? ? 0.52
>      ? ? ? ? ? ? ? ? ? ?gender 1.78? ? ? ? ?1.33? ? ? 0.56
>      ?> performance::check_collinearity(m1)
>     # Check for Multicollinearity
> 
>     Low Correlation
> 
>      ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE Tolerance
>      ? ? ? ? ? ? ? ? ? ? ? age 1.19? ? ? ? ?1.09? ? ? 0.84
>      ? ?economic.cond.national 1.42? ? ? ? ?1.19? ? ? 0.70
>      ? economic.cond.household 1.32? ? ? ? ?1.15? ? ? 0.76
>      ? ? ? ? ? ? ? ? ? ? Blair 1.50? ? ? ? ?1.22? ? ? 0.67
>      ? ? ? ? ? ? ? ? ? ? Hague 1.30? ? ? ? ?1.14? ? ? 0.77
>      ? ? ? ? ? ? ? ? ? Kennedy 1.19? ? ? ? ?1.09? ? ? 0.84
>      ? ? ? ? ? ? ? ? ? ?Europe 1.34? ? ? ? ?1.16? ? ? 0.75
>      ? ? ? political.knowledge 1.30? ? ? ? ?1.14? ? ? 0.77
>      ? ? ? ? ? ? ? ? ? ?gender 1.23? ? ? ? ?1.11? ? ? 0.81
> 
>     --------- snip -----------
> 
>     I looked at the code for vif() and check_collinearity() to see where
>     they went wrong. Both failed to handle the two intercepts in the model
>     correctly -- vif() thought there was no intercept and
>     check_collinearity() just removed the first intercept but not the
>     second.
> 
>     In examining the code for check_collinearity(), I discovered a
>     couple of
>     additional disconcerting facts. First, part of the code seems to be
>     copied from vif.default(). Second, as a consequence,
>     check_collinearity() actually computes GVIFs rather than VIFs (and
>     doesn't reference either the Fox and Monette paper introducing GVIFs or
>     the car package) but doesn't seem to understand that, and, for example,
>     takes the squareroot of the GVIF (reported in the column marked
>     "Increased SE") rather than the 2p root (when there are p > 1
>     coefficients in a term).
> 
>     Here's the relevant code from the two functions (where . . . denotes
>     elided lines) -- the default method for vif() and
>     .check_collinearity(),
>     which is called by check_collinearity.default():
> 
>     --------- snip -----------
> 
>      ?> car:::vif.default
>     function (mod, ...)
>     {
>      ? ? ?. . .
>      ? ? ?v <- vcov(mod)
>      ? ? ?assign <- attr(model.matrix(mod), "assign")
>      ? ? ?if (names(coefficients(mod)[1]) == "(Intercept)") {
>      ? ? ? ? ?v <- v[-1, -1]
>      ? ? ? ? ?assign <- assign[-1]
>      ? ? ?}
>      ? ? ?else warning("No intercept: vifs may not be sensible.")
>      ? ? ?terms <- labels(terms(mod))
>      ? ? ?n.terms <- length(terms)
>      ? ? ?if (n.terms < 2)
>      ? ? ? ? ?stop("model contains fewer than 2 terms")
>      ? ? ?R <- cov2cor(v)
>      ? ? ?detR <- det(R)
>      ? ? ?. . .
>      ? ? ?for (term in 1:n.terms) {
>      ? ? ? ? ?subs <- which(assign == term)
>      ? ? ? ? ?result[term, 1] <- det(as.matrix(R[subs, subs])) *
>     det(as.matrix(R[-subs,
>      ? ? ? ? ? ? ?-subs]))/detR
>      ? ? ? ? ?result[term, 2] <- length(subs)
>      ? ? ?}
>      ? ? ?. . .
>     }
> 
>      ?> performance:::.check_collinearity
>     function (x, component, verbose = TRUE)
>     {
>      ? ? ?v <- insight::get_varcov(x, component = component, verbose =
>     FALSE)
>      ? ? ?assign <- .term_assignments(x, component, verbose = verbose)
>      ? ? ?. . .
>      ? ? ?if (insight::has_intercept(x)) {
>      ? ? ? ? ?v <- v[-1, -1]
>      ? ? ? ? ?assign <- assign[-1]
>      ? ? ?}
>      ? ? ?else {
>      ? ? ? ? ?if (isTRUE(verbose)) {
>      ? ? ? ? ? ? ?warning("Model has no intercept. VIFs may not be
>     sensible.",
>      ? ? ? ? ? ? ? ? ?call. = FALSE)
>      ? ? ? ? ?}
>      ? ? ?}
>      ? ? ? ? ?. . .
>      ? ? ? ? ?terms <- labels(stats::terms(f[[component]]))
>      ? ? ? ? ?. . .
>      ? ? ?n.terms <- length(terms)
>      ? ? ?if (n.terms < 2) {
>      ? ? ? ? ?if (isTRUE(verbose)) {
>      ? ? ? ? ? ? ?warning(insight::format_message(sprintf("Not enough model
>     terms in the %s part of the model to check for multicollinearity.",
>      ? ? ? ? ? ? ? ? ?component)), call. = FALSE)
>      ? ? ? ? ?}
>      ? ? ? ? ?return(NULL)
>      ? ? ?}
>      ? ? ?R <- stats::cov2cor(v)
>      ? ? ?detR <- det(R)
>      ? ? ?. . .
>      ? ? ?for (term in 1:n.terms) {
>      ? ? ? ? ?subs <- which(assign == term)
>      ? ? ? ? ? ? ?. . .
>      ? ? ? ? ? ? ?result <- c(result, det(as.matrix(R[subs, subs])) *
>      ? ? ? ? ? ? ? ? ?det(as.matrix(R[-subs, -subs]))/detR)
>      ? ? ? ? ? ? ?. . .
>      ? ? ?}
>      ? ? ?. . .
>     }
> 
>     --------- snip -----------
> 
>     So, the upshot of all this is that you should be able to do what you
>     want, but not with either car::vif() or
>     performance::check_collinearity(). Instead, either write your own
>     function or do the computations in a script.
> 
>     There's also a lesson here about S3 default methods: The fact that a
>     default method returns a result rather than throwing an error or a
>     warning doesn't mean that the result is the right answer.
> 
>     I hope this helps,
>      ? John
> 
> 
>     On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen wrote:
>      > Dear John W,
>      >
>      > Thank you very much for the tip-off! Apologies for not responding
>     earlier
>      > (gmail apparently decided to direct your email right into the
>     junk folder).
>      > I am very pleased to note that the package you mention does
>     indeed work
>      > with *brms* multinomial models! Thanks again!
>      >
>      > Best,
>      >
>      > Juho
>      >
>      > pe 25. helmik. 2022 klo 19.23 John Willoughby
>     (johnwillec at gmail.com <mailto:johnwillec at gmail.com>)
>      > kirjoitti:
>      >
>      >> Have you tried the check_collinearity() function in the performance
>      >> package? It's supposed to work on brms models, but whether it
>     will work on
>      >> a multinomial model I don't know.? It works well on mixed models
>     generated
>      >> by glmmTMB().
>      >>
>      >> John Willoughby
>      >>
>      >>
>      >> On Fri, Feb 25, 2022 at 3:01 AM
>     <r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >> wrote:
>      >>
>      >>> Send R-sig-mixed-models mailing list submissions to
>      >>> r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >>>
>      >>> To subscribe or unsubscribe via the World Wide Web, visit
>      >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >>> or, via email, send a message with subject or body 'help' to
>      >>> r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >>>
>      >>> You can reach the person managing the list at
>      >>> r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >>>
>      >>> When replying, please edit your Subject line so it is more specific
>      >>> than "Re: Contents of R-sig-mixed-models digest..."
>      >>>
>      >>>
>      >>> Today's Topics:
>      >>>
>      >>>? ? ?1. Collinearity diagnostics for (mixed) multinomial models
>      >>>? ? ? ? (Juho Kristian Ruohonen)
>      >>>
>      >>>
>     ----------------------------------------------------------------------
>      >>>
>      >>> Message: 1
>      >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
>      >>> From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >>> To: John Fox <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >>> Cc: "r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>"
>      >>>? ? ? ? ? <r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >>> Subject: [R-sig-ME] Collinearity diagnostics for (mixed)
>     multinomial
>      >>>? ? ? ? ? models
>      >>> Message-ID:
>      >>>? ? ? ? ? <
>      >>>
>     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
>     <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
>      >>> Content-Type: text/plain; charset="utf-8"
>      >>>
>      >>> Dear John (and anyone else qualified to comment),
>      >>>
>      >>> I fit lots of mixed-effects multinomial models in my research,
>     and I
>      >> would
>      >>> like to see some (multi)collinearity diagnostics on the fixed
>     effects, of
>      >>> which there are over 30. My models are fit using the Bayesian
>     *brms*
>      >>> package because I know of no frequentist packages with
>     multinomial GLMM
>      >>> compatibility.
>      >>>
>      >>> With continuous or dichotomous outcomes, my go-to function for
>      >> calculating
>      >>> multicollinearity diagnostics is of course *vif()* from the *car*
>      >> package.
>      >>> As expected, however, this function does not report sensible
>     diagnostics
>      >>> for multinomial models -- not even for standard ones fit by the
>     *nnet*
>      >>> package's *multinom()* function. The reason, I presume, is
>     because a
>      >>> multinomial model is not really one but C-1 regression models 
>     (where C
>      >> is
>      >>> the number of response categories) and the *vif()* function is not
>      >> designed
>      >>> to deal with this scenario.
>      >>>
>      >>> Therefore, in order to obtain meaningful collinearity metrics,
>     my present
>      >>> plan is to write a simple helper function that uses *vif() *to
>     calculate
>      >>> and present (generalized) variance inflation metrics for the C-1
>      >>> sub-datasets to which the C-1 component binomial models of the
>     overall
>      >>> multinomial model are fit. In other words, it will partition
>     the data
>      >> into
>      >>> those C-1 subsets, and then apply *vif()* to as many linear
>     regressions
>      >>> using a made-up continuous response and the fixed effects of
>     interest.
>      >>>
>      >>> Does this seem like a sensible approach?
>      >>>
>      >>> Best,
>      >>>
>      >>> Juho
>      >>>
>      >>>
>      >>>
>      >>
>      >>? ? ? ? ? [[alternative HTML version deleted]]
>      >>
>      >> _______________________________________________
>      >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >>
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
> 
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Mon Feb 28 23:00:26 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Tue, 1 Mar 2022 00:00:26 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
Message-ID: <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>

Apologies for my misreading, John, and many thanks for showing how the
calculation is done for a single term.

Do you think *vif()* might be updated in the near future with the
capability of auto-detecting a multinomial model and returning
mathematically correct GVIF statistics?

If not, I'll proceed to writing my own function based on your example.
However, *car* is such an excellent and widely used package that the
greatest benefit to mankind would probably accrue if *car *was upgraded
with this feature sooner rather than later.

Best,

Juho









ma 28. helmik. 2022 klo 17.08 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juho,
>
> On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen wrote:
> > Dear Professor Fox and other list members,
> >
> > Profuse thanks for doing that detective work for me! I myself thought
> > the inflation factors reported by check_collinearity() were suspiciously
> > high, but unlike you I lacked the expertise to identify what was going
> on.
> >
> > As for your suggested approach, have I understood this correctly:
> >
> > Since there doesn't yet exist an R function that will calculate the
> > (G)VIFS of multinomial models correctly, my best bet for now is just to
> > ignore the fact that such models partition the data into C-1 subsets,
> > and to calculate approximate GVIFs from the entire dataset at once as if
> > the response were continuous? And a simple way to do this is to
> > construct a fake continuous response, call *lm(fakeresponse ~.)*, and
> > apply *car::vif()* on the result?
>
> No, you misunderstand my suggestion, which perhaps isn't surprising
> given the length of my message. What you propose is what I suggested as
> a rough approximation *before* I confirmed that my guess of the solution
> was correct.
>
> The R code that I sent yesterday showed how to compute the GVIF for a
> multinomial regression model, and I suggested that you write either a
> script or a simple function to do that. Here's a function that will work
> for a model object that responds to vcov():
>
> GVIF <- function(model, intercepts, term){
>    # model: regression model object
>    # intercepts: row/column positions of intercepts in the coefficient
> covariance matrix
>    # term: row/column positions of the coefficients for the focal term
>    V <- vcov(model)
>    term <- colnames(V)[term]
>    V <- V[-intercepts, -intercepts]
>    V <- cov2cor(V)
>    term <- which(colnames(V) %in% term)
>    gvif <- det(V[term, term])*det(V[-term, -term])/det(V)
>    c(GVIF=gvif, "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
> }
>
> and here's an application to the multinom() example that I showed you
> yesterday:
>
>  > colnames(vcov(m)) # to get coefficient positions
>   [1] "Labour:(Intercept)"                       "Labour:age"
>
>   [3] "Labour:economic.cond.national"
> "Labour:economic.cond.household"
>   [5] "Labour:Blair"                             "Labour:Hague"
>
>   [7] "Labour:Kennedy"                           "Labour:Europe"
>
>   [9] "Labour:political.knowledge"               "Labour:gendermale"
>
> [11] "Liberal Democrat:(Intercept)"             "Liberal Democrat:age"
>
> [13] "Liberal Democrat:economic.cond.national"  "Liberal
> Democrat:economic.cond.household"
> [15] "Liberal Democrat:Blair"                   "Liberal Democrat:Hague"
>
> [17] "Liberal Democrat:Kennedy"                 "Liberal
> Democrat:Europe"
> [19] "Liberal Democrat:political.knowledge"     "Liberal
> Democrat:gendermale"
>
>  > GVIF(m, intercepts=c(1, 11), term=c(2, 12)) # GVIF for age
>            GVIF GVIF^(1/(2*p))
>        1.046232       1.011363
>
>
> Finally, here's what you get for a linear model with the same RHS (where
> the sqrt(VIF) should be a rough approximation to GVIF^(1/4) reported by
> my GVIF() function):
>
>  > m.lm <- lm(as.numeric(vote) ~ . - vote1, data=BEPS)
>  > sqrt(car::vif(m.lm))
>                      age  economic.cond.national economic.cond.household
>                    Blair
>                 1.006508                1.124132                1.075656
>                 1.118441
>                    Hague                 Kennedy                  Europe
>      political.knowledge
>                 1.066799                1.015532                1.101741
>                 1.028546
>                   gender
>                 1.017386
>
>
> John
>
> >
> > Best,
> >
> > Juho
> >
> > ma 28. helmik. 2022 klo 2.23 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Juho,
> >
> >     I've now had a chance to think about this problem some more, and I
> >     believe that the approach I suggested is correct. I also had an
> >     opportunity to talk the problem over a bit with Georges Monette, who
> >     coauthored the paper that introduced generalized variance inflation
> >     factors (GVIFs). On the other hand, the results produced by
> >     performance::check_collinearity() for multinomial logit models don't
> >     seem to be correct (see below).
> >
> >     Here's an example, using the nnet::multinom() function to fit a
> >     multinomial logit model, with alternative parametrizations of the
> >     LHS of
> >     the model:
> >
> >     --------- snip -----------
> >
> >       > library(nnet) # for multinom()
> >       > library(carData) # for BEPS data set
> >
> >       > # alternative ordering of the response levels:
> >       > BEPS$vote1 <- factor(BEPS$vote, levels=c("Labour", "Liberal
> >     Democrat", "Conservative"))
> >       > levels(BEPS$vote)
> >     [1] "Conservative"     "Labour"           "Liberal Democrat"
> >       > levels(BEPS$vote1)
> >     [1] "Labour"           "Liberal Democrat" "Conservative"
> >
> >       > m <- multinom(vote ~ . - vote1, data=BEPS)
> >     # weights:  33 (20 variable)
> >     initial  value 1675.383740
> >     iter  10 value 1345.935273
> >     iter  20 value 1150.956807
> >     iter  30 value 1141.921662
> >     iter  30 value 1141.921661
> >     iter  30 value 1141.921661
> >     final  value 1141.921661
> >     converged
> >       > m1 <- multinom(vote1 ~ . - vote, data=BEPS)
> >     # weights:  33 (20 variable)
> >     initial  value 1675.383740
> >     iter  10 value 1280.439304
> >     iter  20 value 1165.513772
> >     final  value 1141.921662
> >     converged
> >
> >       > rbind(coef(m), coef(m1)) # compare coefficients
> >                        (Intercept)          age economic.cond.national
> >     economic.cond.household
> >     Labour             0.9515214 -0.021913989              0.5575707
> >            0.15839096
> >     Liberal Democrat   1.4119306 -0.016810735              0.1810761
> >           -0.01196664
> >     Liberal Democrat   0.4604567  0.005102666             -0.3764928
> >           -0.17036682
> >     Conservative      -0.9514466  0.021912305             -0.5575644
> >           -0.15838744
> >                             Blair       Hague    Kennedy      Europe
> >     political.knowledge
> >     Labour            0.8371764 -0.90775585  0.2513436 -0.22781308
> >     -0.5370612
> >     Liberal Democrat  0.2937331 -0.82217625  0.6710567 -0.20004624
> >     -0.2034605
> >     Liberal Democrat -0.5434408  0.08559455  0.4197027  0.02776465
> >     0.3336068
> >     Conservative     -0.8371670  0.90778068 -0.2513735  0.22781092
> >     0.5370545
> >                         gendermale
> >     Labour            0.13765774
> >     Liberal Democrat  0.12640823
> >     Liberal Democrat -0.01125898
> >     Conservative     -0.13764849
> >
> >       > c(logLik(m), logLik(m1)) # same fit to the data
> >     [1] -1141.922 -1141.922
> >
> >       > # covariance matrices for coefficients:
> >       > V <- vcov(m)
> >       > V1 <- vcov(m1)
> >       > cbind(colnames(V), colnames(V1)) # compare
> >             [,1]                                       [,2]
> >
> >        [1,] "Labour:(Intercept)"                       "Liberal
> >     Democrat:(Intercept)"
> >        [2,] "Labour:age"                               "Liberal
> >     Democrat:age"
> >
> >        [3,] "Labour:economic.cond.national"            "Liberal
> >     Democrat:economic.cond.national"
> >        [4,] "Labour:economic.cond.household"           "Liberal
> >     Democrat:economic.cond.household"
> >        [5,] "Labour:Blair"                             "Liberal
> >     Democrat:Blair"
> >        [6,] "Labour:Hague"                             "Liberal
> >     Democrat:Hague"
> >        [7,] "Labour:Kennedy"                           "Liberal
> >     Democrat:Kennedy"
> >        [8,] "Labour:Europe"                            "Liberal
> >     Democrat:Europe"
> >        [9,] "Labour:political.knowledge"               "Liberal
> >     Democrat:political.knowledge"
> >     [10,] "Labour:gendermale"                        "Liberal
> >     Democrat:gendermale"
> >     [11,] "Liberal Democrat:(Intercept)"
> >     "Conservative:(Intercept)"
> >     [12,] "Liberal Democrat:age"                     "Conservative:age"
> >
> >     [13,] "Liberal Democrat:economic.cond.national"
> >     "Conservative:economic.cond.national"
> >     [14,] "Liberal Democrat:economic.cond.household"
> >     "Conservative:economic.cond.household"
> >     [15,] "Liberal Democrat:Blair"                   "Conservative:Blair"
> >
> >     [16,] "Liberal Democrat:Hague"                   "Conservative:Hague"
> >
> >     [17,] "Liberal Democrat:Kennedy"
>  "Conservative:Kennedy"
> >
> >     [18,] "Liberal Democrat:Europe"
> "Conservative:Europe"
> >
> >     [19,] "Liberal Democrat:political.knowledge"
> >     "Conservative:political.knowledge"
> >     [20,] "Liberal Democrat:gendermale"
> >     "Conservative:gendermale"
> >
> >       > int <- c(1, 11) # remove intercepts
> >       > colnames(V)[int]
> >     [1] "Labour:(Intercept)"           "Liberal Democrat:(Intercept)"
> >
> >       > colnames(V1)[int]
> >     [1] "Liberal Democrat:(Intercept)" "Conservative:(Intercept)"
> >       > V <- V[-int, -int]
> >       > V1 <- V1[-int, -int]
> >
> >       > age <- c(1, 10) # locate age coefficients
> >       > colnames(V)[age]
> >     [1] "Labour:age"           "Liberal Democrat:age"
> >       > colnames(V1)[age]
> >     [1] "Liberal Democrat:age" "Conservative:age"
> >
> >       > V <- cov2cor(V) # compute coefficient correlations
> >       > V1 <- cov2cor(V1)
> >
> >       > # compare GVIFs:
> >       > c(det(V[age, age])*det(V[-age, -age])/det(V),
> >     +   det(V1[age, age])*det(V1[-age, -age])/det(V1))
> >     [1] 1.046232 1.046229
> >
> >     --------- snip -----------
> >
> >     For curiosity, I applied car::vif() and
> >     performance::check_collinearity() to these models to see what they
> >     would
> >     do. Both returned the wrong answer. vif() produced a warning, but
> >     check_collinearity() didn't:
> >
> >     --------- snip -----------
> >
> >       > car::vif(m1)
> >                           age  economic.cond.national
> >     economic.cond.household
> >                     15.461045               22.137772
> >       16.693877
> >                         Blair                   Hague
> >       Kennedy
> >                     14.681562                7.483039
> >       15.812067
> >                        Europe     political.knowledge
> >     gender
> >                      6.502119                4.219507
> >     2.313885
> >     Warning message:
> >     In vif.default(m1) : No intercept: vifs may not be sensible.
> >
> >       > performance::check_collinearity(m)
> >     # Check for Multicollinearity
> >
> >     Low Correlation
> >
> >                           Term  VIF Increased SE Tolerance
> >                            age 1.72         1.31      0.58
> >         economic.cond.national 1.85         1.36      0.54
> >        economic.cond.household 1.86         1.37      0.54
> >                          Blair 1.63         1.28      0.61
> >                          Hague 1.94         1.39      0.52
> >                        Kennedy 1.70         1.30      0.59
> >                         Europe 2.01         1.42      0.50
> >            political.knowledge 1.94         1.39      0.52
> >                         gender 1.78         1.33      0.56
> >       > performance::check_collinearity(m1)
> >     # Check for Multicollinearity
> >
> >     Low Correlation
> >
> >                           Term  VIF Increased SE Tolerance
> >                            age 1.19         1.09      0.84
> >         economic.cond.national 1.42         1.19      0.70
> >        economic.cond.household 1.32         1.15      0.76
> >                          Blair 1.50         1.22      0.67
> >                          Hague 1.30         1.14      0.77
> >                        Kennedy 1.19         1.09      0.84
> >                         Europe 1.34         1.16      0.75
> >            political.knowledge 1.30         1.14      0.77
> >                         gender 1.23         1.11      0.81
> >
> >     --------- snip -----------
> >
> >     I looked at the code for vif() and check_collinearity() to see where
> >     they went wrong. Both failed to handle the two intercepts in the
> model
> >     correctly -- vif() thought there was no intercept and
> >     check_collinearity() just removed the first intercept but not the
> >     second.
> >
> >     In examining the code for check_collinearity(), I discovered a
> >     couple of
> >     additional disconcerting facts. First, part of the code seems to be
> >     copied from vif.default(). Second, as a consequence,
> >     check_collinearity() actually computes GVIFs rather than VIFs (and
> >     doesn't reference either the Fox and Monette paper introducing GVIFs
> or
> >     the car package) but doesn't seem to understand that, and, for
> example,
> >     takes the squareroot of the GVIF (reported in the column marked
> >     "Increased SE") rather than the 2p root (when there are p > 1
> >     coefficients in a term).
> >
> >     Here's the relevant code from the two functions (where . . . denotes
> >     elided lines) -- the default method for vif() and
> >     .check_collinearity(),
> >     which is called by check_collinearity.default():
> >
> >     --------- snip -----------
> >
> >       > car:::vif.default
> >     function (mod, ...)
> >     {
> >           . . .
> >           v <- vcov(mod)
> >           assign <- attr(model.matrix(mod), "assign")
> >           if (names(coefficients(mod)[1]) == "(Intercept)") {
> >               v <- v[-1, -1]
> >               assign <- assign[-1]
> >           }
> >           else warning("No intercept: vifs may not be sensible.")
> >           terms <- labels(terms(mod))
> >           n.terms <- length(terms)
> >           if (n.terms < 2)
> >               stop("model contains fewer than 2 terms")
> >           R <- cov2cor(v)
> >           detR <- det(R)
> >           . . .
> >           for (term in 1:n.terms) {
> >               subs <- which(assign == term)
> >               result[term, 1] <- det(as.matrix(R[subs, subs])) *
> >     det(as.matrix(R[-subs,
> >                   -subs]))/detR
> >               result[term, 2] <- length(subs)
> >           }
> >           . . .
> >     }
> >
> >       > performance:::.check_collinearity
> >     function (x, component, verbose = TRUE)
> >     {
> >           v <- insight::get_varcov(x, component = component, verbose =
> >     FALSE)
> >           assign <- .term_assignments(x, component, verbose = verbose)
> >           . . .
> >           if (insight::has_intercept(x)) {
> >               v <- v[-1, -1]
> >               assign <- assign[-1]
> >           }
> >           else {
> >               if (isTRUE(verbose)) {
> >                   warning("Model has no intercept. VIFs may not be
> >     sensible.",
> >                       call. = FALSE)
> >               }
> >           }
> >               . . .
> >               terms <- labels(stats::terms(f[[component]]))
> >               . . .
> >           n.terms <- length(terms)
> >           if (n.terms < 2) {
> >               if (isTRUE(verbose)) {
> >                   warning(insight::format_message(sprintf("Not enough
> model
> >     terms in the %s part of the model to check for multicollinearity.",
> >                       component)), call. = FALSE)
> >               }
> >               return(NULL)
> >           }
> >           R <- stats::cov2cor(v)
> >           detR <- det(R)
> >           . . .
> >           for (term in 1:n.terms) {
> >               subs <- which(assign == term)
> >                   . . .
> >                   result <- c(result, det(as.matrix(R[subs, subs])) *
> >                       det(as.matrix(R[-subs, -subs]))/detR)
> >                   . . .
> >           }
> >           . . .
> >     }
> >
> >     --------- snip -----------
> >
> >     So, the upshot of all this is that you should be able to do what you
> >     want, but not with either car::vif() or
> >     performance::check_collinearity(). Instead, either write your own
> >     function or do the computations in a script.
> >
> >     There's also a lesson here about S3 default methods: The fact that a
> >     default method returns a result rather than throwing an error or a
> >     warning doesn't mean that the result is the right answer.
> >
> >     I hope this helps,
> >        John
> >
> >
> >     On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen wrote:
> >      > Dear John W,
> >      >
> >      > Thank you very much for the tip-off! Apologies for not responding
> >     earlier
> >      > (gmail apparently decided to direct your email right into the
> >     junk folder).
> >      > I am very pleased to note that the package you mention does
> >     indeed work
> >      > with *brms* multinomial models! Thanks again!
> >      >
> >      > Best,
> >      >
> >      > Juho
> >      >
> >      > pe 25. helmik. 2022 klo 19.23 John Willoughby
> >     (johnwillec at gmail.com <mailto:johnwillec at gmail.com>)
> >      > kirjoitti:
> >      >
> >      >> Have you tried the check_collinearity() function in the
> performance
> >      >> package? It's supposed to work on brms models, but whether it
> >     will work on
> >      >> a multinomial model I don't know.  It works well on mixed models
> >     generated
> >      >> by glmmTMB().
> >      >>
> >      >> John Willoughby
> >      >>
> >      >>
> >      >> On Fri, Feb 25, 2022 at 3:01 AM
> >     <r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >> wrote:
> >      >>
> >      >>> Send R-sig-mixed-models mailing list submissions to
> >      >>> r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>
> >      >>> To subscribe or unsubscribe via the World Wide Web, visit
> >      >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>> or, via email, send a message with subject or body 'help' to
> >      >>> r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>
> >      >>> You can reach the person managing the list at
> >      >>> r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>
> >      >>> When replying, please edit your Subject line so it is more
> specific
> >      >>> than "Re: Contents of R-sig-mixed-models digest..."
> >      >>>
> >      >>>
> >      >>> Today's Topics:
> >      >>>
> >      >>>     1. Collinearity diagnostics for (mixed) multinomial models
> >      >>>        (Juho Kristian Ruohonen)
> >      >>>
> >      >>>
> >
>  ----------------------------------------------------------------------
> >      >>>
> >      >>> Message: 1
> >      >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
> >      >>> From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>> To: John Fox <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>> Cc: "r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>"
> >      >>>          <r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>> Subject: [R-sig-ME] Collinearity diagnostics for (mixed)
> >     multinomial
> >      >>>          models
> >      >>> Message-ID:
> >      >>>          <
> >      >>>
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
> >      >>> Content-Type: text/plain; charset="utf-8"
> >      >>>
> >      >>> Dear John (and anyone else qualified to comment),
> >      >>>
> >      >>> I fit lots of mixed-effects multinomial models in my research,
> >     and I
> >      >> would
> >      >>> like to see some (multi)collinearity diagnostics on the fixed
> >     effects, of
> >      >>> which there are over 30. My models are fit using the Bayesian
> >     *brms*
> >      >>> package because I know of no frequentist packages with
> >     multinomial GLMM
> >      >>> compatibility.
> >      >>>
> >      >>> With continuous or dichotomous outcomes, my go-to function for
> >      >> calculating
> >      >>> multicollinearity diagnostics is of course *vif()* from the
> *car*
> >      >> package.
> >      >>> As expected, however, this function does not report sensible
> >     diagnostics
> >      >>> for multinomial models -- not even for standard ones fit by the
> >     *nnet*
> >      >>> package's *multinom()* function. The reason, I presume, is
> >     because a
> >      >>> multinomial model is not really one but C-1 regression models
> >     (where C
> >      >> is
> >      >>> the number of response categories) and the *vif()* function is
> not
> >      >> designed
> >      >>> to deal with this scenario.
> >      >>>
> >      >>> Therefore, in order to obtain meaningful collinearity metrics,
> >     my present
> >      >>> plan is to write a simple helper function that uses *vif() *to
> >     calculate
> >      >>> and present (generalized) variance inflation metrics for the C-1
> >      >>> sub-datasets to which the C-1 component binomial models of the
> >     overall
> >      >>> multinomial model are fit. In other words, it will partition
> >     the data
> >      >> into
> >      >>> those C-1 subsets, and then apply *vif()* to as many linear
> >     regressions
> >      >>> using a made-up continuous response and the fixed effects of
> >     interest.
> >      >>>
> >      >>> Does this seem like a sensible approach?
> >      >>>
> >      >>> Best,
> >      >>>
> >      >>> Juho
> >      >>>
> >      >>>
> >      >>>
> >      >>
> >      >>          [[alternative HTML version deleted]]
> >      >>
> >      >> _______________________________________________
> >      >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Feb 28 23:05:45 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 28 Feb 2022 17:05:45 -0500
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
Message-ID: <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>

Dear Juha,

On 2022-02-28 5:00 p.m., Juho Kristian Ruohonen wrote:
> Apologies for my misreading, John, and many thanks for showing how the 
> calculation is done for a single term.
> 
> Do you think *vif()* might be updated in the near future with the 
> capability of auto-detecting a multinomial model and returning 
> mathematically correct GVIF statistics?

The thought crossed my mind, but I'd want to do it in a general way, not 
just for the multinom() function, and in a way that avoids incorrect 
results such as those currently produced for "multinom" models, albeit 
with a warning. I can't guarantee whether or when I'll be able to do that.

John

> 
> If not, I'll proceed to writing my own function based on your example. 
> However, /car/ is such an excellent and widely used package that the 
> greatest benefit to mankind would probably accrue if /car /was upgraded 
> with this feature sooner rather than later.
> 
> Best,
> 
> Juho
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ma 28. helmik. 2022 klo 17.08 John Fox (jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>) kirjoitti:
> 
>     Dear Juho,
> 
>     On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen wrote:
>      > Dear Professor Fox and other list members,
>      >
>      > Profuse thanks for doing that detective work for me! I myself
>     thought
>      > the inflation factors reported by check_collinearity() were
>     suspiciously
>      > high, but unlike you I lacked the expertise to identify what was
>     going on.
>      >
>      > As for your suggested approach, have I understood this correctly:
>      >
>      > Since there doesn't yet exist an R function that will calculate the
>      > (G)VIFS of multinomial models correctly, my best bet for now is
>     just to
>      > ignore the fact that such models partition the data into C-1
>     subsets,
>      > and to calculate approximate GVIFs from the entire dataset at
>     once as if
>      > the response were continuous? And a simple way to do this is to
>      > construct a fake continuous response, call *lm(fakeresponse ~.)*,
>     and
>      > apply *car::vif()* on the result?
> 
>     No, you misunderstand my suggestion, which perhaps isn't surprising
>     given the length of my message. What you propose is what I suggested as
>     a rough approximation *before* I confirmed that my guess of the
>     solution
>     was correct.
> 
>     The R code that I sent yesterday showed how to compute the GVIF for a
>     multinomial regression model, and I suggested that you write either a
>     script or a simple function to do that. Here's a function that will
>     work
>     for a model object that responds to vcov():
> 
>     GVIF <- function(model, intercepts, term){
>      ? ?# model: regression model object
>      ? ?# intercepts: row/column positions of intercepts in the coefficient
>     covariance matrix
>      ? ?# term: row/column positions of the coefficients for the focal term
>      ? ?V <- vcov(model)
>      ? ?term <- colnames(V)[term]
>      ? ?V <- V[-intercepts, -intercepts]
>      ? ?V <- cov2cor(V)
>      ? ?term <- which(colnames(V) %in% term)
>      ? ?gvif <- det(V[term, term])*det(V[-term, -term])/det(V)
>      ? ?c(GVIF=gvif, "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
>     }
> 
>     and here's an application to the multinom() example that I showed you
>     yesterday:
> 
>      ?> colnames(vcov(m)) # to get coefficient positions
>      ? [1] "Labour:(Intercept)"? ? ? ? ? ? ? ? ? ? ? ?"Labour:age"
> 
>      ? [3] "Labour:economic.cond.national"
>     "Labour:economic.cond.household"
>      ? [5] "Labour:Blair"? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"Labour:Hague"
> 
>      ? [7] "Labour:Kennedy"? ? ? ? ? ? ? ? ? ? ? ? ? ?"Labour:Europe"
> 
>      ? [9] "Labour:political.knowledge"? ? ? ? ? ? ? ?"Labour:gendermale"
> 
>     [11] "Liberal Democrat:(Intercept)"? ? ? ? ? ? ?"Liberal Democrat:age"
> 
>     [13] "Liberal Democrat:economic.cond.national"? "Liberal
>     Democrat:economic.cond.household"
>     [15] "Liberal Democrat:Blair"? ? ? ? ? ? ? ? ? ?"Liberal
>     Democrat:Hague"
> 
>     [17] "Liberal Democrat:Kennedy"? ? ? ? ? ? ? ? ?"Liberal
>     Democrat:Europe"
>     [19] "Liberal Democrat:political.knowledge"? ? ?"Liberal
>     Democrat:gendermale"
> 
>      ?> GVIF(m, intercepts=c(1, 11), term=c(2, 12)) # GVIF for age
>      ? ? ? ? ? ?GVIF GVIF^(1/(2*p))
>      ? ? ? ?1.046232? ? ? ?1.011363
> 
> 
>     Finally, here's what you get for a linear model with the same RHS
>     (where
>     the sqrt(VIF) should be a rough approximation to GVIF^(1/4) reported by
>     my GVIF() function):
> 
>      ?> m.lm <- lm(as.numeric(vote) ~ . - vote1, data=BEPS)
>      ?> sqrt(car::vif(m.lm))
>      ? ? ? ? ? ? ? ? ? ? ?age? economic.cond.national
>     economic.cond.household
>      ? ? ? ? ? ? ? ? ? ?Blair
>      ? ? ? ? ? ? ? ? 1.006508? ? ? ? ? ? ? ? 1.124132               
>     1.075656
>      ? ? ? ? ? ? ? ? 1.118441
>      ? ? ? ? ? ? ? ? ? ?Hague? ? ? ? ? ? ? ? ?Kennedy                 
>     Europe
>      ? ? ?political.knowledge
>      ? ? ? ? ? ? ? ? 1.066799? ? ? ? ? ? ? ? 1.015532               
>     1.101741
>      ? ? ? ? ? ? ? ? 1.028546
>      ? ? ? ? ? ? ? ? ? gender
>      ? ? ? ? ? ? ? ? 1.017386
> 
> 
>     John
> 
>      >
>      > Best,
>      >
>      > Juho
>      >
>      > ma 28. helmik. 2022 klo 2.23 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
>      >
>      >? ? ?Dear Juho,
>      >
>      >? ? ?I've now had a chance to think about this problem some more,
>     and I
>      >? ? ?believe that the approach I suggested is correct. I also had an
>      >? ? ?opportunity to talk the problem over a bit with Georges
>     Monette, who
>      >? ? ?coauthored the paper that introduced generalized variance
>     inflation
>      >? ? ?factors (GVIFs). On the other hand, the results produced by
>      >? ? ?performance::check_collinearity() for multinomial logit
>     models don't
>      >? ? ?seem to be correct (see below).
>      >
>      >? ? ?Here's an example, using the nnet::multinom() function to fit a
>      >? ? ?multinomial logit model, with alternative parametrizations of the
>      >? ? ?LHS of
>      >? ? ?the model:
>      >
>      >? ? ?--------- snip -----------
>      >
>      >? ? ? ?> library(nnet) # for multinom()
>      >? ? ? ?> library(carData) # for BEPS data set
>      >
>      >? ? ? ?> # alternative ordering of the response levels:
>      >? ? ? ?> BEPS$vote1 <- factor(BEPS$vote, levels=c("Labour", "Liberal
>      >? ? ?Democrat", "Conservative"))
>      >? ? ? ?> levels(BEPS$vote)
>      >? ? ?[1] "Conservative"? ? ?"Labour"? ? ? ? ? ?"Liberal Democrat"
>      >? ? ? ?> levels(BEPS$vote1)
>      >? ? ?[1] "Labour"? ? ? ? ? ?"Liberal Democrat" "Conservative"
>      >
>      >? ? ? ?> m <- multinom(vote ~ . - vote1, data=BEPS)
>      >? ? ?# weights:? 33 (20 variable)
>      >? ? ?initial? value 1675.383740
>      >? ? ?iter? 10 value 1345.935273
>      >? ? ?iter? 20 value 1150.956807
>      >? ? ?iter? 30 value 1141.921662
>      >? ? ?iter? 30 value 1141.921661
>      >? ? ?iter? 30 value 1141.921661
>      >? ? ?final? value 1141.921661
>      >? ? ?converged
>      >? ? ? ?> m1 <- multinom(vote1 ~ . - vote, data=BEPS)
>      >? ? ?# weights:? 33 (20 variable)
>      >? ? ?initial? value 1675.383740
>      >? ? ?iter? 10 value 1280.439304
>      >? ? ?iter? 20 value 1165.513772
>      >? ? ?final? value 1141.921662
>      >? ? ?converged
>      >
>      >? ? ? ?> rbind(coef(m), coef(m1)) # compare coefficients
>      >? ? ? ? ? ? ? ? ? ? ? ? (Intercept)? ? ? ? ? age
>     economic.cond.national
>      >? ? ?economic.cond.household
>      >? ? ?Labour? ? ? ? ? ? ?0.9515214 -0.021913989? ? ? ? ? ? ? 0.5575707
>      >? ? ? ? ? ? 0.15839096
>      >? ? ?Liberal Democrat? ?1.4119306 -0.016810735? ? ? ? ? ? ? 0.1810761
>      >? ? ? ? ? ?-0.01196664
>      >? ? ?Liberal Democrat? ?0.4604567? 0.005102666? ? ? ? ? ? ?-0.3764928
>      >? ? ? ? ? ?-0.17036682
>      >? ? ?Conservative? ? ? -0.9514466? 0.021912305? ? ? ? ? ? ?-0.5575644
>      >? ? ? ? ? ?-0.15838744
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Blair? ? ? ?Hague? ? Kennedy? ? ? Europe
>      >? ? ?political.knowledge
>      >? ? ?Labour? ? ? ? ? ? 0.8371764 -0.90775585? 0.2513436 -0.22781308
>      >? ? ?-0.5370612
>      >? ? ?Liberal Democrat? 0.2937331 -0.82217625? 0.6710567 -0.20004624
>      >? ? ?-0.2034605
>      >? ? ?Liberal Democrat -0.5434408? 0.08559455? 0.4197027? 0.02776465
>      >? ? ?0.3336068
>      >? ? ?Conservative? ? ?-0.8371670? 0.90778068 -0.2513735? 0.22781092
>      >? ? ?0.5370545
>      >? ? ? ? ? ? ? ? ? ? ? ? ?gendermale
>      >? ? ?Labour? ? ? ? ? ? 0.13765774
>      >? ? ?Liberal Democrat? 0.12640823
>      >? ? ?Liberal Democrat -0.01125898
>      >? ? ?Conservative? ? ?-0.13764849
>      >
>      >? ? ? ?> c(logLik(m), logLik(m1)) # same fit to the data
>      >? ? ?[1] -1141.922 -1141.922
>      >
>      >? ? ? ?> # covariance matrices for coefficients:
>      >? ? ? ?> V <- vcov(m)
>      >? ? ? ?> V1 <- vcov(m1)
>      >? ? ? ?> cbind(colnames(V), colnames(V1)) # compare
>      >? ? ? ? ? ? ?[,1]? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?[,2]
>      >
>      >? ? ? ? [1,] "Labour:(Intercept)"? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:(Intercept)"
>      >? ? ? ? [2,] "Labour:age"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:age"
>      >
>      >? ? ? ? [3,] "Labour:economic.cond.national"? ? ? ? ? ? "Liberal
>      >? ? ?Democrat:economic.cond.national"
>      >? ? ? ? [4,] "Labour:economic.cond.household"? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:economic.cond.household"
>      >? ? ? ? [5,] "Labour:Blair"? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:Blair"
>      >? ? ? ? [6,] "Labour:Hague"? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:Hague"
>      >? ? ? ? [7,] "Labour:Kennedy"? ? ? ? ? ? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:Kennedy"
>      >? ? ? ? [8,] "Labour:Europe"? ? ? ? ? ? ? ? ? ? ? ? ? ? "Liberal
>      >? ? ?Democrat:Europe"
>      >? ? ? ? [9,] "Labour:political.knowledge"? ? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:political.knowledge"
>      >? ? ?[10,] "Labour:gendermale"? ? ? ? ? ? ? ? ? ? ? ? "Liberal
>      >? ? ?Democrat:gendermale"
>      >? ? ?[11,] "Liberal Democrat:(Intercept)"
>      >? ? ?"Conservative:(Intercept)"
>      >? ? ?[12,] "Liberal Democrat:age"                   
>      ?"Conservative:age"
>      >
>      >? ? ?[13,] "Liberal Democrat:economic.cond.national"
>      >? ? ?"Conservative:economic.cond.national"
>      >? ? ?[14,] "Liberal Democrat:economic.cond.household"
>      >? ? ?"Conservative:economic.cond.household"
>      >? ? ?[15,] "Liberal Democrat:Blair"                 
>      ?"Conservative:Blair"
>      >
>      >? ? ?[16,] "Liberal Democrat:Hague"                 
>      ?"Conservative:Hague"
>      >
>      >? ? ?[17,] "Liberal Democrat:Kennedy"               
>      ?"Conservative:Kennedy"
>      >
>      >? ? ?[18,] "Liberal Democrat:Europe"                 
>     "Conservative:Europe"
>      >
>      >? ? ?[19,] "Liberal Democrat:political.knowledge"
>      >? ? ?"Conservative:political.knowledge"
>      >? ? ?[20,] "Liberal Democrat:gendermale"
>      >? ? ?"Conservative:gendermale"
>      >
>      >? ? ? ?> int <- c(1, 11) # remove intercepts
>      >? ? ? ?> colnames(V)[int]
>      >? ? ?[1] "Labour:(Intercept)"? ? ? ? ? ?"Liberal Democrat:(Intercept)"
>      >
>      >? ? ? ?> colnames(V1)[int]
>      >? ? ?[1] "Liberal Democrat:(Intercept)" "Conservative:(Intercept)"
>      >? ? ? ?> V <- V[-int, -int]
>      >? ? ? ?> V1 <- V1[-int, -int]
>      >
>      >? ? ? ?> age <- c(1, 10) # locate age coefficients
>      >? ? ? ?> colnames(V)[age]
>      >? ? ?[1] "Labour:age"? ? ? ? ? ?"Liberal Democrat:age"
>      >? ? ? ?> colnames(V1)[age]
>      >? ? ?[1] "Liberal Democrat:age" "Conservative:age"
>      >
>      >? ? ? ?> V <- cov2cor(V) # compute coefficient correlations
>      >? ? ? ?> V1 <- cov2cor(V1)
>      >
>      >? ? ? ?> # compare GVIFs:
>      >? ? ? ?> c(det(V[age, age])*det(V[-age, -age])/det(V),
>      >? ? ?+? ?det(V1[age, age])*det(V1[-age, -age])/det(V1))
>      >? ? ?[1] 1.046232 1.046229
>      >
>      >? ? ?--------- snip -----------
>      >
>      >? ? ?For curiosity, I applied car::vif() and
>      >? ? ?performance::check_collinearity() to these models to see what
>     they
>      >? ? ?would
>      >? ? ?do. Both returned the wrong answer. vif() produced a warning, but
>      >? ? ?check_collinearity() didn't:
>      >
>      >? ? ?--------- snip -----------
>      >
>      >? ? ? ?> car::vif(m1)
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ?age? economic.cond.national
>      >? ? ?economic.cond.household
>      >? ? ? ? ? ? ? ? ? ? ?15.461045? ? ? ? ? ? ? ?22.137772
>      >? ? ? ?16.693877
>      >? ? ? ? ? ? ? ? ? ? ? ? ?Blair? ? ? ? ? ? ? ? ? ?Hague
>      >? ? ? ?Kennedy
>      >? ? ? ? ? ? ? ? ? ? ?14.681562? ? ? ? ? ? ? ? 7.483039
>      >? ? ? ?15.812067
>      >? ? ? ? ? ? ? ? ? ? ? ? Europe? ? ?political.knowledge
>      >? ? ?gender
>      >? ? ? ? ? ? ? ? ? ? ? 6.502119? ? ? ? ? ? ? ? 4.219507
>      >? ? ?2.313885
>      >? ? ?Warning message:
>      >? ? ?In vif.default(m1) : No intercept: vifs may not be sensible.
>      >
>      >? ? ? ?> performance::check_collinearity(m)
>      >? ? ?# Check for Multicollinearity
>      >
>      >? ? ?Low Correlation
>      >
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE Tolerance
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? age 1.72? ? ? ? ?1.31? ? ? 0.58
>      >? ? ? ? ?economic.cond.national 1.85? ? ? ? ?1.36? ? ? 0.54
>      >? ? ? ? economic.cond.household 1.86? ? ? ? ?1.37? ? ? 0.54
>      >? ? ? ? ? ? ? ? ? ? ? ? ? Blair 1.63? ? ? ? ?1.28? ? ? 0.61
>      >? ? ? ? ? ? ? ? ? ? ? ? ? Hague 1.94? ? ? ? ?1.39? ? ? 0.52
>      >? ? ? ? ? ? ? ? ? ? ? ? Kennedy 1.70? ? ? ? ?1.30? ? ? 0.59
>      >? ? ? ? ? ? ? ? ? ? ? ? ?Europe 2.01? ? ? ? ?1.42? ? ? 0.50
>      >? ? ? ? ? ? political.knowledge 1.94? ? ? ? ?1.39? ? ? 0.52
>      >? ? ? ? ? ? ? ? ? ? ? ? ?gender 1.78? ? ? ? ?1.33? ? ? 0.56
>      >? ? ? ?> performance::check_collinearity(m1)
>      >? ? ?# Check for Multicollinearity
>      >
>      >? ? ?Low Correlation
>      >
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE Tolerance
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? age 1.19? ? ? ? ?1.09? ? ? 0.84
>      >? ? ? ? ?economic.cond.national 1.42? ? ? ? ?1.19? ? ? 0.70
>      >? ? ? ? economic.cond.household 1.32? ? ? ? ?1.15? ? ? 0.76
>      >? ? ? ? ? ? ? ? ? ? ? ? ? Blair 1.50? ? ? ? ?1.22? ? ? 0.67
>      >? ? ? ? ? ? ? ? ? ? ? ? ? Hague 1.30? ? ? ? ?1.14? ? ? 0.77
>      >? ? ? ? ? ? ? ? ? ? ? ? Kennedy 1.19? ? ? ? ?1.09? ? ? 0.84
>      >? ? ? ? ? ? ? ? ? ? ? ? ?Europe 1.34? ? ? ? ?1.16? ? ? 0.75
>      >? ? ? ? ? ? political.knowledge 1.30? ? ? ? ?1.14? ? ? 0.77
>      >? ? ? ? ? ? ? ? ? ? ? ? ?gender 1.23? ? ? ? ?1.11? ? ? 0.81
>      >
>      >? ? ?--------- snip -----------
>      >
>      >? ? ?I looked at the code for vif() and check_collinearity() to
>     see where
>      >? ? ?they went wrong. Both failed to handle the two intercepts in
>     the model
>      >? ? ?correctly -- vif() thought there was no intercept and
>      >? ? ?check_collinearity() just removed the first intercept but not the
>      >? ? ?second.
>      >
>      >? ? ?In examining the code for check_collinearity(), I discovered a
>      >? ? ?couple of
>      >? ? ?additional disconcerting facts. First, part of the code seems
>     to be
>      >? ? ?copied from vif.default(). Second, as a consequence,
>      >? ? ?check_collinearity() actually computes GVIFs rather than VIFs
>     (and
>      >? ? ?doesn't reference either the Fox and Monette paper
>     introducing GVIFs or
>      >? ? ?the car package) but doesn't seem to understand that, and,
>     for example,
>      >? ? ?takes the squareroot of the GVIF (reported in the column marked
>      >? ? ?"Increased SE") rather than the 2p root (when there are p > 1
>      >? ? ?coefficients in a term).
>      >
>      >? ? ?Here's the relevant code from the two functions (where . . .
>     denotes
>      >? ? ?elided lines) -- the default method for vif() and
>      >? ? ?.check_collinearity(),
>      >? ? ?which is called by check_collinearity.default():
>      >
>      >? ? ?--------- snip -----------
>      >
>      >? ? ? ?> car:::vif.default
>      >? ? ?function (mod, ...)
>      >? ? ?{
>      >? ? ? ? ? ?. . .
>      >? ? ? ? ? ?v <- vcov(mod)
>      >? ? ? ? ? ?assign <- attr(model.matrix(mod), "assign")
>      >? ? ? ? ? ?if (names(coefficients(mod)[1]) == "(Intercept)") {
>      >? ? ? ? ? ? ? ?v <- v[-1, -1]
>      >? ? ? ? ? ? ? ?assign <- assign[-1]
>      >? ? ? ? ? ?}
>      >? ? ? ? ? ?else warning("No intercept: vifs may not be sensible.")
>      >? ? ? ? ? ?terms <- labels(terms(mod))
>      >? ? ? ? ? ?n.terms <- length(terms)
>      >? ? ? ? ? ?if (n.terms < 2)
>      >? ? ? ? ? ? ? ?stop("model contains fewer than 2 terms")
>      >? ? ? ? ? ?R <- cov2cor(v)
>      >? ? ? ? ? ?detR <- det(R)
>      >? ? ? ? ? ?. . .
>      >? ? ? ? ? ?for (term in 1:n.terms) {
>      >? ? ? ? ? ? ? ?subs <- which(assign == term)
>      >? ? ? ? ? ? ? ?result[term, 1] <- det(as.matrix(R[subs, subs])) *
>      >? ? ?det(as.matrix(R[-subs,
>      >? ? ? ? ? ? ? ? ? ?-subs]))/detR
>      >? ? ? ? ? ? ? ?result[term, 2] <- length(subs)
>      >? ? ? ? ? ?}
>      >? ? ? ? ? ?. . .
>      >? ? ?}
>      >
>      >? ? ? ?> performance:::.check_collinearity
>      >? ? ?function (x, component, verbose = TRUE)
>      >? ? ?{
>      >? ? ? ? ? ?v <- insight::get_varcov(x, component = component,
>     verbose =
>      >? ? ?FALSE)
>      >? ? ? ? ? ?assign <- .term_assignments(x, component, verbose =
>     verbose)
>      >? ? ? ? ? ?. . .
>      >? ? ? ? ? ?if (insight::has_intercept(x)) {
>      >? ? ? ? ? ? ? ?v <- v[-1, -1]
>      >? ? ? ? ? ? ? ?assign <- assign[-1]
>      >? ? ? ? ? ?}
>      >? ? ? ? ? ?else {
>      >? ? ? ? ? ? ? ?if (isTRUE(verbose)) {
>      >? ? ? ? ? ? ? ? ? ?warning("Model has no intercept. VIFs may not be
>      >? ? ?sensible.",
>      >? ? ? ? ? ? ? ? ? ? ? ?call. = FALSE)
>      >? ? ? ? ? ? ? ?}
>      >? ? ? ? ? ?}
>      >? ? ? ? ? ? ? ?. . .
>      >? ? ? ? ? ? ? ?terms <- labels(stats::terms(f[[component]]))
>      >? ? ? ? ? ? ? ?. . .
>      >? ? ? ? ? ?n.terms <- length(terms)
>      >? ? ? ? ? ?if (n.terms < 2) {
>      >? ? ? ? ? ? ? ?if (isTRUE(verbose)) {
>      >? ? ? ? ? ? ? ? ? ?warning(insight::format_message(sprintf("Not
>     enough model
>      >? ? ?terms in the %s part of the model to check for
>     multicollinearity.",
>      >? ? ? ? ? ? ? ? ? ? ? ?component)), call. = FALSE)
>      >? ? ? ? ? ? ? ?}
>      >? ? ? ? ? ? ? ?return(NULL)
>      >? ? ? ? ? ?}
>      >? ? ? ? ? ?R <- stats::cov2cor(v)
>      >? ? ? ? ? ?detR <- det(R)
>      >? ? ? ? ? ?. . .
>      >? ? ? ? ? ?for (term in 1:n.terms) {
>      >? ? ? ? ? ? ? ?subs <- which(assign == term)
>      >? ? ? ? ? ? ? ? ? ?. . .
>      >? ? ? ? ? ? ? ? ? ?result <- c(result, det(as.matrix(R[subs, subs])) *
>      >? ? ? ? ? ? ? ? ? ? ? ?det(as.matrix(R[-subs, -subs]))/detR)
>      >? ? ? ? ? ? ? ? ? ?. . .
>      >? ? ? ? ? ?}
>      >? ? ? ? ? ?. . .
>      >? ? ?}
>      >
>      >? ? ?--------- snip -----------
>      >
>      >? ? ?So, the upshot of all this is that you should be able to do
>     what you
>      >? ? ?want, but not with either car::vif() or
>      >? ? ?performance::check_collinearity(). Instead, either write your own
>      >? ? ?function or do the computations in a script.
>      >
>      >? ? ?There's also a lesson here about S3 default methods: The fact
>     that a
>      >? ? ?default method returns a result rather than throwing an error
>     or a
>      >? ? ?warning doesn't mean that the result is the right answer.
>      >
>      >? ? ?I hope this helps,
>      >? ? ? ? John
>      >
>      >
>      >? ? ?On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen wrote:
>      >? ? ? > Dear John W,
>      >? ? ? >
>      >? ? ? > Thank you very much for the tip-off! Apologies for not
>     responding
>      >? ? ?earlier
>      >? ? ? > (gmail apparently decided to direct your email right into the
>      >? ? ?junk folder).
>      >? ? ? > I am very pleased to note that the package you mention does
>      >? ? ?indeed work
>      >? ? ? > with *brms* multinomial models! Thanks again!
>      >? ? ? >
>      >? ? ? > Best,
>      >? ? ? >
>      >? ? ? > Juho
>      >? ? ? >
>      >? ? ? > pe 25. helmik. 2022 klo 19.23 John Willoughby
>      >? ? ?(johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>)
>      >? ? ? > kirjoitti:
>      >? ? ? >
>      >? ? ? >> Have you tried the check_collinearity() function in the
>     performance
>      >? ? ? >> package? It's supposed to work on brms models, but whether it
>      >? ? ?will work on
>      >? ? ? >> a multinomial model I don't know.? It works well on mixed
>     models
>      >? ? ?generated
>      >? ? ? >> by glmmTMB().
>      >? ? ? >>
>      >? ? ? >> John Willoughby
>      >? ? ? >>
>      >? ? ? >>
>      >? ? ? >> On Fri, Feb 25, 2022 at 3:01 AM
>      >? ? ?<r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>
>      >? ? ? >> wrote:
>      >? ? ? >>
>      >? ? ? >>> Send R-sig-mixed-models mailing list submissions to
>      >? ? ? >>> r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >>>
>      >? ? ? >>> To subscribe or unsubscribe via the World Wide Web, visit
>      >? ? ? >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >>> or, via email, send a message with subject or body 'help' to
>      >? ? ? >>> r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >>>
>      >? ? ? >>> You can reach the person managing the list at
>      >? ? ? >>> r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>
>      >? ? ? >>>
>      >? ? ? >>> When replying, please edit your Subject line so it is
>     more specific
>      >? ? ? >>> than "Re: Contents of R-sig-mixed-models digest..."
>      >? ? ? >>>
>      >? ? ? >>>
>      >? ? ? >>> Today's Topics:
>      >? ? ? >>>
>      >? ? ? >>>? ? ?1. Collinearity diagnostics for (mixed) multinomial
>     models
>      >? ? ? >>>? ? ? ? (Juho Kristian Ruohonen)
>      >? ? ? >>>
>      >? ? ? >>>
>      >   
>      ?----------------------------------------------------------------------
>      >? ? ? >>>
>      >? ? ? >>> Message: 1
>      >? ? ? >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
>      >? ? ? >>> From: Juho Kristian Ruohonen
>     <juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>>
>      >? ? ? >>> To: John Fox <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
>      >? ? ? >>> Cc: "r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>"
>      >? ? ? >>>? ? ? ? ? <r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >>> Subject: [R-sig-ME] Collinearity diagnostics for (mixed)
>      >? ? ?multinomial
>      >? ? ? >>>? ? ? ? ? models
>      >? ? ? >>> Message-ID:
>      >? ? ? >>>? ? ? ? ? <
>      >? ? ? >>>
>      >
>     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
>     <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
>      >   
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>>
>      >? ? ? >>> Content-Type: text/plain; charset="utf-8"
>      >? ? ? >>>
>      >? ? ? >>> Dear John (and anyone else qualified to comment),
>      >? ? ? >>>
>      >? ? ? >>> I fit lots of mixed-effects multinomial models in my
>     research,
>      >? ? ?and I
>      >? ? ? >> would
>      >? ? ? >>> like to see some (multi)collinearity diagnostics on the
>     fixed
>      >? ? ?effects, of
>      >? ? ? >>> which there are over 30. My models are fit using the
>     Bayesian
>      >? ? ?*brms*
>      >? ? ? >>> package because I know of no frequentist packages with
>      >? ? ?multinomial GLMM
>      >? ? ? >>> compatibility.
>      >? ? ? >>>
>      >? ? ? >>> With continuous or dichotomous outcomes, my go-to
>     function for
>      >? ? ? >> calculating
>      >? ? ? >>> multicollinearity diagnostics is of course *vif()* from
>     the *car*
>      >? ? ? >> package.
>      >? ? ? >>> As expected, however, this function does not report sensible
>      >? ? ?diagnostics
>      >? ? ? >>> for multinomial models -- not even for standard ones fit
>     by the
>      >? ? ?*nnet*
>      >? ? ? >>> package's *multinom()* function. The reason, I presume, is
>      >? ? ?because a
>      >? ? ? >>> multinomial model is not really one but C-1 regression
>     models
>      >? ? ?(where C
>      >? ? ? >> is
>      >? ? ? >>> the number of response categories) and the *vif()*
>     function is not
>      >? ? ? >> designed
>      >? ? ? >>> to deal with this scenario.
>      >? ? ? >>>
>      >? ? ? >>> Therefore, in order to obtain meaningful collinearity
>     metrics,
>      >? ? ?my present
>      >? ? ? >>> plan is to write a simple helper function that uses
>     *vif() *to
>      >? ? ?calculate
>      >? ? ? >>> and present (generalized) variance inflation metrics for
>     the C-1
>      >? ? ? >>> sub-datasets to which the C-1 component binomial models
>     of the
>      >? ? ?overall
>      >? ? ? >>> multinomial model are fit. In other words, it will partition
>      >? ? ?the data
>      >? ? ? >> into
>      >? ? ? >>> those C-1 subsets, and then apply *vif()* to as many linear
>      >? ? ?regressions
>      >? ? ? >>> using a made-up continuous response and the fixed effects of
>      >? ? ?interest.
>      >? ? ? >>>
>      >? ? ? >>> Does this seem like a sensible approach?
>      >? ? ? >>>
>      >? ? ? >>> Best,
>      >? ? ? >>>
>      >? ? ? >>> Juho
>      >? ? ? >>>
>      >? ? ? >>>
>      >? ? ? >>>
>      >? ? ? >>
>      >? ? ? >>? ? ? ? ? [[alternative HTML version deleted]]
>      >? ? ? >>
>      >? ? ? >> _______________________________________________
>      >? ? ? >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>      >? ? ? >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >>
>      >? ? ? >
>      >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>      >? ? ? >
>      >? ? ? > _______________________________________________
>      >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ?--
>      >? ? ?John Fox, Professor Emeritus
>      >? ? ?McMaster University
>      >? ? ?Hamilton, Ontario, Canada
>      >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
> 
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Tue Mar  1 14:24:42 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Tue, 1 Mar 2022 15:24:42 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
 <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
Message-ID: <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>

Dear John (Fox, as well as other list members),

I've now written a simple function to try and calculate GVIFS for all
predictors in a nnet::multinom() object based on John's example code. If
its results are correct (see below), I will proceed to write a version that
also works with mixed-effects multinomial models fit by brms::brm(). Here's
the code:

gvif.multinom <- function(model){
>   (classes <- model$lev)
>   (V.all <- vcov(model))
>   (V.noIntercepts <- V.all[!grepl("\\(Intercept\\)$", rownames(V.all),
> perl = T),
>                            !grepl("\\(Intercept\\)$", colnames(V.all),
> perl = T)])
>   (R <- cov2cor(V.noIntercepts))
>   (terms <- attr(model$terms, "term.labels"))
>   (gvif <- numeric(length = length(terms)))
>   (names(gvif) <- terms)
>   (SE.multiplier <- numeric(length = length(terms)))
>   (names(SE.multiplier) <- terms)
>   #The line below tries to capture all factor levels into a regex for coef
> name matching.
>   (LevelsRegex <- paste0("(", paste(unlist(model$xlevels), collapse =
> "|"),")?"))
>
>   for(i in terms){
>     #The regex stuff below tries to ensure all interaction coefficients
> are matched, including those involving factors.
>     if(grepl(":", i)){
>       (termname <- gsub(":", paste0(LevelsRegex, ":"), i, perl = T))
>     }else{termname <- i}
>     (RegexToMatch <- paste0("^(", paste(classes[2:length(classes)],
> collapse = "|") ,"):", termname, LevelsRegex, "$"))
>
>     #Now the actual calculation:
>     (indices <- grep(RegexToMatch, rownames(R), perl = T))
>     (gvif[i] <- det(R[indices, indices]) * det(R[-indices, -indices]) /
> det(R))
>     (SE.multiplier[i] <- gvif[i]^(1/(2*length(indices))))
>   }
>   #Put the results together and order them by degree of SE inflation:
>   (result <- cbind(GVIF = gvif, `GVIF^(1/(2df))` = SE.multiplier))
>   return(result[order(result[,"GVIF^(1/(2df))"], decreasing = T),])}
>

The results seem correct to me when applied to John's example model fit to
the BEPS data. However, that dataset contains no multi-df factors, of which
my own models have many. Below is a maximally simple example with one
multi-df factor (*region*):

mod1 <- multinom(partic ~., data = carData::Womenlf)
> gvif.multinom(mod1)
>
> GVIF GVIF^(1/(2df))
> children 1.298794       1.067542
> hincome  1.184215       1.043176
> region   1.381480       1.020403
>

These results look plausible to me. Finally, below is an example involving
both a multi-df factor and an interaction:

mod2 <- update(mod1, ~. +children:region)
> gvif.multinom(mod2)
>
>                         GVIF GVIF^(1/(2df))
> children:region 4.965762e+16      11.053482
> region          1.420418e+16      10.221768
> children        1.471412e+03       6.193463
> hincome         6.462161e+00       1.594390
>

These results look a bit more dubious. To be sure, it is to be expected
that interaction terms will introduce a lot of collinearity. But an 11-fold
increase in SE? I hope someone can tell me whether this is correct or not!

Best,

Juho











ti 1. maalisk. 2022 klo 0.05 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juha,
>
> On 2022-02-28 5:00 p.m., Juho Kristian Ruohonen wrote:
> > Apologies for my misreading, John, and many thanks for showing how the
> > calculation is done for a single term.
> >
> > Do you think *vif()* might be updated in the near future with the
> > capability of auto-detecting a multinomial model and returning
> > mathematically correct GVIF statistics?
>
> The thought crossed my mind, but I'd want to do it in a general way, not
> just for the multinom() function, and in a way that avoids incorrect
> results such as those currently produced for "multinom" models, albeit
> with a warning. I can't guarantee whether or when I'll be able to do that.
>
> John
>
> >
> > If not, I'll proceed to writing my own function based on your example.
> > However, /car/ is such an excellent and widely used package that the
> > greatest benefit to mankind would probably accrue if /car /was upgraded
> > with this feature sooner rather than later.
> >
> > Best,
> >
> > Juho
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > ma 28. helmik. 2022 klo 17.08 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Juho,
> >
> >     On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen wrote:
> >      > Dear Professor Fox and other list members,
> >      >
> >      > Profuse thanks for doing that detective work for me! I myself
> >     thought
> >      > the inflation factors reported by check_collinearity() were
> >     suspiciously
> >      > high, but unlike you I lacked the expertise to identify what was
> >     going on.
> >      >
> >      > As for your suggested approach, have I understood this correctly:
> >      >
> >      > Since there doesn't yet exist an R function that will calculate
> the
> >      > (G)VIFS of multinomial models correctly, my best bet for now is
> >     just to
> >      > ignore the fact that such models partition the data into C-1
> >     subsets,
> >      > and to calculate approximate GVIFs from the entire dataset at
> >     once as if
> >      > the response were continuous? And a simple way to do this is to
> >      > construct a fake continuous response, call *lm(fakeresponse ~.)*,
> >     and
> >      > apply *car::vif()* on the result?
> >
> >     No, you misunderstand my suggestion, which perhaps isn't surprising
> >     given the length of my message. What you propose is what I suggested
> as
> >     a rough approximation *before* I confirmed that my guess of the
> >     solution
> >     was correct.
> >
> >     The R code that I sent yesterday showed how to compute the GVIF for a
> >     multinomial regression model, and I suggested that you write either a
> >     script or a simple function to do that. Here's a function that will
> >     work
> >     for a model object that responds to vcov():
> >
> >     GVIF <- function(model, intercepts, term){
> >         # model: regression model object
> >         # intercepts: row/column positions of intercepts in the
> coefficient
> >     covariance matrix
> >         # term: row/column positions of the coefficients for the focal
> term
> >         V <- vcov(model)
> >         term <- colnames(V)[term]
> >         V <- V[-intercepts, -intercepts]
> >         V <- cov2cor(V)
> >         term <- which(colnames(V) %in% term)
> >         gvif <- det(V[term, term])*det(V[-term, -term])/det(V)
> >         c(GVIF=gvif, "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
> >     }
> >
> >     and here's an application to the multinom() example that I showed you
> >     yesterday:
> >
> >       > colnames(vcov(m)) # to get coefficient positions
> >        [1] "Labour:(Intercept)"                       "Labour:age"
> >
> >        [3] "Labour:economic.cond.national"
> >     "Labour:economic.cond.household"
> >        [5] "Labour:Blair"                             "Labour:Hague"
> >
> >        [7] "Labour:Kennedy"                           "Labour:Europe"
> >
> >        [9] "Labour:political.knowledge"               "Labour:gendermale"
> >
> >     [11] "Liberal Democrat:(Intercept)"             "Liberal
> Democrat:age"
> >
> >     [13] "Liberal Democrat:economic.cond.national"  "Liberal
> >     Democrat:economic.cond.household"
> >     [15] "Liberal Democrat:Blair"                   "Liberal
> >     Democrat:Hague"
> >
> >     [17] "Liberal Democrat:Kennedy"                 "Liberal
> >     Democrat:Europe"
> >     [19] "Liberal Democrat:political.knowledge"     "Liberal
> >     Democrat:gendermale"
> >
> >       > GVIF(m, intercepts=c(1, 11), term=c(2, 12)) # GVIF for age
> >                 GVIF GVIF^(1/(2*p))
> >             1.046232       1.011363
> >
> >
> >     Finally, here's what you get for a linear model with the same RHS
> >     (where
> >     the sqrt(VIF) should be a rough approximation to GVIF^(1/4) reported
> by
> >     my GVIF() function):
> >
> >       > m.lm <- lm(as.numeric(vote) ~ . - vote1, data=BEPS)
> >       > sqrt(car::vif(m.lm))
> >                           age  economic.cond.national
> >     economic.cond.household
> >                         Blair
> >                      1.006508                1.124132
> >     1.075656
> >                      1.118441
> >                         Hague                 Kennedy
> >     Europe
> >           political.knowledge
> >                      1.066799                1.015532
> >     1.101741
> >                      1.028546
> >                        gender
> >                      1.017386
> >
> >
> >     John
> >
> >      >
> >      > Best,
> >      >
> >      > Juho
> >      >
> >      > ma 28. helmik. 2022 klo 2.23 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
> >      >
> >      >     Dear Juho,
> >      >
> >      >     I've now had a chance to think about this problem some more,
> >     and I
> >      >     believe that the approach I suggested is correct. I also had
> an
> >      >     opportunity to talk the problem over a bit with Georges
> >     Monette, who
> >      >     coauthored the paper that introduced generalized variance
> >     inflation
> >      >     factors (GVIFs). On the other hand, the results produced by
> >      >     performance::check_collinearity() for multinomial logit
> >     models don't
> >      >     seem to be correct (see below).
> >      >
> >      >     Here's an example, using the nnet::multinom() function to fit
> a
> >      >     multinomial logit model, with alternative parametrizations of
> the
> >      >     LHS of
> >      >     the model:
> >      >
> >      >     --------- snip -----------
> >      >
> >      >       > library(nnet) # for multinom()
> >      >       > library(carData) # for BEPS data set
> >      >
> >      >       > # alternative ordering of the response levels:
> >      >       > BEPS$vote1 <- factor(BEPS$vote, levels=c("Labour",
> "Liberal
> >      >     Democrat", "Conservative"))
> >      >       > levels(BEPS$vote)
> >      >     [1] "Conservative"     "Labour"           "Liberal Democrat"
> >      >       > levels(BEPS$vote1)
> >      >     [1] "Labour"           "Liberal Democrat" "Conservative"
> >      >
> >      >       > m <- multinom(vote ~ . - vote1, data=BEPS)
> >      >     # weights:  33 (20 variable)
> >      >     initial  value 1675.383740
> >      >     iter  10 value 1345.935273
> >      >     iter  20 value 1150.956807
> >      >     iter  30 value 1141.921662
> >      >     iter  30 value 1141.921661
> >      >     iter  30 value 1141.921661
> >      >     final  value 1141.921661
> >      >     converged
> >      >       > m1 <- multinom(vote1 ~ . - vote, data=BEPS)
> >      >     # weights:  33 (20 variable)
> >      >     initial  value 1675.383740
> >      >     iter  10 value 1280.439304
> >      >     iter  20 value 1165.513772
> >      >     final  value 1141.921662
> >      >     converged
> >      >
> >      >       > rbind(coef(m), coef(m1)) # compare coefficients
> >      >                        (Intercept)          age
> >     economic.cond.national
> >      >     economic.cond.household
> >      >     Labour             0.9515214 -0.021913989
> 0.5575707
> >      >            0.15839096
> >      >     Liberal Democrat   1.4119306 -0.016810735
> 0.1810761
> >      >           -0.01196664
> >      >     Liberal Democrat   0.4604567  0.005102666
>  -0.3764928
> >      >           -0.17036682
> >      >     Conservative      -0.9514466  0.021912305
>  -0.5575644
> >      >           -0.15838744
> >      >                             Blair       Hague    Kennedy
> Europe
> >      >     political.knowledge
> >      >     Labour            0.8371764 -0.90775585  0.2513436 -0.22781308
> >      >     -0.5370612
> >      >     Liberal Democrat  0.2937331 -0.82217625  0.6710567 -0.20004624
> >      >     -0.2034605
> >      >     Liberal Democrat -0.5434408  0.08559455  0.4197027  0.02776465
> >      >     0.3336068
> >      >     Conservative     -0.8371670  0.90778068 -0.2513735  0.22781092
> >      >     0.5370545
> >      >                         gendermale
> >      >     Labour            0.13765774
> >      >     Liberal Democrat  0.12640823
> >      >     Liberal Democrat -0.01125898
> >      >     Conservative     -0.13764849
> >      >
> >      >       > c(logLik(m), logLik(m1)) # same fit to the data
> >      >     [1] -1141.922 -1141.922
> >      >
> >      >       > # covariance matrices for coefficients:
> >      >       > V <- vcov(m)
> >      >       > V1 <- vcov(m1)
> >      >       > cbind(colnames(V), colnames(V1)) # compare
> >      >             [,1]                                       [,2]
> >      >
> >      >        [1,] "Labour:(Intercept)"                       "Liberal
> >      >     Democrat:(Intercept)"
> >      >        [2,] "Labour:age"                               "Liberal
> >      >     Democrat:age"
> >      >
> >      >        [3,] "Labour:economic.cond.national"            "Liberal
> >      >     Democrat:economic.cond.national"
> >      >        [4,] "Labour:economic.cond.household"           "Liberal
> >      >     Democrat:economic.cond.household"
> >      >        [5,] "Labour:Blair"                             "Liberal
> >      >     Democrat:Blair"
> >      >        [6,] "Labour:Hague"                             "Liberal
> >      >     Democrat:Hague"
> >      >        [7,] "Labour:Kennedy"                           "Liberal
> >      >     Democrat:Kennedy"
> >      >        [8,] "Labour:Europe"                            "Liberal
> >      >     Democrat:Europe"
> >      >        [9,] "Labour:political.knowledge"               "Liberal
> >      >     Democrat:political.knowledge"
> >      >     [10,] "Labour:gendermale"                        "Liberal
> >      >     Democrat:gendermale"
> >      >     [11,] "Liberal Democrat:(Intercept)"
> >      >     "Conservative:(Intercept)"
> >      >     [12,] "Liberal Democrat:age"
> >       "Conservative:age"
> >      >
> >      >     [13,] "Liberal Democrat:economic.cond.national"
> >      >     "Conservative:economic.cond.national"
> >      >     [14,] "Liberal Democrat:economic.cond.household"
> >      >     "Conservative:economic.cond.household"
> >      >     [15,] "Liberal Democrat:Blair"
> >       "Conservative:Blair"
> >      >
> >      >     [16,] "Liberal Democrat:Hague"
> >       "Conservative:Hague"
> >      >
> >      >     [17,] "Liberal Democrat:Kennedy"
> >       "Conservative:Kennedy"
> >      >
> >      >     [18,] "Liberal Democrat:Europe"
> >     "Conservative:Europe"
> >      >
> >      >     [19,] "Liberal Democrat:political.knowledge"
> >      >     "Conservative:political.knowledge"
> >      >     [20,] "Liberal Democrat:gendermale"
> >      >     "Conservative:gendermale"
> >      >
> >      >       > int <- c(1, 11) # remove intercepts
> >      >       > colnames(V)[int]
> >      >     [1] "Labour:(Intercept)"           "Liberal
> Democrat:(Intercept)"
> >      >
> >      >       > colnames(V1)[int]
> >      >     [1] "Liberal Democrat:(Intercept)" "Conservative:(Intercept)"
> >      >       > V <- V[-int, -int]
> >      >       > V1 <- V1[-int, -int]
> >      >
> >      >       > age <- c(1, 10) # locate age coefficients
> >      >       > colnames(V)[age]
> >      >     [1] "Labour:age"           "Liberal Democrat:age"
> >      >       > colnames(V1)[age]
> >      >     [1] "Liberal Democrat:age" "Conservative:age"
> >      >
> >      >       > V <- cov2cor(V) # compute coefficient correlations
> >      >       > V1 <- cov2cor(V1)
> >      >
> >      >       > # compare GVIFs:
> >      >       > c(det(V[age, age])*det(V[-age, -age])/det(V),
> >      >     +   det(V1[age, age])*det(V1[-age, -age])/det(V1))
> >      >     [1] 1.046232 1.046229
> >      >
> >      >     --------- snip -----------
> >      >
> >      >     For curiosity, I applied car::vif() and
> >      >     performance::check_collinearity() to these models to see what
> >     they
> >      >     would
> >      >     do. Both returned the wrong answer. vif() produced a warning,
> but
> >      >     check_collinearity() didn't:
> >      >
> >      >     --------- snip -----------
> >      >
> >      >       > car::vif(m1)
> >      >                           age  economic.cond.national
> >      >     economic.cond.household
> >      >                     15.461045               22.137772
> >      >       16.693877
> >      >                         Blair                   Hague
> >      >       Kennedy
> >      >                     14.681562                7.483039
> >      >       15.812067
> >      >                        Europe     political.knowledge
> >      >     gender
> >      >                      6.502119                4.219507
> >      >     2.313885
> >      >     Warning message:
> >      >     In vif.default(m1) : No intercept: vifs may not be sensible.
> >      >
> >      >       > performance::check_collinearity(m)
> >      >     # Check for Multicollinearity
> >      >
> >      >     Low Correlation
> >      >
> >      >                           Term  VIF Increased SE Tolerance
> >      >                            age 1.72         1.31      0.58
> >      >         economic.cond.national 1.85         1.36      0.54
> >      >        economic.cond.household 1.86         1.37      0.54
> >      >                          Blair 1.63         1.28      0.61
> >      >                          Hague 1.94         1.39      0.52
> >      >                        Kennedy 1.70         1.30      0.59
> >      >                         Europe 2.01         1.42      0.50
> >      >            political.knowledge 1.94         1.39      0.52
> >      >                         gender 1.78         1.33      0.56
> >      >       > performance::check_collinearity(m1)
> >      >     # Check for Multicollinearity
> >      >
> >      >     Low Correlation
> >      >
> >      >                           Term  VIF Increased SE Tolerance
> >      >                            age 1.19         1.09      0.84
> >      >         economic.cond.national 1.42         1.19      0.70
> >      >        economic.cond.household 1.32         1.15      0.76
> >      >                          Blair 1.50         1.22      0.67
> >      >                          Hague 1.30         1.14      0.77
> >      >                        Kennedy 1.19         1.09      0.84
> >      >                         Europe 1.34         1.16      0.75
> >      >            political.knowledge 1.30         1.14      0.77
> >      >                         gender 1.23         1.11      0.81
> >      >
> >      >     --------- snip -----------
> >      >
> >      >     I looked at the code for vif() and check_collinearity() to
> >     see where
> >      >     they went wrong. Both failed to handle the two intercepts in
> >     the model
> >      >     correctly -- vif() thought there was no intercept and
> >      >     check_collinearity() just removed the first intercept but not
> the
> >      >     second.
> >      >
> >      >     In examining the code for check_collinearity(), I discovered a
> >      >     couple of
> >      >     additional disconcerting facts. First, part of the code seems
> >     to be
> >      >     copied from vif.default(). Second, as a consequence,
> >      >     check_collinearity() actually computes GVIFs rather than VIFs
> >     (and
> >      >     doesn't reference either the Fox and Monette paper
> >     introducing GVIFs or
> >      >     the car package) but doesn't seem to understand that, and,
> >     for example,
> >      >     takes the squareroot of the GVIF (reported in the column
> marked
> >      >     "Increased SE") rather than the 2p root (when there are p > 1
> >      >     coefficients in a term).
> >      >
> >      >     Here's the relevant code from the two functions (where . . .
> >     denotes
> >      >     elided lines) -- the default method for vif() and
> >      >     .check_collinearity(),
> >      >     which is called by check_collinearity.default():
> >      >
> >      >     --------- snip -----------
> >      >
> >      >       > car:::vif.default
> >      >     function (mod, ...)
> >      >     {
> >      >           . . .
> >      >           v <- vcov(mod)
> >      >           assign <- attr(model.matrix(mod), "assign")
> >      >           if (names(coefficients(mod)[1]) == "(Intercept)") {
> >      >               v <- v[-1, -1]
> >      >               assign <- assign[-1]
> >      >           }
> >      >           else warning("No intercept: vifs may not be sensible.")
> >      >           terms <- labels(terms(mod))
> >      >           n.terms <- length(terms)
> >      >           if (n.terms < 2)
> >      >               stop("model contains fewer than 2 terms")
> >      >           R <- cov2cor(v)
> >      >           detR <- det(R)
> >      >           . . .
> >      >           for (term in 1:n.terms) {
> >      >               subs <- which(assign == term)
> >      >               result[term, 1] <- det(as.matrix(R[subs, subs])) *
> >      >     det(as.matrix(R[-subs,
> >      >                   -subs]))/detR
> >      >               result[term, 2] <- length(subs)
> >      >           }
> >      >           . . .
> >      >     }
> >      >
> >      >       > performance:::.check_collinearity
> >      >     function (x, component, verbose = TRUE)
> >      >     {
> >      >           v <- insight::get_varcov(x, component = component,
> >     verbose =
> >      >     FALSE)
> >      >           assign <- .term_assignments(x, component, verbose =
> >     verbose)
> >      >           . . .
> >      >           if (insight::has_intercept(x)) {
> >      >               v <- v[-1, -1]
> >      >               assign <- assign[-1]
> >      >           }
> >      >           else {
> >      >               if (isTRUE(verbose)) {
> >      >                   warning("Model has no intercept. VIFs may not be
> >      >     sensible.",
> >      >                       call. = FALSE)
> >      >               }
> >      >           }
> >      >               . . .
> >      >               terms <- labels(stats::terms(f[[component]]))
> >      >               . . .
> >      >           n.terms <- length(terms)
> >      >           if (n.terms < 2) {
> >      >               if (isTRUE(verbose)) {
> >      >                   warning(insight::format_message(sprintf("Not
> >     enough model
> >      >     terms in the %s part of the model to check for
> >     multicollinearity.",
> >      >                       component)), call. = FALSE)
> >      >               }
> >      >               return(NULL)
> >      >           }
> >      >           R <- stats::cov2cor(v)
> >      >           detR <- det(R)
> >      >           . . .
> >      >           for (term in 1:n.terms) {
> >      >               subs <- which(assign == term)
> >      >                   . . .
> >      >                   result <- c(result, det(as.matrix(R[subs,
> subs])) *
> >      >                       det(as.matrix(R[-subs, -subs]))/detR)
> >      >                   . . .
> >      >           }
> >      >           . . .
> >      >     }
> >      >
> >      >     --------- snip -----------
> >      >
> >      >     So, the upshot of all this is that you should be able to do
> >     what you
> >      >     want, but not with either car::vif() or
> >      >     performance::check_collinearity(). Instead, either write your
> own
> >      >     function or do the computations in a script.
> >      >
> >      >     There's also a lesson here about S3 default methods: The fact
> >     that a
> >      >     default method returns a result rather than throwing an error
> >     or a
> >      >     warning doesn't mean that the result is the right answer.
> >      >
> >      >     I hope this helps,
> >      >        John
> >      >
> >      >
> >      >     On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen wrote:
> >      >      > Dear John W,
> >      >      >
> >      >      > Thank you very much for the tip-off! Apologies for not
> >     responding
> >      >     earlier
> >      >      > (gmail apparently decided to direct your email right into
> the
> >      >     junk folder).
> >      >      > I am very pleased to note that the package you mention does
> >      >     indeed work
> >      >      > with *brms* multinomial models! Thanks again!
> >      >      >
> >      >      > Best,
> >      >      >
> >      >      > Juho
> >      >      >
> >      >      > pe 25. helmik. 2022 klo 19.23 John Willoughby
> >      >     (johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>)
> >      >      > kirjoitti:
> >      >      >
> >      >      >> Have you tried the check_collinearity() function in the
> >     performance
> >      >      >> package? It's supposed to work on brms models, but
> whether it
> >      >     will work on
> >      >      >> a multinomial model I don't know.  It works well on mixed
> >     models
> >      >     generated
> >      >      >> by glmmTMB().
> >      >      >>
> >      >      >> John Willoughby
> >      >      >>
> >      >      >>
> >      >      >> On Fri, Feb 25, 2022 at 3:01 AM
> >      >     <r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >      >> wrote:
> >      >      >>
> >      >      >>> Send R-sig-mixed-models mailing list submissions to
> >      >      >>> r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >>>
> >      >      >>> To subscribe or unsubscribe via the World Wide Web, visit
> >      >      >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >>> or, via email, send a message with subject or body
> 'help' to
> >      >      >>> r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >>>
> >      >      >>> You can reach the person managing the list at
> >      >      >>> r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >      >>>
> >      >      >>> When replying, please edit your Subject line so it is
> >     more specific
> >      >      >>> than "Re: Contents of R-sig-mixed-models digest..."
> >      >      >>>
> >      >      >>>
> >      >      >>> Today's Topics:
> >      >      >>>
> >      >      >>>     1. Collinearity diagnostics for (mixed) multinomial
> >     models
> >      >      >>>        (Juho Kristian Ruohonen)
> >      >      >>>
> >      >      >>>
> >      >
> >
>  ----------------------------------------------------------------------
> >      >      >>>
> >      >      >>> Message: 1
> >      >      >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
> >      >      >>> From: Juho Kristian Ruohonen
> >     <juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>
> >      >      >>> To: John Fox <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >      >>> Cc: "r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>"
> >      >      >>>          <r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >>> Subject: [R-sig-ME] Collinearity diagnostics for (mixed)
> >      >     multinomial
> >      >      >>>          models
> >      >      >>> Message-ID:
> >      >      >>>          <
> >      >      >>>
> >      >
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>
> >      >      >>> Content-Type: text/plain; charset="utf-8"
> >      >      >>>
> >      >      >>> Dear John (and anyone else qualified to comment),
> >      >      >>>
> >      >      >>> I fit lots of mixed-effects multinomial models in my
> >     research,
> >      >     and I
> >      >      >> would
> >      >      >>> like to see some (multi)collinearity diagnostics on the
> >     fixed
> >      >     effects, of
> >      >      >>> which there are over 30. My models are fit using the
> >     Bayesian
> >      >     *brms*
> >      >      >>> package because I know of no frequentist packages with
> >      >     multinomial GLMM
> >      >      >>> compatibility.
> >      >      >>>
> >      >      >>> With continuous or dichotomous outcomes, my go-to
> >     function for
> >      >      >> calculating
> >      >      >>> multicollinearity diagnostics is of course *vif()* from
> >     the *car*
> >      >      >> package.
> >      >      >>> As expected, however, this function does not report
> sensible
> >      >     diagnostics
> >      >      >>> for multinomial models -- not even for standard ones fit
> >     by the
> >      >     *nnet*
> >      >      >>> package's *multinom()* function. The reason, I presume,
> is
> >      >     because a
> >      >      >>> multinomial model is not really one but C-1 regression
> >     models
> >      >     (where C
> >      >      >> is
> >      >      >>> the number of response categories) and the *vif()*
> >     function is not
> >      >      >> designed
> >      >      >>> to deal with this scenario.
> >      >      >>>
> >      >      >>> Therefore, in order to obtain meaningful collinearity
> >     metrics,
> >      >     my present
> >      >      >>> plan is to write a simple helper function that uses
> >     *vif() *to
> >      >     calculate
> >      >      >>> and present (generalized) variance inflation metrics for
> >     the C-1
> >      >      >>> sub-datasets to which the C-1 component binomial models
> >     of the
> >      >     overall
> >      >      >>> multinomial model are fit. In other words, it will
> partition
> >      >     the data
> >      >      >> into
> >      >      >>> those C-1 subsets, and then apply *vif()* to as many
> linear
> >      >     regressions
> >      >      >>> using a made-up continuous response and the fixed
> effects of
> >      >     interest.
> >      >      >>>
> >      >      >>> Does this seem like a sensible approach?
> >      >      >>>
> >      >      >>> Best,
> >      >      >>>
> >      >      >>> Juho
> >      >      >>>
> >      >      >>>
> >      >      >>>
> >      >      >>
> >      >      >>          [[alternative HTML version deleted]]
> >      >      >>
> >      >      >> _______________________________________________
> >      >      >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >      >      >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >>
> >      >      >
> >      >      >       [[alternative HTML version deleted]]
> >      >      >
> >      >      > _______________________________________________
> >      >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >      >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >     --
> >      >     John Fox, Professor Emeritus
> >      >     McMaster University
> >      >     Hamilton, Ontario, Canada
> >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Mar  1 17:01:34 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 1 Mar 2022 11:01:34 -0500
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
 <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
 <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>
Message-ID: <0f03187e-d848-ea43-e370-ead2d403b530@mcmaster.ca>

Dear Juho,

On 2022-03-01 8:24 a.m., Juho Kristian Ruohonen wrote:
> Dear John (Fox, as well as other list members),
> 
> I've now written a simple function to try and calculate GVIFS for all 
> predictors in a nnet::multinom() object based on John's example code. If 
> its results are correct (see below), I will proceed to write a version 
> that also works with mixed-effects multinomial models fit by 
> brms::brm(). Here's the code:
> 
>     gvif.multinom <- function(model){
>      ? (classes <- model$lev)
>      ? (V.all <- vcov(model))
>      ? (V.noIntercepts <- V.all[!grepl("\\(Intercept\\)$",
>     rownames(V.all), perl = T),
>      ? ? ? ? ? ? ? ? ? ? ? ? ? ?!grepl("\\(Intercept\\)$",
>     colnames(V.all), perl = T)])
>      ? (R <- cov2cor(V.noIntercepts))
>      ? (terms <- attr(model$terms, "term.labels"))
>      ? (gvif <- numeric(length = length(terms)))
>      ? (names(gvif) <- terms)
>      ? (SE.multiplier <- numeric(length = length(terms)))
>      ? (names(SE.multiplier) <- terms)
>      ? #The line below tries to capture all factor levels into a regex
>     for coef name matching.
>      ? (LevelsRegex <- paste0("(", paste(unlist(model$xlevels), collapse
>     = "|"),")?"))
> 
>      ? for(i in terms){
>      ? ? #The regex stuff below tries to ensure all interaction
>     coefficients are matched, including those involving factors.
>      ? ? if(grepl(":", i)){
>      ? ? ? (termname <- gsub(":", paste0(LevelsRegex, ":"), i, perl = T))
>      ? ? }else{termname <- i}
>      ? ? (RegexToMatch <- paste0("^(", paste(classes[2:length(classes)],
>     collapse = "|") ,"):", termname, LevelsRegex, "$"))
> 
>      ? ? #Now the actual calculation:
>      ? ? (indices <- grep(RegexToMatch, rownames(R), perl = T))
>      ? ? (gvif[i] <- det(R[indices, indices]) * det(R[-indices,
>     -indices]) / det(R))
>      ? ? (SE.multiplier[i] <- gvif[i]^(1/(2*length(indices))))
>      ? }
>      ? #Put the results together and order them by degree of SE inflation:
>      ? (result <- cbind(GVIF = gvif, `GVIF^(1/(2df))` = SE.multiplier))
>      ? return(result[order(result[,"GVIF^(1/(2df))"], decreasing = T),])}
> 
> 
> The results seem correct to me when applied to John's example model fit 
> to the BEPS data. However, that dataset contains no multi-df factors, of 
> which my own models have many. Below is a maximally simple example with 
> one multi-df factor (/region/):
> 
>     mod1 <- multinom(partic ~., data = carData::Womenlf)
>     gvif.multinom(mod1)
> 
>     GVIF GVIF^(1/(2df))
>     children 1.298794 ? ? ? 1.067542
>     hincome ?1.184215 ? ? ? 1.043176
>     region ? 1.381480 ? ? ? 1.020403
> 
> 
> These results look plausible to me. Finally, below is an example 
> involving both a multi-df factor and an interaction:
> 
>     mod2 <- update(mod1, ~. +children:region)
>     gvif.multinom(mod2)
> 
>      ? ? ? ? ? ? ? ? ? ? ? ? GVIF GVIF^(1/(2df))
>     children:region 4.965762e+16 ? ? ?11.053482
>     region ? ? ? ? ?1.420418e+16 ? ? ?10.221768
>     children ? ? ? ?1.471412e+03 ? ? ? 6.193463
>     hincome ? ? ? ? 6.462161e+00 ? ? ? 1.594390
> 
> 
> These results look a bit more dubious. To be sure, it is to be expected 
> that interaction terms will introduce a lot of collinearity. But an 
> 11-fold increase in SE? I hope someone can tell me whether this is 
> correct or not!

You don't need someone else to check your work because you could just 
apply the simple function that I sent you yesterday, which, though not 
automatic, computes the GVIFs in a transparent manner.

A brief comment on GVIFs for models with interactions (this isn't the 
place to discuss the question in detail): The Fox and Monette JASA paper 
addresses the question briefly in the context of a two-way ANOVA, but I 
don't think that the approach suggested there is easily generalized.

The following simple approach pays attention to what's invariant under 
different parametrizations of the RHS side of the model: Simultaneously 
check the collinearity of all of the coefficients of an interaction 
together with the main effects and, potentially, lower-order 
interactions that are marginal to it. So, e.g., in the model y ~ a + b + 
a:b + c, you'd check all of the coefficients for a, b, and a:b together.

Alternatively, one could focus in turn on each explanatory variable and 
check the collinearity of all coefficients to which it is marginal. So 
in y ~ a + b + c + a:b + a:c + d, when you focus on a, you'd look at all 
of the coefficients for a, b, c, a:b, and a:c.

John

> 
> Best,
> 
> Juho
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ti 1. maalisk. 2022 klo 0.05 John Fox (jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>) kirjoitti:
> 
>     Dear Juha,
> 
>     On 2022-02-28 5:00 p.m., Juho Kristian Ruohonen wrote:
>      > Apologies for my misreading, John, and many thanks for showing
>     how the
>      > calculation is done for a single term.
>      >
>      > Do you think *vif()* might be updated in the near future with the
>      > capability of auto-detecting a multinomial model and returning
>      > mathematically correct GVIF statistics?
> 
>     The thought crossed my mind, but I'd want to do it in a general way,
>     not
>     just for the multinom() function, and in a way that avoids incorrect
>     results such as those currently produced for "multinom" models, albeit
>     with a warning. I can't guarantee whether or when I'll be able to do
>     that.
> 
>     John
> 
>      >
>      > If not, I'll proceed to writing my own function based on your
>     example.
>      > However, /car/ is such an excellent and widely used package that the
>      > greatest benefit to mankind would probably accrue if /car /was
>     upgraded
>      > with this feature sooner rather than later.
>      >
>      > Best,
>      >
>      > Juho
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      > ma 28. helmik. 2022 klo 17.08 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
>      >
>      >? ? ?Dear Juho,
>      >
>      >? ? ?On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen wrote:
>      >? ? ? > Dear Professor Fox and other list members,
>      >? ? ? >
>      >? ? ? > Profuse thanks for doing that detective work for me! I myself
>      >? ? ?thought
>      >? ? ? > the inflation factors reported by check_collinearity() were
>      >? ? ?suspiciously
>      >? ? ? > high, but unlike you I lacked the expertise to identify
>     what was
>      >? ? ?going on.
>      >? ? ? >
>      >? ? ? > As for your suggested approach, have I understood this
>     correctly:
>      >? ? ? >
>      >? ? ? > Since there doesn't yet exist an R function that will
>     calculate the
>      >? ? ? > (G)VIFS of multinomial models correctly, my best bet for
>     now is
>      >? ? ?just to
>      >? ? ? > ignore the fact that such models partition the data into C-1
>      >? ? ?subsets,
>      >? ? ? > and to calculate approximate GVIFs from the entire dataset at
>      >? ? ?once as if
>      >? ? ? > the response were continuous? And a simple way to do this
>     is to
>      >? ? ? > construct a fake continuous response, call
>     *lm(fakeresponse ~.)*,
>      >? ? ?and
>      >? ? ? > apply *car::vif()* on the result?
>      >
>      >? ? ?No, you misunderstand my suggestion, which perhaps isn't
>     surprising
>      >? ? ?given the length of my message. What you propose is what I
>     suggested as
>      >? ? ?a rough approximation *before* I confirmed that my guess of the
>      >? ? ?solution
>      >? ? ?was correct.
>      >
>      >? ? ?The R code that I sent yesterday showed how to compute the
>     GVIF for a
>      >? ? ?multinomial regression model, and I suggested that you write
>     either a
>      >? ? ?script or a simple function to do that. Here's a function
>     that will
>      >? ? ?work
>      >? ? ?for a model object that responds to vcov():
>      >
>      >? ? ?GVIF <- function(model, intercepts, term){
>      >? ? ? ? ?# model: regression model object
>      >? ? ? ? ?# intercepts: row/column positions of intercepts in the
>     coefficient
>      >? ? ?covariance matrix
>      >? ? ? ? ?# term: row/column positions of the coefficients for the
>     focal term
>      >? ? ? ? ?V <- vcov(model)
>      >? ? ? ? ?term <- colnames(V)[term]
>      >? ? ? ? ?V <- V[-intercepts, -intercepts]
>      >? ? ? ? ?V <- cov2cor(V)
>      >? ? ? ? ?term <- which(colnames(V) %in% term)
>      >? ? ? ? ?gvif <- det(V[term, term])*det(V[-term, -term])/det(V)
>      >? ? ? ? ?c(GVIF=gvif, "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
>      >? ? ?}
>      >
>      >? ? ?and here's an application to the multinom() example that I
>     showed you
>      >? ? ?yesterday:
>      >
>      >? ? ? ?> colnames(vcov(m)) # to get coefficient positions
>      >? ? ? ? [1] "Labour:(Intercept)"? ? ? ? ? ? ? ? ? ? ? ?"Labour:age"
>      >
>      >? ? ? ? [3] "Labour:economic.cond.national"
>      >? ? ?"Labour:economic.cond.household"
>      >? ? ? ? [5] "Labour:Blair"? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"Labour:Hague"
>      >
>      >? ? ? ? [7] "Labour:Kennedy"? ? ? ? ? ? ? ? ? ? ? ? ? ?"Labour:Europe"
>      >
>      >? ? ? ? [9] "Labour:political.knowledge"             
>      ?"Labour:gendermale"
>      >
>      >? ? ?[11] "Liberal Democrat:(Intercept)"? ? ? ? ? ? ?"Liberal
>     Democrat:age"
>      >
>      >? ? ?[13] "Liberal Democrat:economic.cond.national"? "Liberal
>      >? ? ?Democrat:economic.cond.household"
>      >? ? ?[15] "Liberal Democrat:Blair"? ? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:Hague"
>      >
>      >? ? ?[17] "Liberal Democrat:Kennedy"? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:Europe"
>      >? ? ?[19] "Liberal Democrat:political.knowledge"? ? ?"Liberal
>      >? ? ?Democrat:gendermale"
>      >
>      >? ? ? ?> GVIF(m, intercepts=c(1, 11), term=c(2, 12)) # GVIF for age
>      >? ? ? ? ? ? ? ? ?GVIF GVIF^(1/(2*p))
>      >? ? ? ? ? ? ?1.046232? ? ? ?1.011363
>      >
>      >
>      >? ? ?Finally, here's what you get for a linear model with the same RHS
>      >? ? ?(where
>      >? ? ?the sqrt(VIF) should be a rough approximation to GVIF^(1/4)
>     reported by
>      >? ? ?my GVIF() function):
>      >
>      >? ? ? ?> m.lm <- lm(as.numeric(vote) ~ . - vote1, data=BEPS)
>      >? ? ? ?> sqrt(car::vif(m.lm))
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ?age? economic.cond.national
>      >? ? ?economic.cond.household
>      >? ? ? ? ? ? ? ? ? ? ? ? ?Blair
>      >? ? ? ? ? ? ? ? ? ? ? 1.006508? ? ? ? ? ? ? ? 1.124132
>      >? ? ?1.075656
>      >? ? ? ? ? ? ? ? ? ? ? 1.118441
>      >? ? ? ? ? ? ? ? ? ? ? ? ?Hague? ? ? ? ? ? ? ? ?Kennedy
>      >? ? ?Europe
>      >? ? ? ? ? ?political.knowledge
>      >? ? ? ? ? ? ? ? ? ? ? 1.066799? ? ? ? ? ? ? ? 1.015532
>      >? ? ?1.101741
>      >? ? ? ? ? ? ? ? ? ? ? 1.028546
>      >? ? ? ? ? ? ? ? ? ? ? ? gender
>      >? ? ? ? ? ? ? ? ? ? ? 1.017386
>      >
>      >
>      >? ? ?John
>      >
>      >? ? ? >
>      >? ? ? > Best,
>      >? ? ? >
>      >? ? ? > Juho
>      >? ? ? >
>      >? ? ? > ma 28. helmik. 2022 klo 2.23 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
>      >? ? ? >
>      >? ? ? >? ? ?Dear Juho,
>      >? ? ? >
>      >? ? ? >? ? ?I've now had a chance to think about this problem some
>     more,
>      >? ? ?and I
>      >? ? ? >? ? ?believe that the approach I suggested is correct. I
>     also had an
>      >? ? ? >? ? ?opportunity to talk the problem over a bit with Georges
>      >? ? ?Monette, who
>      >? ? ? >? ? ?coauthored the paper that introduced generalized variance
>      >? ? ?inflation
>      >? ? ? >? ? ?factors (GVIFs). On the other hand, the results
>     produced by
>      >? ? ? >? ? ?performance::check_collinearity() for multinomial logit
>      >? ? ?models don't
>      >? ? ? >? ? ?seem to be correct (see below).
>      >? ? ? >
>      >? ? ? >? ? ?Here's an example, using the nnet::multinom() function
>     to fit a
>      >? ? ? >? ? ?multinomial logit model, with alternative
>     parametrizations of the
>      >? ? ? >? ? ?LHS of
>      >? ? ? >? ? ?the model:
>      >? ? ? >
>      >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >
>      >? ? ? >? ? ? ?> library(nnet) # for multinom()
>      >? ? ? >? ? ? ?> library(carData) # for BEPS data set
>      >? ? ? >
>      >? ? ? >? ? ? ?> # alternative ordering of the response levels:
>      >? ? ? >? ? ? ?> BEPS$vote1 <- factor(BEPS$vote, levels=c("Labour",
>     "Liberal
>      >? ? ? >? ? ?Democrat", "Conservative"))
>      >? ? ? >? ? ? ?> levels(BEPS$vote)
>      >? ? ? >? ? ?[1] "Conservative"? ? ?"Labour"? ? ? ? ? ?"Liberal
>     Democrat"
>      >? ? ? >? ? ? ?> levels(BEPS$vote1)
>      >? ? ? >? ? ?[1] "Labour"? ? ? ? ? ?"Liberal Democrat" "Conservative"
>      >? ? ? >
>      >? ? ? >? ? ? ?> m <- multinom(vote ~ . - vote1, data=BEPS)
>      >? ? ? >? ? ?# weights:? 33 (20 variable)
>      >? ? ? >? ? ?initial? value 1675.383740
>      >? ? ? >? ? ?iter? 10 value 1345.935273
>      >? ? ? >? ? ?iter? 20 value 1150.956807
>      >? ? ? >? ? ?iter? 30 value 1141.921662
>      >? ? ? >? ? ?iter? 30 value 1141.921661
>      >? ? ? >? ? ?iter? 30 value 1141.921661
>      >? ? ? >? ? ?final? value 1141.921661
>      >? ? ? >? ? ?converged
>      >? ? ? >? ? ? ?> m1 <- multinom(vote1 ~ . - vote, data=BEPS)
>      >? ? ? >? ? ?# weights:? 33 (20 variable)
>      >? ? ? >? ? ?initial? value 1675.383740
>      >? ? ? >? ? ?iter? 10 value 1280.439304
>      >? ? ? >? ? ?iter? 20 value 1165.513772
>      >? ? ? >? ? ?final? value 1141.921662
>      >? ? ? >? ? ?converged
>      >? ? ? >
>      >? ? ? >? ? ? ?> rbind(coef(m), coef(m1)) # compare coefficients
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? (Intercept)? ? ? ? ? age
>      >? ? ?economic.cond.national
>      >? ? ? >? ? ?economic.cond.household
>      >? ? ? >? ? ?Labour? ? ? ? ? ? ?0.9515214 -0.021913989             
>     0.5575707
>      >? ? ? >? ? ? ? ? ? 0.15839096
>      >? ? ? >? ? ?Liberal Democrat? ?1.4119306 -0.016810735             
>     0.1810761
>      >? ? ? >? ? ? ? ? ?-0.01196664
>      >? ? ? >? ? ?Liberal Democrat? ?0.4604567? 0.005102666           
>      ?-0.3764928
>      >? ? ? >? ? ? ? ? ?-0.17036682
>      >? ? ? >? ? ?Conservative? ? ? -0.9514466? 0.021912305           
>      ?-0.5575644
>      >? ? ? >? ? ? ? ? ?-0.15838744
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Blair? ? ? ?Hague? ? Kennedy 
>      ? ? Europe
>      >? ? ? >? ? ?political.knowledge
>      >? ? ? >? ? ?Labour? ? ? ? ? ? 0.8371764 -0.90775585? 0.2513436
>     -0.22781308
>      >? ? ? >? ? ?-0.5370612
>      >? ? ? >? ? ?Liberal Democrat? 0.2937331 -0.82217625? 0.6710567
>     -0.20004624
>      >? ? ? >? ? ?-0.2034605
>      >? ? ? >? ? ?Liberal Democrat -0.5434408? 0.08559455? 0.4197027 
>     0.02776465
>      >? ? ? >? ? ?0.3336068
>      >? ? ? >? ? ?Conservative? ? ?-0.8371670? 0.90778068 -0.2513735 
>     0.22781092
>      >? ? ? >? ? ?0.5370545
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gendermale
>      >? ? ? >? ? ?Labour? ? ? ? ? ? 0.13765774
>      >? ? ? >? ? ?Liberal Democrat? 0.12640823
>      >? ? ? >? ? ?Liberal Democrat -0.01125898
>      >? ? ? >? ? ?Conservative? ? ?-0.13764849
>      >? ? ? >
>      >? ? ? >? ? ? ?> c(logLik(m), logLik(m1)) # same fit to the data
>      >? ? ? >? ? ?[1] -1141.922 -1141.922
>      >? ? ? >
>      >? ? ? >? ? ? ?> # covariance matrices for coefficients:
>      >? ? ? >? ? ? ?> V <- vcov(m)
>      >? ? ? >? ? ? ?> V1 <- vcov(m1)
>      >? ? ? >? ? ? ?> cbind(colnames(V), colnames(V1)) # compare
>      >? ? ? >? ? ? ? ? ? ?[,1]? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?[,2]
>      >? ? ? >
>      >? ? ? >? ? ? ? [1,] "Labour:(Intercept)"                     
>      ?"Liberal
>      >? ? ? >? ? ?Democrat:(Intercept)"
>      >? ? ? >? ? ? ? [2,] "Labour:age"                             
>      ?"Liberal
>      >? ? ? >? ? ?Democrat:age"
>      >? ? ? >
>      >? ? ? >? ? ? ? [3,] "Labour:economic.cond.national"           
>     "Liberal
>      >? ? ? >? ? ?Democrat:economic.cond.national"
>      >? ? ? >? ? ? ? [4,] "Labour:economic.cond.household"         
>      ?"Liberal
>      >? ? ? >? ? ?Democrat:economic.cond.household"
>      >? ? ? >? ? ? ? [5,] "Labour:Blair"                           
>      ?"Liberal
>      >? ? ? >? ? ?Democrat:Blair"
>      >? ? ? >? ? ? ? [6,] "Labour:Hague"                           
>      ?"Liberal
>      >? ? ? >? ? ?Democrat:Hague"
>      >? ? ? >? ? ? ? [7,] "Labour:Kennedy"                         
>      ?"Liberal
>      >? ? ? >? ? ?Democrat:Kennedy"
>      >? ? ? >? ? ? ? [8,] "Labour:Europe"                           
>     "Liberal
>      >? ? ? >? ? ?Democrat:Europe"
>      >? ? ? >? ? ? ? [9,] "Labour:political.knowledge"             
>      ?"Liberal
>      >? ? ? >? ? ?Democrat:political.knowledge"
>      >? ? ? >? ? ?[10,] "Labour:gendermale"? ? ? ? ? ? ? ? ? ? ? ? "Liberal
>      >? ? ? >? ? ?Democrat:gendermale"
>      >? ? ? >? ? ?[11,] "Liberal Democrat:(Intercept)"
>      >? ? ? >? ? ?"Conservative:(Intercept)"
>      >? ? ? >? ? ?[12,] "Liberal Democrat:age"
>      >? ? ? ?"Conservative:age"
>      >? ? ? >
>      >? ? ? >? ? ?[13,] "Liberal Democrat:economic.cond.national"
>      >? ? ? >? ? ?"Conservative:economic.cond.national"
>      >? ? ? >? ? ?[14,] "Liberal Democrat:economic.cond.household"
>      >? ? ? >? ? ?"Conservative:economic.cond.household"
>      >? ? ? >? ? ?[15,] "Liberal Democrat:Blair"
>      >? ? ? ?"Conservative:Blair"
>      >? ? ? >
>      >? ? ? >? ? ?[16,] "Liberal Democrat:Hague"
>      >? ? ? ?"Conservative:Hague"
>      >? ? ? >
>      >? ? ? >? ? ?[17,] "Liberal Democrat:Kennedy"
>      >? ? ? ?"Conservative:Kennedy"
>      >? ? ? >
>      >? ? ? >? ? ?[18,] "Liberal Democrat:Europe"
>      >? ? ?"Conservative:Europe"
>      >? ? ? >
>      >? ? ? >? ? ?[19,] "Liberal Democrat:political.knowledge"
>      >? ? ? >? ? ?"Conservative:political.knowledge"
>      >? ? ? >? ? ?[20,] "Liberal Democrat:gendermale"
>      >? ? ? >? ? ?"Conservative:gendermale"
>      >? ? ? >
>      >? ? ? >? ? ? ?> int <- c(1, 11) # remove intercepts
>      >? ? ? >? ? ? ?> colnames(V)[int]
>      >? ? ? >? ? ?[1] "Labour:(Intercept)"? ? ? ? ? ?"Liberal
>     Democrat:(Intercept)"
>      >? ? ? >
>      >? ? ? >? ? ? ?> colnames(V1)[int]
>      >? ? ? >? ? ?[1] "Liberal Democrat:(Intercept)"
>     "Conservative:(Intercept)"
>      >? ? ? >? ? ? ?> V <- V[-int, -int]
>      >? ? ? >? ? ? ?> V1 <- V1[-int, -int]
>      >? ? ? >
>      >? ? ? >? ? ? ?> age <- c(1, 10) # locate age coefficients
>      >? ? ? >? ? ? ?> colnames(V)[age]
>      >? ? ? >? ? ?[1] "Labour:age"? ? ? ? ? ?"Liberal Democrat:age"
>      >? ? ? >? ? ? ?> colnames(V1)[age]
>      >? ? ? >? ? ?[1] "Liberal Democrat:age" "Conservative:age"
>      >? ? ? >
>      >? ? ? >? ? ? ?> V <- cov2cor(V) # compute coefficient correlations
>      >? ? ? >? ? ? ?> V1 <- cov2cor(V1)
>      >? ? ? >
>      >? ? ? >? ? ? ?> # compare GVIFs:
>      >? ? ? >? ? ? ?> c(det(V[age, age])*det(V[-age, -age])/det(V),
>      >? ? ? >? ? ?+? ?det(V1[age, age])*det(V1[-age, -age])/det(V1))
>      >? ? ? >? ? ?[1] 1.046232 1.046229
>      >? ? ? >
>      >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >
>      >? ? ? >? ? ?For curiosity, I applied car::vif() and
>      >? ? ? >? ? ?performance::check_collinearity() to these models to
>     see what
>      >? ? ?they
>      >? ? ? >? ? ?would
>      >? ? ? >? ? ?do. Both returned the wrong answer. vif() produced a
>     warning, but
>      >? ? ? >? ? ?check_collinearity() didn't:
>      >? ? ? >
>      >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >
>      >? ? ? >? ? ? ?> car::vif(m1)
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?age? economic.cond.national
>      >? ? ? >? ? ?economic.cond.household
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ?15.461045? ? ? ? ? ? ? ?22.137772
>      >? ? ? >? ? ? ?16.693877
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Blair? ? ? ? ? ? ? ? ? ?Hague
>      >? ? ? >? ? ? ?Kennedy
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ?14.681562? ? ? ? ? ? ? ? 7.483039
>      >? ? ? >? ? ? ?15.812067
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Europe? ? ?political.knowledge
>      >? ? ? >? ? ?gender
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? 6.502119? ? ? ? ? ? ? ? 4.219507
>      >? ? ? >? ? ?2.313885
>      >? ? ? >? ? ?Warning message:
>      >? ? ? >? ? ?In vif.default(m1) : No intercept: vifs may not be
>     sensible.
>      >? ? ? >
>      >? ? ? >? ? ? ?> performance::check_collinearity(m)
>      >? ? ? >? ? ?# Check for Multicollinearity
>      >? ? ? >
>      >? ? ? >? ? ?Low Correlation
>      >? ? ? >
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE Tolerance
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? age 1.72? ? ? ? ?1.31? ? ? 0.58
>      >? ? ? >? ? ? ? ?economic.cond.national 1.85? ? ? ? ?1.36? ? ? 0.54
>      >? ? ? >? ? ? ? economic.cond.household 1.86? ? ? ? ?1.37? ? ? 0.54
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Blair 1.63? ? ? ? ?1.28? ? ? 0.61
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Hague 1.94? ? ? ? ?1.39? ? ? 0.52
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Kennedy 1.70? ? ? ? ?1.30? ? ? 0.59
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Europe 2.01? ? ? ? ?1.42? ? ? 0.50
>      >? ? ? >? ? ? ? ? ? political.knowledge 1.94? ? ? ? ?1.39? ? ? 0.52
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gender 1.78? ? ? ? ?1.33? ? ? 0.56
>      >? ? ? >? ? ? ?> performance::check_collinearity(m1)
>      >? ? ? >? ? ?# Check for Multicollinearity
>      >? ? ? >
>      >? ? ? >? ? ?Low Correlation
>      >? ? ? >
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE Tolerance
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? age 1.19? ? ? ? ?1.09? ? ? 0.84
>      >? ? ? >? ? ? ? ?economic.cond.national 1.42? ? ? ? ?1.19? ? ? 0.70
>      >? ? ? >? ? ? ? economic.cond.household 1.32? ? ? ? ?1.15? ? ? 0.76
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Blair 1.50? ? ? ? ?1.22? ? ? 0.67
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Hague 1.30? ? ? ? ?1.14? ? ? 0.77
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Kennedy 1.19? ? ? ? ?1.09? ? ? 0.84
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Europe 1.34? ? ? ? ?1.16? ? ? 0.75
>      >? ? ? >? ? ? ? ? ? political.knowledge 1.30? ? ? ? ?1.14? ? ? 0.77
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gender 1.23? ? ? ? ?1.11? ? ? 0.81
>      >? ? ? >
>      >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >
>      >? ? ? >? ? ?I looked at the code for vif() and check_collinearity() to
>      >? ? ?see where
>      >? ? ? >? ? ?they went wrong. Both failed to handle the two
>     intercepts in
>      >? ? ?the model
>      >? ? ? >? ? ?correctly -- vif() thought there was no intercept and
>      >? ? ? >? ? ?check_collinearity() just removed the first intercept
>     but not the
>      >? ? ? >? ? ?second.
>      >? ? ? >
>      >? ? ? >? ? ?In examining the code for check_collinearity(), I
>     discovered a
>      >? ? ? >? ? ?couple of
>      >? ? ? >? ? ?additional disconcerting facts. First, part of the
>     code seems
>      >? ? ?to be
>      >? ? ? >? ? ?copied from vif.default(). Second, as a consequence,
>      >? ? ? >? ? ?check_collinearity() actually computes GVIFs rather
>     than VIFs
>      >? ? ?(and
>      >? ? ? >? ? ?doesn't reference either the Fox and Monette paper
>      >? ? ?introducing GVIFs or
>      >? ? ? >? ? ?the car package) but doesn't seem to understand that, and,
>      >? ? ?for example,
>      >? ? ? >? ? ?takes the squareroot of the GVIF (reported in the
>     column marked
>      >? ? ? >? ? ?"Increased SE") rather than the 2p root (when there
>     are p > 1
>      >? ? ? >? ? ?coefficients in a term).
>      >? ? ? >
>      >? ? ? >? ? ?Here's the relevant code from the two functions (where
>     . . .
>      >? ? ?denotes
>      >? ? ? >? ? ?elided lines) -- the default method for vif() and
>      >? ? ? >? ? ?.check_collinearity(),
>      >? ? ? >? ? ?which is called by check_collinearity.default():
>      >? ? ? >
>      >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >
>      >? ? ? >? ? ? ?> car:::vif.default
>      >? ? ? >? ? ?function (mod, ...)
>      >? ? ? >? ? ?{
>      >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? ? ? ?v <- vcov(mod)
>      >? ? ? >? ? ? ? ? ?assign <- attr(model.matrix(mod), "assign")
>      >? ? ? >? ? ? ? ? ?if (names(coefficients(mod)[1]) == "(Intercept)") {
>      >? ? ? >? ? ? ? ? ? ? ?v <- v[-1, -1]
>      >? ? ? >? ? ? ? ? ? ? ?assign <- assign[-1]
>      >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? ? ? ?else warning("No intercept: vifs may not be
>     sensible.")
>      >? ? ? >? ? ? ? ? ?terms <- labels(terms(mod))
>      >? ? ? >? ? ? ? ? ?n.terms <- length(terms)
>      >? ? ? >? ? ? ? ? ?if (n.terms < 2)
>      >? ? ? >? ? ? ? ? ? ? ?stop("model contains fewer than 2 terms")
>      >? ? ? >? ? ? ? ? ?R <- cov2cor(v)
>      >? ? ? >? ? ? ? ? ?detR <- det(R)
>      >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? ? ? ?for (term in 1:n.terms) {
>      >? ? ? >? ? ? ? ? ? ? ?subs <- which(assign == term)
>      >? ? ? >? ? ? ? ? ? ? ?result[term, 1] <- det(as.matrix(R[subs,
>     subs])) *
>      >? ? ? >? ? ?det(as.matrix(R[-subs,
>      >? ? ? >? ? ? ? ? ? ? ? ? ?-subs]))/detR
>      >? ? ? >? ? ? ? ? ? ? ?result[term, 2] <- length(subs)
>      >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ?}
>      >? ? ? >
>      >? ? ? >? ? ? ?> performance:::.check_collinearity
>      >? ? ? >? ? ?function (x, component, verbose = TRUE)
>      >? ? ? >? ? ?{
>      >? ? ? >? ? ? ? ? ?v <- insight::get_varcov(x, component = component,
>      >? ? ?verbose =
>      >? ? ? >? ? ?FALSE)
>      >? ? ? >? ? ? ? ? ?assign <- .term_assignments(x, component, verbose =
>      >? ? ?verbose)
>      >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? ? ? ?if (insight::has_intercept(x)) {
>      >? ? ? >? ? ? ? ? ? ? ?v <- v[-1, -1]
>      >? ? ? >? ? ? ? ? ? ? ?assign <- assign[-1]
>      >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? ? ? ?else {
>      >? ? ? >? ? ? ? ? ? ? ?if (isTRUE(verbose)) {
>      >? ? ? >? ? ? ? ? ? ? ? ? ?warning("Model has no intercept. VIFs
>     may not be
>      >? ? ? >? ? ?sensible.",
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?call. = FALSE)
>      >? ? ? >? ? ? ? ? ? ? ?}
>      >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? ? ? ? ? ?terms <- labels(stats::terms(f[[component]]))
>      >? ? ? >? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? ? ? ?n.terms <- length(terms)
>      >? ? ? >? ? ? ? ? ?if (n.terms < 2) {
>      >? ? ? >? ? ? ? ? ? ? ?if (isTRUE(verbose)) {
>      >? ? ? >? ? ? ? ? ? ? ? ? ?warning(insight::format_message(sprintf("Not
>      >? ? ?enough model
>      >? ? ? >? ? ?terms in the %s part of the model to check for
>      >? ? ?multicollinearity.",
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?component)), call. = FALSE)
>      >? ? ? >? ? ? ? ? ? ? ?}
>      >? ? ? >? ? ? ? ? ? ? ?return(NULL)
>      >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? ? ? ?R <- stats::cov2cor(v)
>      >? ? ? >? ? ? ? ? ?detR <- det(R)
>      >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? ? ? ?for (term in 1:n.terms) {
>      >? ? ? >? ? ? ? ? ? ? ?subs <- which(assign == term)
>      >? ? ? >? ? ? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? ? ? ? ? ? ? ?result <- c(result,
>     det(as.matrix(R[subs, subs])) *
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?det(as.matrix(R[-subs, -subs]))/detR)
>      >? ? ? >? ? ? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ?}
>      >? ? ? >
>      >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >
>      >? ? ? >? ? ?So, the upshot of all this is that you should be able
>     to do
>      >? ? ?what you
>      >? ? ? >? ? ?want, but not with either car::vif() or
>      >? ? ? >? ? ?performance::check_collinearity(). Instead, either
>     write your own
>      >? ? ? >? ? ?function or do the computations in a script.
>      >? ? ? >
>      >? ? ? >? ? ?There's also a lesson here about S3 default methods:
>     The fact
>      >? ? ?that a
>      >? ? ? >? ? ?default method returns a result rather than throwing
>     an error
>      >? ? ?or a
>      >? ? ? >? ? ?warning doesn't mean that the result is the right answer.
>      >? ? ? >
>      >? ? ? >? ? ?I hope this helps,
>      >? ? ? >? ? ? ? John
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >? ? ?On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen wrote:
>      >? ? ? >? ? ? > Dear John W,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Thank you very much for the tip-off! Apologies for not
>      >? ? ?responding
>      >? ? ? >? ? ?earlier
>      >? ? ? >? ? ? > (gmail apparently decided to direct your email
>     right into the
>      >? ? ? >? ? ?junk folder).
>      >? ? ? >? ? ? > I am very pleased to note that the package you
>     mention does
>      >? ? ? >? ? ?indeed work
>      >? ? ? >? ? ? > with *brms* multinomial models! Thanks again!
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Best,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Juho
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > pe 25. helmik. 2022 klo 19.23 John Willoughby
>      >? ? ? >? ? ?(johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>)
>      >? ? ? >? ? ? > kirjoitti:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >> Have you tried the check_collinearity() function
>     in the
>      >? ? ?performance
>      >? ? ? >? ? ? >> package? It's supposed to work on brms models, but
>     whether it
>      >? ? ? >? ? ?will work on
>      >? ? ? >? ? ? >> a multinomial model I don't know.? It works well
>     on mixed
>      >? ? ?models
>      >? ? ? >? ? ?generated
>      >? ? ? >? ? ? >> by glmmTMB().
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> John Willoughby
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> On Fri, Feb 25, 2022 at 3:01 AM
>      >? ? ? >? ? ?<r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>>
>      >? ? ? >? ? ? >> wrote:
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >>> Send R-sig-mixed-models mailing list submissions to
>      >? ? ? >? ? ? >>> r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> To subscribe or unsubscribe via the World Wide
>     Web, visit
>      >? ? ? >? ? ? >>>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >>> or, via email, send a message with subject or
>     body 'help' to
>      >? ? ? >? ? ? >>> r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> You can reach the person managing the list at
>      >? ? ? >? ? ? >>> r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>>
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> When replying, please edit your Subject line so it is
>      >? ? ?more specific
>      >? ? ? >? ? ? >>> than "Re: Contents of R-sig-mixed-models digest..."
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> Today's Topics:
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>>? ? ?1. Collinearity diagnostics for (mixed)
>     multinomial
>      >? ? ?models
>      >? ? ? >? ? ? >>>? ? ? ? (Juho Kristian Ruohonen)
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>>
>      >? ? ? >
>      >     
>      ?----------------------------------------------------------------------
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> Message: 1
>      >? ? ? >? ? ? >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
>      >? ? ? >? ? ? >>> From: Juho Kristian Ruohonen
>      >? ? ?<juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>>>
>      >? ? ? >? ? ? >>> To: John Fox <jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
>      >? ? ? >? ? ? >>> Cc: "r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>"
>      >? ? ? >? ? ? >>>? ? ? ? ? <r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>
>      >? ? ? >? ? ? >>> Subject: [R-sig-ME] Collinearity diagnostics for
>     (mixed)
>      >? ? ? >? ? ?multinomial
>      >? ? ? >? ? ? >>>? ? ? ? ? models
>      >? ? ? >? ? ? >>> Message-ID:
>      >? ? ? >? ? ? >>>? ? ? ? ? <
>      >? ? ? >? ? ? >>>
>      >? ? ? >
>      >
>     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
>     <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
>      >   
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
>      >? ? ? >
>      >     
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>>>
>      >? ? ? >? ? ? >>> Content-Type: text/plain; charset="utf-8"
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> Dear John (and anyone else qualified to comment),
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> I fit lots of mixed-effects multinomial models in my
>      >? ? ?research,
>      >? ? ? >? ? ?and I
>      >? ? ? >? ? ? >> would
>      >? ? ? >? ? ? >>> like to see some (multi)collinearity diagnostics
>     on the
>      >? ? ?fixed
>      >? ? ? >? ? ?effects, of
>      >? ? ? >? ? ? >>> which there are over 30. My models are fit using the
>      >? ? ?Bayesian
>      >? ? ? >? ? ?*brms*
>      >? ? ? >? ? ? >>> package because I know of no frequentist packages
>     with
>      >? ? ? >? ? ?multinomial GLMM
>      >? ? ? >? ? ? >>> compatibility.
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> With continuous or dichotomous outcomes, my go-to
>      >? ? ?function for
>      >? ? ? >? ? ? >> calculating
>      >? ? ? >? ? ? >>> multicollinearity diagnostics is of course
>     *vif()* from
>      >? ? ?the *car*
>      >? ? ? >? ? ? >> package.
>      >? ? ? >? ? ? >>> As expected, however, this function does not
>     report sensible
>      >? ? ? >? ? ?diagnostics
>      >? ? ? >? ? ? >>> for multinomial models -- not even for standard
>     ones fit
>      >? ? ?by the
>      >? ? ? >? ? ?*nnet*
>      >? ? ? >? ? ? >>> package's *multinom()* function. The reason, I
>     presume, is
>      >? ? ? >? ? ?because a
>      >? ? ? >? ? ? >>> multinomial model is not really one but C-1
>     regression
>      >? ? ?models
>      >? ? ? >? ? ?(where C
>      >? ? ? >? ? ? >> is
>      >? ? ? >? ? ? >>> the number of response categories) and the *vif()*
>      >? ? ?function is not
>      >? ? ? >? ? ? >> designed
>      >? ? ? >? ? ? >>> to deal with this scenario.
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> Therefore, in order to obtain meaningful collinearity
>      >? ? ?metrics,
>      >? ? ? >? ? ?my present
>      >? ? ? >? ? ? >>> plan is to write a simple helper function that uses
>      >? ? ?*vif() *to
>      >? ? ? >? ? ?calculate
>      >? ? ? >? ? ? >>> and present (generalized) variance inflation
>     metrics for
>      >? ? ?the C-1
>      >? ? ? >? ? ? >>> sub-datasets to which the C-1 component binomial
>     models
>      >? ? ?of the
>      >? ? ? >? ? ?overall
>      >? ? ? >? ? ? >>> multinomial model are fit. In other words, it
>     will partition
>      >? ? ? >? ? ?the data
>      >? ? ? >? ? ? >> into
>      >? ? ? >? ? ? >>> those C-1 subsets, and then apply *vif()* to as
>     many linear
>      >? ? ? >? ? ?regressions
>      >? ? ? >? ? ? >>> using a made-up continuous response and the fixed
>     effects of
>      >? ? ? >? ? ?interest.
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> Does this seem like a sensible approach?
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> Best,
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>> Juho
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >>? ? ? ? ? [[alternative HTML version deleted]]
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >> _______________________________________________
>      >? ? ? >? ? ? >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>      >? ? ? >? ? ? >>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > _______________________________________________
>      >? ? ? >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>      >? ? ? >? ? ? >
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ?--
>      >? ? ? >? ? ?John Fox, Professor Emeritus
>      >? ? ? >? ? ?McMaster University
>      >? ? ? >? ? ?Hamilton, Ontario, Canada
>      >? ? ? >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>
>      >? ? ? >
>      >? ? ?--
>      >? ? ?John Fox, Professor Emeritus
>      >? ? ?McMaster University
>      >? ? ?Hamilton, Ontario, Canada
>      >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
> 
------------------------------------------------------------------------
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Tue Mar  1 21:13:35 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Tue, 1 Mar 2022 22:13:35 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <0f03187e-d848-ea43-e370-ead2d403b530@mcmaster.ca>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
 <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
 <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>
 <0f03187e-d848-ea43-e370-ead2d403b530@mcmaster.ca>
Message-ID: <CAG_dBVfv2-8Z0VRvcK4QUP97oh5jOhPd2d=LUj0N_6Ec+appMw@mail.gmail.com>

Dear John,

Yes, my function uses your code for the math. I was just hoping to verify
that it is handling multicategory factors correctly (your examples didn't
involve any).

I guess interactions aren't that important after all, given that the chief
concern is usually collinearity among main effects.

Many thanks for all your help.

Best,

Juho

ti 1. maalisk. 2022 klo 18.01 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juho,
>
> On 2022-03-01 8:24 a.m., Juho Kristian Ruohonen wrote:
> > Dear John (Fox, as well as other list members),
> >
> > I've now written a simple function to try and calculate GVIFS for all
> > predictors in a nnet::multinom() object based on John's example code. If
> > its results are correct (see below), I will proceed to write a version
> > that also works with mixed-effects multinomial models fit by
> > brms::brm(). Here's the code:
> >
> >     gvif.multinom <- function(model){
> >        (classes <- model$lev)
> >        (V.all <- vcov(model))
> >        (V.noIntercepts <- V.all[!grepl("\\(Intercept\\)$",
> >     rownames(V.all), perl = T),
> >                                 !grepl("\\(Intercept\\)$",
> >     colnames(V.all), perl = T)])
> >        (R <- cov2cor(V.noIntercepts))
> >        (terms <- attr(model$terms, "term.labels"))
> >        (gvif <- numeric(length = length(terms)))
> >        (names(gvif) <- terms)
> >        (SE.multiplier <- numeric(length = length(terms)))
> >        (names(SE.multiplier) <- terms)
> >        #The line below tries to capture all factor levels into a regex
> >     for coef name matching.
> >        (LevelsRegex <- paste0("(", paste(unlist(model$xlevels), collapse
> >     = "|"),")?"))
> >
> >        for(i in terms){
> >          #The regex stuff below tries to ensure all interaction
> >     coefficients are matched, including those involving factors.
> >          if(grepl(":", i)){
> >            (termname <- gsub(":", paste0(LevelsRegex, ":"), i, perl = T))
> >          }else{termname <- i}
> >          (RegexToMatch <- paste0("^(", paste(classes[2:length(classes)],
> >     collapse = "|") ,"):", termname, LevelsRegex, "$"))
> >
> >          #Now the actual calculation:
> >          (indices <- grep(RegexToMatch, rownames(R), perl = T))
> >          (gvif[i] <- det(R[indices, indices]) * det(R[-indices,
> >     -indices]) / det(R))
> >          (SE.multiplier[i] <- gvif[i]^(1/(2*length(indices))))
> >        }
> >        #Put the results together and order them by degree of SE
> inflation:
> >        (result <- cbind(GVIF = gvif, `GVIF^(1/(2df))` = SE.multiplier))
> >        return(result[order(result[,"GVIF^(1/(2df))"], decreasing = T),])}
> >
> >
> > The results seem correct to me when applied to John's example model fit
> > to the BEPS data. However, that dataset contains no multi-df factors, of
> > which my own models have many. Below is a maximally simple example with
> > one multi-df factor (/region/):
> >
> >     mod1 <- multinom(partic ~., data = carData::Womenlf)
> >     gvif.multinom(mod1)
> >
> >     GVIF GVIF^(1/(2df))
> >     children 1.298794       1.067542
> >     hincome  1.184215       1.043176
> >     region   1.381480       1.020403
> >
> >
> > These results look plausible to me. Finally, below is an example
> > involving both a multi-df factor and an interaction:
> >
> >     mod2 <- update(mod1, ~. +children:region)
> >     gvif.multinom(mod2)
> >
> >                              GVIF GVIF^(1/(2df))
> >     children:region 4.965762e+16      11.053482
> >     region          1.420418e+16      10.221768
> >     children        1.471412e+03       6.193463
> >     hincome         6.462161e+00       1.594390
> >
> >
> > These results look a bit more dubious. To be sure, it is to be expected
> > that interaction terms will introduce a lot of collinearity. But an
> > 11-fold increase in SE? I hope someone can tell me whether this is
> > correct or not!
>
> You don't need someone else to check your work because you could just
> apply the simple function that I sent you yesterday, which, though not
> automatic, computes the GVIFs in a transparent manner.
>
> A brief comment on GVIFs for models with interactions (this isn't the
> place to discuss the question in detail): The Fox and Monette JASA paper
> addresses the question briefly in the context of a two-way ANOVA, but I
> don't think that the approach suggested there is easily generalized.
>
> The following simple approach pays attention to what's invariant under
> different parametrizations of the RHS side of the model: Simultaneously
> check the collinearity of all of the coefficients of an interaction
> together with the main effects and, potentially, lower-order
> interactions that are marginal to it. So, e.g., in the model y ~ a + b +
> a:b + c, you'd check all of the coefficients for a, b, and a:b together.
>
> Alternatively, one could focus in turn on each explanatory variable and
> check the collinearity of all coefficients to which it is marginal. So
> in y ~ a + b + c + a:b + a:c + d, when you focus on a, you'd look at all
> of the coefficients for a, b, c, a:b, and a:c.
>
> John
>
> >
> > Best,
> >
> > Juho
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > ti 1. maalisk. 2022 klo 0.05 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Juha,
> >
> >     On 2022-02-28 5:00 p.m., Juho Kristian Ruohonen wrote:
> >      > Apologies for my misreading, John, and many thanks for showing
> >     how the
> >      > calculation is done for a single term.
> >      >
> >      > Do you think *vif()* might be updated in the near future with the
> >      > capability of auto-detecting a multinomial model and returning
> >      > mathematically correct GVIF statistics?
> >
> >     The thought crossed my mind, but I'd want to do it in a general way,
> >     not
> >     just for the multinom() function, and in a way that avoids incorrect
> >     results such as those currently produced for "multinom" models,
> albeit
> >     with a warning. I can't guarantee whether or when I'll be able to do
> >     that.
> >
> >     John
> >
> >      >
> >      > If not, I'll proceed to writing my own function based on your
> >     example.
> >      > However, /car/ is such an excellent and widely used package that
> the
> >      > greatest benefit to mankind would probably accrue if /car /was
> >     upgraded
> >      > with this feature sooner rather than later.
> >      >
> >      > Best,
> >      >
> >      > Juho
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      > ma 28. helmik. 2022 klo 17.08 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
> >      >
> >      >     Dear Juho,
> >      >
> >      >     On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen wrote:
> >      >      > Dear Professor Fox and other list members,
> >      >      >
> >      >      > Profuse thanks for doing that detective work for me! I
> myself
> >      >     thought
> >      >      > the inflation factors reported by check_collinearity() were
> >      >     suspiciously
> >      >      > high, but unlike you I lacked the expertise to identify
> >     what was
> >      >     going on.
> >      >      >
> >      >      > As for your suggested approach, have I understood this
> >     correctly:
> >      >      >
> >      >      > Since there doesn't yet exist an R function that will
> >     calculate the
> >      >      > (G)VIFS of multinomial models correctly, my best bet for
> >     now is
> >      >     just to
> >      >      > ignore the fact that such models partition the data into
> C-1
> >      >     subsets,
> >      >      > and to calculate approximate GVIFs from the entire dataset
> at
> >      >     once as if
> >      >      > the response were continuous? And a simple way to do this
> >     is to
> >      >      > construct a fake continuous response, call
> >     *lm(fakeresponse ~.)*,
> >      >     and
> >      >      > apply *car::vif()* on the result?
> >      >
> >      >     No, you misunderstand my suggestion, which perhaps isn't
> >     surprising
> >      >     given the length of my message. What you propose is what I
> >     suggested as
> >      >     a rough approximation *before* I confirmed that my guess of
> the
> >      >     solution
> >      >     was correct.
> >      >
> >      >     The R code that I sent yesterday showed how to compute the
> >     GVIF for a
> >      >     multinomial regression model, and I suggested that you write
> >     either a
> >      >     script or a simple function to do that. Here's a function
> >     that will
> >      >     work
> >      >     for a model object that responds to vcov():
> >      >
> >      >     GVIF <- function(model, intercepts, term){
> >      >         # model: regression model object
> >      >         # intercepts: row/column positions of intercepts in the
> >     coefficient
> >      >     covariance matrix
> >      >         # term: row/column positions of the coefficients for the
> >     focal term
> >      >         V <- vcov(model)
> >      >         term <- colnames(V)[term]
> >      >         V <- V[-intercepts, -intercepts]
> >      >         V <- cov2cor(V)
> >      >         term <- which(colnames(V) %in% term)
> >      >         gvif <- det(V[term, term])*det(V[-term, -term])/det(V)
> >      >         c(GVIF=gvif, "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
> >      >     }
> >      >
> >      >     and here's an application to the multinom() example that I
> >     showed you
> >      >     yesterday:
> >      >
> >      >       > colnames(vcov(m)) # to get coefficient positions
> >      >        [1] "Labour:(Intercept)"                       "Labour:age"
> >      >
> >      >        [3] "Labour:economic.cond.national"
> >      >     "Labour:economic.cond.household"
> >      >        [5] "Labour:Blair"
>  "Labour:Hague"
> >      >
> >      >        [7] "Labour:Kennedy"
>  "Labour:Europe"
> >      >
> >      >        [9] "Labour:political.knowledge"
> >       "Labour:gendermale"
> >      >
> >      >     [11] "Liberal Democrat:(Intercept)"             "Liberal
> >     Democrat:age"
> >      >
> >      >     [13] "Liberal Democrat:economic.cond.national"  "Liberal
> >      >     Democrat:economic.cond.household"
> >      >     [15] "Liberal Democrat:Blair"                   "Liberal
> >      >     Democrat:Hague"
> >      >
> >      >     [17] "Liberal Democrat:Kennedy"                 "Liberal
> >      >     Democrat:Europe"
> >      >     [19] "Liberal Democrat:political.knowledge"     "Liberal
> >      >     Democrat:gendermale"
> >      >
> >      >       > GVIF(m, intercepts=c(1, 11), term=c(2, 12)) # GVIF for age
> >      >                 GVIF GVIF^(1/(2*p))
> >      >             1.046232       1.011363
> >      >
> >      >
> >      >     Finally, here's what you get for a linear model with the same
> RHS
> >      >     (where
> >      >     the sqrt(VIF) should be a rough approximation to GVIF^(1/4)
> >     reported by
> >      >     my GVIF() function):
> >      >
> >      >       > m.lm <- lm(as.numeric(vote) ~ . - vote1, data=BEPS)
> >      >       > sqrt(car::vif(m.lm))
> >      >                           age  economic.cond.national
> >      >     economic.cond.household
> >      >                         Blair
> >      >                      1.006508                1.124132
> >      >     1.075656
> >      >                      1.118441
> >      >                         Hague                 Kennedy
> >      >     Europe
> >      >           political.knowledge
> >      >                      1.066799                1.015532
> >      >     1.101741
> >      >                      1.028546
> >      >                        gender
> >      >                      1.017386
> >      >
> >      >
> >      >     John
> >      >
> >      >      >
> >      >      > Best,
> >      >      >
> >      >      > Juho
> >      >      >
> >      >      > ma 28. helmik. 2022 klo 2.23 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
> >      >      >
> >      >      >     Dear Juho,
> >      >      >
> >      >      >     I've now had a chance to think about this problem some
> >     more,
> >      >     and I
> >      >      >     believe that the approach I suggested is correct. I
> >     also had an
> >      >      >     opportunity to talk the problem over a bit with Georges
> >      >     Monette, who
> >      >      >     coauthored the paper that introduced generalized
> variance
> >      >     inflation
> >      >      >     factors (GVIFs). On the other hand, the results
> >     produced by
> >      >      >     performance::check_collinearity() for multinomial logit
> >      >     models don't
> >      >      >     seem to be correct (see below).
> >      >      >
> >      >      >     Here's an example, using the nnet::multinom() function
> >     to fit a
> >      >      >     multinomial logit model, with alternative
> >     parametrizations of the
> >      >      >     LHS of
> >      >      >     the model:
> >      >      >
> >      >      >     --------- snip -----------
> >      >      >
> >      >      >       > library(nnet) # for multinom()
> >      >      >       > library(carData) # for BEPS data set
> >      >      >
> >      >      >       > # alternative ordering of the response levels:
> >      >      >       > BEPS$vote1 <- factor(BEPS$vote, levels=c("Labour",
> >     "Liberal
> >      >      >     Democrat", "Conservative"))
> >      >      >       > levels(BEPS$vote)
> >      >      >     [1] "Conservative"     "Labour"           "Liberal
> >     Democrat"
> >      >      >       > levels(BEPS$vote1)
> >      >      >     [1] "Labour"           "Liberal Democrat"
> "Conservative"
> >      >      >
> >      >      >       > m <- multinom(vote ~ . - vote1, data=BEPS)
> >      >      >     # weights:  33 (20 variable)
> >      >      >     initial  value 1675.383740
> >      >      >     iter  10 value 1345.935273
> >      >      >     iter  20 value 1150.956807
> >      >      >     iter  30 value 1141.921662
> >      >      >     iter  30 value 1141.921661
> >      >      >     iter  30 value 1141.921661
> >      >      >     final  value 1141.921661
> >      >      >     converged
> >      >      >       > m1 <- multinom(vote1 ~ . - vote, data=BEPS)
> >      >      >     # weights:  33 (20 variable)
> >      >      >     initial  value 1675.383740
> >      >      >     iter  10 value 1280.439304
> >      >      >     iter  20 value 1165.513772
> >      >      >     final  value 1141.921662
> >      >      >     converged
> >      >      >
> >      >      >       > rbind(coef(m), coef(m1)) # compare coefficients
> >      >      >                        (Intercept)          age
> >      >     economic.cond.national
> >      >      >     economic.cond.household
> >      >      >     Labour             0.9515214 -0.021913989
> >     0.5575707
> >      >      >            0.15839096
> >      >      >     Liberal Democrat   1.4119306 -0.016810735
> >     0.1810761
> >      >      >           -0.01196664
> >      >      >     Liberal Democrat   0.4604567  0.005102666
> >       -0.3764928
> >      >      >           -0.17036682
> >      >      >     Conservative      -0.9514466  0.021912305
> >       -0.5575644
> >      >      >           -0.15838744
> >      >      >                             Blair       Hague    Kennedy
> >          Europe
> >      >      >     political.knowledge
> >      >      >     Labour            0.8371764 -0.90775585  0.2513436
> >     -0.22781308
> >      >      >     -0.5370612
> >      >      >     Liberal Democrat  0.2937331 -0.82217625  0.6710567
> >     -0.20004624
> >      >      >     -0.2034605
> >      >      >     Liberal Democrat -0.5434408  0.08559455  0.4197027
> >     0.02776465
> >      >      >     0.3336068
> >      >      >     Conservative     -0.8371670  0.90778068 -0.2513735
> >     0.22781092
> >      >      >     0.5370545
> >      >      >                         gendermale
> >      >      >     Labour            0.13765774
> >      >      >     Liberal Democrat  0.12640823
> >      >      >     Liberal Democrat -0.01125898
> >      >      >     Conservative     -0.13764849
> >      >      >
> >      >      >       > c(logLik(m), logLik(m1)) # same fit to the data
> >      >      >     [1] -1141.922 -1141.922
> >      >      >
> >      >      >       > # covariance matrices for coefficients:
> >      >      >       > V <- vcov(m)
> >      >      >       > V1 <- vcov(m1)
> >      >      >       > cbind(colnames(V), colnames(V1)) # compare
> >      >      >             [,1]                                       [,2]
> >      >      >
> >      >      >        [1,] "Labour:(Intercept)"
> >       "Liberal
> >      >      >     Democrat:(Intercept)"
> >      >      >        [2,] "Labour:age"
> >       "Liberal
> >      >      >     Democrat:age"
> >      >      >
> >      >      >        [3,] "Labour:economic.cond.national"
> >     "Liberal
> >      >      >     Democrat:economic.cond.national"
> >      >      >        [4,] "Labour:economic.cond.household"
> >       "Liberal
> >      >      >     Democrat:economic.cond.household"
> >      >      >        [5,] "Labour:Blair"
> >       "Liberal
> >      >      >     Democrat:Blair"
> >      >      >        [6,] "Labour:Hague"
> >       "Liberal
> >      >      >     Democrat:Hague"
> >      >      >        [7,] "Labour:Kennedy"
> >       "Liberal
> >      >      >     Democrat:Kennedy"
> >      >      >        [8,] "Labour:Europe"
> >     "Liberal
> >      >      >     Democrat:Europe"
> >      >      >        [9,] "Labour:political.knowledge"
> >       "Liberal
> >      >      >     Democrat:political.knowledge"
> >      >      >     [10,] "Labour:gendermale"
> "Liberal
> >      >      >     Democrat:gendermale"
> >      >      >     [11,] "Liberal Democrat:(Intercept)"
> >      >      >     "Conservative:(Intercept)"
> >      >      >     [12,] "Liberal Democrat:age"
> >      >       "Conservative:age"
> >      >      >
> >      >      >     [13,] "Liberal Democrat:economic.cond.national"
> >      >      >     "Conservative:economic.cond.national"
> >      >      >     [14,] "Liberal Democrat:economic.cond.household"
> >      >      >     "Conservative:economic.cond.household"
> >      >      >     [15,] "Liberal Democrat:Blair"
> >      >       "Conservative:Blair"
> >      >      >
> >      >      >     [16,] "Liberal Democrat:Hague"
> >      >       "Conservative:Hague"
> >      >      >
> >      >      >     [17,] "Liberal Democrat:Kennedy"
> >      >       "Conservative:Kennedy"
> >      >      >
> >      >      >     [18,] "Liberal Democrat:Europe"
> >      >     "Conservative:Europe"
> >      >      >
> >      >      >     [19,] "Liberal Democrat:political.knowledge"
> >      >      >     "Conservative:political.knowledge"
> >      >      >     [20,] "Liberal Democrat:gendermale"
> >      >      >     "Conservative:gendermale"
> >      >      >
> >      >      >       > int <- c(1, 11) # remove intercepts
> >      >      >       > colnames(V)[int]
> >      >      >     [1] "Labour:(Intercept)"           "Liberal
> >     Democrat:(Intercept)"
> >      >      >
> >      >      >       > colnames(V1)[int]
> >      >      >     [1] "Liberal Democrat:(Intercept)"
> >     "Conservative:(Intercept)"
> >      >      >       > V <- V[-int, -int]
> >      >      >       > V1 <- V1[-int, -int]
> >      >      >
> >      >      >       > age <- c(1, 10) # locate age coefficients
> >      >      >       > colnames(V)[age]
> >      >      >     [1] "Labour:age"           "Liberal Democrat:age"
> >      >      >       > colnames(V1)[age]
> >      >      >     [1] "Liberal Democrat:age" "Conservative:age"
> >      >      >
> >      >      >       > V <- cov2cor(V) # compute coefficient correlations
> >      >      >       > V1 <- cov2cor(V1)
> >      >      >
> >      >      >       > # compare GVIFs:
> >      >      >       > c(det(V[age, age])*det(V[-age, -age])/det(V),
> >      >      >     +   det(V1[age, age])*det(V1[-age, -age])/det(V1))
> >      >      >     [1] 1.046232 1.046229
> >      >      >
> >      >      >     --------- snip -----------
> >      >      >
> >      >      >     For curiosity, I applied car::vif() and
> >      >      >     performance::check_collinearity() to these models to
> >     see what
> >      >     they
> >      >      >     would
> >      >      >     do. Both returned the wrong answer. vif() produced a
> >     warning, but
> >      >      >     check_collinearity() didn't:
> >      >      >
> >      >      >     --------- snip -----------
> >      >      >
> >      >      >       > car::vif(m1)
> >      >      >                           age  economic.cond.national
> >      >      >     economic.cond.household
> >      >      >                     15.461045               22.137772
> >      >      >       16.693877
> >      >      >                         Blair                   Hague
> >      >      >       Kennedy
> >      >      >                     14.681562                7.483039
> >      >      >       15.812067
> >      >      >                        Europe     political.knowledge
> >      >      >     gender
> >      >      >                      6.502119                4.219507
> >      >      >     2.313885
> >      >      >     Warning message:
> >      >      >     In vif.default(m1) : No intercept: vifs may not be
> >     sensible.
> >      >      >
> >      >      >       > performance::check_collinearity(m)
> >      >      >     # Check for Multicollinearity
> >      >      >
> >      >      >     Low Correlation
> >      >      >
> >      >      >                           Term  VIF Increased SE Tolerance
> >      >      >                            age 1.72         1.31      0.58
> >      >      >         economic.cond.national 1.85         1.36      0.54
> >      >      >        economic.cond.household 1.86         1.37      0.54
> >      >      >                          Blair 1.63         1.28      0.61
> >      >      >                          Hague 1.94         1.39      0.52
> >      >      >                        Kennedy 1.70         1.30      0.59
> >      >      >                         Europe 2.01         1.42      0.50
> >      >      >            political.knowledge 1.94         1.39      0.52
> >      >      >                         gender 1.78         1.33      0.56
> >      >      >       > performance::check_collinearity(m1)
> >      >      >     # Check for Multicollinearity
> >      >      >
> >      >      >     Low Correlation
> >      >      >
> >      >      >                           Term  VIF Increased SE Tolerance
> >      >      >                            age 1.19         1.09      0.84
> >      >      >         economic.cond.national 1.42         1.19      0.70
> >      >      >        economic.cond.household 1.32         1.15      0.76
> >      >      >                          Blair 1.50         1.22      0.67
> >      >      >                          Hague 1.30         1.14      0.77
> >      >      >                        Kennedy 1.19         1.09      0.84
> >      >      >                         Europe 1.34         1.16      0.75
> >      >      >            political.knowledge 1.30         1.14      0.77
> >      >      >                         gender 1.23         1.11      0.81
> >      >      >
> >      >      >     --------- snip -----------
> >      >      >
> >      >      >     I looked at the code for vif() and
> check_collinearity() to
> >      >     see where
> >      >      >     they went wrong. Both failed to handle the two
> >     intercepts in
> >      >     the model
> >      >      >     correctly -- vif() thought there was no intercept and
> >      >      >     check_collinearity() just removed the first intercept
> >     but not the
> >      >      >     second.
> >      >      >
> >      >      >     In examining the code for check_collinearity(), I
> >     discovered a
> >      >      >     couple of
> >      >      >     additional disconcerting facts. First, part of the
> >     code seems
> >      >     to be
> >      >      >     copied from vif.default(). Second, as a consequence,
> >      >      >     check_collinearity() actually computes GVIFs rather
> >     than VIFs
> >      >     (and
> >      >      >     doesn't reference either the Fox and Monette paper
> >      >     introducing GVIFs or
> >      >      >     the car package) but doesn't seem to understand that,
> and,
> >      >     for example,
> >      >      >     takes the squareroot of the GVIF (reported in the
> >     column marked
> >      >      >     "Increased SE") rather than the 2p root (when there
> >     are p > 1
> >      >      >     coefficients in a term).
> >      >      >
> >      >      >     Here's the relevant code from the two functions (where
> >     . . .
> >      >     denotes
> >      >      >     elided lines) -- the default method for vif() and
> >      >      >     .check_collinearity(),
> >      >      >     which is called by check_collinearity.default():
> >      >      >
> >      >      >     --------- snip -----------
> >      >      >
> >      >      >       > car:::vif.default
> >      >      >     function (mod, ...)
> >      >      >     {
> >      >      >           . . .
> >      >      >           v <- vcov(mod)
> >      >      >           assign <- attr(model.matrix(mod), "assign")
> >      >      >           if (names(coefficients(mod)[1]) ==
> "(Intercept)") {
> >      >      >               v <- v[-1, -1]
> >      >      >               assign <- assign[-1]
> >      >      >           }
> >      >      >           else warning("No intercept: vifs may not be
> >     sensible.")
> >      >      >           terms <- labels(terms(mod))
> >      >      >           n.terms <- length(terms)
> >      >      >           if (n.terms < 2)
> >      >      >               stop("model contains fewer than 2 terms")
> >      >      >           R <- cov2cor(v)
> >      >      >           detR <- det(R)
> >      >      >           . . .
> >      >      >           for (term in 1:n.terms) {
> >      >      >               subs <- which(assign == term)
> >      >      >               result[term, 1] <- det(as.matrix(R[subs,
> >     subs])) *
> >      >      >     det(as.matrix(R[-subs,
> >      >      >                   -subs]))/detR
> >      >      >               result[term, 2] <- length(subs)
> >      >      >           }
> >      >      >           . . .
> >      >      >     }
> >      >      >
> >      >      >       > performance:::.check_collinearity
> >      >      >     function (x, component, verbose = TRUE)
> >      >      >     {
> >      >      >           v <- insight::get_varcov(x, component =
> component,
> >      >     verbose =
> >      >      >     FALSE)
> >      >      >           assign <- .term_assignments(x, component,
> verbose =
> >      >     verbose)
> >      >      >           . . .
> >      >      >           if (insight::has_intercept(x)) {
> >      >      >               v <- v[-1, -1]
> >      >      >               assign <- assign[-1]
> >      >      >           }
> >      >      >           else {
> >      >      >               if (isTRUE(verbose)) {
> >      >      >                   warning("Model has no intercept. VIFs
> >     may not be
> >      >      >     sensible.",
> >      >      >                       call. = FALSE)
> >      >      >               }
> >      >      >           }
> >      >      >               . . .
> >      >      >               terms <- labels(stats::terms(f[[component]]))
> >      >      >               . . .
> >      >      >           n.terms <- length(terms)
> >      >      >           if (n.terms < 2) {
> >      >      >               if (isTRUE(verbose)) {
> >      >      >
>  warning(insight::format_message(sprintf("Not
> >      >     enough model
> >      >      >     terms in the %s part of the model to check for
> >      >     multicollinearity.",
> >      >      >                       component)), call. = FALSE)
> >      >      >               }
> >      >      >               return(NULL)
> >      >      >           }
> >      >      >           R <- stats::cov2cor(v)
> >      >      >           detR <- det(R)
> >      >      >           . . .
> >      >      >           for (term in 1:n.terms) {
> >      >      >               subs <- which(assign == term)
> >      >      >                   . . .
> >      >      >                   result <- c(result,
> >     det(as.matrix(R[subs, subs])) *
> >      >      >                       det(as.matrix(R[-subs, -subs]))/detR)
> >      >      >                   . . .
> >      >      >           }
> >      >      >           . . .
> >      >      >     }
> >      >      >
> >      >      >     --------- snip -----------
> >      >      >
> >      >      >     So, the upshot of all this is that you should be able
> >     to do
> >      >     what you
> >      >      >     want, but not with either car::vif() or
> >      >      >     performance::check_collinearity(). Instead, either
> >     write your own
> >      >      >     function or do the computations in a script.
> >      >      >
> >      >      >     There's also a lesson here about S3 default methods:
> >     The fact
> >      >     that a
> >      >      >     default method returns a result rather than throwing
> >     an error
> >      >     or a
> >      >      >     warning doesn't mean that the result is the right
> answer.
> >      >      >
> >      >      >     I hope this helps,
> >      >      >        John
> >      >      >
> >      >      >
> >      >      >     On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen wrote:
> >      >      >      > Dear John W,
> >      >      >      >
> >      >      >      > Thank you very much for the tip-off! Apologies for
> not
> >      >     responding
> >      >      >     earlier
> >      >      >      > (gmail apparently decided to direct your email
> >     right into the
> >      >      >     junk folder).
> >      >      >      > I am very pleased to note that the package you
> >     mention does
> >      >      >     indeed work
> >      >      >      > with *brms* multinomial models! Thanks again!
> >      >      >      >
> >      >      >      > Best,
> >      >      >      >
> >      >      >      > Juho
> >      >      >      >
> >      >      >      > pe 25. helmik. 2022 klo 19.23 John Willoughby
> >      >      >     (johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>)
> >      >      >      > kirjoitti:
> >      >      >      >
> >      >      >      >> Have you tried the check_collinearity() function
> >     in the
> >      >     performance
> >      >      >      >> package? It's supposed to work on brms models, but
> >     whether it
> >      >      >     will work on
> >      >      >      >> a multinomial model I don't know.  It works well
> >     on mixed
> >      >     models
> >      >      >     generated
> >      >      >      >> by glmmTMB().
> >      >      >      >>
> >      >      >      >> John Willoughby
> >      >      >      >>
> >      >      >      >>
> >      >      >      >> On Fri, Feb 25, 2022 at 3:01 AM
> >      >      >     <r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>
> >      >      >      >> wrote:
> >      >      >      >>
> >      >      >      >>> Send R-sig-mixed-models mailing list submissions
> to
> >      >      >      >>> r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >>>
> >      >      >      >>> To subscribe or unsubscribe via the World Wide
> >     Web, visit
> >      >      >      >>>
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >>> or, via email, send a message with subject or
> >     body 'help' to
> >      >      >      >>> r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >      >      >>>
> >      >      >      >>> You can reach the person managing the list at
> >      >      >      >>> r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>
> >      >      >      >>>
> >      >      >      >>> When replying, please edit your Subject line so
> it is
> >      >     more specific
> >      >      >      >>> than "Re: Contents of R-sig-mixed-models
> digest..."
> >      >      >      >>>
> >      >      >      >>>
> >      >      >      >>> Today's Topics:
> >      >      >      >>>
> >      >      >      >>>     1. Collinearity diagnostics for (mixed)
> >     multinomial
> >      >     models
> >      >      >      >>>        (Juho Kristian Ruohonen)
> >      >      >      >>>
> >      >      >      >>>
> >      >      >
> >      >
> >
>  ----------------------------------------------------------------------
> >      >      >      >>>
> >      >      >      >>> Message: 1
> >      >      >      >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
> >      >      >      >>> From: Juho Kristian Ruohonen
> >      >     <juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>>
> >      >      >      >>> To: John Fox <jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
> >      >      >      >>> Cc: "r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>"
> >      >      >      >>>          <r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >      >      >>> Subject: [R-sig-ME] Collinearity diagnostics for
> >     (mixed)
> >      >      >     multinomial
> >      >      >      >>>          models
> >      >      >      >>> Message-ID:
> >      >      >      >>>          <
> >      >      >      >>>
> >      >      >
> >      >
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >      >
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>>
> >      >      >      >>> Content-Type: text/plain; charset="utf-8"
> >      >      >      >>>
> >      >      >      >>> Dear John (and anyone else qualified to comment),
> >      >      >      >>>
> >      >      >      >>> I fit lots of mixed-effects multinomial models in
> my
> >      >     research,
> >      >      >     and I
> >      >      >      >> would
> >      >      >      >>> like to see some (multi)collinearity diagnostics
> >     on the
> >      >     fixed
> >      >      >     effects, of
> >      >      >      >>> which there are over 30. My models are fit using
> the
> >      >     Bayesian
> >      >      >     *brms*
> >      >      >      >>> package because I know of no frequentist packages
> >     with
> >      >      >     multinomial GLMM
> >      >      >      >>> compatibility.
> >      >      >      >>>
> >      >      >      >>> With continuous or dichotomous outcomes, my go-to
> >      >     function for
> >      >      >      >> calculating
> >      >      >      >>> multicollinearity diagnostics is of course
> >     *vif()* from
> >      >     the *car*
> >      >      >      >> package.
> >      >      >      >>> As expected, however, this function does not
> >     report sensible
> >      >      >     diagnostics
> >      >      >      >>> for multinomial models -- not even for standard
> >     ones fit
> >      >     by the
> >      >      >     *nnet*
> >      >      >      >>> package's *multinom()* function. The reason, I
> >     presume, is
> >      >      >     because a
> >      >      >      >>> multinomial model is not really one but C-1
> >     regression
> >      >     models
> >      >      >     (where C
> >      >      >      >> is
> >      >      >      >>> the number of response categories) and the *vif()*
> >      >     function is not
> >      >      >      >> designed
> >      >      >      >>> to deal with this scenario.
> >      >      >      >>>
> >      >      >      >>> Therefore, in order to obtain meaningful
> collinearity
> >      >     metrics,
> >      >      >     my present
> >      >      >      >>> plan is to write a simple helper function that
> uses
> >      >     *vif() *to
> >      >      >     calculate
> >      >      >      >>> and present (generalized) variance inflation
> >     metrics for
> >      >     the C-1
> >      >      >      >>> sub-datasets to which the C-1 component binomial
> >     models
> >      >     of the
> >      >      >     overall
> >      >      >      >>> multinomial model are fit. In other words, it
> >     will partition
> >      >      >     the data
> >      >      >      >> into
> >      >      >      >>> those C-1 subsets, and then apply *vif()* to as
> >     many linear
> >      >      >     regressions
> >      >      >      >>> using a made-up continuous response and the fixed
> >     effects of
> >      >      >     interest.
> >      >      >      >>>
> >      >      >      >>> Does this seem like a sensible approach?
> >      >      >      >>>
> >      >      >      >>> Best,
> >      >      >      >>>
> >      >      >      >>> Juho
> >      >      >      >>>
> >      >      >      >>>
> >      >      >      >>>
> >      >      >      >>
> >      >      >      >>          [[alternative HTML version deleted]]
> >      >      >      >>
> >      >      >      >> _______________________________________________
> >      >      >      >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >      >      >      >>
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >>
> >      >      >      >
> >      >      >      >       [[alternative HTML version deleted]]
> >      >      >      >
> >      >      >      > _______________________________________________
> >      >      >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >      >      >      >
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >     --
> >      >      >     John Fox, Professor Emeritus
> >      >      >     McMaster University
> >      >      >     Hamilton, Ontario, Canada
> >      >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >      >
> >      >     --
> >      >     John Fox, Professor Emeritus
> >      >     McMaster University
> >      >     Hamilton, Ontario, Canada
> >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> ------------------------------------------------------------------------
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Mar  1 22:54:51 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 1 Mar 2022 16:54:51 -0500
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAG_dBVfv2-8Z0VRvcK4QUP97oh5jOhPd2d=LUj0N_6Ec+appMw@mail.gmail.com>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
 <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
 <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>
 <0f03187e-d848-ea43-e370-ead2d403b530@mcmaster.ca>
 <CAG_dBVfv2-8Z0VRvcK4QUP97oh5jOhPd2d=LUj0N_6Ec+appMw@mail.gmail.com>
Message-ID: <f80557f3-35c7-7b22-ae9c-2f14ff0d7ac0@mcmaster.ca>

Dear Juho,

On 2022-03-01 3:13 p.m., Juho Kristian Ruohonen wrote:
> Dear John,
> 
> Yes, my function uses your code for the math. I was just hoping to 
> verify that it is handling multicategory factors correctly (your 
> examples didn't involve any).

That's not really my point. Your code sets up computations for the 
various terms in the model automatically, while the function I sent 
requires that you locate the rows/columns for the intercepts and each 
focal term manually. If you haven't already done so, you could check 
that your function is identifying the correct columns and getting the 
corresponding GVIFs.

> 
> I guess interactions aren't that important after all, given that the 
> chief concern is usually collinearity among main effects.

I wouldn't say that, but it's not clear what collinearity means in 
models with interactions, and if you compute VIFs or GVIFs for "main 
effects" in models with interactions, you'll probably get nonsense.

As I said, I think that this might be a solvable problem, but one that 
requires thought about what needs to remain invariant.

I think that we've probably come to end for now.

John

> 
> Many thanks for all your help.
> 
> Best,
> 
> Juho
> 
> ti 1. maalisk. 2022 klo 18.01 John Fox (jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>) kirjoitti:
> 
>     Dear Juho,
> 
>     On 2022-03-01 8:24 a.m., Juho Kristian Ruohonen wrote:
>      > Dear John (Fox, as well as other list members),
>      >
>      > I've now written a simple function to try and calculate GVIFS for
>     all
>      > predictors in a nnet::multinom() object based on John's example
>     code. If
>      > its results are correct (see below), I will proceed to write a
>     version
>      > that also works with mixed-effects multinomial models fit by
>      > brms::brm(). Here's the code:
>      >
>      >? ? ?gvif.multinom <- function(model){
>      >? ? ? ? (classes <- model$lev)
>      >? ? ? ? (V.all <- vcov(model))
>      >? ? ? ? (V.noIntercepts <- V.all[!grepl("\\(Intercept\\)$",
>      >? ? ?rownames(V.all), perl = T),
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?!grepl("\\(Intercept\\)$",
>      >? ? ?colnames(V.all), perl = T)])
>      >? ? ? ? (R <- cov2cor(V.noIntercepts))
>      >? ? ? ? (terms <- attr(model$terms, "term.labels"))
>      >? ? ? ? (gvif <- numeric(length = length(terms)))
>      >? ? ? ? (names(gvif) <- terms)
>      >? ? ? ? (SE.multiplier <- numeric(length = length(terms)))
>      >? ? ? ? (names(SE.multiplier) <- terms)
>      >? ? ? ? #The line below tries to capture all factor levels into a
>     regex
>      >? ? ?for coef name matching.
>      >? ? ? ? (LevelsRegex <- paste0("(", paste(unlist(model$xlevels),
>     collapse
>      >? ? ?= "|"),")?"))
>      >
>      >? ? ? ? for(i in terms){
>      >? ? ? ? ? #The regex stuff below tries to ensure all interaction
>      >? ? ?coefficients are matched, including those involving factors.
>      >? ? ? ? ? if(grepl(":", i)){
>      >? ? ? ? ? ? (termname <- gsub(":", paste0(LevelsRegex, ":"), i,
>     perl = T))
>      >? ? ? ? ? }else{termname <- i}
>      >? ? ? ? ? (RegexToMatch <- paste0("^(",
>     paste(classes[2:length(classes)],
>      >? ? ?collapse = "|") ,"):", termname, LevelsRegex, "$"))
>      >
>      >? ? ? ? ? #Now the actual calculation:
>      >? ? ? ? ? (indices <- grep(RegexToMatch, rownames(R), perl = T))
>      >? ? ? ? ? (gvif[i] <- det(R[indices, indices]) * det(R[-indices,
>      >? ? ?-indices]) / det(R))
>      >? ? ? ? ? (SE.multiplier[i] <- gvif[i]^(1/(2*length(indices))))
>      >? ? ? ? }
>      >? ? ? ? #Put the results together and order them by degree of SE
>     inflation:
>      >? ? ? ? (result <- cbind(GVIF = gvif, `GVIF^(1/(2df))` =
>     SE.multiplier))
>      >? ? ? ? return(result[order(result[,"GVIF^(1/(2df))"], decreasing
>     = T),])}
>      >
>      >
>      > The results seem correct to me when applied to John's example
>     model fit
>      > to the BEPS data. However, that dataset contains no multi-df
>     factors, of
>      > which my own models have many. Below is a maximally simple
>     example with
>      > one multi-df factor (/region/):
>      >
>      >? ? ?mod1 <- multinom(partic ~., data = carData::Womenlf)
>      >? ? ?gvif.multinom(mod1)
>      >
>      >? ? ?GVIF GVIF^(1/(2df))
>      >? ? ?children 1.298794 ? ? ? 1.067542
>      >? ? ?hincome ?1.184215 ? ? ? 1.043176
>      >? ? ?region ? 1.381480 ? ? ? 1.020403
>      >
>      >
>      > These results look plausible to me. Finally, below is an example
>      > involving both a multi-df factor and an interaction:
>      >
>      >? ? ?mod2 <- update(mod1, ~. +children:region)
>      >? ? ?gvif.multinom(mod2)
>      >
>      >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? GVIF GVIF^(1/(2df))
>      >? ? ?children:region 4.965762e+16 ? ? ?11.053482
>      >? ? ?region ? ? ? ? ?1.420418e+16 ? ? ?10.221768
>      >? ? ?children ? ? ? ?1.471412e+03 ? ? ? 6.193463
>      >? ? ?hincome ? ? ? ? 6.462161e+00 ? ? ? 1.594390
>      >
>      >
>      > These results look a bit more dubious. To be sure, it is to be
>     expected
>      > that interaction terms will introduce a lot of collinearity. But an
>      > 11-fold increase in SE? I hope someone can tell me whether this is
>      > correct or not!
> 
>     You don't need someone else to check your work because you could just
>     apply the simple function that I sent you yesterday, which, though not
>     automatic, computes the GVIFs in a transparent manner.
> 
>     A brief comment on GVIFs for models with interactions (this isn't the
>     place to discuss the question in detail): The Fox and Monette JASA
>     paper
>     addresses the question briefly in the context of a two-way ANOVA, but I
>     don't think that the approach suggested there is easily generalized.
> 
>     The following simple approach pays attention to what's invariant under
>     different parametrizations of the RHS side of the model: Simultaneously
>     check the collinearity of all of the coefficients of an interaction
>     together with the main effects and, potentially, lower-order
>     interactions that are marginal to it. So, e.g., in the model y ~ a +
>     b +
>     a:b + c, you'd check all of the coefficients for a, b, and a:b together.
> 
>     Alternatively, one could focus in turn on each explanatory variable and
>     check the collinearity of all coefficients to which it is marginal. So
>     in y ~ a + b + c + a:b + a:c + d, when you focus on a, you'd look at
>     all
>     of the coefficients for a, b, c, a:b, and a:c.
> 
>     John
> 
>      >
>      > Best,
>      >
>      > Juho
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      > ti 1. maalisk. 2022 klo 0.05 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
>      >
>      >? ? ?Dear Juha,
>      >
>      >? ? ?On 2022-02-28 5:00 p.m., Juho Kristian Ruohonen wrote:
>      >? ? ? > Apologies for my misreading, John, and many thanks for showing
>      >? ? ?how the
>      >? ? ? > calculation is done for a single term.
>      >? ? ? >
>      >? ? ? > Do you think *vif()* might be updated in the near future
>     with the
>      >? ? ? > capability of auto-detecting a multinomial model and returning
>      >? ? ? > mathematically correct GVIF statistics?
>      >
>      >? ? ?The thought crossed my mind, but I'd want to do it in a
>     general way,
>      >? ? ?not
>      >? ? ?just for the multinom() function, and in a way that avoids
>     incorrect
>      >? ? ?results such as those currently produced for "multinom"
>     models, albeit
>      >? ? ?with a warning. I can't guarantee whether or when I'll be
>     able to do
>      >? ? ?that.
>      >
>      >? ? ?John
>      >
>      >? ? ? >
>      >? ? ? > If not, I'll proceed to writing my own function based on your
>      >? ? ?example.
>      >? ? ? > However, /car/ is such an excellent and widely used
>     package that the
>      >? ? ? > greatest benefit to mankind would probably accrue if /car /was
>      >? ? ?upgraded
>      >? ? ? > with this feature sooner rather than later.
>      >? ? ? >
>      >? ? ? > Best,
>      >? ? ? >
>      >? ? ? > Juho
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > ma 28. helmik. 2022 klo 17.08 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
>      >? ? ? >
>      >? ? ? >? ? ?Dear Juho,
>      >? ? ? >
>      >? ? ? >? ? ?On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen wrote:
>      >? ? ? >? ? ? > Dear Professor Fox and other list members,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Profuse thanks for doing that detective work for
>     me! I myself
>      >? ? ? >? ? ?thought
>      >? ? ? >? ? ? > the inflation factors reported by
>     check_collinearity() were
>      >? ? ? >? ? ?suspiciously
>      >? ? ? >? ? ? > high, but unlike you I lacked the expertise to identify
>      >? ? ?what was
>      >? ? ? >? ? ?going on.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > As for your suggested approach, have I understood this
>      >? ? ?correctly:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Since there doesn't yet exist an R function that will
>      >? ? ?calculate the
>      >? ? ? >? ? ? > (G)VIFS of multinomial models correctly, my best
>     bet for
>      >? ? ?now is
>      >? ? ? >? ? ?just to
>      >? ? ? >? ? ? > ignore the fact that such models partition the data
>     into C-1
>      >? ? ? >? ? ?subsets,
>      >? ? ? >? ? ? > and to calculate approximate GVIFs from the entire
>     dataset at
>      >? ? ? >? ? ?once as if
>      >? ? ? >? ? ? > the response were continuous? And a simple way to
>     do this
>      >? ? ?is to
>      >? ? ? >? ? ? > construct a fake continuous response, call
>      >? ? ?*lm(fakeresponse ~.)*,
>      >? ? ? >? ? ?and
>      >? ? ? >? ? ? > apply *car::vif()* on the result?
>      >? ? ? >
>      >? ? ? >? ? ?No, you misunderstand my suggestion, which perhaps isn't
>      >? ? ?surprising
>      >? ? ? >? ? ?given the length of my message. What you propose is what I
>      >? ? ?suggested as
>      >? ? ? >? ? ?a rough approximation *before* I confirmed that my
>     guess of the
>      >? ? ? >? ? ?solution
>      >? ? ? >? ? ?was correct.
>      >? ? ? >
>      >? ? ? >? ? ?The R code that I sent yesterday showed how to compute the
>      >? ? ?GVIF for a
>      >? ? ? >? ? ?multinomial regression model, and I suggested that you
>     write
>      >? ? ?either a
>      >? ? ? >? ? ?script or a simple function to do that. Here's a function
>      >? ? ?that will
>      >? ? ? >? ? ?work
>      >? ? ? >? ? ?for a model object that responds to vcov():
>      >? ? ? >
>      >? ? ? >? ? ?GVIF <- function(model, intercepts, term){
>      >? ? ? >? ? ? ? ?# model: regression model object
>      >? ? ? >? ? ? ? ?# intercepts: row/column positions of intercepts
>     in the
>      >? ? ?coefficient
>      >? ? ? >? ? ?covariance matrix
>      >? ? ? >? ? ? ? ?# term: row/column positions of the coefficients
>     for the
>      >? ? ?focal term
>      >? ? ? >? ? ? ? ?V <- vcov(model)
>      >? ? ? >? ? ? ? ?term <- colnames(V)[term]
>      >? ? ? >? ? ? ? ?V <- V[-intercepts, -intercepts]
>      >? ? ? >? ? ? ? ?V <- cov2cor(V)
>      >? ? ? >? ? ? ? ?term <- which(colnames(V) %in% term)
>      >? ? ? >? ? ? ? ?gvif <- det(V[term, term])*det(V[-term, -term])/det(V)
>      >? ? ? >? ? ? ? ?c(GVIF=gvif,
>     "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
>      >? ? ? >? ? ?}
>      >? ? ? >
>      >? ? ? >? ? ?and here's an application to the multinom() example that I
>      >? ? ?showed you
>      >? ? ? >? ? ?yesterday:
>      >? ? ? >
>      >? ? ? >? ? ? ?> colnames(vcov(m)) # to get coefficient positions
>      >? ? ? >? ? ? ? [1] "Labour:(Intercept)"                     
>      ?"Labour:age"
>      >? ? ? >
>      >? ? ? >? ? ? ? [3] "Labour:economic.cond.national"
>      >? ? ? >? ? ?"Labour:economic.cond.household"
>      >? ? ? >? ? ? ? [5] "Labour:Blair"                           
>      ?"Labour:Hague"
>      >? ? ? >
>      >? ? ? >? ? ? ? [7] "Labour:Kennedy"                         
>      ?"Labour:Europe"
>      >? ? ? >
>      >? ? ? >? ? ? ? [9] "Labour:political.knowledge"
>      >? ? ? ?"Labour:gendermale"
>      >? ? ? >
>      >? ? ? >? ? ?[11] "Liberal Democrat:(Intercept)"? ? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:age"
>      >? ? ? >
>      >? ? ? >? ? ?[13] "Liberal Democrat:economic.cond.national"? "Liberal
>      >? ? ? >? ? ?Democrat:economic.cond.household"
>      >? ? ? >? ? ?[15] "Liberal Democrat:Blair"? ? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ? >? ? ?Democrat:Hague"
>      >? ? ? >
>      >? ? ? >? ? ?[17] "Liberal Democrat:Kennedy"? ? ? ? ? ? ? ? ?"Liberal
>      >? ? ? >? ? ?Democrat:Europe"
>      >? ? ? >? ? ?[19] "Liberal Democrat:political.knowledge"? ? ?"Liberal
>      >? ? ? >? ? ?Democrat:gendermale"
>      >? ? ? >
>      >? ? ? >? ? ? ?> GVIF(m, intercepts=c(1, 11), term=c(2, 12)) # GVIF
>     for age
>      >? ? ? >? ? ? ? ? ? ? ? ?GVIF GVIF^(1/(2*p))
>      >? ? ? >? ? ? ? ? ? ?1.046232? ? ? ?1.011363
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >? ? ?Finally, here's what you get for a linear model with
>     the same RHS
>      >? ? ? >? ? ?(where
>      >? ? ? >? ? ?the sqrt(VIF) should be a rough approximation to
>     GVIF^(1/4)
>      >? ? ?reported by
>      >? ? ? >? ? ?my GVIF() function):
>      >? ? ? >
>      >? ? ? >? ? ? ?> m.lm <- lm(as.numeric(vote) ~ . - vote1, data=BEPS)
>      >? ? ? >? ? ? ?> sqrt(car::vif(m.lm))
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?age? economic.cond.national
>      >? ? ? >? ? ?economic.cond.household
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Blair
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.006508? ? ? ? ? ? ? ? 1.124132
>      >? ? ? >? ? ?1.075656
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.118441
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Hague? ? ? ? ? ? ? ? ?Kennedy
>      >? ? ? >? ? ?Europe
>      >? ? ? >? ? ? ? ? ?political.knowledge
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.066799? ? ? ? ? ? ? ? 1.015532
>      >? ? ? >? ? ?1.101741
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.028546
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? gender
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.017386
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >? ? ?John
>      >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Best,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Juho
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > ma 28. helmik. 2022 klo 2.23 John Fox
>     (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
>      >? ? ? >? ? ? > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>) kirjoitti:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Dear Juho,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?I've now had a chance to think about this
>     problem some
>      >? ? ?more,
>      >? ? ? >? ? ?and I
>      >? ? ? >? ? ? >? ? ?believe that the approach I suggested is correct. I
>      >? ? ?also had an
>      >? ? ? >? ? ? >? ? ?opportunity to talk the problem over a bit with
>     Georges
>      >? ? ? >? ? ?Monette, who
>      >? ? ? >? ? ? >? ? ?coauthored the paper that introduced
>     generalized variance
>      >? ? ? >? ? ?inflation
>      >? ? ? >? ? ? >? ? ?factors (GVIFs). On the other hand, the results
>      >? ? ?produced by
>      >? ? ? >? ? ? >? ? ?performance::check_collinearity() for
>     multinomial logit
>      >? ? ? >? ? ?models don't
>      >? ? ? >? ? ? >? ? ?seem to be correct (see below).
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Here's an example, using the nnet::multinom()
>     function
>      >? ? ?to fit a
>      >? ? ? >? ? ? >? ? ?multinomial logit model, with alternative
>      >? ? ?parametrizations of the
>      >? ? ? >? ? ? >? ? ?LHS of
>      >? ? ? >? ? ? >? ? ?the model:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> library(nnet) # for multinom()
>      >? ? ? >? ? ? >? ? ? ?> library(carData) # for BEPS data set
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> # alternative ordering of the response levels:
>      >? ? ? >? ? ? >? ? ? ?> BEPS$vote1 <- factor(BEPS$vote,
>     levels=c("Labour",
>      >? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat", "Conservative"))
>      >? ? ? >? ? ? >? ? ? ?> levels(BEPS$vote)
>      >? ? ? >? ? ? >? ? ?[1] "Conservative"? ? ?"Labour"? ? ? ? ? ?"Liberal
>      >? ? ?Democrat"
>      >? ? ? >? ? ? >? ? ? ?> levels(BEPS$vote1)
>      >? ? ? >? ? ? >? ? ?[1] "Labour"? ? ? ? ? ?"Liberal Democrat"
>     "Conservative"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> m <- multinom(vote ~ . - vote1, data=BEPS)
>      >? ? ? >? ? ? >? ? ?# weights:? 33 (20 variable)
>      >? ? ? >? ? ? >? ? ?initial? value 1675.383740
>      >? ? ? >? ? ? >? ? ?iter? 10 value 1345.935273
>      >? ? ? >? ? ? >? ? ?iter? 20 value 1150.956807
>      >? ? ? >? ? ? >? ? ?iter? 30 value 1141.921662
>      >? ? ? >? ? ? >? ? ?iter? 30 value 1141.921661
>      >? ? ? >? ? ? >? ? ?iter? 30 value 1141.921661
>      >? ? ? >? ? ? >? ? ?final? value 1141.921661
>      >? ? ? >? ? ? >? ? ?converged
>      >? ? ? >? ? ? >? ? ? ?> m1 <- multinom(vote1 ~ . - vote, data=BEPS)
>      >? ? ? >? ? ? >? ? ?# weights:? 33 (20 variable)
>      >? ? ? >? ? ? >? ? ?initial? value 1675.383740
>      >? ? ? >? ? ? >? ? ?iter? 10 value 1280.439304
>      >? ? ? >? ? ? >? ? ?iter? 20 value 1165.513772
>      >? ? ? >? ? ? >? ? ?final? value 1141.921662
>      >? ? ? >? ? ? >? ? ?converged
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> rbind(coef(m), coef(m1)) # compare coefficients
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? (Intercept)? ? ? ? ? age
>      >? ? ? >? ? ?economic.cond.national
>      >? ? ? >? ? ? >? ? ?economic.cond.household
>      >? ? ? >? ? ? >? ? ?Labour? ? ? ? ? ? ?0.9515214 -0.021913989
>      >? ? ?0.5575707
>      >? ? ? >? ? ? >? ? ? ? ? ? 0.15839096
>      >? ? ? >? ? ? >? ? ?Liberal Democrat? ?1.4119306 -0.016810735
>      >? ? ?0.1810761
>      >? ? ? >? ? ? >? ? ? ? ? ?-0.01196664
>      >? ? ? >? ? ? >? ? ?Liberal Democrat? ?0.4604567? 0.005102666
>      >? ? ? ?-0.3764928
>      >? ? ? >? ? ? >? ? ? ? ? ?-0.17036682
>      >? ? ? >? ? ? >? ? ?Conservative? ? ? -0.9514466? 0.021912305
>      >? ? ? ?-0.5575644
>      >? ? ? >? ? ? >? ? ? ? ? ?-0.15838744
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Blair? ? ? ?Hague   
>     Kennedy
>      >? ? ? ? ? Europe
>      >? ? ? >? ? ? >? ? ?political.knowledge
>      >? ? ? >? ? ? >? ? ?Labour? ? ? ? ? ? 0.8371764 -0.90775585? 0.2513436
>      >? ? ?-0.22781308
>      >? ? ? >? ? ? >? ? ?-0.5370612
>      >? ? ? >? ? ? >? ? ?Liberal Democrat? 0.2937331 -0.82217625? 0.6710567
>      >? ? ?-0.20004624
>      >? ? ? >? ? ? >? ? ?-0.2034605
>      >? ? ? >? ? ? >? ? ?Liberal Democrat -0.5434408? 0.08559455? 0.4197027
>      >? ? ?0.02776465
>      >? ? ? >? ? ? >? ? ?0.3336068
>      >? ? ? >? ? ? >? ? ?Conservative? ? ?-0.8371670? 0.90778068 -0.2513735
>      >? ? ?0.22781092
>      >? ? ? >? ? ? >? ? ?0.5370545
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gendermale
>      >? ? ? >? ? ? >? ? ?Labour? ? ? ? ? ? 0.13765774
>      >? ? ? >? ? ? >? ? ?Liberal Democrat? 0.12640823
>      >? ? ? >? ? ? >? ? ?Liberal Democrat -0.01125898
>      >? ? ? >? ? ? >? ? ?Conservative? ? ?-0.13764849
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> c(logLik(m), logLik(m1)) # same fit to the data
>      >? ? ? >? ? ? >? ? ?[1] -1141.922 -1141.922
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> # covariance matrices for coefficients:
>      >? ? ? >? ? ? >? ? ? ?> V <- vcov(m)
>      >? ? ? >? ? ? >? ? ? ?> V1 <- vcov(m1)
>      >? ? ? >? ? ? >? ? ? ?> cbind(colnames(V), colnames(V1)) # compare
>      >? ? ? >? ? ? >? ? ? ? ? ? ?[,1]                                   
>      ? ?[,2]
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ? [1,] "Labour:(Intercept)"
>      >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:(Intercept)"
>      >? ? ? >? ? ? >? ? ? ? [2,] "Labour:age"
>      >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:age"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ? [3,] "Labour:economic.cond.national"
>      >? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:economic.cond.national"
>      >? ? ? >? ? ? >? ? ? ? [4,] "Labour:economic.cond.household"
>      >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:economic.cond.household"
>      >? ? ? >? ? ? >? ? ? ? [5,] "Labour:Blair"
>      >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:Blair"
>      >? ? ? >? ? ? >? ? ? ? [6,] "Labour:Hague"
>      >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:Hague"
>      >? ? ? >? ? ? >? ? ? ? [7,] "Labour:Kennedy"
>      >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:Kennedy"
>      >? ? ? >? ? ? >? ? ? ? [8,] "Labour:Europe"
>      >? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:Europe"
>      >? ? ? >? ? ? >? ? ? ? [9,] "Labour:political.knowledge"
>      >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:political.knowledge"
>      >? ? ? >? ? ? >? ? ?[10,] "Labour:gendermale"                     
>      ? "Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:gendermale"
>      >? ? ? >? ? ? >? ? ?[11,] "Liberal Democrat:(Intercept)"
>      >? ? ? >? ? ? >? ? ?"Conservative:(Intercept)"
>      >? ? ? >? ? ? >? ? ?[12,] "Liberal Democrat:age"
>      >? ? ? >? ? ? ?"Conservative:age"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?[13,] "Liberal Democrat:economic.cond.national"
>      >? ? ? >? ? ? >? ? ?"Conservative:economic.cond.national"
>      >? ? ? >? ? ? >? ? ?[14,] "Liberal Democrat:economic.cond.household"
>      >? ? ? >? ? ? >? ? ?"Conservative:economic.cond.household"
>      >? ? ? >? ? ? >? ? ?[15,] "Liberal Democrat:Blair"
>      >? ? ? >? ? ? ?"Conservative:Blair"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?[16,] "Liberal Democrat:Hague"
>      >? ? ? >? ? ? ?"Conservative:Hague"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?[17,] "Liberal Democrat:Kennedy"
>      >? ? ? >? ? ? ?"Conservative:Kennedy"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?[18,] "Liberal Democrat:Europe"
>      >? ? ? >? ? ?"Conservative:Europe"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?[19,] "Liberal Democrat:political.knowledge"
>      >? ? ? >? ? ? >? ? ?"Conservative:political.knowledge"
>      >? ? ? >? ? ? >? ? ?[20,] "Liberal Democrat:gendermale"
>      >? ? ? >? ? ? >? ? ?"Conservative:gendermale"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> int <- c(1, 11) # remove intercepts
>      >? ? ? >? ? ? >? ? ? ?> colnames(V)[int]
>      >? ? ? >? ? ? >? ? ?[1] "Labour:(Intercept)"? ? ? ? ? ?"Liberal
>      >? ? ?Democrat:(Intercept)"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> colnames(V1)[int]
>      >? ? ? >? ? ? >? ? ?[1] "Liberal Democrat:(Intercept)"
>      >? ? ?"Conservative:(Intercept)"
>      >? ? ? >? ? ? >? ? ? ?> V <- V[-int, -int]
>      >? ? ? >? ? ? >? ? ? ?> V1 <- V1[-int, -int]
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> age <- c(1, 10) # locate age coefficients
>      >? ? ? >? ? ? >? ? ? ?> colnames(V)[age]
>      >? ? ? >? ? ? >? ? ?[1] "Labour:age"? ? ? ? ? ?"Liberal Democrat:age"
>      >? ? ? >? ? ? >? ? ? ?> colnames(V1)[age]
>      >? ? ? >? ? ? >? ? ?[1] "Liberal Democrat:age" "Conservative:age"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> V <- cov2cor(V) # compute coefficient
>     correlations
>      >? ? ? >? ? ? >? ? ? ?> V1 <- cov2cor(V1)
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> # compare GVIFs:
>      >? ? ? >? ? ? >? ? ? ?> c(det(V[age, age])*det(V[-age, -age])/det(V),
>      >? ? ? >? ? ? >? ? ?+? ?det(V1[age, age])*det(V1[-age, -age])/det(V1))
>      >? ? ? >? ? ? >? ? ?[1] 1.046232 1.046229
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?For curiosity, I applied car::vif() and
>      >? ? ? >? ? ? >? ? ?performance::check_collinearity() to these
>     models to
>      >? ? ?see what
>      >? ? ? >? ? ?they
>      >? ? ? >? ? ? >? ? ?would
>      >? ? ? >? ? ? >? ? ?do. Both returned the wrong answer. vif()
>     produced a
>      >? ? ?warning, but
>      >? ? ? >? ? ? >? ? ?check_collinearity() didn't:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> car::vif(m1)
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?age? economic.cond.national
>      >? ? ? >? ? ? >? ? ?economic.cond.household
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ?15.461045? ? ? ? ? ? ? ?22.137772
>      >? ? ? >? ? ? >? ? ? ?16.693877
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Blair? ? ? ? ? ? ? ? ? ?Hague
>      >? ? ? >? ? ? >? ? ? ?Kennedy
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ?14.681562? ? ? ? ? ? ? ? 7.483039
>      >? ? ? >? ? ? >? ? ? ?15.812067
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Europe? ? ?political.knowledge
>      >? ? ? >? ? ? >? ? ?gender
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? 6.502119? ? ? ? ? ? ? ? 4.219507
>      >? ? ? >? ? ? >? ? ?2.313885
>      >? ? ? >? ? ? >? ? ?Warning message:
>      >? ? ? >? ? ? >? ? ?In vif.default(m1) : No intercept: vifs may not be
>      >? ? ?sensible.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> performance::check_collinearity(m)
>      >? ? ? >? ? ? >? ? ?# Check for Multicollinearity
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Low Correlation
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE
>     Tolerance
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? age 1.72? ? ? ? ?1.31   
>      ? 0.58
>      >? ? ? >? ? ? >? ? ? ? ?economic.cond.national 1.85? ? ? ? ?1.36   
>      ? 0.54
>      >? ? ? >? ? ? >? ? ? ? economic.cond.household 1.86? ? ? ? ?1.37   
>      ? 0.54
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Blair 1.63? ? ? ? ?1.28   
>      ? 0.61
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Hague 1.94? ? ? ? ?1.39   
>      ? 0.52
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Kennedy 1.70? ? ? ? ?1.30   
>      ? 0.59
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Europe 2.01? ? ? ? ?1.42   
>      ? 0.50
>      >? ? ? >? ? ? >? ? ? ? ? ? political.knowledge 1.94? ? ? ? ?1.39   
>      ? 0.52
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gender 1.78? ? ? ? ?1.33   
>      ? 0.56
>      >? ? ? >? ? ? >? ? ? ?> performance::check_collinearity(m1)
>      >? ? ? >? ? ? >? ? ?# Check for Multicollinearity
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Low Correlation
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE
>     Tolerance
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? age 1.19? ? ? ? ?1.09   
>      ? 0.84
>      >? ? ? >? ? ? >? ? ? ? ?economic.cond.national 1.42? ? ? ? ?1.19   
>      ? 0.70
>      >? ? ? >? ? ? >? ? ? ? economic.cond.household 1.32? ? ? ? ?1.15   
>      ? 0.76
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Blair 1.50? ? ? ? ?1.22   
>      ? 0.67
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Hague 1.30? ? ? ? ?1.14   
>      ? 0.77
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Kennedy 1.19? ? ? ? ?1.09   
>      ? 0.84
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Europe 1.34? ? ? ? ?1.16   
>      ? 0.75
>      >? ? ? >? ? ? >? ? ? ? ? ? political.knowledge 1.30? ? ? ? ?1.14   
>      ? 0.77
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gender 1.23? ? ? ? ?1.11   
>      ? 0.81
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?I looked at the code for vif() and
>     check_collinearity() to
>      >? ? ? >? ? ?see where
>      >? ? ? >? ? ? >? ? ?they went wrong. Both failed to handle the two
>      >? ? ?intercepts in
>      >? ? ? >? ? ?the model
>      >? ? ? >? ? ? >? ? ?correctly -- vif() thought there was no
>     intercept and
>      >? ? ? >? ? ? >? ? ?check_collinearity() just removed the first
>     intercept
>      >? ? ?but not the
>      >? ? ? >? ? ? >? ? ?second.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?In examining the code for check_collinearity(), I
>      >? ? ?discovered a
>      >? ? ? >? ? ? >? ? ?couple of
>      >? ? ? >? ? ? >? ? ?additional disconcerting facts. First, part of the
>      >? ? ?code seems
>      >? ? ? >? ? ?to be
>      >? ? ? >? ? ? >? ? ?copied from vif.default(). Second, as a
>     consequence,
>      >? ? ? >? ? ? >? ? ?check_collinearity() actually computes GVIFs rather
>      >? ? ?than VIFs
>      >? ? ? >? ? ?(and
>      >? ? ? >? ? ? >? ? ?doesn't reference either the Fox and Monette paper
>      >? ? ? >? ? ?introducing GVIFs or
>      >? ? ? >? ? ? >? ? ?the car package) but doesn't seem to understand
>     that, and,
>      >? ? ? >? ? ?for example,
>      >? ? ? >? ? ? >? ? ?takes the squareroot of the GVIF (reported in the
>      >? ? ?column marked
>      >? ? ? >? ? ? >? ? ?"Increased SE") rather than the 2p root (when there
>      >? ? ?are p > 1
>      >? ? ? >? ? ? >? ? ?coefficients in a term).
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Here's the relevant code from the two functions
>     (where
>      >? ? ?. . .
>      >? ? ? >? ? ?denotes
>      >? ? ? >? ? ? >? ? ?elided lines) -- the default method for vif() and
>      >? ? ? >? ? ? >? ? ?.check_collinearity(),
>      >? ? ? >? ? ? >? ? ?which is called by check_collinearity.default():
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> car:::vif.default
>      >? ? ? >? ? ? >? ? ?function (mod, ...)
>      >? ? ? >? ? ? >? ? ?{
>      >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? ? ? ?v <- vcov(mod)
>      >? ? ? >? ? ? >? ? ? ? ? ?assign <- attr(model.matrix(mod), "assign")
>      >? ? ? >? ? ? >? ? ? ? ? ?if (names(coefficients(mod)[1]) ==
>     "(Intercept)") {
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?v <- v[-1, -1]
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?assign <- assign[-1]
>      >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? ? ? ?else warning("No intercept: vifs may not be
>      >? ? ?sensible.")
>      >? ? ? >? ? ? >? ? ? ? ? ?terms <- labels(terms(mod))
>      >? ? ? >? ? ? >? ? ? ? ? ?n.terms <- length(terms)
>      >? ? ? >? ? ? >? ? ? ? ? ?if (n.terms < 2)
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?stop("model contains fewer than 2 terms")
>      >? ? ? >? ? ? >? ? ? ? ? ?R <- cov2cor(v)
>      >? ? ? >? ? ? >? ? ? ? ? ?detR <- det(R)
>      >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? ? ? ?for (term in 1:n.terms) {
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?subs <- which(assign == term)
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?result[term, 1] <- det(as.matrix(R[subs,
>      >? ? ?subs])) *
>      >? ? ? >? ? ? >? ? ?det(as.matrix(R[-subs,
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?-subs]))/detR
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?result[term, 2] <- length(subs)
>      >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ?}
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> performance:::.check_collinearity
>      >? ? ? >? ? ? >? ? ?function (x, component, verbose = TRUE)
>      >? ? ? >? ? ? >? ? ?{
>      >? ? ? >? ? ? >? ? ? ? ? ?v <- insight::get_varcov(x, component =
>     component,
>      >? ? ? >? ? ?verbose =
>      >? ? ? >? ? ? >? ? ?FALSE)
>      >? ? ? >? ? ? >? ? ? ? ? ?assign <- .term_assignments(x, component,
>     verbose =
>      >? ? ? >? ? ?verbose)
>      >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? ? ? ?if (insight::has_intercept(x)) {
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?v <- v[-1, -1]
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?assign <- assign[-1]
>      >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? ? ? ?else {
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?if (isTRUE(verbose)) {
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?warning("Model has no intercept. VIFs
>      >? ? ?may not be
>      >? ? ? >? ? ? >? ? ?sensible.",
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?call. = FALSE)
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?terms <-
>     labels(stats::terms(f[[component]]))
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? ? ? ?n.terms <- length(terms)
>      >? ? ? >? ? ? >? ? ? ? ? ?if (n.terms < 2) {
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?if (isTRUE(verbose)) {
>      >? ? ? >? ? ? >                 
>      ?warning(insight::format_message(sprintf("Not
>      >? ? ? >? ? ?enough model
>      >? ? ? >? ? ? >? ? ?terms in the %s part of the model to check for
>      >? ? ? >? ? ?multicollinearity.",
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?component)), call. = FALSE)
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?return(NULL)
>      >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? ? ? ?R <- stats::cov2cor(v)
>      >? ? ? >? ? ? >? ? ? ? ? ?detR <- det(R)
>      >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? ? ? ?for (term in 1:n.terms) {
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ?subs <- which(assign == term)
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?result <- c(result,
>      >? ? ?det(as.matrix(R[subs, subs])) *
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?det(as.matrix(R[-subs,
>     -subs]))/detR)
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ?}
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?So, the upshot of all this is that you should
>     be able
>      >? ? ?to do
>      >? ? ? >? ? ?what you
>      >? ? ? >? ? ? >? ? ?want, but not with either car::vif() or
>      >? ? ? >? ? ? >? ? ?performance::check_collinearity(). Instead, either
>      >? ? ?write your own
>      >? ? ? >? ? ? >? ? ?function or do the computations in a script.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?There's also a lesson here about S3 default
>     methods:
>      >? ? ?The fact
>      >? ? ? >? ? ?that a
>      >? ? ? >? ? ? >? ? ?default method returns a result rather than
>     throwing
>      >? ? ?an error
>      >? ? ? >? ? ?or a
>      >? ? ? >? ? ? >? ? ?warning doesn't mean that the result is the
>     right answer.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?I hope this helps,
>      >? ? ? >? ? ? >? ? ? ? John
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen
>     wrote:
>      >? ? ? >? ? ? >? ? ? > Dear John W,
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > Thank you very much for the tip-off!
>     Apologies for not
>      >? ? ? >? ? ?responding
>      >? ? ? >? ? ? >? ? ?earlier
>      >? ? ? >? ? ? >? ? ? > (gmail apparently decided to direct your email
>      >? ? ?right into the
>      >? ? ? >? ? ? >? ? ?junk folder).
>      >? ? ? >? ? ? >? ? ? > I am very pleased to note that the package you
>      >? ? ?mention does
>      >? ? ? >? ? ? >? ? ?indeed work
>      >? ? ? >? ? ? >? ? ? > with *brms* multinomial models! Thanks again!
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > Best,
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > Juho
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > pe 25. helmik. 2022 klo 19.23 John Willoughby
>      >? ? ? >? ? ? >? ? ?(johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com>>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>
>      >? ? ? >? ? ?<mailto:johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com>>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>>)
>      >? ? ? >? ? ? >? ? ? > kirjoitti:
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >> Have you tried the check_collinearity()
>     function
>      >? ? ?in the
>      >? ? ? >? ? ?performance
>      >? ? ? >? ? ? >? ? ? >> package? It's supposed to work on brms
>     models, but
>      >? ? ?whether it
>      >? ? ? >? ? ? >? ? ?will work on
>      >? ? ? >? ? ? >? ? ? >> a multinomial model I don't know.? It works
>     well
>      >? ? ?on mixed
>      >? ? ? >? ? ?models
>      >? ? ? >? ? ? >? ? ?generated
>      >? ? ? >? ? ? >? ? ? >> by glmmTMB().
>      >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >> John Willoughby
>      >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >> On Fri, Feb 25, 2022 at 3:01 AM
>      >? ? ? >? ? ? >? ? ?<r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>
>      >? ? ? >? ? ? >   
>      ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>>>
>      >? ? ? >? ? ? >? ? ? >> wrote:
>      >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >>> Send R-sig-mixed-models mailing list
>     submissions to
>      >? ? ? >? ? ? >? ? ? >>> r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> To subscribe or unsubscribe via the World Wide
>      >? ? ?Web, visit
>      >? ? ? >? ? ? >? ? ? >>>
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>      >? ? ? >? ? ? >? ? ? >>> or, via email, send a message with subject or
>      >? ? ?body 'help' to
>      >? ? ? >? ? ? >? ? ? >>> r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>
>      >? ? ? >? ? ? >   
>      ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> You can reach the person managing the list at
>      >? ? ? >? ? ? >? ? ? >>> r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> When replying, please edit your Subject
>     line so it is
>      >? ? ? >? ? ?more specific
>      >? ? ? >? ? ? >? ? ? >>> than "Re: Contents of R-sig-mixed-models
>     digest..."
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> Today's Topics:
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>>? ? ?1. Collinearity diagnostics for (mixed)
>      >? ? ?multinomial
>      >? ? ? >? ? ?models
>      >? ? ? >? ? ? >? ? ? >>>? ? ? ? (Juho Kristian Ruohonen)
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >
>      >? ? ? >
>      >     
>      ?----------------------------------------------------------------------
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> Message: 1
>      >? ? ? >? ? ? >? ? ? >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
>      >? ? ? >? ? ? >? ? ? >>> From: Juho Kristian Ruohonen
>      >? ? ? >? ? ?<juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>>
>      >? ? ? >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>>>>
>      >? ? ? >? ? ? >? ? ? >>> To: John Fox <jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
>      >? ? ? >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>
>      >? ? ? >? ? ? >? ? ? >>> Cc: "r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>"
>      >? ? ? >? ? ? >? ? ? >>>? ? ? ? ? <r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>>
>      >? ? ? >? ? ? >? ? ? >>> Subject: [R-sig-ME] Collinearity
>     diagnostics for
>      >? ? ?(mixed)
>      >? ? ? >? ? ? >? ? ?multinomial
>      >? ? ? >? ? ? >? ? ? >>>? ? ? ? ? models
>      >? ? ? >? ? ? >? ? ? >>> Message-ID:
>      >? ? ? >? ? ? >? ? ? >>>? ? ? ? ? <
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >
>      >? ? ? >
>      >
>     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
>     <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
>      >   
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
>      >? ? ? >
>      >     
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>>
>      >? ? ? >? ? ? >
>      >? ? ? >
>      >     
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>>>>
>      >? ? ? >? ? ? >? ? ? >>> Content-Type: text/plain; charset="utf-8"
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> Dear John (and anyone else qualified to
>     comment),
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> I fit lots of mixed-effects multinomial
>     models in my
>      >? ? ? >? ? ?research,
>      >? ? ? >? ? ? >? ? ?and I
>      >? ? ? >? ? ? >? ? ? >> would
>      >? ? ? >? ? ? >? ? ? >>> like to see some (multi)collinearity
>     diagnostics
>      >? ? ?on the
>      >? ? ? >? ? ?fixed
>      >? ? ? >? ? ? >? ? ?effects, of
>      >? ? ? >? ? ? >? ? ? >>> which there are over 30. My models are fit
>     using the
>      >? ? ? >? ? ?Bayesian
>      >? ? ? >? ? ? >? ? ?*brms*
>      >? ? ? >? ? ? >? ? ? >>> package because I know of no frequentist
>     packages
>      >? ? ?with
>      >? ? ? >? ? ? >? ? ?multinomial GLMM
>      >? ? ? >? ? ? >? ? ? >>> compatibility.
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> With continuous or dichotomous outcomes,
>     my go-to
>      >? ? ? >? ? ?function for
>      >? ? ? >? ? ? >? ? ? >> calculating
>      >? ? ? >? ? ? >? ? ? >>> multicollinearity diagnostics is of course
>      >? ? ?*vif()* from
>      >? ? ? >? ? ?the *car*
>      >? ? ? >? ? ? >? ? ? >> package.
>      >? ? ? >? ? ? >? ? ? >>> As expected, however, this function does not
>      >? ? ?report sensible
>      >? ? ? >? ? ? >? ? ?diagnostics
>      >? ? ? >? ? ? >? ? ? >>> for multinomial models -- not even for
>     standard
>      >? ? ?ones fit
>      >? ? ? >? ? ?by the
>      >? ? ? >? ? ? >? ? ?*nnet*
>      >? ? ? >? ? ? >? ? ? >>> package's *multinom()* function. The reason, I
>      >? ? ?presume, is
>      >? ? ? >? ? ? >? ? ?because a
>      >? ? ? >? ? ? >? ? ? >>> multinomial model is not really one but C-1
>      >? ? ?regression
>      >? ? ? >? ? ?models
>      >? ? ? >? ? ? >? ? ?(where C
>      >? ? ? >? ? ? >? ? ? >> is
>      >? ? ? >? ? ? >? ? ? >>> the number of response categories) and the
>     *vif()*
>      >? ? ? >? ? ?function is not
>      >? ? ? >? ? ? >? ? ? >> designed
>      >? ? ? >? ? ? >? ? ? >>> to deal with this scenario.
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> Therefore, in order to obtain meaningful
>     collinearity
>      >? ? ? >? ? ?metrics,
>      >? ? ? >? ? ? >? ? ?my present
>      >? ? ? >? ? ? >? ? ? >>> plan is to write a simple helper function
>     that uses
>      >? ? ? >? ? ?*vif() *to
>      >? ? ? >? ? ? >? ? ?calculate
>      >? ? ? >? ? ? >? ? ? >>> and present (generalized) variance inflation
>      >? ? ?metrics for
>      >? ? ? >? ? ?the C-1
>      >? ? ? >? ? ? >? ? ? >>> sub-datasets to which the C-1 component
>     binomial
>      >? ? ?models
>      >? ? ? >? ? ?of the
>      >? ? ? >? ? ? >? ? ?overall
>      >? ? ? >? ? ? >? ? ? >>> multinomial model are fit. In other words, it
>      >? ? ?will partition
>      >? ? ? >? ? ? >? ? ?the data
>      >? ? ? >? ? ? >? ? ? >> into
>      >? ? ? >? ? ? >? ? ? >>> those C-1 subsets, and then apply *vif()*
>     to as
>      >? ? ?many linear
>      >? ? ? >? ? ? >? ? ?regressions
>      >? ? ? >? ? ? >? ? ? >>> using a made-up continuous response and
>     the fixed
>      >? ? ?effects of
>      >? ? ? >? ? ? >? ? ?interest.
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> Does this seem like a sensible approach?
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> Best,
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>> Juho
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >>? ? ? ? ? [[alternative HTML version deleted]]
>      >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >> _______________________________________________
>      >? ? ? >? ? ? >? ? ? >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>      >? ? ? >? ? ? >? ? ? >>
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>      >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > _______________________________________________
>      >? ? ? >? ? ? >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>      >? ? ? >? ? ? >? ? ? >
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>      >? ? ? >? ? ? >? ? ?--
>      >? ? ? >? ? ? >? ? ?John Fox, Professor Emeritus
>      >? ? ? >? ? ? >? ? ?McMaster University
>      >? ? ? >? ? ? >? ? ?Hamilton, Ontario, Canada
>      >? ? ? >? ? ? >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>
>      >? ? ? >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>>
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ?--
>      >? ? ? >? ? ?John Fox, Professor Emeritus
>      >? ? ? >? ? ?McMaster University
>      >? ? ? >? ? ?Hamilton, Ontario, Canada
>      >? ? ? >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>
>      >? ? ? >
>      >? ? ?--
>      >? ? ?John Fox, Professor Emeritus
>      >? ? ?McMaster University
>      >? ? ?Hamilton, Ontario, Canada
>      >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >
>     ------------------------------------------------------------------------
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
> 
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From me @end|ng |rom ph||||p@|d@y@com  Wed Mar  2 06:12:50 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 1 Mar 2022 23:12:50 -0600
Subject: [R-sig-ME] measuring carry-over effects in mixed models
In-Reply-To: <CACgv6yWxs1GSAwq8K0tv4=WZ+ObEu66XMBSMeECOt+6r=oMCrQ@mail.gmail.com>
References: <CACgv6yWxs1GSAwq8K0tv4=WZ+ObEu66XMBSMeECOt+6r=oMCrQ@mail.gmail.com>
Message-ID: <b7525460-681e-1c2b-52fe-ad904e1ad59f@phillipalday.com>

Depending on the exact nature of the carryover effect, the usual
suspects would be:

1. using an autoregressive model of some type
2. including lead/lag predictors in your model, e.g.
	lmer(y ~ time*group*prev_time + [covariates] + (1 | student))

But note that the initial timepoint doesn't have a prev_time and so
there is a missing value there.

Phillip

On 17/2/22 12:32 pm, Simon Harmel wrote:
> Hello All,
> 
> I'm analyzing the data from my longitudinal study whose design can be
> depicted as (view the following in plain text):
> 
> O1  X1  O2  X2  O3  X3  O4
> O1      O2      O3      O4
> 
> where Xs denote subtitled videos given to the treatment group and Os
> denote measurement occasions.
> 
> My current model is:  lmer(y ~ time*group + [covariates] + (1 | student))
> 
> However, I'm also interested in measuring the "carry-over effects" of
> watching subtitled videos at each occasion to the subsequent
> occasions.
> 
> For instance, I want to know how much watching the subtitled video at
> the first occasion (O1) impacts the treated students' performance at
> later occasions (O2 and O3) etc.
> 
> I wonder if any changes to my model can enable me to measure these
> carry-over effects or if any other R package may provide such
> functionality?
> 
> Many thanks,
> Simon
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Wed Mar  2 06:21:41 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 1 Mar 2022 23:21:41 -0600
Subject: [R-sig-ME] Using nAGQ = 0 in glmer or lmer
In-Reply-To: <BYAPR07MB5094F08B4A8F1914F7A3F0AFD1349@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB5094F08B4A8F1914F7A3F0AFD1349@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <cd35bc7f-33ee-7bf8-9ca1-f3c48d1e7668@phillipalday.com>

If my understanding of lme4 is correct, then nAGQ=0 and nAGQ=1 both use
the Laplace approximation, but differ in whether the fixed effects are
optimized as part of the PIRLS step (=0) or via the nonlinear optimizer
(=1). Generally the latter is more accurate, but in casual testing, I
haven't seen much of a difference.

I tend to use nAGQ=0 for "good enough" things like simulation-based
power analysis / model selection and then use nAGQ=1 for the final model
used for interpretation.

There are a few pathological cases where the fit will converge for one
of those options but not the other (I've only seen this with Poisson
models), in which case the decision is made for you.

On 15/2/22 2:39 pm, Hedyeh Ahmadi wrote:
> Hello All,
> I have used the option nAGQ=0 in many of lme models and I have read about it, my understanding is that the difference between the default, which nAGQ=1 vs nAGQ=0 is the estimation process in the background.
> 
> My question is that, in general if we use nAGQ=0, is our estimation still trustworthy?
> 
> Does it make it more accurate/trustworthy if our sample size is large?
> 
> Are there scenarios that we should absolutely not use nAGQ=0?
> 
> Thank you in advcance.
> 
> Best,
> 
> Hedyeh Ahmadi
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Wed Mar  2 06:23:48 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 1 Mar 2022 23:23:48 -0600
Subject: [R-sig-ME] 
 Truncated Negative Binomial Model Unexpected Marginal Means
In-Reply-To: <423AFBCA-327D-4586-BDC1-ADFF336125CB@OX.AC.UK>
References: <D0D0DE0C-7511-424E-887B-C2EE4D1DAF72@OX.AC.UK>
 <4e31e1e9-b56b-2ebd-f83f-924c73981f72@gmail.com>
 <423AFBCA-327D-4586-BDC1-ADFF336125CB@OX.AC.UK>
Message-ID: <4e1ec791-b856-3484-03a8-a365807d2fb5@phillipalday.com>

If I'm understanding the problem correctly....

I believe emmeans will allow you to pass the reference grid over which
things are computed.

On 15/2/22 1:20 pm, Alex Waldman wrote:
> Thanks, Ben!
> 
> I've copied a response from Russ:
> 
> Support for emmeans for glmmTMB models is in the glmmTMB package. However, I believe those estimates are based on the linear predictor for the conditional model only. That is, these are estimates of the mean of the fitted negative binomial distribution before it is truncated. Perhaps Ben can confirm this.
> 
> I think estimated means for hurdle and zero-inflated models are very difficult to interpret without taking into account both parts of the model; and, unfortunately, it is a somewhat complicated matter to do so that is not currently implemented. Seems worthwhile to try, though. One would have to include all the factors that affect both models; then from the truncated part, estimate its mean M and its probability of zero PT0. And from the ZI part, estimate its probability of zero PZ0. Then the estimated mean of the response is M * (1 - PZ0) / (1 - PT0), unless I made some kind of stupid mistake. The tricky part is estimating the SE of this result.
> 
> In addition, here is some example data attached. I ran the following code:
> 
> data<-read.csv("Example.csv",header=T)
> as.factor(data$ID)->data$ID
> as.factor(data$Location)->data$Location
> as.factor(data$Type)->data$Type
> model<-glmmTMB(Count ~ LocationType + (1 | ID), zi=~LocationType + (1|ID), data=data, family="truncated_nbinom1",control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
> 
> var.corr <-VarCorr(model)
> 
> Conditional model:
> Groups Name Std.Dev.
> ID (Intercept) 0.37105
> 
> Zero-inflation model:
> Groups Name Std.Dev.
> ID (Intercept) 1.3207
> 
> emmeans <- emmeans(model, ~ Location*Type, type="response", sigma=0.37105, bias.adjust=TRUE)
> 
> Location Type response SE df lower.CL upper.CL
> 0 0 1.117 0.277 631 0.687 1.82
> 1 0 0.940 0.251 631 0.556 1.59
> 2 0 0.893 0.266 631 0.498 1.60
> 0 1 1.325 0.254 631 0.909 1.93
> 1 1 1.090 0.248 631 0.698 1.70
> 2 1 1.452 0.300 631 0.967 2.18
> 
> Confidence level used: 0.95
> Intervals are back-transformed from the log scale
> Bias adjustment applied based on sigma = 0.37105
> 
> Interestingly, I tabulated the mean for location0/type1 including 0s and without 0s. Including 0s=1.05 and without 0s=1.88. The emmeans output seems to be in the middle of those two.
> 
> Does anyone have any workaround suggestions on how to tabulate the means of the conditional model above a threshold (ie above 0)? This page seemed to be relevant: https://www.theanalysisfactor.com/getting-accurate-predicted-counts-when-there-are-no-zeros-in-the-data/ but I wasn't sure what R package would fit my needs.
> 
> Thanks for your help!
> 
> Warm Regards,
> Alex 
> 
> ?On 2/15/22, 4:08 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
> 
>     A quick test suggests that emmeans is predicting the response based on 
>     the mean of the *un*truncated distribution (I don't remember and/or 
>     haven't looked into all of the guts of emmeans).  Don't know if Russ 
>     Lenth (emmeans maintainer) is reading ...
> 
>     n <- 1000
>     dd <- data.frame(f = factor(rep(1:2, each = n)))
>     gb <- log(c(2,4))
>     set.seed(101)
>     dd <- transform(dd, y = rnbinom(2*n, mu = exp(gb[f]), size = 2))
>     dd2 <- subset(dd, y > 0)
> 
>     ## un-truncated means
>     aggregate(y ~ f, data = dd, FUN = mean)
>     ##   f        y
>     ## 1 1 2.047
>     ## 2 2 3.917
> 
>     ## truncated means
>     aggregate(y ~ f, data = dd2, FUN = mean)
>     ##   f        y
>     ## 1 1 2.781250
>     ## 2 2 4.446084
> 
>     library(glmmTMB)
>     library(emmeans)
>     m1 <- glmmTMB(y ~ f, family = truncated_nbinom2, data = dd2)
> 
>     ## doesn't match exactly but close to untruncated means
>     emmeans(m1, ~ f, type = "response")
>     ##  f response     SE   df lower.CL upper.CL
>     ##  1     2.15 0.0891 1614     1.99     2.34
>     ##  2     3.98 0.1262 1614     3.74     4.23
> 
>     ## matches means exactly
>     m2 <- glmmTMB(y ~ f, family = nbinom2, data = dd)
>     emmeans(m2, ~ f, type = "response")
>     ##  f response     SE   df lower.CL upper.CL
>     ##  1     2.05 0.0651 1997     1.92     2.18
>     ##  2     3.92 0.1094 1997     3.71     4.14
> 
> 
>     On 2/15/22 10:04 AM, Alex Waldman wrote:
>     > Dear All,
>     > 
>     > Hope all is well! This may be a na?ve question but I am running a hurdle negative binomial model to look at the differences in counts of differing types in different locations. My major interest is the conditional model (ie when counts are above 0).
>     > 
>     > I run the following code:
>     > 
>     > model<-glmmTMB(Count ~ Location*Type + (1 | ID), zi=~Location*Type + (1|ID), data=data, family="truncated_nbinom1",control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
>     > 
>     > var.corr <-VarCorr(model)
>     > 
>     > Conditional model:
>     > Groups Name        Std.Dev.
>     > ID     (Intercept) 0.37105
>     > 
>     > Zero-inflation model:
>     > Groups Name        Std.Dev.
>     > ID     (Intercept) 1.3207
>     > 
>     > emmeans <- emmeans(model, ~ Location*Type, type="response", sigma=0.37105, bias.adjust=TRUE)
>     > 
>     > Location Type response    SE  df lower.CL upper.CL
>     > 0     0             1.117 0.277 631    0.687     1.82
>     > 1     0             0.940 0.251 631    0.556     1.59
>     > 2     0             0.893 0.266 631    0.498     1.60
>     > 0     1             1.325 0.254 631    0.909     1.93
>     > 1     1             1.090 0.248 631    0.698     1.70
>     > 2     1             1.452 0.300 631    0.967     2.18
>     > 
>     > Confidence level used: 0.95
>     > Intervals are back-transformed from the log scale
>     > Bias adjustment applied based on sigma = 0.37105
>     > 
>     > However, I?m not sure why the estimated means and confidence intervals will include values below 1 in the conditional model as I anticipated these values would represent the average number of non-zero counts? Is there something I may be doing wrong or not understanding?
>     > 
>     > Thanks in advance for your help!
>     > 
>     > Warm Regards,
>     > Alex
>     > 
>     > 	[[alternative HTML version deleted]]
>     > 
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>     -- 
>     Dr. Benjamin Bolker
>     Professor, Mathematics & Statistics and Biology, McMaster University
>     Director, School of Computational Science and Engineering
>     (Acting) Graduate chair, Mathematics & Statistics
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Wed Mar  2 06:35:31 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 1 Mar 2022 23:35:31 -0600
Subject: [R-sig-ME] Simulate type I error
In-Reply-To: <CACCU-vOHJAA2+qdtoZwO4wZZs+OUZX3n6asrjMpC3a36RfFJ8w@mail.gmail.com>
References: <CACCU-vOHJAA2+qdtoZwO4wZZs+OUZX3n6asrjMpC3a36RfFJ8w@mail.gmail.com>
Message-ID: <a2104afb-f07e-1d6e-0b0a-89e0e7c15111@phillipalday.com>

Since I haven't seen an answer go by, I'll try to give you a quick
answer and hope that it moves you along. (Thanks for including an MWE,
but I don't have time at the moment to check it. :/ )

When looking at type I error -- false positives -- you're looking for
significant results when the null hypothesis holds. So the thing you
need to simulate is the null hypothesis because you then you know it
holds! So the usual way to do this (using the likelihood-ratio test)
would be:


1. simulate data for the null hypothesis
2. fit the null model m0
3. fit the alternative model m1
4. compute the LRT for m0 vs m1 and store the p-value (not just the
significance!)
5. goto (1) and repeat many times
6. take the p-values you collected and examine them. The simplest thing
in in R would be mean(ps < 0.05) to get your type I error rate. But you
can also look at the standard error or confidence interval on that
estimate (it's statistics all the way down), or plot the distribution of
p-values or .... just a lot of things.
7. If you want to do this for lots of different simulation settings,
then you can do a plot at the end with the simulation parameters on one
axis and the error-rate + associated CI to see how much your error rate
would change under different ground truths.

By the way, the simr package does something for different sample sizes
to create a "power curve" of how the power changes. That could also be a
nice place to look for inspiration on visualization.

On 27/1/22 12:00 pm, Chao Liu wrote:
> Dear R-sig-mixed-models community,
> 
> I would like to simulate type I error for a random-effects model I
> generated.
> 
> The statistic of interest is standard deviations of the random intercept
> and random slope. Specifically, for random intercept, H_{0}: lambda_{0} =2
> and H_{1}: lambda_{0} not equal to 2; for random slope, H_{0}: lambda_{1}
> =1 and H_{1}: lambda_{1} not equal to 1. I assume the test would be a
> likelihood ratio test but please correct me if I am wrong. How do I assess
> type I error for the random-effects model I specified below:
> 
> set.seed(323)
> #The following code is to specify the structure and parameters of the
> random-effects model
> dtfunc = function(nsub){
>   time = 0:9
>   rt = c()
>   time.all = rep(time, nsub)
>   subid.all = as.factor(rep(1:nsub, each = length(time)))
> 
>   # Step 1:  Specify the lambdas.
>   G = matrix(c(2^2, 0, 0, 1^2), nrow = 2)
>   int.mean = 251
>   slope.mean = 10
>   sub.ints.slopes = mvrnorm(nsub, c(int.mean, slope.mean), G)
>   sub.ints = sub.ints.slopes[,1]
>   time.slopes = sub.ints.slopes[,2]
> 
>   # Step 2:  Use the intercepts and slopes to generate RT data
>   sigma = 30
>   for (i in 1:nsub){
>     rt.vec = sub.ints[i] + time.slopes[i]*time + rnorm(length(time), sd =
> sigma)
>     rt = c(rt, rt.vec)
>   }
> 
>   dat = data.frame(rt, time.all, subid.all)
>   return(dat)
> }
> 
> #Here I run one random-effects model
> set.seed(10)
> dat = dtfunc(16)
> lmer(rt~time.all + (1+time.all |subid.all), dat)
> 
> Assuming the test for significance is likelihood ratio test and so in the
> end, I want to see if I run the test 1000 times, what is the probability of
> rejecting the null hypothesis when it is TRUE. Also, how do I plot the
> behavior of type I error if I change the values of standard deviations?
> 
> Any help is appreciated!
> 
> Best,
> 
> Chao
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Mar  2 06:53:38 2022
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Tue, 1 Mar 2022 23:53:38 -0600
Subject: [R-sig-ME] measuring carry-over effects in mixed models
In-Reply-To: <b7525460-681e-1c2b-52fe-ad904e1ad59f@phillipalday.com>
References: <CACgv6yWxs1GSAwq8K0tv4=WZ+ObEu66XMBSMeECOt+6r=oMCrQ@mail.gmail.com>
 <b7525460-681e-1c2b-52fe-ad904e1ad59f@phillipalday.com>
Message-ID: <CACgv6yWLR+ML+acMzvzh-3qRif==fZxSPb6E2Y+t3tMH0Z-=tg@mail.gmail.com>

Dear Phillip,

Thank you for your response. Could you possibly elaborate on
"Depending on the exact nature of the carryover effect"?

Also, how are the "lead/lag predictors" often created?

My data has the following general structure.

m<-"
   student group  time
         1 C         0
         1 C         1
         1 C         2
         1 C         3
         1 T         0
         1 T         1
         1 T         2
         1 T         3
         2 C         0
         2 C         1
         2 C         2
         2 C         3
         2 T         0
         2 T         1
         2 T         2
         2 T         3"

data <- read.table(text=m,h=T)

Simon


On Tue, Mar 1, 2022 at 11:12 PM Phillip Alday <me at phillipalday.com> wrote:
>
> Depending on the exact nature of the carryover effect, the usual
> suspects would be:
>
> 1. using an autoregressive model of some type
> 2. including lead/lag predictors in your model, e.g.
>         lmer(y ~ time*group*prev_time + [covariates] + (1 | student))
>
> But note that the initial timepoint doesn't have a prev_time and so
> there is a missing value there.
>
> Phillip
>
> On 17/2/22 12:32 pm, Simon Harmel wrote:
> > Hello All,
> >
> > I'm analyzing the data from my longitudinal study whose design can be
> > depicted as (view the following in plain text):
> >
> > O1  X1  O2  X2  O3  X3  O4
> > O1      O2      O3      O4
> >
> > where Xs denote subtitled videos given to the treatment group and Os
> > denote measurement occasions.
> >
> > My current model is:  lmer(y ~ time*group + [covariates] + (1 | student))
> >
> > However, I'm also interested in measuring the "carry-over effects" of
> > watching subtitled videos at each occasion to the subsequent
> > occasions.
> >
> > For instance, I want to know how much watching the subtitled video at
> > the first occasion (O1) impacts the treated students' performance at
> > later occasions (O2 and O3) etc.
> >
> > I wonder if any changes to my model can enable me to measure these
> > carry-over effects or if any other R package may provide such
> > functionality?
> >
> > Many thanks,
> > Simon
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >


From me @end|ng |rom ph||||p@|d@y@com  Wed Mar  2 07:03:52 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 2 Mar 2022 00:03:52 -0600
Subject: [R-sig-ME] measuring carry-over effects in mixed models
In-Reply-To: <CACgv6yWLR+ML+acMzvzh-3qRif==fZxSPb6E2Y+t3tMH0Z-=tg@mail.gmail.com>
References: <CACgv6yWxs1GSAwq8K0tv4=WZ+ObEu66XMBSMeECOt+6r=oMCrQ@mail.gmail.com>
 <b7525460-681e-1c2b-52fe-ad904e1ad59f@phillipalday.com>
 <CACgv6yWLR+ML+acMzvzh-3qRif==fZxSPb6E2Y+t3tMH0Z-=tg@mail.gmail.com>
Message-ID: <bccf1458-4a59-ed48-c571-0a2eee740803@phillipalday.com>



On 1/3/22 11:53 pm, Simon Harmel wrote:
> Dear Phillip,
> 
> Thank you for your response. Could you possibly elaborate on
> "Depending on the exact nature of the carryover effect"?
> 

Really just whether you meant something like correlated errors (so
classic AR models) or something more particular based on domain
knowledge (for example a convolution of successive impulses in certain
signal processing domains). The lead/lag solution basically just makes
all the usual assumptions for a linear model, it's just that you have to
consider the collinearity of any relevant covariate/predictor with
itself at a previous time point.

If you include your lagged dependent variable/response as a predictor,
then you have to be a little bit careful with having measurement error /
"errors within variables" because predictors are generally assumed to be
measured without error. (In y_(t) ~ 1 + y_(t-1), you know have the noise
of y on the wrong side.) That's a bigger topic than I have time for at
the moment, but I think I've dropped enough keywords for further
searching and/or setting up your simulations to see what happens.

> Also, how are the "lead/lag predictors" often created?

There are ways to do this in base R, but they can be a little bit tricky
with nested/grouped data, so I would go with the tidverse group_by() +
lag(): https://dplyr.tidyverse.org/reference/lead-lag.html

> 
> My data has the following general structure.
> 
> m<-"
>    student group  time
>          1 C         0
>          1 C         1
>          1 C         2
>          1 C         3
>          1 T         0
>          1 T         1
>          1 T         2
>          1 T         3
>          2 C         0
>          2 C         1
>          2 C         2
>          2 C         3
>          2 T         0
>          2 T         1
>          2 T         2
>          2 T         3"
> 
> data <- read.table(text=m,h=T)
> 
> Simon
> 
> 
> On Tue, Mar 1, 2022 at 11:12 PM Phillip Alday <me at phillipalday.com> wrote:
>>
>> Depending on the exact nature of the carryover effect, the usual
>> suspects would be:
>>
>> 1. using an autoregressive model of some type
>> 2. including lead/lag predictors in your model, e.g.
>>         lmer(y ~ time*group*prev_time + [covariates] + (1 | student))
>>
>> But note that the initial timepoint doesn't have a prev_time and so
>> there is a missing value there.
>>
>> Phillip
>>
>> On 17/2/22 12:32 pm, Simon Harmel wrote:
>>> Hello All,
>>>
>>> I'm analyzing the data from my longitudinal study whose design can be
>>> depicted as (view the following in plain text):
>>>
>>> O1  X1  O2  X2  O3  X3  O4
>>> O1      O2      O3      O4
>>>
>>> where Xs denote subtitled videos given to the treatment group and Os
>>> denote measurement occasions.
>>>
>>> My current model is:  lmer(y ~ time*group + [covariates] + (1 | student))
>>>
>>> However, I'm also interested in measuring the "carry-over effects" of
>>> watching subtitled videos at each occasion to the subsequent
>>> occasions.
>>>
>>> For instance, I want to know how much watching the subtitled video at
>>> the first occasion (O1) impacts the treated students' performance at
>>> later occasions (O2 and O3) etc.
>>>
>>> I wonder if any changes to my model can enable me to measure these
>>> carry-over effects or if any other R package may provide such
>>> functionality?
>>>
>>> Many thanks,
>>> Simon
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Wed Mar  2 12:23:36 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Wed, 2 Mar 2022 13:23:36 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <f80557f3-35c7-7b22-ae9c-2f14ff0d7ac0@mcmaster.ca>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
 <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
 <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>
 <0f03187e-d848-ea43-e370-ead2d403b530@mcmaster.ca>
 <CAG_dBVfv2-8Z0VRvcK4QUP97oh5jOhPd2d=LUj0N_6Ec+appMw@mail.gmail.com>
 <f80557f3-35c7-7b22-ae9c-2f14ff0d7ac0@mcmaster.ca>
Message-ID: <CAG_dBVe7f5aEB_hA5t-j2u9ZJw-bDQPOchxc3-QTX3VejqXQSQ@mail.gmail.com>

One last comment, John: Sorry if I seemed to be implying that you (or
anyone else) should debug my code for me. That wasn't the idea. I do
believe that the function locates the intended rows/columns successfully. I
just wasn't entirely positive what those intended rows/columns should be
when dealing with a multicategory factor. Presently, it locates every
row/column involving the multicategory factor in question, so the number of
rows/columns identified is the number of factor levels minus one, times the
number of response categories minus one. I hope that's correct.

My current plan is to present the output of the new function in my thesis
and credit you for the math. But if *vif()* gets a relevant update before
my project is finished, then I'll use that and cite the *car *package
instead.

Thanks again for your help.

Best,

Juho

ti 1. maalisk. 2022 klo 23.54 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juho,
>
> On 2022-03-01 3:13 p.m., Juho Kristian Ruohonen wrote:
> > Dear John,
> >
> > Yes, my function uses your code for the math. I was just hoping to
> > verify that it is handling multicategory factors correctly (your
> > examples didn't involve any).
>
> That's not really my point. Your code sets up computations for the
> various terms in the model automatically, while the function I sent
> requires that you locate the rows/columns for the intercepts and each
> focal term manually. If you haven't already done so, you could check
> that your function is identifying the correct columns and getting the
> corresponding GVIFs.
>
> >
> > I guess interactions aren't that important after all, given that the
> > chief concern is usually collinearity among main effects.
>
> I wouldn't say that, but it's not clear what collinearity means in
> models with interactions, and if you compute VIFs or GVIFs for "main
> effects" in models with interactions, you'll probably get nonsense.
>
> As I said, I think that this might be a solvable problem, but one that
> requires thought about what needs to remain invariant.
>
> I think that we've probably come to end for now.
>
> John
>
> >
> > Many thanks for all your help.
> >
> > Best,
> >
> > Juho
> >
> > ti 1. maalisk. 2022 klo 18.01 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Juho,
> >
> >     On 2022-03-01 8:24 a.m., Juho Kristian Ruohonen wrote:
> >      > Dear John (Fox, as well as other list members),
> >      >
> >      > I've now written a simple function to try and calculate GVIFS for
> >     all
> >      > predictors in a nnet::multinom() object based on John's example
> >     code. If
> >      > its results are correct (see below), I will proceed to write a
> >     version
> >      > that also works with mixed-effects multinomial models fit by
> >      > brms::brm(). Here's the code:
> >      >
> >      >     gvif.multinom <- function(model){
> >      >        (classes <- model$lev)
> >      >        (V.all <- vcov(model))
> >      >        (V.noIntercepts <- V.all[!grepl("\\(Intercept\\)$",
> >      >     rownames(V.all), perl = T),
> >      >                                 !grepl("\\(Intercept\\)$",
> >      >     colnames(V.all), perl = T)])
> >      >        (R <- cov2cor(V.noIntercepts))
> >      >        (terms <- attr(model$terms, "term.labels"))
> >      >        (gvif <- numeric(length = length(terms)))
> >      >        (names(gvif) <- terms)
> >      >        (SE.multiplier <- numeric(length = length(terms)))
> >      >        (names(SE.multiplier) <- terms)
> >      >        #The line below tries to capture all factor levels into a
> >     regex
> >      >     for coef name matching.
> >      >        (LevelsRegex <- paste0("(", paste(unlist(model$xlevels),
> >     collapse
> >      >     = "|"),")?"))
> >      >
> >      >        for(i in terms){
> >      >          #The regex stuff below tries to ensure all interaction
> >      >     coefficients are matched, including those involving factors.
> >      >          if(grepl(":", i)){
> >      >            (termname <- gsub(":", paste0(LevelsRegex, ":"), i,
> >     perl = T))
> >      >          }else{termname <- i}
> >      >          (RegexToMatch <- paste0("^(",
> >     paste(classes[2:length(classes)],
> >      >     collapse = "|") ,"):", termname, LevelsRegex, "$"))
> >      >
> >      >          #Now the actual calculation:
> >      >          (indices <- grep(RegexToMatch, rownames(R), perl = T))
> >      >          (gvif[i] <- det(R[indices, indices]) * det(R[-indices,
> >      >     -indices]) / det(R))
> >      >          (SE.multiplier[i] <- gvif[i]^(1/(2*length(indices))))
> >      >        }
> >      >        #Put the results together and order them by degree of SE
> >     inflation:
> >      >        (result <- cbind(GVIF = gvif, `GVIF^(1/(2df))` =
> >     SE.multiplier))
> >      >        return(result[order(result[,"GVIF^(1/(2df))"], decreasing
> >     = T),])}
> >      >
> >      >
> >      > The results seem correct to me when applied to John's example
> >     model fit
> >      > to the BEPS data. However, that dataset contains no multi-df
> >     factors, of
> >      > which my own models have many. Below is a maximally simple
> >     example with
> >      > one multi-df factor (/region/):
> >      >
> >      >     mod1 <- multinom(partic ~., data = carData::Womenlf)
> >      >     gvif.multinom(mod1)
> >      >
> >      >     GVIF GVIF^(1/(2df))
> >      >     children 1.298794       1.067542
> >      >     hincome  1.184215       1.043176
> >      >     region   1.381480       1.020403
> >      >
> >      >
> >      > These results look plausible to me. Finally, below is an example
> >      > involving both a multi-df factor and an interaction:
> >      >
> >      >     mod2 <- update(mod1, ~. +children:region)
> >      >     gvif.multinom(mod2)
> >      >
> >      >                              GVIF GVIF^(1/(2df))
> >      >     children:region 4.965762e+16      11.053482
> >      >     region          1.420418e+16      10.221768
> >      >     children        1.471412e+03       6.193463
> >      >     hincome         6.462161e+00       1.594390
> >      >
> >      >
> >      > These results look a bit more dubious. To be sure, it is to be
> >     expected
> >      > that interaction terms will introduce a lot of collinearity. But
> an
> >      > 11-fold increase in SE? I hope someone can tell me whether this is
> >      > correct or not!
> >
> >     You don't need someone else to check your work because you could just
> >     apply the simple function that I sent you yesterday, which, though
> not
> >     automatic, computes the GVIFs in a transparent manner.
> >
> >     A brief comment on GVIFs for models with interactions (this isn't the
> >     place to discuss the question in detail): The Fox and Monette JASA
> >     paper
> >     addresses the question briefly in the context of a two-way ANOVA,
> but I
> >     don't think that the approach suggested there is easily generalized.
> >
> >     The following simple approach pays attention to what's invariant
> under
> >     different parametrizations of the RHS side of the model:
> Simultaneously
> >     check the collinearity of all of the coefficients of an interaction
> >     together with the main effects and, potentially, lower-order
> >     interactions that are marginal to it. So, e.g., in the model y ~ a +
> >     b +
> >     a:b + c, you'd check all of the coefficients for a, b, and a:b
> together.
> >
> >     Alternatively, one could focus in turn on each explanatory variable
> and
> >     check the collinearity of all coefficients to which it is marginal.
> So
> >     in y ~ a + b + c + a:b + a:c + d, when you focus on a, you'd look at
> >     all
> >     of the coefficients for a, b, c, a:b, and a:c.
> >
> >     John
> >
> >      >
> >      > Best,
> >      >
> >      > Juho
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      >
> >      > ti 1. maalisk. 2022 klo 0.05 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
> >      >
> >      >     Dear Juha,
> >      >
> >      >     On 2022-02-28 5:00 p.m., Juho Kristian Ruohonen wrote:
> >      >      > Apologies for my misreading, John, and many thanks for
> showing
> >      >     how the
> >      >      > calculation is done for a single term.
> >      >      >
> >      >      > Do you think *vif()* might be updated in the near future
> >     with the
> >      >      > capability of auto-detecting a multinomial model and
> returning
> >      >      > mathematically correct GVIF statistics?
> >      >
> >      >     The thought crossed my mind, but I'd want to do it in a
> >     general way,
> >      >     not
> >      >     just for the multinom() function, and in a way that avoids
> >     incorrect
> >      >     results such as those currently produced for "multinom"
> >     models, albeit
> >      >     with a warning. I can't guarantee whether or when I'll be
> >     able to do
> >      >     that.
> >      >
> >      >     John
> >      >
> >      >      >
> >      >      > If not, I'll proceed to writing my own function based on
> your
> >      >     example.
> >      >      > However, /car/ is such an excellent and widely used
> >     package that the
> >      >      > greatest benefit to mankind would probably accrue if /car
> /was
> >      >     upgraded
> >      >      > with this feature sooner rather than later.
> >      >      >
> >      >      > Best,
> >      >      >
> >      >      > Juho
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      > ma 28. helmik. 2022 klo 17.08 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
> >      >      >
> >      >      >     Dear Juho,
> >      >      >
> >      >      >     On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen wrote:
> >      >      >      > Dear Professor Fox and other list members,
> >      >      >      >
> >      >      >      > Profuse thanks for doing that detective work for
> >     me! I myself
> >      >      >     thought
> >      >      >      > the inflation factors reported by
> >     check_collinearity() were
> >      >      >     suspiciously
> >      >      >      > high, but unlike you I lacked the expertise to
> identify
> >      >     what was
> >      >      >     going on.
> >      >      >      >
> >      >      >      > As for your suggested approach, have I understood
> this
> >      >     correctly:
> >      >      >      >
> >      >      >      > Since there doesn't yet exist an R function that
> will
> >      >     calculate the
> >      >      >      > (G)VIFS of multinomial models correctly, my best
> >     bet for
> >      >     now is
> >      >      >     just to
> >      >      >      > ignore the fact that such models partition the data
> >     into C-1
> >      >      >     subsets,
> >      >      >      > and to calculate approximate GVIFs from the entire
> >     dataset at
> >      >      >     once as if
> >      >      >      > the response were continuous? And a simple way to
> >     do this
> >      >     is to
> >      >      >      > construct a fake continuous response, call
> >      >     *lm(fakeresponse ~.)*,
> >      >      >     and
> >      >      >      > apply *car::vif()* on the result?
> >      >      >
> >      >      >     No, you misunderstand my suggestion, which perhaps
> isn't
> >      >     surprising
> >      >      >     given the length of my message. What you propose is
> what I
> >      >     suggested as
> >      >      >     a rough approximation *before* I confirmed that my
> >     guess of the
> >      >      >     solution
> >      >      >     was correct.
> >      >      >
> >      >      >     The R code that I sent yesterday showed how to compute
> the
> >      >     GVIF for a
> >      >      >     multinomial regression model, and I suggested that you
> >     write
> >      >     either a
> >      >      >     script or a simple function to do that. Here's a
> function
> >      >     that will
> >      >      >     work
> >      >      >     for a model object that responds to vcov():
> >      >      >
> >      >      >     GVIF <- function(model, intercepts, term){
> >      >      >         # model: regression model object
> >      >      >         # intercepts: row/column positions of intercepts
> >     in the
> >      >     coefficient
> >      >      >     covariance matrix
> >      >      >         # term: row/column positions of the coefficients
> >     for the
> >      >     focal term
> >      >      >         V <- vcov(model)
> >      >      >         term <- colnames(V)[term]
> >      >      >         V <- V[-intercepts, -intercepts]
> >      >      >         V <- cov2cor(V)
> >      >      >         term <- which(colnames(V) %in% term)
> >      >      >         gvif <- det(V[term, term])*det(V[-term,
> -term])/det(V)
> >      >      >         c(GVIF=gvif,
> >     "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
> >      >      >     }
> >      >      >
> >      >      >     and here's an application to the multinom() example
> that I
> >      >     showed you
> >      >      >     yesterday:
> >      >      >
> >      >      >       > colnames(vcov(m)) # to get coefficient positions
> >      >      >        [1] "Labour:(Intercept)"
> >       "Labour:age"
> >      >      >
> >      >      >        [3] "Labour:economic.cond.national"
> >      >      >     "Labour:economic.cond.household"
> >      >      >        [5] "Labour:Blair"
> >       "Labour:Hague"
> >      >      >
> >      >      >        [7] "Labour:Kennedy"
> >       "Labour:Europe"
> >      >      >
> >      >      >        [9] "Labour:political.knowledge"
> >      >       "Labour:gendermale"
> >      >      >
> >      >      >     [11] "Liberal Democrat:(Intercept)"
>  "Liberal
> >      >     Democrat:age"
> >      >      >
> >      >      >     [13] "Liberal Democrat:economic.cond.national"
> "Liberal
> >      >      >     Democrat:economic.cond.household"
> >      >      >     [15] "Liberal Democrat:Blair"
>  "Liberal
> >      >      >     Democrat:Hague"
> >      >      >
> >      >      >     [17] "Liberal Democrat:Kennedy"
>  "Liberal
> >      >      >     Democrat:Europe"
> >      >      >     [19] "Liberal Democrat:political.knowledge"
>  "Liberal
> >      >      >     Democrat:gendermale"
> >      >      >
> >      >      >       > GVIF(m, intercepts=c(1, 11), term=c(2, 12)) # GVIF
> >     for age
> >      >      >                 GVIF GVIF^(1/(2*p))
> >      >      >             1.046232       1.011363
> >      >      >
> >      >      >
> >      >      >     Finally, here's what you get for a linear model with
> >     the same RHS
> >      >      >     (where
> >      >      >     the sqrt(VIF) should be a rough approximation to
> >     GVIF^(1/4)
> >      >     reported by
> >      >      >     my GVIF() function):
> >      >      >
> >      >      >       > m.lm <- lm(as.numeric(vote) ~ . - vote1, data=BEPS)
> >      >      >       > sqrt(car::vif(m.lm))
> >      >      >                           age  economic.cond.national
> >      >      >     economic.cond.household
> >      >      >                         Blair
> >      >      >                      1.006508                1.124132
> >      >      >     1.075656
> >      >      >                      1.118441
> >      >      >                         Hague                 Kennedy
> >      >      >     Europe
> >      >      >           political.knowledge
> >      >      >                      1.066799                1.015532
> >      >      >     1.101741
> >      >      >                      1.028546
> >      >      >                        gender
> >      >      >                      1.017386
> >      >      >
> >      >      >
> >      >      >     John
> >      >      >
> >      >      >      >
> >      >      >      > Best,
> >      >      >      >
> >      >      >      > Juho
> >      >      >      >
> >      >      >      > ma 28. helmik. 2022 klo 2.23 John Fox
> >     (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >      >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>) kirjoitti:
> >      >      >      >
> >      >      >      >     Dear Juho,
> >      >      >      >
> >      >      >      >     I've now had a chance to think about this
> >     problem some
> >      >     more,
> >      >      >     and I
> >      >      >      >     believe that the approach I suggested is
> correct. I
> >      >     also had an
> >      >      >      >     opportunity to talk the problem over a bit with
> >     Georges
> >      >      >     Monette, who
> >      >      >      >     coauthored the paper that introduced
> >     generalized variance
> >      >      >     inflation
> >      >      >      >     factors (GVIFs). On the other hand, the results
> >      >     produced by
> >      >      >      >     performance::check_collinearity() for
> >     multinomial logit
> >      >      >     models don't
> >      >      >      >     seem to be correct (see below).
> >      >      >      >
> >      >      >      >     Here's an example, using the nnet::multinom()
> >     function
> >      >     to fit a
> >      >      >      >     multinomial logit model, with alternative
> >      >     parametrizations of the
> >      >      >      >     LHS of
> >      >      >      >     the model:
> >      >      >      >
> >      >      >      >     --------- snip -----------
> >      >      >      >
> >      >      >      >       > library(nnet) # for multinom()
> >      >      >      >       > library(carData) # for BEPS data set
> >      >      >      >
> >      >      >      >       > # alternative ordering of the response
> levels:
> >      >      >      >       > BEPS$vote1 <- factor(BEPS$vote,
> >     levels=c("Labour",
> >      >     "Liberal
> >      >      >      >     Democrat", "Conservative"))
> >      >      >      >       > levels(BEPS$vote)
> >      >      >      >     [1] "Conservative"     "Labour"
>  "Liberal
> >      >     Democrat"
> >      >      >      >       > levels(BEPS$vote1)
> >      >      >      >     [1] "Labour"           "Liberal Democrat"
> >     "Conservative"
> >      >      >      >
> >      >      >      >       > m <- multinom(vote ~ . - vote1, data=BEPS)
> >      >      >      >     # weights:  33 (20 variable)
> >      >      >      >     initial  value 1675.383740
> >      >      >      >     iter  10 value 1345.935273
> >      >      >      >     iter  20 value 1150.956807
> >      >      >      >     iter  30 value 1141.921662
> >      >      >      >     iter  30 value 1141.921661
> >      >      >      >     iter  30 value 1141.921661
> >      >      >      >     final  value 1141.921661
> >      >      >      >     converged
> >      >      >      >       > m1 <- multinom(vote1 ~ . - vote, data=BEPS)
> >      >      >      >     # weights:  33 (20 variable)
> >      >      >      >     initial  value 1675.383740
> >      >      >      >     iter  10 value 1280.439304
> >      >      >      >     iter  20 value 1165.513772
> >      >      >      >     final  value 1141.921662
> >      >      >      >     converged
> >      >      >      >
> >      >      >      >       > rbind(coef(m), coef(m1)) # compare
> coefficients
> >      >      >      >                        (Intercept)          age
> >      >      >     economic.cond.national
> >      >      >      >     economic.cond.household
> >      >      >      >     Labour             0.9515214 -0.021913989
> >      >     0.5575707
> >      >      >      >            0.15839096
> >      >      >      >     Liberal Democrat   1.4119306 -0.016810735
> >      >     0.1810761
> >      >      >      >           -0.01196664
> >      >      >      >     Liberal Democrat   0.4604567  0.005102666
> >      >       -0.3764928
> >      >      >      >           -0.17036682
> >      >      >      >     Conservative      -0.9514466  0.021912305
> >      >       -0.5575644
> >      >      >      >           -0.15838744
> >      >      >      >                             Blair       Hague
> >     Kennedy
> >      >          Europe
> >      >      >      >     political.knowledge
> >      >      >      >     Labour            0.8371764 -0.90775585
> 0.2513436
> >      >     -0.22781308
> >      >      >      >     -0.5370612
> >      >      >      >     Liberal Democrat  0.2937331 -0.82217625
> 0.6710567
> >      >     -0.20004624
> >      >      >      >     -0.2034605
> >      >      >      >     Liberal Democrat -0.5434408  0.08559455
> 0.4197027
> >      >     0.02776465
> >      >      >      >     0.3336068
> >      >      >      >     Conservative     -0.8371670  0.90778068
> -0.2513735
> >      >     0.22781092
> >      >      >      >     0.5370545
> >      >      >      >                         gendermale
> >      >      >      >     Labour            0.13765774
> >      >      >      >     Liberal Democrat  0.12640823
> >      >      >      >     Liberal Democrat -0.01125898
> >      >      >      >     Conservative     -0.13764849
> >      >      >      >
> >      >      >      >       > c(logLik(m), logLik(m1)) # same fit to the
> data
> >      >      >      >     [1] -1141.922 -1141.922
> >      >      >      >
> >      >      >      >       > # covariance matrices for coefficients:
> >      >      >      >       > V <- vcov(m)
> >      >      >      >       > V1 <- vcov(m1)
> >      >      >      >       > cbind(colnames(V), colnames(V1)) # compare
> >      >      >      >             [,1]
> >         [,2]
> >      >      >      >
> >      >      >      >        [1,] "Labour:(Intercept)"
> >      >       "Liberal
> >      >      >      >     Democrat:(Intercept)"
> >      >      >      >        [2,] "Labour:age"
> >      >       "Liberal
> >      >      >      >     Democrat:age"
> >      >      >      >
> >      >      >      >        [3,] "Labour:economic.cond.national"
> >      >     "Liberal
> >      >      >      >     Democrat:economic.cond.national"
> >      >      >      >        [4,] "Labour:economic.cond.household"
> >      >       "Liberal
> >      >      >      >     Democrat:economic.cond.household"
> >      >      >      >        [5,] "Labour:Blair"
> >      >       "Liberal
> >      >      >      >     Democrat:Blair"
> >      >      >      >        [6,] "Labour:Hague"
> >      >       "Liberal
> >      >      >      >     Democrat:Hague"
> >      >      >      >        [7,] "Labour:Kennedy"
> >      >       "Liberal
> >      >      >      >     Democrat:Kennedy"
> >      >      >      >        [8,] "Labour:Europe"
> >      >     "Liberal
> >      >      >      >     Democrat:Europe"
> >      >      >      >        [9,] "Labour:political.knowledge"
> >      >       "Liberal
> >      >      >      >     Democrat:political.knowledge"
> >      >      >      >     [10,] "Labour:gendermale"
> >        "Liberal
> >      >      >      >     Democrat:gendermale"
> >      >      >      >     [11,] "Liberal Democrat:(Intercept)"
> >      >      >      >     "Conservative:(Intercept)"
> >      >      >      >     [12,] "Liberal Democrat:age"
> >      >      >       "Conservative:age"
> >      >      >      >
> >      >      >      >     [13,] "Liberal Democrat:economic.cond.national"
> >      >      >      >     "Conservative:economic.cond.national"
> >      >      >      >     [14,] "Liberal Democrat:economic.cond.household"
> >      >      >      >     "Conservative:economic.cond.household"
> >      >      >      >     [15,] "Liberal Democrat:Blair"
> >      >      >       "Conservative:Blair"
> >      >      >      >
> >      >      >      >     [16,] "Liberal Democrat:Hague"
> >      >      >       "Conservative:Hague"
> >      >      >      >
> >      >      >      >     [17,] "Liberal Democrat:Kennedy"
> >      >      >       "Conservative:Kennedy"
> >      >      >      >
> >      >      >      >     [18,] "Liberal Democrat:Europe"
> >      >      >     "Conservative:Europe"
> >      >      >      >
> >      >      >      >     [19,] "Liberal Democrat:political.knowledge"
> >      >      >      >     "Conservative:political.knowledge"
> >      >      >      >     [20,] "Liberal Democrat:gendermale"
> >      >      >      >     "Conservative:gendermale"
> >      >      >      >
> >      >      >      >       > int <- c(1, 11) # remove intercepts
> >      >      >      >       > colnames(V)[int]
> >      >      >      >     [1] "Labour:(Intercept)"           "Liberal
> >      >     Democrat:(Intercept)"
> >      >      >      >
> >      >      >      >       > colnames(V1)[int]
> >      >      >      >     [1] "Liberal Democrat:(Intercept)"
> >      >     "Conservative:(Intercept)"
> >      >      >      >       > V <- V[-int, -int]
> >      >      >      >       > V1 <- V1[-int, -int]
> >      >      >      >
> >      >      >      >       > age <- c(1, 10) # locate age coefficients
> >      >      >      >       > colnames(V)[age]
> >      >      >      >     [1] "Labour:age"           "Liberal
> Democrat:age"
> >      >      >      >       > colnames(V1)[age]
> >      >      >      >     [1] "Liberal Democrat:age" "Conservative:age"
> >      >      >      >
> >      >      >      >       > V <- cov2cor(V) # compute coefficient
> >     correlations
> >      >      >      >       > V1 <- cov2cor(V1)
> >      >      >      >
> >      >      >      >       > # compare GVIFs:
> >      >      >      >       > c(det(V[age, age])*det(V[-age,
> -age])/det(V),
> >      >      >      >     +   det(V1[age, age])*det(V1[-age,
> -age])/det(V1))
> >      >      >      >     [1] 1.046232 1.046229
> >      >      >      >
> >      >      >      >     --------- snip -----------
> >      >      >      >
> >      >      >      >     For curiosity, I applied car::vif() and
> >      >      >      >     performance::check_collinearity() to these
> >     models to
> >      >     see what
> >      >      >     they
> >      >      >      >     would
> >      >      >      >     do. Both returned the wrong answer. vif()
> >     produced a
> >      >     warning, but
> >      >      >      >     check_collinearity() didn't:
> >      >      >      >
> >      >      >      >     --------- snip -----------
> >      >      >      >
> >      >      >      >       > car::vif(m1)
> >      >      >      >                           age
> economic.cond.national
> >      >      >      >     economic.cond.household
> >      >      >      >                     15.461045
>  22.137772
> >      >      >      >       16.693877
> >      >      >      >                         Blair
>  Hague
> >      >      >      >       Kennedy
> >      >      >      >                     14.681562
> 7.483039
> >      >      >      >       15.812067
> >      >      >      >                        Europe
>  political.knowledge
> >      >      >      >     gender
> >      >      >      >                      6.502119
> 4.219507
> >      >      >      >     2.313885
> >      >      >      >     Warning message:
> >      >      >      >     In vif.default(m1) : No intercept: vifs may not
> be
> >      >     sensible.
> >      >      >      >
> >      >      >      >       > performance::check_collinearity(m)
> >      >      >      >     # Check for Multicollinearity
> >      >      >      >
> >      >      >      >     Low Correlation
> >      >      >      >
> >      >      >      >                           Term  VIF Increased SE
> >     Tolerance
> >      >      >      >                            age 1.72         1.31
> >        0.58
> >      >      >      >         economic.cond.national 1.85         1.36
> >        0.54
> >      >      >      >        economic.cond.household 1.86         1.37
> >        0.54
> >      >      >      >                          Blair 1.63         1.28
> >        0.61
> >      >      >      >                          Hague 1.94         1.39
> >        0.52
> >      >      >      >                        Kennedy 1.70         1.30
> >        0.59
> >      >      >      >                         Europe 2.01         1.42
> >        0.50
> >      >      >      >            political.knowledge 1.94         1.39
> >        0.52
> >      >      >      >                         gender 1.78         1.33
> >        0.56
> >      >      >      >       > performance::check_collinearity(m1)
> >      >      >      >     # Check for Multicollinearity
> >      >      >      >
> >      >      >      >     Low Correlation
> >      >      >      >
> >      >      >      >                           Term  VIF Increased SE
> >     Tolerance
> >      >      >      >                            age 1.19         1.09
> >        0.84
> >      >      >      >         economic.cond.national 1.42         1.19
> >        0.70
> >      >      >      >        economic.cond.household 1.32         1.15
> >        0.76
> >      >      >      >                          Blair 1.50         1.22
> >        0.67
> >      >      >      >                          Hague 1.30         1.14
> >        0.77
> >      >      >      >                        Kennedy 1.19         1.09
> >        0.84
> >      >      >      >                         Europe 1.34         1.16
> >        0.75
> >      >      >      >            political.knowledge 1.30         1.14
> >        0.77
> >      >      >      >                         gender 1.23         1.11
> >        0.81
> >      >      >      >
> >      >      >      >     --------- snip -----------
> >      >      >      >
> >      >      >      >     I looked at the code for vif() and
> >     check_collinearity() to
> >      >      >     see where
> >      >      >      >     they went wrong. Both failed to handle the two
> >      >     intercepts in
> >      >      >     the model
> >      >      >      >     correctly -- vif() thought there was no
> >     intercept and
> >      >      >      >     check_collinearity() just removed the first
> >     intercept
> >      >     but not the
> >      >      >      >     second.
> >      >      >      >
> >      >      >      >     In examining the code for check_collinearity(),
> I
> >      >     discovered a
> >      >      >      >     couple of
> >      >      >      >     additional disconcerting facts. First, part of
> the
> >      >     code seems
> >      >      >     to be
> >      >      >      >     copied from vif.default(). Second, as a
> >     consequence,
> >      >      >      >     check_collinearity() actually computes GVIFs
> rather
> >      >     than VIFs
> >      >      >     (and
> >      >      >      >     doesn't reference either the Fox and Monette
> paper
> >      >      >     introducing GVIFs or
> >      >      >      >     the car package) but doesn't seem to understand
> >     that, and,
> >      >      >     for example,
> >      >      >      >     takes the squareroot of the GVIF (reported in
> the
> >      >     column marked
> >      >      >      >     "Increased SE") rather than the 2p root (when
> there
> >      >     are p > 1
> >      >      >      >     coefficients in a term).
> >      >      >      >
> >      >      >      >     Here's the relevant code from the two functions
> >     (where
> >      >     . . .
> >      >      >     denotes
> >      >      >      >     elided lines) -- the default method for vif()
> and
> >      >      >      >     .check_collinearity(),
> >      >      >      >     which is called by check_collinearity.default():
> >      >      >      >
> >      >      >      >     --------- snip -----------
> >      >      >      >
> >      >      >      >       > car:::vif.default
> >      >      >      >     function (mod, ...)
> >      >      >      >     {
> >      >      >      >           . . .
> >      >      >      >           v <- vcov(mod)
> >      >      >      >           assign <- attr(model.matrix(mod),
> "assign")
> >      >      >      >           if (names(coefficients(mod)[1]) ==
> >     "(Intercept)") {
> >      >      >      >               v <- v[-1, -1]
> >      >      >      >               assign <- assign[-1]
> >      >      >      >           }
> >      >      >      >           else warning("No intercept: vifs may not
> be
> >      >     sensible.")
> >      >      >      >           terms <- labels(terms(mod))
> >      >      >      >           n.terms <- length(terms)
> >      >      >      >           if (n.terms < 2)
> >      >      >      >               stop("model contains fewer than 2
> terms")
> >      >      >      >           R <- cov2cor(v)
> >      >      >      >           detR <- det(R)
> >      >      >      >           . . .
> >      >      >      >           for (term in 1:n.terms) {
> >      >      >      >               subs <- which(assign == term)
> >      >      >      >               result[term, 1] <-
> det(as.matrix(R[subs,
> >      >     subs])) *
> >      >      >      >     det(as.matrix(R[-subs,
> >      >      >      >                   -subs]))/detR
> >      >      >      >               result[term, 2] <- length(subs)
> >      >      >      >           }
> >      >      >      >           . . .
> >      >      >      >     }
> >      >      >      >
> >      >      >      >       > performance:::.check_collinearity
> >      >      >      >     function (x, component, verbose = TRUE)
> >      >      >      >     {
> >      >      >      >           v <- insight::get_varcov(x, component =
> >     component,
> >      >      >     verbose =
> >      >      >      >     FALSE)
> >      >      >      >           assign <- .term_assignments(x, component,
> >     verbose =
> >      >      >     verbose)
> >      >      >      >           . . .
> >      >      >      >           if (insight::has_intercept(x)) {
> >      >      >      >               v <- v[-1, -1]
> >      >      >      >               assign <- assign[-1]
> >      >      >      >           }
> >      >      >      >           else {
> >      >      >      >               if (isTRUE(verbose)) {
> >      >      >      >                   warning("Model has no intercept.
> VIFs
> >      >     may not be
> >      >      >      >     sensible.",
> >      >      >      >                       call. = FALSE)
> >      >      >      >               }
> >      >      >      >           }
> >      >      >      >               . . .
> >      >      >      >               terms <-
> >     labels(stats::terms(f[[component]]))
> >      >      >      >               . . .
> >      >      >      >           n.terms <- length(terms)
> >      >      >      >           if (n.terms < 2) {
> >      >      >      >               if (isTRUE(verbose)) {
> >      >      >      >
> >       warning(insight::format_message(sprintf("Not
> >      >      >     enough model
> >      >      >      >     terms in the %s part of the model to check for
> >      >      >     multicollinearity.",
> >      >      >      >                       component)), call. = FALSE)
> >      >      >      >               }
> >      >      >      >               return(NULL)
> >      >      >      >           }
> >      >      >      >           R <- stats::cov2cor(v)
> >      >      >      >           detR <- det(R)
> >      >      >      >           . . .
> >      >      >      >           for (term in 1:n.terms) {
> >      >      >      >               subs <- which(assign == term)
> >      >      >      >                   . . .
> >      >      >      >                   result <- c(result,
> >      >     det(as.matrix(R[subs, subs])) *
> >      >      >      >                       det(as.matrix(R[-subs,
> >     -subs]))/detR)
> >      >      >      >                   . . .
> >      >      >      >           }
> >      >      >      >           . . .
> >      >      >      >     }
> >      >      >      >
> >      >      >      >     --------- snip -----------
> >      >      >      >
> >      >      >      >     So, the upshot of all this is that you should
> >     be able
> >      >     to do
> >      >      >     what you
> >      >      >      >     want, but not with either car::vif() or
> >      >      >      >     performance::check_collinearity(). Instead,
> either
> >      >     write your own
> >      >      >      >     function or do the computations in a script.
> >      >      >      >
> >      >      >      >     There's also a lesson here about S3 default
> >     methods:
> >      >     The fact
> >      >      >     that a
> >      >      >      >     default method returns a result rather than
> >     throwing
> >      >     an error
> >      >      >     or a
> >      >      >      >     warning doesn't mean that the result is the
> >     right answer.
> >      >      >      >
> >      >      >      >     I hope this helps,
> >      >      >      >        John
> >      >      >      >
> >      >      >      >
> >      >      >      >     On 2022-02-26 3:45 p.m., Juho Kristian Ruohonen
> >     wrote:
> >      >      >      >      > Dear John W,
> >      >      >      >      >
> >      >      >      >      > Thank you very much for the tip-off!
> >     Apologies for not
> >      >      >     responding
> >      >      >      >     earlier
> >      >      >      >      > (gmail apparently decided to direct your
> email
> >      >     right into the
> >      >      >      >     junk folder).
> >      >      >      >      > I am very pleased to note that the package
> you
> >      >     mention does
> >      >      >      >     indeed work
> >      >      >      >      > with *brms* multinomial models! Thanks again!
> >      >      >      >      >
> >      >      >      >      > Best,
> >      >      >      >      >
> >      >      >      >      > Juho
> >      >      >      >      >
> >      >      >      >      > pe 25. helmik. 2022 klo 19.23 John Willoughby
> >      >      >      >     (johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>
> >      >      >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>>)
> >      >      >      >      > kirjoitti:
> >      >      >      >      >
> >      >      >      >      >> Have you tried the check_collinearity()
> >     function
> >      >     in the
> >      >      >     performance
> >      >      >      >      >> package? It's supposed to work on brms
> >     models, but
> >      >     whether it
> >      >      >      >     will work on
> >      >      >      >      >> a multinomial model I don't know.  It works
> >     well
> >      >     on mixed
> >      >      >     models
> >      >      >      >     generated
> >      >      >      >      >> by glmmTMB().
> >      >      >      >      >>
> >      >      >      >      >> John Willoughby
> >      >      >      >      >>
> >      >      >      >      >>
> >      >      >      >      >> On Fri, Feb 25, 2022 at 3:01 AM
> >      >      >      >     <r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >      >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>>
> >      >      >      >      >> wrote:
> >      >      >      >      >>
> >      >      >      >      >>> Send R-sig-mixed-models mailing list
> >     submissions to
> >      >      >      >      >>> r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >      >      >      >>>
> >      >      >      >      >>> To subscribe or unsubscribe via the World
> Wide
> >      >     Web, visit
> >      >      >      >      >>>
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >      >      >      >>> or, via email, send a message with subject
> or
> >      >     body 'help' to
> >      >      >      >      >>> r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >      >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>
> >      >      >      >      >>>
> >      >      >      >      >>> You can reach the person managing the list
> at
> >      >      >      >      >>> r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>>
> >      >      >      >      >>>
> >      >      >      >      >>> When replying, please edit your Subject
> >     line so it is
> >      >      >     more specific
> >      >      >      >      >>> than "Re: Contents of R-sig-mixed-models
> >     digest..."
> >      >      >      >      >>>
> >      >      >      >      >>>
> >      >      >      >      >>> Today's Topics:
> >      >      >      >      >>>
> >      >      >      >      >>>     1. Collinearity diagnostics for (mixed)
> >      >     multinomial
> >      >      >     models
> >      >      >      >      >>>        (Juho Kristian Ruohonen)
> >      >      >      >      >>>
> >      >      >      >      >>>
> >      >      >      >
> >      >      >
> >      >
> >
>  ----------------------------------------------------------------------
> >      >      >      >      >>>
> >      >      >      >      >>> Message: 1
> >      >      >      >      >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
> >      >      >      >      >>> From: Juho Kristian Ruohonen
> >      >      >     <juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>
> >      >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>>>
> >      >      >      >      >>> To: John Fox <jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>
> >      >      >      >      >>> Cc: "r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>"
> >      >      >      >      >>>          <r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>
> >      >      >      >      >>> Subject: [R-sig-ME] Collinearity
> >     diagnostics for
> >      >     (mixed)
> >      >      >      >     multinomial
> >      >      >      >      >>>          models
> >      >      >      >      >>> Message-ID:
> >      >      >      >      >>>          <
> >      >      >      >      >>>
> >      >      >      >
> >      >      >
> >      >
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >      >
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>
> >      >      >      >
> >      >      >
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>>>
> >      >      >      >      >>> Content-Type: text/plain; charset="utf-8"
> >      >      >      >      >>>
> >      >      >      >      >>> Dear John (and anyone else qualified to
> >     comment),
> >      >      >      >      >>>
> >      >      >      >      >>> I fit lots of mixed-effects multinomial
> >     models in my
> >      >      >     research,
> >      >      >      >     and I
> >      >      >      >      >> would
> >      >      >      >      >>> like to see some (multi)collinearity
> >     diagnostics
> >      >     on the
> >      >      >     fixed
> >      >      >      >     effects, of
> >      >      >      >      >>> which there are over 30. My models are fit
> >     using the
> >      >      >     Bayesian
> >      >      >      >     *brms*
> >      >      >      >      >>> package because I know of no frequentist
> >     packages
> >      >     with
> >      >      >      >     multinomial GLMM
> >      >      >      >      >>> compatibility.
> >      >      >      >      >>>
> >      >      >      >      >>> With continuous or dichotomous outcomes,
> >     my go-to
> >      >      >     function for
> >      >      >      >      >> calculating
> >      >      >      >      >>> multicollinearity diagnostics is of course
> >      >     *vif()* from
> >      >      >     the *car*
> >      >      >      >      >> package.
> >      >      >      >      >>> As expected, however, this function does
> not
> >      >     report sensible
> >      >      >      >     diagnostics
> >      >      >      >      >>> for multinomial models -- not even for
> >     standard
> >      >     ones fit
> >      >      >     by the
> >      >      >      >     *nnet*
> >      >      >      >      >>> package's *multinom()* function. The
> reason, I
> >      >     presume, is
> >      >      >      >     because a
> >      >      >      >      >>> multinomial model is not really one but C-1
> >      >     regression
> >      >      >     models
> >      >      >      >     (where C
> >      >      >      >      >> is
> >      >      >      >      >>> the number of response categories) and the
> >     *vif()*
> >      >      >     function is not
> >      >      >      >      >> designed
> >      >      >      >      >>> to deal with this scenario.
> >      >      >      >      >>>
> >      >      >      >      >>> Therefore, in order to obtain meaningful
> >     collinearity
> >      >      >     metrics,
> >      >      >      >     my present
> >      >      >      >      >>> plan is to write a simple helper function
> >     that uses
> >      >      >     *vif() *to
> >      >      >      >     calculate
> >      >      >      >      >>> and present (generalized) variance
> inflation
> >      >     metrics for
> >      >      >     the C-1
> >      >      >      >      >>> sub-datasets to which the C-1 component
> >     binomial
> >      >     models
> >      >      >     of the
> >      >      >      >     overall
> >      >      >      >      >>> multinomial model are fit. In other words,
> it
> >      >     will partition
> >      >      >      >     the data
> >      >      >      >      >> into
> >      >      >      >      >>> those C-1 subsets, and then apply *vif()*
> >     to as
> >      >     many linear
> >      >      >      >     regressions
> >      >      >      >      >>> using a made-up continuous response and
> >     the fixed
> >      >     effects of
> >      >      >      >     interest.
> >      >      >      >      >>>
> >      >      >      >      >>> Does this seem like a sensible approach?
> >      >      >      >      >>>
> >      >      >      >      >>> Best,
> >      >      >      >      >>>
> >      >      >      >      >>> Juho
> >      >      >      >      >>>
> >      >      >      >      >>>
> >      >      >      >      >>>
> >      >      >      >      >>
> >      >      >      >      >>          [[alternative HTML version
> deleted]]
> >      >      >      >      >>
> >      >      >      >      >>
> _______________________________________________
> >      >      >      >      >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >      >      >      >      >>
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >      >      >      >>
> >      >      >      >      >
> >      >      >      >      >       [[alternative HTML version deleted]]
> >      >      >      >      >
> >      >      >      >      >
> _______________________________________________
> >      >      >      >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >      >      >      >      >
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >      >      >     --
> >      >      >      >     John Fox, Professor Emeritus
> >      >      >      >     McMaster University
> >      >      >      >     Hamilton, Ontario, Canada
> >      >      >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>
> >      >      >      >
> >      >      >     --
> >      >      >     John Fox, Professor Emeritus
> >      >      >     McMaster University
> >      >      >     Hamilton, Ontario, Canada
> >      >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >      >
> >      >     --
> >      >     John Fox, Professor Emeritus
> >      >     McMaster University
> >      >     Hamilton, Ontario, Canada
> >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >
> >
>  ------------------------------------------------------------------------
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Wed Mar  2 15:35:50 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Wed, 2 Mar 2022 09:35:50 -0500
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <CAG_dBVe7f5aEB_hA5t-j2u9ZJw-bDQPOchxc3-QTX3VejqXQSQ@mail.gmail.com>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
 <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
 <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>
 <0f03187e-d848-ea43-e370-ead2d403b530@mcmaster.ca>
 <CAG_dBVfv2-8Z0VRvcK4QUP97oh5jOhPd2d=LUj0N_6Ec+appMw@mail.gmail.com>
 <f80557f3-35c7-7b22-ae9c-2f14ff0d7ac0@mcmaster.ca>
 <CAG_dBVe7f5aEB_hA5t-j2u9ZJw-bDQPOchxc3-QTX3VejqXQSQ@mail.gmail.com>
Message-ID: <d8c397b8-fbec-6c39-fdf5-5047daf6f219@mcmaster.ca>

Dear Juho,

On 2022-03-02 6:23 a.m., Juho Kristian Ruohonen wrote:
> One last comment, John: Sorry if I seemed to be implying that you (or 
> anyone else) should debug my code for me. That wasn't the idea. I do 
> believe that the function locates the intended rows/columns 
> successfully. I just wasn't entirely positive what those intended 
> rows/columns should be when dealing with a multicategory factor. 
> Presently, it locates every row/column involving the multicategory 
> factor in question, so the number of rows/columns identified is the 
> number of factor levels minus one, times the number of response 
> categories minus one. I hope that's correct.

OK, that's a fair remark. Yes, what you describe is correct.

You can also reassure yourself that your function is working properly by:

(1) If you haven't already done so, show that you get the same GVIFs 
from your function as from the one I sent you used directly.

(2) Vary the baseline level of the response variable and confirm that 
you get the same GVIFs.

(3) Vary the basis for the regressor subspace for a factor, e.g., either 
by using contr.sum() in place of the default contr.treatment() or by 
changing the baseline level of the factor for contr.treatment(), and 
again confirm that the GVIFs are unchanged.

Best,
  John

> 
> My current plan is to present the output of the new function in my 
> thesis and credit you for the math. But if *vif()* gets a relevant 
> update before my project is finished, then I'll use that and cite the 
> /car /package instead.
> 
> Thanks again for your help.
> 
> Best,
> 
> Juho
> 
> ti 1. maalisk. 2022 klo 23.54 John Fox (jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>) kirjoitti:
> 
>     Dear Juho,
> 
>     On 2022-03-01 3:13 p.m., Juho Kristian Ruohonen wrote:
>      > Dear John,
>      >
>      > Yes, my function uses your code for the math. I was just hoping to
>      > verify that it is handling multicategory factors correctly (your
>      > examples didn't involve any).
> 
>     That's not really my point. Your code sets up computations for the
>     various terms in the model automatically, while the function I sent
>     requires that you locate the rows/columns for the intercepts and each
>     focal term manually. If you haven't already done so, you could check
>     that your function is identifying the correct columns and getting the
>     corresponding GVIFs.
> 
>      >
>      > I guess interactions aren't that important after all, given that the
>      > chief concern is usually collinearity among main effects.
> 
>     I wouldn't say that, but it's not clear what collinearity means in
>     models with interactions, and if you compute VIFs or GVIFs for "main
>     effects" in models with interactions, you'll probably get nonsense.
> 
>     As I said, I think that this might be a solvable problem, but one that
>     requires thought about what needs to remain invariant.
> 
>     I think that we've probably come to end for now.
> 
>     John
> 
>      >
>      > Many thanks for all your help.
>      >
>      > Best,
>      >
>      > Juho
>      >
>      > ti 1. maalisk. 2022 klo 18.01 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
>      >
>      >? ? ?Dear Juho,
>      >
>      >? ? ?On 2022-03-01 8:24 a.m., Juho Kristian Ruohonen wrote:
>      >? ? ? > Dear John (Fox, as well as other list members),
>      >? ? ? >
>      >? ? ? > I've now written a simple function to try and calculate
>     GVIFS for
>      >? ? ?all
>      >? ? ? > predictors in a nnet::multinom() object based on John's
>     example
>      >? ? ?code. If
>      >? ? ? > its results are correct (see below), I will proceed to write a
>      >? ? ?version
>      >? ? ? > that also works with mixed-effects multinomial models fit by
>      >? ? ? > brms::brm(). Here's the code:
>      >? ? ? >
>      >? ? ? >? ? ?gvif.multinom <- function(model){
>      >? ? ? >? ? ? ? (classes <- model$lev)
>      >? ? ? >? ? ? ? (V.all <- vcov(model))
>      >? ? ? >? ? ? ? (V.noIntercepts <- V.all[!grepl("\\(Intercept\\)$",
>      >? ? ? >? ? ?rownames(V.all), perl = T),
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?!grepl("\\(Intercept\\)$",
>      >? ? ? >? ? ?colnames(V.all), perl = T)])
>      >? ? ? >? ? ? ? (R <- cov2cor(V.noIntercepts))
>      >? ? ? >? ? ? ? (terms <- attr(model$terms, "term.labels"))
>      >? ? ? >? ? ? ? (gvif <- numeric(length = length(terms)))
>      >? ? ? >? ? ? ? (names(gvif) <- terms)
>      >? ? ? >? ? ? ? (SE.multiplier <- numeric(length = length(terms)))
>      >? ? ? >? ? ? ? (names(SE.multiplier) <- terms)
>      >? ? ? >? ? ? ? #The line below tries to capture all factor levels
>     into a
>      >? ? ?regex
>      >? ? ? >? ? ?for coef name matching.
>      >? ? ? >? ? ? ? (LevelsRegex <- paste0("(",
>     paste(unlist(model$xlevels),
>      >? ? ?collapse
>      >? ? ? >? ? ?= "|"),")?"))
>      >? ? ? >
>      >? ? ? >? ? ? ? for(i in terms){
>      >? ? ? >? ? ? ? ? #The regex stuff below tries to ensure all
>     interaction
>      >? ? ? >? ? ?coefficients are matched, including those involving
>     factors.
>      >? ? ? >? ? ? ? ? if(grepl(":", i)){
>      >? ? ? >? ? ? ? ? ? (termname <- gsub(":", paste0(LevelsRegex, ":"), i,
>      >? ? ?perl = T))
>      >? ? ? >? ? ? ? ? }else{termname <- i}
>      >? ? ? >? ? ? ? ? (RegexToMatch <- paste0("^(",
>      >? ? ?paste(classes[2:length(classes)],
>      >? ? ? >? ? ?collapse = "|") ,"):", termname, LevelsRegex, "$"))
>      >? ? ? >
>      >? ? ? >? ? ? ? ? #Now the actual calculation:
>      >? ? ? >? ? ? ? ? (indices <- grep(RegexToMatch, rownames(R), perl
>     = T))
>      >? ? ? >? ? ? ? ? (gvif[i] <- det(R[indices, indices]) *
>     det(R[-indices,
>      >? ? ? >? ? ?-indices]) / det(R))
>      >? ? ? >? ? ? ? ? (SE.multiplier[i] <- gvif[i]^(1/(2*length(indices))))
>      >? ? ? >? ? ? ? }
>      >? ? ? >? ? ? ? #Put the results together and order them by degree
>     of SE
>      >? ? ?inflation:
>      >? ? ? >? ? ? ? (result <- cbind(GVIF = gvif, `GVIF^(1/(2df))` =
>      >? ? ?SE.multiplier))
>      >? ? ? >? ? ? ? return(result[order(result[,"GVIF^(1/(2df))"],
>     decreasing
>      >? ? ?= T),])}
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > The results seem correct to me when applied to John's example
>      >? ? ?model fit
>      >? ? ? > to the BEPS data. However, that dataset contains no multi-df
>      >? ? ?factors, of
>      >? ? ? > which my own models have many. Below is a maximally simple
>      >? ? ?example with
>      >? ? ? > one multi-df factor (/region/):
>      >? ? ? >
>      >? ? ? >? ? ?mod1 <- multinom(partic ~., data = carData::Womenlf)
>      >? ? ? >? ? ?gvif.multinom(mod1)
>      >? ? ? >
>      >? ? ? >? ? ?GVIF GVIF^(1/(2df))
>      >? ? ? >? ? ?children 1.298794 ? ? ? 1.067542
>      >? ? ? >? ? ?hincome ?1.184215 ? ? ? 1.043176
>      >? ? ? >? ? ?region ? 1.381480 ? ? ? 1.020403
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > These results look plausible to me. Finally, below is an
>     example
>      >? ? ? > involving both a multi-df factor and an interaction:
>      >? ? ? >
>      >? ? ? >? ? ?mod2 <- update(mod1, ~. +children:region)
>      >? ? ? >? ? ?gvif.multinom(mod2)
>      >? ? ? >
>      >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? GVIF GVIF^(1/(2df))
>      >? ? ? >? ? ?children:region 4.965762e+16 ? ? ?11.053482
>      >? ? ? >? ? ?region ? ? ? ? ?1.420418e+16 ? ? ?10.221768
>      >? ? ? >? ? ?children ? ? ? ?1.471412e+03 ? ? ? 6.193463
>      >? ? ? >? ? ?hincome ? ? ? ? 6.462161e+00 ? ? ? 1.594390
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > These results look a bit more dubious. To be sure, it is to be
>      >? ? ?expected
>      >? ? ? > that interaction terms will introduce a lot of
>     collinearity. But an
>      >? ? ? > 11-fold increase in SE? I hope someone can tell me whether
>     this is
>      >? ? ? > correct or not!
>      >
>      >? ? ?You don't need someone else to check your work because you
>     could just
>      >? ? ?apply the simple function that I sent you yesterday, which,
>     though not
>      >? ? ?automatic, computes the GVIFs in a transparent manner.
>      >
>      >? ? ?A brief comment on GVIFs for models with interactions (this
>     isn't the
>      >? ? ?place to discuss the question in detail): The Fox and Monette
>     JASA
>      >? ? ?paper
>      >? ? ?addresses the question briefly in the context of a two-way
>     ANOVA, but I
>      >? ? ?don't think that the approach suggested there is easily
>     generalized.
>      >
>      >? ? ?The following simple approach pays attention to what's
>     invariant under
>      >? ? ?different parametrizations of the RHS side of the model:
>     Simultaneously
>      >? ? ?check the collinearity of all of the coefficients of an
>     interaction
>      >? ? ?together with the main effects and, potentially, lower-order
>      >? ? ?interactions that are marginal to it. So, e.g., in the model
>     y ~ a +
>      >? ? ?b +
>      >? ? ?a:b + c, you'd check all of the coefficients for a, b, and
>     a:b together.
>      >
>      >? ? ?Alternatively, one could focus in turn on each explanatory
>     variable and
>      >? ? ?check the collinearity of all coefficients to which it is
>     marginal. So
>      >? ? ?in y ~ a + b + c + a:b + a:c + d, when you focus on a, you'd
>     look at
>      >? ? ?all
>      >? ? ?of the coefficients for a, b, c, a:b, and a:c.
>      >
>      >? ? ?John
>      >
>      >? ? ? >
>      >? ? ? > Best,
>      >? ? ? >
>      >? ? ? > Juho
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > ti 1. maalisk. 2022 klo 0.05 John Fox (jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
>      >? ? ? >
>      >? ? ? >? ? ?Dear Juha,
>      >? ? ? >
>      >? ? ? >? ? ?On 2022-02-28 5:00 p.m., Juho Kristian Ruohonen wrote:
>      >? ? ? >? ? ? > Apologies for my misreading, John, and many thanks
>     for showing
>      >? ? ? >? ? ?how the
>      >? ? ? >? ? ? > calculation is done for a single term.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Do you think *vif()* might be updated in the near
>     future
>      >? ? ?with the
>      >? ? ? >? ? ? > capability of auto-detecting a multinomial model
>     and returning
>      >? ? ? >? ? ? > mathematically correct GVIF statistics?
>      >? ? ? >
>      >? ? ? >? ? ?The thought crossed my mind, but I'd want to do it in a
>      >? ? ?general way,
>      >? ? ? >? ? ?not
>      >? ? ? >? ? ?just for the multinom() function, and in a way that avoids
>      >? ? ?incorrect
>      >? ? ? >? ? ?results such as those currently produced for "multinom"
>      >? ? ?models, albeit
>      >? ? ? >? ? ?with a warning. I can't guarantee whether or when I'll be
>      >? ? ?able to do
>      >? ? ? >? ? ?that.
>      >? ? ? >
>      >? ? ? >? ? ?John
>      >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > If not, I'll proceed to writing my own function
>     based on your
>      >? ? ? >? ? ?example.
>      >? ? ? >? ? ? > However, /car/ is such an excellent and widely used
>      >? ? ?package that the
>      >? ? ? >? ? ? > greatest benefit to mankind would probably accrue
>     if /car /was
>      >? ? ? >? ? ?upgraded
>      >? ? ? >? ? ? > with this feature sooner rather than later.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Best,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Juho
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > ma 28. helmik. 2022 klo 17.08 John Fox
>     (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
>      >? ? ? >? ? ? > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>) kirjoitti:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Dear Juho,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen
>     wrote:
>      >? ? ? >? ? ? >? ? ? > Dear Professor Fox and other list members,
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > Profuse thanks for doing that detective work for
>      >? ? ?me! I myself
>      >? ? ? >? ? ? >? ? ?thought
>      >? ? ? >? ? ? >? ? ? > the inflation factors reported by
>      >? ? ?check_collinearity() were
>      >? ? ? >? ? ? >? ? ?suspiciously
>      >? ? ? >? ? ? >? ? ? > high, but unlike you I lacked the expertise
>     to identify
>      >? ? ? >? ? ?what was
>      >? ? ? >? ? ? >? ? ?going on.
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > As for your suggested approach, have I
>     understood this
>      >? ? ? >? ? ?correctly:
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > Since there doesn't yet exist an R function
>     that will
>      >? ? ? >? ? ?calculate the
>      >? ? ? >? ? ? >? ? ? > (G)VIFS of multinomial models correctly, my best
>      >? ? ?bet for
>      >? ? ? >? ? ?now is
>      >? ? ? >? ? ? >? ? ?just to
>      >? ? ? >? ? ? >? ? ? > ignore the fact that such models partition
>     the data
>      >? ? ?into C-1
>      >? ? ? >? ? ? >? ? ?subsets,
>      >? ? ? >? ? ? >? ? ? > and to calculate approximate GVIFs from the
>     entire
>      >? ? ?dataset at
>      >? ? ? >? ? ? >? ? ?once as if
>      >? ? ? >? ? ? >? ? ? > the response were continuous? And a simple
>     way to
>      >? ? ?do this
>      >? ? ? >? ? ?is to
>      >? ? ? >? ? ? >? ? ? > construct a fake continuous response, call
>      >? ? ? >? ? ?*lm(fakeresponse ~.)*,
>      >? ? ? >? ? ? >? ? ?and
>      >? ? ? >? ? ? >? ? ? > apply *car::vif()* on the result?
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?No, you misunderstand my suggestion, which
>     perhaps isn't
>      >? ? ? >? ? ?surprising
>      >? ? ? >? ? ? >? ? ?given the length of my message. What you
>     propose is what I
>      >? ? ? >? ? ?suggested as
>      >? ? ? >? ? ? >? ? ?a rough approximation *before* I confirmed that my
>      >? ? ?guess of the
>      >? ? ? >? ? ? >? ? ?solution
>      >? ? ? >? ? ? >? ? ?was correct.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?The R code that I sent yesterday showed how to
>     compute the
>      >? ? ? >? ? ?GVIF for a
>      >? ? ? >? ? ? >? ? ?multinomial regression model, and I suggested
>     that you
>      >? ? ?write
>      >? ? ? >? ? ?either a
>      >? ? ? >? ? ? >? ? ?script or a simple function to do that. Here's
>     a function
>      >? ? ? >? ? ?that will
>      >? ? ? >? ? ? >? ? ?work
>      >? ? ? >? ? ? >? ? ?for a model object that responds to vcov():
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?GVIF <- function(model, intercepts, term){
>      >? ? ? >? ? ? >? ? ? ? ?# model: regression model object
>      >? ? ? >? ? ? >? ? ? ? ?# intercepts: row/column positions of
>     intercepts
>      >? ? ?in the
>      >? ? ? >? ? ?coefficient
>      >? ? ? >? ? ? >? ? ?covariance matrix
>      >? ? ? >? ? ? >? ? ? ? ?# term: row/column positions of the
>     coefficients
>      >? ? ?for the
>      >? ? ? >? ? ?focal term
>      >? ? ? >? ? ? >? ? ? ? ?V <- vcov(model)
>      >? ? ? >? ? ? >? ? ? ? ?term <- colnames(V)[term]
>      >? ? ? >? ? ? >? ? ? ? ?V <- V[-intercepts, -intercepts]
>      >? ? ? >? ? ? >? ? ? ? ?V <- cov2cor(V)
>      >? ? ? >? ? ? >? ? ? ? ?term <- which(colnames(V) %in% term)
>      >? ? ? >? ? ? >? ? ? ? ?gvif <- det(V[term, term])*det(V[-term,
>     -term])/det(V)
>      >? ? ? >? ? ? >? ? ? ? ?c(GVIF=gvif,
>      >? ? ?"GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
>      >? ? ? >? ? ? >? ? ?}
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?and here's an application to the multinom()
>     example that I
>      >? ? ? >? ? ?showed you
>      >? ? ? >? ? ? >? ? ?yesterday:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> colnames(vcov(m)) # to get coefficient
>     positions
>      >? ? ? >? ? ? >? ? ? ? [1] "Labour:(Intercept)"
>      >? ? ? ?"Labour:age"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ? [3] "Labour:economic.cond.national"
>      >? ? ? >? ? ? >? ? ?"Labour:economic.cond.household"
>      >? ? ? >? ? ? >? ? ? ? [5] "Labour:Blair"
>      >? ? ? ?"Labour:Hague"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ? [7] "Labour:Kennedy"
>      >? ? ? ?"Labour:Europe"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ? [9] "Labour:political.knowledge"
>      >? ? ? >? ? ? ?"Labour:gendermale"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?[11] "Liberal Democrat:(Intercept)"           
>      ?"Liberal
>      >? ? ? >? ? ?Democrat:age"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?[13] "Liberal Democrat:economic.cond.national" 
>     "Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:economic.cond.household"
>      >? ? ? >? ? ? >? ? ?[15] "Liberal Democrat:Blair"                 
>      ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:Hague"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?[17] "Liberal Democrat:Kennedy"               
>      ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:Europe"
>      >? ? ? >? ? ? >? ? ?[19] "Liberal Democrat:political.knowledge"   
>      ?"Liberal
>      >? ? ? >? ? ? >? ? ?Democrat:gendermale"
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> GVIF(m, intercepts=c(1, 11), term=c(2, 12))
>     # GVIF
>      >? ? ?for age
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ?GVIF GVIF^(1/(2*p))
>      >? ? ? >? ? ? >? ? ? ? ? ? ?1.046232? ? ? ?1.011363
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Finally, here's what you get for a linear model
>     with
>      >? ? ?the same RHS
>      >? ? ? >? ? ? >? ? ?(where
>      >? ? ? >? ? ? >? ? ?the sqrt(VIF) should be a rough approximation to
>      >? ? ?GVIF^(1/4)
>      >? ? ? >? ? ?reported by
>      >? ? ? >? ? ? >? ? ?my GVIF() function):
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?> m.lm <- lm(as.numeric(vote) ~ . - vote1,
>     data=BEPS)
>      >? ? ? >? ? ? >? ? ? ?> sqrt(car::vif(m.lm))
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?age? economic.cond.national
>      >? ? ? >? ? ? >? ? ?economic.cond.household
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Blair
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.006508? ? ? ? ? ? ? ? 1.124132
>      >? ? ? >? ? ? >? ? ?1.075656
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.118441
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Hague? ? ? ? ? ? ? ? ?Kennedy
>      >? ? ? >? ? ? >? ? ?Europe
>      >? ? ? >? ? ? >? ? ? ? ? ?political.knowledge
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.066799? ? ? ? ? ? ? ? 1.015532
>      >? ? ? >? ? ? >? ? ?1.101741
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.028546
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? gender
>      >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? 1.017386
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?John
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > Best,
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > Juho
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > ma 28. helmik. 2022 klo 2.23 John Fox
>      >? ? ?(jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
>      >? ? ? >? ? ? >? ? ?<mailto:jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
>      >? ? ? >? ? ? >? ? ? > <mailto:jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
>      >? ? ? >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>) kirjoitti:
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?Dear Juho,
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?I've now had a chance to think about this
>      >? ? ?problem some
>      >? ? ? >? ? ?more,
>      >? ? ? >? ? ? >? ? ?and I
>      >? ? ? >? ? ? >? ? ? >? ? ?believe that the approach I suggested is
>     correct. I
>      >? ? ? >? ? ?also had an
>      >? ? ? >? ? ? >? ? ? >? ? ?opportunity to talk the problem over a
>     bit with
>      >? ? ?Georges
>      >? ? ? >? ? ? >? ? ?Monette, who
>      >? ? ? >? ? ? >? ? ? >? ? ?coauthored the paper that introduced
>      >? ? ?generalized variance
>      >? ? ? >? ? ? >? ? ?inflation
>      >? ? ? >? ? ? >? ? ? >? ? ?factors (GVIFs). On the other hand, the
>     results
>      >? ? ? >? ? ?produced by
>      >? ? ? >? ? ? >? ? ? >? ? ?performance::check_collinearity() for
>      >? ? ?multinomial logit
>      >? ? ? >? ? ? >? ? ?models don't
>      >? ? ? >? ? ? >? ? ? >? ? ?seem to be correct (see below).
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?Here's an example, using the
>     nnet::multinom()
>      >? ? ?function
>      >? ? ? >? ? ?to fit a
>      >? ? ? >? ? ? >? ? ? >? ? ?multinomial logit model, with alternative
>      >? ? ? >? ? ?parametrizations of the
>      >? ? ? >? ? ? >? ? ? >? ? ?LHS of
>      >? ? ? >? ? ? >? ? ? >? ? ?the model:
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> library(nnet) # for multinom()
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> library(carData) # for BEPS data set
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> # alternative ordering of the
>     response levels:
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> BEPS$vote1 <- factor(BEPS$vote,
>      >? ? ?levels=c("Labour",
>      >? ? ? >? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat", "Conservative"))
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> levels(BEPS$vote)
>      >? ? ? >? ? ? >? ? ? >? ? ?[1] "Conservative"? ? ?"Labour"         
>      ?"Liberal
>      >? ? ? >? ? ?Democrat"
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> levels(BEPS$vote1)
>      >? ? ? >? ? ? >? ? ? >? ? ?[1] "Labour"? ? ? ? ? ?"Liberal Democrat"
>      >? ? ?"Conservative"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> m <- multinom(vote ~ . - vote1,
>     data=BEPS)
>      >? ? ? >? ? ? >? ? ? >? ? ?# weights:? 33 (20 variable)
>      >? ? ? >? ? ? >? ? ? >? ? ?initial? value 1675.383740
>      >? ? ? >? ? ? >? ? ? >? ? ?iter? 10 value 1345.935273
>      >? ? ? >? ? ? >? ? ? >? ? ?iter? 20 value 1150.956807
>      >? ? ? >? ? ? >? ? ? >? ? ?iter? 30 value 1141.921662
>      >? ? ? >? ? ? >? ? ? >? ? ?iter? 30 value 1141.921661
>      >? ? ? >? ? ? >? ? ? >? ? ?iter? 30 value 1141.921661
>      >? ? ? >? ? ? >? ? ? >? ? ?final? value 1141.921661
>      >? ? ? >? ? ? >? ? ? >? ? ?converged
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> m1 <- multinom(vote1 ~ . - vote,
>     data=BEPS)
>      >? ? ? >? ? ? >? ? ? >? ? ?# weights:? 33 (20 variable)
>      >? ? ? >? ? ? >? ? ? >? ? ?initial? value 1675.383740
>      >? ? ? >? ? ? >? ? ? >? ? ?iter? 10 value 1280.439304
>      >? ? ? >? ? ? >? ? ? >? ? ?iter? 20 value 1165.513772
>      >? ? ? >? ? ? >? ? ? >? ? ?final? value 1141.921662
>      >? ? ? >? ? ? >? ? ? >? ? ?converged
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> rbind(coef(m), coef(m1)) # compare
>     coefficients
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? (Intercept)? ? ? ? ? age
>      >? ? ? >? ? ? >? ? ?economic.cond.national
>      >? ? ? >? ? ? >? ? ? >? ? ?economic.cond.household
>      >? ? ? >? ? ? >? ? ? >? ? ?Labour? ? ? ? ? ? ?0.9515214 -0.021913989
>      >? ? ? >? ? ?0.5575707
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? 0.15839096
>      >? ? ? >? ? ? >? ? ? >? ? ?Liberal Democrat? ?1.4119306 -0.016810735
>      >? ? ? >? ? ?0.1810761
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?-0.01196664
>      >? ? ? >? ? ? >? ? ? >? ? ?Liberal Democrat? ?0.4604567? 0.005102666
>      >? ? ? >? ? ? ?-0.3764928
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?-0.17036682
>      >? ? ? >? ? ? >? ? ? >? ? ?Conservative? ? ? -0.9514466? 0.021912305
>      >? ? ? >? ? ? ?-0.5575644
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?-0.15838744
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Blair? ? ? ?Hague
>      >? ? ?Kennedy
>      >? ? ? >? ? ? ? ? Europe
>      >? ? ? >? ? ? >? ? ? >? ? ?political.knowledge
>      >? ? ? >? ? ? >? ? ? >? ? ?Labour? ? ? ? ? ? 0.8371764 -0.90775585 
>     0.2513436
>      >? ? ? >? ? ?-0.22781308
>      >? ? ? >? ? ? >? ? ? >? ? ?-0.5370612
>      >? ? ? >? ? ? >? ? ? >? ? ?Liberal Democrat? 0.2937331 -0.82217625 
>     0.6710567
>      >? ? ? >? ? ?-0.20004624
>      >? ? ? >? ? ? >? ? ? >? ? ?-0.2034605
>      >? ? ? >? ? ? >? ? ? >? ? ?Liberal Democrat -0.5434408? 0.08559455 
>     0.4197027
>      >? ? ? >? ? ?0.02776465
>      >? ? ? >? ? ? >? ? ? >? ? ?0.3336068
>      >? ? ? >? ? ? >? ? ? >? ? ?Conservative? ? ?-0.8371670? 0.90778068
>     -0.2513735
>      >? ? ? >? ? ?0.22781092
>      >? ? ? >? ? ? >? ? ? >? ? ?0.5370545
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gendermale
>      >? ? ? >? ? ? >? ? ? >? ? ?Labour? ? ? ? ? ? 0.13765774
>      >? ? ? >? ? ? >? ? ? >? ? ?Liberal Democrat? 0.12640823
>      >? ? ? >? ? ? >? ? ? >? ? ?Liberal Democrat -0.01125898
>      >? ? ? >? ? ? >? ? ? >? ? ?Conservative? ? ?-0.13764849
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> c(logLik(m), logLik(m1)) # same fit
>     to the data
>      >? ? ? >? ? ? >? ? ? >? ? ?[1] -1141.922 -1141.922
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> # covariance matrices for coefficients:
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> V <- vcov(m)
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> V1 <- vcov(m1)
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> cbind(colnames(V), colnames(V1)) #
>     compare
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ?[,1]
>      >? ? ? ? ?[,2]
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [1,] "Labour:(Intercept)"
>      >? ? ? >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:(Intercept)"
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [2,] "Labour:age"
>      >? ? ? >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:age"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [3,] "Labour:economic.cond.national"
>      >? ? ? >? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:economic.cond.national"
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [4,] "Labour:economic.cond.household"
>      >? ? ? >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:economic.cond.household"
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [5,] "Labour:Blair"
>      >? ? ? >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:Blair"
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [6,] "Labour:Hague"
>      >? ? ? >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:Hague"
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [7,] "Labour:Kennedy"
>      >? ? ? >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:Kennedy"
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [8,] "Labour:Europe"
>      >? ? ? >? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:Europe"
>      >? ? ? >? ? ? >? ? ? >? ? ? ? [9,] "Labour:political.knowledge"
>      >? ? ? >? ? ? ?"Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:political.knowledge"
>      >? ? ? >? ? ? >? ? ? >? ? ?[10,] "Labour:gendermale"
>      >? ? ? ? "Liberal
>      >? ? ? >? ? ? >? ? ? >? ? ?Democrat:gendermale"
>      >? ? ? >? ? ? >? ? ? >? ? ?[11,] "Liberal Democrat:(Intercept)"
>      >? ? ? >? ? ? >? ? ? >? ? ?"Conservative:(Intercept)"
>      >? ? ? >? ? ? >? ? ? >? ? ?[12,] "Liberal Democrat:age"
>      >? ? ? >? ? ? >? ? ? ?"Conservative:age"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?[13,] "Liberal
>     Democrat:economic.cond.national"
>      >? ? ? >? ? ? >? ? ? >? ? ?"Conservative:economic.cond.national"
>      >? ? ? >? ? ? >? ? ? >? ? ?[14,] "Liberal
>     Democrat:economic.cond.household"
>      >? ? ? >? ? ? >? ? ? >? ? ?"Conservative:economic.cond.household"
>      >? ? ? >? ? ? >? ? ? >? ? ?[15,] "Liberal Democrat:Blair"
>      >? ? ? >? ? ? >? ? ? ?"Conservative:Blair"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?[16,] "Liberal Democrat:Hague"
>      >? ? ? >? ? ? >? ? ? ?"Conservative:Hague"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?[17,] "Liberal Democrat:Kennedy"
>      >? ? ? >? ? ? >? ? ? ?"Conservative:Kennedy"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?[18,] "Liberal Democrat:Europe"
>      >? ? ? >? ? ? >? ? ?"Conservative:Europe"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?[19,] "Liberal Democrat:political.knowledge"
>      >? ? ? >? ? ? >? ? ? >? ? ?"Conservative:political.knowledge"
>      >? ? ? >? ? ? >? ? ? >? ? ?[20,] "Liberal Democrat:gendermale"
>      >? ? ? >? ? ? >? ? ? >? ? ?"Conservative:gendermale"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> int <- c(1, 11) # remove intercepts
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> colnames(V)[int]
>      >? ? ? >? ? ? >? ? ? >? ? ?[1] "Labour:(Intercept)"? ? ? ? ? ?"Liberal
>      >? ? ? >? ? ?Democrat:(Intercept)"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> colnames(V1)[int]
>      >? ? ? >? ? ? >? ? ? >? ? ?[1] "Liberal Democrat:(Intercept)"
>      >? ? ? >? ? ?"Conservative:(Intercept)"
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> V <- V[-int, -int]
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> V1 <- V1[-int, -int]
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> age <- c(1, 10) # locate age
>     coefficients
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> colnames(V)[age]
>      >? ? ? >? ? ? >? ? ? >? ? ?[1] "Labour:age"? ? ? ? ? ?"Liberal
>     Democrat:age"
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> colnames(V1)[age]
>      >? ? ? >? ? ? >? ? ? >? ? ?[1] "Liberal Democrat:age"
>     "Conservative:age"
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> V <- cov2cor(V) # compute coefficient
>      >? ? ?correlations
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> V1 <- cov2cor(V1)
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> # compare GVIFs:
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> c(det(V[age, age])*det(V[-age,
>     -age])/det(V),
>      >? ? ? >? ? ? >? ? ? >? ? ?+? ?det(V1[age, age])*det(V1[-age,
>     -age])/det(V1))
>      >? ? ? >? ? ? >? ? ? >? ? ?[1] 1.046232 1.046229
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?For curiosity, I applied car::vif() and
>      >? ? ? >? ? ? >? ? ? >? ? ?performance::check_collinearity() to these
>      >? ? ?models to
>      >? ? ? >? ? ?see what
>      >? ? ? >? ? ? >? ? ?they
>      >? ? ? >? ? ? >? ? ? >? ? ?would
>      >? ? ? >? ? ? >? ? ? >? ? ?do. Both returned the wrong answer. vif()
>      >? ? ?produced a
>      >? ? ? >? ? ?warning, but
>      >? ? ? >? ? ? >? ? ? >? ? ?check_collinearity() didn't:
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> car::vif(m1)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?age 
>     economic.cond.national
>      >? ? ? >? ? ? >? ? ? >? ? ?economic.cond.household
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ?15.461045             
>      ?22.137772
>      >? ? ? >? ? ? >? ? ? >? ? ? ?16.693877
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Blair               
>      ? ?Hague
>      >? ? ? >? ? ? >? ? ? >? ? ? ?Kennedy
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ?14.681562               
>     7.483039
>      >? ? ? >? ? ? >? ? ? >? ? ? ?15.812067
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Europe   
>      ?political.knowledge
>      >? ? ? >? ? ? >? ? ? >? ? ?gender
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? 6.502119               
>     4.219507
>      >? ? ? >? ? ? >? ? ? >? ? ?2.313885
>      >? ? ? >? ? ? >? ? ? >? ? ?Warning message:
>      >? ? ? >? ? ? >? ? ? >? ? ?In vif.default(m1) : No intercept: vifs
>     may not be
>      >? ? ? >? ? ?sensible.
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> performance::check_collinearity(m)
>      >? ? ? >? ? ? >? ? ? >? ? ?# Check for Multicollinearity
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?Low Correlation
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE
>      >? ? ?Tolerance
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? age 1.72       
>      ?1.31
>      >? ? ? ? 0.58
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ?economic.cond.national 1.85       
>      ?1.36
>      >? ? ? ? 0.54
>      >? ? ? >? ? ? >? ? ? >? ? ? ? economic.cond.household 1.86       
>      ?1.37
>      >? ? ? ? 0.54
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Blair 1.63       
>      ?1.28
>      >? ? ? ? 0.61
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Hague 1.94       
>      ?1.39
>      >? ? ? ? 0.52
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Kennedy 1.70       
>      ?1.30
>      >? ? ? ? 0.59
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Europe 2.01       
>      ?1.42
>      >? ? ? ? 0.50
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? political.knowledge 1.94       
>      ?1.39
>      >? ? ? ? 0.52
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gender 1.78       
>      ?1.33
>      >? ? ? ? 0.56
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> performance::check_collinearity(m1)
>      >? ? ? >? ? ? >? ? ? >? ? ?# Check for Multicollinearity
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?Low Correlation
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ?Term? VIF Increased SE
>      >? ? ?Tolerance
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? ? age 1.19       
>      ?1.09
>      >? ? ? ? 0.84
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ?economic.cond.national 1.42       
>      ?1.19
>      >? ? ? ? 0.70
>      >? ? ? >? ? ? >? ? ? >? ? ? ? economic.cond.household 1.32       
>      ?1.15
>      >? ? ? ? 0.76
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Blair 1.50       
>      ?1.22
>      >? ? ? ? 0.67
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ? Hague 1.30       
>      ?1.14
>      >? ? ? ? 0.77
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? Kennedy 1.19       
>      ?1.09
>      >? ? ? ? 0.84
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?Europe 1.34       
>      ?1.16
>      >? ? ? ? 0.75
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? political.knowledge 1.30       
>      ?1.14
>      >? ? ? ? 0.77
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ? ?gender 1.23       
>      ?1.11
>      >? ? ? ? 0.81
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?I looked at the code for vif() and
>      >? ? ?check_collinearity() to
>      >? ? ? >? ? ? >? ? ?see where
>      >? ? ? >? ? ? >? ? ? >? ? ?they went wrong. Both failed to handle
>     the two
>      >? ? ? >? ? ?intercepts in
>      >? ? ? >? ? ? >? ? ?the model
>      >? ? ? >? ? ? >? ? ? >? ? ?correctly -- vif() thought there was no
>      >? ? ?intercept and
>      >? ? ? >? ? ? >? ? ? >? ? ?check_collinearity() just removed the first
>      >? ? ?intercept
>      >? ? ? >? ? ?but not the
>      >? ? ? >? ? ? >? ? ? >? ? ?second.
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?In examining the code for
>     check_collinearity(), I
>      >? ? ? >? ? ?discovered a
>      >? ? ? >? ? ? >? ? ? >? ? ?couple of
>      >? ? ? >? ? ? >? ? ? >? ? ?additional disconcerting facts. First,
>     part of the
>      >? ? ? >? ? ?code seems
>      >? ? ? >? ? ? >? ? ?to be
>      >? ? ? >? ? ? >? ? ? >? ? ?copied from vif.default(). Second, as a
>      >? ? ?consequence,
>      >? ? ? >? ? ? >? ? ? >? ? ?check_collinearity() actually computes
>     GVIFs rather
>      >? ? ? >? ? ?than VIFs
>      >? ? ? >? ? ? >? ? ?(and
>      >? ? ? >? ? ? >? ? ? >? ? ?doesn't reference either the Fox and
>     Monette paper
>      >? ? ? >? ? ? >? ? ?introducing GVIFs or
>      >? ? ? >? ? ? >? ? ? >? ? ?the car package) but doesn't seem to
>     understand
>      >? ? ?that, and,
>      >? ? ? >? ? ? >? ? ?for example,
>      >? ? ? >? ? ? >? ? ? >? ? ?takes the squareroot of the GVIF
>     (reported in the
>      >? ? ? >? ? ?column marked
>      >? ? ? >? ? ? >? ? ? >? ? ?"Increased SE") rather than the 2p root
>     (when there
>      >? ? ? >? ? ?are p > 1
>      >? ? ? >? ? ? >? ? ? >? ? ?coefficients in a term).
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?Here's the relevant code from the two
>     functions
>      >? ? ?(where
>      >? ? ? >? ? ?. . .
>      >? ? ? >? ? ? >? ? ?denotes
>      >? ? ? >? ? ? >? ? ? >? ? ?elided lines) -- the default method for
>     vif() and
>      >? ? ? >? ? ? >? ? ? >? ? ?.check_collinearity(),
>      >? ? ? >? ? ? >? ? ? >? ? ?which is called by
>     check_collinearity.default():
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> car:::vif.default
>      >? ? ? >? ? ? >? ? ? >? ? ?function (mod, ...)
>      >? ? ? >? ? ? >? ? ? >? ? ?{
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?v <- vcov(mod)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?assign <- attr(model.matrix(mod),
>     "assign")
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?if (names(coefficients(mod)[1]) ==
>      >? ? ?"(Intercept)") {
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?v <- v[-1, -1]
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?assign <- assign[-1]
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?else warning("No intercept: vifs
>     may not be
>      >? ? ? >? ? ?sensible.")
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?terms <- labels(terms(mod))
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?n.terms <- length(terms)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?if (n.terms < 2)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?stop("model contains fewer
>     than 2 terms")
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?R <- cov2cor(v)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?detR <- det(R)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?for (term in 1:n.terms) {
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?subs <- which(assign == term)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?result[term, 1] <-
>     det(as.matrix(R[subs,
>      >? ? ? >? ? ?subs])) *
>      >? ? ? >? ? ? >? ? ? >? ? ?det(as.matrix(R[-subs,
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?-subs]))/detR
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?result[term, 2] <- length(subs)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ?}
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? ?> performance:::.check_collinearity
>      >? ? ? >? ? ? >? ? ? >? ? ?function (x, component, verbose = TRUE)
>      >? ? ? >? ? ? >? ? ? >? ? ?{
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?v <- insight::get_varcov(x,
>     component =
>      >? ? ?component,
>      >? ? ? >? ? ? >? ? ?verbose =
>      >? ? ? >? ? ? >? ? ? >? ? ?FALSE)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?assign <- .term_assignments(x,
>     component,
>      >? ? ?verbose =
>      >? ? ? >? ? ? >? ? ?verbose)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?if (insight::has_intercept(x)) {
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?v <- v[-1, -1]
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?assign <- assign[-1]
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?else {
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?if (isTRUE(verbose)) {
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?warning("Model has no
>     intercept. VIFs
>      >? ? ? >? ? ?may not be
>      >? ? ? >? ? ? >? ? ? >? ? ?sensible.",
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?call. = FALSE)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?terms <-
>      >? ? ?labels(stats::terms(f[[component]]))
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?n.terms <- length(terms)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?if (n.terms < 2) {
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?if (isTRUE(verbose)) {
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? ?warning(insight::format_message(sprintf("Not
>      >? ? ? >? ? ? >? ? ?enough model
>      >? ? ? >? ? ? >? ? ? >? ? ?terms in the %s part of the model to
>     check for
>      >? ? ? >? ? ? >? ? ?multicollinearity.",
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?component)), call. =
>     FALSE)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?return(NULL)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?R <- stats::cov2cor(v)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?detR <- det(R)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?for (term in 1:n.terms) {
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ?subs <- which(assign == term)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?result <- c(result,
>      >? ? ? >? ? ?det(as.matrix(R[subs, subs])) *
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ? ? ?det(as.matrix(R[-subs,
>      >? ? ?-subs]))/detR)
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?}
>      >? ? ? >? ? ? >? ? ? >? ? ? ? ? ?. . .
>      >? ? ? >? ? ? >? ? ? >? ? ?}
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?--------- snip -----------
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?So, the upshot of all this is that you
>     should
>      >? ? ?be able
>      >? ? ? >? ? ?to do
>      >? ? ? >? ? ? >? ? ?what you
>      >? ? ? >? ? ? >? ? ? >? ? ?want, but not with either car::vif() or
>      >? ? ? >? ? ? >? ? ? >? ? ?performance::check_collinearity().
>     Instead, either
>      >? ? ? >? ? ?write your own
>      >? ? ? >? ? ? >? ? ? >? ? ?function or do the computations in a script.
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?There's also a lesson here about S3 default
>      >? ? ?methods:
>      >? ? ? >? ? ?The fact
>      >? ? ? >? ? ? >? ? ?that a
>      >? ? ? >? ? ? >? ? ? >? ? ?default method returns a result rather than
>      >? ? ?throwing
>      >? ? ? >? ? ?an error
>      >? ? ? >? ? ? >? ? ?or a
>      >? ? ? >? ? ? >? ? ? >? ? ?warning doesn't mean that the result is the
>      >? ? ?right answer.
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?I hope this helps,
>      >? ? ? >? ? ? >? ? ? >? ? ? ? John
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ?On 2022-02-26 3:45 p.m., Juho Kristian
>     Ruohonen
>      >? ? ?wrote:
>      >? ? ? >? ? ? >? ? ? >? ? ? > Dear John W,
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? > Thank you very much for the tip-off!
>      >? ? ?Apologies for not
>      >? ? ? >? ? ? >? ? ?responding
>      >? ? ? >? ? ? >? ? ? >? ? ?earlier
>      >? ? ? >? ? ? >? ? ? >? ? ? > (gmail apparently decided to direct
>     your email
>      >? ? ? >? ? ?right into the
>      >? ? ? >? ? ? >? ? ? >? ? ?junk folder).
>      >? ? ? >? ? ? >? ? ? >? ? ? > I am very pleased to note that the
>     package you
>      >? ? ? >? ? ?mention does
>      >? ? ? >? ? ? >? ? ? >? ? ?indeed work
>      >? ? ? >? ? ? >? ? ? >? ? ? > with *brms* multinomial models!
>     Thanks again!
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? > Best,
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? > Juho
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? > pe 25. helmik. 2022 klo 19.23 John
>     Willoughby
>      >? ? ? >? ? ? >? ? ? >? ? ?(johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>
>      >? ? ? >? ? ?<mailto:johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com>>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>>
>      >? ? ? >? ? ? >? ? ?<mailto:johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>
>      >? ? ? >? ? ?<mailto:johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
>     <mailto:johnwillec at gmail.com>>
>      >? ? ?<mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
>     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>>>)
>      >? ? ? >? ? ? >? ? ? >? ? ? > kirjoitti:
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? >> Have you tried the check_collinearity()
>      >? ? ?function
>      >? ? ? >? ? ?in the
>      >? ? ? >? ? ? >? ? ?performance
>      >? ? ? >? ? ? >? ? ? >? ? ? >> package? It's supposed to work on brms
>      >? ? ?models, but
>      >? ? ? >? ? ?whether it
>      >? ? ? >? ? ? >? ? ? >? ? ?will work on
>      >? ? ? >? ? ? >? ? ? >? ? ? >> a multinomial model I don't know. 
>     It works
>      >? ? ?well
>      >? ? ? >? ? ?on mixed
>      >? ? ? >? ? ? >? ? ?models
>      >? ? ? >? ? ? >? ? ? >? ? ?generated
>      >? ? ? >? ? ? >? ? ? >? ? ? >> by glmmTMB().
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >? ? ? >> John Willoughby
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >? ? ? >> On Fri, Feb 25, 2022 at 3:01 AM
>      >? ? ? >? ? ? >? ? ? >   
>      ?<r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>
>      >? ? ? >? ? ? >   
>      ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>
>      >? ? ? >? ? ? >   
>      ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >> wrote:
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Send R-sig-mixed-models mailing list
>      >? ? ?submissions to
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> To subscribe or unsubscribe via the
>     World Wide
>      >? ? ? >? ? ?Web, visit
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >     
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> or, via email, send a message with
>     subject or
>      >? ? ? >? ? ?body 'help' to
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>     r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>
>      >? ? ? >? ? ? >   
>      ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>
>      >? ? ? >? ? ? >   
>      ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-request at r-project.org
>     <mailto:r-sig-mixed-models-request at r-project.org>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> You can reach the person managing
>     the list at
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>     r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >   
>      ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models-owner at r-project.org
>     <mailto:r-sig-mixed-models-owner at r-project.org>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> When replying, please edit your Subject
>      >? ? ?line so it is
>      >? ? ? >? ? ? >? ? ?more specific
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> than "Re: Contents of
>     R-sig-mixed-models
>      >? ? ?digest..."
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Today's Topics:
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>? ? ?1. Collinearity diagnostics for
>     (mixed)
>      >? ? ? >? ? ?multinomial
>      >? ? ? >? ? ? >? ? ?models
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>? ? ? ? (Juho Kristian Ruohonen)
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >
>      >     
>      ?----------------------------------------------------------------------
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Message: 1
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Date: Fri, 25 Feb 2022 10:23:25 +0200
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> From: Juho Kristian Ruohonen
>      >? ? ? >? ? ? >? ? ?<juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>>
>      >? ? ? >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>>
>      >? ? ? >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >? ? ? >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>
>      >? ? ?<mailto:juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> To: John Fox <jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ? >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
>      >? ? ? >? ? ? >? ? ?<mailto:jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
>      >? ? ? >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>      >? ? ?<mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Cc:
>     "r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>>"
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>         
>     <r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Subject: [R-sig-ME] Collinearity
>      >? ? ?diagnostics for
>      >? ? ? >? ? ?(mixed)
>      >? ? ? >? ? ? >? ? ? >? ? ?multinomial
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>? ? ? ? ? models
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Message-ID:
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>? ? ? ? ? <
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >
>      >
>     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
>     <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
>      >   
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
>      >? ? ? >
>      >     
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>>
>      >? ? ? >? ? ? >
>      >? ? ? >
>      >     
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >
>      >     
>      ?<mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Content-Type: text/plain;
>     charset="utf-8"
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Dear John (and anyone else qualified to
>      >? ? ?comment),
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> I fit lots of mixed-effects multinomial
>      >? ? ?models in my
>      >? ? ? >? ? ? >? ? ?research,
>      >? ? ? >? ? ? >? ? ? >? ? ?and I
>      >? ? ? >? ? ? >? ? ? >? ? ? >> would
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> like to see some (multi)collinearity
>      >? ? ?diagnostics
>      >? ? ? >? ? ?on the
>      >? ? ? >? ? ? >? ? ?fixed
>      >? ? ? >? ? ? >? ? ? >? ? ?effects, of
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> which there are over 30. My models
>     are fit
>      >? ? ?using the
>      >? ? ? >? ? ? >? ? ?Bayesian
>      >? ? ? >? ? ? >? ? ? >? ? ?*brms*
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> package because I know of no
>     frequentist
>      >? ? ?packages
>      >? ? ? >? ? ?with
>      >? ? ? >? ? ? >? ? ? >? ? ?multinomial GLMM
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> compatibility.
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> With continuous or dichotomous
>     outcomes,
>      >? ? ?my go-to
>      >? ? ? >? ? ? >? ? ?function for
>      >? ? ? >? ? ? >? ? ? >? ? ? >> calculating
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> multicollinearity diagnostics is of
>     course
>      >? ? ? >? ? ?*vif()* from
>      >? ? ? >? ? ? >? ? ?the *car*
>      >? ? ? >? ? ? >? ? ? >? ? ? >> package.
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> As expected, however, this function
>     does not
>      >? ? ? >? ? ?report sensible
>      >? ? ? >? ? ? >? ? ? >? ? ?diagnostics
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> for multinomial models -- not even for
>      >? ? ?standard
>      >? ? ? >? ? ?ones fit
>      >? ? ? >? ? ? >? ? ?by the
>      >? ? ? >? ? ? >? ? ? >? ? ?*nnet*
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> package's *multinom()* function.
>     The reason, I
>      >? ? ? >? ? ?presume, is
>      >? ? ? >? ? ? >? ? ? >? ? ?because a
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> multinomial model is not really one
>     but C-1
>      >? ? ? >? ? ?regression
>      >? ? ? >? ? ? >? ? ?models
>      >? ? ? >? ? ? >? ? ? >? ? ?(where C
>      >? ? ? >? ? ? >? ? ? >? ? ? >> is
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> the number of response categories)
>     and the
>      >? ? ?*vif()*
>      >? ? ? >? ? ? >? ? ?function is not
>      >? ? ? >? ? ? >? ? ? >? ? ? >> designed
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> to deal with this scenario.
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Therefore, in order to obtain
>     meaningful
>      >? ? ?collinearity
>      >? ? ? >? ? ? >? ? ?metrics,
>      >? ? ? >? ? ? >? ? ? >? ? ?my present
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> plan is to write a simple helper
>     function
>      >? ? ?that uses
>      >? ? ? >? ? ? >? ? ?*vif() *to
>      >? ? ? >? ? ? >? ? ? >? ? ?calculate
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> and present (generalized) variance
>     inflation
>      >? ? ? >? ? ?metrics for
>      >? ? ? >? ? ? >? ? ?the C-1
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> sub-datasets to which the C-1 component
>      >? ? ?binomial
>      >? ? ? >? ? ?models
>      >? ? ? >? ? ? >? ? ?of the
>      >? ? ? >? ? ? >? ? ? >? ? ?overall
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> multinomial model are fit. In other
>     words, it
>      >? ? ? >? ? ?will partition
>      >? ? ? >? ? ? >? ? ? >? ? ?the data
>      >? ? ? >? ? ? >? ? ? >? ? ? >> into
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> those C-1 subsets, and then apply
>     *vif()*
>      >? ? ?to as
>      >? ? ? >? ? ?many linear
>      >? ? ? >? ? ? >? ? ? >? ? ?regressions
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> using a made-up continuous response and
>      >? ? ?the fixed
>      >? ? ? >? ? ?effects of
>      >? ? ? >? ? ? >? ? ? >? ? ?interest.
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Does this seem like a sensible
>     approach?
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Best,
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>> Juho
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>? ? ? ? ? [[alternative HTML version
>     deleted]]
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>     _______________________________________________
>      >? ? ? >? ? ? >? ? ? >? ? ? >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >     
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ? >>
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? >? ? ? ?[[alternative HTML version
>     deleted]]
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>     _______________________________________________
>      >? ? ? >? ? ? >? ? ? >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>      >? ? ? >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
>      >? ? ? >? ? ? >? ? ? >? ? ? >
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >     
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
>      >? ? ? >? ? ? >? ? ? >? ? ?--
>      >? ? ? >? ? ? >? ? ? >? ? ?John Fox, Professor Emeritus
>      >? ? ? >? ? ? >? ? ? >? ? ?McMaster University
>      >? ? ? >? ? ? >? ? ? >? ? ?Hamilton, Ontario, Canada
>      >? ? ? >? ? ? >? ? ? >? ? ?web:
>     https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>
>      >? ? ? >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>>
>      >? ? ? >? ? ? >? ? ? >   
>      ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>
>      >? ? ? >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>>>
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?--
>      >? ? ? >? ? ? >? ? ?John Fox, Professor Emeritus
>      >? ? ? >? ? ? >? ? ?McMaster University
>      >? ? ? >? ? ? >? ? ?Hamilton, Ontario, Canada
>      >? ? ? >? ? ? >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>
>      >? ? ? >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>>
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ?--
>      >? ? ? >? ? ?John Fox, Professor Emeritus
>      >? ? ? >? ? ?McMaster University
>      >? ? ? >? ? ?Hamilton, Ontario, Canada
>      >? ? ? >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >? ? ? >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>>
>      >? ? ? >
>      >   
>      ?------------------------------------------------------------------------
>      >? ? ?--
>      >? ? ?John Fox, Professor Emeritus
>      >? ? ?McMaster University
>      >? ? ?Hamilton, Ontario, Canada
>      >? ? ?web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>      >? ? ?<https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>>
>      >
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
> 
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Wed Mar  2 20:02:48 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Wed, 2 Mar 2022 21:02:48 +0200
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <d8c397b8-fbec-6c39-fdf5-5047daf6f219@mcmaster.ca>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <CAKk2L3LEaRHPQDNx49twbQaM4t5=FGJArkz1kCRzBkiAP87kQQ@mail.gmail.com>
 <24314_1645908336_21QKjZ8b017357_CAG_dBVfdOZmbLRsWOQ5f28Y32ZMtDsOVE2-6FZmUaQ0H8f0+EQ@mail.gmail.com>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
 <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
 <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>
 <0f03187e-d848-ea43-e370-ead2d403b530@mcmaster.ca>
 <CAG_dBVfv2-8Z0VRvcK4QUP97oh5jOhPd2d=LUj0N_6Ec+appMw@mail.gmail.com>
 <f80557f3-35c7-7b22-ae9c-2f14ff0d7ac0@mcmaster.ca>
 <CAG_dBVe7f5aEB_hA5t-j2u9ZJw-bDQPOchxc3-QTX3VejqXQSQ@mail.gmail.com>
 <d8c397b8-fbec-6c39-fdf5-5047daf6f219@mcmaster.ca>
Message-ID: <CAG_dBVcoEz_GnDSDjfsHgTmUja2yD+ntNPQEo32TCzqbyXLdyw@mail.gmail.com>

Awesome, thanks!
Best, J


ke 2. maalisk. 2022 klo 16.35 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juho,
>
> On 2022-03-02 6:23 a.m., Juho Kristian Ruohonen wrote:
> > One last comment, John: Sorry if I seemed to be implying that you (or
> > anyone else) should debug my code for me. That wasn't the idea. I do
> > believe that the function locates the intended rows/columns
> > successfully. I just wasn't entirely positive what those intended
> > rows/columns should be when dealing with a multicategory factor.
> > Presently, it locates every row/column involving the multicategory
> > factor in question, so the number of rows/columns identified is the
> > number of factor levels minus one, times the number of response
> > categories minus one. I hope that's correct.
>
> OK, that's a fair remark. Yes, what you describe is correct.
>
> You can also reassure yourself that your function is working properly by:
>
> (1) If you haven't already done so, show that you get the same GVIFs
> from your function as from the one I sent you used directly.
>
> (2) Vary the baseline level of the response variable and confirm that
> you get the same GVIFs.
>
> (3) Vary the basis for the regressor subspace for a factor, e.g., either
> by using contr.sum() in place of the default contr.treatment() or by
> changing the baseline level of the factor for contr.treatment(), and
> again confirm that the GVIFs are unchanged.
>
> Best,
>   John
>
> >
> > My current plan is to present the output of the new function in my
> > thesis and credit you for the math. But if *vif()* gets a relevant
> > update before my project is finished, then I'll use that and cite the
> > /car /package instead.
> >
> > Thanks again for your help.
> >
> > Best,
> >
> > Juho
> >
> > ti 1. maalisk. 2022 klo 23.54 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Juho,
> >
> >     On 2022-03-01 3:13 p.m., Juho Kristian Ruohonen wrote:
> >      > Dear John,
> >      >
> >      > Yes, my function uses your code for the math. I was just hoping to
> >      > verify that it is handling multicategory factors correctly (your
> >      > examples didn't involve any).
> >
> >     That's not really my point. Your code sets up computations for the
> >     various terms in the model automatically, while the function I sent
> >     requires that you locate the rows/columns for the intercepts and each
> >     focal term manually. If you haven't already done so, you could check
> >     that your function is identifying the correct columns and getting the
> >     corresponding GVIFs.
> >
> >      >
> >      > I guess interactions aren't that important after all, given that
> the
> >      > chief concern is usually collinearity among main effects.
> >
> >     I wouldn't say that, but it's not clear what collinearity means in
> >     models with interactions, and if you compute VIFs or GVIFs for "main
> >     effects" in models with interactions, you'll probably get nonsense.
> >
> >     As I said, I think that this might be a solvable problem, but one
> that
> >     requires thought about what needs to remain invariant.
> >
> >     I think that we've probably come to end for now.
> >
> >     John
> >
> >      >
> >      > Many thanks for all your help.
> >      >
> >      > Best,
> >      >
> >      > Juho
> >      >
> >      > ti 1. maalisk. 2022 klo 18.01 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>) kirjoitti:
> >      >
> >      >     Dear Juho,
> >      >
> >      >     On 2022-03-01 8:24 a.m., Juho Kristian Ruohonen wrote:
> >      >      > Dear John (Fox, as well as other list members),
> >      >      >
> >      >      > I've now written a simple function to try and calculate
> >     GVIFS for
> >      >     all
> >      >      > predictors in a nnet::multinom() object based on John's
> >     example
> >      >     code. If
> >      >      > its results are correct (see below), I will proceed to
> write a
> >      >     version
> >      >      > that also works with mixed-effects multinomial models fit
> by
> >      >      > brms::brm(). Here's the code:
> >      >      >
> >      >      >     gvif.multinom <- function(model){
> >      >      >        (classes <- model$lev)
> >      >      >        (V.all <- vcov(model))
> >      >      >        (V.noIntercepts <- V.all[!grepl("\\(Intercept\\)$",
> >      >      >     rownames(V.all), perl = T),
> >      >      >                                 !grepl("\\(Intercept\\)$",
> >      >      >     colnames(V.all), perl = T)])
> >      >      >        (R <- cov2cor(V.noIntercepts))
> >      >      >        (terms <- attr(model$terms, "term.labels"))
> >      >      >        (gvif <- numeric(length = length(terms)))
> >      >      >        (names(gvif) <- terms)
> >      >      >        (SE.multiplier <- numeric(length = length(terms)))
> >      >      >        (names(SE.multiplier) <- terms)
> >      >      >        #The line below tries to capture all factor levels
> >     into a
> >      >     regex
> >      >      >     for coef name matching.
> >      >      >        (LevelsRegex <- paste0("(",
> >     paste(unlist(model$xlevels),
> >      >     collapse
> >      >      >     = "|"),")?"))
> >      >      >
> >      >      >        for(i in terms){
> >      >      >          #The regex stuff below tries to ensure all
> >     interaction
> >      >      >     coefficients are matched, including those involving
> >     factors.
> >      >      >          if(grepl(":", i)){
> >      >      >            (termname <- gsub(":", paste0(LevelsRegex,
> ":"), i,
> >      >     perl = T))
> >      >      >          }else{termname <- i}
> >      >      >          (RegexToMatch <- paste0("^(",
> >      >     paste(classes[2:length(classes)],
> >      >      >     collapse = "|") ,"):", termname, LevelsRegex, "$"))
> >      >      >
> >      >      >          #Now the actual calculation:
> >      >      >          (indices <- grep(RegexToMatch, rownames(R), perl
> >     = T))
> >      >      >          (gvif[i] <- det(R[indices, indices]) *
> >     det(R[-indices,
> >      >      >     -indices]) / det(R))
> >      >      >          (SE.multiplier[i] <-
> gvif[i]^(1/(2*length(indices))))
> >      >      >        }
> >      >      >        #Put the results together and order them by degree
> >     of SE
> >      >     inflation:
> >      >      >        (result <- cbind(GVIF = gvif, `GVIF^(1/(2df))` =
> >      >     SE.multiplier))
> >      >      >        return(result[order(result[,"GVIF^(1/(2df))"],
> >     decreasing
> >      >     = T),])}
> >      >      >
> >      >      >
> >      >      > The results seem correct to me when applied to John's
> example
> >      >     model fit
> >      >      > to the BEPS data. However, that dataset contains no
> multi-df
> >      >     factors, of
> >      >      > which my own models have many. Below is a maximally simple
> >      >     example with
> >      >      > one multi-df factor (/region/):
> >      >      >
> >      >      >     mod1 <- multinom(partic ~., data = carData::Womenlf)
> >      >      >     gvif.multinom(mod1)
> >      >      >
> >      >      >     GVIF GVIF^(1/(2df))
> >      >      >     children 1.298794       1.067542
> >      >      >     hincome  1.184215       1.043176
> >      >      >     region   1.381480       1.020403
> >      >      >
> >      >      >
> >      >      > These results look plausible to me. Finally, below is an
> >     example
> >      >      > involving both a multi-df factor and an interaction:
> >      >      >
> >      >      >     mod2 <- update(mod1, ~. +children:region)
> >      >      >     gvif.multinom(mod2)
> >      >      >
> >      >      >                              GVIF GVIF^(1/(2df))
> >      >      >     children:region 4.965762e+16      11.053482
> >      >      >     region          1.420418e+16      10.221768
> >      >      >     children        1.471412e+03       6.193463
> >      >      >     hincome         6.462161e+00       1.594390
> >      >      >
> >      >      >
> >      >      > These results look a bit more dubious. To be sure, it is
> to be
> >      >     expected
> >      >      > that interaction terms will introduce a lot of
> >     collinearity. But an
> >      >      > 11-fold increase in SE? I hope someone can tell me whether
> >     this is
> >      >      > correct or not!
> >      >
> >      >     You don't need someone else to check your work because you
> >     could just
> >      >     apply the simple function that I sent you yesterday, which,
> >     though not
> >      >     automatic, computes the GVIFs in a transparent manner.
> >      >
> >      >     A brief comment on GVIFs for models with interactions (this
> >     isn't the
> >      >     place to discuss the question in detail): The Fox and Monette
> >     JASA
> >      >     paper
> >      >     addresses the question briefly in the context of a two-way
> >     ANOVA, but I
> >      >     don't think that the approach suggested there is easily
> >     generalized.
> >      >
> >      >     The following simple approach pays attention to what's
> >     invariant under
> >      >     different parametrizations of the RHS side of the model:
> >     Simultaneously
> >      >     check the collinearity of all of the coefficients of an
> >     interaction
> >      >     together with the main effects and, potentially, lower-order
> >      >     interactions that are marginal to it. So, e.g., in the model
> >     y ~ a +
> >      >     b +
> >      >     a:b + c, you'd check all of the coefficients for a, b, and
> >     a:b together.
> >      >
> >      >     Alternatively, one could focus in turn on each explanatory
> >     variable and
> >      >     check the collinearity of all coefficients to which it is
> >     marginal. So
> >      >     in y ~ a + b + c + a:b + a:c + d, when you focus on a, you'd
> >     look at
> >      >     all
> >      >     of the coefficients for a, b, c, a:b, and a:c.
> >      >
> >      >     John
> >      >
> >      >      >
> >      >      > Best,
> >      >      >
> >      >      > Juho
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      >
> >      >      > ti 1. maalisk. 2022 klo 0.05 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
> >      >      >
> >      >      >     Dear Juha,
> >      >      >
> >      >      >     On 2022-02-28 5:00 p.m., Juho Kristian Ruohonen wrote:
> >      >      >      > Apologies for my misreading, John, and many thanks
> >     for showing
> >      >      >     how the
> >      >      >      > calculation is done for a single term.
> >      >      >      >
> >      >      >      > Do you think *vif()* might be updated in the near
> >     future
> >      >     with the
> >      >      >      > capability of auto-detecting a multinomial model
> >     and returning
> >      >      >      > mathematically correct GVIF statistics?
> >      >      >
> >      >      >     The thought crossed my mind, but I'd want to do it in a
> >      >     general way,
> >      >      >     not
> >      >      >     just for the multinom() function, and in a way that
> avoids
> >      >     incorrect
> >      >      >     results such as those currently produced for "multinom"
> >      >     models, albeit
> >      >      >     with a warning. I can't guarantee whether or when I'll
> be
> >      >     able to do
> >      >      >     that.
> >      >      >
> >      >      >     John
> >      >      >
> >      >      >      >
> >      >      >      > If not, I'll proceed to writing my own function
> >     based on your
> >      >      >     example.
> >      >      >      > However, /car/ is such an excellent and widely used
> >      >     package that the
> >      >      >      > greatest benefit to mankind would probably accrue
> >     if /car /was
> >      >      >     upgraded
> >      >      >      > with this feature sooner rather than later.
> >      >      >      >
> >      >      >      > Best,
> >      >      >      >
> >      >      >      > Juho
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      >
> >      >      >      > ma 28. helmik. 2022 klo 17.08 John Fox
> >     (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >      >      > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>) kirjoitti:
> >      >      >      >
> >      >      >      >     Dear Juho,
> >      >      >      >
> >      >      >      >     On 2022-02-28 2:06 a.m., Juho Kristian Ruohonen
> >     wrote:
> >      >      >      >      > Dear Professor Fox and other list members,
> >      >      >      >      >
> >      >      >      >      > Profuse thanks for doing that detective work
> for
> >      >     me! I myself
> >      >      >      >     thought
> >      >      >      >      > the inflation factors reported by
> >      >     check_collinearity() were
> >      >      >      >     suspiciously
> >      >      >      >      > high, but unlike you I lacked the expertise
> >     to identify
> >      >      >     what was
> >      >      >      >     going on.
> >      >      >      >      >
> >      >      >      >      > As for your suggested approach, have I
> >     understood this
> >      >      >     correctly:
> >      >      >      >      >
> >      >      >      >      > Since there doesn't yet exist an R function
> >     that will
> >      >      >     calculate the
> >      >      >      >      > (G)VIFS of multinomial models correctly, my
> best
> >      >     bet for
> >      >      >     now is
> >      >      >      >     just to
> >      >      >      >      > ignore the fact that such models partition
> >     the data
> >      >     into C-1
> >      >      >      >     subsets,
> >      >      >      >      > and to calculate approximate GVIFs from the
> >     entire
> >      >     dataset at
> >      >      >      >     once as if
> >      >      >      >      > the response were continuous? And a simple
> >     way to
> >      >     do this
> >      >      >     is to
> >      >      >      >      > construct a fake continuous response, call
> >      >      >     *lm(fakeresponse ~.)*,
> >      >      >      >     and
> >      >      >      >      > apply *car::vif()* on the result?
> >      >      >      >
> >      >      >      >     No, you misunderstand my suggestion, which
> >     perhaps isn't
> >      >      >     surprising
> >      >      >      >     given the length of my message. What you
> >     propose is what I
> >      >      >     suggested as
> >      >      >      >     a rough approximation *before* I confirmed that
> my
> >      >     guess of the
> >      >      >      >     solution
> >      >      >      >     was correct.
> >      >      >      >
> >      >      >      >     The R code that I sent yesterday showed how to
> >     compute the
> >      >      >     GVIF for a
> >      >      >      >     multinomial regression model, and I suggested
> >     that you
> >      >     write
> >      >      >     either a
> >      >      >      >     script or a simple function to do that. Here's
> >     a function
> >      >      >     that will
> >      >      >      >     work
> >      >      >      >     for a model object that responds to vcov():
> >      >      >      >
> >      >      >      >     GVIF <- function(model, intercepts, term){
> >      >      >      >         # model: regression model object
> >      >      >      >         # intercepts: row/column positions of
> >     intercepts
> >      >     in the
> >      >      >     coefficient
> >      >      >      >     covariance matrix
> >      >      >      >         # term: row/column positions of the
> >     coefficients
> >      >     for the
> >      >      >     focal term
> >      >      >      >         V <- vcov(model)
> >      >      >      >         term <- colnames(V)[term]
> >      >      >      >         V <- V[-intercepts, -intercepts]
> >      >      >      >         V <- cov2cor(V)
> >      >      >      >         term <- which(colnames(V) %in% term)
> >      >      >      >         gvif <- det(V[term, term])*det(V[-term,
> >     -term])/det(V)
> >      >      >      >         c(GVIF=gvif,
> >      >     "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
> >      >      >      >     }
> >      >      >      >
> >      >      >      >     and here's an application to the multinom()
> >     example that I
> >      >      >     showed you
> >      >      >      >     yesterday:
> >      >      >      >
> >      >      >      >       > colnames(vcov(m)) # to get coefficient
> >     positions
> >      >      >      >        [1] "Labour:(Intercept)"
> >      >       "Labour:age"
> >      >      >      >
> >      >      >      >        [3] "Labour:economic.cond.national"
> >      >      >      >     "Labour:economic.cond.household"
> >      >      >      >        [5] "Labour:Blair"
> >      >       "Labour:Hague"
> >      >      >      >
> >      >      >      >        [7] "Labour:Kennedy"
> >      >       "Labour:Europe"
> >      >      >      >
> >      >      >      >        [9] "Labour:political.knowledge"
> >      >      >       "Labour:gendermale"
> >      >      >      >
> >      >      >      >     [11] "Liberal Democrat:(Intercept)"
> >       "Liberal
> >      >      >     Democrat:age"
> >      >      >      >
> >      >      >      >     [13] "Liberal Democrat:economic.cond.national"
> >     "Liberal
> >      >      >      >     Democrat:economic.cond.household"
> >      >      >      >     [15] "Liberal Democrat:Blair"
> >       "Liberal
> >      >      >      >     Democrat:Hague"
> >      >      >      >
> >      >      >      >     [17] "Liberal Democrat:Kennedy"
> >       "Liberal
> >      >      >      >     Democrat:Europe"
> >      >      >      >     [19] "Liberal Democrat:political.knowledge"
> >       "Liberal
> >      >      >      >     Democrat:gendermale"
> >      >      >      >
> >      >      >      >       > GVIF(m, intercepts=c(1, 11), term=c(2, 12))
> >     # GVIF
> >      >     for age
> >      >      >      >                 GVIF GVIF^(1/(2*p))
> >      >      >      >             1.046232       1.011363
> >      >      >      >
> >      >      >      >
> >      >      >      >     Finally, here's what you get for a linear model
> >     with
> >      >     the same RHS
> >      >      >      >     (where
> >      >      >      >     the sqrt(VIF) should be a rough approximation to
> >      >     GVIF^(1/4)
> >      >      >     reported by
> >      >      >      >     my GVIF() function):
> >      >      >      >
> >      >      >      >       > m.lm <- lm(as.numeric(vote) ~ . - vote1,
> >     data=BEPS)
> >      >      >      >       > sqrt(car::vif(m.lm))
> >      >      >      >                           age
> economic.cond.national
> >      >      >      >     economic.cond.household
> >      >      >      >                         Blair
> >      >      >      >                      1.006508
> 1.124132
> >      >      >      >     1.075656
> >      >      >      >                      1.118441
> >      >      >      >                         Hague
>  Kennedy
> >      >      >      >     Europe
> >      >      >      >           political.knowledge
> >      >      >      >                      1.066799
> 1.015532
> >      >      >      >     1.101741
> >      >      >      >                      1.028546
> >      >      >      >                        gender
> >      >      >      >                      1.017386
> >      >      >      >
> >      >      >      >
> >      >      >      >     John
> >      >      >      >
> >      >      >      >      >
> >      >      >      >      > Best,
> >      >      >      >      >
> >      >      >      >      > Juho
> >      >      >      >      >
> >      >      >      >      > ma 28. helmik. 2022 klo 2.23 John Fox
> >      >     (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >      >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
> >      >      >      >      > <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>) kirjoitti:
> >      >      >      >      >
> >      >      >      >      >     Dear Juho,
> >      >      >      >      >
> >      >      >      >      >     I've now had a chance to think about this
> >      >     problem some
> >      >      >     more,
> >      >      >      >     and I
> >      >      >      >      >     believe that the approach I suggested is
> >     correct. I
> >      >      >     also had an
> >      >      >      >      >     opportunity to talk the problem over a
> >     bit with
> >      >     Georges
> >      >      >      >     Monette, who
> >      >      >      >      >     coauthored the paper that introduced
> >      >     generalized variance
> >      >      >      >     inflation
> >      >      >      >      >     factors (GVIFs). On the other hand, the
> >     results
> >      >      >     produced by
> >      >      >      >      >     performance::check_collinearity() for
> >      >     multinomial logit
> >      >      >      >     models don't
> >      >      >      >      >     seem to be correct (see below).
> >      >      >      >      >
> >      >      >      >      >     Here's an example, using the
> >     nnet::multinom()
> >      >     function
> >      >      >     to fit a
> >      >      >      >      >     multinomial logit model, with alternative
> >      >      >     parametrizations of the
> >      >      >      >      >     LHS of
> >      >      >      >      >     the model:
> >      >      >      >      >
> >      >      >      >      >     --------- snip -----------
> >      >      >      >      >
> >      >      >      >      >       > library(nnet) # for multinom()
> >      >      >      >      >       > library(carData) # for BEPS data set
> >      >      >      >      >
> >      >      >      >      >       > # alternative ordering of the
> >     response levels:
> >      >      >      >      >       > BEPS$vote1 <- factor(BEPS$vote,
> >      >     levels=c("Labour",
> >      >      >     "Liberal
> >      >      >      >      >     Democrat", "Conservative"))
> >      >      >      >      >       > levels(BEPS$vote)
> >      >      >      >      >     [1] "Conservative"     "Labour"
> >       "Liberal
> >      >      >     Democrat"
> >      >      >      >      >       > levels(BEPS$vote1)
> >      >      >      >      >     [1] "Labour"           "Liberal Democrat"
> >      >     "Conservative"
> >      >      >      >      >
> >      >      >      >      >       > m <- multinom(vote ~ . - vote1,
> >     data=BEPS)
> >      >      >      >      >     # weights:  33 (20 variable)
> >      >      >      >      >     initial  value 1675.383740
> >      >      >      >      >     iter  10 value 1345.935273
> >      >      >      >      >     iter  20 value 1150.956807
> >      >      >      >      >     iter  30 value 1141.921662
> >      >      >      >      >     iter  30 value 1141.921661
> >      >      >      >      >     iter  30 value 1141.921661
> >      >      >      >      >     final  value 1141.921661
> >      >      >      >      >     converged
> >      >      >      >      >       > m1 <- multinom(vote1 ~ . - vote,
> >     data=BEPS)
> >      >      >      >      >     # weights:  33 (20 variable)
> >      >      >      >      >     initial  value 1675.383740
> >      >      >      >      >     iter  10 value 1280.439304
> >      >      >      >      >     iter  20 value 1165.513772
> >      >      >      >      >     final  value 1141.921662
> >      >      >      >      >     converged
> >      >      >      >      >
> >      >      >      >      >       > rbind(coef(m), coef(m1)) # compare
> >     coefficients
> >      >      >      >      >                        (Intercept)
> age
> >      >      >      >     economic.cond.national
> >      >      >      >      >     economic.cond.household
> >      >      >      >      >     Labour             0.9515214 -0.021913989
> >      >      >     0.5575707
> >      >      >      >      >            0.15839096
> >      >      >      >      >     Liberal Democrat   1.4119306 -0.016810735
> >      >      >     0.1810761
> >      >      >      >      >           -0.01196664
> >      >      >      >      >     Liberal Democrat   0.4604567  0.005102666
> >      >      >       -0.3764928
> >      >      >      >      >           -0.17036682
> >      >      >      >      >     Conservative      -0.9514466  0.021912305
> >      >      >       -0.5575644
> >      >      >      >      >           -0.15838744
> >      >      >      >      >                             Blair       Hague
> >      >     Kennedy
> >      >      >          Europe
> >      >      >      >      >     political.knowledge
> >      >      >      >      >     Labour            0.8371764 -0.90775585
> >     0.2513436
> >      >      >     -0.22781308
> >      >      >      >      >     -0.5370612
> >      >      >      >      >     Liberal Democrat  0.2937331 -0.82217625
> >     0.6710567
> >      >      >     -0.20004624
> >      >      >      >      >     -0.2034605
> >      >      >      >      >     Liberal Democrat -0.5434408  0.08559455
> >     0.4197027
> >      >      >     0.02776465
> >      >      >      >      >     0.3336068
> >      >      >      >      >     Conservative     -0.8371670  0.90778068
> >     -0.2513735
> >      >      >     0.22781092
> >      >      >      >      >     0.5370545
> >      >      >      >      >                         gendermale
> >      >      >      >      >     Labour            0.13765774
> >      >      >      >      >     Liberal Democrat  0.12640823
> >      >      >      >      >     Liberal Democrat -0.01125898
> >      >      >      >      >     Conservative     -0.13764849
> >      >      >      >      >
> >      >      >      >      >       > c(logLik(m), logLik(m1)) # same fit
> >     to the data
> >      >      >      >      >     [1] -1141.922 -1141.922
> >      >      >      >      >
> >      >      >      >      >       > # covariance matrices for
> coefficients:
> >      >      >      >      >       > V <- vcov(m)
> >      >      >      >      >       > V1 <- vcov(m1)
> >      >      >      >      >       > cbind(colnames(V), colnames(V1)) #
> >     compare
> >      >      >      >      >             [,1]
> >      >         [,2]
> >      >      >      >      >
> >      >      >      >      >        [1,] "Labour:(Intercept)"
> >      >      >       "Liberal
> >      >      >      >      >     Democrat:(Intercept)"
> >      >      >      >      >        [2,] "Labour:age"
> >      >      >       "Liberal
> >      >      >      >      >     Democrat:age"
> >      >      >      >      >
> >      >      >      >      >        [3,] "Labour:economic.cond.national"
> >      >      >     "Liberal
> >      >      >      >      >     Democrat:economic.cond.national"
> >      >      >      >      >        [4,] "Labour:economic.cond.household"
> >      >      >       "Liberal
> >      >      >      >      >     Democrat:economic.cond.household"
> >      >      >      >      >        [5,] "Labour:Blair"
> >      >      >       "Liberal
> >      >      >      >      >     Democrat:Blair"
> >      >      >      >      >        [6,] "Labour:Hague"
> >      >      >       "Liberal
> >      >      >      >      >     Democrat:Hague"
> >      >      >      >      >        [7,] "Labour:Kennedy"
> >      >      >       "Liberal
> >      >      >      >      >     Democrat:Kennedy"
> >      >      >      >      >        [8,] "Labour:Europe"
> >      >      >     "Liberal
> >      >      >      >      >     Democrat:Europe"
> >      >      >      >      >        [9,] "Labour:political.knowledge"
> >      >      >       "Liberal
> >      >      >      >      >     Democrat:political.knowledge"
> >      >      >      >      >     [10,] "Labour:gendermale"
> >      >        "Liberal
> >      >      >      >      >     Democrat:gendermale"
> >      >      >      >      >     [11,] "Liberal Democrat:(Intercept)"
> >      >      >      >      >     "Conservative:(Intercept)"
> >      >      >      >      >     [12,] "Liberal Democrat:age"
> >      >      >      >       "Conservative:age"
> >      >      >      >      >
> >      >      >      >      >     [13,] "Liberal
> >     Democrat:economic.cond.national"
> >      >      >      >      >     "Conservative:economic.cond.national"
> >      >      >      >      >     [14,] "Liberal
> >     Democrat:economic.cond.household"
> >      >      >      >      >     "Conservative:economic.cond.household"
> >      >      >      >      >     [15,] "Liberal Democrat:Blair"
> >      >      >      >       "Conservative:Blair"
> >      >      >      >      >
> >      >      >      >      >     [16,] "Liberal Democrat:Hague"
> >      >      >      >       "Conservative:Hague"
> >      >      >      >      >
> >      >      >      >      >     [17,] "Liberal Democrat:Kennedy"
> >      >      >      >       "Conservative:Kennedy"
> >      >      >      >      >
> >      >      >      >      >     [18,] "Liberal Democrat:Europe"
> >      >      >      >     "Conservative:Europe"
> >      >      >      >      >
> >      >      >      >      >     [19,] "Liberal
> Democrat:political.knowledge"
> >      >      >      >      >     "Conservative:political.knowledge"
> >      >      >      >      >     [20,] "Liberal Democrat:gendermale"
> >      >      >      >      >     "Conservative:gendermale"
> >      >      >      >      >
> >      >      >      >      >       > int <- c(1, 11) # remove intercepts
> >      >      >      >      >       > colnames(V)[int]
> >      >      >      >      >     [1] "Labour:(Intercept)"
>  "Liberal
> >      >      >     Democrat:(Intercept)"
> >      >      >      >      >
> >      >      >      >      >       > colnames(V1)[int]
> >      >      >      >      >     [1] "Liberal Democrat:(Intercept)"
> >      >      >     "Conservative:(Intercept)"
> >      >      >      >      >       > V <- V[-int, -int]
> >      >      >      >      >       > V1 <- V1[-int, -int]
> >      >      >      >      >
> >      >      >      >      >       > age <- c(1, 10) # locate age
> >     coefficients
> >      >      >      >      >       > colnames(V)[age]
> >      >      >      >      >     [1] "Labour:age"           "Liberal
> >     Democrat:age"
> >      >      >      >      >       > colnames(V1)[age]
> >      >      >      >      >     [1] "Liberal Democrat:age"
> >     "Conservative:age"
> >      >      >      >      >
> >      >      >      >      >       > V <- cov2cor(V) # compute coefficient
> >      >     correlations
> >      >      >      >      >       > V1 <- cov2cor(V1)
> >      >      >      >      >
> >      >      >      >      >       > # compare GVIFs:
> >      >      >      >      >       > c(det(V[age, age])*det(V[-age,
> >     -age])/det(V),
> >      >      >      >      >     +   det(V1[age, age])*det(V1[-age,
> >     -age])/det(V1))
> >      >      >      >      >     [1] 1.046232 1.046229
> >      >      >      >      >
> >      >      >      >      >     --------- snip -----------
> >      >      >      >      >
> >      >      >      >      >     For curiosity, I applied car::vif() and
> >      >      >      >      >     performance::check_collinearity() to
> these
> >      >     models to
> >      >      >     see what
> >      >      >      >     they
> >      >      >      >      >     would
> >      >      >      >      >     do. Both returned the wrong answer. vif()
> >      >     produced a
> >      >      >     warning, but
> >      >      >      >      >     check_collinearity() didn't:
> >      >      >      >      >
> >      >      >      >      >     --------- snip -----------
> >      >      >      >      >
> >      >      >      >      >       > car::vif(m1)
> >      >      >      >      >                           age
> >     economic.cond.national
> >      >      >      >      >     economic.cond.household
> >      >      >      >      >                     15.461045
> >       22.137772
> >      >      >      >      >       16.693877
> >      >      >      >      >                         Blair
> >         Hague
> >      >      >      >      >       Kennedy
> >      >      >      >      >                     14.681562
> >     7.483039
> >      >      >      >      >       15.812067
> >      >      >      >      >                        Europe
> >       political.knowledge
> >      >      >      >      >     gender
> >      >      >      >      >                      6.502119
> >     4.219507
> >      >      >      >      >     2.313885
> >      >      >      >      >     Warning message:
> >      >      >      >      >     In vif.default(m1) : No intercept: vifs
> >     may not be
> >      >      >     sensible.
> >      >      >      >      >
> >      >      >      >      >       > performance::check_collinearity(m)
> >      >      >      >      >     # Check for Multicollinearity
> >      >      >      >      >
> >      >      >      >      >     Low Correlation
> >      >      >      >      >
> >      >      >      >      >                           Term  VIF
> Increased SE
> >      >     Tolerance
> >      >      >      >      >                            age 1.72
> >       1.31
> >      >        0.58
> >      >      >      >      >         economic.cond.national 1.85
> >       1.36
> >      >        0.54
> >      >      >      >      >        economic.cond.household 1.86
> >       1.37
> >      >        0.54
> >      >      >      >      >                          Blair 1.63
> >       1.28
> >      >        0.61
> >      >      >      >      >                          Hague 1.94
> >       1.39
> >      >        0.52
> >      >      >      >      >                        Kennedy 1.70
> >       1.30
> >      >        0.59
> >      >      >      >      >                         Europe 2.01
> >       1.42
> >      >        0.50
> >      >      >      >      >            political.knowledge 1.94
> >       1.39
> >      >        0.52
> >      >      >      >      >                         gender 1.78
> >       1.33
> >      >        0.56
> >      >      >      >      >       > performance::check_collinearity(m1)
> >      >      >      >      >     # Check for Multicollinearity
> >      >      >      >      >
> >      >      >      >      >     Low Correlation
> >      >      >      >      >
> >      >      >      >      >                           Term  VIF
> Increased SE
> >      >     Tolerance
> >      >      >      >      >                            age 1.19
> >       1.09
> >      >        0.84
> >      >      >      >      >         economic.cond.national 1.42
> >       1.19
> >      >        0.70
> >      >      >      >      >        economic.cond.household 1.32
> >       1.15
> >      >        0.76
> >      >      >      >      >                          Blair 1.50
> >       1.22
> >      >        0.67
> >      >      >      >      >                          Hague 1.30
> >       1.14
> >      >        0.77
> >      >      >      >      >                        Kennedy 1.19
> >       1.09
> >      >        0.84
> >      >      >      >      >                         Europe 1.34
> >       1.16
> >      >        0.75
> >      >      >      >      >            political.knowledge 1.30
> >       1.14
> >      >        0.77
> >      >      >      >      >                         gender 1.23
> >       1.11
> >      >        0.81
> >      >      >      >      >
> >      >      >      >      >     --------- snip -----------
> >      >      >      >      >
> >      >      >      >      >     I looked at the code for vif() and
> >      >     check_collinearity() to
> >      >      >      >     see where
> >      >      >      >      >     they went wrong. Both failed to handle
> >     the two
> >      >      >     intercepts in
> >      >      >      >     the model
> >      >      >      >      >     correctly -- vif() thought there was no
> >      >     intercept and
> >      >      >      >      >     check_collinearity() just removed the
> first
> >      >     intercept
> >      >      >     but not the
> >      >      >      >      >     second.
> >      >      >      >      >
> >      >      >      >      >     In examining the code for
> >     check_collinearity(), I
> >      >      >     discovered a
> >      >      >      >      >     couple of
> >      >      >      >      >     additional disconcerting facts. First,
> >     part of the
> >      >      >     code seems
> >      >      >      >     to be
> >      >      >      >      >     copied from vif.default(). Second, as a
> >      >     consequence,
> >      >      >      >      >     check_collinearity() actually computes
> >     GVIFs rather
> >      >      >     than VIFs
> >      >      >      >     (and
> >      >      >      >      >     doesn't reference either the Fox and
> >     Monette paper
> >      >      >      >     introducing GVIFs or
> >      >      >      >      >     the car package) but doesn't seem to
> >     understand
> >      >     that, and,
> >      >      >      >     for example,
> >      >      >      >      >     takes the squareroot of the GVIF
> >     (reported in the
> >      >      >     column marked
> >      >      >      >      >     "Increased SE") rather than the 2p root
> >     (when there
> >      >      >     are p > 1
> >      >      >      >      >     coefficients in a term).
> >      >      >      >      >
> >      >      >      >      >     Here's the relevant code from the two
> >     functions
> >      >     (where
> >      >      >     . . .
> >      >      >      >     denotes
> >      >      >      >      >     elided lines) -- the default method for
> >     vif() and
> >      >      >      >      >     .check_collinearity(),
> >      >      >      >      >     which is called by
> >     check_collinearity.default():
> >      >      >      >      >
> >      >      >      >      >     --------- snip -----------
> >      >      >      >      >
> >      >      >      >      >       > car:::vif.default
> >      >      >      >      >     function (mod, ...)
> >      >      >      >      >     {
> >      >      >      >      >           . . .
> >      >      >      >      >           v <- vcov(mod)
> >      >      >      >      >           assign <- attr(model.matrix(mod),
> >     "assign")
> >      >      >      >      >           if (names(coefficients(mod)[1]) ==
> >      >     "(Intercept)") {
> >      >      >      >      >               v <- v[-1, -1]
> >      >      >      >      >               assign <- assign[-1]
> >      >      >      >      >           }
> >      >      >      >      >           else warning("No intercept: vifs
> >     may not be
> >      >      >     sensible.")
> >      >      >      >      >           terms <- labels(terms(mod))
> >      >      >      >      >           n.terms <- length(terms)
> >      >      >      >      >           if (n.terms < 2)
> >      >      >      >      >               stop("model contains fewer
> >     than 2 terms")
> >      >      >      >      >           R <- cov2cor(v)
> >      >      >      >      >           detR <- det(R)
> >      >      >      >      >           . . .
> >      >      >      >      >           for (term in 1:n.terms) {
> >      >      >      >      >               subs <- which(assign == term)
> >      >      >      >      >               result[term, 1] <-
> >     det(as.matrix(R[subs,
> >      >      >     subs])) *
> >      >      >      >      >     det(as.matrix(R[-subs,
> >      >      >      >      >                   -subs]))/detR
> >      >      >      >      >               result[term, 2] <- length(subs)
> >      >      >      >      >           }
> >      >      >      >      >           . . .
> >      >      >      >      >     }
> >      >      >      >      >
> >      >      >      >      >       > performance:::.check_collinearity
> >      >      >      >      >     function (x, component, verbose = TRUE)
> >      >      >      >      >     {
> >      >      >      >      >           v <- insight::get_varcov(x,
> >     component =
> >      >     component,
> >      >      >      >     verbose =
> >      >      >      >      >     FALSE)
> >      >      >      >      >           assign <- .term_assignments(x,
> >     component,
> >      >     verbose =
> >      >      >      >     verbose)
> >      >      >      >      >           . . .
> >      >      >      >      >           if (insight::has_intercept(x)) {
> >      >      >      >      >               v <- v[-1, -1]
> >      >      >      >      >               assign <- assign[-1]
> >      >      >      >      >           }
> >      >      >      >      >           else {
> >      >      >      >      >               if (isTRUE(verbose)) {
> >      >      >      >      >                   warning("Model has no
> >     intercept. VIFs
> >      >      >     may not be
> >      >      >      >      >     sensible.",
> >      >      >      >      >                       call. = FALSE)
> >      >      >      >      >               }
> >      >      >      >      >           }
> >      >      >      >      >               . . .
> >      >      >      >      >               terms <-
> >      >     labels(stats::terms(f[[component]]))
> >      >      >      >      >               . . .
> >      >      >      >      >           n.terms <- length(terms)
> >      >      >      >      >           if (n.terms < 2) {
> >      >      >      >      >               if (isTRUE(verbose)) {
> >      >      >      >      >
> >      >       warning(insight::format_message(sprintf("Not
> >      >      >      >     enough model
> >      >      >      >      >     terms in the %s part of the model to
> >     check for
> >      >      >      >     multicollinearity.",
> >      >      >      >      >                       component)), call. =
> >     FALSE)
> >      >      >      >      >               }
> >      >      >      >      >               return(NULL)
> >      >      >      >      >           }
> >      >      >      >      >           R <- stats::cov2cor(v)
> >      >      >      >      >           detR <- det(R)
> >      >      >      >      >           . . .
> >      >      >      >      >           for (term in 1:n.terms) {
> >      >      >      >      >               subs <- which(assign == term)
> >      >      >      >      >                   . . .
> >      >      >      >      >                   result <- c(result,
> >      >      >     det(as.matrix(R[subs, subs])) *
> >      >      >      >      >                       det(as.matrix(R[-subs,
> >      >     -subs]))/detR)
> >      >      >      >      >                   . . .
> >      >      >      >      >           }
> >      >      >      >      >           . . .
> >      >      >      >      >     }
> >      >      >      >      >
> >      >      >      >      >     --------- snip -----------
> >      >      >      >      >
> >      >      >      >      >     So, the upshot of all this is that you
> >     should
> >      >     be able
> >      >      >     to do
> >      >      >      >     what you
> >      >      >      >      >     want, but not with either car::vif() or
> >      >      >      >      >     performance::check_collinearity().
> >     Instead, either
> >      >      >     write your own
> >      >      >      >      >     function or do the computations in a
> script.
> >      >      >      >      >
> >      >      >      >      >     There's also a lesson here about S3
> default
> >      >     methods:
> >      >      >     The fact
> >      >      >      >     that a
> >      >      >      >      >     default method returns a result rather
> than
> >      >     throwing
> >      >      >     an error
> >      >      >      >     or a
> >      >      >      >      >     warning doesn't mean that the result is
> the
> >      >     right answer.
> >      >      >      >      >
> >      >      >      >      >     I hope this helps,
> >      >      >      >      >        John
> >      >      >      >      >
> >      >      >      >      >
> >      >      >      >      >     On 2022-02-26 3:45 p.m., Juho Kristian
> >     Ruohonen
> >      >     wrote:
> >      >      >      >      >      > Dear John W,
> >      >      >      >      >      >
> >      >      >      >      >      > Thank you very much for the tip-off!
> >      >     Apologies for not
> >      >      >      >     responding
> >      >      >      >      >     earlier
> >      >      >      >      >      > (gmail apparently decided to direct
> >     your email
> >      >      >     right into the
> >      >      >      >      >     junk folder).
> >      >      >      >      >      > I am very pleased to note that the
> >     package you
> >      >      >     mention does
> >      >      >      >      >     indeed work
> >      >      >      >      >      > with *brms* multinomial models!
> >     Thanks again!
> >      >      >      >      >      >
> >      >      >      >      >      > Best,
> >      >      >      >      >      >
> >      >      >      >      >      > Juho
> >      >      >      >      >      >
> >      >      >      >      >      > pe 25. helmik. 2022 klo 19.23 John
> >     Willoughby
> >      >      >      >      >     (johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>
> >      >      >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>>
> >      >      >      >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>
> >      >      >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>
> >      >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>
> >     <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com>>>>>)
> >      >      >      >      >      > kirjoitti:
> >      >      >      >      >      >
> >      >      >      >      >      >> Have you tried the
> check_collinearity()
> >      >     function
> >      >      >     in the
> >      >      >      >     performance
> >      >      >      >      >      >> package? It's supposed to work on
> brms
> >      >     models, but
> >      >      >     whether it
> >      >      >      >      >     will work on
> >      >      >      >      >      >> a multinomial model I don't know.
> >     It works
> >      >     well
> >      >      >     on mixed
> >      >      >      >     models
> >      >      >      >      >     generated
> >      >      >      >      >      >> by glmmTMB().
> >      >      >      >      >      >>
> >      >      >      >      >      >> John Willoughby
> >      >      >      >      >      >>
> >      >      >      >      >      >>
> >      >      >      >      >      >> On Fri, Feb 25, 2022 at 3:01 AM
> >      >      >      >      >
> >       <r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >      >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>
> >      >      >      >      >
> >      >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >      >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>>>
> >      >      >      >      >      >> wrote:
> >      >      >      >      >      >>
> >      >      >      >      >      >>> Send R-sig-mixed-models mailing list
> >      >     submissions to
> >      >      >      >      >      >>> r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> To subscribe or unsubscribe via the
> >     World Wide
> >      >      >     Web, visit
> >      >      >      >      >      >>>
> >      >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >      >      >      >
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
> >      >      >      >      >      >>> or, via email, send a message with
> >     subject or
> >      >      >     body 'help' to
> >      >      >      >      >      >>>
> >     r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >      >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>
> >      >      >      >      >
> >      >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >      >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>>
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> You can reach the person managing
> >     the list at
> >      >      >      >      >      >>>
> >     r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>>
> >      >      >      >      >
> >       <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>>>
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> When replying, please edit your
> Subject
> >      >     line so it is
> >      >      >      >     more specific
> >      >      >      >      >      >>> than "Re: Contents of
> >     R-sig-mixed-models
> >      >     digest..."
> >      >      >      >      >      >>>
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> Today's Topics:
> >      >      >      >      >      >>>
> >      >      >      >      >      >>>     1. Collinearity diagnostics for
> >     (mixed)
> >      >      >     multinomial
> >      >      >      >     models
> >      >      >      >      >      >>>        (Juho Kristian Ruohonen)
> >      >      >      >      >      >>>
> >      >      >      >      >      >>>
> >      >      >      >      >
> >      >      >      >
> >      >      >
> >      >
> >
>  ----------------------------------------------------------------------
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> Message: 1
> >      >      >      >      >      >>> Date: Fri, 25 Feb 2022 10:23:25
> +0200
> >      >      >      >      >      >>> From: Juho Kristian Ruohonen
> >      >      >      >     <juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>
> >      >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>>
> >      >      >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>
> >      >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>>>>
> >      >      >      >      >      >>> To: John Fox <jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
> >      >      >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>>
> >      >      >      >      >      >>> Cc:
> >     "r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>"
> >      >      >      >      >      >>>
> >     <r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>>
> >      >      >      >      >      >>> Subject: [R-sig-ME] Collinearity
> >      >     diagnostics for
> >      >      >     (mixed)
> >      >      >      >      >     multinomial
> >      >      >      >      >      >>>          models
> >      >      >      >      >      >>> Message-ID:
> >      >      >      >      >      >>>          <
> >      >      >      >      >      >>>
> >      >      >      >      >
> >      >      >      >
> >      >      >
> >      >
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >      >
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>
> >      >      >      >
> >      >      >
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>>
> >      >      >      >      >
> >      >      >      >
> >      >      >
> >      >
> >       <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>>>>
> >      >      >      >      >      >>> Content-Type: text/plain;
> >     charset="utf-8"
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> Dear John (and anyone else
> qualified to
> >      >     comment),
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> I fit lots of mixed-effects
> multinomial
> >      >     models in my
> >      >      >      >     research,
> >      >      >      >      >     and I
> >      >      >      >      >      >> would
> >      >      >      >      >      >>> like to see some (multi)collinearity
> >      >     diagnostics
> >      >      >     on the
> >      >      >      >     fixed
> >      >      >      >      >     effects, of
> >      >      >      >      >      >>> which there are over 30. My models
> >     are fit
> >      >     using the
> >      >      >      >     Bayesian
> >      >      >      >      >     *brms*
> >      >      >      >      >      >>> package because I know of no
> >     frequentist
> >      >     packages
> >      >      >     with
> >      >      >      >      >     multinomial GLMM
> >      >      >      >      >      >>> compatibility.
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> With continuous or dichotomous
> >     outcomes,
> >      >     my go-to
> >      >      >      >     function for
> >      >      >      >      >      >> calculating
> >      >      >      >      >      >>> multicollinearity diagnostics is of
> >     course
> >      >      >     *vif()* from
> >      >      >      >     the *car*
> >      >      >      >      >      >> package.
> >      >      >      >      >      >>> As expected, however, this function
> >     does not
> >      >      >     report sensible
> >      >      >      >      >     diagnostics
> >      >      >      >      >      >>> for multinomial models -- not even
> for
> >      >     standard
> >      >      >     ones fit
> >      >      >      >     by the
> >      >      >      >      >     *nnet*
> >      >      >      >      >      >>> package's *multinom()* function.
> >     The reason, I
> >      >      >     presume, is
> >      >      >      >      >     because a
> >      >      >      >      >      >>> multinomial model is not really one
> >     but C-1
> >      >      >     regression
> >      >      >      >     models
> >      >      >      >      >     (where C
> >      >      >      >      >      >> is
> >      >      >      >      >      >>> the number of response categories)
> >     and the
> >      >     *vif()*
> >      >      >      >     function is not
> >      >      >      >      >      >> designed
> >      >      >      >      >      >>> to deal with this scenario.
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> Therefore, in order to obtain
> >     meaningful
> >      >     collinearity
> >      >      >      >     metrics,
> >      >      >      >      >     my present
> >      >      >      >      >      >>> plan is to write a simple helper
> >     function
> >      >     that uses
> >      >      >      >     *vif() *to
> >      >      >      >      >     calculate
> >      >      >      >      >      >>> and present (generalized) variance
> >     inflation
> >      >      >     metrics for
> >      >      >      >     the C-1
> >      >      >      >      >      >>> sub-datasets to which the C-1
> component
> >      >     binomial
> >      >      >     models
> >      >      >      >     of the
> >      >      >      >      >     overall
> >      >      >      >      >      >>> multinomial model are fit. In other
> >     words, it
> >      >      >     will partition
> >      >      >      >      >     the data
> >      >      >      >      >      >> into
> >      >      >      >      >      >>> those C-1 subsets, and then apply
> >     *vif()*
> >      >     to as
> >      >      >     many linear
> >      >      >      >      >     regressions
> >      >      >      >      >      >>> using a made-up continuous response
> and
> >      >     the fixed
> >      >      >     effects of
> >      >      >      >      >     interest.
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> Does this seem like a sensible
> >     approach?
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> Best,
> >      >      >      >      >      >>>
> >      >      >      >      >      >>> Juho
> >      >      >      >      >      >>>
> >      >      >      >      >      >>>
> >      >      >      >      >      >>>
> >      >      >      >      >      >>
> >      >      >      >      >      >>          [[alternative HTML version
> >     deleted]]
> >      >      >      >      >      >>
> >      >      >      >      >      >>
> >     _______________________________________________
> >      >      >      >      >      >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>
> >      >      >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
> >      >      >      >      >      >>
> >      >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >      >      >      >
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
> >      >      >      >      >      >>
> >      >      >      >      >      >
> >      >      >      >      >      >       [[alternative HTML version
> >     deleted]]
> >      >      >      >      >      >
> >      >      >      >      >      >
> >     _______________________________________________
> >      >      >      >      >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>
> >      >      >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
> >      >      >      >      >      >
> >      >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >      >      >      >
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >      >      >
> >      >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
> >      >      >      >      >     --
> >      >      >      >      >     John Fox, Professor Emeritus
> >      >      >      >      >     McMaster University
> >      >      >      >      >     Hamilton, Ontario, Canada
> >      >      >      >      >     web:
> >     https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>
> >      >      >      >      >
> >       <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>>
> >      >      >      >      >
> >      >      >      >     --
> >      >      >      >     John Fox, Professor Emeritus
> >      >      >      >     McMaster University
> >      >      >      >     Hamilton, Ontario, Canada
> >      >      >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>
> >      >      >      >
> >      >      >     --
> >      >      >     John Fox, Professor Emeritus
> >      >      >     McMaster University
> >      >      >     Hamilton, Ontario, Canada
> >      >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >      >
> >      >
> >
>  ------------------------------------------------------------------------
> >      >     --
> >      >     John Fox, Professor Emeritus
> >      >     McMaster University
> >      >     Hamilton, Ontario, Canada
> >      >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From heejuhw@ng @end|ng |rom gm@||@com  Thu Mar  3 10:29:51 2022
From: heejuhw@ng @end|ng |rom gm@||@com (Kate Hwang)
Date: Thu, 3 Mar 2022 17:29:51 +0800
Subject: [R-sig-ME] Error message
Message-ID: <CAL+o_QoQCuXTP9uZnVLPNoqb_fnGzkeGqYGjG-UBF-HVBgFbMQ@mail.gmail.com>

Hi
I am getting the following error message and I do not know how to fix it.
Error in reformulate(paste0("(", vapply(findbars(f), deparse1, ""), ")"),
 :
  unused argument (env = environment(f))

Could you please help? Thank you so much for your help in advance and I
look forward to hearing from you!

Best wishes
Kate

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Mar  3 17:23:09 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 3 Mar 2022 11:23:09 -0500
Subject: [R-sig-ME] Error message
In-Reply-To: <CAL+o_QoQCuXTP9uZnVLPNoqb_fnGzkeGqYGjG-UBF-HVBgFbMQ@mail.gmail.com>
References: <CAL+o_QoQCuXTP9uZnVLPNoqb_fnGzkeGqYGjG-UBF-HVBgFbMQ@mail.gmail.com>
Message-ID: <565dde18-288d-ebf6-927b-5af20022b333@gmail.com>

   This is a bug that was recently noted (and fixed in the development 
version) here:

https://github.com/lme4/lme4/issues/664

   Running this code snippet

assign('reformulate', envir = topenv(),
                function(..., env = parent.env) {
                    f <- base::reformulate(...)
                    environment(f) <- env
                    return(f)
                })

might fix the problem.  If not, if you have development tools (compiler 
etc.; Rtools) installed, you can do remotes::install_github("lme4/lme4") 
to install the development version.

   If none of that works, let us know.

  (What version of R are you using?  I suspect it's relatively old (< 
3.6.0).  If so, if you can update your version of R that might make your 
life easier in a variety of ways, as well as fixing this particular 
problem.)

   cheers
    Ben Bolker


On 3/3/22 4:29 AM, Kate Hwang wrote:
> Hi
> I am getting the following error message and I do not know how to fix it.
> Error in reformulate(paste0("(", vapply(findbars(f), deparse1, ""), ")"),
>   :
>    unused argument (env = environment(f))
> 
> Could you please help? Thank you so much for your help in advance and I
> look forward to hearing from you!
> 
> Best wishes
> Kate
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Mar  3 17:23:25 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 3 Mar 2022 17:23:25 +0100
Subject: [R-sig-ME] Error message
In-Reply-To: <CAL+o_QoQCuXTP9uZnVLPNoqb_fnGzkeGqYGjG-UBF-HVBgFbMQ@mail.gmail.com>
References: <CAL+o_QoQCuXTP9uZnVLPNoqb_fnGzkeGqYGjG-UBF-HVBgFbMQ@mail.gmail.com>
Message-ID: <25120.60285.854103.365517@stat.math.ethz.ch>

>>>>> Kate Hwang 
>>>>>     on Thu, 3 Mar 2022 17:29:51 +0800 writes:

    > Hi I am getting the following error message and I do not
    > know how to fix it.  Error in reformulate(paste0("(",
    > vapply(findbars(f), deparse1, ""), ")"), : unused argument
    > (env = environment(f))

    > Could you please help? 

Yes, but only if you help us help you.
We need a minimal reproducible example, so we can run the same R
code as you and get the same error.


    > Thank you so much for your help in
    > advance and I look forward to hearing from you!

    > Best wishes Kate

    > 	[[alternative HTML version deleted]]

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Adr|@@n@de@Jong @end|ng |rom @|u@@e  Fri Mar  4 13:01:23 2022
From: Adr|@@n@de@Jong @end|ng |rom @|u@@e (Adriaan de Jong)
Date: Fri, 4 Mar 2022 12:01:23 +0000
Subject: [R-sig-ME] glmer.nb warning and prediction problem
Message-ID: <8c351202e0b34841aac1eddb5d9d9df3@Exch2-3.slu.se>

Dear list members,

What I?m trying to do is to model a linear trend over the years (Years = Year ? 1992, 1993 was the starting year of the 29 year data series) of bird numbers (?Total?) with a var/mean ratio of 2.85. The variables ?Dag? (= day of the study period starting on April 1 = 1, in this subset ranging from 31 to 80) and ?Dec_Hour? (= decimal hour between 4 AM and 9 PM) are nested random effects. The subset for this analysis (Trend1) contains 993 rows (=counting trips).

The mod5<-glmer.nb(Total~  Years + (1|Dag/Dec_Hour),data=Trend1) command under lme4 gives me the following warning message:

In theta.ml(Y, mu, weights = object at resp$weights, limit = limit,  :
  iteration limit reached

I presume I need to provide glmer.nb with a lmerControl string, but have no clue what it should contain.

I guess that the Dec_Hour may be causing the iteration limit problem. The model seems to converge, though, and the summary looks like this


Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
glmerMod]
 Family: Negative Binomial(798.6507)  ( log )
Formula: Total ~ Years + (1 | Dag/Dec_Hour)
   Data: Trend1

     AIC      BIC   logLik deviance df.resid
  4921.7   4946.2  -2455.8   4911.7      988

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.9784 -0.6199 -0.0885  0.4511  3.8851

Random effects:
 Groups       Name        Variance Std.Dev.
 Dec_Hour:Dag (Intercept) 0.15182  0.3896
 Dag          (Intercept) 0.09292  0.3048
Number of obs: 993, groups:  Dec_Hour:Dag, 945; Dag, 50

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  2.09539    0.06025   34.78   <2e-16 ***
Years       -0.04078    0.00248  -16.44   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
      (Intr)
Years -0.594

This makes sense to me, but I would like to predict the 1993 and 2021 endpoint "Total" values of the yearly trend (numerically Years = 1 and 29) given the peak values of observed birds found to be Dag=34 and Dec_Hour=7. For this I tried:

newd<-data.frame(Years=c(1,29),Dag=34,Dec_Hour=7.0)
pred<-predict(mod5,newd)

This rendered the message:
Error in levelfun(r, n, allow.new.levels = allow.new.levels) :
  new levels detected in newdata

Could anyone give me a hint on (a) how to avoid the iteration problem and (b) how to adjust the predict function? Thanks in advance for your help.

Cheers,
Adjan

Adriaan "Adjan" de Jong
Associate professor
Swedish University of Agricultural Sciences
---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From mo|||eebrook@ @end|ng |rom gm@||@com  Fri Mar  4 16:56:10 2022
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Fri, 4 Mar 2022 16:56:10 +0100
Subject: [R-sig-ME] debugging glmmTMB 1.1.3 on Windows
Message-ID: <9DB9A6FE-5534-4446-9519-01949DFB78EE@gmail.com>

Dear R-sig-mixed,

The glmmTMB developers and I are preparing a new version of the package. On some Windows systems, we get an error mentioning the `up2date` function which we provide for back compatibility. I can?t replicate it on a Windows laptop that I?m unfamiliar with because I get an different error about "file too big". To progress any further with that laptop, I need to figure out how to add a "/bigobj flag" (https://digitalkarabela.com/mingw-w64-how-to-fix-file-too-big-too-many-sections/ <https://digitalkarabela.com/mingw-w64-how-to-fix-file-too-big-too-many-sections/>), but still the Windows system is unfamiliar to me, so it would be even more helpful if someone with Windows skills could figure out what?s going on with the errors below. We think the way to reproduce them might be using devtools::run_examples()

cheers,
Mollie

 
 https://win-builder.r-project.org/incoming_pretest/glmmTMB_1.1.3_20220303_161208/Windows/00check.log <https://win-builder.r-project.org/incoming_pretest/glmmTMB_1.1.3_20220303_161208/Windows/00check.log>
Status: 3 ERRORs, 1 NOTE
 

The output states
* checking examples ... [8s] ERROR
Running examples in 'glmmTMB-Ex.R' failed
The error most likely occurred in:

> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: Anova.glmmTMB
> ### Title: Downstream methods
> ### Aliases: Anova.glmmTMB Effect.glmmTMB downstream_methods
> ###   emmeans.glmmTMB
> 
> ### ** Examples
> 
> warp.lm <- glmmTMB(breaks ~ wool * tension, data = warpbreaks)
> salamander1 <- up2date(readRDS(system.file("example_files","salamander1.rds",package="glmmTMB")))
* checking for unstated dependencies in 'tests' ... OK
* checking tests ... [5s] ERROR
  Running 'AAAtest-all.R' [4s]
Running the tests in 'tests/AAAtest-all.R' failed.
Complete output:
  > if (require("testthat")) {
  +     pkg <- "glmmTMB"
  +     require(pkg, character.only=TRUE)
  +     print(sessionInfo())
  +     test_check(pkg, reporter="summary")
  +     print(warnings()) # TODO? catch most of these by expect_warning(..)
  + } else {
  +     warnings("Package 'testthat' not available, cannot run unit tests for package",
  + 	     sQuote(pkg))
  + }
  Loading required package: testthat
  Loading required package: glmmTMB
  R Under development (unstable) (2022-03-02 r81842 ucrt)
  Platform: x86_64-w64-mingw32/x64 (64-bit)
  Running under: Windows Server x64 (build 20348)
  
  Matrix products: default
  
  locale:
  [1] LC_COLLATE=C                 LC_CTYPE=German_Germany.utf8
  [3] LC_MONETARY=C                LC_NUMERIC=C                
  [5] LC_TIME=C                   
  
  attached base packages:
  [1] stats     graphics  grDevices utils     datasets  methods   base     
  
  other attached packages:
  [1] glmmTMB_1.1.3  testthat_3.1.3
  
  loaded via a namespace (and not attached):
   [1] Rcpp_1.0.8          TMB_1.7.22          magrittr_2.0.2     
   [4] splines_4.2.0       MASS_7.3-55         xtable_1.8-4       
   [7] lattice_0.20-45     R6_2.5.1            rlang_1.0.1        
  [10] multcomp_1.4-18     minqa_1.2.4         grid_4.2.0         
  [13] nlme_3.1-155        TH.data_1.1-0       cli_3.2.0          
  [16] coda_0.19-4         emmeans_1.7.2       survival_3.3-1     
  [19] lme4_1.1-28         numDeriv_2016.8-1.1 brio_1.1.3         
  [22] Matrix_1.4-0        nloptr_2.0.0        codetools_0.2-18   
  [25] sandwich_3.0-1      estimability_1.3    compiler_4.2.0     
  [28] boot_1.3-28         mvtnorm_1.1-3       zoo_1.8-9          
* checking for unstated dependencies in vignettes ... OK
* checking package vignettes in 'inst/doc' ... OK
* checking re-building of vignette outputs ... [64s] ERROR
Error(s) in re-building vignettes:
--- re-building 'covstruct.rmd' using rmarkdown
--- finished re-building 'covstruct.rmd'

--- re-building 'mcmc.rmd' using rmarkdown
--- finished re-building 'mcmc.rmd'

--- re-building 'miscEx.rmd' using rmarkdown
--- finished re-building 'miscEx.rmd'

--- re-building 'parallel.Rmd' using rmarkdown
--- finished re-building 'parallel.Rmd'

--- re-building 'sim.rmd' using rmarkdown
--- finished re-building 'sim.rmd'

--- re-building 'troubleshooting.rmd' using rmarkdown

* checking PDF version of manual ... OK
* checking for detritus in the temp directory ... OK
* DONE
Status: 3 ERRORs, 1 NOTE


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Mar  4 21:02:00 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 4 Mar 2022 15:02:00 -0500
Subject: [R-sig-ME] glmer.nb warning and prediction problem
In-Reply-To: <8c351202e0b34841aac1eddb5d9d9df3@Exch2-3.slu.se>
References: <8c351202e0b34841aac1eddb5d9d9df3@Exch2-3.slu.se>
Message-ID: <CABghstQZd0P8ZkTepNMnN9gwqHj7majHrB+bMGZPnU_HfTGo+Q@mail.gmail.com>

  (1) tl;dr don't worry about it. It's very, very likely that you have
data whose conditional distribution is indistinguishable from a
Poisson. I know that the *marginal* variance/mean ratio is large, but
once we put in the covariates and the random effects, what's left is
presumably equi- or underdispersed (variance ~ mean or variance <
mean). The mean counts at the beginning of the time series are about 8
(exp(2)), decreasing over time; your dispersion parameter is 798, >>
mean - that means the distribution is effectively Poisson. The
iteration limit warning comes from the initial call to MASS::glm.nb,
which tries to determine an initial guess for the dispersion parameter
via an iterative algorithm - it gives up after a while.
   You could try a Poisson model - my guess is that it will give
practically indistinguishable results (and a likelihood ratio test
probably won't reject the null hypothesis that the conditional
distribution is Poisson).
   Or you could ignore the warning.

2. You might need to put the levels of `Dag` and `Dec_Hour` in
quotation marks.  What is `lapply(model.frame(mod5), unique)` ?


On Fri, Mar 4, 2022 at 7:02 AM Adriaan de Jong <Adriaan.de.Jong at slu.se> wrote:
>
> Dear list members,
>
> What I?m trying to do is to model a linear trend over the years (Years = Year ? 1992, 1993 was the starting year of the 29 year data series) of bird numbers (?Total?) with a var/mean ratio of 2.85. The variables ?Dag? (= day of the study period starting on April 1 = 1, in this subset ranging from 31 to 80) and ?Dec_Hour? (= decimal hour between 4 AM and 9 PM) are nested random effects. The subset for this analysis (Trend1) contains 993 rows (=counting trips).
>
> The mod5<-glmer.nb(Total~  Years + (1|Dag/Dec_Hour),data=Trend1) command under lme4 gives me the following warning message:
>
> In theta.ml(Y, mu, weights = object at resp$weights, limit = limit,  :
>   iteration limit reached
>
> I presume I need to provide glmer.nb with a lmerControl string, but have no clue what it should contain.
>
> I guess that the Dec_Hour may be causing the iteration limit problem. The model seems to converge, though, and the summary looks like this
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
> glmerMod]
>  Family: Negative Binomial(798.6507)  ( log )
> Formula: Total ~ Years + (1 | Dag/Dec_Hour)
>    Data: Trend1
>
>      AIC      BIC   logLik deviance df.resid
>   4921.7   4946.2  -2455.8   4911.7      988
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.9784 -0.6199 -0.0885  0.4511  3.8851
>
> Random effects:
>  Groups       Name        Variance Std.Dev.
>  Dec_Hour:Dag (Intercept) 0.15182  0.3896
>  Dag          (Intercept) 0.09292  0.3048
> Number of obs: 993, groups:  Dec_Hour:Dag, 945; Dag, 50
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  2.09539    0.06025   34.78   <2e-16 ***
> Years       -0.04078    0.00248  -16.44   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>       (Intr)
> Years -0.594
>
> This makes sense to me, but I would like to predict the 1993 and 2021 endpoint "Total" values of the yearly trend (numerically Years = 1 and 29) given the peak values of observed birds found to be Dag=34 and Dec_Hour=7. For this I tried:
>
> newd<-data.frame(Years=c(1,29),Dag=34,Dec_Hour=7.0)
> pred<-predict(mod5,newd)
>
> This rendered the message:
> Error in levelfun(r, n, allow.new.levels = allow.new.levels) :
>   new levels detected in newdata
>
> Could anyone give me a hint on (a) how to avoid the iteration problem and (b) how to adjust the predict function? Thanks in advance for your help.
>
> Cheers,
> Adjan
>
> Adriaan "Adjan" de Jong
> Associate professor
> Swedish University of Agricultural Sciences
> ---
> N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
> E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Fri Mar  4 21:02:27 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 4 Mar 2022 15:02:27 -0500
Subject: [R-sig-ME] glmer.nb warning and prediction problem
In-Reply-To: <CABghstQZd0P8ZkTepNMnN9gwqHj7majHrB+bMGZPnU_HfTGo+Q@mail.gmail.com>
References: <8c351202e0b34841aac1eddb5d9d9df3@Exch2-3.slu.se>
 <CABghstQZd0P8ZkTepNMnN9gwqHj7majHrB+bMGZPnU_HfTGo+Q@mail.gmail.com>
Message-ID: <CABghstSM-KvtObWip6SyDopBghMjB_KD+AUKEb3eGmJM32PypQ@mail.gmail.com>

  (It wouldn't hurt for us to make the error message slightly more
informative by listing *which* new levels were found ...)

On Fri, Mar 4, 2022 at 3:02 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>   (1) tl;dr don't worry about it. It's very, very likely that you have
> data whose conditional distribution is indistinguishable from a
> Poisson. I know that the *marginal* variance/mean ratio is large, but
> once we put in the covariates and the random effects, what's left is
> presumably equi- or underdispersed (variance ~ mean or variance <
> mean). The mean counts at the beginning of the time series are about 8
> (exp(2)), decreasing over time; your dispersion parameter is 798, >>
> mean - that means the distribution is effectively Poisson. The
> iteration limit warning comes from the initial call to MASS::glm.nb,
> which tries to determine an initial guess for the dispersion parameter
> via an iterative algorithm - it gives up after a while.
>    You could try a Poisson model - my guess is that it will give
> practically indistinguishable results (and a likelihood ratio test
> probably won't reject the null hypothesis that the conditional
> distribution is Poisson).
>    Or you could ignore the warning.
>
> 2. You might need to put the levels of `Dag` and `Dec_Hour` in
> quotation marks.  What is `lapply(model.frame(mod5), unique)` ?
>
>
> On Fri, Mar 4, 2022 at 7:02 AM Adriaan de Jong <Adriaan.de.Jong at slu.se> wrote:
> >
> > Dear list members,
> >
> > What I?m trying to do is to model a linear trend over the years (Years = Year ? 1992, 1993 was the starting year of the 29 year data series) of bird numbers (?Total?) with a var/mean ratio of 2.85. The variables ?Dag? (= day of the study period starting on April 1 = 1, in this subset ranging from 31 to 80) and ?Dec_Hour? (= decimal hour between 4 AM and 9 PM) are nested random effects. The subset for this analysis (Trend1) contains 993 rows (=counting trips).
> >
> > The mod5<-glmer.nb(Total~  Years + (1|Dag/Dec_Hour),data=Trend1) command under lme4 gives me the following warning message:
> >
> > In theta.ml(Y, mu, weights = object at resp$weights, limit = limit,  :
> >   iteration limit reached
> >
> > I presume I need to provide glmer.nb with a lmerControl string, but have no clue what it should contain.
> >
> > I guess that the Dec_Hour may be causing the iteration limit problem. The model seems to converge, though, and the summary looks like this
> >
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
> > glmerMod]
> >  Family: Negative Binomial(798.6507)  ( log )
> > Formula: Total ~ Years + (1 | Dag/Dec_Hour)
> >    Data: Trend1
> >
> >      AIC      BIC   logLik deviance df.resid
> >   4921.7   4946.2  -2455.8   4911.7      988
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -1.9784 -0.6199 -0.0885  0.4511  3.8851
> >
> > Random effects:
> >  Groups       Name        Variance Std.Dev.
> >  Dec_Hour:Dag (Intercept) 0.15182  0.3896
> >  Dag          (Intercept) 0.09292  0.3048
> > Number of obs: 993, groups:  Dec_Hour:Dag, 945; Dag, 50
> >
> > Fixed effects:
> >             Estimate Std. Error z value Pr(>|z|)
> > (Intercept)  2.09539    0.06025   34.78   <2e-16 ***
> > Years       -0.04078    0.00248  -16.44   <2e-16 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >       (Intr)
> > Years -0.594
> >
> > This makes sense to me, but I would like to predict the 1993 and 2021 endpoint "Total" values of the yearly trend (numerically Years = 1 and 29) given the peak values of observed birds found to be Dag=34 and Dec_Hour=7. For this I tried:
> >
> > newd<-data.frame(Years=c(1,29),Dag=34,Dec_Hour=7.0)
> > pred<-predict(mod5,newd)
> >
> > This rendered the message:
> > Error in levelfun(r, n, allow.new.levels = allow.new.levels) :
> >   new levels detected in newdata
> >
> > Could anyone give me a hint on (a) how to avoid the iteration problem and (b) how to adjust the predict function? Thanks in advance for your help.
> >
> > Cheers,
> > Adjan
> >
> > Adriaan "Adjan" de Jong
> > Associate professor
> > Swedish University of Agricultural Sciences
> > ---
> > N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
> > E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @rr@ypro|||e @end|ng |rom y@hoo@com  Sat Mar  5 02:08:14 2022
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Sat, 5 Mar 2022 01:08:14 +0000 (UTC)
Subject: [R-sig-ME] lmer to estimate batch variability
References: <1456609308.454759.1646442494520.ref@mail.yahoo.com>
Message-ID: <1456609308.454759.1646442494520@mail.yahoo.com>

Dear all, I have this simple dataset to measure the yeild of a crop collected in 2 batches (https://drive.google.com/file/d/1lgVZVLHeecp9a_sFxEPeg6353O-qXZhM/view). when I ran a simple inear mixed model using lmer to estimate within-batch and between-batch variability, the between-batch variability is 0. The run showed that data is singular. Does anyone know why the data is singular and what's the reason for 0 variability? is it because the dataset only has 2 batches?
> daty<-read.table("datx.txt",sep='\t',header=T,row.names=NULL)
> library(lme4)> lmer(yield~1+(1|batch),daty)boundary (singular) fit: see ?isSingularLinear mixed model fit by REML ['lmerMod']Formula: yield ~ 1 + (1 | batch)? ?Data: datyREML criterion at convergence: 115.6358Random effects:?Groups? ?Name? ? ? ? Std.Dev.?batch? ? (Intercept) 0.000? ??Residual? ? ? ? ? ? ?2.789? ?Number of obs: 24, groups:? batch, 2Fixed Effects:(Intercept)??? ? ? 5.788??
Thanks!John

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Mar  5 03:00:27 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Fri, 4 Mar 2022 21:00:27 -0500
Subject: [R-sig-ME] lmer to estimate batch variability
In-Reply-To: <2154_1646442633_2251AX3w028153_1456609308.454759.1646442494520@mail.yahoo.com>
References: <1456609308.454759.1646442494520.ref@mail.yahoo.com>
 <2154_1646442633_2251AX3w028153_1456609308.454759.1646442494520@mail.yahoo.com>
Message-ID: <29fe47cd-f7da-b84a-6cf5-d33ed62ce7b6@mcmaster.ca>

Dear John,

On 2022-03-04 8:08 p.m., array chip via R-sig-mixed-models wrote:
> Dear all, I have this simple dataset to measure the yeild of a crop collected in 2 batches (https://drive.google.com/file/d/1lgVZVLHeecp9a_sFxEPeg6353O-qXZhM/view). when I ran a simple inear mixed model using lmer to estimate within-batch and between-batch variability, the between-batch variability is 0. The run showed that data is singular. Does anyone know why the data is singular and what's the reason for 0 variability? is it because the dataset only has 2 batches?

I'd say yes and no.

Yes, in that you have effectively approximately only 1 degree of freedom 
for between-group variability, very little data in each group, and small 
variability between groups relative to within-group 
variability--apparently sufficiently small that the REML criterion is 
maximized at the boundary of the parameter space:

 > # not quite right because group n's differ:
 > sd(with(daty, tapply(yield, batch, mean)))
[1] 0.3032702

 > with(daty, tapply(yield, batch, sd))
        D        K
2.952165 2.779894

Perhaps someone else can provide a more precise explanation.

No, in that it's not hard to construct data for which a proper solution 
can be obtained; e.g.,

 > set.seed(123)

 > Data <- data.frame(yield=c(rnorm(100, -5, 1), rnorm(100, 5, 1)),
+                    batch=rep(c("D", "K"), each=100))

 > lmer(yield ~ 1 + (1|batch), Data)
Linear mixed model fit by REML ['lmerMod']
Formula: yield ~ 1 + (1 | batch)
    Data: Data
REML criterion at convergence: 554.1332
Random effects:
  Groups   Name        Std.Dev.
  batch    (Intercept) 6.9305
  Residual             0.9403
Number of obs: 200, groups:  batch, 2
Fixed Effects:
(Intercept)
    -0.00857

 > sd(with(Data, tapply(yield, batch, mean))) # estimates 5
[1] 6.931094

 > with(Data, tapply(yield, batch, sd)) # estimate 1
         D         K
0.9128159 0.9669866

BTW, your data *were* included with the original message that you sent 
to r-help, because .txt-file attachments are permitted, but, as you can 
see, your input and output are garbled here because your email wasn't 
plain-text:

>> daty<-read.table("datx.txt",sep='\t',header=T,row.names=NULL)
>> library(lme4)> lmer(yield~1+(1|batch),daty)boundary (singular) fit: see ?isSingularLinear mixed model fit by REML ['lmerMod']Formula: yield ~ 1 + (1 | batch)? ?Data: datyREML criterion at convergence: 115.6358Random effects:?Groups? ?Name? ? ? ? Std.Dev.?batch? ? (Intercept) 0.000? ??Residual? ? ? ? ? ? ?2.789? ?Number of obs: 24, groups:? batch, 2Fixed Effects:(Intercept)??? ? ? 5.788
> Thanks!John

I hope this helps,
  John

> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From @rr@ypro|||e @end|ng |rom y@hoo@com  Sat Mar  5 06:51:04 2022
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Sat, 5 Mar 2022 05:51:04 +0000 (UTC)
Subject: [R-sig-ME] lmer to estimate batch variability
In-Reply-To: <29fe47cd-f7da-b84a-6cf5-d33ed62ce7b6@mcmaster.ca>
References: <1456609308.454759.1646442494520.ref@mail.yahoo.com>
 <2154_1646442633_2251AX3w028153_1456609308.454759.1646442494520@mail.yahoo.com>
 <29fe47cd-f7da-b84a-6cf5-d33ed62ce7b6@mcmaster.ca>
Message-ID: <1409838807.494545.1646459464367@mail.yahoo.com>

 Dear John,
Your explanation makes sense to me in that between-batch variability is too small compared to within batch variabiltity. Thanks a lot for your explanation!
John
    On Friday, March 4, 2022, 06:00:29 PM PST, John Fox <jfox at mcmaster.ca> wrote:  
 
 Dear John,

On 2022-03-04 8:08 p.m., array chip via R-sig-mixed-models wrote:
> Dear all, I have this simple dataset to measure the yeild of a crop collected in 2 batches (https://drive.google.com/file/d/1lgVZVLHeecp9a_sFxEPeg6353O-qXZhM/view). when I ran a simple inear mixed model using lmer to estimate within-batch and between-batch variability, the between-batch variability is 0. The run showed that data is singular. Does anyone know why the data is singular and what's the reason for 0 variability? is it because the dataset only has 2 batches?

I'd say yes and no.

Yes, in that you have effectively approximately only 1 degree of freedom 
for between-group variability, very little data in each group, and small 
variability between groups relative to within-group 
variability--apparently sufficiently small that the REML criterion is 
maximized at the boundary of the parameter space:

 > # not quite right because group n's differ:
 > sd(with(daty, tapply(yield, batch, mean)))
[1] 0.3032702

 > with(daty, tapply(yield, batch, sd))
? ? ? ? D? ? ? ? K
2.952165 2.779894

Perhaps someone else can provide a more precise explanation.

No, in that it's not hard to construct data for which a proper solution 
can be obtained; e.g.,

 > set.seed(123)

 > Data <- data.frame(yield=c(rnorm(100, -5, 1), rnorm(100, 5, 1)),
+? ? ? ? ? ? ? ? ? ? batch=rep(c("D", "K"), each=100))

 > lmer(yield ~ 1 + (1|batch), Data)
Linear mixed model fit by REML ['lmerMod']
Formula: yield ~ 1 + (1 | batch)
? ? Data: Data
REML criterion at convergence: 554.1332
Random effects:
? Groups? Name? ? ? ? Std.Dev.
? batch? ? (Intercept) 6.9305
? Residual? ? ? ? ? ? 0.9403
Number of obs: 200, groups:? batch, 2
Fixed Effects:
(Intercept)
? ? -0.00857

 > sd(with(Data, tapply(yield, batch, mean))) # estimates 5
[1] 6.931094

 > with(Data, tapply(yield, batch, sd)) # estimate 1
? ? ? ? D? ? ? ? K
0.9128159 0.9669866

BTW, your data *were* included with the original message that you sent 
to r-help, because .txt-file attachments are permitted, but, as you can 
see, your input and output are garbled here because your email wasn't 
plain-text:

>> daty<-read.table("datx.txt",sep='\t',header=T,row.names=NULL)
>> library(lme4)> lmer(yield~1+(1|batch),daty)boundary (singular) fit: see ?isSingularLinear mixed model fit by REML ['lmerMod']Formula: yield ~ 1 + (1 | batch)? ?Data: datyREML criterion at convergence: 115.6358Random effects:?Groups? ?Name? ? ? ? Std.Dev.?batch? ? (Intercept) 0.000? ??Residual? ? ? ? ? ? ?2.789? ?Number of obs: 24, groups:? batch, 2Fixed Effects:(Intercept)??? ? ? 5.788
> Thanks!John

I hope this helps,
? John

> 
> ??? [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

  
	[[alternative HTML version deleted]]


From Adr|@@n@de@Jong @end|ng |rom @|u@@e  Sat Mar  5 12:29:21 2022
From: Adr|@@n@de@Jong @end|ng |rom @|u@@e (Adriaan de Jong)
Date: Sat, 5 Mar 2022 11:29:21 +0000
Subject: [R-sig-ME] glmer.nb warning and prediction problem
In-Reply-To: <CABghstSM-KvtObWip6SyDopBghMjB_KD+AUKEb3eGmJM32PypQ@mail.gmail.com>
References: <8c351202e0b34841aac1eddb5d9d9df3@Exch2-3.slu.se>
 <CABghstQZd0P8ZkTepNMnN9gwqHj7majHrB+bMGZPnU_HfTGo+Q@mail.gmail.com>
 <CABghstSM-KvtObWip6SyDopBghMjB_KD+AUKEb3eGmJM32PypQ@mail.gmail.com>
Message-ID: <06b60ccc6c9943169a4eb848e4999ae8@Exch2-3.slu.se>

Hi Ben,
Thank you very much for your comments and suggestions.

As for point 2.
Adding quotation marks didn't solve the problem. But from the lapply(model.frame(mod5), unique) printout (listed below) I understand that the Dec_Hour = 7.0 was not represented among the unique values, but 7.00 was. I changed the newd vector (newd<-data.frame(Years=c(1,29),Dag="34",Dec_Hour="7.00"), but this didn't solve the problem either. The Dag variable does include the value 34 so that couldn't cause the problem. So yes, an error message with more information wouldn't hurt :)

From a biological point of view, the decimal-hours ("Dec_Hour") form of time-of-day doesn't make much more sense than using just full hours ("Hour") in the random effects part. When I changed "Dec_Hour" to "Hour" in the original glmer.nb, things went smoothly (at least after the iteration limit warning). The prediction function
    (newd4<-data.frame(Years=c(1,29),Dag="34",Hour="7")
    pred4<-predict(mod4,newd4)).
also worked well. With and without levels in quotation marks!

As for point 1.
This is great news, because negative binomial modelling has been troublesome for me. Being a non-professional statistician, it makes me wonder, though, when and how to apply the var/mean ratio (often seen as a "law" in family selection).

Never mind, I changed to a poisson glmer (glmer(Total~  Years + (1|Dag/Dec_Hour), family=poisson)) and (obviously) received no iteration limit warning, but again, the prediction function didn't work. Similar to the above, this problem was solved by changing from decimal to Hours in the random effects part.


From this I conclude that the use of Dec_Hour (decimal hour based on a combination of hour and minutes data) is inappropriate in both glmer and glmer.nb when predictions are wanted. Is this information provided anywhere in the documentation of these functions? From my point of view, the interesting thing is that Dec_Hour worked flawless in gam and the predict.gam functions.

This leaves me in a model selection situation. Based on AIC (list below), the glmer.nb with just full hours seems to be the model of choice, especially because it allows for predictions. Does this choice make sense to you?

Cheers,
Adjan

Function and formulaAIC
glmer(Total~  Years + (1|Dag/Hour), family=poisson)4973
glmer(Total~  Years + (1|Dag/Dec_Hour), family=poisson)4920  (prediction failure)
glmer.nb(Total~  Years + (1|Dag/Dec_Hour))4922  (iteration limit warning, prediction failure)
glmer.nb(Total~  Years + (1|Dag/Hour))4914  (iterarion limit warning)



lapply(model.frame(mod5)
$Total
 [1]  9  3  7 14 10  8 12  5  1  2 11  6 17  4 19 15 13 16 18 21 20  0 22

$Years
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29

$Dag
 [1] 33 41 42 47 48 53 59 62 66 67 68 72 77 78 79 31 32 37 38 40 43 46 54 57 61 70 35 50 51 52 56 63 65 75
[35] 36 39 44 49 58 69 73 34 60 80 45 64 55 74 76 71

$Dec_Hour
  [1] 11.42 11.17 15.42  5.33  7.92 15.92 16.92 17.17 10.92 20.42 17.42 14.92  8.42 11.67 16.42 12.17 16.17
 [18] 17.33 10.17 14.17 17.67 15.67 19.50 13.42  9.50 16.25 10.50 12.50 11.75  6.42 19.08  8.17 14.00 16.00
 [35] 20.17  7.67 11.08 17.25 11.00 12.42 10.00 13.00 17.83  6.58 13.17 15.08  7.83 14.42  8.00  9.58 14.50
 [52]  9.25 12.25 18.83  6.67 16.67  8.33 12.00  9.67 12.33  7.50 14.67 15.17 20.92 11.25 19.00  9.00 11.92
 [69] 12.83 17.50 18.00 18.67 12.58  8.67 20.67  8.50 17.92 13.67 18.25 18.17 11.50 16.33 11.83 13.08 15.50
 [86] 19.17 18.50 10.75  9.83 13.83 14.75  8.58  9.08 10.83 11.33 15.25 17.75 12.92 18.58 19.67 13.50 13.92
[103] 10.42 17.00 18.33  5.92  6.33  7.70 15.00 15.83 13.33  6.75  8.83 18.42 19.42 15.05 15.58  5.17 12.67
[120] 13.75 10.33 12.08  6.83  9.17 10.58 20.58 20.75  6.92 16.83  5.42 12.75  8.92  5.67 14.08 18.08 16.58
[137] 14.33  5.08  7.17  6.17  9.75 17.08 10.08  5.25  5.27 10.67 20.33 19.92 17.48  6.50 15.33 14.83 16.50
[154] 20.00  9.92 16.75  5.75  5.83 20.83  7.00 19.33 17.58 18.75 20.25  5.00 19.58 15.75  7.25 16.08  7.75
[171]  7.33  7.42  5.50 20.08  8.25  8.08  6.00  7.58 13.58 18.92 14.58 14.25 19.75  6.08 19.83  7.08 10.25
[188]  9.42  9.33  6.38 13.25  6.25 19.25  8.75



-----Original Message-----
From: Ben Bolker <bbolker at gmail.com>
Sent: den 4 mars 2022 21:02
To: Adriaan de Jong <Adriaan.de.Jong at slu.se>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmer.nb warning and prediction problem

  (It wouldn't hurt for us to make the error message slightly more informative by listing *which* new levels were found ...)

On Fri, Mar 4, 2022 at 3:02 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>   (1) tl;dr don't worry about it. It's very, very likely that you have
> data whose conditional distribution is indistinguishable from a
> Poisson. I know that the *marginal* variance/mean ratio is large, but
> once we put in the covariates and the random effects, what's left is
> presumably equi- or underdispersed (variance ~ mean or variance <
> mean). The mean counts at the beginning of the time series are about 8
> (exp(2)), decreasing over time; your dispersion parameter is 798, >>
> mean - that means the distribution is effectively Poisson. The
> iteration limit warning comes from the initial call to MASS::glm.nb,
> which tries to determine an initial guess for the dispersion parameter
> via an iterative algorithm - it gives up after a while.
>    You could try a Poisson model - my guess is that it will give
> practically indistinguishable results (and a likelihood ratio test
> probably won't reject the null hypothesis that the conditional
> distribution is Poisson).
>    Or you could ignore the warning.
>
> 2. You might need to put the levels of `Dag` and `Dec_Hour` in
> quotation marks.  What is `lapply(model.frame(mod5), unique)` ?
>
>
> On Fri, Mar 4, 2022 at 7:02 AM Adriaan de Jong <Adriaan.de.Jong at slu.se> wrote:
> >
> > Dear list members,
> >
> > What I?m trying to do is to model a linear trend over the years (Years = Year ? 1992, 1993 was the starting year of the 29 year data series) of bird numbers (?Total?) with a var/mean ratio of 2.85. The variables ?Dag? (= day of the study period starting on April 1 = 1, in this subset ranging from 31 to 80) and ?Dec_Hour? (= decimal hour between 4 AM and 9 PM) are nested random effects. The subset for this analysis (Trend1) contains 993 rows (=counting trips).
> >
> > The mod5<-glmer.nb(Total~  Years + (1|Dag/Dec_Hour),data=Trend1) command under lme4 gives me the following warning message:
> >
> > In theta.ml(Y, mu, weights = object at resp$weights, limit = limit,  :
> >   iteration limit reached
> >
> > I presume I need to provide glmer.nb with a lmerControl string, but have no clue what it should contain.
> >
> > I guess that the Dec_Hour may be causing the iteration limit
> > problem. The model seems to converge, though, and the summary looks
> > like this
> >
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) [ glmerMod]
> >  Family: Negative Binomial(798.6507)  ( log )
> > Formula: Total ~ Years + (1 | Dag/Dec_Hour)
> >    Data: Trend1
> >
> >      AIC      BIC   logLik deviance df.resid
> >   4921.7   4946.2  -2455.8   4911.7      988
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -1.9784 -0.6199 -0.0885  0.4511  3.8851
> >
> > Random effects:
> >  Groups       Name        Variance Std.Dev.
> >  Dec_Hour:Dag (Intercept) 0.15182  0.3896
> >  Dag          (Intercept) 0.09292  0.3048
> > Number of obs: 993, groups:  Dec_Hour:Dag, 945; Dag, 50
> >
> > Fixed effects:
> >             Estimate Std. Error z value Pr(>|z|)
> > (Intercept)  2.09539    0.06025   34.78   <2e-16 ***
> > Years       -0.04078    0.00248  -16.44   <2e-16 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >       (Intr)
> > Years -0.594
> >
> > This makes sense to me, but I would like to predict the 1993 and 2021 endpoint "Total" values of the yearly trend (numerically Years = 1 and 29) given the peak values of observed birds found to be Dag=34 and Dec_Hour=7. For this I tried:
> >
> > newd<-data.frame(Years=c(1,29),Dag=34,Dec_Hour=7.0)
> > pred<-predict(mod5,newd)
> >
> > This rendered the message:
> > Error in levelfun(r, n, allow.new.levels = allow.new.levels) :
> >   new levels detected in newdata
> >
> > Could anyone give me a hint on (a) how to avoid the iteration problem and (b) how to adjust the predict function? Thanks in advance for your help.
> >
> > Cheers,
> > Adjan
> >
> > Adriaan "Adjan" de Jong
> > Associate professor
> > Swedish University of Agricultural Sciences
> > ---
> > N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar
> > dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka
> > h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
> > E-mailing SLU will result in SLU processing your personal data. For
> > more information on how this is done, click here
> > <https://www.slu.se/en/about-slu/contact-slu/personal-data/>
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From bbo|ker @end|ng |rom gm@||@com  Sat Mar  5 21:13:16 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 5 Mar 2022 15:13:16 -0500
Subject: [R-sig-ME] glmer.nb warning and prediction problem
In-Reply-To: <06b60ccc6c9943169a4eb848e4999ae8@Exch2-3.slu.se>
References: <8c351202e0b34841aac1eddb5d9d9df3@Exch2-3.slu.se>
 <CABghstQZd0P8ZkTepNMnN9gwqHj7majHrB+bMGZPnU_HfTGo+Q@mail.gmail.com>
 <CABghstSM-KvtObWip6SyDopBghMjB_KD+AUKEb3eGmJM32PypQ@mail.gmail.com>
 <06b60ccc6c9943169a4eb848e4999ae8@Exch2-3.slu.se>
Message-ID: <526a3389-f8fb-4292-fe1f-3006dae0d949@gmail.com>



On 3/5/22 6:29 AM, Adriaan de Jong wrote:
> Hi Ben,
> Thank you very much for your comments and suggestions.
> 
> As for point 2.
> Adding quotation marks didn't solve the problem. But from the lapply(model.frame(mod5), unique) printout (listed below) I understand that the Dec_Hour = 7.0 was not represented among the unique values, but 7.00 was. I changed the newd vector (newd<-data.frame(Years=c(1,29),Dag="34",Dec_Hour="7.00"), but this didn't solve the problem either. The Dag variable does include the value 34 so that couldn't cause the problem. So yes, an error message with more information wouldn't hurt :)
> 
>  From a biological point of view, the decimal-hours ("Dec_Hour") form of time-of-day doesn't make much more sense than using just full hours ("Hour") in the random effects part. When I changed "Dec_Hour" to "Hour" in the original glmer.nb, things went smoothly (at least after the iteration limit warning). The prediction function
>      (newd4<-data.frame(Years=c(1,29),Dag="34",Hour="7")
>      pred4<-predict(mod4,newd4)).
> also worked well. With and without levels in quotation marks!

  As far as I can tell your "hours_dec" is the decimal version of 
5-minute time periods (the values range from 5.00 to 20.92, with 
intervals of approximately 1/12).

   It's not obvious to me why using a resolution of hours rather than 
5-minute periods should make any difference: is there any chance you can 
provide a reproducible example, i.e. post your data somewhere (or if 
necessary send it to me)?

   At a slightly deeper level (that may not be critical for your 
application), I would be strongly tempted to treat time-of-day as a 
fixed covariate (with a linear or quadratic or possibly a spline-based 
effect of time over the course of the day; a cyclic spline would be 
useful if your data covered the full 24-hour span but I think it's 
unnecessary because the range is only (5-21), possibly in addition to an 
"hour nested within day" random effect to account for less-predictable 
temporal variation ...

> 
> As for point 1.
> This is great news, because negative binomial modelling has been troublesome for me. Being a non-professional statistician, it makes me wonder, though, when and how to apply the var/mean ratio (often seen as a "law" in family selection).

   The main point here is that the variance-mean ratio criterion (which 
is not a 'law', just a rule of thumb) applies to the *conditional 
distribution* (i.e., the distribution once the statistical model has 
been applied, controlling for grouping and covariates).  There are 
methods/rules of thumb for testing for overdispersion based on the 
residuals of a fitted model, e.g. see the GLMM FAQ at 
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html

> 
> Never mind, I changed to a poisson glmer (glmer(Total~  Years + (1|Dag/Dec_Hour), family=poisson)) and (obviously) received no iteration limit warning, but again, the prediction function didn't work. Similar to the above, this problem was solved by changing from decimal to Hours in the random effects part.
> 
> 
>  From this I conclude that the use of Dec_Hour (decimal hour based on a combination of hour and minutes data) is inappropriate in both glmer and glmer.nb when predictions are wanted. Is this information provided anywhere in the documentation of these functions? From my point of view, the interesting thing is that Dec_Hour worked flawless in gam and the predict.gam functions.
> 
> This leaves me in a model selection situation. Based on AIC (list below), the glmer.nb with just full hours seems to be the model of choice, especially because it allows for predictions. Does this choice make sense to you?

   Yes (although if it were my problem I would probably want to dig a 
little deeper to understand the differences in goodness of 
fit/differences in conclusions across the different models/etc.).  (In 
any case, if you can provide a reproducible example so we can understand 
the cause of the prediction failure, that would be nice.)

> 
> Cheers,
> Adjan
> 
> Function and formulaAIC
> glmer(Total~  Years + (1|Dag/Hour), family=poisson)4973
> glmer(Total~  Years + (1|Dag/Dec_Hour), family=poisson)4920  (prediction failure)
> glmer.nb(Total~  Years + (1|Dag/Dec_Hour))4922  (iteration limit warning, prediction failure)
> glmer.nb(Total~  Years + (1|Dag/Hour))4914  (iterarion limit warning)
> 
> 
> 

> lapply(model.frame(mod5)
> $Total
>   [1]  9  3  7 14 10  8 12  5  1  2 11  6 17  4 19 15 13 16 18 21 20  0 22
> 
> $Years
>   [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
> 
> $Dag
>   [1] 33 41 42 47 48 53 59 62 66 67 68 72 77 78 79 31 32 37 38 40 43 46 54 57 61 70 35 50 51 52 56 63 65 75
> [35] 36 39 44 49 58 69 73 34 60 80 45 64 55 74 76 71
> 
> $Dec_Hour
>    [1] 11.42 11.17 15.42  5.33  7.92 15.92 16.92 17.17 10.92 20.42 17.42 14.92  8.42 11.67 16.42 12.17 16.17
>   [18] 17.33 10.17 14.17 17.67 15.67 19.50 13.42  9.50 16.25 10.50 12.50 11.75  6.42 19.08  8.17 14.00 16.00
>   [35] 20.17  7.67 11.08 17.25 11.00 12.42 10.00 13.00 17.83  6.58 13.17 15.08  7.83 14.42  8.00  9.58 14.50
>   [52]  9.25 12.25 18.83  6.67 16.67  8.33 12.00  9.67 12.33  7.50 14.67 15.17 20.92 11.25 19.00  9.00 11.92
>   [69] 12.83 17.50 18.00 18.67 12.58  8.67 20.67  8.50 17.92 13.67 18.25 18.17 11.50 16.33 11.83 13.08 15.50
>   [86] 19.17 18.50 10.75  9.83 13.83 14.75  8.58  9.08 10.83 11.33 15.25 17.75 12.92 18.58 19.67 13.50 13.92
> [103] 10.42 17.00 18.33  5.92  6.33  7.70 15.00 15.83 13.33  6.75  8.83 18.42 19.42 15.05 15.58  5.17 12.67
> [120] 13.75 10.33 12.08  6.83  9.17 10.58 20.58 20.75  6.92 16.83  5.42 12.75  8.92  5.67 14.08 18.08 16.58
> [137] 14.33  5.08  7.17  6.17  9.75 17.08 10.08  5.25  5.27 10.67 20.33 19.92 17.48  6.50 15.33 14.83 16.50
> [154] 20.00  9.92 16.75  5.75  5.83 20.83  7.00 19.33 17.58 18.75 20.25  5.00 19.58 15.75  7.25 16.08  7.75
> [171]  7.33  7.42  5.50 20.08  8.25  8.08  6.00  7.58 13.58 18.92 14.58 14.25 19.75  6.08 19.83  7.08 10.25
> [188]  9.42  9.33  6.38 13.25  6.25 19.25  8.75
> 
> 
> 
> -----Original Message-----
> From: Ben Bolker <bbolker at gmail.com>
> Sent: den 4 mars 2022 21:02
> To: Adriaan de Jong <Adriaan.de.Jong at slu.se>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] glmer.nb warning and prediction problem
> 
>    (It wouldn't hurt for us to make the error message slightly more informative by listing *which* new levels were found ...)
> 
> On Fri, Mar 4, 2022 at 3:02 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>    (1) tl;dr don't worry about it. It's very, very likely that you have
>> data whose conditional distribution is indistinguishable from a
>> Poisson. I know that the *marginal* variance/mean ratio is large, but
>> once we put in the covariates and the random effects, what's left is
>> presumably equi- or underdispersed (variance ~ mean or variance <
>> mean). The mean counts at the beginning of the time series are about 8
>> (exp(2)), decreasing over time; your dispersion parameter is 798, >>
>> mean - that means the distribution is effectively Poisson. The
>> iteration limit warning comes from the initial call to MASS::glm.nb,
>> which tries to determine an initial guess for the dispersion parameter
>> via an iterative algorithm - it gives up after a while.
>>     You could try a Poisson model - my guess is that it will give
>> practically indistinguishable results (and a likelihood ratio test
>> probably won't reject the null hypothesis that the conditional
>> distribution is Poisson).
>>     Or you could ignore the warning.
>>
>> 2. You might need to put the levels of `Dag` and `Dec_Hour` in
>> quotation marks.  What is `lapply(model.frame(mod5), unique)` ?
>>
>>
>> On Fri, Mar 4, 2022 at 7:02 AM Adriaan de Jong <Adriaan.de.Jong at slu.se> wrote:
>>>
>>> Dear list members,
>>>
>>> What I?m trying to do is to model a linear trend over the years (Years = Year ? 1992, 1993 was the starting year of the 29 year data series) of bird numbers (?Total?) with a var/mean ratio of 2.85. The variables ?Dag? (= day of the study period starting on April 1 = 1, in this subset ranging from 31 to 80) and ?Dec_Hour? (= decimal hour between 4 AM and 9 PM) are nested random effects. The subset for this analysis (Trend1) contains 993 rows (=counting trips).
>>>
>>> The mod5<-glmer.nb(Total~  Years + (1|Dag/Dec_Hour),data=Trend1) command under lme4 gives me the following warning message:
>>>
>>> In theta.ml(Y, mu, weights = object at resp$weights, limit = limit,  :
>>>    iteration limit reached
>>>
>>> I presume I need to provide glmer.nb with a lmerControl string, but have no clue what it should contain.
>>>
>>> I guess that the Dec_Hour may be causing the iteration limit
>>> problem. The model seems to converge, though, and the summary looks
>>> like this
>>>
>>>
>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>> Approximation) [ glmerMod]
>>>   Family: Negative Binomial(798.6507)  ( log )
>>> Formula: Total ~ Years + (1 | Dag/Dec_Hour)
>>>     Data: Trend1
>>>
>>>       AIC      BIC   logLik deviance df.resid
>>>    4921.7   4946.2  -2455.8   4911.7      988
>>>
>>> Scaled residuals:
>>>      Min      1Q  Median      3Q     Max
>>> -1.9784 -0.6199 -0.0885  0.4511  3.8851
>>>
>>> Random effects:
>>>   Groups       Name        Variance Std.Dev.
>>>   Dec_Hour:Dag (Intercept) 0.15182  0.3896
>>>   Dag          (Intercept) 0.09292  0.3048
>>> Number of obs: 993, groups:  Dec_Hour:Dag, 945; Dag, 50
>>>
>>> Fixed effects:
>>>              Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)  2.09539    0.06025   34.78   <2e-16 ***
>>> Years       -0.04078    0.00248  -16.44   <2e-16 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>        (Intr)
>>> Years -0.594
>>>
>>> This makes sense to me, but I would like to predict the 1993 and 2021 endpoint "Total" values of the yearly trend (numerically Years = 1 and 29) given the peak values of observed birds found to be Dag=34 and Dec_Hour=7. For this I tried:
>>>
>>> newd<-data.frame(Years=c(1,29),Dag=34,Dec_Hour=7.0)
>>> pred<-predict(mod5,newd)
>>>
>>> This rendered the message:
>>> Error in levelfun(r, n, allow.new.levels = allow.new.levels) :
>>>    new levels detected in newdata
>>>
>>> Could anyone give me a hint on (a) how to avoid the iteration problem and (b) how to adjust the predict function? Thanks in advance for your help.
>>>
>>> Cheers,
>>> Adjan
>>>
>>> Adriaan "Adjan" de Jong
>>> Associate professor
>>> Swedish University of Agricultural Sciences
>>> ---
>>> N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar
>>> dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka
>>> h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
>>> E-mailing SLU will result in SLU processing your personal data. For
>>> more information on how this is done, click here
>>> <https://www.slu.se/en/about-slu/contact-slu/personal-data/>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ---
> N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
> E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From bbo|ker @end|ng |rom gm@||@com  Sun Mar  6 02:35:55 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 5 Mar 2022 20:35:55 -0500
Subject: [R-sig-ME] debugging glmmTMB 1.1.3 on Windows
In-Reply-To: <9DB9A6FE-5534-4446-9519-01949DFB78EE@gmail.com>
References: <9DB9A6FE-5534-4446-9519-01949DFB78EE@gmail.com>
Message-ID: <494211b8-549c-a007-e4c0-6069f07b69a9@gmail.com>

   I will second this.
   I've successfully installed glmmTMB on a Windows 11 virtual machine 
(circumventing the /bigobj issue), but haven't been able to reproduce 
the errors.  Short version:

  * relatively trivial code from ?glmmTMB::Anova.glmmTMB (the first 
example run)

      salamander1 <- 
up2date(readRDS(system.file("example_files","salamander1.rds",package="glmmTMB")))

causes an error/makes check fail on CRAN windows platforms (Win-builder 
and their checking platforms).

Daniel Luedecke successfully ran checks (i.e. failed to reproduce the 
problem) on

R version 4.1.2 (2021-11-01)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 22000)
glmmTMB 1.1.3 (2022-03-02 [1] Github (ea6c64a))

I failed to reproduce the problem on

version  R version 4.1.2 (2021-11-01)
os       Windows 10 x64 (build 22000)  [really Windows 11]
glmmTMB 1.1.3
Matrix 1.3-4
TMB 1.7.22

  and  R Under development (unstable) (2022-03-04 r81849 ucrt)

   on the same system.

   So far we haven't been able to find a Windows platform that 
reproduces the problem and that we can play with interactively, and 
haven't been able to isolate what the important differences are.

https://github.com/glmmTMB/glmmTMB/issues/787

On 3/4/22 10:56 AM, Mollie Brooks wrote:
> Dear R-sig-mixed,
> 
> The glmmTMB developers and I are preparing a new version of the package. On some Windows systems, we get an error mentioning the `up2date` function which we provide for back compatibility. I can?t replicate it on a Windows laptop that I?m unfamiliar with because I get an different error about "file too big". To progress any further with that laptop, I need to figure out how to add a "/bigobj flag" (https://digitalkarabela.com/mingw-w64-how-to-fix-file-too-big-too-many-sections/ <https://digitalkarabela.com/mingw-w64-how-to-fix-file-too-big-too-many-sections/>), but still the Windows system is unfamiliar to me, so it would be even more helpful if someone with Windows skills could figure out what?s going on with the errors below. We think the way to reproduce them might be using devtools::run_examples()
> 
> cheers,
> Mollie
> 
>   
>   https://win-builder.r-project.org/incoming_pretest/glmmTMB_1.1.3_20220303_161208/Windows/00check.log <https://win-builder.r-project.org/incoming_pretest/glmmTMB_1.1.3_20220303_161208/Windows/00check.log>
> Status: 3 ERRORs, 1 NOTE
>   
> 
> The output states
> * checking examples ... [8s] ERROR
> Running examples in 'glmmTMB-Ex.R' failed
> The error most likely occurred in:
> 
>> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
>> ### Name: Anova.glmmTMB
>> ### Title: Downstream methods
>> ### Aliases: Anova.glmmTMB Effect.glmmTMB downstream_methods
>> ###   emmeans.glmmTMB
>>
>> ### ** Examples
>>
>> warp.lm <- glmmTMB(breaks ~ wool * tension, data = warpbreaks)
>> salamander1 <- up2date(readRDS(system.file("example_files","salamander1.rds",package="glmmTMB")))
> * checking for unstated dependencies in 'tests' ... OK
> * checking tests ... [5s] ERROR
>    Running 'AAAtest-all.R' [4s]
> Running the tests in 'tests/AAAtest-all.R' failed.
> Complete output:
>    > if (require("testthat")) {
>    +     pkg <- "glmmTMB"
>    +     require(pkg, character.only=TRUE)
>    +     print(sessionInfo())
>    +     test_check(pkg, reporter="summary")
>    +     print(warnings()) # TODO? catch most of these by expect_warning(..)
>    + } else {
>    +     warnings("Package 'testthat' not available, cannot run unit tests for package",
>    + 	     sQuote(pkg))
>    + }
>    Loading required package: testthat
>    Loading required package: glmmTMB
>    R Under development (unstable) (2022-03-02 r81842 ucrt)
>    Platform: x86_64-w64-mingw32/x64 (64-bit)
>    Running under: Windows Server x64 (build 20348)
>    
>    Matrix products: default
>    
>    locale:
>    [1] LC_COLLATE=C                 LC_CTYPE=German_Germany.utf8
>    [3] LC_MONETARY=C                LC_NUMERIC=C
>    [5] LC_TIME=C
>    
>    attached base packages:
>    [1] stats     graphics  grDevices utils     datasets  methods   base
>    
>    other attached packages:
>    [1] glmmTMB_1.1.3  testthat_3.1.3
>    
>    loaded via a namespace (and not attached):
>     [1] Rcpp_1.0.8          TMB_1.7.22          magrittr_2.0.2
>     [4] splines_4.2.0       MASS_7.3-55         xtable_1.8-4
>     [7] lattice_0.20-45     R6_2.5.1            rlang_1.0.1
>    [10] multcomp_1.4-18     minqa_1.2.4         grid_4.2.0
>    [13] nlme_3.1-155        TH.data_1.1-0       cli_3.2.0
>    [16] coda_0.19-4         emmeans_1.7.2       survival_3.3-1
>    [19] lme4_1.1-28         numDeriv_2016.8-1.1 brio_1.1.3
>    [22] Matrix_1.4-0        nloptr_2.0.0        codetools_0.2-18
>    [25] sandwich_3.0-1      estimability_1.3    compiler_4.2.0
>    [28] boot_1.3-28         mvtnorm_1.1-3       zoo_1.8-9
> * checking for unstated dependencies in vignettes ... OK
> * checking package vignettes in 'inst/doc' ... OK
> * checking re-building of vignette outputs ... [64s] ERROR
> Error(s) in re-building vignettes:
> --- re-building 'covstruct.rmd' using rmarkdown
> --- finished re-building 'covstruct.rmd'
> 
> --- re-building 'mcmc.rmd' using rmarkdown
> --- finished re-building 'mcmc.rmd'
> 
> --- re-building 'miscEx.rmd' using rmarkdown
> --- finished re-building 'miscEx.rmd'
> 
> --- re-building 'parallel.Rmd' using rmarkdown
> --- finished re-building 'parallel.Rmd'
> 
> --- re-building 'sim.rmd' using rmarkdown
> --- finished re-building 'sim.rmd'
> 
> --- re-building 'troubleshooting.rmd' using rmarkdown
> 
> * checking PDF version of manual ... OK
> * checking for detritus in the temp directory ... OK
> * DONE
> Status: 3 ERRORs, 1 NOTE
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From johnw|||ec @end|ng |rom gm@||@com  Wed Mar  9 01:18:23 2022
From: johnw|||ec @end|ng |rom gm@||@com (John Willoughby)
Date: Tue, 8 Mar 2022 16:18:23 -0800
Subject: [R-sig-ME] Poisson intercept-only multilevel model doesn't appear
 to return the correct population mean
Message-ID: <CAKk2L3J7JMZ+N2bNGpZfKZ-Rp+cFoEYU++XnJN6=WZeQMTdXYQ@mail.gmail.com>

I have a data set consisting of counts of a particular plant species in
quadrats. The data
were collected using a two-stage sampling design, whereby 75 macroplots
were randomly positioned
in the area to be sampled and five quadrats (actually belt transects) were
sampled in each
macroplot. All of the macroplots are the same size, 25m x 25m, as are the
quadrats (each quadrat
is 0.25m x 25m).

The data file is available here:
https://www.dropbox.com/s/hpptsqap0oysje8/stratum3.csv?dl=0

There are five variables in the data file: plot_id is a unique number
assigned to each macroplot
(there are 75 unique numbers but these are not all consecutive);
belt_number is the number (1-5)
of each belt transect (quadrat) in each macroplot; counts contains the
number of individuals
counted in each belt, weights1 contains sampling weights for the macroplots
(stage 1) and weights2
contains sampling weights for the quadrats (stage 2).

The mean number of plants per quadrat for this dataset is 44.24. Several
covariates were measured
in each of the quadrats, but I'm ignoring these here and they are not
included in the data file.
Instead, I'd like to focus on the estimated population mean I get from
running several different
regressions below. Also, the data are overdispersed and a negative binomial
model seems appropriate,
but I use the Poisson here because it's available in the svyglm() function.

First I present the results from calculating the mean and standard error
from the survey package.
I set the following survey design:

cnt_design3 <- svydesign(weights = ~ weights1 + weights2,
                       id = ~plot_id + belt_number,
                       strata = ~stratum_num,
                       data = stratum3,
                       nest = TRUE)

(Sampling weights aren't really required here since the weights are equal
in each of the two stages.
We'd get the same results if we left them out.)

Running svymean() using this design I get:
svymean(~counts, design = cnt_design3)
       mean     SE
counts 44.24 9.8146

If I use glmmTMB and run an intercept-only multilevel model assuming
(incorrectly) a gaussian
distribution, I get:

glmm3 <- glmmTMB(counts ~ 1 + (1|plot_id), data = stratum3)
Conditional model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   44.240      9.749   4.538 5.68e-06 ***

The mean is exactly the same as that from svymean() and the SE is very
close.

My question arises when I use a Poisson regression on the data set. Here I
focus only on the
estimated population mean and not the standard error since the standard
error can't be
correctly exponentiated.

If I use svyglm() from the survey package and a quasipoisson distribution I
get:

svyglm2 <- svyglm(formula = counts ~ 1, design = cnt_design3, family =
quasipoisson)
Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   3.7896     0.2218   17.08   <2e-16 ***
> exp(coef(svyglm2))
(Intercept)
      44.24

This is the same mean as returned by the other analyses above.

But if I use glmmTMB to run a multilevel model with family = poisson I get
the following:
glmm3.2 <- glmmTMB(counts ~ 1 + (1|plot_id), data = stratum3,
                  family = poisson)
> fixef(glmm3.2)

Conditional model:
(Intercept)
      2.424
which when exponentiated:
> exp(fixef(glmm3.2)[[1]])
(Intercept)
   11.29252

So my question is why don't I get the same value as I get from the other
analyses, particularly
the svyglm() function using quasipoisson? I don't think it's an issue with
geometric vs arithmetic
means. If I ignore the two-stage design and pretend that all 375 quadrats
were randomly positioned
in the population and then run an intercept-only model with family =
poisson I get the correct mean
value of 44.24:

glmm3_no_random <- glmmTMB(counts ~ 1, data = stratum3,
                          family = poisson)
> fixef(glmm3_no_random)

Conditional model:
(Intercept)
       3.79
which when exponentiated:
> exp(fixef(glmm3_no_random)[[1]])
(Intercept)
      44.24

Why would including random intercepts for plot change the grand mean
(exponentiated) from
44.24 to 11.29? Note that this only happens with the multilevel Poisson
regression and not the
multilevel Gaussian. I suspect I'm missing something, but I'll be darned if
I can figure out what.

Thanks for any help you can provide.

John Willoughby

	[[alternative HTML version deleted]]


From Adr|@@n@de@Jong @end|ng |rom @|u@@e  Wed Mar  9 08:27:47 2022
From: Adr|@@n@de@Jong @end|ng |rom @|u@@e (Adriaan de Jong)
Date: Wed, 9 Mar 2022 07:27:47 +0000
Subject: [R-sig-ME] How to activate the overdisp_fun function?
Message-ID: <b19bcd2032e74dcb913a17ba19c88a27@Exch2-3.slu.se>

Dear list members,
For informed choices between poisson and negative binomial models, I've been advised to check preliminary poisson models with the overdisp_fun function in accordance with Ben Bolker's glmmFAQ github site (link below). Unfortunately, I only receive the "Error in overdisp_fun(mod30) : could not find function "overdisp_fun" message (for poisson glmer model "mod30"). I've installed packages MASS, lme4, nlme, mgcv and glmmTMB and run my script under R 4.1.2. Model "mod30" runs and plots flawless. Internet searches haven't helped me. What am I doing wrong and/or where sits this overdisp_fun function?
Thanks in advance for hints and comments,
Cheers,
Adjan

Adriaan "Adjan" de Jong
Associate professor
Swedish University of Agricultural Sciences



https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html




---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

	[[alternative HTML version deleted]]


From d@|uedecke @end|ng |rom uke@de  Wed Mar  9 08:43:57 2022
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Wed, 9 Mar 2022 08:43:57 +0100
Subject: [R-sig-ME] How to activate the overdisp_fun function?
In-Reply-To: <b19bcd2032e74dcb913a17ba19c88a27@Exch2-3.slu.se>
References: <b19bcd2032e74dcb913a17ba19c88a27@Exch2-3.slu.se>
Message-ID: <000201d83389$725c7e30$57157a90$@uke.de>

Dear Adriaan,
the function is a code snippet that you need to copy/paste from the
referenced FAQ. However, there's an implementation in the
performance-package:

https://easystats.github.io/performance/reference/check_overdispersion.html

You can install that package from CRAN:
https://cran.r-project.org/web/packages/performance/index.html

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Adriaan de Jong
Gesendet: Mittwoch, 9. M?rz 2022 08:28
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] How to activate the overdisp_fun function?

Dear list members,
For informed choices between poisson and negative binomial models, I've been
advised to check preliminary poisson models with the overdisp_fun function
in accordance with Ben Bolker's glmmFAQ github site (link below).
Unfortunately, I only receive the "Error in overdisp_fun(mod30) : could not
find function "overdisp_fun" message (for poisson glmer model "mod30"). I've
installed packages MASS, lme4, nlme, mgcv and glmmTMB and run my script
under R 4.1.2. Model "mod30" runs and plots flawless. Internet searches
haven't helped me. What am I doing wrong and/or where sits this overdisp_fun
function?
Thanks in advance for hints and comments,
Cheers,
Adjan

Adriaan "Adjan" de Jong
Associate professor
Swedish University of Agricultural Sciences



https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html




---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina
personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r
<https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more
information on how this is done, click here
<https://www.slu.se/en/about-slu/contact-slu/personal-data/>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From Adr|@@n@de@Jong @end|ng |rom @|u@@e  Wed Mar  9 09:29:43 2022
From: Adr|@@n@de@Jong @end|ng |rom @|u@@e (Adriaan de Jong)
Date: Wed, 9 Mar 2022 08:29:43 +0000
Subject: [R-sig-ME] How to activate the overdisp_fun function?
In-Reply-To: <000201d83389$725c7e30$57157a90$@uke.de>
References: <b19bcd2032e74dcb913a17ba19c88a27@Exch2-3.slu.se>
 <000201d83389$725c7e30$57157a90$@uke.de>
Message-ID: <47659f5a067c4e309b530a7256ea1079@Exch2-3.slu.se>

Dear Daniel,
Great! Thanks for your help.
Both alternatives work well (the second with the check_overdispersion function call instead of overdisp_fun).
Cheers,
Adjan

-----Original Message-----
From: Daniel L?decke <d.luedecke at uke.de>
Sent: den 9 mars 2022 08:44
To: Adriaan de Jong <Adriaan.de.Jong at slu.se>; r-sig-mixed-models at r-project.org
Subject: AW: [R-sig-ME] How to activate the overdisp_fun function?

Dear Adriaan,
the function is a code snippet that you need to copy/paste from the referenced FAQ. However, there's an implementation in the
performance-package:

https://easystats.github.io/performance/reference/check_overdispersion.html

You can install that package from CRAN:
https://cran.r-project.org/web/packages/performance/index.html

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von Adriaan de Jong
Gesendet: Mittwoch, 9. M?rz 2022 08:28
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] How to activate the overdisp_fun function?

Dear list members,
For informed choices between poisson and negative binomial models, I've been advised to check preliminary poisson models with the overdisp_fun function in accordance with Ben Bolker's glmmFAQ github site (link below).
Unfortunately, I only receive the "Error in overdisp_fun(mod30) : could not find function "overdisp_fun" message (for poisson glmer model "mod30"). I've installed packages MASS, lme4, nlme, mgcv and glmmTMB and run my script under R 4.1.2. Model "mod30" runs and plots flawless. Internet searches haven't helped me. What am I doing wrong and/or where sits this overdisp_fun function?
Thanks in advance for hints and comments, Cheers, Adjan

Adriaan "Adjan" de Jong
Associate professor
Swedish University of Agricultural Sciences



https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html




---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel _____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Wed Mar  9 15:15:13 2022
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Wed, 9 Mar 2022 14:15:13 +0000
Subject: [R-sig-ME] 
 Poisson intercept-only multilevel model doesn't appear
 to return the correct population mean
Message-ID: <DM6PR04MB4474A526398B5DCC8121DCFDF10A9@DM6PR04MB4474.namprd04.prod.outlook.com>

This happens precisely because there is a random effect in the model 'glmm3.2'. We have a model that basically says that log Y is normally distributed with an estimate mean of 2.424. That implies that Y is lognormal, and therefore 

    E[Y] = exp(mu + sigma^2/2)

If you use VarCorr(glmm3.2) to get the estimate of sigma^2, and add half of that before you exponentiate, you'll get a lot closer to the estimate you expect.

Russ Lenth

-----Original Message-----

Date: Tue, 8 Mar 2022 16:18:23 -0800
From: John Willoughby <johnwillec at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Poisson intercept-only multilevel model doesn't
	appear to return the correct population mean
Message-ID:
	<CAKk2L3J7JMZ+N2bNGpZfKZ-Rp+cFoEYU++XnJN6=WZeQMTdXYQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

I have a data set consisting of counts of a particular plant species in quadrats. The data were collected using a two-stage sampling design, whereby 75 macroplots were randomly positioned in the area to be sampled and five quadrats (actually belt transects) were sampled in each macroplot. All of the macroplots are the same size, 25m x 25m, as are the quadrats (each quadrat is 0.25m x 25m).

The data file is available here:
https://www.dropbox.com/s/hpptsqap0oysje8/stratum3.csv?dl=0

There are five variables in the data file: plot_id is a unique number assigned to each macroplot (there are 75 unique numbers but these are not all consecutive); belt_number is the number (1-5) of each belt transect (quadrat) in each macroplot; counts contains the number of individuals counted in each belt, weights1 contains sampling weights for the macroplots (stage 1) and weights2 contains sampling weights for the quadrats (stage 2).

The mean number of plants per quadrat for this dataset is 44.24. Several covariates were measured in each of the quadrats, but I'm ignoring these here and they are not included in the data file.
Instead, I'd like to focus on the estimated population mean I get from running several different regressions below. Also, the data are overdispersed and a negative binomial model seems appropriate, but I use the Poisson here because it's available in the svyglm() function.

First I present the results from calculating the mean and standard error from the survey package.
I set the following survey design:

cnt_design3 <- svydesign(weights = ~ weights1 + weights2,
                       id = ~plot_id + belt_number,
                       strata = ~stratum_num,
                       data = stratum3,
                       nest = TRUE)

(Sampling weights aren't really required here since the weights are equal in each of the two stages.
We'd get the same results if we left them out.)

Running svymean() using this design I get:
svymean(~counts, design = cnt_design3)
       mean     SE
counts 44.24 9.8146

If I use glmmTMB and run an intercept-only multilevel model assuming
(incorrectly) a gaussian
distribution, I get:

glmm3 <- glmmTMB(counts ~ 1 + (1|plot_id), data = stratum3) Conditional model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   44.240      9.749   4.538 5.68e-06 ***

The mean is exactly the same as that from svymean() and the SE is very close.

My question arises when I use a Poisson regression on the data set. Here I focus only on the estimated population mean and not the standard error since the standard error can't be correctly exponentiated.

If I use svyglm() from the survey package and a quasipoisson distribution I
get:

svyglm2 <- svyglm(formula = counts ~ 1, design = cnt_design3, family =
quasipoisson)
Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   3.7896     0.2218   17.08   <2e-16 ***
> exp(coef(svyglm2))
(Intercept)
      44.24

This is the same mean as returned by the other analyses above.

But if I use glmmTMB to run a multilevel model with family = poisson I get the following:
glmm3.2 <- glmmTMB(counts ~ 1 + (1|plot_id), data = stratum3,
                  family = poisson)
> fixef(glmm3.2)

Conditional model:
(Intercept)
      2.424
which when exponentiated:
> exp(fixef(glmm3.2)[[1]])
(Intercept)
   11.29252

So my question is why don't I get the same value as I get from the other analyses, particularly the svyglm() function using quasipoisson? I don't think it's an issue with geometric vs arithmetic means. If I ignore the two-stage design and pretend that all 375 quadrats were randomly positioned in the population and then run an intercept-only model with family = poisson I get the correct mean value of 44.24:

glmm3_no_random <- glmmTMB(counts ~ 1, data = stratum3,
                          family = poisson)
> fixef(glmm3_no_random)

Conditional model:
(Intercept)
       3.79
which when exponentiated:
> exp(fixef(glmm3_no_random)[[1]])
(Intercept)
      44.24

Why would including random intercepts for plot change the grand mean
(exponentiated) from
44.24 to 11.29? Note that this only happens with the multilevel Poisson regression and not the multilevel Gaussian. I suspect I'm missing something, but I'll be darned if I can figure out what.

Thanks for any help you can provide.

John Willoughby

From jungm@@rten @end|ng |rom gm@||@com  Wed Mar  9 15:52:46 2022
From: jungm@@rten @end|ng |rom gm@||@com (Maarten Jung)
Date: Wed, 9 Mar 2022 15:52:46 +0100
Subject: [R-sig-ME] 
 Poisson intercept-only multilevel model doesn't appear
 to return the correct population mean
In-Reply-To: <CAKk2L3J7JMZ+N2bNGpZfKZ-Rp+cFoEYU++XnJN6=WZeQMTdXYQ@mail.gmail.com>
References: <CAKk2L3J7JMZ+N2bNGpZfKZ-Rp+cFoEYU++XnJN6=WZeQMTdXYQ@mail.gmail.com>
Message-ID: <ec308b91-5069-42d3-0062-afe9f1873821@gmail.com>

Dear John,

> Why would including random intercepts for plot change the grand mean
> (exponentiated) from
> 44.24 to 11.29? Note that this only happens with the multilevel Poisson
> regression and not the
> multilevel Gaussian. I suspect I'm missing something, but I'll be 
> darned if
> I can figure out what.
In generalized linear mixed models the fixed population effects in the 
marginal and conditional model are in general different (taking the 
expectation of a nonlinear function of a random variable is not the same 
as taking the expectation of that random variable first and then 
applying the nonlinear function).
In particular, for the log-linear Poisson random intercept model, the 
amount by which the intercept terms will differ depends on the random 
effects variance.

Best,
Maarten


From |@w|@wt @end|ng |rom gm@||@com  Wed Mar  9 18:58:52 2022
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Wed, 9 Mar 2022 11:58:52 -0600
Subject: [R-sig-ME] Post hoc on glmer for specific hypotheses
Message-ID: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>

Hello All,

My glmer model below analyzes the performance of a single group of
subjects on a test at two time points. The test has 4 item types.

Data and code are below.

Is there a way to test only the following two hypotheses?

1- ((Baseline multiple-choice_grammar) - (Post-test
multiple-choice_grammar)) - (Baseline production_grammar - (Post-test
production_grammar))

2- ((Baseline multiple-choice_vocabulary) - (Post-test
multiple-choice_vocabulary)) - (Baseline production_vocabulary -
(Post-test production_vocabulary))

dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")

form2 <- y ~ item_type*time + (1 | user_id)

m2 <- glmer(form2, family = binomial, data = dat,
            control =
              glmerControl(optimizer = "bobyqa"))

Sincerely,
Tim M


From bbo|ker @end|ng |rom gm@||@com  Wed Mar  9 19:22:11 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 9 Mar 2022 13:22:11 -0500
Subject: [R-sig-ME] Post hoc on glmer for specific hypotheses
In-Reply-To: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
Message-ID: <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>

  One way to do this would be via `multcomp::glht`, which allows you
to specify any linear combination(s) of parameters to test.  You do
have to figure out the association between the parameters you have and
the contrasts you want. I wrote some (possibly scrutable) stuff about
that problem here:
http://bbolker.github.io/bbmisc/mgreen_contrasts.html

  by hand:

  assuming factor levels are {baseline, post} and {MC, prod}

baseline_MC = intercept
post_MC = intercept + time_post
baseline_prod = intercept + gram_prod
post_prod = intercept + time_post + gram_prod + interax

so your first contrast would be {(intercept - (intercept + time_post))
- (intercept + gram_prod - (intercept + time_post + gram_prod +
interax))
   = (-time_post -time_post - interax) = (-2*time_post - interax)

so the contrast would be (0, -2, 0, -1) assuming that the parameters
are ordered (intercept, time_post, gram_prod, interax)

   (1) You should definitely check my algebra; (2) there may be a
quicker (if less transparent) way to do this by setting up appropriate
contrasts from the beginning; (3) I noticed that I left the "vocab"
levels out of the analysis, but I don't think that changes anything
important.


On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>
> Hello All,
>
> My glmer model below analyzes the performance of a single group of
> subjects on a test at two time points. The test has 4 item types.
>
> Data and code are below.
>
> Is there a way to test only the following two hypotheses?
>
> 1- ((Baseline multiple-choice_grammar) - (Post-test
> multiple-choice_grammar)) - (Baseline production_grammar - (Post-test
> production_grammar))
>
> 2- ((Baseline multiple-choice_vocabulary) - (Post-test
> multiple-choice_vocabulary)) - (Baseline production_vocabulary -
> (Post-test production_vocabulary))
>
> dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
>
> form2 <- y ~ item_type*time + (1 | user_id)
>
> m2 <- glmer(form2, family = binomial, data = dat,
>             control =
>               glmerControl(optimizer = "bobyqa"))
>
> Sincerely,
> Tim M
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |@w|@wt @end|ng |rom gm@||@com  Wed Mar  9 19:46:05 2022
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Wed, 9 Mar 2022 12:46:05 -0600
Subject: [R-sig-ME] Post hoc on glmer for specific hypotheses
In-Reply-To: <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
 <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
Message-ID: <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>

Thanks, Ben! Apparently, the 7th coefficient in the glmer() output
tests the first hypothesis that I'm looking for.

For the second hypothesis, I was able to use emmeans::emmeans() to get
what I want by running:

ems <- emmeans(m2, pairwise ~ time*item_type, type = "response",infer
= c(FALSE, TRUE), adjust = "tukey")[[2]]
vv <- pairs(ems, simple = "each", infer = c(FALSE, TRUE), type =
"response") # on log-odds scale

In this set up, vv[288, ] tests the second hypothesis. But on the Log
odds scale. Is there any way to convert it back to the response scale?

Thanks,
Tim M

On Wed, Mar 9, 2022 at 12:22 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>   One way to do this would be via `multcomp::glht`, which allows you
> to specify any linear combination(s) of parameters to test.  You do
> have to figure out the association between the parameters you have and
> the contrasts you want. I wrote some (possibly scrutable) stuff about
> that problem here:
> http://bbolker.github.io/bbmisc/mgreen_contrasts.html
>
>   by hand:
>
>   assuming factor levels are {baseline, post} and {MC, prod}
>
> baseline_MC = intercept
> post_MC = intercept + time_post
> baseline_prod = intercept + gram_prod
> post_prod = intercept + time_post + gram_prod + interax
>
> so your first contrast would be {(intercept - (intercept + time_post))
> - (intercept + gram_prod - (intercept + time_post + gram_prod +
> interax))
>    = (-time_post -time_post - interax) = (-2*time_post - interax)
>
> so the contrast would be (0, -2, 0, -1) assuming that the parameters
> are ordered (intercept, time_post, gram_prod, interax)
>
>    (1) You should definitely check my algebra; (2) there may be a
> quicker (if less transparent) way to do this by setting up appropriate
> contrasts from the beginning; (3) I noticed that I left the "vocab"
> levels out of the analysis, but I don't think that changes anything
> important.
>
>
> On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> >
> > Hello All,
> >
> > My glmer model below analyzes the performance of a single group of
> > subjects on a test at two time points. The test has 4 item types.
> >
> > Data and code are below.
> >
> > Is there a way to test only the following two hypotheses?
> >
> > 1- ((Baseline multiple-choice_grammar) - (Post-test
> > multiple-choice_grammar)) - (Baseline production_grammar - (Post-test
> > production_grammar))
> >
> > 2- ((Baseline multiple-choice_vocabulary) - (Post-test
> > multiple-choice_vocabulary)) - (Baseline production_vocabulary -
> > (Post-test production_vocabulary))
> >
> > dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> >
> > form2 <- y ~ item_type*time + (1 | user_id)
> >
> > m2 <- glmer(form2, family = binomial, data = dat,
> >             control =
> >               glmerControl(optimizer = "bobyqa"))
> >
> > Sincerely,
> > Tim M
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Wed Mar  9 20:13:56 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 9 Mar 2022 14:13:56 -0500
Subject: [R-sig-ME] Post hoc on glmer for specific hypotheses
In-Reply-To: <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
 <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
 <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>
Message-ID: <CABghstTji+sNP5ZPzJGymLosgwoQkVn9wogrRs+vUx0RVG48Rg@mail.gmail.com>

     Hmm.  Why would you want to test on the response scale?  It
almost always makes sense to test contrasts on the link scale, where
the sampling distributions of the parameters are more likely to be
approximately Gaussian.
     I haven't gone to look at your data/problem in detail, but I'm a
little bit surprised that `type="response"` doesn't exponentiate, i.e.
convert the estimated values from the log-odds to the odds scale?
(Converting to the probability scale is not really feasible because of
the way the math works out ...)

On Wed, Mar 9, 2022 at 1:46 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>
> Thanks, Ben! Apparently, the 7th coefficient in the glmer() output
> tests the first hypothesis that I'm looking for.
>
> For the second hypothesis, I was able to use emmeans::emmeans() to get
> what I want by running:
>
> ems <- emmeans(m2, pairwise ~ time*item_type, type = "response",infer
> = c(FALSE, TRUE), adjust = "tukey")[[2]]
> vv <- pairs(ems, simple = "each", infer = c(FALSE, TRUE), type =
> "response") # on log-odds scale
>
> In this set up, vv[288, ] tests the second hypothesis. But on the Log
> odds scale. Is there any way to convert it back to the response scale?
>
> Thanks,
> Tim M
>
> On Wed, Mar 9, 2022 at 12:22 PM Ben Bolker <bbolker at gmail.com> wrote:
> >
> >   One way to do this would be via `multcomp::glht`, which allows you
> > to specify any linear combination(s) of parameters to test.  You do
> > have to figure out the association between the parameters you have and
> > the contrasts you want. I wrote some (possibly scrutable) stuff about
> > that problem here:
> > http://bbolker.github.io/bbmisc/mgreen_contrasts.html
> >
> >   by hand:
> >
> >   assuming factor levels are {baseline, post} and {MC, prod}
> >
> > baseline_MC = intercept
> > post_MC = intercept + time_post
> > baseline_prod = intercept + gram_prod
> > post_prod = intercept + time_post + gram_prod + interax
> >
> > so your first contrast would be {(intercept - (intercept + time_post))
> > - (intercept + gram_prod - (intercept + time_post + gram_prod +
> > interax))
> >    = (-time_post -time_post - interax) = (-2*time_post - interax)
> >
> > so the contrast would be (0, -2, 0, -1) assuming that the parameters
> > are ordered (intercept, time_post, gram_prod, interax)
> >
> >    (1) You should definitely check my algebra; (2) there may be a
> > quicker (if less transparent) way to do this by setting up appropriate
> > contrasts from the beginning; (3) I noticed that I left the "vocab"
> > levels out of the analysis, but I don't think that changes anything
> > important.
> >
> >
> > On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> > >
> > > Hello All,
> > >
> > > My glmer model below analyzes the performance of a single group of
> > > subjects on a test at two time points. The test has 4 item types.
> > >
> > > Data and code are below.
> > >
> > > Is there a way to test only the following two hypotheses?
> > >
> > > 1- ((Baseline multiple-choice_grammar) - (Post-test
> > > multiple-choice_grammar)) - (Baseline production_grammar - (Post-test
> > > production_grammar))
> > >
> > > 2- ((Baseline multiple-choice_vocabulary) - (Post-test
> > > multiple-choice_vocabulary)) - (Baseline production_vocabulary -
> > > (Post-test production_vocabulary))
> > >
> > > dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> > >
> > > form2 <- y ~ item_type*time + (1 | user_id)
> > >
> > > m2 <- glmer(form2, family = binomial, data = dat,
> > >             control =
> > >               glmerControl(optimizer = "bobyqa"))
> > >
> > > Sincerely,
> > > Tim M
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |@w|@wt @end|ng |rom gm@||@com  Wed Mar  9 20:21:21 2022
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Wed, 9 Mar 2022 13:21:21 -0600
Subject: [R-sig-ME] Post hoc on glmer for specific hypotheses
In-Reply-To: <CABghstTji+sNP5ZPzJGymLosgwoQkVn9wogrRs+vUx0RVG48Rg@mail.gmail.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
 <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
 <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>
 <CABghstTji+sNP5ZPzJGymLosgwoQkVn9wogrRs+vUx0RVG48Rg@mail.gmail.com>
Message-ID: <CADreqiz2Y2j04WipS+1c3xwC1ssopommQqjVrnoatP7vp942DQ@mail.gmail.com>

Ben, type = "response" exponentiates the link-scale results. It just
seems that it doesn't work inside the pairs(...) call. Russ can better
speak to that.

emmeans provides the capability to convert the results from the link
scale into the odds scale (which for comparisons would be odds
ratios).

On Wed, Mar 9, 2022 at 1:14 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>      Hmm.  Why would you want to test on the response scale?  It
> almost always makes sense to test contrasts on the link scale, where
> the sampling distributions of the parameters are more likely to be
> approximately Gaussian.
>      I haven't gone to look at your data/problem in detail, but I'm a
> little bit surprised that `type="response"` doesn't exponentiate, i.e.
> convert the estimated values from the log-odds to the odds scale?
> (Converting to the probability scale is not really feasible because of
> the way the math works out ...)
>
> On Wed, Mar 9, 2022 at 1:46 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> >
> > Thanks, Ben! Apparently, the 7th coefficient in the glmer() output
> > tests the first hypothesis that I'm looking for.
> >
> > For the second hypothesis, I was able to use emmeans::emmeans() to get
> > what I want by running:
> >
> > ems <- emmeans(m2, pairwise ~ time*item_type, type = "response",infer
> > = c(FALSE, TRUE), adjust = "tukey")[[2]]
> > vv <- pairs(ems, simple = "each", infer = c(FALSE, TRUE), type =
> > "response") # on log-odds scale
> >
> > In this set up, vv[288, ] tests the second hypothesis. But on the Log
> > odds scale. Is there any way to convert it back to the response scale?
> >
> > Thanks,
> > Tim M
> >
> > On Wed, Mar 9, 2022 at 12:22 PM Ben Bolker <bbolker at gmail.com> wrote:
> > >
> > >   One way to do this would be via `multcomp::glht`, which allows you
> > > to specify any linear combination(s) of parameters to test.  You do
> > > have to figure out the association between the parameters you have and
> > > the contrasts you want. I wrote some (possibly scrutable) stuff about
> > > that problem here:
> > > http://bbolker.github.io/bbmisc/mgreen_contrasts.html
> > >
> > >   by hand:
> > >
> > >   assuming factor levels are {baseline, post} and {MC, prod}
> > >
> > > baseline_MC = intercept
> > > post_MC = intercept + time_post
> > > baseline_prod = intercept + gram_prod
> > > post_prod = intercept + time_post + gram_prod + interax
> > >
> > > so your first contrast would be {(intercept - (intercept + time_post))
> > > - (intercept + gram_prod - (intercept + time_post + gram_prod +
> > > interax))
> > >    = (-time_post -time_post - interax) = (-2*time_post - interax)
> > >
> > > so the contrast would be (0, -2, 0, -1) assuming that the parameters
> > > are ordered (intercept, time_post, gram_prod, interax)
> > >
> > >    (1) You should definitely check my algebra; (2) there may be a
> > > quicker (if less transparent) way to do this by setting up appropriate
> > > contrasts from the beginning; (3) I noticed that I left the "vocab"
> > > levels out of the analysis, but I don't think that changes anything
> > > important.
> > >
> > >
> > > On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> > > >
> > > > Hello All,
> > > >
> > > > My glmer model below analyzes the performance of a single group of
> > > > subjects on a test at two time points. The test has 4 item types.
> > > >
> > > > Data and code are below.
> > > >
> > > > Is there a way to test only the following two hypotheses?
> > > >
> > > > 1- ((Baseline multiple-choice_grammar) - (Post-test
> > > > multiple-choice_grammar)) - (Baseline production_grammar - (Post-test
> > > > production_grammar))
> > > >
> > > > 2- ((Baseline multiple-choice_vocabulary) - (Post-test
> > > > multiple-choice_vocabulary)) - (Baseline production_vocabulary -
> > > > (Post-test production_vocabulary))
> > > >
> > > > dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> > > >
> > > > form2 <- y ~ item_type*time + (1 | user_id)
> > > >
> > > > m2 <- glmer(form2, family = binomial, data = dat,
> > > >             control =
> > > >               glmerControl(optimizer = "bobyqa"))
> > > >
> > > > Sincerely,
> > > > Tim M
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Wed Mar  9 20:24:03 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 9 Mar 2022 14:24:03 -0500
Subject: [R-sig-ME] Post hoc on glmer for specific hypotheses
In-Reply-To: <CADreqiz2Y2j04WipS+1c3xwC1ssopommQqjVrnoatP7vp942DQ@mail.gmail.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
 <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
 <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>
 <CABghstTji+sNP5ZPzJGymLosgwoQkVn9wogrRs+vUx0RVG48Rg@mail.gmail.com>
 <CADreqiz2Y2j04WipS+1c3xwC1ssopommQqjVrnoatP7vp942DQ@mail.gmail.com>
Message-ID: <CABghstRGFDks+QR-1y-Ppxw4p4FAsKOPS6f1_rCP=ZC5+w7Asw@mail.gmail.com>

  That's fine.  (You could always extract the values and exponentiate
them yourself ...)
 I still can't tell whether there are any remaining issues, i.e. if
type="response" worked as expected would you be happy? (Noting that
the significance tests of the contrasts would still be based on the
estimates and SDs from the log-odds scale ...)

On Wed, Mar 9, 2022 at 2:21 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>
> Ben, type = "response" exponentiates the link-scale results. It just
> seems that it doesn't work inside the pairs(...) call. Russ can better
> speak to that.
>
> emmeans provides the capability to convert the results from the link
> scale into the odds scale (which for comparisons would be odds
> ratios).
>
> On Wed, Mar 9, 2022 at 1:14 PM Ben Bolker <bbolker at gmail.com> wrote:
> >
> >      Hmm.  Why would you want to test on the response scale?  It
> > almost always makes sense to test contrasts on the link scale, where
> > the sampling distributions of the parameters are more likely to be
> > approximately Gaussian.
> >      I haven't gone to look at your data/problem in detail, but I'm a
> > little bit surprised that `type="response"` doesn't exponentiate, i.e.
> > convert the estimated values from the log-odds to the odds scale?
> > (Converting to the probability scale is not really feasible because of
> > the way the math works out ...)
> >
> > On Wed, Mar 9, 2022 at 1:46 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> > >
> > > Thanks, Ben! Apparently, the 7th coefficient in the glmer() output
> > > tests the first hypothesis that I'm looking for.
> > >
> > > For the second hypothesis, I was able to use emmeans::emmeans() to get
> > > what I want by running:
> > >
> > > ems <- emmeans(m2, pairwise ~ time*item_type, type = "response",infer
> > > = c(FALSE, TRUE), adjust = "tukey")[[2]]
> > > vv <- pairs(ems, simple = "each", infer = c(FALSE, TRUE), type =
> > > "response") # on log-odds scale
> > >
> > > In this set up, vv[288, ] tests the second hypothesis. But on the Log
> > > odds scale. Is there any way to convert it back to the response scale?
> > >
> > > Thanks,
> > > Tim M
> > >
> > > On Wed, Mar 9, 2022 at 12:22 PM Ben Bolker <bbolker at gmail.com> wrote:
> > > >
> > > >   One way to do this would be via `multcomp::glht`, which allows you
> > > > to specify any linear combination(s) of parameters to test.  You do
> > > > have to figure out the association between the parameters you have and
> > > > the contrasts you want. I wrote some (possibly scrutable) stuff about
> > > > that problem here:
> > > > http://bbolker.github.io/bbmisc/mgreen_contrasts.html
> > > >
> > > >   by hand:
> > > >
> > > >   assuming factor levels are {baseline, post} and {MC, prod}
> > > >
> > > > baseline_MC = intercept
> > > > post_MC = intercept + time_post
> > > > baseline_prod = intercept + gram_prod
> > > > post_prod = intercept + time_post + gram_prod + interax
> > > >
> > > > so your first contrast would be {(intercept - (intercept + time_post))
> > > > - (intercept + gram_prod - (intercept + time_post + gram_prod +
> > > > interax))
> > > >    = (-time_post -time_post - interax) = (-2*time_post - interax)
> > > >
> > > > so the contrast would be (0, -2, 0, -1) assuming that the parameters
> > > > are ordered (intercept, time_post, gram_prod, interax)
> > > >
> > > >    (1) You should definitely check my algebra; (2) there may be a
> > > > quicker (if less transparent) way to do this by setting up appropriate
> > > > contrasts from the beginning; (3) I noticed that I left the "vocab"
> > > > levels out of the analysis, but I don't think that changes anything
> > > > important.
> > > >
> > > >
> > > > On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> > > > >
> > > > > Hello All,
> > > > >
> > > > > My glmer model below analyzes the performance of a single group of
> > > > > subjects on a test at two time points. The test has 4 item types.
> > > > >
> > > > > Data and code are below.
> > > > >
> > > > > Is there a way to test only the following two hypotheses?
> > > > >
> > > > > 1- ((Baseline multiple-choice_grammar) - (Post-test
> > > > > multiple-choice_grammar)) - (Baseline production_grammar - (Post-test
> > > > > production_grammar))
> > > > >
> > > > > 2- ((Baseline multiple-choice_vocabulary) - (Post-test
> > > > > multiple-choice_vocabulary)) - (Baseline production_vocabulary -
> > > > > (Post-test production_vocabulary))
> > > > >
> > > > > dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> > > > >
> > > > > form2 <- y ~ item_type*time + (1 | user_id)
> > > > >
> > > > > m2 <- glmer(form2, family = binomial, data = dat,
> > > > >             control =
> > > > >               glmerControl(optimizer = "bobyqa"))
> > > > >
> > > > > Sincerely,
> > > > > Tim M
> > > > >
> > > > > _______________________________________________
> > > > > R-sig-mixed-models at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Wed Mar  9 20:37:52 2022
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Wed, 9 Mar 2022 19:37:52 +0000
Subject: [R-sig-ME] [External] Post hoc on glmer for specific hypotheses
In-Reply-To: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
Message-ID: <DM6PR04MB447448B6A18C53D863BCF63DF10A9@DM6PR04MB4474.namprd04.prod.outlook.com>

This would be straightforward using the emmeans package. Just do:

        library(emmeans)
        EMM <- emmeans(m2, ~ item_type * time)
        EMM   # to list the estimates

Then, note the order of those four estimates, and set up the desired contrasts manually:

        CON <- list(c1 = c(...), c2 = c(...))
        contrast(EMM, CON)

where c1 and c2 consist of contrast coefficients of 1 and -1 corresponding to the stated contrasts.

I suppose it is possible to do this via some clever choice of contrast codings for the model such that the needed ones are estimated as the interaction coefficient infixef(m2). However, you would have to do it twice with two different codings, since both of the stated contrasts are interaction contrasts, and we can only estimate one such interaction per model. Generally, I think trying to estimate meaningful things via regression coefficients is overrated. Except in one-factor models, it is too easy to get things wrong.

Russ Lenth

-----Original Message-----
From: Timothy MacKenzie <fswfswt at gmail.com> 
Sent: Wednesday, March 9, 2022 11:59 AM
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Cc: Lenth, Russell V <russell-lenth at uiowa.edu>
Subject: [External] Post hoc on glmer for specific hypotheses

Hello All,

My glmer model below analyzes the performance of a single group of subjects on a test at two time points. The test has 4 item types.

Data and code are below.

Is there a way to test only the following two hypotheses?

1- ((Baseline multiple-choice_grammar) - (Post-test
multiple-choice_grammar)) - (Baseline production_grammar - (Post-test
production_grammar))

2- ((Baseline multiple-choice_vocabulary) - (Post-test
multiple-choice_vocabulary)) - (Baseline production_vocabulary - (Post-test production_vocabulary))

dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")

form2 <- y ~ item_type*time + (1 | user_id)

m2 <- glmer(form2, family = binomial, data = dat,
            control =
              glmerControl(optimizer = "bobyqa"))

Sincerely,
Tim M

From ru@@e||-|enth @end|ng |rom u|ow@@edu  Wed Mar  9 20:48:35 2022
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Wed, 9 Mar 2022 19:48:35 +0000
Subject: [R-sig-ME] 
 [External] Re: Post hoc on glmer for specific hypotheses
In-Reply-To: <CADreqiz2Y2j04WipS+1c3xwC1ssopommQqjVrnoatP7vp942DQ@mail.gmail.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
 <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
 <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>
 <CABghstTji+sNP5ZPzJGymLosgwoQkVn9wogrRs+vUx0RVG48Rg@mail.gmail.com>
 <CADreqiz2Y2j04WipS+1c3xwC1ssopommQqjVrnoatP7vp942DQ@mail.gmail.com>
Message-ID: <DM6PR04MB447416ED68478925804FD5B2F10A9@DM6PR04MB4474.namprd04.prod.outlook.com>

I believe that this doesn't do what you think it does. Specifying 'type = "response"' does not change the way the tests are done, it just changes the scale upon which the results are presented. If you really want those contrasts computed on the response scale, then (using the setup I showed previously) do:

        contrast(regrid(EMM), CON)

... which will convert everything to the response scale before computing the contrasts.

Russ

-----Original Message-----
From: Timothy MacKenzie <fswfswt at gmail.com> 
Sent: Wednesday, March 9, 2022 1:21 PM
To: Ben Bolker <bbolker at gmail.com>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Lenth, Russell V <russell-lenth at uiowa.edu>
Subject: [External] Re: [R-sig-ME] Post hoc on glmer for specific hypotheses

Ben, type = "response" exponentiates the link-scale results. It just seems that it doesn't work inside the pairs(...) call. Russ can better speak to that.

emmeans provides the capability to convert the results from the link scale into the odds scale (which for comparisons would be odds ratios).

On Wed, Mar 9, 2022 at 1:14 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>      Hmm.  Why would you want to test on the response scale?  It 
> almost always makes sense to test contrasts on the link scale, where 
> the sampling distributions of the parameters are more likely to be 
> approximately Gaussian.
>      I haven't gone to look at your data/problem in detail, but I'm a 
> little bit surprised that `type="response"` doesn't exponentiate, i.e.
> convert the estimated values from the log-odds to the odds scale?
> (Converting to the probability scale is not really feasible because of 
> the way the math works out ...)
>
> On Wed, Mar 9, 2022 at 1:46 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> >
> > Thanks, Ben! Apparently, the 7th coefficient in the glmer() output 
> > tests the first hypothesis that I'm looking for.
> >
> > For the second hypothesis, I was able to use emmeans::emmeans() to 
> > get what I want by running:
> >
> > ems <- emmeans(m2, pairwise ~ time*item_type, type = 
> > "response",infer = c(FALSE, TRUE), adjust = "tukey")[[2]] vv <- 
> > pairs(ems, simple = "each", infer = c(FALSE, TRUE), type =
> > "response") # on log-odds scale
> >
> > In this set up, vv[288, ] tests the second hypothesis. But on the 
> > Log odds scale. Is there any way to convert it back to the response scale?
> >
> > Thanks,
> > Tim M
> >
> > On Wed, Mar 9, 2022 at 12:22 PM Ben Bolker <bbolker at gmail.com> wrote:
> > >
> > >   One way to do this would be via `multcomp::glht`, which allows 
> > > you to specify any linear combination(s) of parameters to test.  
> > > You do have to figure out the association between the parameters 
> > > you have and the contrasts you want. I wrote some (possibly 
> > > scrutable) stuff about that problem here:
> > > http://bbolker.github.io/bbmisc/mgreen_contrasts.html
> > >
> > >   by hand:
> > >
> > >   assuming factor levels are {baseline, post} and {MC, prod}
> > >
> > > baseline_MC = intercept
> > > post_MC = intercept + time_post
> > > baseline_prod = intercept + gram_prod post_prod = intercept + 
> > > time_post + gram_prod + interax
> > >
> > > so your first contrast would be {(intercept - (intercept + 
> > > time_post))
> > > - (intercept + gram_prod - (intercept + time_post + gram_prod +
> > > interax))
> > >    = (-time_post -time_post - interax) = (-2*time_post - interax)
> > >
> > > so the contrast would be (0, -2, 0, -1) assuming that the 
> > > parameters are ordered (intercept, time_post, gram_prod, interax)
> > >
> > >    (1) You should definitely check my algebra; (2) there may be a 
> > > quicker (if less transparent) way to do this by setting up 
> > > appropriate contrasts from the beginning; (3) I noticed that I left the "vocab"
> > > levels out of the analysis, but I don't think that changes 
> > > anything important.
> > >
> > >
> > > On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> > > >
> > > > Hello All,
> > > >
> > > > My glmer model below analyzes the performance of a single group 
> > > > of subjects on a test at two time points. The test has 4 item types.
> > > >
> > > > Data and code are below.
> > > >
> > > > Is there a way to test only the following two hypotheses?
> > > >
> > > > 1- ((Baseline multiple-choice_grammar) - (Post-test
> > > > multiple-choice_grammar)) - (Baseline production_grammar - 
> > > > (Post-test
> > > > production_grammar))
> > > >
> > > > 2- ((Baseline multiple-choice_vocabulary) - (Post-test
> > > > multiple-choice_vocabulary)) - (Baseline production_vocabulary - 
> > > > (Post-test production_vocabulary))
> > > >
> > > > dat <- 
> > > > read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> > > >
> > > > form2 <- y ~ item_type*time + (1 | user_id)
> > > >
> > > > m2 <- glmer(form2, family = binomial, data = dat,
> > > >             control =
> > > >               glmerControl(optimizer = "bobyqa"))
> > > >
> > > > Sincerely,
> > > > Tim M
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list 
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From |@w|@wt @end|ng |rom gm@||@com  Wed Mar  9 21:11:18 2022
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Wed, 9 Mar 2022 14:11:18 -0600
Subject: [R-sig-ME] 
 [External] Re: Post hoc on glmer for specific hypotheses
In-Reply-To: <DM6PR04MB447416ED68478925804FD5B2F10A9@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
 <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
 <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>
 <CABghstTji+sNP5ZPzJGymLosgwoQkVn9wogrRs+vUx0RVG48Rg@mail.gmail.com>
 <CADreqiz2Y2j04WipS+1c3xwC1ssopommQqjVrnoatP7vp942DQ@mail.gmail.com>
 <DM6PR04MB447416ED68478925804FD5B2F10A9@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <CADreqixBvWYKwMUOnS7FYXVi7-VG6dEu5MeN5zji9B8Lc8Lngg@mail.gmail.com>

Thanks so much Ben and Russ.

Russ, I get an error that says: "Non-character contrast methods are
not supported with nested objects".

For reproducibility here is the full code:

dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")

form2 <- y ~ item_type*time + (1 | user_id)

m2 <- glmer(form2, family = binomial, data = dat,
            control =
              glmerControl(optimizer = "bobyqa"))
#-----------------------------------------------------------------------------------------------
EMM <- emmeans(m2, ~ item_type * time, infer=c(FALSE,FALSE))

CON <- list(c1 = c(1, 0, -1, 0, -1, 0, 1, 0))

contrast(regrid(EMM), CON)

On Wed, Mar 9, 2022 at 1:48 PM Lenth, Russell V <russell-lenth at uiowa.edu> wrote:
>
> I believe that this doesn't do what you think it does. Specifying 'type = "response"' does not change the way the tests are done, it just changes the scale upon which the results are presented. If you really want those contrasts computed on the response scale, then (using the setup I showed previously) do:
>
>         contrast(regrid(EMM), CON)
>
> ... which will convert everything to the response scale before computing the contrasts.
>
> Russ
>
> -----Original Message-----
> From: Timothy MacKenzie <fswfswt at gmail.com>
> Sent: Wednesday, March 9, 2022 1:21 PM
> To: Ben Bolker <bbolker at gmail.com>
> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Lenth, Russell V <russell-lenth at uiowa.edu>
> Subject: [External] Re: [R-sig-ME] Post hoc on glmer for specific hypotheses
>
> Ben, type = "response" exponentiates the link-scale results. It just seems that it doesn't work inside the pairs(...) call. Russ can better speak to that.
>
> emmeans provides the capability to convert the results from the link scale into the odds scale (which for comparisons would be odds ratios).
>
> On Wed, Mar 9, 2022 at 1:14 PM Ben Bolker <bbolker at gmail.com> wrote:
> >
> >      Hmm.  Why would you want to test on the response scale?  It
> > almost always makes sense to test contrasts on the link scale, where
> > the sampling distributions of the parameters are more likely to be
> > approximately Gaussian.
> >      I haven't gone to look at your data/problem in detail, but I'm a
> > little bit surprised that `type="response"` doesn't exponentiate, i.e.
> > convert the estimated values from the log-odds to the odds scale?
> > (Converting to the probability scale is not really feasible because of
> > the way the math works out ...)
> >
> > On Wed, Mar 9, 2022 at 1:46 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> > >
> > > Thanks, Ben! Apparently, the 7th coefficient in the glmer() output
> > > tests the first hypothesis that I'm looking for.
> > >
> > > For the second hypothesis, I was able to use emmeans::emmeans() to
> > > get what I want by running:
> > >
> > > ems <- emmeans(m2, pairwise ~ time*item_type, type =
> > > "response",infer = c(FALSE, TRUE), adjust = "tukey")[[2]] vv <-
> > > pairs(ems, simple = "each", infer = c(FALSE, TRUE), type =
> > > "response") # on log-odds scale
> > >
> > > In this set up, vv[288, ] tests the second hypothesis. But on the
> > > Log odds scale. Is there any way to convert it back to the response scale?
> > >
> > > Thanks,
> > > Tim M
> > >
> > > On Wed, Mar 9, 2022 at 12:22 PM Ben Bolker <bbolker at gmail.com> wrote:
> > > >
> > > >   One way to do this would be via `multcomp::glht`, which allows
> > > > you to specify any linear combination(s) of parameters to test.
> > > > You do have to figure out the association between the parameters
> > > > you have and the contrasts you want. I wrote some (possibly
> > > > scrutable) stuff about that problem here:
> > > > http://bbolker.github.io/bbmisc/mgreen_contrasts.html
> > > >
> > > >   by hand:
> > > >
> > > >   assuming factor levels are {baseline, post} and {MC, prod}
> > > >
> > > > baseline_MC = intercept
> > > > post_MC = intercept + time_post
> > > > baseline_prod = intercept + gram_prod post_prod = intercept +
> > > > time_post + gram_prod + interax
> > > >
> > > > so your first contrast would be {(intercept - (intercept +
> > > > time_post))
> > > > - (intercept + gram_prod - (intercept + time_post + gram_prod +
> > > > interax))
> > > >    = (-time_post -time_post - interax) = (-2*time_post - interax)
> > > >
> > > > so the contrast would be (0, -2, 0, -1) assuming that the
> > > > parameters are ordered (intercept, time_post, gram_prod, interax)
> > > >
> > > >    (1) You should definitely check my algebra; (2) there may be a
> > > > quicker (if less transparent) way to do this by setting up
> > > > appropriate contrasts from the beginning; (3) I noticed that I left the "vocab"
> > > > levels out of the analysis, but I don't think that changes
> > > > anything important.
> > > >
> > > >
> > > > On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> > > > >
> > > > > Hello All,
> > > > >
> > > > > My glmer model below analyzes the performance of a single group
> > > > > of subjects on a test at two time points. The test has 4 item types.
> > > > >
> > > > > Data and code are below.
> > > > >
> > > > > Is there a way to test only the following two hypotheses?
> > > > >
> > > > > 1- ((Baseline multiple-choice_grammar) - (Post-test
> > > > > multiple-choice_grammar)) - (Baseline production_grammar -
> > > > > (Post-test
> > > > > production_grammar))
> > > > >
> > > > > 2- ((Baseline multiple-choice_vocabulary) - (Post-test
> > > > > multiple-choice_vocabulary)) - (Baseline production_vocabulary -
> > > > > (Post-test production_vocabulary))
> > > > >
> > > > > dat <-
> > > > > read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> > > > >
> > > > > form2 <- y ~ item_type*time + (1 | user_id)
> > > > >
> > > > > m2 <- glmer(form2, family = binomial, data = dat,
> > > > >             control =
> > > > >               glmerControl(optimizer = "bobyqa"))
> > > > >
> > > > > Sincerely,
> > > > > Tim M
> > > > >
> > > > > _______________________________________________
> > > > > R-sig-mixed-models at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Wed Mar  9 22:01:56 2022
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Wed, 9 Mar 2022 21:01:56 +0000
Subject: [R-sig-ME] 
 [External] Re: Post hoc on glmer for specific hypotheses
In-Reply-To: <CADreqixBvWYKwMUOnS7FYXVi7-VG6dEu5MeN5zji9B8Lc8Lngg@mail.gmail.com>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
 <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
 <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>
 <CABghstTji+sNP5ZPzJGymLosgwoQkVn9wogrRs+vUx0RVG48Rg@mail.gmail.com>
 <CADreqiz2Y2j04WipS+1c3xwC1ssopommQqjVrnoatP7vp942DQ@mail.gmail.com>
 <DM6PR04MB447416ED68478925804FD5B2F10A9@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CADreqixBvWYKwMUOnS7FYXVi7-VG6dEu5MeN5zji9B8Lc8Lngg@mail.gmail.com>
Message-ID: <9AE06FE5-C7F2-4379-8C07-75B2F4B2A770@uiowa.edu>

Hmmm. I guess try adding ', nesting = NULL' to the call for EMM.

Sent from my iPad

> On Mar 9, 2022, at 2:11 PM, Timothy MacKenzie <fswfswt at gmail.com> wrote:
> 
> ?Thanks so much Ben and Russ.
> 
> Russ, I get an error that says: "Non-character contrast methods are
> not supported with nested objects".
> 
> For reproducibility here is the full code:
> 
> dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> 
> form2 <- y ~ item_type*time + (1 | user_id)
> 
> m2 <- glmer(form2, family = binomial, data = dat,
>            control =
>              glmerControl(optimizer = "bobyqa"))
> #-----------------------------------------------------------------------------------------------
> EMM <- emmeans(m2, ~ item_type * time, infer=c(FALSE,FALSE))
> 
> CON <- list(c1 = c(1, 0, -1, 0, -1, 0, 1, 0))
> 
> contrast(regrid(EMM), CON)
> 
>> On Wed, Mar 9, 2022 at 1:48 PM Lenth, Russell V <russell-lenth at uiowa.edu> wrote:
>> 
>> I believe that this doesn't do what you think it does. Specifying 'type = "response"' does not change the way the tests are done, it just changes the scale upon which the results are presented. If you really want those contrasts computed on the response scale, then (using the setup I showed previously) do:
>> 
>>        contrast(regrid(EMM), CON)
>> 
>> ... which will convert everything to the response scale before computing the contrasts.
>> 
>> Russ
>> 
>> -----Original Message-----
>> From: Timothy MacKenzie <fswfswt at gmail.com>
>> Sent: Wednesday, March 9, 2022 1:21 PM
>> To: Ben Bolker <bbolker at gmail.com>
>> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Lenth, Russell V <russell-lenth at uiowa.edu>
>> Subject: [External] Re: [R-sig-ME] Post hoc on glmer for specific hypotheses
>> 
>> Ben, type = "response" exponentiates the link-scale results. It just seems that it doesn't work inside the pairs(...) call. Russ can better speak to that.
>> 
>> emmeans provides the capability to convert the results from the link scale into the odds scale (which for comparisons would be odds ratios).
>> 
>>> On Wed, Mar 9, 2022 at 1:14 PM Ben Bolker <bbolker at gmail.com> wrote:
>>> 
>>>     Hmm.  Why would you want to test on the response scale?  It
>>> almost always makes sense to test contrasts on the link scale, where
>>> the sampling distributions of the parameters are more likely to be
>>> approximately Gaussian.
>>>     I haven't gone to look at your data/problem in detail, but I'm a
>>> little bit surprised that `type="response"` doesn't exponentiate, i.e.
>>> convert the estimated values from the log-odds to the odds scale?
>>> (Converting to the probability scale is not really feasible because of
>>> the way the math works out ...)
>>> 
>>> On Wed, Mar 9, 2022 at 1:46 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>>>> 
>>>> Thanks, Ben! Apparently, the 7th coefficient in the glmer() output
>>>> tests the first hypothesis that I'm looking for.
>>>> 
>>>> For the second hypothesis, I was able to use emmeans::emmeans() to
>>>> get what I want by running:
>>>> 
>>>> ems <- emmeans(m2, pairwise ~ time*item_type, type =
>>>> "response",infer = c(FALSE, TRUE), adjust = "tukey")[[2]] vv <-
>>>> pairs(ems, simple = "each", infer = c(FALSE, TRUE), type =
>>>> "response") # on log-odds scale
>>>> 
>>>> In this set up, vv[288, ] tests the second hypothesis. But on the
>>>> Log odds scale. Is there any way to convert it back to the response scale?
>>>> 
>>>> Thanks,
>>>> Tim M
>>>> 
>>>> On Wed, Mar 9, 2022 at 12:22 PM Ben Bolker <bbolker at gmail.com> wrote:
>>>>> 
>>>>>  One way to do this would be via `multcomp::glht`, which allows
>>>>> you to specify any linear combination(s) of parameters to test.
>>>>> You do have to figure out the association between the parameters
>>>>> you have and the contrasts you want. I wrote some (possibly
>>>>> scrutable) stuff about that problem here:
>>>>> http://bbolker.github.io/bbmisc/mgreen_contrasts.html
>>>>> 
>>>>>  by hand:
>>>>> 
>>>>>  assuming factor levels are {baseline, post} and {MC, prod}
>>>>> 
>>>>> baseline_MC = intercept
>>>>> post_MC = intercept + time_post
>>>>> baseline_prod = intercept + gram_prod post_prod = intercept +
>>>>> time_post + gram_prod + interax
>>>>> 
>>>>> so your first contrast would be {(intercept - (intercept +
>>>>> time_post))
>>>>> - (intercept + gram_prod - (intercept + time_post + gram_prod +
>>>>> interax))
>>>>>   = (-time_post -time_post - interax) = (-2*time_post - interax)
>>>>> 
>>>>> so the contrast would be (0, -2, 0, -1) assuming that the
>>>>> parameters are ordered (intercept, time_post, gram_prod, interax)
>>>>> 
>>>>>   (1) You should definitely check my algebra; (2) there may be a
>>>>> quicker (if less transparent) way to do this by setting up
>>>>> appropriate contrasts from the beginning; (3) I noticed that I left the "vocab"
>>>>> levels out of the analysis, but I don't think that changes
>>>>> anything important.
>>>>> 
>>>>> 
>>>>> On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>>>>>> 
>>>>>> Hello All,
>>>>>> 
>>>>>> My glmer model below analyzes the performance of a single group
>>>>>> of subjects on a test at two time points. The test has 4 item types.
>>>>>> 
>>>>>> Data and code are below.
>>>>>> 
>>>>>> Is there a way to test only the following two hypotheses?
>>>>>> 
>>>>>> 1- ((Baseline multiple-choice_grammar) - (Post-test
>>>>>> multiple-choice_grammar)) - (Baseline production_grammar -
>>>>>> (Post-test
>>>>>> production_grammar))
>>>>>> 
>>>>>> 2- ((Baseline multiple-choice_vocabulary) - (Post-test
>>>>>> multiple-choice_vocabulary)) - (Baseline production_vocabulary -
>>>>>> (Post-test production_vocabulary))
>>>>>> 
>>>>>> dat <-
>>>>>> read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
>>>>>> 
>>>>>> form2 <- y ~ item_type*time + (1 | user_id)
>>>>>> 
>>>>>> m2 <- glmer(form2, family = binomial, data = dat,
>>>>>>            control =
>>>>>>              glmerControl(optimizer = "bobyqa"))
>>>>>> 
>>>>>> Sincerely,
>>>>>> Tim M
>>>>>> 
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From |@w|@wt @end|ng |rom gm@||@com  Wed Mar  9 22:14:45 2022
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Wed, 9 Mar 2022 15:14:45 -0600
Subject: [R-sig-ME] 
 [External] Re: Post hoc on glmer for specific hypotheses
In-Reply-To: <9AE06FE5-C7F2-4379-8C07-75B2F4B2A770@uiowa.edu>
References: <CADreqixW_=SgHccCwaUV_Rorq4nvX2-aeuhRC2SnjE4eBevO9A@mail.gmail.com>
 <CABghstQimBHE5oAMh3ZEFgC7eXhObanZ0S_LtKO+MENPDrgSOw@mail.gmail.com>
 <CADreqix-dSH28SNrGFR2Q1_AXukR3OUxtbio+mLq-CdAXcXJkQ@mail.gmail.com>
 <CABghstTji+sNP5ZPzJGymLosgwoQkVn9wogrRs+vUx0RVG48Rg@mail.gmail.com>
 <CADreqiz2Y2j04WipS+1c3xwC1ssopommQqjVrnoatP7vp942DQ@mail.gmail.com>
 <DM6PR04MB447416ED68478925804FD5B2F10A9@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CADreqixBvWYKwMUOnS7FYXVi7-VG6dEu5MeN5zji9B8Lc8Lngg@mail.gmail.com>
 <9AE06FE5-C7F2-4379-8C07-75B2F4B2A770@uiowa.edu>
Message-ID: <CADreqiwoE28yC4D+FOcBZhpSHNRD1cz0V4Yk89_9+CpBfaC9SA@mail.gmail.com>

It did help, thanks! But what scale is the output on?

c1 = c(1, 0, -1, 0, -1, 0, 1, 0) should correspond to the 7th
coefficient in m2. Instead it returns an estimate of 0.0744.

Tim M

On Wed, Mar 9, 2022 at 3:02 PM Lenth, Russell V <russell-lenth at uiowa.edu> wrote:
>
> Hmmm. I guess try adding ', nesting = NULL' to the call for EMM.
>
> Sent from my iPad
>
> > On Mar 9, 2022, at 2:11 PM, Timothy MacKenzie <fswfswt at gmail.com> wrote:
> >
> > ?Thanks so much Ben and Russ.
> >
> > Russ, I get an error that says: "Non-character contrast methods are
> > not supported with nested objects".
> >
> > For reproducibility here is the full code:
> >
> > dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> >
> > form2 <- y ~ item_type*time + (1 | user_id)
> >
> > m2 <- glmer(form2, family = binomial, data = dat,
> >            control =
> >              glmerControl(optimizer = "bobyqa"))
> > #-----------------------------------------------------------------------------------------------
> > EMM <- emmeans(m2, ~ item_type * time, infer=c(FALSE,FALSE))
> >
> > CON <- list(c1 = c(1, 0, -1, 0, -1, 0, 1, 0))
> >
> > contrast(regrid(EMM), CON)
> >
> >> On Wed, Mar 9, 2022 at 1:48 PM Lenth, Russell V <russell-lenth at uiowa.edu> wrote:
> >>
> >> I believe that this doesn't do what you think it does. Specifying 'type = "response"' does not change the way the tests are done, it just changes the scale upon which the results are presented. If you really want those contrasts computed on the response scale, then (using the setup I showed previously) do:
> >>
> >>        contrast(regrid(EMM), CON)
> >>
> >> ... which will convert everything to the response scale before computing the contrasts.
> >>
> >> Russ
> >>
> >> -----Original Message-----
> >> From: Timothy MacKenzie <fswfswt at gmail.com>
> >> Sent: Wednesday, March 9, 2022 1:21 PM
> >> To: Ben Bolker <bbolker at gmail.com>
> >> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Lenth, Russell V <russell-lenth at uiowa.edu>
> >> Subject: [External] Re: [R-sig-ME] Post hoc on glmer for specific hypotheses
> >>
> >> Ben, type = "response" exponentiates the link-scale results. It just seems that it doesn't work inside the pairs(...) call. Russ can better speak to that.
> >>
> >> emmeans provides the capability to convert the results from the link scale into the odds scale (which for comparisons would be odds ratios).
> >>
> >>> On Wed, Mar 9, 2022 at 1:14 PM Ben Bolker <bbolker at gmail.com> wrote:
> >>>
> >>>     Hmm.  Why would you want to test on the response scale?  It
> >>> almost always makes sense to test contrasts on the link scale, where
> >>> the sampling distributions of the parameters are more likely to be
> >>> approximately Gaussian.
> >>>     I haven't gone to look at your data/problem in detail, but I'm a
> >>> little bit surprised that `type="response"` doesn't exponentiate, i.e.
> >>> convert the estimated values from the log-odds to the odds scale?
> >>> (Converting to the probability scale is not really feasible because of
> >>> the way the math works out ...)
> >>>
> >>> On Wed, Mar 9, 2022 at 1:46 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> >>>>
> >>>> Thanks, Ben! Apparently, the 7th coefficient in the glmer() output
> >>>> tests the first hypothesis that I'm looking for.
> >>>>
> >>>> For the second hypothesis, I was able to use emmeans::emmeans() to
> >>>> get what I want by running:
> >>>>
> >>>> ems <- emmeans(m2, pairwise ~ time*item_type, type =
> >>>> "response",infer = c(FALSE, TRUE), adjust = "tukey")[[2]] vv <-
> >>>> pairs(ems, simple = "each", infer = c(FALSE, TRUE), type =
> >>>> "response") # on log-odds scale
> >>>>
> >>>> In this set up, vv[288, ] tests the second hypothesis. But on the
> >>>> Log odds scale. Is there any way to convert it back to the response scale?
> >>>>
> >>>> Thanks,
> >>>> Tim M
> >>>>
> >>>> On Wed, Mar 9, 2022 at 12:22 PM Ben Bolker <bbolker at gmail.com> wrote:
> >>>>>
> >>>>>  One way to do this would be via `multcomp::glht`, which allows
> >>>>> you to specify any linear combination(s) of parameters to test.
> >>>>> You do have to figure out the association between the parameters
> >>>>> you have and the contrasts you want. I wrote some (possibly
> >>>>> scrutable) stuff about that problem here:
> >>>>> http://bbolker.github.io/bbmisc/mgreen_contrasts.html
> >>>>>
> >>>>>  by hand:
> >>>>>
> >>>>>  assuming factor levels are {baseline, post} and {MC, prod}
> >>>>>
> >>>>> baseline_MC = intercept
> >>>>> post_MC = intercept + time_post
> >>>>> baseline_prod = intercept + gram_prod post_prod = intercept +
> >>>>> time_post + gram_prod + interax
> >>>>>
> >>>>> so your first contrast would be {(intercept - (intercept +
> >>>>> time_post))
> >>>>> - (intercept + gram_prod - (intercept + time_post + gram_prod +
> >>>>> interax))
> >>>>>   = (-time_post -time_post - interax) = (-2*time_post - interax)
> >>>>>
> >>>>> so the contrast would be (0, -2, 0, -1) assuming that the
> >>>>> parameters are ordered (intercept, time_post, gram_prod, interax)
> >>>>>
> >>>>>   (1) You should definitely check my algebra; (2) there may be a
> >>>>> quicker (if less transparent) way to do this by setting up
> >>>>> appropriate contrasts from the beginning; (3) I noticed that I left the "vocab"
> >>>>> levels out of the analysis, but I don't think that changes
> >>>>> anything important.
> >>>>>
> >>>>>
> >>>>> On Wed, Mar 9, 2022 at 12:59 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
> >>>>>>
> >>>>>> Hello All,
> >>>>>>
> >>>>>> My glmer model below analyzes the performance of a single group
> >>>>>> of subjects on a test at two time points. The test has 4 item types.
> >>>>>>
> >>>>>> Data and code are below.
> >>>>>>
> >>>>>> Is there a way to test only the following two hypotheses?
> >>>>>>
> >>>>>> 1- ((Baseline multiple-choice_grammar) - (Post-test
> >>>>>> multiple-choice_grammar)) - (Baseline production_grammar -
> >>>>>> (Post-test
> >>>>>> production_grammar))
> >>>>>>
> >>>>>> 2- ((Baseline multiple-choice_vocabulary) - (Post-test
> >>>>>> multiple-choice_vocabulary)) - (Baseline production_vocabulary -
> >>>>>> (Post-test production_vocabulary))
> >>>>>>
> >>>>>> dat <-
> >>>>>> read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
> >>>>>>
> >>>>>> form2 <- y ~ item_type*time + (1 | user_id)
> >>>>>>
> >>>>>> m2 <- glmer(form2, family = binomial, data = dat,
> >>>>>>            control =
> >>>>>>              glmerControl(optimizer = "bobyqa"))
> >>>>>>
> >>>>>> Sincerely,
> >>>>>> Tim M
> >>>>>>
> >>>>>> _______________________________________________
> >>>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From johnw|||ec @end|ng |rom gm@||@com  Wed Mar  9 23:48:36 2022
From: johnw|||ec @end|ng |rom gm@||@com (John Willoughby)
Date: Wed, 9 Mar 2022 14:48:36 -0800
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 183, Issue 17
In-Reply-To: <mailman.19648.333.1646850165.1223.r-sig-mixed-models@r-project.org>
References: <mailman.19648.333.1646850165.1223.r-sig-mixed-models@r-project.org>
Message-ID: <CAKk2L3L3mVfDaw_A88Zgjx5RKdFV2YA9pTgdr_R_X_a96mKu0Q@mail.gmail.com>

Dear Russ and Maarten,

Many thanks for the clarification on why I can't simply exponentiate the
intercept of a Poisson model with random effects and get the same result as
exponentiating
the intercept of a Poisson model without random effects.  I understand the
issue more clearly now.

Best,
John Willoughby



>
>
>    1. Re:  Poisson intercept-only multilevel model doesn't appear
>       to return the correct population mean (Lenth, Russell V)
>    2. Re:  Poisson intercept-only multilevel model doesn't appear
>       to return the correct population mean (Maarten Jung)
>    3. Post hoc on glmer for specific hypotheses (Timothy MacKenzie)
>    4. Re: Post hoc on glmer for specific hypotheses (Ben Bolker)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Wed, 9 Mar 2022 14:15:13 +0000
> From: "Lenth, Russell V" <russell-lenth at uiowa.edu>
> To: John Willoughby <johnwillec at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME]  Poisson intercept-only multilevel model
>         doesn't appear to return the correct population mean
> Message-ID:
>         <
> DM6PR04MB4474A526398B5DCC8121DCFDF10A9 at DM6PR04MB4474.namprd04.prod.outlook.com
> >
>
> Content-Type: text/plain; charset="utf-8"
>
> This happens precisely because there is a random effect in the model
> 'glmm3.2'. We have a model that basically says that log Y is normally
> distributed with an estimate mean of 2.424. That implies that Y is
> lognormal, and therefore
>
>     E[Y] = exp(mu + sigma^2/2)
>
> If you use VarCorr(glmm3.2) to get the estimate of sigma^2, and add half
> of that before you exponentiate, you'll get a lot closer to the estimate
> you expect.
>
> Russ Lenth
>
> -----Original Message-----
>
>
>
>
> Message: 2
> Date: Wed, 9 Mar 2022 15:52:46 +0100
> From: Maarten Jung <jungmaarten at gmail.com>
> To: John Willoughby <johnwillec at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME]  Poisson intercept-only multilevel model
>         doesn't appear to return the correct population mean
> Message-ID: <ec308b91-5069-42d3-0062-afe9f1873821 at gmail.com>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
> Dear John,
>
> > Why would including random intercepts for plot change the grand mean
> > (exponentiated) from
> > 44.24 to 11.29? Note that this only happens with the multilevel Poisson
> > regression and not the
> > multilevel Gaussian. I suspect I'm missing something, but I'll be
> > darned if
> > I can figure out what.
> In generalized linear mixed models the fixed population effects in the
> marginal and conditional model are in general different (taking the
> expectation of a nonlinear function of a random variable is not the same
> as taking the expectation of that random variable first and then
> applying the nonlinear function).
> In particular, for the log-linear Poisson random intercept model, the
> amount by which the intercept terms will differ depends on the random
> effects variance.
>
> Best,
> Maarten
>
>
>

	[[alternative HTML version deleted]]


From benpe|zer @end|ng |rom gm@||@com  Thu Mar 10 13:15:27 2022
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Thu, 10 Mar 2022 13:15:27 +0100
Subject: [R-sig-ME] gls error terms and (co)variances
Message-ID: <CAFgPNS_pHhjnwrdb-G1Rhfk1TRdxowzvpPDa0-MeNCQ_pVYkYg@mail.gmail.com>

Dear list,

I have two questions about model-predicted (co)variances by gls from the
nlme package.

Question 1)

For longitudinal data, 4 fixed occasions in time for each respondent, no
missings, I estimated a gls model with the fixed occasions as predictors,
and an unstructured (co)variance matrix:

UNSTRUC1 <- gls(read ~ 1+occf, data=da, method="REML",
                       correlation=corSymm(form = ~ occasion|id),
                       weights = varIdent(form = ~1|occasion))

"occasion" runs from 1 to 4, "occf" is the factor version of occasion.

The model predicted (co)variances/correlations for the four occasions are
almost, but not exactly, equal to the (co)variances/correlations of the
residuals found with:

resid <- residuals(UNSTRUC1)

I'm wondering why(small) discrepancies exist. When adding extra predictor
variables to the above model, the discrepancies between (co)variances
extracted from the gls (model) object, and those calculated on the
residuals in "resid" get larger. Using the var( ) function to obtain the
variances of the residuals in  "resid", the number of df = n-1. Even after
correcting this into n-4 for the above model, or into n-6 when to extra
predictors are added, the discrepancies remain. I must be overlooking
something, but what? Btw, I used a small routine corandcov(  ), found on
site https://rdrr.io/github/emilelatour/lamisc/src/R/corandcov.R, to
extract model predicted (co)variances and correlation for gls models.

Question 2)

For the above model, the predicted correlations for the four occasions are
(almost) equal to the observed correlations, as expected. When comparing
different correlation structures, like compound symmetry, ar1, toeplitz,
etcetera, one can compare the observed correlations with those predicted by
all these models, to decide "at face value" which model predicted
correlations come closest to the observed correlations. Of course, the
unstructured pattern is always "closest" but how well do the other patterns
fit (or not)? In addition to other fit-measures like AIC, BIC, deviance,
comparing the predicted correlations with the observed could help to asses
the model's quality. However, if there are extra predictors involved, gls
still produces predicted correlations across the four occasions, but there
is no simple "observed correlation matrix" to compare the predicted
correlation matrix with. I tried a linear regression model, with occf and
the extra predictors, and calculated the variances and correlations of the
residuals, but these are in general rather different from the ones gls
produces. Do you have any idea how to calculate such an "observed"
correlation matrix in case there are more predictors than just the occasion
factor occf factor?

Thanks for any help, Ben.

	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Thu Mar 10 15:08:24 2022
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Thu, 10 Mar 2022 15:08:24 +0100
Subject: [R-sig-ME] ar1 structure too big, alternate formulation?
Message-ID: <0698B49D-4839-4CF2-9238-D029433B6A8D@gmail.com>

Hi,

I?m working on a data set where individually tagged cod were observed on ship wrecks (present or absent). We aggregated everything to an hourly scale. We include an AR1 random effect to account for the idea that being present at a particular wreck in one hour makes an individual fish more likely to be present in the next hour. The variable `ID_Wreck` is the combination of fish tag ID and wreck where they were observed; we dropped combinations that were never observed.

dat = na.omit(transform(dPresence1, 
	time = factor(DateTimeCEST_Hourly),
	ID_Wreck = factor(paste(Tag_ID, Wreck, sep="_")))[,c("Presence","Speed_10m","Direction_10m","SeaLevel", "Temp_10m","Diel","time","ID_Wreck")])

There are 506 levels of `ID_Wreck`, each with up to 3550 hourly observations (min 214, median 3233).

I think I want to fit a model like

M0 <- glmmTMB(Presence ~ environ + ar1(time +0| ID_Wreck), family=binomial, data=dat)

where environ is some combination of fixed effects.

Even without any fixed effects, the AR1 random effect seems to cause a problem with the size of the structure.

Error in h(simpleError(msg, call)) : 
  error in evaluating the argument 'x' in selecting a method for function 't': missing value where TRUE/FALSE needed
In addition: Warning message:
In attributes(.Data) <- c(attributes(.Data), attrib) :
  NAs introduced by coercion to integer range

>From what I?ve read, the last part is related to trying to allocate a data frame that is bigger than R can handle (I?m allocating 100GB on a cluster).
https://stackoverflow.com/questions/55183203/how-to-create-data-frame-for-super-large-vectors <https://stackoverflow.com/questions/55183203/how-to-create-data-frame-for-super-large-vectors>

Is there a way to reformulate this problem so that the structures are small enough for R to handle?

What if I instead include a fixed effect of presence/absence in the previous hour? Is there a reference for how that is related to the random effect model (I know it?s easy, but references help)?

Cheers,
Mollie


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Mar 10 15:15:50 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 10 Mar 2022 09:15:50 -0500
Subject: [R-sig-ME] ar1 structure too big, alternate formulation?
In-Reply-To: <0698B49D-4839-4CF2-9238-D029433B6A8D@gmail.com>
References: <0698B49D-4839-4CF2-9238-D029433B6A8D@gmail.com>
Message-ID: <a28debf0-448b-4914-74a7-5cf365e2875d@gmail.com>

   Since you have large clusters, MASS::glmmPQL could work (unless your 
abundance very low or very high (proportions present/absent close to 0 
or 1).
   I don't have a reference for fixed effect of presence/absence in the 
previous hour; if you do that, you're assuming perfect detectability.
   I have thought about some ways that the AR1 implementation in glmmTMB 
could be improved, but they're not quick and easy to implement.

   cheers
    Ben Bolker


On 3/10/22 9:08 AM, Mollie Brooks wrote:
> Hi,
> 
> I?m working on a data set where individually tagged cod were observed on ship wrecks (present or absent). We aggregated everything to an hourly scale. We include an AR1 random effect to account for the idea that being present at a particular wreck in one hour makes an individual fish more likely to be present in the next hour. The variable `ID_Wreck` is the combination of fish tag ID and wreck where they were observed; we dropped combinations that were never observed.
> 
> dat = na.omit(transform(dPresence1,
> 	time = factor(DateTimeCEST_Hourly),
> 	ID_Wreck = factor(paste(Tag_ID, Wreck, sep="_")))[,c("Presence","Speed_10m","Direction_10m","SeaLevel", "Temp_10m","Diel","time","ID_Wreck")])
> 
> There are 506 levels of `ID_Wreck`, each with up to 3550 hourly observations (min 214, median 3233).
> 
> I think I want to fit a model like
> 
> M0 <- glmmTMB(Presence ~ environ + ar1(time +0| ID_Wreck), family=binomial, data=dat)
> 
> where environ is some combination of fixed effects.
> 
> Even without any fixed effects, the AR1 random effect seems to cause a problem with the size of the structure.
> 
> Error in h(simpleError(msg, call)) :
>    error in evaluating the argument 'x' in selecting a method for function 't': missing value where TRUE/FALSE needed
> In addition: Warning message:
> In attributes(.Data) <- c(attributes(.Data), attrib) :
>    NAs introduced by coercion to integer range
> 
>  From what I?ve read, the last part is related to trying to allocate a data frame that is bigger than R can handle (I?m allocating 100GB on a cluster).
> https://stackoverflow.com/questions/55183203/how-to-create-data-frame-for-super-large-vectors <https://stackoverflow.com/questions/55183203/how-to-create-data-frame-for-super-large-vectors>
> 
> Is there a way to reformulate this problem so that the structures are small enough for R to handle?
> 
> What if I instead include a fixed effect of presence/absence in the previous hour? Is there a reference for how that is related to the random effect model (I know it?s easy, but references help)?
> 
> Cheers,
> Mollie
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From |@w|@wt @end|ng |rom gm@||@com  Fri Mar 11 05:27:36 2022
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Thu, 10 Mar 2022 22:27:36 -0600
Subject: [R-sig-ME] Testing all random-effects correlations in lme4
Message-ID: <CADreqixdDDfnjTyApZKiBMVtPKnbn2vCwD-T+RQ-MZ8se6cptA@mail.gmail.com>

Dear All,

Am I right that to test whether each correlation estimate in G (below)
is 0 or not, the only way is to have a full model and then fit
different models each time fixing a correlation estimate to 0 and then
compare the fit of the full model to the model whose target
correlation estimate has been fixed to 0?

Is there any quicker way not to repeat this process manually so many times?

Thanks,
Tim M

library(lme4)

dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")

form3 <- y ~ item_type*time + (0 + item_type | user_id)

full_model <- glmer(form3, family = binomial, data = dat,
            control =
              glmerControl(optimizer = "bobyqa",
                           optCtrl=list(maxfun=1e4)))

G <- VarCorr(full_model)

attr(G$user_id, "correlation")


From cerru006 @end|ng |rom umn@edu  Fri Mar 11 15:13:05 2022
From: cerru006 @end|ng |rom umn@edu (Anibal Cerrudo)
Date: Fri, 11 Mar 2022 11:13:05 -0300
Subject: [R-sig-ME] lmer nesting
Message-ID: <CAPKijhpHbCMfJcr8r053OBotJYbAKZ8O_Yj8GgX7oPARks9OHg@mail.gmail.com>

Dear list members,

I have a conceptual doubt about mixed modeling for the following data.

Soybean grain samples were collected all around North and South
America during 2012-2013-2014 cropping seasons, and analysed for
several grain quality biochemical features. Hierarchical sampling
structure: The American continent* was divided into three regions: US,
Brazil (including Paraguay) and The Pampas (including Argentina and
Uruguay). These three main regions were subdivided into sub_regions:
north, south, central. Each subregion was integrated by all states or
provinces in each subregion.

The main objective is to analyze variation and variance for regions,
subregions and years, in particular: 1) to assess differences among
regions in each quality variable; 2) to have an idea of the stability
of this pattern. compare the proportion of the variation explained by
region and proportion of the variation explained by year; 3)  to
compare variability within a region (among subregions) against
variability among regions.

Our first attempt was fitting a mixed model where region, subregion
and state were fixed effects and year was a random one: "mod".

I basically wonder if this model syntax is ok to address our
objectives (in this case for protein) or should I modify the nesting
factors.

So far I have generated a nested variable: subregion = sub_region
nested in a region and  state = state_proc nested in the subregion.

mod<- lmer(prot_db ~ region  + subregion + state +(1|year) +
(1|region:year) + (1|subregion:year), data = df)

#VCA extracts variances fixed and random
anovaVCA(form= prot_db~ region + (year) + region:(year)+ subregion +
subregion:(year)+ state , Data=df)

Sorry if it was too long, I'm pretty newby in modeling so any help is
highly appreciated.

Best,
Anibal Cerrudo

*The American continent produces 90% of the soybean globally, and
represents 60% of the protein that the world consumes each year.
Environment and genetics affect composition (quality) and there is a
need to determine spatials patterns. The study is oriented to end
users, where to buy soybean for different end uses.


From bbo|ker @end|ng |rom gm@||@com  Fri Mar 11 17:37:14 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 11 Mar 2022 11:37:14 -0500
Subject: [R-sig-ME] Testing all random-effects correlations in lme4
In-Reply-To: <CADreqiwWEXy4f3uqOOedoC_KgHaoB5xj8ijRZZS+HaVrDraXkg@mail.gmail.com>
References: <CADreqixdDDfnjTyApZKiBMVtPKnbn2vCwD-T+RQ-MZ8se6cptA@mail.gmail.com>
 <b000c7e9-d483-59ec-aa5f-97791d427130@gmail.com>
 <CADreqiyr7rpxRrpdwAd5KCS1W-g+VuOjLm=W1-YReDMB-xdWaQ@mail.gmail.com>
 <CADreqixu8rk=Z3+GoL-D8i5-SJr3-Puwq4X9WdoAL+ckOKPyhQ@mail.gmail.com>
 <CADreqiwWEXy4f3uqOOedoC_KgHaoB5xj8ijRZZS+HaVrDraXkg@mail.gmail.com>
Message-ID: <a46253e3-d931-a64b-1126-c7e336c2282f@gmail.com>

   [please keep r-sig-mixed-models in the cc: list]

   You can set the confidence intervals to be computed in parallel (see 
?lme4::profile.merMod, the parallel arguments would get passed through 
as part of the '...' argument from confint.merMod)

   Alternatively, you could use the merDerivs package, e.g.

library(lme4)
library(merDeriv)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
## sd(int), sd(days), cor(int,days), resid
sdcor <- as.data.frame(VarCorr(fm1))[["sdcor"]]
vv <- vcov(fm1, full = TRUE, ranpar = "sd")
se <- sqrt(diag(vv))[c(3,5,4,6)]  ## different order!

then construct the Wald CIs yourself

  I should really add something like this to broom.mixed, although Wald 
CIs of random-effect parameters should come with a giant WARNING SIGN 
that says they are often unreliable measures of uncertainty (which is 
why Doug Bates didn't bother to implement them in the first place ...)

   cheers
    Ben Bolker



On 3/10/22 11:50 PM, Timothy MacKenzie wrote:
> Anyway, this takes a huge amount of time using the profile method. Any
> other possible alternative?
> 
> On Thu, Mar 10, 2022 at 10:49 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>>
>> Oh just saw the documentation, although my data is huge.
>>
>> On Thu, Mar 10, 2022 at 10:44 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>>>
>>> Thanks Ben.
>>>
>>> confint(full_model, method = "Wald", oldNames=TRUE) returns all NAs
>>> for random effects, am I missing something?
>>>
>>>
>>>                 2.5 %     97.5 %
>>> sd_item_typemultiple-choice_grammar|user_id
>>>                     NA         NA
>>> cor_item_typemultiple-choice_vocabulary.item_typemultiple-choice_grammar|user_id
>>>           NA         NA
>>> cor_item_typeproduction_grammar.item_typemultiple-choice_grammar|user_id
>>>                   NA         NA
>>> cor_item_typeproduction_vocabulary.item_typemultiple-choice_grammar|user_id
>>>                NA         NA
>>> sd_item_typemultiple-choice_vocabulary|user_id
>>>                     NA         NA
>>> cor_item_typeproduction_grammar.item_typemultiple-choice_vocabulary|user_id
>>>                NA         NA
>>> cor_item_typeproduction_vocabulary.item_typemultiple-choice_vocabulary|user_id
>>>             NA         NA
>>> sd_item_typeproduction_grammar|user_id
>>>                     NA         NA
>>> cor_item_typeproduction_vocabulary.item_typeproduction_grammar|user_id
>>>                     NA         NA
>>> sd_item_typeproduction_vocabulary|user_id
>>>                     NA         NA
>>> (Intercept)
>>>            -0.02832784  0.2143555
>>> item_typemultiple-choice_vocabulary
>>>             1.46685879  4.7702998
>>> item_typeproduction_grammar
>>>            -0.65403796 -0.2758050
>>> item_typeproduction_vocabulary
>>>             1.00471913  1.5127176
>>> timePost-test
>>>             0.57518030  0.8745273
>>> item_typemultiple-choice_vocabulary:timePost-test
>>>            -0.22191717  0.8354483
>>> item_typeproduction_grammar:timePost-test
>>>             0.16377639  0.6762834
>>> item_typeproduction_vocabulary:timePost-test
>>>             0.06959180  0.6428313
>>>
>>> On Thu, Mar 10, 2022 at 10:30 PM Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>      Calculate the confidence intervals?
>>>>
>>>>      confint(full_model) ...
>>>>
>>>>     (By the way, *none* of the correlation parameters are equal to zero.
>>>>    But you can test whether they're significantly different from zero or
>>>> not :-) )
>>>>
>>>>     Besides which, constraining a single correlation coefficient to zero
>>>> may be harder than you think ...
>>>>
>>>> On 3/10/22 11:27 PM, Timothy MacKenzie wrote:
>>>>> Dear All,
>>>>>
>>>>> Am I right that to test whether each correlation estimate in G (below)
>>>>> is 0 or not, the only way is to have a full model and then fit
>>>>> different models each time fixing a correlation estimate to 0 and then
>>>>> compare the fit of the full model to the model whose target
>>>>> correlation estimate has been fixed to 0?
>>>>>
>>>>> Is there any quicker way not to repeat this process manually so many times?
>>>>>
>>>>> Thanks,
>>>>> Tim M
>>>>>
>>>>> library(lme4)
>>>>>
>>>>> dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")
>>>>>
>>>>> form3 <- y ~ item_type*time + (0 + item_type | user_id)
>>>>>
>>>>> full_model <- glmer(form3, family = binomial, data = dat,
>>>>>               control =
>>>>>                 glmerControl(optimizer = "bobyqa",
>>>>>                              optCtrl=list(maxfun=1e4)))
>>>>>
>>>>> G <- VarCorr(full_model)
>>>>>
>>>>> attr(G$user_id, "correlation")
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> --
>>>> Dr. Benjamin Bolker
>>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>>> Director, School of Computational Science and Engineering
>>>> Graduate chair, Mathematics & Statistics

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From d@|uedecke @end|ng |rom uke@de  Sun Mar 13 10:31:35 2022
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Sun, 13 Mar 2022 10:31:35 +0100
Subject: [R-sig-ME] Testing all random-effects correlations in lme4
In-Reply-To: <a46253e3-d931-a64b-1126-c7e336c2282f@gmail.com>
References: <CADreqixdDDfnjTyApZKiBMVtPKnbn2vCwD-T+RQ-MZ8se6cptA@mail.gmail.com>
 <b000c7e9-d483-59ec-aa5f-97791d427130@gmail.com>
 <CADreqiyr7rpxRrpdwAd5KCS1W-g+VuOjLm=W1-YReDMB-xdWaQ@mail.gmail.com>
 <CADreqixu8rk=Z3+GoL-D8i5-SJr3-Puwq4X9WdoAL+ckOKPyhQ@mail.gmail.com>
 <CADreqiwWEXy4f3uqOOedoC_KgHaoB5xj8ijRZZS+HaVrDraXkg@mail.gmail.com>
 <a46253e3-d931-a64b-1126-c7e336c2282f@gmail.com>
Message-ID: <000001d836bd$225c68f0$67153ad0$@uke.de>

Dear Timothy,
we just recently implemented computing SEs and Cis using Wald approxmination
based on Ben's suggested approach in the parameters package (you can
construct intervals for the random effect parameters both for profile Cis
and Wald Cis). See an example here:
https://easystats.github.io/parameters/reference/model_parameters.merMod.htm
l

The function "model_parameters()" uses the delta-method to transform
standard errors for constructing the intervals around the log-transformed SD
parameters. These are than back-transformed, so that random effect
variances, standard errors and confidence intervals are shown on the
original scale. We decided to do this to ensure that the intervals are
within the correct bounds (i.e. CI for correlations is between -1 and +1,
and intervals for the SD parameters are positive).

This feature is currently only available in the GitHub version (for Wald Cis
of random effects, profiled Cis for random effects already works in the CRAN
version), so if you want to try out, you have to install the package like
this.

install.packages("remotes")
remotes::install_github("easystats/parameters")

And here's a reprex with your model (formatting may be messed up, unless you
have a monospaced font):

library(lme4)
#> Loading required package: Matrix
library(parameters)
dat <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d.csv")

m1 <- glmer(
  y ~ item_type * time + (0 + item_type | user_id),
  family = binomial,
  data = dat,
  control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e4))
)

model_parameters(m1)
#> # Fixed Effects
#> 
#> Parameter                                                 | Log-Odds |
SE |         95% CI |     z |      p
#>
----------------------------------------------------------------------------
---------------------------------
#> (Intercept)                                               |     0.09 |
0.06 | [-0.03,  0.21] |  1.50 | 0.133 
#> item type [multiple-choice vocabulary]                    |     3.12 |
0.84 | [ 1.47,  4.77] |  3.70 | < .001
#> item type [production grammar]                            |    -0.46 |
0.10 | [-0.65, -0.28] | -4.82 | < .001
#> item type [production vocabulary]                         |     1.26 |
0.13 | [ 1.00,  1.51] |  9.71 | < .001
#> time [Post-test]                                          |     0.72 |
0.08 | [ 0.58,  0.87] |  9.49 | < .001
#> item type [multiple-choice vocabulary] * time [Post-test] |     0.31 |
0.27 | [-0.22,  0.84] |  1.14 | 0.255 
#> item type [production grammar] * time [Post-test]         |     0.42 |
0.13 | [ 0.16,  0.68] |  3.21 | 0.001 
#> item type [production vocabulary] * time [Post-test]      |     0.36 |
0.15 | [ 0.07,  0.64] |  2.44 | 0.015 
#> 
#> # Random Effects
#> 
#> Parameter                                           | Coefficient |   SE
|       95% CI
#>
----------------------------------------------------------------------------
-----------
#> SD (item_typemultiple-choice_grammar: user_id)      |        1.17 | 0.07
| [1.03, 1.32]
#> SD (item_typemultiple-choice_vocabulary: user_id)   |        3.41 | 0.70
| [2.28, 5.11]
#> SD (item_typeproduction_grammar: user_id)           |        1.45 | 0.12
| [1.23, 1.70]
#> SD (item_typeproduction_vocabulary: user_id)        |        1.77 | 0.17
| [1.47, 2.13]
#> Cor (Reference~item_typemultiple-choice_vocabulary) |        0.35 | 0.09
| [0.15, 0.52]
#> Cor (Reference~item_typeproduction_grammar)         |        0.38 | 0.06
| [0.25, 0.49]
#> Cor (Reference~item_typeproduction_vocabulary)      |        0.50 | 0.06
| [0.36, 0.62]
#> SD (Residual)                                       |        1.00 |
|
#> 
#> Uncertainty intervals (equal-tailed) and p values (two-tailed) computed
using a
#>   Wald z-distribution approximation.


Best
Daniel


-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Ben Bolker
Gesendet: Freitag, 11. M?rz 2022 17:37
An: Timothy MacKenzie <fswfswt at gmail.com>; R-mixed models mailing list
<r-sig-mixed-models at r-project.org>
Betreff: Re: [R-sig-ME] Testing all random-effects correlations in lme4

   [please keep r-sig-mixed-models in the cc: list]

   You can set the confidence intervals to be computed in parallel (see
?lme4::profile.merMod, the parallel arguments would get passed through as
part of the '...' argument from confint.merMod)

   Alternatively, you could use the merDerivs package, e.g.

library(lme4)
library(merDeriv)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) ## sd(int),
sd(days), cor(int,days), resid sdcor <-
as.data.frame(VarCorr(fm1))[["sdcor"]]
vv <- vcov(fm1, full = TRUE, ranpar = "sd") se <- sqrt(diag(vv))[c(3,5,4,6)]
## different order!

then construct the Wald CIs yourself

  I should really add something like this to broom.mixed, although Wald CIs
of random-effect parameters should come with a giant WARNING SIGN that says
they are often unreliable measures of uncertainty (which is why Doug Bates
didn't bother to implement them in the first place ...)

   cheers
    Ben Bolker



--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From jk|ng@tn @end|ng |rom um@@@@edu  Fri Mar 18 22:44:51 2022
From: jk|ng@tn @end|ng |rom um@@@@edu (John Kingston)
Date: Fri, 18 Mar 2022 17:44:51 -0400
Subject: [R-sig-ME] random effects for a second-order polynomial
Message-ID: <CA+4gnfQERgxRoooM2M_pmeq5bT3RKAK1iP-nkgoT7vU=UU_dAQ@mail.gmail.com>

I am trying to model response times in an experiment in which listeners
hear one of five synthesized syllables, one which is clearly "da", another
which is clearly "ga", or one of three steps in between the clear "da" and
clear "ga", which differ in how ambiguous they are between the clear "da"
or "ga". Listeners must identify each syllable as "da" or "ga". As is
typical in such experiments, response times are much faster to the clear
instances of each syllable than to the ambiguous steps in between them, and
a plot of response times against the steps along this series of syllables,
da 2 3 4 ga, has roughly the shape of an inverted parabola. So, I naturally
modeled the effect of the series with poly(step, 2), and I obtained an
expected negative estimate for the second-order term. My question concerns
the random effect structure. When I include only a first-order effect of
step in the random effects, like this (scDgRsp = whether the response was
"da" or "ga"):

dgRTStep0 <- lmer(logRT ~ scDgRsp +
                    poly(scStep, 2)  +
                (1 | participant) +
                (0 + scDgRsp | participant) +
                (0 + scStep | participant),
                    control = lmerControl(optimizer="bobyqa",
                                           optCtrl=list(maxfun=2e5)),
              data = dgTestTrim)

I get this as the random effects:

Random effects:
 Groups        Name        Variance  Std.Dev.
 participant   (Intercept) 0.0051506 0.07177
 participant.1 scDgRsp     0.0005302 0.02303
 participant.2 scStep      0.0002087 0.01445
 Residual                  0.0194742 0.13955
Number of obs: 13272, groups:  participant, 28


but when I include the second-order term, like this:


dgRTStep1 <- lmer(logRT ~ scDgRsp +
                    poly(scStep, 2)  +
                (1 | participant) +
                (0 + scDgRsp | participant) +
                (0 + poly(scStep, 2) | participant),
                    control = lmerControl(optimizer="bobyqa",
                                           optCtrl=list(maxfun=2e5)),
              data = dgTestTrim)


I get this instead:


Random effects:
 Groups        Name             Variance  Std.Dev. Corr
 participant   (Intercept)      0.0051593 0.07183
 participant.1 scDgRsp          0.0005799 0.02408
 participant.2 poly(scStep, 2)1 3.5037792 1.87184
               poly(scStep, 2)2 1.8811428 1.37155  -0.57
 Residual                       0.0193518 0.13911
Number of obs: 13272, groups:  participant, 28


I'm not so puzzled by the correlation as the sizes of the randow
effects, which four orders of magnitude larger. Is this sensible,
interpretable?


The fixed effects estimates differ little between the two models:


poly(scStep, 2)1  1.077e+00  3.841e-01  2.825e+01   2.804 0.009033 **
poly(scStep, 2)2 -2.969e+00  1.502e-01  1.300e+04 -19.768  < 2e-16 ***


versus


poly(scStep, 2)1  1.102060   0.418011 27.340208   2.636 0.013648 *
poly(scStep, 2)2 -2.968686   0.299938 27.103765  -9.898  1.7e-10 ***


except in the standard errors and degrees of freedom for the
second-order estimate.


Thanks!


Best,

John Kingston
Professor
Linguistics Department
University of Massachusetts
N434 Integrative Learning Center
650 N. Pleasant Street
Amherst, MA 01003
1-413-545-6833, fax -2792
jkingstn at umass.edu
https://blogs.umass.edu/jkingstn
<https://blogs.umass.edu/jkingstn/wp-admin/>

	[[alternative HTML version deleted]]


From m|ch@|| @end|ng |rom tut@@|o  Mon Mar 21 17:53:39 2022
From: m|ch@|| @end|ng |rom tut@@|o (=?UTF-8?Q?Micha=C5=82_Folwarczny?=)
Date: Mon, 21 Mar 2022 17:53:39 +0100 (CET)
Subject: [R-sig-ME] Weird results after fitting a model with lme4
Message-ID: <MyhNi2L--3-2@tuta.io>

Dear colleague(s),

Prof. Bolker suggested me contacting you regarding my question about the results of a model fitted via?lme4. Recently I run a study whereby each participant evaluated 18 different foods in terms of these foods' calorie content. There were two conditions (variable levels: city, nature) and I wanted to test, whether there were differences in their ratings of calories in foods across conditions. So, using the lme4 package I fit a mixed model (see lmer.png), with random intercepts for participants and foods. However, this produced exactly the same results?(for the effect of condition) as fitting a linear model (see lm.png) without random effects! What's even more weird is that when I remove random intercept for foods, then the output is the same (again, for the effects of condition; standard errors for intercepts do indeed change). It doesn't make much sense to me, as I expected standard errors for the effect of the binary variable--condition--would change.

These are the two models that produce the same results:
lm(caloriesIndex ~ condition, df)
lmer(calories ~ condition + (1|id)? + (1|food), dfl)

As a dependent variable in the wide dataset used to running a simple linear model, I use the average of the 18 ratings, i.e.,
df$caloriesIndex <- df %>%
? select(calories1:calories18) %>%
? rowMeans

Do you have an idea why this could have happened? If you wanted to have a look at these data, then I attached data in wide format (df.csv) and long format (dfl.csv).

Thanks in advance for suggestions!
Best regards,
Micha? Folwarczny,
Reykjavik University,

PS: When fitting an alternative model, that is, lmer(calories ~ condition + (1|food), dfl) I get the results that I expected, with lower standard errors for the effect of condition - to my understanding, this is desired and expected from using mixed models as compared to a simple linear regression. Is it possible that adding random intercepts for participants and foods (i.e., items in a study) evens out? If that's the case, then wouldn't using the alternative model with random intercepts for foods only be more appropriate approach to these data?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: lm.png
Type: image/png
Size: 79493 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220321/f3617ca6/attachment-0002.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: lmer.png
Type: image/png
Size: 120892 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220321/f3617ca6/attachment-0003.png>

From h|gh@t@t @end|ng |rom h|gh@t@t@com  Tue Mar 22 10:52:39 2022
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Tue, 22 Mar 2022 09:52:39 +0000
Subject: [R-sig-ME] Stats course: Introduction to Zero Inflated GLM and GLMM
Message-ID: <93b97c5b-1a61-7d72-4118-a505bad99c92@highstat.com>

We would like to announce the following online stats course:

Course: Introduction to Zero Inflated GLM and GLMM


Format: Online course with on-demand video and live Zoom

Key phrases:

1. Introduction to mixed-effects models and GLMM using glmmTMB.
2. Analysis of count data, continuous data and proportional data with an 
excessive number of zeros.
3. Applying the following (zero-inflated) GLMMs in glmmTMB:
 ????? -Count data: Poisson, negative binomial, generalised Poisson.
 ????? -Proportional data: binomial, beta.
 ????? -Continuous data: Tweedie, Gamma, hurdle model.
4. Power analysis: If we were to design a similar field study, how many 
clusters, and how many observations per cluster should we sample?


When: Live summary sessions using Zoom will run in March/April 2022.

Price: 500 GBP (50% reduction for developing countries).

Included: A 1-hour face-to-face video chat with one or both instructors.

Flyer: http://highstat.com/.../2022/Flyer2022_04_ZIMF_Online.pdf

Website: http://highstat.com/index.php/courses-upcoming


Kind regards,

Alain Zuur


From j@v|ermore|r@ @end|ng |rom gm@||@com  Tue Mar 22 14:06:54 2022
From: j@v|ermore|r@ @end|ng |rom gm@||@com (Javier Moreira)
Date: Tue, 22 Mar 2022 10:06:54 -0300
Subject: [R-sig-ME] strip plot design with pseudoreplication
Message-ID: <CAEyHP-0Z7jG9cneHn1=obBihGmVNVx7wCar=tTa_8Nh8=ZgzMg@mail.gmail.com>

hi, members of the group.

I'm trying to find the way to express a model within R.

My intention is to use a set of data from a wheat trial, harvested with GPS
mapping. I'm comparing the standard model that use the average of the plot
(experimental unit) vs. one that use every pseudo-replication (observation
unit-harvest point).

The design is a strip plot or split block, with 2 factors and 3 error
terms. For the first step, I use the Agricolae package.

model0_fijo = with(data21,strip.plot(BLOCK = BLOQUE,
                   COL = AMBIENTE,
                   ROW = TRATAMIENTO,
                   Y = RTO))
*data21, n=72
and this produces an anova with 3 error terms (Ea,Eb,Ec) and the correct
distribution of degrees of freedom (Ambiente, Ea/ Tratamiento,Eb/
interacci?n, Ec).

When I try to use the pseudo-replication, i first try to use lme(), and to
take into account the correct grouping, it produces 2 different Error
terms, and i get (Ambiente, Ea, and tratamamiento and interaction, Eb).
This makes the design as it was a split plot (2 error terms).

modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
                random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
                data=data1)
*data1, n=3095

According to a tutorial
<https://vsni.co.uk/case-studies/dealing-with-pseudo-replication-in-linear-mixed-models>for
the use of ASreml package i was able to use lmer() to account for the
block:plot interaction (1|BLOQUE:parcela) and get the same result as the
tutorial. But, this leaves the model with only 1 error term applied to
every factor and interaction. So, it takes into account the
pseudo-replication but not the correct error assign for the anova.

m2_lmer<-lmer(REND.~AMBIENTE*TRATAMIENTO+
        (1|BLOQUE)+(1|BLOQUE:AMBIENTE)+(1|BLOQUE:parcela),
       data=data1)

In the initial steps, to find a way with lmer() to get a 3 error model that
accounts for pseudo-replication would be great.
Following that, i also have to account for spatial correlation, and that
isn't an option within lmer() so, i have to get the same model translate to
lme().

Thanks a lot for your help. This data analysis is for a on farm trial from
my Msc thesis.

best regards,

Ing. Agr. Javier Moreira

-- 
Javier Moreira de Souza
Ingeniero Agr?nomo
099 406 006

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Tue Mar 22 19:38:32 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 22 Mar 2022 13:38:32 -0500
Subject: [R-sig-ME] random effects for a second-order polynomial
In-Reply-To: <CA+4gnfQERgxRoooM2M_pmeq5bT3RKAK1iP-nkgoT7vU=UU_dAQ@mail.gmail.com>
References: <CA+4gnfQERgxRoooM2M_pmeq5bT3RKAK1iP-nkgoT7vU=UU_dAQ@mail.gmail.com>
Message-ID: <8a1ca047-4677-83d6-c0ec-26f2ee3fcddb@phillipalday.com>

Hi John,

I'm going to try for a quick, intuitive answer in the hope that it's
more helpful to have some quick comments than for a comprehensive answer
sometime in the future.

The increase in variance in the RE surprised me a lot at first glance
but I think it's okay. Here's my thinking:

- The linear term in the two models doesn't directly correspond if
you're using orthogonal polynomials (raw=FALSE, which is the default).
You would need poly(scStep, 1) for a more direct comparison.
- Assuming that the the variance in the quadratic term is correct, that
variance carries over into the variance for the linear term just because
of their covariance (i.e. correlation).
- In the model without a random effect for the quadratic term, the
participant-level variation is constrained essentially by the extrema
and means because those are the points that the line has to pass
through. For the quadratic model, the linear term corresponds to a more
complicated shifting of the overall parabola and so the constraint is
looser. Very, very hand-wavy -- this is essentially the dual of the
previous point.

I would check out the first point and see if the change between the
linear and quadratic model is more reasonable.

Hope that helps,
Phillip

On 18/3/22 4:44 pm, John Kingston wrote:
> I am trying to model response times in an experiment in which listeners
> hear one of five synthesized syllables, one which is clearly "da", another
> which is clearly "ga", or one of three steps in between the clear "da" and
> clear "ga", which differ in how ambiguous they are between the clear "da"
> or "ga". Listeners must identify each syllable as "da" or "ga". As is
> typical in such experiments, response times are much faster to the clear
> instances of each syllable than to the ambiguous steps in between them, and
> a plot of response times against the steps along this series of syllables,
> da 2 3 4 ga, has roughly the shape of an inverted parabola. So, I naturally
> modeled the effect of the series with poly(step, 2), and I obtained an
> expected negative estimate for the second-order term. My question concerns
> the random effect structure. When I include only a first-order effect of
> step in the random effects, like this (scDgRsp = whether the response was
> "da" or "ga"):
> 
> dgRTStep0 <- lmer(logRT ~ scDgRsp +
>                     poly(scStep, 2)  +
>                 (1 | participant) +
>                 (0 + scDgRsp | participant) +
>                 (0 + scStep | participant),
>                     control = lmerControl(optimizer="bobyqa",
>                                            optCtrl=list(maxfun=2e5)),
>               data = dgTestTrim)
> 
> I get this as the random effects:
> 
> Random effects:
>  Groups        Name        Variance  Std.Dev.
>  participant   (Intercept) 0.0051506 0.07177
>  participant.1 scDgRsp     0.0005302 0.02303
>  participant.2 scStep      0.0002087 0.01445
>  Residual                  0.0194742 0.13955
> Number of obs: 13272, groups:  participant, 28
> 
> 
> but when I include the second-order term, like this:
> 
> 
> dgRTStep1 <- lmer(logRT ~ scDgRsp +
>                     poly(scStep, 2)  +
>                 (1 | participant) +
>                 (0 + scDgRsp | participant) +
>                 (0 + poly(scStep, 2) | participant),
>                     control = lmerControl(optimizer="bobyqa",
>                                            optCtrl=list(maxfun=2e5)),
>               data = dgTestTrim)
> 
> 
> I get this instead:
> 
> 
> Random effects:
>  Groups        Name             Variance  Std.Dev. Corr
>  participant   (Intercept)      0.0051593 0.07183
>  participant.1 scDgRsp          0.0005799 0.02408
>  participant.2 poly(scStep, 2)1 3.5037792 1.87184
>                poly(scStep, 2)2 1.8811428 1.37155  -0.57
>  Residual                       0.0193518 0.13911
> Number of obs: 13272, groups:  participant, 28
> 
> 
> I'm not so puzzled by the correlation as the sizes of the randow
> effects, which four orders of magnitude larger. Is this sensible,
> interpretable?
> 
> 
> The fixed effects estimates differ little between the two models:
> 
> 
> poly(scStep, 2)1  1.077e+00  3.841e-01  2.825e+01   2.804 0.009033 **
> poly(scStep, 2)2 -2.969e+00  1.502e-01  1.300e+04 -19.768  < 2e-16 ***
> 
> 
> versus
> 
> 
> poly(scStep, 2)1  1.102060   0.418011 27.340208   2.636 0.013648 *
> poly(scStep, 2)2 -2.968686   0.299938 27.103765  -9.898  1.7e-10 ***
> 
> 
> except in the standard errors and degrees of freedom for the
> second-order estimate.
> 
> 
> Thanks!
> 
> 
> Best,
> 
> John Kingston
> Professor
> Linguistics Department
> University of Massachusetts
> N434 Integrative Learning Center
> 650 N. Pleasant Street
> Amherst, MA 01003
> 1-413-545-6833, fax -2792
> jkingstn at umass.edu
> https://blogs.umass.edu/jkingstn
> <https://blogs.umass.edu/jkingstn/wp-admin/>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Wed Mar 30 13:33:40 2022
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (Alexandre Santos)
Date: Wed, 30 Mar 2022 11:33:40 +0000 (UTC)
Subject: [R-sig-ME] Representation model problem with standardized variables
References: <668477118.139932.1648640020214.ref@mail.yahoo.com>
Message-ID: <668477118.139932.1648640020214@mail.yahoo.com>

Hi Everyone!!

I standardized my input variables (ds.scale) before glmm adjustments but in the final plot, I have a problem with the real-world scale of my variables and the predicted values by model (m_6). I?d like the original scale of my?temp?and?storage?variables represented in my better model (m_6). What is the correct approach for this? Do not standardise my input variables, despite I lot of warmings? Some data transformation at the end? I make:

#Packages
library(lme4)
library(ggplot2)
library(ggeffects)
library(tidyverse)
library(bbmle) 
library(broom)

#Open my dataset
myds<-read.csv("https://raw.githubusercontent.com/Leprechault/trash/main/ds.desenvol.csv")
str(myds)
# 'data.frame': 400 obs. of??4 variables:
#??$ temp?????? : num??0 0 0 0 0 0 0 0 0 0 ...
#??$ storage????: int??5 5 5 5 5 5 5 5 5 5 ...
#??$ rep????????: chr??"r1" "r2" "r3" "r4" ...
#??$ development: int??0 23 22 27 24 25 24 22 0 22 ...

# Storage (days) is temporally correlated with temperature then mixed model
ds.scale<- myds %>%
??mutate(across(c(temp, storage), ~ drop(scale(.))))

# Models creation Poisson/Negative binomial
m_1 <- glmer(development ~ temp + storage +
?????????????? (1 | storage ), data = ds.scale, 
???????????????? family = "poisson")
m_2 <- glmer(development ~ poly(temp,2) + storage +
?????????????? (1 | storage ), data = ds.scale, 
???????????????? family = "poisson")??
m_3 <- glmer(development ~ poly(temp,2) + poly(storage,2) +
?????????????? (1 | storage ), data = ds.scale, 
???????????????? family = "poisson")??
m_4 <- glmer.nb(development ~ temp + storage +
?????????????? (1 | storage ), data = ds.scale)
m_5 <- glmer.nb(development ~ poly(temp,2) + storage +
?????????????? (1 | storage ), data = ds.scale)??
m_6 <- glmer.nb(development ~ poly(temp,2) + poly(storage,2) +
?????????????? (1 | storage ), data = ds.scale)?? 
modList <- tibble::lst(m_1,m_2,m_3,m_4,m_5,m_6)
bbmle::AICtab(modList)

#???? dAIC df
# m_6??0.0 7 
# m_3??1.0 6 
# m_5??3.3 6 
# m_2??5.0 5 
# m_4 17.9 5 
# m_1 21.0 4

# Plot the results for my better model (m_6)
mydf <- ggpredict(m_6, terms = c("temp [all]", "storage[all]"))

# For temp
ggplot(mydf, aes(x, predicted)) +
??geom_point(data=myds, aes(temp, development), alpha = 0.5) + 
??geom_line() +
??labs(x = "temp", y = "development")

# For storage
ggplot(mydf, aes(x, predicted)) +
??geom_point(data=myds, aes(storage, development), alpha = 0.5) + 
??geom_line() +
??labs(x = "storage", y = "development")
# -------------------------------------------------------------------------------------------??


Please, any help with it?
--
Alexandre dos Santos
Geotechnologies and Spatial Statistics applied to Forest Entomology


