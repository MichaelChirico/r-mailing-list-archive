From vlagani at ics.forth.gr  Fri Jan  2 19:06:32 2015
From: vlagani at ics.forth.gr (Vincenzo Lagani)
Date: Fri, 02 Jan 2015 19:06:32 +0100
Subject: [R-sig-ME] standard error and statistical significance in lmer
 versus lm
In-Reply-To: <549E2887.3060108@gmail.com>
References: <549DB2DF.9040009@ics.forth.gr> <549E2887.3060108@gmail.com>
Message-ID: <54A6DE28.7050406@ics.forth.gr>

Dear prof. Bolker,

thanks a lot for your answer. I have not been able to observe any 
definitive pattern by following your suggestion:

One thing that might be interesting would be plotting the residuals from
a model of only probeset variation (i.e., values ~ (week|probeset))
and seeing how the week*genotype pattern was (hopefully) clarified.

Could you please be a little bit more specific about how the residuals 
from the model you suggest should be plotted?

Here the summary of the model, for yours and other readers perusal:

>lme4Model.random <- lmer(values ~ (week|probesets), data = dataset, REML = FALSE);


>summary(lme4Model.random)
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: values ~ (week | probesets)
    Data: dataset

      AIC      BIC   logLik deviance df.resid
172535.9 172590.6 -86263.0 172525.9   414340

Scaled residuals:
      Min       1Q   Median       3Q      Max
-11.2119  -0.5763  -0.0112   0.5812  21.3413

Random effects:
  Groups    Name        Variance Std.Dev. Corr
  probesets (Intercept) 5.166933 2.27309
            week        0.004412 0.06642  -0.25
  Residual              0.061336 0.24766
Number of obs: 414345, groups:  probesets, 18015

Fixed effects:
             Estimate Std. Error t value
(Intercept)  6.64697    0.01662     400


Thanks again,

Vincenzo

On 12/27/2014 4:33 AM, Ben Bolker wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 14-12-26 02:11 PM, Vincenzo Lagani wrote:
>> Dear all,
>>
>> I am modelling gene expression data with mixed models using lme4.
>> My goal is to assess whether gene expression globally decreases or
>>   increases with time.
>>
>> Specifically, the data consist in whole expression profiles
>> measured at five different time points in two different strains of
>> mice. For each time point and each strain there are three
>> replicates. The data are not longitudinal, i.e., different mice are
>> used at each time point. We had to remove one profile from a time
>> point because it was not matching our quality criteria, so the data
>> became not properly balanced.
>>
>> On these data I am fitting the following model:
>>
>> lme4Model.full <- lmer(values ~ week * genotype + (week |
>> probesets), data = dataset, REML = FALSE)
>>
>> where 'values' stands for the gene expression, 'week' is a scaled
>> numeric reporting the age of the mice in weeks, and 'genotype' is a
>>   factor with two levels representing the two different genetic
>> backgrounds. Each single gene is let having its own random
>> intercept and slope.
>>
>> What puzzles me is that when I compare this model with its simpler,
>>   non-mixed version:
>>
>> lmModel.full <- lm(values ~ week * genotype, data = dataset)
>>
>> I obtain the same coefficients but different standard errors (see
>> below). Furthermore, while the interaction coefficient is not
>> significant in the simple linear model, it becomes highly
>> significant in the mixed model, at least according to these ANOVA
>> tests:
>>
>> lmModel <- lm(values ~ week + genotype, data = dataset) lme4Model
>> <- lmer(values ~ week + genotype + (week | probesets), data =
>> dataset, REML = FALSE)
>>
>>> anova(lmModel.full, lmModel)
>> Analysis of Variance Table
>>
>> Model 1: values ~ week * genotype Model 2: values ~ week +
>> genotype Res.Df     RSS Df Sum of Sq      F Pr(>F) 1 414341
>> 2162664 2 414342 2162666 -1   -2.4697 0.4732 0.4915
>>
>>> anova(lme4Model.full, lme4Model)
>> Data: dataset Models: lme4Model: values ~ week + genotype + (week |
>> probesets) lme4Model.full: values ~ week * genotype + (week |
>> probesets) Df   AIC   BIC logLik deviance  Chisq Chi Df Pr(>Chisq)
>> lme4Model       7 72376 72452 -36181    72362 lme4Model.full  8
>> 72325 72413 -36155    72309 52.472      1  4.364e-13 ***
>>
>> Assessing whether the interaction coefficient is significant is
>> actually the aim of my study, and having two totally different
>> answers confuses me. My understanding is that the mixed model
>> better catches the variance structure of the data and thus it is
>> able to better estimate the standard errors and p-values of the
>> coefficients. Is this correct? In other words, can I confidently
>> claim that the p-values obtained from the mixed models are "the
>> correct ones" and that the interaction term is actually
>> significant?
>     As far as I can tell from what you've posted, the result given by
> lme4 is indeed (or certainly could be/I have no reason to believe it
> is not) correct. I'm not sure of the best way to explain the result to
> you, though.  Adding the variation among probesets to the model does
> indeed explain a lot of variation that would otherwise end up being
> modeled as error and filtering into the standard errors.  It would be
> nice to understand the differences by visualizing the different
> models, but with such a large data set it could be challenging ...
> One thing that might be interesting would be plotting the residuals from
> a model of only probeset variation (i.e., values ~ (week|probeset))
> and seeing how the week*genotype pattern was (hopefully) clarified.
>
>> My apologies if this issue has been already posted on this list.
>> Despite having seen multiple posts here on similar topics, I have
>> not been able to find an answer to these questions.
>>
>> Thanks in advance for your help. Any suggestion is very welcome.
>>
>> Regards,
>>
>> Vincenzo
>>
>>
>>> summary(lme4Model.full)
>> Linear mixed model fit by maximum likelihood  ['lmerMod'] Formula:
>> values ~ week * genotype + (week | probesets) Data: dataset
>>
>> AIC      BIC   logLik deviance df.resid 72325.3  72412.8 -36154.7
>> 72309.3   414337
>>
>> Scaled residuals: Min       1Q   Median       3Q      Max -13.2622
>> -0.5246   0.0128   0.5270  23.3456
>>
>> Random effects: Groups    Name        Variance Std.Dev. Corr
>> probesets (Intercept) 5.167338 2.27318 week        0.005029 0.07092
>> -0.23 Residual              0.047063 0.21694 Number of obs: 414345,
>> groups:  probesets, 18015
>>
>> Fixed effects: Estimate Std. Error t value (Intercept)
>> 6.5727983  0.0169414   388.0 week             -0.0151336  0.0006823
>> -22.2 genotypeCSB       0.2405300  0.0007121   337.8
>> week:genotypeCSB  0.0050430  0.0006962     7.2
>>
>> Correlation of Fixed Effects: (Intr) week   gntCSB week
>> -0.177 genotypeCSB -0.015 -0.028 wk:gntypCSB -0.001 -0.392 -0.054
>>
>>
>>> summary(lmModel.full)
>> Call: lm(formula = values ~ week * genotype, data = dataset)
>>
>> Residuals: Min      1Q  Median      3Q     Max -5.7560 -1.9881
>> 0.0083  1.6823  7.6407
>>
>> Coefficients: Estimate Std. Error  t value Pr(>|t|) (Intercept)
>> 6.572798   0.004407 1491.384  < 2e-16 *** week
>> -0.015134   0.004547   -3.329 0.000873 *** genotypeCSB
>> 0.240530   0.007500   32.072  < 2e-16 *** week:genotypeCSB
>> 0.005043   0.007331    0.688 0.491537 --- Signif. codes:  0 ?***?
>> 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Residual standard error: 2.285 on 414341 degrees of freedom
>> Multiple R-squared:  0.002491,	Adjusted R-squared:  0.002484
>> F-statistic: 344.9 on 3 and 414341 DF,  p-value: < 2.2e-16
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJUniiHAAoJEOCV5YRblxUH5GEH/R57rvnCi7OYj0HEV+1dQ9sv
> awXYPd9/q7t2ZPVyrJ8OdVL2+ntVe7KYKFy28D2uRa5eyyH6/jaoy9nSlGI4Gvd0
> dslGQYlIpSw9LmOHY1BPcQYZuqEoJoHlbonbX+00AwgANdanP0CpSWNzNVRmbcUL
> ftPAErAaJecb7yu56+I2Yz5ugN3NYrqNdWvTV/HYxt5emjx45gQdQd4cQRTfKw3n
> JkcM8DMRrOjvN6w2H8Pgps/yE3W+nx5VsgBaSdmagwTIfke6aZ90+55jMhjbDXNJ
> xsbFzPc3CUA5SUO7qQHwoteMz8QlfRp3D8SgfmdfaPixskWCdMHjxAws+0ePAhw=
> =0jkf
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From vlagani at ics.forth.gr  Fri Jan  2 19:16:17 2015
From: vlagani at ics.forth.gr (Vincenzo Lagani)
Date: Fri, 02 Jan 2015 19:16:17 +0100
Subject: [R-sig-ME] standard error and statistical significance in lmer
 versus lm
In-Reply-To: <4486A94C-706B-4D6D-A7FB-17C6E5444A9E@me.com>
References: <549DB2DF.9040009@ics.forth.gr>
	<4486A94C-706B-4D6D-A7FB-17C6E5444A9E@me.com>
Message-ID: <54A6E071.6040003@ics.forth.gr>

Dear Peter,

thanks for your suggestion. Unfortunately, even on my most powerful 
machine I could not fit the models you suggested: R returns a memory 
error, due to the inability of allocating ~60GB of memory (more than 
18000 probesets in my data).

Moreover, I am not totally sure if the model you suggested is suitable 
for my application. While I fully agree with you that it would be 
interesting to observe what happens when the variability due to the 
probesets is explicitly modeled, I must say that I am not interested in 
the specific effect of each single gene. Moreover, the set of genes I am 
using can be considered as a (more or less) random sample from the set 
of all mouse genes. Thus, it seems to me that the term "probesets" 
should be definitely modeled as a random term.

Thanks again and kind regards,

Vincenzo

On 1/2/2015 4:34 PM, Peter Claussen wrote:
> Vincenzo,
>
> If I?m reading this correctly, I don?t think you?re comparing the same models, lm vs lmer
>
> Using lm, you have two models
> 	values ~ week + genotype
> 	values ~ week * genotype
>
> Using lmer, you have two different models.
> 	week + genotype + (week | probesets)
> 	week * genotype + (week | probesets)
>
> If you were to include (week:probesets) in your lm models, and compare
> 	values ~ week + genotype + week:probesets
> 	values ~ week * genotype + week:probesets
>
> would that clarify the confusion about the different results?
>
> Peter
>
>
>> On Dec 26, 2014, at 1:11 PM, Vincenzo Lagani <vlagani at ics.forth.gr> wrote:
>>
>> Dear all,
>>
>> I am modelling gene expression data with mixed models using lme4. My
>> goal is to assess whether gene expression globally decreases or
>> increases with time.
>>
>> Specifically, the data consist in whole expression profiles measured at
>> five different time points in two different strains of mice. For each
>> time point and each strain there are three replicates. The data are not
>> longitudinal, i.e., different mice are used at each time point. We had
>> to remove one profile from a time point because it was not matching our
>> quality criteria, so the data became not properly balanced.
>>
>> On these data I am fitting the following model:
>>
>> lme4Model.full <- lmer(values ~ week * genotype + (week | probesets),
>> data = dataset, REML = FALSE)
>>
>> where 'values' stands for the gene expression, 'week' is a scaled
>> numeric reporting the age of the mice in weeks, and 'genotype' is a
>> factor with two levels representing the two different genetic
>> backgrounds. Each single gene is let having its own random intercept and
>> slope.
>>
>> What puzzles me is that when I compare this model with its simpler,
>> non-mixed version:
>>
>> lmModel.full <- lm(values ~ week * genotype, data = dataset)
>>
>> I obtain the same coefficients but different standard errors (see
>> below). Furthermore, while the interaction coefficient is not
>> significant in the simple linear model, it becomes highly significant in
>> the mixed model, at least according to these ANOVA tests:
>>
>> lmModel <- lm(values ~ week + genotype, data = dataset)
>> lme4Model <- lmer(values ~ week + genotype + (week | probesets), data =
>> dataset, REML = FALSE)
>>
>>> anova(lmModel.full, lmModel)
>> Analysis of Variance Table
>>
>> Model 1: values ~ week * genotype
>> Model 2: values ~ week + genotype
>>    Res.Df     RSS Df Sum of Sq      F Pr(>F)
>> 1 414341 2162664
>> 2 414342 2162666 -1   -2.4697 0.4732 0.4915
>>
>>> anova(lme4Model.full, lme4Model)
>> Data: dataset
>> Models:
>> lme4Model: values ~ week + genotype + (week | probesets)
>> lme4Model.full: values ~ week * genotype + (week | probesets)
>>                 Df   AIC   BIC logLik deviance  Chisq Chi Df Pr(>Chisq)
>> lme4Model       7 72376 72452 -36181    72362
>> lme4Model.full  8 72325 72413 -36155    72309 52.472      1  4.364e-13 ***
>>
>>
>>
>> Assessing whether the interaction coefficient is significant is actually
>> the aim of my study, and having two totally different answers confuses
>> me. My understanding is that the mixed model better catches the variance
>> structure of the data and thus it is able to better estimate the
>> standard errors and p-values of the coefficients. Is this correct? In
>> other words, can I confidently claim that the p-values obtained from the
>> mixed models are "the correct ones" and that the interaction term is
>> actually significant?
>>
>> My apologies if this issue has been already posted on this list. Despite
>> having seen multiple posts here on similar topics, I have not been able
>> to find an answer to these questions.
>>
>> Thanks in advance for your help. Any suggestion is very welcome.
>>
>> Regards,
>>
>> Vincenzo
>>
>>
>>> summary(lme4Model.full)
>> Linear mixed model fit by maximum likelihood  ['lmerMod']
>> Formula: values ~ week * genotype + (week | probesets)
>>     Data: dataset
>>
>>       AIC      BIC   logLik deviance df.resid
>>   72325.3  72412.8 -36154.7  72309.3   414337
>>
>> Scaled residuals:
>>       Min       1Q   Median       3Q      Max
>> -13.2622  -0.5246   0.0128   0.5270  23.3456
>>
>> Random effects:
>>   Groups    Name        Variance Std.Dev. Corr
>>   probesets (Intercept) 5.167338 2.27318
>>             week        0.005029 0.07092  -0.23
>>   Residual              0.047063 0.21694
>> Number of obs: 414345, groups:  probesets, 18015
>>
>> Fixed effects:
>>                     Estimate Std. Error t value
>> (Intercept)       6.5727983  0.0169414   388.0
>> week             -0.0151336  0.0006823   -22.2
>> genotypeCSB       0.2405300  0.0007121   337.8
>> week:genotypeCSB  0.0050430  0.0006962     7.2
>>
>> Correlation of Fixed Effects:
>>              (Intr) week   gntCSB
>> week        -0.177
>> genotypeCSB -0.015 -0.028
>> wk:gntypCSB -0.001 -0.392 -0.054
>>
>>
>>> summary(lmModel.full)
>> Call:
>> lm(formula = values ~ week * genotype, data = dataset)
>>
>> Residuals:
>>      Min      1Q  Median      3Q     Max
>> -5.7560 -1.9881  0.0083  1.6823  7.6407
>>
>> Coefficients:
>>                    Estimate Std. Error  t value Pr(>|t|)
>> (Intercept)       6.572798   0.004407 1491.384  < 2e-16 ***
>> week             -0.015134   0.004547   -3.329 0.000873 ***
>> genotypeCSB       0.240530   0.007500   32.072  < 2e-16 ***
>> week:genotypeCSB  0.005043   0.007331    0.688 0.491537
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Residual standard error: 2.285 on 414341 degrees of freedom
>> Multiple R-squared:  0.002491,	Adjusted R-squared:  0.002484
>> F-statistic: 344.9 on 3 and 414341 DF,  p-value: < 2.2e-16
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dakotajudo at me.com  Fri Jan  2 16:34:18 2015
From: dakotajudo at me.com (Peter Claussen)
Date: Fri, 02 Jan 2015 09:34:18 -0600
Subject: [R-sig-ME] standard error and statistical significance in
	lmer	versus lm
In-Reply-To: <549DB2DF.9040009@ics.forth.gr>
References: <549DB2DF.9040009@ics.forth.gr>
Message-ID: <4486A94C-706B-4D6D-A7FB-17C6E5444A9E@me.com>

Vincenzo,

If I?m reading this correctly, I don?t think you?re comparing the same models, lm vs lmer

Using lm, you have two models
	values ~ week + genotype
	values ~ week * genotype

Using lmer, you have two different models.
	week + genotype + (week | probesets)
	week * genotype + (week | probesets)

If you were to include (week:probesets) in your lm models, and compare
	values ~ week + genotype + week:probesets
	values ~ week * genotype + week:probesets

would that clarify the confusion about the different results?

Peter


> On Dec 26, 2014, at 1:11 PM, Vincenzo Lagani <vlagani at ics.forth.gr> wrote:
> 
> Dear all,
> 
> I am modelling gene expression data with mixed models using lme4. My 
> goal is to assess whether gene expression globally decreases or 
> increases with time.
> 
> Specifically, the data consist in whole expression profiles measured at 
> five different time points in two different strains of mice. For each 
> time point and each strain there are three replicates. The data are not 
> longitudinal, i.e., different mice are used at each time point. We had 
> to remove one profile from a time point because it was not matching our 
> quality criteria, so the data became not properly balanced.
> 
> On these data I am fitting the following model:
> 
> lme4Model.full <- lmer(values ~ week * genotype + (week | probesets), 
> data = dataset, REML = FALSE)
> 
> where 'values' stands for the gene expression, 'week' is a scaled 
> numeric reporting the age of the mice in weeks, and 'genotype' is a 
> factor with two levels representing the two different genetic 
> backgrounds. Each single gene is let having its own random intercept and 
> slope.
> 
> What puzzles me is that when I compare this model with its simpler, 
> non-mixed version:
> 
> lmModel.full <- lm(values ~ week * genotype, data = dataset)
> 
> I obtain the same coefficients but different standard errors (see 
> below). Furthermore, while the interaction coefficient is not 
> significant in the simple linear model, it becomes highly significant in 
> the mixed model, at least according to these ANOVA tests:
> 
> lmModel <- lm(values ~ week + genotype, data = dataset)
> lme4Model <- lmer(values ~ week + genotype + (week | probesets), data = 
> dataset, REML = FALSE)
> 
>> anova(lmModel.full, lmModel)
> Analysis of Variance Table
> 
> Model 1: values ~ week * genotype
> Model 2: values ~ week + genotype
>   Res.Df     RSS Df Sum of Sq      F Pr(>F)
> 1 414341 2162664
> 2 414342 2162666 -1   -2.4697 0.4732 0.4915
> 
>> anova(lme4Model.full, lme4Model)
> Data: dataset
> Models:
> lme4Model: values ~ week + genotype + (week | probesets)
> lme4Model.full: values ~ week * genotype + (week | probesets)
>                Df   AIC   BIC logLik deviance  Chisq Chi Df Pr(>Chisq)
> lme4Model       7 72376 72452 -36181    72362
> lme4Model.full  8 72325 72413 -36155    72309 52.472      1  4.364e-13 ***
> 
> 
> 
> Assessing whether the interaction coefficient is significant is actually 
> the aim of my study, and having two totally different answers confuses 
> me. My understanding is that the mixed model better catches the variance 
> structure of the data and thus it is able to better estimate the 
> standard errors and p-values of the coefficients. Is this correct? In 
> other words, can I confidently claim that the p-values obtained from the 
> mixed models are "the correct ones" and that the interaction term is 
> actually significant?
> 
> My apologies if this issue has been already posted on this list. Despite 
> having seen multiple posts here on similar topics, I have not been able 
> to find an answer to these questions.
> 
> Thanks in advance for your help. Any suggestion is very welcome.
> 
> Regards,
> 
> Vincenzo
> 
> 
>> summary(lme4Model.full)
> Linear mixed model fit by maximum likelihood  ['lmerMod']
> Formula: values ~ week * genotype + (week | probesets)
>    Data: dataset
> 
>      AIC      BIC   logLik deviance df.resid
>  72325.3  72412.8 -36154.7  72309.3   414337
> 
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -13.2622  -0.5246   0.0128   0.5270  23.3456
> 
> Random effects:
>  Groups    Name        Variance Std.Dev. Corr
>  probesets (Intercept) 5.167338 2.27318
>            week        0.005029 0.07092  -0.23
>  Residual              0.047063 0.21694
> Number of obs: 414345, groups:  probesets, 18015
> 
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)       6.5727983  0.0169414   388.0
> week             -0.0151336  0.0006823   -22.2
> genotypeCSB       0.2405300  0.0007121   337.8
> week:genotypeCSB  0.0050430  0.0006962     7.2
> 
> Correlation of Fixed Effects:
>             (Intr) week   gntCSB
> week        -0.177
> genotypeCSB -0.015 -0.028
> wk:gntypCSB -0.001 -0.392 -0.054
> 
> 
>> summary(lmModel.full)
> 
> Call:
> lm(formula = values ~ week * genotype, data = dataset)
> 
> Residuals:
>     Min      1Q  Median      3Q     Max
> -5.7560 -1.9881  0.0083  1.6823  7.6407
> 
> Coefficients:
>                   Estimate Std. Error  t value Pr(>|t|)
> (Intercept)       6.572798   0.004407 1491.384  < 2e-16 ***
> week             -0.015134   0.004547   -3.329 0.000873 ***
> genotypeCSB       0.240530   0.007500   32.072  < 2e-16 ***
> week:genotypeCSB  0.005043   0.007331    0.688 0.491537
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 2.285 on 414341 degrees of freedom
> Multiple R-squared:  0.002491,	Adjusted R-squared:  0.002484
> F-statistic: 344.9 on 3 and 414341 DF,  p-value: < 2.2e-16
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dakotajudo at mac.com  Fri Jan  2 22:23:10 2015
From: dakotajudo at mac.com (Peter Claussen)
Date: Fri, 02 Jan 2015 15:23:10 -0600
Subject: [R-sig-ME] standard error and statistical significance in lmer
 versus lm
In-Reply-To: <54A6E071.6040003@ics.forth.gr>
References: <549DB2DF.9040009@ics.forth.gr>
	<4486A94C-706B-4D6D-A7FB-17C6E5444A9E@me.com>
	<54A6E071.6040003@ics.forth.gr>
Message-ID: <44EEA10D-2B1D-4736-88B3-91A0484D3985@mac.com>

Vincenzo,

My comments are strictly about the computations, as I understand them, and not about the appropriateness of the models.

First, I want to be clear that I am commenting on your concern about having two different answers. My thinking is that you have two different answers because you  are not asking the same question in each case.

What you seem to be asking is, when using either lm or lmer, is the significance genotype:week interaction different?

But what you are really asking is, if I include probeset in the model, is the significance genotype:week interaction different?

That?s because the model specify for lmer includes probeset, but the model you specify for lm does not. These are two different statistical models, and you would expect different inferences about the significance of genotype:week, regardless of which computational engine you use.

I have not doubt that you are not interested in the specific effect of each gene. Nonetheless, by including probeset in the formula you pass to lmer, you are getting estimates for each effect; they?re just not being reported in the summary for lmer objects. IIRC, you would use ranef to view the for each gene by week (that?s a best guess, I?d really have to see the data to be sure about the interpretation)

You can also model probeset as a random effect using lm. Including a random effect in a linear model does not change the nature of the effect, it simply changes how the effects are estimated - in this case, ordinary least squares vs maximum likelihood. The effective difference is how you would compute F values in the resulting AOV table. aov() in R will only run F-tests against residual error; if you have other random effects in the model you need to compute F values manually.

My suggestion is that you run, on a subset of your data, both
	aov(lm(values ~ week * genotype))
	aov(lm(values ~ week * genotype + week:probesets))
	
then compare the residual error to the residual error of 
	lmer(values ~ week * genotype + (week | probesets))

I suspect the second lm model to be very similar to lmer, and that you might rest assured that you are not getting two different answers. I think your concern arises from not comparing like things.

Peter


> On Jan 2, 2015, at 12:16 PM, Vincenzo Lagani <vlagani at ics.forth.gr> wrote:
> 
> Dear Peter,
> 
> thanks for your suggestion. Unfortunately, even on my most powerful machine I could not fit the models you suggested: R returns a memory error, due to the inability of allocating ~60GB of memory (more than 18000 probesets in my data).
> 
> Moreover, I am not totally sure if the model you suggested is suitable for my application. While I fully agree with you that it would be interesting to observe what happens when the variability due to the probesets is explicitly modeled, I must say that I am not interested in the specific effect of each single gene. Moreover, the set of genes I am using can be considered as a (more or less) random sample from the set of all mouse genes. Thus, it seems to me that the term "probesets" should be definitely modeled as a random term.
> 
> Thanks again and kind regards,
> 
> Vincenzo
> 
> On 1/2/2015 4:34 PM, Peter Claussen wrote:
>> Vincenzo,
>> 
>> If I?m reading this correctly, I don?t think you?re comparing the same models, lm vs lmer
>> 
>> Using lm, you have two models
>> 	values ~ week + genotype
>> 	values ~ week * genotype
>> 
>> Using lmer, you have two different models.
>> 	week + genotype + (week | probesets)
>> 	week * genotype + (week | probesets)
>> 
>> If you were to include (week:probesets) in your lm models, and compare
>> 	values ~ week + genotype + week:probesets
>> 	values ~ week * genotype + week:probesets
>> 
>> would that clarify the confusion about the different results?
>> 
>> Peter
>> 
>> 
>>> On Dec 26, 2014, at 1:11 PM, Vincenzo Lagani <vlagani at ics.forth.gr> wrote:
>>> 
>>> Dear all,
>>> 
>>> I am modelling gene expression data with mixed models using lme4. My
>>> goal is to assess whether gene expression globally decreases or
>>> increases with time.
>>> 
>>> Specifically, the data consist in whole expression profiles measured at
>>> five different time points in two different strains of mice. For each
>>> time point and each strain there are three replicates. The data are not
>>> longitudinal, i.e., different mice are used at each time point. We had
>>> to remove one profile from a time point because it was not matching our
>>> quality criteria, so the data became not properly balanced.
>>> 
>>> On these data I am fitting the following model:
>>> 
>>> lme4Model.full <- lmer(values ~ week * genotype + (week | probesets),
>>> data = dataset, REML = FALSE)
>>> 
>>> where 'values' stands for the gene expression, 'week' is a scaled
>>> numeric reporting the age of the mice in weeks, and 'genotype' is a
>>> factor with two levels representing the two different genetic
>>> backgrounds. Each single gene is let having its own random intercept and
>>> slope.
>>> 
>>> What puzzles me is that when I compare this model with its simpler,
>>> non-mixed version:
>>> 
>>> lmModel.full <- lm(values ~ week * genotype, data = dataset)
>>> 
>>> I obtain the same coefficients but different standard errors (see
>>> below). Furthermore, while the interaction coefficient is not
>>> significant in the simple linear model, it becomes highly significant in
>>> the mixed model, at least according to these ANOVA tests:
>>> 
>>> lmModel <- lm(values ~ week + genotype, data = dataset)
>>> lme4Model <- lmer(values ~ week + genotype + (week | probesets), data =
>>> dataset, REML = FALSE)
>>> 
>>>> anova(lmModel.full, lmModel)
>>> Analysis of Variance Table
>>> 
>>> Model 1: values ~ week * genotype
>>> Model 2: values ~ week + genotype
>>>   Res.Df     RSS Df Sum of Sq      F Pr(>F)
>>> 1 414341 2162664
>>> 2 414342 2162666 -1   -2.4697 0.4732 0.4915
>>> 
>>>> anova(lme4Model.full, lme4Model)
>>> Data: dataset
>>> Models:
>>> lme4Model: values ~ week + genotype + (week | probesets)
>>> lme4Model.full: values ~ week * genotype + (week | probesets)
>>>                Df   AIC   BIC logLik deviance  Chisq Chi Df Pr(>Chisq)
>>> lme4Model       7 72376 72452 -36181    72362
>>> lme4Model.full  8 72325 72413 -36155    72309 52.472      1  4.364e-13 ***
>>> 
>>> 
>>> 
>>> Assessing whether the interaction coefficient is significant is actually
>>> the aim of my study, and having two totally different answers confuses
>>> me. My understanding is that the mixed model better catches the variance
>>> structure of the data and thus it is able to better estimate the
>>> standard errors and p-values of the coefficients. Is this correct? In
>>> other words, can I confidently claim that the p-values obtained from the
>>> mixed models are "the correct ones" and that the interaction term is
>>> actually significant?
>>> 
>>> My apologies if this issue has been already posted on this list. Despite
>>> having seen multiple posts here on similar topics, I have not been able
>>> to find an answer to these questions.
>>> 
>>> Thanks in advance for your help. Any suggestion is very welcome.
>>> 
>>> Regards,
>>> 
>>> Vincenzo
>>> 
>>> 
>>>> summary(lme4Model.full)
>>> Linear mixed model fit by maximum likelihood  ['lmerMod']
>>> Formula: values ~ week * genotype + (week | probesets)
>>>    Data: dataset
>>> 
>>>      AIC      BIC   logLik deviance df.resid
>>>  72325.3  72412.8 -36154.7  72309.3   414337
>>> 
>>> Scaled residuals:
>>>      Min       1Q   Median       3Q      Max
>>> -13.2622  -0.5246   0.0128   0.5270  23.3456
>>> 
>>> Random effects:
>>>  Groups    Name        Variance Std.Dev. Corr
>>>  probesets (Intercept) 5.167338 2.27318
>>>            week        0.005029 0.07092  -0.23
>>>  Residual              0.047063 0.21694
>>> Number of obs: 414345, groups:  probesets, 18015
>>> 
>>> Fixed effects:
>>>                    Estimate Std. Error t value
>>> (Intercept)       6.5727983  0.0169414   388.0
>>> week             -0.0151336  0.0006823   -22.2
>>> genotypeCSB       0.2405300  0.0007121   337.8
>>> week:genotypeCSB  0.0050430  0.0006962     7.2
>>> 
>>> Correlation of Fixed Effects:
>>>             (Intr) week   gntCSB
>>> week        -0.177
>>> genotypeCSB -0.015 -0.028
>>> wk:gntypCSB -0.001 -0.392 -0.054
>>> 
>>> 
>>>> summary(lmModel.full)
>>> Call:
>>> lm(formula = values ~ week * genotype, data = dataset)
>>> 
>>> Residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -5.7560 -1.9881  0.0083  1.6823  7.6407
>>> 
>>> Coefficients:
>>>                   Estimate Std. Error  t value Pr(>|t|)
>>> (Intercept)       6.572798   0.004407 1491.384  < 2e-16 ***
>>> week             -0.015134   0.004547   -3.329 0.000873 ***
>>> genotypeCSB       0.240530   0.007500   32.072  < 2e-16 ***
>>> week:genotypeCSB  0.005043   0.007331    0.688 0.491537
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Residual standard error: 2.285 on 414341 degrees of freedom
>>> Multiple R-squared:  0.002491,	Adjusted R-squared:  0.002484
>>> F-statistic: 344.9 on 3 and 414341 DF,  p-value: < 2.2e-16
>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From vlagani at ics.forth.gr  Sat Jan  3 15:35:06 2015
From: vlagani at ics.forth.gr (Vincenzo Lagani)
Date: Sat, 03 Jan 2015 15:35:06 +0100
Subject: [R-sig-ME] standard error and statistical significance in lmer
 versus lm
In-Reply-To: <44EEA10D-2B1D-4736-88B3-91A0484D3985@mac.com>
References: <549DB2DF.9040009@ics.forth.gr>
	<4486A94C-706B-4D6D-A7FB-17C6E5444A9E@me.com>
	<54A6E071.6040003@ics.forth.gr>
	<44EEA10D-2B1D-4736-88B3-91A0484D3985@mac.com>
Message-ID: <54A7FE1A.1090702@ics.forth.gr>

Dear Peter,

thanks for your detailed answer. Let me try to summarize your point, or 
at least my understanding of it: the lm and lmer models provide 
different results regarding the significance of the genotype:week term 
because the latter models take in account the information/variance 
explained by the probesets, while the formers do not.

I must say that I agree with you on this point. Just, it did not come to 
my mind earlier how to include the probeset information into the lm model.

Now I have followed your suggestions and I have fitted the following lm 
model on a subsample of the whole dataset:

set.seed(123)
numProbesets <- length(unique(dataset$probesets));
toKeep <- sample(1:numProbesets , size = floor(numProbesets/20), replace 
=TRUE); #selecting a random 5% sample of all probesets
probesetsToKeep <- unique(dataset$probesets)[toKeep];
subdata <- dataset[dataset$probesets %in% probesetsToKeep, ]
lmModel.probeset2.full <- lm(values ~ week * genotype + week*probesets, 
data = subdata)

The genotype:week term is now significant:

>Anova(lmModel.probeset2.full, type =3)
Anova Table (Type III tests)

Response: values
                Sum Sq    Df    F value    Pr(>F)
(Intercept)      1478     1 30817.8390 < 2.2e-16 ***
week                0     1     3.2522  0.071344 .
genotype          265     1  5518.9498 < 2.2e-16 ***
probesets      101240   877  2407.8307 < 2.2e-16 ***
week:genotype       0     1     9.0273  0.002663 **
week:probesets    127   877     3.0093 < 2.2e-16 ***
Residuals         884 18436
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Note that genotype:week is not significant if your original suggestion 
is implemented, i.e., values ~ week * genotype + week:probesets.

All in all, these results reinforce the idea that modelling the probeset 
information is necessary in order to better catch the variance structure 
of the data and to better estimate standard errors and p-values. 
Consequently, it seems that you are right when you say that the problem 
is not whether to use lm or lmer, but whether the probeset information 
is included in the model or not.

Thanks a lot for your contribution. Things seem much clearer to me now.

Regards,

Vincenzo

On 1/2/2015 10:23 PM, Peter Claussen wrote:
> Vincenzo,
>
> My comments are strictly about the computations, as I understand them, and not about the appropriateness of the models.
>
> First, I want to be clear that I am commenting on your concern about having two different answers. My thinking is that you have two different answers because you  are not asking the same question in each case.
>
> What you seem to be asking is, when using either lm or lmer, is the significance genotype:week interaction different?
>
> But what you are really asking is, if I include probeset in the model, is the significance genotype:week interaction different?
>
> That?s because the model specify for lmer includes probeset, but the model you specify for lm does not. These are two different statistical models, and you would expect different inferences about the significance of genotype:week, regardless of which computational engine you use.
>
> I have not doubt that you are not interested in the specific effect of each gene. Nonetheless, by including probeset in the formula you pass to lmer, you are getting estimates for each effect; they?re just not being reported in the summary for lmer objects. IIRC, you would use ranef to view the for each gene by week (that?s a best guess, I?d really have to see the data to be sure about the interpretation)
>
> You can also model probeset as a random effect using lm. Including a random effect in a linear model does not change the nature of the effect, it simply changes how the effects are estimated - in this case, ordinary least squares vs maximum likelihood. The effective difference is how you would compute F values in the resulting AOV table. aov() in R will only run F-tests against residual error; if you have other random effects in the model you need to compute F values manually.
>
> My suggestion is that you run, on a subset of your data, both
> 	aov(lm(values ~ week * genotype))
> 	aov(lm(values ~ week * genotype + week:probesets))
> 	
> then compare the residual error to the residual error of
> 	lmer(values ~ week * genotype + (week | probesets))
>
> I suspect the second lm model to be very similar to lmer, and that you might rest assured that you are not getting two different answers. I think your concern arises from not comparing like things.
>
> Peter
>
>
>> On Jan 2, 2015, at 12:16 PM, Vincenzo Lagani <vlagani at ics.forth.gr> wrote:
>>
>> Dear Peter,
>>
>> thanks for your suggestion. Unfortunately, even on my most powerful machine I could not fit the models you suggested: R returns a memory error, due to the inability of allocating ~60GB of memory (more than 18000 probesets in my data).
>>
>> Moreover, I am not totally sure if the model you suggested is suitable for my application. While I fully agree with you that it would be interesting to observe what happens when the variability due to the probesets is explicitly modeled, I must say that I am not interested in the specific effect of each single gene. Moreover, the set of genes I am using can be considered as a (more or less) random sample from the set of all mouse genes. Thus, it seems to me that the term "probesets" should be definitely modeled as a random term.
>>
>> Thanks again and kind regards,
>>
>> Vincenzo
>>
>> On 1/2/2015 4:34 PM, Peter Claussen wrote:
>>> Vincenzo,
>>>
>>> If I?m reading this correctly, I don?t think you?re comparing the same models, lm vs lmer
>>>
>>> Using lm, you have two models
>>> 	values ~ week + genotype
>>> 	values ~ week * genotype
>>>
>>> Using lmer, you have two different models.
>>> 	week + genotype + (week | probesets)
>>> 	week * genotype + (week | probesets)
>>>
>>> If you were to include (week:probesets) in your lm models, and compare
>>> 	values ~ week + genotype + week:probesets
>>> 	values ~ week * genotype + week:probesets
>>>
>>> would that clarify the confusion about the different results?
>>>
>>> Peter
>>>
>>>
>>>> On Dec 26, 2014, at 1:11 PM, Vincenzo Lagani <vlagani at ics.forth.gr> wrote:
>>>>
>>>> Dear all,
>>>>
>>>> I am modelling gene expression data with mixed models using lme4. My
>>>> goal is to assess whether gene expression globally decreases or
>>>> increases with time.
>>>>
>>>> Specifically, the data consist in whole expression profiles measured at
>>>> five different time points in two different strains of mice. For each
>>>> time point and each strain there are three replicates. The data are not
>>>> longitudinal, i.e., different mice are used at each time point. We had
>>>> to remove one profile from a time point because it was not matching our
>>>> quality criteria, so the data became not properly balanced.
>>>>
>>>> On these data I am fitting the following model:
>>>>
>>>> lme4Model.full <- lmer(values ~ week * genotype + (week | probesets),
>>>> data = dataset, REML = FALSE)
>>>>
>>>> where 'values' stands for the gene expression, 'week' is a scaled
>>>> numeric reporting the age of the mice in weeks, and 'genotype' is a
>>>> factor with two levels representing the two different genetic
>>>> backgrounds. Each single gene is let having its own random intercept and
>>>> slope.
>>>>
>>>> What puzzles me is that when I compare this model with its simpler,
>>>> non-mixed version:
>>>>
>>>> lmModel.full <- lm(values ~ week * genotype, data = dataset)
>>>>
>>>> I obtain the same coefficients but different standard errors (see
>>>> below). Furthermore, while the interaction coefficient is not
>>>> significant in the simple linear model, it becomes highly significant in
>>>> the mixed model, at least according to these ANOVA tests:
>>>>
>>>> lmModel <- lm(values ~ week + genotype, data = dataset)
>>>> lme4Model <- lmer(values ~ week + genotype + (week | probesets), data =
>>>> dataset, REML = FALSE)
>>>>
>>>>> anova(lmModel.full, lmModel)
>>>> Analysis of Variance Table
>>>>
>>>> Model 1: values ~ week * genotype
>>>> Model 2: values ~ week + genotype
>>>>    Res.Df     RSS Df Sum of Sq      F Pr(>F)
>>>> 1 414341 2162664
>>>> 2 414342 2162666 -1   -2.4697 0.4732 0.4915
>>>>
>>>>> anova(lme4Model.full, lme4Model)
>>>> Data: dataset
>>>> Models:
>>>> lme4Model: values ~ week + genotype + (week | probesets)
>>>> lme4Model.full: values ~ week * genotype + (week | probesets)
>>>>                 Df   AIC   BIC logLik deviance  Chisq Chi Df Pr(>Chisq)
>>>> lme4Model       7 72376 72452 -36181    72362
>>>> lme4Model.full  8 72325 72413 -36155    72309 52.472      1  4.364e-13 ***
>>>>
>>>>
>>>>
>>>> Assessing whether the interaction coefficient is significant is actually
>>>> the aim of my study, and having two totally different answers confuses
>>>> me. My understanding is that the mixed model better catches the variance
>>>> structure of the data and thus it is able to better estimate the
>>>> standard errors and p-values of the coefficients. Is this correct? In
>>>> other words, can I confidently claim that the p-values obtained from the
>>>> mixed models are "the correct ones" and that the interaction term is
>>>> actually significant?
>>>>
>>>> My apologies if this issue has been already posted on this list. Despite
>>>> having seen multiple posts here on similar topics, I have not been able
>>>> to find an answer to these questions.
>>>>
>>>> Thanks in advance for your help. Any suggestion is very welcome.
>>>>
>>>> Regards,
>>>>
>>>> Vincenzo
>>>>
>>>>
>>>>> summary(lme4Model.full)
>>>> Linear mixed model fit by maximum likelihood  ['lmerMod']
>>>> Formula: values ~ week * genotype + (week | probesets)
>>>>     Data: dataset
>>>>
>>>>       AIC      BIC   logLik deviance df.resid
>>>>   72325.3  72412.8 -36154.7  72309.3   414337
>>>>
>>>> Scaled residuals:
>>>>       Min       1Q   Median       3Q      Max
>>>> -13.2622  -0.5246   0.0128   0.5270  23.3456
>>>>
>>>> Random effects:
>>>>   Groups    Name        Variance Std.Dev. Corr
>>>>   probesets (Intercept) 5.167338 2.27318
>>>>             week        0.005029 0.07092  -0.23
>>>>   Residual              0.047063 0.21694
>>>> Number of obs: 414345, groups:  probesets, 18015
>>>>
>>>> Fixed effects:
>>>>                     Estimate Std. Error t value
>>>> (Intercept)       6.5727983  0.0169414   388.0
>>>> week             -0.0151336  0.0006823   -22.2
>>>> genotypeCSB       0.2405300  0.0007121   337.8
>>>> week:genotypeCSB  0.0050430  0.0006962     7.2
>>>>
>>>> Correlation of Fixed Effects:
>>>>              (Intr) week   gntCSB
>>>> week        -0.177
>>>> genotypeCSB -0.015 -0.028
>>>> wk:gntypCSB -0.001 -0.392 -0.054
>>>>
>>>>
>>>>> summary(lmModel.full)
>>>> Call:
>>>> lm(formula = values ~ week * genotype, data = dataset)
>>>>
>>>> Residuals:
>>>>      Min      1Q  Median      3Q     Max
>>>> -5.7560 -1.9881  0.0083  1.6823  7.6407
>>>>
>>>> Coefficients:
>>>>                    Estimate Std. Error  t value Pr(>|t|)
>>>> (Intercept)       6.572798   0.004407 1491.384  < 2e-16 ***
>>>> week             -0.015134   0.004547   -3.329 0.000873 ***
>>>> genotypeCSB       0.240530   0.007500   32.072  < 2e-16 ***
>>>> week:genotypeCSB  0.005043   0.007331    0.688 0.491537
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Residual standard error: 2.285 on 414341 degrees of freedom
>>>> Multiple R-squared:  0.002491,	Adjusted R-squared:  0.002484
>>>> F-statistic: 344.9 on 3 and 414341 DF,  p-value: < 2.2e-16
>>>>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From tim.cole at ucl.ac.uk  Tue Jan  6 13:34:57 2015
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Tue, 6 Jan 2015 12:34:57 +0000
Subject: [R-sig-ME] c++ exception with logistic glmer
Message-ID: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>

I'm returning to a thread I started a year ago. My logistic glmer model (described below) generated an obscure error message, which Emmanuel Curis pointed out arose from duplicate rows in my data. Ben Bolker and David Duffy thought there might be separation in the cleaned dataset, and Jonathan French and Ben suggested an alternative time-to-event analysis instead of the logistic.

The dataset consists of longitudinal measures of a binary bone maturity score called mat, which for each subject (n = 607) consists of zero or more 0s followed by zero or more 1s, the age at 0/1 transition constituting the subject's age at maturity. The aim is to estimate median age at maturity, given by ?intercept/age coefficient and confidence interval based on Fieller's theorem.

The full data frame is bhs (4565 rows), while dfs is a reduced data frame (1086 rows) consisting of the last mat 0 entry and first mat 1 entry per subject (where available).

Using glm ignores the longitudinal element, whille glmer allows a random subject intercept reflecting inter-subject variability in age at maturity.

lm0 <- glm(mat ~ age, family=binomial, data=bhs)
lm0r <- glm(mat ~ age, family=binomial, data=dfs)
for (n in c(0, 1, 5, 9)) {
assign(paste('lm0', n, sep='.'), glmer(mat ~ age + (1 | BHID), family=binomial, data=bhs, nAGQ=n))
assign(paste('lm0r', n, sep='.'), glmer(mat ~ age + (1 | BHID), family=binomial, data=dfs, nAGQ=n))
}
list <- ls(pattern='^lm0')
unlist(list, function(z) {
res <- BIC(get(z))
names(res) <- z
res
}))
             lm0    lm0.0    lm0.1    lm0.5    lm0.9     lm0r   lm0r.0   lm0r.1   lm0r.5   lm0r.9
2474.576 1812.824 1386.288 1788.585 1778.761 1298.951 1305.941 1305.941 1305.941 1305.941

With the full data frame (models lm0.n) BIC varies with nAGQ, and for the Laplace fit (nAGQ=1) the model looks dodgy. The coefficients are as follows:

$lm0
              Estimate Std. Error   z value      Pr(>|z|)
(Intercept) -18.700922  0.5783898 -32.33273 2.426656e-229
age           1.169465  0.0363381  32.18288 3.063925e-227

$lm0.0
              Estimate Std. Error   z value      Pr(>|z|)
(Intercept) -75.261703  3.3652807 -22.36417 8.790724e-111
age           4.710325  0.2086032  22.58031 6.766768e-113

$lm0.1
              Estimate Std. Error   z value Pr(>|z|)
(Intercept) -276.41591 1.21959198 -226.6462        0
age           17.35977 0.08850143  196.1525        0

$lm0.5
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -71.992747  6.7038887 -10.73895 6.679749e-27
age           4.497433  0.4186714  10.74215 6.452210e-27

$lm0.9
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -80.623844  8.9423308 -9.015976 1.951243e-19
age           5.035102  0.5569928  9.039797 1.569631e-19

As expected the regression line is steeper with the random effect included, though again lm0.1 look odd.

With the reduced data frame the lmr.n models do not vary with nAGQ. But the odder thing is that the coefficients are identical with and without the random effect, as the SD of the random effect is estimated to be zero.

$lm0r
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -8.6820194 0.69870600 -12.42586 1.891928e-35
age          0.5393926 0.04395768  12.27072 1.300837e-34

$lm0r.0
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -8.6820193 0.69864489 -12.42694 1.866391e-35
age          0.5393926 0.04395395  12.27177 1.284216e-34

So I have two questions. Why do the results with the full data frame depend on nAGQ, and why with the reduced data frame is the SD of random effect estimated as zero?

Thanks for your thoughts.

Tim
 ---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population, Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK


Date: Mon, 06 Jan 2014 08:43:21 -0500
From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
To: "Cole, Tim" <tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk>>,
"r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] c++ exception with logistic glmer
Message-ID: <52CAB2F9.50306 at gmail.com<mailto:52CAB2F9.50306 at gmail.com>>
Content-Type: text/plain; charset=ISO-8859-1

On 14-01-06 04:04 AM, Cole, Tim wrote:
The dataset consists of longitudinal measures of bone score during
puberty, where 1000 indicates maturity. The aim is to estimate median
age at maturity in four groups by sex and ethnicity.
This glm code works fine, but ignores the longitudinal element. lm2
<- glm(I(RUSBoneScore == 1000) ~ log(DecAge) + Sex * Ethnicity,
family=binomial, data=na.omit(bh[, 3:6]))
This code, which adds a random subject effect, fails with the
unhelpful error message below. lm3 <- glmer(I(RUSBoneScore == 1000) ~
log(DecAge) + Sex * Ethnicity + (1 | BHID), family=binomial,
data=na.omit(bh[, 2:6]))
Error in pwrssUpdate(pp, resp, tolPwrss, GHrule(0L), compDev,
verbose) : c++ exception (unknown reason)
I've tried various alternatives but they all fail in the same way.
Thoughts please.

    Hard to say without a reproducible example. My main comment is that
this is *not* a problem I have seen anyone report before.  sessionInfo()
please?  Can you try with verbose=100? Can you make a reproducible
example that is a reasonable size and doesn't have confidentiality problems?

  Ben Bolker

Thanks, Tim Cole -- Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ucl.ac.uk><mailto:Tim.Cole at ich.ucl.ac.uk>
Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381 Centre for Paediatric
Epidemiology and Biostatistics UCL Institute of Child Health, London
WC1N 1EH, UK




------------------------------

Message: 2
Date: Tue, 7 Jan 2014 02:08:06 +0000 (UTC)
From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Fit negative binomial glmm credible intervals
from the predict function?
Message-ID: <loom.20140107T030759-892 at post.gmane.org<mailto:loom.20140107T030759-892 at post.gmane.org>>
Content-Type: text/plain; charset=us-ascii

Sheryn Olson <sheryn.olson at ...> writes:

Hello Ben and all,
Thank you Ben, very much for your previous reply.  Yes, stand/plot makes
sense.  After talking with a few statisticians, I got convergence!   The
repeated measure issue is solvable with a dummy variable for each of the 3
years (like a fiscal or school year) - so yr1 = 2010smr+2011wtr, and so
on.  Pellet plots were sampled 6 times, 3 each season, vegetation only
once.  Among year variability can be high.
I'm now attempting to make predictive plots from models.  I used UCLA's
method posted at their IRDA site that has a negative binomial example:
             http://www.ats.ucla.edu/stat/r/dae/nbreg.htm
            newdata2 <- cbind(newdata2, predict(m1, newdata2,type =
"link", se.fit=TRUE))
            newdata2 <- within(newdata2, {
            DaysAbsent <- exp(fit)
                  LL <- exp(fit - 1.96 * se.fit)
                  UL <- exp(fit + 1.96 * se.fit)
              })
but I have an uneasy feeling about fitting standard errors from a
gaussian distribution.

  In case it helps, what you're assuming is Normal is the *sampling
distribution of the parameters*, not the data themselves ...

  The bottom line is that what you're doing seems reasonable, with
the caveats already expressed in ?predict.glmmadmb ...

In the past I've used MCMCglmm to estimate credible intervals around the
beta coefficients of a categorical variable, but now,
I have a continuous variable, conifer sapling count.

  Well, technically it's a discrete (count) variable, not continuous ...

  Section 2 of the glmmADMB vignette [vignette("glmmADMB")] has
a bit of information about running post-fit MCMC.   There should
be an example of how to generate confidence intervals (basically,
you would generate predictions for each sampled set of coefficients
and then compute the quantiles or credible intervals of the
predictions), but there isn't (yet ...)

So, lots of questions!
How does one make an accurate predictive graph from a nbinom model?

  Good question.  Not easy, you may need to take some shortcuts
and hope for the best.

Does it make sense to set up a dataframe with the means of the
covariates when the covariates'
distributions were skewed count data?

  It depends what values you want to predict for.  The data frame
typically includes "typical" values of the parameters; you're welcome
to compute predictions for the medians instead if you prefer, or
for a range of values.

How do I use MCMCglmm correctly?

  ??  Do you mean the 'mcmc' argument of glmmadmb?

Is "se.fit" valid for the nbinom log link, or....?

  [Update: I just wrote a bunch of stuff about how se.fit doesn't
work for glmmadmb, when it indeed does! However, I had already
written all the stuff below, which describes more generally how
you would do it by hand, so I'm just going to send it anyway]

  The basic recipe for constructing confidence intervals, as laid out
in http://glmm.wikidot.com/faq in the "Predictions and/or confidence
(or prediction) intervals on predictions" section, is

(1) construct the model matrix (X)
  * If you want predictions on the original model (not this case),
the model.matrix() accessor may work to extract it from the fit for you
  * If not, or if you want to construct predictions for new data,
you need to call model.matrix() with the fixed-effect formula (you
may or may not be able to extract the fixed-effect part of the
formula only from the model, but it's usually fairly easy just
to respecify it

  (2) extract the variance-covariance matrix of the fixed effect
predictors, V (usually just vcov(model))

  (3) extract the fixed-effect coefficients (usually just fixef(model)
or coef(model))

then the predictions (on the linear predictor scale, at the population
level [i.e. ignoring all random effects]) are

X %*% beta

(plus an offset if there is one)

and the standard errors of prediction, *CONDITIONAL ON THE
RANDOM EFFECTS* [i.e. ignoring all uncertainty due to uncertainty
of the random effects] are

  sqrt(diag(X %*% V %*% t(X)))

Then to get confidence intervals you should compute

  inverse_link(fit +/- 1.96*se.fit) exactly as you have below

This assumes further that the sampling distribution of the
coefficients is Normal (in which case the linear computation
we did above will also lead to a Normal distribution, on
the linear predictor scale).  This might not be true for
small or badly behaved data sets (of course it is never
exactly true except asymptotically ...), but there's not
much you can do about it without working much harder.

my Code:
########## CONIFER SAPLINGS by pellets/ha/month (phm)  #####################
#### mod1.all <- glmmadmb(pellets ~ season * (t.con.splgs +
t.dec.trees + pctMidCov + t.BAtrees + cc) +
####                     offset(ln.days)+(1|stand/plot)+ (1|hareyr),
data=hv, family="nbinom")
predCS <- data.frame(
                      t.con.splgs = rep(seq(from = min(hv$t.con.splgs),
to = max(hv$t.con.splgs),length.out = 100), 2),
                          t.dec.trees=rep(mean(hv$t.dec.trees),200),
                          pctMidCov=rep(mean(hv$pctMidCov),200),
t.BAtrees=rep(mean(hv$t.BAtrees),200),cc=rep(mean(hv$cc),200),
                          ln.days=rep(log(30.25),200),
                          season = factor(rep(1:2, each = 100), levels
= 1:2, labels =levels(hv$season)))
predCS <- cbind(predCS, predict(mod1.all, predCS, type = "link", se.fit=TRUE))
predCS <- within(predCS, {
   pellets <- exp(fit)
   LL <- exp(fit - 1.96 * se.fit)   # these seem wrong !!
   UL <- exp(fit + 1.96 * se.fit)   # ??
})

  Do you mean you're suspicious of the code, or that the numbers
it produces seem wrong?

head(predCS)           #  check to see fits
   t.con.splgs t.dec.trees pctMidCov t.BAtrees       cc  ln.days season
       fit    se.fit       UL       LL   pellets
1   0.0000000    3.493585  40.80654  4.117168 82.84937 3.409496    smr
-1.051665 0.5187013 6437.304 842.6536 0.3493557
2   0.7142493    3.493585  40.80654  4.117168 82.84937 3.409496    smr
-1.046329 0.5187194 6471.975 847.1320 0.3512248
3   1.4284985    3.493585  40.80654  4.117168 82.84937 3.409496    smr
-1.040993 0.5187633 6507.163 851.5911 0.3531040
4   2.1427478    3.493585  40.80654  4.117168 82.84937 3.409496    smr
-1.035657 0.5188331 6542.872 856.0304 0.3549932
5   2.8569971    3.493585  40.80654  4.117168 82.84937 3.409496    smr
-1.030321 0.5189286 6579.111 860.4492 0.3568926
6   3.5712464    3.493585  40.80654  4.117168 82.84937 3.409496    smr
-1.024984 0.5190500 6615.885 864.8472 0.3588020
   con.splgs.ha      phm
1      0.00000 2329.038
2      5.10152 2341.499
3     20.40608 2354.027
4     45.91368 2366.622
5     81.62432 2379.284
6    127.53801 2392.014
############# pellets/ha/month (phm) scale up
#############  and scale up saplings to per ha from 0.1ha plot level
predCS <- within(predCS, {
   pellets <- exp(fit)
   phm <- pellets/1.5*10000
    LL <- (exp(fit - 1.96 * se.fit))/1.5*10000
    UL <- (exp(fit + 1.96 * se.fit))/1.5*10000
    con.splgs.ha <- 10*(t.con.splgs^2)          # backtransform square
root and scale up
})
CS <- ggplot(predCS, aes(con.splgs.ha, phm)) +
   theme_bw() +   #eliminates background, gridlines, but not border
   theme(
     plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
#   ,panel.border = element_blank()
    ,panel.background = element_blank()
   ) +
   geom_ribbon(aes(ymin = LL, ymax = UL, fill = season),alpha = .25) +
   #geom_line(aes(colour = season),size = 1) +
   geom_smooth(aes(colour=season, linetype=season),size = 1, se = F) +
   scale_colour_manual(values=c("wtr"= 4, "smr" = 3)) +
   scale_x_continuous(limits = c(0, 25000)) +
   scale_y_continuous(limits = c(0, 12000)) +
   scale_fill_brewer(palette="Accent") +
   theme(legend.position = 'none') +         #get rid of the legend
   labs(x = "Conifer Sapling Count per ha", y = "Predicted Pellets/ha/month")
print(CS)
Thanks for any ideas.
Sheryn




------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 85, Issue 6
*************************************************



	[[alternative HTML version deleted]]


From Javier.Atalah at cawthron.org.nz  Wed Jan  7 03:36:52 2015
From: Javier.Atalah at cawthron.org.nz (Javier Atalah)
Date: Wed, 7 Jan 2015 02:36:52 +0000
Subject: [R-sig-ME] cloglog logistic regression interpretation
In-Reply-To: <C21FD1E5422A1242B4594022DB0A3E193F6B3B@ci011.cawthron.org.nz>
References: <C21FD1E5422A1242B4594022DB0A3E193F6B3B@ci011.cawthron.org.nz>
Message-ID: <C21FD1E5422A1242B4594022DB0A3E193F6B5C@ci011.cawthron.org.nz>

Hi,

Could someone advise me on how to interpret the estimates from a logistic regression using a cloglog link?

I have fitted the following model in lme4:

glm(cbind (dead, live) ~ time + factor(temp) * biomass, data=mussel, family='binomial' (link=cloglog))

                                                Estimate              Std. Error             z value                                 Pr(>|z|)
(Intercept)                                          -4.970                    0.428                     -11.61                    3.64E-31
time                                                       0.015                     0.001                     12.15                     5.81E-34
temp19                                         2.845                     0.235                     12.1                        1.00E-33
biomassL                                             -0.654                    0.148                     -4.42                      9.73E-06
temp19:biomassL                            0.484                     0.194                     2.49                        1.27E-02

Is it correct to say, for example, the estimate of time is 0.015
Thus  1 - (EXP (-EXP (-0.015))) = 0.627

That means the probability of mortality is increasing 62.7% per unit increase of time if all other variables were held constant?

Many thanks in advance.

Javier


#####################################################################################

Note:
This message is for the named person's use only.  It may...{{dropped:18}}


From gaughra at tcd.ie  Wed Jan  7 16:33:44 2015
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Wed, 7 Jan 2015 15:33:44 +0000
Subject: [R-sig-ME] Help with glmmADMB error messages
Message-ID: <CAN=0SEnOvrO9CRSEQvMj8fg_gvMwaj8scbEG0NexrouDyAhcRw@mail.gmail.com>

Hello, I have a global model that seems to be working (albeit with a subset
of my dataset, not my full dataset). There are 9 explanatory variables, 2
random variables and three interaction terms. However I can only get it to
run with two of the interaction terms. The third (habitat:month) causes
this error message which Ive web searched but cant seem to find an
explanation for.

Error in glmmadmb(field_count ~ age + sex + habitat + month + soil + slope
+ : rank of X = 139 < ncol(X) = 142

Habitat has 10 levels and month has 12. Perhaps this is too much for the
model to cope with? Can you shed any light on this problem?

Also, does you know why my model breaks down the more data I include? At
the moment Im including 10,000 rows of data, but I need to analyse ~45,000
rows (and counting).

Many thanks,

-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Jan  7 16:44:27 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Jan 2015 10:44:27 -0500
Subject: [R-sig-ME] Help with glmmADMB error messages
In-Reply-To: <CAN=0SEnOvrO9CRSEQvMj8fg_gvMwaj8scbEG0NexrouDyAhcRw@mail.gmail.com>
References: <CAN=0SEnOvrO9CRSEQvMj8fg_gvMwaj8scbEG0NexrouDyAhcRw@mail.gmail.com>
Message-ID: <CABghstS104BmOeW3R-YT8EU8yZ=+qCc-NgDuTu8S3zeD7E6D3Q@mail.gmail.com>

The problem here is that there are some combinations (probably in the
interaction terms, which aren't showing up in your error message due
to truncation) that are missing from your data.

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021510.html
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q4/019499.html

discuss this issue.

http://rpubs.com/bbolker/6311 shows a worked example of how to find
the problematic columns, and a bit of information on how to work
around the problem.

  Side question: I presume you're using glmmADMB rather than lme4
because you need to fit a negative binomial (or zero-inflated) model?


On Wed, Jan 7, 2015 at 10:33 AM, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
> Hello, I have a global model that seems to be working (albeit with a subset
> of my dataset, not my full dataset). There are 9 explanatory variables, 2
> random variables and three interaction terms. However I can only get it to
> run with two of the interaction terms. The third (habitat:month) causes
> this error message which Ive web searched but cant seem to find an
> explanation for.
>
> Error in glmmadmb(field_count ~ age + sex + habitat + month + soil + slope
> + : rank of X = 139 < ncol(X) = 142
>
> Habitat has 10 levels and month has 12. Perhaps this is too much for the
> model to cope with? Can you shed any light on this problem?
>
> Also, does you know why my model breaks down the more data I include? At
> the moment Im including 10,000 rows of data, but I need to analyse ~45,000
> rows (and counting).
>
> Many thanks,
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Jan  7 20:09:45 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Jan 2015 19:09:45 +0000 (UTC)
Subject: [R-sig-ME] cloglog logistic regression interpretation
References: <C21FD1E5422A1242B4594022DB0A3E193F6B3B@ci011.cawthron.org.nz>
	<C21FD1E5422A1242B4594022DB0A3E193F6B5C@ci011.cawthron.org.nz>
Message-ID: <loom.20150107T194731-986@post.gmane.org>

Javier Atalah <Javier.Atalah at ...> writes:

> 
> Hi,

> Could someone advise me on how to interpret the estimates from a
  logistic regression using a cloglog link?
 
> I have fitted the following model in lme4:
 
> glm(cbind (dead, live) ~ time + factor(temp) * biomass, data=mussel,
  family='binomial' (link=cloglog))

This is not actually a mixed model -- you're using glm(), not glmer().
Even if you were using glmer(), this question is not specifically related
to mixed models, it's a more general, GLM-related question.
 
 Asking in a more general statistics forum such as CrossValidated
(http://stats.stackexchange.com) would be more appropriate (I took
a quick look there and didn't find anything exactly answering your 
question).

> Estimate Std. Error z value Pr(>|z|)
> (Intercept) -4.970 0.428 -11.61 3.64E-31
> time 0.015 0.001 12.15 5.81E-34
> temp19 2.845 0.235 12.1 1.00E-33
> biomassL -0.654 0.148 -4.42 9.73E-06
> temp19:biomassL 0.484 0.194 2.49 1.27E-02

> Is it correct to say, for example, the estimate of time is 0.015
> Thus  1 - (EXP (-EXP (-0.015))) = 0.627

> That means the probability of mortality is 
> increasing 62.7% per unit increase of time if all other
> variables were held constant?

  You can't quite do this.  What you know is that the *log-hazard*
increases by 0.015 per time unit, so the hazard (probability of
mortality per unit time) is multiplied by exp(0.015) = 1.015113
\approx 1.5% per passing time unit.

  Good luck (this looks like a good CV question, but don't
forget to read http://stats.stackexchange.com/help/how-to-ask )

  Ben Bolker


From wzhmelly at gmail.com  Thu Jan  8 01:13:24 2015
From: wzhmelly at gmail.com (Zhaohong)
Date: Wed, 7 Jan 2015 19:13:24 -0500
Subject: [R-sig-ME] [lme4 package] Does the order of rows(trials) in a data
 frame (long format) affect the results of the lmer model (maybe somehow)?
Message-ID: <CAHpascedJxB=ARjjLi0hu=520M04WTy6jnZS3_9UrsBOM_DKeg@mail.gmail.com>

*I believe that the order shouldn't matter, but I don't know why I got
different results after fitting the same model in a data frame that is
ordered differently. *

*Here are my R codes. Did I use the order() function wrongly such that I
got different results?*

*The lmer model fitted with the data frame before it is ordered (There were
no warning messages, and the model was able to converge.):*

*Model1<-lmer(Stimulus.RT~
1+A*B*C+(1+A|Subject)+(1+A*B*C|Item)+(1+A*B*C|Category),
data=edata,verbose=2,control=lmerControl(optCtrl=list(maxfun=500000)))*

*The verbose results are as follows:*
npt = 77 , n =  75
rhobeg =  0.2 , rhoend =  2e-07
   0.020:  86:     -783.903;0.492578 -0.0462110 -0.0363706 -0.0207690
-0.00431843 0.00131644 -0.00481740 -0.00308283 0.502089 -0.0211198
-0.0336018 -0.0237567 -0.00155808 -0.0307396 -0.000390386 0.354830
-0.0308058 -0.0351383 -0.0137964 -0.0238208 -0.0133714 0.305507 -0.0174871
-0.0328382 -0.00155512 0.00996183 0.646703 -0.0258383 -0.00140789
-0.00146090 0.593574 -0.0176632 -0.0351208 0.611448 0.000434827 0.819591
0.735976 -0.105154 0.553306 0.948775 -0.00950248 -0.00976528 -0.0113362
-0.00949456 -0.00980388 -0.0100146 -0.00779947 0.946928 -0.00984788
-0.0101504 -0.00957164 -0.00986887 -0.00987130 -0.00960832 0.946926
-0.0101303 -0.0103410 -0.00976277 -0.00978197 -0.00937871 0.947412
-0.00988796 -0.0100200 -0.0103097 -0.0103002 0.949607 -0.0106541
-0.00943222 -0.0111189 0.947582 -0.0104333 -0.00883065 0.949409 -0.0119380
0.954371
  0.0020: 1266:     -1011.94;0.450579 -0.0561922 -0.0390931 0.00888335
0.0594143 0.0967819 0.0600815 0.0674752 0.220653 0.00904686 -0.0695420
-0.0628733 0.117864 -0.0596009 0.0799141 0.229251 -0.0664593 -0.123684
0.0490019 -0.0235120 -0.0541726 0.118324 -0.0741990 -0.0809683 0.0958857
0.268214 0.249829 0.0324988 0.114487 0.128747 0.0173838 0.0167991
-0.00732449 0.0501891 0.0850320 0.157297 0.746053 -0.130440 0.331480
0.293937 0.0743482 0.0377308 -0.139008 0.0682751 0.0331050 -0.0866526
-0.0383130 0.0117850 -0.0240952 0.0400393 0.0809940 -0.0429156 -0.159851
0.0126200 0.0106298 -0.0212809 0.00295026 -0.00943432 0.0602099 -0.0644152
 0.00000 0.0531561 0.00504124 0.107394 -0.0116981 0.177808 -0.0275010
0.0632146 -0.0964148 0.0448545 0.0930555 -0.0329402 0.233815 0.111024
0.684505
 0.00020: 2829:     -1024.14;0.452709 -0.0579625 -0.0344969 0.0120118
0.0734510 0.0896992 0.0499010 0.0954442 0.229133 0.00559951 -0.0696637
-0.0242122 0.111817 -0.0789206 0.0837580 0.222271 -0.0611380 -0.112126
0.0329055 -0.0277847 -0.00797160 0.120486 -0.0643358 -0.0845771 0.0736635
0.288591 0.257914 -0.00181955 0.110898 0.147722  0.00000 0.000172809
0.00919736 0.0110891 0.0152384 0.00828677 0.748922 -0.123172 0.330259
0.206775 0.0476522 0.0280362 -0.101461 0.0463152 0.0216698 0.0248654
0.170800 0.0176330 -0.0380416 0.0317560 0.142628 -0.0190826 -0.0671519
-0.00752021  0.00000 -0.0188540 0.0493985 -0.0278924 0.112063 -0.127799
 0.00000 0.0437870 -0.0209737 0.0658322 -0.0777777 0.0965694 -0.0408791
0.127360 -0.174456  0.00000 -0.000274027 -0.0130361 2.24477e-05 9.26975e-05
0.0325827
 2.0e-05: 5773:     -1024.50;0.453311 -0.0585468 -0.0356171 0.0124542
0.0734133 0.0881771 0.0507491 0.0961264 0.230039 0.00643291 -0.0684440
-0.0227084 0.110856 -0.0735117 0.0881374 0.222234 -0.0600243 -0.108611
0.0331596 -0.0250605 -0.00237720 0.120825 -0.0585146 -0.0847106 0.0774464
0.290086 0.261511 -3.75224e-05 0.115623 0.142874  0.00000 0.000183608
0.000936919 0.000697002 0.000660236 0.00131320 0.749940 -0.124134 0.330879
0.212274 0.0477193 0.0297672 -0.103379 0.0384115 0.0255082 0.0174492
0.192128 0.0200405 -0.0419245 0.0218963 0.182316 -0.0385164 0.00556693
-0.0984504 0.00132058 -0.0348845 0.0586401 -0.0444801 0.190766 -0.212638
 0.00000 0.000668956 -0.000403147 0.00142120 -0.00175281  0.00000
0.000166863 -0.00106768 0.000914863 0.000467674 -0.00274150 0.00346480
0.00114500 -0.000318531 0.00111171
 2.0e-06: 9248:     -1024.51;0.453348 -0.0584731 -0.0355746 0.0125052
0.0734903 0.0881831 0.0507601 0.0960166 0.230127 0.00645362 -0.0684865
-0.0230384 0.110978 -0.0737085 0.0876321 0.222118 -0.0599844 -0.108724
0.0331173 -0.0250216 -0.00259363 0.120773 -0.0589481 -0.0846303 0.0772936
0.289112 0.261172 -0.000167296 0.115547 0.144054 9.37833e-07 -2.73741e-05
-4.00219e-05 1.07567e-05 3.85261e-05 3.10490e-05 0.750009 -0.124225
0.330861 0.212679 0.0477609 0.0298412 -0.103074 0.0371887 0.0264153
0.0144220 0.197224 0.0205217 -0.0404589 0.0134622 0.191228 -0.0472840
0.0469882 -0.142964 0.0109281 -0.0403486 0.0179550 -0.0346377 0.183949
-0.183214 0.00214351 -0.00362890 0.00276037 -0.0118387 0.0131118  0.00000
5.56133e-05 -0.000257805 0.000368822  0.00000 0.000199027 -0.000336293
0.000352925 -0.000454433 1.25530e-05
 2.0e-07: 15764:     -1024.51;0.453351 -0.0584700 -0.0355723 0.0124965
0.0734787 0.0881846 0.0507616 0.0960397 0.230123 0.00645416 -0.0684847
-0.0230381 0.110983 -0.0737035 0.0876777 0.222123 -0.0599873 -0.108719
0.0331109 -0.0250217 -0.00255763 0.120773 -0.0589676 -0.0846268 0.0772896
0.289120 0.261188 -0.000185005 0.115550 0.144119 2.65656e-06 -6.82831e-06
-2.76466e-05  0.00000 1.83385e-05 7.87228e-07 0.750014 -0.124224 0.330867
0.212670 0.0477592 0.0298445 -0.103084 0.0371768 0.0264019 0.0144639
0.197132 0.0205263 -0.0404874 0.0135545 0.191202 -0.0472145 0.0466104
-0.142610 0.0108195 -0.0403564 0.0185109 -0.0348318 0.184403 -0.183997
0.000797901 -0.00138066 0.00103545 -0.00442881 0.00490172  0.00000
7.51833e-06 -3.87226e-05 6.04092e-05  0.00000 3.63510e-06 -4.49410e-06
1.42910e-06 5.74795e-06 5.03001e-07
At return
30433:    -1024.5110: 0.453352 -0.0584699 -0.0355712 0.0124974 0.0734792
0.0881850 0.0507622 0.0960430 0.230123 0.00645469 -0.0684872 -0.0230377
0.110983 -0.0737051 0.0876725 0.222122 -0.0599864 -0.108715 0.0331096
-0.0250228 -0.00255738 0.120773 -0.0589583 -0.0846263 0.0772945 0.289133
0.261192 -0.000180489 0.115545 0.144090  0.00000 -1.01443e-06 -2.72331e-06
4.36692e-09 2.82744e-07 1.08531e-07 0.750012 -0.124223 0.330865 0.212669
0.0477582 0.0298448 -0.103086 0.0371794 0.0264002 0.0144699 0.197126
0.0205267 -0.0404964 0.0135892 0.191188 -0.0471837 0.0464530 -0.142440
0.0107821 -0.0403469 0.0186941 -0.0348872 0.184494 -0.184176 0.000119925
-0.000204327 0.000154724 -0.000663551 0.000735230 6.17347e-06 -3.20551e-06
1.16271e-05 -1.43359e-05  0.00000 1.40493e-06 -2.16589e-06 1.27346e-06
-2.57135e-06 2.74006e-08

*The model summary is as follows:*
Linear mixed model fit by REML ['lmerMod']
Formula: Stimulus.RRT ~ 1 + A * B * C + (1 + A |      Subject) + (1 + A * B
* C | Item) +
    (1 + A * B * C | Category)
   Data: edata
Control: lmerControl(optCtrl = list(maxfun = 5e+05))

REML criterion at convergence: -1024.5

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.1135 -0.6290 -0.0239  0.6658  3.4528

Random effects:
 Groups   Name                          Variance  Std.Dev. Corr

 Item     (Intercept)                   0.0079856 0.08936

          A1                     0.0021904 0.04680  -0.25

          B1                    0.0019678 0.04436  -0.16  0.07

          C1                      0.0008949 0.02991   0.08 -0.46 -0.42

          A1:B1          0.0034753 0.05895   0.25 -0.14 -0.40  0.04

          A1:C1            0.0011016 0.03319   0.52  0.51  0.13 -0.73  0.10

          B1:C1           0.0010864 0.03296   0.30 -0.50 -0.21  0.65  0.68
-0.39
          A1:B1:C1 0.0047121 0.06864   0.28  0.18 -0.04  0.57  0.25 -0.11
 0.64
 Subject  (Intercept)                   0.0218561 0.14784

          A1                     0.0048530 0.06966  -0.35

 Category (Intercept)                   0.0017573 0.04192

          A1                     0.0001050 0.01025   0.92

          B1                    0.0001028 0.01014   0.58  0.22

          C1                      0.0004833 0.02198  -0.92 -0.80 -0.71

          A1:B1          0.0014875 0.03857   0.19  0.56 -0.64 -0.09

          A1:C1            0.0001609 0.01268   0.41  0.09  0.70 -0.27 -0.69

          B1:C1           0.0014145 0.03761   0.08  0.17  0.05 -0.39  0.34
-0.67
          A1:B1:C1 0.0036161 0.06013   0.65  0.41  0.62 -0.44 -0.39  0.93
-0.65
 Residual                               0.0388540 0.19711

Number of obs: 4064, groups:  Item, 68; Subject, 64; Category, 6

Fixed effects:
                               Estimate Std. Error t value
(Intercept)                   -0.897455   0.027600  -32.52
A1                      0.002163   0.012815    0.17
B1                    -0.085623   0.038088   -2.25
C1                       0.004287   0.014429    0.30
A1:B1          -0.005849   0.027516   -0.21
A1:C1             0.112263   0.075240    1.49
B1:C1            0.014424   0.026637    0.54
A1:B1:C1 -0.275033   0.152135   -1.81

Correlation of Fixed Effects:
            (Intr) A1 B1 C1 A1:B1 A1:C B1:C1
A1   -0.017
B1   0.030  0.012
C1    -0.349 -0.216 -0.064
A1:B1  0.093  0.091 -0.271 -0.028
A1:C1  0.028  0.014  0.006 -0.230 -0.027
B1:C1  0.044  0.000 -0.001 -0.114  0.138   -0.029
A1:B1:C1  0.071  0.025  0.010 -0.036 -0.033    0.010 -0.279

*However, if I reorder the dataset, the model failed to converge:*
*edata.reordered<-edata[order(edata$Subject,edata$Item),]*

*Model2<-lmer(Stimulus.RT~
1+1+A*B*C+(1+A|Subject)+(1+A*B*C|Item)+(1+A*B*C|Category),
data=edata.reordered,verbose=2,control=lmerControl(optCtrl=list(maxfun=500000)))*

*The model failed to converge, with the following warning messages given.
The verbose results are as follows:*
npt = 77 , n =  75
rhobeg =  0.2 , rhoend =  2e-07
   0.020:  86:     -783.903;0.492578 -0.0462110 -0.0363706 -0.0207690
-0.00431843 0.00131644 -0.00481740 -0.00308283 0.502089 -0.0211198
-0.0336018 -0.0237567 -0.00155808 -0.0307396 -0.000390386 0.354830
-0.0308058 -0.0351383 -0.0137964 -0.0238208 -0.0133714 0.305507 -0.0174871
-0.0328382 -0.00155512 0.00996183 0.646703 -0.0258383 -0.00140789
-0.00146090 0.593574 -0.0176632 -0.0351208 0.611448 0.000434827 0.819591
0.735976 -0.105154 0.553306 0.948775 -0.00950248 -0.00976528 -0.0113362
-0.00949456 -0.00980388 -0.0100146 -0.00779947 0.946928 -0.00984788
-0.0101504 -0.00957164 -0.00986887 -0.00987130 -0.00960832 0.946926
-0.0101303 -0.0103410 -0.00976277 -0.00978197 -0.00937871 0.947412
-0.00988796 -0.0100200 -0.0103097 -0.0103002 0.949607 -0.0106541
-0.00943222 -0.0111189 0.947582 -0.0104333 -0.00883065 0.949409 -0.0119380
0.954371
  0.0020: 1139:     -1011.00;0.450616 -0.0596810 -0.0402272 0.0225926
0.0713467 0.103440 0.0602312 0.0721565 0.235672 0.00831575 -0.0664559
-0.0410181 0.131944 -0.0611257 0.0909471 0.234925 -0.0677961 -0.0928579
0.0491887 -0.0160378 -0.0609188 0.111951 -0.0797617 -0.0797398 0.105130
0.265564 0.270820 0.0170410 0.124769 0.199425 0.00278578 0.0268160
-0.00875111 0.0510349 0.110946 0.171222 0.758551 -0.121379 0.340244
0.289164 0.0340301 0.0299344 -0.127966 0.0945493 -0.0521814 -0.0136706
0.0808901 0.00103150 0.00478129 -0.0168369 -0.0419573 0.0154279 -0.0318584
-0.0284232 0.0113707 -0.00386646 -0.00455879 0.0266343 -0.0767034 0.0166990
0.0104083 -0.0298060 0.0336969 -0.0939880 -0.0530341 0.234749 -0.0630262
0.0236229 -0.0798100 0.0822270 -0.0883803 0.0469641 0.374075 0.0619410
0.530030
 0.00020: 2754:     -1024.04;0.453973 -0.0580443 -0.0341541 0.0128765
0.0743429 0.0876562 0.0513254 0.0961985 0.231256 0.00668522 -0.0689680
-0.0198556 0.111337 -0.0720035 0.0878909 0.222762 -0.0592635 -0.109626
0.0323470 -0.0244422 -0.00152948 0.121270 -0.0558188 -0.0840473 0.0772543
0.292009 0.262116 0.000440403 0.116106 0.141180 0.00136894 -0.00339338
-0.00197460 0.00348747 0.0105328 0.0115974 0.749943 -0.123029 0.330931
0.211777 0.0482195 0.0264188 -0.104392 0.0473197 0.0235507 0.0216781
0.184163  0.00000 0.0428526 -0.0310683 -0.175357 0.0368789 0.00217481
0.0939259  0.00000 0.0261004 -0.0313647 0.0268754 -0.122563 0.125346
0.000144427 -0.00203618 -0.000134387 -0.00154909 -0.000171925 0.0680554
-0.0371162 0.127778 -0.153718 0.0109013 -0.0471354 0.0631039 0.0408311
-0.0496230 0.0145855
 2.0e-05: 5427:     -1024.35;0.453500 -0.0588233 -0.0356824 0.0125644
0.0734100 0.0880990 0.0508688 0.0959347 0.230738 0.00618009 -0.0685843
-0.0222441 0.111017 -0.0734275 0.0869347 0.222257 -0.0600188 -0.109157
0.0332115 -0.0247808 -0.00219908 0.120720 -0.0585300 -0.0847411 0.0775846
0.290674 0.261498 -0.000106363 0.115210 0.143180 9.04281e-05 0.000517393
-0.000649503 0.000192640 0.000530472 0.00197453 0.749767 -0.124101 0.330961
0.212375 0.0487225 0.0278073 -0.102167 0.0463200 0.0243823 0.0162048
0.190955  0.00000 0.0439928 -0.0318335 -0.176979 0.0374637 0.00573705
0.0905893 0.00202642 0.0324678 -0.0734993 0.0480481 -0.190881 0.220526
0.000424046 -0.000319556 0.000485731 -0.00232483 0.00320987 0.00183945
-0.000969938 0.00300023 -0.00391019  0.00000 0.00377342 -0.00500665
0.000579337 -0.00215229 0.00124792
 2.0e-06: 6708:     -1024.35;0.453448 -0.0588097 -0.0355748 0.0125304
0.0734757 0.0881016 0.0508944 0.0958161 0.230754 0.00612699 -0.0684914
-0.0222696 0.110948 -0.0734877 0.0875664 0.222282 -0.0600764 -0.109357
0.0332592 -0.0250735 -0.00216874 0.120772 -0.0592389 -0.0846883 0.0772328
0.289264 0.261555 -0.000223966 0.115482 0.143552 1.82883e-06 8.95088e-05
0.000234107 4.38268e-06 -0.000100557 0.000268633 0.750021 -0.124161
0.330928 0.212373 0.0486257 0.0278246 -0.102272 0.0464224 0.0241039
0.0167711 0.190122  0.00000 0.0439680 -0.0319783 -0.176695 0.0374161
0.00595413 0.0898001 0.00213386 0.0324226 -0.0734879 0.0479364 -0.190868
0.220519 0.000515865 -0.000947565 0.000694358 -0.00286088 0.00324899
 0.00000 9.25677e-05 -0.000493308 0.000515791  0.00000 3.22998e-05
1.34428e-06 0.000265348 -0.000330170  0.00000
 2.0e-07: 8013:     -1024.35;0.453452 -0.0588158 -0.0355775 0.0125249
0.0734807 0.0881052 0.0508818 0.0958264 0.230755 0.00613428 -0.0684918
-0.0222859 0.110940 -0.0735018 0.0875183 0.222287 -0.0600648 -0.109338
0.0332510 -0.0250861 -0.00212940 0.120774 -0.0592879 -0.0846939 0.0772195
0.289318 0.261524 -0.000225946 0.115515 0.143581 2.96479e-06 4.74658e-07
-4.67167e-06 6.32876e-07 -1.68484e-05 1.97228e-05 0.750021 -0.124164
0.330935 0.212387 0.0486304 0.0278256 -0.102275 0.0464074 0.0241141
0.0168024 0.190120  0.00000 0.0439746 -0.0319812 -0.176684 0.0373949
0.00599897 0.0897709 0.00214402 0.0324037 -0.0735321 0.0479302 -0.190866
0.220458 0.000500648 -0.000957101 0.000681481 -0.00281640 0.00318786
3.86116e-05 -1.87433e-05 6.35711e-05 -8.10232e-05 2.14600e-06 -9.10076e-06
1.52841e-05 1.48079e-05 -2.33962e-05 4.43378e-06
At return
9308:    -1024.3493: 0.453452 -0.0588161 -0.0355779 0.0125253 0.0734813
0.0881053 0.0508814 0.0958291 0.230755 0.00613352 -0.0684914 -0.0222835
0.110941 -0.0734998 0.0875198 0.222286 -0.0600641 -0.109337 0.0332509
-0.0250859 -0.00212406 0.120774 -0.0592844 -0.0846942 0.0772196 0.289324
0.261524 -0.000224812 0.115519 0.143582  0.00000 6.69837e-07 2.90331e-06
5.81219e-07 -6.03136e-07 3.60563e-06 0.750021 -0.124164 0.330934 0.212389
0.0486307 0.0278253 -0.102276 0.0464083 0.0241164 0.0168007 0.190123
 0.00000 0.0439749 -0.0319808 -0.176684 0.0373947 0.00599638 0.0897735
0.00214274 0.0324038 -0.0735262 0.0479285 -0.190864 0.220444 0.000501759
-0.000958368 0.000680990 -0.00282345 0.00319184 6.93762e-06 -2.82172e-06
7.79924e-06 -1.11704e-05 1.20920e-08 2.23002e-06 -2.13124e-06 2.39686e-06
-2.38538e-06 8.82173e-08
*Warning messages:*
*1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :*
*  Model failed to converge with max|grad| = 0.761054 (tol = 0.002,
component 54)*
*2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :*
*  Model failed to converge: degenerate  Hessian with 1 negative
eigenvalues*

*The model summary is as follows:*
Linear mixed model fit by REML ['lmerMod']
Formula: Stimulus.RRT ~ 1 + RanOrCat * Direction * Running + (1 + RanOrCat
|      Subject) + (1 + RanOrCat * Direction * Running | Item) +
    (1 + RanOrCat * Direction * Running | Category)
   Data: Edata.Correct.NoBadItems.reordered
Control: lmerControl(optCtrl = list(maxfun = 5e+05))

REML criterion at convergence: -1024.3

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.1137 -0.6293 -0.0207  0.6657  3.4540

Random effects:
 Groups   Name                          Variance  Std.Dev. Corr

 Item     (Intercept)                   7.989e-03 0.089382

          RanOrCat1                     2.203e-03 0.046939 -0.25

          Direction1                    1.970e-03 0.044390 -0.16  0.07

          Running1                      8.953e-04 0.029921  0.08 -0.46
-0.42
          RanOrCat1:Direction1          3.488e-03 0.059055  0.25 -0.13
-0.40  0.04
          RanOrCat1:Running1            1.101e-03 0.033188  0.52  0.51
 0.13 -0.73  0.11
          Direction1:Running1           1.085e-03 0.032941  0.30 -0.50
-0.21  0.65  0.67 -0.39
          RanOrCat1:Direction1:Running1 4.708e-03 0.068615  0.28  0.18
-0.04  0.57  0.25 -0.11  0.64
 Subject  (Intercept)                   2.186e-02 0.147840

          RanOrCat1                     4.854e-03 0.069672 -0.35

 Category (Intercept)                   1.753e-03 0.041865

          RanOrCat1                     9.189e-05 0.009586  1.00

          Direction1                    1.054e-04 0.010266  0.53  0.53

          Running1                      4.870e-04 0.022067 -0.91 -0.91
-0.72
          RanOrCat1:Direction1          1.507e-03 0.038816  0.24  0.24
-0.65 -0.07
          RanOrCat1:Running1            1.662e-04 0.012892  0.37  0.37
 0.71 -0.29 -0.70
          Direction1:Running1           1.428e-03 0.037790  0.09  0.09
 0.03 -0.38  0.36 -0.68
          RanOrCat1:Direction1:Running1 3.606e-03 0.060051  0.62  0.62
 0.61 -0.44 -0.39  0.93 -0.66
 Residual                               3.885e-02 0.197114

Number of obs: 4064, groups:  Item, 68; Subject, 64; Category, 6

Fixed effects:
                               Estimate Std. Error t value
(Intercept)                   -0.897433   0.027587  -32.53
RanOrCat1                      0.002115   0.012737    0.17
Direction1                    -0.085626   0.038095   -2.25
Running1                       0.004295   0.014451    0.30
RanOrCat1:Direction1          -0.005863   0.027579   -0.21
RanOrCat1:Running1             0.112270   0.075247    1.49
Direction1:Running1            0.014433   0.026681    0.54
RanOrCat1:Direction1:Running1 -0.275019   0.152130   -1.81

Correlation of Fixed Effects:
            (Intr) RnOrC1 Drctn1 Rnnng1 RnOC1:D1 ROC1:R Dr1:R1
RanOrCat1   -0.014
Direction1   0.028  0.023
Running1    -0.345 -0.229 -0.065
RnOrCt1:Dr1  0.109  0.028 -0.272 -0.020
RnOrCt1:Rn1  0.027  0.020  0.007 -0.231 -0.028
Drctn1:Rnn1  0.049 -0.016 -0.002 -0.111  0.145   -0.030
RnOC1:D1:R1  0.068  0.034  0.010 -0.036 -0.032    0.010 -0.279

*If we compare the two model summaries, we can see that the model summaries
are really similar, with very little differences in values. Nevertheless,
because Model2 failed to converge, I don't know if the model summary is
still reliable and ok to report.*

*Thank you for your time and I truly welcome and appreciate your comments.*

Best,
Zhaohong

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jan  8 05:12:55 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 07 Jan 2015 23:12:55 -0500
Subject: [R-sig-ME] [lme4 package] Does the order of rows(trials) in a
 data frame (long format) affect the results of the lmer model (maybe
 somehow)?
In-Reply-To: <CAHpascedJxB=ARjjLi0hu=520M04WTy6jnZS3_9UrsBOM_DKeg@mail.gmail.com>
References: <CAHpascedJxB=ARjjLi0hu=520M04WTy6jnZS3_9UrsBOM_DKeg@mail.gmail.com>
Message-ID: <54AE03C7.8070805@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-01-07 07:13 PM, Zhaohong wrote:
> *I believe that the order shouldn't matter, but I don't know why I
> got different results after fitting the same model in a data frame
> that is ordered differently. *

  We have seen one case where the order does change the results slightly
(https://github.com/lme4/lme4/issues/262) , and have a
not-yet-reproducible report (see prev link) of a case where the order
changes the standard error estimates considerably more.  That the
order affects the results is surprising, but believable; I/we haven't
had a chance yet to dig through and figure out how the ordering could
change the linear algebra, but clearly it does.

   A couple of comments:

* the factor names are different in your two examples (A/B/C vs
RanOrCt/Direction/Running etc.) -- that makes me mildly suspicious that
there might be some other difference in the input data, but maybe you
just forgot to rewrite something.

   Probably the simplest way to double check these results is to do an
experiment where you input the results from each case as starting values
(e.g. update(model1,start=getME(model2,"theta"))) and see what happens.
Hopefully starting from each of those (very similar) starting points will
get you to the same starting point.

  It would also be worth trying a different optimizer (see
https://rpubs.com/bbolker/lme4trouble1 for examples).

  Having a random effect with only 6 levels (Category) is pushing the
envelope a bit, especially as you're trying to fit an 8x8
variance-covariance
matrix ((A*B*C|Category)); you might try recasting that as a fixed effect.

> 
> *Here are my R codes. Did I use the order() function wrongly such
> that I got different results?*
> 
> *The lmer model fitted with the data frame before it is ordered
> (There were no warning messages, and the model was able to
> converge.):*
> 
> *Model1<-lmer(Stimulus.RT~ 
> 1+A*B*C+(1+A|Subject)+(1+A*B*C|Item)+(1+A*B*C|Category), 
> data=edata,verbose=2,control=lmerControl(optCtrl=list(maxfun=500000)))*
>
>  *The verbose results are as follows:* npt = 77 , n =  75 rhobeg =
> 0.2 , rhoend =  2e-07 0.020:  86:     -783.903;0.492578 -0.0462110
> -0.0363706 -0.0207690 -0.00431843 0.00131644 -0.00481740
> -0.00308283 0.502089 -0.0211198 -0.0336018 -0.0237567 -0.00155808
> -0.0307396 -0.000390386 0.354830 -0.0308058 -0.0351383 -0.0137964
> -0.0238208 -0.0133714 0.305507 -0.0174871 -0.0328382 -0.00155512
> 0.00996183 0.646703 -0.0258383 -0.00140789 -0.00146090 0.593574
> -0.0176632 -0.0351208 0.611448 0.000434827 0.819591 0.735976
> -0.105154 0.553306 0.948775 -0.00950248 -0.00976528 -0.0113362 
> -0.00949456 -0.00980388 -0.0100146 -0.00779947 0.946928
> -0.00984788 -0.0101504 -0.00957164 -0.00986887 -0.00987130
> -0.00960832 0.946926 -0.0101303 -0.0103410 -0.00976277 -0.00978197
> -0.00937871 0.947412 -0.00988796 -0.0100200 -0.0103097 -0.0103002
> 0.949607 -0.0106541 -0.00943222 -0.0111189 0.947582 -0.0104333
> -0.00883065 0.949409 -0.0119380 0.954371

  From comparing with the results below, it looks like the first report
(at step "0.020: 86") is identical between versions, but that the two
versions have diverged slightly by the second report ("0.0020: 1139" in
one case, "0.0020: 1266" in the other)

> 0.0020: 1266:     -1011.94;0.450579 -0.0561922 -0.0390931
> 0.00888335 0.0594143 0.0967819 0.0600815 0.0674752 0.220653
> 0.00904686 -0.0695420 -0.0628733 0.117864 -0.0596009 0.0799141
> 0.229251 -0.0664593 -0.123684 0.0490019 -0.0235120 -0.0541726
> 0.118324 -0.0741990 -0.0809683 0.0958857 0.268214 0.249829
> 0.0324988 0.114487 0.128747 0.0173838 0.0167991 -0.00732449
> 0.0501891 0.0850320 0.157297 0.746053 -0.130440 0.331480 0.293937
> 0.0743482 0.0377308 -0.139008 0.0682751 0.0331050 -0.0866526 
> -0.0383130 0.0117850 -0.0240952 0.0400393 0.0809940 -0.0429156
> -0.159851 0.0126200 0.0106298 -0.0212809 0.00295026 -0.00943432
> 0.0602099 -0.0644152 0.00000 0.0531561 0.00504124 0.107394
> -0.0116981 0.177808 -0.0275010 0.0632146 -0.0964148 0.0448545
> 0.0930555 -0.0329402 0.233815 0.111024 0.684505 0.00020: 2829:
> -1024.14;0.452709 -0.0579625 -0.0344969 0.0120118 0.0734510
> 0.0896992 0.0499010 0.0954442 0.229133 0.00559951 -0.0696637 
> -0.0242122 0.111817 -0.0789206 0.0837580 0.222271 -0.0611380
> -0.112126 0.0329055 -0.0277847 -0.00797160 0.120486 -0.0643358
> -0.0845771 0.0736635 0.288591 0.257914 -0.00181955 0.110898
> 0.147722  0.00000 0.000172809 0.00919736 0.0110891 0.0152384
> 0.00828677 0.748922 -0.123172 0.330259 0.206775 0.0476522 0.0280362
> -0.101461 0.0463152 0.0216698 0.0248654 0.170800 0.0176330
> -0.0380416 0.0317560 0.142628 -0.0190826 -0.0671519 -0.00752021
> 0.00000 -0.0188540 0.0493985 -0.0278924 0.112063 -0.127799 0.00000
> 0.0437870 -0.0209737 0.0658322 -0.0777777 0.0965694 -0.0408791 
> 0.127360 -0.174456  0.00000 -0.000274027 -0.0130361 2.24477e-05
> 9.26975e-05 0.0325827 2.0e-05: 5773:     -1024.50;0.453311
> -0.0585468 -0.0356171 0.0124542 0.0734133 0.0881771 0.0507491
> 0.0961264 0.230039 0.00643291 -0.0684440 -0.0227084 0.110856
> -0.0735117 0.0881374 0.222234 -0.0600243 -0.108611 0.0331596
> -0.0250605 -0.00237720 0.120825 -0.0585146 -0.0847106 0.0774464 
> 0.290086 0.261511 -3.75224e-05 0.115623 0.142874  0.00000
> 0.000183608 0.000936919 0.000697002 0.000660236 0.00131320 0.749940
> -0.124134 0.330879 0.212274 0.0477193 0.0297672 -0.103379 0.0384115
> 0.0255082 0.0174492 0.192128 0.0200405 -0.0419245 0.0218963
> 0.182316 -0.0385164 0.00556693 -0.0984504 0.00132058 -0.0348845
> 0.0586401 -0.0444801 0.190766 -0.212638 0.00000 0.000668956
> -0.000403147 0.00142120 -0.00175281  0.00000 0.000166863
> -0.00106768 0.000914863 0.000467674 -0.00274150 0.00346480 
> 0.00114500 -0.000318531 0.00111171 2.0e-06: 9248:
> -1024.51;0.453348 -0.0584731 -0.0355746 0.0125052 0.0734903
> 0.0881831 0.0507601 0.0960166 0.230127 0.00645362 -0.0684865 
> -0.0230384 0.110978 -0.0737085 0.0876321 0.222118 -0.0599844
> -0.108724 0.0331173 -0.0250216 -0.00259363 0.120773 -0.0589481
> -0.0846303 0.0772936 0.289112 0.261172 -0.000167296 0.115547
> 0.144054 9.37833e-07 -2.73741e-05 -4.00219e-05 1.07567e-05
> 3.85261e-05 3.10490e-05 0.750009 -0.124225 0.330861 0.212679
> 0.0477609 0.0298412 -0.103074 0.0371887 0.0264153 0.0144220
> 0.197224 0.0205217 -0.0404589 0.0134622 0.191228 -0.0472840 
> 0.0469882 -0.142964 0.0109281 -0.0403486 0.0179550 -0.0346377
> 0.183949 -0.183214 0.00214351 -0.00362890 0.00276037 -0.0118387
> 0.0131118  0.00000 5.56133e-05 -0.000257805 0.000368822  0.00000
> 0.000199027 -0.000336293 0.000352925 -0.000454433 1.25530e-05 
> 2.0e-07: 15764:     -1024.51;0.453351 -0.0584700 -0.0355723
> 0.0124965 0.0734787 0.0881846 0.0507616 0.0960397 0.230123
> 0.00645416 -0.0684847 -0.0230381 0.110983 -0.0737035 0.0876777
> 0.222123 -0.0599873 -0.108719 0.0331109 -0.0250217 -0.00255763
> 0.120773 -0.0589676 -0.0846268 0.0772896 0.289120 0.261188
> -0.000185005 0.115550 0.144119 2.65656e-06 -6.82831e-06 
> -2.76466e-05  0.00000 1.83385e-05 7.87228e-07 0.750014 -0.124224
> 0.330867 0.212670 0.0477592 0.0298445 -0.103084 0.0371768 0.0264019
> 0.0144639 0.197132 0.0205263 -0.0404874 0.0135545 0.191202
> -0.0472145 0.0466104 -0.142610 0.0108195 -0.0403564 0.0185109
> -0.0348318 0.184403 -0.183997 0.000797901 -0.00138066 0.00103545
> -0.00442881 0.00490172  0.00000 7.51833e-06 -3.87226e-05
> 6.04092e-05  0.00000 3.63510e-06 -4.49410e-06 1.42910e-06
> 5.74795e-06 5.03001e-07 At return 30433:    -1024.5110: 0.453352
> -0.0584699 -0.0355712 0.0124974 0.0734792 0.0881850 0.0507622
> 0.0960430 0.230123 0.00645469 -0.0684872 -0.0230377 0.110983
> -0.0737051 0.0876725 0.222122 -0.0599864 -0.108715 0.0331096 
> -0.0250228 -0.00255738 0.120773 -0.0589583 -0.0846263 0.0772945
> 0.289133 0.261192 -0.000180489 0.115545 0.144090  0.00000
> -1.01443e-06 -2.72331e-06 4.36692e-09 2.82744e-07 1.08531e-07
> 0.750012 -0.124223 0.330865 0.212669 0.0477582 0.0298448 -0.103086
> 0.0371794 0.0264002 0.0144699 0.197126 0.0205267 -0.0404964
> 0.0135892 0.191188 -0.0471837 0.0464530 -0.142440 0.0107821
> -0.0403469 0.0186941 -0.0348872 0.184494 -0.184176 0.000119925 
> -0.000204327 0.000154724 -0.000663551 0.000735230 6.17347e-06
> -3.20551e-06 1.16271e-05 -1.43359e-05  0.00000 1.40493e-06
> -2.16589e-06 1.27346e-06 -2.57135e-06 2.74006e-08
> 
> *The model summary is as follows:* Linear mixed model fit by REML
> ['lmerMod'] Formula: Stimulus.RRT ~ 1 + A * B * C + (1 + A |
> Subject) + (1 + A * B * C | Item) + (1 + A * B * C | Category) 
> Data: edata Control: lmerControl(optCtrl = list(maxfun = 5e+05))
> 
> REML criterion at convergence: -1024.5
> 
> Scaled residuals: Min      1Q  Median      3Q     Max -4.1135
> -0.6290 -0.0239  0.6658  3.4528
> 
> Random effects: Groups   Name                          Variance
> Std.Dev. Corr Item     (Intercept)      .0079856 0.08936
> 
> A1               0.0021904 0.04680  -0.25 B1
> 0.0019678 0.04436  -0.16  0.07 C1               0.0008949 0.02991
> 0.08 -0.46 -0.42 A1:B1            0.0034753 0.05895   0.25 -0.14
> -0.40  0.04 A1:C1            0.0011016 0.03319   0.52  0.51  0.13
> -0.73  0.10 B1:C1            0.0010864 0.03296   0.30 -0.50 -0.21
> 0.65  0.68 -0.39 A1:B1:C1 0.0047121 0.06864   0.28  0.18 -0.04
> 0.57  0.25 -0.11 0.64 Subject  (Intercept)
> 0.0218561 0.14784
> 
> A1                     0.0048530 0.06966  -0.35 Category
> (Intercept)                   0.0017573 0.04192 A1
> 0.0001050 0.01025   0.92 B1                    0.0001028 0.01014
> 0.58  0.22 C1                      0.0004833 0.02198  -0.92 -0.80
> -0.71 A1:B1          0.0014875 0.03857   0.19  0.56 -0.64 -0.09 
> A1:C1            0.0001609 0.01268   0.41  0.09  0.70 -0.27 -0.69 
> B1:C1           0.0014145 0.03761   0.08  0.17  0.05 -0.39  0.34
> -0.67 A1:B1:C1 0.0036161 0.06013   0.65  0.41  0.62 -0.44 -0.39
> 0.93 -0.65 Residual                               0.0388540
> 0.19711
> 
> Number of obs: 4064, groups:  Item, 68; Subject, 64; Category, 6
> 
> Fixed effects: Estimate Std. Error t value (Intercept)
> -0.897455   0.027600  -32.52 A1                      0.002163
> 0.012815    0.17 B1                    -0.085623   0.038088
> -2.25 C1                       0.004287   0.014429    0.30 A1:B1
> -0.005849   0.027516   -0.21 A1:C1             0.112263   0.075240
> 1.49 B1:C1            0.014424   0.026637    0.54 A1:B1:C1
> -0.275033   0.152135   -1.81
> 
> Correlation of Fixed Effects: (Intr) A1 B1 C1 A1:B1 A1:C B1:C1 A1
> -0.017 B1   0.030  0.012 C1    -0.349 -0.216 -0.064 A1:B1  0.093
> 0.091 -0.271 -0.028 A1:C1  0.028  0.014  0.006 -0.230 -0.027 B1:C1
> 0.044  0.000 -0.001 -0.114  0.138   -0.029 A1:B1:C1  0.071  0.025
> 0.010 -0.036 -0.033    0.010 -0.279
> 
> *However, if I reorder the dataset, the model failed to converge:* 
> *edata.reordered<-edata[order(edata$Subject,edata$Item),]*
> 
> *Model2<-lmer(Stimulus.RT~ 
> 1+1+A*B*C+(1+A|Subject)+(1+A*B*C|Item)+(1+A*B*C|Category), 
> data=edata.reordered,verbose=2,control=lmerControl(optCtrl=list(maxfun=500000)))*
>
>  *The model failed to converge, with the following warning messages
> given. The verbose results are as follows:* npt = 77 , n =  75 
> rhobeg =  0.2 , rhoend =  2e-07 0.020:  86:     -783.903;0.492578
> -0.0462110 -0.0363706 -0.0207690 -0.00431843 0.00131644 -0.00481740
> -0.00308283 0.502089 -0.0211198 -0.0336018 -0.0237567 -0.00155808
> -0.0307396 -0.000390386 0.354830 -0.0308058 -0.0351383 -0.0137964
> -0.0238208 -0.0133714 0.305507 -0.0174871 -0.0328382 -0.00155512
> 0.00996183 0.646703 -0.0258383 -0.00140789 -0.00146090 0.593574
> -0.0176632 -0.0351208 0.611448 0.000434827 0.819591 0.735976
> -0.105154 0.553306 0.948775 -0.00950248 -0.00976528 -0.0113362 
> -0.00949456 -0.00980388 -0.0100146 -0.00779947 0.946928
> -0.00984788 -0.0101504 -0.00957164 -0.00986887 -0.00987130
> -0.00960832 0.946926 -0.0101303 -0.0103410 -0.00976277 -0.00978197
> -0.00937871 0.947412 -0.00988796 -0.0100200 -0.0103097 -0.0103002
> 0.949607 -0.0106541 -0.00943222 -0.0111189 0.947582 -0.0104333
> -0.00883065 0.949409 -0.0119380 0.954371 0.0020: 1139:
> -1011.00;0.450616 -0.0596810 -0.0402272 0.0225926 0.0713467
> 0.103440 0.0602312 0.0721565 0.235672 0.00831575 -0.0664559 
> -0.0410181 0.131944 -0.0611257 0.0909471 0.234925 -0.0677961
> -0.0928579 0.0491887 -0.0160378 -0.0609188 0.111951 -0.0797617
> -0.0797398 0.105130 0.265564 0.270820 0.0170410 0.124769 0.199425
> 0.00278578 0.0268160 -0.00875111 0.0510349 0.110946 0.171222
> 0.758551 -0.121379 0.340244 0.289164 0.0340301 0.0299344 -0.127966
> 0.0945493 -0.0521814 -0.0136706 0.0808901 0.00103150 0.00478129
> -0.0168369 -0.0419573 0.0154279 -0.0318584 -0.0284232 0.0113707
> -0.00386646 -0.00455879 0.0266343 -0.0767034 0.0166990 0.0104083
> -0.0298060 0.0336969 -0.0939880 -0.0530341 0.234749 -0.0630262 
> 0.0236229 -0.0798100 0.0822270 -0.0883803 0.0469641 0.374075
> 0.0619410 0.530030 0.00020: 2754:     -1024.04;0.453973 -0.0580443
> -0.0341541 0.0128765 0.0743429 0.0876562 0.0513254 0.0961985
> 0.231256 0.00668522 -0.0689680 -0.0198556 0.111337 -0.0720035
> 0.0878909 0.222762 -0.0592635 -0.109626 0.0323470 -0.0244422
> -0.00152948 0.121270 -0.0558188 -0.0840473 0.0772543 0.292009
> 0.262116 0.000440403 0.116106 0.141180 0.00136894 -0.00339338 
> -0.00197460 0.00348747 0.0105328 0.0115974 0.749943 -0.123029
> 0.330931 0.211777 0.0482195 0.0264188 -0.104392 0.0473197 0.0235507
> 0.0216781 0.184163  0.00000 0.0428526 -0.0310683 -0.175357
> 0.0368789 0.00217481 0.0939259  0.00000 0.0261004 -0.0313647
> 0.0268754 -0.122563 0.125346 0.000144427 -0.00203618 -0.000134387
> -0.00154909 -0.000171925 0.0680554 -0.0371162 0.127778 -0.153718
> 0.0109013 -0.0471354 0.0631039 0.0408311 -0.0496230 0.0145855 
> 2.0e-05: 5427:     -1024.35;0.453500 -0.0588233 -0.0356824
> 0.0125644 0.0734100 0.0880990 0.0508688 0.0959347 0.230738
> 0.00618009 -0.0685843 -0.0222441 0.111017 -0.0734275 0.0869347
> 0.222257 -0.0600188 -0.109157 0.0332115 -0.0247808 -0.00219908
> 0.120720 -0.0585300 -0.0847411 0.0775846 0.290674 0.261498
> -0.000106363 0.115210 0.143180 9.04281e-05 0.000517393 -0.000649503
> 0.000192640 0.000530472 0.00197453 0.749767 -0.124101 0.330961 
> 0.212375 0.0487225 0.0278073 -0.102167 0.0463200 0.0243823
> 0.0162048 0.190955  0.00000 0.0439928 -0.0318335 -0.176979
> 0.0374637 0.00573705 0.0905893 0.00202642 0.0324678 -0.0734993
> 0.0480481 -0.190881 0.220526 0.000424046 -0.000319556 0.000485731
> -0.00232483 0.00320987 0.00183945 -0.000969938 0.00300023
> -0.00391019  0.00000 0.00377342 -0.00500665 0.000579337 -0.00215229
> 0.00124792 2.0e-06: 6708:     -1024.35;0.453448 -0.0588097
> -0.0355748 0.0125304 0.0734757 0.0881016 0.0508944 0.0958161
> 0.230754 0.00612699 -0.0684914 -0.0222696 0.110948 -0.0734877
> 0.0875664 0.222282 -0.0600764 -0.109357 0.0332592 -0.0250735
> -0.00216874 0.120772 -0.0592389 -0.0846883 0.0772328 0.289264
> 0.261555 -0.000223966 0.115482 0.143552 1.82883e-06 8.95088e-05 
> 0.000234107 4.38268e-06 -0.000100557 0.000268633 0.750021
> -0.124161 0.330928 0.212373 0.0486257 0.0278246 -0.102272 0.0464224
> 0.0241039 0.0167711 0.190122  0.00000 0.0439680 -0.0319783
> -0.176695 0.0374161 0.00595413 0.0898001 0.00213386 0.0324226
> -0.0734879 0.0479364 -0.190868 0.220519 0.000515865 -0.000947565
> 0.000694358 -0.00286088 0.00324899 0.00000 9.25677e-05 -0.000493308
> 0.000515791  0.00000 3.22998e-05 1.34428e-06 0.000265348
> -0.000330170  0.00000 2.0e-07: 8013:     -1024.35;0.453452
> -0.0588158 -0.0355775 0.0125249 0.0734807 0.0881052 0.0508818
> 0.0958264 0.230755 0.00613428 -0.0684918 -0.0222859 0.110940
> -0.0735018 0.0875183 0.222287 -0.0600648 -0.109338 0.0332510
> -0.0250861 -0.00212940 0.120774 -0.0592879 -0.0846939 0.0772195 
> 0.289318 0.261524 -0.000225946 0.115515 0.143581 2.96479e-06
> 4.74658e-07 -4.67167e-06 6.32876e-07 -1.68484e-05 1.97228e-05
> 0.750021 -0.124164 0.330935 0.212387 0.0486304 0.0278256 -0.102275
> 0.0464074 0.0241141 0.0168024 0.190120  0.00000 0.0439746
> -0.0319812 -0.176684 0.0373949 0.00599897 0.0897709 0.00214402
> 0.0324037 -0.0735321 0.0479302 -0.190866 0.220458 0.000500648
> -0.000957101 0.000681481 -0.00281640 0.00318786 3.86116e-05
> -1.87433e-05 6.35711e-05 -8.10232e-05 2.14600e-06 -9.10076e-06 
> 1.52841e-05 1.48079e-05 -2.33962e-05 4.43378e-06 At return 9308:
> -1024.3493: 0.453452 -0.0588161 -0.0355779 0.0125253 0.0734813 
> 0.0881053 0.0508814 0.0958291 0.230755 0.00613352 -0.0684914
> -0.0222835 0.110941 -0.0734998 0.0875198 0.222286 -0.0600641
> -0.109337 0.0332509 -0.0250859 -0.00212406 0.120774 -0.0592844
> -0.0846942 0.0772196 0.289324 0.261524 -0.000224812 0.115519
> 0.143582  0.00000 6.69837e-07 2.90331e-06 5.81219e-07 -6.03136e-07
> 3.60563e-06 0.750021 -0.124164 0.330934 0.212389 0.0486307
> 0.0278253 -0.102276 0.0464083 0.0241164 0.0168007 0.190123 0.00000
> 0.0439749 -0.0319808 -0.176684 0.0373947 0.00599638 0.0897735 
> 0.00214274 0.0324038 -0.0735262 0.0479285 -0.190864 0.220444
> 0.000501759 -0.000958368 0.000680990 -0.00282345 0.00319184
> 6.93762e-06 -2.82172e-06 7.79924e-06 -1.11704e-05 1.20920e-08
> 2.23002e-06 -2.13124e-06 2.39686e-06 -2.38538e-06 8.82173e-08 
> *Warning messages:* *1: In checkConv(attr(opt, "derivs"), opt$par,
> ctrl = control$checkConv,  :* *  Model failed to converge with
> max|grad| = 0.761054 (tol = 0.002, component 54)* *2: In
> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :* *  Model failed to converge: degenerate  Hessian with 1
> negative eigenvalues*
> 
> *The model summary is as follows:* Linear mixed model fit by REML
> ['lmerMod'] Formula: Stimulus.RRT ~ 1 + RanOrCat * Direction *
> Running + (1 + RanOrCat |      Subject) + (1 + RanOrCat * Direction
> * Running | Item) + (1 + RanOrCat * Direction * Running |
> Category) Data: Edata.Correct.NoBadItems.reordered Control:
> lmerControl(optCtrl = list(maxfun = 5e+05))
> 
> REML criterion at convergence: -1024.3
> 
> Scaled residuals: Min      1Q  Median      3Q     Max -4.1137
> -0.6293 -0.0207  0.6657  3.4540
> 
> Random effects: Groups   Name                  Variance  Std.Dev.
> Corr Item     (Intercept)          7.989e-03 0.089382 RanOrCat1
> 2.203e-03 0.046939 -0.25 Direction1           1.970e-03 0.044390
> -0.16  0.07 Running1             8.953e-04 0.029921  0.08 -0.46
> -0.42 RanOrCat1:Direction  3.488e-03 0.059055  0.25 -0.13  -0.40
> 0.04 RanOrCat1:Running1   1.101e-03 0.033188  0.52  0.51  0.13
> -0.73  0.11 Direction1:Running1  1.085e-03 0.032941  0.30 -0.50 >
> -0.21  0.65  0.67 -0.39 RanOrCat1:Direction1:Running1 4.708e-03
> 0.068615  0.28  0.18
                                                -0.04  0.57  0.25
- -0.11  0.64
> Subject  (Intercept)          2.186e-02 0.147840 RanOrCat1
> 4.854e-03 0.069672 -0.35 Category (Intercept)          1.753e-03
> 0.041865 RanOrCat1            9.189e-05 0.009586  1.00 Direction1
> 1.054e-04 0.010266  0.53  0.53 Running1             4.870e-04
> 0.022067 -0.91 -0.91 -0.72 RanOrCat1:Direction1 1.507e-03 0.038816
> 0.24  0.24 -0.65 -0.07 RanOrCat1:Running1   1.662e-04 0.012892
> 0.37  0.37  0.71 -0.29 -0.70 Direction1:Running1  1.428e-03
> 0.037790  0.09  0.09  0.03 -0.38  0.36 -0.68 
> RanOrCat1:Direction1:Running1 3.606e-03 0.060051  0.62  0.62
                                                0.61 -0.44 -0.39  0.93
- -0.66
> Residual                               3.885e-02 0.197114
> 
> Number of obs: 4064, groups:  Item, 68; Subject, 64; Category, 6
> 
> Fixed effects: Estimate Std. Error t value (Intercept)
> -0.897433   0.027587  -32.53 RanOrCat1
> 0.002115   0.012737    0.17 Direction1                    -0.085626
> 0.038095   -2.25 Running1                       0.004295   0.014451
> 0.30 RanOrCat1:Direction1          -0.005863   0.027579   -0.21 
> RanOrCat1:Running1             0.112270   0.075247    1.49 
> Direction1:Running1            0.014433   0.026681    0.54 
> RanOrCat1:Direction1:Running1 -0.275019   0.152130   -1.81
> 
> Correlation of Fixed Effects: (Intr) RnOrC1 Drctn1 Rnnng1 RnOC1:D1
> ROC1:R Dr1:R1 RanOrCat1   -0.014 Direction1   0.028  0.023 Running1
> -0.345 -0.229 -0.065 RnOrCt1:Dr1  0.109  0.028 -0.272 -0.020 
> RnOrCt1:Rn1  0.027  0.020  0.007 -0.231 -0.028 Drctn1:Rnn1  0.049
> -0.016 -0.002 -0.111  0.145   -0.030 RnOC1:D1:R1  0.068  0.034
> 0.010 -0.036 -0.032    0.010 -0.279
> 
> *If we compare the two model summaries, we can see that the model
> summaries are really similar, with very little differences in
> values. Nevertheless, because Model2 failed to converge, I don't
> know if the model summary is still reliable and ok to report.*
> 
> *Thank you for your time and I truly welcome and appreciate your
> comments.*
> 
> Best, Zhaohong
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUrgPHAAoJEOCV5YRblxUH6qIIAJYKp9Djg4a8mf22WqIJ7tE6
/GzQTfdknwQgXwvMHbUP47YEE/mU0ms92zWwj6gvwKG+NsHmGmOrn+qGgqCS9LzC
fI1ou5nYLrcSb2If+aXPWkQ2VYKbxyCh+ycuwbTqV5tz2LAEujbZYCKck+ZSXXFS
UbazesAW618+A7VRIUWIuUtDSBA6qSchXjSZTsrosmCCS8JVtI5N2eOR/uCP3atn
SPOPSPUy33hZaMLzZHpzSM6EV/nC9CAJGTaBtiSCiWbJbMeQiHiHJ9Nyk65sPoSS
XOFfAl5FffLao6QWOWMRkD1q8eF8Y8hdagpniClxEvDc793zewzWALpBtXAgI0A=
=VEtd
-----END PGP SIGNATURE-----


From David.Duffy at qimr.edu.au  Thu Jan  8 06:32:16 2015
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 8 Jan 2015 15:32:16 +1000
Subject: [R-sig-ME] c++ exception with logistic glmer
In-Reply-To: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>
References: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>
Message-ID: <alpine.LMD.2.00.1501081507380.27571@orpheus.qimr.edu.au>

On Tue, 6 Jan 2015, Cole, Tim wrote:

> I'm returning to a thread I started a year ago. My logistic glmer model
[...]B
> and Jonathan French and Ben suggested an alternative time-to-event 
> analysis instead of the logistic.

As now described, your problem is clearly interval censored time-to-event, 
and your logistic model is just not the right approach - bone maturity is 
an irreversible state (consider what happens to your age regression 
coefficient if you add in more ages before or after maturity).  Either do 
the survival analysis, which gives you the median age at maturity, or fit 
a (nonlinear) growth model to maturity score.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From tim.cole at ucl.ac.uk  Thu Jan  8 12:33:42 2015
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Thu, 8 Jan 2015 11:33:42 +0000
Subject: [R-sig-ME] c++ exception with logistic glmer
In-Reply-To: <alpine.LMD.2.00.1501081507380.27571@orpheus.qimr.edu.au>
References: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>
	<alpine.LMD.2.00.1501081507380.27571@orpheus.qimr.edu.au>
Message-ID: <D0D417E9.BB7F%tim.cole@ucl.ac.uk>

David,

I agree that the model can be fitted as an interval-censored time-to-event (actually it's a mix of left, right and interval-censored), but that does not make my approach wrong. In fact it is better in two respects.

First, bone maturity score is subject to measurement error, so it's possible (though rare) to transition from 0 to 1 and then back to 0. Survival analysis treats such points as missing, when they are a valid representation of measurement error.

Second, I am interested in the between-subject SD of the time to maturity, obtained by dividing the random intercept SD by the age coefficient. To my knowledge this is not available from the survival analysis.

Whether or not you are persuaded by these arguments, the fact remains that my two questions about glmer remain valid - its behavour is odd.

Best wishes,
Tim
---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK

From: David Duffy <David.Duffy at qimr.edu.au<mailto:David.Duffy at qimr.edu.au>>
Date: Thursday, 8 January 2015 05:32
To: Tim Cole <tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk>>
Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] c++ exception with logistic glmer

On Tue, 6 Jan 2015, Cole, Tim wrote:

I'm returning to a thread I started a year ago. My logistic glmer model
[...]B
and Jonathan French and Ben suggested an alternative time-to-event
analysis instead of the logistic.

As now described, your problem is clearly interval censored time-to-event,
and your logistic model is just not the right approach - bone maturity is
an irreversible state (consider what happens to your age regression
coefficient if you add in more ages before or after maturity).  Either do
the survival analysis, which gives you the median age at maturity, or fit
a (nonlinear) growth model to maturity score.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au<mailto:David.Duffy at qimrberghofer.edu.au>  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


	[[alternative HTML version deleted]]


From emmanuel.curis at parisdescartes.fr  Thu Jan  8 12:46:07 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Thu, 8 Jan 2015 12:46:07 +0100
Subject: [R-sig-ME] c++ exception with logistic glmer
In-Reply-To: <D0D417E9.BB7F%tim.cole@ucl.ac.uk>
References: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>
	<alpine.LMD.2.00.1501081507380.27571@orpheus.qimr.edu.au>
	<D0D417E9.BB7F%tim.cole@ucl.ac.uk>
Message-ID: <20150108114607.GA28986@info124.pharmacie.univ-paris5.fr>

Tim,

Did you looked at the msm package which, IIRC, allows to implement a
hidden markov model with hidden states the real state (with only 0 ->
1 transition allowed) and allowed states the observed states (which
can then have 1 -> 0 sequences), with transition matrix probabilities
and measurement errors matrixes? This should handle the measurement
errors problems you mention, also handling various censoring.

However, I am not sure it will easily allow to estimate a
between-subject SD of the time to maturity, you should check the
package doc and the underlying model to see if one can access each
individual transition time to have your answer... I am unfortunately
not familiar enough with it to confirm or not that.

On Thu, Jan 08, 2015 at 11:33:42AM +0000, Cole, Tim wrote:
? David,
? 
? I agree that the model can be fitted as an interval-censored time-to-event (actually it's a mix of left, right and interval-censored), but that does not make my approach wrong. In fact it is better in two respects.
? 
? First, bone maturity score is subject to measurement error, so it's possible (though rare) to transition from 0 to 1 and then back to 0. Survival analysis treats such points as missing, when they are a valid representation of measurement error.
? 
? Second, I am interested in the between-subject SD of the time to maturity, obtained by dividing the random intercept SD by the age coefficient. To my knowledge this is not available from the survival analysis.
? 
? Whether or not you are persuaded by these arguments, the fact remains that my two questions about glmer remain valid - its behavour is odd.
? 
? Best wishes,
? Tim
? ---
? Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
? Population Policy and Practice Programme
? UCL Institute of Child Health, London WC1N 1EH, UK
? 
? From: David Duffy <David.Duffy at qimr.edu.au<mailto:David.Duffy at qimr.edu.au>>
? Date: Thursday, 8 January 2015 05:32
? To: Tim Cole <tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk>>
? Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
? Subject: Re: [R-sig-ME] c++ exception with logistic glmer
? 
? On Tue, 6 Jan 2015, Cole, Tim wrote:
? 
? I'm returning to a thread I started a year ago. My logistic glmer model
? [...]B
? and Jonathan French and Ben suggested an alternative time-to-event
? analysis instead of the logistic.
? 
? As now described, your problem is clearly interval censored time-to-event,
? and your logistic model is just not the right approach - bone maturity is
? an irreversible state (consider what happens to your age regression
? coefficient if you add in more ages before or after maturity).  Either do
? the survival analysis, which gives you the median age at maturity, or fit
? a (nonlinear) growth model to maturity score.
? 
? | David Duffy (MBBS PhD)
? | email: David.Duffy at qimrberghofer.edu.au<mailto:David.Duffy at qimrberghofer.edu.au>  ph: INT+61+7+3362-0217 fax: -0101
? | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
? | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A
? 
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From tim.cole at ucl.ac.uk  Thu Jan  8 13:38:49 2015
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Thu, 8 Jan 2015 12:38:49 +0000
Subject: [R-sig-ME] c++ exception with logistic glmer
In-Reply-To: <20150108114607.GA28986@info124.pharmacie.univ-paris5.fr>
References: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>
	<alpine.LMD.2.00.1501081507380.27571@orpheus.qimr.edu.au>
	<D0D417E9.BB7F%tim.cole@ucl.ac.uk>
	<20150108114607.GA28986@info124.pharmacie.univ-paris5.fr>
Message-ID: <D0D4257E.BBD1%tim.cole@ucl.ac.uk>

Thanks Emmanuel. I haven't come across msm.

In my previous post I forgot to respond to David's comment about growth curve modelling. As it happens I have already analysed and published the data that way, using my SITAR model which includes a subject-specific random effect on the age scale. This is exactly analogous to the random effect I am trying to fit with glmer, and hence is another reason why I prefer that approach.

Best wishes,
Tim
---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK

From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr<mailto:emmanuel.curis at parisdescartes.fr>>
Date: Thursday, 8 January 2015 11:46
To: Tim Cole <tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk>>
Cc: David Duffy <David.Duffy at qimr.edu.au<mailto:David.Duffy at qimr.edu.au>>, "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] c++ exception with logistic glmer

Tim,

Did you looked at the msm package which, IIRC, allows to implement a
hidden markov model with hidden states the real state (with only 0 ->
1 transition allowed) and allowed states the observed states (which
can then have 1 -> 0 sequences), with transition matrix probabilities
and measurement errors matrixes? This should handle the measurement
errors problems you mention, also handling various censoring.

However, I am not sure it will easily allow to estimate a
between-subject SD of the time to maturity, you should check the
package doc and the underlying model to see if one can access each
individual transition time to have your answer... I am unfortunately
not familiar enough with it to confirm or not that.

On Thu, Jan 08, 2015 at 11:33:42AM +0000, Cole, Tim wrote:
? David,
?
? I agree that the model can be fitted as an interval-censored time-to-event (actually it's a mix of left, right and interval-censored), but that does not make my approach wrong. In fact it is better in two respects.
?
? First, bone maturity score is subject to measurement error, so it's possible (though rare) to transition from 0 to 1 and then back to 0. Survival analysis treats such points as missing, when they are a valid representation of measurement error.
?
? Second, I am interested in the between-subject SD of the time to maturity, obtained by dividing the random intercept SD by the age coefficient. To my knowledge this is not available from the survival analysis.
?
? Whether or not you are persuaded by these arguments, the fact remains that my two questions about glmer remain valid - its behavour is odd.
?
? Best wishes,
? Tim
? ---
? Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ucl.ac.uk><mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
? Population Policy and Practice Programme
? UCL Institute of Child Health, London WC1N 1EH, UK
?
? From: David Duffy <David.Duffy at qimr.edu.au<mailto:David.Duffy at qimr.edu.au><mailto:David.Duffy at qimr.edu.au>>
? Date: Thursday, 8 January 2015 05:32
? To: Tim Cole <tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk><mailto:tim.cole at ucl.ac.uk>>
? Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>>
? Subject: Re: [R-sig-ME] c++ exception with logistic glmer
?
? On Tue, 6 Jan 2015, Cole, Tim wrote:
?
? I'm returning to a thread I started a year ago. My logistic glmer model
? [...]B
? and Jonathan French and Ben suggested an alternative time-to-event
? analysis instead of the logistic.
?
? As now described, your problem is clearly interval censored time-to-event,
? and your logistic model is just not the right approach - bone maturity is
? an irreversible state (consider what happens to your age regression
? coefficient if you add in more ages before or after maturity).  Either do
? the survival analysis, which gives you the median age at maturity, or fit
? a (nonlinear) growth model to maturity score.
?
? | David Duffy (MBBS PhD)
? | email: David.Duffy at qimrberghofer.edu.au<mailto:David.Duffy at qimrberghofer.edu.au><mailto:David.Duffy at qimrberghofer.edu.au>  ph: INT+61+7+3362-0217 fax: -0101
? | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
? | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A
?
?
? [[alternative HTML version deleted]]
?
? _______________________________________________
? R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr<mailto:emmanuel.curis at parisdescartes.fr>

Page WWW: http://emmanuel.curis.online.fr/index.html


	[[alternative HTML version deleted]]


From dnchariworld at yahoo.com  Thu Jan  8 14:34:58 2015
From: dnchariworld at yahoo.com (Narahara Chari D)
Date: Thu, 8 Jan 2015 13:34:58 +0000 (UTC)
Subject: [R-sig-ME] Genetic Algorithm in R
Message-ID: <1900401465.1483906.1420724098161.JavaMail.yahoo@jws10782.mail.gq1.yahoo.com>

Hi All,
I am trying to implement Genetic Algorithm based on the request to fill 500 ask based on the inventory. Algorithm should pick optimized combinations based on the rank (low rank inventory should be selected first) and update the inventory after fulfilling the request.

dataGA
   Inventory Rank
1        200    2
2        150    1
3        300    3
4        100    4
5         50    1
6        250    1
7        350    2
8        100    2
9        250    3
10        25    4
11       125    4
12       100    5
13       225    1
14       220    2
15       150    3

library(GA)
Rastrigin <- function(x1, x2)
{
    x1*x2 - 500
}

x1 <- dataGA$Inventory
x2 <- seq(0.01, 1, by = 0.01)

f <- outer(x1, x2, Rastrigin)
GA <- ga(type = "real-valued", fitness = function(x) -Rastrigin(x1, x2),
         min = c(1000, 0.01), max = c(10000000, 1), popSize = 50, maxiter = 100)
summary(GA)I have solutions
+-----------------------------------+
|         Genetic Algorithm         |
+-----------------------------------+

GA settings: 
Type                  =  real-valued 
Population size       =  50 
Number of generations =  100 
Elitism               =  2 
Crossover probability =  0.8 
Mutation probability  =  0.1 
Search domain 
     x1   x2
Min  25 0.01
Max 350 1.00

GA results: 
Iterations             = 100 
Fitness function value = 498 
Solutions              = 
             x1        x2
[1,]  194.44965 0.3886958
[2,]  191.24609 0.4016915
[3,]  243.08729 0.3699107
[4,]  137.36235 0.4050092
[5,]  177.33917 0.4570788
[6,]  139.32841 0.3755744
[7,]  137.68704 0.3534409
[8,]  156.28470 0.3825039
[9,]  196.84368 0.4089103
[10,]  80.42056 0.3796008
...                      
[48,] 183.48574 0.4611285For the ask of 500, I want solutions to be?x1[c(2,5,6,13),] and x2[c(2,5,6,13),] with uniqueID which is a row number here.
Or please suggest any other Package/Algorithm combination for this problem,
Thank You,Best Regards,Chari

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jan  8 14:54:50 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 08 Jan 2015 08:54:50 -0500
Subject: [R-sig-ME] Genetic Algorithm in R
In-Reply-To: <1900401465.1483906.1420724098161.JavaMail.yahoo@jws10782.mail.gq1.yahoo.com>
References: <1900401465.1483906.1420724098161.JavaMail.yahoo@jws10782.mail.gq1.yahoo.com>
Message-ID: <54AE8C2A.1030900@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-01-08 08:34 AM, Narahara Chari D via R-sig-mixed-models wrote:
> Hi All, I am trying to implement Genetic Algorithm based on the 
> request to fill 500 ask based on the inventory. Algorithm should
> pick optimized combinations based on the rank (low rank inventory
> should be selected first) and update the inventory after fulfilling
> the request.
> 
> dataGA Inventory Rank 1        200    2 2        150    1 3 300
> 3 4        100    4 5         50    1 6        250    1 7 350    2
> 8        100    2 9        250    3 10        25    4 11 125    4
> 12       100    5 13       225    1 14       220    2 15 150    3
> 
> library(GA) Rastrigin <- function(x1, x2) { x1*x2 - 500 }
> 
> x1 <- dataGA$Inventory x2 <- seq(0.01, 1, by = 0.01)
> 
> f <- outer(x1, x2, Rastrigin) GA <- ga(type = "real-valued",
> fitness = function(x) -Rastrigin(x1, x2), min = c(1000, 0.01), max
> = c(10000000, 1), popSize = 50, maxiter = 100) summary(GA)I have 
> solutions +-----------------------------------+ |         Genetic 
> Algorithm         | +-----------------------------------+
> 
> GA settings: Type                  =  real-valued Population size =
> 50 Number of generations =  100 Elitism               =  2 
> Crossover probability =  0.8 Mutation probability  =  0.1 Search 
> domain x1   x2 Min  25 0.01 Max 350 1.00
> 
> GA results: Iterations             = 100 Fitness function value =
> 498 Solutions              = x1        x2 [1,]  194.44965 0.3886958
> [2,] 191.24609 0.4016915 [3,]  243.08729 0.3699107 [4,]  137.36235 
> 0.4050092 [5,]  177.33917 0.4570788 [6,]  139.32841 0.3755744 [7,] 
> 137.68704 0.3534409 [8,]  156.28470 0.3825039 [9,]  196.84368 
> 0.4089103 [10,]  80.42056 0.3796008 ... [48,] 183.48574
> 0.4611285For the ask of 500, I want solutions to be
> x1[c(2,5,6,13),] and x2[c(2,5,6,13),] with uniqueID which is a row
> number here. Or please suggest any other Package/Algorithm
> combination for this problem, Thank You,Best Regards,Chari

  Sorry, this is not a mixed model problem -- not even particularly
closely related to mixed models.  (When you send your question
elsewhere, you may want to provide a reproducible example, and to
explain your question more clearly -- I couldn't understand it.)

  sincerely,
    Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUrowqAAoJEOCV5YRblxUHfacH/RKMTV4YQmwgXwfUf8NP0lA6
hYh6afVL1NxYh9P0GAPxxeGIbf3FC3R6gpsbGCfpHP9WYQjXkOjunBaw4eNo44Ry
P20eAUogj2Yr+zluUIzNHXcsOSaUeyAHNTOM2a63z2eUJ9MTCAnT9NAdPG2H8xDi
RC7am/NWsyGj47u9BWjZubGOBFBITnpWjV52HOficGxCLOT9Ssm+9q6fnsdLlvyC
wDS2hamNzxzu7+IZS2oCvDM0KHVZxIX+GZ2O3vChuUVOoJOPQWmypsXfaAWeBuo8
qu6ZYth4Me/jzXm+aYI18qj7oH6KH77Z/3TsR+PaXCdTZJgrRtJoToJYGuV18pE=
=Huy+
-----END PGP SIGNATURE-----


From emmanuel.curis at parisdescartes.fr  Thu Jan  8 18:00:17 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Thu, 8 Jan 2015 18:00:17 +0100
Subject: [R-sig-ME] [lme4 package] Does the order of rows(trials) in a
 data frame (long format) affect the results of the lmer model (maybe
 somehow)?
In-Reply-To: <54AE03C7.8070805@gmail.com>
References: <CAHpascedJxB=ARjjLi0hu=520M04WTy6jnZS3_9UrsBOM_DKeg@mail.gmail.com>
	<54AE03C7.8070805@gmail.com>
Message-ID: <20150108170017.GI31753@info124.pharmacie.univ-paris5.fr>

Hi,

Does it really change the lineary algebra, or does it change its
numerical implementation in computers? Since computer addition is not
commutative, that would explain ordering effects...

> 1 + 1e-15 - 1
[1] 1.110223e-15
> 1 - 1 + 1e-15
[1] 1e-15

> version$version.string
version.string R version 3.0.1 (2013-05-16)

In other words, may be computation with such big matrice can lead to
rounding errors that add-up quickly if matrices are somehow
ill-conditionned?

I'm not familiar with this field, but for instance I noticed that when
you try to compute linear model matrices, coefficients and so one
using the projection formula, even with as few as a tenth of values,
values that should be 0 in the projection matrices (and especially
inverses) are quickly around ~10^-16 and after that, things can get
very bad quiclky, which is solved by adding a ? cleaning ? of matrices
such as m[ abs( m ) < 1e^-10 ] <- 0...

Of course, the above approach is very very dirty and inefficient and
has only pedagogical interest, but are the more subtle algorithm
robust enough on that aspect for such big matrices?

On Wed, Jan 07, 2015 at 11:12:55PM -0500, Ben Bolker wrote:

?   We have seen one case where the order does change the results slightly
? (https://github.com/lme4/lme4/issues/262) , and have a
? not-yet-reproducible report (see prev link) of a case where the order
? changes the standard error estimates considerably more.  That the
? order affects the results is surprising, but believable; I/we haven't
? had a chance yet to dig through and figure out how the ordering could
? change the linear algebra, but clearly it does.

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From Daniel.Wright at act.org  Thu Jan  8 18:13:21 2015
From: Daniel.Wright at act.org (Daniel Wright)
Date: Thu, 8 Jan 2015 17:13:21 +0000
Subject: [R-sig-ME] [lme4 package] Does the order of rows(trials) in a
 data frame (long format) affect the results of the lmer model (maybe
 somehow)?
In-Reply-To: <20150108170017.GI31753@info124.pharmacie.univ-paris5.fr>
References: <CAHpascedJxB=ARjjLi0hu=520M04WTy6jnZS3_9UrsBOM_DKeg@mail.gmail.com>
	<54AE03C7.8070805@gmail.com>
	<20150108170017.GI31753@info124.pharmacie.univ-paris5.fr>
Message-ID: <CO2PR04MB8266C54290A6278BF445120EA470@CO2PR04MB826.namprd04.prod.outlook.com>

On floating points in R, an enjoyable discussion of this "Circle 1" of the inferno is in Patrick Burn's The R Inferno 

http://www.burns-stat.com/pages/Tutor/R_inferno.pdf

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Emmanuel Curis
Sent: Thursday, January 08, 2015 11:00 AM
To: Ben Bolker
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] [lme4 package] Does the order of rows(trials) in a data frame (long format) affect the results of the lmer model (maybe somehow)?

Hi,

Does it really change the lineary algebra, or does it change its numerical implementation in computers? Since computer addition is not commutative, that would explain ordering effects...

> 1 + 1e-15 - 1
[1] 1.110223e-15
> 1 - 1 + 1e-15
[1] 1e-15

> version$version.string
version.string R version 3.0.1 (2013-05-16)

In other words, may be computation with such big matrice can lead to rounding errors that add-up quickly if matrices are somehow ill-conditionned?

I'm not familiar with this field, but for instance I noticed that when you try to compute linear model matrices, coefficients and so one using the projection formula, even with as few as a tenth of values, values that should be 0 in the projection matrices (and especially
inverses) are quickly around ~10^-16 and after that, things can get very bad quiclky, which is solved by adding a < cleaning > of matrices such as m[ abs( m ) < 1e^-10 ] <- 0...

Of course, the above approach is very very dirty and inefficient and has only pedagogical interest, but are the more subtle algorithm robust enough on that aspect for such big matrices?

On Wed, Jan 07, 2015 at 11:12:55PM -0500, Ben Bolker wrote:

<   We have seen one case where the order does change the results slightly
< (https://github.com/lme4/lme4/issues/262) , and have a < not-yet-reproducible report (see prev link) of a case where the order < changes the standard error estimates considerably more.  That the < order affects the results is surprising, but believable; I/we haven't < had a chance yet to dig through and figure out how the ordering could < change the linear algebra, but clearly it does.

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ken.beath at mq.edu.au  Thu Jan  8 23:08:08 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Fri, 9 Jan 2015 09:08:08 +1100
Subject: [R-sig-ME] c++ exception with logistic glmer
In-Reply-To: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>
References: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>
Message-ID: <CAF5_5czcYQG6t_6mAYTA3G9=c2bhghOr9ZEOQ9a21pMmPNhDqQ@mail.gmail.com>

The different log likelihoods for different values of nAGQ, and hence BIC,
is a known problem with glmer. nAGQ=1 is correct, and I think other values
are just out by a constant.

As to your model, what is happening is that a step function is being
modeled by a logistic. As a result the coefficient of age tends towards a
large number (a parameter estimate of 5 corresponds to an odds ratio of
about 150 per year, 17 is a huge odds ratio) , in an attempt  to reproduce
the step. The random effect will be modeling where the switch happens so
will also be large, as it needs to move a very steep line to varying values
of age. Effectively the model is close to being non-identifiable, as the
loglikelihood will remain almost unchanged for increasing combinations of
age parameter and random effect variance. Centering age might improve the
numerics and result in even larger coefficients.

I'm not certain what is happening with the 2 observations per subject. If
they were all 0,1 then the coefficient of age would be infinite, as a one
year change in age would always produce a change from zero to one.
However, it is similar to the discrete logistic survival which has a series
of zeroes followed by a 1 and doesn't require a random effect to model.

Ken

On 6 January 2015 at 23:34, Cole, Tim <tim.cole at ucl.ac.uk> wrote:

> I'm returning to a thread I started a year ago. My logistic glmer model
> (described below) generated an obscure error message, which Emmanuel Curis
> pointed out arose from duplicate rows in my data. Ben Bolker and David
> Duffy thought there might be separation in the cleaned dataset, and
> Jonathan French and Ben suggested an alternative time-to-event analysis
> instead of the logistic.
>
> The dataset consists of longitudinal measures of a binary bone maturity
> score called mat, which for each subject (n = 607) consists of zero or more
> 0s followed by zero or more 1s, the age at 0/1 transition constituting the
> subject's age at maturity. The aim is to estimate median age at maturity,
> given by ?intercept/age coefficient and confidence interval based on
> Fieller's theorem.
>
> The full data frame is bhs (4565 rows), while dfs is a reduced data frame
> (1086 rows) consisting of the last mat 0 entry and first mat 1 entry per
> subject (where available).
>
> Using glm ignores the longitudinal element, whille glmer allows a random
> subject intercept reflecting inter-subject variability in age at maturity.
>
> lm0 <- glm(mat ~ age, family=binomial, data=bhs)
> lm0r <- glm(mat ~ age, family=binomial, data=dfs)
> for (n in c(0, 1, 5, 9)) {
> assign(paste('lm0', n, sep='.'), glmer(mat ~ age + (1 | BHID),
> family=binomial, data=bhs, nAGQ=n))
> assign(paste('lm0r', n, sep='.'), glmer(mat ~ age + (1 | BHID),
> family=binomial, data=dfs, nAGQ=n))
> }
> list <- ls(pattern='^lm0')
> unlist(list, function(z) {
> res <- BIC(get(z))
> names(res) <- z
> res
> }))
>              lm0    lm0.0    lm0.1    lm0.5    lm0.9     lm0r   lm0r.0
>  lm0r.1   lm0r.5   lm0r.9
> 2474.576 1812.824 1386.288 1788.585 1778.761 1298.951 1305.941 1305.941
> 1305.941 1305.941
>
> With the full data frame (models lm0.n) BIC varies with nAGQ, and for the
> Laplace fit (nAGQ=1) the model looks dodgy. The coefficients are as follows:
>
> $lm0
>               Estimate Std. Error   z value      Pr(>|z|)
> (Intercept) -18.700922  0.5783898 -32.33273 2.426656e-229
> age           1.169465  0.0363381  32.18288 3.063925e-227
>
> $lm0.0
>               Estimate Std. Error   z value      Pr(>|z|)
> (Intercept) -75.261703  3.3652807 -22.36417 8.790724e-111
> age           4.710325  0.2086032  22.58031 6.766768e-113
>
> $lm0.1
>               Estimate Std. Error   z value Pr(>|z|)
> (Intercept) -276.41591 1.21959198 -226.6462        0
> age           17.35977 0.08850143  196.1525        0
>
> $lm0.5
>               Estimate Std. Error   z value     Pr(>|z|)
> (Intercept) -71.992747  6.7038887 -10.73895 6.679749e-27
> age           4.497433  0.4186714  10.74215 6.452210e-27
>
> $lm0.9
>               Estimate Std. Error   z value     Pr(>|z|)
> (Intercept) -80.623844  8.9423308 -9.015976 1.951243e-19
> age           5.035102  0.5569928  9.039797 1.569631e-19
>
> As expected the regression line is steeper with the random effect
> included, though again lm0.1 look odd.
>
> With the reduced data frame the lmr.n models do not vary with nAGQ. But
> the odder thing is that the coefficients are identical with and without the
> random effect, as the SD of the random effect is estimated to be zero.
>
> $lm0r
>               Estimate Std. Error   z value     Pr(>|z|)
> (Intercept) -8.6820194 0.69870600 -12.42586 1.891928e-35
> age          0.5393926 0.04395768  12.27072 1.300837e-34
>
> $lm0r.0
>               Estimate Std. Error   z value     Pr(>|z|)
> (Intercept) -8.6820193 0.69864489 -12.42694 1.866391e-35
> age          0.5393926 0.04395395  12.27177 1.284216e-34
>
> So I have two questions. Why do the results with the full data frame
> depend on nAGQ, and why with the reduced data frame is the SD of random
> effect estimated as zero?
>
> Thanks for your thoughts.
>
> Tim
>  ---
> Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666
> Fax +44(0)20 7905 2381
> Population, Policy and Practice Programme
> UCL Institute of Child Health, London WC1N 1EH, UK
>
>
>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From wzhmelly at gmail.com  Fri Jan  9 03:56:03 2015
From: wzhmelly at gmail.com (Zhaohong)
Date: Thu, 8 Jan 2015 21:56:03 -0500
Subject: [R-sig-ME] [lme4 package] Does the order of rows(trials) in a
 data frame (long format) affect the results of the lmer model (maybe
 somehow)?
Message-ID: <CAHpasccjUbfoeeau2ioM5H29jj2Cb_yZdGG5hZd0pNPaz6n5dQ@mail.gmail.com>

Dear Dr. Bolker,

Thank you so much for your response and your very helpful suggestions. Here
are a few follow-up points:

1. I did forgot to rewrite the variable names in model 2. I rewrote the
variable names in model one but forgot to do so in model 2, so that was not
a concern for different results:)

2. The reordering in my post was actually random (I randomly reordered the
data according to first subject number, and then item number), and the
results were different (The model before reordering was able to converge,
and wasn't after reordering). The reason for me doing so was to demonstrate
that reordering can change the results. My original methodological
reordering motivation was to create a new variable/column based on an
existing variable/column ordered according to two other variables/columns.
The model wasn't able to converge after methodological reordering. For
demonstration simplicity I posted the random reordering model results. But
both ways of reordering changed the results such that the model in the
reordered ones failed to converge even though model summaries were very
similar.

3. For the lmer model fit in the methodological reordered dataset that
could not converge, I first followed your suggestion of trying different
optimizers (built-in N-M and bobyqa; nlminb and L-BFGS-B from base R, via
the optimx package; and the nloptr versions of N-M and bobyqa), but
unfortunately none of the optimizers were able to make the model converge
in this case. I then followed your suggestion of doing the experiment of
inputing the results from each case as starting values. LUCKILY the model
was able to converge (even though the verbose reports are different, the
model summary of the updated model is the same as the original model)!

Model 1 and Model 3 were able to converge and have the same model
summaries. They do have different verbose reports. Model 2 failed to
converge, and has slightly different SEs, but the same t-values.

I am wondering if this means that able-to-converge model invalidate the
warning message of the unable-to-converge model or otherwise?

Here are the verbose results for each of the models:

Model 1: The model that was able to converge in the original dataset before
methodological reordering:

npt = 77 , n =  75
rhobeg =  0.2 , rhoend =  2e-07
   0.020:  86:     -783.903;0.492578 -0.0462110 -0.0363706 -0.0207690
-0.00431843 0.00131644 -0.00481740 -0.00308283 0.502089 -0.0211198
-0.0336018 -0.0237567 -0.00155808 -0.0307396 -0.000390386 0.354830
-0.0308058 -0.0351383 -0.0137964 -0.0238208 -0.0133714 0.305507 -0.0174871
-0.0328382 -0.00155512 0.00996183 0.646703 -0.0258383 -0.00140789
-0.00146090 0.593574 -0.0176632 -0.0351208 0.611448 0.000434827 0.819591
0.735976 -0.105154 0.553306 0.948775 -0.00950248 -0.00976528 -0.0113362
-0.00949456 -0.00980388 -0.0100146 -0.00779947 0.946928 -0.00984788
-0.0101504 -0.00957164 -0.00986887 -0.00987130 -0.00960832 0.946926
-0.0101303 -0.0103410 -0.00976277 -0.00978197 -0.00937871 0.947412
-0.00988796 -0.0100200 -0.0103097 -0.0103002 0.949607 -0.0106541
-0.00943222 -0.0111189 0.947582 -0.0104333 -0.00883065 0.949409 -0.0119380
0.954371
  0.0020: 1266:     -1011.94;0.450579 -0.0561922 -0.0390931 0.00888335
0.0594143 0.0967819 0.0600815 0.0674752 0.220653 0.00904686 -0.0695420
-0.0628733 0.117864 -0.0596009 0.0799141 0.229251 -0.0664593 -0.123684
0.0490019 -0.0235120 -0.0541726 0.118324 -0.0741990 -0.0809683 0.0958857
0.268214 0.249829 0.0324988 0.114487 0.128747 0.0173838 0.0167991
-0.00732449 0.0501891 0.0850320 0.157297 0.746053 -0.130440 0.331480
0.293937 0.0743482 0.0377308 -0.139008 0.0682751 0.0331050 -0.0866526
-0.0383130 0.0117850 -0.0240952 0.0400393 0.0809940 -0.0429156 -0.159851
0.0126200 0.0106298 -0.0212809 0.00295026 -0.00943432 0.0602099 -0.0644152
 0.00000 0.0531561 0.00504124 0.107394 -0.0116981 0.177808 -0.0275010
0.0632146 -0.0964148 0.0448545 0.0930555 -0.0329402 0.233815 0.111024
0.684505
 0.00020: 2829:     -1024.14;0.452709 -0.0579625 -0.0344969 0.0120118
0.0734510 0.0896992 0.0499010 0.0954442 0.229133 0.00559951 -0.0696637
-0.0242122 0.111817 -0.0789206 0.0837580 0.222271 -0.0611380 -0.112126
0.0329055 -0.0277847 -0.00797160 0.120486 -0.0643358 -0.0845771 0.0736635
0.288591 0.257914 -0.00181955 0.110898 0.147722  0.00000 0.000172809
0.00919736 0.0110891 0.0152384 0.00828677 0.748922 -0.123172 0.330259
0.206775 0.0476522 0.0280362 -0.101461 0.0463152 0.0216698 0.0248654
0.170800 0.0176330 -0.0380416 0.0317560 0.142628 -0.0190826 -0.0671519
-0.00752021  0.00000 -0.0188540 0.0493985 -0.0278924 0.112063 -0.127799
 0.00000 0.0437870 -0.0209737 0.0658322 -0.0777777 0.0965694 -0.0408791
0.127360 -0.174456  0.00000 -0.000274027 -0.0130361 2.24477e-05 9.26975e-05
0.0325827
 2.0e-05: 5773:     -1024.50;0.453311 -0.0585468 -0.0356171 0.0124542
0.0734133 0.0881771 0.0507491 0.0961264 0.230039 0.00643291 -0.0684440
-0.0227084 0.110856 -0.0735117 0.0881374 0.222234 -0.0600243 -0.108611
0.0331596 -0.0250605 -0.00237720 0.120825 -0.0585146 -0.0847106 0.0774464
0.290086 0.261511 -3.75224e-05 0.115623 0.142874  0.00000 0.000183608
0.000936919 0.000697002 0.000660236 0.00131320 0.749940 -0.124134 0.330879
0.212274 0.0477193 0.0297672 -0.103379 0.0384115 0.0255082 0.0174492
0.192128 0.0200405 -0.0419245 0.0218963 0.182316 -0.0385164 0.00556693
-0.0984504 0.00132058 -0.0348845 0.0586401 -0.0444801 0.190766 -0.212638
 0.00000 0.000668956 -0.000403147 0.00142120 -0.00175281  0.00000
0.000166863 -0.00106768 0.000914863 0.000467674 -0.00274150 0.00346480
0.00114500 -0.000318531 0.00111171
 2.0e-06: 9248:     -1024.51;0.453348 -0.0584731 -0.0355746 0.0125052
0.0734903 0.0881831 0.0507601 0.0960166 0.230127 0.00645362 -0.0684865
-0.0230384 0.110978 -0.0737085 0.0876321 0.222118 -0.0599844 -0.108724
0.0331173 -0.0250216 -0.00259363 0.120773 -0.0589481 -0.0846303 0.0772936
0.289112 0.261172 -0.000167296 0.115547 0.144054 9.37833e-07 -2.73741e-05
-4.00219e-05 1.07567e-05 3.85261e-05 3.10490e-05 0.750009 -0.124225
0.330861 0.212679 0.0477609 0.0298412 -0.103074 0.0371887 0.0264153
0.0144220 0.197224 0.0205217 -0.0404589 0.0134622 0.191228 -0.0472840
0.0469882 -0.142964 0.0109281 -0.0403486 0.0179550 -0.0346377 0.183949
-0.183214 0.00214351 -0.00362890 0.00276037 -0.0118387 0.0131118  0.00000
5.56133e-05 -0.000257805 0.000368822  0.00000 0.000199027 -0.000336293
0.000352925 -0.000454433 1.25530e-05
 2.0e-07: 15764:     -1024.51;0.453351 -0.0584700 -0.0355723 0.0124965
0.0734787 0.0881846 0.0507616 0.0960397 0.230123 0.00645416 -0.0684847
-0.0230381 0.110983 -0.0737035 0.0876777 0.222123 -0.0599873 -0.108719
0.0331109 -0.0250217 -0.00255763 0.120773 -0.0589676 -0.0846268 0.0772896
0.289120 0.261188 -0.000185005 0.115550 0.144119 2.65656e-06 -6.82831e-06
-2.76466e-05  0.00000 1.83385e-05 7.87228e-07 0.750014 -0.124224 0.330867
0.212670 0.0477592 0.0298445 -0.103084 0.0371768 0.0264019 0.0144639
0.197132 0.0205263 -0.0404874 0.0135545 0.191202 -0.0472145 0.0466104
-0.142610 0.0108195 -0.0403564 0.0185109 -0.0348318 0.184403 -0.183997
0.000797901 -0.00138066 0.00103545 -0.00442881 0.00490172  0.00000
7.51833e-06 -3.87226e-05 6.04092e-05  0.00000 3.63510e-06 -4.49410e-06
1.42910e-06 5.74795e-06 5.03001e-07
At return
30433:    -1024.5110: 0.453352 -0.0584699 -0.0355712 0.0124974 0.0734792
0.0881850 0.0507622 0.0960430 0.230123 0.00645469 -0.0684872 -0.0230377
0.110983 -0.0737051 0.0876725 0.222122 -0.0599864 -0.108715 0.0331096
-0.0250228 -0.00255738 0.120773 -0.0589583 -0.0846263 0.0772945 0.289133
0.261192 -0.000180489 0.115545 0.144090  0.00000 -1.01443e-06 -2.72331e-06
4.36692e-09 2.82744e-07 1.08531e-07 0.750012 -0.124223 0.330865 0.212669
0.0477582 0.0298448 -0.103086 0.0371794 0.0264002 0.0144699 0.197126
0.0205267 -0.0404964 0.0135892 0.191188 -0.0471837 0.0464530 -0.142440
0.0107821 -0.0403469 0.0186941 -0.0348872 0.184494 -0.184176 0.000119925
-0.000204327 0.000154724 -0.000663551 0.000735230 6.17347e-06 -3.20551e-06
1.16271e-05 -1.43359e-05  0.00000 1.40493e-06 -2.16589e-06 1.27346e-06
-2.57135e-06 2.74006e-08


Model 2: The model that failed to converge in the methodologically
reordered dataset:

npt = 77 , n =  75
rhobeg =  0.2 , rhoend =  2e-07
   0.020:  86:     -783.903;0.492578 -0.0462110 -0.0363706 -0.0207690
-0.00431843 0.00131644 -0.00481740 -0.00308283 0.502089 -0.0211198
-0.0336018 -0.0237567 -0.00155808 -0.0307396 -0.000390386 0.354830
-0.0308058 -0.0351383 -0.0137964 -0.0238208 -0.0133714 0.305507 -0.0174871
-0.0328382 -0.00155512 0.00996183 0.646703 -0.0258383 -0.00140789
-0.00146090 0.593574 -0.0176632 -0.0351208 0.611448 0.000434827 0.819591
0.735976 -0.105154 0.553306 0.948775 -0.00950248 -0.00976528 -0.0113362
-0.00949456 -0.00980388 -0.0100146 -0.00779947 0.946928 -0.00984788
-0.0101504 -0.00957164 -0.00986887 -0.00987130 -0.00960832 0.946926
-0.0101303 -0.0103410 -0.00976277 -0.00978197 -0.00937871 0.947412
-0.00988796 -0.0100200 -0.0103097 -0.0103002 0.949607 -0.0106541
-0.00943222 -0.0111189 0.947582 -0.0104333 -0.00883065 0.949409 -0.0119380
0.954371
  0.0020: 1172:     -1014.44;0.447624 -0.0669099 -0.0320947 0.0167277
0.0912024 0.0719610 0.0630252 0.0938361 0.222104 0.00464982 -0.0604313
-0.0253292 0.105348 -0.0903103 0.145056 0.219771 -0.0684526 -0.0980628
0.0509629 -0.0193132 -0.0425260 0.111319 -0.0674473 -0.0826473 0.0645061
0.308971 0.275658 0.00898888 0.0991931 0.0808576 0.0383104 -0.0420248
-0.0892487 0.0548139 0.207690 0.159669 0.757029 -0.120768 0.331302 0.267592
0.0676536 0.0201904 -0.126278 0.0562606 0.0250859 -0.0697141 0.0129532
 0.00000 -0.00388083 0.0181382 -0.0313332 0.0263182 -0.113085 0.0409921
0.0244835 -0.00143217 -0.109671 0.0390520 -0.102010 0.215959 0.0189336
0.0559744 -0.00894316 -0.0905837 0.00493369 0.131495 -0.0369109 0.00188335
-0.0600454 0.0130668 -0.000123405 0.0735400 0.299381 0.100145 0.406015
 0.00020: 2316:     -1024.17;0.452651 -0.0576679 -0.0363522 0.0142167
0.0737818 0.0886794 0.0505187 0.0968153 0.230282 0.00656979 -0.0700034
-0.0229655 0.112017 -0.0729715 0.0846494 0.222177 -0.0601802 -0.109146
0.0348149 -0.0255153 -0.0102024 0.119204 -0.0593872 -0.0844258 0.0784315
0.290692 0.265046 0.000206971 0.114277 0.137916 0.00347211 -0.00262445
-0.0181085 0.0191210 0.0499287 0.0236533 0.750671 -0.124422 0.332829
0.208668 0.0474820 0.0264901 -0.103312 0.0506237 0.0221234 0.0282738
0.161618 0.00724535 -0.0234226 0.0364098 0.0571019 0.00927926 -0.128524
0.0884775 0.0357219 -0.00762950 -0.178271 0.0554376 -0.101325 0.194006
0.0146784 -0.00596418 0.0138789 -0.0792504 0.0696503 0.0233231 -0.0134198
0.0447087 -0.0595230 0.00147059 -0.0191394 0.0156479 0.0305705 -0.0303258
0.0440939
 2.0e-05: 6667:     -1024.50;0.453333 -0.0585376 -0.0356834 0.0125678
0.0734487 0.0882151 0.0506785 0.0962391 0.230149 0.00646481 -0.0684075
-0.0229736 0.110955 -0.0735249 0.0887876 0.222150 -0.0599851 -0.108783
0.0331485 -0.0249883 -0.00231090 0.120743 -0.0588238 -0.0846573 0.0773961
0.289167 0.261248 -0.000202959 0.115370 0.143609 0.000375922 -0.000227722
-0.00210776 0.000249744 0.000200904 0.00155220 0.750066 -0.124132 0.330857
0.212715 0.0477406 0.0299282 -0.103651 0.0375423 0.0260087 0.0168784
0.195044 0.0201795 -0.0417657 0.0213221 0.183624 -0.0393913 0.00908481
-0.103410  0.00000 0.0341739 -0.0558429 0.0434061 -0.187388 0.206720
0.00602252 -0.0104587 0.00784840 -0.0335030 0.0373768  0.00000 0.000810863
-0.00406451 0.00531339 0.000623899 -0.00298601 0.00364139 0.00127020
-0.00249732 0.000136553
 2.0e-06: 7951:     -1024.50;0.453363 -0.0585214 -0.0355937 0.0125148
0.0734771 0.0881768 0.0507700 0.0960643 0.230135 0.00647050 -0.0684990
-0.0229578 0.110975 -0.0736253 0.0877978 0.222128 -0.0599846 -0.108632
0.0331081 -0.0249697 -0.00240205 0.120748 -0.0589092 -0.0846212 0.0773143
0.289105 0.261252 -0.000171769 0.115543 0.144025 7.68975e-06 -9.93934e-05
-0.000158060 2.14420e-06 -0.000108389 4.40368e-06 0.749999 -0.124185
0.330849 0.212710 0.0477984 0.0298783 -0.103537 0.0378475 0.0258748
0.0167651 0.194737 0.0200724 -0.0418390 0.0216548 0.183097 -0.0389119
0.00712609 -0.101166  0.00000 0.0340977 -0.0575895 0.0438893 -0.187939
0.208423 0.00597793 -0.00995945 0.00765416 -0.0329048 0.0363802 9.49403e-06
-1.55017e-05 4.43789e-05 -5.32016e-06 2.81165e-05 -0.000129310 0.000211690
3.15843e-05 -7.69581e-05 2.67395e-06
 2.0e-07: 8903:     -1024.50;0.453360 -0.0585275 -0.0355925 0.0125155
0.0734845 0.0881790 0.0507774 0.0960783 0.230139 0.00647101 -0.0684924
-0.0229629 0.110969 -0.0736363 0.0877776 0.222135 -0.0599849 -0.108668
0.0331033 -0.0249925 -0.00249774 0.120746 -0.0589032 -0.0846192 0.0773104
0.289164 0.261220 -0.000165898 0.115538 0.144051 2.68516e-06 -8.50514e-06
-1.59307e-05 1.31307e-06 -1.15980e-05 1.25947e-05 0.749998 -0.124188
0.330852 0.212669 0.0477858 0.0298613 -0.103532 0.0378953 0.0258498
0.0168472 0.194461 0.0200718 -0.0418512 0.0216547 0.183128 -0.0389264
0.00718263 -0.101254  0.00000 0.0341018 -0.0575525 0.0438835 -0.187975
0.208542 0.00595594 -0.0100401 0.00766203 -0.0328283 0.0364101 5.20909e-05
-2.37566e-05 7.39340e-05 -0.000105120 2.19095e-06 -9.43038e-06 1.25759e-05
 0.00000 1.09861e-05 1.18396e-05
At return
10078:    -1024.5030: 0.453360 -0.0585273 -0.0355919 0.0125149 0.0734832
0.0881784 0.0507752 0.0960809 0.230139 0.00647089 -0.0684925 -0.0229637
0.110970 -0.0736367 0.0877742 0.222135 -0.0599852 -0.108670 0.0331028
-0.0249919 -0.00249632 0.120746 -0.0589016 -0.0846198 0.0773097 0.289162
0.261220 -0.000166264 0.115537 0.144045  0.00000 -1.19720e-07 1.53556e-06
3.08499e-07 -2.54427e-06 1.83151e-06 0.749999 -0.124188 0.330852 0.212667
0.0477863 0.0298606 -0.103533 0.0379029 0.0258461 0.0168572 0.194439
0.0200716 -0.0418515 0.0216519 0.183133 -0.0389304 0.00720182 -0.101281
 0.00000 0.0341025 -0.0575332 0.0438776 -0.187972 0.208527 0.00595515
-0.0100495 0.00766287 -0.0328261 0.0364180 6.42615e-06 -3.40726e-06
1.16423e-05 -1.43135e-05 1.68240e-06 -7.84610e-06 9.54898e-06 8.95258e-08
-1.45106e-06 7.29374e-09
Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 2.40355 (tol = 0.002, component
65)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

(3) The updated model of (2) using (1) theta:

E.maximal.model.RRT.rep.updated <-
update(E.maximal.model.RRT.rep,start=getME(E.maximal.model.RRT,"theta"))

npt = 77 , n =  75
rhobeg =  0.1500024 , rhoend =  1.500024e-07
   0.015:  78:     -1007.25;0.453352 -0.0584699 -0.0355712 0.0124974
0.0734792 0.0881850 0.0507622 0.0960430 0.230123 0.00645469 -0.0684872
-0.0230377 0.110983 -0.0737051 0.0876725 0.222122 -0.0599864 -0.108715
0.0331096 -0.0250228 -0.00255738 0.150002 -0.0589583 -0.0846263 0.0772945
0.289133 0.261192 -0.000180489 0.115545 0.144090  0.00000 -1.01443e-06
-2.72331e-06 0.150002 2.82744e-07 0.150002 0.750012 -0.124223 0.330865
0.212669 0.0477582 0.0298448 -0.103086 0.0371794 0.0264002 0.0144699
0.197126 0.150002 -0.0404964 0.0135892 0.191188 -0.0471837 0.0464530
-0.142440 0.150002 -0.0403469 0.0186941 -0.0348872 0.184494 -0.184176
0.150002 -0.000204327 0.000154724 -0.000663551 0.150738 0.150002
-3.20551e-06 1.16271e-05 -1.43359e-05  0.00000 1.40493e-06 -2.16589e-06
0.150002 -2.57135e-06 0.150002
  0.0015: 274:     -1022.80;0.452074 -0.0566838 -0.0335530 0.0105914
0.0650464 0.0888558 0.0454422 0.0818484 0.235260 0.00370672 -0.0607487
-0.0170701 0.112566 -0.0772648 0.0912295 0.218476 -0.0619023 -0.112771
0.0219813 -0.0268611 -0.00187945 0.122432 -0.0469394 -0.0843561 0.0856558
0.287286 0.244826 -0.00158542 0.113384 0.156312 0.00346480 0.00953380
0.0145042 0.0610715 0.0340415 0.133814 0.742904 -0.118794 0.327997 0.209131
0.0405832 0.0273765 -0.0978607 0.0438295 0.0244138 0.00520580 0.190993
0.00849323 -0.0492413 0.0159085 0.196088 -0.0479540 0.0673088 -0.132961
0.0114834 -0.0414148 -0.00971450 -0.0242264 0.186732 -0.160444 0.0116101
0.00253052 0.00599139 -0.0153175 0.0741567 0.0938898 -0.0160072 0.0283886
-0.00636907 0.00202612 0.00303601 0.0144939 0.0831271 -0.0668251 0.113080
 0.00015: 883:     -1024.39;0.453665 -0.0585067 -0.0360498 0.0123685
0.0732151 0.0885324 0.0508982 0.0923064 0.230682 0.00673961 -0.0680962
-0.0233385 0.111270 -0.0730391 0.0959433 0.223503 -0.0594483 -0.107672
0.0320622 -0.0249977 0.000572442 0.120297 -0.0596571 -0.0848154 0.0760521
0.286619 0.262302 -0.00181074 0.116938 0.147450 0.000607578 0.00258809
0.00295064 0.00870774 0.0110953 0.0513588 0.751154 -0.124160 0.330323
0.212719 0.0478004 0.0297213 -0.102591 0.0370312 0.0263823 0.0156825
0.194049 0.0207475 -0.0401990 0.0116376 0.188745 -0.0486827 0.0560793
-0.145942 0.0143298 -0.0398109 0.00324054 -0.0290687 0.172062 -0.160556
0.00815574 -0.00979049 0.00919127 -0.0416405 0.0436646 0.0192964
-0.00983632 0.0248093 -0.0310215 0.000459667 0.00130757 -0.000901646
0.0342696 -0.0376915 0.0306594
 1.5e-05: 3284:     -1024.51;0.453385 -0.0584484 -0.0356090 0.0124758
0.0734563 0.0881546 0.0508248 0.0962059 0.230125 0.00646632 -0.0685329
-0.0233102 0.111124 -0.0737367 0.0872650 0.222137 -0.0600659 -0.108960
0.0332052 -0.0249734 -0.00297287 0.120747 -0.0596915 -0.0846255 0.0770361
0.288639 0.260991 -0.000252664 0.115696 0.144715  0.00000 0.000212990
0.000133828 1.60752e-05 -0.000197350  0.00000 0.750004 -0.124227 0.330932
0.212779 0.0478032 0.0298216 -0.103062 0.0372814 0.0263856 0.0143016
0.197110 0.0205353 -0.0399386 0.0118496 0.191628 -0.0486431 0.0544321
-0.150492 0.0128156 -0.0404642 0.00802782 -0.0314552 0.177600 -0.172395
0.00727224 -0.0124290 0.00934080 -0.0404360 0.0448702 0.00474710
-0.00245309 0.00790385 -0.0103348  0.00000 0.000371469 -0.000983666
 0.00000 0.000141958 0.000421746
 1.5e-06: 7178:     -1024.51;0.453352 -0.0584690 -0.0355774 0.0124997
0.0734840 0.0881869 0.0507670 0.0960555 0.230123 0.00645470 -0.0684869
-0.0230435 0.110983 -0.0737021 0.0876813 0.222121 -0.0599796 -0.108712
0.0331053 -0.0250164 -0.00249269 0.120771 -0.0589597 -0.0846281 0.0772928
0.289162 0.261192 -0.000190203 0.115552 0.144091 2.01629e-06 -4.08502e-05
-1.90946e-05  0.00000 -9.66359e-05 1.04936e-05 0.750011 -0.124226 0.330863
0.212665 0.0477618 0.0298406 -0.103103 0.0372181 0.0263686 0.0145848
0.196972 0.0205089 -0.0405674 0.0139592 0.190847 -0.0468184 0.0446604
-0.140577 0.0105124 -0.0395898 0.0187035 -0.0343555 0.181272 -0.181164
0.00664697 -0.0113702 0.00859624 -0.0368000 0.0407681  0.00000 1.76746e-05
-9.88034e-05 1.88689e-05  0.00000 5.17909e-05 -8.02859e-05 3.64008e-05
-6.60707e-05 5.93081e-06
 1.5e-07: 16007:     -1024.51;0.453353 -0.0584700 -0.0355713 0.0124974
0.0734791 0.0881842 0.0507617 0.0960368 0.230124 0.00645341 -0.0684879
-0.0230369 0.110985 -0.0737046 0.0876622 0.222121 -0.0599878 -0.108716
0.0331093 -0.0250229 -0.00255615 0.120773 -0.0589587 -0.0846260 0.0772924
0.289138 0.261189 -0.000183022 0.115548 0.144100  0.00000 -2.77640e-06
1.38614e-06 1.83196e-06 -2.21543e-06 1.76626e-06 0.750012 -0.124222
0.330866 0.212674 0.0477582 0.0298468 -0.103088 0.0371797 0.0263991
0.0144792 0.197126 0.0205267 -0.0405065 0.0136319 0.191163 -0.0471447
0.0462561 -0.142231 0.0107401 -0.0403131 0.0188609 -0.0349189 0.184476
-0.184251 0.000942279 -0.00163288 0.00122564 -0.00523554 0.00580441
1.43220e-05 -9.76379e-06 4.38830e-05 -3.89789e-05 1.56950e-05 -7.46413e-05
9.71269e-05 4.58216e-05 -4.96008e-05 2.15804e-06
At return
39183:    -1024.5110: 0.453351 -0.0584699 -0.0355713 0.0124976 0.0734794
0.0881849 0.0507626 0.0960419 0.230123 0.00645454 -0.0684866 -0.0230371
0.110983 -0.0737039 0.0876768 0.222122 -0.0599866 -0.108715 0.0331095
-0.0250227 -0.00255809 0.120773 -0.0589560 -0.0846266 0.0772956 0.289136
0.261192 -0.000179848 0.115546 0.144084 1.74822e-07 -3.48518e-07
-2.06009e-06 7.14056e-07 3.68010e-06 3.77125e-07 0.750012 -0.124223
0.330865 0.212669 0.0477582 0.0298451 -0.103087 0.0371793 0.0263998
0.0144727 0.197124 0.0205267 -0.0405008 0.0136068 0.191179 -0.0471682
0.0463709 -0.142355 0.0107635 -0.0403371 0.0187756 -0.0349080 0.184511
-0.184236 0.000261844 -0.000451348 0.000339652 -0.00145181 0.00160760
4.66708e-06 -2.02023e-06 6.29582e-06 -6.76577e-06  0.00000 4.54581e-06
-4.78681e-06 1.56292e-07 1.35805e-06 4.87490e-06

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Fri Jan  9 15:58:54 2015
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Fri, 9 Jan 2015 14:58:54 +0000
Subject: [R-sig-ME] prediction from glmer(...,
	family = binomial(link = "probit"))
Message-ID: <6BFF6B04-E3E1-4BAC-9162-9C3F25EC5877@glasgow.ac.uk>

I?m using glmer to fit a binomial GLMM with a probit link to some simulated data, and I?m looking for help in interpreting (back-transforming) the intercept estimate.

The response is logical (is a subject resistant to an infectious disease or not). Subjects are clustered in 700 families, with 3 subjects in each family:

        fam resistant
  1       1     FALSE
  2       1     FALSE
  3       1     FALSE
  4       2     FALSE
  5       2     FALSE
  6       2     FALSE
  7       3     FALSE
  8       3     FALSE
  9       3     FALSE
  ?
  2100   700    FALSE

The prevalence of resistance is low, at 5%, and the degree of familial clustering is moderate, with ICC = 0.25 (this is the ICC of the latent trait liability). The prevalence in the simulated data is 5.3%, close to the parameter value. 

I fitted the following model: 

  fit.glmer <- glmer(resistant ~ 1 + (1 | fam), family = binomial(link = "probit"), data = simdat)

The intercept estimate is -3.79. Back-transforming this gives a very low prevalence estimate of about 0.01% when I marginalise over the random effect:
> pnorm(fixef(fit.glmer)) 
 (Intercept) 
7.550163e-05 
or equivalently:
>   predict(fit.glmer, type = "response", re.form = NA)[1]
           1 
7.550163e-05 

Averaging over the family-specific predicted prevalences gets closer, but still underestimates the true prevalence (this bias is repeatable, so not just dues to sampling families):
> mean(predict(fit.glmer, type = "response", re.form = NULL))
[1] 0.0435032
This does better because back-transforming before taking the mean draws in the predicted prevalence of the families with no resistant subjects, which is very low on the probit scale but bounded by zero on the proportion scale. However I?m pretty sure this is the wrong way to do it.

Perhaps a more likely explanation is that I?m wrong to assume variance = 1 in the inverse probit function? Should I be adding the inter-family variance, additive dispersion (is this fixed at 1?) and the distribution specific variance, as predict.MCMCglmm does (I?ve fitted the same model in MCMCglmm and it recovers the prevalence and ICC accurately)? However the family variance estimate is so large that including it results in large overestimates, and the fact that predict.merMod doesn?t do this suggests it isn?t necessary.

Alternatively, could glmer be overestimating the inter-family variance, leading to an underestimate of the prevalence, due to a combination of low prevalence and and small families (n=3; most families have 0/3 resistant, and the maximum is 2/3). 

I?m exploring these possibilities but it would be great to have some expert advice.

Thanks in advance,
Paul

PS I could post the simulation code but it?s rather long so I?ll wait and see if there?s a simple solution.


From Michael.Jackson at vuw.ac.nz  Sun Jan 11 21:58:43 2015
From: Michael.Jackson at vuw.ac.nz (Michael Jackson)
Date: Sun, 11 Jan 2015 20:58:43 +0000
Subject: [R-sig-ME] lmer or glmer?
Message-ID: <AD3758FC3C68B54EA3C8883F56EFCC8C3BCF4845@STAWINCOX10MBX2.staff.vuw.ac.nz>

Hi Ben,

Im wondering if you can help - ive been going round in circles for some weeks now and busily getting more bamboozled. Im basically wanting to use model selection (AICc scores, deltas etc) based on "lme4" outputs to identify the key nutritive drivers of animal consumption. Ive attached my data for you as I think it'll help greatly in showing my issues....My questions are...

1) Should I use REML=FALSE if wanting to compare mixed effects models via their AICc scores, deltas etc. where the random effects are always incorporated, but the fixed effects change between models. Everything ive read suggests yes...do you agree?

2) Ive got 14 different models to run - some additive, some interactive...an example of my code is as follows
m2 = lmer(Consumption ~ Fat + Protein + (1|Product/Trial), data=mydata, REML=FALSE)
m3 = lmer(Consumption ~ Sugars * Fat + (1|Product/Trial), data=mydata, REML=FALSE)

However - no matter which model I run and/or how I scale or transform my variables (both predictor and response) a shaprio wilks test, for example  shapiro.test(resids(m2)) is always significant ....Would using "glmer" be my option here? After reading your paper "Generalised linear mixed models: a practical guide for ecology and evolution" and this article on stackexchange<http://stackoverflow.com/questions/25356633/error-message-when-performing-gamma-glmer-in-r-pirls-step-halvings-failed-to-re>....Would the following example code be OK based on my raw untransformed data?

glmer(Consumption ~ Fat + Protein + (1|Product/Trial), data=mydata, family=Gamma(link=log))

Id value your comment and assistance as I dont want create loads of models and then make incorrect inferences of my AICc outputs based on flawed regression outputs...

Thanks in advance

Mike
..............
PhD Candidate
Centre for Biodiversity and Restoration Ecology
Room KK 411
Kirk Building
Kelburn Parade
Wellington 6012

From Thierry.ONKELINX at inbo.be  Mon Jan 12 09:57:40 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 12 Jan 2015 08:57:40 +0000
Subject: [R-sig-ME] prediction from glmer(...,
 family = binomial(link = "probit"))
In-Reply-To: <6BFF6B04-E3E1-4BAC-9162-9C3F25EC5877@glasgow.ac.uk>
References: <6BFF6B04-E3E1-4BAC-9162-9C3F25EC5877@glasgow.ac.uk>
Message-ID: <AA818EAD2576BC488B4F623941DA742701096F0803@inbomail.inbo.be>

Dear Paul,

I think that the strong negative parameter estimates are due to the complete separation in your dataset. You might want to try Bayesian solutions like blme or inla.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Paul Johnson
Verzonden: vrijdag 9 januari 2015 15:59
Aan: R-mixed models mailing list
Onderwerp: [R-sig-ME] prediction from glmer(..., family = binomial(link = "probit"))

I'm using glmer to fit a binomial GLMM with a probit link to some simulated data, and I'm looking for help in interpreting (back-transforming) the intercept estimate.

The response is logical (is a subject resistant to an infectious disease or not). Subjects are clustered in 700 families, with 3 subjects in each family:

        fam resistant
  1       1     FALSE
  2       1     FALSE
  3       1     FALSE
  4       2     FALSE
  5       2     FALSE
  6       2     FALSE
  7       3     FALSE
  8       3     FALSE
  9       3     FALSE
  ...
  2100   700    FALSE

The prevalence of resistance is low, at 5%, and the degree of familial clustering is moderate, with ICC = 0.25 (this is the ICC of the latent trait liability). The prevalence in the simulated data is 5.3%, close to the parameter value.

I fitted the following model:

  fit.glmer <- glmer(resistant ~ 1 + (1 | fam), family = binomial(link = "probit"), data = simdat)

The intercept estimate is -3.79. Back-transforming this gives a very low prevalence estimate of about 0.01% when I marginalise over the random effect:
> pnorm(fixef(fit.glmer))
 (Intercept)
7.550163e-05
or equivalently:
>   predict(fit.glmer, type = "response", re.form = NA)[1]
           1
7.550163e-05

Averaging over the family-specific predicted prevalences gets closer, but still underestimates the true prevalence (this bias is repeatable, so not just dues to sampling families):
> mean(predict(fit.glmer, type = "response", re.form = NULL))
[1] 0.0435032
This does better because back-transforming before taking the mean draws in the predicted prevalence of the families with no resistant subjects, which is very low on the probit scale but bounded by zero on the proportion scale. However I'm pretty sure this is the wrong way to do it.

Perhaps a more likely explanation is that I'm wrong to assume variance = 1 in the inverse probit function? Should I be adding the inter-family variance, additive dispersion (is this fixed at 1?) and the distribution specific variance, as predict.MCMCglmm does (I've fitted the same model in MCMCglmm and it recovers the prevalence and ICC accurately)? However the family variance estimate is so large that including it results in large overestimates, and the fact that predict.merMod doesn't do this suggests it isn't necessary.

Alternatively, could glmer be overestimating the inter-family variance, leading to an underestimate of the prevalence, due to a combination of low prevalence and and small families (n=3; most families have 0/3 resistant, and the maximum is 2/3).

I'm exploring these possibilities but it would be great to have some expert advice.

Thanks in advance,
Paul

PS I could post the simulation code but it's rather long so I'll wait and see if there's a simple solution.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From Thierry.ONKELINX at inbo.be  Mon Jan 12 10:52:15 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 12 Jan 2015 09:52:15 +0000
Subject: [R-sig-ME] lmer or glmer?
In-Reply-To: <AD3758FC3C68B54EA3C8883F56EFCC8C3BCF4845@STAWINCOX10MBX2.staff.vuw.ac.nz>
References: <AD3758FC3C68B54EA3C8883F56EFCC8C3BCF4845@STAWINCOX10MBX2.staff.vuw.ac.nz>
Message-ID: <AA818EAD2576BC488B4F623941DA742701096F0925@inbomail.inbo.be>

Dear Michael,

I'd rather assess the normality graphically. Non-normality can be caused by missing variables or interactions as well. I tend to avoid transformations as much as possible since they complicate the interpretation of the results. However, a priori knowledge about the relationship should be honored. E.g. if you know that a relationship is exponential, then use this information and transform either the response or the covariate to make things linear again.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Michael Jackson
Verzonden: zondag 11 januari 2015 21:59
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] lmer or glmer?

Hi Ben,

Im wondering if you can help - ive been going round in circles for some weeks now and busily getting more bamboozled. Im basically wanting to use model selection (AICc scores, deltas etc) based on "lme4" outputs to identify the key nutritive drivers of animal consumption. Ive attached my data for you as I think it'll help greatly in showing my issues....My questions are...

1) Should I use REML=FALSE if wanting to compare mixed effects models via their AICc scores, deltas etc. where the random effects are always incorporated, but the fixed effects change between models. Everything ive read suggests yes...do you agree?

2) Ive got 14 different models to run - some additive, some interactive...an example of my code is as follows
m2 = lmer(Consumption ~ Fat + Protein + (1|Product/Trial), data=mydata, REML=FALSE)
m3 = lmer(Consumption ~ Sugars * Fat + (1|Product/Trial), data=mydata, REML=FALSE)

However - no matter which model I run and/or how I scale or transform my variables (both predictor and response) a shaprio wilks test, for example  shapiro.test(resids(m2)) is always significant ....Would using "glmer" be my option here? After reading your paper "Generalised linear mixed models: a practical guide for ecology and evolution" and this article on stackexchange<http://stackoverflow.com/questions/25356633/error-message-when-performing-gamma-glmer-in-r-pirls-step-halvings-failed-to-re>....Would the following example code be OK based on my raw untransformed data?

glmer(Consumption ~ Fat + Protein + (1|Product/Trial), data=mydata, family=Gamma(link=log))

Id value your comment and assistance as I dont want create loads of models and then make incorrect inferences of my AICc outputs based on flawed regression outputs...

Thanks in advance

Mike
..............
PhD Candidate
Centre for Biodiversity and Restoration Ecology Room KK 411 Kirk Building Kelburn Parade Wellington 6012 _______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From stefan.vandongen at uantwerpen.be  Mon Jan 12 13:52:44 2015
From: stefan.vandongen at uantwerpen.be (Van Dongen Stefan)
Date: Mon, 12 Jan 2015 12:52:44 +0000
Subject: [R-sig-ME] intra and inter-observer correlations in a bivariate
	model
Message-ID: <B4D4B84E4C26984690619D21577874EAA6246691@xmail33.ad.ua.ac.be>

Dear All,

Perhaps the answer to my question is trivial, but I got stuck in my own arguments and hope someone can drag me out

Here is the problem ... we have two behavioral traits (say A and B) which are measured for a range of individuals in different years. We have calculated within- and between-year reliabilities on the basis of the basis of residual, individual and year:individual variance components. Next what we want to study is to what extent the correlations between A and B differ if considered within or between years. It is a test-retest type of question as for the reliabilities, but now between the two traits, and cannot clear my mind on how to get those...

any help would be greatly appreciated

Stefan

-------------------------------------------------------------------------------------------------------------------------
Prof. Dr. Stefan Van Dongen
Evolutionary Ecology - Department of Biology - University of Antwerp (http://www.ua.ac.be/eveco)
StatUA Statistics Center, University of Antwerp (http://www.ua.ac.be/statua)
Groenenborgerlaan 171 - B-2020 Antwerp - Belgium

room V324b, building V, campus Groenenborger
Tel: + 32 3 265 33 36
Fax: + 32 3 265 34 74
http://www.ua.ac.be/stefan.vandongen
--------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From Michael.Jackson at vuw.ac.nz  Mon Jan 12 20:41:03 2015
From: Michael.Jackson at vuw.ac.nz (Michael Jackson)
Date: Mon, 12 Jan 2015 19:41:03 +0000
Subject: [R-sig-ME] lmer or glmer?
Message-ID: <AD3758FC3C68B54EA3C8883F56EFCC8C3BCF83EE@STAWINCOX10MBX2.staff.vuw.ac.nz>

Hi Thierry,

Thanks for the input. Ive attached some links to qqnorm(resid(x)) plots run for varying data.

Plot 1 (link below) (based on lmer code) is characteristic of all my plots when using my raw data, i.e., showing positive skew to a greater or lesser extent than this example. I identified the response variable as key to driving this and therefore tried log transforming my response variable.

Plot 2 is the same raw data and lmer coding, but with a log transformed response variable. It now shows slight negative skew and if anything is worse.

Plot 3 is from my glmer coding I proposed in my first message (the two former used the lmer coding) and also my raw untransformed response or predictors. This looks lots better. A SW test is also not significant (p=0.67). This is actually based on using "family=poisson(link=log)" as ive now read that the "family=" aspect only relates to the response, not predictors ...Id be interested in your thoughts.


Plot 1 http://s166.photobucket.com/user/michaeljackson1972/media/Plot1_zps1e8eb440.png.html

Plot 2 http://s166.photobucket.com/user/michaeljackson1972/media/Plot2_zpsa5e555b8.png.html

Plot 3 http://s166.photobucket.com/user/michaeljackson1972/media/Plot3_zpsf4a5b638.png.html

Thanks again,

Mike


..............
PhD Candidate
Centre for Biodiversity and Restoration Ecology
Room KK 411
Kirk Building
Kelburn Parade
Wellington 6012

	[[alternative HTML version deleted]]


From daniel_rubi at ymail.com  Mon Jan 12 21:18:46 2015
From: daniel_rubi at ymail.com (Daniel Rubi)
Date: Mon, 12 Jan 2015 20:18:46 +0000 (UTC)
Subject: [R-sig-ME] Fitting a heteroscedastic glmm for binomial responses
Message-ID: <1642646608.2636.1421093926534.JavaMail.yahoo@jws10710.mail.gq1.yahoo.com>

?I have data from the following experimental design: my observations are counts of the numbers of successes (K) out of corresponding number of trials (N), measured for two groups each comprised of?I?individuals, from?T?treatments, where in each such factor combination there are?R?replicates. Hence, altogether I have 2 * I * T * R?K's and corresponding?N's.
I'm interested in estimating the effects that group and treatment have on the dispersion/variance of the success probabilities (i.e.,?K/N), and I believe id needs to be specified as a random effect. Therefore I'm looking for an appropriate glmm in which in addition to modelling the expected value of the response the variance of the response is also modeled.
Clearly, the variance of a binomial success probability is affected by the number of trials and the underlying success probability (the higher the number of trials is and the more extreme the underlying success probability is (i.e., near 0 or 1), the lower the variance of the success probability), so that has to be accounted for.
Here's an R code for simulated example data:library(MASS)
set.seed(1)
I <- 20 # individuals in each group
G <- 2  # groups
T <- 3  # treatments
R <- 30 # replicates of each individual, in each group, in each treatment

groups <- letters[1:G]
ids <- c(sapply(groups, function(g){ paste(rep(g, I), 1:I, sep=".") }))
treatments <- paste(rep("t", T), 1:T, sep=".")
 # create random mean number of trials for each individual and 
 #  dispersion values to simulate trials from a negative binomial:
mean.trials <- rlnorm(length(ids), meanlog=10, sdlog=1)
thetas <- 10^6/mean.trials
 # create the underlying success probability for each individual:
p.vec <- runif(length(ids), min=0, max=1)
 # create a dispersion factor for each success probability, where the 
 #  individuals of group 2 have higher dispersion thus creating a group effect:
dispersion.vec <- c(runif(length(ids)/2, min=0, max=0.1),
                   runif(length(ids)/2, min=0, max=0.2))
 # create empty an data.frame:
data.df <- data.frame(id=rep(sapply(ids, function(i){ rep(i, R) }), T),
                     group=rep(sapply(groups, function(g){ rep(g, I*R) }), T),
                     treatment=c(sapply(treatments, 
                                        function(t){ rep(t, length(ids)*R) })),
                     N=rep(NA, length(ids)*T*R), 
                     K=rep(NA, length(ids)*T*R) )
 # fill N's and K's - trials and successes. Trials are assumed to be overdisperesed and hence N's are drawn from a negative binomial
for(i in 1:length(ids)){
  N <- rnegbin(T*R, mu=mean.trials[i], theta=thetas[i])
  probs <- runif(T*R, min=max((1-dispersion.vec[i])*p.vec[i],0),
                max=min((1+dispersion.vec)*p.vec[i],1))
  K <- rbinom(T*R, N, probs)
  data.df$N[which(as.character(data.df$id) == ids[i])] <- N
  data.df$K[which(as.character(data.df$id) == ids[i])] <- K
}Attached are the following plots (group a are in orange and group b are in black; treatment?t.1 are in squares, treatment t.2 are in circles, and treatment t.3 are in triangle):1. Sample variance vs. sample mean of the estimated success probability (denoted as p hat = K/N), which illustrates that extreme success probabilities have lower variance.2. If I apply the arcsin square root transformation to K/N (denoted as asin(sqrt(p.hat))), this relationship is largely eliminated.3. Sample variance of asin(sqrt(p.hat))? vs. the mean N across replicates for each individual shows the expected negative relationship.4. Sample variance of asin(sqrt(p.hat)) for the two groups shows that group b has slightly higher variances, which is how I simulated the data.5. Sample variance of asin(sqrt(p.hat)) for the?three?treatments shows no difference between treatments, which is how I simulated the data.
Is there any form of a glmm with which I can quantify the group and treatment effects on the variance of the success probabilities? Perhaps a heteroscedastic glmm (i.e. which estimates the effect of regressors on the variance of the response)?
Help would be most appreciated.Thanks a lot,Dan
P.S.I also posted this on cross validated but it wasn't answered.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: var.p.hat.vs.mean.p.hat.png
Type: image/png
Size: 3919 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150112/50f635d4/attachment-0005.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: var.asin.sqrt.p.hat.vs.mean.asin.sqrt.p.hat.png
Type: image/png
Size: 4162 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150112/50f635d4/attachment-0006.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: var.asin.sqrt.p.hat.vs.mean.N.png
Type: image/png
Size: 4195 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150112/50f635d4/attachment-0007.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: var.asin.sqrt.p.hat.vs.group.png
Type: image/png
Size: 3806 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150112/50f635d4/attachment-0008.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: var.asin.sqrt.p.hat.vs.treatment.png
Type: image/png
Size: 3991 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150112/50f635d4/attachment-0009.png>

From ken.beath at mq.edu.au  Mon Jan 12 23:11:17 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Tue, 13 Jan 2015 09:11:17 +1100
Subject: [R-sig-ME] lmer or glmer?
In-Reply-To: <AD3758FC3C68B54EA3C8883F56EFCC8C3BCF83EE@STAWINCOX10MBX2.staff.vuw.ac.nz>
References: <AD3758FC3C68B54EA3C8883F56EFCC8C3BCF83EE@STAWINCOX10MBX2.staff.vuw.ac.nz>
Message-ID: <CAF5_5cyY7_vXoT1iGoc5TXzJSS=xgzjPoUYZL7VWzGVjjiNKOw@mail.gmail.com>

Rather than using poisson you should use quasi poisson, as the data that
you have is not counts so you can't assume the fixed relationship between
mean and variance that Poisson requires. You should also look at the
residuals versus fitted values as these will indicate whether the
increasing variance with mean from a Poisson or quasi Poisson is correct.
The spread of the residuals should look fairly constant.


On 13 January 2015 at 06:41, Michael Jackson <Michael.Jackson at vuw.ac.nz>
wrote:

> Hi Thierry,
>
> Thanks for the input. Ive attached some links to qqnorm(resid(x)) plots
> run for varying data.
>
> Plot 1 (link below) (based on lmer code) is characteristic of all my plots
> when using my raw data, i.e., showing positive skew to a greater or lesser
> extent than this example. I identified the response variable as key to
> driving this and therefore tried log transforming my response variable.
>
> Plot 2 is the same raw data and lmer coding, but with a log transformed
> response variable. It now shows slight negative skew and if anything is
> worse.
>
> Plot 3 is from my glmer coding I proposed in my first message (the two
> former used the lmer coding) and also my raw untransformed response or
> predictors. This looks lots better. A SW test is also not significant
> (p=0.67). This is actually based on using "family=poisson(link=log)" as ive
> now read that the "family=" aspect only relates to the response, not
> predictors ...Id be interested in your thoughts.
>
>
> Plot 1
> http://s166.photobucket.com/user/michaeljackson1972/media/Plot1_zps1e8eb440.png.html
>
> Plot 2
> http://s166.photobucket.com/user/michaeljackson1972/media/Plot2_zpsa5e555b8.png.html
>
> Plot 3
> http://s166.photobucket.com/user/michaeljackson1972/media/Plot3_zpsf4a5b638.png.html
>
> Thanks again,
>
> Mike
>
>
> ..............
> PhD Candidate
> Centre for Biodiversity and Restoration Ecology
> Room KK 411
> Kirk Building
> Kelburn Parade
> Wellington 6012
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From Thierry.ONKELINX at inbo.be  Tue Jan 13 10:32:40 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 13 Jan 2015 09:32:40 +0000
Subject: [R-sig-ME] lmer or glmer?
In-Reply-To: <AD3758FC3C68B54EA3C8883F56EFCC8C3BCF83EE@STAWINCOX10MBX2.staff.vuw.ac.nz>
References: <AD3758FC3C68B54EA3C8883F56EFCC8C3BCF83EE@STAWINCOX10MBX2.staff.vuw.ac.nz>
Message-ID: <AA818EAD2576BC488B4F623941DA742701096F2FEE@inbomail.inbo.be>

Dear Michael,

Neither of the qq plots look terribly problematic. But don't just look at qq plots! Plot the residuals against the available covariates and see if there is any pattern.

Choose a distribution family based on the properties of the response. Poisson assumes non-negative integer values. So don't use Poisson if the response is continuous. You will need to tell us more about the response if you need help on that.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens Michael Jackson [Michael.Jackson at vuw.ac.nz]
Verzonden: maandag 12 januari 2015 20:41
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] lmer or glmer?

Hi Thierry,

Thanks for the input. Ive attached some links to qqnorm(resid(x)) plots run for varying data.

Plot 1 (link below) (based on lmer code) is characteristic of all my plots when using my raw data, i.e., showing positive skew to a greater or lesser extent than this example. I identified the response variable as key to driving this and therefore tried log transforming my response variable.

Plot 2 is the same raw data and lmer coding, but with a log transformed response variable. It now shows slight negative skew and if anything is worse.

Plot 3 is from my glmer coding I proposed in my first message (the two former used the lmer coding) and also my raw untransformed response or predictors. This looks lots better. A SW test is also not significant (p=0.67). This is actually based on using "family=poisson(link=log)" as ive now read that the "family=" aspect only relates to the response, not predictors ...Id be interested in your thoughts.


Plot 1 http://s166.photobucket.com/user/michaeljackson1972/media/Plot1_zps1e8eb440.png.html

Plot 2 http://s166.photobucket.com/user/michaeljackson1972/media/Plot2_zpsa5e555b8.png.html

Plot 3 http://s166.photobucket.com/user/michaeljackson1972/media/Plot3_zpsf4a5b638.png.html

Thanks again,

Mike


..............
PhD Candidate
Centre for Biodiversity and Restoration Ecology
Room KK 411
Kirk Building
Kelburn Parade
Wellington 6012

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From highstat at highstat.com  Tue Jan 13 11:41:38 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 13 Jan 2015 10:41:38 +0000
Subject: [R-sig-ME] Two stats courses in Portugal
Message-ID: <54B4F662.4010307@highstat.com>

Apologies for cross-posting

There are 5 remaining seats available on each of the following two courses:

Data exploration, regression, GLM & GAM with introduction to R.
2 - 6 February 2015.  Coimbra, Portugal


Introduction to Linear mixed effects models,  GLMM and MCMC with R
9-13 February 2015. Lisbon, Portugal



For registration, course flyers and further information: 
http://www.highstat.com/statscourse.htm


Kind regards,

Alain

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From tim.cole at ucl.ac.uk  Wed Jan 14 10:37:10 2015
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Wed, 14 Jan 2015 09:37:10 +0000
Subject: [R-sig-ME] c++ exception with logistic glmer
In-Reply-To: <CAF5_5czcYQG6t_6mAYTA3G9=c2bhghOr9ZEOQ9a21pMmPNhDqQ@mail.gmail.com>
References: <D0D01AE1.3651B%tim.cole@ucl.ac.uk>
	<CAF5_5czcYQG6t_6mAYTA3G9=c2bhghOr9ZEOQ9a21pMmPNhDqQ@mail.gmail.com>
Message-ID: <D0DBE7A4.BE3B%tim.cole@ucl.ac.uk>

Thanks Ken for your insights, and also for David Duffy?s thoughts (sent offline):

The reduced model has an undefined intraclass correlation for the binary
maturity variable (every cluster is 0-1), so this is why the variance is
zero.  It seems to me, as I mentioned earlier, that if you add additional
time points on either side of the transition to maturity the slope
coefficient for each individual will (arbitrarily) flatten out, which
implies the random intercept model isn't doing what you want it to.
Certainly, the empirical within-individual correlation between
observations is not uniform, which is the simplest RE model.

The message is clear, that this model is not going to work, which is a shame. I would point out though that all the models give reasonable estimates of the median age at maturity, -intercept/slope, which is one of the summary statistics I?m interested in.

Tim
---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK

From: Ken Beath <ken.beath at mq.edu.au<mailto:ken.beath at mq.edu.au>>
Date: Thursday, 8 January 2015 22:08
To: Tim Cole <tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk>>
Cc: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>, "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] c++ exception with logistic glmer

The different log likelihoods for different values of nAGQ, and hence BIC, is a known problem with glmer. nAGQ=1 is correct, and I think other values are just out by a constant.

As to your model, what is happening is that a step function is being modeled by a logistic. As a result the coefficient of age tends towards a large number (a parameter estimate of 5 corresponds to an odds ratio of about 150 per year, 17 is a huge odds ratio) , in an attempt  to reproduce the step. The random effect will be modeling where the switch happens so will also be large, as it needs to move a very steep line to varying values of age. Effectively the model is close to being non-identifiable, as the loglikelihood will remain almost unchanged for increasing combinations of age parameter and random effect variance. Centering age might improve the numerics and result in even larger coefficients.

I'm not certain what is happening with the 2 observations per subject. If they were all 0,1 then the coefficient of age would be infinite, as a one year change in age would always produce a change from zero to one.   However, it is similar to the discrete logistic survival which has a series of zeroes followed by a 1 and doesn't require a random effect to model.

Ken

On 6 January 2015 at 23:34, Cole, Tim <tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk>> wrote:
I'm returning to a thread I started a year ago. My logistic glmer model (described below) generated an obscure error message, which Emmanuel Curis pointed out arose from duplicate rows in my data. Ben Bolker and David Duffy thought there might be separation in the cleaned dataset, and Jonathan French and Ben suggested an alternative time-to-event analysis instead of the logistic.

The dataset consists of longitudinal measures of a binary bone maturity score called mat, which for each subject (n = 607) consists of zero or more 0s followed by zero or more 1s, the age at 0/1 transition constituting the subject's age at maturity. The aim is to estimate median age at maturity, given by ?intercept/age coefficient and confidence interval based on Fieller's theorem.

The full data frame is bhs (4565 rows), while dfs is a reduced data frame (1086 rows) consisting of the last mat 0 entry and first mat 1 entry per subject (where available).

Using glm ignores the longitudinal element, whille glmer allows a random subject intercept reflecting inter-subject variability in age at maturity.

lm0 <- glm(mat ~ age, family=binomial, data=bhs)
lm0r <- glm(mat ~ age, family=binomial, data=dfs)
for (n in c(0, 1, 5, 9)) {
assign(paste('lm0', n, sep='.'), glmer(mat ~ age + (1 | BHID), family=binomial, data=bhs, nAGQ=n))
assign(paste('lm0r', n, sep='.'), glmer(mat ~ age + (1 | BHID), family=binomial, data=dfs, nAGQ=n))
}
list <- ls(pattern='^lm0')
unlist(list, function(z) {
res <- BIC(get(z))
names(res) <- z
res
}))
             lm0    lm0.0    lm0.1    lm0.5    lm0.9     lm0r   lm0r.0   lm0r.1   lm0r.5   lm0r.9
2474.576 1812.824 1386.288 1788.585 1778.761 1298.951 1305.941 1305.941 1305.941 1305.941

With the full data frame (models lm0.n) BIC varies with nAGQ, and for the Laplace fit (nAGQ=1) the model looks dodgy. The coefficients are as follows:

$lm0
              Estimate Std. Error   z value      Pr(>|z|)
(Intercept) -18.700922  0.5783898 -32.33273 2.426656e-229
age           1.169465  0.0363381  32.18288 3.063925e-227

$lm0.0
              Estimate Std. Error   z value      Pr(>|z|)
(Intercept) -75.261703  3.3652807 -22.36417 8.790724e-111
age           4.710325  0.2086032  22.58031 6.766768e-113

$lm0.1
              Estimate Std. Error   z value Pr(>|z|)
(Intercept) -276.41591 1.21959198 -226.6462        0
age           17.35977 0.08850143  196.1525        0

$lm0.5
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -71.992747  6.7038887 -10.73895 6.679749e-27
age           4.497433  0.4186714  10.74215 6.452210e-27

$lm0.9
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -80.623844  8.9423308 -9.015976 1.951243e-19
age           5.035102  0.5569928  9.039797 1.569631e-19

As expected the regression line is steeper with the random effect included, though again lm0.1 look odd.

With the reduced data frame the lmr.n models do not vary with nAGQ. But the odder thing is that the coefficients are identical with and without the random effect, as the SD of the random effect is estimated to be zero.

$lm0r
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -8.6820194 0.69870600 -12.42586 1.891928e-35
age          0.5393926 0.04395768  12.27072 1.300837e-34

$lm0r.0
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -8.6820193 0.69864489 -12.42694 1.866391e-35
age          0.5393926 0.04395395  12.27177 1.284216e-34

So I have two questions. Why do the results with the full data frame depend on nAGQ, and why with the reduced data frame is the SD of random effect estimated as zero?

Thanks for your thoughts.

Tim
 ---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ucl.ac.uk><mailto:Tim.Cole at ich.ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk>> Phone +44(0)20 7905 2666<tel:%2B44%280%2920%207905%202666> Fax +44(0)20 7905 2381<tel:%2B44%280%2920%207905%202381>
Population, Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK






--

Ken Beath
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:10}}


From lofgrene at vbi.vt.edu  Wed Jan 14 21:12:44 2015
From: lofgrene at vbi.vt.edu (Eric Lofgren)
Date: Wed, 14 Jan 2015 15:12:44 -0500
Subject: [R-sig-ME] Tackling various errors in a mixed-effects Poisson model
Message-ID: <D83B98CF-4F89-4A85-B7F4-101BC387DC43@vbi.vt.edu>

(Some of this content cross-posted to either StackExchange or CrossValidated)

Hey folks,

I?m currently working on an interrupted time-series project, and have run into some implementation issues I was hoping folks might be able to help me through. The data I?m working with has about ~1200 observations, with the observations split evenly between 17 sites for a total of 72 observations/site.

At the moment, I?m trying to estimate a single rate as a response to an indicator variable indicating a change in policy, the time up until the policy, the time after the policy, a binary cofounder and a continuous confounder.

If I was just doing a single site, the model would look something like:

mod <- glm(Outcome ~ Exposure + t_before + t_after + Var1 + Var2 + offset((log(PersonTime)), family=Poisson, data=data)

Since we?ve got multiple sites, I?ve moved to a mixed-effects model that looks like so:

mod <- glmer(Outcome ~ Exposure + t_before + t_after + Var1 + Var2 + (t_before + t_after + Var1 + Var2|Site) + offset((log(PersonTime)), family=Poisson, data=data)

I?ve also added control=glmerControl(optimizer="bobyqa",optCtrl = list(maxfun = 500000)) because of some convergence issues in a test model. This brings me to the two major issues I?m having:

1. In some of the models, lme4 is generating this error "Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate? in the presence of some, but not all offsets. I can?t see a clear difference between the offsets that are triggering this and the offset that isn?t (save that the triggering offsets are smaller, but they?re both reasonably normal when log transformed).

2. Generally, these models are having some serious convergence issues with lme4. I?m reluctant to simplify the models much further, but does anyone have suggestions in that regard? Would an MCMC based approach work better (if more computationally intensively) for this kind of data? If so, how would you compose the model above in something like MCMCglmm?

Thanks very much for your help,

Eric


From PaulW.Rasmussen at wisconsin.gov  Wed Jan 14 21:22:25 2015
From: PaulW.Rasmussen at wisconsin.gov (Rasmussen, Paul W - DNR)
Date: Wed, 14 Jan 2015 20:22:25 +0000
Subject: [R-sig-ME] prediction interval for prediction from mixed effects
	model
Message-ID: <33d8c2b04e684e73895a8e5bd233a1c4@MEWMAD0P1962.accounts.wistate.us>

Hi,

I have a question about the description of computing prediction intervals at the glmm.wikidot.com/faq site.  I have copied the relevant sections of code below, with the subsections that I'm concerned about underlined.  The code example for nlme uses the variance of the fixed effects (predvar) and adds to it the residual variance (fm1$sigma^2).  The code example for lme4 uses the variance of the fixed effects (pvar1) and adds to it the variance among subjects (VarCorr(fm1)$Subject[1]).  It seems to me that the nlme example is correct and that the lme4 example is incorrect - shouldn't the lme4 example add the residual variance instead of the variance among subjects?  I would think that the variance among subjects would only be appropriate when predicting for a subject not previously observed.


lme
library(nlme)
fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data = Orthodont)

plot(Orthodont)
newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
newdat$pred <- predict(fm1, newdat, level = 0)

Designmat <- model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
predvar <- diag(Designmat %*% fm1$varFix %*% t(Designmat))
newdat$SE <- sqrt(predvar)
newdat$SE2 <- sqrt(predvar+fm1$sigma^2)

lme4

library(lme4)
library(ggplot2) # Plotting
data("Orthodont",package="MEMSS")
fm1 <- lmer(
    formula = distance ~ age*Sex + (age|Subject)
    , data = Orthodont
)
newdat <- expand.grid(
    age=c(8,10,12,14)
    , Sex=c("Male","Female")
    , distance = 0
)
mm <- model.matrix(terms(fm1),newdat)
newdat$distance <- predict(fm1,newdat)
## or newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(fm1),mm))
tvar1 <- pvar1+VarCorr(fm1)$Subject[1]  ## must be adapted for more complex models

Thank you,
Paul Rasmussen
WI DNR





	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Wed Jan 14 23:26:35 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 15 Jan 2015 09:26:35 +1100
Subject: [R-sig-ME] Tackling various errors in a mixed-effects Poisson
	model
In-Reply-To: <D83B98CF-4F89-4A85-B7F4-101BC387DC43@vbi.vt.edu>
References: <D83B98CF-4F89-4A85-B7F4-101BC387DC43@vbi.vt.edu>
Message-ID: <CAF5_5cw71dJbSYXtpn5uhhrPQr=-LmiqAYa_BnafWqhQLkCfnA@mail.gmail.com>

5 random effects is a lot to be fitting, and is probably causing the
convergence problems. I would start with just a random effect for the
intercept and then add in the others one by one and look at the effect on
AIC.

On 15 January 2015 at 07:12, Eric Lofgren <lofgrene at vbi.vt.edu> wrote:

> (Some of this content cross-posted to either StackExchange or
> CrossValidated)
>
> Hey folks,
>
> I?m currently working on an interrupted time-series project, and have run
> into some implementation issues I was hoping folks might be able to help me
> through. The data I?m working with has about ~1200 observations, with the
> observations split evenly between 17 sites for a total of 72
> observations/site.
>
> At the moment, I?m trying to estimate a single rate as a response to an
> indicator variable indicating a change in policy, the time up until the
> policy, the time after the policy, a binary cofounder and a continuous
> confounder.
>
> If I was just doing a single site, the model would look something like:
>
> mod <- glm(Outcome ~ Exposure + t_before + t_after + Var1 + Var2 +
> offset((log(PersonTime)), family=Poisson, data=data)
>
> Since we?ve got multiple sites, I?ve moved to a mixed-effects model that
> looks like so:
>
> mod <- glmer(Outcome ~ Exposure + t_before + t_after + Var1 + Var2 +
> (t_before + t_after + Var1 + Var2|Site) + offset((log(PersonTime)),
> family=Poisson, data=data)
>
> I?ve also added control=glmerControl(optimizer="bobyqa",optCtrl =
> list(maxfun = 500000)) because of some convergence issues in a test model.
> This brings me to the two major issues I?m having:
>
> 1. In some of the models, lme4 is generating this error "Error:
> (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate? in the presence of some, but not all offsets. I can?t see a
> clear difference between the offsets that are triggering this and the
> offset that isn?t (save that the triggering offsets are smaller, but
> they?re both reasonably normal when log transformed).
>
> 2. Generally, these models are having some serious convergence issues with
> lme4. I?m reluctant to simplify the models much further, but does anyone
> have suggestions in that regard? Would an MCMC based approach work better
> (if more computationally intensively) for this kind of data? If so, how
> would you compose the model above in something like MCMCglmm?
>
> Thanks very much for your help,
>
> Eric
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From Michael.Jackson at vuw.ac.nz  Wed Jan 14 23:26:09 2015
From: Michael.Jackson at vuw.ac.nz (Michael Jackson)
Date: Wed, 14 Jan 2015 22:26:09 +0000
Subject: [R-sig-ME] lmer or glmer?
Message-ID: <AD3758FC3C68B54EA3C8883F56EFCC8C3BD00230@STAWINCOX10MBX2.staff.vuw.ac.nz>

Hi Ken and Thierry

Thanks very much for you input...

M

..............
PhD Candidate
Centre for Biodiversity and Restoration Ecology
Room KK 411
Kirk Building
Kelburn Parade
Wellington 6012

	[[alternative HTML version deleted]]


From karl.ove.hufthammer at helse-bergen.no  Thu Jan 15 17:34:17 2015
From: karl.ove.hufthammer at helse-bergen.no (Hufthammer, Karl Ove)
Date: Thu, 15 Jan 2015 17:34:17 +0100
Subject: [R-sig-ME] Modelling random effects for only part of the
	observations (in lme4)
Message-ID: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9F8@BGO-MCS005.ihelse.net>

Dear list members,

I have a seemingly easy problem, though it turned out to be more difficult in practice. Basically, I'm wondering if it is possible in lme4 to model random effects for only *some* of the observations?

Here's my problem (somewhat simplified). Individuals are randomised to either treatment or no treatment. The treatment consists of group therapy, where the individuals are (randomly) assigned to groups. It is reasonable to expect some sort of group/cluster effect -?e.g.?a therapist effect and/or a within-group interaction effect for the individuals?- and this effect can be modelled as a random effect. So far so good.

However, for the individuals randomised to no treatment, there are no groups, and thus no group effects. So basically (I think!) I can use the linear model (in mathematical notation)

  y_ij = intercept + b*x_ij + eps_ij

for the untreated individuals, and

  y_ij = intercept + b*x_ij + treatment + B_i + eps_ij

for the treated indivduals, where i are group indices, j are indices for the individuals, x_ij is some (baseline) covariate(s) and B_i are the random effects. (i is of course not really defined for the control individuals, so you can assume that all j indices are different for different individuals, and replace ij with j and i with i(j), if that makes the syntax easier to understand.)

Or, in lme4/lm syntax:

  y ~ x + treat_factor + (1|group) # Treated individuals
  y ~ x + treat_factor             # Untreated individuals

where treat_factor is a two-level factor (control/treatment).

The two *mathematical* linear predictor formulas are easy to combine into one:
  
  y_ij = intercept + b*x_ij + arm_ij*treatment + arm_ij*B_i + eps_ij

where arm_ij (indicating treatment/control arm) is 1 if the individual (i,j) was randomised to the treatment arm and 0 if he/she was randomised to the control arm.

But how do I write this in lme4 syntax?

I have thought about letting each individual in the control arm being its own cluster/group. But this doesn't seem realistic. Why would the variance between groups (in the treatment arm) be similar to the variance between individuals in control arm? It doesn't seem like a realistic model, and I believe it would bias the estimated treatment effect.

Is it even possible to fit these types of models? Or are there other R packages that can be used instead? (Note that for my actual data set I have a logistic, not a linear, model, but I doubt this makes things *easier* .)

Any help would be appreciated.

-- 
Karl Ove Hufthammer


From mmalten at gmail.com  Thu Jan 15 19:34:04 2015
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Thu, 15 Jan 2015 13:34:04 -0500
Subject: [R-sig-ME] Modelling random effects for only part of the
 observations (in lme4)
In-Reply-To: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9F8@BGO-MCS005.ihelse.net>
References: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9F8@BGO-MCS005.ihelse.net>
Message-ID: <CANOgrHZCth0UmVzGhD79Pw9VknpfRKP_9xr5u3uOHOAtDLnnXg@mail.gmail.com>

What about nested random effects...where you only have one group within no
treatment, and multiple groups within treatment?  Or would R crash?

On Thursday, January 15, 2015, Hufthammer, Karl Ove <
karl.ove.hufthammer at helse-bergen.no> wrote:

> Dear list members,
>
> I have a seemingly easy problem, though it turned out to be more difficult
> in practice. Basically, I'm wondering if it is possible in lme4 to model
> random effects for only *some* of the observations?
>
> Here's my problem (somewhat simplified). Individuals are randomised to
> either treatment or no treatment. The treatment consists of group therapy,
> where the individuals are (randomly) assigned to groups. It is reasonable
> to expect some sort of group/cluster effect - e.g. a therapist effect
> and/or a within-group interaction effect for the individuals - and this
> effect can be modelled as a random effect. So far so good.
>
> However, for the individuals randomised to no treatment, there are no
> groups, and thus no group effects. So basically (I think!) I can use the
> linear model (in mathematical notation)
>
>   y_ij = intercept + b*x_ij + eps_ij
>
> for the untreated individuals, and
>
>   y_ij = intercept + b*x_ij + treatment + B_i + eps_ij
>
> for the treated indivduals, where i are group indices, j are indices for
> the individuals, x_ij is some (baseline) covariate(s) and B_i are the
> random effects. (i is of course not really defined for the control
> individuals, so you can assume that all j indices are different for
> different individuals, and replace ij with j and i with i(j), if that makes
> the syntax easier to understand.)
>
> Or, in lme4/lm syntax:
>
>   y ~ x + treat_factor + (1|group) # Treated individuals
>   y ~ x + treat_factor             # Untreated individuals
>
> where treat_factor is a two-level factor (control/treatment).
>
> The two *mathematical* linear predictor formulas are easy to combine into
> one:
>
>   y_ij = intercept + b*x_ij + arm_ij*treatment + arm_ij*B_i + eps_ij
>
> where arm_ij (indicating treatment/control arm) is 1 if the individual
> (i,j) was randomised to the treatment arm and 0 if he/she was randomised to
> the control arm.
>
> But how do I write this in lme4 syntax?
>
> I have thought about letting each individual in the control arm being its
> own cluster/group. But this doesn't seem realistic. Why would the variance
> between groups (in the treatment arm) be similar to the variance between
> individuals in control arm? It doesn't seem like a realistic model, and I
> believe it would bias the estimated treatment effect.
>
> Is it even possible to fit these types of models? Or are there other R
> packages that can be used instead? (Note that for my actual data set I have
> a logistic, not a linear, model, but I doubt this makes things *easier* .)
>
> Any help would be appreciated.
>
> --
> Karl Ove Hufthammer
>
> _______________________________________________
> R-sig-mixed-models at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
____________________________
Ersatzistician and Chutzpahthologist

I can answer any question.  "I don't know" is an answer. "I don't know yet"
is a better answer.

"I can write better than anybody who can write faster, and I can write
faster than anybody who can write better" AJ Liebling

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Jan 15 19:55:17 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 15 Jan 2015 18:55:17 +0000
Subject: [R-sig-ME] Modelling random effects for only part of the
 observations (in lme4)
In-Reply-To: <CANOgrHZCth0UmVzGhD79Pw9VknpfRKP_9xr5u3uOHOAtDLnnXg@mail.gmail.com>
References: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9F8@BGO-MCS005.ihelse.net>
	<CANOgrHZCth0UmVzGhD79Pw9VknpfRKP_9xr5u3uOHOAtDLnnXg@mail.gmail.com>
Message-ID: <20150115185517.194823rjulurzcis@www.staffmail.ed.ac.uk>

Hi,

Create a binary vector (lets call it b) with 0 for observations where  
you don't want random effects and a 1 where you do. Then fit:

(b|group)

Cheers,

Jarrod



Quoting Mitchell Maltenfort <mmalten at gmail.com> on Thu, 15 Jan 2015  
13:34:04 -0500:

> What about nested random effects...where you only have one group within no
> treatment, and multiple groups within treatment?  Or would R crash?
>
> On Thursday, January 15, 2015, Hufthammer, Karl Ove <
> karl.ove.hufthammer at helse-bergen.no> wrote:
>
>> Dear list members,
>>
>> I have a seemingly easy problem, though it turned out to be more difficult
>> in practice. Basically, I'm wondering if it is possible in lme4 to model
>> random effects for only *some* of the observations?
>>
>> Here's my problem (somewhat simplified). Individuals are randomised to
>> either treatment or no treatment. The treatment consists of group therapy,
>> where the individuals are (randomly) assigned to groups. It is reasonable
>> to expect some sort of group/cluster effect - e.g. a therapist effect
>> and/or a within-group interaction effect for the individuals - and this
>> effect can be modelled as a random effect. So far so good.
>>
>> However, for the individuals randomised to no treatment, there are no
>> groups, and thus no group effects. So basically (I think!) I can use the
>> linear model (in mathematical notation)
>>
>>   y_ij = intercept + b*x_ij + eps_ij
>>
>> for the untreated individuals, and
>>
>>   y_ij = intercept + b*x_ij + treatment + B_i + eps_ij
>>
>> for the treated indivduals, where i are group indices, j are indices for
>> the individuals, x_ij is some (baseline) covariate(s) and B_i are the
>> random effects. (i is of course not really defined for the control
>> individuals, so you can assume that all j indices are different for
>> different individuals, and replace ij with j and i with i(j), if that makes
>> the syntax easier to understand.)
>>
>> Or, in lme4/lm syntax:
>>
>>   y ~ x + treat_factor + (1|group) # Treated individuals
>>   y ~ x + treat_factor             # Untreated individuals
>>
>> where treat_factor is a two-level factor (control/treatment).
>>
>> The two *mathematical* linear predictor formulas are easy to combine into
>> one:
>>
>>   y_ij = intercept + b*x_ij + arm_ij*treatment + arm_ij*B_i + eps_ij
>>
>> where arm_ij (indicating treatment/control arm) is 1 if the individual
>> (i,j) was randomised to the treatment arm and 0 if he/she was randomised to
>> the control arm.
>>
>> But how do I write this in lme4 syntax?
>>
>> I have thought about letting each individual in the control arm being its
>> own cluster/group. But this doesn't seem realistic. Why would the variance
>> between groups (in the treatment arm) be similar to the variance between
>> individuals in control arm? It doesn't seem like a realistic model, and I
>> believe it would bias the estimated treatment effect.
>>
>> Is it even possible to fit these types of models? Or are there other R
>> packages that can be used instead? (Note that for my actual data set I have
>> a logistic, not a linear, model, but I doubt this makes things *easier* .)
>>
>> Any help would be appreciated.
>>
>> --
>> Karl Ove Hufthammer
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <javascript:;> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> ____________________________
> Ersatzistician and Chutzpahthologist
>
> I can answer any question.  "I don't know" is an answer. "I don't know yet"
> is a better answer.
>
> "I can write better than anybody who can write faster, and I can write
> faster than anybody who can write better" AJ Liebling
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From jackiewood7 at gmail.com  Thu Jan 15 21:41:57 2015
From: jackiewood7 at gmail.com (Jackie Wood)
Date: Thu, 15 Jan 2015 15:41:57 -0500
Subject: [R-sig-ME] Meta-analysis for heritability using MCMCglmm?
In-Reply-To: <20141226065813.21424g2r4lweojk0@www.staffmail.ed.ac.uk>
References: <CAOxxGR=8rvPJTiHPjVYJNaCDZcUH0medNnk+fba2bONrX8kS2Q@mail.gmail.com>
	<CAF5_5cyX-HYrnrO1qDvP2+CsRWTaRpVU8BgpGe9sR+bf8LRiRg@mail.gmail.com>
	<20141226065813.21424g2r4lweojk0@www.staffmail.ed.ac.uk>
Message-ID: <CAOxxGR=O0B-cmiy_4HwUnOaHNrorn-XUtY2bJMo6uwqYYmMVuw@mail.gmail.com>

Hi Jarrod and Ken,

Hope you had a great New Year! Thanks so much for your responses to my
inquiry. Given that we've been using MCMCglmm all along, we'll probably
stick with it unless there's a compelling reason to change programs. We'll
be running the h2 models in the coming days and will specify a Gaussian
distribution as Jarrod suggested; we have quite a bit of data so hopefully
the residuals will behave!

The advice is much appreciated as always!
Jackie

On Fri, Dec 26, 2014 at 1:58 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi Jackie,
>
> The data are not binomial they are continuous: a beta distribution is
> probably most appropriate for continuos observations bounded by 0 and 1.
> However, although heritabilities are bounded by 0 and 1, heritability
> estimates are not necessarily so, depending on the method of inference (for
> example it would be possible to get a negative parent-offspring regression,
> either by chance or through certain types of maternal effect).
>
> We have just finished a meta-analysis of h2 estimates and just treated
> them as Gaussian. The distribution of the residuals wasn't far off and I
> think the conclusions are robust to the distributional assumptions. Have
> you checked your residuals - do they look badly non-normal?
>
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> Quoting Ken Beath <ken.beath at mq.edu.au> on Wed, 24 Dec 2014 12:30:03
> +1100:
>
>  If you have the original data giving the numerator and denominator for the
>> proportion then it is binomial data, and can be modelled in a
>> met-analysis.
>> I don't know if this can be done with MCMCglmm but should be possible with
>> STAN, JAGS or BUGS. All will require a bit of effort in setting up the
>> model.
>>
>> On 24 December 2014 at 07:17, Jackie Wood <jackiewood7 at gmail.com> wrote:
>>
>>  Dear R-users,
>>>
>>> I am attempting to conduct a meta-analysis to investigate the
>>> relationship
>>> of narrow-sense heritability with population size. In previous work, I
>>> have
>>> used MCMCglmm to conduct a formal meta-analysis which allowed me to
>>> account
>>> for the effect of sampling error through the argument "mev". This was
>>> relatively easy to do for a continuous response variable, however,
>>> heritability is presented as a proportion and is therefore bounded by 0
>>> and
>>> 1 which clearly changes the situation.
>>>
>>> In fact, I am not actually certain if it possible to conduct a formal
>>> weighted meta-analysis on the heritability data using MCMCglmm. I have
>>> seen
>>> elsewhere where data presented as a proportion (survival, yolk-conversion
>>> efficiency for example) has been logit transformed and fitted using a
>>> Gaussian error distribution (though this was done using REML rather than
>>> Bayesian modelling) but I don't know if this is a legitimate strategy
>>> for a
>>> formal meta-analysis using heritability as a response variable since any
>>> transformation applied to the heritability data would also need to be
>>> applied to the standard errors?
>>>
>>> I would greatly appreciate any advice on this matter!
>>>
>>> Cheers,
>>> Jackie
>>>
>>> --
>>> Jacquelyn L.A. Wood, PhD.
>>> Biology Department
>>> Concordia University
>>> 7141 Sherbrooke St. West
>>> Montreal, QC
>>> H4B 1R6
>>> Phone: (514) 293-7255
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may...{{dropped:9}}
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
Jacquelyn L.A. Wood, PhD.
Biology Department
Concordia University
7141 Sherbrooke St. West
Montreal, QC
H4B 1R6
Phone: (514) 293-7255

	[[alternative HTML version deleted]]


From karl.ove.hufthammer at helse-bergen.no  Fri Jan 16 09:36:24 2015
From: karl.ove.hufthammer at helse-bergen.no (Hufthammer, Karl Ove)
Date: Fri, 16 Jan 2015 09:36:24 +0100
Subject: [R-sig-ME] Modelling random effects for only part of the
 observations (in lme4)
Message-ID: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9F9@BGO-MCS005.ihelse.net>

Jarrod Hadfield  wrote:
> Create a binary vector (lets call it b) with 0 for observations where
> you don't want random effects and a 1 where you do. Then fit:
> 
> (b|group)

Thank you for the suggestion. I have now tried it, but can't get it to work. I do get a variety of error messages, depending on how I create the 'group' variable, though. :)

These are the errors/warnings: Either (with group = gr1 in code below)

?????????????
Error: number of observations (=100) <= number of random effects (=134) for term (b | gr); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable
?????????????

or (with group = gr2 in code below)

?????????????
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?
?????????????

or (with group = gr3 in code below)

?????????????
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
  contrasts can be applied only to factors with 2 or more levels
?????????????

Here's some example code. The simulation is based on an assumption that belonging to a (treatment) group *adds* a random effect, i.e., it adds to the total subject error (so that the *residual* error is identical in both arms). I guess it could be argued that a model where the total *subject error* was identical in the two arms, and belonging to a group would only add intragroup correlation, would also be reasonable. I'm not sure which model is most realistic.


mu = 10                       # Average level in control group
treat = 5                     # Treatment effect (additive)
n = 100                       # Number of individuals
prop.treat = .5               # Treatment proportion
n.treat = round(n*prop.treat) # Number in control group
n.contr = n - n.treat         # Number in treatment group
grsize = 3                    # Group size (fixed, but could be random)
sigeps = 3                    # Residual standard deviation
siggrp = 1                    # Group standard deviation

# Set up treatment factor
arm = factor(c(rep("treatment", n.treat), rep("control", n.contr)))

# Create observations
y = rnorm(n, mu, sd = sigeps)
y[arm=="treatment"] = y[arm=="treatment"] + treat +
                      rep(rnorm(ceiling(n.treat/3), 0, siggrp),
                          each=grsize)[1:n.treat]

# Create group (with control subjects each having a unique group)
gr = c(rep(1:ceiling(n.treat/3), each=3)[1:n.treat], (n.treat+1):n)

# Create group (with control subjects sharing a group)
gr2 = gr
gr2[(n.treat+1):n] = 0

# Create group (with control subjects having group value NA)
gr3=gr2
gr3[gr3==0]=NA

# Convert group variables to factors
gr = factor(gr)
gr2 = factor(gr2)
gr3 = factor(gr3)

# Correct (?) random effects model
b = as.numeric(arm) - 1 # Equal to 1 for random effect and 0 for no random effect
table(b, arm)

# Try to fit lme4 models
library(lme4)
lmer(y ~ arm + (b|gr))
lmer(y ~ arm + (b|gr2))
lmer(y ~ arm + (b|gr3))

-- 
Karl Ove Hufthammer


From Thierry.ONKELINX at inbo.be  Fri Jan 16 10:16:01 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 16 Jan 2015 09:16:01 +0000
Subject: [R-sig-ME] Modelling random effects for only part of the
 observations (in lme4)
In-Reply-To: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9F9@BGO-MCS005.ihelse.net>
References: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9F9@BGO-MCS005.ihelse.net>
Message-ID: <AA818EAD2576BC488B4F623941DA742701096F9323@inbomail.inbo.be>

Dear Karl Ove,

(X|G) is equivalent to (1 + X|G). Or mathematically: b_0i + b_1iX. But you need b_1iX.

The solution is to remove the random intercept (0 + X|G)

I would go for lmer(y ~ arm + (0 + b|gr2))

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens Hufthammer, Karl Ove [karl.ove.hufthammer at helse-bergen.no]
Verzonden: vrijdag 16 januari 2015 9:36
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Modelling random effects for only part of the observations (in lme4)

Jarrod Hadfield  wrote:
> Create a binary vector (lets call it b) with 0 for observations where
> you don't want random effects and a 1 where you do. Then fit:
>
> (b|group)

Thank you for the suggestion. I have now tried it, but can't get it to work. I do get a variety of error messages, depending on how I create the 'group' variable, though. :)

These are the errors/warnings: Either (with group = gr1 in code below)

?????????????
Error: number of observations (=100) <= number of random effects (=134) for term (b | gr); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable
?????????????

or (with group = gr2 in code below)

?????????????
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?
?????????????

or (with group = gr3 in code below)

?????????????
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels
?????????????

Here's some example code. The simulation is based on an assumption that belonging to a (treatment) group *adds* a random effect, i.e., it adds to the total subject error (so that the *residual* error is identical in both arms). I guess it could be argued that a model where the total *subject error* was identical in the two arms, and belonging to a group would only add intragroup correlation, would also be reasonable. I'm not sure which model is most realistic.


mu = 10                       # Average level in control group
treat = 5                     # Treatment effect (additive)
n = 100                       # Number of individuals
prop.treat = .5               # Treatment proportion
n.treat = round(n*prop.treat) # Number in control group
n.contr = n - n.treat         # Number in treatment group
grsize = 3                    # Group size (fixed, but could be random)
sigeps = 3                    # Residual standard deviation
siggrp = 1                    # Group standard deviation

# Set up treatment factor
arm = factor(c(rep("treatment", n.treat), rep("control", n.contr)))

# Create observations
y = rnorm(n, mu, sd = sigeps)
y[arm=="treatment"] = y[arm=="treatment"] + treat +
                      rep(rnorm(ceiling(n.treat/3), 0, siggrp),
                          each=grsize)[1:n.treat]

# Create group (with control subjects each having a unique group)
gr = c(rep(1:ceiling(n.treat/3), each=3)[1:n.treat], (n.treat+1):n)

# Create group (with control subjects sharing a group)
gr2 = gr
gr2[(n.treat+1):n] = 0

# Create group (with control subjects having group value NA)
gr3=gr2
gr3[gr3==0]=NA

# Convert group variables to factors
gr = factor(gr)
gr2 = factor(gr2)
gr3 = factor(gr3)

# Correct (?) random effects model
b = as.numeric(arm) - 1 # Equal to 1 for random effect and 0 for no random effect
table(b, arm)

# Try to fit lme4 models
library(lme4)
lmer(y ~ arm + (b|gr))
lmer(y ~ arm + (b|gr2))
lmer(y ~ arm + (b|gr3))

--
Karl Ove Hufthammer

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From karl.ove.hufthammer at helse-bergen.no  Fri Jan 16 10:37:43 2015
From: karl.ove.hufthammer at helse-bergen.no (Hufthammer, Karl Ove)
Date: Fri, 16 Jan 2015 10:37:43 +0100
Subject: [R-sig-ME] Modelling random effects for only part of the
 observations (in lme4)
Message-ID: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9FA@BGO-MCS005.ihelse.net>

Thierry ONKELINX wrote:
> Dear Karl Ove,
>
> (X|G) is equivalent to (1 + X|G). Or mathematically: b_0i + b_1iX. But you need b_1iX.
> 
> The solution is to remove the random intercept (0 + X|G)
> 
> I would go for lmer(y ~ arm + (0 + b|gr2))

Great! Thanks. This works perfectly.

And I now understand what's going on in the formula too. The lme4 syntax is rather elegant. :)

The fixed effect estimates are near identical to estimates based on lm(y ~ arm), while the standard errors are different, which is exactly what would be expected. The reason they're not exactly identical is that one treatment group had only 2 subjects, so the design was not perfectly balanced. If I change it to a balanced design (equal number of subjects in each treatment group), the estimates are identical between lmer and lm (while of course the standard errors still differ).

-- 
Karl Ove Hufthammer


From bbolker at gmail.com  Fri Jan 16 15:14:53 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 16 Jan 2015 09:14:53 -0500
Subject: [R-sig-ME] Modelling random effects for only part of the
 observations (in lme4)
In-Reply-To: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9FA@BGO-MCS005.ihelse.net>
References: <0D0C1D497D86144EA6BD73E47CDB64CA11AF69C9FA@BGO-MCS005.ihelse.net>
Message-ID: <54B91CDD.7030403@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-01-16 04:37 AM, Hufthammer, Karl Ove wrote:
> Thierry ONKELINX wrote:
>> Dear Karl Ove,
>> 
>> (X|G) is equivalent to (1 + X|G). Or mathematically: b_0i +
>> b_1iX. But you need b_1iX.
>> 
>> The solution is to remove the random intercept (0 + X|G)
>> 
>> I would go for lmer(y ~ arm + (0 + b|gr2))
> 
> Great! Thanks. This works perfectly.
> 
> And I now understand what's going on in the formula too. The lme4 
> syntax is rather elegant. :)

  Can we quote you on that?

  :-)

> 
> The fixed effect estimates are near identical to estimates based
> on lm(y ~ arm), while the standard errors are different, which is 
> exactly what would be expected. The reason they're not exactly 
> identical is that one treatment group had only 2 subjects, so the 
> design was not perfectly balanced. If I change it to a balanced 
> design (equal number of subjects in each treatment group), the 
> estimates are identical between lmer and lm (while of course the 
> standard errors still differ).
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUuRzdAAoJEOCV5YRblxUHm0wH/13AiAPnPkVMUQkU2dUYQF/p
JFjg9bAyBx29BviAJk9kfxxgHcKBTM+mdDrPRrmqwmZXTu6cyuw10VRiwVNsap3s
7h8qd5MnxGFuUUho8cTpHPzgunEHtQu85lFctqEGuSXTmOxOSvL9hCkWl3m7jTLw
it79ZuuBG3sO1L96z/nZ/MqRqiubOL3afc14TpW2Bmt3OQjMYWx5bT4bKNIY10/s
l3wRoLI4pTjgTVflrH1d+gLBizsyiaX84sPY+OWshv9XCaEZuN0CoxtVvc0tkqoD
z3kWyt32LRzELtWNhAm3jUEDK6EK46F5/22XnC3KBfcMlxfZxpVW85mIX5S6UZM=
=mTY9
-----END PGP SIGNATURE-----


From jrmorrongiello at gmail.com  Sun Jan 18 05:56:16 2015
From: jrmorrongiello at gmail.com (John Morrongiello)
Date: Sun, 18 Jan 2015 15:56:16 +1100
Subject: [R-sig-ME] priors for multivariate mixed model in MCMCglmm with
 random intercepts and slopes
Message-ID: <CAPTgL1aFMeQN7-SAtL8_pySr-TRXKmgrxmGpZc8WxHuyAPDw0g@mail.gmail.com>

Hi
I've got a data set with 7 response variables measured monthly through time
across 38 individuals (FishID). There are 124 months (MonthCode)
representing each sampling time, with the data set having 1021 observations
in total. I have previously analysed this data using a series of univariate
mixed models fitted in lme4 of the form

m1<-lmer(AvGrowth~ Age + (Age|FishID) + (Age|MonthCode), data=alldata1)
.....mx<-lmer(.....)

Here, Age is a continuous covariate that models an age-dependent decline in
growth; the slope of this relationship allowed to vary amongst individuals
(FishID) and through time (MonthCode). To this model structure I have also
added environmental effects like temperature etc.

As the 7 response variables are all measured at the same time from each
fish (they are estimates of growth and otolith microchemistry), I thought
to fit a multivariate mixed model to estimate covariances and also
succinctly ascertain the importance of various environmental effects.

I have had success fitting m2 below where the overall model intercept is
suppressed and the trait-dependent iAge effect is allowed to vary by
individual and MonthCode (similar to m1):

prior1<-list(R=list(V=diag(7),nu=7),G=list(G1=list(V=diag(7),nu=7),G2=list(V=diag(7),nu=7)))

m2<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
~(trait + trait:Age -1),
random=~us(trait:Age):FishID + us(trait:Age):MonthCode,
rcov=~us(trait):units,
family=rep("gaussian",7), prior=prior1,
nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)

When I use posterior.mode(m2$VCV) however, I don't get estimates of the
random intercept terms FishID and MonthCode, nor their covariance with Age,
rather just variances dependent on the iAge slope (e.g.
AvGrowth.std:Age):AvGrowth.std:Age).FishID). I therefore tried to
explicitly code a correlated random intercept and slope using us(1+
trait:(Age):FishID in m3:

m3<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
~(trait + trait:Age -1),
random=~us(1+ trait:Age):FishID + us(1+ trait:Age):MonthCode,
rcov=~us(trait):units,
family=rep("gaussian",7), prior=prior1,
nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)

This returns the error:
Error in priorformat(if (NOpriorG) { :  V is the wrong dimension for some
prior$G/prior$R elements

So I'm tipping something is wrong with my priors. m4, where I estimate an
overall model intercept and specific random intercepts also returns the
same error.

m4<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
~(trait + trait:Age +1),
random=~us(1+ trait:Age):FishID + us(1+ trait:Age):MonthCode,
rcov=~us(trait):units,
family=rep("gaussian",7), prior=prior1,
nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)

Would someone have some tips about how to get the priors for m3 and m4
working? I've worked through the course notes and read some email posts,
but admit that I a little at sea in terms of understanding the specifics of
what is being coded on the prior side of things.

Cheers

John

	[[alternative HTML version deleted]]


From stan.aggerwal at gmail.com  Mon Jan 19 15:12:58 2015
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Mon, 19 Jan 2015 14:12:58 +0000
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
Message-ID: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>

I am trying to figure out mixed models using a simulated example.

I get the essentially the same parameter values and SEs whether I do:
1. lm() ignoring the within subjects nature of the expt
2. lmer()
3. fit a line to each subject's data and find mean and SE of parameters
across subjects

At this point, my feeling is I should just do (1) or possibly (3) above.
Please tell me why I should do anything else. Maybe my example is somehow
weird? It is typical of expts I deal with.

- cond is a factor with levels a, b, and c
- x is a continuous indep var
- each condition has slope and intercept
- each subject receives all conditions; each subject has own slope
and intercept randomly varying about population value

==========================

set.seed(1234)
nsubj<-30
z<-expand.grid(x=1:5,cond=c("a","b","c"),subj=as.factor(1:nsubj))
x<-z$x
cond<-z$cond
subj<-z$subj

a1<- rep(1+rnorm(nsubj,mean=0,sd=.1),5)  #inta=1
a2<- rep(1+rnorm(nsubj,mean=0,sd=.1),5)  #intb-inta=2-1=1
a3<- rep(2+rnorm(nsubj,mean=0,sd=.1),5)  #intc-inta=3-1=2
a4<- rep(3+rnorm(nsubj,mean=0,sd=.1),5)  #slopea=3
a5<- rep(-1+rnorm(nsubj,mean=0,sd=.1),5) #slopeb-slopea
a6<- rep(-2+rnorm(nsubj,mean=0,sd=.1),5) #slopec-slopea

y<- (cond=="a")*(a1 + a4*x) + (cond=="b")*(a1+a2 + (a4+a5)*x) +
  (cond=="c")*(a1+a3 + (a4+a6)*x) + rnorm(5*3*nsubj,mean=0,sd=.5)

#### ignore within subjects design and treat as independent errors
fit1<-lm(y~cond*x)
summary(fit)

## mixed model using lmer()
library(lme4)
fit2<-lmer(y~x*cond + (x*cond|subj))
summary(fit2)

## lme from nlme package
library(nlme)
fit3<-lme(y~x*cond, random=~(x*cond)|subj)
#does not converge

##fit line to each subject; get mean and se of params across subjects
beta<-matrix(0,ncol=6,nrow=nsubj)
for(i in 1:nsubj)
  {
  f<-lm(y[subj==i]~cond[subj==i]*x[subj==i])
  beta[i,]<-coef(f)
  }

colMeans(beta)
apply(beta,2,sd)/sqrt(nsubj)
# 0.9730283  0.3577780  1.8709841  3.0270420 -0.8013505 -1.9840602
# 0.10121264 0.17860228 0.15895837 0.02820369 0.04765495 0.03834946

======================

This last method makes the most sense to me. Getting 95% CIs and p-values
for the params would be straightforward.

Thanks very much for your help.

Stan

	[[alternative HTML version deleted]]


From holtermann at hwwi.org  Mon Jan 19 18:39:52 2015
From: holtermann at hwwi.org (Linus Holtermann)
Date: Mon, 19 Jan 2015 18:39:52 +0100
Subject: [R-sig-ME] Comparison of crossed ranom effects: lmer vs. MCMCglmm
Message-ID: <AD0050057515F54084E7D5B93478C8481FC6620781@winxbede39.exchange.xchg>

Hello,

I read that lmer can handle independent (often labelled as crossed) random effets in mixed models. It seems to be possible with MCMCglmm as long as groups for the random effects are uniquely labelled. I use the "Penicllin" data in the lme4-package to compare both approaches:

library(lme4)
library(MCMCglmm)

str(Penicillin)
attach(Penicillin)

ml <- lmer(diameter~ 1 + (1|plate)+ (1|sample))
summary(ml)

mcmc <- MCMCglmm(diameter~ 1, random=~ plate + sample,verbose=F, nitt=110000,burn=10000,thin=10,data=Penicillin)
summary(mcmc)

Why are the result for the plate-variance differ by a large amount? Is it because MCMCglmm applies Gibbs sampling? Or is MCMCglmm doing something else here, instead of fitting independent random effects?


Best regards,


Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org
 
Amtsgericht Hamburg HRB 94303
Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
Prokura: Dipl. Kauffrau Alexis Malchin
Umsatzsteuer-ID: DE 241849425

From j.hadfield at ed.ac.uk  Mon Jan 19 19:25:44 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 19 Jan 2015 18:25:44 +0000
Subject: [R-sig-ME] Comparison of crossed ranom effects: lmer vs.
 MCMCglmm
In-Reply-To: <AD0050057515F54084E7D5B93478C8481FC6620781@winxbede39.exchange.xchg>
References: <AD0050057515F54084E7D5B93478C8481FC6620781@winxbede39.exchange.xchg>
Message-ID: <20150119182544.14745jtkn3x3n7cw@www.staffmail.ed.ac.uk>

Hi Linus,

The point estimates are almost identical if the posterior mode is used:

hist(mcmc$VCV[,"plate"], breaks=30)

abline(v=VarCorr(ml)[["plate"]][1], col="red")

The posterior mean (which is reported in the summary) is often not a  
good measure of central tendency for variance components because of  
the skew. Posterior modes have high Monte Carlo error though.

Cheers,

Jarrod




Quoting Linus Holtermann <holtermann at hwwi.org> on Mon, 19 Jan 2015  
18:39:52 +0100:

> Hello,
>
> I read that lmer can handle independent (often labelled as crossed)  
> random effets in mixed models. It seems to be possible with MCMCglmm  
> as long as groups for the random effects are uniquely labelled. I  
> use the "Penicllin" data in the lme4-package to compare both  
> approaches:
>
> library(lme4)
> library(MCMCglmm)
>
> str(Penicillin)
> attach(Penicillin)
>
> ml <- lmer(diameter~ 1 + (1|plate)+ (1|sample))
> summary(ml)
>
> mcmc <- MCMCglmm(diameter~ 1, random=~ plate + sample,verbose=F,  
> nitt=110000,burn=10000,thin=10,data=Penicillin)
> summary(mcmc)
>
> Why are the result for the plate-variance differ by a large amount?  
> Is it because MCMCglmm applies Gibbs sampling? Or is MCMCglmm doing  
> something else here, instead of fitting independent random effects?
>
>
> Best regards,
>
>
> Linus Holtermann
> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
> Heimhuder Stra?e 71
> 20148 Hamburg
> Tel +49-(0)40-340576-336
> Fax+49-(0)40-340576-776
> Internet: www.hwwi.org
> Email: holtermann at hwwi.org
>
> Amtsgericht Hamburg HRB 94303
> Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
> Prokura: Dipl. Kauffrau Alexis Malchin
> Umsatzsteuer-ID: DE 241849425
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From holtermann at hwwi.org  Tue Jan 20 10:50:41 2015
From: holtermann at hwwi.org (Linus Holtermann)
Date: Tue, 20 Jan 2015 10:50:41 +0100
Subject: [R-sig-ME] Comparison of crossed ranom effects: lmer vs.
 MCMCglmm
In-Reply-To: <20150119182544.14745jtkn3x3n7cw@www.staffmail.ed.ac.uk>
References: <AD0050057515F54084E7D5B93478C8481FC6620781@winxbede39.exchange.xchg>,
	<20150119182544.14745jtkn3x3n7cw@www.staffmail.ed.ac.uk>
Message-ID: <AD0050057515F54084E7D5B93478C8481FC6620782@winxbede39.exchange.xchg>

Thanks Jarrod. 
Just to be on the safe side, MCMCglmm indeed fits two independent random effects in the "mcmc"-specification? The different results emerge because the MCMC-Approach treat the variance components as random variables that capture more of the skewness?  It is often claimed that mixed models fitted via Maximum Likelihood underestimate the random effect variance.


Best regards,


Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org

Amtsgericht Hamburg HRB 94303
Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
Prokura: Dipl. Kauffrau Alexis Malchin
Umsatzsteuer-ID: DE 241849425
________________________________________
Von: Jarrod Hadfield [j.hadfield at ed.ac.uk]
Gesendet: Montag, 19. Januar 2015 19:25
An: Linus Holtermann
Cc: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Comparison of crossed ranom effects: lmer vs. MCMCglmm

Hi Linus,

The point estimates are almost identical if the posterior mode is used:

hist(mcmc$VCV[,"plate"], breaks=30)

abline(v=VarCorr(ml)[["plate"]][1], col="red")

The posterior mean (which is reported in the summary) is often not a
good measure of central tendency for variance components because of
the skew. Posterior modes have high Monte Carlo error though.

Cheers,

Jarrod




Quoting Linus Holtermann <holtermann at hwwi.org> on Mon, 19 Jan 2015
18:39:52 +0100:

> Hello,
>
> I read that lmer can handle independent (often labelled as crossed)
> random effets in mixed models. It seems to be possible with MCMCglmm
> as long as groups for the random effects are uniquely labelled. I
> use the "Penicllin" data in the lme4-package to compare both
> approaches:
>
> library(lme4)
> library(MCMCglmm)
>
> str(Penicillin)
> attach(Penicillin)
>
> ml <- lmer(diameter~ 1 + (1|plate)+ (1|sample))
> summary(ml)
>
> mcmc <- MCMCglmm(diameter~ 1, random=~ plate + sample,verbose=F,
> nitt=110000,burn=10000,thin=10,data=Penicillin)
> summary(mcmc)
>
> Why are the result for the plate-variance differ by a large amount?
> Is it because MCMCglmm applies Gibbs sampling? Or is MCMCglmm doing
> something else here, instead of fitting independent random effects?
>
>
> Best regards,
>
>
> Linus Holtermann
> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
> Heimhuder Stra?e 71
> 20148 Hamburg
> Tel +49-(0)40-340576-336
> Fax+49-(0)40-340576-776
> Internet: www.hwwi.org
> Email: holtermann at hwwi.org
>
> Amtsgericht Hamburg HRB 94303
> Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
> Prokura: Dipl. Kauffrau Alexis Malchin
> Umsatzsteuer-ID: DE 241849425
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From mtoncic at ffri.hr  Tue Jan 20 14:24:31 2015
From: mtoncic at ffri.hr (marKo)
Date: Tue, 20 Jan 2015 14:24:31 +0100
Subject: [R-sig-ME] time delayed response as a covariate in lme4
Message-ID: <54BE570F.707@ffri.hr>

I have a dataset which have a continuous outcome variable and a time 
(chron) covariate for 99 subjects (id). To get an idea:

 > str(dataframe)
'data.frame':   36352 obs. of  9 variables:
   $ response  : int  100 79 63 50 71 73 62 72 76 77 ...
  $ id   : Factor w/ 99 levels "g1_1","g1_12",..: 2 2 2 2 2 2 2 2 2 2 ...
  $ time   :Classes 'chron', 'dates', 'times'  atomic [1:36352] 15875 
15875 15875 15875 15875 ...
   .. ..- attr(*, "format")= Named chr [1:2] "m/d/y" "h:m:s"
   .. .. ..- attr(*, "names")= chr [1:2] "dates" "times"
   .. ..- attr(*, "origin")= Named num [1:3] 1 1 1970
   .. .. ..- attr(*, "names")= chr [1:3] "month" "day" "year"

I would like to use the time delayed response as a predictor/covariate. 
Lets say a would like to use response at time-1 as a covariate. How can 
this be done?

Something like (conceptually):

model<-lmer(response~poly(time, n) + response(time -1) + (poly(time, 
n)|id, data=dataframe)

I suppose that I could use some correlation structure for this (in nlme, 
because I think that lme4 do not support this a this stage), although 
I'd rather do this in lme4.

Any ideas?

Cheers (and thanks),

Marko

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jan 20 15:07:01 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 20 Jan 2015 09:07:01 -0500
Subject: [R-sig-ME] time delayed response as a covariate in lme4
In-Reply-To: <54BE570F.707@ffri.hr>
References: <54BE570F.707@ffri.hr>
Message-ID: <54BE6105.6090903@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-01-20 08:24 AM, marKo wrote:
> I have a dataset which have a continuous outcome variable and a
> time (chron) covariate for 99 subjects (id). To get an idea:
> 
>> str(dataframe)
> 'data.frame':   36352 obs. of  9 variables: $ response  : int  100
> 79 63 50 71 73 62 72 76 77 ... $ id   : Factor w/ 99 levels
> "g1_1","g1_12",..: 2 2 2 2 2 2 2 2 2 2 ... $ time   :Classes
> 'chron', 'dates', 'times'  atomic [1:36352] 15875 15875 15875 15875
> 15875 ... .. ..- attr(*, "format")= Named chr [1:2] "m/d/y"
> "h:m:s" .. .. ..- attr(*, "names")= chr [1:2] "dates" "times" ..
> ..- attr(*, "origin")= Named num [1:3] 1 1 1970 .. .. ..- attr(*,
> "names")= chr [1:3] "month" "day" "year"
> 
> I would like to use the time delayed response as a
> predictor/covariate. Lets say a would like to use response at
> time-1 as a covariate. How can this be done?
> 
> Something like (conceptually):
> 
> model<-lmer(response~poly(time, n) + response(time -1) +
> (poly(time, n)|id, data=dataframe)
> 
> I suppose that I could use some correlation structure for this (in
> nlme, because I think that lme4 do not support this a this stage),
> although I'd rather do this in lme4.

  The standard way to do this in R is to shift the variable by
creating a shifted response variable that is NA in the first row
(because we don't know the response before the observations started)
and runs from 1 to (nobs-1), e.g.

  dataframe <- transform(dataframe,
    shiftresp=c(NA,response[1:(nrow(dataframe)-1)])

You can also use c(NA,head(response,-1)) for this although it may be
less transparent.

  I might suggest transforming your chron response to an explicit
numeric variable -- it might be more transparent (e.g. do you want
your covariate scale to be in response per second?)


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUvmEFAAoJEOCV5YRblxUH3BsIAM2S1IFo7hraXTP+gHk1vAG6
vla9p8pjYCYaBlnVVc3zdLXJZP1+BhlXh6A/LTuU1rnc0e4O9yQwW5JM+SqVdDua
Ur3XhMnR+n/PUvJyaoSQ92fFv9rpgP/JtDf36Om2VLodLNVBnWxUrSnnTnd/QeE4
hUv79mGE/RqbueP0H8YwcNAmNmZR/iMd+uC2nYli9Viv42Fk6lE/oNs13wW5AiOT
BytB45z0rX5qesjam+HY9UX+0dejSV5ldRN8fQ9SJPSMddDZzny5KIbmdgho6lxc
0N4suZXIfztU56IbAYJDDwCZmE7Vuv3rkMSci1jY6UbaYCihW86V9BYzK3QTZ+I=
=h/4l
-----END PGP SIGNATURE-----


From mtoncic at ffri.hr  Tue Jan 20 17:04:19 2015
From: mtoncic at ffri.hr (marKo)
Date: Tue, 20 Jan 2015 17:04:19 +0100
Subject: [R-sig-ME] time delayed response as a covariate in lme4
In-Reply-To: <54BE6105.6090903@gmail.com>
References: <54BE570F.707@ffri.hr> <54BE6105.6090903@gmail.com>
Message-ID: <54BE7C83.9010701@ffri.hr>

On 01/20/2015 03:07 PM, Ben Bolker wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-01-20 08:24 AM, marKo wrote:
>> I have a dataset which have a continuous outcome variable and a
>> time (chron) covariate for 99 subjects (id). To get an idea:
>>
>>> str(dataframe)
>> 'data.frame':   36352 obs. of  9 variables: $ response  : int  100
>> 79 63 50 71 73 62 72 76 77 ... $ id   : Factor w/ 99 levels
>> "g1_1","g1_12",..: 2 2 2 2 2 2 2 2 2 2 ... $ time   :Classes
>> 'chron', 'dates', 'times'  atomic [1:36352] 15875 15875 15875 15875
>> 15875 ... .. ..- attr(*, "format")= Named chr [1:2] "m/d/y"
>> "h:m:s" .. .. ..- attr(*, "names")= chr [1:2] "dates" "times" ..
>> ..- attr(*, "origin")= Named num [1:3] 1 1 1970 .. .. ..- attr(*,
>> "names")= chr [1:3] "month" "day" "year"
>>
>> I would like to use the time delayed response as a
>> predictor/covariate. Lets say a would like to use response at
>> time-1 as a covariate. How can this be done?
>>
>> Something like (conceptually):
>>
>> model<-lmer(response~poly(time, n) + response(time -1) +
>> (poly(time, n)|id, data=dataframe)
>>
>> I suppose that I could use some correlation structure for this (in
>> nlme, because I think that lme4 do not support this a this stage),
>> although I'd rather do this in lme4.
>    The standard way to do this in R is to shift the variable by
> creating a shifted response variable that is NA in the first row
> (because we don't know the response before the observations started)
> and runs from 1 to (nobs-1), e.g.
>
>    dataframe <- transform(dataframe,
>      shiftresp=c(NA,response[1:(nrow(dataframe)-1)])
>
> You can also use c(NA,head(response,-1)) for this although it may be
> less transparent.
>
>    I might suggest transforming your chron response to an explicit
> numeric variable -- it might be more transparent (e.g. do you want
> your covariate scale to be in response per second?)
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJUvmEFAAoJEOCV5YRblxUH3BsIAM2S1IFo7hraXTP+gHk1vAG6
> vla9p8pjYCYaBlnVVc3zdLXJZP1+BhlXh6A/LTuU1rnc0e4O9yQwW5JM+SqVdDua
> Ur3XhMnR+n/PUvJyaoSQ92fFv9rpgP/JtDf36Om2VLodLNVBnWxUrSnnTnd/QeE4
> hUv79mGE/RqbueP0H8YwcNAmNmZR/iMd+uC2nYli9Viv42Fk6lE/oNs13wW5AiOT
> BytB45z0rX5qesjam+HY9UX+0dejSV5ldRN8fQ9SJPSMddDZzny5KIbmdgho6lxc
> 0N4suZXIfztU56IbAYJDDwCZmE7Vuv3rkMSci1jY6UbaYCihW86V9BYzK3QTZ+I=
> =h/4l
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Thanks for your reply Ben.

I thought that it might be something like that. I have another problem 
in that area, because I actually have two response variable (something 
like y and z coordinates) and, since they are on the same scale, I am 
trying to fit a models to the outcome conditional to the response 
coordinates.
To make it mode clear:

response    response_id    time    id
r1x    x    t1    1
r1z    z    t1    1
r2x    x    t2    1
r2z    z    t2    1
?.

so the model actually looks something like that:

model<-lmer(response~response_id*poly(time, n)+(response_id*poly(time, 
n)|id), data=dataset).

My hope was that it can be done in some other way just to avoid 
potential errors that might occur when fiddling with transpositions like 
the one suggested (different number of observations per id and 
potentially missing x or y coordinate).
As for the chron object, since I'm trying to fit a polynomial, I have 
rescaled the time in a numeric form from 0 to 1 (the time is actually od 
the form YYYY/MM/DD HH:MM:SS an the span is of 3 weeks, but I am only 
interested in daily variation. So the beginning of the day is 0 and the 
end 1). The polynomial have a much more simple behavior in that range.


From stan.aggerwal at gmail.com  Wed Jan 21 09:16:06 2015
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Wed, 21 Jan 2015 08:16:06 +0000
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
In-Reply-To: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
References: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
Message-ID: <CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>

I will attempt an answer to my own question. Possibly the reason I got the
same answer with the 3 methods is that my simulation was wrong. It
simulated the responses as:

y<- (cond=="a")*(a1 + a4*x) + (cond=="b")*(a1+a2 + (a4+a5)*x) +
  (cond=="c")*(a1+a3 + (a4+a6)*x) + rnorm(5*3*nsubj,mean=0,sd=.5)

This contains the intercepts and slopes which are unique to each subject
and randomly sampled from some population values. However the term:
rnorm(5*3*nsubj,mean=0,sd=.5)
is wrong because it says the errors are independent. Instead they should be
correlated within each subject.

I will give that a go.

Stan

	[[alternative HTML version deleted]]


From mtoncic at ffri.hr  Wed Jan 21 09:30:24 2015
From: mtoncic at ffri.hr (marKo)
Date: Wed, 21 Jan 2015 09:30:24 +0100
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
In-Reply-To: <CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
References: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
	<CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
Message-ID: <54BF63A0.5000604@ffri.hr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I think that you have correctly identified the problem.

Cheers,

Marko



On 01/21/2015 09:16 AM, Stanislav Aggerwal wrote:
> I will attempt an answer to my own question. Possibly the reason I
> got the same answer with the 3 methods is that my simulation was
> wrong. It simulated the responses as:
> 
> y<- (cond=="a")*(a1 + a4*x) + (cond=="b")*(a1+a2 + (a4+a5)*x) + 
> (cond=="c")*(a1+a3 + (a4+a6)*x) + rnorm(5*3*nsubj,mean=0,sd=.5)
> 
> This contains the intercepts and slopes which are unique to each
> subject and randomly sampled from some population values. However
> the term: rnorm(5*3*nsubj,mean=0,sd=.5) is wrong because it says
> the errors are independent. Instead they should be correlated
> within each subject.
> 
> I will give that a go.
> 
> Stan
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAEBAgAGBQJUv2OgAAoJEJcj4KySkkQsUbgP/jhOyGuwPpAyS8I6uFElxztg
sQdiGeUaVKjutcJJsHisezEcRxcf84k09hWnR1bnc/fuFQgDqS58qnoUa2JJqiZh
BrnCjIV7Cj///DLC0MLzyzvmZLq21medi6vdUwdAF5gc1GOJHoA9IWgoEACucqEc
SbpWiaqUWpNK2rCOZ3crTEBZNHEHO72qKBq670L5zDTfRfx4IXsjGMyY68Lf/Tz/
jECjDGM3byO2pw5KginLWl3hA+0ChcKNNmti3rY8p9JVZ8c4iEDrT0Hjvx/VN8zn
JPcRSJFR263haozcENATtAgUmBCT66j+IfB/7aQgAOthTdEWWjtnnnVxTbDvBkik
tVB617PXdUL5l7kcmxZYcwiigOQerJrEDcUhoL8SMtL54JluWg9MZIZxXmjGHMlm
mtrvbv6rfU3XzB80ck8zm6SSgPwP1IYoqJZ7QWBx0XTuU057tjyG8rA6F/jkYc3t
Uoe0NwY1Ox9Q62paJQ4sysyf2dgyW2RYRVVQuK1UjlH9ZfmETtq36J6yyEXjuhir
ztVsKeofNgRKo4FrmhcOLcBPofzQBnzTI1RjuqCxcbt9vsr4Wwn1uvup20OqDYb7
VKbzoKr8HR26YDS7Oc3vUiOzjszNEALnKAWFoUfW/BQRQGzIZl0lR1g52SzRphL5
u/shRpd5ZYjTJUgT9IQ+
=/B+Q
-----END PGP SIGNATURE-----


From j.hadfield at ed.ac.uk  Wed Jan 21 10:41:22 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 21 Jan 2015 09:41:22 +0000
Subject: [R-sig-ME] Comparison of crossed ranom effects: lmer vs.
 MCMCglmm
In-Reply-To: <AD0050057515F54084E7D5B93478C8481FC6620782@winxbede39.exchange.xchg>
References: <AD0050057515F54084E7D5B93478C8481FC6620781@winxbede39.exchange.xchg>,
	<20150119182544.14745jtkn3x3n7cw@www.staffmail.ed.ac.uk>
	<AD0050057515F54084E7D5B93478C8481FC6620782@winxbede39.exchange.xchg>
Message-ID: <20150121094122.200181t4tlp8a88y@www.staffmail.ed.ac.uk>

Hi,

Yes, MCMCglmm fits two independent random effects.

Bayesian approaches treat the variance components as random variables,  
and MCMC allows you to estimate their distribution. In general that  
distribution is not known, but if the response is Gaussian, the prior  
conjugate, and all fixed effects known, then the distribution is  
scaled inverse-Chi-squared. This distribution is skewed, particularly  
with low degrees of freedom.

(RE)ML does not posit a distribution for the variance components, it  
simply finds the variance components that maximise the (restricted)  
likelihood. Sometimes an approximate distribution for the *estimates*  
of the variance components is posited: usually normal with mean equal  
to the (RE)ML estimates. This approximation is based on high-n, but in  
reality the sampling distribution will rarely be normal and will also  
have skew.

The underestimation of the variance components via Maximum Likelihood  
is a separate issue. This arises because the deviation of observations  
from the estimated mean will always be smaller than the deviation of  
observations from the true mean. REML corrects for this by accounting  
for the uncertainty in estimated mean.

Cheers,

Jarrod





Quoting Linus Holtermann <holtermann at hwwi.org> on Tue, 20 Jan 2015  
10:50:41 +0100:

> Thanks Jarrod.
> Just to be on the safe side, MCMCglmm indeed fits two independent  
> random effects in the "mcmc"-specification? The different results  
> emerge because the MCMC-Approach treat the variance components as  
> random variables that capture more of the skewness?  It is often  
> claimed that mixed models fitted via Maximum Likelihood  
> underestimate the random effect variance.
>
>
> Best regards,
>
>
> Linus Holtermann
> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
> Heimhuder Stra?e 71
> 20148 Hamburg
> Tel +49-(0)40-340576-336
> Fax+49-(0)40-340576-776
> Internet: www.hwwi.org
> Email: holtermann at hwwi.org
>
> Amtsgericht Hamburg HRB 94303
> Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
> Prokura: Dipl. Kauffrau Alexis Malchin
> Umsatzsteuer-ID: DE 241849425
> ________________________________________
> Von: Jarrod Hadfield [j.hadfield at ed.ac.uk]
> Gesendet: Montag, 19. Januar 2015 19:25
> An: Linus Holtermann
> Cc: r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] Comparison of crossed ranom effects: lmer  
> vs. MCMCglmm
>
> Hi Linus,
>
> The point estimates are almost identical if the posterior mode is used:
>
> hist(mcmc$VCV[,"plate"], breaks=30)
>
> abline(v=VarCorr(ml)[["plate"]][1], col="red")
>
> The posterior mean (which is reported in the summary) is often not a
> good measure of central tendency for variance components because of
> the skew. Posterior modes have high Monte Carlo error though.
>
> Cheers,
>
> Jarrod
>
>
>
>
> Quoting Linus Holtermann <holtermann at hwwi.org> on Mon, 19 Jan 2015
> 18:39:52 +0100:
>
>> Hello,
>>
>> I read that lmer can handle independent (often labelled as crossed)
>> random effets in mixed models. It seems to be possible with MCMCglmm
>> as long as groups for the random effects are uniquely labelled. I
>> use the "Penicllin" data in the lme4-package to compare both
>> approaches:
>>
>> library(lme4)
>> library(MCMCglmm)
>>
>> str(Penicillin)
>> attach(Penicillin)
>>
>> ml <- lmer(diameter~ 1 + (1|plate)+ (1|sample))
>> summary(ml)
>>
>> mcmc <- MCMCglmm(diameter~ 1, random=~ plate + sample,verbose=F,
>> nitt=110000,burn=10000,thin=10,data=Penicillin)
>> summary(mcmc)
>>
>> Why are the result for the plate-variance differ by a large amount?
>> Is it because MCMCglmm applies Gibbs sampling? Or is MCMCglmm doing
>> something else here, instead of fitting independent random effects?
>>
>>
>> Best regards,
>>
>>
>> Linus Holtermann
>> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
>> Heimhuder Stra?e 71
>> 20148 Hamburg
>> Tel +49-(0)40-340576-336
>> Fax+49-(0)40-340576-776
>> Internet: www.hwwi.org
>> Email: holtermann at hwwi.org
>>
>> Amtsgericht Hamburg HRB 94303
>> Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
>> Prokura: Dipl. Kauffrau Alexis Malchin
>> Umsatzsteuer-ID: DE 241849425
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From stan.aggerwal at gmail.com  Wed Jan 21 11:07:11 2015
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Wed, 21 Jan 2015 10:07:11 +0000
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
In-Reply-To: <CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
References: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
	<CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
Message-ID: <CAOZp1onuPfYqCq6rF4HQjZUExwbLWiBeH0HP6GnFYjfra6T6Ng@mail.gmail.com>

I have revised the simulation. Now each subject has autocorrelated errors.
It is a substantial autocorrelation. Still, the 3 methods, including the
obviously "wrong" and simple lm() method, all give the same parameter
estimates and SEs.

Thanks for any insights. Should I really just ignore the repeated measures
design and use lm() for problems like this? (Funny how lme() cannot fit
these data)

Cheers,
Stan

The simulation:

######### previous example assumed indep errors. Now use errors that
# are correlated within each subject
set.seed(1234)
nsubj<-30
z<-expand.grid(x=1:5,cond=c("a","b","c"),subj=as.factor(1:nsubj))
x<-z$x
cond<-z$cond
subj<-z$subj
y<-rep(0,nrow(z))

a1<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #inta=1
a2<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #intb-inta=2-1=1
a3<- rep(2+rnorm(nsubj,mean=0,sd=.1),each=5)  #intc-inta=3-1=2
a4<- rep(3+rnorm(nsubj,mean=0,sd=.1),each=5)  #slopea=3
a5<- rep(-1+rnorm(nsubj,mean=0,sd=.1),each=5) #slopeb-slopea
a6<- rep(-2+rnorm(nsubj,mean=0,sd=.1),each=5) #slopec-slopea

y[cond=="a"]<-a1    + a4*x[cond=="a"]
y[cond=="b"]<-a1+a2 + (a4+a5)*x[cond=="b"]
y[cond=="c"]<-a1+a3 + (a4+a6)*x[cond=="c"]

autocorrelated errors
for(i in 1:nsubj)
  {
  y[subj==i]<-y[subj==i] +

as.numeric(filter(rnorm(5*3,mean=0,sd=.5),filter=0.5,method="recursive"))
  }

plot(x[cond=="a"],y[cond=="a"],xlab="x", ylab="y")
points(x[cond=="b"],y[cond=="b"],col='red')
points(x[cond=="c"],y[cond=="c"],col='green')

## ignore within subjects design and treat as independent errors
fit<-lm(y~cond*x)
summary(fit)
#            Estimate Std. Error t value Pr(>|t|)
#(Intercept)  1.00355    0.13628   7.364 8.75e-13 ***
#condb        0.84320    0.19273   4.375 1.51e-05 ***
#condc        2.03207    0.19273  10.544  < 2e-16 ***
#x            2.99975    0.04109  73.005  < 2e-16 ***
#condb:x     -0.95972    0.05811 -16.516  < 2e-16 ***
#condc:x     -1.98477    0.05811 -34.156  < 2e-16 ***

b<-coef(fit)
abline(b[1],b[4])  #line for cond a
abline(b[1]+b[2],b[4]+b[5],col='red')  #line for cond b
abline(b[1]+b[3],b[4]+b[6],col='green')  #line for cond c

## use Linear Mixed Effects to take account of repeated measures
# lmer() from lme4 package
library(lme4)
fit2<-lmer(y~x*cond + (x*cond|subj))
summary(fit2)
# no p-values. Same param estimates and ses as fit()
#Fixed effects:
#            Estimate Std. Error t value
#(Intercept)  1.00355    0.12632    7.94
#x            2.99975    0.03463   86.62
#condb        0.84320    0.21619    3.90
#condc        2.03207    0.18783   10.82
#x:condb     -0.95972    0.05558  -17.27
#x:condc     -1.98477    0.04671  -42.50

## lme from nlme package
#library(nlme)
#fit3<-lme(y~x*cond, random=~(x*cond)|subj)
##does not converge

##fit line to each subject; get mean and sd of params across subjects

beta<-matrix(0,ncol=6,nrow=nsubj)
for(i in 1:nsubj)
  {
  f<-lm(y[subj==i]~cond[subj==i]*x[subj==i])
  beta[i,]<-coef(f)
  }

m<-colMeans(beta)
s<-apply(beta,2,sd)/sqrt(nsubj)
z<-m/s
pval<-pnorm(abs(z),lower.tail=F)*2 #two-tailed
#pval<-pt(abs(z),df=nsubj-1,lower.tail=F)*2 #two-tailed
cbind(m,s,z,pval)
#              m          s          z         pval
#[1,]  1.0035461 0.12250006   8.192209 2.564748e-16
#[2,]  0.8432030 0.21703074   3.885178 1.022551e-04
#[3,]  2.0320664 0.19155457  10.608290 2.726940e-26
#[4,]  2.9997546 0.03330906  90.058219 0.000000e+00
#[5,] -0.9597171 0.05593306 -17.158318 5.446869e-66
#[6,] -1.9847668 0.05045750 -39.335421 0.000000e+00

	[[alternative HTML version deleted]]


From david.stevens at usu.edu  Wed Jan 21 22:35:26 2015
From: david.stevens at usu.edu (David Stevens)
Date: Wed, 21 Jan 2015 14:35:26 -0700
Subject: [R-sig-ME] mixed-ish model
Message-ID: <54C01B9E.9040707@usu.edu>

I have a mixed-effects model problem in which y ~ x|s where s is a 
random effect and x is a fixed effect. s has three levels (0,1,2) and 
I'm looking for a lmer(...) solution to the case where if s == c(1,2), 
the slope is the same but the intercept is different. If s == 0, slope 
and intercept are different.

lmer(y~x + (1+x|s)) yields three slopes and three intercepts

If I define s2 = 0 for s = 0 and s2 = 1 for s %in% (1,2)
lmer(y~x + (1+x|s2)) yields two slopes and two intercepts

I can brute force this using categorical variables and lm(...) , but I 
was hoping for a more R-ish way. Any thoughts or pointers?

Here are the data
# ... x
x <- c(190,110,150,170,170,170,200,140,140,160,140,110,110,120,110,110,110)
x <-  c(x,140,140,120,190,120,110,110,100,100,120,120,100,80,100)
x <- c(x,580,640,500,530,670,670,640,0640,560,590,640,590,600)
# ... y
y <- 
c(5.96,6.08,5.93,5.99,6.01,5.97,5.88,6.06,6.06,6.03,6.02,6.17,6.31,6.27,6.42,6.28,6.43)
y <- 
c(y,6.33,6.43,6.37,6.09,6.32,6.37,6.73,6.89,6.87,6.3,6.52,6.39,6.87,6.85)
y <- c(y,5.82,5.94,5.73,5.91,5.87,5.8,5.8,5.78,5.78,5.73,5.63,5.79,6.02)
# ... s
s <- as.factor(c(rep(1,17),rep(2,14),rep(0,13)))
y.df = data.frame(x=x,y=y,s=s)
y.df$s2 <- as.factor(1 - as.numeric( !(y.df$s %in% c(1,2))))


Thanks

David

-- 
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From eatonrac at msu.edu  Wed Jan 21 20:58:45 2015
From: eatonrac at msu.edu (Rachael Eaton)
Date: Wed, 21 Jan 2015 14:58:45 -0500
Subject: [R-sig-ME] Question regarding GLMMs and proportional data
Message-ID: <CAHf4mqq+=Od=jvhgAyns0B=dr7d5DiQSPnUcUTo-prE2=UBHiA@mail.gmail.com>

Hello,

I am having some trouble identifying the best model structure for my data.
I am trying to construct models to look at a response variable of
proportions. These data are highly skewed toward zero, with a max value of
0.2. I also have one random variable and a few fixed effects. Therefore, I
decided to use GLMM. I applied a log-transformation of (1 + the response
variable). I then modeled these using glmer with a gamma family with an
inverse link.

Following concerns from a colleague, I also tried modeling the
untransformed data with a binomial family, since I know the denominators
for my proportion data. However, the model fit for this approach was not as
strong as for the gamma approach. AIC strongly favored the model using the
gamma distribution over the model using the binomial distribution.

If you have any recommendations or suggestions on how best to model these
data I've described, I would greatly appreciate it.

-- 
*Rachael Eaton*
PhD Candidate
Department of Zoology
Graduate Program in Ecology, Evol Biology & Behavior
Michigan State University
rachaeleaton.weebly.com <http://www.rachaeleaton.weebly.com>

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Thu Jan 22 10:03:49 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 22 Jan 2015 09:03:49 +0000
Subject: [R-sig-ME] mixed-ish model
In-Reply-To: <54C01B9E.9040707@usu.edu>
References: <54C01B9E.9040707@usu.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA742701096FFDE3@inbomail.inbo.be>

Dear David,

Unfortunately 3 levels of s is not enough to fit a sensible mixed model. This is discussed at http://glmm.wikidot.com/faq

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens David Stevens
Verzonden: woensdag 21 januari 2015 22:35
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] mixed-ish model

I have a mixed-effects model problem in which y ~ x|s where s is a random effect and x is a fixed effect. s has three levels (0,1,2) and I'm looking for a lmer(...) solution to the case where if s == c(1,2), the slope is the same but the intercept is different. If s == 0, slope and intercept are different.

lmer(y~x + (1+x|s)) yields three slopes and three intercepts

If I define s2 = 0 for s = 0 and s2 = 1 for s %in% (1,2) lmer(y~x + (1+x|s2)) yields two slopes and two intercepts

I can brute force this using categorical variables and lm(...) , but I was hoping for a more R-ish way. Any thoughts or pointers?

Here are the data
# ... x
x <- c(190,110,150,170,170,170,200,140,140,160,140,110,110,120,110,110,110)
x <-  c(x,140,140,120,190,120,110,110,100,100,120,120,100,80,100)
x <- c(x,580,640,500,530,670,670,640,0640,560,590,640,590,600)
# ... y
y <-
c(5.96,6.08,5.93,5.99,6.01,5.97,5.88,6.06,6.06,6.03,6.02,6.17,6.31,6.27,6.42,6.28,6.43)
y <-
c(y,6.33,6.43,6.37,6.09,6.32,6.37,6.73,6.89,6.87,6.3,6.52,6.39,6.87,6.85)
y <- c(y,5.82,5.94,5.73,5.91,5.87,5.8,5.8,5.78,5.78,5.73,5.63,5.79,6.02)
# ... s
s <- as.factor(c(rep(1,17),rep(2,14),rep(0,13)))
y.df = data.frame(x=x,y=y,s=s)
y.df$s2 <- as.factor(1 - as.numeric( !(y.df$s %in% c(1,2))))


Thanks

David

--
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering Civil and Environmental Engineering Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From Thierry.ONKELINX at inbo.be  Thu Jan 22 09:55:43 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 22 Jan 2015 08:55:43 +0000
Subject: [R-sig-ME] Question regarding GLMMs and proportional data
In-Reply-To: <CAHf4mqq+=Od=jvhgAyns0B=dr7d5DiQSPnUcUTo-prE2=UBHiA@mail.gmail.com>
References: <CAHf4mqq+=Od=jvhgAyns0B=dr7d5DiQSPnUcUTo-prE2=UBHiA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742701096FFDB2@inbomail.inbo.be>

Dear Rachel,

IMHO you should choose the most appropriate distribution depending on the nature of the response. If it comes for  a number of Bernoulli trails, then the binomial family makes more sense than the gamma. I presume that the denominator is integer? If the denominator is real, then the data generating process is not a set of Bernoulli trials.

I'm not sure if you can compare AIC among models with a different family.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Rachael Eaton
Verzonden: woensdag 21 januari 2015 20:59
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Question regarding GLMMs and proportional data

Hello,

I am having some trouble identifying the best model structure for my data.
I am trying to construct models to look at a response variable of proportions. These data are highly skewed toward zero, with a max value of 0.2. I also have one random variable and a few fixed effects. Therefore, I decided to use GLMM. I applied a log-transformation of (1 + the response variable). I then modeled these using glmer with a gamma family with an inverse link.

Following concerns from a colleague, I also tried modeling the untransformed data with a binomial family, since I know the denominators for my proportion data. However, the model fit for this approach was not as strong as for the gamma approach. AIC strongly favored the model using the gamma distribution over the model using the binomial distribution.

If you have any recommendations or suggestions on how best to model these data I've described, I would greatly appreciate it.

--
*Rachael Eaton*
PhD Candidate
Department of Zoology
Graduate Program in Ecology, Evol Biology & Behavior Michigan State University rachaeleaton.weebly.com <http://www.rachaeleaton.weebly.com>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From Thierry.ONKELINX at inbo.be  Thu Jan 22 10:08:17 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 22 Jan 2015 09:08:17 +0000
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
In-Reply-To: <CAOZp1onuPfYqCq6rF4HQjZUExwbLWiBeH0HP6GnFYjfra6T6Ng@mail.gmail.com>
References: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
	<CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
	<CAOZp1onuPfYqCq6rF4HQjZUExwbLWiBeH0HP6GnFYjfra6T6Ng@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742701096FFE11@inbomail.inbo.be>

Dear Stan,

You get the right answer for the wrong question. Because you have a bug in the code that simulates the data. You added a second noise term instead of a random intercept. Hint: set all parameters not related to the random intercept to 0 in a1 to a6. Then a1 to a6 should be equal.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Stanislav Aggerwal
Verzonden: woensdag 21 januari 2015 11:07
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] within subjects, 3 conditions, 3 lines

I have revised the simulation. Now each subject has autocorrelated errors.
It is a substantial autocorrelation. Still, the 3 methods, including the obviously "wrong" and simple lm() method, all give the same parameter estimates and SEs.

Thanks for any insights. Should I really just ignore the repeated measures design and use lm() for problems like this? (Funny how lme() cannot fit these data)

Cheers,
Stan

The simulation:

######### previous example assumed indep errors. Now use errors that # are correlated within each subject
set.seed(1234)
nsubj<-30
z<-expand.grid(x=1:5,cond=c("a","b","c"),subj=as.factor(1:nsubj))
x<-z$x
cond<-z$cond
subj<-z$subj
y<-rep(0,nrow(z))

a1<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #inta=1
a2<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #intb-inta=2-1=1
a3<- rep(2+rnorm(nsubj,mean=0,sd=.1),each=5)  #intc-inta=3-1=2
a4<- rep(3+rnorm(nsubj,mean=0,sd=.1),each=5)  #slopea=3
a5<- rep(-1+rnorm(nsubj,mean=0,sd=.1),each=5) #slopeb-slopea
a6<- rep(-2+rnorm(nsubj,mean=0,sd=.1),each=5) #slopec-slopea

y[cond=="a"]<-a1    + a4*x[cond=="a"]
y[cond=="b"]<-a1+a2 + (a4+a5)*x[cond=="b"]
y[cond=="c"]<-a1+a3 + (a4+a6)*x[cond=="c"]

autocorrelated errors
for(i in 1:nsubj)
  {
  y[subj==i]<-y[subj==i] +

as.numeric(filter(rnorm(5*3,mean=0,sd=.5),filter=0.5,method="recursive"))
  }

plot(x[cond=="a"],y[cond=="a"],xlab="x", ylab="y")
points(x[cond=="b"],y[cond=="b"],col='red')
points(x[cond=="c"],y[cond=="c"],col='green')

## ignore within subjects design and treat as independent errors
fit<-lm(y~cond*x)
summary(fit)
#            Estimate Std. Error t value Pr(>|t|)
#(Intercept)  1.00355    0.13628   7.364 8.75e-13 ***
#condb        0.84320    0.19273   4.375 1.51e-05 ***
#condc        2.03207    0.19273  10.544  < 2e-16 ***
#x            2.99975    0.04109  73.005  < 2e-16 ***
#condb:x     -0.95972    0.05811 -16.516  < 2e-16 ***
#condc:x     -1.98477    0.05811 -34.156  < 2e-16 ***

b<-coef(fit)
abline(b[1],b[4])  #line for cond a
abline(b[1]+b[2],b[4]+b[5],col='red')  #line for cond b
abline(b[1]+b[3],b[4]+b[6],col='green')  #line for cond c

## use Linear Mixed Effects to take account of repeated measures # lmer() from lme4 package
library(lme4)
fit2<-lmer(y~x*cond + (x*cond|subj))
summary(fit2)
# no p-values. Same param estimates and ses as fit() #Fixed effects:
#            Estimate Std. Error t value
#(Intercept)  1.00355    0.12632    7.94
#x            2.99975    0.03463   86.62
#condb        0.84320    0.21619    3.90
#condc        2.03207    0.18783   10.82
#x:condb     -0.95972    0.05558  -17.27
#x:condc     -1.98477    0.04671  -42.50

## lme from nlme package
#library(nlme)
#fit3<-lme(y~x*cond, random=~(x*cond)|subj) ##does not converge

##fit line to each subject; get mean and sd of params across subjects

beta<-matrix(0,ncol=6,nrow=nsubj)
for(i in 1:nsubj)
  {
  f<-lm(y[subj==i]~cond[subj==i]*x[subj==i])
  beta[i,]<-coef(f)
  }

m<-colMeans(beta)
s<-apply(beta,2,sd)/sqrt(nsubj)
z<-m/s
pval<-pnorm(abs(z),lower.tail=F)*2 #two-tailed
#pval<-pt(abs(z),df=nsubj-1,lower.tail=F)*2 #two-tailed
cbind(m,s,z,pval)
#              m          s          z         pval
#[1,]  1.0035461 0.12250006   8.192209 2.564748e-16
#[2,]  0.8432030 0.21703074   3.885178 1.022551e-04
#[3,]  2.0320664 0.19155457  10.608290 2.726940e-26 #[4,]  2.9997546 0.03330906  90.058219 0.000000e+00 #[5,] -0.9597171 0.05593306 -17.158318 5.446869e-66 #[6,] -1.9847668 0.05045750 -39.335421 0.000000e+00

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From jrmorrongiello at gmail.com  Thu Jan 22 12:23:26 2015
From: jrmorrongiello at gmail.com (John Morrongiello)
Date: Thu, 22 Jan 2015 22:23:26 +1100
Subject: [R-sig-ME] Fwd: priors for multivariate mixed model in MCMCglmm
 with random intercepts and slopes
In-Reply-To: <CAPTgL1aFMeQN7-SAtL8_pySr-TRXKmgrxmGpZc8WxHuyAPDw0g@mail.gmail.com>
References: <CAPTgL1aFMeQN7-SAtL8_pySr-TRXKmgrxmGpZc8WxHuyAPDw0g@mail.gmail.com>
Message-ID: <CAPTgL1ZtRT7cRDN9qZKG7CA+3GVBrEitzp5qgxX9dbmOoqfpwg@mail.gmail.com>

Just wondering if anyone has any thoughts on this question about MCMCglmm
priors for a multivariate mixed model with random intercepts and slopes?

---------- Forwarded message ----------
From: John Morrongiello <jrmorrongiello at gmail.com>
Date: Sun, Jan 18, 2015 at 3:56 PM
Subject: priors for multivariate mixed model in MCMCglmm with random
intercepts and slopes
To: r-sig-mixed-models at r-project.org

Hi
I've got a data set with 7 response variables measured monthly through time
across 38 individuals (FishID). There are 124 months (MonthCode)
representing each sampling time, with the data set having 1021 observations
in total. I have previously analysed this data using a series of univariate
mixed models fitted in lme4 of the form

m1<-lmer(AvGrowth~ Age + (Age|FishID) + (Age|MonthCode), data=alldata1)
.....mx<-lmer(.....)

Here, Age is a continuous covariate that models an age-dependent decline in
growth; the slope of this relationship allowed to vary amongst individuals
(FishID) and through time (MonthCode). To this model structure I have also
added environmental effects like temperature etc.

As the 7 response variables are all measured at the same time from each
fish (they are estimates of growth and otolith microchemistry), I thought
to fit a multivariate mixed model to estimate covariances and also
succinctly ascertain the importance of various environmental effects.

I have had success fitting m2 below where the overall model intercept is
suppressed and the trait-dependent iAge effect is allowed to vary by
individual and MonthCode (similar to m1):

prior1<-list(R=list(V=diag(7),nu=7),G=list(G1=list(V=diag(7),nu=7),G2=list(V=diag(7),nu=7)))

m2<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
~(trait + trait:Age -1),
random=~us(trait:Age):FishID + us(trait:Age):MonthCode,
rcov=~us(trait):units,
family=rep("gaussian",7), prior=prior1,
nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)

When I use posterior.mode(m2$VCV) however, I don't get estimates of the
random intercept terms FishID and MonthCode, nor their covariance with Age,
rather just variances dependent on the iAge slope (e.g.
AvGrowth.std:Age):AvGrowth.std:Age).FishID). I therefore tried to
explicitly code a correlated random intercept and slope using us(1+
trait:(Age):FishID in m3:

m3<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
~(trait + trait:Age -1),
random=~us(1+ trait:Age):FishID + us(1+ trait:Age):MonthCode,
rcov=~us(trait):units,
family=rep("gaussian",7), prior=prior1,
nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)

This returns the error:
Error in priorformat(if (NOpriorG) { :  V is the wrong dimension for some
prior$G/prior$R elements

So I'm tipping something is wrong with my priors. m4, where I estimate an
overall model intercept and specific random intercepts also returns the
same error.

m4<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
~(trait + trait:Age +1),
random=~us(1+ trait:Age):FishID + us(1+ trait:Age):MonthCode,
rcov=~us(trait):units,
family=rep("gaussian",7), prior=prior1,
nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)

Would someone have some tips about how to get the priors for m3 and m4
working? I've worked through the course notes and read some email posts,
but admit that I a little at sea in terms of understanding the specifics of
what is being coded on the prior side of things.

Cheers

John

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Thu Jan 22 17:16:44 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 22 Jan 2015 16:16:44 +0000
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
In-Reply-To: <CAOZp1o=bXYRo9D_QvL9Zpk5xOS3_j-hO9m2K=xiGeojiK_HBmA@mail.gmail.com>
References: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
	<CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
	<CAOZp1onuPfYqCq6rF4HQjZUExwbLWiBeH0HP6GnFYjfra6T6Ng@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA742701096FFE11@inbomail.inbo.be>
	<CAOZp1o=bXYRo9D_QvL9Zpk5xOS3_j-hO9m2K=xiGeojiK_HBmA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74270109700600@inbomail.inbo.be>

Dear Stan,

Please keep the mailing in cc.  You use rnorm(nsubj,mean=0,sd=.1) as the random intercept. However rnorm() will be evaluate again in a1, a2, ..., a6 and thus yielding different values of the random intercept in a1, a2, ..., a6. You want

Rf <- rnorm(nsubj,mean=0,sd=.1)
a1<- rep(1+ rf,each=5)  #inta=1
a2<- rep(1 + rf,each=5)  #intb-inta=2-1=1

Note that is more clear to define the fixed, random effect and noise separately and add those components in a separate step.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

Van: Stanislav Aggerwal [mailto:stan.aggerwal at gmail.com]
Verzonden: donderdag 22 januari 2015 12:25
Aan: ONKELINX, Thierry
Onderwerp: Re: [R-sig-ME] within subjects, 3 conditions, 3 lines

Thanks Thierry for your help. Could I get some clarification please?


You get the right answer for the wrong question. Because you have a bug in the code that simulates the data. You added a second noise term instead of a random intercept. Hint: set all parameters not related to the random intercept to 0 in a1 to a6. Then a1 to a6 should be equal.

There are 30*3 (subjects * conditions) random intercepts. Also 30 random slopes. There are 6 params because there are 3 conditions: (slope and intercept)*3

a1-a6 have the population values: 1, 1, 2, 3, -1, -2
Then each subject has a1-a6 values that randomly vary about these population values.
It is the model I meant, and it describes my data.
Are you saying I implemented it wrong? I don't understand how.

a1<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #inta=1
a2<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #intb-inta=2-1=1
a3<- rep(2+rnorm(nsubj,mean=0,sd=.1),each=5)  #intc-inta=3-1=2
a4<- rep(3+rnorm(nsubj,mean=0,sd=.1),each=5)  #slopea=3
a5<- rep(-1+rnorm(nsubj,mean=0,sd=.1),each=5) #slopeb-slopea
a6<- rep(-2+rnorm(nsubj,mean=0,sd=.1),each=5) #slopec-slopea

y[cond=="a"]<-a1    + a4*x[cond=="a"]
y[cond=="b"]<-a1+a2 + (a4+a5)*x[cond=="b"]
y[cond=="c"]<-a1+a3 + (a4+a6)*x[cond=="c"]

Then I add errors. For each subject the data are not perfectly described by a line, due to measurement error. If I did not add this, the only source of noise in the model is due to the variation in slopes and intercepts between subjects.
Are you saying I should eliminate these measurement errors?
This is the model I intend:
For each subject in each condition:
y = int + slope*x + error
each subject has 3 lines (for a, b, c) with params a1-a6

#autocorrelated errors
for(i in 1:nsubj)
  {
  y[subj==i]<-y[subj==i] +
as.numeric(filter(rnorm(5*3,mean=0,sd=.5),filter=0.5,method="recursive"))
  }

If you look at the plot I think it looks correct.
Thanks very much!
Cheers
Stan

Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

From M.Fairbrother at bristol.ac.uk  Fri Jan 23 19:49:38 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 23 Jan 2015 12:49:38 -0600
Subject: [R-sig-ME] Fwd: priors for multivariate mixed model in MCMCglmm
 with random intercepts and slopes
Message-ID: <CAAH-yP8kkAJGrknv3SiD9A9G6ht6UVYaO38DAeQrePTvjYMfSQ@mail.gmail.com>

Hi John,

This is not my substantive area of expertise at all, and I'm not completely
confident I can help. But, nobody else has responded, and I have fitted
some multivariate models with MCMCglmm. So, for what it's worth...

For starters, I'm not sure I understand the data. If you're saying each of
7 properties are observed on 38 fish each observed over the course of 124
months, where does 1021 come from? (38x124 is 4712...) Are you saying you
have repeated observations on fish over the course of 124 months, but for
each actual fish you have fewer observations than 124?

Next, two questions about your models:
Why do you allow the slope for Age to vary randomly across months?
And why model growth (so, say, % or absolute change in length) rather than
the property that is growing (length)? The latter would seem more
straightforward to me.

As regards the priors, if I understand you correctly, you've kept the same
prior specification (prior1) when fitting models (m3 and m4) with an
additional parameter at each higher level. So maybe try changing 7 to 8 at
those levels?

prior2  <- list(R=list(V=diag(7), nu=7), G=list(G1=list(V=diag(8), nu=8),
G2=list(V=diag(8), nu=8)))

Additionally, also for what it's worth, I've found parameter-expanded
priors to be more uninformative, and Jarrod has made them pretty easy to
use. So (assuming you want them to be uninformative) you might try:

prior2a  <- list(R=list(V=diag(7), nu=7.02), G=list(G1=list(V=diag(8),
nu=8.02, alpha.mu=rep(0,8), alpha.V=1000*diag(8)), G2=list(V=diag(8),
nu=8.02, alpha.mu=rep(0,8), alpha.V=1000*diag(8))))

Hope that helps...?

Don't feel bad. You're far from the first person to write to this list with
questions about priors for MCMCglmm!

Cheers,
Malcolm




> Date: Thu, 22 Jan 2015 22:23:26 +1100
> From: John Morrongiello <jrmorrongiello at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Fwd: priors for multivariate mixed model in
>         MCMCglmm with random intercepts and slopes
>
> Just wondering if anyone has any thoughts on this question about MCMCglmm
> priors for a multivariate mixed model with random intercepts and slopes?
>
> ---------- Forwarded message ----------
> From: John Morrongiello <jrmorrongiello at gmail.com>
> Date: Sun, Jan 18, 2015 at 3:56 PM
> Subject: priors for multivariate mixed model in MCMCglmm with random
> intercepts and slopes
> To: r-sig-mixed-models at r-project.org
>
> Hi
> I've got a data set with 7 response variables measured monthly through time
> across 38 individuals (FishID). There are 124 months (MonthCode)
> representing each sampling time, with the data set having 1021 observations
> in total. I have previously analysed this data using a series of univariate
> mixed models fitted in lme4 of the form
>
> m1<-lmer(AvGrowth~ Age + (Age|FishID) + (Age|MonthCode), data=alldata1)
> .....mx<-lmer(.....)
>
> Here, Age is a continuous covariate that models an age-dependent decline in
> growth; the slope of this relationship allowed to vary amongst individuals
> (FishID) and through time (MonthCode). To this model structure I have also
> added environmental effects like temperature etc.
>
> As the 7 response variables are all measured at the same time from each
> fish (they are estimates of growth and otolith microchemistry), I thought
> to fit a multivariate mixed model to estimate covariances and also
> succinctly ascertain the importance of various environmental effects.
>
> I have had success fitting m2 below where the overall model intercept is
> suppressed and the trait-dependent iAge effect is allowed to vary by
> individual and MonthCode (similar to m1):
>
>
> prior1<-list(R=list(V=diag(7),nu=7),G=list(G1=list(V=diag(7),nu=7),G2=list(V=diag(7),nu=7)))
>
>
> m2<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
> ~(trait + trait:Age -1),
> random=~us(trait:Age):FishID + us(trait:Age):MonthCode,
> rcov=~us(trait):units,
> family=rep("gaussian",7), prior=prior1,
> nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)
>
> When I use posterior.mode(m2$VCV) however, I don't get estimates of the
> random intercept terms FishID and MonthCode, nor their covariance with Age,
> rather just variances dependent on the iAge slope (e.g.
> AvGrowth.std:Age):AvGrowth.std:Age).FishID). I therefore tried to
> explicitly code a correlated random intercept and slope using us(1+
> trait:(Age):FishID in m3:
>
>
> m3<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
> ~(trait + trait:Age -1),
> random=~us(1+ trait:Age):FishID + us(1+ trait:Age):MonthCode,
> rcov=~us(trait):units,
> family=rep("gaussian",7), prior=prior1,
> nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)
>
> This returns the error:
> Error in priorformat(if (NOpriorG) { :  V is the wrong dimension for some
> prior$G/prior$R elements
>
> So I'm tipping something is wrong with my priors. m4, where I estimate an
> overall model intercept and specific random intercepts also returns the
> same error.
>
>
> m4<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
> ~(trait + trait:Age +1),
> random=~us(1+ trait:Age):FishID + us(1+ trait:Age):MonthCode,
> rcov=~us(trait):units,
> family=rep("gaussian",7), prior=prior1,
> nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)
>
> Would someone have some tips about how to get the priors for m3 and m4
> working? I've worked through the course notes and read some email posts,
> but admit that I a little at sea in terms of understanding the specifics of
> what is being coded on the prior side of things.
>
> Cheers
>
> John
>

	[[alternative HTML version deleted]]


From stan.aggerwal at gmail.com  Sat Jan 24 11:35:40 2015
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Sat, 24 Jan 2015 10:35:40 +0000
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
In-Reply-To: <AA818EAD2576BC488B4F623941DA74270109700600@inbomail.inbo.be>
References: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
	<CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
	<CAOZp1onuPfYqCq6rF4HQjZUExwbLWiBeH0HP6GnFYjfra6T6Ng@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA742701096FFE11@inbomail.inbo.be>
	<CAOZp1o=bXYRo9D_QvL9Zpk5xOS3_j-hO9m2K=xiGeojiK_HBmA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74270109700600@inbomail.inbo.be>
Message-ID: <CAOZp1okd2eC1TWXG7aughOZQBsrmoXV-q=CL=L5C6F0RAcEmGA@mail.gmail.com>

Thanks Thierry!

Stan

On Thu, Jan 22, 2015 at 4:16 PM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be
> wrote:

> Dear Stan,
>
> Please keep the mailing in cc.  You use rnorm(nsubj,mean=0,sd=.1) as the
> random intercept. However rnorm() will be evaluate again in a1, a2, ..., a6
> and thus yielding different values of the random intercept in a1, a2, ...,
> a6. You want
>
> Rf <- rnorm(nsubj,mean=0,sd=.1)
> a1<- rep(1+ rf,each=5)  #inta=1
> a2<- rep(1 + rf,each=5)  #intb-inta=2-1=1
>
> Note that is more clear to define the fixed, random effect and noise
> separately and add those components in a separate step.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> Van: Stanislav Aggerwal [mailto:stan.aggerwal at gmail.com]
> Verzonden: donderdag 22 januari 2015 12:25
> Aan: ONKELINX, Thierry
> Onderwerp: Re: [R-sig-ME] within subjects, 3 conditions, 3 lines
>
> Thanks Thierry for your help. Could I get some clarification please?
>
>
> You get the right answer for the wrong question. Because you have a bug in
> the code that simulates the data. You added a second noise term instead of
> a random intercept. Hint: set all parameters not related to the random
> intercept to 0 in a1 to a6. Then a1 to a6 should be equal.
>
> There are 30*3 (subjects * conditions) random intercepts. Also 30 random
> slopes. There are 6 params because there are 3 conditions: (slope and
> intercept)*3
>
> a1-a6 have the population values: 1, 1, 2, 3, -1, -2
> Then each subject has a1-a6 values that randomly vary about these
> population values.
> It is the model I meant, and it describes my data.
> Are you saying I implemented it wrong? I don't understand how.
>
> a1<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #inta=1
> a2<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #intb-inta=2-1=1
> a3<- rep(2+rnorm(nsubj,mean=0,sd=.1),each=5)  #intc-inta=3-1=2
> a4<- rep(3+rnorm(nsubj,mean=0,sd=.1),each=5)  #slopea=3
> a5<- rep(-1+rnorm(nsubj,mean=0,sd=.1),each=5) #slopeb-slopea
> a6<- rep(-2+rnorm(nsubj,mean=0,sd=.1),each=5) #slopec-slopea
>
> y[cond=="a"]<-a1    + a4*x[cond=="a"]
> y[cond=="b"]<-a1+a2 + (a4+a5)*x[cond=="b"]
> y[cond=="c"]<-a1+a3 + (a4+a6)*x[cond=="c"]
>
> Then I add errors. For each subject the data are not perfectly described
> by a line, due to measurement error. If I did not add this, the only source
> of noise in the model is due to the variation in slopes and intercepts
> between subjects.
> Are you saying I should eliminate these measurement errors?
> This is the model I intend:
> For each subject in each condition:
> y = int + slope*x + error
> each subject has 3 lines (for a, b, c) with params a1-a6
>
> #autocorrelated errors
> for(i in 1:nsubj)
>   {
>   y[subj==i]<-y[subj==i] +
> as.numeric(filter(rnorm(5*3,mean=0,sd=.5),filter=0.5,method="recursive"))
>   }
>
> If you look at the plot I think it looks correct.
> Thanks very much!
> Cheers
> Stan
>
> Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
>

	[[alternative HTML version deleted]]


From stan.aggerwal at gmail.com  Sun Jan 25 14:00:47 2015
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Sun, 25 Jan 2015 13:00:47 +0000
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
In-Reply-To: <CAOZp1okd2eC1TWXG7aughOZQBsrmoXV-q=CL=L5C6F0RAcEmGA@mail.gmail.com>
References: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
	<CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
	<CAOZp1onuPfYqCq6rF4HQjZUExwbLWiBeH0HP6GnFYjfra6T6Ng@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA742701096FFE11@inbomail.inbo.be>
	<CAOZp1o=bXYRo9D_QvL9Zpk5xOS3_j-hO9m2K=xiGeojiK_HBmA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74270109700600@inbomail.inbo.be>
	<CAOZp1okd2eC1TWXG7aughOZQBsrmoXV-q=CL=L5C6F0RAcEmGA@mail.gmail.com>
Message-ID: <CAOZp1okQYvrvBDJqiyR-PWf+BuZOwUxNX5omot4qYBMfO0722A@mail.gmail.com>

Thierry, thanks for your help, but your model is completely different from
what I want, so far as I can tell.

The model I want to fit is this. Each subject produces 3 lines, one for
each condition
y = b1 + b2*x + error  #condition a
y = b3 + b4*x + error # condition b
y = b5 + b6*x + error #condition c
Within each subject, these three lines have differing slopes and
intercepts. For each subject, each parameter (b1 to pick an example) is not
identical to that of other subjects but is similar to that from other
subjects.

The intercepts, b1, b3, and b5 vary between subjects. Each subject's b1,
b3, and b5 is randomly sampled from N(p_i,sd_i) where p_i is the population
value for each of the 3 parameters

The intercepts, b2, b4, and b6 vary between subjects. Each subject's b2,
b4, and b6 is randomly sampled from N(p_i,sd_i) where p_i is the population
value for each of the 3 parameters.

In my simulations I used params a1-a6 which are the R parametrisation used
in fitting linear models, instead of b1-b6. E.g. a2 = b1+b2

So far as I can tell (and I looked hard), my code is producing the right
sort of simulated data. And these simulated data look similar to my real
data.

If we pretend that subjects is a fixed effect, we have
lm(y ~ x*cond*subj)
A different slope and intercept for each condition and each subject.

Thanks again,
Bill



On Sat, Jan 24, 2015 at 10:35 AM, Stanislav Aggerwal <
stan.aggerwal at gmail.com> wrote:

> Thanks Thierry!
>
> Stan
>
> On Thu, Jan 22, 2015 at 4:16 PM, ONKELINX, Thierry <
> Thierry.ONKELINX at inbo.be> wrote:
>
>> Dear Stan,
>>
>> Please keep the mailing in cc.  You use rnorm(nsubj,mean=0,sd=.1) as the
>> random intercept. However rnorm() will be evaluate again in a1, a2, ..., a6
>> and thus yielding different values of the random intercept in a1, a2, ...,
>> a6. You want
>>
>> Rf <- rnorm(nsubj,mean=0,sd=.1)
>> a1<- rep(1+ rf,each=5)  #inta=1
>> a2<- rep(1 + rf,each=5)  #intb-inta=2-1=1
>>
>> Note that is more clear to define the fixed, random effect and noise
>> separately and add those components in a separate step.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> + 32 2 525 02 51
>> + 32 54 43 61 85
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> Van: Stanislav Aggerwal [mailto:stan.aggerwal at gmail.com]
>> Verzonden: donderdag 22 januari 2015 12:25
>> Aan: ONKELINX, Thierry
>> Onderwerp: Re: [R-sig-ME] within subjects, 3 conditions, 3 lines
>>
>> Thanks Thierry for your help. Could I get some clarification please?
>>
>>
>> You get the right answer for the wrong question. Because you have a bug
>> in the code that simulates the data. You added a second noise term instead
>> of a random intercept. Hint: set all parameters not related to the random
>> intercept to 0 in a1 to a6. Then a1 to a6 should be equal.
>>
>> There are 30*3 (subjects * conditions) random intercepts. Also 30 random
>> slopes. There are 6 params because there are 3 conditions: (slope and
>> intercept)*3
>>
>> a1-a6 have the population values: 1, 1, 2, 3, -1, -2
>> Then each subject has a1-a6 values that randomly vary about these
>> population values.
>> It is the model I meant, and it describes my data.
>> Are you saying I implemented it wrong? I don't understand how.
>>
>> a1<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #inta=1
>> a2<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #intb-inta=2-1=1
>> a3<- rep(2+rnorm(nsubj,mean=0,sd=.1),each=5)  #intc-inta=3-1=2
>> a4<- rep(3+rnorm(nsubj,mean=0,sd=.1),each=5)  #slopea=3
>> a5<- rep(-1+rnorm(nsubj,mean=0,sd=.1),each=5) #slopeb-slopea
>> a6<- rep(-2+rnorm(nsubj,mean=0,sd=.1),each=5) #slopec-slopea
>>
>> y[cond=="a"]<-a1    + a4*x[cond=="a"]
>> y[cond=="b"]<-a1+a2 + (a4+a5)*x[cond=="b"]
>> y[cond=="c"]<-a1+a3 + (a4+a6)*x[cond=="c"]
>>
>> Then I add errors. For each subject the data are not perfectly described
>> by a line, due to measurement error. If I did not add this, the only source
>> of noise in the model is due to the variation in slopes and intercepts
>> between subjects.
>> Are you saying I should eliminate these measurement errors?
>> This is the model I intend:
>> For each subject in each condition:
>> y = int + slope*x + error
>> each subject has 3 lines (for a, b, c) with params a1-a6
>>
>> #autocorrelated errors
>> for(i in 1:nsubj)
>>   {
>>   y[subj==i]<-y[subj==i] +
>> as.numeric(filter(rnorm(5*3,mean=0,sd=.5),filter=0.5,method="recursive"))
>>   }
>>
>> If you look at the plot I think it looks correct.
>> Thanks very much!
>> Cheers
>> Stan
>>
>> Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
>>
>
>

	[[alternative HTML version deleted]]


From asafw.at.wharton at gmail.com  Fri Jan 23 01:10:51 2015
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Thu, 22 Jan 2015 19:10:51 -0500
Subject: [R-sig-ME] Square root of a matrix
Message-ID: <CAGG0PdD97LFung_B8eE_EyO7WT-K+wrH6T51zbCoEhQ55z=nFw@mail.gmail.com>

Hi,

If Q is a positive-definite matrix, what is the most popular function to
obtain a matrix B s.t. B'B = Q? I found pdFactor() (in the nlme package)
and just wanted to know if there are more basic functions for this purpose.

Thank you!
Asaf

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Jan 25 17:05:55 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 25 Jan 2015 11:05:55 -0500
Subject: [R-sig-ME] Square root of a matrix
In-Reply-To: <CAGG0PdD97LFung_B8eE_EyO7WT-K+wrH6T51zbCoEhQ55z=nFw@mail.gmail.com>
References: <CAGG0PdD97LFung_B8eE_EyO7WT-K+wrH6T51zbCoEhQ55z=nFw@mail.gmail.com>
Message-ID: <54C51463.4050108@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-01-22 07:10 PM, Asaf Weinstein wrote:
> Hi,
> 
> If Q is a positive-definite matrix, what is the most popular
> function to obtain a matrix B s.t. B'B = Q? I found pdFactor() (in
> the nlme package) and just wanted to know if there are more basic
> functions for this purpose.
> 
> Thank you! Asaf

  ?chol, which can be found in base R and extended (via new methods
for chol, and ?Cholesky) in Matrix ... ?
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUxRRjAAoJEOCV5YRblxUHTZsH/1hBQsUYf8NXeYYAJRbXKbnD
fe5HMKLPVWnn1TziPLPSHB9hfFPD7esh8+YhVN6oVyE/iALeKwknbDcEOKAGwnI6
iM2TdV2wNLTnneFydPfUw9GpHYZ0RLT2mJ+rdLwEAUfTF7B/UVoF8vMV/P/ERCCo
wdo4F532+3QDhDaH11wgHoidnLT0Ns0g11gm1/QrdrHVnHVZTh7usYqguDMim1WN
oicnF4PsxSpMrFHQL9dUSPxBRgSM4oqBK9eCCQpi7UhCL8nzwbPAujsNPkoUsIFe
H8CaDncupIYYmMoQo0DKvxlPQgb1N+ylnRC12v1Ljf/JlUSnNKB4CjVkuUfPfIA=
=s0a+
-----END PGP SIGNATURE-----


From bbonit at tin.it  Sun Jan 25 18:27:52 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Sun, 25 Jan 2015 18:27:52 +0100 (CET)
Subject: [R-sig-ME] LogLikelihood
Message-ID: <14b2222ab7c.bbonit@tin.it>



Dear list, my name is Gianluca Bonitta
I'm trying to build up the Loglikelihood of the following model.
For check it I had used logLik(mod0,REML=F) like "gold standard" 
Like You see there is a difference   # diff   logLik(mod0,REML=F) - mylog = 0.6339805 
Can somebody help to resolve my mistake ?  
Maybe professor Bolker or professor Bates that are the "fathers" of lme4 pack 
thank You in advance
Best
Gianluca

########################################################################################
library(lme4)
data(sleepstudy)
dat <- sleepstudy[ (sleepstudy$Days %in% 0:4) &amp; (sleepstudy$Subject %in% 331:333) ,]
colnames(dat) <- c("y", "x", "group")
mod0 <- lmer( y ~ 1 + x  +( x | group ), data = dat,REML="F")  
########################################################################################

  q <- 2                                          # number of random effects
  n <- nrow(dat)                              # number of individuals
  m <- length(unique(dat$group))      # number of groups
  Y <- dat$y                                    # response vector
  R <- diag(1,nrow(dat))*summary(mod0)$sigma^2    # covariance matrix of residuals
  beta <- as.numeric(fixef(mod0))                 # fixed effects vector (p x 1)
  a<-rep(c(597.1903,60.05023),m)                  # variance rand effects
  ranef(mod0)$group
  b <-c(17.94432, -3.753130,-33.31148, 10.294328,15.36716, -6.541198) # random effect estimated
  D <-matrix(-0.97,6,6)                           # random effect estimated correlation
  diag(D) <-a
  X <- cbind(rep(1,n), dat$x)                     # model matrix of fixed effects (n x p)
  Z.sparse<- getME(mod0,"Z")                   # model matrix of random effect (sparse format)
  Z <- as.matrix(Z.sparse)  
  V <-Z%*% D %*% t(Z) + R                   # (total) covariance matrix of Y
  # check: values in Y can be perfectly matched using lmer's information
  Y.test <- X %*% beta + Z %*% b + resid(mod0)
  cbind(Y, Y.test)
  mu = X %*% beta + Z %*% b
###############################################################################################
   ll = -n/2*log(2*pi) - sum(log(diag(chol(V)))) -  .5 * t(Y- mu) %*% chol2inv(chol(V)) %*% (Y-mu); 
   logLik(mod0,REML=F)
   ll
####################################?
# diff   'log Lik.' 0.6339805 (df=6)

   logLik(mod0,REML=F) -ll
	[[alternative HTML version deleted]]


From agalecki at umich.edu  Sun Jan 25 18:51:25 2015
From: agalecki at umich.edu (Andrzej Galecki)
Date: Sun, 25 Jan 2015 12:51:25 -0500
Subject: [R-sig-ME] LogLikelihood
In-Reply-To: <14b2222ab7c.bbonit@tin.it>
References: <14b2222ab7c.bbonit@tin.it>
Message-ID: <CA+XOvOTs3whx3LsOifAj=Y4SbK7hkoSPQqhG_R01sCOmAWm71Q@mail.gmail.com>

Hello Gianluca,

There are two random effects (q=2).

Matrix D should be 2 by 2, not 6 by 6.

Did not check the rest of your code, but this is an obvious mistake/error.

Best wishes

Andrzej Galecki


On Sun, Jan 25, 2015 at 12:27 PM, bbonit at tin.it <bbonit at tin.it> wrote:

>
>
> Dear list, my name is Gianluca Bonitta
> I'm trying to build up the Loglikelihood of the following model.
> For check it I had used logLik(mod0,REML=F) like "gold standard"
> Like You see there is a difference   # diff   logLik(mod0,REML=F) - mylog
> = 0.6339805
> Can somebody help to resolve my mistake ?
> Maybe professor Bolker or professor Bates that are the "fathers" of lme4
> pack
> thank You in advance
> Best
> Gianluca
>
>
> ########################################################################################
> library(lme4)
> data(sleepstudy)
> dat <- sleepstudy[ (sleepstudy$Days %in% 0:4) &amp; (sleepstudy$Subject
> %in% 331:333) ,]
> colnames(dat) <- c("y", "x", "group")
> mod0 <- lmer( y ~ 1 + x  +( x | group ), data = dat,REML="F")
>
> ########################################################################################
>
>   q <- 2                                          # number of random
> effects
>   n <- nrow(dat)                              # number of individuals
>   m <- length(unique(dat$group))      # number of groups
>   Y <- dat$y                                    # response vector
>   R <- diag(1,nrow(dat))*summary(mod0)$sigma^2    # covariance matrix of
> residuals
>   beta <- as.numeric(fixef(mod0))                 # fixed effects vector
> (p x 1)
>   a<-rep(c(597.1903,60.05023),m)                  # variance rand effects
>   ranef(mod0)$group
>   b <-c(17.94432, -3.753130,-33.31148, 10.294328,15.36716, -6.541198) #
> random effect estimated
>   D <-matrix(-0.97,6,6)                           # random effect
> estimated correlation
>   diag(D) <-a
>   X <- cbind(rep(1,n), dat$x)                     # model matrix of fixed
> effects (n x p)
>   Z.sparse<- getME(mod0,"Z")                   # model matrix of random
> effect (sparse format)
>   Z <- as.matrix(Z.sparse)
>   V <-Z%*% D %*% t(Z) + R                   # (total) covariance matrix of
> Y
>   # check: values in Y can be perfectly matched using lmer's information
>   Y.test <- X %*% beta + Z %*% b + resid(mod0)
>   cbind(Y, Y.test)
>   mu = X %*% beta + Z %*% b
>
> ###############################################################################################
>    ll = -n/2*log(2*pi) - sum(log(diag(chol(V)))) -  .5 * t(Y- mu) %*%
> chol2inv(chol(V)) %*% (Y-mu);
>    logLik(mod0,REML=F)
>    ll
> ####################################?
> # diff   'log Lik.' 0.6339805 (df=6)
>
>    logLik(mod0,REML=F) -ll
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From agalecki at umich.edu  Sun Jan 25 18:58:13 2015
From: agalecki at umich.edu (Andrzej Galecki)
Date: Sun, 25 Jan 2015 12:58:13 -0500
Subject: [R-sig-ME] LogLikelihood
In-Reply-To: <CA+XOvOTs3whx3LsOifAj=Y4SbK7hkoSPQqhG_R01sCOmAWm71Q@mail.gmail.com>
References: <14b2222ab7c.bbonit@tin.it>
	<CA+XOvOTs3whx3LsOifAj=Y4SbK7hkoSPQqhG_R01sCOmAWm71Q@mail.gmail.com>
Message-ID: <CA+XOvORAxNRYTg7wws4zYRYtirfy-dfFgLZum7O5rKPkbXdRag@mail.gmail.com>

More precisely D should be positive definite and have 2 by  2 blocks on the
diagonal.

AG



On Sun, Jan 25, 2015 at 12:51 PM, Andrzej Galecki <agalecki at umich.edu>
wrote:

> Hello Gianluca,
>
> There are two random effects (q=2).
>
> Matrix D should be 2 by 2, not 6 by 6.
>
> Did not check the rest of your code, but this is an obvious mistake/error.
>
> Best wishes
>
> Andrzej Galecki
>
>
> On Sun, Jan 25, 2015 at 12:27 PM, bbonit at tin.it <bbonit at tin.it> wrote:
>
>>
>>
>> Dear list, my name is Gianluca Bonitta
>> I'm trying to build up the Loglikelihood of the following model.
>> For check it I had used logLik(mod0,REML=F) like "gold standard"
>> Like You see there is a difference   # diff   logLik(mod0,REML=F) - mylog
>> = 0.6339805
>> Can somebody help to resolve my mistake ?
>> Maybe professor Bolker or professor Bates that are the "fathers" of lme4
>> pack
>> thank You in advance
>> Best
>> Gianluca
>>
>>
>> ########################################################################################
>> library(lme4)
>> data(sleepstudy)
>> dat <- sleepstudy[ (sleepstudy$Days %in% 0:4) &amp; (sleepstudy$Subject
>> %in% 331:333) ,]
>> colnames(dat) <- c("y", "x", "group")
>> mod0 <- lmer( y ~ 1 + x  +( x | group ), data = dat,REML="F")
>>
>> ########################################################################################
>>
>>   q <- 2                                          # number of random
>> effects
>>   n <- nrow(dat)                              # number of individuals
>>   m <- length(unique(dat$group))      # number of groups
>>   Y <- dat$y                                    # response vector
>>   R <- diag(1,nrow(dat))*summary(mod0)$sigma^2    # covariance matrix of
>> residuals
>>   beta <- as.numeric(fixef(mod0))                 # fixed effects vector
>> (p x 1)
>>   a<-rep(c(597.1903,60.05023),m)                  # variance rand effects
>>   ranef(mod0)$group
>>   b <-c(17.94432, -3.753130,-33.31148, 10.294328,15.36716, -6.541198) #
>> random effect estimated
>>   D <-matrix(-0.97,6,6)                           # random effect
>> estimated correlation
>>   diag(D) <-a
>>   X <- cbind(rep(1,n), dat$x)                     # model matrix of fixed
>> effects (n x p)
>>   Z.sparse<- getME(mod0,"Z")                   # model matrix of random
>> effect (sparse format)
>>   Z <- as.matrix(Z.sparse)
>>   V <-Z%*% D %*% t(Z) + R                   # (total) covariance matrix
>> of Y
>>   # check: values in Y can be perfectly matched using lmer's information
>>   Y.test <- X %*% beta + Z %*% b + resid(mod0)
>>   cbind(Y, Y.test)
>>   mu = X %*% beta + Z %*% b
>>
>> ###############################################################################################
>>    ll = -n/2*log(2*pi) - sum(log(diag(chol(V)))) -  .5 * t(Y- mu) %*%
>> chol2inv(chol(V)) %*% (Y-mu);
>>    logLik(mod0,REML=F)
>>    ll
>> ####################################?
>> # diff   'log Lik.' 0.6339805 (df=6)
>>
>>    logLik(mod0,REML=F) -ll
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From bbonit at tin.it  Sun Jan 25 19:16:56 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Sun, 25 Jan 2015 19:16:56 +0100 (CET)
Subject: [R-sig-ME] Loglikelihood
Message-ID: <14b224f95cb.bbonit@tin.it>


 
Oh yes i have 2 random effects for 3 groups   for write this V <-Z%*% D %*% t(Z) + R
to have conformability with D
i need 6X6 matrix where       
  
       [,1]     [,2]
[1,] 597.1903 -0.97000
[2,]  -0.9700 60.05023

rappresent a blok of D       D matrix depends on Z  matrix   ( 
I use Z.sparse<- getME(mod0,"Z") # model matrix of random effect (sparse format)
Z <- as.matrix(Z.sparse)  because the lme4 built if for me only specify the formula        

the D matrix is for 2 random effects for 3 groups
a1 b1  a2 b2  a3 b3

V <-Z%*% D %*% t(Z) + R

       [,1]     [,2]     [,3]     [,4]     [,5]     [,6]
[1,] 597.1903 -0.97000  -0.9700 -0.97000  -0.9700 -0.97000
[2,]  -0.9700 60.05023  -0.9700 -0.97000  -0.9700 -0.97000
[3,]  -0.9700 -0.97000 597.1903 -0.97000  -0.9700 -0.97000
[4,]  -0.9700 -0.97000  -0.9700 60.05023  -0.9700 -0.97000
[5,]  -0.9700 -0.97000  -0.9700 -0.97000 597.1903 -0.97000
[6,]  -0.9700 -0.97000  -0.9700 -0.97000  -0.9700 60.05023
 
	[[alternative HTML version deleted]]


From bbonit at tin.it  Sun Jan 25 20:35:29 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Sun, 25 Jan 2015 20:35:29 +0100 (CET)
Subject: [R-sig-ME] Loglikelihood
Message-ID: <14b22978132.bbonit@tin.it>


 m1 <- matrix(c(597.1903,-0.97,-0.97,60.05023),nrow=2,byrow=TRUE)
D1 <-as.matrix(bdiag(m1, m1, m1))
V1 <-Z%*% D1 %*% t(Z) + R 
D1

         [,1]     [,2]     [,3]     [,4]     [,5]     [,6]
[1,] 597.1903 -0.97000   0.0000  0.00000   0.0000  0.00000
[2,]  -0.9700 60.05023   0.0000  0.00000   0.0000  0.00000
[3,]   0.0000  0.00000 597.1903 -0.97000   0.0000  0.00000
[4,]   0.0000  0.00000  -0.9700 60.05023   0.0000  0.00000
[5,]   0.0000  0.00000   0.0000  0.00000 597.1903 -0.97000
[6,]   0.0000  0.00000   0.0000  0.00000  -0.9700 60.05023

insted of 
        [,1]     [,2]     [,3]     [,4]     [,5]     [,6]
[1,] 597.1903 -0.97000  -0.9700 -0.97000  -0.9700 -0.97000
[2,]  -0.9700 60.05023  -0.9700 -0.97000  -0.9700 -0.97000
[3,]  -0.9700 -0.97000 597.1903 -0.97000  -0.9700 -0.97000
[4,]  -0.9700 -0.97000  -0.9700 60.05023  -0.9700 -0.97000
[5,]  -0.9700 -0.97000  -0.9700 -0.97000 597.1903 -0.97000
[6,]  -0.9700 -0.97000  -0.9700 -0.97000  -0.9700 60.05023


but this dont affect the decomposition into ll (loglike) and dont change my loglike 
	[[alternative HTML version deleted]]


From smilodon2000 at hotmail.com  Sun Jan 25 22:36:37 2015
From: smilodon2000 at hotmail.com (john benson)
Date: Sun, 25 Jan 2015 21:36:37 +0000
Subject: [R-sig-ME] plotting gams in mgcv
Message-ID: <BAY173-W23B9B1F113670B24797CAFDC340@phx.gbl>

Hi,
I am running a GAM that has a smooth x factor interaction accomplished with the "by" function.
The model looks like this where X1 is a continuous smooth term and X2 is a categorical factor variable with 2 levels:
Gam1<-gam(y~s(X1, by = X2) + X2, data=datum)summary(Gam1)plot (Gam1)
The plot of this model gives separate figures for the separate smooth functions for each level (n=2) of the factor term.  I would like the rug plot for each figure to show only the locations of the covariate values along the x-axis that are specific to each level of the factor term.  
Instead, the gam plot gives me identical rug plots (with all covariate locations across both factor levels) for both of the 2 plots of the separate smooth functions.
Does anyone know if it is possible to only display the rug plot for covariate values associated with correct level of the factor variable for each of these 2 figures? 
Many thanks for any help with this!
Best,
John 		 	   		  
	[[alternative HTML version deleted]]


From markl033 at umn.edu  Mon Jan 26 07:05:20 2015
From: markl033 at umn.edu (Tricia Markle)
Date: Mon, 26 Jan 2015 00:05:20 -0600
Subject: [R-sig-ME] Priors for us(trait):units structure in MCMCglmm model.
 Error message - help needed.
Message-ID: <CAO=0ZJUR6ncdngJCrd-O+w5YOEb7NLkxtdq8-xDfZ1_or4tJEQ@mail.gmail.com>

Hello,



I am hoping that someone could provide some thoughts on an appropriate
prior set-up for my model which uses a ?us(trait):units? structure in an
MCMCglmm model with repeat measures and a phylogeny component.



I am assuming that I need to use uninformative proper priors with a set-up
something along the lines of:



prior<-list(G=list(G1=list(V=diag(#), nu=#)), R=list(V=diag(#), n=#))



I have spent a considerable amount of time working on this (looking at help
guides, posted examples etc.) and regardless of what numbers I try, I
continue to get the following error message:



Error in priorformat(if (NOpriorG) { :

  V is the wrong dimension for some prior$G/prior$R elements



Data Details: I have 308 individual salamanders, each acclimated at 3
different temperatures (6,14,22C). Then for each acclimation temperature
metabolic rate is measured at 3 test temperatures (5, 15, 25C) (so total of
9 trials per individual).



I am attempting to compare slopes of the test temperatures between
acclimation temperatures. There are 18 species, but my main question is
whether large ranging species have greater differences in slope between
acclimation temps than narrow ranging species (species are divided into
those with small (1) versus large (2) ranges).



Here is the rest of my code:



dataset<-read.csv(file="RespData.csv", head=TRUE)

dataset$Range<-as.factor(dataset$Range)

str(dataset)

#Phylogeny Component

tree<-read.tree("Plethodontidae_comb61_PL.phy")

species<-c("D._carolinensis", "D._fuscus", "D._imitator", "D._ochrophaeus",
"D._ocoee", "D._orestes",  "D._monticola_A",  "D._santeetlah",
"P_cinereus", "P_cylindraceus", "P_glutinosus", "P_hubrichti",
"P_montanus", "P_punctatus", "P_richmondi", "P_teyahalee", "P_virginia",
"P_wehrlei")

pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
tree$tip.label)])# Prune tree to just include species of interest

sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node") #rename
nodes to be unique



treeAinv<-inverseA(sptree, nodes="TIPS")$Ainv



random=~us(1+Temp):Range



#note, I could alternatively use random=~us(1+Temp):species, but results
are likely harder to interpret



prior<-list(G=list(G1=list(V=diag(#), nu=#)), R=list(V=diag(#), n=#))



model1<-MCMCglmm(LVO2~1+Acclm+Temp+LMass+Sex+Range+Acclm*Temp*Range,
random=random, data=dataset, family="gaussian",
ginverse=list(species=treeAinv), prior=prior, nitt=300000, burnin=25000,
thin = 1000, verbose=FALSE)



Thank you kindly for your help.



Tricia

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Mon Jan 26 09:20:41 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 26 Jan 2015 08:20:41 +0000
Subject: [R-sig-ME] within subjects, 3 conditions, 3 lines
In-Reply-To: <CAOZp1okQYvrvBDJqiyR-PWf+BuZOwUxNX5omot4qYBMfO0722A@mail.gmail.com>
References: <CAOZp1onebLYvi6sC_oGh=q5YUO1bD+hC-U8tbXeGZ8iyY27Pgg@mail.gmail.com>
	<CAOZp1okyHwXnCk_ALQPPc3ccdiSyCKmfP1PgHPm2D-VxrdBQiQ@mail.gmail.com>
	<CAOZp1onuPfYqCq6rF4HQjZUExwbLWiBeH0HP6GnFYjfra6T6Ng@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA742701096FFE11@inbomail.inbo.be>
	<CAOZp1o=bXYRo9D_QvL9Zpk5xOS3_j-hO9m2K=xiGeojiK_HBmA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74270109700600@inbomail.inbo.be>
	<CAOZp1okd2eC1TWXG7aughOZQBsrmoXV-q=CL=L5C6F0RAcEmGA@mail.gmail.com>,
	<CAOZp1okQYvrvBDJqiyR-PWf+BuZOwUxNX5omot4qYBMfO0722A@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74270109703F1B@inbomail.inbo.be>

I made a Gist (https://gist.github.com/ThierryO/58ebc3c08da4fec58fb4) with a working example to simulate data. Note that the standard errors for the fixed effects of the mixed model are larger than those of the linear model.

Best regards,


ir. Thierry Onkelinx

Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest

team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25

1070 Anderlecht

Belgium

+ 32 2 525 02 51

+ 32 54 43 61 85

Thierry.Onkelinx at inbo.be


www.inbo.be


To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment
 died of. ~ Sir Ronald Aylmer Fisher


The plural of anecdote is not data. ~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey






Van: Stanislav Aggerwal [stan.aggerwal at gmail.com]

Verzonden: zondag 25 januari 2015 14:00

Aan: ONKELINX, Thierry

CC: r-sig-mixed-models at r-project.org

Onderwerp: Re: [R-sig-ME] within subjects, 3 conditions, 3 lines















Thierry, thanks for your help, but your model is completely different from what I want, so far as I can tell.






The model I want to fit is this. Each subject produces 3 lines, one for each condition



y = b1 + b2*x + error  #condition a


y = b3 + b4*x + error # condition b


y = b5 + b6*x + error #condition c


Within each subject, these three lines have differing slopes and intercepts. For each subject, each parameter (b1 to pick an example) is not identical to that of other subjects but is similar to that from other subjects.





The intercepts, b1, b3, and b5 vary between subjects. Each subject's b1, b3, and b5 is randomly sampled from N(p_i,sd_i) where p_i is the population value for each of the 3 parameters



The intercepts, b2, b4, and b6 vary between subjects. Each subject's b2, b4, and b6 is randomly sampled from N(p_i,sd_i) where p_i is the population value for each of the 3 parameters.





In my simulations I used params a1-a6 which are the R parametrisation used in fitting linear models, instead of b1-b6. E.g. a2 = b1+b2











So far as I can tell (and I looked hard), my code is producing the right sort of simulated data. And these simulated data look similar to my real data.





If we pretend that subjects is a fixed effect, we have


lm(y ~ x*cond*subj)


A different slope and intercept for each condition and each subject.





Thanks again,

Bill











On Sat, Jan 24, 2015 at 10:35 AM, Stanislav Aggerwal
<stan.aggerwal at gmail.com> wrote:



Thanks Thierry!





Stan






On Thu, Jan 22, 2015 at 4:16 PM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:


Dear Stan,



Please keep the mailing in cc.  You use rnorm(nsubj,mean=0,sd=.1) as the random intercept. However rnorm() will be evaluate again in a1, a2, ..., a6 and thus yielding different values of the random intercept in a1, a2, ..., a6. You want



Rf <- rnorm(nsubj,mean=0,sd=.1)

a1<- rep(1+ rf,each=5)  #inta=1

a2<- rep(1 + rf,each=5)  #intb-inta=2-1=1



Note that is more clear to define the fixed, random effect and noise separately and add those components in a separate step.



Best regards,



Thierry



ir. Thierry Onkelinx

Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest

team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance

Kliniekstraat 25

1070 Anderlecht

Belgium

+ 32 2 525 02 51

+ 32 54 43 61 85

Thierry.Onkelinx at inbo.be

www.inbo.be



To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.

~ Sir Ronald Aylmer Fisher



The plural of anecdote is not data.

~ Roger Brinner



The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.

~ John Tukey



Van: Stanislav Aggerwal [mailto:stan.aggerwal at gmail.com]

Verzonden: donderdag 22 januari 2015 12:25

Aan: ONKELINX, Thierry

Onderwerp: Re: [R-sig-ME] within subjects, 3 conditions, 3 lines





Thanks Thierry for your help. Could I get some clarification please?





You get the right answer for the wrong question. Because you have a bug in the code that simulates the data. You added a second noise term instead of a random intercept. Hint: set all parameters not related to the random intercept to 0 in a1 to a6. Then a1
 to a6 should be equal.



There are 30*3 (subjects * conditions) random intercepts. Also 30 random slopes. There are 6 params because there are 3 conditions: (slope and intercept)*3



a1-a6 have the population values: 1, 1, 2, 3, -1, -2

Then each subject has a1-a6 values that randomly vary about these population values.

It is the model I meant, and it describes my data.

Are you saying I implemented it wrong? I don't understand how.



a1<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #inta=1

a2<- rep(1+rnorm(nsubj,mean=0,sd=.1),each=5)  #intb-inta=2-1=1

a3<- rep(2+rnorm(nsubj,mean=0,sd=.1),each=5)  #intc-inta=3-1=2

a4<- rep(3+rnorm(nsubj,mean=0,sd=.1),each=5)  #slopea=3

a5<- rep(-1+rnorm(nsubj,mean=0,sd=.1),each=5) #slopeb-slopea

a6<- rep(-2+rnorm(nsubj,mean=0,sd=.1),each=5) #slopec-slopea



y[cond=="a"]<-a1    + a4*x[cond=="a"]

y[cond=="b"]<-a1+a2 + (a4+a5)*x[cond=="b"]

y[cond=="c"]<-a1+a3 + (a4+a6)*x[cond=="c"]



Then I add errors. For each subject the data are not perfectly described by a line, due to measurement error. If I did not add this, the only source of noise in the model is due to the variation in slopes and intercepts between subjects.

Are you saying I should eliminate these measurement errors?

This is the model I intend:

For each subject in each condition:

y = int + slope*x + error

each subject has 3 lines (for a, b, c) with params a1-a6



#autocorrelated errors

for(i in 1:nsubj)

  {

  y[subj==i]<-y[subj==i] +

as.numeric(filter(rnorm(5*3,mean=0,sd=.5),filter=0.5,method="recursive"))

  }



If you look at the plot I think it looks correct.

Thanks very much!

Cheers

Stan





Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>




























Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From M.Fairbrother at bristol.ac.uk  Mon Jan 26 09:28:02 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 26 Jan 2015 02:28:02 -0600
Subject: [R-sig-ME] BLUPs of the random effects from MCMCglmm
Message-ID: <CAAH-yP-Eq14vUEu_P04xX7r-GhasVTeWcuvMTbAJ2yk-OfLGkg@mail.gmail.com>

Dear all,

I'm trying to understand how to extract BLUPs of the random effects from
LMMs, and GLMMs, fitted with MCMCglmm.

To use a simple example:
library(lme4)
library(MCMCglmm)
data(PlodiaPO)
m2 <- lmer(PO ~ 1 + (1 | FSfamily), PlodiaPO)
MC2 <- MCMCglmm(PO ~ 1, random = ~ FSfamily, data=PlodiaPO, verbose=F, pr=T)

The help file for "ranef" in the lme4 package says this function
"extract[s] the conditional modes of the random effects from a fitted model
object. For linear mixed models the conditional modes of the random effects
are also the conditional means."

Bracketing some conceptual fuzziness, threads like <
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q1/000128.html>
suggest "ranef" yields BLUPs.

But how do I get the equivalent from an MCMCglmm object (like MC2 here)?
Two possibilities:
colMeans(MC2$Sol[,-1])
or
posterior.mode(MC2$Sol[,-1])

In the thread <
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/017565.html>,
Jarrod says that, with some conditions, "The marginal posterior modes of
the random effects should coincide with BLUPs...". So does that mean
"posterior.mode" is the function to use here?

And given the statement about modes and means in the statement about ranef
above, alternatively, would colMeans work with MCMCglmm in the case of a
LMM, but not GLMM?

In this simple example, the three approaches yield very similar results:
cor(cbind(ranef(m2)$FSfamily, colMeans(MC2$Sol[,-1]),
posterior.mode(MC2$Sol[,-1])))

But maybe that doesn't always happen.

(I also came across the thread <
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015947.html>, but
that raises some broader questions of principle which I'll park for now.)

Any assistance would be greatly appreciated.

Many thanks,
Malcolm

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Jan 26 10:25:16 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 26 Jan 2015 09:25:16 +0000
Subject: [R-sig-ME] BLUPs of the random effects from MCMCglmm
In-Reply-To: <CAAH-yP-Eq14vUEu_P04xX7r-GhasVTeWcuvMTbAJ2yk-OfLGkg@mail.gmail.com>
References: <CAAH-yP-Eq14vUEu_P04xX7r-GhasVTeWcuvMTbAJ2yk-OfLGkg@mail.gmail.com>
Message-ID: <20150126092516.61573i1lsim0eeck@www.staffmail.ed.ac.uk>

Hi Malcolm,

BLUPs are exactly equivalent to the posterior mode (and posterior  
mean) random effects in a LMM when the variance components are known.  
When they are known the joint distribution of the random effects is  
multivariate normal and so the mean and mode coincide. More generally,  
BLUPs will not exactly coincide with the marginal mode/means from  
MCMCglmm, because their distribution is marginal with respect to the  
variance components rather than being conditional on them. My guess is  
that they are very close in practice though. The posterior mean has  
lower Monte Carlo error than the posterior mode, so if the marginal  
distributions are symmetric I would use the posterior mean.

Cheers,

Jarrod





Quoting Malcolm Fairbrother <M.Fairbrother at bristol.ac.uk> on Mon, 26  
Jan 2015 02:28:02 -0600:

> Dear all,
>
> I'm trying to understand how to extract BLUPs of the random effects from
> LMMs, and GLMMs, fitted with MCMCglmm.
>
> To use a simple example:
> library(lme4)
> library(MCMCglmm)
> data(PlodiaPO)
> m2 <- lmer(PO ~ 1 + (1 | FSfamily), PlodiaPO)
> MC2 <- MCMCglmm(PO ~ 1, random = ~ FSfamily, data=PlodiaPO, verbose=F, pr=T)
>
> The help file for "ranef" in the lme4 package says this function
> "extract[s] the conditional modes of the random effects from a fitted model
> object. For linear mixed models the conditional modes of the random effects
> are also the conditional means."
>
> Bracketing some conceptual fuzziness, threads like <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q1/000128.html>
> suggest "ranef" yields BLUPs.
>
> But how do I get the equivalent from an MCMCglmm object (like MC2 here)?
> Two possibilities:
> colMeans(MC2$Sol[,-1])
> or
> posterior.mode(MC2$Sol[,-1])
>
> In the thread <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/017565.html>,
> Jarrod says that, with some conditions, "The marginal posterior modes of
> the random effects should coincide with BLUPs...". So does that mean
> "posterior.mode" is the function to use here?
>
> And given the statement about modes and means in the statement about ranef
> above, alternatively, would colMeans work with MCMCglmm in the case of a
> LMM, but not GLMM?
>
> In this simple example, the three approaches yield very similar results:
> cor(cbind(ranef(m2)$FSfamily, colMeans(MC2$Sol[,-1]),
> posterior.mode(MC2$Sol[,-1])))
>
> But maybe that doesn't always happen.
>
> (I also came across the thread <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015947.html>, but
> that raises some broader questions of principle which I'll park for now.)
>
> Any assistance would be greatly appreciated.
>
> Many thanks,
> Malcolm
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Jan 26 10:37:39 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 26 Jan 2015 09:37:39 +0000
Subject: [R-sig-ME] Priors for us(trait):units structure in MCMCglmm
 model. Error message - help needed.
In-Reply-To: <CAO=0ZJUR6ncdngJCrd-O+w5YOEb7NLkxtdq8-xDfZ1_or4tJEQ@mail.gmail.com>
References: <CAO=0ZJUR6ncdngJCrd-O+w5YOEb7NLkxtdq8-xDfZ1_or4tJEQ@mail.gmail.com>
Message-ID: <20150126093739.96204hlmy25fv7k0@www.staffmail.ed.ac.uk>

Hi,

If temp is continuous, you are trying to estimate a 2X2 covariance  
matrix for the random effects and a scalar variance for the residuals.  
In general, I use priors of the form:

prior<-list(G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),  
alpha.V=diag(2)*1000)), R=list(V=diag(1), nu=0.002))

If temp is categorical then you are trying to estimate a 3X3  
covariance matrix for the random effects. Personally, I would opt for  
continuous temp, at least in the random effect part of the model.

You almost certainly want random=~us(1+Temp):species rather than  
random=~us(1+Temp):Range. It sounds like Temp:Range in the fixed part  
of the model is the key term you want to test (do large ranging  
species respond differently to temp). random=~us(1+Temp):species deals  
with the fact that species may vary in their response to temperature  
independently of anything to do with their ranges.

You don't have many species so don't expect to get very precise  
estimates of the covariance matrix, particularly given the species  
effects are assumed to be correlated due to their shared phylogenetic  
history.

Cheers,

Jarrod




Quoting Tricia Markle <markl033 at umn.edu> on Mon, 26 Jan 2015 00:05:20 -0600:

> Hello,
>
>
>
> I am hoping that someone could provide some thoughts on an appropriate
> prior set-up for my model which uses a ?us(trait):units? structure in an
> MCMCglmm model with repeat measures and a phylogeny component.
>
>
>
> I am assuming that I need to use uninformative proper priors with a set-up
> something along the lines of:
>
>
>
> prior<-list(G=list(G1=list(V=diag(#), nu=#)), R=list(V=diag(#), n=#))
>
>
>
> I have spent a considerable amount of time working on this (looking at help
> guides, posted examples etc.) and regardless of what numbers I try, I
> continue to get the following error message:
>
>
>
> Error in priorformat(if (NOpriorG) { :
>
>   V is the wrong dimension for some prior$G/prior$R elements
>
>
>
> Data Details: I have 308 individual salamanders, each acclimated at 3
> different temperatures (6,14,22C). Then for each acclimation temperature
> metabolic rate is measured at 3 test temperatures (5, 15, 25C) (so total of
> 9 trials per individual).
>
>
>
> I am attempting to compare slopes of the test temperatures between
> acclimation temperatures. There are 18 species, but my main question is
> whether large ranging species have greater differences in slope between
> acclimation temps than narrow ranging species (species are divided into
> those with small (1) versus large (2) ranges).
>
>
>
> Here is the rest of my code:
>
>
>
> dataset<-read.csv(file="RespData.csv", head=TRUE)
>
> dataset$Range<-as.factor(dataset$Range)
>
> str(dataset)
>
> #Phylogeny Component
>
> tree<-read.tree("Plethodontidae_comb61_PL.phy")
>
> species<-c("D._carolinensis", "D._fuscus", "D._imitator", "D._ochrophaeus",
> "D._ocoee", "D._orestes",  "D._monticola_A",  "D._santeetlah",
> "P_cinereus", "P_cylindraceus", "P_glutinosus", "P_hubrichti",
> "P_montanus", "P_punctatus", "P_richmondi", "P_teyahalee", "P_virginia",
> "P_wehrlei")
>
> pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
> tree$tip.label)])# Prune tree to just include species of interest
>
> sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node") #rename
> nodes to be unique
>
>
>
> treeAinv<-inverseA(sptree, nodes="TIPS")$Ainv
>
>
>
> random=~us(1+Temp):Range
>
>
>
> #note, I could alternatively use random=~us(1+Temp):species, but results
> are likely harder to interpret
>
>
>
> prior<-list(G=list(G1=list(V=diag(#), nu=#)), R=list(V=diag(#), n=#))
>
>
>
> model1<-MCMCglmm(LVO2~1+Acclm+Temp+LMass+Sex+Range+Acclm*Temp*Range,
> random=random, data=dataset, family="gaussian",
> ginverse=list(species=treeAinv), prior=prior, nitt=300000, burnin=25000,
> thin = 1000, verbose=FALSE)
>
>
>
> Thank you kindly for your help.
>
>
>
> Tricia
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ukoether at uke.de  Mon Jan 26 11:25:28 2015
From: ukoether at uke.de (=?windows-1252?Q?Ulf_K=F6ther?=)
Date: Mon, 26 Jan 2015 11:25:28 +0100
Subject: [R-sig-ME] plotting gams in mgcv
In-Reply-To: <BAY173-W23B9B1F113670B24797CAFDC340@phx.gbl>
References: <BAY173-W23B9B1F113670B24797CAFDC340@phx.gbl>
Message-ID: <54C61618.8050502@uke.de>

Dear John,

because no one answered your question yet, I give it a try. I am no
expert, so in case someone knows an answer via just tweaking the
plot.gam-function, please come forward..!

Here is a solution making use of the predict.gam-function and ggplot2:

# Generate data, example from help files of mgcv 1.8-4, function "s":
library(mgcv)

set.seed(0)
n <- 200
sig2 <- 4
x1 <- runif(n, 0, 1)
x2 <- runif(n, 0, 1)
x3 <- runif(n, 0, 1)
fac <- c(rep(1, n/2), rep(2, n/2)) # create factor
fac.1 <- rep(0, n) + (fac == 1)
fac.2 <- 1 - fac.1 # and dummy variables
fac <- as.factor(fac)
f1 <- exp(2 * x1) - 3.75887
f2 <- 0.2 * x1^11 * (10 * (1 - x1))^6 + 10 * (10 * x1)^3 * (1 - x1)^10
f <- f1 * fac.1 + f2 * fac.2 + x2
e <- rnorm(n, 0, sqrt(abs(sig2)))
y <- f + e

# Putting everything in a dataframe:

data <- data.frame(cbind(fac, x1, x2, y))
colnames(data) <- c("fac", "x1", "x2", "y")
data$fac <- factor(data$fac)

# Housekeeping:
rm(e, f, f1, f2, fac, fac.1, fac.2, n, sig2, x1, x2, x3, y)

# Model fitting:
b <- gam(y ~ fac + s(x1, by = fac) + x2, data = data) 
summary(b)
plot(b, pages = 1, shade = TRUE)

# Plotting with predict and ggplot2:
library(ggplot2)

pred <- expand.grid(fac = factor(c(1,2)),
                    x2 = mean(data$x2),
                    x1 = seq(from = min(data$x1), 
                             to = max(data$x1),
                             length = 100))
# Ordering works better in regard of the split of the predictions later on
pred <- pred[order(pred$fac),] 

# using the predict.gam-function with type = "terms" is essential:
predNew <- predict(b, newdata = pred, type = "terms", se.fit = TRUE)

# Notice the manual split of the fit and the se to get both factor levels
# in one variable:
predPlot <- data.frame(cbind(pred.fit = c(predNew$fit[1:100, "s(x1):fac1"],
                                          predNew$fit[101:200, "s(x1):fac2"]),
                             pred.se = c(predNew$se.fit[1:100, "s(x1):fac1"],
                                         predNew$se.fit[101:200, "s(x1):fac2"]),
                             pred))

# CIs:
predPlot$CI_Low <- predPlot$pred.fit - qnorm(0.975) * predPlot$pred.se
predPlot$CI_High <- predPlot$pred.fit + qnorm(0.975) * predPlot$pred.se

# Plotting with a coloured rug to highlight the difference:
ggplot(predPlot, aes(y = pred.fit, x = x1)) + geom_line() + 
    facet_grid(. ~ fac) + theme_bw() +
    geom_ribbon(aes(x = x1, ymin = CI_Low, ymax = CI_High), alpha = 0.3) +
    geom_rug(data = data, aes(y = y, x = x1, colour = fac),
             size = 0.6, alpha = 0.5, sides = "b") + 
    theme(legend.position = "none")


Good luck!


Am 25.01.2015 um 22:36 schrieb john benson:
> Hi,
> I am running a GAM that has a smooth x factor interaction accomplished with the "by" function.
> The model looks like this where X1 is a continuous smooth term and X2 is a categorical factor variable with 2 levels:
> Gam1<-gam(y~s(X1, by = X2) + X2, data=datum)summary(Gam1)plot (Gam1)
> The plot of this model gives separate figures for the separate smooth functions for each level (n=2) of the factor term.  I would like the rug plot for each figure to show only the locations of the covariate values along the x-axis that are specific to each level of the factor term.  
> Instead, the gam plot gives me identical rug plots (with all covariate locations across both factor levels) for both of the 2 plots of the separate smooth functions.
> Does anyone know if it is possible to only display the rug plot for covariate values associated with correct level of the factor variable for each of these 2 figures? 
> Many thanks for any help with this!
> Best,
> John 		 	   		  
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From dianacaro0918 at hotmail.com  Mon Jan 26 15:58:46 2015
From: dianacaro0918 at hotmail.com (Diana Caro)
Date: Mon, 26 Jan 2015 09:58:46 -0500
Subject: [R-sig-ME] informative priors in MCMCglmm
Message-ID: <SNT151-W940D75F7F8A7A929E8340CB3350@phx.gbl>

Hi!
I want to estimate variance components for four weight traits in a multivariate model.If I have prior information of variances or heritabilities (from literature), how can I incorporate this information in a prior?

Thanks

Diana 		 	   		  
	[[alternative HTML version deleted]]


From steve.walker at utoronto.ca  Tue Jan 27 04:26:06 2015
From: steve.walker at utoronto.ca (Steve Walker)
Date: Mon, 26 Jan 2015 22:26:06 -0500
Subject: [R-sig-ME] LogLikelihood
In-Reply-To: <14b2222ab7c.bbonit@tin.it>
References: <14b2222ab7c.bbonit@tin.it>
Message-ID: <54C7054E.9040104@utoronto.ca>

Hope this helps clear things up:

with(getME(mod0, c("n", "L", "X", "beta", "Z", "Lambda", "u", "y")), {
     mu <- as.numeric((X %*% beta) + (Z %*% Lambda %*% u))
     r2 <- sum((y-mu)^2) + sum(u^2)
     ldL2 <- 2*determinant(L, logarithm = TRUE)$modulus
     -0.5*(ldL2 + n*(1 + log((2*pi*r2)/n)))
})
logLik(mod0)

Other useful references include the lme4pureR package and the lmer paper:

https://github.com/lme4/lme4pureR/blob/master/R/JSS.R
http://arxiv.org/pdf/1406.5823v1.pdf

Equation 34 of the paper is minus twice the log-likelihood.

Cheers,
Steve


On 2015-01-25 12:27 PM, bbonit at tin.it wrote:
>
>
> Dear list, my name is Gianluca Bonitta
> I'm trying to build up the Loglikelihood of the following model.
> For check it I had used logLik(mod0,REML=F) like "gold standard"
> Like You see there is a difference   # diff   logLik(mod0,REML=F) - mylog = 0.6339805
> Can somebody help to resolve my mistake ?
> Maybe professor Bolker or professor Bates that are the "fathers" of lme4 pack
> thank You in advance
> Best
> Gianluca
>
> ########################################################################################
> library(lme4)
> data(sleepstudy)
> dat <- sleepstudy[ (sleepstudy$Days %in% 0:4) &amp; (sleepstudy$Subject %in% 331:333) ,]
> colnames(dat) <- c("y", "x", "group")
> mod0 <- lmer( y ~ 1 + x  +( x | group ), data = dat,REML="F")
> ########################################################################################
>
>    q <- 2                                          # number of random effects
>    n <- nrow(dat)                              # number of individuals
>    m <- length(unique(dat$group))      # number of groups
>    Y <- dat$y                                    # response vector
>    R <- diag(1,nrow(dat))*summary(mod0)$sigma^2    # covariance matrix of residuals
>    beta <- as.numeric(fixef(mod0))                 # fixed effects vector (p x 1)
>    a<-rep(c(597.1903,60.05023),m)                  # variance rand effects
>    ranef(mod0)$group
>    b <-c(17.94432, -3.753130,-33.31148, 10.294328,15.36716, -6.541198) # random effect estimated
>    D <-matrix(-0.97,6,6)                           # random effect estimated correlation
>    diag(D) <-a
>    X <- cbind(rep(1,n), dat$x)                     # model matrix of fixed effects (n x p)
>    Z.sparse<- getME(mod0,"Z")                   # model matrix of random effect (sparse format)
>    Z <- as.matrix(Z.sparse)
>    V <-Z%*% D %*% t(Z) + R                   # (total) covariance matrix of Y
>    # check: values in Y can be perfectly matched using lmer's information
>    Y.test <- X %*% beta + Z %*% b + resid(mod0)
>    cbind(Y, Y.test)
>    mu = X %*% beta + Z %*% b
> ###############################################################################################
>     ll = -n/2*log(2*pi) - sum(log(diag(chol(V)))) -  .5 * t(Y- mu) %*% chol2inv(chol(V)) %*% (Y-mu);
>     logLik(mod0,REML=F)
>     ll
> ####################################?
> # diff   'log Lik.' 0.6339805 (df=6)
>
>     logLik(mod0,REML=F) -ll
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From xavier.paoletti at curie.fr  Tue Jan 27 09:45:48 2015
From: xavier.paoletti at curie.fr (xavier.paoletti at curie.fr)
Date: Tue, 27 Jan 2015 09:45:48 +0100
Subject: [R-sig-ME] c++ exception (unknown reason) when using an offset of
	the slope with glmer
Message-ID: <OF159E51D6.7ED45B93-ONC1257DDA.0030231F@curie.net>


Dear all,

I am new on this forum and I hope my request follows the right format.

I use R 3.1.2 and lme1.7 on a mac OS X (snow leopard) or Windows OS.

I try to fit a longitudinal logistic mixed effect model on dose-time
response data where the response is measured several times at the same
dose. The probability of response increases with the dose.
There is a set of discrete doses (let's say 6) but most of the data are
measured at 1 or 2 doses.

I use a very simple logstic model with a random intercept and the dose
effect.
In the simplest case, there is not time effect.
Furthermore, I would like to set the slope of the dose to some value using
offset slope=1.5.

The command line,
glmer(DLTb ~ offset(slope*dose) + (1 | patid),
family=binomial,data=dataAllCRM,nAGQ=10)
gives the following error:
Under Mac OSX: (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L,
control = glmerControl(),  :
  c++ exception (unknown reason)

Under Windows: Error: (maxstephalfit) PIRLS step-halvings failed to reduce
deviance in pwrssUpdate

Whatever the value of the offset, I get the same error.
If I remove the offset or if I remove the variable, some estimates are
obtained.

Please find attached an example of dataset as an illustration; I get the
same error for all tested datasets.


Thank you very much for your help.

Best regards,

Xavier

From bbonit at tin.it  Tue Jan 27 10:31:39 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Tue, 27 Jan 2015 10:31:39 +0100 (CET)
Subject: [R-sig-ME] Loglikelihood
Message-ID: <14b2abb65d9.bbonit@tin.it>

 Many thanks, professor Walker.
 I'm reading the papers that you suggest me.
 I think that  the discrepance  rise inside a variance components implemetation ... (it was my suspect)
 Thank You again 
  Sorry for noise 
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jan 27 14:14:05 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 27 Jan 2015 08:14:05 -0500
Subject: [R-sig-ME] c++ exception (unknown reason) when using an offset
 of the slope with glmer
In-Reply-To: <OF159E51D6.7ED45B93-ONC1257DDA.0030231F@curie.net>
References: <OF159E51D6.7ED45B93-ONC1257DDA.0030231F@curie.net>
Message-ID: <CABghstS=q8aUDUP4J483G+rDbNybHHCUYumHHfm=TA2z5dcVhw@mail.gmail.com>

  Your posted data set got removed by the mailing list machinery.  Can
you post it somewhere publicly accessible?


On Tue, Jan 27, 2015 at 3:45 AM,  <xavier.paoletti at curie.fr> wrote:
>
> Dear all,
>
> I am new on this forum and I hope my request follows the right format.
>
> I use R 3.1.2 and lme1.7 on a mac OS X (snow leopard) or Windows OS.
>
> I try to fit a longitudinal logistic mixed effect model on dose-time
> response data where the response is measured several times at the same
> dose. The probability of response increases with the dose.
> There is a set of discrete doses (let's say 6) but most of the data are
> measured at 1 or 2 doses.
>
> I use a very simple logstic model with a random intercept and the dose
> effect.
> In the simplest case, there is not time effect.
> Furthermore, I would like to set the slope of the dose to some value using
> offset slope=1.5.
>
> The command line,
> glmer(DLTb ~ offset(slope*dose) + (1 | patid),
> family=binomial,data=dataAllCRM,nAGQ=10)
> gives the following error:
> Under Mac OSX: (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L,
> control = glmerControl(),  :
>   c++ exception (unknown reason)
>
> Under Windows: Error: (maxstephalfit) PIRLS step-halvings failed to reduce
> deviance in pwrssUpdate
>
> Whatever the value of the offset, I get the same error.
> If I remove the offset or if I remove the variable, some estimates are
> obtained.
>
> Please find attached an example of dataset as an illustration; I get the
> same error for all tested datasets.
>
>
> Thank you very much for your help.
>
> Best regards,
>
> Xavier
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From xavier.paoletti at curie.fr  Tue Jan 27 14:24:01 2015
From: xavier.paoletti at curie.fr (xavier.paoletti at curie.fr)
Date: Tue, 27 Jan 2015 14:24:01 +0100
Subject: [R-sig-ME] c++ exception (unknown reason) when using an offset
 of the slope with glmer
In-Reply-To: <CABghstS=q8aUDUP4J483G+rDbNybHHCUYumHHfm=TA2z5dcVhw@mail.gmail.com>
References: <OF159E51D6.7ED45B93-ONC1257DDA.0030231F@curie.net>
	<CABghstS=q8aUDUP4J483G+rDbNybHHCUYumHHfm=TA2z5dcVhw@mail.gmail.com>
Message-ID: <OF563A2E19.4C3ACFE9-ONC1257DDA.00493E45-C1257DDA.00499C41@curie.net>

Thanks for your attention. 

Here there are. 180 rows, 4 columns + obs number.
Obs    patid cycle dose DLT
1       1     1  4.1   0
2       2     1  4.8   0
3       3     1  5.3   0
4       4     1  5.7   0
5       5     1  6.0   1
6       6     1  5.7   1
7       7     1  5.7   0
8       8     1  5.3   0
9       9     1  5.3   0
10     10     1  5.7   0
11     11     1  5.3   0
12     12     1  5.3   0
13     13     1  5.3   0
14     14     1  5.3   0
15     15     1  5.7   0
16     16     1  5.3   0
17     17     1  5.3   0
18     18     1  5.3   0
19     19     1  5.3   0
20     20     1  5.7   0
21     21     1  5.7   1
22     22     1  5.7   1
23     23     1  5.7   0
24     24     1  5.3   0
25     25     1  5.3   0
26     26     1  5.3   0
27     27     1  5.3   1
28     28     1  5.7   0
29     29     1  5.7   1
30     30     1  5.7   0
31      1     2  4.1   0
32      2     2  4.8   0
33      3     2  5.3   0
34      4     2  5.7   0
35      5     2  6.0   0
36      6     2  5.7   0
37      7     2  5.7   1
38      8     2  5.3   0
39      9     2  5.3   0
40     10     2  5.7   0
41     11     2  5.3   0
42     12     2  5.3   0
43     13     2  5.3   0
44     14     2  5.3   0
45     15     2  5.7   0
46     16     2  5.3   0
47     17     2  5.3   0
48     18     2  5.3   0
49     19     2  5.3   0
50     20     2  5.7   0
51     21     2  5.7   0
52     22     2  5.7   0
53     23     2  5.7   1
54     24     2  5.3   0
55     25     2  5.3   0
56     26     2  5.3   0
57     27     2  5.3   0
58     28     2  5.7   0
59     29     2  5.7   0
60     30     2  5.7   1
61      1     3  4.1   0
62      2     3  4.8   0
63      3     3  5.3   0
64      4     3  5.7   0
65      5     3  6.0   1
66      6     3  5.7   1
67      7     3  5.7   1
68      8     3  5.3   0
69      9     3  5.3   0
70     10     3  5.7   0
71     11     3  5.3   0
72     12     3  5.3   0
73     13     3  5.3   0
74     14     3  5.3   0
75     15     3  5.7   0
76     16     3  5.3   0
77     17     3  5.3   0
78     18     3  5.3   0
79     19     3  5.3   1
80     20     3  5.7   0
81     21     3  5.7   0
82     22     3  5.7   0
83     23     3  5.7   1
84     24     3  5.3   0
85     25     3  5.3   0
86     26     3  5.3   1
87     27     3  5.3   0
88     28     3  5.7   0
89     29     3  5.7   0
90     30     3  5.7   1
91      1     4  4.1   0
92      2     4  4.8   0
93      3     4  5.3   0
94      4     4  5.7   0
95      5     4  6.0   0
96      6     4  5.7   0
97      7     4  5.7   0
98      8     4  5.3   0
99      9     4  5.3   0
100    10     4  5.7   0
101    11     4  5.3   1
102    12     4  5.3   1
103    13     4  5.3   0
104    14     4  5.3   0
105    15     4  5.7   1
106    16     4  5.3   0
107    17     4  5.3   0
108    18     4  5.3   0
109    19     4  5.3   0
110    20     4  5.7   0
111    21     4  5.7   0
112    22     4  5.7   0
113    23     4  5.7   0
114    24     4  5.3   0
115    25     4  5.3   0
116    26     4  5.3   0
117    27     4  5.3   0
118    28     4  5.7   0
119    29     4  5.7   0
120    30     4  5.7   0
121     1     5  4.1   0
122     2     5  4.8   0
123     3     5  5.3   0
124     4     5  5.7   0
125     5     5  6.0   0
126     6     5  5.7   1
127     7     5  5.7   0
128     8     5  5.3   1
129     9     5  5.3   0
130    10     5  5.7   0
131    11     5  5.3   0
132    12     5  5.3   0
133    13     5  5.3   1
134    14     5  5.3   0
135    15     5  5.7   0
136    16     5  5.3   0
137    17     5  5.3   0
138    18     5  5.3   0
139    19     5  5.3   0
140    20     5  5.7   0
141    21     5  5.7   1
142    22     5  5.7   0
143    23     5  5.7   0
144    24     5  5.3   0
145    25     5  5.3   0
146    26     5  5.3   0
147    27     5  5.3   0
148    28     5  5.7   0
149    29     5  5.7   0
150    30     5  5.7   0
151     1     6  4.1   0
152     2     6  4.8   0
153     3     6  5.3   0
154     4     6  5.7   1
155     5     6  6.0   1
156     6     6  5.7   0
157     7     6  5.7   0
158     8     6  5.3   0
159     9     6  5.3   0
160    10     6  5.7   1
161    11     6  5.3   0
162    12     6  5.3   0
163    13     6  5.3   0
164    14     6  5.3   0
165    15     6  5.7   0
166    16     6  5.3   0
167    17     6  5.3   0
168    18     6  5.3   0
169    19     6  5.3   0
170    20     6  5.7   1
171    21     6  5.7   1
172    22     6  5.7   0
173    23     6  5.7   0
174    24     6  5.3   0
175    25     6  5.3   0
176    26     6  5.3   1
177    27     6  5.3   0
178    28     6  5.7   0
179    29     6  5.7   1
180    30     6  5.7   0




Ben Bolker <bbolker at gmail.com> 
27/01/2015 14:14

A
<xavier.paoletti at curie.fr>
cc
"r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Objet
Re: [R-sig-ME] c++ exception (unknown reason) when using an offset of the 
slope with glmer






  Your posted data set got removed by the mailing list machinery.  Can
you post it somewhere publicly accessible?


On Tue, Jan 27, 2015 at 3:45 AM,  <xavier.paoletti at curie.fr> wrote:
>
> Dear all,
>
> I am new on this forum and I hope my request follows the right format.
>
> I use R 3.1.2 and lme1.7 on a mac OS X (snow leopard) or Windows OS.
>
> I try to fit a longitudinal logistic mixed effect model on dose-time
> response data where the response is measured several times at the same
> dose. The probability of response increases with the dose.
> There is a set of discrete doses (let's say 6) but most of the data are
> measured at 1 or 2 doses.
>
> I use a very simple logstic model with a random intercept and the dose
> effect.
> In the simplest case, there is not time effect.
> Furthermore, I would like to set the slope of the dose to some value 
using
> offset slope=1.5.
>
> The command line,
> glmer(DLTb ~ offset(slope*dose) + (1 | patid),
> family=binomial,data=dataAllCRM,nAGQ=10)
> gives the following error:
> Under Mac OSX: (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 
0L,
> control = glmerControl(),  :
>   c++ exception (unknown reason)
>
> Under Windows: Error: (maxstephalfit) PIRLS step-halvings failed to 
reduce
> deviance in pwrssUpdate
>
> Whatever the value of the offset, I get the same error.
> If I remove the offset or if I remove the variable, some estimates are
> obtained.
>
> Please find attached an example of dataset as an illustration; I get the
> same error for all tested datasets.
>
>
> Thank you very much for your help.
>
> Best regards,
>
> Xavier
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- section suivante --------------
Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : dataEx_Glmer.txt
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150127/3652cc70/attachment.txt>

From celia.rezouki at etu.univ-lyon1.fr  Wed Jan 28 10:17:18 2015
From: celia.rezouki at etu.univ-lyon1.fr (REZOUKI CELIA p1314815)
Date: Wed, 28 Jan 2015 09:17:18 +0000
Subject: [R-sig-ME] Variance components analysis using a GLMM,
 how to insert a variance-covariance matrix in the model ?
Message-ID: <F3AABEFCC68A3942B173A79B033F7891BED8E3@mbx2010-02.univ-lyon1.fr>

Dear list,
 
We are analysing the survival rates of a mammalian species from a 
capture-mark-recapture protocol. As a biologist, the usual way to 
proceed is to analyse capture histories (raw data) with a specific 
software named MARK (http://www.phidot.org/software/mark/) to run 
capture-mark-recapture analyses.
 
Our problem is to get an estimation of a random effect of time using 
linear mixed models, not from the observed data, but from a coefficient 
vector (let's call it 'phi') representing annual estimates of the 
survival rates, and the empirical variance/covariance matrix (Rcov) 
obtained from MARK.
 
We would like to use the output of the analyse (phis and Rcov) from MARK 
in a linear mixed-model in R to extract both a variance components and 
eventually, to model linear effects of different covariates such as 
time. The response variable being a proportion, it would be best to use 
a binomial family and hence, a generalized version of the mixed models.
 
The model would look like:
- response variable: logit(phi_t), the annual survival estimated from MARK
- fixed effects : temporal trends (year entered as a covariable)
- random effects : variance in survival around the temporal trend
- Rcov, the empirical variance/covariance matrix from MARK is known and 
should be entered into the GLMM.
 
It is unclear to us whether such an analysis is doable in R or not. The 
closest we found would be to use mcmcglmm but we would need confirmation 
and somes hint to start.
 
In case you want to help, you can get a vector of estimated survival 
rates along with the empirical variance/covariance matrix returned by 
MARK from a subsample of our data here:
 
load(url("http://mammal-research.org/data/example.RData"))
 
Any help would be greatly appreciated.
 
C?lia


--

C?lia Rezouki
PhD student

UMR CNRS 5558 - LBBE
Biom?trie et Biologie ?volutive
UCB Lyon 1 - B?t. Gr?gor Mendel
43 bd du 11 novembre 1918
69622 VILLEURBANNE cedex

From Thierry.ONKELINX at inbo.be  Wed Jan 28 11:17:13 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 28 Jan 2015 10:17:13 +0000
Subject: [R-sig-ME] Variance components analysis using a GLMM,
 how to insert a variance-covariance matrix in the model ?
In-Reply-To: <F3AABEFCC68A3942B173A79B033F7891BED8E3@mbx2010-02.univ-lyon1.fr>
References: <F3AABEFCC68A3942B173A79B033F7891BED8E3@mbx2010-02.univ-lyon1.fr>
Message-ID: <AA818EAD2576BC488B4F623941DA74270109708776@inbomail.inbo.be>

Dear Celia,

Do you have just one phi per year? Note that you need multiple observations per random effect level to fit a mixed model.

How do you want to incorporate Rcov into the model. Writing the model as a mathematical expression would clarify things.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens REZOUKI CELIA p1314815
Verzonden: woensdag 28 januari 2015 10:17
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Variance components analysis using a GLMM, how to insert a variance-covariance matrix in the model ?

Dear list,

We are analysing the survival rates of a mammalian species from a capture-mark-recapture protocol. As a biologist, the usual way to proceed is to analyse capture histories (raw data) with a specific software named MARK (http://www.phidot.org/software/mark/) to run capture-mark-recapture analyses.

Our problem is to get an estimation of a random effect of time using linear mixed models, not from the observed data, but from a coefficient vector (let's call it 'phi') representing annual estimates of the survival rates, and the empirical variance/covariance matrix (Rcov) obtained from MARK.

We would like to use the output of the analyse (phis and Rcov) from MARK in a linear mixed-model in R to extract both a variance components and eventually, to model linear effects of different covariates such as time. The response variable being a proportion, it would be best to use a binomial family and hence, a generalized version of the mixed models.

The model would look like:
- response variable: logit(phi_t), the annual survival estimated from MARK
- fixed effects : temporal trends (year entered as a covariable)
- random effects : variance in survival around the temporal trend
- Rcov, the empirical variance/covariance matrix from MARK is known and should be entered into the GLMM.

It is unclear to us whether such an analysis is doable in R or not. The closest we found would be to use mcmcglmm but we would need confirmation and somes hint to start.

In case you want to help, you can get a vector of estimated survival rates along with the empirical variance/covariance matrix returned by MARK from a subsample of our data here:

load(url("http://mammal-research.org/data/example.RData"))

Any help would be greatly appreciated.

C?lia


--

C?lia Rezouki
PhD student

UMR CNRS 5558 - LBBE
Biom?trie et Biologie ?volutive
UCB Lyon 1 - B?t. Gr?gor Mendel
43 bd du 11 novembre 1918
69622 VILLEURBANNE cedex
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From jesse.whittington2 at gmail.com  Wed Jan 28 15:01:34 2015
From: jesse.whittington2 at gmail.com (Jesse Whittington)
Date: Wed, 28 Jan 2015 07:01:34 -0700
Subject: [R-sig-ME] Variance components analysis using a GLMM,
 how to insert a variance-covariance matrix in the model ?
In-Reply-To: <F3AABEFCC68A3942B173A79B033F7891BED8E3@mbx2010-02.univ-lyon1.fr>
References: <F3AABEFCC68A3942B173A79B033F7891BED8E3@mbx2010-02.univ-lyon1.fr>
Message-ID: <CAMEDFLC61ntZjo6s-Gjad8OqHX-Af7hNqCCtLw3RY0dcv0gTrQ@mail.gmail.com>

Hi C?lia,

Check out the rma function in the metafor package.  It is similar to the
RMark var.components.reml function.

I've used it for similar analyses with derived annual occupancy estimates.
You can input variance associated with each survival estimate - I'm not
sure if you can include covariance among estimates.

Here's an example of your model that I ran in RMark and metafor (sorry it's
not self contained).

# Multi-year occupancy model.
m <- try(mark(data=d.proc, ddl=d.ddl, model='RDOccupEG',
model.parameters=list(Epsilon=f.eps.t,  p=f.p), output=F, silent=T,
delete=T), silent=TRUE)
 psi <- m$results$derived
psi$year <- 0:(nrow(psi) - 1)
vcv <- m$results$derived.vcv
fixed.mat1 <- model.matrix( ~ 1 + year, data=psi)  # cannot use this with
only 2 years of data

# RMark Test for a linear Trend
m.trend <- try(var.components.reml(theta=psi$estimate, design=fixed.mat1,
vcv=vcv), silent=TRUE)  # Linear model for significant trend

# metafor
m.trend <- rma(yi = estimate, sei = se, mods = ~ year, data = psi)

Warning:  I'm not a statistician, so I cannot guarentee that what I've done
is correct.

Jesse Whittington
Wildlife Biologist
Banff National Park

On Wed, Jan 28, 2015 at 2:17 AM, REZOUKI CELIA p1314815 <
celia.rezouki at etu.univ-lyon1.fr> wrote:

> Dear list,
>
> We are analysing the survival rates of a mammalian species from a
> capture-mark-recapture protocol. As a biologist, the usual way to
> proceed is to analyse capture histories (raw data) with a specific
> software named MARK (http://www.phidot.org/software/mark/) to run
> capture-mark-recapture analyses.
>
> Our problem is to get an estimation of a random effect of time using
> linear mixed models, not from the observed data, but from a coefficient
> vector (let's call it 'phi') representing annual estimates of the
> survival rates, and the empirical variance/covariance matrix (Rcov)
> obtained from MARK.
>
> We would like to use the output of the analyse (phis and Rcov) from MARK
> in a linear mixed-model in R to extract both a variance components and
> eventually, to model linear effects of different covariates such as
> time. The response variable being a proportion, it would be best to use
> a binomial family and hence, a generalized version of the mixed models.
>
> The model would look like:
> - response variable: logit(phi_t), the annual survival estimated from MARK
> - fixed effects : temporal trends (year entered as a covariable)
> - random effects : variance in survival around the temporal trend
> - Rcov, the empirical variance/covariance matrix from MARK is known and
> should be entered into the GLMM.
>
> It is unclear to us whether such an analysis is doable in R or not. The
> closest we found would be to use mcmcglmm but we would need confirmation
> and somes hint to start.
>
> In case you want to help, you can get a vector of estimated survival
> rates along with the empirical variance/covariance matrix returned by
> MARK from a subsample of our data here:
>
> load(url("http://mammal-research.org/data/example.RData"))
>
> Any help would be greatly appreciated.
>
> C?lia
>
>
> --
>
> C?lia Rezouki
> PhD student
>
> UMR CNRS 5558 - LBBE
> Biom?trie et Biologie ?volutive
> UCB Lyon 1 - B?t. Gr?gor Mendel
> 43 bd du 11 novembre 1918
> 69622 VILLEURBANNE cedex
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Jan 28 15:45:27 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 28 Jan 2015 09:45:27 -0500
Subject: [R-sig-ME] c++ exception (unknown reason) when using an offset
 of the slope with glmer
In-Reply-To: <OF563A2E19.4C3ACFE9-ONC1257DDA.00493E45-C1257DDA.00499C41@curie.net>
References: <OF159E51D6.7ED45B93-ONC1257DDA.0030231F@curie.net>
	<CABghstS=q8aUDUP4J483G+rDbNybHHCUYumHHfm=TA2z5dcVhw@mail.gmail.com>
	<OF563A2E19.4C3ACFE9-ONC1257DDA.00493E45-C1257DDA.00499C41@curie.net>
Message-ID: <54C8F607.7090001@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Confirmed on

R Under development (unstable) (2015-01-26 r67627)
Platform: i686-pc-linux-gnu (32-bit)
lme4 1.1.8

 I will see what I can figure out.  I suspect the main problem is that
the doses range from 4 to 6, so with an offset of (1.5*dose), that
says that the logit-probability or log-odds should range from 6 to 9,
which corresponds to a baseline probability of 0.997 to 0.999.  Those
are very high probabilities: they're going to make it very hard to
make a sensible model.   Can you say a little bit more about what
you're trying to do/why an offset of 1.5 makes sense?

  Ben Bolker



On 15-01-27 08:24 AM, xavier.paoletti at curie.fr wrote:
> Thanks for your attention.
> 
> Here there are. 180 rows, 4 columns + obs number. Obs    patid
> cycle dose DLT 1       1     1  4.1   0 2       2     1  4.8   0 3
> 3     1  5.3   0 4       4     1  5.7   0 5       5     1  6.0   1 
> 6       6     1  5.7   1 7       7     1  5.7   0 8       8     1
> 5.3   0 9       9     1  5.3   0 10     10     1  5.7   0 11     11
> 1  5.3   0 12     12     1  5.3   0 13     13     1  5.3   0 14
> 14     1  5.3   0 15     15     1  5.7   0 16     16     1  5.3
> 0 17     17     1  5.3   0 18     18     1  5.3   0 19     19     1
> 5.3   0 20     20     1  5.7   0 21     21     1  5.7   1 22     22
> 1  5.7   1 23     23     1  5.7   0 24     24     1  5.3   0 25
> 25     1  5.3   0 26     26     1  5.3   0 27     27     1  5.3
> 1 28     28     1  5.7   0 29     29     1  5.7   1 30     30     1
> 5.7   0 31      1     2  4.1   0 32      2     2  4.8   0 33      3
> 2  5.3   0 34      4     2  5.7   0 35      5     2  6.0   0 36
> 6     2  5.7   0 37      7     2  5.7   1 38      8     2  5.3   0 
> 39      9     2  5.3   0 40     10     2  5.7   0 41     11     2
> 5.3   0 42     12     2  5.3   0 43     13     2  5.3   0 44     14
> 2  5.3   0 45     15     2  5.7   0 46     16     2  5.3   0 47
> 17     2  5.3   0 48     18     2  5.3   0 49     19     2  5.3
> 0 50     20     2  5.7   0 51     21     2  5.7   0 52     22     2
> 5.7   0 53     23     2  5.7   1 54     24     2  5.3   0 55     25
> 2  5.3   0 56     26     2  5.3   0 57     27     2  5.3   0 58
> 28     2  5.7   0 59     29     2  5.7   0 60     30     2  5.7
> 1 61      1     3  4.1   0 62      2     3  4.8   0 63      3     3
> 5.3   0 64      4     3  5.7   0 65      5     3  6.0   1 66      6
> 3  5.7   1 67      7     3  5.7   1 68      8     3  5.3   0 69
> 9     3  5.3   0 70     10     3  5.7   0 71     11     3  5.3   0 
> 72     12     3  5.3   0 73     13     3  5.3   0 74     14     3
> 5.3   0 75     15     3  5.7   0 76     16     3  5.3   0 77     17
> 3  5.3   0 78     18     3  5.3   0 79     19     3  5.3   1 80
> 20     3  5.7   0 81     21     3  5.7   0 82     22     3  5.7
> 0 83     23     3  5.7   1 84     24     3  5.3   0 85     25     3
> 5.3   0 86     26     3  5.3   1 87     27     3  5.3   0 88     28
> 3  5.7   0 89     29     3  5.7   0 90     30     3  5.7   1 91
> 1     4  4.1   0 92      2     4  4.8   0 93      3     4  5.3   0 
> 94      4     4  5.7   0 95      5     4  6.0   0 96      6     4
> 5.7   0 97      7     4  5.7   0 98      8     4  5.3   0 99      9
> 4  5.3   0 100    10     4  5.7   0 101    11     4  5.3   1 102
> 12     4  5.3   1 103    13     4  5.3   0 104    14     4  5.3
> 0 105    15     4  5.7   1 106    16     4  5.3   0 107    17     4
> 5.3   0 108    18     4  5.3   0 109    19     4  5.3   0 110    20
> 4  5.7   0 111    21     4  5.7   0 112    22     4  5.7   0 113
> 23     4  5.7   0 114    24     4  5.3   0 115    25     4  5.3
> 0 116    26     4  5.3   0 117    27     4  5.3   0 118    28     4
> 5.7   0 119    29     4  5.7   0 120    30     4  5.7   0 121     1
> 5  4.1   0 122     2     5  4.8   0 123     3     5  5.3   0 124
> 4     5  5.7   0 125     5     5  6.0   0 126     6     5  5.7   1 
> 127     7     5  5.7   0 128     8     5  5.3   1 129     9     5
> 5.3   0 130    10     5  5.7   0 131    11     5  5.3   0 132    12
> 5  5.3   0 133    13     5  5.3   1 134    14     5  5.3   0 135
> 15     5  5.7   0 136    16     5  5.3   0 137    17     5  5.3
> 0 138    18     5  5.3   0 139    19     5  5.3   0 140    20     5
> 5.7   0 141    21     5  5.7   1 142    22     5  5.7   0 143    23
> 5  5.7   0 144    24     5  5.3   0 145    25     5  5.3   0 146
> 26     5  5.3   0 147    27     5  5.3   0 148    28     5  5.7
> 0 149    29     5  5.7   0 150    30     5  5.7   0 151     1     6
> 4.1   0 152     2     6  4.8   0 153     3     6  5.3   0 154     4
> 6  5.7   1 155     5     6  6.0   1 156     6     6  5.7   0 157
> 7     6  5.7   0 158     8     6  5.3   0 159     9     6  5.3   0 
> 160    10     6  5.7   1 161    11     6  5.3   0 162    12     6
> 5.3   0 163    13     6  5.3   0 164    14     6  5.3   0 165    15
> 6  5.7   0 166    16     6  5.3   0 167    17     6  5.3   0 168
> 18     6  5.3   0 169    19     6  5.3   0 170    20     6  5.7
> 1 171    21     6  5.7   1 172    22     6  5.7   0 173    23     6
> 5.7   0 174    24     6  5.3   0 175    25     6  5.3   0 176    26
> 6  5.3   1 177    27     6  5.3   0 178    28     6  5.7   0 179
> 29     6  5.7   1 180    30     6  5.7   0
> 
> 
> 
> 
> Ben Bolker <bbolker at gmail.com> 27/01/2015 14:14
> 
> A <xavier.paoletti at curie.fr> cc "r-sig-mixed-models at r-project.org"
> <r-sig-mixed-models at r-project.org> Objet Re: [R-sig-ME] c++
> exception (unknown reason) when using an offset of the slope with
> glmer
> 
> 
> 
> 
> 
> 
> Your posted data set got removed by the mailing list machinery.
> Can you post it somewhere publicly accessible?
> 
> 
> On Tue, Jan 27, 2015 at 3:45 AM,  <xavier.paoletti at curie.fr>
> wrote:
>> 
>> Dear all,
>> 
>> I am new on this forum and I hope my request follows the right
>> format.
>> 
>> I use R 3.1.2 and lme1.7 on a mac OS X (snow leopard) or Windows
>> OS.
>> 
>> I try to fit a longitudinal logistic mixed effect model on
>> dose-time response data where the response is measured several
>> times at the same dose. The probability of response increases
>> with the dose. There is a set of discrete doses (let's say 6) but
>> most of the data are measured at 1 or 2 doses.
>> 
>> I use a very simple logstic model with a random intercept and the
>> dose effect. In the simplest case, there is not time effect. 
>> Furthermore, I would like to set the slope of the dose to some
>> value
> using
>> offset slope=1.5.
>> 
>> The command line, glmer(DLTb ~ offset(slope*dose) + (1 | patid), 
>> family=binomial,data=dataAllCRM,nAGQ=10) gives the following
>> error: Under Mac OSX: (function (fr, X, reTrms, family, nAGQ =
>> 1L, verbose =
> 0L,
>> control = glmerControl(),  : c++ exception (unknown reason)
>> 
>> Under Windows: Error: (maxstephalfit) PIRLS step-halvings failed
>> to
> reduce
>> deviance in pwrssUpdate
>> 
>> Whatever the value of the offset, I get the same error. If I
>> remove the offset or if I remove the variable, some estimates
>> are obtained.
>> 
>> Please find attached an example of dataset as an illustration; I
>> get the same error for all tested datasets.
>> 
>> 
>> Thank you very much for your help.
>> 
>> Best regards,
>> 
>> Xavier _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUyPYHAAoJEOCV5YRblxUHjjUH/R5gK8gIHEhTUnEQQiGQMF/m
pkzjJK37im+Tjg9ivu8xiorw9YSl4NcoB8KHK4joMySZoLhI/jQ1dg16aWId0FNO
1WWP6OOodqF/GdCerqg6BIQFgHJag/HOYRYnrwzoSOKQk82ZhxWFqOILaQxd7EvG
RzPDs7pEbWPS/cHELPWrmuvU+CAlnuRU2qAadGRn93hx19VFLsdVHsfKCza0RQd6
MAKwnkcj8jM2EWnjFaUapaF6i3QGpuXQaIDJUhvoo0ObAhKKFU8awtDyZTW19jKk
1gnKFWQnahyBYtoGkQE6Nk9gPzOrOznwdS3d++YE3tVS5e3oPQCJrfBx/UF3D8A=
=fw27
-----END PGP SIGNATURE-----


From xavier.paoletti at curie.fr  Wed Jan 28 17:10:03 2015
From: xavier.paoletti at curie.fr (xavier.paoletti at curie.fr)
Date: Wed, 28 Jan 2015 17:10:03 +0100
Subject: [R-sig-ME] c++ exception (unknown reason) when using an offset of
 the slope with glmer
In-Reply-To: <54C8F607.7090001@gmail.com>
References: <OF159E51D6.7ED45B93-ONC1257DDA.0030231F@curie.net>
	<CABghstS=q8aUDUP4J483G+rDbNybHHCUYumHHfm=TA2z5dcVhw@mail.gmail.com>
	<OF563A2E19.4C3ACFE9-ONC1257DDA.00493E45-C1257DDA.00499C41@curie.net>
	<54C8F607.7090001@gmail.com>
Message-ID: <OF147EB781.5A40EEE5-ONC1257DDB.00563C23-C1257DDB.0058CF63@curie.net>

Thank you very much. 
Probabilities of event range approximately between .05 to .60

You are right, If I choose an offset of the slope=0.1, I can obtain 
estimates of the intercept. 

The offset of 1.5 came from the expected increase in the risk of event 
when escalating the dose from 4 to 6. 

If I fit the model without offset, I get the following etimates for the 
fixed effects
intercept:: -12.7
dose     : 2.3


Finally, the reason for choosing an offset is to reduce the dimensionality 
of the model due to the sampling matrix. 
I work on an extension of phase I dose escalation design in oncology, 
where the proportion of data that is sampled at one or 2 dose levels 
increases with the overall sample size. Therefore after 30, 40, 50 
patients, the contribution of this dose level to the likelihood is 
massive. Esimating both the intercept and the slope of the dose-response 
relationship gets useless or even misleading. 


I am not sure to understand why offset of the dose = 1.5 is misleading for 
the intercept estimate, but I will dig in .

Thanks again for your help

Xavier





Ben Bolker <bbolker at gmail.com> 
28/01/2015 15:45

A
<xavier.paoletti at curie.fr>
cc
"r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Objet
Re: [R-sig-ME] c++ exception (unknown reason) when using an offset of the 
slope with glmer






-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Confirmed on

R Under development (unstable) (2015-01-26 r67627)
Platform: i686-pc-linux-gnu (32-bit)
lme4 1.1.8

 I will see what I can figure out.  I suspect the main problem is that
the doses range from 4 to 6, so with an offset of (1.5*dose), that
says that the logit-probability or log-odds should range from 6 to 9,
which corresponds to a baseline probability of 0.997 to 0.999.  Those
are very high probabilities: they're going to make it very hard to
make a sensible model.   Can you say a little bit more about what
you're trying to do/why an offset of 1.5 makes sense?

  Ben Bolker



On 15-01-27 08:24 AM, xavier.paoletti at curie.fr wrote:
> Thanks for your attention.
> 
> Here there are. 180 rows, 4 columns + obs number. Obs    patid
> cycle dose DLT 1       1     1  4.1   0 2       2     1  4.8   0 3
> 3     1  5.3   0 4       4     1  5.7   0 5       5     1  6.0   1 
> 6       6     1  5.7   1 7       7     1  5.7   0 8       8     1
> 5.3   0 9       9     1  5.3   0 10     10     1  5.7   0 11     11
> 1  5.3   0 12     12     1  5.3   0 13     13     1  5.3   0 14
> 14     1  5.3   0 15     15     1  5.7   0 16     16     1  5.3
> 0 17     17     1  5.3   0 18     18     1  5.3   0 19     19     1
> 5.3   0 20     20     1  5.7   0 21     21     1  5.7   1 22     22
> 1  5.7   1 23     23     1  5.7   0 24     24     1  5.3   0 25
> 25     1  5.3   0 26     26     1  5.3   0 27     27     1  5.3
> 1 28     28     1  5.7   0 29     29     1  5.7   1 30     30     1
> 5.7   0 31      1     2  4.1   0 32      2     2  4.8   0 33      3
> 2  5.3   0 34      4     2  5.7   0 35      5     2  6.0   0 36
> 6     2  5.7   0 37      7     2  5.7   1 38      8     2  5.3   0 
> 39      9     2  5.3   0 40     10     2  5.7   0 41     11     2
> 5.3   0 42     12     2  5.3   0 43     13     2  5.3   0 44     14
> 2  5.3   0 45     15     2  5.7   0 46     16     2  5.3   0 47
> 17     2  5.3   0 48     18     2  5.3   0 49     19     2  5.3
> 0 50     20     2  5.7   0 51     21     2  5.7   0 52     22     2
> 5.7   0 53     23     2  5.7   1 54     24     2  5.3   0 55     25
> 2  5.3   0 56     26     2  5.3   0 57     27     2  5.3   0 58
> 28     2  5.7   0 59     29     2  5.7   0 60     30     2  5.7
> 1 61      1     3  4.1   0 62      2     3  4.8   0 63      3     3
> 5.3   0 64      4     3  5.7   0 65      5     3  6.0   1 66      6
> 3  5.7   1 67      7     3  5.7   1 68      8     3  5.3   0 69
> 9     3  5.3   0 70     10     3  5.7   0 71     11     3  5.3   0 
> 72     12     3  5.3   0 73     13     3  5.3   0 74     14     3
> 5.3   0 75     15     3  5.7   0 76     16     3  5.3   0 77     17
> 3  5.3   0 78     18     3  5.3   0 79     19     3  5.3   1 80
> 20     3  5.7   0 81     21     3  5.7   0 82     22     3  5.7
> 0 83     23     3  5.7   1 84     24     3  5.3   0 85     25     3
> 5.3   0 86     26     3  5.3   1 87     27     3  5.3   0 88     28
> 3  5.7   0 89     29     3  5.7   0 90     30     3  5.7   1 91
> 1     4  4.1   0 92      2     4  4.8   0 93      3     4  5.3   0 
> 94      4     4  5.7   0 95      5     4  6.0   0 96      6     4
> 5.7   0 97      7     4  5.7   0 98      8     4  5.3   0 99      9
> 4  5.3   0 100    10     4  5.7   0 101    11     4  5.3   1 102
> 12     4  5.3   1 103    13     4  5.3   0 104    14     4  5.3
> 0 105    15     4  5.7   1 106    16     4  5.3   0 107    17     4
> 5.3   0 108    18     4  5.3   0 109    19     4  5.3   0 110    20
> 4  5.7   0 111    21     4  5.7   0 112    22     4  5.7   0 113
> 23     4  5.7   0 114    24     4  5.3   0 115    25     4  5.3
> 0 116    26     4  5.3   0 117    27     4  5.3   0 118    28     4
> 5.7   0 119    29     4  5.7   0 120    30     4  5.7   0 121     1
> 5  4.1   0 122     2     5  4.8   0 123     3     5  5.3   0 124
> 4     5  5.7   0 125     5     5  6.0   0 126     6     5  5.7   1 
> 127     7     5  5.7   0 128     8     5  5.3   1 129     9     5
> 5.3   0 130    10     5  5.7   0 131    11     5  5.3   0 132    12
> 5  5.3   0 133    13     5  5.3   1 134    14     5  5.3   0 135
> 15     5  5.7   0 136    16     5  5.3   0 137    17     5  5.3
> 0 138    18     5  5.3   0 139    19     5  5.3   0 140    20     5
> 5.7   0 141    21     5  5.7   1 142    22     5  5.7   0 143    23
> 5  5.7   0 144    24     5  5.3   0 145    25     5  5.3   0 146
> 26     5  5.3   0 147    27     5  5.3   0 148    28     5  5.7
> 0 149    29     5  5.7   0 150    30     5  5.7   0 151     1     6
> 4.1   0 152     2     6  4.8   0 153     3     6  5.3   0 154     4
> 6  5.7   1 155     5     6  6.0   1 156     6     6  5.7   0 157
> 7     6  5.7   0 158     8     6  5.3   0 159     9     6  5.3   0 
> 160    10     6  5.7   1 161    11     6  5.3   0 162    12     6
> 5.3   0 163    13     6  5.3   0 164    14     6  5.3   0 165    15
> 6  5.7   0 166    16     6  5.3   0 167    17     6  5.3   0 168
> 18     6  5.3   0 169    19     6  5.3   0 170    20     6  5.7
> 1 171    21     6  5.7   1 172    22     6  5.7   0 173    23     6
> 5.7   0 174    24     6  5.3   0 175    25     6  5.3   0 176    26
> 6  5.3   1 177    27     6  5.3   0 178    28     6  5.7   0 179
> 29     6  5.7   1 180    30     6  5.7   0
> 
> 
> 
> 
> Ben Bolker <bbolker at gmail.com> 27/01/2015 14:14
> 
> A <xavier.paoletti at curie.fr> cc "r-sig-mixed-models at r-project.org"
> <r-sig-mixed-models at r-project.org> Objet Re: [R-sig-ME] c++
> exception (unknown reason) when using an offset of the slope with
> glmer
> 
> 
> 
> 
> 
> 
> Your posted data set got removed by the mailing list machinery.
> Can you post it somewhere publicly accessible?
> 
> 
> On Tue, Jan 27, 2015 at 3:45 AM,  <xavier.paoletti at curie.fr>
> wrote:
>> 
>> Dear all,
>> 
>> I am new on this forum and I hope my request follows the right
>> format.
>> 
>> I use R 3.1.2 and lme1.7 on a mac OS X (snow leopard) or Windows
>> OS.
>> 
>> I try to fit a longitudinal logistic mixed effect model on
>> dose-time response data where the response is measured several
>> times at the same dose. The probability of response increases
>> with the dose. There is a set of discrete doses (let's say 6) but
>> most of the data are measured at 1 or 2 doses.
>> 
>> I use a very simple logstic model with a random intercept and the
>> dose effect. In the simplest case, there is not time effect. 
>> Furthermore, I would like to set the slope of the dose to some
>> value
> using
>> offset slope=1.5.
>> 
>> The command line, glmer(DLTb ~ offset(slope*dose) + (1 | patid), 
>> family=binomial,data=dataAllCRM,nAGQ=10) gives the following
>> error: Under Mac OSX: (function (fr, X, reTrms, family, nAGQ =
>> 1L, verbose =
> 0L,
>> control = glmerControl(),  : c++ exception (unknown reason)
>> 
>> Under Windows: Error: (maxstephalfit) PIRLS step-halvings failed
>> to
> reduce
>> deviance in pwrssUpdate
>> 
>> Whatever the value of the offset, I get the same error. If I
>> remove the offset or if I remove the variable, some estimates
>> are obtained.
>> 
>> Please find attached an example of dataset as an illustration; I
>> get the same error for all tested datasets.
>> 
>> 
>> Thank you very much for your help.
>> 
>> Best regards,
>> 
>> Xavier _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUyPYHAAoJEOCV5YRblxUHjjUH/R5gK8gIHEhTUnEQQiGQMF/m
pkzjJK37im+Tjg9ivu8xiorw9YSl4NcoB8KHK4joMySZoLhI/jQ1dg16aWId0FNO
1WWP6OOodqF/GdCerqg6BIQFgHJag/HOYRYnrwzoSOKQk82ZhxWFqOILaQxd7EvG
RzPDs7pEbWPS/cHELPWrmuvU+CAlnuRU2qAadGRn93hx19VFLsdVHsfKCza0RQd6
MAKwnkcj8jM2EWnjFaUapaF6i3QGpuXQaIDJUhvoo0ObAhKKFU8awtDyZTW19jKk
1gnKFWQnahyBYtoGkQE6Nk9gPzOrOznwdS3d++YE3tVS5e3oPQCJrfBx/UF3D8A=
=fw27
-----END PGP SIGNATURE-----


	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Jan 28 17:29:03 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 28 Jan 2015 16:29:03 +0000
Subject: [R-sig-ME] Statistics courses in Australia
Message-ID: <54C90E4F.1070100@highstat.com>

Hello,


In July/August/September 2015 we will be running again a series of 
statistics courses in Australia.

Confirmed courses:

1. Darwin: Data exploration, regression, GLM and GAM with introduction to R
2. Sydney: Introduction to mixed modelling, GLMM and MCMC with R
3. Canberra: Introduction to mixed modelling, GLMM and MCMC with R
4. Phillip Island Nature Parks: Data exploration and visualisation with 
R (with introduction to R)

Dates & prices will be decided later. If you would like to participate 
in one of these courses, or organise any of the following 9 courses at 
your institute, please contact us for further information.

1. Introduction to R
2. Data exploration and visualisation with R (with introduction to R)
3. Multivariate analysis with R
4. Data exploration, regression, GLM and GAM with introduction to R
5. Introduction mixed modelling and GLMM (either frequentist or 
Bayesian+frequentist)
6. Introduction to GAM and GAMM (either frequentist or Bayesian+frequentist)
7. Introduction to Bayesian analysis and MCMC
8. Introduction to zero inflated GLM and GLMM with R.
9. Workshop using own data

For flyers/prices/info of similar courses at other places see: 
http://www.highstat.com/statscourse.htm


Kind regards,

Alain

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Jan 28 18:33:21 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 28 Jan 2015 18:33:21 +0100
Subject: [R-sig-ME] Variance components analysis using a GLMM,
 how to insert a variance-covariance matrix in the model ?
In-Reply-To: <CAMEDFLC61ntZjo6s-Gjad8OqHX-Af7hNqCCtLw3RY0dcv0gTrQ@mail.gmail.com>
References: <F3AABEFCC68A3942B173A79B033F7891BED8E3@mbx2010-02.univ-lyon1.fr>
	<CAMEDFLC61ntZjo6s-Gjad8OqHX-Af7hNqCCtLw3RY0dcv0gTrQ@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F05B3D0F3@UM-MAIL4112.unimaas.nl>

Thanks, Jesse. I was about to (cautiously) suggest giving metafor a try.

Indeed, if you have a vector of estimates and a corresponding (approximately) known var-cov matrix, then one can tackle this from a meta-analytic perspective (which, in the end, is nothing else than two-stage multilevel modeling, maybe with a twist here and there). You may find this illustration useful:

http://www.metafor-project.org/doku.php/tips:two_stage_analysis

It compares the two-stage approach to a single mixed-effects model for longitudinal data. If one can use a single mixed-effects model for the analyses, then this is usually better, but this may not be possible in all cases and there may be circumstances where the two-stage approach has advantages.

In the present case, things are even simpler, since there is no additional grouping variable. 

You (C?lia) wrote that the response variable is a proportion, but you also wrote logit(phi_t), which sounds like a logit-transformed proportion. So, is Rcov the (estimated) var-cov matrix of the raw or logit transformed proportions?

At any rate, you would then want to use rma.mv() from the metafor package, which allows for an entire var-cov matrix of the estimates as input. So:

library(metafor)

load(url("http://mammal-research.org/data/example.RData"))

### this assumes that Rcov is the var-cov matrix of the raw proportions
dat <- data.frame(yi = marmot$estimates$estimate, time = as.numeric(as.character(marmot$estimates$time)) - 1990)

res <- rma.mv(yi, V=marmot$vc, mods = ~ time, data=dat)
res

var.components.reml(dat$yi, design = model.matrix(~ dat$time), vcv=marmot$vc)

But you probably want something like:

dat$id <- 1:nrow(dat)
res <- rma.mv(yi, V=marmot$vc, mods = ~ time, random = ~ 1 | id, data=dat)
res

plot(dat$time, dat$yi, pch=19, xaxt="n", xlab="Year", ylab="Estimate")
axis(side=1, at=dat$time, labels=dat$time+1990)
abline(res)
lines(dat$time, predict(res)$ci.lb, lty="dotted")
lines(dat$time, predict(res)$ci.ub, lty="dotted")

for a random-effects model. The fit looks pretty decent.

An issue here is that the analysis above is based on a model that assumes that the sampling distributions of the estimates can be approximated with normal distributions. With raw proportions, that may not be sensible, especially when some of the proportions are so close to 1 as in the present case.

Some form of a generalized mixed-effects model may be an alternative that is more suitable, but you have proportions and I see no information about the denominator on which those proportions are based. Also, I don't know how MARK computes that var-cov matrix (I downloaded the "gentle introduction" book from the MARK website, but when I realized it has more than 1000 pages, I quickly abandoned the idea of figuring this out). It may already be based on some normal approximation in the first place. Also, I don't see an obvious way of incorporating a known var-cov matrix into a GLMM, since the mean and variance structures of such models are typically intertwined.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Jesse Whittington
> Sent: Wednesday, January 28, 2015 15:02
> To: REZOUKI CELIA p1314815
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Variance components analysis using a GLMM, how to
> insert a variance-covariance matrix in the model ?
> 
> Hi C?lia,
> 
> Check out the rma function in the metafor package.  It is similar to the
> RMark var.components.reml function.
> 
> I've used it for similar analyses with derived annual occupancy
> estimates.
> You can input variance associated with each survival estimate - I'm not
> sure if you can include covariance among estimates.
> 
> Here's an example of your model that I ran in RMark and metafor (sorry
> it's
> not self contained).
> 
> # Multi-year occupancy model.
> m <- try(mark(data=d.proc, ddl=d.ddl, model='RDOccupEG',
> model.parameters=list(Epsilon=f.eps.t,  p=f.p), output=F, silent=T,
> delete=T), silent=TRUE)
>  psi <- m$results$derived
> psi$year <- 0:(nrow(psi) - 1)
> vcv <- m$results$derived.vcv
> fixed.mat1 <- model.matrix( ~ 1 + year, data=psi)  # cannot use this with
> only 2 years of data
> 
> # RMark Test for a linear Trend
> m.trend <- try(var.components.reml(theta=psi$estimate, design=fixed.mat1,
> vcv=vcv), silent=TRUE)  # Linear model for significant trend
> 
> # metafor
> m.trend <- rma(yi = estimate, sei = se, mods = ~ year, data = psi)
> 
> Warning:  I'm not a statistician, so I cannot guarentee that what I've
> done
> is correct.
> 
> Jesse Whittington
> Wildlife Biologist
> Banff National Park
> 
> On Wed, Jan 28, 2015 at 2:17 AM, REZOUKI CELIA p1314815 <
> celia.rezouki at etu.univ-lyon1.fr> wrote:
> 
> > Dear list,
> >
> > We are analysing the survival rates of a mammalian species from a
> > capture-mark-recapture protocol. As a biologist, the usual way to
> > proceed is to analyse capture histories (raw data) with a specific
> > software named MARK (http://www.phidot.org/software/mark/) to run
> > capture-mark-recapture analyses.
> >
> > Our problem is to get an estimation of a random effect of time using
> > linear mixed models, not from the observed data, but from a coefficient
> > vector (let's call it 'phi') representing annual estimates of the
> > survival rates, and the empirical variance/covariance matrix (Rcov)
> > obtained from MARK.
> >
> > We would like to use the output of the analyse (phis and Rcov) from
> MARK
> > in a linear mixed-model in R to extract both a variance components and
> > eventually, to model linear effects of different covariates such as
> > time. The response variable being a proportion, it would be best to use
> > a binomial family and hence, a generalized version of the mixed models.
> >
> > The model would look like:
> > - response variable: logit(phi_t), the annual survival estimated from
> MARK
> > - fixed effects : temporal trends (year entered as a covariable)
> > - random effects : variance in survival around the temporal trend
> > - Rcov, the empirical variance/covariance matrix from MARK is known and
> > should be entered into the GLMM.
> >
> > It is unclear to us whether such an analysis is doable in R or not. The
> > closest we found would be to use mcmcglmm but we would need
> confirmation
> > and somes hint to start.
> >
> > In case you want to help, you can get a vector of estimated survival
> > rates along with the empirical variance/covariance matrix returned by
> > MARK from a subsample of our data here:
> >
> > load(url("http://mammal-research.org/data/example.RData"))
> >
> > Any help would be greatly appreciated.
> >
> > C?lia
> >
> > --
> >
> > C?lia Rezouki
> > PhD student
> >
> > UMR CNRS 5558 - LBBE
> > Biom?trie et Biologie ?volutive
> > UCB Lyon 1 - B?t. Gr?gor Mendel
> > 43 bd du 11 novembre 1918
> > 69622 VILLEURBANNE cedex

From bbonit at tin.it  Wed Jan 28 19:49:48 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Wed, 28 Jan 2015 19:49:48 +0100 (CET)
Subject: [R-sig-ME] Loglikelihood
Message-ID: <14b31e0c16e.bbonit@tin.it>


I understand the discrepance .....  it rise from this  line from  
http://arxiv.org/pdf/1406.5823v1.pdf    pag 27  suggested by professor Walker S.
Thank again 

Conditional variances of random effects

" It is useful to clarify that the conditional covariance concept in lme4 is based on a simplification
of the linear mixed model. In particular, we simplify the model by assuming ..... " 
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jan 29 16:00:57 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Jan 2015 10:00:57 -0500
Subject: [R-sig-ME] c++ exception (unknown reason) when using an offset
 of the slope with glmer
In-Reply-To: <OF147EB781.5A40EEE5-ONC1257DDB.00563C23-C1257DDB.0058CF63@curie.net>
References: <OF159E51D6.7ED45B93-ONC1257DDA.0030231F@curie.net>
	<CABghstS=q8aUDUP4J483G+rDbNybHHCUYumHHfm=TA2z5dcVhw@mail.gmail.com>
	<OF563A2E19.4C3ACFE9-ONC1257DDA.00493E45-C1257DDA.00499C41@curie.net>
	<54C8F607.7090001@gmail.com>
	<OF147EB781.5A40EEE5-ONC1257DDB.00563C23-C1257DDB.0058CF63@curie.net>
Message-ID: <54CA4B29.6090802@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  The intercept seems awfully extreme, but I guess that's basically
because a dose of zero is actually unrealistic.

  I got a little carried away and explored this in

  http://rpubs.com/bbolker/glmer_offset

The bottom line is that I think you can work around the offset issues
if necessary (although I agree that it does technically constitute a
bug in lme4; I will post an issue at
https://github.com/lme4/lme4/issues when I get around to it, or
someone else would be welcome to), but that a GLMM actually seems like
overkill for this problem.

  cheers
    Ben Bolker

On 15-01-28 11:10 AM, xavier.paoletti at curie.fr wrote:
> Thank you very much. Probabilities of event range approximately
> between .05 to .60
> 
> You are right, If I choose an offset of the slope=0.1, I can obtain
>  estimates of the intercept.
> 
> The offset of 1.5 came from the expected increase in the risk of
> event when escalating the dose from 4 to 6.
> 
> If I fit the model without offset, I get the following etimates for
> the fixed effects intercept:: -12.7 dose     : 2.3
> 
> 
> Finally, the reason for choosing an offset is to reduce the
> dimensionality of the model due to the sampling matrix. I work on
> an extension of phase I dose escalation design in oncology, where
> the proportion of data that is sampled at one or 2 dose levels 
> increases with the overall sample size. Therefore after 30, 40, 50
>  patients, the contribution of this dose level to the likelihood is
>  massive. Esimating both the intercept and the slope of the
> dose-response relationship gets useless or even misleading.
> 
> 
> I am not sure to understand why offset of the dose = 1.5 is
> misleading for the intercept estimate, but I will dig in .
> 
> Thanks again for your help
> 
> Xavier
> 
> 
> 
> 
> 
> Ben Bolker <bbolker at gmail.com> 28/01/2015 15:45
> 
> A <xavier.paoletti at curie.fr> cc "r-sig-mixed-models at r-project.org"
> <r-sig-mixed-models at r-project.org> Objet Re: [R-sig-ME] c++
> exception (unknown reason) when using an offset of the slope with
> glmer
> 
> 
> 
> 
> 
> 
> Confirmed on
> 
> R Under development (unstable) (2015-01-26 r67627) Platform:
> i686-pc-linux-gnu (32-bit) lme4 1.1.8
> 
> I will see what I can figure out.  I suspect the main problem is
> that the doses range from 4 to 6, so with an offset of (1.5*dose),
> that says that the logit-probability or log-odds should range from
> 6 to 9, which corresponds to a baseline probability of 0.997 to
> 0.999.  Those are very high probabilities: they're going to make it
> very hard to make a sensible model.   Can you say a little bit more
> about what you're trying to do/why an offset of 1.5 makes sense?
> 
> Ben Bolker
> 
> 
> 
> On 15-01-27 08:24 AM, xavier.paoletti at curie.fr wrote:
>> Thanks for your attention.
> 
>> Here there are. 180 rows, 4 columns + obs number. Obs    patid 
>> cycle dose DLT 1       1     1  4.1   0 2       2     1  4.8   0
>> 3 3     1  5.3   0 4       4     1  5.7   0 5       5     1  6.0
>> 1 6       6     1  5.7   1 7       7     1  5.7   0 8       8
>> 1 5.3   0 9       9     1  5.3   0 10     10     1  5.7   0 11
>> 11 1  5.3   0 12     12     1  5.3   0 13     13     1  5.3   0
>> 14 14     1  5.3   0 15     15     1  5.7   0 16     16     1
>> 5.3 0 17     17     1  5.3   0 18     18     1  5.3   0 19     19
>> 1 5.3   0 20     20     1  5.7   0 21     21     1  5.7   1 22
>> 22 1  5.7   1 23     23     1  5.7   0 24     24     1  5.3   0
>> 25 25     1  5.3   0 26     26     1  5.3   0 27     27     1
>> 5.3 1 28     28     1  5.7   0 29     29     1  5.7   1 30     30
>> 1 5.7   0 31      1     2  4.1   0 32      2     2  4.8   0 33
>> 3 2  5.3   0 34      4     2  5.7   0 35      5     2  6.0   0
>> 36 6     2  5.7   0 37      7     2  5.7   1 38      8     2  5.3
>> 0 39      9     2  5.3   0 40     10     2  5.7   0 41     11
>> 2 5.3   0 42     12     2  5.3   0 43     13     2  5.3   0 44
>> 14 2  5.3   0 45     15     2  5.7   0 46     16     2  5.3   0
>> 47 17     2  5.3   0 48     18     2  5.3   0 49     19     2
>> 5.3 0 50     20     2  5.7   0 51     21     2  5.7   0 52     22
>> 2 5.7   0 53     23     2  5.7   1 54     24     2  5.3   0 55
>> 25 2  5.3   0 56     26     2  5.3   0 57     27     2  5.3   0
>> 58 28     2  5.7   0 59     29     2  5.7   0 60     30     2
>> 5.7 1 61      1     3  4.1   0 62      2     3  4.8   0 63      3
>> 3 5.3   0 64      4     3  5.7   0 65      5     3  6.0   1 66
>> 6 3  5.7   1 67      7     3  5.7   1 68      8     3  5.3   0
>> 69 9     3  5.3   0 70     10     3  5.7   0 71     11     3  5.3
>> 0 72     12     3  5.3   0 73     13     3  5.3   0 74     14
>> 3 5.3   0 75     15     3  5.7   0 76     16     3  5.3   0 77
>> 17 3  5.3   0 78     18     3  5.3   0 79     19     3  5.3   1
>> 80 20     3  5.7   0 81     21     3  5.7   0 82     22     3
>> 5.7 0 83     23     3  5.7   1 84     24     3  5.3   0 85     25
>> 3 5.3   0 86     26     3  5.3   1 87     27     3  5.3   0 88
>> 28 3  5.7   0 89     29     3  5.7   0 90     30     3  5.7   1
>> 91 1     4  4.1   0 92      2     4  4.8   0 93      3     4  5.3
>> 0 94      4     4  5.7   0 95      5     4  6.0   0 96      6
>> 4 5.7   0 97      7     4  5.7   0 98      8     4  5.3   0 99
>> 9 4  5.3   0 100    10     4  5.7   0 101    11     4  5.3   1
>> 102 12     4  5.3   1 103    13     4  5.3   0 104    14     4
>> 5.3 0 105    15     4  5.7   1 106    16     4  5.3   0 107    17
>> 4 5.3   0 108    18     4  5.3   0 109    19     4  5.3   0 110
>> 20 4  5.7   0 111    21     4  5.7   0 112    22     4  5.7   0
>> 113 23     4  5.7   0 114    24     4  5.3   0 115    25     4
>> 5.3 0 116    26     4  5.3   0 117    27     4  5.3   0 118    28
>> 4 5.7   0 119    29     4  5.7   0 120    30     4  5.7   0 121
>> 1 5  4.1   0 122     2     5  4.8   0 123     3     5  5.3   0
>> 124 4     5  5.7   0 125     5     5  6.0   0 126     6     5
>> 5.7   1 127     7     5  5.7   0 128     8     5  5.3   1 129
>> 9     5 5.3   0 130    10     5  5.7   0 131    11     5  5.3   0
>> 132    12 5  5.3   0 133    13     5  5.3   1 134    14     5
>> 5.3   0 135 15     5  5.7   0 136    16     5  5.3   0 137    17
>> 5  5.3 0 138    18     5  5.3   0 139    19     5  5.3   0 140
>> 20     5 5.7   0 141    21     5  5.7   1 142    22     5  5.7
>> 0 143    23 5  5.7   0 144    24     5  5.3   0 145    25     5
>> 5.3   0 146 26     5  5.3   0 147    27     5  5.3   0 148    28
>> 5  5.7 0 149    29     5  5.7   0 150    30     5  5.7   0 151
>> 1     6 4.1   0 152     2     6  4.8   0 153     3     6  5.3   0
>> 154     4 6  5.7   1 155     5     6  6.0   1 156     6     6
>> 5.7   0 157 7     6  5.7   0 158     8     6  5.3   0 159     9
>> 6  5.3   0 160    10     6  5.7   1 161    11     6  5.3   0 162
>> 12     6 5.3   0 163    13     6  5.3   0 164    14     6  5.3
>> 0 165    15 6  5.7   0 166    16     6  5.3   0 167    17     6
>> 5.3   0 168 18     6  5.3   0 169    19     6  5.3   0 170    20
>> 6  5.7 1 171    21     6  5.7   1 172    22     6  5.7   0 173
>> 23     6 5.7   0 174    24     6  5.3   0 175    25     6  5.3
>> 0 176    26 6  5.3   1 177    27     6  5.3   0 178    28     6
>> 5.7   0 179 29     6  5.7   1 180    30     6  5.7   0
> 
> 
> 
> 
>> Ben Bolker <bbolker at gmail.com> 27/01/2015 14:14
> 
>> A <xavier.paoletti at curie.fr> cc
>> "r-sig-mixed-models at r-project.org" 
>> <r-sig-mixed-models at r-project.org> Objet Re: [R-sig-ME] c++ 
>> exception (unknown reason) when using an offset of the slope
>> with glmer
> 
> 
> 
> 
> 
> 
>> Your posted data set got removed by the mailing list machinery. 
>> Can you post it somewhere publicly accessible?
> 
> 
>> On Tue, Jan 27, 2015 at 3:45 AM,  <xavier.paoletti at curie.fr> 
>> wrote:
>>> 
>>> Dear all,
>>> 
>>> I am new on this forum and I hope my request follows the right 
>>> format.
>>> 
>>> I use R 3.1.2 and lme1.7 on a mac OS X (snow leopard) or
>>> Windows OS.
>>> 
>>> I try to fit a longitudinal logistic mixed effect model on 
>>> dose-time response data where the response is measured several 
>>> times at the same dose. The probability of response increases 
>>> with the dose. There is a set of discrete doses (let's say 6)
>>> but most of the data are measured at 1 or 2 doses.
>>> 
>>> I use a very simple logstic model with a random intercept and
>>> the dose effect. In the simplest case, there is not time
>>> effect. Furthermore, I would like to set the slope of the dose
>>> to some value
>> using
>>> offset slope=1.5.
>>> 
>>> The command line, glmer(DLTb ~ offset(slope*dose) + (1 |
>>> patid), family=binomial,data=dataAllCRM,nAGQ=10) gives the
>>> following error: Under Mac OSX: (function (fr, X, reTrms,
>>> family, nAGQ = 1L, verbose =
>> 0L,
>>> control = glmerControl(),  : c++ exception (unknown reason)
>>> 
>>> Under Windows: Error: (maxstephalfit) PIRLS step-halvings
>>> failed to
>> reduce
>>> deviance in pwrssUpdate
>>> 
>>> Whatever the value of the offset, I get the same error. If I 
>>> remove the offset or if I remove the variable, some estimates 
>>> are obtained.
>>> 
>>> Please find attached an example of dataset as an illustration;
>>> I get the same error for all tested datasets.
>>> 
>>> 
>>> Thank you very much for your help.
>>> 
>>> Best regards,
>>> 
>>> Xavier _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUykspAAoJEOCV5YRblxUHfHMIAKYw44W2SDYxy8sy/VUHlaNE
V1EcmfYu8wS8JH1bfk4nyi71+kvG9DZMdQL2SDBZAHeJo4iu2k4Burqdz+y01KaO
8n2X0oFAzJQfyP3vQJfEf2a90BwFFaUx2kTXuDq64a3sm8hGk6mtwYtMzzvQFamS
Xl9IKdCJNrelf9d4WkP0l9ZYzx7R1QABU7/i22YUoGmWygnR6bzqS/m1oyxqijSq
stoEZVAinl3ADK0zlnByuxBiPVev+swrYbG68GNzlk/a9Oi8gB0lVPvxdh5tiKB4
Ulpu7cbMO8xlQYR+H+SaDyi9NSxPuQat14iFLcmX82Yzf0RlEq0Vri+c4HCikck=
=/Msf
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Sat Jan 31 01:17:45 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 31 Jan 2015 00:17:45 +0000 (UTC)
Subject: [R-sig-ME] c++ exception (unknown reason) when using an offset
	of the slope with glmer
References: <OF159E51D6.7ED45B93-ONC1257DDA.0030231F@curie.net>
	<CABghstS=q8aUDUP4J483G+rDbNybHHCUYumHHfm=TA2z5dcVhw@mail.gmail.com>
	<OF563A2E19.4C3ACFE9-ONC1257DDA.00493E45-C1257DDA.00499C41@curie.net>
	<54C8F607.7090001@gmail.com>
	<OF147EB781.5A40EEE5-ONC1257DDB.00563C23-C1257DDB.0058CF63@curie.net>
	<54CA4B29.6090802@gmail.com>
Message-ID: <loom.20150131T011622-344@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> The bottom line is that I think you can work around the offset issues
> if necessary (although I agree that it does technically constitute a
> bug in lme4; I will post an issue at
> https://github.com/lme4/lme4/issues when I get around to it, or
> someone else would be welcome to), but that a GLMM actually seems like
> overkill for this problem.
> 
>   cheers
>     Ben Bolker
> 

  Just pointing out that discussion on this issue (actually focused
for the moment on a very closely related issue instead, but relevant)
is continuing at https://github.com/lme4/lme4/issues/273 , for those
who want to follow along ...


From jackiewood7 at gmail.com  Sun Feb  1 18:10:51 2015
From: jackiewood7 at gmail.com (Jackie Wood)
Date: Sun, 1 Feb 2015 12:10:51 -0500
Subject: [R-sig-ME] Meta-analysis for heritability using MCMCglmm?
In-Reply-To: <CAOxxGR=O0B-cmiy_4HwUnOaHNrorn-XUtY2bJMo6uwqYYmMVuw@mail.gmail.com>
References: <CAOxxGR=8rvPJTiHPjVYJNaCDZcUH0medNnk+fba2bONrX8kS2Q@mail.gmail.com>
	<CAF5_5cyX-HYrnrO1qDvP2+CsRWTaRpVU8BgpGe9sR+bf8LRiRg@mail.gmail.com>
	<20141226065813.21424g2r4lweojk0@www.staffmail.ed.ac.uk>
	<CAOxxGR=O0B-cmiy_4HwUnOaHNrorn-XUtY2bJMo6uwqYYmMVuw@mail.gmail.com>
Message-ID: <CAOxxGRmza_LHg=HKbKKVLvU3ouidZ8FJGccNVE=T8pmzB=-YdA@mail.gmail.com>

Hi Jarrod,

We were finally able to dig into the statistical analysis of our
heritability data (as a reminder, we are conducting a meta-analysis
investigating heritability in relation to population size) and of course a
few questions have come up.

You had mentioned examining the residuals for the model. This may seem like
a "beginner" question, how does one extract the residuals from MCMCglmm?
The residuals.mcmcglmm function does not work. Summary plots of the MCMC
parameter estimates appear to be roughly normally distributed, and the
traces seem fine. Is this what you were referring to? We ran an unweighted
analysis (heritability estimates without SEs) in both MCMCglmm and lmer to
see if they give similar results, and they are basically concordant as
well. However, the residual distribution for the models run in lmer
(treating heritability as gaussian) is slightly skewed. These are from an
unweighted analysis, though, as I have also read that lme4 is unsuitable
for conducting formal weighted meta-analyses.

We also had a few questions that we thought would be worth discussing about
some methodological issues relating to incorporating common estimates of
heritability in the literature. Bayesian methodologies have become
increasingly popular to use when estimating trait heritabilities, but
bayesian estimates do not provide typical standard error or variance
estimates, as parent-offspring/ANOVA/REML methods do. Published bayesian
heritability estimates typically only include asymmetric confidence
intervals, and we unsure whether these can be translated into variance
estimates that can be used to weight our meta-analysis. For now, we plan on
performing a weighted meta-analysis using heritability estimates that
provide S.E.s, and an additional unweighted analysis that will include the
bayesian point-estimates we have collected from the literature. We were
wondering if you resolved this issue in your own heritability meta-analysis
and knew of a way to incorporate bayesian estimates (which form a
considerable proportion of the suitable heritability estimates available,
at least in recent history) into a formal weighted meta-analysis.

Additionally, we were wondering about the suitability of DIC to conduct
model selection for our analysis of heritability. I recall reading on this
SIG list that you had mentioned that there were potential issues using DIC
for hierarchical models as well as non-gaussian data. Since we're treating
heritability as gaussian, would it still be appropriate?

Any advise would be much appreciated!


On Thu, Jan 15, 2015 at 3:41 PM, Jackie Wood <jackiewood7 at gmail.com> wrote:

> Hi Jarrod and Ken,
>
> Hope you had a great New Year! Thanks so much for your responses to my
> inquiry. Given that we've been using MCMCglmm all along, we'll probably
> stick with it unless there's a compelling reason to change programs. We'll
> be running the h2 models in the coming days and will specify a Gaussian
> distribution as Jarrod suggested; we have quite a bit of data so hopefully
> the residuals will behave!
>
> The advice is much appreciated as always!
> Jackie
>
> On Fri, Dec 26, 2014 at 1:58 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi Jackie,
>>
>> The data are not binomial they are continuous: a beta distribution is
>> probably most appropriate for continuos observations bounded by 0 and 1.
>> However, although heritabilities are bounded by 0 and 1, heritability
>> estimates are not necessarily so, depending on the method of inference (for
>> example it would be possible to get a negative parent-offspring regression,
>> either by chance or through certain types of maternal effect).
>>
>> We have just finished a meta-analysis of h2 estimates and just treated
>> them as Gaussian. The distribution of the residuals wasn't far off and I
>> think the conclusions are robust to the distributional assumptions. Have
>> you checked your residuals - do they look badly non-normal?
>>
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>> Quoting Ken Beath <ken.beath at mq.edu.au> on Wed, 24 Dec 2014 12:30:03
>> +1100:
>>
>>  If you have the original data giving the numerator and denominator for
>>> the
>>> proportion then it is binomial data, and can be modelled in a
>>> met-analysis.
>>> I don't know if this can be done with MCMCglmm but should be possible
>>> with
>>> STAN, JAGS or BUGS. All will require a bit of effort in setting up the
>>> model.
>>>
>>> On 24 December 2014 at 07:17, Jackie Wood <jackiewood7 at gmail.com> wrote:
>>>
>>>  Dear R-users,
>>>>
>>>> I am attempting to conduct a meta-analysis to investigate the
>>>> relationship
>>>> of narrow-sense heritability with population size. In previous work, I
>>>> have
>>>> used MCMCglmm to conduct a formal meta-analysis which allowed me to
>>>> account
>>>> for the effect of sampling error through the argument "mev". This was
>>>> relatively easy to do for a continuous response variable, however,
>>>> heritability is presented as a proportion and is therefore bounded by 0
>>>> and
>>>> 1 which clearly changes the situation.
>>>>
>>>> In fact, I am not actually certain if it possible to conduct a formal
>>>> weighted meta-analysis on the heritability data using MCMCglmm. I have
>>>> seen
>>>> elsewhere where data presented as a proportion (survival,
>>>> yolk-conversion
>>>> efficiency for example) has been logit transformed and fitted using a
>>>> Gaussian error distribution (though this was done using REML rather than
>>>> Bayesian modelling) but I don't know if this is a legitimate strategy
>>>> for a
>>>> formal meta-analysis using heritability as a response variable since any
>>>> transformation applied to the heritability data would also need to be
>>>> applied to the standard errors?
>>>>
>>>> I would greatly appreciate any advice on this matter!
>>>>
>>>> Cheers,
>>>> Jackie
>>>>
>>>> --
>>>> Jacquelyn L.A. Wood, PhD.
>>>> Biology Department
>>>> Concordia University
>>>> 7141 Sherbrooke St. West
>>>> Montreal, QC
>>>> H4B 1R6
>>>> Phone: (514) 293-7255
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>> --
>>>
>>> *Ken Beath*
>>> Lecturer
>>> Statistics Department
>>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>>
>>> Phone: +61 (0)2 9850 8516
>>>
>>> Building E4A, room 526
>>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>>
>>> CRICOS Provider No 00002J
>>> This message is intended for the addressee named and may...{{dropped:9}}
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> Jacquelyn L.A. Wood, PhD.
> Biology Department
> Concordia University
> 7141 Sherbrooke St. West
> Montreal, QC
> H4B 1R6
> Phone: (514) 293-7255
>
>


-- 
Jacquelyn L.A. Wood, PhD.
Biology Department
Concordia University
7141 Sherbrooke St. West
Montreal, QC
H4B 1R6
Phone: (514) 293-7255

	[[alternative HTML version deleted]]


From bbonit at tin.it  Sun Feb  1 23:03:42 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Sun, 1 Feb 2015 23:03:42 +0100 (CET)
Subject: [R-sig-ME] lme4@flexLambda  Error
Message-ID: <14b472bb83b.bbonit@tin.it>


 
Deal list, 
I have installed  this version of lme4
https://github.com/lme4/lme4/tree/flexLambda

following the example i have fitted m <-  flexLmer(y ~ time + ar1d(~(time|id)), data=fr)
but one error arise:

Error in .Call(merPredDCreate, as(X, "matrix"), Lambdat, LamtUt, RZX,  : 
Incorrect number of arguments (15), expecting 17 for 'merPredDCreate'

What does it means ?  I can resolve i?

Thank in advance
Bonitta Gianluca

set.seed(2352)
nsubj <- 20
nreps <- 2
length <- 20
n <- nsubj*nreps*length
fr <- expand.grid(
    time=1:length,
    id=factor(1:nsubj),
    rep=factor(1:nreps))

rho <- .8
sd.b <- 3
b <- sd.b * as.vector(replicate(nsubj, arima.sim(n=length, model=list(ar=c(rho)))))              
sd.eps <- 1
beta <- .5
fr <- within(fr,{
    mu <- beta*time
    y <- mu + model.matrix(~0+as.factor(time):id)%*%b + 
        rnorm(n, sd=sd.eps)
})

m <-  flexLmer(y ~ time + ar1d(~(time|id)), data=fr)
 
	[[alternative HTML version deleted]]


From steve.walker at utoronto.ca  Sun Feb  1 23:16:48 2015
From: steve.walker at utoronto.ca (Steve Walker)
Date: Sun, 01 Feb 2015 17:16:48 -0500
Subject: [R-sig-ME] lme4@flexLambda  Error
In-Reply-To: <14b472bb83b.bbonit@tin.it>
References: <14b472bb83b.bbonit@tin.it>
Message-ID: <54CEA5D0.4070304@utoronto.ca>

I'm sorry but I couldn't reproduce the error.  Could you provide 
sessionInfo()?  Mine is below.

Steve

 > sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_2.0      Rcpp_0.11.2.1 Matrix_1.1-4  setup_0.0-1

loaded via a namespace (and not attached):
[1] MASS_7.3-33     compiler_3.1.1  grid_3.1.1      lattice_0.20-29
[5] minqa_1.2.3     nlme_3.1-117    nloptr_1.0.0    splines_3.1.1
[9] tools_3.1.1
 >



On 2015-02-01 5:03 PM, bbonit at tin.it wrote:
> set.seed(2352)
> nsubj <- 20
> nreps <- 2
> length <- 20
> n <- nsubj*nreps*length
> fr <- expand.grid(
>      time=1:length,
>      id=factor(1:nsubj),
>      rep=factor(1:nreps))
>
> rho <- .8
> sd.b <- 3
> b <- sd.b * as.vector(replicate(nsubj, arima.sim(n=length, model=list(ar=c(rho)))))
> sd.eps <- 1
> beta <- .5
> fr <- within(fr,{
>      mu <- beta*time
>      y <- mu + model.matrix(~0+as.factor(time):id)%*%b +
>          rnorm(n, sd=sd.eps)
> })
>
> m <-  flexLmer(y ~ time + ar1d(~(time|id)), data=fr)


From jrmorrongiello at gmail.com  Mon Feb  2 04:23:50 2015
From: jrmorrongiello at gmail.com (John Morrongiello)
Date: Mon, 2 Feb 2015 14:23:50 +1100
Subject: [R-sig-ME] Fwd: priors for multivariate mixed model in MCMCglmm
 with random intercepts and slopes
In-Reply-To: <CAAH-yP8kkAJGrknv3SiD9A9G6ht6UVYaO38DAeQrePTvjYMfSQ@mail.gmail.com>
References: <CAAH-yP8kkAJGrknv3SiD9A9G6ht6UVYaO38DAeQrePTvjYMfSQ@mail.gmail.com>
Message-ID: <CAPTgL1aUnc8GTBFjfCDY1Nqn_S6K-snxC-_-Oioe=fJk2_TiYg@mail.gmail.com>

Hi Malcolm thanks for the suggestions regarding the priors. Changing the 7
to an 8 for the random effect priors worked a treat, as did your
specification for uninformative priors. The model runs and results are
sensible.

In regards to your other questions about the data and model specification:
I lied a bit in outlining the level of coverage. Some individuals have the
7 observations across each of 124 time periods, others less. This is partly
because of different aged individuals and also because I ensured that I'm
only analysing data from a given time point for an individual when all 7
response variables are present. I allow Age to randomly vary across months
because the month term captures most of the extrinsic sources of variation
in the model without specifying what this is (obviously this can be
attributed when environmental terms are added to the model). It is highly
likely thathow an individual responds to a change in the environment is age
dependent, hence the random age slope on month (which just so happens to
greatly improve model performance).

Finally, I model growth as opposed to size at age as we only have
information from the otolith on increment width which is a proxy for
growth. I could do some form of back-calculation to convert increment
measurements into fish size, but this process is not perfect and can
introduce bias into the data. Also, I find model interpretation easier when
I talk about growth (e.g. conditions in year x were good for growth, warm
temperatures favour higher growth) rather than changes in fish size, which
is very much conditional on the size of fish at the previous time step, and
the range of fish that contribute to a given section of the chronology.

Cheers
John



On Sat, Jan 24, 2015 at 5:49 AM, Malcolm Fairbrother <
M.Fairbrother at bristol.ac.uk> wrote:

> Hi John,
>
> This is not my substantive area of expertise at all, and I'm not
> completely confident I can help. But, nobody else has responded, and I have
> fitted some multivariate models with MCMCglmm. So, for what it's worth...
>
> For starters, I'm not sure I understand the data. If you're saying each of
> 7 properties are observed on 38 fish each observed over the course of 124
> months, where does 1021 come from? (38x124 is 4712...) Are you saying you
> have repeated observations on fish over the course of 124 months, but for
> each actual fish you have fewer observations than 124?
>
> Next, two questions about your models:
> Why do you allow the slope for Age to vary randomly across months?
> And why model growth (so, say, % or absolute change in length) rather than
> the property that is growing (length)? The latter would seem more
> straightforward to me.
>
> As regards the priors, if I understand you correctly, you've kept the same
> prior specification (prior1) when fitting models (m3 and m4) with an
> additional parameter at each higher level. So maybe try changing 7 to 8 at
> those levels?
>
> prior2  <- list(R=list(V=diag(7), nu=7), G=list(G1=list(V=diag(8), nu=8),
> G2=list(V=diag(8), nu=8)))
>
> Additionally, also for what it's worth, I've found parameter-expanded
> priors to be more uninformative, and Jarrod has made them pretty easy to
> use. So (assuming you want them to be uninformative) you might try:
>
> prior2a  <- list(R=list(V=diag(7), nu=7.02), G=list(G1=list(V=diag(8),
> nu=8.02, alpha.mu=rep(0,8), alpha.V=1000*diag(8)), G2=list(V=diag(8),
> nu=8.02, alpha.mu=rep(0,8), alpha.V=1000*diag(8))))
>
> Hope that helps...?
>
> Don't feel bad. You're far from the first person to write to this list
> with questions about priors for MCMCglmm!
>
> Cheers,
> Malcolm
>
>
>
>
>> Date: Thu, 22 Jan 2015 22:23:26 +1100
>> From: John Morrongiello <jrmorrongiello at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Fwd: priors for multivariate mixed model in
>>         MCMCglmm with random intercepts and slopes
>>
>> Just wondering if anyone has any thoughts on this question about MCMCglmm
>> priors for a multivariate mixed model with random intercepts and slopes?
>>
>> ---------- Forwarded message ----------
>> From: John Morrongiello <jrmorrongiello at gmail.com>
>> Date: Sun, Jan 18, 2015 at 3:56 PM
>> Subject: priors for multivariate mixed model in MCMCglmm with random
>> intercepts and slopes
>> To: r-sig-mixed-models at r-project.org
>>
>> Hi
>> I've got a data set with 7 response variables measured monthly through
>> time
>> across 38 individuals (FishID). There are 124 months (MonthCode)
>> representing each sampling time, with the data set having 1021
>> observations
>> in total. I have previously analysed this data using a series of
>> univariate
>> mixed models fitted in lme4 of the form
>>
>> m1<-lmer(AvGrowth~ Age + (Age|FishID) + (Age|MonthCode), data=alldata1)
>> .....mx<-lmer(.....)
>>
>> Here, Age is a continuous covariate that models an age-dependent decline
>> in
>> growth; the slope of this relationship allowed to vary amongst individuals
>> (FishID) and through time (MonthCode). To this model structure I have also
>> added environmental effects like temperature etc.
>>
>> As the 7 response variables are all measured at the same time from each
>> fish (they are estimates of growth and otolith microchemistry), I thought
>> to fit a multivariate mixed model to estimate covariances and also
>> succinctly ascertain the importance of various environmental effects.
>>
>> I have had success fitting m2 below where the overall model intercept is
>> suppressed and the trait-dependent iAge effect is allowed to vary by
>> individual and MonthCode (similar to m1):
>>
>>
>> prior1<-list(R=list(V=diag(7),nu=7),G=list(G1=list(V=diag(7),nu=7),G2=list(V=diag(7),nu=7)))
>>
>>
>> m2<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
>> ~(trait + trait:Age -1),
>> random=~us(trait:Age):FishID + us(trait:Age):MonthCode,
>> rcov=~us(trait):units,
>> family=rep("gaussian",7), prior=prior1,
>> nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)
>>
>> When I use posterior.mode(m2$VCV) however, I don't get estimates of the
>> random intercept terms FishID and MonthCode, nor their covariance with
>> Age,
>> rather just variances dependent on the iAge slope (e.g.
>> AvGrowth.std:Age):AvGrowth.std:Age).FishID). I therefore tried to
>> explicitly code a correlated random intercept and slope using us(1+
>> trait:(Age):FishID in m3:
>>
>>
>> m3<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
>> ~(trait + trait:Age -1),
>> random=~us(1+ trait:Age):FishID + us(1+ trait:Age):MonthCode,
>> rcov=~us(trait):units,
>> family=rep("gaussian",7), prior=prior1,
>> nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)
>>
>> This returns the error:
>> Error in priorformat(if (NOpriorG) { :  V is the wrong dimension for some
>> prior$G/prior$R elements
>>
>> So I'm tipping something is wrong with my priors. m4, where I estimate an
>> overall model intercept and specific random intercepts also returns the
>> same error.
>>
>>
>> m4<-MCMCglmm(cbind(AvGrowth.std,NaCa.std,SrCa.std,logMgCa.std,logBca.std,logBaCa.std,logLiCa.std)
>> ~(trait + trait:Age +1),
>> random=~us(1+ trait:Age):FishID + us(1+ trait:Age):MonthCode,
>> rcov=~us(trait):units,
>> family=rep("gaussian",7), prior=prior1,
>> nitt=60000,thin=25,burnin=10000, data=alldata1,verbose=FALSE)
>>
>> Would someone have some tips about how to get the priors for m3 and m4
>> working? I've worked through the course notes and read some email posts,
>> but admit that I a little at sea in terms of understanding the specifics
>> of
>> what is being coded on the prior side of things.
>>
>> Cheers
>>
>> John
>>
>
>

	[[alternative HTML version deleted]]


From asafw.at.wharton at gmail.com  Mon Jan 26 01:22:33 2015
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Sun, 25 Jan 2015 19:22:33 -0500
Subject: [R-sig-ME] Square root of a matrix
In-Reply-To: <54C51463.4050108@gmail.com>
References: <CAGG0PdD97LFung_B8eE_EyO7WT-K+wrH6T51zbCoEhQ55z=nFw@mail.gmail.com>
	<54C51463.4050108@gmail.com>
Message-ID: <CAGG0PdDDc6if=28zuFZcNCD2G-LNHow5=Zjhc7XFEMd91MG4cw@mail.gmail.com>

Thanks a lot Ben!

On 25 January 2015 at 11:05, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-01-22 07:10 PM, Asaf Weinstein wrote:
> > Hi,
> >
> > If Q is a positive-definite matrix, what is the most popular
> > function to obtain a matrix B s.t. B'B = Q? I found pdFactor() (in
> > the nlme package) and just wanted to know if there are more basic
> > functions for this purpose.
> >
> > Thank you! Asaf
>
>   ?chol, which can be found in base R and extended (via new methods
> for chol, and ?Cholesky) in Matrix ... ?
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJUxRRjAAoJEOCV5YRblxUHTZsH/1hBQsUYf8NXeYYAJRbXKbnD
> fe5HMKLPVWnn1TziPLPSHB9hfFPD7esh8+YhVN6oVyE/iALeKwknbDcEOKAGwnI6
> iM2TdV2wNLTnneFydPfUw9GpHYZ0RLT2mJ+rdLwEAUfTF7B/UVoF8vMV/P/ERCCo
> wdo4F532+3QDhDaH11wgHoidnLT0Ns0g11gm1/QrdrHVnHVZTh7usYqguDMim1WN
> oicnF4PsxSpMrFHQL9dUSPxBRgSM4oqBK9eCCQpi7UhCL8nzwbPAujsNPkoUsIFe
> H8CaDncupIYYmMoQo0DKvxlPQgb1N+ylnRC12v1Ljf/JlUSnNKB4CjVkuUfPfIA=
> =s0a+
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From simona.picardi at live.com  Wed Jan 28 10:57:27 2015
From: simona.picardi at live.com (Simona Picardi)
Date: Wed, 28 Jan 2015 10:57:27 +0100
Subject: [R-sig-ME] glmmadmb function
Message-ID: <BLU436-SMTP995C1A1E15DD75794A576AFE330@phx.gbl>

Dear members,

I'm using the glmmADMB package version 0.8.0 on R version 3.0.2 (2013-09-25) to run the following mixed effect models with gamma distribution:

mod1 <- glmmadmb(dist~test+(1|id),data=dataHS1,family="gamma")
mod2 <- glmmadmb(dist~test+(1|id),data=dataHS1,family="gamma",link="identity")

In the first case, using gamma with the default link, everything works fine.

As I try to specify link="identity", I get the following error message:

Error in glmmadmb(formula = dist ~ test + (1 | id), data = dataHS1, family = "gamma",  : 
  The function maximizer failed (couldn't find STD file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl'
Inoltre: Warning message:
running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 21 
 Incompatible bounds in dvar_vector& dvar_vector::operator = (const dvar_vector& t)

I already tried to set the directory, but I keep getting the same error message. 

Any help would be hugely appreciated. 

Thanks in advance,
Simona Picardi 
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Feb  2 17:15:56 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 02 Feb 2015 11:15:56 -0500
Subject: [R-sig-ME] glmmadmb function
In-Reply-To: <BLU436-SMTP995C1A1E15DD75794A576AFE330@phx.gbl>
References: <BLU436-SMTP995C1A1E15DD75794A576AFE330@phx.gbl>
Message-ID: <54CFA2BC.20303@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  In general, fitting models with link functions that allow
non-feasible results is difficult. In particular, the Gamma likelihood
is only finite for non-negative values of the x variable (only
positive values for some parameter ranges)).  So any inverse-link
function with a range that includes negative values is going to be
problematic; this includes the identity link as well as the default
(canonical) inverse.  It's interesting that it works for the default
in this case -- there are often problems, a log link is often much
more stable.

  Specifying starting values might help.

  Depending on your reasons for fitting a Gamma model, I often
recommend just log-transforming the response and fitting a linear
mixed model instead (i.e. that generally gives results very close to a
Gamma with a log link).

  Changing the directory doesn't make the model run any better, it
just dumps the output in a way that may make it easier for AD Model
Builder experts to figure out what's going on.

  Ben Bolker


On 15-01-28 04:57 AM, Simona Picardi wrote:
> Dear members,
> 
> I'm using the glmmADMB package version 0.8.0 on R version 3.0.2 
> (2013-09-25) to run the following mixed effect models with gamma 
> distribution:
> 
> mod1 <- glmmadmb(dist~test+(1|id),data=dataHS1,family="gamma")
> mod2 <- 
> glmmadmb(dist~test+(1|id),data=dataHS1,family="gamma",link="identity")
>
>
> 
In the first case, using gamma with the default link, everything
> works fine.
> 
> As I try to specify link="identity", I get the following error 
> message:
> 
> Error in glmmadmb(formula = dist ~ test + (1 | id), data =
> dataHS1, family = "gamma",  : The function maximizer failed
> (couldn't find STD file) Troubleshooting steps include (1) run with
> 'save.dir' set and inspect output files; (2) change run parameters:
> see '?admbControl' Inoltre: Warning message: running command
> './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 21
> Incompatible bounds in dvar_vector& dvar_vector::operator = (const
> dvar_vector& t)
> 
> I already tried to set the directory, but I keep getting the same 
> error message.
> 
> Any help would be hugely appreciated.
> 
> Thanks in advance, Simona Picardi [[alternative HTML version 
> deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUz6K8AAoJEOCV5YRblxUHbQ0H/RLGEMugjNfYySDOwL7RKy0j
nRAApxy8pFKXAqsYOSW6fSp7ELFeW6/j7sk/nRDT/MV61Fd+ginbxxaTjOBH6X99
00wyXni7wITePT6IO8bXfSLlpwC+rtuPAIOx3CYEueU/fbw0Qft9imLCIf5IQGrQ
opOEXM/gXXWOPPR3FzWIaUnBsKvkbnjscnI+6y7URUw1NFssUY5CtJkna+HM03KW
DirHLxycpguNAT04eS8aHhm3GRIPeKt3hpLMQdvOIz4PPmXG0Gr3ALRTtv/KTx9v
o+dWa4Y8VXg6OXlnRnWczvmU3dVX2MR/T11A9+/cP2VEbkQN5JA6kI1MiAQbXDI=
=xBmQ
-----END PGP SIGNATURE-----


From bbonit at tin.it  Mon Feb  2 17:25:16 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Mon, 2 Feb 2015 17:25:16 +0100 (CET)
Subject: [R-sig-ME] lme4 at flexLambda Error
Message-ID: <14b4b1c3a37.bbonit@tin.it>


Furst of all, thank You.
As you request this is my session info.
Best

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252   
[3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C                  
[5] LC_TIME=Italian_Italy.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_2.0     Rcpp_0.11.3  Matrix_1.1-2

loaded via a namespace (and not attached):
[1] grid_3.0.2      lattice_0.20-29 MASS_7.3-35     minqa_1.2.2    
[5] nlme_3.1-119    nloptr_1.0.4    splines_3.0.2  
>  
	[[alternative HTML version deleted]]


From steve.walker at utoronto.ca  Mon Feb  2 18:50:21 2015
From: steve.walker at utoronto.ca (Steve Walker)
Date: Mon, 02 Feb 2015 12:50:21 -0500
Subject: [R-sig-ME] lme4 at flexLambda Error
In-Reply-To: <14b4b1c3a37.bbonit@tin.it>
References: <14b4b1c3a37.bbonit@tin.it>
Message-ID: <54CFB8DD.2070909@utoronto.ca>

Sorry, it's going to be pretty hard to figure this out without a windows 
machine.  I tried building you a binary with winbuilder, but gave up 
after it didn't Just Work.  Given that flexLambda is still considered 
experimental, getting it to work on windows is still pretty far down on 
the list.

The only other thing I can think of is that your R version is pretty 
old, so maybe updating would help?

Good luck!

Steve

On 2015-02-02 11:25 AM, bbonit at tin.it wrote:
>
> Furst of all, thank You.
> As you request this is my session info.
> Best
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
> [5] LC_TIME=Italian_Italy.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_2.0     Rcpp_0.11.3  Matrix_1.1-2
>
> loaded via a namespace (and not attached):
> [1] grid_3.0.2      lattice_0.20-29 MASS_7.3-35     minqa_1.2.2
> [5] nlme_3.1-119    nloptr_1.0.4    splines_3.0.2
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From bbolker at gmail.com  Mon Feb  2 20:20:01 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Feb 2015 19:20:01 +0000 (UTC)
Subject: [R-sig-ME] lme4 at flexLambda Error
References: <14b4b1c3a37.bbonit@tin.it> <54CFB8DD.2070909@utoronto.ca>
Message-ID: <loom.20150202T201840-179@post.gmane.org>

Steve Walker <steve.walker at ...> writes:

> 
> Sorry, it's going to be pretty hard to figure this out without a windows 
> machine.  I tried building you a binary with winbuilder, but gave up 
> after it didn't Just Work.  Given that flexLambda is still considered 
> experimental, getting it to work on windows is still pretty far down on 
> the list.
> 
> The only other thing I can think of is that your R version is pretty 
> old, so maybe updating would help?
> 
> Good luck!
> 
> Steve

  For the record, this also appears at

https://github.com/lme4/lme4/issues/230

   We may have a look, but we can't make any promises about when
we're going to get to it ...


From bbonit at tin.it  Mon Feb  2 21:03:59 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Mon, 2 Feb 2015 21:03:59 +0100 (CET)
Subject: [R-sig-ME] R: Re:  lme4 at flexLambda Error
Message-ID: <14b4be47b0d.bbonit@tin.it>

Thank You ...  i 'll try to instal an update  R version   ..... 
thank you .
Best 
Bonitta


From steve.walker at utoronto.ca  Tue Feb  3 15:43:48 2015
From: steve.walker at utoronto.ca (Steve Walker)
Date: Tue, 03 Feb 2015 09:43:48 -0500
Subject: [R-sig-ME] lme4 at flexLambda Error
In-Reply-To: <loom.20150202T201840-179@post.gmane.org>
References: <14b4b1c3a37.bbonit@tin.it> <54CFB8DD.2070909@utoronto.ca>
	<loom.20150202T201840-179@post.gmane.org>
Message-ID: <54D0DEA4.7050103@utoronto.ca>

On 2015-02-02 2:20 PM, Ben Bolker wrote:
> Steve Walker <steve.walker at ...> writes:
>
>>
>> Sorry, it's going to be pretty hard to figure this out without a windows
>> machine.  I tried building you a binary with winbuilder, but gave up
>> after it didn't Just Work.  Given that flexLambda is still considered
>> experimental, getting it to work on windows is still pretty far down on
>> the list.
>>
>> The only other thing I can think of is that your R version is pretty
>> old, so maybe updating would help?
>>
>> Good luck!
>>
>> Steve
>
>    For the record, this also appears at
>
> https://github.com/lme4/lme4/issues/230
>
>     We may have a look, but we can't make any promises about when
> we're going to get to it ...

I just had a look.  I'm able to reproduce Bonitta's error message in a 
different context with:

L <- load(system.file("testdata","polytomous_vcov_ex.RData",
                       package="lme4"))
vcov(polytomous_vcov_ex)
Error in .Call(merPredDCreate, as(X, "matrix"), Lambdat, LamtUt, Lind,  :
   Incorrect number of arguments (17), expecting 15 for 'merPredDCreate'

However, the only reason for this failure is that `polytomous_vcov_ex` 
is a glmerMod object fitted with lme4 version < 2.0 (i.e. not 
flexLambda).  In those pre-2.0 versions, merPredDCreate took 17 
arguments, whereas in 2.0 it takes 15.  In particular, the `Lind` and 
`theta` arguments are no longer used in flexLambda.

The reason for this change relates to the whole point of flexLambda, 
which is to allow more flexible parameterizations of the relative 
covariance factor, Lambda.  In pre-2.0 versions (e.g. the current 
version on CRAN), `theta` contains the parameters of `Lambda` and `Lind` 
controls the mapping from `theta` to `Lambda`.  In flexLambda (i.e. 
v2.0), the parameterization is handled on the R-side to make it more 
flexible for users and those interested in extending lme4.

I still don't know exactly how your error arose, but I would need more 
information for that.  In general however, I would just recommend 
keeping your lme4_1.8 and lme4_2.0 sessions very clearly separated.

Steve

> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From pargyriou at gmail.com  Wed Feb  4 14:35:36 2015
From: pargyriou at gmail.com (Paraskevi Argyriou)
Date: Wed, 4 Feb 2015 13:35:36 +0000
Subject: [R-sig-ME] post for likelihood ration tests
Message-ID: <7B54E664-4525-4219-95F4-86FFA1547792@gmail.com>

Hi there, 

I was wondering if i could get some advice regarding the model comparison when interaction is included. please see some details below


Info

DV: Metaphoricity (continuous)

Fixed effects (within subjects manipulation): Hand Free (Left v. Right)

                                                                        Gesture (Absence vs. Presence)

Random effects: Participants

                        Items

 

Maximal model (driven by our research question)

Model1 = lmer(Metaphoricity ~ HandFree*Gesture + (1 + HandFree*Gesture|Participants) + (1 + HandFree*Gesture|Items)

 

 

Reduced model with main effects only

Model2 = lmer(Metaphoricity ~ HandFree + Gesture + (1 + HandFree + Gesture|Participants) + (1 + HandFree + Gesture|Items)

 

 

Null model

Model3 = lmer(Metaphoricity ~ 1 + (1 + HandFree*Gesture|Participants) + (1 + HandFree*Gesture|Items)

 

 

 

Question:

1.     What will be the correct reduced/null model to compare the maximal one with in a likelihood ratio test as a means to obtain p-values?

a.     If I use the reduced model with main effects only the random effect structure would have to change contrary to Barr et al.?s (2013) suggestion to keep the same random effect structure.

b.     If I use the null model with no fixed effect I am not sure I understand why we keep the by subjects and by items slope for the interaction when the interaction is not in the model. 
	[[alternative HTML version deleted]]


From tcarpenter at spu.edu  Thu Feb  5 02:25:19 2015
From: tcarpenter at spu.edu (Carpenter, Tom)
Date: Thu, 5 Feb 2015 01:25:19 +0000
Subject: [R-sig-ME] lme4: Parameter contrasts?
Message-ID: <1EB8F230-E942-4121-83DA-088B0188D52C@spu.edu>

Hoping someone has some advice here. I recently made the switch from using HLM to lmer. I know that in HLM, you could do a parameter contrast (e.g., contrast two fixed effects against each other and test the significance of the contrast). I was curious if anyone knows how to do this in R? I have run a model in lmer (with standardized predictors) and wish to see if one fixed effect is significantly larger (more predictive) than other fixed effect.

If that is not possible in lme4, does anyone have any advice for how to bootstrap it? I?m fine letting the thing run overnight to get a 95% CI if anyone has any suggestions.

Tom Carpenter, Ph.D.
Instructor of Psychology
Seattle Pacific University
3307 3rd Ave W. Suite 107,
Seattle, WA, 98119
tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>
Office: (206) 281-2916
Fax: (206) 281-2695












	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Feb  5 02:34:18 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 04 Feb 2015 20:34:18 -0500
Subject: [R-sig-ME] lme4: Parameter contrasts?
In-Reply-To: <1EB8F230-E942-4121-83DA-088B0188D52C@spu.edu>
References: <1EB8F230-E942-4121-83DA-088B0188D52C@spu.edu>
Message-ID: <54D2C89A.3010505@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-02-04 08:25 PM, Carpenter, Tom wrote:
> Hoping someone has some advice here. I recently made the switch
> from using HLM to lmer. I know that in HLM, you could do a
> parameter contrast (e.g., contrast two fixed effects against each
> other and test the significance of the contrast). I was curious if
> anyone knows how to do this in R? I have run a model in lmer (with
> standardized predictors) and wish to see if one fixed effect is
> significantly larger (more predictive) than other fixed effect.
> 
> If that is not possible in lme4, does anyone have any advice for
> how to bootstrap it? I?m fine letting the thing run overnight to
> get a 95% CI if anyone has any suggestions.
> 
> Tom Carpenter, Ph.D. Instructor of Psychology Seattle Pacific 
> University 3307 3rd Ave W. Suite 107, Seattle, WA, 98119 
> tcarpenter at spu.edu<mailto:tcarpenter at spu.edu> Office: (206)
> 281-2916 Fax: (206) 281-2695
> 

  I'm pretty sure that Russ Lenth's "lsmeans" package works with
merMod objects.

  bootstrapping would go something like

  bootMer(fitted, FUN = function(m) { f <- fixef(m); f[3]-f[1] })

(for example, to compare fixed effect parameters #3 and #1).  The PB
estimates would probably be a little bit better (i.e., take account of
more aspects of variation) than the lsmeans() contrast, which would be
conditional on the estimates of the RE variance ...

  (however, you might conceivably run into problems with
https://github.com/lme4/lme4/issues/231 , which we haven't gotten
around to fixing yet ...)

  Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU0siaAAoJEOCV5YRblxUHEvkIALJns7YtDxYv49uxRTcDk2Ms
dMbS1ppo9NY1jAbrC24B1ANBctZUxGI3be889dvXBR3kZLPTW5F3ajM6J5DLEXDt
xXJ7QVT4fz6TvUztmWhZFhNBFT8HJYXSfcLCiXVuXiW1K2Wv7mW2FetplgFKrEho
wJbFCbxi/0/xFjJJbIRDXTZS2JBSklVN/TmBCeOW+ky3dQ4m62amKtuMiaTdjFL1
BTByO9iAS3mt6GXM88ztxrCODZoCgGrFaMVg5KQyAxD8F+2BWmnna2QGdkQg0abV
BWdeZZiCPeHYxO9kEsifReDrYNOKIhMED+plgKD9k08+eY1YSjBMiB/5SGmakvU=
=bb22
-----END PGP SIGNATURE-----


From A.Robinson at ms.unimelb.edu.au  Thu Feb  5 03:58:28 2015
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 5 Feb 2015 13:58:28 +1100
Subject: [R-sig-ME] lme4: Parameter contrasts?
In-Reply-To: <54D2C89A.3010505@gmail.com>
References: <1EB8F230-E942-4121-83DA-088B0188D52C@spu.edu>
	<54D2C89A.3010505@gmail.com>
Message-ID: <CAHyGmd7XfWXD4TjJy2UUzromx+vfN3jAmcWUYxqjf74OE3sztw@mail.gmail.com>

Also maybe try the inestimable estimable() in gmodels.

Cheers

Andrew

On Thu, Feb 5, 2015 at 12:34 PM, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-02-04 08:25 PM, Carpenter, Tom wrote:
> > Hoping someone has some advice here. I recently made the switch
> > from using HLM to lmer. I know that in HLM, you could do a
> > parameter contrast (e.g., contrast two fixed effects against each
> > other and test the significance of the contrast). I was curious if
> > anyone knows how to do this in R? I have run a model in lmer (with
> > standardized predictors) and wish to see if one fixed effect is
> > significantly larger (more predictive) than other fixed effect.
> >
> > If that is not possible in lme4, does anyone have any advice for
> > how to bootstrap it? I?m fine letting the thing run overnight to
> > get a 95% CI if anyone has any suggestions.
> >
> > Tom Carpenter, Ph.D. Instructor of Psychology Seattle Pacific
> > University 3307 3rd Ave W. Suite 107, Seattle, WA, 98119
> > tcarpenter at spu.edu<mailto:tcarpenter at spu.edu> Office: (206)
> > 281-2916 Fax: (206) 281-2695
> >
>
>   I'm pretty sure that Russ Lenth's "lsmeans" package works with
> merMod objects.
>
>   bootstrapping would go something like
>
>   bootMer(fitted, FUN = function(m) { f <- fixef(m); f[3]-f[1] })
>
> (for example, to compare fixed effect parameters #3 and #1).  The PB
> estimates would probably be a little bit better (i.e., take account of
> more aspects of variation) than the lsmeans() contrast, which would be
> conditional on the estimates of the RE variance ...
>
>   (however, you might conceivably run into problems with
> https://github.com/lme4/lme4/issues/231 , which we haven't gotten
> around to fixing yet ...)
>
>   Ben Bolker
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJU0siaAAoJEOCV5YRblxUHEvkIALJns7YtDxYv49uxRTcDk2Ms
> dMbS1ppo9NY1jAbrC24B1ANBctZUxGI3be889dvXBR3kZLPTW5F3ajM6J5DLEXDt
> xXJ7QVT4fz6TvUztmWhZFhNBFT8HJYXSfcLCiXVuXiW1K2Wv7mW2FetplgFKrEho
> wJbFCbxi/0/xFjJJbIRDXTZS2JBSklVN/TmBCeOW+ky3dQ4m62amKtuMiaTdjFL1
> BTByO9iAS3mt6GXM88ztxrCODZoCgGrFaMVg5KQyAxD8F+2BWmnna2QGdkQg0abV
> BWdeZZiCPeHYxO9kEsifReDrYNOKIhMED+plgKD9k08+eY1YSjBMiB/5SGmakvU=
> =bb22
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Andrew Robinson
Deputy Director, CEBRA, School of Biosciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: +61-3-8344
4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

MSME: http://www.crcpress.com/product/isbn/9781439858028
FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/

	[[alternative HTML version deleted]]


From karl.ove.hufthammer at helse-bergen.no  Thu Feb  5 13:12:17 2015
From: karl.ove.hufthammer at helse-bergen.no (Hufthammer, Karl Ove)
Date: Thu, 5 Feb 2015 13:12:17 +0100
Subject: [R-sig-ME] lme4: Parameter contrasts?
Message-ID: <0D0C1D497D86144EA6BD73E47CDB64CA11B04D4FBA@BGO-MCS005.ihelse.net>

Tom Carpenter wrote:
> Hoping someone has some advice here. I recently made the switch from using
> HLM to lmer. I know that in HLM, you could do a parameter contrast (e.g., contrast
> two fixed effects against each other and test the significance of the contrast).
> I was curious if anyone knows how to do this in R

There are at least four options:

the multcomp package
estimable() in the gmodels package
the lsmeans package
the contrast package

Some of these work with nlme models (lme and/or gls) and some with lme4 models, and some with both (and with other type of models, e.g. GEE models). Some of them can adjust for multiple comparisons. They all give slightly different answers, even when not adjusting for multiple comparisons. I think this is mostly related to treating the degrees of freedom differently:

multcomp uses asymptotic tests (?infinite? degrees of freedom, z-tests) for everything except normal linear (non mixed-effects models), where it uses ordinary t-tests. (It even uses z-tests for gls models, though I think this shouldn?t be necessary.) It has excellent support for adjusting for multiple comparisons, in a variety of ways.

estimable() uses the *minimum* of the degrees of freedom of the parameters of the chosen contract when testing and constructing confidence intervals.

lsmeans uses asymptotic tests for lme(r) models, but calculates the correct (?) degrees of freedom for gls and lm objects. (In a simple gls example I tested, it seemed to sum the degrees of freedom.) It also supports the multcomp package.

contrast calculates degrees of freedom for both lme and gls models. However, the calculated degrees of freedom seems to differ between what I believe should basically be equivalent lme and gls models (e.g., a two time-point longitudinal gls model with compound symmetry and a mixed effects model with a random intercept for subject).

-- 
Karl Ove Hufthammer

From pierces1 at msu.edu  Thu Feb  5 14:43:06 2015
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Thu, 5 Feb 2015 08:43:06 -0500
Subject: [R-sig-ME] lme4: Parameter contrasts?
In-Reply-To: <1EB8F230-E942-4121-83DA-088B0188D52C@spu.edu>
References: <1EB8F230-E942-4121-83DA-088B0188D52C@spu.edu>
Message-ID: <000001d04149$ac4d75c0$04e86140$@msu.edu>

You might want to check out whether the multcomp package would handle this. Bretz et al. (2010) describes use of the package. 

Bretz, F., Hothorn, T., & Westfall, P. (2010). Multiple comparisons using R. Boca Raton, FL: Chapman & Hall/CRC.


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Carpenter, Tom [mailto:tcarpenter at spu.edu] 
Sent: Wednesday, February 04, 2015 8:25 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] lme4: Parameter contrasts?

Hoping someone has some advice here. I recently made the switch from using HLM to lmer. I know that in HLM, you could do a parameter contrast (e.g., contrast two fixed effects against each other and test the significance of the contrast). I was curious if anyone knows how to do this in R? I have run a model in lmer (with standardized predictors) and wish to see if one fixed effect is significantly larger (more predictive) than other fixed effect.

If that is not possible in lme4, does anyone have any advice for how to bootstrap it? I?m fine letting the thing run overnight to get a 95% CI if anyone has any suggestions.

Tom Carpenter, Ph.D.
Instructor of Psychology
Seattle Pacific University
3307 3rd Ave W. Suite 107,
Seattle, WA, 98119
tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>
Office: (206) 281-2916
Fax: (206) 281-2695












	[[alternative HTML version deleted]]


From esm120 at msstate.edu  Thu Feb  5 00:52:41 2015
From: esm120 at msstate.edu (Eric Michel)
Date: Wed, 4 Feb 2015 17:52:41 -0600
Subject: [R-sig-ME] Back-transforming posterior means and credible intervals
Message-ID: <02b701d040d5$aa200020$fe600060$@msstate.edu>

Hello Everyone,

I am running a full animal model in MCMCglmm and am trying to back-transform
the posterior means and credible intervals from the model output to make
them more interpretable. Forgive me if there is a simple solution to this
but I am relatively new to Program R and am having a hard time finding a
solution.

 

Thanks for your help!

 

Eric Michel 

 

 

 

 


	[[alternative HTML version deleted]]


From lauren.meyer90 at gmail.com  Tue Feb  3 07:25:47 2015
From: lauren.meyer90 at gmail.com (Lauren Meyer)
Date: Tue, 3 Feb 2015 16:25:47 +1000
Subject: [R-sig-ME] df pseudoreplication in lme model
Message-ID: <CAKk3=oR=77UG25RLD1h9UK-o8aquHss=oD9r1MqR627r=hT9fw@mail.gmail.com>

Hello, I am trying to assess weather or not my df are pseudoreplicated in my
lme model.

my study was undertaken on five fish (labeled PC) each tested in two
replicates(REP), across each combination of three treatments HOM, C18 and
CU, each of which had two levels; HOM(SON, BLD),C18 SML, BIG), CU (YES, NO).
The variable we are assessing is the amount of toxin extracted (TOX1). Also,
some data is missing, and has already been removed. I am using an lme
model, as the study design is similar to a split plot design, with a
2X2X2 full factorial design. There are a total of 65 observations.


Here is the model I am using:
>model<- lme(TOX1~HOM*C18*CU, random=~1|PC/REP, data=Data4, method="ML")
Linear mixed-effects model fit by maximum likelihood

which results in 48 DF for everything. Furthermore, I removed the
three way interaction as well as all of the two way interactions as
they were deemed non-significant, producing the final model :

> model5<- lme(TOX1~HOM+C18+CU, random=~1|PC/REP, data=Data4, method="ML")

which has 52 DF

However, I am unsure if these Df are pseudoreplicated and would like some
help in how to determine if this is the case. I am happy to upload the
full dataset and/or any of the outputs if that would help.

Thank you


From tcarpenter at spu.edu  Fri Feb  6 02:28:09 2015
From: tcarpenter at spu.edu (Carpenter, Tom)
Date: Fri, 6 Feb 2015 01:28:09 +0000
Subject: [R-sig-ME] lme4: Parameter contrasts?
In-Reply-To: <000001d04149$ac4d75c0$04e86140$@msu.edu>
References: <1EB8F230-E942-4121-83DA-088B0188D52C@spu.edu>,
	<000001d04149$ac4d75c0$04e86140$@msu.edu>
Message-ID: <2726C0DA-9983-4682-97FC-D7E11588FDDA@spu.edu>

Thanks! I was also hoping there might be an easy way to bootstrap it.

Tom Carpenter, Ph.D.
Instructor of Psychology
Seattle Pacific University
3307 3rd Ave W. Suite 107,
Seattle, WA, 98119
tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>
Office: (206) 281-2916
Mobile: (206) 276-1541
Fax: (206) 281-2695

On Feb 5, 2015, at 5:43 AM, Steven J. Pierce <pierces1 at msu.edu<mailto:pierces1 at msu.edu>> wrote:

You might want to check out whether the multcomp package would handle this. Bretz et al. (2010) describes use of the package.

Bretz, F., Hothorn, T., & Westfall, P. (2010). Multiple comparisons using R. Boca Raton, FL: Chapman & Hall/CRC.


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Carpenter, Tom [mailto:tcarpenter at spu.edu]
Sent: Wednesday, February 04, 2015 8:25 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] lme4: Parameter contrasts?

Hoping someone has some advice here. I recently made the switch from using HLM to lmer. I know that in HLM, you could do a parameter contrast (e.g., contrast two fixed effects against each other and test the significance of the contrast). I was curious if anyone knows how to do this in R? I have run a model in lmer (with standardized predictors) and wish to see if one fixed effect is significantly larger (more predictive) than other fixed effect.

If that is not possible in lme4, does anyone have any advice for how to bootstrap it? I?m fine letting the thing run overnight to get a 95% CI if anyone has any suggestions.

Tom Carpenter, Ph.D.
Instructor of Psychology
Seattle Pacific University
3307 3rd Ave W. Suite 107,
Seattle, WA, 98119
tcarpenter at spu.edu<mailto:tcarpenter at spu.edu><mailto:tcarpenter at spu.edu>
Office: (206) 281-2916
Fax: (206) 281-2695












   [[alternative HTML version deleted]]




	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Fri Feb  6 03:53:50 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Fri, 6 Feb 2015 13:53:50 +1100
Subject: [R-sig-ME] lme4: Parameter contrasts?
In-Reply-To: <2726C0DA-9983-4682-97FC-D7E11588FDDA@spu.edu>
References: <1EB8F230-E942-4121-83DA-088B0188D52C@spu.edu>
	<000001d04149$ac4d75c0$04e86140$@msu.edu>
	<2726C0DA-9983-4682-97FC-D7E11588FDDA@spu.edu>
Message-ID: <CAF5_5czx9nkGcmkaucQtgWw8jrcmbSdgxqAPTJM1ZEn=9cv3jw@mail.gmail.com>

A parametric bootstrap should be easy to achieve using the simulate method
and the parametric bootstrap from the boot package.

On 6 February 2015 at 12:28, Carpenter, Tom <tcarpenter at spu.edu> wrote:

> Thanks! I was also hoping there might be an easy way to bootstrap it.
>
> Tom Carpenter, Ph.D.
> Instructor of Psychology
> Seattle Pacific University
> 3307 3rd Ave W. Suite 107,
> Seattle, WA, 98119
> tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>
> Office: (206) 281-2916
> Mobile: (206) 276-1541
> Fax: (206) 281-2695
>
> On Feb 5, 2015, at 5:43 AM, Steven J. Pierce <pierces1 at msu.edu<mailto:
> pierces1 at msu.edu>> wrote:
>
> You might want to check out whether the multcomp package would handle
> this. Bretz et al. (2010) describes use of the package.
>
> Bretz, F., Hothorn, T., & Westfall, P. (2010). Multiple comparisons using
> R. Boca Raton, FL: Chapman & Hall/CRC.
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
>
> -----Original Message-----
> From: Carpenter, Tom [mailto:tcarpenter at spu.edu]
> Sent: Wednesday, February 04, 2015 8:25 PM
> To: r-sig-mixed-models at r-project.org<mailto:
> r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] lme4: Parameter contrasts?
>
> Hoping someone has some advice here. I recently made the switch from using
> HLM to lmer. I know that in HLM, you could do a parameter contrast (e.g.,
> contrast two fixed effects against each other and test the significance of
> the contrast). I was curious if anyone knows how to do this in R? I have
> run a model in lmer (with standardized predictors) and wish to see if one
> fixed effect is significantly larger (more predictive) than other fixed
> effect.
>
> If that is not possible in lme4, does anyone have any advice for how to
> bootstrap it? I?m fine letting the thing run overnight to get a 95% CI if
> anyone has any suggestions.
>
> Tom Carpenter, Ph.D.
> Instructor of Psychology
> Seattle Pacific University
> 3307 3rd Ave W. Suite 107,
> Seattle, WA, 98119
> tcarpenter at spu.edu<mailto:tcarpenter at spu.edu><mailto:tcarpenter at spu.edu>
> Office: (206) 281-2916
> Fax: (206) 281-2695
>
>
>
>
>
>
>
>
>
>
>
>
>    [[alternative HTML version deleted]]
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From karl.ove.hufthammer at helse-bergen.no  Fri Feb  6 09:34:07 2015
From: karl.ove.hufthammer at helse-bergen.no (Hufthammer, Karl Ove)
Date: Fri, 6 Feb 2015 09:34:07 +0100
Subject: [R-sig-ME] Differences in degrees of freedom between a
 mixed-effects model and a gls model using nlme
Message-ID: <0D0C1D497D86144EA6BD73E47CDB64CA11B04D4FC9@BGO-MCS005.ihelse.net>

Dear list members,

I'm having some problems understanding the difference in degrees of freedom between a mixed-effect model and a gls model, both fitted using the nlme package. I'm used to it being difficult to figure out the 'correct' (if such a thing exists) number of degrees of freedom in mixed-effects models, but in the following very simple example the *mixed-effects model* seems to use the correct degrees of freedom, while the gls model uses too many degrees of freedom.

Here's the example. Basically, I want to test if a mixed-effects model is equivalent to a paired t-test.

# Generate some correlated data
set.seed(1)
n = 10
u = 5 + rnorm(n, sd=1)
x1 = u + rnorm(n)
x2 = u + rnorm(n) + 1

# A paired t-test is, as expected, more powerful than an unpaired one
t.test(x1, x2)              # p = .1407
t.test(x1, x2, paired=TRUE) # p = .0597

The relevant line of output for the paired test is:
t = -2.1532, df = 9, p-value = 0.05972

# Fit a linear mixed-effects model
library(nlme)
l = lme(values~ind, random=~1|id, data=df)
summary(l)

The relevant lines of output are:

               Value Std.Error DF   t-value p-value
indx2       0.617482 0.2867705  9  2.153226  0.0597

So we get the same t-value (to five decimal places - it differs in the last decimal), degrees of freedom and p-value as in the paired t-test. Let's now try to fit a gls model for correlated data. This should in theory be equivalent to doing a paired t-test. We get:

#  Fit a correlated gls model
library(nlme)
l2 = gls(values~ind, correlation=corSymm(form=~1|id), data=df)
summary(l2)

               Value Std.Error   t-value p-value
indx2       0.617482 0.2867703  2.153228  0.0451

The t-value is the same as in the t-test (here to *six* decimal place), but the p-value is too small. The reason is that the test uses twice the degrees of freedom that it should. It uses 18 degrees of freedom:

2*pt(2.153228, 18, lower.tail = FALSE) # 0.04510817

So the mixed-effects model gets it right, while the gls model gets it wrong. But it's actually the *gls* model that should be equivalent to the paired t-test, not the mixed-effects model. We can easily see this by changing the correlation to be negative:

set.seed(2)
n = 10
u = 5 + rnorm(n, sd=1)
x1 = u + rnorm(n)
x2 = 15 - 2*u + rnorm(n) + 1
cor(x1, x2) # -0.50

Unpaired t-test:
t = -0.5052, df = 15.753, p-value = 0.6204

Paired t-test (note that the p-value is *greater* than for the unpaired case):
t = -0.418, df = 9, p-value = 0.6857

Mixed-effects model:

               Value Std.Error DF  t-value p-value
indx2       0.481868 0.9537336  9 0.505244  0.6255

Of course, the mixed-effects model doesn't really fit the data. The random effect variance is estimated to be ~0, so basically this corresponds to an *unpaired* t-test (but one that assumes equal variance). Note that the t-statistic is equal to the t-statistic of the unpaired t-test (though the latter uses 18 degrees of freedom, while this model uses 9 degrees of freedom).

Now, if I've understood everything correctly, the gls model should *exactly* correspond to a paired t-test; it's the same underlying model. And indeed we get the same t-statistic (0.418):

               Value Std.Error  t-value p-value
indx2       0.481868 1.1526947 0.418036  0.6809

But the p-value differs somewhat, since the gls model assumes 18 degrees of freedom, while the t-test (correctly) assumes 9 degrees of freedom.

At least for positive correlations, a mixed-effect random intercept model and a gls model with compound symmetry should be *almost* equivalent, so I see no reason that the gls model can assume that the test statistics has twice as many degrees of freedom as in the mixed-effects model. So why the discrepancy? Shouldn't I trust the degrees of freedom calculations from gls()?

-- 
Karl Ove Hufthammer


From pargyriou at gmail.com  Fri Feb  6 16:42:28 2015
From: pargyriou at gmail.com (Paraskevi Argyriou)
Date: Fri, 6 Feb 2015 15:42:28 +0000
Subject: [R-sig-ME] LME model comparison - likelihood ratio tests
Message-ID: <CADqE61K9sjQimwXCQp8sGcJGdauWTaBKkX3WbaRjjZmZ1b4HRQ@mail.gmail.com>

Hi there,

I was hoping if i could get some advice on the following:

*Info of design*
DV = continuous
IV1 = categorical predictor with two levels
IV2 = categorical predictor with two levels
Within participants and items manipulation

Following, Barr et al. (2013) paper on keeping the random effect structure
maximal in psycholinguistic experimental designs within subjects/items,
plus based on the fact that my research question needs to asses the
interaction between the two predictors, I built the following model

model1 -> lmer(DV ~ IV1 + IV2 + IV1:IV2 + (1 + IV1:IV2|Participant) + (1 +
IV1:IV2|Item), REML = FALSE)

*Other models*
model2 -> lmer(DV ~ IV1*IV2 + (1 + IV1*IV2|Participant) + (1 +
IV1*IV2|Item), REML = FALSE)

model.null.1 -> lmer(DV ~ IV1 + IV2 + (1 + IV1:IV2|Participant) + (1 +
IV1:IV2|Item), REML = FALSE)

model.null.2 -> lmer(DV ~ 1 + (1 + IV1*IV2|Participant) + (1 +
IV1*IV2|Item), REML = FALSE)

*Questions*
1. Is model1 the correct one?
2. What is the best comparison for the likelihood ratio tests to assess if
the interaction improves the model fit? Would it be anova(model.null.1,
model1)? Does it make sense to use a null model like model.null.2 and
compare it with model2?
3. Is it acceptable to further explore the simple main effects and
contrasts(using the glht( ) function), if the interaction reveals as not
important for the model fit?
4. Is it a good practice to center categorical predictors? How do we
perform contrasts with centered predictors?
5. Why R gives different results when you use string categorical predictors
compared to dummy coded predictors compared to centered ones?

I am sorry for all these questions and please excuse my ignorance -
Many thanks in advance for any help.

	[[alternative HTML version deleted]]


From m.ramon.fernandez at gmail.com  Fri Feb  6 23:01:10 2015
From: m.ramon.fernandez at gmail.com (Manuel Ramon)
Date: Fri, 6 Feb 2015 23:01:10 +0100
Subject: [R-sig-ME]  Example of Fixed Random effects decomposition
Message-ID: <CAHB8JpL-0oRPJPbnnvSd+3vaMWgXGeWATNKRFzYLy+s9_=B19w@mail.gmail.com>

Hi there,

A time ago, I found an example (I don't remember where) in which estimated
effects of fixed and random factors were removed from raw data. Thus,
removing effect of a fixed factor changed mean of raw data but not variance
(displaying as histogram). Contrary, removing random factor effect reduced
variability of raw data but not its mean (the histogram become more
narrower but having the same mean).

Does anyone know where I could I found such example or could help me
to produce one?

Thank you in advance for any help.

Manuel.


-- 

Manuel Ram?n
m[dot]ramon[dot]fernandez[at]gmail[dot]com

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Sun Feb  8 08:29:37 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sun, 8 Feb 2015 18:29:37 +1100
Subject: [R-sig-ME] Differences in degrees of freedom between a
 mixed-effects model and a gls model using nlme
In-Reply-To: <0D0C1D497D86144EA6BD73E47CDB64CA11B04D4FC9@BGO-MCS005.ihelse.net>
References: <0D0C1D497D86144EA6BD73E47CDB64CA11B04D4FC9@BGO-MCS005.ihelse.net>
Message-ID: <CAF5_5cx_QDRbw-s5j_+_OSRmJiuSYtrjFeU6f5NYoa4cpxza6g@mail.gmail.com>

All 3 (paired t-test, mixed effect and gls with compound symmetry) are
fitting the same model, and so should give the same result. That is what
you see with the first example. The gls model is not getting it wrong
except for the df.

For the second the 3 model results should again be the same. I'm not
certain why but it may be numerical. Even though the data come from a model
that isn't correct for the fitting that should be irrelevant, it is the
data that produce the model fit not the model that produces the data.
Possibly estimates of the correlation are poor when there is little
correlation, and that flows through to the mixed effects and glass results.

The relationship to the unpaired t-test is probably irrelevant. Note also
that the default for the t.test is unequal variances whereas for a mixed
model it is equal variances.

The df for gls is obviously in a sense a bug. Getting the df for a mixed
model isn't easy. Here we have a nice simple correlation structure and
there is an obvious correct answer, but usually there isn't one. If the
model assumed uncorrelated data then the gls df would be correct, so it is
necessary for the software to work out what is going on. Using parametric
bootstrapping to determine the underlying distribution seems a better
method if accuracy is important.

Ken

On 6 February 2015 at 19:34, Hufthammer, Karl Ove <
karl.ove.hufthammer at helse-bergen.no> wrote:

> Dear list members,
>
> I'm having some problems understanding the difference in degrees of
> freedom between a mixed-effect model and a gls model, both fitted using the
> nlme package. I'm used to it being difficult to figure out the 'correct'
> (if such a thing exists) number of degrees of freedom in mixed-effects
> models, but in the following very simple example the *mixed-effects model*
> seems to use the correct degrees of freedom, while the gls model uses too
> many degrees of freedom.
>
> Here's the example. Basically, I want to test if a mixed-effects model is
> equivalent to a paired t-test.
>
> # Generate some correlated data
> set.seed(1)
> n = 10
> u = 5 + rnorm(n, sd=1)
> x1 = u + rnorm(n)
> x2 = u + rnorm(n) + 1
>
> # A paired t-test is, as expected, more powerful than an unpaired one
> t.test(x1, x2)              # p = .1407
> t.test(x1, x2, paired=TRUE) # p = .0597
>
> The relevant line of output for the paired test is:
> t = -2.1532, df = 9, p-value = 0.05972
>
> # Fit a linear mixed-effects model
> library(nlme)
> l = lme(values~ind, random=~1|id, data=df)
> summary(l)
>
> The relevant lines of output are:
>
>                Value Std.Error DF   t-value p-value
> indx2       0.617482 0.2867705  9  2.153226  0.0597
>
> So we get the same t-value (to five decimal places - it differs in the
> last decimal), degrees of freedom and p-value as in the paired t-test.
> Let's now try to fit a gls model for correlated data. This should in theory
> be equivalent to doing a paired t-test. We get:
>
> #  Fit a correlated gls model
> library(nlme)
> l2 = gls(values~ind, correlation=corSymm(form=~1|id), data=df)
> summary(l2)
>
>                Value Std.Error   t-value p-value
> indx2       0.617482 0.2867703  2.153228  0.0451
>
> The t-value is the same as in the t-test (here to *six* decimal place),
> but the p-value is too small. The reason is that the test uses twice the
> degrees of freedom that it should. It uses 18 degrees of freedom:
>
> 2*pt(2.153228, 18, lower.tail = FALSE) # 0.04510817
>
> So the mixed-effects model gets it right, while the gls model gets it
> wrong. But it's actually the *gls* model that should be equivalent to the
> paired t-test, not the mixed-effects model. We can easily see this by
> changing the correlation to be negative:
>
> set.seed(2)
> n = 10
> u = 5 + rnorm(n, sd=1)
> x1 = u + rnorm(n)
> x2 = 15 - 2*u + rnorm(n) + 1
> cor(x1, x2) # -0.50
>
> Unpaired t-test:
> t = -0.5052, df = 15.753, p-value = 0.6204
>
> Paired t-test (note that the p-value is *greater* than for the unpaired
> case):
> t = -0.418, df = 9, p-value = 0.6857
>
> Mixed-effects model:
>
>                Value Std.Error DF  t-value p-value
> indx2       0.481868 0.9537336  9 0.505244  0.6255
>
> Of course, the mixed-effects model doesn't really fit the data. The random
> effect variance is estimated to be ~0, so basically this corresponds to an
> *unpaired* t-test (but one that assumes equal variance). Note that the
> t-statistic is equal to the t-statistic of the unpaired t-test (though the
> latter uses 18 degrees of freedom, while this model uses 9 degrees of
> freedom).
>
> Now, if I've understood everything correctly, the gls model should
> *exactly* correspond to a paired t-test; it's the same underlying model.
> And indeed we get the same t-statistic (0.418):
>
>                Value Std.Error  t-value p-value
> indx2       0.481868 1.1526947 0.418036  0.6809
>
> But the p-value differs somewhat, since the gls model assumes 18 degrees
> of freedom, while the t-test (correctly) assumes 9 degrees of freedom.
>
> At least for positive correlations, a mixed-effect random intercept model
> and a gls model with compound symmetry should be *almost* equivalent, so I
> see no reason that the gls model can assume that the test statistics has
> twice as many degrees of freedom as in the mixed-effects model. So why the
> discrepancy? Shouldn't I trust the degrees of freedom calculations from
> gls()?
>
> --
> Karl Ove Hufthammer
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Mon Feb  9 05:36:11 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Feb 2015 04:36:11 +0000 (UTC)
Subject: [R-sig-ME] Differences in degrees of freedom between a
	mixed-effects model and a gls model using nlme
References: <0D0C1D497D86144EA6BD73E47CDB64CA11B04D4FC9@BGO-MCS005.ihelse.net>
	<CAF5_5cx_QDRbw-s5j_+_OSRmJiuSYtrjFeU6f5NYoa4cpxza6g@mail.gmail.com>
Message-ID: <loom.20150209T053152-169@post.gmane.org>

Ken Beath <ken.beath at ...> writes:

> 
> All 3 (paired t-test, mixed effect and gls with compound symmetry) are
> fitting the same model, and so should give the same result. That is what
> you see with the first example. The gls model is not getting it wrong
> except for the df.
> 
> For the second the 3 model results should again be the same. I'm not
> certain why but it may be numerical. Even though the data come 
> from a model
> that isn't correct for the fitting that should be irrelevant, it is the
> data that produce the model fit not the model that produces the data.
> Possibly estimates of the correlation are poor when there is little
> correlation, and that flows through to the mixed effects and 
> gls results.
> 
> The relationship to the unpaired t-test is probably irrelevant. Note also
> that the default for the t.test is unequal variances whereas for a mixed
> model it is equal variances.
> 
> The df for gls is obviously in a sense a bug. Getting the df for a mixed
> model isn't easy. Here we have a nice simple correlation structure and
> there is an obvious correct answer, but usually there isn't one. If the
> model assumed uncorrelated data then the gls df would be correct, so it is
> necessary for the software to work out what is going on. Using parametric
> bootstrapping to determine the underlying distribution seems a better
> method if accuracy is important.
> 
> Ken
> 

  For what it's worth you can easily see what gls() is doing to
get its df, and confirm that it's naive, by printing nlme:::summary.gls:

  tTable[, "p-value"] <- 2 * pt(-abs(tTable[, "t-value"]), 
        dims$N - dims$p)

For what it's worth, I've found that the df calculations used by
lme() often fail quite badly for random-slopes models ... it's often
really hard to guess, even for simpler designs (i.e. where there
really is a precise correspondence with an F distribution -- no correlation
structures or lack of balance or crossed random effects).


From bbolker at gmail.com  Mon Feb  9 05:47:35 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Feb 2015 04:47:35 +0000 (UTC)
Subject: [R-sig-ME] df pseudoreplication in lme model
References: <CAKk3=oR=77UG25RLD1h9UK-o8aquHss=oD9r1MqR627r=hT9fw@mail.gmail.com>
Message-ID: <loom.20150209T053627-910@post.gmane.org>

Lauren Meyer <lauren.meyer90 at ...> writes:

> 
> Hello, I am trying to assess whether or not 
> my df are pseudoreplicated in my
> lme model.
> 
> my study was undertaken on five fish (labeled PC) each tested in two
> replicates(REP), across each combination of three treatments HOM, C18 and
> CU, each of which had two levels; HOM(SON, BLD),C18 SML, BIG), 
> CU (YES, NO).
> The variable we are assessing is the amount of toxin 
> extracted (TOX1). Also,
> some data is missing, and has already been removed. I am using an lme
> model, as the study design is similar to a split plot design, with a
> 2X2X2 full factorial design. There are a total of 65 observations.
> 
> Here is the model I am using:
> >model<- lme(TOX1~HOM*C18*CU, random=~1|PC/REP, data=Data4, method="ML")
> Linear mixed-effects model fit by maximum likelihood
> 
> which results in 48 DF for everything. Furthermore, I removed the
> three way interaction as well as all of the two way interactions as
> they were deemed non-significant, producing the final model :
> 
> > model5<- lme(TOX1~HOM+C18+CU, random=~1|PC/REP, data=Data4, method="ML")
> 
> which has 52 DF
> 
> However, I am unsure if these Df are pseudoreplicated and would like some
> help in how to determine if this is the case. I am happy to upload the
> full dataset and/or any of the outputs if that would help.

  Not sure entirely what you mean by "pseudoreplicated df".
I guess there are quite a few missing observations (since
5 x 2 x 2 x 2 x 2 = 80). 
 
  In principle since this is a randomized block design (you have
the treatments replicated within every fish*rep combination), the
df here should be correct (you can look up the formula for the df
of a randomized block design in a general stats book, e.g.
Ellison and Gotelli _Primer of Ecological Statistics_).  
There is one potential issue here, though:
technically, since you measured all treatments in every fish,
you have the capability to measure whether the treatments vary
across fish and across replicates (random = ~HOM+C18+CU|PC/REP).
However, 5 fish is not very many reps, especially not for estimating
a full 3x3 variance-covariance matrix for the treatments ...)

Schielzeth and Forstmeier Behav Ecol 20:416?420 (2009) talk about the
importance of accounting for among-individual variation in effects, but
caution:

> There are a few potential problems when using random slope
models. First, if there are only few individuals, the
between-individual variance components are difficult to estimate and
tend to be underestimated. This leads to unstable and often slightly
overconfident SEs. Second, random slope models might not converge,
particularly if more than one random intercept and one random slope
are included. The number of parameters to be estimated increases
substantially because not only the random effect for the intercepts
and slopes but also the correlations among them have to be
estimated. In case of convergence problems, we suggest following
Figure 1 to judge if including random slopes is likely to have a large
influence and to run preliminary submodels to decide whether or not to
include particular random slopes.

From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Feb  9 11:24:26 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 9 Feb 2015 11:24:26 +0100
Subject: [R-sig-ME] Differences in degrees of freedom between a
 mixed-effects model and a gls model using nlme
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F060200E4@UM-MAIL4112.unimaas.nl>

I don't want to derail this thread entirely, but it does make me wonder: Are people really concerned about calculating the "right" degrees of freedom in their applications anyway? I have pretty much stopped worrying about the software cleverly figuring out what the right dfs are, as I hardly ever deal with situations where there is a clear and correct answer to that question -- even in the designed experiments I see, unbalancedness creeps in in various ways, the most obvious one being missing data due to attrition (in Karl's example, there is of course a clear answer, but my question is more general).

I am sure that the type of applications one deals with has an influence on this matter. If you see nicely designed experiments with balanced data, getting the dfs right might seem like an important concern. Or if sample sizes are small (as in the number of individuals and/or number of repeated measurements), then it may matter whether the dfs are 10 or 100 for the conclusions you draw from a test (which, in the end, is then based, at least partly, on the p-value the software throws at you). But as far as I am concerned, I constantly (and grudgingly, with a lot of wishful thinking) need to rely on the asymptotic behavior of the estimates, standard errors, and test statistics every which way I turn anyway. Whether the dfs are 10, 40.5682..., or 100 is one of my least pressing concerns. If the conclusion doesn't pass the interocular traumatization test, I don't have much faith in it anyway.

I know that this has come up before, http://glmm.wikidot.com/faq discusses this as well, and the fact that lme4 doesn't provide p-values is, in essence, a statement in the same direction, but I am just curious about other people's opinion on this.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Ben Bolker
> Sent: Monday, February 09, 2015 05:36
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Differences in degrees of freedom between a
> mixed-effects model and a gls model using nlme
> 
> Ken Beath <ken.beath at ...> writes:
> 
> >
> > All 3 (paired t-test, mixed effect and gls with compound symmetry) are
> > fitting the same model, and so should give the same result. That is
> what
> > you see with the first example. The gls model is not getting it wrong
> > except for the df.
> >
> > For the second the 3 model results should again be the same. I'm not
> > certain why but it may be numerical. Even though the data come
> > from a model
> > that isn't correct for the fitting that should be irrelevant, it is the
> > data that produce the model fit not the model that produces the data.
> > Possibly estimates of the correlation are poor when there is little
> > correlation, and that flows through to the mixed effects and
> > gls results.
> >
> > The relationship to the unpaired t-test is probably irrelevant. Note
> also
> > that the default for the t.test is unequal variances whereas for a
> mixed
> > model it is equal variances.
> >
> > The df for gls is obviously in a sense a bug. Getting the df for a
> mixed
> > model isn't easy. Here we have a nice simple correlation structure and
> > there is an obvious correct answer, but usually there isn't one. If the
> > model assumed uncorrelated data then the gls df would be correct, so it
> is
> > necessary for the software to work out what is going on. Using
> parametric
> > bootstrapping to determine the underlying distribution seems a better
> > method if accuracy is important.
> >
> > Ken
> >
> 
>   For what it's worth you can easily see what gls() is doing to
> get its df, and confirm that it's naive, by printing nlme:::summary.gls:
> 
>   tTable[, "p-value"] <- 2 * pt(-abs(tTable[, "t-value"]),
>         dims$N - dims$p)
> 
> For what it's worth, I've found that the df calculations used by
> lme() often fail quite badly for random-slopes models ... it's often
> really hard to guess, even for simpler designs (i.e. where there
> really is a precise correspondence with an F distribution -- no
> correlation
> structures or lack of balance or crossed random effects).
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ken.beath at mq.edu.au  Mon Feb  9 22:57:25 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Tue, 10 Feb 2015 08:57:25 +1100
Subject: [R-sig-ME] Differences in degrees of freedom between a
 mixed-effects model and a gls model using nlme
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F060200E4@UM-MAIL4112.unimaas.nl>
References: <077E31A57DA26E46AB0D493C9966AC730F060200E4@UM-MAIL4112.unimaas.nl>
Message-ID: <CAF5_5cxZGVzEteApurUR75h5cVvqgtqMuv74dM2MqXsV4CXwzQ@mail.gmail.com>

I agree. I think we too often get hung up on trying to obtain the "correct"
results based on the theory. In practice that is quite often irrelevant, as
the results are much more affected by the violation of teh distributional
assumptions.

One point with these models is that assumptions of asymptotic normality are
anti-conservative, so early statisticians would have wanted to do something
to reduce this bias, and any degrees of freedom less than infinity will
give a more conservative result. These days there are better ways.

Ken

On 9 February 2015 at 21:24, Viechtbauer Wolfgang (STAT) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> I don't want to derail this thread entirely, but it does make me wonder:
> Are people really concerned about calculating the "right" degrees of
> freedom in their applications anyway? I have pretty much stopped worrying
> about the software cleverly figuring out what the right dfs are, as I
> hardly ever deal with situations where there is a clear and correct answer
> to that question -- even in the designed experiments I see, unbalancedness
> creeps in in various ways, the most obvious one being missing data due to
> attrition (in Karl's example, there is of course a clear answer, but my
> question is more general).
>
> I am sure that the type of applications one deals with has an influence on
> this matter. If you see nicely designed experiments with balanced data,
> getting the dfs right might seem like an important concern. Or if sample
> sizes are small (as in the number of individuals and/or number of repeated
> measurements), then it may matter whether the dfs are 10 or 100 for the
> conclusions you draw from a test (which, in the end, is then based, at
> least partly, on the p-value the software throws at you). But as far as I
> am concerned, I constantly (and grudgingly, with a lot of wishful thinking)
> need to rely on the asymptotic behavior of the estimates, standard errors,
> and test statistics every which way I turn anyway. Whether the dfs are 10,
> 40.5682..., or 100 is one of my least pressing concerns. If the conclusion
> doesn't pass the interocular traumatization test, I don't have much faith
> in it anyway.
>
> I know that this has come up before, http://glmm.wikidot.com/faq
> discusses this as well, and the fact that lme4 doesn't provide p-values is,
> in essence, a statement in the same direction, but I am just curious about
> other people's opinion on this.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
>
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> > project.org] On Behalf Of Ben Bolker
> > Sent: Monday, February 09, 2015 05:36
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Differences in degrees of freedom between a
> > mixed-effects model and a gls model using nlme
> >
> > Ken Beath <ken.beath at ...> writes:
> >
> > >
> > > All 3 (paired t-test, mixed effect and gls with compound symmetry) are
> > > fitting the same model, and so should give the same result. That is
> > what
> > > you see with the first example. The gls model is not getting it wrong
> > > except for the df.
> > >
> > > For the second the 3 model results should again be the same. I'm not
> > > certain why but it may be numerical. Even though the data come
> > > from a model
> > > that isn't correct for the fitting that should be irrelevant, it is the
> > > data that produce the model fit not the model that produces the data.
> > > Possibly estimates of the correlation are poor when there is little
> > > correlation, and that flows through to the mixed effects and
> > > gls results.
> > >
> > > The relationship to the unpaired t-test is probably irrelevant. Note
> > also
> > > that the default for the t.test is unequal variances whereas for a
> > mixed
> > > model it is equal variances.
> > >
> > > The df for gls is obviously in a sense a bug. Getting the df for a
> > mixed
> > > model isn't easy. Here we have a nice simple correlation structure and
> > > there is an obvious correct answer, but usually there isn't one. If the
> > > model assumed uncorrelated data then the gls df would be correct, so it
> > is
> > > necessary for the software to work out what is going on. Using
> > parametric
> > > bootstrapping to determine the underlying distribution seems a better
> > > method if accuracy is important.
> > >
> > > Ken
> > >
> >
> >   For what it's worth you can easily see what gls() is doing to
> > get its df, and confirm that it's naive, by printing nlme:::summary.gls:
> >
> >   tTable[, "p-value"] <- 2 * pt(-abs(tTable[, "t-value"]),
> >         dims$N - dims$p)
> >
> > For what it's worth, I've found that the df calculations used by
> > lme() often fail quite badly for random-slopes models ... it's often
> > really hard to guess, even for simpler designs (i.e. where there
> > really is a precise correspondence with an F distribution -- no
> > correlation
> > structures or lack of balance or crossed random effects).
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From rubinjoni at gmail.com  Wed Feb 11 15:13:59 2015
From: rubinjoni at gmail.com (Luka Rubinjoni)
Date: Wed, 11 Feb 2015 15:13:59 +0100
Subject: [R-sig-ME] Ordinal data analysis with MCMCglmm
Message-ID: <54DB63A7.70805@gmail.com>

Dear list members,

	I'm trying to analyze ordinal data with MCMCglmm, but I keep getting
inconsistent results. I'm a biologist with no experience in Bayesian
inference and mixed models, these are my first attempts...

	I'm exploring herbivory load on a dioecious plant (separate male and
female sex). I used leaf damage as an estimate of herbivory load, by
assigning each leaf with a 1 (no damage) to 4 (heavy/severe damage)
score. I have sampled about 500 plants from 12 locations, and have about
10 leaves per plant. Plants do not have a constant number of leaves, it
ranges from 6 to 17. All plants were collected from natural habitats -
there was no experimental setup for a full factorial design. Also,
uneven number of plants was sampled from various locations.

	I wish to determine if one of the sexes (male or female) is more
susceptible to herbivore damage. I would also like to compare sites
according to the observed damage, and explore sex*site interaction.
Further, I would like to see if some other plant traits (except sex)
have an impact on herbivory: plant height, plant mass, leaf number, leaf
mass, flower/fruit mass & number, reproductive allocation...

	I tried running MCMCglmm procedure with the default prior (without
declaring the prior), but I get awkward results (negative DICs, large
differences in DICs between runs...). I'm not sure if I'm making any
other mistakes, too. Do you have any suggestions for the prior
specification?

Best regards,
Luka Rubinjoni
Faculty of Biology, University of Belgrade

P.S. Here's summary of the data, and output from one of the models:

> summary(skorovi)
       ID           LeafID     score          N
 K24M   :  17   Min.   :   1   1:2248   Min.   : 6.00
 M9M    :  17   1st Qu.:1480   2:2982   1st Qu.:10.00
 J10M   :  16   Median :2960   3: 564   Median :11.00
 K18M   :  16   Mean   :2960   4: 124   Mean   :11.35
 M17F   :  16   3rd Qu.:4439            3rd Qu.:12.00
 M19M   :  16   Max.   :5918            Max.   :17.00
 (Other):5820
     PlantH         FlowerN       InternodeN
 Min.   : 94.0   Min.   : 1.0   Min.   : 4.000
 1st Qu.:204.0   1st Qu.: 5.0   1st Qu.: 5.000
 Median :231.0   Median :11.0   Median : 6.000
 Mean   :233.7   Mean   :15.6   Mean   : 6.131
 3rd Qu.:265.0   3rd Qu.:24.0   3rd Qu.: 7.000
 Max.   :398.0   Max.   :68.0   Max.   :10.000

     PlantM           LeafM        Sex           Site
 Min.   :0.1690   Min.   :0.1170   F:2891   A2S    : 875
 1st Qu.:0.4760   1st Qu.:0.2950   M:3027   A      : 805
 Median :0.6120   Median :0.3910            K      : 784
 Mean   :0.6816   Mean   :0.4316            M      : 566
 3rd Qu.:0.8500   3rd Qu.:0.5310            DJ     : 479
 Max.   :2.3020   Max.   :1.5610            P      : 454
                                            (Other):1955
       RA           InfloresenceN      FlowerM
 Min.   :0.001348   Min.   :1.000   Min.   :0.00100
 1st Qu.:0.011674   1st Qu.:4.000   1st Qu.:0.00700
 Median :0.024943   Median :4.000   Median :0.01700
 Mean   :0.065849   Mean   :4.492   Mean   :0.04613
 3rd Qu.:0.097990   3rd Qu.:5.000   3rd Qu.:0.05600
 Max.   :0.838617   Max.   :9.000   Max.   :0.56100
                    NA's   :2891

CMC200kIDSite <- MCMCglmm(score~Sex, ~ID+Site, rcov=~units,
family="ordinal", data=skorovi, DIC=TRUE, nitt=200000, thin=100,
burnin=5000)

...
 MCMC iteration = 200000

  Acceptance ratio for latent scores = 0.897869
 Acceptance ratio for cutpoint set 1 = 0.779000

> summary(MCMC200kIDSite)

 Iterations = 5001:199901
 Thinning interval  = 100
 Sample size  = 1950

 DIC: -9100.507

 G-structure:  ~ID

   post.mean l-95% CI u-95% CI eff.samp
ID     12.02   0.3165    24.33    1.436

               ~Site

     post.mean l-95% CI u-95% CI eff.samp
Site     17.89   0.1927    52.11    5.023

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units     40.44    0.198    80.42    1.478

 Location effects: score ~ Sex

            post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)   2.38948  0.01827  5.96931    5.605 0.0359 *
SexM          0.11478 -0.64723  0.90102 1950.000 0.7426
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

 Cutpoints:
                      post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitscore.1     10.74    2.051    16.73    1.347
cutpoint.traitscore.2     16.79    3.203    26.18    1.323

> autocorr(MCMC200kIDSite$Sol)
, , (Intercept)

         (Intercept)       SexM
Lag 0      1.0000000 0.02834661
Lag 100    0.4652665 0.12773192
Lag 500    0.4637719 0.12885704
Lag 1000   0.4608056 0.10518225
Lag 5000   0.4426579 0.10261122

, , SexM

         (Intercept)        SexM
Lag 0     0.02834661 1.000000000
Lag 100   0.10172481 0.000939134
Lag 500   0.13601706 0.003533253
Lag 1000  0.13280788 0.040197635
Lag 5000  0.11814053 0.070899772

> autocorr(MCMC200kIDSite$VCV)
, , ID

                ID      Site     units
Lag 0    1.0000000 0.7125238 0.9873699
Lag 100  0.9770221 0.7118302 0.9862788
Lag 500  0.9692561 0.7054513 0.9799585
Lag 1000 0.9644127 0.6951924 0.9737191
Lag 5000 0.9104725 0.6701422 0.9193135

, , Site

                ID      Site     units
Lag 0    0.7125238 1.0000000 0.7214728
Lag 100  0.7095693 0.4868717 0.7170873
Lag 500  0.7028373 0.5282474 0.7136912
Lag 1000 0.7045606 0.5254454 0.7081390
Lag 5000 0.6686113 0.4824315 0.6739685

, , units

                ID      Site     units
Lag 0    0.9873699 0.7214728 1.0000000
Lag 100  0.9864973 0.7192773 0.9971748
Lag 500  0.9810497 0.7137308 0.9910396
Lag 1000 0.9743296 0.7063965 0.9838989
Lag 5000 0.9213108 0.6722353 0.9303135


From j.hadfield at ed.ac.uk  Wed Feb 11 16:25:27 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 11 Feb 2015 15:25:27 +0000
Subject: [R-sig-ME] Ordinal data analysis with MCMCglmm
In-Reply-To: <54DB63A7.70805@gmail.com>
References: <54DB63A7.70805@gmail.com>
Message-ID: <20150211152527.166977lx1eeqmr4s@www.staffmail.ed.ac.uk>

Hi,

The residual variance is not identifiable in the likelihood for  
ordinal models - you need to fix it at something (e.g. 1):

prior=list(R=list(V=1, fix=1), ...)

Note that under family="ordinal" this is equivalent to probit  
regression but with a variance of 2 (rather than the standard 1) in  
the normal cumulative distribution function (i.e. pnorm).

family="threhold" fits the same model but fixing the unit variance at  
1 gives the standard probit regression. This implementation samples  
the posterior more efficiently too.

Cheers,

Jarrod


Quoting Luka Rubinjoni <rubinjoni at gmail.com> on Wed, 11 Feb 2015  
15:13:59 +0100:

> Dear list members,
>
> 	I'm trying to analyze ordinal data with MCMCglmm, but I keep getting
> inconsistent results. I'm a biologist with no experience in Bayesian
> inference and mixed models, these are my first attempts...
>
> 	I'm exploring herbivory load on a dioecious plant (separate male and
> female sex). I used leaf damage as an estimate of herbivory load, by
> assigning each leaf with a 1 (no damage) to 4 (heavy/severe damage)
> score. I have sampled about 500 plants from 12 locations, and have about
> 10 leaves per plant. Plants do not have a constant number of leaves, it
> ranges from 6 to 17. All plants were collected from natural habitats -
> there was no experimental setup for a full factorial design. Also,
> uneven number of plants was sampled from various locations.
>
> 	I wish to determine if one of the sexes (male or female) is more
> susceptible to herbivore damage. I would also like to compare sites
> according to the observed damage, and explore sex*site interaction.
> Further, I would like to see if some other plant traits (except sex)
> have an impact on herbivory: plant height, plant mass, leaf number, leaf
> mass, flower/fruit mass & number, reproductive allocation...
>
> 	I tried running MCMCglmm procedure with the default prior (without
> declaring the prior), but I get awkward results (negative DICs, large
> differences in DICs between runs...). I'm not sure if I'm making any
> other mistakes, too. Do you have any suggestions for the prior
> specification?
>
> Best regards,
> Luka Rubinjoni
> Faculty of Biology, University of Belgrade
>
> P.S. Here's summary of the data, and output from one of the models:
>
>> summary(skorovi)
>        ID           LeafID     score          N
>  K24M   :  17   Min.   :   1   1:2248   Min.   : 6.00
>  M9M    :  17   1st Qu.:1480   2:2982   1st Qu.:10.00
>  J10M   :  16   Median :2960   3: 564   Median :11.00
>  K18M   :  16   Mean   :2960   4: 124   Mean   :11.35
>  M17F   :  16   3rd Qu.:4439            3rd Qu.:12.00
>  M19M   :  16   Max.   :5918            Max.   :17.00
>  (Other):5820
>      PlantH         FlowerN       InternodeN
>  Min.   : 94.0   Min.   : 1.0   Min.   : 4.000
>  1st Qu.:204.0   1st Qu.: 5.0   1st Qu.: 5.000
>  Median :231.0   Median :11.0   Median : 6.000
>  Mean   :233.7   Mean   :15.6   Mean   : 6.131
>  3rd Qu.:265.0   3rd Qu.:24.0   3rd Qu.: 7.000
>  Max.   :398.0   Max.   :68.0   Max.   :10.000
>
>      PlantM           LeafM        Sex           Site
>  Min.   :0.1690   Min.   :0.1170   F:2891   A2S    : 875
>  1st Qu.:0.4760   1st Qu.:0.2950   M:3027   A      : 805
>  Median :0.6120   Median :0.3910            K      : 784
>  Mean   :0.6816   Mean   :0.4316            M      : 566
>  3rd Qu.:0.8500   3rd Qu.:0.5310            DJ     : 479
>  Max.   :2.3020   Max.   :1.5610            P      : 454
>                                             (Other):1955
>        RA           InfloresenceN      FlowerM
>  Min.   :0.001348   Min.   :1.000   Min.   :0.00100
>  1st Qu.:0.011674   1st Qu.:4.000   1st Qu.:0.00700
>  Median :0.024943   Median :4.000   Median :0.01700
>  Mean   :0.065849   Mean   :4.492   Mean   :0.04613
>  3rd Qu.:0.097990   3rd Qu.:5.000   3rd Qu.:0.05600
>  Max.   :0.838617   Max.   :9.000   Max.   :0.56100
>                     NA's   :2891
>
> CMC200kIDSite <- MCMCglmm(score~Sex, ~ID+Site, rcov=~units,
> family="ordinal", data=skorovi, DIC=TRUE, nitt=200000, thin=100,
> burnin=5000)
>
> ...
>  MCMC iteration = 200000
>
>   Acceptance ratio for latent scores = 0.897869
>  Acceptance ratio for cutpoint set 1 = 0.779000
>
>> summary(MCMC200kIDSite)
>
>  Iterations = 5001:199901
>  Thinning interval  = 100
>  Sample size  = 1950
>
>  DIC: -9100.507
>
>  G-structure:  ~ID
>
>    post.mean l-95% CI u-95% CI eff.samp
> ID     12.02   0.3165    24.33    1.436
>
>                ~Site
>
>      post.mean l-95% CI u-95% CI eff.samp
> Site     17.89   0.1927    52.11    5.023
>
>  R-structure:  ~units
>
>       post.mean l-95% CI u-95% CI eff.samp
> units     40.44    0.198    80.42    1.478
>
>  Location effects: score ~ Sex
>
>             post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)   2.38948  0.01827  5.96931    5.605 0.0359 *
> SexM          0.11478 -0.64723  0.90102 1950.000 0.7426
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>  Cutpoints:
>                       post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitscore.1     10.74    2.051    16.73    1.347
> cutpoint.traitscore.2     16.79    3.203    26.18    1.323
>
>> autocorr(MCMC200kIDSite$Sol)
> , , (Intercept)
>
>          (Intercept)       SexM
> Lag 0      1.0000000 0.02834661
> Lag 100    0.4652665 0.12773192
> Lag 500    0.4637719 0.12885704
> Lag 1000   0.4608056 0.10518225
> Lag 5000   0.4426579 0.10261122
>
> , , SexM
>
>          (Intercept)        SexM
> Lag 0     0.02834661 1.000000000
> Lag 100   0.10172481 0.000939134
> Lag 500   0.13601706 0.003533253
> Lag 1000  0.13280788 0.040197635
> Lag 5000  0.11814053 0.070899772
>
>> autocorr(MCMC200kIDSite$VCV)
> , , ID
>
>                 ID      Site     units
> Lag 0    1.0000000 0.7125238 0.9873699
> Lag 100  0.9770221 0.7118302 0.9862788
> Lag 500  0.9692561 0.7054513 0.9799585
> Lag 1000 0.9644127 0.6951924 0.9737191
> Lag 5000 0.9104725 0.6701422 0.9193135
>
> , , Site
>
>                 ID      Site     units
> Lag 0    0.7125238 1.0000000 0.7214728
> Lag 100  0.7095693 0.4868717 0.7170873
> Lag 500  0.7028373 0.5282474 0.7136912
> Lag 1000 0.7045606 0.5254454 0.7081390
> Lag 5000 0.6686113 0.4824315 0.6739685
>
> , , units
>
>                 ID      Site     units
> Lag 0    0.9873699 0.7214728 1.0000000
> Lag 100  0.9864973 0.7192773 0.9971748
> Lag 500  0.9810497 0.7137308 0.9910396
> Lag 1000 0.9743296 0.7063965 0.9838989
> Lag 5000 0.9213108 0.6722353 0.9303135
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bonamy at horus.ens.fr  Thu Feb 12 10:09:41 2015
From: bonamy at horus.ens.fr (Pierre de Villemereuil)
Date: Thu, 12 Feb 2015 10:09:41 +0100
Subject: [R-sig-ME] Ordinal data analysis with MCMCglmm
In-Reply-To: <20150211152527.166977lx1eeqmr4s@www.staffmail.ed.ac.uk>
References: <54DB63A7.70805@gmail.com>
	<20150211152527.166977lx1eeqmr4s@www.staffmail.ed.ac.uk>
Message-ID: <2458720.BsKmzVyCMM@fitzroy>

Hi!

Sorry, I'm inviting myself in the conversation. Jarrod, could you be more 
specific on the difference between "ordinal" and "threshold"?

I gather from you last updated "MCMCglmm Course Notes" that "threshold" uses 
the "latent residual variance" directly in the link function, whereas 
"ordinal" adds another variance of 1, is that right?

Thank you in advance for the clarification.

Cheers,
Pierre.

Le mercredi 11 f?vrier 2015, 15:25:27 Jarrod Hadfield a ?crit :
> Hi,
> 
> The residual variance is not identifiable in the likelihood for
> ordinal models - you need to fix it at something (e.g. 1):
> 
> prior=list(R=list(V=1, fix=1), ...)
> 
> Note that under family="ordinal" this is equivalent to probit
> regression but with a variance of 2 (rather than the standard 1) in
> the normal cumulative distribution function (i.e. pnorm).
> 
> family="threhold" fits the same model but fixing the unit variance at
> 1 gives the standard probit regression. This implementation samples
> the posterior more efficiently too.
> 
> Cheers,
> 
> Jarrod
> 
> 
> Quoting Luka Rubinjoni <rubinjoni at gmail.com> on Wed, 11 Feb 2015
> 
> 15:13:59 +0100:
> > Dear list members,
> > 
> > 	I'm trying to analyze ordinal data with MCMCglmm, but I keep getting
> > 
> > inconsistent results. I'm a biologist with no experience in Bayesian
> > inference and mixed models, these are my first attempts...
> > 
> > 	I'm exploring herbivory load on a dioecious plant (separate male and
> > 
> > female sex). I used leaf damage as an estimate of herbivory load, by
> > assigning each leaf with a 1 (no damage) to 4 (heavy/severe damage)
> > score. I have sampled about 500 plants from 12 locations, and have about
> > 10 leaves per plant. Plants do not have a constant number of leaves, it
> > ranges from 6 to 17. All plants were collected from natural habitats -
> > there was no experimental setup for a full factorial design. Also,
> > uneven number of plants was sampled from various locations.
> > 
> > 	I wish to determine if one of the sexes (male or female) is more
> > 
> > susceptible to herbivore damage. I would also like to compare sites
> > according to the observed damage, and explore sex*site interaction.
> > Further, I would like to see if some other plant traits (except sex)
> > have an impact on herbivory: plant height, plant mass, leaf number, leaf
> > mass, flower/fruit mass & number, reproductive allocation...
> > 
> > 	I tried running MCMCglmm procedure with the default prior (without
> > 
> > declaring the prior), but I get awkward results (negative DICs, large
> > differences in DICs between runs...). I'm not sure if I'm making any
> > other mistakes, too. Do you have any suggestions for the prior
> > specification?
> > 
> > Best regards,
> > Luka Rubinjoni
> > Faculty of Biology, University of Belgrade
> > 
> > P.S. Here's summary of the data, and output from one of the models:
> >> summary(skorovi)
> >> 
> >        ID           LeafID     score          N
> >  
> >  K24M   :  17   Min.   :   1   1:2248   Min.   : 6.00
> >  M9M    :  17   1st Qu.:1480   2:2982   1st Qu.:10.00
> >  J10M   :  16   Median :2960   3: 564   Median :11.00
> >  K18M   :  16   Mean   :2960   4: 124   Mean   :11.35
> >  M17F   :  16   3rd Qu.:4439            3rd Qu.:12.00
> >  M19M   :  16   Max.   :5918            Max.   :17.00
> >  (Other):5820
> >  
> >      PlantH         FlowerN       InternodeN
> >  
> >  Min.   : 94.0   Min.   : 1.0   Min.   : 4.000
> >  1st Qu.:204.0   1st Qu.: 5.0   1st Qu.: 5.000
> >  Median :231.0   Median :11.0   Median : 6.000
> >  Mean   :233.7   Mean   :15.6   Mean   : 6.131
> >  3rd Qu.:265.0   3rd Qu.:24.0   3rd Qu.: 7.000
> >  Max.   :398.0   Max.   :68.0   Max.   :10.000
> >  
> >      PlantM           LeafM        Sex           Site
> >  
> >  Min.   :0.1690   Min.   :0.1170   F:2891   A2S    : 875
> >  1st Qu.:0.4760   1st Qu.:0.2950   M:3027   A      : 805
> >  Median :0.6120   Median :0.3910            K      : 784
> >  Mean   :0.6816   Mean   :0.4316            M      : 566
> >  3rd Qu.:0.8500   3rd Qu.:0.5310            DJ     : 479
> >  Max.   :2.3020   Max.   :1.5610            P      : 454
> >  
> >                                             (Other):1955
> >        
> >        RA           InfloresenceN      FlowerM
> >  
> >  Min.   :0.001348   Min.   :1.000   Min.   :0.00100
> >  1st Qu.:0.011674   1st Qu.:4.000   1st Qu.:0.00700
> >  Median :0.024943   Median :4.000   Median :0.01700
> >  Mean   :0.065849   Mean   :4.492   Mean   :0.04613
> >  3rd Qu.:0.097990   3rd Qu.:5.000   3rd Qu.:0.05600
> >  Max.   :0.838617   Max.   :9.000   Max.   :0.56100
> >  
> >                     NA's   :2891
> > 
> > CMC200kIDSite <- MCMCglmm(score~Sex, ~ID+Site, rcov=~units,
> > family="ordinal", data=skorovi, DIC=TRUE, nitt=200000, thin=100,
> > burnin=5000)
> > 
> > ...
> > 
> >  MCMC iteration = 200000
> >  
> >   Acceptance ratio for latent scores = 0.897869
> >  
> >  Acceptance ratio for cutpoint set 1 = 0.779000
> >  
> >> summary(MCMC200kIDSite)
> >> 
> >  Iterations = 5001:199901
> >  Thinning interval  = 100
> >  Sample size  = 1950
> >  
> >  DIC: -9100.507
> >  
> >  G-structure:  ~ID
> >  
> >    post.mean l-95% CI u-95% CI eff.samp
> > 
> > ID     12.02   0.3165    24.33    1.436
> > 
> >                ~Site
> >      
> >      post.mean l-95% CI u-95% CI eff.samp
> > 
> > Site     17.89   0.1927    52.11    5.023
> > 
> >  R-structure:  ~units
> >  
> >       post.mean l-95% CI u-95% CI eff.samp
> > 
> > units     40.44    0.198    80.42    1.478
> > 
> >  Location effects: score ~ Sex
> >  
> >             post.mean l-95% CI u-95% CI eff.samp  pMCMC
> > 
> > (Intercept)   2.38948  0.01827  5.96931    5.605 0.0359 *
> > SexM          0.11478 -0.64723  0.90102 1950.000 0.7426
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > 
> >  Cutpoints:
> >                       post.mean l-95% CI u-95% CI eff.samp
> > 
> > cutpoint.traitscore.1     10.74    2.051    16.73    1.347
> > cutpoint.traitscore.2     16.79    3.203    26.18    1.323
> > 
> >> autocorr(MCMC200kIDSite$Sol)
> > 
> > , , (Intercept)
> > 
> >          (Intercept)       SexM
> > 
> > Lag 0      1.0000000 0.02834661
> > Lag 100    0.4652665 0.12773192
> > Lag 500    0.4637719 0.12885704
> > Lag 1000   0.4608056 0.10518225
> > Lag 5000   0.4426579 0.10261122
> > 
> > , , SexM
> > 
> >          (Intercept)        SexM
> > 
> > Lag 0     0.02834661 1.000000000
> > Lag 100   0.10172481 0.000939134
> > Lag 500   0.13601706 0.003533253
> > Lag 1000  0.13280788 0.040197635
> > Lag 5000  0.11814053 0.070899772
> > 
> >> autocorr(MCMC200kIDSite$VCV)
> > 
> > , , ID
> > 
> >                 ID      Site     units
> > 
> > Lag 0    1.0000000 0.7125238 0.9873699
> > Lag 100  0.9770221 0.7118302 0.9862788
> > Lag 500  0.9692561 0.7054513 0.9799585
> > Lag 1000 0.9644127 0.6951924 0.9737191
> > Lag 5000 0.9104725 0.6701422 0.9193135
> > 
> > , , Site
> > 
> >                 ID      Site     units
> > 
> > Lag 0    0.7125238 1.0000000 0.7214728
> > Lag 100  0.7095693 0.4868717 0.7170873
> > Lag 500  0.7028373 0.5282474 0.7136912
> > Lag 1000 0.7045606 0.5254454 0.7081390
> > Lag 5000 0.6686113 0.4824315 0.6739685
> > 
> > , , units
> > 
> >                 ID      Site     units
> > 
> > Lag 0    0.9873699 0.7214728 1.0000000
> > Lag 100  0.9864973 0.7192773 0.9971748
> > Lag 500  0.9810497 0.7137308 0.9910396
> > Lag 1000 0.9743296 0.7063965 0.9838989
> > Lag 5000 0.9213108 0.6722353 0.9303135
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j.hadfield at ed.ac.uk  Thu Feb 12 10:36:16 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 12 Feb 2015 09:36:16 +0000
Subject: [R-sig-ME] Ordinal data analysis with MCMCglmm
In-Reply-To: <2458720.BsKmzVyCMM@fitzroy>
References: <54DB63A7.70805@gmail.com>
	<20150211152527.166977lx1eeqmr4s@www.staffmail.ed.ac.uk>
	<2458720.BsKmzVyCMM@fitzroy>
Message-ID: <20150212093616.144532lj2prykbac@www.staffmail.ed.ac.uk>

Hi Pierre,

Exactly. There's two ways to think about GLMM on categorical data. To  
take binary data and a probit link function, the probability of  
success is:

pnorm(eta,0,1)

where eta is the linear predictor. In family="ordinal" the linear predictor is

Xb+Zu+e

and the residual e is Gaussian with variance V.

Another way to think about it is a success happens when

Xb+Zu+e+epsilon > 0

where epsilon is from the unit normal (mean=0, variance=1)

e and epsilon are confounded and e+epsilon is Gaussian with zero mean  
and variance V+1.  The variance is not identifiable and has to be  
fixed, and so fixing V=1 gives the variance of e+epsilon as 2. The  
probability of success can also be written as:

pnorm(Xb+Zu,0,sqrt(V+1))

It might be tempting to set V=0 because then we end up with the  
`standard' probit regression:

pnorm(Xb+Zu,0,sqrt(1))

but MCMCglmm would complain because mixing requires V>0. This isn't a  
big deal because the location effects can be rescaled to what they  
would be under the standard parameterisation:

pnorm(Xb+Zu,0,sqrt(2)) = pnorm((Xb+Zu)/sqrt(2),0,1)

family="threshold" is pretty much the same except VAR(e) is set to  
zero implicitly and V in the prior designates VAR(epsilon). Setting it  
to one gives the standard parameterisation directly.

Cheers,

Jarrod























Quoting Pierre de Villemereuil <bonamy at horus.ens.fr> on Thu, 12 Feb  
2015 10:09:41 +0100:

> Hi!
>
> Sorry, I'm inviting myself in the conversation. Jarrod, could you be more
> specific on the difference between "ordinal" and "threshold"?
>
> I gather from you last updated "MCMCglmm Course Notes" that "threshold" uses
> the "latent residual variance" directly in the link function, whereas
> "ordinal" adds another variance of 1, is that right?
>
> Thank you in advance for the clarification.
>
> Cheers,
> Pierre.
>
> Le mercredi 11 f?vrier 2015, 15:25:27 Jarrod Hadfield a ?crit :
>> Hi,
>>
>> The residual variance is not identifiable in the likelihood for
>> ordinal models - you need to fix it at something (e.g. 1):
>>
>> prior=list(R=list(V=1, fix=1), ...)
>>
>> Note that under family="ordinal" this is equivalent to probit
>> regression but with a variance of 2 (rather than the standard 1) in
>> the normal cumulative distribution function (i.e. pnorm).
>>
>> family="threhold" fits the same model but fixing the unit variance at
>> 1 gives the standard probit regression. This implementation samples
>> the posterior more efficiently too.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> Quoting Luka Rubinjoni <rubinjoni at gmail.com> on Wed, 11 Feb 2015
>>
>> 15:13:59 +0100:
>> > Dear list members,
>> >
>> > 	I'm trying to analyze ordinal data with MCMCglmm, but I keep getting
>> >
>> > inconsistent results. I'm a biologist with no experience in Bayesian
>> > inference and mixed models, these are my first attempts...
>> >
>> > 	I'm exploring herbivory load on a dioecious plant (separate male and
>> >
>> > female sex). I used leaf damage as an estimate of herbivory load, by
>> > assigning each leaf with a 1 (no damage) to 4 (heavy/severe damage)
>> > score. I have sampled about 500 plants from 12 locations, and have about
>> > 10 leaves per plant. Plants do not have a constant number of leaves, it
>> > ranges from 6 to 17. All plants were collected from natural habitats -
>> > there was no experimental setup for a full factorial design. Also,
>> > uneven number of plants was sampled from various locations.
>> >
>> > 	I wish to determine if one of the sexes (male or female) is more
>> >
>> > susceptible to herbivore damage. I would also like to compare sites
>> > according to the observed damage, and explore sex*site interaction.
>> > Further, I would like to see if some other plant traits (except sex)
>> > have an impact on herbivory: plant height, plant mass, leaf number, leaf
>> > mass, flower/fruit mass & number, reproductive allocation...
>> >
>> > 	I tried running MCMCglmm procedure with the default prior (without
>> >
>> > declaring the prior), but I get awkward results (negative DICs, large
>> > differences in DICs between runs...). I'm not sure if I'm making any
>> > other mistakes, too. Do you have any suggestions for the prior
>> > specification?
>> >
>> > Best regards,
>> > Luka Rubinjoni
>> > Faculty of Biology, University of Belgrade
>> >
>> > P.S. Here's summary of the data, and output from one of the models:
>> >> summary(skorovi)
>> >>
>> >        ID           LeafID     score          N
>> >
>> >  K24M   :  17   Min.   :   1   1:2248   Min.   : 6.00
>> >  M9M    :  17   1st Qu.:1480   2:2982   1st Qu.:10.00
>> >  J10M   :  16   Median :2960   3: 564   Median :11.00
>> >  K18M   :  16   Mean   :2960   4: 124   Mean   :11.35
>> >  M17F   :  16   3rd Qu.:4439            3rd Qu.:12.00
>> >  M19M   :  16   Max.   :5918            Max.   :17.00
>> >  (Other):5820
>> >
>> >      PlantH         FlowerN       InternodeN
>> >
>> >  Min.   : 94.0   Min.   : 1.0   Min.   : 4.000
>> >  1st Qu.:204.0   1st Qu.: 5.0   1st Qu.: 5.000
>> >  Median :231.0   Median :11.0   Median : 6.000
>> >  Mean   :233.7   Mean   :15.6   Mean   : 6.131
>> >  3rd Qu.:265.0   3rd Qu.:24.0   3rd Qu.: 7.000
>> >  Max.   :398.0   Max.   :68.0   Max.   :10.000
>> >
>> >      PlantM           LeafM        Sex           Site
>> >
>> >  Min.   :0.1690   Min.   :0.1170   F:2891   A2S    : 875
>> >  1st Qu.:0.4760   1st Qu.:0.2950   M:3027   A      : 805
>> >  Median :0.6120   Median :0.3910            K      : 784
>> >  Mean   :0.6816   Mean   :0.4316            M      : 566
>> >  3rd Qu.:0.8500   3rd Qu.:0.5310            DJ     : 479
>> >  Max.   :2.3020   Max.   :1.5610            P      : 454
>> >
>> >                                             (Other):1955
>> >
>> >        RA           InfloresenceN      FlowerM
>> >
>> >  Min.   :0.001348   Min.   :1.000   Min.   :0.00100
>> >  1st Qu.:0.011674   1st Qu.:4.000   1st Qu.:0.00700
>> >  Median :0.024943   Median :4.000   Median :0.01700
>> >  Mean   :0.065849   Mean   :4.492   Mean   :0.04613
>> >  3rd Qu.:0.097990   3rd Qu.:5.000   3rd Qu.:0.05600
>> >  Max.   :0.838617   Max.   :9.000   Max.   :0.56100
>> >
>> >                     NA's   :2891
>> >
>> > CMC200kIDSite <- MCMCglmm(score~Sex, ~ID+Site, rcov=~units,
>> > family="ordinal", data=skorovi, DIC=TRUE, nitt=200000, thin=100,
>> > burnin=5000)
>> >
>> > ...
>> >
>> >  MCMC iteration = 200000
>> >
>> >   Acceptance ratio for latent scores = 0.897869
>> >
>> >  Acceptance ratio for cutpoint set 1 = 0.779000
>> >
>> >> summary(MCMC200kIDSite)
>> >>
>> >  Iterations = 5001:199901
>> >  Thinning interval  = 100
>> >  Sample size  = 1950
>> >
>> >  DIC: -9100.507
>> >
>> >  G-structure:  ~ID
>> >
>> >    post.mean l-95% CI u-95% CI eff.samp
>> >
>> > ID     12.02   0.3165    24.33    1.436
>> >
>> >                ~Site
>> >
>> >      post.mean l-95% CI u-95% CI eff.samp
>> >
>> > Site     17.89   0.1927    52.11    5.023
>> >
>> >  R-structure:  ~units
>> >
>> >       post.mean l-95% CI u-95% CI eff.samp
>> >
>> > units     40.44    0.198    80.42    1.478
>> >
>> >  Location effects: score ~ Sex
>> >
>> >             post.mean l-95% CI u-95% CI eff.samp  pMCMC
>> >
>> > (Intercept)   2.38948  0.01827  5.96931    5.605 0.0359 *
>> > SexM          0.11478 -0.64723  0.90102 1950.000 0.7426
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> >  Cutpoints:
>> >                       post.mean l-95% CI u-95% CI eff.samp
>> >
>> > cutpoint.traitscore.1     10.74    2.051    16.73    1.347
>> > cutpoint.traitscore.2     16.79    3.203    26.18    1.323
>> >
>> >> autocorr(MCMC200kIDSite$Sol)
>> >
>> > , , (Intercept)
>> >
>> >          (Intercept)       SexM
>> >
>> > Lag 0      1.0000000 0.02834661
>> > Lag 100    0.4652665 0.12773192
>> > Lag 500    0.4637719 0.12885704
>> > Lag 1000   0.4608056 0.10518225
>> > Lag 5000   0.4426579 0.10261122
>> >
>> > , , SexM
>> >
>> >          (Intercept)        SexM
>> >
>> > Lag 0     0.02834661 1.000000000
>> > Lag 100   0.10172481 0.000939134
>> > Lag 500   0.13601706 0.003533253
>> > Lag 1000  0.13280788 0.040197635
>> > Lag 5000  0.11814053 0.070899772
>> >
>> >> autocorr(MCMC200kIDSite$VCV)
>> >
>> > , , ID
>> >
>> >                 ID      Site     units
>> >
>> > Lag 0    1.0000000 0.7125238 0.9873699
>> > Lag 100  0.9770221 0.7118302 0.9862788
>> > Lag 500  0.9692561 0.7054513 0.9799585
>> > Lag 1000 0.9644127 0.6951924 0.9737191
>> > Lag 5000 0.9104725 0.6701422 0.9193135
>> >
>> > , , Site
>> >
>> >                 ID      Site     units
>> >
>> > Lag 0    0.7125238 1.0000000 0.7214728
>> > Lag 100  0.7095693 0.4868717 0.7170873
>> > Lag 500  0.7028373 0.5282474 0.7136912
>> > Lag 1000 0.7045606 0.5254454 0.7081390
>> > Lag 5000 0.6686113 0.4824315 0.6739685
>> >
>> > , , units
>> >
>> >                 ID      Site     units
>> >
>> > Lag 0    0.9873699 0.7214728 1.0000000
>> > Lag 100  0.9864973 0.7192773 0.9971748
>> > Lag 500  0.9810497 0.7137308 0.9910396
>> > Lag 1000 0.9743296 0.7063965 0.9838989
>> > Lag 5000 0.9213108 0.6722353 0.9303135
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From tove.jansson at gmail.com  Thu Feb 12 12:09:08 2015
From: tove.jansson at gmail.com (Tove Jansson)
Date: Thu, 12 Feb 2015 12:09:08 +0100
Subject: [R-sig-ME] Multiple contrasts and what data to include when writing
	up a three-way interaction in lmer?
Message-ID: <A1DAF5C2-0CDC-420A-A528-B1A0BD2C5176@gmail.com>

Hi,

I have a question about three-way (or any) interaction data. Perhaps my question is more conceptual than allowed on this list - but I hope it can still be considered relevant - I am very new to mixed models and it has been difficult for me to find an answer for questions regarding interactions with continuous predictors.

Brief background:

Our lmer model has a significant three-way interaction. Our DV is continuous and we have three predictors. One predictor is categorical (three levels) and the other two predictors are continuous.

To view all possible contrasts within the highest order interaction we have been using a custom contrast matrix, in a similar way as to what was done here: http://stats.stackexchange.com/questions/43664/mixed-model-multiple-comparisons-for-interaction-between-continuous-and-categori <http://stats.stackexchange.com/questions/43664/mixed-model-multiple-comparisons-for-interaction-between-continuous-and-categori>

To correct our alpha correction for multiple comparisons, we have been using the default single-step adjustment in the glht function in multcomp package.

The problem:

To minimize the adjustment for multiple comparisons, I limited my glht contrasts to the highest order interaction (the three-way).

But in order to understand the interaction, I need to also look at the simple effects for the categorical predictor. For example, it?s important for me to know if there was a significant difference at the original intercept value of a certain predictor so that I can know if an effect is a) emerging on account of an interaction or b) becoming stronger on account of the same interaction. However, if I include these simple effects in the contrasts, then I am forced to make adjustments to the alpha.

How is this typically handled? Is there a way to present the simple effects without further penalty to my p values? Or am I thinking about this the wrong way - does the mere fact that I want to look at them mean that I must correct my alpha more? Apologies if this should be perfectly obvious.

Also - can anyone recommend a good way of plotting three-way interactions for lmer output? I have been using plot() and effect() to create trellis plots, as seen below, but I find it difficult and confusing trying to control the parameters. For example, I have not found a way to manually select the values for Pred2 (incremental, select values are selected by default for the trellis plots) and I have not found a way to indicate confidence intervals. If anyone can direct me to a good source that explains how to use plot() with these sorts of objects, please do so. ggplot2 does not seem to work for effects objects.

Thanks in advance.

#plot multiline
p0 <- effect(?condition:Pred1:Pred2", testTotalRegion2_lmer14)
p1 <- plot(p0, 
	multiline=TRUE, 
	main="Region2", 
	xlab=?Pred1", 
	ylab="FD (logged + residualalized)", 
	key.args=list(x=1,y=1,corner=c(x=.8, y=1))
	)
p1



	[[alternative HTML version deleted]]


From tmeeha at gmail.com  Thu Feb 12 17:25:36 2015
From: tmeeha at gmail.com (Tim Meehan)
Date: Thu, 12 Feb 2015 09:25:36 -0700
Subject: [R-sig-ME] Multiple contrasts and what data to include when
 writing up a three-way interaction in lmer?
In-Reply-To: <A1DAF5C2-0CDC-420A-A528-B1A0BD2C5176@gmail.com>
References: <A1DAF5C2-0CDC-420A-A528-B1A0BD2C5176@gmail.com>
Message-ID: <CAMTWOzqgD0jv7b5XqnXoWixP+wmi9wMOQNpyeR+vzNExreBWeQ@mail.gmail.com>

Hi Tove,

The visreg package [visreg()] and languageR package [plotLMER.fnc()] can
sometimes be helpful for wrapping your head around interactions.

Best,
Tim

On Thu, Feb 12, 2015 at 4:09 AM, Tove Jansson <tove.jansson at gmail.com>
wrote:

> Hi,
>
> I have a question about three-way (or any) interaction data. Perhaps my
> question is more conceptual than allowed on this list - but I hope it can
> still be considered relevant - I am very new to mixed models and it has
> been difficult for me to find an answer for questions regarding
> interactions with continuous predictors.
>
> Brief background:
>
> Our lmer model has a significant three-way interaction. Our DV is
> continuous and we have three predictors. One predictor is categorical
> (three levels) and the other two predictors are continuous.
>
> To view all possible contrasts within the highest order interaction we
> have been using a custom contrast matrix, in a similar way as to what was
> done here:
> http://stats.stackexchange.com/questions/43664/mixed-model-multiple-comparisons-for-interaction-between-continuous-and-categori
> <
> http://stats.stackexchange.com/questions/43664/mixed-model-multiple-comparisons-for-interaction-between-continuous-and-categori
> >
>
> To correct our alpha correction for multiple comparisons, we have been
> using the default single-step adjustment in the glht function in multcomp
> package.
>
> The problem:
>
> To minimize the adjustment for multiple comparisons, I limited my glht
> contrasts to the highest order interaction (the three-way).
>
> But in order to understand the interaction, I need to also look at the
> simple effects for the categorical predictor. For example, it?s important
> for me to know if there was a significant difference at the original
> intercept value of a certain predictor so that I can know if an effect is
> a) emerging on account of an interaction or b) becoming stronger on account
> of the same interaction. However, if I include these simple effects in the
> contrasts, then I am forced to make adjustments to the alpha.
>
> How is this typically handled? Is there a way to present the simple
> effects without further penalty to my p values? Or am I thinking about this
> the wrong way - does the mere fact that I want to look at them mean that I
> must correct my alpha more? Apologies if this should be perfectly obvious.
>
> Also - can anyone recommend a good way of plotting three-way interactions
> for lmer output? I have been using plot() and effect() to create trellis
> plots, as seen below, but I find it difficult and confusing trying to
> control the parameters. For example, I have not found a way to manually
> select the values for Pred2 (incremental, select values are selected by
> default for the trellis plots) and I have not found a way to indicate
> confidence intervals. If anyone can direct me to a good source that
> explains how to use plot() with these sorts of objects, please do so.
> ggplot2 does not seem to work for effects objects.
>
> Thanks in advance.
>
> #plot multiline
> p0 <- effect(?condition:Pred1:Pred2", testTotalRegion2_lmer14)
> p1 <- plot(p0,
>         multiline=TRUE,
>         main="Region2",
>         xlab=?Pred1",
>         ylab="FD (logged + residualalized)",
>         key.args=list(x=1,y=1,corner=c(x=.8, y=1))
>         )
> p1
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From tove.jansson at gmail.com  Fri Feb 13 07:46:10 2015
From: tove.jansson at gmail.com (Tove Jansson)
Date: Fri, 13 Feb 2015 07:46:10 +0100
Subject: [R-sig-ME] Multiple contrasts and what data to include when
	writing up a three-way interaction in lmer?
In-Reply-To: <CAMTWOzqgD0jv7b5XqnXoWixP+wmi9wMOQNpyeR+vzNExreBWeQ@mail.gmail.com>
References: <A1DAF5C2-0CDC-420A-A528-B1A0BD2C5176@gmail.com>
	<CAMTWOzqgD0jv7b5XqnXoWixP+wmi9wMOQNpyeR+vzNExreBWeQ@mail.gmail.com>
Message-ID: <CE6FE291-2EF7-4C7F-8194-FE50C9BAEBAF@gmail.com>

Tim - Thanks for the suggestions. It?s not completely clear if visreg() will work with lmer (lack of a ?predict? function?), though there seems to be some discussion at the end of the associated paper about what it can do with such models. I will definitely look into it. I believe I tried plotLMER, but had trouble getting the code straight. I will look again.

Any suggestions regarding including simple effects without necessitating further adjustment for multiple comparisons?

Thanks 


> On Feb 12, 2015, at 5:25 PM, Tim Meehan <tmeeha at gmail.com> wrote:
> 
> Hi Tove,
> 
> The visreg package [visreg()] and languageR package [plotLMER.fnc()] can sometimes be helpful for wrapping your head around interactions.
> 
> Best,
> Tim
> 
> On Thu, Feb 12, 2015 at 4:09 AM, Tove Jansson <tove.jansson at gmail.com <mailto:tove.jansson at gmail.com>> wrote:
> Hi,
> 
> I have a question about three-way (or any) interaction data. Perhaps my question is more conceptual than allowed on this list - but I hope it can still be considered relevant - I am very new to mixed models and it has been difficult for me to find an answer for questions regarding interactions with continuous predictors.
> 
> Brief background:
> 
> Our lmer model has a significant three-way interaction. Our DV is continuous and we have three predictors. One predictor is categorical (three levels) and the other two predictors are continuous.
> 
> To view all possible contrasts within the highest order interaction we have been using a custom contrast matrix, in a similar way as to what was done here: http://stats.stackexchange.com/questions/43664/mixed-model-multiple-comparisons-for-interaction-between-continuous-and-categori <http://stats.stackexchange.com/questions/43664/mixed-model-multiple-comparisons-for-interaction-between-continuous-and-categori> <http://stats.stackexchange.com/questions/43664/mixed-model-multiple-comparisons-for-interaction-between-continuous-and-categori <http://stats.stackexchange.com/questions/43664/mixed-model-multiple-comparisons-for-interaction-between-continuous-and-categori>>
> 
> To correct our alpha correction for multiple comparisons, we have been using the default single-step adjustment in the glht function in multcomp package.
> 
> The problem:
> 
> To minimize the adjustment for multiple comparisons, I limited my glht contrasts to the highest order interaction (the three-way).
> 
> But in order to understand the interaction, I need to also look at the simple effects for the categorical predictor. For example, it?s important for me to know if there was a significant difference at the original intercept value of a certain predictor so that I can know if an effect is a) emerging on account of an interaction or b) becoming stronger on account of the same interaction. However, if I include these simple effects in the contrasts, then I am forced to make adjustments to the alpha.
> 
> How is this typically handled? Is there a way to present the simple effects without further penalty to my p values? Or am I thinking about this the wrong way - does the mere fact that I want to look at them mean that I must correct my alpha more? Apologies if this should be perfectly obvious.
> 
> Also - can anyone recommend a good way of plotting three-way interactions for lmer output? I have been using plot() and effect() to create trellis plots, as seen below, but I find it difficult and confusing trying to control the parameters. For example, I have not found a way to manually select the values for Pred2 (incremental, select values are selected by default for the trellis plots) and I have not found a way to indicate confidence intervals. If anyone can direct me to a good source that explains how to use plot() with these sorts of objects, please do so. ggplot2 does not seem to work for effects objects.
> 
> Thanks in advance.
> 
> #plot multiline
> p0 <- effect(?condition:Pred1:Pred2", testTotalRegion2_lmer14)
> p1 <- plot(p0,
>         multiline=TRUE,
>         main="Region2",
>         xlab=?Pred1",
>         ylab="FD (logged + residualalized)",
>         key.args=list(x=1,y=1,corner=c(x=.8, y=1))
>         )
> p1
> 
> 
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 


	[[alternative HTML version deleted]]


From bran.chri at gmail.com  Fri Feb 13 09:58:08 2015
From: bran.chri at gmail.com (=?UTF-8?Q?Brandst=C3=A4tter_Christian?=)
Date: Fri, 13 Feb 2015 09:58:08 +0100
Subject: [R-sig-ME] Interpreting 2-way aov interaction
Message-ID: <CAALi0v+P8J1qgVJ4rxj3CGYf_WRzcgER=EM_uwsFV47zWfqA2A@mail.gmail.com>

Dear community,

I encountered a problem with an experimental setup; we had one treatment
step and a few mixing steps in a laboratory experiment.
The data was stored in a usual dataframe (df as below, long format) with
the categorial variables as factors left.
We could clearly observe an interaction between mixing (f2) and treatment
(meas) by applying aov as in the (extreme) example below.

f2 <- factor(c(rep(seq(1,4),each=20)))
meas <- factor(c(rep(1,18),c(rep(2,44),c(rep(1,18)))))
res <- 15*as.numeric(f2)*as.numeric(meas)
df <- data.frame(f2,meas,res)
summary(aov(data=df,res~f2*meas))

My question is, would there be a way to somehow "exclude" the variation
from the mixing step?
Would it be correct to include an error term as follows:
summary(aov(data=df,res~meas+Error(f2)))

And would that mean, what I am thinking it does: the treatment is still
significant, even if the variation through mixing (f2) is considered?
One obvious alternative I could think of would be to separate the mixing
steps, but of course in the experiment there were a few of them.

Another option would be a lmer-model I found, but the interpretation of the
output is harder to interpret:
library(lme4)
mix.model = lmer(res ~ meas + (1|f2),data=df)
summary(mix.model)

I am unfortunately not very familiar with mixed anova-setups and available
sources usually mention rather catchy examples from psychology which I find
hard to translate for this case.

Best regards
Brandst?tter Christian

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Fri Feb 13 10:19:55 2015
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 13 Feb 2015 09:19:55 +0000
Subject: [R-sig-ME] Interpreting 2-way aov interaction
In-Reply-To: <CAALi0v+P8J1qgVJ4rxj3CGYf_WRzcgER=EM_uwsFV47zWfqA2A@mail.gmail.com>
References: <CAALi0v+P8J1qgVJ4rxj3CGYf_WRzcgER=EM_uwsFV47zWfqA2A@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742701098424CF@inbomail.inbo.be>

Dear Christian,

If the interaction is important, you can model it by a random slope. See the example below. Caveat: a random effect with only 4 levels is not a good idea. See http://glmm.wikidot.com/faq for more details.

f2 <- factor(c(rep(seq(1,4),each=20)))
meas <- factor(c(rep(1,18),c(rep(2,44),c(rep(1,18)))))
df <- data.frame(f2,meas)
df$interaction <- interaction(df$meas, df$f2)

rf <- rnorm(length(levels(df$interaction)))
main <- c(10, 20)
noise <- rnorm(nrow(df), sd = 0.1)
df$res <- main[df$meas] + rf[df$interaction] + noise


library(lme4)
model.interaction <- lmer(res ~ meas + (0 + meas|f2), data = df)
model.no.interaction <- lmer(res ~ meas + (1|f2), data = df)
anova(model.interaction, model.no.interaction)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Brandst?tter Christian
Verzonden: vrijdag 13 februari 2015 9:58
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Interpreting 2-way aov interaction

Dear community,

I encountered a problem with an experimental setup; we had one treatment step and a few mixing steps in a laboratory experiment.
The data was stored in a usual dataframe (df as below, long format) with the categorial variables as factors left.
We could clearly observe an interaction between mixing (f2) and treatment
(meas) by applying aov as in the (extreme) example below.

f2 <- factor(c(rep(seq(1,4),each=20)))
meas <- factor(c(rep(1,18),c(rep(2,44),c(rep(1,18)))))
res <- 15*as.numeric(f2)*as.numeric(meas)
df <- data.frame(f2,meas,res)
summary(aov(data=df,res~f2*meas))

My question is, would there be a way to somehow "exclude" the variation from the mixing step?
Would it be correct to include an error term as follows:
summary(aov(data=df,res~meas+Error(f2)))

And would that mean, what I am thinking it does: the treatment is still significant, even if the variation through mixing (f2) is considered?
One obvious alternative I could think of would be to separate the mixing steps, but of course in the experiment there were a few of them.

Another option would be a lmer-model I found, but the interpretation of the output is harder to interpret:
library(lme4)
mix.model = lmer(res ~ meas + (1|f2),data=df)
summary(mix.model)

I am unfortunately not very familiar with mixed anova-setups and available sources usually mention rather catchy examples from psychology which I find hard to translate for this case.

Best regards
Brandst?tter Christian

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

From bran.chri at gmail.com  Fri Feb 13 15:28:24 2015
From: bran.chri at gmail.com (=?UTF-8?Q?Brandst=C3=A4tter_Christian?=)
Date: Fri, 13 Feb 2015 15:28:24 +0100
Subject: [R-sig-ME] Interpreting 2-way aov interaction
In-Reply-To: <AA818EAD2576BC488B4F623941DA742701098424CF@inbomail.inbo.be>
References: <CAALi0v+P8J1qgVJ4rxj3CGYf_WRzcgER=EM_uwsFV47zWfqA2A@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA742701098424CF@inbomail.inbo.be>
Message-ID: <CAALi0vJqkZeXGduCUOEwY6Qhc2rX3dV19mVUEd0PsLpk3+K2YA@mail.gmail.com>

Thank you for the answer, also for the very useful link.
However, we are thinking to stick with aov(), for its easier
interpretation.
There is a strong interaction between the variables, but even for each
group seperately the difference between the treatments remains significant.
And the interaction is in so far of importance, as that we want to know if
the treatment would differ even without the influence from other factors.
With best regards
Brandst?tter Christian


2015-02-13 10:19 GMT+01:00 ONKELINX, Thierry <Thierry.ONKELINX at inbo.be>:

> Dear Christian,
>
> If the interaction is important, you can model it by a random slope. See
> the example below. Caveat: a random effect with only 4 levels is not a good
> idea. See http://glmm.wikidot.com/faq for more details.
>
> f2 <- factor(c(rep(seq(1,4),each=20)))
> meas <- factor(c(rep(1,18),c(rep(2,44),c(rep(1,18)))))
> df <- data.frame(f2,meas)
> df$interaction <- interaction(df$meas, df$f2)
>
> rf <- rnorm(length(levels(df$interaction)))
> main <- c(10, 20)
> noise <- rnorm(nrow(df), sd = 0.1)
> df$res <- main[df$meas] + rf[df$interaction] + noise
>
>
> library(lme4)
> model.interaction <- lmer(res ~ meas + (0 + meas|f2), data = df)
> model.no.interaction <- lmer(res ~ meas + (1|f2), data = df)
> anova(model.interaction, model.no.interaction)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> Namens Brandst?tter Christian
> Verzonden: vrijdag 13 februari 2015 9:58
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Interpreting 2-way aov interaction
>
> Dear community,
>
> I encountered a problem with an experimental setup; we had one treatment
> step and a few mixing steps in a laboratory experiment.
> The data was stored in a usual dataframe (df as below, long format) with
> the categorial variables as factors left.
> We could clearly observe an interaction between mixing (f2) and treatment
> (meas) by applying aov as in the (extreme) example below.
>
> f2 <- factor(c(rep(seq(1,4),each=20)))
> meas <- factor(c(rep(1,18),c(rep(2,44),c(rep(1,18)))))
> res <- 15*as.numeric(f2)*as.numeric(meas)
> df <- data.frame(f2,meas,res)
> summary(aov(data=df,res~f2*meas))
>
> My question is, would there be a way to somehow "exclude" the variation
> from the mixing step?
> Would it be correct to include an error term as follows:
> summary(aov(data=df,res~meas+Error(f2)))
>
> And would that mean, what I am thinking it does: the treatment is still
> significant, even if the variation through mixing (f2) is considered?
> One obvious alternative I could think of would be to separate the mixing
> steps, but of course in the experiment there were a few of them.
>
> Another option would be a lmer-model I found, but the interpretation of
> the output is harder to interpret:
> library(lme4)
> mix.model = lmer(res ~ meas + (1|f2),data=df)
> summary(mix.model)
>
> I am unfortunately not very familiar with mixed anova-setups and available
> sources usually mention rather catchy examples from psychology which I find
> hard to translate for this case.
>
> Best regards
> Brandst?tter Christian
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> Disclaimer<https://www.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sat Feb 14 09:03:58 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 14 Feb 2015 08:03:58 +0000
Subject: [R-sig-ME] informative priors in MCMCglmm
In-Reply-To: <SNT151-W940D75F7F8A7A929E8340CB3350@phx.gbl>
References: <SNT151-W940D75F7F8A7A929E8340CB3350@phx.gbl>
Message-ID: <20150214080358.16393b28vdb6svms@www.staffmail.ed.ac.uk>

HI Diane,

Sorry for the delay. You can't place a prior directly on the  
heritability in MCMCglmm (you would have to use JAGS/WinBUGS to do  
that). You can place priors on the variance components though. You  
have the choice of inverse Wishart priors (aka inverse gamma or  
inverse scaled chi-square in the univariate case) or parameter  
expanded priors (setting nu=1 and alpha.mu=0 you have a scaled F(1,1)  
prior). The inverse Wishart prior is the easiest to understand:  
placing a prior of V=2, nu=1 on the additive genetic variance is  
equivalent to having a prior observation of a single breeding value of  
value sqrt(V). A prior of this strength sounds innocuous but it can  
have a surprisingly strong effect.

Cheers,

Jarrod










Quoting Diana Caro <dianacaro0918 at hotmail.com> on Mon, 26 Jan 2015  
09:58:46 -0500:

> Hi!
> I want to estimate variance components for four weight traits in a  
> multivariate model.If I have prior information of variances or  
> heritabilities (from literature), how can I incorporate this  
> information in a prior?
>
> Thanks
>
> Diana
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Sat Feb 14 09:06:33 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 14 Feb 2015 08:06:33 +0000
Subject: [R-sig-ME] Back-transforming posterior means and credible
 intervals
In-Reply-To: <02b701d040d5$aa200020$fe600060$@msstate.edu>
References: <02b701d040d5$aa200020$fe600060$@msstate.edu>
Message-ID: <20150214080633.11417gefhnjngrk0@www.staffmail.ed.ac.uk>

Hi Eric,


What do you mean by back transform? Do you want to calculate a  
posterior distribution for something on the inverse link scale?

Cheers,

Jarrod



Quoting Eric Michel <esm120 at msstate.edu> on Wed, 4 Feb 2015 17:52:41 -0600:

> Hello Everyone,
>
> I am running a full animal model in MCMCglmm and am trying to back-transform
> the posterior means and credible intervals from the model output to make
> them more interpretable. Forgive me if there is a simple solution to this
> but I am relatively new to Program R and am having a hard time finding a
> solution.
>
>
>
> Thanks for your help!
>
>
>
> Eric Michel
>
>
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Sat Feb 14 09:34:41 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 14 Feb 2015 08:34:41 +0000
Subject: [R-sig-ME] Meta-analysis for heritability using MCMCglmm?
In-Reply-To: <CAOxxGRmza_LHg=HKbKKVLvU3ouidZ8FJGccNVE=T8pmzB=-YdA@mail.gmail.com>
References: <CAOxxGR=8rvPJTiHPjVYJNaCDZcUH0medNnk+fba2bONrX8kS2Q@mail.gmail.com>
	<CAF5_5cyX-HYrnrO1qDvP2+CsRWTaRpVU8BgpGe9sR+bf8LRiRg@mail.gmail.com>
	<20141226065813.21424g2r4lweojk0@www.staffmail.ed.ac.uk>
	<CAOxxGR=O0B-cmiy_4HwUnOaHNrorn-XUtY2bJMo6uwqYYmMVuw@mail.gmail.com>
	<CAOxxGRmza_LHg=HKbKKVLvU3ouidZ8FJGccNVE=T8pmzB=-YdA@mail.gmail.com>
Message-ID: <20150214083441.20061vgpbgxx3mbo@www.staffmail.ed.ac.uk>

Hi Jackie,

1/ For the residuals you can do:

my_data$y-predict(my_model)

In the code above the predictions are marginal with respect to the  
random effects. If you want the predictions to include the random  
effects then use:

my_data$y-predict(my_model, marginal=NULL)


2/ I don't have a good solution for the weighted analysis. In fact we  
didn't do a weighted analysis in the end because only about 50% of  
studies provided standard errors. We figured that we lost more power  
by discarding the 50% than we would gain by incorporating information  
about the relative precision of different estimates. REML standard  
errors are based on the sampling distribution of estimates tending to  
the normal as n goes to infinity. In reality the sampling distribution  
will be skewed (particularly when h2 and/or sample size is low) like  
the posterior distribution. Its far from perfect but you could use the  
standard error given by:

0.5*((u95-pm)/qnorm(0.975)+(l95-pm)/qnorm(0.025))

where l95 and u95 are the lower and upper 95% credible intervals and  
pm is the posterior mean/mode.  The motivation behind this is *if* the  
posterior was normal and the asymmetry in the 95% credible intervals  
was just due to Monte Carlo error then this would be the best estimate  
of the posterior standard deviation (sort of like a standard error)  
given the information at hand. Not great justification!


3/ DIC (as focussed in MCMCglmm) is not a reliable model selection  
criterion for scientific inference. For Gaussian resopnses you could  
refocus DIC at the correct level post-analysis and then it would be  
more reliable. I should probably write a function to do this ....

Cheers,

Jarrod


Quoting Jackie Wood <jackiewood7 at gmail.com> on Sun, 1 Feb 2015 12:10:51 -0500:

> Hi Jarrod,
>
> We were finally able to dig into the statistical analysis of our
> heritability data (as a reminder, we are conducting a meta-analysis
> investigating heritability in relation to population size) and of course a
> few questions have come up.
>
> You had mentioned examining the residuals for the model. This may seem like
> a "beginner" question, how does one extract the residuals from MCMCglmm?
> The residuals.mcmcglmm function does not work. Summary plots of the MCMC
> parameter estimates appear to be roughly normally distributed, and the
> traces seem fine. Is this what you were referring to? We ran an unweighted
> analysis (heritability estimates without SEs) in both MCMCglmm and lmer to
> see if they give similar results, and they are basically concordant as
> well. However, the residual distribution for the models run in lmer
> (treating heritability as gaussian) is slightly skewed. These are from an
> unweighted analysis, though, as I have also read that lme4 is unsuitable
> for conducting formal weighted meta-analyses.
>
> We also had a few questions that we thought would be worth discussing about
> some methodological issues relating to incorporating common estimates of
> heritability in the literature. Bayesian methodologies have become
> increasingly popular to use when estimating trait heritabilities, but
> bayesian estimates do not provide typical standard error or variance
> estimates, as parent-offspring/ANOVA/REML methods do. Published bayesian
> heritability estimates typically only include asymmetric confidence
> intervals, and we unsure whether these can be translated into variance
> estimates that can be used to weight our meta-analysis. For now, we plan on
> performing a weighted meta-analysis using heritability estimates that
> provide S.E.s, and an additional unweighted analysis that will include the
> bayesian point-estimates we have collected from the literature. We were
> wondering if you resolved this issue in your own heritability meta-analysis
> and knew of a way to incorporate bayesian estimates (which form a
> considerable proportion of the suitable heritability estimates available,
> at least in recent history) into a formal weighted meta-analysis.
>
> Additionally, we were wondering about the suitability of DIC to conduct
> model selection for our analysis of heritability. I recall reading on this
> SIG list that you had mentioned that there were potential issues using DIC
> for hierarchical models as well as non-gaussian data. Since we're treating
> heritability as gaussian, would it still be appropriate?
>
> Any advise would be much appreciated!
>
>
> On Thu, Jan 15, 2015 at 3:41 PM, Jackie Wood <jackiewood7 at gmail.com> wrote:
>
>> Hi Jarrod and Ken,
>>
>> Hope you had a great New Year! Thanks so much for your responses to my
>> inquiry. Given that we've been using MCMCglmm all along, we'll probably
>> stick with it unless there's a compelling reason to change programs. We'll
>> be running the h2 models in the coming days and will specify a Gaussian
>> distribution as Jarrod suggested; we have quite a bit of data so hopefully
>> the residuals will behave!
>>
>> The advice is much appreciated as always!
>> Jackie
>>
>> On Fri, Dec 26, 2014 at 1:58 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>> Hi Jackie,
>>>
>>> The data are not binomial they are continuous: a beta distribution is
>>> probably most appropriate for continuos observations bounded by 0 and 1.
>>> However, although heritabilities are bounded by 0 and 1, heritability
>>> estimates are not necessarily so, depending on the method of inference (for
>>> example it would be possible to get a negative parent-offspring regression,
>>> either by chance or through certain types of maternal effect).
>>>
>>> We have just finished a meta-analysis of h2 estimates and just treated
>>> them as Gaussian. The distribution of the residuals wasn't far off and I
>>> think the conclusions are robust to the distributional assumptions. Have
>>> you checked your residuals - do they look badly non-normal?
>>>
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>> Quoting Ken Beath <ken.beath at mq.edu.au> on Wed, 24 Dec 2014 12:30:03
>>> +1100:
>>>
>>>  If you have the original data giving the numerator and denominator for
>>>> the
>>>> proportion then it is binomial data, and can be modelled in a
>>>> met-analysis.
>>>> I don't know if this can be done with MCMCglmm but should be possible
>>>> with
>>>> STAN, JAGS or BUGS. All will require a bit of effort in setting up the
>>>> model.
>>>>
>>>> On 24 December 2014 at 07:17, Jackie Wood <jackiewood7 at gmail.com> wrote:
>>>>
>>>>  Dear R-users,
>>>>>
>>>>> I am attempting to conduct a meta-analysis to investigate the
>>>>> relationship
>>>>> of narrow-sense heritability with population size. In previous work, I
>>>>> have
>>>>> used MCMCglmm to conduct a formal meta-analysis which allowed me to
>>>>> account
>>>>> for the effect of sampling error through the argument "mev". This was
>>>>> relatively easy to do for a continuous response variable, however,
>>>>> heritability is presented as a proportion and is therefore bounded by 0
>>>>> and
>>>>> 1 which clearly changes the situation.
>>>>>
>>>>> In fact, I am not actually certain if it possible to conduct a formal
>>>>> weighted meta-analysis on the heritability data using MCMCglmm. I have
>>>>> seen
>>>>> elsewhere where data presented as a proportion (survival,
>>>>> yolk-conversion
>>>>> efficiency for example) has been logit transformed and fitted using a
>>>>> Gaussian error distribution (though this was done using REML rather than
>>>>> Bayesian modelling) but I don't know if this is a legitimate strategy
>>>>> for a
>>>>> formal meta-analysis using heritability as a response variable since any
>>>>> transformation applied to the heritability data would also need to be
>>>>> applied to the standard errors?
>>>>>
>>>>> I would greatly appreciate any advice on this matter!
>>>>>
>>>>> Cheers,
>>>>> Jackie
>>>>>
>>>>> --
>>>>> Jacquelyn L.A. Wood, PhD.
>>>>> Biology Department
>>>>> Concordia University
>>>>> 7141 Sherbrooke St. West
>>>>> Montreal, QC
>>>>> H4B 1R6
>>>>> Phone: (514) 293-7255
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>>
>>>> *Ken Beath*
>>>> Lecturer
>>>> Statistics Department
>>>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>>>
>>>> Phone: +61 (0)2 9850 8516
>>>>
>>>> Building E4A, room 526
>>>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>>>
>>>> CRICOS Provider No 00002J
>>>> This message is intended for the addressee named and may...{{dropped:9}}
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>
>>
>> --
>> Jacquelyn L.A. Wood, PhD.
>> Biology Department
>> Concordia University
>> 7141 Sherbrooke St. West
>> Montreal, QC
>> H4B 1R6
>> Phone: (514) 293-7255
>>
>>
>
>
> --
> Jacquelyn L.A. Wood, PhD.
> Biology Department
> Concordia University
> 7141 Sherbrooke St. West
> Montreal, QC
> H4B 1R6
> Phone: (514) 293-7255
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From andreas.nord at biol.lu.se  Tue Feb 17 15:51:26 2015
From: andreas.nord at biol.lu.se (Andreas Nord)
Date: Tue, 17 Feb 2015 14:51:26 +0000
Subject: [R-sig-ME] Autoregressive covariance structure for lme object and
 R/SAS differences in model output
Message-ID: <504BD08817485B49A9AB0ED11F217112F74F7BB6@UWMBX03.uw.lu.se>

Dear R users,
We are working on a data set in which we have measured repeatedly a physiological response variable (y)
every 20 min for 12 h (time variable; 'x') in subjects ('id') beloning to one of five groups ('group'; 'A' to 'E'). Data are located at:https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0

We are interested to model if the response in y differences with time (i.e. 'x') for the two groups. Thus:
require(nlme)
m1<-lme(y~group*x+group*I(x^2),random=~x|id,data=data.df,na.action=na.omit)

But because data are collected repeatedly over short time intervals for each subject, it seemed prudent to consider an autoregressive covariance structure. Thus:
m2<-update(m1,~.,corr=corCAR1(form=~x|id))

AIC values indicate the latter (i.e. m2) as more appropriate:
  anova(m1,m2)
#   Model df      AIC      BIC       logLik        Test  L.Ratio      p-value
#m1     1 19 2155.996 2260.767 -1058.9981
#m2     2 20 2021.944 2132.229  -990.9718 1 vs 2 136.0525  <.0001

Fixed effects and test statistics differ between models. A look at marginal ANOVA tables suggest inference might differ somewhat between models:

anova.lme(m1,type="m")
#              numDF denDF  F-value p-value
#(Intercept)      1  1789 63384.80  <.0001
#group             4    45      1.29  0.2893
#x                   1  1789     0.05  0.8226
#I(x^2)            1  1789     4.02  0.0451
#group:x          4  1789     2.61  0.0341
#group:I(x^2)   4  1789     4.37  0.0016

anova.lme(m2,type="m")
#             numDF denDF  F-value p-value
#(Intercept)      1  1789 59395.79  <.0001
#group             4    45      1.33  0.2725
#x                    1  1789     0.04  0.8379
#I(x^2)            1  1789     2.28  0.1312
#group:x          4  1789     2.09  0.0802
#group:I(x^2)  4  1789     2.81  0.0244

Now, this is all well. But: my colleagues have been running the same data set using PROC MIXED in SAS and come up with substantially different results when comparing SAS default covariance structure (variance components) and AR1. Specifically, there is virtually no change in either test statistics or fitted values when using AR1 instead of Variance Components in SAS, which fits the observation that AIC values (in SAS) indicate both covariance structures fit data equally well.

This is not very satisfactory to me, and I would be interesting to know what is happening here. Realizing
this might not be the correct forum for this question, I would like to ask you all if anyone would have any
input as to what is going on here, e.g. am I setting up my model erroneously, etc.?

N.b. I have no desire to replicate SAS results, but I would most certainly be interested to know what could possibly explain  such a large discrepancy between the two platforms. Any suggestions greatly welcomed.

(Data are located at: https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0)

With all best wishes,
Andreas

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Feb 17 18:00:18 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Feb 2015 18:00:18 +0100
Subject: [R-sig-ME] Autoregressive covariance structure for lme object
 and R/SAS differences in model output
In-Reply-To: <504BD08817485B49A9AB0ED11F217112F74F7BB6@UWMBX03.uw.lu.se>
References: <504BD08817485B49A9AB0ED11F217112F74F7BB6@UWMBX03.uw.lu.se>
Message-ID: <CAJuCY5y6Gn=mdPTXL89pPbDVra7xwZK98370L9gF4GkL8T2W3A@mail.gmail.com>

Dear Andreas,

Write down the equation of the lme model and the SAS model and look for
differences in that. It is likely that both models look at a different kind
of correlation. lme() models the correlation in the residuals WITHIN the
same group as defined by the random effect levels. If I recall correctly
SAS has correlation structures for what they call the G-side and the
R-side. You need to ask your colleagues how SAS handles the correlation.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-17 15:51 GMT+01:00 Andreas Nord <andreas.nord at biol.lu.se>:

> Dear R users,
> We are working on a data set in which we have measured repeatedly a
> physiological response variable (y)
> every 20 min for 12 h (time variable; 'x') in subjects ('id') beloning to
> one of five groups ('group'; 'A' to 'E'). Data are located at:
> https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0
>
> We are interested to model if the response in y differences with time
> (i.e. 'x') for the two groups. Thus:
> require(nlme)
> m1<-lme(y~group*x+group*I(x^2),random=~x|id,data=data.df,na.action=na.omit)
>
> But because data are collected repeatedly over short time intervals for
> each subject, it seemed prudent to consider an autoregressive covariance
> structure. Thus:
> m2<-update(m1,~.,corr=corCAR1(form=~x|id))
>
> AIC values indicate the latter (i.e. m2) as more appropriate:
>   anova(m1,m2)
> #   Model df      AIC      BIC       logLik        Test  L.Ratio
> p-value
> #m1     1 19 2155.996 2260.767 -1058.9981
> #m2     2 20 2021.944 2132.229  -990.9718 1 vs 2 136.0525  <.0001
>
> Fixed effects and test statistics differ between models. A look at
> marginal ANOVA tables suggest inference might differ somewhat between
> models:
>
> anova.lme(m1,type="m")
> #              numDF denDF  F-value p-value
> #(Intercept)      1  1789 63384.80  <.0001
> #group             4    45      1.29  0.2893
> #x                   1  1789     0.05  0.8226
> #I(x^2)            1  1789     4.02  0.0451
> #group:x          4  1789     2.61  0.0341
> #group:I(x^2)   4  1789     4.37  0.0016
>
> anova.lme(m2,type="m")
> #             numDF denDF  F-value p-value
> #(Intercept)      1  1789 59395.79  <.0001
> #group             4    45      1.33  0.2725
> #x                    1  1789     0.04  0.8379
> #I(x^2)            1  1789     2.28  0.1312
> #group:x          4  1789     2.09  0.0802
> #group:I(x^2)  4  1789     2.81  0.0244
>
> Now, this is all well. But: my colleagues have been running the same data
> set using PROC MIXED in SAS and come up with substantially different
> results when comparing SAS default covariance structure (variance
> components) and AR1. Specifically, there is virtually no change in either
> test statistics or fitted values when using AR1 instead of Variance
> Components in SAS, which fits the observation that AIC values (in SAS)
> indicate both covariance structures fit data equally well.
>
> This is not very satisfactory to me, and I would be interesting to know
> what is happening here. Realizing
> this might not be the correct forum for this question, I would like to ask
> you all if anyone would have any
> input as to what is going on here, e.g. am I setting up my model
> erroneously, etc.?
>
> N.b. I have no desire to replicate SAS results, but I would most certainly
> be interested to know what could possibly explain  such a large discrepancy
> between the two platforms. Any suggestions greatly welcomed.
>
> (Data are located at:
> https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0)
>
> With all best wishes,
> Andreas
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From burwood70 at gmail.com  Thu Feb 19 01:59:55 2015
From: burwood70 at gmail.com (Steve Candy)
Date: Thu, 19 Feb 2015 11:59:55 +1100
Subject: [R-sig-ME] Autoregressive covariance structure for lme object
	and R/SAS
Message-ID: <001001d04bdf$63a56bc0$2af04340$@gmail.com>

Andreas
 You state:
> ...using AR1 instead of Variance Components in SAS, which fits the
observation that AIC values (in SAS) indicate both covariance structures fit
data equally well.

The lme model includes both random subject effects and an CAR1 process so
this last process is on the residuals adjusting for subject random effect
estimates. Is the SAS model equivalent? The above statement implies its
either random subject effects fitted or a CAR1 error process but not both
together. The summary(m2) in terms of the error model variance
component/parameters could be compared to the SAS output. Also you could
plot the sample/theoretical variograms with the R-code below. My experience
with lme suggested to me that you have to have subjects ("id") as a random
effect when fitting corCAR1(form=~x|id) but there may be a way around this
restriction. 

vg.01 <- Variogram(m2, form = ~ x|id)
plot(y= vg.01$variog , x= vg.01$dist)
# extract Phi (or set its value to output value)
# over-plot the fitted CAR1 model 
lines(y=(1-Phi^(seq(1,length(vg.01$dist)))), x=seq(1,length(vg.01$dist)),
lwd=2)


Dr Steven G. Candy
Director/Consultant
SCANDY STATISTICAL MODELLING PTY LTD


> Dear R users,
> We are working on a data set in which we have measured repeatedly a 
> physiological response variable (y) every 20 min for 12 h (time 
> variable; 'x') in subjects ('id') beloning to one of five groups 
> ('group'; 'A' to 'E'). Data are located at:
> https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0
>
> We are interested to model if the response in y differences with time 
> (i.e. 'x') for the two groups. Thus:
> require(nlme)
> m1<-lme(y~group*x+group*I(x^2),random=~x|id,data=data.df,na.action=na.
> omit)
>
> But because data are collected repeatedly over short time intervals 
> for each subject, it seemed prudent to consider an autoregressive 
> covariance structure. Thus:
> m2<-update(m1,~.,corr=corCAR1(form=~x|id))
>
> AIC values indicate the latter (i.e. m2) as more appropriate:
>   anova(m1,m2)
> #   Model df      AIC      BIC       logLik        Test  L.Ratio
> p-value
> #m1     1 19 2155.996 2260.767 -1058.9981
> #m2     2 20 2021.944 2132.229  -990.9718 1 vs 2 136.0525  <.0001
>
> Fixed effects and test statistics differ between models. A look at 
> marginal ANOVA tables suggest inference might differ somewhat between
> models:
>
> anova.lme(m1,type="m")
> #              numDF denDF  F-value p-value
> #(Intercept)      1  1789 63384.80  <.0001
> #group             4    45      1.29  0.2893
> #x                   1  1789     0.05  0.8226
> #I(x^2)            1  1789     4.02  0.0451
> #group:x          4  1789     2.61  0.0341
> #group:I(x^2)   4  1789     4.37  0.0016
>
> anova.lme(m2,type="m")
> #             numDF denDF  F-value p-value
> #(Intercept)      1  1789 59395.79  <.0001
> #group             4    45      1.33  0.2725
> #x                    1  1789     0.04  0.8379
> #I(x^2)            1  1789     2.28  0.1312
> #group:x          4  1789     2.09  0.0802
> #group:I(x^2)  4  1789     2.81  0.0244
>
> Now, this is all well. But: my colleagues have been running the same 
> data set using PROC MIXED in SAS and come up with substantially 
> different results when comparing SAS default covariance structure 
> (variance
> components) and AR1. Specifically, there is virtually no change in 
> either test statistics or fitted values when using AR1 instead of 
> Variance Components in SAS, which fits the observation that AIC values 
> (in SAS) indicate both covariance structures fit data equally well.
>
> This is not very satisfactory to me, and I would be interesting to 
> know what is happening here. Realizing this might not be the correct 
> forum for this question, I would like to ask you all if anyone would 
> have any input as to what is going on here, e.g. am I setting up my 
> model erroneously, etc.?
>
> N.b. I have no desire to replicate SAS results, but I would most 
> certainly be interested to know what could possibly explain  such a 
> large discrepancy between the two platforms. Any suggestions greatly
welcomed.
>
> (Data are located at:
> https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0)
>
> With all best wishes,
> Andreas
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 98, Issue 14


From tom_philippi at nps.gov  Thu Feb 19 04:00:29 2015
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Wed, 18 Feb 2015 19:00:29 -0800
Subject: [R-sig-ME] Autoregressive covariance structure for lme object
	and R/SAS
In-Reply-To: <001001d04bdf$63a56bc0$2af04340$@gmail.com>
References: <001001d04bdf$63a56bc0$2af04340$@gmail.com>
Message-ID: <CAM9kYqizjdFGDiZ_qhbw7xZoR-aAHhM3pJnV5EJQByQBctWoNQ@mail.gmail.com>

Andreas--
If you need to understand what SAS is doing, and how it differs from nlme,
I strongly recommend you look at either Stroup's paper:

@article{stroup2014rethinking,
  title={Rethinking the Analysis of Non-Normal Data in Plant and Soil Science},
  author={Stroup, Walter W},
  journal={Agronomy Journal},
  year={2014},
  publisher={The American Society of Agronomy, Inc.}
}

https://dl.sciencesocieties.org/publications/aj/articles/0/0/agronj2013.0342

or you may need to look at the whole book:

@book{stroup2012generalized,
  title={Generalized linear mixed models: modern concepts, methods and
applications},
  author={Stroup, Walter W},
  year={2012},
  publisher={CRC Press}
}

https://books.google.com/books?hl=en&lr=&id=GcGrySpkXRMC&oi=fnd&pg=PP1&dq=%22what+would+fisher+do%22+stroup&ots=jUWUpAfgVY&sig=KtAHT4Sx6zvuFnIMzMXPYRIi6QE

They're both incredibly informative and fun reads (I believe that Doug
Bates recommended it to this list last year), and will let you know exactly
what the different SAS PROCS are doing.

I hope that this helps,
Tom 2

On Wed, Feb 18, 2015 at 4:59 PM, Steve Candy <burwood70 at gmail.com> wrote:

> Andreas
>  You state:
> > ...using AR1 instead of Variance Components in SAS, which fits the
> observation that AIC values (in SAS) indicate both covariance structures
> fit
> data equally well.
>
> The lme model includes both random subject effects and an CAR1 process so
> this last process is on the residuals adjusting for subject random effect
> estimates. Is the SAS model equivalent? The above statement implies its
> either random subject effects fitted or a CAR1 error process but not both
> together. The summary(m2) in terms of the error model variance
> component/parameters could be compared to the SAS output. Also you could
> plot the sample/theoretical variograms with the R-code below. My experience
> with lme suggested to me that you have to have subjects ("id") as a random
> effect when fitting corCAR1(form=~x|id) but there may be a way around this
> restriction.
>
> vg.01 <- Variogram(m2, form = ~ x|id)
> plot(y= vg.01$variog , x= vg.01$dist)
> # extract Phi (or set its value to output value)
> # over-plot the fitted CAR1 model
> lines(y=(1-Phi^(seq(1,length(vg.01$dist)))), x=seq(1,length(vg.01$dist)),
> lwd=2)
>
>
> Dr Steven G. Candy
> Director/Consultant
> SCANDY STATISTICAL MODELLING PTY LTD
>
>
> > Dear R users,
> > We are working on a data set in which we have measured repeatedly a
> > physiological response variable (y) every 20 min for 12 h (time
> > variable; 'x') in subjects ('id') beloning to one of five groups
> > ('group'; 'A' to 'E'). Data are located at:
> > https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0
> >
> > We are interested to model if the response in y differences with time
> > (i.e. 'x') for the two groups. Thus:
> > require(nlme)
> > m1<-lme(y~group*x+group*I(x^2),random=~x|id,data=data.df,na.action=na.
> > omit)
> >
> > But because data are collected repeatedly over short time intervals
> > for each subject, it seemed prudent to consider an autoregressive
> > covariance structure. Thus:
> > m2<-update(m1,~.,corr=corCAR1(form=~x|id))
> >
> > AIC values indicate the latter (i.e. m2) as more appropriate:
> >   anova(m1,m2)
> > #   Model df      AIC      BIC       logLik        Test  L.Ratio
> > p-value
> > #m1     1 19 2155.996 2260.767 -1058.9981
> > #m2     2 20 2021.944 2132.229  -990.9718 1 vs 2 136.0525  <.0001
> >
> > Fixed effects and test statistics differ between models. A look at
> > marginal ANOVA tables suggest inference might differ somewhat between
> > models:
> >
> > anova.lme(m1,type="m")
> > #              numDF denDF  F-value p-value
> > #(Intercept)      1  1789 63384.80  <.0001
> > #group             4    45      1.29  0.2893
> > #x                   1  1789     0.05  0.8226
> > #I(x^2)            1  1789     4.02  0.0451
> > #group:x          4  1789     2.61  0.0341
> > #group:I(x^2)   4  1789     4.37  0.0016
> >
> > anova.lme(m2,type="m")
> > #             numDF denDF  F-value p-value
> > #(Intercept)      1  1789 59395.79  <.0001
> > #group             4    45      1.33  0.2725
> > #x                    1  1789     0.04  0.8379
> > #I(x^2)            1  1789     2.28  0.1312
> > #group:x          4  1789     2.09  0.0802
> > #group:I(x^2)  4  1789     2.81  0.0244
> >
> > Now, this is all well. But: my colleagues have been running the same
> > data set using PROC MIXED in SAS and come up with substantially
> > different results when comparing SAS default covariance structure
> > (variance
> > components) and AR1. Specifically, there is virtually no change in
> > either test statistics or fitted values when using AR1 instead of
> > Variance Components in SAS, which fits the observation that AIC values
> > (in SAS) indicate both covariance structures fit data equally well.
> >
> > This is not very satisfactory to me, and I would be interesting to
> > know what is happening here. Realizing this might not be the correct
> > forum for this question, I would like to ask you all if anyone would
> > have any input as to what is going on here, e.g. am I setting up my
> > model erroneously, etc.?
> >
> > N.b. I have no desire to replicate SAS results, but I would most
> > certainly be interested to know what could possibly explain  such a
> > large discrepancy between the two platforms. Any suggestions greatly
> welcomed.
> >
> > (Data are located at:
> > https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0)
> >
> > With all best wishes,
> > Andreas
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 98, Issue 14
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
-------------------------------------------
Tom Philippi
Quantitative Ecologist & Data Therapist
Inventory and Monitoring Program
National Park Service

	[[alternative HTML version deleted]]


From atarca at med.wayne.edu  Thu Feb 19 17:33:36 2015
From: atarca at med.wayne.edu (Tarca, Adi)
Date: Thu, 19 Feb 2015 16:33:36 +0000
Subject: [R-sig-ME] postdoctoral opportunity
Message-ID: <6DE578F501A8B2489DBD4893CEC996BA20B0099B@MED-CORE07B.med.wayne.edu>

Dear list,

Please allow me to ask if anyone is interested in a postdoctoral position involving longitudinal data modeling with lme4 and other R packages. Please see the ad at http://bioinformaticsprb.med.wayne.edu/?page_id=62
Thanks

Adi Laurentiu TARCA, Ph.D.
Associate Professor
Department of Obstetrics and Gynecology,
Wayne State University, School of Medicine.
Director
Bioinformatics and Computational Biology Unit,
Perinatology Research Branch (NICHD/NIH),
3990 John R., Office 4809,
Detroit, Michigan 48201
Tel: 1-313-5775305
Fax: 1-3135778986



________________________________

This document may include proprietary and confidential information. This document may not be reproduced, copied, distributed, published, modified or furnished to third parties, without prior written consent. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. If you are not the intended recipient you are notified that disclosing, copying, distributing or taking any action in reliance on the contents of this information is strictly prohibited.


From josie.galbraith at gmail.com  Sun Feb 22 00:17:54 2015
From: josie.galbraith at gmail.com (Josie Galbraith)
Date: Sun, 22 Feb 2015 12:17:54 +1300
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models in
	blme
Message-ID: <CAGb-hRp9YRcm8f+fnQ=_UfuYxeSN97FMCZmzaDOC3v0ydAPMzg@mail.gmail.com>

Hi all,

I've been looking for solutions to the issue of complete separation for the
data I'm analysing for my PhD. I gather from everything I've read that I
should use a Bayesian GLMM - using blme in R.  I'm completely new to the
Bayesian framework (and this mailing list!) so apologies if my questions
are basic.

I'm after some advice on how to choose which priors to use.  I gather I
need to impose a weak prior on the fixed effects of my model but no
covariance priors - is this correct?  Can I use a default prior (i.e. t, or
normal defaults in the blme package) or does it depend on my data?  What is
considered a suitably weak prior?

I am running binomial models for epidemiology data (response variable is
presence/absence of lesions), with 2 fixed effects (FOOD: F/NF; SEASON:
Autumn/Spring) and a random effect (SITE: 8 levels).  The main goal of
these models is to test for an effect of the treatment 'FOOD.'  I'm
guessing from what I've read, that my model should be something like the
following:

bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family = binomial,
fixef.prior = normal, cov.prior = NULL)

This is the output when I run the model:

Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...), common.scale =
FALSE)
Prior dev  : 18.2419

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
bglmerMod]
 Family: binomial ( logit )
Formula: LESION ~ FOOD * SEASON + (1 | SITE)
   Data: SEYE.df

     AIC      BIC   logLik deviance df.resid
   112.1    128.0    -51.0    102.1      173

Scaled residuals:
    Min      1Q  Median      3Q     Max
-0.4464 -0.3814 -0.2813 -0.1737  3.5800

Random effects:
 Groups Name        Variance Std.Dev.
 SITE   (Intercept) 0.3064   0.5535
Number of obs: 178, groups: SITE, 8

Fixed effects:
                    Estimate Std. Error z value Pr(>|z|)
(Intercept)          -3.7664     1.4551  -2.588  0.00964 **
FOODNF                0.5462     1.6838   0.324  0.74567
SEASONSpring          1.7529     1.4721   1.191  0.23378
FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) FOODNF SEASON
FOODNF      -0.864
SEASONSprng -0.954  0.824
FOODNF:SEAS  0.787 -0.892 -0.824

Advice or thoughts as to whether I'm on the right track would be greatly
appreciated.
Cheers,
Josie


-- 
*Josie Galbraith* MSc (hons)

PhD candidate
*University of Auckland *
Joint Graduate School in Biodiversity and Biosecurity ? School of
Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
*www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>

	[[alternative HTML version deleted]]


From solimarygh at usp.br  Tue Feb 24 22:35:24 2015
From: solimarygh at usp.br (solimarygh at usp.br)
Date: Tue, 24 Feb 2015 18:35:24 -0300 (BRT)
Subject: [R-sig-ME] Macroecology of sexual selection
In-Reply-To: <2065011651.6391074.1424813595596.JavaMail.root@usp.br>
Message-ID: <1642129550.6391527.1424813724109.JavaMail.root@usp.br>


Hi, Bolker, nice to meet you. 
I?m doing my master degree at University of S?o Paulo. I?m traing to analize how the temperature affects the sexual traits. I have a morfological data from 21 populations along to east cost of Brazil. For each population I have just one data of temperture and one coordenates (Lat, Lon). And I want see the temperatura efect in male and females (like an ANCOVA in a simple case). So, I don?t know what is kind of analise that I need to do, because, all that I tried to do, result in the same problem: 


"Error in getCovariate.corSpatial(object, data = data) : 
cannot have zero distances in "corSpatial" ". 


Plesae, I'd greatly appreciate advice on the matter. 


A hug, Soly
	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Feb 25 09:45:16 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 Feb 2015 09:45:16 +0100
Subject: [R-sig-ME] Macroecology of sexual selection
In-Reply-To: <1642129550.6391527.1424813724109.JavaMail.root@usp.br>
References: <2065011651.6391074.1424813595596.JavaMail.root@usp.br>
	<1642129550.6391527.1424813724109.JavaMail.root@usp.br>
Message-ID: <CAJuCY5wCyOe2y65ASHKumbusizKtW-fCvLBgSA=5i3kin25sgg@mail.gmail.com>

Dear Soly,

A workaround is to add some random noise to the locations.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-24 22:35 GMT+01:00 <solimarygh at usp.br>:

>
> Hi, Bolker, nice to meet you.
> I?m doing my master degree at University of S?o Paulo. I?m traing to
> analize how the temperature affects the sexual traits. I have a
> morfological data from 21 populations along to east cost of Brazil. For
> each population I have just one data of temperture and one coordenates
> (Lat, Lon). And I want see the temperatura efect in male and females (like
> an ANCOVA in a simple case). So, I don?t know what is kind of analise that
> I need to do, because, all that I tried to do, result in the same problem:
>
>
> "Error in getCovariate.corSpatial(object, data = data) :
> cannot have zero distances in "corSpatial" ".
>
>
> Plesae, I'd greatly appreciate advice on the matter.
>
>
> A hug, Soly
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Feb 25 11:15:54 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 25 Feb 2015 10:15:54 +0000
Subject: [R-sig-ME] Stats course: GAM and GAMM in Genoa, Italy
Message-ID: <54EDA0DA.6050003@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course:

Course:   Introduction to GAM and GAMM with R
Location: University of Genoa, Italy
Date:       11 - 15 May 2015.
Price:       425 GBP

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2015_05Genua.pdf


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From mckellercran at gmail.com  Thu Feb 26 00:42:32 2015
From: mckellercran at gmail.com (Matthew Keller)
Date: Wed, 25 Feb 2015 16:42:32 -0700
Subject: [R-sig-ME] estimating variance components for arbitrarily defined
	var/covar matrices
Message-ID: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>

Hi all,

This is a typical problem in genetics and I'm trying to figure out whether
there's any way to solve it using lmer or similar, and if not, why it isn't
possible.

Often in genetics, we have an n-by-n matrix (n=sample size) of genetic
relationships, where the diagonal is how related you are to yourself (~1,
depending on inbreeding) and off-diagonals each pairwise relationship. I'd
like to be able to use lmer or some other function in R to estimate the
variance attributable to this genetic relationship matrix. Thus:
y = b0 + b*X + g*Z + error
where y is a vector of observations, b is a vector of fixed covariate
effects and g is a vector of random genetic effects. X and Z are incidence
matrices for b & g respectively, and we assume g ~ N(0, VG). The variance
of y is therefore
var(y) = Z*Z' * VG + I*var(e)

Z*Z' is the observed n-by-n genetic relationship matrix. Given an observed
Z*Z' genetic relationship matrix, is there a way to estimate VG?

I guess this boils down to, if we have an observed n-by-n matrix of
similarities, can we use mixed models in R to get the variance in y that is
explained by that similarity?

Thanks in advance!

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Feb 26 01:12:14 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Feb 2015 19:12:14 -0500
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
Message-ID: <54EE64DE.5030409@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  I haven't actually tried any problems like this, but

1. in principle this is possible
2. There's a hack at
http://stackoverflow.com/questions/19327088/reproducing-results-from-previous-answer-is-not-working-due-to-using-new-version/19382162#19382162
3. you might take a look at the pedigreemm package for another
example.  There *might* be something else in the Reverse
Depends/Suggests list at
http://cran.r-project.org/web/packages/lme4/index.html , but nothing
jumps out at me.

  Steve Walker is in the very early stages of working on a
phylogenetic model with a similar structure.

  Looking forward to seeing what other people have to say ...

  Ben


On 15-02-25 06:42 PM, Matthew Keller wrote:
> Hi all,
> 
> This is a typical problem in genetics and I'm trying to figure out
> whether there's any way to solve it using lmer or similar, and if
> not, why it isn't possible.
> 
> Often in genetics, we have an n-by-n matrix (n=sample size) of
> genetic relationships, where the diagonal is how related you are to
> yourself (~1, depending on inbreeding) and off-diagonals each
> pairwise relationship. I'd like to be able to use lmer or some
> other function in R to estimate the variance attributable to this
> genetic relationship matrix. Thus: y = b0 + b*X + g*Z + error where
> y is a vector of observations, b is a vector of fixed covariate 
> effects and g is a vector of random genetic effects. X and Z are
> incidence matrices for b & g respectively, and we assume g ~ N(0,
> VG). The variance of y is therefore var(y) = Z*Z' * VG + I*var(e)
> 
> Z*Z' is the observed n-by-n genetic relationship matrix. Given an
> observed Z*Z' genetic relationship matrix, is there a way to
> estimate VG?
> 
> I guess this boils down to, if we have an observed n-by-n matrix
> of similarities, can we use mixed models in R to get the variance
> in y that is explained by that similarity?
> 
> Thanks in advance!
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU7mTeAAoJEOCV5YRblxUHZ+8IAJbS6sHtOIHM1zJcql0jcizh
IpPKXsu4x0jhEnhH4RIxLDwumHXKZQyZeGOYWDeD+wgE/mNUHqeWRiGYp8Qd8w+m
IR6uaswTp5wVP/HcMfRB5cTeFVkhoXQ3aRa0nOZrwI7V4d5HTIRmg5NvCb9Kro7n
ZM4ONyLEETHMXfOUgeDAA7SOWrGmoNschOBuMdhD/jaajo2Cf3QOI4owaq/vQ+D4
fW41afw5lWXOgck6MLDck77R+8IELxIrbfYWauxPJp47CyHHPS27pCH3PoHX7S7B
LF5VJXL+Ta7gS3luig8Sou/fkXdt/NdHs1CqDP7EJ2B7VBM/1BasMMju13Y0ork=
=4RMa
-----END PGP SIGNATURE-----


From David.Duffy at qimr.edu.au  Thu Feb 26 01:52:54 2015
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 26 Feb 2015 10:52:54 +1000
Subject: [R-sig-ME] estimating variance components for arbitrarily
 definedvar/covar matrices
In-Reply-To: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1502261046070.3292@orpheus.qimr.edu.au>

Hi Matt.

It depends if you want to do GLMMs or not. Look at the AnimalINLA, kinship 
(now kinship2) with nlme, and regress packages for starters, since you can 
feed them an arbitrary matrix out of the box.  I have used glmmPQL too. 
WRT Ben's comment about pedigreemm, you would have to look at their code 
but it should be _relatively_ straightforward.

CHeers, David.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From r.turner at auckland.ac.nz  Thu Feb 26 02:07:16 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 26 Feb 2015 14:07:16 +1300
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <54EE64DE.5030409@gmail.com>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<54EE64DE.5030409@gmail.com>
Message-ID: <54EE71C4.5050301@auckland.ac.nz>



Ben:  Perhaps I am misunderstanding, but isn't this essentially the same 
as a problem that I asked you about, some years ago, about which you 
said that it cannot currently be done in lme4?

I guess that in my old question to you, Z*Z' was the identity matrix, so 
the current question is perhaps a generalization of my question.

The catch, it seems to me, is that var(e) is ill-defined --- you can 
replace var(e) by var(e) - zeta and Z*Z*VG by Z*Z'*VG + zeta*I for any 
zeta such that

    -delta < zeta < var(e)

where delta = min(diag(Z*Z'*VG)), and have an equivalent model.

Is it not so?  If not, what am I misunderstanding?

In my question to you I asked if one could constrain var(e) to be zero 
so as to make the model well defined, and you said no, one could not, 
because of the way lmer does its estimation.

cheers,

Rolf


On 26/02/15 13:12, Ben Bolker wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>    I haven't actually tried any problems like this, but
>
> 1. in principle this is possible
> 2. There's a hack at
> http://stackoverflow.com/questions/19327088/reproducing-results-from-previous-answer-is-not-working-due-to-using-new-version/19382162#19382162
> 3. you might take a look at the pedigreemm package for another
> example.  There *might* be something else in the Reverse
> Depends/Suggests list at
> http://cran.r-project.org/web/packages/lme4/index.html , but nothing
> jumps out at me.
>
>    Steve Walker is in the very early stages of working on a
> phylogenetic model with a similar structure.
>
>    Looking forward to seeing what other people have to say ...
>
>    Ben
>
>
> On 15-02-25 06:42 PM, Matthew Keller wrote:
>> Hi all,
>>
>> This is a typical problem in genetics and I'm trying to figure out
>> whether there's any way to solve it using lmer or similar, and if
>> not, why it isn't possible.
>>
>> Often in genetics, we have an n-by-n matrix (n=sample size) of
>> genetic relationships, where the diagonal is how related you are to
>> yourself (~1, depending on inbreeding) and off-diagonals each
>> pairwise relationship. I'd like to be able to use lmer or some
>> other function in R to estimate the variance attributable to this
>> genetic relationship matrix. Thus: y = b0 + b*X + g*Z + error where
>> y is a vector of observations, b is a vector of fixed covariate
>> effects and g is a vector of random genetic effects. X and Z are
>> incidence matrices for b & g respectively, and we assume g ~ N(0,
>> VG). The variance of y is therefore var(y) = Z*Z' * VG + I*var(e)
>>
>> Z*Z' is the observed n-by-n genetic relationship matrix. Given an
>> observed Z*Z' genetic relationship matrix, is there a way to
>> estimate VG?
>>
>> I guess this boils down to, if we have an observed n-by-n matrix
>> of similarities, can we use mixed models in R to get the variance
>> in y that is explained by that similarity?
>>
>> Thanks in advance!
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJU7mTeAAoJEOCV5YRblxUHZ+8IAJbS6sHtOIHM1zJcql0jcizh
> IpPKXsu4x0jhEnhH4RIxLDwumHXKZQyZeGOYWDeD+wgE/mNUHqeWRiGYp8Qd8w+m
> IR6uaswTp5wVP/HcMfRB5cTeFVkhoXQ3aRa0nOZrwI7V4d5HTIRmg5NvCb9Kro7n
> ZM4ONyLEETHMXfOUgeDAA7SOWrGmoNschOBuMdhD/jaajo2Cf3QOI4owaq/vQ+D4
> fW41afw5lWXOgck6MLDck77R+8IELxIrbfYWauxPJp47CyHHPS27pCH3PoHX7S7B
> LF5VJXL+Ta7gS3luig8Sou/fkXdt/NdHs1CqDP7EJ2B7VBM/1BasMMju13Y0ork=
> =4RMa
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From bbolker at gmail.com  Thu Feb 26 04:54:20 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Feb 2015 22:54:20 -0500
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <54EE71C4.5050301@auckland.ac.nz>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<54EE64DE.5030409@gmail.com> <54EE71C4.5050301@auckland.ac.nz>
Message-ID: <54EE98EC.6010202@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  I thought we were assuming a fixed var-cov matrix PLUS an error
variance, i.e. Sigma + s^2*I (increasing the variance and decreasing
the correlation).

  But I could be wrong about what model is intended.

On 15-02-25 08:07 PM, Rolf Turner wrote:
> 
> 
> Ben:  Perhaps I am misunderstanding, but isn't this essentially the
> same as a problem that I asked you about, some years ago, about
> which you said that it cannot currently be done in lme4?
> 
> I guess that in my old question to you, Z*Z' was the identity
> matrix, so the current question is perhaps a generalization of my
> question.
> 
> The catch, it seems to me, is that var(e) is ill-defined --- you
> can replace var(e) by var(e) - zeta and Z*Z*VG by Z*Z'*VG + zeta*I
> for any zeta such that
> 
> -delta < zeta < var(e)
> 
> where delta = min(diag(Z*Z'*VG)), and have an equivalent model.
> 
> Is it not so?  If not, what am I misunderstanding?
> 
> In my question to you I asked if one could constrain var(e) to be
> zero so as to make the model well defined, and you said no, one
> could not, because of the way lmer does its estimation.
> 
> cheers,
> 
> Rolf
> 
> 
> On 26/02/15 13:12, Ben Bolker wrote: I haven't actually tried any
> problems like this, but
> 
> 1. in principle this is possible 2. There's a hack at 
> http://stackoverflow.com/questions/19327088/reproducing-results-from-previous-answer-is-not-working-due-to-using-new-version/19382162#19382162
>
>  3. you might take a look at the pedigreemm package for another 
> example.  There *might* be something else in the Reverse 
> Depends/Suggests list at 
> http://cran.r-project.org/web/packages/lme4/index.html , but
> nothing jumps out at me.
> 
> Steve Walker is in the very early stages of working on a 
> phylogenetic model with a similar structure.
> 
> Looking forward to seeing what other people have to say ...
> 
> Ben
> 
> 
> On 15-02-25 06:42 PM, Matthew Keller wrote:
>>>> Hi all,
>>>> 
>>>> This is a typical problem in genetics and I'm trying to
>>>> figure out whether there's any way to solve it using lmer or
>>>> similar, and if not, why it isn't possible.
>>>> 
>>>> Often in genetics, we have an n-by-n matrix (n=sample size)
>>>> of genetic relationships, where the diagonal is how related
>>>> you are to yourself (~1, depending on inbreeding) and
>>>> off-diagonals each pairwise relationship. I'd like to be able
>>>> to use lmer or some other function in R to estimate the
>>>> variance attributable to this genetic relationship matrix.
>>>> Thus: y = b0 + b*X + g*Z + error where y is a vector of
>>>> observations, b is a vector of fixed covariate effects and g
>>>> is a vector of random genetic effects. X and Z are incidence
>>>> matrices for b & g respectively, and we assume g ~ N(0, VG).
>>>> The variance of y is therefore var(y) = Z*Z' * VG + I*var(e)
>>>> 
>>>> Z*Z' is the observed n-by-n genetic relationship matrix.
>>>> Given an observed Z*Z' genetic relationship matrix, is there
>>>> a way to estimate VG?
>>>> 
>>>> I guess this boils down to, if we have an observed n-by-n
>>>> matrix of similarities, can we use mixed models in R to get
>>>> the variance in y that is explained by that similarity?
>>>> 
>>>> Thanks in advance!
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
> 
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU7pjsAAoJEOCV5YRblxUHfxAIANU53/bbUluWrJBijHmywLoI
WO4+XInWA8i9RAYcHU6p35//i1pTlpTSJiIlROpZo9Q5RwbFIRz30oMrRf6KpVDX
4MBYaQALH5frN9M/aaxg3nuDcya4UUb+HVblOULgrdxcAhlqOW7CtNBB143RVnhh
hmPtPXt2qeJGGXCcogePw+yB4IPe9fsFn81AQAWpGFfF75u9h9F57d0RHkgd7TlQ
9rzEU158OfknEkgEtL83jWVkKU45NF1cFUKbPQ3Ba0vKTsq1dyNhGgEdUDxlyniS
1LJaG9ae7bwo+CI9nIgzWLuj1QHSal+1aSajG4PbCfm12qIuRQrkXmw2PPW+e3Q=
=hi2q
-----END PGP SIGNATURE-----


From j.hadfield at ed.ac.uk  Thu Feb 26 08:00:14 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 26 Feb 2015 07:00:14 +0000
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
Message-ID: <20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>

Hi Matthew,

Both MCMCglmm and asreml-r fit these models in R.

Cheers,

Jarrod




  Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015  
16:42:32 -0700:

> Hi all,
>
> This is a typical problem in genetics and I'm trying to figure out whether
> there's any way to solve it using lmer or similar, and if not, why it isn't
> possible.
>
> Often in genetics, we have an n-by-n matrix (n=sample size) of genetic
> relationships, where the diagonal is how related you are to yourself (~1,
> depending on inbreeding) and off-diagonals each pairwise relationship. I'd
> like to be able to use lmer or some other function in R to estimate the
> variance attributable to this genetic relationship matrix. Thus:
> y = b0 + b*X + g*Z + error
> where y is a vector of observations, b is a vector of fixed covariate
> effects and g is a vector of random genetic effects. X and Z are incidence
> matrices for b & g respectively, and we assume g ~ N(0, VG). The variance
> of y is therefore
> var(y) = Z*Z' * VG + I*var(e)
>
> Z*Z' is the observed n-by-n genetic relationship matrix. Given an observed
> Z*Z' genetic relationship matrix, is there a way to estimate VG?
>
> I guess this boils down to, if we have an observed n-by-n matrix of
> similarities, can we use mixed models in R to get the variance in y that is
> explained by that similarity?
>
> Thanks in advance!
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From arives at wisc.edu  Thu Feb 26 13:04:29 2015
From: arives at wisc.edu (Anthony R Ives)
Date: Thu, 26 Feb 2015 06:04:29 -0600
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>
	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
Message-ID: <7510b92b15aef.54eeb76d@wiscmail.wisc.edu>

Matthew,

You should be able to do this in communityPGLMM in {pez}. Also, Steve Walker is currently working on a way to do this in lmer/glmer.


Cheers, Tony


On 02/26/15, Jarrod Hadfield  wrote:
> Hi Matthew,
> 
> Both MCMCglmm and asreml-r fit these models in R.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015 16:42:32 -0700:
> 
> >Hi all,
> >
> >This is a typical problem in genetics and I'm trying to figure out whether
> >there's any way to solve it using lmer or similar, and if not, why it isn't
> >possible.
> >
> >Often in genetics, we have an n-by-n matrix (n=sample size) of genetic
> >relationships, where the diagonal is how related you are to yourself (~1,
> >depending on inbreeding) and off-diagonals each pairwise relationship. I'd
> >like to be able to use lmer or some other function in R to estimate the
> >variance attributable to this genetic relationship matrix. Thus:
> >y = b0 + b*X + g*Z + error
> >where y is a vector of observations, b is a vector of fixed covariate
> >effects and g is a vector of random genetic effects. X and Z are incidence
> >matrices for b & g respectively, and we assume g ~ N(0, VG). The variance
> >of y is therefore
> >var(y) = Z*Z' * VG + I*var(e)
> >
> >Z*Z' is the observed n-by-n genetic relationship matrix. Given an observed
> >Z*Z' genetic relationship matrix, is there a way to estimate VG?
> >
> >I guess this boils down to, if we have an observed n-by-n matrix of
> >similarities, can we use mixed models in R to get the variance in y that is
> >explained by that similarity?
> >
> >Thanks in advance!
> >
> >	[[alternative HTML version deleted]]
> >
> >_______________________________________________
> >R-sig-mixed-models at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Feb 26 17:24:39 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 26 Feb 2015 17:24:39 +0100
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>
	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
	<7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F065D8B12@UM-MAIL4112.unimaas.nl>

And just to throw another package in the mix, you can also use the metafor package for this. While this doesn't quite sound like a meta-analysis, in the end, meta-analysis models are just mixed-effects models. And in a phylogenetic meta-analysis, we add random effects with known correlations matrices to the model.

The syntax would be:

id.e <- 1:nrow(dat)
id.r <- 1:nrow(dat)
rma.mv(y ~ <fixed effects>, V = 0, random = list(~ 1 | id.r, ~ 1 | id.e), R = list(id.r = GRM), data=dat)

where 'GRM' is the n x n matrix of similarities. The V = 0 part seems a bit strange, but in meta-analytic models, we usually don't estimate the error variance and instead have known sampling variances (or even a known variance-covariance matrix of the sampling errors). Here, we don't, so we just set that part to 0 (you'll get a warning that 'V appears to be not positive definite.' but you can safely ignore this). This will fit the model that you specified below.

Besides the estimates of the fixed effects, the results will include two variance components, one for id.r (this is VG) and one for id.e (this is sigma^2_error). The default is REML estimation (method="ML" is you want MLEs).

By default, rma.mv() tries to rescale the matrix supplied via the R argument into a correlation matrix. Not sure if your matrix of similarities is really a correlation matrix or not. In case you don't want the function to mess with the matrix, set 'Rscale=FALSE' and it won't touch it.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Anthony R Ives
> Sent: Thursday, February 26, 2015 13:04
> To: Jarrod Hadfield; Matthew Keller
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] estimating variance components for arbitrarily
> defined var/covar matrices
> 
> Matthew,
> 
> You should be able to do this in communityPGLMM in {pez}. Also, Steve
> Walker is currently working on a way to do this in lmer/glmer.
> 
> Cheers, Tony
> 
> 
> On 02/26/15, Jarrod Hadfield  wrote:
> > Hi Matthew,
> >
> > Both MCMCglmm and asreml-r fit these models in R.
> >
> > Cheers,
> >
> > Jarrod
> >
> > Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015
> 16:42:32 -0700:
> >
> > >Hi all,
> > >
> > >This is a typical problem in genetics and I'm trying to figure out
> whether
> > >there's any way to solve it using lmer or similar, and if not, why it
> isn't
> > >possible.
> > >
> > >Often in genetics, we have an n-by-n matrix (n=sample size) of genetic
> > >relationships, where the diagonal is how related you are to yourself
> (~1,
> > >depending on inbreeding) and off-diagonals each pairwise relationship.
> I'd
> > >like to be able to use lmer or some other function in R to estimate
> the
> > >variance attributable to this genetic relationship matrix. Thus:
> > >y = b0 + b*X + g*Z + error
> > >where y is a vector of observations, b is a vector of fixed covariate
> > >effects and g is a vector of random genetic effects. X and Z are
> incidence
> > >matrices for b & g respectively, and we assume g ~ N(0, VG). The
> variance
> > >of y is therefore
> > >var(y) = Z*Z' * VG + I*var(e)
> > >
> > >Z*Z' is the observed n-by-n genetic relationship matrix. Given an
> observed
> > >Z*Z' genetic relationship matrix, is there a way to estimate VG?
> > >
> > >I guess this boils down to, if we have an observed n-by-n matrix of
> > >similarities, can we use mixed models in R to get the variance in y
> that is
> > >explained by that similarity?
> > >
> > >Thanks in advance!


From j.hadfield at ed.ac.uk  Thu Feb 26 17:41:56 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 26 Feb 2015 16:41:56 +0000
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F065D8B12@UM-MAIL4112.unimaas.nl>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>
	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
	<7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
	<077E31A57DA26E46AB0D493C9966AC730F065D8B12@UM-MAIL4112.unimaas.nl>
Message-ID: <20150226164156.20672er6gz19a3fo@www.staffmail.ed.ac.uk>

Hi,

If the `genetic' matrix is pedigree derived (?) the matrix is a  
correlation matrix (in the absence of inbreeding) or proportional to  
the covariance matrix (with inbreeding). However, the matrix has a lot  
of structure that can be exploited by *not* treating it as just  
another correlation matrix. Specifically, the inverse of the matrix is  
all zeros, except for the diagonal elements and those that correspond  
to mates and/or parent-offspring. ASReml, WOMBAT, MCMCglmm, pedigreem  
(?) + others all exploit this structure leading to faster more robust  
results. For small problems this might not be an issue.

Cheers,

Jarrod



Quoting "Viechtbauer Wolfgang (STAT)"  
<wolfgang.viechtbauer at maastrichtuniversity.nl> on Thu, 26 Feb 2015  
17:24:39 +0100:

> And just to throw another package in the mix, you can also use the  
> metafor package for this. While this doesn't quite sound like a  
> meta-analysis, in the end, meta-analysis models are just  
> mixed-effects models. And in a phylogenetic meta-analysis, we add  
> random effects with known correlations matrices to the model.
>
> The syntax would be:
>
> id.e <- 1:nrow(dat)
> id.r <- 1:nrow(dat)
> rma.mv(y ~ <fixed effects>, V = 0, random = list(~ 1 | id.r, ~ 1 |  
> id.e), R = list(id.r = GRM), data=dat)
>
> where 'GRM' is the n x n matrix of similarities. The V = 0 part  
> seems a bit strange, but in meta-analytic models, we usually don't  
> estimate the error variance and instead have known sampling  
> variances (or even a known variance-covariance matrix of the  
> sampling errors). Here, we don't, so we just set that part to 0  
> (you'll get a warning that 'V appears to be not positive definite.'  
> but you can safely ignore this). This will fit the model that you  
> specified below.
>
> Besides the estimates of the fixed effects, the results will include  
> two variance components, one for id.r (this is VG) and one for id.e  
> (this is sigma^2_error). The default is REML estimation (method="ML"  
> is you want MLEs).
>
> By default, rma.mv() tries to rescale the matrix supplied via the R  
> argument into a correlation matrix. Not sure if your matrix of  
> similarities is really a correlation matrix or not. In case you  
> don't want the function to mess with the matrix, set 'Rscale=FALSE'  
> and it won't touch it.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
>
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Anthony R Ives
>> Sent: Thursday, February 26, 2015 13:04
>> To: Jarrod Hadfield; Matthew Keller
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] estimating variance components for arbitrarily
>> defined var/covar matrices
>>
>> Matthew,
>>
>> You should be able to do this in communityPGLMM in {pez}. Also, Steve
>> Walker is currently working on a way to do this in lmer/glmer.
>>
>> Cheers, Tony
>>
>>
>> On 02/26/15, Jarrod Hadfield  wrote:
>> > Hi Matthew,
>> >
>> > Both MCMCglmm and asreml-r fit these models in R.
>> >
>> > Cheers,
>> >
>> > Jarrod
>> >
>> > Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015
>> 16:42:32 -0700:
>> >
>> > >Hi all,
>> > >
>> > >This is a typical problem in genetics and I'm trying to figure out
>> whether
>> > >there's any way to solve it using lmer or similar, and if not, why it
>> isn't
>> > >possible.
>> > >
>> > >Often in genetics, we have an n-by-n matrix (n=sample size) of genetic
>> > >relationships, where the diagonal is how related you are to yourself
>> (~1,
>> > >depending on inbreeding) and off-diagonals each pairwise relationship.
>> I'd
>> > >like to be able to use lmer or some other function in R to estimate
>> the
>> > >variance attributable to this genetic relationship matrix. Thus:
>> > >y = b0 + b*X + g*Z + error
>> > >where y is a vector of observations, b is a vector of fixed covariate
>> > >effects and g is a vector of random genetic effects. X and Z are
>> incidence
>> > >matrices for b & g respectively, and we assume g ~ N(0, VG). The
>> variance
>> > >of y is therefore
>> > >var(y) = Z*Z' * VG + I*var(e)
>> > >
>> > >Z*Z' is the observed n-by-n genetic relationship matrix. Given an
>> observed
>> > >Z*Z' genetic relationship matrix, is there a way to estimate VG?
>> > >
>> > >I guess this boils down to, if we have an observed n-by-n matrix of
>> > >similarities, can we use mixed models in R to get the variance in y
>> that is
>> > >explained by that similarity?
>> > >
>> > >Thanks in advance!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Feb 26 17:50:36 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 26 Feb 2015 17:50:36 +0100
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <20150226164156.20672er6gz19a3fo@www.staffmail.ed.ac.uk>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>
	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
	<7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
	<077E31A57DA26E46AB0D493C9966AC730F065D8B12@UM-MAIL4112.unimaas.nl>
	<20150226164156.20672er6gz19a3fo@www.staffmail.ed.ac.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F065D8B29@UM-MAIL4112.unimaas.nl>

Good point. Using sparse matrix methods is one way of handling that. Set 'sparse=TRUE' for rma.mv() to do so.

Best,
Wolfgang

> -----Original Message-----
> From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
> Sent: Thursday, February 26, 2015 17:42
> To: Viechtbauer Wolfgang (STAT)
> Cc: r-sig-mixed-models at r-project.org; Matthew Keller
> Subject: Re: [R-sig-ME] estimating variance components for arbitrarily
> defined var/covar matrices
> 
> Hi,
> 
> If the `genetic' matrix is pedigree derived (?) the matrix is a
> correlation matrix (in the absence of inbreeding) or proportional to
> the covariance matrix (with inbreeding). However, the matrix has a lot
> of structure that can be exploited by *not* treating it as just
> another correlation matrix. Specifically, the inverse of the matrix is
> all zeros, except for the diagonal elements and those that correspond
> to mates and/or parent-offspring. ASReml, WOMBAT, MCMCglmm, pedigreem
> (?) + others all exploit this structure leading to faster more robust
> results. For small problems this might not be an issue.
> 
> Cheers,
> 
> Jarrod
> 
> Quoting "Viechtbauer Wolfgang (STAT)"
> <wolfgang.viechtbauer at maastrichtuniversity.nl> on Thu, 26 Feb 2015
> 17:24:39 +0100:
> 
> > And just to throw another package in the mix, you can also use the
> > metafor package for this. While this doesn't quite sound like a
> > meta-analysis, in the end, meta-analysis models are just
> > mixed-effects models. And in a phylogenetic meta-analysis, we add
> > random effects with known correlations matrices to the model.
> >
> > The syntax would be:
> >
> > id.e <- 1:nrow(dat)
> > id.r <- 1:nrow(dat)
> > rma.mv(y ~ <fixed effects>, V = 0, random = list(~ 1 | id.r, ~ 1 |
> > id.e), R = list(id.r = GRM), data=dat)
> >
> > where 'GRM' is the n x n matrix of similarities. The V = 0 part
> > seems a bit strange, but in meta-analytic models, we usually don't
> > estimate the error variance and instead have known sampling
> > variances (or even a known variance-covariance matrix of the
> > sampling errors). Here, we don't, so we just set that part to 0
> > (you'll get a warning that 'V appears to be not positive definite.'
> > but you can safely ignore this). This will fit the model that you
> > specified below.
> >
> > Besides the estimates of the fixed effects, the results will include
> > two variance components, one for id.r (this is VG) and one for id.e
> > (this is sigma^2_error). The default is REML estimation (method="ML"
> > is you want MLEs).
> >
> > By default, rma.mv() tries to rescale the matrix supplied via the R
> > argument into a correlation matrix. Not sure if your matrix of
> > similarities is really a correlation matrix or not. In case you
> > don't want the function to mess with the matrix, set 'Rscale=FALSE'
> > and it won't touch it.
> >
> > Best,
> > Wolfgang
> >
> > --
> > Wolfgang Viechtbauer, Ph.D., Statistician
> > Department of Psychiatry and Psychology
> > School for Mental Health and Neuroscience
> > Faculty of Health, Medicine, and Life Sciences
> > Maastricht University, P.O. Box 616 (VIJV1)
> > 6200 MD Maastricht, The Netherlands
> > +31 (43) 388-4170 | http://www.wvbauer.com
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Anthony R Ives
> >> Sent: Thursday, February 26, 2015 13:04
> >> To: Jarrod Hadfield; Matthew Keller
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] estimating variance components for arbitrarily
> >> defined var/covar matrices
> >>
> >> Matthew,
> >>
> >> You should be able to do this in communityPGLMM in {pez}. Also, Steve
> >> Walker is currently working on a way to do this in lmer/glmer.
> >>
> >> Cheers, Tony
> >>
> >>
> >> On 02/26/15, Jarrod Hadfield  wrote:
> >> > Hi Matthew,
> >> >
> >> > Both MCMCglmm and asreml-r fit these models in R.
> >> >
> >> > Cheers,
> >> >
> >> > Jarrod
> >> >
> >> > Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015
> >> 16:42:32 -0700:
> >> >
> >> > >Hi all,
> >> > >
> >> > >This is a typical problem in genetics and I'm trying to figure out
> >> whether
> >> > >there's any way to solve it using lmer or similar, and if not, why
> it
> >> isn't
> >> > >possible.
> >> > >
> >> > >Often in genetics, we have an n-by-n matrix (n=sample size) of
> genetic
> >> > >relationships, where the diagonal is how related you are to
> yourself
> >> (~1,
> >> > >depending on inbreeding) and off-diagonals each pairwise
> relationship.
> >> I'd
> >> > >like to be able to use lmer or some other function in R to estimate
> >> the
> >> > >variance attributable to this genetic relationship matrix. Thus:
> >> > >y = b0 + b*X + g*Z + error
> >> > >where y is a vector of observations, b is a vector of fixed
> covariate
> >> > >effects and g is a vector of random genetic effects. X and Z are
> >> incidence
> >> > >matrices for b & g respectively, and we assume g ~ N(0, VG). The
> >> variance
> >> > >of y is therefore
> >> > >var(y) = Z*Z' * VG + I*var(e)
> >> > >
> >> > >Z*Z' is the observed n-by-n genetic relationship matrix. Given an
> >> observed
> >> > >Z*Z' genetic relationship matrix, is there a way to estimate VG?
> >> > >
> >> > >I guess this boils down to, if we have an observed n-by-n matrix of
> >> > >similarities, can we use mixed models in R to get the variance in y
> >> that is
> >> > >explained by that similarity?
> >> > >
> >> > >Thanks in advance!


From zsa11 at mail.aub.edu  Thu Feb 26 00:02:53 2015
From: zsa11 at mail.aub.edu (Zahwa Al Ayyash (Student))
Date: Wed, 25 Feb 2015 23:02:53 +0000
Subject: [R-sig-ME] Zero-inflated mixed models
Message-ID: <1424905368937.78449@mail.aub.edu>

Dear all,

Zero-inflated models have a count component (Poisson/Neg. Binomial) and a zero component (logistic regression part).

glmmADMB supports the zero-inflation feature but only through estimating a zero-inflation parameter that is assumed constant across the whole data set?.


  1.  ?Why doesn't the glmmadmb support the two-stage fitting of zero-inflated models like it does with hurdle models? I once read that its estimation might be more complex than that of hurdle models. Is that true? If yes, why?
  2.  Is there an R package that allows for the two-model fitting (i.e., each model with its own covariates) of ZIP or ZINB (not hurdle) and allowing for a random effect?

Many thanks,
Z


	[[alternative HTML version deleted]]


From bellonedavide1 at gmail.com  Thu Feb 26 18:14:38 2015
From: bellonedavide1 at gmail.com (Davide Bellone)
Date: Thu, 26 Feb 2015 18:14:38 +0100
Subject: [R-sig-ME] Problem- Warning message
Message-ID: <CABa6ee0msQrE5uztANxWuXUtwfnTaKCycoCX5ZUYDUu+H3e92A@mail.gmail.com>

Goodevening,

this is my first mail . From what a collegue told me I can ask to the
members of this mailing list to help me with my problem.
So, what I am trying to do is a glmer model. I have 1 random effect (Site)
and 6 fixed effects.

Model <- read.table("c:\\TXT X R\\Tabella modello gruppi
completo.txt",header=T)
y <- cbind(Model$Rem, Model$Total-Model$Rem)
Model$wood <- as.factor(Model$wood)
Model$under <- as.factor(Model$under)
Model$Manage <- as.factor(Model$Manage)
Model$Size <- as.factor(Model$Size)
Model$Site <- as.factor(Model$Site)
obs <- 1:length(Model$Site)
obs
options(contrasts=c("contr.sum", "contr.poly"))
R1 <- glmer(y ~ Model$Manage + Model$age +  Model$veg + Model$Size +
Model$wood + Model$under + Model$age*Model$Manage + Model$veg*Model$Manage
+ (1|Model$Site)+(1|obs) , family= binomial)

The first output is:
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 1.02046 (tol = 0.001, component
3)

Can someone explain if there is some problem in data and if there is a
solution?

Thank you. I hope that my collegue told me the right way to how to use the
mailing list

D?vide

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Feb 26 18:17:47 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 26 Feb 2015 17:17:47 +0000
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F065D8B29@UM-MAIL4112.unimaas.nl>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>
	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
	<7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
	<077E31A57DA26E46AB0D493C9966AC730F065D8B12@UM-MAIL4112.unimaas.nl>
	<20150226164156.20672er6gz19a3fo@www.staffmail.ed.ac.uk>
	<077E31A57DA26E46AB0D493C9966AC730F065D8B29@UM-MAIL4112.unimaas.nl>
Message-ID: <20150226171747.577218rt19i0ql34@www.staffmail.ed.ac.uk>

Hi Wolfgang,

The matrix itself is not necessarily sparse (although usually is) its  
the inverse that is sparse.  The pattern of sparsity is also important  
because the equations can be permuted so they are more easily solved  
(if you use something like minimum degree ordering it will probably do  
a good job automatically). In addition, the nice structure is lost if  
individuals connecting two relatives are omitted. In this situation  
(the usual case) the random effect vector is usually augmented with  
these `missing' individuals and so the matrix is of greater dimension  
than the number of observations, and the corresponding columns of the  
design matrix are set to zero. I'm not sure if metafor handles these  
sorts of issues? The issues are not difficult to solve, but often  
general-purpose packages don't accommodate them because for most  
problems its not clear why you would ever need to worry about them.

Cheers,

Jarrod

Quoting "Viechtbauer Wolfgang (STAT)"  
<wolfgang.viechtbauer at maastrichtuniversity.nl> on Thu, 26 Feb 2015  
17:50:36 +0100:

> Good point. Using sparse matrix methods is one way of handling that.  
> Set 'sparse=TRUE' for rma.mv() to do so.
>
> Best,
> Wolfgang
>
>> -----Original Message-----
>> From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
>> Sent: Thursday, February 26, 2015 17:42
>> To: Viechtbauer Wolfgang (STAT)
>> Cc: r-sig-mixed-models at r-project.org; Matthew Keller
>> Subject: Re: [R-sig-ME] estimating variance components for arbitrarily
>> defined var/covar matrices
>>
>> Hi,
>>
>> If the `genetic' matrix is pedigree derived (?) the matrix is a
>> correlation matrix (in the absence of inbreeding) or proportional to
>> the covariance matrix (with inbreeding). However, the matrix has a lot
>> of structure that can be exploited by *not* treating it as just
>> another correlation matrix. Specifically, the inverse of the matrix is
>> all zeros, except for the diagonal elements and those that correspond
>> to mates and/or parent-offspring. ASReml, WOMBAT, MCMCglmm, pedigreem
>> (?) + others all exploit this structure leading to faster more robust
>> results. For small problems this might not be an issue.
>>
>> Cheers,
>>
>> Jarrod
>>
>> Quoting "Viechtbauer Wolfgang (STAT)"
>> <wolfgang.viechtbauer at maastrichtuniversity.nl> on Thu, 26 Feb 2015
>> 17:24:39 +0100:
>>
>> > And just to throw another package in the mix, you can also use the
>> > metafor package for this. While this doesn't quite sound like a
>> > meta-analysis, in the end, meta-analysis models are just
>> > mixed-effects models. And in a phylogenetic meta-analysis, we add
>> > random effects with known correlations matrices to the model.
>> >
>> > The syntax would be:
>> >
>> > id.e <- 1:nrow(dat)
>> > id.r <- 1:nrow(dat)
>> > rma.mv(y ~ <fixed effects>, V = 0, random = list(~ 1 | id.r, ~ 1 |
>> > id.e), R = list(id.r = GRM), data=dat)
>> >
>> > where 'GRM' is the n x n matrix of similarities. The V = 0 part
>> > seems a bit strange, but in meta-analytic models, we usually don't
>> > estimate the error variance and instead have known sampling
>> > variances (or even a known variance-covariance matrix of the
>> > sampling errors). Here, we don't, so we just set that part to 0
>> > (you'll get a warning that 'V appears to be not positive definite.'
>> > but you can safely ignore this). This will fit the model that you
>> > specified below.
>> >
>> > Besides the estimates of the fixed effects, the results will include
>> > two variance components, one for id.r (this is VG) and one for id.e
>> > (this is sigma^2_error). The default is REML estimation (method="ML"
>> > is you want MLEs).
>> >
>> > By default, rma.mv() tries to rescale the matrix supplied via the R
>> > argument into a correlation matrix. Not sure if your matrix of
>> > similarities is really a correlation matrix or not. In case you
>> > don't want the function to mess with the matrix, set 'Rscale=FALSE'
>> > and it won't touch it.
>> >
>> > Best,
>> > Wolfgang
>> >
>> > --
>> > Wolfgang Viechtbauer, Ph.D., Statistician
>> > Department of Psychiatry and Psychology
>> > School for Mental Health and Neuroscience
>> > Faculty of Health, Medicine, and Life Sciences
>> > Maastricht University, P.O. Box 616 (VIJV1)
>> > 6200 MD Maastricht, The Netherlands
>> > +31 (43) 388-4170 | http://www.wvbauer.com
>> >
>> >> -----Original Message-----
>> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> >> project.org] On Behalf Of Anthony R Ives
>> >> Sent: Thursday, February 26, 2015 13:04
>> >> To: Jarrod Hadfield; Matthew Keller
>> >> Cc: r-sig-mixed-models at r-project.org
>> >> Subject: Re: [R-sig-ME] estimating variance components for arbitrarily
>> >> defined var/covar matrices
>> >>
>> >> Matthew,
>> >>
>> >> You should be able to do this in communityPGLMM in {pez}. Also, Steve
>> >> Walker is currently working on a way to do this in lmer/glmer.
>> >>
>> >> Cheers, Tony
>> >>
>> >>
>> >> On 02/26/15, Jarrod Hadfield  wrote:
>> >> > Hi Matthew,
>> >> >
>> >> > Both MCMCglmm and asreml-r fit these models in R.
>> >> >
>> >> > Cheers,
>> >> >
>> >> > Jarrod
>> >> >
>> >> > Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015
>> >> 16:42:32 -0700:
>> >> >
>> >> > >Hi all,
>> >> > >
>> >> > >This is a typical problem in genetics and I'm trying to figure out
>> >> whether
>> >> > >there's any way to solve it using lmer or similar, and if not, why
>> it
>> >> isn't
>> >> > >possible.
>> >> > >
>> >> > >Often in genetics, we have an n-by-n matrix (n=sample size) of
>> genetic
>> >> > >relationships, where the diagonal is how related you are to
>> yourself
>> >> (~1,
>> >> > >depending on inbreeding) and off-diagonals each pairwise
>> relationship.
>> >> I'd
>> >> > >like to be able to use lmer or some other function in R to estimate
>> >> the
>> >> > >variance attributable to this genetic relationship matrix. Thus:
>> >> > >y = b0 + b*X + g*Z + error
>> >> > >where y is a vector of observations, b is a vector of fixed
>> covariate
>> >> > >effects and g is a vector of random genetic effects. X and Z are
>> >> incidence
>> >> > >matrices for b & g respectively, and we assume g ~ N(0, VG). The
>> >> variance
>> >> > >of y is therefore
>> >> > >var(y) = Z*Z' * VG + I*var(e)
>> >> > >
>> >> > >Z*Z' is the observed n-by-n genetic relationship matrix. Given an
>> >> observed
>> >> > >Z*Z' genetic relationship matrix, is there a way to estimate VG?
>> >> > >
>> >> > >I guess this boils down to, if we have an observed n-by-n matrix of
>> >> > >similarities, can we use mixed models in R to get the variance in y
>> >> that is
>> >> > >explained by that similarity?
>> >> > >
>> >> > >Thanks in advance!
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From steve.walker at utoronto.ca  Thu Feb 26 20:09:27 2015
From: steve.walker at utoronto.ca (Steve Walker)
Date: Thu, 26 Feb 2015 14:09:27 -0500
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
	<7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
Message-ID: <54EF6F67.5020907@utoronto.ca>

Thanks Tony.  For those interested, you can check out the development of 
my work on phylogenetic models in lme4 here:

https://github.com/stevencarlislewalker/lme4ord

The section in the README file about phylogenetic models gives an 
example and briefly describes the kinds of models that can be fitted.

Regarding speed, the glmerc (with a 'c' for known covariance over 
grouping factor levels) function can fit models similar to the one in 
the README but with a 500 tip phylogeny in about 20 seconds on my pretty 
standard macbook pro.  lme4 uses sparse matrices for all random 
effect-related matrix computations, so most of the speed comes from this 
infrastructure.  However, it may be possible to speed things up more by 
exploiting Kronecker-product-type structure, but this would require some 
substantial additions to lme4, I think.

I should also note that the models fitted by glmerc do _not_ allow for 
fitting parameters that scale branch lengths (e.g. Ornstein-Uhlenbeck). 
  The fundamental challenge with these models in lme4 is that lme4 is 
based on a Cholesky factor parameterization of the random effects 
covariance matrix.  To parameterize the covariance matrix on the 
covariance or branch length scale, one would need to compute a Cholesky 
factor every time the deviance function is evaluated.  This could get 
costly.  The recent methods of Ho and An? (2014) in the phylolm package 
might help here.  However, in their current form these methods only 
apply to quadratic terms involving the inverse covariance matrix and to 
the log determinant of the covariance matrix.  These computations are 
certainly important in mixed modelling in general, but unfortunately not 
_so_ much for lme4, because of the Cholesky parameterization.  However, 
I bet that their ideas could be modified to be applicable to lme4.  In 
particular I bet one could compute a series of small Cholesky 
decompositions at the tips and then iteratively rank-one update them by 
traversing the tree to the root.  My guess is that this procedure would 
scale linearly, as do the other methods of Ho and An? (2014).

Cheers,
Steve

On 2015-02-26 7:04 AM, Anthony R Ives wrote:
> Matthew,
>
> You should be able to do this in communityPGLMM in {pez}. Also, Steve
> Walker is currently working on a way to do this in lmer/glmer.
>
>
> Cheers, Tony
>
>
> On 02/26/15, Jarrod Hadfield  wrote:
>> Hi Matthew,
>>
>> Both MCMCglmm and asreml-r fit these models in R.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015
>> 16:42:32 -0700:
>>
>>> Hi all,
>>>
>>> This is a typical problem in genetics and I'm trying to figure
>>> out whether there's any way to solve it using lmer or similar,
>>> and if not, why it isn't possible.
>>>
>>> Often in genetics, we have an n-by-n matrix (n=sample size) of
>>> genetic relationships, where the diagonal is how related you are
>>> to yourself (~1, depending on inbreeding) and off-diagonals each
>>> pairwise relationship. I'd like to be able to use lmer or some
>>> other function in R to estimate the variance attributable to this
>>> genetic relationship matrix. Thus: y = b0 + b*X + g*Z + error
>>> where y is a vector of observations, b is a vector of fixed
>>> covariate effects and g is a vector of random genetic effects. X
>>> and Z are incidence matrices for b & g respectively, and we
>>> assume g ~ N(0, VG). The variance of y is therefore var(y) = Z*Z'
>>> * VG + I*var(e)
>>>
>>> Z*Z' is the observed n-by-n genetic relationship matrix. Given an
>>> observed Z*Z' genetic relationship matrix, is there a way to
>>> estimate VG?
>>>
>>> I guess this boils down to, if we have an observed n-by-n matrix
>>> of similarities, can we use mixed models in R to get the variance
>>> in y that is explained by that similarity?
>>>
>>> Thanks in advance!
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>
>> -- The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Feb 26 20:23:17 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 26 Feb 2015 20:23:17 +0100
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <20150226171747.577218rt19i0ql34@www.staffmail.ed.ac.uk>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>
	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
	<7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
	<077E31A57DA26E46AB0D493C9966AC730F065D8B12@UM-MAIL4112.unimaas.nl>
	<20150226164156.20672er6gz19a3fo@www.staffmail.ed.ac.uk>
	<077E31A57DA26E46AB0D493C9966AC730F065D8B29@UM-MAIL4112.unimaas.nl>
	<20150226171747.577218rt19i0ql34@www.staffmail.ed.ac.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F065D8B4B@UM-MAIL4112.unimaas.nl>

Interesting, thanks for the feedback. I am replying to you and cc-ing r-sig-mixed-models, as this is getting a bit off-topic.

The degree of sparseness of course depends on the application. For phylogenies, both the matrix and its inverse are equally sparse (due to the split at the root node). For pedigrees, this may be different, but I don't know enough about this. The types of applications I have been working on are phylogenetic meta-analyses, so here using sparse matrices works just fine (and in fact, we have been doing comparisons between metafor and MCMCglmm and things match up pretty nicely).

At any rate, one can use rma.mv() just fine to fit the model that Matthew was asking about. Maybe it is not the most efficient way of doing this, but I don't see how it is wrong.

Best,
Wolfgang

> -----Original Message-----
> From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
> Sent: Thursday, February 26, 2015 18:18
> To: Viechtbauer Wolfgang (STAT)
> Cc: r-sig-mixed-models at r-project.org; Matthew Keller
> Subject: RE: [R-sig-ME] estimating variance components for arbitrarily
> defined var/covar matrices
> 
> Hi Wolfgang,
> 
> The matrix itself is not necessarily sparse (although usually is) its
> the inverse that is sparse.  The pattern of sparsity is also important
> because the equations can be permuted so they are more easily solved
> (if you use something like minimum degree ordering it will probably do
> a good job automatically). In addition, the nice structure is lost if
> individuals connecting two relatives are omitted. In this situation
> (the usual case) the random effect vector is usually augmented with
> these `missing' individuals and so the matrix is of greater dimension
> than the number of observations, and the corresponding columns of the
> design matrix are set to zero. I'm not sure if metafor handles these
> sorts of issues? The issues are not difficult to solve, but often
> general-purpose packages don't accommodate them because for most
> problems its not clear why you would ever need to worry about them.
> 
> Cheers,
> 
> Jarrod
> 
> Quoting "Viechtbauer Wolfgang (STAT)"
> <wolfgang.viechtbauer at maastrichtuniversity.nl> on Thu, 26 Feb 2015
> 17:50:36 +0100:
> 
> > Good point. Using sparse matrix methods is one way of handling that.
> > Set 'sparse=TRUE' for rma.mv() to do so.
> >
> > Best,
> > Wolfgang
> >
> >> -----Original Message-----
> >> From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
> >> Sent: Thursday, February 26, 2015 17:42
> >> To: Viechtbauer Wolfgang (STAT)
> >> Cc: r-sig-mixed-models at r-project.org; Matthew Keller
> >> Subject: Re: [R-sig-ME] estimating variance components for arbitrarily
> >> defined var/covar matrices
> >>
> >> Hi,
> >>
> >> If the `genetic' matrix is pedigree derived (?) the matrix is a
> >> correlation matrix (in the absence of inbreeding) or proportional to
> >> the covariance matrix (with inbreeding). However, the matrix has a lot
> >> of structure that can be exploited by *not* treating it as just
> >> another correlation matrix. Specifically, the inverse of the matrix is
> >> all zeros, except for the diagonal elements and those that correspond
> >> to mates and/or parent-offspring. ASReml, WOMBAT, MCMCglmm, pedigreem
> >> (?) + others all exploit this structure leading to faster more robust
> >> results. For small problems this might not be an issue.
> >>
> >> Cheers,
> >>
> >> Jarrod
> >>
> >> Quoting "Viechtbauer Wolfgang (STAT)"
> >> <wolfgang.viechtbauer at maastrichtuniversity.nl> on Thu, 26 Feb 2015
> >> 17:24:39 +0100:
> >>
> >> > And just to throw another package in the mix, you can also use the
> >> > metafor package for this. While this doesn't quite sound like a
> >> > meta-analysis, in the end, meta-analysis models are just
> >> > mixed-effects models. And in a phylogenetic meta-analysis, we add
> >> > random effects with known correlations matrices to the model.
> >> >
> >> > The syntax would be:
> >> >
> >> > id.e <- 1:nrow(dat)
> >> > id.r <- 1:nrow(dat)
> >> > rma.mv(y ~ <fixed effects>, V = 0, random = list(~ 1 | id.r, ~ 1 |
> >> > id.e), R = list(id.r = GRM), data=dat)
> >> >
> >> > where 'GRM' is the n x n matrix of similarities. The V = 0 part
> >> > seems a bit strange, but in meta-analytic models, we usually don't
> >> > estimate the error variance and instead have known sampling
> >> > variances (or even a known variance-covariance matrix of the
> >> > sampling errors). Here, we don't, so we just set that part to 0
> >> > (you'll get a warning that 'V appears to be not positive definite.'
> >> > but you can safely ignore this). This will fit the model that you
> >> > specified below.
> >> >
> >> > Besides the estimates of the fixed effects, the results will include
> >> > two variance components, one for id.r (this is VG) and one for id.e
> >> > (this is sigma^2_error). The default is REML estimation (method="ML"
> >> > is you want MLEs).
> >> >
> >> > By default, rma.mv() tries to rescale the matrix supplied via the R
> >> > argument into a correlation matrix. Not sure if your matrix of
> >> > similarities is really a correlation matrix or not. In case you
> >> > don't want the function to mess with the matrix, set 'Rscale=FALSE'
> >> > and it won't touch it.
> >> >
> >> > Best,
> >> > Wolfgang
> >> >
> >> > --
> >> > Wolfgang Viechtbauer, Ph.D., Statistician
> >> > Department of Psychiatry and Psychology
> >> > School for Mental Health and Neuroscience
> >> > Faculty of Health, Medicine, and Life Sciences
> >> > Maastricht University, P.O. Box 616 (VIJV1)
> >> > 6200 MD Maastricht, The Netherlands
> >> > +31 (43) 388-4170 | http://www.wvbauer.com
> >> >
> >> >> -----Original Message-----
> >> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> >> project.org] On Behalf Of Anthony R Ives
> >> >> Sent: Thursday, February 26, 2015 13:04
> >> >> To: Jarrod Hadfield; Matthew Keller
> >> >> Cc: r-sig-mixed-models at r-project.org
> >> >> Subject: Re: [R-sig-ME] estimating variance components for
> arbitrarily
> >> >> defined var/covar matrices
> >> >>
> >> >> Matthew,
> >> >>
> >> >> You should be able to do this in communityPGLMM in {pez}. Also,
> Steve
> >> >> Walker is currently working on a way to do this in lmer/glmer.
> >> >>
> >> >> Cheers, Tony
> >> >>
> >> >>
> >> >> On 02/26/15, Jarrod Hadfield  wrote:
> >> >> > Hi Matthew,
> >> >> >
> >> >> > Both MCMCglmm and asreml-r fit these models in R.
> >> >> >
> >> >> > Cheers,
> >> >> >
> >> >> > Jarrod
> >> >> >
> >> >> > Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb
> 2015
> >> >> 16:42:32 -0700:
> >> >> >
> >> >> > >Hi all,
> >> >> > >
> >> >> > >This is a typical problem in genetics and I'm trying to figure
> out
> >> >> whether
> >> >> > >there's any way to solve it using lmer or similar, and if not,
> why
> >> it
> >> >> isn't
> >> >> > >possible.
> >> >> > >
> >> >> > >Often in genetics, we have an n-by-n matrix (n=sample size) of
> >> genetic
> >> >> > >relationships, where the diagonal is how related you are to
> >> yourself
> >> >> (~1,
> >> >> > >depending on inbreeding) and off-diagonals each pairwise
> >> relationship.
> >> >> I'd
> >> >> > >like to be able to use lmer or some other function in R to
> estimate
> >> >> the
> >> >> > >variance attributable to this genetic relationship matrix. Thus:
> >> >> > >y = b0 + b*X + g*Z + error
> >> >> > >where y is a vector of observations, b is a vector of fixed
> >> covariate
> >> >> > >effects and g is a vector of random genetic effects. X and Z are
> >> >> incidence
> >> >> > >matrices for b & g respectively, and we assume g ~ N(0, VG). The
> >> >> variance
> >> >> > >of y is therefore
> >> >> > >var(y) = Z*Z' * VG + I*var(e)
> >> >> > >
> >> >> > >Z*Z' is the observed n-by-n genetic relationship matrix. Given
> an
> >> >> observed
> >> >> > >Z*Z' genetic relationship matrix, is there a way to estimate VG?
> >> >> > >
> >> >> > >I guess this boils down to, if we have an observed n-by-n matrix
> of
> >> >> > >similarities, can we use mixed models in R to get the variance
> in y
> >> >> that is
> >> >> > >explained by that similarity?
> >> >> > >
> >> >> > >Thanks in advance!


From arives at wisc.edu  Thu Feb 26 21:46:39 2015
From: arives at wisc.edu (Anthony Ives)
Date: Thu, 26 Feb 2015 14:46:39 -0600
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <54EF6F67.5020907@utoronto.ca>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>
	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
	<7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
	<54EF6F67.5020907@utoronto.ca>
Message-ID: <1BD7660B-3874-4E20-806D-E50BA170C611@wisc.edu>

Steve,

Just a quick follow-up. Even though your work (and communityPGLMM) does not allow transformations in the covariance matrices themselves (like the OU), it does in effect perform Pagel?s lambda in the form sigma2*V + I ~= lambda*V + (1-lambda)*I.

Cheers, Tony


Anthony Ives
Department of Zoology
459 Birge Hall (4th floor, E end of bldg)
UW-Madison
Madison, WI 53706
608-262-1519

> On Feb 26, 2015, at 1:09 PM, Steve Walker <steve.walker at utoronto.ca> wrote:
> 
> Thanks Tony.  For those interested, you can check out the development of my work on phylogenetic models in lme4 here:
> 
> https://github.com/stevencarlislewalker/lme4ord
> 
> The section in the README file about phylogenetic models gives an example and briefly describes the kinds of models that can be fitted.
> 
> Regarding speed, the glmerc (with a 'c' for known covariance over grouping factor levels) function can fit models similar to the one in the README but with a 500 tip phylogeny in about 20 seconds on my pretty standard macbook pro.  lme4 uses sparse matrices for all random effect-related matrix computations, so most of the speed comes from this infrastructure.  However, it may be possible to speed things up more by exploiting Kronecker-product-type structure, but this would require some substantial additions to lme4, I think.
> 
> I should also note that the models fitted by glmerc do _not_ allow for fitting parameters that scale branch lengths (e.g. Ornstein-Uhlenbeck).  The fundamental challenge with these models in lme4 is that lme4 is based on a Cholesky factor parameterization of the random effects covariance matrix.  To parameterize the covariance matrix on the covariance or branch length scale, one would need to compute a Cholesky factor every time the deviance function is evaluated.  This could get costly.  The recent methods of Ho and An? (2014) in the phylolm package might help here.  However, in their current form these methods only apply to quadratic terms involving the inverse covariance matrix and to the log determinant of the covariance matrix.  These computations are certainly important in mixed modelling in general, but unfortunately not _so_ much for lme4, because of the Cholesky parameterization.  However, I bet that their ideas could be modified to be applicable to lme4.  In particular I bet one could compute a series of small Cholesky decompositions at the tips and then iteratively rank-one update them by traversing the tree to the root.  My guess is that this procedure would scale linearly, as do the other methods of Ho and An? (2014).
> 
> Cheers,
> Steve
> 
> On 2015-02-26 7:04 AM, Anthony R Ives wrote:
>> Matthew,
>> 
>> You should be able to do this in communityPGLMM in {pez}. Also, Steve
>> Walker is currently working on a way to do this in lmer/glmer.
>> 
>> 
>> Cheers, Tony
>> 
>> 
>> On 02/26/15, Jarrod Hadfield  wrote:
>>> Hi Matthew,
>>> 
>>> Both MCMCglmm and asreml-r fit these models in R.
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> 
>>> Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015
>>> 16:42:32 -0700:
>>> 
>>>> Hi all,
>>>> 
>>>> This is a typical problem in genetics and I'm trying to figure
>>>> out whether there's any way to solve it using lmer or similar,
>>>> and if not, why it isn't possible.
>>>> 
>>>> Often in genetics, we have an n-by-n matrix (n=sample size) of
>>>> genetic relationships, where the diagonal is how related you are
>>>> to yourself (~1, depending on inbreeding) and off-diagonals each
>>>> pairwise relationship. I'd like to be able to use lmer or some
>>>> other function in R to estimate the variance attributable to this
>>>> genetic relationship matrix. Thus: y = b0 + b*X + g*Z + error
>>>> where y is a vector of observations, b is a vector of fixed
>>>> covariate effects and g is a vector of random genetic effects. X
>>>> and Z are incidence matrices for b & g respectively, and we
>>>> assume g ~ N(0, VG). The variance of y is therefore var(y) = Z*Z'
>>>> * VG + I*var(e)
>>>> 
>>>> Z*Z' is the observed n-by-n genetic relationship matrix. Given an
>>>> observed Z*Z' genetic relationship matrix, is there a way to
>>>> estimate VG?
>>>> 
>>>> I guess this boils down to, if we have an observed n-by-n matrix
>>>> of similarities, can we use mixed models in R to get the variance
>>>> in y that is explained by that similarity?
>>>> 
>>>> Thanks in advance!
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>>> 
>>> 
>>> 
>>> 
>>> -- The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 


From r.turner at auckland.ac.nz  Thu Feb 26 22:47:56 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 27 Feb 2015 10:47:56 +1300
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <54EE98EC.6010202@gmail.com>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<54EE64DE.5030409@gmail.com> <54EE71C4.5050301@auckland.ac.nz>
	<54EE98EC.6010202@gmail.com>
Message-ID: <54EF948C.1060609@auckland.ac.nz>

On 26/02/15 16:54, Ben Bolker wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>    I thought we were assuming a fixed var-cov matrix

So Z*Z'*VG is fixed/known, rather than being estimated from the data.

That's what I didn't properly apprehend.

> PLUS an error
> variance, i.e. Sigma + s^2*I (increasing the variance and decreasing
> the correlation).
>
>    But I could be wrong about what model is intended.

No, I think that the misunderstanding was entirely mine.

Sorry for the noise.

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From mckellercran at gmail.com  Thu Feb 26 23:05:34 2015
From: mckellercran at gmail.com (Matthew Keller)
Date: Thu, 26 Feb 2015 15:05:34 -0700
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <54EF948C.1060609@auckland.ac.nz>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<54EE64DE.5030409@gmail.com> <54EE71C4.5050301@auckland.ac.nz>
	<54EE98EC.6010202@gmail.com> <54EF948C.1060609@auckland.ac.nz>
Message-ID: <CAB7vCMQ=8oYme6Mcqvev-_vg4ueyYgr27SyiSNxQeqzi-hJ0Bw@mail.gmail.com>

Hi all,

This has been wonderful to follow, thank you very much to all who have
contributed!!

Quick clarification:
Z*Z' is fixed/known. VG is unknown and would be estimated from the data.

Another issue:
The number of individuals fit in these models is often very large (e.g.,
10K - 100K) because the variance of the off-diagonals of Z*Z' is tiny. Of
the above approaches suggested, are any able to work with datasets of this
size in a 'reasonable' amount of time? E.g., < 1 day?

Best,

Matt

On Thu, Feb 26, 2015 at 2:47 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 26/02/15 16:54, Ben Bolker wrote:
>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>>    I thought we were assuming a fixed var-cov matrix
>>
>
> So Z*Z'*VG is fixed/known, rather than being estimated from the data.
>
> That's what I didn't properly apprehend.
>
>  PLUS an error
>> variance, i.e. Sigma + s^2*I (increasing the variance and decreasing
>> the correlation).
>>
>>    But I could be wrong about what model is intended.
>>
>
> No, I think that the misunderstanding was entirely mine.
>
> Sorry for the noise.
>
> cheers,
>
> Rolf
>
> --
> Rolf Turner
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> Home phone: +64-9-480-4619
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Matthew C Keller
Asst. Professor of Psychology
University of Colorado at Boulder
www.matthewckeller.com

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Thu Feb 26 23:19:54 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Fri, 27 Feb 2015 09:19:54 +1100
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <CAB7vCMQ=8oYme6Mcqvev-_vg4ueyYgr27SyiSNxQeqzi-hJ0Bw@mail.gmail.com>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<54EE64DE.5030409@gmail.com> <54EE71C4.5050301@auckland.ac.nz>
	<54EE98EC.6010202@gmail.com> <54EF948C.1060609@auckland.ac.nz>
	<CAB7vCMQ=8oYme6Mcqvev-_vg4ueyYgr27SyiSNxQeqzi-hJ0Bw@mail.gmail.com>
Message-ID: <CAF5_5cwGqBsc4Pb51ESThfwx7egZ2MoW-VyxZ6E2U=jNz1PtoQ@mail.gmail.com>

Is http://cran.r-project.org/web/packages/coxme/vignettes/lmekin.pdf useful?

On 27 February 2015 at 09:05, Matthew Keller <mckellercran at gmail.com> wrote:

> Hi all,
>
> This has been wonderful to follow, thank you very much to all who have
> contributed!!
>
> Quick clarification:
> Z*Z' is fixed/known. VG is unknown and would be estimated from the data.
>
> Another issue:
> The number of individuals fit in these models is often very large (e.g.,
> 10K - 100K) because the variance of the off-diagonals of Z*Z' is tiny. Of
> the above approaches suggested, are any able to work with datasets of this
> size in a 'reasonable' amount of time? E.g., < 1 day?
>
> Best,
>
> Matt
>
> On Thu, Feb 26, 2015 at 2:47 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
>
> > On 26/02/15 16:54, Ben Bolker wrote:
> >
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA1
> >>
> >>    I thought we were assuming a fixed var-cov matrix
> >>
> >
> > So Z*Z'*VG is fixed/known, rather than being estimated from the data.
> >
> > That's what I didn't properly apprehend.
> >
> >  PLUS an error
> >> variance, i.e. Sigma + s^2*I (increasing the variance and decreasing
> >> the correlation).
> >>
> >>    But I could be wrong about what model is intended.
> >>
> >
> > No, I think that the misunderstanding was entirely mine.
> >
> > Sorry for the noise.
> >
> > cheers,
> >
> > Rolf
> >
> > --
> > Rolf Turner
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> > Home phone: +64-9-480-4619
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
> --
> Matthew C Keller
> Asst. Professor of Psychology
> University of Colorado at Boulder
> www.matthewckeller.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From steve.walker at utoronto.ca  Thu Feb 26 23:20:53 2015
From: steve.walker at utoronto.ca (steve.walker at utoronto.ca)
Date: Thu, 26 Feb 2015 17:20:53 -0500
Subject: [R-sig-ME] estimating variance components for
	arbitrarily	defined var/covar matrices
In-Reply-To: <1BD7660B-3874-4E20-806D-E50BA170C611@wisc.edu>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<20150226070014.21325mbnowhxe800@www.staffmail.ed.ac.uk>
	<7740a68b131c0.54ef0b3e@wiscmail.wisc.edu>
	<7510b92b15aef.54eeb76d@wiscmail.wisc.edu>
	<54EF6F67.5020907@utoronto.ca>
	<1BD7660B-3874-4E20-806D-E50BA170C611@wisc.edu>
Message-ID: <20150226172053.v4x18lb2uooccg8w@webmail.utoronto.ca>

Good point Tony.  I'll add that to the README.

Cheers,
Steve

Quoting Anthony Ives <arives at wisc.edu>:

> Steve,
>
> Just a quick follow-up. Even though your work (and communityPGLMM)   
> does not allow transformations in the covariance matrices themselves  
>  (like the OU), it does in effect perform Pagel's lambda in the form  
>  sigma2*V + I ~= lambda*V + (1-lambda)*I.
>
> Cheers, Tony
>
>
> Anthony Ives
> Department of Zoology
> 459 Birge Hall (4th floor, E end of bldg)
> UW-Madison
> Madison, WI 53706
> 608-262-1519
>
>> On Feb 26, 2015, at 1:09 PM, Steve Walker <steve.walker at utoronto.ca> wrote:
>>
>> Thanks Tony.  For those interested, you can check out the   
>> development of my work on phylogenetic models in lme4 here:
>>
>> https://github.com/stevencarlislewalker/lme4ord
>>
>> The section in the README file about phylogenetic models gives an   
>> example and briefly describes the kinds of models that can be fitted.
>>
>> Regarding speed, the glmerc (with a 'c' for known covariance over   
>> grouping factor levels) function can fit models similar to the one   
>> in the README but with a 500 tip phylogeny in about 20 seconds on   
>> my pretty standard macbook pro.  lme4 uses sparse matrices for all   
>> random effect-related matrix computations, so most of the speed   
>> comes from this infrastructure.  However, it may be possible to   
>> speed things up more by exploiting Kronecker-product-type   
>> structure, but this would require some substantial additions to   
>> lme4, I think.
>>
>> I should also note that the models fitted by glmerc do _not_ allow  
>> for fitting parameters that scale branch lengths (e.g.  
>> Ornstein-Uhlenbeck).  The fundamental challenge with these models  
>> in lme4 is that lme4 is based on a Cholesky factor parameterization  
>> of the random effects covariance matrix.  To parameterize the  
>> covariance matrix on the covariance or branch length scale, one  
>> would need to compute a Cholesky factor every time the deviance  
>> function is evaluated.  This could get costly.  The recent methods  
>> of Ho and An? (2014) in the phylolm package might help here.   
>> However, in their current form these methods only apply to  
>> quadratic terms involving the inverse covariance matrix and to the  
>> log determinant of the covariance matrix.  These computations are  
>> certainly important in mixed modelling in general, but  
>> unfortunately not _so_ much for lme4, because of the Cholesky  
>> parameterization.  However, I bet that their ideas could be  
>> modified to be applicable to lme4.  In particular I
>>  bet one could compute a series of small Cholesky decompositions at  
>> the tips and then iteratively rank-one update them by traversing  
>> the tree to the root.  My guess is that this procedure would scale  
>> linearly, as do the other methods of Ho and An? (2014).
>>
>> Cheers,
>> Steve
>>
>> On 2015-02-26 7:04 AM, Anthony R Ives wrote:
>>> Matthew,
>>>
>>> You should be able to do this in communityPGLMM in {pez}. Also, Steve
>>> Walker is currently working on a way to do this in lmer/glmer.
>>>
>>>
>>> Cheers, Tony
>>>
>>>
>>> On 02/26/15, Jarrod Hadfield  wrote:
>>>> Hi Matthew,
>>>>
>>>> Both MCMCglmm and asreml-r fit these models in R.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>> Quoting Matthew Keller <mckellercran at gmail.com> on Wed, 25 Feb 2015
>>>> 16:42:32 -0700:
>>>>
>>>>> Hi all,
>>>>>
>>>>> This is a typical problem in genetics and I'm trying to figure
>>>>> out whether there's any way to solve it using lmer or similar,
>>>>> and if not, why it isn't possible.
>>>>>
>>>>> Often in genetics, we have an n-by-n matrix (n=sample size) of
>>>>> genetic relationships, where the diagonal is how related you are
>>>>> to yourself (~1, depending on inbreeding) and off-diagonals each
>>>>> pairwise relationship. I'd like to be able to use lmer or some
>>>>> other function in R to estimate the variance attributable to this
>>>>> genetic relationship matrix. Thus: y = b0 + b*X + g*Z + error
>>>>> where y is a vector of observations, b is a vector of fixed
>>>>> covariate effects and g is a vector of random genetic effects. X
>>>>> and Z are incidence matrices for b & g respectively, and we
>>>>> assume g ~ N(0, VG). The variance of y is therefore var(y) = Z*Z'
>>>>> * VG + I*var(e)
>>>>>
>>>>> Z*Z' is the observed n-by-n genetic relationship matrix. Given an
>>>>> observed Z*Z' genetic relationship matrix, is there a way to
>>>>> estimate VG?
>>>>>
>>>>> I guess this boils down to, if we have an observed n-by-n matrix
>>>>> of similarities, can we use mixed models in R to get the variance
>>>>> in y that is explained by that similarity?
>>>>>
>>>>> Thanks in advance!
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>> -- The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>
>


From ken.beath at mq.edu.au  Thu Feb 26 23:40:41 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Fri, 27 Feb 2015 09:40:41 +1100
Subject: [R-sig-ME] Problem- Warning message
In-Reply-To: <CABa6ee0msQrE5uztANxWuXUtwfnTaKCycoCX5ZUYDUu+H3e92A@mail.gmail.com>
References: <CABa6ee0msQrE5uztANxWuXUtwfnTaKCycoCX5ZUYDUu+H3e92A@mail.gmail.com>
Message-ID: <CAF5_5czw04yk+u-rEr9w-dernpcSEzuoEHQUZzedYxU1mYbuBg@mail.gmail.com>

There are two random effects, another one for obs which is modelling
overdispersion.

It looks like the optimizer has decided to stop, but has stopped when the
gradients are not zero, that is it is not a maxima. It could just be the
numerical gradients are a problem, but it could be something else. I've
been having similar trouble with a glmm, and it seems to be a problem with
the way glmer does something.

I don't know how much data that you have, but it is possible that your
model is just too complex for the data available. The first rule of these
models is to start with something simple and then add to the model until
something breaks, then you can think about why it broke.

On 27 February 2015 at 04:14, Davide Bellone <bellonedavide1 at gmail.com>
wrote:

> Goodevening,
>
> this is my first mail . From what a collegue told me I can ask to the
> members of this mailing list to help me with my problem.
> So, what I am trying to do is a glmer model. I have 1 random effect (Site)
> and 6 fixed effects.
>
> Model <- read.table("c:\\TXT X R\\Tabella modello gruppi
> completo.txt",header=T)
> y <- cbind(Model$Rem, Model$Total-Model$Rem)
> Model$wood <- as.factor(Model$wood)
> Model$under <- as.factor(Model$under)
> Model$Manage <- as.factor(Model$Manage)
> Model$Size <- as.factor(Model$Size)
> Model$Site <- as.factor(Model$Site)
> obs <- 1:length(Model$Site)
> obs
> options(contrasts=c("contr.sum", "contr.poly"))
> R1 <- glmer(y ~ Model$Manage + Model$age +  Model$veg + Model$Size +
> Model$wood + Model$under + Model$age*Model$Manage + Model$veg*Model$Manage
> + (1|Model$Site)+(1|obs) , family= binomial)
>
> The first output is:
> Warning message:
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 1.02046 (tol = 0.001, component
> 3)
>
> Can someone explain if there is some problem in data and if there is a
> solution?
>
> Thank you. I hope that my collegue told me the right way to how to use the
> mailing list
>
> D?vide
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bmdixon at ucdavis.edu  Fri Feb 27 03:30:41 2015
From: bmdixon at ucdavis.edu (Bonnie Dixon)
Date: Thu, 26 Feb 2015 18:30:41 -0800
Subject: [R-sig-ME] Best way to handle missing data?
Message-ID: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>

Dear list;

I am using nlme to create a repeated measures (i.e. 2 level) model.  There
is missing data in several of the predictor variables.  What is the best
way to handle this situation?  The variable with (by far) the most missing
data is the best predictor in the model, so I would not want to remove it.
I am also trying to avoid omitting the observations with missing data,
because that would require omitting almost 40% of the observations and
would result in a substantial loss of power.

A member of my dissertation committee who uses SAS, recommended that I use
full information maximum likelihood estimation (FIML) (described here:
http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf),
which is the easiest way to handle missing data in SAS.  Is there an
equivalent procedure in R?

Alternatively, I have tried several approaches to multiple imputation.  For
example, I used the package, Amelia, which appears to handle the clustered
structure of the data appropriately, to generate five imputed versions of
the data set, and then used lapply to run my model on each.  But I am not
sure how to combine the resulting five models into one final result.  I
will need a final result that enables me to report, not just the fixed
effects of the model, but also the random effects variance components and,
ideally, the distributions across the population of the random intercept
and slopes, and correlations between them.

Many thanks for any suggestions on how to proceed.

Bonnie

	[[alternative HTML version deleted]]


From mmalten at gmail.com  Fri Feb 27 05:33:06 2015
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Thu, 26 Feb 2015 23:33:06 -0500
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
Message-ID: <CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>

Mice might be the package you need

On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:

> Dear list;
>
> I am using nlme to create a repeated measures (i.e. 2 level) model.  There
> is missing data in several of the predictor variables.  What is the best
> way to handle this situation?  The variable with (by far) the most missing
> data is the best predictor in the model, so I would not want to remove it.
> I am also trying to avoid omitting the observations with missing data,
> because that would require omitting almost 40% of the observations and
> would result in a substantial loss of power.
>
> A member of my dissertation committee who uses SAS, recommended that I use
> full information maximum likelihood estimation (FIML) (described here:
> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
> ),
> which is the easiest way to handle missing data in SAS.  Is there an
> equivalent procedure in R?
>
> Alternatively, I have tried several approaches to multiple imputation.  For
> example, I used the package, Amelia, which appears to handle the clustered
> structure of the data appropriately, to generate five imputed versions of
> the data set, and then used lapply to run my model on each.  But I am not
> sure how to combine the resulting five models into one final result.  I
> will need a final result that enables me to report, not just the fixed
> effects of the model, but also the random effects variance components and,
> ideally, the distributions across the population of the random intercept
> and slopes, and correlations between them.
>
> Many thanks for any suggestions on how to proceed.
>
> Bonnie
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
____________________________
Ersatzistician and Chutzpahthologist

I can answer any question.  "I don't know" is an answer. "I don't know yet"
is a better answer.

"I can write better than anybody who can write faster, and I can write
faster than anybody who can write better" AJ Liebling

	[[alternative HTML version deleted]]


From bmdixon at ucdavis.edu  Fri Feb 27 06:20:33 2015
From: bmdixon at ucdavis.edu (Bonnie Dixon)
Date: Thu, 26 Feb 2015 21:20:33 -0800
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
Message-ID: <CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>

I actually did try mice also (method "2l.norm"), but it seemed that Amelia
was preferable for imputation.  Mice seems to only be able to impute one
variable, whereas Amelia can impute as many variables as have missing data
producing 100% complete data sets as output.

However, most of the missing data in the data set I am working with is in
just one variable, so I could consider using mice, and just imputing the
variable that has the most missing data, while omitting observations that
have missing data in any of the other variables.  But the pooled results
from mice only seem to include the fixed effects of the model, so this
still leaves me wondering how to report the random effects, which are very
important to my research question.

When using Amelia to impute, the packages Zelig and ZeligMultilevel can be
used to combine the results from each of the models.  But again, only the
fixed effects seem to be included in the output, so I am not sure how to
report on the random effects.

Bonnie

On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <mmalten at gmail.com>
wrote:

> Mice might be the package you need
>
>
> On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:
>
>> Dear list;
>>
>> I am using nlme to create a repeated measures (i.e. 2 level) model.  There
>> is missing data in several of the predictor variables.  What is the best
>> way to handle this situation?  The variable with (by far) the most missing
>> data is the best predictor in the model, so I would not want to remove it.
>> I am also trying to avoid omitting the observations with missing data,
>> because that would require omitting almost 40% of the observations and
>> would result in a substantial loss of power.
>>
>> A member of my dissertation committee who uses SAS, recommended that I use
>> full information maximum likelihood estimation (FIML) (described here:
>> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
>> ),
>> which is the easiest way to handle missing data in SAS.  Is there an
>> equivalent procedure in R?
>>
>> Alternatively, I have tried several approaches to multiple imputation.
>> For
>> example, I used the package, Amelia, which appears to handle the clustered
>> structure of the data appropriately, to generate five imputed versions of
>> the data set, and then used lapply to run my model on each.  But I am not
>> sure how to combine the resulting five models into one final result.  I
>> will need a final result that enables me to report, not just the fixed
>> effects of the model, but also the random effects variance components and,
>> ideally, the distributions across the population of the random intercept
>> and slopes, and correlations between them.
>>
>> Many thanks for any suggestions on how to proceed.
>>
>> Bonnie
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> ____________________________
> Ersatzistician and Chutzpahthologist
>
> I can answer any question.  "I don't know" is an answer. "I don't know
> yet" is a better answer.
>
> "I can write better than anybody who can write faster, and I can write
> faster than anybody who can write better" AJ Liebling
>
>

	[[alternative HTML version deleted]]


From ljrhurley at gmail.com  Fri Feb 27 06:36:22 2015
From: ljrhurley at gmail.com (landon hurley)
Date: Fri, 27 Feb 2015 00:36:22 -0500
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
Message-ID: <54F00256.9010002@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 02/26/2015 09:30 PM, Bonnie Dixon wrote:
> Dear list;
> 
> A member of my dissertation committee who uses SAS, recommended that I use
> full information maximum likelihood estimation (FIML) (described here:
> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf),
> which is the easiest way to handle missing data in SAS.  Is there an
> equivalent procedure in R?

If you are interested in having maximum likelihood methods, you can use
either ml or reml, specified with the method flag for the nlme command.
However, ml is the default method for estimating parameters for nlme,
and you shouldn't need to do anything at all, outside specify the model.
- From your email, it seems that you are saying that the number of
observations/groups is not reporting the number that you are expecting
there to be though. Is that correct? This is assuming you are content
with the multivariate normal assumption, and are not trying to analyse
discrete outcomes.

> I actually did try mice also (method "2l.norm"), but it seemed that Amelia
> was preferable for imputation.  Mice seems to only be able to impute one
> variable, whereas Amelia can impute as many variables as have missing data
> producing 100% complete data sets as output.

Mice will impute the entire dataset. Off hand, I believe the syntax
would look something like mice(data, m= , method= , maxit= ), where m is
the number of independent datasets being imputed (generally you want
25+), maxit being at least 10, and the method being a vector of
character indications of how you want to impute each of the variables,
in the same order that the appear if you use the command names(data). If
you specified 2l.norm, it should have attempted to impute all the
variables using that method, which may not have worked. What mice does
is impute each marginal variable, using the other variables to predict
the true value, done the number of times (random draws using Gibbs
sampling) within each imputation that is specified with the maxit flag,
for m times.

Again, nlme is by default using maximum likelihood though --you
shouldn't need to change anything, as long as you are content with the
MVN and missing at random assumptions for your data.

landon

- -- 
Violence is the last refuge of the incompetent.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQIcBAEBCgAGBQJU8AJWAAoJEDeph/0fVJWsJ58P/R06GjLjjdaRTJPTT3/6d4xr
EkcQmW1+bH8NZkSBlUzYk/CVmZ/EGK71KIjcdSTzDusAyh9neyXvh5zQiPU287Tl
VRQlOtbLlgoW0rE+x0uFd6PLwsCQRkck2upSU4sCyEpq+/ZSkGUTuE2VsUVCu27y
z4Ecl9sw+s93IpJGj91b9PjdH8g8RysZR7CH/FCfvpzXrRalFTtC75oP8VXEdMWp
rYTqh2/sCds29x/qbS1oxrlWSN0/NuYeTgBE+uCYZ4QxTmQO8JmJA9Sn0k5kKbjU
l1RiZhd48vUj6BFpKCw6HDn1jBVeURXVPlUOBXCFDg13vJBhYdnZAR/nRGQe3dqG
leA/+Ajyyu+fHxlN7T73Nk7nYSM2YfVYJcBT+ALtqf2XWXaHti5rQMi0YaaEI3TN
tTzAEDTjYbt0WCJ4er+pXCcZIVBUoepFH708XFL8LNZ95E/qmsKTTydN+PPmjzIJ
OpGOjDx1Xk0Xc8rKGhAJ/hJbDd7bqmaqrkfa2ydxSd20IPlGMPlx3Fk+2K2l+JyF
qYI7Y3+qGd0YSOGacg+uwEGt6KSEvWsbrx2Vfreifi0p1H4koSySqccaCBvDhVKu
0BBPoG7ErZ0bTpDWQrAChtPAb2jYEbBLCtdKqKezNHFw5/tNEKQFAUvVSu0OByeY
4IG8phi2yApsZ4yEdt/v
=DiLG
-----END PGP SIGNATURE-----


From ken.beath at mq.edu.au  Fri Feb 27 07:02:58 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Fri, 27 Feb 2015 17:02:58 +1100
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
Message-ID: <CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>

mice will impute the complete dataset, it just needs to have an imputation
method setup for each variable. See the example given in the help for
mice.impute.2lonly.norm

Full information maximum likelihood estimation (FIML) (Note for Landon,
this is ML taking into account the missing data) is only feasible if you
can reformulate everything as a structural equation model and use software
that can cope with this. Otherwise working with the integrals is pretty
much impossible. If there is something in the model that is nonlinear it
probably isn't an option at all. One of the great things about multiple
imputation is that you get it running with say 20 imputations and then run
it overnight with 200 or more and it probably won't change but you will
know that you have enough imputations. So FIML doesn't have an advantage in
that respect.



On 27 February 2015 at 16:20, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:

> I actually did try mice also (method "2l.norm"), but it seemed that Amelia
> was preferable for imputation.  Mice seems to only be able to impute one
> variable, whereas Amelia can impute as many variables as have missing data
> producing 100% complete data sets as output.
>
> However, most of the missing data in the data set I am working with is in
> just one variable, so I could consider using mice, and just imputing the
> variable that has the most missing data, while omitting observations that
> have missing data in any of the other variables.  But the pooled results
> from mice only seem to include the fixed effects of the model, so this
> still leaves me wondering how to report the random effects, which are very
> important to my research question.
>
> When using Amelia to impute, the packages Zelig and ZeligMultilevel can be
> used to combine the results from each of the models.  But again, only the
> fixed effects seem to be included in the output, so I am not sure how to
> report on the random effects.
>
> Bonnie
>
> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <mmalten at gmail.com>
> wrote:
>
> > Mice might be the package you need
> >
> >
> > On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
> wrote:
> >
> >> Dear list;
> >>
> >> I am using nlme to create a repeated measures (i.e. 2 level) model.
> There
> >> is missing data in several of the predictor variables.  What is the best
> >> way to handle this situation?  The variable with (by far) the most
> missing
> >> data is the best predictor in the model, so I would not want to remove
> it.
> >> I am also trying to avoid omitting the observations with missing data,
> >> because that would require omitting almost 40% of the observations and
> >> would result in a substantial loss of power.
> >>
> >> A member of my dissertation committee who uses SAS, recommended that I
> use
> >> full information maximum likelihood estimation (FIML) (described here:
> >>
> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
> >> ),
> >> which is the easiest way to handle missing data in SAS.  Is there an
> >> equivalent procedure in R?
> >>
> >> Alternatively, I have tried several approaches to multiple imputation.
> >> For
> >> example, I used the package, Amelia, which appears to handle the
> clustered
> >> structure of the data appropriately, to generate five imputed versions
> of
> >> the data set, and then used lapply to run my model on each.  But I am
> not
> >> sure how to combine the resulting five models into one final result.  I
> >> will need a final result that enables me to report, not just the fixed
> >> effects of the model, but also the random effects variance components
> and,
> >> ideally, the distributions across the population of the random intercept
> >> and slopes, and correlations between them.
> >>
> >> Many thanks for any suggestions on how to proceed.
> >>
> >> Bonnie
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> > --
> > ____________________________
> > Ersatzistician and Chutzpahthologist
> >
> > I can answer any question.  "I don't know" is an answer. "I don't know
> > yet" is a better answer.
> >
> > "I can write better than anybody who can write faster, and I can write
> > faster than anybody who can write better" AJ Liebling
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From ljrhurley at gmail.com  Fri Feb 27 07:27:12 2015
From: ljrhurley at gmail.com (landon hurley)
Date: Fri, 27 Feb 2015 01:27:12 -0500
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
	<CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
Message-ID: <54F00E40.7000002@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 02/27/2015 01:02 AM, Ken Beath wrote:
> mice will impute the complete dataset, it just needs to have an imputation
> method setup for each variable. See the example given in the help for
> mice.impute.2lonly.norm
> 
> Full information maximum likelihood estimation (FIML) (Note for Landon,
> this is ML taking into account the missing data) is only feasible if you
> can reformulate everything as a structural equation model and use software
> that can cope with this. Otherwise working with the integrals is pretty
> much impossible. If there is something in the model that is nonlinear it
> probably isn't an option at all. One of the great things about multiple
> imputation is that you get it running with say 20 imputations and then run
> it overnight with 200 or more and it probably won't change but you will
> know that you have enough imputations. So FIML doesn't have an advantage in
> that respect.
> 

I'm not sure that's needed as a distinction. This quote from the 	r-help
mailing list [0]  addresses it:

> I'm not sure you are correct on this. Other texts on multilevel models
> (e.g., Raudenbush and Bryk, Kreft and Deeuw, and Singer & Willett) all
> use FiML as a synonym for ML. In fact, Kreft and Deleeuw go as far to
> even state they are the same thing (see page 131).
> 
> When you run a model in HLM selecting "Full Maximum Likelihood" and
> method="ML" in lme, the results, including all fixed effects, variance
> components, empirical bayes residuals, degrees of freedom are exactly
> the same.
> 
> So, I think Doug [Bates] is correct in that ML == FiML. 
> 
> Harold

So maybe a semantics difference. However, with respect to the handling
of the integral: if it's problematic, that should result in a
non-convergence problem, or different results reported when he reruns
the model, in terms of diagnostics.

[0]https://stat.ethz.ch/pipermail/r-help/2004-August/056723.html

> 
> 
> On 27 February 2015 at 16:20, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:
> 
>> I actually did try mice also (method "2l.norm"), but it seemed that Amelia
>> was preferable for imputation.  Mice seems to only be able to impute one
>> variable, whereas Amelia can impute as many variables as have missing data
>> producing 100% complete data sets as output.
>>
>> However, most of the missing data in the data set I am working with is in
>> just one variable, so I could consider using mice, and just imputing the
>> variable that has the most missing data, while omitting observations that
>> have missing data in any of the other variables.  But the pooled results
>> from mice only seem to include the fixed effects of the model, so this
>> still leaves me wondering how to report the random effects, which are very
>> important to my research question.
>>
>> When using Amelia to impute, the packages Zelig and ZeligMultilevel can be
>> used to combine the results from each of the models.  But again, only the
>> fixed effects seem to be included in the output, so I am not sure how to
>> report on the random effects.
>>
>> Bonnie
>>
>> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <mmalten at gmail.com>
>> wrote:
>>
>>> Mice might be the package you need
>>>
>>>
>>> On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
>> wrote:
>>>
>>>> Dear list;
>>>>
>>>> I am using nlme to create a repeated measures (i.e. 2 level) model.
>> There
>>>> is missing data in several of the predictor variables.  What is the best
>>>> way to handle this situation?  The variable with (by far) the most
>> missing
>>>> data is the best predictor in the model, so I would not want to remove
>> it.
>>>> I am also trying to avoid omitting the observations with missing data,
>>>> because that would require omitting almost 40% of the observations and
>>>> would result in a substantial loss of power.
>>>>
>>>> A member of my dissertation committee who uses SAS, recommended that I
>> use
>>>> full information maximum likelihood estimation (FIML) (described here:
>>>>
>> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
>>>> ),
>>>> which is the easiest way to handle missing data in SAS.  Is there an
>>>> equivalent procedure in R?
>>>>
>>>> Alternatively, I have tried several approaches to multiple imputation.
>>>> For
>>>> example, I used the package, Amelia, which appears to handle the
>> clustered
>>>> structure of the data appropriately, to generate five imputed versions
>> of
>>>> the data set, and then used lapply to run my model on each.  But I am
>> not
>>>> sure how to combine the resulting five models into one final result.  I
>>>> will need a final result that enables me to report, not just the fixed
>>>> effects of the model, but also the random effects variance components
>> and,
>>>> ideally, the distributions across the population of the random intercept
>>>> and slopes, and correlations between them.
>>>>
>>>> Many thanks for any suggestions on how to proceed.
>>>>
>>>> Bonnie
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>> ____________________________
>>> Ersatzistician and Chutzpahthologist
>>>
>>> I can answer any question.  "I don't know" is an answer. "I don't know
>>> yet" is a better answer.
>>>
>>> "I can write better than anybody who can write faster, and I can write
>>> faster than anybody who can write better" AJ Liebling
>>>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 
> 


- -- 
Violence is the last refuge of the incompetent.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQIcBAEBCgAGBQJU8A5AAAoJEDeph/0fVJWsbNUP/invP0QBC1qS0sWfKrnRVM09
kV1fv4Y8rVflFnS+znsbAPDJOK+5YnvITmfoVLMdwTAWaUEyugKZVGDydY+fTDfg
GxokxDpNAdGlfDBg+asw49VOFoTFtBKai0PWKyw4zHrAHYS9rzTqeO2CVq1Qlb8G
F7je9naYr+iwcEkIWQZ2JloBH8OPw80UueWqNjQ0totVRN8ehYgsu2+iyyudTQnH
Sl7LWkg6QnDYYVKrlV9ygd6z9yOymU9f5w52px1cUIY0mBoT12fYturEfyi/aIxF
+3nBjRCE14C2c9y6mW2Lab9AYpR8bbzsmTK6y7PXid6/VxcqkZlE6Qsj4bD4zvK3
lkIdFj8BR2LdzJNI1EdM8LREA82VPrkS5LFf/4ige0pSo6X3aVoInC2ohLKGSdr5
r66Nh3tLu1a6kPtPBNw7YAxzkzRd2CKy9OTvOpz5wRqlXNvzOoq2Is7Hpoeva0yB
3hvAAgmJUtq8ZbTEXLQiDl2w/qeO+8o5KRfm/2uutN8z29S768me/6bfnvLELw9w
y2R4vwOGdpp+3XBAfs8sF5bMGVvTEzZj/ILph5D7OFRJi/pfCbntnf2mAFrllvlt
KUh+Okd0bO5dC2gfLuu42J3jQnCTMez/ghrEVlXkRX9XMnMz3JB7r4pdgmUqXHYu
w9eXfCoXza9efwhgHF1q
=LMV6
-----END PGP SIGNATURE-----


From j.hadfield at ed.ac.uk  Fri Feb 27 07:34:34 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 27 Feb 2015 06:34:34 +0000
Subject: [R-sig-ME] estimating variance components for arbitrarily
 defined var/covar matrices
In-Reply-To: <CAB7vCMQ=8oYme6Mcqvev-_vg4ueyYgr27SyiSNxQeqzi-hJ0Bw@mail.gmail.com>
References: <CAB7vCMTooeiEp4kt2zKGHAY1AkVQNo=PSAaPY+4T6Vs=_=v9Dw@mail.gmail.com>
	<54EE64DE.5030409@gmail.com> <54EE71C4.5050301@auckland.ac.nz>
	<54EE98EC.6010202@gmail.com> <54EF948C.1060609@auckland.ac.nz>
	<CAB7vCMQ=8oYme6Mcqvev-_vg4ueyYgr27SyiSNxQeqzi-hJ0Bw@mail.gmail.com>
Message-ID: <20150227063434.546353cx2fn9dekg@www.staffmail.ed.ac.uk>

Hi Matthew,

It depends a bit on the pedigree (is it a pedigree or derived from  
markers?) 10K - 100K would take a few seconds to a few minutes in  
asreml, but it is often not very good with non-Guassian data. MCMCglmm  
(being MCMC based) would probably take half an hour to a half a day  
for pedigrees of this size. In both cases it depends on pedigree  
structure - big marriage chains can slow it down dramatically. WOMBAT  
(which I've never used) is probably comparable to asreml in speed. If  
G is derived from markers something like GCTA will perform better, but  
this is slow because G is completely dense.

Cheers,

Jarrod











Quoting Matthew Keller <mckellercran at gmail.com> on Thu, 26 Feb 2015  
15:05:34 -0700:

> Hi all,
>
> This has been wonderful to follow, thank you very much to all who have
> contributed!!
>
> Quick clarification:
> Z*Z' is fixed/known. VG is unknown and would be estimated from the data.
>
> Another issue:
> The number of individuals fit in these models is often very large (e.g.,
> 10K - 100K) because the variance of the off-diagonals of Z*Z' is tiny. Of
> the above approaches suggested, are any able to work with datasets of this
> size in a 'reasonable' amount of time? E.g., < 1 day?
>
> Best,
>
> Matt
>
> On Thu, Feb 26, 2015 at 2:47 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
>
>> On 26/02/15 16:54, Ben Bolker wrote:
>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>>    I thought we were assuming a fixed var-cov matrix
>>>
>>
>> So Z*Z'*VG is fixed/known, rather than being estimated from the data.
>>
>> That's what I didn't properly apprehend.
>>
>>  PLUS an error
>>> variance, i.e. Sigma + s^2*I (increasing the variance and decreasing
>>> the correlation).
>>>
>>>    But I could be wrong about what model is intended.
>>>
>>
>> No, I think that the misunderstanding was entirely mine.
>>
>> Sorry for the noise.
>>
>> cheers,
>>
>> Rolf
>>
>> --
>> Rolf Turner
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> Home phone: +64-9-480-4619
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Matthew C Keller
> Asst. Professor of Psychology
> University of Colorado at Boulder
> www.matthewckeller.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ken.beath at mq.edu.au  Fri Feb 27 08:26:48 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Fri, 27 Feb 2015 18:26:48 +1100
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <54F00E40.7000002@gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
	<CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
	<54F00E40.7000002@gmail.com>
Message-ID: <CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com>

>From the same posting

>*From: Chris Lawrence <chris at lordsutch.com <https://stat.ethz.ch/mailman/listinfo/r-help>>*

<snip>

>*I have seen FIML used to refer to a type of ML estimation where a
*>*missing data treatment is included in the estimation procedure
*>*(parameter estimates are derived from incomplete cases for only the
*>*variables present in the case, rather than simply discarding the
*>*cases), at least in the latent-variable SEM context, specifically in
*>*AMOS.  This may be what Francisco is getting at.
*>>*To my knowledge, no R packages implement this sort of "FIML", for any
*>*class of models, although there are other available missing data
*>*treatments (EM, MCMC estimation). *

*This is what is correctly referred to as FIML. Your original post claimed
that FIML was available through the ML option which is incorrect, and will
not fix missing values except in the dependent variable. The fact that some
software may claim that it does something that it doesn't will not change
this. What could be said is that FIML is simply ML done correctly in that
it builds the proper model for the data, rather than ignoring the
observations with missing data, so both are maximum likelihood. *

On 27 February 2015 at 17:27, landon hurley <ljrhurley at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
>
> On 02/27/2015 01:02 AM, Ken Beath wrote:
> > mice will impute the complete dataset, it just needs to have an
> imputation
> > method setup for each variable. See the example given in the help for
> > mice.impute.2lonly.norm
> >
> > Full information maximum likelihood estimation (FIML) (Note for Landon,
> > this is ML taking into account the missing data) is only feasible if you
> > can reformulate everything as a structural equation model and use
> software
> > that can cope with this. Otherwise working with the integrals is pretty
> > much impossible. If there is something in the model that is nonlinear it
> > probably isn't an option at all. One of the great things about multiple
> > imputation is that you get it running with say 20 imputations and then
> run
> > it overnight with 200 or more and it probably won't change but you will
> > know that you have enough imputations. So FIML doesn't have an advantage
> in
> > that respect.
> >
>
> I'm not sure that's needed as a distinction. This quote from the
> r-help
> mailing list [0]  addresses it:
>
> > I'm not sure you are correct on this. Other texts on multilevel models
> > (e.g., Raudenbush and Bryk, Kreft and Deeuw, and Singer & Willett) all
> > use FiML as a synonym for ML. In fact, Kreft and Deleeuw go as far to
> > even state they are the same thing (see page 131).
> >
> > When you run a model in HLM selecting "Full Maximum Likelihood" and
> > method="ML" in lme, the results, including all fixed effects, variance
> > components, empirical bayes residuals, degrees of freedom are exactly
> > the same.
> >
> > So, I think Doug [Bates] is correct in that ML == FiML.
> >
> > Harold
>
> So maybe a semantics difference. However, with respect to the handling
> of the integral: if it's problematic, that should result in a
> non-convergence problem, or different results reported when he reruns
> the model, in terms of diagnostics.
>
> [0]https://stat.ethz.ch/pipermail/r-help/2004-August/056723.html
>
> >
> >
> > On 27 February 2015 at 16:20, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:
> >
> >> I actually did try mice also (method "2l.norm"), but it seemed that
> Amelia
> >> was preferable for imputation.  Mice seems to only be able to impute one
> >> variable, whereas Amelia can impute as many variables as have missing
> data
> >> producing 100% complete data sets as output.
> >>
> >> However, most of the missing data in the data set I am working with is
> in
> >> just one variable, so I could consider using mice, and just imputing the
> >> variable that has the most missing data, while omitting observations
> that
> >> have missing data in any of the other variables.  But the pooled results
> >> from mice only seem to include the fixed effects of the model, so this
> >> still leaves me wondering how to report the random effects, which are
> very
> >> important to my research question.
> >>
> >> When using Amelia to impute, the packages Zelig and ZeligMultilevel can
> be
> >> used to combine the results from each of the models.  But again, only
> the
> >> fixed effects seem to be included in the output, so I am not sure how to
> >> report on the random effects.
> >>
> >> Bonnie
> >>
> >> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <mmalten at gmail.com
> >
> >> wrote:
> >>
> >>> Mice might be the package you need
> >>>
> >>>
> >>> On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
> >> wrote:
> >>>
> >>>> Dear list;
> >>>>
> >>>> I am using nlme to create a repeated measures (i.e. 2 level) model.
> >> There
> >>>> is missing data in several of the predictor variables.  What is the
> best
> >>>> way to handle this situation?  The variable with (by far) the most
> >> missing
> >>>> data is the best predictor in the model, so I would not want to remove
> >> it.
> >>>> I am also trying to avoid omitting the observations with missing data,
> >>>> because that would require omitting almost 40% of the observations and
> >>>> would result in a substantial loss of power.
> >>>>
> >>>> A member of my dissertation committee who uses SAS, recommended that I
> >> use
> >>>> full information maximum likelihood estimation (FIML) (described here:
> >>>>
> >>
> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
> >>>> ),
> >>>> which is the easiest way to handle missing data in SAS.  Is there an
> >>>> equivalent procedure in R?
> >>>>
> >>>> Alternatively, I have tried several approaches to multiple imputation.
> >>>> For
> >>>> example, I used the package, Amelia, which appears to handle the
> >> clustered
> >>>> structure of the data appropriately, to generate five imputed versions
> >> of
> >>>> the data set, and then used lapply to run my model on each.  But I am
> >> not
> >>>> sure how to combine the resulting five models into one final result.
> I
> >>>> will need a final result that enables me to report, not just the fixed
> >>>> effects of the model, but also the random effects variance components
> >> and,
> >>>> ideally, the distributions across the population of the random
> intercept
> >>>> and slopes, and correlations between them.
> >>>>
> >>>> Many thanks for any suggestions on how to proceed.
> >>>>
> >>>> Bonnie
> >>>>
> >>>>         [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>>
> >>> --
> >>> ____________________________
> >>> Ersatzistician and Chutzpahthologist
> >>>
> >>> I can answer any question.  "I don't know" is an answer. "I don't know
> >>> yet" is a better answer.
> >>>
> >>> "I can write better than anybody who can write faster, and I can write
> >>> faster than anybody who can write better" AJ Liebling
> >>>
> >>>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> >
>
>
> - --
> Violence is the last refuge of the incompetent.
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQIcBAEBCgAGBQJU8A5AAAoJEDeph/0fVJWsbNUP/invP0QBC1qS0sWfKrnRVM09
> kV1fv4Y8rVflFnS+znsbAPDJOK+5YnvITmfoVLMdwTAWaUEyugKZVGDydY+fTDfg
> GxokxDpNAdGlfDBg+asw49VOFoTFtBKai0PWKyw4zHrAHYS9rzTqeO2CVq1Qlb8G
> F7je9naYr+iwcEkIWQZ2JloBH8OPw80UueWqNjQ0totVRN8ehYgsu2+iyyudTQnH
> Sl7LWkg6QnDYYVKrlV9ygd6z9yOymU9f5w52px1cUIY0mBoT12fYturEfyi/aIxF
> +3nBjRCE14C2c9y6mW2Lab9AYpR8bbzsmTK6y7PXid6/VxcqkZlE6Qsj4bD4zvK3
> lkIdFj8BR2LdzJNI1EdM8LREA82VPrkS5LFf/4ige0pSo6X3aVoInC2ohLKGSdr5
> r66Nh3tLu1a6kPtPBNw7YAxzkzRd2CKy9OTvOpz5wRqlXNvzOoq2Is7Hpoeva0yB
> 3hvAAgmJUtq8ZbTEXLQiDl2w/qeO+8o5KRfm/2uutN8z29S768me/6bfnvLELw9w
> y2R4vwOGdpp+3XBAfs8sF5bMGVvTEzZj/ILph5D7OFRJi/pfCbntnf2mAFrllvlt
> KUh+Okd0bO5dC2gfLuu42J3jQnCTMez/ghrEVlXkRX9XMnMz3JB7r4pdgmUqXHYu
> w9eXfCoXza9efwhgHF1q
> =LMV6
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From M.Fairbrother at bristol.ac.uk  Fri Feb 27 13:47:24 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 27 Feb 2015 13:47:24 +0100
Subject: [R-sig-ME] Best way to handle missing data?
Message-ID: <CAAH-yP-UP0h7K6C-BZiggnP87orqaiNfopawyfiVncXYF_yZnQ@mail.gmail.com>

Hi Bonnie,

I have not seen a formal treatment of this issue, but from the Amelia
documentation, my understanding is that if you want an estimate of the
random effects variance, you can just take the average of the estimates
from the model fitted to each imputed dataset. This is true for any
parameter, from the sounds of what Honaker, King, and Blackwell have
written.

 "you can combine directly and use as the multiple imputation estimate of
this parameter, q ?, the average of them separate estimates"

Even if Zelig doesn't report the RE variance estimates automatically, they
must be "in there" somewhere... I'm sure you can extract them. Or maybe
skip Zelig, and just use Amelia, and extract the estimated RE variances
from each fitted model (presumably using lme4)?

Cheers,
Malcolm


Date: Thu, 26 Feb 2015 21:20:33 -0800
> From: Bonnie Dixon <bmdixon at ucdavis.edu>
> To: Mitchell Maltenfort <mmalten at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Best way to handle missing data?
>
> I actually did try mice also (method "2l.norm"), but it seemed that Amelia
> was preferable for imputation.  Mice seems to only be able to impute one
> variable, whereas Amelia can impute as many variables as have missing data
> producing 100% complete data sets as output.
>
> However, most of the missing data in the data set I am working with is in
> just one variable, so I could consider using mice, and just imputing the
> variable that has the most missing data, while omitting observations that
> have missing data in any of the other variables.  But the pooled results
> from mice only seem to include the fixed effects of the model, so this
> still leaves me wondering how to report the random effects, which are very
> important to my research question.
>
> When using Amelia to impute, the packages Zelig and ZeligMultilevel can be
> used to combine the results from each of the models.  But again, only the
> fixed effects seem to be included in the output, so I am not sure how to
> report on the random effects.
>
> Bonnie
>
> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <mmalten at gmail.com>
> wrote:
>
> > Mice might be the package you need
> >
> >
> > On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
> wrote:
> >
> >> Dear list;
> >>
> >> I am using nlme to create a repeated measures (i.e. 2 level) model.
> There
> >> is missing data in several of the predictor variables.  What is the best
> >> way to handle this situation?  The variable with (by far) the most
> missing
> >> data is the best predictor in the model, so I would not want to remove
> it.
> >> I am also trying to avoid omitting the observations with missing data,
> >> because that would require omitting almost 40% of the observations and
> >> would result in a substantial loss of power.
> >>
> >> A member of my dissertation committee who uses SAS, recommended that I
> use
> >> full information maximum likelihood estimation (FIML) (described here:
> >>
> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
> >> ),
> >> which is the easiest way to handle missing data in SAS.  Is there an
> >> equivalent procedure in R?
> >>
> >> Alternatively, I have tried several approaches to multiple imputation.
> >> For
> >> example, I used the package, Amelia, which appears to handle the
> clustered
> >> structure of the data appropriately, to generate five imputed versions
> of
> >> the data set, and then used lapply to run my model on each.  But I am
> not
> >> sure how to combine the resulting five models into one final result.  I
> >> will need a final result that enables me to report, not just the fixed
> >> effects of the model, but also the random effects variance components
> and,
> >> ideally, the distributions across the population of the random intercept
> >> and slopes, and correlations between them.
> >>
> >> Many thanks for any suggestions on how to proceed.
> >>
> >> Bonnie

	[[alternative HTML version deleted]]


From bmdixon at ucdavis.edu  Fri Feb 27 21:00:55 2015
From: bmdixon at ucdavis.edu (Bonnie Dixon)
Date: Fri, 27 Feb 2015 12:00:55 -0800
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
	<CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
	<54F00E40.7000002@gmail.com>
	<CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com>
Message-ID: <CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com>

Thank you very much to everyone who has replied for your helpful
suggestions.

For clarification about FIML (and in support of what Ken explained), my
professor who does multilevel modeling in SAS tells me that in SAS, "FIML"
refers to a form of maximum likelihood estimation that can accept an
incomplete data set, and does not omit the observations with missing data
as must be done in both "ML" and "REML" in nlme.  FIML in SAS handles
observations in which the data is missing for some variables by just using
those variables for which data is available and integrating over the
missing values.  This is the default method in SAS PROC MIXED for all mixed
effects models (not just for structural equation modeling).  But this
functionality does not appear to be available in R except for structural
equation modeling (i.e. package, lavaan).

Given that, I am now working on a multiple imputation solution for my
problem, using either mice or Amelia, and will post again to the list once
I have a working example.  (Apparently, I was wrong about mice only being
able to impute one variable.)  How many imputations are needed?  Many
sources online indicate that 3-10 is usually enough, and the default in
both mice and Amelia is 5.

Bonnie

On Thu, Feb 26, 2015 at 11:26 PM, Ken Beath <ken.beath at mq.edu.au> wrote:

> >From the same posting
>
> >*From: Chris Lawrence <chris at lordsutch.com <
> https://stat.ethz.ch/mailman/listinfo/r-help>>*
>
> <snip>
>
> >*I have seen FIML used to refer to a type of ML estimation where a
> *>*missing data treatment is included in the estimation procedure
> *>*(parameter estimates are derived from incomplete cases for only the
> *>*variables present in the case, rather than simply discarding the
> *>*cases), at least in the latent-variable SEM context, specifically in
> *>*AMOS.  This may be what Francisco is getting at.
> *>>*To my knowledge, no R packages implement this sort of "FIML", for any
> *>*class of models, although there are other available missing data
> *>*treatments (EM, MCMC estimation). *
>
> *This is what is correctly referred to as FIML. Your original post claimed
> that FIML was available through the ML option which is incorrect, and will
> not fix missing values except in the dependent variable. The fact that some
> software may claim that it does something that it doesn't will not change
> this. What could be said is that FIML is simply ML done correctly in that
> it builds the proper model for the data, rather than ignoring the
> observations with missing data, so both are maximum likelihood. *
>
> On 27 February 2015 at 17:27, landon hurley <ljrhurley at gmail.com> wrote:
>
> > -----BEGIN PGP SIGNED MESSAGE-----
> > Hash: SHA512
> >
> > On 02/27/2015 01:02 AM, Ken Beath wrote:
> > > mice will impute the complete dataset, it just needs to have an
> > imputation
> > > method setup for each variable. See the example given in the help for
> > > mice.impute.2lonly.norm
> > >
> > > Full information maximum likelihood estimation (FIML) (Note for Landon,
> > > this is ML taking into account the missing data) is only feasible if
> you
> > > can reformulate everything as a structural equation model and use
> > software
> > > that can cope with this. Otherwise working with the integrals is pretty
> > > much impossible. If there is something in the model that is nonlinear
> it
> > > probably isn't an option at all. One of the great things about multiple
> > > imputation is that you get it running with say 20 imputations and then
> > run
> > > it overnight with 200 or more and it probably won't change but you will
> > > know that you have enough imputations. So FIML doesn't have an
> advantage
> > in
> > > that respect.
> > >
> >
> > I'm not sure that's needed as a distinction. This quote from the
> > r-help
> > mailing list [0]  addresses it:
> >
> > > I'm not sure you are correct on this. Other texts on multilevel models
> > > (e.g., Raudenbush and Bryk, Kreft and Deeuw, and Singer & Willett) all
> > > use FiML as a synonym for ML. In fact, Kreft and Deleeuw go as far to
> > > even state they are the same thing (see page 131).
> > >
> > > When you run a model in HLM selecting "Full Maximum Likelihood" and
> > > method="ML" in lme, the results, including all fixed effects, variance
> > > components, empirical bayes residuals, degrees of freedom are exactly
> > > the same.
> > >
> > > So, I think Doug [Bates] is correct in that ML == FiML.
> > >
> > > Harold
> >
> > So maybe a semantics difference. However, with respect to the handling
> > of the integral: if it's problematic, that should result in a
> > non-convergence problem, or different results reported when he reruns
> > the model, in terms of diagnostics.
> >
> > [0]https://stat.ethz.ch/pipermail/r-help/2004-August/056723.html
> >
> > >
> > >
> > > On 27 February 2015 at 16:20, Bonnie Dixon <bmdixon at ucdavis.edu>
> wrote:
> > >
> > >> I actually did try mice also (method "2l.norm"), but it seemed that
> > Amelia
> > >> was preferable for imputation.  Mice seems to only be able to impute
> one
> > >> variable, whereas Amelia can impute as many variables as have missing
> > data
> > >> producing 100% complete data sets as output.
> > >>
> > >> However, most of the missing data in the data set I am working with is
> > in
> > >> just one variable, so I could consider using mice, and just imputing
> the
> > >> variable that has the most missing data, while omitting observations
> > that
> > >> have missing data in any of the other variables.  But the pooled
> results
> > >> from mice only seem to include the fixed effects of the model, so this
> > >> still leaves me wondering how to report the random effects, which are
> > very
> > >> important to my research question.
> > >>
> > >> When using Amelia to impute, the packages Zelig and ZeligMultilevel
> can
> > be
> > >> used to combine the results from each of the models.  But again, only
> > the
> > >> fixed effects seem to be included in the output, so I am not sure how
> to
> > >> report on the random effects.
> > >>
> > >> Bonnie
> > >>
> > >> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <
> mmalten at gmail.com
> > >
> > >> wrote:
> > >>
> > >>> Mice might be the package you need
> > >>>
> > >>>
> > >>> On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
> > >> wrote:
> > >>>
> > >>>> Dear list;
> > >>>>
> > >>>> I am using nlme to create a repeated measures (i.e. 2 level) model.
> > >> There
> > >>>> is missing data in several of the predictor variables.  What is the
> > best
> > >>>> way to handle this situation?  The variable with (by far) the most
> > >> missing
> > >>>> data is the best predictor in the model, so I would not want to
> remove
> > >> it.
> > >>>> I am also trying to avoid omitting the observations with missing
> data,
> > >>>> because that would require omitting almost 40% of the observations
> and
> > >>>> would result in a substantial loss of power.
> > >>>>
> > >>>> A member of my dissertation committee who uses SAS, recommended
> that I
> > >> use
> > >>>> full information maximum likelihood estimation (FIML) (described
> here:
> > >>>>
> > >>
> >
> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
> > >>>> ),
> > >>>> which is the easiest way to handle missing data in SAS.  Is there an
> > >>>> equivalent procedure in R?
> > >>>>
> > >>>> Alternatively, I have tried several approaches to multiple
> imputation.
> > >>>> For
> > >>>> example, I used the package, Amelia, which appears to handle the
> > >> clustered
> > >>>> structure of the data appropriately, to generate five imputed
> versions
> > >> of
> > >>>> the data set, and then used lapply to run my model on each.  But I
> am
> > >> not
> > >>>> sure how to combine the resulting five models into one final result.
> > I
> > >>>> will need a final result that enables me to report, not just the
> fixed
> > >>>> effects of the model, but also the random effects variance
> components
> > >> and,
> > >>>> ideally, the distributions across the population of the random
> > intercept
> > >>>> and slopes, and correlations between them.
> > >>>>
> > >>>> Many thanks for any suggestions on how to proceed.
> > >>>>
> > >>>> Bonnie
> > >>>>
> > >>>>         [[alternative HTML version deleted]]
> > >>>>
> > >>>> _______________________________________________
> > >>>> R-sig-mixed-models at r-project.org mailing list
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>>>
> > >>>
> > >>>
> > >>> --
> > >>> ____________________________
> > >>> Ersatzistician and Chutzpahthologist
> > >>>
> > >>> I can answer any question.  "I don't know" is an answer. "I don't
> know
> > >>> yet" is a better answer.
> > >>>
> > >>> "I can write better than anybody who can write faster, and I can
> write
> > >>> faster than anybody who can write better" AJ Liebling
> > >>>
> > >>>
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >
> > >
> > >
> >
> >
> > - --
> > Violence is the last refuge of the incompetent.
> > -----BEGIN PGP SIGNATURE-----
> > Version: GnuPG v1.4.11 (GNU/Linux)
> >
> > iQIcBAEBCgAGBQJU8A5AAAoJEDeph/0fVJWsbNUP/invP0QBC1qS0sWfKrnRVM09
> > kV1fv4Y8rVflFnS+znsbAPDJOK+5YnvITmfoVLMdwTAWaUEyugKZVGDydY+fTDfg
> > GxokxDpNAdGlfDBg+asw49VOFoTFtBKai0PWKyw4zHrAHYS9rzTqeO2CVq1Qlb8G
> > F7je9naYr+iwcEkIWQZ2JloBH8OPw80UueWqNjQ0totVRN8ehYgsu2+iyyudTQnH
> > Sl7LWkg6QnDYYVKrlV9ygd6z9yOymU9f5w52px1cUIY0mBoT12fYturEfyi/aIxF
> > +3nBjRCE14C2c9y6mW2Lab9AYpR8bbzsmTK6y7PXid6/VxcqkZlE6Qsj4bD4zvK3
> > lkIdFj8BR2LdzJNI1EdM8LREA82VPrkS5LFf/4ige0pSo6X3aVoInC2ohLKGSdr5
> > r66Nh3tLu1a6kPtPBNw7YAxzkzRd2CKy9OTvOpz5wRqlXNvzOoq2Is7Hpoeva0yB
> > 3hvAAgmJUtq8ZbTEXLQiDl2w/qeO+8o5KRfm/2uutN8z29S768me/6bfnvLELw9w
> > y2R4vwOGdpp+3XBAfs8sF5bMGVvTEzZj/ILph5D7OFRJi/pfCbntnf2mAFrllvlt
> > KUh+Okd0bO5dC2gfLuu42J3jQnCTMez/ghrEVlXkRX9XMnMz3JB7r4pdgmUqXHYu
> > w9eXfCoXza9efwhgHF1q
> > =LMV6
> > -----END PGP SIGNATURE-----
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:10}}


From ken.beath at mq.edu.au  Fri Feb 27 22:47:42 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sat, 28 Feb 2015 08:47:42 +1100
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
	<CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
	<54F00E40.7000002@gmail.com>
	<CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com>
	<CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com>
Message-ID: <CAF5_5cwnPX5_MsEOCCbzaLicG0tZJ8V8XNkyWO2c9GELNTqu4w@mail.gmail.com>

On 28 February 2015 at 07:00, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:


> Given that, I am now working on a multiple imputation solution for my
> problem, using either mice or Amelia, and will post again to the list once
> I have a working example.  (Apparently, I was wrong about mice only being
> able to impute one variable.)  How many imputations are needed?  Many
> sources online indicate that 3-10 is usually enough, and the default in
> both mice and Amelia is 5.
>
>
Others claim 20, and that seems to be more than sufficient for a lot of
problems. It will depend on what proportion of your data is missing, and
how dependent the outcome is on these. As you generally can't have too many
then I would start with say 20 and then try a couple of larger number and
if there is no change then 20 was sufficient.

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Sat Feb 28 01:22:49 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Sat, 28 Feb 2015 01:22:49 +0100
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
	<CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
	<54F00E40.7000002@gmail.com>
	<CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com>
	<CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F065D8DAD@UM-MAIL4112.unimaas.nl>

> For clarification about FIML (and in support of what Ken explained), my
> professor who does multilevel modeling in SAS tells me that in SAS,
> "FIML"
> refers to a form of maximum likelihood estimation that can accept an
> incomplete data set, and does not omit the observations with missing data
> as must be done in both "ML" and "REML" in nlme.  FIML in SAS handles
> observations in which the data is missing for some variables by just
> using
> those variables for which data is available and integrating over the
> missing values.  This is the default method in SAS PROC MIXED for all
> mixed
> effects models (not just for structural equation modeling).

I hate to be so blunt here, but this is just flat out wrong. proc mixed is great and all, but it doesn't do such a thing. Just like lmer() and lme() (with na.action=na.omit), proc mixed will just delete rows with missing data and then use ML or REML estimation on what's left (which is perfectly fine under certain missing data mechanisms). Consequently, fitting the same model with proc mixed and lmer() or lme() to the same data with missing data yields essentially identical results. One can easily confirm this with a few examples.

> But this
> functionality does not appear to be available in R except for structural
> equation modeling (i.e. package, lavaan).

Indeed, one has to switch to some form of a latent variable model if one wants to use FIML. In R, one should look into 'lavaan' or 'sem' (or 'OpenMX' for the more adventurous). In SAS, one would need to use something like proc calis:

http://support.sas.com/documentation/cdl/en/statug/63347/HTML/default/statug_calis_sect103.htm

Again, proc mixed does not use FIML. I am really just repeating what Ken has already stated. Also relevant:

http://stats.stackexchange.com/questions/51006/full-information-maximum-likelihood-for-missing-data-in-r

Best,
Wolfgang


From hannah.hlx at gmail.com  Sat Feb 28 04:16:01 2015
From: hannah.hlx at gmail.com (li li)
Date: Fri, 27 Feb 2015 22:16:01 -0500
Subject: [R-sig-ME] title of r plots
Message-ID: <CAHLnndYzBDwkGB10h+hcJU=9i_MnsE1S4hXSjOsUx3+9JPqgKQ@mail.gmail.com>

Hi all,
  I would like to add "-70?C ? 10?C/Ambient"  as the title of my plot.
Could anyone give some help on this?
  Thanks.
   Hanna

	[[alternative HTML version deleted]]


From smckinney at bccrc.ca  Sat Feb 28 04:21:07 2015
From: smckinney at bccrc.ca (Steven McKinney)
Date: Fri, 27 Feb 2015 19:21:07 -0800
Subject: [R-sig-ME] title of r plots
In-Reply-To: <CAHLnndYzBDwkGB10h+hcJU=9i_MnsE1S4hXSjOsUx3+9JPqgKQ@mail.gmail.com>
References: <CAHLnndYzBDwkGB10h+hcJU=9i_MnsE1S4hXSjOsUx3+9JPqgKQ@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0CD6D6CA1E@crcmail4.BCCRC.CA>

You'll get more answers faster if you post this on r-help - this is a mixed models listserv.

See e.g. help("text") and the use of expression() in plot and text labels.  


Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre


________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] On Behalf Of li li [hannah.hlx at gmail.com]
Sent: February 27, 2015 7:16 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] title of r plots

Hi all,
  I would like to add "-70?C ? 10?C/Ambient"  as the title of my plot.
Could anyone give some help on this?
  Thanks.
   Hanna

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bmdixon at ucdavis.edu  Mon Mar  2 01:00:40 2015
From: bmdixon at ucdavis.edu (Bonnie Dixon)
Date: Sun, 1 Mar 2015 16:00:40 -0800
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F065D8DAD@UM-MAIL4112.unimaas.nl>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
	<CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
	<54F00E40.7000002@gmail.com>
	<CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com>
	<CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F065D8DAD@UM-MAIL4112.unimaas.nl>
Message-ID: <CAMDF+bqK=B20AaNogB7B+RGbH35omDB19Ype5HUkReZs4eOUyA@mail.gmail.com>

Thank you for this clarification.  I can see from studying the article
linked below more closely that it confirms what you have said.
http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf

The distinction seems to be between missing data in the dependent variable
(which SAS PROC MIXED handles automatically) versus missing data in a
predictor variable (which would require switching to a structural equation
modeling program, such as SAS PROC CALIS to handle automatically using
FIML).  Here is a quote from the conclusion of the article that explains
this:

"When estimating mixed models for repeated measurements, PROC MIXED and
PROC GLIMMIX automatically handle missing data by maximum likelihood, as
long as there are no missing data on predictor variables. When data are
missing on both predictor and dependent variables, PROC CALIS can do
maximum likelihood for a large class of linear models..."

This sounds approximately equivalent to the functionality available in R.

I don't think the model I am working on is a good candidate for structural
equation modeling because the data set is very unbalanced (ie. there are
very different numbers of observations for different people, taken at
different times), the main relationship of interest involves a time-varying
predictor, and one of the variables with missing data is not continuous (it
is a binary, categorical variable).  So, I will stick with the multiple
imputation approach for handling the missing data.

Bonnie


On Fri, Feb 27, 2015 at 4:22 PM, Viechtbauer Wolfgang (STAT) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> > For clarification about FIML (and in support of what Ken explained), my
> > professor who does multilevel modeling in SAS tells me that in SAS,
> > "FIML"
> > refers to a form of maximum likelihood estimation that can accept an
> > incomplete data set, and does not omit the observations with missing data
> > as must be done in both "ML" and "REML" in nlme.  FIML in SAS handles
> > observations in which the data is missing for some variables by just
> > using
> > those variables for which data is available and integrating over the
> > missing values.  This is the default method in SAS PROC MIXED for all
> > mixed
> > effects models (not just for structural equation modeling).
>
> I hate to be so blunt here, but this is just flat out wrong. proc mixed is
> great and all, but it doesn't do such a thing. Just like lmer() and lme()
> (with na.action=na.omit), proc mixed will just delete rows with missing
> data and then use ML or REML estimation on what's left (which is perfectly
> fine under certain missing data mechanisms). Consequently, fitting the same
> model with proc mixed and lmer() or lme() to the same data with missing
> data yields essentially identical results. One can easily confirm this with
> a few examples.
>
> > But this
> > functionality does not appear to be available in R except for structural
> > equation modeling (i.e. package, lavaan).
>
> Indeed, one has to switch to some form of a latent variable model if one
> wants to use FIML. In R, one should look into 'lavaan' or 'sem' (or
> 'OpenMX' for the more adventurous). In SAS, one would need to use something
> like proc calis:
>
>
> http://support.sas.com/documentation/cdl/en/statug/63347/HTML/default/statug_calis_sect103.htm
>
> Again, proc mixed does not use FIML. I am really just repeating what Ken
> has already stated. Also relevant:
>
>
> http://stats.stackexchange.com/questions/51006/full-information-maximum-likelihood-for-missing-data-in-r
>
> Best,
> Wolfgang
>

	[[alternative HTML version deleted]]


From David.Duffy at qimr.edu.au  Mon Mar  2 02:29:20 2015
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 2 Mar 2015 11:29:20 +1000
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAMDF+bqK=B20AaNogB7B+RGbH35omDB19Ype5HUkReZs4eOUyA@mail.gmail.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com><CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com><CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com><CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com><54F00E40.7000002@gmail.com><CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com><CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com><077E31A57DA26E46AB0D493C9966AC730F065D8DAD@UM-MAIL4112.unimaas.nl>
	<CAMDF+bqK=B20AaNogB7B+RGbH35omDB19Ype5HUkReZs4eOUyA@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1503021121270.9107@orpheus.qimr.edu.au>

On Mon, 2 Mar 2015, Bonnie Dixon wrote:

> I don't think the model I am working on is a good candidate for structural
> equation modeling because the data set is very unbalanced (ie. there are
> very different numbers of observations for different people, taken at
> different times), the main relationship of interest involves a time-varying
> predictor, and one of the variables with missing data is not continuous (it
> is a binary, categorical variable).  So, I will stick with the multiple
> imputation approach for handling the missing data.

As Wolfgang mentioned, OpenMX can fit a FIML analysis to irregular data. 
If you were, for example, interested in a profile likelihood around a 
variance component, that might be the way to go.  It seems to me that 
multiple imputation might not always respect complicated 
clustering/correlation, depending on the actual method. A quick search 
found some cautionary tales in:

http://www.bmj.com/content/338/bmj.b2393.extract

Just another 2c, David.


| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From bmdixon at ucdavis.edu  Mon Mar  2 20:37:49 2015
From: bmdixon at ucdavis.edu (Bonnie Dixon)
Date: Mon, 2 Mar 2015 11:37:49 -0800
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAAH-yP-UP0h7K6C-BZiggnP87orqaiNfopawyfiVncXYF_yZnQ@mail.gmail.com>
References: <CAAH-yP-UP0h7K6C-BZiggnP87orqaiNfopawyfiVncXYF_yZnQ@mail.gmail.com>
Message-ID: <CAMDF+bpGy+RE+1PmUSg=aJGDFu8Oa3knix0zqQFXNp-u-m6JFg@mail.gmail.com>

Thanks for this suggestion, Malcolm.  Here is an example in which I use
Amelia/Zelig with the "africa" data set that is available in Amelia.
I extracted the average standard deviation of the random effects from the
result produced by Zelig.  (In this example, I am using the version of the
summary.MI function found here:
http://stackoverflow.com/questions/16571580/multi-level-regression-model-on-multiply-imputed-data-set-in-r-amelia-zelig-l)
 Perhaps this approach will work for my purposes.

# Get packages
require(Amelia)
require(Zelig)
require(ZeligMultilevel)

# Look at the data
data(africa)
head(africa)
summary(africa)
help(africa)

# Impute the missing data
africa.am <-
  amelia(x = africa,
         m = 30,
         cs = "country",
         ts = "year",
         logs = "gdp_pc")
summary(africa.am)
plot(africa.am)
missmap(africa.am)
names(africa.am)

# Create a model:
africa.z <-
  zelig(formula = gdp_pc ~ infl + tag(infl | country),
        data = africa.am$imputations,
        model = "ls.mixed")

# The combined fixed effects:
summary(africa.z)

# The average standard deviation of the random intercepts and slopes:
ran.ints <-
  sapply(africa.z,
         function(x)
           attributes(VarCorr(x$result)$country)$stddev["(Intercept)"])
mean(ran.ints)

ran.slopes <-
  sapply(africa.z,
         function(x)
           attributes(VarCorr(x$result)$country)$stddev["infl"])
mean(ran.slopes)



On Fri, Feb 27, 2015 at 4:47 AM, Malcolm Fairbrother <
M.Fairbrother at bristol.ac.uk> wrote:

> Hi Bonnie,
>
> I have not seen a formal treatment of this issue, but from the Amelia
> documentation, my understanding is that if you want an estimate of the
> random effects variance, you can just take the average of the estimates
> from the model fitted to each imputed dataset. This is true for any
> parameter, from the sounds of what Honaker, King, and Blackwell have
> written.
>
>  "you can combine directly and use as the multiple imputation estimate of
> this parameter, q ?, the average of them separate estimates"
>
> Even if Zelig doesn't report the RE variance estimates automatically, they
> must be "in there" somewhere... I'm sure you can extract them. Or maybe
> skip Zelig, and just use Amelia, and extract the estimated RE variances
> from each fitted model (presumably using lme4)?
>
> Cheers,
> Malcolm
>
>
> Date: Thu, 26 Feb 2015 21:20:33 -0800
>> From: Bonnie Dixon <bmdixon at ucdavis.edu>
>> To: Mitchell Maltenfort <mmalten at gmail.com>
>> Cc: "r-sig-mixed-models at r-project.org"
>>         <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Best way to handle missing data?
>>
>>
>> I actually did try mice also (method "2l.norm"), but it seemed that Amelia
>> was preferable for imputation.  Mice seems to only be able to impute one
>> variable, whereas Amelia can impute as many variables as have missing data
>> producing 100% complete data sets as output.
>>
>> However, most of the missing data in the data set I am working with is in
>> just one variable, so I could consider using mice, and just imputing the
>> variable that has the most missing data, while omitting observations that
>> have missing data in any of the other variables.  But the pooled results
>> from mice only seem to include the fixed effects of the model, so this
>> still leaves me wondering how to report the random effects, which are very
>> important to my research question.
>>
>> When using Amelia to impute, the packages Zelig and ZeligMultilevel can be
>> used to combine the results from each of the models.  But again, only the
>> fixed effects seem to be included in the output, so I am not sure how to
>> report on the random effects.
>>
>> Bonnie
>>
>> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <mmalten at gmail.com>
>> wrote:
>>
>> > Mice might be the package you need
>> >
>> >
>> > On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
>> wrote:
>> >
>> >> Dear list;
>> >>
>> >> I am using nlme to create a repeated measures (i.e. 2 level) model.
>> There
>> >> is missing data in several of the predictor variables.  What is the
>> best
>> >> way to handle this situation?  The variable with (by far) the most
>> missing
>> >> data is the best predictor in the model, so I would not want to remove
>> it.
>> >> I am also trying to avoid omitting the observations with missing data,
>> >> because that would require omitting almost 40% of the observations and
>> >> would result in a substantial loss of power.
>> >>
>> >> A member of my dissertation committee who uses SAS, recommended that I
>> use
>> >> full information maximum likelihood estimation (FIML) (described here:
>> >>
>> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
>> >> ),
>> >> which is the easiest way to handle missing data in SAS.  Is there an
>> >> equivalent procedure in R?
>> >>
>> >> Alternatively, I have tried several approaches to multiple imputation.
>> >> For
>> >> example, I used the package, Amelia, which appears to handle the
>> clustered
>> >> structure of the data appropriately, to generate five imputed versions
>> of
>> >> the data set, and then used lapply to run my model on each.  But I am
>> not
>> >> sure how to combine the resulting five models into one final result.  I
>> >> will need a final result that enables me to report, not just the fixed
>> >> effects of the model, but also the random effects variance components
>> and,
>> >> ideally, the distributions across the population of the random
>> intercept
>> >> and slopes, and correlations between them.
>> >>
>> >> Many thanks for any suggestions on how to proceed.
>> >>
>> >> Bonnie
>>
>

	[[alternative HTML version deleted]]


From joseph.bulbulia at me.com  Mon Mar  2 13:03:49 2015
From: joseph.bulbulia at me.com (Joseph Bulbulia)
Date: Tue, 03 Mar 2015 01:03:49 +1300
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <alpine.LMD.2.00.1503021121270.9107@orpheus.qimr.edu.au>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
	<CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
	<54F00E40.7000002@gmail.com>
	<CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com>
	<CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F065D8DAD@UM-MAIL4112.unimaas.nl>
	<CAMDF+bqK=B20AaNogB7B+RGbH35omDB19Ype5HUkReZs4eOUyA@mail.gmail.com>
	<alpine.LMD.2.00.1503021121270.9107@orpheus.qimr.edu.au>
Message-ID: <E7DFF16B-90C4-457C-9C17-2AA4B5E94B96@me.com>

RELATED QUESTION
I have a related and probably naive question, but raising it might be helpful to Bonnie and others (myself included) who are struggling with multiple-imputaton in a mixed-effects modeling setting. 

FIRST, MY DISCOMFORT
The question arises from (1) my discomfort with averaging across multiply imputed datasets, which seems to lose the uncertainty from the data-generating imputation process (2) my need to use a wider class of models than is made available by Zelig ? such as MCMCglmm. 

NOTE
I realise that MCMCglmm can handle missing variables (MAR) as outcome variables,  but where many columns have missing values, the resulting multivariate outcome model will often becomes overly complex.    

THE QUESTION
To avoid averaging, if multiple data sets were generated (assume sensibly) through a multiple imputation algorithm (say using the Amelia package), would it make any sense to combine the datasets (e.g. using r-bind) with an indicator for each of the imputed datasets, and then to model each specific imputed dataset as a random effect in, say,  MCMCglmm?

REASONING 
If the observations from the datasets were conceived as measurements on individuals (also included as an effect modelled as random).  Then conceptually it seems you would be adjusting your expectation for the variation of multiple observations within individuals from the multiply imputed datasets. Where there is no imputation, the observed values remain constant, and part of me thinks this constancy of observations within individuals shouldn?t effect the estimates... I think?   

SNAG
On the other hand, just combining datasets with an indicator for each dataset would artificially (and often dramatically) increase the number of observations, which might not be handled adequately by the G/ R structures.    


APOLOGY
I apologise if this question makes little sense, or if the answer is just plain obvious.  I?d intended to ask a statistician at work, and to simulate some data with him,  but the topic came up here, and I figured others might benefit, in case others had the same (potentially naive) thought, and the experts have a quick answer, even if the answer is ?you are muddled.? 

Cheers, 

Joseph









> On 2/03/2015, at 2:29 pm, David Duffy <David.Duffy at qimr.edu.au> wrote:
> 
> On Mon, 2 Mar 2015, Bonnie Dixon wrote:
> 
>> I don't think the model I am working on is a good candidate for structural
>> equation modeling because the data set is very unbalanced (ie. there are
>> very different numbers of observations for different people, taken at
>> different times), the main relationship of interest involves a time-varying
>> predictor, and one of the variables with missing data is not continuous (it
>> is a binary, categorical variable).  So, I will stick with the multiple
>> imputation approach for handling the missing data.
> 
> As Wolfgang mentioned, OpenMX can fit a FIML analysis to irregular data. If you were, for example, interested in a profile likelihood around a variance component, that might be the way to go.  It seems to me that multiple imputation might not always respect complicated clustering/correlation, depending on the actual method. A quick search found some cautionary tales in:
> 
> http://www.bmj.com/content/338/bmj.b2393.extract
> 
> Just another 2c, David.
> 
> 
> | David Duffy (MBBS PhD)
> | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
> | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
> | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Tue Mar  3 10:53:00 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 3 Mar 2015 10:53:00 +0100
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAMDF+bpGy+RE+1PmUSg=aJGDFu8Oa3knix0zqQFXNp-u-m6JFg@mail.gmail.com>
References: <CAAH-yP-UP0h7K6C-BZiggnP87orqaiNfopawyfiVncXYF_yZnQ@mail.gmail.com>
	<CAMDF+bpGy+RE+1PmUSg=aJGDFu8Oa3knix0zqQFXNp-u-m6JFg@mail.gmail.com>
Message-ID: <CAAH-yP_fDVnJoCcPiJwdBbV1KibaCjh1z86_w=G0H_BG_wTd8Q@mail.gmail.com>

Hi Bonnie,

I was getting an error with that code, and finding Zelig cumbersome. So how
about just:

mods <- lapply(africa.am[[1]], function(x) lmer(gdp_pc ~ infl + (infl |
country), data=x))
rowMeans(sapply(mods, fixef)) # fixed effects
rowMeans(sapply(mods, function(x) as.data.frame(VarCorr(x))$vcov)) # random
effects variances
Reduce("+", sapply(mods, ranef))/length(mods) # random effects (intercepts
and slopes)
sqrt(rowMeans(sapply(mods, function(x) diag(vcov(x)))) +
diag(var(t(sapply(mods, fixef))))*(1+1/length(mods))) # SEs

I think that gets you everything you want?

The last row of code is my interpretation of: "The variance of the point
estimate is the average of the estimated variances from within each
completed data set, plus the sample variance in the point estimates across
the data sets (multiplied by a factor that corrects for the bias because m
< ?)." (from http://r.iq.harvard.edu/docs/amelia/amelia.pdf)

Does that correspond to what you were getting via Zelig? I'd be interested
to know that this worked, actually.

Cheers,
Malcolm




On 2 March 2015 at 20:37, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:

> Thanks for this suggestion, Malcolm.  Here is an example in which I use
> Amelia/Zelig with the "africa" data set that is available in Amelia.
> I extracted the average standard deviation of the random effects from the
> result produced by Zelig.  (In this example, I am using the version of the
> summary.MI function found here:
> http://stackoverflow.com/questions/16571580/multi-level-regression-model-on-multiply-imputed-data-set-in-r-amelia-zelig-l)
>  Perhaps this approach will work for my purposes.
>
> # Get packages
> require(Amelia)
> require(Zelig)
> require(ZeligMultilevel)
>
> # Look at the data
> data(africa)
> head(africa)
> summary(africa)
> help(africa)
>
> # Impute the missing data
> africa.am <-
>   amelia(x = africa,
>          m = 30,
>          cs = "country",
>          ts = "year",
>          logs = "gdp_pc")
> summary(africa.am)
> plot(africa.am)
> missmap(africa.am)
> names(africa.am)
>
> # Create a model:
> africa.z <-
>   zelig(formula = gdp_pc ~ infl + tag(infl | country),
>         data = africa.am$imputations,
>         model = "ls.mixed")
>
> # The combined fixed effects:
> summary(africa.z)
>
> # The average standard deviation of the random intercepts and slopes:
> ran.ints <-
>   sapply(africa.z,
>          function(x)
>            attributes(VarCorr(x$result)$country)$stddev["(Intercept)"])
> mean(ran.ints)
>
> ran.slopes <-
>   sapply(africa.z,
>          function(x)
>            attributes(VarCorr(x$result)$country)$stddev["infl"])
> mean(ran.slopes)
>
>
>
> On Fri, Feb 27, 2015 at 4:47 AM, Malcolm Fairbrother <
> M.Fairbrother at bristol.ac.uk> wrote:
>
>> Hi Bonnie,
>>
>> I have not seen a formal treatment of this issue, but from the Amelia
>> documentation, my understanding is that if you want an estimate of the
>> random effects variance, you can just take the average of the estimates
>> from the model fitted to each imputed dataset. This is true for any
>> parameter, from the sounds of what Honaker, King, and Blackwell have
>> written.
>>
>>  "you can combine directly and use as the multiple imputation estimate of
>> this parameter, q ?, the average of them separate estimates"
>>
>> Even if Zelig doesn't report the RE variance estimates automatically,
>> they must be "in there" somewhere... I'm sure you can extract them. Or
>> maybe skip Zelig, and just use Amelia, and extract the estimated RE
>> variances from each fitted model (presumably using lme4)?
>>
>> Cheers,
>> Malcolm
>>
>>
>> Date: Thu, 26 Feb 2015 21:20:33 -0800
>>> From: Bonnie Dixon <bmdixon at ucdavis.edu>
>>> To: Mitchell Maltenfort <mmalten at gmail.com>
>>> Cc: "r-sig-mixed-models at r-project.org"
>>>         <r-sig-mixed-models at r-project.org>
>>> Subject: Re: [R-sig-ME] Best way to handle missing data?
>>>
>>>
>>> I actually did try mice also (method "2l.norm"), but it seemed that
>>> Amelia
>>> was preferable for imputation.  Mice seems to only be able to impute one
>>> variable, whereas Amelia can impute as many variables as have missing
>>> data
>>> producing 100% complete data sets as output.
>>>
>>> However, most of the missing data in the data set I am working with is in
>>> just one variable, so I could consider using mice, and just imputing the
>>> variable that has the most missing data, while omitting observations that
>>> have missing data in any of the other variables.  But the pooled results
>>> from mice only seem to include the fixed effects of the model, so this
>>> still leaves me wondering how to report the random effects, which are
>>> very
>>> important to my research question.
>>>
>>> When using Amelia to impute, the packages Zelig and ZeligMultilevel can
>>> be
>>> used to combine the results from each of the models.  But again, only the
>>> fixed effects seem to be included in the output, so I am not sure how to
>>> report on the random effects.
>>>
>>> Bonnie
>>>
>>> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <mmalten at gmail.com>
>>> wrote:
>>>
>>> > Mice might be the package you need
>>> >
>>> >
>>> > On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
>>> wrote:
>>> >
>>> >> Dear list;
>>> >>
>>> >> I am using nlme to create a repeated measures (i.e. 2 level) model.
>>> There
>>> >> is missing data in several of the predictor variables.  What is the
>>> best
>>> >> way to handle this situation?  The variable with (by far) the most
>>> missing
>>> >> data is the best predictor in the model, so I would not want to
>>> remove it.
>>> >> I am also trying to avoid omitting the observations with missing data,
>>> >> because that would require omitting almost 40% of the observations and
>>> >> would result in a substantial loss of power.
>>> >>
>>> >> A member of my dissertation committee who uses SAS, recommended that
>>> I use
>>> >> full information maximum likelihood estimation (FIML) (described here:
>>> >>
>>> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
>>> >> ),
>>> >> which is the easiest way to handle missing data in SAS.  Is there an
>>> >> equivalent procedure in R?
>>> >>
>>> >> Alternatively, I have tried several approaches to multiple imputation.
>>> >> For
>>> >> example, I used the package, Amelia, which appears to handle the
>>> clustered
>>> >> structure of the data appropriately, to generate five imputed
>>> versions of
>>> >> the data set, and then used lapply to run my model on each.  But I am
>>> not
>>> >> sure how to combine the resulting five models into one final result.
>>> I
>>> >> will need a final result that enables me to report, not just the fixed
>>> >> effects of the model, but also the random effects variance components
>>> and,
>>> >> ideally, the distributions across the population of the random
>>> intercept
>>> >> and slopes, and correlations between them.
>>> >>
>>> >> Many thanks for any suggestions on how to proceed.
>>> >>
>>> >> Bonnie
>>>
>>
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Mar  3 11:16:54 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 3 Mar 2015 11:16:54 +0100
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <E7DFF16B-90C4-457C-9C17-2AA4B5E94B96@me.com>
References: <CAMDF+br8mS8-LUXTEhQncyjAGP8zVJ5KFFs0F7CqZhmB9Er7YQ@mail.gmail.com>
	<CANOgrHaqSwAF46hB0aE606jfUEomHZyL29HrHz7_-sAVsGZJMQ@mail.gmail.com>
	<CAMDF+bprHjFX2r5WDyYizBOgXGy=M0YuDBYAznyqsxW4KJ5+Yw@mail.gmail.com>
	<CAF5_5cwptoP7V2xX+cWy-p8PD8hf5ZmbXShLmUr529z-U57oWw@mail.gmail.com>
	<54F00E40.7000002@gmail.com>
	<CAF5_5cyY89BG6kmh5XWkXe41vR1eOFROC43gXpQQWF+WCR7pEw@mail.gmail.com>
	<CAMDF+brXqcufYVZUHsR6U=ZpSODTfm-+jjsyRp4KO0dtg0S25w@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F065D8DAD@UM-MAIL4112.unimaas.nl>
	<CAMDF+bqK=B20AaNogB7B+RGbH35omDB19Ype5HUkReZs4eOUyA@mail.gmail.com>
	<alpine.LMD.2.00.1503021121270.9107@orpheus.qimr.edu.au>
	<E7DFF16B-90C4-457C-9C17-2AA4B5E94B96@me.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F065D93A2@UM-MAIL4112.unimaas.nl>

With MI, you do indeed average parameter estimates across the imputed datasets. And the way the SE for such an average is computed takes into consideration not only the variance of the estimate conditional on a particular dataset but also the variability across datasets. That's in fact the entire point of doing the imputation multiple times.

See, for example: http://sites.stat.psu.edu/~jls/mifaq.html#howto

One can apply that principle to any parameter estimate, even if this computation is not automated for particular models via a package.

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Joseph Bulbulia
> Sent: Monday, March 02, 2015 13:04
> To: David Duffy
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Best way to handle missing data?
> 
> RELATED QUESTION
> I have a related and probably naive question, but raising it might be
> helpful to Bonnie and others (myself included) who are struggling with
> multiple-imputaton in a mixed-effects modeling setting.
> 
> FIRST, MY DISCOMFORT
> The question arises from (1) my discomfort with averaging across multiply
> imputed datasets, which seems to lose the uncertainty from the data-
> generating imputation process (2) my need to use a wider class of models
> than is made available by Zelig ? such as MCMCglmm.
> 
> NOTE
> I realise that MCMCglmm can handle missing variables (MAR) as outcome
> variables,  but where many columns have missing values, the resulting
> multivariate outcome model will often becomes overly complex.
> 
> THE QUESTION
> To avoid averaging, if multiple data sets were generated (assume
> sensibly) through a multiple imputation algorithm (say using the Amelia
> package), would it make any sense to combine the datasets (e.g. using r-
> bind) with an indicator for each of the imputed datasets, and then to
> model each specific imputed dataset as a random effect in, say,
> MCMCglmm?
> 
> REASONING
> If the observations from the datasets were conceived as measurements on
> individuals (also included as an effect modelled as random).  Then
> conceptually it seems you would be adjusting your expectation for the
> variation of multiple observations within individuals from the multiply
> imputed datasets. Where there is no imputation, the observed values
> remain constant, and part of me thinks this constancy of observations
> within individuals shouldn?t effect the estimates... I think?
> 
> SNAG
> On the other hand, just combining datasets with an indicator for each
> dataset would artificially (and often dramatically) increase the number
> of observations, which might not be handled adequately by the G/ R
> structures.
> 
> 
> APOLOGY
> I apologise if this question makes little sense, or if the answer is just
> plain obvious.  I?d intended to ask a statistician at work, and to
> simulate some data with him,  but the topic came up here, and I figured
> others might benefit, in case others had the same (potentially naive)
> thought, and the experts have a quick answer, even if the answer is ?you
> are muddled.?
> 
> Cheers,
> 
> Joseph

From bbolker at gmail.com  Wed Mar  4 03:15:16 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Mar 2015 02:15:16 +0000 (UTC)
Subject: [R-sig-ME] Problem- Warning message
References: <CABa6ee0msQrE5uztANxWuXUtwfnTaKCycoCX5ZUYDUu+H3e92A@mail.gmail.com>
	<CAF5_5czw04yk+u-rEr9w-dernpcSEzuoEHQUZzedYxU1mYbuBg@mail.gmail.com>
Message-ID: <loom.20150304T030956-42@post.gmane.org>

Ken Beath <ken.beath at ...> writes:

> 
> There are two random effects, another one for obs which is modelling
> overdispersion.
> 
> It looks like the optimizer has decided to stop, but has stopped when the
> gradients are not zero, that is it is not a maxima. It could just be the
> numerical gradients are a problem, but it could be something else. I've
> been having similar trouble with a glmm, and it seems to be a problem with
> the way glmer does something.
> 
> I don't know how much data that you have, but it is possible that your
> model is just too complex for the data available. The first rule of these
> models is to start with something simple and then add to the model until
> something breaks, then you can think about why it broke.

  As regular readers of this list will probably know, the tests for
convergence that we added in 1.1-6 were too strenuous (improved for
1.1-7, but still subject to false positives).  We are still discussing
how we can increase specificity without hurting sensitivity too much.
In the meantime, as a rule of thumb, I would probably not worry about
convergence warnings reporting scaled gradients of <0.1, especially
with large data sets.  However, 1.02 looks pretty big.

I would examine your data graphically to look for anomalies,
and try the recommendations listed at
http://rpubs.com/bbolker/lme4trouble1

> 
> On 27 February 2015 at 04:14, Davide Bellone <bellonedavide1 <at> gmail.com>
> wrote:
> 
> > Goodevening,
> >
> > this is my first mail . From what a collegue told me I can ask to the
> > members of this mailing list to help me with my problem.
> > So, what I am trying to do is a glmer model. I have 1 random effect (Site)
> > and 6 fixed effects.
> >
> > Model <- read.table("c:\\TXT X R\\Tabella modello gruppi
> > completo.txt",header=T)
> > y <- cbind(Model$Rem, Model$Total-Model$Rem)
> > Model$wood <- as.factor(Model$wood)
> > Model$under <- as.factor(Model$under)
> > Model$Manage <- as.factor(Model$Manage)
> > Model$Size <- as.factor(Model$Size)
> > Model$Site <- as.factor(Model$Site)
> > obs <- 1:length(Model$Site)
> > obs
> > options(contrasts=c("contr.sum", "contr.poly"))
> > R1 <- glmer(y ~ Model$Manage + Model$age +  Model$veg + Model$Size +
> > Model$wood + Model$under + Model$age*Model$Manage + Model$veg*Model$Manage
> > + (1|Model$Site)+(1|obs) , family= binomial)

This would probably be better as

Model$obs <- 1:nrow(Model)
R1 <- glmer(cbind(Rem,Total-Rem) ~ Size + wood + under + (age+ veg)*Manage +
             (1|Site)+(1|obs) , family= binomial)


> >
> > The first output is:
> > Warning message:
> > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >   Model failed to converge with max|grad| = 1.02046 (tol = 0.001, component
> > 3)
> >
> > Can someone explain if there is some problem in data and if there is a
> > solution?
> >


From bbolker at gmail.com  Wed Mar  4 03:18:47 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Mar 2015 02:18:47 +0000 (UTC)
Subject: [R-sig-ME] Zero-inflated mixed models
References: <1424905368937.78449@mail.aub.edu>
Message-ID: <loom.20150304T031529-621@post.gmane.org>

Zahwa Al Ayyash (Student <zsa11 at ...> writes:

> 
> Dear all,
> 
> Zero-inflated models have a count component 
> (Poisson/Neg. Binomial) and a zero component (logistic
> regression part).
 
> glmmADMB supports the zero-inflation feature but only through
> estimating a zero-inflation parameter that is assumed constant
> across the whole data set?.
 
>   1.  ?Why doesn't the glmmadmb support the two-stage fitting of
> zero-inflated models like it does with hurdle models? I once read
> that its estimation might be more complex than that of hurdle
> models. Is that true? If yes, why?

  It doesn't support it because we never got around to implementing
it -- i.e. making sure the interface was well designed, implementing,
and testing.

>   2.  Is there an R package that allows for the two-model fitting
> (i.e., each model with its own covariates) of ZIP or ZINB (not
> hurdle) and allowing for a random effect?

  You can take a look the stuff here:

https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls
https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/R/owls_R_funs.R

search for 'zipme.f' in the source code.

  Ben Bolker


From bbolker at gmail.com  Wed Mar  4 03:25:35 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Mar 2015 02:25:35 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Choosing_appropriate_priors_for_bglmer_mixed?=
	=?utf-8?q?_models_in=09blme?=
References: <CAGb-hRp9YRcm8f+fnQ=_UfuYxeSN97FMCZmzaDOC3v0ydAPMzg@mail.gmail.com>
Message-ID: <loom.20150304T031906-724@post.gmane.org>

Josie Galbraith <josie.galbraith at ...> writes:

> 

[snip]

> 
> I'm after some advice on how to choose which priors to use.  I gather I
> need to impose a weak prior on the fixed effects of my model but no
> covariance priors - is this correct?  Can I use a default prior (i.e. t, or
> normal defaults in the blme package) or does it depend on my data?  What is
> considered a suitably weak prior?

   If all you're trying to do is deal with complete separation (and not,
e.g. singular estimates of variance components [typically indicated
by zero variances or +/- 1 correlations, although I'm not sure those
are necessary conditions for singularity]), then it should be OK
to put the prior only on the fixed effects.  Generally speaking a
weak prior is one with a standard deviation that is large relative
to the expected scale of the effect (e.g. we might say sigma=10 is
large, but it won't be if the units of measurement are very small
so that a typical value of the mean is 100,000 ...)

> I am running binomial models for epidemiology data (response variable is
> presence/absence of lesions), with 2 fixed effects (FOOD: F/NF; SEASON:
> Autumn/Spring) and a random effect (SITE: 8 levels).  The main goal of
> these models is to test for an effect of the treatment 'FOOD.'  I'm
> guessing from what I've read, that my model should be something like the
> following:


This seems fairly reasonable at first glance.  Where were you seeing
the complete separation, though?   I would normally expect to
see at least one of the parameters still being reasonably large
if that's the case.
 
> bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family = binomial,
> fixef.prior = normal, cov.prior = NULL)
> 
> This is the output when I run the model:
> 
> Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...), common.scale =
> FALSE)
> Prior dev  : 18.2419
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> bglmerMod]
>  Family: binomial ( logit )
> Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>    Data: SEYE.df
> 

[snip]
 
> Random effects:
>  Groups Name        Variance Std.Dev.
>  SITE   (Intercept) 0.3064   0.5535
> Number of obs: 178, groups: SITE, 8
> 
> Fixed effects:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
> FOODNF                0.5462     1.6838   0.324  0.74567
> SEASONSpring          1.7529     1.4721   1.191  0.23378
> FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 

[snip]

From bmdixon at ucdavis.edu  Wed Mar  4 06:42:18 2015
From: bmdixon at ucdavis.edu (Bonnie Dixon)
Date: Tue, 3 Mar 2015 21:42:18 -0800
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAAH-yP_fDVnJoCcPiJwdBbV1KibaCjh1z86_w=G0H_BG_wTd8Q@mail.gmail.com>
References: <CAAH-yP-UP0h7K6C-BZiggnP87orqaiNfopawyfiVncXYF_yZnQ@mail.gmail.com>
	<CAMDF+bpGy+RE+1PmUSg=aJGDFu8Oa3knix0zqQFXNp-u-m6JFg@mail.gmail.com>
	<CAAH-yP_fDVnJoCcPiJwdBbV1KibaCjh1z86_w=G0H_BG_wTd8Q@mail.gmail.com>
Message-ID: <CAMDF+bqhKtmkJFgrRa6XAKtEACgKhhto=HDrHVeiHT0dn+-LjA@mail.gmail.com>

Thanks, Malcolm!  Yes, that extracts all the results I need from out of the
multiple imputation models.  This method also seems preferable over using
Zelig because it provides the flexibility to create the models using lme4,
or using a different package, such as nlme or MCMCglmm.  And, yes, the
results using this method are identical to the results from Zelig.

Bonnie

P.S.  By the way, that error that occurs when using summary() on the object
created by Zelig can be avoided by using the modified version of the
summary.MI function below (from
http://stackoverflow.com/questions/16571580/multi-level-regression-model-on-multiply-imputed-data-set-in-r-amelia-zelig-l
).

summary.MI <- function (object, subset = NULL, ...) {
  if (length(object) == 0) {
    stop('Invalid input for "subset"')
  } else {
    if (length(object) == 1) {
      return(summary(object[[1]]))
    }
  }

    getcoef <- function(obj) {
    # S4
    if (!isS4(obj)) {
      coef(obj)
    } else {
      if ("coef3" %in% slotNames(obj)) {
        obj at coef3
      } else {
        obj at coef
      }
    }
  }

  res <- list()

  # Get indices
  subset <- if (is.null(subset)) {
    1:length(object)
  } else {
    c(subset)
  }

  # Compute the summary of all objects
  for (k in subset) {
    res[[k]] <- summary(object[[k]])
  }


  # Answer
  ans <- list(
    zelig = object[[1]]$name,
    call = object[[1]]$result at call,
    all = res
  )

  coef1 <- se1 <- NULL

  for (k in subset) {
    tmp <- coef(res[[k]])
    coef1 <- cbind(coef1, tmp[, 1])
    se1 <- cbind(se1, tmp[, 2])
  }

  rows <- nrow(coef1)
  Q <- apply(coef1, 1, mean)
  U <- apply(se1^2, 1, mean)
  B <- apply((coef1-Q)^2, 1, sum)/(length(subset)-1)
  var <- U+(1+1/length(subset))*B
  nu <- (length(subset)-1)*(1+U/((1+1/length(subset))*B))^2

  coef.table <- matrix(NA, nrow = rows, ncol = 4)
  dimnames(coef.table) <- list(rownames(coef1),
                               c("Value", "Std. Error", "t-stat",
"p-value"))
  coef.table[,1] <- Q
  coef.table[,2] <- sqrt(var)
  coef.table[,3] <- Q/sqrt(var)
  coef.table[,4] <- pt(abs(Q/sqrt(var)), df=nu, lower.tail=F)*2
  ans$coefficients <- coef.table
  ans$cov.scaled <- ans$cov.unscaled <- NULL

  for (i in 1:length(ans)) {
    if (is.numeric(ans[[i]]) && !names(ans)[i] %in% c("coefficients")) {
      tmp <- NULL
      for (j in subset) {
        r <- res[[j]]
        tmp <- cbind(tmp, r[[pmatch(names(ans)[i], names(res[[j]]))]])
      }
      ans[[i]] <- apply(tmp, 1, mean)
    }
  }

  class(ans) <- "summaryMI"
  ans
}

On Tue, Mar 3, 2015 at 1:53 AM, Malcolm Fairbrother <
M.Fairbrother at bristol.ac.uk> wrote:

> Hi Bonnie,
>
> I was getting an error with that code, and finding Zelig cumbersome. So
> how about just:
>
> mods <- lapply(africa.am[[1]], function(x) lmer(gdp_pc ~ infl + (infl |
> country), data=x))
> rowMeans(sapply(mods, fixef)) # fixed effects
> rowMeans(sapply(mods, function(x) as.data.frame(VarCorr(x))$vcov)) #
> random effects variances
> Reduce("+", sapply(mods, ranef))/length(mods) # random effects (intercepts
> and slopes)
> sqrt(rowMeans(sapply(mods, function(x) diag(vcov(x)))) +
> diag(var(t(sapply(mods, fixef))))*(1+1/length(mods))) # SEs
>
> I think that gets you everything you want?
>
> The last row of code is my interpretation of: "The variance of the point
> estimate is the average of the estimated variances from within each
> completed data set, plus the sample variance in the point estimates across
> the data sets (multiplied by a factor that corrects for the bias because m
> < ?)." (from http://r.iq.harvard.edu/docs/amelia/amelia.pdf)
>
> Does that correspond to what you were getting via Zelig? I'd be interested
> to know that this worked, actually.
>
> Cheers,
> Malcolm
>
>
>
>
> On 2 March 2015 at 20:37, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:
>
>> Thanks for this suggestion, Malcolm.  Here is an example in which I use
>> Amelia/Zelig with the "africa" data set that is available in Amelia.
>> I extracted the average standard deviation of the random effects from the
>> result produced by Zelig.  (In this example, I am using the version of the
>> summary.MI function found here:
>> http://stackoverflow.com/questions/16571580/multi-level-regression-model-on-multiply-imputed-data-set-in-r-amelia-zelig-l)
>>  Perhaps this approach will work for my purposes.
>>
>> # Get packages
>> require(Amelia)
>> require(Zelig)
>> require(ZeligMultilevel)
>>
>> # Look at the data
>> data(africa)
>> head(africa)
>> summary(africa)
>> help(africa)
>>
>> # Impute the missing data
>> africa.am <-
>>   amelia(x = africa,
>>          m = 30,
>>          cs = "country",
>>          ts = "year",
>>          logs = "gdp_pc")
>> summary(africa.am)
>> plot(africa.am)
>> missmap(africa.am)
>> names(africa.am)
>>
>> # Create a model:
>> africa.z <-
>>   zelig(formula = gdp_pc ~ infl + tag(infl | country),
>>         data = africa.am$imputations,
>>         model = "ls.mixed")
>>
>> # The combined fixed effects:
>> summary(africa.z)
>>
>> # The average standard deviation of the random intercepts and slopes:
>> ran.ints <-
>>   sapply(africa.z,
>>          function(x)
>>            attributes(VarCorr(x$result)$country)$stddev["(Intercept)"])
>> mean(ran.ints)
>>
>> ran.slopes <-
>>   sapply(africa.z,
>>          function(x)
>>            attributes(VarCorr(x$result)$country)$stddev["infl"])
>> mean(ran.slopes)
>>
>>
>>
>> On Fri, Feb 27, 2015 at 4:47 AM, Malcolm Fairbrother <
>> M.Fairbrother at bristol.ac.uk> wrote:
>>
>>> Hi Bonnie,
>>>
>>> I have not seen a formal treatment of this issue, but from the Amelia
>>> documentation, my understanding is that if you want an estimate of the
>>> random effects variance, you can just take the average of the estimates
>>> from the model fitted to each imputed dataset. This is true for any
>>> parameter, from the sounds of what Honaker, King, and Blackwell have
>>> written.
>>>
>>>  "you can combine directly and use as the multiple imputation estimate
>>> of this parameter, q ?, the average of them separate estimates"
>>>
>>> Even if Zelig doesn't report the RE variance estimates automatically,
>>> they must be "in there" somewhere... I'm sure you can extract them. Or
>>> maybe skip Zelig, and just use Amelia, and extract the estimated RE
>>> variances from each fitted model (presumably using lme4)?
>>>
>>> Cheers,
>>> Malcolm
>>>
>>>
>>> Date: Thu, 26 Feb 2015 21:20:33 -0800
>>>> From: Bonnie Dixon <bmdixon at ucdavis.edu>
>>>> To: Mitchell Maltenfort <mmalten at gmail.com>
>>>> Cc: "r-sig-mixed-models at r-project.org"
>>>>         <r-sig-mixed-models at r-project.org>
>>>> Subject: Re: [R-sig-ME] Best way to handle missing data?
>>>>
>>>>
>>>> I actually did try mice also (method "2l.norm"), but it seemed that
>>>> Amelia
>>>> was preferable for imputation.  Mice seems to only be able to impute one
>>>> variable, whereas Amelia can impute as many variables as have missing
>>>> data
>>>> producing 100% complete data sets as output.
>>>>
>>>> However, most of the missing data in the data set I am working with is
>>>> in
>>>> just one variable, so I could consider using mice, and just imputing the
>>>> variable that has the most missing data, while omitting observations
>>>> that
>>>> have missing data in any of the other variables.  But the pooled results
>>>> from mice only seem to include the fixed effects of the model, so this
>>>> still leaves me wondering how to report the random effects, which are
>>>> very
>>>> important to my research question.
>>>>
>>>> When using Amelia to impute, the packages Zelig and ZeligMultilevel can
>>>> be
>>>> used to combine the results from each of the models.  But again, only
>>>> the
>>>> fixed effects seem to be included in the output, so I am not sure how to
>>>> report on the random effects.
>>>>
>>>> Bonnie
>>>>
>>>> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <mmalten at gmail.com
>>>> >
>>>> wrote:
>>>>
>>>> > Mice might be the package you need
>>>> >
>>>> >
>>>> > On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
>>>> wrote:
>>>> >
>>>> >> Dear list;
>>>> >>
>>>> >> I am using nlme to create a repeated measures (i.e. 2 level) model.
>>>> There
>>>> >> is missing data in several of the predictor variables.  What is the
>>>> best
>>>> >> way to handle this situation?  The variable with (by far) the most
>>>> missing
>>>> >> data is the best predictor in the model, so I would not want to
>>>> remove it.
>>>> >> I am also trying to avoid omitting the observations with missing
>>>> data,
>>>> >> because that would require omitting almost 40% of the observations
>>>> and
>>>> >> would result in a substantial loss of power.
>>>> >>
>>>> >> A member of my dissertation committee who uses SAS, recommended that
>>>> I use
>>>> >> full information maximum likelihood estimation (FIML) (described
>>>> here:
>>>> >>
>>>> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
>>>> >> ),
>>>> >> which is the easiest way to handle missing data in SAS.  Is there an
>>>> >> equivalent procedure in R?
>>>> >>
>>>> >> Alternatively, I have tried several approaches to multiple
>>>> imputation.
>>>> >> For
>>>> >> example, I used the package, Amelia, which appears to handle the
>>>> clustered
>>>> >> structure of the data appropriately, to generate five imputed
>>>> versions of
>>>> >> the data set, and then used lapply to run my model on each.  But I
>>>> am not
>>>> >> sure how to combine the resulting five models into one final
>>>> result.  I
>>>> >> will need a final result that enables me to report, not just the
>>>> fixed
>>>> >> effects of the model, but also the random effects variance
>>>> components and,
>>>> >> ideally, the distributions across the population of the random
>>>> intercept
>>>> >> and slopes, and correlations between them.
>>>> >>
>>>> >> Many thanks for any suggestions on how to proceed.
>>>> >>
>>>> >> Bonnie
>>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Wed Mar  4 08:42:23 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Wed, 4 Mar 2015 08:42:23 +0100
Subject: [R-sig-ME] Best way to handle missing data?
In-Reply-To: <CAMDF+bqhKtmkJFgrRa6XAKtEACgKhhto=HDrHVeiHT0dn+-LjA@mail.gmail.com>
References: <CAAH-yP-UP0h7K6C-BZiggnP87orqaiNfopawyfiVncXYF_yZnQ@mail.gmail.com>
	<CAMDF+bpGy+RE+1PmUSg=aJGDFu8Oa3knix0zqQFXNp-u-m6JFg@mail.gmail.com>
	<CAAH-yP_fDVnJoCcPiJwdBbV1KibaCjh1z86_w=G0H_BG_wTd8Q@mail.gmail.com>
	<CAMDF+bqhKtmkJFgrRa6XAKtEACgKhhto=HDrHVeiHT0dn+-LjA@mail.gmail.com>
Message-ID: <CAAH-yP8FyE6tzAmp9qwGZ3q2-vByJLTehm7+d0fP1FsHiB90=A@mail.gmail.com>

Great, glad that worked!

On the topic of MCMC estimation with multiply imputed data, my
understanding is that you can simply merge each (m=5, 30, or whatever) of
the separate chains, and then analyse those using whatever techniques you
would have applied to a single chain. I guess this could also be useful for
assessing convergence. Others are welcome to correct me on this, however.

- Malcolm



On 4 March 2015 at 06:42, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:

> Thanks, Malcolm!  Yes, that extracts all the results I need from out of
> the multiple imputation models.  This method also seems preferable over
> using Zelig because it provides the flexibility to create the models using
> lme4, or using a different package, such as nlme or MCMCglmm.  And, yes,
> the results using this method are identical to the results from Zelig.
>
> Bonnie
>
> P.S.  By the way, that error that occurs when using summary() on the
> object created by Zelig can be avoided by using the modified version of the
> summary.MI function below (from
> http://stackoverflow.com/questions/16571580/multi-level-regression-model-on-multiply-imputed-data-set-in-r-amelia-zelig-l
> ).
>
> summary.MI <- function (object, subset = NULL, ...) {
>   if (length(object) == 0) {
>     stop('Invalid input for "subset"')
>   } else {
>     if (length(object) == 1) {
>       return(summary(object[[1]]))
>     }
>   }
>
>     getcoef <- function(obj) {
>     # S4
>     if (!isS4(obj)) {
>       coef(obj)
>     } else {
>       if ("coef3" %in% slotNames(obj)) {
>         obj at coef3
>       } else {
>         obj at coef
>       }
>     }
>   }
>
>   res <- list()
>
>   # Get indices
>   subset <- if (is.null(subset)) {
>     1:length(object)
>   } else {
>     c(subset)
>   }
>
>   # Compute the summary of all objects
>   for (k in subset) {
>     res[[k]] <- summary(object[[k]])
>   }
>
>
>   # Answer
>   ans <- list(
>     zelig = object[[1]]$name,
>     call = object[[1]]$result at call,
>     all = res
>   )
>
>   coef1 <- se1 <- NULL
>
>   for (k in subset) {
>     tmp <- coef(res[[k]])
>     coef1 <- cbind(coef1, tmp[, 1])
>     se1 <- cbind(se1, tmp[, 2])
>   }
>
>   rows <- nrow(coef1)
>   Q <- apply(coef1, 1, mean)
>   U <- apply(se1^2, 1, mean)
>   B <- apply((coef1-Q)^2, 1, sum)/(length(subset)-1)
>   var <- U+(1+1/length(subset))*B
>   nu <- (length(subset)-1)*(1+U/((1+1/length(subset))*B))^2
>
>   coef.table <- matrix(NA, nrow = rows, ncol = 4)
>   dimnames(coef.table) <- list(rownames(coef1),
>                                c("Value", "Std. Error", "t-stat",
> "p-value"))
>   coef.table[,1] <- Q
>   coef.table[,2] <- sqrt(var)
>   coef.table[,3] <- Q/sqrt(var)
>   coef.table[,4] <- pt(abs(Q/sqrt(var)), df=nu, lower.tail=F)*2
>   ans$coefficients <- coef.table
>   ans$cov.scaled <- ans$cov.unscaled <- NULL
>
>   for (i in 1:length(ans)) {
>     if (is.numeric(ans[[i]]) && !names(ans)[i] %in% c("coefficients")) {
>       tmp <- NULL
>       for (j in subset) {
>         r <- res[[j]]
>         tmp <- cbind(tmp, r[[pmatch(names(ans)[i], names(res[[j]]))]])
>       }
>       ans[[i]] <- apply(tmp, 1, mean)
>     }
>   }
>
>   class(ans) <- "summaryMI"
>   ans
> }
>
> On Tue, Mar 3, 2015 at 1:53 AM, Malcolm Fairbrother <
> M.Fairbrother at bristol.ac.uk> wrote:
>
>> Hi Bonnie,
>>
>> I was getting an error with that code, and finding Zelig cumbersome. So
>> how about just:
>>
>> mods <- lapply(africa.am[[1]], function(x) lmer(gdp_pc ~ infl + (infl |
>> country), data=x))
>> rowMeans(sapply(mods, fixef)) # fixed effects
>> rowMeans(sapply(mods, function(x) as.data.frame(VarCorr(x))$vcov)) #
>> random effects variances
>> Reduce("+", sapply(mods, ranef))/length(mods) # random effects
>> (intercepts and slopes)
>> sqrt(rowMeans(sapply(mods, function(x) diag(vcov(x)))) +
>> diag(var(t(sapply(mods, fixef))))*(1+1/length(mods))) # SEs
>>
>> I think that gets you everything you want?
>>
>> The last row of code is my interpretation of: "The variance of the point
>> estimate is the average of the estimated variances from within each
>> completed data set, plus the sample variance in the point estimates across
>> the data sets (multiplied by a factor that corrects for the bias because m
>> < ?)." (from http://r.iq.harvard.edu/docs/amelia/amelia.pdf)
>>
>> Does that correspond to what you were getting via Zelig? I'd be
>> interested to know that this worked, actually.
>>
>> Cheers,
>> Malcolm
>>
>>
>>
>>
>> On 2 March 2015 at 20:37, Bonnie Dixon <bmdixon at ucdavis.edu> wrote:
>>
>>> Thanks for this suggestion, Malcolm.  Here is an example in which I use
>>> Amelia/Zelig with the "africa" data set that is available in Amelia.
>>> I extracted the average standard deviation of the random effects from the
>>> result produced by Zelig.  (In this example, I am using the version of the
>>> summary.MI function found here:
>>> http://stackoverflow.com/questions/16571580/multi-level-regression-model-on-multiply-imputed-data-set-in-r-amelia-zelig-l)
>>>  Perhaps this approach will work for my purposes.
>>>
>>> # Get packages
>>> require(Amelia)
>>> require(Zelig)
>>> require(ZeligMultilevel)
>>>
>>> # Look at the data
>>> data(africa)
>>> head(africa)
>>> summary(africa)
>>> help(africa)
>>>
>>> # Impute the missing data
>>> africa.am <-
>>>   amelia(x = africa,
>>>          m = 30,
>>>          cs = "country",
>>>          ts = "year",
>>>          logs = "gdp_pc")
>>> summary(africa.am)
>>> plot(africa.am)
>>> missmap(africa.am)
>>> names(africa.am)
>>>
>>> # Create a model:
>>> africa.z <-
>>>   zelig(formula = gdp_pc ~ infl + tag(infl | country),
>>>         data = africa.am$imputations,
>>>         model = "ls.mixed")
>>>
>>> # The combined fixed effects:
>>> summary(africa.z)
>>>
>>> # The average standard deviation of the random intercepts and slopes:
>>> ran.ints <-
>>>   sapply(africa.z,
>>>          function(x)
>>>            attributes(VarCorr(x$result)$country)$stddev["(Intercept)"])
>>> mean(ran.ints)
>>>
>>> ran.slopes <-
>>>   sapply(africa.z,
>>>          function(x)
>>>            attributes(VarCorr(x$result)$country)$stddev["infl"])
>>> mean(ran.slopes)
>>>
>>>
>>>
>>> On Fri, Feb 27, 2015 at 4:47 AM, Malcolm Fairbrother <
>>> M.Fairbrother at bristol.ac.uk> wrote:
>>>
>>>> Hi Bonnie,
>>>>
>>>> I have not seen a formal treatment of this issue, but from the Amelia
>>>> documentation, my understanding is that if you want an estimate of the
>>>> random effects variance, you can just take the average of the estimates
>>>> from the model fitted to each imputed dataset. This is true for any
>>>> parameter, from the sounds of what Honaker, King, and Blackwell have
>>>> written.
>>>>
>>>>  "you can combine directly and use as the multiple imputation estimate
>>>> of this parameter, q ?, the average of them separate estimates"
>>>>
>>>> Even if Zelig doesn't report the RE variance estimates automatically,
>>>> they must be "in there" somewhere... I'm sure you can extract them. Or
>>>> maybe skip Zelig, and just use Amelia, and extract the estimated RE
>>>> variances from each fitted model (presumably using lme4)?
>>>>
>>>> Cheers,
>>>> Malcolm
>>>>
>>>>
>>>> Date: Thu, 26 Feb 2015 21:20:33 -0800
>>>>> From: Bonnie Dixon <bmdixon at ucdavis.edu>
>>>>> To: Mitchell Maltenfort <mmalten at gmail.com>
>>>>> Cc: "r-sig-mixed-models at r-project.org"
>>>>>         <r-sig-mixed-models at r-project.org>
>>>>> Subject: Re: [R-sig-ME] Best way to handle missing data?
>>>>>
>>>>>
>>>>> I actually did try mice also (method "2l.norm"), but it seemed that
>>>>> Amelia
>>>>> was preferable for imputation.  Mice seems to only be able to impute
>>>>> one
>>>>> variable, whereas Amelia can impute as many variables as have missing
>>>>> data
>>>>> producing 100% complete data sets as output.
>>>>>
>>>>> However, most of the missing data in the data set I am working with is
>>>>> in
>>>>> just one variable, so I could consider using mice, and just imputing
>>>>> the
>>>>> variable that has the most missing data, while omitting observations
>>>>> that
>>>>> have missing data in any of the other variables.  But the pooled
>>>>> results
>>>>> from mice only seem to include the fixed effects of the model, so this
>>>>> still leaves me wondering how to report the random effects, which are
>>>>> very
>>>>> important to my research question.
>>>>>
>>>>> When using Amelia to impute, the packages Zelig and ZeligMultilevel
>>>>> can be
>>>>> used to combine the results from each of the models.  But again, only
>>>>> the
>>>>> fixed effects seem to be included in the output, so I am not sure how
>>>>> to
>>>>> report on the random effects.
>>>>>
>>>>> Bonnie
>>>>>
>>>>> On Thu, Feb 26, 2015 at 8:33 PM, Mitchell Maltenfort <
>>>>> mmalten at gmail.com>
>>>>> wrote:
>>>>>
>>>>> > Mice might be the package you need
>>>>> >
>>>>> >
>>>>> > On Thursday, February 26, 2015, Bonnie Dixon <bmdixon at ucdavis.edu>
>>>>> wrote:
>>>>> >
>>>>> >> Dear list;
>>>>> >>
>>>>> >> I am using nlme to create a repeated measures (i.e. 2 level)
>>>>> model.  There
>>>>> >> is missing data in several of the predictor variables.  What is the
>>>>> best
>>>>> >> way to handle this situation?  The variable with (by far) the most
>>>>> missing
>>>>> >> data is the best predictor in the model, so I would not want to
>>>>> remove it.
>>>>> >> I am also trying to avoid omitting the observations with missing
>>>>> data,
>>>>> >> because that would require omitting almost 40% of the observations
>>>>> and
>>>>> >> would result in a substantial loss of power.
>>>>> >>
>>>>> >> A member of my dissertation committee who uses SAS, recommended
>>>>> that I use
>>>>> >> full information maximum likelihood estimation (FIML) (described
>>>>> here:
>>>>> >>
>>>>> http://www.statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf
>>>>> >> ),
>>>>> >> which is the easiest way to handle missing data in SAS.  Is there an
>>>>> >> equivalent procedure in R?
>>>>> >>
>>>>> >> Alternatively, I have tried several approaches to multiple
>>>>> imputation.
>>>>> >> For
>>>>> >> example, I used the package, Amelia, which appears to handle the
>>>>> clustered
>>>>> >> structure of the data appropriately, to generate five imputed
>>>>> versions of
>>>>> >> the data set, and then used lapply to run my model on each.  But I
>>>>> am not
>>>>> >> sure how to combine the resulting five models into one final
>>>>> result.  I
>>>>> >> will need a final result that enables me to report, not just the
>>>>> fixed
>>>>> >> effects of the model, but also the random effects variance
>>>>> components and,
>>>>> >> ideally, the distributions across the population of the random
>>>>> intercept
>>>>> >> and slopes, and correlations between them.
>>>>> >>
>>>>> >> Many thanks for any suggestions on how to proceed.
>>>>> >>
>>>>> >> Bonnie
>>>>>
>>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From makutzer at gmail.com  Wed Mar  4 21:11:22 2015
From: makutzer at gmail.com (Megan Kutzer)
Date: Wed, 4 Mar 2015 21:11:22 +0100
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
Message-ID: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>

Hi,

I'm fairly new to mixed models and have done a lot of reading without much
success. Unfortunately there is no one at my institution who is really
familiar with them so I thought I would try this list.

I'm running a binomial generalized linear mixed effects model and I need
p-values for the main effects. I know this isn't entirely correct with this
type of model but my supervisor wants the p-values!

The model is:

glmer (Proportion hatched ~ Diet * Infection status * Day + (1|SubjectID) +
(1|Day), family=binomial)

where,

Proportion hatched = cbind(Offspring, Eggs-Offspring)
Diet is a factor with 2 levels
Infection status is a factor with 4 levels
Day is a factor with 3 levels

Using Subject ID number and Day as random effects is supposed to control
for pseudoreplication in the model, although I am not entirely sure that
this is specified in the correct way. I wanted to include experimental
replicate here too but the model failed to converge.

My question is: is there a way to get p-values for the main fixed effects
of Diet, Infection and Day?

If you need more specific model information or the model output I would be
happy to provide it.

Thanks,
Megan

	[[alternative HTML version deleted]]


From tmeeha at gmail.com  Wed Mar  4 21:23:27 2015
From: tmeeha at gmail.com (Tim Meehan)
Date: Wed, 4 Mar 2015 13:23:27 -0700
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
Message-ID: <CAMTWOzpO-FGgWmNgZOhPXTpgE9BX8UyLzEnRzn_j3Y-nH3oSXw@mail.gmail.com>

Some solutions and their drawbacks are discussed here:

http://stats.stackexchange.com/questions/22988/significant-effect-in-lme4-mixed-model

On Wed, Mar 4, 2015 at 1:11 PM, Megan Kutzer <makutzer at gmail.com> wrote:

> Hi,
>
> I'm fairly new to mixed models and have done a lot of reading without much
> success. Unfortunately there is no one at my institution who is really
> familiar with them so I thought I would try this list.
>
> I'm running a binomial generalized linear mixed effects model and I need
> p-values for the main effects. I know this isn't entirely correct with this
> type of model but my supervisor wants the p-values!
>
> The model is:
>
> glmer (Proportion hatched ~ Diet * Infection status * Day + (1|SubjectID) +
> (1|Day), family=binomial)
>
> where,
>
> Proportion hatched = cbind(Offspring, Eggs-Offspring)
> Diet is a factor with 2 levels
> Infection status is a factor with 4 levels
> Day is a factor with 3 levels
>
> Using Subject ID number and Day as random effects is supposed to control
> for pseudoreplication in the model, although I am not entirely sure that
> this is specified in the correct way. I wanted to include experimental
> replicate here too but the model failed to converge.
>
> My question is: is there a way to get p-values for the main fixed effects
> of Diet, Infection and Day?
>
> If you need more specific model information or the model output I would be
> happy to provide it.
>
> Thanks,
> Megan
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From e.sharps at gmail.com  Wed Mar  4 21:47:54 2015
From: e.sharps at gmail.com (Elwyn Sharps)
Date: Wed, 4 Mar 2015 20:47:54 +0000
Subject: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
 failed to reduce deviance in pwrssUpdate
Message-ID: <CAM7=EBTYycpeYLtLjdGWtDTGF6pxYX++zP-GmJO71OyK3rXYNQ@mail.gmail.com>

Hi,

I am using a nest survival model (glmer) with random effects and a logistic
exposure link function, as described here:

http://stackoverflow.com/questions/19012128/user-defined-link-function-for-
glmer-for-known-fate-survival-modelling

I am running a number of different models, with varying fixed effects. Some
of them are running well, with no error or warning messages, however
for other models, I am getting the following message:

*Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
pwrssUpdate*

I'm not sure what is causing this error. I have tried to check the data for
simple problems, however can't see anything that could be causing trouble.

I've also tried running the model without the random effects. This results
in a different error message:

*Error: cannot find valid starting values: please specify some*

The other models are all running without the need for starting values.

Any advice or thoughts are greatly appreciated. Example data is attached to
this email.

Thanks, and best wishes

Elwyn


-------------------------------------------------------------------------------------------------------------------------------

*Example code:*

library(lme4)
library(MASS)

logexp <- function(exposure = 1)
{
  linkfun <- function(mu) qlogis(mu^(1/exposure))
  linkinv <- function(eta)  plogis(eta)^exposure
  mu.eta <- function(eta) exposure * plogis(eta)^(exposure-1) *
    .Call(stats:::C_logit_mu_eta, eta, PACKAGE = "stats")
  valideta <- function(eta) TRUE
  link <- paste("logexp(", deparse(substitute(exposure)), ")",
                sep="")
  structure(list(linkfun = linkfun, linkinv = linkinv,
                 mu.eta = mu.eta, valideta = valideta,
                 name = link),
            class = "link-glm")
}

##Read in data, called 'mydata'

glm1<-glm(survive/trials~habitat,family=binomial(logexp(exposure=mydata$expos)),data=mydata)


##error message:*Error: cannot find valid starting values: please specify
some*

Mod1<-glmer(survive/trials~habitat + (1|site)+ (1|year),
family=binomial(logexp(exposure=mydata$expos)),data=mydata)

##error message: *Error: (maxstephalfit) PIRLS step-halvings failed to
reduce deviance in pwrssUpdate*

From baron at psych.upenn.edu  Wed Mar  4 22:46:01 2015
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 4 Mar 2015 16:46:01 -0500
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAMTWOzpO-FGgWmNgZOhPXTpgE9BX8UyLzEnRzn_j3Y-nH3oSXw@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
	<CAMTWOzpO-FGgWmNgZOhPXTpgE9BX8UyLzEnRzn_j3Y-nH3oSXw@mail.gmail.com>
Message-ID: <20150304214601.GA16353@psych.upenn.edu>

I believe that this is old (although probably still useful). A more
recent account is here:

http://finzi.psych.upenn.edu/library/lme4/html/pvalues.html

which comes with the lme4 package.

Jon

On 03/04/15 13:23, Tim Meehan wrote:
>Some solutions and their drawbacks are discussed here:
>
>http://stats.stackexchange.com/questions/22988/significant-effect-in-lme4-mixed-model
>
>On Wed, Mar 4, 2015 at 1:11 PM, Megan Kutzer <makutzer at gmail.com> wrote:
>
>> Hi,
>>
>> I'm fairly new to mixed models and have done a lot of reading without much
>> success. Unfortunately there is no one at my institution who is really
>> familiar with them so I thought I would try this list.
>>
>> I'm running a binomial generalized linear mixed effects model and I need
>> p-values for the main effects. I know this isn't entirely correct with this
>> type of model but my supervisor wants the p-values!
>>
>> The model is:
>>
>> glmer (Proportion hatched ~ Diet * Infection status * Day + (1|SubjectID) +
>> (1|Day), family=binomial)
>>
>> where,
>>
>> Proportion hatched = cbind(Offspring, Eggs-Offspring)
>> Diet is a factor with 2 levels
>> Infection status is a factor with 4 levels
>> Day is a factor with 3 levels
>>
>> Using Subject ID number and Day as random effects is supposed to control
>> for pseudoreplication in the model, although I am not entirely sure that
>> this is specified in the correct way. I wanted to include experimental
>> replicate here too but the model failed to converge.
>>
>> My question is: is there a way to get p-values for the main fixed effects
>> of Diet, Infection and Day?
>>
>> If you need more specific model information or the model output I would be
>> happy to provide it.
>>
>> Thanks,
>> Megan
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From doogan.1 at osu.edu  Wed Mar  4 23:09:23 2015
From: doogan.1 at osu.edu (Doogan, Nathan)
Date: Wed, 4 Mar 2015 22:09:23 +0000
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
Message-ID: <69AD021970EB5C4181A53E9C165E0A6985308144@CIO-KRC-D1MBX05.osuad.osu.edu>

At last check, the summary() of a glmer() object does report p-values. It's output from lmer() that does not. I suppose I could be working with an older version...

-Nate



--
Nathan J. Doogan, Ph.D.
Post-Doctoral Researcher
College of Public Health
The Ohio State University

________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Megan Kutzer [makutzer at gmail.com]
Sent: Wednesday, March 04, 2015 3:11 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm

Hi,

I'm fairly new to mixed models and have done a lot of reading without much
success. Unfortunately there is no one at my institution who is really
familiar with them so I thought I would try this list.

I'm running a binomial generalized linear mixed effects model and I need
p-values for the main effects. I know this isn't entirely correct with this
type of model but my supervisor wants the p-values!

The model is:

glmer (Proportion hatched ~ Diet * Infection status * Day + (1|SubjectID) +
(1|Day), family=binomial)

where,

Proportion hatched = cbind(Offspring, Eggs-Offspring)
Diet is a factor with 2 levels
Infection status is a factor with 4 levels
Day is a factor with 3 levels

Using Subject ID number and Day as random effects is supposed to control
for pseudoreplication in the model, although I am not entirely sure that
this is specified in the correct way. I wanted to include experimental
replicate here too but the model failed to converge.

My question is: is there a way to get p-values for the main fixed effects
of Diet, Infection and Day?

If you need more specific model information or the model output I would be
happy to provide it.

Thanks,
Megan

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ken.beath at mq.edu.au  Wed Mar  4 23:34:22 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 5 Mar 2015 09:34:22 +1100
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
Message-ID: <CAF5_5cyh1fA+dtcxQhxoD5ZmAfnxrdPGPMRO7bXTNa5zcEpqmA@mail.gmail.com>

Did yo mean to have interactions between all 3 as "Diet * Infection status
* Day". With interactions it isn't possible to test for the effect of main
effects.

On 5 March 2015 at 07:11, Megan Kutzer <makutzer at gmail.com> wrote:

> Hi,
>
> I'm fairly new to mixed models and have done a lot of reading without much
> success. Unfortunately there is no one at my institution who is really
> familiar with them so I thought I would try this list.
>
> I'm running a binomial generalized linear mixed effects model and I need
> p-values for the main effects. I know this isn't entirely correct with this
> type of model but my supervisor wants the p-values!
>
> The model is:
>
> glmer (Proportion hatched ~ Diet * Infection status * Day + (1|SubjectID) +
> (1|Day), family=binomial)
>
> where,
>
> Proportion hatched = cbind(Offspring, Eggs-Offspring)
> Diet is a factor with 2 levels
> Infection status is a factor with 4 levels
> Day is a factor with 3 levels
>
> Using Subject ID number and Day as random effects is supposed to control
> for pseudoreplication in the model, although I am not entirely sure that
> this is specified in the correct way. I wanted to include experimental
> replicate here too but the model failed to converge.
>
> My question is: is there a way to get p-values for the main fixed effects
> of Diet, Infection and Day?
>
> If you need more specific model information or the model output I would be
> happy to provide it.
>
> Thanks,
> Megan
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From makutzer at gmail.com  Wed Mar  4 23:44:09 2015
From: makutzer at gmail.com (Megan Kutzer)
Date: Wed, 4 Mar 2015 23:44:09 +0100
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAF5_5cyh1fA+dtcxQhxoD5ZmAfnxrdPGPMRO7bXTNa5zcEpqmA@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
	<CAF5_5cyh1fA+dtcxQhxoD5ZmAfnxrdPGPMRO7bXTNa5zcEpqmA@mail.gmail.com>
Message-ID: <CAB7rHM0-FMibYMpf6misuEQweRrU4kGKqmd4H_GxVUN1c1_WAQ@mail.gmail.com>

No, sorry, the model is Diet + infection status + day and all the two way
interactions and the 3 way interaction.
On 4 Mar 2015 23:34, "Ken Beath" <ken.beath at mq.edu.au> wrote:

> Did yo mean to have interactions between all 3 as "Diet * Infection
> status * Day". With interactions it isn't possible to test for the effect
> of main effects.
>
> On 5 March 2015 at 07:11, Megan Kutzer <makutzer at gmail.com> wrote:
>
>> Hi,
>>
>> I'm fairly new to mixed models and have done a lot of reading without much
>> success. Unfortunately there is no one at my institution who is really
>> familiar with them so I thought I would try this list.
>>
>> I'm running a binomial generalized linear mixed effects model and I need
>> p-values for the main effects. I know this isn't entirely correct with
>> this
>> type of model but my supervisor wants the p-values!
>>
>> The model is:
>>
>> glmer (Proportion hatched ~ Diet * Infection status * Day + (1|SubjectID)
>> +
>> (1|Day), family=binomial)
>>
>> where,
>>
>> Proportion hatched = cbind(Offspring, Eggs-Offspring)
>> Diet is a factor with 2 levels
>> Infection status is a factor with 4 levels
>> Day is a factor with 3 levels
>>
>> Using Subject ID number and Day as random effects is supposed to control
>> for pseudoreplication in the model, although I am not entirely sure that
>> this is specified in the correct way. I wanted to include experimental
>> replicate here too but the model failed to converge.
>>
>> My question is: is there a way to get p-values for the main fixed effects
>> of Diet, Infection and Day?
>>
>> If you need more specific model information or the model output I would be
>> happy to provide it.
>>
>> Thanks,
>> Megan
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:11}}


From bbolker at gmail.com  Wed Mar  4 23:46:26 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 04 Mar 2015 17:46:26 -0500
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <69AD021970EB5C4181A53E9C165E0A6985308144@CIO-KRC-D1MBX05.osuad.osu.edu>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
	<69AD021970EB5C4181A53E9C165E0A6985308144@CIO-KRC-D1MBX05.osuad.osu.edu>
Message-ID: <54F78B42.4070802@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-04 05:09 PM, Doogan, Nathan wrote:
> At last check, the summary() of a glmer() object does report 
> p-values. It's output from lmer() that does not. I suppose I could
> be working with an older version...
> 
> -Nate
> 

 Yes (and has more or less for forever), although these are based on
Wald Z-scores.  Thanks to the reminder from Jonathan Baron about
?pvalues ...


> 
> 
> -- Nathan J. Doogan, Ph.D. Post-Doctoral Researcher College of
> Public Health The Ohio State University
> 
> ________________________________________ From: R-sig-mixed-models 
> [r-sig-mixed-models-bounces at r-project.org] on behalf of Megan
> Kutzer [makutzer at gmail.com] Sent: Wednesday, March 04, 2015 3:11 PM
> To: r-sig-mixed-models at r-project.org Subject: [R-sig-ME] extracting
> p values for main effects of binomial glmm
> 
> Hi,
> 
> I'm fairly new to mixed models and have done a lot of reading
> without much success. Unfortunately there is no one at my
> institution who is really familiar with them so I thought I would
> try this list.
> 
> I'm running a binomial generalized linear mixed effects model and
> I need p-values for the main effects. I know this isn't entirely 
> correct with this type of model but my supervisor wants the 
> p-values!
> 
> The model is:
> 
> glmer (Proportion hatched ~ Diet * Infection status * Day + 
> (1|SubjectID) + (1|Day), family=binomial)
> 
> where,
> 
> Proportion hatched = cbind(Offspring, Eggs-Offspring) Diet is a 
> factor with 2 levels Infection status is a factor with 4 levels
> Day is a factor with 3 levels
> 
> Using Subject ID number and Day as random effects is supposed to 
> control for pseudoreplication in the model, although I am not 
> entirely sure that this is specified in the correct way. I wanted
> to include experimental replicate here too but the model failed to 
> converge.
> 
> My question is: is there a way to get p-values for the main fixed 
> effects of Diet, Infection and Day?
> 
> If you need more specific model information or the model output I 
> would be happy to provide it.
> 
> Thanks, Megan
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU94tCAAoJEOCV5YRblxUHnPcIAKgay6VpUxGahQfi7JMsj43Z
iDPdR2d97ANFLqOXaZJpGktquGKtFbYGmua9XSyz4DSdl5bpX9n2hb+NYT4Secdo
1cVc28noVbP83Od6wHdJgyRWmzJ85onZ+m0t8CK2BtnJO4C/1GMUZwX9H4+F8g6N
ljbIaAD07AOmx14VF8l4XpW9guw3NNEOgKcupZBJ5K7zsLkkdtnLoAJZFCcxpypg
WdGcrcft82nJorqwcEYrjpqF/X9CzFvRIPAhf+cbZbDe06W98coM4RVNyLRXrLNE
2NKOKK2Pg5tHVAW6PnlaOBBuSCFgpSeWTQINDLda/Q3j5OUqmoCeLjpjjTb3A30=
=iWlw
-----END PGP SIGNATURE-----


From ken.beath at mq.edu.au  Wed Mar  4 23:56:36 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 5 Mar 2015 09:56:36 +1100
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAB7rHM0-FMibYMpf6misuEQweRrU4kGKqmd4H_GxVUN1c1_WAQ@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
	<CAF5_5cyh1fA+dtcxQhxoD5ZmAfnxrdPGPMRO7bXTNa5zcEpqmA@mail.gmail.com>
	<CAB7rHM0-FMibYMpf6misuEQweRrU4kGKqmd4H_GxVUN1c1_WAQ@mail.gmail.com>
Message-ID: <CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>

That is what I though you meant. In that case you can't discuss main
effects at all, as the effect of diet, for example, is different for each
combination of infection status and day. SAS and some other software will
attempt to give results but they aren't usually sensible.

On 5 March 2015 at 09:44, Megan Kutzer <makutzer at gmail.com> wrote:

> No, sorry, the model is Diet + infection status + day and all the two way
> interactions and the 3 way interaction.
> On 4 Mar 2015 23:34, "Ken Beath" <ken.beath at mq.edu.au> wrote:
>
>> Did yo mean to have interactions between all 3 as "Diet * Infection
>> status * Day". With interactions it isn't possible to test for the effect
>> of main effects.
>>
>> On 5 March 2015 at 07:11, Megan Kutzer <makutzer at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I'm fairly new to mixed models and have done a lot of reading without
>>> much
>>> success. Unfortunately there is no one at my institution who is really
>>> familiar with them so I thought I would try this list.
>>>
>>> I'm running a binomial generalized linear mixed effects model and I need
>>> p-values for the main effects. I know this isn't entirely correct with
>>> this
>>> type of model but my supervisor wants the p-values!
>>>
>>> The model is:
>>>
>>> glmer (Proportion hatched ~ Diet * Infection status * Day +
>>> (1|SubjectID) +
>>> (1|Day), family=binomial)
>>>
>>> where,
>>>
>>> Proportion hatched = cbind(Offspring, Eggs-Offspring)
>>> Diet is a factor with 2 levels
>>> Infection status is a factor with 4 levels
>>> Day is a factor with 3 levels
>>>
>>> Using Subject ID number and Day as random effects is supposed to control
>>> for pseudoreplication in the model, although I am not entirely sure that
>>> this is specified in the correct way. I wanted to include experimental
>>> replicate here too but the model failed to converge.
>>>
>>> My question is: is there a way to get p-values for the main fixed effects
>>> of Diet, Infection and Day?
>>>
>>> If you need more specific model information or the model output I would
>>> be
>>> happy to provide it.
>>>
>>> Thanks,
>>> Megan
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may contain
>> confidential information.  If you are not the intended recipient, please
>> delete it and notify the sender.  Views expressed in this message are those
>> of the individual sender, and are not necessarily the views of the Faculty
>> of Science, Department of Statistics or Macquarie University.
>>
>>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From makutzer at gmail.com  Thu Mar  5 00:00:08 2015
From: makutzer at gmail.com (Megan Kutzer)
Date: Thu, 5 Mar 2015 00:00:08 +0100
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
	<CAF5_5cyh1fA+dtcxQhxoD5ZmAfnxrdPGPMRO7bXTNa5zcEpqmA@mail.gmail.com>
	<CAB7rHM0-FMibYMpf6misuEQweRrU4kGKqmd4H_GxVUN1c1_WAQ@mail.gmail.com>
	<CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
Message-ID: <CAB7rHM2uxG9G209JCzDjgqVWGsMz3dybDRLZZ95D=FUiMLPE2w@mail.gmail.com>

Thanks everyone. I'll try to explain that to my supervisor.
On 4 Mar 2015 23:56, "Ken Beath" <ken.beath at mq.edu.au> wrote:

> That is what I though you meant. In that case you can't discuss main
> effects at all, as the effect of diet, for example, is different for each
> combination of infection status and day. SAS and some other software will
> attempt to give results but they aren't usually sensible.
>
> On 5 March 2015 at 09:44, Megan Kutzer <makutzer at gmail.com> wrote:
>
>> No, sorry, the model is Diet + infection status + day and all the two way
>> interactions and the 3 way interaction.
>> On 4 Mar 2015 23:34, "Ken Beath" <ken.beath at mq.edu.au> wrote:
>>
>>> Did yo mean to have interactions between all 3 as "Diet * Infection
>>> status * Day". With interactions it isn't possible to test for the effect
>>> of main effects.
>>>
>>> On 5 March 2015 at 07:11, Megan Kutzer <makutzer at gmail.com> wrote:
>>>
>>>> Hi,
>>>>
>>>> I'm fairly new to mixed models and have done a lot of reading without
>>>> much
>>>> success. Unfortunately there is no one at my institution who is really
>>>> familiar with them so I thought I would try this list.
>>>>
>>>> I'm running a binomial generalized linear mixed effects model and I need
>>>> p-values for the main effects. I know this isn't entirely correct with
>>>> this
>>>> type of model but my supervisor wants the p-values!
>>>>
>>>> The model is:
>>>>
>>>> glmer (Proportion hatched ~ Diet * Infection status * Day +
>>>> (1|SubjectID) +
>>>> (1|Day), family=binomial)
>>>>
>>>> where,
>>>>
>>>> Proportion hatched = cbind(Offspring, Eggs-Offspring)
>>>> Diet is a factor with 2 levels
>>>> Infection status is a factor with 4 levels
>>>> Day is a factor with 3 levels
>>>>
>>>> Using Subject ID number and Day as random effects is supposed to control
>>>> for pseudoreplication in the model, although I am not entirely sure that
>>>> this is specified in the correct way. I wanted to include experimental
>>>> replicate here too but the model failed to converge.
>>>>
>>>> My question is: is there a way to get p-values for the main fixed
>>>> effects
>>>> of Diet, Infection and Day?
>>>>
>>>> If you need more specific model information or the model output I would
>>>> be
>>>> happy to provide it.
>>>>
>>>> Thanks,
>>>> Megan
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>>
>>> --
>>>
>>> *Ken Beath*
>>> Lecturer
>>> Statistics Department
>>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>>
>>> Phone: +61 (0)2 9850 8516
>>>
>>> Building E4A, room 526
>>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>>
>>> CRICOS Provider No 00002J
>>> This message is intended for the addressee named and may contain
>>> confidential information.  If you are not the intended recipient, please
>>> delete it and notify the sender.  Views expressed in this message are those
>>> of the individual sender, and are not necessarily the views of the Faculty
>>> of Science, Department of Statistics or Macquarie University.
>>>
>>>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:11}}


From jbaldwin at fs.fed.us  Thu Mar  5 00:08:21 2015
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Wed, 4 Mar 2015 23:08:21 +0000
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
	<CAF5_5cyh1fA+dtcxQhxoD5ZmAfnxrdPGPMRO7bXTNa5zcEpqmA@mail.gmail.com>
	<CAB7rHM0-FMibYMpf6misuEQweRrU4kGKqmd4H_GxVUN1c1_WAQ@mail.gmail.com>
	<CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45691A55E930@001FSN2MPN1-061.001f.mgd2.msft.net>

I'd like to suggest that the phrase "we can't discuss main effects in the presence of a statistically significant interaction" isn't so cut-and-dry.  It depends.

If the size of the main effects is far greater than additional interaction effect, then one can certainly talk about main effects.  The catch is knowing about "practical" or "subject matter" significance as it is not solely a statistical issue.

It is the "interpretation" of results that can be problematic and not necessarily the fault of SAS or R or any other software package that provides the results.

Jim


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ken Beath
Sent: Wednesday, March 04, 2015 2:57 PM
To: Megan Kutzer
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] extracting p values for main effects of binomial glmm

That is what I though you meant. In that case you can't discuss main effects at all, as the effect of diet, for example, is different for each combination of infection status and day. SAS and some other software will attempt to give results but they aren't usually sensible.

On 5 March 2015 at 09:44, Megan Kutzer <makutzer at gmail.com> wrote:

> No, sorry, the model is Diet + infection status + day and all the two
> way interactions and the 3 way interaction.
> On 4 Mar 2015 23:34, "Ken Beath" <ken.beath at mq.edu.au> wrote:
>
>> Did yo mean to have interactions between all 3 as "Diet * Infection
>> status * Day". With interactions it isn't possible to test for the
>> effect of main effects.
>>
>> On 5 March 2015 at 07:11, Megan Kutzer <makutzer at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I'm fairly new to mixed models and have done a lot of reading
>>> without much success. Unfortunately there is no one at my
>>> institution who is really familiar with them so I thought I would
>>> try this list.
>>>
>>> I'm running a binomial generalized linear mixed effects model and I
>>> need p-values for the main effects. I know this isn't entirely
>>> correct with this type of model but my supervisor wants the
>>> p-values!
>>>
>>> The model is:
>>>
>>> glmer (Proportion hatched ~ Diet * Infection status * Day +
>>> (1|SubjectID) +
>>> (1|Day), family=binomial)
>>>
>>> where,
>>>
>>> Proportion hatched = cbind(Offspring, Eggs-Offspring) Diet is a
>>> factor with 2 levels Infection status is a factor with 4 levels Day
>>> is a factor with 3 levels
>>>
>>> Using Subject ID number and Day as random effects is supposed to
>>> control for pseudoreplication in the model, although I am not
>>> entirely sure that this is specified in the correct way. I wanted to
>>> include experimental replicate here too but the model failed to converge.
>>>
>>> My question is: is there a way to get p-values for the main fixed
>>> effects of Diet, Infection and Day?
>>>
>>> If you need more specific model information or the model output I
>>> would be happy to provide it.
>>>
>>> Thanks,
>>> Megan
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken
>> /
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may contain
>> confidential information.  If you are not the intended recipient,
>> please delete it and notify the sender.  Views expressed in this
>> message are those of the individual sender, and are not necessarily
>> the views of the Faculty of Science, Department of Statistics or Macquarie University.
>>
>>


--

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:16}}


From ken.beath at mq.edu.au  Thu Mar  5 00:25:13 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 5 Mar 2015 10:25:13 +1100
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <DDC5EC9B78340042B0D5A0C3789D45691A55E930@001FSN2MPN1-061.001f.mgd2.msft.net>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
	<CAF5_5cyh1fA+dtcxQhxoD5ZmAfnxrdPGPMRO7bXTNa5zcEpqmA@mail.gmail.com>
	<CAB7rHM0-FMibYMpf6misuEQweRrU4kGKqmd4H_GxVUN1c1_WAQ@mail.gmail.com>
	<CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45691A55E930@001FSN2MPN1-061.001f.mgd2.msft.net>
Message-ID: <CAF5_5czEtHX1x5AKxixBkzL=1tbWgeJLGpf1HpbcwCM+jKJprg@mail.gmail.com>

I'll agree with that, it just makes interpretation very difficult, and has
to be done carefully.

One thing I would check first is are the interactions needed?

On 5 March 2015 at 10:08, Baldwin, Jim -FS <jbaldwin at fs.fed.us> wrote:

> I'd like to suggest that the phrase "we can't discuss main effects in the
> presence of a statistically significant interaction" isn't so cut-and-dry.
> It depends.
>
> If the size of the main effects is far greater than additional interaction
> effect, then one can certainly talk about main effects.  The catch is
> knowing about "practical" or "subject matter" significance as it is not
> solely a statistical issue.
>
> It is the "interpretation" of results that can be problematic and not
> necessarily the fault of SAS or R or any other software package that
> provides the results.
>
> Jim
>
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ken Beath
> Sent: Wednesday, March 04, 2015 2:57 PM
> To: Megan Kutzer
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] extracting p values for main effects of binomial
> glmm
>
> That is what I though you meant. In that case you can't discuss main
> effects at all, as the effect of diet, for example, is different for each
> combination of infection status and day. SAS and some other software will
> attempt to give results but they aren't usually sensible.
>
> On 5 March 2015 at 09:44, Megan Kutzer <makutzer at gmail.com> wrote:
>
> > No, sorry, the model is Diet + infection status + day and all the two
> > way interactions and the 3 way interaction.
> > On 4 Mar 2015 23:34, "Ken Beath" <ken.beath at mq.edu.au> wrote:
> >
> >> Did yo mean to have interactions between all 3 as "Diet * Infection
> >> status * Day". With interactions it isn't possible to test for the
> >> effect of main effects.
> >>
> >> On 5 March 2015 at 07:11, Megan Kutzer <makutzer at gmail.com> wrote:
> >>
> >>> Hi,
> >>>
> >>> I'm fairly new to mixed models and have done a lot of reading
> >>> without much success. Unfortunately there is no one at my
> >>> institution who is really familiar with them so I thought I would
> >>> try this list.
> >>>
> >>> I'm running a binomial generalized linear mixed effects model and I
> >>> need p-values for the main effects. I know this isn't entirely
> >>> correct with this type of model but my supervisor wants the
> >>> p-values!
> >>>
> >>> The model is:
> >>>
> >>> glmer (Proportion hatched ~ Diet * Infection status * Day +
> >>> (1|SubjectID) +
> >>> (1|Day), family=binomial)
> >>>
> >>> where,
> >>>
> >>> Proportion hatched = cbind(Offspring, Eggs-Offspring) Diet is a
> >>> factor with 2 levels Infection status is a factor with 4 levels Day
> >>> is a factor with 3 levels
> >>>
> >>> Using Subject ID number and Day as random effects is supposed to
> >>> control for pseudoreplication in the model, although I am not
> >>> entirely sure that this is specified in the correct way. I wanted to
> >>> include experimental replicate here too but the model failed to
> converge.
> >>>
> >>> My question is: is there a way to get p-values for the main fixed
> >>> effects of Diet, Infection and Day?
> >>>
> >>> If you need more specific model information or the model output I
> >>> would be happy to provide it.
> >>>
> >>> Thanks,
> >>> Megan
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >>
> >> --
> >>
> >> *Ken Beath*
> >> Lecturer
> >> Statistics Department
> >> MACQUARIE UNIVERSITY NSW 2109, Australia
> >>
> >> Phone: +61 (0)2 9850 8516
> >>
> >> Building E4A, room 526
> >> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken
> >> /
> >>
> >> CRICOS Provider No 00002J
> >> This message is intended for the addressee named and may contain
> >> confidential information.  If you are not the intended recipient,
> >> please delete it and notify the sender.  Views expressed in this
> >> message are those of the individual sender, and are not necessarily
> >> the views of the Faculty of Science, Department of Statistics or
> Macquarie University.
> >>
> >>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and may...{{dropped:9}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> This electronic message contains information generated by the USDA solely
> for the intended recipients. Any unauthorized interception of this message
> or the use or disclosure of the information it contains may violate the law
> and subject the violator to civil or criminal penalties. If you believe you
> have received this message in error, please notify the sender and delete
> the email immediately.
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may contain
confidential information.  If you are not the intended recipient, please
delete it and notify the sender.  Views expressed in this message are those
of the individual sender, and are not necessarily the views of the Faculty
of Science, Department of Statistics or Macquarie University.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Mar  5 04:11:17 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 5 Mar 2015 03:11:17 +0000 (UTC)
Subject: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
	failed to reduce deviance in pwrssUpdate
References: <CAM7=EBTYycpeYLtLjdGWtDTGF6pxYX++zP-GmJO71OyK3rXYNQ@mail.gmail.com>
Message-ID: <loom.20150305T040807-558@post.gmane.org>

Elwyn Sharps <e.sharps at ...> writes:

> 

[snip]

> I am using a nest survival model (glmer) with random effects and a logistic
> exposure link function, as described here:
> 
> http://stackoverflow.com/questions/19012128/user-defined-link-function-for-
> glmer-for-known-fate-survival-modelling
> 
> I am running a number of different models, with varying fixed effects. Some
> of them are running well, with no error or warning messages, however
> for other models, I am getting the following message:
> 
> *Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate*
> 
> I'm not sure what is causing this error. I have tried to check the data for
> simple problems, however can't see anything that could be causing trouble.
> 
> I've also tried running the model without the random effects. This results
> in a different error message:
> 
> *Error: cannot find valid starting values: please specify some*

  Example data doesn't seem to be attached: it may have been
stripped by the mailing list software.  Can you post it somewhere
public and provide a URL?

  My guess it that there is something rather wonky about the data
for this example, e.g. complete separation (for example, no individuals
die for some combination of predictor variables).  Hard to say
without the data though.

  Ben Bolker


From e.sharps at gmail.com  Thu Mar  5 12:02:42 2015
From: e.sharps at gmail.com (Elwyn Sharps)
Date: Thu, 5 Mar 2015 11:02:42 +0000
Subject: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
 failed to reduce deviance in pwrssUpdate
In-Reply-To: <loom.20150305T040807-558@post.gmane.org>
References: <CAM7=EBTYycpeYLtLjdGWtDTGF6pxYX++zP-GmJO71OyK3rXYNQ@mail.gmail.com>
	<loom.20150305T040807-558@post.gmane.org>
Message-ID: <CAM7=EBTPJQb0CKuyOhkafsMou+mnwOdKMsANsXbM7iJa5ob9Vg@mail.gmail.com>

Hi Ben

Thank you very much for your reply. If you click on this link, it should
give you the data in a CSV file.
https://sites.google.com/site/es263datahlp/habitat-type_example.csv

Many thanks

Elwyn

On 5 March 2015 at 03:11, Ben Bolker <bbolker at gmail.com> wrote:

> Elwyn Sharps <e.sharps at ...> writes:
>
> >
>
> [snip]
>
> > I am using a nest survival model (glmer) with random effects and a
> logistic
> > exposure link function, as described here:
> >
> >
> http://stackoverflow.com/questions/19012128/user-defined-link-function-for-
> > glmer-for-known-fate-survival-modelling
> >
> > I am running a number of different models, with varying fixed effects.
> Some
> > of them are running well, with no error or warning messages, however
> > for other models, I am getting the following message:
> >
> > *Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> > pwrssUpdate*
> >
> > I'm not sure what is causing this error. I have tried to check the data
> for
> > simple problems, however can't see anything that could be causing
> trouble.
> >
> > I've also tried running the model without the random effects. This
> results
> > in a different error message:
> >
> > *Error: cannot find valid starting values: please specify some*
>
>   Example data doesn't seem to be attached: it may have been
> stripped by the mailing list software.  Can you post it somewhere
> public and provide a URL?
>
>   My guess it that there is something rather wonky about the data
> for this example, e.g. complete separation (for example, no individuals
> die for some combination of predictor variables).  Hard to say
> without the data though.
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From henrik.singmann at psychologie.uni-freiburg.de  Thu Mar  5 12:25:23 2015
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Thu, 05 Mar 2015 12:25:23 +0100
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
Message-ID: <54F83D23.3060207@psychologie.uni-freiburg.de>

Hi,

As others have pointed out, the issue of obtaining p-values for effects is not trivial and there are pitfalls. Nevertheless I think that the easiest way to obtain what you want is to use mixed(..., method = "LRT") from package afex (full disclaimer: I am the main author of said package and function).

mixed() takes care of some issues, such as using appropriate coding and how to test main effects in the presence of interactions, in not uncontroversial but sensible ways (e.g., it does the latter by simply removing the main effect in a brute-force manner from the model-matrix and compare the full with the so reduced model). The way things are handled in mixed might not be correct in all cases but may provide exactly the combination of ease of use with sensible defaults that may be helpful in your case. In other words, it tries to adopt an approach often taken by commercial statistics packages.

You simply call mixed instead of glmer which fits and refits various versions of the model to provide likelihood-ratio tests for all effects as you want them. Note however, that mixed() cannot deal with the way you specify the model using cbind() as dependent variable. What you need to do is compute the proportions of "successes" and pass the number of observations as weights. Assuming your data resides in a data.frame df this would result in something along the following lines:


df$prop_weights <- df$Offspring + df$Eggs_Offspring
df$proportion_hatched <- df$Offspring/df$prop_weights

m1 <- mixed(proportion_hatched ~ Diet * Infection_status * Day + (1|SubjectID) + (1|Day), data = df, family=binomial, weights = df$proportion_weights, method = "LRT")

However, as Ken Beath has said, the main effects may not be sensible given interactions. To asses the degree of this threat for your data (which very much much depends on the type of interaction and their size) I suggest to follow the excellent advice of fortune(193) to "take the unusual step of plotting the data." This can be done nicely with e.g., the effects package, even for complicated interactions and binomial mixed models.

Hope this helps,
Henrik


Am 04.03.2015 um 21:11 schrieb Megan Kutzer:
> Hi,
>
> I'm fairly new to mixed models and have done a lot of reading without much
> success. Unfortunately there is no one at my institution who is really
> familiar with them so I thought I would try this list.
>
> I'm running a binomial generalized linear mixed effects model and I need
> p-values for the main effects. I know this isn't entirely correct with this
> type of model but my supervisor wants the p-values!
>
> The model is:
>
> glmer (Proportion hatched ~ Diet * Infection status * Day + (1|SubjectID) +
> (1|Day), family=binomial)
>
> where,
>
> Proportion hatched = cbind(Offspring, Eggs-Offspring)
> Diet is a factor with 2 levels
> Infection status is a factor with 4 levels
> Day is a factor with 3 levels
>
> Using Subject ID number and Day as random effects is supposed to control
> for pseudoreplication in the model, although I am not entirely sure that
> this is specified in the correct way. I wanted to include experimental
> replicate here too but the model failed to converge.
>
> My question is: is there a way to get p-values for the main fixed effects
> of Diet, Infection and Day?
>
> If you need more specific model information or the model output I would be
> happy to provide it.
>
> Thanks,
> Megan
>
> 	[[alternative HTML version deleted]]
>

-- 
Dr. Henrik Singmann
Universit?t Z?rich, Schweiz
http://singmann.org


From zsa11 at mail.aub.edu  Thu Mar  5 12:08:37 2015
From: zsa11 at mail.aub.edu (Zahwa Al Ayyash (Student))
Date: Thu, 5 Mar 2015 11:08:37 +0000
Subject: [R-sig-ME] Zero-inflated mixed models
In-Reply-To: <loom.20150304T031529-621@post.gmane.org>
References: <1424905368937.78449@mail.aub.edu>,
	<loom.20150304T031529-621@post.gmane.org>
Message-ID: <53C2E25A-2182-45A7-9403-6036FCBF3DD4@mail.aub.edu>

Thank you both for your responses!

> On Mar 4, 2015, at 4:21 AM, "Ben Bolker" <bbolker at gmail.com> wrote:
> 
> Zahwa Al Ayyash (Student <zsa11 at ...> writes:
> 
>> 
>> Dear all,
>> 
>> Zero-inflated models have a count component 
>> (Poisson/Neg. Binomial) and a zero component (logistic
>> regression part).
> 
>> glmmADMB supports the zero-inflation feature but only through
>> estimating a zero-inflation parameter that is assumed constant
>> across the whole data set?.
> 
>>  1.  ?Why doesn't the glmmadmb support the two-stage fitting of
>> zero-inflated models like it does with hurdle models? I once read
>> that its estimation might be more complex than that of hurdle
>> models. Is that true? If yes, why?
> 
>  It doesn't support it because we never got around to implementing
> it -- i.e. making sure the interface was well designed, implementing,
> and testing.
> 
>>  2.  Is there an R package that allows for the two-model fitting
>> (i.e., each model with its own covariates) of ZIP or ZINB (not
>> hurdle) and allowing for a random effect?
> 
>  You can take a look the stuff here:
> 
> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls
> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/R/owls_R_funs.R
> 
> search for 'zipme.f' in the source code.
> 
>  Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From stevedrd at yahoo.com  Thu Mar  5 19:14:37 2015
From: stevedrd at yahoo.com (Steve Denham)
Date: Thu, 5 Mar 2015 18:14:37 +0000 (UTC)
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
References: <CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
Message-ID: <365114960.1370806.1425579277900.JavaMail.yahoo@mail.yahoo.com>

Hmm. ?I have never had a problem interpreting interactions that I got from SAS procedures (MIXED, GLIMMIX, HPMIXED). ?What do you mean as 'not sensible'?
Thanks,?Steve Denham
Director, Biostatistics
MPI Research, Inc.
 
      From: Ken Beath <ken.beath at mq.edu.au>
 To: Megan Kutzer <makutzer at gmail.com> 
Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Sent: Wednesday, March 4, 2015 5:56 PM
 Subject: Re: [R-sig-ME] extracting p values for main effects of binomial glmm
   
That is what I though you meant. In that case you can't discuss main
effects at all, as the effect of diet, for example, is different for each
combination of infection status and day. SAS and some other software will
attempt to give results but they aren't usually sensible.

On 5 March 2015 at 09:44, Megan Kutzer <makutzer at gmail.com> wrote:

> No, sorry, the model is Diet + infection status + day and all the two way
> interactions and the 3 way interaction.
> On 4 Mar 2015 23:34, "Ken Beath" <ken.beath at mq.edu.au> wrote:
>
>> Did yo mean to have interactions between all 3 as "Diet * Infection
>> status * Day". With interactions it isn't possible to test for the effect
>> of main effects.
>>
>> On 5 March 2015 at 07:11, Megan Kutzer <makutzer at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I'm fairly new to mixed models and have done a lot of reading without
>>> much
>>> success. Unfortunately there is no one at my institution who is really
>>> familiar with them so I thought I would try this list.
>>>
>>> I'm running a binomial generalized linear mixed effects model and I need
>>> p-values for the main effects. I know this isn't entirely correct with
>>> this
>>> type of model but my supervisor wants the p-values!
>>>
>>> The model is:
>>>
>>> glmer (Proportion hatched ~ Diet * Infection status * Day +
>>> (1|SubjectID) +
>>> (1|Day), family=binomial)
>>>
>>> where,
>>>
>>> Proportion hatched = cbind(Offspring, Eggs-Offspring)
>>> Diet is a factor with 2 levels
>>> Infection status is a factor with 4 levels
>>> Day is a factor with 3 levels
>>>
>>> Using Subject ID number and Day as random effects is supposed to control
>>> for pseudoreplication in the model, although I am not entirely sure that
>>> this is specified in the correct way. I wanted to include experimental
>>> replicate here too but the model failed to converge.
>>>
>>> My question is: is there a way to get p-values for the main fixed effects
>>> of Diet, Infection and Day?
>>>
>>> If you need more specific model information or the model output I would
>>> be
>>> happy to provide it.
>>>
>>> Thanks,
>>> Megan
>>>
>>>? ? ? ? [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may contain
>> confidential information.? If you are not the intended recipient, please
>> delete it and notify the sender.? Views expressed in this message are those
>> of the individual sender, and are not necessarily the views of the Faculty
>> of Science, Department of Statistics or Macquarie University.
>>
>>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:14}}


From baron at psych.upenn.edu  Thu Mar  5 20:13:29 2015
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 5 Mar 2015 14:13:29 -0500
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <365114960.1370806.1425579277900.JavaMail.yahoo@mail.yahoo.com>
References: <CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
	<365114960.1370806.1425579277900.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20150305191329.GA13964@psych.upenn.edu>

I can't resist butting in here on the general problem of interpreting
main effects when interactions are included in the model, even though
this was not the original topic. The standard advice is that you
should be "very careful" when you do this, but what should you be
careful ABOUT?

I think the most common answer is this: Think of a graph in which Y is
the dependent variable, X1 is 2-level factor, and X2 is another
variable. The graph has one line for each level of X1. If there is no
X1*X2 interaction, they are parallel lines, and the distance between
them is the main effect of X1. If there is an X1*X2 interaction, then
the distance between them depends on X2. If the lines are straight and
lone enough, they will cross somewhere. So what does the main effect
mean?

What it means in the output of the function is the intercept when X2
is zero. This will change if you simply add/subtract a constant from
your measure of X2, although the measure of the interaction will not
change. Thus, the scaling of X2 is crucial for looking at main effects
when interactions are present, although it doesn't matter for looking
at the interaction. If you don't have a natural way to define the zero
point of X2, then it could be meaningless to talk about THE main
effect of X1.

In some cases you can define the level of X2 so that this intercept is
exactly what you want to know. For example, X2 could be some
contaminating variable whose effect you want to remove, and it could
be positive or negative, with effects in opposite directions, but when
it is zero it cannot have an effect. In this case, the intercept when
X2 is 0 is exactly what you want. You do NOT want to remove the
interaction term from the model, because then the main effect will
depend on the distribution of X2. But you want to know what happens
when X2 is zero and thus has no effect. In this case, then, you want
to examine the main effect in the presence of the interaction.

On 03/05/15 18:14, Steve Denham via R-sig-mixed-models wrote:
>Hmm. ? I have never had a problem interpreting interactions that I got from SAS 
>procedures (MIXED, GLIMMIX, HPMIXED). ? What do you mean as 'not sensible'?
>Thanks,? Steve Denham
>Director, Biostatistics
>MPI Research, Inc.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From Paul.Thompson at SanfordHealth.org  Thu Mar  5 21:03:49 2015
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Thu, 5 Mar 2015 20:03:49 +0000
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <20150305191329.GA13964@psych.upenn.edu>
References: <CAF5_5cyZQtQwL7dL7GE-4AsPu+84xQ3t+OtPXmASoJ-YoFHE8w@mail.gmail.com>
	<365114960.1370806.1425579277900.JavaMail.yahoo@mail.yahoo.com>,
	<20150305191329.GA13964@psych.upenn.edu>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D970153548CD4@SFSMCEXMBX3.sanfordhealth.org>

The issue with interactions is that the two factors have differing differences. Sometimes the interactions are CROSSING. Sometimes they are DIVERGENT. However, they simply mean that UNCONDITIONAL statements are incorrect.

Consider Factors A and B which interact. 

1) What is the main problem? If you wish to say "Level A1 is higher than Level A2", an interaction makes this unwise. UNCONDITIONAL statements cannot be made.

2) What is a solution? Do not make UNCONDITIONAL statements. Make CONDITIONAL statements. These are termed "simple main effets" or "designed contrasts". If you say "Level A1 is higher than Level A2 for B1 cases, but Level A1 is lower than Level A2 for B2 cases". This statement is not UNCONDITIONAL. 

It's really not a problem. It just depends on what you wish to do.

________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jonathan Baron [baron at psych.upenn.edu]
Sent: Thursday, March 05, 2015 1:13 PM
To: Steve Denham
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] extracting p values for main effects of binomial glmm

I can't resist butting in here on the general problem of interpreting
main effects when interactions are included in the model, even though
this was not the original topic. The standard advice is that you
should be "very careful" when you do this, but what should you be
careful ABOUT?

I think the most common answer is this: Think of a graph in which Y is
the dependent variable, X1 is 2-level factor, and X2 is another
variable. The graph has one line for each level of X1. If there is no
X1*X2 interaction, they are parallel lines, and the distance between
them is the main effect of X1. If there is an X1*X2 interaction, then
the distance between them depends on X2. If the lines are straight and
lone enough, they will cross somewhere. So what does the main effect
mean?

What it means in the output of the function is the intercept when X2
is zero. This will change if you simply add/subtract a constant from
your measure of X2, although the measure of the interaction will not
change. Thus, the scaling of X2 is crucial for looking at main effects
when interactions are present, although it doesn't matter for looking
at the interaction. If you don't have a natural way to define the zero
point of X2, then it could be meaningless to talk about THE main
effect of X1.

In some cases you can define the level of X2 so that this intercept is
exactly what you want to know. For example, X2 could be some
contaminating variable whose effect you want to remove, and it could
be positive or negative, with effects in opposite directions, but when
it is zero it cannot have an effect. In this case, the intercept when
X2 is 0 is exactly what you want. You do NOT want to remove the
interaction term from the model, because then the main effect will
depend on the distribution of X2. But you want to know what happens
when X2 is zero and thus has no effect. In this case, then, you want
to examine the main effect in the presence of the interaction.

On 03/05/15 18:14, Steve Denham via R-sig-mixed-models wrote:
>Hmm. ? I have never had a problem interpreting interactions that I got from SAS
>procedures (MIXED, GLIMMIX, HPMIXED). ? What do you mean as 'not sensible'?
>Thanks,? Steve Denham
>Director, Biostatistics
>MPI Research, Inc.

--
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.

From john.maindonald at anu.edu.au  Thu Mar  5 21:08:41 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 5 Mar 2015 20:08:41 +0000
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <54F83D23.3060207@psychologie.uni-freiburg.de>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>
	<54F83D23.3060207@psychologie.uni-freiburg.de>
Message-ID: <70BFA22C-D4E6-41B0-ABD6-228EA453CA83@anu.edu.au>

An issue that has not been raised so far is whether the binomial or 
other GLM type variance takes account of all relevant observation 
level sources of variation.  This is pertinent for all generalised linear
mixed models.

Over-dispersed binomial or Poisson is in my experience much more
common (certainly, e.g. in such areas as ecology) than binomial or
Poisson.  The effect on the variance can be huge, multiplying by a
factor of 3 or 4 or more.  More generally, the multiplier may not be a
constant factor.  This issue is most serious for comparisons where
the relevant variances are the observation level variances.

With glmer(), one way to handle this is to fit an observation level
random effect; the multiplier is not then a constant factor.  glmer() did
at one time allow a constant multiplier.  I think it unfortunate that this
was removed, as it restricted the options available.   Using negative
binomial errors is in principle another possibility, but such models
can be difficult to get to converge.  If the model is wrong, it may well
not converge, which is an obstacle to getting to the point where one
has something half-sensible that does converge ? this is the case 
for glm.nb() as well as for glmer.nb().

With predicted probabilities that are close to 0 or 1, or Poisson means 
that are close to 0, the Hauck-Donner effect where the standard errors
for Wald statistics become nonsense and z-statistics become smaller
as the distance between means that are to be compared increases,
is something more to worry about.

I guess the message is that this is treacherous territory, and it really
is necessary to know what one is doing!

I?d like to echo Jonathon Baron?s comments on the ?main effects in
the presence of interactions issue."

John Maindonald             email: john.maindonald at anu.edu.au
Wellington, NZ

On 6/03/2015, at 0:25, Henrik Singmann <henrik.singmann at psychologie.uni-freiburg.de> wrote:

> Hi,
> 
> As others have pointed out, the issue of obtaining p-values for effects is not trivial and there are pitfalls. Nevertheless I think that the easiest way to obtain what you want is to use mixed(..., method = "LRT") from package afex (full disclaimer: I am the main author of said package and function).
> 
> mixed() takes care of some issues, such as using appropriate coding and how to test main effects in the presence of interactions, in not uncontroversial but sensible ways (e.g., it does the latter by simply removing the main effect in a brute-force manner from the model-matrix and compare the full with the so reduced model). The way things are handled in mixed might not be correct in all cases but may provide exactly the combination of ease of use with sensible defaults that may be helpful in your case. In other words, it tries to adopt an approach often taken by commercial statistics packages.
> 
> You simply call mixed instead of glmer which fits and refits various versions of the model to provide likelihood-ratio tests for all effects as you want them. Note however, that mixed() cannot deal with the way you specify the model using cbind() as dependent variable. What you need to do is compute the proportions of "successes" and pass the number of observations as weights. Assuming your data resides in a data.frame df this would result in something along the following lines:
> 
> 
> df$prop_weights <- df$Offspring + df$Eggs_Offspring
> df$proportion_hatched <- df$Offspring/df$prop_weights
> 
> m1 <- mixed(proportion_hatched ~ Diet * Infection_status * Day + (1|SubjectID) + (1|Day), data = df, family=binomial, weights = df$proportion_weights, method = "LRT")
> 
> However, as Ken Beath has said, the main effects may not be sensible given interactions. To asses the degree of this threat for your data (which very much much depends on the type of interaction and their size) I suggest to follow the excellent advice of fortune(193) to "take the unusual step of plotting the data." This can be done nicely with e.g., the effects package, even for complicated interactions and binomial mixed models.
> 
> Hope this helps,
> Henrik
> 
> 
> Am 04.03.2015 um 21:11 schrieb Megan Kutzer:
>> Hi,
>> 
>> I'm fairly new to mixed models and have done a lot of reading without much
>> success. Unfortunately there is no one at my institution who is really
>> familiar with them so I thought I would try this list.
>> 
>> I'm running a binomial generalized linear mixed effects model and I need
>> p-values for the main effects. I know this isn't entirely correct with this
>> type of model but my supervisor wants the p-values!
>> 
>> The model is:
>> 
>> glmer (Proportion hatched ~ Diet * Infection status * Day + (1|SubjectID) +
>> (1|Day), family=binomial)
>> 
>> where,
>> 
>> Proportion hatched = cbind(Offspring, Eggs-Offspring)
>> Diet is a factor with 2 levels
>> Infection status is a factor with 4 levels
>> Day is a factor with 3 levels
>> 
>> Using Subject ID number and Day as random effects is supposed to control
>> for pseudoreplication in the model, although I am not entirely sure that
>> this is specified in the correct way. I wanted to include experimental
>> replicate here too but the model failed to converge.
>> 
>> My question is: is there a way to get p-values for the main fixed effects
>> of Diet, Infection and Day?
>> 
>> If you need more specific model information or the model output I would be
>> happy to provide it.
>> 
>> Thanks,
>> Megan
>> 
>> 	[[alternative HTML version deleted]]
>> 
> 
> -- 
> Dr. Henrik Singmann
> Universit?t Z?rich, Schweiz
> http://singmann.org
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Mar  5 21:29:59 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 05 Mar 2015 15:29:59 -0500
Subject: [R-sig-ME] extracting p values for main effects of binomial glmm
In-Reply-To: <70BFA22C-D4E6-41B0-ABD6-228EA453CA83@anu.edu.au>
References: <CAB7rHM2nLsy0L90EAWrH2Sr9H0_Kd0vODKEA-E02UpUH5cfeqA@mail.gmail.com>	<54F83D23.3060207@psychologie.uni-freiburg.de>
	<70BFA22C-D4E6-41B0-ABD6-228EA453CA83@anu.edu.au>
Message-ID: <54F8BCC7.2010002@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-05 03:08 PM, John Maindonald wrote:
> An issue that has not been raised so far is whether the binomial or
>  other GLM type variance takes account of all relevant observation
>  level sources of variation.  This is pertinent for all
> generalised linear mixed models.
> 
> Over-dispersed binomial or Poisson is in my experience much more 
> common (certainly, e.g. in such areas as ecology) than binomial or
>  Poisson.  The effect on the variance can be huge, multiplying by a
>  factor of 3 or 4 or more.  More generally, the multiplier may not
> be a constant factor.  This issue is most serious for comparisons
> where the relevant variances are the observation level variances.
> 
> With glmer(), one way to handle this is to fit an observation level
>  random effect; the multiplier is not then a constant factor.
> glmer() did at one time allow a constant multiplier.  I think it
> unfortunate that this was removed, as it restricted the options
> available.

  It was removed because we (Doug Bates in particular) decided that we
really didn't understand at a theoretical level what the quasi- model
was doing, and that it sometimes seemed to be producing unreasonable
outputs.  That doesn't mean it *can't* be understood at a theoretical
level -- in principle, it should act similarly to other conditional
response distributions with free scale parameters, which we do allow
(e.g. Gamma) -- but this is still on our very long list of things to try
to figure out.

> Using negative binomial errors is in principle another possibility,
> but such models can be difficult to get to converge.  If the model
> is wrong, it may well not converge, which is an obstacle to getting
> to the point where one has something half-sensible that does
> converge ? this is the case for glm.nb() as well as for
> glmer.nb().

  For what it's worth glmmADMB (which operates in a general
optimization framework, not in a GLM-like IRLS mode) allows both NB2
(negative binomial parameterized in the traditional V=mu*(1+mu/k) way)
and NB1 (negative binomial parameterized so that V=phi*mu, as in the
quasi-Poisson case)



> 
> With predicted probabilities that are close to 0 or 1, or Poisson 
> means that are close to 0, the Hauck-Donner effect where the
> standard errors for Wald statistics become nonsense and
> z-statistics become smaller as the distance between means that are
> to be compared increases, is something more to worry about.

  Well in this case, just use profile confidence intervals or LRTs.  At
least it's usually pretty obvious when this is happening.

> 
> I guess the message is that this is treacherous territory, and it 
> really is necessary to know what one is doing!

  Yes; we have all of the complexities of linear models, GLMs (which
seem to be the issues you are pointing out here), and mixed models on
top of that ...

> 
> I?d like to echo Jonathon Baron?s comments on the ?main effects in
>  the presence of interactions issue."
> 
> John Maindonald             email: john.maindonald at anu.edu.au 
> Wellington, NZ
> 
> On 6/03/2015, at 0:25, Henrik Singmann 
> <henrik.singmann at psychologie.uni-freiburg.de> wrote:
> 
>> Hi,
>> 
>> As others have pointed out, the issue of obtaining p-values for 
>> effects is not trivial and there are pitfalls. Nevertheless I
>> think that the easiest way to obtain what you want is to use
>> mixed(..., method = "LRT") from package afex (full disclaimer: I
>> am the main author of said package and function).
>> 
>> mixed() takes care of some issues, such as using appropriate
>> coding and how to test main effects in the presence of
>> interactions, in not uncontroversial but sensible ways (e.g., it
>> does the latter by simply removing the main effect in a
>> brute-force manner from the model-matrix and compare the full
>> with the so reduced model). The way things are handled in mixed
>> might not be correct in all cases but may provide exactly the
>> combination of ease of use with sensible defaults that may be
>> helpful in your case. In other words, it tries to adopt an
>> approach often taken by commercial statistics packages.
>> 
>> You simply call mixed instead of glmer which fits and refits 
>> various versions of the model to provide likelihood-ratio tests
>> for all effects as you want them. Note however, that mixed()
>> cannot deal with the way you specify the model using cbind() as
>> dependent variable. What you need to do is compute the
>> proportions of "successes" and pass the number of observations as
>> weights. Assuming your data resides in a data.frame df this would
>> result in something along the following lines:
>> 
>> 
>> df$prop_weights <- df$Offspring + df$Eggs_Offspring 
>> df$proportion_hatched <- df$Offspring/df$prop_weights
>> 
>> m1 <- mixed(proportion_hatched ~ Diet * Infection_status * Day + 
>> (1|SubjectID) + (1|Day), data = df, family=binomial, weights = 
>> df$proportion_weights, method = "LRT")
>> 
>> However, as Ken Beath has said, the main effects may not be 
>> sensible given interactions. To asses the degree of this threat
>> for your data (which very much much depends on the type of
>> interaction and their size) I suggest to follow the excellent
>> advice of fortune(193) to "take the unusual step of plotting the
>> data." This can be done nicely with e.g., the effects package,
>> even for complicated interactions and binomial mixed models.
>> 
>> Hope this helps, Henrik
>> 
>> 
>> Am 04.03.2015 um 21:11 schrieb Megan Kutzer:
>>> Hi,
>>> 
>>> I'm fairly new to mixed models and have done a lot of reading 
>>> without much success. Unfortunately there is no one at my 
>>> institution who is really familiar with them so I thought I
>>> would try this list.
>>> 
>>> I'm running a binomial generalized linear mixed effects model
>>> and I need p-values for the main effects. I know this isn't
>>> entirely correct with this type of model but my supervisor
>>> wants the p-values!
>>> 
>>> The model is:
>>> 
>>> glmer (Proportion hatched ~ Diet * Infection status * Day + 
>>> (1|SubjectID) + (1|Day), family=binomial)
>>> 
>>> where,
>>> 
>>> Proportion hatched = cbind(Offspring, Eggs-Offspring) Diet is
>>> a factor with 2 levels Infection status is a factor with 4
>>> levels Day is a factor with 3 levels
>>> 
>>> Using Subject ID number and Day as random effects is supposed
>>> to control for pseudoreplication in the model, although I am
>>> not entirely sure that this is specified in the correct way. I
>>> wanted to include experimental replicate here too but the model
>>> failed to converge.
>>> 
>>> My question is: is there a way to get p-values for the main
>>> fixed effects of Diet, Infection and Day?
>>> 
>>> If you need more specific model information or the model output
>>> I would be happy to provide it.
>>> 
>>> Thanks, Megan
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>> 
>> -- Dr. Henrik Singmann Universit?t Z?rich, Schweiz 
>> http://singmann.org
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU+LzHAAoJEOCV5YRblxUHhoEH/3/vP0pnOgluZ9gw77eh3p//
UOPuJgv1iYViJMatg1G5Aq4LxXDduTPPDqrOgEFji+/1D/7x5DH7cYb6e6AVeZbA
jNPOVXPX66ER/8NDF5l2VT1To+anMtRZ2aKNusDS2ntdx1Xofqlzk1WShNlEstMM
fhKTGf2s1IKdZwFrXcVdb5u9a9SFYbFisy/U3lx5LmNEJn1wnyg23e709PFjSZMv
N4/BeaN8fUUYYRSS9XzGV0Q3ZKkVqE8z0idPto5LaQIMmDc04ny9DHPbg6iG4J/y
i5zCE/j/DnhI7N/LVgDuQQvlYWURpWHcvDqncj4a6jXBnKfwRIG0hzFTr4I2KWg=
=G8uO
-----END PGP SIGNATURE-----


From tibor at linguistics.rub.de  Fri Mar  6 08:16:12 2015
From: tibor at linguistics.rub.de (Tibor Kiss)
Date: Fri, 6 Mar 2015 08:16:12 +0100
Subject: [R-sig-ME] Comparing Odds ratios in two different binomial GLMM
Message-ID: <B17B5ABE-347A-4606-A50B-97B6F615D804@linguistics.rub.de>

Dear list,

I have a question concerning the comparison of two binomial GLMMs (random intercept models) with partially different factors. I am investigating possible syntactic realizations of German prepositions (English: "on the bus" etc.). The question emerges from my comparison of a model for the preposition *mit* (with) and *unter* (under), for reference, the glmm at calls are provided below. 

The two GLMMs have a factor in common with seven levels (nominal_dep_mod), where the levels describe whether the noun in the phrase ("bus" in the example above) shows an extension or not (like ? somewhat artificially ? "on the bus straight out of Compton"). I would like to compare the odds ratios for this common factor, and if I just compare them, then the results are what I would expect from looking into the data:  for one of the prepositions one level of nominal_dep_mod has a much stronger influence than for the other preposition: an odds ratio of 64 vs. an odds ratio of 4, while the other levels are on a par. Simplifying things somewhat, the  factor nominal_dep_mod determines whether the presence of an extension makes the realization of a determiner (*the*) more or less likely. So for one preposition, it makes it much more likely, while for the other, it makes it just more likely. 

The contrasts for both models are set so that nominal_dep_mod starts with the same reference level (no extension). 

But the other fixed effects for the two models differ, partly because the interpretation of the prepositions play a role, and the possible interpretations of *with* differ from the ones for *under*. Furthermore, the model for *mit* has more fixed effects than the other one, and the fixed effects have more (and different) levels  ? and naturally, the random effects differ in number, as well in their contribution to the models.  

I have added the two calls as well as the xtabs for nominal_dep_mod for reference. 

My perhaps somewhat basic question is: Given the two models, am I justified to assume the interpretation of the odds ratio given above?

Thanks a lot.

With kind regards

Tibor


> unter.050315.glmm at call
glmer(formula = determiner ~ nominal_dep_mod + adja_in_hit + 
    TN_LEX_nominalisierung + prep_meaning + (1 | target_noun_lemma), 
    data = unter.050315.data, family = binomial(), contrasts = list(prep_meaning = contr.treatment(levels(unter.050315.data$prep_meaning), 2), 
    nominal_dep_mod = contr.treatment(levels(unter.050315.data$nominal_dep_mod), 4)))  

> xtabs(~prep_meaning, unter.050315.data)
prep_meaning
konditional       lokal       modal     regiert  restriktiv   zuordnung     zustand 
        363        3026         759          63         101        1003          23 

> mit.050315.glmm at call
glmer(formula = determiner ~ adja_in_hit + nominal_dep_mod + 
    TN_LEX_nominalisierung + prep_meaning + TN_LEX_GN_Kommunikation + 
    TN_LEX_GN_Besitz + TN_LEX_GN_Attribut + TN_LEX_GN_Geschehen + 
    (1 | target_noun_lemma), data = mit.050315.data, family = binomial(), 
    contrasts = list(prep_meaning = contr.treatment(levels(mit.050315.data$prep_meaning), 14), nominal_dep_mod = contr.treatment(levels(mit.050315.data$nominal_dep_mod), 4)))

> xtabs(~prep_meaning, mit.050315.data)
prep_meaning
abhaengigkeit   beteiligung   bezugspunkt     indikator   konditional korrespondenz         modal   realisation       regiert    restriktiv 
           52           3346           441                    204           733             1                             4826           361          3298            26 
stellungnahme      temporal       vorgang vorhandensein     zuordnung 
           30               69                 439          3582                  10 




   	 	
Prof. Dr. Tibor Kiss, Sprachwissenschaftliches Institut
Ruhr-Universit?t Bochum D-44780 Bochum
Office: +49-234-322-5114

 


	[[alternative HTML version deleted]]


From e.sharps at gmail.com  Fri Mar  6 11:14:23 2015
From: e.sharps at gmail.com (Elwyn Sharps)
Date: Fri, 6 Mar 2015 10:14:23 +0000
Subject: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
 failed to reduce deviance in pwrssUpdate
Message-ID: <CAM7=EBRe+KSK-zk=zC0YUsbvoGypAi-Yu=Ek3O+YqFVwNC98Lw@mail.gmail.com>

Hi Ben

Thank you very much for your reply. If you click on this link, it should
give you the data in a CSV file.
https://sites.google.com/site/es263datahlp/habitat-type_example.csv

Many thanks

Elwyn

On 5 March 2015 at 03:11, Ben Bolker <bbolker at gmail.com> wrote:

> Elwyn Sharps <e.sharps at ...> writes:
>
> >
>
> [snip]
>
> > I am using a nest survival model (glmer) with random effects and a
> logistic
> > exposure link function, as described here:
> >
> >
> http://stackoverflow.com/questions/19012128/user-defined-link-function-for-
> > glmer-for-known-fate-survival-modelling
> >
> > I am running a number of different models, with varying fixed effects.
> Some
> > of them are running well, with no error or warning messages, however
> > for other models, I am getting the following message:
> >
> > *Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> > pwrssUpdate*
> >
> > I'm not sure what is causing this error. I have tried to check the data
> for
> > simple problems, however can't see anything that could be causing
> trouble.
> >
> > I've also tried running the model without the random effects. This
> results
> > in a different error message:
> >
> > *Error: cannot find valid starting values: please specify some*
>
>   Example data doesn't seem to be attached: it may have been
> stripped by the mailing list software.  Can you post it somewhere
> public and provide a URL?
>
>   My guess it that there is something rather wonky about the data
> for this example, e.g. complete separation (for example, no individuals
> die for some combination of predictor variables).  Hard to say
> without the data though.
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From boris.fuchs at schultraining.ch  Fri Mar  6 10:07:45 2015
From: boris.fuchs at schultraining.ch (Boris Fuchs)
Date: Fri, 6 Mar 2015 10:07:45 +0100
Subject: [R-sig-ME] binary response, random factor
Message-ID: <002201d057ed$03249860$096dc920$@schultraining.ch>

-----BEGIN PGP SIGNED MESSAGE-----

Hash: SHA1

 

  Can you please send this to r-sig-mixed-models at r-project.org ?

 

  I think the answer would be of general interest.

 

  I do have one paper (Pasch et al Am Nat 2013 in which we initially
considered using a mixed model but decided not to in the end -- you could
cite that in support ...

 

On 15-03-05 11:05 AM, Boris Fuchs wrote:

> Hi Ben

> 

> 

> 

> Thirst: thanks for all the answers you share in the net.

> 

> 

> 

> Guess you are busy. I try to be short.

> 

> 

> 

> I try to publish my master thesis:

> 

> 

> 

> I have a data set of 106 Scandinavian wolves. A binary response 

> whether they are tested positive or negative for a parasite (Sarcoptic 

> mange). I test if individual variables (sex, age?) or environmental 

> variables (fox density, latitude?) are better explaining the test 

> results (positive or negative).

> 

> 

> 

> I use glm?s, selected by AICc in R.

> 

> 

> 

> 

> 

> 16 are positive.

> 

> 

> 

> I am aware of potential overfitting problems (max K = n/10 or better 

> 20?)

> 

> 

> 

> About 40 individuals got sampled >1 up to 4 times. ?> random factor

> 

> 

> 

> Some territories are sampled multiple times. ? random factor

> 

> 

> 

> However:

> 

> I did not succeed with building random structures and I belief because 

> of missing variability within the random factors. Most of the 

> individuals are tested only once. Easier if most of them would be 

> tested several times and would be both, positive and negative.

> The same with the territories. Is this right?

> 

> 

> 

> I would like to state the lacking variation as a reason to not use a 

> random structure. But I need some published support (not to say it 

> works anyway, but not). I seem not skilled enough to understand

> (select) the key literature. Do you have any hint?

> 

> 

> 

> 

> 

> Since most of the individuals are sampled once and the time between 

> the sampling is by far enough to change from positive to negative and 

> vica versa I think I can take the risk of violation of independence.

> 

> 

> 

> 

> 

> 

> 

> Boris

> 

> 

> 

> 

> 

> 

> 

> boris fuchs ole evenstadsvei 1156 2480 koppang +47 41 51 49 30 

> boris.fuchs at schultraining.ch

> 

> 

> 

> 

 

-----BEGIN PGP SIGNATURE-----

Version: GnuPG v1.4.11 (GNU/Linux)

 

iQEcBAEBAgAGBQJU+L7dAAoJEOCV5YRblxUH1IUH/jciVrXp/i5o6B8w6rM68LEy

CMHD3udnNLr+DFBXKVjH+XM6pljGDQSBUKBYncSZgY0jTWDsMfHTDgt0mHttlodF

koAebeqminRsvp3yc+lgpE4stBAEVUPRIh2onaVS6pzISYaoZEmmGwrJNAerZvyl

sEUgTH+pLSsSdXDJzKR8KYgocoAifMvHoDmwjtkdIz6FTdGxpqgkHNjLHj5Itesd

mexuWPyFFcmHI1IuCUNiuZnJNvA07c1isWSncuY0+NkfsRZWjjTNi8PNSuClLDXx

9K0k+8HySbH9zNqyFod9ErDd566AVeSVgqItA0xEtNVE6puyvFGF1tT1gw5WPes=

=15/3

-----END PGP SIGNATURE-----

 

 

boris fuchs
ole evenstadsvei 1156
2480 koppang
+47 41 51 49 30
boris.fuchs at schultraining.ch

 


	[[alternative HTML version deleted]]


From josie.galbraith at gmail.com  Sat Mar  7 00:15:41 2015
From: josie.galbraith at gmail.com (Josie Galbraith)
Date: Sat, 7 Mar 2015 12:15:41 +1300
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
	in blme
Message-ID: <CAGb-hRr7Xkdfh6oT+40Vr0+O8Bd4_gxf=Y8O_WF36pqvQi6jtA@mail.gmail.com>

Thanks Ben,
I didn't have problems with singular estimates of variance components with
this data set.  However, I have a few other pathogens/parasites that I'm
looking at (I'm running separate models for each), and after looking at all
of them some do have zero variances for the random effect, either in
addition to large parameter estimates or alongside reasonable parameter
estimates.
Should I be also be imposing a covariance prior in either of these cases?

As a related aside, my data are collected from individual birds - captured
over 4 sampling rounds (6 months apart).  While the majority of
observations are independent, there is a small proportion of birds that
were recaptured in a subsequent sampling round (between 2?15% of
observations, depending on which response variable).  I have modelled my
data both both with and without bird ID as a random effect.  Including it
seems to cause more problems with zero variances.  Is this because too few
of the birds have actually been resampled?

Cheers,
Josie



> Josie Galbraith <josie.galbraith at ...> writes:
>
> >
>
> [snip]
>
> >
> > I'm after some advice on how to choose which priors to use.  I gather I
> > need to impose a weak prior on the fixed effects of my model but no
> > covariance priors - is this correct?  Can I use a default prior (i.e. t,
> or
> > normal defaults in the blme package) or does it depend on my data?  What
> is
> > considered a suitably weak prior?
>
>    If all you're trying to do is deal with complete separation (and not,
> e.g. singular estimates of variance components [typically indicated
> by zero variances or +/- 1 correlations, although I'm not sure those
> are necessary conditions for singularity]), then it should be OK
> to put the prior only on the fixed effects.  Generally speaking a
> weak prior is one with a standard deviation that is large relative
> to the expected scale of the effect (e.g. we might say sigma=10 is
> large, but it won't be if the units of measurement are very small
> so that a typical value of the mean is 100,000 ...)
>
> > I am running binomial models for epidemiology data (response variable is
> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF; SEASON:
> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main goal of
> > these models is to test for an effect of the treatment 'FOOD.'  I'm
> > guessing from what I've read, that my model should be something like the
> > following:
>
>
> This seems fairly reasonable at first glance.  Where were you seeing
> the complete separation, though?   I would normally expect to
> see at least one of the parameters still being reasonably large
> if that's the case.
>
> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
> binomial,
> > fixef.prior = normal, cov.prior = NULL)
> >
> > This is the output when I run the model:
> >
> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...), common.scale =
> > FALSE)
> > Prior dev  : 18.2419
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) [
> > bglmerMod]
> >  Family: binomial ( logit )
> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
> >    Data: SEYE.df
> >
>
> [snip]
>
> > Random effects:
> >  Groups Name        Variance Std.Dev.
> >  SITE   (Intercept) 0.3064   0.5535
> > Number of obs: 178, groups: SITE, 8
> >
> > Fixed effects:
> >                     Estimate Std. Error z value Pr(>|z|)
> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
> > FOODNF                0.5462     1.6838   0.324  0.74567
> > SEASONSpring          1.7529     1.4721   1.191  0.23378
> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
>
> [snip]
>
> ------------------------------
>


-- 
*Josie Galbraith* MSc (hons)

PhD candidate
*University of Auckland *
Joint Graduate School in Biodiversity and Biosecurity ? School of
Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
*www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sat Mar  7 09:09:36 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 07 Mar 2015 08:09:36 +0000
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
 in blme
In-Reply-To: <CAGb-hRr7Xkdfh6oT+40Vr0+O8Bd4_gxf=Y8O_WF36pqvQi6jtA@mail.gmail.com>
References: <CAGb-hRr7Xkdfh6oT+40Vr0+O8Bd4_gxf=Y8O_WF36pqvQi6jtA@mail.gmail.com>
Message-ID: <20150307080936.155838kcwslvoegw@www.staffmail.ed.ac.uk>

Hi Josie,

Regarding the priors on the fixed effects, if complete separation is  
the issue having a diffuse prior is not going to help. Gelman (2008)  
gives some recommendations about priors for logistic regression.  
Although a Cauchy-prior was considered better than a t-prior, the  
latter can be used in blmer and should alleviate complete separation  
issues. I tend to use a normal-prior after performing Gelman's  
rescaling, but this is mainly because MCMCglmm only handles normal  
priors for the fixed effects (this may not be true). In a hierarchical  
model I'm not sure Gelman's advice holds: at least with a normal-prior  
it makes sense to increase the prior variance as the random-effect  
variances increase. If the prior variance is approximately v+pi^2/3,  
where v is the sum of the variance components, then the effects on the  
probability scale are quite close to being uniform on the 0,1 interval.

You can use the gelman.prior function to obtain the prior covariance  
matrix for your model. However, note that in the help file I say that  
the scale argument takes the standard deviation. In fact it takes the  
variance, but in the next version of MCMCglmm (coming soon) I have  
fixed this and it will take the standard deviation.

Cheers,

Jarrod


Gelman, A. et al. (2008) The Annals of Appled Statistics 2 4 1360-1383


Quoting Josie Galbraith <josie.galbraith at gmail.com> on Sat, 7 Mar 2015  
12:15:41 +1300:

> Thanks Ben,
> I didn't have problems with singular estimates of variance components with
> this data set.  However, I have a few other pathogens/parasites that I'm
> looking at (I'm running separate models for each), and after looking at all
> of them some do have zero variances for the random effect, either in
> addition to large parameter estimates or alongside reasonable parameter
> estimates.
> Should I be also be imposing a covariance prior in either of these cases?
>
> As a related aside, my data are collected from individual birds - captured
> over 4 sampling rounds (6 months apart).  While the majority of
> observations are independent, there is a small proportion of birds that
> were recaptured in a subsequent sampling round (between 2?15% of
> observations, depending on which response variable).  I have modelled my
> data both both with and without bird ID as a random effect.  Including it
> seems to cause more problems with zero variances.  Is this because too few
> of the birds have actually been resampled?
>
> Cheers,
> Josie
>
>
>
>> Josie Galbraith <josie.galbraith at ...> writes:
>>
>> >
>>
>> [snip]
>>
>> >
>> > I'm after some advice on how to choose which priors to use.  I gather I
>> > need to impose a weak prior on the fixed effects of my model but no
>> > covariance priors - is this correct?  Can I use a default prior (i.e. t,
>> or
>> > normal defaults in the blme package) or does it depend on my data?  What
>> is
>> > considered a suitably weak prior?
>>
>>    If all you're trying to do is deal with complete separation (and not,
>> e.g. singular estimates of variance components [typically indicated
>> by zero variances or +/- 1 correlations, although I'm not sure those
>> are necessary conditions for singularity]), then it should be OK
>> to put the prior only on the fixed effects.  Generally speaking a
>> weak prior is one with a standard deviation that is large relative
>> to the expected scale of the effect (e.g. we might say sigma=10 is
>> large, but it won't be if the units of measurement are very small
>> so that a typical value of the mean is 100,000 ...)
>>
>> > I am running binomial models for epidemiology data (response variable is
>> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF; SEASON:
>> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main goal of
>> > these models is to test for an effect of the treatment 'FOOD.'  I'm
>> > guessing from what I've read, that my model should be something like the
>> > following:
>>
>>
>> This seems fairly reasonable at first glance.  Where were you seeing
>> the complete separation, though?   I would normally expect to
>> see at least one of the parameters still being reasonably large
>> if that's the case.
>>
>> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
>> binomial,
>> > fixef.prior = normal, cov.prior = NULL)
>> >
>> > This is the output when I run the model:
>> >
>> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...), common.scale =
>> > FALSE)
>> > Prior dev  : 18.2419
>> >
>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>> > Approximation) [
>> > bglmerMod]
>> >  Family: binomial ( logit )
>> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>> >    Data: SEYE.df
>> >
>>
>> [snip]
>>
>> > Random effects:
>> >  Groups Name        Variance Std.Dev.
>> >  SITE   (Intercept) 0.3064   0.5535
>> > Number of obs: 178, groups: SITE, 8
>> >
>> > Fixed effects:
>> >                     Estimate Std. Error z value Pr(>|z|)
>> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
>> > FOODNF                0.5462     1.6838   0.324  0.74567
>> > SEASONSpring          1.7529     1.4721   1.191  0.23378
>> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>>
>> [snip]
>>
>> ------------------------------
>>
>
>
> --
> *Josie Galbraith* MSc (hons)
>
> PhD candidate
> *University of Auckland *
> Joint Graduate School in Biodiversity and Biosecurity ? School of
> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From vjd4 at nyu.edu  Sat Mar  7 15:47:40 2015
From: vjd4 at nyu.edu (Vincent Dorie)
Date: Sat, 7 Mar 2015 09:47:40 -0500
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
	in blme
In-Reply-To: <20150307080936.155838kcwslvoegw@www.staffmail.ed.ac.uk>
References: <CAGb-hRr7Xkdfh6oT+40Vr0+O8Bd4_gxf=Y8O_WF36pqvQi6jtA@mail.gmail.com>
	<20150307080936.155838kcwslvoegw@www.staffmail.ed.ac.uk>
Message-ID: <6EB306ED-2D34-4235-8922-E9236B43EC3C@nyu.edu>

Just to follow up on Gelman's Cauchy prior, it seems to work quite well even in glmms. I don't have any theoretical results as of yet, but if you look at the sampling distribution of the fixed effects for any model, they cluster rather nicely. You get "sane" estimates for when no kind of separation is involved, infinite (or convergence failures) for complete/quasi complete separation, and a third group exists with large estimates for when a group contains all 0s or 1s. In the third case, a random effect can perfectly predict for that group, but because they're integrated out the likelihood remains well defined. You'll just get really large estimates of random effects, which then go with large estimates of fixed effects.

So long as you believe that some effect magnitudes for logistic regression pretty much never happen in nature, the Cauchy prior does a good job of pulling the extreme cases back down to earth while leaving the well-estimated ones roughly in place. That being said, using the priors in blme to patch up a data set is really only advised for checking the viability of a model (usually one among many, rapidly fit). After that, using something like MCMCglmm for a fully Bayesian analysis is the way to go.

Vince

> On Mar 7, 2015, at 3:09 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> 
> Hi Josie,
> 
> Regarding the priors on the fixed effects, if complete separation is the issue having a diffuse prior is not going to help. Gelman (2008) gives some recommendations about priors for logistic regression. Although a Cauchy-prior was considered better than a t-prior, the latter can be used in blmer and should alleviate complete separation issues. I tend to use a normal-prior after performing Gelman's rescaling, but this is mainly because MCMCglmm only handles normal priors for the fixed effects (this may not be true). In a hierarchical model I'm not sure Gelman's advice holds: at least with a normal-prior it makes sense to increase the prior variance as the random-effect variances increase. If the prior variance is approximately v+pi^2/3, where v is the sum of the variance components, then the effects on the probability scale are quite close to being uniform on the 0,1 interval.
> 
> You can use the gelman.prior function to obtain the prior covariance matrix for your model. However, note that in the help file I say that the scale argument takes the standard deviation. In fact it takes the variance, but in the next version of MCMCglmm (coming soon) I have fixed this and it will take the standard deviation.
> 
> Cheers,
> 
> Jarrod
> 
> 
> Gelman, A. et al. (2008) The Annals of Appled Statistics 2 4 1360-1383
> 
> 
> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Sat, 7 Mar 2015 12:15:41 +1300:
> 
>> Thanks Ben,
>> I didn't have problems with singular estimates of variance components with
>> this data set.  However, I have a few other pathogens/parasites that I'm
>> looking at (I'm running separate models for each), and after looking at all
>> of them some do have zero variances for the random effect, either in
>> addition to large parameter estimates or alongside reasonable parameter
>> estimates.
>> Should I be also be imposing a covariance prior in either of these cases?
>> 
>> As a related aside, my data are collected from individual birds - captured
>> over 4 sampling rounds (6 months apart).  While the majority of
>> observations are independent, there is a small proportion of birds that
>> were recaptured in a subsequent sampling round (between 2?15% of
>> observations, depending on which response variable).  I have modelled my
>> data both both with and without bird ID as a random effect.  Including it
>> seems to cause more problems with zero variances.  Is this because too few
>> of the birds have actually been resampled?
>> 
>> Cheers,
>> Josie
>> 
>> 
>> 
>>> Josie Galbraith <josie.galbraith at ...> writes:
>>> 
>>> >
>>> 
>>> [snip]
>>> 
>>> >
>>> > I'm after some advice on how to choose which priors to use.  I gather I
>>> > need to impose a weak prior on the fixed effects of my model but no
>>> > covariance priors - is this correct?  Can I use a default prior (i.e. t,
>>> or
>>> > normal defaults in the blme package) or does it depend on my data?  What
>>> is
>>> > considered a suitably weak prior?
>>> 
>>>   If all you're trying to do is deal with complete separation (and not,
>>> e.g. singular estimates of variance components [typically indicated
>>> by zero variances or +/- 1 correlations, although I'm not sure those
>>> are necessary conditions for singularity]), then it should be OK
>>> to put the prior only on the fixed effects.  Generally speaking a
>>> weak prior is one with a standard deviation that is large relative
>>> to the expected scale of the effect (e.g. we might say sigma=10 is
>>> large, but it won't be if the units of measurement are very small
>>> so that a typical value of the mean is 100,000 ...)
>>> 
>>> > I am running binomial models for epidemiology data (response variable is
>>> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF; SEASON:
>>> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main goal of
>>> > these models is to test for an effect of the treatment 'FOOD.'  I'm
>>> > guessing from what I've read, that my model should be something like the
>>> > following:
>>> 
>>> 
>>> This seems fairly reasonable at first glance.  Where were you seeing
>>> the complete separation, though?   I would normally expect to
>>> see at least one of the parameters still being reasonably large
>>> if that's the case.
>>> 
>>> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
>>> binomial,
>>> > fixef.prior = normal, cov.prior = NULL)
>>> >
>>> > This is the output when I run the model:
>>> >
>>> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...), common.scale =
>>> > FALSE)
>>> > Prior dev  : 18.2419
>>> >
>>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>>> > Approximation) [
>>> > bglmerMod]
>>> >  Family: binomial ( logit )
>>> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>>> >    Data: SEYE.df
>>> >
>>> 
>>> [snip]
>>> 
>>> > Random effects:
>>> >  Groups Name        Variance Std.Dev.
>>> >  SITE   (Intercept) 0.3064   0.5535
>>> > Number of obs: 178, groups: SITE, 8
>>> >
>>> > Fixed effects:
>>> >                     Estimate Std. Error z value Pr(>|z|)
>>> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
>>> > FOODNF                0.5462     1.6838   0.324  0.74567
>>> > SEASONSpring          1.7529     1.4721   1.191  0.23378
>>> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
>>> > ---
>>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> >
>>> 
>>> [snip]
>>> 
>>> ------------------------------
>>> 
>> 
>> 
>> --
>> *Josie Galbraith* MSc (hons)
>> 
>> PhD candidate
>> *University of Auckland *
>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j.hadfield at ed.ac.uk  Sat Mar  7 17:50:06 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 07 Mar 2015 16:50:06 +0000
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
 in blme
In-Reply-To: <6EB306ED-2D34-4235-8922-E9236B43EC3C@nyu.edu>
References: <CAGb-hRr7Xkdfh6oT+40Vr0+O8Bd4_gxf=Y8O_WF36pqvQi6jtA@mail.gmail.com>
	<20150307080936.155838kcwslvoegw@www.staffmail.ed.ac.uk>
	<6EB306ED-2D34-4235-8922-E9236B43EC3C@nyu.edu>
Message-ID: <20150307165006.15412kdm11903dq8@www.staffmail.ed.ac.uk>

Hi Vince,

For a given difference on the logit scale between (lets say) two  
treatment groups then the difference on the observed scale depends on  
the magnitude of the variance components. For logit effects beta1 and  
beta2, the expected difference is approximately:

plogis(beta1/sqrt(1+c2*v))-plogis(beta2/sqrt(1+c2*v))

where v is the variance component and c2 = (16*sqrt(3)/(15*pi))^2.

If a prior (Cauchy or otherwise) was set up that was invariant to v  
then it would imply different prior beliefs about the magnitude of the  
difference (on the observed scale) depending on v. For the normal  
prior it would imply that when v is large we should expect smaller  
differences between treatment groups. This maybe OK (I'm not sure) but  
if not is there a way to make it invariant for the t/Cauchy prior? For  
the normal you can make the scale = sqrt(v+pi^2/3) which seems to work  
OKish.

Cheers,

Jarrod




Quoting Vincent Dorie <vjd4 at nyu.edu> on Sat, 7 Mar 2015 09:47:40 -0500:

> Just to follow up on Gelman's Cauchy prior, it seems to work quite  
> well even in glmms. I don't have any theoretical results as of yet,  
> but if you look at the sampling distribution of the fixed effects  
> for any model, they cluster rather nicely. You get "sane" estimates  
> for when no kind of separation is involved, infinite (or convergence  
> failures) for complete/quasi complete separation, and a third group  
> exists with large estimates for when a group contains all 0s or 1s.  
> In the third case, a random effect can perfectly predict for that  
> group, but because they're integrated out the likelihood remains  
> well defined. You'll just get really large estimates of random  
> effects, which then go with large estimates of fixed effects.
>
> So long as you believe that some effect magnitudes for logistic  
> regression pretty much never happen in nature, the Cauchy prior does  
> a good job of pulling the extreme cases back down to earth while  
> leaving the well-estimated ones roughly in place. That being said,  
> using the priors in blme to patch up a data set is really only  
> advised for checking the viability of a model (usually one among  
> many, rapidly fit). After that, using something like MCMCglmm for a  
> fully Bayesian analysis is the way to go.
>
> Vince
>
>> On Mar 7, 2015, at 3:09 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>
>> Hi Josie,
>>
>> Regarding the priors on the fixed effects, if complete separation  
>> is the issue having a diffuse prior is not going to help. Gelman  
>> (2008) gives some recommendations about priors for logistic  
>> regression. Although a Cauchy-prior was considered better than a  
>> t-prior, the latter can be used in blmer and should alleviate  
>> complete separation issues. I tend to use a normal-prior after  
>> performing Gelman's rescaling, but this is mainly because MCMCglmm  
>> only handles normal priors for the fixed effects (this may not be  
>> true). In a hierarchical model I'm not sure Gelman's advice holds:  
>> at least with a normal-prior it makes sense to increase the prior  
>> variance as the random-effect variances increase. If the prior  
>> variance is approximately v+pi^2/3, where v is the sum of the  
>> variance components, then the effects on the probability scale are  
>> quite close to being uniform on the 0,1 interval.
>>
>> You can use the gelman.prior function to obtain the prior  
>> covariance matrix for your model. However, note that in the help  
>> file I say that the scale argument takes the standard deviation. In  
>> fact it takes the variance, but in the next version of MCMCglmm  
>> (coming soon) I have fixed this and it will take the standard  
>> deviation.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> Gelman, A. et al. (2008) The Annals of Appled Statistics 2 4 1360-1383
>>
>>
>> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Sat, 7 Mar  
>> 2015 12:15:41 +1300:
>>
>>> Thanks Ben,
>>> I didn't have problems with singular estimates of variance components with
>>> this data set.  However, I have a few other pathogens/parasites that I'm
>>> looking at (I'm running separate models for each), and after looking at all
>>> of them some do have zero variances for the random effect, either in
>>> addition to large parameter estimates or alongside reasonable parameter
>>> estimates.
>>> Should I be also be imposing a covariance prior in either of these cases?
>>>
>>> As a related aside, my data are collected from individual birds - captured
>>> over 4 sampling rounds (6 months apart).  While the majority of
>>> observations are independent, there is a small proportion of birds that
>>> were recaptured in a subsequent sampling round (between 2?15% of
>>> observations, depending on which response variable).  I have modelled my
>>> data both both with and without bird ID as a random effect.  Including it
>>> seems to cause more problems with zero variances.  Is this because too few
>>> of the birds have actually been resampled?
>>>
>>> Cheers,
>>> Josie
>>>
>>>
>>>
>>>> Josie Galbraith <josie.galbraith at ...> writes:
>>>>
>>>> >
>>>>
>>>> [snip]
>>>>
>>>> >
>>>> > I'm after some advice on how to choose which priors to use.  I gather I
>>>> > need to impose a weak prior on the fixed effects of my model but no
>>>> > covariance priors - is this correct?  Can I use a default prior (i.e. t,
>>>> or
>>>> > normal defaults in the blme package) or does it depend on my data?  What
>>>> is
>>>> > considered a suitably weak prior?
>>>>
>>>>   If all you're trying to do is deal with complete separation (and not,
>>>> e.g. singular estimates of variance components [typically indicated
>>>> by zero variances or +/- 1 correlations, although I'm not sure those
>>>> are necessary conditions for singularity]), then it should be OK
>>>> to put the prior only on the fixed effects.  Generally speaking a
>>>> weak prior is one with a standard deviation that is large relative
>>>> to the expected scale of the effect (e.g. we might say sigma=10 is
>>>> large, but it won't be if the units of measurement are very small
>>>> so that a typical value of the mean is 100,000 ...)
>>>>
>>>> > I am running binomial models for epidemiology data (response variable is
>>>> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF; SEASON:
>>>> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main goal of
>>>> > these models is to test for an effect of the treatment 'FOOD.'  I'm
>>>> > guessing from what I've read, that my model should be something like the
>>>> > following:
>>>>
>>>>
>>>> This seems fairly reasonable at first glance.  Where were you seeing
>>>> the complete separation, though?   I would normally expect to
>>>> see at least one of the parameters still being reasonably large
>>>> if that's the case.
>>>>
>>>> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
>>>> binomial,
>>>> > fixef.prior = normal, cov.prior = NULL)
>>>> >
>>>> > This is the output when I run the model:
>>>> >
>>>> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...),  
>>>> common.scale =
>>>> > FALSE)
>>>> > Prior dev  : 18.2419
>>>> >
>>>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>>>> > Approximation) [
>>>> > bglmerMod]
>>>> >  Family: binomial ( logit )
>>>> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>>>> >    Data: SEYE.df
>>>> >
>>>>
>>>> [snip]
>>>>
>>>> > Random effects:
>>>> >  Groups Name        Variance Std.Dev.
>>>> >  SITE   (Intercept) 0.3064   0.5535
>>>> > Number of obs: 178, groups: SITE, 8
>>>> >
>>>> > Fixed effects:
>>>> >                     Estimate Std. Error z value Pr(>|z|)
>>>> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
>>>> > FOODNF                0.5462     1.6838   0.324  0.74567
>>>> > SEASONSpring          1.7529     1.4721   1.191  0.23378
>>>> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
>>>> > ---
>>>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> >
>>>>
>>>> [snip]
>>>>
>>>> ------------------------------
>>>>
>>>
>>>
>>> --
>>> *Josie Galbraith* MSc (hons)
>>>
>>> PhD candidate
>>> *University of Auckland *
>>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
>>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
>>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Siham.ElKihal at hof.uni-frankfurt.de  Fri Mar  6 21:21:38 2015
From: Siham.ElKihal at hof.uni-frankfurt.de (El Kihal, Siham)
Date: Fri, 6 Mar 2015 21:21:38 +0100
Subject: [R-sig-ME] lmer with binomial distribution of random effects
Message-ID: <449B554E28A38046A4BE07F9871EFC724AB983901E@EX1.hof.uni-frankfurt.de>

Dear lmer() friends,

I am trying to estimate a model with a random intercept, and 2 random slopes.
I believe that my betas (slopes) do not follow a normal distribution, but rather a bimodal distribution. The reason for this that there are two possible mechanisms that influence the evolution of this variable, one with a negative influence and another one with a positive influence. This is why I need to use a bimodal distribution for my slopes to avoid the fact that both effects right now cancel out.

Does anyone of you has already done this or has an idea how to concretely implement this using lmer()?

Thanks a lot for your support, this will help me a lot!

Many regards,

Siham


	[[alternative HTML version deleted]]


From whitworth.alex at gmail.com  Fri Mar  6 22:05:16 2015
From: whitworth.alex at gmail.com (Alex Whitworth)
Date: Fri, 6 Mar 2015 13:05:16 -0800
Subject: [R-sig-ME] trouble with Dev version
Message-ID: <CA+8zgHK6U4xDv+Ss0gQ+cG2QZovgBicyXC3m0S0pa1v8Hsc-7w@mail.gmail.com>

Is anyone able to reproduce this error, trouble installing and using lme4
from Github (v1.1.8)


http://stackoverflow.com/questions/28906341/lme4-dev-install-reproducible

Alex

	[[alternative HTML version deleted]]


From vjd4 at nyu.edu  Sun Mar  8 19:50:45 2015
From: vjd4 at nyu.edu (Vincent Dorie)
Date: Sun, 8 Mar 2015 14:50:45 -0400
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
	in blme
In-Reply-To: <20150307165006.15412kdm11903dq8@www.staffmail.ed.ac.uk>
References: <CAGb-hRr7Xkdfh6oT+40Vr0+O8Bd4_gxf=Y8O_WF36pqvQi6jtA@mail.gmail.com>
	<20150307080936.155838kcwslvoegw@www.staffmail.ed.ac.uk>
	<6EB306ED-2D34-4235-8922-E9236B43EC3C@nyu.edu>
	<20150307165006.15412kdm11903dq8@www.staffmail.ed.ac.uk>
Message-ID: <A2394EC2-4362-4867-9178-A29E4DE1E313@nyu.edu>

Hi Jarrod,

I'm not familiar with those calculations. Are those for the MLE in a balanced, varying intercept model?

I guess the short answer is that it would be pretty easy to add this to blme (I think it can already be done, even). I am not 100% certain, but since the t/Cauchy is just a normal distribution with an unknown scale component it should be sufficient to use something proportional to your proposed scale.

The longer answer might be that the Cauchy prior is OK as is, since the implicit prior it imposes on the variance component keeps the random effects from exploiting separation between groups. Maybe it's a feature and not a bug? On the other hand, I suppose it is more philosophically clean to penalize both parameters directly. If one can make an argument that there is prior information about the range of fixed effects possible in a logistic regression, the same can be said for the random effects or their variance component. On the other, other hand, that's one more tuning parameter.

It looks as if folk are running blme when the MLE breaks down. Ideally, they would then move on to a fully Bayesian solution. In the event that they don't, the goal is then to provide posterior mode estimates under on prior that looks similar to posterior means under a "reference" prior, but also conditioned on the knowledge that something isn't quite right with the data. I'm very open to suggestions on how to best do this.

Vince

> On Mar 7, 2015, at 11:50 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> 
> Hi Vince,
> 
> For a given difference on the logit scale between (lets say) two treatment groups then the difference on the observed scale depends on the magnitude of the variance components. For logit effects beta1 and beta2, the expected difference is approximately:
> 
> plogis(beta1/sqrt(1+c2*v))-plogis(beta2/sqrt(1+c2*v))
> 
> where v is the variance component and c2 = (16*sqrt(3)/(15*pi))^2.
> 
> If a prior (Cauchy or otherwise) was set up that was invariant to v then it would imply different prior beliefs about the magnitude of the difference (on the observed scale) depending on v. For the normal prior it would imply that when v is large we should expect smaller differences between treatment groups. This maybe OK (I'm not sure) but if not is there a way to make it invariant for the t/Cauchy prior? For the normal you can make the scale = sqrt(v+pi^2/3) which seems to work OKish.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> Quoting Vincent Dorie <vjd4 at nyu.edu> on Sat, 7 Mar 2015 09:47:40 -0500:
> 
>> Just to follow up on Gelman's Cauchy prior, it seems to work quite well even in glmms. I don't have any theoretical results as of yet, but if you look at the sampling distribution of the fixed effects for any model, they cluster rather nicely. You get "sane" estimates for when no kind of separation is involved, infinite (or convergence failures) for complete/quasi complete separation, and a third group exists with large estimates for when a group contains all 0s or 1s. In the third case, a random effect can perfectly predict for that group, but because they're integrated out the likelihood remains well defined. You'll just get really large estimates of random effects, which then go with large estimates of fixed effects.
>> 
>> So long as you believe that some effect magnitudes for logistic regression pretty much never happen in nature, the Cauchy prior does a good job of pulling the extreme cases back down to earth while leaving the well-estimated ones roughly in place. That being said, using the priors in blme to patch up a data set is really only advised for checking the viability of a model (usually one among many, rapidly fit). After that, using something like MCMCglmm for a fully Bayesian analysis is the way to go.
>> 
>> Vince
>> 
>>> On Mar 7, 2015, at 3:09 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>> 
>>> Hi Josie,
>>> 
>>> Regarding the priors on the fixed effects, if complete separation is the issue having a diffuse prior is not going to help. Gelman (2008) gives some recommendations about priors for logistic regression. Although a Cauchy-prior was considered better than a t-prior, the latter can be used in blmer and should alleviate complete separation issues. I tend to use a normal-prior after performing Gelman's rescaling, but this is mainly because MCMCglmm only handles normal priors for the fixed effects (this may not be true). In a hierarchical model I'm not sure Gelman's advice holds: at least with a normal-prior it makes sense to increase the prior variance as the random-effect variances increase. If the prior variance is approximately v+pi^2/3, where v is the sum of the variance components, then the effects on the probability scale are quite close to being uniform on the 0,1 interval.
>>> 
>>> You can use the gelman.prior function to obtain the prior covariance matrix for your model. However, note that in the help file I say that the scale argument takes the standard deviation. In fact it takes the variance, but in the next version of MCMCglmm (coming soon) I have fixed this and it will take the standard deviation.
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> Gelman, A. et al. (2008) The Annals of Appled Statistics 2 4 1360-1383
>>> 
>>> 
>>> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Sat, 7 Mar 2015 12:15:41 +1300:
>>> 
>>>> Thanks Ben,
>>>> I didn't have problems with singular estimates of variance components with
>>>> this data set.  However, I have a few other pathogens/parasites that I'm
>>>> looking at (I'm running separate models for each), and after looking at all
>>>> of them some do have zero variances for the random effect, either in
>>>> addition to large parameter estimates or alongside reasonable parameter
>>>> estimates.
>>>> Should I be also be imposing a covariance prior in either of these cases?
>>>> 
>>>> As a related aside, my data are collected from individual birds - captured
>>>> over 4 sampling rounds (6 months apart).  While the majority of
>>>> observations are independent, there is a small proportion of birds that
>>>> were recaptured in a subsequent sampling round (between 2?15% of
>>>> observations, depending on which response variable).  I have modelled my
>>>> data both both with and without bird ID as a random effect.  Including it
>>>> seems to cause more problems with zero variances.  Is this because too few
>>>> of the birds have actually been resampled?
>>>> 
>>>> Cheers,
>>>> Josie
>>>> 
>>>> 
>>>> 
>>>>> Josie Galbraith <josie.galbraith at ...> writes:
>>>>> 
>>>>> >
>>>>> 
>>>>> [snip]
>>>>> 
>>>>> >
>>>>> > I'm after some advice on how to choose which priors to use.  I gather I
>>>>> > need to impose a weak prior on the fixed effects of my model but no
>>>>> > covariance priors - is this correct?  Can I use a default prior (i.e. t,
>>>>> or
>>>>> > normal defaults in the blme package) or does it depend on my data?  What
>>>>> is
>>>>> > considered a suitably weak prior?
>>>>> 
>>>>>  If all you're trying to do is deal with complete separation (and not,
>>>>> e.g. singular estimates of variance components [typically indicated
>>>>> by zero variances or +/- 1 correlations, although I'm not sure those
>>>>> are necessary conditions for singularity]), then it should be OK
>>>>> to put the prior only on the fixed effects.  Generally speaking a
>>>>> weak prior is one with a standard deviation that is large relative
>>>>> to the expected scale of the effect (e.g. we might say sigma=10 is
>>>>> large, but it won't be if the units of measurement are very small
>>>>> so that a typical value of the mean is 100,000 ...)
>>>>> 
>>>>> > I am running binomial models for epidemiology data (response variable is
>>>>> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF; SEASON:
>>>>> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main goal of
>>>>> > these models is to test for an effect of the treatment 'FOOD.'  I'm
>>>>> > guessing from what I've read, that my model should be something like the
>>>>> > following:
>>>>> 
>>>>> 
>>>>> This seems fairly reasonable at first glance.  Where were you seeing
>>>>> the complete separation, though?   I would normally expect to
>>>>> see at least one of the parameters still being reasonably large
>>>>> if that's the case.
>>>>> 
>>>>> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
>>>>> binomial,
>>>>> > fixef.prior = normal, cov.prior = NULL)
>>>>> >
>>>>> > This is the output when I run the model:
>>>>> >
>>>>> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...), common.scale =
>>>>> > FALSE)
>>>>> > Prior dev  : 18.2419
>>>>> >
>>>>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>>>>> > Approximation) [
>>>>> > bglmerMod]
>>>>> >  Family: binomial ( logit )
>>>>> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>>>>> >    Data: SEYE.df
>>>>> >
>>>>> 
>>>>> [snip]
>>>>> 
>>>>> > Random effects:
>>>>> >  Groups Name        Variance Std.Dev.
>>>>> >  SITE   (Intercept) 0.3064   0.5535
>>>>> > Number of obs: 178, groups: SITE, 8
>>>>> >
>>>>> > Fixed effects:
>>>>> >                     Estimate Std. Error z value Pr(>|z|)
>>>>> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
>>>>> > FOODNF                0.5462     1.6838   0.324  0.74567
>>>>> > SEASONSpring          1.7529     1.4721   1.191  0.23378
>>>>> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
>>>>> > ---
>>>>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>> >
>>>>> 
>>>>> [snip]
>>>>> 
>>>>> ------------------------------
>>>>> 
>>>> 
>>>> 
>>>> --
>>>> *Josie Galbraith* MSc (hons)
>>>> 
>>>> PhD candidate
>>>> *University of Auckland *
>>>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>>>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
>>>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
>>>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>>>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> 
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


From bbolker at gmail.com  Mon Mar  9 02:13:42 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Mar 2015 01:13:42 +0000 (UTC)
Subject: [R-sig-ME] trouble with Dev version
References: <CA+8zgHK6U4xDv+Ss0gQ+cG2QZovgBicyXC3m0S0pa1v8Hsc-7w@mail.gmail.com>
Message-ID: <loom.20150309T021235-94@post.gmane.org>

Alex Whitworth <whitworth.alex at ...> writes:

> 
> Is anyone able to reproduce this error, trouble installing and using lme4
> from Github (v1.1.8)
> 
> http://stackoverflow.com/questions/28906341/lme4-dev-install-reproducible
> 
> Alex
> 


  As I answered on SO, this ("lazy-load database corrupt") sort of
error usually seems to be transient (and unrelated to lme4 specifically).
I suggested that you try a clean R session and perhaps a clean
re-install; you deleted the SO question, which suggests that it
might have worked.


From bbolker at gmail.com  Mon Mar  9 02:17:57 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Mar 2015 01:17:57 +0000 (UTC)
Subject: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
	failed to reduce deviance in pwrssUpdate
References: <CAM7=EBRe+KSK-zk=zC0YUsbvoGypAi-Yu=Ek3O+YqFVwNC98Lw@mail.gmail.com>
Message-ID: <loom.20150309T021601-509@post.gmane.org>

Elwyn Sharps <e.sharps at ...> writes:

> 
> Hi Ben
> 
> Thank you very much for your reply. If you click on this link, it should
> give you the data in a CSV file.
> https://sites.google.com/site/es263datahlp/habitat-type_example.csv
> 
> Many thanks
> 
> Elwyn

  I worked on this for a while, without complete success. The main
issue is that the inverse-link function and derivative functions
need some clamping so that they don't hit 0/1 ... this still doesn't
solve the lme4 problem, but at least it allows the GLM to work.

  Have you considered a cloglog link + offset(log(exposure))
model?  That *might* be a little more stable ...


library(lme4)
library(MASS)

logexp <- function(exposure = 1, eps=1e-8, maxlink=Inf)
{
  linkfun <- function(mu) {
      r <- qlogis(mu^(1/exposure))
      ## clamp link function: not actually necessary?
      ##  maxlink set to Inf
      if (any(toobig <- abs(r)>maxlink)) {
          ## cat("max threshold hit") 
          r[toobig] <- sign(r[toobig])*maxlink
      }
      return(r)
  }
  ## utility for clamping inverse-link, derivative function
  clamp <- function(x) {
      x <- pmax(eps,x)
      if (upr) x <- pmin(1-eps,x)
      return(x)
  }
  linkinv <- function(eta)  clamp(plogis(eta)^exposure)
  mu.eta <- function(eta) {
      r <- exposure * clamp(plogis(eta)^(exposure-1)) *
          .Call(stats:::C_logit_mu_eta, eta, PACKAGE = "stats")
      return(r)
  }
  valideta <- function(eta) TRUE
  link <- paste("logexp(", deparse(substitute(exposure)), ")",
                sep="")
  structure(list(linkfun = linkfun, linkinv = linkinv,
                 mu.eta = mu.eta, valideta = valideta,
                 name = link),
            class = "link-glm")
}

##Read in data, called 'mydata'

mydata <- read.csv("habitat-type_example.csv")

library("ggplot2")
with(mydata,table(survive,trials))
with(mydata,table(survive,habitat))
ggplot(mydata,aes(log(1+expos),survive,colour=habitat))+
    geom_point()+
    geom_smooth(method="glm",family="binomial")
ggplot(subset(mydata,habitat=="Conregrowth"),
       aes(expos,survive))+
           stat_sum(aes(size=..n..))+
    geom_smooth(method="glm",family="binomial")+
        scale_size_area()

## trials is always == 1 in this data set

## the fact that glm() fails means that the problem is more
## basic than a GLMM problem
glm1 <- glm(survive~habitat,
            family=binomial(logexp(exposure=mydata$expos)),
            data=mydata)

Mod1 <- glmer(survive~habitat + (1|site)+(1|year),
              family=binomial(logexp(exposure=mydata$expos)),data=mydata,
              nAGQ=1,
              devFunOnly=TRUE,
              control=glmerControl(nAGQ0initStep=FALSE),
              start=list(beta=coef(glm1),theta=1e-5),
              verbose=100)

Mod2 <- glmer(survive~habitat + (1|year),
              family=binomial(logexp(exposure=mydata$expos)),data=mydata,
              start=list(theta=c(1e-6,1e-6)),
              nAGQ=0,
              devFunOnly=TRUE)

Mod3 <- glmer(survive~habitat + (1|site),
              family=binomial(logexp(exposure=mydata$expos)),data=mydata,
              start=list(theta=c(1e-6,1e-6)),
              nAGQ=0,
              devFunOnly=TRUE)

mydata3 <- droplevels(subset(mydata,habitat!="Conregrowth"))
Mod4 <- glmer(survive~habitat + (1|year),
              family=binomial(logexp(exposure=mydata3$expos)),data=mydata3)

Mod5 <- glmer(survive~habitat + (1|site),
              family=binomial(logexp(exposure=mydata3$expos)),data=mydata3,
              nAGQ=1,
              devFunOnly=TRUE,
              control=glmerControl(nAGQ0initStep=FALSE),
              start=list(beta=coef(glm1),theta=1e-5),
              verbose=100)

with(mydata3,table(site,habitat,survive))
with(mydata,table(year,habitat,survive))

> 
> On 5 March 2015 at 03:11, Ben Bolker <bbolker at ...> wrote:
> 
> > Elwyn Sharps <e.sharps <at> ...> writes:
> >
> > >
> >
> > [snip]
> >
> > > I am using a nest survival model (glmer) with random effects and a
> > logistic
> > > exposure link function, as described here:
> > >
> > >
> > http://stackoverflow.com/questions/19012128/user-defined-link-function-for-
> > > glmer-for-known-fate-survival-modelling
> > >
> > > I am running a number of different models, with varying fixed effects.
> > Some
> > > of them are running well, with no error or warning messages, however
> > > for other models, I am getting the following message:
> > >
> > > *Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> > > pwrssUpdate*
> > >
> > > I'm not sure what is causing this error. I have tried to check the data
> > for
> > > simple problems, however can't see anything that could be causing
> > trouble.
> > >
> > > I've also tried running the model without the random effects. This
> > results
> > > in a different error message:
> > >
> > > *Error: cannot find valid starting values: please specify some*
> >
> >   Example data doesn't seem to be attached: it may have been
> > stripped by the mailing list software.  Can you post it somewhere
> > public and provide a URL?
> >
> >   My guess it that there is something rather wonky about the data
> > for this example, e.g. complete separation (for example, no individuals
> > die for some combination of predictor variables).  Hard to say
> > without the data though.
> >
> >   Ben Bolker
> >
> > _______________________________________________
> > R-sig-mixed-models at ... mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 	[[alternative HTML version deleted]]
> 
>


From bbolker at gmail.com  Mon Mar  9 02:15:42 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Mar 2015 01:15:42 +0000 (UTC)
Subject: [R-sig-ME] lmer with binomial distribution of random effects
References: <449B554E28A38046A4BE07F9871EFC724AB983901E@EX1.hof.uni-frankfurt.de>
Message-ID: <loom.20150309T021358-280@post.gmane.org>

El Kihal, Siham <Siham.ElKihal at ...> writes:

> 
> Dear lmer() friends,
> 
> I am trying to estimate a model with a random 
> intercept, and 2 random slopes.
> I believe that my betas (slopes) do not follow 
>a normal distribution, but rather a bimodal distribution.
> The reason for this that there are two possible 
> mechanisms that influence the evolution of this variable,
> one with a negative influence and another one with a
>  positive influence. This is why I need to use a bimodal
> distribution for my slopes to avoid the fact that 
> both effects right now cancel out.
> 
> Does anyone of you has already done this or has 
> an idea how to concretely implement this using lmer()?

  This sounds like a latent mixture model problem.  lme4 doesn't
do this; you *might* be able to implement an expectation-maximization
wrapper around lme4 that would do it, but it wouldn't be entirely
trivial.  If I had to do this I would probably turn to JAGS/BUGS.
Looking forward to other answers from the list ...


From j.hadfield at ed.ac.uk  Mon Mar  9 08:50:19 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 09 Mar 2015 07:50:19 +0000
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
	in blme
In-Reply-To: <CAGb-hRoXsEKsX2x0H9WnF0Q8r=kkXxFP4TjMEgmDBB+2pSwNZQ@mail.gmail.com>
References: <CAGb-hRoXsEKsX2x0H9WnF0Q8r=kkXxFP4TjMEgmDBB+2pSwNZQ@mail.gmail.com>
Message-ID: <20150309075019.84131m3s1sr4uzs0@www.staffmail.ed.ac.uk>

Hi Josie,

Is the problem you are having because of complete separation, either  
because you have some very good predictors of lesions and/or you have  
low replication for some factor levels? If so blmer with Gelman's  
recommended prior (not the diffuse prior) should do a reasonable job  
of allowing sensible inferences to be made. However, as Ben said in an  
earlier post,its not clear that this is the problem.

Similar issues are possible with the random effects, but this tends to  
be rare because they are constrained. I only see it when the variance  
component is very large, not zero as here.

If the perceived problem is zero variance estimates, I'm not sure why  
this is a problem. If the true variances are zero you should expect a  
MLE of zero 50% of the time. With only 8 levels of the random effect,  
you should expect an MLE of zero often, even if the true variance is  
moderate. The same power issues will generate MLE correlations of -1  
and 1.

Cheers,

Jarrod





Quoting Josie Galbraith <josie.galbraith at gmail.com> on Mon, 9 Mar 2015  
13:08:59 +1300:

> Thanks very much Jarrod & Vince for your inputs.
> Admittedly this analysis is stretching my level of understanding!
>
> From a practical point of view, given that time is of the essence in
> writing up my PhD, if I only want to test the main effects of my model
> (rather than make predictions etc), is this something I can achieve in
> blme? (ie testing model terms using LRTs).  If so should I be using blme
> for this?
>
> Or should I really be working in MCMCglmm (which I haven't used before -
> another learning curve!)?  Any further thoughts on using normal priors
> rather than Cauchy?
>
> Thanks again,
> Josie
>
>
>
>
>> Message: 2
>>
>> Hi Vince,
>>
>> For a given difference on the logit scale between (lets say) two
>> treatment groups then the difference on the observed scale depends on
>> the magnitude of the variance components. For logit effects beta1 and
>> beta2, the expected difference is approximately:
>>
>> plogis(beta1/sqrt(1+c2*v))-plogis(beta2/sqrt(1+c2*v))
>>
>> where v is the variance component and c2 = (16*sqrt(3)/(15*pi))^2.
>>
>> If a prior (Cauchy or otherwise) was set up that was invariant to v
>> then it would imply different prior beliefs about the magnitude of the
>> difference (on the observed scale) depending on v. For the normal
>> prior it would imply that when v is large we should expect smaller
>> differences between treatment groups. This maybe OK (I'm not sure) but
>> if not is there a way to make it invariant for the t/Cauchy prior? For
>> the normal you can make the scale = sqrt(v+pi^2/3) which seems to work
>> OKish.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Vincent Dorie <vjd4 at nyu.edu> on Sat, 7 Mar 2015 09:47:40 -0500:
>>
>> > Just to follow up on Gelman's Cauchy prior, it seems to work quite
>> > well even in glmms. I don't have any theoretical results as of yet,
>> > but if you look at the sampling distribution of the fixed effects
>> > for any model, they cluster rather nicely. You get "sane" estimates
>> > for when no kind of separation is involved, infinite (or convergence
>> > failures) for complete/quasi complete separation, and a third group
>> > exists with large estimates for when a group contains all 0s or 1s.
>> > In the third case, a random effect can perfectly predict for that
>> > group, but because they're integrated out the likelihood remains
>> > well defined. You'll just get really large estimates of random
>> > effects, which then go with large estimates of fixed effects.
>> >
>> > So long as you believe that some effect magnitudes for logistic
>> > regression pretty much never happen in nature, the Cauchy prior does
>> > a good job of pulling the extreme cases back down to earth while
>> > leaving the well-estimated ones roughly in place. That being said,
>> > using the priors in blme to patch up a data set is really only
>> > advised for checking the viability of a model (usually one among
>> > many, rapidly fit). After that, using something like MCMCglmm for a
>> > fully Bayesian analysis is the way to go.
>> >
>> > Vince
>> >
>> >> On Mar 7, 2015, at 3:09 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>> >>
>> >> Hi Josie,
>> >>
>> >> Regarding the priors on the fixed effects, if complete separation
>> >> is the issue having a diffuse prior is not going to help. Gelman
>> >> (2008) gives some recommendations about priors for logistic
>> >> regression. Although a Cauchy-prior was considered better than a
>> >> t-prior, the latter can be used in blmer and should alleviate
>> >> complete separation issues. I tend to use a normal-prior after
>> >> performing Gelman's rescaling, but this is mainly because MCMCglmm
>> >> only handles normal priors for the fixed effects (this may not be
>> >> true). In a hierarchical model I'm not sure Gelman's advice holds:
>> >> at least with a normal-prior it makes sense to increase the prior
>> >> variance as the random-effect variances increase. If the prior
>> >> variance is approximately v+pi^2/3, where v is the sum of the
>> >> variance components, then the effects on the probability scale are
>> >> quite close to being uniform on the 0,1 interval.
>> >>
>> >> You can use the gelman.prior function to obtain the prior
>> >> covariance matrix for your model. However, note that in the help
>> >> file I say that the scale argument takes the standard deviation. In
>> >> fact it takes the variance, but in the next version of MCMCglmm
>> >> (coming soon) I have fixed this and it will take the standard
>> >> deviation.
>> >>
>> >> Cheers,
>> >>
>> >> Jarrod
>> >>
>> >>
>> >> Gelman, A. et al. (2008) The Annals of Appled Statistics 2 4 1360-1383
>> >>
>> >>
>> >> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Sat, 7 Mar
>> >> 2015 12:15:41 +1300:
>> >>
>> >>> Thanks Ben,
>> >>> I didn't have problems with singular estimates of variance components
>> with
>> >>> this data set.  However, I have a few other pathogens/parasites that
>> I'm
>> >>> looking at (I'm running separate models for each), and after looking
>> at all
>> >>> of them some do have zero variances for the random effect, either in
>> >>> addition to large parameter estimates or alongside reasonable parameter
>> >>> estimates.
>> >>> Should I be also be imposing a covariance prior in either of these
>> cases?
>> >>>
>> >>> As a related aside, my data are collected from individual birds -
>> captured
>> >>> over 4 sampling rounds (6 months apart).  While the majority of
>> >>> observations are independent, there is a small proportion of birds that
>> >>> were recaptured in a subsequent sampling round (between 2?15% of
>> >>> observations, depending on which response variable).  I have modelled
>> my
>> >>> data both both with and without bird ID as a random effect.  Including
>> it
>> >>> seems to cause more problems with zero variances.  Is this because too
>> few
>> >>> of the birds have actually been resampled?
>> >>>
>> >>> Cheers,
>> >>> Josie
>> >>>
>> >>>
>> >>>
>> >>>> Josie Galbraith <josie.galbraith at ...> writes:
>> >>>>
>> >>>> >
>> >>>>
>> >>>> [snip]
>> >>>>
>> >>>> >
>> >>>> > I'm after some advice on how to choose which priors to use.  I
>> gather I
>> >>>> > need to impose a weak prior on the fixed effects of my model but no
>> >>>> > covariance priors - is this correct?  Can I use a default prior
>> (i.e. t,
>> >>>> or
>> >>>> > normal defaults in the blme package) or does it depend on my data?
>> What
>> >>>> is
>> >>>> > considered a suitably weak prior?
>> >>>>
>> >>>>   If all you're trying to do is deal with complete separation (and
>> not,
>> >>>> e.g. singular estimates of variance components [typically indicated
>> >>>> by zero variances or +/- 1 correlations, although I'm not sure those
>> >>>> are necessary conditions for singularity]), then it should be OK
>> >>>> to put the prior only on the fixed effects.  Generally speaking a
>> >>>> weak prior is one with a standard deviation that is large relative
>> >>>> to the expected scale of the effect (e.g. we might say sigma=10 is
>> >>>> large, but it won't be if the units of measurement are very small
>> >>>> so that a typical value of the mean is 100,000 ...)
>> >>>>
>> >>>> > I am running binomial models for epidemiology data (response
>> variable is
>> >>>> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF;
>> SEASON:
>> >>>> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main goal
>> of
>> >>>> > these models is to test for an effect of the treatment 'FOOD.'  I'm
>> >>>> > guessing from what I've read, that my model should be something
>> like the
>> >>>> > following:
>> >>>>
>> >>>>
>> >>>> This seems fairly reasonable at first glance.  Where were you seeing
>> >>>> the complete separation, though?   I would normally expect to
>> >>>> see at least one of the parameters still being reasonably large
>> >>>> if that's the case.
>> >>>>
>> >>>> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
>> >>>> binomial,
>> >>>> > fixef.prior = normal, cov.prior = NULL)
>> >>>> >
>> >>>> > This is the output when I run the model:
>> >>>> >
>> >>>> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...),
>> >>>> common.scale =
>> >>>> > FALSE)
>> >>>> > Prior dev  : 18.2419
>> >>>> >
>> >>>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>> >>>> > Approximation) [
>> >>>> > bglmerMod]
>> >>>> >  Family: binomial ( logit )
>> >>>> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>> >>>> >    Data: SEYE.df
>> >>>> >
>> >>>>
>> >>>> [snip]
>> >>>>
>> >>>> > Random effects:
>> >>>> >  Groups Name        Variance Std.Dev.
>> >>>> >  SITE   (Intercept) 0.3064   0.5535
>> >>>> > Number of obs: 178, groups: SITE, 8
>> >>>> >
>> >>>> > Fixed effects:
>> >>>> >                     Estimate Std. Error z value Pr(>|z|)
>> >>>> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
>> >>>> > FOODNF                0.5462     1.6838   0.324  0.74567
>> >>>> > SEASONSpring          1.7529     1.4721   1.191  0.23378
>> >>>> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
>> >>>> > ---
>> >>>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >>>> >
>> >>>>
>> >>>> [snip]
>> >>>>
>> >>>> ------------------------------
>> >>>>
>> >>>
>> >>>
>> >>> --
>> >>> *Josie Galbraith* MSc (hons)
>> >>>
>> >>> PhD candidate
>> >>> *University of Auckland *
>> >>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>> >>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland
>> 1142* ?
>> >>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: *
>> UoA Web
>> >>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>> >>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>> >>>
>> >>>     [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>
>> >>
>> >> --
>> >> The University of Edinburgh is a charitable body, registered in
>> >> Scotland, with registration number SC005336.
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>> ------------------------------
>>
>> Subject: Digest Footer
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> ------------------------------
>>
>> End of R-sig-mixed-models Digest, Vol 99, Issue 11
>> **************************************************
>>
>
>
>
> --
> *Josie Galbraith* MSc (hons)
>
> PhD candidate
> *University of Auckland *
> Joint Graduate School in Biodiversity and Biosecurity ? School of
> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From thierry.onkelinx at inbo.be  Mon Mar  9 09:22:48 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 9 Mar 2015 09:22:48 +0100
Subject: [R-sig-ME] lmer with binomial distribution of random effects
In-Reply-To: <loom.20150309T021358-280@post.gmane.org>
References: <449B554E28A38046A4BE07F9871EFC724AB983901E@EX1.hof.uni-frankfurt.de>
	<loom.20150309T021358-280@post.gmane.org>
Message-ID: <CAJuCY5z5gxnWCQ7V-a4UVUo1nqoG1TCc6j1d1y09y6ed29xkWA@mail.gmail.com>

Dear Siham,

I would take a step back first. Do you have enough data to fit such a
complex model?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-09 2:15 GMT+01:00 Ben Bolker <bbolker at gmail.com>:

> El Kihal, Siham <Siham.ElKihal at ...> writes:
>
> >
> > Dear lmer() friends,
> >
> > I am trying to estimate a model with a random
> > intercept, and 2 random slopes.
> > I believe that my betas (slopes) do not follow
> >a normal distribution, but rather a bimodal distribution.
> > The reason for this that there are two possible
> > mechanisms that influence the evolution of this variable,
> > one with a negative influence and another one with a
> >  positive influence. This is why I need to use a bimodal
> > distribution for my slopes to avoid the fact that
> > both effects right now cancel out.
> >
> > Does anyone of you has already done this or has
> > an idea how to concretely implement this using lmer()?
>
>   This sounds like a latent mixture model problem.  lme4 doesn't
> do this; you *might* be able to implement an expectation-maximization
> wrapper around lme4 that would do it, but it wouldn't be entirely
> trivial.  If I had to do this I would probably turn to JAGS/BUGS.
> Looking forward to other answers from the list ...
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mervat_moh2006 at yahoo.com  Mon Mar  9 11:53:32 2015
From: mervat_moh2006 at yahoo.com (mervat mohamed)
Date: Mon, 9 Mar 2015 10:53:32 +0000 (UTC)
Subject: [R-sig-ME] (no subject)
Message-ID: <1900105589.1333536.1425898412949.JavaMail.yahoo@mail.yahoo.com>

Dear lmer() friends,

I amtrying to estimate a model about regress deviance y on deviance x

Doesanyone of you has already done this before using lmer() method?
?i want the code of this model

Thanksa lot?

mervat


-------------- next part --------------
A non-text attachment was scrubbed...
Name: blob.jpg
Type: image/png
Size: 2036 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150309/819d3824/attachment-0001.png>

From rubenarslan at gmail.com  Mon Mar  9 12:07:08 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Mon, 09 Mar 2015 11:07:08 +0000
Subject: [R-sig-ME] Prediction and bootstrapping with glmer
Message-ID: <CALv3xzvqHAiFnWmUSraokGtjzmV7DPYDRtaZERiS_Dg0XYsmQg@mail.gmail.com>

Dear list,

I want to inquire about the current state of affairs regarding bootMer and
refit (in lme4 1.1-7).

I am attaching a helper function I made to plot predictions for a factor
variable, maybe it's useful for someone else.
The function makes plots like this https://i.imgur.com/AlKCS9C.png
I plan to use this to visually demonstrate that it is justifiable to use a
linear predictor instead of a factor variable (and hence to simplify my
models) and also simply to show the effect in easily understood quantities
(type='response'), since I noticed at a conference that many people
interpreted my ORs as probabilities because they're smaller than 1,
regardless of intercept and me trying to explain.

I also made a few attempts to do this "the easy way" (?) using the
instructions here: http://glmm.wikidot.com/faq#predconf but my results did
not agree with the bootstrapped results and I liked the violins. I that FAQ
may be out-of-date.
Of course, given my new problems, now I'm not sure if it wasn't the
bootstrapped results that were off.

I am sometimes getting ## T, : some bootstrap runs failed (100/100)
and thought it might be related to this issue this
https://github.com/lme4/lme4/issues/231
For me, it's basically either/or though, mostly all runs fail or all
succeed.

I read there that there might be a computationally intensive workaround for
problems related to refit (using update instead).
I have to bootstrap my predictions on a cluster "anyway" so I would be able
to stomach a performance cost (if it's not huge and even more so if I were
able to use MPI for parallelisation instead of "just" multicore). However,
I've examined the bootMer code and consider it likely that I would botch
things up, if I tried to hotfix it into a self-made bootMer2.

I believe the line
            foo <- try(FUN(refit(x, ss[[i]])), silent = TRUE)

would have to make way for

           foo <- try(FUN({
            newdata = x at frame
            newdata[, names(fit at frame)[1] ] = ss[[i]]
            update(x,data=newdata)
}), silent = TRUE)

but I thought it smarter to ask here first, maybe I'm going about the
entirely wrong way.

Best regards,

Ruben Arslan

Georg August University G?ttingen
Biological Personality Psychology
Georg Elias M?ller Institute of Psychology
Go?lerstr. 14
37073 G?ttingen
Germany
Tel.: +49 551 3920704
https://psych.uni-goettingen.de/en/arslan
https://formr.org


plot_factor_response = function(fit, factor_base = "paternalage.factor",
nsim = 100,
newdata # for context: I left out code where I generate newdata to only
contain one desired level for all predictor except "paternalage.factor"
) {
library(lme4); library(ggplot2); library(dplyr);
modelname = deparse(substitute(fit))
outcome = names(fit at frame)[1]

mypred = function(fit) predict(fit, type = "response", re.form = ~0,
newdata = newdata)
strapped = bootMer(fit, mypred, nsim = nsim, parallel = "multicore", ncpus
= parallel::detectCores())
 mstrapped = suppressMessages(as.data.frame(strapped) %>% melt()) # to
suppress "No id variables; using all as measure variables" which is desired
here
newdata$variable = 1:nrow(newdata)
mstrapped = merge(mstrapped, newdata, by = 'variable')

print( ggplot(mstrapped,  aes_string(x = factor_base, y = "value")) +
 geom_violin(colour = "transparent", fill = "#5ea16e", alpha = 0.3)  +
 geom_pointrange(stat = "summary", fun.data = "mean_sdl")+
 ggtitle(modelname) +
 scale_y_continuous(outcome)  +
 geom_smooth(aes(weight = 1/sd(value, na.rm = T), group = 1),method = "lm",
se = F, lty = "dashed") +
 analysis_theme
)
 class(x = mstrapped) = c("mboot",class(x = mstrapped))
invisible(mstrapped)
}

	[[alternative HTML version deleted]]


From rubenarslan at gmail.com  Mon Mar  9 12:24:19 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Mon, 09 Mar 2015 11:24:19 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
Message-ID: <CALv3xzuRTk+Z8BeBFOKQtD2Bi43ka7daFATbrgufam8CGxfhWw@mail.gmail.com>

Dear list,

I wanted to ask: Is there any (maybe just back of the envelope) way to
obtain a response prediction for zero-inflated or hurdle type models?
I've fit such models in MCMCglmm, but I don't work in ecology and my
previous experience with explaining such models to "my audience" did not
bode well. When it comes to humans, the researchers I presented to are not
used to offspring count being zero-inflated (or acquainted with that
concept), but in my historical data with high infant mortality, it is (in
modern data it's actually slightly underdispersed).

Currently I'm using lme4 and simply splitting my models into two stages
(finding a mate and having offspring).
That's okay too, but in one population the effect of interest is not
clearly visible in either stage, only when both are taken together (but
then the outcome is zero-inflated).
I expect to be given a hard time for this and hence thought I'd use a
binomial model with the outcome offspring>0 as my main model, but that
turns out to be hard to explain too and doesn't really do the data justice.

Basically I don't want to be forced to discuss my smallest population as a
non-replication of the effect because I was insufficiently able to explain
the statistics behind my reasoning that the effect shows.

Best regards,

Ruben Arslan

Georg August University G?ttingen
Biological Personality Psychology
Georg Elias M?ller Institute of Psychology
Go?lerstr. 14
37073 G?ttingen
Germany
Tel.: +49 551 3920704
https://psych.uni-goettingen.de/en/arslan
https://formr.org

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Mar  9 12:58:14 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 9 Mar 2015 12:58:14 +0100
Subject: [R-sig-ME] lmer with binomial distribution of random effects
In-Reply-To: <CB2E5B57-5361-498D-B3FB-8C44D496F8EE@yahoo.de>
References: <449B554E28A38046A4BE07F9871EFC724AB983901E@EX1.hof.uni-frankfurt.de>
	<loom.20150309T021358-280@post.gmane.org>
	<CAJuCY5z5gxnWCQ7V-a4UVUo1nqoG1TCc6j1d1y09y6ed29xkWA@mail.gmail.com>
	<CB2E5B57-5361-498D-B3FB-8C44D496F8EE@yahoo.de>
Message-ID: <CAJuCY5yV8eXoJTAOAeFBsi9mjYMuCf31uT3d4ZZMRC16keaTfw@mail.gmail.com>

Dear Siham,

Please keep the mailing list in cc.

I assume that customer is the grouping factor. Note that you not only need
enough different grouping factor, you also need enough data for each
individual grouping factor. Given that you want a random intercept and two
slopes, then you need to fit a 3 x 3 covariance matrix. That needs 6
parameters. You won't get a stable fit, unless a decent number of customers
have a lot of transactions.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-09 12:43 GMT+01:00 Siham El Kihal <sihamelkihal at yahoo.de>:

> Hi Thierry,
>
> I have tausends of transactions of customers purchases. I guess it should
> be fine.
>
> Siham
>
> > Le 09.03.2015 ? 04:22, Thierry Onkelinx <thierry.onkelinx at inbo.be> a
> ?crit :
> >
> > Dear Siham,
> >
> > I would take a step back first. Do you have enough data to fit such a
> > complex model?
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2015-03-09 2:15 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
> >
> >> El Kihal, Siham <Siham.ElKihal at ...> writes:
> >>
> >>>
> >>> Dear lmer() friends,
> >>>
> >>> I am trying to estimate a model with a random
> >>> intercept, and 2 random slopes.
> >>> I believe that my betas (slopes) do not follow
> >>> a normal distribution, but rather a bimodal distribution.
> >>> The reason for this that there are two possible
> >>> mechanisms that influence the evolution of this variable,
> >>> one with a negative influence and another one with a
> >>> positive influence. This is why I need to use a bimodal
> >>> distribution for my slopes to avoid the fact that
> >>> both effects right now cancel out.
> >>>
> >>> Does anyone of you has already done this or has
> >>> an idea how to concretely implement this using lmer()?
> >>
> >>  This sounds like a latent mixture model problem.  lme4 doesn't
> >> do this; you *might* be able to implement an expectation-maximization
> >> wrapper around lme4 that would do it, but it wouldn't be entirely
> >> trivial.  If I had to do this I would probably turn to JAGS/BUGS.
> >> Looking forward to other answers from the list ...
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >    [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From sihamelkihal at yahoo.de  Mon Mar  9 14:04:57 2015
From: sihamelkihal at yahoo.de (Siham El Kihal)
Date: Mon, 9 Mar 2015 09:04:57 -0400
Subject: [R-sig-ME] lmer with binomial distribution of random effects
In-Reply-To: <CAJuCY5yV8eXoJTAOAeFBsi9mjYMuCf31uT3d4ZZMRC16keaTfw@mail.gmail.com>
References: <449B554E28A38046A4BE07F9871EFC724AB983901E@EX1.hof.uni-frankfurt.de>	<loom.20150309T021358-280@post.gmane.org>	<CAJuCY5z5gxnWCQ7V-a4UVUo1nqoG1TCc6j1d1y09y6ed29xkWA@mail.gmail.com>	<CB2E5B57-5361-498D-B3FB-8C44D496F8EE@yahoo.de>
	<CAJuCY5yV8eXoJTAOAeFBsi9mjYMuCf31uT3d4ZZMRC16keaTfw@mail.gmail.com>
Message-ID: <002401d05a69$a71e4870$f55ad950$@yahoo.de>

Dear Thierry,

 

Thanks for your quick answer. You are right, the customer is the grouping factor in my analysis.

I am using for this analysis only data from customers who have a certain minimum number of observations to make the model work.

 

Still I need  to make the distribution of one of the slopes bi-modal, because I am expecting a certain mechanism to have a negative effect and another one to have a positive effect.

 

Do you have some idea in mind how this would work?

 

Thank you so much!

Siham

 

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Sent: Montag, 9. M?rz 2015 07:58
To: Siham El Kihal; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lmer with binomial distribution of random effects

 

Dear Siham,

 

Please keep the mailing list in cc.

 

I assume that customer is the grouping factor. Note that you not only need enough different grouping factor, you also need enough data for each individual grouping factor. Given that you want a random intercept and two slopes, then you need to fit a 3 x 3 covariance matrix. That needs 6 parameters. You won't get a stable fit, unless a decent number of customers have a lot of transactions.

 

Best regards,




ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

 

2015-03-09 12:43 GMT+01:00 Siham El Kihal <sihamelkihal at yahoo.de <mailto:sihamelkihal at yahoo.de> >:

Hi Thierry,

I have tausends of transactions of customers purchases. I guess it should be fine.

Siham

> Le 09.03.2015 ? 04:22, Thierry Onkelinx <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be> > a ?crit :
>
> Dear Siham,
>
> I would take a step back first. Do you have enough data to fit such a
> complex model?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-03-09 2:15 GMT+01:00 Ben Bolker < <mailto:bbolker at gmail.com> bbolker at gmail.com>:
>
>> El Kihal, Siham < <mailto:Siham.ElKihal at ...> Siham.ElKihal at ...> writes:
>>
>>>
>>> Dear lmer() friends,
>>>
>>> I am trying to estimate a model with a random
>>> intercept, and 2 random slopes.
>>> I believe that my betas (slopes) do not follow
>>> a normal distribution, but rather a bimodal distribution.
>>> The reason for this that there are two possible
>>> mechanisms that influence the evolution of this variable,
>>> one with a negative influence and another one with a
>>> positive influence. This is why I need to use a bimodal
>>> distribution for my slopes to avoid the fact that
>>> both effects right now cancel out.
>>>
>>> Does anyone of you has already done this or has
>>> an idea how to concretely implement this using lmer()?
>>
>>  This sounds like a latent mixture model problem.  lme4 doesn't
>> do this; you *might* be able to implement an expectation-maximization
>> wrapper around lme4 that would do it, but it wouldn't be entirely
>> trivial.  If I had to do this I would probably turn to JAGS/BUGS.
>> Looking forward to other answers from the list ...
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 


	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon Mar  9 18:03:34 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 09 Mar 2015 19:03:34 +0200
Subject: [R-sig-ME] Book: Beginner's Guide to Data Exploration and
 Visualisation with R.
Message-ID: <54FDD266.90306@highstat.com>


We are please to announce the following book:

Title: Beginner's Guide to Data Exploration and Visualisation with R.
Authors: Ieno & Zuur


Book website: http://www.highstat.com/BGDEV.htm

Paperback or EBook can be order (exclusively) from:
http://www.highstat.com/bookorder.htm

TOC: http://www.highstat.com/BGS/DV/TOC_Online.pdf
Price: 29 GBP


Outline:
In 2010 we published a paper in the journal Methods in Ecology and Evolution entitled ?A protocol for data exploration to avoid common statistical problems?. Little did we know at the time that this paper would become one of the journal?s all-time top papers, both top downloaded and top cited papers, with 22,472 downloads between 2010 and 2014.

Based on this success we decided to extend the material in the paper into a book. It is part of our 'Beginner?s Guide to ...' book series. We tried to write this book in such a way that the statistical knowledge level is as low as possible. A knowledge of linear regression is all that you need.


Keywords:
Outliers, normality, homogeneity, collinearity, relationships, confounding. Case studies



Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From mherzog at usgs.gov  Mon Mar  9 21:30:17 2015
From: mherzog at usgs.gov (Mark Herzog)
Date: Mon, 9 Mar 2015 13:30:17 -0700
Subject: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
 failed to reduce deviance in pwrssUpdate
In-Reply-To: <loom.20150309T021601-509@post.gmane.org>
References: <CAM7=EBRe+KSK-zk=zC0YUsbvoGypAi-Yu=Ek3O+YqFVwNC98Lw@mail.gmail.com>
	<loom.20150309T021601-509@post.gmane.org>
Message-ID: <1631f1b7746f0d391ca615e623b198aa@mail.gmail.com>

   RE: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings failed
to reduce deviance in pwrssUpdate

I think it might be a result of you having an exposure period of zero days
in your data... That won't work very well given the link function....

Sorry this is based using my R package, so the codes a little different,
but here's the example:

> library(nestsurvival)

> mydata<-read.csv("c:/users/mherzog/Downloads/habitat-type_example.csv")

>
glm1<-glm(survive/trials~habitat,family=binomial(logexp(days=mydata$expos)),data=mydata)

Error: cannot find valid starting values: please specify some

> mydata<-subset(mydata,expos>0)

>
glm1<-glm(survive/trials~habitat,family=binomial(logexp(days=mydata$expos)),data=mydata)

> summary(glm1)

Call:

glm(formula = survive/trials ~ habitat, family = binomial(logexp(days =
mydata$expos)),

    data = mydata)

Deviance Residuals:

    Min       1Q   Median       3Q      Max

-2.0963  -0.8808   0.5694   0.8052   2.2708

Coefficients:

              Estimate Std. Error z value Pr(>|z|)

(Intercept)     1.9629     0.4036   4.863 1.16e-06 ***

habitatForest  -0.0342     0.4327  -0.079   0.9370

habitatHeath    0.5090     0.4126   1.234   0.2173

habitatScrub    0.8395     0.4497   1.867   0.0619 .

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 787.11  on 568  degrees of freedom

Residual deviance: 621.21  on 565  degrees of freedom

AIC: 629.21

Number of Fisher Scoring iterations: 5

 -----Original Message-----

From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org
<r-sig-mixed-models-bounces at r-project.org>] On Behalf Of Ben Bolker

Sent: Sunday, March 08, 2015 6:18 PM

To: r-sig-mixed-models at r-project.org

Subject: Re: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
failed to reduce deviance in pwrssUpdate

Elwyn Sharps <e.sharps at ...> writes:

>

> Hi Ben

>

> Thank you very much for your reply. If you click on this link, it

> should give you the data in a CSV file.

> https://sites.google.com/site/es263datahlp/habitat-type_example.csv

>

> Many thanks

>

> Elwyn

  I worked on this for a while, without complete success. The main issue is
that the inverse-link function and derivative functions need some clamping
so that they don't hit 0/1 ... this still doesn't solve the lme4 problem,
but at least it allows the GLM to work.

  Have you considered a cloglog link + offset(log(exposure)) model?  That
*might* be a little more stable ...

library(lme4)

library(MASS)

logexp <- function(exposure = 1, eps=1e-8, maxlink=Inf) {

  linkfun <- function(mu) {

      r <- qlogis(mu^(1/exposure))

      ## clamp link function: not actually necessary?

      ##  maxlink set to Inf

      if (any(toobig <- abs(r)>maxlink)) {

          ## cat("max threshold hit")

          r[toobig] <- sign(r[toobig])*maxlink

      }

      return(r)

  }

  ## utility for clamping inverse-link, derivative function

  clamp <- function(x) {

      x <- pmax(eps,x)

      if (upr) x <- pmin(1-eps,x)

      return(x)

  }

  linkinv <- function(eta)  clamp(plogis(eta)^exposure)

  mu.eta <- function(eta) {

      r <- exposure * clamp(plogis(eta)^(exposure-1)) *

          .Call(stats:::C_logit_mu_eta, eta, PACKAGE = "stats")

      return(r)

  }

  valideta <- function(eta) TRUE

  link <- paste("logexp(", deparse(substitute(exposure)), ")",

                sep="")

  structure(list(linkfun = linkfun, linkinv = linkinv,

                 mu.eta = mu.eta, valideta = valideta,

                 name = link),

            class = "link-glm")

}

##Read in data, called 'mydata'

mydata <- read.csv("habitat-type_example.csv")

library("ggplot2")

with(mydata,table(survive,trials))

with(mydata,table(survive,habitat))

ggplot(mydata,aes(log(1+expos),survive,colour=habitat))+

    geom_point()+

    geom_smooth(method="glm",family="binomial")

ggplot(subset(mydata,habitat=="Conregrowth"),

       aes(expos,survive))+

           stat_sum(aes(size=..n..))+

    geom_smooth(method="glm",family="binomial")+

        scale_size_area()

## trials is always == 1 in this data set

## the fact that glm() fails means that the problem is more ## basic than a
GLMM problem

glm1 <- glm(survive~habitat,

            family=binomial(logexp(exposure=mydata$expos)),

            data=mydata)

Mod1 <- glmer(survive~habitat + (1|site)+(1|year),

              family=binomial(logexp(exposure=mydata$expos)),data=mydata,

              nAGQ=1,

              devFunOnly=TRUE,

              control=glmerControl(nAGQ0initStep=FALSE),

              start=list(beta=coef(glm1),theta=1e-5),

              verbose=100)

Mod2 <- glmer(survive~habitat + (1|year),

              family=binomial(logexp(exposure=mydata$expos)),data=mydata,

              start=list(theta=c(1e-6,1e-6)),

              nAGQ=0,

              devFunOnly=TRUE)

Mod3 <- glmer(survive~habitat + (1|site),

              family=binomial(logexp(exposure=mydata$expos)),data=mydata,

              start=list(theta=c(1e-6,1e-6)),

              nAGQ=0,

              devFunOnly=TRUE)

mydata3 <- droplevels(subset(mydata,habitat!="Conregrowth"))

Mod4 <- glmer(survive~habitat + (1|year),

              family=binomial(logexp(exposure=mydata3$expos)),data=mydata3)

Mod5 <- glmer(survive~habitat + (1|site),

              family=binomial(logexp(exposure=mydata3$expos)),data=mydata3,

              nAGQ=1,

              devFunOnly=TRUE,

              control=glmerControl(nAGQ0initStep=FALSE),

              start=list(beta=coef(glm1),theta=1e-5),

              verbose=100)

with(mydata3,table(site,habitat,survive))

with(mydata,table(year,habitat,survive))

>

> On 5 March 2015 at 03:11, Ben Bolker <bbolker at ...> wrote:

>

> > Elwyn Sharps <e.sharps <at> ...> writes:

> >

> > >

> >

> > [snip]

> >

> > > I am using a nest survival model (glmer) with random effects and a

> > logistic

> > > exposure link function, as described here:

> > >

> > >

> > http://stackoverflow.com/questions/19012128/user-defined-link-functi

> > on-for-

> > > glmer-for-known-fate-survival-modelling

> > >

> > > I am running a number of different models, with varying fixed effects.

> > Some

> > > of them are running well, with no error or warning messages,

> > > however for other models, I am getting the following message:

> > >

> > > *Error: (maxstephalfit) PIRLS step-halvings failed to reduce

> > > deviance in

> > > pwrssUpdate*

> > >

> > > I'm not sure what is causing this error. I have tried to check the

> > > data

> > for

> > > simple problems, however can't see anything that could be causing

> > trouble.

> > >

> > > I've also tried running the model without the random effects. This

> > results

> > > in a different error message:

> > >

> > > *Error: cannot find valid starting values: please specify some*

> >

> >   Example data doesn't seem to be attached: it may have been

> > stripped by the mailing list software.  Can you post it somewhere

> > public and provide a URL?

> >

> >   My guess it that there is something rather wonky about the data

> > for this example, e.g. complete separation (for example, no

> > individuals die for some combination of predictor variables).  Hard

> > to say without the data though.

> >

> >   Ben Bolker

> >

> > _______________________________________________

> > R-sig-mixed-models at ... mailing list

> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

> >

>

>       [[alternative HTML version deleted]]

>

>

_______________________________________________

R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Mar  9 22:06:58 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 09 Mar 2015 17:06:58 -0400
Subject: [R-sig-ME] (no subject)
In-Reply-To: <1900105589.1333536.1425898412949.JavaMail.yahoo@mail.yahoo.com>
References: <1900105589.1333536.1425898412949.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54FE0B72.1030006@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-09 06:53 AM, mervat mohamed via R-sig-mixed-models wrote:
> Dear lmer() friends,
> 
> I amtrying to estimate a model about regress deviance y on deviance
> x
> 
> Doesanyone of you has already done this before using lmer()
> method? i want the code of this model
> 
> Thanksa lot
> 
> mervat
> 
> 
> 

transcribing your equation into TeX format:

(y_{ij} - \bar y_{.j}) =
   \beta(x_{ij}-\bar x_{.j}) + e_{ij} - \bar e_{.j}

It's not really clear to me what you want to do.  It looks like
it *might* be a random_slope model.  In other words,

  y ~ x + (x|f)

where x is a continuous covariate and f is a grouping variable
(factor) gives

 y_{ij} = beta_0 + beta_1*x + (b_{0j} + b_{1j}*x)

Where b_{0j} is a group-level deviate from the intercept and b_{1j} is
a group-level deviation from the slope.

Is that translatable into your context?

Depending on how you want your results presented, van de Pol and
Wright 2009 might be useful:
http://www.myscience.eu/martijn/pdfs/vandePol%26Wright2009_AnimBeh.pdf

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU/gtxAAoJEOCV5YRblxUHWpkH+wXX9P8xmK8pQoBmix/Jtk4E
MmS5V2G0REuuiZHcOpjNVfWH4+Mda3VrULiZ5C2PJkLAizAZ0ME/HTtW8Ai2wAGx
tJDlo5A19/WMGGo3OHH8hU2UroCJWFfa3Ion4jVMP6911t5lL4Eewb+B+BcxcvQD
QIhs8hH+i9Pv9lOEWtzpgxp7Elhjs0q4wXRF++CopBG3mKHtutl7G1+zFS+jm64o
ZztJ7MZ/oeAvNHTExi0rxdB6MDrcX5eXHrRiDCP5OD7rD6MWxfEezne1QV/V1feX
R21iN64wBiSSZmTFCy3xP+Vl7CZ/hJvXsKvPf7c0HwfUwN0TflXN3GO8Jf2Ebcs=
=iics
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Mon Mar  9 22:10:28 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Mar 2015 21:10:28 +0000 (UTC)
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
References: <CALv3xzuRTk+Z8BeBFOKQtD2Bi43ka7daFATbrgufam8CGxfhWw@mail.gmail.com>
Message-ID: <loom.20150309T220710-595@post.gmane.org>

Ruben Arslan <rubenarslan at ...> writes:

> 
> Dear list,
> 
> I wanted to ask: Is there any (maybe just back of the envelope) way to
> obtain a response prediction for zero-inflated or hurdle type models?
> I've fit such models in MCMCglmm, but I don't work in ecology and my
> previous experience with explaining such models to "my audience" did not
> bode well. When it comes to humans, the researchers I presented to are not
> used to offspring count being zero-inflated (or acquainted with that
> concept), but in my historical data with high infant mortality, it is (in
> modern data it's actually slightly underdispersed).
> 
> Currently I'm using lme4 and simply splitting my models into two stages
> (finding a mate and having offspring).
> That's okay too, but in one population the effect of interest is not
> clearly visible in either stage, only when both are taken together (but
> then the outcome is zero-inflated).
> I expect to be given a hard time for this and hence thought I'd use a
> binomial model with the outcome offspring>0 as my main model, but that
> turns out to be hard to explain too and doesn't 
> really do the data justice.
> 
> Basically I don't want to be forced to discuss my smallest population as a
> non-replication of the effect because I was insufficiently able to explain
> the statistics behind my reasoning that the effect shows.

  I think the back-of-the envelope answer would be that for a two-stage
model with a prediction of p_i for the probability of having a non-zero
response (or in the case of zero-inflated models, the probability of
_not_ having a structural zero) and a prediction of n_i for the conditional
part of the model, the mean predicted value is p_i*n_i and the 
variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 + var(n_i)/n_i^2)
(this is assuming
that you haven't built in any correlation between p_i and n_i, which
would be hard in lme4 but _might_ be possible under certain circumstances
via a multitype model in MCMCglmm).

  Does that help?


From josie.galbraith at gmail.com  Mon Mar  9 22:30:12 2015
From: josie.galbraith at gmail.com (Josie Galbraith)
Date: Tue, 10 Mar 2015 10:30:12 +1300
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
	in blme
In-Reply-To: <20150309075019.84131m3s1sr4uzs0@www.staffmail.ed.ac.uk>
References: <CAGb-hRoXsEKsX2x0H9WnF0Q8r=kkXxFP4TjMEgmDBB+2pSwNZQ@mail.gmail.com>
	<20150309075019.84131m3s1sr4uzs0@www.staffmail.ed.ac.uk>
Message-ID: <CAGb-hRpECdi23WD74wsFF1byiCJqZj5to5qD7N8TCC1QYa_GNA@mail.gmail.com>

Hi Jarrod,

I'm pretty sure it is a complete separation issue.  This is the xtab of
counts for the main factors:

                                LESION  0    1
SEASON     FOOD
Autumn            NF                 38   2
                          F                  21   0
Spring              NF                 27   3
                         F                   76  11

Lesion incidences were low generally, but particularly so in Autumn (and
fewer replicates in Autumn).

Thanks again,
Josie





On Mon, Mar 9, 2015 at 8:50 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Josie,
>
> Is the problem you are having because of complete separation, either
> because you have some very good predictors of lesions and/or you have low
> replication for some factor levels? If so blmer with Gelman's recommended
> prior (not the diffuse prior) should do a reasonable job of allowing
> sensible inferences to be made. However, as Ben said in an earlier post,its
> not clear that this is the problem.
>
> Similar issues are possible with the random effects, but this tends to be
> rare because they are constrained. I only see it when the variance
> component is very large, not zero as here.
>
> If the perceived problem is zero variance estimates, I'm not sure why this
> is a problem. If the true variances are zero you should expect a MLE of
> zero 50% of the time. With only 8 levels of the random effect, you should
> expect an MLE of zero often, even if the true variance is moderate. The
> same power issues will generate MLE correlations of -1 and 1.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Mon, 9 Mar 2015
> 13:08:59 +1300:
>
>  Thanks very much Jarrod & Vince for your inputs.
>> Admittedly this analysis is stretching my level of understanding!
>>
>> From a practical point of view, given that time is of the essence in
>> writing up my PhD, if I only want to test the main effects of my model
>> (rather than make predictions etc), is this something I can achieve in
>> blme? (ie testing model terms using LRTs).  If so should I be using blme
>> for this?
>>
>> Or should I really be working in MCMCglmm (which I haven't used before -
>> another learning curve!)?  Any further thoughts on using normal priors
>> rather than Cauchy?
>>
>> Thanks again,
>> Josie
>>
>>
>>
>>
>>  Message: 2
>>>
>>> Hi Vince,
>>>
>>> For a given difference on the logit scale between (lets say) two
>>> treatment groups then the difference on the observed scale depends on
>>> the magnitude of the variance components. For logit effects beta1 and
>>> beta2, the expected difference is approximately:
>>>
>>> plogis(beta1/sqrt(1+c2*v))-plogis(beta2/sqrt(1+c2*v))
>>>
>>> where v is the variance component and c2 = (16*sqrt(3)/(15*pi))^2.
>>>
>>> If a prior (Cauchy or otherwise) was set up that was invariant to v
>>> then it would imply different prior beliefs about the magnitude of the
>>> difference (on the observed scale) depending on v. For the normal
>>> prior it would imply that when v is large we should expect smaller
>>> differences between treatment groups. This maybe OK (I'm not sure) but
>>> if not is there a way to make it invariant for the t/Cauchy prior? For
>>> the normal you can make the scale = sqrt(v+pi^2/3) which seems to work
>>> OKish.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>> Quoting Vincent Dorie <vjd4 at nyu.edu> on Sat, 7 Mar 2015 09:47:40 -0500:
>>>
>>> > Just to follow up on Gelman's Cauchy prior, it seems to work quite
>>> > well even in glmms. I don't have any theoretical results as of yet,
>>> > but if you look at the sampling distribution of the fixed effects
>>> > for any model, they cluster rather nicely. You get "sane" estimates
>>> > for when no kind of separation is involved, infinite (or convergence
>>> > failures) for complete/quasi complete separation, and a third group
>>> > exists with large estimates for when a group contains all 0s or 1s.
>>> > In the third case, a random effect can perfectly predict for that
>>> > group, but because they're integrated out the likelihood remains
>>> > well defined. You'll just get really large estimates of random
>>> > effects, which then go with large estimates of fixed effects.
>>> >
>>> > So long as you believe that some effect magnitudes for logistic
>>> > regression pretty much never happen in nature, the Cauchy prior does
>>> > a good job of pulling the extreme cases back down to earth while
>>> > leaving the well-estimated ones roughly in place. That being said,
>>> > using the priors in blme to patch up a data set is really only
>>> > advised for checking the viability of a model (usually one among
>>> > many, rapidly fit). After that, using something like MCMCglmm for a
>>> > fully Bayesian analysis is the way to go.
>>> >
>>> > Vince
>>> >
>>> >> On Mar 7, 2015, at 3:09 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> wrote:
>>> >>
>>> >> Hi Josie,
>>> >>
>>> >> Regarding the priors on the fixed effects, if complete separation
>>> >> is the issue having a diffuse prior is not going to help. Gelman
>>> >> (2008) gives some recommendations about priors for logistic
>>> >> regression. Although a Cauchy-prior was considered better than a
>>> >> t-prior, the latter can be used in blmer and should alleviate
>>> >> complete separation issues. I tend to use a normal-prior after
>>> >> performing Gelman's rescaling, but this is mainly because MCMCglmm
>>> >> only handles normal priors for the fixed effects (this may not be
>>> >> true). In a hierarchical model I'm not sure Gelman's advice holds:
>>> >> at least with a normal-prior it makes sense to increase the prior
>>> >> variance as the random-effect variances increase. If the prior
>>> >> variance is approximately v+pi^2/3, where v is the sum of the
>>> >> variance components, then the effects on the probability scale are
>>> >> quite close to being uniform on the 0,1 interval.
>>> >>
>>> >> You can use the gelman.prior function to obtain the prior
>>> >> covariance matrix for your model. However, note that in the help
>>> >> file I say that the scale argument takes the standard deviation. In
>>> >> fact it takes the variance, but in the next version of MCMCglmm
>>> >> (coming soon) I have fixed this and it will take the standard
>>> >> deviation.
>>> >>
>>> >> Cheers,
>>> >>
>>> >> Jarrod
>>> >>
>>> >>
>>> >> Gelman, A. et al. (2008) The Annals of Appled Statistics 2 4 1360-1383
>>> >>
>>> >>
>>> >> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Sat, 7 Mar
>>> >> 2015 12:15:41 +1300:
>>> >>
>>> >>> Thanks Ben,
>>> >>> I didn't have problems with singular estimates of variance components
>>> with
>>> >>> this data set.  However, I have a few other pathogens/parasites that
>>> I'm
>>> >>> looking at (I'm running separate models for each), and after looking
>>> at all
>>> >>> of them some do have zero variances for the random effect, either in
>>> >>> addition to large parameter estimates or alongside reasonable
>>> parameter
>>> >>> estimates.
>>> >>> Should I be also be imposing a covariance prior in either of these
>>> cases?
>>> >>>
>>> >>> As a related aside, my data are collected from individual birds -
>>> captured
>>> >>> over 4 sampling rounds (6 months apart).  While the majority of
>>> >>> observations are independent, there is a small proportion of birds
>>> that
>>> >>> were recaptured in a subsequent sampling round (between 2?15% of
>>> >>> observations, depending on which response variable).  I have modelled
>>> my
>>> >>> data both both with and without bird ID as a random effect.
>>> Including
>>> it
>>> >>> seems to cause more problems with zero variances.  Is this because
>>> too
>>> few
>>> >>> of the birds have actually been resampled?
>>> >>>
>>> >>> Cheers,
>>> >>> Josie
>>> >>>
>>> >>>
>>> >>>
>>> >>>> Josie Galbraith <josie.galbraith at ...> writes:
>>> >>>>
>>> >>>> >
>>> >>>>
>>> >>>> [snip]
>>> >>>>
>>> >>>> >
>>> >>>> > I'm after some advice on how to choose which priors to use.  I
>>> gather I
>>> >>>> > need to impose a weak prior on the fixed effects of my model but
>>> no
>>> >>>> > covariance priors - is this correct?  Can I use a default prior
>>> (i.e. t,
>>> >>>> or
>>> >>>> > normal defaults in the blme package) or does it depend on my data?
>>> What
>>> >>>> is
>>> >>>> > considered a suitably weak prior?
>>> >>>>
>>> >>>>   If all you're trying to do is deal with complete separation (and
>>> not,
>>> >>>> e.g. singular estimates of variance components [typically indicated
>>> >>>> by zero variances or +/- 1 correlations, although I'm not sure those
>>> >>>> are necessary conditions for singularity]), then it should be OK
>>> >>>> to put the prior only on the fixed effects.  Generally speaking a
>>> >>>> weak prior is one with a standard deviation that is large relative
>>> >>>> to the expected scale of the effect (e.g. we might say sigma=10 is
>>> >>>> large, but it won't be if the units of measurement are very small
>>> >>>> so that a typical value of the mean is 100,000 ...)
>>> >>>>
>>> >>>> > I am running binomial models for epidemiology data (response
>>> variable is
>>> >>>> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF;
>>> SEASON:
>>> >>>> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main
>>> goal
>>> of
>>> >>>> > these models is to test for an effect of the treatment 'FOOD.'
>>> I'm
>>> >>>> > guessing from what I've read, that my model should be something
>>> like the
>>> >>>> > following:
>>> >>>>
>>> >>>>
>>> >>>> This seems fairly reasonable at first glance.  Where were you seeing
>>> >>>> the complete separation, though?   I would normally expect to
>>> >>>> see at least one of the parameters still being reasonably large
>>> >>>> if that's the case.
>>> >>>>
>>> >>>> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
>>> >>>> binomial,
>>> >>>> > fixef.prior = normal, cov.prior = NULL)
>>> >>>> >
>>> >>>> > This is the output when I run the model:
>>> >>>> >
>>> >>>> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...),
>>> >>>> common.scale =
>>> >>>> > FALSE)
>>> >>>> > Prior dev  : 18.2419
>>> >>>> >
>>> >>>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>>> >>>> > Approximation) [
>>> >>>> > bglmerMod]
>>> >>>> >  Family: binomial ( logit )
>>> >>>> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>>> >>>> >    Data: SEYE.df
>>> >>>> >
>>> >>>>
>>> >>>> [snip]
>>> >>>>
>>> >>>> > Random effects:
>>> >>>> >  Groups Name        Variance Std.Dev.
>>> >>>> >  SITE   (Intercept) 0.3064   0.5535
>>> >>>> > Number of obs: 178, groups: SITE, 8
>>> >>>> >
>>> >>>> > Fixed effects:
>>> >>>> >                     Estimate Std. Error z value Pr(>|z|)
>>> >>>> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
>>> >>>> > FOODNF                0.5462     1.6838   0.324  0.74567
>>> >>>> > SEASONSpring          1.7529     1.4721   1.191  0.23378
>>> >>>> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
>>> >>>> > ---
>>> >>>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> >>>> >
>>> >>>>
>>> >>>> [snip]
>>> >>>>
>>> >>>> ------------------------------
>>> >>>>
>>> >>>
>>> >>>
>>> >>> --
>>> >>> *Josie Galbraith* MSc (hons)
>>> >>>
>>> >>> PhD candidate
>>> >>> *University of Auckland *
>>> >>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>>> >>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland
>>> 1142* ?
>>> >>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: *
>>> UoA Web
>>> >>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>>> >>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>>> >>>
>>> >>>     [[alternative HTML version deleted]]
>>> >>>
>>> >>> _______________________________________________
>>> >>> R-sig-mixed-models at r-project.org mailing list
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>
>>> >>
>>> >>
>>> >> --
>>> >> The University of Edinburgh is a charitable body, registered in
>>> >> Scotland, with registration number SC005336.
>>> >>
>>> >> _______________________________________________
>>> >> R-sig-mixed-models at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>> >
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Subject: Digest Footer
>>>
>>> _______________________________________________
>>> R-sig-mixed-models mailing list
>>> R-sig-mixed-models at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> ------------------------------
>>>
>>> End of R-sig-mixed-models Digest, Vol 99, Issue 11
>>> **************************************************
>>>
>>>
>>
>>
>> --
>> *Josie Galbraith* MSc (hons)
>>
>> PhD candidate
>> *University of Auckland *
>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA
>> Web
>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
*Josie Galbraith* MSc (hons)

PhD candidate
*University of Auckland *
Joint Graduate School in Biodiversity and Biosecurity ? School of
Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
*www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Mar 10 08:15:36 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 10 Mar 2015 07:15:36 +0000
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
	in blme
In-Reply-To: <CAGb-hRpECdi23WD74wsFF1byiCJqZj5to5qD7N8TCC1QYa_GNA@mail.gmail.com>
References: <CAGb-hRoXsEKsX2x0H9WnF0Q8r=kkXxFP4TjMEgmDBB+2pSwNZQ@mail.gmail.com>
	<20150309075019.84131m3s1sr4uzs0@www.staffmail.ed.ac.uk>
	<CAGb-hRpECdi23WD74wsFF1byiCJqZj5to5qD7N8TCC1QYa_GNA@mail.gmail.com>
Message-ID: <20150310071536.82277l56psd3iz48@www.staffmail.ed.ac.uk>

Hi Josie,

Yes - I would scale your input variables and go for the t-prior in  
blme (I think the Cauchy prior is not implemented?). You might want to  
up the scale a little from that recommended in order to deal with the  
fact you may have non-zero random effects, but it might not make a big  
difference if their variance isn't too large.

Cheers,

Jarrod



Quoting Josie Galbraith <josie.galbraith at gmail.com> on Tue, 10 Mar  
2015 10:30:12 +1300:

> Hi Jarrod,
>
> I'm pretty sure it is a complete separation issue.  This is the xtab of
> counts for the main factors:
>
>                                 LESION  0    1
> SEASON     FOOD
> Autumn            NF                 38   2
>                           F                  21   0
> Spring              NF                 27   3
>                          F                   76  11
>
> Lesion incidences were low generally, but particularly so in Autumn (and
> fewer replicates in Autumn).
>
> Thanks again,
> Josie
>
>
>
>
>
> On Mon, Mar 9, 2015 at 8:50 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi Josie,
>>
>> Is the problem you are having because of complete separation, either
>> because you have some very good predictors of lesions and/or you have low
>> replication for some factor levels? If so blmer with Gelman's recommended
>> prior (not the diffuse prior) should do a reasonable job of allowing
>> sensible inferences to be made. However, as Ben said in an earlier post,its
>> not clear that this is the problem.
>>
>> Similar issues are possible with the random effects, but this tends to be
>> rare because they are constrained. I only see it when the variance
>> component is very large, not zero as here.
>>
>> If the perceived problem is zero variance estimates, I'm not sure why this
>> is a problem. If the true variances are zero you should expect a MLE of
>> zero 50% of the time. With only 8 levels of the random effect, you should
>> expect an MLE of zero often, even if the true variance is moderate. The
>> same power issues will generate MLE correlations of -1 and 1.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Mon, 9 Mar 2015
>> 13:08:59 +1300:
>>
>>  Thanks very much Jarrod & Vince for your inputs.
>>> Admittedly this analysis is stretching my level of understanding!
>>>
>>> From a practical point of view, given that time is of the essence in
>>> writing up my PhD, if I only want to test the main effects of my model
>>> (rather than make predictions etc), is this something I can achieve in
>>> blme? (ie testing model terms using LRTs).  If so should I be using blme
>>> for this?
>>>
>>> Or should I really be working in MCMCglmm (which I haven't used before -
>>> another learning curve!)?  Any further thoughts on using normal priors
>>> rather than Cauchy?
>>>
>>> Thanks again,
>>> Josie
>>>
>>>
>>>
>>>
>>>  Message: 2
>>>>
>>>> Hi Vince,
>>>>
>>>> For a given difference on the logit scale between (lets say) two
>>>> treatment groups then the difference on the observed scale depends on
>>>> the magnitude of the variance components. For logit effects beta1 and
>>>> beta2, the expected difference is approximately:
>>>>
>>>> plogis(beta1/sqrt(1+c2*v))-plogis(beta2/sqrt(1+c2*v))
>>>>
>>>> where v is the variance component and c2 = (16*sqrt(3)/(15*pi))^2.
>>>>
>>>> If a prior (Cauchy or otherwise) was set up that was invariant to v
>>>> then it would imply different prior beliefs about the magnitude of the
>>>> difference (on the observed scale) depending on v. For the normal
>>>> prior it would imply that when v is large we should expect smaller
>>>> differences between treatment groups. This maybe OK (I'm not sure) but
>>>> if not is there a way to make it invariant for the t/Cauchy prior? For
>>>> the normal you can make the scale = sqrt(v+pi^2/3) which seems to work
>>>> OKish.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>> Quoting Vincent Dorie <vjd4 at nyu.edu> on Sat, 7 Mar 2015 09:47:40 -0500:
>>>>
>>>> > Just to follow up on Gelman's Cauchy prior, it seems to work quite
>>>> > well even in glmms. I don't have any theoretical results as of yet,
>>>> > but if you look at the sampling distribution of the fixed effects
>>>> > for any model, they cluster rather nicely. You get "sane" estimates
>>>> > for when no kind of separation is involved, infinite (or convergence
>>>> > failures) for complete/quasi complete separation, and a third group
>>>> > exists with large estimates for when a group contains all 0s or 1s.
>>>> > In the third case, a random effect can perfectly predict for that
>>>> > group, but because they're integrated out the likelihood remains
>>>> > well defined. You'll just get really large estimates of random
>>>> > effects, which then go with large estimates of fixed effects.
>>>> >
>>>> > So long as you believe that some effect magnitudes for logistic
>>>> > regression pretty much never happen in nature, the Cauchy prior does
>>>> > a good job of pulling the extreme cases back down to earth while
>>>> > leaving the well-estimated ones roughly in place. That being said,
>>>> > using the priors in blme to patch up a data set is really only
>>>> > advised for checking the viability of a model (usually one among
>>>> > many, rapidly fit). After that, using something like MCMCglmm for a
>>>> > fully Bayesian analysis is the way to go.
>>>> >
>>>> > Vince
>>>> >
>>>> >> On Mar 7, 2015, at 3:09 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> wrote:
>>>> >>
>>>> >> Hi Josie,
>>>> >>
>>>> >> Regarding the priors on the fixed effects, if complete separation
>>>> >> is the issue having a diffuse prior is not going to help. Gelman
>>>> >> (2008) gives some recommendations about priors for logistic
>>>> >> regression. Although a Cauchy-prior was considered better than a
>>>> >> t-prior, the latter can be used in blmer and should alleviate
>>>> >> complete separation issues. I tend to use a normal-prior after
>>>> >> performing Gelman's rescaling, but this is mainly because MCMCglmm
>>>> >> only handles normal priors for the fixed effects (this may not be
>>>> >> true). In a hierarchical model I'm not sure Gelman's advice holds:
>>>> >> at least with a normal-prior it makes sense to increase the prior
>>>> >> variance as the random-effect variances increase. If the prior
>>>> >> variance is approximately v+pi^2/3, where v is the sum of the
>>>> >> variance components, then the effects on the probability scale are
>>>> >> quite close to being uniform on the 0,1 interval.
>>>> >>
>>>> >> You can use the gelman.prior function to obtain the prior
>>>> >> covariance matrix for your model. However, note that in the help
>>>> >> file I say that the scale argument takes the standard deviation. In
>>>> >> fact it takes the variance, but in the next version of MCMCglmm
>>>> >> (coming soon) I have fixed this and it will take the standard
>>>> >> deviation.
>>>> >>
>>>> >> Cheers,
>>>> >>
>>>> >> Jarrod
>>>> >>
>>>> >>
>>>> >> Gelman, A. et al. (2008) The Annals of Appled Statistics 2 4 1360-1383
>>>> >>
>>>> >>
>>>> >> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Sat, 7 Mar
>>>> >> 2015 12:15:41 +1300:
>>>> >>
>>>> >>> Thanks Ben,
>>>> >>> I didn't have problems with singular estimates of variance components
>>>> with
>>>> >>> this data set.  However, I have a few other pathogens/parasites that
>>>> I'm
>>>> >>> looking at (I'm running separate models for each), and after looking
>>>> at all
>>>> >>> of them some do have zero variances for the random effect, either in
>>>> >>> addition to large parameter estimates or alongside reasonable
>>>> parameter
>>>> >>> estimates.
>>>> >>> Should I be also be imposing a covariance prior in either of these
>>>> cases?
>>>> >>>
>>>> >>> As a related aside, my data are collected from individual birds -
>>>> captured
>>>> >>> over 4 sampling rounds (6 months apart).  While the majority of
>>>> >>> observations are independent, there is a small proportion of birds
>>>> that
>>>> >>> were recaptured in a subsequent sampling round (between 2?15% of
>>>> >>> observations, depending on which response variable).  I have modelled
>>>> my
>>>> >>> data both both with and without bird ID as a random effect.
>>>> Including
>>>> it
>>>> >>> seems to cause more problems with zero variances.  Is this because
>>>> too
>>>> few
>>>> >>> of the birds have actually been resampled?
>>>> >>>
>>>> >>> Cheers,
>>>> >>> Josie
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>> Josie Galbraith <josie.galbraith at ...> writes:
>>>> >>>>
>>>> >>>> >
>>>> >>>>
>>>> >>>> [snip]
>>>> >>>>
>>>> >>>> >
>>>> >>>> > I'm after some advice on how to choose which priors to use.  I
>>>> gather I
>>>> >>>> > need to impose a weak prior on the fixed effects of my model but
>>>> no
>>>> >>>> > covariance priors - is this correct?  Can I use a default prior
>>>> (i.e. t,
>>>> >>>> or
>>>> >>>> > normal defaults in the blme package) or does it depend on my data?
>>>> What
>>>> >>>> is
>>>> >>>> > considered a suitably weak prior?
>>>> >>>>
>>>> >>>>   If all you're trying to do is deal with complete separation (and
>>>> not,
>>>> >>>> e.g. singular estimates of variance components [typically indicated
>>>> >>>> by zero variances or +/- 1 correlations, although I'm not sure those
>>>> >>>> are necessary conditions for singularity]), then it should be OK
>>>> >>>> to put the prior only on the fixed effects.  Generally speaking a
>>>> >>>> weak prior is one with a standard deviation that is large relative
>>>> >>>> to the expected scale of the effect (e.g. we might say sigma=10 is
>>>> >>>> large, but it won't be if the units of measurement are very small
>>>> >>>> so that a typical value of the mean is 100,000 ...)
>>>> >>>>
>>>> >>>> > I am running binomial models for epidemiology data (response
>>>> variable is
>>>> >>>> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF;
>>>> SEASON:
>>>> >>>> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main
>>>> goal
>>>> of
>>>> >>>> > these models is to test for an effect of the treatment 'FOOD.'
>>>> I'm
>>>> >>>> > guessing from what I've read, that my model should be something
>>>> like the
>>>> >>>> > following:
>>>> >>>>
>>>> >>>>
>>>> >>>> This seems fairly reasonable at first glance.  Where were you seeing
>>>> >>>> the complete separation, though?   I would normally expect to
>>>> >>>> see at least one of the parameters still being reasonably large
>>>> >>>> if that's the case.
>>>> >>>>
>>>> >>>> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
>>>> >>>> binomial,
>>>> >>>> > fixef.prior = normal, cov.prior = NULL)
>>>> >>>> >
>>>> >>>> > This is the output when I run the model:
>>>> >>>> >
>>>> >>>> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...),
>>>> >>>> common.scale =
>>>> >>>> > FALSE)
>>>> >>>> > Prior dev  : 18.2419
>>>> >>>> >
>>>> >>>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>>>> >>>> > Approximation) [
>>>> >>>> > bglmerMod]
>>>> >>>> >  Family: binomial ( logit )
>>>> >>>> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>>>> >>>> >    Data: SEYE.df
>>>> >>>> >
>>>> >>>>
>>>> >>>> [snip]
>>>> >>>>
>>>> >>>> > Random effects:
>>>> >>>> >  Groups Name        Variance Std.Dev.
>>>> >>>> >  SITE   (Intercept) 0.3064   0.5535
>>>> >>>> > Number of obs: 178, groups: SITE, 8
>>>> >>>> >
>>>> >>>> > Fixed effects:
>>>> >>>> >                     Estimate Std. Error z value Pr(>|z|)
>>>> >>>> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
>>>> >>>> > FOODNF                0.5462     1.6838   0.324  0.74567
>>>> >>>> > SEASONSpring          1.7529     1.4721   1.191  0.23378
>>>> >>>> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
>>>> >>>> > ---
>>>> >>>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> >>>> >
>>>> >>>>
>>>> >>>> [snip]
>>>> >>>>
>>>> >>>> ------------------------------
>>>> >>>>
>>>> >>>
>>>> >>>
>>>> >>> --
>>>> >>> *Josie Galbraith* MSc (hons)
>>>> >>>
>>>> >>> PhD candidate
>>>> >>> *University of Auckland *
>>>> >>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>>>> >>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland
>>>> 1142* ?
>>>> >>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: *
>>>> UoA Web
>>>> >>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>>>> >>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>>>> >>>
>>>> >>>     [[alternative HTML version deleted]]
>>>> >>>
>>>> >>> _______________________________________________
>>>> >>> R-sig-mixed-models at r-project.org mailing list
>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>
>>>> >>
>>>> >>
>>>> >> --
>>>> >> The University of Edinburgh is a charitable body, registered in
>>>> >> Scotland, with registration number SC005336.
>>>> >>
>>>> >> _______________________________________________
>>>> >> R-sig-mixed-models at r-project.org mailing list
>>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >
>>>> > _______________________________________________
>>>> > R-sig-mixed-models at r-project.org mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >
>>>> >
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>>
>>>> ------------------------------
>>>>
>>>> Subject: Digest Footer
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models mailing list
>>>> R-sig-mixed-models at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>> ------------------------------
>>>>
>>>> End of R-sig-mixed-models Digest, Vol 99, Issue 11
>>>> **************************************************
>>>>
>>>>
>>>
>>>
>>> --
>>> *Josie Galbraith* MSc (hons)
>>>
>>> PhD candidate
>>> *University of Auckland *
>>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
>>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA
>>> Web
>>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> *Josie Galbraith* MSc (hons)
>
> PhD candidate
> *University of Auckland *
> Joint Graduate School in Biodiversity and Biosecurity ? School of
> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From josie.galbraith at gmail.com  Tue Mar 10 04:47:05 2015
From: josie.galbraith at gmail.com (Josie Galbraith)
Date: Tue, 10 Mar 2015 16:47:05 +1300
Subject: [R-sig-ME] Error fitting reduced model in bglmer for LRT
Message-ID: <CAGb-hRqJ5J8OEvmtLDm0b=mOD=U_t1m8xd3ZMADomnkovELthA@mail.gmail.com>

Hi all,

In following on from this post
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023191.html>,
regarding using blme and fixed effect priors to address issues of complete
separation in my data, I've come up against a problem trying to fit reduced
models for testing the model terms using likelihood ratio tests (LRT).

Firstly, can I use LRTs (anova()) for testing the fixed effects of bglmer
models, as I would for glmer models?

If yes, then I need help understanding why I'm getting the following error
fitting a reduced bglmer model:
"Error in if (nrow(cov) == 2) { : argument is of length zero"

This is my full model:
SE.les.mod = bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family
= binomial, fixef.prior = t(1,2.5), cov.prior = NULL)

I can fit a model without the interaction term ok:
SE.les.add = bglmer (LESION ~ FOOD+SEASON +(1|SITE), data = SEYE.df, family
= binomial, fixef.prior = t(1,2.5), cov.prior = NULL)

But I get the error message with both of the single fixed effects models:
SE.les.FOOD = bglmer (LESION ~ SEASON +(1|SITE), data = SEYE.df, family =
binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
SE.les.SEAS = bglmer (LESION ~ FOOD +(1|SITE), data = SEYE.df, family =
binomial, fixef.prior = t(1,2.5), cov.prior = NULL)

Thanks very much,
Josie



-- 
*Josie Galbraith* MSc (hons)

PhD candidate
*University of Auckland *
Joint Graduate School in Biodiversity and Biosecurity ? School of
Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
*www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Mar 10 09:45:07 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 10 Mar 2015 09:45:07 +0100
Subject: [R-sig-ME] lmer with binomial distribution of random effects
In-Reply-To: <loom.20150309T021358-280@post.gmane.org>
References: <449B554E28A38046A4BE07F9871EFC724AB983901E@EX1.hof.uni-frankfurt.de>
	<loom.20150309T021358-280@post.gmane.org>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F067E89AE@UM-MAIL4112.unimaas.nl>

The lcmm package looks promising:

http://finzi.psych.upenn.edu/R/library/lcmm/html/lcmm-package.html

And it seems there may be relevant stuff in DPpackage:

http://finzi.psych.upenn.edu/R/library/DPpackage/html/00Index.html

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Ben Bolker
> Sent: Monday, March 09, 2015 02:16
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lmer with binomial distribution of random effects
> 
> El Kihal, Siham <Siham.ElKihal at ...> writes:
> 
> >
> > Dear lmer() friends,
> >
> > I am trying to estimate a model with a random
> > intercept, and 2 random slopes.
> > I believe that my betas (slopes) do not follow
> >a normal distribution, but rather a bimodal distribution.
> > The reason for this that there are two possible
> > mechanisms that influence the evolution of this variable,
> > one with a negative influence and another one with a
> >  positive influence. This is why I need to use a bimodal
> > distribution for my slopes to avoid the fact that
> > both effects right now cancel out.
> >
> > Does anyone of you has already done this or has
> > an idea how to concretely implement this using lmer()?
> 
>   This sounds like a latent mixture model problem.  lme4 doesn't
> do this; you *might* be able to implement an expectation-maximization
> wrapper around lme4 that would do it, but it wouldn't be entirely
> trivial.  If I had to do this I would probably turn to JAGS/BUGS.
> Looking forward to other answers from the list ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mervat_moh2006 at yahoo.com  Tue Mar 10 10:46:35 2015
From: mervat_moh2006 at yahoo.com (mervat mohamed)
Date: Tue, 10 Mar 2015 09:46:35 +0000 (UTC)
Subject: [R-sig-ME] Fw:  (no subject)
In-Reply-To: <54FE0B72.1030006@gmail.com>
References: <54FE0B72.1030006@gmail.com>
Message-ID: <962504463.2420668.1425980795564.JavaMail.yahoo@mail.yahoo.com>

many thanx
i appreciate?your help, but ?i concern about Glynn and Wakefield model, and i want to use the lmer function to perform this model and estimate the parameters of the attached model (18)




??

      On Monday, March 9, 2015 11:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
   

 -----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-09 06:53 AM, mervat mohamed via R-sig-mixed-models wrote:
> Dear lmer() friends,
> 
> I amtrying to estimate a model about regress deviance y on deviance
> x
> 
> Doesanyone of you has already done this before using lmer()
> method? i want the code of this model
> 
> Thanksa lot
> 
> mervat
> 
> 
> 

transcribing your equation into TeX format:

(y_{ij} - \bar y_{.j}) =
? \beta(x_{ij}-\bar x_{.j}) + e_{ij} - \bar e_{.j}

It's not really clear to me what you want to do.? It looks like
it *might* be a random_slope model.? In other words,

? y ~ x + (x|f)

where x is a continuous covariate and f is a grouping variable
(factor) gives

 y_{ij} = beta_0 + beta_1*x + (b_{0j} + b_{1j}*x)

Where b_{0j} is a group-level deviate from the intercept and b_{1j} is
a group-level deviation from the slope.

Is that translatable into your context?

Depending on how you want your results presented, van de Pol and
Wright 2009 might be useful:
http://www.myscience.eu/martijn/pdfs/vandePol%26Wright2009_AnimBeh.pdf

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU/gtxAAoJEOCV5YRblxUHWpkH+wXX9P8xmK8pQoBmix/Jtk4E
MmS5V2G0REuuiZHcOpjNVfWH4+Mda3VrULiZ5C2PJkLAizAZ0ME/HTtW8Ai2wAGx
tJDlo5A19/WMGGo3OHH8hU2UroCJWFfa3Ion4jVMP6911t5lL4Eewb+B+BcxcvQD
QIhs8hH+i9Pv9lOEWtzpgxp7Elhjs0q4wXRF++CopBG3mKHtutl7G1+zFS+jm64o
ZztJ7MZ/oeAvNHTExi0rxdB6MDrcX5eXHrRiDCP5OD7rD6MWxfEezne1QV/V1feX
R21iN64wBiSSZmTFCy3xP+Vl7CZ/hJvXsKvPf7c0HwfUwN0TflXN3GO8Jf2Ebcs=
=iics
-----END PGP SIGNATURE-----

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


   
-------------- next part --------------
A non-text attachment was scrubbed...
Name: blob.jpg
Type: image/png
Size: 73778 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150310/59e2fb1e/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: blob.jpg
Type: image/png
Size: 6210 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150310/59e2fb1e/attachment-0003.png>

From bellonedavide1 at gmail.com  Tue Mar 10 12:01:37 2015
From: bellonedavide1 at gmail.com (Davide Bellone)
Date: Tue, 10 Mar 2015 12:01:37 +0100
Subject: [R-sig-ME] Output glmer
Message-ID: <CABa6ee2F+dCroU_SdBfGPG+1nP7fBxxvYWr+5fwgPjyDT6RSdg@mail.gmail.com>

Good afternoon,

I have a little problem in my glmer output. In my model, before run the
model I used

options(contrasts=c("contr.sum", "contr.poly"))

So after stepwise deletion I arrive at the finel output:

Formula: y ~ Model$Manage + Model$age + Model$veg + Model$wood +
Model$under +
    Model$veg * Model$Manage + Model$age * Model$veg + Model$under *
 Model$wood + Model$veg * Model$under + (1 | Model$Site) +
    (1 | obs)

     AIC      BIC   logLik deviance df.resid
   568.0    604.1   -272.0    544.0      138

Scaled residuals:
     Min       1Q   Median       3Q      Max
-0.76077 -0.15913  0.00041  0.26754  0.70326

Random effects:
 Groups     Name        Variance Std.Dev.
 obs        (Intercept) 11.954   3.458
 Model$Site (Intercept)  7.405   2.721
Number of obs: 150, groups:  obs, 150; Model$Site, 10

Fixed effects:
                                              Estimate      d. Error z
value Pr(>|z|)
(Intercept)                                16.67112     7.73426   2.155
0.0311 *
Model$Manage1                         -5.72100    2.79907  -2.044   0.0410 *
Model$age                                -2.10245     0.84062  -2.501
0.0124 *
Model$veg                                -0.62276     0.29968  -2.078
0.0377 *
Model$wood1                             0.36500     0.41976   0.870
0.3846
Model$under1                             3.69383     2.73372   1.351
0.1766
Model$Manage1:Model$veg          0.20478     0.09007   2.274   0.0230 *
Model$age:Model$veg                  0.08319    0.03326   2.502   0.0124 *
Model$wood1:Model$under1          1.02751    0.44610   2.303   0.0213 *
Model$veg:Model$under1             -0.17567    0.08846  -1.986   0.0470 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Manage, wood and under are categorical with 2 levels each.

My question is: how can I find the real value of the estimates in the
summary output (since I used the contrast)? Also, how it works with the
interactions estimate?
The books that I am reading don?t help much since they don?t show
interactions between variables. Usually, they show only one variable with
more levels.  I Hope this is the right section to ask this question.

Thank you for who can help to understand this (maybe simple) problem.

Davide

	[[alternative HTML version deleted]]


From rubenarslan at gmail.com  Tue Mar 10 13:22:26 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Tue, 10 Mar 2015 12:22:26 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <loom.20150309T220710-595@post.gmane.org>
Message-ID: <CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>

Dear Dr Bolker,

I'd thought about something like this, one point of asking was to see whether
a) it's implemented already, because I'll probably make dumb mistakes while
trying b) it's not implemented because it's a bad idea.
Your response and the MCMCglmm course notes make me hope that it's c) not
implemented because nobody did yet or d) it's so simple that everybody does
it on-the-fly.

So I tried my hand and would appreciate corrections. I am sure there is
some screw-up or an inelegant approach in there.
I included code for dealing with mcmc.lists because that's what I have and
I'm not entirely sure how I deal with them is correct either.

I started with a zero-altered model, because those fit fastest and
according to the course notes have the least complex likelihood.
Because I know not what I do, I'm not dealing with my random effects at all.

I pasted a model summary below to show what I've applied the below function
to. The function gives the following quantiles when applied to 19 chains of
that model.
         5%         50%         95%
5.431684178 5.561211207 5.690655200
         5%         50%         95%
5.003974382 5.178192327 5.348246558

Warm regards,

Ruben Arslan

HPDpredict_za = function(object, predictor) {

if(class(object) != "MCMCglmm") {
if(length( object[[1]]$Residual$nrt )>1) {
object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
}
Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
vars = colnames(Sol[[1]])
} else {
Sol = as.data.frame(object$Sol)
vars = names(Sol)
}
za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
"traitza_"]
za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
"traitza_"]
 intercept = Sol[,"(Intercept)"]
za_intercept = Sol[, za_intercept_name]
l1 = Sol[, predictor ]
l2 = Sol[, za_predictor ]
if(is.list(object)) {
intercept = unlist(intercept)
za_intercept = unlist(za_intercept)
l1 = unlist(l1)
l2 = unlist(l2)
}
 py_0 = dpois(0, exp(intercept + za_intercept))
y_ygt0 = exp(intercept)
at_intercept = (1-py_0) * y_ygt0

py_0 = dpois(0, exp(intercept + za_intercept + l2))
y_ygt0 = exp(intercept +  l1)
at_predictor_1 = (1-py_0) * y_ygt0
print(qplot(at_intercept))
print(qplot(at_predictor_1))
df = data.frame("intercept" = at_intercept)
df[, predictor] = at_predictor_1
print(qplot(x=variable,
y=value,data=suppressMessages(melt(df)),fill=variable,alpha=I(0.40), geom =
'violin'))
print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
invisible(df)
}


> summary(object[[1]])

 Iterations = 100001:299901
 Thinning interval  = 100
 Sample size  = 2000

 DIC: 349094

 G-structure:  ~idh(trait):idParents

                      post.mean l-95% CI u-95% CI eff.samp
children.idParents       0.0189   0.0164   0.0214     1729
za_children.idParents    0.2392   0.2171   0.2622     1647

 R-structure:  ~idh(trait):units

                  post.mean l-95% CI u-95% CI eff.samp
children.units        0.144    0.139    0.148     1715
za_children.units     1.000    1.000    1.000        0

 Location effects: children ~ trait * (maternalage.factor + paternalloss +
maternalloss + center(nr.siblings) + birth.cohort + urban + male +
paternalage.mean + paternalage.diff)

                                           post.mean  l-95% CI  u-95% CI
eff.samp   pMCMC
(Intercept)                                 2.088717  2.073009  2.103357
  2000 <0.0005 ***
traitza_children                           -1.933491 -1.981945 -1.887863
  2000 <0.0005 ***
maternalage.factor(14,20]                   0.007709 -0.014238  0.027883
  1500   0.460
maternalage.factor(35,50]                   0.006350 -0.009634  0.024107
  2000   0.462
paternallossTRUE                            0.000797 -0.022716  0.025015
  2000   0.925
maternallossTRUE                           -0.015542 -0.040240  0.009549
  2000   0.226
center(nr.siblings)                         0.005869  0.004302  0.007510
  2000 <0.0005 ***
birth.cohort(1703,1722]                    -0.045487 -0.062240 -0.028965
  2000 <0.0005 ***
birth.cohort(1722,1734]                    -0.055872 -0.072856 -0.036452
  2000 <0.0005 ***
birth.cohort(1734,1743]                    -0.039770 -0.056580 -0.020907
  2000 <0.0005 ***
birth.cohort(1743,1750]                    -0.030713 -0.048301 -0.012214
  2000   0.002 **
urban                                      -0.076748 -0.093240 -0.063002
  2567 <0.0005 ***
male                                        0.106074  0.095705  0.115742
  2000 <0.0005 ***
paternalage.mean                           -0.024119 -0.033133 -0.014444
  2000 <0.0005 ***
paternalage.diff                           -0.018367 -0.032083 -0.005721
  2000   0.007 **
traitza_children:maternalage.factor(14,20] -0.116510 -0.182432 -0.051978
  1876   0.001 ***
traitza_children:maternalage.factor(35,50] -0.045196 -0.094485  0.002640
  2000   0.075 .
traitza_children:paternallossTRUE          -0.171957 -0.238218 -0.104820
  2000 <0.0005 ***
traitza_children:maternallossTRUE          -0.499539 -0.566825 -0.430637
  2000 <0.0005 ***
traitza_children:center(nr.siblings)       -0.023723 -0.028676 -0.018746
  1848 <0.0005 ***
traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250  0.026024
  2000   0.319
traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462 -0.227187
  2000 <0.0005 ***
traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659 -0.204462
  2130 <0.0005 ***
traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568 -0.426648
  2000 <0.0005 ***
traitza_children:urban                     -0.604108 -0.645169 -0.562554
  1702 <0.0005 ***
traitza_children:male                      -0.414988 -0.444589 -0.387005
  2000 <0.0005 ***
traitza_children:paternalage.mean           0.006545 -0.018570  0.036227
  2000   0.651
traitza_children:paternalage.diff          -0.097982 -0.136302 -0.060677
  2000 <0.0005 ***


On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com> wrote:

> Ruben Arslan <rubenarslan at ...> writes:
>
> >
> > Dear list,
> >
> > I wanted to ask: Is there any (maybe just back of the envelope) way to
> > obtain a response prediction for zero-inflated or hurdle type models?
> > I've fit such models in MCMCglmm, but I don't work in ecology and my
> > previous experience with explaining such models to "my audience" did not
> > bode well. When it comes to humans, the researchers I presented to are
> not
> > used to offspring count being zero-inflated (or acquainted with that
> > concept), but in my historical data with high infant mortality, it is (in
> > modern data it's actually slightly underdispersed).
> >
> > Currently I'm using lme4 and simply splitting my models into two stages
> > (finding a mate and having offspring).
> > That's okay too, but in one population the effect of interest is not
> > clearly visible in either stage, only when both are taken together (but
> > then the outcome is zero-inflated).
> > I expect to be given a hard time for this and hence thought I'd use a
> > binomial model with the outcome offspring>0 as my main model, but that
> > turns out to be hard to explain too and doesn't
> > really do the data justice.
> >
> > Basically I don't want to be forced to discuss my smallest population as
> a
> > non-replication of the effect because I was insufficiently able to
> explain
> > the statistics behind my reasoning that the effect shows.
>
>   I think the back-of-the envelope answer would be that for a two-stage
> model with a prediction of p_i for the probability of having a non-zero
> response (or in the case of zero-inflated models, the probability of
> _not_ having a structural zero) and a prediction of n_i for the conditional
> part of the model, the mean predicted value is p_i*n_i and the
> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 + var(n_i)/n_i^2)
> (this is assuming
> that you haven't built in any correlation between p_i and n_i, which
> would be hard in lme4 but _might_ be possible under certain circumstances
> via a multitype model in MCMCglmm).
>
>   Does that help?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Mar 10 14:45:13 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Mar 2015 09:45:13 -0400
Subject: [R-sig-ME] Output glmer
In-Reply-To: <CABa6ee2F+dCroU_SdBfGPG+1nP7fBxxvYWr+5fwgPjyDT6RSdg@mail.gmail.com>
References: <CABa6ee2F+dCroU_SdBfGPG+1nP7fBxxvYWr+5fwgPjyDT6RSdg@mail.gmail.com>
Message-ID: <54FEF569.6000208@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-10 07:01 AM, Davide Bellone wrote:
> Good afternoon,
> 
> I have a little problem in my glmer output. In my model, before run
> the model I used
> 
> options(contrasts=c("contr.sum", "contr.poly"))
> 
> So after stepwise deletion I arrive at the finel output:

  First of all, I would caution against stepwise deletion (see e.g.
Frank Harrell's book _Regression Modeling Strategies_, or Google
"stepwise regression problems"


> Formula: y ~ Model$Manage + Model$age + Model$veg + Model$wood + 
> Model$under + Model$veg * Model$Manage + Model$age * Model$veg +
> Model$under * Model$wood + Model$veg * Model$under + (1 |
> Model$Site) + (1 | obs)

  Second, I would suggest that you leave the "Model$" out of your
formula, and that you recognize that * incorporates both main effects
and interactions: your model can be written more simply as

  y ~ Manage + age + veg + wood + under + veg:Manage + veg:age +
      under:wood + under:veg + (1|Site) + (1|obs)

or even

  y ~ veg*(Manage+age + under) + under*wood + (1|Site) + (1|obs)

(there is one redundant term here -- the main effect of under is
incorporated in both terms -- but R will take care of dropping it
automatically)

or better, retain all two-way interactions:

  y ~ (veg+Manage+age+under+wood)^2 + (1|Site) + (1|obs)

> 
> AIC      BIC   logLik deviance df.resid 568.0    604.1   -272.0
> 544.0      138
> 
> Scaled residuals: Min       1Q   Median       3Q      Max -0.76077
> -0.15913  0.00041  0.26754  0.70326
> 
> Random effects: Groups     Name        Variance Std.Dev. obs
> (Intercept) 11.954   3.458 Model$Site (Intercept)  7.405   2.721 
> Number of obs: 150, groups:  obs, 150; Model$Site, 10
> 
> Fixed effects: Estimate      d. Error z value Pr(>|z|) (Intercept)
> 16.67112     7.73426   2.155 0.0311 * Model$Manage1
> -5.72100    2.79907  -2.044   0.0410 * Model$age
> -2.10245     0.84062  -2.501 0.0124 * Model$veg
> -0.62276     0.29968  -2.078 0.0377 * Model$wood1
> 0.36500     0.41976   0.870 0.3846 Model$under1
> 3.69383     2.73372   1.351 0.1766 Model$Manage1:Model$veg
> 0.20478     0.09007   2.274   0.0230 * Model$age:Model$veg
> 0.08319    0.03326   2.502   0.0124 * Model$wood1:Model$under1
> 1.02751    0.44610   2.303   0.0213 * Model$veg:Model$under1
> -0.17567    0.08846  -1.986   0.0470 * --- Signif. codes:  0 ?***?
> 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Manage, wood and under are categorical with 2 levels each.
> 
> My question is: how can I find the real value of the estimates in
> the summary output (since I used the contrast)? Also, how it works
> with the interactions estimate?

   What do you mean by the "real value of the estimates"?  I think you
might want to take a look at the lsmeans or effects packages, or you
could use predict() to compute the expected outcome for some
particular combination of factors ...

  The question about contrasts/interpretation of parameters in linear
or generalized linear models is not really specific to mixed models.
Maybe take a look at Crawley's book, or Faraway's ...


> The books that I am reading don?t help much since they don?t show 
> interactions between variables. Usually, they show only one
> variable with more levels.  I Hope this is the right section to ask
> this question.
> 
> Thank you for who can help to understand this (maybe simple)
> problem.
> 
> Davide
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU/vVpAAoJEOCV5YRblxUHGMQH/3HMpXDO7Zouj4hBEPX9O9lm
1x6czZa+SQSCphKT01WevbT0wjLgFwaBhwfE/cFKbqr6YLsD5TsC3iG6FK5qzmob
Mmm1nWl1L04ZI7lPVkfH07UTDUNyQlToagPFuZYs/g+HlOx7vlQ44VgWIgTnGA3X
bmEtorIDF2n6PZvnMothJZrrri+0dOQBrFFDpdACpCR0zsGFQ4oJP5VJsW3mE40M
pqolU3CRMxO5Q9GzPO2I+P+IMb0rIj6Ke1ADdnkx1rt0QZcnndhFyA4wHk/rJwoQ
2NBXSgy+dBsX479CgCoS4aIJBTevUoHZ/S9SAAapoq8XAruEVwxPpYGxYqC1fMk=
=lwqn
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Tue Mar 10 15:08:49 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Mar 2015 10:08:49 -0400
Subject: [R-sig-ME] Fw:  (no subject)
In-Reply-To: <962504463.2420668.1425980795564.JavaMail.yahoo@mail.yahoo.com>
References: <54FE0B72.1030006@gmail.com>
	<962504463.2420668.1425980795564.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54FEFAF1.4090801@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-10 05:46 AM, mervat mohamed via R-sig-mixed-models wrote:
> many thanx i appreciate your help, but  i concern about Glynn and 
> Wakefield model, and i want to use the lmer function to perform
> this model and estimate the parameters of the attached model (18)
> 
> 
> 

  I'm sorry, but this is a little bit too much for me to handle right
now.  I don't have any background on a "Glynn and Wakefield" model is:
I found this

http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2801082/
(Glynn, Wakefield, Handcock, and Richardson 2008)
which seems very close but not identical to the JPGs you included
(note that the mailing list strips most attachments).  Maybe they
published a book chapter closely related to their paper?

  Good luck.


> 
> 
> 
> On Monday, March 9, 2015 11:12 PM, Ben Bolker <bbolker at gmail.com> 
> wrote:
> 
> 
> -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA1
> 
> On 15-03-09 06:53 AM, mervat mohamed via R-sig-mixed-models wrote:
>> Dear lmer() friends,
>> 
>> I amtrying to estimate a model about regress deviance y on 
>> deviance x
>> 
>> Doesanyone of you has already done this before using lmer()
>> method? i want the code of this model
>> 
>> Thanksa lot
>> 
>> mervat
>> 
>> 
>> 
> 
> transcribing your equation into TeX format:
> 
> (y_{ij} - \bar y_{.j}) = \beta(x_{ij}-\bar x_{.j}) + e_{ij} - \bar 
> e_{.j}
> 
> It's not really clear to me what you want to do.  It looks like it 
> *might* be a random_slope model.  In other words,
> 
> y ~ x + (x|f)
> 
> where x is a continuous covariate and f is a grouping variable 
> (factor) gives
> 
> y_{ij} = beta_0 + beta_1*x + (b_{0j} + b_{1j}*x)
> 
> Where b_{0j} is a group-level deviate from the intercept and
> b_{1j} is a group-level deviation from the slope.
> 
> Is that translatable into your context?
> 
> Depending on how you want your results presented, van de Pol and 
> Wright 2009 might be useful: 
> http://www.myscience.eu/martijn/pdfs/vandePol%26Wright2009_AnimBeh.pdf
>
>
> 
- -----BEGIN PGP SIGNATURE----- Version: GnuPG v1.4.11 (GNU/Linux)
> 
> iQEcBAEBAgAGBQJU/gtxAAoJEOCV5YRblxUHWpkH+wXX9P8xmK8pQoBmix/Jtk4E 
> MmS5V2G0REuuiZHcOpjNVfWH4+Mda3VrULiZ5C2PJkLAizAZ0ME/HTtW8Ai2wAGx 
> tJDlo5A19/WMGGo3OHH8hU2UroCJWFfa3Ion4jVMP6911t5lL4Eewb+B+BcxcvQD 
> QIhs8hH+i9Pv9lOEWtzpgxp7Elhjs0q4wXRF++CopBG3mKHtutl7G1+zFS+jm64o 
> ZztJ7MZ/oeAvNHTExi0rxdB6MDrcX5eXHrRiDCP5OD7rD6MWxfEezne1QV/V1feX 
> R21iN64wBiSSZmTFCy3xP+Vl7CZ/hJvXsKvPf7c0HwfUwN0TflXN3GO8Jf2Ebcs= 
> =iics -----END PGP SIGNATURE-----
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU/vrwAAoJEOCV5YRblxUH0cQH/0M1mgNZsU1nNE/Rq2mL3XHt
8plfYgnlfhA37PoB8L2dEmSU4JREM9evNIqVAHe2sv3KnJ/5C5oaK+FL8dcnp6ZR
vb5bL1AUoLyxqxQ9CuAOKDIUH8sQS/ev2qFJgKtn86SamQXYo6CxY+cpZ/lcFh/H
BfKfWA6ynVEuzIdTsCjNf3M4judxQ1MzVTY1qctVkUfxOfChUlOlcWiM6Nxj6wY0
Kvzww85ZV+40rFIvwlPQohO8rBBtWpyad9COohZtFUEUB1bqN2VH4jPfcFQylxA7
hc9scjEMyxI5Ngvd/23bUXvBTjsr9sFxvNcQWky7W1UvNsWG5On1/D7kOK6aGTo=
=nt8m
-----END PGP SIGNATURE-----


From asafw.at.wharton at gmail.com  Tue Mar 10 02:52:34 2015
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Mon, 9 Mar 2015 21:52:34 -0400
Subject: [R-sig-ME] lmer fails when too many observations
Message-ID: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>

Dear lmer community,

I am trying to run a simulation for a two-way random-effects model with
unbalanced design (ie, unequal number of observations per cell) and no
interaction.
It's especially important for me to be able to run the lmer/blmer functions
when the number of (column and row) random effects is large, say 100, and
with possible replicates in each cell.
The problem is that lmer() works with the full vector of observations, as
opposed to working with the cell averages (which is a sufficient
statistic), and the methods fails pretty quickly when there are replicates
(because the response vector is too big, I suppose). I get the following
error:

*Error in get("checkConv", lme4Env)(attr(opt, "derivs"), opt$par, ctrl =
control$checkConv,  : *
*  (converted from warning) Model failed to converge with max|grad| =
0.00244385 (tol = 0.002)*

Just to give an example: suppose there are R=100 row effects, C=100 column
effects, and 5 replicates in each cell. The vector of individual
observations is of length 100^5 (lmer fails), while the vector of cell
averages is of length 100^2 (a size which causes no problem for lmer).
My question is whether there is a way to tell lmer() to work with the
sufficient statistic (of course, the conditional covariance is no longer
c*Identity, a fact which is used in the implementation of lmer (according
to documentation) ).

Thank you very much and I hope I was clear!

Asaf

	[[alternative HTML version deleted]]


From zsa11 at mail.aub.edu  Tue Mar 10 02:39:20 2015
From: zsa11 at mail.aub.edu (Zahwa Al Ayyash (Student))
Date: Tue, 10 Mar 2015 01:39:20 +0000
Subject: [R-sig-ME] Dispersion parameter in glmmadmb and model selection
Message-ID: <1425951555129.86251@mail.aub.edu>

Dear list,

1) I am fitting a negative binomial and zero-inflated negative binomial models using glmmadmb. I am getting a very high dispersion parameter:

Negative binomial dispersion parameter: 403.43 (std. err.: 0.39244)

I am aware that my data might be over-dispersed, but what does the very high value indicate? Could there be an error in estimation?
Also, surprisingly, I am using two different data sets to estimate the neg. bin. models, and I am getting the same value (403.43) but with different std. errors. Any clues?

2) My second question is rather general; What could be the best ways to compare glmmadmb models and select the best amongst Poisson, Neg. Bin, Zero-inflated Poisson, Zero-inflated Neg. Bin., Hurdle Poisson and Hurdle Neg. Bin?

PS: My models employ a random effect to capture correlation among individuals (IDs).

Many thanks to your help,
Zahwa Al-Ayyash






	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar 10 15:43:55 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 10 Mar 2015 15:43:55 +0100
Subject: [R-sig-ME] lmer fails when too many observations
In-Reply-To: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>
References: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>
Message-ID: <CAJuCY5zZuBMjJdqxeeY6=v6tnBf_U3pRfdyd=y71pOc70VQSXg@mail.gmail.com>

Dear Asaf,

Can you provide a reproducible example of the error? That should be easy
since you are simulating data.

It is not clear to me what kind of model you are fitting.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-10 2:52 GMT+01:00 Asaf Weinstein <asafw.at.wharton at gmail.com>:

> Dear lmer community,
>
> I am trying to run a simulation for a two-way random-effects model with
> unbalanced design (ie, unequal number of observations per cell) and no
> interaction.
> It's especially important for me to be able to run the lmer/blmer functions
> when the number of (column and row) random effects is large, say 100, and
> with possible replicates in each cell.
> The problem is that lmer() works with the full vector of observations, as
> opposed to working with the cell averages (which is a sufficient
> statistic), and the methods fails pretty quickly when there are replicates
> (because the response vector is too big, I suppose). I get the following
> error:
>
> *Error in get("checkConv", lme4Env)(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  : *
> *  (converted from warning) Model failed to converge with max|grad| =
> 0.00244385 (tol = 0.002)*
>
> Just to give an example: suppose there are R=100 row effects, C=100 column
> effects, and 5 replicates in each cell. The vector of individual
> observations is of length 100^5 (lmer fails), while the vector of cell
> averages is of length 100^2 (a size which causes no problem for lmer).
> My question is whether there is a way to tell lmer() to work with the
> sufficient statistic (of course, the conditional covariance is no longer
> c*Identity, a fact which is used in the implementation of lmer (according
> to documentation) ).
>
> Thank you very much and I hope I was clear!
>
> Asaf
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From vjd4 at nyu.edu  Tue Mar 10 16:14:51 2015
From: vjd4 at nyu.edu (Vincent Dorie)
Date: Tue, 10 Mar 2015 11:14:51 -0400
Subject: [R-sig-ME] Choosing appropriate priors for bglmer mixed models
	in blme
In-Reply-To: <20150310071536.82277l56psd3iz48@www.staffmail.ed.ac.uk>
References: <CAGb-hRoXsEKsX2x0H9WnF0Q8r=kkXxFP4TjMEgmDBB+2pSwNZQ@mail.gmail.com>
	<20150309075019.84131m3s1sr4uzs0@www.staffmail.ed.ac.uk>
	<CAGb-hRpECdi23WD74wsFF1byiCJqZj5to5qD7N8TCC1QYa_GNA@mail.gmail.com>
	<20150310071536.82277l56psd3iz48@www.staffmail.ed.ac.uk>
Message-ID: <97FCEB0D-DB45-4728-913E-21C19F144B8C@nyu.edu>

Cauchy is just t with 1 degree of freedom.

Vince

> On Mar 10, 2015, at 3:15 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> 
> Hi Josie,
> 
> Yes - I would scale your input variables and go for the t-prior in blme (I think the Cauchy prior is not implemented?). You might want to up the scale a little from that recommended in order to deal with the fact you may have non-zero random effects, but it might not make a big difference if their variance isn't too large.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Tue, 10 Mar 2015 10:30:12 +1300:
> 
>> Hi Jarrod,
>> 
>> I'm pretty sure it is a complete separation issue.  This is the xtab of
>> counts for the main factors:
>> 
>>                                LESION  0    1
>> SEASON     FOOD
>> Autumn            NF                 38   2
>>                          F                  21   0
>> Spring              NF                 27   3
>>                         F                   76  11
>> 
>> Lesion incidences were low generally, but particularly so in Autumn (and
>> fewer replicates in Autumn).
>> 
>> Thanks again,
>> Josie
>> 
>> 
>> 
>> 
>> 
>> On Mon, Mar 9, 2015 at 8:50 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> 
>>> Hi Josie,
>>> 
>>> Is the problem you are having because of complete separation, either
>>> because you have some very good predictors of lesions and/or you have low
>>> replication for some factor levels? If so blmer with Gelman's recommended
>>> prior (not the diffuse prior) should do a reasonable job of allowing
>>> sensible inferences to be made. However, as Ben said in an earlier post,its
>>> not clear that this is the problem.
>>> 
>>> Similar issues are possible with the random effects, but this tends to be
>>> rare because they are constrained. I only see it when the variance
>>> component is very large, not zero as here.
>>> 
>>> If the perceived problem is zero variance estimates, I'm not sure why this
>>> is a problem. If the true variances are zero you should expect a MLE of
>>> zero 50% of the time. With only 8 levels of the random effect, you should
>>> expect an MLE of zero often, even if the true variance is moderate. The
>>> same power issues will generate MLE correlations of -1 and 1.
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Mon, 9 Mar 2015
>>> 13:08:59 +1300:
>>> 
>>> Thanks very much Jarrod & Vince for your inputs.
>>>> Admittedly this analysis is stretching my level of understanding!
>>>> 
>>>> From a practical point of view, given that time is of the essence in
>>>> writing up my PhD, if I only want to test the main effects of my model
>>>> (rather than make predictions etc), is this something I can achieve in
>>>> blme? (ie testing model terms using LRTs).  If so should I be using blme
>>>> for this?
>>>> 
>>>> Or should I really be working in MCMCglmm (which I haven't used before -
>>>> another learning curve!)?  Any further thoughts on using normal priors
>>>> rather than Cauchy?
>>>> 
>>>> Thanks again,
>>>> Josie
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Message: 2
>>>>> 
>>>>> Hi Vince,
>>>>> 
>>>>> For a given difference on the logit scale between (lets say) two
>>>>> treatment groups then the difference on the observed scale depends on
>>>>> the magnitude of the variance components. For logit effects beta1 and
>>>>> beta2, the expected difference is approximately:
>>>>> 
>>>>> plogis(beta1/sqrt(1+c2*v))-plogis(beta2/sqrt(1+c2*v))
>>>>> 
>>>>> where v is the variance component and c2 = (16*sqrt(3)/(15*pi))^2.
>>>>> 
>>>>> If a prior (Cauchy or otherwise) was set up that was invariant to v
>>>>> then it would imply different prior beliefs about the magnitude of the
>>>>> difference (on the observed scale) depending on v. For the normal
>>>>> prior it would imply that when v is large we should expect smaller
>>>>> differences between treatment groups. This maybe OK (I'm not sure) but
>>>>> if not is there a way to make it invariant for the t/Cauchy prior? For
>>>>> the normal you can make the scale = sqrt(v+pi^2/3) which seems to work
>>>>> OKish.
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>> Jarrod
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> Quoting Vincent Dorie <vjd4 at nyu.edu> on Sat, 7 Mar 2015 09:47:40 -0500:
>>>>> 
>>>>> > Just to follow up on Gelman's Cauchy prior, it seems to work quite
>>>>> > well even in glmms. I don't have any theoretical results as of yet,
>>>>> > but if you look at the sampling distribution of the fixed effects
>>>>> > for any model, they cluster rather nicely. You get "sane" estimates
>>>>> > for when no kind of separation is involved, infinite (or convergence
>>>>> > failures) for complete/quasi complete separation, and a third group
>>>>> > exists with large estimates for when a group contains all 0s or 1s.
>>>>> > In the third case, a random effect can perfectly predict for that
>>>>> > group, but because they're integrated out the likelihood remains
>>>>> > well defined. You'll just get really large estimates of random
>>>>> > effects, which then go with large estimates of fixed effects.
>>>>> >
>>>>> > So long as you believe that some effect magnitudes for logistic
>>>>> > regression pretty much never happen in nature, the Cauchy prior does
>>>>> > a good job of pulling the extreme cases back down to earth while
>>>>> > leaving the well-estimated ones roughly in place. That being said,
>>>>> > using the priors in blme to patch up a data set is really only
>>>>> > advised for checking the viability of a model (usually one among
>>>>> > many, rapidly fit). After that, using something like MCMCglmm for a
>>>>> > fully Bayesian analysis is the way to go.
>>>>> >
>>>>> > Vince
>>>>> >
>>>>> >> On Mar 7, 2015, at 3:09 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>> wrote:
>>>>> >>
>>>>> >> Hi Josie,
>>>>> >>
>>>>> >> Regarding the priors on the fixed effects, if complete separation
>>>>> >> is the issue having a diffuse prior is not going to help. Gelman
>>>>> >> (2008) gives some recommendations about priors for logistic
>>>>> >> regression. Although a Cauchy-prior was considered better than a
>>>>> >> t-prior, the latter can be used in blmer and should alleviate
>>>>> >> complete separation issues. I tend to use a normal-prior after
>>>>> >> performing Gelman's rescaling, but this is mainly because MCMCglmm
>>>>> >> only handles normal priors for the fixed effects (this may not be
>>>>> >> true). In a hierarchical model I'm not sure Gelman's advice holds:
>>>>> >> at least with a normal-prior it makes sense to increase the prior
>>>>> >> variance as the random-effect variances increase. If the prior
>>>>> >> variance is approximately v+pi^2/3, where v is the sum of the
>>>>> >> variance components, then the effects on the probability scale are
>>>>> >> quite close to being uniform on the 0,1 interval.
>>>>> >>
>>>>> >> You can use the gelman.prior function to obtain the prior
>>>>> >> covariance matrix for your model. However, note that in the help
>>>>> >> file I say that the scale argument takes the standard deviation. In
>>>>> >> fact it takes the variance, but in the next version of MCMCglmm
>>>>> >> (coming soon) I have fixed this and it will take the standard
>>>>> >> deviation.
>>>>> >>
>>>>> >> Cheers,
>>>>> >>
>>>>> >> Jarrod
>>>>> >>
>>>>> >>
>>>>> >> Gelman, A. et al. (2008) The Annals of Appled Statistics 2 4 1360-1383
>>>>> >>
>>>>> >>
>>>>> >> Quoting Josie Galbraith <josie.galbraith at gmail.com> on Sat, 7 Mar
>>>>> >> 2015 12:15:41 +1300:
>>>>> >>
>>>>> >>> Thanks Ben,
>>>>> >>> I didn't have problems with singular estimates of variance components
>>>>> with
>>>>> >>> this data set.  However, I have a few other pathogens/parasites that
>>>>> I'm
>>>>> >>> looking at (I'm running separate models for each), and after looking
>>>>> at all
>>>>> >>> of them some do have zero variances for the random effect, either in
>>>>> >>> addition to large parameter estimates or alongside reasonable
>>>>> parameter
>>>>> >>> estimates.
>>>>> >>> Should I be also be imposing a covariance prior in either of these
>>>>> cases?
>>>>> >>>
>>>>> >>> As a related aside, my data are collected from individual birds -
>>>>> captured
>>>>> >>> over 4 sampling rounds (6 months apart).  While the majority of
>>>>> >>> observations are independent, there is a small proportion of birds
>>>>> that
>>>>> >>> were recaptured in a subsequent sampling round (between 2?15% of
>>>>> >>> observations, depending on which response variable).  I have modelled
>>>>> my
>>>>> >>> data both both with and without bird ID as a random effect.
>>>>> Including
>>>>> it
>>>>> >>> seems to cause more problems with zero variances.  Is this because
>>>>> too
>>>>> few
>>>>> >>> of the birds have actually been resampled?
>>>>> >>>
>>>>> >>> Cheers,
>>>>> >>> Josie
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>> Josie Galbraith <josie.galbraith at ...> writes:
>>>>> >>>>
>>>>> >>>> >
>>>>> >>>>
>>>>> >>>> [snip]
>>>>> >>>>
>>>>> >>>> >
>>>>> >>>> > I'm after some advice on how to choose which priors to use.  I
>>>>> gather I
>>>>> >>>> > need to impose a weak prior on the fixed effects of my model but
>>>>> no
>>>>> >>>> > covariance priors - is this correct?  Can I use a default prior
>>>>> (i.e. t,
>>>>> >>>> or
>>>>> >>>> > normal defaults in the blme package) or does it depend on my data?
>>>>> What
>>>>> >>>> is
>>>>> >>>> > considered a suitably weak prior?
>>>>> >>>>
>>>>> >>>>   If all you're trying to do is deal with complete separation (and
>>>>> not,
>>>>> >>>> e.g. singular estimates of variance components [typically indicated
>>>>> >>>> by zero variances or +/- 1 correlations, although I'm not sure those
>>>>> >>>> are necessary conditions for singularity]), then it should be OK
>>>>> >>>> to put the prior only on the fixed effects.  Generally speaking a
>>>>> >>>> weak prior is one with a standard deviation that is large relative
>>>>> >>>> to the expected scale of the effect (e.g. we might say sigma=10 is
>>>>> >>>> large, but it won't be if the units of measurement are very small
>>>>> >>>> so that a typical value of the mean is 100,000 ...)
>>>>> >>>>
>>>>> >>>> > I am running binomial models for epidemiology data (response
>>>>> variable is
>>>>> >>>> > presence/absence of lesions), with 2 fixed effects (FOOD: F/NF;
>>>>> SEASON:
>>>>> >>>> > Autumn/Spring) and a random effect (SITE: 8 levels).  The main
>>>>> goal
>>>>> of
>>>>> >>>> > these models is to test for an effect of the treatment 'FOOD.'
>>>>> I'm
>>>>> >>>> > guessing from what I've read, that my model should be something
>>>>> like the
>>>>> >>>> > following:
>>>>> >>>>
>>>>> >>>>
>>>>> >>>> This seems fairly reasonable at first glance.  Where were you seeing
>>>>> >>>> the complete separation, though?   I would normally expect to
>>>>> >>>> see at least one of the parameters still being reasonably large
>>>>> >>>> if that's the case.
>>>>> >>>>
>>>>> >>>> > bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family =
>>>>> >>>> binomial,
>>>>> >>>> > fixef.prior = normal, cov.prior = NULL)
>>>>> >>>> >
>>>>> >>>> > This is the output when I run the model:
>>>>> >>>> >
>>>>> >>>> > Fixef prior: normal(sd = c(10, 2.5, ...), corr = c(0 ...),
>>>>> >>>> common.scale =
>>>>> >>>> > FALSE)
>>>>> >>>> > Prior dev  : 18.2419
>>>>> >>>> >
>>>>> >>>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>>>>> >>>> > Approximation) [
>>>>> >>>> > bglmerMod]
>>>>> >>>> >  Family: binomial ( logit )
>>>>> >>>> > Formula: LESION ~ FOOD * SEASON + (1 | SITE)
>>>>> >>>> >    Data: SEYE.df
>>>>> >>>> >
>>>>> >>>>
>>>>> >>>> [snip]
>>>>> >>>>
>>>>> >>>> > Random effects:
>>>>> >>>> >  Groups Name        Variance Std.Dev.
>>>>> >>>> >  SITE   (Intercept) 0.3064   0.5535
>>>>> >>>> > Number of obs: 178, groups: SITE, 8
>>>>> >>>> >
>>>>> >>>> > Fixed effects:
>>>>> >>>> >                     Estimate Std. Error z value Pr(>|z|)
>>>>> >>>> > (Intercept)          -3.7664     1.4551  -2.588  0.00964 **
>>>>> >>>> > FOODNF                0.5462     1.6838   0.324  0.74567
>>>>> >>>> > SEASONSpring          1.7529     1.4721   1.191  0.23378
>>>>> >>>> > FOODNF:SEASONSpring  -0.8151     1.7855  -0.456  0.64803
>>>>> >>>> > ---
>>>>> >>>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>> >>>> >
>>>>> >>>>
>>>>> >>>> [snip]
>>>>> >>>>
>>>>> >>>> ------------------------------
>>>>> >>>>
>>>>> >>>
>>>>> >>>
>>>>> >>> --
>>>>> >>> *Josie Galbraith* MSc (hons)
>>>>> >>>
>>>>> >>> PhD candidate
>>>>> >>> *University of Auckland *
>>>>> >>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>>>>> >>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland
>>>>> 1142* ?
>>>>> >>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: *
>>>>> UoA Web
>>>>> >>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>>>>> >>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>>>>> >>>
>>>>> >>>     [[alternative HTML version deleted]]
>>>>> >>>
>>>>> >>> _______________________________________________
>>>>> >>> R-sig-mixed-models at r-project.org mailing list
>>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>
>>>>> >>
>>>>> >>
>>>>> >> --
>>>>> >> The University of Edinburgh is a charitable body, registered in
>>>>> >> Scotland, with registration number SC005336.
>>>>> >>
>>>>> >> _______________________________________________
>>>>> >> R-sig-mixed-models at r-project.org mailing list
>>>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >
>>>>> > _______________________________________________
>>>>> > R-sig-mixed-models at r-project.org mailing list
>>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >
>>>>> >
>>>>> 
>>>>> 
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>> 
>>>>> 
>>>>> 
>>>>> ------------------------------
>>>>> 
>>>>> Subject: Digest Footer
>>>>> 
>>>>> _______________________________________________
>>>>> R-sig-mixed-models mailing list
>>>>> R-sig-mixed-models at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> 
>>>>> 
>>>>> ------------------------------
>>>>> 
>>>>> End of R-sig-mixed-models Digest, Vol 99, Issue 11
>>>>> **************************************************
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> --
>>>> *Josie Galbraith* MSc (hons)
>>>> 
>>>> PhD candidate
>>>> *University of Auckland *
>>>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>>>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
>>>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA
>>>> Web
>>>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>>>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>>>> 
>>>> 
>>> 
>>> 
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> 
>>> 
>> 
>> 
>> --
>> *Josie Galbraith* MSc (hons)
>> 
>> PhD candidate
>> *University of Auckland *
>> Joint Graduate School in Biodiversity and Biosecurity ? School of
>> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
>> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
>> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
>> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


From paul.johnson at glasgow.ac.uk  Tue Mar 10 16:25:45 2015
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 10 Mar 2015 15:25:45 +0000
Subject: [R-sig-ME] Dispersion parameter in glmmadmb and model selection
In-Reply-To: <1425951555129.86251@mail.aub.edu>
References: <1425951555129.86251@mail.aub.edu>
Message-ID: <C98F7032-C8E8-4391-B247-C10CAB449896@glasgow.ac.uk>

Hi Zahwa, 

In answer to the first question, the dispersion parameter, alpha, is inversely proportional to the amount of additional variance due to overdispersion...

Y ~ Poisson(lambda)
Var(Y) = lambda

Y ~ NB(lambda, alpha)
Var(Y) = lambda + lambda^2 / alpha

...so your error distribution appears not to be very overdispersed. In fact, if probably isn?t overdispersed at all, as I think glmmadmb puts an upper limit on the alpha estimate of exp(6) = 403.43, presumably to prevent it wondering off towards infinity when there is no evidence of overdispersion. This would explain why you get the same estimate from different (non-overdispersed) data sets. Try simulating some Poisson data and fitting an NB model (see code below). 

I guess for low lambda, e.g. around 10, lambda^2 / 403 will be reasonable approximation of zero addition variance, but not for higher lambda, e.g. > 100. Not sure how glmmadmb copes with that, or if it?s possible to raise this ceiling.

Best wishes,
Paul

> set.seed(1234);
> y <- rpois(100, 5)
> dummy.group <- factor(rep(1:10, each = 10))
> fit <- glmmadmb(y ~ (1 | dummy.group), family = "nbinom2")
> summary(fit)

Call:
glmmadmb(formula = y ~ (1 | dummy.group), family = "nbinom2")

AIC: 422.6 

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    1.520      0.047    32.3   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=100, dummy.group=10 
Random effect variance(s):
Group=dummy.group
             Variance    StdDev
(Intercept) 2.696e-08 0.0001642

Negative binomial dispersion parameter: 403.43 (std. err.: 0.72454)

Log-likelihood: -208.295 
> fit$alpha
[1] 403.43
> log(fit$alpha)
[1] 6.000003




On 10 Mar 2015, at 01:39, Zahwa Al Ayyash (Student) <zsa11 at mail.aub.edu> wrote:

> Dear list,
> 
> 1) I am fitting a negative binomial and zero-inflated negative binomial models using glmmadmb. I am getting a very high dispersion parameter:
> 
> Negative binomial dispersion parameter: 403.43 (std. err.: 0.39244)
> 
> I am aware that my data might be over-dispersed, but what does the very high value indicate? Could there be an error in estimation?
> Also, surprisingly, I am using two different data sets to estimate the neg. bin. models, and I am getting the same value (403.43) but with different std. errors. Any clues?
> 
> 2) My second question is rather general; What could be the best ways to compare glmmadmb models and select the best amongst Poisson, Neg. Bin, Zero-inflated Poisson, Zero-inflated Neg. Bin., Hurdle Poisson and Hurdle Neg. Bin?
> 
> PS: My models employ a random effect to capture correlation among individuals (IDs).
> 
> Many thanks to your help,
> Zahwa Al-Ayyash
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From zsa11 at mail.aub.edu  Tue Mar 10 17:08:58 2015
From: zsa11 at mail.aub.edu (Zahwa Al Ayyash (Student))
Date: Tue, 10 Mar 2015 16:08:58 +0000
Subject: [R-sig-ME] Dispersion parameter in glmmadmb and model selection
In-Reply-To: <C98F7032-C8E8-4391-B247-C10CAB449896@glasgow.ac.uk>
References: <1425951555129.86251@mail.aub.edu>,
	<C98F7032-C8E8-4391-B247-C10CAB449896@glasgow.ac.uk>
Message-ID: <1426003734168.55983@mail.aub.edu>

Thanks a lot, things are much clearer now. My lambda is in fact around 2, so the 403 value of alpha seems to prove that my data is not over-dispersed.

Zahwa

________________________________________
From: Paul Johnson <paul.johnson at glasgow.ac.uk>
Sent: Tuesday, March 10, 2015 5:25 PM
To: Zahwa Al Ayyash (Student)
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Dispersion parameter in glmmadmb and model selection

Hi Zahwa,

In answer to the first question, the dispersion parameter, alpha, is inversely proportional to the amount of additional variance due to overdispersion...

Y ~ Poisson(lambda)
Var(Y) = lambda

Y ~ NB(lambda, alpha)
Var(Y) = lambda + lambda^2 / alpha

...so your error distribution appears not to be very overdispersed. In fact, if probably isn?t overdispersed at all, as I think glmmadmb puts an upper limit on the alpha estimate of exp(6) = 403.43, presumably to prevent it wondering off towards infinity when there is no evidence of overdispersion. This would explain why you get the same estimate from different (non-overdispersed) data sets. Try simulating some Poisson data and fitting an NB model (see code below).

I guess for low lambda, e.g. around 10, lambda^2 / 403 will be reasonable approximation of zero addition variance, but not for higher lambda, e.g. > 100. Not sure how glmmadmb copes with that, or if it?s possible to raise this ceiling.

Best wishes,
Paul

> set.seed(1234);
> y <- rpois(100, 5)
> dummy.group <- factor(rep(1:10, each = 10))
> fit <- glmmadmb(y ~ (1 | dummy.group), family = "nbinom2")
> summary(fit)

Call:
glmmadmb(formula = y ~ (1 | dummy.group), family = "nbinom2")

AIC: 422.6

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)    1.520      0.047    32.3   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=100, dummy.group=10
Random effect variance(s):
Group=dummy.group
             Variance    StdDev
(Intercept) 2.696e-08 0.0001642

Negative binomial dispersion parameter: 403.43 (std. err.: 0.72454)

Log-likelihood: -208.295
> fit$alpha
[1] 403.43
> log(fit$alpha)
[1] 6.000003




On 10 Mar 2015, at 01:39, Zahwa Al Ayyash (Student) <zsa11 at mail.aub.edu> wrote:

> Dear list,
>
> 1) I am fitting a negative binomial and zero-inflated negative binomial models using glmmadmb. I am getting a very high dispersion parameter:
>
> Negative binomial dispersion parameter: 403.43 (std. err.: 0.39244)
>
> I am aware that my data might be over-dispersed, but what does the very high value indicate? Could there be an error in estimation?
> Also, surprisingly, I am using two different data sets to estimate the neg. bin. models, and I am getting the same value (403.43) but with different std. errors. Any clues?
>
> 2) My second question is rather general; What could be the best ways to compare glmmadmb models and select the best amongst Poisson, Neg. Bin, Zero-inflated Poisson, Zero-inflated Neg. Bin., Hurdle Poisson and Hurdle Neg. Bin?
>
> PS: My models employ a random effect to capture correlation among individuals (IDs).
>
> Many thanks to your help,
> Zahwa Al-Ayyash
>
>
>
>
>
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bates at stat.wisc.edu  Tue Mar 10 17:40:54 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 10 Mar 2015 16:40:54 +0000
Subject: [R-sig-ME] lmer fails when too many observations
In-Reply-To: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>
References: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>
Message-ID: <CAO7JsnQWM24Uua9bwvV8BS8unjQUJLqA4gd81TAbggzPtVTD2w@mail.gmail.com>

It is not clear that the error message you quote is a result of too many
observations.

As Thierry stated, it would help to have a small reproducible example.

On Tue, Mar 10, 2015 at 9:24 AM Asaf Weinstein <asafw.at.wharton at gmail.com>
wrote:

> Dear lmer community,
>
> I am trying to run a simulation for a two-way random-effects model with
> unbalanced design (ie, unequal number of observations per cell) and no
> interaction.
> It's especially important for me to be able to run the lmer/blmer functions
> when the number of (column and row) random effects is large, say 100, and
> with possible replicates in each cell.
> The problem is that lmer() works with the full vector of observations, as
> opposed to working with the cell averages (which is a sufficient
> statistic), and the methods fails pretty quickly when there are replicates
> (because the response vector is too big, I suppose). I get the following
> error:
>
> *Error in get("checkConv", lme4Env)(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  : *
> *  (converted from warning) Model failed to converge with max|grad| =
> 0.00244385 (tol = 0.002)*
>
> Just to give an example: suppose there are R=100 row effects, C=100 column
> effects, and 5 replicates in each cell. The vector of individual
> observations is of length 100^5 (lmer fails), while the vector of cell
> averages is of length 100^2 (a size which causes no problem for lmer).
> My question is whether there is a way to tell lmer() to work with the
> sufficient statistic (of course, the conditional covariance is no longer
> c*Identity, a fact which is used in the implementation of lmer (according
> to documentation) ).
>
> Thank you very much and I hope I was clear!
>
> Asaf
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From vjd4 at nyu.edu  Tue Mar 10 18:23:22 2015
From: vjd4 at nyu.edu (Vincent Dorie)
Date: Tue, 10 Mar 2015 13:23:22 -0400
Subject: [R-sig-ME] Error fitting reduced model in bglmer for LRT
In-Reply-To: <CAGb-hRqJ5J8OEvmtLDm0b=mOD=U_t1m8xd3ZMADomnkovELthA@mail.gmail.com>
References: <CAGb-hRqJ5J8OEvmtLDm0b=mOD=U_t1m8xd3ZMADomnkovELthA@mail.gmail.com>
Message-ID: <9FBE19D0-EA83-4F5B-8333-0C52C18390D9@nyu.edu>

I don't know what exactly anova() does for glmms, but I wouldn't recommend a likelihood ratio test to compare posterior modes unless you can be certain the data swamp the prior.

The error you experienced is a copy/paste error on my part. You can run the code below to fix it temporarily, until I can get a new release on CRAN.

assignInNamespace("toString.bmerTDist", function(x, digits = getOption("digits"), ...) {
  scaleString <- ""
  scale <- crossprod(solve(x at R.scale.inv))
  
  if (nrow(scale) > 2) {
    scaleString <- paste("scale = c(", toString(round(scale[1:4], digits)), ", ...)", sep = "")
  } else if (nrow(scale) == 2) {
    scaleString <- paste("scale = c(", toString(round(scale[1:4], digits)), ")", sep = "")
  } else {
    scaleString <- paste("scale = ", toString(round(scale[1], digits)), sep = "")
  }
  
  paste("t(df = ", x at df, ", ", scaleString,
        ", common.scale = ", x at commonScale,
        ")", sep="")
}, "blme")

Vince

> On Mar 9, 2015, at 11:47 PM, Josie Galbraith <josie.galbraith at gmail.com> wrote:
> 
> Hi all,
> 
> In following on from this post
> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023191.html>,
> regarding using blme and fixed effect priors to address issues of complete
> separation in my data, I've come up against a problem trying to fit reduced
> models for testing the model terms using likelihood ratio tests (LRT).
> 
> Firstly, can I use LRTs (anova()) for testing the fixed effects of bglmer
> models, as I would for glmer models?
> 
> If yes, then I need help understanding why I'm getting the following error
> fitting a reduced bglmer model:
> "Error in if (nrow(cov) == 2) { : argument is of length zero"
> 
> This is my full model:
> SE.les.mod = bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family
> = binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> 
> I can fit a model without the interaction term ok:
> SE.les.add = bglmer (LESION ~ FOOD+SEASON +(1|SITE), data = SEYE.df, family
> = binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> 
> But I get the error message with both of the single fixed effects models:
> SE.les.FOOD = bglmer (LESION ~ SEASON +(1|SITE), data = SEYE.df, family =
> binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> SE.les.SEAS = bglmer (LESION ~ FOOD +(1|SITE), data = SEYE.df, family =
> binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> 
> Thanks very much,
> Josie
> 
> 
> 
> -- 
> *Josie Galbraith* MSc (hons)
> 
> PhD candidate
> *University of Auckland *
> Joint Graduate School in Biodiversity and Biosecurity ? School of
> Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
> P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
> Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
> *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From e.sharps at gmail.com  Wed Mar 11 11:43:19 2015
From: e.sharps at gmail.com (Elwyn Sharps)
Date: Wed, 11 Mar 2015 10:43:19 +0000
Subject: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
 failed to reduce deviance in pwrssUpdate
In-Reply-To: <1631f1b7746f0d391ca615e623b198aa@mail.gmail.com>
References: <CAM7=EBRe+KSK-zk=zC0YUsbvoGypAi-Yu=Ek3O+YqFVwNC98Lw@mail.gmail.com>
	<loom.20150309T021601-509@post.gmane.org>
	<1631f1b7746f0d391ca615e623b198aa@mail.gmail.com>
Message-ID: <CAM7=EBRNNK6vevtiE=v3d-d9p+NE-Cr747_XvS-ONHckJFrH0g@mail.gmail.com>

Thank you very much for working on this Ben and your very useful comment
Mark! I really appreciate all of your help. It looks like it was the zero
in the exposure days that was causing the problem. As the data were
recently sent on to me from a variety of sources, I hadn't spotted this! It
looks like it is due to an observer witnessing a nest mortality on the same
day as he found the active nest, which then resulted in zero exposure days.

Very grateful for all your help

Best wishes

Elwyn

On 9 March 2015 at 20:30, Mark Herzog <mherzog at usgs.gov> wrote:

>    RE: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings failed
> to reduce deviance in pwrssUpdate
>
> I think it might be a result of you having an exposure period of zero days
> in your data... That won't work very well given the link function....
>
> Sorry this is based using my R package, so the codes a little different,
> but here's the example:
>
> > library(nestsurvival)
>
> > mydata<-read.csv("c:/users/mherzog/Downloads/habitat-type_example.csv")
>
> >
>
> glm1<-glm(survive/trials~habitat,family=binomial(logexp(days=mydata$expos)),data=mydata)
>
> Error: cannot find valid starting values: please specify some
>
> > mydata<-subset(mydata,expos>0)
>
> >
>
> glm1<-glm(survive/trials~habitat,family=binomial(logexp(days=mydata$expos)),data=mydata)
>
> > summary(glm1)
>
> Call:
>
> glm(formula = survive/trials ~ habitat, family = binomial(logexp(days =
> mydata$expos)),
>
>     data = mydata)
>
> Deviance Residuals:
>
>     Min       1Q   Median       3Q      Max
>
> -2.0963  -0.8808   0.5694   0.8052   2.2708
>
> Coefficients:
>
>               Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)     1.9629     0.4036   4.863 1.16e-06 ***
>
> habitatForest  -0.0342     0.4327  -0.079   0.9370
>
> habitatHeath    0.5090     0.4126   1.234   0.2173
>
> habitatScrub    0.8395     0.4497   1.867   0.0619 .
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>     Null deviance: 787.11  on 568  degrees of freedom
>
> Residual deviance: 621.21  on 565  degrees of freedom
>
> AIC: 629.21
>
> Number of Fisher Scoring iterations: 5
>
>  -----Original Message-----
>
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org
> <r-sig-mixed-models-bounces at r-project.org>] On Behalf Of Ben Bolker
>
> Sent: Sunday, March 08, 2015 6:18 PM
>
> To: r-sig-mixed-models at r-project.org
>
> Subject: Re: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
> failed to reduce deviance in pwrssUpdate
>
> Elwyn Sharps <e.sharps at ...> writes:
>
> >
>
> > Hi Ben
>
> >
>
> > Thank you very much for your reply. If you click on this link, it
>
> > should give you the data in a CSV file.
>
> > https://sites.google.com/site/es263datahlp/habitat-type_example.csv
>
> >
>
> > Many thanks
>
> >
>
> > Elwyn
>
>   I worked on this for a while, without complete success. The main issue is
> that the inverse-link function and derivative functions need some clamping
> so that they don't hit 0/1 ... this still doesn't solve the lme4 problem,
> but at least it allows the GLM to work.
>
>   Have you considered a cloglog link + offset(log(exposure)) model?  That
> *might* be a little more stable ...
>
> library(lme4)
>
> library(MASS)
>
> logexp <- function(exposure = 1, eps=1e-8, maxlink=Inf) {
>
>   linkfun <- function(mu) {
>
>       r <- qlogis(mu^(1/exposure))
>
>       ## clamp link function: not actually necessary?
>
>       ##  maxlink set to Inf
>
>       if (any(toobig <- abs(r)>maxlink)) {
>
>           ## cat("max threshold hit")
>
>           r[toobig] <- sign(r[toobig])*maxlink
>
>       }
>
>       return(r)
>
>   }
>
>   ## utility for clamping inverse-link, derivative function
>
>   clamp <- function(x) {
>
>       x <- pmax(eps,x)
>
>       if (upr) x <- pmin(1-eps,x)
>
>       return(x)
>
>   }
>
>   linkinv <- function(eta)  clamp(plogis(eta)^exposure)
>
>   mu.eta <- function(eta) {
>
>       r <- exposure * clamp(plogis(eta)^(exposure-1)) *
>
>           .Call(stats:::C_logit_mu_eta, eta, PACKAGE = "stats")
>
>       return(r)
>
>   }
>
>   valideta <- function(eta) TRUE
>
>   link <- paste("logexp(", deparse(substitute(exposure)), ")",
>
>                 sep="")
>
>   structure(list(linkfun = linkfun, linkinv = linkinv,
>
>                  mu.eta = mu.eta, valideta = valideta,
>
>                  name = link),
>
>             class = "link-glm")
>
> }
>
> ##Read in data, called 'mydata'
>
> mydata <- read.csv("habitat-type_example.csv")
>
> library("ggplot2")
>
> with(mydata,table(survive,trials))
>
> with(mydata,table(survive,habitat))
>
> ggplot(mydata,aes(log(1+expos),survive,colour=habitat))+
>
>     geom_point()+
>
>     geom_smooth(method="glm",family="binomial")
>
> ggplot(subset(mydata,habitat=="Conregrowth"),
>
>        aes(expos,survive))+
>
>            stat_sum(aes(size=..n..))+
>
>     geom_smooth(method="glm",family="binomial")+
>
>         scale_size_area()
>
> ## trials is always == 1 in this data set
>
> ## the fact that glm() fails means that the problem is more ## basic than a
> GLMM problem
>
> glm1 <- glm(survive~habitat,
>
>             family=binomial(logexp(exposure=mydata$expos)),
>
>             data=mydata)
>
> Mod1 <- glmer(survive~habitat + (1|site)+(1|year),
>
>               family=binomial(logexp(exposure=mydata$expos)),data=mydata,
>
>               nAGQ=1,
>
>               devFunOnly=TRUE,
>
>               control=glmerControl(nAGQ0initStep=FALSE),
>
>               start=list(beta=coef(glm1),theta=1e-5),
>
>               verbose=100)
>
> Mod2 <- glmer(survive~habitat + (1|year),
>
>               family=binomial(logexp(exposure=mydata$expos)),data=mydata,
>
>               start=list(theta=c(1e-6,1e-6)),
>
>               nAGQ=0,
>
>               devFunOnly=TRUE)
>
> Mod3 <- glmer(survive~habitat + (1|site),
>
>               family=binomial(logexp(exposure=mydata$expos)),data=mydata,
>
>               start=list(theta=c(1e-6,1e-6)),
>
>               nAGQ=0,
>
>               devFunOnly=TRUE)
>
> mydata3 <- droplevels(subset(mydata,habitat!="Conregrowth"))
>
> Mod4 <- glmer(survive~habitat + (1|year),
>
>               family=binomial(logexp(exposure=mydata3$expos)),data=mydata3)
>
> Mod5 <- glmer(survive~habitat + (1|site),
>
>               family=binomial(logexp(exposure=mydata3$expos)),data=mydata3,
>
>               nAGQ=1,
>
>               devFunOnly=TRUE,
>
>               control=glmerControl(nAGQ0initStep=FALSE),
>
>               start=list(beta=coef(glm1),theta=1e-5),
>
>               verbose=100)
>
> with(mydata3,table(site,habitat,survive))
>
> with(mydata,table(year,habitat,survive))
>
> >
>
> > On 5 March 2015 at 03:11, Ben Bolker <bbolker at ...> wrote:
>
> >
>
> > > Elwyn Sharps <e.sharps <at> ...> writes:
>
> > >
>
> > > >
>
> > >
>
> > > [snip]
>
> > >
>
> > > > I am using a nest survival model (glmer) with random effects and a
>
> > > logistic
>
> > > > exposure link function, as described here:
>
> > > >
>
> > > >
>
> > > http://stackoverflow.com/questions/19012128/user-defined-link-functi
>
> > > on-for-
>
> > > > glmer-for-known-fate-survival-modelling
>
> > > >
>
> > > > I am running a number of different models, with varying fixed
> effects.
>
> > > Some
>
> > > > of them are running well, with no error or warning messages,
>
> > > > however for other models, I am getting the following message:
>
> > > >
>
> > > > *Error: (maxstephalfit) PIRLS step-halvings failed to reduce
>
> > > > deviance in
>
> > > > pwrssUpdate*
>
> > > >
>
> > > > I'm not sure what is causing this error. I have tried to check the
>
> > > > data
>
> > > for
>
> > > > simple problems, however can't see anything that could be causing
>
> > > trouble.
>
> > > >
>
> > > > I've also tried running the model without the random effects. This
>
> > > results
>
> > > > in a different error message:
>
> > > >
>
> > > > *Error: cannot find valid starting values: please specify some*
>
> > >
>
> > >   Example data doesn't seem to be attached: it may have been
>
> > > stripped by the mailing list software.  Can you post it somewhere
>
> > > public and provide a URL?
>
> > >
>
> > >   My guess it that there is something rather wonky about the data
>
> > > for this example, e.g. complete separation (for example, no
>
> > > individuals die for some combination of predictor variables).  Hard
>
> > > to say without the data though.
>
> > >
>
> > >   Ben Bolker
>
> > >
>
> > > _______________________________________________
>
> > > R-sig-mixed-models at ... mailing list
>
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> > >
>
> >
>
> >       [[alternative HTML version deleted]]
>
> >
>
> >
>
> _______________________________________________
>
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Mar 11 13:05:41 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Mar 2015 08:05:41 -0400
Subject: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
 failed to reduce deviance in pwrssUpdate
In-Reply-To: <CAM7=EBRNNK6vevtiE=v3d-d9p+NE-Cr747_XvS-ONHckJFrH0g@mail.gmail.com>
References: <CAM7=EBRe+KSK-zk=zC0YUsbvoGypAi-Yu=Ek3O+YqFVwNC98Lw@mail.gmail.com>
	<loom.20150309T021601-509@post.gmane.org>
	<1631f1b7746f0d391ca615e623b198aa@mail.gmail.com>
	<CAM7=EBRNNK6vevtiE=v3d-d9p+NE-Cr747_XvS-ONHckJFrH0g@mail.gmail.com>
Message-ID: <CABghstQFJuMwzA73zX0333mBY2AJ+713Pttm1eax7YwOHEZteA@mail.gmail.com>

  Huh.  I saw that zero-exposure case, but clamping the inverse-link
function seemed to make the GLM work, so I didn't think that it would
still be screwing up the GLMM ...

On Wed, Mar 11, 2015 at 6:43 AM, Elwyn Sharps <e.sharps at gmail.com> wrote:
>
> Thank you very much for working on this Ben and your very useful comment
> Mark! I really appreciate all of your help. It looks like it was the zero in
> the exposure days that was causing the problem. As the data were recently
> sent on to me from a variety of sources, I hadn't spotted this! It looks
> like it is due to an observer witnessing a nest mortality on the same day as
> he found the active nest, which then resulted in zero exposure days.
>
> Very grateful for all your help
>
> Best wishes
>
> Elwyn
>
> On 9 March 2015 at 20:30, Mark Herzog <mherzog at usgs.gov> wrote:
>>
>>    RE: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
>> failed
>> to reduce deviance in pwrssUpdate
>>
>> I think it might be a result of you having an exposure period of zero days
>> in your data... That won't work very well given the link function....
>>
>> Sorry this is based using my R package, so the codes a little different,
>> but here's the example:
>>
>> > library(nestsurvival)
>>
>> > mydata<-read.csv("c:/users/mherzog/Downloads/habitat-type_example.csv")
>>
>> >
>>
>> glm1<-glm(survive/trials~habitat,family=binomial(logexp(days=mydata$expos)),data=mydata)
>>
>> Error: cannot find valid starting values: please specify some
>>
>> > mydata<-subset(mydata,expos>0)
>>
>> >
>>
>> glm1<-glm(survive/trials~habitat,family=binomial(logexp(days=mydata$expos)),data=mydata)
>>
>> > summary(glm1)
>>
>> Call:
>>
>> glm(formula = survive/trials ~ habitat, family = binomial(logexp(days =
>> mydata$expos)),
>>
>>     data = mydata)
>>
>> Deviance Residuals:
>>
>>     Min       1Q   Median       3Q      Max
>>
>> -2.0963  -0.8808   0.5694   0.8052   2.2708
>>
>> Coefficients:
>>
>>               Estimate Std. Error z value Pr(>|z|)
>>
>> (Intercept)     1.9629     0.4036   4.863 1.16e-06 ***
>>
>> habitatForest  -0.0342     0.4327  -0.079   0.9370
>>
>> habitatHeath    0.5090     0.4126   1.234   0.2173
>>
>> habitatScrub    0.8395     0.4497   1.867   0.0619 .
>>
>> ---
>>
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> (Dispersion parameter for binomial family taken to be 1)
>>
>>     Null deviance: 787.11  on 568  degrees of freedom
>>
>> Residual deviance: 621.21  on 565  degrees of freedom
>>
>> AIC: 629.21
>>
>> Number of Fisher Scoring iterations: 5
>>
>>  -----Original Message-----
>>
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org
>> <r-sig-mixed-models-bounces at r-project.org>] On Behalf Of Ben Bolker
>>
>> Sent: Sunday, March 08, 2015 6:18 PM
>>
>> To: r-sig-mixed-models at r-project.org
>>
>> Subject: Re: [R-sig-ME] Nest survival: (maxstephalfit) PIRLS step-halvings
>> failed to reduce deviance in pwrssUpdate
>>
>> Elwyn Sharps <e.sharps at ...> writes:
>>
>> >
>>
>> > Hi Ben
>>
>> >
>>
>> > Thank you very much for your reply. If you click on this link, it
>>
>> > should give you the data in a CSV file.
>>
>> > https://sites.google.com/site/es263datahlp/habitat-type_example.csv
>>
>> >
>>
>> > Many thanks
>>
>> >
>>
>> > Elwyn
>>
>>   I worked on this for a while, without complete success. The main issue
>> is
>> that the inverse-link function and derivative functions need some clamping
>> so that they don't hit 0/1 ... this still doesn't solve the lme4 problem,
>> but at least it allows the GLM to work.
>>
>>   Have you considered a cloglog link + offset(log(exposure)) model?  That
>> *might* be a little more stable ...
>>
>> library(lme4)
>>
>> library(MASS)
>>
>> logexp <- function(exposure = 1, eps=1e-8, maxlink=Inf) {
>>
>>   linkfun <- function(mu) {
>>
>>       r <- qlogis(mu^(1/exposure))
>>
>>       ## clamp link function: not actually necessary?
>>
>>       ##  maxlink set to Inf
>>
>>       if (any(toobig <- abs(r)>maxlink)) {
>>
>>           ## cat("max threshold hit")
>>
>>           r[toobig] <- sign(r[toobig])*maxlink
>>
>>       }
>>
>>       return(r)
>>
>>   }
>>
>>   ## utility for clamping inverse-link, derivative function
>>
>>   clamp <- function(x) {
>>
>>       x <- pmax(eps,x)
>>
>>       if (upr) x <- pmin(1-eps,x)
>>
>>       return(x)
>>
>>   }
>>
>>   linkinv <- function(eta)  clamp(plogis(eta)^exposure)
>>
>>   mu.eta <- function(eta) {
>>
>>       r <- exposure * clamp(plogis(eta)^(exposure-1)) *
>>
>>           .Call(stats:::C_logit_mu_eta, eta, PACKAGE = "stats")
>>
>>       return(r)
>>
>>   }
>>
>>   valideta <- function(eta) TRUE
>>
>>   link <- paste("logexp(", deparse(substitute(exposure)), ")",
>>
>>                 sep="")
>>
>>   structure(list(linkfun = linkfun, linkinv = linkinv,
>>
>>                  mu.eta = mu.eta, valideta = valideta,
>>
>>                  name = link),
>>
>>             class = "link-glm")
>>
>> }
>>
>> ##Read in data, called 'mydata'
>>
>> mydata <- read.csv("habitat-type_example.csv")
>>
>> library("ggplot2")
>>
>> with(mydata,table(survive,trials))
>>
>> with(mydata,table(survive,habitat))
>>
>> ggplot(mydata,aes(log(1+expos),survive,colour=habitat))+
>>
>>     geom_point()+
>>
>>     geom_smooth(method="glm",family="binomial")
>>
>> ggplot(subset(mydata,habitat=="Conregrowth"),
>>
>>        aes(expos,survive))+
>>
>>            stat_sum(aes(size=..n..))+
>>
>>     geom_smooth(method="glm",family="binomial")+
>>
>>         scale_size_area()
>>
>> ## trials is always == 1 in this data set
>>
>> ## the fact that glm() fails means that the problem is more ## basic than
>> a
>> GLMM problem
>>
>> glm1 <- glm(survive~habitat,
>>
>>             family=binomial(logexp(exposure=mydata$expos)),
>>
>>             data=mydata)
>>
>> Mod1 <- glmer(survive~habitat + (1|site)+(1|year),
>>
>>               family=binomial(logexp(exposure=mydata$expos)),data=mydata,
>>
>>               nAGQ=1,
>>
>>               devFunOnly=TRUE,
>>
>>               control=glmerControl(nAGQ0initStep=FALSE),
>>
>>               start=list(beta=coef(glm1),theta=1e-5),
>>
>>               verbose=100)
>>
>> Mod2 <- glmer(survive~habitat + (1|year),
>>
>>               family=binomial(logexp(exposure=mydata$expos)),data=mydata,
>>
>>               start=list(theta=c(1e-6,1e-6)),
>>
>>               nAGQ=0,
>>
>>               devFunOnly=TRUE)
>>
>> Mod3 <- glmer(survive~habitat + (1|site),
>>
>>               family=binomial(logexp(exposure=mydata$expos)),data=mydata,
>>
>>               start=list(theta=c(1e-6,1e-6)),
>>
>>               nAGQ=0,
>>
>>               devFunOnly=TRUE)
>>
>> mydata3 <- droplevels(subset(mydata,habitat!="Conregrowth"))
>>
>> Mod4 <- glmer(survive~habitat + (1|year),
>>
>>
>> family=binomial(logexp(exposure=mydata3$expos)),data=mydata3)
>>
>> Mod5 <- glmer(survive~habitat + (1|site),
>>
>>
>> family=binomial(logexp(exposure=mydata3$expos)),data=mydata3,
>>
>>               nAGQ=1,
>>
>>               devFunOnly=TRUE,
>>
>>               control=glmerControl(nAGQ0initStep=FALSE),
>>
>>               start=list(beta=coef(glm1),theta=1e-5),
>>
>>               verbose=100)
>>
>> with(mydata3,table(site,habitat,survive))
>>
>> with(mydata,table(year,habitat,survive))
>>
>> >
>>
>> > On 5 March 2015 at 03:11, Ben Bolker <bbolker at ...> wrote:
>>
>> >
>>
>> > > Elwyn Sharps <e.sharps <at> ...> writes:
>>
>> > >
>>
>> > > >
>>
>> > >
>>
>> > > [snip]
>>
>> > >
>>
>> > > > I am using a nest survival model (glmer) with random effects and a
>>
>> > > logistic
>>
>> > > > exposure link function, as described here:
>>
>> > > >
>>
>> > > >
>>
>> > > http://stackoverflow.com/questions/19012128/user-defined-link-functi
>>
>> > > on-for-
>>
>> > > > glmer-for-known-fate-survival-modelling
>>
>> > > >
>>
>> > > > I am running a number of different models, with varying fixed
>> > > > effects.
>>
>> > > Some
>>
>> > > > of them are running well, with no error or warning messages,
>>
>> > > > however for other models, I am getting the following message:
>>
>> > > >
>>
>> > > > *Error: (maxstephalfit) PIRLS step-halvings failed to reduce
>>
>> > > > deviance in
>>
>> > > > pwrssUpdate*
>>
>> > > >
>>
>> > > > I'm not sure what is causing this error. I have tried to check the
>>
>> > > > data
>>
>> > > for
>>
>> > > > simple problems, however can't see anything that could be causing
>>
>> > > trouble.
>>
>> > > >
>>
>> > > > I've also tried running the model without the random effects. This
>>
>> > > results
>>
>> > > > in a different error message:
>>
>> > > >
>>
>> > > > *Error: cannot find valid starting values: please specify some*
>>
>> > >
>>
>> > >   Example data doesn't seem to be attached: it may have been
>>
>> > > stripped by the mailing list software.  Can you post it somewhere
>>
>> > > public and provide a URL?
>>
>> > >
>>
>> > >   My guess it that there is something rather wonky about the data
>>
>> > > for this example, e.g. complete separation (for example, no
>>
>> > > individuals die for some combination of predictor variables).  Hard
>>
>> > > to say without the data though.
>>
>> > >
>>
>> > >   Ben Bolker
>>
>> > >
>>
>> > > _______________________________________________
>>
>> > > R-sig-mixed-models at ... mailing list
>>
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> > >
>>
>> >
>>
>> >       [[alternative HTML version deleted]]
>>
>> >
>>
>> >
>>
>> _______________________________________________
>>
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From bbolker at gmail.com  Wed Mar 11 22:26:50 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Mar 2015 17:26:50 -0400
Subject: [R-sig-ME] lmer fails when too many observations
In-Reply-To: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>
References: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>
Message-ID: <5500B31A.1010900@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Just a quick update on this.
  This 'failure' is coming because (1) the current version of lme4 has
too strict a test for convergence and gives what we think are
false-positive warnings, especially for large data sets; (2) you have
set options(warn=2) so that warnings get converted into errors.  Until
we get the issue fixed (which could take a while, as we haven't yet
given up on finding a more principled way than just increasing the
default tolerance a lot) you can either (a) convert your warnings back
to regular warnings (i.e. options(warn=1) or options(warn=0) or (b)
increase the tolerance level, e.g.

 control= lmerControl(check.conv.grad = .makeCC("warning", tol = 1e-2))

or

 control = lmerControl(check.conv.grad = "ignore")



On 15-03-09 09:52 PM, Asaf Weinstein wrote:
> Dear lmer community,
> 
> I am trying to run a simulation for a two-way random-effects model
> with unbalanced design (ie, unequal number of observations per
> cell) and no interaction. It's especially important for me to be
> able to run the lmer/blmer functions when the number of (column and
> row) random effects is large, say 100, and with possible replicates
> in each cell. The problem is that lmer() works with the full vector
> of observations, as opposed to working with the cell averages
> (which is a sufficient statistic), and the methods fails pretty
> quickly when there are replicates (because the response vector is
> too big, I suppose). I get the following error:
> 
> *Error in get("checkConv", lme4Env)(attr(opt, "derivs"), opt$par,
> ctrl = control$checkConv,  : * *  (converted from warning) Model
> failed to converge with max|grad| = 0.00244385 (tol = 0.002)*
> 
> Just to give an example: suppose there are R=100 row effects, C=100
> column effects, and 5 replicates in each cell. The vector of
> individual observations is of length 100^5 (lmer fails), while the
> vector of cell averages is of length 100^2 (a size which causes no
> problem for lmer). My question is whether there is a way to tell
> lmer() to work with the sufficient statistic (of course, the
> conditional covariance is no longer c*Identity, a fact which is
> used in the implementation of lmer (according to documentation) ).
> 
> Thank you very much and I hope I was clear!



-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVALMaAAoJEOCV5YRblxUHnRwH/j8/MFNfYKgvgzbBBCdmfXOi
nfRGRpGWrFUM7MznFWFf4hdA0SFPUOTS9yZYxoGuyJHos1q5WeAyR9kdlqNQjdDx
lPV+zYy9gsj+uMl5XBVSurDrfJY+JXfnqtOzZECMbrZjNxHgTMnSxzMdRNVZAVm6
DaCAaNGJkeTI96k4jg7ucj1p/xGgk3deVW8NMY3bKMasd+dtFzTXqPDvEYovBRQT
sbQ7SavzjJY93QYHabaaDkpsD8N86qe5fJgOE9uVLNkvuOGVPELvwG8lCaC/kj7y
wdd4+HOum1AgeBUosCRfs+Ld41V4wBUySxFW9coLRUVwzQGfU8rOTjIpKs4iCpY=
=jitR
-----END PGP SIGNATURE-----


From bates at stat.wisc.edu  Thu Mar 12 18:51:29 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 12 Mar 2015 17:51:29 +0000
Subject: [R-sig-ME] GLS models question
In-Reply-To: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0881E81FFF31@CMS04.campus.gla.ac.uk>
References: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0881E81FFF31@CMS04.campus.gla.ac.uk>
Message-ID: <CAO7JsnRD9mNtg2vVqJ3_irn12WgQpqS+hAV-Q3KwE1O0XCprKg@mail.gmail.com>

It is better to send questions like this to the
R-SIG-Mixed-Models at R-project.org mailing list, which I am cc'ing on this
reply.  Several of those who read that list are better able to respond
quickly than I am.

On Thu, Mar 12, 2015 at 7:55 AM Sophie Elliott <
s.elliott.1 at research.gla.ac.uk> wrote:

> Dear Dr Pinheiro and Dr Bates,
>
> I?m a PhD student from the university of Glasgow and have been using your
> nlme package in R for data analysis. Specifically I have been using a GLS
> model distribution for my data since I have heterogeneity in my data. I was
> wondering whether it was valid to add an independent random effect to my
> model in addition to the variance structures i.e. I am interested in
> understanding how substrate type and standardised fauna dominance affects
> the standardised abundance of juvenile cod. The data has been standardised
> according to the area of a transect instead of adding an offset since my
> sample size is small due to logistical problems in collecting the data.
>
> Through model selection procedure I have fitted a GLS with a variance
> structure for fauna dominance, however I would like to add a random effect
> for Julian date and Cluster locations (to take into account temporal and
> spatial variation). Do you think this is possible, if so how could I apply
> this? I have tried applying a random effect and a variance structure a
> normal GLMM using nlme, however the residuals are far more heterogeneous
> when I use a GLS model structure. I also tried adding JD to the GLS
> variance structure of the model only but I wasn?t sure whether this was a
> statistically sound method to carry out the analysis
>
> e.g. of the GLS I am not sure about:
> VCb<- varComb(varIdent(form=~ 1|factor(JD)),
>               varPower(form=~ IDominance))##power
>
> GLS4 <- gls(SNumber ~ Substrate + IDominance,
>             weights=VCb,
>             data=Cod)#
>
>
> Thank you so much for you time
>
> Sophie
>
>
>
> PhD Student
> University of Glasgow
> Institute of Biodiversity, Animal Health and Comparative Medicine
> Graham Kerr Building, University of Glasgow, Glasgow G12 8QQ
>
> Email: S.Elliott.1 at research.gla.ac.uk
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Thu Mar 12 18:52:34 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 12 Mar 2015 17:52:34 +0000
Subject: [R-sig-ME] Contrast in lme4
In-Reply-To: <CABGg3O6WM_8t9sOv7YcDzEFQ_SkfFUS7iTebZTex+qeY8h=TmA@mail.gmail.com>
References: <CABGg3O6WM_8t9sOv7YcDzEFQ_SkfFUS7iTebZTex+qeY8h=TmA@mail.gmail.com>
Message-ID: <CAO7JsnRhe4T5=OJAc-7Q292rxrYHdhVGLH5=-XkA=pGVKuguJA@mail.gmail.com>

It is better to send questions like this to the
R-SIG-Mixed-Models at R-project.org mailing list, which I am cc:ing on this
reply.

On Thu, Mar 12, 2015 at 3:09 AM adeela uaf <adeela.uaf at gmail.com> wrote:

> Dear Douglas Bates,
> How to perform contrast analysis for fixed effects in lme4 package. My
> data is same as sleepstudy data with an additional cloumn comprising  12
> treatments also. The structure of the treatmnets is such that:
> 1) 1 treatment is control
> 2) 4 treatments are bio-agents.
> 3) 3 treatments are botanical.
> 4) 2 are bi prodcts
> 5) 2 are fungisides
> I want to make comparison among the groups which differ significantly
> after
> Model<-lmer(Disease~Trt+Date+Trt*Date+(1|Subject),data=YR)
> Best Regars,
> Adeela
>

	[[alternative HTML version deleted]]


From sophia.kyriakou17 at gmail.com  Thu Mar 12 18:56:57 2015
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Thu, 12 Mar 2015 19:56:57 +0200
Subject: [R-sig-ME] glmer warning messages using version 1.1.7
Message-ID: <CAO4gA+odDarYj_DU58D9OeJxMXOrNhye9So3q9GBCqYoJVbV8A@mail.gmail.com>

Hello,

I run a simulation study fitting a GLMM random intercept model and I get
warning messages. I tried various optimizers but they all give warning
messages. Please find below one of the simulated samples.
I am using the lme4 package version 1.1.7 on R 3.1.3.
Do I ignore these warning messages or is there a way of dealing with them?

Thanks in advance.

library(lme4)
library(optimx)
m <- 6
q <- 20
beta  <- 2
sigma2 <- 0.1
set.seed(206)
alpha <- rnorm(q, 0, sqrt(sigma2))
Y <- rbinom(q,m,plogis(alpha+beta))
cl <- seq.int(q)
tot <- rep(m,q)
dat <- data.frame(y = Y, tot = tot, cl = cl)
g0.bobyqa <- glmer(cbind(y, tot - y) ~ 1 + (1 | cl), data = dat,family =
binomial(),nAGQ = 20,control=glmerControl(optimizer="bobyqa"))
g0.NM <- update(g0.bobyqa,control=glmerControl(optimizer="Nelder_Mead"))
g0.nlminb <-
update(g0.bobyqa,control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
g0.LBFGSB <-
update(g0.bobyqa,control=glmerControl(optimizer="optimx",optCtrl=list(method="L-BFGS-B")))

library(nloptr)
## from https://github.com/lme4/lme4/issues/98:
defaultControl <-
list(algorithm="NLOPT_LN_BOBYQA",xtol_rel=1e-6,maxeval=1e5)
nloptwrap2 <- function(fn,par,lower,upper,control=list(),...) {
    for (n in names(defaultControl))
      if (is.null(control[[n]])) control[[n]] <- defaultControl[[n]]
    res <- nloptr(x0=par,eval_f=fn,lb=lower,ub=upper,opts=control,...)
    with(res,list(par=solution,
                  fval=objective,
                  feval=iterations,
                  conv=if (status>0) 0 else status,
                  message=message))
}
g0.bobyqa2 <- update(g0.bobyqa,control=glmerControl(optimizer=nloptwrap2))
g0.NM2 <-
update(g0.bobyqa,control=glmerControl(optimizer=nloptwrap2,optCtrl=list(algorithm="NLOPT_LN_NELDERMEAD")))


dd <- g0.bobyqa at optinfo$derivs
with(dd,max(abs(solve(Hessian,gradient)))<2e-3)

	[[alternative HTML version deleted]]


From sophia.kyriakou17 at gmail.com  Thu Mar 12 19:35:38 2015
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Thu, 12 Mar 2015 20:35:38 +0200
Subject: [R-sig-ME] convergence warnings with lme4 1.1.7
Message-ID: <CAO4gA+rXjtkwFYPcwN8KUgkcQMUWPGPR1FS3GnFExo+vY6Vfyw@mail.gmail.com>

Hello,

I run a simulation study fitting a GLMM random intercept model and I get
warning messages. I tried various optimizers but they all give warning
messages. Please find below one of the simulated samples.
I am using the lme4 package version 1.1.7 on R 3.1.3.
Do I ignore these warning messages or is there a way of dealing with them?

Thanks in advance.

library(lme4)
library(optimx)
m <- 6
q <- 20
beta  <- 2
sigma2 <- 0.1
set.seed(206)
alpha <- rnorm(q, 0, sqrt(sigma2))
Y <- rbinom(q,m,plogis(alpha+beta))
cl <- seq.int(q)
tot <- rep(m,q)
dat <- data.frame(y = Y, tot = tot, cl = cl)
g0.bobyqa <- glmer(cbind(y, tot - y) ~ 1 + (1 | cl), data = dat,family =
binomial(),nAGQ = 20,control=glmerControl(optimizer="bobyqa"))
g0.NM <- update(g0.bobyqa,control=glmerControl(optimizer="Nelder_Mead"))
g0.nlminb <-
update(g0.bobyqa,control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
g0.LBFGSB <-
update(g0.bobyqa,control=glmerControl(optimizer="optimx",optCtrl=list(method="L-BFGS-B")))

library(nloptr)
## from https://github.com/lme4/lme4/issues/98:
defaultControl <-
list(algorithm="NLOPT_LN_BOBYQA",xtol_rel=1e-6,maxeval=1e5)
nloptwrap2 <- function(fn,par,lower,upper,control=list(),...) {
    for (n in names(defaultControl))
      if (is.null(control[[n]])) control[[n]] <- defaultControl[[n]]
    res <- nloptr(x0=par,eval_f=fn,lb=lower,ub=upper,opts=control,...)
    with(res,list(par=solution,
                  fval=objective,
                  feval=iterations,
                  conv=if (status>0) 0 else status,
                  message=message))
}
g0.bobyqa2 <- update(g0.bobyqa,control=glmerControl(optimizer=nloptwrap2))
g0.NM2 <-
update(g0.bobyqa,control=glmerControl(optimizer=nloptwrap2,optCtrl=list(algorithm="NLOPT_LN_NELDERMEAD")))


dd <- g0.bobyqa at optinfo$derivs
with(dd,max(abs(solve(Hessian,gradient)))<2e-3)

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Mar 12 19:45:05 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Mar 2015 14:45:05 -0400
Subject: [R-sig-ME] glmer warning messages using version 1.1.7
In-Reply-To: <CAO4gA+odDarYj_DU58D9OeJxMXOrNhye9So3q9GBCqYoJVbV8A@mail.gmail.com>
References: <CAO4gA+odDarYj_DU58D9OeJxMXOrNhye9So3q9GBCqYoJVbV8A@mail.gmail.com>
Message-ID: <5501DEB1.30100@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


   I think these are ignorable.  If you want to turn them off,
check out ?glmerControl.

Here's what I looked at:

H <- g0.bobyqa at optinfo$derivs$Hessian
V <- solve(H)
diag(V)
## [1] 2.674870e+05 5.314489e-02
sqrt(diag(V))
## [1] 517.1914636   0.2305318

So lme4 is detecting that the surface is much flatter
in one direction than the other (the Wald std dev is about 2500
times greater for the first parameter (the RE std. dev) than for
the second (the intercept).

I have been working on the profiling stuff a bit in the development
version, so your results may not be identical, but mine seem to show
that only with Nelder-Mead (which is a bit funny since it is otherwise
often the worst optimizer out of the bunch) do we successfully profile
the RE standard dev.  I think I need to work on the robustness of
the profiler a little bit more.  The good news is that we do manage
to fit the profile, we see what we expect -- the sqrt(zeta) line is
very flat near the origin (corresponding to low curvature/large
uncertainty),
but steepens as we get away from it so that the actual profile
confidence intervals are not too big.

profList <- lapply(list(default=g0.bobyqa,
                   bobyqa=g0.bobyqa,
                   NM=g0.NM,
                   nlminb=g0.nlminb,
                   LBFGSB=g0.LBFGSB),profile,dev.tol=1e-3,
                   delta=0.1)
profdfList <-   Map(function(x,n) {
                          data.frame(as.data.frame(x),opt=n)
                       },
                       profList,names(profList))
profdf <- do.call(rbind,profdfList)
library("ggplot2"); theme_set(theme_bw())
ggplot(profdf,aes(.focal,abs(.zeta),colour=opt))+
         geom_point()+geom_line()+facet_grid(opt~.par,scale="free")+
             geom_hline(yintercept=1.96,col="gray")


On 15-03-12 01:56 PM, Sophia Kyriakou wrote:
> Hello,
> 
> I run a simulation study fitting a GLMM random intercept model and
> I get warning messages. I tried various optimizers but they all
> give warning messages. Please find below one of the simulated
> samples. I am using the lme4 package version 1.1.7 on R 3.1.3. Do I
> ignore these warning messages or is there a way of dealing with
> them?
> 
> Thanks in advance.
> 
library(lme4)
library(optimx)
m <- 6
q <- 20
beta  <- 2
sigma2 <- 0.1
set.seed(206)
alpha <- rnorm(q, 0, sqrt(sigma2))
Y <- rbinom(q,m,plogis(alpha+beta))
cl <- seq.int(q)
tot <- rep(m,q)
dat <- data.frame(y = Y, tot = tot, cl = cl)
g0.default <- glmer(cbind(y, tot - y) ~ 1 + (1 | cl), data = dat,family =
  binomial(),nAGQ = 20)
g0.bobyqa <- glmer(cbind(y, tot - y) ~ 1 + (1 | cl), data = dat,family =
  binomial(),nAGQ = 20,control=glmerControl(optimizer="bobyqa"))
g0.NM <- update(g0.bobyqa,control=glmerControl(optimizer="Nelder_Mead"))
g0.nlminb <-
 update(g0.bobyqa,control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
g0.LBFGSB <-
update(g0.bobyqa,control=glmerControl(optimizer="optimx",optCtrl=list(method="L-BFGS-B")))
> 
> library(nloptr) ## from https://github.com/lme4/lme4/issues/98: 
> defaultControl <- 
> list(algorithm="NLOPT_LN_BOBYQA",xtol_rel=1e-6,maxeval=1e5) 
> nloptwrap2 <- function(fn,par,lower,upper,control=list(),...) { for
> (n in names(defaultControl)) if (is.null(control[[n]]))
> control[[n]] <- defaultControl[[n]] res <-
> nloptr(x0=par,eval_f=fn,lb=lower,ub=upper,opts=control,...) 
> with(res,list(par=solution, fval=objective, feval=iterations, 
> conv=if (status>0) 0 else status, message=message)) } g0.bobyqa2 <-
> update(g0.bobyqa,control=glmerControl(optimizer=nloptwrap2)) g0.NM2
> <- 
> update(g0.bobyqa,control=glmerControl(optimizer=nloptwrap2,optCtrl=list(algorithm="NLOPT_LN_NELDERMEAD")))
>
> 
> 
> dd <- g0.bobyqa at optinfo$derivs 
> with(dd,max(abs(solve(Hessian,gradient)))<2e-3)
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVAd6xAAoJEOCV5YRblxUHT5sIAMtbaxL374r20+MXuYg5XNwa
RH27D59/cWvBX/UmEZD8716AR7kTxJhyLn2JEE9NkI+5qwlpoMyCSU/fL5eWzhx1
wKGM895ZVnbdsw4kbSoim1uPerwx4IJsmV8Ktxy7LP5nU5aeTbMAo9xJvy7/yGht
LmFOlRrZYylhGDpztUZIpbK+sJWeu7OdAnJWXWgzXgSexKDyPhaUnq6QQpUOXn9J
lmcJsARl6Aq6kzbrBGNICZUZB7wneWkgnhpVbKndkqgKwr5uNPzLFLMKOR0cAen2
dgi5VXEHZYm+oILr+NseJzboXdJSSTpyFQzOpGYZyWIhjr6FAJ3S/fRwen6h7Ws=
=JNrE
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Thu Mar 12 19:55:06 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Mar 2015 14:55:06 -0400
Subject: [R-sig-ME] Contrast in lme4
In-Reply-To: <CAO7JsnRhe4T5=OJAc-7Q292rxrYHdhVGLH5=-XkA=pGVKuguJA@mail.gmail.com>
References: <CABGg3O6WM_8t9sOv7YcDzEFQ_SkfFUS7iTebZTex+qeY8h=TmA@mail.gmail.com>
	<CAO7JsnRhe4T5=OJAc-7Q292rxrYHdhVGLH5=-XkA=pGVKuguJA@mail.gmail.com>
Message-ID: <5501E10A.4020404@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  "How do I set up custom contrasts?" is (1) not specific to mixed
models (so not really appropriate for this list -- maybe try r-help or
Stack Overflow); (2) rather tricky in R (it may be difficult in all
statistics packages/languages, I don't know); and (3) sufficiently
detailed that the information you give below isn't really quite
sufficient.  A reproducible example will help when you post your
question somewhere else.  You can use the "contrast" package, or the
"multicomp" package, to test contrasts.  As far as how the contrasts
are set up, there's a reasonable description in Crawley's _Data
Analysis in S-PLUS_ book, or see

http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm
http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf


On 15-03-12 01:52 PM, Douglas Bates wrote:
> It is better to send questions like this to the 
> R-SIG-Mixed-Models at R-project.org mailing list, which I am cc:ing on
> this reply.
> 
> On Thu, Mar 12, 2015 at 3:09 AM adeela uaf <adeela.uaf at gmail.com>
> wrote:
> 
>> Dear Douglas Bates, How to perform contrast analysis for fixed
>> effects in lme4 package. My data is same as sleepstudy data with
>> an additional cloumn comprising  12 treatments also. The
>> structure of the treatmnets is such that: 1) 1 treatment is
>> control 2) 4 treatments are bio-agents. 3) 3 treatments are
>> botanical. 4) 2 are bi prodcts 5) 2 are fungisides I want to make
>> comparison among the groups which differ significantly after 
>> Model<-lmer(Disease~Trt+Date+Trt*Date+(1|Subject),data=YR) Best
>> Regars, Adeela
>> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVAeEKAAoJEOCV5YRblxUHVKoH+QHgr4Z9sH8TlZsawhbZCn6B
+k5VyPyffaY0SavglCGl1zC9Q4aBipTp8+cGiwKyf6HxXsj6X65Q1NCYDptKArr5
35bHEJ49ITAEX4ur8qw0KRVZCE5BwsCgB1rAW3Pg/ltMz2bG1VpAe1TsOQy+NNkz
ZNfm8OaJurjy1ScAj9HCDvbLVhFyuD72tACI8hrWwVBrACRKdad4xDtc0BQyhm+Q
sadLClqK7/diTX9KHmS4LhMibHfVgRzWgTN7MesKj8y6d3uX/dX2WQtmViXY2RXP
C8jzeF/evoofgAxPE6ivGTWku0frG+1qAicNNcYznGi+SuLmH0cvyW1asy9TSgc=
=TVUv
-----END PGP SIGNATURE-----


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Mar 12 20:14:42 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 12 Mar 2015 20:14:42 +0100
Subject: [R-sig-ME] Contrast in lme4
In-Reply-To: <5501E10A.4020404@gmail.com>
References: <CABGg3O6WM_8t9sOv7YcDzEFQ_SkfFUS7iTebZTex+qeY8h=TmA@mail.gmail.com>
	<CAO7JsnRhe4T5=OJAc-7Q292rxrYHdhVGLH5=-XkA=pGVKuguJA@mail.gmail.com>
	<5501E10A.4020404@gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0699E413@UM-MAIL4112.unimaas.nl>

I think these may be helpful to the OP:

http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm

http://www.ats.ucla.edu/stat/r/faq/testing_contrasts.htm

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Ben Bolker
> Sent: Thursday, March 12, 2015 19:55
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Contrast in lme4
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
>   "How do I set up custom contrasts?" is (1) not specific to mixed
> models (so not really appropriate for this list -- maybe try r-help or
> Stack Overflow); (2) rather tricky in R (it may be difficult in all
> statistics packages/languages, I don't know); and (3) sufficiently
> detailed that the information you give below isn't really quite
> sufficient.  A reproducible example will help when you post your
> question somewhere else.  You can use the "contrast" package, or the
> "multicomp" package, to test contrasts.  As far as how the contrasts
> are set up, there's a reasonable description in Crawley's _Data
> Analysis in S-PLUS_ book, or see
> 
> http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm
> http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf
> 
> 
> On 15-03-12 01:52 PM, Douglas Bates wrote:
> > It is better to send questions like this to the
> > R-SIG-Mixed-Models at R-project.org mailing list, which I am cc:ing on
> > this reply.
> >
> > On Thu, Mar 12, 2015 at 3:09 AM adeela uaf <adeela.uaf at gmail.com>
> > wrote:
> >
> >> Dear Douglas Bates, How to perform contrast analysis for fixed
> >> effects in lme4 package. My data is same as sleepstudy data with
> >> an additional cloumn comprising  12 treatments also. The
> >> structure of the treatmnets is such that: 1) 1 treatment is
> >> control 2) 4 treatments are bio-agents. 3) 3 treatments are
> >> botanical. 4) 2 are bi prodcts 5) 2 are fungisides I want to make
> >> comparison among the groups which differ significantly after
> >> Model<-lmer(Disease~Trt+Date+Trt*Date+(1|Subject),data=YR) Best
> >> Regars, Adeela
> >>
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
> 
> iQEcBAEBAgAGBQJVAeEKAAoJEOCV5YRblxUHVKoH+QHgr4Z9sH8TlZsawhbZCn6B
> +k5VyPyffaY0SavglCGl1zC9Q4aBipTp8+cGiwKyf6HxXsj6X65Q1NCYDptKArr5
> 35bHEJ49ITAEX4ur8qw0KRVZCE5BwsCgB1rAW3Pg/ltMz2bG1VpAe1TsOQy+NNkz
> ZNfm8OaJurjy1ScAj9HCDvbLVhFyuD72tACI8hrWwVBrACRKdad4xDtc0BQyhm+Q
> sadLClqK7/diTX9KHmS4LhMibHfVgRzWgTN7MesKj8y6d3uX/dX2WQtmViXY2RXP
> C8jzeF/evoofgAxPE6ivGTWku0frG+1qAicNNcYznGi+SuLmH0cvyW1asy9TSgc=
> =TVUv
> -----END PGP SIGNATURE-----
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From sophia.kyriakou17 at gmail.com  Thu Mar 12 21:00:49 2015
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Thu, 12 Mar 2015 22:00:49 +0200
Subject: [R-sig-ME] glmer warning messages using version 1.1.7
Message-ID: <CAO4gA+p1q1Ts=tDEE6jSC+zRBiRg7fKSCh7CROr8EB7FqhCuGw@mail.gmail.com>

The bad news is that when I run the profList function I get an error
message instead

> profList <- lapply(list(default=g0.bobyqa,
+                    bobyqa=g0.bobyqa,
+                    NM=g0.NM,
+                    nlminb=g0.nlminb,
+                    LBFGSB=g0.LBFGSB),profile,dev.tol=1e-3,
+                    delta=0.1)
There were 14 warnings (use warnings() to see them)
Error in diag(vcov(object, use.hessian = use.hessian)) :
  error in evaluating the argument 'x' in selecting a method for function
'diag': Error in solve.default(h) : system is computationally singular:
reciprocal condition number = 3.04588e-17

warnings()
Warning messages:
1: In zeta(shiftpar, start = opt[seqpar1][-w]) :
  slightly lower deviances (diff=-3.55271e-15) detected
2: In nextpar(mat, cc, i, delta, lowcut, upcut) :
  Last two rows have identical or NA .zeta values: using minstep
3: In nextpar(mat, cc, i, delta, lowcut, upcut) :
  Last two rows have identical or NA .zeta values: using minstep
4: In profile.merMod(X[[1L]], ...) : non-monotonic profile
5: In zeta(shiftpar, start = opt[seqpar1][-w]) :
  slightly lower deviances (diff=-3.55271e-15) detected
6: In nextpar(mat, cc, i, delta, lowcut, upcut) :
  Last two rows have identical or NA .zeta values: using minstep
7: In nextpar(mat, cc, i, delta, lowcut, upcut) :
  Last two rows have identical or NA .zeta values: using minstep
8: In profile.merMod(X[[2L]], ...) : non-monotonic profile
9: In nextpar(mat, cc, i, delta, lowcut, upcut) :
  Last two rows have identical or NA .zeta values: using minstep
10: In profile.merMod(X[[3L]], ...) : non-monotonic profile
11: In zetafun(np, ns) : slightly lower deviances (diff=-3.55271e-15)
detected
12: In zetafun(np, ns) : slightly lower deviances (diff=-3.55271e-15)
detected
13: In nextpar(mat, cc, i, delta, lowcut, upcut) :
  Last two rows have identical or NA .zeta values: using minstep
14: In profile.merMod(X[[4L]], ...) : non-monotonic profile


 Many thanks,
Sophia

Message: 5
> Date: Thu, 12 Mar 2015 14:45:05 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] glmer warning messages using version 1.1.7
> Message-ID: <5501DEB1.30100 at gmail.com>
> Content-Type: text/plain; charset=windows-1252
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
>    I think these are ignorable.  If you want to turn them off,
> check out ?glmerControl.
>
> Here's what I looked at:
>
> H <- g0.bobyqa at optinfo$derivs$Hessian
> V <- solve(H)
> diag(V)
> ## [1] 2.674870e+05 5.314489e-02
> sqrt(diag(V))
> ## [1] 517.1914636   0.2305318
>
> So lme4 is detecting that the surface is much flatter
> in one direction than the other (the Wald std dev is about 2500
> times greater for the first parameter (the RE std. dev) than for
> the second (the intercept).
>
> I have been working on the profiling stuff a bit in the development
> version, so your results may not be identical, but mine seem to show
> that only with Nelder-Mead (which is a bit funny since it is otherwise
> often the worst optimizer out of the bunch) do we successfully profile
> the RE standard dev.  I think I need to work on the robustness of
> the profiler a little bit more.  The good news is that we do manage
> to fit the profile, we see what we expect -- the sqrt(zeta) line is
> very flat near the origin (corresponding to low curvature/large
> uncertainty),
> but steepens as we get away from it so that the actual profile
> confidence intervals are not too big.
>
> profList <- lapply(list(default=g0.bobyqa,
>                    bobyqa=g0.bobyqa,
>                    NM=g0.NM,
>                    nlminb=g0.nlminb,
>                    LBFGSB=g0.LBFGSB),profile,dev.tol=1e-3,
>                    delta=0.1)
> profdfList <-   Map(function(x,n) {
>                           data.frame(as.data.frame(x),opt=n)
>                        },
>                        profList,names(profList))
> profdf <- do.call(rbind,profdfList)
> library("ggplot2"); theme_set(theme_bw())
> ggplot(profdf,aes(.focal,abs(.zeta),colour=opt))+
>          geom_point()+geom_line()+facet_grid(opt~.par,scale="free")+
>              geom_hline(yintercept=1.96,col="gray")
>
>
> On 15-03-12 01:56 PM, Sophia Kyriakou wrote:
> > Hello,
> >
> > I run a simulation study fitting a GLMM random intercept model and
> > I get warning messages. I tried various optimizers but they all
> > give warning messages. Please find below one of the simulated
> > samples. I am using the lme4 package version 1.1.7 on R 3.1.3. Do I
> > ignore these warning messages or is there a way of dealing with
> > them?
> >
> > Thanks in advance.
> >
> library(lme4)
> library(optimx)
> m <- 6
> q <- 20
> beta  <- 2
> sigma2 <- 0.1
> set.seed(206)
> alpha <- rnorm(q, 0, sqrt(sigma2))
> Y <- rbinom(q,m,plogis(alpha+beta))
> cl <- seq.int(q)
> tot <- rep(m,q)
> dat <- data.frame(y = Y, tot = tot, cl = cl)
> g0.default <- glmer(cbind(y, tot - y) ~ 1 + (1 | cl), data = dat,family =
>   binomial(),nAGQ = 20)
> g0.bobyqa <- glmer(cbind(y, tot - y) ~ 1 + (1 | cl), data = dat,family =
>   binomial(),nAGQ = 20,control=glmerControl(optimizer="bobyqa"))
> g0.NM <- update(g0.bobyqa,control=glmerControl(optimizer="Nelder_Mead"))
> g0.nlminb <-
>
>  update(g0.bobyqa,control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
> g0.LBFGSB <-
>
> update(g0.bobyqa,control=glmerControl(optimizer="optimx",optCtrl=list(method="L-BFGS-B")))
> >
> > library(nloptr) ## from https://github.com/lme4/lme4/issues/98:
> > defaultControl <-
> > list(algorithm="NLOPT_LN_BOBYQA",xtol_rel=1e-6,maxeval=1e5)
> > nloptwrap2 <- function(fn,par,lower,upper,control=list(),...) { for
> > (n in names(defaultControl)) if (is.null(control[[n]]))
> > control[[n]] <- defaultControl[[n]] res <-
> > nloptr(x0=par,eval_f=fn,lb=lower,ub=upper,opts=control,...)
> > with(res,list(par=solution, fval=objective, feval=iterations,
> > conv=if (status>0) 0 else status, message=message)) } g0.bobyqa2 <-
> > update(g0.bobyqa,control=glmerControl(optimizer=nloptwrap2)) g0.NM2
> > <-
> >
> update(g0.bobyqa,control=glmerControl(optimizer=nloptwrap2,optCtrl=list(algorithm="NLOPT_LN_NELDERMEAD")))
> >
> >
> >
> > dd <- g0.bobyqa at optinfo$derivs
> > with(dd,max(abs(solve(Hessian,gradient)))<2e-3)
>
>

	[[alternative HTML version deleted]]


From vjd4 at nyu.edu  Fri Mar 13 03:12:44 2015
From: vjd4 at nyu.edu (Vincent Dorie)
Date: Thu, 12 Mar 2015 22:12:44 -0400
Subject: [R-sig-ME] Error fitting reduced model in bglmer for LRT
In-Reply-To: <CAGb-hRpQFD7pAgrYzS4gT0530kkH1Wb52rEeP_3PnuS0j1rTYQ@mail.gmail.com>
References: <CAGb-hRpQFD7pAgrYzS4gT0530kkH1Wb52rEeP_3PnuS0j1rTYQ@mail.gmail.com>
Message-ID: <058E6DB9-2664-4000-A02E-510BBCA91E86@nyu.edu>

Apparently, something stripped symbols from the code in my email. Replace anything that says " at " with an 'at' sign.

As to tests, there is a section for that on http://glmm.wikidot.com/faq <http://glmm.wikidot.com/faq>. MCMCglmm should solve the separability issues in the data and make it straightforward to derive inferences.

> On Mar 12, 2015, at 7:39 PM, Josie Galbraith <josie.galbraith at gmail.com> wrote:
> 
> Thanks Vince.
> So should I just use the Wald-Z output instead then? Or another method of inference? Any ideas which is best in this situation?
> 
> The code for the temp fix didn't work for me (see below).  But that may not be important if I use another method of inference...
> 
> Cheers,
> Josie
> 
> > assignInNamespace("toString.bmerTDist", function(x, digits = getOption("digits"), ...) {
> +   scaleString <- ""
> +   scale <- crossprod(solve(x at R.scale.inv))
> Error: unexpected symbol in:
> "  scaleString <- ""
>   scale <- crossprod(solve(x at"
> >   
> >   if (nrow(scale) > 2) {
> +     scaleString <- paste("scale = c(", toString(round(scale[1:4], digits)), ", ...)", sep = "")
> +   } else if (nrow(scale) == 2) {
> +     scaleString <- paste("scale = c(", toString(round(scale[1:4], digits)), ")", sep = "")
> +   } else {
> +     scaleString <- paste("scale = ", toString(round(scale[1], digits)), sep = "")
> +   }
> Error in if (nrow(scale) > 2) { : argument is of length zero
> >   
> >   paste("t(df = ", x at df, ", ", scaleString,
> Error: unexpected symbol in "  paste("t(df = ", x at"
> >         ", common.scale = ", x at commonScale,
> Error: unexpected ',' in "        ", common.scale = ","
> >         ")", sep="")
> Error: unexpected ',' in "        ")","
> > }, "blme")
> Error: unexpected '}' in "}"
> > 
> 
> 
> 
> 
> 
> Date: Tue, 10 Mar 2015 13:23:22 -0400
> From: Vincent Dorie <vjd4 at nyu.edu <mailto:vjd4 at nyu.edu>>
> To: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Error fitting reduced model in bglmer for LRT
> Message-ID: <9FBE19D0-EA83-4F5B-8333-0C52C18390D9 at nyu.edu <mailto:9FBE19D0-EA83-4F5B-8333-0C52C18390D9 at nyu.edu>>
> Content-Type: text/plain; charset=utf-8
> 
> I don't know what exactly anova() does for glmms, but I wouldn't recommend a likelihood ratio test to compare posterior modes unless you can be certain the data swamp the prior.
> 
> The error you experienced is a copy/paste error on my part. You can run the code below to fix it temporarily, until I can get a new release on CRAN.
> 
> assignInNamespace("toString.bmerTDist", function(x, digits = getOption("digits"), ...) {
>   scaleString <- ""
>   scale <- crossprod(solve(x at R.scale.inv))
> 
>   if (nrow(scale) > 2) {
>     scaleString <- paste("scale = c(", toString(round(scale[1:4], digits)), ", ...)", sep = "")
>   } else if (nrow(scale) == 2) {
>     scaleString <- paste("scale = c(", toString(round(scale[1:4], digits)), ")", sep = "")
>   } else {
>     scaleString <- paste("scale = ", toString(round(scale[1], digits)), sep = "")
>   }
> 
>   paste("t(df = ", x at df, ", ", scaleString,
>         ", common.scale = ", x at commonScale,
>         ")", sep="")
> }, "blme")
> 
> Vince
> 
> > On Mar 9, 2015, at 11:47 PM, Josie Galbraith <josie.galbraith at gmail.com <mailto:josie.galbraith at gmail.com>> wrote:
> >
> > Hi all,
> >
> > In following on from this post
> > <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023191.html <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023191.html>>,
> > regarding using blme and fixed effect priors to address issues of complete
> > separation in my data, I've come up against a problem trying to fit reduced
> > models for testing the model terms using likelihood ratio tests (LRT).
> >
> > Firstly, can I use LRTs (anova()) for testing the fixed effects of bglmer
> > models, as I would for glmer models?
> >
> > If yes, then I need help understanding why I'm getting the following error
> > fitting a reduced bglmer model:
> > "Error in if (nrow(cov) == 2) { : argument is of length zero"
> >
> > This is my full model:
> > SE.les.mod = bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df, family
> > = binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> >
> > I can fit a model without the interaction term ok:
> > SE.les.add = bglmer (LESION ~ FOOD+SEASON +(1|SITE), data = SEYE.df, family
> > = binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> >
> > But I get the error message with both of the single fixed effects models:
> > SE.les.FOOD = bglmer (LESION ~ SEASON +(1|SITE), data = SEYE.df, family =
> > binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> > SE.les.SEAS = bglmer (LESION ~ FOOD +(1|SITE), data = SEYE.df, family =
> > binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> >
> > Thanks very much,
> > Josie
> >
> >
> >
> > --
> > *Josie Galbraith* MSc (hons)
> >
> > PhD candidate
> > *University of Auckland *
> > Joint Graduate School in Biodiversity and Biosecurity ? School of
> > Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
> > P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com <mailto:josie.galbraith at gmail.com>* ? W: * UoA Web
> > Profile <https://unidirectory.auckland.ac.nz/profile/jgal026 <https://unidirectory.auckland.ac.nz/profile/jgal026>> and
> > *www.birdfeedingnz.weebly.com/* <http://www.birdfeedingnz.weebly.com/*> <http://birdfeedingnz.weebly.com/ <http://birdfeedingnz.weebly.com/>>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
> -- 
> Josie Galbraith MSc (hons)
> 
> PhD candidate
> University of Auckland 
> Joint Graduate School in Biodiversity and Biosecurity ? School of Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142 ? P: 09-373 7599 ext. 83132 ? E: josie.galbraith at gmail.com <mailto:josie.galbraith at gmail.com> ? W:  UoA Web Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and www.birdfeedingnz.weebly.com/ <http://birdfeedingnz.weebly.com/>
> 
> 


	[[alternative HTML version deleted]]


From josie.galbraith at gmail.com  Fri Mar 13 00:39:00 2015
From: josie.galbraith at gmail.com (Josie Galbraith)
Date: Fri, 13 Mar 2015 12:39:00 +1300
Subject: [R-sig-ME] Error fitting reduced model in bglmer for LRT
Message-ID: <CAGb-hRpQFD7pAgrYzS4gT0530kkH1Wb52rEeP_3PnuS0j1rTYQ@mail.gmail.com>

Thanks Vince.
So should I just use the Wald-Z output instead then? Or another method of
inference? Any ideas which is best in this situation?

The code for the temp fix didn't work for me (see below).  But that may not
be important if I use another method of inference...

Cheers,
Josie

> assignInNamespace("toString.bmerTDist", function(x, digits =
getOption("digits"), ...) {
+   scaleString <- ""
+   scale <- crossprod(solve(x at R.scale.inv))
Error: unexpected symbol in:
"  scaleString <- ""
  scale <- crossprod(solve(x at"
>
>   if (nrow(scale) > 2) {
+     scaleString <- paste("scale = c(", toString(round(scale[1:4],
digits)), ", ...)", sep = "")
+   } else if (nrow(scale) == 2) {
+     scaleString <- paste("scale = c(", toString(round(scale[1:4],
digits)), ")", sep = "")
+   } else {
+     scaleString <- paste("scale = ", toString(round(scale[1], digits)),
sep = "")
+   }
Error in if (nrow(scale) > 2) { : argument is of length zero
>
>   paste("t(df = ", x at df, ", ", scaleString,
Error: unexpected symbol in "  paste("t(df = ", x at"
>         ", common.scale = ", x at commonScale,
Error: unexpected ',' in "        ", common.scale = ","
>         ")", sep="")
Error: unexpected ',' in "        ")","
> }, "blme")
Error: unexpected '}' in "}"
>





Date: Tue, 10 Mar 2015 13:23:22 -0400
> From: Vincent Dorie <vjd4 at nyu.edu>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Error fitting reduced model in bglmer for LRT
> Message-ID: <9FBE19D0-EA83-4F5B-8333-0C52C18390D9 at nyu.edu>
> Content-Type: text/plain; charset=utf-8
>
> I don't know what exactly anova() does for glmms, but I wouldn't recommend
> a likelihood ratio test to compare posterior modes unless you can be
> certain the data swamp the prior.
>
> The error you experienced is a copy/paste error on my part. You can run
> the code below to fix it temporarily, until I can get a new release on CRAN.
>
> assignInNamespace("toString.bmerTDist", function(x, digits =
> getOption("digits"), ...) {
>   scaleString <- ""
>   scale <- crossprod(solve(x at R.scale.inv))
>
>   if (nrow(scale) > 2) {
>     scaleString <- paste("scale = c(", toString(round(scale[1:4],
> digits)), ", ...)", sep = "")
>   } else if (nrow(scale) == 2) {
>     scaleString <- paste("scale = c(", toString(round(scale[1:4],
> digits)), ")", sep = "")
>   } else {
>     scaleString <- paste("scale = ", toString(round(scale[1], digits)),
> sep = "")
>   }
>
>   paste("t(df = ", x at df, ", ", scaleString,
>         ", common.scale = ", x at commonScale,
>         ")", sep="")
> }, "blme")
>
> Vince
>
> > On Mar 9, 2015, at 11:47 PM, Josie Galbraith <josie.galbraith at gmail.com>
> wrote:
> >
> > Hi all,
> >
> > In following on from this post
> > <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023191.html>,
> > regarding using blme and fixed effect priors to address issues of
> complete
> > separation in my data, I've come up against a problem trying to fit
> reduced
> > models for testing the model terms using likelihood ratio tests (LRT).
> >
> > Firstly, can I use LRTs (anova()) for testing the fixed effects of bglmer
> > models, as I would for glmer models?
> >
> > If yes, then I need help understanding why I'm getting the following
> error
> > fitting a reduced bglmer model:
> > "Error in if (nrow(cov) == 2) { : argument is of length zero"
> >
> > This is my full model:
> > SE.les.mod = bglmer (LESION ~ FOOD*SEASON +(1|SITE), data = SEYE.df,
> family
> > = binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> >
> > I can fit a model without the interaction term ok:
> > SE.les.add = bglmer (LESION ~ FOOD+SEASON +(1|SITE), data = SEYE.df,
> family
> > = binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> >
> > But I get the error message with both of the single fixed effects models:
> > SE.les.FOOD = bglmer (LESION ~ SEASON +(1|SITE), data = SEYE.df, family =
> > binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> > SE.les.SEAS = bglmer (LESION ~ FOOD +(1|SITE), data = SEYE.df, family =
> > binomial, fixef.prior = t(1,2.5), cov.prior = NULL)
> >
> > Thanks very much,
> > Josie
> >
> >
> >
> > --
> > *Josie Galbraith* MSc (hons)
> >
> > PhD candidate
> > *University of Auckland *
> > Joint Graduate School in Biodiversity and Biosecurity ? School of
> > Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142*
> ?
> > P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA
> Web
> > Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
> > *www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
*Josie Galbraith* MSc (hons)

PhD candidate
*University of Auckland *
Joint Graduate School in Biodiversity and Biosecurity ? School of
Biological Sciences ? Tamaki Campus ? Private Bag 92019 ? Auckland 1142* ?
P:* 09-373 7599 ext. 83132* ? E:* josie.galbraith at gmail.com* ? W: * UoA Web
Profile <https://unidirectory.auckland.ac.nz/profile/jgal026> and
*www.birdfeedingnz.weebly.com/* <http://birdfeedingnz.weebly.com/>

	[[alternative HTML version deleted]]


From bran.chri at gmail.com  Fri Mar 13 18:04:58 2015
From: bran.chri at gmail.com (=?UTF-8?Q?Brandst=C3=A4tter_Christian?=)
Date: Fri, 13 Mar 2015 18:04:58 +0100
Subject: [R-sig-ME] Cyclic Block Design
Message-ID: <CAALi0vLEO=jGKEEeNdbo830oCwrASs=zBT2+u8=jdHML25McAA@mail.gmail.com>

Dear list,

I came upon a question of a linear block design for reviewing an article.
It is less of an R-question, but I basically would not know where else to
ask.

The experimental design looked as follows:
Material of different compostion (9 different combinations) was incubated
in a laboratory under 3x3 different conditions (each 3 different water and
temperature levels).
According to the authors, this would lead to 9 treatments (v), 9 blocks
(b), a block size of 3 (k) and # of treatments appearing in the design as 3
(r) for their cyclic incomplete block design. Then they assume, 27
experimental vessels would have been enough to answer their
question.Failing to apply ordinary multivariate linear models they used
MARS models for predicting some measured time series data.

My question would be, is this a) a valid/ experimental (block) design and
b) based on that, a valid statistical regression approach?

Thanks in advance.
Christian

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Mar 13 23:05:07 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Mar 2015 22:05:07 +0000 (UTC)
Subject: [R-sig-ME] Cyclic Block Design
References: <CAALi0vLEO=jGKEEeNdbo830oCwrASs=zBT2+u8=jdHML25McAA@mail.gmail.com>
Message-ID: <loom.20150313T230358-606@post.gmane.org>

Brandst?tter Christian <bran.chri at ...> writes:

> 
> Dear list,
> 
> I came upon a question of a linear block design for reviewing an article.
> It is less of an R-question, but I basically would not know where else to
> ask.
> 
> The experimental design looked as follows:

 [snip ... Gmane doesn't like me to quote a lot ...]

> 
> My question would be, is this a) a valid/ experimental (block) design and
> b) based on that, a valid statistical regression approach?

  This is definitely not an appropriate question for this list; I'd
recommend CrossValidated <http://stats.stackexchange.com> ...

  Ben Bolker


From bbolker at gmail.com  Fri Mar 13 23:30:41 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Mar 2015 22:30:41 +0000 (UTC)
Subject: [R-sig-ME] glmer warning messages using version 1.1.7
References: <CAO4gA+p1q1Ts=tDEE6jSC+zRBiRg7fKSCh7CROr8EB7FqhCuGw@mail.gmail.com>
Message-ID: <loom.20150313T232925-908@post.gmane.org>

Sophia Kyriakou <sophia.kyriakou17 at ...> writes:

> 
> The bad news is that when I run the profList function I get an error
> message instead ...
> 

  I'm snipping most of the context from this thread, but just coming
back here to say I've posted a fairly thorough analysis of this issue
(along with pictures) at

http://rpubs.com/bbolker/proftest

  The answer there about the original question, "is it OK to 
ignore thse warnings?", is

tl;dr; yes. These are singular fits (due to a small number of levels of the
grouping variable), but that?s not actually the proximal problem. It turns
out that the second derivative of the random-effects std dev parameter is
quite small near zero (the MLE), making the estimated uncertainty in this
parameter very large and triggering warnings about scaling, etc etc, from
lme4. Plotting the profiles demonstrates (for the most part) that the level
of uncertainty is actually reasonable (upper 95% confidence interval around
2), just not well characterized by the local curvature at the MLE.

From asafw.at.wharton at gmail.com  Wed Mar 11 04:24:47 2015
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Tue, 10 Mar 2015 23:24:47 -0400
Subject: [R-sig-ME] lmer fails when too many observations
In-Reply-To: <CAO7JsnQWM24Uua9bwvV8BS8unjQUJLqA4gd81TAbggzPtVTD2w@mail.gmail.com>
References: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>
	<CAO7JsnQWM24Uua9bwvV8BS8unjQUJLqA4gd81TAbggzPtVTD2w@mail.gmail.com>
Message-ID: <CAGG0PdD=_BO58aUDCJhV=pF3pm68BY=+rvx=SaOenmR_jREMkQ@mail.gmail.com>

Dear Thierry and Douglas,

Thank you very much for your responses; It seems like, as Douglas remarked,
the error message I got was not a result of too many observations; I tried
a similar example on a different computer, and it worked fine (as a matter
of fact, I tried it on the same computer again and I it also worked, only
gave a warning message now rather than an error).

I regret sending the original email and sorry for the false alarm!

Here is the example, in any case:

  ## generate data from a two-way random-effects model with balanced design
##


R <- 100

C <- 100

sig <- 5 # sd, not variance

mu <- 0

theta.A <- 1/sqrt(4*C) # variance order of sigma^2/(# of col's) for
shrinkage to take place

theta.B <- 1/sqrt(4*R)


K <- matrix( 10, nrow=R, ncol=C )

level.A.all <- as.factor( rep(t(row(K)),t(K)) )  #same as factor( rep(1:R,
apply(K,1,sum)) )

level.B.all <- as.factor( rep( t(col(K)),t(K) ) )  #same as factor( unlist(
apply(K,1,function(t) rep( 1:C, t )) ) )

#cbind(level.A.all, level.B.all)

#table(level.A.all,level.B.all) # same as K


effects.A <- rnorm(R, mean=0, sd= sig * theta.A)

effects.B <- rnorm(C, mean=0, sd= sig * theta.B)

eta.all <- mu + effects.A[level.A.all] + effects.B[level.B.all] # cell
means for individual obs model


eps.all <- rnorm( sum(K), mean= 0, sd = sig )

y.all <- eta.all + eps.all

#head(cbind(level.A.all,level.B.all,eta.all, y.all))


## estimation ##


# LS estimates

fm.LS <- lm(y.all~1+level.A.all+level.B.all)  # Least Squares

etahat.LS <- c(  t( tapply(fitted(fm.LS),list(level.A.all,level.B.all),mean)
)  )


  # EB Maximum-Likelihood

fm.EBML <- blmer( y.all ~ 1+(1|level.A.all)+(1|level.B.all), cov.prior =
NULL, resid.prior = point(value = sig, posterior.scale='sd'), REML=FALSE )

theta.EBML <- getME(fm.EBML,'theta')

etahat.EBML <- c(  t( tapply(fitted(fm.EBML),list(level.A.all,level.B.all),
mean) )  )


Thank you again,

Asaf

On 10 March 2015 at 12:40, Douglas Bates <bates at stat.wisc.edu> wrote:

> It is not clear that the error message you quote is a result of too many
> observations.
>
> As Thierry stated, it would help to have a small reproducible example.
>
> On Tue, Mar 10, 2015 at 9:24 AM Asaf Weinstein <asafw.at.wharton at gmail.com>
> wrote:
>
>> Dear lmer community,
>>
>> I am trying to run a simulation for a two-way random-effects model with
>> unbalanced design (ie, unequal number of observations per cell) and no
>> interaction.
>> It's especially important for me to be able to run the lmer/blmer
>> functions
>> when the number of (column and row) random effects is large, say 100, and
>> with possible replicates in each cell.
>> The problem is that lmer() works with the full vector of observations, as
>> opposed to working with the cell averages (which is a sufficient
>> statistic), and the methods fails pretty quickly when there are replicates
>> (because the response vector is too big, I suppose). I get the following
>> error:
>>
>> *Error in get("checkConv", lme4Env)(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  : *
>> *  (converted from warning) Model failed to converge with max|grad| =
>> 0.00244385 (tol = 0.002)*
>>
>> Just to give an example: suppose there are R=100 row effects, C=100 column
>> effects, and 5 replicates in each cell. The vector of individual
>> observations is of length 100^5 (lmer fails), while the vector of cell
>> averages is of length 100^2 (a size which causes no problem for lmer).
>> My question is whether there is a way to tell lmer() to work with the
>> sufficient statistic (of course, the conditional covariance is no longer
>> c*Identity, a fact which is used in the implementation of lmer (according
>> to documentation) ).
>>
>> Thank you very much and I hope I was clear!
>>
>> Asaf
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From ashley.asmus at gmail.com  Fri Mar 13 16:39:46 2015
From: ashley.asmus at gmail.com (Ashley Asmus)
Date: Fri, 13 Mar 2015 10:39:46 -0500
Subject: [R-sig-ME] Cook's distance: glmmADMB ZIP / influence.ME not
	compatible?
Message-ID: <CAPN4cTjM0142+U9R3RsWJwakjDDc9LD4wW57AG6nNhK9Ah94OQ@mail.gmail.com>

Dear r-sig-ME,

I am working with a small (zero-inflated) dataset of counts. The design is
repeated-measures, with several measures at each time point made in
experimental blocks. I have fit the model with glmmADMB using the
zero-inflated poisson options:

zip<-glmmadmb(wasp~ treatment  +  (1|sample.period) + (1|block), data=data,
family="poisson", zeroInflation=TRUE)

I am suspicious of 1-3 observations (the dataset is only 24 observations
big, so I promise to be cautious), and wish to evaluate their influence on
the model fit. Usually I work in lme4, then use the influence.ME package
and eliminate points based on cook's distance/leverage plots. Applying
influence.ME to the glmmADMB model produces a strange error message:

library(influence.ME)
infl <- influence(zip, obs = TRUE)
Error in eval(expr, envir, enclos) : object 'sample.period' not found

For some reason influence.ME is not finding my random factor
"sample.period." Are glmmADMB and influence.ME incompatible when
zero-inflation models are involved? If anyone knows of an alternative
approach I would love to hear about it.

Thank you very much!
Ashley Asmus
Ph.D. Student
The University of Texas at Arlington

	[[alternative HTML version deleted]]


From b.hsu at rug.nl  Thu Mar 12 12:27:28 2015
From: b.hsu at rug.nl (Hsu, B.)
Date: Thu, 12 Mar 2015 12:27:28 +0100
Subject: [R-sig-ME] Different results and warning messages from an identical
 glmer model at different times.
Message-ID: <CAL+Nd0Z-68jbRyg9q2=gDSMzNPxxTC6pAsGEj2UY1X1b=bgn5w@mail.gmail.com>

Hello,

About October and November last year, I used the glmer function in lme4 to
analyze some data of my experiment. I made two models to analyze the
probably of embryo development and hatching success of a species of birds,
as below:

glmer(developed ~ Treatment + Layingorder + Eggmass + Layingdate + (1|Nest
of egg laying) + (1|Nest of incubation), data, family="binomial")
glmer(hatching ~ Treatment + Layingorder + Eggmass + Layingdate + (1|Nest
of egg laying) + (1|Nest of incubation), data, family="binomial")

Both models worked fine at that moment.

However, now I am re-running these models but the results become different,
and the models give some warning messages which did not come out before. I
am sure that the data are not modified since last time and the code is
identical. I also checked the version of lme4, which is 1.1-7, and this
version seems to be published on 2014-7-19. Therefore, the version I am
using now is the same as last time. This makes me so puzzled why I got
different results and why I got warning messages that I did not have at
last time.

After some work of google and reading, I still could not find any clue to
solve this problem. Given the fact that I ran the same model twice with the
same version of lme4 but at different times, would it be due to any update
in lme4?

The warning messages I got are copied below:

for the model of embryo development:

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 4.04423 (tol = 0.001, component
3)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

for the model of hatching success:

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.970515 (tol = 0.001,
component 3)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

Thank you very much in advance,
Bin-Yan Hsu

-- 
Bin-Yan Hsu*, *PhD candidate,
Behavioural Biology,
Groningen Institute for Evolutionary Life Sciences,
Faculty of Mathematics and Natural Sciences,
University of Groningen

	[[alternative HTML version deleted]]


From mwiederm at mtu.edu  Fri Mar 13 16:47:16 2015
From: mwiederm at mtu.edu (Lea)
Date: Fri, 13 Mar 2015 15:47:16 +0000 (UTC)
Subject: [R-sig-ME] repeated measures on split plot design
Message-ID: <loom.20150313T154624-342@post.gmane.org>

Hi!

I am hoping for help with formulating the random structure for a data set
that fits a log normal distribution. The data was collected from a split
plot designed experiment (block: 4 replicates; v treatment: 3 levels; d
treatment: 2 levels). d is nested within v which is nested within block; 
total n = 4x3x2 = 24; my random effects are all categorical
hence using lme: random= ~1|block/veg, or lmer: (1|block/veg)

I think I am OK with that but I can not figure out how to include the
temporal repeated measure. This split plot setup was samples 5 times
(monthly during the summer) for 3 years-> 15 times and I am too interested
in the month and year effect. Ergo I do not want to average it out. Also
from plotting the data there is an increase of the response throughout the year.

Most everybody seems to be using the lme4 and not the nlme package these
days. Is there still someone who could help me to write the temporal
structure of the random term using the nlme package?

my fixed factors are: v*d*year*month (I am not interested in the block
effect) my fixed effects are all categorical

m1<-lme(response~v*d*year*month, random= ~1|block/veg  and what do I do with
the 15month in 3 years????

or 

m2<-lmer(response~v*d*year*month+(1|block/veg  and what do I do with the
15month in 3 years????

Thank you so much! 
Lea

p.s.: I hope I don't offend anybody by writing things out for both packages.


From thierry.onkelinx at inbo.be  Mon Mar 16 15:17:16 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 16 Mar 2015 15:17:16 +0100
Subject: [R-sig-ME] repeated measures on split plot design
In-Reply-To: <loom.20150313T154624-342@post.gmane.org>
References: <loom.20150313T154624-342@post.gmane.org>
Message-ID: <CAJuCY5x7tkhgt-7JtChX7MkqANZkEaXeFabNkd-tuW4wuj-pkA@mail.gmail.com>

Dear Lea,

Much depends on how the observations are correlated. nlme handles
correlated residuals within the most detailed level of the random effects.
In your case it will assume some correlation structure among residuals of
the same block:veg combination. Residuals from different block:veg
combinations are assumed to be independent.

Autocorrelation as a higher level (e.g. block or even the main effects) is
not possible in nlme. The INLA package allows for correlated random effects.

You need to provide more information on the kind of temporal correlation
that you want to incorporate and at which level is should operate.

Note that you have not specified veg. block has only very few levels. It
might not be a good idea to use it as a random effect. See "Should I treat
factor xxx as fixed or random?" on http://glmm.wikidot.com/faq

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-13 16:47 GMT+01:00 Lea <mwiederm at mtu.edu>:

> Hi!
>
> I am hoping for help with formulating the random structure for a data set
> that fits a log normal distribution. The data was collected from a split
> plot designed experiment (block: 4 replicates; v treatment: 3 levels; d
> treatment: 2 levels). d is nested within v which is nested within block;
> total n = 4x3x2 = 24; my random effects are all categorical
> hence using lme: random= ~1|block/veg, or lmer: (1|block/veg)
>
> I think I am OK with that but I can not figure out how to include the
> temporal repeated measure. This split plot setup was samples 5 times
> (monthly during the summer) for 3 years-> 15 times and I am too interested
> in the month and year effect. Ergo I do not want to average it out. Also
> from plotting the data there is an increase of the response throughout the
> year.
>
> Most everybody seems to be using the lme4 and not the nlme package these
> days. Is there still someone who could help me to write the temporal
> structure of the random term using the nlme package?
>
> my fixed factors are: v*d*year*month (I am not interested in the block
> effect) my fixed effects are all categorical
>
> m1<-lme(response~v*d*year*month, random= ~1|block/veg  and what do I do
> with
> the 15month in 3 years????
>
> or
>
> m2<-lmer(response~v*d*year*month+(1|block/veg  and what do I do with the
> 15month in 3 years????
>
> Thank you so much!
> Lea
>
> p.s.: I hope I don't offend anybody by writing things out for both
> packages.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Tue Mar 17 10:29:04 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Tue, 17 Mar 2015 20:29:04 +1100
Subject: [R-sig-ME] Problems with convergence
Message-ID: <CAF5_5cxHcAWSvgYL3876407aM5tM4pVBB+LTjr_gKPc7Bh8rbQ@mail.gmail.com>

The following code shows that there are convergence problem messages where
there is a problem with convergence. The profiling shows that the maximum
found is not the correct one. This is simulated data for a binary
meta-analysis with fixed effect for study and random effect for treatment.

library(lme4)

thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
200,200,200,200,200,200,200,200,200,200,200,200,200,
200,200,200,200,200,200,200,200,200,200,200,200,200,
200,200,200,200,200,200,200,200,200,200),trt=c(0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
"2","3","4","5","6","7","8","9","10","11","12","13",
"14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
"total","trt","id"),row.names=c(NA,40L),class="data.frame")

glmer1<-glmer(cbind(nEvents,total-nEvents)~trt+factor(id)+(0+trt|id),data=thedata,family=binomial)

# while glmer has problems with component 9 it is 8 with a problem profile
# I've use devtol so the discrepancy is printed
prof.glmer1<-profile(glmer1,which=8,devtol=1.0e-3)


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From rubenarslan at gmail.com  Tue Mar 17 14:33:25 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Tue, 17 Mar 2015 13:33:25 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
References: <loom.20150309T220710-595@post.gmane.org>
	<CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
Message-ID: <CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>

Dear list,

I've made a reproducible example of the zero-altered prediction,
in the hope that someone will have a look and reassure me that I'm going
about this the right way.
I was a bit confused by the point about p_i and n_i being correlated (they
are in my case), but I think this was a red herring for me
since I'm not deriving the variance analytically.
The script is here: https://gist.github.com/rubenarslan/aeacdd306b3d061819a6
and if you don't want to run the simulation fit yourself, I've put an RDS
file of the fit here:
https://dl.dropboxusercontent.com/u/1078620/m1.rds

Best regards,

Ruben Arslan

On Tue, Mar 10, 2015 at 1:22 PM Ruben Arslan <rubenarslan at gmail.com> wrote:

> Dear Dr Bolker,
>
> I'd thought about something like this, one point of asking was to see whether
> a) it's implemented already, because I'll probably make dumb mistakes while
> trying b) it's not implemented because it's a bad idea.
> Your response and the MCMCglmm course notes make me hope that it's c) not
> implemented because nobody did yet or d) it's so simple that everybody does
> it on-the-fly.
>
> So I tried my hand and would appreciate corrections. I am sure there is
> some screw-up or an inelegant approach in there.
> I included code for dealing with mcmc.lists because that's what I have and
> I'm not entirely sure how I deal with them is correct either.
>
> I started with a zero-altered model, because those fit fastest and
> according to the course notes have the least complex likelihood.
> Because I know not what I do, I'm not dealing with my random effects at
> all.
>
> I pasted a model summary below to show what I've applied the below
> function to. The function gives the following quantiles when applied to 19
> chains of that model.
>          5%         50%         95%
> 5.431684178 5.561211207 5.690655200
>          5%         50%         95%
> 5.003974382 5.178192327 5.348246558
>
> Warm regards,
>
> Ruben Arslan
>
> HPDpredict_za = function(object, predictor) {
>
> if(class(object) != "MCMCglmm") {
> if(length( object[[1]]$Residual$nrt )>1) {
> object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
> }
> Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
> vars = colnames(Sol[[1]])
> } else {
> Sol = as.data.frame(object$Sol)
> vars = names(Sol)
> }
> za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
> "traitza_"]
> za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
> "traitza_"]
>  intercept = Sol[,"(Intercept)"]
> za_intercept = Sol[, za_intercept_name]
> l1 = Sol[, predictor ]
> l2 = Sol[, za_predictor ]
> if(is.list(object)) {
> intercept = unlist(intercept)
> za_intercept = unlist(za_intercept)
> l1 = unlist(l1)
> l2 = unlist(l2)
> }
>  py_0 = dpois(0, exp(intercept + za_intercept))
> y_ygt0 = exp(intercept)
> at_intercept = (1-py_0) * y_ygt0
>
> py_0 = dpois(0, exp(intercept + za_intercept + l2))
> y_ygt0 = exp(intercept +  l1)
> at_predictor_1 = (1-py_0) * y_ygt0
> print(qplot(at_intercept))
> print(qplot(at_predictor_1))
> df = data.frame("intercept" = at_intercept)
> df[, predictor] = at_predictor_1
> print(qplot(x=variable,
> y=value,data=suppressMessages(melt(df)),fill=variable,alpha=I(0.40), geom =
> 'violin'))
> print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
> print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
> invisible(df)
> }
>
>
> > summary(object[[1]])
>
>  Iterations = 100001:299901
>  Thinning interval  = 100
>  Sample size  = 2000
>
>  DIC: 349094
>
>  G-structure:  ~idh(trait):idParents
>
>                       post.mean l-95% CI u-95% CI eff.samp
> children.idParents       0.0189   0.0164   0.0214     1729
> za_children.idParents    0.2392   0.2171   0.2622     1647
>
>  R-structure:  ~idh(trait):units
>
>                   post.mean l-95% CI u-95% CI eff.samp
> children.units        0.144    0.139    0.148     1715
> za_children.units     1.000    1.000    1.000        0
>
>  Location effects: children ~ trait * (maternalage.factor + paternalloss +
> maternalloss + center(nr.siblings) + birth.cohort + urban + male +
> paternalage.mean + paternalage.diff)
>
>                                            post.mean  l-95% CI  u-95% CI
> eff.samp   pMCMC
> (Intercept)                                 2.088717  2.073009  2.103357
>   2000 <0.0005 ***
> traitza_children                           -1.933491 -1.981945 -1.887863
>   2000 <0.0005 ***
> maternalage.factor(14,20]                   0.007709 -0.014238  0.027883
>   1500   0.460
> maternalage.factor(35,50]                   0.006350 -0.009634  0.024107
>   2000   0.462
> paternallossTRUE                            0.000797 -0.022716  0.025015
>   2000   0.925
> maternallossTRUE                           -0.015542 -0.040240  0.009549
>   2000   0.226
> center(nr.siblings)                         0.005869  0.004302  0.007510
>   2000 <0.0005 ***
> birth.cohort(1703,1722]                    -0.045487 -0.062240 -0.028965
>   2000 <0.0005 ***
> birth.cohort(1722,1734]                    -0.055872 -0.072856 -0.036452
>   2000 <0.0005 ***
> birth.cohort(1734,1743]                    -0.039770 -0.056580 -0.020907
>   2000 <0.0005 ***
> birth.cohort(1743,1750]                    -0.030713 -0.048301 -0.012214
>   2000   0.002 **
> urban                                      -0.076748 -0.093240 -0.063002
>   2567 <0.0005 ***
> male                                        0.106074  0.095705  0.115742
>   2000 <0.0005 ***
> paternalage.mean                           -0.024119 -0.033133 -0.014444
>   2000 <0.0005 ***
> paternalage.diff                           -0.018367 -0.032083 -0.005721
>   2000   0.007 **
> traitza_children:maternalage.factor(14,20] -0.116510 -0.182432 -0.051978
>   1876   0.001 ***
> traitza_children:maternalage.factor(35,50] -0.045196 -0.094485  0.002640
>   2000   0.075 .
> traitza_children:paternallossTRUE          -0.171957 -0.238218 -0.104820
>   2000 <0.0005 ***
> traitza_children:maternallossTRUE          -0.499539 -0.566825 -0.430637
>   2000 <0.0005 ***
> traitza_children:center(nr.siblings)       -0.023723 -0.028676 -0.018746
>   1848 <0.0005 ***
> traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250  0.026024
>   2000   0.319
> traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462 -0.227187
>   2000 <0.0005 ***
> traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659 -0.204462
>   2130 <0.0005 ***
> traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568 -0.426648
>   2000 <0.0005 ***
> traitza_children:urban                     -0.604108 -0.645169 -0.562554
>   1702 <0.0005 ***
> traitza_children:male                      -0.414988 -0.444589 -0.387005
>   2000 <0.0005 ***
> traitza_children:paternalage.mean           0.006545 -0.018570  0.036227
>   2000   0.651
> traitza_children:paternalage.diff          -0.097982 -0.136302 -0.060677
>   2000 <0.0005 ***
>
>
> On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>> Ruben Arslan <rubenarslan at ...> writes:
>>
>> >
>> > Dear list,
>> >
>> > I wanted to ask: Is there any (maybe just back of the envelope) way to
>> > obtain a response prediction for zero-inflated or hurdle type models?
>> > I've fit such models in MCMCglmm, but I don't work in ecology and my
>> > previous experience with explaining such models to "my audience" did not
>> > bode well. When it comes to humans, the researchers I presented to are
>> not
>> > used to offspring count being zero-inflated (or acquainted with that
>> > concept), but in my historical data with high infant mortality, it is
>> (in
>> > modern data it's actually slightly underdispersed).
>> >
>> > Currently I'm using lme4 and simply splitting my models into two stages
>> > (finding a mate and having offspring).
>> > That's okay too, but in one population the effect of interest is not
>> > clearly visible in either stage, only when both are taken together (but
>> > then the outcome is zero-inflated).
>> > I expect to be given a hard time for this and hence thought I'd use a
>> > binomial model with the outcome offspring>0 as my main model, but that
>> > turns out to be hard to explain too and doesn't
>> > really do the data justice.
>> >
>> > Basically I don't want to be forced to discuss my smallest population
>> as a
>> > non-replication of the effect because I was insufficiently able to
>> explain
>> > the statistics behind my reasoning that the effect shows.
>>
>>   I think the back-of-the envelope answer would be that for a two-stage
>> model with a prediction of p_i for the probability of having a non-zero
>> response (or in the case of zero-inflated models, the probability of
>> _not_ having a structural zero) and a prediction of n_i for the
>> conditional
>> part of the model, the mean predicted value is p_i*n_i and the
>> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 + var(n_i)/n_i^2)
>> (this is assuming
>> that you haven't built in any correlation between p_i and n_i, which
>> would be hard in lme4 but _might_ be possible under certain circumstances
>> via a multitype model in MCMCglmm).
>>
>>   Does that help?
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From stefan.vandongen at uantwerpen.be  Tue Mar 17 14:34:13 2015
From: stefan.vandongen at uantwerpen.be (Van Dongen Stefan)
Date: Tue, 17 Mar 2015 13:34:13 +0000
Subject: [R-sig-ME] r-square type of measure for cox PH in MCMCglmm
Message-ID: <B4D4B84E4C26984690619D21577874EAA62ABC83@xmail33.ad.ua.ac.be>

Hi All,

I am running a multivariate animal model in MCMCglmm. One response variable is censored, so I use a cox proportional hazards approach for that one. The model is running OK and I get an estimate for the association of the hazard with a fixed covariate. Is there a way to get an R-square estimate for the strength of association?

many thanks

Stefan

-------------------------------------------------------------------------------------------------------------------------
Prof. Dr. Stefan Van Dongen
Evolutionary Ecology - Department of Biology - University of Antwerp (http://www.ua.ac.be/eveco)
StatUA Statistics Center, University of Antwerp (http://www.ua.ac.be/statua)
Groenenborgerlaan 171 - B-2020 Antwerp - Belgium

room V324b, building V, campus Groenenborger
Tel: + 32 3 265 33 36
Fax: + 32 3 265 34 74
http://www.ua.ac.be/stefan.vandongen
--------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From Farrar.David at epa.gov  Tue Mar 17 15:55:27 2015
From: Farrar.David at epa.gov (Farrar, David)
Date: Tue, 17 Mar 2015 14:55:27 +0000
Subject: [R-sig-ME] r-square type of measure for cox PH in MCMCglmm
In-Reply-To: <B4D4B84E4C26984690619D21577874EAA62ABC83@xmail33.ad.ua.ac.be>
References: <B4D4B84E4C26984690619D21577874EAA62ABC83@xmail33.ad.ua.ac.be>
Message-ID: <CY1PR09MB07589DF75F343DAD66198CC69A030@CY1PR09MB0758.namprd09.prod.outlook.com>


You might start with this FAQ:  http://glmm.wikidot.com/faq
While analogues may exist, as far as I know there is no good reason to think that an R^2 should exist which should be viewed in the same way for any sort of regression model.


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Van Dongen Stefan
Sent: Tuesday, March 17, 2015 9:34 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] r-square type of measure for cox PH in MCMCglmm

Hi All,

I am running a multivariate animal model in MCMCglmm. One response variable is censored, so I use a cox proportional hazards approach for that one. The model is running OK and I get an estimate for the association of the hazard with a fixed covariate. Is there a way to get an R-square estimate for the strength of association?

many thanks

Stefan

-------------------------------------------------------------------------------------------------------------------------
Prof. Dr. Stefan Van Dongen
Evolutionary Ecology - Department of Biology - University of Antwerp (http://www.ua.ac.be/eveco) StatUA Statistics Center, University of Antwerp (http://www.ua.ac.be/statua) Groenenborgerlaan 171 - B-2020 Antwerp - Belgium

room V324b, building V, campus Groenenborger
Tel: + 32 3 265 33 36
Fax: + 32 3 265 34 74
http://www.ua.ac.be/stefan.vandongen
--------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From slu at ccsr.uchicago.edu  Tue Mar 17 17:01:21 2015
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 17 Mar 2015 11:01:21 -0500
Subject: [R-sig-ME] lme4 upgrade broke my old code?
Message-ID: <1426608081.31324.8.camel@ccsr.uchicago.edu>

Hello, I'm trying to update a mer object (here called crossed.lmer3)
created about 2 years ago using lmer of a version I don't remember. I'm
now using lme4_1.1-7   Rcpp_0.11.5  Matrix_1.1-5 in R version 3.1.2
(2014-10-31) Platform: x86_64-redhat-linux-gnu (64-bit). When I do stuff
that worked before, I get errors. E.g.:
> crossed.lmer3a <- update(crossed.lmer3, ~ . + cmclsach + crclsach)
Error: $ operator not defined for this S4 class

and summary() gives nothing interesting.
> summary(crossed.lmer3)
Length  Class   Mode 
     1    mer     S4 

Also, code from the examples from the lme4 manual also gives errors:
 str(terms(crossed.lmer3))
Error: $ operator not defined for this S4 class

Enter a frame number, or 0 to exit   

Can I get a little advice here, please?
-- 
Stuart Luppescu -=-=- slu <AT> ccsr <DOT> uchicago <DOT> edu
CCSR at U of C ,.;-*^*-;.,  ccsr.uchicago.edu
     (^_^)/    ????????
[Crash programs] fail because they are based on the theory that, 
with nine women pregnant, you can get a baby a month.
                -- Wernher von Braun


From j.hadfield at ed.ac.uk  Tue Mar 17 17:31:12 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 17 Mar 2015 16:31:12 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>
References: <loom.20150309T220710-595@post.gmane.org>
	<CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
	<CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>
Message-ID: <20150317163112.14195p92nh01nwso@www.staffmail.ed.ac.uk>

Hi,

Sorry - I should have replied to this post earlier. I've been working  
on predict/simulate methods for all MCMcglmm models (including  
zero-inflated/altered/hurdle/truncated models) and these are now  
largely complete (together with newdata options).

When predictions are to be taken after marginalising the random  
effects (including the `residual' over-dispersion) it is not possible  
to obtain closed form expressions. The options that will be available  
in MCMCglmm are:

1) algebraic approximation
2) numerical integration
3) simulation

1) and 2) are currently only accurate when the random/residual effect  
structure implies no covariance between the Poisson part and the  
binary part.

1) is reasonably accurate for zero-inflated distributions, but can be  
pretty poor for the remainder because they all involve zero-truncated  
Poisson log-normal distributions and my taylor approximation for the  
mean is less than ideal (any suggestions would be helpful).

2) could be extended to double integration in which case covariance  
between the Poisson part and the binary part could be handled.

In your code, part of the problem is that you have fitted a zapoisson,  
but the prediction is based on a zipoisson (with complementary log-log  
link rather than logt link).

In all zero-inflated/altered/hurdle/truncated models

E[y] = E[(1-prob)*meanc]

where prob is the probabilty of a zero in the binary part and meanc is  
the mean of a Poisson distribution (zipoisson) or a zero-truncated  
poisson (zapoisson and hupoisson). If we have eta_1 as the linear  
predictor for the poisson part and eta_2 as the linear predictor for  
the binary part:

In zipoisson: prob = plogis(eta_2)     and meanc = exp(eta_1)
In zapoisson: prob = exp(-exp(eta_2))  and meanc =  
exp(eta_1)/(1-exp(-exp(eta_1)))
In hupoisson: prob = plogis(eta_2)     and meanc =  
exp(eta_1)/(1-exp(-exp(eta_1)))
In ztpoisson: prob = 0                 and meanc =  
exp(eta_1)/(1-exp(-exp(eta_1)))

In each case the linear predictor has a `fixed' part and a `random'  
part which I'll denote as `a' and `u' respectively. Ideally we would  
want

E[(1-prob)*meanc] taken over u_1 & u_2

if prob and meanc are independent this is a bit easier as

E[y] = E[1-prob]E[meanc]

and the two expectations ony need to taken with repsect to their  
respective random effects. If we have sd_1 and sd_2 as the standard  
deviations of the two sets of random effects then for the zapoisson:

   normal.evd<-function(x, mu, v){
      exp(-exp(x))*dnorm(x, mu, sqrt(v))
   }
   normal.zt<-function(x, mu, v){
     exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sqrt(v))
   }

   pred<-function(a_1, a_2, sd_1, sd_2){
     prob<-1-integrate(normal.evd, qnorm(0.0001, a_2,sd_2),  
qnorm(0.9999, a_2,sd_2), a_2,sd_2)[[1]]
     meanc<-integrate(normal.zt, qnorm(0.0001, a_1,sd_1),  
qnorm(0.9999, a_1,sd_1), a_1,sd_1)[[1]]
     prob*meanc
   }

#  gives the expected value with reasonable accuracy.  As an example:

   x<-rnorm(300)
   l1<-rnorm(300, 1/2+x, sqrt(1))
   l2<-rnorm(300, 1-x, sqrt(1))

   y<-rbinom(300, 1, 1-exp(-exp(l2)))
   y[which(y==1)]<-qpois(runif(sum(y==1), dpois(0,  
exp(l1[which(y==1)])), 1), exp(l1[which(y==1)]))
   # cunning sampler from Peter Dalgaard (R-sig-mixed)

   data=data.frame(y=y, x=x)
   prior=list(R=list(V=diag(2), nu=0.002, fix=2))

   m1<-MCMCglmm(y~trait+trait:x-1, rcov=~idh(trait):units, data=data,  
family="zapoisson", prior=prior)

   b_1<-colMeans(m1$Sol)[c(1,3)]
   b_2<-colMeans(m1$Sol)[c(2,4)]
   sd_1<-mean(sqrt(m1$VCV[,1]))
   sd_2<-mean(sqrt(m1$VCV[,2]))

   # note it is more accurate to take the posterior mean prediction  
rather than the prediction from the posterior means as I've done here,  
but for illustration:

   x.pred<-seq(-3,3,length=100)
   p<-1:100
   for(i in 1:100){
     p[i]<-pred(a_1 = b_1[1]+x.pred[i]*b_1[2], a_2 =  
b_2[1]+x.pred[i]*b_2[2], sd_1=sd_1, sd_2=sd_2)
   }

   plot(y~x)
   lines(p~x.pred)

Cheers,

Jarrod




Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015  
13:33:25 +0000:

> Dear list,
>
> I've made a reproducible example of the zero-altered prediction,
> in the hope that someone will have a look and reassure me that I'm going
> about this the right way.
> I was a bit confused by the point about p_i and n_i being correlated (they
> are in my case), but I think this was a red herring for me
> since I'm not deriving the variance analytically.
> The script is here: https://gist.github.com/rubenarslan/aeacdd306b3d061819a6
> and if you don't want to run the simulation fit yourself, I've put an RDS
> file of the fit here:
> https://dl.dropboxusercontent.com/u/1078620/m1.rds
>
> Best regards,
>
> Ruben Arslan
>
> On Tue, Mar 10, 2015 at 1:22 PM Ruben Arslan <rubenarslan at gmail.com> wrote:
>
>> Dear Dr Bolker,
>>
>> I'd thought about something like this, one point of asking was to  
>> see whether
>> a) it's implemented already, because I'll probably make dumb mistakes while
>> trying b) it's not implemented because it's a bad idea.
>> Your response and the MCMCglmm course notes make me hope that it's c) not
>> implemented because nobody did yet or d) it's so simple that everybody does
>> it on-the-fly.
>>
>> So I tried my hand and would appreciate corrections. I am sure there is
>> some screw-up or an inelegant approach in there.
>> I included code for dealing with mcmc.lists because that's what I have and
>> I'm not entirely sure how I deal with them is correct either.
>>
>> I started with a zero-altered model, because those fit fastest and
>> according to the course notes have the least complex likelihood.
>> Because I know not what I do, I'm not dealing with my random effects at
>> all.
>>
>> I pasted a model summary below to show what I've applied the below
>> function to. The function gives the following quantiles when applied to 19
>> chains of that model.
>>          5%         50%         95%
>> 5.431684178 5.561211207 5.690655200
>>          5%         50%         95%
>> 5.003974382 5.178192327 5.348246558
>>
>> Warm regards,
>>
>> Ruben Arslan
>>
>> HPDpredict_za = function(object, predictor) {
>>
>> if(class(object) != "MCMCglmm") {
>> if(length( object[[1]]$Residual$nrt )>1) {
>> object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
>> }
>> Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
>> vars = colnames(Sol[[1]])
>> } else {
>> Sol = as.data.frame(object$Sol)
>> vars = names(Sol)
>> }
>> za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
>> "traitza_"]
>> za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
>> "traitza_"]
>>  intercept = Sol[,"(Intercept)"]
>> za_intercept = Sol[, za_intercept_name]
>> l1 = Sol[, predictor ]
>> l2 = Sol[, za_predictor ]
>> if(is.list(object)) {
>> intercept = unlist(intercept)
>> za_intercept = unlist(za_intercept)
>> l1 = unlist(l1)
>> l2 = unlist(l2)
>> }
>>  py_0 = dpois(0, exp(intercept + za_intercept))
>> y_ygt0 = exp(intercept)
>> at_intercept = (1-py_0) * y_ygt0
>>
>> py_0 = dpois(0, exp(intercept + za_intercept + l2))
>> y_ygt0 = exp(intercept +  l1)
>> at_predictor_1 = (1-py_0) * y_ygt0
>> print(qplot(at_intercept))
>> print(qplot(at_predictor_1))
>> df = data.frame("intercept" = at_intercept)
>> df[, predictor] = at_predictor_1
>> print(qplot(x=variable,
>> y=value,data=suppressMessages(melt(df)),fill=variable,alpha=I(0.40), geom =
>> 'violin'))
>> print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
>> print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
>> invisible(df)
>> }
>>
>>
>> > summary(object[[1]])
>>
>>  Iterations = 100001:299901
>>  Thinning interval  = 100
>>  Sample size  = 2000
>>
>>  DIC: 349094
>>
>>  G-structure:  ~idh(trait):idParents
>>
>>                       post.mean l-95% CI u-95% CI eff.samp
>> children.idParents       0.0189   0.0164   0.0214     1729
>> za_children.idParents    0.2392   0.2171   0.2622     1647
>>
>>  R-structure:  ~idh(trait):units
>>
>>                   post.mean l-95% CI u-95% CI eff.samp
>> children.units        0.144    0.139    0.148     1715
>> za_children.units     1.000    1.000    1.000        0
>>
>>  Location effects: children ~ trait * (maternalage.factor + paternalloss +
>> maternalloss + center(nr.siblings) + birth.cohort + urban + male +
>> paternalage.mean + paternalage.diff)
>>
>>                                            post.mean  l-95% CI  u-95% CI
>> eff.samp   pMCMC
>> (Intercept)                                 2.088717  2.073009  2.103357
>>   2000 <0.0005 ***
>> traitza_children                           -1.933491 -1.981945 -1.887863
>>   2000 <0.0005 ***
>> maternalage.factor(14,20]                   0.007709 -0.014238  0.027883
>>   1500   0.460
>> maternalage.factor(35,50]                   0.006350 -0.009634  0.024107
>>   2000   0.462
>> paternallossTRUE                            0.000797 -0.022716  0.025015
>>   2000   0.925
>> maternallossTRUE                           -0.015542 -0.040240  0.009549
>>   2000   0.226
>> center(nr.siblings)                         0.005869  0.004302  0.007510
>>   2000 <0.0005 ***
>> birth.cohort(1703,1722]                    -0.045487 -0.062240 -0.028965
>>   2000 <0.0005 ***
>> birth.cohort(1722,1734]                    -0.055872 -0.072856 -0.036452
>>   2000 <0.0005 ***
>> birth.cohort(1734,1743]                    -0.039770 -0.056580 -0.020907
>>   2000 <0.0005 ***
>> birth.cohort(1743,1750]                    -0.030713 -0.048301 -0.012214
>>   2000   0.002 **
>> urban                                      -0.076748 -0.093240 -0.063002
>>   2567 <0.0005 ***
>> male                                        0.106074  0.095705  0.115742
>>   2000 <0.0005 ***
>> paternalage.mean                           -0.024119 -0.033133 -0.014444
>>   2000 <0.0005 ***
>> paternalage.diff                           -0.018367 -0.032083 -0.005721
>>   2000   0.007 **
>> traitza_children:maternalage.factor(14,20] -0.116510 -0.182432 -0.051978
>>   1876   0.001 ***
>> traitza_children:maternalage.factor(35,50] -0.045196 -0.094485  0.002640
>>   2000   0.075 .
>> traitza_children:paternallossTRUE          -0.171957 -0.238218 -0.104820
>>   2000 <0.0005 ***
>> traitza_children:maternallossTRUE          -0.499539 -0.566825 -0.430637
>>   2000 <0.0005 ***
>> traitza_children:center(nr.siblings)       -0.023723 -0.028676 -0.018746
>>   1848 <0.0005 ***
>> traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250  0.026024
>>   2000   0.319
>> traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462 -0.227187
>>   2000 <0.0005 ***
>> traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659 -0.204462
>>   2130 <0.0005 ***
>> traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568 -0.426648
>>   2000 <0.0005 ***
>> traitza_children:urban                     -0.604108 -0.645169 -0.562554
>>   1702 <0.0005 ***
>> traitza_children:male                      -0.414988 -0.444589 -0.387005
>>   2000 <0.0005 ***
>> traitza_children:paternalage.mean           0.006545 -0.018570  0.036227
>>   2000   0.651
>> traitza_children:paternalage.diff          -0.097982 -0.136302 -0.060677
>>   2000 <0.0005 ***
>>
>>
>> On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> Ruben Arslan <rubenarslan at ...> writes:
>>>
>>> >
>>> > Dear list,
>>> >
>>> > I wanted to ask: Is there any (maybe just back of the envelope) way to
>>> > obtain a response prediction for zero-inflated or hurdle type models?
>>> > I've fit such models in MCMCglmm, but I don't work in ecology and my
>>> > previous experience with explaining such models to "my audience" did not
>>> > bode well. When it comes to humans, the researchers I presented to are
>>> not
>>> > used to offspring count being zero-inflated (or acquainted with that
>>> > concept), but in my historical data with high infant mortality, it is
>>> (in
>>> > modern data it's actually slightly underdispersed).
>>> >
>>> > Currently I'm using lme4 and simply splitting my models into two stages
>>> > (finding a mate and having offspring).
>>> > That's okay too, but in one population the effect of interest is not
>>> > clearly visible in either stage, only when both are taken together (but
>>> > then the outcome is zero-inflated).
>>> > I expect to be given a hard time for this and hence thought I'd use a
>>> > binomial model with the outcome offspring>0 as my main model, but that
>>> > turns out to be hard to explain too and doesn't
>>> > really do the data justice.
>>> >
>>> > Basically I don't want to be forced to discuss my smallest population
>>> as a
>>> > non-replication of the effect because I was insufficiently able to
>>> explain
>>> > the statistics behind my reasoning that the effect shows.
>>>
>>>   I think the back-of-the envelope answer would be that for a two-stage
>>> model with a prediction of p_i for the probability of having a non-zero
>>> response (or in the case of zero-inflated models, the probability of
>>> _not_ having a structural zero) and a prediction of n_i for the
>>> conditional
>>> part of the model, the mean predicted value is p_i*n_i and the
>>> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 + var(n_i)/n_i^2)
>>> (this is assuming
>>> that you haven't built in any correlation between p_i and n_i, which
>>> would be hard in lme4 but _might_ be possible under certain circumstances
>>> via a multitype model in MCMCglmm).
>>>
>>>   Does that help?
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From anne.krause at frequenz.uni-freiburg.de  Tue Mar 17 18:06:48 2015
From: anne.krause at frequenz.uni-freiburg.de (Anne Krause)
Date: Tue, 17 Mar 2015 18:06:48 +0100
Subject: [R-sig-ME] transform glmer model into MCMCglmm: how to define the
	priors?
Message-ID: <web-254004262@uni-freiburg.de>

Dear list members,
I am a linguist who would like to use MCMCglmm in order to
model change in language morphology. I have a 3-level
dependent variable (unordered) which are 3 realisations of
a morphological form in German. Say, I call them A, B, and
C - A and B share the same vowel, B and C share the
suffixation.
I did not know about MCMCglmm until recently; therefore I
worked with two glmer models, looking at vowel and
suffixation separately. However, I have been criticised for
the clumsy model interpretation, and I am sure that the
output of a MCMCglmm would be more straightforward and
convincing.

My glmer looks like this:
model <- glmer(vowel~frequency+year+recency+
                  frequency*recency+
                  (1|verb)+(1|author), data=imp,
                  family=binomial)
- where ?vowel? differentiates between AB on the one hand
and C on the other hand,
- ?frequency? and ?year? are numeric fixed variables and
?recency? a categorical fixed variable (7 levels),
- ?verb? and ?author? are categorical random variables

The model for the dependent variable ?suffix? is
practically the same (part of the criticism), ?suffix?
distinguishing between A on the one hand and BC on the
other hand.

Trying to transform this into an MCMCglmm, I managed to get
as far as this:
model2 <- MCMCglmm(form~trait:frequency+trait:recency+
                  trait:year-1, 
                  random=~us(trait):author, 
                  rcov=~us(trait):units,
                  data=imp, family="categorical",)
(?form? now distinguishing between all 3 three levels of
the dependent variable A, B, and C)

I am well aware that this model is running without priors.
Whichever prior I tried gave me the error ?V is the wrong
dimension for some prior$G/prior$R elements? and I have no
idea (after reading through the general description, the
tutorial, the course notes and entries in this mailing
list) how these priors are defined. I guess there is no
rule of thumb, but I hope this short explanation of my
variables is enough for someone of you to point out a
solution (or a starting point for me). I also need to
include the second random from above (?verb?) and the
interaction between ?frequency? and ?recency?.

Even though model2 is running, I cannot call the summary
for it (error: ?Error in get(as.character(FUN), mode =
"function", envir = envir) :   object 'C:\Users\Anne
Krause\some_directory.Rdata' of mode 'function' was not
found?), which probably has to do with the fact that I did
not include priors (?!).

Thank you so much in advance for help and/ or comments,
pointers or the like!

Best, Anne
____________________________________

Anne Krause
Research Training Group GRK DFG 1624
"Frequency Effects in Language"
University of Freiburg
Belfortstra?e 18
79098 Freiburg

Phone: 0761/203-97670
frequenz.uni-freiburg.de/krause


From mtoncic at ffri.hr  Tue Mar 17 18:13:00 2015
From: mtoncic at ffri.hr (marKo)
Date: Tue, 17 Mar 2015 18:13:00 +0100
Subject: [R-sig-ME] lme4 upgrade broke my old code?
In-Reply-To: <1426608081.31324.8.camel@ccsr.uchicago.edu>
References: <1426608081.31324.8.camel@ccsr.uchicago.edu>
Message-ID: <5508609C.7000207@ffri.hr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 03/17/2015 05:01 PM, Stuart Luppescu wrote:
> Hello, I'm trying to update a mer object (here called 
> crossed.lmer3) created about 2 years ago using lmer of a version I 
> don't remember. I'm now using lme4_1.1-7   Rcpp_0.11.5 Matrix_1.1-5
> in R version 3.1.2 (2014-10-31) Platform: x86_64-redhat-linux-gnu
> (64-bit). When I do stuff that worked before, I get errors. E.g.:
>> crossed.lmer3a <- update(crossed.lmer3, ~ . + cmclsach + 
>> crclsach)
> Error: $ operator not defined for this S4 class
> 
> and summary() gives nothing interesting.
>> summary(crossed.lmer3)
> Length  Class   Mode 1    mer     S4
> 
> Also, code from the examples from the lme4 manual also gives 
> errors: str(terms(crossed.lmer3)) Error: $ operator not defined
> for this S4 class
> 
> Enter a frame number, or 0 to exit
> 
> Can I get a little advice here, please?
> 

I think that starting with version 1, lme4 was not compatible with the
lower version code.
I am afraid that you will have to calculate the old models again with
the newer lme4.

Cheers,

Marko



- -- 
Marko Ton?i?
Research Assistant
University of Rijeka
Faculty of Humanities and Social Sciences
Department of Psychology
Sveucilisna avenija 4, 51000 Rijeka, CROATIA
e-mail: mtoncic at ffri.hr
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAEBAgAGBQJVCGCYAAoJEJcj4KySkkQsTkQQAMW7lBxO7qcA5fQqVsQlnWWT
ZH+L8xyRAEnUgBL5STcnMF4chDuBH9sJKGGJqJZ1rQwDWamq8rqhbFUZCs9hcxi8
lK2auYp1r66qL6BuuftRRZNoazyjANnI8Z+lK/dP/5KOSdEOBh9OcK5IEkQ9l0gf
zWexNpNBmid3DVkgs25PIXYz0C8TypdfYwnjwSJZL2g/gDaOweNkEEpelXx9Xwu+
gVlSE2lZSijuBNHL0pVyfKth84/2gnSth/Bjt38D7m1z9S8nf8nq7ZZW5jc+3+Vu
YZZibIZjCPbHHJUL/KfP+AMiGi74+h3RI6krMH290kTn3DWcUfHZlLAw8D+RFOCZ
EE5UPWexAp8ovKLD3JzSIatDpu2md7QR3202uO9dwW5LSyCGWQh41K4BiS2HLvyX
so4ONqdBEfNStWIqReL3fyg8KbJroPHAc+fNjl7Tpbjmej5dKLBY7s85viCvVk3w
liDEdeUuQV1kq3vpGPMJ7RIgFlbHLIZjbDRhtmP45EYvgvNC1sAV4oy43coASuCC
Cfpy8rReJYm75PfXd6Wq8/NAnvGb+1xUlpgPZHuakWj0vyTmzCWoHLLt+tiDYTiU
izKA6Quw9uz9C7CRkRGS48dV8J/sO2dV7CKX3RkKkVjD0qP2Mze2ePGBHs8ZctW6
OJVfBY4x3bmN4pTtT0T4
=HGGP
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Tue Mar 17 18:27:20 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Mar 2015 13:27:20 -0400
Subject: [R-sig-ME] lme4 upgrade broke my old code?
In-Reply-To: <5508609C.7000207@ffri.hr>
References: <1426608081.31324.8.camel@ccsr.uchicago.edu>
	<5508609C.7000207@ffri.hr>
Message-ID: <550863F8.9060300@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-17 01:13 PM, marKo wrote:
> On 03/17/2015 05:01 PM, Stuart Luppescu wrote:
>> Hello, I'm trying to update a mer object (here called 
>> crossed.lmer3) created about 2 years ago using lmer of a version
>> I don't remember. I'm now using lme4_1.1-7   Rcpp_0.11.5
>> Matrix_1.1-5 in R version 3.1.2 (2014-10-31) Platform:
>> x86_64-redhat-linux-gnu (64-bit). When I do stuff that worked
>> before, I get errors. E.g.:
>>> crossed.lmer3a <- update(crossed.lmer3, ~ . + cmclsach + 
>>> crclsach)
>> Error: $ operator not defined for this S4 class
> 
>> and summary() gives nothing interesting.
>>> summary(crossed.lmer3)
>> Length  Class   Mode 1    mer     S4
> 
>> Also, code from the examples from the lme4 manual also gives 
>> errors: str(terms(crossed.lmer3)) Error: $ operator not defined 
>> for this S4 class
> 
>> Enter a frame number, or 0 to exit
> 
>> Can I get a little advice here, please?
> 
> 
> I think that starting with version 1, lme4 was not compatible with
> the lower version code. I am afraid that you will have to calculate
> the old models again with the newer lme4.
> 
> Cheers,
> 
> Marko

  There is some help here.  If you install the lme4.0 package (see the
README at https://github.com/lme4/lme4 ) you can at least use
convert_old_lme4() to update lme4 pre 1.0 to lme4.0  ...  We don't
currently have a function to convert stuff that old to modern lme4
(lots of the internal structures have changed), but if you want to
badly enough you can use lme4.0 ...
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVCGP4AAoJEOCV5YRblxUH9qkIANo8W80aKVDVfYIozoiTX37Y
1CTYoY/XlQpLJVHGaAj2C8pZeZHK8eCRsPBz6+BlhArX7VyCDhVz0QZJNiyqnaIY
YpbI4nxIO24qoLm+cnRcfh+BcyTIJ6o0m26IrK+ivmthMqtfFj2QHZp5iJ43XFfF
XvcnRaRfsynD8ccGFlghqhMFooNtLIN7f646axTybTvNm12oEtzL2fRT+DspQVDw
4/FsUiAsrK829NpjMTMVIBFRYDbGnBlBHgD4VEEXlQmupPiBe7G+eDMficHOjrFy
nGVX4myi1G/roykO3w2U+82xaMUyD+ffKcZjQLo9HXE9TKu2hPgQIJDmxyxYH8o=
=LIgP
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Tue Mar 17 19:26:20 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Mar 2015 18:26:20 +0000 (UTC)
Subject: [R-sig-ME] lme4 upgrade broke my old code?
References: <1426608081.31324.8.camel@ccsr.uchicago.edu>
	<5508609C.7000207@ffri.hr> <550863F8.9060300@gmail.com>
Message-ID: <loom.20150317T192333-21@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> 
> On 15-03-17 01:13 PM, marKo wrote:
> > On 03/17/2015 05:01 PM, Stuart Luppescu wrote:
> >> Hello, I'm trying to update a mer object (here called 
> >> crossed.lmer3) created about 2 years ago using lmer of a version
> >> I don't remember. I'm now using lme4_1.1-7   Rcpp_0.11.5
> >> Matrix_1.1-5 in R version 3.1.2 (2014-10-31) Platform:
> >> x86_64-redhat-linux-gnu (64-bit). When I do stuff that worked
> >> before, I get errors. E.g.:
> >>> crossed.lmer3a <- update(crossed.lmer3, ~ . + cmclsach + 
> >>> crclsach)
> >> Error: $ operator not defined for this S4 class
> > 
> >> and summary() gives nothing interesting.
> >>> summary(crossed.lmer3)
> >> Length  Class   Mode 1    mer     S4
> > 
> >> Also, code from the examples from the lme4 manual also gives 
> >> errors: str(terms(crossed.lmer3)) Error: $ operator not defined 
> >> for this S4 class
> > 
> >> Enter a frame number, or 0 to exit
> > 
> >> Can I get a little advice here, please?
> > 
> > 
> > I think that starting with version 1, lme4 was not compatible with
> > the lower version code. I am afraid that you will have to calculate
> > the old models again with the newer lme4.
> > 
> > Cheers,
> > 
> > Marko
> 
>   There is some help here.  If you install the lme4.0 package (see the
> README at https://github.com/lme4/lme4 ) you can at least use
> convert_old_lme4() to update lme4 pre 1.0 to lme4.0  ...  We don't
> currently have a function to convert stuff that old to modern lme4
> (lots of the internal structures have changed), but if you want to
> badly enough you can use lme4.0 ...
> 

  Just to follow up on my own post a little bit:

  it would probably be quite a big pain to import *all* of the
results from an old-lme4 fit into a new-lme4 object, as the internal
structures have changed quite a lot.  Something that would work
well and be reasonably efficient would be to import the basic
data structures such as the random-effects design matrix (Z), the
Cholesky factor of the RE var-cov matrix (Lambda), hopefully along
with its symbolic permutation information, and to re-fit the model
starting from the ML/REML estimates from the old model.  There hasn't
been a big outcry demanding this feature, but if it were to be
posted as a Github issue something *might* happen ...

  cheers
    Ben Bolker


From rubenarslan at gmail.com  Tue Mar 17 19:53:33 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Tue, 17 Mar 2015 18:53:33 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <20150317163112.14195p92nh01nwso@www.staffmail.ed.ac.uk>
References: <loom.20150309T220710-595@post.gmane.org>
	<CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
	<CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>
	<20150317163112.14195p92nh01nwso@www.staffmail.ed.ac.uk>
Message-ID: <CALv3xzuKdax26=sdMRTj16we9-UsWbF4y7bo_5rkwXcky1WR6Q@mail.gmail.com>

Hi Jarrod,

thanks for the extensive reply! This helps a lot, though it sounds like I
was hubristic to attempt this myself.
I tried using the approach you mapped out in the function gist
<https://gist.github.com/rubenarslan/aeacdd306b3d061819a6> I posted. I
simply put the pred function in a loop, so that I wouldn't make any
mistakes while vectorising and since I don't care about performance at this
point.

Of course, I have some follow up questions though.. I'm sorry if I'm being
a pain, I really appreciate the free advice, but understand of course if
other things take precedence.

1. You're not "down with" developing publicly are you? Because I sure would
like to test-drive the newdata prediction and simulation functions..

2. Could you make sure that I got this right: "When predictions are to be
taken after marginalising the random effects (including the `residual'
over-dispersion) it is not possible to obtain closed form expressions."
That is basically my scenario, right? In the example I included, I also had
a group-level random effect (family). Ore are you talking about the "trait"
as the random effect (as in your example) and my scenario is different and
I cannot apply the numerical double integration procedure you posted?
To be clear about my prediction goal without using language that I might be
using incorrectly: I want to show what the average effect in the response
unit, number of children, is in my population(s). I have data on whole
populations and am using all of it (except individuals that don't have
completed fertility yet, because I have yet to find a way to model both
zero-inflation and right censoring).

3. "Numerical integration could be extended to double integration in which
case covariance between the Poisson part and the binary part could be
handled." That is what you posted an example of and it applies to my
scenario, because I specified a prior R=list(V=diag(2), nu=1.002, fix=2)
and rcov=~idh(trait):units, random=~idh(trait):idParents?
But this double integration approach is something you just wrote
off-the-cuff and I probably shouldn't use it in a publication? Or is this
in the forthcoming MCMCglmm release and I might actually be able to refer
to it once I get to submitting?

4. Could I change my model specification to forbid covariance between the
two parts and not shoot myself in the foot? Would this allow for a more
valid/tested approach to prediction?

5. When I use your method on my real data, I get less variation around the
prediction "for the reference level" than for all other factor levels.
My reference level actually has fewer cases than the others, so this isn't
"right" in a way.
Is this because I'm not doing newdata prediction? I get the "right" looking
uncertainty if I bootstrap newdata predictions in lme4,
Sorry if this is children's logic :-)
Here's an image of the prediction
<http://rpubs.com/rubenarslan/mcmcglmm_pred> and the raw data
<http://rpubs.com/rubenarslan/raw>.

Many thanks for any answers that you feel inclined to give.

Best wishes,

Ruben

On Tue, Mar 17, 2015 at 5:31 PM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi,
>
> Sorry - I should have replied to this post earlier. I've been working
> on predict/simulate methods for all MCMcglmm models (including
> zero-inflated/altered/hurdle/truncated models) and these are now
> largely complete (together with newdata options).
>
> When predictions are to be taken after marginalising the random
> effects (including the `residual' over-dispersion) it is not possible
> to obtain closed form expressions. The options that will be available
> in MCMCglmm are:
>
> 1) algebraic approximation
> 2) numerical integration
> 3) simulation
>
> 1) and 2) are currently only accurate when the random/residual effect
> structure implies no covariance between the Poisson part and the
> binary part.
>
> 1) is reasonably accurate for zero-inflated distributions, but can be
> pretty poor for the remainder because they all involve zero-truncated
> Poisson log-normal distributions and my taylor approximation for the
> mean is less than ideal (any suggestions would be helpful).
>
> 2) could be extended to double integration in which case covariance
> between the Poisson part and the binary part could be handled.
>
> In your code, part of the problem is that you have fitted a zapoisson,
> but the prediction is based on a zipoisson (with complementary log-log
> link rather than logt link).
>
> In all zero-inflated/altered/hurdle/truncated models
>
> E[y] = E[(1-prob)*meanc]
>
> where prob is the probabilty of a zero in the binary part and meanc is
> the mean of a Poisson distribution (zipoisson) or a zero-truncated
> poisson (zapoisson and hupoisson). If we have eta_1 as the linear
> predictor for the poisson part and eta_2 as the linear predictor for
> the binary part:
>
> In zipoisson: prob = plogis(eta_2)     and meanc = exp(eta_1)
> In zapoisson: prob = exp(-exp(eta_2))  and meanc =
> exp(eta_1)/(1-exp(-exp(eta_1)))
> In hupoisson: prob = plogis(eta_2)     and meanc =
> exp(eta_1)/(1-exp(-exp(eta_1)))
> In ztpoisson: prob = 0                 and meanc =
> exp(eta_1)/(1-exp(-exp(eta_1)))
>
> In each case the linear predictor has a `fixed' part and a `random'
> part which I'll denote as `a' and `u' respectively. Ideally we would
> want
>
> E[(1-prob)*meanc] taken over u_1 & u_2
>
> if prob and meanc are independent this is a bit easier as
>
> E[y] = E[1-prob]E[meanc]
>
> and the two expectations ony need to taken with repsect to their
> respective random effects. If we have sd_1 and sd_2 as the standard
> deviations of the two sets of random effects then for the zapoisson:
>
>    normal.evd<-function(x, mu, v){
>       exp(-exp(x))*dnorm(x, mu, sqrt(v))
>    }
>    normal.zt<-function(x, mu, v){
>      exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sqrt(v))
>    }
>
>    pred<-function(a_1, a_2, sd_1, sd_2){
>      prob<-1-integrate(normal.evd, qnorm(0.0001, a_2,sd_2),
> qnorm(0.9999, a_2,sd_2), a_2,sd_2)[[1]]
>      meanc<-integrate(normal.zt, qnorm(0.0001, a_1,sd_1),
> qnorm(0.9999, a_1,sd_1), a_1,sd_1)[[1]]
>      prob*meanc
>    }
>
> #  gives the expected value with reasonable accuracy.  As an example:
>
>    x<-rnorm(300)
>    l1<-rnorm(300, 1/2+x, sqrt(1))
>    l2<-rnorm(300, 1-x, sqrt(1))
>
>    y<-rbinom(300, 1, 1-exp(-exp(l2)))
>    y[which(y==1)]<-qpois(runif(sum(y==1), dpois(0,
> exp(l1[which(y==1)])), 1), exp(l1[which(y==1)]))
>    # cunning sampler from Peter Dalgaard (R-sig-mixed)
>
>    data=data.frame(y=y, x=x)
>    prior=list(R=list(V=diag(2), nu=0.002, fix=2))
>
>    m1<-MCMCglmm(y~trait+trait:x-1, rcov=~idh(trait):units, data=data,
> family="zapoisson", prior=prior)
>
>    b_1<-colMeans(m1$Sol)[c(1,3)]
>    b_2<-colMeans(m1$Sol)[c(2,4)]
>    sd_1<-mean(sqrt(m1$VCV[,1]))
>    sd_2<-mean(sqrt(m1$VCV[,2]))
>
>    # note it is more accurate to take the posterior mean prediction
> rather than the prediction from the posterior means as I've done here,
> but for illustration:
>
>    x.pred<-seq(-3,3,length=100)
>    p<-1:100
>    for(i in 1:100){
>      p[i]<-pred(a_1 = b_1[1]+x.pred[i]*b_1[2], a_2 =
> b_2[1]+x.pred[i]*b_2[2], sd_1=sd_1, sd_2=sd_2)
>    }
>
>    plot(y~x)
>    lines(p~x.pred)
>
> Cheers,
>
> Jarrod
>
>
>
>
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015
> 13:33:25 +0000:
>
> > Dear list,
> >
> > I've made a reproducible example of the zero-altered prediction,
> > in the hope that someone will have a look and reassure me that I'm going
> > about this the right way.
> > I was a bit confused by the point about p_i and n_i being correlated
> (they
> > are in my case), but I think this was a red herring for me
> > since I'm not deriving the variance analytically.
> > The script is here: https://gist.github.com/rubenarslan/
> aeacdd306b3d061819a6
> > and if you don't want to run the simulation fit yourself, I've put an RDS
> > file of the fit here:
> > https://dl.dropboxusercontent.com/u/1078620/m1.rds
> >
> > Best regards,
> >
> > Ruben Arslan
> >
> > On Tue, Mar 10, 2015 at 1:22 PM Ruben Arslan <rubenarslan at gmail.com>
> wrote:
> >
> >> Dear Dr Bolker,
> >>
> >> I'd thought about something like this, one point of asking was to
> >> see whether
> >> a) it's implemented already, because I'll probably make dumb mistakes
> while
> >> trying b) it's not implemented because it's a bad idea.
> >> Your response and the MCMCglmm course notes make me hope that it's c)
> not
> >> implemented because nobody did yet or d) it's so simple that everybody
> does
> >> it on-the-fly.
> >>
> >> So I tried my hand and would appreciate corrections. I am sure there is
> >> some screw-up or an inelegant approach in there.
> >> I included code for dealing with mcmc.lists because that's what I have
> and
> >> I'm not entirely sure how I deal with them is correct either.
> >>
> >> I started with a zero-altered model, because those fit fastest and
> >> according to the course notes have the least complex likelihood.
> >> Because I know not what I do, I'm not dealing with my random effects at
> >> all.
> >>
> >> I pasted a model summary below to show what I've applied the below
> >> function to. The function gives the following quantiles when applied to
> 19
> >> chains of that model.
> >>          5%         50%         95%
> >> 5.431684178 5.561211207 5.690655200
> >>          5%         50%         95%
> >> 5.003974382 5.178192327 5.348246558
> >>
> >> Warm regards,
> >>
> >> Ruben Arslan
> >>
> >> HPDpredict_za = function(object, predictor) {
> >>
> >> if(class(object) != "MCMCglmm") {
> >> if(length( object[[1]]$Residual$nrt )>1) {
> >> object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
> >> }
> >> Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
> >> vars = colnames(Sol[[1]])
> >> } else {
> >> Sol = as.data.frame(object$Sol)
> >> vars = names(Sol)
> >> }
> >> za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
> >> "traitza_"]
> >> za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
> >> "traitza_"]
> >>  intercept = Sol[,"(Intercept)"]
> >> za_intercept = Sol[, za_intercept_name]
> >> l1 = Sol[, predictor ]
> >> l2 = Sol[, za_predictor ]
> >> if(is.list(object)) {
> >> intercept = unlist(intercept)
> >> za_intercept = unlist(za_intercept)
> >> l1 = unlist(l1)
> >> l2 = unlist(l2)
> >> }
> >>  py_0 = dpois(0, exp(intercept + za_intercept))
> >> y_ygt0 = exp(intercept)
> >> at_intercept = (1-py_0) * y_ygt0
> >>
> >> py_0 = dpois(0, exp(intercept + za_intercept + l2))
> >> y_ygt0 = exp(intercept +  l1)
> >> at_predictor_1 = (1-py_0) * y_ygt0
> >> print(qplot(at_intercept))
> >> print(qplot(at_predictor_1))
> >> df = data.frame("intercept" = at_intercept)
> >> df[, predictor] = at_predictor_1
> >> print(qplot(x=variable,
> >> y=value,data=suppressMessages(melt(df)),fill=variable,alpha=I(0.40),
> geom =
> >> 'violin'))
> >> print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
> >> print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
> >> invisible(df)
> >> }
> >>
> >>
> >> > summary(object[[1]])
> >>
> >>  Iterations = 100001:299901
> >>  Thinning interval  = 100
> >>  Sample size  = 2000
> >>
> >>  DIC: 349094
> >>
> >>  G-structure:  ~idh(trait):idParents
> >>
> >>                       post.mean l-95% CI u-95% CI eff.samp
> >> children.idParents       0.0189   0.0164   0.0214     1729
> >> za_children.idParents    0.2392   0.2171   0.2622     1647
> >>
> >>  R-structure:  ~idh(trait):units
> >>
> >>                   post.mean l-95% CI u-95% CI eff.samp
> >> children.units        0.144    0.139    0.148     1715
> >> za_children.units     1.000    1.000    1.000        0
> >>
> >>  Location effects: children ~ trait * (maternalage.factor +
> paternalloss +
> >> maternalloss + center(nr.siblings) + birth.cohort + urban + male +
> >> paternalage.mean + paternalage.diff)
> >>
> >>                                            post.mean  l-95% CI  u-95% CI
> >> eff.samp   pMCMC
> >> (Intercept)                                 2.088717  2.073009  2.103357
> >>   2000 <0.0005 ***
> >> traitza_children                           -1.933491 -1.981945 -1.887863
> >>   2000 <0.0005 ***
> >> maternalage.factor(14,20]                   0.007709 -0.014238  0.027883
> >>   1500   0.460
> >> maternalage.factor(35,50]                   0.006350 -0.009634  0.024107
> >>   2000   0.462
> >> paternallossTRUE                            0.000797 -0.022716  0.025015
> >>   2000   0.925
> >> maternallossTRUE                           -0.015542 -0.040240  0.009549
> >>   2000   0.226
> >> center(nr.siblings)                         0.005869  0.004302  0.007510
> >>   2000 <0.0005 ***
> >> birth.cohort(1703,1722]                    -0.045487 -0.062240 -0.028965
> >>   2000 <0.0005 ***
> >> birth.cohort(1722,1734]                    -0.055872 -0.072856 -0.036452
> >>   2000 <0.0005 ***
> >> birth.cohort(1734,1743]                    -0.039770 -0.056580 -0.020907
> >>   2000 <0.0005 ***
> >> birth.cohort(1743,1750]                    -0.030713 -0.048301 -0.012214
> >>   2000   0.002 **
> >> urban                                      -0.076748 -0.093240 -0.063002
> >>   2567 <0.0005 ***
> >> male                                        0.106074  0.095705  0.115742
> >>   2000 <0.0005 ***
> >> paternalage.mean                           -0.024119 -0.033133 -0.014444
> >>   2000 <0.0005 ***
> >> paternalage.diff                           -0.018367 -0.032083 -0.005721
> >>   2000   0.007 **
> >> traitza_children:maternalage.factor(14,20] -0.116510 -0.182432
> -0.051978
> >>   1876   0.001 ***
> >> traitza_children:maternalage.factor(35,50] -0.045196 -0.094485
> 0.002640
> >>   2000   0.075 .
> >> traitza_children:paternallossTRUE          -0.171957 -0.238218
> -0.104820
> >>   2000 <0.0005 ***
> >> traitza_children:maternallossTRUE          -0.499539 -0.566825
> -0.430637
> >>   2000 <0.0005 ***
> >> traitza_children:center(nr.siblings)       -0.023723 -0.028676
> -0.018746
> >>   1848 <0.0005 ***
> >> traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250
> 0.026024
> >>   2000   0.319
> >> traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462
> -0.227187
> >>   2000 <0.0005 ***
> >> traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659
> -0.204462
> >>   2130 <0.0005 ***
> >> traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568
> -0.426648
> >>   2000 <0.0005 ***
> >> traitza_children:urban                     -0.604108 -0.645169 -0.562554
> >>   1702 <0.0005 ***
> >> traitza_children:male                      -0.414988 -0.444589 -0.387005
> >>   2000 <0.0005 ***
> >> traitza_children:paternalage.mean           0.006545 -0.018570
> 0.036227
> >>   2000   0.651
> >> traitza_children:paternalage.diff          -0.097982 -0.136302
> -0.060677
> >>   2000 <0.0005 ***
> >>
> >>
> >> On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>> Ruben Arslan <rubenarslan at ...> writes:
> >>>
> >>> >
> >>> > Dear list,
> >>> >
> >>> > I wanted to ask: Is there any (maybe just back of the envelope) way
> to
> >>> > obtain a response prediction for zero-inflated or hurdle type models?
> >>> > I've fit such models in MCMCglmm, but I don't work in ecology and my
> >>> > previous experience with explaining such models to "my audience" did
> not
> >>> > bode well. When it comes to humans, the researchers I presented to
> are
> >>> not
> >>> > used to offspring count being zero-inflated (or acquainted with that
> >>> > concept), but in my historical data with high infant mortality, it is
> >>> (in
> >>> > modern data it's actually slightly underdispersed).
> >>> >
> >>> > Currently I'm using lme4 and simply splitting my models into two
> stages
> >>> > (finding a mate and having offspring).
> >>> > That's okay too, but in one population the effect of interest is not
> >>> > clearly visible in either stage, only when both are taken together
> (but
> >>> > then the outcome is zero-inflated).
> >>> > I expect to be given a hard time for this and hence thought I'd use a
> >>> > binomial model with the outcome offspring>0 as my main model, but
> that
> >>> > turns out to be hard to explain too and doesn't
> >>> > really do the data justice.
> >>> >
> >>> > Basically I don't want to be forced to discuss my smallest population
> >>> as a
> >>> > non-replication of the effect because I was insufficiently able to
> >>> explain
> >>> > the statistics behind my reasoning that the effect shows.
> >>>
> >>>   I think the back-of-the envelope answer would be that for a two-stage
> >>> model with a prediction of p_i for the probability of having a non-zero
> >>> response (or in the case of zero-inflated models, the probability of
> >>> _not_ having a structural zero) and a prediction of n_i for the
> >>> conditional
> >>> part of the model, the mean predicted value is p_i*n_i and the
> >>> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 +
> var(n_i)/n_i^2)
> >>> (this is assuming
> >>> that you haven't built in any correlation between p_i and n_i, which
> >>> would be hard in lme4 but _might_ be possible under certain
> circumstances
> >>> via a multitype model in MCMCglmm).
> >>>
> >>>   Does that help?
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>

	[[alternative HTML version deleted]]


From rubenarslan at gmail.com  Tue Mar 17 20:21:06 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Tue, 17 Mar 2015 19:21:06 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <CALv3xzuKdax26=sdMRTj16we9-UsWbF4y7bo_5rkwXcky1WR6Q@mail.gmail.com>
References: <loom.20150309T220710-595@post.gmane.org>
	<CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
	<CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>
	<20150317163112.14195p92nh01nwso@www.staffmail.ed.ac.uk>
	<CALv3xzuKdax26=sdMRTj16we9-UsWbF4y7bo_5rkwXcky1WR6Q@mail.gmail.com>
Message-ID: <CALv3xzu4UDx=NaotMmp_UZwQiX-3Bgmcbo=57auyRO+hQuQX_w@mail.gmail.com>

Hi,

two more questions, sorry.

6.
could it be that where you wrote
normal.evd<-function(x, mu, v){
exp(-exp(x))*dnorm(x, mu, sqrt(v))
}

you're not actually passing the variance but the standard deviation? so the
functions should be

normal.evd<-function(x, mu, sd){
exp(-exp(x))*dnorm(x, mu, sd)
}
normal.zt<-function(x, mu, sd){
exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sd)
}

Because at least in the example, you were taking the square root here
already: sd_1<-mean(sqrt(m1$VCV[,1]))
Maybe this was a copy-paste from the source where you do it differently? Or
I misunderstood...

An addition to question 5:
5. When I use the correct inverse link function in my old code, but don't
do double integration, I do get a "reasonable" amount of uncertainty around
the reference factor. The predicted means are too low, which I put down to
this approach ignoring the VCV. I was just wondering how this could happen
(actually seeing the "reasonable" amount of uncertainty was what made me
hopeful that my approach might not be entirely wrong).

Best,

Ruben


On Tue, Mar 17, 2015 at 7:53 PM Ruben Arslan <rubenarslan at gmail.com> wrote:

> Hi Jarrod,
>
> thanks for the extensive reply! This helps a lot, though it sounds like I
> was hubristic to attempt this myself.
> I tried using the approach you mapped out in the function gist
> <https://gist.github.com/rubenarslan/aeacdd306b3d061819a6> I posted. I
> simply put the pred function in a loop, so that I wouldn't make any
> mistakes while vectorising and since I don't care about performance at this
> point.
>
> Of course, I have some follow up questions though.. I'm sorry if I'm being
> a pain, I really appreciate the free advice, but understand of course if
> other things take precedence.
>
> 1. You're not "down with" developing publicly are you? Because I sure
> would like to test-drive the newdata prediction and simulation functions..
>
> 2. Could you make sure that I got this right: "When predictions are to be
> taken after marginalising the random effects (including the `residual'
> over-dispersion) it is not possible to obtain closed form expressions."
> That is basically my scenario, right? In the example I included, I also
> had a group-level random effect (family). Ore are you talking about the
> "trait" as the random effect (as in your example) and my scenario is
> different and I cannot apply the numerical double integration procedure you
> posted?
> To be clear about my prediction goal without using language that I might
> be using incorrectly: I want to show what the average effect in the
> response unit, number of children, is in my population(s). I have data on
> whole populations and am using all of it (except individuals that don't
> have completed fertility yet, because I have yet to find a way to model
> both zero-inflation and right censoring).
>
> 3. "Numerical integration could be extended to double integration in
> which case covariance between the Poisson part and the binary part could
> be handled." That is what you posted an example of and it applies to my
> scenario, because I specified a prior R=list(V=diag(2), nu=1.002, fix=2)
> and rcov=~idh(trait):units, random=~idh(trait):idParents?
> But this double integration approach is something you just wrote
> off-the-cuff and I probably shouldn't use it in a publication? Or is this
> in the forthcoming MCMCglmm release and I might actually be able to refer
> to it once I get to submitting?
>
> 4. Could I change my model specification to forbid covariance between the
> two parts and not shoot myself in the foot? Would this allow for a more
> valid/tested approach to prediction?
>
> 5. When I use your method on my real data, I get less variation around the
> prediction "for the reference level" than for all other factor levels.
> My reference level actually has fewer cases than the others, so this
> isn't "right" in a way.
> Is this because I'm not doing newdata prediction? I get the "right"
> looking uncertainty if I bootstrap newdata predictions in lme4,
> Sorry if this is children's logic :-)
> Here's an image of the prediction
> <http://rpubs.com/rubenarslan/mcmcglmm_pred> and the raw data
> <http://rpubs.com/rubenarslan/raw>.
>
> Many thanks for any answers that you feel inclined to give.
>
> Best wishes,
>
> Ruben
>
> On Tue, Mar 17, 2015 at 5:31 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi,
>>
>> Sorry - I should have replied to this post earlier. I've been working
>> on predict/simulate methods for all MCMcglmm models (including
>> zero-inflated/altered/hurdle/truncated models) and these are now
>> largely complete (together with newdata options).
>>
>> When predictions are to be taken after marginalising the random
>> effects (including the `residual' over-dispersion) it is not possible
>> to obtain closed form expressions. The options that will be available
>> in MCMCglmm are:
>>
>> 1) algebraic approximation
>> 2) numerical integration
>> 3) simulation
>>
>> 1) and 2) are currently only accurate when the random/residual effect
>> structure implies no covariance between the Poisson part and the
>> binary part.
>>
>> 1) is reasonably accurate for zero-inflated distributions, but can be
>> pretty poor for the remainder because they all involve zero-truncated
>> Poisson log-normal distributions and my taylor approximation for the
>> mean is less than ideal (any suggestions would be helpful).
>>
>> 2) could be extended to double integration in which case covariance
>> between the Poisson part and the binary part could be handled.
>>
>> In your code, part of the problem is that you have fitted a zapoisson,
>> but the prediction is based on a zipoisson (with complementary log-log
>> link rather than logt link).
>>
>> In all zero-inflated/altered/hurdle/truncated models
>>
>> E[y] = E[(1-prob)*meanc]
>>
>> where prob is the probabilty of a zero in the binary part and meanc is
>> the mean of a Poisson distribution (zipoisson) or a zero-truncated
>> poisson (zapoisson and hupoisson). If we have eta_1 as the linear
>> predictor for the poisson part and eta_2 as the linear predictor for
>> the binary part:
>>
>> In zipoisson: prob = plogis(eta_2)     and meanc = exp(eta_1)
>> In zapoisson: prob = exp(-exp(eta_2))  and meanc =
>> exp(eta_1)/(1-exp(-exp(eta_1)))
>> In hupoisson: prob = plogis(eta_2)     and meanc =
>> exp(eta_1)/(1-exp(-exp(eta_1)))
>> In ztpoisson: prob = 0                 and meanc =
>> exp(eta_1)/(1-exp(-exp(eta_1)))
>>
>> In each case the linear predictor has a `fixed' part and a `random'
>> part which I'll denote as `a' and `u' respectively. Ideally we would
>> want
>>
>> E[(1-prob)*meanc] taken over u_1 & u_2
>>
>> if prob and meanc are independent this is a bit easier as
>>
>> E[y] = E[1-prob]E[meanc]
>>
>> and the two expectations ony need to taken with repsect to their
>> respective random effects. If we have sd_1 and sd_2 as the standard
>> deviations of the two sets of random effects then for the zapoisson:
>>
>>    normal.evd<-function(x, mu, v){
>>       exp(-exp(x))*dnorm(x, mu, sqrt(v))
>>    }
>>    normal.zt<-function(x, mu, v){
>>      exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sqrt(v))
>>    }
>>
>>    pred<-function(a_1, a_2, sd_1, sd_2){
>>      prob<-1-integrate(normal.evd, qnorm(0.0001, a_2,sd_2),
>> qnorm(0.9999, a_2,sd_2), a_2,sd_2)[[1]]
>>      meanc<-integrate(normal.zt, qnorm(0.0001, a_1,sd_1),
>> qnorm(0.9999, a_1,sd_1), a_1,sd_1)[[1]]
>>      prob*meanc
>>    }
>>
>> #  gives the expected value with reasonable accuracy.  As an example:
>>
>>    x<-rnorm(300)
>>    l1<-rnorm(300, 1/2+x, sqrt(1))
>>    l2<-rnorm(300, 1-x, sqrt(1))
>>
>>    y<-rbinom(300, 1, 1-exp(-exp(l2)))
>>    y[which(y==1)]<-qpois(runif(sum(y==1), dpois(0,
>> exp(l1[which(y==1)])), 1), exp(l1[which(y==1)]))
>>    # cunning sampler from Peter Dalgaard (R-sig-mixed)
>>
>>    data=data.frame(y=y, x=x)
>>    prior=list(R=list(V=diag(2), nu=0.002, fix=2))
>>
>>    m1<-MCMCglmm(y~trait+trait:x-1, rcov=~idh(trait):units, data=data,
>> family="zapoisson", prior=prior)
>>
>>    b_1<-colMeans(m1$Sol)[c(1,3)]
>>    b_2<-colMeans(m1$Sol)[c(2,4)]
>>    sd_1<-mean(sqrt(m1$VCV[,1]))
>>    sd_2<-mean(sqrt(m1$VCV[,2]))
>>
>>    # note it is more accurate to take the posterior mean prediction
>> rather than the prediction from the posterior means as I've done here,
>> but for illustration:
>>
>>    x.pred<-seq(-3,3,length=100)
>>    p<-1:100
>>    for(i in 1:100){
>>      p[i]<-pred(a_1 = b_1[1]+x.pred[i]*b_1[2], a_2 =
>> b_2[1]+x.pred[i]*b_2[2], sd_1=sd_1, sd_2=sd_2)
>>    }
>>
>>    plot(y~x)
>>    lines(p~x.pred)
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015
>> 13:33:25 +0000:
>>
>> > Dear list,
>> >
>> > I've made a reproducible example of the zero-altered prediction,
>> > in the hope that someone will have a look and reassure me that I'm going
>> > about this the right way.
>> > I was a bit confused by the point about p_i and n_i being correlated
>> (they
>> > are in my case), but I think this was a red herring for me
>> > since I'm not deriving the variance analytically.
>> > The script is here: https://gist.github.com/rubenarslan/
>> aeacdd306b3d061819a6
>> > and if you don't want to run the simulation fit yourself, I've put an
>> RDS
>> > file of the fit here:
>> > https://dl.dropboxusercontent.com/u/1078620/m1.rds
>> >
>> > Best regards,
>> >
>> > Ruben Arslan
>> >
>> > On Tue, Mar 10, 2015 at 1:22 PM Ruben Arslan <rubenarslan at gmail.com>
>> wrote:
>> >
>> >> Dear Dr Bolker,
>> >>
>> >> I'd thought about something like this, one point of asking was to
>> >> see whether
>> >> a) it's implemented already, because I'll probably make dumb mistakes
>> while
>> >> trying b) it's not implemented because it's a bad idea.
>> >> Your response and the MCMCglmm course notes make me hope that it's c)
>> not
>> >> implemented because nobody did yet or d) it's so simple that everybody
>> does
>> >> it on-the-fly.
>> >>
>> >> So I tried my hand and would appreciate corrections. I am sure there is
>> >> some screw-up or an inelegant approach in there.
>> >> I included code for dealing with mcmc.lists because that's what I have
>> and
>> >> I'm not entirely sure how I deal with them is correct either.
>> >>
>> >> I started with a zero-altered model, because those fit fastest and
>> >> according to the course notes have the least complex likelihood.
>> >> Because I know not what I do, I'm not dealing with my random effects at
>> >> all.
>> >>
>> >> I pasted a model summary below to show what I've applied the below
>> >> function to. The function gives the following quantiles when applied
>> to 19
>> >> chains of that model.
>> >>          5%         50%         95%
>> >> 5.431684178 5.561211207 5.690655200
>> >>          5%         50%         95%
>> >> 5.003974382 5.178192327 5.348246558
>> >>
>> >> Warm regards,
>> >>
>> >> Ruben Arslan
>> >>
>> >> HPDpredict_za = function(object, predictor) {
>> >>
>> >> if(class(object) != "MCMCglmm") {
>> >> if(length( object[[1]]$Residual$nrt )>1) {
>> >> object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
>> >> }
>> >> Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
>> >> vars = colnames(Sol[[1]])
>> >> } else {
>> >> Sol = as.data.frame(object$Sol)
>> >> vars = names(Sol)
>> >> }
>> >> za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
>> >> "traitza_"]
>> >> za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
>> >> "traitza_"]
>> >>  intercept = Sol[,"(Intercept)"]
>> >> za_intercept = Sol[, za_intercept_name]
>> >> l1 = Sol[, predictor ]
>> >> l2 = Sol[, za_predictor ]
>> >> if(is.list(object)) {
>> >> intercept = unlist(intercept)
>> >> za_intercept = unlist(za_intercept)
>> >> l1 = unlist(l1)
>> >> l2 = unlist(l2)
>> >> }
>> >>  py_0 = dpois(0, exp(intercept + za_intercept))
>> >> y_ygt0 = exp(intercept)
>> >> at_intercept = (1-py_0) * y_ygt0
>> >>
>> >> py_0 = dpois(0, exp(intercept + za_intercept + l2))
>> >> y_ygt0 = exp(intercept +  l1)
>> >> at_predictor_1 = (1-py_0) * y_ygt0
>> >> print(qplot(at_intercept))
>> >> print(qplot(at_predictor_1))
>> >> df = data.frame("intercept" = at_intercept)
>> >> df[, predictor] = at_predictor_1
>> >> print(qplot(x=variable,
>> >> y=value,data=suppressMessages(melt(df)),fill=variable,alpha=I(0.40),
>> geom =
>> >> 'violin'))
>> >> print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
>> >> print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
>> >> invisible(df)
>> >> }
>> >>
>> >>
>> >> > summary(object[[1]])
>> >>
>> >>  Iterations = 100001:299901
>> >>  Thinning interval  = 100
>> >>  Sample size  = 2000
>> >>
>> >>  DIC: 349094
>> >>
>> >>  G-structure:  ~idh(trait):idParents
>> >>
>> >>                       post.mean l-95% CI u-95% CI eff.samp
>> >> children.idParents       0.0189   0.0164   0.0214     1729
>> >> za_children.idParents    0.2392   0.2171   0.2622     1647
>> >>
>> >>  R-structure:  ~idh(trait):units
>> >>
>> >>                   post.mean l-95% CI u-95% CI eff.samp
>> >> children.units        0.144    0.139    0.148     1715
>> >> za_children.units     1.000    1.000    1.000        0
>> >>
>> >>  Location effects: children ~ trait * (maternalage.factor +
>> paternalloss +
>> >> maternalloss + center(nr.siblings) + birth.cohort + urban + male +
>> >> paternalage.mean + paternalage.diff)
>> >>
>> >>                                            post.mean  l-95% CI  u-95%
>> CI
>> >> eff.samp   pMCMC
>> >> (Intercept)                                 2.088717  2.073009
>> 2.103357
>> >>   2000 <0.0005 ***
>> >> traitza_children                           -1.933491 -1.981945
>> -1.887863
>> >>   2000 <0.0005 ***
>> >> maternalage.factor(14,20]                   0.007709 -0.014238
>> 0.027883
>> >>   1500   0.460
>> >> maternalage.factor(35,50]                   0.006350 -0.009634
>> 0.024107
>> >>   2000   0.462
>> >> paternallossTRUE                            0.000797 -0.022716
>> 0.025015
>> >>   2000   0.925
>> >> maternallossTRUE                           -0.015542 -0.040240
>> 0.009549
>> >>   2000   0.226
>> >> center(nr.siblings)                         0.005869  0.004302
>> 0.007510
>> >>   2000 <0.0005 ***
>> >> birth.cohort(1703,1722]                    -0.045487 -0.062240
>> -0.028965
>> >>   2000 <0.0005 ***
>> >> birth.cohort(1722,1734]                    -0.055872 -0.072856
>> -0.036452
>> >>   2000 <0.0005 ***
>> >> birth.cohort(1734,1743]                    -0.039770 -0.056580
>> -0.020907
>> >>   2000 <0.0005 ***
>> >> birth.cohort(1743,1750]                    -0.030713 -0.048301
>> -0.012214
>> >>   2000   0.002 **
>> >> urban                                      -0.076748 -0.093240
>> -0.063002
>> >>   2567 <0.0005 ***
>> >> male                                        0.106074  0.095705
>> 0.115742
>> >>   2000 <0.0005 ***
>> >> paternalage.mean                           -0.024119 -0.033133
>> -0.014444
>> >>   2000 <0.0005 ***
>> >> paternalage.diff                           -0.018367 -0.032083
>> -0.005721
>> >>   2000   0.007 **
>> >> traitza_children:maternalage.factor(14,20] -0.116510 -0.182432
>> -0.051978
>> >>   1876   0.001 ***
>> >> traitza_children:maternalage.factor(35,50] -0.045196 -0.094485
>> 0.002640
>> >>   2000   0.075 .
>> >> traitza_children:paternallossTRUE          -0.171957 -0.238218
>> -0.104820
>> >>   2000 <0.0005 ***
>> >> traitza_children:maternallossTRUE          -0.499539 -0.566825
>> -0.430637
>> >>   2000 <0.0005 ***
>> >> traitza_children:center(nr.siblings)       -0.023723 -0.028676
>> -0.018746
>> >>   1848 <0.0005 ***
>> >> traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250
>> 0.026024
>> >>   2000   0.319
>> >> traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462
>> -0.227187
>> >>   2000 <0.0005 ***
>> >> traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659
>> -0.204462
>> >>   2130 <0.0005 ***
>> >> traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568
>> -0.426648
>> >>   2000 <0.0005 ***
>> >> traitza_children:urban                     -0.604108 -0.645169
>> -0.562554
>> >>   1702 <0.0005 ***
>> >> traitza_children:male                      -0.414988 -0.444589
>> -0.387005
>> >>   2000 <0.0005 ***
>> >> traitza_children:paternalage.mean           0.006545 -0.018570
>> 0.036227
>> >>   2000   0.651
>> >> traitza_children:paternalage.diff          -0.097982 -0.136302
>> -0.060677
>> >>   2000 <0.0005 ***
>> >>
>> >>
>> >> On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com> wrote:
>> >>
>> >>> Ruben Arslan <rubenarslan at ...> writes:
>> >>>
>> >>> >
>> >>> > Dear list,
>> >>> >
>> >>> > I wanted to ask: Is there any (maybe just back of the envelope) way
>> to
>> >>> > obtain a response prediction for zero-inflated or hurdle type
>> models?
>> >>> > I've fit such models in MCMCglmm, but I don't work in ecology and my
>> >>> > previous experience with explaining such models to "my audience"
>> did not
>> >>> > bode well. When it comes to humans, the researchers I presented to
>> are
>> >>> not
>> >>> > used to offspring count being zero-inflated (or acquainted with that
>> >>> > concept), but in my historical data with high infant mortality, it
>> is
>> >>> (in
>> >>> > modern data it's actually slightly underdispersed).
>> >>> >
>> >>> > Currently I'm using lme4 and simply splitting my models into two
>> stages
>> >>> > (finding a mate and having offspring).
>> >>> > That's okay too, but in one population the effect of interest is not
>> >>> > clearly visible in either stage, only when both are taken together
>> (but
>> >>> > then the outcome is zero-inflated).
>> >>> > I expect to be given a hard time for this and hence thought I'd use
>> a
>> >>> > binomial model with the outcome offspring>0 as my main model, but
>> that
>> >>> > turns out to be hard to explain too and doesn't
>> >>> > really do the data justice.
>> >>> >
>> >>> > Basically I don't want to be forced to discuss my smallest
>> population
>> >>> as a
>> >>> > non-replication of the effect because I was insufficiently able to
>> >>> explain
>> >>> > the statistics behind my reasoning that the effect shows.
>> >>>
>> >>>   I think the back-of-the envelope answer would be that for a
>> two-stage
>> >>> model with a prediction of p_i for the probability of having a
>> non-zero
>> >>> response (or in the case of zero-inflated models, the probability of
>> >>> _not_ having a structural zero) and a prediction of n_i for the
>> >>> conditional
>> >>> part of the model, the mean predicted value is p_i*n_i and the
>> >>> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 +
>> var(n_i)/n_i^2)
>> >>> (this is assuming
>> >>> that you haven't built in any correlation between p_i and n_i, which
>> >>> would be hard in lme4 but _might_ be possible under certain
>> circumstances
>> >>> via a multitype model in MCMCglmm).
>> >>>
>> >>>   Does that help?
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Mar 18 07:03:50 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 18 Mar 2015 06:03:50 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <CALv3xzuKdax26=sdMRTj16we9-UsWbF4y7bo_5rkwXcky1WR6Q@mail.gmail.com>
References: <loom.20150309T220710-595@post.gmane.org>
	<CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
	<CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>
	<20150317163112.14195p92nh01nwso@www.staffmail.ed.ac.uk>
	<CALv3xzuKdax26=sdMRTj16we9-UsWbF4y7bo_5rkwXcky1WR6Q@mail.gmail.com>
Message-ID: <20150318060350.17916452yhk805s8@www.staffmail.ed.ac.uk>

Hi,

1/ I have no problem with it - I'm just lazy about it.

2/ This is the case for all GLMM. In your case you have two sources of  
variation to average over: family effects and units  
(observation-level) effects. However, they are independent of each  
other and so you can replace (for example) u_1 with family_1+units_1  
and v_1 with v_family+v_units.

3/ In your model the zero-alteration and the Poisson process are  
treated as independent as you use an idh structure. Here, the  
covariance is set to zero. You could use an us structure which would  
then allow a non-zero covariance between family effects (the  
covariance is not identifiable at the units level). I did not post a  
double integration example, the integration was of the form


int_{u_{1}} 1-prob d_{u_{1}} * int_{u_{2}} meanc d_{u_{2}}

Double integration would involve

int_{u_{1}}int_{u_{2}} (1-prob)*meanc d_{u_{2}}d_{u_{1}}

For example with have a = [a_{1}, a_{2}]'  and V the covariance matrix  
of random effects.


library(mvtnorm)
library(cubature)

normal.zap<-function(x, mu, V){
  (1-exp(-exp(x[2])))*dmvnorm(x, mu, V)*exp(x[1])/(1-exp(-exp(x[1])))
}

pred2<-function(a,V){

  low1<-qnorm(0.0001, a[1],sqrt(V[1,1]))
  upp1<-qnorm(0.9999, a[1],sqrt(V[1,1]))
  low2<-qnorm(0.0001, a[2],sqrt(V[2,2]))
  upp2<-qnorm(0.9999, a[2],sqrt(V[2,2]))

  adaptIntegrate(normal.zap, c(low1,low2),c(upp1,upp2), mu=a, V=V)$integral

}


a<-runif(2)
V<-diag(2)

pred2(a,V)


should give the same answer as pred when V is diagonal (after fixing  
my mistakes in the last post). The forthcoming version of MCMCglmm  
just has the single integration method, but I guess I could also put  
this into the next version too.


4/ Currently you have zero covariances, but if you think they exist I  
would model them. Remember, that a nice feature of zap models is that  
the standard Poisson model is a special case. In terms of random  
effects, this occurs when the correlation between family effects for  
the two processes is 1 (i.e. fit ~family, rather than  
idh(trait):family).

5/ I'm not sure I understand the question. The uncertainty here is  
arising because of uncertainty in the parameters of the model? If so,  
possibilities are that i) there is more information for the reference  
level because other levels are more confounded with other predictors  
in the model ii) the reference level is associated with larger  
outcomes and so the same change on the link scale generates larger  
differences on the data scale.

Cheers,

Jarrod




Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015  
18:53:33 +0000:

> Hi Jarrod,
>
> thanks for the extensive reply! This helps a lot, though it sounds like I
> was hubristic to attempt this myself.
> I tried using the approach you mapped out in the function gist
> <https://gist.github.com/rubenarslan/aeacdd306b3d061819a6> I posted. I
> simply put the pred function in a loop, so that I wouldn't make any
> mistakes while vectorising and since I don't care about performance at this
> point.
>
> Of course, I have some follow up questions though.. I'm sorry if I'm being
> a pain, I really appreciate the free advice, but understand of course if
> other things take precedence.
>
> 1. You're not "down with" developing publicly are you? Because I sure would
> like to test-drive the newdata prediction and simulation functions..
>
> 2. Could you make sure that I got this right: "When predictions are to be
> taken after marginalising the random effects (including the `residual'
> over-dispersion) it is not possible to obtain closed form expressions."
> That is basically my scenario, right? In the example I included, I also had
> a group-level random effect (family). Ore are you talking about the "trait"
> as the random effect (as in your example) and my scenario is different and
> I cannot apply the numerical double integration procedure you posted?
> To be clear about my prediction goal without using language that I might be
> using incorrectly: I want to show what the average effect in the response
> unit, number of children, is in my population(s). I have data on whole
> populations and am using all of it (except individuals that don't have
> completed fertility yet, because I have yet to find a way to model both
> zero-inflation and right censoring).
>
> 3. "Numerical integration could be extended to double integration in which
> case covariance between the Poisson part and the binary part could be
> handled." That is what you posted an example of and it applies to my
> scenario, because I specified a prior R=list(V=diag(2), nu=1.002, fix=2)
> and rcov=~idh(trait):units, random=~idh(trait):idParents?
> But this double integration approach is something you just wrote
> off-the-cuff and I probably shouldn't use it in a publication? Or is this
> in the forthcoming MCMCglmm release and I might actually be able to refer
> to it once I get to submitting?
>
> 4. Could I change my model specification to forbid covariance between the
> two parts and not shoot myself in the foot? Would this allow for a more
> valid/tested approach to prediction?
>
> 5. When I use your method on my real data, I get less variation around the
> prediction "for the reference level" than for all other factor levels.
> My reference level actually has fewer cases than the others, so this isn't
> "right" in a way.
> Is this because I'm not doing newdata prediction? I get the "right" looking
> uncertainty if I bootstrap newdata predictions in lme4,
> Sorry if this is children's logic :-)
> Here's an image of the prediction
> <http://rpubs.com/rubenarslan/mcmcglmm_pred> and the raw data
> <http://rpubs.com/rubenarslan/raw>.
>
> Many thanks for any answers that you feel inclined to give.
>
> Best wishes,
>
> Ruben
>
> On Tue, Mar 17, 2015 at 5:31 PM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi,
>>
>> Sorry - I should have replied to this post earlier. I've been working
>> on predict/simulate methods for all MCMcglmm models (including
>> zero-inflated/altered/hurdle/truncated models) and these are now
>> largely complete (together with newdata options).
>>
>> When predictions are to be taken after marginalising the random
>> effects (including the `residual' over-dispersion) it is not possible
>> to obtain closed form expressions. The options that will be available
>> in MCMCglmm are:
>>
>> 1) algebraic approximation
>> 2) numerical integration
>> 3) simulation
>>
>> 1) and 2) are currently only accurate when the random/residual effect
>> structure implies no covariance between the Poisson part and the
>> binary part.
>>
>> 1) is reasonably accurate for zero-inflated distributions, but can be
>> pretty poor for the remainder because they all involve zero-truncated
>> Poisson log-normal distributions and my taylor approximation for the
>> mean is less than ideal (any suggestions would be helpful).
>>
>> 2) could be extended to double integration in which case covariance
>> between the Poisson part and the binary part could be handled.
>>
>> In your code, part of the problem is that you have fitted a zapoisson,
>> but the prediction is based on a zipoisson (with complementary log-log
>> link rather than logt link).
>>
>> In all zero-inflated/altered/hurdle/truncated models
>>
>> E[y] = E[(1-prob)*meanc]
>>
>> where prob is the probabilty of a zero in the binary part and meanc is
>> the mean of a Poisson distribution (zipoisson) or a zero-truncated
>> poisson (zapoisson and hupoisson). If we have eta_1 as the linear
>> predictor for the poisson part and eta_2 as the linear predictor for
>> the binary part:
>>
>> In zipoisson: prob = plogis(eta_2)     and meanc = exp(eta_1)
>> In zapoisson: prob = exp(-exp(eta_2))  and meanc =
>> exp(eta_1)/(1-exp(-exp(eta_1)))
>> In hupoisson: prob = plogis(eta_2)     and meanc =
>> exp(eta_1)/(1-exp(-exp(eta_1)))
>> In ztpoisson: prob = 0                 and meanc =
>> exp(eta_1)/(1-exp(-exp(eta_1)))
>>
>> In each case the linear predictor has a `fixed' part and a `random'
>> part which I'll denote as `a' and `u' respectively. Ideally we would
>> want
>>
>> E[(1-prob)*meanc] taken over u_1 & u_2
>>
>> if prob and meanc are independent this is a bit easier as
>>
>> E[y] = E[1-prob]E[meanc]
>>
>> and the two expectations ony need to taken with repsect to their
>> respective random effects. If we have sd_1 and sd_2 as the standard
>> deviations of the two sets of random effects then for the zapoisson:
>>
>>    normal.evd<-function(x, mu, v){
>>       exp(-exp(x))*dnorm(x, mu, sqrt(v))
>>    }
>>    normal.zt<-function(x, mu, v){
>>      exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sqrt(v))
>>    }
>>
>>    pred<-function(a_1, a_2, sd_1, sd_2){
>>      prob<-1-integrate(normal.evd, qnorm(0.0001, a_2,sd_2),
>> qnorm(0.9999, a_2,sd_2), a_2,sd_2)[[1]]
>>      meanc<-integrate(normal.zt, qnorm(0.0001, a_1,sd_1),
>> qnorm(0.9999, a_1,sd_1), a_1,sd_1)[[1]]
>>      prob*meanc
>>    }
>>
>> #  gives the expected value with reasonable accuracy.  As an example:
>>
>>    x<-rnorm(300)
>>    l1<-rnorm(300, 1/2+x, sqrt(1))
>>    l2<-rnorm(300, 1-x, sqrt(1))
>>
>>    y<-rbinom(300, 1, 1-exp(-exp(l2)))
>>    y[which(y==1)]<-qpois(runif(sum(y==1), dpois(0,
>> exp(l1[which(y==1)])), 1), exp(l1[which(y==1)]))
>>    # cunning sampler from Peter Dalgaard (R-sig-mixed)
>>
>>    data=data.frame(y=y, x=x)
>>    prior=list(R=list(V=diag(2), nu=0.002, fix=2))
>>
>>    m1<-MCMCglmm(y~trait+trait:x-1, rcov=~idh(trait):units, data=data,
>> family="zapoisson", prior=prior)
>>
>>    b_1<-colMeans(m1$Sol)[c(1,3)]
>>    b_2<-colMeans(m1$Sol)[c(2,4)]
>>    sd_1<-mean(sqrt(m1$VCV[,1]))
>>    sd_2<-mean(sqrt(m1$VCV[,2]))
>>
>>    # note it is more accurate to take the posterior mean prediction
>> rather than the prediction from the posterior means as I've done here,
>> but for illustration:
>>
>>    x.pred<-seq(-3,3,length=100)
>>    p<-1:100
>>    for(i in 1:100){
>>      p[i]<-pred(a_1 = b_1[1]+x.pred[i]*b_1[2], a_2 =
>> b_2[1]+x.pred[i]*b_2[2], sd_1=sd_1, sd_2=sd_2)
>>    }
>>
>>    plot(y~x)
>>    lines(p~x.pred)
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015
>> 13:33:25 +0000:
>>
>> > Dear list,
>> >
>> > I've made a reproducible example of the zero-altered prediction,
>> > in the hope that someone will have a look and reassure me that I'm going
>> > about this the right way.
>> > I was a bit confused by the point about p_i and n_i being correlated
>> (they
>> > are in my case), but I think this was a red herring for me
>> > since I'm not deriving the variance analytically.
>> > The script is here: https://gist.github.com/rubenarslan/
>> aeacdd306b3d061819a6
>> > and if you don't want to run the simulation fit yourself, I've put an RDS
>> > file of the fit here:
>> > https://dl.dropboxusercontent.com/u/1078620/m1.rds
>> >
>> > Best regards,
>> >
>> > Ruben Arslan
>> >
>> > On Tue, Mar 10, 2015 at 1:22 PM Ruben Arslan <rubenarslan at gmail.com>
>> wrote:
>> >
>> >> Dear Dr Bolker,
>> >>
>> >> I'd thought about something like this, one point of asking was to
>> >> see whether
>> >> a) it's implemented already, because I'll probably make dumb mistakes
>> while
>> >> trying b) it's not implemented because it's a bad idea.
>> >> Your response and the MCMCglmm course notes make me hope that it's c)
>> not
>> >> implemented because nobody did yet or d) it's so simple that everybody
>> does
>> >> it on-the-fly.
>> >>
>> >> So I tried my hand and would appreciate corrections. I am sure there is
>> >> some screw-up or an inelegant approach in there.
>> >> I included code for dealing with mcmc.lists because that's what I have
>> and
>> >> I'm not entirely sure how I deal with them is correct either.
>> >>
>> >> I started with a zero-altered model, because those fit fastest and
>> >> according to the course notes have the least complex likelihood.
>> >> Because I know not what I do, I'm not dealing with my random effects at
>> >> all.
>> >>
>> >> I pasted a model summary below to show what I've applied the below
>> >> function to. The function gives the following quantiles when applied to
>> 19
>> >> chains of that model.
>> >>          5%         50%         95%
>> >> 5.431684178 5.561211207 5.690655200
>> >>          5%         50%         95%
>> >> 5.003974382 5.178192327 5.348246558
>> >>
>> >> Warm regards,
>> >>
>> >> Ruben Arslan
>> >>
>> >> HPDpredict_za = function(object, predictor) {
>> >>
>> >> if(class(object) != "MCMCglmm") {
>> >> if(length( object[[1]]$Residual$nrt )>1) {
>> >> object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
>> >> }
>> >> Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
>> >> vars = colnames(Sol[[1]])
>> >> } else {
>> >> Sol = as.data.frame(object$Sol)
>> >> vars = names(Sol)
>> >> }
>> >> za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
>> >> "traitza_"]
>> >> za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
>> >> "traitza_"]
>> >>  intercept = Sol[,"(Intercept)"]
>> >> za_intercept = Sol[, za_intercept_name]
>> >> l1 = Sol[, predictor ]
>> >> l2 = Sol[, za_predictor ]
>> >> if(is.list(object)) {
>> >> intercept = unlist(intercept)
>> >> za_intercept = unlist(za_intercept)
>> >> l1 = unlist(l1)
>> >> l2 = unlist(l2)
>> >> }
>> >>  py_0 = dpois(0, exp(intercept + za_intercept))
>> >> y_ygt0 = exp(intercept)
>> >> at_intercept = (1-py_0) * y_ygt0
>> >>
>> >> py_0 = dpois(0, exp(intercept + za_intercept + l2))
>> >> y_ygt0 = exp(intercept +  l1)
>> >> at_predictor_1 = (1-py_0) * y_ygt0
>> >> print(qplot(at_intercept))
>> >> print(qplot(at_predictor_1))
>> >> df = data.frame("intercept" = at_intercept)
>> >> df[, predictor] = at_predictor_1
>> >> print(qplot(x=variable,
>> >> y=value,data=suppressMessages(melt(df)),fill=variable,alpha=I(0.40),
>> geom =
>> >> 'violin'))
>> >> print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
>> >> print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
>> >> invisible(df)
>> >> }
>> >>
>> >>
>> >> > summary(object[[1]])
>> >>
>> >>  Iterations = 100001:299901
>> >>  Thinning interval  = 100
>> >>  Sample size  = 2000
>> >>
>> >>  DIC: 349094
>> >>
>> >>  G-structure:  ~idh(trait):idParents
>> >>
>> >>                       post.mean l-95% CI u-95% CI eff.samp
>> >> children.idParents       0.0189   0.0164   0.0214     1729
>> >> za_children.idParents    0.2392   0.2171   0.2622     1647
>> >>
>> >>  R-structure:  ~idh(trait):units
>> >>
>> >>                   post.mean l-95% CI u-95% CI eff.samp
>> >> children.units        0.144    0.139    0.148     1715
>> >> za_children.units     1.000    1.000    1.000        0
>> >>
>> >>  Location effects: children ~ trait * (maternalage.factor +
>> paternalloss +
>> >> maternalloss + center(nr.siblings) + birth.cohort + urban + male +
>> >> paternalage.mean + paternalage.diff)
>> >>
>> >>                                            post.mean  l-95% CI  u-95% CI
>> >> eff.samp   pMCMC
>> >> (Intercept)                                 2.088717  2.073009  2.103357
>> >>   2000 <0.0005 ***
>> >> traitza_children                           -1.933491 -1.981945 -1.887863
>> >>   2000 <0.0005 ***
>> >> maternalage.factor(14,20]                   0.007709 -0.014238  0.027883
>> >>   1500   0.460
>> >> maternalage.factor(35,50]                   0.006350 -0.009634  0.024107
>> >>   2000   0.462
>> >> paternallossTRUE                            0.000797 -0.022716  0.025015
>> >>   2000   0.925
>> >> maternallossTRUE                           -0.015542 -0.040240  0.009549
>> >>   2000   0.226
>> >> center(nr.siblings)                         0.005869  0.004302  0.007510
>> >>   2000 <0.0005 ***
>> >> birth.cohort(1703,1722]                    -0.045487 -0.062240 -0.028965
>> >>   2000 <0.0005 ***
>> >> birth.cohort(1722,1734]                    -0.055872 -0.072856 -0.036452
>> >>   2000 <0.0005 ***
>> >> birth.cohort(1734,1743]                    -0.039770 -0.056580 -0.020907
>> >>   2000 <0.0005 ***
>> >> birth.cohort(1743,1750]                    -0.030713 -0.048301 -0.012214
>> >>   2000   0.002 **
>> >> urban                                      -0.076748 -0.093240 -0.063002
>> >>   2567 <0.0005 ***
>> >> male                                        0.106074  0.095705  0.115742
>> >>   2000 <0.0005 ***
>> >> paternalage.mean                           -0.024119 -0.033133 -0.014444
>> >>   2000 <0.0005 ***
>> >> paternalage.diff                           -0.018367 -0.032083 -0.005721
>> >>   2000   0.007 **
>> >> traitza_children:maternalage.factor(14,20] -0.116510 -0.182432
>> -0.051978
>> >>   1876   0.001 ***
>> >> traitza_children:maternalage.factor(35,50] -0.045196 -0.094485
>> 0.002640
>> >>   2000   0.075 .
>> >> traitza_children:paternallossTRUE          -0.171957 -0.238218
>> -0.104820
>> >>   2000 <0.0005 ***
>> >> traitza_children:maternallossTRUE          -0.499539 -0.566825
>> -0.430637
>> >>   2000 <0.0005 ***
>> >> traitza_children:center(nr.siblings)       -0.023723 -0.028676
>> -0.018746
>> >>   1848 <0.0005 ***
>> >> traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250
>> 0.026024
>> >>   2000   0.319
>> >> traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462
>> -0.227187
>> >>   2000 <0.0005 ***
>> >> traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659
>> -0.204462
>> >>   2130 <0.0005 ***
>> >> traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568
>> -0.426648
>> >>   2000 <0.0005 ***
>> >> traitza_children:urban                     -0.604108 -0.645169 -0.562554
>> >>   1702 <0.0005 ***
>> >> traitza_children:male                      -0.414988 -0.444589 -0.387005
>> >>   2000 <0.0005 ***
>> >> traitza_children:paternalage.mean           0.006545 -0.018570
>> 0.036227
>> >>   2000   0.651
>> >> traitza_children:paternalage.diff          -0.097982 -0.136302
>> -0.060677
>> >>   2000 <0.0005 ***
>> >>
>> >>
>> >> On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com> wrote:
>> >>
>> >>> Ruben Arslan <rubenarslan at ...> writes:
>> >>>
>> >>> >
>> >>> > Dear list,
>> >>> >
>> >>> > I wanted to ask: Is there any (maybe just back of the envelope) way
>> to
>> >>> > obtain a response prediction for zero-inflated or hurdle type models?
>> >>> > I've fit such models in MCMCglmm, but I don't work in ecology and my
>> >>> > previous experience with explaining such models to "my audience" did
>> not
>> >>> > bode well. When it comes to humans, the researchers I presented to
>> are
>> >>> not
>> >>> > used to offspring count being zero-inflated (or acquainted with that
>> >>> > concept), but in my historical data with high infant mortality, it is
>> >>> (in
>> >>> > modern data it's actually slightly underdispersed).
>> >>> >
>> >>> > Currently I'm using lme4 and simply splitting my models into two
>> stages
>> >>> > (finding a mate and having offspring).
>> >>> > That's okay too, but in one population the effect of interest is not
>> >>> > clearly visible in either stage, only when both are taken together
>> (but
>> >>> > then the outcome is zero-inflated).
>> >>> > I expect to be given a hard time for this and hence thought I'd use a
>> >>> > binomial model with the outcome offspring>0 as my main model, but
>> that
>> >>> > turns out to be hard to explain too and doesn't
>> >>> > really do the data justice.
>> >>> >
>> >>> > Basically I don't want to be forced to discuss my smallest population
>> >>> as a
>> >>> > non-replication of the effect because I was insufficiently able to
>> >>> explain
>> >>> > the statistics behind my reasoning that the effect shows.
>> >>>
>> >>>   I think the back-of-the envelope answer would be that for a two-stage
>> >>> model with a prediction of p_i for the probability of having a non-zero
>> >>> response (or in the case of zero-inflated models, the probability of
>> >>> _not_ having a structural zero) and a prediction of n_i for the
>> >>> conditional
>> >>> part of the model, the mean predicted value is p_i*n_i and the
>> >>> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 +
>> var(n_i)/n_i^2)
>> >>> (this is assuming
>> >>> that you haven't built in any correlation between p_i and n_i, which
>> >>> would be hard in lme4 but _might_ be possible under certain
>> circumstances
>> >>> via a multitype model in MCMCglmm).
>> >>>
>> >>>   Does that help?
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Wed Mar 18 07:06:43 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 18 Mar 2015 06:06:43 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <CALv3xzu4UDx=NaotMmp_UZwQiX-3Bgmcbo=57auyRO+hQuQX_w@mail.gmail.com>
References: <loom.20150309T220710-595@post.gmane.org>
	<CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
	<CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>
	<20150317163112.14195p92nh01nwso@www.staffmail.ed.ac.uk>
	<CALv3xzuKdax26=sdMRTj16we9-UsWbF4y7bo_5rkwXcky1WR6Q@mail.gmail.com>
	<CALv3xzu4UDx=NaotMmp_UZwQiX-3Bgmcbo=57auyRO+hQuQX_w@mail.gmail.com>
Message-ID: <20150318060643.13225lb85fypl9ss@www.staffmail.ed.ac.uk>

Hi,

6/ you are correct - my mistake.


5b/ I'm still not sure what you mean by the uncertainty, but ignoring  
the random effects will result in under prediction. For a Poisson  
log-normal the mean  is  exp(a_1+v_1/2)  rather than  exp(a_1) for the  
standard Poisson.

Cheers,

Jarrod



Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015  
19:21:06 +0000:

> Hi,
>
> two more questions, sorry.
>
> 6.
> could it be that where you wrote
> normal.evd<-function(x, mu, v){
> exp(-exp(x))*dnorm(x, mu, sqrt(v))
> }
>
> you're not actually passing the variance but the standard deviation? so the
> functions should be
>
> normal.evd<-function(x, mu, sd){
> exp(-exp(x))*dnorm(x, mu, sd)
> }
> normal.zt<-function(x, mu, sd){
> exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sd)
> }
>
> Because at least in the example, you were taking the square root here
> already: sd_1<-mean(sqrt(m1$VCV[,1]))
> Maybe this was a copy-paste from the source where you do it differently? Or
> I misunderstood...
>
> An addition to question 5:
> 5. When I use the correct inverse link function in my old code, but don't
> do double integration, I do get a "reasonable" amount of uncertainty around
> the reference factor. The predicted means are too low, which I put down to
> this approach ignoring the VCV. I was just wondering how this could happen
> (actually seeing the "reasonable" amount of uncertainty was what made me
> hopeful that my approach might not be entirely wrong).
>
> Best,
>
> Ruben
>
>
> On Tue, Mar 17, 2015 at 7:53 PM Ruben Arslan <rubenarslan at gmail.com> wrote:
>
>> Hi Jarrod,
>>
>> thanks for the extensive reply! This helps a lot, though it sounds like I
>> was hubristic to attempt this myself.
>> I tried using the approach you mapped out in the function gist
>> <https://gist.github.com/rubenarslan/aeacdd306b3d061819a6> I posted. I
>> simply put the pred function in a loop, so that I wouldn't make any
>> mistakes while vectorising and since I don't care about performance at this
>> point.
>>
>> Of course, I have some follow up questions though.. I'm sorry if I'm being
>> a pain, I really appreciate the free advice, but understand of course if
>> other things take precedence.
>>
>> 1. You're not "down with" developing publicly are you? Because I sure
>> would like to test-drive the newdata prediction and simulation functions..
>>
>> 2. Could you make sure that I got this right: "When predictions are to be
>> taken after marginalising the random effects (including the `residual'
>> over-dispersion) it is not possible to obtain closed form expressions."
>> That is basically my scenario, right? In the example I included, I also
>> had a group-level random effect (family). Ore are you talking about the
>> "trait" as the random effect (as in your example) and my scenario is
>> different and I cannot apply the numerical double integration procedure you
>> posted?
>> To be clear about my prediction goal without using language that I might
>> be using incorrectly: I want to show what the average effect in the
>> response unit, number of children, is in my population(s). I have data on
>> whole populations and am using all of it (except individuals that don't
>> have completed fertility yet, because I have yet to find a way to model
>> both zero-inflation and right censoring).
>>
>> 3. "Numerical integration could be extended to double integration in
>> which case covariance between the Poisson part and the binary part could
>> be handled." That is what you posted an example of and it applies to my
>> scenario, because I specified a prior R=list(V=diag(2), nu=1.002, fix=2)
>> and rcov=~idh(trait):units, random=~idh(trait):idParents?
>> But this double integration approach is something you just wrote
>> off-the-cuff and I probably shouldn't use it in a publication? Or is this
>> in the forthcoming MCMCglmm release and I might actually be able to refer
>> to it once I get to submitting?
>>
>> 4. Could I change my model specification to forbid covariance between the
>> two parts and not shoot myself in the foot? Would this allow for a more
>> valid/tested approach to prediction?
>>
>> 5. When I use your method on my real data, I get less variation around the
>> prediction "for the reference level" than for all other factor levels.
>> My reference level actually has fewer cases than the others, so this
>> isn't "right" in a way.
>> Is this because I'm not doing newdata prediction? I get the "right"
>> looking uncertainty if I bootstrap newdata predictions in lme4,
>> Sorry if this is children's logic :-)
>> Here's an image of the prediction
>> <http://rpubs.com/rubenarslan/mcmcglmm_pred> and the raw data
>> <http://rpubs.com/rubenarslan/raw>.
>>
>> Many thanks for any answers that you feel inclined to give.
>>
>> Best wishes,
>>
>> Ruben
>>
>> On Tue, Mar 17, 2015 at 5:31 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>> Hi,
>>>
>>> Sorry - I should have replied to this post earlier. I've been working
>>> on predict/simulate methods for all MCMcglmm models (including
>>> zero-inflated/altered/hurdle/truncated models) and these are now
>>> largely complete (together with newdata options).
>>>
>>> When predictions are to be taken after marginalising the random
>>> effects (including the `residual' over-dispersion) it is not possible
>>> to obtain closed form expressions. The options that will be available
>>> in MCMCglmm are:
>>>
>>> 1) algebraic approximation
>>> 2) numerical integration
>>> 3) simulation
>>>
>>> 1) and 2) are currently only accurate when the random/residual effect
>>> structure implies no covariance between the Poisson part and the
>>> binary part.
>>>
>>> 1) is reasonably accurate for zero-inflated distributions, but can be
>>> pretty poor for the remainder because they all involve zero-truncated
>>> Poisson log-normal distributions and my taylor approximation for the
>>> mean is less than ideal (any suggestions would be helpful).
>>>
>>> 2) could be extended to double integration in which case covariance
>>> between the Poisson part and the binary part could be handled.
>>>
>>> In your code, part of the problem is that you have fitted a zapoisson,
>>> but the prediction is based on a zipoisson (with complementary log-log
>>> link rather than logt link).
>>>
>>> In all zero-inflated/altered/hurdle/truncated models
>>>
>>> E[y] = E[(1-prob)*meanc]
>>>
>>> where prob is the probabilty of a zero in the binary part and meanc is
>>> the mean of a Poisson distribution (zipoisson) or a zero-truncated
>>> poisson (zapoisson and hupoisson). If we have eta_1 as the linear
>>> predictor for the poisson part and eta_2 as the linear predictor for
>>> the binary part:
>>>
>>> In zipoisson: prob = plogis(eta_2)     and meanc = exp(eta_1)
>>> In zapoisson: prob = exp(-exp(eta_2))  and meanc =
>>> exp(eta_1)/(1-exp(-exp(eta_1)))
>>> In hupoisson: prob = plogis(eta_2)     and meanc =
>>> exp(eta_1)/(1-exp(-exp(eta_1)))
>>> In ztpoisson: prob = 0                 and meanc =
>>> exp(eta_1)/(1-exp(-exp(eta_1)))
>>>
>>> In each case the linear predictor has a `fixed' part and a `random'
>>> part which I'll denote as `a' and `u' respectively. Ideally we would
>>> want
>>>
>>> E[(1-prob)*meanc] taken over u_1 & u_2
>>>
>>> if prob and meanc are independent this is a bit easier as
>>>
>>> E[y] = E[1-prob]E[meanc]
>>>
>>> and the two expectations ony need to taken with repsect to their
>>> respective random effects. If we have sd_1 and sd_2 as the standard
>>> deviations of the two sets of random effects then for the zapoisson:
>>>
>>>    normal.evd<-function(x, mu, v){
>>>       exp(-exp(x))*dnorm(x, mu, sqrt(v))
>>>    }
>>>    normal.zt<-function(x, mu, v){
>>>      exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sqrt(v))
>>>    }
>>>
>>>    pred<-function(a_1, a_2, sd_1, sd_2){
>>>      prob<-1-integrate(normal.evd, qnorm(0.0001, a_2,sd_2),
>>> qnorm(0.9999, a_2,sd_2), a_2,sd_2)[[1]]
>>>      meanc<-integrate(normal.zt, qnorm(0.0001, a_1,sd_1),
>>> qnorm(0.9999, a_1,sd_1), a_1,sd_1)[[1]]
>>>      prob*meanc
>>>    }
>>>
>>> #  gives the expected value with reasonable accuracy.  As an example:
>>>
>>>    x<-rnorm(300)
>>>    l1<-rnorm(300, 1/2+x, sqrt(1))
>>>    l2<-rnorm(300, 1-x, sqrt(1))
>>>
>>>    y<-rbinom(300, 1, 1-exp(-exp(l2)))
>>>    y[which(y==1)]<-qpois(runif(sum(y==1), dpois(0,
>>> exp(l1[which(y==1)])), 1), exp(l1[which(y==1)]))
>>>    # cunning sampler from Peter Dalgaard (R-sig-mixed)
>>>
>>>    data=data.frame(y=y, x=x)
>>>    prior=list(R=list(V=diag(2), nu=0.002, fix=2))
>>>
>>>    m1<-MCMCglmm(y~trait+trait:x-1, rcov=~idh(trait):units, data=data,
>>> family="zapoisson", prior=prior)
>>>
>>>    b_1<-colMeans(m1$Sol)[c(1,3)]
>>>    b_2<-colMeans(m1$Sol)[c(2,4)]
>>>    sd_1<-mean(sqrt(m1$VCV[,1]))
>>>    sd_2<-mean(sqrt(m1$VCV[,2]))
>>>
>>>    # note it is more accurate to take the posterior mean prediction
>>> rather than the prediction from the posterior means as I've done here,
>>> but for illustration:
>>>
>>>    x.pred<-seq(-3,3,length=100)
>>>    p<-1:100
>>>    for(i in 1:100){
>>>      p[i]<-pred(a_1 = b_1[1]+x.pred[i]*b_1[2], a_2 =
>>> b_2[1]+x.pred[i]*b_2[2], sd_1=sd_1, sd_2=sd_2)
>>>    }
>>>
>>>    plot(y~x)
>>>    lines(p~x.pred)
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015
>>> 13:33:25 +0000:
>>>
>>> > Dear list,
>>> >
>>> > I've made a reproducible example of the zero-altered prediction,
>>> > in the hope that someone will have a look and reassure me that I'm going
>>> > about this the right way.
>>> > I was a bit confused by the point about p_i and n_i being correlated
>>> (they
>>> > are in my case), but I think this was a red herring for me
>>> > since I'm not deriving the variance analytically.
>>> > The script is here: https://gist.github.com/rubenarslan/
>>> aeacdd306b3d061819a6
>>> > and if you don't want to run the simulation fit yourself, I've put an
>>> RDS
>>> > file of the fit here:
>>> > https://dl.dropboxusercontent.com/u/1078620/m1.rds
>>> >
>>> > Best regards,
>>> >
>>> > Ruben Arslan
>>> >
>>> > On Tue, Mar 10, 2015 at 1:22 PM Ruben Arslan <rubenarslan at gmail.com>
>>> wrote:
>>> >
>>> >> Dear Dr Bolker,
>>> >>
>>> >> I'd thought about something like this, one point of asking was to
>>> >> see whether
>>> >> a) it's implemented already, because I'll probably make dumb mistakes
>>> while
>>> >> trying b) it's not implemented because it's a bad idea.
>>> >> Your response and the MCMCglmm course notes make me hope that it's c)
>>> not
>>> >> implemented because nobody did yet or d) it's so simple that everybody
>>> does
>>> >> it on-the-fly.
>>> >>
>>> >> So I tried my hand and would appreciate corrections. I am sure there is
>>> >> some screw-up or an inelegant approach in there.
>>> >> I included code for dealing with mcmc.lists because that's what I have
>>> and
>>> >> I'm not entirely sure how I deal with them is correct either.
>>> >>
>>> >> I started with a zero-altered model, because those fit fastest and
>>> >> according to the course notes have the least complex likelihood.
>>> >> Because I know not what I do, I'm not dealing with my random effects at
>>> >> all.
>>> >>
>>> >> I pasted a model summary below to show what I've applied the below
>>> >> function to. The function gives the following quantiles when applied
>>> to 19
>>> >> chains of that model.
>>> >>          5%         50%         95%
>>> >> 5.431684178 5.561211207 5.690655200
>>> >>          5%         50%         95%
>>> >> 5.003974382 5.178192327 5.348246558
>>> >>
>>> >> Warm regards,
>>> >>
>>> >> Ruben Arslan
>>> >>
>>> >> HPDpredict_za = function(object, predictor) {
>>> >>
>>> >> if(class(object) != "MCMCglmm") {
>>> >> if(length( object[[1]]$Residual$nrt )>1) {
>>> >> object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
>>> >> }
>>> >> Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
>>> >> vars = colnames(Sol[[1]])
>>> >> } else {
>>> >> Sol = as.data.frame(object$Sol)
>>> >> vars = names(Sol)
>>> >> }
>>> >> za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
>>> >> "traitza_"]
>>> >> za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
>>> >> "traitza_"]
>>> >>  intercept = Sol[,"(Intercept)"]
>>> >> za_intercept = Sol[, za_intercept_name]
>>> >> l1 = Sol[, predictor ]
>>> >> l2 = Sol[, za_predictor ]
>>> >> if(is.list(object)) {
>>> >> intercept = unlist(intercept)
>>> >> za_intercept = unlist(za_intercept)
>>> >> l1 = unlist(l1)
>>> >> l2 = unlist(l2)
>>> >> }
>>> >>  py_0 = dpois(0, exp(intercept + za_intercept))
>>> >> y_ygt0 = exp(intercept)
>>> >> at_intercept = (1-py_0) * y_ygt0
>>> >>
>>> >> py_0 = dpois(0, exp(intercept + za_intercept + l2))
>>> >> y_ygt0 = exp(intercept +  l1)
>>> >> at_predictor_1 = (1-py_0) * y_ygt0
>>> >> print(qplot(at_intercept))
>>> >> print(qplot(at_predictor_1))
>>> >> df = data.frame("intercept" = at_intercept)
>>> >> df[, predictor] = at_predictor_1
>>> >> print(qplot(x=variable,
>>> >> y=value,data=suppressMessages(melt(df)),fill=variable,alpha=I(0.40),
>>> geom =
>>> >> 'violin'))
>>> >> print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
>>> >> print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
>>> >> invisible(df)
>>> >> }
>>> >>
>>> >>
>>> >> > summary(object[[1]])
>>> >>
>>> >>  Iterations = 100001:299901
>>> >>  Thinning interval  = 100
>>> >>  Sample size  = 2000
>>> >>
>>> >>  DIC: 349094
>>> >>
>>> >>  G-structure:  ~idh(trait):idParents
>>> >>
>>> >>                       post.mean l-95% CI u-95% CI eff.samp
>>> >> children.idParents       0.0189   0.0164   0.0214     1729
>>> >> za_children.idParents    0.2392   0.2171   0.2622     1647
>>> >>
>>> >>  R-structure:  ~idh(trait):units
>>> >>
>>> >>                   post.mean l-95% CI u-95% CI eff.samp
>>> >> children.units        0.144    0.139    0.148     1715
>>> >> za_children.units     1.000    1.000    1.000        0
>>> >>
>>> >>  Location effects: children ~ trait * (maternalage.factor +
>>> paternalloss +
>>> >> maternalloss + center(nr.siblings) + birth.cohort + urban + male +
>>> >> paternalage.mean + paternalage.diff)
>>> >>
>>> >>                                            post.mean  l-95% CI  u-95%
>>> CI
>>> >> eff.samp   pMCMC
>>> >> (Intercept)                                 2.088717  2.073009
>>> 2.103357
>>> >>   2000 <0.0005 ***
>>> >> traitza_children                           -1.933491 -1.981945
>>> -1.887863
>>> >>   2000 <0.0005 ***
>>> >> maternalage.factor(14,20]                   0.007709 -0.014238
>>> 0.027883
>>> >>   1500   0.460
>>> >> maternalage.factor(35,50]                   0.006350 -0.009634
>>> 0.024107
>>> >>   2000   0.462
>>> >> paternallossTRUE                            0.000797 -0.022716
>>> 0.025015
>>> >>   2000   0.925
>>> >> maternallossTRUE                           -0.015542 -0.040240
>>> 0.009549
>>> >>   2000   0.226
>>> >> center(nr.siblings)                         0.005869  0.004302
>>> 0.007510
>>> >>   2000 <0.0005 ***
>>> >> birth.cohort(1703,1722]                    -0.045487 -0.062240
>>> -0.028965
>>> >>   2000 <0.0005 ***
>>> >> birth.cohort(1722,1734]                    -0.055872 -0.072856
>>> -0.036452
>>> >>   2000 <0.0005 ***
>>> >> birth.cohort(1734,1743]                    -0.039770 -0.056580
>>> -0.020907
>>> >>   2000 <0.0005 ***
>>> >> birth.cohort(1743,1750]                    -0.030713 -0.048301
>>> -0.012214
>>> >>   2000   0.002 **
>>> >> urban                                      -0.076748 -0.093240
>>> -0.063002
>>> >>   2567 <0.0005 ***
>>> >> male                                        0.106074  0.095705
>>> 0.115742
>>> >>   2000 <0.0005 ***
>>> >> paternalage.mean                           -0.024119 -0.033133
>>> -0.014444
>>> >>   2000 <0.0005 ***
>>> >> paternalage.diff                           -0.018367 -0.032083
>>> -0.005721
>>> >>   2000   0.007 **
>>> >> traitza_children:maternalage.factor(14,20] -0.116510 -0.182432
>>> -0.051978
>>> >>   1876   0.001 ***
>>> >> traitza_children:maternalage.factor(35,50] -0.045196 -0.094485
>>> 0.002640
>>> >>   2000   0.075 .
>>> >> traitza_children:paternallossTRUE          -0.171957 -0.238218
>>> -0.104820
>>> >>   2000 <0.0005 ***
>>> >> traitza_children:maternallossTRUE          -0.499539 -0.566825
>>> -0.430637
>>> >>   2000 <0.0005 ***
>>> >> traitza_children:center(nr.siblings)       -0.023723 -0.028676
>>> -0.018746
>>> >>   1848 <0.0005 ***
>>> >> traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250
>>> 0.026024
>>> >>   2000   0.319
>>> >> traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462
>>> -0.227187
>>> >>   2000 <0.0005 ***
>>> >> traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659
>>> -0.204462
>>> >>   2130 <0.0005 ***
>>> >> traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568
>>> -0.426648
>>> >>   2000 <0.0005 ***
>>> >> traitza_children:urban                     -0.604108 -0.645169
>>> -0.562554
>>> >>   1702 <0.0005 ***
>>> >> traitza_children:male                      -0.414988 -0.444589
>>> -0.387005
>>> >>   2000 <0.0005 ***
>>> >> traitza_children:paternalage.mean           0.006545 -0.018570
>>> 0.036227
>>> >>   2000   0.651
>>> >> traitza_children:paternalage.diff          -0.097982 -0.136302
>>> -0.060677
>>> >>   2000 <0.0005 ***
>>> >>
>>> >>
>>> >> On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com> wrote:
>>> >>
>>> >>> Ruben Arslan <rubenarslan at ...> writes:
>>> >>>
>>> >>> >
>>> >>> > Dear list,
>>> >>> >
>>> >>> > I wanted to ask: Is there any (maybe just back of the envelope) way
>>> to
>>> >>> > obtain a response prediction for zero-inflated or hurdle type
>>> models?
>>> >>> > I've fit such models in MCMCglmm, but I don't work in ecology and my
>>> >>> > previous experience with explaining such models to "my audience"
>>> did not
>>> >>> > bode well. When it comes to humans, the researchers I presented to
>>> are
>>> >>> not
>>> >>> > used to offspring count being zero-inflated (or acquainted with that
>>> >>> > concept), but in my historical data with high infant mortality, it
>>> is
>>> >>> (in
>>> >>> > modern data it's actually slightly underdispersed).
>>> >>> >
>>> >>> > Currently I'm using lme4 and simply splitting my models into two
>>> stages
>>> >>> > (finding a mate and having offspring).
>>> >>> > That's okay too, but in one population the effect of interest is not
>>> >>> > clearly visible in either stage, only when both are taken together
>>> (but
>>> >>> > then the outcome is zero-inflated).
>>> >>> > I expect to be given a hard time for this and hence thought I'd use
>>> a
>>> >>> > binomial model with the outcome offspring>0 as my main model, but
>>> that
>>> >>> > turns out to be hard to explain too and doesn't
>>> >>> > really do the data justice.
>>> >>> >
>>> >>> > Basically I don't want to be forced to discuss my smallest
>>> population
>>> >>> as a
>>> >>> > non-replication of the effect because I was insufficiently able to
>>> >>> explain
>>> >>> > the statistics behind my reasoning that the effect shows.
>>> >>>
>>> >>>   I think the back-of-the envelope answer would be that for a
>>> two-stage
>>> >>> model with a prediction of p_i for the probability of having a
>>> non-zero
>>> >>> response (or in the case of zero-inflated models, the probability of
>>> >>> _not_ having a structural zero) and a prediction of n_i for the
>>> >>> conditional
>>> >>> part of the model, the mean predicted value is p_i*n_i and the
>>> >>> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 +
>>> var(n_i)/n_i^2)
>>> >>> (this is assuming
>>> >>> that you haven't built in any correlation between p_i and n_i, which
>>> >>> would be hard in lme4 but _might_ be possible under certain
>>> circumstances
>>> >>> via a multitype model in MCMCglmm).
>>> >>>
>>> >>>   Does that help?
>>> >>>
>>> >>> _______________________________________________
>>> >>> R-sig-mixed-models at r-project.org mailing list
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>
>>> >>
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>> >
>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Wed Mar 18 07:18:50 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 18 Mar 2015 06:18:50 +0000
Subject: [R-sig-ME] transform glmer model into MCMCglmm: how to define
 the priors?
In-Reply-To: <web-254004262@uni-freiburg.de>
References: <web-254004262@uni-freiburg.de>
Message-ID: <20150318061850.29976xmtuv3i3808@www.staffmail.ed.ac.uk>

Hi,

You will need priors for this model: the observation-level (units)  
effects are not identifiable. The random effect covariance structures  
are 2x2 matrices. For these models I fix the residual covariance  
matrix at

IJ <- (1/k) * (diag(k-1) + matrix(1, k-1, k-1))

where k is the number of categories in the response:


A starting prior might look something like:

prior=list(R=list(V=IJ, fix=1), G=list(G1=list(V=diag(2), nu=2,  
alpha.mu=c(0,0), alpha.V=diag(2)*1000)))


Although I haven't seen it done (although I don't know the literature  
on multinomial models) it might make sense to have the random effect  
covarinace matrix proportional to IJ and estimate a single variance  
component (rather than a 2x2 covariance matrix). The rational behind  
the IJ matrix is that the propensity to belong to a category varies  
over random effects, but variation in the propensity is equal for all  
categories, and the propensity for two categories are uncorrelated. In  
non-multinomial models such an assumption would be represented by an  
identity matrix (i.e. trait:author) but for multinomial models this is  
a bit trickier because things are parameterised in terms of  
differences from a base-line category.

The error you are getting does not look like it is a MCMCglmm issue.  
Could you post the data (or a reproducible example) so I can check?


Cheers,

Jarrod




Quoting Anne Krause <anne.krause at frequenz.uni-freiburg.de> on Tue, 17  
Mar 2015 18:06:48 +0100:

> Dear list members,
> I am a linguist who would like to use MCMCglmm in order to
> model change in language morphology. I have a 3-level
> dependent variable (unordered) which are 3 realisations of
> a morphological form in German. Say, I call them A, B, and
> C - A and B share the same vowel, B and C share the
> suffixation.
> I did not know about MCMCglmm until recently; therefore I
> worked with two glmer models, looking at vowel and
> suffixation separately. However, I have been criticised for
> the clumsy model interpretation, and I am sure that the
> output of a MCMCglmm would be more straightforward and
> convincing.
>
> My glmer looks like this:
> model <- glmer(vowel~frequency+year+recency+
>                   frequency*recency+
>                   (1|verb)+(1|author), data=imp,
>                   family=binomial)
> - where ?vowel? differentiates between AB on the one hand
> and C on the other hand,
> - ?frequency? and ?year? are numeric fixed variables and
> ?recency? a categorical fixed variable (7 levels),
> - ?verb? and ?author? are categorical random variables
>
> The model for the dependent variable ?suffix? is
> practically the same (part of the criticism), ?suffix?
> distinguishing between A on the one hand and BC on the
> other hand.
>
> Trying to transform this into an MCMCglmm, I managed to get
> as far as this:
> model2 <- MCMCglmm(form~trait:frequency+trait:recency+
>                   trait:year-1,
>                   random=~us(trait):author,
>                   rcov=~us(trait):units,
>                   data=imp, family="categorical",)
> (?form? now distinguishing between all 3 three levels of
> the dependent variable A, B, and C)
>
> I am well aware that this model is running without priors.
> Whichever prior I tried gave me the error ?V is the wrong
> dimension for some prior$G/prior$R elements? and I have no
> idea (after reading through the general description, the
> tutorial, the course notes and entries in this mailing
> list) how these priors are defined. I guess there is no
> rule of thumb, but I hope this short explanation of my
> variables is enough for someone of you to point out a
> solution (or a starting point for me). I also need to
> include the second random from above (?verb?) and the
> interaction between ?frequency? and ?recency?.
>
> Even though model2 is running, I cannot call the summary
> for it (error: ?Error in get(as.character(FUN), mode =
> "function", envir = envir) :   object 'C:\Users\Anne
> Krause\some_directory.Rdata' of mode 'function' was not
> found?), which probably has to do with the fact that I did
> not include priors (?!).
>
> Thank you so much in advance for help and/ or comments,
> pointers or the like!
>
> Best, Anne
> ____________________________________
>
> Anne Krause
> Research Training Group GRK DFG 1624
> "Frequency Effects in Language"
> University of Freiburg
> Belfortstra?e 18
> 79098 Freiburg
>
> Phone: 0761/203-97670
> frequenz.uni-freiburg.de/krause
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From matejus106 at googlemail.com  Wed Mar 18 10:50:23 2015
From: matejus106 at googlemail.com (jos matejus)
Date: Wed, 18 Mar 2015 09:50:23 +0000
Subject: [R-sig-ME] the equation of a mixed model fitted using nlme
Message-ID: <CAGL_TsdiJL7hspJ19617FL7km2NqV6pXSCX4DiqBW+rPNiJjLQ@mail.gmail.com>

Dear R mixed modellers

I am writing to the R mixed modelling community to request some help and
advice regarding reporting a mixed model in a publication. I have recently
received referees comments regarding a paper I submitted some time ago. The
referee has requested that I write one of the models used to analyse my
data 'statistically'. I think they mean that I should write out the
equation, and while I don?t think this is unreasonable I am having trouble
doing so. I know many of you have heard the excuse ?I am not a
statistician? but I?m afraid that this applies in my case, but I have tried
for a couple of days to figure this one out and harassed many colleagues
but without success. Therefore I am hoping I can prevail on the kindness of
the R mixed modelling community to help me with this problem.

The code used for the model was

vf1Exp<-  varExp(form=~I(days-7)|habitat*treat)

final.model <- lme(length.sq~ poly(I(days-7),2)*treat*habitat, data=mydata,
method="REML",random=~poly(I(days-7),2)|family, weights=vf1Exp)

length.sq = square root transformed length of fish

days = day following exposure (10, one day intervals starting from day 7
after exposure)

treat = two level treatment factor

habitat = two level habitat factor

family = 19 level factor



I have 10 fish per treatment combination (treat*habitat) at each time point
for each family.



The second order polynomial term for day was included to account for non
linear growth and the variance structure to account for an increase in
variance over time that was different depending on the treatment
combination. The 3-way interaction was significant.

How should I represent this model as an equation?

Thanks a million for your help.

Jos

	[[alternative HTML version deleted]]


From phillip.gienapp at helsinki.fi  Wed Mar 18 11:25:07 2015
From: phillip.gienapp at helsinki.fi (Phillip Gienapp)
Date: Wed, 18 Mar 2015 11:25:07 +0100
Subject: [R-sig-ME] Bivariate random regression model in MCMCglmm to
 estimate selection on reaction norm slopes
Message-ID: <55095283.8000903@helsinki.fi>

Dear all,

First a bit of background: I currently work on an anlysis of phenotypic 
plasticity of avian phenology in response to temperature. Using a random 
regression model I found that individual reaction norms (defined by 
slope and intercept) vary among individuals, i.e. some individuals 
change their phenology more strongly in response to temperatures than 
others and also that some individuals have a consistently earlier 
phenology than others.

I now want to test whether there is selection on reaction norm slopes, 
i.e. whether individuals with steeper/shallower slope have a 
higher/lower fitness. This means I have to fit a bivariate random 
regression model but only one trait (phenology) should be regressed 
against temperature. For the random effects part this should give me a 
3x3 covariance matrix with variation in slopes, intercepts, fitness plus 
all the covariances and then the covariance between slope and fitness 
indicates selection on reaction norm slopes.

I figured how to regress only phenology and not fitness against 
temperature for the fixed effects part but am still struggling with the 
syntax for the random effects part.


The univariate random regression model (omitting obvious syntax parts) is:

phenology~age + temp, random=~us(1+temp):individual


For the multivariate model I came up with:

cbind(phenology,fitness)~trait:age + at.level(trait,1):temp, 
random=~us(at.level(trait,1):(1+mt2):at.level(trait,2):1):individual, 
rcov=~us(trait):units

but curiously this fits only a single variance for individual and not 
the desired 3x3 matrix...

I hope I managed to explain my problem clearly enough (maybe there was 
too much non-technical detail...). Any ideas to fit the desired model 
are highly welcome!


Best,
Phillip


From highstat at highstat.com  Wed Mar 18 12:14:15 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 18 Mar 2015 11:14:15 +0000
Subject: [R-sig-ME] Bayesian course + GLMM course
Message-ID: <55095E07.6080704@highstat.com>

Apologies for cross-posting


There are a few remaining seats on the following two (combined) courses:

Course 1 (3 days): Introduction to Bayesian statistics and MCMC
When: 8-10 April 2015
Where: University of Southampton, Southampton, UK
Course flyer: 
http://www.highstat.com/Courses/Flyer2015_04Southampton_Course2.pdf
URL: http://www.highstat.com/statscourse.htm


Course 2 (5 days): Introduction to Linear Mixed Effects Models and GLMM 
with R
When: 13-17 April 2015
Where: University of Southampton, Southampton, UK
Course flyer: 
http://www.highstat.com/Courses/Flyer2015_04Southampton_Course3.pdf
URL: http://www.highstat.com/statscourse.htm



Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From bbolker at gmail.com  Wed Mar 18 14:26:16 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Mar 2015 13:26:16 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Cook=27s_distance=3A_glmmADMB_ZIP_/_influenc?=
	=?utf-8?q?e=2EME_not=09compatible=3F?=
References: <CAPN4cTjM0142+U9R3RsWJwakjDDc9LD4wW57AG6nNhK9Ah94OQ@mail.gmail.com>
Message-ID: <loom.20150318T142034-28@post.gmane.org>

Ashley Asmus <ashley.asmus at ...> writes:

> 
> Dear r-sig-ME,
> 
> I am working with a small (zero-inflated) dataset of counts. The design is
> repeated-measures, with several measures at each time point made in
> experimental blocks. I have fit the model with glmmADMB using the
> zero-inflated poisson options:
> 
> zip<-glmmadmb(wasp~ treatment  +  (1|sample.period) 
> + (1|block), data=data,
> family="poisson", zeroInflation=TRUE)
> 
> I am suspicious of 1-3 observations (the dataset is only 24 observations
> big, so I promise to be cautious), and wish to evaluate their influence on
> the model fit. Usually I work in lme4, then use the influence.ME package
> and eliminate points based on cook's distance/leverage plots. Applying
> influence.ME to the glmmADMB model produces a strange error message:
> 
> library(influence.ME)
> infl <- influence(zip, obs = TRUE)
> Error in eval(expr, envir, enclos) : object 'sample.period' not found
> 
> For some reason influence.ME is not finding my random factor
> "sample.period." Are glmmADMB and influence.ME incompatible when
> zero-inflation models are involved? If anyone knows of an alternative
> approach I would love to hear about it.
> 

  No, glmmADMB isn't compatible with influence.ME; the guts of
glmmADMB are very different.
   It sounds like you've identified suspicious observations already,
but if you haven't then I would try identifying by eye from fitted
vs. residual or predictor vs. residual plots, then drop them and
see what happens to the fitted model.

  Good luck,
   Ben Bolker


From anne.krause at frequenz.uni-freiburg.de  Wed Mar 18 14:35:29 2015
From: anne.krause at frequenz.uni-freiburg.de (Anne Krause)
Date: Wed, 18 Mar 2015 14:35:29 +0100
Subject: [R-sig-ME] transform glmer model into MCMCglmm: how to define
 the priors?
In-Reply-To: <20150318061850.29976xmtuv3i3808@www.staffmail.ed.ac.uk>
References: <web-254004262@uni-freiburg.de>
	<20150318061850.29976xmtuv3i3808@www.staffmail.ed.ac.uk>
Message-ID: <web-254079042@uni-freiburg.de>

Dear Jarrod,
thank you so much for your quick reply and the prior which
finally got me started on a working model:

k <- length(levels(imp$form))
IJ <- (1/k) * (diag(k-1) + matrix(1, k-1, k-1))

prior<-list(
  R=list(V=IJ, fix=1),
  G=list(
    G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
   alpha.V=diag(2)*1000),
    G2=list(V=diag(2), nu=2, alpha.mu=c(0,0),
alpha.V=diag(2)*1000)))


model1 <- MCMCglmm(form~trait:frequency+trait:recency+
                 trait:year-1,
                 random=~us(trait):author+us(trait):verb, 
                 rcov=~us(trait):units,
                 prior=prior,
                 data=imp, family="categorical",)

The summary problem unfortunately remains the same. I have
attached the data and R script and hope that you (or
someone else on the list) can figure this out.

Thanks a lot!

Best, Anne

On Wed, 18 Mar 2015 06:18:50 +0000
 Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi,
> 
> You will need priors for this model: the
> observation-level (units) effects are not identifiable.
> The random effect covariance structures are 2x2 matrices.
> For these models I fix the residual covariance matrix at
> 
> IJ <- (1/k) * (diag(k-1) + matrix(1, k-1, k-1))
> 
> where k is the number of categories in the response:
> 
> 
> A starting prior might look something like:
> 
> prior=list(R=list(V=IJ, fix=1), G=list(G1=list(V=diag(2),
> nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
> 
> 
> Although I haven't seen it done (although I don't know
> the literature on multinomial models) it might make sense
> to have the random effect covarinace matrix proportional
> to IJ and estimate a single variance component (rather
> than a 2x2 covariance matrix). The rational behind the IJ
> matrix is that the propensity to belong to a category
> varies over random effects, but variation in the
> propensity is equal for all categories, and the
> propensity for two categories are uncorrelated. In
> non-multinomial models such an assumption would be
> represented by an identity matrix (i.e. trait:author) but
> for multinomial models this is a bit trickier because
> things are parameterised in terms of differences from a
> base-line category.
> 
> The error you are getting does not look like it is a
> MCMCglmm issue. Could you post the data (or a
> reproducible example) so I can check?
> 
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> Quoting Anne Krause
> <anne.krause at frequenz.uni-freiburg.de> on Tue, 17 Mar
> 2015 18:06:48 +0100:
> 
> > Dear list members,
> > I am a linguist who would like to use MCMCglmm in order
> to
> > model change in language morphology. I have a 3-level
> > dependent variable (unordered) which are 3 realisations
> of
> > a morphological form in German. Say, I call them A, B,
> and
> > C - A and B share the same vowel, B and C share the
> > suffixation.
> > I did not know about MCMCglmm until recently; therefore
> I
> > worked with two glmer models, looking at vowel and
> > suffixation separately. However, I have been criticised
> for
> > the clumsy model interpretation, and I am sure that the
> > output of a MCMCglmm would be more straightforward and
> > convincing.
> >
> > My glmer looks like this:
> > model <- glmer(vowel~frequency+year+recency+
> >                   frequency*recency+
> >                   (1|verb)+(1|author), data=imp,
> >                   family=binomial)
> > - where ?vowel? differentiates between AB on the one
> hand
> > and C on the other hand,
> > - ?frequency? and ?year? are numeric fixed variables
> and
> > ?recency? a categorical fixed variable (7 levels),
> > - ?verb? and ?author? are categorical random variables
> >
> > The model for the dependent variable ?suffix? is
> > practically the same (part of the criticism), ?suffix?
> > distinguishing between A on the one hand and BC on the
> > other hand.
> >
> > Trying to transform this into an MCMCglmm, I managed to
> get
> > as far as this:
> > model2 <- MCMCglmm(form~trait:frequency+trait:recency+
> >                   trait:year-1,
> >                   random=~us(trait):author,
> >                   rcov=~us(trait):units,
> >                   data=imp, family="categorical",)
> > (?form? now distinguishing between all 3 three levels
> of
> > the dependent variable A, B, and C)
> >
> > I am well aware that this model is running without
> priors.
> > Whichever prior I tried gave me the error ?V is the
> wrong
> > dimension for some prior$G/prior$R elements? and I have
> no
> > idea (after reading through the general description,
> the
> > tutorial, the course notes and entries in this mailing
> > list) how these priors are defined. I guess there is no
> > rule of thumb, but I hope this short explanation of my
> > variables is enough for someone of you to point out a
> > solution (or a starting point for me). I also need to
> > include the second random from above (?verb?) and the
> > interaction between ?frequency? and ?recency?.
> >
> > Even though model2 is running, I cannot call the
> summary
> > for it (error: ?Error in get(as.character(FUN), mode =
> > "function", envir = envir) :   object 'C:\Users\Anne
> > Krause\some_directory.Rdata' of mode 'function' was not
> > found?), which probably has to do with the fact that I
> did
> > not include priors (?!).
> >
> > Thank you so much in advance for help and/ or comments,
> > pointers or the like!
> >
> > Best, Anne
> > ____________________________________
> >
> > Anne Krause
> > Research Training Group GRK DFG 1624
> > "Frequency Effects in Language"
> > University of Freiburg
> > Belfortstra?e 18
> > 79098 Freiburg
> >
> > Phone: 0761/203-97670
> > frequenz.uni-freiburg.de/krause
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> 
> 
> -- 
> The University of Edinburgh is a charitable body,
> registered in
> Scotland, with registration number SC005336.
> 
> 

____________________________________

Anne Krause
Research Training Group GRK DFG 1624
"Frequency Effects in Language"
University of Freiburg
Belfortstra?e 18
79098 Freiburg

Phone: 0761/203-97670
frequenz.uni-freiburg.de/krause

From rubenarslan at gmail.com  Wed Mar 18 14:51:50 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Wed, 18 Mar 2015 13:51:50 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <20150318060643.13225lb85fypl9ss@www.staffmail.ed.ac.uk>
References: <loom.20150309T220710-595@post.gmane.org>
	<CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
	<CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>
	<20150317163112.14195p92nh01nwso@www.staffmail.ed.ac.uk>
	<CALv3xzuKdax26=sdMRTj16we9-UsWbF4y7bo_5rkwXcky1WR6Q@mail.gmail.com>
	<CALv3xzu4UDx=NaotMmp_UZwQiX-3Bgmcbo=57auyRO+hQuQX_w@mail.gmail.com>
	<20150318060643.13225lb85fypl9ss@www.staffmail.ed.ac.uk>
Message-ID: <CALv3xzuiM2mwLb-AC8-wgoJtSFq9_MU_4_a5BCbXb1bXdo7G6w@mail.gmail.com>

Hi,

thanks for your reply. This clears some things up.

1. Colour me interested then, if you ever find the time to put it on
Github. Maybe after seeing the nonsense I've wrought in the following
points you might find sending me a zip of the pre-release might save you
some time as opposed to guessing where I went wrong?

2. I'm not sure I understand.
You're saying I can add the VCV components for the family random effect to
the respective unit components.
But I would only want that if I was interested in predicting the effect for
any family, which in my case is not the goal, since my population data
includes all families and I want to know the effect for the average family
in that population (to compare it to other populations).

3. Oh right, I'm sorry I think I got a little confused/sidetracked, these
models have been with me for a while now and I learned about us()/idh()
back then.

4. Okay, I will keep this in mind, but am for now focusing on getting the
prediction for this simpler case right.

5. I made a reproducible report
<http://rpubs.com/rubenarslan/repro_variab_mcmcglmm> to show the problem. I
think the problem is not due to the changes I made in my prediction helper
function but to some fundamental.
It shows that for some toy data, the credibility intervals for predictions
depend on the reference I choose for a factor predictor.
This is less bad with the method I used initially simply using the inverse
link.
However, both methods _underpredict_ as far as I can tell.

Surely I'm missing an important step, but I hope this illustrates what
confuses me. Of course the reasons you map out for the discrepancy
(variable confounding etc) are sound in theory, but I don't see these wide
CIs using any other method (simple descriptives, lme4).
Oh and I used a different data simulation, because the one you used
actually induces zero-deflation as far as I can tell (a lot of zeroes, but
lambda is very low too).

Best regards and again thanks so much for taking the time,

Ruben


On Wed, Mar 18, 2015 at 7:06 AM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi,
>
> 6/ you are correct - my mistake.
>
>
> 5b/ I'm still not sure what you mean by the uncertainty, but ignoring
> the random effects will result in under prediction. For a Poisson
> log-normal the mean  is  exp(a_1+v_1/2)  rather than  exp(a_1) for the
> standard Poisson.
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015
> 19:21:06 +0000:
>
> > Hi,
> >
> > two more questions, sorry.
> >
> > 6.
> > could it be that where you wrote
> > normal.evd<-function(x, mu, v){
> > exp(-exp(x))*dnorm(x, mu, sqrt(v))
> > }
> >
> > you're not actually passing the variance but the standard deviation? so
> the
> > functions should be
> >
> > normal.evd<-function(x, mu, sd){
> > exp(-exp(x))*dnorm(x, mu, sd)
> > }
> > normal.zt<-function(x, mu, sd){
> > exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sd)
> > }
> >
> > Because at least in the example, you were taking the square root here
> > already: sd_1<-mean(sqrt(m1$VCV[,1]))
> > Maybe this was a copy-paste from the source where you do it differently?
> Or
> > I misunderstood...
> >
> > An addition to question 5:
> > 5. When I use the correct inverse link function in my old code, but don't
> > do double integration, I do get a "reasonable" amount of uncertainty
> around
> > the reference factor. The predicted means are too low, which I put down
> to
> > this approach ignoring the VCV. I was just wondering how this could
> happen
> > (actually seeing the "reasonable" amount of uncertainty was what made me
> > hopeful that my approach might not be entirely wrong).
> >
> > Best,
> >
> > Ruben
> >
> >
> > On Tue, Mar 17, 2015 at 7:53 PM Ruben Arslan <rubenarslan at gmail.com>
> wrote:
> >
> >> Hi Jarrod,
> >>
> >> thanks for the extensive reply! This helps a lot, though it sounds like
> I
> >> was hubristic to attempt this myself.
> >> I tried using the approach you mapped out in the function gist
> >> <https://gist.github.com/rubenarslan/aeacdd306b3d061819a6> I posted. I
> >> simply put the pred function in a loop, so that I wouldn't make any
> >> mistakes while vectorising and since I don't care about performance at
> this
> >> point.
> >>
> >> Of course, I have some follow up questions though.. I'm sorry if I'm
> being
> >> a pain, I really appreciate the free advice, but understand of course if
> >> other things take precedence.
> >>
> >> 1. You're not "down with" developing publicly are you? Because I sure
> >> would like to test-drive the newdata prediction and simulation
> functions..
> >>
> >> 2. Could you make sure that I got this right: "When predictions are to
> be
> >> taken after marginalising the random effects (including the `residual'
> >> over-dispersion) it is not possible to obtain closed form expressions."
> >> That is basically my scenario, right? In the example I included, I also
> >> had a group-level random effect (family). Ore are you talking about the
> >> "trait" as the random effect (as in your example) and my scenario is
> >> different and I cannot apply the numerical double integration procedure
> you
> >> posted?
> >> To be clear about my prediction goal without using language that I might
> >> be using incorrectly: I want to show what the average effect in the
> >> response unit, number of children, is in my population(s). I have data
> on
> >> whole populations and am using all of it (except individuals that don't
> >> have completed fertility yet, because I have yet to find a way to model
> >> both zero-inflation and right censoring).
> >>
> >> 3. "Numerical integration could be extended to double integration in
> >> which case covariance between the Poisson part and the binary part could
> >> be handled." That is what you posted an example of and it applies to my
> >> scenario, because I specified a prior R=list(V=diag(2), nu=1.002, fix=2)
> >> and rcov=~idh(trait):units, random=~idh(trait):idParents?
> >> But this double integration approach is something you just wrote
> >> off-the-cuff and I probably shouldn't use it in a publication? Or is
> this
> >> in the forthcoming MCMCglmm release and I might actually be able to
> refer
> >> to it once I get to submitting?
> >>
> >> 4. Could I change my model specification to forbid covariance between
> the
> >> two parts and not shoot myself in the foot? Would this allow for a more
> >> valid/tested approach to prediction?
> >>
> >> 5. When I use your method on my real data, I get less variation around
> the
> >> prediction "for the reference level" than for all other factor levels.
> >> My reference level actually has fewer cases than the others, so this
> >> isn't "right" in a way.
> >> Is this because I'm not doing newdata prediction? I get the "right"
> >> looking uncertainty if I bootstrap newdata predictions in lme4,
> >> Sorry if this is children's logic :-)
> >> Here's an image of the prediction
> >> <http://rpubs.com/rubenarslan/mcmcglmm_pred> and the raw data
> >> <http://rpubs.com/rubenarslan/raw>.
> >>
> >> Many thanks for any answers that you feel inclined to give.
> >>
> >> Best wishes,
> >>
> >> Ruben
> >>
> >> On Tue, Mar 17, 2015 at 5:31 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
> >> wrote:
> >>
> >>> Hi,
> >>>
> >>> Sorry - I should have replied to this post earlier. I've been working
> >>> on predict/simulate methods for all MCMcglmm models (including
> >>> zero-inflated/altered/hurdle/truncated models) and these are now
> >>> largely complete (together with newdata options).
> >>>
> >>> When predictions are to be taken after marginalising the random
> >>> effects (including the `residual' over-dispersion) it is not possible
> >>> to obtain closed form expressions. The options that will be available
> >>> in MCMCglmm are:
> >>>
> >>> 1) algebraic approximation
> >>> 2) numerical integration
> >>> 3) simulation
> >>>
> >>> 1) and 2) are currently only accurate when the random/residual effect
> >>> structure implies no covariance between the Poisson part and the
> >>> binary part.
> >>>
> >>> 1) is reasonably accurate for zero-inflated distributions, but can be
> >>> pretty poor for the remainder because they all involve zero-truncated
> >>> Poisson log-normal distributions and my taylor approximation for the
> >>> mean is less than ideal (any suggestions would be helpful).
> >>>
> >>> 2) could be extended to double integration in which case covariance
> >>> between the Poisson part and the binary part could be handled.
> >>>
> >>> In your code, part of the problem is that you have fitted a zapoisson,
> >>> but the prediction is based on a zipoisson (with complementary log-log
> >>> link rather than logt link).
> >>>
> >>> In all zero-inflated/altered/hurdle/truncated models
> >>>
> >>> E[y] = E[(1-prob)*meanc]
> >>>
> >>> where prob is the probabilty of a zero in the binary part and meanc is
> >>> the mean of a Poisson distribution (zipoisson) or a zero-truncated
> >>> poisson (zapoisson and hupoisson). If we have eta_1 as the linear
> >>> predictor for the poisson part and eta_2 as the linear predictor for
> >>> the binary part:
> >>>
> >>> In zipoisson: prob = plogis(eta_2)     and meanc = exp(eta_1)
> >>> In zapoisson: prob = exp(-exp(eta_2))  and meanc =
> >>> exp(eta_1)/(1-exp(-exp(eta_1)))
> >>> In hupoisson: prob = plogis(eta_2)     and meanc =
> >>> exp(eta_1)/(1-exp(-exp(eta_1)))
> >>> In ztpoisson: prob = 0                 and meanc =
> >>> exp(eta_1)/(1-exp(-exp(eta_1)))
> >>>
> >>> In each case the linear predictor has a `fixed' part and a `random'
> >>> part which I'll denote as `a' and `u' respectively. Ideally we would
> >>> want
> >>>
> >>> E[(1-prob)*meanc] taken over u_1 & u_2
> >>>
> >>> if prob and meanc are independent this is a bit easier as
> >>>
> >>> E[y] = E[1-prob]E[meanc]
> >>>
> >>> and the two expectations ony need to taken with repsect to their
> >>> respective random effects. If we have sd_1 and sd_2 as the standard
> >>> deviations of the two sets of random effects then for the zapoisson:
> >>>
> >>>    normal.evd<-function(x, mu, v){
> >>>       exp(-exp(x))*dnorm(x, mu, sqrt(v))
> >>>    }
> >>>    normal.zt<-function(x, mu, v){
> >>>      exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sqrt(v))
> >>>    }
> >>>
> >>>    pred<-function(a_1, a_2, sd_1, sd_2){
> >>>      prob<-1-integrate(normal.evd, qnorm(0.0001, a_2,sd_2),
> >>> qnorm(0.9999, a_2,sd_2), a_2,sd_2)[[1]]
> >>>      meanc<-integrate(normal.zt, qnorm(0.0001, a_1,sd_1),
> >>> qnorm(0.9999, a_1,sd_1), a_1,sd_1)[[1]]
> >>>      prob*meanc
> >>>    }
> >>>
> >>> #  gives the expected value with reasonable accuracy.  As an example:
> >>>
> >>>    x<-rnorm(300)
> >>>    l1<-rnorm(300, 1/2+x, sqrt(1))
> >>>    l2<-rnorm(300, 1-x, sqrt(1))
> >>>
> >>>    y<-rbinom(300, 1, 1-exp(-exp(l2)))
> >>>    y[which(y==1)]<-qpois(runif(sum(y==1), dpois(0,
> >>> exp(l1[which(y==1)])), 1), exp(l1[which(y==1)]))
> >>>    # cunning sampler from Peter Dalgaard (R-sig-mixed)
> >>>
> >>>    data=data.frame(y=y, x=x)
> >>>    prior=list(R=list(V=diag(2), nu=0.002, fix=2))
> >>>
> >>>    m1<-MCMCglmm(y~trait+trait:x-1, rcov=~idh(trait):units, data=data,
> >>> family="zapoisson", prior=prior)
> >>>
> >>>    b_1<-colMeans(m1$Sol)[c(1,3)]
> >>>    b_2<-colMeans(m1$Sol)[c(2,4)]
> >>>    sd_1<-mean(sqrt(m1$VCV[,1]))
> >>>    sd_2<-mean(sqrt(m1$VCV[,2]))
> >>>
> >>>    # note it is more accurate to take the posterior mean prediction
> >>> rather than the prediction from the posterior means as I've done here,
> >>> but for illustration:
> >>>
> >>>    x.pred<-seq(-3,3,length=100)
> >>>    p<-1:100
> >>>    for(i in 1:100){
> >>>      p[i]<-pred(a_1 = b_1[1]+x.pred[i]*b_1[2], a_2 =
> >>> b_2[1]+x.pred[i]*b_2[2], sd_1=sd_1, sd_2=sd_2)
> >>>    }
> >>>
> >>>    plot(y~x)
> >>>    lines(p~x.pred)
> >>>
> >>> Cheers,
> >>>
> >>> Jarrod
> >>>
> >>>
> >>>
> >>>
> >>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015
> >>> 13:33:25 +0000:
> >>>
> >>> > Dear list,
> >>> >
> >>> > I've made a reproducible example of the zero-altered prediction,
> >>> > in the hope that someone will have a look and reassure me that I'm
> going
> >>> > about this the right way.
> >>> > I was a bit confused by the point about p_i and n_i being correlated
> >>> (they
> >>> > are in my case), but I think this was a red herring for me
> >>> > since I'm not deriving the variance analytically.
> >>> > The script is here: https://gist.github.com/rubenarslan/
> >>> aeacdd306b3d061819a6
> >>> > and if you don't want to run the simulation fit yourself, I've put an
> >>> RDS
> >>> > file of the fit here:
> >>> > https://dl.dropboxusercontent.com/u/1078620/m1.rds
> >>> >
> >>> > Best regards,
> >>> >
> >>> > Ruben Arslan
> >>> >
> >>> > On Tue, Mar 10, 2015 at 1:22 PM Ruben Arslan <rubenarslan at gmail.com>
> >>> wrote:
> >>> >
> >>> >> Dear Dr Bolker,
> >>> >>
> >>> >> I'd thought about something like this, one point of asking was to
> >>> >> see whether
> >>> >> a) it's implemented already, because I'll probably make dumb
> mistakes
> >>> while
> >>> >> trying b) it's not implemented because it's a bad idea.
> >>> >> Your response and the MCMCglmm course notes make me hope that it's
> c)
> >>> not
> >>> >> implemented because nobody did yet or d) it's so simple that
> everybody
> >>> does
> >>> >> it on-the-fly.
> >>> >>
> >>> >> So I tried my hand and would appreciate corrections. I am sure
> there is
> >>> >> some screw-up or an inelegant approach in there.
> >>> >> I included code for dealing with mcmc.lists because that's what I
> have
> >>> and
> >>> >> I'm not entirely sure how I deal with them is correct either.
> >>> >>
> >>> >> I started with a zero-altered model, because those fit fastest and
> >>> >> according to the course notes have the least complex likelihood.
> >>> >> Because I know not what I do, I'm not dealing with my random
> effects at
> >>> >> all.
> >>> >>
> >>> >> I pasted a model summary below to show what I've applied the below
> >>> >> function to. The function gives the following quantiles when applied
> >>> to 19
> >>> >> chains of that model.
> >>> >>          5%         50%         95%
> >>> >> 5.431684178 5.561211207 5.690655200
> >>> >>          5%         50%         95%
> >>> >> 5.003974382 5.178192327 5.348246558
> >>> >>
> >>> >> Warm regards,
> >>> >>
> >>> >> Ruben Arslan
> >>> >>
> >>> >> HPDpredict_za = function(object, predictor) {
> >>> >>
> >>> >> if(class(object) != "MCMCglmm") {
> >>> >> if(length( object[[1]]$Residual$nrt )>1) {
> >>> >> object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
> >>> >> }
> >>> >> Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
> >>> >> vars = colnames(Sol[[1]])
> >>> >> } else {
> >>> >> Sol = as.data.frame(object$Sol)
> >>> >> vars = names(Sol)
> >>> >> }
> >>> >> za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
> >>> >> "traitza_"]
> >>> >> za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
> >>> >> "traitza_"]
> >>> >>  intercept = Sol[,"(Intercept)"]
> >>> >> za_intercept = Sol[, za_intercept_name]
> >>> >> l1 = Sol[, predictor ]
> >>> >> l2 = Sol[, za_predictor ]
> >>> >> if(is.list(object)) {
> >>> >> intercept = unlist(intercept)
> >>> >> za_intercept = unlist(za_intercept)
> >>> >> l1 = unlist(l1)
> >>> >> l2 = unlist(l2)
> >>> >> }
> >>> >>  py_0 = dpois(0, exp(intercept + za_intercept))
> >>> >> y_ygt0 = exp(intercept)
> >>> >> at_intercept = (1-py_0) * y_ygt0
> >>> >>
> >>> >> py_0 = dpois(0, exp(intercept + za_intercept + l2))
> >>> >> y_ygt0 = exp(intercept +  l1)
> >>> >> at_predictor_1 = (1-py_0) * y_ygt0
> >>> >> print(qplot(at_intercept))
> >>> >> print(qplot(at_predictor_1))
> >>> >> df = data.frame("intercept" = at_intercept)
> >>> >> df[, predictor] = at_predictor_1
> >>> >> print(qplot(x=variable,
> >>> >> y=value,data=suppressMessages(melt(df)),fill=variable,alpha=
> I(0.40),
> >>> geom =
> >>> >> 'violin'))
> >>> >> print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
> >>> >> print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
> >>> >> invisible(df)
> >>> >> }
> >>> >>
> >>> >>
> >>> >> > summary(object[[1]])
> >>> >>
> >>> >>  Iterations = 100001:299901
> >>> >>  Thinning interval  = 100
> >>> >>  Sample size  = 2000
> >>> >>
> >>> >>  DIC: 349094
> >>> >>
> >>> >>  G-structure:  ~idh(trait):idParents
> >>> >>
> >>> >>                       post.mean l-95% CI u-95% CI eff.samp
> >>> >> children.idParents       0.0189   0.0164   0.0214     1729
> >>> >> za_children.idParents    0.2392   0.2171   0.2622     1647
> >>> >>
> >>> >>  R-structure:  ~idh(trait):units
> >>> >>
> >>> >>                   post.mean l-95% CI u-95% CI eff.samp
> >>> >> children.units        0.144    0.139    0.148     1715
> >>> >> za_children.units     1.000    1.000    1.000        0
> >>> >>
> >>> >>  Location effects: children ~ trait * (maternalage.factor +
> >>> paternalloss +
> >>> >> maternalloss + center(nr.siblings) + birth.cohort + urban + male +
> >>> >> paternalage.mean + paternalage.diff)
> >>> >>
> >>> >>                                            post.mean  l-95% CI
> u-95%
> >>> CI
> >>> >> eff.samp   pMCMC
> >>> >> (Intercept)                                 2.088717  2.073009
> >>> 2.103357
> >>> >>   2000 <0.0005 ***
> >>> >> traitza_children                           -1.933491 -1.981945
> >>> -1.887863
> >>> >>   2000 <0.0005 ***
> >>> >> maternalage.factor(14,20]                   0.007709 -0.014238
> >>> 0.027883
> >>> >>   1500   0.460
> >>> >> maternalage.factor(35,50]                   0.006350 -0.009634
> >>> 0.024107
> >>> >>   2000   0.462
> >>> >> paternallossTRUE                            0.000797 -0.022716
> >>> 0.025015
> >>> >>   2000   0.925
> >>> >> maternallossTRUE                           -0.015542 -0.040240
> >>> 0.009549
> >>> >>   2000   0.226
> >>> >> center(nr.siblings)                         0.005869  0.004302
> >>> 0.007510
> >>> >>   2000 <0.0005 ***
> >>> >> birth.cohort(1703,1722]                    -0.045487 -0.062240
> >>> -0.028965
> >>> >>   2000 <0.0005 ***
> >>> >> birth.cohort(1722,1734]                    -0.055872 -0.072856
> >>> -0.036452
> >>> >>   2000 <0.0005 ***
> >>> >> birth.cohort(1734,1743]                    -0.039770 -0.056580
> >>> -0.020907
> >>> >>   2000 <0.0005 ***
> >>> >> birth.cohort(1743,1750]                    -0.030713 -0.048301
> >>> -0.012214
> >>> >>   2000   0.002 **
> >>> >> urban                                      -0.076748 -0.093240
> >>> -0.063002
> >>> >>   2567 <0.0005 ***
> >>> >> male                                        0.106074  0.095705
> >>> 0.115742
> >>> >>   2000 <0.0005 ***
> >>> >> paternalage.mean                           -0.024119 -0.033133
> >>> -0.014444
> >>> >>   2000 <0.0005 ***
> >>> >> paternalage.diff                           -0.018367 -0.032083
> >>> -0.005721
> >>> >>   2000   0.007 **
> >>> >> traitza_children:maternalage.factor(14,20] -0.116510 -0.182432
> >>> -0.051978
> >>> >>   1876   0.001 ***
> >>> >> traitza_children:maternalage.factor(35,50] -0.045196 -0.094485
> >>> 0.002640
> >>> >>   2000   0.075 .
> >>> >> traitza_children:paternallossTRUE          -0.171957 -0.238218
> >>> -0.104820
> >>> >>   2000 <0.0005 ***
> >>> >> traitza_children:maternallossTRUE          -0.499539 -0.566825
> >>> -0.430637
> >>> >>   2000 <0.0005 ***
> >>> >> traitza_children:center(nr.siblings)       -0.023723 -0.028676
> >>> -0.018746
> >>> >>   1848 <0.0005 ***
> >>> >> traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250
> >>> 0.026024
> >>> >>   2000   0.319
> >>> >> traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462
> >>> -0.227187
> >>> >>   2000 <0.0005 ***
> >>> >> traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659
> >>> -0.204462
> >>> >>   2130 <0.0005 ***
> >>> >> traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568
> >>> -0.426648
> >>> >>   2000 <0.0005 ***
> >>> >> traitza_children:urban                     -0.604108 -0.645169
> >>> -0.562554
> >>> >>   1702 <0.0005 ***
> >>> >> traitza_children:male                      -0.414988 -0.444589
> >>> -0.387005
> >>> >>   2000 <0.0005 ***
> >>> >> traitza_children:paternalage.mean           0.006545 -0.018570
> >>> 0.036227
> >>> >>   2000   0.651
> >>> >> traitza_children:paternalage.diff          -0.097982 -0.136302
> >>> -0.060677
> >>> >>   2000 <0.0005 ***
> >>> >>
> >>> >>
> >>> >> On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com>
> wrote:
> >>> >>
> >>> >>> Ruben Arslan <rubenarslan at ...> writes:
> >>> >>>
> >>> >>> >
> >>> >>> > Dear list,
> >>> >>> >
> >>> >>> > I wanted to ask: Is there any (maybe just back of the envelope)
> way
> >>> to
> >>> >>> > obtain a response prediction for zero-inflated or hurdle type
> >>> models?
> >>> >>> > I've fit such models in MCMCglmm, but I don't work in ecology
> and my
> >>> >>> > previous experience with explaining such models to "my audience"
> >>> did not
> >>> >>> > bode well. When it comes to humans, the researchers I presented
> to
> >>> are
> >>> >>> not
> >>> >>> > used to offspring count being zero-inflated (or acquainted with
> that
> >>> >>> > concept), but in my historical data with high infant mortality,
> it
> >>> is
> >>> >>> (in
> >>> >>> > modern data it's actually slightly underdispersed).
> >>> >>> >
> >>> >>> > Currently I'm using lme4 and simply splitting my models into two
> >>> stages
> >>> >>> > (finding a mate and having offspring).
> >>> >>> > That's okay too, but in one population the effect of interest is
> not
> >>> >>> > clearly visible in either stage, only when both are taken
> together
> >>> (but
> >>> >>> > then the outcome is zero-inflated).
> >>> >>> > I expect to be given a hard time for this and hence thought I'd
> use
> >>> a
> >>> >>> > binomial model with the outcome offspring>0 as my main model, but
> >>> that
> >>> >>> > turns out to be hard to explain too and doesn't
> >>> >>> > really do the data justice.
> >>> >>> >
> >>> >>> > Basically I don't want to be forced to discuss my smallest
> >>> population
> >>> >>> as a
> >>> >>> > non-replication of the effect because I was insufficiently able
> to
> >>> >>> explain
> >>> >>> > the statistics behind my reasoning that the effect shows.
> >>> >>>
> >>> >>>   I think the back-of-the envelope answer would be that for a
> >>> two-stage
> >>> >>> model with a prediction of p_i for the probability of having a
> >>> non-zero
> >>> >>> response (or in the case of zero-inflated models, the probability
> of
> >>> >>> _not_ having a structural zero) and a prediction of n_i for the
> >>> >>> conditional
> >>> >>> part of the model, the mean predicted value is p_i*n_i and the
> >>> >>> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 +
> >>> var(n_i)/n_i^2)
> >>> >>> (this is assuming
> >>> >>> that you haven't built in any correlation between p_i and n_i,
> which
> >>> >>> would be hard in lme4 but _might_ be possible under certain
> >>> circumstances
> >>> >>> via a multitype model in MCMCglmm).
> >>> >>>
> >>> >>>   Does that help?
> >>> >>>
> >>> >>> _______________________________________________
> >>> >>> R-sig-mixed-models at r-project.org mailing list
> >>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>> >>>
> >>> >>
> >>> >
> >>> >       [[alternative HTML version deleted]]
> >>> >
> >>> > _______________________________________________
> >>> > R-sig-mixed-models at r-project.org mailing list
> >>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>> >
> >>> >
> >>>
> >>>
> >>>
> >>> --
> >>> The University of Edinburgh is a charitable body, registered in
> >>> Scotland, with registration number SC005336.
> >>>
> >>>
> >>>
> >
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Mar 18 15:57:35 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 18 Mar 2015 14:57:35 +0000
Subject: [R-sig-ME] transform glmer model into MCMCglmm: how to define
 the priors?
In-Reply-To: <web-254079042@uni-freiburg.de>
References: <web-254004262@uni-freiburg.de>
	<20150318061850.29976xmtuv3i3808@www.staffmail.ed.ac.uk>
	<web-254079042@uni-freiburg.de>
Message-ID: <20150318145735.1003200ruxgsul34@www.staffmail.ed.ac.uk>

Hi,

This works fine on my computer and with old versions.  I think the  
problem is not due to MCMCglmm:

http://stackoverflow.com/questions/21367922/error-in-getas-characterfun-mode-function-envir-envir

perhaps open a new session without history, and try running the script  
you sent me. Does the problem persist?

Jarrod


Quoting Anne Krause <anne.krause at frequenz.uni-freiburg.de> on Wed, 18  
Mar 2015 14:35:29 +0100:

> Dear Jarrod,
> thank you so much for your quick reply and the prior which
> finally got me started on a working model:
>
> k <- length(levels(imp$form))
> IJ <- (1/k) * (diag(k-1) + matrix(1, k-1, k-1))
>
> prior<-list(
>   R=list(V=IJ, fix=1),
>   G=list(
>     G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
>    alpha.V=diag(2)*1000),
>     G2=list(V=diag(2), nu=2, alpha.mu=c(0,0),
> alpha.V=diag(2)*1000)))
>
>
> model1 <- MCMCglmm(form~trait:frequency+trait:recency+
>                  trait:year-1,
>                  random=~us(trait):author+us(trait):verb,
>                  rcov=~us(trait):units,
>                  prior=prior,
>                  data=imp, family="categorical",)
>
> The summary problem unfortunately remains the same. I have
> attached the data and R script and hope that you (or
> someone else on the list) can figure this out.
>
> Thanks a lot!
>
> Best, Anne
>
> On Wed, 18 Mar 2015 06:18:50 +0000
>  Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> Hi,
>>
>> You will need priors for this model: the
>> observation-level (units) effects are not identifiable.
>> The random effect covariance structures are 2x2 matrices.
>> For these models I fix the residual covariance matrix at
>>
>> IJ <- (1/k) * (diag(k-1) + matrix(1, k-1, k-1))
>>
>> where k is the number of categories in the response:
>>
>>
>> A starting prior might look something like:
>>
>> prior=list(R=list(V=IJ, fix=1), G=list(G1=list(V=diag(2),
>> nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>
>>
>> Although I haven't seen it done (although I don't know
>> the literature on multinomial models) it might make sense
>> to have the random effect covarinace matrix proportional
>> to IJ and estimate a single variance component (rather
>> than a 2x2 covariance matrix). The rational behind the IJ
>> matrix is that the propensity to belong to a category
>> varies over random effects, but variation in the
>> propensity is equal for all categories, and the
>> propensity for two categories are uncorrelated. In
>> non-multinomial models such an assumption would be
>> represented by an identity matrix (i.e. trait:author) but
>> for multinomial models this is a bit trickier because
>> things are parameterised in terms of differences from a
>> base-line category.
>>
>> The error you are getting does not look like it is a
>> MCMCglmm issue. Could you post the data (or a
>> reproducible example) so I can check?
>>
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Anne Krause
>> <anne.krause at frequenz.uni-freiburg.de> on Tue, 17 Mar
>> 2015 18:06:48 +0100:
>>
>> > Dear list members,
>> > I am a linguist who would like to use MCMCglmm in order
>> to
>> > model change in language morphology. I have a 3-level
>> > dependent variable (unordered) which are 3 realisations
>> of
>> > a morphological form in German. Say, I call them A, B,
>> and
>> > C - A and B share the same vowel, B and C share the
>> > suffixation.
>> > I did not know about MCMCglmm until recently; therefore
>> I
>> > worked with two glmer models, looking at vowel and
>> > suffixation separately. However, I have been criticised
>> for
>> > the clumsy model interpretation, and I am sure that the
>> > output of a MCMCglmm would be more straightforward and
>> > convincing.
>> >
>> > My glmer looks like this:
>> > model <- glmer(vowel~frequency+year+recency+
>> >                   frequency*recency+
>> >                   (1|verb)+(1|author), data=imp,
>> >                   family=binomial)
>> > - where ?vowel? differentiates between AB on the one
>> hand
>> > and C on the other hand,
>> > - ?frequency? and ?year? are numeric fixed variables
>> and
>> > ?recency? a categorical fixed variable (7 levels),
>> > - ?verb? and ?author? are categorical random variables
>> >
>> > The model for the dependent variable ?suffix? is
>> > practically the same (part of the criticism), ?suffix?
>> > distinguishing between A on the one hand and BC on the
>> > other hand.
>> >
>> > Trying to transform this into an MCMCglmm, I managed to
>> get
>> > as far as this:
>> > model2 <- MCMCglmm(form~trait:frequency+trait:recency+
>> >                   trait:year-1,
>> >                   random=~us(trait):author,
>> >                   rcov=~us(trait):units,
>> >                   data=imp, family="categorical",)
>> > (?form? now distinguishing between all 3 three levels
>> of
>> > the dependent variable A, B, and C)
>> >
>> > I am well aware that this model is running without
>> priors.
>> > Whichever prior I tried gave me the error ?V is the
>> wrong
>> > dimension for some prior$G/prior$R elements? and I have
>> no
>> > idea (after reading through the general description,
>> the
>> > tutorial, the course notes and entries in this mailing
>> > list) how these priors are defined. I guess there is no
>> > rule of thumb, but I hope this short explanation of my
>> > variables is enough for someone of you to point out a
>> > solution (or a starting point for me). I also need to
>> > include the second random from above (?verb?) and the
>> > interaction between ?frequency? and ?recency?.
>> >
>> > Even though model2 is running, I cannot call the
>> summary
>> > for it (error: ?Error in get(as.character(FUN), mode =
>> > "function", envir = envir) :   object 'C:\Users\Anne
>> > Krause\some_directory.Rdata' of mode 'function' was not
>> > found?), which probably has to do with the fact that I
>> did
>> > not include priors (?!).
>> >
>> > Thank you so much in advance for help and/ or comments,
>> > pointers or the like!
>> >
>> > Best, Anne
>> > ____________________________________
>> >
>> > Anne Krause
>> > Research Training Group GRK DFG 1624
>> > "Frequency Effects in Language"
>> > University of Freiburg
>> > Belfortstra?e 18
>> > 79098 Freiburg
>> >
>> > Phone: 0761/203-97670
>> > frequenz.uni-freiburg.de/krause
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> >
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>>
>>
>> --
>> The University of Edinburgh is a charitable body,
>> registered in
>> Scotland, with registration number SC005336.
>>
>>
>
> ____________________________________
>
> Anne Krause
> Research Training Group GRK DFG 1624
> "Frequency Effects in Language"
> University of Freiburg
> Belfortstra?e 18
> 79098 Freiburg
>
> Phone: 0761/203-97670
> frequenz.uni-freiburg.de/krause
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From asafw.at.wharton at gmail.com  Tue Mar 17 01:06:37 2015
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Mon, 16 Mar 2015 20:06:37 -0400
Subject: [R-sig-ME] lmer fails when too many observations
In-Reply-To: <5500B31A.1010900@gmail.com>
References: <CAGG0PdDFQQLyVng=ReMr4wXbGmn7eoNhM7h0=ZZ+SudWbUyMKA@mail.gmail.com>
	<5500B31A.1010900@gmail.com>
Message-ID: <CAGG0PdDMGtEAFZaWW0QEuTSck8YUm9BATp7kOt=7D9Jk3HGMKg@mail.gmail.com>

Thank you very much Ben for the detailed explanation, this is so helpful.
I did set warn=2, as you mention. Anyhow, this is very useful information.

Asaf

On 11 March 2015 at 17:26, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>   Just a quick update on this.
>   This 'failure' is coming because (1) the current version of lme4 has
> too strict a test for convergence and gives what we think are
> false-positive warnings, especially for large data sets; (2) you have
> set options(warn=2) so that warnings get converted into errors.  Until
> we get the issue fixed (which could take a while, as we haven't yet
> given up on finding a more principled way than just increasing the
> default tolerance a lot) you can either (a) convert your warnings back
> to regular warnings (i.e. options(warn=1) or options(warn=0) or (b)
> increase the tolerance level, e.g.
>
>  control= lmerControl(check.conv.grad = .makeCC("warning", tol = 1e-2))
>
> or
>
>  control = lmerControl(check.conv.grad = "ignore")
>
>
>
> On 15-03-09 09:52 PM, Asaf Weinstein wrote:
> > Dear lmer community,
> >
> > I am trying to run a simulation for a two-way random-effects model
> > with unbalanced design (ie, unequal number of observations per
> > cell) and no interaction. It's especially important for me to be
> > able to run the lmer/blmer functions when the number of (column and
> > row) random effects is large, say 100, and with possible replicates
> > in each cell. The problem is that lmer() works with the full vector
> > of observations, as opposed to working with the cell averages
> > (which is a sufficient statistic), and the methods fails pretty
> > quickly when there are replicates (because the response vector is
> > too big, I suppose). I get the following error:
> >
> > *Error in get("checkConv", lme4Env)(attr(opt, "derivs"), opt$par,
> > ctrl = control$checkConv,  : * *  (converted from warning) Model
> > failed to converge with max|grad| = 0.00244385 (tol = 0.002)*
> >
> > Just to give an example: suppose there are R=100 row effects, C=100
> > column effects, and 5 replicates in each cell. The vector of
> > individual observations is of length 100^5 (lmer fails), while the
> > vector of cell averages is of length 100^2 (a size which causes no
> > problem for lmer). My question is whether there is a way to tell
> > lmer() to work with the sufficient statistic (of course, the
> > conditional covariance is no longer c*Identity, a fact which is
> > used in the implementation of lmer (according to documentation) ).
> >
> > Thank you very much and I hope I was clear!
>
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVALMaAAoJEOCV5YRblxUHnRwH/j8/MFNfYKgvgzbBBCdmfXOi
> nfRGRpGWrFUM7MznFWFf4hdA0SFPUOTS9yZYxoGuyJHos1q5WeAyR9kdlqNQjdDx
> lPV+zYy9gsj+uMl5XBVSurDrfJY+JXfnqtOzZECMbrZjNxHgTMnSxzMdRNVZAVm6
> DaCAaNGJkeTI96k4jg7ucj1p/xGgk3deVW8NMY3bKMasd+dtFzTXqPDvEYovBRQT
> sbQ7SavzjJY93QYHabaaDkpsD8N86qe5fJgOE9uVLNkvuOGVPELvwG8lCaC/kj7y
> wdd4+HOum1AgeBUosCRfs+Ld41V4wBUySxFW9coLRUVwzQGfU8rOTjIpKs4iCpY=
> =jitR
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From lupp at uchicago.edu  Tue Mar 17 19:24:27 2015
From: lupp at uchicago.edu (Stuart Luppescu)
Date: Tue, 17 Mar 2015 13:24:27 -0500
Subject: [R-sig-ME] lme4 upgrade broke my old code?
In-Reply-To: <550863F8.9060300@gmail.com>
References: <1426608081.31324.8.camel@ccsr.uchicago.edu>
	<5508609C.7000207@ffri.hr> <550863F8.9060300@gmail.com>
Message-ID: <1426616667.31324.11.camel@uchicago.edu>

On Tue, 2015-03-17 at 13:27 -0400, Ben Bolker wrote:
> I think that starting with version 1, lme4 was not compatible with
> > the lower version code. I am afraid that you will have to calculate
> > the old models again with the newer lme4.
> > 
> > Cheers,
> > 
> > Marko
> 
>   There is some help here.  If you install the lme4.0 package (see the
> README at https://github.com/lme4/lme4 ) you can at least use
> convert_old_lme4() to update lme4 pre 1.0 to lme4.0  ...  We don't
> currently have a function to convert stuff that old to modern lme4
> (lots of the internal structures have changed), but if you want to
> badly enough you can use lme4.0 ...

That's what I was afraid of. Thanks Marko and Ben. I'm rerunning it now
-- takes a long time with 2.5 million observations.

-- 
Stuart Luppescu -=-=- slu <AT> ccsr <DOT> uchicago <DOT> edu
CCSR at U of C ,.;-*^*-;.,  ccsr.uchicago.edu
     (^_^)/    ????????
[Crash programs] fail because they are based on the theory that, 
with nine women pregnant, you can get a baby a month.
                -- Wernher von Braun


From mwiederm at mtu.edu  Wed Mar 18 13:07:02 2015
From: mwiederm at mtu.edu (Magdalena Wiedermann)
Date: Wed, 18 Mar 2015 08:07:02 -0400
Subject: [R-sig-ME] repeated measures on split plot design
Message-ID: <55096A66.50504@mtu.edu>

Dear Thierry

Thank you so very much for taking this on and helping out. I was 
particularly happy about the glmm wiki link you sent. It contained a lot 
of relevant information in an organized way. THANK YOU! Now I also 
understand what you are getting at with your question about the 
correlation structure of the random factors. My Crawley based 
understanding  (Crawley 2007 "The R Book" page 472-473) comes closest to 
"2. Effects are fixed if they are interesting in themselves or random if 
there is interest in the underlying population."

I am likely dealing with crossed random effects:
"Relatively few mixed effect modelling packages can handle crossed 
random effects, i.e. those where one level of a random effect can appear 
in conjunction with more than one level of another effect. (This 
definition is confusing, and I would happily accept a better one.) A 
classic example is crossed temporal and spatial effects. If there is 
random variation among temporal blocks (e.g. years) ''and'' random 
variation among spatial blocks (e.g. sites), ''and'' if there is a 
consistent year effect across sites and ''vice versa'', then the random 
effects should be treated as crossed."

However I consider some of my spacial autocorrelation weak. The main 
factor that causes variation (in just about everything) in that system 
is water table. My within block variation is greater than my between 
block variation. Where we do have a high degree of spacial 
autocorrelation is by sampling 2 depth within each plot that are more or 
less on top of each other.

When it comes to time on the other hand May 2012 is more closely related 
to June 2012 than it is to October 2012 or September 2014.

For the random part I am primarily interested in formulating the model 
as to avoid pseudoreplication. My n=316 (I have a few missing values and 
dates) but really I only have 12 plots (4 blocks if used in a split plot 
analysis). I am aware that the 4 levels of block is not a good 
representation of the population of levels which is a requirement for it 
to be a random factor. But how do I formulate the model without running 
into pseudoreplication?

For pretty much all the analysis I have ever done nlme and lme4 resulted 
in the same F-values (with marginal differences). nlme and glmmPQL (the 
SAS person had suggested a Gamma distribution, which I am not entirely 
convinced of) yield exactly the same Dd.f.

Do you have any examples of code for crossed random effects?
I ran it like this but can not tell whether or not it makes sense.

|nlme & car:
m1<-lme(||log(||responses||)||~veg*depth*year*Month, random=~1|block/veg/year/Month, data=T)||
anova(m1)|

I am actually planing to include water table too
|m2<-lme(||log(||responses||)||~veg*depth*WT*year*Month, random=~1|block/veg/year/Month, data=T)||
anova(m2)|

Thank you so much!!
Lea



From anne.krause at frequenz.uni-freiburg.de  Wed Mar 18 19:00:22 2015
From: anne.krause at frequenz.uni-freiburg.de (Anne Krause)
Date: Wed, 18 Mar 2015 19:00:22 +0100
Subject: [R-sig-ME] transform glmer model into MCMCglmm: how to define
 the priors?
In-Reply-To: <20150318145735.1003200ruxgsul34@www.staffmail.ed.ac.uk>
References: <web-254004262@uni-freiburg.de>
	<20150318061850.29976xmtuv3i3808@www.staffmail.ed.ac.uk>
	<web-254079042@uni-freiburg.de>
	<20150318145735.1003200ruxgsul34@www.staffmail.ed.ac.uk>
Message-ID: <web-254103704@uni-freiburg.de>

Dear Jarrod,
thanks for the link. The problem persisted until I renamed
the model. Now I can call the summary.

I cannot say it often enough: Thank you so much for your
help! In less than a day (!!!) I went from "never going to
solve this problem :-(" to "yeah! this is working! :-D".

Best, Anne 

On Wed, 18 Mar 2015 14:57:35 +0000
 Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi,
> 
> This works fine on my computer and with old versions.  I
> think the problem is not due to MCMCglmm:
> 
>
http://stackoverflow.com/questions/21367922/error-in-getas-characterfun-mode-function-envir-envir
> 
> perhaps open a new session without history, and try
> running the script you sent me. Does the problem persist?
> 
> Jarrod
> 
> 
> Quoting Anne Krause
> <anne.krause at frequenz.uni-freiburg.de> on Wed, 18 Mar
> 2015 14:35:29 +0100:
> 
> > Dear Jarrod,
> > thank you so much for your quick reply and the prior
> which
> > finally got me started on a working model:
> >
> > k <- length(levels(imp$form))
> > IJ <- (1/k) * (diag(k-1) + matrix(1, k-1, k-1))
> >
> > prior<-list(
> >   R=list(V=IJ, fix=1),
> >   G=list(
> >     G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
> >    alpha.V=diag(2)*1000),
> >     G2=list(V=diag(2), nu=2, alpha.mu=c(0,0),
> > alpha.V=diag(2)*1000)))
> >
> >
> > model1 <- MCMCglmm(form~trait:frequency+trait:recency+
> >                  trait:year-1,
> >
>                  random=~us(trait):author+us(trait):verb,
> >                  rcov=~us(trait):units,
> >                  prior=prior,
> >                  data=imp, family="categorical",)
> >
> > The summary problem unfortunately remains the same. I
> have
> > attached the data and R script and hope that you (or
> > someone else on the list) can figure this out.
> >
> > Thanks a lot!
> >
> > Best, Anne
> >
> > On Wed, 18 Mar 2015 06:18:50 +0000
> >  Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> >> Hi,
> >>
> >> You will need priors for this model: the
> >> observation-level (units) effects are not
> identifiable.
> >> The random effect covariance structures are 2x2
> matrices.
> >> For these models I fix the residual covariance matrix
> at
> >>
> >> IJ <- (1/k) * (diag(k-1) + matrix(1, k-1, k-1))
> >>
> >> where k is the number of categories in the response:
> >>
> >>
> >> A starting prior might look something like:
> >>
> >> prior=list(R=list(V=IJ, fix=1),
> G=list(G1=list(V=diag(2),
> >> nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
> >>
> >>
> >> Although I haven't seen it done (although I don't know
> >> the literature on multinomial models) it might make
> sense
> >> to have the random effect covarinace matrix
> proportional
> >> to IJ and estimate a single variance component (rather
> >> than a 2x2 covariance matrix). The rational behind the
> IJ
> >> matrix is that the propensity to belong to a category
> >> varies over random effects, but variation in the
> >> propensity is equal for all categories, and the
> >> propensity for two categories are uncorrelated. In
> >> non-multinomial models such an assumption would be
> >> represented by an identity matrix (i.e. trait:author)
> but
> >> for multinomial models this is a bit trickier because
> >> things are parameterised in terms of differences from
> a
> >> base-line category.
> >>
> >> The error you are getting does not look like it is a
> >> MCMCglmm issue. Could you post the data (or a
> >> reproducible example) so I can check?
> >>
> >>
> >> Cheers,
> >>
> >> Jarrod
> >>
> >>
> >>
> >>
> >> Quoting Anne Krause
> >> <anne.krause at frequenz.uni-freiburg.de> on Tue, 17 Mar
> >> 2015 18:06:48 +0100:
> >>
> >> > Dear list members,
> >> > I am a linguist who would like to use MCMCglmm in
> order
> >> to
> >> > model change in language morphology. I have a
> 3-level
> >> > dependent variable (unordered) which are 3
> realisations
> >> of
> >> > a morphological form in German. Say, I call them A,
> B,
> >> and
> >> > C - A and B share the same vowel, B and C share the
> >> > suffixation.
> >> > I did not know about MCMCglmm until recently;
> therefore
> >> I
> >> > worked with two glmer models, looking at vowel and
> >> > suffixation separately. However, I have been
> criticised
> >> for
> >> > the clumsy model interpretation, and I am sure that
> the
> >> > output of a MCMCglmm would be more straightforward
> and
> >> > convincing.
> >> >
> >> > My glmer looks like this:
> >> > model <- glmer(vowel~frequency+year+recency+
> >> >                   frequency*recency+
> >> >                   (1|verb)+(1|author), data=imp,
> >> >                   family=binomial)
> >> > - where ?vowel? differentiates between AB on the one
> >> hand
> >> > and C on the other hand,
> >> > - ?frequency? and ?year? are numeric fixed variables
> >> and
> >> > ?recency? a categorical fixed variable (7 levels),
> >> > - ?verb? and ?author? are categorical random
> variables
> >> >
> >> > The model for the dependent variable ?suffix? is
> >> > practically the same (part of the criticism),
> ?suffix?
> >> > distinguishing between A on the one hand and BC on
> the
> >> > other hand.
> >> >
> >> > Trying to transform this into an MCMCglmm, I managed
> to
> >> get
> >> > as far as this:
> >> > model2 <-
> MCMCglmm(form~trait:frequency+trait:recency+
> >> >                   trait:year-1,
> >> >                   random=~us(trait):author,
> >> >                   rcov=~us(trait):units,
> >> >                   data=imp, family="categorical",)
> >> > (?form? now distinguishing between all 3 three
> levels
> >> of
> >> > the dependent variable A, B, and C)
> >> >
> >> > I am well aware that this model is running without
> >> priors.
> >> > Whichever prior I tried gave me the error ?V is the
> >> wrong
> >> > dimension for some prior$G/prior$R elements? and I
> have
> >> no
> >> > idea (after reading through the general description,
> >> the
> >> > tutorial, the course notes and entries in this
> mailing
> >> > list) how these priors are defined. I guess there is
> no
> >> > rule of thumb, but I hope this short explanation of
> my
> >> > variables is enough for someone of you to point out
> a
> >> > solution (or a starting point for me). I also need
> to
> >> > include the second random from above (?verb?) and
> the
> >> > interaction between ?frequency? and ?recency?.
> >> >
> >> > Even though model2 is running, I cannot call the
> >> summary
> >> > for it (error: ?Error in get(as.character(FUN), mode
> =
> >> > "function", envir = envir) :   object 'C:\Users\Anne
> >> > Krause\some_directory.Rdata' of mode 'function' was
> not
> >> > found?), which probably has to do with the fact that
> I
> >> did
> >> > not include priors (?!).
> >> >
> >> > Thank you so much in advance for help and/ or
> comments,
> >> > pointers or the like!
> >> >
> >> > Best, Anne
> >> > ____________________________________
> >> >
> >> > Anne Krause
> >> > Research Training Group GRK DFG 1624
> >> > "Frequency Effects in Language"
> >> > University of Freiburg
> >> > Belfortstra?e 18
> >> > 79098 Freiburg
> >> >
> >> > Phone: 0761/203-97670
> >> > frequenz.uni-freiburg.de/krause
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> >
> >>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >> >
> >>
> >>
> >> --
> >> The University of Edinburgh is a charitable body,
> >> registered in
> >> Scotland, with registration number SC005336.
> >>
> >>
> >
> > ____________________________________
> >
> > Anne Krause
> > Research Training Group GRK DFG 1624
> > "Frequency Effects in Language"
> > University of Freiburg
> > Belfortstra?e 18
> > 79098 Freiburg
> >
> > Phone: 0761/203-97670
> > frequenz.uni-freiburg.de/krause
> >
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body,
> registered in
> Scotland, with registration number SC005336.
> 
> 

____________________________________

Anne Krause
Research Training Group GRK DFG 1624
"Frequency Effects in Language"
University of Freiburg
Belfortstra?e 18
79098 Freiburg

Phone: 0761/203-97670
frequenz.uni-freiburg.de/krause


From bbolker at gmail.com  Wed Mar 18 21:26:13 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Mar 2015 16:26:13 -0400
Subject: [R-sig-ME] lme4 upgrade broke my old code?
In-Reply-To: <1426616667.31324.11.camel@uchicago.edu>
References: <1426608081.31324.8.camel@ccsr.uchicago.edu>	<5508609C.7000207@ffri.hr>
	<550863F8.9060300@gmail.com>
	<1426616667.31324.11.camel@uchicago.edu>
Message-ID: <5509DF65.4040605@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-17 02:24 PM, Stuart Luppescu wrote:
> On Tue, 2015-03-17 at 13:27 -0400, Ben Bolker wrote:
>> I think that starting with version 1, lme4 was not compatible
>> with
>>> the lower version code. I am afraid that you will have to
>>> calculate the old models again with the newer lme4.
>>> 
>>> Cheers,
>>> 
>>> Marko
>> 
>> There is some help here.  If you install the lme4.0 package (see
>> the README at https://github.com/lme4/lme4 ) you can at least
>> use convert_old_lme4() to update lme4 pre 1.0 to lme4.0  ...  We
>> don't currently have a function to convert stuff that old to
>> modern lme4 (lots of the internal structures have changed), but
>> if you want to badly enough you can use lme4.0 ...
> 
> That's what I was afraid of. Thanks Marko and Ben. I'm rerunning it
> now -- takes a long time with 2.5 million observations.
> 


  Even in the absence of my more complicated suggestion (trying to
populate the merMod object with already-computed stuff), I would make
sure you are

(1) starting from the previously computed best-fit values
(2) using the known tricks for optimizing speed -- in particular I
would use control=lmerControl(optimizer="nloptwrap"), as the default
bobyqa optimizer uses tolerance criteria that are probably stricter
than they need to be.

   cheers
    Ben

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVCd9lAAoJEOCV5YRblxUHRRkH/31iRyILEMpdlnc1NqH/Zpyf
z0E5/Juv44PPtZxl8t2EC4zbrl+UPm7ML9olvjHa/W6vGtyfD3M9hIHi4FkyHhWx
eOjmtVzl8v9aAtyMDIYGEZC+aDxttPcpe71JieWMw4zEPSXZTMyGpzDrlIJ/h+Lg
Ts74sw9iXb8Q/qgxnY5PVMICt+XyxflcsfZ8nzha5I/ECdgw9F36RjizoJh9fFH8
eH2Q1iH+VIwT/nuQmLNy9yQOUttTpV/7jsSRVwb3gFAell2JioQKa9DVudYLE20I
Mssb0QAQ4x89iiiVrlmmPgO0ZSRW8NpPUemC7l8hR3S8eNco98Cq5kSD0PVMSPU=
=XkiQ
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Thu Mar 19 04:45:19 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 19 Mar 2015 03:45:19 +0000 (UTC)
Subject: [R-sig-ME] Problems with convergence
References: <CAF5_5cxHcAWSvgYL3876407aM5tM4pVBB+LTjr_gKPc7Bh8rbQ@mail.gmail.com>
Message-ID: <loom.20150319T042938-705@post.gmane.org>

Ken Beath <ken.beath at ...> writes:

 
> The following code shows that there are convergence problem messages
> where there is a problem with convergence. The profiling shows that
> the maximum found is not the correct one. This is simulated data for
> a binary meta-analysis with fixed effect for study and random effect
> for treatment.
 
  I'm not 100% sure what the point is here (that's a real question,
not a criticism).  I *think* it's that we can get a convergence
failure with a computed gradient size that seems fairly innocuous
(only 0.003, which is perhaps below what I where I would have set
the new cutoff to eliminate a lot of the probably-false-positives
that people have been getting with larger data sets), which is 
nevertheless a real convergence failure.  This underscores the
need to set a gradient tolerance that is data-set-size-dependent
(which the developers have discussed a bit, but maybe not in a 
public forum).

  However, may I comment that this is a slightly ridiculous scenario?
The data set here has 40 observations, and the model tries to fit 22
parameters.  The model that treats id as a random effect works much
better.  I can believe there are scenarios where you really do
want study as a fixed effect, but did you expect it to be practical
here?

But maybe you're just trying to show that this is a "true positive"
case for the convergence warnings.

Some random code I wrote while diagnosing what was going on:

library(ggplot2); theme_set(theme_bw())

## proportion + weights is a little easier to handle
thedata <- transform(thedata,prop=nEvents/total)

ggplot(thedata,aes(trt,prop))+geom_point(aes(size=total))+
    geom_line(aes(group=id),colour="gray")
glmer1 <- glmer(prop~trt+factor(id)+(0+trt|id),
                weights=total,data=thedata,family=binomial)

## id as RE
glmer2 <- glmer(prop~trt+(1|id)+(0+trt|id),
                weights=total,data=thedata,family=binomial)

dd <- update(glmer1,devFunOnly=TRUE)
pars <- unlist(getME(glmer1,c("theta","fixef")))
library("bbmle")
ss <- slice2D(pars,dd)
library("lattice")
plot(ss)
## too complex, but too much work to cut down significantly


> library(lme4)
> 
> thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
> 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
> 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
> 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
> 200,200,200,200,200,200,200,200,200,200,200,200,200,
> 200,200,200,200,200,200,200,200,200,200,200,200,200,
> 200,200,200,200,200,200,200,200,200,200),trt=c(0,
> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
> 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
> 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
> 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
> 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
> "2","3","4","5","6","7","8","9","10","11","12","13",
> "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
> "total","trt","id"),row.names=c(NA,40L),class="data.frame")
> 
> glmer1<-glmer(cbind(nEvents,total-nEvents)~trt+factor(id)+
##   (0+trt|id),data=thedata,family=binomial)
> 
> # while glmer has problems with component 9 it is 8 with a problem profile
> # I've use devtol so the discrepancy is printed
> prof.glmer1<-profile(glmer1,which=8,devtol=1.0e-3)
>


From thierry.onkelinx at inbo.be  Thu Mar 19 14:10:27 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 19 Mar 2015 14:10:27 +0100
Subject: [R-sig-ME] the equation of a mixed model fitted using nlme
In-Reply-To: <CAGL_TsdiJL7hspJ19617FL7km2NqV6pXSCX4DiqBW+rPNiJjLQ@mail.gmail.com>
References: <CAGL_TsdiJL7hspJ19617FL7km2NqV6pXSCX4DiqBW+rPNiJjLQ@mail.gmail.com>
Message-ID: <CAJuCY5zyoWMv+8ZgaF+yQFQXzWeH0R_q-3GgUH=YoAxZkq6S5w@mail.gmail.com>

Dear Jos,

Here is an attempt. Have a look at Pinheiro & Bates (2000) for examples.

$c$ days - 7
$p1$ first order polynomial of days - 7
$p2$ second order polynomial of days - 7
$i$ family index
$j$ habitat index
$k$ treatment index
$l$ observation index

$length_{ijkl} = \beta_0 + \beta_1 p1_{ijkl} + \beta_2 p2_{ijkl} + \beta_j
+ \beta_k + \beta_{1j} p1_{ijkl}  + \beta_{2j} p2_{ijkl} + \beta_{1k}
p1_{ijkl}  + \beta_{2k} p2_{ijkl} + \beta_{1jk} p1_{ijkl}  + \beta_{2jk}
p2_{ijkl} + b_{0i} + b_{1i} p1_{ijkl} + b_{2i} p2_{ijkl} + \epsilon_{ijkl}$

$b_i = \left[{\\begin{array}{c}
  b_{0i} \\\\
  b_{1i} \\\\
  b_{1i}
\\end{array}
}\right]
\sim N(0, \Psi)$

$E[\epsilon_{ijkl}] = 0$
$Var(\epsilon_{ijkl}) = \sigma ^ 2 exp(2 \delta_{jk} c_{ijkl})$

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-18 10:50 GMT+01:00 jos matejus <matejus106 at googlemail.com>:

> Dear R mixed modellers
>
> I am writing to the R mixed modelling community to request some help and
> advice regarding reporting a mixed model in a publication. I have recently
> received referees comments regarding a paper I submitted some time ago. The
> referee has requested that I write one of the models used to analyse my
> data 'statistically'. I think they mean that I should write out the
> equation, and while I don?t think this is unreasonable I am having trouble
> doing so. I know many of you have heard the excuse ?I am not a
> statistician? but I?m afraid that this applies in my case, but I have tried
> for a couple of days to figure this one out and harassed many colleagues
> but without success. Therefore I am hoping I can prevail on the kindness of
> the R mixed modelling community to help me with this problem.
>
> The code used for the model was
>
> vf1Exp<-  varExp(form=~I(days-7)|habitat*treat)
>
> final.model <- lme(length.sq~ poly(I(days-7),2)*treat*habitat, data=mydata,
> method="REML",random=~poly(I(days-7),2)|family, weights=vf1Exp)
>
> length.sq = square root transformed length of fish
>
> days = day following exposure (10, one day intervals starting from day 7
> after exposure)
>
> treat = two level treatment factor
>
> habitat = two level habitat factor
>
> family = 19 level factor
>
>
>
> I have 10 fish per treatment combination (treat*habitat) at each time point
> for each family.
>
>
>
> The second order polynomial term for day was included to account for non
> linear growth and the variance structure to account for an increase in
> variance over time that was different depending on the treatment
> combination. The 3-way interaction was significant.
>
> How should I represent this model as an equation?
>
> Thanks a million for your help.
>
> Jos
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From zsa11 at mail.aub.edu  Fri Mar 20 00:08:04 2015
From: zsa11 at mail.aub.edu (Zahwa Al Ayyash (Student))
Date: Thu, 19 Mar 2015 23:08:04 +0000
Subject: [R-sig-ME] Robust Standard Errors
Message-ID: <1426806478088.73059@mail.aub.edu>

Dear list,

Can we extract the robust standard errors from Poisson/Negative Binomial/Zero Inflated/Hurdle Models in glmmADMB?

If yes, how is this doable?
If no, are there possible consequences of using the standard errors that are returned currently?


Your responses are appreciated, thank you,
Zahwa Al Ayyash




	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Mar 22 03:48:44 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Mar 2015 02:48:44 +0000 (UTC)
Subject: [R-sig-ME] Robust Standard Errors
References: <1426806478088.73059@mail.aub.edu>
Message-ID: <loom.20150322T034025-629@post.gmane.org>

Zahwa Al Ayyash (Student <zsa11 at ...> writes:

> 
> Dear list,
> 
> Can we extract the robust standard errors from 
> Poisson/Negative Binomial/Zero Inflated/Hurdle Models
> in glmmADMB?
> 
> If yes, how is this doable?
> If no, are there possible consequences of using the standard errors that
are returned currently?
> 

  Not easily.

  You could try to implement one of the standard approaches for 
estimating heteroscedasticity-consistent standard errors:

http://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors

I don't know how much trouble you'll get into if you try to estimate
this naively (e.g. you need the inverse of X X^T) ...

  The possible consequences of using the non-robust standard errors
are, as usual, that if the model is misspecified you'll get the wrong
answer.  You have to decide for yourself how much this worries you.
An equal and possibly bigger problem is whether using Wald estimates
of the standard errors for inference is OK in this case.  You might
want to look into profile confidence intervals (hmm, ADMB has
these but they don't seem to be implemented in glmmADBM) or post-hoc
MCMC (which *is* implemented).


From rubenarslan at gmail.com  Mon Mar 23 13:53:20 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Mon, 23 Mar 2015 12:53:20 +0000
Subject: [R-sig-ME] Little variability in outcome;
	"pwrssUpdate did not converge"
Message-ID: <CALv3xzukLbtnxVvT_N+ZRM=BOrUp01zVzXJXOuVfaEpos0LZGQ@mail.gmail.com>

Dear list,

I have a dichotomous outcome (child mortality) with a very high mean
(0.9946) in a large dataset (3.5m).
The "Error: pwrssUpdate did not converge in (maxit) iterations" occurs in
most cases. I've tried using blme to combat complete separation with
fixef.priors with SDs from 1 to 10 without success. The variance explained
by the random family effect is numerically very small (0.000698) though I
suppose that still amounts to ca 7%. There's few members per family (~ 2 on
average). Fitting a glm without the family intercepts results in fairly
different results (which I expect), judging by the few models that ran.
Using less data sometimes leads to convergence, depending on the sample I
draw, I suppose. I'm using bobyqa.

I thought maybe the problem still is complete separation and I'm just being
too timid with the blme prior.

Oddly (maybe not), the only model where I do get convergence is one where I
accidentally mis-specified my sample, so my outcome was censored (hence the
mean but not the intercept was lower). I'm attaching the model.

Best regards,

Ruben Arslan

## Cov prior : idParents ~ wishart(df = 3.5, scale = Inf, posterior.scale =
cov, common.scale = TRUE) ## Fixef prior: normal(sd = c(9, 9, ...), corr =
c(0 ...), common.scale = FALSE) ## Prior dev : 143 ## ## Generalized linear
mixed model fit by maximum likelihood (Laplace ## Approximation)
[bglmerMod] ## Family: binomial ( logit ) ## Formula: surviveR ~
maternalage.factor + paternalloss + maternalloss + ## center(nr.siblings) +
birth.cohort + male + paternalage.mean + ## paternalage.factor + (1 |
idParents) ## Data: swed.2 ## Control: control_defaults ## Subset:
survive1y == TRUE & byear < 2000 ## ## AIC BIC logLik deviance df.resid ##
938507 938795 -469231 938463 3691460 ## ## Scaled residuals: ## Min 1Q
Median 3Q Max ## -134.50 0.04 0.05 0.06 3.07 ## ## Random effects: ##
Groups Name Variance Std.Dev. ## idParents (Intercept) 0.000698 0.0264 ##
Number of obs: 3691482, groups: idParents, 1907489 ## ## Fixed effects: ##
Estimate Std. Error z value Pr(>|z|) ## (Intercept) 6.84279 0.03471 197.2 <
2e-16 *** ## maternalage.factor(14,20] 0.16356 0.01600 10.2 < 2e-16 *** ##
maternalage.factor(35,61] -0.18822 0.00871 -21.6 < 2e-16 *** ##
paternallossTRUE -0.41957 0.04694 -8.9 < 2e-16 *** ## paternallossNA
-0.30693 0.01819 -16.9 < 2e-16 *** ## maternallossTRUE -0.67635 0.08228
-8.2 < 2e-16 *** ## maternallossNA -0.11658 0.02607 -4.5 7.8e-06 *** ##
center(nr.siblings) 0.27749 0.00288 96.2 < 2e-16 *** ##
birth.cohort(1970,1977] 0.35761 0.02833 12.6 < 2e-16 *** ##
birth.cohort(1977,1984] 0.72394 0.03203 22.6 < 2e-16 *** ##
birth.cohort(1984,1991] 0.86295 0.03173 27.2 < 2e-16 *** ##
birth.cohort(1991,1999] -5.95342 0.01933 -308.0 < 2e-16 *** ## male
-0.01946 0.00512 -3.8 0.00015 *** ## paternalage.mean 0.88269 0.01168 75.5
< 2e-16 *** ## paternalage.factor(25,30] -0.53984 0.01068 -50.5 < 2e-16 ***
## paternalage.factor(30,35] -1.18842 0.01360 -87.4 < 2e-16 *** ##
paternalage.factor(35,40] -1.59243 0.01815 -87.7 < 2e-16 *** ##
paternalage.factor(40,45] -2.02418 0.02429 -83.3 < 2e-16 *** ##
paternalage.factor(45,50] -2.46269 0.03266 -75.4 < 2e-16 *** ##
paternalage.factor(50,55] -3.11201 0.04679 -66.5 < 2e-16 *** ##
paternalage.factor(55,90] -3.67437 0.06747 -54.5 < 2e-16 ***

## R version 3.1.0 (2014-04-10) ## Platform: x86_64-redhat-linux-gnu
(64-bit) ## ## other attached packages: ## [1] mgcv_1.8-4 nlme_3.1-119
stringr_0.6.2 pander_0.5.1 ## [5] blme_1.0-2 formr_0.1.11 lme4_1.1-7
Rcpp_0.11.4 ## [9] Matrix_1.1-5 ggplot2_1.0.0 data.table_1.9.5 knitr_1.9

	[[alternative HTML version deleted]]


From tim.cole at ucl.ac.uk  Mon Mar 23 14:56:24 2015
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Mon, 23 Mar 2015 13:56:24 +0000
Subject: [R-sig-ME] nlme prediction with predictor function
Message-ID: <D135B8E9.38F98%tim.cole@ucl.ac.uk>

My sitar library fits an nlme model with (for example) a 5 df regression spline as follows, where a, b and c are mixed effects:

.fitnlme <<- function(x, s1, s2, s3, s4, s5, a, b, c) {
splinecoefs <- as.matrix(cbind(s1, s2, s3, s4, s5))
as.vector( a +
(splinecoefs * as.matrix(ns((x - ( b )) * exp( c ),
knots=knots, Boundary.knots=bounds))) %*%
matrix(rep(1, df), ncol=1))
}
nlme(y ~ .fitnlme(x, s1, s2, s3, s4, s5, a, b, c),
fixed = s1 + s2 + s3 + s4 + s5 + a + b + c ~ 1,
random = a + b + c ~ 1 | id,
etc)

Note that the function .fitnlme is written to globalenv to make it available during the fitting - I've not found a more elegant way to do it. I could include the function code within nlme, but I need the named function to use with predict.

Using predict.nlme(object, newdata) also requires .fitnlme. Again I could write it to globalenv but I'd prefer to pass it in the predict.nlme call. I've tried various incantations to achieve this, but none of them work. Is it possible, and can anyone advise?

I recognise that this is only marginally a mixed-models query...

Thanks,
Tim
---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population, Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK


	[[alternative HTML version deleted]]


From shi_peijian at 163.com  Mon Mar 23 04:37:03 2015
From: shi_peijian at 163.com (shi_peijian)
Date: Mon, 23 Mar 2015 11:37:03 +0800 (CST)
Subject: [R-sig-ME] Peijian Shi
Message-ID: <7e19fbf1.63dc.14c44b484bd.Coremail.shi_peijian@163.com>

Dear Sir / Ms.,
 
I am using lme4 to analyze the effects of three treatment levels, three seed types, six sites on the removal percentage of seeds over 20 days. Each day, six sites were randomly chose, so the six sites' locations are different from another day's. There are total 10 seed for each combination (Treatment * Type) for oberving the removal number.
 
I think, Day should be a random effect and Site also a random effect. Then I use the following code:

    glmer(cbind(Removal, 10-Removal) ~ Type + Treatment + (1 | Day / Site),  family=binomial)

My quesiton is whether (1|Day/Site) correct for my experiment? Each day, there were six random sites, and we observed the removal number per 10 seeds for the combinations (Treatment * Type).
 
Thank you very much!
  
Best wishes,
 
Peijian Shi

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar 24 09:28:52 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 24 Mar 2015 09:28:52 +0100
Subject: [R-sig-ME] the equation of a mixed model fitted using nlme
In-Reply-To: <CAGL_Tscutg0ip8VwwieEB+iyDzX10U4sdnV3HiCbPTsABW8GxQ@mail.gmail.com>
References: <CAGL_TsdiJL7hspJ19617FL7km2NqV6pXSCX4DiqBW+rPNiJjLQ@mail.gmail.com>
	<CAJuCY5zyoWMv+8ZgaF+yQFQXzWeH0R_q-3GgUH=YoAxZkq6S5w@mail.gmail.com>
	<CAGL_Tscutg0ip8VwwieEB+iyDzX10U4sdnV3HiCbPTsABW8GxQ@mail.gmail.com>
Message-ID: <CAJuCY5yrWcBOjMo_64phz7EOUT8w3MPGr58JaJFEO=T028BoaA@mail.gmail.com>

Dear Jos,

Please keep the mailing list in cc.

The markup for the equations can be used in LaTeX and Markdown. Here is a
Markdown tutorial: http://rmarkdown.rstudio.com/

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-23 17:27 GMT+01:00 jos matejus <matejus106 at googlemail.com>:

> Thanks you very much for your help Thierry.
>
> Just out of interest, what markup language are you using in your reply? Is
> there a software package to view this in?
>
> Cheers
> Jos
>
> On 19 March 2015 at 13:10, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Jos,
>>
>> Here is an attempt. Have a look at Pinheiro & Bates (2000) for examples.
>>
>> $c$ days - 7
>> $p1$ first order polynomial of days - 7
>> $p2$ second order polynomial of days - 7
>> $i$ family index
>> $j$ habitat index
>> $k$ treatment index
>> $l$ observation index
>>
>> $length_{ijkl} = \beta_0 + \beta_1 p1_{ijkl} + \beta_2 p2_{ijkl} +
>> \beta_j + \beta_k + \beta_{1j} p1_{ijkl}  + \beta_{2j} p2_{ijkl} +
>> \beta_{1k} p1_{ijkl}  + \beta_{2k} p2_{ijkl} + \beta_{1jk} p1_{ijkl}  +
>> \beta_{2jk} p2_{ijkl} + b_{0i} + b_{1i} p1_{ijkl} + b_{2i} p2_{ijkl} +
>> \epsilon_{ijkl}$
>>
>> $b_i = \left[{\\begin{array}{c}
>>   b_{0i} \\\\
>>   b_{1i} \\\\
>>   b_{1i}
>> \\end{array}
>> }\right]
>> \sim N(0, \Psi)$
>>
>> $E[\epsilon_{ijkl}] = 0$
>> $Var(\epsilon_{ijkl}) = \sigma ^ 2 exp(2 \delta_{jk} c_{ijkl})$
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-03-18 10:50 GMT+01:00 jos matejus <matejus106 at googlemail.com>:
>>
>>> Dear R mixed modellers
>>>
>>> I am writing to the R mixed modelling community to request some help and
>>> advice regarding reporting a mixed model in a publication. I have
>>> recently
>>> received referees comments regarding a paper I submitted some time ago.
>>> The
>>> referee has requested that I write one of the models used to analyse my
>>> data 'statistically'. I think they mean that I should write out the
>>> equation, and while I don?t think this is unreasonable I am having
>>> trouble
>>> doing so. I know many of you have heard the excuse ?I am not a
>>> statistician? but I?m afraid that this applies in my case, but I have
>>> tried
>>> for a couple of days to figure this one out and harassed many colleagues
>>> but without success. Therefore I am hoping I can prevail on the kindness
>>> of
>>> the R mixed modelling community to help me with this problem.
>>>
>>> The code used for the model was
>>>
>>> vf1Exp<-  varExp(form=~I(days-7)|habitat*treat)
>>>
>>> final.model <- lme(length.sq~ poly(I(days-7),2)*treat*habitat,
>>> data=mydata,
>>> method="REML",random=~poly(I(days-7),2)|family, weights=vf1Exp)
>>>
>>> length.sq = square root transformed length of fish
>>>
>>> days = day following exposure (10, one day intervals starting from day 7
>>> after exposure)
>>>
>>> treat = two level treatment factor
>>>
>>> habitat = two level habitat factor
>>>
>>> family = 19 level factor
>>>
>>>
>>>
>>> I have 10 fish per treatment combination (treat*habitat) at each time
>>> point
>>> for each family.
>>>
>>>
>>>
>>> The second order polynomial term for day was included to account for non
>>> linear growth and the variance structure to account for an increase in
>>> variance over time that was different depending on the treatment
>>> combination. The 3-way interaction was significant.
>>>
>>> How should I represent this model as an equation?
>>>
>>> Thanks a million for your help.
>>>
>>> Jos
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From samantha.franks at bto.org  Tue Mar 24 13:10:10 2015
From: samantha.franks at bto.org (Samantha Franks)
Date: Tue, 24 Mar 2015 12:10:10 +0000
Subject: [R-sig-ME] predictions and standard errors on model-averaged mixed
	effects models
Message-ID: <CADYD3BNRNc3VyXCXUQKgeMpphpxJKre-8J8t3X53RUZ4VZGvvw@mail.gmail.com>

I'm using the MuMIn package to run model selection and model averaging on a
candidate set of 10 lme models. The structure of my global model is as
follows:

Response ~ lme(x1 + x2*x3, random = ~1|species, dat, method="ML")

After using model.sel() on my candidate set of models, it appears that I
have quite a lot of model uncertainty:

   df    logLik     AICc      delta       weight
10  9 -131.0876 280.5062  0.0000000 3.551586e-01
9   7 -133.3542 280.9136  0.4074347 2.897003e-01
8   8 -132.9586 282.1814  1.6751970 1.536943e-01
7   6 -135.1632 282.4800  1.9738133 1.323775e-01
6   5 -137.2159 284.5413  4.0350878 4.722958e-02
4   4 -139.0313 286.1354  5.6292648 2.128350e-02
2   4 -143.6987 295.4704 14.9641822 1.999822e-04
5   6 -141.7289 295.6114 15.1052171 1.863657e-04
1   3 -145.5371 297.1178 16.6115902 8.775287e-05
3   5 -143.5712 297.2518 16.7456510 8.206357e-05

Hence, I would like to use the full model-averaged model-averaged
coefficients produced by model.avg for predictions and plotting the
population-level response of the main effects. So, taking the
model-averaged object like so:

pred <- MuMIn:::predict.averaging(modavg.out, newdata=newdat, level=0) #
population level response

My question specifically pertains to obtaining standard errors on
predictions from model-averaged mixed effects models. On a single model,
this has been addressed nicely on the GLMM Wiki FAQ:
http://glmm.wikidot.com/faq, where the standard errors are calculated on
the covariance matrix.

Setting se.fit=TRUE in predict.averaging:

pred <- MuMIn:::predict.averaging(modavg.out, newdata=newdat, level=0,
se.fit=TRUE)

gives a list of two component objects, the fits and the SEs.

But I wonder how the SEs in this case are calculated by predict.averaging,
and whether in fact they give a valid estimation for the SEs on
model-averaged predictions from mixed effects models? Is there such a thing
as a model-averaged variance-covariance matrix??

Many thanks for any help.
Sam

-- 
Dr Samantha Franks
Research Ecologist
British Trust for Ornithology
The Nunnery, Thetford
IP24 2PU  01842 750050
samantha.franks at bto.org <sam.franks at bto.org>
Twitter <https://twitter.com/_SamanthaFranks>  ReseachGate
<http://www.researchgate.net/profile/Samantha_Franks>

	[[alternative HTML version deleted]]


From David.Duffy at qimr.edu.au  Wed Mar 25 00:01:56 2015
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 25 Mar 2015 09:01:56 +1000
Subject: [R-sig-ME] Little variability in outcome;
 "pwrssUpdate did not converge"
In-Reply-To: <CALv3xzukLbtnxVvT_N+ZRM=BOrUp01zVzXJXOuVfaEpos0LZGQ@mail.gmail.com>
References: <CALv3xzukLbtnxVvT_N+ZRM=BOrUp01zVzXJXOuVfaEpos0LZGQ@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1503250854140.26026@orpheus.qimr.edu.au>

On Mon, 23 Mar 2015, Ruben Arslan wrote:

> I have a dichotomous outcome (child mortality) with a very high mean
> (0.9946) in a large dataset (3.5m).
>
> I thought maybe the problem still is complete separation and I'm just being
> too timid with the blme prior.
>
> Oddly (maybe not), the only model where I do get convergence is one where I
> accidentally mis-specified my sample, so my outcome was censored (hence the
> mean but not the intercept was lower). I'm attaching the model.

The misspecified model? Maybe you should be doing something else, such as 
bivariate logistic (dropping extra offspring) or marginal models? If you 
are interested just in familial aggregation, you can do the conditional 
analysis using just the ~18000 odd families with one or more events, 
using the other families just to estimate offsets.

A few random thoughts ;)

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From rubenarslan at gmail.com  Wed Mar 25 01:06:41 2015
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Wed, 25 Mar 2015 01:06:41 +0100
Subject: [R-sig-ME] Little variability in outcome;
	"pwrssUpdate did not converge"
In-Reply-To: <alpine.LMD.2.00.1503250854140.26026@orpheus.qimr.edu.au>
References: <CALv3xzukLbtnxVvT_N+ZRM=BOrUp01zVzXJXOuVfaEpos0LZGQ@mail.gmail.com>
	<alpine.LMD.2.00.1503250854140.26026@orpheus.qimr.edu.au>
Message-ID: <2B26E481-723B-4F95-8BBB-299EC1ED1EC2@gmail.com>

Thanks for your response! I'd prefer to model this the same way I did in three other populations (with lower means and sample sizes) for the sake of presentation and comparability. The basic idea (sorry that wasn't clear) is a sibling control design, examining the effect of paternal age within families (i.e. no marginal models for me).

I'm not sure I understand how I could estimate offsets separately from the conditional analysis. I've tried including only families with at least two sibs (nope), but wouldn't selecting based on the outcome introduce bias? How would I remedy that?

My previous mail contained a mis-specified model, since that happened to give any output and I thought it might be informative. 
It also had a odd prior specification. The default specification is c(10,2.5). Unthinkingly, I set a very high SD on the slopes i.e. c(9,9). That's not a good idea since these high SDs on the normal put a lot of weight on 0 and 1 on the logit (there's a section on this in 2.6. of the MCMCglmm course notes).
Unfortunately, even though I do get improved results with small subsamples (30k) using the default prior spec (as opposed to vanilla glmer), the models still do not converge with the 3.5m dataset. 

I was thinking that I might get closer by simply splitting my sample? I'm of course still hoping there's some control I've missed.


> On 25 Mar 2015, at 00:01, David Duffy <David.Duffy at qimr.edu.au> wrote:
> 
> On Mon, 23 Mar 2015, Ruben Arslan wrote:
> 
>> I have a dichotomous outcome (child mortality) with a very high mean
>> (0.9946) in a large dataset (3.5m).
>> 
>> I thought maybe the problem still is complete separation and I'm just being
>> too timid with the blme prior.
>> 
>> Oddly (maybe not), the only model where I do get convergence is one where I
>> accidentally mis-specified my sample, so my outcome was censored (hence the
>> mean but not the intercept was lower). I'm attaching the model.
> 
> The misspecified model? Maybe you should be doing something else, such as bivariate logistic (dropping extra offspring) or marginal models? If you are interested just in familial aggregation, you can do the conditional analysis using just the ~18000 odd families with one or more events, using the other families just to estimate offsets.
> 
> A few random thoughts ;)
> 
> | David Duffy (MBBS PhD)
> | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
> | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
> | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From bbolker at gmail.com  Wed Mar 25 14:31:11 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Mar 2015 13:31:11 +0000 (UTC)
Subject: [R-sig-ME] Peijian Shi
References: <7e19fbf1.63dc.14c44b484bd.Coremail.shi_peijian@163.com>
Message-ID: <loom.20150325T142120-721@post.gmane.org>

shi_peijian <shi_peijian at ...> writes:

> 
> Dear Sir / Ms.,
 
> I am using lme4 to analyze the effects of three treatment levels,
> three seed types, six sites on the removal percentage of seeds over
> 20 days. Each day, six sites were randomly chose, so the six sites'
> locations are different from another day's. There are total 10 seed
> for each combination (Treatment * Type) for oberving the removal
> number.
 
> I think, Day should be a random effect and Site also a random effect. Then
I use the following code:
 
>     glmer(cbind(Removal, 10-Removal) ~ Type + Treatment + (1 | Day / Site),  
  family=binomial)
 
> My quesiton is whether (1|Day/Site) correct for my experiment? Each
> day, there were six random sites, and we observed the removal number
> per 10 seeds for the combinations (Treatment * Type).
 

  This looks about right, if you have unique sites.  If you wanted,
you could look for time trends by adding Day as continuous fixed
covariate; it's probably not going to make a very big difference,
but might improve model fit (normality of conditional modes) slightly.


From asafw.at.wharton at gmail.com  Wed Mar 25 14:40:11 2015
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Wed, 25 Mar 2015 09:40:11 -0400
Subject: [R-sig-ME] lmer estimates for highly unbalanced anova
Message-ID: <CAGG0PdD0mpN7rOj7o3h9fv_0qBxKu3Qob8aU3FpTCvorYfF=Tw@mail.gmail.com>

Dear lme4 community,

I am doing some theoretical research on a problem involving a two-way
random effects model with an unbalanced design.
I am wondering if the behavior of the ML estimates for the variance
components (theta, in the notation of lme4 documentation) was studied under
highly unbalanced design, e.g., the ratio lambda := max(K_ij)/min(K_ij) is
very large, where K_ij = number of observations in the ij cell (i=1,..,R,
j=1,...,C).
More specifically, I am wondering if anybody has studied the asymptotic
behavior of the MLE when R,C-->\infty and also lambda -->\infty at some
rate, say o([RC]^{\alpha}).
I am suspecting that the performance of the ML estimator may deteriorate
when the design matrix (=matrix with element (i,j) equal to K_ij) is
ill-conditioned, i.e., lambda is very large; but I am curious whether this
can be confirmed.
I would appreciate very much any comment or reference that might be
relevant.

Thank you very much,
Asaf

	[[alternative HTML version deleted]]


From robgriffin247 at hotmail.com  Fri Mar 27 15:33:15 2015
From: robgriffin247 at hotmail.com (Robert Griffin)
Date: Fri, 27 Mar 2015 15:33:15 +0100
Subject: [R-sig-ME] priors for univariate model with very low expected
 variance contributions (mcmcglmm)
Message-ID: <CAMm5Hax6EJ3wn7kpjjjk9_ZfAojm6R91hos-oKUxLZtbF8N6cA@mail.gmail.com>

Dear list,

I have sampled ~35 copies of a chromosome from a population because I want
to estimate how much contribution that part of the genome makes to the
variance in the traits. Therefore I want to estimate the additive genetic
variance. I will do this by using making a univariate response model in
MCMCglmm. The data for the trait was collected from 300-500 offspring per
sampled chromosome, and measured in males. This was done across 4
experimental *blocks *and within each *line *and *block *there were 4 *vials
*of many individuals, each sourced from one of two *sets *of parents.

Within the model there are *block*, parental set (*set*), *vial*, and *line
*effects to model. I have done this in the following way:

chain1 = MCMCglmm(trait ~1 + block,
random = ~line + set + vial,
rcov = ~units,
nitt = nitt,
thin = thin,
burnin = burnin,
prior = prior,
family = "gaussian",
start = list(QUASI = FALSE),
data = df1)


However, the phenotypic variance in this trait is large [var(trait) =
~150], and I am expecting an extremely large part of the variance to be
environmental & measurement error (residual), and the variables of line,
set, block, and vial to contribute very little (probably <5% of total
variation each) - visual examination of the data suggests that there is
almost no variance among lines, blocks, vials, or parental sets. Which
leads me to my call for help.

I am mainly concerned about how to choose priors for variances which are
expected to be near zero (when the aim is to test if line variance is not
0) - can this affect the outcome of the model? How should I define my
priors in such a case? Currently my best estimate from reading the
literature is to use the following:

prior = list(G = list( G1 = list(V = var(trait)/4, nu=0.002),
G2 = list(V = var(trait)/4, nu=0.002),
G3 = list(V = var(trait)/4, nu=0.002)),
R  = list(V = var(trait)/4, nu=0.002))


Advice about the priors (and the model in general if you happen spot
anything- e.g. should the family be Gaussian?) would be greatly appreciated,

Rob


-----------------------------
Robert Griffin
PhD candidate, Uppsala University
griffinevo.wordpress.com

	[[alternative HTML version deleted]]


From tim.cole at ucl.ac.uk  Fri Mar 27 18:30:16 2015
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Fri, 27 Mar 2015 17:30:16 +0000
Subject: [R-sig-ME] nlme prediction with predictor function
Message-ID: <D13B2FDB.391E8%tim.cole@ucl.ac.uk>

Dear Mario,

You'll remember I was struggling to find a way of passing a function to nlme within a package. After about 5 years I have finally cracked it!

This is the structure I want, but unless both instructions are in globalenv nlme does not see fitnlme.
fitnlme <- function(...) {...}
nlme(y ~ fitnlme(...), fixed = ..., random = ..., ...)

The solution is as follows: create a new environment, write fitnlme to it and then attach it:
fitenv <- new.env()
fitenv$fitnlme <- function(...) {...}
attach(fitenv)
on.exit(detach(fitenv))
nlmecode <- "text containing nlme command code"
nlme.out <- eval(parse(text=nlmecode))

It works!

Best wishes,
Tim
---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population, Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK


	[[alternative HTML version deleted]]


From zsa11 at mail.aub.edu  Fri Mar 27 00:03:49 2015
From: zsa11 at mail.aub.edu (Zahwa Al Ayyash (Student))
Date: Thu, 26 Mar 2015 23:03:49 +0000
Subject: [R-sig-ME] Standard errors in glmmADMB
Message-ID: <1427411029128.7631@mail.aub.edu>

Dear list,


I am modeling the number of weekly trips (using public transport models) using Hurdle Poisson Model in glmmADMB.


I have longitudinal data as every respondent was given a set of 8 question (an SP kind of survey). So, I am including a random intercept to account for correlation among the choices of the respondents.


glmmADMB outputs the variance of the random effect, but not its standard error. How can I test for its significance?


I read online that maybe it is not necessary to test it if the random effect is part of the experimental design, which is the case, but still for the sake of completeness, any suggestions are welcome. Also, a suggested solution was to do anova test for comparing the model with and without the random intercept.


Is there an easy way to get the standard error? or to do a t-test (for example) and get the significance of the random effect?


Thank you so much in advance,

Zahwa AlAyyash

Graduate Student in Civil and Environmental Engineering


	[[alternative HTML version deleted]]


From alexandre.m.martin at gmail.com  Fri Mar 27 21:39:40 2015
From: alexandre.m.martin at gmail.com (Alexandre Martin)
Date: Fri, 27 Mar 2015 16:39:40 -0400
Subject: [R-sig-ME] design matrices in MCMCglmm
Message-ID: <5515C00C.8000904@gmail.com>

Dear all,

I am working on estimating maternal effects (genetic and environmental) 
with MCMCglmm that is new for me.

I am trying to apply to MCMCglmm what is shown in online Muir's course 
notes made for SAS. Leanning on Henderson?s Mixed Model Equation, these 
notes explain how to solve MME to predict random effects ?by hand?.

Here is my concern:

I do not know how to extract the design matrices for a MCMCglmm model, 
e.g. the relatedness matrix or the one for maternal genetic effects. I 
want that to understand how the design matrices are constructed by 
comparing them to what they are supposed to look like.  For instance, 
the design matrix for maternal genetic effects should relate offspring 
to all the individuals that are in the pedigree, whereas the design 
matrix for maternal environmental effects should just relate offspring 
to their mothers. Does such a difference exist when MCMCglmm constructs 
its design matrices? If not, how to include such different matrices in 
models?


Any help will be greatly appreciated. Thank you!


Alexandre

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sat Mar 28 08:35:56 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 28 Mar 2015 07:35:56 +0000
Subject: [R-sig-ME] Predictions from zero-inflated or hurdle models
In-Reply-To: <CALv3xzuiM2mwLb-AC8-wgoJtSFq9_MU_4_a5BCbXb1bXdo7G6w@mail.gmail.com>
References: <loom.20150309T220710-595@post.gmane.org>
	<CALv3xzubKUPsatUpZoXOCUZiT1TrDkMmbt4c-_W6SW0shhE+1w@mail.gmail.com>
	<CALv3xzuSbdODmYrQ1uz0nx-TL4T02Mo=1aJwH-gJnBhD87TfrA@mail.gmail.com>
	<20150317163112.14195p92nh01nwso@www.staffmail.ed.ac.uk>
	<CALv3xzuKdax26=sdMRTj16we9-UsWbF4y7bo_5rkwXcky1WR6Q@mail.gmail.com>
	<CALv3xzu4UDx=NaotMmp_UZwQiX-3Bgmcbo=57auyRO+hQuQX_w@mail.gmail.com>
	<20150318060643.13225lb85fypl9ss@www.staffmail.ed.ac.uk>
	<CALv3xzuiM2mwLb-AC8-wgoJtSFq9_MU_4_a5BCbXb1bXdo7G6w@mail.gmail.com>
Message-ID: <20150328073556.598931h28p2u21gc@www.staffmail.ed.ac.uk>

Hi Ruben,

Regarding 2/ you want to add the family variance if you want to  
predict what the average response will be across families. If you want  
to predict for a specific family (for example one where the random  
effect = 0) then you should not include the variance.

Cheers,

Jarrod



Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 18 Mar 2015  
13:51:50 +0000:

> Hi,
>
> thanks for your reply. This clears some things up.
>
> 1. Colour me interested then, if you ever find the time to put it on
> Github. Maybe after seeing the nonsense I've wrought in the following
> points you might find sending me a zip of the pre-release might save you
> some time as opposed to guessing where I went wrong?
>
> 2. I'm not sure I understand.
> You're saying I can add the VCV components for the family random effect to
> the respective unit components.
> But I would only want that if I was interested in predicting the effect for
> any family, which in my case is not the goal, since my population data
> includes all families and I want to know the effect for the average family
> in that population (to compare it to other populations).
>
> 3. Oh right, I'm sorry I think I got a little confused/sidetracked, these
> models have been with me for a while now and I learned about us()/idh()
> back then.
>
> 4. Okay, I will keep this in mind, but am for now focusing on getting the
> prediction for this simpler case right.
>
> 5. I made a reproducible report
> <http://rpubs.com/rubenarslan/repro_variab_mcmcglmm> to show the problem. I
> think the problem is not due to the changes I made in my prediction helper
> function but to some fundamental.
> It shows that for some toy data, the credibility intervals for predictions
> depend on the reference I choose for a factor predictor.
> This is less bad with the method I used initially simply using the inverse
> link.
> However, both methods _underpredict_ as far as I can tell.
>
> Surely I'm missing an important step, but I hope this illustrates what
> confuses me. Of course the reasons you map out for the discrepancy
> (variable confounding etc) are sound in theory, but I don't see these wide
> CIs using any other method (simple descriptives, lme4).
> Oh and I used a different data simulation, because the one you used
> actually induces zero-deflation as far as I can tell (a lot of zeroes, but
> lambda is very low too).
>
> Best regards and again thanks so much for taking the time,
>
> Ruben
>
>
> On Wed, Mar 18, 2015 at 7:06 AM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi,
>>
>> 6/ you are correct - my mistake.
>>
>>
>> 5b/ I'm still not sure what you mean by the uncertainty, but ignoring
>> the random effects will result in under prediction. For a Poisson
>> log-normal the mean  is  exp(a_1+v_1/2)  rather than  exp(a_1) for the
>> standard Poisson.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015
>> 19:21:06 +0000:
>>
>> > Hi,
>> >
>> > two more questions, sorry.
>> >
>> > 6.
>> > could it be that where you wrote
>> > normal.evd<-function(x, mu, v){
>> > exp(-exp(x))*dnorm(x, mu, sqrt(v))
>> > }
>> >
>> > you're not actually passing the variance but the standard deviation? so
>> the
>> > functions should be
>> >
>> > normal.evd<-function(x, mu, sd){
>> > exp(-exp(x))*dnorm(x, mu, sd)
>> > }
>> > normal.zt<-function(x, mu, sd){
>> > exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sd)
>> > }
>> >
>> > Because at least in the example, you were taking the square root here
>> > already: sd_1<-mean(sqrt(m1$VCV[,1]))
>> > Maybe this was a copy-paste from the source where you do it differently?
>> Or
>> > I misunderstood...
>> >
>> > An addition to question 5:
>> > 5. When I use the correct inverse link function in my old code, but don't
>> > do double integration, I do get a "reasonable" amount of uncertainty
>> around
>> > the reference factor. The predicted means are too low, which I put down
>> to
>> > this approach ignoring the VCV. I was just wondering how this could
>> happen
>> > (actually seeing the "reasonable" amount of uncertainty was what made me
>> > hopeful that my approach might not be entirely wrong).
>> >
>> > Best,
>> >
>> > Ruben
>> >
>> >
>> > On Tue, Mar 17, 2015 at 7:53 PM Ruben Arslan <rubenarslan at gmail.com>
>> wrote:
>> >
>> >> Hi Jarrod,
>> >>
>> >> thanks for the extensive reply! This helps a lot, though it sounds like
>> I
>> >> was hubristic to attempt this myself.
>> >> I tried using the approach you mapped out in the function gist
>> >> <https://gist.github.com/rubenarslan/aeacdd306b3d061819a6> I posted. I
>> >> simply put the pred function in a loop, so that I wouldn't make any
>> >> mistakes while vectorising and since I don't care about performance at
>> this
>> >> point.
>> >>
>> >> Of course, I have some follow up questions though.. I'm sorry if I'm
>> being
>> >> a pain, I really appreciate the free advice, but understand of course if
>> >> other things take precedence.
>> >>
>> >> 1. You're not "down with" developing publicly are you? Because I sure
>> >> would like to test-drive the newdata prediction and simulation
>> functions..
>> >>
>> >> 2. Could you make sure that I got this right: "When predictions are to
>> be
>> >> taken after marginalising the random effects (including the `residual'
>> >> over-dispersion) it is not possible to obtain closed form expressions."
>> >> That is basically my scenario, right? In the example I included, I also
>> >> had a group-level random effect (family). Ore are you talking about the
>> >> "trait" as the random effect (as in your example) and my scenario is
>> >> different and I cannot apply the numerical double integration procedure
>> you
>> >> posted?
>> >> To be clear about my prediction goal without using language that I might
>> >> be using incorrectly: I want to show what the average effect in the
>> >> response unit, number of children, is in my population(s). I have data
>> on
>> >> whole populations and am using all of it (except individuals that don't
>> >> have completed fertility yet, because I have yet to find a way to model
>> >> both zero-inflation and right censoring).
>> >>
>> >> 3. "Numerical integration could be extended to double integration in
>> >> which case covariance between the Poisson part and the binary part could
>> >> be handled." That is what you posted an example of and it applies to my
>> >> scenario, because I specified a prior R=list(V=diag(2), nu=1.002, fix=2)
>> >> and rcov=~idh(trait):units, random=~idh(trait):idParents?
>> >> But this double integration approach is something you just wrote
>> >> off-the-cuff and I probably shouldn't use it in a publication? Or is
>> this
>> >> in the forthcoming MCMCglmm release and I might actually be able to
>> refer
>> >> to it once I get to submitting?
>> >>
>> >> 4. Could I change my model specification to forbid covariance between
>> the
>> >> two parts and not shoot myself in the foot? Would this allow for a more
>> >> valid/tested approach to prediction?
>> >>
>> >> 5. When I use your method on my real data, I get less variation around
>> the
>> >> prediction "for the reference level" than for all other factor levels.
>> >> My reference level actually has fewer cases than the others, so this
>> >> isn't "right" in a way.
>> >> Is this because I'm not doing newdata prediction? I get the "right"
>> >> looking uncertainty if I bootstrap newdata predictions in lme4,
>> >> Sorry if this is children's logic :-)
>> >> Here's an image of the prediction
>> >> <http://rpubs.com/rubenarslan/mcmcglmm_pred> and the raw data
>> >> <http://rpubs.com/rubenarslan/raw>.
>> >>
>> >> Many thanks for any answers that you feel inclined to give.
>> >>
>> >> Best wishes,
>> >>
>> >> Ruben
>> >>
>> >> On Tue, Mar 17, 2015 at 5:31 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> >> wrote:
>> >>
>> >>> Hi,
>> >>>
>> >>> Sorry - I should have replied to this post earlier. I've been working
>> >>> on predict/simulate methods for all MCMcglmm models (including
>> >>> zero-inflated/altered/hurdle/truncated models) and these are now
>> >>> largely complete (together with newdata options).
>> >>>
>> >>> When predictions are to be taken after marginalising the random
>> >>> effects (including the `residual' over-dispersion) it is not possible
>> >>> to obtain closed form expressions. The options that will be available
>> >>> in MCMCglmm are:
>> >>>
>> >>> 1) algebraic approximation
>> >>> 2) numerical integration
>> >>> 3) simulation
>> >>>
>> >>> 1) and 2) are currently only accurate when the random/residual effect
>> >>> structure implies no covariance between the Poisson part and the
>> >>> binary part.
>> >>>
>> >>> 1) is reasonably accurate for zero-inflated distributions, but can be
>> >>> pretty poor for the remainder because they all involve zero-truncated
>> >>> Poisson log-normal distributions and my taylor approximation for the
>> >>> mean is less than ideal (any suggestions would be helpful).
>> >>>
>> >>> 2) could be extended to double integration in which case covariance
>> >>> between the Poisson part and the binary part could be handled.
>> >>>
>> >>> In your code, part of the problem is that you have fitted a zapoisson,
>> >>> but the prediction is based on a zipoisson (with complementary log-log
>> >>> link rather than logt link).
>> >>>
>> >>> In all zero-inflated/altered/hurdle/truncated models
>> >>>
>> >>> E[y] = E[(1-prob)*meanc]
>> >>>
>> >>> where prob is the probabilty of a zero in the binary part and meanc is
>> >>> the mean of a Poisson distribution (zipoisson) or a zero-truncated
>> >>> poisson (zapoisson and hupoisson). If we have eta_1 as the linear
>> >>> predictor for the poisson part and eta_2 as the linear predictor for
>> >>> the binary part:
>> >>>
>> >>> In zipoisson: prob = plogis(eta_2)     and meanc = exp(eta_1)
>> >>> In zapoisson: prob = exp(-exp(eta_2))  and meanc =
>> >>> exp(eta_1)/(1-exp(-exp(eta_1)))
>> >>> In hupoisson: prob = plogis(eta_2)     and meanc =
>> >>> exp(eta_1)/(1-exp(-exp(eta_1)))
>> >>> In ztpoisson: prob = 0                 and meanc =
>> >>> exp(eta_1)/(1-exp(-exp(eta_1)))
>> >>>
>> >>> In each case the linear predictor has a `fixed' part and a `random'
>> >>> part which I'll denote as `a' and `u' respectively. Ideally we would
>> >>> want
>> >>>
>> >>> E[(1-prob)*meanc] taken over u_1 & u_2
>> >>>
>> >>> if prob and meanc are independent this is a bit easier as
>> >>>
>> >>> E[y] = E[1-prob]E[meanc]
>> >>>
>> >>> and the two expectations ony need to taken with repsect to their
>> >>> respective random effects. If we have sd_1 and sd_2 as the standard
>> >>> deviations of the two sets of random effects then for the zapoisson:
>> >>>
>> >>>    normal.evd<-function(x, mu, v){
>> >>>       exp(-exp(x))*dnorm(x, mu, sqrt(v))
>> >>>    }
>> >>>    normal.zt<-function(x, mu, v){
>> >>>      exp(x)/(1-exp(-exp(x)))*dnorm(x, mu, sqrt(v))
>> >>>    }
>> >>>
>> >>>    pred<-function(a_1, a_2, sd_1, sd_2){
>> >>>      prob<-1-integrate(normal.evd, qnorm(0.0001, a_2,sd_2),
>> >>> qnorm(0.9999, a_2,sd_2), a_2,sd_2)[[1]]
>> >>>      meanc<-integrate(normal.zt, qnorm(0.0001, a_1,sd_1),
>> >>> qnorm(0.9999, a_1,sd_1), a_1,sd_1)[[1]]
>> >>>      prob*meanc
>> >>>    }
>> >>>
>> >>> #  gives the expected value with reasonable accuracy.  As an example:
>> >>>
>> >>>    x<-rnorm(300)
>> >>>    l1<-rnorm(300, 1/2+x, sqrt(1))
>> >>>    l2<-rnorm(300, 1-x, sqrt(1))
>> >>>
>> >>>    y<-rbinom(300, 1, 1-exp(-exp(l2)))
>> >>>    y[which(y==1)]<-qpois(runif(sum(y==1), dpois(0,
>> >>> exp(l1[which(y==1)])), 1), exp(l1[which(y==1)]))
>> >>>    # cunning sampler from Peter Dalgaard (R-sig-mixed)
>> >>>
>> >>>    data=data.frame(y=y, x=x)
>> >>>    prior=list(R=list(V=diag(2), nu=0.002, fix=2))
>> >>>
>> >>>    m1<-MCMCglmm(y~trait+trait:x-1, rcov=~idh(trait):units, data=data,
>> >>> family="zapoisson", prior=prior)
>> >>>
>> >>>    b_1<-colMeans(m1$Sol)[c(1,3)]
>> >>>    b_2<-colMeans(m1$Sol)[c(2,4)]
>> >>>    sd_1<-mean(sqrt(m1$VCV[,1]))
>> >>>    sd_2<-mean(sqrt(m1$VCV[,2]))
>> >>>
>> >>>    # note it is more accurate to take the posterior mean prediction
>> >>> rather than the prediction from the posterior means as I've done here,
>> >>> but for illustration:
>> >>>
>> >>>    x.pred<-seq(-3,3,length=100)
>> >>>    p<-1:100
>> >>>    for(i in 1:100){
>> >>>      p[i]<-pred(a_1 = b_1[1]+x.pred[i]*b_1[2], a_2 =
>> >>> b_2[1]+x.pred[i]*b_2[2], sd_1=sd_1, sd_2=sd_2)
>> >>>    }
>> >>>
>> >>>    plot(y~x)
>> >>>    lines(p~x.pred)
>> >>>
>> >>> Cheers,
>> >>>
>> >>> Jarrod
>> >>>
>> >>>
>> >>>
>> >>>
>> >>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Tue, 17 Mar 2015
>> >>> 13:33:25 +0000:
>> >>>
>> >>> > Dear list,
>> >>> >
>> >>> > I've made a reproducible example of the zero-altered prediction,
>> >>> > in the hope that someone will have a look and reassure me that I'm
>> going
>> >>> > about this the right way.
>> >>> > I was a bit confused by the point about p_i and n_i being correlated
>> >>> (they
>> >>> > are in my case), but I think this was a red herring for me
>> >>> > since I'm not deriving the variance analytically.
>> >>> > The script is here: https://gist.github.com/rubenarslan/
>> >>> aeacdd306b3d061819a6
>> >>> > and if you don't want to run the simulation fit yourself, I've put an
>> >>> RDS
>> >>> > file of the fit here:
>> >>> > https://dl.dropboxusercontent.com/u/1078620/m1.rds
>> >>> >
>> >>> > Best regards,
>> >>> >
>> >>> > Ruben Arslan
>> >>> >
>> >>> > On Tue, Mar 10, 2015 at 1:22 PM Ruben Arslan <rubenarslan at gmail.com>
>> >>> wrote:
>> >>> >
>> >>> >> Dear Dr Bolker,
>> >>> >>
>> >>> >> I'd thought about something like this, one point of asking was to
>> >>> >> see whether
>> >>> >> a) it's implemented already, because I'll probably make dumb
>> mistakes
>> >>> while
>> >>> >> trying b) it's not implemented because it's a bad idea.
>> >>> >> Your response and the MCMCglmm course notes make me hope that it's
>> c)
>> >>> not
>> >>> >> implemented because nobody did yet or d) it's so simple that
>> everybody
>> >>> does
>> >>> >> it on-the-fly.
>> >>> >>
>> >>> >> So I tried my hand and would appreciate corrections. I am sure
>> there is
>> >>> >> some screw-up or an inelegant approach in there.
>> >>> >> I included code for dealing with mcmc.lists because that's what I
>> have
>> >>> and
>> >>> >> I'm not entirely sure how I deal with them is correct either.
>> >>> >>
>> >>> >> I started with a zero-altered model, because those fit fastest and
>> >>> >> according to the course notes have the least complex likelihood.
>> >>> >> Because I know not what I do, I'm not dealing with my random
>> effects at
>> >>> >> all.
>> >>> >>
>> >>> >> I pasted a model summary below to show what I've applied the below
>> >>> >> function to. The function gives the following quantiles when applied
>> >>> to 19
>> >>> >> chains of that model.
>> >>> >>          5%         50%         95%
>> >>> >> 5.431684178 5.561211207 5.690655200
>> >>> >>          5%         50%         95%
>> >>> >> 5.003974382 5.178192327 5.348246558
>> >>> >>
>> >>> >> Warm regards,
>> >>> >>
>> >>> >> Ruben Arslan
>> >>> >>
>> >>> >> HPDpredict_za = function(object, predictor) {
>> >>> >>
>> >>> >> if(class(object) != "MCMCglmm") {
>> >>> >> if(length( object[[1]]$Residual$nrt )>1) {
>> >>> >> object = lapply(object,FUN=function(x) { x$Residual$nrt<-2;x })
>> >>> >> }
>> >>> >> Sol = mcmc.list(lapply(object,FUN=function(x) { x$Sol}))
>> >>> >> vars = colnames(Sol[[1]])
>> >>> >> } else {
>> >>> >> Sol = as.data.frame(object$Sol)
>> >>> >> vars = names(Sol)
>> >>> >> }
>> >>> >> za_predictor = vars[ vars %ends_with% predictor & vars %begins_with%
>> >>> >> "traitza_"]
>> >>> >> za_intercept_name = vars[ ! vars %contains% ":" & vars %begins_with%
>> >>> >> "traitza_"]
>> >>> >>  intercept = Sol[,"(Intercept)"]
>> >>> >> za_intercept = Sol[, za_intercept_name]
>> >>> >> l1 = Sol[, predictor ]
>> >>> >> l2 = Sol[, za_predictor ]
>> >>> >> if(is.list(object)) {
>> >>> >> intercept = unlist(intercept)
>> >>> >> za_intercept = unlist(za_intercept)
>> >>> >> l1 = unlist(l1)
>> >>> >> l2 = unlist(l2)
>> >>> >> }
>> >>> >>  py_0 = dpois(0, exp(intercept + za_intercept))
>> >>> >> y_ygt0 = exp(intercept)
>> >>> >> at_intercept = (1-py_0) * y_ygt0
>> >>> >>
>> >>> >> py_0 = dpois(0, exp(intercept + za_intercept + l2))
>> >>> >> y_ygt0 = exp(intercept +  l1)
>> >>> >> at_predictor_1 = (1-py_0) * y_ygt0
>> >>> >> print(qplot(at_intercept))
>> >>> >> print(qplot(at_predictor_1))
>> >>> >> df = data.frame("intercept" = at_intercept)
>> >>> >> df[, predictor] = at_predictor_1
>> >>> >> print(qplot(x=variable,
>> >>> >> y=value,data=suppressMessages(melt(df)),fill=variable,alpha=
>> I(0.40),
>> >>> geom =
>> >>> >> 'violin'))
>> >>> >> print(quantile(at_intercept, probs = c(0.05,0.5,0.95)))
>> >>> >> print(quantile(at_predictor_1, probs = c(0.05,0.5,0.95)))
>> >>> >> invisible(df)
>> >>> >> }
>> >>> >>
>> >>> >>
>> >>> >> > summary(object[[1]])
>> >>> >>
>> >>> >>  Iterations = 100001:299901
>> >>> >>  Thinning interval  = 100
>> >>> >>  Sample size  = 2000
>> >>> >>
>> >>> >>  DIC: 349094
>> >>> >>
>> >>> >>  G-structure:  ~idh(trait):idParents
>> >>> >>
>> >>> >>                       post.mean l-95% CI u-95% CI eff.samp
>> >>> >> children.idParents       0.0189   0.0164   0.0214     1729
>> >>> >> za_children.idParents    0.2392   0.2171   0.2622     1647
>> >>> >>
>> >>> >>  R-structure:  ~idh(trait):units
>> >>> >>
>> >>> >>                   post.mean l-95% CI u-95% CI eff.samp
>> >>> >> children.units        0.144    0.139    0.148     1715
>> >>> >> za_children.units     1.000    1.000    1.000        0
>> >>> >>
>> >>> >>  Location effects: children ~ trait * (maternalage.factor +
>> >>> paternalloss +
>> >>> >> maternalloss + center(nr.siblings) + birth.cohort + urban + male +
>> >>> >> paternalage.mean + paternalage.diff)
>> >>> >>
>> >>> >>                                            post.mean  l-95% CI
>> u-95%
>> >>> CI
>> >>> >> eff.samp   pMCMC
>> >>> >> (Intercept)                                 2.088717  2.073009
>> >>> 2.103357
>> >>> >>   2000 <0.0005 ***
>> >>> >> traitza_children                           -1.933491 -1.981945
>> >>> -1.887863
>> >>> >>   2000 <0.0005 ***
>> >>> >> maternalage.factor(14,20]                   0.007709 -0.014238
>> >>> 0.027883
>> >>> >>   1500   0.460
>> >>> >> maternalage.factor(35,50]                   0.006350 -0.009634
>> >>> 0.024107
>> >>> >>   2000   0.462
>> >>> >> paternallossTRUE                            0.000797 -0.022716
>> >>> 0.025015
>> >>> >>   2000   0.925
>> >>> >> maternallossTRUE                           -0.015542 -0.040240
>> >>> 0.009549
>> >>> >>   2000   0.226
>> >>> >> center(nr.siblings)                         0.005869  0.004302
>> >>> 0.007510
>> >>> >>   2000 <0.0005 ***
>> >>> >> birth.cohort(1703,1722]                    -0.045487 -0.062240
>> >>> -0.028965
>> >>> >>   2000 <0.0005 ***
>> >>> >> birth.cohort(1722,1734]                    -0.055872 -0.072856
>> >>> -0.036452
>> >>> >>   2000 <0.0005 ***
>> >>> >> birth.cohort(1734,1743]                    -0.039770 -0.056580
>> >>> -0.020907
>> >>> >>   2000 <0.0005 ***
>> >>> >> birth.cohort(1743,1750]                    -0.030713 -0.048301
>> >>> -0.012214
>> >>> >>   2000   0.002 **
>> >>> >> urban                                      -0.076748 -0.093240
>> >>> -0.063002
>> >>> >>   2567 <0.0005 ***
>> >>> >> male                                        0.106074  0.095705
>> >>> 0.115742
>> >>> >>   2000 <0.0005 ***
>> >>> >> paternalage.mean                           -0.024119 -0.033133
>> >>> -0.014444
>> >>> >>   2000 <0.0005 ***
>> >>> >> paternalage.diff                           -0.018367 -0.032083
>> >>> -0.005721
>> >>> >>   2000   0.007 **
>> >>> >> traitza_children:maternalage.factor(14,20] -0.116510 -0.182432
>> >>> -0.051978
>> >>> >>   1876   0.001 ***
>> >>> >> traitza_children:maternalage.factor(35,50] -0.045196 -0.094485
>> >>> 0.002640
>> >>> >>   2000   0.075 .
>> >>> >> traitza_children:paternallossTRUE          -0.171957 -0.238218
>> >>> -0.104820
>> >>> >>   2000 <0.0005 ***
>> >>> >> traitza_children:maternallossTRUE          -0.499539 -0.566825
>> >>> -0.430637
>> >>> >>   2000 <0.0005 ***
>> >>> >> traitza_children:center(nr.siblings)       -0.023723 -0.028676
>> >>> -0.018746
>> >>> >>   1848 <0.0005 ***
>> >>> >> traitza_children:birth.cohort(1703,1722]   -0.026012 -0.074250
>> >>> 0.026024
>> >>> >>   2000   0.319
>> >>> >> traitza_children:birth.cohort(1722,1734]   -0.279418 -0.329462
>> >>> -0.227187
>> >>> >>   2000 <0.0005 ***
>> >>> >> traitza_children:birth.cohort(1734,1743]   -0.260165 -0.312659
>> >>> -0.204462
>> >>> >>   2130 <0.0005 ***
>> >>> >> traitza_children:birth.cohort(1743,1750]   -0.481457 -0.534568
>> >>> -0.426648
>> >>> >>   2000 <0.0005 ***
>> >>> >> traitza_children:urban                     -0.604108 -0.645169
>> >>> -0.562554
>> >>> >>   1702 <0.0005 ***
>> >>> >> traitza_children:male                      -0.414988 -0.444589
>> >>> -0.387005
>> >>> >>   2000 <0.0005 ***
>> >>> >> traitza_children:paternalage.mean           0.006545 -0.018570
>> >>> 0.036227
>> >>> >>   2000   0.651
>> >>> >> traitza_children:paternalage.diff          -0.097982 -0.136302
>> >>> -0.060677
>> >>> >>   2000 <0.0005 ***
>> >>> >>
>> >>> >>
>> >>> >> On Mon, Mar 9, 2015 at 10:12 PM Ben Bolker <bbolker at gmail.com>
>> wrote:
>> >>> >>
>> >>> >>> Ruben Arslan <rubenarslan at ...> writes:
>> >>> >>>
>> >>> >>> >
>> >>> >>> > Dear list,
>> >>> >>> >
>> >>> >>> > I wanted to ask: Is there any (maybe just back of the envelope)
>> way
>> >>> to
>> >>> >>> > obtain a response prediction for zero-inflated or hurdle type
>> >>> models?
>> >>> >>> > I've fit such models in MCMCglmm, but I don't work in ecology
>> and my
>> >>> >>> > previous experience with explaining such models to "my audience"
>> >>> did not
>> >>> >>> > bode well. When it comes to humans, the researchers I presented
>> to
>> >>> are
>> >>> >>> not
>> >>> >>> > used to offspring count being zero-inflated (or acquainted with
>> that
>> >>> >>> > concept), but in my historical data with high infant mortality,
>> it
>> >>> is
>> >>> >>> (in
>> >>> >>> > modern data it's actually slightly underdispersed).
>> >>> >>> >
>> >>> >>> > Currently I'm using lme4 and simply splitting my models into two
>> >>> stages
>> >>> >>> > (finding a mate and having offspring).
>> >>> >>> > That's okay too, but in one population the effect of interest is
>> not
>> >>> >>> > clearly visible in either stage, only when both are taken
>> together
>> >>> (but
>> >>> >>> > then the outcome is zero-inflated).
>> >>> >>> > I expect to be given a hard time for this and hence thought I'd
>> use
>> >>> a
>> >>> >>> > binomial model with the outcome offspring>0 as my main model, but
>> >>> that
>> >>> >>> > turns out to be hard to explain too and doesn't
>> >>> >>> > really do the data justice.
>> >>> >>> >
>> >>> >>> > Basically I don't want to be forced to discuss my smallest
>> >>> population
>> >>> >>> as a
>> >>> >>> > non-replication of the effect because I was insufficiently able
>> to
>> >>> >>> explain
>> >>> >>> > the statistics behind my reasoning that the effect shows.
>> >>> >>>
>> >>> >>>   I think the back-of-the envelope answer would be that for a
>> >>> two-stage
>> >>> >>> model with a prediction of p_i for the probability of having a
>> >>> non-zero
>> >>> >>> response (or in the case of zero-inflated models, the probability
>> of
>> >>> >>> _not_ having a structural zero) and a prediction of n_i for the
>> >>> >>> conditional
>> >>> >>> part of the model, the mean predicted value is p_i*n_i and the
>> >>> >>> variance is _approximately_ (p_i*n_i)^2*(var(p_i)/p_i^2 +
>> >>> var(n_i)/n_i^2)
>> >>> >>> (this is assuming
>> >>> >>> that you haven't built in any correlation between p_i and n_i,
>> which
>> >>> >>> would be hard in lme4 but _might_ be possible under certain
>> >>> circumstances
>> >>> >>> via a multitype model in MCMCglmm).
>> >>> >>>
>> >>> >>>   Does that help?
>> >>> >>>
>> >>> >>> _______________________________________________
>> >>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>> >>>
>> >>> >>
>> >>> >
>> >>> >       [[alternative HTML version deleted]]
>> >>> >
>> >>> > _______________________________________________
>> >>> > R-sig-mixed-models at r-project.org mailing list
>> >>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>> >
>> >>> >
>> >>>
>> >>>
>> >>>
>> >>> --
>> >>> The University of Edinburgh is a charitable body, registered in
>> >>> Scotland, with registration number SC005336.
>> >>>
>> >>>
>> >>>
>> >
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Sat Mar 28 08:47:52 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 28 Mar 2015 07:47:52 +0000
Subject: [R-sig-ME] Bivariate random regression model in MCMCglmm to
 estimate selection on reaction norm slopes
In-Reply-To: <55095283.8000903@helsinki.fi>
References: <55095283.8000903@helsinki.fi>
Message-ID: <20150328074752.18461k6g820b2k00@www.staffmail.ed.ac.uk>

Hi Phillip,

The correct syntax (assuming fitness is an annual measure so you have  
repeat records?) is:


us(trait+at.level(trait,1):mt2):individual

Cheers,

Jarrod


Quoting Phillip Gienapp <phillip.gienapp at helsinki.fi> on Wed, 18 Mar  
2015 11:25:07 +0100:

> Dear all,
>
> First a bit of background: I currently work on an anlysis of  
> phenotypic plasticity of avian phenology in response to temperature.  
> Using a random regression model I found that individual reaction  
> norms (defined by slope and intercept) vary among individuals, i.e.  
> some individuals change their phenology more strongly in response to  
> temperatures than others and also that some individuals have a  
> consistently earlier phenology than others.
>
> I now want to test whether there is selection on reaction norm  
> slopes, i.e. whether individuals with steeper/shallower slope have a  
> higher/lower fitness. This means I have to fit a bivariate random  
> regression model but only one trait (phenology) should be regressed  
> against temperature. For the random effects part this should give me  
> a 3x3 covariance matrix with variation in slopes, intercepts,  
> fitness plus all the covariances and then the covariance between  
> slope and fitness indicates selection on reaction norm slopes.
>
> I figured how to regress only phenology and not fitness against  
> temperature for the fixed effects part but am still struggling with  
> the syntax for the random effects part.
>
>
> The univariate random regression model (omitting obvious syntax parts) is:
>
> phenology~age + temp, random=~us(1+temp):individual
>
>
> For the multivariate model I came up with:
>
> cbind(phenology,fitness)~trait:age + at.level(trait,1):temp,  
> random=~us(at.level(trait,1):(1+mt2):at.level(trait,2):1):individual,  
> rcov=~us(trait):units
>
> but curiously this fits only a single variance for individual and  
> not the desired 3x3 matrix...
>
> I hope I managed to explain my problem clearly enough (maybe there  
> was too much non-technical detail...). Any ideas to fit the desired  
> model are highly welcome!
>
>
> Best,
> Phillip
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Sat Mar 28 08:55:59 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 28 Mar 2015 07:55:59 +0000
Subject: [R-sig-ME] priors for univariate model with very low expected
 variance contributions (mcmcglmm)
In-Reply-To: <CAMm5Hax6EJ3wn7kpjjjk9_ZfAojm6R91hos-oKUxLZtbF8N6cA@mail.gmail.com>
References: <CAMm5Hax6EJ3wn7kpjjjk9_ZfAojm6R91hos-oKUxLZtbF8N6cA@mail.gmail.com>
Message-ID: <20150328075559.564378ihmkmqwgkc@www.staffmail.ed.ac.uk>

Hi Rob,

Parameter expanded priors are probably a better option:


prior = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G3 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
R  = list(V = 1, nu=0.002))

This prior is approximately flat for the standard deviation. Note that  
this does not imply it is flat for the variance; it still puts quite a  
bit of mass at zero, but less than the inverse-Wishart with low degree  
of belief. If you want something flat on the variance scale (e.g. a  
uniform distribution) you'll have to move to WinBugs or JAGS.

Parameter expansion is not implemented for the residuals so I've left  
the inverse-Wishart prior on the residual variance. Usually the data  
overwhelm the prior for the residual variance so you can probably be  
pretty relaxed about that.

Cheers,

Jarrod




Quoting Robert Griffin <robgriffin247 at hotmail.com> on Fri, 27 Mar 2015  
15:33:15 +0100:

> Dear list,
>
> I have sampled ~35 copies of a chromosome from a population because I want
> to estimate how much contribution that part of the genome makes to the
> variance in the traits. Therefore I want to estimate the additive genetic
> variance. I will do this by using making a univariate response model in
> MCMCglmm. The data for the trait was collected from 300-500 offspring per
> sampled chromosome, and measured in males. This was done across 4
> experimental *blocks *and within each *line *and *block *there were 4 *vials
> *of many individuals, each sourced from one of two *sets *of parents.
>
> Within the model there are *block*, parental set (*set*), *vial*, and *line
> *effects to model. I have done this in the following way:
>
> chain1 = MCMCglmm(trait ~1 + block,
> random = ~line + set + vial,
> rcov = ~units,
> nitt = nitt,
> thin = thin,
> burnin = burnin,
> prior = prior,
> family = "gaussian",
> start = list(QUASI = FALSE),
> data = df1)
>
>
> However, the phenotypic variance in this trait is large [var(trait) =
> ~150], and I am expecting an extremely large part of the variance to be
> environmental & measurement error (residual), and the variables of line,
> set, block, and vial to contribute very little (probably <5% of total
> variation each) - visual examination of the data suggests that there is
> almost no variance among lines, blocks, vials, or parental sets. Which
> leads me to my call for help.
>
> I am mainly concerned about how to choose priors for variances which are
> expected to be near zero (when the aim is to test if line variance is not
> 0) - can this affect the outcome of the model? How should I define my
> priors in such a case? Currently my best estimate from reading the
> literature is to use the following:
>
> prior = list(G = list( G1 = list(V = var(trait)/4, nu=0.002),
> G2 = list(V = var(trait)/4, nu=0.002),
> G3 = list(V = var(trait)/4, nu=0.002)),
> R  = list(V = var(trait)/4, nu=0.002))
>
>
> Advice about the priors (and the model in general if you happen spot
> anything- e.g. should the family be Gaussian?) would be greatly appreciated,
>
> Rob
>
>
> -----------------------------
> Robert Griffin
> PhD candidate, Uppsala University
> griffinevo.wordpress.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Sat Mar 28 09:01:33 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 28 Mar 2015 08:01:33 +0000
Subject: [R-sig-ME] design matrices in MCMCglmm
In-Reply-To: <5515C00C.8000904@gmail.com>
References: <5515C00C.8000904@gmail.com>
Message-ID: <20150328080133.381406iv6lkvpdjw@www.staffmail.ed.ac.uk>

Hi Alexandre,

The design matrices should be identical for both effects (z_{ij}=1 if  
the jth individual is the mother of individual i). The difference is  
in the correlation structure of the random effects. For environmental  
maternal effects they are assumed iid (i.e. an identity matrix) but  
for the maternal genetic effects they are assumed to be proportional  
to the A matrix. inverseA will return the inverse of A if you pass it  
the pedigree. It is this inverse that is required for forming the MME.

Cheers,

Jarrod






Quoting Alexandre Martin <alexandre.m.martin at gmail.com> on Fri, 27 Mar  
2015 16:39:40 -0400:

> Dear all,
>
> I am working on estimating maternal effects (genetic and environmental)
> with MCMCglmm that is new for me.
>
> I am trying to apply to MCMCglmm what is shown in online Muir's course
> notes made for SAS. Leanning on Henderson?s Mixed Model Equation, these
> notes explain how to solve MME to predict random effects ?by hand?.
>
> Here is my concern:
>
> I do not know how to extract the design matrices for a MCMCglmm model,
> e.g. the relatedness matrix or the one for maternal genetic effects. I
> want that to understand how the design matrices are constructed by
> comparing them to what they are supposed to look like.  For instance,
> the design matrix for maternal genetic effects should relate offspring
> to all the individuals that are in the pedigree, whereas the design
> matrix for maternal environmental effects should just relate offspring
> to their mothers. Does such a difference exist when MCMCglmm constructs
> its design matrices? If not, how to include such different matrices in
> models?
>
>
> Any help will be greatly appreciated. Thank you!
>
>
> Alexandre
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Sun Mar 29 01:58:20 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 29 Mar 2015 00:58:20 +0000 (UTC)
Subject: [R-sig-ME] Standard errors in glmmADMB
References: <1427411029128.7631@mail.aub.edu>
Message-ID: <loom.20150329T014850-920@post.gmane.org>

Zahwa Al Ayyash (Student <zsa11 at ...> writes:

> 
> Dear list,
 
> I am modeling the number of weekly trips (using public transport
  models) using Hurdle Poisson Model in glmmADMB.
 
> I have longitudinal data as every respondent was given a set of 8
> question (an SP kind of survey). So, I am including a random
> intercept to account for correlation among the choices of the
> respondents.
 
> glmmADMB outputs the variance of the random effect, but not its
  standard error. How can I test for its significance?
 
> I read online 

  Maybe at http://glmm.wikidot.com/faq ?

> that maybe it is not necessary to test it if the
> random effect is part of the experimental design, which is the case,
> but still for the sake of completeness, any suggestions are
> welcome. Also, a suggested solution was to do anova test for
> comparing the model with and without the random intercept.
 
> Is there an easy way to get the standard error? or to do a t-test
> (for example) and get the significance of the random effect?

    There are a bunch of issues here.

* As you already state, it's not necessarily a good idea to do
significance tests on variance components (one way of thinking of
significance tests is as a way to ask whether we can reliably estimate
the _sign_ of an estimated parameter, and we already know that
variance components are non-negative).

* However, putting that aside ("for the sake of completeness"):
http://glmm.wikidot.com/faq#random-sig suggests several difficulties
with hypothesis tests on variance components.

  * Parametric bootstrap could work and is more or
less the "gold standard", but will be slow.

  * Likelihood ratio tests may not be reliable because the
sampling distribution of variance components is not generally
chi-squared, but in the simplest case the estimated p-value is
twice its nominal value

  * glmmADMB objects *do* contain Wald standard errors for the
variance components (fit$sd_S), but they will be pretty much useless
for hypothesis testing; my guess that when the Wald CIS of the
variance overlap zero, that mostly just tells you that the estimates
are in the regime where Wald standard errors are unreliable


From ken.beath at mq.edu.au  Mon Mar 30 07:22:05 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Mon, 30 Mar 2015 16:22:05 +1100
Subject: [R-sig-ME] Problems with convergence
In-Reply-To: <loom.20150319T042938-705@post.gmane.org>
References: <CAF5_5cxHcAWSvgYL3876407aM5tM4pVBB+LTjr_gKPc7Bh8rbQ@mail.gmail.com>
	<loom.20150319T042938-705@post.gmane.org>
Message-ID: <CAF5_5cy0BE9Mi-_VROBQ+fUXYM+GX8=vbmga+KygRVWfZHsQ5w@mail.gmail.com>

Yes, I was demonstrating that it fails convergence and then as a
consequence fails to profile. I have my doubts about convergence for the bobyqa
algorithm, I have other applications where it doesn't converge properly.
For some of my own work I've used nlminb followed by Nelder-Mead if there
is a convergence failure. Not optimal but it seems to work.

While it is fairly heavily parameterised it is a real model,  a frequentist
implementation of Smith, T. C., Spiegelhalter, D. J., & Thomas, a. (1995).
Bayesian approaches to random-effects meta-analysis: a comparative study.
Statistics in Medicine, 14(24), 2685?99. The reason for having studies as
fixed effects is probably philosophical, the overall success rates are not
likely to be given by normally distributed random effects, and are in many
cases specifically chosen.

I did find that one of the data sets that I have also failed, but fitted
with a commercial program that is based on the EM algorithm. For this type
of problem it is actually faster, as any type of quasi-Newton needs to
calculate lots of derivatives.

Anyway, I'm going to keep looking at the methods, and eventually the code
for glmer and may eventually have some suggestions.

On 19 March 2015 at 14:45, Ben Bolker <bbolker at gmail.com> wrote:

> Ken Beath <ken.beath at ...> writes:
>
>
> > The following code shows that there are convergence problem messages
> > where there is a problem with convergence. The profiling shows that
> > the maximum found is not the correct one. This is simulated data for
> > a binary meta-analysis with fixed effect for study and random effect
> > for treatment.
>
>   I'm not 100% sure what the point is here (that's a real question,
> not a criticism).  I *think* it's that we can get a convergence
> failure with a computed gradient size that seems fairly innocuous
> (only 0.003, which is perhaps below what I where I would have set
> the new cutoff to eliminate a lot of the probably-false-positives
> that people have been getting with larger data sets), which is
> nevertheless a real convergence failure.  This underscores the
> need to set a gradient tolerance that is data-set-size-dependent
> (which the developers have discussed a bit, but maybe not in a
> public forum).
>
>   However, may I comment that this is a slightly ridiculous scenario?
> The data set here has 40 observations, and the model tries to fit 22
> parameters.  The model that treats id as a random effect works much
> better.  I can believe there are scenarios where you really do
> want study as a fixed effect, but did you expect it to be practical
> here?
>
> But maybe you're just trying to show that this is a "true positive"
> case for the convergence warnings.
>
> Some random code I wrote while diagnosing what was going on:
>
> library(ggplot2); theme_set(theme_bw())
>
> ## proportion + weights is a little easier to handle
> thedata <- transform(thedata,prop=nEvents/total)
>
> ggplot(thedata,aes(trt,prop))+geom_point(aes(size=total))+
>     geom_line(aes(group=id),colour="gray")
> glmer1 <- glmer(prop~trt+factor(id)+(0+trt|id),
>                 weights=total,data=thedata,family=binomial)
>
> ## id as RE
> glmer2 <- glmer(prop~trt+(1|id)+(0+trt|id),
>                 weights=total,data=thedata,family=binomial)
>
> dd <- update(glmer1,devFunOnly=TRUE)
> pars <- unlist(getME(glmer1,c("theta","fixef")))
> library("bbmle")
> ss <- slice2D(pars,dd)
> library("lattice")
> plot(ss)
> ## too complex, but too much work to cut down significantly
>
>
> > library(lme4)
> >
> > thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
> > 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
> > 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
> > 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
> > 200,200,200,200,200,200,200,200,200,200,200,200,200,
> > 200,200,200,200,200,200,200,200,200,200,200,200,200,
> > 200,200,200,200,200,200,200,200,200,200),trt=c(0,
> > 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
> > 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
> > 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
> > 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
> > 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
> > "2","3","4","5","6","7","8","9","10","11","12","13",
> > "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
> > "total","trt","id"),row.names=c(NA,40L),class="data.frame")
> >
> > glmer1<-glmer(cbind(nEvents,total-nEvents)~trt+factor(id)+
> ##   (0+trt|id),data=thedata,family=binomial)
> >
> > # while glmer has problems with component 9 it is 8 with a problem
> profile
> > # I've use devtol so the discrepancy is printed
> > prof.glmer1<-profile(glmer1,which=8,devtol=1.0e-3)
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From EasdaleT at landcareresearch.co.nz  Mon Mar 30 07:25:30 2015
From: EasdaleT at landcareresearch.co.nz (Tomas Easdale)
Date: Mon, 30 Mar 2015 05:25:30 +0000
Subject: [R-sig-ME] how to extract the scale parameter for a Gamma
 distribution from a fitted glmer()
Message-ID: <60F31DD8833DA649B45C59B39324DD4E1221C828@HERMES.landcare.ad.landcareresearch.co.nz>


Greetings

I have a glmer() model fitted with Gamma family and identity link which appears to be behaving nicely. I may be missing something obvious but have checked the documentation and cannot find a way of extracting the estimated scale (or shape) parameter for the Gamma distribution from the fitted model. Any tips much appreciated.

Tom?s Easdale
Landcare Research, Lincoln, NZ


________________________________

Please consider the environment before printing this email
Warning: This electronic message together with any attachments is confidential. If you receive it in error: (i) you must not read, use, disclose, copy or retain it; (ii) please contact the sender immediately by reply email and then delete the emails.
The views expressed in this email may not be those of Landcare Research New Zealand Limited. http://www.landcareresearch.co.nz

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Mar 30 16:31:16 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 30 Mar 2015 14:31:16 +0000 (UTC)
Subject: [R-sig-ME] how to extract the scale parameter for a Gamma
	distribution from a fitted glmer()
References: <60F31DD8833DA649B45C59B39324DD4E1221C828@HERMES.landcare.ad.landcareresearch.co.nz>
Message-ID: <loom.20150330T162651-130@post.gmane.org>

Tomas Easdale <EasdaleT at ...> writes:

> 
 
> Greetings I have a glmer() model fitted with Gamma family and
> identity link which appears to be behaving nicely. I may be missing
> something obvious but have checked the documentation and cannot find
> a way of extracting the estimated scale (or shape) parameter for the
> Gamma distribution from the fitted model. Any tips much appreciated.
> Tom

This is in fact not documented anywhere that I can see, but 1/sigma(fit)^2
appears to do the trick for the shape parameter.  For the purposes of
GL(M)Ms, the Gamma is parameterized as (mean,shape), so the values you're
estimating will be the mean -- if you want the scale parameters, use
mean = shape*scale -> scale = mean/shape ...

===============

library("lme4")
set.seed(101)
d <- expand.grid(block=LETTERS[1:26], rep=1:100, KEEP.OUT.ATTRS = FALSE)
d$x <- runif(nrow(d))  ## sd=1
reff_f <- rnorm(length(levels(d$block)),sd=1)
## need intercept large enough to avoid negative values
d$eta0 <- 4+3*d$x  ## fixed effects only
d$eta <- d$eta0+reff_f[d$block]
shapevec <- c(1,2,5)
res <- expand.grid(rep=1:10,shape=shapevec,est=NA) ## order matters
k <- 1
for (i in seq_along(shapevec)) {
    cat(".")
    for (j in 1:10) {
        dgl <- d
        dgl$mu <- exp(d$eta)
        dgl$y <- rgamma(nrow(d),scale=dgl$mu/2,shape=shapevec[i])
        ggl1 <- glmer(y ~ x + (1|block), data=dgl, family=Gamma(link="log"))
        res[k,"est"] <- 1/sigma(ggl1)^2
        k <- k+1
    }
}
library(ggplot2); theme_set(theme_bw())
ggplot(res,aes(shape,est))+geom_point()


From a_lafontaine at hotmail.com  Sat Mar 28 16:14:22 2015
From: a_lafontaine at hotmail.com (Alexandre Lafontaine)
Date: Sat, 28 Mar 2015 11:14:22 -0400
Subject: [R-sig-ME] lmer and standard error
Message-ID: <SNT153-W4555A016D6C9779E3F7FF6ECF70@phx.gbl>

Dear R users,
I have a question regarding how lmer (either lme4 or lmerTest) handles the degrees of freedom and calculation of the standard error for repeated observations.
I have a dataset in wich I have multiple observations for 57 different idyears in two different regions (range).
head(database) idyear      range overlapok cut05 c0620 regen water roads  elevaju36 GJ502006 charlevoix         1     0     0     0     0     0 223.888937 GJ502006 charlevoix         1     0   100     0     0     0 220.582938 GJ502006 charlevoix         1     0   100     0     0     0 219.411039 GJ502006 charlevoix         1     0   100     0     0     0 219.411040 GJ502006 charlevoix         1     0   100     0     0     0 219.411041 GJ502006 charlevoix         1     0   100     0     0     0 219.0555
Here is my lmer formula in which i nested idyears in range as random effects:
fidint5 <- lmer(overlapok ~ natdist + cut05 + c0620 + regen +(1|range/idyear) , data=database)summary(fidint5)
The summary identifies the good number of  groups (57) for 2 range. However, the df shows that the error is computed on between 2404 and 2418 df which returns really high t values and therefore extremely small p values.

Random effects: Groups       Name        Variance Std.Dev. idyear:range (Intercept) 0.16211  0.4026   range        (Intercept) 0.00000  0.0000   Residual                 0.01709  0.1307  Number of obs: 2429, groups:  idyear:range, 33; range, 2
Fixed effects:                Estimate   Std. Error           df t value(Intercept)    0.6691140    0.0704710   32.1000000   9.495natdist       -0.0023431    0.0015088 2404.1000000  -1.553cut05          0.0092084    0.0005473 2407.9000000  16.824c0620          0.0041097    0.0004459 2418.0000000   9.217regen         -0.0089785    0.0003203 2407.3000000 -28.027                        Pr(>|t|)    (Intercept)      0.0000000000765 ***natdist                    0.121    cut05       < 0.0000000000000002 ***c0620       < 0.0000000000000002 ***regen       < 0.0000000000000002 ***
Are the groups specified in the random term considered in this result? Is the way I specified the random effects incorrect or is this the way lmer function is designed? I am really only beginning to use mixed models and would really appreciate any help on this.
Thanks a lot for your time and wisdom, 
Alexandre Lafontaine


 		 	   		  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Mar 30 22:21:20 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 30 Mar 2015 20:21:20 +0000 (UTC)
Subject: [R-sig-ME] Problems with convergence
References: <CAF5_5cxHcAWSvgYL3876407aM5tM4pVBB+LTjr_gKPc7Bh8rbQ@mail.gmail.com>
	<loom.20150319T042938-705@post.gmane.org>
	<CAF5_5cy0BE9Mi-_VROBQ+fUXYM+GX8=vbmga+KygRVWfZHsQ5w@mail.gmail.com>
Message-ID: <loom.20150330T220526-332@post.gmane.org>

Ken Beath <ken.beath at ...> writes:

> Yes, I was demonstrating that it fails convergence and then as a
> consequence fails to profile. I have my doubts about 
> convergence for the bobyqa
> algorithm, I have other applications where it doesn't converge properly.
> For some of my own work I've used nlminb followed by Nelder-Mead if there
> is a convergence failure. Not optimal but it seems to work.

   I'm still not sure whether you expect it to converge (I think you
do), or whether you are just pointing out that the convergence warning
in this case is probably justified (in the face of so many convergence
warnings that turn out to be false positives, this is a useful piece
of information).

> While it is fairly heavily parameterised it is a real model, 
>  a frequentist
> implementation of Smith, T. C., Spiegelhalter, D. J., & Thomas, a. (1995).
> Bayesian approaches to random-effects meta-analysis: a comparative study.
> Statistics in Medicine, 14(24), 2685?99. The reason for having studies as
> fixed effects is probably philosophical, the overall success rates are not
> likely to be given by normally distributed random effects, and are in many
> cases specifically chosen.

  I can appreciate that, but I still think it's unrealistic to expect
to be able to fit 22 parameters to 40 observations except under very
special circumstances.  One point about switching from the Bayesian
to the frequentist world is that the Bayesians (by definition) put
priors on their parameters, which provides a degree of regularization
that is not by default available to frequentist methods.  What priors
did Smith et al. use?  It might be worth trying this in blme with
priors on the fixed effects ...

> I did find that one of the data sets that I have also failed, but fitted
> with a commercial program that is based on the EM algorithm. For this type
> of problem it is actually faster, as any type of quasi-Newton needs to
> calculate lots of derivatives.

  I could whine about the difficulty of finding globally robust,
reliable, and fast optimization algorithms, but I won't.  I can certainly
appreciate that there are more reliable methods for particular
sub-classes of problems.

> Anyway, I'm going to keep looking at the methods, and eventually the code
> for glmer and may eventually have some suggestions.

  Would be happy to hear them.

  It's worth pointing out that lme4 is using a preliminary "nAGQ=0"
step, which ignores the terms contributed by the integrals over the
distributions of the conditional modes and as a result is able to
fit both the fixed-effect parameters and the conditional modes in
a single linear-algebra step, reducing the dimensionality of the
nonlinear optimization to the length of the variance-covariance
parameter vector ...
 
> On 19 March 2015 at 14:45, Ben Bolker <bbolker <at> gmail.com> wrote:
> 
> > Ken Beath <ken.beath <at> ...> writes:
> >
> > > The following code shows that there are convergence problem messages
> > > where there is a problem with convergence. The profiling shows that
> > > the maximum found is not the correct one. This is simulated data for
> > > a binary meta-analysis with fixed effect for study and random effect
> > > for treatment.
> >

 [paragraph snipped to try to make Gmane happy]

> >   However, may I comment that this is a slightly ridiculous scenario?
> > The data set here has 40 observations, and the model tries to fit 22
> > parameters.  The model that treats id as a random effect works much
> > better.  I can believe there are scenarios where you really do
> > want study as a fixed effect, but did you expect it to be practical
> > here?
> >
> > But maybe you're just trying to show that this is a "true positive"
> > case for the convergence warnings.
> >
> > Some random code I wrote while diagnosing what was going on:
> >
> > library(ggplot2); theme_set(theme_bw())
> >
> > ## proportion + weights is a little easier to handle
> > thedata <- transform(thedata,prop=nEvents/total)
> >
> > ggplot(thedata,aes(trt,prop))+geom_point(aes(size=total))+
> >     geom_line(aes(group=id),colour="gray")
> > glmer1 <- glmer(prop~trt+factor(id)+(0+trt|id),
> >                 weights=total,data=thedata,family=binomial)
> >
> > ## id as RE
> > glmer2 <- glmer(prop~trt+(1|id)+(0+trt|id),
> >                 weights=total,data=thedata,family=binomial)
> >
> > dd <- update(glmer1,devFunOnly=TRUE)
> > pars <- unlist(getME(glmer1,c("theta","fixef")))
> > library("bbmle")
> > ss <- slice2D(pars,dd)
> > library("lattice")
> > plot(ss)
> > ## too complex, but too much work to cut down significantly
> >
> > > library(lme4)
> > >
> > > thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
> > > 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
> > > 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
> > > 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
> > > 200,200,200,200,200,200,200,200,200,200,200,200,200,
> > > 200,200,200,200,200,200,200,200,200,200,200,200,200,
> > > 200,200,200,200,200,200,200,200,200,200),trt=c(0,
> > > 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
> > > 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
> > > 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
> > > 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
> > > 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
> > > "2","3","4","5","6","7","8","9","10","11","12","13",
> > > "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
> > > "total","trt","id"),row.names=c(NA,40L),class="data.frame")
> > >
> > > glmer1<-glmer(cbind(nEvents,total-nEvents)~trt+factor(id)+
> > ##   (0+trt|id),data=thedata,family=binomial)
> > >
> > > # while glmer has problems with component 9 it is 8 with a problem
> > profile
> > > # I've use devtol so the discrepancy is printed
> > > prof.glmer1<-profile(glmer1,which=8,devtol=1.0e-3)



From bbolker at gmail.com  Mon Mar 30 22:44:45 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 30 Mar 2015 20:44:45 +0000 (UTC)
Subject: [R-sig-ME] lmer and standard error
References: <SNT153-W4555A016D6C9779E3F7FF6ECF70@phx.gbl>
Message-ID: <loom.20150330T223738-237@post.gmane.org>

Alexandre Lafontaine <a_lafontaine at ...> writes:


> Dear R users,

> I have a question regarding how lmer (either lme4 or lmerTest)
> handles the degrees of freedom and calculation of the standard error
> for repeated observations.  I have a dataset in wich I have multiple
> observations for 57 different idyears in two different regions
> (range).

  Your formatting got mangled; it's best to try to send to the
mailing list using the simplest format you have available (plain
text, monospace font).  (I'm further mangling it because I'm posting
via Gmane, which doesn't like lines > 80 characters)


> head(database) 
idyear      range overlapok cut05 c0620 regen water
     roads  elevaju36 GJ502006 charlevoix        
 1     0     0     0    
> 0     0 223.888937 GJ502006 charlevoix         1   
  0   100     0     0     0 220.582938 GJ502006 charlevoix         
1     0   100     0     0     0 219.411039
> GJ502006 charlevoix         1     0   100     0     0     
0 219.411040 GJ502006 charlevoix         1     0   100     0     0     0 
219.411041 GJ502006
> charlevoix         1     0   100     0     0     0 219.0555


> Here is my lmer formula in which i nested idyears in range as random effects:

> fidint5 <- lmer(overlapok ~ natdist + cut05 + c0620 + regen +
  (1|range/idyear) , data=database)

summary(fidint5)

The summary identifies the good number of  groups (57) for 2 range. 
However, the df shows that the error is
computed on between 2404 and 2418 df which returns really high t values 
and therefore extremely small p values.
 
 Random effects: Groups       Name        Variance Std.Dev. 
idyear:range (Intercept) 0.16211  0.4026   
range        (Intercept) 0.00000  0.0000   
Residual                 0.01709  0.1307  
Number of obs: 2429, groups:  idyear:range, 33; range, 2

   It doesn't make sense to use range as a random effect, since
there are only two levels.  Most practical to treat it as fixed
instead.

[snip]

> Are the groups specified in the random term considered in this
> result? Is the way I specified the random effects incorrect or is
> this the way lmer function is designed? I am really only beginning
> to use mixed models and would really appreciate any help on this.

  The plain old lme4 package gives no df, leaving it to you to 
work it out for yourself.

  lmerTest uses Satterthwaite approximations, which are generally
pretty good but might have failed you here.  You could try the
pbkrtest and/or afex packages to get Kenward-Roger approximations,
which are slower but more reliable (if they're very close to
the Satterthwaite results you could fall back on the Satterthwaite
approx for practical use rather than slowing yourself down all
the time).

  If your covariates (natdist + cut05 + c0620 + regen) 
vary within years, then this is more or less a randomized-block
design, in which case the df given will be about right.

  By treating 'range' as a fixed effect, you won't be able to
make inferences beyond the two ranges considered -- but practically
speaking you wouldn't be able to extrapolate to other ranges if
you had only measured two in the first place ...


  Please try not to post in HTML ...


From xavier.paoletti at curie.fr  Tue Mar 31 16:01:38 2015
From: xavier.paoletti at curie.fr (xavier.paoletti at curie.fr)
Date: Tue, 31 Mar 2015 16:01:38 +0200
Subject: [R-sig-ME] AUTO : No longer at Institut Curie
Message-ID: <OFB013B82A.5CB9E238-ONC1257E19.004D0E25-C1257E19.004D0E25@curie.net>


Je suis absent(e) du bureau jusqu'au 31/12/2015

I do not work at Curie any more.
Please contact Alexia Savignoni for any questions related to stat analyses.

Best regards,

Xavier Paoletti


Remarque?: ceci est une r?ponse automatique ? votre message
"R-sig-mixed-models Digest, Vol 99, Issue 43" envoy? le 31/03/2015 12:00:03
.

C'est la seule notification que vous recevrez pendant l'absence de cette
personne.


L'int?grit? de ce message n'?tant pas assur?e sur Internet, l'Institut Curie ne peut ?tre tenu responsable de son contenu. 
Si vous n'?tes pas destinataire de ce message confidentiel, merci de le d?truire et d'avertir imm?diatement l'exp?diteur.
Afin de contribuer au respect de l'environnement, merci de n'imprimer ce mail qu'en cas de n?cessit?.


From alexandre.m.martin at gmail.com  Tue Mar 31 16:07:34 2015
From: alexandre.m.martin at gmail.com (Alexandre Martin)
Date: Tue, 31 Mar 2015 10:07:34 -0400
Subject: [R-sig-ME] design matrices in MCMCglmm
In-Reply-To: <20150328080133.381406iv6lkvpdjw@www.staffmail.ed.ac.uk>
References: <5515C00C.8000904@gmail.com>
	<20150328080133.381406iv6lkvpdjw@www.staffmail.ed.ac.uk>
Message-ID: <551AAA26.6050204@gmail.com>

Hi Jarrod,

Thank you for your help.
My question is now extended to the subject of associative indirect 
genetic effects.

For example in this data set :
id    cage
a    1
b    2
c    1
d    1
e    2
f    2
g    2

cage is a grouping variable describing the composition of cages. For 
instance, individuals a,c,d live in cage 1.

Design matrix Z_cage typically produced by MCMCglmm should be:
      c1   c2
a    1    0
b    0    1
c    1    0
d    1    0
e    0    1
f    0    1
g    0    1
where phenotype of individuals {a, b, ..., g} are linked to cages 1 and 2.

Design matrix Z_mates, however, linking the phenotype of individual i to 
its cage' mates is:
      a    b    c    d    e    f    g
a    0    0    1    1    0    0    0
b    0    0    0    0    1    1    1
c    1    0    0    1    0    0    0
d    1    0    1    0    0    0    0
e    0    1    0    0    0    1    1
f    0    1    0    0    1    0    1
g    0    1    0    0    1    1    0

It is Z_cage that is given by default, whereas it is matrix Z_mates that 
should be used to predict associative effects.

Is it possible to force MCMCglmm to work with Z_mates instead of Z_cage?

Thanks again!

Alexandre

Le 2015-03-28 04:01, Jarrod Hadfield a ?crit :
> Hi Alexandre,
>
> The design matrices should be identical for both effects (z_{ij}=1 if
> the jth individual is the mother of individual i). The difference is in
> the correlation structure of the random effects. For environmental
> maternal effects they are assumed iid (i.e. an identity matrix) but for
> the maternal genetic effects they are assumed to be proportional to the
> A matrix. inverseA will return the inverse of A if you pass it the
> pedigree. It is this inverse that is required for forming the MME.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
> Quoting Alexandre Martin <alexandre.m.martin at gmail.com> on Fri, 27 Mar
> 2015 16:39:40 -0400:
>
>> Dear all,
>>
>> I am working on estimating maternal effects (genetic and environmental)
>> with MCMCglmm that is new for me.
>>
>> I am trying to apply to MCMCglmm what is shown in online Muir's course
>> notes made for SAS. Leanning on Henderson?s Mixed Model Equation, these
>> notes explain how to solve MME to predict random effects ?by hand?.
>>
>> Here is my concern:
>>
>> I do not know how to extract the design matrices for a MCMCglmm model,
>> e.g. the relatedness matrix or the one for maternal genetic effects. I
>> want that to understand how the design matrices are constructed by
>> comparing them to what they are supposed to look like.  For instance,
>> the design matrix for maternal genetic effects should relate offspring
>> to all the individuals that are in the pedigree, whereas the design
>> matrix for maternal environmental effects should just relate offspring
>> to their mothers. Does such a difference exist when MCMCglmm constructs
>> its design matrices? If not, how to include such different matrices in
>> models?
>>
>>
>> Any help will be greatly appreciated. Thank you!
>>
>>
>> Alexandre
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Mar 31 17:25:12 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 31 Mar 2015 17:25:12 +0200
Subject: [R-sig-ME] Problems with convergence
In-Reply-To: <loom.20150330T220526-332@post.gmane.org>
References: <CAF5_5cxHcAWSvgYL3876407aM5tM4pVBB+LTjr_gKPc7Bh8rbQ@mail.gmail.com>
	<loom.20150319T042938-705@post.gmane.org>
	<CAF5_5cy0BE9Mi-_VROBQ+fUXYM+GX8=vbmga+KygRVWfZHsQ5w@mail.gmail.com>
	<loom.20150330T220526-332@post.gmane.org>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0978FF5A@UM-MAIL4112.unimaas.nl>

This discussion piqued my interest. The model that Ken was fitting is in essence one of the models that is fitted by the rma.glmm() function in the metafor package. This is sometimes called the unconditional model with fixed study effects. To illustrate:

### original data

thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
200,200,200,200,200,200,200,200,200,200,200,200,200,
200,200,200,200,200,200,200,200,200,200,200,200,200,
200,200,200,200,200,200,200,200,200,200),trt=c(0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
"2","3","4","5","6","7","8","9","10","11","12","13",
"14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
"total","trt","id"),row.names=c(NA,40L),class="data.frame")

### restructure data as needed for input into rma.glmm()

dat <- cbind(thedata[1:20,], thedata[21:40,])
dat$id <- dat$id <- dat$trt <- dat$trt <- NULL
colnames(dat) <- c("ci", "n2i", "ai", "n1i")

library(metafor)
library(lme4)

### model fitted by Ken
res1 <- glmer(cbind(nEvents,total-nEvents) ~ trt + factor(id) + (0+trt|id), data=thedata, family=binomial)

### fit unconditional model with fixed study effects via rma.glmm()
res2 <- rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, nAGQ=1)

### to get exact equivalence, use +-1/2 coding for the random effects
thedata$trt12 <- thedata$trt - 1/2
res3 <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt + factor(id) + (0+trt12|id), data=thedata, family=binomial)

summary(res1)
summary(res2)
summary(res3)

### end example

A few notes:

1) rma.glmm() uses nAGQ=7 by default, so I switched that to 1 for the comparison.

2) Some discussion of the 0/1 versus +-1/2 coding can be found in Turner et al. (2000) and Higgins et al. (2001). I tend to prefer the +-1/2 coding, so that is also what is currently implemented in rma.glmm(), but I may add the 0/1 coding as an option.

3) A nice discussion of the model is provided by Senn (2000). He also discusses a variety of other modeling options, including a model using random study effects.

4) In fact, the unconditional model with random study effects can be fitted with:

rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, model="UM.RS")

(which makes use of glmer() underneath). As discussed by Senn, this model may violate what he calls the 'concurrent control principle', but his wording is cautious ('may violate', 'may be regarded as undesirable'), which reflects the lack of a thorough discussion in the literature comparing the various models.

5) Yet another option is the (mixed-effects) conditional logistic model. See, for example, Stijnen et al. (2010). This model is obtained when conditioning on the total number of events within each study and leads to non-central hypergeometric distributions for the data within each study. This model can be fitted with:

rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, model="CM.EL")

Sorry, it's slow (I haven't found a clever way of speeding up the integration over the non-central hypergeometric distributions). Much faster, thanks to lme4, is:

rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, model="CM.AL")

which uses an approximation to the exact conditional likelihood.

6) And of course there are Bayesian implementations of such models.

7) With respect to the model fitted by Ken, it's maybe interesting to note that NOT using the Laplace approximation, but something like 7 quadrature points, does not cause any convergence warnings:

glmer(cbind(nEvents,total-nEvents) ~ trt + factor(id) + (0+trt|id), data=thedata, family=binomial, nAGQ=7)

Alright, I'll shut up now.

References mentioned above:

Higgins, J. P. T., Whitehead, A., Turner, R. M., Omar, R. Z., & Thompson, S. G. (2001). Meta-analysis of continuous outcome data from individual patients. Statistics in Medicine, 20(15), 2219-2241.

Senn, S. (2000). The many modes of meta. Drug Information Journal, 34, 535-549.

Stijnen, T., Hamza, T. H., & Ozdemir, P. (2010). Random effects meta-analysis of event outcome in the framework of the generalized linear mixed model with applications in sparse data. Statistics in Medicine, 29(29), 3046-3067.

Turner, R. M., Omar, R. Z., Yang, M., Goldstein, H., & Thompson, S. G. (2000). A multilevel model framework for meta-analysis of clinical trials with binary outcomes. Statistics in Medicine, 19(24), 3417-3432.

Best,
Wolfgang

--    
Wolfgang Viechtbauer, Ph.D., Statistician    
Department of Psychiatry and Neuropsychology    
School for Mental Health and Neuroscience    
Faculty of Health, Medicine, and Life Sciences    
Maastricht University, P.O. Box 616 (VIJV1)    
6200 MD Maastricht, The Netherlands    
+31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Ben Bolker
> Sent: Monday, March 30, 2015 22:21
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Problems with convergence
> 
> Ken Beath <ken.beath at ...> writes:
> 
> > Yes, I was demonstrating that it fails convergence and then as a
> > consequence fails to profile. I have my doubts about
> > convergence for the bobyqa
> > algorithm, I have other applications where it doesn't converge
> properly.
> > For some of my own work I've used nlminb followed by Nelder-Mead if
> there
> > is a convergence failure. Not optimal but it seems to work.
> 
>    I'm still not sure whether you expect it to converge (I think you
> do), or whether you are just pointing out that the convergence warning
> in this case is probably justified (in the face of so many convergence
> warnings that turn out to be false positives, this is a useful piece
> of information).
> 
> > While it is fairly heavily parameterised it is a real model,
> >  a frequentist
> > implementation of Smith, T. C., Spiegelhalter, D. J., & Thomas, a.
> (1995).
> > Bayesian approaches to random-effects meta-analysis: a comparative
> study.
> > Statistics in Medicine, 14(24), 2685?99. The reason for having studies
> as
> > fixed effects is probably philosophical, the overall success rates are
> not
> > likely to be given by normally distributed random effects, and are in
> many
> > cases specifically chosen.
> 
>   I can appreciate that, but I still think it's unrealistic to expect
> to be able to fit 22 parameters to 40 observations except under very
> special circumstances.  One point about switching from the Bayesian
> to the frequentist world is that the Bayesians (by definition) put
> priors on their parameters, which provides a degree of regularization
> that is not by default available to frequentist methods.  What priors
> did Smith et al. use?  It might be worth trying this in blme with
> priors on the fixed effects ...
> 
> > I did find that one of the data sets that I have also failed, but
> fitted
> > with a commercial program that is based on the EM algorithm. For this
> type
> > of problem it is actually faster, as any type of quasi-Newton needs to
> > calculate lots of derivatives.
> 
>   I could whine about the difficulty of finding globally robust,
> reliable, and fast optimization algorithms, but I won't.  I can certainly
> appreciate that there are more reliable methods for particular
> sub-classes of problems.
> 
> > Anyway, I'm going to keep looking at the methods, and eventually the
> code
> > for glmer and may eventually have some suggestions.
> 
>   Would be happy to hear them.
> 
>   It's worth pointing out that lme4 is using a preliminary "nAGQ=0"
> step, which ignores the terms contributed by the integrals over the
> distributions of the conditional modes and as a result is able to
> fit both the fixed-effect parameters and the conditional modes in
> a single linear-algebra step, reducing the dimensionality of the
> nonlinear optimization to the length of the variance-covariance
> parameter vector ...
> 
> > On 19 March 2015 at 14:45, Ben Bolker <bbolker <at> gmail.com> wrote:
> >
> > > Ken Beath <ken.beath <at> ...> writes:
> > >
> > > > The following code shows that there are convergence problem
> messages
> > > > where there is a problem with convergence. The profiling shows that
> > > > the maximum found is not the correct one. This is simulated data
> for
> > > > a binary meta-analysis with fixed effect for study and random
> effect
> > > > for treatment.
> > >
> 
>  [paragraph snipped to try to make Gmane happy]
> 
> > >   However, may I comment that this is a slightly ridiculous scenario?
> > > The data set here has 40 observations, and the model tries to fit 22
> > > parameters.  The model that treats id as a random effect works much
> > > better.  I can believe there are scenarios where you really do
> > > want study as a fixed effect, but did you expect it to be practical
> > > here?
> > >
> > > But maybe you're just trying to show that this is a "true positive"
> > > case for the convergence warnings.
> > >
> > > Some random code I wrote while diagnosing what was going on:
> > >
> > > library(ggplot2); theme_set(theme_bw())
> > >
> > > ## proportion + weights is a little easier to handle
> > > thedata <- transform(thedata,prop=nEvents/total)
> > >
> > > ggplot(thedata,aes(trt,prop))+geom_point(aes(size=total))+
> > >     geom_line(aes(group=id),colour="gray")
> > > glmer1 <- glmer(prop~trt+factor(id)+(0+trt|id),
> > >                 weights=total,data=thedata,family=binomial)
> > >
> > > ## id as RE
> > > glmer2 <- glmer(prop~trt+(1|id)+(0+trt|id),
> > >                 weights=total,data=thedata,family=binomial)
> > >
> > > dd <- update(glmer1,devFunOnly=TRUE)
> > > pars <- unlist(getME(glmer1,c("theta","fixef")))
> > > library("bbmle")
> > > ss <- slice2D(pars,dd)
> > > library("lattice")
> > > plot(ss)
> > > ## too complex, but too much work to cut down significantly
> > >
> > > > library(lme4)
> > > >
> > > > thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
> > > > 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
> > > > 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
> > > > 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
> > > > 200,200,200,200,200,200,200,200,200,200,200,200,200,
> > > > 200,200,200,200,200,200,200,200,200,200,200,200,200,
> > > > 200,200,200,200,200,200,200,200,200,200),trt=c(0,
> > > > 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
> > > > 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
> > > > 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
> > > > 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
> > > > 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
> > > > "2","3","4","5","6","7","8","9","10","11","12","13",
> > > >
> "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
> > > > "total","trt","id"),row.names=c(NA,40L),class="data.frame")
> > > >
> > > > glmer1<-glmer(cbind(nEvents,total-nEvents)~trt+factor(id)+
> > > ##   (0+trt|id),data=thedata,family=binomial)
> > > >
> > > > # while glmer has problems with component 9 it is 8 with a problem
> > > profile
> > > > # I've use devtol so the discrepancy is printed
> > > > prof.glmer1<-profile(glmer1,which=8,devtol=1.0e-3)

