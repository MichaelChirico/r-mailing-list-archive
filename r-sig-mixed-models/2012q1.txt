From ramos.grad.student at gmail.com  Mon Jan  2 09:41:39 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 2 Jan 2012 00:41:39 -0800
Subject: [R-sig-ME] covariance structures for longitudinal models
Message-ID: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120102/2f1f39eb/attachment-0003.pl>

From jwiley.psych at gmail.com  Mon Jan  2 17:13:59 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 2 Jan 2012 08:13:59 -0800
Subject: [R-sig-ME] covariance structures for longitudinal models
In-Reply-To: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
Message-ID: <CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>

Hi Antonio,

I am not familiar with antedependence models so no comment there.

For factor analysis and that genre, I like OpenMx (also see sem and
lavaan).  One thing I like about OpenMx is while it caters to SEM, it
is a general purpose matrix optimizer, and it really is not difficult
to access that power.  So in principal, you can have whatever matrices
you want, roll your own objective function, and away it'll go.

For BUGS you have a lot of options including: R2OpenBUGS and R2WinBUGS
among others.

Cheers,

Josh

On Mon, Jan 2, 2012 at 12:41 AM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> Hi all,
>
> I've trying to use R to fit some longitudinal models, mostly via lme and
> nlme packages. However, it seems that many standard models are lacking,
> such as antedependence models or factor analytic models for covariance
> matrices. These models are readily available in SAS. Does an recommend
> other packages for the job in R? I don't really care if I am in frequentist
> or bayesian world as long as I have more modeling flexibility. I would also
> be interested in doing that in WINBUGS/JAGS.
>
> All the best,
>
> Antonio.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From ramos.grad.student at gmail.com  Mon Jan  2 21:16:38 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 2 Jan 2012 12:16:38 -0800
Subject: [R-sig-ME] covariance structures for longitudinal models
In-Reply-To: <CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
	<CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>
Message-ID: <CAHawB9utWpzVSgTBz82M1O4ss5Th+NvZtt4bLCJGe581uitHPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120102/d19f3da0/attachment-0001.pl>

From ramos.grad.student at gmail.com  Wed Jan  4 02:52:47 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 3 Jan 2012 17:52:47 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
	over 146
Message-ID: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120103/0755b9c2/attachment-0001.pl>

From jwiley.psych at gmail.com  Wed Jan  4 03:51:00 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 3 Jan 2012 18:51:00 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
 over 146
In-Reply-To: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
References: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
Message-ID: <CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>

Hi Antonio,

Look at the error message: "function evaluation limit reached without
convergence" you increased the number of iterations, but the objective
function reached its limit for max evaluations prior to convergance.
The 'brute force' approach would be to use the msMaxEval argument of
lmeControl to up that, but I would suggest carefully scrutinizing your
data and model prior before blindly asking the optimizer to run
longer.

Have you graphed your data?  What sort of variables are time and
maternal_educ?  If you send us data, we can show you some examples of
how you might graph and examine your data.  Also, do you really want a
random interaction?

Finally, in model formulae, * behaves specially, so x * z expands to:
x + z + x:z, thus a simplified writing of your model (not really
important and if the other way is clearer to you, by all means use it,
but you can save a few keystrokes; also note I show the msMaxEval
argument):

model.c2 <- lme(log(child_mortality) ~  time * log(maternal_educ),
  control = lmeControl(msMaxIter = 200, msMaxEval = 500 msVerbose = TRUE),
  merged1, random = ~ log(maternal_educ) * time | country.x,
  na.action = na.omit, method = "ML")

Cheers,

Josh

On Tue, Jan 3, 2012 at 5:52 PM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> Hi all,
>
> I am trying to fit a simple mixed model for longitudinal data, but the
> algorithm is not converging. When I add additional commands in the call I
> am able to increase the number of iterations from the default of 50 to 146,
> but no more than that. Does anyway have an idea about what is going on? ?I
> can provided data if needed.
>
> Best, Antonio.
>
>> model.c2 <- lme(log(child_mortality) ~ ?time + log(maternal_educ) +
> log(maternal_educ)*time,
> + ? ? ? ? ? ? ? ?control=lmeControl(msMaxIter = 200, msVerbose = TRUE),
> + ? ? ? ? ? ? ? ?merged1, random= ~time + log(maternal_educ)*time
> |country.x, na.action=na.omit,method="ML")
> ?0: ? ? 11378.396: -1.65670 ?2.44758 -3.03894 ?2.00310 -34.0487 0.186837
> 0.0637447 ?49.2689 -10.3311 ?5.94936
> ?1: ? ? 11375.740: -1.68701 ?2.45171 -3.03866 ?2.00265 -34.0499 0.302840
> 0.0305228 ?49.2682 -10.3309 ?5.94934
> ?2: ? ? 11375.323: -1.68664 ?2.45188 -3.03838 ?2.00234 -34.0499 0.302036
> 0.0279806 ?49.2682 -10.3309 ?5.94934
> ?3: ? ? 11375.161: -1.68509 ?2.45164 -3.03478 ?1.99830 -34.0500 0.301491
> 0.0299300 ?49.2682 -10.3309 ?5.94939
> ?4: ? ? 11374.835: -1.68137 ?2.45134 -3.03272 ?1.99601 -34.0499 0.290639
> 0.0313596 ?49.2682 -10.3310 ?5.94943
> ?5: ? ? 11361.671: -1.63878 ?2.45243 -2.66545 ?1.58982 -34.0573 0.726526
> -0.0906120 ?49.2606 -10.3367 ?5.95909
> ?6: ? ? 11359.791: -1.65178 ?2.44927 -2.57664 ?1.47997 -34.0610 0.975864
> -0.170656 ?49.2572 -10.3386 ?5.96736
> ?7: ? ? 11359.595: -1.65004 ?2.45965 -2.56790 ?1.46837 -34.0612 ?1.00787
> -0.168258 ?49.2564 -10.3397 ?5.97066
>
>
>
> 132: ? ? 11307.797: -1.39340 ?3.37422 0.317114 0.526105 -90.6641 ?44.6928
> -13.9187 ?667.927 -208.799 ?26.9546
> 133: ? ? 11307.797: -1.39346 ?3.38002 0.320773 0.526102 -91.1985 ?45.1140
> -14.0518 ?675.133 -211.078 ?27.0564
> 134: ? ? 11307.796: -1.39350 ?3.38197 0.321697 0.525758 -91.3801 ?45.2651
> -14.0996 ?677.663 -211.877 ?27.0798
> 135: ? ? 11307.795: -1.39360 ?3.38872 0.325211 0.525153 -92.0139 ?45.7838
> -14.2635 ?686.411 -214.643 ?27.1729
> 136: ? ? 11307.794: -1.39365 ?3.39553 0.329183 0.525088 -92.6545 ?46.2974
> -14.4259 ?695.158 -217.409 ?27.2829
> 137: ? ? 11307.792: -1.39368 ?3.40218 0.332937 0.525082 -93.2910 ?46.8111
> -14.5883 ?703.905 -220.176 ?27.3876
> 138: ? ? 11307.791: -1.39373 ?3.40895 0.337031 0.525186 -93.9332 ?47.3224
> -14.7500 ?712.652 -222.942 ?27.5031
> 139: ? ? 11307.790: -1.39378 ?3.41494 0.341038 0.525609 -94.5084 ?47.7708
> -14.8918 ?720.413 -225.398 ?27.6206
> 140: ? ? 11307.789: -1.39382 ?3.41930 0.344713 0.526541 -94.9384 ?48.0868
> -14.9919 ?726.060 -227.188 ?27.7364
> 141: ? ? 11307.788: -1.39387 ?3.42361 0.347375 0.526566 -95.3534 ?48.4155
> -15.0959 ?731.709 -228.975 ?27.8133
> 142: ? ? 11307.788: -1.39393 ?3.42785 0.349776 0.526344 -95.7643 ?48.7467
> -15.2006 ?737.357 -230.762 ?27.8810
> 143: ? ? 11307.787: -1.39401 ?3.43137 0.351265 0.525645 -96.1084 ?49.0365
> -15.2922 ?742.207 -232.294 ?27.9192
> 144: ? ? 11307.786: -1.39407 ?3.43484 0.352910 0.525314 -96.4518 ?49.3214
> -15.3823 ?747.014 -233.815 ?27.9635
> 145: ? ? 11307.786: -1.39410 ?3.43839 0.354938 0.525329 -96.8011 ?49.6024
> -15.4711 ?751.820 -235.335 ?28.0217
> 146: ? ? 11307.786: -1.39410 ?3.43839 0.354938 0.525329 -96.8011 ?49.6024
> -15.4711 ?751.820 -235.335 ?28.0217
> Error in lme.formula(log(child_mortality) ~ time + log(maternal_educ) + ?:
> ?nlminb problem, convergence error code = 1
> ?message = function evaluation limit reached without convergence (9)
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From ramos.grad.student at gmail.com  Wed Jan  4 04:20:30 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 3 Jan 2012 19:20:30 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
 over 146
In-Reply-To: <CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>
References: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
	<CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>
Message-ID: <CAHawB9tkjXpY=kZvxtcrpHPTCg+1t+95a4_5PC_am+7gRpRdTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120103/f2cff3f9/attachment-0001.pl>

From jwiley.psych at gmail.com  Wed Jan  4 06:09:42 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 3 Jan 2012 21:09:42 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
 over 146
In-Reply-To: <CAHawB9tkjXpY=kZvxtcrpHPTCg+1t+95a4_5PC_am+7gRpRdTw@mail.gmail.com>
References: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
	<CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>
	<CAHawB9tkjXpY=kZvxtcrpHPTCg+1t+95a4_5PC_am+7gRpRdTw@mail.gmail.com>
Message-ID: <CANz9Z_J_hk_s+zHK5d3bQ3UAD3MgM7Ug9t+bC4fx_62piQO34A@mail.gmail.com>

On Tue, Jan 3, 2012 at 7:20 PM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
[snip]
 at end of the day, it still don't undertand why it
> doesn't obey my instructions and increase the number of interactions, even
> if to crash.

It does increase the number of iterations---you reached a function
evaluation limit, not an iteration limit.  There is not a 1:1
relationship between function evaluations and iterations.  If you're
curious, you may enjoy: http://netlib.bell-labs.com/cm/cs/cstr/153.pdf
 or http://www.numerical-recipes.com/ the first is some documentation
for the PORT routines which are used by nlimnb(), the latter is goes
into more detail about optimization.  There are other (possibly much
better) books out there, but it is the only one I am personally
familiar with.

Cheers,

Josh

-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From ramos.grad.student at gmail.com  Wed Jan  4 06:19:12 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 3 Jan 2012 21:19:12 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
 over 146
In-Reply-To: <CANz9Z_J_hk_s+zHK5d3bQ3UAD3MgM7Ug9t+bC4fx_62piQO34A@mail.gmail.com>
References: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
	<CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>
	<CAHawB9tkjXpY=kZvxtcrpHPTCg+1t+95a4_5PC_am+7gRpRdTw@mail.gmail.com>
	<CANz9Z_J_hk_s+zHK5d3bQ3UAD3MgM7Ug9t+bC4fx_62piQO34A@mail.gmail.com>
Message-ID: <CAHawB9sNiaxJqKKV6UbOhC8kjN59yXH2Mep6CN3kA9JEwZ5dLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120103/08816d95/attachment-0001.pl>

From kevinjspring at gmail.com  Wed Jan  4 12:56:50 2012
From: kevinjspring at gmail.com (Kevin Spring)
Date: Wed, 4 Jan 2012 05:56:50 -0600
Subject: [R-sig-ME] extracting values from lmer
Message-ID: <CAPv6FHgzdYBKsagM7Svy3zP+Q7T33LgSaS3BcUYenx6fS8Av-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120104/64888082/attachment-0001.pl>

From robert.espesser at lpl-aix.fr  Wed Jan  4 13:44:26 2012
From: robert.espesser at lpl-aix.fr (espesser)
Date: Wed, 04 Jan 2012 13:44:26 +0100
Subject: [R-sig-ME] extracting values from lmer
In-Reply-To: <CAPv6FHgzdYBKsagM7Svy3zP+Q7T33LgSaS3BcUYenx6fS8Av-w@mail.gmail.com>
References: <CAPv6FHgzdYBKsagM7Svy3zP+Q7T33LgSaS3BcUYenx6fS8Av-w@mail.gmail.com>
Message-ID: <4F0449AA.7000102@lpl-aix.fr>

  Hi Kevin,
Maybe there is a better way (a function) , but you can use:

yourmodel at deviance["sigmaREML"]

it returns the residual std. dev.   :  0.13636
(in case of the default setting for lmer()  , i.e. REML=TRUE)
More generally,  " str(yourmodel)   "   gives useful informations  .
R


Le 04/01/2012 12:56, Kevin Spring a ?crit :
> I am trying to extract the residual variance from the lmer function in the
> package lme4.
>
> For example, I have the following response from lmer:
>
> Random effects:
>>   Groups                  Name            Variance    Std.Dev.
>>   Cell.line:DNA.extract (Intercept)  0.130554    0.36132
>>   Residual                                    *0.018595*     0.13636
>
> I want to extract 0.018595 from this output.
>
> VarCorr allows me to extract the variance 0.130554, but I want to be able
> to extract the Residual variance and I don't see a function that does this
> in lme4.  Any ideas?
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Robert Espesser
CNRS UMR 6057 - Universit? de Provence
5 Avenue Pasteur
13100 AIX-EN-PROVENCE

Tel: +33 (0)413 55 36 26



From esnm2 at mnhn.fr  Wed Jan  4 17:35:31 2012
From: esnm2 at mnhn.fr (esnm2 at mnhn.fr)
Date: Wed, 04 Jan 2012 17:35:31 +0100
Subject: [R-sig-ME] Problems in using GEEs
Message-ID: <20120104173531.93322gdpsqaatntf@dsiwebmail.mnhn.fr>

Dear list

I?m puzzled with running GEEs with a small dataset. I use R 2.11.1
My data (a subset given below- ?muskerbis?) are seasonal abundances of  
two small vertebrate populations on two distinct sites (gui and coc)  
differing by habitat quality (for the animals) and collected over 10  
years (1999-2010, except 2 years ? 2004 and 2006) that I want to  
correlate with climatic variables. I suspect a serial correlation, and  
tried running a GLS with a corAR1 structure within the ?ile? group,  
but even with ranking the dependent variable (absmay ? summer animal  
abundances), i didn?t reached good distribution in residuals and  
homoskedasticity. The best I could get was using a GLM neg.bin  
approach ? but couldn?t include an AR1. I therefore tried GEEs poisson  
with rounded square rooted dependent variable and ?ile? as cluster  
using yags, geepack, and gee packages. The results are below:

> print(muskerbis)
enr	yr	ile	absmay	abssep	ps
1	1999	bgui	288	89	200.8
2	2000	bgui	157	1	133.6
3	2001	bgui	186	34	145.4
4	2002	bgui	102	9	83.4
5	2003	bgui	27	7	134.2
6	2005	bgui	52	6	129.2
7	2007	bgui	75	6	113.8
8	2008	bgui	272	19	254.6
9	2009	bgui	55	16	111.8
10	2010	bgui	104	7	171
11	1999	acoc	361	83	200.8
12	2000	acoc	173	117	133.6
13	2001	acoc	187	29	145.4
14	2002	acoc	292	48	83.4
15	2003	acoc	382	34	134.2
16	2005	acoc	313	138	129.2
17	2007	acoc	202	3	113.8
18	2008	acoc	312	14	254.6
19	2009	acoc	239	4	111.8
20	2010	acoc	211	58	171

cile=as.factor(ile)	##transform ? ile ? as a factor

Using GEEPACK:
guicocgeeglmsumps1=geeglm(as.integer(sqrt(absmay))~cile+ps+cile:ps,  
corstr="ar1", id=cile, family=poisson(link = "log"),
na.action=na.omit, data=muskerbis)
summary(guicocgeeglmsumps1)
Call:
geeglm(formula = as.integer(sqrt(absmay)) ~ cile + ps + cile:ps,
     family = poisson(link = "log"), data = muskerbis, na.action = na.omit,
     id = cile, corstr = "ar1")
Coefficients:
              Estimate   Std.err Wald Pr(>|W|)
(Intercept)  2.621597  0.000000  Inf   <2e-16 ***
cilebgui    -1.002342  0.000000  Inf   <2e-16 ***
ps           0.000935  0.000000  Inf   <2e-16 ***
cilebgui:ps  0.003796  0.000000  Inf   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
Estimated Scale Parameters:
             Estimate Std.err
(Intercept)    0.457   0.171
Correlation: Structure = ar1  Link = identity
Estimated Correlation Parameters:
       Estimate Std.err
alpha    0.235   0.093
Number of clusters:   2   Maximum cluster size: 10

Using YAGS:
guicocyagssumtps1<-yags(as.integer(sqrt(absmay))~cile+ps+cile:ps,  
corstr="ar1", cor.met=rank(yr), id=cile, family=poisson,
data=muskerbis, alphainit=0.)
guicocyagssumtps1
YAGS (yet another GEE solver) $Date: 2004/10/22 18:49:23 $
Call:
yags(formula = as.integer(sqrt(absmay)) ~ cile + ps + cile:ps,
     id = cile, cor.met = rank(yr), family = poisson, corstruct = "ar1",
     alphainit = 0, data = muskerbis)
Regression estimates:
                 est. naive s.e. naive z sand. s.e. sand. z
(Intercept)  2.60549    0.17431   14.95   1.90e-06 1369761
cilebgui    -0.97181    0.28518   -3.41   4.45e-06 -218230
ps           0.00104    0.00095    1.10   1.28e-08   81387
cilebgui:ps  0.00362    0.00146    2.47   2.36e-08  153630
Working correlation model: ar1
alpha est: 0.654
NULL
Pan QIC(R): -3365.819
QLS: 38.87
Rotnitzky-Jewell: 0, 0
yags/R: $Id: yags.R,v 1.5 2004/10/22 18:49:23 stvjc Exp $

Using GEE
guicocgeesumps1<-gee(as.integer(sqrt(absmay))~cile+ps+cile:ps,  
corstr="AR-M", Mv=1, id=cile, family=poisson(link = "log"),
na.action=na.omit, data=muskerbis)
summary(guicocgeesumps1)
GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA
  gee S-function, version 4.13 modified 98/01/27 (1998)
Model:
  Link:                      Logarithm
  Variance to Mean Relation: Poisson
  Correlation Structure:     AR-M , M = 1
Call:
gee(formula = as.integer(sqrt(absmay)) ~ cile + ps + cile:ps,
     id = cile, data = muskerbis, na.action = na.omit, family =  
poisson(link = "log"),
     corstr = "AR-M", Mv = 1)
Summary of Residuals:
    Min     1Q Median     3Q    Max
-4.562 -1.750 -0.649  2.364  3.422
Coefficients:
             Estimate Naive S.E. Naive z Robust S.E. Robust z
(Intercept)  2.60935    0.17772   14.68    9.27e-07  2816177
cilebgui    -0.98027    0.28867   -3.40    2.32e-06  -422088
ps           0.00102    0.00100    1.01    6.49e-09   156718
cilebgui:ps  0.00367    0.00154    2.38    1.31e-08   279242
Estimated Scale Parameter:  0.572
Number of Iterations:  3
Working Correlation
           [,1]     [,2]     [,3]    [,4]    [,5]    [,6]    [,7]      
[,8]     [,9]    [,10]
  [1,] 1.000000 0.369769 0.136729 0.05056 0.01869 0.00691 0.00256  
0.000945 0.000349 0.000129


I believe to have a good design of my model, as geepack ?tells? me I  
have 2 clusters with each 10 obs. residuals rather well behave, so for  
homoskedasticity (not shown). However, I don?t understand why it does  
not produce estimation of the se?s estimates and corresponding Wald  
statistics;
I also do not understand the differences in estimating alpha between  
all packages: 0.235 with geepack, 0.654 with yags, and 0.370 with gee  
??? also for the scale parameter given in gee (0.572) and yags (0.457)  
??
Moreover, although estimates are reliable between packages, it seems  
that na?ve z-values from yags and gee perform better than from  
robust-z ???
Finally, could also someone give me some advice on what to use for  
?fixed? effects selection ? more specifically how to compute a  
?working Wald test? or a ?na?ve likelihood ratio test? as proposed by  
on page 135 by Ballinger 2004 (Organizational Research Methods 2004 7:  
127-150 DOI: 10.1177/1094428104263672) ? as I may have such situation  
here (ie fewer covariates than obs per group ?)

Many thanks by advance for helping me (I?m at the limit of my  
knowledge in maths and informatics ?) and happy new year to everyone
ben



From stefanie.kuchinsky at gmail.com  Wed Jan  4 20:34:38 2012
From: stefanie.kuchinsky at gmail.com (Stefanie Kuchinsky)
Date: Wed, 4 Jan 2012 14:34:38 -0500
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
Message-ID: <CABhs0QY+c0LQkifK80D4W_JjumBWQ1WUmtCYYMrneV5AQpyBEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120104/6ca31548/attachment-0001.pl>

From kevinjspring at gmail.com  Thu Jan  5 00:22:23 2012
From: kevinjspring at gmail.com (Kevin Spring)
Date: Wed, 4 Jan 2012 17:22:23 -0600
Subject: [R-sig-ME] bootstrap variance component in a mixed linear model
Message-ID: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120104/7cc303fb/attachment-0001.pl>

From bbolker at gmail.com  Fri Jan  6 00:01:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 5 Jan 2012 23:01:22 +0000 (UTC)
Subject: [R-sig-ME] extracting values from lmer
References: <CAPv6FHgzdYBKsagM7Svy3zP+Q7T33LgSaS3BcUYenx6fS8Av-w@mail.gmail.com>
	<4F0449AA.7000102@lpl-aix.fr>
Message-ID: <loom.20120106T000059-115@post.gmane.org>

espesser <robert.espesser at ...> writes:

> 
>   Hi Kevin,
> Maybe there is a better way (a function) , but you can use:
> 
> yourmodel <at> deviance["sigmaREML"]
> 
> it returns the residual std. dev.   :  0.13636
> (in case of the default setting for lmer()  , i.e. REML=TRUE)
> More generally,  " str(yourmodel)   "   gives useful informations  .
> R
> 
> Le 04/01/2012 12:56, Kevin Spring a ?crit :
> > I am trying to extract the residual variance from the lmer function in the
> > package lme4.
> >
> > For example, I have the following response from lmer:
> >
> > Random effects:
> >>   Groups                  Name            Variance    Std.Dev.
> >>   Cell.line:DNA.extract (Intercept)  0.130554    0.36132
> >>   Residual                                    *0.018595*     0.13636
> >
> > I want to extract 0.018595 from this output.
> >
> > VarCorr allows me to extract the variance 0.130554, but I want to be able
> > to extract the Residual variance and I don't see a function that does this
> > in lme4.  Any ideas?


   You shouldn't have to work this hard to get it, but I would
suggest:

library(lme4)
example(lmer)  ## to get some examples to work with

attr(VarCorr(fm1),"sc")
[1] 25.59182

fm1 at deviance["sigmaREML"]
sigmaREML 
 25.59182 

both of these count a bit as digging into the internals
(which you're not supposed to do if you can help it, but
in this case you don't have a choice), but the former
is digging slightly less deep.

  Ben Bolker



From Alen.Hajnal at usm.edu  Fri Jan  6 01:22:22 2012
From: Alen.Hajnal at usm.edu (Alen Hajnal)
Date: Thu, 5 Jan 2012 18:22:22 -0600
Subject: [R-sig-ME] Tukey after lme does not match
Message-ID: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1111@CCRMBX01.usmexchange.loc>

Dear R users:
I have a simple lme model based on the following data:
sub	trial	angle	RMSy
1	1	30	3.745084
1	2	0	7.520667
1	3	90	11.17038
1	4	15	7.581526
1	5	60	11.17822
1	6	75	8.440891
1	7	45	13.19024
1	8	15	9.822035
1	9	60	6.002665
1	10	75	4.393961
1	11	0	7.436676

When I run the model the results show that 0vs45, 0vs60, 0vs75, and 0vs90 are all significant main effects:

> m.base01<-lme(RMSy ~ angle+trial, data=data,  random=~ trial|sub,method='ML')
> summary(m.base01)
Fixed effects: RMSy ~ angle + trial 
                	Value 	Std.Error  	DF     t-value     p-value
(Intercept)  5.236020 	0.6312637 	267  8.294505  0.0000
angle15     -0.687669 	0.4140277 	267 -1.660925  0.0979
angle30     -0.571092 	0.4129365 	267 -1.383001  0.1678
angle45     -0.984597 	0.4139330 	267 -2.378638  0.0181
angle60     -0.874718 	0.4135615 	267 -2.115085  0.0353
angle75     -1.389835 	0.4113411 	267 -3.378788  0.0008
angle90     -1.620493 	0.4133209 	267 -3.920666  0.0001
trial       -0.009372 	0.0299782 	267 -0.312620  0.7548

However, when I try to run a Tukey posthoc test, I get different results (notice that the estimates are the same as the main effect values above): ONLY 0vs90 is significant at p<.05 :

> summary(glht(m.base01, linfct=mcp(angle = "Tukey")))

         Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lme.formula(fixed = RMSy ~ angle + trial, data = data, random = ~trial | 
    sub, method = "ML")

Linear Hypotheses:
             Estimate Std. Error z value Pr(>|z|)   
15 - 0 == 0   -0.6877     0.4082  -1.684  0.62652   
30 - 0 == 0   -0.5711     0.4072  -1.403  0.80077   
45 - 0 == 0   -0.9846     0.4081  -2.412  0.19329   
60 - 0 == 0   -0.8747     0.4078  -2.145  0.32592   
75 - 0 == 0   -1.3898     0.4056  -3.427  0.01070 * 
90 - 0 == 0   -1.6205     0.4075  -3.976  0.00138 **
30 - 15 == 0   0.1166     0.4079   0.286  0.99996   
45 - 15 == 0  -0.2969     0.4078  -0.728  0.99090   
60 - 15 == 0  -0.1870     0.4078  -0.459  0.99931   
75 - 15 == 0  -0.7022     0.4050  -1.734  0.59342   
90 - 15 == 0  -0.9328     0.4073  -2.290  0.24842   
45 - 30 == 0  -0.4135     0.4082  -1.013  0.95124   
60 - 30 == 0  -0.3036     0.4074  -0.745  0.98971   
75 - 30 == 0  -0.8187     0.4052  -2.021  0.40123   
90 - 30 == 0  -1.0494     0.4076  -2.574  0.13377   
60 - 45 == 0   0.1099     0.4077   0.269  0.99997   
75 - 45 == 0  -0.4052     0.4059  -0.998  0.95449   
90 - 45 == 0  -0.6359     0.4078  -1.559  0.70835   
75 - 60 == 0  -0.5151     0.4050  -1.272  0.86496   
90 - 60 == 0  -0.7458     0.4074  -1.831  0.52730   
90 - 75 == 0  -0.2307     0.4049  -0.570  0.99763  

Why does the Tukey not match the lme results?
Any help would be much appreciated!
Thanks, Alen




----------
Alen Hajnal, PhD.
Department of Psychology
The University of Southern Mississippi
118 College Drive #5025
Hattiesburg, MS 39406
USA
Tel. +1 (601) 266-4617
alen.hajnal @ usm.edu
http://ocean.otr.usm.edu/~w785427/lab.html


From Alen.Hajnal at usm.edu  Fri Jan  6 01:28:59 2012
From: Alen.Hajnal at usm.edu (Alen Hajnal)
Date: Thu, 5 Jan 2012 18:28:59 -0600
Subject: [R-sig-ME] (SMALL CORRECTION): Tukey after lme does not match
Message-ID: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1112@CCRMBX01.usmexchange.loc>

Actually 0vs75 is also significant according to Tukey, but there is still no perfect match with the initial lme analysis.


----------
Alen Hajnal, PhD.
Department of Psychology
The University of Southern Mississippi
118 College Drive #5025
Hattiesburg, MS 39406
USA
Tel. +1 (601) 266-4617
alen.hajnal @ usm.edu
http://ocean.otr.usm.edu/~w785427/lab.html


From A.Robinson at ms.unimelb.edu.au  Fri Jan  6 01:54:42 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 6 Jan 2012 11:54:42 +1100
Subject: [R-sig-ME] (SMALL CORRECTION): Tukey after lme does not match
In-Reply-To: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1112@CCRMBX01.usmexchange.loc>
References: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1112@CCRMBX01.usmexchange.loc>
Message-ID: <CAHyGmd6L6L-+ug5FdmiPQPH4qi7GKh-xMbfOkWOBuGO181pb7A@mail.gmail.com>

Dear Alen,

I suggest that it might be useful for you to do some background
reading on the purposes and interpretations of Wald tests (which are
the tests that you are interpreting directly from lme) and
Tukey-corrected tests (from the Tukey output).

But, very briefly, it would be very surprising if the two were to
agree.  The Wald tests p-values are computed for each test as though
it were the only one under consideration, whereas the Tukey p-values
are computed taking account of the inference of the other tests.  So,
the more comparisons being performed at the same time (here, 6 + 5 + 4
+ 3 + 2 + 1 = 21), the more conservative Tukey will be, whereas the
Wald test will not change.

I hope that this helps --- but I reiterate my recommendation for
background reading.

Andrew

On Fri, Jan 6, 2012 at 11:28 AM, Alen Hajnal <Alen.Hajnal at usm.edu> wrote:
> Actually 0vs75 is also significant according to Tukey, but there is still no perfect match with the initial lme analysis.
>
>
> ----------
> Alen Hajnal, PhD.
> Department of Psychology
> The University of Southern Mississippi
> 118 College Drive #5025
> Hattiesburg, MS 39406
> USA
> Tel. +1 (601) 266-4617
> alen.hajnal @ usm.edu
> http://ocean.otr.usm.edu/~w785427/lab.html
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Andrew Robinson
Deputy Director, ACERA
Senior Lecturer in Applied Statistics??????????? ? ? ? ? ? Tel: +61-3-8344-6410
Department of Mathematics and Statistics??????????? Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au??? Website: http://www.ms.unimelb.edu.au

FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/



From djmuser at gmail.com  Fri Jan  6 05:36:41 2012
From: djmuser at gmail.com (Dennis Murphy)
Date: Thu, 5 Jan 2012 20:36:41 -0800
Subject: [R-sig-ME] Tukey after lme does not match
In-Reply-To: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1111@CCRMBX01.usmexchange.loc>
References: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1111@CCRMBX01.usmexchange.loc>
Message-ID: <CADv2QyF0TYAR9=D2__cXDcWuxYDapE+m6pzqMP4rw2-9A72AkQ@mail.gmail.com>

Hi:

In addition to Dr. Robinson's comments, I would add the following:

(i) Your model specification indicates that you want random slopes for
trial by subject with correlated intercepts. Is that what you
intended?
(ii) I'm wondering why you're not treating angle as a continuous
variable and looking for potential trends in the response as a
function of angle. If you have a discernable trend, its form would be
more useful than a collection of multiple comparisons. Did you plot
the response by subject and angle (either a conditioning plot by
subject or a 'spaghetti plot' of individual profiles of (angle, RMSy)
pairs)?

My 2c,
Dennis

On Thu, Jan 5, 2012 at 4:22 PM, Alen Hajnal <Alen.Hajnal at usm.edu> wrote:
> Dear R users:
> I have a simple lme model based on the following data:
> sub ? ? trial ? angle ? RMSy
> 1 ? ? ? 1 ? ? ? 30 ? ? ?3.745084
> 1 ? ? ? 2 ? ? ? 0 ? ? ? 7.520667
> 1 ? ? ? 3 ? ? ? 90 ? ? ?11.17038
> 1 ? ? ? 4 ? ? ? 15 ? ? ?7.581526
> 1 ? ? ? 5 ? ? ? 60 ? ? ?11.17822
> 1 ? ? ? 6 ? ? ? 75 ? ? ?8.440891
> 1 ? ? ? 7 ? ? ? 45 ? ? ?13.19024
> 1 ? ? ? 8 ? ? ? 15 ? ? ?9.822035
> 1 ? ? ? 9 ? ? ? 60 ? ? ?6.002665
> 1 ? ? ? 10 ? ? ?75 ? ? ?4.393961
> 1 ? ? ? 11 ? ? ?0 ? ? ? 7.436676
>
> When I run the model the results show that 0vs45, 0vs60, 0vs75, and 0vs90 are all significant main effects:
>
>> m.base01<-lme(RMSy ~ angle+trial, data=data, ?random=~ trial|sub,method='ML')
>> summary(m.base01)
> Fixed effects: RMSy ~ angle + trial
> ? ? ? ? ? ? ? ? ? ? ? ?Value ? Std.Error ? ? ? DF ? ? t-value ? ? p-value
> (Intercept) ?5.236020 ? 0.6312637 ? ? ? 267 8.294505 ?0.0000
> angle15 ? ? -0.687669 ? 0.4140277 ? ? ? 267 -1.660925 ?0.0979
> angle30 ? ? -0.571092 ? 0.4129365 ? ? ? 267 -1.383001 ?0.1678
> angle45 ? ? -0.984597 ? 0.4139330 ? ? ? 267 -2.378638 ?0.0181
> angle60 ? ? -0.874718 ? 0.4135615 ? ? ? 267 -2.115085 ?0.0353
> angle75 ? ? -1.389835 ? 0.4113411 ? ? ? 267 -3.378788 ?0.0008
> angle90 ? ? -1.620493 ? 0.4133209 ? ? ? 267 -3.920666 ?0.0001
> trial ? ? ? -0.009372 ? 0.0299782 ? ? ? 267 -0.312620 ?0.7548
>
> However, when I try to run a Tukey posthoc test, I get different results (notice that the estimates are the same as the main effect values above): ONLY 0vs90 is significant at p<.05 :
>
>> summary(glht(m.base01, linfct=mcp(angle = "Tukey")))
>
> ? ? ? ? Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: lme.formula(fixed = RMSy ~ angle + trial, data = data, random = ~trial |
> ? ?sub, method = "ML")
>
> Linear Hypotheses:
> ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> 15 - 0 == 0 ? -0.6877 ? ? 0.4082 ?-1.684 ?0.62652
> 30 - 0 == 0 ? -0.5711 ? ? 0.4072 ?-1.403 ?0.80077
> 45 - 0 == 0 ? -0.9846 ? ? 0.4081 ?-2.412 ?0.19329
> 60 - 0 == 0 ? -0.8747 ? ? 0.4078 ?-2.145 ?0.32592
> 75 - 0 == 0 ? -1.3898 ? ? 0.4056 ?-3.427 ?0.01070 *
> 90 - 0 == 0 ? -1.6205 ? ? 0.4075 ?-3.976 ?0.00138 **
> 30 - 15 == 0 ? 0.1166 ? ? 0.4079 ? 0.286 ?0.99996
> 45 - 15 == 0 ?-0.2969 ? ? 0.4078 ?-0.728 ?0.99090
> 60 - 15 == 0 ?-0.1870 ? ? 0.4078 ?-0.459 ?0.99931
> 75 - 15 == 0 ?-0.7022 ? ? 0.4050 ?-1.734 ?0.59342
> 90 - 15 == 0 ?-0.9328 ? ? 0.4073 ?-2.290 ?0.24842
> 45 - 30 == 0 ?-0.4135 ? ? 0.4082 ?-1.013 ?0.95124
> 60 - 30 == 0 ?-0.3036 ? ? 0.4074 ?-0.745 ?0.98971
> 75 - 30 == 0 ?-0.8187 ? ? 0.4052 ?-2.021 ?0.40123
> 90 - 30 == 0 ?-1.0494 ? ? 0.4076 ?-2.574 ?0.13377
> 60 - 45 == 0 ? 0.1099 ? ? 0.4077 ? 0.269 ?0.99997
> 75 - 45 == 0 ?-0.4052 ? ? 0.4059 ?-0.998 ?0.95449
> 90 - 45 == 0 ?-0.6359 ? ? 0.4078 ?-1.559 ?0.70835
> 75 - 60 == 0 ?-0.5151 ? ? 0.4050 ?-1.272 ?0.86496
> 90 - 60 == 0 ?-0.7458 ? ? 0.4074 ?-1.831 ?0.52730
> 90 - 75 == 0 ?-0.2307 ? ? 0.4049 ?-0.570 ?0.99763
>
> Why does the Tukey not match the lme results?
> Any help would be much appreciated!
> Thanks, Alen
>
>
>
>
> ----------
> Alen Hajnal, PhD.
> Department of Psychology
> The University of Southern Mississippi
> 118 College Drive #5025
> Hattiesburg, MS 39406
> USA
> Tel. +1 (601) 266-4617
> alen.hajnal @ usm.edu
> http://ocean.otr.usm.edu/~w785427/lab.html
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From sorenh at math.aau.dk  Thu Jan  5 13:27:41 2012
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Thu, 5 Jan 2012 12:27:41 +0000
Subject: [R-sig-ME] bootstrap variance component in a mixed linear model
In-Reply-To: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>
References: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3F75B6D@AD-EXCHMBX2-1.aau.dk>

Hi Kevin,

In the pbkrtest package there is function PBmodcomp for calculating p-values using parametric bootstrap and in the implementation of this function I have also observed the same phenomenon. I guess that what happens is simply that some of the bootstrap samples lead to "singularities" somewhere in the estimation algorithms. My solution in PBmodcomp has been to use the suppressWarnings() function...

Cheers
S?ren
 

-----Oprindelig meddelelse-----
Fra: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] P? vegne af Kevin Spring
Sendt: 5. januar 2012 00:22
Til: r-sig-mixed-models at r-project.org
Emne: [R-sig-ME] bootstrap variance component in a mixed linear model

Hi, everyone.  I don't know what is going wrong with my bootstrap.  Could anyone help me find out what is wrong?

I am trying to bootstrap the variance component in a mixed linear model.

My statistic for the bootstrap is the following:

varcomp <- function ( formula, data, indices ) {
>     d <- data[indices,] #sample for boot
>     fit <- lmer(formula, data=d) #linear model
>     return (attr (VarCorr(fit), "sc")^2) #output random effects 
> residual var }


The formula for the model is: log( y ) ~ ( 1 | a:b ) + a, where '*b*' is a
random effect nested within '*a';* which is a fixed effect.

When I run the linear model on its own it works fine, but when I try to run
the bootstrap I get warning messages of false convergence.

Warning messages:
> 1: In mer_finalize(ans) : false convergence (8)
> 2: In mer_finalize(ans) : false convergence (8)
> 3: In mer_finalize(ans) : false convergence (8)
> 4: In mer_finalize(ans) : false convergence (8)
> 5: In mer_finalize(ans) : false convergence (8)
> 6: In mer_finalize(ans) : false convergence (8)


The example data I used can be downloaded at:
http://www.mediafire.com/?77xb24rmul90k5d

The R code I actually did:

library(boot)
library(lme4)
#
#Load data
#
fp1 <- read.csv("desktop/p1f.csv")
#Set as factors
fp1$Cell.line <- as.factor(fp1$Cell.line)
fp1$DNA.extract <- as.factor(fp1$DNA.extract)
#test mixed model
lm1 <- lmer(formula=log(CNPC)~(1|Cell.line:DNA.extract)+Cell.line,data=fp1)
attr (VarCorr(lm1), "sc")
#
##Bootstrap statistic
#
varcomp <- function ( formula, data, indices ) {
    d <- data[indices,] #sample for boot
    fit <- lmer(formula, data=d) #linear model
    return (attr (VarCorr(fit), "sc")) #output random effects residual
standard deviation
}
##Bootstrap with 1000 replicates
fp1.boot <- boot ( data = fp1, statistic=varcomp, R=1000,
formula=log(CNPC)~(1|Cell.line:DNA.extract)+Cell.line)

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From geralttee at gmail.com  Fri Jan  6 19:08:28 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Fri, 6 Jan 2012 19:08:28 +0100
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
Message-ID: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/53f952ee/attachment-0001.pl>

From bbolker at gmail.com  Fri Jan  6 19:40:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Jan 2012 18:40:28 +0000 (UTC)
Subject: [R-sig-ME] covariance structures for longitudinal models
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
	<CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>
	<CAHawB9utWpzVSgTBz82M1O4ss5Th+NvZtt4bLCJGe581uitHPA@mail.gmail.com>
Message-ID: <loom.20120106T191953-19@post.gmane.org>

Antonio P. Ramos <ramos.grad.student at ...> writes:

> 
> Thanks for your replies. To complement my own question: would  MCMCglmm do
> the job?

  I don't think so, because your models all seem to be expressed in
terms of R-side correlation, and MCMCglmm (although quite a bit more
flexible than lmer) does not seem to be as flexible as lme (or GLIMMIX/
NLMIXED) in specifying R-side correlations.  There aren't a huge
number of examples of the use of the 'rcov' argument in the MCMCglmm
course notes, but the examples there are show things like

  rcov=~us(trait):units 

  this is for a multi-response model, so the residual variance is
modeled within units, with 'us' (unstructured) and different variances
for each trait (so, e.g. ~us(time):units should fit an unstructured
correlation model)

  rcov=~idh(trait):units allows different variances by trait but
enforces independence

  The only other option that makes sense here is ~idv (equal variances)
which basically reduces to unstructured residuals.

    I started working on a 'corClass' definition that follows
the antecedent model you requested (and, if it worked, could serve
as a model for implementing other possibilities, such as the
anisotropic spatial correlation models people have asked about
previously on the list).  It's not quite working -- I still
have some confusions about when transformed vs untransformed
(or in lme's terminology "unconstrained" vs "constrained"
parameters are used -- but it's a start, and in case I don't
get around to doing anything further with it I thought I
would make it available at 
<http://www.math.mcmaster.ca/bolker/R/misc/newcorstruct.R>

> 
> On Mon, Jan 2, 2012 at 8:13 AM, Joshua Wiley <jwiley.psych at ...> wrote:
> 
> > Hi Antonio,
> >
> > I am not familiar with antedependence models so no comment there.
> >
> > For factor analysis and that genre, I like OpenMx (also see sem and
> > lavaan).  One thing I like about OpenMx is while it caters to SEM, it
> > is a general purpose matrix optimizer, and it really is not difficult
> > to access that power.  So in principal, you can have whatever matrices
> > you want, roll your own objective function, and away it'll go.
> >
> > For BUGS you have a lot of options including: R2OpenBUGS and R2WinBUGS
> > among others.
> >
> > Cheers,
> >
> > Josh
> >
> > On Mon, Jan 2, 2012 at 12:41 AM, Antonio P. Ramos
> > <ramos.grad.student at ...> wrote:
> > > Hi all,
> > >
> > > I've trying to use R to fit some longitudinal models, mostly via lme and
> > > nlme packages. However, it seems that many standard models are lacking,
> > > such as antedependence models or factor analytic models for covariance
> > > matrices. These models are readily available in SAS. Does an recommend
> > > other packages for the job in R? I don't really care if I am in
> > frequentist
> > > or bayesian world as long as I have more modeling flexibility. I would
> > also
> > > be interested in doing that in WINBUGS/JAGS.
> > >
> > > All the best,
> > >
> > > Antonio.
> > >
> > >        [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at ... mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> > --
> > Joshua Wiley
> > Ph.D. Student, Health Psychology
> > Programmer Analyst II, Statistical Consulting Group
> > University of California, Los Angeles
> > https://joshuawiley.com/
> >
> 
> 	[[alternative HTML version deleted]]
> 
>



From m.lee.davis at gmail.com  Fri Jan  6 19:54:01 2012
From: m.lee.davis at gmail.com (Lee Davis)
Date: Fri, 6 Jan 2012 13:54:01 -0500
Subject: [R-sig-ME] Correlated count data technique advice
Message-ID: <CAPiP9jVXdjnMT-+ipPArd8yZ_zpmhy5dden6hZU7gYOXyrdZpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/e9a18c65/attachment-0001.pl>

From stefanie.kuchinsky at gmail.com  Fri Jan  6 19:55:44 2012
From: stefanie.kuchinsky at gmail.com (Stefanie Kuchinsky)
Date: Fri, 6 Jan 2012 13:55:44 -0500
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
In-Reply-To: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>
References: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>
Message-ID: <CABhs0QZ7x0AGBtqJ-QmoCoV=xZPgRd5kSi3nJY=9aCukuwF6=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/64f5b1cd/attachment-0001.pl>

From stefanie.kuchinsky at gmail.com  Fri Jan  6 20:40:34 2012
From: stefanie.kuchinsky at gmail.com (Stefanie Kuchinsky)
Date: Fri, 6 Jan 2012 14:40:34 -0500
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
In-Reply-To: <CABhs0QZ7x0AGBtqJ-QmoCoV=xZPgRd5kSi3nJY=9aCukuwF6=Q@mail.gmail.com>
References: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>
	<CABhs0QZ7x0AGBtqJ-QmoCoV=xZPgRd5kSi3nJY=9aCukuwF6=Q@mail.gmail.com>
Message-ID: <CABhs0QYvR4yQ87GhozjDAc5ZW6eXbWEEU+PH4-1WMU1r4pf3jg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/b741879d/attachment-0001.pl>

From geralttee at gmail.com  Fri Jan  6 21:05:38 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Fri, 6 Jan 2012 21:05:38 +0100
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
In-Reply-To: <CABhs0QYvR4yQ87GhozjDAc5ZW6eXbWEEU+PH4-1WMU1r4pf3jg@mail.gmail.com>
References: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>
	<CABhs0QZ7x0AGBtqJ-QmoCoV=xZPgRd5kSi3nJY=9aCukuwF6=Q@mail.gmail.com>
	<CABhs0QYvR4yQ87GhozjDAc5ZW6eXbWEEU+PH4-1WMU1r4pf3jg@mail.gmail.com>
Message-ID: <CANXb-o6-Wwv9eaGq1ofGxPyODtKFQpLayJJpCVOzBF_QSk6=aw@mail.gmail.com>

Hi again,

you're right. usually when terms are missing in our output - it means
the're not identifiable from our data (e.g. there's not enough
replication or specific combinations of factors are missing) - that's
why your'e getting some interactions tested after removing some other
terms. As for which terms to include - my conservative way of doing
things is to include lower terms always when I want to have higher
terms. What happens when you remove the triple interactions? Also I
wouldn;t say that interpretation of continous:categorical interactions
?should be avoided in cases similar to yours: such interactions
quantify differences in betas at respective levels of the categorical
variable and provide useful valuable insight to how your response
changes with the covariate. What however should be avoided (or better
said - applied with caution) is drawing conclusions about categorical
variables (i.e. A or B in your model) if the're involved in
significant interactions with continous variables (problem similar to
heterogenous slopes in classical ANCOVA).

Cheers,
sz.

On 6 January 2012 20:40, Stefanie Kuchinsky
<stefanie.kuchinsky at gmail.com> wrote:
>
> I just realized a probable explanation.
>
> For the time3 term for which it only displayed half of the interaction term, the lower order time3:A and time3:B had been included in the model.
>
> However, there was no time4:A in the model (though there was time4:B). When I removed this effect, I now get both parts of the interaction term output [and the F test df are now correct (2, 9294) instead of (1, 9294)]. I assume that this means the higher order terms are redundant with the lower order terms in the model.
>
> Is it then appropriate to remove the lower order interactions from the model (even though they appear significant when I run anova() and given their betas)? I believe I should not be theoretically interpreting time3:A when there is a time3:A:B interaction, anyway.
>
> So, I would interpret the betas for these terms very generally:
> time3:A1:B0 -- The effect of the cubic polynomial modulated by A (1 > 0) when B is held constant at 0.
> time3:A1:B1 -- The effect of the cubic polynomial as modulated by A (1>0) when B is held constant at 1.
>
> Thanks again for your input-- I wouldn't have thought of this is you hadn't mentioned looking at the lower order terms.
>
>
>
> On Fri, Jan 6, 2012 at 1:55 PM, Stefanie Kuchinsky <stefanie.kuchinsky at gmail.com> wrote:
>>
>> Thanks so much for your response. I had not included some of the output table to save space in the original email, but the model does include the lower order terms. I've pasted the full table at the bottom of this email. The polynomial terms were indeed created with the poly() function.
>>
>> You were exactly right about the continuous vs. factor error in my second dataset. I had a typo in my code and so B had never been converted to a factor. I really appreciate you catching that!
>>
>> However, I'm still confused about the interpretation of time4:A1:B1-- specifically why there is no beta for time4:A1:B0 when there is both a beta for time3:A1:B1 and time3:A1:B0?
>>
>>
>> Again, snippet of dataset 1 output:
>>
>> time3:A1:B1?? -68.6999? 33.14614 9294? -2.07264? 0.0382
>> time4:A1:B0?? 132.5765? 23.43786 9294?? 5.65651? 0.0000
>> time4:A1:B1? -124.2845? 23.43786 9294? -5.30272? 0.0000
>>
>> Corrected output for dataset 2:
>> time3:A1:B1?? 135.0679?? 46.2636 9294?? 2.91953? 0.0035
>> time4:A1:B0??? 80.8813?? 32.7133 9294?? 2.47243? 0.0134
>> time4:A1:B1? -108.9340?? 32.7133 9294? -3.32996? 0.0009
>>
>>
>> Full table for dataset 1(minus the correlation tables):
>>
>> > summary(m.int4e)
>> Linear mixed-effects model fit by maximum likelihood
>> ?Data: Data
>> ?????? AIC????? BIC??? logLik
>> ? 109842.6 110837.5 -54782.28
>>
>> Random effects:
>> ?Formula: ~time1 | subjAB
>> ?Structure: General positive-definite, Log-Cholesky parametrization
>> ??????????? StdDev??? Corr
>> (Intercept)? 38.33670 (Intr)
>> time1???????? 434.94747 0.488
>> Residual???? 75.40533
>>
>> Fixed effects: pupil1000 ~ time1 + time2 + time3 + time4 + time5 + subj + subj:time1 + subj:time2 +????? subj:time3 + subj:time4 + subj:time5 + A:time1 + A:time2 + A:time3 +????? A:time5 + B:time3 + B:time4 + A:B:time3 + A:B:time4
>> ?????????????????????? Value Std.Error?? DF?? t-value p-value
>> (Intercept)???????? 976.6327? 19.63384 9294? 49.74231? 0.0000
>> time1???????????????? 891.8779 226.37671 9294?? 3.93980? 0.0001
>> time2??????????????? -917.0701? 38.86729 9294 -23.59491? 0.0000
>> time3??????????????? -131.3754? 40.59556 9294? -3.23620? 0.0012
>> time4???????????????? 459.9003? 40.59556 9294? 11.32883? 0.0000
>> time5??????????????? -444.2458? 38.86729 9294 -11.42981? 0.0000
>> subj2??????????????? 47.7965? 27.76645?? 63?? 1.72137? 0.0901
>> subj3??????????????? 65.4712? 27.76645?? 63?? 2.35793? 0.0215
>> subj4?????????????? 130.2721? 27.76645?? 63?? 4.69171? 0.0000
>> subj5??????????????? 57.2987? 27.76645?? 63?? 2.06359? 0.0432
>> subj6??????????????? 25.6571? 27.76645?? 63?? 0.92403? 0.3590
>> subj7??????????????? -7.6969? 27.76645?? 63? -0.27720? 0.7825
>> subj8??????????????? 81.3031? 27.76645?? 63?? 2.92811? 0.0047
>> subj9??????????????? 15.1726? 27.76645?? 63?? 0.54644? 0.5867
>> subj10?????????????? 62.5996? 27.76645?? 63?? 2.25450? 0.0276
>> subj11????????????? -64.4270? 27.76645?? 63? -2.32032? 0.0236
>> subj12?????????????? 10.0465? 27.76645?? 63?? 0.36182? 0.7187
>> subj13?????????????? 43.7500? 27.76645?? 63?? 1.57564? 0.1201
>> subj14?????????????? 26.4845? 27.76645?? 63?? 0.95383? 0.3438
>> subj15????????????? -46.7323? 27.76645?? 63? -1.68305? 0.0973
>> subj16????????????? 137.6261? 27.76645?? 63?? 4.95656? 0.0000
>> subj17?????????????? 14.9735? 27.76645?? 63?? 0.53926? 0.5916
>> subj18?????????????? 26.3230? 27.76645?? 63?? 0.94802? 0.3467
>> subj19?????????????? 55.4912? 27.76645?? 63?? 1.99850? 0.0500
>> subj20?????????????? 98.4027? 27.76645?? 63?? 3.54394? 0.0007
>> subj21????????????? 162.8186? 27.76645?? 63?? 5.86386? 0.0000
>> time1:subj2????????? -848.2627 314.38569 9294? -2.69816? 0.0070
>> time1:subj3????????? -462.8857 314.38569 9294? -1.47235? 0.1410
>> time1:subj4????????? -286.9459 314.38569 9294? -0.91272? 0.3614
>> time1:subj5????????? -350.9655 314.38569 9294? -1.11635? 0.2643
>> time1:subj6???????? -1079.1256 314.38569 9294? -3.43249? 0.0006
>> time1:subj7????????? -958.1396 314.38569 9294? -3.04766? 0.0023
>> time1:subj8?????????? 396.6793 314.38569 9294?? 1.26176? 0.2071
>> time1:subj9?????????? 870.7418 314.38569 9294?? 2.76966? 0.0056
>> time1:subj10???????? 2433.2401 314.38569 9294?? 7.73967? 0.0000
>> time1:subj11????????? 518.0574 314.38569 9294?? 1.64784? 0.0994
>> time1:subj12???????? -544.9605 314.38569 9294? -1.73341? 0.0831
>> time1:subj13???????? -142.6669 314.38569 9294? -0.45380? 0.6500
>> time1:subj14???????? -447.2835 314.38569 9294? -1.42272? 0.1549
>> time1:subj15?????????? 73.0371 314.38569 9294?? 0.23232? 0.8163
>> time1:subj16???????? -147.8436 314.38569 9294? -0.47026? 0.6382
>> time1:subj17???????? -321.5527 314.38569 9294? -1.02280? 0.3064
>> time1:subj18??????? -1104.0885 314.38569 9294? -3.51189? 0.0004
>> time1:subj19???????? -500.0802 314.38569 9294? -1.59066? 0.1117
>> time1:subj20?????????? 73.0061 314.38569 9294?? 0.23222? 0.8164
>> time1:subj21???????? -977.4932 314.38569 9294? -3.10922? 0.0019
>> time2:subj2?????????? 103.9564? 53.70288 9294?? 1.93577? 0.0529
>> time2:subj3?????????? 462.7823? 53.70288 9294?? 8.61746? 0.0000
>> time2:subj4?????????? 133.1718? 53.70288 9294?? 2.47979? 0.0132
>> time2:subj5?????????? 435.4522? 53.70288 9294?? 8.10854? 0.0000
>> time2:subj6?????????? 866.3608? 53.70288 9294? 16.13248? 0.0000
>> time2:subj7????????? 1040.2131? 53.70288 9294? 19.36978? 0.0000
>> time2:subj8?????????? -48.0412? 53.70288 9294? -0.89457? 0.3710
>> time2:subj9?????????? -33.9246? 53.70288 9294? -0.63171? 0.5276
>> time2:subj10????????? 575.5907? 53.70288 9294? 10.71806? 0.0000
>> time2:subj11???????? -534.9280? 53.70288 9294? -9.96088? 0.0000
>> time2:subj12????????? 180.5477? 53.70288 9294?? 3.36197? 0.0008
>> time2:subj13???????? -919.1235? 53.70288 9294 -17.11498? 0.0000
>> time2:subj14????????? 585.8640? 53.70288 9294? 10.90936? 0.0000
>> time2:subj15????????? 405.6596? 53.70288 9294?? 7.55378? 0.0000
>> time2:subj16??????? -1104.0865? 53.70288 9294 -20.55917? 0.0000
>> time2:subj17????????? 877.9724? 53.70288 9294? 16.34870? 0.0000
>> time2:subj18???????? 1828.7923? 53.70288 9294? 34.05389? 0.0000
>> time2:subj19????????? 820.0829? 53.70288 9294? 15.27074? 0.0000
>> time2:subj20?????????? 44.1932? 53.70288 9294?? 0.82292? 0.4106
>> time2:subj21????????? 845.2039? 53.70288 9294? 15.73852? 0.0000
>> time3:subj2?????????? 658.7997? 53.70288 9294? 12.26749? 0.0000
>> time3:subj3??????????? 30.3625? 53.70288 9294?? 0.56538? 0.5718
>> time3:subj4?????????? 595.8939? 53.70288 9294? 11.09612? 0.0000
>> time3:subj5?????????? 243.5716? 53.70288 9294?? 4.53554? 0.0000
>> time3:subj6?????????? 350.5870? 53.70288 9294?? 6.52827? 0.0000
>> time3:subj7??????????? 62.7208? 53.70288 9294?? 1.16792? 0.2429
>> time3:subj8?????????? 187.1384? 53.70288 9294?? 3.48470? 0.0005
>> time3:subj9????????? -745.5636? 53.70288 9294 -13.88312? 0.0000
>> time3:subj10???????? -937.4916? 53.70288 9294 -17.45701? 0.0000
>> time3:subj11????????? 349.5809? 53.70288 9294?? 6.50954? 0.0000
>> time3:subj12???????? -419.0377? 53.70288 9294? -7.80289? 0.0000
>> time3:subj13????????? 812.8245? 53.70288 9294? 15.13558? 0.0000
>> time3:subj14????????? 179.8396? 53.70288 9294?? 3.34879? 0.0008
>> time3:subj15???????? -150.8652? 53.70288 9294? -2.80926? 0.0050
>> time3:subj16???????? 1267.6097? 53.70288 9294? 23.60413? 0.0000
>> time3:subj17????????? 223.1138? 53.70288 9294?? 4.15460? 0.0000
>> time3:subj18?????????? 83.5245? 53.70288 9294?? 1.55531? 0.1199
>> time3:subj19???????? 1295.0211? 53.70288 9294? 24.11455? 0.0000
>> time3:subj20????????? 599.0144? 53.70288 9294? 11.15423? 0.0000
>> time3:subj21????????? 142.3725? 53.70288 9294?? 2.65111? 0.0080
>> time4:subj2????????? -357.4785? 53.70288 9294? -6.65660? 0.0000
>> time4:subj3????????? -343.2897? 53.70288 9294? -6.39239? 0.0000
>> time4:subj4????????? -705.7852? 53.70288 9294 -13.14241? 0.0000
>> time4:subj5????????? -445.1367? 53.70288 9294? -8.28888? 0.0000
>> time4:subj6????????? -602.6113? 53.70288 9294 -11.22121? 0.0000
>> time4:subj7????????? -421.4880? 53.70288 9294? -7.84852? 0.0000
>> time4:subj8??????????? 30.3527? 53.70288 9294?? 0.56520? 0.5720
>> time4:subj9?????????? 563.3041? 53.70288 9294? 10.48927? 0.0000
>> time4:subj10???????? -206.4712? 53.70288 9294? -3.84470? 0.0001
>> time4:subj11????????? 515.5052? 53.70288 9294?? 9.59921? 0.0000
>> time4:subj12????????? 184.6193? 53.70288 9294?? 3.43779? 0.0006
>> time4:subj13????????? 293.2901? 53.70288 9294?? 5.46135? 0.0000
>> time4:subj14???????? -478.9555? 53.70288 9294? -8.91862? 0.0000
>> time4:subj15???????? -240.5382? 53.70288 9294? -4.47906? 0.0000
>> time4:subj16???????? -975.5266? 53.70288 9294 -18.16526? 0.0000
>> time4:subj17???????? -403.4663? 53.70288 9294? -7.51294? 0.0000
>> time4:subj18???????? -876.2704? 53.70288 9294 -16.31701? 0.0000
>> time4:subj19??????? -1979.2893? 53.70288 9294 -36.85629? 0.0000
>> time4:subj20???????? -534.4526? 53.70288 9294? -9.95203? 0.0000
>> time4:subj21???????? -448.4306? 53.70288 9294? -8.35022? 0.0000
>> time5:subj2?????????? -10.8598? 53.70288 9294? -0.20222? 0.8397
>> time5:subj3?????????? 356.3984? 53.70288 9294?? 6.63649? 0.0000
>> time5:subj4?????????? 321.0171? 53.70288 9294?? 5.97765? 0.0000
>> time5:subj5?????????? 159.0899? 53.70288 9294?? 2.96241? 0.0031
>> time5:subj6?????????? 277.8362? 53.70288 9294?? 5.17358? 0.0000
>> time5:subj7?????????? 392.0390? 53.70288 9294?? 7.30015? 0.0000
>> time5:subj8??????????? 76.0262? 53.70288 9294?? 1.41568? 0.1569
>> time5:subj9?????????? 675.6410? 53.70288 9294? 12.58109? 0.0000
>> time5:subj10????????? 739.3099? 53.70288 9294? 13.76667? 0.0000
>> time5:subj11???????? -218.8505? 53.70288 9294? -4.07521? 0.0000
>> time5:subj12????????? 315.8796? 53.70288 9294?? 5.88199? 0.0000
>> time5:subj13???????? -248.9957? 53.70288 9294? -4.63654? 0.0000
>> time5:subj14????????? 396.2154? 53.70288 9294?? 7.37792? 0.0000
>> time5:subj15????????? 231.0236? 53.70288 9294?? 4.30188? 0.0000
>> time5:subj16????????? 224.9218? 53.70288 9294?? 4.18826? 0.0000
>> time5:subj17????????? 209.4774? 53.70288 9294?? 3.90067? 0.0001
>> time5:subj18????????? 505.3070? 53.70288 9294?? 9.40931? 0.0000
>> time5:subj19????????? 369.0887? 53.70288 9294?? 6.87279? 0.0000
>> time5:subj20????????? 275.5678? 53.70288 9294?? 5.13134? 0.0000
>> time5:subj21????????? 480.7268? 53.70288 9294?? 8.95160? 0.0000
>>
>>
>> time1:A1??????????? 353.1338? 85.49229 9294?? 4.13059? 0.0000
>> time2:A1??????????? -68.5389? 16.57307 9294? -4.13556? 0.0000
>> time3:A1?????????? -154.4407? 23.43786 9294? -6.58937? 0.0000
>> time5:A1??????????? 123.8607? 16.57307 9294?? 7.47361? 0.0000
>> time3:B1??????? 100.1996? 23.43786 9294?? 4.27512? 0.0000
>> time4:B1??????? 201.6411? 23.43786 9294?? 8.60322? 0.0000
>> time3:A1:B1?? -68.6999? 33.14614 9294? -2.07264? 0.0382
>> time4:A1:B0?? 132.5765? 23.43786 9294?? 5.65651? 0.0000
>> time4:A1:B1? -124.2845? 23.43786 9294? -5.30272? 0.0000
>>
>>
>>
>>
>>
>> On Fri, Jan 6, 2012 at 1:08 PM, Szymek Drobniak <geralttee at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> for me it's unclear how you specify your data and your model. in general - it seems that you're using user-made polynomial terms? or have you used the poly() function to form them? I'm asking because you don't have most of the lower-order terms in your output. as for the interaction - it's interpretation is fairly straightforward. E.g. interaction of time4:A1:B1 contains the fourth order coefficient of regression for your relationship in the objects from both A1 and B1 groups. The lack of 0/1 next to B in the second example may be caused by accidental conversion of B into numerical (rather than factor) variable - in such a situation it would be treated as continous variable and just a single regression coefficient would be returned.
>>>
>>> cheers,
>>> sz.
>>>
>>> --
>>> Szymon Drobniak || Population Ecology Group
>>> Institute of Environmental Sciences,?Jagiellonian University
>>> ul. Gronostajowa 7, 30-387 Krak?w, POLAND
>>> tel.: +48 12 664 51 79 fax: +48 12 664 69 12
>>>
>>> www.eko.uj.edu.pl/drobniak
>>
>>
>



--
Szymon Drobniak || Population Ecology Group
Institute of Environmental Sciences,?Jagiellonian University
ul. Gronostajowa 7, 30-387 Krak?w, POLAND
tel.: +48 12 664 51 79 fax: +48 12 664 69 12

www.eko.uj.edu.pl/drobniak



From ramos.grad.student at gmail.com  Fri Jan  6 21:41:08 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Fri, 6 Jan 2012 12:41:08 -0800
Subject: [R-sig-ME] covariance structures for longitudinal models
In-Reply-To: <loom.20120106T191953-19@post.gmane.org>
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
	<CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>
	<CAHawB9utWpzVSgTBz82M1O4ss5Th+NvZtt4bLCJGe581uitHPA@mail.gmail.com>
	<loom.20120106T191953-19@post.gmane.org>
Message-ID: <CAHawB9u-9aVYcGsmuNQyFVfbZmpD1Vbf+erPvpS81pqnMnE01Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/c87bae39/attachment-0001.pl>

From kw.stat at gmail.com  Fri Jan  6 22:01:50 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 6 Jan 2012 15:01:50 -0600
Subject: [R-sig-ME] covariance structures for longitudinal models
In-Reply-To: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
Message-ID: <CAKFxdiRZZb1Wuy8MCbvnmmJovm47KZpMW4_RaK81nnbYHOAeSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/ebfc6712/attachment-0001.pl>

From jens.astrom at slu.se  Sun Jan  8 08:55:03 2012
From: jens.astrom at slu.se (=?UTF-8?B?SmVucyDDhXN0csO2bQ==?=)
Date: Sun, 08 Jan 2012 08:55:03 +0100
Subject: [R-sig-ME] Mean of random effects same as fixed effect?
Message-ID: <4F094BD7.1080408@slu.se>

Hi all,

A couple of weeks ago I posted a question but got no answers. Here goes
a second attempt, now shorter and more general.


Are the following two model specifications interchangeable, or is there
a statistical reason for why it is not OK to express model 1 in the form
of model 2?

Model 1)
y=fixed.intercept+fixed.slope*x+random.intercept+random.slope*x

Model 2)
y=random.intercept*x+random.slope*x
fixed.intercept=mean(random.intercept)
fixed.slope=mean(random.slope)



The reasons for my asking is that I have trouble getting convergence
with model specification 1, when the random intercepts and random slopes
are correlated, but specifying it as model 2 seemed to work. This is me
trying to implement some standard mixed models in BUGS/JAGS. Original
post with complete working example is here:
http://markmail.org/message/vhqeq4j3kldttlt5



I'm happy for any comments, with or without BUGS/JAGS code.

/Jens Astrom



From Thierry.ONKELINX at inbo.be  Mon Jan  9 10:07:21 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 9 Jan 2012 09:07:21 +0000
Subject: [R-sig-ME] Correlated count data technique advice
In-Reply-To: <CAPiP9jVXdjnMT-+ipPArd8yZ_zpmhy5dden6hZU7gYOXyrdZpA@mail.gmail.com>
References: <CAPiP9jVXdjnMT-+ipPArd8yZ_zpmhy5dden6hZU7gYOXyrdZpA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742757324440@inbomail.inbo.be>

Dear Lee,

A large numbers of zero do not imply zero-inflation. E.g.
> mean(rpois(10000, 0.01) == 0)
[1] 0.9902
This simulation has 99% zero's and is not zero-inflated.

Since you have a timeserie at only one location and one measurement per year there is no point in using a mixed model.

Wouldn't it be more relevant to look directly at the temperature than using a derived variable?

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Lee Davis
Verzonden: vrijdag 6 januari 2012 19:54
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Correlated count data technique advice

Please excuse me for having posted a similar question on ecolog, but thus far I have received few useful answers there.

I am looking for some advice concerning techniques in R that are appropriate for correlated count data.

Specifically, I have some "freezing days" data, which is a count of the number of days each spring that were below freezing. The counts were taken at the same location over a period of years. The data set is highly zero inflated and over-dispersed; glm with a quasipoisson error structure would seem to be appropriate, except that there is a high degree of correlation at lags of 1 making something like a corAR1 structure appropriate. My difficulty is that glm() does not take an argument for correlation.

I could use  lmer() to fit a model like:

freezing days~years+(1|years), family=quasipoisson, correlation=corAR1

but lmer (and glmer) don't seem to be operating on quasi families anymore; I've found plenty of old posts here where lmer seems to have accepted quasi families in the past, but I get an error message that indicates lmer does not in fact accept quasi families.

I should note that I have run the following model:

 freeze.glmmPQL3<-glmmPQL(num.
freeze.days~years, random= ~1|years,
       family=quasipoisson,correlation=corAR1())

My gut says this is not the correct approach and I am unconvinced by the tiny p values that have been returned, especially as specification of poisson vs quasipoisson and the specification of corAR1() seem to make no difference to parameter estimation or p vals for said pars--it would seem that the random term for varying intercept by year is dominant. Maybe this is OK, but my above glm models return non-significant results and I expected handling the correlation to increase my p vals rather than decrease them. Perhaps an incorrect assumption.

Therefore I need some alternative to look at trends in this data over time that allows for quasipoisson error and something along the lines of a
corAR1() structure (or a mixed model that handles temporal pseudo-replication, but I am hesitant here).

Thank you in advance,
Lee

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From g.leckie at bristol.ac.uk  Mon Jan  9 13:51:46 2012
From: g.leckie at bristol.ac.uk (George Leckie)
Date: Mon, 9 Jan 2012 12:51:46 +0000 (UTC)
Subject: [R-sig-ME] =?utf-8?b?cGFja2FnZSDigJhsbWU0YeKAmSBpcyBub3QgYXZhaWxh?=
	=?utf-8?q?ble_=28for_R_version_2=2E14=2E1=29?=
Message-ID: <loom.20120109T134811-751@post.gmane.org>

Hi All,

I am having problems installing lme4a

> install.packages("lme4a", repos="http://R-Forge.R-project.org")
Installing package(s) into ?D:/Program Files/R/R-2.14.1/library?
(as ?lib? is unspecified)
Warning in install.packages :
 package ?lme4a? is not available (for R version 2.14.1)

I tried this on 2.13.0 and this produced the same error

Any ideas? Aplogies in advanced if I am making a trivial error (I am new to R).

Many thanks

George



From bates at stat.wisc.edu  Mon Jan  9 21:02:06 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 9 Jan 2012 14:02:06 -0600
Subject: [R-sig-ME] Mean of random effects same as fixed effect?
In-Reply-To: <4F094BD7.1080408@slu.se>
References: <4F094BD7.1080408@slu.se>
Message-ID: <CAO7JsnT+9YeewXf1izJ41Fh_uSMPweLOCsi4TDNjr=OgT6wSjw@mail.gmail.com>

On Sun, Jan 8, 2012 at 1:55 AM, Jens ?str?m <jens.astrom at slu.se> wrote:
> Hi all,
>
> A couple of weeks ago I posted a question but got no answers. Here goes
> a second attempt, now shorter and more general.
>
>
> Are the following two model specifications interchangeable, or is there
> a statistical reason for why it is not OK to express model 1 in the form
> of model 2?
>
> Model 1)
> y=fixed.intercept+fixed.slope*x+random.intercept+random.slope*x
>
> Model 2)
> y=random.intercept*x+random.slope*x
> fixed.intercept=mean(random.intercept)
> fixed.slope=mean(random.slope)

You would need at least equal group sizes and identical values of the
covariate with respect to which you have a random slope to be able to
count on this.  Even then I'm not entirely sure it would work.

Generally the unconditional distribution of the random effects is
defined to have a mean of zero.  I don't know how you are defining
yours (and prefer not to wade through BUGS/JAGS model specifications
to find out).

> The reasons for my asking is that I have trouble getting convergence
> with model specification 1, when the random intercepts and random slopes
> are correlated, but specifying it as model 2 seemed to work. This is me
> trying to implement some standard mixed models in BUGS/JAGS. Original
> post with complete working example is here:
> http://markmail.org/message/vhqeq4j3kldttlt5
>
>
>
> I'm happy for any comments, with or without BUGS/JAGS code.
>
> /Jens Astrom
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From m.lee.davis at gmail.com  Tue Jan 10 02:47:11 2012
From: m.lee.davis at gmail.com (Lee Davis)
Date: Mon, 9 Jan 2012 20:47:11 -0500
Subject: [R-sig-ME] Correlated Count Data
Message-ID: <CAPiP9jWWMyKoLq72ugF-_Kk6ziQL3E5Wm2vVoW7Lr0vJD7T1CA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120109/332499b9/attachment-0001.pl>

From Thierry.ONKELINX at inbo.be  Tue Jan 10 09:58:16 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 10 Jan 2012 08:58:16 +0000
Subject: [R-sig-ME] Correlated Count Data
In-Reply-To: <CAPiP9jWWMyKoLq72ugF-_Kk6ziQL3E5Wm2vVoW7Lr0vJD7T1CA@mail.gmail.com>
References: <CAPiP9jWWMyKoLq72ugF-_Kk6ziQL3E5Wm2vVoW7Lr0vJD7T1CA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742757327E37@inbomail.inbo.be>

Lee,

I don't think you can use glmgee either because that is also designed to handle multiple timelines.

So you probabily need some kind of timeseries approach that can handle poisson data. But that is outside my expertise.

A new post on another list seems a good idea.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Lee Davis
Verzonden: dinsdag 10 januari 2012 2:47
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Correlated Count Data

Thierry,

I agree that the data is not actually zero-inflated and so I haven't worried with something like a ZIP. I also have no desire to use a mixed model for the very reason you state-that the measures were made at one location.

As for using temperature rather than a derived variable--as much as I may agree, that one's not my call.

What would your opinion be one the use of geeglm() for this data?

Perhaps it may be more appropriate to move this thread to the general help list.

Thank you,

Lee



---------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 9 Jan 2012 09:07:21 +0000
> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> To: Lee Davis <m.lee.davis at gmail.com>,
>        "r-sig-mixed-models at r-project.org"      <
> r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Correlated count data technique advice
> Message-ID:
>        <AA818EAD2576BC488B4F623941DA742757324440 at inbomail.inbo.be>
> Content-Type: text/plain; charset="us-ascii"
>
> Dear Lee,
>
> A large numbers of zero do not imply zero-inflation. E.g.
> > mean(rpois(10000, 0.01) == 0)
> [1] 0.9902
> This simulation has 99% zero's and is not zero-inflated.
>
> Since you have a timeserie at only one location and one measurement 
> per year there is no point in using a mixed model.
>
> Wouldn't it be more relevant to look directly at the temperature than 
> using a derived variable?
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] Namens Lee Davis
> Verzonden: vrijdag 6 januari 2012 19:54
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Correlated count data technique advice
>
> Please excuse me for having posted a similar question on ecolog, but 
> thus far I have received few useful answers there.
>
> I am looking for some advice concerning techniques in R that are 
> appropriate for correlated count data.
>
> Specifically, I have some "freezing days" data, which is a count of 
> the number of days each spring that were below freezing. The counts 
> were taken at the same location over a period of years. The data set 
> is highly zero inflated and over-dispersed; glm with a quasipoisson 
> error structure would seem to be appropriate, except that there is a 
> high degree of correlation at lags of 1 making something like a corAR1 
> structure appropriate. My difficulty is that glm() does not take an argument for correlation.
>
> I could use  lmer() to fit a model like:
>
> freezing days~years+(1|years), family=quasipoisson, correlation=corAR1
>
> but lmer (and glmer) don't seem to be operating on quasi families 
> anymore; I've found plenty of old posts here where lmer seems to have 
> accepted quasi families in the past, but I get an error message that 
> indicates lmer does not in fact accept quasi families.
>
> I should note that I have run the following model:
>
>  freeze.glmmPQL3<-glmmPQL(num.
> freeze.days~years, random= ~1|years,
>       family=quasipoisson,correlation=corAR1())
>
> My gut says this is not the correct approach and I am unconvinced by 
> the tiny p values that have been returned, especially as specification 
> of poisson vs quasipoisson and the specification of corAR1() seem to 
> make no difference to parameter estimation or p vals for said pars--it 
> would seem that the random term for varying intercept by year is 
> dominant. Maybe this is OK, but my above glm models return 
> non-significant results and I expected handling the correlation to 
> increase my p vals rather than decrease them. Perhaps an incorrect assumption.
>
> Therefore I need some alternative to look at trends in this data over 
> time that allows for quasipoisson error and something along the lines 
> of a
> corAR1() structure (or a mixed model that handles temporal 
> pseudo-replication, but I am hesitant here).
>
> Thank you in advance,
> Lee
>
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From highstat at highstat.com  Tue Jan 10 13:52:06 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 10 Jan 2012 08:52:06 -0400
Subject: [R-sig-ME] Correlated Count Data
Message-ID: <4F0C3476.70601@highstat.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120110/bd9a2097/attachment-0001.pl>

From Michelle.Gosse at foodstandards.gov.au  Tue Jan 10 20:05:47 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Wed, 11 Jan 2012 06:05:47 +1100
Subject: [R-sig-ME] nlme model not working but lme models are fine
	[SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4EC@EXCHANGE07.foodstandards.gov.au>

Hi all,

I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.

My working lme4 code is:
Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
	data=Male.Data,
	weights = SampleWeight)

Where:
BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.

I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.

In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):

Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.

male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
		data = Male.Group,
		random = ~ 1 | RespondentID)
		

When I run the next bit,I get an error. Error and traceback() provided after the syntax:

Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
		fixed = ordered(AgeFactor) + IntakeDay ~ 1,
		random = RespondentID ~ 1,
		data = Male.Group,
		start= fixef(male.lme2)
		)

I get the error message:
Error in eval(expr, envir, enclos) : object 'AgeFactor' not found

The results of traceback() are:
8: eval(expr, envir, enclos)
7: eval(x[[length(x)]], dat)
6: FUN(X[[1L]], ...)
5: lapply(form, function(x, dat, N) {
       val <- eval(x[[length(x)]], dat)
       if (length(val) == 1) {
           return(as.factor(rep(val, N)))
       }
       else {
           return(as.factor(val)[drop = TRUE])
       }
   }, dat = object, N = nrow(object))
4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1", deparse(groups[[2]]), 
       sep = "|"))))
3: getGroups(dataMix, eval(parse(text = paste("~1", deparse(groups[[2]]), 
       sep = "|"))))
2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed = ordered(AgeFactor) + 
       IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group, 
       start = fixef(male.lme2))
1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed = ordered(AgeFactor) + 
       IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group, 
       start = fixef(male.lme2))

Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.

cheers
Michelle

UNCLASSIFIED
**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}



From bates at stat.wisc.edu  Tue Jan 10 20:56:05 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 10 Jan 2012 13:56:05 -0600
Subject: [R-sig-ME] nlme model not working but lme models are fine
	[SEC=UNCLASSIFIED]
In-Reply-To: <12E932690323AB4EBEEB21BAA28D90DE369E10A4EC@EXCHANGE07.foodstandards.gov.au>
References: <12E932690323AB4EBEEB21BAA28D90DE369E10A4EC@EXCHANGE07.foodstandards.gov.au>
Message-ID: <CAO7JsnT5qmFPz04jKcubgNOW+Xa6R0AAWueGvW+AvfpYuP45bA@mail.gmail.com>

On Tue, Jan 10, 2012 at 1:05 PM, Gosse, Michelle
<Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi all,
>
> I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.

So what is the nonlinear model?  You haven't specified it in your call to nlme.

> My working lme4 code is:
> Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
> ? ? ? ?data=Male.Data,
> ? ? ? ?weights = SampleWeight)
>
> Where:
> BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
> IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.
>
> I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.
>
> In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):
>
> Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.
>
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?random = ~ 1 | RespondentID)
>
>
> When I run the next bit,I get an error. Error and traceback() provided after the syntax:
>
> Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?fixed = ordered(AgeFactor) + IntakeDay ~ 1,
> ? ? ? ? ? ? ? ?random = RespondentID ~ 1,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?start= fixef(male.lme2)
> ? ? ? ? ? ? ? ?)

Your formula is not an nlme specification.  The right hand side of the
formula should be a function call using nonlinear model parameters and
covariates.  You are using a linear model formula on the right hand
side and this will not give the result you are expecting.

> I get the error message:
> Error in eval(expr, envir, enclos) : object 'AgeFactor' not found
>
> The results of traceback() are:
> 8: eval(expr, envir, enclos)
> 7: eval(x[[length(x)]], dat)
> 6: FUN(X[[1L]], ...)
> 5: lapply(form, function(x, dat, N) {
> ? ? ? val <- eval(x[[length(x)]], dat)
> ? ? ? if (length(val) == 1) {
> ? ? ? ? ? return(as.factor(rep(val, N)))
> ? ? ? }
> ? ? ? else {
> ? ? ? ? ? return(as.factor(val)[drop = TRUE])
> ? ? ? }
> ? }, dat = object, N = nrow(object))
> 4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1", deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 3: getGroups(dataMix, eval(parse(text = paste("~1", deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed = ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
> 1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed = ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
>
> Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.



From bates at stat.wisc.edu  Tue Jan 10 21:32:10 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 10 Jan 2012 14:32:10 -0600
Subject: [R-sig-ME] bootstrap variance component in a mixed linear model
In-Reply-To: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>
References: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>
Message-ID: <CAO7JsnSgMvfiv7gq676-P4uO2LDXS5=hzkgp_5_7xQcyEezrNg@mail.gmail.com>

On Wed, Jan 4, 2012 at 5:22 PM, Kevin Spring <kevinjspring at gmail.com> wrote:
> Hi, everyone. ?I don't know what is going wrong with my bootstrap. ?Could
> anyone help me find out what is wrong?
>
> I am trying to bootstrap the variance component in a mixed linear model.
>
> My statistic for the bootstrap is the following:
>
> varcomp <- function ( formula, data, indices ) {
>> ? ? d <- data[indices,] #sample for boot
>> ? ? fit <- lmer(formula, data=d) #linear model
>> ? ? return (attr (VarCorr(fit), "sc")^2) #output random effects residual
>> var
>> }
>
>
> The formula for the model is: log( y ) ~ ( 1 | a:b ) + a, where '*b*' is a
> random effect nested within '*a';* which is a fixed effect.
>
> When I run the linear model on its own it works fine, but when I try to run
> the bootstrap I get warning messages of false convergence.
>
> Warning messages:
>> 1: In mer_finalize(ans) : false convergence (8)
>> 2: In mer_finalize(ans) : false convergence (8)
>> 3: In mer_finalize(ans) : false convergence (8)
>> 4: In mer_finalize(ans) : false convergence (8)
>> 5: In mer_finalize(ans) : false convergence (8)
>> 6: In mer_finalize(ans) : false convergence (8)
>

Those warnings are coming from the optimizer used in lme4 (the same
one as in the R function nlminb).  Finding reliable code for
optimizing a nonlinear function subject to box constraints (in this
case, standard deviations being greater than zero) is not easy.
Eventually I gave up and created an implementation of the Nelder-Mead
simplex method (the version used in the optim function in R doesn't
handle constraints) which can be a bit slower but is also more
reliable.  This is used in the development version of lme4 called
lme4Eigen. (I know - "not ANOTHER development version".  I have a
rather severe "best is the enemy of the good" problem.)

For some GLMMs the version of glmer in lme4Eigen is both faster and
more reliable.

Ben has set a deadline of January for releasing what is now lme4Eigen
as lme4.  I hope he means the end of January and not the beginning of
January.

We would appreciate feedback on lme4Eigen.  Unfortunately you need to
compile it to be able to use it on Windows or on Mac OS X (sigh).  On
Windows there is a problem with compiling the 64-bit version which
traces back to something in Rcpp.  It may be possible to make a small
change in Rcpp to bypass that.  On Mac OS X the compilation of
RcppEigen, on which lme4Eigen depends, croaks because the decade-old
compiler that Apple still uses has bugs.  Apparently Apple is going to
replace gcc-4.2.1 with clang in a new release of Xcode so that logjam
may be freed up too.


> The example data I used can be downloaded at:
> http://www.mediafire.com/?77xb24rmul90k5d
>
> The R code I actually did:
>
> library(boot)
> library(lme4)
> #
> #Load data
> #
> fp1 <- read.csv("desktop/p1f.csv")
> #Set as factors
> fp1$Cell.line <- as.factor(fp1$Cell.line)
> fp1$DNA.extract <- as.factor(fp1$DNA.extract)
> #test mixed model
> lm1 <- lmer(formula=log(CNPC)~(1|Cell.line:DNA.extract)+Cell.line,data=fp1)
> attr (VarCorr(lm1), "sc")
> #
> ##Bootstrap statistic
> #
> varcomp <- function ( formula, data, indices ) {
> ? ?d <- data[indices,] #sample for boot
> ? ?fit <- lmer(formula, data=d) #linear model
> ? ?return (attr (VarCorr(fit), "sc")) #output random effects residual
> standard deviation
> }
> ##Bootstrap with 1000 replicates
> fp1.boot <- boot ( data = fp1, statistic=varcomp, R=1000,
> formula=log(CNPC)~(1|Cell.line:DNA.extract)+Cell.line)
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Stefan.Schreiber at ales.ualberta.ca  Tue Jan 10 23:30:34 2012
From: Stefan.Schreiber at ales.ualberta.ca (Schreiber, Stefan)
Date: Tue, 10 Jan 2012 15:30:34 -0700
Subject: [R-sig-ME] lmer model for repeated measure in RCB design
Message-ID: <70F02259E17B6242B15D81E58EB7EB11087B5A17@afhe-ex.afhe.ualberta.ca>


Hi all,

I have a questions about the following situation and was hoping to find
clarification here.

I have a data frame with the following variables:

id, genotype, group, block, climate, response

I measured a response of 7 genotypes in a randomized complete block
design. I measured each genotype 8 times (n=48). I grouped my 7
genotypes into 3 for me more reasonable groups. I measured the response
on the same 7 genotypes 3 times under different climatic conditions.

I specified block and genotype as random and group as fixed. I believe
the proper random statement should look like: block, genotype nested
within group.

I came up with the following code:

fit1 <- lmer(weight ~ group*climate + (1|block) + (1|group/genotype) ,
data=df)

The problem I have now is how can I include the fact that I measured the
same genotypes at three different times? Can I say (1|group/genotype/id)
instead of (1|group/genotype)?

Thanks for any comments on this!

Stefan



From Michelle.Gosse at foodstandards.gov.au  Wed Jan 11 04:04:33 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Wed, 11 Jan 2012 14:04:33 +1100
Subject: [R-sig-ME] nlme model not working but lme models are fine
 [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F0@EXCHANGE07.foodstandards.gov.au>

Hi,

Thanks for the help.  I'm now trying to figure out (1) the function and (2) how to specify it in nlme. 

cheers
Michelle

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Wednesday, January 11, 2012 8:56 AM
To: Gosse, Michelle
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]

On Tue, Jan 10, 2012 at 1:05 PM, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi all,
>
> I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.

So what is the nonlinear model?  You haven't specified it in your call to nlme.

> My working lme4 code is:
> Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
> ? ? ? ?data=Male.Data,
> ? ? ? ?weights = SampleWeight)
>
> Where:
> BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
> IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.
>
> I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.
>
> In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):
>
> Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.
>
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?random = ~ 1 | RespondentID)
>
>
> When I run the next bit,I get an error. Error and traceback() provided after the syntax:
>
> Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?fixed = ordered(AgeFactor) + IntakeDay ~ 1,
> ? ? ? ? ? ? ? ?random = RespondentID ~ 1,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?start= fixef(male.lme2)
> ? ? ? ? ? ? ? ?)

Your formula is not an nlme specification.  The right hand side of the formula should be a function call using nonlinear model parameters and covariates.  You are using a linear model formula on the right hand side and this will not give the result you are expecting.

> I get the error message:
> Error in eval(expr, envir, enclos) : object 'AgeFactor' not found
>
> The results of traceback() are:
> 8: eval(expr, envir, enclos)
> 7: eval(x[[length(x)]], dat)
> 6: FUN(X[[1L]], ...)
> 5: lapply(form, function(x, dat, N) {
> ? ? ? val <- eval(x[[length(x)]], dat)
> ? ? ? if (length(val) == 1) {
> ? ? ? ? ? return(as.factor(rep(val, N)))
> ? ? ? }
> ? ? ? else {
> ? ? ? ? ? return(as.factor(val)[drop = TRUE])
> ? ? ? }
> ? }, dat = object, N = nrow(object))
> 4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1", 
> deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 3: getGroups(dataMix, eval(parse(text = paste("~1", 
> deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
> ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
> 1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
> ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
>
> Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.

UNCLASSIFIED

**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}



From h.l.ward at qmul.ac.uk  Wed Jan 11 16:59:46 2012
From: h.l.ward at qmul.ac.uk (Helen Ward)
Date: Wed, 11 Jan 2012 15:59:46 +0000
Subject: [R-sig-ME] Mixed model with zero truncated Poisson distributed data
Message-ID: <4F0DB1F2.70406@qmul.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120111/be8d1be9/attachment-0001.pl>

From bonny.marica at gmail.com  Wed Jan 11 17:29:55 2012
From: bonny.marica at gmail.com (Bonny Marica)
Date: Thu, 12 Jan 2012 00:29:55 +0800
Subject: [R-sig-ME] Mixed model with zero truncated Poisson distributed
	data
In-Reply-To: <4F0DB1F2.70406@qmul.ac.uk>
References: <4F0DB1F2.70406@qmul.ac.uk>
Message-ID: <CAO-DCq9p8rprV9MWHS1evQR9H+=vLwFAnixCbELK8Gwueqn8aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/2e83396c/attachment-0001.pl>

From bbolker at gmail.com  Wed Jan 11 19:46:46 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Jan 2012 18:46:46 +0000 (UTC)
Subject: [R-sig-ME] Mixed model with zero truncated Poisson distributed
	data
References: <4F0DB1F2.70406@qmul.ac.uk>
Message-ID: <loom.20120111T194340-544@post.gmane.org>

Helen Ward <h.l.ward at ...> writes:

> I would like to describe the relationship between age and male 
> reproductive success in a population of greater horseshoe bats.
> 
> My data consists of three columns: MaleID, Age, NumberofPups (at that 
> age). Many of the males appear multiple times in the data set, so I 
> believe I need to derive a mixed model with MaleID as a random variable.
> 
> The data is Poisson distributed, but zero-truncated. So far I have only 
> succeeded in making a mixed model with a poisson distribution (using 
> glmmPQL in the MASS package), and a zero truncated poisson model (using 
> vglm in the VGAM package), but not a mixed model capable of handling 
> zero truncated Poisson data.
> 
> It has been suggested that I could just minus 1 from each value in the 
> NumberofPups column to make a more usual Poisson distribution, so I can 
> ignore the zero truncated bit. I have tried this and it changes the 
> results of the model, but is this an acceptable transformation?
> 
> If not, can anyone advise me on a mixed model that can handle zero 
> truncated Poisson data please?
> 
  
  Thanks for letting us know about cross-posting.

  You should be able to do this in either the MCMCglmm package or
(recent versions of) the glmmADMB package.  In MCMCglmm, use
family="ztpoisson"; in glmmADMB, use family="truncpoiss" ...

  Ben Bolker



From bbolker at gmail.com  Wed Jan 11 20:13:15 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Jan 2012 19:13:15 +0000 (UTC)
Subject: [R-sig-ME] lmer model for repeated measure in RCB design
References: <70F02259E17B6242B15D81E58EB7EB11087B5A17@afhe-ex.afhe.ualberta.ca>
Message-ID: <loom.20120111T195022-335@post.gmane.org>

Schreiber, Stefan <Stefan.Schreiber at ...> writes:

> 
> 
> Hi all,
> 
> I have a questions about the following situation and was hoping to find
> clarification here.
> 
> I have a data frame with the following variables:
> 
> id, genotype, group, block, climate, response
> 
> I measured a response of 7 genotypes in a randomized complete block
> design. I measured each genotype 8 times (n=48). 

    You have some missing combinations?  (8*7=56, right?) 

> I grouped my 7
> genotypes into 3 for me more reasonable groups. I measured the response
> on the same 7 genotypes 3 times under different climatic conditions.
> 
> I specified block and genotype as random and group as fixed.  I believe
> the proper random statement should look like: block, genotype nested
> within group.
> 
> I came up with the following code:
> 
> fit1 <- lmer(weight ~ group*climate + (1|block) + (1|group/genotype) ,
> data=df)
> 
> The problem I have now is how can I include the fact that I measured the
> same genotypes at three different times? Can I say (1|group/genotype/id)
> instead of (1|group/genotype)?

  Is id a unique identifier for each observation?  In that
case it's definitely redundant with the residual variance and
should not be included in the model statement.

  I'm still a little bit uncertain about your experimental design
(thanks for the careful explanation, though).  I'm going to make up
one possible explanation.  How unbalanced is it?  Does climate
represent another level of replication (e.g. are there three climate
conditions that are measured for each group*genotype*block
combination), or does it vary in an unbalanced way across
group*genotype*block combinations?  Would your total number
of observations be 8 (blocks) * 7 (genotypes) * 3 (climate conditions)?

  You shouldn't include group both as a fixed effect (your
fixed group*climate term expands to group+climate+group:climate)
and a random effect (your group/genotype term expands to 
group+group:genotype).  You should probably use
(1|group:genotype) instead (make sure group and genotype
are both stored as factors).

  Even if it weren't redundant, including a random effect of
group (with only three groups) is likely to give you an
estimated group-level variance of zero -- there aren't enough
levels to estimate variance reliably.

  If genotypes have unique IDs then you don't need the explicit
nesting or interaction syntax.  If so, my best guess is that

weight ~ group*climate + (1|block) + (1|genotype)

is what you want.

You might consider whether it's worth including other random terms --
the most complex model would include (group*climate|block)
and (climate|genotype) -- but you might find that you were running
out of signal ...



From Stefan.Schreiber at ales.ualberta.ca  Wed Jan 11 21:49:00 2012
From: Stefan.Schreiber at ales.ualberta.ca (Schreiber, Stefan)
Date: Wed, 11 Jan 2012 13:49:00 -0700
Subject: [R-sig-ME] lmer model for repeated measure in RCB design
References: <70F02259E17B6242B15D81E58EB7EB11087B5A17@afhe-ex.afhe.ualberta.ca>
	<loom.20120111T195022-335@post.gmane.org>
Message-ID: <70F02259E17B6242B15D81E58EB7EB1107B35E6E@afhe-ex.afhe.ualberta.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120111/d913c6e7/attachment-0001.pl>

From bbolker at gmail.com  Wed Jan 11 21:58:57 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Jan 2012 15:58:57 -0500
Subject: [R-sig-ME] lmer model for repeated measure in RCB design
In-Reply-To: <70F02259E17B6242B15D81E58EB7EB1107B35E6D@afhe-ex.afhe.ualberta.ca>
References: <70F02259E17B6242B15D81E58EB7EB11087B5A17@afhe-ex.afhe.ualberta.ca>
	<loom.20120111T195022-335@post.gmane.org>
	<70F02259E17B6242B15D81E58EB7EB1107B35E6D@afhe-ex.afhe.ualberta.ca>
Message-ID: <4F0DF811.20303@gmail.com>

  [cc'ing back to r-sig-mixed-models]


On 12-01-11 03:47 PM, Schreiber, Stefan wrote:
> Thanks Ben!
> 
> Yes, you are right, n=56. I don't know what happened there ;)
> 
> As for the ID, yes it is unique for each observation and identifies
> the sampled genotype in its respective block. The ID is build as
> "Genotype_Block".

  Technically, I would say that ID is not technically unique for each
observation since there are three observations (fall, winter, and
spring) for each ID ... ?  (You confirm this below: "each ID is
replicated three times ...") (By "observation", I mean the smallest
sampling unit -- one row of the data frame, in long format)

> Each genotype was replicated 5 times within each
> block. That way I was able to sample 8 genotypes by only having 5
> blocks. That means I sampled three blocks twice for the respective
> genotype.

  Makes sense.
> 
> Then I measured a physiological response on these genotypes in fall,
> winter and spring, representing different climate conditions. I
> always measured the same IDs over three different conditions (56*3).
> So each ID is replicated three times in my ID column.
> 
> Also, I grouped these 7 genotypes into 3 groups since I would rather
> compare the groups within each climatic condition and across the
> climatic conditions instead of all the genotypes.

  That makes perfect sense.
> 
> Since the ID is replicated 3 times, id is nested within genotype,
> correct?
> 
> response ~ group*climate + (1|block) + (1|genotype/id)

  This looks reasonable, although since id is *implicitly* nested (i.e.
it contains the genotype info) you should also be able to write it as
(1|genotype) + (1|id) .

   When you run this, lmer should report appropriate numbers of levels
in each group (block=5, genotype=8, genotype:id = 56? or 40? I'm not
sure ...) ... check these values and see that they are as you expect.
> 
> 
> Thanks again! Stefan
> 
> 
> 
> -----Original Message----- From:
> r-sig-mixed-models-bounces at r-project.org on behalf of Ben Bolker 
> Sent: Wed 1/11/2012 12:13 PM To: r-sig-mixed-models at r-project.org 
> Subject: Re: [R-sig-ME] lmer model for repeated measure in RCB
> design
> 
> Schreiber, Stefan <Stefan.Schreiber at ...> writes:
> 
>> 
>> 
>> Hi all,
>> 
>> I have a questions about the following situation and was hoping to
>> find clarification here.
>> 
>> I have a data frame with the following variables:
>> 
>> id, genotype, group, block, climate, response
>> 
>> I measured a response of 7 genotypes in a randomized complete
>> block design. I measured each genotype 8 times (n=48).
> 
> You have some missing combinations?  (8*7=56, right?)
> 
>> I grouped my 7 genotypes into 3 for me more reasonable groups. I
>> measured the response on the same 7 genotypes 3 times under
>> different climatic conditions.
>> 
>> I specified block and genotype as random and group as fixed.  I
>> believe the proper random statement should look like: block,
>> genotype nested within group.
>> 
>> I came up with the following code:
>> 
>> fit1 <- lmer(weight ~ group*climate + (1|block) +
>> (1|group/genotype) , data=df)
>> 
>> The problem I have now is how can I include the fact that I
>> measured the same genotypes at three different times? Can I say
>> (1|group/genotype/id) instead of (1|group/genotype)?
> 
> Is id a unique identifier for each observation?  In that case it's
> definitely redundant with the residual variance and should not be
> included in the model statement.
> 
> I'm still a little bit uncertain about your experimental design 
> (thanks for the careful explanation, though).  I'm going to make up 
> one possible explanation.  How unbalanced is it?  Does climate 
> represent another level of replication (e.g. are there three climate 
> conditions that are measured for each group*genotype*block 
> combination), or does it vary in an unbalanced way across 
> group*genotype*block combinations?  Would your total number of
> observations be 8 (blocks) * 7 (genotypes) * 3 (climate conditions)?
> 
> You shouldn't include group both as a fixed effect (your fixed
> group*climate term expands to group+climate+group:climate) and a
> random effect (your group/genotype term expands to 
> group+group:genotype).  You should probably use (1|group:genotype)
> instead (make sure group and genotype are both stored as factors).
> 
> Even if it weren't redundant, including a random effect of group
> (with only three groups) is likely to give you an estimated
> group-level variance of zero -- there aren't enough levels to
> estimate variance reliably.
> 
> If genotypes have unique IDs then you don't need the explicit nesting
> or interaction syntax.  If so, my best guess is that
> 
> weight ~ group*climate + (1|block) + (1|genotype)
> 
> is what you want.
> 
> You might consider whether it's worth including other random terms
> -- the most complex model would include (group*climate|block) and
> (climate|genotype) -- but you might find that you were running out of
> signal ...
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
>



From Michelle.Gosse at foodstandards.gov.au  Wed Jan 11 23:35:08 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Thu, 12 Jan 2012 09:35:08 +1100
Subject: [R-sig-ME] nlme model not working but lme models are fine
 [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F5@EXCHANGE07.foodstandards.gov.au>

Hi all,

I've replied to my message so hopefully the archive will stay tracking this as a single question.

Having examined the log likelihood formulae I was given for the SAS code, read Chapter 7 of Pinheiro & Bates, and searching for help,  I have got as far as (note, I am not using a grouped data frame as I get an error in nlme.fomula message saying that the "starting values for the fixed component are the wrong length" when I do this):

male.lme3 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
	data=Male.Data,
	random= ~1|RespondentID)

and then I am trying to run the following, and yes I wish the covariates to be additive the model I am basing this on (from SAS) has additive covariates:
Male.nlme <- nlme(BoxCoxXY ~ A + B*factor(AgeFactor) + C*factor(IntakeDay),
	data=Male.Data,
	fixed= A + B + C ~ 1,
	random=A ~1,
	group=RespondentID,
	start=fixef(male.lme3)
	)

I get the error " Error in eval(expr, envir, enclos) : object 'A' not found"

I don't have a more complicated model as the REML is taking care of it. Using the Wafer example in Chapter 8 of Pinheiro & Bates, and also this thread:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005473.html

I thought I just had to show how the coefficients relate to the covariates and intercept. Clearly I have made an error of judgement, and I'm still not sure where I have gone wrong with the model. The Wafer nlme model uses A, B, and C in its model statement and the linked thread uses b0,...,b5. 

Would someone mind pointing out where I have gone wrong this time?

cheers
Michelle

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Gosse, Michelle
Sent: Wednesday, January 11, 2012 4:05 PM
To: 'Douglas Bates'
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]

Hi,

Thanks for the help.  I'm now trying to figure out (1) the function and (2) how to specify it in nlme. 

cheers
Michelle

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Wednesday, January 11, 2012 8:56 AM
To: Gosse, Michelle
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]

On Tue, Jan 10, 2012 at 1:05 PM, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi all,
>
> I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.

So what is the nonlinear model?  You haven't specified it in your call to nlme.

> My working lme4 code is:
> Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
> ? ? ? ?data=Male.Data,
> ? ? ? ?weights = SampleWeight)
>
> Where:
> BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
> IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.
>
> I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.
>
> In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):
>
> Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.
>
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?random = ~ 1 | RespondentID)
>
>
> When I run the next bit,I get an error. Error and traceback() provided after the syntax:
>
> Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?fixed = ordered(AgeFactor) + IntakeDay ~ 1,
> ? ? ? ? ? ? ? ?random = RespondentID ~ 1,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?start= fixef(male.lme2)
> ? ? ? ? ? ? ? ?)

Your formula is not an nlme specification.  The right hand side of the formula should be a function call using nonlinear model parameters and covariates.  You are using a linear model formula on the right hand side and this will not give the result you are expecting.

> I get the error message:
> Error in eval(expr, envir, enclos) : object 'AgeFactor' not found
>
> The results of traceback() are:
> 8: eval(expr, envir, enclos)
> 7: eval(x[[length(x)]], dat)
> 6: FUN(X[[1L]], ...)
> 5: lapply(form, function(x, dat, N) {
> ? ? ? val <- eval(x[[length(x)]], dat)
> ? ? ? if (length(val) == 1) {
> ? ? ? ? ? return(as.factor(rep(val, N)))
> ? ? ? }
> ? ? ? else {
> ? ? ? ? ? return(as.factor(val)[drop = TRUE])
> ? ? ? }
> ? }, dat = object, N = nrow(object))
> 4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1", 
> deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 3: getGroups(dataMix, eval(parse(text = paste("~1", 
> deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
> ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
> 1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
> ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
>
> Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.

UNCLASSIFIED

**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

UNCLASSIFIED

**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}



From mhm2002 at med.cornell.edu  Thu Jan 12 03:06:07 2012
From: mhm2002 at med.cornell.edu (Matthew Malter Cohen)
Date: Wed, 11 Jan 2012 21:06:07 -0500
Subject: [R-sig-ME] Mixed model formulation
Message-ID: <CAA=9ftUqedZ-t+_HeijKUcBwYptcBgWkwMsnovOjKbw9m_PRFA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120111/a56e92ec/attachment-0001.pl>

From ramos.grad.student at gmail.com  Thu Jan 12 03:57:56 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 11 Jan 2012 18:57:56 -0800
Subject: [R-sig-ME] how to get predicted values from a lme call with random
 intercepts and AR(1) for the residuals ?
Message-ID: <CAHawB9v4EKoPaJWx+uyQRhysgcnOQiaXJSRVM2bpdKk30piSQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120111/d61e8ec7/attachment-0001.pl>

From Michelle.Gosse at foodstandards.gov.au  Thu Jan 12 04:13:43 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Thu, 12 Jan 2012 14:13:43 +1100
Subject: [R-sig-ME] start values for starting parameters,
	factors [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F9@EXCHANGE07.foodstandards.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/d2f43dd7/attachment-0001.pl>

From isa.blasco.costa at gmail.com  Thu Jan 12 06:13:52 2012
From: isa.blasco.costa at gmail.com (Isa Blasco)
Date: Thu, 12 Jan 2012 18:13:52 +1300
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
Message-ID: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/79a03cc8/attachment-0001.pl>

From marta.m.rufino at gmail.com  Thu Jan 12 12:03:29 2012
From: marta.m.rufino at gmail.com (marta rufino)
Date: Thu, 12 Jan 2012 11:03:29 +0000
Subject: [R-sig-ME] SE for predictions in lme
Message-ID: <CAKSASLC+DK9oWkx3Prz71t8=krNfTuJ1jOF-r2FgcY9ri6Ux+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/81293b99/attachment-0001.pl>

From mails00000 at gmail.com  Thu Jan 12 15:07:18 2012
From: mails00000 at gmail.com (mails)
Date: Thu, 12 Jan 2012 14:07:18 +0000
Subject: [R-sig-ME] Interpreting linear models
Message-ID: <48966A32-1DF0-4B37-B560-A18184032DE0@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/74754b5d/attachment-0001.pl>

From bbolker at gmail.com  Thu Jan 12 17:42:59 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Jan 2012 16:42:59 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
Message-ID: <loom.20120112T173419-47@post.gmane.org>

Isa Blasco <isa.blasco.costa at ...> writes:

> 
> Hi,
> I am using glmmADMB to fit a negative binomial model to my data. My
> explanatory variable is an ordered factor with 10 levels and I also
> included a random factor (numeric) and Zero inflation.
> This is the code I used: m7 <- glmmadmb (abun~odist + (1|sl), data=apa,
> zeroInflation=TRUE, family="nbinom")
> 
> When I run it I got this error:
> Error in UseMethod("droplevels") :
>   no applicable method for 'droplevels' applied to an object of class
> "c('double', 'numeric')"
> 
> I do not know what the 'double' means but I checked the glmmADMB manual and
> they use the same kind of variables in their example. Any guess on what it
> is happening? How can I solve it?
> I hope somebody knows!

  It means that it doesn't make sense to use a numeric variable as
a grouping variable for a random factor (which is what you've done):
if sl is a discrete numeric code that identifies groups of observations,
then you should convert it to a factor.  If it's a continuous variable,
then you need to go back and read/think some more about the meanings
of random factors ...

  It also means that I made some changes to glmmADMB recently that
got in the way of an informative error message (you should have
received an error message that told you this).  I will try to 
catch that error in a more informative way.

  Ben Bolker



From ctr4g2 at mail.missouri.edu  Thu Jan 12 18:27:22 2012
From: ctr4g2 at mail.missouri.edu (Christopher Rota)
Date: Thu, 12 Jan 2012 11:27:22 -0600
Subject: [R-sig-ME] glmmADMB v 0.7.1
Message-ID: <4F0F17FA.2090403@mail.missouri.edu>

Dear R Users,

I am running into some trouble when using glmmADMB version 0.7.1 and am 
hoping someone in the R community may have some insight.

I am trying to fit a rather large negative binomial mixed-effects 
model.  I have 3980 observations (counts of foraging attempts).  My 
'global' model has 17 fixed effects and 2 random effects.  Fixed effects 
consist of both continuous and categorical variables.  Each categorical 
variable has at least 22 observations, most have considerably more.  One 
random effect is an 'observer' effect consisting of 11 different 
observers.  Each observer made at least 29 observations, but most made 
considerably more.  The other random effect in an 'individual bird' 
effect consisting of 78 individual birds.  There are at least 20 
observations made on each bird.

Here is my call to glmmadmb:
fit <- glmmadmb(formula=count~BrnLight + BrnMod + BrnMPB + BrnSev + 
GrnHit + GryHit + RedHit + Autumn + Spring + Winter + Yr01 + Yr12 + Yr23 
+ Yr34 + Yr45 + Est.DBH.in + Start.Time + (1|Color.Combo) + 
(1|Observers), data=beh.data, family='nbinom')

The variables 'BrnLight' through 'RedHit' represent categorical 
variables describing tree condition.  They are coded as dummy variables, 
and one tree condition category (Green) is omitted from model 
specification and interpreted as the intercept.  The season (Autumn, 
Spring, Winter) and year (Yr01, etc.) variables are coded in an 
identical manner (note that I also coded categorical variables as 
factors, and encountered the same problem described below).  DBH and 
Start.Time are continuous variables.

This global model runs for about 10 minutes, then fails with the 
following message:
Memory allocation error -- Perhaps you are trying to allocate too much 
memory in your program

When I monitor my computer performance with Windows Task Manager while 
the model is running, I can watch Physical Memory Usage slowly tick up. 
All of that increased memory use is attributed to glmmadmb.exe.  I will 
watch memory use for this program tick up to about 1.7GB, and that is 
when the model fails.  I am using a computer with a Windows Vista 32-bit 
operating system with 4GB RAM.  Is the problem simply that I do not have 
enough memory on my computer to run this model?  If indeed the problem 
is a shortage of memory, is there any way to make glmmadmb.exe use 
memory differently, or do I need to use a more powerful computer?

Thank you for any insight.

Chris Rota

-- 
Christopher Rota
Ph.D. Student

University of Missouri
Fisheries and Wildlife Science
302 Anheuser-Busch Natural Resources Building
Columbia, MO 65211

Office:  303O Anheuser-Busch Natural Resources Buildling
Email:  ctr4g2 at mail.missouri.edu
Phone:  573-239-6975
Website:  http://www.biosci.missouri.edu/avianecology/rota/index.html
Calendar:  http://www.google.com/calendar/embed?src=christopher.rota%40gmail.com&ctz=America/Chicago



From bbolker at gmail.com  Thu Jan 12 19:24:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Jan 2012 13:24:44 -0500
Subject: [R-sig-ME] Mixed model with zero truncated Poisson distributed
 data
In-Reply-To: <4F0F1DE7.9000603@qmul.ac.uk>
References: <4F0DB1F2.70406@qmul.ac.uk>
	<loom.20120111T194340-544@post.gmane.org>
	<4F0F1DE7.9000603@qmul.ac.uk>
Message-ID: <4F0F256C.1090101@gmail.com>

  [I'm taking the liberty of cc'ing this to the r-sig-mixed-models
mailing list, where it can be archived]

On 12-01-12 12:52 PM, Helen Ward wrote:
> Dear Ben,
> 
> Thank you for your speedy response. I've been having a go with MCMCglmm
> today, but I suspect I have over simplified the model (I'm new to
> Bayesian statistics), as I now get three suspiciously significant
> results...
> 
> The model I've tried (included below with its summary) runs, but my
> reading of the help file and the vignette make me suspect that I need to
> give some sort of prior of something to make it sensible. Am I on the
> right track?
> 
> I have also had a quick go with glmmADMB, trying the following models,
> 
>>  model1<-glmmadmb(RSperYr~Age+I(Age^2),data,family="truncpoiss",~1|DadID)
> 
> Error in switch(link, log = log, logit = qlogis, probit = qnorm, inverse
> = function(x) { :
> 
> EXPR must be a length 1 vector

   Here the problem is that you are specifying the random effect without
giving its name (i.e. random=~1|DadID), so R is trying to interpret it
as your desired link function (which is the fourth argument to the
glmmadmb() function: see ?glmmadmb).

> 
>>  model1<-glmmadmb(RSperYr~Age+I(Age^2)+(1|DadID),data,family="truncpoiss")
>>
> 
> Error in UseMethod("droplevels") :
> 
> no applicable method for 'droplevels' applied to an object of class
> "c('integer', 'numeric')",
> 
> but as you can see from the error mesddages I am obviously doing
> something a bit wrong here as well.

  As mentioned in another message on this list this morning, the problem
here is that you need to explicitly convert "DadID" to a factor from a
numeric value [e.g. data$DadID <- factor(data$DadID)] -- the current
error message is not very informative.

> I'll keep trying!, but are there any more obvious pointers you can give
> me please?
> 
> All the best,
> Helen
> 
> 
> This is the model I've tried using MCMCglmm.
>>
> model2<-MCMCglmm(RSperYr~Age+I(Age^2),random=~DadID,family="ztpoisson",data=data)
> 
>>  summary(model2)
> 
> Iterations = 3001:12991
> Thinning interval= 10
> Sample size= 1000
> 
> DIC: 808.5343
> 
> G-structure:~DadID
> 
> post.meanl-95% CI u-95% CI eff.samp
> 
> DadID0.07409 0.00057460.182239.75
> 
> R-structure:~units
> 
> post.mean l-95% CI u-95% CI eff.samp
> 
> units0.06205 0.0014050.176322.55
> 
> Location effects: RSperYr ~ Age + I(Age^2)
> 
> post.meanl-95% CIu-95% CI eff.samp pMCMC
> 
> (Intercept) -0.694625 -1.321090 -0.16384737.17 0.004 **
> 
> Age0.1978390.0667140.33041768.64 0.002 **
> 
> I(Age^2)-0.008292 -0.014887 -0.00158971.46 0.010 **
> 
> 

  At a *quick* glance this looks reasonable.  Try plot(model2$Sol) and
plot(model2$VCV) to see if the trace and density plots look reasonable
(compare them with the results from example("MCMCglmm"). You should take
a quick look at the Overview and CourseNotes vignettes (e.g.
vignette("Overview",package="MCMCglmm")) (the latter in particular is a
bit overwhelming but well worth digging into if you're going to use
these methods)

> 
> 
> 
> On 11/01/2012 18:46, Ben Bolker wrote:
>> Helen Ward<h.l.ward at ...>  writes:
>>
>>> I would like to describe the relationship between age and male
>>> reproductive success in a population of greater horseshoe bats.
>>>
>>> My data consists of three columns: MaleID, Age, NumberofPups (at that
>>> age). Many of the males appear multiple times in the data set, so I
>>> believe I need to derive a mixed model with MaleID as a random variable.
>>>
>>> The data is Poisson distributed, but zero-truncated. So far I have only
>>> succeeded in making a mixed model with a poisson distribution (using
>>> glmmPQL in the MASS package), and a zero truncated poisson model (using
>>> vglm in the VGAM package), but not a mixed model capable of handling
>>> zero truncated Poisson data.
>>>
>>> It has been suggested that I could just minus 1 from each value in the
>>> NumberofPups column to make a more usual Poisson distribution, so I can
>>> ignore the zero truncated bit. I have tried this and it changes the
>>> results of the model, but is this an acceptable transformation?
>>>
>>> If not, can anyone advise me on a mixed model that can handle zero
>>> truncated Poisson data please?
>>>
>>
>>    Thanks for letting us know about cross-posting.
>>
>>    You should be able to do this in either the MCMCglmm package or
>> (recent versions of) the glmmADMB package.  In MCMCglmm, use
>> family="ztpoisson"; in glmmADMB, use family="truncpoiss" ...
>>
>>    Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From giulia.dottisani at gmail.com  Thu Jan 12 19:36:39 2012
From: giulia.dottisani at gmail.com (Giulia Dotti Sani)
Date: Thu, 12 Jan 2012 19:36:39 +0100
Subject: [R-sig-ME] In II[, ii] + REmat$codes[[i]] :
Message-ID: <CAKz8Hv=jZvhNxijKV-X7eWkViTCfVghe0HdoPGEcRCzzpBoyPw@mail.gmail.com>

Hello,

I'm running the following poisson and I keep getting the same error.
M01 <- glmmadmb(chi_hh ~ age_m + educ +(1 |country_y), data=data,
family="poisson")

In II[, ii] + REmat$codes[[i]] :
  longer object length is not a multiple of shorter object length

I think it has to do with the grouping variable but I don't see what's
the problem.
Thank you for any suggestions,

Giulia



From bates at stat.wisc.edu  Thu Jan 12 20:38:23 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 12 Jan 2012 13:38:23 -0600
Subject: [R-sig-ME] nlme model not working but lme models are fine
	[SEC=UNCLASSIFIED]
In-Reply-To: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F5@EXCHANGE07.foodstandards.gov.au>
References: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F5@EXCHANGE07.foodstandards.gov.au>
Message-ID: <CAO7JsnTKGSBqOZ6J-NF0dEcMH4d866XnhXTuNR6hqCp0bfhi0g@mail.gmail.com>

On Wed, Jan 11, 2012 at 4:35 PM, Gosse, Michelle
<Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi all,
>
> I've replied to my message so hopefully the archive will stay tracking this as a single question.
>
> Having examined the log likelihood formulae I was given for the SAS code, read Chapter 7 of Pinheiro & Bates, and searching for help, ?I have got as far as (note, I am not using a grouped data frame as I get an error in nlme.fomula message saying that the "starting values for the fixed component are the wrong length" when I do this):
>
> male.lme3 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ?data=Male.Data,
> ? ? ? ?random= ~1|RespondentID)
>
> and then I am trying to run the following, and yes I wish the covariates to be additive the model I am basing this on (from SAS) has additive covariates:
> Male.nlme <- nlme(BoxCoxXY ~ A + B*factor(AgeFactor) + C*factor(IntakeDay),
> ? ? ? ?data=Male.Data,
> ? ? ? ?fixed= A + B + C ~ 1,
> ? ? ? ?random=A ~1,
> ? ? ? ?group=RespondentID,
> ? ? ? ?start=fixef(male.lme3)
> ? ? ? ?)
>
> I get the error " Error in eval(expr, envir, enclos) : object 'A' not found"
>
> I don't have a more complicated model as the REML is taking care of it. Using the Wafer example in Chapter 8 of Pinheiro & Bates, and also this thread:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005473.html
>
> I thought I just had to show how the coefficients relate to the covariates and intercept. Clearly I have made an error of judgement, and I'm still not sure where I have gone wrong with the model. The Wafer nlme model uses A, B, and C in its model statement and the linked thread uses b0,...,b5.
>
> Would someone mind pointing out where I have gone wrong this time?

The names of your starting values must correspond to the names used in
the formula (A, B and C).  I don't think that formula is what you want
because ordered(AgeFactor) will be converted to integer values 1, 2,
..., # of levels of AgeFactor and the same with factor(IntakeDay).
It is highly unlikely that this model does what you expect it to do.

In the end you would just end up with an awkward nonlinear model
formula representing a linear model.

You said that you were asked to fit a nonlinear mixed-effects model.
I recommend that you go back to the person who suggested this and get
clarification on what model they intended.  Converting a linear
mixed-effects model to a nonlinear model formula, in which all the
parameters occur linearly, and fitting that is not a nonlinear
mixed-effects model.  It is the same linear mixed-effects model fit
inefficiently.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Gosse, Michelle
> Sent: Wednesday, January 11, 2012 4:05 PM
> To: 'Douglas Bates'
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]
>
> Hi,
>
> Thanks for the help. ?I'm now trying to figure out (1) the function and (2) how to specify it in nlme.
>
> cheers
> Michelle
>
> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
> Sent: Wednesday, January 11, 2012 8:56 AM
> To: Gosse, Michelle
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]
>
> On Tue, Jan 10, 2012 at 1:05 PM, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
>> Hi all,
>>
>> I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.
>
> So what is the nonlinear model? ?You haven't specified it in your call to nlme.
>
>> My working lme4 code is:
>> Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
>> ? ? ? ?data=Male.Data,
>> ? ? ? ?weights = SampleWeight)
>>
>> Where:
>> BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
>> IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.
>>
>> I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.
>>
>> In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):
>>
>> Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.
>>
>> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
>> ? ? ? ? ? ? ? ?data = Male.Group,
>> ? ? ? ? ? ? ? ?random = ~ 1 | RespondentID)
>>
>>
>> When I run the next bit,I get an error. Error and traceback() provided after the syntax:
>>
>> Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
>> ? ? ? ? ? ? ? ?fixed = ordered(AgeFactor) + IntakeDay ~ 1,
>> ? ? ? ? ? ? ? ?random = RespondentID ~ 1,
>> ? ? ? ? ? ? ? ?data = Male.Group,
>> ? ? ? ? ? ? ? ?start= fixef(male.lme2)
>> ? ? ? ? ? ? ? ?)
>
> Your formula is not an nlme specification. ?The right hand side of the formula should be a function call using nonlinear model parameters and covariates. ?You are using a linear model formula on the right hand side and this will not give the result you are expecting.
>
>> I get the error message:
>> Error in eval(expr, envir, enclos) : object 'AgeFactor' not found
>>
>> The results of traceback() are:
>> 8: eval(expr, envir, enclos)
>> 7: eval(x[[length(x)]], dat)
>> 6: FUN(X[[1L]], ...)
>> 5: lapply(form, function(x, dat, N) {
>> ? ? ? val <- eval(x[[length(x)]], dat)
>> ? ? ? if (length(val) == 1) {
>> ? ? ? ? ? return(as.factor(rep(val, N)))
>> ? ? ? }
>> ? ? ? else {
>> ? ? ? ? ? return(as.factor(val)[drop = TRUE])
>> ? ? ? }
>> ? }, dat = object, N = nrow(object))
>> 4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1",
>> deparse(groups[[2]]),
>> ? ? ? sep = "|"))))
>> 3: getGroups(dataMix, eval(parse(text = paste("~1",
>> deparse(groups[[2]]),
>> ? ? ? sep = "|"))))
>> 2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
>> ordered(AgeFactor) +
>> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
>> ? ? ? start = fixef(male.lme2))
>> 1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
>> ordered(AgeFactor) +
>> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
>> ? ? ? start = fixef(male.lme2))
>>
>> Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.
>
> UNCLASSIFIED
>
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:9}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> UNCLASSIFIED
>
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:9}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Thu Jan 12 20:50:45 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 12 Jan 2012 13:50:45 -0600
Subject: [R-sig-ME] start values for starting parameters,
	factors [SEC=UNCLASSIFIED]
In-Reply-To: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F9@EXCHANGE07.foodstandards.gov.au>
References: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F9@EXCHANGE07.foodstandards.gov.au>
Message-ID: <CAO7JsnRMp6HLJ0U8uM6-RfNL23jy0w-4Eieqon8sJf9UR06iSg@mail.gmail.com>

On Wed, Jan 11, 2012 at 9:13 PM, Gosse, Michelle
<Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi again,
>
> More reading later, and I have the following model with the log likelihood function specified:
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random= ~1|RespondentID)
>
> male.nlme <- nlme(IntakeAmt ~ log(1/sqrt(2*pi*(Scale^2))) +
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?(-(A*BoxCoxXY-(B*AgeFactor + C*IntakeDay))^2)/(2*Scale)+(Lambda.Value-1)*log(IntakeAmt),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?fixed = A - B + C ~ 1,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = A ~ 1|RespondentID,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?start=fixef(male.lme2)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)
>
> The nlme syntax gives me the error:
> "Error in nlme.formula(IntakeAmt ~ log(1/sqrt(2 * pi * (Scale^2))) + (-(A * :
> ? ? ? ? ? ?starting values for the fixed component are not the correct length"
>
> Reading on the internet made me understand that this is because there needs to be 3 fixed component start parameters, as confirmed by the model below not giving that error:
> male.nlme <- nlme(IntakeAmt ~ log(1/sqrt(2*pi*(Scale^2))) +
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?(-(A*BoxCoxXY-(B*AgeFactor + C*IntakeDay))^2)/(2*Scale)+(Lambda.Value-1)*log(IntakeAmt),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?fixed = A - B + C ~ 1,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = A ~ 1|RespondentID,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?start=c(A=1,B=1,C=1)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)
>
> The test model immediately above gives the error:
> "Error in chol.default((value + t(value))/2) :
> ? ? ? ? ? ?the leading minor of order 1 is not positive definite"
>
> Which I think is occurring because of the warning messages:
> 1: In Ops.ordered(B, AgeFactor) :
> ? ? ? ? ? ?'*' is not meaningful for ordered factors
> 2: In Ops.factor(C, IntakeDay) : * not meaningful for factors
>
> Given that I have 3 AgeFactor and 1 IntakeDay parameters, as there are 4 and 2 factor levels respectively (lowest level omitted for each), how do I specify the nlme model and fixed effects without changing to dummy variable coding?
>
> Sorry for all my questions on this, at least this time I get the error on step 14 of the traceback() so I feel I am coming to grips with nlme slowly.

Well, as the messages say, it doesn't make sense to multiply AgeFactor
by B and IntakeDay by C.

You really should start from the beginning and decide what the model
you are trying to fit is.  It must be an expression in which every
name is a parameter or a covariate name or the name of a function.
The names of the parameters are determined by the names of the start
argument.  The names of the covariates are those in Male.Group.  Do
these include IntakeAmt, Scale and Lambda?

Also, it is unusual and generally misguided to include IntakeAmt on
both the left and the right hand side of the formula.

We don't know why you are using the expressions that you are and it
probably won't be productive to continue to guess what form the model
expression should be then report error messages to us.



From davef at otter-rsch.com  Thu Jan 12 20:54:26 2012
From: davef at otter-rsch.com (dave fournier)
Date: Thu, 12 Jan 2012 11:54:26 -0800
Subject: [R-sig-ME] glmmADMB v 0.7.1
In-Reply-To: <4F0F17FA.2090403@mail.missouri.edu>
References: <4F0F17FA.2090403@mail.missouri.edu>
Message-ID: <4F0F3A72.5080808@otter-rsch.com>

When you run glmmadmb in R, R writes ADMB's files and runs the glmmadmb 
program
via system(). There is an option to keep these files and then to run 
glmmadmb from outside
R. You can then read the results back into R. Doing it this way (i.e. 
exiting R before
running glmmadmb) will give you a bit more memory. It may be enough.
That is the simplest first thing to try I think.



From Stefan.Schreiber at ales.ualberta.ca  Thu Jan 12 21:02:50 2012
From: Stefan.Schreiber at ales.ualberta.ca (Schreiber, Stefan)
Date: Thu, 12 Jan 2012 13:02:50 -0700
Subject: [R-sig-ME] TukeyHSD on aov(fit.lmer)
In-Reply-To: <4F0DF811.20303@gmail.com>
References: <70F02259E17B6242B15D81E58EB7EB1107B35E6D@afhe-ex.afhe.ualberta.ca>
	<4F0DF811.20303@gmail.com>
Message-ID: <70F02259E17B6242B15D81E58EB7EB11087B5A1E@afhe-ex.afhe.ualberta.ca>

Hi all,

I have the following mixed model for my data (Thanks Ben!):

lmer.fit<- response ~ group*climate + (1|block) + (1|genotype) + (1|id)

Here's the summary:

Linear mixed model fit by REML 
Formula: response ~ group*climate + (1|block) + (1|genotype) + (1|id) 
   Data: plc 
  AIC  BIC logLik deviance REMLdev
 1275 1325   -622     1296    1243
Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept)  10.25    3.20   
 clone    (Intercept)   2.75    1.66   
 rep      (Intercept)   5.34    2.31   
 Residual             148.21   12.17   
Number of obs: 168, groups: id, 56; genotype, 7; block, 5

Then I ran TukeyHSD(aov(lmer.fit)) and it gives me no error and an
output that "looks" ok. However, I am uncertain whether this is correct
to do, or not.

Here is an made up example:
d.fr<-data.frame(id=rep(1:16,3),treat1=rep(as.factor(LETTERS[1:3]),each=
16),treat2=rep(as.factor(letters[4:7]),each=4),response=rnorm(48))
fit1<-lmer(response~treat1*treat2+(1|id),data=d.fr)
TukeyHSD(aov(fit1))

I hope to get some advice on whether this is a valid thing to do.

Thanks!
Stefan



From Michelle.Gosse at foodstandards.gov.au  Thu Jan 12 21:09:19 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Fri, 13 Jan 2012 07:09:19 +1100
Subject: [R-sig-ME] start values for starting parameters,
 factors [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4FB@EXCHANGE07.foodstandards.gov.au>

Hi Doug,

Thanks for replying and thanks also to Steve for his comments.

I agree with your comments below, and am following this point up with the people who made the request to use this method. In case anyone is interested, the method is outlined in this paper, section  3.2: http://www.stat.tamu.edu/~carroll/ftp/2011.papers.directory/NCIMethod_aspublished.pdf

I appreciate the time that people have put into this for me, it has helped me out a lot on the conceptual perspective as well as the nlme specification perspective.

Cheers
Michelle



-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Friday, January 13, 2012 8:51 AM
To: Gosse, Michelle
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] start values for starting parameters, factors [SEC=UNCLASSIFIED]

On Wed, Jan 11, 2012 at 9:13 PM, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi again,
>
> More reading later, and I have the following model with the log likelihood function specified:
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random= ~1|RespondentID)
>
> male.nlme <- nlme(IntakeAmt ~ log(1/sqrt(2*pi*(Scale^2))) +
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
> (-(A*BoxCoxXY-(B*AgeFactor +
> C*IntakeDay))^2)/(2*Scale)+(Lambda.Value-1)*log(IntakeAmt),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?fixed = A - B + C ~ 1,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = A ~ 1|RespondentID,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?start=fixef(male.lme2)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)
>
> The nlme syntax gives me the error:
> "Error in nlme.formula(IntakeAmt ~ log(1/sqrt(2 * pi * (Scale^2))) + (-(A * :
> ? ? ? ? ? ?starting values for the fixed component are not the correct length"
>
> Reading on the internet made me understand that this is because there needs to be 3 fixed component start parameters, as confirmed by the model below not giving that error:
> male.nlme <- nlme(IntakeAmt ~ log(1/sqrt(2*pi*(Scale^2))) +
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
> (-(A*BoxCoxXY-(B*AgeFactor +
> C*IntakeDay))^2)/(2*Scale)+(Lambda.Value-1)*log(IntakeAmt),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?fixed = A - B + C ~ 1,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = A ~ 1|RespondentID,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?start=c(A=1,B=1,C=1)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)
>
> The test model immediately above gives the error:
> "Error in chol.default((value + t(value))/2) :
> ? ? ? ? ? ?the leading minor of order 1 is not positive definite"
>
> Which I think is occurring because of the warning messages:
> 1: In Ops.ordered(B, AgeFactor) :
> ? ? ? ? ? ?'*' is not meaningful for ordered factors
> 2: In Ops.factor(C, IntakeDay) : * not meaningful for factors
>
> Given that I have 3 AgeFactor and 1 IntakeDay parameters, as there are 4 and 2 factor levels respectively (lowest level omitted for each), how do I specify the nlme model and fixed effects without changing to dummy variable coding?
>
> Sorry for all my questions on this, at least this time I get the error on step 14 of the traceback() so I feel I am coming to grips with nlme slowly.

Well, as the messages say, it doesn't make sense to multiply AgeFactor by B and IntakeDay by C.

You really should start from the beginning and decide what the model you are trying to fit is.  It must be an expression in which every name is a parameter or a covariate name or the name of a function.
The names of the parameters are determined by the names of the start argument.  The names of the covariates are those in Male.Group.  Do these include IntakeAmt, Scale and Lambda?

Also, it is unusual and generally misguided to include IntakeAmt on both the left and the right hand side of the formula.

We don't know why you are using the expressions that you are and it probably won't be productive to continue to guess what form the model expression should be then report error messages to us.

UNCLASSIFIED

**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}



From john.maindonald at anu.edu.au  Thu Jan 12 23:15:47 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 13 Jan 2012 09:15:47 +1100
Subject: [R-sig-ME] SE for predictions in lme
In-Reply-To: <CAKSASLC+DK9oWkx3Prz71t8=krNfTuJ1jOF-r2FgcY9ri6Ux+g@mail.gmail.com>
References: <CAKSASLC+DK9oWkx3Prz71t8=krNfTuJ1jOF-r2FgcY9ri6Ux+g@mail.gmail.com>
Message-ID: <61516561-3577-443C-9789-EF288C3CDF69@anu.edu.au>

On 12/01/2012, at 10:03 PM, marta rufino wrote:

> Hi,
> 
> This topic has been discussed in several posts in this list before, but I
> could not completely understand if there was a clear answer. Also, I
> searched the books (Pinheiro, Faraway and Zuur) I could not reach a
> conclusion. I guess I am missing some point here :) so I am sorry for
> recover this topic again.
> I will start by providing an example code and then put my questions, as
> clear as possible.
> 
> Following the code provided in previous posts (see for example):
> http://markmail.org/message/lhtols3t5wrleewc
> using another dataset, for example:
> 
>            # Example to ask the list
>            data(iris)
>            kk=data.frame(stack(iris[,1:3]),sp=rep(iris$Species),
> subject=rep(1:dim(iris)[1],3))
>            summary(kk)
>            require(nlme)
>            kk2=lme(values~ind*sp, kk, weights = varIdent(form= ~ 1|ind),
> random=~1|subject)
>            kk2
>            anova(kk2) #all factors are significant.
> 
>            # Calculate model predictions    and plot it ==== this is from
> Ben's code
>                newdat <- expand.grid(ind=levels(kk$ind), sp=levels(kk$sp))
>                newdat$pred <- predict(kk2, newdat, level = 0)
> 
>                Designmat <- model.matrix(eval(eval(kk2$call$fixed)[-2]),
> newdat[-3])
>                predvar <- diag(Designmat %*% kk2$varFix %*% t(Designmat))
>                newdat$SE <- sqrt(predvar)

Prediction for a new observation on one of the subjects in the sample data

>                newdat$SE2 <- sqrt(predvar+kk2$sigma^2)

Prediction for a new observation on a new subject

Exercise: What is the SE for the average of 3 observations on a new subject?

(It is the way the SE changes depending on what exactly one is predicting
that raises questions about what exactly AIC and related statistics are 
designed to optimise, when such statistics are used to compare models.)

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

>                #install.packages("ggplot2")
>                library(ggplot2)
>                pd <- position_dodge(width=0.4)
>                ggplot(newdat,aes(x=ind, y=pred, colour=sp))+
>                geom_point(aes(x=kk$ind,y=kk$values, colour=kk$sp),
> size=.3, shape=2, position=pd)+
>                geom_point(position=pd)+
>                geom_linerange(aes(ymin=pred-2*SE2,
> ymax=pred+2*SE2),col="red", position=pd)+
>                geom_errorbar(aes(ymin=pred-2*SE, ymax=pred+2*SE),
> col="black", width=.1, position=pd)
> 
> So, we can see the actual points, the SE and SE2 modelled and respective
> means, I think.
> My questions are:
> What is exactly the SE and SE2 (how do we call it in an article legend, for
> example) and how can these be interpreted?
> Can we consider that when the 'lines' do not overlap the species (or
> varieties) are different?
> The SE2 are larger than the actual data in setosa/Petal.Length and overlap
> in the remaining variaties--- how can these show significant differences
> than?
> 
> I think I am getting confused or I am missing something important, because
> the results do not appear congruent in my head.
> 
> Any help will be much appreciated,
> 
> All the best,
> Marta
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From chris at trickysolutions.com.au  Thu Jan 12 23:42:44 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 13 Jan 2012 09:42:44 +1100
Subject: [R-sig-ME] glmmADMB v 0.7.1
In-Reply-To: <4F0F17FA.2090403@mail.missouri.edu>
References: <4F0F17FA.2090403@mail.missouri.edu>
Message-ID: <0b578b720fcc8d94403cca1de8888e6c@mail.gmail.com>

Hi Chris,

If it's getting upto 2GB that's about the limit on your machine unless U
manually change it (see ?memory-limit for more info)

Have u tried removing all unnecessary objects from the workspace and then
garbage collecting: gc()?

The following code may help:

# Set Memory parameters
# Help on memory limits
?Memory-limits
# Remove unneccessary objects (in this call everything)
rm(list=ls())
ls()
# Garbage collection, this can increase available memory after a call to
rm()
gc()
# Set Memory Limit to Max on a 4GB machine
memory.limit(size=4095)
# report memory limit
memory.limit(size=NA)
# maximum amount of memory obtained from the OS is reported
memory.limit(size=TRUE)
# amount currently in use
memory.limit(size=FALSE)

Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Christopher
Rota
Sent: Friday, 13 January 2012 4:27 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] glmmADMB v 0.7.1

Dear R Users,

I am running into some trouble when using glmmADMB version 0.7.1 and am
hoping someone in the R community may have some insight.

I am trying to fit a rather large negative binomial mixed-effects
model.  I have 3980 observations (counts of foraging attempts).  My
'global' model has 17 fixed effects and 2 random effects.  Fixed effects
consist of both continuous and categorical variables.  Each categorical
variable has at least 22 observations, most have considerably more.  One
random effect is an 'observer' effect consisting of 11 different
observers.  Each observer made at least 29 observations, but most made
considerably more.  The other random effect in an 'individual bird'
effect consisting of 78 individual birds.  There are at least 20
observations made on each bird.

Here is my call to glmmadmb:
fit <- glmmadmb(formula=count~BrnLight + BrnMod + BrnMPB + BrnSev +
GrnHit + GryHit + RedHit + Autumn + Spring + Winter + Yr01 + Yr12 + Yr23
+ Yr34 + Yr45 + Est.DBH.in + Start.Time + (1|Color.Combo) +
(1|Observers), data=beh.data, family='nbinom')

The variables 'BrnLight' through 'RedHit' represent categorical
variables describing tree condition.  They are coded as dummy variables,
and one tree condition category (Green) is omitted from model
specification and interpreted as the intercept.  The season (Autumn,
Spring, Winter) and year (Yr01, etc.) variables are coded in an
identical manner (note that I also coded categorical variables as
factors, and encountered the same problem described below).  DBH and
Start.Time are continuous variables.

This global model runs for about 10 minutes, then fails with the
following message:
Memory allocation error -- Perhaps you are trying to allocate too much
memory in your program

When I monitor my computer performance with Windows Task Manager while
the model is running, I can watch Physical Memory Usage slowly tick up.
All of that increased memory use is attributed to glmmadmb.exe.  I will
watch memory use for this program tick up to about 1.7GB, and that is
when the model fails.  I am using a computer with a Windows Vista 32-bit
operating system with 4GB RAM.  Is the problem simply that I do not have
enough memory on my computer to run this model?  If indeed the problem
is a shortage of memory, is there any way to make glmmadmb.exe use
memory differently, or do I need to use a more powerful computer?

Thank you for any insight.

Chris Rota

--
Christopher Rota
Ph.D. Student

University of Missouri
Fisheries and Wildlife Science
302 Anheuser-Busch Natural Resources Building
Columbia, MO 65211

Office:  303O Anheuser-Busch Natural Resources Buildling
Email:  ctr4g2 at mail.missouri.edu
Phone:  573-239-6975
Website:  http://www.biosci.missouri.edu/avianecology/rota/index.html
Calendar:
http://www.google.com/calendar/embed?src=christopher.rota%40gmail.com&ctz=
America/Chicago

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Jan 13 16:52:02 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Jan 2012 09:52:02 -0600
Subject: [R-sig-ME] Fwd: lme4 and sample size
In-Reply-To: <CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
References: <6C86BD70D72CB449A189A18EED3037CA057EE65B@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
Message-ID: <CAO7JsnQ4rRgjQAU_aFzMmoUjjGAifo+qrYb+gg0s5LVY6Es9og@mail.gmail.com>

After saying I would cc: the list on this reply, I didn't.


---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Fri, Jan 13, 2012 at 9:51 AM
Subject: Re: lme4 and sample size
To: "Bouwmeester, W." <W.Bouwmeester at umcutrecht.nl>


I have taken the liberty of copying the reply to the
R-SIG-Mixed-Models at R-Project.org mailing list so that it will be
available in a searchable archive.

On Fri, Jan 13, 2012 at 9:37 AM, Bouwmeester, W.
<W.Bouwmeester at umcutrecht.nl> wrote:
> Dear professor Bates,
>
> I will incvestigate the required sample size to develop a prediction model in hierarchical data, using a simulation study. One of the model evaluation criteria will be whether the model converged. R will give warning messages if no or singular convergence appeared.
> Is it possible to evaluate model convergence from the cvg column in attr(mix.model,"dims")? Has this "cvg" anything to do with convergence?
>
> I saw this "cvg" output from attr(mix.model, "dims") in your publication on October 4, 2011, Linear mixed model implementation in lme4, page 6 and 20.

I would strongly recommend using lmer instead of lme to fit
heirarchical linear models in a simulation study. ?The lmer function
in the lme4 package is much faster and more reliable than the lme
function from the nlme package.

The current version of lme4 on CRAN can sometimes encounter a warning
about "false convergence". ?The version named lme4Eigen on the R-forge
site is, in our preliminary tests, more reliable and usually faster
than the released version. ?You do need to be able to build an R
package from source to be able to use the lme4Eigen at present.



From bates at stat.wisc.edu  Fri Jan 13 17:05:52 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Jan 2012 10:05:52 -0600
Subject: [R-sig-ME] lme4 and sample size
In-Reply-To: <6C86BD70D72CB449A189A18EED3037CA057EE66C@EXMB1501.ds.umcutrecht.nl>
References: <6C86BD70D72CB449A189A18EED3037CA057EE65B@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
	<6C86BD70D72CB449A189A18EED3037CA057EE66C@EXMB1501.ds.umcutrecht.nl>
Message-ID: <CAO7JsnSBCo4exTRgzCaB54udtM0RBQh668zc_NOqXpaRhH93fg@mail.gmail.com>

On Fri, Jan 13, 2012 at 9:58 AM, Bouwmeester, W.
<W.Bouwmeester at umcutrecht.nl> wrote:
> Dear professor Bates,
>
> I'am using the lmer function indeed. Can I use 'cvg' from the output attr(model, "dims") to evaluate convergence? (here, the object "model" is fitted with the lmer function)

Yes, but do bear in mind that the cvg indicator is from the optimizer,
which is nlminb in the case of the released lme4.  We have encountered
difficulties with nlminb failing to converge or giving the false
convergence message or getting stuck at boundary values.  We later
switched to the bobyqa optimizer from the minqa package and then to a
local implementation of the Nelder-Mead simplex optimizer.

Failure to converge is a property of the optimizer being used, not the
overall design of lme4.  It happens that good optimizers that are
available to Open Source projects are difficult to come by.

> Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
> Verzonden: vrijdag 13 januari 2012 16:51
> To: Bouwmeester, W.
> Onderwerp: Re: lme4 and sample size
>
> I have taken the liberty of copying the reply to the
> R-SIG-Mixed-Models at R-Project.org mailing list so that it will be
> available in a searchable archive.
>
> On Fri, Jan 13, 2012 at 9:37 AM, Bouwmeester, W.
> <W.Bouwmeester at umcutrecht.nl> wrote:
>> Dear professor Bates,
>>
>> I will incvestigate the required sample size to develop a prediction model in hierarchical data, using a simulation study. One of the model evaluation criteria will be whether the model converged. R will give warning messages if no or singular convergence appeared.
>> Is it possible to evaluate model convergence from the cvg column in attr(mix.model,"dims")? Has this "cvg" anything to do with convergence?
>>
>> I saw this "cvg" output from attr(mix.model, "dims") in your publication on October 4, 2011, Linear mixed model implementation in lme4, page 6 and 20.
>
> I would strongly recommend using lmer instead of lme to fit
> heirarchical linear models in a simulation study. ?The lmer function
> in the lme4 package is much faster and more reliable than the lme
> function from the nlme package.
>
> The current version of lme4 on CRAN can sometimes encounter a warning
> about "false convergence". ?The version named lme4Eigen on the R-forge
> site is, in our preliminary tests, more reliable and usually faster
> than the released version. ?You do need to be able to build an R
> package from source to be able to use the lme4Eigen at present.
> ------------------------------------------------------------------------------
>
> De informatie opgenomen in dit bericht kan vertrouwelijk zijn en is
> uitsluitend bestemd voor de geadresseerde. Indien u dit bericht onterecht
> ontvangt, wordt u verzocht de inhoud niet te gebruiken en de afzender direct
> te informeren door het bericht te retourneren. Het Universitair Medisch
> Centrum Utrecht is een publiekrechtelijke rechtspersoon in de zin van de W.H.W.
> (Wet Hoger Onderwijs en Wetenschappelijk Onderzoek) en staat geregistreerd bij
> de Kamer van Koophandel voor Midden-Nederland onder nr. 30244197.
>
> Denk s.v.p aan het milieu voor u deze e-mail afdrukt.
>
> ------------------------------------------------------------------------------
>
> This message may contain confidential information and ...{{dropped:12}}



From pharriso at uwaterloo.ca  Fri Jan 13 17:46:40 2012
From: pharriso at uwaterloo.ca (Philip Harrison)
Date: Fri, 13 Jan 2012 11:46:40 -0500
Subject: [R-sig-ME] SE for predictions in lme
Message-ID: <20120113114640.14594y0zdj0x1nwo@www.nexusmail.uwaterloo.ca>

Hi Marta,

My understanding of this is that the SE*2 gives 95% confidence  
intervals on predictions. You can add a bonferroni type adjustment by  
varying the *2 (which is really 1.96)

The SE2 gives prediction intervals. Confidence intervals of  
predictions tell you how well you have predicted the mean. Prediction  
intervals tell where you could expect the next to see the next value  
sampled. The key point is that the prediction interval tells you about  
the distribution of values, not the uncertainty in determining the  
population mean.

Therefore as far as I can tell, the CIs are the most useful for making  
inferences about differences in the conditional means/BLUPs

You can also use the function predictSE.lme from the package  
AICcmodavg to produce prediction and SEs from an lme object and then  
calculate CIs accordingly. I like this method as it gives a reference  
to the method:

"predictSE.lme? computes predicted values based on fixed effects and  
associated standard errors.
Standard errors are approximated using the delta method (Oehlert 1992)"

These two methods result in identical predictions and almost identical  
SEs for my dataset

Some confusion arise for me because the predict.lme function calls the  
prediction Best linear Unbiased Predictions (BLUPs) which combine  
random and fixed effects, and the predictSE.lme function states that  
these predictions do not incorporate the random effects. Yet they give  
identical predictions for me.

Hope this helps

Phil


Quoting marta rufino <marta.m.rufino at gmail.com>:

> Hi,
>
> This topic has been discussed in several posts in this list before, but I
> could not completely understand if there was a clear answer. Also, I
> searched the books (Pinheiro, Faraway and Zuur) I could not reach a
> conclusion. I guess I am missing some point here :) so I am sorry for
> recover this topic again.
> I will start by providing an example code and then put my questions, as
> clear as possible.
>
> Following the code provided in previous posts (see for example):
> http://markmail.org/message/lhtols3t5wrleewc
> using another dataset, for example:
>
>            # Example to ask the list
>            data(iris)
>            kk=data.frame(stack(iris[,1:3]),sp=rep(iris$Species),
> subject=rep(1:dim(iris)[1],3))
>            summary(kk)
>            require(nlme)
>            kk2=lme(values~ind*sp, kk, weights = varIdent(form= ~ 1|ind),
> random=~1|subject)
>            kk2
>            anova(kk2) #all factors are significant.
>
>            # Calculate model predictions    and plot it ==== this is from
> Ben's code
>                newdat <- expand.grid(ind=levels(kk$ind), sp=levels(kk$sp))
>                newdat$pred <- predict(kk2, newdat, level = 0)
>
>                Designmat <- model.matrix(eval(eval(kk2$call$fixed)[-2]),
> newdat[-3])
>                predvar <- diag(Designmat %*% kk2$varFix %*% t(Designmat))
>                newdat$SE <- sqrt(predvar)
>                newdat$SE2 <- sqrt(predvar+kk2$sigma^2)
>
>                #install.packages("ggplot2")
>                library(ggplot2)
>                pd <- position_dodge(width=0.4)
>                ggplot(newdat,aes(x=ind, y=pred, colour=sp))+
>                geom_point(aes(x=kk$ind,y=kk$values, colour=kk$sp),
> size=.3, shape=2, position=pd)+
>                geom_point(position=pd)+
>                geom_linerange(aes(ymin=pred-2*SE2,
> ymax=pred+2*SE2),col="red", position=pd)+
>                geom_errorbar(aes(ymin=pred-2*SE, ymax=pred+2*SE),
> col="black", width=.1, position=pd)
>
> So, we can see the actual points, the SE and SE2 modelled and respective
> means, I think.
> My questions are:
> What is exactly the SE and SE2 (how do we call it in an article legend, for
> example) and how can these be interpreted?
> Can we consider that when the 'lines' do not overlap the species (or
> varieties) are different?
> The SE2 are larger than the actual data in setosa/Petal.Length and overlap
> in the remaining variaties--- how can these show significant differences
> than?
>
> I think I am getting confused or I am missing something important, because
> the results do not appear congruent in my head.
>
> Any help will be much appreciated,
>
> All the best,
> Marta
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



Philip Harrison MSc
PhD student (Fisheries Ecology)
Department of Biology
University of Waterloo
200 University Avenue West
Waterloo, Ontario, Canada
N2L 3G1
Cell:226-808-2309
Email:pharriso at uwaterloo.ca



From bbolker at gmail.com  Fri Jan 13 18:32:17 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Jan 2012 17:32:17 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB v 0.7.1
References: <4F0F17FA.2090403@mail.missouri.edu>
	<4F0F3A72.5080808@otter-rsch.com>
Message-ID: <loom.20120113T180228-511@post.gmane.org>

dave fournier <davef at ...> writes:

> 
> When you run glmmadmb in R, R writes ADMB's files and runs the glmmadmb 
> program
> via system(). There is an option to keep these files and then to run 
> glmmadmb from outside
> R. You can then read the results back into R. Doing it this way (i.e. 
> exiting R before
> running glmmadmb) will give you a bit more memory. It may be enough.
> That is the simplest first thing to try I think.
> 
> 
  specifically, you should be able to specify 

..., save.dir="tmp", admb.opts=admbControl(run=FALSE), ...

which will create the temp directory with everything you need in it.
Then run ADMB from the terminal/command window.

  Here's an example:

data(bacteria,package="MASS")
bacteria$present <- as.numeric(bacteria$y)-1
## run to generate files
glmmadmb(present ~ trt + I(week > 2), random = ~ 1 | ID,
                     family = "binomial", data = bacteria,
         save.dir="tmp",admb.opts=admbControl(run=FALSE),
         debug=TRUE)
## now run glmmadmb outside of R ...
## ./glmmadmb -maxfn 500 -maxph 5 -noinit -shess
## run to read in data
result <- glmmadmb(present ~ trt + I(week > 2), random = ~ 1 | ID,
                     family = "binomial", data = bacteria,
         save.dir="tmp",admb.opts=admbControl(run=FALSE))



From bbolker at gmail.com  Fri Jan 13 18:35:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Jan 2012 17:35:44 +0000 (UTC)
Subject: [R-sig-ME] In II[, ii] + REmat$codes[[i]] :
References: <CAKz8Hv=jZvhNxijKV-X7eWkViTCfVghe0HdoPGEcRCzzpBoyPw@mail.gmail.com>
Message-ID: <loom.20120113T183322-344@post.gmane.org>

Giulia Dotti Sani <giulia.dottisani at ...> writes:

> I'm running the following poisson and I keep getting the same error.
> M01 <- glmmadmb(chi_hh ~ age_m + educ +(1 |country_y), data=data,
> family="poisson")
> 
> In II[, ii] + REmat$codes[[i]] :
>   longer object length is not a multiple of shorter object length
> 
> I think it has to do with the grouping variable but I don't see what's
> the problem.

  Not reproducible ... post the data somewhere or send them to me?
  Results of sessionInfo() please (i.e. what version of glmmADMB
are you using?)
  For what it's worth, for this problem you could also use glmer,
which might be faster.  glmmADMB really comes into its own for
extended models (zero-inflated or truncated, negative binomial, Beta, etc.) that
glmer can't handle.

  Ben Bolker



From bbolker at gmail.com  Fri Jan 13 19:44:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Jan 2012 13:44:21 -0500
Subject: [R-sig-ME] In II[, ii] + REmat$codes[[i]] :
In-Reply-To: <CAKz8Hv=5Usr9FwFVJO6CjUzFVGfA4pvv5_wEXJU5O6thPY2cbA@mail.gmail.com>
References: <CAKz8Hv=jZvhNxijKV-X7eWkViTCfVghe0HdoPGEcRCzzpBoyPw@mail.gmail.com>	<loom.20120113T183322-344@post.gmane.org>
	<CAKz8Hv=5Usr9FwFVJO6CjUzFVGfA4pvv5_wEXJU5O6thPY2cbA@mail.gmail.com>
Message-ID: <4F107B85.3000602@gmail.com>

 [cc'ing back to r-sig-mixed-models]

  A few things:

* the basic problem is that you have NA values in your data: these get
removed automatically in one place in the code and not in the other,
hence the length mismatch.  This is not absolutely trivial to fix
automatically -- the fixed and random effect predictors are handled
separately, and there may be extra variables in the data that should be
disregarded completely -- but in the meantime I have at least put in an
informative warning message in this case (for the next release).  The
simplest solution is to use na.omit() to get rid of these values (which
can't be used in the fit anyway).

 * it's not advisable to fit a random effect to a factor with only three
levels, although in this case it seems not to do anything disastrous
(ADMB does issue one warning, although in this case it seems harmless)

 * for this problem glmer works *much* faster than glmmADMB (glmmADMB
used to work faster, but we made it slower in the process of adapting it
to be more general and flexible) -- about 2 seconds vs. 2 minutes on my
computer.  quasi-likelihood is unreliable (and no longer possible) in
glmer, but you should check http://glmm.wikidot.com/faq for other
alternatives for handling overdispersion [and for more on the previous
point about numbers of levels of random effects] (although it is still
true that glmmADMB allows a wider range of options than glmer)

 * the data set you sent didn't have a 'chi_hh' variable in it, only an
'ave_chi_hh' variable -- I used it instead for the fitting. *However*,
ave_chi_hh is not integer-valued.  Unless you're absolutely sure you
know what you're doing, you shouldn't use a Poisson GLMM to fit
non-integer data.  (I'm adding a test and a warning for this too.)

library(glmmADMB)
## best not to call data 'data', this masks a built-in R function
ddat <- read.csv("dottisani_data.csv")
summary(ddat)
ddat <- na.omit(ddat)

library(lme4)
t1 <- system.time(g1 <- glmer(ave_chi_hh ~ age + educ +(1 |country_y),
data=ddat,
         family="poisson"))

t2 <- system.time(g2 <- glmmadmb(ave_chi_hh ~ age + educ +(1
|country_y), data=ddat,
         family="poisson"))


On 12-01-13 01:08 PM, Giulia Dotti Sani wrote:
> Hello and thanks for the answer
> I'm attaching a subset of the data I'm using.  I was using lmer, but I
> moved to glmm to tackle overdispersion, since I've been reading that
> the quasipoisson families for lmer are not reliable.
> 
> thank you
> Giulia
> 
> 
>>  sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
> [5] LC_TIME=Italian_Italy.1252
> 
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods
> [8] base
> 
> other attached packages:
>  [1] glmmADMB_0.7.2   R2admb_0.7.5     car_2.0-11       survival_2.36-10
>  [5] nnet_7.3-1       foreign_0.8-48   arm_1.4-14       abind_1.4-0
>  [9] R2WinBUGS_2.1-18 coda_0.14-6      MASS_7.3-16      lmtest_0.9-29
> [13] zoo_1.7-6        lme4_0.999375-42 Matrix_1.0-2     lattice_0.20-0
> 
> loaded via a namespace (and not attached):
> [1] grid_2.14.1   nlme_3.1-102  stats4_2.14.1 tools_2.14.1
> 
> 
> On Fri, Jan 13, 2012 at 6:35 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Giulia Dotti Sani <giulia.dottisani at ...> writes:
>>
>>> I'm running the following poisson and I keep getting the same error.
>>> M01 <- glmmadmb(chi_hh ~ age_m + educ +(1 |country_y), data=data,
>>> family="poisson")
>>>
>>> In II[, ii] + REmat$codes[[i]] :
>>>   longer object length is not a multiple of shorter object length
>>>
>>> I think it has to do with the grouping variable but I don't see what's
>>> the problem.
>>
>>  Not reproducible ... post the data somewhere or send them to me?
>>  Results of sessionInfo() please (i.e. what version of glmmADMB
>> are you using?)
>>  For what it's worth, for this problem you could also use glmer,
>> which might be faster.  glmmADMB really comes into its own for
>> extended models (zero-inflated or truncated, negative binomial, Beta, etc.) that
>> glmer can't handle.
>>
>>  Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From mrmetz at ucdavis.edu  Fri Jan 13 21:41:14 2012
From: mrmetz at ucdavis.edu (Margaret Metz)
Date: Fri, 13 Jan 2012 12:41:14 -0800
Subject: [R-sig-ME] specifying/interpreting random effects with near-zero
	variance in glmer()
Message-ID: <A9F0FB10-577E-4719-80C2-CDE2E0B19987@ucdavis.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120113/ea160f77/attachment-0001.pl>

From bbolker at gmail.com  Fri Jan 13 23:37:52 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Jan 2012 17:37:52 -0500
Subject: [R-sig-ME] In II[, ii] + REmat$codes[[i]] :
In-Reply-To: <CAKz8HvmaZ97CEOOVBiiDX7Sfn_dBcZCQ2HvTP2iqAnvrE-Y1_A@mail.gmail.com>
References: <CAKz8Hv=jZvhNxijKV-X7eWkViTCfVghe0HdoPGEcRCzzpBoyPw@mail.gmail.com>	<loom.20120113T183322-344@post.gmane.org>	<CAKz8Hv=5Usr9FwFVJO6CjUzFVGfA4pvv5_wEXJU5O6thPY2cbA@mail.gmail.com>	<4F107B85.3000602@gmail.com>
	<CAKz8HvmaZ97CEOOVBiiDX7Sfn_dBcZCQ2HvTP2iqAnvrE-Y1_A@mail.gmail.com>
Message-ID: <4F10B240.5020104@gmail.com>


  [cc'd back to r-sig-mixed-models again: I strongly prefer to have
these conversations on the record so they can be archived and so that
others can benefit from them]

On 12-01-13 05:13 PM, Giulia Dotti Sani wrote:
> Thank you for the suggestions,
> 
> *Indeed getting rid of NA's solved that problem.
> 
> * I actually have 37 groups, but it didn't seem useful to send you a
> gigantic dataset for this purpose. I apologize if this was misleading.
> 
> *I'm trying out glmmPQL for overdispersion at the moment to see if
> works faster (and it seems to)

  I'm sure glmmPQL is faster than glmmADMB for these problems, but I
repeat that there are at least some options (the primary one being
adding an observation-level random effect) for handling overdispersion
in glmer.  Furthermore, in general the Laplace approximation (glmer's
default algorithm is more accurate than PQL, and AGQ (an option with
glmer) is more accurate still, although it may not matter much in your
case (I would definitely do at least a brief comparison between the
results of the different methods on a test data set to see how much they
differ).

> *I'm using a Poisson with non integers beacause the dependent var is
> the ratio of time in a / time in b. It necessarily has values between
> 0 and 1, but also greater than 1. time-use data literature suggests to
> use the poisson because it wouldn't make sense to have negative
> estimates.

  I won't say this makes *no* sense, but I claim it's not necessarily
sensible.  If you're really analyzing ratios then beta regression has a
better theoretical foundation (it is supported in glmmADMB, although not
in glmer), although it's not without its practical problems.  Gamma
regression (supported in both glmmADMB and glmer, although somewhat
finicky in glmer) also assumes a non-negative response, although it
assumes a continuous response (which seems more sensible).  Log-normal
(i.e. simply transform the data) is also a possibility.
  Looking at the marginal distribution of your response variable, it
seems to have values up to 57?  Are these on a percentage scale?

  I wonder if the zeros are a different category or simply represent
censoring/lack of resolution ...

ggplot(ddat,aes(x=age,y=0.001+ave_chi_hh,colour=country_y))+stat_sum(alpha=0.3)+geom_smooth()+facet_wrap(~educ)+
  scale_y_log10()+theme_bw()


> 
> 
> On Fri, Jan 13, 2012 at 7:44 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>  [cc'ing back to r-sig-mixed-models]
>>
>>  A few things:
>>
>> * the basic problem is that you have NA values in your data: these get
>> removed automatically in one place in the code and not in the other,
>> hence the length mismatch.  This is not absolutely trivial to fix
>> automatically -- the fixed and random effect predictors are handled
>> separately, and there may be extra variables in the data that should be
>> disregarded completely -- but in the meantime I have at least put in an
>> informative warning message in this case (for the next release).  The
>> simplest solution is to use na.omit() to get rid of these values (which
>> can't be used in the fit anyway).
>>
>>  * it's not advisable to fit a random effect to a factor with only three
>> levels, although in this case it seems not to do anything disastrous
>> (ADMB does issue one warning, although in this case it seems harmless)
>>
>>  * for this problem glmer works *much* faster than glmmADMB (glmmADMB
>> used to work faster, but we made it slower in the process of adapting it
>> to be more general and flexible) -- about 2 seconds vs. 2 minutes on my
>> computer.  quasi-likelihood is unreliable (and no longer possible) in
>> glmer, but you should check http://glmm.wikidot.com/faq for other
>> alternatives for handling overdispersion [and for more on the previous
>> point about numbers of levels of random effects] (although it is still
>> true that glmmADMB allows a wider range of options than glmer)
>>
>>  * the data set you sent didn't have a 'chi_hh' variable in it, only an
>> 'ave_chi_hh' variable -- I used it instead for the fitting. *However*,
>> ave_chi_hh is not integer-valued.  Unless you're absolutely sure you
>> know what you're doing, you shouldn't use a Poisson GLMM to fit
>> non-integer data.  (I'm adding a test and a warning for this too.)
>>
>> library(glmmADMB)
>> ## best not to call data 'data', this masks a built-in R function
>> ddat <- read.csv("dottisani_data.csv")
>> summary(ddat)
>> ddat <- na.omit(ddat)
>>
>> library(lme4)
>> t1 <- system.time(g1 <- glmer(ave_chi_hh ~ age + educ +(1 |country_y),
>> data=ddat,
>>         family="poisson"))
>>
>> t2 <- system.time(g2 <- glmmadmb(ave_chi_hh ~ age + educ +(1
>> |country_y), data=ddat,
>>         family="poisson"))
>>
>>
>> On 12-01-13 01:08 PM, Giulia Dotti Sani wrote:
>>> Hello and thanks for the answer
>>> I'm attaching a subset of the data I'm using.  I was using lmer, but I
>>> moved to glmm to tackle overdispersion, since I've been reading that
>>> the quasipoisson families for lmer are not reliable.
>>>
>>> thank you
>>> Giulia
>>>
>>>
>>>>  sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
>>> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
>>> [5] LC_TIME=Italian_Italy.1252
>>>
>>> attached base packages:
>>> [1] splines   stats     graphics  grDevices utils     datasets  methods
>>> [8] base
>>>
>>> other attached packages:
>>>  [1] glmmADMB_0.7.2   R2admb_0.7.5     car_2.0-11       survival_2.36-10
>>>  [5] nnet_7.3-1       foreign_0.8-48   arm_1.4-14       abind_1.4-0
>>>  [9] R2WinBUGS_2.1-18 coda_0.14-6      MASS_7.3-16      lmtest_0.9-29
>>> [13] zoo_1.7-6        lme4_0.999375-42 Matrix_1.0-2     lattice_0.20-0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.14.1   nlme_3.1-102  stats4_2.14.1 tools_2.14.1
>>>
>>>
>>> On Fri, Jan 13, 2012 at 6:35 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>> Giulia Dotti Sani <giulia.dottisani at ...> writes:
>>>>
>>>>> I'm running the following poisson and I keep getting the same error.
>>>>> M01 <- glmmadmb(chi_hh ~ age_m + educ +(1 |country_y), data=data,
>>>>> family="poisson")
>>>>>
>>>>> In II[, ii] + REmat$codes[[i]] :
>>>>>   longer object length is not a multiple of shorter object length
>>>>>
>>>>> I think it has to do with the grouping variable but I don't see what's
>>>>> the problem.
>>>>
>>>>  Not reproducible ... post the data somewhere or send them to me?
>>>>  Results of sessionInfo() please (i.e. what version of glmmADMB
>>>> are you using?)
>>>>  For what it's worth, for this problem you could also use glmer,
>>>> which might be faster.  glmmADMB really comes into its own for
>>>> extended models (zero-inflated or truncated, negative binomial, Beta, etc.) that
>>>> glmer can't handle.
>>>>
>>>>  Ben Bolker
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From bbolker at gmail.com  Sat Jan 14 01:49:38 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 14 Jan 2012 00:49:38 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?specifying/interpreting_random_effects_with_?=
	=?utf-8?q?near-zero=09variance_in_glmer=28=29?=
References: <A9F0FB10-577E-4719-80C2-CDE2E0B19987@ucdavis.edu>
Message-ID: <loom.20120114T013651-497@post.gmane.org>

Margaret Metz <mrmetz at ...> writes:

[snip]
 
> I am using glmer() and a logit link for the survival model,
> including fixed factors of 3 topographic models ("topo1", "topo2",
> and "topo3" for simplicity), starting height ("ht") I have 130+
> species ("sp") found at 200 census stations ("station").  Not all
> species are found at all stations, and the sample size per species
> ranges from 10 - 1200 individuals (and I could restrict these
> further to ones with a sample size greater than some threshold).

  The topo variables are continuous, right?

  You probably don't need to -- this is one of the strengths of 
the mixed modeling approach.

>  I would like to know whether the topographic variables are
> significant predictors of mortality while including the random
> factors of census station to account for non-independence of
> seedlings at the same location (which have the same topo
> measurements) and species to allow for variation in species'
> responses.  I expect that both the slope and intercept of species'
> responses to each variable could be quite different.  To allow for
> different slopes/intercepts among species, I have centered the
> continuous variables and specified the model as:

 
> glmer(survival ~ topo1 + topo2 + topo3 + ht + 
> (0 + topo1 | sp) + (0 + topo2 | sp) + (0 + topo3 | sp) + (1 | sp) + 
> (1 | station), data=seedlingdata, family=binomial)

  This looks reasonable, you might want to check for overdispersion.

> Questions: When I do this, there is a random intercept for station,
> a random intercept for species, and then random slopes among species
> for the relationship with the topographic variables as follows in
> the model output.  I believe this is allowing for the variation
> among species that I intend, but would like confirmation of this
> specification vs. something like (topo1 | sp) or (1 + topo1 | sp) as
> someone else has suggested to me.

(topo1 | sp) is equivalent to (1 | topo1 | sp) (as
(0 + topo1 | sp) is equivalent to (topo1 - 1 | sp)

  If you have enough data you could try

(topo1 + topo2 + topo3 | sp ) 

which allows for correlation among the effects of the topographic
variables -- although you can run out of data pretty quickly in
some cases, and it sounds from stuff below as though you're running
low on signal anyway.  (This model has (n+1)*(n+2)/2 = 10 parameters --
4 variances (topo[1-3] plus intercept) and 6 covariances -- as opposed
to the 4 variances of the model you are using.) (I'm not counting
the station variable in these totals.)
 
> Any version of these models that I have run results in significant
> fixed factors and zero or near-zero variances for the random
> effects.  I interpret this to mean that the topographic variables
> are important predictors of seedling mortality, but that the
> relationship does not vary among species groups nor census
> locations.  Is this your interpretation too or need I worry about
> model specification or the sample size or variance structure of my
> variables?

   This is a reasonable interpretation.  However, be aware that this
is signal-to-noise / sample-size dependent.  There could be (is, by
definition, in an ecological system) some among-species and
among-station variance that you just can't detect with this data set.
(In a classical model with a balanced, nested, etc. design you would
probably just find a small (non-significant) variance in this case,
rather than a practically-zero one -- on the other hand, there are
other classical models where you would actually estimate a *negative*
variance.)

>  A suggestion was made to confirm a lack of spatial autocorrelation
> in the residuals of this model, but I am not sure that is
> appropriate given the inclusion of the random effect of census
> station and the fixed effects of topography, which are shared by
> seedlings at the same station.  Can anyone suggest an appropriate
> reference to support or refute this suggestion?

  I don't have a reference but I would suggest that checking for
spatial autocorrelation might be worthwhile. Spatial autocorrelation
would detect the effects of _unmeasured_ covariates that were more
similar among nearby stations.


> Finally, if the response to topography DID significantly vary among
> species, where in this model would I see it?  In a large variance
> for the species slopes or intercept?  
 
  Exactly (variance among species in responses to topo1, topo2, topo3)

Or would I need to include
> species as a fixed factor crossed with the topographic variables?

  (topo1 | sp) is effectively crossing topo with species.

  I would consider looking (at least graphically) for evidence
of nonlinearity in the responses to the continuous variables ...
you could fit a GAM without *too* much extra effort, and with
this size dataset it might produce interesting results.



From bates at stat.wisc.edu  Sat Jan 14 17:27:41 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 14 Jan 2012 10:27:41 -0600
Subject: [R-sig-ME] specifying/interpreting random effects with
 near-zero variance in glmer()
In-Reply-To: <loom.20120114T013651-497@post.gmane.org>
References: <A9F0FB10-577E-4719-80C2-CDE2E0B19987@ucdavis.edu>
	<loom.20120114T013651-497@post.gmane.org>
Message-ID: <CAO7JsnRjZ2=wcZNMYuAxuHQKBj8Leaon6d4=hUWcdmJzSyndww@mail.gmail.com>

On Fri, Jan 13, 2012 at 6:49 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Margaret Metz <mrmetz at ...> writes:
>
> [snip]
>
>> I am using glmer() and a logit link for the survival model,
>> including fixed factors of 3 topographic models ("topo1", "topo2",
>> and "topo3" for simplicity), starting height ("ht") I have 130+
>> species ("sp") found at 200 census stations ("station"). ?Not all
>> species are found at all stations, and the sample size per species
>> ranges from 10 - 1200 individuals (and I could restrict these
>> further to ones with a sample size greater than some threshold).
>
> ?The topo variables are continuous, right?
>
> ?You probably don't need to -- this is one of the strengths of
> the mixed modeling approach.
>
>> ?I would like to know whether the topographic variables are
>> significant predictors of mortality while including the random
>> factors of census station to account for non-independence of
>> seedlings at the same location (which have the same topo
>> measurements) and species to allow for variation in species'
>> responses. ?I expect that both the slope and intercept of species'
>> responses to each variable could be quite different. ?To allow for
>> different slopes/intercepts among species, I have centered the
>> continuous variables and specified the model as:
>
>
>> glmer(survival ~ topo1 + topo2 + topo3 + ht +
>> (0 + topo1 | sp) + (0 + topo2 | sp) + (0 + topo3 | sp) + (1 | sp) +
>> (1 | station), data=seedlingdata, family=binomial)
>
> ?This looks reasonable, you might want to check for overdispersion.
>
>> Questions: When I do this, there is a random intercept for station,
>> a random intercept for species, and then random slopes among species
>> for the relationship with the topographic variables as follows in
>> the model output. ?I believe this is allowing for the variation
>> among species that I intend, but would like confirmation of this
>> specification vs. something like (topo1 | sp) or (1 + topo1 | sp) as
>> someone else has suggested to me.
>
> (topo1 | sp) is equivalent to (1 | topo1 | sp) (as
> (0 + topo1 | sp) is equivalent to (topo1 - 1 | sp)

To forestall future confusion, I think you meant that (topo1 | sp) is
equivalent to (1 + topo1 | sp)

> ?If you have enough data you could try
>
> (topo1 + topo2 + topo3 | sp )
>
> which allows for correlation among the effects of the topographic
> variables -- although you can run out of data pretty quickly in
> some cases, and it sounds from stuff below as though you're running
> low on signal anyway. ?(This model has (n+1)*(n+2)/2 = 10 parameters --
> 4 variances (topo[1-3] plus intercept) and 6 covariances -- as opposed
> to the 4 variances of the model you are using.) (I'm not counting
> the station variable in these totals.)
>
>> Any version of these models that I have run results in significant
>> fixed factors and zero or near-zero variances for the random
>> effects. ?I interpret this to mean that the topographic variables
>> are important predictors of seedling mortality, but that the
>> relationship does not vary among species groups nor census
>> locations. ?Is this your interpretation too or need I worry about
>> model specification or the sample size or variance structure of my
>> variables?
>
> ? This is a reasonable interpretation. ?However, be aware that this
> is signal-to-noise / sample-size dependent. ?There could be (is, by
> definition, in an ecological system) some among-species and
> among-station variance that you just can't detect with this data set.
> (In a classical model with a balanced, nested, etc. design you would
> probably just find a small (non-significant) variance in this case,
> rather than a practically-zero one -- on the other hand, there are
> other classical models where you would actually estimate a *negative*
> variance.)
>
>> ?A suggestion was made to confirm a lack of spatial autocorrelation
>> in the residuals of this model, but I am not sure that is
>> appropriate given the inclusion of the random effect of census
>> station and the fixed effects of topography, which are shared by
>> seedlings at the same station. ?Can anyone suggest an appropriate
>> reference to support or refute this suggestion?
>
> ?I don't have a reference but I would suggest that checking for
> spatial autocorrelation might be worthwhile. Spatial autocorrelation
> would detect the effects of _unmeasured_ covariates that were more
> similar among nearby stations.
>
>
>> Finally, if the response to topography DID significantly vary among
>> species, where in this model would I see it? ?In a large variance
>> for the species slopes or intercept?
>
> ?Exactly (variance among species in responses to topo1, topo2, topo3)
>
> Or would I need to include
>> species as a fixed factor crossed with the topographic variables?
>
> ?(topo1 | sp) is effectively crossing topo with species.
>
> ?I would consider looking (at least graphically) for evidence
> of nonlinearity in the responses to the continuous variables ...
> you could fit a GAM without *too* much extra effort, and with
> this size dataset it might produce interesting results.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From lontrenzo at gmail.com  Sat Jan 14 17:31:32 2012
From: lontrenzo at gmail.com (Lorenzo Quaglietta)
Date: Sat, 14 Jan 2012 16:31:32 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod(
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
	<loom.20120112T173419-47@post.gmane.org>
Message-ID: <loom.20120114T172522-882@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Isa Blasco <isa.blasco.costa at ...> writes:
> 
> > 
> > Hi,
> > I am using glmmADMB to fit a negative binomial model to my data. My
> > explanatory variable is an ordered factor with 10 levels and I also
> > included a random factor (numeric) and Zero inflation.
> > This is the code I used: m7 <- glmmadmb (abun~odist + (1|sl), data=apa,
> > zeroInflation=TRUE, family="nbinom")
> > 
> > When I run it I got this error:
> > Error in UseMethod("droplevels") :
> >   no applicable method for 'droplevels' applied to an object of class
> > "c('double', 'numeric')"
> > 
> > I do not know what the 'double' means but I checked the glmmADMB manual and
> > they use the same kind of variables in their example. Any guess on what it
> > is happening? How can I solve it?
> > I hope somebody knows!
> 
>   It means that it doesn't make sense to use a numeric variable as
> a grouping variable for a random factor (which is what you've done):
> if sl is a discrete numeric code that identifies groups of observations,
> then you should convert it to a factor.  If it's a continuous variable,
> then you need to go back and read/think some more about the meanings
> of random factors ...
> 
>   It also means that I made some changes to glmmADMB recently that
> got in the way of an informative error message (you should have
> received an error message that told you this).  I will try to 
> catch that error in a more informative way.
> 
>   Ben Bolker
> 
> 


Hi,

I'm having  a similar problem.

My model formula is:

glmmADMB1 <- glmmadmb(Fix ~ log_BIO_F * log_BIO_P + log_drs + fperp + log_pr +
log_la + (1 | ANIMALE) + (1 | ID) + (1 | Time), data=otters, zeroInflation=TRUE,
family="poisson").

and I got the following error message:

"Error in UseMethod("droplevels") : 
  no applicable method for 'droplevels' applied to an object of class
"c('integer', 'numeric')".

My random terms are not categorical nor fitted as factors. Which could be the
problem?

Many thanks in advance, best regards,

Lorenzo Quaglietta



From biowahl at gmail.com  Sun Jan 15 01:22:55 2012
From: biowahl at gmail.com (Colin Wahl)
Date: Sat, 14 Jan 2012 16:22:55 -0800
Subject: [R-sig-ME] Comparing results from glmer and glht
Message-ID: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>

I will try to make this concise.

Background: I am testing the effects of land use and forested riparian
buffers on stream invertebrates and in-stream variables. There are 4
watershed types (defined by 4 types of land use) and two riparian
types (forested and non). Percent EPT (relative abundance) was my main
response variable. I also measured a variety of in-stream variables
like temperature, nutrients, and toxicity. There are 72 observations
for invertebrates, and 24 for in-stream variables.

I am curious of how acceptable p values are from pairwise comparisons
using glht() from the multcomp package

I used glmer with a binomial error structure and an observation-level
random effect (to account for overdispersion), to model invertebrates:

modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs),
data=ept, family=binomial(link="logit"))

   AIC   BIC logLik deviance
 284.4 309.5 -131.2    262.4
Random effects:
 Groups     Name        Variance Std.Dev.
 obs        (Intercept) 0.30186  0.54942
 stream:rip (Intercept) 0.40229  0.63427
 stream     (Intercept) 0.12788  0.35760
Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12

Fixed effects:
                 Estimate Std. Error z value Pr(>|z|)
(Intercept)   -4.2906     0.4935   -8.694  < 2e-16 ***
wshd           -2.0557     0.7601  -2.705  0.00684 **
wshf            3.3575     0.6339   5.297  1.18e-07 ***
wshg           3.3923     0.7486    4.531  5.86e-06 ***
ripN             0.1425     0.6323   0.225  0.82165
wshd:ripN     0.3708     0.9682   0.383  0.70170
wshf:ripN    -0.8665     0.8087   -1.071  0.28400
wshg:ripN    -3.1530     0.9601  -3.284  0.00102 **
---

Correlation of Fixed Effects:
                 (Intr)  wshd   wshf   wshg   ripN   wshd:N wshf:N
wshd        -0.649
wshf        -0.779  0.505
wshg        -0.659  0.428  0.513
ripN         -0.644  0.418  0.501  0.424
wshd:ripN  0.421 -0.672 -0.327 -0.277 -0.653
wshf:ripN  0.503 -0.327 -0.638 -0.332 -0.782  0.511
wshg:ripN  0.424 -0.275 -0.330 -0.632 -0.659  0.430  0.515


I then used this model to do Tukey's HSD contrasts between watershed types:

summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))
Linear Hypotheses:

                Estimate Std. Error z value Pr(>|z|)
d - c == 0 -2.05573    0.76010  -2.705   0.0341 *
f - c == 0  3.35753    0.63386   5.297   <0.001 ***
g - c == 0  3.39231    0.74862   4.531   <0.001 ***
f - d == 0  5.41326    0.70176   7.714   <0.001 ***
g - d == 0  5.44804    0.80692   6.752   <0.001 ***
g - f == 0  0.03479    0.68931   0.050   1.0000

and riparian types:

                                                          Estimate
Std. Error z value Pr(>|z|)
C: Forested vs. Non-Forested == 0         0.1425     0.6323   0.225  0.99999
D: Forested vs. Non-Forested == 0         0.5134     0.7332   0.700  0.98659
F: Forested vs. Non-Forested == 0        -0.7239     0.5042  -1.436  0.69625
G: Forested vs. Non-Forested == 0        -3.0105     0.7225  -4.167  < 0.001 ***

Are these p values accurate? Or is that a personal judgement I have to
make based on the clarity of the patterns they reflect?

I've shown these results in my figures and explained them in my
results. I've basically explained that though these p values
reasonably reflect patterns in my data, effects sizes, and variances,
that they are inexact and potentially anti-conservative due to the
issues with degrees of freedom in mixed models.

>From what I understand from my research in the last year is that
Douglas Bates and others advocate something of a paradigm shift away
from the petagogically reinforced reliance on cryptic p values toward
more in depth discussions of effects sizes and variances. The use of
MCMC sampling and HPD intervals are suggested, but these are not
available for generalized models.

I am interested in publishing these results as an ecologist, not a
statistician (pardon the somewhat artificial distinction), and, I am
very interested in what kind of a discussion the statisticians and
ecologists of the r-sig-mixed-models mailing list would like to see as
potential reviewers.

Thank you,

Colin Wahl

M.S. candidate,
Dept. of Biology
Western Washington University
Bellingham, WA



From jens.astrom at slu.se  Sun Jan 15 13:04:18 2012
From: jens.astrom at slu.se (=?ISO-8859-1?Q?Jens_=C5str=F6m?=)
Date: Sun, 15 Jan 2012 13:04:18 +0100
Subject: [R-sig-ME] Mean of random effects same as fixed effect?
In-Reply-To: <CAO7JsnT+9YeewXf1izJ41Fh_uSMPweLOCsi4TDNjr=OgT6wSjw@mail.gmail.com>
References: <4F094BD7.1080408@slu.se>
	<CAO7JsnT+9YeewXf1izJ41Fh_uSMPweLOCsi4TDNjr=OgT6wSjw@mail.gmail.com>
Message-ID: <4F12C0C2.3050708@slu.se>

Thanks for the input! It is appreciated. In practice, my problem is
solved but there still remains some questions.

I was shown off list the conventional way of modelling this in a
Bayesian framework (below). It seems I was barking in the right general
direction, but not at the right tree. Prof. Bates objections may explain
the slight differences in results between my hack version and the more
conventional, but I am not sure.

I realise now that simply taking the mean of observations defined to be
normally distributed is not the same as estimating the mean of that
underlying distribution. For instance, there may be extreme values that
could be given undue influence by just taking the mean.

I believe that the conventional BUGS approach deals with this problem,
but I am curious if it is still subject to any of Prof. Bates
objections. The unconditional means of the random effects is here
defined as the fixed intercept and slope values. Remember, the initial
problem was that doing differently resulted in non-convergence.

When I manipulate the sleepstudy data set to produce a non-balanced data
set, the three methods (my hack version, the conventional BUGS, and
lmer) all gives slightly different answers, otherwise pretty much the
same. This leaves me curious if one can be considered more correct than
the other.

Any other suggestions of model specifications or other thoughts are
appreciated, otherwise I will settle with the conventional for now.



For future reference, this appears to be a conventional way to implement
models of the form
fm1<-lmer(Reaction~Days+(Days|Subject),data=sleepstudy)
in BUGS/JAGS (thanks again Kent!). (Inverse wishart is another way)




model{

   for (i in 1:length(Reaction)){
     Reaction[i] ~ dnorm (mu[i], tau.Reaction)
     mu[i] <-subj.inter[subj[i]] + subj.Days[subj[i]]*Days[i]
   }
   tau.Reaction~dgamma(0.001,0.001)

   sigma.Reaction<-sqrt(1/tau.Reaction)

   for (j in 1:nr.subj){
     subj.inter[j] <- B[j,1]
     subj.Days[j] <- B[j,2]
     B[j,1:2] ~ dmnorm (B.hat[j,], Tau.B[,])
     B.hat[j,1] <- intercept
     B.hat[j,2] <- Days.par
   }
   intercept ~ dnorm(0, 1.0e-6)
   Days.par ~ dnorm(0, 1.0e-6)

   ## hack.intercept<-mean(subj.inter[])
   ## hack.Days.par<-mean(subj.Days[])

   Tau.B[1:2,1:2] <- inverse(Sigma.B[,])
   Sigma.B[1,1] <- pow(sigma.subj.inter, 2)
   sigma.subj.inter ~ dunif (0, 100)
   Sigma.B[2,2] <- pow(sigma.subj.Days, 2)
   sigma.subj.Days ~ dunif (0, 100)
   Sigma.B[1,2] <- rho*sigma.subj.inter*sigma.subj.Days
   Sigma.B[2,1] <- Sigma.B[1,2]
   rho ~ dunif (-1, 1)
   #rho<-0 #set this at zero for non correlated random effects
}


/Jens




On 01/09/2012 09:02 PM, Douglas Bates wrote:
> On Sun, Jan 8, 2012 at 1:55 AM, Jens ?str?m <jens.astrom at slu.se> wrote:
>> Hi all,
>>
>> A couple of weeks ago I posted a question but got no answers. Here goes
>> a second attempt, now shorter and more general.
>>
>>
>> Are the following two model specifications interchangeable, or is there
>> a statistical reason for why it is not OK to express model 1 in the form
>> of model 2?
>>
>> Model 1)
>> y=fixed.intercept+fixed.slope*x+random.intercept+random.slope*x
>>
>> Model 2)
>> y=random.intercept*x+random.slope*x
>> fixed.intercept=mean(random.intercept)
>> fixed.slope=mean(random.slope)
> 
> You would need at least equal group sizes and identical values of the
> covariate with respect to which you have a random slope to be able to
> count on this.  Even then I'm not entirely sure it would work.
> 
> Generally the unconditional distribution of the random effects is
> defined to have a mean of zero.  I don't know how you are defining
> yours (and prefer not to wade through BUGS/JAGS model specifications
> to find out).
> 
>> The reasons for my asking is that I have trouble getting convergence
>> with model specification 1, when the random intercepts and random slopes
>> are correlated, but specifying it as model 2 seemed to work. This is me
>> trying to implement some standard mixed models in BUGS/JAGS. Original
>> post with complete working example is here:
>> http://markmail.org/message/vhqeq4j3kldttlt5
>>
>>
>>
>> I'm happy for any comments, with or without BUGS/JAGS code.
>>
>> /Jens Astrom
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From erikfrenzel at gmail.com  Sun Jan 15 18:10:43 2012
From: erikfrenzel at gmail.com (Erik Frenzel)
Date: Sun, 15 Jan 2012 09:10:43 -0800
Subject: [R-sig-ME] Advice on GLS model specification
Message-ID: <CANJAy05uQtpa=oOTzojL8BJ6S_JOgQH5WGx56ryQWH3_g=1GDw@mail.gmail.com>

Hello mixed modellers:
I'm helping a coworker analyze some toxicology data and would
appreciate any feedback on my proposed analysis, particularly in
regards to how I've specified a contrast.

He collected 1 blood sample from each of 79 animals at 7 sites in 2
regions. He would like to know the difference in the response variable
(concentration of a chemical in the blood) between regions after
accounting for two covariates (mass and temperature) which were
measured for each animal. The data are unbalanced and the variance of
the response variable also differs between sites.

My plan is to fit a GLS model with fixed effects of the two covariates
and site, specify the correlation and variance structures, and test
for the difference between regions using a contrast between the sites
in two regions. Reproducible code with data from dput() is at the end
of the message.

> str(data) #  each record is a blood sample
'data.frame':   79 obs. of  5 variables:
 $ region: Factor w/ 2 levels "north","south": 1 1 1 1 1 1 1 1 1 1 ...
 $ site  : Factor w/ 7 levels "a","b","c","d",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ resp  : num  0.1672 0.0733 0.1637 0.0836 0.1195 ...
 $ mass  : num  185 450 718 388 250 410 602 315 462 637 ...
 $ temp  : num  25.2 24.2 23.8 25.2 23.4 24.8 24 23.5 26.2 27.1 ...

> xtabs(~region+site, data=data) # unequal number of observations between sites
       site
region   a  b  c  d  e  f  g
  north 11 20  8  0  0  0  0
  south  0  0  0 10 24  4  2

> library(nlme)
> contrasts(data$site) <- c(-1/3, -1/3, -1/3, 1/4, 1/4, 1/4, 1/4) # test the difference between 3 northern and 4 southern sites, other contrasts may be of interest but I'm starting with this one.

> gls1 <- gls(resp ~ mass + temp + site, weights = varIdent(site), correlation = corCompSymm(form = ~ 1|site), method = "REML", data = data)

> summary(gls1)
Generalized least squares fit by REML
  Model: resp ~ mass + temp + site
  Data: data
   AIC  BIC logLik
  -231 -207    127

Correlation Structure: Compound symmetry
 Formula: ~1 | site
 Parameter estimate(s):
    Rho
3.8e-08

Coefficients:
              Value Std.Error t-value p-value
(Intercept)  0.1143    0.0442   2.587  0.0118
mass         0.0000    0.0000   1.072  0.2875
temp        -0.0004    0.0018  -0.215  0.8305
site1       -0.0538    0.0179  -3.008  0.0037
site2       -0.0061    0.0108  -0.563  0.5755
site3       -0.0122    0.0108  -1.127  0.2638
site4       -0.0039    0.0097  -0.403  0.6882
site5        0.0171    0.0153   1.122  0.2658
site6       -0.0038    0.0189  -0.204  0.8391

 Correlation:
      (Intr) mass   temp   site1  site2  site3  site4  site5
mass  -0.221
temp  -0.969 -0.001
site1 -0.318  0.443  0.267
site2 -0.350  0.199  0.329  0.051
site3 -0.065  0.110  0.003 -0.167  0.073
site4 -0.237 -0.112  0.207 -0.371  0.102  0.329
site5  0.399  0.121 -0.437  0.004 -0.084 -0.067 -0.100
site6 -0.077 -0.336  0.199  0.255  0.028 -0.387 -0.239 -0.497

Standardized residuals:
    Min      Q1     Med      Q3     Max
-2.4083 -0.5903 -0.0519  0.5830  2.0042

Residual standard error: 0.0305
Degrees of freedom: 79 total; 70 residual


I would interpret this as a difference between the two regions
(contrast = "site1") which is significantly different from 0.  The
effects of mass and temperature don't appear to be significanly
different from zero. Spread of the residuals is still somewhat greater
for some groups. I would welcome any thoughts on the suitability of
this approach. Thanks, Erik


########### reproducible code
data <-

structure(list(region = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("north", "south"), class =
"factor"),
    site = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
    5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L), .Label = c("a", "b",
    "c", "d", "e", "f", "g"), class = "factor"), resp = c(0.1672,
    0.0733, 0.1637, 0.0836, 0.1195, 0.1855, 0.1502, 0.12, 0.1985,
    0.1083, 0.1522, 0.1387, 0.109, 0.0712, 0.1724, 0.1775, 0.1071,
    0.1641, 0.13, 0.1845, 0.1348, 0.1808, 0.1841, 0.0739, 0.0888,
    0.1421, 0.1883, 0.1305, 0.1173, 0.1875, 0.114, 0.1365, 0.1443,
    0.1601, 0.1272, 0.1313, 0.1269, 0.0903, 0.1218, 0.0533, 0.0963,
    0.0868, 0.1259, 0.086, 0.0828, 0.0792, 0.0818, 0.0878, 0.0843,
    0.0963, 0.1138, 0.084, 0.0698, 0.1098, 0.0848, 0.1077, 0.1458,
    0.0896, 0.1045, 0.0719, 0.0771, 0.0868, 0.0743, 0.0868, 0.092,
    0.0774, 0.1591, 0.0858, 0.0734, 0.1256, 0.1027, 0.0988, 0.1234,
    0.0896, 0.1202, 0.1134, 0.1311, 0.1398, 0.0674), mass = c(185,
    450, 718, 388, 250, 410, 602, 315, 462, 637, 861, 423, 764,
    806, 892, 630, 622, 595, 314, 586, 796, 502, 803, 440, 256,
    695, 476, 664, 530, 646, 745, 144, 449, 566, 398, 542, 568,
    198, 649, 160, 248, 244, 211, 259, 178, 230, 216, 254, 269,
    232, 282, 309, 504, 294, 544, 296, 378, 309, 364, 313, 352,
    507, 163, 422, 126, 345, 397, 288, 95, 384, 336, 192, 240,
    359, 133, 208, 101, 560, 509), temp = c(25.2, 24.2, 23.8,
    25.2, 23.4, 24.8, 24, 23.5, 26.2, 27.1, 23.7, 23.4, 25, 25.6,
    25.8, 27.2, 25.4, 25.6, 24.8, 23.6, 23, 24.6, 24.8, 23.2,
    23.8, 25.4, 24.8, 28, 26.6, 26.4, 23.9, 23.2, 23, 20.8, 21.4,
    21.2, 23.2, 23.4, 23.8, 23.8, 22.8, 23.6, 22.2, 21.6, 21.8,
    21.6, 22.8, 21.6, 22.4, 24.4, 20.4, 21, 22.4, 22.2, 22.4,
    22.8, 14.4, 14.2, 15.4, 21, 21.6, 21.4, 20.8, 21.4, 23, 21.3,
    22.6, 22.8, 22.4, 23.6, 22.8, 24.4, 23.8, 28.6, 28.6, 24.4,
    22.6, 21.2, 19.6)), .Names = c("region", "site", "resp",
"mass", "temp"), row.names = c(NA, 79L), class = "data.frame")

str(data)
xtabs(~region+site, data=data) # very unequal number of observations
between sites
library(nlme)
contrasts(data$site) <- c(-1/3, -1/3, -1/3, 1/4, 1/4, 1/4, 1/4) # test
the difference between 3 northern and 4 southern sites
gls1 <- gls(resp ~ mass + temp + site, weights = varIdent(site),
correlation = corCompSymm(form = ~ 1|site), method = "REML", data =
data)
summary(gls1)



From Michelle.Gosse at foodstandards.gov.au  Sun Jan 15 19:50:46 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Mon, 16 Jan 2012 05:50:46 +1100
Subject: [R-sig-ME] MC, sample weights,
	and mixed effect models [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A504@EXCHANGE07.foodstandards.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120116/b8b1b892/attachment-0001.pl>

From c.ryan.king at gmail.com  Sun Jan 15 20:35:40 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Sun, 15 Jan 2012 13:35:40 -0600
Subject: [R-sig-ME] MCMCglmm output 1) on right scale? 2) produces huge
	deviance spread?
Message-ID: <CAEQ+J25=0+CaK8hUMcyOqvM88GTTvU+eOpkqEqKmg_Aa=Nmw2Q@mail.gmail.com>

Hi, I have an MCMCglmm run predicting a binary outcome with a single
fixed effect and two groups of random effects like so

testprior4<-list( R=list(V=1, fix=1), G=list(G1=list(V=1, nu=1,
alpha.mu=0, alpha.v=.5^2 ), G2=list(V=1, nu=1, alpha.mu=0, alpha.v=1 )
), B=list(mu=c(0,0), V=diag(2)*4 ) )

testmcmc5b<-MCMCglmm(fixed=myy2~myx,random=~idv(myz)+idv(newz3)   ,
family = "ordinal", prior= testprior4, data=mydata, nitt=6000,
thin=10, burnin=5000 , pr=TRUE)

I can provide the full simulation details, but hope that this is a
general rather than specific problem.

The first set of random effects have large effects, but the second set
is just noise.

I'm setting up a bridge sampler to get a bayes factor, which means I
need to get a log-likelihood + log-prior for my proposal.

I tested my log-likelihood calculation with  MCMC output and got
atrociously spread out log-likelihoods (sd of 15-20). That seems like
rather a lot on the log scale, and means that numerical problems are
likely for the bridge sampler. GLM produces the same deviance up to a
constant (regressing the outcome versus the linear predictor), so that
function is fine. This problem is much smaller when using only the
true predictors (sd = 6) .  The estimated variance component for the
noise predictors never goes above .015, so that they cause this
problem is surprising. Is there a handy explanation / work around?

More troubling, a calibration exercise in the deviance calculation
showed that the groups of linear predictors were not on the right
scale.
That is, multiplying through the two sets of random effects and design
matrices to get batches of linear predictors, and running a glm of the
binary outcome versus the linear predictors using a probit (or logit)
link gets coefficients consistently not 1. The true random effects get
a coefficient of about .65, and the noise random effects between .7
and .4 depending on how I set them up. I don't think it's a bad mixing
problem, because 1) I have gotten the same thing on independent
chains, 2) effectiveSize() reports large effective samples 3) there is
quite a bit of spread in the deviances.  This problem persists if I
run with family="categorical".

When I plug in the re-calibrated linear predictor, the sd of the
log-likelihood goes down a lot, from 15 to 6 in the
two-predictor-group case and from 6 to 3 when using only the true
predictors. That's much better, but still quite a premium for having a
group of noise predictors.

Thanks,
Ryan King
Dept Health Studies
University of Chicago



From Thierry.ONKELINX at inbo.be  Mon Jan 16 09:58:40 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 16 Jan 2012 08:58:40 +0000
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275732B97D@inbomail.inbo.be>

Dear Colin,

I don't think your Tukey tests are very informative. Because you are testing main effects how have an interaction with another variable. So you are not testing the overall effect of a variable but the effect when all other variable are 0 (continuous) or at the reference level (factor).

A better way of doing this could bet o create a new variable which is the interaction between wsh and rip and use that in your model instead of wsh * rip. Then you can use glht() with user defined contrasts so that the contrasts test what you want to test.

Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Colin Wahl
Verzonden: zondag 15 januari 2012 1:23
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Comparing results from glmer and glht

I will try to make this concise.

Background: I am testing the effects of land use and forested riparian buffers on stream invertebrates and in-stream variables. There are 4 watershed types (defined by 4 types of land use) and two riparian types (forested and non). Percent EPT (relative abundance) was my main response variable. I also measured a variety of in-stream variables like temperature, nutrients, and toxicity. There are 72 observations for invertebrates, and 24 for in-stream variables.

I am curious of how acceptable p values are from pairwise comparisons using glht() from the multcomp package

I used glmer with a binomial error structure and an observation-level random effect (to account for overdispersion), to model invertebrates:

modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs), data=ept, family=binomial(link="logit"))

   AIC   BIC logLik deviance
 284.4 309.5 -131.2    262.4
Random effects:
 Groups     Name        Variance Std.Dev.
 obs        (Intercept) 0.30186  0.54942
 stream:rip (Intercept) 0.40229  0.63427
 stream     (Intercept) 0.12788  0.35760
Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12

Fixed effects:
                 Estimate Std. Error z value Pr(>|z|)
(Intercept)   -4.2906     0.4935   -8.694  < 2e-16 ***
wshd           -2.0557     0.7601  -2.705  0.00684 **
wshf            3.3575     0.6339   5.297  1.18e-07 ***
wshg           3.3923     0.7486    4.531  5.86e-06 ***
ripN             0.1425     0.6323   0.225  0.82165
wshd:ripN     0.3708     0.9682   0.383  0.70170
wshf:ripN    -0.8665     0.8087   -1.071  0.28400
wshg:ripN    -3.1530     0.9601  -3.284  0.00102 **
---

Correlation of Fixed Effects:
                 (Intr)  wshd   wshf   wshg   ripN   wshd:N wshf:N
wshd        -0.649
wshf        -0.779  0.505
wshg        -0.659  0.428  0.513
ripN         -0.644  0.418  0.501  0.424
wshd:ripN  0.421 -0.672 -0.327 -0.277 -0.653 wshf:ripN  0.503 -0.327 -0.638 -0.332 -0.782  0.511 wshg:ripN  0.424 -0.275 -0.330 -0.632 -0.659  0.430  0.515


I then used this model to do Tukey's HSD contrasts between watershed types:

summary(glht(modelEPT, linfct=mcp(wsh="Tukey"))) Linear Hypotheses:

                Estimate Std. Error z value Pr(>|z|)
d - c == 0 -2.05573    0.76010  -2.705   0.0341 *
f - c == 0  3.35753    0.63386   5.297   <0.001 ***
g - c == 0  3.39231    0.74862   4.531   <0.001 ***
f - d == 0  5.41326    0.70176   7.714   <0.001 ***
g - d == 0  5.44804    0.80692   6.752   <0.001 ***
g - f == 0  0.03479    0.68931   0.050   1.0000

and riparian types:

                                                          Estimate Std. Error z value Pr(>|z|)
C: Forested vs. Non-Forested == 0         0.1425     0.6323   0.225  0.99999
D: Forested vs. Non-Forested == 0         0.5134     0.7332   0.700  0.98659
F: Forested vs. Non-Forested == 0        -0.7239     0.5042  -1.436  0.69625
G: Forested vs. Non-Forested == 0        -3.0105     0.7225  -4.167  < 0.001 ***

Are these p values accurate? Or is that a personal judgement I have to make based on the clarity of the patterns they reflect?

I've shown these results in my figures and explained them in my results. I've basically explained that though these p values reasonably reflect patterns in my data, effects sizes, and variances, that they are inexact and potentially anti-conservative due to the issues with degrees of freedom in mixed models.

>From what I understand from my research in the last year is that
Douglas Bates and others advocate something of a paradigm shift away from the petagogically reinforced reliance on cryptic p values toward more in depth discussions of effects sizes and variances. The use of MCMC sampling and HPD intervals are suggested, but these are not available for generalized models.

I am interested in publishing these results as an ecologist, not a statistician (pardon the somewhat artificial distinction), and, I am very interested in what kind of a discussion the statisticians and ecologists of the r-sig-mixed-models mailing list would like to see as potential reviewers.

Thank you,

Colin Wahl

M.S. candidate,
Dept. of Biology
Western Washington University
Bellingham, WA

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From i.m.s.white at ed.ac.uk  Mon Jan 16 12:06:17 2012
From: i.m.s.white at ed.ac.uk (i white)
Date: Mon, 16 Jan 2012 11:06:17 +0000
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
Message-ID: <4F1404A9.7010107@ed.ac.uk>

Colin,

A simple graph of means for your eight combinations of 4 watershed types 
and two riparian types shows there are significant differences between 
watershed types c, d and f, and that for those types of watershed, 
riparian type makes no difference to the response. For watershed g, 
response is similar to watershed f for forested streams, but 
significantly lower at non-forested streams (if I have interpreted your 
factor labels correctly). These conclusions are based on inspection of a 
very simple graph with say a white dot for forested stream, black dot 
for unforested stream, and different locations along x axis for the 4 
watershed types. Somewhere on the graph there needs to be a bar whose 
length represents a rough estimate of the average standard error of a 
mean (or difference between two means). Note that neither p-values nor 
multiple comparisons have been mentioned.

Colin Wahl wrote:
> I will try to make this concise.
> 
> Background: I am testing the effects of land use and forested riparian
> buffers on stream invertebrates and in-stream variables. There are 4
> watershed types (defined by 4 types of land use) and two riparian
> types (forested and non). Percent EPT (relative abundance) was my main
> response variable. I also measured a variety of in-stream variables
> like temperature, nutrients, and toxicity. There are 72 observations
> for invertebrates, and 24 for in-stream variables.
> 
> I am curious of how acceptable p values are from pairwise comparisons
> using glht() from the multcomp package
> 
> I used glmer with a binomial error structure and an observation-level
> random effect (to account for overdispersion), to model invertebrates:
> 
> modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs),
> data=ept, family=binomial(link="logit"))
> 
>    AIC   BIC logLik deviance
>  284.4 309.5 -131.2    262.4
> Random effects:
>  Groups     Name        Variance Std.Dev.
>  obs        (Intercept) 0.30186  0.54942
>  stream:rip (Intercept) 0.40229  0.63427
>  stream     (Intercept) 0.12788  0.35760
> Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12
> 
> Fixed effects:
>                  Estimate Std. Error z value Pr(>|z|)
> (Intercept)   -4.2906     0.4935   -8.694  < 2e-16 ***
> wshd           -2.0557     0.7601  -2.705  0.00684 **
> wshf            3.3575     0.6339   5.297  1.18e-07 ***
> wshg           3.3923     0.7486    4.531  5.86e-06 ***
> ripN             0.1425     0.6323   0.225  0.82165
> wshd:ripN     0.3708     0.9682   0.383  0.70170
> wshf:ripN    -0.8665     0.8087   -1.071  0.28400
> wshg:ripN    -3.1530     0.9601  -3.284  0.00102 **
> ---
> 
> Correlation of Fixed Effects:
>                  (Intr)  wshd   wshf   wshg   ripN   wshd:N wshf:N
> wshd        -0.649
> wshf        -0.779  0.505
> wshg        -0.659  0.428  0.513
> ripN         -0.644  0.418  0.501  0.424
> wshd:ripN  0.421 -0.672 -0.327 -0.277 -0.653
> wshf:ripN  0.503 -0.327 -0.638 -0.332 -0.782  0.511
> wshg:ripN  0.424 -0.275 -0.330 -0.632 -0.659  0.430  0.515
> 
> 
> I then used this model to do Tukey's HSD contrasts between watershed types:
> 
> summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))
> Linear Hypotheses:
> 
>                 Estimate Std. Error z value Pr(>|z|)
> d - c == 0 -2.05573    0.76010  -2.705   0.0341 *
> f - c == 0  3.35753    0.63386   5.297   <0.001 ***
> g - c == 0  3.39231    0.74862   4.531   <0.001 ***
> f - d == 0  5.41326    0.70176   7.714   <0.001 ***
> g - d == 0  5.44804    0.80692   6.752   <0.001 ***
> g - f == 0  0.03479    0.68931   0.050   1.0000
> 
> and riparian types:
> 
>                                                           Estimate
> Std. Error z value Pr(>|z|)
> C: Forested vs. Non-Forested == 0         0.1425     0.6323   0.225  0.99999
> D: Forested vs. Non-Forested == 0         0.5134     0.7332   0.700  0.98659
> F: Forested vs. Non-Forested == 0        -0.7239     0.5042  -1.436  0.69625
> G: Forested vs. Non-Forested == 0        -3.0105     0.7225  -4.167  < 0.001 ***
> 
> Are these p values accurate? Or is that a personal judgement I have to
> make based on the clarity of the patterns they reflect?
> 
> I've shown these results in my figures and explained them in my
> results. I've basically explained that though these p values
> reasonably reflect patterns in my data, effects sizes, and variances,
> that they are inexact and potentially anti-conservative due to the
> issues with degrees of freedom in mixed models.
> 
>>From what I understand from my research in the last year is that
> Douglas Bates and others advocate something of a paradigm shift away
> from the petagogically reinforced reliance on cryptic p values toward
> more in depth discussions of effects sizes and variances. The use of
> MCMC sampling and HPD intervals are suggested, but these are not
> available for generalized models.
> 
> I am interested in publishing these results as an ecologist, not a
> statistician (pardon the somewhat artificial distinction), and, I am
> very interested in what kind of a discussion the statisticians and
> ecologists of the r-sig-mixed-models mailing list would like to see as
> potential reviewers.
> 
> Thank you,
> 
> Colin Wahl
> 
> M.S. candidate,
> Dept. of Biology
> Western Washington University
> Bellingham, WA
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From rstuff.miles at gmail.com  Mon Jan 16 16:25:45 2012
From: rstuff.miles at gmail.com (Andrew Miles)
Date: Mon, 16 Jan 2012 10:25:45 -0500
Subject: [R-sig-ME] Log-likelihood and mixed models in glmer
Message-ID: <0015790A-4E33-4458-A7AE-15650CFC4473@gmail.com>

Can someone point me to a reference that will explain why, when using mixed models (glmer and lmer) adding explanatory variables decreases the log likelihood?  This makes no sense to me, as adding explanatory power should make the model fit the data worse.  I've attached the data I am using, which contains no missing values, and here are the models I am running, and the results:

Any help is appreciated.  Thanks!

#note, models do not fully converge, but examination of estimates using verbose=T suggests they are resonable

mod.null = glmer(res.lifesat.last5 ~ 1 + (1|hhidpn) + (1|hhid), data=data.nomiss, family=binomial(link="probit"))
mod1 = glmer(res.lifesat.last5 ~ networth2.gmc + (1|hhidpn) + (1|hhid), data=data.nomiss, family=binomial(link="probit"))
mod2 = glmer(res.lifesat.last5 ~ networth2.gmc + married + (1|hhidpn) + (1|hhid), data=data.nomiss, family=binomial(link="probit"))
mod3 = glmer(res.lifesat.last5 ~ networth2.gmc + married + depscore + selfhealth + (1|hhidpn) + (1|hhid), data=data.nomiss, family=binomial(link="probit"))

#note that mod2 and mod3 have lower log-likelihoods than mod1, and mod3 has a lower LL than the null model
anova(mod.null, mod1, mod2, mod3)

Andrew Miles




From bbolker at gmail.com  Mon Jan 16 18:09:53 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 Jan 2012 17:09:53 +0000 (UTC)
Subject: [R-sig-ME] Log-likelihood and mixed models in glmer
References: <0015790A-4E33-4458-A7AE-15650CFC4473@gmail.com>
Message-ID: <loom.20120116T180506-44@post.gmane.org>

Andrew Miles <rstuff.miles at ...> writes:

>  Can someone point me to a reference that will explain why, when
> using mixed models (glmer and lmer) adding explanatory variables
> decreases the log likelihood?  This makes no sense to me, as adding
> explanatory power should make the model fit the data worse.  I've
                        ^^^^^
                        never?

> attached the data I am using, which contains no missing values, and
> here are the models I am running, and the results:

  The attachment didn't make it through to the mailing list.
Could you post it somewhere (or send it to me)?

> #note, models do not fully converge, but examination of estimates
>   using verbose=T suggests they are resonable

    The fact that they didn't converge (combined with your observation)
seems like a giant warning message to me ...  hard to say more without
seeing the data (see above)

> mod.null = glmer(res.lifesat.last5 ~ 1 + (1|hhidpn) + 
> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
> mod1 = glmer(res.lifesat.last5 ~ networth2.gmc + (1|hhidpn) + 
>  (1|hhid), data=data.nomiss, family=binomial(link="probit"))
> mod2 = glmer(res.lifesat.last5 ~ networth2.gmc + married + (1|hhidpn) +
>  (1|hhid), data=data.nomiss, family=binomial(link="probit"))
> mod3 = glmer(res.lifesat.last5 ~ networth2.gmc + married + depscore + 
> selfhealth + (1|hhidpn) +
> (1|hhid), data=data.nomiss, family=binomial(link="probit"))

  I have to add some text so the Gmane portal will be happy,
so let me just add that

  mod1 <- update(mod.null, . ~ . + networth2.gmc)
  mod2 <- update(mod1, . ~ . + married)
  mod3 <- update(mod2, . ~ . + depscore + selfhealth)

  would be a little bit clearer.

  Have you tried centering any continuous predictors?
 
> #note that mod2 and mod3 have lower log-likelihoods than mod1, 
>  and mod3 has a lower LL than the null model
> anova(mod.null, mod1, mod2, mod3)

   Do you get the same results from just using logLik() ?  Perhaps
anova() is scrambling things up?



From biowahl at gmail.com  Mon Jan 16 21:14:56 2012
From: biowahl at gmail.com (Colin Wahl)
Date: Mon, 16 Jan 2012 12:14:56 -0800
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <4F1404A9.7010107@ed.ac.uk>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
	<4F1404A9.7010107@ed.ac.uk>
Message-ID: <CACu_zZnXjrG-8Ld-dij4J3Y22d=BkBC_nP8L0cgj+OEGNtVBGQ@mail.gmail.com>

Good. This is the same conclusion I've made with a boxplot/graph of
the EPT data. The pattern is very clear. However, if not using p
values, how do you conclude that the differences are "significant?"
The patterns are less clear with other variables.

For example, nutrients, are clearly higher in cultivated streams, but
doing mcmc sampling and using HPD intervals to calculate 95%
confidence intervals results in huge conf. intervals. I've discussed
this with Thierry on this list before, where he asserted that with an
n of 24, the model lacks the power to find significance. However, a
child could look at the graph and tell you that nutrients are way
higher in cultivated streams. Also, the variance/st. deviation is zero
for the random stream variable. Does that mean it should be excluded?
Here are the results of the Nitrate/nitrite model, where nitrates are
higher in non-forested reaches in cultivated streams:

Linear mixed model fit by REML
Formula: LN ~ wsh * rip + (1 | stream)
   Data: all24
   AIC   BIC logLik deviance REMLdev
 43.89 55.24 -11.94    14.12   23.89
Random effects:
 Groups   Name        Variance Std.Dev.
 stream   (Intercept) 0.00000  0.00000
 Residual             0.16589  0.40729
Number of obs: 23, groups: stream, 12

Fixed effects:
            Estimate Std. Error t value
(Intercept)   0.5726     0.2351   2.435
wshD         -0.1040     0.3326  -0.313
wshF         -0.2562     0.3326  -0.770
wshG         -0.2758     0.3718  -0.742
ripN          0.8442     0.3326   2.538
wshD:ripN    -0.6730     0.4703  -1.431
wshF:ripN    -0.7653     0.4554  -1.681
wshG:ripN    -1.1080     0.5258  -2.107

Correlation of Fixed Effects:
          (Intr) wshD   wshF   wshG   ripN   wshD:N wshF:N
wshD      -0.707
wshF      -0.707  0.500
wshG      -0.632  0.447  0.447
ripN      -0.707  0.500  0.500  0.447
wshD:ripN  0.500 -0.707 -0.354 -0.316 -0.707
wshF:ripN  0.516 -0.365 -0.730 -0.327 -0.730  0.516
wshG:ripN  0.447 -0.316 -0.316 -0.707 -0.632  0.447  0.462

On Mon, Jan 16, 2012 at 3:06 AM, i white <i.m.s.white at ed.ac.uk> wrote:
> Colin,
>
> A simple graph of means for your eight combinations of 4 watershed types and
> two riparian types shows there are significant differences between watershed
> types c, d and f, and that for those types of watershed, riparian type makes
> no difference to the response. For watershed g, response is similar to
> watershed f for forested streams, but significantly lower at non-forested
> streams (if I have interpreted your factor labels correctly). These
> conclusions are based on inspection of a very simple graph with say a white
> dot for forested stream, black dot for unforested stream, and different
> locations along x axis for the 4 watershed types. Somewhere on the graph
> there needs to be a bar whose length represents a rough estimate of the
> average standard error of a mean (or difference between two means). Note
> that neither p-values nor multiple comparisons have been mentioned.
>
> Colin Wahl wrote:
>>
>> I will try to make this concise.
>>
>> Background: I am testing the effects of land use and forested riparian
>> buffers on stream invertebrates and in-stream variables. There are 4
>> watershed types (defined by 4 types of land use) and two riparian
>> types (forested and non). Percent EPT (relative abundance) was my main
>> response variable. I also measured a variety of in-stream variables
>> like temperature, nutrients, and toxicity. There are 72 observations
>> for invertebrates, and 24 for in-stream variables.
>>
>> I am curious of how acceptable p values are from pairwise comparisons
>> using glht() from the multcomp package
>>
>> I used glmer with a binomial error structure and an observation-level
>> random effect (to account for overdispersion), to model invertebrates:
>>
>> modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs),
>> data=ept, family=binomial(link="logit"))
>>
>> ? AIC ? BIC logLik deviance
>> ?284.4 309.5 -131.2 ? ?262.4
>> Random effects:
>> ?Groups ? ? Name ? ? ? ?Variance Std.Dev.
>> ?obs ? ? ? ?(Intercept) 0.30186 ?0.54942
>> ?stream:rip (Intercept) 0.40229 ?0.63427
>> ?stream ? ? (Intercept) 0.12788 ?0.35760
>> Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12
>>
>> Fixed effects:
>> ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ? -4.2906 ? ? 0.4935 ? -8.694 ?< 2e-16 ***
>> wshd ? ? ? ? ? -2.0557 ? ? 0.7601 ?-2.705 0.00684 **
>> wshf ? ? ? ? ? ?3.3575 ? ? 0.6339 ? 5.297 ?1.18e-07 ***
>> wshg ? ? ? ? ? 3.3923 ? ? 0.7486 ? ?4.531 ?5.86e-06 ***
>> ripN ? ? ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?0.82165
>> wshd:ripN ? ? 0.3708 ? ? 0.9682 ? 0.383 ?0.70170
>> wshf:ripN ? ?-0.8665 ? ? 0.8087 ? -1.071 ?0.28400
>> wshg:ripN ? ?-3.1530 ? ? 0.9601 ?-3.284 ?0.00102 **
>> ---
>>
>> Correlation of Fixed Effects:
>> ? ? ? ? ? ? ? ? (Intr) ?wshd ? wshf ? wshg ? ripN ? wshd:N wshf:N
>> wshd ? ? ? ?-0.649
>> wshf ? ? ? ?-0.779 ?0.505
>> wshg ? ? ? ?-0.659 ?0.428 ?0.513
>> ripN ? ? ? ? -0.644 ?0.418 ?0.501 ?0.424
>> wshd:ripN ?0.421 -0.672 -0.327 -0.277 -0.653
>> wshf:ripN ?0.503 -0.327 -0.638 -0.332 -0.782 ?0.511
>> wshg:ripN ?0.424 -0.275 -0.330 -0.632 -0.659 ?0.430 ?0.515
>>
>>
>> I then used this model to do Tukey's HSD contrasts between watershed
>> types:
>>
>> summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))
>> Linear Hypotheses:
>>
>> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> d - c == 0 -2.05573 ? ?0.76010 ?-2.705 ? 0.0341 *
>> f - c == 0 ?3.35753 ? ?0.63386 ? 5.297 ? <0.001 ***
>> g - c == 0 ?3.39231 ? ?0.74862 ? 4.531 ? <0.001 ***
>> f - d == 0 ?5.41326 ? ?0.70176 ? 7.714 ? <0.001 ***
>> g - d == 0 ?5.44804 ? ?0.80692 ? 6.752 ? <0.001 ***
>> g - f == 0 ?0.03479 ? ?0.68931 ? 0.050 ? 1.0000
>>
>> and riparian types:
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate
>> Std. Error z value Pr(>|z|)
>> C: Forested vs. Non-Forested == 0 ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225
>> ?0.99999
>> D: Forested vs. Non-Forested == 0 ? ? ? ? 0.5134 ? ? 0.7332 ? 0.700
>> ?0.98659
>> F: Forested vs. Non-Forested == 0 ? ? ? ?-0.7239 ? ? 0.5042 ?-1.436
>> ?0.69625
>> G: Forested vs. Non-Forested == 0 ? ? ? ?-3.0105 ? ? 0.7225 ?-4.167 ?<
>> 0.001 ***
>>
>> Are these p values accurate? Or is that a personal judgement I have to
>> make based on the clarity of the patterns they reflect?
>>
>> I've shown these results in my figures and explained them in my
>> results. I've basically explained that though these p values
>> reasonably reflect patterns in my data, effects sizes, and variances,
>> that they are inexact and potentially anti-conservative due to the
>> issues with degrees of freedom in mixed models.
>>
>>> From what I understand from my research in the last year is that
>>
>> Douglas Bates and others advocate something of a paradigm shift away
>> from the petagogically reinforced reliance on cryptic p values toward
>> more in depth discussions of effects sizes and variances. The use of
>> MCMC sampling and HPD intervals are suggested, but these are not
>> available for generalized models.
>>
>> I am interested in publishing these results as an ecologist, not a
>> statistician (pardon the somewhat artificial distinction), and, I am
>> very interested in what kind of a discussion the statisticians and
>> ecologists of the r-sig-mixed-models mailing list would like to see as
>> potential reviewers.
>>
>> Thank you,
>>
>> Colin Wahl
>>
>> M.S. candidate,
>> Dept. of Biology
>> Western Washington University
>> Bellingham, WA
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>



From biowahl at gmail.com  Mon Jan 16 21:54:48 2012
From: biowahl at gmail.com (Colin Wahl)
Date: Mon, 16 Jan 2012 12:54:48 -0800
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <AA818EAD2576BC488B4F623941DA74275732B97D@inbomail.inbo.be>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74275732B97D@inbomail.inbo.be>
Message-ID: <CACu_zZnP-pjY9N733ZkqGz9k9OPbxtY5e7LfpNYeGg-JkQqnnw@mail.gmail.com>

Thierry,
Thank you for the suggestion. I think I understand, though creating
user defined contrasts will be difficult.

I create a combined variable:
wshrip <-c bind(wsh, rip)

Resulting in a new model
modelEPT<-glmer(EPT ~ wshrip + (1|stream) + (1|stream:rip) + (1|obs),
data=ept, family=binomial(link="logit"))

The user defined contrasts I tried previously were:
wsh <- rbind("C vs. D" = c(1,0,0,0,0,0,0,0),
            "C vs. F" = c(0,1,0,0,0,0,0,0),
            "C vs. G" = c(0,0,1,0,0,0,0,0),
            "D vs. F" = c(-1,1,0,0,0,0,0,0),
            "D vs. G" = c(-1,0,1,0,0,0,0,1),
            "F vs. G" = c(0,-1,1,0,0,0,0,0))

This did not give me reasonable results, prompting me to use built-in
contrasts:

summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))

For riparian contrasts I used:
rip <- rbind("C: Forested vs. Non-Forested" = c(0,0,0,0,1,0,0,0),
            "D: Forested vs. Non-Forested" = c(0,0,0,0,1,1,0,0),
            "F: Forested vs. Non-Forested" = c(0,0,0,0,1,0,1,0),
            "G: Forested vs. Non-Forested" = c(0,0,0,0,1,0,0,1))

I dont understand how these contrasts are defined, but based them on
contrasts on an almost identical design found here:
http://thebiobucket.blogspot.com/2011/06/glmm-with-custom-multiple-comparisons.html#more

Could you please explain how to use user-defined for the model with a
wshrip combined variable? I cant find a clear example of how to do
this. The parameter length is different from the original model now
that there is a combined variable, correct?

Thank you very much, I'd be lost in the dark without this mailing list.

Colin






On Mon, Jan 16, 2012 at 12:58 AM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> Dear Colin,
>
> I don't think your Tukey tests are very informative. Because you are testing main effects how have an interaction with another variable. So you are not testing the overall effect of a variable but the effect when all other variable are 0 (continuous) or at the reference level (factor).
>
> A better way of doing this could bet o create a new variable which is the interaction between wsh and rip and use that in your model instead of wsh * rip. Then you can use glht() with user defined contrasts so that the contrasts test what you want to test.
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Colin Wahl
> Verzonden: zondag 15 januari 2012 1:23
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Comparing results from glmer and glht
>
> I will try to make this concise.
>
> Background: I am testing the effects of land use and forested riparian buffers on stream invertebrates and in-stream variables. There are 4 watershed types (defined by 4 types of land use) and two riparian types (forested and non). Percent EPT (relative abundance) was my main response variable. I also measured a variety of in-stream variables like temperature, nutrients, and toxicity. There are 72 observations for invertebrates, and 24 for in-stream variables.
>
> I am curious of how acceptable p values are from pairwise comparisons using glht() from the multcomp package
>
> I used glmer with a binomial error structure and an observation-level random effect (to account for overdispersion), to model invertebrates:
>
> modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs), data=ept, family=binomial(link="logit"))
>
> ? AIC ? BIC logLik deviance
> ?284.4 309.5 -131.2 ? ?262.4
> Random effects:
> ?Groups ? ? Name ? ? ? ?Variance Std.Dev.
> ?obs ? ? ? ?(Intercept) 0.30186 ?0.54942
> ?stream:rip (Intercept) 0.40229 ?0.63427
> ?stream ? ? (Intercept) 0.12788 ?0.35760
> Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12
>
> Fixed effects:
> ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? -4.2906 ? ? 0.4935 ? -8.694 ?< 2e-16 ***
> wshd ? ? ? ? ? -2.0557 ? ? 0.7601 ?-2.705 0.00684 **
> wshf ? ? ? ? ? ?3.3575 ? ? 0.6339 ? 5.297 ?1.18e-07 ***
> wshg ? ? ? ? ? 3.3923 ? ? 0.7486 ? ?4.531 ?5.86e-06 ***
> ripN ? ? ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?0.82165
> wshd:ripN ? ? 0.3708 ? ? 0.9682 ? 0.383 ?0.70170
> wshf:ripN ? ?-0.8665 ? ? 0.8087 ? -1.071 ?0.28400
> wshg:ripN ? ?-3.1530 ? ? 0.9601 ?-3.284 ?0.00102 **
> ---
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ? ? ? (Intr) ?wshd ? wshf ? wshg ? ripN ? wshd:N wshf:N
> wshd ? ? ? ?-0.649
> wshf ? ? ? ?-0.779 ?0.505
> wshg ? ? ? ?-0.659 ?0.428 ?0.513
> ripN ? ? ? ? -0.644 ?0.418 ?0.501 ?0.424
> wshd:ripN ?0.421 -0.672 -0.327 -0.277 -0.653 wshf:ripN ?0.503 -0.327 -0.638 -0.332 -0.782 ?0.511 wshg:ripN ?0.424 -0.275 -0.330 -0.632 -0.659 ?0.430 ?0.515
>
>
> I then used this model to do Tukey's HSD contrasts between watershed types:
>
> summary(glht(modelEPT, linfct=mcp(wsh="Tukey"))) Linear Hypotheses:
>
> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> d - c == 0 -2.05573 ? ?0.76010 ?-2.705 ? 0.0341 *
> f - c == 0 ?3.35753 ? ?0.63386 ? 5.297 ? <0.001 ***
> g - c == 0 ?3.39231 ? ?0.74862 ? 4.531 ? <0.001 ***
> f - d == 0 ?5.41326 ? ?0.70176 ? 7.714 ? <0.001 ***
> g - d == 0 ?5.44804 ? ?0.80692 ? 6.752 ? <0.001 ***
> g - f == 0 ?0.03479 ? ?0.68931 ? 0.050 ? 1.0000
>
> and riparian types:
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> C: Forested vs. Non-Forested == 0 ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?0.99999
> D: Forested vs. Non-Forested == 0 ? ? ? ? 0.5134 ? ? 0.7332 ? 0.700 ?0.98659
> F: Forested vs. Non-Forested == 0 ? ? ? ?-0.7239 ? ? 0.5042 ?-1.436 ?0.69625
> G: Forested vs. Non-Forested == 0 ? ? ? ?-3.0105 ? ? 0.7225 ?-4.167 ?< 0.001 ***
>
> Are these p values accurate? Or is that a personal judgement I have to make based on the clarity of the patterns they reflect?
>
> I've shown these results in my figures and explained them in my results. I've basically explained that though these p values reasonably reflect patterns in my data, effects sizes, and variances, that they are inexact and potentially anti-conservative due to the issues with degrees of freedom in mixed models.
>
> >From what I understand from my research in the last year is that
> Douglas Bates and others advocate something of a paradigm shift away from the petagogically reinforced reliance on cryptic p values toward more in depth discussions of effects sizes and variances. The use of MCMC sampling and HPD intervals are suggested, but these are not available for generalized models.
>
> I am interested in publishing these results as an ecologist, not a statistician (pardon the somewhat artificial distinction), and, I am very interested in what kind of a discussion the statisticians and ecologists of the r-sig-mixed-models mailing list would like to see as potential reviewers.
>
> Thank you,
>
> Colin Wahl
>
> M.S. candidate,
> Dept. of Biology
> Western Washington University
> Bellingham, WA
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From giaguarenzo at yahoo.it  Tue Jan 17 00:46:59 2012
From: giaguarenzo at yahoo.it (Lorenzo Quaglietta)
Date: Mon, 16 Jan 2012 23:46:59 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
	<loom.20120112T173419-47@post.gmane.org>
Message-ID: <loom.20120117T004350-179@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Isa Blasco <isa.blasco.costa at ...> writes:
> 
> > 
> > Hi,
> > I am using glmmADMB to fit a negative binomial model to my data. My
> > explanatory variable is an ordered factor with 10 levels and I also
> > included a random factor (numeric) and Zero inflation.
> > This is the code I used: m7 <- glmmadmb (abun~odist + (1|sl), data=apa,
> > zeroInflation=TRUE, family="nbinom")
> > 
> > When I run it I got this error:
> > Error in UseMethod("droplevels") :
> >   no applicable method for 'droplevels' applied to an object of class
> > "c('double', 'numeric')"
> > 
> > I do not know what the 'double' means but I checked the glmmADMB manual and
> > they use the same kind of variables in their example. Any guess on what it
> > is happening? How can I solve it?
> > I hope somebody knows!
> 
>   It means that it doesn't make sense to use a numeric variable as
> a grouping variable for a random factor (which is what you've done):
> if sl is a discrete numeric code that identifies groups of observations,
> then you should convert it to a factor.  If it's a continuous variable,
> then you need to go back and read/think some more about the meanings
> of random factors ...
> 
>   It also means that I made some changes to glmmADMB recently that
> got in the way of an informative error message (you should have
> received an error message that told you this).  I will try to 
> catch that error in a more informative way.
> 
>   Ben Bolker
> 
> 

Hi,

I'm having  a similar problem.

My model formula is:

glmmADMB1 <- glmmadmb(Fix ~ log_BIO_F * log_BIO_P + log_drs + fperp + log_pr +
log_la + (1 | ANIMALE) + (1 | ID) + (1 | Time), data=otters, zeroInflation=TRUE,
family="poisson").

and I got the following error message:

"Error in UseMethod("droplevels") : 
  no applicable method for 'droplevels' applied to an object of class
"c('integer', 'numeric')".

My random terms are not categorical nor fitted as factors. Covariates are
continous (the log_ ones) and a factor (fperp). Any clue about what can be the
problem would be very appreciated.

Many thanks in advance, best regards,

Lorenzo Quaglietta



From schmettow at web.de  Tue Jan 17 14:51:25 2012
From: schmettow at web.de (Martin Schmettow)
Date: Tue, 17 Jan 2012 14:51:25 +0100
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
Message-ID: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120117/c45f15a7/attachment-0001.pl>

From Thierry.ONKELINX at inbo.be  Tue Jan 17 15:28:00 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 17 Jan 2012 14:28:00 +0000
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <CACu_zZnP-pjY9N733ZkqGz9k9OPbxtY5e7LfpNYeGg-JkQqnnw@mail.gmail.com>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74275732B97D@inbomail.inbo.be>
	<CACu_zZnP-pjY9N733ZkqGz9k9OPbxtY5e7LfpNYeGg-JkQqnnw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275732D564@inbomail.inbo.be>

Hi Colin,

This is what I would do. The example is on a simple lm() but is similar to a mixed model.
I find it easier to define contrasts on models without the intercept.

set.seed(12345)
dataset <- expand.grid(wsh = c("C", "D", "F", "G"), rip = c("Forest", "Non-forest"), id = seq_len(10))
dataset$wshrip <- with(dataset, wsh:rip)
dataset$Y <- runif(4, min = -10, max = 10)[dataset$wsh] + runif(2, min = -2, max = 2)[dataset$rip] + runif(8, min = -1, max = 1)[dataset$wshrip] + rnorm(nrow(dataset))
model <- lm(Y ~ 0 + wshrip, data = dataset)
library(multcomp)
K <- rbind(
  c(1, 1, -1, -1, 0, 0, 0, 0),
  c(0, 0, 1, 1, 0, 0, -1, -1), 
  c(1, -1, 1, -1, 1, -1, 1, -1))
rownames(K) <- c("C - D = 0", "D - G = 0", "Forest - non-forest = 0")
summary(glht(model, K))

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Colin Wahl [mailto:biowahl at gmail.com] 
Verzonden: maandag 16 januari 2012 21:55
Aan: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Comparing results from glmer and glht

Thierry,
Thank you for the suggestion. I think I understand, though creating user defined contrasts will be difficult.

I create a combined variable:
wshrip <-c bind(wsh, rip)

Resulting in a new model
modelEPT<-glmer(EPT ~ wshrip + (1|stream) + (1|stream:rip) + (1|obs), data=ept, family=binomial(link="logit"))

The user defined contrasts I tried previously were:
wsh <- rbind("C vs. D" = c(1,0,0,0,0,0,0,0),
            "C vs. F" = c(0,1,0,0,0,0,0,0),
            "C vs. G" = c(0,0,1,0,0,0,0,0),
            "D vs. F" = c(-1,1,0,0,0,0,0,0),
            "D vs. G" = c(-1,0,1,0,0,0,0,1),
            "F vs. G" = c(0,-1,1,0,0,0,0,0))

This did not give me reasonable results, prompting me to use built-in
contrasts:

summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))

For riparian contrasts I used:
rip <- rbind("C: Forested vs. Non-Forested" = c(0,0,0,0,1,0,0,0),
            "D: Forested vs. Non-Forested" = c(0,0,0,0,1,1,0,0),
            "F: Forested vs. Non-Forested" = c(0,0,0,0,1,0,1,0),
            "G: Forested vs. Non-Forested" = c(0,0,0,0,1,0,0,1))

I dont understand how these contrasts are defined, but based them on contrasts on an almost identical design found here:
http://thebiobucket.blogspot.com/2011/06/glmm-with-custom-multiple-comparisons.html#more

Could you please explain how to use user-defined for the model with a wshrip combined variable? I cant find a clear example of how to do this. The parameter length is different from the original model now that there is a combined variable, correct?

Thank you very much, I'd be lost in the dark without this mailing list.

Colin






On Mon, Jan 16, 2012 at 12:58 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> Dear Colin,
>
> I don't think your Tukey tests are very informative. Because you are testing main effects how have an interaction with another variable. So you are not testing the overall effect of a variable but the effect when all other variable are 0 (continuous) or at the reference level (factor).
>
> A better way of doing this could bet o create a new variable which is the interaction between wsh and rip and use that in your model instead of wsh * rip. Then you can use glht() with user defined contrasts so that the contrasts test what you want to test.
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Colin Wahl
> Verzonden: zondag 15 januari 2012 1:23
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Comparing results from glmer and glht
>
> I will try to make this concise.
>
> Background: I am testing the effects of land use and forested riparian buffers on stream invertebrates and in-stream variables. There are 4 watershed types (defined by 4 types of land use) and two riparian types (forested and non). Percent EPT (relative abundance) was my main response variable. I also measured a variety of in-stream variables like temperature, nutrients, and toxicity. There are 72 observations for invertebrates, and 24 for in-stream variables.
>
> I am curious of how acceptable p values are from pairwise comparisons 
> using glht() from the multcomp package
>
> I used glmer with a binomial error structure and an observation-level random effect (to account for overdispersion), to model invertebrates:
>
> modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs), 
> data=ept, family=binomial(link="logit"))
>
> ? AIC ? BIC logLik deviance
> ?284.4 309.5 -131.2 ? ?262.4
> Random effects:
> ?Groups ? ? Name ? ? ? ?Variance Std.Dev.
> ?obs ? ? ? ?(Intercept) 0.30186 ?0.54942
> ?stream:rip (Intercept) 0.40229 ?0.63427
> ?stream ? ? (Intercept) 0.12788 ?0.35760 Number of obs: 72, groups: 
> obs, 72; stream:rip, 24; stream, 12
>
> Fixed effects:
> ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? -4.2906 ? ? 0.4935 ? -8.694 ?< 2e-16 *** wshd ? ? ? ? ? 
> -2.0557 ? ? 0.7601 ?-2.705 0.00684 ** wshf ? ? ? ? ? ?3.3575 ? ? 
> 0.6339 ? 5.297 ?1.18e-07 *** wshg ? ? ? ? ? 3.3923 ? ? 0.7486 ? ?4.531 ?
> 5.86e-06 *** ripN ? ? ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?0.82165 
> wshd:ripN ? ? 0.3708 ? ? 0.9682 ? 0.383 ?0.70170 wshf:ripN ? ?-0.8665 ? ? 
> 0.8087 ? -1.071 ?0.28400 wshg:ripN ? ?-3.1530 ? ? 0.9601 ?-3.284 ?
> 0.00102 **
> ---
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ? ? ? (Intr) ?wshd ? wshf ? wshg ? ripN ? wshd:N wshf:N wshd ? ? ? ?
> -0.649 wshf ? ? ? ?-0.779 ?0.505 wshg ? ? ? ?-0.659 ?0.428 ?0.513 ripN ? ? ? ? 
> -0.644 ?0.418 ?0.501 ?0.424 wshd:ripN ?0.421 -0.672 -0.327 -0.277 
> -0.653 wshf:ripN ?0.503 -0.327 -0.638 -0.332 -0.782 ?0.511 wshg:ripN ?
> 0.424 -0.275 -0.330 -0.632 -0.659 ?0.430 ?0.515
>
>
> I then used this model to do Tukey's HSD contrasts between watershed types:
>
> summary(glht(modelEPT, linfct=mcp(wsh="Tukey"))) Linear Hypotheses:
>
> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|) d - c == 0 
> -2.05573 ? ?0.76010 ?-2.705 ? 0.0341 * f - c == 0 ?3.35753 ? ?0.63386 ? 
> 5.297 ? <0.001 *** g - c == 0 ?3.39231 ? ?0.74862 ? 4.531 ? <0.001 *** 
> f - d == 0 ?5.41326 ? ?0.70176 ? 7.714 ? <0.001 *** g - d == 0 ?
> 5.44804 ? ?0.80692 ? 6.752 ? <0.001 *** g - f == 0 ?0.03479 ? ?0.68931 ? 
> 0.050 ? 1.0000
>
> and riparian types:
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. 
> Error z value Pr(>|z|)
> C: Forested vs. Non-Forested == 0 ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?
> 0.99999
> D: Forested vs. Non-Forested == 0 ? ? ? ? 0.5134 ? ? 0.7332 ? 0.700 ?
> 0.98659
> F: Forested vs. Non-Forested == 0 ? ? ? ?-0.7239 ? ? 0.5042 ?-1.436 ?
> 0.69625
> G: Forested vs. Non-Forested == 0 ? ? ? ?-3.0105 ? ? 0.7225 ?-4.167 ?< 
> 0.001 ***
>
> Are these p values accurate? Or is that a personal judgement I have to make based on the clarity of the patterns they reflect?
>
> I've shown these results in my figures and explained them in my results. I've basically explained that though these p values reasonably reflect patterns in my data, effects sizes, and variances, that they are inexact and potentially anti-conservative due to the issues with degrees of freedom in mixed models.
>
> >From what I understand from my research in the last year is that
> Douglas Bates and others advocate something of a paradigm shift away from the petagogically reinforced reliance on cryptic p values toward more in depth discussions of effects sizes and variances. The use of MCMC sampling and HPD intervals are suggested, but these are not available for generalized models.
>
> I am interested in publishing these results as an ecologist, not a statistician (pardon the somewhat artificial distinction), and, I am very interested in what kind of a discussion the statisticians and ecologists of the r-sig-mixed-models mailing list would like to see as potential reviewers.
>
> Thank you,
>
> Colin Wahl
>
> M.S. candidate,
> Dept. of Biology
> Western Washington University
> Bellingham, WA
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From 20736466 at student.uwa.edu.au  Tue Jan 17 05:04:37 2012
From: 20736466 at student.uwa.edu.au (Angela Eads)
Date: Tue, 17 Jan 2012 12:04:37 +0800
Subject: [R-sig-ME] Interpreting HPD intervals to determine confidence of
	variance components
Message-ID: <CALtYuRaSgPFeQp03v64GuTJOCMkoRSr9Uu_Oondk9wuUcQQb7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120117/92ce7131/attachment-0001.pl>

From rstuff.miles at gmail.com  Tue Jan 17 00:37:14 2012
From: rstuff.miles at gmail.com (Andrew Miles)
Date: Mon, 16 Jan 2012 18:37:14 -0500
Subject: [R-sig-ME] Log-likelihood and mixed models in glmer
In-Reply-To: <loom.20120116T180506-44@post.gmane.org>
References: <0015790A-4E33-4458-A7AE-15650CFC4473@gmail.com>
	<loom.20120116T180506-44@post.gmane.org>
Message-ID: <EB58422B-EB1E-49B5-BDC0-55FE7476EEBB@gmail.com>

Here's the data.  In answer to your questions:

1. Yes, I meant adding predictors should "never" make the model fit the data worse.
2. The variable networth2.gmc is grand-mean centered - actually, I divided the original variable by 100,000 and then centered it to reduce the variable range and make estimation (and interpretation) easier.  Married  is dichotomous, depscore ranges from 0-8, and selfhealth from 0-5.  I did not center the last two since their range is already quite limited.
3. I tried the logLik function, and it returns the same values as anova().

I'm not sure about the convergence problems.  Based on some of the comments I've read about lmer, a convergence problem doesn't mean the estimates aren't reasonable, they only mean the fitting function stalled out without meeting its internal criteria for what an optimal fit looks like (i.e., a clear maximum).  Hence I looked at the parameters estimated at each step, they look to be converging to a set of reasonable parameters, and so I assume the models are reliable.  But if I'm wrong, I'd love to know it, and to know why.

Thanks in advance for all your help!

Andrew Miles


On Jan 16, 2012, at 12:09 PM, Ben Bolker wrote:

> Andrew Miles <rstuff.miles at ...> writes:
> 
>> Can someone point me to a reference that will explain why, when
>> using mixed models (glmer and lmer) adding explanatory variables
>> decreases the log likelihood?  This makes no sense to me, as adding
>> explanatory power should make the model fit the data worse.  I've
>                        ^^^^^
>                        never?
> 
>> attached the data I am using, which contains no missing values, and
>> here are the models I am running, and the results:
> 
>  The attachment didn't make it through to the mailing list.
> Could you post it somewhere (or send it to me)?
> 
>> #note, models do not fully converge, but examination of estimates
>>  using verbose=T suggests they are resonable
> 
>    The fact that they didn't converge (combined with your observation)
> seems like a giant warning message to me ...  hard to say more without
> seeing the data (see above)
> 
>> mod.null = glmer(res.lifesat.last5 ~ 1 + (1|hhidpn) + 
>> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
>> mod1 = glmer(res.lifesat.last5 ~ networth2.gmc + (1|hhidpn) + 
>> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
>> mod2 = glmer(res.lifesat.last5 ~ networth2.gmc + married + (1|hhidpn) +
>> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
>> mod3 = glmer(res.lifesat.last5 ~ networth2.gmc + married + depscore + 
>> selfhealth + (1|hhidpn) +
>> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
> 
>  I have to add some text so the Gmane portal will be happy,
> so let me just add that
> 
>  mod1 <- update(mod.null, . ~ . + networth2.gmc)
>  mod2 <- update(mod1, . ~ . + married)
>  mod3 <- update(mod2, . ~ . + depscore + selfhealth)
> 
>  would be a little bit clearer.
> 
>  Have you tried centering any continuous predictors?
> 
>> #note that mod2 and mod3 have lower log-likelihoods than mod1, 
>> and mod3 has a lower LL than the null model
>> anova(mod.null, mod1, mod2, mod3)
> 
>   Do you get the same results from just using logLik() ?  Perhaps
> anova() is scrambling things up?
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Tue Jan 17 17:38:49 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 17 Jan 2012 10:38:49 -0600
Subject: [R-sig-ME] Fwd: questions about mixed logit models with R
In-Reply-To: <CAO7JsnTBnkoONYVVPceW-Yh13s1-Kfi-ZnzQ_t5v_LOKcdqbwg@mail.gmail.com>
References: <1326812665.2197.YahooMailNeo@web36801.mail.mud.yahoo.com>
	<CAO7JsnTBnkoONYVVPceW-Yh13s1-Kfi-ZnzQ_t5v_LOKcdqbwg@mail.gmail.com>
Message-ID: <CAO7JsnT+HXzFqUjjX=uUt+HgvejURC_XDM8WNwfVkMw1Wd9hEg@mail.gmail.com>

Yet another occasion when I said I would cc: the list and forgot to.


---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Tue, Jan 17, 2012 at 10:38 AM
Subject: Re: questions about mixed logit models with R
To: Angel Tabullo <angeltabullo at yahoo.com>


I suggest that you send such a request to the
R-SIG-Mixed-Models at R-project.org mailing list, which I am copying on
this reply. ?There are several experts who read that list and may be
able to provide help more readily than I can.

On Tue, Jan 17, 2012 at 9:04 AM, Angel Tabullo <angeltabullo at yahoo.com> wrote:
> Dear professor Bates
>
> My name's Angel Tabullo, I'm a phd student and I'm currently working on
> neurolinguistics and experimental psychology. I'm trying to run a mixed
> effects model analysis on some behavioral data with R, but I'm quite new to
> this kind of statistics and I'm having trouble to interpret the results. I'm
> writing to you because I found your tutorial in the web and it was very
> helpful. ?I also wrote to the R-lang mailing list. I will be very thankful
> for any advice you could give me in this matter.
>
> In my experiment, subjects were exposed to artificial languages with
> different word orders (two of them frequent among world languages: SOV, SVO
> and two of them infrequent: VSO, OSV). After training, subject had to
> classify new sentences as "correct" or incorrect, according to what they
> have learned. Sentences could either be correct, contain a syntax violation
> or a semantic violation (mismatch between a scene and the sentences
> describing it). Dependent variables were response latency and accuracy
> (right or wrong answer). I'm trying to analyze the accuracy (1 = right
> answer, 0 = wrong answer) data using a mixed logit model with "word order
> (OSV, SVO, SOV, VSO)" and "type of sentence" (correct, semantic violation,
> syntax violation) as fixed factors, and subject as a random factor. Word
> order is a between subjects variable, while type of sentences is a repeated
> measures factor.
>
> My questions are:
>
> 1) In order to contrast each level of each factor with all the others, as
> well as their interactions: should I ran different models changing the
> reference category? Does this mean I should run 4 x 3 = 12 models?
> 2) Would it be correct to compare interaction levels with post hoc Tukey
> contrasts (for instance: OSV - correct vs. OSV semantic violation, SVO
> correct vs. OSV correct and so on?).
> 3) How do I interpret a significant interaction? For instance:
>
> ModeloAngel = lmer(respuest=="1" ~ grupo * tipoF + (1|sujeto),
> data=DatosAngel, family="binomial")
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? ? ? ? ? ? 1.79585 ? ?0.19196 ? 9.356 ?< 2e-16 ***
> grupoOSV ? ? ? ? ? ? ? ?0.25816 ? ?0.26740 ? 0.965 ? 0.3343
> grupoSOV ? ? ? ? ? ? ? ?0.70875 ? ?0.29315 ? 2.418 ? 0.0156 *
> grupoSVO ? ? ? ? ? ? ? ?0.59607 ? ?0.26769 ? 2.227 ? 0.0260 *
> tipoFVsemanti ? ? ? ? ?-1.01756 ? ?0.14765 ?-6.892 5.51e-12 ***
> tipoFVsintact ? ? ? ? ?-1.46088 ? ?0.14566 -10.029 ?< 2e-16 ***
> grupoOSV:tipoFVsemanti -0.29214 ? ?0.20841 ?-1.402 ? 0.1610
> grupoSOV:tipoFVsemanti -0.39714 ? ?0.23265 ?-1.707 ? 0.0878 .
> grupoSVO:tipoFVsemanti ?0.03181 ? ?0.21459 ? 0.148 ? 0.8821
> grupoOSV:tipoFVsintact ?0.83284 ? ?0.21107 ? 3.946 7.95e-05 ***
> grupoSOV:tipoFVsintact ?0.42079 ? ?0.23408 ? 1.798 ? 0.0722 .
> grupoSVO:tipoFVsintact ?0.16667 ? ?0.21136 ? 0.789 ? 0.4304
>
> If the reference levels are VSO and "correct": does this mean that
> performance of OSV in syntax violations trials is better than that of VSO in
> syntax violation trials. Or does this mean that OSV - syntax violations
> performance is better than VSO - "correct" performance?
>
> Thank you again for your kind attention, I look forward to your answer.



From diegobilski at gmail.com  Tue Jan 17 20:35:11 2012
From: diegobilski at gmail.com (Diego Bilski)
Date: Tue, 17 Jan 2012 17:35:11 -0200
Subject: [R-sig-ME] convergence problems and model averaging
Message-ID: <CA+ViX4r_UuJvpyf5iB_RSzUswyZj5sG4RDdrar5GUUg7L7NF4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120117/cb6ddae8/attachment-0001.pl>

From David.Duffy at qimr.edu.au  Wed Jan 18 00:02:04 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 18 Jan 2012 09:02:04 +1000 (EST)
Subject: [R-sig-ME] convergence problems and model averaging
In-Reply-To: <CA+ViX4r_UuJvpyf5iB_RSzUswyZj5sG4RDdrar5GUUg7L7NF4g@mail.gmail.com>
References: <CA+ViX4r_UuJvpyf5iB_RSzUswyZj5sG4RDdrar5GUUg7L7NF4g@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1201180854020.14745@orpheus.qimr.edu.au>

On Tue, 17 Jan 2012, Diego Bilski wrote:

> Dear list,
>
> I have 1340 observations of animal survival (binomial), and 10 variables in
> my full model (with no interactions between variables). Using lmer() this
> full model didn't converged, then I removed 2 variables that were highly
> correlated (r=0.75 and 0.49) with two other, and this model presented no
> convergence problems.
>
> I standardized variables dividing by 2SD, in the "arm" package, and used
> the dredge() function of "MuMIn" to perform all combinations of variables,
> then selected those with deltaAIC <= 4. But from the 27 models with this
> deltaAIC, 19 presented false convergence warnings.

So, the 8 variable model works, but submodels of this are failing to 
converge?  If you have false convergence warnings, and you are interested 
in that model, you will need to crosscheck that solution using another 
package.  Since you just have a simple random intercept model, you can use
glmmML, glmmADMB, hglm...

Just 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From mcfarlas at uoguelph.ca  Wed Jan 18 00:14:26 2012
From: mcfarlas at uoguelph.ca (Eryn McFarlane)
Date: Tue, 17 Jan 2012 18:14:26 -0500
Subject: [R-sig-ME] BLUPs from MCMCglmm
Message-ID: <04AC4F09-CC5D-47BB-8FD0-8381BD56CAE3@uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120117/1e3ac997/attachment-0001.pl>

From David.Duffy at qimr.edu.au  Wed Jan 18 00:27:56 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 18 Jan 2012 09:27:56 +1000 (EST)
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
In-Reply-To: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de>
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de>
Message-ID: <Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>

On Tue, 17 Jan 2012, Martin Schmettow wrote:

> The problem I have is similar to the capture-recapture approach for
> estimating abundance. In my case the captured animals are design flaws of
> software.
>
> A given number of testers independently tries to find these flaws, which
> makes it a binomial problem. However, flaws that were never discovered
> during the study are not known to the experimenter.

> Furthermore this is a crossed mixed-effects 
> situation as
> discovery trials are repeated over testers and flaws.
>
> (1)    Does effectiveness of testers increases with years of experience?
> (2)    Are certain classes of flaws easier to find than others?
>
> A general finding of previous research is that testers as well as flaws are
> heterogeneous. Some flaws are less visible than others and testers differ in
> overall effectiveness. Hence, random effects are needed to account for
> overdispersion, right?

I may be corrected, but I think your setup is "actually" a Rasch type 
model with each flaw being an item.  Some flaws are just too difficult to 
see, ie the item is "too hard".  I presume, given your research questions, 
you are not actually interested in estimating the number of undetected 
flaws from each class, so a missing data type setup is not really needed.

http://www.jstatsoft.org/v20/a02/paper

is one paper from our esteemed leader ;)

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From jwiley.psych at gmail.com  Wed Jan 18 08:52:11 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 17 Jan 2012 23:52:11 -0800
Subject: [R-sig-ME] family for random coefficients in glmmADMB?
Message-ID: <CANz9Z_LMG_Dkt6HVxwORLUZkw+ZV2_t8qzFP9oOpswUd049vhA@mail.gmail.com>

Hi All,

Apologies if this is an obvious question.  I have been playing with
some random coefficient count models using the glmmADMB package.  I
can specify the family for the response (poisson or negative binomial,
in my case), but I am wondering what distribution is assumed for the
random parameters?  I know it is common to use the conjugate prior of
the response family (gamma for poisson or beta for negative binomial),
but others are theoretically possible, no?

Looking through the documentation did not give me any hints (not to
say they were not there, but at least did not register for me).

Thanks!

Josh


-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From bbolker at gmail.com  Wed Jan 18 15:43:11 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Jan 2012 14:43:11 +0000 (UTC)
Subject: [R-sig-ME] family for random coefficients in glmmADMB?
References: <CANz9Z_LMG_Dkt6HVxwORLUZkw+ZV2_t8qzFP9oOpswUd049vhA@mail.gmail.com>
Message-ID: <loom.20120118T153809-471@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> Apologies if this is an obvious question.  I have been playing with
> some random coefficient count models using the glmmADMB package.  I
> can specify the family for the response (poisson or negative binomial,
> in my case), but I am wondering what distribution is assumed for the
> random parameters?  I know it is common to use the conjugate prior of
> the response family (gamma for poisson or beta for negative binomial),
> but others are theoretically possible, no?

  The random variables are assumed to be normally distributed
on the linear predictor scale (as is almost always the case for GLMMs --
there is a little bit of literature on nonparametric estimation of
mixing/random-effects distributions, and some for different frailty
distributions in survival analysis, but the standard definition of
GLMMs is as I stated).  So in your case the assumed RE distribution
would be lognormal (unless you're using a nonstandard link for your
Poisson or NB models).

If you wanted badly enough to change this it might be hackable, but
I'm not sure how the math underlying the Laplace approximation (or
other approximations used) would hold up under this variation.  If
you really want to experiment with different RE distributions I think
I would suggest the Bayesian (BUGS/JAGS etc. route).



From bbolker at gmail.com  Wed Jan 18 15:51:36 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Jan 2012 14:51:36 +0000 (UTC)
Subject: [R-sig-ME] BLUPs from MCMCglmm
References: <04AC4F09-CC5D-47BB-8FD0-8381BD56CAE3@uoguelph.ca>
Message-ID: <loom.20120118T154325-109@post.gmane.org>

Eryn McFarlane <mcfarlas at ...> writes:

> 
> Dear list,
> 
> I was wondering if anyone knew of a way to estimate BLUPs
>  from an MCMCglmm model? I would just like to eyeball
> the individuals with high and low BLUPs for my trait to 
> see if there are other relationships that I can see
> (i.e. year effects, affect of territory). Does this make sense to try to do
from these models?


  I *think* you can just look at the $Liab component of the fit,
which as stated is the posterior distribution of the latent variables --
you need to set pl=TRUE.

  This should get you started (although HPDinterval() isn't
behaving sensibly in this case -- not quite sure why not)

 data(PlodiaPO)  
     model1<-MCMCglmm(PO~1, random=~FSfamily, data=PlodiaPO, 
    verbose=FALSE, pl=TRUE)
str(model1$Liab)
mm <- data.frame(m=colMeans(model1$Liab),HPDinterval(model1$Liab))
plot(mm[order(mm$m),"m")



From schmettow at web.de  Thu Jan 19 11:53:54 2012
From: schmettow at web.de (Martin Schmettow)
Date: Thu, 19 Jan 2012 11:53:54 +0100
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
In-Reply-To: <Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de>
	<Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
Message-ID: <000301ccd698$a32bee00$e983ca00$@web.de>

> > The problem I have is similar to the capture-recapture approach for
> > estimating abundance. In my case the captured animals are design flaws
> > of software.
> >
> > A given number of testers independently tries to find these flaws,
> > which makes it a binomial problem. However, flaws that were never
> > discovered during the study are not known to the experimenter.
> 
> I may be corrected, but I think your setup is "actually" a Rasch type
model
> with each flaw being an item.  Some flaws are just too difficult to see,
ie the
> item is "too hard".  I presume, given your research questions, you are not
> actually interested in estimating the number of undetected flaws from each
> class, so a missing data type setup is not really needed.
> 
> http://www.jstatsoft.org/v20/a02/paper
> 
> is one paper from our esteemed leader ;)

In one of my works on that topic I, indeed, viewed this as a Rasch type
model. And I well remember how excited I got when reading above paper,
because that would allow me to deal with predictors in a straight forward
way.

However, the number of undetected flaws is crucial by itself as it means to
go on testing. Capture-recapture models are a good way to estimate these,
but they don't allow for predictors. So, if I run a crossed mixed effects
logistic regression on my data, I have missing values.

So, while the above paper merges IRT models with (crossed) mixed effects
models (and that's great!), I would need sth. that merges the latter with
C-R models. C-R models do deal with sort of random effects: the
heterogeneous capturability of animals (denoted "h") and variability in
trials ("t"). So called Mht models could thus be viewed as crossed random
effects models, but: C-R models (afaik) don't deal with predictors and
mixed-effects models require at least missing-at-random, which is not the
case.

Any ideas?

CU, Martin



From j.hadfield at ed.ac.uk  Thu Jan 19 12:29:02 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 19 Jan 2012 11:29:02 +0000
Subject: [R-sig-ME] MCMCglmm output 1) on right scale? 2) produces huge
	deviance spread?
In-Reply-To: <CAEQ+J25=0+CaK8hUMcyOqvM88GTTvU+eOpkqEqKmg_Aa=Nmw2Q@mail.gmail.com>
References: <CAEQ+J25=0+CaK8hUMcyOqvM88GTTvU+eOpkqEqKmg_Aa=Nmw2Q@mail.gmail.com>
Message-ID: <DCD97396-3404-4568-88FD-6736C53375E9@ed.ac.uk>

Hi Ryan,

Sorry for not replying earlier - I've been away for two months. I'm  
having trouble understanding the issues but my gut feeling (especially  
for the second issue) is that they arise because of the error variance  
being set to one in MCMCglmm rather than zero as in glm.  For example,

id<-gl(100,2)  # 100 individuals observed twice
u<-rnorm(100)  # individual random effects ~ N(0,1)
lp<-u[id]+rnorm(200)  # linear predictor includes error ~ N(0,1)

y<-rbinom(200, 1, plogis(lp))  # response (with logit link)

glm(y~lp, family="binomial")$coef[2]

# regression on linear predictor should have coefficient of 1 on  
average as you suggest

glm(y~u[id], family="binomial")$coef[2]

# regression on linear predictor omitting noise has a coefficient < 1

Section 2.5 has ways of obtaining a rescaled linear predictor for the  
logit link, but the probit link may be a bit easier to work with in  
this respect as you can set the variance of the normal in the cdf  
calculation to 2 rather than 1.

Alternatively you could extract the latent variables (pl=TRUE) stored  
under Liab, which are the linear predictors including the noise term

Note sure this helps for the first problem though - perhaps you could  
provide the simulation code together with comments on what you expect  
to happen?

Cheers,

Jarrod







On 15 Jan 2012, at 19:35, Ryan King wrote:

> Hi, I have an MCMCglmm run predicting a binary outcome with a single
> fixed effect and two groups of random effects like so
>
> testprior4<-list( R=list(V=1, fix=1), G=list(G1=list(V=1, nu=1,
> alpha.mu=0, alpha.v=.5^2 ), G2=list(V=1, nu=1, alpha.mu=0, alpha.v=1 )
> ), B=list(mu=c(0,0), V=diag(2)*4 ) )
>
> testmcmc5b<-MCMCglmm(fixed=myy2~myx,random=~idv(myz)+idv(newz3)   ,
> family = "ordinal", prior= testprior4, data=mydata, nitt=6000,
> thin=10, burnin=5000 , pr=TRUE)
>
> I can provide the full simulation details, but hope that this is a
> general rather than specific problem.
>
> The first set of random effects have large effects, but the second set
> is just noise.
>
> I'm setting up a bridge sampler to get a bayes factor, which means I
> need to get a log-likelihood + log-prior for my proposal.
>
> I tested my log-likelihood calculation with  MCMC output and got
> atrociously spread out log-likelihoods (sd of 15-20). That seems like
> rather a lot on the log scale, and means that numerical problems are
> likely for the bridge sampler. GLM produces the same deviance up to a
> constant (regressing the outcome versus the linear predictor), so that
> function is fine. This problem is much smaller when using only the
> true predictors (sd = 6) .  The estimated variance component for the
> noise predictors never goes above .015, so that they cause this
> problem is surprising. Is there a handy explanation / work around?
>
> More troubling, a calibration exercise in the deviance calculation
> showed that the groups of linear predictors were not on the right
> scale.
> That is, multiplying through the two sets of random effects and design
> matrices to get batches of linear predictors, and running a glm of the
> binary outcome versus the linear predictors using a probit (or logit)
> link gets coefficients consistently not 1. The true random effects get
> a coefficient of about .65, and the noise random effects between .7
> and .4 depending on how I set them up. I don't think it's a bad mixing
> problem, because 1) I have gotten the same thing on independent
> chains, 2) effectiveSize() reports large effective samples 3) there is
> quite a bit of spread in the deviances.  This problem persists if I
> run with family="categorical".
>
> When I plug in the re-calibrated linear predictor, the sd of the
> log-likelihood goes down a lot, from 15 to 6 in the
> two-predictor-group case and from 6 to 3 when using only the true
> predictors. That's much better, but still quite a premium for having a
> group of noise predictors.
>
> Thanks,
> Ryan King
> Dept Health Studies
> University of Chicago
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Thu Jan 19 12:34:43 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 19 Jan 2012 11:34:43 +0000
Subject: [R-sig-ME] BLUPs from MCMCglmm
In-Reply-To: <loom.20120118T154325-109@post.gmane.org>
References: <04AC4F09-CC5D-47BB-8FD0-8381BD56CAE3@uoguelph.ca>
	<loom.20120118T154325-109@post.gmane.org>
Message-ID: <AF39FC02-9621-4928-9871-ED8343C91FFC@ed.ac.uk>

Hi,

The random effects are actually stored in Sol (solutions) and will be  
saved if you use the argument pr=TRUE.  The marginal posterior modes  
of the random effects should coincide with BLUPs if the variances are  
fixed a priori to the value used when obtaining BLUPs and the fixed  
effects are either fixed a priori or are given improper flat priors.  
However, in practice (i.e. when the variances are not fixed etc.) the  
correlation between BLUPs and marginal posterior modes is usually very  
very high.

Be aware that if you have many (m) random effects and you store many  
(n) iterations you end up with a lot (m*n) of numbers  to store.

Cheers,

Jarrod




On 18 Jan 2012, at 14:51, Ben Bolker wrote:

> Eryn McFarlane <mcfarlas at ...> writes:
>
>>
>> Dear list,
>>
>> I was wondering if anyone knew of a way to estimate BLUPs
>> from an MCMCglmm model? I would just like to eyeball
>> the individuals with high and low BLUPs for my trait to
>> see if there are other relationships that I can see
>> (i.e. year effects, affect of territory). Does this make sense to  
>> try to do
> from these models?
>
>
>  I *think* you can just look at the $Liab component of the fit,
> which as stated is the posterior distribution of the latent  
> variables --
> you need to set pl=TRUE.
>
>  This should get you started (although HPDinterval() isn't
> behaving sensibly in this case -- not quite sure why not)
>
> data(PlodiaPO)
>     model1<-MCMCglmm(PO~1, random=~FSfamily, data=PlodiaPO,
>    verbose=FALSE, pl=TRUE)
> str(model1$Liab)
> mm <- data.frame(m=colMeans(model1$Liab),HPDinterval(model1$Liab))
> plot(mm[order(mm$m),"m")
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Thu Jan 19 14:07:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 19 Jan 2012 13:07:22 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
	<loom.20120112T173419-47@post.gmane.org>
	<loom.20120117T004350-179@post.gmane.org>
Message-ID: <loom.20120119T140202-20@post.gmane.org>

Lorenzo Quaglietta <giaguarenzo at ...> writes:

> 
> Ben Bolker <bbolker at ...> writes:
> 
> >   It means that it doesn't make sense to use a numeric variable as
> > a grouping variable for a random factor (which is what you've done):
> > if sl is a discrete numeric code that identifies groups of observations,
> > then you should convert it to a factor.  If it's a continuous variable,
> > then you need to go back and read/think some more about the meanings
> > of random factors ...
> > 
> >   It also means that I made some changes to glmmADMB recently that
> > got in the way of an informative error message (you should have
> > received an error message that told you this).  I will try to 
> > catch that error in a more informative way.
> > 
> My model formula is:
> 
> glmmADMB1 <- glmmadmb(Fix ~ log_BIO_F * log_BIO_P + log_drs + fperp + log_pr +
> log_la + (1 | ANIMALE) + (1 | ID) + (1 | Time), 
> data=otters, zeroInflation=TRUE,
> family="poisson").
> 
> and I got the following error message:
> 
> "Error in UseMethod("droplevels") : 
>   no applicable method for 'droplevels' applied to an object of class
> "c('integer', 'numeric')".
> 
> My random terms are not categorical nor fitted as factors. Covariates are
> continous (the log_ ones) and a factor (fperp). Any clue about what can be the
> problem would be very appreciated.

  Can you be clearer about what you mean by "my random terms are not 
categorical nor fitted as factors"?  Grouping terms in glmmADMB
*must* be defined as factors (i.e. you must convert ANIMALE, ID,
Time to factors).
   I could have made glmmADMB make this conversion internally,
but I thought it was better to make this the user's responsibility,
so that if someone were doing something strange (like trying to
use a continuous variable as a grouping factor, on the right side
of the bar in (1|g)) it would be more immediately obvious.

  In general, it would be very helpful if you can include the
version of glmmADMB in any query, as the package is evolving very
quickly.  If you install the latest version (0.7.2.5) you should
still get an error, but the error will be (slightly) more
informative -- it will tell you that all grouping variables
must be factors.

  Ben Bolker



From jwiley.psych at gmail.com  Thu Jan 19 17:29:20 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 19 Jan 2012 08:29:20 -0800
Subject: [R-sig-ME] family for random coefficients in glmmADMB?
In-Reply-To: <loom.20120118T153809-471@post.gmane.org>
References: <CANz9Z_LMG_Dkt6HVxwORLUZkw+ZV2_t8qzFP9oOpswUd049vhA@mail.gmail.com>
	<loom.20120118T153809-471@post.gmane.org>
Message-ID: <CANz9Z_LYCnjhAo_=vq+x=1xvL28Xxi9faUOfq+2P=c5_vF5LKw@mail.gmail.com>

Hi Ben,

Thanks for the information.  If normal is the usual case, that is
fine.  Mostly I just wanted to know what was done---from reading
Agresti's book on Categorical Data Analysis, I got the sense that
different distributions were used, but I could have just misread.

Thanks again,

Josh

On Wed, Jan 18, 2012 at 6:43 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Joshua Wiley <jwiley.psych at ...> writes:
>
>> Apologies if this is an obvious question. ?I have been playing with
>> some random coefficient count models using the glmmADMB package. ?I
>> can specify the family for the response (poisson or negative binomial,
>> in my case), but I am wondering what distribution is assumed for the
>> random parameters? ?I know it is common to use the conjugate prior of
>> the response family (gamma for poisson or beta for negative binomial),
>> but others are theoretically possible, no?
>
> ?The random variables are assumed to be normally distributed
> on the linear predictor scale (as is almost always the case for GLMMs --
> there is a little bit of literature on nonparametric estimation of
> mixing/random-effects distributions, and some for different frailty
> distributions in survival analysis, but the standard definition of
> GLMMs is as I stated). ?So in your case the assumed RE distribution
> would be lognormal (unless you're using a nonstandard link for your
> Poisson or NB models).
>
> If you wanted badly enough to change this it might be hackable, but
> I'm not sure how the math underlying the Laplace approximation (or
> other approximations used) would hold up under this variation. ?If
> you really want to experiment with different RE distributions I think
> I would suggest the Bayesian (BUGS/JAGS etc. route).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From bbolker at gmail.com  Thu Jan 19 17:44:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 19 Jan 2012 16:44:16 +0000 (UTC)
Subject: [R-sig-ME] family for random coefficients in glmmADMB?
References: <CANz9Z_LMG_Dkt6HVxwORLUZkw+ZV2_t8qzFP9oOpswUd049vhA@mail.gmail.com>
	<loom.20120118T153809-471@post.gmane.org>
	<CANz9Z_LYCnjhAo_=vq+x=1xvL28Xxi9faUOfq+2P=c5_vF5LKw@mail.gmail.com>
Message-ID: <loom.20120119T173642-530@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> 
> Hi Ben,
> 
> Thanks for the information.  If normal is the usual case, that is
> fine.  Mostly I just wanted to know what was done---from reading
> Agresti's book on Categorical Data Analysis, I got the sense that
> different distributions were used, but I could have just misread.
> 

  I think it depends on whether you focus on ch 12 of Agresti (which
is about classical GLMMs) or ch 13 (which is about other kinds of mixture
models).  One possible confusion is that negative binomial models are
right at the edge of what one can define as GLMMs, because the NB
with unspecified overdispersion parameter (k) is not in the exponential
family -- NB models like those in MASS::glm.nb() use an outer loop
over possible values.  The NB mixed models that glmmADMB fits are
a bit of a hybrid -- one can think of them as models with Poisson
responses that use Gamma-distributed random effects at the
among-individual level, and log-normal distributed random effects
at all of the other levels.

   Ben

> 
> On Wed, Jan 18, 2012 at 6:43 AM, Ben Bolker <bbolker <at> gmail.com> wrote:
> > Joshua Wiley <jwiley.psych at ...> writes:
> >
> >> Apologies if this is an obvious question. ?I have been playing with
> >> some random coefficient count models using the glmmADMB package. ?I
> >> can specify the family for the response (poisson or negative binomial,
> >> in my case), but I am wondering what distribution is assumed for the
> >> random parameters? ?I know it is common to use the conjugate prior of
> >> the response family (gamma for poisson or beta for negative binomial),
> >> but others are theoretically possible, no?
> >
> > ?The random variables are assumed to be normally distributed
> > on the linear predictor scale (as is almost always the case for GLMMs --
> > there is a little bit of literature on nonparametric estimation of
> > mixing/random-effects distributions, and some for different frailty
> > distributions in survival analysis, but the standard definition of
> > GLMMs is as I stated). ?So in your case the assumed RE distribution
> > would be lognormal (unless you're using a nonstandard link for your
> > Poisson or NB models).
> >
> > If you wanted badly enough to change this it might be hackable, but
> > I'm not sure how the math underlying the Laplace approximation (or
> > other approximations used) would hold up under this variation. ?If
> > you really want to experiment with different RE distributions I think
> > I would suggest the Bayesian (BUGS/JAGS etc. route).
> >
> > _______________________________________________
> > R-sig-mixed-models <at> r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From David.Duffy at qimr.edu.au  Fri Jan 20 00:42:19 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 20 Jan 2012 09:42:19 +1000
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de><Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
	<000301ccd698$a32bee00$e983ca00$@web.de>
Message-ID: <6F35A958A12B9149BD16E3C2F3B0AD0DB37864@SPHINX.adqimr.ad.lan>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120120/63f0d4b1/attachment-0001.pl>

From raptorbio at hotmail.com  Fri Jan 20 05:22:00 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Thu, 19 Jan 2012 23:22:00 -0500
Subject: [R-sig-ME] GLMM parameter interpretation
Message-ID: <BAY170-W226D02A52B38596C044A97A1870@phx.gbl>


All,

A quick question, and an easy one I expect.

Suppose the following generic overdispersed log-linear model:

Count ~ A + B + C + (1|level1) + (1|level2) + (1|obs)

A, B, and C are all factors.
A does not vary within level1 subjects.
B does not vary within level2 subjects.
C varies within level 1 and level 2 subjects.

Does the conditional nature of the GLMM and the lack of variation in A (within level 1 subjects) and B (within level 2 subjects) result in nonsensical or uninterpretable coefficients for these two covariates?

Thanks,

Adam Smith
Dept. Natural Resources Science
105 Coastal Institute in Kingston
University of Rhode Island
 		 	   		  


From Thierry.ONKELINX at inbo.be  Fri Jan 20 09:31:03 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 20 Jan 2012 08:31:03 +0000
Subject: [R-sig-ME] GLMM parameter interpretation
In-Reply-To: <BAY170-W226D02A52B38596C044A97A1870@phx.gbl>
References: <BAY170-W226D02A52B38596C044A97A1870@phx.gbl>
Message-ID: <AA818EAD2576BC488B4F623941DA74275732F45B@inbomail.inbo.be>

A quick answer: No

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Adam Smith
Verzonden: vrijdag 20 januari 2012 5:22
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] GLMM parameter interpretation


All,

A quick question, and an easy one I expect.

Suppose the following generic overdispersed log-linear model:

Count ~ A + B + C + (1|level1) + (1|level2) + (1|obs)

A, B, and C are all factors.
A does not vary within level1 subjects.
B does not vary within level2 subjects.
C varies within level 1 and level 2 subjects.

Does the conditional nature of the GLMM and the lack of variation in A (within level 1 subjects) and B (within level 2 subjects) result in nonsensical or uninterpretable coefficients for these two covariates?

Thanks,

Adam Smith
Dept. Natural Resources Science
105 Coastal Institute in Kingston
University of Rhode Island
 		 	   		  
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From giorgio.arcara at gmail.com  Fri Jan 20 11:53:37 2012
From: giorgio.arcara at gmail.com (Giorgio Arcara)
Date: Fri, 20 Jan 2012 11:53:37 +0100
Subject: [R-sig-ME] lme or lmer?
Message-ID: <43825DBA-F86F-4732-AFE1-4B139B572331@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120120/2ceb0486/attachment-0001.pl>

From Julia.Sommerfeld at utas.edu.au  Fri Jan 20 15:11:46 2012
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Fri, 20 Jan 2012 15:11:46 +0100
Subject: [R-sig-ME] Off the topic: Problem with ISOdatetime
Message-ID: <CAOCHjhSBrbpdf-r+OsUMMw_sizTM=JhR+hZnCM+EBpAq7-UC0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120120/31631e0d/attachment-0001.pl>

From Thierry.ONKELINX at inbo.be  Fri Jan 20 15:27:29 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 20 Jan 2012 14:27:29 +0000
Subject: [R-sig-ME] Off the topic: Problem with ISOdatetime
In-Reply-To: <CAOCHjhSBrbpdf-r+OsUMMw_sizTM=JhR+hZnCM+EBpAq7-UC0A@mail.gmail.com>
References: <CAOCHjhSBrbpdf-r+OsUMMw_sizTM=JhR+hZnCM+EBpAq7-UC0A@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275732F7EA@inbomail.inbo.be>

Dear Julia,

R-help is a better forum for this kind of questions.

Have a look at the timezones and daylight saving time. That might be the problem.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Julia Sommerfeld
Verzonden: vrijdag 20 januari 2012 15:12
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Off the topic: Problem with ISOdatetime

Dear list,

This question is probably off the topic, but in order to test my data with GLMM, I need to transform the DateTime of my GPS data from:

"666.1751" into yyyy/mm/dd hh:mm:ss

I have the following code:

d$Date <- ISOdatetime(2009, 1, 1, 0, 0, 0, tz = "GMT")+d$Date*(24*3600)

This gives me: 2010-10-29 04:12:09, which is wrong. It should be 2010-10-29
06:12:09

Another example:

418.3219 corresponds to: 2010-02-23 07:43:30, but it should be 2010-02-23 08:43:30.

Any ideas or suggestions, where I could find the answer, are very much appreciated.

Best regards,

Julia

PS. I've tried to find the answer in all sorts of R help forums and also in my R books - no luck so far. Maybe I'm missunderstanding the entire ISOdatetime function?



--
Julia Sommerfeld - PhD Candidate
Institute for Marine and Antarctic Studies University of Tasmania Private Bag 129, Hobart TAS 7001

Phone: +61 477 289 301
Email: julia.somma at gmx.de
Julia.Sommerfeld at utas.edu.au

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rense.nieuwenhuis at gmail.com  Fri Jan 20 15:35:41 2012
From: rense.nieuwenhuis at gmail.com (Rense Nieuwenhuis)
Date: Fri, 20 Jan 2012 15:35:41 +0100
Subject: [R-sig-ME] Sresid with lme4
Message-ID: <ACC83A31-75F9-4938-A1C1-7D94A5D0E815@gmail.com>

Dear All,

I was hoping anyone knows if it is possible to extract or calculate studentized residuals (sresid) for mixed effects models estimated with the lme4 package? 

Any help or suggestions would be greatly appreciated. 

With kind regards,
Rense


From d.rizopoulos at erasmusmc.nl  Fri Jan 20 15:45:37 2012
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Fri, 20 Jan 2012 15:45:37 +0100
Subject: [R-sig-ME] Sresid with lme4
In-Reply-To: <ACC83A31-75F9-4938-A1C1-7D94A5D0E815@gmail.com>
References: <ACC83A31-75F9-4938-A1C1-7D94A5D0E815@gmail.com>
Message-ID: <4F197E11.9050602@erasmusmc.nl>

Several types of residuals for linear mixed models are mentioned in the 
following article:

@Article{nobre.singer:07,
   author    = {Nobre, J. and Singer, J.},
   journal   = {Biometrical Journal},
   pages     = {863--875},
   title     = {Residuals analysis for linear mixed models},
   volume    = {6},
   year      = {2007}
}

Probably it would be feasible to calculate them by extracting the 
required components from an 'mer' object.

Best,
Dimitris


On 1/20/2012 3:35 PM, Rense Nieuwenhuis wrote:
> Dear All,
>
> I was hoping anyone knows if it is possible to extract or calculate studentized residuals (sresid) for mixed effects models estimated with the lme4 package?
>
> Any help or suggestions would be greatly appreciated.
>
> With kind regards,
> Rense
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web: http://www.erasmusmc.nl/biostatistiek/



From lborger at cebc.cnrs.fr  Fri Jan 20 16:08:17 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Fri, 20 Jan 2012 16:08:17 +0100
Subject: [R-sig-ME] Sresid with lme4
In-Reply-To: <4F197E11.9050602@erasmusmc.nl>
References: <ACC83A31-75F9-4938-A1C1-7D94A5D0E815@gmail.com>
	<4F197E11.9050602@erasmusmc.nl>
Message-ID: <4F198361.7060003@cebc.cnrs.fr>




Codes employed for the analysis of the example and the simulation
developed in R (function lmmresdidual ) and can be obtained directly
from the authors
 >Probably it would be feasible to calculate them by extracting the 
required components from an 'mer' object.

In case this is useful, the slides of a recent presentation on residual 
analysis for LMMs by Singer&Nobre are available online 
(http://www.ime.usp.br/~jmsinger/MAE0610/Mixedmodelresiduals.pdf 
<http://www.ime.usp.br/%7Ejmsinger/MAE0610/Mixedmodelresiduals.pdf>) and 
the authors state at the end:

"Codes employed for the analysis of the example and the simulation
developed in R (function lmmresdidual ) and can be obtained directly
from the authors"


Cheers,

Luca




* forthcoming conference "Ecology and Behaviour"
* April 2-6 2012 Chize (France)
* http://serl2012.org
---------------------------------------------------------------------
Luca Borger
Postdoctoral Research Fellow
Centre d'Etudes Biologiques de Chiz?
CNRS (UPR1934); INRA (USC1339)
79360 Beauvoir-sur-Niort, France

Tel: +33 (0)549 09 96 13
Fax: +33 (0)549 09 65 26
email: lborger at cebc.cnrs.fr
Web: http://cnrs.academia.edu/LucaBorger
Researcher ID: http://www.researcherid.com/rid/C-6003-2008
Google Scholar: http://scholar.google.com/citations?user=D5CTvNUAAAAJ
---------------------------------------------------------------------
# Newly published! Animal Migration: A synthesis (ch. 8):
# http://ukcatalogue.oup.com/product/9780199568994.do



Le 20/01/2012 15:45, Dimitris Rizopoulos a ?crit :
> Several types of residuals for linear mixed models are mentioned in 
> the following article:
>
> @Article{nobre.singer:07,
>   author    = {Nobre, J. and Singer, J.},
>   journal   = {Biometrical Journal},
>   pages     = {863--875},
>   title     = {Residuals analysis for linear mixed models},
>   volume    = {6},
>   year      = {2007}
> }
>
> Probably it would be feasible to calculate them by extracting the 
> required components from an 'mer' object.
>
> Best,
> Dimitris
>
>
> On 1/20/2012 3:35 PM, Rense Nieuwenhuis wrote:
>> Dear All,
>>
>> I was hoping anyone knows if it is possible to extract or calculate 
>> studentized residuals (sresid) for mixed effects models estimated 
>> with the lme4 package?
>>
>> Any help or suggestions would be greatly appreciated.
>>
>> With kind regards,
>> Rense
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From raptorbio at hotmail.com  Fri Jan 20 16:18:31 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Fri, 20 Jan 2012 10:18:31 -0500
Subject: [R-sig-ME] GLMM parameter interpretation
In-Reply-To: <AA818EAD2576BC488B4F623941DA74275732F45B@inbomail.inbo.be>
References: <BAY170-W226D02A52B38596C044A97A1870@phx.gbl>,
	<AA818EAD2576BC488B4F623941DA74275732F45B@inbomail.inbo.be>
Message-ID: <BAY170-W5E71DBF9459672E20E74BA1870@phx.gbl>


Thanks, although I should correct an omission in my description.? Factor A does not vary within level 1 OR level 2 subjects.? Does this change anything for that covariate?

Adam

----------------------------------------
> From: Thierry.ONKELINX at inbo.be
> To: raptorbio at hotmail.com; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] GLMM parameter interpretation
> Date: Fri, 20 Jan 2012 08:31:03 +0000
>
> A quick answer: No
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Adam Smith
> Verzonden: vrijdag 20 januari 2012 5:22
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] GLMM parameter interpretation
>
>
> All,
>
> A quick question, and an easy one I expect.
>
> Suppose the following generic overdispersed log-linear model:
>
> Count ~ A + B + C + (1|level1) + (1|level2) + (1|obs)
>
> A, B, and C are all factors.
> A does not vary within level1 subjects.
> B does not vary within level2 subjects.
> C varies within level 1 and level 2 subjects.
>
> Does the conditional nature of the GLMM and the lack of variation in A (within level 1 subjects) and B (within level 2 subjects) result in nonsensical or uninterpretable coefficients for these two covariates?
>
> Thanks,
>
> Adam Smith
> Dept. Natural Resources Science
> 105 Coastal Institute in Kingston
> University of Rhode Island
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  


From erikfrenzel at gmail.com  Fri Jan 20 17:29:08 2012
From: erikfrenzel at gmail.com (Erik Frenzel)
Date: Fri, 20 Jan 2012 08:29:08 -0800
Subject: [R-sig-ME]  GLMM parameter interpretation
Message-ID: <CANJAy045CYuHy60BLm92TFVKpUnTNRvpy-0H==Arb5i_mnkUOQ@mail.gmail.com>

Adam,
I had a similar question and found this post helpful:

http://r.789695.n4.nabble.com/lme4-and-Variable-level-detection-td881680.html

Erik

> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 19 Jan 2012 23:22:00 -0500
> From: Adam Smith <raptorbio at hotmail.com>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] GLMM parameter interpretation
> Message-ID: <BAY170-W226D02A52B38596C044A97A1870 at phx.gbl>
> Content-Type: text/plain; charset="iso-8859-1"
>
>
> All,
>
> A quick question, and an easy one I expect.
>
> Suppose the following generic overdispersed log-linear model:
>
> Count ~ A + B + C + (1|level1) + (1|level2) + (1|obs)
>
> A, B, and C are all factors.
> A does not vary within level1 subjects.
> B does not vary within level2 subjects.
> C varies within level 1 and level 2 subjects.
>
> Does the conditional nature of the GLMM and the lack of variation in A (within level 1 subjects) and B (within level 2 subjects) result in nonsensical or uninterpretable coefficients for these two covariates?
>
> Thanks,
>
> Adam Smith
> Dept. Natural Resources Science
> 105 Coastal Institute in Kingston
> University of Rhode Island



From slu at ccsr.uchicago.edu  Fri Jan 20 20:06:05 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Fri, 20 Jan 2012 13:06:05 -0600
Subject: [R-sig-ME] Confusion specifiying random effect interactions
Message-ID: <1327086365.3052.27.camel@localhost>

Hello, I'm interested in determining whether teachers are better at
teaching one subject than another. I have a data set of reading and math
value-added measures for students grouped by classroom. Here is a
portion of the dataset:

            vam grade  classroom Subject
9    0.246568321     4   2860A104    Math
10   0.282774796     4    3510108    Math
25   0.203518951     4   5180A111    Math
26   0.924048731     4   8000A201    Math
27   0.005249245     4   5140A213    Math
37   0.145352029     4   3430A205    Math
46   0.015531502     4   6100A202    Math
47   0.412358095     4   6370A111    Math
51   0.165086054     4   6950A103    Math
56   0.830843297     4   3040A200    Math
59   0.259168594     4   6610A202    Math
62   0.497570314     4   3360A203    Math
961  0.872717363     4   3240A207    Math


My aim is to get the within-classroom, between-subject correlation, and
the fixed effect for subject. I ran two models:

lme1 <- lmer(data=data.all,
     formula=vam ~ grade + Subject +  (Subject|classroom))
     
lme2 <- lmer(data=data.all,
     formula=vam ~ grade + Subject +  (0 + Subject|classroom))
     
lme1 gives these variance components:

Linear mixed model fit by REML 
Formula: vam ~ grade + Subject + (Subject | classroom) 
   Data: data.all 
   AIC   BIC logLik deviance REMLdev
 42844 42924 -21414    42787   42828
Random effects:
 Groups    Name        Variance  Std.Dev. Corr  
 classroom (Intercept) 0.0079163 0.088974       
           SubjectRead 0.0069161 0.083163 0.041 
 Residual              0.0721588 0.268624       
Number of obs: 161031, groups: classroom, 3786

If I'm interpreting this correctly, this gives the between-classroom
variance, and the between-subject variance, and the correlation between
the intercept and the subject effect. (The fixed effect for Subject is
insignificantly small.)

The second model gives this:
Linear mixed model fit by REML 
Formula: vam ~ grade + Subject + (0 + Subject | classroom) 
   Data: data.all 
   AIC   BIC logLik deviance REMLdev
 42844 42924 -21414    42787   42828
Random effects:
 Groups    Name        Variance  Std.Dev. Corr  
 classroom SubjectMath 0.0079163 0.088974       
           SubjectRead 0.0154327 0.124228 0.743 
 Residual              0.0721588 0.268624       
Number of obs: 161031, groups: classroom, 3786

This one gives the correlation between Reading and Math, but puts all
the between-classroom variance into the subject-classroom interaction.
I'm thinking that in order to make the correct inferences I should have
a combination of these two with a between-classroom variance component,
and a subject-by-classroom component, but I can't figure out how to do
it in one model. I would appreciate any help I can get.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.1.6-gentoo                
I'm always thrilled when people discover what
 lexical scoping really means.    -- Robert
 Gentleman       Statistical Computing 2003,
 Reisensburg (June 2003)



From bbolker at gmail.com  Sat Jan 21 16:54:00 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Jan 2012 15:54:00 +0000 (UTC)
Subject: [R-sig-ME] lme or lmer?
References: <43825DBA-F86F-4732-AFE1-4B139B572331@gmail.com>
Message-ID: <loom.20120121T041825-883@post.gmane.org>

Giorgio Arcara <giorgio.arcara at ...> writes:

> I would like to use mixed models in R to analyze EEG data, but I don't  
> know if it is more correct to use lme or lmer.
> My data have the following structure
> 
> Subject	Electrode	 Interval	Trial 	Condition	Ampl
> 1		Fp1		200-300		1	A		3.5
> 1		Fp1		200-300		2	B		4.2
> 1		Fp2		400-600		1	A		6.5
> 1		Fp2		400-600		2	B		3.3
> 2		Fp1		200-300		1	A		2.1
> 2		Fp1		200-300		2	B		-5.4
> 2		Fp2		400-600		1	A		-5.6
> 2		Fp2		400-600		2	B		-3.2

 [snip]

  In general if you *can* use either lme or lmer (i.e. the random effects are
not nested, there is no heteroscedasticity or correlation structure at the
level of residuals ...) then either is OK.  I generally recommend lme in 
these cases (with apologies to Doug Bates) because it is better documented,
although it's slower.

> For sake of simplicity, here I include only 2 Trials but in the real  
> dataset they are many more.
> In this hypothetical dataset Ampl is the depentent variable. Electrode  
> and Interval are two predictors. I expect that levels of Electrode  
> will be highly correlated as well the levels of Interval.

  ?? Meaning that most instances of FP1 have Interval 200-300, most
of Fp2 have 400-500, and there are few 'crossover' instances where you
have FP1 with 400-500 and FP2 with 200-300?  This will in general make
it hard to estimate to distinguish the two effects ... but presumably
you know that.

> My goal is to study if Condition influence Ampl and if interact with  
> Electrode variable and Interval Variable.
> 
> I would fit a model on these data with lmer with the following structure
> 
> mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject) 
> +(1+Interval|Subject))
> If I'm correct the corresponding lme model would be
> 
> mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition| 
> Subject, ~1+Interval|Subject))

  Why not (Electrode+Interval|Subject)?  That (a) avoids a duplicated intercept
term and (b) estimates correlations between the intercept, electrode, and
Interval RE.

> Any suggestion for covariance matrix specification in lme?

  Do you need one other than the default -- i.e. do you expect
any particular correlation structure?



From trea26 at gmail.com  Sat Jan 21 17:55:50 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sat, 21 Jan 2012 12:55:50 -0400
Subject: [R-sig-ME] lme or lmer?
In-Reply-To: <mailman.3.1327057203.19517.r-sig-mixed-models@r-project.org>
References: <mailman.3.1327057203.19517.r-sig-mixed-models@r-project.org>
Message-ID: <4F1AEE16.3090801@gmail.com>

Hey Giorgio!

I have one published paper in JoCN where we analyzed ERP data using 
LMER, another one is on the way, and a methods paper is almost finished 
and submitted to NeuroImage regarding the addition of by-item random 
intercepts and slopes to the model. I'm sending you a copy of the JoCN 
paper (proofs for now, it'll be officially out any time soon) and a copy 
of the almost finished NeuroImage paper. If others are interested, 
please let me know and I can send them to you (trea26 at gmail dot com).

So LMER-wise, adding (1+Electtrode|Subject), which you could simply 
write (Electrode|Subject) is correct, but fitting a model with such a 
random effect will take forever.

In NewmanTremblay2011 paper we collapsed Electrode into 9 ROIs: left 
anterior, midline anterior, right anterior, left central, midline 
central, right central, left posterior, midline posterior, and right 
posterior and use that new variable (ROI) instead of Electrode. Note 
that we are not averaging at all! The main reason for this is 
computation time: With 9 levels of ROI in the model as (ROI|Subject) it 
takes A LOT of time to fit, tried once with (Electrode|Subject) and 
would run for sooooo long, actually killed it after like two or three 
days. Even the model with ROI takes what seems to be forever.

Then, once fitted, you'll see with print(model) that in the random 
effects portion of the summary there's a table of correlations between 
levels of ROI, something like this from one of our models (incomplete):

Linear mixed model fit by REML
Formula: Ampl ~ rProficiency * Condition * ROI * Group + (Condition | 
  Subject) + (1 | Subject) + (ROI | Subject)
    Data: dat
      AIC     BIC  logLik deviance REMLdev
  1011929 1013147 -505843  1011340 1011685
Random effects:
  Groups   Name          Variance   Std.Dev. Corr
  Subject  (Intercept)   2.5852e-01 0.508447
           ConditionGood 1.4045e+00 1.185133 -0.681
  Subject  (Intercept)   1.8638e-04 0.013652
  Subject  (Intercept)   2.8105e+00 1.676449
           ROILcent      9.4985e-01 0.974604 -0.423
           ROILpost      3.2123e+00 1.792281 -0.644  0.833
           ROIMant       3.3728e-01 0.580755 -0.240  0.150  0.258
           ROIMcent      1.8586e+00 1.363301 -0.249  0.687  ...
           ROIMpost      2.8172e+00 1.678445 -0.577  0.746  ...
           ROIRant       7.5682e-01 0.869957 -0.421 -0.171  ...
           ROIRcent      1.4031e+00 1.184519 -0.840  0.531  ...
           ROIRpost      3.0983e+00 1.760201 -0.797  0.578  ...
  Residual               3.3207e+01 5.762530
Number of obs: 159374, groups: Subject, 44

I'm attaching a complete report (using Sweave) for your reference.

There's one other paper where they used lme with a corSpher function in 
Davidson2007 (attached here, see page 90). The problem i see with using 
lme is that you can't really add crossed by-item random effect, which 
you should as demonstrated in Tremblay2012. Basically, adding by-item 
random effects substantially decreases the amount of (partial) 
autocorrelation in the model residuals (i.e., better approximation of 
the assumption of independence of errors. Note that the data used in 
that paper is available on CRAN (data package LCFdata) and I can send 
you the .Rnw file that contains the R code used for data manipulation, 
analysis and plotting in Tremblay2012, so it's fully replicable. Note 
that for simplicity, analyses in Tremblay2012 are on a single electrode, 
and that I'm not comparing (ROI|Subject) in LMER to corSpher in LME. 
Would like to eventually look a variograms to see how well the two take 
care of spatial correlation and also compare them with a model that 
doesn't account for this correlation.

Note that, as I demonstrate in Tremblay2012, by-item random effect 
should be added if warranted (by Log-likelihood Ratio Test or other; I 
suspect it will always be).


Cheers,

Antoine


On 12-01-20 07:00 AM, r-sig-mixed-models-request at r-project.org wrote:
> ------------------------------
>
> Message: 3
> Date: Fri, 20 Jan 2012 11:53:37 +0100
> From: Giorgio Arcara<giorgio.arcara at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme or lmer?
> Message-ID:<43825DBA-F86F-4732-AFE1-4B139B572331 at gmail.com>
> Content-Type: text/plain
>
>
> I would like to use mixed models in R to analyze EEG data, but I don't
> know if it is more correct to use lme or lmer.
> My data have the following structure
>
>
> Subject	Electrode	 Interval		Trial 	Condition		Ampl
> 1		Fp1		200-300		1		A			3.5
> 1		Fp1		200-300		2		B			4.2
> 1		Fp2		400-600		1		A			6.5
> 1		Fp2		400-600		2		B			3.3
> 2		Fp1		200-300		1		A			2.1
> 2		Fp1		200-300		2		B			-5.4
> 2		Fp2		400-600		1		A			-5.6
> 2		Fp2		400-600		2		B			-3.2
> .
> .
> .
>
> For sake of simplicity, here I include only 2 Trials but in the real
> dataset they are many more.
> In this hypothetical dataset Ampl is the depentent variable. Electrode
> and Interval are two predictors. I expect that levels of Electrode
> will be highly correlated as well the levels of Interval.
> My goal is to study if Condition influence Ampl and if interact with
> Electrode variable and Interval Variable.
>
>
> I would fit a model on these data with lmer with the following structure
>
> mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject)
> +(1+Interval|Subject))
>
> If I'm correct the corresponding lme model would be
>
> mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition|
> Subject, ~1+Interval|Subject))
>
>
> So my questions are:
> Are these specification corrects?
> Should I use lmer or lme?
> Any suggestion for covariance matrix specification in lme?
>
> Thanks in advance!!!
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> ___________
>
> Giorgio Arcara
> Ph.D.
>
> Department of General Psychology, University of Padua
> Via Venezia 15, 35131 Padova - Italy
> e-mail: giorgio.arcara at unipd.it
> Phone:  +39 049 8276149
> http://lcnl.psy.unipd.it/people/arcara.htm
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 61, Issue 29
> **************************************************
>



From trea26 at gmail.com  Sat Jan 21 18:05:52 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sat, 21 Jan 2012 13:05:52 -0400
Subject: [R-sig-ME] lme or lmer?
Message-ID: <4F1AF070.5040209@gmail.com>

Hey Giorgio!

I have one published paper in JoCN where we analyzed ERP data using 
LMER, another one is on the way, and a methods paper is almost finished 
and submitted to NeuroImage regarding the addition of by-item random 
intercepts and slopes to the model. I'm sending you a copy of the JoCN 
paper (proofs for now, it'll be officially out any time soon) and a copy 
of the almost finished NeuroImage paper. If others are interested, 
please let me know and I can send them to you (trea26 at gmail dot com).

So LMER-wise, adding (1+Electtrode|Subject), which you could simply 
write (Electrode|Subject) is correct, but fitting a model with such a 
random effect will take forever.

In NewmanTremblay2011 paper we collapsed Electrode into 9 ROIs: left 
anterior, midline anterior, right anterior, left central, midline 
central, right central, left posterior, midline posterior, and right 
posterior and use that new variable (ROI) instead of Electrode. Note 
that we are not averaging at all! The main reason for this is 
computation time: With 9 levels of ROI in the model as (ROI|Subject) it 
takes A LOT of time to fit, tried once with (Electrode|Subject) and 
would run for sooooo long, actually killed it after like two or three 
days. Even the model with ROI takes what seems to be forever.

Then, once fitted, you'll see with print(model) that in the random 
effects portion of the summary there's a table of correlations between 
levels of ROI, something like this from one of our models (incomplete):

Linear mixed model fit by REML
Formula: Ampl ~ rProficiency * Condition * ROI * Group + (Condition | 
Subject) + (1 | Subject) + (ROI | Subject)
    Data: dat
      AIC     BIC  logLik deviance REMLdev
  1011929 1013147 -505843  1011340 1011685
Random effects:
  Groups   Name          Variance   Std.Dev. Corr
  Subject  (Intercept)   2.5852e-01 0.508447
           ConditionGood 1.4045e+00 1.185133 -0.681
  Subject  (Intercept)   1.8638e-04 0.013652
  Subject  (Intercept)   2.8105e+00 1.676449
           ROILcent      9.4985e-01 0.974604 -0.423
           ROILpost      3.2123e+00 1.792281 -0.644  0.833
           ROIMant       3.3728e-01 0.580755 -0.240  0.150  0.258
           ROIMcent      1.8586e+00 1.363301 -0.249  0.687  ...
           ROIMpost      2.8172e+00 1.678445 -0.577  0.746  ...
           ROIRant       7.5682e-01 0.869957 -0.421 -0.171  ...
           ROIRcent      1.4031e+00 1.184519 -0.840  0.531  ...
           ROIRpost      3.0983e+00 1.760201 -0.797  0.578  ...
  Residual               3.3207e+01 5.762530
Number of obs: 159374, groups: Subject, 44

I'm attaching a complete report (using Sweave) for your reference.

There's one other paper where they used lme with a corSpher function in 
Davidson2007 (attached here, see page 90). The problem i see with using 
lme is that you can't really add crossed by-item random effect, which 
you should as demonstrated in Tremblay2012. Basically, adding by-item 
random effects substantially decreases the amount of (partial) 
autocorrelation in the model residuals (i.e., better approximation of 
the assumption of independence of errors. Note that the data used in 
that paper is available on CRAN (data package LCFdata) and I can send 
you the .Rnw file that contains the R code used for data manipulation, 
analysis and plotting in Tremblay2012, so it's fully replicable. Note 
that for simplicity, analyses in Tremblay2012 are on a single electrode, 
and that I'm not comparing (ROI|Subject) in LMER to corSpher in LME. 
Would like to eventually look a variograms to see how well the two take 
care of spatial correlation and also compare them with a model that 
doesn't account for this correlation.

Note that, as I demonstrate in Tremblay2012, by-item random effect 
should be added if warranted (by Log-likelihood Ratio Test or other; I 
suspect it will always be).


Cheers,

Antoine


On 12-01-20 07:00 AM, r-sig-mixed-models-request at r-project.org wrote:
 > ------------------------------
 >
 > Message: 3
 > Date: Fri, 20 Jan 2012 11:53:37 +0100
 > From: Giorgio Arcara<giorgio.arcara at gmail.com>
 > To: r-sig-mixed-models at r-project.org
 > Subject: [R-sig-ME] lme or lmer?
 > Message-ID:<43825DBA-F86F-4732-AFE1-4B139B572331 at gmail.com>
 > Content-Type: text/plain
 >
 >
 > I would like to use mixed models in R to analyze EEG data, but I don't
 > know if it is more correct to use lme or lmer.
 > My data have the following structure
 >
 >
 > Subject    Electrode     Interval        Trial     Condition        Ampl
 > 1        Fp1        200-300        1        A            3.5
 > 1        Fp1        200-300        2        B            4.2
 > 1        Fp2        400-600        1        A            6.5
 > 1        Fp2        400-600        2        B            3.3
 > 2        Fp1        200-300        1        A            2.1
 > 2        Fp1        200-300        2        B            -5.4
 > 2        Fp2        400-600        1        A            -5.6
 > 2        Fp2        400-600        2        B            -3.2
 > .
 > .
 > .
 >
 > For sake of simplicity, here I include only 2 Trials but in the real
 > dataset they are many more.
 > In this hypothetical dataset Ampl is the depentent variable. Electrode
 > and Interval are two predictors. I expect that levels of Electrode
 > will be highly correlated as well the levels of Interval.
 > My goal is to study if Condition influence Ampl and if interact with
 > Electrode variable and Interval Variable.
 >
 >
 > I would fit a model on these data with lmer with the following structure
 >
 > mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject)
 > +(1+Interval|Subject))
 >
 > If I'm correct the corresponding lme model would be
 >
 > mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition|
 > Subject, ~1+Interval|Subject))
 >
 >
 > So my questions are:
 > Are these specification corrects?
 > Should I use lmer or lme?
 > Any suggestion for covariance matrix specification in lme?
 >
 > Thanks in advance!!!
 >
 >
 > ___________
 >
 > Giorgio Arcara
 > Ph.D.
 >
 > Department of General Psychology, University of Padua
 > Via Venezia 15, 35131 Padova - Italy
 > e-mail: giorgio.arcara at unipd.it
 > Phone:  +39 049 8276149
 > http://lcnl.psy.unipd.it/people/arcara.htm
 >
 >
 >     [[alternative HTML version deleted]]
 >
 >
 >
 > ------------------------------
 >
 > _______________________________________________
 > R-sig-mixed-models mailing list
 > R-sig-mixed-models at r-project.org
 > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 >
 >
 > End of R-sig-mixed-models Digest, Vol 61, Issue 29
 > **************************************************
 >



From c.ryan.king at gmail.com  Sat Jan 21 18:55:33 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Sat, 21 Jan 2012 11:55:33 -0600
Subject: [R-sig-ME] MCMCglmm output 1) on right scale? 2) produces huge
 deviance spread? (Jarrod Hadfield)
Message-ID: <CAEQ+J253wJKVTQNFaB5Y3itpvR+qG7EAFczEdrZrS1_L3R5AaA@mail.gmail.com>

For posterity / google: It turns out the key issues were
1) The R component specified in the model is not the latent
gaussian(0,1)  noise inherent in a probit regression, but in addition
to that quantity. Setting it to near zero results in the answers I
expected, but very poor mixing of the chain. Fixing it at some value,
and doing the deviance calculation with residual variance 1 +
mcmcoutput$VCV[,"units"] does what I want.

2) The mcmcoutput$Dev and $DIC are the deviance treating the R
component as a real piece of the model and not a computational device.
That is, there are effectively hundreds of additional parameters. If
you want the deviance treating R as a computational device, you have
to calculate it by hand as above.

3) I had a typo in my prior specification, G1=list(V=1, nu=1,
alpha.mu=0, alpha.v=number) does not trigger parameter expansion or an
error; it has to be alpha.V=number.

4) Near-singular variance components are possible in parameter
expanded models (ie a cauchy prior and data supporting the null G=0)
and lead to unstable calculations; the mixed model equation solver in
the block-gibbs update of random effects computes G^-1. There are
other formulations of the MME which don't require inverting G, but
they tend to be less sparse.

Ryan King



From dhocking at unh.edu  Sat Jan 21 21:44:13 2012
From: dhocking at unh.edu (Daniel Hocking)
Date: Sat, 21 Jan 2012 15:44:13 -0500
Subject: [R-sig-ME] Using Observations as Random Effect in GLMM?
Message-ID: <8362F277-4517-41B8-B1D8-14F9C35DAA37@unh.edu>

Hi everyone,

I am having trouble with overdispersion when trying to model count  
data using a GLMM. Beyond going to a negative binomial or Poisson- 
lognormal distribution, I have seen the suggestion (from Ben Bolker I  
believe) to include observation as a random effect. For example using  
the lme4 package my code would look something like this:

glmer(count ~ SoilT + SoilT2 + RH + rain24 + drought +
rain24*SoilT + drought*rain24 + (1 | plot) + (1 | obs), data = Data,
family = poisson)

When I try this I get a fitted vs. residual plot with large residuals  
at low fitted values funneling down to small residuals as the fitted  
values get larger. This indicates heterogeneity. I was wondering if  
that is expected for some reason with observation-level random effects  
or if this model just doesn't meet the assumptions of GLMM for my data?

Thanks,
Dan
------------------------------------------------------------------------------------
Daniel J. Hocking
122 James  Hall
Department of Natural Resources & the Environment
University of New Hampshire
Durham, NH 03824

dhocking at unh.edu
http://sites.google.com/site/danieljhocking/
http://quantitativeecology.blogspot.com/
http://richnessoflife.blogspot.com/

"Without data, you are just another person with an opinion."



From giaguarenzo at yahoo.it  Sun Jan 22 00:37:49 2012
From: giaguarenzo at yahoo.it (Lorenzo Quaglietta)
Date: Sat, 21 Jan 2012 23:37:49 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
	<loom.20120112T173419-47@post.gmane.org>
	<loom.20120117T004350-179@post.gmane.org>
	<loom.20120119T140202-20@post.gmane.org>
Message-ID: <loom.20120122T003109-499@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Lorenzo Quaglietta <giaguarenzo at ...> writes:
> 
> > 
> > Ben Bolker <bbolker at ...> writes:
> > 
> > >   It means that it doesn't make sense to use a numeric variable as
> > > a grouping variable for a random factor (which is what you've done):
> > > if sl is a discrete numeric code that identifies groups of observations,
> > > then you should convert it to a factor.  If it's a continuous variable,
> > > then you need to go back and read/think some more about the meanings
> > > of random factors ...
> > > 
> > >   It also means that I made some changes to glmmADMB recently that
> > > got in the way of an informative error message (you should have
> > > received an error message that told you this).  I will try to 
> > > catch that error in a more informative way.
> > > 
> > My model formula is:
> > 
> > glmmADMB1 <- glmmadmb(Fix ~ log_BIO_F * log_BIO_P + log_drs + fperp + 
log_pr +
> > log_la + (1 | ANIMALE) + (1 | ID) + (1 | Time), 
> > data=otters, zeroInflation=TRUE,
> > family="poisson").
> > 
> > and I got the following error message:
> > 
> > "Error in UseMethod("droplevels") : 
> >   no applicable method for 'droplevels' applied to an object of class
> > "c('integer', 'numeric')".
> > 
> > My random terms are not categorical nor fitted as factors. Covariates are
> > continous (the log_ ones) and a factor (fperp). Any clue about what can be 
the
> > problem would be very appreciated.
> 
>   Can you be clearer about what you mean by "my random terms are not 
> categorical nor fitted as factors"?  Grouping terms in glmmADMB
> *must* be defined as factors (i.e. you must convert ANIMALE, ID,
> Time to factors).
>    I could have made glmmADMB make this conversion internally,
> but I thought it was better to make this the user's responsibility,
> so that if someone were doing something strange (like trying to
> use a continuous variable as a grouping factor, on the right side
> of the bar in (1|g)) it would be more immediately obvious.
> 
>   In general, it would be very helpful if you can include the
> version of glmmADMB in any query, as the package is evolving very
> quickly.  If you install the latest version (0.7.2.5) you should
> still get an error, but the error will be (slightly) more
> informative -- it will tell you that all grouping variables
> must be factors.
> 
>   Ben Bolker

Thank you very much. I've defined the random terms as factors and that error 
did not appear anymore.
However, I've encountered another message of error, which I copy here below 
(there's a very long series of codes of which I've copied only the last part 
and below the error):

Newton raphson 1   f = 344.5193892398689 max g = 2.123148492572113e-07
Newton raphson 2   f = 344.5193892398687 max g = 4.356515148629114e-13
 inner maxg = 0.0007671776212085923  Inner second time = 
0.0007671776212085923  Inner f = 344.5055506201622
 f = 344.5055506201622 max g = 0.0007671776212085923
Newton raphson 1   f = 344.505550121035 max g = 9.045343487557034e-07
Newton raphson 2   f = 344.5055501210349 max g = 7.366329768387914e-12
Warning -- Hessian does not appear to be positive definite
Error in run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary = !
use_tmp_dir,  : 
  object "sys.result" not found
then: Warning messages:
1: running command 'C:\WINDOWS\system32\cmd.exe /c "C:/Programmi/R/R-
2.14.1/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500 -maxph 4 -
noinit -shess' had status 1 
2: In shell(cmd, invisible = TRUE) :
  '"C:/Programmi/R/R-2.14.1/library/glmmADMB/bin/windows32/glmmadmb.exe" -
maxfn 500 -maxph 4 -noinit -shess' execution failed with error code 1

I ignore what all this may means, so any help would be great.

glmmADMB version is 0.7.2.

Thanks in advance, best,

Lorenzo



From john.maindonald at anu.edu.au  Sun Jan 22 01:25:20 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 22 Jan 2012 11:25:20 +1100
Subject: [R-sig-ME] Using Observations as Random Effect in GLMM?
In-Reply-To: <8362F277-4517-41B8-B1D8-14F9C35DAA37@unh.edu>
References: <8362F277-4517-41B8-B1D8-14F9C35DAA37@unh.edu>
Message-ID: <1AB5EE71-B5CA-4C49-A492-F3FCB41AA9D6@anu.edu.au>

I've been looking recently at animal count data that I've modeled
as Poisson with an observation level random effect, and have
worried a bit about such issues.

The observation level random effects model and the over-dispersion 
model add variances on different scales -- for the observation level
random effects random effects model the added variance is 
proportional to the square of the Poisson mean, whereas for the
over-dispersion model it is proportional to the mean. (These 
comments assume small additional error; but they do delineate
the broad ballparks in which the two models operate.   The glmer() 
function is making its own very specific assumptions about the 
scale on which to add the additional normal error.

The models are thus pretty much equivalent only if the range of 
expected values is small.  It would be useful to have more flexibility,
at the observation level at least, in the modelling of the extra-Poisson
error.  Among the various packages that handle GLMMs, do any of
them offer such flexibility, maybe allowing e.g. a quasi-Poisson error? 

(Sure, there are issues about how legit quasi-Poisson errors are.  
I expect however someone will sometime work out how to give them 
full theoretical respectability, and they will duly be admitted to the part 
of the statistical pantheon allocated to those models that are thus 
theoretically respectable.)


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 22/01/2012, at 7:44 AM, Daniel Hocking wrote:

> Hi everyone,
> 
> I am having trouble with overdispersion when trying to model count data using a GLMM. Beyond going to a negative binomial or Poisson-lognormal distribution, I have seen the suggestion (from Ben Bolker I believe) to include observation as a random effect. For example using the lme4 package my code would look something like this:
> 
> glmer(count ~ SoilT + SoilT2 + RH + rain24 + drought +
> rain24*SoilT + drought*rain24 + (1 | plot) + (1 | obs), data = Data,
> family = poisson)
> 
> When I try this I get a fitted vs. residual plot with large residuals at low fitted values funneling down to small residuals as the fitted values get larger. This indicates heterogeneity. I was wondering if that is expected for some reason with observation-level random effects or if this model just doesn't meet the assumptions of GLMM for my data?
> 
> Thanks,
> Dan
> ------------------------------------------------------------------------------------
> Daniel J. Hocking
> 122 James  Hall
> Department of Natural Resources & the Environment
> University of New Hampshire
> Durham, NH 03824
> 
> dhocking at unh.edu
> http://sites.google.com/site/danieljhocking/
> http://quantitativeecology.blogspot.com/
> http://richnessoflife.blogspot.com/
> 
> "Without data, you are just another person with an opinion."
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Sun Jan 22 16:30:31 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Jan 2012 15:30:31 +0000 (UTC)
Subject: [R-sig-ME] Using Observations as Random Effect in GLMM?
References: <8362F277-4517-41B8-B1D8-14F9C35DAA37@unh.edu>
	<1AB5EE71-B5CA-4C49-A492-F3FCB41AA9D6@anu.edu.au>
Message-ID: <loom.20120122T162516-479@post.gmane.org>

John Maindonald <john.maindonald at ...> writes:

> 
> I've been looking recently at animal count data that I've modeled
> as Poisson with an observation level random effect, and have
> worried a bit about such issues.
> 
> The observation level random effects model and the over-dispersion 
> model add variances on different scales -- for the observation level
> random effects random effects model the added variance is 
> proportional to the square of the Poisson mean, whereas for the
> over-dispersion model it is proportional to the mean. (These 
> comments assume small additional error; but they do delineate
> the broad ballparks in which the two models operate.   The glmer() 
> function is making its own very specific assumptions about the 
> scale on which to add the additional normal error.
> 
> The models are thus pretty much equivalent only if the range of 
> expected values is small.  It would be useful to have more flexibility,
> at the observation level at least, in the modelling of the extra-Poisson
> error.  Among the various packages that handle GLMMs, do any of
> them offer such flexibility, maybe allowing e.g. a quasi-Poisson error? 

  Recent versions of the glmmADMB package offer two flavors of negative
binomial model, either with variance = mu*(1+mu/k) (the classic
'quadratic' (almost) parameterization, which Hardin and Hilbe call
NB2) or with variance = phi*mu (which Hardin and Hilbe call
NB1; I believe this is what you are calling "quasi-Poisson" above).
The variance-mean relationship of NB2 and of the lognormal-Poisson
model are the same, although the details do differ ...

> (Sure, there are issues about how legit quasi-Poisson errors are.  
> I expect however someone will sometime work out how to give them 
> full theoretical respectability, and they will duly be admitted to the part 
> of the statistical pantheon allocated to those models that are thus 
> theoretically respectable.)

  I haven't tried it yet, but my response to the original poster
would have been to try a well-behaved simulation and see whether
the same phenomenon occurred ...



From trea26 at gmail.com  Sun Jan 22 19:13:56 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sun, 22 Jan 2012 14:13:56 -0400
Subject: [R-sig-ME] lme or lmer?
In-Reply-To: <mailman.5087.1327178663.4521.r-sig-mixed-models@r-project.org>
References: <mailman.5087.1327178663.4521.r-sig-mixed-models@r-project.org>
Message-ID: <4F1C51E4.7030707@gmail.com>

Giorgio, another thing regarding the Interval variable that came to my 
attention after reading Ben Bolker's reply to your question.

Were you planning on adding Interval to your model specification? 
Because it *shouldn't* be in the model. From what I can see, you'd be 
performing an analysis on the 200-300 time window, then another one on 
the 400-600 time window, and so forth, and in each analysis you'd 
include all electrodes (which, as I mentioned in my reply, is probably 
best re-coded as ROI with 9 levels).

I'm assuming you chose these time windows because you were expecting to 
find amplitude differences between your two conditions with respect to 
ERPs found in these time windows (e.g., maybe a late N400 in the 400-600 
window?).

So, for *each* time window the model would look something like this 
(after recoding Electrode to ROI and your datya frame is named eeg):

m1 <- lmer(Ampl ~ Condition * ROI + (1|Subject) + (1|Item) + 
(ROI|Subject), data = eeg)

Would check model assumptions using e.g., function mcp.fnc from package 
LMERConvenienceFunctions.

mcp.fnc(m1, trim = 2.5)

Typically the qq plot top right isn't good and there are a lot of data 
points with undue influence (bottom right panel). But after removing 
outliers +/- 2.5 std. dev. below and above the m1 residuals mean (could 
use function romr.fnc from package LMERConvenienceFunctions) the plots 
look much, much better.

eeg<- romr.fnc(model = m1, data = eeg, trim = 2.5)$data

Typically 1.5% to 2.5% of the data is removed this way (the function 
tells you the percentage). Then refit the model:

m1 <- update(m1)

Then look at the model criticism plot:

mcp.fnc(m1, trim = 2.5)


In addition, you could start with a simple model with only (1|Subject) 
then fit a more complex model with (1|Subject) + (1|Item) then a more 
complex one with (1|Subject) + (1|Item) + (ROI|Subject) ... and test 
whether the inclusion of the random effects is warranted using a log 
likelihood ratio test (anova(m1,m2) ...). I'd bet that (1|Subject) + 
(1|Item) + (ROI|Subject) will be warranted, maybe also (Condition|Subject).

Sincerely,

Antoine Tremblay
NeuroCognitive Imaging Laboratory
Dalhousie university
Halifax, Canada

> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 21 Jan 2012 15:54:00 +0000 (UTC)
> From: Ben Bolker<bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme or lmer?
> Message-ID:<loom.20120121T041825-883 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
>
> Giorgio Arcara<giorgio.arcara at ...>  writes:
>
>> I would like to use mixed models in R to analyze EEG data, but I don't
>> know if it is more correct to use lme or lmer.
>> My data have the following structure
>>
>> Subject	Electrode	 Interval	Trial 	Condition	Ampl
>> 1		Fp1		200-300		1	A		3.5
>> 1		Fp1		200-300		2	B		4.2
>> 1		Fp2		400-600		1	A		6.5
>> 1		Fp2		400-600		2	B		3.3
>> 2		Fp1		200-300		1	A		2.1
>> 2		Fp1		200-300		2	B		-5.4
>> 2		Fp2		400-600		1	A		-5.6
>> 2		Fp2		400-600		2	B		-3.2
>
>   [snip]
>
>    In general if you *can* use either lme or lmer (i.e. the random effects are
> not nested, there is no heteroscedasticity or correlation structure at the
> level of residuals ...) then either is OK.  I generally recommend lme in
> these cases (with apologies to Doug Bates) because it is better documented,
> although it's slower.
>
>> For sake of simplicity, here I include only 2 Trials but in the real
>> dataset they are many more.
>> In this hypothetical dataset Ampl is the depentent variable. Electrode
>> and Interval are two predictors. I expect that levels of Electrode
>> will be highly correlated as well the levels of Interval.
>
>    ?? Meaning that most instances of FP1 have Interval 200-300, most
> of Fp2 have 400-500, and there are few 'crossover' instances where you
> have FP1 with 400-500 and FP2 with 200-300?  This will in general make
> it hard to estimate to distinguish the two effects ... but presumably
> you know that.
>
>> My goal is to study if Condition influence Ampl and if interact with
>> Electrode variable and Interval Variable.
>>
>> I would fit a model on these data with lmer with the following structure
>>
>> mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject)
>> +(1+Interval|Subject))
>> If I'm correct the corresponding lme model would be
>>
>> mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition|
>> Subject, ~1+Interval|Subject))
>
>    Why not (Electrode+Interval|Subject)?  That (a) avoids a duplicated intercept
> term and (b) estimates correlations between the intercept, electrode, and
> Interval RE.
>
>> Any suggestion for covariance matrix specification in lme?
>
>    Do you need one other than the default -- i.e. do you expect
> any particular correlation structure?
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 21 Jan 2012 12:55:50 -0400
> From: Antoine Tremblay<trea26 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Cc: r-sig-mixed-models-request at r-project.org
> Subject: Re: [R-sig-ME] lme or lmer?
> Message-ID:<4F1AEE16.3090801 at gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hey Giorgio!
>
> I have one published paper in JoCN where we analyzed ERP data using
> LMER, another one is on the way, and a methods paper is almost finished
> and submitted to NeuroImage regarding the addition of by-item random
> intercepts and slopes to the model. I'm sending you a copy of the JoCN
> paper (proofs for now, it'll be officially out any time soon) and a copy
> of the almost finished NeuroImage paper. If others are interested,
> please let me know and I can send them to you (trea26 at gmail dot com).
>
> So LMER-wise, adding (1+Electtrode|Subject), which you could simply
> write (Electrode|Subject) is correct, but fitting a model with such a
> random effect will take forever.
>
> In NewmanTremblay2011 paper we collapsed Electrode into 9 ROIs: left
> anterior, midline anterior, right anterior, left central, midline
> central, right central, left posterior, midline posterior, and right
> posterior and use that new variable (ROI) instead of Electrode. Note
> that we are not averaging at all! The main reason for this is
> computation time: With 9 levels of ROI in the model as (ROI|Subject) it
> takes A LOT of time to fit, tried once with (Electrode|Subject) and
> would run for sooooo long, actually killed it after like two or three
> days. Even the model with ROI takes what seems to be forever.
>
> Then, once fitted, you'll see with print(model) that in the random
> effects portion of the summary there's a table of correlations between
> levels of ROI, something like this from one of our models (incomplete):
>
> Linear mixed model fit by REML
> Formula: Ampl ~ rProficiency * Condition * ROI * Group + (Condition |
>    Subject) + (1 | Subject) + (ROI | Subject)
>      Data: dat
>        AIC     BIC  logLik deviance REMLdev
>    1011929 1013147 -505843  1011340 1011685
> Random effects:
>    Groups   Name          Variance   Std.Dev. Corr
>    Subject  (Intercept)   2.5852e-01 0.508447
>             ConditionGood 1.4045e+00 1.185133 -0.681
>    Subject  (Intercept)   1.8638e-04 0.013652
>    Subject  (Intercept)   2.8105e+00 1.676449
>             ROILcent      9.4985e-01 0.974604 -0.423
>             ROILpost      3.2123e+00 1.792281 -0.644  0.833
>             ROIMant       3.3728e-01 0.580755 -0.240  0.150  0.258
>             ROIMcent      1.8586e+00 1.363301 -0.249  0.687  ...
>             ROIMpost      2.8172e+00 1.678445 -0.577  0.746  ...
>             ROIRant       7.5682e-01 0.869957 -0.421 -0.171  ...
>             ROIRcent      1.4031e+00 1.184519 -0.840  0.531  ...
>             ROIRpost      3.0983e+00 1.760201 -0.797  0.578  ...
>    Residual               3.3207e+01 5.762530
> Number of obs: 159374, groups: Subject, 44
>
> I'm attaching a complete report (using Sweave) for your reference.
>
> There's one other paper where they used lme with a corSpher function in
> Davidson2007 (attached here, see page 90). The problem i see with using
> lme is that you can't really add crossed by-item random effect, which
> you should as demonstrated in Tremblay2012. Basically, adding by-item
> random effects substantially decreases the amount of (partial)
> autocorrelation in the model residuals (i.e., better approximation of
> the assumption of independence of errors. Note that the data used in
> that paper is available on CRAN (data package LCFdata) and I can send
> you the .Rnw file that contains the R code used for data manipulation,
> analysis and plotting in Tremblay2012, so it's fully replicable. Note
> that for simplicity, analyses in Tremblay2012 are on a single electrode,
> and that I'm not comparing (ROI|Subject) in LMER to corSpher in LME.
> Would like to eventually look a variograms to see how well the two take
> care of spatial correlation and also compare them with a model that
> doesn't account for this correlation.
>
> Note that, as I demonstrate in Tremblay2012, by-item random effect
> should be added if warranted (by Log-likelihood Ratio Test or other; I
> suspect it will always be).
>
>
> Cheers,
>
> Antoine
>
>
> End of R-sig-mixed-models Digest, Vol 61, Issue 31
> **************************************************
>



From eef201 at exeter.ac.uk  Sun Jan 22 23:38:35 2012
From: eef201 at exeter.ac.uk (Flores-de-Gracia, Eric)
Date: Sun, 22 Jan 2012 22:38:35 +0000
Subject: [R-sig-ME] Using lmer in survival
Message-ID: <8395A297256F694B9308A0446D3CF6A520435A5128@EXCHMBS03.isad.isadroot.ex.ac.uk>

Hi there

I?m trying to fit a lmer model to a data on survival (1=death, 0=alive) of artificial frog models deployed in the field. At this early point want to know if "size" has an general effect on survival

I have found difficult to understand the model goodness of fit using the model simplification. Using a randomized block design, my response variable is "surv" and my predictor is "size".

model1<-lmer(surv~size+(1|block/size),family="binomial")
summary(model1)

model2<-update(model1,~.-size)

anova(model1,model2)

But the plot of residuals against the predicted values looks quite strange, perhaps due to the huge amount of "0" in the dataset! (562 ceros vs 35 ones).

Is there any other error structure that can be implemented to deal with the huge amount of ceros?

Any suggestion welcome, thanks.
 
Eric Flores De Gracia
School of Biosciences
University of Exeter, Cornwall Campus
Penryn, Cornwall
TR10 9EZ
United Kingdom
Mobilephone: +044 07578724705
http://biosciences.exeter.ac.uk/staff/postgradresearch/ericflores/
________________________________________
De: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] En nombre de Antoine Tremblay [trea26 at gmail.com]
Enviado el: domingo, 22 de enero de 2012 18:13
Para: r-sig-mixed-models at r-project.org
CC: r-sig-mixed-models-request at r-project.org
Asunto: Re: [R-sig-ME] lme or lmer?

Giorgio, another thing regarding the Interval variable that came to my
attention after reading Ben Bolker's reply to your question.

Were you planning on adding Interval to your model specification?
Because it *shouldn't* be in the model. From what I can see, you'd be
performing an analysis on the 200-300 time window, then another one on
the 400-600 time window, and so forth, and in each analysis you'd
include all electrodes (which, as I mentioned in my reply, is probably
best re-coded as ROI with 9 levels).

I'm assuming you chose these time windows because you were expecting to
find amplitude differences between your two conditions with respect to
ERPs found in these time windows (e.g., maybe a late N400 in the 400-600
window?).

So, for *each* time window the model would look something like this
(after recoding Electrode to ROI and your datya frame is named eeg):

m1 <- lmer(Ampl ~ Condition * ROI + (1|Subject) + (1|Item) +
(ROI|Subject), data = eeg)

Would check model assumptions using e.g., function mcp.fnc from package
LMERConvenienceFunctions.

mcp.fnc(m1, trim = 2.5)

Typically the qq plot top right isn't good and there are a lot of data
points with undue influence (bottom right panel). But after removing
outliers +/- 2.5 std. dev. below and above the m1 residuals mean (could
use function romr.fnc from package LMERConvenienceFunctions) the plots
look much, much better.

eeg<- romr.fnc(model = m1, data = eeg, trim = 2.5)$data

Typically 1.5% to 2.5% of the data is removed this way (the function
tells you the percentage). Then refit the model:

m1 <- update(m1)

Then look at the model criticism plot:

mcp.fnc(m1, trim = 2.5)


In addition, you could start with a simple model with only (1|Subject)
then fit a more complex model with (1|Subject) + (1|Item) then a more
complex one with (1|Subject) + (1|Item) + (ROI|Subject) ... and test
whether the inclusion of the random effects is warranted using a log
likelihood ratio test (anova(m1,m2) ...). I'd bet that (1|Subject) +
(1|Item) + (ROI|Subject) will be warranted, maybe also (Condition|Subject).

Sincerely,

Antoine Tremblay
NeuroCognitive Imaging Laboratory
Dalhousie university
Halifax, Canada

> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 21 Jan 2012 15:54:00 +0000 (UTC)
> From: Ben Bolker<bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme or lmer?
> Message-ID:<loom.20120121T041825-883 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
>
> Giorgio Arcara<giorgio.arcara at ...>  writes:
>
>> I would like to use mixed models in R to analyze EEG data, but I don't
>> know if it is more correct to use lme or lmer.
>> My data have the following structure
>>
>> Subject      Electrode        Interval       Trial   Condition       Ampl
>> 1            Fp1             200-300         1       A               3.5
>> 1            Fp1             200-300         2       B               4.2
>> 1            Fp2             400-600         1       A               6.5
>> 1            Fp2             400-600         2       B               3.3
>> 2            Fp1             200-300         1       A               2.1
>> 2            Fp1             200-300         2       B               -5.4
>> 2            Fp2             400-600         1       A               -5.6
>> 2            Fp2             400-600         2       B               -3.2
>
>   [snip]
>
>    In general if you *can* use either lme or lmer (i.e. the random effects are
> not nested, there is no heteroscedasticity or correlation structure at the
> level of residuals ...) then either is OK.  I generally recommend lme in
> these cases (with apologies to Doug Bates) because it is better documented,
> although it's slower.
>
>> For sake of simplicity, here I include only 2 Trials but in the real
>> dataset they are many more.
>> In this hypothetical dataset Ampl is the depentent variable. Electrode
>> and Interval are two predictors. I expect that levels of Electrode
>> will be highly correlated as well the levels of Interval.
>
>    ?? Meaning that most instances of FP1 have Interval 200-300, most
> of Fp2 have 400-500, and there are few 'crossover' instances where you
> have FP1 with 400-500 and FP2 with 200-300?  This will in general make
> it hard to estimate to distinguish the two effects ... but presumably
> you know that.
>
>> My goal is to study if Condition influence Ampl and if interact with
>> Electrode variable and Interval Variable.
>>
>> I would fit a model on these data with lmer with the following structure
>>
>> mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject)
>> +(1+Interval|Subject))
>> If I'm correct the corresponding lme model would be
>>
>> mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition|
>> Subject, ~1+Interval|Subject))
>
>    Why not (Electrode+Interval|Subject)?  That (a) avoids a duplicated intercept
> term and (b) estimates correlations between the intercept, electrode, and
> Interval RE.
>
>> Any suggestion for covariance matrix specification in lme?
>
>    Do you need one other than the default -- i.e. do you expect
> any particular correlation structure?
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 21 Jan 2012 12:55:50 -0400
> From: Antoine Tremblay<trea26 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Cc: r-sig-mixed-models-request at r-project.org
> Subject: Re: [R-sig-ME] lme or lmer?
> Message-ID:<4F1AEE16.3090801 at gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hey Giorgio!
>
> I have one published paper in JoCN where we analyzed ERP data using
> LMER, another one is on the way, and a methods paper is almost finished
> and submitted to NeuroImage regarding the addition of by-item random
> intercepts and slopes to the model. I'm sending you a copy of the JoCN
> paper (proofs for now, it'll be officially out any time soon) and a copy
> of the almost finished NeuroImage paper. If others are interested,
> please let me know and I can send them to you (trea26 at gmail dot com).
>
> So LMER-wise, adding (1+Electtrode|Subject), which you could simply
> write (Electrode|Subject) is correct, but fitting a model with such a
> random effect will take forever.
>
> In NewmanTremblay2011 paper we collapsed Electrode into 9 ROIs: left
> anterior, midline anterior, right anterior, left central, midline
> central, right central, left posterior, midline posterior, and right
> posterior and use that new variable (ROI) instead of Electrode. Note
> that we are not averaging at all! The main reason for this is
> computation time: With 9 levels of ROI in the model as (ROI|Subject) it
> takes A LOT of time to fit, tried once with (Electrode|Subject) and
> would run for sooooo long, actually killed it after like two or three
> days. Even the model with ROI takes what seems to be forever.
>
> Then, once fitted, you'll see with print(model) that in the random
> effects portion of the summary there's a table of correlations between
> levels of ROI, something like this from one of our models (incomplete):
>
> Linear mixed model fit by REML
> Formula: Ampl ~ rProficiency * Condition * ROI * Group + (Condition |
>    Subject) + (1 | Subject) + (ROI | Subject)
>      Data: dat
>        AIC     BIC  logLik deviance REMLdev
>    1011929 1013147 -505843  1011340 1011685
> Random effects:
>    Groups   Name          Variance   Std.Dev. Corr
>    Subject  (Intercept)   2.5852e-01 0.508447
>             ConditionGood 1.4045e+00 1.185133 -0.681
>    Subject  (Intercept)   1.8638e-04 0.013652
>    Subject  (Intercept)   2.8105e+00 1.676449
>             ROILcent      9.4985e-01 0.974604 -0.423
>             ROILpost      3.2123e+00 1.792281 -0.644  0.833
>             ROIMant       3.3728e-01 0.580755 -0.240  0.150  0.258
>             ROIMcent      1.8586e+00 1.363301 -0.249  0.687  ...
>             ROIMpost      2.8172e+00 1.678445 -0.577  0.746  ...
>             ROIRant       7.5682e-01 0.869957 -0.421 -0.171  ...
>             ROIRcent      1.4031e+00 1.184519 -0.840  0.531  ...
>             ROIRpost      3.0983e+00 1.760201 -0.797  0.578  ...
>    Residual               3.3207e+01 5.762530
> Number of obs: 159374, groups: Subject, 44
>
> I'm attaching a complete report (using Sweave) for your reference.
>
> There's one other paper where they used lme with a corSpher function in
> Davidson2007 (attached here, see page 90). The problem i see with using
> lme is that you can't really add crossed by-item random effect, which
> you should as demonstrated in Tremblay2012. Basically, adding by-item
> random effects substantially decreases the amount of (partial)
> autocorrelation in the model residuals (i.e., better approximation of
> the assumption of independence of errors. Note that the data used in
> that paper is available on CRAN (data package LCFdata) and I can send
> you the .Rnw file that contains the R code used for data manipulation,
> analysis and plotting in Tremblay2012, so it's fully replicable. Note
> that for simplicity, analyses in Tremblay2012 are on a single electrode,
> and that I'm not comparing (ROI|Subject) in LMER to corSpher in LME.
> Would like to eventually look a variograms to see how well the two take
> care of spatial correlation and also compare them with a model that
> doesn't account for this correlation.
>
> Note that, as I demonstrate in Tremblay2012, by-item random effect
> should be added if warranted (by Log-likelihood Ratio Test or other; I
> suspect it will always be).
>
>
> Cheers,
>
> Antoine
>
>
> End of R-sig-mixed-models Digest, Vol 61, Issue 31
> **************************************************
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From geralttee at gmail.com  Mon Jan 23 00:50:46 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Mon, 23 Jan 2012 00:50:46 +0100
Subject: [R-sig-ME] Using lmer in survival
Message-ID: <CANXb-o6KsbChhU5+FPzozE5T37H9LURHAbSoYBZ2Cn_LnF-5Cw@mail.gmail.com>

Hi,

Try using MCMCglmm - it fits zero-inflated binomial models. Just be
careful with priors - you might have big separation in your data so
use appropriate priors for fixed effects (see Jarrod Hadfiel's Course
Notes for details). you could also try vgam library (as far as I know
vglm fits zero-inflated binomial models but I haven't use it yet).

Cheers,
sz.

-- 
Szymon Drobniak || Population Ecology Group
Institute of Environmental Sciences,?Jagiellonian University
ul. Gronostajowa 7, 30-387 Krak?w, POLAND
tel.: +48 12 664 51 79 fax: +48 12 664 69 12
szymek.dronbiak at uj.edu.pl
www.eko.uj.edu.pl/drobniak



From bbolker at gmail.com  Mon Jan 23 17:41:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 23 Jan 2012 16:41:16 +0000 (UTC)
Subject: [R-sig-ME] Using lmer in survival
References: <CANXb-o6KsbChhU5+FPzozE5T37H9LURHAbSoYBZ2Cn_LnF-5Cw@mail.gmail.com>
Message-ID: <loom.20120123T174001-856@post.gmane.org>

Szymek Drobniak <geralttee at ...> writes:

> 
> Hi,
> 
> Try using MCMCglmm - it fits zero-inflated binomial models. Just be
> careful with priors - you might have big separation in your data so
> use appropriate priors for fixed effects (see Jarrod Hadfiel's Course
> Notes for details). you could also try vgam library (as far as I know
> vglm fits zero-inflated binomial models but I haven't use it yet).
> 

  glmmADMB is also a possibility.
  I would consider carefully whether you really need zero-inflation --
remember that not all zero-rich data sets are actually zero-inflated.
  The blme package might also be useful for strongly separated data
sets.



From jianyun.fred.wu at gmail.com  Tue Jan 24 01:57:22 2012
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Tue, 24 Jan 2012 11:57:22 +1100
Subject: [R-sig-ME] Bootstrapping linear mixed model
Message-ID: <CAOMGRDLSLzcYPJLCfM=BFERRHOTPSD0FJPzXo=X9JQsNgafXsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/b53eb5d4/attachment-0001.pl>

From arives at wisc.edu  Tue Jan 24 02:19:25 2012
From: arives at wisc.edu (Anthony R Ives)
Date: Mon, 23 Jan 2012 19:19:25 -0600
Subject: [R-sig-ME] Bootstrapping linear mixed model
In-Reply-To: <CAOMGRDLSLzcYPJLCfM=BFERRHOTPSD0FJPzXo=X9JQsNgafXsQ@mail.gmail.com>
References: <CAOMGRDLSLzcYPJLCfM=BFERRHOTPSD0FJPzXo=X9JQsNgafXsQ@mail.gmail.com>
Message-ID: <61D31289-32A4-4243-A50A-4A6D7A0B7487@wisc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120123/7ee91fd8/attachment-0001.pl>

From schmettow at web.de  Tue Jan 24 14:52:09 2012
From: schmettow at web.de (Martin Schmettow)
Date: Tue, 24 Jan 2012 14:52:09 +0100
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
In-Reply-To: <6F35A958A12B9149BD16E3C2F3B0AD0DB37864@SPHINX.adqimr.ad.lan>
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de><Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
	<000301ccd698$a32bee00$e983ca00$@web.de>
	<6F35A958A12B9149BD16E3C2F3B0AD0DB37864@SPHINX.adqimr.ad.lan>
Message-ID: <00ca01ccda9f$5e04f460$1a0edd20$@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/47b0a87e/attachment-0001.pl>

From tavgar at uoguelph.ca  Tue Jan 24 20:07:14 2012
From: tavgar at uoguelph.ca (Tal Avgar)
Date: Tue, 24 Jan 2012 14:07:14 -0500
Subject: [R-sig-ME] accounting for residual autocorrelation
Message-ID: <007201ccdacb$61d7ca50$25875ef0$@ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/963379d4/attachment-0001.pl>

From kw.stat at gmail.com  Tue Jan 24 21:40:05 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 24 Jan 2012 14:40:05 -0600
Subject: [R-sig-ME] accounting for residual autocorrelation
In-Reply-To: <007201ccdacb$61d7ca50$25875ef0$@ca>
References: <007201ccdacb$61d7ca50$25875ef0$@ca>
Message-ID: <CAKFxdiSfBkF7P4vAJixc2sog868HrCmUTX+kYxLCksn8P+jU5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/1327c4b0/attachment-0001.pl>

From mhorton at uchicago.edu  Tue Jan 24 22:35:58 2012
From: mhorton at uchicago.edu (mhorton at uchicago.edu)
Date: Tue, 24 Jan 2012 15:35:58 -0600 (CST)
Subject: [R-sig-ME] adding a kinship matrix to a GLMM
Message-ID: <20120124153558.BDK79131@mstore03.uchicago.edu>

Hello,

I'd like to test the mixed-model approach taken in EMMA (-X):
http://www.nature.com/ng/journal/v42/n4/abs/ng.548.html

in a GLMM framework to analyze non-normal data (e.g. count data; sometimes 
there are lots of zeros). I'm trying this with MASS' glmmPQL, which seems to 
allow the user to provide an "an optional correlation structure".

There are a few classes that extend corStruct, but if I try corSymm, things seem 
to work with:

K <- read.table("kinship.txt",...); # an n x n 'identity by state' matrix
cs.K <- corSymm(K[lower.tri(K)],fixed=T);
cs.K <- Initialize(cs.K,data=data.init);
test <- glmmPQL( response ~ snps_i + offset(log(offset)),
          random=~1|subject,correlation=cs.K, family="quasipoisson" );

# data.init is a 1-column matrix of unique subject ids.
# there are between 1-4 biological replicates per subject

I'm writing to ask is this the best model formulation?
Also, if I add a co-factor 'block', which has 6 levels (subjects do not occur in all 
blocks), I get a lot of NA errors:
test <- glmmPQL( response ~ snps_i + as.factor(block)+ offset(log(offset)), 
          random=~1|subject,correlation=cs.K, family="quasipoisson" );
iteration 1
iteration 2
iteration 3
Error in na.fail.default(list(subject = c(1L, 1L, 1L, 2L, 2L, 2L, 3L,  : 
  missing values in object

Again, is there a better model formula?  Is corSymm even doing what I think it is 
doing here? 

Thanks for your time and any comments!
Matt



From deter088 at umn.edu  Wed Jan 25 03:32:07 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 24 Jan 2012 20:32:07 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
Message-ID: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/c00c0e1d/attachment-0001.pl>

From Paul.Thompson at SanfordHealth.org  Wed Jan 25 03:48:25 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Wed, 25 Jan 2012 02:48:25 +0000
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B1D622A@SFSMCEXMBX2.sanfordhealth.org>

In the CS model, the F values for Gender and Gender*age are really close, but age is quite discrepant. That seems problematic.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles Determan Jr
Sent: Tuesday, January 24, 2012 8:32 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R

Greetings,

I have been working on R for some time now and I have begun the endeavor of
trying to replicate some SAS code in R.  I have scoured the forums but
haven't been able to find an answer.  I hope one of you could be so kind as
to enlighten me.

I am attempting to replicate a repeated measures experiment using some
standard data.  I have posted the SAS code and output directly from a
publication as well as my attempts in R to replicate it.  My main issue
comes with the 'unstructured' component.

The 'dental' dataset from 'mixedQF' package,
equivalent to formixed data in SAS

    distance age Subject    Sex
1       26.0   8     M01   Male
2       25.0  10     M01   Male
3       29.0  12     M01   Male
4       31.0  14     M01   Male
5       21.5   8     M02   Male
6       22.5  10     M02   Male
7       23.0  12     M02   Male
8       26.5  14     M02   Male
9       23.0   8     M03   Male
10      22.5  10     M03   Male
11      24.0  12     M03   Male
12      27.5  14     M03   Male
13      25.5   8     M04   Male
14      27.5  10     M04   Male
15      26.5  12     M04   Male
16      27.0  14     M04   Male
17      20.0   8     M05   Male
18      23.5  10     M05   Male
19      22.5  12     M05   Male
20      26.0  14     M05   Male
21      24.5   8     M06   Male
22      25.5  10     M06   Male
23      27.0  12     M06   Male
24      28.5  14     M06   Male
25      22.0   8     M07   Male
26      22.0  10     M07   Male
27      24.5  12     M07   Male
28      26.5  14     M07   Male
29      24.0   8     M08   Male
30      21.5  10     M08   Male
31      24.5  12     M08   Male
32      25.5  14     M08   Male
33      23.0   8     M09   Male
34      20.5  10     M09   Male
35      31.0  12     M09   Male
36      26.0  14     M09   Male
37      27.5   8     M10   Male
38      28.0  10     M10   Male
39      31.0  12     M10   Male
40      31.5  14     M10   Male
41      23.0   8     M11   Male
42      23.0  10     M11   Male
43      23.5  12     M11   Male
44      25.0  14     M11   Male
45      21.5   8     M12   Male
46      23.5  10     M12   Male
47      24.0  12     M12   Male
48      28.0  14     M12   Male
49      17.0   8     M13   Male
50      24.5  10     M13   Male
51      26.0  12     M13   Male
52      29.5  14     M13   Male
53      22.5   8     M14   Male
54      25.5  10     M14   Male
55      25.5  12     M14   Male
56      26.0  14     M14   Male
57      23.0   8     M15   Male
58      24.5  10     M15   Male
59      26.0  12     M15   Male
60      30.0  14     M15   Male
61      22.0   8     M16   Male
62      21.5  10     M16   Male
63      23.5  12     M16   Male
64      25.0  14     M16   Male
65      21.0   8     F01 Female
66      20.0  10     F01 Female
67      21.5  12     F01 Female
68      23.0  14     F01 Female
69      21.0   8     F02 Female
70      21.5  10     F02 Female
71      24.0  12     F02 Female
72      25.5  14     F02 Female
73      20.5   8     F03 Female
74      24.0  10     F03 Female
75      24.5  12     F03 Female
76      26.0  14     F03 Female
77      23.5   8     F04 Female
78      24.5  10     F04 Female
79      25.0  12     F04 Female
80      26.5  14     F04 Female
81      21.5   8     F05 Female
82      23.0  10     F05 Female
83      22.5  12     F05 Female
84      23.5  14     F05 Female
85      20.0   8     F06 Female
86      21.0  10     F06 Female
87      21.0  12     F06 Female
88      22.5  14     F06 Female
89      21.5   8     F07 Female
90      22.5  10     F07 Female
91      23.0  12     F07 Female
92      25.0  14     F07 Female
93      23.0   8     F08 Female
94      23.0  10     F08 Female
95      23.5  12     F08 Female
96      24.0  14     F08 Female
97      20.0   8     F09 Female
98      21.0  10     F09 Female
99      22.0  12     F09 Female
100     21.5  14     F09 Female
101     16.5   8     F10 Female
102     19.0  10     F10 Female
103     19.0  12     F10 Female
104     19.5  14     F10 Female
105     24.5   8     F11 Female
106     25.0  10     F11 Female
107     28.0  12     F11 Female
108     28.0  14     F11 Female

*Mixed modeling and fixed effect test*
SAS
proc mixed data=formixed;
class gender age person;
model y = gender|age;
repeated / type=cs sub=person;
run;

output of interest to me
          Tests of Fixed Effects
Source             NDF   DDF    Type III F    Pr > F
GENDER           1        25        9.29        0.0054
AGE                  3        75       35.35       0.0001
GENDER*AGE   3        75        2.36        0.0781

R (nlme package)
y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
anova(y)

            numDF denDF  F-value p-value
(Intercept)     1    75 4123.156  <.0001
Sex              1    25    9.292  0.0054
age               3    75   40.032  <.0001
Sex:age        3    75    2.362  0.0781

Now this isn't exact but it is extremely close, however when I try to
replicate the unstructured,

SAS
proc mixed data=formixed;
class gender age person;
model y = gender|age;
repeated / type=un sub=person;
run;

             Tests of Fixed Effects
Source          NDF DDF Type III F Pr > F
GENDER         1    25     9.29    0.0054
AGE                3    25    34.45   0.0001
GENDER*AGE 3    25     2.93    0.0532

R
either
y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
data=dental)
anova(y)
or
z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(), data=dental)
anova(z)

gives the output

            numDF denDF  F-value    p-value
(Intercept)     1    75     4052.028  <.0001
Sex              1    25       8.462      0.0075
age               3    75      39.022    <.0001
Sex:age        3    75       2.868      0.0421

What am I doing wrong to replicate the unstructured linear mixed model from
SAS?

Regards,

Charles

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From deter088 at umn.edu  Wed Jan 25 15:35:41 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 25 Jan 2012 08:35:41 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1D622A@SFSMCEXMBX2.sanfordhealth.org>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D622A@SFSMCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJph=evRi_LsgXJZyEAKqsD3apCFkY9FTFdPRYSeoHa-LcTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120125/bbae2d1f/attachment-0001.pl>

From W.Bouwmeester at umcutrecht.nl  Wed Jan 25 12:02:18 2012
From: W.Bouwmeester at umcutrecht.nl (Bouwmeester, W.)
Date: Wed, 25 Jan 2012 11:02:18 +0000
Subject: [R-sig-ME] lme4 and sample size
In-Reply-To: <CAO7JsnSBCo4exTRgzCaB54udtM0RBQh668zc_NOqXpaRhH93fg@mail.gmail.com>
References: <6C86BD70D72CB449A189A18EED3037CA057EE65B@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
	<6C86BD70D72CB449A189A18EED3037CA057EE66C@EXMB1501.ds.umcutrecht.nl>,
	<CAO7JsnSBCo4exTRgzCaB54udtM0RBQh668zc_NOqXpaRhH93fg@mail.gmail.com>
Message-ID: <6C86BD70D72CB449A189A18EED3037CA05803CA7@EXMB2501.ds.umcutrecht.nl>

Dear professor Bates,

Is it possible to put the iteration information in an R object (this is printed when verbose=TRUE in the lmer function)? 

I like to monitor this output during simulations.

Kind regards, 
Walter



________________________________________
Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
Verzonden: vrijdag 13 januari 2012 17:05
To: Bouwmeester, W.
Cc: R-mixed models mailing list
Onderwerp: Re: lme4 and sample size

On Fri, Jan 13, 2012 at 9:58 AM, Bouwmeester, W.
<W.Bouwmeester at umcutrecht.nl> wrote:
> Dear professor Bates,
>
> I'am using the lmer function indeed. Can I use 'cvg' from the output attr(model, "dims") to evaluate convergence? (here, the object "model" is fitted with the lmer function)

Yes, but do bear in mind that the cvg indicator is from the optimizer,
which is nlminb in the case of the released lme4.  We have encountered
difficulties with nlminb failing to converge or giving the false
convergence message or getting stuck at boundary values.  We later
switched to the bobyqa optimizer from the minqa package and then to a
local implementation of the Nelder-Mead simplex optimizer.

Failure to converge is a property of the optimizer being used, not the
overall design of lme4.  It happens that good optimizers that are
available to Open Source projects are difficult to come by.

> Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
> Verzonden: vrijdag 13 januari 2012 16:51
> To: Bouwmeester, W.
> Onderwerp: Re: lme4 and sample size
>
> I have taken the liberty of copying the reply to the
> R-SIG-Mixed-Models at R-Project.org mailing list so that it will be
> available in a searchable archive.
>
> On Fri, Jan 13, 2012 at 9:37 AM, Bouwmeester, W.
> <W.Bouwmeester at umcutrecht.nl> wrote:
>> Dear professor Bates,
>>
>> I will incvestigate the required sample size to develop a prediction model in hierarchical data, using a simulation study. One of the model evaluation criteria will be whether the model converged. R will give warning messages if no or singular convergence appeared.
>> Is it possible to evaluate model convergence from the cvg column in attr(mix.model,"dims")? Has this "cvg" anything to do with convergence?
>>
>> I saw this "cvg" output from attr(mix.model, "dims") in your publication on October 4, 2011, Linear mixed model implementation in lme4, page 6 and 20.
>
> I would strongly recommend using lmer instead of lme to fit
> heirarchical linear models in a simulation study.  The lmer function
> in the lme4 package is much faster and more reliable than the lme
> function from the nlme package.
>
> The current version of lme4 on CRAN can sometimes encounter a warning
> about "false convergence".  The version named lme4Eigen on the R-forge
> site is, in our preliminary tests, more reliable and usually faster
> than the released version.  You do need to be able to build an R
> package from source to be able to use the lme4Eigen at present.
> ------------------------------------------------------------------------------
>
> De informatie opgenomen in dit bericht kan vertrouwelijk zijn en is
> uitsluitend bestemd voor de geadresseerde. Indien u dit bericht onterecht
> ontvangt, wordt u verzocht de inhoud niet te gebruiken en de afzender direct
> te informeren door het bericht te retourneren. Het Universitair Medisch
> Centrum Utrecht is een publiekrechtelijke rechtspersoon in de zin van de W.H.W.
> (Wet Hoger Onderwijs en Wetenschappelijk Onderzoek) en staat geregistreerd bij
> de Kamer van Koophandel voor Midden-Nederland onder nr. 30244197.
>
> Denk s.v.p aan het milieu voor u deze e-mail afdrukt.
>
> ------------------------------------------------------------------------------
>
> This message may contain confidential information and ...{{dropped:12}}



From datkins at u.washington.edu  Wed Jan 25 20:39:56 2012
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 25 Jan 2012 11:39:56 -0800
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
Message-ID: <4F205A8C.4010303@u.washington.edu>


Hi Charles--

So, I don't know SAS at all, so just providing the SAS code and anova 
table don't tell me (at least) all that much about what SAS is doing. 
Also keep in mind that the anova table summary will depend on the "type" 
of sums of squares (and there have been some diatribes about this and 
type III sums of squares in the past on this list).

I find it a bit more informative to look at the summary output from lme(r):

 > y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
 >
 > summary(y)
Linear mixed-effects model fit by REML
  Data: dental
        AIC      BIC    logLik
   445.7572 461.6236 -216.8786

Random effects:
  Formula: ~1 | Subject
         (Intercept) Residual
StdDev:    1.816214 1.386382

Fixed effects: distance ~ Sex * age
                   Value Std.Error DF   t-value p-value
(Intercept)   16.340625 0.9813122 79 16.651810  0.0000
SexFemale      1.032102 1.5374208 25  0.671321  0.5082
age            0.784375 0.0775011 79 10.120823  0.0000
SexFemale:age -0.304830 0.1214209 79 -2.510520  0.0141
  Correlation:
               (Intr) SexFml age
SexFemale     -0.638
age           -0.869  0.555
SexFemale:age  0.555 -0.869 -0.638

Standardized Within-Group Residuals:
         Min          Q1         Med          Q3         Max
-3.59804400 -0.45461690  0.01578365  0.50244658  3.68620792

Number of Observations: 108
Number of Groups: 27

DAVE: so, we fit a random-intercept, residual error, and 4 fixed-effects 
(N = 27 people and 108 observations)

Here is your second model:

 > y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
+ data=dental)
 > summary(y)
Linear mixed-effects model fit by REML
  Data: dental
        AIC      BIC    logLik
   450.1706 481.9033 -213.0853

Random effects:
  Formula: ~1 | Subject
         (Intercept) Residual
StdDev:    1.827112 1.375353

Correlation Structure: General
  Formula: ~1 | Subject
  Parameter estimate(s):
  Correlation:
   1      2      3
2 -0.174
3 -0.002 -0.177
4 -0.342  0.306  0.227
Fixed effects: distance ~ Sex * age
                   Value Std.Error DF   t-value p-value
(Intercept)   15.932927 0.9978753 79 15.966852  0.0000
SexFemale      1.473662 1.5633701 25  0.942619  0.3549
age            0.824339 0.0824260 79 10.000962  0.0000
SexFemale:age -0.348100 0.1291367 79 -2.695594  0.0086
  Correlation:
               (Intr) SexFml age
SexFemale     -0.638
age           -0.874  0.558
SexFemale:age  0.558 -0.874 -0.638

Standardized Within-Group Residuals:
          Min           Q1          Med           Q3          Max
-3.180968424 -0.544002662  0.001195789  0.495264398  3.730242930

Number of Observations: 108
Number of Groups: 27

DAVE: Now, in addition to earlier parameters, we have an unstructured 
covariance matrix for repeated measures.  By all indications this is a 
*worse* fitting model...

Finally, I wonder whether SAS is fitting random-effects at all (no idea, 
just a guess).  If so, you might check it relative to a gls() fit, a la:

 > y2=gls(distance~Sex*age, corr=corSymm(,~1|Subject),
+ data=dental)
 > summary(y2)
Generalized least squares fit by REML
   Model: distance ~ Sex * age
   Data: dental
        AIC      BIC    logLik
   448.1706 477.2589 -213.0853

Correlation Structure: General
  Formula: ~1 | Subject
  Parameter estimate(s):
  Correlation:
   1     2     3
2 0.575
3 0.638 0.574
4 0.515 0.749 0.721

Coefficients:
                   Value Std.Error   t-value p-value
(Intercept)   15.932911 0.9978729 15.966874  0.0000
SexFemale      1.473679 1.5633664  0.942632  0.3481
age            0.824340 0.0824258 10.001000  0.0000
SexFemale:age -0.348102 0.1291364 -2.695611  0.0082

  Correlation:
               (Intr) SexFml age
SexFemale     -0.638
age           -0.874  0.558
SexFemale:age  0.558 -0.874 -0.638

Standardized residuals:
         Min          Q1         Med          Q3         Max
-2.41707752 -0.64439706 -0.07388955  0.58480683  2.26288228

Residual standard error: 2.286908
Degrees of freedom: 108 total; 104 residual

So, not sure if this is helpful, but perhaps you could provide 
additional output / commentary on what exactly SAS is doing (beyond 
anova table).

cheers, Dave


Greetings,

I have been working on R for some time now and I have begun the endeavor of
trying to replicate some SAS code in R.  I have scoured the forums but
haven't been able to find an answer.  I hope one of you could be so kind as
to enlighten me.

I am attempting to replicate a repeated measures experiment using some
standard data.  I have posted the SAS code and output directly from a
publication as well as my attempts in R to replicate it.  My main issue
comes with the 'unstructured' component.

The 'dental' dataset from 'mixedQF' package,
equivalent to formixed data in SAS

     distance age Subject    Sex
1       26.0   8     M01   Male
2       25.0  10     M01   Male
3       29.0  12     M01   Male
4       31.0  14     M01   Male
5       21.5   8     M02   Male
6       22.5  10     M02   Male
7       23.0  12     M02   Male
8       26.5  14     M02   Male
9       23.0   8     M03   Male
10      22.5  10     M03   Male
11      24.0  12     M03   Male
12      27.5  14     M03   Male
13      25.5   8     M04   Male
14      27.5  10     M04   Male
15      26.5  12     M04   Male
16      27.0  14     M04   Male
17      20.0   8     M05   Male
18      23.5  10     M05   Male
19      22.5  12     M05   Male
20      26.0  14     M05   Male
21      24.5   8     M06   Male
22      25.5  10     M06   Male
23      27.0  12     M06   Male
24      28.5  14     M06   Male
25      22.0   8     M07   Male
26      22.0  10     M07   Male
27      24.5  12     M07   Male
28      26.5  14     M07   Male
29      24.0   8     M08   Male
30      21.5  10     M08   Male
31      24.5  12     M08   Male
32      25.5  14     M08   Male
33      23.0   8     M09   Male
34      20.5  10     M09   Male
35      31.0  12     M09   Male
36      26.0  14     M09   Male
37      27.5   8     M10   Male
38      28.0  10     M10   Male
39      31.0  12     M10   Male
40      31.5  14     M10   Male
41      23.0   8     M11   Male
42      23.0  10     M11   Male
43      23.5  12     M11   Male
44      25.0  14     M11   Male
45      21.5   8     M12   Male
46      23.5  10     M12   Male
47      24.0  12     M12   Male
48      28.0  14     M12   Male
49      17.0   8     M13   Male
50      24.5  10     M13   Male
51      26.0  12     M13   Male
52      29.5  14     M13   Male
53      22.5   8     M14   Male
54      25.5  10     M14   Male
55      25.5  12     M14   Male
56      26.0  14     M14   Male
57      23.0   8     M15   Male
58      24.5  10     M15   Male
59      26.0  12     M15   Male
60      30.0  14     M15   Male
61      22.0   8     M16   Male
62      21.5  10     M16   Male
63      23.5  12     M16   Male
64      25.0  14     M16   Male
65      21.0   8     F01 Female
66      20.0  10     F01 Female
67      21.5  12     F01 Female
68      23.0  14     F01 Female
69      21.0   8     F02 Female
70      21.5  10     F02 Female
71      24.0  12     F02 Female
72      25.5  14     F02 Female
73      20.5   8     F03 Female
74      24.0  10     F03 Female
75      24.5  12     F03 Female
76      26.0  14     F03 Female
77      23.5   8     F04 Female
78      24.5  10     F04 Female
79      25.0  12     F04 Female
80      26.5  14     F04 Female
81      21.5   8     F05 Female
82      23.0  10     F05 Female
83      22.5  12     F05 Female
84      23.5  14     F05 Female
85      20.0   8     F06 Female
86      21.0  10     F06 Female
87      21.0  12     F06 Female
88      22.5  14     F06 Female
89      21.5   8     F07 Female
90      22.5  10     F07 Female
91      23.0  12     F07 Female
92      25.0  14     F07 Female
93      23.0   8     F08 Female
94      23.0  10     F08 Female
95      23.5  12     F08 Female
96      24.0  14     F08 Female
97      20.0   8     F09 Female
98      21.0  10     F09 Female
99      22.0  12     F09 Female
100     21.5  14     F09 Female
101     16.5   8     F10 Female
102     19.0  10     F10 Female
103     19.0  12     F10 Female
104     19.5  14     F10 Female
105     24.5   8     F11 Female
106     25.0  10     F11 Female
107     28.0  12     F11 Female
108     28.0  14     F11 Female

*Mixed modeling and fixed effect test*
SAS
proc mixed data=formixed;
class gender age person;
model y = gender|age;
repeated / type=cs sub=person;
run;

output of interest to me
           Tests of Fixed Effects
Source             NDF   DDF    Type III F    Pr > F
GENDER           1        25        9.29        0.0054
AGE                  3        75       35.35       0.0001
GENDER*AGE   3        75        2.36        0.0781

R (nlme package)
y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
anova(y)

             numDF denDF  F-value p-value
(Intercept)     1    75 4123.156  <.0001
Sex              1    25    9.292  0.0054
age               3    75   40.032  <.0001
Sex:age        3    75    2.362  0.0781

Now this isn't exact but it is extremely close, however when I try to
replicate the unstructured,

SAS
proc mixed data=formixed;
class gender age person;
model y = gender|age;
repeated / type=un sub=person;
run;

              Tests of Fixed Effects
Source          NDF DDF Type III F Pr > F
GENDER         1    25     9.29    0.0054
AGE                3    25    34.45   0.0001
GENDER*AGE 3    25     2.93    0.0532

R
either
y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
data=dental)
anova(y)
or
z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(), data=dental)
anova(z)

gives the output

             numDF denDF  F-value    p-value
(Intercept)     1    75     4052.028  <.0001
Sex              1    25       8.462      0.0075
age               3    75      39.022    <.0001
Sex:age        3    75       2.868      0.0421

What am I doing wrong to replicate the unstructured linear mixed model from
SAS?

Regards,

Charles

	[[alternative HTML version deleted]]

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From David.Duffy at qimr.edu.au  Thu Jan 26 01:33:21 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 26 Jan 2012 10:33:21 +1000 (EST)
Subject: [R-sig-ME] adding a kinship matrix to a GLMM
In-Reply-To: <20120124153558.BDK79131@mstore03.uchicago.edu>
References: <20120124153558.BDK79131@mstore03.uchicago.edu>
Message-ID: <Pine.LNX.4.64.1201261010410.16419@orpheus.qimr.edu.au>

On Tue, 24 Jan 2012, mhorton at uchicago.edu wrote:

> I'm trying this with MASS' glmmPQL, which seems to
> allow the user to provide an "an optional correlation structure".
>
> There are a few classes that extend corStruct, but if I try corSymm, things seem
> to work with:
>
> I'm writing to ask is this the best model formulation?
> Also, if I add a co-factor 'block', which has 6 levels (subjects do not occur in all
> blocks), I get a lot of NA errors:
> test <- glmmPQL( response ~ snps_i + as.factor(block)+ offset(log(offset)),
>          random=~1|subject,correlation=cs.K, family="quasipoisson" );
> iteration 1
> iteration 2
> iteration 3
> Error in na.fail.default(list(subject = c(1L, 1L, 1L, 2L, 2L, 2L, 3L,  :
>  missing values in object
>
> Again, is there a better model formula?  Is corSymm even doing what I think it is
> doing here?

I think so.  That error might be arising from incomplete data, as it says 
(do debug(lme) to see where, as this is what glmmPQL calls).  PQL might 
not be giving brilliant estimates of the random effects, but I presume you 
are most interested in snps_1.  Here is one result from a simulation of 
mine for a binomial trait, using R GLMM packages, augmented by your 
PQL

head(x)
   ped id fa mo sex trait locus
1   1  1 NA NA   m  <NA>   1/2
2   1  2 NA NA   f  <NA>   1/2
3   1  3  1  2   f     n   1/2
4   1  4  1  2   f     y   1/1
5   1  5  1  2   f     n   1/1
6   2  6 NA NA   f  <NA>   1/2


library(pedigreemm)
ped <- pedigree(x$fa, x$mo, x$id)
pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), family=binomial(), 
data=x)
pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), 
family=binomial(link=probit), data=x)

library(AnimalINLA)
ped2 <- x[,2:4]
ped2[is.na(ped2)] <- 0
Ainv <- compute.Ainverse(ped2)
pheno <- data.frame(id=x$id, trait=(x$trait=="y"), Individual=x$id)
pheno <- pheno[complete.cases(pheno$trait),]
m1 <- animal.inla("trait", genetic="id", Ainverse=Ainv, data=pheno, 
type.data = "binomial")
summary(m1)

library(MASS)
library(kinship)
K <- kinship(x$id, x$fa, x$mo)
observed <- !is.na(x$trait)
K <- K[observed, observed]
cs.K <- corSymm(2*K[lower.tri(K)],fixed=T)
id <- as.matrix(as.factor(x$id[observed]))
colnames(id) <- "id"
cs.K <- Initialize(cs.K,data=id)
pql1 <- glmmPQL(trait ~ 1, random=~1|id,
                 correlation=cs.K,
                 data=x[observed,], family="binomial
summary(pql1)

library(MCMCglmm)
pheno <- data.frame(animal=x$id, sire=x$fa, dam=x$mo, y=(x$trait=="y"))
g1 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
                family="categorical", data=pheno, verbose=FALSE)
summary(g1)
g2 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
                family="ordinal", data=pheno, verbose=FALSE)
summary(g2)

-----------------------------
logistic-normal
                  RE SD
pedigreemm       0.847
AnimalINLA       0.671
glmmPQL          1.185
MCMCglmm         1.389


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From David.Duffy at qimr.edu.au  Thu Jan 26 03:54:48 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 26 Jan 2012 12:54:48 +1000 (EST)
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>

On Tue, 24 Jan 2012, Charles Determan Jr wrote:

> Greetings,
>
> I have been working on R for some time now and I have begun the endeavor of
> trying to replicate some SAS code in R.  I have scoured the forums but
>
This is also the Orthodont dataset, distributed with nlme.

As David Atkins pointed out, R defaults to Type I SS. so you would need to 
use, for example, the Anova() command from the car package.  The other 
thing is that the SAS F statistics are only approximate, depending on 
which covariance structure is chosen (perhaps John Maindonald or someone 
clever could comment), so SAS offers different possibilities for ddf eg

http://www2.sas.com/proceedings/sugi26/p262-26.pdf

while lme and lmer offer one or none.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From john.maindonald at anu.edu.au  Thu Jan 26 06:19:22 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 26 Jan 2012 16:19:22 +1100
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
Message-ID: <1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>

It is well to note that type III sums of squares are problematic.
For testing the effects of a main effect, the null model is constraining
the main effect in a manner that depends on the parameterisation.

There are situations where it makes sense to fit interactions without
main effects, and it is clear what constraint on the main effect is the
relevant null (with an interaction between a factor and a variable,
does one want all lines to go though the same point, or through
perhaps the origin?), but that situation is unusual.  For lines that 
are separate or all through the one point, one does not need 
type III sums of squares.

Analyses often or frequently have enough genuine complications 
worrying (unless it is blindingly obvious that one ought to worry
about it) without the rarely relevant complication of attending to a 
type III sum of squares.  

I'd guess that SAS and lme are, effectively, making different
assumptions about the intended generalisation.  They are
clearly using different denominator degrees of freedom for F.
As one is looking for consistency across the 27 different youths,
SAS's denominator degrees of freedom for the interaction seem 
more or less right, pretty much equivalent to calculating slopes 
for females and slopes for males and using a t-test to compare 
them.  (Sure, in the analyses presented, age has been treated 
as a categorical variable, but the comment still applies.)

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 26/01/2012, at 1:54 PM, David Duffy wrote:

> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
> 
>> Greetings,
>> 
>> I have been working on R for some time now and I have begun the endeavor of
>> trying to replicate some SAS code in R.  I have scoured the forums but
>> 
> This is also the Orthodont dataset, distributed with nlme.
> 
> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
> 
> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
> 
> while lme and lmer offer one or none.
> 
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From deter088 at umn.edu  Thu Jan 26 15:24:11 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 08:24:11 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
Message-ID: <CAOLJphkNxMLK2bfa5cx7S7OSyU0_1qLrcgiTv-u04pE-7d4_tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/f2c20fbd/attachment-0001.pl>

From Paul.Thompson at SanfordHealth.org  Thu Jan 26 15:52:01 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Thu, 26 Jan 2012 14:52:01 +0000
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>

I am unfamiliar with this critique of Type III SS. Can you point me to a reference discussing the difficulties with Type III SS?

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
Sent: Wednesday, January 25, 2012 11:19 PM
To: David Duffy
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R

It is well to note that type III sums of squares are problematic.
For testing the effects of a main effect, the null model is constraining
the main effect in a manner that depends on the parameterisation.

There are situations where it makes sense to fit interactions without
main effects, and it is clear what constraint on the main effect is the
relevant null (with an interaction between a factor and a variable,
does one want all lines to go though the same point, or through
perhaps the origin?), but that situation is unusual.  For lines that 
are separate or all through the one point, one does not need 
type III sums of squares.

Analyses often or frequently have enough genuine complications 
worrying (unless it is blindingly obvious that one ought to worry
about it) without the rarely relevant complication of attending to a 
type III sum of squares.  

I'd guess that SAS and lme are, effectively, making different
assumptions about the intended generalisation.  They are
clearly using different denominator degrees of freedom for F.
As one is looking for consistency across the 27 different youths,
SAS's denominator degrees of freedom for the interaction seem 
more or less right, pretty much equivalent to calculating slopes 
for females and slopes for males and using a t-test to compare 
them.  (Sure, in the analyses presented, age has been treated 
as a categorical variable, but the comment still applies.)

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 26/01/2012, at 1:54 PM, David Duffy wrote:

> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
> 
>> Greetings,
>> 
>> I have been working on R for some time now and I have begun the endeavor of
>> trying to replicate some SAS code in R.  I have scoured the forums but
>> 
> This is also the Orthodont dataset, distributed with nlme.
> 
> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
> 
> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
> 
> while lme and lmer offer one or none.
> 
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From lborger at cebc.cnrs.fr  Thu Jan 26 16:02:48 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Thu, 26 Jan 2012 16:02:48 +0100
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
Message-ID: <4F216B18.6030405@cebc.cnrs.fr>

I think:

http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

HTH
Luca



Le 26/01/2012 15:52, Thompson,Paul a ?crit :
> I am unfamiliar with this critique of Type III SS. Can you point me to a reference discussing the difficulties with Type III SS?
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
> Sent: Wednesday, January 25, 2012 11:19 PM
> To: David Duffy
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
>
> It is well to note that type III sums of squares are problematic.
> For testing the effects of a main effect, the null model is constraining
> the main effect in a manner that depends on the parameterisation.
>
> There are situations where it makes sense to fit interactions without
> main effects, and it is clear what constraint on the main effect is the
> relevant null (with an interaction between a factor and a variable,
> does one want all lines to go though the same point, or through
> perhaps the origin?), but that situation is unusual.  For lines that
> are separate or all through the one point, one does not need
> type III sums of squares.
>
> Analyses often or frequently have enough genuine complications
> worrying (unless it is blindingly obvious that one ought to worry
> about it) without the rarely relevant complication of attending to a
> type III sum of squares.
>
> I'd guess that SAS and lme are, effectively, making different
> assumptions about the intended generalisation.  They are
> clearly using different denominator degrees of freedom for F.
> As one is looking for consistency across the 27 different youths,
> SAS's denominator degrees of freedom for the interaction seem
> more or less right, pretty much equivalent to calculating slopes
> for females and slopes for males and using a t-test to compare
> them.  (Sure, in the analyses presented, age has been treated
> as a categorical variable, but the comment still applies.)
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 26/01/2012, at 1:54 PM, David Duffy wrote:
>
>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
>>
>>> Greetings,
>>>
>>> I have been working on R for some time now and I have begun the endeavor of
>>> trying to replicate some SAS code in R.  I have scoured the forums but
>>>
>> This is also the Orthodont dataset, distributed with nlme.
>>
>> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
>>
>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
>>
>> while lme and lmer offer one or none.
>>
>> -- 
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>



From Paul.Thompson at SanfordHealth.org  Thu Jan 26 16:41:10 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Thu, 26 Jan 2012 15:41:10 +0000
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <4F216B18.6030405@cebc.cnrs.fr>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>

OK, I've looked at that reference. 

There are 2 aspects of an estimate like a SS. The first is the stability of the estimate, and the second is the interpretation of the estimate. The issues with the interpretation of the different estimates go back to 1970, and they are simply a matter of interpretation. The point of the Venables discussion is that he does not like Type III SS, not that they are wrong. He does not agree with the interpretation.

The issue here is the accuracy of the Type III or Type I or Type II or whatever. Accuracy comes before interpretation. If the r module and SAS do not arrive at the same estimates, that is an important thing. 

Once we agree upon computation, we can argue about interpretation. Charles Determan is inquiring as to computational accuracy. The use and interpretation of the various Type I, II, III, IV, LVX SS are secondary.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
Sent: Thursday, January 26, 2012 9:03 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R

I think:

http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

HTH
Luca



Le 26/01/2012 15:52, Thompson,Paul a ?crit :
> I am unfamiliar with this critique of Type III SS. Can you point me to a reference discussing the difficulties with Type III SS?
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
> Sent: Wednesday, January 25, 2012 11:19 PM
> To: David Duffy
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
>
> It is well to note that type III sums of squares are problematic.
> For testing the effects of a main effect, the null model is constraining
> the main effect in a manner that depends on the parameterisation.
>
> There are situations where it makes sense to fit interactions without
> main effects, and it is clear what constraint on the main effect is the
> relevant null (with an interaction between a factor and a variable,
> does one want all lines to go though the same point, or through
> perhaps the origin?), but that situation is unusual.  For lines that
> are separate or all through the one point, one does not need
> type III sums of squares.
>
> Analyses often or frequently have enough genuine complications
> worrying (unless it is blindingly obvious that one ought to worry
> about it) without the rarely relevant complication of attending to a
> type III sum of squares.
>
> I'd guess that SAS and lme are, effectively, making different
> assumptions about the intended generalisation.  They are
> clearly using different denominator degrees of freedom for F.
> As one is looking for consistency across the 27 different youths,
> SAS's denominator degrees of freedom for the interaction seem
> more or less right, pretty much equivalent to calculating slopes
> for females and slopes for males and using a t-test to compare
> them.  (Sure, in the analyses presented, age has been treated
> as a categorical variable, but the comment still applies.)
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 26/01/2012, at 1:54 PM, David Duffy wrote:
>
>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
>>
>>> Greetings,
>>>
>>> I have been working on R for some time now and I have begun the endeavor of
>>> trying to replicate some SAS code in R.  I have scoured the forums but
>>>
>> This is also the Orthodont dataset, distributed with nlme.
>>
>> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
>>
>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
>>
>> while lme and lmer offer one or none.
>>
>> -- 
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From mhorton at uchicago.edu  Thu Jan 26 17:10:45 2012
From: mhorton at uchicago.edu (mhorton at uchicago.edu)
Date: Thu, 26 Jan 2012 10:10:45 -0600 (CST)
Subject: [R-sig-ME] adding a kinship matrix to a GLMM
In-Reply-To: <Pine.LNX.4.64.1201261010410.16419@orpheus.qimr.edu.au>
References: <20120124153558.BDK79131@mstore03.uchicago.edu>
	<Pine.LNX.4.64.1201261010410.16419@orpheus.qimr.edu.au>
Message-ID: <20120126101045.BDN88330@mstore03.uchicago.edu>

Thanks David. I'll see if I can fit a kinship matrix using the other packages you show. 
It would also be great to setup the same test case to see how quickly any of this will 
actually run. I can't do that immediately, but I will try to post the results next week.

---- Original message ----
>Date: Thu, 26 Jan 2012 10:33:21 +1000 (EST)
>From: "David Duffy" <David.Duffy at qimr.edu.au>  
>Subject: Re: [R-sig-ME] adding a kinship matrix to a GLMM  
>To: <mhorton at uchicago.edu>
>Cc: <r-sig-mixed-models at r-project.org>
>
>On Tue, 24 Jan 2012, mhorton at uchicago.edu wrote:
>
>> I'm trying this with MASS' glmmPQL, which seems to
>> allow the user to provide an "an optional correlation structure".
>>
>> There are a few classes that extend corStruct, but if I try corSymm, things seem
>> to work with:
>>
>> I'm writing to ask is this the best model formulation?
>> Also, if I add a co-factor 'block', which has 6 levels (subjects do not occur in all
>> blocks), I get a lot of NA errors:
>> test <- glmmPQL( response ~ snps_i + as.factor(block)+ offset(log(offset)),
>>          random=~1|subject,correlation=cs.K, family="quasipoisson" );
>> iteration 1
>> iteration 2
>> iteration 3
>> Error in na.fail.default(list(subject = c(1L, 1L, 1L, 2L, 2L, 2L, 3L,  :
>>  missing values in object
>>
>> Again, is there a better model formula?  Is corSymm even doing what I think it is
>> doing here?
>
>I think so.  That error might be arising from incomplete data, as it says 
>(do debug(lme) to see where, as this is what glmmPQL calls).  PQL might 
>not be giving brilliant estimates of the random effects, but I presume you 
>are most interested in snps_1.  Here is one result from a simulation of 
>mine for a binomial trait, using R GLMM packages, augmented by your 
>PQL
>
>head(x)
>   ped id fa mo sex trait locus
>1   1  1 NA NA   m  <NA>   1/2
>2   1  2 NA NA   f  <NA>   1/2
>3   1  3  1  2   f     n   1/2
>4   1  4  1  2   f     y   1/1
>5   1  5  1  2   f     n   1/1
>6   2  6 NA NA   f  <NA>   1/2
>
>
>library(pedigreemm)
>ped <- pedigree(x$fa, x$mo, x$id)
>pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), family=binomial(), 
>data=x)
>pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), 
>family=binomial(link=probit), data=x)
>
>library(AnimalINLA)
>ped2 <- x[,2:4]
>ped2[is.na(ped2)] <- 0
>Ainv <- compute.Ainverse(ped2)
>pheno <- data.frame(id=x$id, trait=(x$trait=="y"), Individual=x$id)
>pheno <- pheno[complete.cases(pheno$trait),]
>m1 <- animal.inla("trait", genetic="id", Ainverse=Ainv, data=pheno, 
>type.data = "binomial")
>summary(m1)
>
>library(MASS)
>library(kinship)
>K <- kinship(x$id, x$fa, x$mo)
>observed <- !is.na(x$trait)
>K <- K[observed, observed]
>cs.K <- corSymm(2*K[lower.tri(K)],fixed=T)
>id <- as.matrix(as.factor(x$id[observed]))
>colnames(id) <- "id"
>cs.K <- Initialize(cs.K,data=id)
>pql1 <- glmmPQL(trait ~ 1, random=~1|id,
>                 correlation=cs.K,
>                 data=x[observed,], family="binomial
>summary(pql1)
>
>library(MCMCglmm)
>pheno <- data.frame(animal=x$id, sire=x$fa, dam=x$mo, y=(x$trait=="y"))
>g1 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
>                family="categorical", data=pheno, verbose=FALSE)
>summary(g1)
>g2 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
>                family="ordinal", data=pheno, verbose=FALSE)
>summary(g2)
>
>-----------------------------
>logistic-normal
>                  RE SD
>pedigreemm       0.847
>AnimalINLA       0.671
>glmmPQL          1.185
>MCMCglmm         1.389
>
>
>-- 
>| David Duffy (MBBS PhD)                                         ,-_|\
>| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From byrnes at nceas.ucsb.edu  Thu Jan 26 17:43:05 2012
From: byrnes at nceas.ucsb.edu (Jarrett Byrnes)
Date: Thu, 26 Jan 2012 11:43:05 -0500
Subject: [R-sig-ME] Visualizing coefficients
Message-ID: <39AA5C0F-39EF-47B2-876F-C16FA484A557@nceas.ucsb.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/591803aa/attachment-0001.pl>

From bbolker at gmail.com  Thu Jan 26 17:46:53 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 26 Jan 2012 11:46:53 -0500
Subject: [R-sig-ME] [R-SIG-Mac] Visualizing coefficients
In-Reply-To: <60BAAAAE-BDA2-42F4-921D-280A09D82D38@nceas.ucsb.edu>
References: <60BAAAAE-BDA2-42F4-921D-280A09D82D38@nceas.ucsb.edu>
Message-ID: <4F21837D.6000803@gmail.com>

On 12-01-26 10:52 AM, Jarrett Byrnes wrote:
> Before I re-invent a well built wheel, has anyone on this list put
> together a good set of functions for visualizing net effects and the
> variation in the estimates for a fitter lmer or glmer model?  I
> realize that this can be done to some extent via simulation and then
> putting the results into coda or R2WinBUGS, but, has anyone gone
> about it via a different route?  I'm also curious to track down other
> resources for visualizing the results of fitted mer objects.
> 
> -Jarrett
> 

  Did you send this to r-sig-mac rather than r-sig-mixed-models by
mistake? [Forwarding to r-sig-mixed-models]

   in addition to John Fox's suggestion of the 'effects' package I would
mention coefplot (in the arm package: Gelman is the first author,
Yu-Sung Su is the maintainer) and coefplot2 (package of the same name).

  Ben



From byrnes at nceas.ucsb.edu  Thu Jan 26 17:52:18 2012
From: byrnes at nceas.ucsb.edu (Jarrett Byrnes)
Date: Thu, 26 Jan 2012 11:52:18 -0500
Subject: [R-sig-ME] [R-SIG-Mac] Visualizing coefficients
In-Reply-To: <4F21837D.6000803@gmail.com>
References: <60BAAAAE-BDA2-42F4-921D-280A09D82D38@nceas.ucsb.edu>
	<4F21837D.6000803@gmail.com>
Message-ID: <1CA350AC-0745-4823-B342-3CDE0AFC7C35@nceas.ucsb.edu>

Yes, it was indeed a mistake.

Do not trust autocomplete.

On Jan 26, 2012, at 11:46 AM, Ben Bolker wrote:

> On 12-01-26 10:52 AM, Jarrett Byrnes wrote:
>> Before I re-invent a well built wheel, has anyone on this list put
>> together a good set of functions for visualizing net effects and the
>> variation in the estimates for a fitter lmer or glmer model?  I
>> realize that this can be done to some extent via simulation and then
>> putting the results into coda or R2WinBUGS, but, has anyone gone
>> about it via a different route?  I'm also curious to track down other
>> resources for visualizing the results of fitted mer objects.
>> 
>> -Jarrett
>> 
> 
>  Did you send this to r-sig-mac rather than r-sig-mixed-models by
> mistake? [Forwarding to r-sig-mixed-models]
> 
>   in addition to John Fox's suggestion of the 'effects' package I would
> mention coefplot (in the arm package: Gelman is the first author,
> Yu-Sung Su is the maintainer) and coefplot2 (package of the same name).
> 
>  Ben



From j.hadfield at ed.ac.uk  Thu Jan 26 18:16:00 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 26 Jan 2012 17:16:00 +0000
Subject: [R-sig-ME] adding a kinship matrix to a GLMM
In-Reply-To: <20120126101045.BDN88330@mstore03.uchicago.edu>
References: <20120124153558.BDK79131@mstore03.uchicago.edu>
	<Pine.LNX.4.64.1201261010410.16419@orpheus.qimr.edu.au>
	<20120126101045.BDN88330@mstore03.uchicago.edu>
Message-ID: <20120126171600.10829954j10so7yo@www.staffmail.ed.ac.uk>

Hi,

Just a quick note on the MCMCglmm syntax: it is best to fix the  
residual variance a priori with binary data since it cannot be  
estimated. In order to make the variance comparable with the other  
methods you also need to rescale by 1/(1+a) for probit models or  
1/(1+c2*a) for logit models where "a" is the residual varaiance (I  
usually fix at one) and c2 is:

((16 * sqrt(3))/(15 * pi))^2

Cheers,

Jarrod


Quoting mhorton at uchicago.edu on Thu, 26 Jan 2012 10:10:45 -0600 (CST):

> Thanks David. I'll see if I can fit a kinship matrix using the other  
> packages you show.
> It would also be great to setup the same test case to see how  
> quickly any of this will
> actually run. I can't do that immediately, but I will try to post  
> the results next week.
>
> ---- Original message ----
>> Date: Thu, 26 Jan 2012 10:33:21 +1000 (EST)
>> From: "David Duffy" <David.Duffy at qimr.edu.au>
>> Subject: Re: [R-sig-ME] adding a kinship matrix to a GLMM
>> To: <mhorton at uchicago.edu>
>> Cc: <r-sig-mixed-models at r-project.org>
>>
>> On Tue, 24 Jan 2012, mhorton at uchicago.edu wrote:
>>
>>> I'm trying this with MASS' glmmPQL, which seems to
>>> allow the user to provide an "an optional correlation structure".
>>>
>>> There are a few classes that extend corStruct, but if I try  
>>> corSymm, things seem
>>> to work with:
>>>
>>> I'm writing to ask is this the best model formulation?
>>> Also, if I add a co-factor 'block', which has 6 levels (subjects  
>>> do not occur in all
>>> blocks), I get a lot of NA errors:
>>> test <- glmmPQL( response ~ snps_i + as.factor(block)+ offset(log(offset)),
>>>          random=~1|subject,correlation=cs.K, family="quasipoisson" );
>>> iteration 1
>>> iteration 2
>>> iteration 3
>>> Error in na.fail.default(list(subject = c(1L, 1L, 1L, 2L, 2L, 2L, 3L,  :
>>>  missing values in object
>>>
>>> Again, is there a better model formula?  Is corSymm even doing  
>>> what I think it is
>>> doing here?
>>
>> I think so.  That error might be arising from incomplete data, as it says
>> (do debug(lme) to see where, as this is what glmmPQL calls).  PQL might
>> not be giving brilliant estimates of the random effects, but I presume you
>> are most interested in snps_1.  Here is one result from a simulation of
>> mine for a binomial trait, using R GLMM packages, augmented by your
>> PQL
>>
>> head(x)
>>   ped id fa mo sex trait locus
>> 1   1  1 NA NA   m  <NA>   1/2
>> 2   1  2 NA NA   f  <NA>   1/2
>> 3   1  3  1  2   f     n   1/2
>> 4   1  4  1  2   f     y   1/1
>> 5   1  5  1  2   f     n   1/1
>> 6   2  6 NA NA   f  <NA>   1/2
>>
>>
>> library(pedigreemm)
>> ped <- pedigree(x$fa, x$mo, x$id)
>> pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), family=binomial(),
>> data=x)
>> pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped),
>> family=binomial(link=probit), data=x)
>>
>> library(AnimalINLA)
>> ped2 <- x[,2:4]
>> ped2[is.na(ped2)] <- 0
>> Ainv <- compute.Ainverse(ped2)
>> pheno <- data.frame(id=x$id, trait=(x$trait=="y"), Individual=x$id)
>> pheno <- pheno[complete.cases(pheno$trait),]
>> m1 <- animal.inla("trait", genetic="id", Ainverse=Ainv, data=pheno,
>> type.data = "binomial")
>> summary(m1)
>>
>> library(MASS)
>> library(kinship)
>> K <- kinship(x$id, x$fa, x$mo)
>> observed <- !is.na(x$trait)
>> K <- K[observed, observed]
>> cs.K <- corSymm(2*K[lower.tri(K)],fixed=T)
>> id <- as.matrix(as.factor(x$id[observed]))
>> colnames(id) <- "id"
>> cs.K <- Initialize(cs.K,data=id)
>> pql1 <- glmmPQL(trait ~ 1, random=~1|id,
>>                 correlation=cs.K,
>>                 data=x[observed,], family="binomial
>> summary(pql1)
>>
>> library(MCMCglmm)
>> pheno <- data.frame(animal=x$id, sire=x$fa, dam=x$mo, y=(x$trait=="y"))
>> g1 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
>>                family="categorical", data=pheno, verbose=FALSE)
>> summary(g1)
>> g2 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
>>                family="ordinal", data=pheno, verbose=FALSE)
>> summary(g2)
>>
>> -----------------------------
>> logistic-normal
>>                  RE SD
>> pedigreemm       0.847
>> AnimalINLA       0.671
>> glmmPQL          1.185
>> MCMCglmm         1.389
>>
>>
>> --
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ramos.grad.student at gmail.com  Thu Jan 26 18:50:19 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 26 Jan 2012 09:50:19 -0800
Subject: [R-sig-ME] [R-SIG-Mac] Visualizing coefficients
In-Reply-To: <1CA350AC-0745-4823-B342-3CDE0AFC7C35@nceas.ucsb.edu>
References: <60BAAAAE-BDA2-42F4-921D-280A09D82D38@nceas.ucsb.edu>
	<4F21837D.6000803@gmail.com>
	<1CA350AC-0745-4823-B342-3CDE0AFC7C35@nceas.ucsb.edu>
Message-ID: <CAHawB9ucMDL89DchNDPy8CsShjFc8E3v92AO2jqY_Jicr88ofQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/190d22ef/attachment-0001.pl>

From bates at stat.wisc.edu  Thu Jan 26 20:03:03 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 26 Jan 2012 13:03:03 -0600
Subject: [R-sig-ME] lme4 and sample size
In-Reply-To: <6C86BD70D72CB449A189A18EED3037CA05803CA7@EXMB2501.ds.umcutrecht.nl>
References: <6C86BD70D72CB449A189A18EED3037CA057EE65B@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
	<6C86BD70D72CB449A189A18EED3037CA057EE66C@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnSBCo4exTRgzCaB54udtM0RBQh668zc_NOqXpaRhH93fg@mail.gmail.com>
	<6C86BD70D72CB449A189A18EED3037CA05803CA7@EXMB2501.ds.umcutrecht.nl>
Message-ID: <CAO7JsnSHo7gYuipani3hpdxSfK4Jon4X3yJXASrLh0UZz_68KA@mail.gmail.com>

On Wed, Jan 25, 2012 at 5:02 AM, Bouwmeester, W.
<W.Bouwmeester at umcutrecht.nl> wrote:
> Dear professor Bates,

> Is it possible to put the iteration information in an R object (this is printed when verbose=TRUE in the lmer function)?

> I like to monitor this output during simulations.

About the only way to do that is to use capture.output().  The
information on iterations comes from the optimizer, not from lmer.

> ________________________________________
> Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
> Verzonden: vrijdag 13 januari 2012 17:05
> To: Bouwmeester, W.
> Cc: R-mixed models mailing list
> Onderwerp: Re: lme4 and sample size
>
> On Fri, Jan 13, 2012 at 9:58 AM, Bouwmeester, W.
> <W.Bouwmeester at umcutrecht.nl> wrote:
>> Dear professor Bates,
>>
>> I'am using the lmer function indeed. Can I use 'cvg' from the output attr(model, "dims") to evaluate convergence? (here, the object "model" is fitted with the lmer function)
>
> Yes, but do bear in mind that the cvg indicator is from the optimizer,
> which is nlminb in the case of the released lme4. ?We have encountered
> difficulties with nlminb failing to converge or giving the false
> convergence message or getting stuck at boundary values. ?We later
> switched to the bobyqa optimizer from the minqa package and then to a
> local implementation of the Nelder-Mead simplex optimizer.
>
> Failure to converge is a property of the optimizer being used, not the
> overall design of lme4. ?It happens that good optimizers that are
> available to Open Source projects are difficult to come by.
>
>> Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
>> Verzonden: vrijdag 13 januari 2012 16:51
>> To: Bouwmeester, W.
>> Onderwerp: Re: lme4 and sample size
>>
>> I have taken the liberty of copying the reply to the
>> R-SIG-Mixed-Models at R-Project.org mailing list so that it will be
>> available in a searchable archive.
>>
>> On Fri, Jan 13, 2012 at 9:37 AM, Bouwmeester, W.
>> <W.Bouwmeester at umcutrecht.nl> wrote:
>>> Dear professor Bates,
>>>
>>> I will incvestigate the required sample size to develop a prediction model in hierarchical data, using a simulation study. One of the model evaluation criteria will be whether the model converged. R will give warning messages if no or singular convergence appeared.
>>> Is it possible to evaluate model convergence from the cvg column in attr(mix.model,"dims")? Has this "cvg" anything to do with convergence?
>>>
>>> I saw this "cvg" output from attr(mix.model, "dims") in your publication on October 4, 2011, Linear mixed model implementation in lme4, page 6 and 20.
>>
>> I would strongly recommend using lmer instead of lme to fit
>> heirarchical linear models in a simulation study. ?The lmer function
>> in the lme4 package is much faster and more reliable than the lme
>> function from the nlme package.
>>
>> The current version of lme4 on CRAN can sometimes encounter a warning
>> about "false convergence". ?The version named lme4Eigen on the R-forge
>> site is, in our preliminary tests, more reliable and usually faster
>> than the released version. ?You do need to be able to build an R
>> package from source to be able to use the lme4Eigen at present.
>> ------------------------------------------------------------------------------
>>
>> De informatie opgenomen in dit bericht kan vertrouwelijk zijn en is
>> uitsluitend bestemd voor de geadresseerde. Indien u dit bericht onterecht
>> ontvangt, wordt u verzocht de inhoud niet te gebruiken en de afzender direct
>> te informeren door het bericht te retourneren. Het Universitair Medisch
>> Centrum Utrecht is een publiekrechtelijke rechtspersoon in de zin van de W.H.W.
>> (Wet Hoger Onderwijs en Wetenschappelijk Onderzoek) en staat geregistreerd bij
>> de Kamer van Koophandel voor Midden-Nederland onder nr. 30244197.
>>
>> Denk s.v.p aan het milieu voor u deze e-mail afdrukt.
>>
>> ------------------------------------------------------------------------------
>>
>> This message may contain confidential information and is intended exclusively
>> for the addressee. If you receive this message unintentionally, please do not
>> use the contents but notify the sender immediately by return e-mail. University
>> Medical Center Utrecht is a legal person by public law and is registered at
>> the Chamber of Commerce for Midden-Nederland under no. 30244197.
>>
>> Please consider the environment before printing this e-mail.



From smccracken at tadpoleorg.org  Thu Jan 26 20:16:12 2012
From: smccracken at tadpoleorg.org (Shawn McCracken)
Date: Thu, 26 Jan 2012 13:16:12 -0600
Subject: [R-sig-ME] GLMM distribution family model comparison using Poisson
 w/observation level random effect
Message-ID: <CAE+9gVGEtv6coOG1Un=pWVKWyd2s=cZQGZv3SeCgMvvENVjbWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/c3232823/attachment-0001.pl>

From john.maindonald at anu.edu.au  Thu Jan 26 23:37:21 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 27 Jan 2012 09:37:21 +1100
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
Message-ID: <7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>

It is not really a matter of computational accuracy.  One can get highly
accurate values for an inappropriate statistic.  

Or if there is insistence on using the word, accuracy, what is the 
meaning?

i) the wrong formula is used?  Then in what sense is it 'wrong'?

ii) there is a numerical inaccuracy in the calculation?  This is almost
never an issue in a relatively simple calculation such as this, given
the care taken by the code writers in such matters.

iii) where an approximation is used, as in using an F-distribution
approximation, is the best choice of degrees of freedom  made to
for use of this approximation?  I judge that the degrees of freedom 
for lme's F-statistic for the interaction are not well chosen.  Users
really have to sort this out for themselves, rather than relying on
what may be a fairly wild approximation that appears in lm's
output.  Using 75df rather than 25df does not however make the 
difference that a choice between (e.g.) 5df and 25df would.

A further and more basic issue is whether the statistic that is 
provided is appropriate to the intended generalisation.  I'd take
this to be generalisation to another sample of youths from the
same population.  In order to understand why R and SAS are 
giving different F-statistics for the interaction, one needs to
understand just what variance-covariance structure is assumed
in each case.  One might extract the two estimates of the 
var-cov structure and compare them. Look for terms in one that
do not appear, or maybe that are zero, in the other.

Finally, it is not just that Venables does not like type III SS.
He is saying that they almost never correspond to a null
hypothesis that makes any sense.  Those who disagree try to 
write down the model to which the null hypothesis corresponds
in testing for the main effect of factor1 with a factor1:factor2
interaction.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 27/01/2012, at 2:41 AM, Thompson,Paul wrote:

> OK, I've looked at that reference. 
> 
> There are 2 aspects of an estimate like a SS. The first is the stability of the estimate, and the second is the interpretation of the estimate. The issues with the interpretation of the different estimates go back to 1970, and they are simply a matter of interpretation. The point of the Venables discussion is that he does not like Type III SS, not that they are wrong. He does not agree with the interpretation.
> 
> The issue here is the accuracy of the Type III or Type I or Type II or whatever. Accuracy comes before interpretation. If the r module and SAS do not arrive at the same estimates, that is an important thing. 
> 
> Once we agree upon computation, we can argue about interpretation. Charles Determan is inquiring as to computational accuracy. The use and interpretation of the various Type I, II, III, IV, LVX SS are secondary.
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
> Sent: Thursday, January 26, 2012 9:03 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
> 
> I think:
> 
> http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
> 
> HTH
> Luca
> 
> 
> 
> Le 26/01/2012 15:52, Thompson,Paul a ?crit :
>> I am unfamiliar with this critique of Type III SS. Can you point me to a reference discussing the difficulties with Type III SS?
>> 
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
>> Sent: Wednesday, January 25, 2012 11:19 PM
>> To: David Duffy
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
>> 
>> It is well to note that type III sums of squares are problematic.
>> For testing the effects of a main effect, the null model is constraining
>> the main effect in a manner that depends on the parameterisation.
>> 
>> There are situations where it makes sense to fit interactions without
>> main effects, and it is clear what constraint on the main effect is the
>> relevant null (with an interaction between a factor and a variable,
>> does one want all lines to go though the same point, or through
>> perhaps the origin?), but that situation is unusual.  For lines that
>> are separate or all through the one point, one does not need
>> type III sums of squares.
>> 
>> Analyses often or frequently have enough genuine complications
>> worrying (unless it is blindingly obvious that one ought to worry
>> about it) without the rarely relevant complication of attending to a
>> type III sum of squares.
>> 
>> I'd guess that SAS and lme are, effectively, making different
>> assumptions about the intended generalisation.  They are
>> clearly using different denominator degrees of freedom for F.
>> As one is looking for consistency across the 27 different youths,
>> SAS's denominator degrees of freedom for the interaction seem
>> more or less right, pretty much equivalent to calculating slopes
>> for females and slopes for males and using a t-test to compare
>> them.  (Sure, in the analyses presented, age has been treated
>> as a categorical variable, but the comment still applies.)
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics&  Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> On 26/01/2012, at 1:54 PM, David Duffy wrote:
>> 
>>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
>>> 
>>>> Greetings,
>>>> 
>>>> I have been working on R for some time now and I have begun the endeavor of
>>>> trying to replicate some SAS code in R.  I have scoured the forums but
>>>> 
>>> This is also the Orthodont dataset, distributed with nlme.
>>> 
>>> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
>>> 
>>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
>>> 
>>> while lme and lmer offer one or none.
>>> 
>>> -- 
>>> | David Duffy (MBBS PhD)                                         ,-_|\
>>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> -----------------------------------------------------------------------
>> Confidentiality Notice: This e-mail message, including any attachments,
>> is for the sole use of the intended recipient(s) and may contain
>> privileged and confidential information.  Any unauthorized review, use,
>> disclosure or distribution is prohibited.  If you are not the intended
>> recipient, please contact the sender by reply e-mail and destroy
>> all copies of the original message.
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From deter088 at umn.edu  Fri Jan 27 01:06:45 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 18:06:45 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
Message-ID: <CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/26eaf876/attachment-0001.pl>

From smckinney at bccrc.ca  Fri Jan 27 01:36:15 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 26 Jan 2012 16:36:15 -0800
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>

Since SAS does not publish its source code,
replicating SAS code is not always possible
(nor always desirable).  

R code is completely open, so can be studied,
debated and replicated or modified - very useful when
people want to engage in scientific discussions
of statistical issues.  Doing good science and
data analysis is challenging when you are working with 
a black box of mysterious computer code.  That's
why statisticians have worked so hard for years to
set up open source computational tools such as R.


Steven McKinney
Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Charles Determan Jr
> Sent: January-26-12 4:07 PM
> To: John Maindonald
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in
> R
> 
> The only thing I am looking for is the appropriate R code to replicate the
> SAS analysis shown in the previously mentioned paper.  That is all I ask.
> What should the code be in order to analyze this 'dental' data to replicate
> the 'UN' or 'unstructured' analysis in the prior paper.
> 
> Regards,
> 
> Charles
> 
> On Thu, Jan 26, 2012 at 4:37 PM, John Maindonald
> <john.maindonald at anu.edu.au
> > wrote:
> 
> > It is not really a matter of computational accuracy.  One can get highly
> > accurate values for an inappropriate statistic.
> >
> > Or if there is insistence on using the word, accuracy, what is the
> > meaning?
> >
> > i) the wrong formula is used?  Then in what sense is it 'wrong'?
> >
> > ii) there is a numerical inaccuracy in the calculation?  This is almost
> > never an issue in a relatively simple calculation such as this, given
> > the care taken by the code writers in such matters.
> >
> > iii) where an approximation is used, as in using an F-distribution
> > approximation, is the best choice of degrees of freedom  made to
> > for use of this approximation?  I judge that the degrees of freedom
> > for lme's F-statistic for the interaction are not well chosen.  Users
> > really have to sort this out for themselves, rather than relying on
> > what may be a fairly wild approximation that appears in lm's
> > output.  Using 75df rather than 25df does not however make the
> > difference that a choice between (e.g.) 5df and 25df would.
> >
> > A further and more basic issue is whether the statistic that is
> > provided is appropriate to the intended generalisation.  I'd take
> > this to be generalisation to another sample of youths from the
> > same population.  In order to understand why R and SAS are
> > giving different F-statistics for the interaction, one needs to
> > understand just what variance-covariance structure is assumed
> > in each case.  One might extract the two estimates of the
> > var-cov structure and compare them. Look for terms in one that
> > do not appear, or maybe that are zero, in the other.
> >
> > Finally, it is not just that Venables does not like type III SS.
> > He is saying that they almost never correspond to a null
> > hypothesis that makes any sense.  Those who disagree try to
> > write down the model to which the null hypothesis corresponds
> > in testing for the main effect of factor1 with a factor1:factor2
> > interaction.
> >
> > John Maindonald             email: john.maindonald at anu.edu.au
> > phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> > Centre for Mathematics & Its Applications, Room 1194,
> > John Dedman Mathematical Sciences Building (Building 27)
> > Australian National University, Canberra ACT 0200.
> > http://www.maths.anu.edu.au/~johnm
> >
> > On 27/01/2012, at 2:41 AM, Thompson,Paul wrote:
> >
> > > OK, I've looked at that reference.
> > >
> > > There are 2 aspects of an estimate like a SS. The first is the
> stability
> > of the estimate, and the second is the interpretation of the estimate.
> The
> > issues with the interpretation of the different estimates go back to
> 1970,
> > and they are simply a matter of interpretation. The point of the Venables
> > discussion is that he does not like Type III SS, not that they are wrong.
> > He does not agree with the interpretation.
> > >
> > > The issue here is the accuracy of the Type III or Type I or Type II or
> > whatever. Accuracy comes before interpretation. If the r module and SAS
> do
> > not arrive at the same estimates, that is an important thing.
> > >
> > > Once we agree upon computation, we can argue about interpretation.
> > Charles Determan is inquiring as to computational accuracy. The use and
> > interpretation of the various Type I, II, III, IV, LVX SS are secondary.
> > >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
> > > Sent: Thursday, January 26, 2012 9:03 AM
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
> Procedure
> > in R
> > >
> > > I think:
> > >
> > > http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
> > >
> > > HTH
> > > Luca
> > >
> > >
> > >
> > > Le 26/01/2012 15:52, Thompson,Paul a ?crit :
> > >> I am unfamiliar with this critique of Type III SS. Can you point me to
> > a reference discussing the difficulties with Type III SS?
> > >>
> > >> -----Original Message-----
> > >> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
> > >> Sent: Wednesday, January 25, 2012 11:19 PM
> > >> To: David Duffy
> > >> Cc: r-sig-mixed-models at r-project.org
> > >> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
> > Procedure in R
> > >>
> > >> It is well to note that type III sums of squares are problematic.
> > >> For testing the effects of a main effect, the null model is
> constraining
> > >> the main effect in a manner that depends on the parameterisation.
> > >>
> > >> There are situations where it makes sense to fit interactions without
> > >> main effects, and it is clear what constraint on the main effect is
> the
> > >> relevant null (with an interaction between a factor and a variable,
> > >> does one want all lines to go though the same point, or through
> > >> perhaps the origin?), but that situation is unusual.  For lines that
> > >> are separate or all through the one point, one does not need
> > >> type III sums of squares.
> > >>
> > >> Analyses often or frequently have enough genuine complications
> > >> worrying (unless it is blindingly obvious that one ought to worry
> > >> about it) without the rarely relevant complication of attending to a
> > >> type III sum of squares.
> > >>
> > >> I'd guess that SAS and lme are, effectively, making different
> > >> assumptions about the intended generalisation.  They are
> > >> clearly using different denominator degrees of freedom for F.
> > >> As one is looking for consistency across the 27 different youths,
> > >> SAS's denominator degrees of freedom for the interaction seem
> > >> more or less right, pretty much equivalent to calculating slopes
> > >> for females and slopes for males and using a t-test to compare
> > >> them.  (Sure, in the analyses presented, age has been treated
> > >> as a categorical variable, but the comment still applies.)
> > >>
> > >> John Maindonald             email: john.maindonald at anu.edu.au
> > >> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> > >> Centre for Mathematics&  Its Applications, Room 1194,
> > >> John Dedman Mathematical Sciences Building (Building 27)
> > >> Australian National University, Canberra ACT 0200.
> > >> http://www.maths.anu.edu.au/~johnm
> > >>
> > >> On 26/01/2012, at 1:54 PM, David Duffy wrote:
> > >>
> > >>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
> > >>>
> > >>>> Greetings,
> > >>>>
> > >>>> I have been working on R for some time now and I have begun the
> > endeavor of
> > >>>> trying to replicate some SAS code in R.  I have scoured the forums
> but
> > >>>>
> > >>> This is also the Orthodont dataset, distributed with nlme.
> > >>>
> > >>> As David Atkins pointed out, R defaults to Type I SS. so you would
> > need to use, for example, the Anova() command from the car package.  The
> > other thing is that the SAS F statistics are only approximate, depending
> on
> > which covariance structure is chosen (perhaps John Maindonald or someone
> > clever could comment), so SAS offers different possibilities for ddf eg
> > >>>
> > >>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
> > >>>
> > >>> while lme and lmer offer one or none.
> > >>>
> > >>> --
> > >>> | David Duffy (MBBS PhD)                                         ,-
> _|\
> > >>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /
> > *
> > >>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-
> ._/
> > >>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A
> v
> > >>>
> > >>> _______________________________________________
> > >>> R-sig-mixed-models at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >> ----------------------------------------------------------------------
> -
> > >> Confidentiality Notice: This e-mail message, including any
> attachments,
> > >> is for the sole use of the intended recipient(s) and may contain
> > >> privileged and confidential information.  Any unauthorized review,
> use,
> > >> disclosure or distribution is prohibited.  If you are not the intended
> > >> recipient, please contact the sender by reply e-mail and destroy
> > >> all copies of the original message.
> > >>
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >>
> > >>
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > -----------------------------------------------------------------------
> > > Confidentiality Notice: This e-mail message, including any attachments,
> > > is for the sole use of the intended recipient(s) and may contain
> > > privileged and confidential information.  Any unauthorized review, use,
> > > disclosure or distribution is prohibited.  If you are not the intended
> > > recipient, please contact the sender by reply e-mail and destroy
> > > all copies of the original message.
> > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 	[[alternative HTML version deleted]]



From deter088 at umn.edu  Fri Jan 27 01:50:26 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 18:50:26 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
Message-ID: <CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/4adecd42/attachment-0001.pl>

From smckinney at bccrc.ca  Fri Jan 27 02:20:53 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 26 Jan 2012 17:20:53 -0800
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
	<CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>

Here's a typical agreement that users of SAS must agree to:


Subject to the provisions contained herein, EMPLOYEE may use the SAS copyrighted computer software products which LICENSEE has provided in accordance with its agreement with SAS.

EMPLOYEE acknowledges that these products are copyrighted and that SAS retains all title and ownership rights to the products.  EMPLOYEE agrees not to copy or permit others to copy the products, in whole or in part.

EMPLOYEE agrees to use the products under this agreement only on a computer which is owned or leased by LICENSEE and controlled by LICENSEE.  EMPLOYEE further agrees that the products must remain under EMPLOYEE's control, and that resale or other transfer is explicitly prohibited.

EMPLOYEE agrees to use the products only for EMPLOYEE's or LICENSEE's own data processing requirements, and not for commercial time-sharing, rental or service bureau use.

EMPLOYEE agrees not to create, or attempt to create, or permit or help others to create, the source code from the products furnished under this agreement.  EMPLOYEE agrees that it will not reverse engineer or decompile the products.


(source: http://www.mcmaster.ca/uts/software_downloads/docs/SAS/saslicendform.doc )

Note that last paragraph.  You can find it in other SAS end user license agreements.

So anyone who tries to "replicate PROC MIXED for repeated measures set as unstructured in R"
is then subject to legal action by the largest wealthiest statistical software company ever in
existence.  I personally am not up for that challenge, especially when the code has
debateable merits.

I'd rather write code from scratch using sound statistical first principles,
which I can do thanks to the amazing amount of hard work by the R core group,
none of whom have ever asked me to sign any agreement (though they do insist
that I distribute source code and the GNU General Public License with any
copies I modify and/or distribute).


Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre




From: Charles Determan Jr [mailto:deter088 at umn.edu]
Sent: January-26-12 4:50 PM
To: Steven McKinney
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R

So am I to assume that this implies that there isn't any known way to replicate PROC MIXED for repeated measures set as unstructured in R?

Charles
On Thu, Jan 26, 2012 at 6:36 PM, Steven McKinney <smckinney at bccrc.ca> wrote:
Since SAS does not publish its source code,
replicating SAS code is not always possible
(nor always desirable).

R code is completely open, so can be studied,
debated and replicated or modified - very useful when
people want to engage in scientific discussions
of statistical issues.  Doing good science and
data analysis is challenging when you are working with
a black box of mysterious computer code.  That's
why statisticians have worked so hard for years to
set up open source computational tools such as R.


Steven McKinney
Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Charles Determan Jr
> Sent: January-26-12 4:07 PM
> To: John Maindonald
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in
> R
>
> The only thing I am looking for is the appropriate R code to replicate the
> SAS analysis shown in the previously mentioned paper.  That is all I ask.
> What should the code be in order to analyze this 'dental' data to replicate
> the 'UN' or 'unstructured' analysis in the prior paper.
>
> Regards,
>
> Charles
>
> On Thu, Jan 26, 2012 at 4:37 PM, John Maindonald
> <john.maindonald at anu.edu.au
> > wrote:
>
> > It is not really a matter of computational accuracy.  One can get highly
> > accurate values for an inappropriate statistic.
> >
> > Or if there is insistence on using the word, accuracy, what is the
> > meaning?
> >
> > i) the wrong formula is used?  Then in what sense is it 'wrong'?
> >
> > ii) there is a numerical inaccuracy in the calculation?  This is almost
> > never an issue in a relatively simple calculation such as this, given
> > the care taken by the code writers in such matters.
> >
> > iii) where an approximation is used, as in using an F-distribution
> > approximation, is the best choice of degrees of freedom  made to
> > for use of this approximation?  I judge that the degrees of freedom
> > for lme's F-statistic for the interaction are not well chosen.  Users
> > really have to sort this out for themselves, rather than relying on
> > what may be a fairly wild approximation that appears in lm's
> > output.  Using 75df rather than 25df does not however make the
> > difference that a choice between (e.g.) 5df and 25df would.
> >
> > A further and more basic issue is whether the statistic that is
> > provided is appropriate to the intended generalisation.  I'd take
> > this to be generalisation to another sample of youths from the
> > same population.  In order to understand why R and SAS are
> > giving different F-statistics for the interaction, one needs to
> > understand just what variance-covariance structure is assumed
> > in each case.  One might extract the two estimates of the
> > var-cov structure and compare them. Look for terms in one that
> > do not appear, or maybe that are zero, in the other.
> >
> > Finally, it is not just that Venables does not like type III SS.
> > He is saying that they almost never correspond to a null
> > hypothesis that makes any sense.  Those who disagree try to
> > write down the model to which the null hypothesis corresponds
> > in testing for the main effect of factor1 with a factor1:factor2
> > interaction.
> >
> > John Maindonald             email: john.maindonald at anu.edu.au
> > phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> > Centre for Mathematics & Its Applications, Room 1194,
> > John Dedman Mathematical Sciences Building (Building 27)
> > Australian National University, Canberra ACT 0200.
> > http://www.maths.anu.edu.au/~johnm
> >
> > On 27/01/2012, at 2:41 AM, Thompson,Paul wrote:
> >
> > > OK, I've looked at that reference.
> > >
> > > There are 2 aspects of an estimate like a SS. The first is the
> stability
> > of the estimate, and the second is the interpretation of the estimate.
> The
> > issues with the interpretation of the different estimates go back to
> 1970,
> > and they are simply a matter of interpretation. The point of the Venables
> > discussion is that he does not like Type III SS, not that they are wrong.
> > He does not agree with the interpretation.
> > >
> > > The issue here is the accuracy of the Type III or Type I or Type II or
> > whatever. Accuracy comes before interpretation. If the r module and SAS
> do
> > not arrive at the same estimates, that is an important thing.
> > >
> > > Once we agree upon computation, we can argue about interpretation.
> > Charles Determan is inquiring as to computational accuracy. The use and
> > interpretation of the various Type I, II, III, IV, LVX SS are secondary.
> > >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
> > > Sent: Thursday, January 26, 2012 9:03 AM
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
> Procedure
> > in R
> > >
> > > I think:
> > >
> > > http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
> > >
> > > HTH
> > > Luca
> > >
> > >
> > >
> > > Le 26/01/2012 15:52, Thompson,Paul a ?crit :
> > >> I am unfamiliar with this critique of Type III SS. Can you point me to
> > a reference discussing the difficulties with Type III SS?
> > >>
> > >> -----Original Message-----
> > >> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
> > >> Sent: Wednesday, January 25, 2012 11:19 PM
> > >> To: David Duffy
> > >> Cc: r-sig-mixed-models at r-project.org
> > >> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
> > Procedure in R
> > >>
> > >> It is well to note that type III sums of squares are problematic.
> > >> For testing the effects of a main effect, the null model is
> constraining
> > >> the main effect in a manner that depends on the parameterisation.
> > >>
> > >> There are situations where it makes sense to fit interactions without
> > >> main effects, and it is clear what constraint on the main effect is
> the
> > >> relevant null (with an interaction between a factor and a variable,
> > >> does one want all lines to go though the same point, or through
> > >> perhaps the origin?), but that situation is unusual.  For lines that
> > >> are separate or all through the one point, one does not need
> > >> type III sums of squares.
> > >>
> > >> Analyses often or frequently have enough genuine complications
> > >> worrying (unless it is blindingly obvious that one ought to worry
> > >> about it) without the rarely relevant complication of attending to a
> > >> type III sum of squares.
> > >>
> > >> I'd guess that SAS and lme are, effectively, making different
> > >> assumptions about the intended generalisation.  They are
> > >> clearly using different denominator degrees of freedom for F.
> > >> As one is looking for consistency across the 27 different youths,
> > >> SAS's denominator degrees of freedom for the interaction seem
> > >> more or less right, pretty much equivalent to calculating slopes
> > >> for females and slopes for males and using a t-test to compare
> > >> them.  (Sure, in the analyses presented, age has been treated
> > >> as a categorical variable, but the comment still applies.)
> > >>
> > >> John Maindonald             email: john.maindonald at anu.edu.au
> > >> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> > >> Centre for Mathematics&  Its Applications, Room 1194,
> > >> John Dedman Mathematical Sciences Building (Building 27)
> > >> Australian National University, Canberra ACT 0200.
> > >> http://www.maths.anu.edu.au/~johnm
> > >>
> > >> On 26/01/2012, at 1:54 PM, David Duffy wrote:
> > >>
> > >>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
> > >>>
> > >>>> Greetings,
> > >>>>
> > >>>> I have been working on R for some time now and I have begun the
> > endeavor of
> > >>>> trying to replicate some SAS code in R.  I have scoured the forums
> but
> > >>>>
> > >>> This is also the Orthodont dataset, distributed with nlme.
> > >>>
> > >>> As David Atkins pointed out, R defaults to Type I SS. so you would
> > need to use, for example, the Anova() command from the car package.  The
> > other thing is that the SAS F statistics are only approximate, depending
> on
> > which covariance structure is chosen (perhaps John Maindonald or someone
> > clever could comment), so SAS offers different possibilities for ddf eg
> > >>>
> > >>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
> > >>>
> > >>> while lme and lmer offer one or none.
> > >>>
> > >>> --
> > >>> | David Duffy (MBBS PhD)                                         ,-
> _|\
> > >>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /
> > *
> > >>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-
> ._/
> > >>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A
> v
> > >>>
> > >>> _______________________________________________
> > >>> R-sig-mixed-models at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >> ----------------------------------------------------------------------
> -
> > >> Confidentiality Notice: This e-mail message, including any
> attachments,
> > >> is for the sole use of the intended recipient(s) and may contain
> > >> privileged and confidential information.  Any unauthorized review,
> use,
> > >> disclosure or distribution is prohibited.  If you are not the intended
> > >> recipient, please contact the sender by reply e-mail and destroy
> > >> all copies of the original message.
> > >>
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >>
> > >>
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > -----------------------------------------------------------------------
> > > Confidentiality Notice: This e-mail message, including any attachments,
> > > is for the sole use of the intended recipient(s) and may contain
> > > privileged and confidential information.  Any unauthorized review, use,
> > > disclosure or distribution is prohibited.  If you are not the intended
> > > recipient, please contact the sender by reply e-mail and destroy
> > > all copies of the original message.
> > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>       [[alternative HTML version deleted]]



From deter088 at umn.edu  Fri Jan 27 02:37:30 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 19:37:30 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
	<CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
Message-ID: <CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/fceb609f/attachment-0001.pl>

From mbrooks at ufl.edu  Fri Jan 27 02:45:13 2012
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Thu, 26 Jan 2012 20:45:13 -0500
Subject: [R-sig-ME] GLMM distribution family model comparison using
	Poisson w/observation level random effect
In-Reply-To: <mailman.268.1327622817.4475.r-sig-mixed-models@r-project.org>
References: <mailman.268.1327622817.4475.r-sig-mixed-models@r-project.org>
Message-ID: <BCC5E2AB-FC36-4B3A-B339-C6111292A41A@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/72d75ca2/attachment-0001.pl>

From David.Duffy at qimr.edu.au  Fri Jan 27 03:21:47 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 27 Jan 2012 12:21:47 +1000 (EST)
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com><Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au><1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au><9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org><4F216B18.6030405@cebc.cnrs.fr><9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org><7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au><20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com><DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA><CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com><DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
	<CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1201271217010.18082@orpheus.qimr.edu.au>

On Thu, 26 Jan 2012, Charles Determan Jr wrote:

> I see, thank you Steven for your response.  Perhaps I should start a new
> question on here for what people would recommend currently in R for
> analyzing a repeated measures data set.

If you Google on "Orthodont" and R, you will find several analyses of this 
dataset, including one in John Maindonald's book.  In those analyses, age 
has been treated as a continuous covariate, rather than the SAS example's 
approach.



-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From jwiley.psych at gmail.com  Fri Jan 27 04:11:22 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 26 Jan 2012 19:11:22 -0800
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
	<CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
	<CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
Message-ID: <CANz9Z_KLX9J=2D9w2Jncswu9B43J8UX67cOY5i2ibQ7c-9h9FQ@mail.gmail.com>

Hi Charles,

Caveat emptor: I have not read John Maindonalds analysis of this data.
 There may well be problems with this, but here are some of the things
I would try with the data.

By the way, if you want us to help you fit the same model as SAS, it
would help to know what SAS is fitting.  If you could provide the
formula for the model and covariance structure, that would help.  If
you do not know, perhaps first try to replicate in SAS using something
more explicit than the 'repeated' option.

Cheers,

Josh

dat <- structure(list(distance = c(26, 25, 29, 31, 21.5, 22.5, 23, 26.5,
23, 22.5, 24, 27.5, 25.5, 27.5, 26.5, 27, 20, 23.5, 22.5, 26,
24.5, 25.5, 27, 28.5, 22, 22, 24.5, 26.5, 24, 21.5, 24.5, 25.5,
23, 20.5, 31, 26, 27.5, 28, 31, 31.5, 23, 23, 23.5, 25, 21.5,
23.5, 24, 28, 17, 24.5, 26, 29.5, 22.5, 25.5, 25.5, 26, 23, 24.5,
26, 30, 22, 21.5, 23.5, 25, 21, 20, 21.5, 23, 21, 21.5, 24, 25.5,
20.5, 24, 24.5, 26, 23.5, 24.5, 25, 26.5, 21.5, 23, 22.5, 23.5,
20, 21, 21, 22.5, 21.5, 22.5, 23, 25, 23, 23, 23.5, 24, 20, 21,
22, 21.5, 16.5, 19, 19, 19.5, 24.5, 25, 28, 28), age = c(8L,
10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L,
12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L,
14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L,
8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L,
10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L,
12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L,
14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L,
8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L,
10L, 12L, 14L), Subject = structure(c(12L, 12L, 12L, 12L, 13L,
13L, 13L, 13L, 14L, 14L, 14L, 14L, 15L, 15L, 15L, 15L, 16L, 16L,
16L, 16L, 17L, 17L, 17L, 17L, 18L, 18L, 18L, 18L, 19L, 19L, 19L,
19L, 20L, 20L, 20L, 20L, 21L, 21L, 21L, 21L, 22L, 22L, 22L, 22L,
23L, 23L, 23L, 23L, 24L, 24L, 24L, 24L, 25L, 25L, 25L, 25L, 26L,
26L, 26L, 26L, 27L, 27L, 27L, 27L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L,
6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L,
10L, 10L, 11L, 11L, 11L, 11L), .Label = c("F01", "F02", "F03",
"F04", "F05", "F06", "F07", "F08", "F09", "F10", "F11", "M01",
"M02", "M03", "M04", "M05", "M06", "M07", "M08", "M09", "M10",
"M11", "M12", "M13", "M14", "M15", "M16"), class = "factor"),
    Sex = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("Female", "Male"
    ), class = "factor")), .Names = c("distance", "age", "Subject",
"Sex"), class = "data.frame", row.names = c("1", "2", "3", "4",
"5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15",
"16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26",
"27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37",
"38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48",
"49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59",
"60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "70",
"71", "72", "73", "74", "75", "76", "77", "78", "79", "80", "81",
"82", "83", "84", "85", "86", "87", "88", "89", "90", "91", "92",
"93", "94", "95", "96", "97", "98", "99", "100", "101", "102",
"103", "104", "105", "106", "107", "108"))

require(ggplot2)
require(mgcv)

## intercepts and slopes seem different between sexes
## but there is no evidence of a nonlinear relationship between
## age and distance
ggplot(dat, aes(x = age, y = distance, colour = Sex)) +
  geom_point() +
  stat_smooth(method = "gam", formula = y ~ s(x))

## reorder data by initial distance value
dat$Subject <- with(dat, reorder(Subject,
  distance[ifelse(age == min(age), TRUE, NA)],
  FUN = mean, na.rm = TRUE))

## slight evidence that lower intercepts may be
## associated with more positive slopes
ggplot(dat, aes(x = age, y = distance, colour = Sex)) +
  geom_point() +
  stat_smooth(method = "gam", formula = y ~ s(x)) +
  facet_wrap(~ Subject)

## lme4 package for mixed effects models
require(lme4)

mnull <- lmer(distance ~ 1 + (1 | Subject), data = dat)
m1 <- update(mnull, . ~ . + age * Sex)
m2 <- update(m2, . ~ . + (0 + age | Subject))
m3 <- lmer(distance ~ age * Sex + (1 + age | Subject), data = dat)

## compare different models, m1 seems good
anova(mnull, m1, m2, m3)

plot(dat$distance, fitted(m1))

## examine residuals and random effects
qqnorm(resid(m1))
plot(dat$age, resid(m1))
qqnorm(ranef(m1)$Subject[,1])

## view the summary
summary(m1)
## Linear mixed model fit by REML
## Formula: distance ~ (1 | Subject) + age + Sex + age:Sex
##    Data: dat
##    AIC   BIC logLik deviance REMLdev
##  445.8 461.9 -216.9    428.7   433.8
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Subject  (Intercept) 3.2986   1.8162
##  Residual             1.9221   1.3864
## Number of obs: 108, groups: Subject, 27

## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 17.37273    1.18349  14.679
## age          0.47955    0.09347   5.130
## SexMale     -1.03210    1.53740  -0.671
## age:SexMale  0.30483    0.12142   2.511

## Correlation of Fixed Effects:
##             (Intr) age    SexMal
## age         -0.869
## SexMale     -0.770  0.669
## age:SexMale  0.669 -0.770 -0.869


On Thu, Jan 26, 2012 at 5:37 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> I see, thank you Steven for your response. ?Perhaps I should start a new
> question on here for what people would recommend currently in R for
> analyzing a repeated measures data set. ?Would that be an appropriate
> request without infringing upon any possible legal ramifications? ?Perhaps
> there is a slightly different method that is built on 'sound statistical
> first principles'. ?Or does anyone currently following this thread know an
> appropriate repeated measures analysis of this 'dental' data that would be
> similar to the SAS results?
>
> Charles
>
> On Thu, Jan 26, 2012 at 7:20 PM, Steven McKinney <smckinney at bccrc.ca> wrote:
>
>> Here's a typical agreement that users of SAS must agree to:
>>
>>
>> Subject to the provisions contained herein, EMPLOYEE may use the SAS
>> copyrighted computer software products which LICENSEE has provided in
>> accordance with its agreement with SAS.
>>
>> EMPLOYEE acknowledges that these products are copyrighted and that SAS
>> retains all title and ownership rights to the products. ?EMPLOYEE agrees
>> not to copy or permit others to copy the products, in whole or in part.
>>
>> EMPLOYEE agrees to use the products under this agreement only on a
>> computer which is owned or leased by LICENSEE and controlled by LICENSEE.
>> ?EMPLOYEE further agrees that the products must remain under EMPLOYEE's
>> control, and that resale or other transfer is explicitly prohibited.
>>
>> EMPLOYEE agrees to use the products only for EMPLOYEE's or LICENSEE's own
>> data processing requirements, and not for commercial time-sharing, rental
>> or service bureau use.
>>
>> EMPLOYEE agrees not to create, or attempt to create, or permit or help
>> others to create, the source code from the products furnished under this
>> agreement. ?EMPLOYEE agrees that it will not reverse engineer or decompile
>> the products.
>>
>>
>> (source:
>> http://www.mcmaster.ca/uts/software_downloads/docs/SAS/saslicendform.doc )
>>
>> Note that last paragraph. ?You can find it in other SAS end user license
>> agreements.
>>
>> So anyone who tries to "replicate PROC MIXED for repeated measures set as
>> unstructured in R"
>> is then subject to legal action by the largest wealthiest statistical
>> software company ever in
>> existence. ?I personally am not up for that challenge, especially when the
>> code has
>> debateable merits.
>>
>> I'd rather write code from scratch using sound statistical first
>> principles,
>> which I can do thanks to the amazing amount of hard work by the R core
>> group,
>> none of whom have ever asked me to sign any agreement (though they do
>> insist
>> that I distribute source code and the GNU General Public License with any
>> copies I modify and/or distribute).
>>
>>
>> Steven McKinney
>>
>> Statistician
>> Molecular Oncology and Breast Cancer Program
>> British Columbia Cancer Research Centre
>>
>>
>>
>>
>> From: Charles Determan Jr [mailto:deter088 at umn.edu]
>> Sent: January-26-12 4:50 PM
>> To: Steven McKinney
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure
>> in R
>>
>> So am I to assume that this implies that there isn't any known way to
>> replicate PROC MIXED for repeated measures set as unstructured in R?
>>
>> Charles
>> On Thu, Jan 26, 2012 at 6:36 PM, Steven McKinney <smckinney at bccrc.ca>
>> wrote:
>> Since SAS does not publish its source code,
>> replicating SAS code is not always possible
>> (nor always desirable).
>>
>> R code is completely open, so can be studied,
>> debated and replicated or modified - very useful when
>> people want to engage in scientific discussions
>> of statistical issues. ?Doing good science and
>> data analysis is challenging when you are working with
>> a black box of mysterious computer code. ?That's
>> why statisticians have worked so hard for years to
>> set up open source computational tools such as R.
>>
>>
>> Steven McKinney
>> Statistician
>> Molecular Oncology and Breast Cancer Program
>> British Columbia Cancer Research Centre
>>
>> > -----Original Message-----
>> > From: r-sig-mixed-models-bounces at r-project.org [mailto:
>> r-sig-mixed-models-
>> > bounces at r-project.org] On Behalf Of Charles Determan Jr
>> > Sent: January-26-12 4:07 PM
>> > To: John Maindonald
>> > Cc: r-sig-mixed-models at r-project.org
>> > Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure
>> in
>> > R
>> >
>> > The only thing I am looking for is the appropriate R code to replicate
>> the
>> > SAS analysis shown in the previously mentioned paper. ?That is all I ask.
>> > What should the code be in order to analyze this 'dental' data to
>> replicate
>> > the 'UN' or 'unstructured' analysis in the prior paper.
>> >
>> > Regards,
>> >
>> > Charles
>> >
>> > On Thu, Jan 26, 2012 at 4:37 PM, John Maindonald
>> > <john.maindonald at anu.edu.au
>> > > wrote:
>> >
>> > > It is not really a matter of computational accuracy. ?One can get
>> highly
>> > > accurate values for an inappropriate statistic.
>> > >
>> > > Or if there is insistence on using the word, accuracy, what is the
>> > > meaning?
>> > >
>> > > i) the wrong formula is used? ?Then in what sense is it 'wrong'?
>> > >
>> > > ii) there is a numerical inaccuracy in the calculation? ?This is almost
>> > > never an issue in a relatively simple calculation such as this, given
>> > > the care taken by the code writers in such matters.
>> > >
>> > > iii) where an approximation is used, as in using an F-distribution
>> > > approximation, is the best choice of degrees of freedom ?made to
>> > > for use of this approximation? ?I judge that the degrees of freedom
>> > > for lme's F-statistic for the interaction are not well chosen. ?Users
>> > > really have to sort this out for themselves, rather than relying on
>> > > what may be a fairly wild approximation that appears in lm's
>> > > output. ?Using 75df rather than 25df does not however make the
>> > > difference that a choice between (e.g.) 5df and 25df would.
>> > >
>> > > A further and more basic issue is whether the statistic that is
>> > > provided is appropriate to the intended generalisation. ?I'd take
>> > > this to be generalisation to another sample of youths from the
>> > > same population. ?In order to understand why R and SAS are
>> > > giving different F-statistics for the interaction, one needs to
>> > > understand just what variance-covariance structure is assumed
>> > > in each case. ?One might extract the two estimates of the
>> > > var-cov structure and compare them. Look for terms in one that
>> > > do not appear, or maybe that are zero, in the other.
>> > >
>> > > Finally, it is not just that Venables does not like type III SS.
>> > > He is saying that they almost never correspond to a null
>> > > hypothesis that makes any sense. ?Those who disagree try to
>> > > write down the model to which the null hypothesis corresponds
>> > > in testing for the main effect of factor1 with a factor1:factor2
>> > > interaction.
>> > >
>> > > John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>> > > phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>> > > Centre for Mathematics & Its Applications, Room 1194,
>> > > John Dedman Mathematical Sciences Building (Building 27)
>> > > Australian National University, Canberra ACT 0200.
>> > > http://www.maths.anu.edu.au/~johnm
>> > >
>> > > On 27/01/2012, at 2:41 AM, Thompson,Paul wrote:
>> > >
>> > > > OK, I've looked at that reference.
>> > > >
>> > > > There are 2 aspects of an estimate like a SS. The first is the
>> > stability
>> > > of the estimate, and the second is the interpretation of the estimate.
>> > The
>> > > issues with the interpretation of the different estimates go back to
>> > 1970,
>> > > and they are simply a matter of interpretation. The point of the
>> Venables
>> > > discussion is that he does not like Type III SS, not that they are
>> wrong.
>> > > He does not agree with the interpretation.
>> > > >
>> > > > The issue here is the accuracy of the Type III or Type I or Type II
>> or
>> > > whatever. Accuracy comes before interpretation. If the r module and SAS
>> > do
>> > > not arrive at the same estimates, that is an important thing.
>> > > >
>> > > > Once we agree upon computation, we can argue about interpretation.
>> > > Charles Determan is inquiring as to computational accuracy. The use and
>> > > interpretation of the various Type I, II, III, IV, LVX SS are
>> secondary.
>> > > >
>> > > > -----Original Message-----
>> > > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
>> > > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
>> > > > Sent: Thursday, January 26, 2012 9:03 AM
>> > > > To: r-sig-mixed-models at r-project.org
>> > > > Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
>> > Procedure
>> > > in R
>> > > >
>> > > > I think:
>> > > >
>> > > > http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
>> > > >
>> > > > HTH
>> > > > Luca
>> > > >
>> > > >
>> > > >
>> > > > Le 26/01/2012 15:52, Thompson,Paul a ?crit :
>> > > >> I am unfamiliar with this critique of Type III SS. Can you point me
>> to
>> > > a reference discussing the difficulties with Type III SS?
>> > > >>
>> > > >> -----Original Message-----
>> > > >> From: r-sig-mixed-models-bounces at r-project.org [mailto:
>> > > r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
>> > > >> Sent: Wednesday, January 25, 2012 11:19 PM
>> > > >> To: David Duffy
>> > > >> Cc: r-sig-mixed-models at r-project.org
>> > > >> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
>> > > Procedure in R
>> > > >>
>> > > >> It is well to note that type III sums of squares are problematic.
>> > > >> For testing the effects of a main effect, the null model is
>> > constraining
>> > > >> the main effect in a manner that depends on the parameterisation.
>> > > >>
>> > > >> There are situations where it makes sense to fit interactions
>> without
>> > > >> main effects, and it is clear what constraint on the main effect is
>> > the
>> > > >> relevant null (with an interaction between a factor and a variable,
>> > > >> does one want all lines to go though the same point, or through
>> > > >> perhaps the origin?), but that situation is unusual. ?For lines that
>> > > >> are separate or all through the one point, one does not need
>> > > >> type III sums of squares.
>> > > >>
>> > > >> Analyses often or frequently have enough genuine complications
>> > > >> worrying (unless it is blindingly obvious that one ought to worry
>> > > >> about it) without the rarely relevant complication of attending to a
>> > > >> type III sum of squares.
>> > > >>
>> > > >> I'd guess that SAS and lme are, effectively, making different
>> > > >> assumptions about the intended generalisation. ?They are
>> > > >> clearly using different denominator degrees of freedom for F.
>> > > >> As one is looking for consistency across the 27 different youths,
>> > > >> SAS's denominator degrees of freedom for the interaction seem
>> > > >> more or less right, pretty much equivalent to calculating slopes
>> > > >> for females and slopes for males and using a t-test to compare
>> > > >> them. ?(Sure, in the analyses presented, age has been treated
>> > > >> as a categorical variable, but the comment still applies.)
>> > > >>
>> > > >> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>> > > >> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>> > > >> Centre for Mathematics& ?Its Applications, Room 1194,
>> > > >> John Dedman Mathematical Sciences Building (Building 27)
>> > > >> Australian National University, Canberra ACT 0200.
>> > > >> http://www.maths.anu.edu.au/~johnm
>> > > >>
>> > > >> On 26/01/2012, at 1:54 PM, David Duffy wrote:
>> > > >>
>> > > >>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
>> > > >>>
>> > > >>>> Greetings,
>> > > >>>>
>> > > >>>> I have been working on R for some time now and I have begun the
>> > > endeavor of
>> > > >>>> trying to replicate some SAS code in R. ?I have scoured the forums
>> > but
>> > > >>>>
>> > > >>> This is also the Orthodont dataset, distributed with nlme.
>> > > >>>
>> > > >>> As David Atkins pointed out, R defaults to Type I SS. so you would
>> > > need to use, for example, the Anova() command from the car package.
>> ?The
>> > > other thing is that the SAS F statistics are only approximate,
>> depending
>> > on
>> > > which covariance structure is chosen (perhaps John Maindonald or
>> someone
>> > > clever could comment), so SAS offers different possibilities for ddf eg
>> > > >>>
>> > > >>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
>> > > >>>
>> > > >>> while lme and lmer offer one or none.
>> > > >>>
>> > > >>> --
>> > > >>> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-
>> > _|\
>> > > >>> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/
>> > > *
>> > > >>> | Epidemiology Unit, Queensland Institute of Medical Research
>> \_,-
>> > ._/
>> > > >>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG
>> 4D0B994A
>> > v
>> > > >>>
>> > > >>> _______________________________________________
>> > > >>> R-sig-mixed-models at r-project.org mailing list
>> > > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > > >> _______________________________________________
>> > > >> R-sig-mixed-models at r-project.org mailing list
>> > > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > > >>
>> > > >>
>> ----------------------------------------------------------------------
>> > -
>> > > >> Confidentiality Notice: This e-mail message, including any
>> > attachments,
>> > > >> is for the sole use of the intended recipient(s) and may contain
>> > > >> privileged and confidential information. ?Any unauthorized review,
>> > use,
>> > > >> disclosure or distribution is prohibited. ?If you are not the
>> intended
>> > > >> recipient, please contact the sender by reply e-mail and destroy
>> > > >> all copies of the original message.
>> > > >>
>> > > >>
>> > > >> _______________________________________________
>> > > >> R-sig-mixed-models at r-project.org mailing list
>> > > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > > >>
>> > > >>
>> > > >>
>> > > >
>> > > > _______________________________________________
>> > > > R-sig-mixed-models at r-project.org mailing list
>> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > > >
>> > > >
>> -----------------------------------------------------------------------
>> > > > Confidentiality Notice: This e-mail message, including any
>> attachments,
>> > > > is for the sole use of the intended recipient(s) and may contain
>> > > > privileged and confidential information. ?Any unauthorized review,
>> use,
>> > > > disclosure or distribution is prohibited. ?If you are not the
>> intended
>> > > > recipient, please contact the sender by reply e-mail and destroy
>> > > > all copies of the original message.
>> > > >
>> > > >
>> > > > _______________________________________________
>> > > > R-sig-mixed-models at r-project.org mailing list
>> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> >
>> > ? ? ? [[alternative HTML version deleted]]
>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From deter088 at umn.edu  Fri Jan 27 04:18:20 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 21:18:20 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CANz9Z_KLX9J=2D9w2Jncswu9B43J8UX67cOY5i2ibQ7c-9h9FQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
	<CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
	<CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
	<CANz9Z_KLX9J=2D9w2Jncswu9B43J8UX67cOY5i2ibQ7c-9h9FQ@mail.gmail.com>
Message-ID: <CAOLJphkR2Z9koar2RknwcxG4kWCS=313H0rMEDKeLFkGCBWCAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/9725d363/attachment-0001.pl>

From kw.stat at gmail.com  Fri Jan 27 06:03:17 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 26 Jan 2012 23:03:17 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
Message-ID: <CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/75056ae5/attachment-0001.pl>

From john.maindonald at anu.edu.au  Fri Jan 27 07:10:18 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 27 Jan 2012 17:10:18 +1100
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
Message-ID: <7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>

I've twigged that "unstructured" means a variance-covariance matrix 
that ignores the time structure, i.e., each element is estimated 
separately.  One can do this in lme4, thus:

Orthodont$Age <- factor(Orthodont$age)
> orth.lmer <- lmer(distance ~ Sex*Age+((Sex*Age)|Subject), 
+ data=Orthodont)
> anova(orth.lmer)
Analysis of Variance Table
        Df Sum Sq Mean Sq F value
Sex      1  9.591  9.5905 33.9645
Age      3 34.876 11.6252 41.1703
Sex:Age  3  2.930  0.9768  3.4594

The sum of squares for the Sex*Age interaction agrees with that from SAS.
lmer() leaves the user to work out an appropriate df for the F-statistic.  One
has, in agreement with the SAS output:
> 1-pf(2.93, 3, 25)
[1] 0.05318945

The main effects SS and F's are of course not expected to agree and 
indeed, in my strong view, true SAS type III SS's are inappropriate.

I regard this R analysis however as an inelegant use of the data, with low
power.  My book with John Braun (3rd edn and if I recall correctly, 2nd)
has an analysis that I am prepared to defend that uses lmer() from lme4.
Several years ago, I placed on the web a version of the analysis that uses
 lme() from nlme:
   http://maths.anu.edu.au/~johnm/r-book/xtras/mlm-lme.pdf
I'd forgotten that it was there.

This is a list for R users.  You will not necessarily find folk here with a high
level of SAS expertise, maybe not even enough to understand what the
SAS documentation means when it uses the term "unstructured".  Charles,
I think you've done pretty well in the amount of free advice that you have
received.  I think too that Steven McKinney's point is well made.  Kevin's
interpretation of the EULA is probably more or less correct, but the 
document comes across rather more ferociously than he suggests, and it
is not a good starting point for scientific assessment of the respective 
methodologies.  Many of us have other reasons why we are not very
interested in SAS does.  The implied threat in the EULA provides, even
if we are not party to any such agreement, just one more reason why SAS
is not to any large extent in our path ahead to the future.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 27/01/2012, at 4:03 PM, Kevin Wright wrote:

> Dear Charles,
> 
> First, I hope you are not put off by the tone of some the responses in this
> email thread.  Sometimes people have strong opinions and it might come
> across aggressively.
> 
> Second, be sure to understand that reproducing a SAS analysis with lme in
> no way violates any legal agreements that SAS may have, if for no other
> reason than you never signed an agreement with SAS!  That bit in the EULA
> about decompiling and reverse engineering means that people are prohibited
> from creating a new version of PROC MIXED that does the same thing.  The
> nlme package uses different methods than SAS. E.g. different optimizers,
> even uses a log-parameterization deep in the code so that negative variance
> components cannot happen.
> 
> Third, by now you've probably figured out that PROC MIXED and lme have very
> different ideas about degrees of freedom.  Also, the loglikelihoods are on
> different scales.  For that reason, when I try to reproduce an analysis, I
> find the best way to compare is to look at the variance components.
> 
> Here is what PROC MIXED says:
> 
>    Cov Parm Estimate     Std Error       Z  Pr > |Z|
> UN(1,1)     5.41545455    1.53172185    3.54    0.0004
> UN(2,1)     2.71681818    1.09623989    2.48    0.0132
> UN(2,2)     4.18477273    1.18363247    3.54    0.0004
> UN(3,1)     3.91022727    1.41775367    2.76    0.0058
> UN(3,2)     2.92715909    1.19304751    2.45    0.0141
> UN(3,3)     6.45573864    1.82595863    3.54    0.0004
> UN(4,1)     2.71022727    1.17209851    2.31    0.0208
> UN(4,2)     3.31715909    1.12903016    2.94    0.0033
> UN(4,3)     4.13073864    1.40356157    2.94    0.0033
> UN(4,4)     4.98573864    1.41017984    3.54    0.0004
> Residual         1.00000000 .       .         .
> 
> That's our target, and here is the lme code to get us there.
> 
> library(nlme)
> orth <- as.data.frame(Orthodont)
> m1 <- gls(distance ~ Sex*age,
>          correlation=corSymm(form = ~ 1 | Subject),
>          weights = varIdent(form = ~ 1 | age),
>          data = orth)
> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
> cors*covs
> 
> Now, some explanations will surely help, so let's step through the code
> with comments.
> 
> The Orthodont data is a groupedData object, which can be helpful, but
> sometimes confusing, so coercing to a data.frame removes the formula--you
> can see it with 'formula(Orthodont)'.
> 
> orth <- as.data.frame(Orthodont)
> 
> Since there is no "random" line in the PROC MIXED code, we don't want to
> use 'lme' (also why I removed the formula from the data), but instead use
> 'gls' for generalized least squares.  The 'corSymm' part specifies a
> symmetric correlation matrix with 1 on the diagonal.  Looking at the MIXED
> parameters, the results are given a covariances, not correlations.  Note
> how the variances UN(1,1), UN(2,2,), etc are different, not constant along
> the diagonal.  We use the 'weights' statement to specify different stratum
> variances.
> 
> m1 <- gls(distance ~ Sex*age,
>          correlation=corSymm(form = ~ 1 | Subject),
>          weights = varIdent(form = ~ 1 | age),
>          data = orth)
> 
> Now we have to convert the correlations and standard deviations of lme into
> covariance parameters of MIXED.
> 
> First, extract the correlation matrix from lme.
> 
> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
> 
> Now, hard-code the stratum std deviations and square them to get
> variances.  Multiply by the square of the residual std dev.  (There's a way
> to extract all these values from the fitted model instead of hand-typing
> them, but I can't find them at the moment.)
> 
> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
> 
> Now create a matrix of variances and covariances.
> 
> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
> 
> Finally, multiply the correlations by the covariances.  Let's compare
> results:
> 
> PROC MIXED:
> 
> Row Col1 Col2 Col3 Col4
> 1 5.415 2.716 3.910 2.710
> 2 2.716 4.184 2.927 3.317
> 3 3.910 2.927 6.455 4.130
> 4 2.710 3.317 4.130 4.985
> 
> R> round(cors*covs,3)
>      [,1]  [,2]  [,3]  [,4]
> [1,] 5.425 2.709 3.841 2.715
> [2,] 2.709 4.191 2.975 3.314
> [3,] 3.841 2.975 6.263 4.133
> [4,] 2.715 3.314 4.133 4.986
> 
> In my experience, the small differences in the results are typical for
> unstructured models.
> 
> Hope this helps.
> 
> Kevin Wright
> 
> 
> On Tue, Jan 24, 2012 at 8:32 PM, Charles Determan Jr <deter088 at umn.edu>wrote:
> 
>> Greetings,
>> 
>> I have been working on R for some time now and I have begun the endeavor of
>> trying to replicate some SAS code in R.  I have scoured the forums but
>> haven't been able to find an answer.  I hope one of you could be so kind as
>> to enlighten me.
>> 
>> I am attempting to replicate a repeated measures experiment using some
>> standard data.  I have posted the SAS code and output directly from a
>> publication as well as my attempts in R to replicate it.  My main issue
>> comes with the 'unstructured' component.
>> 
>> The 'dental' dataset from 'mixedQF' package,
>> equivalent to formixed data in SAS
>> 
>>   distance age Subject    Sex
>> 1       26.0   8     M01   Male
>> 2       25.0  10     M01   Male
>> 3       29.0  12     M01   Male
>> 4       31.0  14     M01   Male
>> 5       21.5   8     M02   Male
>> 6       22.5  10     M02   Male
>> 7       23.0  12     M02   Male
>> 8       26.5  14     M02   Male
>> 9       23.0   8     M03   Male
>> 10      22.5  10     M03   Male
>> 11      24.0  12     M03   Male
>> 12      27.5  14     M03   Male
>> 13      25.5   8     M04   Male
>> 14      27.5  10     M04   Male
>> 15      26.5  12     M04   Male
>> 16      27.0  14     M04   Male
>> 17      20.0   8     M05   Male
>> 18      23.5  10     M05   Male
>> 19      22.5  12     M05   Male
>> 20      26.0  14     M05   Male
>> 21      24.5   8     M06   Male
>> 22      25.5  10     M06   Male
>> 23      27.0  12     M06   Male
>> 24      28.5  14     M06   Male
>> 25      22.0   8     M07   Male
>> 26      22.0  10     M07   Male
>> 27      24.5  12     M07   Male
>> 28      26.5  14     M07   Male
>> 29      24.0   8     M08   Male
>> 30      21.5  10     M08   Male
>> 31      24.5  12     M08   Male
>> 32      25.5  14     M08   Male
>> 33      23.0   8     M09   Male
>> 34      20.5  10     M09   Male
>> 35      31.0  12     M09   Male
>> 36      26.0  14     M09   Male
>> 37      27.5   8     M10   Male
>> 38      28.0  10     M10   Male
>> 39      31.0  12     M10   Male
>> 40      31.5  14     M10   Male
>> 41      23.0   8     M11   Male
>> 42      23.0  10     M11   Male
>> 43      23.5  12     M11   Male
>> 44      25.0  14     M11   Male
>> 45      21.5   8     M12   Male
>> 46      23.5  10     M12   Male
>> 47      24.0  12     M12   Male
>> 48      28.0  14     M12   Male
>> 49      17.0   8     M13   Male
>> 50      24.5  10     M13   Male
>> 51      26.0  12     M13   Male
>> 52      29.5  14     M13   Male
>> 53      22.5   8     M14   Male
>> 54      25.5  10     M14   Male
>> 55      25.5  12     M14   Male
>> 56      26.0  14     M14   Male
>> 57      23.0   8     M15   Male
>> 58      24.5  10     M15   Male
>> 59      26.0  12     M15   Male
>> 60      30.0  14     M15   Male
>> 61      22.0   8     M16   Male
>> 62      21.5  10     M16   Male
>> 63      23.5  12     M16   Male
>> 64      25.0  14     M16   Male
>> 65      21.0   8     F01 Female
>> 66      20.0  10     F01 Female
>> 67      21.5  12     F01 Female
>> 68      23.0  14     F01 Female
>> 69      21.0   8     F02 Female
>> 70      21.5  10     F02 Female
>> 71      24.0  12     F02 Female
>> 72      25.5  14     F02 Female
>> 73      20.5   8     F03 Female
>> 74      24.0  10     F03 Female
>> 75      24.5  12     F03 Female
>> 76      26.0  14     F03 Female
>> 77      23.5   8     F04 Female
>> 78      24.5  10     F04 Female
>> 79      25.0  12     F04 Female
>> 80      26.5  14     F04 Female
>> 81      21.5   8     F05 Female
>> 82      23.0  10     F05 Female
>> 83      22.5  12     F05 Female
>> 84      23.5  14     F05 Female
>> 85      20.0   8     F06 Female
>> 86      21.0  10     F06 Female
>> 87      21.0  12     F06 Female
>> 88      22.5  14     F06 Female
>> 89      21.5   8     F07 Female
>> 90      22.5  10     F07 Female
>> 91      23.0  12     F07 Female
>> 92      25.0  14     F07 Female
>> 93      23.0   8     F08 Female
>> 94      23.0  10     F08 Female
>> 95      23.5  12     F08 Female
>> 96      24.0  14     F08 Female
>> 97      20.0   8     F09 Female
>> 98      21.0  10     F09 Female
>> 99      22.0  12     F09 Female
>> 100     21.5  14     F09 Female
>> 101     16.5   8     F10 Female
>> 102     19.0  10     F10 Female
>> 103     19.0  12     F10 Female
>> 104     19.5  14     F10 Female
>> 105     24.5   8     F11 Female
>> 106     25.0  10     F11 Female
>> 107     28.0  12     F11 Female
>> 108     28.0  14     F11 Female
>> 
>> *Mixed modeling and fixed effect test*
>> SAS
>> proc mixed data=formixed;
>> class gender age person;
>> model y = gender|age;
>> repeated / type=cs sub=person;
>> run;
>> 
>> output of interest to me
>>         Tests of Fixed Effects
>> Source             NDF   DDF    Type III F    Pr > F
>> GENDER           1        25        9.29        0.0054
>> AGE                  3        75       35.35       0.0001
>> GENDER*AGE   3        75        2.36        0.0781
>> 
>> R (nlme package)
>> y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
>> anova(y)
>> 
>>           numDF denDF  F-value p-value
>> (Intercept)     1    75 4123.156  <.0001
>> Sex              1    25    9.292  0.0054
>> age               3    75   40.032  <.0001
>> Sex:age        3    75    2.362  0.0781
>> 
>> Now this isn't exact but it is extremely close, however when I try to
>> replicate the unstructured,
>> 
>> SAS
>> proc mixed data=formixed;
>> class gender age person;
>> model y = gender|age;
>> repeated / type=un sub=person;
>> run;
>> 
>>            Tests of Fixed Effects
>> Source          NDF DDF Type III F Pr > F
>> GENDER         1    25     9.29    0.0054
>> AGE                3    25    34.45   0.0001
>> GENDER*AGE 3    25     2.93    0.0532
>> 
>> R
>> either
>> y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
>> data=dental)
>> anova(y)
>> or
>> z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(), data=dental)
>> anova(z)
>> 
>> gives the output
>> 
>>           numDF denDF  F-value    p-value
>> (Intercept)     1    75     4052.028  <.0001
>> Sex              1    25       8.462      0.0075
>> age               3    75      39.022    <.0001
>> Sex:age        3    75       2.868      0.0421
>> 
>> What am I doing wrong to replicate the unstructured linear mixed model from
>> SAS?
>> 
>> Regards,
>> 
>> Charles
>> 
>>       [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 
> -- 
> Kevin Wright
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Gustaf.Granath at ebc.uu.se  Fri Jan 27 12:58:55 2012
From: Gustaf.Granath at ebc.uu.se (Gustaf Granath)
Date: Fri, 27 Jan 2012 12:58:55 +0100
Subject: [R-sig-ME] Problems with parametric bootstrap, glmer
Message-ID: <4F22917F.5060908@ebc.uu.se>

Hi all,
A few times a have encountered a problem when I try to perform a 
parametric bootstrap to obtain a "corrected" p-value for a fixed effect 
using glmer, like (lmer(y~x+x1+x2+(1|ran)+(1|id),data,family="poisson"). 
I can run the model without errors but when a use simulate(model) as 
response (y) I sometimes get the classic " Cholmod warning 'not positive 
definite'". Even more peculiar is that when I use refit() (e.g. as 
described in the lme4 documentation under 'simulate-mer'), then this 
happens more often compared to if I use the update() function.

So I can get a p-value based on the LR  (anova(model1,model2)) but if I 
run a parametric bootstrap (n=1000), maybe only 600-700 runs converge. 
My models are not particularly overparametrized (maximum 16 fix coef, 2 
random, N=500), random effects are not close to zero and centering data 
does not help (actually, it made it worse in some cases...?). Has anyone 
else encountered this problem? I assume that it is wrong to use the 
600-700 successful bootstrap runs to calculate a parametric bootstrap 
P-value. Any alternative ideas how to proceed?

I tried to put together test code (see below), I hope it works. It 
should show that update() works better than refit() but I wasnt able to 
reproduce that update() can fail as well (maybe I didnt run it long 
enough though).

Cheers,

Gustaf Granath (PhD student)

##############CODE
set.seed(100)
dat<-expand.grid(y=c(1:5),site=as.factor(c(1:10)),tree=c("spruce","pine"))
i=9
for (i in 0:i) {
     dat$y[(1+i*5):(5+5*i)]<- rpois(5,(5+1*i))+round(rnorm(5,0,2))
     dat$y[(51+i*5):(50+(5+5*i))]<- rpois(5,(9+1*i))+round(rnorm(5,0,2))
}
dat$cov<-rnorm(100,100,10)
dat$id<- 1:nrow(dat)

#run models
m1<-lmer(y~tree+cov+(1|site)+(1|id),dat,family="poisson")
m0<-lmer(y~cov+(1|site)+(1|id),dat,family="poisson")

#function for refit()
pboot2 <- function(m0,m1) {
     s <- simulate(m0)
     L0 <- logLik(refit(m0,s),REML=F)
     L1 <- logLik(refit(m1,s),REML=F)
     c(2*(L1-L0))
}
dist1<-replicate(10,pboot2(m0,m1))

#use update() instead (no errors now)
dist2=numeric(10)
for (i in 1:10) {
     dat$s <- simulate(m0)$sim_1
     m0.refit <-    update(m0,s~.,data=dat)
     L0 <- logLik(m0.refit,REML=F)
     m1.refit <-    update(m1,s~.,data=dat)
     L1 <- logLik(m1.refit,REML=F)
     dist2[i]<- c(2*(L1-L0))
}

#compare refit() and update()
dist1 #with refit()
dist2 #with update()



From deter088 at umn.edu  Fri Jan 27 13:02:49 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 27 Jan 2012 06:02:49 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
Message-ID: <CAOLJphnyNerUf1OR15XoAgDz7uUAawZQL4t+tNsXmss=2CmRig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120127/b326ed53/attachment-0001.pl>

From deter088 at umn.edu  Fri Jan 27 13:08:24 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 27 Jan 2012 06:08:24 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
	<7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>
Message-ID: <CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120127/ebcca832/attachment-0001.pl>

From i.m.s.white at ed.ac.uk  Fri Jan 27 14:38:46 2012
From: i.m.s.white at ed.ac.uk (i white)
Date: Fri, 27 Jan 2012 13:38:46 +0000
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>	<7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>
	<CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>
Message-ID: <4F22A8E6.9090600@ed.ac.uk>

Charles,

I guess that SAS is using the Satterthwaite formula to approximate 
denominator degrees of freedom (google 'Satterthwaite'). See Kenward and 
Roger (1997) Biometrics 53 983-997 for another approach.

Charles Determan Jr wrote:
> Thank you John, I truly appreciate all the advice I have received.  At no
> point to I feel entitled for someone to provide this for me.  I do hope
> that others may find this thread useful as well.  If I may just as one more
> question.  Is there an accepted way to calculate the degrees of freedom in
> this case to come to the value of 25?  This has been something I have been
> trying to determine.
> 
> Again, thank you to all for providing me with all the information you have,
> 
> Charles
> 
> On Fri, Jan 27, 2012 at 12:10 AM, John Maindonald <
> john.maindonald at anu.edu.au> wrote:
> 
>> I've twigged that "unstructured" means a variance-covariance matrix
>> that ignores the time structure, i.e., each element is estimated
>> separately.  One can do this in lme4, thus:
>>
>> Orthodont$Age <- factor(Orthodont$age)
>>> orth.lmer <- lmer(distance ~ Sex*Age+((Sex*Age)|Subject),
>> + data=Orthodont)
>>> anova(orth.lmer)
>> Analysis of Variance Table
>>        Df Sum Sq Mean Sq F value
>> Sex      1  9.591  9.5905 33.9645
>> Age      3 34.876 11.6252 41.1703
>> Sex:Age  3  2.930  0.9768  3.4594
>>
>> The sum of squares for the Sex*Age interaction agrees with that from SAS.
>> lmer() leaves the user to work out an appropriate df for the F-statistic.
>>  One
>> has, in agreement with the SAS output:
>>> 1-pf(2.93, 3, 25)
>> [1] 0.05318945
>>
>> The main effects SS and F's are of course not expected to agree and
>> indeed, in my strong view, true SAS type III SS's are inappropriate.
>>
>> I regard this R analysis however as an inelegant use of the data, with low
>> power.  My book with John Braun (3rd edn and if I recall correctly, 2nd)
>> has an analysis that I am prepared to defend that uses lmer() from lme4.
>> Several years ago, I placed on the web a version of the analysis that uses
>>  lme() from nlme:
>>   http://maths.anu.edu.au/~johnm/r-book/xtras/mlm-lme.pdf
>> I'd forgotten that it was there.
>>
>> This is a list for R users.  You will not necessarily find folk here with
>> a high
>> level of SAS expertise, maybe not even enough to understand what the
>> SAS documentation means when it uses the term "unstructured".  Charles,
>> I think you've done pretty well in the amount of free advice that you have
>> received.  I think too that Steven McKinney's point is well made.  Kevin's
>> interpretation of the EULA is probably more or less correct, but the
>> document comes across rather more ferociously than he suggests, and it
>> is not a good starting point for scientific assessment of the respective
>> methodologies.  Many of us have other reasons why we are not very
>> interested in SAS does.  The implied threat in the EULA provides, even
>> if we are not party to any such agreement, just one more reason why SAS
>> is not to any large extent in our path ahead to the future.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> On 27/01/2012, at 4:03 PM, Kevin Wright wrote:
>>
>>> Dear Charles,
>>>
>>> First, I hope you are not put off by the tone of some the responses in
>> this
>>> email thread.  Sometimes people have strong opinions and it might come
>>> across aggressively.
>>>
>>> Second, be sure to understand that reproducing a SAS analysis with lme in
>>> no way violates any legal agreements that SAS may have, if for no other
>>> reason than you never signed an agreement with SAS!  That bit in the EULA
>>> about decompiling and reverse engineering means that people are
>> prohibited
>>> from creating a new version of PROC MIXED that does the same thing.  The
>>> nlme package uses different methods than SAS. E.g. different optimizers,
>>> even uses a log-parameterization deep in the code so that negative
>> variance
>>> components cannot happen.
>>>
>>> Third, by now you've probably figured out that PROC MIXED and lme have
>> very
>>> different ideas about degrees of freedom.  Also, the loglikelihoods are
>> on
>>> different scales.  For that reason, when I try to reproduce an analysis,
>> I
>>> find the best way to compare is to look at the variance components.
>>>
>>> Here is what PROC MIXED says:
>>>
>>>    Cov Parm Estimate     Std Error       Z  Pr > |Z|
>>> UN(1,1)     5.41545455    1.53172185    3.54    0.0004
>>> UN(2,1)     2.71681818    1.09623989    2.48    0.0132
>>> UN(2,2)     4.18477273    1.18363247    3.54    0.0004
>>> UN(3,1)     3.91022727    1.41775367    2.76    0.0058
>>> UN(3,2)     2.92715909    1.19304751    2.45    0.0141
>>> UN(3,3)     6.45573864    1.82595863    3.54    0.0004
>>> UN(4,1)     2.71022727    1.17209851    2.31    0.0208
>>> UN(4,2)     3.31715909    1.12903016    2.94    0.0033
>>> UN(4,3)     4.13073864    1.40356157    2.94    0.0033
>>> UN(4,4)     4.98573864    1.41017984    3.54    0.0004
>>> Residual         1.00000000 .       .         .
>>>
>>> That's our target, and here is the lme code to get us there.
>>>
>>> library(nlme)
>>> orth <- as.data.frame(Orthodont)
>>> m1 <- gls(distance ~ Sex*age,
>>>          correlation=corSymm(form = ~ 1 | Subject),
>>>          weights = varIdent(form = ~ 1 | age),
>>>          data = orth)
>>> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
>>> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
>>> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
>>> cors*covs
>>>
>>> Now, some explanations will surely help, so let's step through the code
>>> with comments.
>>>
>>> The Orthodont data is a groupedData object, which can be helpful, but
>>> sometimes confusing, so coercing to a data.frame removes the formula--you
>>> can see it with 'formula(Orthodont)'.
>>>
>>> orth <- as.data.frame(Orthodont)
>>>
>>> Since there is no "random" line in the PROC MIXED code, we don't want to
>>> use 'lme' (also why I removed the formula from the data), but instead use
>>> 'gls' for generalized least squares.  The 'corSymm' part specifies a
>>> symmetric correlation matrix with 1 on the diagonal.  Looking at the
>> MIXED
>>> parameters, the results are given a covariances, not correlations.  Note
>>> how the variances UN(1,1), UN(2,2,), etc are different, not constant
>> along
>>> the diagonal.  We use the 'weights' statement to specify different
>> stratum
>>> variances.
>>>
>>> m1 <- gls(distance ~ Sex*age,
>>>          correlation=corSymm(form = ~ 1 | Subject),
>>>          weights = varIdent(form = ~ 1 | age),
>>>          data = orth)
>>>
>>> Now we have to convert the correlations and standard deviations of lme
>> into
>>> covariance parameters of MIXED.
>>>
>>> First, extract the correlation matrix from lme.
>>>
>>> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
>>>
>>> Now, hard-code the stratum std deviations and square them to get
>>> variances.  Multiply by the square of the residual std dev.  (There's a
>> way
>>> to extract all these values from the fitted model instead of hand-typing
>>> them, but I can't find them at the moment.)
>>>
>>> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
>>>
>>> Now create a matrix of variances and covariances.
>>>
>>> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
>>>
>>> Finally, multiply the correlations by the covariances.  Let's compare
>>> results:
>>>
>>> PROC MIXED:
>>>
>>> Row Col1 Col2 Col3 Col4
>>> 1 5.415 2.716 3.910 2.710
>>> 2 2.716 4.184 2.927 3.317
>>> 3 3.910 2.927 6.455 4.130
>>> 4 2.710 3.317 4.130 4.985
>>>
>>> R> round(cors*covs,3)
>>>      [,1]  [,2]  [,3]  [,4]
>>> [1,] 5.425 2.709 3.841 2.715
>>> [2,] 2.709 4.191 2.975 3.314
>>> [3,] 3.841 2.975 6.263 4.133
>>> [4,] 2.715 3.314 4.133 4.986
>>>
>>> In my experience, the small differences in the results are typical for
>>> unstructured models.
>>>
>>> Hope this helps.
>>>
>>> Kevin Wright
>>>
>>>
>>> On Tue, Jan 24, 2012 at 8:32 PM, Charles Determan Jr <deter088 at umn.edu
>>> wrote:
>>>
>>>> Greetings,
>>>>
>>>> I have been working on R for some time now and I have begun the
>> endeavor of
>>>> trying to replicate some SAS code in R.  I have scoured the forums but
>>>> haven't been able to find an answer.  I hope one of you could be so
>> kind as
>>>> to enlighten me.
>>>>
>>>> I am attempting to replicate a repeated measures experiment using some
>>>> standard data.  I have posted the SAS code and output directly from a
>>>> publication as well as my attempts in R to replicate it.  My main issue
>>>> comes with the 'unstructured' component.
>>>>
>>>> The 'dental' dataset from 'mixedQF' package,
>>>> equivalent to formixed data in SAS
>>>>
>>>>   distance age Subject    Sex
>>>> 1       26.0   8     M01   Male
>>>> 2       25.0  10     M01   Male
>>>> 3       29.0  12     M01   Male
>>>> 4       31.0  14     M01   Male
>>>> 5       21.5   8     M02   Male
>>>> 6       22.5  10     M02   Male
>>>> 7       23.0  12     M02   Male
>>>> 8       26.5  14     M02   Male
>>>> 9       23.0   8     M03   Male
>>>> 10      22.5  10     M03   Male
>>>> 11      24.0  12     M03   Male
>>>> 12      27.5  14     M03   Male
>>>> 13      25.5   8     M04   Male
>>>> 14      27.5  10     M04   Male
>>>> 15      26.5  12     M04   Male
>>>> 16      27.0  14     M04   Male
>>>> 17      20.0   8     M05   Male
>>>> 18      23.5  10     M05   Male
>>>> 19      22.5  12     M05   Male
>>>> 20      26.0  14     M05   Male
>>>> 21      24.5   8     M06   Male
>>>> 22      25.5  10     M06   Male
>>>> 23      27.0  12     M06   Male
>>>> 24      28.5  14     M06   Male
>>>> 25      22.0   8     M07   Male
>>>> 26      22.0  10     M07   Male
>>>> 27      24.5  12     M07   Male
>>>> 28      26.5  14     M07   Male
>>>> 29      24.0   8     M08   Male
>>>> 30      21.5  10     M08   Male
>>>> 31      24.5  12     M08   Male
>>>> 32      25.5  14     M08   Male
>>>> 33      23.0   8     M09   Male
>>>> 34      20.5  10     M09   Male
>>>> 35      31.0  12     M09   Male
>>>> 36      26.0  14     M09   Male
>>>> 37      27.5   8     M10   Male
>>>> 38      28.0  10     M10   Male
>>>> 39      31.0  12     M10   Male
>>>> 40      31.5  14     M10   Male
>>>> 41      23.0   8     M11   Male
>>>> 42      23.0  10     M11   Male
>>>> 43      23.5  12     M11   Male
>>>> 44      25.0  14     M11   Male
>>>> 45      21.5   8     M12   Male
>>>> 46      23.5  10     M12   Male
>>>> 47      24.0  12     M12   Male
>>>> 48      28.0  14     M12   Male
>>>> 49      17.0   8     M13   Male
>>>> 50      24.5  10     M13   Male
>>>> 51      26.0  12     M13   Male
>>>> 52      29.5  14     M13   Male
>>>> 53      22.5   8     M14   Male
>>>> 54      25.5  10     M14   Male
>>>> 55      25.5  12     M14   Male
>>>> 56      26.0  14     M14   Male
>>>> 57      23.0   8     M15   Male
>>>> 58      24.5  10     M15   Male
>>>> 59      26.0  12     M15   Male
>>>> 60      30.0  14     M15   Male
>>>> 61      22.0   8     M16   Male
>>>> 62      21.5  10     M16   Male
>>>> 63      23.5  12     M16   Male
>>>> 64      25.0  14     M16   Male
>>>> 65      21.0   8     F01 Female
>>>> 66      20.0  10     F01 Female
>>>> 67      21.5  12     F01 Female
>>>> 68      23.0  14     F01 Female
>>>> 69      21.0   8     F02 Female
>>>> 70      21.5  10     F02 Female
>>>> 71      24.0  12     F02 Female
>>>> 72      25.5  14     F02 Female
>>>> 73      20.5   8     F03 Female
>>>> 74      24.0  10     F03 Female
>>>> 75      24.5  12     F03 Female
>>>> 76      26.0  14     F03 Female
>>>> 77      23.5   8     F04 Female
>>>> 78      24.5  10     F04 Female
>>>> 79      25.0  12     F04 Female
>>>> 80      26.5  14     F04 Female
>>>> 81      21.5   8     F05 Female
>>>> 82      23.0  10     F05 Female
>>>> 83      22.5  12     F05 Female
>>>> 84      23.5  14     F05 Female
>>>> 85      20.0   8     F06 Female
>>>> 86      21.0  10     F06 Female
>>>> 87      21.0  12     F06 Female
>>>> 88      22.5  14     F06 Female
>>>> 89      21.5   8     F07 Female
>>>> 90      22.5  10     F07 Female
>>>> 91      23.0  12     F07 Female
>>>> 92      25.0  14     F07 Female
>>>> 93      23.0   8     F08 Female
>>>> 94      23.0  10     F08 Female
>>>> 95      23.5  12     F08 Female
>>>> 96      24.0  14     F08 Female
>>>> 97      20.0   8     F09 Female
>>>> 98      21.0  10     F09 Female
>>>> 99      22.0  12     F09 Female
>>>> 100     21.5  14     F09 Female
>>>> 101     16.5   8     F10 Female
>>>> 102     19.0  10     F10 Female
>>>> 103     19.0  12     F10 Female
>>>> 104     19.5  14     F10 Female
>>>> 105     24.5   8     F11 Female
>>>> 106     25.0  10     F11 Female
>>>> 107     28.0  12     F11 Female
>>>> 108     28.0  14     F11 Female
>>>>
>>>> *Mixed modeling and fixed effect test*
>>>> SAS
>>>> proc mixed data=formixed;
>>>> class gender age person;
>>>> model y = gender|age;
>>>> repeated / type=cs sub=person;
>>>> run;
>>>>
>>>> output of interest to me
>>>>         Tests of Fixed Effects
>>>> Source             NDF   DDF    Type III F    Pr > F
>>>> GENDER           1        25        9.29        0.0054
>>>> AGE                  3        75       35.35       0.0001
>>>> GENDER*AGE   3        75        2.36        0.0781
>>>>
>>>> R (nlme package)
>>>> y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
>>>> anova(y)
>>>>
>>>>           numDF denDF  F-value p-value
>>>> (Intercept)     1    75 4123.156  <.0001
>>>> Sex              1    25    9.292  0.0054
>>>> age               3    75   40.032  <.0001
>>>> Sex:age        3    75    2.362  0.0781
>>>>
>>>> Now this isn't exact but it is extremely close, however when I try to
>>>> replicate the unstructured,
>>>>
>>>> SAS
>>>> proc mixed data=formixed;
>>>> class gender age person;
>>>> model y = gender|age;
>>>> repeated / type=un sub=person;
>>>> run;
>>>>
>>>>            Tests of Fixed Effects
>>>> Source          NDF DDF Type III F Pr > F
>>>> GENDER         1    25     9.29    0.0054
>>>> AGE                3    25    34.45   0.0001
>>>> GENDER*AGE 3    25     2.93    0.0532
>>>>
>>>> R
>>>> either
>>>> y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
>>>> data=dental)
>>>> anova(y)
>>>> or
>>>> z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(),
>> data=dental)
>>>> anova(z)
>>>>
>>>> gives the output
>>>>
>>>>           numDF denDF  F-value    p-value
>>>> (Intercept)     1    75     4052.028  <.0001
>>>> Sex              1    25       8.462      0.0075
>>>> age               3    75      39.022    <.0001
>>>> Sex:age        3    75       2.868      0.0421
>>>>
>>>> What am I doing wrong to replicate the unstructured linear mixed model
>> from
>>>> SAS?
>>>>
>>>> Regards,
>>>>
>>>> Charles
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>> Kevin Wright
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From kmancuso88 at gmail.com  Fri Jan 27 02:11:22 2012
From: kmancuso88 at gmail.com (Kristen Mancuso)
Date: Thu, 26 Jan 2012 20:11:22 -0500
Subject: [R-sig-ME] checking overdispersion when modelling proportions
Message-ID: <CA+Z8Yv+_suX-_RPLLjW3U00JxXj19f43m-GjbM2T8pFm991gyw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/7319db7c/attachment-0001.pl>

From pierces1 at msu.edu  Fri Jan 27 17:31:34 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Fri, 27 Jan 2012 11:31:34 -0500
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>	<7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>
	<CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>
Message-ID: <004b01ccdd11$22836240$678a26c0$@msu.edu>

It seems to me that the SAS documentation ought to tell you what algorithm
it uses to compute the degrees of freedom. Perhaps they do that by
referencing a published paper. If so, just read the original source to get
the relevant formulas. The only reliable way to get the same DF that SAS
provides is to use the same formula for calculating it. There may or may not
be existing R code that implements the required formulas, but you need to
know what you're looking for in order to find it. 

Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 


-----Original Message-----
From: Charles Determan Jr [mailto:deter088 at umn.edu] 
Sent: Friday, January 27, 2012 7:08 AM
To: John Maindonald
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in
R

Thank you John, I truly appreciate all the advice I have received.  At no
point to I feel entitled for someone to provide this for me.  I do hope
that others may find this thread useful as well.  If I may just as one more
question.  Is there an accepted way to calculate the degrees of freedom in
this case to come to the value of 25?  This has been something I have been
trying to determine.

Again, thank you to all for providing me with all the information you have,

Charles



From juliet.hannah at gmail.com  Fri Jan 27 20:00:39 2012
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Fri, 27 Jan 2012 14:00:39 -0500
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
Message-ID: <CALzuZRTz9PVQz2Fa9XCrAqLwaD6-mtadHAa2rOGr1v12myz9+A@mail.gmail.com>

My post may be redundant, but just in case I wanted to comment.  I
think Kevin's post
addressed a few things that are helpful to start with.

The original proc mixed syntax did not have a random statement. This
is similar to what
Pinheiro and Bates (Chapter 5) describe as an extended linear model.
Therefore, it seems we should not be able
to reproduce this with  lme and nlme. Instead, we use gls. I think
some people do not like to call this
a mixed effect model because the intercept or slope are not random,
but I can see why SAS would include
it with proc mixed because of the similarities. The SAS reference for
this is Littell (SAS for mixed models) Chapter 5.

proc mixed data=formixed;
class gender person;
model y = gender|age/solution;
repeated / type=un sub=person;
run;

gives me a similar result to

 gls( y ~ gender + age + gender*age , formixed, correlation =
corSymm(form = ~ 1 | person))

SAS output:

Intercept 15.84
gender 1.58
age 0.82
age*gender -.35

nlme output:

Coefficients:

(Intercept)      15.93
genderFemale      1.47
age               0.82
genderFemale:age -0.35



On Fri, Jan 27, 2012 at 12:03 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> Dear Charles,
>
> First, I hope you are not put off by the tone of some the responses in this
> email thread. ?Sometimes people have strong opinions and it might come
> across aggressively.
>
> Second, be sure to understand that reproducing a SAS analysis with lme in
> no way violates any legal agreements that SAS may have, if for no other
> reason than you never signed an agreement with SAS! ?That bit in the EULA
> about decompiling and reverse engineering means that people are prohibited
> from creating a new version of PROC MIXED that does the same thing. ?The
> nlme package uses different methods than SAS. E.g. different optimizers,
> even uses a log-parameterization deep in the code so that negative variance
> components cannot happen.
>
> Third, by now you've probably figured out that PROC MIXED and lme have very
> different ideas about degrees of freedom. ?Also, the loglikelihoods are on
> different scales. ?For that reason, when I try to reproduce an analysis, I
> find the best way to compare is to look at the variance components.
>
> Here is what PROC MIXED says:
>
> ? ?Cov Parm Estimate ? ? Std Error ? ? ? Z ?Pr > |Z|
> UN(1,1) ? ? 5.41545455 ? ?1.53172185 ? ?3.54 ? ?0.0004
> UN(2,1) ? ? 2.71681818 ? ?1.09623989 ? ?2.48 ? ?0.0132
> UN(2,2) ? ? 4.18477273 ? ?1.18363247 ? ?3.54 ? ?0.0004
> UN(3,1) ? ? 3.91022727 ? ?1.41775367 ? ?2.76 ? ?0.0058
> UN(3,2) ? ? 2.92715909 ? ?1.19304751 ? ?2.45 ? ?0.0141
> UN(3,3) ? ? 6.45573864 ? ?1.82595863 ? ?3.54 ? ?0.0004
> UN(4,1) ? ? 2.71022727 ? ?1.17209851 ? ?2.31 ? ?0.0208
> UN(4,2) ? ? 3.31715909 ? ?1.12903016 ? ?2.94 ? ?0.0033
> UN(4,3) ? ? 4.13073864 ? ?1.40356157 ? ?2.94 ? ?0.0033
> UN(4,4) ? ? 4.98573864 ? ?1.41017984 ? ?3.54 ? ?0.0004
> Residual ? ? ? ? 1.00000000 . ? ? ? . ? ? ? ? .
>
> That's our target, and here is the lme code to get us there.
>
> library(nlme)
> orth <- as.data.frame(Orthodont)
> m1 <- gls(distance ~ Sex*age,
> ? ? ? ? ?correlation=corSymm(form = ~ 1 | Subject),
> ? ? ? ? ?weights = varIdent(form = ~ 1 | age),
> ? ? ? ? ?data = orth)
> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
> cors*covs
>
> Now, some explanations will surely help, so let's step through the code
> with comments.
>
> The Orthodont data is a groupedData object, which can be helpful, but
> sometimes confusing, so coercing to a data.frame removes the formula--you
> can see it with 'formula(Orthodont)'.
>
> orth <- as.data.frame(Orthodont)
>
> Since there is no "random" line in the PROC MIXED code, we don't want to
> use 'lme' (also why I removed the formula from the data), but instead use
> 'gls' for generalized least squares. ?The 'corSymm' part specifies a
> symmetric correlation matrix with 1 on the diagonal. ?Looking at the MIXED
> parameters, the results are given a covariances, not correlations. ?Note
> how the variances UN(1,1), UN(2,2,), etc are different, not constant along
> the diagonal. ?We use the 'weights' statement to specify different stratum
> variances.
>
> m1 <- gls(distance ~ Sex*age,
> ? ? ? ? ?correlation=corSymm(form = ~ 1 | Subject),
> ? ? ? ? ?weights = varIdent(form = ~ 1 | age),
> ? ? ? ? ?data = orth)
>
> Now we have to convert the correlations and standard deviations of lme into
> covariance parameters of MIXED.
>
> First, extract the correlation matrix from lme.
>
> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
>
> Now, hard-code the stratum std deviations and square them to get
> variances. ?Multiply by the square of the residual std dev. ?(There's a way
> to extract all these values from the fitted model instead of hand-typing
> them, but I can't find them at the moment.)
>
> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
>
> Now create a matrix of variances and covariances.
>
> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
>
> Finally, multiply the correlations by the covariances. ?Let's compare
> results:
>
> PROC MIXED:
>
> Row Col1 Col2 Col3 Col4
> 1 5.415 2.716 3.910 2.710
> 2 2.716 4.184 2.927 3.317
> 3 3.910 2.927 6.455 4.130
> 4 2.710 3.317 4.130 4.985
>
> R> round(cors*covs,3)
> ? ? ?[,1] ?[,2] ?[,3] ?[,4]
> [1,] 5.425 2.709 3.841 2.715
> [2,] 2.709 4.191 2.975 3.314
> [3,] 3.841 2.975 6.263 4.133
> [4,] 2.715 3.314 4.133 4.986
>
> In my experience, the small differences in the results are typical for
> unstructured models.
>
> Hope this helps.
>
> Kevin Wright
>
>
> On Tue, Jan 24, 2012 at 8:32 PM, Charles Determan Jr <deter088 at umn.edu>wrote:
>
>> Greetings,
>>
>> I have been working on R for some time now and I have begun the endeavor of
>> trying to replicate some SAS code in R. ?I have scoured the forums but
>> haven't been able to find an answer. ?I hope one of you could be so kind as
>> to enlighten me.
>>
>> I am attempting to replicate a repeated measures experiment using some
>> standard data. ?I have posted the SAS code and output directly from a
>> publication as well as my attempts in R to replicate it. ?My main issue
>> comes with the 'unstructured' component.
>>
>> The 'dental' dataset from 'mixedQF' package,
>> equivalent to formixed data in SAS
>>
>> ? ?distance age Subject ? ?Sex
>> 1 ? ? ? 26.0 ? 8 ? ? M01 ? Male
>> 2 ? ? ? 25.0 ?10 ? ? M01 ? Male
>> 3 ? ? ? 29.0 ?12 ? ? M01 ? Male
>> 4 ? ? ? 31.0 ?14 ? ? M01 ? Male
>> 5 ? ? ? 21.5 ? 8 ? ? M02 ? Male
>> 6 ? ? ? 22.5 ?10 ? ? M02 ? Male
>> 7 ? ? ? 23.0 ?12 ? ? M02 ? Male
>> 8 ? ? ? 26.5 ?14 ? ? M02 ? Male
>> 9 ? ? ? 23.0 ? 8 ? ? M03 ? Male
>> 10 ? ? ?22.5 ?10 ? ? M03 ? Male
>> 11 ? ? ?24.0 ?12 ? ? M03 ? Male
>> 12 ? ? ?27.5 ?14 ? ? M03 ? Male
>> 13 ? ? ?25.5 ? 8 ? ? M04 ? Male
>> 14 ? ? ?27.5 ?10 ? ? M04 ? Male
>> 15 ? ? ?26.5 ?12 ? ? M04 ? Male
>> 16 ? ? ?27.0 ?14 ? ? M04 ? Male
>> 17 ? ? ?20.0 ? 8 ? ? M05 ? Male
>> 18 ? ? ?23.5 ?10 ? ? M05 ? Male
>> 19 ? ? ?22.5 ?12 ? ? M05 ? Male
>> 20 ? ? ?26.0 ?14 ? ? M05 ? Male
>> 21 ? ? ?24.5 ? 8 ? ? M06 ? Male
>> 22 ? ? ?25.5 ?10 ? ? M06 ? Male
>> 23 ? ? ?27.0 ?12 ? ? M06 ? Male
>> 24 ? ? ?28.5 ?14 ? ? M06 ? Male
>> 25 ? ? ?22.0 ? 8 ? ? M07 ? Male
>> 26 ? ? ?22.0 ?10 ? ? M07 ? Male
>> 27 ? ? ?24.5 ?12 ? ? M07 ? Male
>> 28 ? ? ?26.5 ?14 ? ? M07 ? Male
>> 29 ? ? ?24.0 ? 8 ? ? M08 ? Male
>> 30 ? ? ?21.5 ?10 ? ? M08 ? Male
>> 31 ? ? ?24.5 ?12 ? ? M08 ? Male
>> 32 ? ? ?25.5 ?14 ? ? M08 ? Male
>> 33 ? ? ?23.0 ? 8 ? ? M09 ? Male
>> 34 ? ? ?20.5 ?10 ? ? M09 ? Male
>> 35 ? ? ?31.0 ?12 ? ? M09 ? Male
>> 36 ? ? ?26.0 ?14 ? ? M09 ? Male
>> 37 ? ? ?27.5 ? 8 ? ? M10 ? Male
>> 38 ? ? ?28.0 ?10 ? ? M10 ? Male
>> 39 ? ? ?31.0 ?12 ? ? M10 ? Male
>> 40 ? ? ?31.5 ?14 ? ? M10 ? Male
>> 41 ? ? ?23.0 ? 8 ? ? M11 ? Male
>> 42 ? ? ?23.0 ?10 ? ? M11 ? Male
>> 43 ? ? ?23.5 ?12 ? ? M11 ? Male
>> 44 ? ? ?25.0 ?14 ? ? M11 ? Male
>> 45 ? ? ?21.5 ? 8 ? ? M12 ? Male
>> 46 ? ? ?23.5 ?10 ? ? M12 ? Male
>> 47 ? ? ?24.0 ?12 ? ? M12 ? Male
>> 48 ? ? ?28.0 ?14 ? ? M12 ? Male
>> 49 ? ? ?17.0 ? 8 ? ? M13 ? Male
>> 50 ? ? ?24.5 ?10 ? ? M13 ? Male
>> 51 ? ? ?26.0 ?12 ? ? M13 ? Male
>> 52 ? ? ?29.5 ?14 ? ? M13 ? Male
>> 53 ? ? ?22.5 ? 8 ? ? M14 ? Male
>> 54 ? ? ?25.5 ?10 ? ? M14 ? Male
>> 55 ? ? ?25.5 ?12 ? ? M14 ? Male
>> 56 ? ? ?26.0 ?14 ? ? M14 ? Male
>> 57 ? ? ?23.0 ? 8 ? ? M15 ? Male
>> 58 ? ? ?24.5 ?10 ? ? M15 ? Male
>> 59 ? ? ?26.0 ?12 ? ? M15 ? Male
>> 60 ? ? ?30.0 ?14 ? ? M15 ? Male
>> 61 ? ? ?22.0 ? 8 ? ? M16 ? Male
>> 62 ? ? ?21.5 ?10 ? ? M16 ? Male
>> 63 ? ? ?23.5 ?12 ? ? M16 ? Male
>> 64 ? ? ?25.0 ?14 ? ? M16 ? Male
>> 65 ? ? ?21.0 ? 8 ? ? F01 Female
>> 66 ? ? ?20.0 ?10 ? ? F01 Female
>> 67 ? ? ?21.5 ?12 ? ? F01 Female
>> 68 ? ? ?23.0 ?14 ? ? F01 Female
>> 69 ? ? ?21.0 ? 8 ? ? F02 Female
>> 70 ? ? ?21.5 ?10 ? ? F02 Female
>> 71 ? ? ?24.0 ?12 ? ? F02 Female
>> 72 ? ? ?25.5 ?14 ? ? F02 Female
>> 73 ? ? ?20.5 ? 8 ? ? F03 Female
>> 74 ? ? ?24.0 ?10 ? ? F03 Female
>> 75 ? ? ?24.5 ?12 ? ? F03 Female
>> 76 ? ? ?26.0 ?14 ? ? F03 Female
>> 77 ? ? ?23.5 ? 8 ? ? F04 Female
>> 78 ? ? ?24.5 ?10 ? ? F04 Female
>> 79 ? ? ?25.0 ?12 ? ? F04 Female
>> 80 ? ? ?26.5 ?14 ? ? F04 Female
>> 81 ? ? ?21.5 ? 8 ? ? F05 Female
>> 82 ? ? ?23.0 ?10 ? ? F05 Female
>> 83 ? ? ?22.5 ?12 ? ? F05 Female
>> 84 ? ? ?23.5 ?14 ? ? F05 Female
>> 85 ? ? ?20.0 ? 8 ? ? F06 Female
>> 86 ? ? ?21.0 ?10 ? ? F06 Female
>> 87 ? ? ?21.0 ?12 ? ? F06 Female
>> 88 ? ? ?22.5 ?14 ? ? F06 Female
>> 89 ? ? ?21.5 ? 8 ? ? F07 Female
>> 90 ? ? ?22.5 ?10 ? ? F07 Female
>> 91 ? ? ?23.0 ?12 ? ? F07 Female
>> 92 ? ? ?25.0 ?14 ? ? F07 Female
>> 93 ? ? ?23.0 ? 8 ? ? F08 Female
>> 94 ? ? ?23.0 ?10 ? ? F08 Female
>> 95 ? ? ?23.5 ?12 ? ? F08 Female
>> 96 ? ? ?24.0 ?14 ? ? F08 Female
>> 97 ? ? ?20.0 ? 8 ? ? F09 Female
>> 98 ? ? ?21.0 ?10 ? ? F09 Female
>> 99 ? ? ?22.0 ?12 ? ? F09 Female
>> 100 ? ? 21.5 ?14 ? ? F09 Female
>> 101 ? ? 16.5 ? 8 ? ? F10 Female
>> 102 ? ? 19.0 ?10 ? ? F10 Female
>> 103 ? ? 19.0 ?12 ? ? F10 Female
>> 104 ? ? 19.5 ?14 ? ? F10 Female
>> 105 ? ? 24.5 ? 8 ? ? F11 Female
>> 106 ? ? 25.0 ?10 ? ? F11 Female
>> 107 ? ? 28.0 ?12 ? ? F11 Female
>> 108 ? ? 28.0 ?14 ? ? F11 Female
>>
>> *Mixed modeling and fixed effect test*
>> SAS
>> proc mixed data=formixed;
>> class gender age person;
>> model y = gender|age;
>> repeated / type=cs sub=person;
>> run;
>>
>> output of interest to me
>> ? ? ? ? ?Tests of Fixed Effects
>> Source ? ? ? ? ? ? NDF ? DDF ? ?Type III F ? ?Pr > F
>> GENDER ? ? ? ? ? 1 ? ? ? ?25 ? ? ? ?9.29 ? ? ? ?0.0054
>> AGE ? ? ? ? ? ? ? ? ?3 ? ? ? ?75 ? ? ? 35.35 ? ? ? 0.0001
>> GENDER*AGE ? 3 ? ? ? ?75 ? ? ? ?2.36 ? ? ? ?0.0781
>>
>> R (nlme package)
>> y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
>> anova(y)
>>
>> ? ? ? ? ? ?numDF denDF ?F-value p-value
>> (Intercept) ? ? 1 ? ?75 4123.156 ?<.0001
>> Sex ? ? ? ? ? ? ?1 ? ?25 ? ?9.292 ?0.0054
>> age ? ? ? ? ? ? ? 3 ? ?75 ? 40.032 ?<.0001
>> Sex:age ? ? ? ?3 ? ?75 ? ?2.362 ?0.0781
>>
>> Now this isn't exact but it is extremely close, however when I try to
>> replicate the unstructured,
>>
>> SAS
>> proc mixed data=formixed;
>> class gender age person;
>> model y = gender|age;
>> repeated / type=un sub=person;
>> run;
>>
>> ? ? ? ? ? ? Tests of Fixed Effects
>> Source ? ? ? ? ?NDF DDF Type III F Pr > F
>> GENDER ? ? ? ? 1 ? ?25 ? ? 9.29 ? ?0.0054
>> AGE ? ? ? ? ? ? ? ?3 ? ?25 ? ?34.45 ? 0.0001
>> GENDER*AGE 3 ? ?25 ? ? 2.93 ? ?0.0532
>>
>> R
>> either
>> y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
>> data=dental)
>> anova(y)
>> or
>> z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(), data=dental)
>> anova(z)
>>
>> gives the output
>>
>> ? ? ? ? ? ?numDF denDF ?F-value ? ?p-value
>> (Intercept) ? ? 1 ? ?75 ? ? 4052.028 ?<.0001
>> Sex ? ? ? ? ? ? ?1 ? ?25 ? ? ? 8.462 ? ? ?0.0075
>> age ? ? ? ? ? ? ? 3 ? ?75 ? ? ?39.022 ? ?<.0001
>> Sex:age ? ? ? ?3 ? ?75 ? ? ? 2.868 ? ? ?0.0421
>>
>> What am I doing wrong to replicate the unstructured linear mixed model from
>> SAS?
>>
>> Regards,
>>
>> Charles
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Kevin Wright
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Sun Jan 29 02:09:40 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 28 Jan 2012 20:09:40 -0500
Subject: [R-sig-ME] r-sig-mixed-models answer
Message-ID: <4F249C54.8000803@ufl.edu>

> Date: Thu, 26 Jan 2012 13:16:12 -0600 From: Shawn McCracken 
> <smccracken at ...> To: r-sig-mixed-models at ... Subject: [R-sig-ME] GLMM
>  distribution family model comparison using Poisson w/observation 
> level random effect Message-ID: 
> <CAE+9gVGEtv6coOG1Un=pWVKWyd2s=cZQGZv3SeCgMvvENVjbWA at ...> 
> Content-Type: text/plain
> 
> Dear R mixed model users,
> 
> I have been using package glmmADMB to run a full model and then 
> reduced model versions with the following distribution families: 
> poisson, zero-inflated poisson, poisson w/observation level random 
> effect, negative binomial, zero-inflated negative binomial, negative
>  binomial type 1, and zero-inflated negative binomial type 1. The 
> models using poisson w/observation level random effect give the best
>  fit according to AIC values but I am wondering if this is a fair 
> comparison since it has an additional random variable (observation)?

  If you look, I believe you will find that the Poisson with
observation-level random effect is counted as having the same number of
parameters as the negative binomial.  The number of parameters *should* be:

  Poisson           N
  ZIP              N+1
  Poisson w/ obs   N+1
  NB               N+1
  ZINB             N+2
  NB1              N+1
  ZINB1            N+2

I just tried running this with a relatively trivial example (intercept +
1 continuous covariate + 1 intercept-only random effect, so N=3),
and glmmADMB appears to agree with what I thought it should do:

  poiss     ZIP LNPoiss      NB    ZINB     NB1   ZINB1
      3       4       4       4       5       4       5

The particular example I ran had a true NB2 distribution with N=500, 10
blocks, intercept=1, slope=2, RE variance=1, overdispersion parameter
=1.2, and this was the AIC table:

> AICtab(mlist)
        dAIC   df
NB         0.0 4
ZINB       0.9 5
LNPoiss   43.4 4
ZINB1    104.6 5
NB1      115.4 4
ZIP     1854.7 4
poiss   4730.9 3

  This is somewhat comforting.  The only thing I find surprising here is
that LNPoiss (= lognormal Poisson = Poisson with observation-level
error) is so much worse, since it has exactly the same mean-variance
relationship as NB2.  Everything else is about as I expected.

  As Mollie hints, there are two issues with applying AIC to mixed
models (one of which also applies to ZI models): (1) boundary effects
and (2) counting number of parameters.  There's more on this on
http://glmm.wikidot.com/faq as well as in the paper Mollie cites.

=========================
Since no one has responded yet, I'll take a stab at this.

You are correct that it's not quite fair, but it's not straightforward.
I'm guessing that negative binomial is the 2nd runner up because it also
is based on a Poisson distribution with a mean that comes from a
right skewed distribution (Gamma distribution). The difference is that
by including an observation level random effect, you have somewhere
between 1 and nobs-1 parameters. I believe this gives more flexibility
than the 1 extra parameter of the negative binomial model
and ideally the model would be penalized for this, but estimating
degrees of freedom in mixed models is not straightforward (see Box 3 of
Bolker et al 2009 doi:10.1016/j.tree.2008.10.008). By running a glmmadmb
example I see that the df only counts 1 parameter for the random effect
(it's standard deviation). Approximations of df are controversial.



Mollie
>



From bbolker at gmail.com  Sun Jan 29 02:44:09 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 29 Jan 2012 01:44:09 +0000 (UTC)
Subject: [R-sig-ME] checking overdispersion when modelling proportions
References: <CA+Z8Yv+_suX-_RPLLjW3U00JxXj19f43m-GjbM2T8pFm991gyw@mail.gmail.com>
Message-ID: <loom.20120129T024258-513@post.gmane.org>

Kristen Mancuso <kmancuso88 at ...> writes:

> 
> Hi,
> 
> When looking at the R book, it suggests one should be able to check for
> overdispersion when looking at the summary output of a mixed model with
> proportional data, but I am confused about how to assess this since it does
> not give residual deviance or degrees of freedom.  Any help on this would
> be greatly appreciated!
> 
> Here is the output I receive after fitting the model:
> 
> > model<-lmer(y~ Treatment*Type + (1|Site), family=binomial)
> > summary(model)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: y ~ Treatment * Type + (1 | Site)
>    AIC   BIC logLik deviance
>  37.39 47.99 -9.694    19.39
> Random effects:
>  Groups Name        Variance  Std.Dev.
>  Site   (Intercept) 0.0023005 0.047964
> Number of obs: 24, groups: Site, 12
> 
> Fixed effects:

  I just added this to http://glmm.wikidot.com/faq -- comments welcome.
 
How can I test for overdispersion?

    with the usual caveats (e.g. see Venables and Ripley MASS p. 209), plus a
few extras ? counting degrees of freedom, etc. ? the usual procedure of
calculating the sum of squared Pearson residuals and comparing it to the
residual degrees of freedom should give at least a crude idea of overdispersion.
The following crude attempt counts each variance or covariance parameter as one
model degree of freedom and presents the sum of squared Pearson residuals, the
ratio of (SSQ residuals/rdf), the residual df, and the $$p$$-value based on the
(approximately!!) appropriate $$\chi^2$ distribution.

overdisp_fun <- function(model) {
  ## number of variance parameters in 
  ##   an n-by-n variance-covariance matrix
  vpars <- function(m) {
    nrow(m)*(nrow(m)+1)/2
  }
  model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
  (rdf <- nrow(model at frame)-model.df)
  rp <- residuals(model)
  Pearson.chisq <- sum(rp^2)
  prat <- Pearson.chisq/rdf
  pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
  c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}



From deter088 at umn.edu  Mon Jan 30 19:44:29 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 30 Jan 2012 12:44:29 -0600
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
Message-ID: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120130/97069ef9/attachment-0001.pl>

From kw.stat at gmail.com  Mon Jan 30 20:30:35 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 30 Jan 2012 13:30:35 -0600
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
In-Reply-To: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
References: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
Message-ID: <CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120130/29dede4f/attachment-0001.pl>

From Paul.Thompson at SanfordHealth.org  Mon Jan 30 20:38:59 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Mon, 30 Jan 2012 19:38:59 +0000
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
In-Reply-To: <CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>
References: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
	<CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B1E2E85@SFPCEXMBX2.sanfordhealth.org>

Another approach to the problem of interactions with missing cells would be to design specific contrasts which assess interactions in those cases, but which exclude the missing cells. To do that, you would need to define the entire experiment as a single factor situation, and write the appropriate contrasts.


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Kevin Wright
Sent: Monday, January 30, 2012 1:31 PM
To: Charles Determan Jr
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lmer on dataset with missing values 'not at random'

Charles,

You are trying to fit fixed effects for two-way and three-way interactions
when, as you have shown, there are no data for certain combinations of
those factors.  Generally, to estimate fixed-effect interactions you need
data in every cell of the interaction xtabs table.

You can start by removing the interactions from your model.  If the
interactions are of interest, you could try fitting the interactions as
random effects, but you need to understand this leads to a different model
with different interpretations and inferences...

Kevin


On Mon, Jan 30, 2012 at 12:44 PM, Charles Determan Jr <deter088 at umn.edu>wrote:

> Greetings R users,
>
> I have been trying to fit a mixed model on the following dataset.  All
> columns are factors except 'met'.  When I try to run a full model with
> lmer, I get the error 'Error in mer_finalize(ans) : Downdated X'X is not
> positive definite, 27.'  I took a quick look at the dataset and I can see
> there are 4 '0's in the survival 2 group.  This makes sense as not all
> experiments made it to the end, therefore if they didn't finish then they
> didn't have any further timepoints.  I have read about missing data at
> random but I can't find a way to run lmer on a dataset that has values
> missing 'not at random'.  Is there a way to modify the lmer statement
> without cutting out data points?
>
> My sincere thanks,
>
> x
>    time group survival subj met
> 1      1     2        1      2   1.3954
> 2      2     2        1      2   1.8063
> 3      3     2        1      2   1.3684
> 4      4     2        1      2   2.0046
> 5      5     2        1      2   1.0334
> 6      6     2        1      2   0.3644
> 7      7     2        1      2   0.4819
> 8      8     2        1      2   1.4558
> 9      9     2        1     2   0.9718
> 10     1     1        2    5   0.7771
> 11     2     1        2    5   1.2439
> 12     1     2        2    8   1.0980
> 13     2     2        2    8   0.9511
> 14     1     2        1    9   1.0534
> 15     2     2        1    9   1.7279
> 16     3     2        1    9   1.4904
> 17     4     2        1    9   1.2737
> 18     5     2        1    9   0.8929
> 19     6     2        1    9   0.5828
> 20     7     2        1    9   0.3260
> 21     8     2        1    9   1.0373
> 22     9     2        1    9   0.9624
> 23     1     2        2   10   1.1391
> 24     2     2        2   10   1.3945
> 25     3     2        2   10   0.9414
> 26     4     2        2   10   1.1152
> 27     5     2        2   10   0.8222
> 28     6     2        2   10   0.4417
> 29     7     2        2   10   0.4126
> 30     1     1        1   12   1.3024
> 31     2     1        1   12   1.1811
> 32     3     1        1   12   0.9379
> 33     4     1        1   12   1.3000
> 34     5     1        1   12   1.2977
> 35     6     1        1   12   0.4949
> 36     7     1        1   12   0.5238
> 37     8     1        1   12   1.3862
> 38     1     1        1   16   1.2259
> 39     2     1        1   16   0.8681
> 40     3     1        1   16   1.2645
> 41     4     1        1   16   0.7316
> 42     5     1        1   16   0.6648
> 43     6     1        1   16   0.9671
> 44     7     1        1   16   1.0131
> 45     8     1        1   16   1.1762
> 46     9     1        1   16   0.8776
> 47     1     2        2   18   1.1231
> 48     2     2        2   18   1.2133
> 49     3     2        2   18   1.2005
> 50     4     2        2   18   0.7198
> 51     5     2        2   18   0.6620
> 52     6     2        2   18   0.5908
> 53     7     2        2   18   0.3945
> 54     1     2        2   19   0.7852
> 55     2     2        2   19   0.6758
> 56     3     2        2   19   0.5246
> 57     4     2        2   19   0.5263
> 58     1     2        2   20   1.2284
> 59     2     2        2   20   0.7017
> 60     1     2        1   23   0.9604
> 61     2     2        1   23   0.7977
> 62     3     2        1   23   1.2267
> 63     4     2        1   23   1.3857
> 64     5     2        1   23   0.9486
> 65     6     2        1   23   0.3571
> 66     7     2        1   23   0.3134
> 67     8     2        1   23   1.9984
> 68     9     2        1   23   0.4837
> 69     1     1        1   24   1.1793
> 70     2     1        1   24   1.3883
> 71     3     1        1   24   2.1080
> 72     4     1        1   24   0.8810
> 73     5     1        1   24   0.8825
> 74     6     1        1   24   0.4124
> 75     7     1        1   24   0.5270
> 76     8     1        1   24   1.9003
> 77     9     1        1   24   1.4344
> 78     1     1        1   27   1.1905
> 79     2     1        1   27   1.1033
> 80     3     1        1   27   1.4976
> 81     4     1        1   27   1.9018
> 82     5     1        1   27   0.5815
> 83     6     1        1   27   0.4428
> 84     7     1        1   27   0.4728
> 85     8     1        1   27   1.6309
> 86     9     1        1   27   0.4054
> 87     1     1        1   28   0.9538
> 88     2     1        1   28   0.7796
> 89     3     1        1   28   1.7906
> 90     5     1        1   28   0.4715
> 91     6     1        1   28   0.4214
> 92     7     1        1   28   0.4120
> 93     8     1        1   28   1.3111
> 94     9     1        1   28   0.3677
> 95     1     1        2    1   1.3853
> 96     2     1        2    1   1.5966
> 97     3     1        2    1   1.4542
> 98     4     1        2    1   1.3084
> 99     5     1        2    1   1.2826
> 100    6     1        2    1   0.6835
> 101    7     1        2    1   0.9709
> 102    1     1        1    3   1.3175
> 103    2     1        1    3   0.7792
> 104    3     1        1    3   1.8763
> 105    5     1        1    3   1.4633
> 106    6     1        1    3   0.0735
> 107    7     1        1    3   0.5612
> 108    8     1        1    3   1.3777
> 109    9     1        1    3   0.3810
> 110    1     1        2    4   1.3486
> 111    1     1        1    6   1.2635
> 112    2     1        1    6   0.7572
> 113    3     1        1    6   1.5011
> 114    5     1        1    6   0.6873
> 115    6     1        1    6   0.3778
> 116    7     1        1    6   0.4231
> 117    8     1        1    6   1.3817
> 118    9     1        1    6   0.5850
> 119    1     2        2    7   0.7362
> 120    2     2        2    7   0.5495
> 121    3     2        2    7   0.7621
> 122    4     2        2    7   0.8421
> 123    5     2        2    7   1.0438
> 124    6     2        2    7   0.9802
> 125    7     2        2    7   0.5627
> 126    1     1        1   11   1.5575
> 127    2     1        1   11   2.1356
> 128    3     1        1   11   1.3575
> 129    4     1        1   11   1.3056
> 130    5     1        1   11   0.8144
> 131    6     1        1   11   0.5876
> 132    7     1        1   11   0.4104
> 133    9     1        1   11   0.4942
> 134    1     2        1   13   1.0046
> 135    2     2        1   13   0.8805
> 136    3     2        1   13   0.7685
> 137    4     2        1   13   0.8786
> 138    5     2        1   13   1.4249
> 139    6     2        1   13   0.5339
> 140    7     2        1   13   0.5480
> 141    8     2        1   13   2.6369
> 142    9     2        1   13   1.7159
> 143    1     2        1   14   0.7161
> 144    2     2        1   14   0.3968
> 145    3     2        1   14   0.8142
> 146    4     2        1   14   0.6140
> 147    5     2        1   14   0.6585
> 148    6     2        1   14   0.7176
> 149    7     2        1   14   0.6613
> 150    8     2        1   14   1.6494
> 151    9     2        1   14   0.3903
> 152    1     1        1   15   1.4357
> 153    2     1        1   15   1.4772
> 154    3     1        1   15   1.3156
> 155    4     1        1   15   0.9654
> 156    5     1        1   15   1.2709
> 157    6     1        1   15   0.9330
> 158    7     1        1   15   0.3515
> 159    8     1        1   15   1.6801
> 160    9     1        1   15   0.3584
> 161    1     2        2   17   0.8077
> 162    2     2        2   17   0.7560
> 163    1     1        1   21   1.1890
> 164    2     1        1   21   0.9631
> 165    3     1        1   21   0.9753
> 166    4     1        1   21   0.9519
> 167    5     1        1   21   0.6348
> 168    6     1        1   21   0.8516
> 169    7     1        1   21   0.2366
> 170    8     1        1   21   1.0440
> 171    9     1        1   21   0.5360
> 172    1     2        1   22   1.0747
> 173    2     2        1   22   0.6451
> 174    3     2        1   22   0.8408
> 175    5     2        1   22   0.8730
> 176    6     2        1   22   0.3594
> 177    7     2        1   22   0.3019
> 178    9     2        1   22   1.2053
> 179    1     2        2   25   0.4654
> 180    2     2        2   25   0.3024
> 181    3     2        2   25   0.7525
> 182    4     2        2   25   0.7808
> 183    5     2        2   25   0.6294
> 184    6     2        2   25   0.3016
> 185    7     2        2   25   0.3223
> 186    1     2        1   26   0.5363
> 187    2     2        1   26   0.2279
> 188    3     2        1   26   0.4756
> 189    4     2        1   26   0.6644
> 190    5     2        1   26   0.6631
> 191    6     2        1   26   0.3419
> 192    7     2        1   26   0.4188
> 193    8     2        1   26   0.3199
> 194    9     2        1   26   0.2889
> 195    1     1        2   29   1.2765
> 196    2     1        2   29   1.0653
> 197    3     1        2   29   1.5607
> 198    1     1        1   30   0.8641
> 199    2     1        1   30   0.9250
> 200    3     1        1   30   1.0887
> 201    4     1        1   30   0.5537
> 202    5     1        1   30   0.7930
> 203    6     1        1   30   0.3960
> 204    7     1        1   30   0.3917
> 205    8     1        1   30   1.2687
> 206    9     1        1   30   0.5328
> 207    1     2        1   31   1.0765
> 208    2     2        1   31   0.8778
> 209    3     2        1   31   0.8228
> 210    4     2        1   31   1.2017
> 211    5     2        1   31   1.1787
> 212    6     2        1   31   0.4037
> 213    7     2        1   31   0.2625
> 214    8     2        1   31   2.2690
> 215    9     2        1   31   0.4423
> 216    1     1        2   32   1.2880
> 217    2     1        2   32   0.8537
>
> ds=lmer(met~group*time*survival + (1|subj), data=x)
> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 27.
>
> xtabs(~group+time+survival, x)
> , , survival = 1
>
>     time
> group  1  2  3  4  5  6  7  8  9
>    1 11 11 11  8 11 11 11 10 10
>    2  8  8  8  7  8  8  8  7  8
>
> , , survival = 2
>
>     time
> group  1  2  3  4  5  6  7  8  9
>    1  5  4  2  1  1  1  1  0  0
>    2  8  8  5  5  4  4  4  0  0
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From deter088 at umn.edu  Mon Jan 30 20:43:10 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 30 Jan 2012 13:43:10 -0600
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1E2E85@SFPCEXMBX2.sanfordhealth.org>
References: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
	<CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E2E85@SFPCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJph=V-5P9s0xgrqqJuOfveYmJzNY04svfiVsA00oP14KEow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120130/a0e91844/attachment-0001.pl>

From m.dossena at qmul.ac.uk  Mon Jan 30 21:05:18 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Mon, 30 Jan 2012 20:05:18 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
Message-ID: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>

Dear All,

I'm having a some doubts on how to properly specify the random effect  in lmer for the following experiment:

I have 10 subject assigned to treatment A and 10 assigned to treatment B. For each subject I measured 2 variables, V1 and V2, and these measures were repeated in season A and season B.

I'm interested in assessing the effect of treatment, season and their interaction on the relationship between the two variables. 

I'm a little confused on how I have to specify the random structure.

According to the design  I identified the following random structure

(1 + V2 | treatment/subject) + (1 + V2 | season)

where the first term account for the nested design and temporal pseudorplication
and the second term for the other unmeasured variable that covary with season and could affect the within season relationship between V1 and V2

correct?

Then i performed a model selection procedure, to investigate which would be the best random structure. To do so I subsequently removed each term from the random structure, and  compared the AIC score.
From this procedure it turned out that the best random structure is:  (1 + var2 | season).

My concern here is, if subject is no longer included in the random structure, i'm no longer accounting for the pseudorplication, am I?

Is the fact that the term (1 + V2 | treatment/subject) does not improve the model fit telling that in fact there is no significant correlation between measures on the same subject?


To further explore the issue, i also analysed the following random structure:

(1 + V2 | subject) + (1 + V2 | season)

and in this case the model selection procedure identified this as the best random structure.

So here is where i got confused.
My question is how do i properly specify the random structure?

Searching for an answer to my doubt in the literature, in Crawley 2007, i came across a further way to account  for temporal pseudoreplication (in lme: random = ~ season | subject) translated in lmer would it be

(season | subject) ? 

at this stage I had to give up and ask for help.
Could anyone give me some advice? is my strategy somehow wrong?

Cheers 
matteo


From Thierry.ONKELINX at inbo.be  Tue Jan 31 13:02:22 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 31 Jan 2012 12:02:22 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
Message-ID: <AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>

Dear Matteo,

You want to know the effect of treatment and season: then you should use them as fixed effect. Here a some models

V1 ~ treatment * season + V2 + (1|subject)
V1 ~ treatment * season + V2 + (1 + V2|subject) #interaction between subject and V2
V1 ~ treatment * season + V2 + (1|subject/season) #interaction between subject and season

You way want to do some reading on mixed models. E.g. Zuur et al (2009)

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens matteo dossena
Verzonden: maandag 30 januari 2012 21:05
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] repeated measure in partially crossed design

Dear All,

I'm having a some doubts on how to properly specify the random effect  in lmer for the following experiment:

I have 10 subject assigned to treatment A and 10 assigned to treatment B. For each subject I measured 2 variables, V1 and V2, and these measures were repeated in season A and season B.

I'm interested in assessing the effect of treatment, season and their interaction on the relationship between the two variables. 

I'm a little confused on how I have to specify the random structure.

According to the design  I identified the following random structure

(1 + V2 | treatment/subject) + (1 + V2 | season)

where the first term account for the nested design and temporal pseudorplication and the second term for the other unmeasured variable that covary with season and could affect the within season relationship between V1 and V2

correct?

Then i performed a model selection procedure, to investigate which would be the best random structure. To do so I subsequently removed each term from the random structure, and  compared the AIC score.
>From this procedure it turned out that the best random structure is:  (1 + var2 | season).

My concern here is, if subject is no longer included in the random structure, i'm no longer accounting for the pseudorplication, am I?

Is the fact that the term (1 + V2 | treatment/subject) does not improve the model fit telling that in fact there is no significant correlation between measures on the same subject?


To further explore the issue, i also analysed the following random structure:

(1 + V2 | subject) + (1 + V2 | season)

and in this case the model selection procedure identified this as the best random structure.

So here is where i got confused.
My question is how do i properly specify the random structure?

Searching for an answer to my doubt in the literature, in Crawley 2007, i came across a further way to account  for temporal pseudoreplication (in lme: random = ~ season | subject) translated in lmer would it be

(season | subject) ? 

at this stage I had to give up and ask for help.
Could anyone give me some advice? is my strategy somehow wrong?

Cheers
matteo
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From natalia.vizcaino.palomar at gmail.com  Tue Jan 31 13:02:46 2012
From: natalia.vizcaino.palomar at gmail.com (=?ISO-8859-1?Q?Natalia_Vizca=EDno_Palomar?=)
Date: Tue, 31 Jan 2012 13:02:46 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
	positive definite, 9
Message-ID: <CAOh1aTwMhp8EexKATiJp81kA_+6-LyxZShkuZa-8jiN--59ONw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120131/50e23fa7/attachment-0001.pl>

From m.dossena at qmul.ac.uk  Tue Jan 31 13:43:42 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Tue, 31 Jan 2012 12:43:42 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
Message-ID: <8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>

Thierry,
thanks for the answer.
I apologize for having omitted the fixed effect from the model posted previously.

My doubts are regarding the specification of the random structure.
more specifically should i specify in the random structure that subject is nested within treatment?
Correct me if I'm wrong, but , doesn't the syntax: (1|subject/season) means season nested within subject? 

second
Having repeated measures on subject, including subject in the random effect, am I already accounting for the non independence of the residuals?
or should I also add the correlation structure?

sorry for the incompleteness of my previous post, hope this hep to clarify my question.

best regards
m.


Il giorno 31 Jan 2012, alle ore 12:02, ONKELINX, Thierry ha scritto:

> Dear Matteo,
> 
> You want to know the effect of treatment and season: then you should use them as fixed effect. Here a some models
> 
> V1 ~ treatment * season + V2 + (1|subject)
> V1 ~ treatment * season + V2 + (1 + V2|subject) #interaction between subject and V2
> V1 ~ treatment * season + V2 + (1|subject/season) #interaction between subject and season
> 
> You way want to do some reading on mixed models. E.g. Zuur et al (2009)
> 
> Best regards,
> 
> Thierry
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens matteo dossena
> Verzonden: maandag 30 januari 2012 21:05
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] repeated measure in partially crossed design
> 
> Dear All,
> 
> I'm having a some doubts on how to properly specify the random effect  in lmer for the following experiment:
> 
> I have 10 subject assigned to treatment A and 10 assigned to treatment B. For each subject I measured 2 variables, V1 and V2, and these measures were repeated in season A and season B.
> 
> I'm interested in assessing the effect of treatment, season and their interaction on the relationship between the two variables. 
> 
> I'm a little confused on how I have to specify the random structure.
> 
> According to the design  I identified the following random structure
> 
> (1 + V2 | treatment/subject) + (1 + V2 | season)
> 
> where the first term account for the nested design and temporal pseudorplication and the second term for the other unmeasured variable that covary with season and could affect the within season relationship between V1 and V2
> 
> correct?
> 
> Then i performed a model selection procedure, to investigate which would be the best random structure. To do so I subsequently removed each term from the random structure, and  compared the AIC score.
> From this procedure it turned out that the best random structure is:  (1 + var2 | season).
> 
> My concern here is, if subject is no longer included in the random structure, i'm no longer accounting for the pseudorplication, am I?
> 
> Is the fact that the term (1 + V2 | treatment/subject) does not improve the model fit telling that in fact there is no significant correlation between measures on the same subject?
> 
> 
> To further explore the issue, i also analysed the following random structure:
> 
> (1 + V2 | subject) + (1 + V2 | season)
> 
> and in this case the model selection procedure identified this as the best random structure.
> 
> So here is where i got confused.
> My question is how do i properly specify the random structure?
> 
> Searching for an answer to my doubt in the literature, in Crawley 2007, i came across a further way to account  for temporal pseudoreplication (in lme: random = ~ season | subject) translated in lmer would it be
> 
> (season | subject) ? 
> 
> at this stage I had to give up and ask for help.
> Could anyone give me some advice? is my strategy somehow wrong?
> 
> Cheers
> matteo
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From m.dossena at qmul.ac.uk  Tue Jan 31 14:58:33 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Tue, 31 Jan 2012 13:58:33 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
Message-ID: <F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120131/4124209c/attachment-0001.pl>

From deter088 at umn.edu  Tue Jan 31 16:01:17 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 31 Jan 2012 09:01:17 -0600
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
In-Reply-To: <CAOLJphkvfuD2CLwbvGUVedWWi+rpUKmxq-hgWCmLr=Tn=WCgGg@mail.gmail.com>
References: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
	<CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E2E85@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJph=V-5P9s0xgrqqJuOfveYmJzNY04svfiVsA00oP14KEow@mail.gmail.com>
	<CAKFxdiSn43NBkrAbh5CSzLuhH_TFrnfN+79E3s1-ds3HEM0YPA@mail.gmail.com>
	<CAOLJphkvfuD2CLwbvGUVedWWi+rpUKmxq-hgWCmLr=Tn=WCgGg@mail.gmail.com>
Message-ID: <CAOLJphnN0s6JqGpUYHgCzqfcyBKf2s50jQFpxVxX5_eb-6t_Cg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120131/93d3c7aa/attachment-0001.pl>

From agalecki at umich.edu  Tue Jan 31 17:43:18 2012
From: agalecki at umich.edu (Andrzej Galecki)
Date: Tue, 31 Jan 2012 11:43:18 -0500
Subject: [R-sig-ME] Book about linear mixed effects models using R
In-Reply-To: <4EC2C691.9080800@umich.edu>
References: <4EC2C691.9080800@umich.edu>
Message-ID: <4F281A26.9040401@umich.edu>

Dear Mixed Models Experts,

My colleague Tomasz Burzykowski from the Hasselt University, Belgium and 
I are in a final stage of writing a book about linear mixed effects 
models using R. The book focuses on applications of lme() function from 
nlme package, but there are some examples of using  lmer() function from 
lme4 package. Part I of the book is available at:

http://www-personal.umich.edu/~agalecki/BookPartI120131.pdf.

The book underwent two rounds of ''official'' review and selected 
portions of it have been read by some members of this list. At this 
point, we are getting ready to submit the manuscript to Springer for a 
final editorial review.

If  you are willing/be able within the next 4-6 weeks to read selected 
chapters of the manuscript, share your comments, suggestions, catch 
mistakes, omissions, make syntax more efficient, make sure we are using 
proper terminology etc please contact me directly at agalecki at umich.edu.

With warm regards,

Andrzej Galecki
University of Michigan
http://www-personal.umich.edu/~agalecki



From oneil.shawnt at gmail.com  Tue Jan 31 01:03:00 2012
From: oneil.shawnt at gmail.com (Shawn O'Neil)
Date: Mon, 30 Jan 2012 19:03:00 -0500
Subject: [R-sig-ME] setting corStruct range in a mixed effects model
Message-ID: <CAHJOu+pv_ZhsYozDwo0OUM+ak_OFZL6y31-GqoJoV0-_vnELsg@mail.gmail.com>

Hello all,

I have a question regarding the use of the available correlation structures
in package nlme.  We are using mixed effects models to relate information
from lesser scaup kernel density distributions to underlying habitat
covariates.  Based on semivariogram and correlogram examinations, we find
spatial autocorrelation between the residuals of our full linear mixed
effects model.  We have tried to follow an example given by Pinheiro &
Bates (2000, pp 262-264) where a spherical correlation structure is fitted
to a sample semivariogram by imposing a user-defined range and nugget.  We
are trying this approach in an attempt to ignore some potentially spurious
autocorrelation effects occurring at large lag distances.  However, we
cannot achieve the result that the authors do in forcing a specific range.

For example,  we run a random intercept model using all of our covariates
including a surface trend:


FormXY <- formula(logUDval ~ DEP + I(DEP^2) + log(EDGE+0.5) + H2O:SUB +
log(CATTR+0.5) + NHOT +
    I(NHOT^2) + H2O*NDENS + I(NDENS^2) + Year_ + BCIndex + Age + X_ST*Y_ST
+ I(X_ST^2) + I(Y_ST^2) + I(X_ST^3)
    + I(Y_ST^3))

m11.lme<-lme(FormXY, random = ~1 | BirdID, method = "REML", data=hrdata)

Next, we examine the sample semivariogram (Figure 1) and determine that the
range should be approximately 900 and we do not see a significant nugget
effect.  At distances > 3500, there are some odd things occurring that for
now we would like to ignore.  We are primarily concerned with modeling the
spatial autocorrelation that is evident between 0 and 900 so we try to
specify this using the spherical correlation structure (as an example).  I
had to use lmeControl to get around false convergence errors:

m11.lme.spher<-lme(FormXY, random = ~1 | BirdID, correlation =
corSpher(c(900), form = ~X_COORD + Y_COORD | BirdID), method =
"REML",       data=hrdata,
control = lmeControl(opt = c("optim")))

The model finishes but we can see by the sample semivariogram (Figure 2)
and the sample semivariogram of normalized residuals (Figure 3) that the
correlation structure did not fit the way we wanted it to.  Also, the range
in the model summary does not match the value that we put in:

> summary(m11.lme.spher)
Linear mixed-effects model fit by REML
 Data: hrdata
        AIC       BIC   logLik
  -26755.58 -26562.75 13402.79

Random effects:
 Formula: ~1 | BirdID
        (Intercept)  Residual
StdDev:   0.5524643 0.3513228

Correlation Structure: Spherical spatial correlation
 Formula: ~X_COORD + Y_COORD | BirdID
 Parameter estimate(s):
   range
1950.937

Am I making a mistake somewhere?  We have tried all the other corStructs
and also tried setting the nugget in addition to the range but we never get
to a result that models the spatial autocorrelation trend accurately at
distances 0 - 900.  Any advice is greatly appreciated!

Thank you,
Shawn

-- 
Shawn O'Neil
Research Assistant, Applied Ecology
Forest Resources and Environmental Science
Michigan Technological University
701-741-4361

From slu at ccsr.uchicago.edu  Tue Jan 31 18:51:03 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 31 Jan 2012 11:51:03 -0600
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
Message-ID: <1328032263.8250.12.camel@localhost>

Hello, I have a dataset with outcomes {1, 2, 3, 4}. The outcome variable
is actually ordered categories, but as point of reference for
comparison, I analyzed it as numeric in lmer, and got these results:

Linear mixed model fit by REML 
Formula: rating ~ comp.f + grade.f + subject.f + obsord.f + (1 | obsid)
+      (1 | tid) + (1 | grade.f) + (1 | subject.f) + (1 | obsord.f) 
   Data: ratings.prin 
  AIC  BIC logLik deviance REMLdev
 6886 7058  -3416     6740    6832
Random effects:
 Groups    Name        Variance   Std.Dev.
 tid       (Intercept) 0.19082494 0.436835
 obsid     (Intercept) 0.10405718 0.322579
 subject.f (Intercept) 0.00075553 0.027487
 grade.f   (Intercept) 0.00075435 0.027465
 obsord.f  (Intercept) 0.00060346 0.024565
 Residual              0.24073207 0.490645
Number of obs: 4253, groups: tid, 245; obsid, 94; subject.f, 5; grade.f,
5; obsord.f, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept)  3.261329   0.140592  23.197
comp.f2     -0.095729   0.033461  -2.861
comp.f3     -0.061422   0.033316  -1.844
comp.f4     -0.144613   0.033364  -4.334
comp.f5     -0.059794   0.033599  -1.780
comp.f6     -0.074454   0.033249  -2.239
comp.f7     -0.325454   0.033274  -9.781
comp.f8     -0.186724   0.033187  -5.626
comp.f9     -0.320803   0.033741  -9.508
comp.f10    -0.226328   0.034056  -6.646
grade.f2    -0.203406   0.140249  -1.450
grade.f3    -0.227049   0.134389  -1.689
grade.f4    -0.377642   0.137710  -2.742
grade.f5    -0.225643   0.140196  -1.609
subject.f2  -0.009939   0.053291  -0.187
subject.f3   0.289519   0.061324   4.721
subject.f4  -0.223719   0.107737  -2.077
subject.f5  -0.025963   0.073520  -0.353
obsord.f2    0.004840   0.038436   0.126
obsord.f3    0.112110   0.052707   2.127
obsord.f4    0.156406   0.078614   1.990

These results seem somewhat reasonable to me. But when I analyze the
very same dataset using the same model in MCMCglmm I get very different
results:

glme5 <- MCMCglmm(rating.o ~ comp.f + grade.f + subject.f + obsord.f ,
                  prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0),
G5=list(V=1, nu=0) )),
               random = ~tid + obsid + grade.f + subject.f + obsord.f ,
               family = "ordinal",
               nitt=100000,
               data = ratings.prin)


 Iterations = 3001:99991
 Thinning interval  = 10
 Sample size  = 9700 

 DIC: 5701.873 

 G-structure:  ~tid

    post.mean l-95% CI u-95% CI eff.samp
tid     2.423    1.821    3.063     2759

               ~obsid

      post.mean l-95% CI u-95% CI eff.samp
obsid     1.521   0.7707    2.331     5227

               ~grade.f

        post.mean  l-95% CI  u-95% CI eff.samp
grade.f  95365148 2.234e-17 104888830     2296

               ~subject.f

          post.mean  l-95% CI  u-95% CI eff.samp
subject.f   7.5e+07 1.502e-17 101313849     3950

               ~obsord.f

         post.mean  l-95% CI u-95% CI eff.samp
obsord.f 122278523 2.079e-17 64065615     3851

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: rating.o ~ comp.f + grade.f + subject.f + obsord.f 

             post.mean   l-95% CI   u-95% CI eff.samp    pMCMC    
(Intercept)  1.430e+02 -2.218e+04  1.781e+04    10178 0.607629    
comp.f2     -3.448e-01 -5.854e-01 -1.161e-01     6220 0.004124 ** 
comp.f3     -2.219e-01 -4.527e-01  1.402e-02     6328 0.064124 .  
comp.f4     -5.166e-01 -7.459e-01 -2.831e-01     6454 0.000206 ***
comp.f5     -2.087e-01 -4.431e-01  2.333e-02     6338 0.084536 .  
comp.f6     -2.692e-01 -5.091e-01 -4.112e-02     6290 0.024948 *  
comp.f7     -1.163e+00 -1.403e+00 -9.395e-01     4027  < 1e-04 ***
comp.f8     -6.682e-01 -9.011e-01 -4.368e-01     5448  < 1e-04 ***
comp.f9     -1.157e+00 -1.392e+00 -9.171e-01     4253  < 1e-04 ***
comp.f10    -8.167e-01 -1.056e+00 -5.742e-01     6152  < 1e-04 ***
grade.f2    -2.417e+00 -7.966e+03  8.888e+03    13314 0.396082    
grade.f3     1.304e+02 -7.486e+03  9.484e+03    10314 0.342062    
grade.f4    -1.684e+02 -9.879e+03  6.926e+03    12352 0.283711    
grade.f5     1.218e+02 -8.380e+03  7.895e+03     8740 0.351546    
subject.f2  -9.163e+01 -7.562e+03  7.806e+03    12224 0.930309    
subject.f3   1.699e+01 -7.411e+03  8.238e+03    12320 0.344536    
subject.f4   3.477e+01 -9.427e+03  7.519e+03    13106 0.372165    
subject.f5  -1.203e+02 -7.618e+03  8.837e+03     9071 0.848247    
obsord.f2   -5.860e+01 -7.058e+03  5.605e+03     9290 0.819794    
obsord.f3   -9.302e+01 -5.852e+03  5.641e+03     7386 0.332990    
obsord.f4   -1.243e+02 -6.891e+03  6.093e+03    10073 0.343299    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

 Cutpoints: 
                         post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitrating.o.1     3.309    3.101    3.517    172.5
cutpoint.traitrating.o.2     6.790    6.552    7.056    150.1


Obviously, something has gone kablooey here. The confidence intervals
for the grade, subject and obsord random effects range over 25 orders of
magnitude, and the fixed effects are also extremely large (but with
correspondingly large standard errors). The intercept is 143, while the
outcomes only range between 1 and 4. Can anyone tell me what I have
screwed up here?

TIA.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
To paraphrase provocatively, 'machine learning is
 statistics minus any checking of models and
 assumptions'.    -- Brian D. Ripley (about the
 difference between machine learning and      
 statistics)       useR! 2004, Vienna (May 2004)



From Thierry.ONKELINX at inbo.be  Tue Jan 31 20:43:47 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 31 Jan 2012 19:43:47 +0000
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
In-Reply-To: <1328032263.8250.12.camel@localhost>
References: <1328032263.8250.12.camel@localhost>
Message-ID: <AA818EAD2576BC488B4F623941DA74275733A260@inbomail.inbo.be>

Dear Stuart,

A few remarks on the model itself. You are adding 3 factors both as fixed and random effect. That is not a good idea since they will be competing for exact the same information. Hence the huge CI with the MCMC model. 

I'm a bit surprised with the lmer results as well. I would expect to see zero variances for these random effects.

Best regards,

Thierry


________________________________________
Van: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] namens Stuart Luppescu [slu at ccsr.uchicago.edu]
Verzonden: dinsdag 31 januari 2012 18:51
Aan: r-sig-mixed-models
Onderwerp: [R-sig-ME] Very different results from lmer and MCMCglmm

Hello, I have a dataset with outcomes {1, 2, 3, 4}. The outcome variable
is actually ordered categories, but as point of reference for
comparison, I analyzed it as numeric in lmer, and got these results:

Linear mixed model fit by REML
Formula: rating ~ comp.f + grade.f + subject.f + obsord.f + (1 | obsid)
+      (1 | tid) + (1 | grade.f) + (1 | subject.f) + (1 | obsord.f)
   Data: ratings.prin
  AIC  BIC logLik deviance REMLdev
 6886 7058  -3416     6740    6832
Random effects:
 Groups    Name        Variance   Std.Dev.
 tid       (Intercept) 0.19082494 0.436835
 obsid     (Intercept) 0.10405718 0.322579
 subject.f (Intercept) 0.00075553 0.027487
 grade.f   (Intercept) 0.00075435 0.027465
 obsord.f  (Intercept) 0.00060346 0.024565
 Residual              0.24073207 0.490645
Number of obs: 4253, groups: tid, 245; obsid, 94; subject.f, 5; grade.f,
5; obsord.f, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept)  3.261329   0.140592  23.197
comp.f2     -0.095729   0.033461  -2.861
comp.f3     -0.061422   0.033316  -1.844
comp.f4     -0.144613   0.033364  -4.334
comp.f5     -0.059794   0.033599  -1.780
comp.f6     -0.074454   0.033249  -2.239
comp.f7     -0.325454   0.033274  -9.781
comp.f8     -0.186724   0.033187  -5.626
comp.f9     -0.320803   0.033741  -9.508
comp.f10    -0.226328   0.034056  -6.646
grade.f2    -0.203406   0.140249  -1.450
grade.f3    -0.227049   0.134389  -1.689
grade.f4    -0.377642   0.137710  -2.742
grade.f5    -0.225643   0.140196  -1.609
subject.f2  -0.009939   0.053291  -0.187
subject.f3   0.289519   0.061324   4.721
subject.f4  -0.223719   0.107737  -2.077
subject.f5  -0.025963   0.073520  -0.353
obsord.f2    0.004840   0.038436   0.126
obsord.f3    0.112110   0.052707   2.127
obsord.f4    0.156406   0.078614   1.990

These results seem somewhat reasonable to me. But when I analyze the
very same dataset using the same model in MCMCglmm I get very different
results:

glme5 <- MCMCglmm(rating.o ~ comp.f + grade.f + subject.f + obsord.f ,
                  prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0),
G5=list(V=1, nu=0) )),
               random = ~tid + obsid + grade.f + subject.f + obsord.f ,
               family = "ordinal",
               nitt=100000,
               data = ratings.prin)


 Iterations = 3001:99991
 Thinning interval  = 10
 Sample size  = 9700

 DIC: 5701.873

 G-structure:  ~tid

    post.mean l-95% CI u-95% CI eff.samp
tid     2.423    1.821    3.063     2759

               ~obsid

      post.mean l-95% CI u-95% CI eff.samp
obsid     1.521   0.7707    2.331     5227

               ~grade.f

        post.mean  l-95% CI  u-95% CI eff.samp
grade.f  95365148 2.234e-17 104888830     2296

               ~subject.f

          post.mean  l-95% CI  u-95% CI eff.samp
subject.f   7.5e+07 1.502e-17 101313849     3950

               ~obsord.f

         post.mean  l-95% CI u-95% CI eff.samp
obsord.f 122278523 2.079e-17 64065615     3851

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: rating.o ~ comp.f + grade.f + subject.f + obsord.f

             post.mean   l-95% CI   u-95% CI eff.samp    pMCMC
(Intercept)  1.430e+02 -2.218e+04  1.781e+04    10178 0.607629
comp.f2     -3.448e-01 -5.854e-01 -1.161e-01     6220 0.004124 **
comp.f3     -2.219e-01 -4.527e-01  1.402e-02     6328 0.064124 .
comp.f4     -5.166e-01 -7.459e-01 -2.831e-01     6454 0.000206 ***
comp.f5     -2.087e-01 -4.431e-01  2.333e-02     6338 0.084536 .
comp.f6     -2.692e-01 -5.091e-01 -4.112e-02     6290 0.024948 *
comp.f7     -1.163e+00 -1.403e+00 -9.395e-01     4027  < 1e-04 ***
comp.f8     -6.682e-01 -9.011e-01 -4.368e-01     5448  < 1e-04 ***
comp.f9     -1.157e+00 -1.392e+00 -9.171e-01     4253  < 1e-04 ***
comp.f10    -8.167e-01 -1.056e+00 -5.742e-01     6152  < 1e-04 ***
grade.f2    -2.417e+00 -7.966e+03  8.888e+03    13314 0.396082
grade.f3     1.304e+02 -7.486e+03  9.484e+03    10314 0.342062
grade.f4    -1.684e+02 -9.879e+03  6.926e+03    12352 0.283711
grade.f5     1.218e+02 -8.380e+03  7.895e+03     8740 0.351546
subject.f2  -9.163e+01 -7.562e+03  7.806e+03    12224 0.930309
subject.f3   1.699e+01 -7.411e+03  8.238e+03    12320 0.344536
subject.f4   3.477e+01 -9.427e+03  7.519e+03    13106 0.372165
subject.f5  -1.203e+02 -7.618e+03  8.837e+03     9071 0.848247
obsord.f2   -5.860e+01 -7.058e+03  5.605e+03     9290 0.819794
obsord.f3   -9.302e+01 -5.852e+03  5.641e+03     7386 0.332990
obsord.f4   -1.243e+02 -6.891e+03  6.093e+03    10073 0.343299
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

 Cutpoints:
                         post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitrating.o.1     3.309    3.101    3.517    172.5
cutpoint.traitrating.o.2     6.790    6.552    7.056    150.1


Obviously, something has gone kablooey here. The confidence intervals
for the grade, subject and obsord random effects range over 25 orders of
magnitude, and the fixed effects are also extremely large (but with
correspondingly large standard errors). The intercept is 143, while the
outcomes only range between 1 and 4. Can anyone tell me what I have
screwed up here?

TIA.

--
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu
University of Chicago -=- CCSR
???????? -=-    Kernel 3.2.1-gentoo-r2
To paraphrase provocatively, 'machine learning is
 statistics minus any checking of models and
 assumptions'.    -- Brian D. Ripley (about the
 difference between machine learning and
 statistics)       useR! 2004, Vienna (May 2004)

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From slu at ccsr.uchicago.edu  Tue Jan 31 23:08:18 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 31 Jan 2012 16:08:18 -0600
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
In-Reply-To: <AA818EAD2576BC488B4F623941DA74275733A260@inbomail.inbo.be>
References: <1328032263.8250.12.camel@localhost>
	<AA818EAD2576BC488B4F623941DA74275733A260@inbomail.inbo.be>
Message-ID: <1328047698.8250.18.camel@localhost>

On Tue, 2012-01-31 at 19:43 +0000, ONKELINX, Thierry wrote:
> A few remarks on the model itself. You are adding 3 factors both as
> fixed and random effect. That is not a good idea since they will be
> competing for exact the same information. Hence the huge CI with the
> MCMC model. 

Ah, right. I reran it without the fixed effects and the results were
much better.

> I'm a bit surprised with the lmer results as well. I would expect to
> see zero variances for these random effects.

Wow. lmer is really robust!

Thanks very much for the help.
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
If I were to be treated by a cure created by
 stepwise regression, I would prefer voodoo.    -- 
 Dieter Menne (in a thread about regressions with
 many variables)       R-help (October 2009)



From David.Duffy at qimr.edu.au  Tue Jan 31 23:33:30 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 1 Feb 2012 08:33:30 +1000 (EST)
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
In-Reply-To: <1328032263.8250.12.camel@localhost>
References: <1328032263.8250.12.camel@localhost>
Message-ID: <Pine.LNX.4.64.1202010821140.13091@orpheus.qimr.edu.au>

What did you get from MCMCglmm(...family="gaussian")?

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Wed Feb  1 03:15:12 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 1 Feb 2012 02:15:12 +0000 (UTC)
Subject: [R-sig-ME] repeated measure in partially crossed design
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
	<F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>
Message-ID: <loom.20120201T030103-410@post.gmane.org>

matteo dossena <m.dossena at ...> writes:

> Dear all,
 
> sorry to write again on this topic, but i feel like I haven't make
> myself clear.  I try to rephrase my question, hope I'm not annoying
> you.  So given that each level of season - e.g. April and Oct -
> occurs at each level of subject while each level of treatment
> -e.g. high or control - only occurs on a half of the the subjects
> respectively and randomly, should I specify the random effects in
> the model as

If you really want to "... assess[] the effect of treatment, season
and their interaction on the relationship between the two variables",
you may want treatment*season*V2 as fixed effect (so you can tell whether 
the V1~V2 relationship changes with treatment and season)

  Having any *factor* included as both a fixed effect and a random
effect will cause trouble, e.g. in your model (2).  (On the other
hand, it does sometimes make sense to include a _continuous_ predictor
as both fixed (which will estimate a linear trend) and random (which
will consider variation around the linear trend -- this only makes
sense if you have multiple measurements per value of the predictor,
though.  Another apparent exception to this is subject in the
(1|treatment/subject) term, which is only included as subject nested
within treatment.
 
> (1) having subject nested within treatment and crossed with date, 
>  V1 ~ treatment * season + V2 + (1|treatment/subject) + (1|season)

  Here both treatment and season are included as both fixed and random --
probably not a good idea.

> (2) subject crossed with date ignoring the nesting with treatment,
> (3) random effects on subject only ignoring the crossed and nested
> data structure V1 ~ treatment * season + V2 + (1|subject) +
> (1|season)

  Still probably don't want season and (1|season)
> 

> (3) random effects on subject only ignoring the crossed and nested
> data structure V1 ~ treatment * season + V2 + (1|subject)

   This is not unreasonable.  You could consider (season|subject),
or (1|subject)+(0+season|subject) [which fits the intercept and slope
independently], since you have both seasons assessed for each individual.

   This gets raised a lot on this list, but: I would generally only
drop a random effect from the model if it actually appears overfitted
(i.e.  estimated as zeros, or a perfect +1/-1 correlation between
random effects), and not if it is merely non-significant (Hurlbert
calls this "sacrificial pseudoreplication").  I've been very impressed
by the results from the blme package, which incorporates a weak
Bayesian prior to push underdetermined variance components away from
zero ...



From bbolker at gmail.com  Wed Feb  1 03:17:45 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 1 Feb 2012 02:17:45 +0000 (UTC)
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de><Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
	<000301ccd698$a32bee00$e983ca00$@web.de>
	<6F35A958A12B9149BD16E3C2F3B0AD0DB37864@SPHINX.adqimr.ad.lan>
	<00ca01ccda9f$5e04f460$1a0edd20$@web.de>
Message-ID: <loom.20120201T031617-765@post.gmane.org>

Martin Schmettow <schmettow at ...> writes:

> 
> Thank you for your ideas. 
> 
> You seem to suggest that I use a C-R model to estimate the number of missing
> values per category and then impute these values?
> 
> Sounds feasible, although I was in hope for a more straight forward way to
> deal with zero trunc. binomial data like seemingly is available for Poisson
> data.
> 
> Since zero trunc. Poisson  is available in glmmADMB, would it also be an
> option to treat binomial data as Poisson by using a per class offset?
> 
> CU, Martin.

  Seems reasonable.  I would try it on some simulations ...

  glmmADMB has (in principle) zero-inflated binomial (although I've
never tested it ...), and truncated binomial could be implemented
without a great deal of trouble ...



From geralttee at gmail.com  Wed Feb  1 11:10:18 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Wed, 1 Feb 2012 11:10:18 +0100
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
Message-ID: <CANXb-o5boKLq_JaSbVduhPts+PEr-YFNXSXJspJaBUWPz6VysQ@mail.gmail.com>

Hi, one more thing (although it turned out not to be important_ -
you're using improper (nu=0) priors which in some situations might be
problematic. in general try using proper ones (see Jarrod's Course
Notes for details) or parameter expansion, especially if you expect
close-to-zero variances.

Cheers,
sz.

--
Szymon Drobniak || Population Ecology Group
Institute of Environmental Sciences,?Jagiellonian University
ul. Gronostajowa 7, 30-387 Krak?w, POLAND
tel.: +48 12 664 51 79 fax: +48 12 664 69 12
szymek.dronbiak at uj.edu.pl
www.eko.uj.edu.pl/drobniak



From m.dossena at qmul.ac.uk  Wed Feb  1 11:53:16 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Wed, 1 Feb 2012 10:53:16 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <loom.20120201T030103-410@post.gmane.org>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
	<F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>
	<loom.20120201T030103-410@post.gmane.org>
Message-ID: <8B77AD44-9DF0-4EE4-911D-AAA1A3948A4E@qmul.ac.uk>

Really appreciate Ben,

this really make things clearer now, seems like (season|subject), could be the appropriate structure.

However, a last doubt still trouble me.

Having (season|subject) fitted as random effect, is it taking in consideration pseudoreplication (repeated measures on subject)?
If I would do this analysis with lme() I would fit a model with the argument correlation=CorCompSymm(form=~1|subject),
and a model without correlation than compared the two to assess wether or not  there is violation of the independence.
Is this a sensible things to do?

Since i'm working with lmer(), how can I check if correlation has to be included in the model?

Cheers
m.

Il giorno 1 Feb 2012, alle ore 02:15, Ben Bolker ha scritto:

> matteo dossena <m.dossena at ...> writes:
> 
>> Dear all,
> 
>> sorry to write again on this topic, but i feel like I haven't make
>> myself clear.  I try to rephrase my question, hope I'm not annoying
>> you.  So given that each level of season - e.g. April and Oct -
>> occurs at each level of subject while each level of treatment
>> -e.g. high or control - only occurs on a half of the the subjects
>> respectively and randomly, should I specify the random effects in
>> the model as
> 
> If you really want to "... assess[] the effect of treatment, season
> and their interaction on the relationship between the two variables",
> you may want treatment*season*V2 as fixed effect (so you can tell whether 
> the V1~V2 relationship changes with treatment and season)
> 
>  Having any *factor* included as both a fixed effect and a random
> effect will cause trouble, e.g. in your model (2).  (On the other
> hand, it does sometimes make sense to include a _continuous_ predictor
> as both fixed (which will estimate a linear trend) and random (which
> will consider variation around the linear trend -- this only makes
> sense if you have multiple measurements per value of the predictor,
> though.  Another apparent exception to this is subject in the
> (1|treatment/subject) term, which is only included as subject nested
> within treatment.
> 
>> (1) having subject nested within treatment and crossed with date, 
>> V1 ~ treatment * season + V2 + (1|treatment/subject) + (1|season)
> 
>  Here both treatment and season are included as both fixed and random --
> probably not a good idea.
> 
>> (2) subject crossed with date ignoring the nesting with treatment,
>> (3) random effects on subject only ignoring the crossed and nested
>> data structure V1 ~ treatment * season + V2 + (1|subject) +
>> (1|season)
> 
>  Still probably don't want season and (1|season)
>> 
> 
>> (3) random effects on subject only ignoring the crossed and nested
>> data structure V1 ~ treatment * season + V2 + (1|subject)
> 
>   This is not unreasonable.  You could consider (season|subject),
> or (1|subject)+(0+season|subject) [which fits the intercept and slope
> independently], since you have both seasons assessed for each individual.
> 
>   This gets raised a lot on this list, but: I would generally only
> drop a random effect from the model if it actually appears overfitted
> (i.e.  estimated as zeros, or a perfect +1/-1 correlation between
> random effects), and not if it is merely non-significant (Hurlbert
> calls this "sacrificial pseudoreplication").  I've been very impressed
> by the results from the blme package, which incorporates a weak
> Bayesian prior to push underdetermined variance components away from
> zero ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From pjmiller_57 at yahoo.com  Wed Feb  1 16:32:56 2012
From: pjmiller_57 at yahoo.com (Paul Miller)
Date: Wed, 1 Feb 2012 07:32:56 -0800 (PST)
Subject: [R-sig-ME] Mixed Model Version of Two-Stage Least Squares Analysis
In-Reply-To: <8B77AD44-9DF0-4EE4-911D-AAA1A3948A4E@qmul.ac.uk>
Message-ID: <1328110376.89784.YahooMailClassic@web161603.mail.bf1.yahoo.com>

Hello Everyone,

I'm familiar with the use of Two-Stage Least Squares Analysis to obtain results like one gets with SEM. I was wondering if anyone knows how to extend this approach to nested data. My data contain multiple observations from cancer patients. The number of observations varies by patient and the intervals between observations are not equally spaced.

Is it possible to apply a 2SLS approach to my data? If so, are there measures of model fit from the standard 2SLS approach that will work if I'm using a mixed model to account for non-independence of observations in my data? Or are there maybe some other measures I could use?

Thanks,

Paul



From odirrodriguezvillagra at gmail.com  Wed Feb  1 17:34:15 2012
From: odirrodriguezvillagra at gmail.com (=?ISO-8859-1?Q?Odir_Rodr=EDguez_Villagra?=)
Date: Wed, 1 Feb 2012 17:34:15 +0100
Subject: [R-sig-ME] question about random intercept reflecting mean value of
 between subject factor
Message-ID: <CAGDkQnb0LLTrHfFQVGFOAz5nXSv8ejy1jkanR1D_tNN5PKHKTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120201/0460f4c3/attachment-0001.pl>

From maggie.neff at gmail.com  Wed Feb  1 19:54:20 2012
From: maggie.neff at gmail.com (Maggie Neff)
Date: Wed, 1 Feb 2012 13:54:20 -0500
Subject: [R-sig-ME] Estimating variance in linear mixed models
Message-ID: <CAH3MgyL_8snnonps579mo9AtiyYJhJ-a=Q1fr1UQW113ZW9mTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120201/f21c9467/attachment-0001.pl>

From ljkjar at hotmail.com  Wed Feb  1 21:00:11 2012
From: ljkjar at hotmail.com (Lene Jung)
Date: Wed, 1 Feb 2012 21:00:11 +0100
Subject: [R-sig-ME] non-parametric mixed model
Message-ID: <BLU0-SMTP34095B4B35D4B3D1402D31CDB730@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120201/5622979b/attachment-0001.pl>

From rstuff.miles at gmail.com  Wed Feb  1 21:31:05 2012
From: rstuff.miles at gmail.com (Andrew Miles)
Date: Wed, 1 Feb 2012 15:31:05 -0500
Subject: [R-sig-ME] Estimating variance in linear mixed models
In-Reply-To: <CAH3MgyL_8snnonps579mo9AtiyYJhJ-a=Q1fr1UQW113ZW9mTw@mail.gmail.com>
References: <CAH3MgyL_8snnonps579mo9AtiyYJhJ-a=Q1fr1UQW113ZW9mTw@mail.gmail.com>
Message-ID: <85BBAFD8-A893-4A45-960C-6241B43ACB44@gmail.com>

A linear multilevel model like you are using can be used to estimate the between-year variance, like so (note I'm using the lmer function, not lme, which I am less familiar with):

library(lme4)
mod=lmer(cont ~ 1 + (1|year), data=fish)

The Random Effects for (Intercept) will give you the variance of the estimates of contaminants in each year.  However, with only 9 different years (and hence 9 different estimates of contaminants), the random effect might not be very reliable.  You can get model predicted estimates for each of the years like so:
coef(mod)

I can't immediately think of a way to estimate within-year variance using a MLM, but you could get estimates of the within-year variance doing something like this:
tapply(cont, year, var)

This should break down cont by year, and then estimate the variance in each year.

I hope this helps.

Andrew Miles


On Feb 1, 2012, at 1:54 PM, Maggie Neff wrote:

> Hello,
> 
> This is both an R and stats question.  I have some data covering
> contaminant concentrations in fish over a time period of ~35 years.  Each
> year, multiple samples of fish were taken (with varying sample sizes each
> year). The trend is modeled using a linear regression on ln[contaminant]
> and year.  The ultimate goal of this project is to do a power analysis for
> a monitoring program, and to do this, I need an estimation of both random
> within-year variation and random between-year variation.
> 
> I used a linear mixed model to estimate these variances.  My questions is
> whether the function as I've set it up will return the estimates that I'm
> looking for, and if so, which values within the output reflect those
> estimates.  If someone knows of a better/alternative way to estimate these
> values, that would also be useful.
> 
>> fish<-read.csv("data.csv",header=TRUE)
>> fish
>   SPECIES YEAR CONT
> 1  Walleye 1970 2.83
> 2  Walleye 1970 2.56
> 3  Walleye 1970 2.83
> 4  Walleye 1970 2.56
> 5  Walleye 1970 2.77
> 6  Walleye 1970 2.56
> 7  Walleye 1970 2.64
> 8  Walleye 1970 2.22
> 9  Walleye 1970 2.56
> 10 Walleye 1970 2.40
> 11 Walleye 1975 1.59
> 12 Walleye 1975 1.53
> 13 Walleye 1975 2.16
> 14 Walleye 1975 1.60
> 15 Walleye 1975 2.16
> 16 Walleye 1976 2.03
> 17 Walleye 1976 1.97
> 18 Walleye 1976 1.95
> 19 Walleye 1976 2.36
> 20 Walleye 1976 1.82
> 21 Walleye 1976 1.99
> 22 Walleye 1977 1.06
> 23 Walleye 1977 2.00
> 24 Walleye 1977 1.97
> 25 Walleye 1977 2.00
> 26 Walleye 1977 1.99
> 27 Walleye 1977 1.95
> 28 Walleye 1977 2.10
> 29 Walleye 1977 2.29
> 30 Walleye 1977 2.20
> 31 Walleye 1979 1.90
> 32 Walleye 1979 1.98
> 33 Walleye 1979 2.00
> 34 Walleye 1979 2.11
> 35 Walleye 1980 1.92
> 36 Walleye 1980 2.00
> 37 Walleye 1980 1.98
> 38 Walleye 1980 2.25
> 39 Walleye 1981 1.22
> 40 Walleye 1981 1.36
> 41 Walleye 1981 1.48
> 42 Walleye 1981 1.86
> 43 Walleye 1981 1.41
> 44 Walleye 1982 1.25
> 45 Walleye 1982 1.10
> 46 Walleye 1982 1.28
> 47 Walleye 1982 1.28
> 48 Walleye 1982 1.77
> 49 Walleye 1982 1.59
> 50 Walleye 1982 1.61
> 51 Walleye 1982 1.55
> 52 Walleye 1984 1.25
> 53 Walleye 1984 1.41
> 54 Walleye 1984 1.50
> 55 Walleye 1984 1.39
>> year<-fish$YEAR
>> cont<-fish$CONT
>> reg3<-lme(year~cont,random=~1|year,method="REML")
>> reg3
> Linear mixed-effects model fit by REML
>  Data: NULL
>  Log-restricted-likelihood: 1243.336
>  Fixed: year ~ cont
> (Intercept)         cont
> 1.978213e+03 4.947785e-14
> 
> Random effects:
> Formula: ~1 | year
>        (Intercept)    Residual
> StdDev:     4.23609 1.18049e-13
> 
> Number of Observations: 55
> Number of Groups: 9
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Thu Feb  2 04:07:22 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 2 Feb 2012 13:07:22 +1000 (EST)
Subject: [R-sig-ME] non-parametric mixed model
In-Reply-To: <BLU0-SMTP34095B4B35D4B3D1402D31CDB730@phx.gbl>
References: <BLU0-SMTP34095B4B35D4B3D1402D31CDB730@phx.gbl>
Message-ID: <Pine.LNX.4.64.1202021302240.17444@orpheus.qimr.edu.au>

On Wed, 1 Feb 2012, Lene Jung wrote:

> variables. For all variables, I have repeated measurements from individuals
> (multiple seasons) and 2 different study sites, so I am using a mixed-model
> approach with individual as subject (random effect) to test for differences
> between sites and seasons.
>
> My problem is that I have 2 variables that are cosines which means that
> they are in the interval -1 to 1. One of the variables have many ties (many
> 1s) whereas the other doesn't.

This is circular data?  There apparently are mixed models eg for 
longitudinal circular data, and there are nonparametric tests of 
homogeneity.

eg http://www.omicsonline.org/2155-6180/2155-6180-1-107.php,
R CircStats package.

Or am I completely misunderstanding?

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From istazahn at gmail.com  Thu Feb  2 13:16:51 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 02 Feb 2012 07:16:51 -0500
Subject: [R-sig-ME] Estimating variance in linear mixed models
In-Reply-To: <85BBAFD8-A893-4A45-960C-6241B43ACB44@gmail.com>
References: <CAH3MgyL_8snnonps579mo9AtiyYJhJ-a=Q1fr1UQW113ZW9mTw@mail.gmail.com>
	<85BBAFD8-A893-4A45-960C-6241B43ACB44@gmail.com>
Message-ID: <6960314.PpG1NVmF94@arch-desktop>

Hi Andrew and Maggie,

On Wednesday, February 01, 2012 03:31:05 PM Andrew Miles wrote:
> A linear multilevel model like you are using can be used to estimate the
> between-year variance, like so (note I'm using the lmer function, not lme,
> which I am less familiar with):
> 
> library(lme4)
> mod=lmer(cont ~ 1 + (1|year), data=fish)
> 
> The Random Effects for (Intercept) will give you the variance of the
> estimates of contaminants in each year.  However, with only 9 different
> years (and hence 9 different estimates of contaminants), the random effect
> might not be very reliable.  You can get model predicted estimates for each
> of the years like so: coef(mod)
> 
> I can't immediately think of a way to estimate within-year variance using a
> MLM, but you could get estimates of the within-year variance doing
> something like this: tapply(cont, year, var)

The residual variance from the lmer model is the within-year variance, no?

> 
> This should break down cont by year, and then estimate the variance in each
> year.
> 
> I hope this helps.
> 
> Andrew Miles
> 
> On Feb 1, 2012, at 1:54 PM, Maggie Neff wrote:
> > Hello,
> > 
> > This is both an R and stats question.  I have some data covering
> > contaminant concentrations in fish over a time period of ~35 years.  Each
> > year, multiple samples of fish were taken (with varying sample sizes each
> > year). The trend is modeled using a linear regression on ln[contaminant]
> > and year.  The ultimate goal of this project is to do a power analysis for
> > a monitoring program, and to do this, I need an estimation of both random
> > within-year variation and random between-year variation.
> > 
> > I used a linear mixed model to estimate these variances.  My questions is
> > whether the function as I've set it up will return the estimates that I'm
> > looking for, and if so, which values within the output reflect those
> > estimates.  If someone knows of a better/alternative way to estimate these
> > values, that would also be useful.
> > 
> >> fish<-read.csv("data.csv",header=TRUE)
> >> fish
> >> 
> >   SPECIES YEAR CONT
> > 
> > 1  Walleye 1970 2.83
> > 2  Walleye 1970 2.56
> > 3  Walleye 1970 2.83
> > 4  Walleye 1970 2.56
> > 5  Walleye 1970 2.77
> > 6  Walleye 1970 2.56
> > 7  Walleye 1970 2.64
> > 8  Walleye 1970 2.22
> > 9  Walleye 1970 2.56
> > 10 Walleye 1970 2.40
> > 11 Walleye 1975 1.59
> > 12 Walleye 1975 1.53
> > 13 Walleye 1975 2.16
> > 14 Walleye 1975 1.60
> > 15 Walleye 1975 2.16
> > 16 Walleye 1976 2.03
> > 17 Walleye 1976 1.97
> > 18 Walleye 1976 1.95
> > 19 Walleye 1976 2.36
> > 20 Walleye 1976 1.82
> > 21 Walleye 1976 1.99
> > 22 Walleye 1977 1.06
> > 23 Walleye 1977 2.00
> > 24 Walleye 1977 1.97
> > 25 Walleye 1977 2.00
> > 26 Walleye 1977 1.99
> > 27 Walleye 1977 1.95
> > 28 Walleye 1977 2.10
> > 29 Walleye 1977 2.29
> > 30 Walleye 1977 2.20
> > 31 Walleye 1979 1.90
> > 32 Walleye 1979 1.98
> > 33 Walleye 1979 2.00
> > 34 Walleye 1979 2.11
> > 35 Walleye 1980 1.92
> > 36 Walleye 1980 2.00
> > 37 Walleye 1980 1.98
> > 38 Walleye 1980 2.25
> > 39 Walleye 1981 1.22
> > 40 Walleye 1981 1.36
> > 41 Walleye 1981 1.48
> > 42 Walleye 1981 1.86
> > 43 Walleye 1981 1.41
> > 44 Walleye 1982 1.25
> > 45 Walleye 1982 1.10
> > 46 Walleye 1982 1.28
> > 47 Walleye 1982 1.28
> > 48 Walleye 1982 1.77
> > 49 Walleye 1982 1.59
> > 50 Walleye 1982 1.61
> > 51 Walleye 1982 1.55
> > 52 Walleye 1984 1.25
> > 53 Walleye 1984 1.41
> > 54 Walleye 1984 1.50
> > 55 Walleye 1984 1.39
> > 
> >> year<-fish$YEAR
> >> cont<-fish$CONT
> >> reg3<-lme(year~cont,random=~1|year,method="REML")
> >> reg3
> > 
> > Linear mixed-effects model fit by REML
> > 
> >  Data: NULL
> >  Log-restricted-likelihood: 1243.336
> >  Fixed: year ~ cont
> > 
> > (Intercept)         cont
> > 1.978213e+03 4.947785e-14
> > 
> > Random effects:
> > Formula: ~1 | year
> > 
> >        (Intercept)    Residual
> > 
> > StdDev:     4.23609 1.18049e-13
> > 
> > Number of Observations: 55
> > Number of Groups: 9
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From c.ryan.king at gmail.com  Thu Feb  2 18:53:01 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Thu, 2 Feb 2012 11:53:01 -0600
Subject: [R-sig-ME] MCMCglmm rcov specifications
Message-ID: <CAEQ+J26csPh_-O3Pc_fz_Kfs1L_9Rg3kJiFmotYLyPDY_FnsXw@mail.gmail.com>

Hi list,
If I want to specify heterogeneous variances proportional to a known
factor in MCMCglmm, it seems like mev is the correct option, but
looking at the code it appears to add person-level random effects with
variance fixed at the specified value:

random = ~us(leg(MCMC_mev, -1, FALSE)):MCMC_meta
prior$G<-list(G1=list(V=as.matrix(1), nu=1, fix=1))

I've used the same trick to specify a known co-variance function.
However, the updates for this specification seem to go slowly and
induce bad mixing in my binary outcomes problem. The unidentified
residual variance certainly isn't helping. Is there a trick to
directly specify a matrix R and avoid inducing the identification
headache and slow MME solving?

Thanks,
Ryan King



From j.hadfield at ed.ac.uk  Thu Feb  2 19:05:34 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 2 Feb 2012 18:05:34 +0000
Subject: [R-sig-ME] MCMCglmm rcov specifications
In-Reply-To: <CAEQ+J26csPh_-O3Pc_fz_Kfs1L_9Rg3kJiFmotYLyPDY_FnsXw@mail.gmail.com>
References: <CAEQ+J26csPh_-O3Pc_fz_Kfs1L_9Rg3kJiFmotYLyPDY_FnsXw@mail.gmail.com>
Message-ID: <3A75ECEA-7E9F-4B9A-9A2B-9BCDAD31E78F@ed.ac.uk>

Hi,

see the schools example in the course notes:

rcov=~idh(units):units

prior=list(R=list(V=diag(mev), fix=1))

Cheers,

Jarrod

On 2 Feb 2012, at 17:53, Ryan King wrote:

> Hi list,
> If I want to specify heterogeneous variances proportional to a known
> factor in MCMCglmm, it seems like mev is the correct option, but
> looking at the code it appears to add person-level random effects with
> variance fixed at the specified value:
>
> random = ~us(leg(MCMC_mev, -1, FALSE)):MCMC_meta
> prior$G<-list(G1=list(V=as.matrix(1), nu=1, fix=1))
>
> I've used the same trick to specify a known co-variance function.
> However, the updates for this specification seem to go slowly and
> induce bad mixing in my binary outcomes problem. The unidentified
> residual variance certainly isn't helping. Is there a trick to
> directly specify a matrix R and avoid inducing the identification
> headache and slow MME solving?
>
> Thanks,
> Ryan King
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From j.hadfield at ed.ac.uk  Thu Feb  2 19:11:03 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 02 Feb 2012 18:11:03 +0000
Subject: [R-sig-ME] MCMCglmm rcov specifications
In-Reply-To: <3A75ECEA-7E9F-4B9A-9A2B-9BCDAD31E78F@ed.ac.uk>
References: <CAEQ+J26csPh_-O3Pc_fz_Kfs1L_9Rg3kJiFmotYLyPDY_FnsXw@mail.gmail.com>
	<3A75ECEA-7E9F-4B9A-9A2B-9BCDAD31E78F@ed.ac.uk>
Message-ID: <20120202181103.15470w7u4trln9o0@www.staffmail.ed.ac.uk>

HI,

Sorry - I was to quick. The residual variances will not be  
proportional to mev, they will be mev. Its not possible to fit the  
proportional model currently/easily, although I could imagine with  
some thought you could trick MCMCglmm into doing it via a SIR model. See

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/004916.html

for a solution to a similar problem. Not very elegant I'm afraid!

Jarrod





Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Thu, 2 Feb 2012  
18:05:34 +0000:

> Hi,
>
> see the schools example in the course notes:
>
> rcov=~idh(units):units
>
> prior=list(R=list(V=diag(mev), fix=1))
>
> Cheers,
>
> Jarrod
>
> On 2 Feb 2012, at 17:53, Ryan King wrote:
>
>> Hi list,
>> If I want to specify heterogeneous variances proportional to a known
>> factor in MCMCglmm, it seems like mev is the correct option, but
>> looking at the code it appears to add person-level random effects with
>> variance fixed at the specified value:
>>
>> random = ~us(leg(MCMC_mev, -1, FALSE)):MCMC_meta
>> prior$G<-list(G1=list(V=as.matrix(1), nu=1, fix=1))
>>
>> I've used the same trick to specify a known co-variance function.
>> However, the updates for this specification seem to go slowly and
>> induce bad mixing in my binary outcomes problem. The unidentified
>> residual variance certainly isn't helping. Is there a trick to
>> directly specify a matrix R and avoid inducing the identification
>> headache and slow MME solving?
>>
>> Thanks,
>> Ryan King
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From smccracken at tadpoleorg.org  Fri Feb  3 00:05:32 2012
From: smccracken at tadpoleorg.org (Shawn McCracken)
Date: Thu, 2 Feb 2012 17:05:32 -0600
Subject: [R-sig-ME] r-sig-mixed-models answer
In-Reply-To: <4F249C54.8000803@ufl.edu>
References: <4F249C54.8000803@ufl.edu>
Message-ID: <CAE+9gVHvy_ow2+syyGsuxAKV=_kmZaK+yOmH5OrFOZNZTQr=ow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120202/410335d1/attachment-0001.pl>

From deter088 at umn.edu  Fri Feb  3 14:05:57 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 07:05:57 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
Message-ID: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/51ef360d/attachment-0001.pl>

From deter088 at umn.edu  Fri Feb  3 15:35:52 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 08:35:52 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/d234bef9/attachment-0001.pl>

From deter088 at umn.edu  Fri Feb  3 16:17:55 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 09:17:55 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/8326c69b/attachment-0001.pl>

From jbaldwin at fs.fed.us  Fri Feb  3 16:25:43 2012
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Fri, 3 Feb 2012 15:25:43 +0000
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>

I think the only way to resolve this is to provide a specific example.

Jim Baldwin
Station Statistician
USDA Forest Service
Albany, California

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles Determan Jr
Sent: Friday, February 03, 2012 7:18 AM
To: Thompson,Paul; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lme capable of running with missing data?

So, is there a way in which I can alter the design matrix so the mixed model will work or is this something that can only be done in SAS currently?  The output from the SAS run did provide Type III fixed effect test values.

On Fri, Feb 3, 2012 at 9:14 AM, Thompson,Paul < Paul.Thompson at sanfordhealth.org> wrote:

>  That's interesting. SAS uses the sweep approach (it was in fact 
> devised by Goodnight). The method used in construction of various 
> types of SS does allow you to estimate when cells are missing. I would 
> wonder if Type II SS can be done. Type III (despite the incorrect 
> statement that they are
> illegitimate) and Type IV would work fine. ****
>
> ** **
>
> It's really an issue of the manner in which the design matrix is
> contructed.****
>
> ** **
>
> *From:* Charles Determan Jr [mailto:deter088 at umn.edu]
> *Sent:* Friday, February 03, 2012 8:36 AM
> *To:* Thompson,Paul; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] lme capable of running with missing 
> data?****
>
> ** **
>
> Thank you Paul, I do appreciate your response and especially your time.
> The reason I am so persistent is that I know the prior data I posted 
> was run in SAS (however I don't have the exact coding although I do 
> know it was done with PROC MIXED with an unstructured covariance 
> structure and REML estimation method) and it provided all the 
> interactions.  As such, I have scoured the web and literature as to 
> how this could be done with the missing data (timepoints as a result 
> of survival).  Perhaps this simply has not yet been done in R and I am 
> stuck for the time being.  None-the-less, I want to be certain before I give up on running this type of analysis in R.
>
> Thanks again,****
>
> On Fri, Feb 3, 2012 at 8:26 AM, Thompson,Paul < 
> Paul.Thompson at sanfordhealth.org> wrote:****
>
> Charles:
>
> I did suggest the use of specific contrasts to do the analysis with 
> missing cells. I played around, and just have to admit that this is 
> not possible. I tried to use standard construction techniques to 
> produce main effects using contrast coding, and then multiply those to 
> produce interactions. This does not work. It may be possible to use 
> orthonormalization and the sweep operator to produce a consistent 
> estimator, but I ran out of time to work on this.
>
> What you can do is convert the design to a single factor, and do the 
> analysis with specific contrasts, recognizing that this will not 
> enable you to get to specific things like interaction effects. To 
> understand why, consider the situation with a 2 x 2, where one cell is entirely missing.
> You have lost 1 df for the design, and the interaction is entirely missing.
> You can estimate and test specific contrasts, but you can't even 
> really test the A factor or the B factor. If Cell(2,2) is missing, you 
> can test Cell (1,1) v Cell(1,2) and you can test Cell (2,1) v Cell 
> (1,1), but neither of these is the test of the "main effect" of A or 
> B. When you have larger designs with 2 or 3 factors, the comparisons 
> again have fewer df than should be encountered. This means that the 
> interactions are not defined properly.
>
> Do you NEED the interactions for theoretical purposes, or are they 
> there simply for completedness? Are the cells missing due to your 
> design or due to happenstance?
>
> It is the case that fractional factorial designs eliminate cells from 
> the design to estimate main effects and losing the ability to estimate 
> interactions. So, missing cells, when planned for appropriately, can 
> result in appropriate analysis. I am not sure how to run mixed models 
> with fractional factorials, however.****
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles 
> Determan Jr
> Sent: Friday, February 03, 2012 7:06 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme capable of running with missing data?
>
> Greetings,
>
> Some of you may recognize my name from a few related posts but I just 
> have general question that perhaps can be clarified.  I have read 
> several times that 'lme' and 'lmer' are techniques capable of running 
> data sets with missing values.  Is this true?  I have put up similar 
> posts where when I try to run a two or three way interaction mixed 
> model I get an error of singularities or X'X not positive.  Does the 
> data set need to be formatted in some way where the mixed model can be run with all interactions?
> Furthermore, if the missing values are 'not missing at random' is 
> there another method to follow for generating the mixed model?  I am 
> just confused why I see posts that lme can be run when data is missing.
>
> Regards,****
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ----------------------------------------------------------------------
> - Confidentiality Notice: This e-mail message, including any 
> attachments, is for the sole use of the intended recipient(s) and may 
> contain privileged and confidential information.  Any unauthorized 
> review, use, disclosure or distribution is prohibited.  If you are not 
> the intended recipient, please contact the sender by reply e-mail and 
> destroy all copies of the original message.****
>
> ** **
>
>
> ----------------------------------------------------------------------
> - Confidentiality Notice: This e-mail message, including any 
> attachments, is for the sole use of the intended recipient(s) and may 
> contain privileged and confidential information. Any unauthorized 
> review, use, disclosure or distribution is prohibited. If you are not 
> the intended recipient, please contact the sender by reply e-mail and 
> destroy all copies of the original message.
>

	[[alternative HTML version deleted]]



From deter088 at umn.edu  Fri Feb  3 16:31:03 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 09:31:03 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
Message-ID: <CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/e0b0429b/attachment-0001.pl>

From deter088 at umn.edu  Fri Feb  3 17:18:59 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 10:18:59 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
Message-ID: <CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/ab5adf74/attachment-0001.pl>

From numashankar at gsu.edu  Fri Feb  3 14:42:47 2012
From: numashankar at gsu.edu (Nita Umashankar)
Date: Fri, 3 Feb 2012 13:42:47 +0000
Subject: [R-sig-ME] Heckit for HLM models
Message-ID: <7B82ADECF221B54B952F768A84D70B742929EC92@BL2PRD0510MB362.namprd05.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/47c9a1ec/attachment-0001.pl>

From kw.stat at gmail.com  Fri Feb  3 17:58:27 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 3 Feb 2012 10:58:27 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
Message-ID: <CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/f32680e9/attachment-0001.pl>

From deter088 at umn.edu  Fri Feb  3 18:06:32 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 11:06:32 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
Message-ID: <CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/b65757ee/attachment-0001.pl>

From jbaldwin at fs.fed.us  Fri Feb  3 18:08:51 2012
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Fri, 3 Feb 2012 17:08:51 +0000
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45690E2C1FEF@001FSN2MPN1-016.001f.mgd2.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/751cf7c8/attachment-0001.pl>

From aslacksmith2 at gmail.com  Fri Feb  3 18:18:35 2012
From: aslacksmith2 at gmail.com (Andrew Slack-Smith)
Date: Sat, 4 Feb 2012 04:18:35 +1100
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
Message-ID: <002701cce297$e04ccb50$a0e661f0$@gmail.com>


Charles

As you suggest SAS will run the data. I just put it into SAS and all OK.

SAS uses the Satterthwaite "degrees of freedom method". If that helps at
all. 

>From the web page  http://glmm.wikidot.com/faq I grabbed the following which
may relate to your problem.


 - Other df approximation schemes that have been suggested (Satterthwaite,
Kenward-Roger, etc.) would apparently be fairly hard to implement in
lme4/nlme, both because of a difference in notational framework and because
naive approaches would be computationally difficult in the case of large
data sets. (The Kenward-Roger approach has now been implemented in the
pbkrtest package (as KRmodcomp): note that it was derived for LMMs and is
not necessarily applicable to GLMMs!)

 - When the data are not classical (crossed, unbalanced, R-side effects), we
might still guess that the deviances etc. are approximately F-distributed
but that we don't know the real degrees of freedom - this is what the
Satterthwaite, Kenward-Roger, Fai-Cornelius, etc. approximations are
supposed to do.


All the best

Andrew


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Kevin Wright
Sent: Saturday, 4 February 2012 3:58 AM
To: Charles Determan Jr
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lme capable of running with missing data?

Charles,

Here's a simple thought example.  Use a piece of graph paper (or just a
simple sketch).  Write the following letters at the coordinates specified:

A1  (1,1)
A2 (3,2)
B1 (1,2)
B2 (missing)

Draw a line from A1 to A2.  Imagine a line from B1 to the missing value of
B2.

By looking at this, you could calculate an overall mean for the A factor.
You could also estimate an overall mean for the B factor, if you assume the
lines are parallel.  This is what happens with fixed effects, as in lme (
... A + B, ...).
But, when you specify lme(... A*B, ...) which is the same as lme(... A + B
+ A:B, ...), you are essentially saying to the computer, "The A1-A2 and
B1-B2 lines are not parallel, but please give me an estimate of the slope of
the B1-B2 line."

Could _you_ draw the B1-B2 line?  No.  Neither can lme.

It's okay that B2 is missing if you don't want to fit an interaction, but
when B2 is missing, there is no way to estimate an interaction (non-parallel
slope).

Kevin





On Fri, Feb 3, 2012 at 10:18 AM, Charles Determan Jr
<deter088 at umn.edu>wrote:

> After the data is input, and factors are assigned,
>
> model=lme(arginine~group*time*survival, random=~1|subj, method="REML",
> data=x)
>
> Error in MEEM(object, conLin, control$niterEM) : Singularity in 
> backsolve at level 0, block 1
>
>
>
> On Fri, Feb 3, 2012 at 10:01 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>
>> Providing the data is not a "reproducible example".  Complete data 
>> and R-code are helpful.
>>
>> Kevin
>>
>>
>>
>> On Fri, Feb 3, 2012 at 9:31 AM, Charles Determan Jr
<deter088 at umn.edu>wrote:
>>
>>> Here is the dataset, everything should be run as a factor except 'met'
>>> which is numeric.  Thanks for the assistance,
>>>
>>>    time group survival subj met
>>> 1      1     2        1      2   1.3954
>>> 2      2     2        1      2   1.8063
>>> 3      3     2        1      2   1.3684
>>> 4      4     2        1      2   2.0046
>>> 5      5     2        1      2   1.0334
>>> 6      6     2        1      2   0.3644
>>> 7      7     2        1      2   0.4819
>>> 8      8     2        1      2   1.4558
>>> 9      9     2        1     2   0.9718
>>> 10     1     1        2    5   0.7771
>>> 11     2     1        2    5   1.2439
>>> 12     1     2        2    8   1.0980
>>> 13     2     2        2    8   0.9511
>>> 14     1     2        1    9   1.0534
>>> 15     2     2        1    9   1.7279
>>> 16     3     2        1    9   1.4904
>>> 17     4     2        1    9   1.2737
>>> 18     5     2        1    9   0.8929
>>> 19     6     2        1    9   0.5828
>>> 20     7     2        1    9   0.3260
>>> 21     8     2        1    9   1.0373
>>> 22     9     2        1    9   0.9624
>>> 23     1     2        2   10   1.1391
>>> 24     2     2        2   10   1.3945
>>> 25     3     2        2   10   0.9414
>>> 26     4     2        2   10   1.1152
>>> 27     5     2        2   10   0.8222
>>> 28     6     2        2   10   0.4417
>>> 29     7     2        2   10   0.4126
>>> 30     1     1        1   12   1.3024
>>> 31     2     1        1   12   1.1811
>>> 32     3     1        1   12   0.9379
>>> 33     4     1        1   12   1.3000
>>> 34     5     1        1   12   1.2977
>>> 35     6     1        1   12   0.4949
>>> 36     7     1        1   12   0.5238
>>> 37     8     1        1   12   1.3862
>>> 38     1     1        1   16   1.2259
>>> 39     2     1        1   16   0.8681
>>> 40     3     1        1   16   1.2645
>>> 41     4     1        1   16   0.7316
>>> 42     5     1        1   16   0.6648
>>> 43     6     1        1   16   0.9671
>>> 44     7     1        1   16   1.0131
>>> 45     8     1        1   16   1.1762
>>> 46     9     1        1   16   0.8776
>>> 47     1     2        2   18   1.1231
>>> 48     2     2        2   18   1.2133
>>> 49     3     2        2   18   1.2005
>>> 50     4     2        2   18   0.7198
>>> 51     5     2        2   18   0.6620
>>> 52     6     2        2   18   0.5908
>>> 53     7     2        2   18   0.3945
>>> 54     1     2        2   19   0.7852
>>> 55     2     2        2   19   0.6758
>>> 56     3     2        2   19   0.5246
>>> 57     4     2        2   19   0.5263
>>> 58     1     2        2   20   1.2284
>>> 59     2     2        2   20   0.7017
>>> 60     1     2        1   23   0.9604
>>> 61     2     2        1   23   0.7977
>>> 62     3     2        1   23   1.2267
>>> 63     4     2        1   23   1.3857
>>> 64     5     2        1   23   0.9486
>>> 65     6     2        1   23   0.3571
>>> 66     7     2        1   23   0.3134
>>> 67     8     2        1   23   1.9984
>>> 68     9     2        1   23   0.4837
>>> 69     1     1        1   24   1.1793
>>> 70     2     1        1   24   1.3883
>>> 71     3     1        1   24   2.1080
>>> 72     4     1        1   24   0.8810
>>> 73     5     1        1   24   0.8825
>>> 74     6     1        1   24   0.4124
>>> 75     7     1        1   24   0.5270
>>> 76     8     1        1   24   1.9003
>>> 77     9     1        1   24   1.4344
>>> 78     1     1        1   27   1.1905
>>> 79     2     1        1   27   1.1033
>>> 80     3     1        1   27   1.4976
>>> 81     4     1        1   27   1.9018
>>> 82     5     1        1   27   0.5815
>>> 83     6     1        1   27   0.4428
>>> 84     7     1        1   27   0.4728
>>> 85     8     1        1   27   1.6309
>>> 86     9     1        1   27   0.4054
>>> 87     1     1        1   28   0.9538
>>> 88     2     1        1   28   0.7796
>>> 89     3     1        1   28   1.7906
>>> 90     5     1        1   28   0.4715
>>> 91     6     1        1   28   0.4214
>>> 92     7     1        1   28   0.4120
>>> 93     8     1        1   28   1.3111
>>> 94     9     1        1   28   0.3677
>>> 95     1     1        2    1   1.3853
>>> 96     2     1        2    1   1.5966
>>> 97     3     1        2    1   1.4542
>>> 98     4     1        2    1   1.3084
>>> 99     5     1        2    1   1.2826
>>> 100    6     1        2    1   0.6835
>>> 101    7     1        2    1   0.9709
>>> 102    1     1        1    3   1.3175
>>> 103    2     1        1    3   0.7792
>>> 104    3     1        1    3   1.8763
>>> 105    5     1        1    3   1.4633
>>> 106    6     1        1    3   0.0735
>>> 107    7     1        1    3   0.5612
>>> 108    8     1        1    3   1.3777
>>> 109    9     1        1    3   0.3810
>>> 110    1     1        2    4   1.3486
>>> 111    1     1        1    6   1.2635
>>> 112    2     1        1    6   0.7572
>>> 113    3     1        1    6   1.5011
>>> 114    5     1        1    6   0.6873
>>> 115    6     1        1    6   0.3778
>>> 116    7     1        1    6   0.4231
>>> 117    8     1        1    6   1.3817
>>> 118    9     1        1    6   0.5850
>>> 119    1     2        2    7   0.7362
>>> 120    2     2        2    7   0.5495
>>> 121    3     2        2    7   0.7621
>>> 122    4     2        2    7   0.8421
>>> 123    5     2        2    7   1.0438
>>> 124    6     2        2    7   0.9802
>>> 125    7     2        2    7   0.5627
>>> 126    1     1        1   11   1.5575
>>> 127    2     1        1   11   2.1356
>>> 128    3     1        1   11   1.3575
>>> 129    4     1        1   11   1.3056
>>> 130    5     1        1   11   0.8144
>>> 131    6     1        1   11   0.5876
>>> 132    7     1        1   11   0.4104
>>> 133    9     1        1   11   0.4942
>>> 134    1     2        1   13   1.0046
>>> 135    2     2        1   13   0.8805
>>> 136    3     2        1   13   0.7685
>>> 137    4     2        1   13   0.8786
>>> 138    5     2        1   13   1.4249
>>> 139    6     2        1   13   0.5339
>>> 140    7     2        1   13   0.5480
>>> 141    8     2        1   13   2.6369
>>> 142    9     2        1   13   1.7159
>>> 143    1     2        1   14   0.7161
>>> 144    2     2        1   14   0.3968
>>> 145    3     2        1   14   0.8142
>>> 146    4     2        1   14   0.6140
>>> 147    5     2        1   14   0.6585
>>> 148    6     2        1   14   0.7176
>>> 149    7     2        1   14   0.6613
>>> 150    8     2        1   14   1.6494
>>> 151    9     2        1   14   0.3903
>>> 152    1     1        1   15   1.4357
>>> 153    2     1        1   15   1.4772
>>> 154    3     1        1   15   1.3156
>>> 155    4     1        1   15   0.9654
>>> 156    5     1        1   15   1.2709
>>> 157    6     1        1   15   0.9330
>>> 158    7     1        1   15   0.3515
>>> 159    8     1        1   15   1.6801
>>> 160    9     1        1   15   0.3584
>>> 161    1     2        2   17   0.8077
>>> 162    2     2        2   17   0.7560
>>> 163    1     1        1   21   1.1890
>>> 164    2     1        1   21   0.9631
>>> 165    3     1        1   21   0.9753
>>> 166    4     1        1   21   0.9519
>>> 167    5     1        1   21   0.6348
>>> 168    6     1        1   21   0.8516
>>> 169    7     1        1   21   0.2366
>>> 170    8     1        1   21   1.0440
>>> 171    9     1        1   21   0.5360
>>> 172    1     2        1   22   1.0747
>>> 173    2     2        1   22   0.6451
>>> 174    3     2        1   22   0.8408
>>> 175    5     2        1   22   0.8730
>>> 176    6     2        1   22   0.3594
>>> 177    7     2        1   22   0.3019
>>> 178    9     2        1   22   1.2053
>>> 179    1     2        2   25   0.4654
>>> 180    2     2        2   25   0.3024
>>> 181    3     2        2   25   0.7525
>>> 182    4     2        2   25   0.7808
>>> 183    5     2        2   25   0.6294
>>> 184    6     2        2   25   0.3016
>>> 185    7     2        2   25   0.3223
>>> 186    1     2        1   26   0.5363
>>> 187    2     2        1   26   0.2279
>>> 188    3     2        1   26   0.4756
>>> 189    4     2        1   26   0.6644
>>> 190    5     2        1   26   0.6631
>>> 191    6     2        1   26   0.3419
>>> 192    7     2        1   26   0.4188
>>> 193    8     2        1   26   0.3199
>>> 194    9     2        1   26   0.2889
>>> 195    1     1        2   29   1.2765
>>> 196    2     1        2   29   1.0653
>>> 197    3     1        2   29   1.5607
>>> 198    1     1        1   30   0.8641
>>> 199    2     1        1   30   0.9250
>>> 200    3     1        1   30   1.0887
>>> 201    4     1        1   30   0.5537
>>> 202    5     1        1   30   0.7930
>>> 203    6     1        1   30   0.3960
>>> 204    7     1        1   30   0.3917
>>> 205    8     1        1   30   1.2687
>>> 206    9     1        1   30   0.5328
>>> 207    1     2        1   31   1.0765
>>> 208    2     2        1   31   0.8778
>>> 209    3     2        1   31   0.8228
>>> 210    4     2        1   31   1.2017
>>> 211    5     2        1   31   1.1787
>>> 212    6     2        1   31   0.4037
>>> 213    7     2        1   31   0.2625
>>> 214    8     2        1   31   2.2690
>>> 215    9     2        1   31   0.4423
>>> 216    1     1        2   32   1.2880
>>> 217    2     1        2   32   0.8537
>>>
>>> On Fri, Feb 3, 2012 at 9:25 AM, Baldwin, Jim -FS 
>>> <jbaldwin at fs.fed.us>
>>> wrote:
>>>
>>> > I think the only way to resolve this is to provide a specific example.
>>> >
>>> > Jim Baldwin
>>> > Station Statistician
>>> > USDA Forest Service
>>> > Albany, California
>>> >
>>> > -----Original Message-----
>>> > From: r-sig-mixed-models-bounces at r-project.org [mailto:
>>> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles
>>> Determan Jr
>>> > Sent: Friday, February 03, 2012 7:18 AM
>>> > To: Thompson,Paul; r-sig-mixed-models at r-project.org
>>> > Subject: Re: [R-sig-ME] lme capable of running with missing data?
>>> >
>>> > So, is there a way in which I can alter the design matrix so the 
>>> > mixed model will work or is this something that can only be done 
>>> > in SAS currently?  The output from the SAS run did provide Type 
>>> > III fixed
>>> effect
>>> > test values.
>>> >
>>> > On Fri, Feb 3, 2012 at 9:14 AM, Thompson,Paul < 
>>> > Paul.Thompson at sanfordhealth.org> wrote:
>>> >
>>> > >  That's interesting. SAS uses the sweep approach (it was in fact 
>>> > > devised by Goodnight). The method used in construction of 
>>> > > various types of SS does allow you to estimate when cells are 
>>> > > missing. I
>>> would
>>> > > wonder if Type II SS can be done. Type III (despite the 
>>> > > incorrect statement that they are
>>> > > illegitimate) and Type IV would work fine. ****
>>> > >
>>> > > ** **
>>> > >
>>> > > It's really an issue of the manner in which the design matrix is
>>> > > contructed.****
>>> > >
>>> > > ** **
>>> > >
>>> > > *From:* Charles Determan Jr [mailto:deter088 at umn.edu]
>>> > > *Sent:* Friday, February 03, 2012 8:36 AM
>>> > > *To:* Thompson,Paul; r-sig-mixed-models at r-project.org
>>> > > *Subject:* Re: [R-sig-ME] lme capable of running with missing
>>> > > data?****
>>> > >
>>> > > ** **
>>> > >
>>> > > Thank you Paul, I do appreciate your response and especially 
>>> > > your
>>> time.
>>> > > The reason I am so persistent is that I know the prior data I 
>>> > > posted was run in SAS (however I don't have the exact coding 
>>> > > although I do know it was done with PROC MIXED with an 
>>> > > unstructured covariance structure and REML estimation method) 
>>> > > and it provided all the interactions.  As such, I have scoured 
>>> > > the web and literature as to how this could be done with the 
>>> > > missing data (timepoints as a result of survival).  Perhaps this 
>>> > > simply has not yet been done in R and I
>>> am
>>> > > stuck for the time being.  None-the-less, I want to be certain
>>> before I
>>> > give up on running this type of analysis in R.
>>> > >
>>> > > Thanks again,****
>>> > >
>>> > > On Fri, Feb 3, 2012 at 8:26 AM, Thompson,Paul < 
>>> > > Paul.Thompson at sanfordhealth.org> wrote:****
>>> > >
>>> > > Charles:
>>> > >
>>> > > I did suggest the use of specific contrasts to do the analysis 
>>> > > with missing cells. I played around, and just have to admit that 
>>> > > this is not possible. I tried to use standard construction 
>>> > > techniques to produce main effects using contrast coding, and 
>>> > > then multiply those
>>> to
>>> > > produce interactions. This does not work. It may be possible to 
>>> > > use orthonormalization and the sweep operator to produce a 
>>> > > consistent estimator, but I ran out of time to work on this.
>>> > >
>>> > > What you can do is convert the design to a single factor, and do 
>>> > > the analysis with specific contrasts, recognizing that this will 
>>> > > not enable you to get to specific things like interaction 
>>> > > effects. To understand why, consider the situation with a 2 x 2, 
>>> > > where one cell
>>> is
>>> > entirely missing.
>>> > > You have lost 1 df for the design, and the interaction is 
>>> > > entirely
>>> > missing.
>>> > > You can estimate and test specific contrasts, but you can't even 
>>> > > really test the A factor or the B factor. If Cell(2,2) is 
>>> > > missing,
>>> you
>>> > > can test Cell (1,1) v Cell(1,2) and you can test Cell (2,1) v 
>>> > > Cell (1,1), but neither of these is the test of the "main 
>>> > > effect" of A or B. When you have larger designs with 2 or 3 
>>> > > factors, the comparisons again have fewer df than should be 
>>> > > encountered. This means that the interactions are not defined
properly.
>>> > >
>>> > > Do you NEED the interactions for theoretical purposes, or are 
>>> > > they there simply for completedness? Are the cells missing due 
>>> > > to your design or due to happenstance?
>>> > >
>>> > > It is the case that fractional factorial designs eliminate cells 
>>> > > from the design to estimate main effects and losing the ability 
>>> > > to
>>> estimate
>>> > > interactions. So, missing cells, when planned for appropriately, 
>>> > > can result in appropriate analysis. I am not sure how to run 
>>> > > mixed models with fractional factorials, however.****
>>> > >
>>> > >
>>> > > -----Original Message-----
>>> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
>>> > > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles 
>>> > > Determan Jr
>>> > > Sent: Friday, February 03, 2012 7:06 AM
>>> > > To: r-sig-mixed-models at r-project.org
>>> > > Subject: [R-sig-ME] lme capable of running with missing data?
>>> > >
>>> > > Greetings,
>>> > >
>>> > > Some of you may recognize my name from a few related posts but I 
>>> > > just have general question that perhaps can be clarified.  I 
>>> > > have read several times that 'lme' and 'lmer' are techniques 
>>> > > capable of running data sets with missing values.  Is this true?  
>>> > > I have put up similar posts where when I try to run a two or 
>>> > > three way interaction mixed model I get an error of 
>>> > > singularities or X'X not positive.  Does the data set need to be 
>>> > > formatted in some way where the mixed model can
>>> be
>>> > run with all interactions?
>>> > > Furthermore, if the missing values are 'not missing at random' 
>>> > > is there another method to follow for generating the mixed 
>>> > > model?  I am just confused why I see posts that lme can be run 
>>> > > when data is
>>> missing.
>>> > >
>>> > > Regards,****
>>> > >
>>> > >        [[alternative HTML version deleted]]
>>> > >
>>> > > _______________________________________________
>>> > > R-sig-mixed-models at r-project.org mailing list 
>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> > >
>>> > >
>>> --------------------------------------------------------------------
>>> --
>>> > > - Confidentiality Notice: This e-mail message, including any 
>>> > > attachments, is for the sole use of the intended recipient(s) 
>>> > > and may contain privileged and confidential information.  Any 
>>> > > unauthorized review, use, disclosure or distribution is 
>>> > > prohibited.  If you are
>>> not
>>> > > the intended recipient, please contact the sender by reply 
>>> > > e-mail and destroy all copies of the original message.****
>>> > >
>>> > > ** **
>>> > >
>>> > >
>>> > >
>>> --------------------------------------------------------------------
>>> --
>>> > > - Confidentiality Notice: This e-mail message, including any 
>>> > > attachments, is for the sole use of the intended recipient(s) 
>>> > > and may contain privileged and confidential information. Any 
>>> > > unauthorized review, use, disclosure or distribution is 
>>> > > prohibited. If you are not the intended recipient, please 
>>> > > contact the sender by reply e-mail and destroy all copies of the
original message.
>>> > >
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> >
>>> >
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> Kevin Wright
>>
>>
>


--
Kevin Wright

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From joerg.luedicke at gmail.com  Fri Feb  3 19:54:42 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Fri, 3 Feb 2012 13:54:42 -0500
Subject: [R-sig-ME] GLMM with lme4/ marginal predictions
Message-ID: <CAEn158Ri+=q5xJKyMNNuXN5aBtbTJ+J9Gd4sK_yOMCS8H9BOpQ@mail.gmail.com>

Hi everybody,

I have a (overdispersed) Poisson GLMM  and would like to calculate
marginal predictions while taking random effects into account. To do
that, I am following a simulation based approach which is briefly
described in the technical appendix of the following paper by David
Atkins and colleagues (p. 26):

http://depts.washington.edu/cshrb/newweb/stats%20documents/Draft.Longitudinal.Regression.pdf

The basic idea is to draw N number of samples from the posterior
distributions of the random effects and then averaging the predictions
over all N realizations of the data. So far so good. My problem is now
that I would like to get marginal counts from a model that, besides
including my main variable of interest, includes other covariates as
well. Now, if I would just doing predictions from fixed effects, I
would just average the predictions across my data. However, I cannot
think of a way to average across the random draws from the posterior
random effects distributions _and_ averaging predictions across my
data at the same time? That is, integrating out the random effects
_and_ integrating predictions over other covariates.

I was hoping that somebody here may have done something similar in the
past and could give me a hint?


To be a bit more concrete, I will post some code to illustrate the problem:

My data are yearly observations (5 years) from (~900) schools that are
nested within (~170) school districts.
So, a model with only my independent variable of interest (hfc2) could
look like this:

model.1=glmer(paidcount ~ hfc2  +
    (1|obs_effect) + (1+hfc2|school.id) + (1+hfc2|dist.id), family="poisson",
    offset=log(offspaid0), verbose=FALSE, data=mc1)

What follows is the code to draw from the posterior random effects
distributions and averaging predictions across draws:

(This code is mostly adopted from the above mentioned paper's
accompanying webpage:
http://depts.washington.edu/cshrb/newweb/stats%20documents/Rcode2011.R )

#-------------START-----------#

### Number of simulations
M <- 10000

### Fixed-effect estimates
beta <- fixef(model.1)

### Variance-covariance information
vc <- VarCorr(model.1)

### Pull-out over-dispersion term (as SD)
sdover <- as.numeric(attr(vc$obs_effect, "stddev"))

### Pull-out var-cov of random-effects as matrix (school level)
sdid.school <- as.matrix(vc$school.id)[1:2, 1:2]

### Pull-out var-cov of random-effects as matrix (district level)
sdid.dist <- as.matrix(vc$dist.id)[1:2, 1:2]

### Generate M random draws from variances
rover <- rnorm(M, sd = sdover)
rid1 <- mvrnorm(M, mu = rep(0,2), Sigma = sdid.school)
rid2 <- mvrnorm(M, mu = rep(0,2), Sigma = sdid.dist)

### Get predictions including fixed-effects as well as M
### simulations from random-effects (and averaging)

mean.offset=mean(mc1$offspaid0) #for multiplication with exponentiated baseline

marg.nohfc <- mean(exp(beta[1])*mean.offset * #baseline
              exp(rover + rid1 + rid2 ))

marg.hfc <- mean(exp(beta[1])*mean.offset * #baseline
              exp(beta[2] + #covariate
              rover + rid1 + rid2 ))

#Displaying marginal counts
round(cbind(marg.hfc.el, marg.nohfc.el), 2)

#-------------END-----------#

At this point, I get the marginal counts for my independent (binary)
variable. I am just not sure how to average predictions across my data
as well, if I have other covariates in the model?

Any help is much appreciated!

Joerg



From kfrost at wisc.edu  Sat Feb  4 02:45:14 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Fri, 03 Feb 2012 19:45:14 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
	<CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>
	<75e0d743133e90.4f2c8d0f@wiscmail.wisc.edu>
	<767093351351e8.4f2c8d4d@wiscmail.wisc.edu>
	<7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
Message-ID: <7620a004131150.4f2c394a@wiscmail.wisc.edu>

On 02/03/12, Charles Determan Jr   wrote:
> Kevin,
> 
> I understand that but then how is SAS accomplishing the interactions?


I have been following this conversation a little bit and this seems to be the right question to ask. I would also like to know the answer. However, this could be the wrong venue to get an answer to this question.

?
> On Fri, Feb 3, 2012 at 10:58 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> 
> > Charles,
> >
> > Here's a simple thought example.  Use a piece of graph paper (or just a
> > simple sketch).  Write the following letters at the coordinates specified:
> >
> > A1  (1,1)
> > A2 (3,2)
> > B1 (1,2)
> > B2 (missing)
> >
> > Draw a line from A1 to A2.  Imagine a line from B1 to the missing value of
> > B2.
> >
> > By looking at this, you could calculate an overall mean for the A factor.
> > You could also estimate an overall mean for the B factor, if you assume the
> > lines are parallel.  This is what happens with fixed effects, as in lme (
> > ... A + B, ...).
> > But, when you specify lme(... A*B, ...) which is the same as lme(... A + B
> > + A:B, ...), you are essentially saying to the computer, "The A1-A2 and
> > B1-B2 lines are not parallel, but please give me an estimate of the slope
> > of the B1-B2 line."
> >
> > Could _you_ draw the B1-B2 line?  No.  Neither can lme.
> >
> > It's okay that B2 is missing if you don't want to fit an interaction, but
> > when B2 is missing, there is no way to estimate an interaction
> > (non-parallel slope).
> >
> > Kevin
> >
> >
> >
> >
> >
> >
> > On Fri, Feb 3, 2012 at 10:18 AM, Charles Determan Jr <deter088 at umn.edu>wrote:
> >
> >> After the data is input, and factors are assigned,
> >>
> >> model=lme(arginine~group*time*survival, random=~1|subj, method="REML",
> >> data=x)
> >>
> >> Error in MEEM(object, conLin, control$niterEM) : Singularity in backsolve
> >> at level 0, block 1
> >>
> >>
> >>
> >> On Fri, Feb 3, 2012 at 10:01 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> >>
> >>> Providing the data is not a "reproducible example".  Complete data and
> >>> R-code are helpful.
> >>>
> >>> Kevin
> >>>
> >>>
> >>>
> >>> On Fri, Feb 3, 2012 at 9:31 AM, Charles Determan Jr <deter088 at umn.edu>wrote:
> >>>
> >>>> Here is the dataset, everything should be run as a factor except 'met'
> >>>> which is numeric.  Thanks for the assistance,
> >>>>
> >>>>    time group survival subj met
> >>>> 1      1     2        1      2   1.3954
> >>>> 2      2     2        1      2   1.8063
> >>>> 3      3     2        1      2   1.3684
> >>>> 4      4     2        1      2   2.0046
> >>>> 5      5     2        1      2   1.0334
> >>>> 6      6     2        1      2   0.3644
> >>>> 7      7     2        1      2   0.4819
> >>>> 8      8     2        1      2   1.4558
> >>>> 9      9     2        1     2   0.9718
> >>>> 10     1     1        2    5   0.7771
> >>>> 11     2     1        2    5   1.2439
> >>>> 12     1     2        2    8   1.0980
> >>>> 13     2     2        2    8   0.9511
> >>>> 14     1     2        1    9   1.0534
> >>>> 15     2     2        1    9   1.7279
> >>>> 16     3     2        1    9   1.4904
> >>>> 17     4     2        1    9   1.2737
> >>>> 18     5     2        1    9   0.8929
> >>>> 19     6     2        1    9   0.5828
> >>>> 20     7     2        1    9   0.3260
> >>>> 21     8     2        1    9   1.0373
> >>>> 22     9     2        1    9   0.9624
> >>>> 23     1     2        2   10   1.1391
> >>>> 24     2     2        2   10   1.3945
> >>>> 25     3     2        2   10   0.9414
> >>>> 26     4     2        2   10   1.1152
> >>>> 27     5     2        2   10   0.8222
> >>>> 28     6     2        2   10   0.4417
> >>>> 29     7     2        2   10   0.4126
> >>>> 30     1     1        1   12   1.3024
> >>>> 31     2     1        1   12   1.1811
> >>>> 32     3     1        1   12   0.9379
> >>>> 33     4     1        1   12   1.3000
> >>>> 34     5     1        1   12   1.2977
> >>>> 35     6     1        1   12   0.4949
> >>>> 36     7     1        1   12   0.5238
> >>>> 37     8     1        1   12   1.3862
> >>>> 38     1     1        1   16   1.2259
> >>>> 39     2     1        1   16   0.8681
> >>>> 40     3     1        1   16   1.2645
> >>>> 41     4     1        1   16   0.7316
> >>>> 42     5     1        1   16   0.6648
> >>>> 43     6     1        1   16   0.9671
> >>>> 44     7     1        1   16   1.0131
> >>>> 45     8     1        1   16   1.1762
> >>>> 46     9     1        1   16   0.8776
> >>>> 47     1     2        2   18   1.1231
> >>>> 48     2     2        2   18   1.2133
> >>>> 49     3     2        2   18   1.2005
> >>>> 50     4     2        2   18   0.7198
> >>>> 51     5     2        2   18   0.6620
> >>>> 52     6     2        2   18   0.5908
> >>>> 53     7     2        2   18   0.3945
> >>>> 54     1     2        2   19   0.7852
> >>>> 55     2     2        2   19   0.6758
> >>>> 56     3     2        2   19   0.5246
> >>>> 57     4     2        2   19   0.5263
> >>>> 58     1     2        2   20   1.2284
> >>>> 59     2     2        2   20   0.7017
> >>>> 60     1     2        1   23   0.9604
> >>>> 61     2     2        1   23   0.7977
> >>>> 62     3     2        1   23   1.2267
> >>>> 63     4     2        1   23   1.3857
> >>>> 64     5     2        1   23   0.9486
> >>>> 65     6     2        1   23   0.3571
> >>>> 66     7     2        1   23   0.3134
> >>>> 67     8     2        1   23   1.9984
> >>>> 68     9     2        1   23   0.4837
> >>>> 69     1     1        1   24   1.1793
> >>>> 70     2     1        1   24   1.3883
> >>>> 71     3     1        1   24   2.1080
> >>>> 72     4     1        1   24   0.8810
> >>>> 73     5     1        1   24   0.8825
> >>>> 74     6     1        1   24   0.4124
> >>>> 75     7     1        1   24   0.5270
> >>>> 76     8     1        1   24   1.9003
> >>>> 77     9     1        1   24   1.4344
> >>>> 78     1     1        1   27   1.1905
> >>>> 79     2     1        1   27   1.1033
> >>>> 80     3     1        1   27   1.4976
> >>>> 81     4     1        1   27   1.9018
> >>>> 82     5     1        1   27   0.5815
> >>>> 83     6     1        1   27   0.4428
> >>>> 84     7     1        1   27   0.4728
> >>>> 85     8     1        1   27   1.6309
> >>>> 86     9     1        1   27   0.4054
> >>>> 87     1     1        1   28   0.9538
> >>>> 88     2     1        1   28   0.7796
> >>>> 89     3     1        1   28   1.7906
> >>>> 90     5     1        1   28   0.4715
> >>>> 91     6     1        1   28   0.4214
> >>>> 92     7     1        1   28   0.4120
> >>>> 93     8     1        1   28   1.3111
> >>>> 94     9     1        1   28   0.3677
> >>>> 95     1     1        2    1   1.3853
> >>>> 96     2     1        2    1   1.5966
> >>>> 97     3     1        2    1   1.4542
> >>>> 98     4     1        2    1   1.3084
> >>>> 99     5     1        2    1   1.2826
> >>>> 100    6     1        2    1   0.6835
> >>>> 101    7     1        2    1   0.9709
> >>>> 102    1     1        1    3   1.3175
> >>>> 103    2     1        1    3   0.7792
> >>>> 104    3     1        1    3   1.8763
> >>>> 105    5     1        1    3   1.4633
> >>>> 106    6     1        1    3   0.0735
> >>>> 107    7     1        1    3   0.5612
> >>>> 108    8     1        1    3   1.3777
> >>>> 109    9     1        1    3   0.3810
> >>>> 110    1     1        2    4   1.3486
> >>>> 111    1     1        1    6   1.2635
> >>>> 112    2     1        1    6   0.7572
> >>>> 113    3     1        1    6   1.5011
> >>>> 114    5     1        1    6   0.6873
> >>>> 115    6     1        1    6   0.3778
> >>>> 116    7     1        1    6   0.4231
> >>>> 117    8     1        1    6   1.3817
> >>>> 118    9     1        1    6   0.5850
> >>>> 119    1     2        2    7   0.7362
> >>>> 120    2     2        2    7   0.5495
> >>>> 121    3     2        2    7   0.7621
> >>>> 122    4     2        2    7   0.8421
> >>>> 123    5     2        2    7   1.0438
> >>>> 124    6     2        2    7   0.9802
> >>>> 125    7     2        2    7   0.5627
> >>>> 126    1     1        1   11   1.5575
> >>>> 127    2     1        1   11   2.1356
> >>>> 128    3     1        1   11   1.3575
> >>>> 129    4     1        1   11   1.3056
> >>>> 130    5     1        1   11   0.8144
> >>>> 131    6     1        1   11   0.5876
> >>>> 132    7     1        1   11   0.4104
> >>>> 133    9     1        1   11   0.4942
> >>>> 134    1     2        1   13   1.0046
> >>>> 135    2     2        1   13   0.8805
> >>>> 136    3     2        1   13   0.7685
> >>>> 137    4     2        1   13   0.8786
> >>>> 138    5     2        1   13   1.4249
> >>>> 139    6     2        1   13   0.5339
> >>>> 140    7     2        1   13   0.5480
> >>>> 141    8     2        1   13   2.6369
> >>>> 142    9     2        1   13   1.7159
> >>>> 143    1     2        1   14   0.7161
> >>>> 144    2     2        1   14   0.3968
> >>>> 145    3     2        1   14   0.8142
> >>>> 146    4     2        1   14   0.6140
> >>>> 147    5     2        1   14   0.6585
> >>>> 148    6     2        1   14   0.7176
> >>>> 149    7     2        1   14   0.6613
> >>>> 150    8     2        1   14   1.6494
> >>>> 151    9     2        1   14   0.3903
> >>>> 152    1     1        1   15   1.4357
> >>>> 153    2     1        1   15   1.4772
> >>>> 154    3     1        1   15   1.3156
> >>>> 155    4     1        1   15   0.9654
> >>>> 156    5     1        1   15   1.2709
> >>>> 157    6     1        1   15   0.9330
> >>>> 158    7     1        1   15   0.3515
> >>>> 159    8     1        1   15   1.6801
> >>>> 160    9     1        1   15   0.3584
> >>>> 161    1     2        2   17   0.8077
> >>>> 162    2     2        2   17   0.7560
> >>>> 163    1     1        1   21   1.1890
> >>>> 164    2     1        1   21   0.9631
> >>>> 165    3     1        1   21   0.9753
> >>>> 166    4     1        1   21   0.9519
> >>>> 167    5     1        1   21   0.6348
> >>>> 168    6     1        1   21   0.8516
> >>>> 169    7     1        1   21   0.2366
> >>>> 170    8     1        1   21   1.0440
> >>>> 171    9     1        1   21   0.5360
> >>>> 172    1     2        1   22   1.0747
> >>>> 173    2     2        1   22   0.6451
> >>>> 174    3     2        1   22   0.8408
> >>>> 175    5     2        1   22   0.8730
> >>>> 176    6     2        1   22   0.3594
> >>>> 177    7     2        1   22   0.3019
> >>>> 178    9     2        1   22   1.2053
> >>>> 179    1     2        2   25   0.4654
> >>>> 180    2     2        2   25   0.3024
> >>>> 181    3     2        2   25   0.7525
> >>>> 182    4     2        2   25   0.7808
> >>>> 183    5     2        2   25   0.6294
> >>>> 184    6     2        2   25   0.3016
> >>>> 185    7     2        2   25   0.3223
> >>>> 186    1     2        1   26   0.5363
> >>>> 187    2     2        1   26   0.2279
> >>>> 188    3     2        1   26   0.4756
> >>>> 189    4     2        1   26   0.6644
> >>>> 190    5     2        1   26   0.6631
> >>>> 191    6     2        1   26   0.3419
> >>>> 192    7     2        1   26   0.4188
> >>>> 193    8     2        1   26   0.3199
> >>>> 194    9     2        1   26   0.2889
> >>>> 195    1     1        2   29   1.2765
> >>>> 196    2     1        2   29   1.0653
> >>>> 197    3     1        2   29   1.5607
> >>>> 198    1     1        1   30   0.8641
> >>>> 199    2     1        1   30   0.9250
> >>>> 200    3     1        1   30   1.0887
> >>>> 201    4     1        1   30   0.5537
> >>>> 202    5     1        1   30   0.7930
> >>>> 203    6     1        1   30   0.3960
> >>>> 204    7     1        1   30   0.3917
> >>>> 205    8     1        1   30   1.2687
> >>>> 206    9     1        1   30   0.5328
> >>>> 207    1     2        1   31   1.0765
> >>>> 208    2     2        1   31   0.8778
> >>>> 209    3     2        1   31   0.8228
> >>>> 210    4     2        1   31   1.2017
> >>>> 211    5     2        1   31   1.1787
> >>>> 212    6     2        1   31   0.4037
> >>>> 213    7     2        1   31   0.2625
> >>>> 214    8     2        1   31   2.2690
> >>>> 215    9     2        1   31   0.4423
> >>>> 216    1     1        2   32   1.2880
> >>>> 217    2     1        2   32   0.8537
> >>>>
> >>>> On Fri, Feb 3, 2012 at 9:25 AM, Baldwin, Jim -FS <jbaldwin at fs.fed.us>
> >>>> wrote:
> >>>>
> >>>> > I think the only way to resolve this is to provide a specific example.
> >>>> >
> >>>> > Jim Baldwin
> >>>> > Station Statistician
> >>>> > USDA Forest Service
> >>>> > Albany, California
> >>>> >
> >>>> > -----Original Message-----
> >>>> > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> >>>> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles
> >>>> Determan Jr
> >>>> > Sent: Friday, February 03, 2012 7:18 AM
> >>>> > To: Thompson,Paul; r-sig-mixed-models at r-project.org
> >>>> > Subject: Re: [R-sig-ME] lme capable of running with missing data?
> >>>> >
> >>>> > So, is there a way in which I can alter the design matrix so the mixed
> >>>> > model will work or is this something that can only be done in SAS
> >>>> > currently?  The output from the SAS run did provide Type III fixed
> >>>> effect
> >>>> > test values.
> >>>> >
> >>>> > On Fri, Feb 3, 2012 at 9:14 AM, Thompson,Paul <
> >>>> > Paul.Thompson at sanfordhealth.org> wrote:
> >>>> >
> >>>> > >  That's interesting. SAS uses the sweep approach (it was in fact
> >>>> > > devised by Goodnight). The method used in construction of various
> >>>> > > types of SS does allow you to estimate when cells are missing. I
> >>>> would
> >>>> > > wonder if Type II SS can be done. Type III (despite the incorrect
> >>>> > > statement that they are
> >>>> > > illegitimate) and Type IV would work fine. ****
> >>>> > >
> >>>> > > ** **
> >>>> > >
> >>>> > > It's really an issue of the manner in which the design matrix is
> >>>> > > contructed.****
> >>>> > >
> >>>> > > ** **
> >>>> > >
> >>>> > > *From:* Charles Determan Jr [mailto:deter088 at umn.edu](javascript:main.compose()
> >>>> > > *Sent:* Friday, February 03, 2012 8:36 AM
> >>>> > > *To:* Thompson,Paul; r-sig-mixed-models at r-project.org
> >>>> > > *Subject:* Re: [R-sig-ME] lme capable of running with missing
> >>>> > > data?****
> >>>> > >
> >>>> > > ** **
> >>>> > >
> >>>> > > Thank you Paul, I do appreciate your response and especially your
> >>>> time.
> >>>> > > The reason I am so persistent is that I know the prior data I posted
> >>>> > > was run in SAS (however I don't have the exact coding although I do
> >>>> > > know it was done with PROC MIXED with an unstructured covariance
> >>>> > > structure and REML estimation method) and it provided all the
> >>>> > > interactions.  As such, I have scoured the web and literature as to
> >>>> > > how this could be done with the missing data (timepoints as a result
> >>>> > > of survival).  Perhaps this simply has not yet been done in R and I
> >>>> am
> >>>> > > stuck for the time being.  None-the-less, I want to be certain
> >>>> before I
> >>>> > give up on running this type of analysis in R.
> >>>> > >
> >>>> > > Thanks again,****
> >>>> > >
> >>>> > > On Fri, Feb 3, 2012 at 8:26 AM, Thompson,Paul <
> >>>> > > Paul.Thompson at sanfordhealth.org> wrote:****
> >>>> > >
> >>>> > > Charles:
> >>>> > >
> >>>> > > I did suggest the use of specific contrasts to do the analysis with
> >>>> > > missing cells. I played around, and just have to admit that this is
> >>>> > > not possible. I tried to use standard construction techniques to
> >>>> > > produce main effects using contrast coding, and then multiply those
> >>>> to
> >>>> > > produce interactions. This does not work. It may be possible to use
> >>>> > > orthonormalization and the sweep operator to produce a consistent
> >>>> > > estimator, but I ran out of time to work on this.
> >>>> > >
> >>>> > > What you can do is convert the design to a single factor, and do the
> >>>> > > analysis with specific contrasts, recognizing that this will not
> >>>> > > enable you to get to specific things like interaction effects. To
> >>>> > > understand why, consider the situation with a 2 x 2, where one cell
> >>>> is
> >>>> > entirely missing.
> >>>> > > You have lost 1 df for the design, and the interaction is entirely
> >>>> > missing.
> >>>> > > You can estimate and test specific contrasts, but you can't even
> >>>> > > really test the A factor or the B factor. If Cell(2,2) is missing,
> >>>> you
> >>>> > > can test Cell (1,1) v Cell(1,2) and you can test Cell (2,1) v Cell
> >>>> > > (1,1), but neither of these is the test of the "main effect" of A or
> >>>> > > B. When you have larger designs with 2 or 3 factors, the comparisons
> >>>> > > again have fewer df than should be encountered. This means that the
> >>>> > > interactions are not defined properly.
> >>>> > >
> >>>> > > Do you NEED the interactions for theoretical purposes, or are they
> >>>> > > there simply for completedness? Are the cells missing due to your
> >>>> > > design or due to happenstance?
> >>>> > >
> >>>> > > It is the case that fractional factorial designs eliminate cells
> >>>> from
> >>>> > > the design to estimate main effects and losing the ability to
> >>>> estimate
> >>>> > > interactions. So, missing cells, when planned for appropriately, can
> >>>> > > result in appropriate analysis. I am not sure how to run mixed
> >>>> models
> >>>> > > with fractional factorials, however.****
> >>>> > >
> >>>> > >
> >>>> > > -----Original Message-----
> >>>> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> >>>> > > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles
> >>>> > > Determan Jr
> >>>> > > Sent: Friday, February 03, 2012 7:06 AM
> >>>> > > To: r-sig-mixed-models at r-project.org
> >>>> > > Subject: [R-sig-ME] lme capable of running with missing data?
> >>>> > >
> >>>> > > Greetings,
> >>>> > >
> >>>> > > Some of you may recognize my name from a few related posts but I
> >>>> just
> >>>> > > have general question that perhaps can be clarified.  I have read
> >>>> > > several times that 'lme' and 'lmer' are techniques capable of
> >>>> running
> >>>> > > data sets with missing values.  Is this true?  I have put up similar
> >>>> > > posts where when I try to run a two or three way interaction mixed
> >>>> > > model I get an error of singularities or X'X not positive.  Does the
> >>>> > > data set need to be formatted in some way where the mixed model can
> >>>> be
> >>>> > run with all interactions?
> >>>> > > Furthermore, if the missing values are 'not missing at random' is
> >>>> > > there another method to follow for generating the mixed model?  I am
> >>>> > > just confused why I see posts that lme can be run when data is
> >>>> missing.
> >>>> > >
> >>>> > > Regards,****
> >>>> > >
> >>>> > >        [[alternative HTML version deleted]]
> >>>> > >
> >>>> > > _______________________________________________
> >>>> > > R-sig-mixed-models at r-project.org mailing list
> >>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>> > >
> >>>> > >
> >>>> ----------------------------------------------------------------------
> >>>> > > - Confidentiality Notice: This e-mail message, including any
> >>>> > > attachments, is for the sole use of the intended recipient(s) and
> >>>> may
> >>>> > > contain privileged and confidential information.  Any unauthorized
> >>>> > > review, use, disclosure or distribution is prohibited.  If you are
> >>>> not
> >>>> > > the intended recipient, please contact the sender by reply e-mail
> >>>> and
> >>>> > > destroy all copies of the original message.****
> >>>> > >
> >>>> > > ** **
> >>>> > >
> >>>> > >
> >>>> > >
> >>>> ----------------------------------------------------------------------
> >>>> > > - Confidentiality Notice: This e-mail message, including any
> >>>> > > attachments, is for the sole use of the intended recipient(s) and
> >>>> may
> >>>> > > contain privileged and confidential information. Any unauthorized
> >>>> > > review, use, disclosure or distribution is prohibited. If you are
> >>>> not
> >>>> > > the intended recipient, please contact the sender by reply e-mail
> >>>> and
> >>>> > > destroy all copies of the original message.
> >>>> > >
> >>>> >
> >>>> >         [[alternative HTML version deleted]]
> >>>> >
> >>>> >
> >>>> >
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>>
> >>>
> >>> --
> >>> Kevin Wright
> >>>
> >>>
> >>
> >
> >
> > --
> > Kevin Wright
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r.turner at auckland.ac.nz  Sat Feb  4 03:20:45 2012
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 04 Feb 2012 15:20:45 +1300
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <7620a004131150.4f2c394a@wiscmail.wisc.edu>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>	<CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>	<75e0d743133e90.4f2c8d0f@wiscmail.wisc.edu>	<767093351351e8.4f2c8d4d@wiscmail.wisc.edu>	<7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
	<7620a004131150.4f2c394a@wiscmail.wisc.edu>
Message-ID: <4F2C95FD.3040405@auckland.ac.nz>

On 04/02/12 14:45, Kenneth Frost wrote:
> On 02/03/12, Charles Determan Jr   wrote:
>> Kevin,
>>
>> I understand that but then how is SAS accomplishing the interactions?
>
> I have been following this conversation a little bit and this seems to be the right question to ask. I would also like to know the answer. However, this could be the wrong venue to get an answer to this question.
<SNIP>

It may be the case that fortune(203) is relevant here! :-)

     cheers,

         Rolf Turner



From stat.list at yahoo.co.uk  Sun Feb  5 19:41:14 2012
From: stat.list at yahoo.co.uk (Rachel Cohen)
Date: Sun, 5 Feb 2012 18:41:14 +0000 (GMT)
Subject: [R-sig-ME] cross-validation of linear mixed effect models
Message-ID: <1328467274.87331.YahooMailNeo@web132202.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120205/e3a1b264/attachment-0001.pl>

From Mike.Lawrence at dal.ca  Sun Feb  5 19:55:10 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sun, 5 Feb 2012 14:55:10 -0400
Subject: [R-sig-ME] cross-validation of linear mixed effect models
In-Reply-To: <1328467274.87331.YahooMailNeo@web132202.mail.ird.yahoo.com>
References: <1328467274.87331.YahooMailNeo@web132202.mail.ird.yahoo.com>
Message-ID: <CAB+QPJDEbO_XjoexgC1miDYWapJfCy27uF9LLr2CY25cXH87pw@mail.gmail.com>

One thought is that according to Fang (2011,
http://www.jds-online.com/file_download/278/JDS-652a.pdf), AIC for a
mixed effects model is asymptotically equivalent to
leave-one-cluster-out cross-validation, so possibly you already have a
metric of cross-validated prediction accuracy in your AIC scores. Now
that I think of it though, I see Fang makes a distinction between
marginal vs conditional AIC, and I'm not sure though which is
implemented when you submit an lmer model to the AIC() function in R.
Also, I'm not sure if the use of REML in fitting the model affects the
equivalence asserted by Fang; certainly I've been advised on this list
before that if I want to compare nested models on AIC scores, I needed
to ensure that REML=F in the fitted models.


On Sun, Feb 5, 2012 at 2:41 PM, Rachel Cohen <stat.list at yahoo.co.uk> wrote:
> Hi, I am a PhD student who is using mixed effect models (and R) for the first time so apologies if my question is a bit basic.? I also haven't used this forum much so if this topic has already been covered in depth in the past and there is an easy answer out there that I've missed then additional apologies!
>
> I am using a linear mixed model (structure as below) to predict total tree biomass (log.mass) using tree diameter (dbh) and height as explanatory variables, allowing the intercept and the slope of height to vary by my grouping factor (species_site).
>
> Model:
>
> lmer((log.mass)~centre.log.dbh+centre.log.height+(1+centre.log.height|species_site),data=data3,REML=T)
>
> This model structure was chosen as 'the best' primarily on the basis of AIC value.?? Residual plots look fairly OK.
>
> I would now like to check the predictive performance of my model (by cross-validation?) and wonder how to go about this in the context of a linear mixed effect model?.? Is there a package/function in R which deals with this?
>
> Any advice on how to proceed would be greatly appreciated!
>
> Regards,
>
> Rachel Cohen
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From tahtg6 at gmail.com  Mon Feb  6 02:49:17 2012
From: tahtg6 at gmail.com (Tiffanie Cross)
Date: Sun, 5 Feb 2012 17:49:17 -0800
Subject: [R-sig-ME] lmer blocking by subject?
Message-ID: <CALBCd4h+6u1a5fFkQ1uATGPZRQ4KxGC68WYE7rDm5M0gjUR4Mg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120205/32cf47f4/attachment-0001.pl>

From bbolker at gmail.com  Mon Feb  6 04:50:52 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 6 Feb 2012 03:50:52 +0000 (UTC)
Subject: [R-sig-ME] lmer blocking by subject?
References: <CALBCd4h+6u1a5fFkQ1uATGPZRQ4KxGC68WYE7rDm5M0gjUR4Mg@mail.gmail.com>
Message-ID: <loom.20120206T043305-347@post.gmane.org>

Tiffanie Cross <tahtg6 at ...> writes:

> I am new to R and would like some guidance on how to block by subject.
> 
> I collected presence/absence 24 hrs/day for 44 birds, denoted "bird", at 5
> stations, denoted "colony" for the duration of a breeding season. The
> breeding season was broken into biologically relevant time periods (3
> levels), denoted "period". The birds were captured on 2 different colonies,
> 22 on each colony, denoted "homecolony". I also have the variable, "sex". I
> have about 300,000 total observations for these 44 birds. This data is
> temporally auto-correlated because it is VHF radio-telemetry data recorded
> continually throughout the study.

  What is the temporal resolution?  Based on a guess at the length
of the breeding season (60 days), I'm guessing about every 10-12 minutes.
This isn't essential information but would help get a feel for the
data.

   Be aware that modeling temporal autocorrelation in a binary
variable may be a little bit tricky -- there are a variety of
approaches, but none are quite as easy as the way one builds
autocorrelation into a normal-response model, by making the residuals
within blocks multivariate normal with a specified autocorrelation.  A
few possibilities that spring to mind are (1) because there is
presumably no error in the observations themselves, you could
condition on the previous observation (i.e. put it in as a predictor);
(2) aggregate the data to a coarser temporal scale and fit the data as
binomial (e.g.  number of presence/absence values per 2-hour period,
or per day, or some other appropriate period that balances resolution
and lack of autocorrelation); (3) if there are long 'runs' of
presence/absences, aggregate the data down to times when birds entered
or left; (4) [fanciest, but not necessarily worth the trouble or most
appropriate] assume an underlying multivariate normal distribution
that *is* autocorrelated and controls probability of presence
(i.e. a hierarchical model with autocorrelation in the level
below the observation level).
 
> I have a binary response variable, "present", with independent variables
> "sex" at 2 levels, "homecolony" at 2 levels, "colony" at 5 levels, and
> "period" at 3 levels. I would like to incorporate "period", "bird" and
> "colony" as random effects. Fixed effects are "sex" and "homecolony". The
> "bird" variable is what I want the model blocked by.

   Practically speaking, you can't treat period as a random effect --
not enough levels.

> I am trying to answer the following questions: "Are there differences in
> presence between sexes, homecolony, and period?" "Do birds from one
> homecolony differ in their use of other colonies (colony)?"
> 
> I cannot figure out how to specify that I want the model to block by
> subject, i.e. "bird". I have tried incorporating "bird" as a random effect,
> but the degrees of freedom still come out to be close to 300,000 which is
> near the total number of observations. Can anyone show me syntax that will
> incorporate bird as a random effect that the model blocks by subject?

   Where are you seeing the degrees of freedom?
> 
> I tried following examples from Doug Bates' LME4 book, Chapter 4:

> Glmm_FD <- lmer(present ~ 1 + gender + period + homecolony + colony + (1 +
> period|bird), data = FD, family = binomial, REML = 0)
> I know that the (1+period|bird) term is probably incorrect.

  REML=0 is meaningless in this case (lmer doesn't use REML
or an analogue of it when fitting a non-Gaussian model), but
otherwise your model specification seems to be on the right track.

  Since I'm guessing the birds can only be detected at a single
station at a time, this is a bit more of a categorical response
(i.e., is bird X present at colony 1-5 or "none of the above"
at time T?)  Have you thought about multistate mark-recapture
models ... ?

   This seems like a fairly complex problem.  How have others
in your field handled these kinds of data?  With lots of data
on each bird, you may be able to simplify your life a bit by
analyzing each bird separately -- i.e. a two-stage model rather
than a mixed/multilevel model -- Murtaugh 2007 _Ecology_ recommends
this, although I don't always agree with him ...

  I would recommend Zuur et al for messy/complex ecological
data, although I don't agree with all of that either ...



From raquel.benavides at mncn.csic.es  Mon Feb  6 16:34:32 2012
From: raquel.benavides at mncn.csic.es (Raquel Benavides)
Date: Mon, 6 Feb 2012 16:34:32 +0100
Subject: [R-sig-ME] glmmADMB error
Message-ID: <00df01cce4e4$d2d829c0$78887d40$@mncn.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/4e455f6d/attachment-0001.pl>

From bbolker at gmail.com  Mon Feb  6 18:09:11 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 6 Feb 2012 17:09:11 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB error
References: <00df01cce4e4$d2d829c0$78887d40$@mncn.csic.es>
Message-ID: <loom.20120206T180459-92@post.gmane.org>

Raquel Benavides <raquel.benavides at ...> writes:

> Dear all, 
> 
> I am trying to run glmmADMB for the first time to check the effect of some
> fixed effects over the number of seedlings in some plots (my random factors
> are site/transect/plot). However I have some errors. I show what I obtained
> with the simplest model (just one fixed and random variable). See that very
> long assessments, and at the end the error I get. Does anybody understand
> what it means or what does it do? 
> 
> seed_glmmADMB<-glmmadmb(seedling~Tanual+(1|name),data=datos,zeroInflation=TR
> UE,family="poisson")

  [snip]
> 
> Error in run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary =
> !use_tmp_dir,  : 
> 
>   object 'sys.result' not found
> 
> > 
> 
> Hope somebody could tell me what I am doing wrong!!


   Using a slightly out-dated version of glmmADMB that has a bug in it.  
Please update to version 0.7.2.5 ( see <http://glmmadmb.r-forge.r-project.org/>
for detailed instructions if necessary ).

  Ben Bolker



From federico.tettamanti at gmail.com  Mon Feb  6 11:16:19 2012
From: federico.tettamanti at gmail.com (Federico Tettamanti)
Date: Mon, 6 Feb 2012 11:16:19 +0100
Subject: [R-sig-ME] Modeling ecological observations
Message-ID: <CACNpG7tncy=+c9zgCzBV-VozAr3R3c1=PFKEY1Zh6s7zfYztbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/99898fbf/attachment-0001.pl>

From jianyun.fred.wu at gmail.com  Mon Feb  6 20:13:25 2012
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Tue, 7 Feb 2012 06:13:25 +1100
Subject: [R-sig-ME] fixed-effects models or mixed-effects models for
	population data
Message-ID: <CAOMGRD+FPUvBD1h73ggz2JjWs1ACioK4h2mR5KCXY9C9+mFzTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/145a208f/attachment-0001.pl>

From deter088 at umn.edu  Mon Feb  6 22:14:04 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 6 Feb 2012 15:14:04 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <DDC5EC9B78340042B0D5A0C3789D45690E2C1FEF@001FSN2MPN1-016.001f.mgd2.msft.net>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FEF@001FSN2MPN1-016.001f.mgd2.msft.net>
Message-ID: <CAOLJphno5iBKQJLJouSAS1xSvPwnuQZi+TfYreaK-ekXchAEjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/1ae1e40e/attachment-0001.pl>

From kevinjspring at gmail.com  Mon Feb  6 22:32:35 2012
From: kevinjspring at gmail.com (Kevin Spring)
Date: Mon, 6 Feb 2012 15:32:35 -0600
Subject: [R-sig-ME] Bootstrap the variance difference
Message-ID: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/559e7bb6/attachment-0001.pl>

From jwiley.psych at gmail.com  Mon Feb  6 23:08:35 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 6 Feb 2012 14:08:35 -0800
Subject: [R-sig-ME] Bootstrap the variance difference
In-Reply-To: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
References: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
Message-ID: <CANz9Z_LrWoO2f-dO6GioHsupB=q_WWT4bsXstD2fW4oGsSnHVA@mail.gmail.com>

Hi Kevin,

I worry a bit that your model is correctly specified and you are doing
what you really want to be doing, but that is a bit of a different
question (perhaps worth checking).  In any case, your models did not
run on my system with your example data.  Supposing all works well in
the full data and you are confident with what you have, then this is
one approach to dealing with the boot issue:

rather than pass two data sets, pass one wide data set in.  Use
slightly different names and pass in two formulae to use the correct
variables.

Hope this helps,

Josh

P.S. If real data is large, this may be somewhat slow and would easily
benefit from parallelizing if you have multiple cores and sufficient
memory----check out the parallel option to boot().

#####################################################

dat1 <- read.csv(file.choose()) ## final
dat2 <- read.csv(file.choose()) ## initial

colnames(dat1) <- paste("f", colnames(dat1), sep = '')
colnames(dat2) <- paste("i", colnames(dat2), sep = '')

dat <- cbind(dat2, dat1)

varcomp <- function (lformula, dat, indices) {
  d <- dat[indices, ]
  fit1 <- lmer(lformula[[1]], data=d) #linear model
  fit2 <- lmer(lformula[[2]], data=d) #linear model
  a <- (attr (VarCorr(fit1), "sc")^2) #output variance estimation
  b <- (attr (VarCorr(fit2), "sc")^2) #output variance estimation
  drv <- (a - b) #difference between the variance estimations
  return(drv)
}

require(lme4)
require(boot)

system.time(ip1.boot <- boot (data = dat, statistic = varcomp, R =
100, lformula = list(
  initial = iCNPC ~ (1 | iCell.line) + (1 | iDNA.extract) + iCell.line,
  final = fCNPC ~ (1 | fCell.line) + (1 | fDNA.extract) + fCell.line)))



On Mon, Feb 6, 2012 at 1:32 PM, Kevin Spring <kevinjspring at gmail.com> wrote:
> ?I asked this question on Stack Exchange, but I think it might be too
> specialized. ?Hopefully someone in the mixed model group can help me out.
>
> I want to be able to bootstrap the variance differences between two data
> sets obtained at different times while taking out the error in a random
> effect.
>
> I have 2 sets of experimental data, where the data was measured at 2 time
> points (initial and final). I also have a set of simulation data. I want to
> compare the variance of the simulated date with the variance difference
> between the experimental data (final - initial). The idea is to get
> confidence intervals from the bootstrap to compare the experimental data
> with the simulation.
>
> I am having trouble making the statistic for the bootstrap function in the
> boot package for R. So far I have.
>
> varcomp <- function ( formula, data, indices ) {
> ? ?d <- data[indices,] #sample for boot
> ? ?fit <- lmer(formula, data=d) #linear model
> ? ?res.var = (attr (VarCorr(fit), "sc")^2) # variance estimation
> ? ?return(res.var)
> ? ?}
>
> But this function only returns the variance of a single data set. I want to
> be able to input 2 sets of data and have it return the difference between
> the two data sets' variance.
>
> When I try something like:
>
> varcomp <- function ( formula, data1, data2, indices ) {
> d1 <- data1[indices,] #sample for boot
> d2 <- data2[indices,] #sample for boot
> fit1 <- lmer(formula, data=d1) #linear model
> fit2 <- lmer(formula, data=d2) #linear model
> a = (attr (VarCorr(fit1), "sc")^2) #output variance estimation
> b = (attr (VarCorr(fit2), "sc")^2) #output variance estimation
> drv = a - b #difference between the variance estimations
> return(drv)
> }
>
> I would then put it into boot such as:
>
> ip1.boot <- boot ( data = ip1, statistic=varcomp, R=100,
> formula=CNPC~(1|Cell.line:DNA.extract)+Cell.line)
>
> I can't do it this way because the boot function only allows for one data
> set to be inputted.
>
> *Does anyone know how to create the correct statistic function for this?*
>
> An example of the data can also be downloaded
> here<http://www.mediafire.com/file/68a3ro1cfneiy2r/data.zip.zip>(2 csv
> files zipped 1.22KB.)
>
> My data looks something like the following:
>
> Initial
>
> ? ? ? Cell.line ? ?Time DNA.extract ? Gene ? ? ?CNPC
> 1 ? ? ? ? ?9 initial ? ? ? ? ? 1 atubP1 1778.4589
> 2 ? ? ? ? ?9 initial ? ? ? ? ? 1 atubP1 2108.0552
> 3 ? ? ? ? ?9 initial ? ? ? ? ? 1 atubP1 2118.6725
> 4 ? ? ? ? ?9 initial ? ? ? ? ? 2 atubP1 2018.6593
> 5 ? ? ? ? ?9 initial ? ? ? ? ? 2 atubP1 1935.9008
> 6 ? ? ? ? ?9 initial ? ? ? ? ? 2 atubP1 1749.9158
> 7 ? ? ? ? ?9 initial ? ? ? ? ? 3 atubP1 1524.7475
> 8 ? ? ? ? ?9 initial ? ? ? ? ? 3 atubP1 1532.9781
> 9 ? ? ? ? ?9 initial ? ? ? ? ? 3 atubP1 1693.3098
> 10 ? ? ? ?17 initial ? ? ? ? ? 1 atubP1 1076.4720
> 11 ? ? ? ?17 initial ? ? ? ? ? 1 atubP1 1101.3315
> 12 ? ? ? ?17 initial ? ? ? ? ? 1 atubP1 1185.3606
> 13 ? ? ? ?17 initial ? ? ? ? ? 2 atubP1 1131.1118
> 14 ? ? ? ?17 initial ? ? ? ? ? 2 atubP1 ?892.7087
> 15 ? ? ? ?17 initial ? ? ? ? ? 2 atubP1 1028.5465
> 16 ? ? ? ?17 initial ? ? ? ? ? 3 atubP1 ?887.9972
> 17 ? ? ? ?17 initial ? ? ? ? ? 3 atubP1 ?732.9646
> 18 ? ? ? ?17 initial ? ? ? ? ? 3 atubP1 ?680.6724
>
> Final
>
> ? Cell.line ?Time DNA.extract ? Gene ? ? ?CNPC
> 1 ? ? ? ? ?9 final ? ? ? ? ? 1 atubP1 1262.2378
> 2 ? ? ? ? ?9 final ? ? ? ? ? 1 atubP1 1261.9858
> 3 ? ? ? ? ?9 final ? ? ? ? ? 1 atubP1 1390.6873
> 4 ? ? ? ? ?9 final ? ? ? ? ? 2 atubP1 1539.7180
> 5 ? ? ? ? ?9 final ? ? ? ? ? 2 atubP1 1510.5405
> 6 ? ? ? ? ?9 final ? ? ? ? ? 2 atubP1 1443.1767
> 7 ? ? ? ? ?9 final ? ? ? ? ? 3 atubP1 1456.2050
> 8 ? ? ? ? ?9 final ? ? ? ? ? 3 atubP1 1578.6396
> 9 ? ? ? ? ?9 final ? ? ? ? ? 3 atubP1 1656.1822
> 10 ? ? ? ?17 final ? ? ? ? ? 1 atubP1 1462.5179
> 11 ? ? ? ?17 final ? ? ? ? ? 1 atubP1 1580.9956
> 12 ? ? ? ?17 final ? ? ? ? ? 1 atubP1 1255.9020
> 13 ? ? ? ?17 final ? ? ? ? ? 2 atubP1 ?886.7579
> 14 ? ? ? ?17 final ? ? ? ? ? 2 atubP1 ?581.8116
> 15 ? ? ? ?17 final ? ? ? ? ? 2 atubP1 ?722.0526
> 16 ? ? ? ?17 final ? ? ? ? ? 3 atubP1 4168.7895
> 17 ? ? ? ?17 final ? ? ? ? ? 3 atubP1 3266.2105
> 18 ? ? ? ?17 final ? ? ? ? ? 3 atubP1 4219.5645
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From David.Duffy at qimr.edu.au  Mon Feb  6 23:03:22 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 7 Feb 2012 08:03:22 +1000 (EST)
Subject: [R-sig-ME] Bootstrap the variance difference
In-Reply-To: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
References: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1202070802350.13671@orpheus.qimr.edu.au>

On Mon, 6 Feb 2012, Kevin Spring wrote:

> I can't do it this way because the boot function only allows for one data
> set to be inputted.

So you tried one combined dataset and subset?



From chris.eckert at queensu.ca  Mon Feb  6 23:26:56 2012
From: chris.eckert at queensu.ca (Chris Eckert)
Date: Mon, 06 Feb 2012 17:26:56 -0500
Subject: [R-sig-ME] Extracting means and SEs from an lmer object
Message-ID: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/84d7f594/attachment-0001.pl>

From A.Robinson at ms.unimelb.edu.au  Mon Feb  6 23:43:26 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 7 Feb 2012 09:43:26 +1100
Subject: [R-sig-ME] Bootstrap the variance difference
In-Reply-To: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
References: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
Message-ID: <20120206224326.GF1242@ms.unimelb.edu.au>

Hi Kevin,

add an indicator to each dataset and then rbind them. The indicator
variable then distinguishes between the sources. Pass it to boot as
the strata= argument.  Then also use that indicator in the varcomp
function to distinguish between the two datasets, e.g. using the
subset= arguments in lmer..

Cheers

Andrew

On Mon, Feb 06, 2012 at 03:32:35PM -0600, Kevin Spring wrote:
>  I asked this question on Stack Exchange, but I think it might be too
> specialized.  Hopefully someone in the mixed model group can help me out.
> 
> I want to be able to bootstrap the variance differences between two data
> sets obtained at different times while taking out the error in a random
> effect.
> 
> I have 2 sets of experimental data, where the data was measured at 2 time
> points (initial and final). I also have a set of simulation data. I want to
> compare the variance of the simulated date with the variance difference
> between the experimental data (final - initial). The idea is to get
> confidence intervals from the bootstrap to compare the experimental data
> with the simulation.
> 
> I am having trouble making the statistic for the bootstrap function in the
> boot package for R. So far I have.
> 
> varcomp <- function ( formula, data, indices ) {
>     d <- data[indices,] #sample for boot
>     fit <- lmer(formula, data=d) #linear model
>     res.var = (attr (VarCorr(fit), "sc")^2) # variance estimation
>     return(res.var)
>     }
> 
> But this function only returns the variance of a single data set. I want to
> be able to input 2 sets of data and have it return the difference between
> the two data sets' variance.
> 
> When I try something like:
> 
> varcomp <- function ( formula, data1, data2, indices ) {
> d1 <- data1[indices,] #sample for boot
> d2 <- data2[indices,] #sample for boot
> fit1 <- lmer(formula, data=d1) #linear model
> fit2 <- lmer(formula, data=d2) #linear model
> a = (attr (VarCorr(fit1), "sc")^2) #output variance estimation
> b = (attr (VarCorr(fit2), "sc")^2) #output variance estimation
> drv = a - b #difference between the variance estimations
> return(drv)
> }
> 
> I would then put it into boot such as:
> 
> ip1.boot <- boot ( data = ip1, statistic=varcomp, R=100,
> formula=CNPC~(1|Cell.line:DNA.extract)+Cell.line)
> 
> I can't do it this way because the boot function only allows for one data
> set to be inputted.
> 
> *Does anyone know how to create the correct statistic function for this?*
> 
> An example of the data can also be downloaded
> here<http://www.mediafire.com/file/68a3ro1cfneiy2r/data.zip.zip>(2 csv
> files zipped 1.22KB.)
> 
> My data looks something like the following:
> 
> Initial
> 
>        Cell.line    Time DNA.extract   Gene      CNPC
> 1          9 initial           1 atubP1 1778.4589
> 2          9 initial           1 atubP1 2108.0552
> 3          9 initial           1 atubP1 2118.6725
> 4          9 initial           2 atubP1 2018.6593
> 5          9 initial           2 atubP1 1935.9008
> 6          9 initial           2 atubP1 1749.9158
> 7          9 initial           3 atubP1 1524.7475
> 8          9 initial           3 atubP1 1532.9781
> 9          9 initial           3 atubP1 1693.3098
> 10        17 initial           1 atubP1 1076.4720
> 11        17 initial           1 atubP1 1101.3315
> 12        17 initial           1 atubP1 1185.3606
> 13        17 initial           2 atubP1 1131.1118
> 14        17 initial           2 atubP1  892.7087
> 15        17 initial           2 atubP1 1028.5465
> 16        17 initial           3 atubP1  887.9972
> 17        17 initial           3 atubP1  732.9646
> 18        17 initial           3 atubP1  680.6724
> 
> Final
> 
>    Cell.line  Time DNA.extract   Gene      CNPC
> 1          9 final           1 atubP1 1262.2378
> 2          9 final           1 atubP1 1261.9858
> 3          9 final           1 atubP1 1390.6873
> 4          9 final           2 atubP1 1539.7180
> 5          9 final           2 atubP1 1510.5405
> 6          9 final           2 atubP1 1443.1767
> 7          9 final           3 atubP1 1456.2050
> 8          9 final           3 atubP1 1578.6396
> 9          9 final           3 atubP1 1656.1822
> 10        17 final           1 atubP1 1462.5179
> 11        17 final           1 atubP1 1580.9956
> 12        17 final           1 atubP1 1255.9020
> 13        17 final           2 atubP1  886.7579
> 14        17 final           2 atubP1  581.8116
> 15        17 final           2 atubP1  722.0526
> 16        17 final           3 atubP1 4168.7895
> 17        17 final           3 atubP1 3266.2105
> 18        17 final           3 atubP1 4219.5645
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Deputy Director, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/



From kevinjspring at gmail.com  Mon Feb  6 23:43:43 2012
From: kevinjspring at gmail.com (Kevin Spring)
Date: Mon, 6 Feb 2012 16:43:43 -0600
Subject: [R-sig-ME] Bootstrap the variance difference
In-Reply-To: <CAPv6FHjZ37gmx7EAOAfQHCkahgJe1N1vZzKFT5OAajYKStgT1A@mail.gmail.com>
References: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
	<Pine.LNX.4.64.1202070802350.13671@orpheus.qimr.edu.au>
	<CAPv6FHjZ37gmx7EAOAfQHCkahgJe1N1vZzKFT5OAajYKStgT1A@mail.gmail.com>
Message-ID: <CAPv6FHiBUcAe1JaczZ3A1BpLS8nLCLgyFLffsoaA_iG0s6j=4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/a8714b67/attachment-0001.pl>

From bates at stat.wisc.edu  Tue Feb  7 00:00:22 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 6 Feb 2012 17:00:22 -0600
Subject: [R-sig-ME] Extracting means and SEs from an lmer object
In-Reply-To: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>
References: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>
Message-ID: <CAO7JsnTRCgruYbX4ux1iRRkWOhkxkdiwWyX1Rgjmok3kyKBm7A@mail.gmail.com>

On Mon, Feb 6, 2012 at 4:26 PM, Chris Eckert <chris.eckert at queensu.ca> wrote:
> Hi,
> I am trying to extract means and SEs from an lmer object.
> So, I followed the example code from http://glmm.wikidot.com/faq
> from the "Predictions and/or confidence (or prediction) intervals on predictions" section of the faq

> library(lme4)
> library(ggplot2) # Plotting
> library(MEMSS) # for Orthodont

The problem may be due to MEMSS bringing in other packages that mask
the definition of fixef in lme4.  It works for me (see enclosed) if I
use
data(Orthodont, package="MEMSS")
instead.

> fm1 = lmer(
> ? ?formula = distance ~ age*Sex + (age|Subject)
> ? ?, data = Orthodont
> )
> newdat <- expand.grid(
> ? ?age=c(8,10,12,14)
> ? ?, Sex=c("Male","Female")
> ? ?, distance = 0
> )
> mm = model.matrix(terms(fm1),newdat)
> newdat$distance = mm %*% fixef(fm1)
> pvar1 <- diag(mm %*% tcrossprod(vcov(fm1),mm))
> tvar1 <- pvar1+VarCorr(fm1)$Subject[1]
> newdat <- data.frame(
> ? ?newdat
> ? ?, plo = newdat$distance-2*sqrt(pvar1)
> ? ?, phi = newdat$distance+2*sqrt(pvar1)
> ? ?, tlo = newdat$distance-2*sqrt(tvar1)
> ? ?, thi = newdat$distance+2*sqrt(tvar1)
> )
> When I get to the "newdat$distance = mm %*% fixef(fm1)" I get the following error:
> "Error in UseMethod("fixef") :
> ?no applicable method for 'fixef' applied to an object of class "mer""
>
> I am using lme4 version version 0.999375-42 (the most recent version on Cran) with R version 2.14.0
>
> Any explanation for this would be greatly appreciated.
>
> Chris Eckert
> Department of Biology
> Queen's University
> Kingston, Ontario, Canada

Seeing that makes me nostalgic. I spend my formative years at Queen's.
-------------- next part --------------

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: ?Matrix?

The following object(s) are masked from ?package:base?:

    det


Attaching package: ?lme4?

The following object(s) are masked from ?package:stats?:

    AIC, BIC

> library(ggplot2) # Plotting
Loading required package: reshape
Loading required package: plyr

Attaching package: ?reshape?

The following object(s) are masked from ?package:plyr?:

    rename, round_any

The following object(s) are masked from ?package:Matrix?:

    expand

Loading required package: grid
Loading required package: proto
> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
[1] ggplot2_0.8.9    proto_0.3-9.2    reshape_0.8.4    plyr_1.7.1      
[5] lme4_0.999375-42 Matrix_1.0-3     lattice_0.20-0  

loaded via a namespace (and not attached):
[1] nlme_3.1-103  stats4_2.14.1
> data(Orthodont, package="MEMSS")
> fm1 <- lmer(
+    formula = distance ~ age*Sex + (age|Subject)
+    , data = Orthodont
+ )
> fixef(fm1)
(Intercept)         age     SexMale age:SexMale 
 17.3727273   0.4795455  -1.0321023   0.3048295 
> newdat <- expand.grid(
+    age=c(8,10,12,14)
+    , Sex=c("Male","Female")
+    , distance = 0
+ )
> mm <- model.matrix(terms(fm1),newdat)
> newdat$distance <- mm %*% fixef(fm1)
> pvar1 <- diag(mm %*% tcrossprod(vcov(fm1),mm))
> tvar1 <- pvar1+VarCorr(fm1)$Subject[1]
> newdat <- data.frame(
+    newdat
+    , plo = newdat$distance-2*sqrt(pvar1)
+    , phi = newdat$distance+2*sqrt(pvar1)
+    , tlo = newdat$distance-2*sqrt(tvar1)
+    , thi = newdat$distance+2*sqrt(tvar1)
+ )
> 
> proc.time()
   user  system elapsed 
  4.136   0.800   4.031 

From kw.stat at gmail.com  Tue Feb  7 00:29:02 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 6 Feb 2012 17:29:02 -0600
Subject: [R-sig-ME] Extracting means and SEs from an lmer object
In-Reply-To: <CAO7JsnTRCgruYbX4ux1iRRkWOhkxkdiwWyX1Rgjmok3kyKBm7A@mail.gmail.com>
References: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>
	<CAO7JsnTRCgruYbX4ux1iRRkWOhkxkdiwWyX1Rgjmok3kyKBm7A@mail.gmail.com>
Message-ID: <CAKFxdiThkd41kym8Ae9VzZFjetAhOU=o79=S1gzcZrM8PaT5Rg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/d9ccbd3f/attachment-0001.pl>

From bates at stat.wisc.edu  Tue Feb  7 00:39:01 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 6 Feb 2012 17:39:01 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <4F2C95FD.3040405@auckland.ac.nz>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
	<CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>
	<75e0d743133e90.4f2c8d0f@wiscmail.wisc.edu>
	<767093351351e8.4f2c8d4d@wiscmail.wisc.edu>
	<7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
	<7620a004131150.4f2c394a@wiscmail.wisc.edu>
	<4F2C95FD.3040405@auckland.ac.nz>
Message-ID: <CAO7JsnQL4o-G6vYq0mxWTLGYOgjA9oEOHrH_oH2yvdVQC7ThTA@mail.gmail.com>

On Fri, Feb 3, 2012 at 8:20 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 04/02/12 14:45, Kenneth Frost wrote:
>>
>> On 02/03/12, Charles Determan Jr ? wrote:
>>>
>>> Kevin,
>>>
>>> I understand that but then how is SAS accomplishing the interactions?
>>
>>
>> I have been following this conversation a little bit and this seems to be
>> the right question to ask. I would also like to know the answer. However,
>> this could be the wrong venue to get an answer to this question.
>
> <SNIP>
>
> It may be the case that fortune(203) is relevant here! :-)

Mathematical impossibilty, no (fortune(203) refers to obtaining
negative estimates of variance components, IIRC).  The problem here is
determining a full-rank model matrix for a model with interactions and
missing cells.  Because SAS uses the sweep operator in solving least
squares problems it does not encounter problems with rank deficiency.
(I am sorely tempted to make remarks about "sweeping them under the
carpet".)  In fact, SAS expects to handle rank deficiencies because it
generates a redundant set of indicators for each factor variable then
prunes them on the fly.

The approach in R is to generate a model matrix that should be of
full-rank except in circumstances like this and to check for rank
deficiency.  There is special code in the version of the QR
decomposition used with R to detect rank deficiency and pivot the
offending columns out but keep the others in their original order.

Dirk Eddelbuettel and I explored several approaches to handling such
rank deficiency in the vignette accompanying the RcppEigen package
(http://cran.us.r-project.org/web/packages/RcppEigen/vignettes/RcppEigen-intro-nojss.pdf).
 The development version of lme4 (called lme4Eigen on the R-forge
project site) detects rank deficiency earlier in the calculation but
does not yet repair the rank deficiency.  Using the column-pivoted QR
decomposition is probably the best approach but even then it would be
necessary to find the columns that are linear dependent on columns to
their left then drop only those columns.  It is not impossible by any
means, it just requires some work and is not high on the priority list
right now.

Regarding type III tests, I have forgotten which ones they are.  Are
they the sequential sums of squares or the ones where you drop the
main effect but keep the interactions thereby rendering your null
model nonsensical is most cases?
All the silliness about Types I, II, III and IV sums of squares and
tests was formulated when fitting any model was difficult (see
fortune("JCL")).  So doing a hypothesis test by fitting the null model
and fitting the alternative model and comparing the results would take
much much longer than doing a lot of linear algebra gymnastics on the
fit of the full or alternative model.  That is no longer the case.  If
you really want to perform a hypothesis test then formulate it in
terms of models, fit them and compare them.  It's not difficult and
has the undeniable advantage of forcing you to think about the model
and whether it makes sense.  Read Bill Venables' famous unpublished
paper "Exegeses on Linear Models" (just put the name in a search
engine).  (By the way, Bill is going to be at the useR conference in
Nashville in July so maybe if a bunch of us ganged up on him he could
be convinced to submit a version of that paper for publication.)



From kfrost at wisc.edu  Tue Feb  7 01:02:49 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Mon, 06 Feb 2012 18:02:49 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <7630f83985c35.4f306925@wiscmail.wisc.edu>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
	<CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>
	<75e0d743133e90.4f2c8d0f@wiscmail.wisc.edu>
	<767093351351e8.4f2c8d4d@wiscmail.wisc.edu>
	<7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
	<7620a004131150.4f2c394a@wiscmail.wisc.edu>
	<4F2C95FD.3040405@auckland.ac.nz>
	<CAO7JsnQL4o-G6vYq0mxWTLGYOgjA9oEOHrH_oH2yvdVQC7ThTA@mail.gmail.com>
	<7750887b86a4a.4f30668b@wiscmail.wisc.edu>
	<7780c32584739.4f306704@wiscmail.wisc.edu>
	<7630b99485277.4f306831@wiscmail.wisc.edu>
	<7750a59386776.4f30686e@wiscmail.wisc.edu>
	<7750ada685dda.4f3068ab@wiscmail.wisc.edu>
	<7750f596830b9.4f3068e8@wiscmail.wisc.edu>
	<7630f83985c35.4f306925@wiscmail.wisc.edu>
Message-ID: <763096e7864e1.4f3015c9@wiscmail.wisc.edu>

Doug-

Thanks for the explanation. I think I can understand what is happening in the column-pivoted QR decomposition you are describing.? I'm not sure if I understand how the sweep operator works (although I'm not too worried about it at the moment).

Ken
?

On 02/06/12, Douglas Bates   wrote:
> On Fri, Feb 3, 2012 at 8:20 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> > On 04/02/12 14:45, Kenneth Frost wrote:
> >>
> >> On 02/03/12, Charles Determan Jr ? wrote:
> >>>
> >>> Kevin,
> >>>
> >>> I understand that but then how is SAS accomplishing the interactions?
> >>
> >>
> >> I have been following this conversation a little bit and this seems to be
> >> the right question to ask. I would also like to know the answer. However,
> >> this could be the wrong venue to get an answer to this question.
> >
> > <SNIP>
> >
> > It may be the case that fortune(203) is relevant here! :-)
> 
> Mathematical impossibilty, no (fortune(203) refers to obtaining
> negative estimates of variance components, IIRC).  The problem here is
> determining a full-rank model matrix for a model with interactions and
> missing cells.  Because SAS uses the sweep operator in solving least
> squares problems it does not encounter problems with rank deficiency.
> (I am sorely tempted to make remarks about "sweeping them under the
> carpet".)  In fact, SAS expects to handle rank deficiencies because it
> generates a redundant set of indicators for each factor variable then
> prunes them on the fly.
> 
> The approach in R is to generate a model matrix that should be of
> full-rank except in circumstances like this and to check for rank
> deficiency.  There is special code in the version of the QR
> decomposition used with R to detect rank deficiency and pivot the
> offending columns out but keep the others in their original order.
> 
> Dirk Eddelbuettel and I explored several approaches to handling such
> rank deficiency in the vignette accompanying the RcppEigen package
> (http://cran.us.r-project.org/web/packages/RcppEigen/vignettes/RcppEigen-intro-nojss.pdf).
>  The development version of lme4 (called lme4Eigen on the R-forge
> project site) detects rank deficiency earlier in the calculation but
> does not yet repair the rank deficiency.  Using the column-pivoted QR
> decomposition is probably the best approach but even then it would be
> necessary to find the columns that are linear dependent on columns to
> their left then drop only those columns.  It is not impossible by any
> means, it just requires some work and is not high on the priority list
> right now.
> 
> Regarding type III tests, I have forgotten which ones they are.  Are
> they the sequential sums of squares or the ones where you drop the
> main effect but keep the interactions thereby rendering your null
> model nonsensical is most cases?
> All the silliness about Types I, II, III and IV sums of squares and
> tests was formulated when fitting any model was difficult (see
> fortune("JCL")).  So doing a hypothesis test by fitting the null model
> and fitting the alternative model and comparing the results would take
> much much longer than doing a lot of linear algebra gymnastics on the
> fit of the full or alternative model.  That is no longer the case.  If
> you really want to perform a hypothesis test then formulate it in
> terms of models, fit them and compare them.  It's not difficult and
> has the undeniable advantage of forcing you to think about the model
> and whether it makes sense.  Read Bill Venables' famous unpublished
> paper "Exegeses on Linear Models" (just put the name in a search
> engine).  (By the way, Bill is going to be at the useR conference in
> Nashville in July so maybe if a bunch of us ganged up on him he could
> be convinced to submit a version of that paper for publication.)


From fan.mongxie at gmail.com  Tue Feb  7 15:13:57 2012
From: fan.mongxie at gmail.com (Fan Mongxie)
Date: Tue, 7 Feb 2012 15:13:57 +0100
Subject: [R-sig-ME] Check the predictions of glmer
Message-ID: <CAAZy3PDSto8xttftUJPWb8W3ET11JQ55g1NmaVULVm_CY5+S0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/42313705/attachment-0001.pl>

From bbolker at gmail.com  Tue Feb  7 15:23:18 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 07 Feb 2012 09:23:18 -0500
Subject: [R-sig-ME] lmer blocking by subject?
In-Reply-To: <CALBCd4id6P7-A7rXGWfu0w0sizWfuAL5vx3EJq7LZGGmQkY0QA@mail.gmail.com>
References: <CALBCd4h+6u1a5fFkQ1uATGPZRQ4KxGC68WYE7rDm5M0gjUR4Mg@mail.gmail.com>
	<loom.20120206T043305-347@post.gmane.org>
	<CALBCd4id6P7-A7rXGWfu0w0sizWfuAL5vx3EJq7LZGGmQkY0QA@mail.gmail.com>
Message-ID: <4F3133D6.6010500@gmail.com>

  [cc'ing back to r-sig-mixed-models]

On 12-02-05 11:31 PM, Tiffanie Cross wrote:
> 
> 
> On Sun, Feb 5, 2012 at 7:50 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>     Tiffanie Cross <tahtg6 at ...> writes:
> 
>     > I am new to R and would like some guidance on how to block by subject.
>     >
>     > I collected presence/absence 24 hrs/day for 44 birds, denoted
>     "bird", at 5
>     > stations, denoted "colony" for the duration of a breeding season. The
>     > breeding season was broken into biologically relevant time periods (3
>     > levels), denoted "period". The birds were captured on 2 different
>     colonies,
>     > 22 on each colony, denoted "homecolony". I also have the variable,
>     "sex". I
>     > have about 300,000 total observations for these 44 birds. This data is
>     > temporally auto-correlated because it is VHF radio-telemetry data
>     recorded
>     > continually throughout the study.
> 
>      What is the temporal resolution?  Based on a guess at the length
>     of the breeding season (60 days), I'm guessing about every 10-12
>     minutes.
>     This isn't essential information but would help get a feel for the
>     data.
> 
> 
> The breeding season is from 22 May to 15 August. The maximum detection
> interval is 20 minutes in the case that all tagged birds are present,
> and the minimum is 3 minutes in the case that only one tagged bird is
> present.  


  So the samples are unevenly spaced too ... ?

> 
> 
>       Be aware that modeling temporal autocorrelation in a binary
>     variable may be a little bit tricky -- there are a variety of
>     approaches, but none are quite as easy as the way one builds
>     autocorrelation into a normal-response model, by making the residuals
>     within blocks multivariate normal with a specified autocorrelation.  A
>     few possibilities that spring to mind are (1) because there is
>     presumably no error in the observations themselves, you could
>     condition on the previous observation (i.e. put it in as a predictor);
>     (2) aggregate the data to a coarser temporal scale and fit the data as
>     binomial (e.g.  number of presence/absence values per 2-hour period,
>     or per day, or some other appropriate period that balances resolution
>     and lack of autocorrelation); (3) if there are long 'runs' of
>     presence/absences, aggregate the data down to times when birds entered
>     or left; (4) [fanciest, but not necessarily worth the trouble or most
>     appropriate] assume an underlying multivariate normal distribution
>     that *is* autocorrelated and controls probability of presence
>     (i.e. a hierarchical model with autocorrelation in the level
>     below the observation level).
> 
> 
> I had the model fitted as you describe in option 4 using PROC GLIMMIX in
> SAS. The next step in SAS was to look at residuals and I couldn't figure
> out how to do that. So, I consulted a colleague who turned me on to Zuur
> et al. which was helpful initially. And now I'm stuck in R, too. I'm
> supposed to defend soon and this is kind of ruining that, I fear. =( 

   The closest equivalent to PROC GLIMMIX in SAS is glmmPQL from the
MASS package, in R.  Most of what you can do in GLIMMIX you can also do
in glmmPQL.

  The model statement for blocking by bird and allowing for correlation
within birds across time would be something like

  glmmPQL(present ~  gender + period + homecolony + colony,
   random=~period|bird), correlation=corCAR1(form=~time|bird),
    data = FD, family = binomial)


>     > I know that the (1+period|bird) term is probably incorrect

  why do you think so?

  this allows for the effect of period to vary across birds.  I would
say you *might* want ~period+colony|bird , if your data can support it ...


   The two drawbacks with using glmmPQL or GLIMMIX are that (1) they
both use penalized quasi-likelihood, which are known to give biased
estimates of the variances for binary data; and (2) it's possible to fit
models that don't really make much sense in them.  However, both of
these are matters of taste (in my opinion) rather than absolute
show-stoppers.  I hate to say it, but if SAS was mostly working for you
and it was just a matter of getting residuals wouldn't that be an
easier problem to solve ... ?  (I

http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_glimmix_a0000001413.htm


  BTW GLIMMIX now does Laplace and quadrature methods too, but it does
not allow autocorrelation with these methods:

http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_glimmix_a0000001405.htm

 *  Because a valid conditional distribution is required, R-side random
 effects are not permitted for METHOD=LAPLACE in the GLIMMIX procedure.
In other words, the GLIMMIX procedure requires for METHOD=LAPLACE
conditional independence without R-side overdispersion or covariance
structure.

> 
> I did build a column into my data for "hour", so I guess I do have an
> "hour" variable that 'detections per hour' could be calculated for each
> individual. 
> 
> 
>     > I have a binary response variable, "present", with independent
>     variables
>     > "sex" at 2 levels, "homecolony" at 2 levels, "colony" at 5 levels, and
>     > "period" at 3 levels. I would like to incorporate "period", "bird" and
>     > "colony" as random effects. Fixed effects are "sex" and
>     "homecolony". The
>     > "bird" variable is what I want the model blocked by.
> 
>       Practically speaking, you can't treat period as a random effect --
>     not enough levels.
> 
> 
> Ok. I will specify it as fixed. :) Thanks! 
> 
> 
>     > I am trying to answer the following questions: "Are there
>     differences in
>     > presence between sexes, homecolony, and period?" "Do birds from one
>     > homecolony differ in their use of other colonies (colony)?"
>     >
>     > I cannot figure out how to specify that I want the model to block by
>     > subject, i.e. "bird". I have tried incorporating "bird" as a
>     random effect,
>     > but the degrees of freedom still come out to be close to 300,000
>     which is
>     > near the total number of observations. Can anyone show me syntax
>     that will
>     > incorporate bird as a random effect that the model blocks by subject?
> 
>       Where are you seeing the degrees of freedom?
> 
> 
> I don't remember and I didn't save the output.  
> 
>     >
>     > I tried following examples from Doug Bates' LME4 book, Chapter 4:
> 
>     > Glmm_FD <- lmer(present ~ 1 + gender + period + homecolony +
>     colony + (1 +
>     > period|bird), data = FD, family = binomial, REML = 0)
>     > I know that the (1+period|bird) term is probably incorrect.
> 
>      REML=0 is meaningless in this case (lmer doesn't use REML
>     or an analogue of it when fitting a non-Gaussian model), but
>     otherwise your model specification seems to be on the right track.
> 
>      Since I'm guessing the birds can only be detected at a single
>     station at a time, this is a bit more of a categorical response
>     (i.e., is bird X present at colony 1-5 or "none of the above"
>     at time T?)  Have you thought about multistate mark-recapture 
> 
>     models ... ?
> 
> 
> I'll take REML = 0 out of the model. The birds can only be detected at
> one station at time T. I don't know what multistate mark-recapture
> models are. I mentally steered clear of mark-recapture because they make
> me think of population estimates or homerange type analyses. I'm after
> mostly behavioral information here.

  Well, I think they could be useful, but no need to delve into
unnecessary complications ...
> 
> 
>       This seems like a fairly complex problem.  How have others
>     in your field handled these kinds of data?  With lots of data
>     on each bird, you may be able to simplify your life a bit by
>     analyzing each bird separately -- i.e. a two-stage model rather
>     than a mixed/multilevel model -- Murtaugh 2007 _Ecology_ recommends
>     this, although I don't always agree with him ...
> 
> 
> I haven't seen others in my field with this sort of data use GLM or GLMM
> at all. I actually disagreed with previous methods and if my memory
> serves I didn't see any statistical information provided. 
> 
> 
>      I would recommend Zuur et al for messy/complex ecological
>     data, although I don't agree with all of that either ...
> 
> 
> So is there no command like "Subject = bird" as there is in PROC GLIMMIX
> in SAS?

  Well, the point is that (1|bird) *is* more or less equivalent (as I
understand it) to "Subject=bird".

  I would definitely follow Murtaugh's advice here and use the
*simplest* method that you think will make sense.  Doing a two-stage
analysis might be just fine.

  Ben Bolker



From bbolker at gmail.com  Tue Feb  7 17:56:42 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Feb 2012 16:56:42 +0000 (UTC)
Subject: [R-sig-ME] repeated measure in partially crossed design
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
	<F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>
	<loom.20120201T030103-410@post.gmane.org>
	<8B77AD44-9DF0-4EE4-911D-AAA1A3948A4E@qmul.ac.uk>
Message-ID: <loom.20120207T175226-898@post.gmane.org>

matteo dossena <m.dossena at ...> writes:

> this really make things clearer now, seems like (season|subject), 
> could be the appropriate structure.
> 
> However, a last doubt still trouble me.
> 
> Having (season|subject) fitted as random effect, 
> is it taking in consideration pseudoreplication
> (repeated measures on subject)?

  Yes.

> If I would do this analysis with lme() I would fit a model with the
>  argument correlation=CorCompSymm(form=~1|subject),
> and a model without correlation than compared the two 
> to assess wether or not  there is violation of the independence.
> Is this a sensible things to do?

  I have to admit I don't quite understand why people fit
CorCompSymm models so much since they are *almost* equivalent to
just including a random effect of the form ~1|subject (with the
difference, I guess, that negative within-cluster correlations
are possible, while random=~1|subject enforces positive correlations).

> 
> Since i'm working with lmer(), how can I check if correlation
>  has to be included in the model?

  This is partly a philosophical question.  I would say that if
subject blocking is part of your experimental/sampling design then
you should include it in the model in any case, unless it causes
severe technical difficulties with the fitting.

   CorCompSymm is not a possibility in lmer.  In principle 
you can do a likelihood ratio test, but lmer won't fit models
without any random effects.  You could try the RLRsim package.
See also advice in <http://glmm.wikidot.com/faq> about how
(and whether) to test random effects.

> 
> Cheers
> m.
> 

 [snip snip]



From bates at stat.wisc.edu  Tue Feb  7 18:11:20 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Feb 2012 11:11:20 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
Message-ID: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>

We (the lme4 authors) have mentioned on this list that we are
preparing a new version of lme4 that will provide enhanced
capabilities.  That's the good news.  The bad news is that the
internal representation of the model has been changed yet again.  If
your use of the lme4 package is through the exported functions only
you should be okay.  However, if you find problems then please report
them to us either in email <lme4-authors at r-forge.wu-wien.ac.at> or on
the bug-tracker at R-forge,

https://r-forge.r-project.org/tracker/?func=add&group_id=60&atid=298

One major, and unfortunately inevitable, problem that will affect many
users is the inability of the new code to load saved objects created
with the old code.  Unfortunately that is what happens when you change
the class representation.  If possible it is best to save the code and
data that generated the fitted model and re-fit after the change.

If your usage involved access to components or slots in the object
then there will be changes.  To ease the transition, Martin created a
function called getME that is available in the current lme4 and in the
new lme4, available as lme4Eigen on R-forge.  This function takes a
fitted model and a character variable naming a component and returns
the desired component.  For example, if you want the fixed-effects
model matrix from fitted model fm1 then use

getME(fm1, "X")

Similarly for the random-effects model matrix, "Z", or its transpose,
"Zt", the sparse Cholesky factor, "L" and many others.  Use

library(lme4)
example(getME)

to get some examples.

The new lme4 will provide

 - profiling of the deviance function with respect to the parameters
   in a linear mixed model (and soon generalized linear mixed models).
   The profiles allow for creation of realistic confidence intervals
   on the parameters and for various plots that show the sensitivity
   of the deviance to the values of the parameters.

 - a more reliable and flexible implementation of generalized linear
   mixed models, including the use of adaptive Gauss-Hermite
   quadrature for evaluating an approximation to the deviance.

 - short-cut functions such as refitML and refit to re-evaluate a
   model under the maximum likelihood criterion or with a new response
   vector.

 - a cleaner internal representations that provides, in most cases,
   faster and more reliable model fits.

 - choice of optimizer when estimating the parameters.  Current
   choices are "NelderMead" and "bobyqa".  Both are generally faster
   and more reliable than the optimizer used in the current lme4,
   which is based on the code in R's nlminb() function, the one that
   gives those annoying "false convergence" messages.

 - smaller memory footprint.  The need for copying large objects is
   reduced through the use of reference classes in R.  In the past
   there were circumstances where it was possible to fit a model to a
   large data set but not to print or show the results because a new
   copy of the entire object was created during the process of
   creating a summary.  This no longer occurs.

 - nlmer has been improved and will, by the time of release, allow
   adaptive Gauss-Hermite quadrature.

An alpha-test release will be made available on the R-forge archive
but *not* uploaded to CRAN.  If you use lme4 extensively please test
this release by installing from the R-forge archive and telling us if
there are problems with your code.  This way you can still back out to
the current release by removing the lme4 package and reinstalling from
CRAN.  Once the new lme4 has been released to CRAN it will be much
more difficult to back out that installation.

Authors of packages that depend on lme4 will get a separate message
off-list about testing and suggested modifications.

Thanks for your cooperation.  We do honestly believe that this change
will provide an improved capability for fitting and analyzing
mixed-effects models.



From shaillymehrotra at gmail.com  Tue Feb  7 15:40:58 2012
From: shaillymehrotra at gmail.com (SHAILLY MEHROTRA)
Date: Tue, 7 Feb 2012 09:40:58 -0500
Subject: [R-sig-ME] nlme -95% CI of parameter estimates
Message-ID: <CAN8uQptfeq++wUU4H9dmL1k4E=gV+uNVB9+Hwro+QQbWo5+n1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/6565db6c/attachment-0001.pl>

From m.dossena at qmul.ac.uk  Tue Feb  7 18:28:39 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Tue, 7 Feb 2012 17:28:39 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <loom.20120207T175226-898@post.gmane.org>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
	<F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>
	<loom.20120201T030103-410@post.gmane.org>
	<8B77AD44-9DF0-4EE4-911D-AAA1A3948A4E@qmul.ac.uk>
	<loom.20120207T175226-898@post.gmane.org>
Message-ID: <1A61E9AE-211D-4D34-B39F-5FADFD2706E5@qmul.ac.uk>

Thanks a lot Ben,

most probably, my doubt rises from a still superficial comprehension of the topic.
I guess, the correlation matrix is more important when is not simply symmetric and 
when the analysis is actually investigating the temporal dynamics.
I my case I'm interested in fitting a model that properly accounts for the experimental design.

Cheers
m.

Il giorno 7 Feb 2012, alle ore 16:56, Ben Bolker ha scritto:

> matteo dossena <m.dossena at ...> writes:
> 
>> this really make things clearer now, seems like (season|subject), 
>> could be the appropriate structure.
>> 
>> However, a last doubt still trouble me.
>> 
>> Having (season|subject) fitted as random effect, 
>> is it taking in consideration pseudoreplication
>> (repeated measures on subject)?
> 
> Yes.
> 
>> If I would do this analysis with lme() I would fit a model with the
>> argument correlation=CorCompSymm(form=~1|subject),
>> and a model without correlation than compared the two 
>> to assess wether or not  there is violation of the independence.
>> Is this a sensible things to do?
> 
> I have to admit I don't quite understand why people fit
> CorCompSymm models so much since they are *almost* equivalent to
> just including a random effect of the form ~1|subject (with the
> difference, I guess, that negative within-cluster correlations
> are possible, while random=~1|subject enforces positive correlations).
> 
>> 
>> Since i'm working with lmer(), how can I check if correlation
>> has to be included in the model?
> 
> This is partly a philosophical question.  I would say that if
> subject blocking is part of your experimental/sampling design then
> you should include it in the model in any case, unless it causes
> severe technical difficulties with the fitting.
> 
>  CorCompSymm is not a possibility in lmer.  In principle 
> you can do a likelihood ratio test, but lmer won't fit models
> without any random effects.  You could try the RLRsim package.
> See also advice in <http://glmm.wikidot.com/faq> about how
> (and whether) to test random effects.
> 
>> 
>> Cheers
>> m.
>> 
> 
> [snip snip]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Tue Feb  7 18:47:59 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Feb 2012 11:47:59 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
Message-ID: <CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>

On Tue, Feb 7, 2012 at 11:11 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> We (the lme4 authors) have mentioned on this list that we are
> preparing a new version of lme4 that will provide enhanced
> capabilities. ?That's the good news. ?The bad news is that the
> internal representation of the model has been changed yet again. ?If
> your use of the lme4 package is through the exported functions only
> you should be okay. ?However, if you find problems then please report
> them to us either in email <lme4-authors at r-forge.wu-wien.ac.at> or on
> the bug-tracker at R-forge,
>
> https://r-forge.r-project.org/tracker/?func=add&group_id=60&atid=298
>
> One major, and unfortunately inevitable, problem that will affect many
> users is the inability of the new code to load saved objects created
> with the old code. ?Unfortunately that is what happens when you change
> the class representation. ?If possible it is best to save the code and
> data that generated the fitted model and re-fit after the change.
>
> If your usage involved access to components or slots in the object
> then there will be changes. ?To ease the transition, Martin created a
> function called getME that is available in the current lme4 and in the
> new lme4, available as lme4Eigen on R-forge. ?This function takes a
> fitted model and a character variable naming a component and returns
> the desired component. ?For example, if you want the fixed-effects
> model matrix from fitted model fm1 then use
>
> getME(fm1, "X")
>
> Similarly for the random-effects model matrix, "Z", or its transpose,
> "Zt", the sparse Cholesky factor, "L" and many others. ?Use
>
> library(lme4)
> example(getME)
>
> to get some examples.
>
> The new lme4 will provide
>
> ?- profiling of the deviance function with respect to the parameters
> ? in a linear mixed model (and soon generalized linear mixed models).
> ? The profiles allow for creation of realistic confidence intervals
> ? on the parameters and for various plots that show the sensitivity
> ? of the deviance to the values of the parameters.
>
> ?- a more reliable and flexible implementation of generalized linear
> ? mixed models, including the use of adaptive Gauss-Hermite
> ? quadrature for evaluating an approximation to the deviance.
>
> ?- short-cut functions such as refitML and refit to re-evaluate a
> ? model under the maximum likelihood criterion or with a new response
> ? vector.
>
> ?- a cleaner internal representations that provides, in most cases,
> ? faster and more reliable model fits.
>
> ?- choice of optimizer when estimating the parameters. ?Current
> ? choices are "NelderMead" and "bobyqa". ?Both are generally faster
> ? and more reliable than the optimizer used in the current lme4,
> ? which is based on the code in R's nlminb() function, the one that
> ? gives those annoying "false convergence" messages.
>
> ?- smaller memory footprint. ?The need for copying large objects is
> ? reduced through the use of reference classes in R. ?In the past
> ? there were circumstances where it was possible to fit a model to a
> ? large data set but not to print or show the results because a new
> ? copy of the entire object was created during the process of
> ? creating a summary. ?This no longer occurs.
>
> ?- nlmer has been improved and will, by the time of release, allow
> ? adaptive Gauss-Hermite quadrature.
>
> An alpha-test release will be made available on the R-forge archive
> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
> this release by installing from the R-forge archive and telling us if
> there are problems with your code. ?This way you can still back out to
> the current release by removing the lme4 package and reinstalling from
> CRAN. ?Once the new lme4 has been released to CRAN it will be much
> more difficult to back out that installation.
>
> Authors of packages that depend on lme4 will get a separate message
> off-list about testing and suggested modifications.
>
> Thanks for your cooperation. ?We do honestly believe that this change
> will provide an improved capability for fitting and analyzing
> mixed-effects models.

I forgot to mention an important point for Mac OS X users.  The new
lme4, which is based on the Eigen linear algebra library, requires the
RcppEigen package for which there is no binary Mac OS X package on
CRAN.  It's a ridiculous situation that comes about because Apple
ships an antique version of gcc in their XCode development
environment, and won't upgrade because of licensing disagreements.
Even that very old version of g++ compiles the package successfully
for Intel Macs but it croaks when trying to cross-compile for the ppc
architecture.  You can see at
http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-00install.html
that the advice it to inform Apple of the compiler error but they
ignore such reports.  Things may improve when XCode 4 is in use
because it provides clang++ in addition to the same very old version
of g++.  In the meantime we will provide a binary i386 Mac OS X
package for RcppEigen.



From mjgeha at huskers.unl.edu  Tue Feb  7 19:33:49 2012
From: mjgeha at huskers.unl.edu (mjgeha at huskers.unl.edu)
Date: Tue, 7 Feb 2012 18:33:49 +0000
Subject: [R-sig-ME] MCMCglmm with zibinomial
Message-ID: <D355D72185FD4941AAF21E72A017059E0170C029@SN2PRD0102MB131.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/74173676/attachment-0001.pl>

From smckinney at bccrc.ca  Tue Feb  7 20:40:08 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 7 Feb 2012 11:40:08 -0800
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <2359_1328636892_1328636892_CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<2359_1328636892_1328636892_CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A70846@crcmail4.BCCRC.CA>



> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Douglas Bates
> Sent: February-07-12 9:48 AM
> To: R-mixed models mailing list
> Subject: Re: [R-sig-ME] Upcoming changes in lme4
> 
> On Tue, Feb 7, 2012 at 11:11 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> > We (the lme4 authors) have mentioned on this list that we are
> > preparing a new version of lme4 that will provide enhanced
> > capabilities. ?That's the good news. ?

<snip>


> 
> I forgot to mention an important point for Mac OS X users.  The new
> lme4, which is based on the Eigen linear algebra library, requires the
> RcppEigen package for which there is no binary Mac OS X package on
> CRAN.  It's a ridiculous situation that comes about because Apple
> ships an antique version of gcc in their XCode development
> environment, and won't upgrade because of licensing disagreements.
> Even that very old version of g++ compiles the package successfully
> for Intel Macs but it croaks when trying to cross-compile for the ppc
> architecture.  You can see at
> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-
> 00install.html
> that the advice it to inform Apple of the compiler error but they
> ignore such reports.  Things may improve when XCode 4 is in use
> because it provides clang++ in addition to the same very old version
> of g++.  In the meantime we will provide a binary i386 Mac OS X
> package for RcppEigen.


Thanks for all your hard and good work on the lme4 package.
I use it regularly, but many of my data sets are huge and
64 bit processing is essential.

Would you be able to provide Intel binary i386 (32 bit) and 
x86_64 (64 bit) builds in your Mac OS X package?


Best

Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre


> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Tue Feb  7 21:12:19 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 07 Feb 2012 20:12:19 +0000
Subject: [R-sig-ME] MCMCglmm with zibinomial
In-Reply-To: <D355D72185FD4941AAF21E72A017059E0170C029@SN2PRD0102MB131.prod.exchangelabs.com>
References: <D355D72185FD4941AAF21E72A017059E0170C029@SN2PRD0102MB131.prod.exchangelabs.com>
Message-ID: <20120207201219.11651wsp09l5fp34@www.staffmail.ed.ac.uk>

Hi,


Below is a zero-inflated binomial example. I can only get your warning  
if the data are not positive integers. Are you sure this is not the  
case?

You can fit multiple correlation structures (e.g. animal and sire)  
using the ginverse argument.

Cheers,

Jarrod


library(VGAM)

n<-1000                                # number of observations
size<-rpois(n,1)+10            # number of trials per observation
prob<-rnorm(n, 1, sqrt(2))  # logit probability of success (with variance 2)
phi.logit<-(-1)  # logit probability of zero (ignoring the binomial  
distribution)

y<-rzibinom(n, size, plogis(prob), phi = plogis(phi.logit))

detach(package:VGAM) # detach: VGAM conflicts with everything

dat<-data.frame(success=y, failure=size-y)

prior<-list(R=list(V=diag(2), nu=0, fix=2))

# as in binary data the observation-level heterogeneity in  
zero-inflation cannot be estimated - the varaince of these effects  
I've arbitrarily set at 1.

m1<-MCMCglmm(c(success, failure)~trait-1, rcov=~idh(trait):units,  
data=dat, family="zibinomial", prior=prior)

# below posteriors with simulation value in red

hist(m1$Sol[,1])
abline(v=1, col="red")

c2 <- (16 * sqrt(3)/(15 * pi))^2  # correction fator because  
VGAM::rzbinom assumes the variance in logit zero-inflation  
probabilities is zero not one as in MCMCglmm

hist(m1$Sol[,2]/sqrt(1+c2))
abline(v=phi.logit, col="red")

hist(m1$VCV[,1])
abline(v=2, col="red")



Quoting "mjgeha at huskers.unl.edu" <mjgeha at huskers.unl.edu> on Tue, 7  
Feb 2012 18:33:49 +0000:

> I have been trying to fit a zibinomial distribution to a set of data I have.
>
> The response variable is in a single column and represents the  
> percentages of a certain incidence (ranging obviously between 0 and  
> 1).
>
> The data is assumed to be zero-inflated as > 40% of the data is made  
> up of zeroes.
>
> I have tried to fit the following:
>
> analysis.1<-MCMCglmm(response~1,random=~animal,rcov=~units,family="zibinomial",nitt=50000,burnin=5000,thin=25,data=source1,pedigree=ped.dat)
>
>
>
> I get the same error message as reported in a previous question  
> regarding the "zibinomial" :
>
> "Error in rowSums(data[, match(response.names[0:1 + nt], names(data))]) :
>   error in evaluating the argument 'x' in selecting a method for  
> function 'rowSums': Error in `[.data.frame`(data, ,  
> match(response.names[0:1 + nt], names(data))) :
>   undefined columns selected"
>
>
>
> I looked up the answer submitted to that question and tried creating  
>  "success" and "failure" variables and fit the following:
>
> MCMCglmm(cbind(success,failure)~  
> -1,random=~us(trait):animal,rcov=~us(trait):units,family=rep("zibinomial",2),nitt=50000,burnin=1000,thin=25,data=snap)
>
> Now I'm getting the following error message:
>
> "Error in MCMCglmm(cbind(success, failure) ~ - 1, random =  
> ~us(trait):animal,  :
>   binomial data must be non-negative integers"
>
> I'm sure I don't have any negative integers in my data set.
>
> I was wondering if it would be possible to get more  
> clarification/example/reference on fitting zibinomial in MCMCglmm.
>
>
>
> Also would it be possible to fit more than one pedigree relationship  
> matrix? The current example is for an animal model but what if we  
> had both an animal effect and a sire effect and we want to fit two  
> pedigree relationship matrices instead of just one?
>
>
>
> Any help on that issue is more than appreciated.
>
>
>
> Thanks,
>
>
>
> Mak
>
>
>
> Makram J. Geha,PhD
> Quantitative Geneticist
> Dow AgroSciences, LLC.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From f.calboli at imperial.ac.uk  Tue Feb  7 21:36:59 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 7 Feb 2012 20:36:59 +0000
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
Message-ID: <9F025792-02C8-4280-9FCA-627D54FC5B9A@imperial.ac.uk>

On 7 Feb 2012, at 17:47, Douglas Bates wrote:
> 
> I forgot to mention an important point for Mac OS X users.  The new
> lme4, which is based on the Eigen linear algebra library, requires the
> RcppEigen package for which there is no binary Mac OS X package on
> CRAN.  It's a ridiculous situation that comes about because Apple
> ships an antique version of gcc in their XCode development
> environment, and won't upgrade because of licensing disagreements.
> Even that very old version of g++ compiles the package successfully
> for Intel Macs but it croaks when trying to cross-compile for the ppc
> architecture.  You can see at
> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-00install.html
> that the advice it to inform Apple of the compiler error but they
> ignore such reports.  Things may improve when XCode 4 is in use
> because it provides clang++ in addition to the same very old version
> of g++.  In the meantime we will provide a binary i386 Mac OS X
> package for RcppEigen.


Thank you for the hard work, it is very much appreciated. I use R 64-bit more than R 32-bit, but I guess all I have to do is to compile the package by hand (I'm on OS 10.7.3, and have Xcode 4.2.1, i.e. intel mac + clang), right? 

I never had any problems compiling packages where binaries were not available, I do not see how RccpEigen should give me more grief. 

Best wishes and, again, many thanks

F

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From Mike.Lawrence at dal.ca  Tue Feb  7 21:41:17 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 7 Feb 2012 16:41:17 -0400
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <9F025792-02C8-4280-9FCA-627D54FC5B9A@imperial.ac.uk>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
	<9F025792-02C8-4280-9FCA-627D54FC5B9A@imperial.ac.uk>
Message-ID: <CAB+QPJC6y1-pyX8cHtCByaW8Uy6cvu5aNAjmYc6YMAZLxj3pyQ@mail.gmail.com>

I can at least confirm that on my system (Mac OS 10.7.2, xcode 4.1, R
2.14.2), RcppEigen builds fine while running the following in the
64-bit GUI:

install.packages('RcppEigen',type='source',INSTALL_opts='--byte-compile')



On Tue, Feb 7, 2012 at 4:36 PM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> On 7 Feb 2012, at 17:47, Douglas Bates wrote:
>>
>> I forgot to mention an important point for Mac OS X users. ?The new
>> lme4, which is based on the Eigen linear algebra library, requires the
>> RcppEigen package for which there is no binary Mac OS X package on
>> CRAN. ?It's a ridiculous situation that comes about because Apple
>> ships an antique version of gcc in their XCode development
>> environment, and won't upgrade because of licensing disagreements.
>> Even that very old version of g++ compiles the package successfully
>> for Intel Macs but it croaks when trying to cross-compile for the ppc
>> architecture. ?You can see at
>> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-00install.html
>> that the advice it to inform Apple of the compiler error but they
>> ignore such reports. ?Things may improve when XCode 4 is in use
>> because it provides clang++ in addition to the same very old version
>> of g++. ?In the meantime we will provide a binary i386 Mac OS X
>> package for RcppEigen.
>
>
> Thank you for the hard work, it is very much appreciated. I use R 64-bit more than R 32-bit, but I guess all I have to do is to compile the package by hand (I'm on OS 10.7.3, and have Xcode 4.2.1, i.e. intel mac + clang), right?
>
> I never had any problems compiling packages where binaries were not available, I do not see how RccpEigen should give me more grief.
>
> Best wishes and, again, many thanks
>
> F
>
> --
> Federico C. F. Calboli
> Neuroepidemiology and Ageing Research
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602 ? Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From reinhold.kliegl at gmail.com  Tue Feb  7 21:48:08 2012
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 7 Feb 2012 21:48:08 +0100
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAB+QPJC6y1-pyX8cHtCByaW8Uy6cvu5aNAjmYc6YMAZLxj3pyQ@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
	<9F025792-02C8-4280-9FCA-627D54FC5B9A@imperial.ac.uk>
	<CAB+QPJC6y1-pyX8cHtCByaW8Uy6cvu5aNAjmYc6YMAZLxj3pyQ@mail.gmail.com>
Message-ID: <CAG+WrExwSrOW=oFGZTeTNwTm=uJ8KOqMzY6=GtgN8NiniLy4Rw@mail.gmail.com>

I confirm Mike's report with high appreciation for this line of code.
Thank you very much, Mike!
Reinhold Kliegl

On Tue, Feb 7, 2012 at 9:41 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> I can at least confirm that on my system (Mac OS 10.7.2, xcode 4.1, R
> 2.14.2), RcppEigen builds fine while running the following in the
> 64-bit GUI:
>
> install.packages('RcppEigen',type='source',INSTALL_opts='--byte-compile')
>
>
>
> On Tue, Feb 7, 2012 at 4:36 PM, Federico Calboli
> <f.calboli at imperial.ac.uk> wrote:
>> On 7 Feb 2012, at 17:47, Douglas Bates wrote:
>>>
>>> I forgot to mention an important point for Mac OS X users. ?The new
>>> lme4, which is based on the Eigen linear algebra library, requires the
>>> RcppEigen package for which there is no binary Mac OS X package on
>>> CRAN. ?It's a ridiculous situation that comes about because Apple
>>> ships an antique version of gcc in their XCode development
>>> environment, and won't upgrade because of licensing disagreements.
>>> Even that very old version of g++ compiles the package successfully
>>> for Intel Macs but it croaks when trying to cross-compile for the ppc
>>> architecture. ?You can see at
>>> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-00install.html
>>> that the advice it to inform Apple of the compiler error but they
>>> ignore such reports. ?Things may improve when XCode 4 is in use
>>> because it provides clang++ in addition to the same very old version
>>> of g++. ?In the meantime we will provide a binary i386 Mac OS X
>>> package for RcppEigen.
>>
>>
>> Thank you for the hard work, it is very much appreciated. I use R 64-bit more than R 32-bit, but I guess all I have to do is to compile the package by hand (I'm on OS 10.7.3, and have Xcode 4.2.1, i.e. intel mac + clang), right?
>>
>> I never had any problems compiling packages where binaries were not available, I do not see how RccpEigen should give me more grief.
>>
>> Best wishes and, again, many thanks
>>
>> F
>>
>> --
>> Federico C. F. Calboli
>> Neuroepidemiology and Ageing Research
>> Imperial College, St. Mary's Campus
>> Norfolk Place, London W2 1PG
>>
>> Tel +44 (0)20 75941602 ? Fax +44 (0)20 75943193
>>
>> f.calboli [.a.t] imperial.ac.uk
>> f.calboli [.a.t] gmail.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ken.knoblauch at inserm.fr  Tue Feb  7 22:20:34 2012
From: ken.knoblauch at inserm.fr (ken knoblauch)
Date: Tue, 7 Feb 2012 21:20:34 +0000 (UTC)
Subject: [R-sig-ME] Upcoming changes in lme4
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
Message-ID: <loom.20120207T221646-279@post.gmane.org>

Douglas Bates <bates at ...> writes:

> 
> We (the lme4 authors) have mentioned on this list that we are
> preparing a new version of lme4 that will provide enhanced
> capabilities.  That's the good news.  The bad news is that the
> internal representation of the model has been changed yet again.  If
> your use of the lme4 package is through the exported functions only
> you should be okay.  However, if you find problems then please report
> them to us either in email <lme4-authors at ...> or on
> the bug-tracker at R-forge,
> 
>>>>> snip for gmane >>>>>>>>

> 
> An alpha-test release will be made available on the R-forge archive
> but *not* uploaded to CRAN.  If you use lme4 extensively please test
> this release by installing from the R-forge archive and telling us if
> there are problems with your code.  This way you can still back out to
> the current release by removing the lme4 package and reinstalling from
> CRAN.  Once the new lme4 has been released to CRAN it will be much
> more difficult to back out that installation.
> 
> Authors of packages that depend on lme4 will get a separate message
> off-list about testing and suggested modifications.
> 
> Thanks for your cooperation.  We do honestly believe that this change
> will provide an improved capability for fitting and analyzing
> mixed-effects models.
> 
I echo the thanks and congratulations of the other members of the list.

Will the link functions for glmer be built-in as currently with lme4 or
will it be possible to provide customized links in R code as currently
with lme4a?

best,

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From lborger at cebc.cnrs.fr  Tue Feb  7 22:40:47 2012
From: lborger at cebc.cnrs.fr (lborger)
Date: Tue, 07 Feb 2012 22:40:47 +0100
Subject: [R-sig-ME] nlme -95% CI of parameter estimates
In-Reply-To: <CAN8uQptfeq++wUU4H9dmL1k4E=gV+uNVB9+Hwro+QQbWo5+n1A@mail.gmail.com>
References: <CAN8uQptfeq++wUU4H9dmL1k4E=gV+uNVB9+Hwro+QQbWo5+n1A@mail.gmail.com>
Message-ID: <WC20120207214047.29010C@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/90c2e226/attachment-0001.pl>

From bates at stat.wisc.edu  Tue Feb  7 22:49:11 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Feb 2012 15:49:11 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <loom.20120207T221646-279@post.gmane.org>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<loom.20120207T221646-279@post.gmane.org>
Message-ID: <CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>

On Tue, Feb 7, 2012 at 3:20 PM, ken knoblauch <ken.knoblauch at inserm.fr> wrote:
> Douglas Bates <bates at ...> writes:
>
>>
>> We (the lme4 authors) have mentioned on this list that we are
>> preparing a new version of lme4 that will provide enhanced
>> capabilities. ?That's the good news. ?The bad news is that the
>> internal representation of the model has been changed yet again. ?If
>> your use of the lme4 package is through the exported functions only
>> you should be okay. ?However, if you find problems then please report
>> them to us either in email <lme4-authors at ...> or on
>> the bug-tracker at R-forge,
>>
>>>>>> snip for gmane >>>>>>>>
>
>>
>> An alpha-test release will be made available on the R-forge archive
>> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
>> this release by installing from the R-forge archive and telling us if
>> there are problems with your code. ?This way you can still back out to
>> the current release by removing the lme4 package and reinstalling from
>> CRAN. ?Once the new lme4 has been released to CRAN it will be much
>> more difficult to back out that installation.
>>
>> Authors of packages that depend on lme4 will get a separate message
>> off-list about testing and suggested modifications.
>>
>> Thanks for your cooperation. ?We do honestly believe that this change
>> will provide an improved capability for fitting and analyzing
>> mixed-effects models.
>>
> I echo the thanks and congratulations of the other members of the list.
>
> Will the link functions for glmer be built-in as currently with lme4 or
> will it be possible to provide customized links in R code as currently
> with lme4a?

Both.  Standard families (binomial, Gamma, gaussian, inverse.gaussian)
with typical links are evaluated in compiled code.  If the family is
not available in compiled code then callbacks to the R functions in
the family are used.

We are quite interested in collaborating with you to ensure that your
families in the psyphy package that allow asymptotes on binomial
probabilities can be used.



From ken.knoblauch at inserm.fr  Tue Feb  7 22:55:05 2012
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Tue, 07 Feb 2012 22:55:05 +0100
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<loom.20120207T221646-279@post.gmane.org>
	<CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>
Message-ID: <20120207225505.y4jq137x8gowkgo0@imp.inserm.fr>

Quoting Douglas Bates <bates at stat.wisc.edu>:

> On Tue, Feb 7, 2012 at 3:20 PM, ken knoblauch   
> <ken.knoblauch at inserm.fr> wrote:
>> Douglas Bates <bates at ...> writes:
>>
>>>
>>> We (the lme4 authors) have mentioned on this list that we are
>>> preparing a new version of lme4 that will provide enhanced
>>> capabilities. ?That's the good news. ?The bad news is that the
>>> internal representation of the model has been changed yet again. ?If
>>> your use of the lme4 package is through the exported functions only
>>> you should be okay. ?However, if you find problems then please report
>>> them to us either in email <lme4-authors at ...> or on
>>> the bug-tracker at R-forge,
>>>
>>>>>>> snip for gmane >>>>>>>>
>>
>>>
>>> An alpha-test release will be made available on the R-forge archive
>>> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
>>> this release by installing from the R-forge archive and telling us if
>>> there are problems with your code. ?This way you can still back out to
>>> the current release by removing the lme4 package and reinstalling from
>>> CRAN. ?Once the new lme4 has been released to CRAN it will be much
>>> more difficult to back out that installation.
>>>
>>> Authors of packages that depend on lme4 will get a separate message
>>> off-list about testing and suggested modifications.
>>>
>>> Thanks for your cooperation. ?We do honestly believe that this change
>>> will provide an improved capability for fitting and analyzing
>>> mixed-effects models.
>>>
>> I echo the thanks and congratulations of the other members of the list.
>>
>> Will the link functions for glmer be built-in as currently with lme4 or
>> will it be possible to provide customized links in R code as currently
>> with lme4a?
>
> Both.  Standard families (binomial, Gamma, gaussian, inverse.gaussian)
> with typical links are evaluated in compiled code.  If the family is
> not available in compiled code then callbacks to the R functions in
> the family are used.
>
> We are quite interested in collaborating with you to ensure that your
> families in the psyphy package that allow asymptotes on binomial
> probabilities can be used.
>

Great.  Thanks, again.  I'm looking forward to testing these.

best wishes,

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From bates at stat.wisc.edu  Tue Feb  7 22:55:29 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Feb 2012 15:55:29 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<loom.20120207T221646-279@post.gmane.org>
	<CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>
Message-ID: <CAO7JsnQUwUFuisW+8Leqq5oV4bPETSvk01p5hWpos7E--yr-9w@mail.gmail.com>

On Tue, Feb 7, 2012 at 3:49 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Feb 7, 2012 at 3:20 PM, ken knoblauch <ken.knoblauch at inserm.fr> wrote:
>> Douglas Bates <bates at ...> writes:
>>
>>>
>>> We (the lme4 authors) have mentioned on this list that we are
>>> preparing a new version of lme4 that will provide enhanced
>>> capabilities. ?That's the good news. ?The bad news is that the
>>> internal representation of the model has been changed yet again. ?If
>>> your use of the lme4 package is through the exported functions only
>>> you should be okay. ?However, if you find problems then please report
>>> them to us either in email <lme4-authors at ...> or on
>>> the bug-tracker at R-forge,
>>>
>>>>>>> snip for gmane >>>>>>>>
>>
>>>
>>> An alpha-test release will be made available on the R-forge archive
>>> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
>>> this release by installing from the R-forge archive and telling us if
>>> there are problems with your code. ?This way you can still back out to
>>> the current release by removing the lme4 package and reinstalling from
>>> CRAN. ?Once the new lme4 has been released to CRAN it will be much
>>> more difficult to back out that installation.
>>>
>>> Authors of packages that depend on lme4 will get a separate message
>>> off-list about testing and suggested modifications.
>>>
>>> Thanks for your cooperation. ?We do honestly believe that this change
>>> will provide an improved capability for fitting and analyzing
>>> mixed-effects models.
>>>
>> I echo the thanks and congratulations of the other members of the list.
>>
>> Will the link functions for glmer be built-in as currently with lme4 or
>> will it be possible to provide customized links in R code as currently
>> with lme4a?
>
> Both. ?Standard families (binomial, Gamma, gaussian, inverse.gaussian)

I forgot poisson.  It is available in compiled code too.

> with typical links are evaluated in compiled code. ?If the family is
> not available in compiled code then callbacks to the R functions in
> the family are used.
>
> We are quite interested in collaborating with you to ensure that your
> families in the psyphy package that allow asymptotes on binomial
> probabilities can be used.



From bbolker at gmail.com  Wed Feb  8 00:29:38 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Feb 2012 23:29:38 +0000 (UTC)
Subject: [R-sig-ME] Upcoming changes in lme4
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<2359_1328636892_1328636892_CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A70846@crcmail4.BCCRC.CA>
Message-ID: <loom.20120208T002622-219@post.gmane.org>

Steven McKinney <smckinney at ...> writes:

> 
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at ... [mailto:r-sig-mixed-models-
> > bounces at ...] On Behalf Of Douglas Bates
> > Sent: February-07-12 9:48 AM
> > Subject: Re: [R-sig-ME] Upcoming changes in lme4
> > 
> > On Tue, Feb 7, 2012 at 11:11 AM, Douglas Bates <bates at ...> wrote:
> > > We (the lme4 authors) have mentioned on this list that we are
> > > preparing a new version of lme4 that will provide enhanced
> > > capabilities. ?That's the good news. ?
> 
> <snip>
> 
>   In the meantime we will provide a binary i386 Mac OS X
> > package for RcppEigen.
> 

> Would you be able to provide Intel binary i386 (32 bit) and 
> x86_64 (64 bit) builds in your Mac OS X package?
> 


Try out the versions posted now at 

  http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/2.14/

I believe they include both 32- and 64-bit versions.

  Let me know if not.

  Ben Bolker



From smckinney at bccrc.ca  Wed Feb  8 00:42:01 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 7 Feb 2012 15:42:01 -0800
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <26630_1328657413_1328657413_loom.20120208T002622-219@post.gmane.org>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<2359_1328636892_1328636892_CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A70846@crcmail4.BCCRC.CA>
	<26630_1328657413_1328657413_loom.20120208T002622-219@post.gmane.org>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A70847@crcmail4.BCCRC.CA>


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: February-07-12 3:30 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Upcoming changes in lme4
> 
> Steven McKinney <smckinney at ...> writes:
> 
> >
> >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at ... [mailto:r-sig-mixed-models-
> > > bounces at ...] On Behalf Of Douglas Bates
> > > Sent: February-07-12 9:48 AM
> > > Subject: Re: [R-sig-ME] Upcoming changes in lme4
> > >
> > > On Tue, Feb 7, 2012 at 11:11 AM, Douglas Bates <bates at ...> wrote:
> > > > We (the lme4 authors) have mentioned on this list that we are
> > > > preparing a new version of lme4 that will provide enhanced
> > > > capabilities. ?That's the good news.
> >
> > <snip>
> >
> >   In the meantime we will provide a binary i386 Mac OS X
> > > package for RcppEigen.
> >
> 
> > Would you be able to provide Intel binary i386 (32 bit) and
> > x86_64 (64 bit) builds in your Mac OS X package?
> >
> 
> 
> Try out the versions posted now at
> 
>   http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/2.14/
> 
> I believe they include both 32- and 64-bit versions.

They do indeed, thank you very much.

Steve McKinney

> 
>   Let me know if not.
> 
>   Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From ovitek at stat.purdue.edu  Tue Feb  7 21:03:47 2012
From: ovitek at stat.purdue.edu (Olga Vitek)
Date: Tue, 7 Feb 2012 15:03:47 -0500
Subject: [R-sig-ME] Error when using models with lmer
Message-ID: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>

Hello, 

I am executing the following code

> library("lme4")
> library(faraway)
> data(penicillin)
> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)

and the lines below generate error messages

> library(gmodels)
> ci(fit4)
Error in as.vector(data) : 
 no method for coercing this S4 class to a vector

> contrast.function <- c(0, -1, 0, 0)
> test.result <- estimable(fit4, contrast.function)
Error in as.vector(data) : 
 no method for coercing this S4 class to a vector


This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.

Would you have suggestions on how to make this work?
Thank you in advance
Olga Vitek

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] gmodels_2.15.1   faraway_1.0.5    lme4_0.999375-42 Matrix_1.0-3     lattice_0.20-0  

loaded via a namespace (and not attached):
[1] gdata_2.8.2   grid_2.14.1   gtools_2.6.2  MASS_7.3-16   nlme_3.1-102  stats4_2.14.1 tools_2.14.1


From bates at stat.wisc.edu  Wed Feb  8 17:51:30 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Feb 2012 10:51:30 -0600
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
Message-ID: <CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>

On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
> Hello,
>
> I am executing the following code
>
>> library("lme4")
>> library(faraway)
>> data(penicillin)
>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>
> and the lines below generate error messages
>
>> library(gmodels)
>> ci(fit4)

Yes.  Why would you want to try to create a vector from an S4 fitted
model object?

It almost never makes sense to use

c(foo)

Most of the time when people use that idiom what they really mean is

foo

(I say "almost never" because in the old days many of us would use
c(myMatrix) to create a vector from a matrix.  The preferred form is
now as.vector(myMatrix).)

> Error in as.vector(data) :
> ?no method for coercing this S4 class to a vector
>
>> contrast.function <- c(0, -1, 0, 0)
>> test.result <- estimable(fit4, contrast.function)
> Error in as.vector(data) :

I assume that the "estimable" function is in the gmodels package, so
you should contact the author of that package about this.

> ?no method for coercing this S4 class to a vector
>
>
> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>
> Would you have suggestions on how to make this work?
> Thank you in advance
> Olga Vitek
>
>> sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>
> loaded via a namespace (and not attached):
> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From shsarafzade at gmail.com  Wed Feb  8 17:13:23 2012
From: shsarafzade at gmail.com (sheida sarafzade)
Date: Wed, 8 Feb 2012 20:43:23 +0430
Subject: [R-sig-ME] A question
Message-ID: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>

Hello
I'm MSc. student in biostatistics and working on mixed effect models
I?m trying to add fitted line to scatter plot (x,y)
Here ?weight? is dependent variable and ?month? is time variable.
The program is:
Lme1<-Lme(weight~month+(month^2),data=DataSetName,random=~month|id)

When I use the code below:
Lines(month[order(month)],fitted.lme(lme1,level=0)[order(month)])

It draws a smooth line but when I add a covariate (like birth weight)
to my model as below:

Lme2<-lme(weight~BirthWeight+month+(month^2),data=DataSetName,random=~month|id)

And then write the code below:
Lines(month[order(month)],fitted.lme(lme2,level=0)[order(month)])

It doesn?t draw smooth line. the line is not smooth.

How can I fix this problem?
What is the role of term ?level? in this code? And what are it?s option?

for more information please see attachment
Thanks a lot
-------------- next part --------------
A non-text attachment was scrubbed...
Name: question.pdf
Type: application/pdf
Size: 8814 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120208/1fd098e1/attachment-0001.pdf>

From istazahn at gmail.com  Wed Feb  8 19:51:34 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 8 Feb 2012 13:51:34 -0500
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
Message-ID: <CA+vqiLFyCcBriy009K8MRJEUwKGZGqqNZjbqPYz4Jzn0AJwPpw@mail.gmail.com>

Hi all,

Prof. Bates, I think you missed the "i" in "ci". It took me a while to
figure out, but I think the OP is trying to use ci.mer from the
gmodels package.

Olga, the proper course of action is to contact the gmodels maintainer
to alert them to this bug / incompatibility, as even the ci examples
do not run:

## Example from ci() documentation

fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
ci(fm2)
Error in as.vector(data) :
  no method for coercing this S4 class to a vector

Best,
Ista

On Wed, Feb 8, 2012 at 11:51 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>> Hello,
>>
>> I am executing the following code
>>
>>> library("lme4")
>>> library(faraway)
>>> data(penicillin)
>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>>
>> and the lines below generate error messages
>>
>>> library(gmodels)
>>> ci(fit4)
>
> Yes. ?Why would you want to try to create a vector from an S4 fitted
> model object?
>
> It almost never makes sense to use
>
> c(foo)
>
> Most of the time when people use that idiom what they really mean is
>
> foo
>
> (I say "almost never" because in the old days many of us would use
> c(myMatrix) to create a vector from a matrix. ?The preferred form is
> now as.vector(myMatrix).)
>
>> Error in as.vector(data) :
>> ?no method for coercing this S4 class to a vector
>>
>>> contrast.function <- c(0, -1, 0, 0)
>>> test.result <- estimable(fit4, contrast.function)
>> Error in as.vector(data) :
>
> I assume that the "estimable" function is in the gmodels package, so
> you should contact the author of that package about this.
>
>> ?no method for coercing this S4 class to a vector
>>
>>
>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>>
>> Would you have suggestions on how to make this work?
>> Thank you in advance
>> Olga Vitek
>>
>>> sessionInfo()
>> R version 2.14.1 (2011-12-22)
>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>>
>> loaded via a namespace (and not attached):
>> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Wed Feb  8 19:57:54 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Feb 2012 12:57:54 -0600
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <CA+vqiLFyCcBriy009K8MRJEUwKGZGqqNZjbqPYz4Jzn0AJwPpw@mail.gmail.com>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
	<CA+vqiLFyCcBriy009K8MRJEUwKGZGqqNZjbqPYz4Jzn0AJwPpw@mail.gmail.com>
Message-ID: <CAO7JsnTecTCKyDvUGqj+qxCNHX6uR7O++TjGD2KVeeegygVMUA@mail.gmail.com>

On Wed, Feb 8, 2012 at 12:51 PM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi all,
>
> Prof. Bates, I think you missed the "i" in "ci". It took me a while to
> figure out, but I think the OP is trying to use ci.mer from the
> gmodels package.

You're right.  My old eyes are failing me.  Soon I will be reduced to
sitting in a coffee shop with a bunch of other old guys complaining
about the government full time.

> Olga, the proper course of action is to contact the gmodels maintainer
> to alert them to this bug / incompatibility, as even the ci examples
> do not run:
>
> ## Example from ci() documentation
>
> fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
> ci(fm2)
> Error in as.vector(data) :
> ?no method for coercing this S4 class to a vector
>
> Best,
> Ista
>
> On Wed, Feb 8, 2012 at 11:51 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>>> Hello,
>>>
>>> I am executing the following code
>>>
>>>> library("lme4")
>>>> library(faraway)
>>>> data(penicillin)
>>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>>>
>>> and the lines below generate error messages
>>>
>>>> library(gmodels)
>>>> ci(fit4)
>>
>> Yes. ?Why would you want to try to create a vector from an S4 fitted
>> model object?
>>
>> It almost never makes sense to use
>>
>> c(foo)
>>
>> Most of the time when people use that idiom what they really mean is
>>
>> foo
>>
>> (I say "almost never" because in the old days many of us would use
>> c(myMatrix) to create a vector from a matrix. ?The preferred form is
>> now as.vector(myMatrix).)
>>
>>> Error in as.vector(data) :
>>> ?no method for coercing this S4 class to a vector
>>>
>>>> contrast.function <- c(0, -1, 0, 0)
>>>> test.result <- estimable(fit4, contrast.function)
>>> Error in as.vector(data) :
>>
>> I assume that the "estimable" function is in the gmodels package, so
>> you should contact the author of that package about this.
>>
>>> ?no method for coercing this S4 class to a vector
>>>
>>>
>>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>>>
>>> Would you have suggestions on how to make this work?
>>> Thank you in advance
>>> Olga Vitek
>>>
>>>> sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> other attached packages:
>>> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ovitek at stat.purdue.edu  Wed Feb  8 19:52:33 2012
From: ovitek at stat.purdue.edu (Olga Vitek)
Date: Wed, 8 Feb 2012 13:52:33 -0500
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
Message-ID: <FEAC9E5D-C93B-4DD9-8723-4DFC56D8E21E@stat.purdue.edu>

Dear Dr. Bates,

May I ask you for a clarification? The two problematic functions are indeed from the package gmodels

ci(fit4)                                         # 'ci' stands for confidence intervals of the fixed effects
estimable(fit4, c(0, -1, 0, 0))       # produces estimates of SE of the linear combination of the fixed effects

The difficulty is that there was no change in the version of gmodels before or after the problem occurred. The code worked with lme4_0.999375-40 and R2.13.1, but not with lme4_0.999375-42 and R2.14.1.

Could you kindly let me know if there were changes in the structure of the class 'mer' since lme4_0.999375-40? Alternatively, could you recommend other options for calculating standard errors of linear combinations of fixed effects?

Many thanks in advance
Olga Vitek





On Feb 8, 2012, at 11:51 AM, Douglas Bates wrote:

> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>> Hello,
>> 
>> I am executing the following code
>> 
>>> library("lme4")
>>> library(faraway)
>>> data(penicillin)
>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>> 
>> and the lines below generate error messages
>> 
>>> library(gmodels)
>>> ci(fit4)
> 
> Yes.  Why would you want to try to create a vector from an S4 fitted
> model object?
> 
> It almost never makes sense to use
> 
> c(foo)
> 
> Most of the time when people use that idiom what they really mean is
> 
> foo
> 
> (I say "almost never" because in the old days many of us would use
> c(myMatrix) to create a vector from a matrix.  The preferred form is
> now as.vector(myMatrix).)
> 
>> Error in as.vector(data) :
>>  no method for coercing this S4 class to a vector
>> 
>>> contrast.function <- c(0, -1, 0, 0)
>>> test.result <- estimable(fit4, contrast.function)
>> Error in as.vector(data) :
> 
> I assume that the "estimable" function is in the gmodels package, so
> you should contact the author of that package about this.
> 
>>  no method for coercing this S4 class to a vector
>> 
>> 
>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>> 
>> Would you have suggestions on how to make this work?
>> Thank you in advance
>> Olga Vitek
>> 
>>> sessionInfo()
>> R version 2.14.1 (2011-12-22)
>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] gmodels_2.15.1   faraway_1.0.5    lme4_0.999375-42 Matrix_1.0-3     lattice_0.20-0
>> 
>> loaded via a namespace (and not attached):
>> [1] gdata_2.8.2   grid_2.14.1   gtools_2.6.2  MASS_7.3-16   nlme_3.1-102  stats4_2.14.1 tools_2.14.1
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Tom_Philippi at nps.gov  Wed Feb  8 20:33:12 2012
From: Tom_Philippi at nps.gov (Tom_Philippi at nps.gov)
Date: Wed, 8 Feb 2012 11:33:12 -0800
Subject: [R-sig-ME] A question
In-Reply-To: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>
References: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>
Message-ID: <OF4E8FD4AE.151D7179-ON8525799E.005F158E-8825799E.006B696B@nps.gov>

Sheida--

What you are drawing with your call to lines() is a connect-the-dots graph,
where you have a number of points with different values for weight at each
discrete value of month.  The vertical bar at each month value is zigging
and zagging among all of your points at that value for month.  The lines
from one month to the next are simply connecting the last value at one
month to the first at the next month.  Why do you have so many points?  I
suspect because you have multiple population-level predictions for
different values of BirthWeight.

What value of BirthWeight do you want your line to represent?  Your graph
is only weight v month, but your second model is a response surface of
BirthWeight and month+month^2.  Do you have perfectly balanced data (same
set of months for each subject)?  Do you want to show a line of the
predictions for only the mean value of BirthWeight?  For perhaps quantiles
of the BirthWeight distribution?  For each individual value of BirthWeight
(which may or may not be each individual subject id)?

If you want to see what is going on, break apart your call to lines() by
making the fitted result a separate object:
Yfit <- fitted.lme(lme2,level=0)[order(month)]
head(Yfit)
nrow(Yfit)# probably 9 in your model without BirthWeight much larger in
model with BirthWeight
Lines(month[order(month)],Yfit[order(month)])


?fitted.lme explains the level= parameter: level=0 extracted
population-level fitted values, in your case I believe that level=1 would
give subject-level (id) fitted values (you can perform the experiment with
level=c(0:1) as in the example).

I hope that this helps steer you in the right direction.

Tom 2

ps: also, see:
fortunes::fortune(285)
about selecting a subject line more likely to attract responses from the
real gurus (not me) on this list.

-------------------------------------------
Tom Philippi, Ph.D.
Quantitative Ecologist
Inventory and Monitoring Program
National Park Service
c/o Cabrillo National Monument
1800 Cabrillo Memorial Dr
San Diego, CA 92106
(619) 523-4576
Tom_philippi at NPS.gov
http://science.nature.nps.gov/im/monitor
-------------------------------------------



                                                                           
             sheida sarafzade                                              
             <shsarafzade at gmai                                             
             l.com>                                                     To 
             Sent by:                  r-sig-mixed-models at r-project.org    
             r-sig-mixed-model                                          cc 
             s-bounces at r-proje         shsarafzade <shsarafzade at gmail.com> 
             ct.org                                                Subject 
                                       [R-sig-ME] A question               
                                                                           
             02/08/2012 08:43                                              
             PM ZE4B                                                       
                                                                           
                                                                           
                                                                           




Hello
I'm MSc. student in biostatistics and working on mixed effect models
I?m trying to add fitted line to scatter plot (x,y)
Here ?weight? is dependent variable and ?month? is time variable.
The program is:
Lme1<-Lme(weight~month+(month^2),data=DataSetName,random=~month|id)

When I use the code below:
Lines(month[order(month)],fitted.lme(lme1,level=0)[order(month)])

It draws a smooth line but when I add a covariate (like birth weight)
to my model as below:

Lme2<-lme(weight~BirthWeight+month+(month^2),data=DataSetName,random=~month|id)


And then write the code below:
Lines(month[order(month)],fitted.lme(lme2,level=0)[order(month)])

It doesn?t draw smooth line. the line is not smooth.

How can I fix this problem?
What is the role of term ?level? in this code? And what are it?s option?

for more information please see attachment
Thanks a lot
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bates at stat.wisc.edu  Wed Feb  8 21:11:19 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Feb 2012 14:11:19 -0600
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <FEAC9E5D-C93B-4DD9-8723-4DFC56D8E21E@stat.purdue.edu>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
	<FEAC9E5D-C93B-4DD9-8723-4DFC56D8E21E@stat.purdue.edu>
Message-ID: <CAO7JsnThLz-Vp29ybByGG+Jii2Bw9KLPF=txQQeTSMD0_iK6VQ@mail.gmail.com>

On Wed, Feb 8, 2012 at 12:52 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
> Dear Dr. Bates,
>
> May I ask you for a clarification? The two problematic functions are indeed from the package gmodels
>
> ci(fit4) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # 'ci' stands for confidence intervals of the fixed effects
> estimable(fit4, c(0, -1, 0, 0)) ? ? ? # produces estimates of SE of the linear combination of the fixed effects
>
> The difficulty is that there was no change in the version of gmodels before or after the problem occurred. The code worked with lme4_0.999375-40 and R2.13.1, but not with lme4_0.999375-42 and R2.14.1.

You need to go through some hidden functions to find out where the
problem lies.  Eventually it boils down to a hidden function called
gmodels:::est.mer which calls mcmcsamp and that function is no longer
available.

> Could you kindly let me know if there were changes in the structure of the class 'mer' since lme4_0.999375-40? Alternatively, could you recommend other options for calculating standard errors of linear combinations of fixed effects?
>
> Many thanks in advance
> Olga Vitek
>
>
>
>
>
> On Feb 8, 2012, at 11:51 AM, Douglas Bates wrote:
>
>> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>>> Hello,
>>>
>>> I am executing the following code
>>>
>>>> library("lme4")
>>>> library(faraway)
>>>> data(penicillin)
>>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>>>
>>> and the lines below generate error messages
>>>
>>>> library(gmodels)
>>>> ci(fit4)
>>
>> Yes. ?Why would you want to try to create a vector from an S4 fitted
>> model object?
>>
>> It almost never makes sense to use
>>
>> c(foo)
>>
>> Most of the time when people use that idiom what they really mean is
>>
>> foo
>>
>> (I say "almost never" because in the old days many of us would use
>> c(myMatrix) to create a vector from a matrix. ?The preferred form is
>> now as.vector(myMatrix).)
>>
>>> Error in as.vector(data) :
>>> ?no method for coercing this S4 class to a vector
>>>
>>>> contrast.function <- c(0, -1, 0, 0)
>>>> test.result <- estimable(fit4, contrast.function)
>>> Error in as.vector(data) :
>>
>> I assume that the "estimable" function is in the gmodels package, so
>> you should contact the author of that package about this.
>>
>>> ?no method for coercing this S4 class to a vector
>>>
>>>
>>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>>>
>>> Would you have suggestions on how to make this work?
>>> Thank you in advance
>>> Olga Vitek
>>>
>>>> sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> other attached packages:
>>> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Feb  8 23:37:02 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Feb 2012 16:37:02 -0600
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <CAO7JsnThLz-Vp29ybByGG+Jii2Bw9KLPF=txQQeTSMD0_iK6VQ@mail.gmail.com>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
	<FEAC9E5D-C93B-4DD9-8723-4DFC56D8E21E@stat.purdue.edu>
	<CAO7JsnThLz-Vp29ybByGG+Jii2Bw9KLPF=txQQeTSMD0_iK6VQ@mail.gmail.com>
Message-ID: <CAO7JsnTMWeaqAm63fZY=hQihRKVUt0kEKPXdL_jEqT3eFtp=tw@mail.gmail.com>

On Wed, Feb 8, 2012 at 2:11 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Feb 8, 2012 at 12:52 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>> Dear Dr. Bates,
>>
>> May I ask you for a clarification? The two problematic functions are indeed from the package gmodels
>>
>> ci(fit4) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # 'ci' stands for confidence intervals of the fixed effects
>> estimable(fit4, c(0, -1, 0, 0)) ? ? ? # produces estimates of SE of the linear combination of the fixed effects
>>
>> The difficulty is that there was no change in the version of gmodels before or after the problem occurred. The code worked with lme4_0.999375-40 and R2.13.1, but not with lme4_0.999375-42 and R2.14.1.
>
> You need to go through some hidden functions to find out where the
> problem lies. ?Eventually it boils down to a hidden function called
> gmodels:::est.mer which calls mcmcsamp and that function is no longer
> available.

Again, I misspoke.  It's just not my day.  The mcmcsamp function is
still available in the released version of lme4.  Actually the code in
gmodels is trying to convert the merMCMC object to a matrix and
somehow isn't seeing the necessary method for as.matrix.  It will have
to do with namespaces and the best way to solve that would be in the
NAMESPACE file for the gmodels package.

>> Could you kindly let me know if there were changes in the structure of the class 'mer' since lme4_0.999375-40? Alternatively, could you recommend other options for calculating standard errors of linear combinations of fixed effects?
>>
>> Many thanks in advance
>> Olga Vitek
>>
>>
>>
>>
>>
>> On Feb 8, 2012, at 11:51 AM, Douglas Bates wrote:
>>
>>> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>>>> Hello,
>>>>
>>>> I am executing the following code
>>>>
>>>>> library("lme4")
>>>>> library(faraway)
>>>>> data(penicillin)
>>>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>>>>
>>>> and the lines below generate error messages
>>>>
>>>>> library(gmodels)
>>>>> ci(fit4)
>>>
>>> Yes. ?Why would you want to try to create a vector from an S4 fitted
>>> model object?
>>>
>>> It almost never makes sense to use
>>>
>>> c(foo)
>>>
>>> Most of the time when people use that idiom what they really mean is
>>>
>>> foo
>>>
>>> (I say "almost never" because in the old days many of us would use
>>> c(myMatrix) to create a vector from a matrix. ?The preferred form is
>>> now as.vector(myMatrix).)
>>>
>>>> Error in as.vector(data) :
>>>> ?no method for coercing this S4 class to a vector
>>>>
>>>>> contrast.function <- c(0, -1, 0, 0)
>>>>> test.result <- estimable(fit4, contrast.function)
>>>> Error in as.vector(data) :
>>>
>>> I assume that the "estimable" function is in the gmodels package, so
>>> you should contact the author of that package about this.
>>>
>>>> ?no method for coercing this S4 class to a vector
>>>>
>>>>
>>>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>>>>
>>>> Would you have suggestions on how to make this work?
>>>> Thank you in advance
>>>> Olga Vitek
>>>>
>>>>> sessionInfo()
>>>> R version 2.14.1 (2011-12-22)
>>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>>
>>>> locale:
>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>>
>>>> other attached packages:
>>>> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From jwiley.psych at gmail.com  Thu Feb  9 01:32:25 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 8 Feb 2012 16:32:25 -0800
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
Message-ID: <CANz9Z_LPMXFT9me6CSZ7hXdbUnjWHcXoFEkxyaseUZdsZ933xg@mail.gmail.com>

Thanks to the authors for fantastic work.

Once the new version is pushed to CRAN, does anyone know if it will be
called lme4Eigen or the familiar lme4?

Josh

On Tue, Feb 7, 2012 at 9:11 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> We (the lme4 authors) have mentioned on this list that we are
> preparing a new version of lme4 that will provide enhanced
> capabilities. ?That's the good news. ?The bad news is that the
> internal representation of the model has been changed yet again. ?If
> your use of the lme4 package is through the exported functions only
> you should be okay. ?However, if you find problems then please report
> them to us either in email <lme4-authors at r-forge.wu-wien.ac.at> or on
> the bug-tracker at R-forge,
>
> https://r-forge.r-project.org/tracker/?func=add&group_id=60&atid=298
>
> One major, and unfortunately inevitable, problem that will affect many
> users is the inability of the new code to load saved objects created
> with the old code. ?Unfortunately that is what happens when you change
> the class representation. ?If possible it is best to save the code and
> data that generated the fitted model and re-fit after the change.
>
> If your usage involved access to components or slots in the object
> then there will be changes. ?To ease the transition, Martin created a
> function called getME that is available in the current lme4 and in the
> new lme4, available as lme4Eigen on R-forge. ?This function takes a
> fitted model and a character variable naming a component and returns
> the desired component. ?For example, if you want the fixed-effects
> model matrix from fitted model fm1 then use
>
> getME(fm1, "X")
>
> Similarly for the random-effects model matrix, "Z", or its transpose,
> "Zt", the sparse Cholesky factor, "L" and many others. ?Use
>
> library(lme4)
> example(getME)
>
> to get some examples.
>
> The new lme4 will provide
>
> ?- profiling of the deviance function with respect to the parameters
> ? in a linear mixed model (and soon generalized linear mixed models).
> ? The profiles allow for creation of realistic confidence intervals
> ? on the parameters and for various plots that show the sensitivity
> ? of the deviance to the values of the parameters.
>
> ?- a more reliable and flexible implementation of generalized linear
> ? mixed models, including the use of adaptive Gauss-Hermite
> ? quadrature for evaluating an approximation to the deviance.
>
> ?- short-cut functions such as refitML and refit to re-evaluate a
> ? model under the maximum likelihood criterion or with a new response
> ? vector.
>
> ?- a cleaner internal representations that provides, in most cases,
> ? faster and more reliable model fits.
>
> ?- choice of optimizer when estimating the parameters. ?Current
> ? choices are "NelderMead" and "bobyqa". ?Both are generally faster
> ? and more reliable than the optimizer used in the current lme4,
> ? which is based on the code in R's nlminb() function, the one that
> ? gives those annoying "false convergence" messages.
>
> ?- smaller memory footprint. ?The need for copying large objects is
> ? reduced through the use of reference classes in R. ?In the past
> ? there were circumstances where it was possible to fit a model to a
> ? large data set but not to print or show the results because a new
> ? copy of the entire object was created during the process of
> ? creating a summary. ?This no longer occurs.
>
> ?- nlmer has been improved and will, by the time of release, allow
> ? adaptive Gauss-Hermite quadrature.
>
> An alpha-test release will be made available on the R-forge archive
> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
> this release by installing from the R-forge archive and telling us if
> there are problems with your code. ?This way you can still back out to
> the current release by removing the lme4 package and reinstalling from
> CRAN. ?Once the new lme4 has been released to CRAN it will be much
> more difficult to back out that installation.
>
> Authors of packages that depend on lme4 will get a separate message
> off-list about testing and suggested modifications.
>
> Thanks for your cooperation. ?We do honestly believe that this change
> will provide an improved capability for fitting and analyzing
> mixed-effects models.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From acdelre at stanford.edu  Thu Feb  9 02:28:02 2012
From: acdelre at stanford.edu (AC Del Re)
Date: Wed, 8 Feb 2012 17:28:02 -0800
Subject: [R-sig-ME] LMM with Big data using binary DV
Message-ID: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120208/1b8ef48a/attachment-0001.pl>

From jwiley.psych at gmail.com  Thu Feb  9 03:28:13 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 8 Feb 2012 18:28:13 -0800
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
References: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
Message-ID: <CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>

Hi AC,

My personal preference would be glmer from the lme4 package.  I prefer
the Laplace approximation for the likelihood over the quasilikelihood
in glmmPQL.  To give some exemplary numbers, I simulated a dataset
with 2 million observations nested within 200 groups (10,000
observations per group).  I then ran an random intercepts model using:

system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))

where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
million, 6]; W = [2 million, 3]; G = [2 million, 1]

This took around 481 seconds to fit on a 1.6ghz dual core laptop.
With the OS and R running, my system used ~ 6GB of RAM for the model
and went up to ~7GB to show the summary (copies of the data are
made---changed in the upcoming version of lme4).

So as long as you have plenty of memory, you should have no trouble
modelling your data using glmer().  To initially make sure all your
code works, I might use a subset of your data (say 10k), once you are
convinced you have the model you want, run it on the full data.

Cheers,

Josh

On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
> Hi,
>
> I have a huge dataset (2.5 million patients nested within ?> 100
> facilities) and would like to examine variability across facilities in
> program utilization (0=n, 1=y; utilization rates are low in general), along
> with patient and facility predictors of utilization.
>
> I have 3 questions:
>
> 1. What program and/or package(s) do you recommend for running LMMs with
> big data (even if they are not R packages)?
>
> 2. Are there any clever work arounds (e.g., random sampling of subset of
> data, etc) that would allow me to use only R packages to run this dataset
> (assuming I need to use another program due to the size of the dataset)?
>
> 3. What type of LMM is recommended with a binary DV similar to the one I am
> wanting to examine? I know of two potential options (family=binomial option
> in lmer and the glmmPQL in the MASS package) but am not sure which is more
> appropriate or what other R packages and functions are available for this
> purpose?
>
> Thank you,
>
> AC
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From m.fenati at libero.it  Thu Feb  9 11:25:30 2012
From: m.fenati at libero.it (m.fenati at libero.it)
Date: Thu, 9 Feb 2012 11:25:30 +0100 (CET)
Subject: [R-sig-ME] ghlt different results for different hypotheses?
Message-ID: <5725262.8850411328783130878.JavaMail.defaultUser@defaultHost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/1233e3d4/attachment-0001.pl>

From raquel.benavides at mncn.csic.es  Thu Feb  9 12:01:21 2012
From: raquel.benavides at mncn.csic.es (Raquel Benavides)
Date: Thu, 9 Feb 2012 12:01:21 +0100
Subject: [R-sig-ME] hurdle model with glmmadmb
Message-ID: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/ff8e7127/attachment-0001.pl>

From j.hadfield at ed.ac.uk  Thu Feb  9 12:17:19 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 09 Feb 2012 11:17:19 +0000
Subject: [R-sig-ME] hurdle model with glmmadmb
In-Reply-To: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>
References: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>
Message-ID: <20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>

Hi,

missing bracket after parcela2?

Jarrod

Quoting Raquel Benavides <raquel.benavides at mncn.csic.es> on Thu, 9 Feb  
2012 12:01:21 +0100:

> Dear all,
>
>
>
> I am trying to run glmmADMB to check the effect of some fixed effects over
> the number of seedlings in some plots (my random factors are
> site/transect/plot). In particular, I want to run a hurdle model. I have
> tried to follow the instructions given in athe document uploaded in the
> webpage http://glmmadmb.r-forge.r-project.org/. However I have some errors,
> and I don?t really understand what do they mean. Does anybody understand
> what it means and how to avoid it?
>
>
>
>>
> seed_hurdle1<-glmmadmb(seedling~I(Tanual^2)+(1|site/transecto/parcela2,data=
> subset(datos,seedling>0),family="truncnbinom1")
>
>
>
> Error en glmmadmb(seedling ~ I(Tanual^2) + (1 | name/transecto/parcela),  :
>
>   The function maximizer failed (couldn't find STD file)
>
> Adem?s: Mensajes de aviso perdidos
>
> 1: In glmmadmb(seedling ~ I(Tanual2^2) + (1 | name/transecto/parcela),  :
>
>   zero response values in truncated family
>
> 2: comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c "C:/Archivos de
> programa/R/R-2.14.0/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500
> -maxph 5 -noinit -shess' tiene estatus 1
>
>
>
> Thanks
>
> Raquel
>
>
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From raquel.benavides at mncn.csic.es  Thu Feb  9 14:43:11 2012
From: raquel.benavides at mncn.csic.es (Raquel Benavides)
Date: Thu, 9 Feb 2012 14:43:11 +0100
Subject: [R-sig-ME] hurdle model with glmmadmb
In-Reply-To: <20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>
References: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>
	<20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>
Message-ID: <006101cce730$c3a7c3e0$4af74ba0$@mncn.csic.es>

I am afraid it isnt the problema, the bracket was missed during the copy process in the mail...Any other idea?

-----Mensaje original-----
De: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] 
Enviado el: jueves, 09 de febrero de 2012 12:17
Para: Raquel Benavides
CC: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] hurdle model with glmmadmb

Hi,

missing bracket after parcela2?

Jarrod

Quoting Raquel Benavides <raquel.benavides at mncn.csic.es> on Thu, 9 Feb
2012 12:01:21 +0100:

> Dear all,
>
>
>
> I am trying to run glmmADMB to check the effect of some fixed effects 
> over the number of seedlings in some plots (my random factors are 
> site/transect/plot). In particular, I want to run a hurdle model. I 
> have tried to follow the instructions given in athe document uploaded 
> in the webpage http://glmmadmb.r-forge.r-project.org/. However I have 
> some errors, and I don?t really understand what do they mean. Does 
> anybody understand what it means and how to avoid it?
>
>
>
>>
> seed_hurdle1<-glmmadmb(seedling~I(Tanual^2)+(1|site/transecto/parcela2
> ,data=
> subset(datos,seedling>0),family="truncnbinom1")
>
>
>
> Error en glmmadmb(seedling ~ I(Tanual^2) + (1 | name/transecto/parcela),  :
>
>   The function maximizer failed (couldn't find STD file)
>
> Adem?s: Mensajes de aviso perdidos
>
> 1: In glmmadmb(seedling ~ I(Tanual2^2) + (1 | name/transecto/parcela),  :
>
>   zero response values in truncated family
>
> 2: comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c "C:/Archivos de 
> programa/R/R-2.14.0/library/glmmADMB/bin/windows32/glmmadmb.exe" 
> -maxfn 500 -maxph 5 -noinit -shess' tiene estatus 1
>
>
>
> Thanks
>
> Raquel
>
>
> 	[[alternative HTML version deleted]]
>
>



--
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336.



From bbolker at gmail.com  Thu Feb  9 14:58:45 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 9 Feb 2012 13:58:45 +0000 (UTC)
Subject: [R-sig-ME] hurdle model with glmmadmb
References: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>
	<20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>
	<006101cce730$c3a7c3e0$4af74ba0$@mncn.csic.es>
Message-ID: <loom.20120209T145214-367@post.gmane.org>

Raquel Benavides <raquel.benavides at ...> writes:

> 
> I am afraid it isnt the problema, the bracket was missed during the copy
process in the mail...Any other idea?
> 
> -----Mensaje original-----
> De: Jarrod Hadfield [mailto:j.hadfield <at> ed.ac.uk] 
> 
> Hi,
> 
> missing bracket after parcela2?
> 
> Jarrod
> 
> Quoting Raquel Benavides <raquel.benavides <at> mncn.csic.es> on Thu, 9 Feb
> 2012 12:01:21 +0100:
> 
> > Dear all,
> >
> >
> >
> > I am trying to run glmmADMB to check the effect of some fixed effects 
> > over the number of seedlings in some plots (my random factors are 
> > site/transect/plot). In particular, I want to run a hurdle model. I 
> > have tried to follow the instructions given in athe document uploaded 
> > in the webpage http://glmmadmb.r-forge.r-project.org/. However I have 
> > some errors, and I don?t really understand what do they mean. Does 
> > anybody understand what it means and how to avoid it?
>
> > seed_hurdle1<-glmmadmb(seedling~I(Tanual^2)+(1|site/transecto/parcela2
> > ,data=
> > subset(datos,seedling>0),family="truncnbinom1")
> 
> > Error en glmmadmb(seedling ~ I(Tanual^2) + (1 | name/transecto/parcela),  :
> >
> >   The function maximizer failed (couldn't find STD file)
> >
> > Adem?s: Mensajes de aviso perdidos
> >
> > 1: In glmmadmb(seedling ~ I(Tanual2^2) + (1 | name/transecto/parcela),  :
> >
> >   zero response values in truncated family
> >
> > 2: comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c "C:/Archivos de 
> > programa/R/R-2.14.0/library/glmmADMB/bin/windows32/glmmadmb.exe" 
> > -maxfn 500 -maxph 5 -noinit -shess' tiene estatus 1

  Hmm.  It's surprising that you get the warning about zero response
values when you are explicitly using subset(datos, seedling>0).  Do you
by any chance have another copy of "seedling" lying around your
workspace, or have you attach()ed some data frames?  (This should
*not* break things, but it might anyway ...)

  You can try setting verbose=TRUE, although it will give you
loads of output where probably only the very end will be useful ...

  Are you willing to send me data?

  Ben Bolker



From andre.frainer at emg.umu.se  Thu Feb  9 17:33:14 2012
From: andre.frainer at emg.umu.se (=?Windows-1252?Q?Andr=E9_Barbosa?=)
Date: Thu, 9 Feb 2012 17:33:14 +0100
Subject: [R-sig-ME] random intercept and random slope
Message-ID: <5F7C032D-1E9E-453E-8898-4E059B8F8396@emg.umu.se>

Dear list members,
I have read several threads on this list about the use of random variables and its interpretation. I seem to have learned a lot about model fitting, from plotting the raw data and checking the slopes and intercepts, to getting rid of the p-value mindset in which I had had my basic statistics courses at university.
However, since my statistical courses never covered Mixed Effect Models, I am still unsure if I am doing the right thing or not. Having said that, would you please take a look at the following data and see if my rational is correct? The model is quite simple, I believe.
I have 8 different plant species, which were mixed two-by-two in all possible combinations. So, each species has 7 pairs + it being alone (monoculture). My response variable is a ratio (observed /expected productivity values, where observed is the productivity of species ?a? achieved when mixed with another species, and expected is its value when in monoculture).
Each species had its own nutrient content analyzed. As I had three nutrient variables measured from each plant, I calculated indices of dissimilarity for each of those pairs.
My starting model (without specifying random or fixed effects) would be:
ratio ~ dissimilarity | species
I expected, based on previous studies, that the relationship between ratio and dissimilarity would yield different slopes for each species, from negative to positive ? expectation confirmed by potting a xyplot function of my data. Thus, species should be random. Looking at the xyplot of my data, I also see that the intercepts are somehow variable, ranging between 0.5 and 1.5 (response data points do not extend much further from this range, either). For this reason, I thought on including intercepts as random, as well, which leave me without fixed variables.
So, I decided to test:
lmer(ratio ~ 1 + (dissimilarity|species))
Here follows a subset of my data:
species            pair            ratio            dissimilarity
a            a+b            1.090935            1.870297012
a            a+c            1.182509            0.691033781
a            a+d            1.505538            1.441237522
a            a+e            1.547295            0.953060747
a            a+f            1.463782            1.306913498
a            a+g            1.197587            1.331087471
a            a+h            1.113263            1.097840225
b            b+a            0.899969            1.870297012
b            b+c            1.102478            1.548604304
b            b+d            1.218110            1.669409077
b            b+e            1.095748            1.536191709
b            b+f            1.306822            1.579788658
b            b+g            1.299480            1.084382658
b            b+h            1.219945            1.137927922
c            c+a            1.092199            1.441237522
c            c+b            1.486702            1.669409077
c            c+d            0.847517            1.688612802
c            c+e            0.210150            0.651183878
c            c+f            1.459219            1.064428069
c            c+g            0.87810            0.590191888
c            c+h            0.91223            1.37455314
d            d+a            1.32486            0.953060747
d            d+b            1.37737            1.536191709
d            d+c            1.23869            1.310607287
d            d+e            1.15714            0.651183878
d            d+f            0.97390            1.22540051
d            d+g            0.92355            0.640371057
d            d+h            0.79097            1.224534999

The output from my model, using the whole data set is:
> summary(random.model)
Linear mixed model fit by REML
Formula: ratio~ 1 + (dissimilarity | species)
   Data: k
   AIC   BIC  logLik deviance REMLdev
 11.29 21.42 -0.6465   -3.273   1.293
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 species  (Intercept) 0.092206 0.30365
          dissimilarity        0.030348 0.17421  -1.000
 Residual             0.048348 0.21988
Number of obs: 56, groups: species, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.18024    0.04087   28.88

----

My questions:

1. Is my approach correct in plotting the independent variable ?dissimilarity? as random intercept, as in ~ 1 + (dissimilarity|species)?
2. On a publication, can I report the variance component of the random terms (in percentage) as the main result of the test?
3. Would it be possible to run McMC on a model that does not have Fixed Effects?
4. Would there be any other metrics that I should report as well?

I am sure that my questions are pretty basic, but I would strongly appreciate any input from you. Thank you!
Andre



From bates at stat.wisc.edu  Thu Feb  9 17:45:56 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 10:45:56 -0600
Subject: [R-sig-ME] Extracting means and SEs from an lmer object
In-Reply-To: <CAKFxdiThkd41kym8Ae9VzZFjetAhOU=o79=S1gzcZrM8PaT5Rg@mail.gmail.com>
References: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>
	<CAO7JsnTRCgruYbX4ux1iRRkWOhkxkdiwWyX1Rgjmok3kyKBm7A@mail.gmail.com>
	<CAKFxdiThkd41kym8Ae9VzZFjetAhOU=o79=S1gzcZrM8PaT5Rg@mail.gmail.com>
Message-ID: <CAO7JsnRaKO8Gwjd-O6jnF9oYzvZh4pvBXEfBbwkN-_ht1yVO6w@mail.gmail.com>

On Mon, Feb 6, 2012 at 5:29 PM, Kevin Wright <kw.stat at gmail.com> wrote:
> Doug,

> Relating to your comment below, there are getting to be quite a few R
> packages that fit mixed models in various forms.

> I have found myself often wishing that there was a generic 'fixef' and
> 'ranef' in the 'stats' package (similar to 'coef') to make it easier to work
> with different methods for these extractors.? The different class systems
> (S3, S4), different packages, and ever-changing R core (e.g. mandatory
> namespaces) have forced me to write and re-write multiple times the methods
> for fixef and ranef to support different packages.

> Any thoughts on this?

In lme4Eigen S3 methods are used even for S4 classes when method
dispatch is on the first argument only, which is the case for most
standard generics.  This avoids the problem of reconciling S4 generics
and S3 generics, which can get very complicated if more than one
package defines an S4 generic from the same S3 generic.  The majority
of the S3 generics are in the stats package, which is fine because the
stats package is usually attached.  As the nlme package is a
recommended package, it is assumed to be available but not always
loaded or attached.  I have opted for importing the S3 generics for
"fixef" and "ranef" and "VarCorr" from the nlme package but not
depending on the nlme package, which makes life too complicated.  The
generic is imported then exported and the method is declared in the
NAMESPACE file.  In other words, the NAMESPACE file has

importFrom(nlme, fixef)
export(fixef)
S3method(fixef,merMod)

and the same for ranef and VarCorr.  Right now that is the way that I
would recommend other package authors to handle the situation.  I'm
not sure if loading two such packages will give complaints about
masking the names - it may.

Eventually it might be best to move these generics to the stats
package.  Due to my own error I cannot currently change either the
stats package or the nlme package so I will need to wait for Martin to
return from vacation before making any changes.



>> The problem may be due to MEMSS bringing in other packages that mask
>> the definition of fixef in lme4. ?It works for me (see enclosed) if I
>> use
>> data(Orthodont, package="MEMSS")
>> instead.
>
>



From acdelre at stanford.edu  Thu Feb  9 17:48:15 2012
From: acdelre at stanford.edu (AC Del Re)
Date: Thu, 9 Feb 2012 08:48:15 -0800
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
References: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
	<CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
Message-ID: <CALsYQZe_Y0f0O8tq_P9EaxuE87ne6kAvHr=K33wMOZ8D0FbYJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/8310f852/attachment-0001.pl>

From ahmatias at gmail.com  Thu Feb  9 18:08:59 2012
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Thu, 9 Feb 2012 18:08:59 +0100
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
	convergence (7)"
Message-ID: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/2895ab26/attachment-0001.pl>

From bates at stat.wisc.edu  Thu Feb  9 18:16:47 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 11:16:47 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CANz9Z_LPMXFT9me6CSZ7hXdbUnjWHcXoFEkxyaseUZdsZ933xg@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CANz9Z_LPMXFT9me6CSZ7hXdbUnjWHcXoFEkxyaseUZdsZ933xg@mail.gmail.com>
Message-ID: <CAO7JsnRZGz2z2bCdKa6jaMGjZea=+ZdUgbzma1aJ0VmQ1BrgCA@mail.gmail.com>

On Wed, Feb 8, 2012 at 6:32 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Thanks to the authors for fantastic work.
>
> Once the new version is pushed to CRAN, does anyone know if it will be
> called lme4Eigen or the familiar lme4?

Current plan is that the new version will still be called lme4 but we
will also release to CRAN a package lme4preEigen as a bacikup for
users whose code gets broken by the new version.  At present Martin is
on vacation and the plan has not been confirmed by him (and he knows
more about the packaging system and CRAN than Ben or I do).  We will
wait until he returns next week before confirming.

> On Tue, Feb 7, 2012 at 9:11 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> We (the lme4 authors) have mentioned on this list that we are
>> preparing a new version of lme4 that will provide enhanced
>> capabilities. ?That's the good news. ?The bad news is that the
>> internal representation of the model has been changed yet again. ?If
>> your use of the lme4 package is through the exported functions only
>> you should be okay. ?However, if you find problems then please report
>> them to us either in email <lme4-authors at r-forge.wu-wien.ac.at> or on
>> the bug-tracker at R-forge,
>>
>> https://r-forge.r-project.org/tracker/?func=add&group_id=60&atid=298
>>
>> One major, and unfortunately inevitable, problem that will affect many
>> users is the inability of the new code to load saved objects created
>> with the old code. ?Unfortunately that is what happens when you change
>> the class representation. ?If possible it is best to save the code and
>> data that generated the fitted model and re-fit after the change.
>>
>> If your usage involved access to components or slots in the object
>> then there will be changes. ?To ease the transition, Martin created a
>> function called getME that is available in the current lme4 and in the
>> new lme4, available as lme4Eigen on R-forge. ?This function takes a
>> fitted model and a character variable naming a component and returns
>> the desired component. ?For example, if you want the fixed-effects
>> model matrix from fitted model fm1 then use
>>
>> getME(fm1, "X")
>>
>> Similarly for the random-effects model matrix, "Z", or its transpose,
>> "Zt", the sparse Cholesky factor, "L" and many others. ?Use
>>
>> library(lme4)
>> example(getME)
>>
>> to get some examples.
>>
>> The new lme4 will provide
>>
>> ?- profiling of the deviance function with respect to the parameters
>> ? in a linear mixed model (and soon generalized linear mixed models).
>> ? The profiles allow for creation of realistic confidence intervals
>> ? on the parameters and for various plots that show the sensitivity
>> ? of the deviance to the values of the parameters.
>>
>> ?- a more reliable and flexible implementation of generalized linear
>> ? mixed models, including the use of adaptive Gauss-Hermite
>> ? quadrature for evaluating an approximation to the deviance.
>>
>> ?- short-cut functions such as refitML and refit to re-evaluate a
>> ? model under the maximum likelihood criterion or with a new response
>> ? vector.
>>
>> ?- a cleaner internal representations that provides, in most cases,
>> ? faster and more reliable model fits.
>>
>> ?- choice of optimizer when estimating the parameters. ?Current
>> ? choices are "NelderMead" and "bobyqa". ?Both are generally faster
>> ? and more reliable than the optimizer used in the current lme4,
>> ? which is based on the code in R's nlminb() function, the one that
>> ? gives those annoying "false convergence" messages.
>>
>> ?- smaller memory footprint. ?The need for copying large objects is
>> ? reduced through the use of reference classes in R. ?In the past
>> ? there were circumstances where it was possible to fit a model to a
>> ? large data set but not to print or show the results because a new
>> ? copy of the entire object was created during the process of
>> ? creating a summary. ?This no longer occurs.
>>
>> ?- nlmer has been improved and will, by the time of release, allow
>> ? adaptive Gauss-Hermite quadrature.
>>
>> An alpha-test release will be made available on the R-forge archive
>> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
>> this release by installing from the R-forge archive and telling us if
>> there are problems with your code. ?This way you can still back out to
>> the current release by removing the lme4 package and reinstalling from
>> CRAN. ?Once the new lme4 has been released to CRAN it will be much
>> more difficult to back out that installation.
>>
>> Authors of packages that depend on lme4 will get a separate message
>> off-list about testing and suggested modifications.
>>
>> Thanks for your cooperation. ?We do honestly believe that this change
>> will provide an improved capability for fitting and analyzing
>> mixed-effects models.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Thu Feb  9 19:44:27 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 09 Feb 2012 13:44:27 -0500
Subject: [R-sig-ME] hurdle model with glmmadmb
In-Reply-To: <007001cce73c$aedd1440$0c973cc0$@mncn.csic.es>
References: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>	<20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>	<006101cce730$c3a7c3e0$4af74ba0$@mncn.csic.es>
	<loom.20120209T145214-367@post.gmane.org>
	<007001cce73c$aedd1440$0c973cc0$@mncn.csic.es>
Message-ID: <4F34140B.4090900@gmail.com>

  [cc'ing back to r-sig-mixed-models]

   There are a few different things going on here.

 (1) your attempt to drop data with zero seedlings failed, for the
following reason:
  (a) you defined new variables, seedling2, Tanual2, name2, etc. ...
*outside* of the datos2 data frame;
  (b) you passed data=subset(datos2,seedling2<0) to glmmADMB
  (c) but ... you used the new variables (seedling2 etc.) in your
formula, *not* names of variables from the data frame.  For example,
glmmADMB looks for a variable "seedling2" in the data frame specified by
the data= argument (which has been subsetted to remove the zero-seedling
cases); it doesn't find it, so it pulls the variable from the global
workspace.  But this variable (and the other variables) has *not* been
subsetted.

  I don't really know how to prevent this kind of error.  I could try to
make glmmADMB *only* look in the data frame specified by data= (at which
point you would get an error saying it couldn't find the 'seedling2'
variable or one of the other variables you specified), but that would be
a little bit tricky to program reliably, and is different (for better or
worse) from the way that the other modeling functions in R work (i.e.
they look first in 'data', then in other environments).  Checking for
length mismatches would work if you only specified *one* variable from
outside of the data frame, but not in the current case.  At least the
warning about zero cases alerts you that something is wrong ...

  Really the best advice is to try to manipulate variables *inside* the
data set, and keep things as clean as possible (see below).

  (2) if you did run glmmADMB with verbose=TRUE you would see the error:
42074072>=40000000
 No memory for dvar_vectors
 Need to increase ARRAY_MEMBLOCK_SIZE parameter

 This tells you the proximate reason why glmmADMB failed (although the
ultimate reason is as stated above).  There are 1717 total cases and
only 438 with seedlings>0, so this is a bigger data set.   If you did
want to run such a big model you would have to use extra.args="-ams
500000000" (I figured this out by poking around in the ADMB manual).
However, I had more trouble making the model work -- I stopped trying to
troubleshoot, knowing that I was working on the wrong data set anyway.

  (3) a couple of minor points: you may have trouble using 'name' as a
random effect, since it only has three levels; as long as you're going
to use the nesting syntax (name/transect/plot), you don't need to
construct the interaction terms yourself.

  Here is my recommended approach -- I manipulate the variables *only*
inside the data frame, and I do as little manipulation as I can get away
with (to keep things cleaner and easier to read).

## start from a CLEAN R session or rm(list=ls())
datos<-read.csv("regenerado_pisy.csv",header=TRUE,sep=";",dec=".")
datos2 <- transform(na.omit(datos),
                    name=factor(name),
                    transect=factor(transect),
                    plot=factor(plot))

library(glmmADMB)
seed_hurdle1<-glmmadmb(seedlings~I(Tmed_anual^2)+(1|name/transect/plot),
                       data=subset(datos2,seedlings>0),
                       family="truncnbinom1")


On 12-02-09 10:08 AM, Raquel Benavides wrote:
> Dear Ben, 
> I have attached the data and the script with the defined variables. The original ones, and then the variables excluding NAs, as previously I got a warning about different lengths of variables that disappeared with the new ones. 
> I tried to put verbose=TRUE and it told me where there were zeros. However, I can not understand why they were selected while I specified seedlings number >0.
> Thanks a lot
> Raquel
> 
> -----Mensaje original-----
> De: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Ben Bolker
> Enviado el: jueves, 09 de febrero de 2012 14:59
> Para: r-sig-mixed-models at r-project.org
> Asunto: Re: [R-sig-ME] hurdle model with glmmadmb
> 
> Raquel Benavides <raquel.benavides at ...> writes:
> 
>>
>> I am afraid it isnt the problema, the bracket was missed during the 
>> copy
> process in the mail...Any other idea?
>>
>> -----Mensaje original-----
>> De: Jarrod Hadfield [mailto:j.hadfield <at> ed.ac.uk]
>>
>> Hi,
>>
>> missing bracket after parcela2?
>>
>> Jarrod
>>
>> Quoting Raquel Benavides <raquel.benavides <at> mncn.csic.es> on Thu, 
>> 9 Feb
>> 2012 12:01:21 +0100:
>>
>>> Dear all,
>>>
>>>
>>>
>>> I am trying to run glmmADMB to check the effect of some fixed 
>>> effects over the number of seedlings in some plots (my random 
>>> factors are site/transect/plot). In particular, I want to run a 
>>> hurdle model. I have tried to follow the instructions given in athe 
>>> document uploaded in the webpage 
>>> http://glmmadmb.r-forge.r-project.org/. However I have some errors, 
>>> and I don?t really understand what do they mean. Does anybody understand what it means and how to avoid it?
>>
>>> seed_hurdle1<-glmmadmb(seedling~I(Tanual^2)+(1|site/transecto/parcel
>>> a2
>>> ,data=
>>> subset(datos,seedling>0),family="truncnbinom1")
>>
>>> Error en glmmadmb(seedling ~ I(Tanual^2) + (1 | name/transecto/parcela),  :
>>>
>>>   The function maximizer failed (couldn't find STD file)
>>>
>>> Adem?s: Mensajes de aviso perdidos
>>>
>>> 1: In glmmadmb(seedling ~ I(Tanual2^2) + (1 | name/transecto/parcela),  :
>>>
>>>   zero response values in truncated family
>>>
>>> 2: comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c "C:/Archivos de 
>>> programa/R/R-2.14.0/library/glmmADMB/bin/windows32/glmmadmb.exe"
>>> -maxfn 500 -maxph 5 -noinit -shess' tiene estatus 1
> 
>   Hmm.  It's surprising that you get the warning about zero response values when you are explicitly using subset(datos, seedling>0).  Do you by any chance have another copy of "seedling" lying around your workspace, or have you attach()ed some data frames?  (This should
> *not* break things, but it might anyway ...)
> 
>   You can try setting verbose=TRUE, although it will give you loads of output where probably only the very end will be useful ...
> 
>   Are you willing to send me data?
> 
>   Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kw.stat at gmail.com  Thu Feb  9 20:04:29 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 9 Feb 2012 13:04:29 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRZGz2z2bCdKa6jaMGjZea=+ZdUgbzma1aJ0VmQ1BrgCA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CANz9Z_LPMXFT9me6CSZ7hXdbUnjWHcXoFEkxyaseUZdsZ933xg@mail.gmail.com>
	<CAO7JsnRZGz2z2bCdKa6jaMGjZea=+ZdUgbzma1aJ0VmQ1BrgCA@mail.gmail.com>
Message-ID: <CAKFxdiRgOgzrZpC0xut5HjUd96kMsrPfe3hkRvM1iSV-kCgRHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/bf4715d7/attachment-0001.pl>

From bates at stat.wisc.edu  Thu Feb  9 21:03:49 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 14:03:49 -0600
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
 convergence (7)"
In-Reply-To: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
References: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
Message-ID: <CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>

On Thu, Feb 9, 2012 at 11:08 AM, Toni Hernandez-Matias
<ahmatias at gmail.com> wrote:
> Dear all,

> I am trying to fit a set of models with lmer function.
> My aim is to investigate the relationship between the abundance of a mammal
> species (count) and several environmental variables.
> The sample size is 648, but the observations are not independent and the
> random effect is nested: I have 10 study areas, within each area I
> performed 6 transects. I have 9-10 observations in all transects. So an
> example of a model with a single independent variable is:
> mod05<-lmer(cagaders~E_arb_alt+(1|ter)+(1|ter:trans),data=conill,family=poisson)

> When running this model I get the warning:
> In mer_finalize(ans) : singular convergence (7)

Try using verbose=TRUE to determine where the parameter values are
going during the iterative optimization process.

If your data could be made available, even in an anonymized form, we
could check the model fit against other optimizers that may be more
successful.

> I don't see an apparent reason for this warning.
> I would be very grateful if someone can help me to solve this problem and
> to know wether the results in the fitted model are credible.
>
> Thank you very much in advance,
>
> Toni
>
> --
> *********************************************************
>
> Antonio Hernandez Matias
>
> Departament de Biologia Animal (Vertebrats)
> Facultat de Biologia
> Universitat de Barcelona
> Av. Diagonal, 645
> Barcelona ? ? ?08028
> Spain
> Telephone: +34-934035857
> FAX: +34-934035740
> e-mail: ahernandezmatias at ub.edu
>
> ***********************************************************
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Thu Feb  9 21:13:24 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 14:13:24 -0600
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
References: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
	<CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
Message-ID: <CAO7JsnQVEiw9Y9SA6jNbhqejMxU87bWJL5MozfKzX++McOcyTA@mail.gmail.com>

On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi AC,
>
> My personal preference would be glmer from the lme4 package. ?I prefer
> the Laplace approximation for the likelihood over the quasilikelihood
> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
> with 2 million observations nested within 200 groups (10,000
> observations per group). ?I then ran an random intercepts model using:
>
> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>
> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>
> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
> With the OS and R running, my system used ~ 6GB of RAM for the model
> and went up to ~7GB to show the summary (copies of the data are
> made---changed in the upcoming version of lme4).
>
> So as long as you have plenty of memory, you should have no trouble
> modelling your data using glmer(). ?To initially make sure all your
> code works, I might use a subset of your data (say 10k), once you are
> convinced you have the model you want, run it on the full data.

If you would have an opportunity to run that model fit or a comparable
on lme4Eigen::glmer we would appreciate information about speed,
accuracy and memory usage.

In lme4Eigen::glmer there are different levels of precision in the
approximation to the deviance being optimizer.  These are controlled
by the nAGQ argument to the function.  The default, nAGQ=1, uses the
Laplace approximation.  The special value nAGQ=0 also uses the Laplace
approximation but profiles out the fixed-effects parameters.  This
profiling is not exact but usually gets you close to the optimum that
you would get from nAGQ=1, but much, much faster.  In a model like
this you can also use nAGQ>1 and <= 25.  On the model fits we have
tried we don't see a lot of difference in timing between, say, nAGQ=9
and nAGQ=25 but on a model fit like this you might.

As a fallback, we would appreciate the code that you used to simulate
the response.  We could generate something ourselves, of course, but
it is easier to compare when you copy someone else's simulation.
> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>> Hi,
>>
>> I have a huge dataset (2.5 million patients nested within ?> 100
>> facilities) and would like to examine variability across facilities in
>> program utilization (0=n, 1=y; utilization rates are low in general), along
>> with patient and facility predictors of utilization.
>>
>> I have 3 questions:
>>
>> 1. What program and/or package(s) do you recommend for running LMMs with
>> big data (even if they are not R packages)?
>>
>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>> data, etc) that would allow me to use only R packages to run this dataset
>> (assuming I need to use another program due to the size of the dataset)?
>>
>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>> wanting to examine? I know of two potential options (family=binomial option
>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>> appropriate or what other R packages and functions are available for this
>> purpose?
>>
>> Thank you,
>>
>> AC
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Thu Feb  9 21:59:13 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 14:59:13 -0600
Subject: [R-sig-ME] random intercept and random slope
In-Reply-To: <5F7C032D-1E9E-453E-8898-4E059B8F8396@emg.umu.se>
References: <5F7C032D-1E9E-453E-8898-4E059B8F8396@emg.umu.se>
Message-ID: <CAO7JsnTUAoZ8v-_6Ba+7Wjytx+Eh=oyi1Z=d2HQ-Fwhd1X=6AQ@mail.gmail.com>

2012/2/9 Andr? Barbosa <andre.frainer at emg.umu.se>:
> Dear list members,
> I have read several threads on this list about the use of random variables and its interpretation. I seem to have learned a lot about model fitting, from plotting the raw data and checking the slopes and intercepts, to getting rid of the p-value mindset in which I had had my basic statistics courses at university.
> However, since my statistical courses never covered Mixed Effect Models, I am still unsure if I am doing the right thing or not. Having said that, would you please take a look at the following data and see if my rational is correct? The model is quite simple, I believe.
> I have 8 different plant species, which were mixed two-by-two in all possible combinations. So, each species has 7 pairs + it being alone (monoculture). My response variable is a ratio (observed /expected productivity values, where observed is the productivity of species ?a? achieved when mixed with another species, and expected is its value when in monoculture).
> Each species had its own nutrient content analyzed. As I had three nutrient variables measured from each plant, I calculated indices of dissimilarity for each of those pairs.
> My starting model (without specifying random or fixed effects) would be:
> ratio ~ dissimilarity | species
> I expected, based on previous studies, that the relationship between ratio and dissimilarity would yield different slopes for each species, from negative to positive ? expectation confirmed by potting a xyplot function of my data. Thus, species should be random. Looking at the xyplot of my data, I also see that the intercepts are somehow variable, ranging between 0.5 and 1.5 (response data points do not extend much further from this range, either). For this reason, I thought on including intercepts as random, as well, which leave me without fixed variables.
> So, I decided to test:
> lmer(ratio ~ 1 + (dissimilarity|species))
> Here follows a subset of my data:
> species ? ? ? ? ? ?pair ? ? ? ? ? ?ratio ? ? ? ? ? ?dissimilarity
> a ? ? ? ? ? ?a+b ? ? ? ? ? ?1.090935 ? ? ? ? ? ?1.870297012
> a ? ? ? ? ? ?a+c ? ? ? ? ? ?1.182509 ? ? ? ? ? ?0.691033781
> a ? ? ? ? ? ?a+d ? ? ? ? ? ?1.505538 ? ? ? ? ? ?1.441237522
> a ? ? ? ? ? ?a+e ? ? ? ? ? ?1.547295 ? ? ? ? ? ?0.953060747
> a ? ? ? ? ? ?a+f ? ? ? ? ? ?1.463782 ? ? ? ? ? ?1.306913498
> a ? ? ? ? ? ?a+g ? ? ? ? ? ?1.197587 ? ? ? ? ? ?1.331087471
> a ? ? ? ? ? ?a+h ? ? ? ? ? ?1.113263 ? ? ? ? ? ?1.097840225
> b ? ? ? ? ? ?b+a ? ? ? ? ? ?0.899969 ? ? ? ? ? ?1.870297012
> b ? ? ? ? ? ?b+c ? ? ? ? ? ?1.102478 ? ? ? ? ? ?1.548604304
> b ? ? ? ? ? ?b+d ? ? ? ? ? ?1.218110 ? ? ? ? ? ?1.669409077
> b ? ? ? ? ? ?b+e ? ? ? ? ? ?1.095748 ? ? ? ? ? ?1.536191709
> b ? ? ? ? ? ?b+f ? ? ? ? ? ?1.306822 ? ? ? ? ? ?1.579788658
> b ? ? ? ? ? ?b+g ? ? ? ? ? ?1.299480 ? ? ? ? ? ?1.084382658
> b ? ? ? ? ? ?b+h ? ? ? ? ? ?1.219945 ? ? ? ? ? ?1.137927922
> c ? ? ? ? ? ?c+a ? ? ? ? ? ?1.092199 ? ? ? ? ? ?1.441237522
> c ? ? ? ? ? ?c+b ? ? ? ? ? ?1.486702 ? ? ? ? ? ?1.669409077
> c ? ? ? ? ? ?c+d ? ? ? ? ? ?0.847517 ? ? ? ? ? ?1.688612802
> c ? ? ? ? ? ?c+e ? ? ? ? ? ?0.210150 ? ? ? ? ? ?0.651183878
> c ? ? ? ? ? ?c+f ? ? ? ? ? ?1.459219 ? ? ? ? ? ?1.064428069
> c ? ? ? ? ? ?c+g ? ? ? ? ? ?0.87810 ? ? ? ? ? ?0.590191888
> c ? ? ? ? ? ?c+h ? ? ? ? ? ?0.91223 ? ? ? ? ? ?1.37455314
> d ? ? ? ? ? ?d+a ? ? ? ? ? ?1.32486 ? ? ? ? ? ?0.953060747
> d ? ? ? ? ? ?d+b ? ? ? ? ? ?1.37737 ? ? ? ? ? ?1.536191709
> d ? ? ? ? ? ?d+c ? ? ? ? ? ?1.23869 ? ? ? ? ? ?1.310607287
> d ? ? ? ? ? ?d+e ? ? ? ? ? ?1.15714 ? ? ? ? ? ?0.651183878
> d ? ? ? ? ? ?d+f ? ? ? ? ? ?0.97390 ? ? ? ? ? ?1.22540051
> d ? ? ? ? ? ?d+g ? ? ? ? ? ?0.92355 ? ? ? ? ? ?0.640371057
> d ? ? ? ? ? ?d+h ? ? ? ? ? ?0.79097 ? ? ? ? ? ?1.224534999
>
> The output from my model, using the whole data set is:
>> summary(random.model)
> Linear mixed model fit by REML
> Formula: ratio~ 1 + (dissimilarity | species)
> ? Data: k
> ? AIC ? BIC ?logLik deviance REMLdev
> ?11.29 21.42 -0.6465 ? -3.273 ? 1.293
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
> ?species ?(Intercept) 0.092206 0.30365
> ? ? ? ? ?dissimilarity ? ? ? ?0.030348 0.17421 ?-1.000
> ?Residual ? ? ? ? ? ? 0.048348 0.21988
> Number of obs: 56, groups: species, 8
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?1.18024 0.04087 ? 28.88
>
> ----
>
> My questions:
>
> 1. Is my approach correct in plotting the independent variable ?dissimilarity? as random intercept, as in ~ 1 + (dissimilarity|species)?

Probably not.  The random effects are defined to have mean 0 so any
non-zero mean must occur in the fixed effects.  Generally the model to
be fit is

ratio ~ 1 + dissumilarity + (1 + dissimilarlity|species)

which is equivalent to

ratio ~ dissimilarity + (dissimilarity|specties)

It is a matter of taste whether to include the 1+ or not in a model
formula like this.  I find that doing so emphasizes to me where each
of the parameters come from.

> 2. On a publication, can I report the variance component of the random terms (in percentage) as the main result of the test?
> 3. Would it be possible to run McMC on a model that does not have Fixed Effects?
> 4. Would there be any other metrics that I should report as well?
>
> I am sure that my questions are pretty basic, but I would strongly appreciate any input from you. Thank you!
> Andre
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ahmatias at gmail.com  Fri Feb 10 12:06:19 2012
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Fri, 10 Feb 2012 12:06:19 +0100
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
 convergence (7)"
In-Reply-To: <CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
References: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
	<CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
Message-ID: <CA+hwERn-9DHnOVr9omj50dRY-wfQ4aDBEDiqiktSBdmexf4_uw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120210/064c53c7/attachment-0001.pl>

From m.fairbrother at bristol.ac.uk  Fri Feb 10 13:20:45 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 10 Feb 2012 12:20:45 +0000
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
References: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
Message-ID: <FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>

Dear AC (and perhaps Doug),

>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>> data, etc) that would allow me to use only R packages to run this dataset
>>> (assuming I need to use another program due to the size of the dataset)?

You may be well aware of this, but one way of substantially speeding up the estimation of models with binary data is to use "cbind", though the feasibility of this depends on the nature of the model (number of predictors and number of unique values for each predictor variable). The kind of code you need for this is below. You'll see that the fixed effects estimates, standard errors, and random effects variances turn out the same.

> If you would have an opportunity to run that model fit or a comparable
> on lme4Eigen::glmer we would appreciate information about speed,
> accuracy and memory usage.

> As a fallback, we would appreciate the code that you used to simulate
> the response.  We could generate something ourselves, of course, but
> it is easier to compare when you copy someone else's simulation.

I've compared the speed of lme4 versus lme4Eigen, on a simulated dataset with 100,000 observations, using a 2GHz MacBook. Based on a handful of simulations, there doesn't appear to be much difference between the two packages in terms of speed (sometimes one is faster, sometimes the other). I have reported the results of one simulation here. The two packages generate identical results for this dataset.

Cheers,
Malcolm


N <- 100000
grps <- 100
dat <- data.frame(x1 = sample(1:10, N, replace=T), x2 = sample(18:23, N, replace=T), grp=rep(1:grps, each=N/grps))
dat$y <- rbinom(N, prob = plogis(-5 + 0.1*dat$x1 + 0.2*dat$x2 + rnorm(grps)[dat$grp]), size = 1)
failures <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==0))
successes <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==1))
dat2 <- expand.grid(x1=sort(unique(dat$x1)), x2=sort(unique(dat$x2)), grp=sort(unique(dat$grp)))
dat2$failures <- as.vector(failures)
dat2$successes <- as.vector(successes)
library(lme4)
system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
#   user  system elapsed 
# 22.918   0.660  24.441
system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
#   user  system elapsed 
#  1.833   0.017   1.855 
detach("package:lme4")
library(lme4Eigen)
system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
#   user  system elapsed 
# 24.824   1.811  26.773 
system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
#   user  system elapsed 
#  1.687   0.039   1.723



> Date: Thu, 9 Feb 2012 14:13:24 -0600
> From: Douglas Bates <bates at stat.wisc.edu>
> To: Joshua Wiley <jwiley.psych at gmail.com>
> Cc: AC Del Re <acdelre at stanford.edu>, r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] LMM with Big data using binary DV
> 
> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>> Hi AC,
>> 
>> My personal preference would be glmer from the lme4 package. ?I prefer
>> the Laplace approximation for the likelihood over the quasilikelihood
>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>> with 2 million observations nested within 200 groups (10,000
>> observations per group). ?I then ran an random intercepts model using:
>> 
>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>> 
>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>> 
>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>> With the OS and R running, my system used ~ 6GB of RAM for the model
>> and went up to ~7GB to show the summary (copies of the data are
>> made---changed in the upcoming version of lme4).
>> 
>> So as long as you have plenty of memory, you should have no trouble
>> modelling your data using glmer(). ?To initially make sure all your
>> code works, I might use a subset of your data (say 10k), once you are
>> convinced you have the model you want, run it on the full data.
> 
> If you would have an opportunity to run that model fit or a comparable
> on lme4Eigen::glmer we would appreciate information about speed,
> accuracy and memory usage.
> 
> In lme4Eigen::glmer there are different levels of precision in the
> approximation to the deviance being optimizer.  These are controlled
> by the nAGQ argument to the function.  The default, nAGQ=1, uses the
> Laplace approximation.  The special value nAGQ=0 also uses the Laplace
> approximation but profiles out the fixed-effects parameters.  This
> profiling is not exact but usually gets you close to the optimum that
> you would get from nAGQ=1, but much, much faster.  In a model like
> this you can also use nAGQ>1 and <= 25.  On the model fits we have
> tried we don't see a lot of difference in timing between, say, nAGQ=9
> and nAGQ=25 but on a model fit like this you might.
> 
> As a fallback, we would appreciate the code that you used to simulate
> the response.  We could generate something ourselves, of course, but
> it is easier to compare when you copy someone else's simulation.
>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>> Hi,
>>> 
>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>> facilities) and would like to examine variability across facilities in
>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>> with patient and facility predictors of utilization.
>>> 
>>> I have 3 questions:
>>> 
>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>> big data (even if they are not R packages)?
>>> 
>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>> data, etc) that would allow me to use only R packages to run this dataset
>>> (assuming I need to use another program due to the size of the dataset)?
>>> 
>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>> wanting to examine? I know of two potential options (family=binomial option
>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>> appropriate or what other R packages and functions are available for this
>>> purpose?
>>> 
>>> Thank you,
>>> 
>>> AC



From schmidt.fa at gmail.com  Fri Feb 10 14:37:04 2012
From: schmidt.fa at gmail.com (Fernando Schmidt)
Date: Fri, 10 Feb 2012 11:37:04 -0200
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
 convergence (7)"
In-Reply-To: <CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
References: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
	<CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
Message-ID: <CACddD7Bmkdcf+M-prA6PmLXynnh65AT7o-ZYigpHN=kK_q0SiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120210/0ff616ca/attachment-0001.pl>

From 538280 at gmail.com  Fri Feb 10 17:25:35 2012
From: 538280 at gmail.com (538280 at gmail.com)
Date: Fri, 10 Feb 2012 09:25:35 -0700
Subject: [R-sig-ME] A question
In-Reply-To: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>
References: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>
Message-ID: <CAFEqCdwog6swNu4jiJMuYpgokuUpAfhsfYFkfk53Us=g1p-6dw@mail.gmail.com>

Assuming that you are using the lme function from the nlme package,
you probably want to look at the augPred and plot.augPred functions in
the same package for more meaningful ways to make and plot predictions
from mixed effects models.

On Wed, Feb 8, 2012 at 9:13 AM, sheida sarafzade <shsarafzade at gmail.com> wrote:
> Hello
> I'm MSc. student in biostatistics and working on mixed effect models
> I?m trying to add fitted line to scatter plot (x,y)
> Here ?weight? is dependent variable and ?month? is time variable.
> The program is:
> Lme1<-Lme(weight~month+(month^2),data=DataSetName,random=~month|id)
>
> When I use the code below:
> Lines(month[order(month)],fitted.lme(lme1,level=0)[order(month)])
>
> It draws a smooth line but when I add a covariate (like birth weight)
> to my model as below:
>
> Lme2<-lme(weight~BirthWeight+month+(month^2),data=DataSetName,random=~month|id)
>
> And then write the code below:
> Lines(month[order(month)],fitted.lme(lme2,level=0)[order(month)])
>
> It doesn?t draw smooth line. the line is not smooth.
>
> How can I fix this problem?
> What is the role of term ?level? in this code? And what are it?s option?
>
> for more information please see attachment
> Thanks a lot
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From schmidt.fa at gmail.com  Fri Feb 10 18:25:26 2012
From: schmidt.fa at gmail.com (Fernando Schmidt)
Date: Fri, 10 Feb 2012 15:25:26 -0200
Subject: [R-sig-ME] Doubts about model.avg function at MuMin package
Message-ID: <CACddD7B=RGhY_tgzpdL+mR_wLt3vfw7W9pTwY9wSGMB4HY2LZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120210/a2fcf1b4/attachment-0001.pl>

From 538280 at gmail.com  Fri Feb 10 18:36:05 2012
From: 538280 at gmail.com (538280 at gmail.com)
Date: Fri, 10 Feb 2012 10:36:05 -0700
Subject: [R-sig-ME] ghlt different results for different hypotheses?
In-Reply-To: <5725262.8850411328783130878.JavaMail.defaultUser@defaultHost>
References: <5725262.8850411328783130878.JavaMail.defaultUser@defaultHost>
Message-ID: <CAFEqCdwUaqPATpxyo2dvL87PQL0F+uRLz5mzxYTQqUf_Sjv-1Q@mail.gmail.com>

The more comparisons/tests that you do the more opportunities you have
of getting a type I error.  The multiple comparisons procedures adjust
for the number of comparisons so that the overall probability of
making at least 1 type I error is fixed.  So the more comparisons the
more adjustment needs to be made.

Think of this simple example.  You are playing a game where you are
trying to throw a wadded up piece of paper into a basket, you win if
you get it in at least once.  What are your chances of winning if you
get 10 tries compared to if you get 20 tries (from the same spot)?  If
you want the same chance of winning with 20 tries as you had for 10
tries (or 1 try), then you need to move further away or some other
penalty.

So with glht there is a bigger penalty when you do more comparisons
since there are more opportunities of making a type I error.

On Thu, Feb 9, 2012 at 3:25 AM, m.fenati at libero.it <m.fenati at libero.it> wrote:
>
>
> Dear R users,
> I would like to understand a simple problem related to glht() multeplicity correction and linear Hypotheses testing. Given a simple lme model with two predictors (group = 3 levels; time = ?2 levels) and their interaction with treatment contrast, I see that the p-values are lower and higher when I test few or many hypotheses respectively. Because I dont't have a deep knowledge of multiple comparison theory, I ask you some suggestion or explanation about the different obtained results.
> As you can see in the example below, "m1" and "m2" test a different number of hypotheses but comparing the same hypothesis a different results occurred.
>
>
> time<-rep(c(rep(0,8),rep(1,8)),3)
> group<-c(rep(0,16),rep(1,16),rep(2,16))
> id<-c(rep(1:8,2),rep(9:16,2),rep(17:24,2))
> w<-c(172.9, 185.8, 173.1, 187.3, 161.6, 167.1, 168.4, 161.1, 166.5, 175.3, 167.1, 181.9, 163.0, 167.7, 172.1, 170.3, 167.2, 183.3, 160.7,167.8, 149.6, 159.1, 164.2, 171.0, 168.6, 173.5, 161.8, 166.5, 148.4, 167.1, 166.8, 166.6, 150.6, 178.4, 166.4, 159.2, 163.2, 167.8, 136.6, 161.8, 166.1, 175.8, 175.6, 166.2, 168.5, 170.5, 152.0, 164.4)
> dati<-data.frame(time,group,id,w)
> dati$time<-as.factor(dati$time)
> dati$group<-as.factor(dati$group)
> dati$id<-as.factor(dati$id)
>
>
>
>
> kp<-rbind("after Treatment: Group 1 - Controls"=c(0,1,0,0,0,0),
> ? ? ? ? "after Treatment: Group 2 - Controls"=c(0,0,1,0,0,0),
> ? ? ? ? "before Treatment: Group 1 - Controls"=c(0,1,0,0,1,0),
> ? ? ? ? "before Treatment: Group 2 - Controls"=c(0,0,1,0,0,1),
> ? ? ? ? "Controls: time trend (T1 - T0)"=c(0,0,0,-1,0,0),
> ? ? ? ? "Group 1: time trend (T1 - T0)"=c(0,0,0,-1,-1,0),
> ? ? ? ? "Group 2: time trend (T1 - T0)"=c(0,0,0,-1,0,-1))
>
>
> k<-rbind("after Treatment: Group 1 - Controls"=c(0,1,0,0,0,0),
> ? ? ? ? "after Treatment: Group 2 - Controls"=c(0,0,1,0,0,0),
> ? ? ? ? "before Treatment: Group 1 - Controls"=c(0,1,0,0,1,0),
> ? ? ? ? "before Treatment: Group 2 - Controls"=c(0,0,1,0,0,1)
> ? ? ? ? )
>
>
>
>
> w.lme<-lme(w~group*time,data=dati,random=~1|id)
> m1<-summary(glht(w.lme,kp))
> m2<-summary(glht(w.lme,k))
>
>
> Thank in advances for your suggestions
>
>
> Massimo
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From bates at stat.wisc.edu  Fri Feb 10 18:36:10 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 10 Feb 2012 11:36:10 -0600
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>
References: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
	<FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>
Message-ID: <CAO7JsnSDMS_unUTP+dECFJfkBnJSojkXixchyi1Y3GQVCH-1AA@mail.gmail.com>

On Fri, Feb 10, 2012 at 6:20 AM, Malcolm Fairbrother
<m.fairbrother at bristol.ac.uk> wrote:
> Dear AC (and perhaps Doug),
>
>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>> (assuming I need to use another program due to the size of the dataset)?
>
> You may be well aware of this, but one way of substantially speeding up the estimation of models with binary data is to use "cbind", though the feasibility of this depends on the nature of the model (number of predictors and number of unique values for each predictor variable). The kind of code you need for this is below. You'll see that the fixed effects estimates, standard errors, and random effects variances turn out the same.
>
>> If you would have an opportunity to run that model fit or a comparable
>> on lme4Eigen::glmer we would appreciate information about speed,
>> accuracy and memory usage.
>
>> As a fallback, we would appreciate the code that you used to simulate
>> the response. ?We could generate something ourselves, of course, but
>> it is easier to compare when you copy someone else's simulation.
>
> I've compared the speed of lme4 versus lme4Eigen, on a simulated dataset with 100,000 observations, using a 2GHz MacBook. Based on a handful of simulations, there doesn't appear to be much difference between the two packages in terms of speed (sometimes one is faster, sometimes the other). I have reported the results of one simulation here. The two packages generate identical results for this dataset.
>
> Cheers,
> Malcolm
>
>
> N <- 100000
> grps <- 100
> dat <- data.frame(x1 = sample(1:10, N, replace=T), x2 = sample(18:23, N, replace=T), grp=rep(1:grps, each=N/grps))
> dat$y <- rbinom(N, prob = plogis(-5 + 0.1*dat$x1 + 0.2*dat$x2 + rnorm(grps)[dat$grp]), size = 1)
> failures <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==0))
> successes <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==1))
> dat2 <- expand.grid(x1=sort(unique(dat$x1)), x2=sort(unique(dat$x2)), grp=sort(unique(dat$grp)))
> dat2$failures <- as.vector(failures)
> dat2$successes <- as.vector(successes)
> library(lme4)
> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
> # ? user ?system elapsed
> # 22.918 ? 0.660 ?24.441
> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
> # ? user ?system elapsed
> # ?1.833 ? 0.017 ? 1.855
> detach("package:lme4")
> library(lme4Eigen)
> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
> # ? user ?system elapsed
> # 24.824 ? 1.811 ?26.773
> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
> # ? user ?system elapsed
> # ?1.687 ? 0.039 ? 1.723

Thanks for sending that, Malcolm.

Your collapsing of the binary responses to the number of successes and
failures works in this case by can't be expected to work in general.
In establishing dat2 using expand.grid you are assuming that all
combinations of covariates occur in the data.  If not you would end up
with a successes=0, failures=0 row and that might cause problems in
glm or glmer finding the proportion of successes (I havent' gone back
to look at the code to determine this).  I am trying to think of a way
of doing this using the type of strategy in the hidden function
duplicated.data.frame.  If you have the model frame and you know that
there are only two unique values for the response you can get the
counts by determining the unique combinations of covariates and using
xtabs. If you look at duplicated.data.frame, you will see that getting
the unique combinations is done by pasting the text representation of
the row using a separator that will not occur in numeric data.  The C
function do_duplicated uses hash tables and hashing a character string
is very fast.

The end result looks like the enclosed.

Of course, there is probably a much cleaner way of doing this using
Hadley Wickham's reshape package but I haven't studied that package
enough yet.

As Malcolm said, the two sets of parameter estimates are very similar
but the deviance is different.  I am working on changes that will
create the proper value of the deviance from the model in terms of
successes and failure.  It is very confusing - the function in the glm
family that produces the deviance is called "aic" and the function
called "dev.resids" actually produces the square of the deviance
residuals and their sum should be the glm deviance, except when it
isn't.  It's disheartening at best.

I also include a timing of the model fit using nAGQ=25 which should be
a very accurate evaluation of the deviance.

The other version with nAGQ=0 uses a Laplace approximation and
(approximately) profiles out the fixed-effects parameters.  In many
situations this gets close enough to the correct deviance that the
results can be used for rough model comparisons.


>> Date: Thu, 9 Feb 2012 14:13:24 -0600
>> From: Douglas Bates <bates at stat.wisc.edu>
>> To: Joshua Wiley <jwiley.psych at gmail.com>
>> Cc: AC Del Re <acdelre at stanford.edu>, r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] LMM with Big data using binary DV
>>
>> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>> Hi AC,
>>>
>>> My personal preference would be glmer from the lme4 package. ?I prefer
>>> the Laplace approximation for the likelihood over the quasilikelihood
>>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>>> with 2 million observations nested within 200 groups (10,000
>>> observations per group). ?I then ran an random intercepts model using:
>>>
>>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>>>
>>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>>>
>>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>>> With the OS and R running, my system used ~ 6GB of RAM for the model
>>> and went up to ~7GB to show the summary (copies of the data are
>>> made---changed in the upcoming version of lme4).
>>>
>>> So as long as you have plenty of memory, you should have no trouble
>>> modelling your data using glmer(). ?To initially make sure all your
>>> code works, I might use a subset of your data (say 10k), once you are
>>> convinced you have the model you want, run it on the full data.
>>
>> If you would have an opportunity to run that model fit or a comparable
>> on lme4Eigen::glmer we would appreciate information about speed,
>> accuracy and memory usage.
>>
>> In lme4Eigen::glmer there are different levels of precision in the
>> approximation to the deviance being optimizer. ?These are controlled
>> by the nAGQ argument to the function. ?The default, nAGQ=1, uses the
>> Laplace approximation. ?The special value nAGQ=0 also uses the Laplace
>> approximation but profiles out the fixed-effects parameters. ?This
>> profiling is not exact but usually gets you close to the optimum that
>> you would get from nAGQ=1, but much, much faster. ?In a model like
>> this you can also use nAGQ>1 and <= 25. ?On the model fits we have
>> tried we don't see a lot of difference in timing between, say, nAGQ=9
>> and nAGQ=25 but on a model fit like this you might.
>>
>> As a fallback, we would appreciate the code that you used to simulate
>> the response. ?We could generate something ourselves, of course, but
>> it is easier to compare when you copy someone else's simulation.
>>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>>> Hi,
>>>>
>>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>>> facilities) and would like to examine variability across facilities in
>>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>>> with patient and facility predictors of utilization.
>>>>
>>>> I have 3 questions:
>>>>
>>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>>> big data (even if they are not R packages)?
>>>>
>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>> (assuming I need to use another program due to the size of the dataset)?
>>>>
>>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>>> wanting to examine? I know of two potential options (family=binomial option
>>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>>> appropriate or what other R packages and functions are available for this
>>>> purpose?
>>>>
>>>> Thank you,
>>>>
>>>> AC
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-------------- next part --------------

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> N <- 100000
> ngrps <- 100
> set.seed(101)
> str(dat <- within(data.frame(x1   = sample(1:10, N, replace=TRUE),
+                              x2   = sample(18:23, N, replace=TRUE),
+                              grps = factor(sample.int(ngrps, N, replace=TRUE))),
+               {
+                   y <- rbinom(N,
+                               prob = plogis(-5 + 0.1 * x1 + 0.2 * x2 + rnorm(ngrps)[grps]),
+                               size = 1)
+                   covs <- do.call(paste, c(model.frame(~ x1 + x2 + grps), sep="\r"))
+               }))
'data.frame':	100000 obs. of  5 variables:
 $ x1  : int  4 1 8 7 3 4 6 4 7 6 ...
 $ x2  : int  21 20 19 21 19 22 23 22 22 23 ...
 $ grps: Factor w/ 100 levels "1","2","3","4",..: 94 13 40 95 43 53 31 72 43 21 ...
 $ covs: chr  "4\r21\r94" "1\r20\r13" "8\r19\r40" "7\r21\r95" ...
 $ y   : num  0 0 1 0 0 1 1 0 0 1 ...
> head(dat)
  x1 x2 grps      covs y
1  4 21   94 4\r21\r94 0
2  1 20   13 1\r20\r13 0
3  8 19   40 8\r19\r40 1
4  7 21   95 7\r21\r95 0
5  3 19   43 3\r19\r43 0
6  4 22   53 4\r22\r53 1
> str(freq <- xtabs(~ covs + y, dat))
 xtabs [1:6000, 1:2] 10 11 12 5 7 1 12 5 6 6 ...
 - attr(*, "dimnames")=List of 2
  ..$ covs: chr [1:6000] "10\r18\r1" "10\r18\r10" "10\r18\r100" "10\r18\r11" ...
  ..$ y   : chr [1:2] "0" "1"
 - attr(*, "class")= chr [1:2] "xtabs" "table"
 - attr(*, "call")= language xtabs(formula = ~covs + y, data = dat)
> head(freq)
             y
covs           0 1
  10\r18\r1   10 7
  10\r18\r10  11 1
  10\r18\r100 12 3
  10\r18\r11   5 7
  10\r18\r12   7 9
  10\r18\r13   1 6
> str(dat2 <- within(dat[!duplicated(dat$covs),],
+                {
+                    failure <- freq[covs, 1]
+                    success <- freq[covs, 2]
+                    y       <- NULL
+                    covs    <- NULL
+                }))
'data.frame':	6000 obs. of  5 variables:
 $ x1     : int  4 1 8 7 3 4 6 4 7 6 ...
 $ x2     : int  21 20 19 21 19 22 23 22 22 23 ...
 $ grps   : Factor w/ 100 levels "1","2","3","4",..: 94 13 40 95 43 53 31 72 43 21 ...
 $ success: num  4 8 12 6 4 8 11 9 4 12 ...
 $ failure: num  10 9 10 13 19 10 3 10 15 5 ...
> head(dat2)
  x1 x2 grps success failure
1  4 21   94       4      10
2  1 20   13       8       9
3  8 19   40      12      10
4  7 21   95       6      13
5  3 19   43       4      19
6  4 22   53       8      10
> xtabs(~ y, subset(dat, covs == "4\r21\r94"))  # corresponds to first row in dat2
y
 0  1 
10  4 
> 
> library(lme4Eigen)
Loading required package: lattice
> ## using the full data frame, dat
> 
> ## default fit using the Laplace approximation
> system.time(print(gm01a <- glmer(y ~ x1 + x2 + (1 | grps), dat, binomial), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: y ~ x1 + x2 + (1 | grps) 
   Data: dat 

      AIC       BIC    logLik  deviance 
113146.67 113184.73 -56569.34 113138.67 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 100000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.039837   0.137784  -36.58
x1           0.102856   0.002550   40.33
x2           0.195406   0.004307   45.37
   user  system elapsed 
 32.250   0.084  32.327 
> 
> ## faster but less accurate version that profiles out the fixed-effects parameters
> system.time(print(gm01b <- glmer(y ~ x1 + x2 + (1 | grps), dat, binomial, nAGQ=0L), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: y ~ x1 + x2 + (1 | grps) 
   Data: dat 

      AIC       BIC    logLik  deviance 
113146.68 113184.74 -56569.34 113138.68 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.077    1.038   
Number of obs: 100000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.034540   0.137930  -36.50
x1           0.102753   0.002550   40.30
x2           0.195209   0.004306   45.33
   user  system elapsed 
  4.824   0.020   4.841 
> 
> ## slowest but most accurate version
> system.time(print(gm01c <- glmer(y ~ x1 + x2 + (1 | grps), dat, binomial, nAGQ=25L), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: y ~ x1 + x2 + (1 | grps) 
   Data: dat 

     AIC      BIC   logLik deviance 
113146.6 113184.7 -56569.3 113138.6 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 100000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.039829   0.137783  -36.58
x1           0.102856   0.002550   40.33
x2           0.195406   0.004307   45.37
   user  system elapsed 
 81.589   0.088  81.726 
> 
> ## using the reduced data frame, dat2
> 
> ## default fit using the Laplace approximation
> system.time(print(gmsda <- glmer(cbind(success,failure) ~ x1 + x2 + (1 | grps), dat2, binomial),
+                   corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: cbind(success, failure) ~ x1 + x2 + (1 | grps) 
   Data: dat2 

      AIC       BIC    logLik  deviance 
 6890.896  6917.694 -3441.448  6882.896 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 6000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.039823   0.137783  -36.58
x1           0.102857   0.002550   40.33
x2           0.195406   0.004307   45.37
   user  system elapsed 
  1.508   0.012   1.513 
> ## fastest version profiling out the fixed-effects parameters
> system.time(print(gmsdb <- glmer(cbind(success,failure) ~ x1 + x2 + (1 | grps), dat2,
+                                  binomial, nAGQ=0L), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: cbind(success, failure) ~ x1 + x2 + (1 | grps) 
   Data: dat2 

      AIC       BIC    logLik  deviance 
 6890.901  6917.699 -3441.450  6882.901 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 6000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.034500   0.137780  -36.54
x1           0.102752   0.002550   40.30
x2           0.195207   0.004306   45.33
   user  system elapsed 
  0.220   0.008   0.223 
> ## slower but most accurate version
> system.time(print(gmsd25 <- glmer(cbind(success,failure) ~ x1 + x2 + (1 | grps), dat2,
+                                   binomial, nAGQ=25L), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: cbind(success, failure) ~ x1 + x2 + (1 | grps) 
   Data: dat2 

      AIC       BIC    logLik  deviance 
 6890.827  6917.625 -3441.414  6882.827 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 6000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.039829   0.137783  -36.58
x1           0.102857   0.002550   40.33
x2           0.195406   0.004307   45.37
   user  system elapsed 
  6.113   0.004   6.112 
> 
> proc.time()
   user  system elapsed 
131.684   1.040 131.792 

From m.fairbrother at bristol.ac.uk  Fri Feb 10 19:01:21 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 10 Feb 2012 18:01:21 +0000
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CAO7JsnSDMS_unUTP+dECFJfkBnJSojkXixchyi1Y3GQVCH-1AA@mail.gmail.com>
References: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
	<FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>
	<CAO7JsnSDMS_unUTP+dECFJfkBnJSojkXixchyi1Y3GQVCH-1AA@mail.gmail.com>
Message-ID: <3C5A8FE9-5547-409A-9F65-280385DA31FA@bristol.ac.uk>

Thanks very much for the correction. Just to clarify, are you saying there are two distinct problems:

(1) The possibility of rows with both zero successes and zero failures. This seems minor--one can just check for those and exclude them if there are any, no?

(2) Even if there are no rows with zero successes and zero failures, the optimisation could converge on some very inaccurate parameter estimates, because of the problems you mention with the deviance? (I hope this is roughly the right way to express this point.)

For problems like AC's, it would be quite helpful to have confidence that the "cbind(successes, failures)" approach is trustworthy, so thanks for looking into this.

- Malcolm



On 10 Feb 2012, at 17:36, Douglas Bates wrote:

> On Fri, Feb 10, 2012 at 6:20 AM, Malcolm Fairbrother
> <m.fairbrother at bristol.ac.uk> wrote:
>> Dear AC (and perhaps Doug),
>> 
>>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>>> (assuming I need to use another program due to the size of the dataset)?
>> 
>> You may be well aware of this, but one way of substantially speeding up the estimation of models with binary data is to use "cbind", though the feasibility of this depends on the nature of the model (number of predictors and number of unique values for each predictor variable). The kind of code you need for this is below. You'll see that the fixed effects estimates, standard errors, and random effects variances turn out the same.
>> 
>>> If you would have an opportunity to run that model fit or a comparable
>>> on lme4Eigen::glmer we would appreciate information about speed,
>>> accuracy and memory usage.
>> 
>>> As a fallback, we would appreciate the code that you used to simulate
>>> the response.  We could generate something ourselves, of course, but
>>> it is easier to compare when you copy someone else's simulation.
>> 
>> I've compared the speed of lme4 versus lme4Eigen, on a simulated dataset with 100,000 observations, using a 2GHz MacBook. Based on a handful of simulations, there doesn't appear to be much difference between the two packages in terms of speed (sometimes one is faster, sometimes the other). I have reported the results of one simulation here. The two packages generate identical results for this dataset.
>> 
>> Cheers,
>> Malcolm
>> 
>> 
>> N <- 100000
>> grps <- 100
>> dat <- data.frame(x1 = sample(1:10, N, replace=T), x2 = sample(18:23, N, replace=T), grp=rep(1:grps, each=N/grps))
>> dat$y <- rbinom(N, prob = plogis(-5 + 0.1*dat$x1 + 0.2*dat$x2 + rnorm(grps)[dat$grp]), size = 1)
>> failures <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==0))
>> successes <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==1))
>> dat2 <- expand.grid(x1=sort(unique(dat$x1)), x2=sort(unique(dat$x2)), grp=sort(unique(dat$grp)))
>> dat2$failures <- as.vector(failures)
>> dat2$successes <- as.vector(successes)
>> library(lme4)
>> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
>> #   user  system elapsed
>> # 22.918   0.660  24.441
>> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
>> #   user  system elapsed
>> #  1.833   0.017   1.855
>> detach("package:lme4")
>> library(lme4Eigen)
>> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
>> #   user  system elapsed
>> # 24.824   1.811  26.773
>> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
>> #   user  system elapsed
>> #  1.687   0.039   1.723
> 
> Thanks for sending that, Malcolm.
> 
> Your collapsing of the binary responses to the number of successes and
> failures works in this case by can't be expected to work in general.
> In establishing dat2 using expand.grid you are assuming that all
> combinations of covariates occur in the data.  If not you would end up
> with a successes=0, failures=0 row and that might cause problems in
> glm or glmer finding the proportion of successes (I havent' gone back
> to look at the code to determine this).  I am trying to think of a way
> of doing this using the type of strategy in the hidden function
> duplicated.data.frame.  If you have the model frame and you know that
> there are only two unique values for the response you can get the
> counts by determining the unique combinations of covariates and using
> xtabs. If you look at duplicated.data.frame, you will see that getting
> the unique combinations is done by pasting the text representation of
> the row using a separator that will not occur in numeric data.  The C
> function do_duplicated uses hash tables and hashing a character string
> is very fast.
> 
> The end result looks like the enclosed.
> 
> Of course, there is probably a much cleaner way of doing this using
> Hadley Wickham's reshape package but I haven't studied that package
> enough yet.
> 
> As Malcolm said, the two sets of parameter estimates are very similar
> but the deviance is different.  I am working on changes that will
> create the proper value of the deviance from the model in terms of
> successes and failure.  It is very confusing - the function in the glm
> family that produces the deviance is called "aic" and the function
> called "dev.resids" actually produces the square of the deviance
> residuals and their sum should be the glm deviance, except when it
> isn't.  It's disheartening at best.
> 
> I also include a timing of the model fit using nAGQ=25 which should be
> a very accurate evaluation of the deviance.
> 
> The other version with nAGQ=0 uses a Laplace approximation and
> (approximately) profiles out the fixed-effects parameters.  In many
> situations this gets close enough to the correct deviance that the
> results can be used for rough model comparisons.
> 
> 
>>> Date: Thu, 9 Feb 2012 14:13:24 -0600
>>> From: Douglas Bates <bates at stat.wisc.edu>
>>> To: Joshua Wiley <jwiley.psych at gmail.com>
>>> Cc: AC Del Re <acdelre at stanford.edu>, r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] LMM with Big data using binary DV
>>> 
>>> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>>> Hi AC,
>>>> 
>>>> My personal preference would be glmer from the lme4 package. ?I prefer
>>>> the Laplace approximation for the likelihood over the quasilikelihood
>>>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>>>> with 2 million observations nested within 200 groups (10,000
>>>> observations per group). ?I then ran an random intercepts model using:
>>>> 
>>>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>>>> 
>>>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>>>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>>>> 
>>>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>>>> With the OS and R running, my system used ~ 6GB of RAM for the model
>>>> and went up to ~7GB to show the summary (copies of the data are
>>>> made---changed in the upcoming version of lme4).
>>>> 
>>>> So as long as you have plenty of memory, you should have no trouble
>>>> modelling your data using glmer(). ?To initially make sure all your
>>>> code works, I might use a subset of your data (say 10k), once you are
>>>> convinced you have the model you want, run it on the full data.
>>> 
>>> If you would have an opportunity to run that model fit or a comparable
>>> on lme4Eigen::glmer we would appreciate information about speed,
>>> accuracy and memory usage.
>>> 
>>> In lme4Eigen::glmer there are different levels of precision in the
>>> approximation to the deviance being optimizer.  These are controlled
>>> by the nAGQ argument to the function.  The default, nAGQ=1, uses the
>>> Laplace approximation.  The special value nAGQ=0 also uses the Laplace
>>> approximation but profiles out the fixed-effects parameters.  This
>>> profiling is not exact but usually gets you close to the optimum that
>>> you would get from nAGQ=1, but much, much faster.  In a model like
>>> this you can also use nAGQ>1 and <= 25.  On the model fits we have
>>> tried we don't see a lot of difference in timing between, say, nAGQ=9
>>> and nAGQ=25 but on a model fit like this you might.
>>> 
>>> As a fallback, we would appreciate the code that you used to simulate
>>> the response.  We could generate something ourselves, of course, but
>>> it is easier to compare when you copy someone else's simulation.
>>>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>>>> Hi,
>>>>> 
>>>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>>>> facilities) and would like to examine variability across facilities in
>>>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>>>> with patient and facility predictors of utilization.
>>>>> 
>>>>> I have 3 questions:
>>>>> 
>>>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>>>> big data (even if they are not R packages)?
>>>>> 
>>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>>> (assuming I need to use another program due to the size of the dataset)?
>>>>> 
>>>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>>>> wanting to examine? I know of two potential options (family=binomial option
>>>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>>>> appropriate or what other R packages and functions are available for this
>>>>> purpose?
>>>>> 
>>>>> Thank you,
>>>>> 
>>>>> AC
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> <Malcolm_Rout.txt><Malcolm.R>



From eder at leg.ufpr.br  Fri Feb 10 19:51:49 2012
From: eder at leg.ufpr.br (Eder David Borges da Silva)
Date: Fri, 10 Feb 2012 16:51:49 -0200
Subject: [R-sig-ME] GWS in MCMCglmm and INLA
Message-ID: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>

Dear R user,
Just to better understand the GWS (genomic Wide Select), I would like
to adjust the model by making the inference in different ways, I could
adjust using the INLA, MCMC would like to use, especially with the
function MCMCglmm, but I could not understand if this is possible, so
I want your help.
The code is:
### Sele??o Genomica Ampla - Genomic Wide Select
#browseURL('http://www.infoteca.cnptia.embrapa.br/bitstream/doc/883425/1/Doc210.pdf')
#pg 54
###-----------------------------------------------------###
rm(list=ls())
require(INLA)
require(MCMCglmm)
###-----------------------------------------------------###
dados <- data.frame(ind=c(1:5),
                    diametro=c(9.87,14.48,8.91,14.64,9.55),
                    M1=c(2,1,0,1,1),
                    M2=c(0,1,2,0,0),
                    M3=c(0,0,0,1,0),
                    M4=c(0,0,0,0,1),
                    M5=c(2,1,0,1,1),
                    M6=c(0,1,0,0,1),
                    M7=c(0,0,2,0,0))
dados
###-----------------------------------------------------###
### Create Z matrix
Z  <- as.matrix(dados[,3:ncol(dados)])
### change effects de 0 1 2 para -1 0 1
Z <- apply(Z,2,function(x) ifelse(x==1,-1, ifelse(x!=0,1,0)))
Z
###-----------------------------------------------------###
### fit in INLA
rr.inla.fit = inla(diametro ~ 1 +
f(ind,model="z",Z=Z),data=dados,family="gaussian")
summary(rr.inla.fit)
rr.inla.fit$summary.random
###-----------------------------------------------------###
### fit MCMCglmm
rr.mcmc.fit = MCMCglmm(diametro ~ 1, random = Z,data=dados,family="gaussian")
summary(rr.mcmc.fit)

random = ????

Thanks
?der David Borges da Silva



From bates at stat.wisc.edu  Fri Feb 10 21:43:04 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 10 Feb 2012 14:43:04 -0600
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <3C5A8FE9-5547-409A-9F65-280385DA31FA@bristol.ac.uk>
References: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
	<FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>
	<CAO7JsnSDMS_unUTP+dECFJfkBnJSojkXixchyi1Y3GQVCH-1AA@mail.gmail.com>
	<3C5A8FE9-5547-409A-9F65-280385DA31FA@bristol.ac.uk>
Message-ID: <CAO7JsnTidqcX7nUkE4VYS6BUB_Ce4vOD9wmKM_E4DL9y734LMg@mail.gmail.com>

On Fri, Feb 10, 2012 at 12:01 PM, Malcolm Fairbrother
<m.fairbrother at bristol.ac.uk> wrote:
> Thanks very much for the correction. Just to clarify, are you saying there are two distinct problems:

> (1) The possibility of rows with both zero successes and zero failures. This seems minor--one can just check for those and exclude them if there are any, no?

I'm just saying that it is best to avoid the zero successes/zero
failues rows if you can.  When you use expand.grid a covariate with a
large number of unique values can inflate the size of the resulting
array substantially, possibly resulting in most of the rows having
zero successes and zero failures.  (In such cases it is doubtful that
you would achieve much of a speed-up by going to the reduced form
anyway.) That is why I would choose to use what corresponds to
obtaining the unique combinations of covariates present in the data.
You can always generate the zero successes/zero failures rows and then
filter them but that is the sort of thing that J. Edwards Deming
called "burning the toast and then scraping it".

> (2) Even if there are no rows with zero successes and zero failures, the optimisation could converge on some very inaccurate parameter estimates, because of the problems you mention with the deviance? (I hope this is roughly the right way to express this point.)

The location of the optimum is the same but, in the case of the
binomial representation the calculation of the deviance is off from
the Bernoulli representation by an additive factor.  There are
actually two issues here.  One is that the deviance for the Bernoulli
model differs from the deviance for the binomial model by

> with(dat2, 2 * sum(lchoose(success + failure, success)))
[1] 89442.18

In other words, it is twice the sum of the logarithms of the "n choose
k" terms in the binomial probability density function.  The binomial
model deviance is for all possible combinations of patterns of
successes and failures.  The Bernoulli model deviance is for the
particular pattern that you observed.

There is a further additive constant related to the fact that deviance
of the binomial model is not the sum of the squared deviance
residuals.  This is why there is another function in the family called
"aic" which, naturally, returns the deviance.

When I first wrote this reply I had a long rant in here about the
design of the glm family structure in general but that is not very
illuminating.  Suffice it to say that it is a bad design because it is
a holdover from S and S-PLUS which did not have the ability to
evaluate functions in a shared environment.

The short version of the story is that if you use the aic member
function then the deviances from the two model fits agree up to the
difference caused by the "n choose k" terms

> (gmsdb at resp$aic() + with(dat2, 2 * sum(lchoose(success + failure, success))))
[1] 112510.5
> gm01b at resp$aic()
[1] 112510.5

(Please don't go off and copy that type of code - we'll create better
extractor functions.)

> For problems like AC's, it would be quite helpful to have confidence that the "cbind(successes, failures)" approach is trustworthy, so thanks for looking into this.
>
> - Malcolm
>
>
>
> On 10 Feb 2012, at 17:36, Douglas Bates wrote:
>
>> On Fri, Feb 10, 2012 at 6:20 AM, Malcolm Fairbrother
>> <m.fairbrother at bristol.ac.uk> wrote:
>>> Dear AC (and perhaps Doug),
>>>
>>>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>>>> (assuming I need to use another program due to the size of the dataset)?
>>>
>>> You may be well aware of this, but one way of substantially speeding up the estimation of models with binary data is to use "cbind", though the feasibility of this depends on the nature of the model (number of predictors and number of unique values for each predictor variable). The kind of code you need for this is below. You'll see that the fixed effects estimates, standard errors, and random effects variances turn out the same.
>>>
>>>> If you would have an opportunity to run that model fit or a comparable
>>>> on lme4Eigen::glmer we would appreciate information about speed,
>>>> accuracy and memory usage.
>>>
>>>> As a fallback, we would appreciate the code that you used to simulate
>>>> the response. ?We could generate something ourselves, of course, but
>>>> it is easier to compare when you copy someone else's simulation.
>>>
>>> I've compared the speed of lme4 versus lme4Eigen, on a simulated dataset with 100,000 observations, using a 2GHz MacBook. Based on a handful of simulations, there doesn't appear to be much difference between the two packages in terms of speed (sometimes one is faster, sometimes the other). I have reported the results of one simulation here. The two packages generate identical results for this dataset.
>>>
>>> Cheers,
>>> Malcolm
>>>
>>>
>>> N <- 100000
>>> grps <- 100
>>> dat <- data.frame(x1 = sample(1:10, N, replace=T), x2 = sample(18:23, N, replace=T), grp=rep(1:grps, each=N/grps))
>>> dat$y <- rbinom(N, prob = plogis(-5 + 0.1*dat$x1 + 0.2*dat$x2 + rnorm(grps)[dat$grp]), size = 1)
>>> failures <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==0))
>>> successes <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==1))
>>> dat2 <- expand.grid(x1=sort(unique(dat$x1)), x2=sort(unique(dat$x2)), grp=sort(unique(dat$grp)))
>>> dat2$failures <- as.vector(failures)
>>> dat2$successes <- as.vector(successes)
>>> library(lme4)
>>> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
>>> # ? user ?system elapsed
>>> # 22.918 ? 0.660 ?24.441
>>> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
>>> # ? user ?system elapsed
>>> # ?1.833 ? 0.017 ? 1.855
>>> detach("package:lme4")
>>> library(lme4Eigen)
>>> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
>>> # ? user ?system elapsed
>>> # 24.824 ? 1.811 ?26.773
>>> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
>>> # ? user ?system elapsed
>>> # ?1.687 ? 0.039 ? 1.723
>>
>> Thanks for sending that, Malcolm.
>>
>> Your collapsing of the binary responses to the number of successes and
>> failures works in this case by can't be expected to work in general.
>> In establishing dat2 using expand.grid you are assuming that all
>> combinations of covariates occur in the data. ?If not you would end up
>> with a successes=0, failures=0 row and that might cause problems in
>> glm or glmer finding the proportion of successes (I havent' gone back
>> to look at the code to determine this). ?I am trying to think of a way
>> of doing this using the type of strategy in the hidden function
>> duplicated.data.frame. ?If you have the model frame and you know that
>> there are only two unique values for the response you can get the
>> counts by determining the unique combinations of covariates and using
>> xtabs. If you look at duplicated.data.frame, you will see that getting
>> the unique combinations is done by pasting the text representation of
>> the row using a separator that will not occur in numeric data. ?The C
>> function do_duplicated uses hash tables and hashing a character string
>> is very fast.
>>
>> The end result looks like the enclosed.
>>
>> Of course, there is probably a much cleaner way of doing this using
>> Hadley Wickham's reshape package but I haven't studied that package
>> enough yet.
>>
>> As Malcolm said, the two sets of parameter estimates are very similar
>> but the deviance is different. ?I am working on changes that will
>> create the proper value of the deviance from the model in terms of
>> successes and failure. ?It is very confusing - the function in the glm
>> family that produces the deviance is called "aic" and the function
>> called "dev.resids" actually produces the square of the deviance
>> residuals and their sum should be the glm deviance, except when it
>> isn't. ?It's disheartening at best.
>>
>> I also include a timing of the model fit using nAGQ=25 which should be
>> a very accurate evaluation of the deviance.
>>
>> The other version with nAGQ=0 uses a Laplace approximation and
>> (approximately) profiles out the fixed-effects parameters. ?In many
>> situations this gets close enough to the correct deviance that the
>> results can be used for rough model comparisons.
>>
>>
>>>> Date: Thu, 9 Feb 2012 14:13:24 -0600
>>>> From: Douglas Bates <bates at stat.wisc.edu>
>>>> To: Joshua Wiley <jwiley.psych at gmail.com>
>>>> Cc: AC Del Re <acdelre at stanford.edu>, r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] LMM with Big data using binary DV
>>>>
>>>> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>>>> Hi AC,
>>>>>
>>>>> My personal preference would be glmer from the lme4 package. ?I prefer
>>>>> the Laplace approximation for the likelihood over the quasilikelihood
>>>>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>>>>> with 2 million observations nested within 200 groups (10,000
>>>>> observations per group). ?I then ran an random intercepts model using:
>>>>>
>>>>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>>>>>
>>>>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>>>>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>>>>>
>>>>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>>>>> With the OS and R running, my system used ~ 6GB of RAM for the model
>>>>> and went up to ~7GB to show the summary (copies of the data are
>>>>> made---changed in the upcoming version of lme4).
>>>>>
>>>>> So as long as you have plenty of memory, you should have no trouble
>>>>> modelling your data using glmer(). ?To initially make sure all your
>>>>> code works, I might use a subset of your data (say 10k), once you are
>>>>> convinced you have the model you want, run it on the full data.
>>>>
>>>> If you would have an opportunity to run that model fit or a comparable
>>>> on lme4Eigen::glmer we would appreciate information about speed,
>>>> accuracy and memory usage.
>>>>
>>>> In lme4Eigen::glmer there are different levels of precision in the
>>>> approximation to the deviance being optimizer. ?These are controlled
>>>> by the nAGQ argument to the function. ?The default, nAGQ=1, uses the
>>>> Laplace approximation. ?The special value nAGQ=0 also uses the Laplace
>>>> approximation but profiles out the fixed-effects parameters. ?This
>>>> profiling is not exact but usually gets you close to the optimum that
>>>> you would get from nAGQ=1, but much, much faster. ?In a model like
>>>> this you can also use nAGQ>1 and <= 25. ?On the model fits we have
>>>> tried we don't see a lot of difference in timing between, say, nAGQ=9
>>>> and nAGQ=25 but on a model fit like this you might.
>>>>
>>>> As a fallback, we would appreciate the code that you used to simulate
>>>> the response. ?We could generate something ourselves, of course, but
>>>> it is easier to compare when you copy someone else's simulation.
>>>>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>>>>> facilities) and would like to examine variability across facilities in
>>>>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>>>>> with patient and facility predictors of utilization.
>>>>>>
>>>>>> I have 3 questions:
>>>>>>
>>>>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>>>>> big data (even if they are not R packages)?
>>>>>>
>>>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>>>> (assuming I need to use another program due to the size of the dataset)?
>>>>>>
>>>>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>>>>> wanting to examine? I know of two potential options (family=binomial option
>>>>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>>>>> appropriate or what other R packages and functions are available for this
>>>>>> purpose?
>>>>>>
>>>>>> Thank you,
>>>>>>
>>>>>> AC
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> <Malcolm_Rout.txt><Malcolm.R>
>



From m.fenati at libero.it  Sat Feb 11 10:00:54 2012
From: m.fenati at libero.it (m.fenati at libero.it)
Date: Sat, 11 Feb 2012 10:00:54 +0100 (CET)
Subject: [R-sig-ME] ghlt different results for different hypotheses?
Message-ID: <17179796.25708831328950854693.JavaMail.defaultUser@defaultHost>

Thanks a lot also for your good example!

Regards

Massimo


>----Messaggio originale----
>Da: 538280 at gmail.com
>Data: 10/02/2012 18.36
>A: "m.fenati at libero.it"<m.fenati at libero.it>
>Cc: <r-sig-mixed-models at r-project.org>
>Ogg: Re: [R-sig-ME] ghlt different results for different hypotheses?
>
>The more comparisons/tests that you do the more opportunities you have
>of getting a type I error.  The multiple comparisons procedures adjust
>for the number of comparisons so that the overall probability of
>making at least 1 type I error is fixed.  So the more comparisons the
>more adjustment needs to be made.
>
>Think of this simple example.  You are playing a game where you are
>trying to throw a wadded up piece of paper into a basket, you win if
>you get it in at least once.  What are your chances of winning if you
>get 10 tries compared to if you get 20 tries (from the same spot)?  If
>you want the same chance of winning with 20 tries as you had for 10
>tries (or 1 try), then you need to move further away or some other
>penalty.
>
>So with glht there is a bigger penalty when you do more comparisons
>since there are more opportunities of making a type I error.
>
>On Thu, Feb 9, 2012 at 3:25 AM, m.fenati at libero.it <m.fenati at libero.it> 
wrote:
>>
>>
>> Dear R users,
>> I would like to understand a simple problem related to glht() multeplicity 
correction and linear Hypotheses testing. Given a simple lme model with two 
predictors (group = 3 levels; time = ?2 levels) and their interaction with 
treatment contrast, I see that the p-values are lower and higher when I test 
few or many hypotheses respectively. Because I dont't have a deep knowledge of 
multiple comparison theory, I ask you some suggestion or explanation about the 
different obtained results.
>> As you can see in the example below, "m1" and "m2" test a different number 
of hypotheses but comparing the same hypothesis a different results occurred.
>>
>>
>> time<-rep(c(rep(0,8),rep(1,8)),3)
>> group<-c(rep(0,16),rep(1,16),rep(2,16))
>> id<-c(rep(1:8,2),rep(9:16,2),rep(17:24,2))
>> w<-c(172.9, 185.8, 173.1, 187.3, 161.6, 167.1, 168.4, 161.1, 166.5, 175.3, 
167.1, 181.9, 163.0, 167.7, 172.1, 170.3, 167.2, 183.3, 160.7,167.8, 149.6, 
159.1, 164.2, 171.0, 168.6, 173.5, 161.8, 166.5, 148.4, 167.1, 166.8, 166.6, 
150.6, 178.4, 166.4, 159.2, 163.2, 167.8, 136.6, 161.8, 166.1, 175.8, 175.6, 
166.2, 168.5, 170.5, 152.0, 164.4)
>> dati<-data.frame(time,group,id,w)
>> dati$time<-as.factor(dati$time)
>> dati$group<-as.factor(dati$group)
>> dati$id<-as.factor(dati$id)
>>
>>
>>
>>
>> kp<-rbind("after Treatment: Group 1 - Controls"=c(0,1,0,0,0,0),
>> ? ? ? ? "after Treatment: Group 2 - Controls"=c(0,0,1,0,0,0),
>> ? ? ? ? "before Treatment: Group 1 - Controls"=c(0,1,0,0,1,0),
>> ? ? ? ? "before Treatment: Group 2 - Controls"=c(0,0,1,0,0,1),
>> ? ? ? ? "Controls: time trend (T1 - T0)"=c(0,0,0,-1,0,0),
>> ? ? ? ? "Group 1: time trend (T1 - T0)"=c(0,0,0,-1,-1,0),
>> ? ? ? ? "Group 2: time trend (T1 - T0)"=c(0,0,0,-1,0,-1))
>>
>>
>> k<-rbind("after Treatment: Group 1 - Controls"=c(0,1,0,0,0,0),
>> ? ? ? ? "after Treatment: Group 2 - Controls"=c(0,0,1,0,0,0),
>> ? ? ? ? "before Treatment: Group 1 - Controls"=c(0,1,0,0,1,0),
>> ? ? ? ? "before Treatment: Group 2 - Controls"=c(0,0,1,0,0,1)
>> ? ? ? ? )
>>
>>
>>
>>
>> w.lme<-lme(w~group*time,data=dati,random=~1|id)
>> m1<-summary(glht(w.lme,kp))
>> m2<-summary(glht(w.lme,k))
>>
>>
>> Thank in advances for your suggestions
>>
>>
>> Massimo
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>-- 
>Gregory (Greg) L. Snow Ph.D.
>538280 at gmail.com
>



From fan.mongxie at gmail.com  Sat Feb 11 11:12:51 2012
From: fan.mongxie at gmail.com (Fan Mongxie)
Date: Sat, 11 Feb 2012 11:12:51 +0100
Subject: [R-sig-ME] lmer correlation btw random effects
Message-ID: <CAAZy3PAg=nHwex+qUQ4ZN5cvBwsF9dSwzXfFDEgaVLTxROtShA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120211/3316b920/attachment-0001.pl>

From j.hadfield at ed.ac.uk  Sat Feb 11 16:15:37 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 11 Feb 2012 15:15:37 +0000
Subject: [R-sig-ME] GWS in MCMCglmm and INLA
In-Reply-To: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>
Message-ID: <20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>

Hi,

dados$Z<-Z
rr.mcmc.fit<-MCMCglmm(diametro~1,random=~idv(Z),data=dados,family="gaussian")

would be one way of dong it. Not very efficient for setting up the  
model, but once MCMCing it should be OK.

Cheers,

Jarrod

Quoting Eder David Borges da Silva <eder at leg.ufpr.br> on Fri, 10 Feb  
2012 16:51:49 -0200:

> Dear R user,
> Just to better understand the GWS (genomic Wide Select), I would like
> to adjust the model by making the inference in different ways, I could
> adjust using the INLA, MCMC would like to use, especially with the
> function MCMCglmm, but I could not understand if this is possible, so
> I want your help.
> The code is:
> ### Sele??o Genomica Ampla - Genomic Wide Select
> #browseURL('http://www.infoteca.cnptia.embrapa.br/bitstream/doc/883425/1/Doc210.pdf')
> #pg 54
> ###-----------------------------------------------------###
> rm(list=ls())
> require(INLA)
> require(MCMCglmm)
> ###-----------------------------------------------------###
> dados <- data.frame(ind=c(1:5),
>                     diametro=c(9.87,14.48,8.91,14.64,9.55),
>                     M1=c(2,1,0,1,1),
>                     M2=c(0,1,2,0,0),
>                     M3=c(0,0,0,1,0),
>                     M4=c(0,0,0,0,1),
>                     M5=c(2,1,0,1,1),
>                     M6=c(0,1,0,0,1),
>                     M7=c(0,0,2,0,0))
> dados
> ###-----------------------------------------------------###
> ### Create Z matrix
> Z  <- as.matrix(dados[,3:ncol(dados)])
> ### change effects de 0 1 2 para -1 0 1
> Z <- apply(Z,2,function(x) ifelse(x==1,-1, ifelse(x!=0,1,0)))
> Z
> ###-----------------------------------------------------###
> ### fit in INLA
> rr.inla.fit = inla(diametro ~ 1 +
> f(ind,model="z",Z=Z),data=dados,family="gaussian")
> summary(rr.inla.fit)
> rr.inla.fit$summary.random
> ###-----------------------------------------------------###
> ### fit MCMCglmm
> rr.mcmc.fit = MCMCglmm(diametro ~ 1, random =  
> Z,data=dados,family="gaussian")
> summary(rr.mcmc.fit)
>
> random = ????
>
> Thanks
> ?der David Borges da Silva
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From tulsipaudel at hotmail.com  Fri Feb 10 16:04:07 2012
From: tulsipaudel at hotmail.com (Tulsi Paudel)
Date: Fri, 10 Feb 2012 07:04:07 -0800
Subject: [R-sig-ME] mixed model-request for help
In-Reply-To: <BAY155-W5E044C71A2AA23214D496B1780@phx.gbl>
References: <BAY155-W5E044C71A2AA23214D496B1780@phx.gbl>
Message-ID: <BAY155-W71C2F8B88C6FBBE20AE10B1780@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120210/9cdb1717/attachment-0001.pl>

From ruzong.fan at nih.gov  Sun Feb 12 00:58:52 2012
From: ruzong.fan at nih.gov (Fan, Ruzong (NIH/NICHD) [E])
Date: Sat, 11 Feb 2012 18:58:52 -0500
Subject: [R-sig-ME] generalized linear mixed model for qualitative in R
Message-ID: <C9106BA831B26B4DA4E7B9054C1A705341107A43@NIHMLBX12.nih.gov>

Dear folks,

I wonder if  glmer can we do spline or model correlation for longitudinal data?

In lme, it is possible to do both spline and model correlation. For instance, I wrote a short codes as below: 
#################################################################
fit1E  <- lme( sbp ~ -1 + X.mean,
                random      = list(group = pdIdent(~-1+Z.mean), 
                                      id = ~1),
                correlation = corExp(form = ~ x | group/id), 
                    na.action   = na.exclude,
                method      = "ML",
                subset      = notmissing )
#################################################################
Basically, 'X.mean' models the fixed effect, and `Z.mean' models the spline random effect. The above codes will lead to 3 random variance estimations: one from Z.mean, one from id, and the other from the residual. 

In addition, 'correlation = corExp(form = ~ x | group/id)' models the correlation. 

I don't see there is something like `random = list( ... )' in glmer. So I am not sure how to do spline using glmer. 

Plus, I don't find similar things like `correlation = corExp(form = ~ x | group/id)' in glmer to model correlation?

Thanks. R.F


From eder at leg.ufpr.br  Sun Feb 12 19:46:23 2012
From: eder at leg.ufpr.br (Eder David Borges da Silva)
Date: Sun, 12 Feb 2012 16:46:23 -0200
Subject: [R-sig-ME] GWS in MCMCglmm and INLA
In-Reply-To: <20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>
	<20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>
Message-ID: <CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>

Thanks Jarrod,
My comparisons between MCMC and INLA worked perfectly
Thank you
?der

2012/2/11 Jarrod Hadfield <j.hadfield at ed.ac.uk>:
> Hi,
>
> dados$Z<-Z
> rr.mcmc.fit<-MCMCglmm(diametro~1,random=~idv(Z),data=dados,family="gaussian")
>
> would be one way of dong it. Not very efficient for setting up the model,
> but once MCMCing it should be OK.
>
> Cheers,
>
> Jarrod
>
>
> Quoting Eder David Borges da Silva <eder at leg.ufpr.br> on Fri, 10 Feb 2012
> 16:51:49 -0200:
>
>> Dear R user,
>> Just to better understand the GWS (genomic Wide Select), I would like
>> to adjust the model by making the inference in different ways, I could
>> adjust using the INLA, MCMC would like to use, especially with the
>> function MCMCglmm, but I could not understand if this is possible, so
>> I want your help.
>> The code is:
>> ### Sele??o Genomica Ampla - Genomic Wide Select
>>
>> #browseURL('http://www.infoteca.cnptia.embrapa.br/bitstream/doc/883425/1/Doc210.pdf')
>> #pg 54
>> ###-----------------------------------------------------###
>> rm(list=ls())
>> require(INLA)
>> require(MCMCglmm)
>> ###-----------------------------------------------------###
>> dados <- data.frame(ind=c(1:5),
>> ? ? ? ? ? ? ? ? ? ?diametro=c(9.87,14.48,8.91,14.64,9.55),
>> ? ? ? ? ? ? ? ? ? ?M1=c(2,1,0,1,1),
>> ? ? ? ? ? ? ? ? ? ?M2=c(0,1,2,0,0),
>> ? ? ? ? ? ? ? ? ? ?M3=c(0,0,0,1,0),
>> ? ? ? ? ? ? ? ? ? ?M4=c(0,0,0,0,1),
>> ? ? ? ? ? ? ? ? ? ?M5=c(2,1,0,1,1),
>> ? ? ? ? ? ? ? ? ? ?M6=c(0,1,0,0,1),
>> ? ? ? ? ? ? ? ? ? ?M7=c(0,0,2,0,0))
>> dados
>> ###-----------------------------------------------------###
>> ### Create Z matrix
>> Z ?<- as.matrix(dados[,3:ncol(dados)])
>> ### change effects de 0 1 2 para -1 0 1
>> Z <- apply(Z,2,function(x) ifelse(x==1,-1, ifelse(x!=0,1,0)))
>> Z
>> ###-----------------------------------------------------###
>> ### fit in INLA
>> rr.inla.fit = inla(diametro ~ 1 +
>> f(ind,model="z",Z=Z),data=dados,family="gaussian")
>> summary(rr.inla.fit)
>> rr.inla.fit$summary.random
>> ###-----------------------------------------------------###
>> ### fit MCMCglmm
>> rr.mcmc.fit = MCMCglmm(diametro ~ 1, random = Z
>> ,data=dados,family="gaussian")
>> summary(rr.mcmc.fit)
>>
>> random = ????
>>
>> Thanks
>> ?der David Borges da Silva
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>



From raptorbio at hotmail.com  Sun Feb 12 20:35:11 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Sun, 12 Feb 2012 14:35:11 -0500
Subject: [R-sig-ME] Considerable discrepancies between fixed and random
 effect estimates of lme4 (glmer) and glmmADMB
In-Reply-To: <CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>,
	<20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>,
	<CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>
Message-ID: <BAY170-W1321C2FA87E1FAFC47F40CDA17E0@phx.gbl>


I hope I'm not overlooking something elementary here, but estimated fixed and random effects are considerably different from the following Poisson model in lme4 and glmmADMB.? The fixed effects seem to differ most considerably...? Thanks for any thoughts...

Adam Smith

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-pc-mingw32/x64 (64-bit)

(SNIP)

other attached packages:
[1] glmmADMB_0.7.2.5?? lme4_0.999375-42?? Matrix_1.0-3?????? bbmle_1.0.4.1????? numDeriv_2010.11-1
[6] lattice_0.20-0???? R2admb_0.7.5?????? MASS_7.3-16?????? 

> str(cons09) # The dataset
'data.frame':?? 394 obs. of? 15 variables:
?$ plot?????? : Factor w/ 16 levels "n_10","n_2","n_3",..: 2 2 2 2 2 2 2 2 2 2 ...
?$ plot_trt?? : Factor w/ 32 levels "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
?$ geog?????? : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
?$ trt??????? : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
?$ count????? : Factor w/ 14 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
?$ total????? : int? 341 326 257 244 185 141 128 121 115 84 ...
?$ cons?????? : int? 12 52 8 57 36 8 0 1 20 27 ...
?$ dt???????? : int? 4 3 3 3 3 3 3 3 3 3 ...
?$ obs??????? : Factor w/ 394 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
?$ logtotal?? : num? 5.83 5.79 5.55 5.5 5.22 ...
?$ logdt????? : num? 1.39 1.1 1.1 1.1 1.1 ...

# The models
> Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt + count:geog + trt:geog + offset(logtotal) +
??? ??? offset(logdt) + (1|plot) + (1|plot_trt), zeroInflation=FALSE, family="poisson", data=cons09)

> P_glmer <- glmer(cons ~ count + geog + trt + count:trt + count:geog + trt:geog + offset(log(total)) +
??? ? offset(log(dt)) + (1|plot) + (1|plot_trt), family="poisson", data=cons09)

> fixef(Poiss)
?? (Intercept)???????? count2???????? count3???????? count4???????? count5???????? count6???????? count7???????? count8???????? count9??????? count10??????? count11??????? count12 
?????? 0.77333??????? 0.58885?????? -0.21547??????? 0.79101??????? 0.24924?????? -0.02565??????? 0.36004?????? -0.94852??????? 0.39442??????? 0.29032??????? 0.13658?????? -0.39564 
?????? count13??????? count14????????? geogs???????? trttrt? count2:trttrt? count3:trttrt? count4:trttrt? count5:trttrt? count6:trttrt? count7:trttrt? count8:trttrt? count9:trttrt 
????? -1.37470?????? -0.88496?????? -0.53259?????? -0.25434?????? -0.41033??????? 1.18840??????? 0.25678??????? 0.69734??????? 0.59823??????? 1.11430?????? -0.17330?????? -0.15364 
count10:trttrt count11:trttrt count12:trttrt count13:trttrt count14:trttrt?? count2:geogs?? count3:geogs?? count4:geogs?? count5:geogs?? count6:geogs?? count7:geogs?? count8:geogs 
?????? 0.98442??????? 0.51533?????? -0.99431?????? -1.63920?????? -0.40455?????? -1.55670??????? 0.15891??????? 0.35378??????? 0.45748??????? 0.92293??????? 0.78373??????? 1.05440 
? count9:geogs? count10:geogs? count11:geogs? count12:geogs? count13:geogs? count14:geogs?? geogs:trttrt 
?????? 0.39598??????? 0.32019??????? 1.41600??????? 0.86656??????? 2.45790??????? 1.07350?????? -0.31149 

# After detaching glmmADMB and lme4, then re-requiring lme4 to avoid masking of lme4's fixef function
> fixef(P_glmer)
?? (Intercept)???????? count2???????? count3???????? count4???????? count5???????? count6???????? count7???????? count8???????? count9??????? count10??????? count11??????? count12 
?? -5.00326871???? 0.69554781???? 0.17105622???? 1.29467717???? 0.97268949???? 0.87707266???? 1.39399967???? 0.22923370???? 1.61829807???? 1.84546906???? 1.99506279???? 1.37859852 
?????? count13??????? count14????????? geogs???????? trttrt? count2:trttrt? count3:trttrt? count4:trttrt? count5:trttrt? count6:trttrt? count7:trttrt? count8:trttrt? count9:trttrt 
??? 0.53987085???? 1.13282524??? -0.12901214???? 0.07021103??? -0.52669841???? 0.87378323???? 0.05397134???? 0.46901053???? 0.39863837???? 0.94486828??? -0.18146287??? -0.20340655 
count10:trttrt count11:trttrt count12:trttrt count13:trttrt count14:trttrt?? count2:geogs?? count3:geogs?? count4:geogs?? count5:geogs?? count6:geogs?? count7:geogs?? count8:geogs 
??? 0.77866847???? 0.49935778??? -0.65101999??? -1.05381279??? -0.05290984??? -1.54103716??? -0.03887633???? 0.04570463???? 0.02076874???? 0.47883964???? 0.23057821???? 0.49408747 
? count9:geogs? count10:geogs? count11:geogs? count12:geogs? count13:geogs? count14:geogs?? geogs:trttrt 
?? -0.15116087??? -0.32683907???? 0.50098187???? 0.14670125???? 1.63961096???? 0.40944384??? -0.22555478 

I juxtapose ranef() estimates here for comparison's sake...

> ranef(Poiss)$plot
?????? (Intercept)
n_10 -0.0943733643
n_2?? 0.1849966635
n_3?? 0.1925622397
n_4? -0.1873429084
n_5? -0.0522031304
n_6? -0.2297389315
n_7?? 0.1648785136
n_8?? 0.0944159043
n_9? -0.0556750492
s_1? -0.3023318134
s_2?? 0.0970108446
s_3? -0.2753679950
s_5?? 0.0909701639
s_6?? 0.4699361596
s_7? -0.0634075132
s_8?? 0.0007413087

> ranef(P_glmer)$plot

???? (Intercept)

n_10 -0.39846683

n_2?? 0.04002750

n_3?? 0.61876383

n_4? -0.15421355

n_5? -0.46932629

n_6? -0.40931865

n_7?? 0.97591378

n_8?? 0.10866846

n_9? -0.28021810

s_1? -0.17423214

s_2? -0.19732599

s_3? -0.85567064

s_5?? 0.12795497

s_6?? 1.34047871

s_7? -0.27174719

s_8?? 0.06440244

>ranef(Poiss)$plot_trt
????????? (Intercept)
cont_n_10 -0.35187629
cont_n_2?? 0.59527239
cont_n_3?? 0.85766093
cont_n_4? -0.53814502
cont_n_5? -0.66935729
cont_n_6? -0.26606817
cont_n_7?? 0.80261648
cont_n_8?? 0.02233052
cont_n_9? -0.41806768
cont_s_1? -0.23483630
cont_s_2? -0.02224468
cont_s_3? -0.17660444
cont_s_5? -0.58505585
cont_s_6?? 1.49490396
cont_s_7?? 0.07621585
cont_s_8? -0.52568948
trt_n_10?? 0.03431004
trt_n_2??? 0.02722629
trt_n_3?? -0.20972715
trt_n_4?? -0.09225497
trt_n_5??? 0.49368927
trt_n_6?? -0.50699118
trt_n_7?? -0.24780806
trt_n_8??? 0.29537319
trt_n_9??? 0.23071847
trt_s_1?? -0.78250755
trt_s_2??? 0.34867686
trt_s_3?? -0.74997310
trt_s_5??? 0.89115581
trt_s_6??? 0.08645040
trt_s_7?? -0.28957461
trt_s_8??? 0.52818059

> ranef(P_glmer)$plot_trt
??????????? (Intercept)
cont_n_10 -0.4813895272
cont_n_2?? 0.6307028124
cont_n_3?? 0.5442036884
cont_n_4? -0.5256622000
cont_n_5? -0.6562034135
cont_n_6?? 0.1186249885
cont_n_7?? 1.0098808410
cont_n_8? -0.2196620296
cont_n_9? -0.3985906214
cont_s_1? -0.1821209263
cont_s_2? -0.5517396588
cont_s_3?? 0.1368254894
cont_s_5? -0.1701340605
cont_s_6?? 1.8066871045
cont_s_7? -0.5317778373
cont_s_8? -0.4961046022
trt_n_10?? 0.0668058960
trt_n_2?? -0.5890563232
trt_n_3??? 0.0995873106
trt_n_4??? 0.3652111668
trt_n_5??? 0.1678942605
trt_n_6?? -0.5444993690
trt_n_7??? 0.0055057682
trt_n_8??? 0.3327258112
trt_n_9??? 0.1070385259
trt_s_1??? 0.0008416109
trt_s_2??? 0.3464324210
trt_s_3?? -1.0271054737
trt_s_5??? 0.3032644345
trt_s_6?? -0.4119899922
trt_s_7??? 0.2490392783
trt_s_8??? 0.5631119264

 		 	   		  


From Nick.Masca at effem.com  Mon Feb 13 13:33:42 2012
From: Nick.Masca at effem.com (Masca, Nick)
Date: Mon, 13 Feb 2012 12:33:42 +0000
Subject: [R-sig-ME] Comparing against a negative control in an LMM
Message-ID: <8295A4D50D4C644CAC4323DD070D9597106F2D@034-CH1MPN1-014.034d.mgd.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120213/e354dc21/attachment-0001.pl>

From agostino.moro99 at gmail.com  Mon Feb 13 16:02:20 2012
From: agostino.moro99 at gmail.com (Agostino Moro)
Date: Mon, 13 Feb 2012 15:02:20 +0000
Subject: [R-sig-ME] MCMCglmm with cross-classified random effects
In-Reply-To: <CAMS_pxuWBRgPZptGEoyJ7Cxvf1389jghA-6q_mBZN-23vM12cg@mail.gmail.com>
References: <CAMS_pxuWBRgPZptGEoyJ7Cxvf1389jghA-6q_mBZN-23vM12cg@mail.gmail.com>
Message-ID: <CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA@mail.gmail.com>

Dear R-users,

I would like to fit ?a glmm with cross-classified random effects with
the function MCMCglmm. Something along the lines:

model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)

where re1 and re2 should be crossed random effects. I was wondering
whether you could tell me specifying cross-classified random effects
in MCMCglmm requires a particular syntax? Are there any examples
somewhere? I have had a look at the manual and the package vignette,
but I have not been able to find any examples relevant to what I want
to do.

Thanks,

Agostino



From j.hadfield at ed.ac.uk  Mon Feb 13 16:19:07 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 13 Feb 2012 15:19:07 +0000
Subject: [R-sig-ME] MCMCglmm with cross-classified random effects
In-Reply-To: <CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA@mail.gmail.com>
References: <CAMS_pxuWBRgPZptGEoyJ7Cxvf1389jghA-6q_mBZN-23vM12cg@mail.gmail.com>
	<CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA@mail.gmail.com>
Message-ID: <20120213151907.57957fqy2tmlxcg8@www.staffmail.ed.ac.uk>

Hi,

As long as the levels of re1 and re2 are uniquely labelled any cross  
classification will be dealt with appropriately.

Cheers,

Jarrod


Quoting Agostino Moro <agostino.moro99 at gmail.com> on Mon, 13 Feb 2012  
15:02:20 +0000:

> Dear R-users,
>
> I would like to fit ?a glmm with cross-classified random effects with
> the function MCMCglmm. Something along the lines:
>
> model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)
>
> where re1 and re2 should be crossed random effects. I was wondering
> whether you could tell me specifying cross-classified random effects
> in MCMCglmm requires a particular syntax? Are there any examples
> somewhere? I have had a look at the manual and the package vignette,
> but I have not been able to find any examples relevant to what I want
> to do.
>
> Thanks,
>
> Agostino
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Mon Feb 13 17:43:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 13 Feb 2012 16:43:51 +0000 (UTC)
Subject: [R-sig-ME] Considerable discrepancies between fixed and random
	effect estimates of lme4 (glmer) and glmmADMB
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>,
	<20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>,
	<CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>
	<BAY170-W1321C2FA87E1FAFC47F40CDA17E0@phx.gbl>
Message-ID: <loom.20120213T045329-772@post.gmane.org>

Adam Smith <raptorbio at ...> writes:

 
> I hope I'm not overlooking something elementary here, but estimated
> fixed and random effects are considerably different from the
> following Poisson model in lme4 and glmmADMB.? The fixed effects
> seem to differ most considerably...? Thanks for any thoughts...
> Adam Smith

> > sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> (SNIP)
> 
> other attached packages:
> [1] glmmADMB_0.7.2.5?? lme4_0.999375-42?? Matrix_1.0-3??????
bbmle_1.0.4.1????? numDeriv_2010.11-1
> [6] lattice_0.20-0???? R2admb_0.7.5?????? MASS_7.3-16?????? 

 
> > str(cons09) # The dataset
> 'data.frame':?? 394 obs. of? 15 variables:
> ?$ plot?????? : Factor w/ 16 levels "n_10","n_2","n_3",..: 
> 2 2 2 2 2 2 2 2 2 2 ...
> ?$ plot_trt?? : Factor w/ 32 levels 
> "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
> ?$ geog?????? : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ trt??????? : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ count????? : Factor w/ 14 levels "1","2","3","4",..:
>  1 2 3 4 5 6 7 8 9 10 ...
> ?$ total????? : int? 341 326 257 244 185 141 128 121 115 84 ...
> ?$ cons?????? : int? 12 52 8 57 36 8 0 1 20 27 ...
> ?$ dt???????? : int? 4 3 3 3 3 3 3 3 3 3 ...
> ?$ obs??????? : Factor w/ 394 levels "1","2","3","4",..: 
> 1 2 3 4 5 6 7 8 9 10 ...
> ?$ logtotal?? : num? 5.83 5.79 5.55 5.5 5.22 ...
> ?$ logdt????? : num? 1.39 1.1 1.1 1.1 1.1 ...

 
> # The models
> > Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt + 
> count:geog + trt:geog + offset(logtotal) +
> ??? ??? offset(logdt) + (1|plot) + (1|plot_trt),
>  zeroInflation=FALSE, family="poisson", data=cons09)
> 
> > P_glmer <- glmer(cons ~ count + geog + trt + 
> count:trt + count:geog + trt:geog + offset(log(total)) +
> ??? ? offset(log(dt)) + (1|plot) + 
> (1|plot_trt), family="poisson", data=cons09)
 
By the way, you can specify these fixed effects 
more compactly as (count+geog+trt)^2 ...

> > fixef(Poiss)

>   0.77333  0.58885  -0.21547 0.79101  0.24924  -0.02565  0.36004 
> -0.94852  0.39442  0.29032  0.13658 -0.39564 
>   -1.37470  -0.88496  -0.53259  -0.25434 
> -0.41033  1.18840  0.25678  0.69734 
> 0.59823  1.11430  -0.17330  -0.15364 
>   0.98442  0.51533  -0.99431 -1.63920  -0.40455  -1.55670  0.15891 
> 0.35378  0.45748  0.92293  0.78373 1.05440 
>   0.39598  0.32019  1.41600 
> 0.86656  2.45790  1.07350  -0.31149 

> # After detaching glmmADMB and lme4, then 
> re-requiring lme4 to avoid masking of lme4's fixef function
> > fixef(P_glmer)
>   -5.00326871  0.69554781  0.17105622  1.29467717 
> 0.97268949  0.87707266  1.39399967  0.22923370 
> 1.61829807  1.84546906  1.99506279  1.37859852 
>   0.53987085  1.13282524  -0.12901214  0.07021103 
> -0.52669841  0.87378323  0.05397134  0.46901053 
> 0.39863837  0.94486828  -0.18146287  -0.20340655 
>   0.77866847  0.49935778  -0.65101999  -1.05381279 
> -0.05290984  -1.54103716  -0.03887633  0.04570463  0.02076874 
> 0.47883964  0.23057821  0.49408747 
>   -0.15116087  -0.32683907  0.50098187  0.14670125 
> 1.63961096  0.40944384  -0.22555478 
> 
> I juxtapose ranef() estimates here for comparison's sake...
> 
  [snip]

  There's nothing obviously wrong here.  It's not a full solution,
but I wonder how wide the confidence intervals are ... if they
are very wide, then the practical answer is that these are poorly
determined estimates.  You're probably overfitting the model --
2 random effects plus 43 fixed-effect coefficients is
quite a lot for 394 observations (the general rule of thumb
is N/(# params)>10), especially if the Poisson data are sparse
(although they don't look that way from the first few
values listed in str() -- is there anyway you can allow
'count' to be continuous, or ordinal, rather than insisting
on it being categorical?) But it would be best to try to answer
more definitively ... can you send data?

  Ben Bolker



From zt020200 at gmail.com  Mon Feb 13 18:22:24 2012
From: zt020200 at gmail.com (Tao Zhang)
Date: Mon, 13 Feb 2012 09:22:24 -0800
Subject: [R-sig-ME] Any package for best subset selection for random effects
	model
Message-ID: <CADMWRionUd97x-oUuUqj0nUStGiSZohudJLVh4kctEY0tC8=cw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120213/f23e37be/attachment-0001.pl>

From gangchen6 at gmail.com  Mon Feb 13 19:41:43 2012
From: gangchen6 at gmail.com (Gang Chen)
Date: Mon, 13 Feb 2012 13:41:43 -0500
Subject: [R-sig-ME] Interpretation of nonlinear mixed-effects modeling
	results
Message-ID: <CAHmzXO6hydefDRtcZAgbuHBhiJXGfM6zDxDfPkP=k8LouY5suQ@mail.gmail.com>

I'm fitting a nonlinear mixed-effects model to some data with two
groups (controls and patients) with something like

fm <- nlme(response ~  myFunc(time, a, b), data=myData, fixed = a + b
~ group, start=...)

myFunc is a nonlinear function defined with two parameters a and b.
I'm very confused with the results between summary(fm) and anova(fm):

> summary(fm)

...
Fixed effects: a + b ~ group
                        Value       Std.Error   DF     t-value      p-value
a.(Intercept) 29.905889 10.532769 2196  2.839319  0.0046
a.groupPat     6.437218 16.045223 2196  0.401192  0.6883
b.(Intercept)  0.290943  0.072544 2196  4.010559  0.0001
b.groupPat    -0.138361  0.077339 2196 -1.789010  0.0738
...

> anova(fm)
                 numDF denDF  F-value p-value
a.(Intercept)     1  2196 497.8594  <.0001
a.group           1  2196  12.6109  0.0004
b.(Intercept)     1  2196  45.2787  <.0001
b.group           1  2196   3.2006  0.0738

If I understand it correctly, the last row in the fixed effects table
of summary(fm) is the difference in parameter b between the two
groups, and the t-statistic (and p-value) matches the F-statistic (and
p-value) from the last row of anova(fm): (-1.789010)^2 = 3.2006.
However, I'm totally at a loss for the other three rows in the two
tables? For example, I thought a.groupPat (2nd row) in the summary(fm)
table is the amount in parameter a in Patient group that is more than
parameter a in the Control group (1st row); but this interpretation is
not consistent with what is shown in the 2nd row of anova(fm) table.
What am I missing here?

Thanks,
Gang



From raptorbio at hotmail.com  Mon Feb 13 20:06:57 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Mon, 13 Feb 2012 14:06:57 -0500
Subject: [R-sig-ME] Considerable discrepancies between fixed and random
 effect estimates of lme4 (glmer) and glmmADMB
In-Reply-To: <loom.20120213T045329-772@post.gmane.org>
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>,
	, <20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>, ,
	<CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>,
	<BAY170-W1321C2FA87E1FAFC47F40CDA17E0@phx.gbl>,
	<loom.20120213T045329-772@post.gmane.org>
Message-ID: <BAY170-W29F87F0CC98BFF5E9B7F8EA17F0@phx.gbl>



> > I hope I'm not overlooking something elementary here, but estimated
> > fixed and random effects are considerably different from the
> > following Poisson model in lme4 and glmmADMB.  The fixed effects
> > seem to differ most considerably...  Thanks for any thoughts...
> > Adam Smith
>
> > > sessionInfo()
> > R version 2.14.1 (2011-12-22)
> > Platform: x86_64-pc-mingw32/x64 (64-bit)
> >
> > (SNIP)
> >
> > other attached packages:
> > [1] glmmADMB_0.7.2.5   lme4_0.999375-42   Matrix_1.0-3
> bbmle_1.0.4.1      numDeriv_2010.11-1
> > [6] lattice_0.20-0     R2admb_0.7.5       MASS_7.3-16
>
>
> > > str(cons09) # The dataset
> > 'data.frame':   394 obs. of  15 variables:
> >  $ plot       : Factor w/ 16 levels "n_10","n_2","n_3",..:
> > 2 2 2 2 2 2 2 2 2 2 ...
> >  $ plot_trt   : Factor w/ 32 levels
> > "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
> >  $ geog       : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
> >  $ trt        : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
> >  $ count      : Factor w/ 14 levels "1","2","3","4",..:
> > 1 2 3 4 5 6 7 8 9 10 ...
> >  $ total      : int  341 326 257 244 185 141 128 121 115 84 ...
> >  $ cons       : int  12 52 8 57 36 8 0 1 20 27 ...
> >  $ dt         : int  4 3 3 3 3 3 3 3 3 3 ...
> >  $ obs        : Factor w/ 394 levels "1","2","3","4",..:
> > 1 2 3 4 5 6 7 8 9 10 ...
> >  $ logtotal   : num  5.83 5.79 5.55 5.5 5.22 ...
> >  $ logdt      : num  1.39 1.1 1.1 1.1 1.1 ...
>
>
> > # The models
> > > Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt +
> > count:geog + trt:geog + offset(logtotal) +
> >         offset(logdt) + (1|plot) + (1|plot_trt),
> > zeroInflation=FALSE, family="poisson", data=cons09)
> >
> > > P_glmer <- glmer(cons ~ count + geog + trt +
> > count:trt + count:geog + trt:geog + offset(log(total)) +
> >       offset(log(dt)) + (1|plot) +
> > (1|plot_trt), family="poisson", data=cons09)
>
> By the way, you can specify these fixed effects
> more compactly as (count+geog+trt)^2 ...

Indeed, I was being explicit for explicitness' sake...

>
> > > fixef(Poiss)
>
> > 0.77333 0.58885 -0.21547 0.79101 0.24924 -0.02565 0.36004
> > -0.94852 0.39442 0.29032 0.13658 -0.39564
> > -1.37470 -0.88496 -0.53259 -0.25434
> > -0.41033 1.18840 0.25678 0.69734
> > 0.59823 1.11430 -0.17330 -0.15364
> > 0.98442 0.51533 -0.99431 -1.63920 -0.40455 -1.55670 0.15891
> > 0.35378 0.45748 0.92293 0.78373 1.05440
> > 0.39598 0.32019 1.41600
> > 0.86656 2.45790 1.07350 -0.31149
>
> > # After detaching glmmADMB and lme4, then
> > re-requiring lme4 to avoid masking of lme4's fixef function
> > > fixef(P_glmer)
> > -5.00326871 0.69554781 0.17105622 1.29467717
> > 0.97268949 0.87707266 1.39399967 0.22923370
> > 1.61829807 1.84546906 1.99506279 1.37859852
> > 0.53987085 1.13282524 -0.12901214 0.07021103
> > -0.52669841 0.87378323 0.05397134 0.46901053
> > 0.39863837 0.94486828 -0.18146287 -0.20340655
> > 0.77866847 0.49935778 -0.65101999 -1.05381279
> > -0.05290984 -1.54103716 -0.03887633 0.04570463 0.02076874
> > 0.47883964 0.23057821 0.49408747
> > -0.15116087 -0.32683907 0.50098187 0.14670125
> > 1.63961096 0.40944384 -0.22555478
> >
> > I juxtapose ranef() estimates here for comparison's sake...
> >
> [snip]
>
> There's nothing obviously wrong here. It's not a full solution,
> but I wonder how wide the confidence intervals are ... if they
> are very wide, then the practical answer is that these are poorly
> determined estimates. You're probably overfitting the model --
> 2 random effects plus 43 fixed-effect coefficients is
> quite a lot for 394 observations (the general rule of thumb
> is N/(# params)>10), especially if the Poisson data are sparse
> (although they don't look that way from the first few
> values listed in str() -- is there anyway you can allow
> 'count' to be continuous, or ordinal, rather than insisting
> on it being categorical?) But it would be best to try to answer
> more definitively ... can you send data?

I started with a general specification of count expecting to model 
it with an additive term when I start comparing fixed effects.? I 
suppose I could model it as a lower order polynomial initially... 
Doing so should drastically reduce the number of fixed effects in 
the model.? I suppose I should center it before creating the
polynomial terms...

However, I'll still send the data off-list.? 

Thanks for looking this over.

>
> Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  


From sjtr at ceh.ac.uk  Mon Feb 13 21:18:38 2012
From: sjtr at ceh.ac.uk (Thackeray, Stephen J.)
Date: Mon, 13 Feb 2012 20:18:38 +0000
Subject: [R-sig-ME] Any package for best subset selection for random
 effects	model
In-Reply-To: <CADMWRionUd97x-oUuUqj0nUStGiSZohudJLVh4kctEY0tC8=cw@mail.gmail.com>
References: <CADMWRionUd97x-oUuUqj0nUStGiSZohudJLVh4kctEY0tC8=cw@mail.gmail.com>
Message-ID: <42AFDDFA3288A141B63C93EE7F138E97216D3BADF7@nerckwmb1.ad.nerc.ac.uk>

Hello Tao,

>From your question, I am unsure of quite what you want. If you are interested in determining from a global model (with all fixed effects included) the model(s) with the most optimal subset of these fixed effects then you could try the dredge function in the MuMIn package. This will accept lme and lmer mixed effects models...

All the best

Steve



________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Tao Zhang [zt020200 at gmail.com]
Sent: 13 February 2012 17:22
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Any package for best subset selection for random effects    model

 Hi Pros,
      I know leaps() computes the best subset selection for linear model,
and
 the bestglm() computes the best subset selection for generalized linear
 model. Is there any package for best subset selection on random effects
 model, or mixed effects model?

Thank you!

Tao

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models-- 
This message (and any attachments) is for the recipient only. NERC
is subject to the Freedom of Information Act 2000 and the contents
of this email and any reply you make may be disclosed by NERC unless
it is exempt from release under the Act. Any material supplied to
NERC may be stored in an electronic records management system.


From anthony.sealey at utoronto.ca  Mon Feb 13 21:40:09 2012
From: anthony.sealey at utoronto.ca (anthony.sealey at utoronto.ca)
Date: Mon, 13 Feb 2012 20:40:09 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 62, Issue 29
In-Reply-To: <mailman.3107.1329160031.4475.r-sig-mixed-models@r-project.org>
References: <mailman.3107.1329160031.4475.r-sig-mixed-models@r-project.org>
Message-ID: <354080429-1329165020-cardhu_decombobulator_blackberry.rim.net-278480037-@b25.c26.bise6.blackberry>

9sbnopoi
-----Original Message-----
From:	r-sig-mixed-models-request at r-project.org
Sender:	r-sig-mixed-models-bounces at r-project.org
Date:	Mon, 13 Feb 2012 20:07:11 
To: <r-sig-mixed-models at r-project.org>
Reply-To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 62, Issue 29

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Comparing against a negative control in an LMM (Masca, Nick)
   2. MCMCglmm with cross-classified random effects (Agostino Moro)
   3. Re: MCMCglmm with cross-classified random effects
      (Jarrod Hadfield)
   4. Re: Considerable discrepancies between fixed and random
      effect estimates of lme4 (glmer) and glmmADMB (Ben Bolker)
   5. Any package for best subset selection for random effects
      model (Tao Zhang)
   6. Interpretation of nonlinear mixed-effects modeling	results
      (Gang Chen)
   7. Re: Considerable discrepancies between fixed and random
      effect estimates of lme4 (glmer) and glmmADMB (Adam Smith)


----------------------------------------------------------------------

Message: 1
Date: Mon, 13 Feb 2012 12:33:42 +0000
From: "Masca, Nick" <Nick.Masca at effem.com>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Comparing against a negative control in an LMM
Message-ID:
	<8295A4D50D4C644CAC4323DD070D9597106F2D at 034-CH1MPN1-014.034d.mgd.msft.net>
	
Content-Type: text/plain

Hi all,

I have a problem based on a colleague's experiment that I've been asked to analyse, which is more of a general mixed modelling issue rather than specifically an R issue, and I would be extremely grateful for any help that any readers of this list can provide.

An experiment was conducted in which the aim was to compare 3 concentrations of 2 active treatments (i.e. 6 active treatments in total) to a negative control.  Three batches of each of the actives have been tested, and 3 reps tested for each batch.  In contrast, 20 replicates have been taken of the negative control - but, by definition, there is no "batch" for this treatment.

Here is some code to reproduce the experimental design:

Treat<- factor(c(rep("NC", 20), rep("A", 27), rep("B", 27)))
Conc<-factor(c(rep(1, 20), rep(1:3, each=9), rep(1:3, each=9)))
Batch<-factor(c(rep(1, 20), rep( rep(1:3, each=3), 6)))
Treatment<-factor(Treat:Conc)  #specify new treatment variable (so don't attempt to estimate Conc. 2&3 for NC)

I originally planned to analyses these data in a LMM, with Treat*Conc as a 7 level fixed effect (i.e. 3*2 actives + control), and with Treat:Conc:Batch as random.  The following code simulates my response variable assuming this model:

                Resp<-  rep(9, 74) + #simulate intercept
                                c( rep(rnorm(1, 0, sd=2.5), 20)^2, rep(rnorm(18, 0, sd=2.5), each=3)^2) + #simulate treat.conc.batch variance
                                rep(rnorm(74, 0, sd=.2)^2) + #simulate residual variance
                                c(rep(0,20), rep(c(-4, 0,0,-4, 0,0), each= 9)) #simulate fixed effects
                Data<-data.frame(Treatment, Conc, Batch, Resp)

While this code models the data using lme4:
                Mod<-lmer(Resp ~ Treatment + (1|Treatment:Batch), data=Data)

I can now obtain and plot treatment means/CIs using glht in the multcomp package:
library(multcomp)
                Mean.mat<-diag(rep(1,7))
                                Mean.mat[,1]<-rep(1,7)
                                rownames(Mean.mat)<-levels(Data$Treatment)
                Est.means<-glht(Mod, Mean.mat)
plot(Est.means)

Hopefully from the above plot you can see what my issue is.  The negative control, which I want to compare everything against, has by far the least precision around its estimate, despite the data for the control hardly varying at all.  This happens because the greatest source of variability in the model (by far) is the variability between batches, but different batches of the negative control don't exist.  As such, I'm not sure that this is a fair way to model the data, because the negative control is unfairly penalised by the variability between the batches of the other treatments.

I imagine that this kind of problem isn't particularly uncommon, but it's the first time I've had to deal with something like this myself.   The only potential solution I've come up with so far is to scrap the negative control from the model, and simply subtract the negative control's mean "count" from all other values (either by specifying this mean as an offset or by subtracting it from all data-points).  But this will probably give "anti-conservative" results, as it would assume the mean for the negative control doesn't vary.

I would be extremely grateful if anyone would care to share their thoughts on possible solutions to this problem - and whether anyone has dealt with this kind of issue before.  I feel that I may well be missing something obvious - but can't see at the moment how else to get around it!

Many thanks for any help you can provide.

Cheers,

Nick





	[[alternative HTML version deleted]]



------------------------------

Message: 2
Date: Mon, 13 Feb 2012 15:02:20 +0000
From: Agostino Moro <agostino.moro99 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] MCMCglmm with cross-classified random effects
Message-ID:
	<CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Dear R-users,

I would like to fit ?a glmm with cross-classified random effects with
the function MCMCglmm. Something along the lines:

model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)

where re1 and re2 should be crossed random effects. I was wondering
whether you could tell me specifying cross-classified random effects
in MCMCglmm requires a particular syntax? Are there any examples
somewhere? I have had a look at the manual and the package vignette,
but I have not been able to find any examples relevant to what I want
to do.

Thanks,

Agostino



------------------------------

Message: 3
Date: Mon, 13 Feb 2012 15:19:07 +0000
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
To: Agostino Moro <agostino.moro99 at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm with cross-classified random effects
Message-ID: <20120213151907.57957fqy2tmlxcg8 at www.staffmail.ed.ac.uk>
Content-Type: text/plain; charset=ISO-8859-1; DelSp="Yes";
	format="flowed"

Hi,

As long as the levels of re1 and re2 are uniquely labelled any cross  
classification will be dealt with appropriately.

Cheers,

Jarrod


Quoting Agostino Moro <agostino.moro99 at gmail.com> on Mon, 13 Feb 2012  
15:02:20 +0000:

> Dear R-users,
>
> I would like to fit ?a glmm with cross-classified random effects with
> the function MCMCglmm. Something along the lines:
>
> model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)
>
> where re1 and re2 should be crossed random effects. I was wondering
> whether you could tell me specifying cross-classified random effects
> in MCMCglmm requires a particular syntax? Are there any examples
> somewhere? I have had a look at the manual and the package vignette,
> but I have not been able to find any examples relevant to what I want
> to do.
>
> Thanks,
>
> Agostino
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



------------------------------

Message: 4
Date: Mon, 13 Feb 2012 16:43:51 +0000 (UTC)
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Considerable discrepancies between fixed and
	random	effect estimates of lme4 (glmer) and glmmADMB
Message-ID: <loom.20120213T045329-772 at post.gmane.org>
Content-Type: text/plain; charset=utf-8

Adam Smith <raptorbio at ...> writes:

 
> I hope I'm not overlooking something elementary here, but estimated
> fixed and random effects are considerably different from the
> following Poisson model in lme4 and glmmADMB.? The fixed effects
> seem to differ most considerably...? Thanks for any thoughts...
> Adam Smith

> > sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> (SNIP)
> 
> other attached packages:
> [1] glmmADMB_0.7.2.5?? lme4_0.999375-42?? Matrix_1.0-3??????
bbmle_1.0.4.1????? numDeriv_2010.11-1
> [6] lattice_0.20-0???? R2admb_0.7.5?????? MASS_7.3-16?????? 

 
> > str(cons09) # The dataset
> 'data.frame':?? 394 obs. of? 15 variables:
> ?$ plot?????? : Factor w/ 16 levels "n_10","n_2","n_3",..: 
> 2 2 2 2 2 2 2 2 2 2 ...
> ?$ plot_trt?? : Factor w/ 32 levels 
> "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
> ?$ geog?????? : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ trt??????? : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ count????? : Factor w/ 14 levels "1","2","3","4",..:
>  1 2 3 4 5 6 7 8 9 10 ...
> ?$ total????? : int? 341 326 257 244 185 141 128 121 115 84 ...
> ?$ cons?????? : int? 12 52 8 57 36 8 0 1 20 27 ...
> ?$ dt???????? : int? 4 3 3 3 3 3 3 3 3 3 ...
> ?$ obs??????? : Factor w/ 394 levels "1","2","3","4",..: 
> 1 2 3 4 5 6 7 8 9 10 ...
> ?$ logtotal?? : num? 5.83 5.79 5.55 5.5 5.22 ...
> ?$ logdt????? : num? 1.39 1.1 1.1 1.1 1.1 ...

 
> # The models
> > Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt + 
> count:geog + trt:geog + offset(logtotal) +
> ??? ??? offset(logdt) + (1|plot) + (1|plot_trt),
>  zeroInflation=FALSE, family="poisson", data=cons09)
> 
> > P_glmer <- glmer(cons ~ count + geog + trt + 
> count:trt + count:geog + trt:geog + offset(log(total)) +
> ??? ? offset(log(dt)) + (1|plot) + 
> (1|plot_trt), family="poisson", data=cons09)
 
By the way, you can specify these fixed effects 
more compactly as (count+geog+trt)^2 ...

> > fixef(Poiss)

>   0.77333  0.58885  -0.21547 0.79101  0.24924  -0.02565  0.36004 
> -0.94852  0.39442  0.29032  0.13658 -0.39564 
>   -1.37470  -0.88496  -0.53259  -0.25434 
> -0.41033  1.18840  0.25678  0.69734 
> 0.59823  1.11430  -0.17330  -0.15364 
>   0.98442  0.51533  -0.99431 -1.63920  -0.40455  -1.55670  0.15891 
> 0.35378  0.45748  0.92293  0.78373 1.05440 
>   0.39598  0.32019  1.41600 
> 0.86656  2.45790  1.07350  -0.31149 

> # After detaching glmmADMB and lme4, then 
> re-requiring lme4 to avoid masking of lme4's fixef function
> > fixef(P_glmer)
>   -5.00326871  0.69554781  0.17105622  1.29467717 
> 0.97268949  0.87707266  1.39399967  0.22923370 
> 1.61829807  1.84546906  1.99506279  1.37859852 
>   0.53987085  1.13282524  -0.12901214  0.07021103 
> -0.52669841  0.87378323  0.05397134  0.46901053 
> 0.39863837  0.94486828  -0.18146287  -0.20340655 
>   0.77866847  0.49935778  -0.65101999  -1.05381279 
> -0.05290984  -1.54103716  -0.03887633  0.04570463  0.02076874 
> 0.47883964  0.23057821  0.49408747 
>   -0.15116087  -0.32683907  0.50098187  0.14670125 
> 1.63961096  0.40944384  -0.22555478 
> 
> I juxtapose ranef() estimates here for comparison's sake...
> 
  [snip]

  There's nothing obviously wrong here.  It's not a full solution,
but I wonder how wide the confidence intervals are ... if they
are very wide, then the practical answer is that these are poorly
determined estimates.  You're probably overfitting the model --
2 random effects plus 43 fixed-effect coefficients is
quite a lot for 394 observations (the general rule of thumb
is N/(# params)>10), especially if the Poisson data are sparse
(although they don't look that way from the first few
values listed in str() -- is there anyway you can allow
'count' to be continuous, or ordinal, rather than insisting
on it being categorical?) But it would be best to try to answer
more definitively ... can you send data?

  Ben Bolker



------------------------------

Message: 5
Date: Mon, 13 Feb 2012 09:22:24 -0800
From: Tao Zhang <zt020200 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Any package for best subset selection for random
	effects	model
Message-ID:
	<CADMWRionUd97x-oUuUqj0nUStGiSZohudJLVh4kctEY0tC8=cw at mail.gmail.com>
Content-Type: text/plain

 Hi Pros,
      I know leaps() computes the best subset selection for linear model,
and
 the bestglm() computes the best subset selection for generalized linear
 model. Is there any package for best subset selection on random effects
 model, or mixed effects model?

Thank you!

Tao

	[[alternative HTML version deleted]]



------------------------------

Message: 6
Date: Mon, 13 Feb 2012 13:41:43 -0500
From: Gang Chen <gangchen6 at gmail.com>
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Interpretation of nonlinear mixed-effects modeling
	results
Message-ID:
	<CAHmzXO6hydefDRtcZAgbuHBhiJXGfM6zDxDfPkP=k8LouY5suQ at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

I'm fitting a nonlinear mixed-effects model to some data with two
groups (controls and patients) with something like

fm <- nlme(response ~  myFunc(time, a, b), data=myData, fixed = a + b
~ group, start=...)

myFunc is a nonlinear function defined with two parameters a and b.
I'm very confused with the results between summary(fm) and anova(fm):

> summary(fm)

...
Fixed effects: a + b ~ group
                        Value       Std.Error   DF     t-value      p-value
a.(Intercept) 29.905889 10.532769 2196  2.839319  0.0046
a.groupPat     6.437218 16.045223 2196  0.401192  0.6883
b.(Intercept)  0.290943  0.072544 2196  4.010559  0.0001
b.groupPat    -0.138361  0.077339 2196 -1.789010  0.0738
...

> anova(fm)
                 numDF denDF  F-value p-value
a.(Intercept)     1  2196 497.8594  <.0001
a.group           1  2196  12.6109  0.0004
b.(Intercept)     1  2196  45.2787  <.0001
b.group           1  2196   3.2006  0.0738

If I understand it correctly, the last row in the fixed effects table
of summary(fm) is the difference in parameter b between the two
groups, and the t-statistic (and p-value) matches the F-statistic (and
p-value) from the last row of anova(fm): (-1.789010)^2 = 3.2006.
However, I'm totally at a loss for the other three rows in the two
tables? For example, I thought a.groupPat (2nd row) in the summary(fm)
table is the amount in parameter a in Patient group that is more than
parameter a in the Control group (1st row); but this interpretation is
not consistent with what is shown in the 2nd row of anova(fm) table.
What am I missing here?

Thanks,
Gang



------------------------------

Message: 7
Date: Mon, 13 Feb 2012 14:06:57 -0500
From: Adam Smith <raptorbio at hotmail.com>
To: <bbolker at gmail.com>, <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Considerable discrepancies between fixed and
	random effect estimates of lme4 (glmer) and glmmADMB
Message-ID: <BAY170-W29F87F0CC98BFF5E9B7F8EA17F0 at phx.gbl>
Content-Type: text/plain; charset="iso-8859-1"



> > I hope I'm not overlooking something elementary here, but estimated
> > fixed and random effects are considerably different from the
> > following Poisson model in lme4 and glmmADMB.  The fixed effects
> > seem to differ most considerably...  Thanks for any thoughts...
> > Adam Smith
>
> > > sessionInfo()
> > R version 2.14.1 (2011-12-22)
> > Platform: x86_64-pc-mingw32/x64 (64-bit)
> >
> > (SNIP)
> >
> > other attached packages:
> > [1] glmmADMB_0.7.2.5   lme4_0.999375-42   Matrix_1.0-3
> bbmle_1.0.4.1      numDeriv_2010.11-1
> > [6] lattice_0.20-0     R2admb_0.7.5       MASS_7.3-16
>
>
> > > str(cons09) # The dataset
> > 'data.frame':   394 obs. of  15 variables:
> >  $ plot       : Factor w/ 16 levels "n_10","n_2","n_3",..:
> > 2 2 2 2 2 2 2 2 2 2 ...
> >  $ plot_trt   : Factor w/ 32 levels
> > "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
> >  $ geog       : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
> >  $ trt        : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
> >  $ count      : Factor w/ 14 levels "1","2","3","4",..:
> > 1 2 3 4 5 6 7 8 9 10 ...
> >  $ total      : int  341 326 257 244 185 141 128 121 115 84 ...
> >  $ cons       : int  12 52 8 57 36 8 0 1 20 27 ...
> >  $ dt         : int  4 3 3 3 3 3 3 3 3 3 ...
> >  $ obs        : Factor w/ 394 levels "1","2","3","4",..:
> > 1 2 3 4 5 6 7 8 9 10 ...
> >  $ logtotal   : num  5.83 5.79 5.55 5.5 5.22 ...
> >  $ logdt      : num  1.39 1.1 1.1 1.1 1.1 ...
>
>
> > # The models
> > > Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt +
> > count:geog + trt:geog + offset(logtotal) +
> >         offset(logdt) + (1|plot) + (1|plot_trt),
> > zeroInflation=FALSE, family="poisson", data=cons09)
> >
> > > P_glmer <- glmer(cons ~ count + geog + trt +
> > count:trt + count:geog + trt:geog + offset(log(total)) +
> >       offset(log(dt)) + (1|plot) +
> > (1|plot_trt), family="poisson", data=cons09)
>
> By the way, you can specify these fixed effects
> more compactly as (count+geog+trt)^2 ...

Indeed, I was being explicit for explicitness' sake...

>
> > > fixef(Poiss)
>
> > 0.77333 0.58885 -0.21547 0.79101 0.24924 -0.02565 0.36004
> > -0.94852 0.39442 0.29032 0.13658 -0.39564
> > -1.37470 -0.88496 -0.53259 -0.25434
> > -0.41033 1.18840 0.25678 0.69734
> > 0.59823 1.11430 -0.17330 -0.15364
> > 0.98442 0.51533 -0.99431 -1.63920 -0.40455 -1.55670 0.15891
> > 0.35378 0.45748 0.92293 0.78373 1.05440
> > 0.39598 0.32019 1.41600
> > 0.86656 2.45790 1.07350 -0.31149
>
> > # After detaching glmmADMB and lme4, then
> > re-requiring lme4 to avoid masking of lme4's fixef function
> > > fixef(P_glmer)
> > -5.00326871 0.69554781 0.17105622 1.29467717
> > 0.97268949 0.87707266 1.39399967 0.22923370
> > 1.61829807 1.84546906 1.99506279 1.37859852
> > 0.53987085 1.13282524 -0.12901214 0.07021103
> > -0.52669841 0.87378323 0.05397134 0.46901053
> > 0.39863837 0.94486828 -0.18146287 -0.20340655
> > 0.77866847 0.49935778 -0.65101999 -1.05381279
> > -0.05290984 -1.54103716 -0.03887633 0.04570463 0.02076874
> > 0.47883964 0.23057821 0.49408747
> > -0.15116087 -0.32683907 0.50098187 0.14670125
> > 1.63961096 0.40944384 -0.22555478
> >
> > I juxtapose ranef() estimates here for comparison's sake...
> >
> [snip]
>
> There's nothing obviously wrong here. It's not a full solution,
> but I wonder how wide the confidence intervals are ... if they
> are very wide, then the practical answer is that these are poorly
> determined estimates. You're probably overfitting the model --
> 2 random effects plus 43 fixed-effect coefficients is
> quite a lot for 394 observations (the general rule of thumb
> is N/(# params)>10), especially if the Poisson data are sparse
> (although they don't look that way from the first few
> values listed in str() -- is there anyway you can allow
> 'count' to be continuous, or ordinal, rather than insisting
> on it being categorical?) But it would be best to try to answer
> more definitively ... can you send data?

I started with a general specification of count expecting to model 
it with an additive term when I start comparing fixed effects.? I 
suppose I could model it as a lower order polynomial initially... 
Doing so should drastically reduce the number of fixed effects in 
the model.? I suppose I should center it before creating the
polynomial terms...

However, I'll still send the data off-list.? 

Thanks for looking this over.

>
> Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  


------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 62, Issue 29
**************************************************

From trea26 at gmail.com  Mon Feb 13 21:45:06 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Mon, 13 Feb 2012 16:45:06 -0400
Subject: [R-sig-ME] Any package for best subset selection for,
 random effects model
In-Reply-To: <mailman.3116.1329165038.4475.r-sig-mixed-models@r-project.org>
References: <mailman.3116.1329165038.4475.r-sig-mixed-models@r-project.org>
Message-ID: <4F397652.40707@gmail.com>

Maybe function ffRanefLMER.fnc from package LMERConvenienceFunctions???

Antoine Tremblay, PhD
NeuroCognitive Imaging Laboratory
Dalhousie University
Halifax, NS B3H 3J5,
Canada

Tel.: (902) 494-1911
eom

On 12-02-13 04:30 PM, r-sig-mixed-models-request at r-project.org wrote:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>     1. Re: Any package for best subset selection for random effects
>        model (Thackeray, Stephen J.)
>     2. Re: R-sig-mixed-models Digest, Vol 62, Issue 29
>        (anthony.sealey at utoronto.ca)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 13 Feb 2012 20:18:38 +0000
> From: "Thackeray, Stephen J."<sjtr at ceh.ac.uk>
> To: Tao Zhang<zt020200 at gmail.com>, "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Any package for best subset selection for
> 	random effects	model
> Message-ID:
> 	<42AFDDFA3288A141B63C93EE7F138E97216D3BADF7 at nerckwmb1.ad.nerc.ac.uk>
> Content-Type: text/plain; charset="us-ascii"
>
> Hello Tao,
>
>> From your question, I am unsure of quite what you want. If you are interested in determining from a global model (with all fixed effects included) the model(s) with the most optimal subset of these fixed effects then you could try the dredge function in the MuMIn package. This will accept lme and lmer mixed effects models...
>
> All the best
>
> Steve
>
>
>
> ________________________________________
> From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Tao Zhang [zt020200 at gmail.com]
> Sent: 13 February 2012 17:22
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Any package for best subset selection for random effects    model
>
>   Hi Pros,
>        I know leaps() computes the best subset selection for linear model,
> and
>   the bestglm() computes the best subset selection for generalized linear
>   model. Is there any package for best subset selection on random effects
>   model, or mixed effects model?
>
> Thank you!
>
> Tao
>
>          [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models--
> This message (and any attachments) is for the recipient only. NERC
> is subject to the Freedom of Information Act 2000 and the contents
> of this email and any reply you make may be disclosed by NERC unless
> it is exempt from release under the Act. Any material supplied to
> NERC may be stored in an electronic records management system.
>
>
> ------------------------------
>
> Message: 2
> Date: Mon, 13 Feb 2012 20:40:09 +0000
> From: anthony.sealey at utoronto.ca
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 62, Issue 29
> Message-ID:
> 	<354080429-1329165020-cardhu_decombobulator_blackberry.rim.net-278480037- at b25.c26.bise6.blackberry>
> 	
> Content-Type: text/plain
>
> 9sbnopoi
> -----Original Message-----
> From:	r-sig-mixed-models-request at r-project.org
> Sender:	r-sig-mixed-models-bounces at r-project.org
> Date:	Mon, 13 Feb 2012 20:07:11
> To:<r-sig-mixed-models at r-project.org>
> Reply-To: r-sig-mixed-models at r-project.org
> Subject: R-sig-mixed-models Digest, Vol 62, Issue 29
>
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>     1. Comparing against a negative control in an LMM (Masca, Nick)
>     2. MCMCglmm with cross-classified random effects (Agostino Moro)
>     3. Re: MCMCglmm with cross-classified random effects
>        (Jarrod Hadfield)
>     4. Re: Considerable discrepancies between fixed and random
>        effect estimates of lme4 (glmer) and glmmADMB (Ben Bolker)
>     5. Any package for best subset selection for random effects
>        model (Tao Zhang)
>     6. Interpretation of nonlinear mixed-effects modeling	results
>        (Gang Chen)
>     7. Re: Considerable discrepancies between fixed and random
>        effect estimates of lme4 (glmer) and glmmADMB (Adam Smith)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 13 Feb 2012 12:33:42 +0000
> From: "Masca, Nick"<Nick.Masca at effem.com>
> To: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Comparing against a negative control in an LMM
> Message-ID:
> 	<8295A4D50D4C644CAC4323DD070D9597106F2D at 034-CH1MPN1-014.034d.mgd.msft.net>
> 	
> Content-Type: text/plain
>
> Hi all,
>
> I have a problem based on a colleague's experiment that I've been asked to analyse, which is more of a general mixed modelling issue rather than specifically an R issue, and I would be extremely grateful for any help that any readers of this list can provide.
>
> An experiment was conducted in which the aim was to compare 3 concentrations of 2 active treatments (i.e. 6 active treatments in total) to a negative control.  Three batches of each of the actives have been tested, and 3 reps tested for each batch.  In contrast, 20 replicates have been taken of the negative control - but, by definition, there is no "batch" for this treatment.
>
> Here is some code to reproduce the experimental design:
>
> Treat<- factor(c(rep("NC", 20), rep("A", 27), rep("B", 27)))
> Conc<-factor(c(rep(1, 20), rep(1:3, each=9), rep(1:3, each=9)))
> Batch<-factor(c(rep(1, 20), rep( rep(1:3, each=3), 6)))
> Treatment<-factor(Treat:Conc)  #specify new treatment variable (so don't attempt to estimate Conc. 2&3 for NC)
>
> I originally planned to analyses these data in a LMM, with Treat*Conc as a 7 level fixed effect (i.e. 3*2 actives + control), and with Treat:Conc:Batch as random.  The following code simulates my response variable assuming this model:
>
>                  Resp<-  rep(9, 74) + #simulate intercept
>                                  c( rep(rnorm(1, 0, sd=2.5), 20)^2, rep(rnorm(18, 0, sd=2.5), each=3)^2) + #simulate treat.conc.batch variance
>                                  rep(rnorm(74, 0, sd=.2)^2) + #simulate residual variance
>                                  c(rep(0,20), rep(c(-4, 0,0,-4, 0,0), each= 9)) #simulate fixed effects
>                  Data<-data.frame(Treatment, Conc, Batch, Resp)
>
> While this code models the data using lme4:
>                  Mod<-lmer(Resp ~ Treatment + (1|Treatment:Batch), data=Data)
>
> I can now obtain and plot treatment means/CIs using glht in the multcomp package:
> library(multcomp)
>                  Mean.mat<-diag(rep(1,7))
>                                  Mean.mat[,1]<-rep(1,7)
>                                  rownames(Mean.mat)<-levels(Data$Treatment)
>                  Est.means<-glht(Mod, Mean.mat)
> plot(Est.means)
>
> Hopefully from the above plot you can see what my issue is.  The negative control, which I want to compare everything against, has by far the least precision around its estimate, despite the data for the control hardly varying at all.  This happens because the greatest source of variability in the model (by far) is the variability between batches, but different batches of the negative control don't exist.  As such, I'm not sure that this is a fair way to model the data, because the negative control is unfairly penalised by the variability between the batches of the other treatments.
>
> I imagine that this kind of problem isn't particularly uncommon, but it's the first time I've had to deal with something like this myself.   The only potential solution I've come up with so far is to scrap the negative control from the model, and simply subtract the negative control's mean "count" from all other values (either by specifying this mean as an offset or by subtracting it from all data-points).  But this will probably give "anti-conservative" results, as it would assume the mean for the negative control doesn't vary.
>
> I would be extremely grateful if anyone would care to share their thoughts on possible solutions to this problem - and whether anyone has dealt with this kind of issue before.  I feel that I may well be missing something obvious - but can't see at the moment how else to get around it!
>
> Many thanks for any help you can provide.
>
> Cheers,
>
> Nick
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 2
> Date: Mon, 13 Feb 2012 15:02:20 +0000
> From: Agostino Moro<agostino.moro99 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] MCMCglmm with cross-classified random effects
> Message-ID:
> 	<CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Dear R-users,
>
> I would like to fit ?a glmm with cross-classified random effects with
> the function MCMCglmm. Something along the lines:
>
> model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)
>
> where re1 and re2 should be crossed random effects. I was wondering
> whether you could tell me specifying cross-classified random effects
> in MCMCglmm requires a particular syntax? Are there any examples
> somewhere? I have had a look at the manual and the package vignette,
> but I have not been able to find any examples relevant to what I want
> to do.
>
> Thanks,
>
> Agostino
>
>
>
> ------------------------------
>
> Message: 3
> Date: Mon, 13 Feb 2012 15:19:07 +0000
> From: Jarrod Hadfield<j.hadfield at ed.ac.uk>
> To: Agostino Moro<agostino.moro99 at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm with cross-classified random effects
> Message-ID:<20120213151907.57957fqy2tmlxcg8 at www.staffmail.ed.ac.uk>
> Content-Type: text/plain; charset=ISO-8859-1; DelSp="Yes";
> 	format="flowed"
>
> Hi,
>
> As long as the levels of re1 and re2 are uniquely labelled any cross
> classification will be dealt with appropriately.
>
> Cheers,
>
> Jarrod
>
>
> Quoting Agostino Moro<agostino.moro99 at gmail.com>  on Mon, 13 Feb 2012
> 15:02:20 +0000:
>
>> Dear R-users,
>>
>> I would like to fit ?a glmm with cross-classified random effects with
>> the function MCMCglmm. Something along the lines:
>>
>> model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)
>>
>> where re1 and re2 should be crossed random effects. I was wondering
>> whether you could tell me specifying cross-classified random effects
>> in MCMCglmm requires a particular syntax? Are there any examples
>> somewhere? I have had a look at the manual and the package vignette,
>> but I have not been able to find any examples relevant to what I want
>> to do.
>>
>> Thanks,
>>
>> Agostino
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>



From Jeffrey.Morris at sanofipasteur.com  Tue Feb 14 16:22:59 2012
From: Jeffrey.Morris at sanofipasteur.com (Jeffrey.Morris at sanofipasteur.com)
Date: Tue, 14 Feb 2012 10:22:59 -0500
Subject: [R-sig-ME] Simple Task: CI on Total Imprecision
Message-ID: <15B762F2463DA8429B5B5E7F128258E716A74E81@USSWTEXS102.pasteur.aventis.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120214/b460ada0/attachment-0001.pl>

From bates at stat.wisc.edu  Tue Feb 14 16:23:09 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 14 Feb 2012 09:23:09 -0600
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
 convergence (7)"
In-Reply-To: <CA+hwERn-9DHnOVr9omj50dRY-wfQ4aDBEDiqiktSBdmexf4_uw@mail.gmail.com>
References: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
	<CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
	<CA+hwERn-9DHnOVr9omj50dRY-wfQ4aDBEDiqiktSBdmexf4_uw@mail.gmail.com>
Message-ID: <CAO7JsnRkL3abu1OiyoA7uP8rOWka-Sj3X4wXnQXe0VNOojrLWw@mail.gmail.com>

On Fri, Feb 10, 2012 at 5:06 AM, Toni Hernandez-Matias
<ahmatias at gmail.com> wrote:
> Dear Douglas,
>
> thank you very much for your message. If necessary I can send you my data
> set. Before let me show you the output of the verbose=TRUE and the summary
> of the model results (see below).
> I wonder wether the problem is that the variance estimated for the main
> random effect (study area: coded as 'ter') takes the value of 0 (third
> column in the results of the 'verbose'). If that would be the problem, I
> wonder whether it would be acceptable (dessing) that I would ommit this
> random effect in the models and only considering the random effect of the
> transects (coded as 'trans'). On the other hand, I don't understand why this
> problem only happens with some of the independent variables (other models
> fitted fine).
>
> Thank you very much in advance,
>
> Toni
>
> mod05<-lmer(cagaders~E_arb_alt+(1|ter)+(1|ter:trans),data=conill,family=poisson,verbose=TRUE)
>
> ?0:???? 1580.1040: 0.521157 0.212762 0.0146621 -0.00550703
> ?1:???? 1578.7769: 0.529048 0.217137 0.0121796 -0.00198275
> ?2:???? 1574.8963: 0.536915 0.221586 0.00963723 -0.00542672
> ?3:???? 1546.2308: 0.659172 0.290027 -0.0296622 -2.71216e-05
> ?4:???? 1544.4481: 0.659755 0.290395 -0.0299398 -0.00438446
> ?5:???? 1512.2918: 0.827224 0.356975 -0.453220 0.000576404
> ?6:???? 1506.1926:? 1.14082 0.0210690 -0.431339 -0.00365397
> ?7:???? 1500.5942:? 1.16992? 0.00000 -0.828777 0.00123612
> ?8:???? 1500.3060:? 1.20528? 0.00000 -0.790690 0.00198426
> ?9:???? 1499.5992:? 1.25168? 0.00000 -0.779210 0.000659413
> 10:???? 1499.3691:? 1.28723? 0.00000 -0.803391 0.000445819
> 11:???? 1499.2722:? 1.32511? 0.00000 -0.837827 0.000455882
> 12:???? 1499.2705:? 1.33004? 0.00000 -0.843619 0.000496015
> 13:???? 1499.2704:? 1.33032? 0.00000 -0.844199 0.000502862
> 14:???? 1499.2704:? 1.33030? 0.00000 -0.844231 0.000503448
> Mensajes de aviso perdidos

The fact that the second parameter is stuck at 0 indicates that the
random effect associated with ter is inert given that the random
effect associated with ter:trans is in the model.  You should try
fitting a model of the form

cagaders ~ E_arb_alt + (1|ter:trans)

> In mer_finalize(ans) : singular convergence (7)
>
>
>
> SUMMARY
> Generalized linear mixed model fit by the Laplace approximation Formula:
> cagaders ~ E_arb_alt + (1 | ter) + (1 | ter:trans)?? Data: conill? AIC? BIC
> logLik deviance
> 1507 1525 -749.6???? 1499
> Random effects:
> Groups??? Name??????? Variance Std.Dev.
> ter:trans (Intercept) 1.7697?? 1.3303? ter?????? (Intercept) 0.0000
> 0.0000? Number of obs: 648, groups: ter:trans, 66; ter, 11
>
> Fixed effects:
> ??????????? Estimate Std. Error z value Pr(>|z|)??? (Intercept) -0.8442310
> 0.1839531? -4.589 4.45e-06 ***
> E_arb_alt??? 0.0005023? 0.0029302?? 0.171??? 0.864??? ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Correlation of Fixed Effects:
> ??????? (Intr)
> E_arb_alt -0.247
>
>
>
>
>
>
> On Thu, Feb 9, 2012 at 9:03 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>> On Thu, Feb 9, 2012 at 11:08 AM, Toni Hernandez-Matias
>> <ahmatias at gmail.com> wrote:
>> > Dear all,
>>
>> > I am trying to fit a set of models with lmer function.
>> > My aim is to investigate the relationship between the abundance of a
>> > mammal
>> > species (count) and several environmental variables.
>> > The sample size is 648, but the observations are not independent and the
>> > random effect is nested: I have 10 study areas, within each area I
>> > performed 6 transects. I have 9-10 observations in all transects. So an
>> > example of a model with a single independent variable is:
>> >
>> > mod05<-lmer(cagaders~E_arb_alt+(1|ter)+(1|ter:trans),data=conill,family=poisson)
>>
>> > When running this model I get the warning:
>> > In mer_finalize(ans) : singular convergence (7)
>>
>> Try using verbose=TRUE to determine where the parameter values are
>> going during the iterative optimization process.
>>
>> If your data could be made available, even in an anonymized form, we
>> could check the model fit against other optimizers that may be more
>> successful.
>>
>> > I don't see an apparent reason for this warning.
>> > I would be very grateful if someone can help me to solve this problem
>> > and
>> > to know wether the results in the fitted model are credible.
>> >
>> > Thank you very much in advance,
>> >
>> > Toni
>> >
>
>
> --
> *********************************************************
>
> Antonio Hernandez Matias
>
> Departament de Biologia Animal (Vertebrats)
> Facultat de Biologia
> Universitat de Barcelona
> Av. Diagonal, 645
> Barcelona? ? ? 08028
> Spain
> Telephone: +34-934035857
> FAX: +34-934035740
> e-mail: ahernandezmatias at ub.edu
>
> ***********************************************************



From federico.tettamanti at gmail.com  Tue Feb 14 09:51:40 2012
From: federico.tettamanti at gmail.com (Federico Tettamanti)
Date: Tue, 14 Feb 2012 09:51:40 +0100
Subject: [R-sig-ME] Fwd: Modeling ecological observations
In-Reply-To: <CACNpG7tncy=+c9zgCzBV-VozAr3R3c1=PFKEY1Zh6s7zfYztbA@mail.gmail.com>
References: <CACNpG7tncy=+c9zgCzBV-VozAr3R3c1=PFKEY1Zh6s7zfYztbA@mail.gmail.com>
Message-ID: <CACNpG7s2QJOvYo=oMbQ4auBGm1gheOJpeM2qPq1q21AceZ4Kiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120214/804ab684/attachment-0001.pl>

From geetha_r at ces.iisc.ernet.in  Wed Feb 15 04:39:17 2012
From: geetha_r at ces.iisc.ernet.in (Geetha Ramaswami)
Date: Wed, 15 Feb 2012 09:09:17 +0530 (IST)
Subject: [R-sig-ME] Reg. interpretation of parameter CIs from lmer()
Message-ID: <41753.10.16.40.14.1329277157.squirrel@ces.iisc.ernet.in>

Dear All,

 I am working with an ecological data set wherein I am trying to compare
 the growth rate of seedlings in plots where an invasive species is present
 or absent. Repeated measures on seedlings were made every two months
 across 40 plots of which 20 had the invasive species while the remaining
 20 did not. Seedling growth is measured as log(proportion increment in
 height) per month. I am also interested in looking at how rainfall
 received between two consecutive growth measurements and seedling habitat
 preferences affect growth. I came up with the following mixed effects
 model

 growth ~ invasive density (2 levels) + seedling habitat preference (3
 levels) + rainfall (mm) + all two-way interactions + random intercept on
 repeatedly measured plots

 The residuals on this model are highly overdispersed and do not meet the
 normality criteria, so i decided to use nonparametric bootstrapping
 (refitting the model with 10000 random subsets of data) to obtain 95% CI
 on all the fixed effects parameters estimated (I assumed that the CIs
 non-overlapping with zero indicated significant fixed effects). Apart from
 the 'intercept', the 'rain' term and the 'invasive density' term, 95% Cis
 of all other parameters included zero. I am interested in graphically
 representing only these effects. Since the normality assumption of
 residuals is not satisfied, is it appropriate to simplify the model using
 anova (with REML = F)? Or can I create a new, simpler model with just the
 terms of interest, generate 95% CI for these parameters and use these for
 graphical representation?

 Thank you in advance for your help.
 Geetha

 Geetha Ramaswami
 PhD Student
 Centre for Ecological Sciences,
 Indian Institute of Science,
 Bangalore 560012,
 India


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From federico.tettamanti at gmail.com  Wed Feb 15 10:36:13 2012
From: federico.tettamanti at gmail.com (Federico Tettamanti)
Date: Wed, 15 Feb 2012 10:36:13 +0100
Subject: [R-sig-ME] Modeling of behavioural observation
Message-ID: <CACNpG7t+mDX6fuwnsSZ9UcOm8DApzKvsh+Agr_YjNSqrOW+jvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120215/423f806c/attachment-0001.pl>

From felipnunes at gmail.com  Wed Feb 15 18:31:57 2012
From: felipnunes at gmail.com (Felipe Nunes)
Date: Wed, 15 Feb 2012 09:31:57 -0800
Subject: [R-sig-ME] glmer error
Message-ID: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120215/aaf7edfd/attachment-0001.pl>

From jianyun.fred.wu at gmail.com  Wed Feb 15 22:05:42 2012
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Thu, 16 Feb 2012 08:05:42 +1100
Subject: [R-sig-ME] modelling seasonal patterns as random effects in a
	monthly time series
Message-ID: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120216/c67b59b6/attachment-0001.pl>

From kfrost at wisc.edu  Wed Feb 15 22:12:56 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Wed, 15 Feb 2012 15:12:56 -0600
Subject: [R-sig-ME] modelling seasonal patterns as random effects in
	a	monthly time series
In-Reply-To: <7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
References: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>
	<7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
Message-ID: <77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>

Hi, Fred-

The answer to your question is probably yes, but you need to provide more details about what you want to do.

Ken

On 02/15/12, Jianyun Wu   wrote:
> Dear All,
> 
> Is there any function or packages in R that I can treat seasonal patterns
> as random effects in a monthly time series?
> 
> Is this possible to formulate such a model using nlme, lme4 or other
> available mixed model packages?
> 
> Thanks and Regards
> 
> Fred
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jianyun.fred.wu at gmail.com  Wed Feb 15 22:33:36 2012
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Thu, 16 Feb 2012 08:33:36 +1100
Subject: [R-sig-ME] modelling seasonal patterns as random effects in a
 monthly time series
In-Reply-To: <77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>
References: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>
	<7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
	<77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>
Message-ID: <CAOMGRDL0SBpcCMOTqWRdFhDG2ucJL1aj-hKGOvJ3q0smEyscCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120216/4296ec08/attachment-0001.pl>

From chris at trickysolutions.com.au  Thu Feb 16 00:09:29 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Thu, 16 Feb 2012 10:09:29 +1100
Subject: [R-sig-ME] modelling seasonal patterns as random effects in a
 monthly time series
In-Reply-To: <CAOMGRDL0SBpcCMOTqWRdFhDG2ucJL1aj-hKGOvJ3q0smEyscCA@mail.gmail.com>
References: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>
	<7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
	<77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>
	<CAOMGRDL0SBpcCMOTqWRdFhDG2ucJL1aj-hKGOvJ3q0smEyscCA@mail.gmail.com>
Message-ID: <5983470160263463854@unknownmsgid>

Try lme and lme4. There is also a list calle r-sig-me.



Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 16/02/2012, at 8:35, Jianyun Wu <jianyun.fred.wu at gmail.com> wrote:

> Hi Ken,
> I have a monthly time series, and the seasonal pattern is obvious where
> peaks are in Dec and drops in Jan. However due to various "external"
> factors, the seasonal variation during the year may change from time to
> time. The traditional practice here is to use seasonal dummies to treat
> them deterministically.
> Therefore I am curious that instead of treating them as fixed effects,
> whether random effects model can apply for 12 month in each year.
> We do not use Box-Jenkin approach to difference the time series as we can
> hardly find a significant association on a variable of interest. But using
> determinstic trend and seasonal dummies do....
> Thanks
> Fred
>
> On Thu, Feb 16, 2012 at 8:12 AM, Kenneth Frost <kfrost at wisc.edu> wrote:
>
>> Hi, Fred-
>>
>> The answer to your question is probably yes, but you need to provide more
>> details about what you want to do.
>>
>> Ken
>>
>> On 02/15/12, Jianyun Wu   wrote:
>>> Dear All,
>>>
>>> Is there any function or packages in R that I can treat seasonal patterns
>>> as random effects in a monthly time series?
>>>
>>> Is this possible to formulate such a model using nlme, lme4 or other
>>> available mixed model packages?
>>>
>>> Thanks and Regards
>>>
>>> Fred
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>   [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From chris at trickysolutions.com.au  Thu Feb 16 00:16:07 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Thu, 16 Feb 2012 10:16:07 +1100
Subject: [R-sig-ME] modelling seasonal patterns as random effects in a
 monthly time series
In-Reply-To: <5983470160263463854@unknownmsgid>
References: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>
	<7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
	<77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>
	<CAOMGRDL0SBpcCMOTqWRdFhDG2ucJL1aj-hKGOvJ3q0smEyscCA@mail.gmail.com>
	<5983470160263463854@unknownmsgid>
Message-ID: <943502692803007561@unknownmsgid>

Very Sorry everyone for the redundant reply to jianyun.

for some reason I thought that came from the r-sig-Eco list I'm on and
I also managed to not process  jianyun's last sentence.

I think I must still be half asleep, my only excuse is that I haven't
had my cup of tea yet.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 16/02/2012, at 10:09, Chris Howden <chris at trickysolutions.com.au> wrote:

> Try lme and lme4. There is also a list calle r-sig-me.
>
>
>
> Chris Howden
> Founding Partner
> Tricky Solutions
> Tricky Solutions 4 Tricky Problems
> Evidence Based Strategic Development, IP Commercialisation and
> Innovation, Data Analysis, Modelling and Training
>
> (mobile) 0410 689 945
> (fax / office)
> chris at trickysolutions.com.au
>
> Disclaimer: The information in this email and any attachments to it are
> confidential and may contain legally privileged information. If you are not
> the named or intended recipient, please delete this communication and
> contact us immediately. Please note you are not authorised to copy,
> use or disclose this communication or any attachments without our
> consent. Although this email has been checked by anti-virus software,
> there is a risk that email messages may be corrupted or infected by
> viruses or other
> interferences. No responsibility is accepted for such interference. Unless
> expressly stated, the views of the writer are not those of the
> company. Tricky Solutions always does our best to provide accurate
> forecasts and analyses based on the data supplied, however it is
> possible that some important predictors were not included in the data
> sent to us. Information provided by us should not be solely relied
> upon when making decisions and clients should use their own judgement.
>
> On 16/02/2012, at 8:35, Jianyun Wu <jianyun.fred.wu at gmail.com> wrote:
>
>> Hi Ken,
>> I have a monthly time series, and the seasonal pattern is obvious where
>> peaks are in Dec and drops in Jan. However due to various "external"
>> factors, the seasonal variation during the year may change from time to
>> time. The traditional practice here is to use seasonal dummies to treat
>> them deterministically.
>> Therefore I am curious that instead of treating them as fixed effects,
>> whether random effects model can apply for 12 month in each year.
>> We do not use Box-Jenkin approach to difference the time series as we can
>> hardly find a significant association on a variable of interest. But using
>> determinstic trend and seasonal dummies do....
>> Thanks
>> Fred
>>
>> On Thu, Feb 16, 2012 at 8:12 AM, Kenneth Frost <kfrost at wisc.edu> wrote:
>>
>>> Hi, Fred-
>>>
>>> The answer to your question is probably yes, but you need to provide more
>>> details about what you want to do.
>>>
>>> Ken
>>>
>>> On 02/15/12, Jianyun Wu   wrote:
>>>> Dear All,
>>>>
>>>> Is there any function or packages in R that I can treat seasonal patterns
>>>> as random effects in a monthly time series?
>>>>
>>>> Is this possible to formulate such a model using nlme, lme4 or other
>>>> available mixed model packages?
>>>>
>>>> Thanks and Regards
>>>>
>>>> Fred
>>>>
>>>>    [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>  [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Thu Feb 16 02:35:47 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 16 Feb 2012 11:35:47 +1000 (EST)
Subject: [R-sig-ME] glmer error
In-Reply-To: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
References: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1202161126140.19412@orpheus.qimr.edu.au>

On Wed, 15 Feb 2012, Felipe Nunes wrote:

> glmer(dummy ~ x + time + (time | subject), data, family=binomial(link
> = "logit"), REML=T, verbose=T)
>
> Error in glm.fit(fr$X, fr$Y, weights = wts, offset = offset, family =
> family,  :
>
> NA/NaN/Inf in foreign function call (arg 1)
>
> I omitted NAs, changed the model specification, transformed x to log(x) but
> nothing solved the problem. I think the problem is on variable 'x' given
> that is the only one that causes that problem.

You need to provide us with a subset of your dataset that causes the same 
problem.  Alternatively, debug(glm.fit) and look at the contents of 
"x[good,]" etc.  Maybe it's separation.



From John.Morrongiello at csiro.au  Thu Feb 16 02:59:16 2012
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Thu, 16 Feb 2012 12:59:16 +1100
Subject: [R-sig-ME] random effects structure and overfitting
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB159EFDFFA3@exvic-mbx03.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120216/36a0f586/attachment-0001.pl>

From rhbc at imm.dtu.dk  Thu Feb 16 07:26:28 2012
From: rhbc at imm.dtu.dk (Rune Haubo)
Date: Thu, 16 Feb 2012 07:26:28 +0100
Subject: [R-sig-ME] glmer error
In-Reply-To: <Pine.LNX.4.64.1202161126140.19412@orpheus.qimr.edu.au>
References: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
	<Pine.LNX.4.64.1202161126140.19412@orpheus.qimr.edu.au>
Message-ID: <CAG_uk91gGHk8VA4U58X06yDy5W7C+SXtbbDKzLng8fQXY2DNww@mail.gmail.com>

On 16 February 2012 02:35, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Wed, 15 Feb 2012, Felipe Nunes wrote:
>
>> glmer(dummy ~ x + time + (time | subject), data, family=binomial(link
>> = "logit"), REML=T, verbose=T)

Will data=pool solve it?

/Rune

PS: REML=T makes no sense for GLMMs and is, I believe, just ignored.

>>
>> Error in glm.fit(fr$X, fr$Y, weights = wts, offset = offset, family =
>> family, ?:
>>
>> NA/NaN/Inf in foreign function call (arg 1)
>>
>> I omitted NAs, changed the model specification, transformed x to log(x)
>> but
>> nothing solved the problem. I think the problem is on variable 'x' given
>> that is the only one that causes that problem.
>
>
> You need to provide us with a subset of your dataset that causes the same
> problem. ?Alternatively, debug(glm.fit) and look at the contents of
> "x[good,]" etc. ?Maybe it's separation.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jwiley.psych at gmail.com  Fri Feb 17 04:29:32 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 16 Feb 2012 19:29:32 -0800
Subject: [R-sig-ME] glmer error
In-Reply-To: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
References: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
Message-ID: <CANz9Z_KOyaeZbowyWuxdCBfKtChPnRWjXqaaAf3cH2y4beTP7Q@mail.gmail.com>

Hi Felipe,

Your problem is probably not too difficult to fix given some data.
The error message comes from glm.fit.  glmer() actually fits a basic
logistic model prior to fitting the random coefficient model.  You are
running into problems at this stage.  You can get to this stage pretty
easily, which simplifies debugging.

Lacking data, I wrote a short function to simulate some binary data here:

https://gist.github.com/1850238

require(lme4)
## simulate data
dat <- bsim(reps = 10)

## your formula
f <- Y ~ X + W + (1 | G)
## your call to glmer (
mc <- call("glmer", formula = f, data = dat, family = binomial(link = "logit"))
m <- eval(mc) # evaluate the glmer call (works on my data, fails on
yours, presumably)

## use the glmer call to extract the frames passed to glm.fit
base <- lme4:::lmerFrames(mc, f, NULL)
## run the logistic model (the error suggests you run into problems here)
m2 <- glm.fit(base$X, base$Y, family = binomial(link = "logit"))
m2$converge ## should be true if it runs

you can do debugging, traceback() etc. at this stage, which should
make your life a little easier.  I would examine the X and Y matrices,
check for separation, etc.

if your x variable is categorical, try looking at at the crosstabs of
it with your outcome a l?:

xtabs(~ y + x)

also in any follow up emails to the list, please report the output of
sessionInfo() per the posting guide.  The version of R/lme4 you are
running may be relevant (alternately, upgrade to the latest stable
release of R and lme4).  Douglas Bates et al have been active working
on development, and it would be rather silly for us to spend time and
confusion because we are using one version and you are using another
and neither side realizes it.

Cheers,

Josh

On Wed, Feb 15, 2012 at 9:31 AM, Felipe Nunes <felipnunes at gmail.com> wrote:
> I'm trying to fit the model
>
> glmer(dummy ~ x + time + (time | subject), data, family=binomial(link
> = "logit"), REML=T, verbose=T)
>
> but I keep receiving the following error:
>
> Error in glm.fit(fr$X, fr$Y, weights = wts, offset = offset, family =
> family, ?:
>
> NA/NaN/Inf in foreign function call (arg 1)
>
> I omitted NAs, changed the model specification, transformed x to log(x) but
> nothing solved the problem. I think the problem is on variable 'x' given
> that is the only one that causes that problem.
>
> When I run
>
> mod6 <- glmer(dummy ~ a + I(b) + I(c) + d + e + time + (time |
> subject) + (time|subjectregion), data=pool, family=binomial(link =
> "logit"), REML=T, verbose=T)
>
> I don't have any problem.
>
> Any idea about what is happening?
> *
> *
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From longrob604 at gmail.com  Fri Feb 17 13:52:45 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 12:52:45 +0000
Subject: [R-sig-ME] LMER vs MLwiN
Message-ID: <4F3E4D9D.80707@gmail.com>

Hello

I'm new to using mixed models in R. Thus far I've been using MLwiN. I am 
trying to duplicate the results in MLwiN of a logistic mixed effects model.

At the moment I have no covariates, and a data hierarchy of
pupil within class within school within commune with random effects at 
each level above pupil.

There are 9000 observations in total;

300 classes
100 schools
20 communes
These have been set as factors with as.factor(). I'm not sure if this is 
correct as they were not categorical in MLwiN (they were just ints) but 
I was getting this error before I did that:
"Error: length(f1) == length(f2) is not TRUE"

I have tried to fit a model with glmer like this:

glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS/PUPIL),data=dt,family=binomial(link = 
"logit"))

However this generates the error
"Error: cannot allocate vector of size 9.5 Gb"

I have also tried glmmPQL in the MASS package:
glmmPQL(LOSS~1,data=dt, random = 
~1|COMMUNE/SCHOOL/CLASS/PUPIL,family=binomial(link = "logit"))

However this generates /completely/ wrong estimates so I can only assume 
that I am specifying the model incorrectly in R.

If anyone can advise, I would be very grateful
Thanks
RL



From f.calboli at imperial.ac.uk  Fri Feb 17 14:06:44 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Fri, 17 Feb 2012 13:06:44 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <4F3E4D9D.80707@gmail.com>
References: <4F3E4D9D.80707@gmail.com>
Message-ID: <D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>

On 17 Feb 2012, at 12:52, W Robert Long wrote:

> Hello
> 
> I'm new to using mixed models in R. Thus far I've been using MLwiN. I am trying to duplicate the results in MLwiN of a logistic mixed effects model.
> 
> At the moment I have no covariates, and a data hierarchy of
> pupil within class within school within commune with random effects at each level above pupil.
> 
> There are 9000 observations in total;
> 
> 300 classes
> 100 schools
> 20 communes
> These have been set as factors with as.factor(). I'm not sure if this is correct as they were not categorical in MLwiN (they were just ints) but I was getting this error before I did that:
> "Error: length(f1) == length(f2) is not TRUE"
> 
> I have tried to fit a model with glmer like this:
> 
> glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS/PUPIL),data=dt,family=binomial(link = "logit"))

you seem to specify COMMUNE and SCHOOL as random effects, with no fixed effects. If I were you I would:

1) code PUPIL from 1:n so that you never have two different pupils in two different classes coded with the same code. 
2) code CLASS from 1:n (see above)

then I'd try

glmer(LOSS~ COMMUNE + SCHOOL + (1|CLASS) + (1|PUPIL) ,data=dt,family=binomial(link = "logit")) #coding class and pupil as I said will automatically take care of the nesting

as see what happens.

If you are using R 32 bits you might want to use R 64 bits to have more RAM available.

BW

F



> 
> However this generates the error
> "Error: cannot allocate vector of size 9.5 Gb"
> 
> I have also tried glmmPQL in the MASS package:
> glmmPQL(LOSS~1,data=dt, random = ~1|COMMUNE/SCHOOL/CLASS/PUPIL,family=binomial(link = "logit"))
> 
> However this generates /completely/ wrong estimates so I can only assume that I am specifying the model incorrectly in R.
> 
> If anyone can advise, I would be very grateful
> Thanks
> RL
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bbolker at gmail.com  Fri Feb 17 15:49:32 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 Feb 2012 14:49:32 +0000 (UTC)
Subject: [R-sig-ME] LMER vs MLwiN
References: <4F3E4D9D.80707@gmail.com>
Message-ID: <loom.20120217T153412-117@post.gmane.org>

W Robert Long <longrob604 at ...> writes:

> I'm new to using mixed models in R. Thus far I've been using MLwiN. I am 
> trying to duplicate the results in MLwiN of a logistic mixed effects model.
> 
> At the moment I have no covariates, and a data hierarchy of
> pupil within class within school within commune with random effects at 
> each level above pupil.
> 
> There are 9000 observations in total;
> 
> 300 classes
> 100 schools
> 20 communes
> These have been set as factors with as.factor(). I'm not sure if this is 
> correct as they were not categorical in MLwiN (they were just ints) but 
> I was getting this error before I did that:
> "Error: length(f1) == length(f2) is not TRUE"
> 
> I have tried to fit a model with glmer like this:
> 
> glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS/PUPIL),data=dt,family=binomial(link = 
> "logit"))
> 
> However this generates the error
> "Error: cannot allocate vector of size 9.5 Gb"
> 
> I have also tried glmmPQL in the MASS package:
> glmmPQL(LOSS~1,data=dt, random = 
> ~1|COMMUNE/SCHOOL/CLASS/PUPIL,family=binomial(link = "logit"))
> 
> However this generates /completely/ wrong estimates so I can only assume 
> that I am specifying the model incorrectly in R.
> 

  Hmmm. I'm not quite sure what's wrong, since a made-up example
with the same structure as yours worked pretty well on my system
(13 seconds to run, on a Linux virtual machine with a *total* of
3G of RAM).

ncomm <- 20
nschool <- 100
nclass <- 300
ntot <- 9000

set.seed(101)

u.comm <- rnorm(ncomm)
u.school <- rnorm(nschool)
u.class <- rnorm(nclass)
u.obs <- rnorm(ntot)

dt <- expand.grid(commune=factor(1:ncomm),
                  school=factor(1:(nschool/ncomm)),
                  class=factor(1:(nclass/nschool)),
                  pupil=factor(1:(ntot/nclass)))

## here lower-level units are not numbered uniquely, but that's OK as
## long as we always using nested syntax to refer to them

eta <- with(dt,u.comm[commune]+u.school[commune:school]+
            u.class[commune:school:class]+u.obs)
dt$loss <- rbinom(ntot,plogis(eta),size=1)

summary(dt)

    commune     school   class        pupil           loss       
 1      : 450   1:1800   1:3000   1      : 300   Min.   :0.0000  
 2      : 450   2:1800   2:3000   2      : 300   1st Qu.:0.0000  
 3      : 450   3:1800   3:3000   3      : 300   Median :0.0000  
 4      : 450   4:1800            4      : 300   Mean   :0.4776  
 5      : 450   5:1800            5      : 300   3rd Qu.:1.0000  
 6      : 450                     6      : 300   Max.   :1.0000  
 (Other):6300                     (Other):7200


library(lme4)
t1 <- system.time(g1 <- glmer(loss~(1|commune/school/class/pupil),data=dt,
                        family=binomial))

library(MASS)
t2 <- system.time(g2 <- glmmPQL(loss~1,
                                random=~1|commune/school/class/pupil,data=dt,
                        family=binomial))
## Error in lme.formula(fixed = zz ~ 1, random = ~1 |
commune/school/class/pupil,  : 
##   nlminb problem, convergence error code = 1
##  message = iteration limit reached without convergence (10)

lmer appears to underestimate the true variances (which were all set
to 1.0):

unlist(VarCorr(g1))
## pupil:(class:(school:commune))         class:(school:commune) 
##                     0.0000000                      0.7556695 
##                 school:commune                        commune 
##                     0.5782637                      0.3326618 

I also tried this in the development version of lme4 (which has
very different machinery internally) and got the same answer,
at least to within about 0.3% ... (it took about 3 seconds longer).
                                                   
  Can you export this data set and try it in MLWiN?



From longrob604 at gmail.com  Fri Feb 17 15:50:11 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 14:50:11 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
Message-ID: <4F3E6923.5080508@gmail.com>

Hi Federico

Thank you very much.

However, the model I'm trying to fit has no fixed effects. The MLwiN 
output gives me:
beta_0_hat: 1.012(0.107)  conditional log odds
var_f0_hat: 0.031(0.066)  variance between communues
var_v0_hat: 0.760(0.141)  variance between schools within commune
var_u0_hat: 0.186(0.38)   variance between classes within schools

This is what I am trying to duplicate in R with the same data.

BTW I am using 64 bit R

Thanks again
RL

On 17/02/2012 1:06 PM, Federico Calboli wrote:
> On 17 Feb 2012, at 12:52, W Robert Long wrote:
>
>> Hello
>>
>> I'm new to using mixed models in R. Thus far I've been using MLwiN. I am trying to duplicate the results in MLwiN of a logistic mixed effects model.
>>
>> At the moment I have no covariates, and a data hierarchy of
>> pupil within class within school within commune with random effects at each level above pupil.
>>
>> There are 9000 observations in total;
>>
>> 300 classes
>> 100 schools
>> 20 communes
>> These have been set as factors with as.factor(). I'm not sure if this is correct as they were not categorical in MLwiN (they were just ints) but I was getting this error before I did that:
>> "Error: length(f1) == length(f2) is not TRUE"
>>
>> I have tried to fit a model with glmer like this:
>>
>> glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS/PUPIL),data=dt,family=binomial(link = "logit"))
>
> you seem to specify COMMUNE and SCHOOL as random effects, with no fixed effects. If I were you I would:
>
> 1) code PUPIL from 1:n so that you never have two different pupils in two different classes coded with the same code.
> 2) code CLASS from 1:n (see above)
>
> then I'd try
>
> glmer(LOSS~ COMMUNE + SCHOOL + (1|CLASS) + (1|PUPIL) ,data=dt,family=binomial(link = "logit")) #coding class and pupil as I said will automatically take care of the nesting
>
> as see what happens.
>
> If you are using R 32 bits you might want to use R 64 bits to have more RAM available.
>
> BW
>
> F
>
>
>
>>
>> However this generates the error
>> "Error: cannot allocate vector of size 9.5 Gb"
>>
>> I have also tried glmmPQL in the MASS package:
>> glmmPQL(LOSS~1,data=dt, random = ~1|COMMUNE/SCHOOL/CLASS/PUPIL,family=binomial(link = "logit"))
>>
>> However this generates /completely/ wrong estimates so I can only assume that I am specifying the model incorrectly in R.
>>
>> If anyone can advise, I would be very grateful
>> Thanks
>> RL
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Federico C. F. Calboli
> Neuroepidemiology and Ageing Research
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>



From bbolker at gmail.com  Fri Feb 17 16:15:15 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 Feb 2012 15:15:15 +0000 (UTC)
Subject: [R-sig-ME] LMER vs MLwiN
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>
Message-ID: <loom.20120217T161249-694@post.gmane.org>

W Robert Long <longrob604 at ...> writes:

> 
> Hi Federico
> 
> Thank you very much.
> 
> However, the model I'm trying to fit has no fixed effects. The MLwiN 
> output gives me:
> beta_0_hat: 1.012(0.107)  conditional log odds
> var_f0_hat: 0.031(0.066)  variance between communues
> var_v0_hat: 0.760(0.141)  variance between schools within commune
> var_u0_hat: 0.186(0.38)   variance between classes within schools
> 
> This is what I am trying to duplicate in R with the same data.
> 
> BTW I am using 64 bit R

  OK, based on this output you shouldn't include 'pupil' in your
random effects specification (now that I think of it, you probably
shouldn't anyway, because it's unidentifiable for a Bernoulli outcome).

  If you wanted you could redo my example with your observed effects
(e.g. u.commune = rnorm(n.comm,sd=sqrt(0.031)) ...)

  Note that it is a bit harder to get uncertainty estimates on the
variance parameters in lme4.

>



From jaime.undurraga at med.kuleuven.be  Fri Feb 17 16:36:26 2012
From: jaime.undurraga at med.kuleuven.be (Jaime Undurraga)
Date: Fri, 17 Feb 2012 16:36:26 +0100
Subject: [R-sig-ME] lmer and aovlmer.fnc
Message-ID: <CAKD3jcTMJ3ZNOFu9okCD5nKkqxwOEtB6UAZD_afE3hYT-7BsJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120217/d7adee5f/attachment-0001.pl>

From longrob604 at gmail.com  Fri Feb 17 17:06:39 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 16:06:39 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <loom.20120217T161249-694@post.gmane.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>
	<loom.20120217T161249-694@post.gmane.org>
Message-ID: <4F3E7B0F.3040604@gmail.com>

Hi Ben

Thanks very much.

I have removed PUPIL as random effect (makes 100% sense to me - it's 
variance is fixed - I should have realised that myself earlier !).

glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS),data=dt,family=binomial(link = "logit"))

The output is:

Generalized linear mixed model fit by the Laplace approximation
Formula: LOSS ~ (1 | COMMUNE/SCHOOL/CLASS)
    Data: dt
    AIC   BIC logLik deviance
  10380 10408  -5186    10372
Random effects:
  Groups                 Name        Variance Std.Dev.
  CLASS:(SCHOOL:COMMUNE) (Intercept) 0.173259 0.41624
  SCHOOL:COMMUNE         (Intercept) 0.736581 0.85824
  COMMUNE                (Intercept) 0.024233 0.15567
Number of obs: 9162, groups: CLASS:(SCHOOL:COMMUNE), 310; 
SCHOOL:COMMUNE, 98; COMMUNE, 20

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   0.9874     0.1030    9.59   <2e-16 ***

The estimates look pretty close, but the standard errors for the REs are 
quite different - I seem to remember the sampling variance of REs has a 
skewed distribution, but I don't know if this has anything to do with it 
? Was this what you were getting at when you said "Note that it is a bit 
harder to get uncertainty estimates on the variance parameters in lme4" ?

BTW, MLwiN is using penalised quasi-likelihood (order=2).

I was very interested to back-test using your simulated R code - would I 
need to change it, bearing in mind that pupil isn't a random effect ? I 
did export the data into MLwiN but it gave zero estimates for all the 
random effects (and SEs) and a negative estimate for the fixed effect :(

Thanks again
RL


On 17/02/2012 3:15 PM, Ben Bolker wrote:
> W Robert Long<longrob604 at ...>  writes:
>
>>
>> Hi Federico
>>
>> Thank you very much.
>>
>> However, the model I'm trying to fit has no fixed effects. The MLwiN
>> output gives me:
>> beta_0_hat: 1.012(0.107)  conditional log odds
>> var_f0_hat: 0.031(0.066)  variance between communues
>> var_v0_hat: 0.760(0.141)  variance between schools within commune
>> var_u0_hat: 0.186(0.38)   variance between classes within schools
>>
>> This is what I am trying to duplicate in R with the same data.
>>
>> BTW I am using 64 bit R
>
>    OK, based on this output you shouldn't include 'pupil' in your
> random effects specification (now that I think of it, you probably
> shouldn't anyway, because it's unidentifiable for a Bernoulli outcome).
>
>    If you wanted you could redo my example with your observed effects
> (e.g. u.commune = rnorm(n.comm,sd=sqrt(0.031)) ...)
>
>    Note that it is a bit harder to get uncertainty estimates on the
> variance parameters in lme4.
>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Feb 17 17:37:42 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 17 Feb 2012 10:37:42 -0600
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <4F3E7B0F.3040604@gmail.com>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>
	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
Message-ID: <CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>

On Fri, Feb 17, 2012 at 10:06 AM, W Robert Long <longrob604 at gmail.com> wrote:
> Hi Ben
>
> Thanks very much.
>
> I have removed PUPIL as random effect (makes 100% sense to me - it's
> variance is fixed - I should have realised that myself earlier !).
>
> glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS),data=dt,family=binomial(link = "logit"))
>
> The output is:
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: LOSS ~ (1 | COMMUNE/SCHOOL/CLASS)
> ? Data: dt
> ? AIC ? BIC logLik deviance
> ?10380 10408 ?-5186 ? ?10372
> Random effects:
> ?Groups ? ? ? ? ? ? ? ? Name ? ? ? ?Variance Std.Dev.
> ?CLASS:(SCHOOL:COMMUNE) (Intercept) 0.173259 0.41624
> ?SCHOOL:COMMUNE ? ? ? ? (Intercept) 0.736581 0.85824
> ?COMMUNE ? ? ? ? ? ? ? ?(Intercept) 0.024233 0.15567
> Number of obs: 9162, groups: CLASS:(SCHOOL:COMMUNE), 310; SCHOOL:COMMUNE,
> 98; COMMUNE, 20
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? 0.9874 ? ? 0.1030 ? ?9.59 ? <2e-16 ***
>
> The estimates look pretty close, but the standard errors for the REs are
> quite different - I seem to remember the sampling variance of REs has a
> skewed distribution, but I don't know if this has anything to do with it ?

Those are not standard errors in the glmer output.  They are simply
the variance estimates on the standard deviation scale (i.e. 0.15567 =
sqrt(0.024233)).  The reason that glmer does not provide a standard
error for an estimate of a variance component is because they don't
make sense in most cases.  The distribution of the estimator is highly
skewed.

> Was this what you were getting at when you said "Note that it is a bit
> harder to get uncertainty estimates on the variance parameters in lme4" ?
>
> BTW, MLwiN is using penalised quasi-likelihood (order=2).
>
> I was very interested to back-test using your simulated R code - would I
> need to change it, bearing in mind that pupil isn't a random effect ? I did
> export the data into MLwiN but it gave zero estimates for all the random
> effects (and SEs) and a negative estimate for the fixed effect :(
>
> Thanks again
> RL
>
>
>
> On 17/02/2012 3:15 PM, Ben Bolker wrote:
>>
>> W Robert Long<longrob604 at ...> ?writes:
>>
>>>
>>> Hi Federico
>>>
>>> Thank you very much.
>>>
>>> However, the model I'm trying to fit has no fixed effects. The MLwiN
>>> output gives me:
>>> beta_0_hat: 1.012(0.107) ?conditional log odds
>>> var_f0_hat: 0.031(0.066) ?variance between communues
>>> var_v0_hat: 0.760(0.141) ?variance between schools within commune
>>> var_u0_hat: 0.186(0.38) ? variance between classes within schools
>>>
>>> This is what I am trying to duplicate in R with the same data.
>>>
>>> BTW I am using 64 bit R
>>
>>
>> ? OK, based on this output you shouldn't include 'pupil' in your
>> random effects specification (now that I think of it, you probably
>> shouldn't anyway, because it's unidentifiable for a Bernoulli outcome).
>>
>> ? If you wanted you could redo my example with your observed effects
>> (e.g. u.commune = rnorm(n.comm,sd=sqrt(0.031)) ...)
>>
>> ? Note that it is a bit harder to get uncertainty estimates on the
>> variance parameters in lme4.
>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From r.kozarski at gmail.com  Fri Feb 17 18:55:23 2012
From: r.kozarski at gmail.com (Robert Kozarski)
Date: Fri, 17 Feb 2012 17:55:23 +0000
Subject: [R-sig-ME] crossed random effect
Message-ID: <CAJBun_zut7kooCEuSGPs6TK7wAXcGgN-b4RQ=YnX6YmVFZRYJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120217/d2f3a4a5/attachment-0001.pl>

From longrob604 at gmail.com  Fri Feb 17 20:32:42 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 19:32:42 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>
	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
Message-ID: <4F3EAB5A.9040700@gmail.com>


On 17/02/2012 4:37 PM, Douglas Bates wrote:
<snip>
>> The estimates look pretty close, but the standard errors for the REs are
>> quite different - I seem to remember the sampling variance of REs has a
>> skewed distribution, but I don't know if this has anything to do with it ?
>
> Those are not standard errors in the glmer output.  They are simply
> the variance estimates on the standard deviation scale (i.e. 0.15567 =
> sqrt(0.024233)).  The reason that glmer does not provide a standard
> error for an estimate of a variance component is because they don't
> make sense in most cases.  The distribution of the estimator is highly
> skewed.
>
<snip>

Thank you for that. Could you provide a reference for this latter point 
? I have a copy of the Pinheiro and Bates (2000) book available in our 
library, if it's in there ? Otherwise, a published paper would be also 
be fine.



From HDoran at air.org  Fri Feb 17 20:55:17 2012
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Feb 2012 14:55:17 -0500
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <4F3EAB5A.9040700@gmail.com>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>

Raudenbush and Bryk do discuss this in their book if you require a text. But, it is quite easy to show. At one point, there was an example of how to do this using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice plots in that help page now. 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of W Robert Long
> Sent: Friday, February 17, 2012 2:33 PM
> To: r-sig-mixed-models at r-project.org; Douglas Bates
> Subject: Re: [R-sig-ME] LMER vs MLwiN
> 
> 
> On 17/02/2012 4:37 PM, Douglas Bates wrote:
> <snip>
> >> The estimates look pretty close, but the standard errors for the REs are
> >> quite different - I seem to remember the sampling variance of REs has a
> >> skewed distribution, but I don't know if this has anything to do with it ?
> >
> > Those are not standard errors in the glmer output.  They are simply
> > the variance estimates on the standard deviation scale (i.e. 0.15567 =
> > sqrt(0.024233)).  The reason that glmer does not provide a standard
> > error for an estimate of a variance component is because they don't
> > make sense in most cases.  The distribution of the estimator is highly
> > skewed.
> >
> <snip>
> 
> Thank you for that. Could you provide a reference for this latter point
> ? I have a copy of the Pinheiro and Bates (2000) book available in our
> library, if it's in there ? Otherwise, a published paper would be also
> be fine.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HDoran at air.org  Fri Feb 17 20:58:15 2012
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Feb 2012 14:58:15 -0500
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>

Sorry, meant to also add that you can try this as

> example(mcmcsamp)
> densityplot(samp0)
> qqmath(samp0)

I think you can then extend this your data to see if the distributional assumptions hold

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Doran, Harold
> Sent: Friday, February 17, 2012 2:55 PM
> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
> Subject: Re: [R-sig-ME] LMER vs MLwiN
> 
> Raudenbush and Bryk do discuss this in their book if you require a text. But,
> it is quite easy to show. At one point, there was an example of how to do this
> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
> plots in that help page now.
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> > bounces at r-project.org] On Behalf Of W Robert Long
> > Sent: Friday, February 17, 2012 2:33 PM
> > To: r-sig-mixed-models at r-project.org; Douglas Bates
> > Subject: Re: [R-sig-ME] LMER vs MLwiN
> >
> >
> > On 17/02/2012 4:37 PM, Douglas Bates wrote:
> > <snip>
> > >> The estimates look pretty close, but the standard errors for the REs are
> > >> quite different - I seem to remember the sampling variance of REs has a
> > >> skewed distribution, but I don't know if this has anything to do with it
> ?
> > >
> > > Those are not standard errors in the glmer output.  They are simply
> > > the variance estimates on the standard deviation scale (i.e. 0.15567 =
> > > sqrt(0.024233)).  The reason that glmer does not provide a standard
> > > error for an estimate of a variance component is because they don't
> > > make sense in most cases.  The distribution of the estimator is highly
> > > skewed.
> > >
> > <snip>
> >
> > Thank you for that. Could you provide a reference for this latter point
> > ? I have a copy of the Pinheiro and Bates (2000) book available in our
> > library, if it's in there ? Otherwise, a published paper would be also
> > be fine.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From longrob604 at gmail.com  Fri Feb 17 21:35:46 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 20:35:46 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
Message-ID: <4F3EBA22.90507@gmail.com>

Thanks, but sadly I don't have access to Raudenbush and Bryk book.
I need to write about this, so a reference would be appreciated, but I'm 
also interested to see/show it in my data.


On 17/02/2012 7:55 PM, Doran, Harold wrote:
> Raudenbush and Bryk do discuss this in their book if you require a text. But, it is quite easy to show. At one point, there was an example of how to do this using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice plots in that help page now.
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>> bounces at r-project.org] On Behalf Of W Robert Long
>> Sent: Friday, February 17, 2012 2:33 PM
>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>
>>
>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>> <snip>
>>>> The estimates look pretty close, but the standard errors for the REs are
>>>> quite different - I seem to remember the sampling variance of REs has a
>>>> skewed distribution, but I don't know if this has anything to do with it ?
>>>
>>> Those are not standard errors in the glmer output.  They are simply
>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>> error for an estimate of a variance component is because they don't
>>> make sense in most cases.  The distribution of the estimator is highly
>>> skewed.
>>>
>> <snip>
>>
>> Thank you for that. Could you provide a reference for this latter point
>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>> library, if it's in there ? Otherwise, a published paper would be also
>> be fine.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From longrob604 at gmail.com  Fri Feb 17 21:45:20 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 20:45:20 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>
Message-ID: <4F3EBC60.1090003@gmail.com>

Thank you. I tried mcmcsamp but I received the error "Update not yet 
written". A little searching revealed that mcmcsamp may not work with 
non-gaussian models ?

On 17/02/2012 7:58 PM, Doran, Harold wrote:
> Sorry, meant to also add that you can try this as
>
>> example(mcmcsamp)
>> densityplot(samp0)
>> qqmath(samp0)
>
> I think you can then extend this your data to see if the distributional assumptions hold
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>> bounces at r-project.org] On Behalf Of Doran, Harold
>> Sent: Friday, February 17, 2012 2:55 PM
>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>
>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>> it is quite easy to show. At one point, there was an example of how to do this
>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>> plots in that help page now.
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>> bounces at r-project.org] On Behalf Of W Robert Long
>>> Sent: Friday, February 17, 2012 2:33 PM
>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>
>>>
>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>> <snip>
>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>> skewed distribution, but I don't know if this has anything to do with it
>> ?
>>>>
>>>> Those are not standard errors in the glmer output.  They are simply
>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>> error for an estimate of a variance component is because they don't
>>>> make sense in most cases.  The distribution of the estimator is highly
>>>> skewed.
>>>>
>>> <snip>
>>>
>>> Thank you for that. Could you provide a reference for this latter point
>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>> library, if it's in there ? Otherwise, a published paper would be also
>>> be fine.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HDoran at air.org  Fri Feb 17 22:05:12 2012
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Feb 2012 16:05:12 -0500
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <4F3EBC60.1090003@gmail.com>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>,
	<4F3EBC60.1090003@gmail.com>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E063C614E20@DC1VEX07MB001.air.org>

It is straight forward to write your own resampling method for your fitted model. May be worth the effort for you
________________________________________
From: W Robert Long [longrob604 at gmail.com]
Sent: Friday, February 17, 2012 3:45 PM
To: Doran, Harold
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] LMER vs MLwiN

Thank you. I tried mcmcsamp but I received the error "Update not yet
written". A little searching revealed that mcmcsamp may not work with
non-gaussian models ?

On 17/02/2012 7:58 PM, Doran, Harold wrote:
> Sorry, meant to also add that you can try this as
>
>> example(mcmcsamp)
>> densityplot(samp0)
>> qqmath(samp0)
>
> I think you can then extend this your data to see if the distributional assumptions hold
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>> bounces at r-project.org] On Behalf Of Doran, Harold
>> Sent: Friday, February 17, 2012 2:55 PM
>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>
>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>> it is quite easy to show. At one point, there was an example of how to do this
>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>> plots in that help page now.
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>> bounces at r-project.org] On Behalf Of W Robert Long
>>> Sent: Friday, February 17, 2012 2:33 PM
>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>
>>>
>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>> <snip>
>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>> skewed distribution, but I don't know if this has anything to do with it
>> ?
>>>>
>>>> Those are not standard errors in the glmer output.  They are simply
>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>> error for an estimate of a variance component is because they don't
>>>> make sense in most cases.  The distribution of the estimator is highly
>>>> skewed.
>>>>
>>> <snip>
>>>
>>> Thank you for that. Could you provide a reference for this latter point
>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>> library, if it's in there ? Otherwise, a published paper would be also
>>> be fine.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From longrob604 at gmail.com  Fri Feb 17 22:11:35 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 21:11:35 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063C614E20@DC1VEX07MB001.air.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>,
	<4F3EBC60.1090003@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063C614E20@DC1VEX07MB001.air.org>
Message-ID: <4F3EC287.6010907@gmail.com>

Thanks. Can you point me to any resources that would explain how to do 
that ? On the one hand it's great to know that it's straightforward, and 
I'm keen to learn,  but on the other it is rather depressing as I 
haven't a clue how to do it ;)

On 17/02/2012 9:05 PM, Doran, Harold wrote:
> It is straight forward to write your own resampling method for your fitted model. May be worth the effort for you
> ________________________________________
> From: W Robert Long [longrob604 at gmail.com]
> Sent: Friday, February 17, 2012 3:45 PM
> To: Doran, Harold
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] LMER vs MLwiN
>
> Thank you. I tried mcmcsamp but I received the error "Update not yet
> written". A little searching revealed that mcmcsamp may not work with
> non-gaussian models ?
>
> On 17/02/2012 7:58 PM, Doran, Harold wrote:
>> Sorry, meant to also add that you can try this as
>>
>>> example(mcmcsamp)
>>> densityplot(samp0)
>>> qqmath(samp0)
>>
>> I think you can then extend this your data to see if the distributional assumptions hold
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>> bounces at r-project.org] On Behalf Of Doran, Harold
>>> Sent: Friday, February 17, 2012 2:55 PM
>>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>
>>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>>> it is quite easy to show. At one point, there was an example of how to do this
>>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>>> plots in that help page now.
>>>
>>>> -----Original Message-----
>>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>>> bounces at r-project.org] On Behalf Of W Robert Long
>>>> Sent: Friday, February 17, 2012 2:33 PM
>>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>>
>>>>
>>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>>> <snip>
>>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>>> skewed distribution, but I don't know if this has anything to do with it
>>> ?
>>>>>
>>>>> Those are not standard errors in the glmer output.  They are simply
>>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>>> error for an estimate of a variance component is because they don't
>>>>> make sense in most cases.  The distribution of the estimator is highly
>>>>> skewed.
>>>>>
>>>> <snip>
>>>>
>>>> Thank you for that. Could you provide a reference for this latter point
>>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>>> library, if it's in there ? Otherwise, a published paper would be also
>>>> be fine.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HDoran at air.org  Fri Feb 17 22:18:05 2012
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Feb 2012 16:18:05 -0500
Subject: [R-sig-ME] LMER vs MLwiN
Message-ID: <686DF18D10EF1C428C2760321FB5B69E063C757E49@DC1VEX07MB001.air.org>

I think you need to consult a local statistician who can help you at this point. This list really cannot do all the work for you. 

----- Original Message -----
From: W Robert Long <longrob604 at gmail.com>
To: Doran, Harold
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Sent: Fri Feb 17 16:11:35 2012
Subject: Re: [R-sig-ME] LMER vs MLwiN

Thanks. Can you point me to any resources that would explain how to do 
that ? On the one hand it's great to know that it's straightforward, and 
I'm keen to learn,  but on the other it is rather depressing as I 
haven't a clue how to do it ;)

On 17/02/2012 9:05 PM, Doran, Harold wrote:
> It is straight forward to write your own resampling method for your fitted model. May be worth the effort for you
> ________________________________________
> From: W Robert Long [longrob604 at gmail.com]
> Sent: Friday, February 17, 2012 3:45 PM
> To: Doran, Harold
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] LMER vs MLwiN
>
> Thank you. I tried mcmcsamp but I received the error "Update not yet
> written". A little searching revealed that mcmcsamp may not work with
> non-gaussian models ?
>
> On 17/02/2012 7:58 PM, Doran, Harold wrote:
>> Sorry, meant to also add that you can try this as
>>
>>> example(mcmcsamp)
>>> densityplot(samp0)
>>> qqmath(samp0)
>>
>> I think you can then extend this your data to see if the distributional assumptions hold
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>> bounces at r-project.org] On Behalf Of Doran, Harold
>>> Sent: Friday, February 17, 2012 2:55 PM
>>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>
>>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>>> it is quite easy to show. At one point, there was an example of how to do this
>>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>>> plots in that help page now.
>>>
>>>> -----Original Message-----
>>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>>> bounces at r-project.org] On Behalf Of W Robert Long
>>>> Sent: Friday, February 17, 2012 2:33 PM
>>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>>
>>>>
>>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>>> <snip>
>>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>>> skewed distribution, but I don't know if this has anything to do with it
>>> ?
>>>>>
>>>>> Those are not standard errors in the glmer output.  They are simply
>>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>>> error for an estimate of a variance component is because they don't
>>>>> make sense in most cases.  The distribution of the estimator is highly
>>>>> skewed.
>>>>>
>>>> <snip>
>>>>
>>>> Thank you for that. Could you provide a reference for this latter point
>>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>>> library, if it's in there ? Otherwise, a published paper would be also
>>>> be fine.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From longrob604 at gmail.com  Fri Feb 17 22:21:38 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 21:21:38 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063C757E49@DC1VEX07MB001.air.org>
References: <686DF18D10EF1C428C2760321FB5B69E063C757E49@DC1VEX07MB001.air.org>
Message-ID: <4F3EC4E2.7090506@gmail.com>

I wasn't aware that I had asked anyone to  "do all the work" for me ! !

I am a statistics graduate student but I do not know R very well, so, in 
case anyone can point me towards any resources that can help, I would be 
most humbly grateful.


On 17/02/2012 9:18 PM, Doran, Harold wrote:
> I think you need to consult a local statistician who can help you at this point. This list really cannot do all the work for you.
>
> ----- Original Message -----
> From: W Robert Long<longrob604 at gmail.com>
> To: Doran, Harold
> Cc: r-sig-mixed-models at r-project.org<r-sig-mixed-models at r-project.org>
> Sent: Fri Feb 17 16:11:35 2012
> Subject: Re: [R-sig-ME] LMER vs MLwiN
>
> Thanks. Can you point me to any resources that would explain how to do
> that ? On the one hand it's great to know that it's straightforward, and
> I'm keen to learn,  but on the other it is rather depressing as I
> haven't a clue how to do it ;)
>
> On 17/02/2012 9:05 PM, Doran, Harold wrote:
>> It is straight forward to write your own resampling method for your fitted model. May be worth the effort for you
>> ________________________________________
>> From: W Robert Long [longrob604 at gmail.com]
>> Sent: Friday, February 17, 2012 3:45 PM
>> To: Doran, Harold
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>
>> Thank you. I tried mcmcsamp but I received the error "Update not yet
>> written". A little searching revealed that mcmcsamp may not work with
>> non-gaussian models ?
>>
>> On 17/02/2012 7:58 PM, Doran, Harold wrote:
>>> Sorry, meant to also add that you can try this as
>>>
>>>> example(mcmcsamp)
>>>> densityplot(samp0)
>>>> qqmath(samp0)
>>>
>>> I think you can then extend this your data to see if the distributional assumptions hold
>>>
>>>> -----Original Message-----
>>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>>> bounces at r-project.org] On Behalf Of Doran, Harold
>>>> Sent: Friday, February 17, 2012 2:55 PM
>>>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>>
>>>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>>>> it is quite easy to show. At one point, there was an example of how to do this
>>>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>>>> plots in that help page now.
>>>>
>>>>> -----Original Message-----
>>>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>>>> bounces at r-project.org] On Behalf Of W Robert Long
>>>>> Sent: Friday, February 17, 2012 2:33 PM
>>>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>>>
>>>>>
>>>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>>>> <snip>
>>>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>>>> skewed distribution, but I don't know if this has anything to do with it
>>>> ?
>>>>>>
>>>>>> Those are not standard errors in the glmer output.  They are simply
>>>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>>>> error for an estimate of a variance component is because they don't
>>>>>> make sense in most cases.  The distribution of the estimator is highly
>>>>>> skewed.
>>>>>>
>>>>> <snip>
>>>>>
>>>>> Thank you for that. Could you provide a reference for this latter point
>>>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>>>> library, if it's in there ? Otherwise, a published paper would be also
>>>>> be fine.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From llopezt2000 at yahoo.com.mx  Sat Feb 18 18:13:04 2012
From: llopezt2000 at yahoo.com.mx (lopez toledo)
Date: Sat, 18 Feb 2012 09:13:04 -0800 (PST)
Subject: [R-sig-ME] Need some help with glmer output
Message-ID: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120218/78204928/attachment-0001.pl>

From jennifer.s.lyon at gmail.com  Sat Feb 18 18:44:48 2012
From: jennifer.s.lyon at gmail.com (Jennifer Lyon)
Date: Sat, 18 Feb 2012 10:44:48 -0700
Subject: [R-sig-ME] Moving from lme4a to lme4Eigen correlation of random
	effects goes to 1
Message-ID: <CAKstpn6LX8OB+zAdZisHnz3XTYiC6449MsMXCCQrejp9eFht5w@mail.gmail.com>

Hi:

I am modeling the score participants in three conditions achieved at
three times.  The times are not equally spaced, with the difference
between t2 and t3 over an order of magnitude longer than the
difference between t1 and t2. The design is not balanced. The variable
LMNo is unique per individual.

         time
condition t1 t2 t3
        A 76 75 72
        B 18 18 17
        C 28 27 26

I've attached a plot of the data.

The literature suggests that there are individual differences
at the different times, so I fitted the following model:

me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)

When moving from lme4a to lme4Eigen, the correlations of the random
effects all went to 1.000. I was slightly surprised by this change of
events. Is this result indicating that the simpler model:

me.c.m0<-lmer(score~ 1+time + condition + (1|LMNo), me.c, REML = 0)

is sufficient? I ask because when I do a likelihood ratio test
using anova, the p-value is small and AIC prefers the more complex
model while BIC prefers the simpler model. Does the correlation
going to one also indicate a preference for the simpler model?

#run in lme4Eigen
anova(me.c.m0, me.c.m)
Data: me.c
Models:
me.c.m0: score ~ 1 + time + condition + (1 | LMNo)
me.c.m: score ~ 1 + time + condition + (1 + time | LMNo)
        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
me.c.m0  7 2069.8 2096.9 -1027.9   2055.8
me.c.m  12 2055.3 2101.9 -1015.7   2031.3 24.445      5  0.0001782 ***

I don't know if this is related, but when I run profile() on
the models in lme4a and lme4Eigen, I get an error (which is
shown below). I have additional information on the participants,
such as gender and which participants are siblings, but before
I go for a more complex model, I'd like to better understand
what this model is telling me.

Thanks for any and all insights.

Jen

Here are the details of fitting the models in lme4a and lme4Eigen:

In lme4a_0.9996875-1

> library(lme4a)
> me.c<-read.table("mixed-effects-data-clean.txt", header=T)

> me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
> summary(me.c.m)
Linear mixed model fit by maximum likelihood ['summary.mer']
Formula: score ~ 1 + time + condition + (1 + time | LMNo)
   Data: me.c
      AIC       BIC    logLik  deviance
 2049.704  2096.236 -1012.852  2025.704

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 LMNo     (Intercept) 41.280   6.425
          timet2       6.007   2.451    0.452
          timet3       5.174   2.275    0.382 0.997
 Residual              4.314   2.077
Number of obs: 357, groups: LMNo, 122

Fixed effects:
            Estimate Std. Error t value
(Intercept)  27.8800     0.7727   36.08
timet2       -3.6805     0.3492  -10.54
timet3       -4.2801     0.3429  -12.48
conditionB   -1.9732     1.7585   -1.12
conditionC  -10.0301     1.4833   -6.76

Correlation of Fixed Effects:
           (Intr) timet2 timet3 cndtnB
timet2      0.086
timet3      0.039  0.687
conditionB -0.436  0.000  0.000
conditionC -0.517 -0.001  0.000  0.227

> profile(me.c.m)
Error in rbind2(fillmat(pres, lowcut, zeta, wp1), fillmat(nres, lowcut,  :
  error in evaluating the argument 'y' in selecting a method for
function 'rbind2': Error in while (i < nr && abs(mat[i, ".zeta"]) <=
cutoff && mat[i, cc] >  :
  missing value where TRUE/FALSE needed

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4a_0.9996875-1  MatrixModels_0.3-1 minqa_1.1.18       Rcpp_0.9.10
[5] Matrix_1.0-3       lattice_0.20-0

loaded via a namespace (and not attached):
[1] codetools_0.2-8  colorspace_1.1-1 grid_2.14.1      int64_1.1.2
[5] nlme_3.1-103     splines_2.14.1

> q()

R --vanilla
> library(lme4Eigen)

> me.c<-read.table("mixed-effects-data-clean.txt", header=T)

> me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
> summary(me.c.m)
Linear mixed model fit by maximum likelihood ['summary.mer']
Formula: score ~ 1 + time + condition + (1 + time | LMNo)
   Data: me.c

      AIC       BIC    logLik  deviance
 2055.339  2101.872 -1015.669  2031.339

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 LMNo     (Intercept) 39.351   6.273
          timet2       2.440   1.562    1.000
          timet3       1.730   1.315    1.000 1.000
 Residual              5.507   2.347
Number of obs: 357, groups: LMNo, 122

Fixed effects:
            Estimate Std. Error t value
(Intercept)  27.7704     0.7639   36.35
timet2       -3.6838     0.3348  -11.00
timet3       -4.2865     0.3305  -12.97
conditionB   -1.9870     1.7285   -1.15
conditionC   -9.5437     1.4583   -6.54

Correlation of Fixed Effects:
           (Intr) timet2 timet3 cndtnB
timet2      0.138
timet3      0.089  0.569
conditionB -0.433  0.001  0.000
conditionC -0.514 -0.002 -0.001  0.227

> profile(me.c.m)
Warning message:
In sqrt(ores$fval - base) : NaNs produced
Error in rbind2(fillmat(pres, lowcut, zeta, wp1), fillmat(nres, lowcut,  :
  error in evaluating the argument 'x' in selecting a method for
function 'rbind2': Error in while (i < nr && abs(mat[i, ".zeta"]) <=
cutoff && mat[i, cc] >  :
  missing value where TRUE/FALSE needed

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4Eigen_0.9996875-9 lattice_0.20-0

loaded via a namespace (and not attached):
[1] colorspace_1.1-1 grid_2.14.1      Matrix_1.0-3     minqa_1.1.18
[5] nlme_3.1-103     Rcpp_0.9.10      splines_2.14.1
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mixed-model-participant-score-by-condition.pdf
Type: application/pdf
Size: 6002 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120218/b788c8a3/attachment-0001.pdf>

From jwiley.psych at gmail.com  Sat Feb 18 22:56:01 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 18 Feb 2012 13:56:01 -0800
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CAO7JsnQVEiw9Y9SA6jNbhqejMxU87bWJL5MozfKzX++McOcyTA@mail.gmail.com>
References: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
	<CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
	<CAO7JsnQVEiw9Y9SA6jNbhqejMxU87bWJL5MozfKzX++McOcyTA@mail.gmail.com>
Message-ID: <CANz9Z_JirWeYz5EFkQUXY6gV9uHjktFQDfxs5eXNmS67cb64NQ@mail.gmail.com>

Apologies for the delay.  I had not saved the process to simulate the
data.  I created a new simulation and spent several days trying to get
it working on my laptop, without much success.  My first simulation
appears to have been something of a fluke in terms of speed.  The
present simulation used a data set of 200 groups with 5,000
replications each, 6 'observation level' predictors and 3 'group'
level predictors.  I backed down from 2 million to 1 million because
it still took over an hour to run and I was tired of waiting.
Curiously, lme4Eigen::glmer reports Inf and -Inf deviance and
loglikeihood values.  The parameter estimates from all three versions
are similar, though not exact.  With nAGQ = 0, the loglikelihood and
deviance between lme4Eigen and lme4 are similar.  Full code, timings,
and commented output form my runs are in the script, but the synopsis
is:

lme4::glmer
## > system.time(m1 <- glmer(dat$Y ~ dat$X + dat$W + (1 | dat$G),
family = "binomial"))
##    user  system elapsed
## 4158.10  117.19 4313.85

lme4Eigen::glmer
## > system.time(m1 <- glmer(dat$Y ~ dat$X + dat$W + (1 | dat$G),
family = "binomial"))
##    user  system elapsed
##  129.03    9.67  140.62
## infinite deviance, otherwise same ball park as the other two

lme4Eigen::glmer with nAGQ = 0
## > system.time(mfast <- glmer(dat$Y ~ dat$X + dat$W + (1 | dat$G),
family = "binomial", nAGQ = 0))
##    user  system elapsed
##  128.51    9.59  139.61


System characteristics:

R Under development (unstable) (2012-02-03 r58258)
Platform: x86_64-pc-mingw32/x64 (64-bit)
lme4Eigen_0.9996875-9
lme4_0.999375-42

Windows 7 x64; 6GB memory @ 1066MHZ; intel core i7 920 @ 2.66GHZ



On Thu, Feb 9, 2012 at 12:13 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>> Hi AC,
>>
>> My personal preference would be glmer from the lme4 package. ?I prefer
>> the Laplace approximation for the likelihood over the quasilikelihood
>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>> with 2 million observations nested within 200 groups (10,000
>> observations per group). ?I then ran an random intercepts model using:
>>
>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>>
>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>>
>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>> With the OS and R running, my system used ~ 6GB of RAM for the model
>> and went up to ~7GB to show the summary (copies of the data are
>> made---changed in the upcoming version of lme4).
>>
>> So as long as you have plenty of memory, you should have no trouble
>> modelling your data using glmer(). ?To initially make sure all your
>> code works, I might use a subset of your data (say 10k), once you are
>> convinced you have the model you want, run it on the full data.
>
> If you would have an opportunity to run that model fit or a comparable
> on lme4Eigen::glmer we would appreciate information about speed,
> accuracy and memory usage.
>
> In lme4Eigen::glmer there are different levels of precision in the
> approximation to the deviance being optimizer. ?These are controlled
> by the nAGQ argument to the function. ?The default, nAGQ=1, uses the
> Laplace approximation. ?The special value nAGQ=0 also uses the Laplace
> approximation but profiles out the fixed-effects parameters. ?This
> profiling is not exact but usually gets you close to the optimum that
> you would get from nAGQ=1, but much, much faster. ?In a model like
> this you can also use nAGQ>1 and <= 25. ?On the model fits we have
> tried we don't see a lot of difference in timing between, say, nAGQ=9
> and nAGQ=25 but on a model fit like this you might.
>
> As a fallback, we would appreciate the code that you used to simulate
> the response. ?We could generate something ourselves, of course, but
> it is easier to compare when you copy someone else's simulation.
>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>> Hi,
>>>
>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>> facilities) and would like to examine variability across facilities in
>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>> with patient and facility predictors of utilization.
>>>
>>> I have 3 questions:
>>>
>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>> big data (even if they are not R packages)?
>>>
>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>> data, etc) that would allow me to use only R packages to run this dataset
>>> (assuming I need to use another program due to the size of the dataset)?
>>>
>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>> wanting to examine? I know of two potential options (family=binomial option
>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>> appropriate or what other R packages and functions are available for this
>>> purpose?
>>>
>>> Thank you,
>>>
>>> AC
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group
>> University of California, Los Angeles
>> https://joshuawiley.com/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/

From bbolker at gmail.com  Sun Feb 19 17:02:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 19 Feb 2012 16:02:08 +0000 (UTC)
Subject: [R-sig-ME] LMER vs MLwiN
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
	<4F3EBA22.90507@gmail.com>
Message-ID: <loom.20120219T163118-782@post.gmane.org>


W Robert Long <longrob604 at ...> writes:

> 
> Thanks, but sadly I don't have access to Raudenbush and Bryk book.
> I need to write about this, so a reference would be appreciated, but I'm 
> also interested to see/show it in my data.

 I have posted a worked example at http://glmm.wikidot.com/examples ,
specifically

http://glmm.wikidot.com/
http://glmm.wikidot.com/local--files/examples/biglogist.pdf

  I was able to see some relevant bits of Raudenbush and Bryk by
going to Google books, finding the book, and searching for "skewed",
the 7th hit, on p 55, is worth looking at.

>  On 17/02/2012 7:55 PM, Doran, Harold wrote: > Raudenbush and Bryk
> do discuss this in their book if you require a text. But, it is
> quite easy to show. At one point, there was an example of how to do
> this using mcmcsamp() in the lme4 package (I think). But, I don't
> see the lattice plots in that help page now.  >

mcmcsamp doesn't work for GLMMs at present ..



From ricr2 at cantab.net  Sun Feb 19 23:08:59 2012
From: ricr2 at cantab.net (Rebecca Ross)
Date: Sun, 19 Feb 2012 22:08:59 +0000
Subject: [R-sig-ME] GLMER - p values proportion data
Message-ID: <CALKh-7qA3quARH_8m+NP_0M04vbgGpa12UyUyHZb21Zsw4-yxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/8b3f9c83/attachment-0001.pl>

From hans at sociologi.cjb.net  Mon Feb 20 01:38:49 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 20 Feb 2012 01:38:49 +0100
Subject: [R-sig-ME] Use of mixed models when the causal relations are
	unclear?
Message-ID: <20120220003849.GA10481@isas.ltsp>

When I was looking at official statistics for level of education, for
native vs migrant populations in different areas of a city I'm
currently studying, it struck me that I could use mixed models to back
up an initial observation I did. After conducting the analysis, I was
unsure whether or not this was a proper thing to do. Perhaps you can
give some judgement on this?

Here are some rows from two tables of official statistics that gave me the idea:

native.education (educational level, measured in years)
            Area  -8    9   11   12   14   15+  NA   SUM
1       Gunnared 461 1772 1721 1427  557   532 104  6574
2     L?rjedalen 443 1568 1755 1587  802   830  84  7069
...
15        Styrs? 242  449  648  536  437   686  23  3021


migrant.education
            Area   -8    9   11   12   14  15+   NA  SUM
1       Gunnared 1474 1627 2166 1723  988 1097  817 9892
2     L?rjedalen 1839 1667 1947 1668  945  918 1008 9992
...
15        Styrs?    7   17   27   16   25   47   13  152

In the area "Styrs?", being migrant was associated with having a higher
level of education than the natives in the area. The same applies to
the area "Gunnared", but for the area "L?rjedalen" the reverse seems
to hold. I used lmer in lme4 to test my hypothesis.

Based on the tables I created a data.frame which you can get here:

print(load(url("http://code.cjb.net/temp/dotplottest.RData")))
[1] "test.df"
> str(test.df)
'data.frame':	362319 obs. of  3 variables:
 $ area     : Factor w/ 21 levels "Gunnared","L?rjedalen",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ native   : Factor w/ 2 levels "yes","no": 1 1 1 1 1 1 1 1 1 1 ...
 $ education: Ord.factor w/ 6 levels "Folkskola"<"Grundskola"<..: 1 1 1 1 1 1 1 1 1 1 ...

(I translated the labels of the education factor into a rough estimate
in years in the tables above, since the labels are only meaningful for
speakers of the swedish language)

I fitted the following model on the data:

library(lme4)
my.fit <- lmer(education ~ 1 + (native | area), data = test.df)

and I got an nice graph:

dotplot(ranef(my.fit, postVar = T))

The question I have is this: if education is a factor in the selection
of which area into which a migrant will move, then education is not
dependent on the area, and the model is not "true".

While the causal relations in this case thus are unclear, or mixed, is
it still reasonable to use the mixed model as I did to get proper
confidence intervals, for the mere correlation/association between
area, nativeness and educational level?



From hans at sociologi.cjb.net  Mon Feb 20 02:01:09 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 20 Feb 2012 02:01:09 +0100
Subject: [R-sig-ME] Need some help with glmer output
In-Reply-To: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
Message-ID: <20120220010109.GB10481@isas.ltsp>

On Sat, Feb 18, 2012 at 09:13:04AM -0800, lopez toledo wrote:
> Dears lme4 users:
> I'm doing a repeated measurement analysis, which seems pretty obvious to 
> me, but I'm getting some strange results, which I do not 
> understand. Hope you can help me!! Thanks in advance!
> 
> I'm evaluating the effects of Defoliation Treatments (4 levels), Gender 
> (Male/Female) and Time on several responses (Growth , leaf production, 
> inflorescence production, etc) of a palm dioecious species 
> 
> I have about 550 palms total which have been measured 3 times. My main question is whether the effects depends on the intensity of defoliation, palm gender and how this has changed through time. I am 
> considering the effects of repeated measurement as Palm/Time
> I am exploring with the model below, which include as fixed factors DT*G*Time and as 
> random factor Palm/Time to consider the effect of repeated measurements. 
> 
> In this case, I'm using glmer, 'cos I've have counts as response variables (number of leaves, number of inflorescences, etc).
> 
> Model1<-glmer(Total leaves ~ DT * G * Time + (1 | palm/Time), family=poisson)
> 
> 
> I've got two questions:
> 1) Am 
> I considering the random effects correctly or not? as when I run the model there is the following message
> 
> 
> "Number of levels of a grouping factor for the random effects
> is *equal* to n, the number of observations"

Is it not enough to define one simple random effect for palm? Wouldn't
that take care of the problem of repeated measurements of the same
palm?

Try:

Model1<-glmer(Total leaves ~ DT * G * Time + (1 | palm), family=poisson)



From hans at sociologi.cjb.net  Mon Feb 20 02:07:52 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 20 Feb 2012 02:07:52 +0100
Subject: [R-sig-ME] Need some help with glmer output
In-Reply-To: <20120220010109.GB10481@isas.ltsp>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
	<20120220010109.GB10481@isas.ltsp>
Message-ID: <20120220010752.GC10481@isas.ltsp>

On Mon, Feb 20, 2012 at 02:01:09AM +0100, Hans Ekbrand wrote:
> On Sat, Feb 18, 2012 at 09:13:04AM -0800, lopez toledo wrote:
> > Dears lme4 users:
> > I'm doing a repeated measurement analysis, which seems pretty obvious to 
> > me, but I'm getting some strange results, which I do not 
> > understand. Hope you can help me!! Thanks in advance!
> > 
> > I'm evaluating the effects of Defoliation Treatments (4 levels), Gender 
> > (Male/Female) and Time on several responses (Growth , leaf production, 
> > inflorescence production, etc) of a palm dioecious species 
> > 
> > I have about 550 palms total which have been measured 3 times. My main question is whether the effects depends on the intensity of defoliation, palm gender and how this has changed through time. 

Rereading this paragraph, and in particular "and how this has changed
through time", I think you might want to specify Time as a random
variable too. However, I think it should be on its own, like this:

Model1<-glmer(Total leaves ~ DT * G + (1 | Time) + (1 | palm), family=poisson)

> Is it not enough to define one simple random effect for palm? Wouldn't
> that take care of the problem of repeated measurements of the same
> palm?
> 
> Try:
> 
> Model1<-glmer(Total leaves ~ DT * G * Time + (1 | palm), family=poisson)



From llopezt2000 at yahoo.com.mx  Mon Feb 20 05:16:37 2012
From: llopezt2000 at yahoo.com.mx (lopez toledo)
Date: Sun, 19 Feb 2012 20:16:37 -0800 (PST)
Subject: [R-sig-ME] More help with glmer!
In-Reply-To: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
Message-ID: <1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/12d81da6/attachment-0001.pl>

From jwiley.psych at gmail.com  Mon Feb 20 05:43:37 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 19 Feb 2012 20:43:37 -0800
Subject: [R-sig-ME] More help with glmer!
In-Reply-To: <1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
	<1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>
Message-ID: <A13E908F-C3BF-40E8-813B-62F8A94040C9@gmail.com>

Hi,

The lack of residual variance is not a function of glmer per se, rather the distribution you used.  The poisson distribution only has parameter---the expectation and dispersion.

The variance of the random subject effect is the variability in intercepts by subject.  In your case something like the variability in expected log count when treatment is 0 for different subjects.  It is very small.

glmer does use a maximum likelihood estimator and returns maximum likelihood estimates.  The Laplace approximation is a numerical way to calculate them (optimize the likelihood function).

You can set nAGQ to some number higher than 1 to increase the number of points evaluated and obtain slightly more accurate estimates at the cost of speed.

Cheers,

Josh

On Feb 19, 2012, at 20:16, lopez toledo <llopezt2000 at yahoo.com.mx> wrote:

> Hi all:Hope you understand I'm not an statistician and hope my question is not very basic. I did have a deep look to old posts but could not find an appropriate response. So, let me ask my question!
> I'm doing some lmer and glmer (poisson) models, but I noticed that for glmer there is not residual variance for the random effects. So, how do variance values should be interpreted in a glmer? What does the 6.8578 e-06 mean in the example below? I understand the "Subject" factor is explaining 6.8 e-06 of the variance, but what is the total or the residual variance? This number does not say many to me. 
> Additionally, is it possible to fit a glmer with maximum likelihood? or is Laplace approximation the only option?
> 
> Thanks for your help and comprehension ? 
> 
>> summary(glmer1)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: Response ~ Treatment + (1 | Subject) 
> ?? AIC? BIC logLik deviance
> ?788.8 1052 -345.4??? 690.8
> Random effects:
> ?Groups Name??????? Variance?? Std.Dev. 
> Subject ?? (Intercept) 6.8578e-06 0.0026187
> Number of obs: 1604, groups: NNo, 555
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From llopezt2000 at yahoo.com.mx  Mon Feb 20 06:23:54 2012
From: llopezt2000 at yahoo.com.mx (lopez toledo)
Date: Sun, 19 Feb 2012 21:23:54 -0800 (PST)
Subject: [R-sig-ME] More help with glmer!
In-Reply-To: <A13E908F-C3BF-40E8-813B-62F8A94040C9@gmail.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
	<1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>
	<A13E908F-C3BF-40E8-813B-62F8A94040C9@gmail.com>
Message-ID: <1329715434.77201.YahooMailNeo@web161204.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/138fe487/attachment-0001.pl>

From llopezt2000 at yahoo.com.mx  Mon Feb 20 06:47:29 2012
From: llopezt2000 at yahoo.com.mx (lopez toledo)
Date: Sun, 19 Feb 2012 21:47:29 -0800 (PST)
Subject: [R-sig-ME] Need some help with glmer output (Hans Ekbrand)
Message-ID: <1329716849.85927.YahooMailNeo@web161204.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/813accdf/attachment-0001.pl>

From jwiley.psych at gmail.com  Mon Feb 20 07:56:54 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 19 Feb 2012 22:56:54 -0800
Subject: [R-sig-ME] More help with glmer!
In-Reply-To: <1329715434.77201.YahooMailNeo@web161204.mail.bf1.yahoo.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
	<1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>
	<A13E908F-C3BF-40E8-813B-62F8A94040C9@gmail.com>
	<1329715434.77201.YahooMailNeo@web161204.mail.bf1.yahoo.com>
Message-ID: <4B0AB5BA-42B0-4DF6-991C-81C4B3004972@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/52798c77/attachment-0001.pl>

From hans at sociologi.cjb.net  Mon Feb 20 08:41:01 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 20 Feb 2012 08:41:01 +0100
Subject: [R-sig-ME] Need some help with glmer output (Hans Ekbrand)
In-Reply-To: <1329716849.85927.YahooMailNeo@web161204.mail.bf1.yahoo.com>
References: <1329716849.85927.YahooMailNeo@web161204.mail.bf1.yahoo.com>
Message-ID: <20120220074101.GA25224@isas.ltsp>

On Sun, Feb 19, 2012 at 09:47:29PM -0800, lopez toledo wrote:
> Thanks Hans for your two messages to my question on glmer yesterday. May I ask another question?

Sure, I was just thinking about my second suggestion, it required the
Time variable to have certain properties that you did not explictly
state it had.

> In your first reply you suggested to include only one single random effects (Palm) and Time as Fixed factor (1). I like that model as I can see the effects among years.? However in your second suggested model, Time as random effect does not indicate to me whether there is difference among years. There is some variance, but variance does not say nothing to me, specially if there is not a total/residual variance to compare with!

If you like the first model, then use it. The second version only makes sense
if there are idiosyncracies of the years, e.g. very little rain in
year 2010 or something like that.

If you're only interested in general differences in growth rate
between plants that are 1, 2, and 3 years old, then the first model is
what you want.

> 1) Model1<-glmer(Total leaves ~ DT * G * Time + (1 | palm), family=poisson)
> 2) Model1<-glmer(Total leaves ~ DT * G + (1 | Time) + (1 | palm), family=poisson)
> 
> Can you let me know your thought?
> 
> Leo



From h.colleran at ucl.ac.uk  Mon Feb 20 17:08:03 2012
From: h.colleran at ucl.ac.uk (Heidi Colleran)
Date: Mon, 20 Feb 2012 16:08:03 +0000
Subject: [R-sig-ME] overlapping multiple membership specification in lme4
Message-ID: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120220/ae7d5105/attachment-0001.pl>

From datkins at u.washington.edu  Mon Feb 20 21:29:07 2012
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 20 Feb 2012 12:29:07 -0800
Subject: [R-sig-ME] overlapping multiple membership specification in lme4
In-Reply-To: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>
References: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>
Message-ID: <4F42AD13.9030708@u.washington.edu>


Hi Heidi--

This issue has come up before on the listserv, and last year there were 
responses on how to fit multiple membership models in both lmer() and 
MCMCglmm() -- though, both involve some fiddling to work properly.  Take 
a look at the various postings in the following thread:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q2/006318.html

Hope that helps.

cheers, Dave

Dear List,

I'm a PhD student writing to ask for some help on specifying a model in R.
I'm currently using the lme4 package.

I'm trying to analyse how migration effects womens fertility rates in a
sample of 22 groups (villages). I have a sample of ~1500 women who were
born and continue to live in one of the 22 groups. I treat the model as
women clustered within groups. Each woman has an origin group ID and a
current group ID, so for women who never migrated these ID numbers will be
the same. I want to obtain variance parameters for the different groupings,
to see whether origin or current group has a greater effect on fertility
rates, with a view to then seeing if other group-level predictors explain
some of the variance, but I'm not sure if I have specified the model
correctly, or if I need to make some changes to the data (for example
weighting the memberships somehow).

I started with (what I think is) a cross-classified model of the form
(y~1+(1|originGroupID)+(1|currentGroupID)),
but given that the groups themselves are exactly the same thing, and that
membership in them overlaps, I am worried that this will cause problems for
estimating the group variances and covariances, or that this specification
perhaps doesn't make sense. Should the groups be coded differently?

If anyone could point me in the direction of some references specific to
this kind of overlapping structure, or indeed offer some advice as to
different ways I could specify the model, or recode the data somehow, I
would be extremely grateful.

Many thanks,

Heidi
--

	[[alternative HTML version deleted]]

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From bbolker at gmail.com  Tue Feb 21 03:42:50 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Feb 2012 02:42:50 +0000 (UTC)
Subject: [R-sig-ME] GLMER - p values proportion data
References: <CALKh-7qA3quARH_8m+NP_0M04vbgGpa12UyUyHZb21Zsw4-yxg@mail.gmail.com>
Message-ID: <loom.20120221T033813-997@post.gmane.org>

Rebecca Ross <ricr2 at ...> writes:

> 
> Dear All,
> 
> I would like to analyse proportion data (number of trials, number of
> successes) with one fixed effect (continuous) and one random effect
> (categorical). I believe (using Bolker TREE paper analysis) that I should
> be using a GLMER model. Can I trust the p-values produced by this, and if
> not, what should I be doing?
> 
> I have tried to follow up on various R mailing lists, but I am not 100%
> sure what the right answer is.
> 

  Using glmer (i.e. a GLMM) seems perfectly reasonable.  The p values
produced by summary() for a glmer model are (as is typical in the context
of generalized linear models) asymptotic Wald test statistics.  They
may be OK for large, well behaved data sets.  To get more reliable
likelihood ratio test statistics, either fit reduced models and use
anova(), or use drop1().  However, these are still asymptotic.
If you have a large number of random-effect blocks (>40 or so) these
should be very reliable.  If you have a smaller number and you really
want reliable p-values you will probably need to do some form of
resampling (parametric or non-parametric bootstrap, MCMC, etc.).



From i.m.s.white at ed.ac.uk  Tue Feb 21 11:34:41 2012
From: i.m.s.white at ed.ac.uk (i white)
Date: Tue, 21 Feb 2012 10:34:41 +0000
Subject: [R-sig-ME] overlapping multiple membership specification in lme4
In-Reply-To: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>
References: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>
Message-ID: <4F437341.1020805@ed.ac.uk>

Heidi,

I know nothing about multiple membership models but your problem reminds 
me of what plant breeders call a diallel cross design, in which (e.g. 
22) different lines of plants are crossed and the progeny measured. If 
we allow different line effects for male and female parents, this is a 
conventional two-way anova, but if we assume that the line effect is the 
same whether parent is male or female, we have something like your 
situation, in that the model is

y(ij) = const + (alpha)i + (alpha)j + ...

instead of

        const + (alpha)i + (beta)j + ...

for the cross of male parent from line i and female parent from line j. 
Analysis requires a special model matrix which is the sum (overlay) of 
the model matrices for male and female parents, with rows corresponding 
to between-line crosses consisting of two 1s and (in this case) 20 zeros.

Heidi Colleran wrote:
> Dear List,
> 
> I'm a PhD student writing to ask for some help on specifying a model in R.
> I'm currently using the lme4 package.
> 
> I'm trying to analyse how migration effects womens fertility rates in a
> sample of 22 groups (villages). I have a sample of ~1500 women who were
> born and continue to live in one of the 22 groups. I treat the model as
> women clustered within groups. Each woman has an origin group ID and a
> current group ID, so for women who never migrated these ID numbers will be
> the same. I want to obtain variance parameters for the different groupings,
> to see whether origin or current group has a greater effect on fertility
> rates, with a view to then seeing if other group-level predictors explain
> some of the variance, but I'm not sure if I have specified the model
> correctly, or if I need to make some changes to the data (for example
> weighting the memberships somehow).
> 
> I started with (what I think is) a cross-classified model of the form
> (y~1+(1|originGroupID)+(1|currentGroupID)),
> but given that the groups themselves are exactly the same thing, and that
> membership in them overlaps, I am worried that this will cause problems for
> estimating the group variances and covariances, or that this specification
> perhaps doesn't make sense. Should the groups be coded differently?
> 
> If anyone could point me in the direction of some references specific to
> this kind of overlapping structure, or indeed offer some advice as to
> different ways I could specify the model, or recode the data somehow, I
> would be extremely grateful.
> 
> Many thanks,
> 
> Heidi
> --
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Kevin_J_Ryan at umit.maine.edu  Tue Feb 21 17:21:55 2012
From: Kevin_J_Ryan at umit.maine.edu (Kevin J. Ryan)
Date: Tue, 21 Feb 2012 11:21:55 -0500
Subject: [R-sig-ME] Incorporating a Temporal Correlation Structure in a GLM
Message-ID: <fc.004c4d194d3477bb004c4d194d3477bb.4d3492fa@umit.maine.edu>

Hello,

I'm attempting to use mixed-model logistic regression to model spadefoot emergence as a function of weather variables (individuals are monitored continuously from 1-84 days [with gaps]).  However, the weather variables are serially autocorrelated,
apparently at a lag of 12 days or so.  Does anyone have experience incorporating a temporal autocorrelation structure of predictor variables into a glm?  I've been examining the lme4 package but it does not appear to be able to do this.  

Any advice is greatly appreciated.

 - Kevin

Kevin J. Ryan
PhD Candidate
Wildlife Ecology Department
University of Maine
5755 Nutting Hall, Room 220
Orono, ME 04469
cell: (914) 907-7896



From bbolker at gmail.com  Wed Feb 22 02:07:45 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Feb 2012 01:07:45 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Moving_from_lme4a_to_lme4Eigen_correlation_o?=
	=?utf-8?q?f_random=09effects_goes_to_1?=
References: <CAKstpn6LX8OB+zAdZisHnz3XTYiC6449MsMXCCQrejp9eFht5w@mail.gmail.com>
Message-ID: <loom.20120222T004353-501@post.gmane.org>

Jennifer Lyon <jennifer.s.lyon at ...> writes:

> I am modeling the score participants in three conditions achieved at
> three times.  The times are not equally spaced, with the difference
> between t2 and t3 over an order of magnitude longer than the
> difference between t1 and t2. The design is not balanced. The variable
> LMNo is unique per individual.
> 
>          time
> condition t1 t2 t3
>         A 76 75 72
>         B 18 18 17
>         C 28 27 26

> I've attached a plot of the data.

  (didn't come through -- the mailing list discards a lot
of file types)

> The literature suggests that there are individual differences
> at the different times, so I fitted the following model:
> 
> me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
> 
 When moving from lme4a to lme4Eigen, the correlations of the random
 effects all went to 1.000. I was slightly surprised by this change of
 events. Is this result indicating that the simpler model:
 
 me.c.m0<-lmer(score~ 1+time + condition + (1|LMNo), me.c, REML = 0)
 
 is sufficient? 

   It typically would.  It does mean you're somewhere on the
edge of overfitting ...
   If time were used as a continuous predictor (i.e. linear regression),
it might make sense to try to fit the model with (1|LMNo)+(0+time|LMNo),
but I suspect it *doesn't* make sense when time is a factor.

 I ask because when I do a likelihood ratio test
 using anova, the p-value is small and AIC prefers the more complex
 model while BIC prefers the simpler model. Does the correlation
 going to one also indicate a preference for the simpler model?
 
 #run in lme4Eigen
 anova(me.c.m0, me.c.m)
 Data: me.c
 Models:
 me.c.m0: score ~ 1 + time + condition + (1 | LMNo)
 me.c.m: score ~ 1 + time + condition + (1 + time | LMNo)
         Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(Chisq)
 me.c.m0  7 2069.8 2096.9 -1027.9   2055.8
 me.c.m  12 2055.3 2101.9 -1015.7   2031.3 24.445      5  0.0001782 ***

  On the other hand, this seems to say pretty definitively that
the variation in time effects across individuals is doing something ...

 I don't know if this is related, but when I run profile() on
 the models in lme4a and lme4Eigen, I get an error (which is
 shown below). I have additional information on the participants,
 such as gender and which participants are siblings, but before
 I go for a more complex model, I'd like to better understand
 what this model is telling me.

  Very wise.


> Here are the details of fitting the models in lme4a and lme4Eigen:
> 
> In lme4a_0.9996875-1
> 
> > library(lme4a)
> > me.c<-read.table("mixed-effects-data-clean.txt", header=T)
> 
> > me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
> > summary(me.c.m)

 [snip]

>    Data: me.c
>       AIC       BIC    logLik  deviance
>  2049.704  2096.236 -1012.852  2025.704
> 
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  LMNo     (Intercept) 41.280   6.425
>           timet2       6.007   2.451    0.452
>           timet3       5.174   2.275    0.382 0.997
>  Residual              4.314   2.077
> Number of obs: 357, groups: LMNo, 122
> 
> Fixed effects:

 [snip]
 
> > profile(me.c.m)
> Error in rbind2(fillmat(pres, lowcut, zeta, wp1), fillmat(nres, lowcut,  :
>   error in evaluating the argument 'y' in selecting a method for
> function 'rbind2': Error in while (i < nr && abs(mat[i, ".zeta"]) <=
> cutoff && mat[i, cc] >  :
>   missing value where TRUE/FALSE needed

  Hmmm.  Are you willing to send data?

  As cross-checks on lme4a and lme4Eigen, you might try
the packages
* glmmADMB (recent versions can handle Gaussian responses,
although it's not well tested)
* regress
* lmm
* sabreR

  although all (except glmmADMB) have fairly different
interfaces, unfortunately. 

> 

 [snip]
 
 > me.c<-read.table("mixed-effects-data-clean.txt", header=T)
 
 > me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
 > summary(me.c.m)
 Linear mixed model fit by maximum likelihood ['summary.mer']
 Formula: score ~ 1 + time + condition + (1 + time | LMNo)
    Data: me.c
 
       AIC       BIC    logLik  deviance
  2055.339  2101.872 -1015.669  2031.339
 
 Random effects:
  Groups   Name        Variance Std.Dev. Corr
  LMNo     (Intercept) 39.351   6.273
           timet2       2.440   1.562    1.000
           timet3       1.730   1.315    1.000 1.000
  Residual              5.507   2.347
 Number of obs: 357, groups: LMNo, 122
 
 Fixed effects:

 [snip]
 
 > profile(me.c.m)
 Warning message:
 In sqrt(ores$fval - base) : NaNs produced
 Error in rbind2(fillmat(pres, lowcut, zeta, wp1), fillmat(nres, lowcut,  :
   error in evaluating the argument 'x' in selecting a method for
 function 'rbind2': Error in while (i < nr && abs(mat[i, ".zeta"]) <=
 cutoff && mat[i, cc] >  :
   missing value where TRUE/FALSE needed
 

[snip]



From bbolker at gmail.com  Wed Feb 22 02:15:49 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Feb 2012 01:15:49 +0000 (UTC)
Subject: [R-sig-ME] Incorporating a Temporal Correlation Structure in a
	GLM
References: <fc.004c4d194d3477bb004c4d194d3477bb.4d3492fa@umit.maine.edu>
Message-ID: <loom.20120222T020754-835@post.gmane.org>

Kevin J. Ryan <Kevin_J_Ryan at ...> writes:


> I'm attempting to use mixed-model logistic regression to model
> spadefoot emergence as a function of weather variables (individuals
> are monitored continuously from 1-84 days [with gaps]).  However,
> the weather variables are serially autocorrelated, apparently at a
> lag of 12 days or so.  Does anyone have experience incorporating a
> temporal autocorrelation structure of predictor variables into a
> glm?  I've been examining the lme4 package but it does not appear to
> be able to do this.

  A couple of quick thoughts:

* you could use glmmPQL (in the MASS package), which does allow any
of the correlation structures that are defined in the nlme
package (including corCAR1, which allows for gappy data). This
is not preferred for binary data, but probably (?) correcting
for correlation and using a slightly questionable estimation method
is better than ignoring correlation.

* if your responses are measured without error you might
be able to use emergences at a previous time point as
a predictor.

* you could just use glm (or whatever) and evaluate the correlations
among the residuals -- if there's nothing going on there then you
have a reasonable excuse for proceeding without a correlation model.

* the fact that the _predictor_ variables are autocorrelated isn't
that much of a big deal -- it's really the response (or rather the
residuals of the response) that you should be worried about, although
there is always a bit of an issue in time-series analysis in
looking at relationships of autocorrelated series with other
autocorrelated series ...

* generalized estimating equations (GEE: see geepack etc.) are
another approach, although I don't know if any of the R packages
that do GEEs have an option for autocorrelations on unevenly
spaced data (try installing the "sos" package and searching
via something like findFn("gee uneven"))

* in my opinion the gold standard (if the data are rich enough
to warrant it) is to build a hierarchical model with a latent
normally distributed variable with temporal autocorrelation and
an observed binary variable (emergence) on top of it, but this
is fairly hard work -- you'd need AD Model Builder or some
dialect of BUGS.

 I will be interested to see if anyone has better suggestions.

 I would check the books from Highland Statistics (Zuur et al.)
to see if they have anything useful ...



From arives at wisc.edu  Wed Feb 22 12:35:00 2012
From: arives at wisc.edu (Anthony R Ives)
Date: Wed, 22 Feb 2012 05:35:00 -0600
Subject: [R-sig-ME] Incorporating a Temporal Correlation Structure in
	a	GLM
In-Reply-To: <loom.20120222T020754-835@post.gmane.org>
References: <fc.004c4d194d3477bb004c4d194d3477bb.4d3492fa@umit.maine.edu>
	<loom.20120222T020754-835@post.gmane.org>
Message-ID: <155F553A-8E23-470A-A182-90D61105BD88@wisc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120222/fa041c76/attachment-0001.pl>

From highstat at highstat.com  Wed Feb 22 20:26:20 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 22 Feb 2012 21:26:20 +0200
Subject: [R-sig-ME] Incorporating a Temporal Correlation Structure,
	in a	GLM
In-Reply-To: <mailman.5.1329908402.15027.r-sig-mixed-models@r-project.org>
References: <mailman.5.1329908402.15027.r-sig-mixed-models@r-project.org>
Message-ID: <4F45415C.70301@highstat.com>


* you could just use glm (or whatever) and evaluate the correlations
among the residuals -- if there's nothing going on there then you
have a reasonable excuse for proceeding without a correlation model.

* the fact that the _predictor_ variables are autocorrelated isn't
that much of a big deal -- it's really the response (or rather the
residuals of the response) that you should be worried about, although
there is always a bit of an issue in time-series analysis in
looking at relationships of autocorrelated series with other
autocorrelated series ...

* generalized estimating equations (GEE: see geepack etc.) are
another approach, although I don't know if any of the R packages
that do GEEs have an option for autocorrelations on unevenly
spaced data (try installing the "sos" package and searching
via something like findFn("gee uneven"))

* in my opinion the gold standard (if the data are rich enough
to warrant it) is to build a hierarchical model with a latent
normally distributed variable with temporal autocorrelation and
an observed binary variable (emergence) on top of it, but this
is fairly hard work -- you'd need AD Model Builder or some
dialect of BUGS.

  I will be interested to see if anyone has better suggestions.



Kevin,

Ben..thanks for the advertisement..:-))

The last chapter in our 2009 book shows how a Poisson GLM can be 
extended with an AR1 correlation structure on the residuals. We took 
this further in our upcoming book "Zero inflated models and GLMM with 
R", which comes out in 2 weeks. We extend GLM models with spatial or 
temporal correlations by using CAR structures on the residuals. We have 
done it in a Poisson/NB GLM/GAM context...but also in a binomial context 
(which means that you can then also do it for a ZIP). These are models 
of the form:

Y_i ~ Poisson(mu_i)

log(mu_i) = alpha + beta * X_i + epsilon_i

where the epsilon_i are spatially correlated following a CAR. And you 
can also use this for time series. Some recent papers used CAR on the 
random effects.

The bad news is that this is indeed MCMC...and we used WinBUGS (the book 
actually starts with a beginner's intro to MCMC and WinBUGS). I am 
tempted to write an ADMB supplement as it seems to be much faster in 
fitting these models.  The ADMB guys were kind enough to provide code to 
fit some of the models used in the book.


In our experience adding a correlation to a GLM works fine as long as it 
represents small-scale correlation. As soon as you allow it to capture 
large scale correlation then it may start to fight with the covariates. 
And then you get very poor mixing of chains. So..it is a bit of an art. 
I think it also depends on what type of correlation you are trying to 
model...does the spatial (or temporal) correlation represent a missing 
covariate...it is small scale variation...or is it 'real' dependency 
(pseudo replication).

A paper from VerHoef and Janssen was quite inspiring.

Anyway...enough advertisement...

Kind regards,

Alain


>   I would check the books from Highland Statistics (Zuur et al.)
> to see if they have anything useful ...
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 62, Issue 43
> **************************************************
>


-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From David.Duffy at qimr.edu.au  Wed Feb 22 21:57:16 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 23 Feb 2012 06:57:16 +1000
Subject: [R-sig-ME] Use of mixed models when the causal relations
	areunclear?
Message-ID: <6F35A958A12B9149BD16E3C2F3B0AD0DB37866@SPHINX.adqimr.ad.lan>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/ae4f7ae8/attachment-0001.pl>

From amelie.pinet at gmail.com  Thu Feb 23 15:02:14 2012
From: amelie.pinet at gmail.com (amelie pinet)
Date: Thu, 23 Feb 2012 15:02:14 +0100
Subject: [R-sig-ME] Assumptions on within group errors in lme model
Message-ID: <CAKNZCKE5iOCddgBZQ0xhxP02yFGNZzODOag-ShpDXtqdWS6-Kw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/fff4bebf/attachment-0001.pl>

From Walter.Leite at coe.ufl.edu  Thu Feb 23 17:29:36 2012
From: Walter.Leite at coe.ufl.edu (Leite,Walter)
Date: Thu, 23 Feb 2012 16:29:36 +0000
Subject: [R-sig-ME] Problematic correlations between random effects
Message-ID: <FF9DF1CEDEBA874E96DB251402D6B416144B942E@UFEXCH-MBXN04.ad.ufl.edu>

Folks,

I fitted a model with several random affects to data with a cross-classification of students and schools using lmer. Two random effects have correlation of -1 and others near 1, as shown below. I thought that this would only occur if any random effects were not necessary in the model, but I built this model adding the random effects one at a time and comparing the fit with BIC and AIC. Also, none of the variances are very small. Could someone advise me on why these correlations occurred and ways I can solve this problem?

Thank you,

Walter

Random effects:
 Groups    Name             Variance  Std.Dev. Corr                 
 CHILDID   (Intercept)      333.63787 18.26576                      
           time.period        7.99838  2.82814 -1.000               
           I(time.period^2)  11.16830  3.34190 -0.514  0.514        
           I(time.period^3)   0.31869  0.56453 -0.189  0.189  0.938 
 School_ID (Intercept)       87.59255  9.35909                      
           time.period       33.30370  5.77094  0.093               
           I(time.period^2)   1.48008  1.21659 -0.171  0.960        
 Residual                    39.94649  6.32032                      
Number of obs: 11960, groups: CHILDID, 2990; School_ID, 996



From stat.list at yahoo.co.uk  Thu Feb 23 18:43:08 2012
From: stat.list at yahoo.co.uk (Rachel Cohen)
Date: Thu, 23 Feb 2012 17:43:08 +0000 (GMT)
Subject: [R-sig-ME] lme4a and Profile
Message-ID: <1330018988.69754.YahooMailNeo@web132205.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/29d19d57/attachment-0001.pl>

From agostino.moro99 at gmail.com  Thu Feb 23 18:53:14 2012
From: agostino.moro99 at gmail.com (Agostino Moro)
Date: Thu, 23 Feb 2012 17:53:14 +0000
Subject: [R-sig-ME] nlme Fixed Variance Function
Message-ID: <CAMS_pxsh41A=2WdfVU3267+iKZWP8xgDFuS4y1zaG9B6jo6cYg@mail.gmail.com>

Dear R users,

I am trying to fit a gls model and weight my data points using a
VarFixed structure. I have found many examples, but I do not
understand the difference between the following models with varFixed
specified in a different way:

mod<-gls(y~x,weights=varFixed(~1/invsigma)

mod<-gls(y~x,weights=varFixed(~invsigma)

In my case I would simply like to weigh my data points by their
inverse variance.

Any help would be greatly appreciated!

Cheers,

Agostino



From dadrivr at gmail.com  Thu Feb 23 20:46:39 2012
From: dadrivr at gmail.com (Isaac Petersen)
Date: Thu, 23 Feb 2012 14:46:39 -0500
Subject: [R-sig-ME] Calculating Pseudo R-squared from nlme
Message-ID: <CAPBn5Xtc-hf_Z+8ZXNPH4sLTXs2rWnwOtBR3v3FWq9cP553hSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/0d5ce7d1/attachment-0001.pl>

From bbolker at gmail.com  Thu Feb 23 22:12:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Feb 2012 21:12:22 +0000 (UTC)
Subject: [R-sig-ME] lme4a and Profile
References: <1330018988.69754.YahooMailNeo@web132205.mail.ird.yahoo.com>
Message-ID: <loom.20120223T220515-437@post.gmane.org>

Rachel Cohen <stat.list at ...> writes:

> Hi, I would like to try using the profile() function etc.
> to look at confidence intervals on mixed model
> parameters (as detailed in Douglas Bate's online book).? 
> Working through the book's example I get the
> following error message:

> Error in UseMethod("profile") : 
> ? no applicable method for 'profile' applied to an object of class "mer"

>  I believe I have to install lme4a in order to use these 
> new functions.? I can't seem to find any mention of
> this new version of lme4 on R-forge.
>  Does anyone know where I can obtain lme4a and if it's ready/reliable
> for use?

(1)  If you have the appropriate tools for building packages installed
you should be able to just

install.packages("lme4a",repos="http://r-forge.r-project.org",type="source")

(2) Otherwise, I would normally tell you to
see http://lme4.r-forge.r-project.org , but ... the binary versions
of lme4a there are somewhat out of date, so they won't be automatically
installed in R 2.14.  You can try poking around at 
http://lme4.r-forge.r-project.org/repos/bin/ , downloading versions for 
slightly older versions of R and installing the binaries locally --
it *might* work.

(3) lme4a is relatively stable, lme4Eigen (the new, new, new
development version) is getting so -- it should run all the
profiling examples in the book, although Doug Bates is working
on updating a few small details in the book to make them work
with lme4Eigen.  You could try lme4Eigen ...

(4) if all else fails, ask again here for lme4a binaries to be
provided (I'd slightly rather spend my effort providing binaries
for lme4Eigen, but would be willing to make some new lme4a binaries
in the interim).



From bbolker at gmail.com  Thu Feb 23 22:24:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Feb 2012 21:24:34 +0000 (UTC)
Subject: [R-sig-ME] nlme Fixed Variance Function
References: <CAMS_pxsh41A=2WdfVU3267+iKZWP8xgDFuS4y1zaG9B6jo6cYg@mail.gmail.com>
Message-ID: <loom.20120223T221850-645@post.gmane.org>

Agostino Moro <agostino.moro99 at ...> writes:

> 
> Dear R users,
> 
> I am trying to fit a gls model and weight my data points using a
> VarFixed structure. I have found many examples, but I do not
> understand the difference between the following models with varFixed
> specified in a different way:
> 
> mod<-gls(y~x,weights=varFixed(~1/invsigma)
> 
> mod<-gls(y~x,weights=varFixed(~invsigma)
> 
> In my case I would simply like to weigh my data points by their
> inverse variance.
> 

  It would be interesting to have links to examples that show
these two usages.  One of them must be wrong, or at least weird.
Have you looked at ?varFixed?  It says:

 Letting v denote the variance covariate defined in ?value?, the variance
     function s2(v) for this class is s2(v)=|v|. 

Thus if you know the variance _a priori_ is 'yvar' I think you want
weights=varFixed(~yvar) .  This will set the variance to yvar and
hence weight by 1/yvar.  (I'm using "yvar" rather than "sigma" or
"invsigma" because it's easy to get confused about whether "sigma"
represents variance or standard deviation ...)

  I would strongly recommend using the 'data' argument: have x, y, 
and yvar as columns in a data frame d and use

mod <- gls(y~x,weights=varFixed(~yvar),data=d)

  Taking a look at Pinheiro and Bates 2000 would be a good idea.
If you're too cheap or in too much of a hurry to buy it, you can
search for "varFixed" within the book on Google books (see p. 209)
for a slightly more extended discussion of the admittedly terse
example in ?varFixed ...



From karla.letto at gmail.com  Thu Feb 23 23:33:10 2012
From: karla.letto at gmail.com (Karla Letto)
Date: Thu, 23 Feb 2012 19:03:10 -0330
Subject: [R-sig-ME] fitting a distribution to zero-inflated catch per unit
	effort mixed model
Message-ID: <CABMU9jxFFYtyHX5reHkrdgvv+3zLz9Ddm3CxhnvYcaSotuq8mA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/0e7a918a/attachment-0001.pl>

From David.Duffy at qimr.edu.au  Thu Feb 23 23:42:11 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 24 Feb 2012 08:42:11 +1000 (EST)
Subject: [R-sig-ME] Problematic correlations between random effects
In-Reply-To: <FF9DF1CEDEBA874E96DB251402D6B416144B942E@UFEXCH-MBXN04.ad.ufl.edu>
References: <FF9DF1CEDEBA874E96DB251402D6B416144B942E@UFEXCH-MBXN04.ad.ufl.edu>
Message-ID: <Pine.LNX.4.64.1202240838220.11505@orpheus.qimr.edu.au>

On Thu, 23 Feb 2012, Leite,Walter wrote:

> Folks,
>
> I fitted a model with several random effects to data with a 
> cross-classification of students and schools using lmer. Two random 
> effects have correlation of -1 and others near 1, as shown below. I 
> thought that this would only occur if any random effects were not 
> necessary in the model, but I built this model adding the random effects 
> one at a time and comparing the fit with BIC and AIC. Also, none of the 
> variances are very small. Could someone advise me on why these 
> correlations occurred and ways I can solve this problem?
>
> Random effects:
> Groups    Name             Variance  Std.Dev. Corr
> CHILDID   (Intercept)      333.63787 18.26576
>           time.period        7.99838  2.82814 -1.000
>           I(time.period^2)  11.16830  3.34190 -0.514  0.514
>           I(time.period^3)   0.31869  0.56453 -0.189  0.189  0.938
> School_ID (Intercept)       87.59255  9.35909
>           time.period       33.30370  5.77094  0.093
>           I(time.period^2)   1.48008  1.21659 -0.171  0.960
> Residual                    39.94649  6.32032
> Number of obs: 11960, groups: CHILDID, 2990; School_ID, 996

Have you centred time.period?  My simple minded understanding is that 
polynomial terms like that will always be highly correlated unless you 
orthogonalize them, but the LR based criteria will still guide you 
correctly.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Fri Feb 24 00:10:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Feb 2012 23:10:21 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?fitting_a_distribution_to_zero-inflated_catc?=
	=?utf-8?q?h_per_unit=09effort_mixed_model?=
References: <CABMU9jxFFYtyHX5reHkrdgvv+3zLz9Ddm3CxhnvYcaSotuq8mA@mail.gmail.com>
Message-ID: <loom.20120224T000238-482@post.gmane.org>

Karla Letto <karla.letto at ...> writes:

> I am having trouble fitting a distribution to my mixed model for meadow
> vole catch per unit effort (CPUE) data. I have tried several families and
> cannot find one that does not violate both the homogeneity and normality
> assumptions. NOTE: The data set is zero-inflated (no captures).
> Here is my study design:
> 
> I am trying to determine if the CPUE of meadow voles differ among lines
> (line = near,mid, or far) at increasing distances from a linear feature
> (type = road, trail or powerline corridor) in two different habitat types
> (habitat=forest or barren).
> Response variable: catch per unit effort (non-integer values)
> Fixed explanatory variables: line (3 categories), habitat (2 categories),
> type (3 categories)
> Random explanatory variable: site (8 categories), cycle (2 categories)


> The random variable site is for the 8 different sites I sampled in (4
> barren and 4 forest) and the cycle is there because I visited each site
> twice.

  Practically speaking you probably can't use cycle as a random
effect; you can include cycle as a fixed effect (specifying the
difference between first & second visits), and possibly
nesting it within site as a random effect (if you have more than
one observation per site/sample combination).

  What is the total size (number of observations) in your data set?

> Here is an excerpt of my data set:
>    CE2  catch effort site line   cycle habitat      type
> 0.000000     0   57.5    A near  first   forest     trail
> 3.278689     2   61.0    A   mid   first   forest     trail
> 0.000000     0   60.5    A   far   first   forest     trail
> 0.000000     0   66.5    G near  first   barren       road
> 0.000000     0   74.5    G   mid   first   barren       road
> 0.000000     0   74.0    G   far   first   barren       road
> 1.449275     1   69.0    E near second  barren powerline
> 0.000000     0   73.0    E   mid second  barren powerline
> 0.000000     0   71.5    E   far second  barren powerline
> 
> I tried the lme4 package using the following syntax:
> 
 [snip]
> 
> I then tried using a poisson error structure using catch (the actual number
> of animals) as the response and incorporated effort as an offset. Effort as
> an offset is commonly used for analysis of CPUE data.
> 
> Model2<-
> glmer(catch~line+habitat+type+(1|site)+(1|cycle)+
>  offset(effort),family=poisson)

  This is a good way to do it, but you need to incorporate the
LOG of effort.  You may also need to account for overdispersion
and/or zero-inflation; the former via incorporating an observation-level
random effect (in glmer, glmmadmb, or MCMCglmm) or negative binomial
distribution (in glmmadmb), the latter (if necessary) via zero-inflation
or hurdle models (in glmmadmb or MCMCglmm).

 [snip snip snip]

> Does anyone have any suggestions on how I can analyze zero-inflated CPUE
> data? I have been trying to figure out how to do a Monte Carlo permutation
> test for a mixed model but I am having trouble figuring out the syntax. Any
> help would be greatly appreciated.

  What are you using to assess homogeneity of variance and normality?
Normality of residuals can only be expected approximately (and in the case of
large mean counts) in this case.

   I would start off this way:

mydata$obs <- factor(seq(nrow(mydata)))
glmer(catch~line+habitat+type+cycle+(1|site/cycle)+(1|obs)+
  offset(log(effort)),family=poisson, data=mydata)

You can use the simulate() method to simulate data sets, count
the proportion of zeros expected, and see if your observed 
proportion of zeros is off ...



From joe.c.hightower at boeing.com  Fri Feb 24 19:22:54 2012
From: joe.c.hightower at boeing.com (Hightower, Joe C)
Date: Fri, 24 Feb 2012 10:22:54 -0800
Subject: [R-sig-ME] errors in mcmcpvalue
Message-ID: <F15A9A546A827B4FAB4FED0B256BE9A3461933427C@XCH-NW-08V.nw.nos.boeing.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120224/509b440f/attachment-0001.pl>

From roby.joehanes at nih.gov  Fri Feb 24 22:37:40 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Fri, 24 Feb 2012 16:37:40 -0500
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
Message-ID: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>

Hi,

I learned about the impending release of the new version of lme4 (or lme4a) from Dr. Bates' post here:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007499.html

Firstly, just to make sure, is this based on lme4a? I have the source tarball of lme4a 0.999375-65 and found that a new optimizer, BOBYQA, is now in use, instead of the nlminb. The announcement above also mentioned the same change. So, I suspect that the older lme4 is supplanted with lme4a. Is this true?

Secondly, I would like to get a source tarball of the latest bleeding edge release to play with (or even read-only SVN access). I found from some sniff tests the lmer outputs of lme4a to be closely matched with those of SAS than those of the lme4 (with nlminb optimizer), except for the lack of p-values. I would love to play with the new version and even give you comparisons with the old version. The problem I am facing with lme4a 0.999375-65 is that it sometimes crashes (core dumps).

Thirdly, I also would love to see the Satterthwaite or Kenward-Rogers DF estimation. I would like to try to add these features into lme4, if you will. I don't know much about the formulas to compute the DFs from quantities output by lmer / glmer. Any pointers?

Thank you.

Sincerely,
Roby


From joe.c.hightower at boeing.com  Fri Feb 24 23:05:54 2012
From: joe.c.hightower at boeing.com (Hightower, Joe C)
Date: Fri, 24 Feb 2012 14:05:54 -0800
Subject: [R-sig-ME] influence.ME questions
Message-ID: <F15A9A546A827B4FAB4FED0B256BE9A3461933427E@XCH-NW-08V.nw.nos.boeing.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120224/89d45aa9/attachment-0001.pl>

From knozue at ucdavis.edu  Fri Feb 24 23:21:10 2012
From: knozue at ucdavis.edu (Kazunari Nozue)
Date: Fri, 24 Feb 2012 14:21:10 -0800
Subject: [R-sig-ME] permutation approach to know effect of one factor
	(factor A) to another (factor B) in each level of factor A
	(although it is slow)
Message-ID: <26472CCD-44BF-49F9-913A-1AF005C99D29@ucdavis.edu>

Hi all,

At first I will explain my linear mixed effects model;
lme1 <- lme(leaf_length ~ Treatment*Genotype*leaf,random=~Treatment|Set,data=data)

or
lmer1 <- lmer(leaf~Treatment*Genotype*leaf+(Treatment|Set),data=data)


Treatment factor has two conditions: mock (=Mo) and treatment(=Tr)
Leaf is position of leaf: 3rd leaf, 4th leaf, ....
Genotype is type of plant: wt, mut1, mut2, ....., mut72
Set is experimental replicates: A to J.
I would like to ask how to compare leaf length under condition A and one under condition B in each Genotype, i.e. know effect of one factor (factor A, ?Genotype?) to another (factor B, ?Treatment?) in each level of factor A (eg. ?wt?, ?mut1?, ?mut2?, ...).
Since my data is unbalanced data, I could not use TukeyHSD() multiple comparison (see its help).
My understanding is that pvalue in summary(lme1)$tTable is controversial and pvals.fnc(lmer1) # in languageR package
gave me an error (due to (Treatment|Set) because (1|Set) did not gave me an error, but (Treatment\SET) is essential in this model.).

As seen below, I would like to know my permutation method is OK or not.

I started from a simple permutation approach from Maindonald and Braun (2003) "Data Analysis and Graphics Using R." pg 98. (see scripts below) and I combined my mixed model and this approach with simulated data (omitting leaf factor to simplify, see scripts below). Disadvantage of this method is running time could be long in large data sets with many permutation (eg. 10000), I would like to know my method is OK. If I could have better methods (probably by using multcomp package, such as glht() function), I would really appreciate them.

Sorry for long message.

Thank you,

Kazu
##############################
### Maindonald nad Braun pg. 98
##############################
library(DAAG)
data(two65) # from DAAG package
x1 <- two65$ambient;x2<-two65$heated;x<-c(x1,x2)
n1<-length(x1);n2<-length(x2);n<-n1+n2
dbar<-mean(x2) - mean(x1)
z<-array(,2000)

for(i in 1:2000) {
mn<-sample(n,n2,replace=FALSE)
dbardash<-mean(x[mn])-mean(x[-mn])
z[i]<-dbardash
}

pval<-(sum(z > abs(dbar)) + sum(z< -abs(dbar)))/2000
plot(density(z),yaxs="i")
abline(v=dbar)
abline(v=-dbar,lty=2)
###############################
### my example with unbalanced data
###############################
library(lme4)
#simulate data. leaf length in Tr is longer than Mo. wt shows more dramatic response to Tr than mut. setA plants were longer than setB plants (set factor is significant in this model).
set.seed(1234)
data <- data.frame(Treatment=rep(c("Tr","Mo"),c(9,11)),leaf=c(rnorm(9,11),rnorm(11,10)),Set=rep(c("A","B"),times=10))
data$Genotype <- factor(rep(c("mut","wt"),each=5,length.out=20))
#add setA specific effect for shade and then for sun
data$leaf[data$Treatment=="Tr" & data$Set=="A"] <- data$leaf[data$Treatment=="Tr" & data$Set=="A"] + rnorm(length(data$leaf[data$Treatment=="Tr" & data$Set=="A"]),1)
data$leaf[data$Treatment=="Tr" & data$Genotype=="mut"] <- data$leaf[data$Treatment=="Tr" & data$Genotype=="mut"] + rnorm(length(data$leaf[data$Treatment=="Tr" & data$Genotype=="mut"]),-0.5)
data$leaf[data$Treatment=="Mo" & data$Set=="A"] <- data$leaf[data$Treatment=="Mo" & data$Set=="A"] + rnorm(length(data$leaf[data$Treatment=="Mo" & data$Set=="A"]),-0.25)
data
# mean from observed data
mean.table.obs<-tapply(data$leaf, list(data$Treatment,data$Genotype),mean)
# permutation
mean.table.PER<-list()
nreps<-1000
z<-list() # mean differences

for(i in 1:nreps) {
	new.data<-data.frame()
	new.wt<-sample(data[data$Genotype=="wt",]$leaf,sum(data$Genotype=="wt",na.rm=TRUE),replace=FALSE) # null hypothesis: leaf in Mo = Tr in wt
	new.mut<-sample(data[data$Genotype=="mut",]$leaf,sum(data$Genotype=="mut",na.rm=TRUE),replace=FALSE)
	new.data<-data.frame(leaf=c(new.wt,new.mut),Genotype=data$Genotype,Treatment=data$Treatment,Set=data$Set)
	# mixed effect model
	lmer.temp<- lmer(leaf~Treatment*Genotype+(Treatment|Set),data=new.data)
	#calculate mean of each group
	mean.table.PER[[i]]<-tapply(fitted(lmer.temp), list(new.data$Treatment,new.data$Genotype),mean)
	z[[i]]<-mean.table.PER[[i]][2,] - mean.table.PER[[i]][1,]
}

# calculate p value
TF1<-list()
TF2<-list()
p.value<-vector()

for(i in 1:length(levels(data$Genotype))) {
	for(n in 1:length(z)) {
	     TF1[[n]]<-          (z[[n]][i] > abs(mean.table.obs[2,i] - mean.table.obs[1,i]))*1
	     TF2[[n]]<-      (z[[n]][i] < -abs(mean.table.obs[2,i] - mean.table.obs[1,i]))*1
         }    
	p.value[i]<-(sum(as.numeric(TF1) + as.numeric(TF2)))/length(z)
}

names(p.value)<-levels(data$Genotype)
p.value
p.adjust<-p.adjust(p=p.value,method=?fdr?)
p.adjust
# graph
par(mfcol=c(2,1))
hist(unlist(z)[names(unlist(z))=="mut"],breaks=seq(-5,5,0.2))
abline(v=abs(mean.table.obs[2,1] - mean.table.obs[1,1]))
abline(v=-abs(mean.table.obs[2,1] - mean.table.obs[1,1]))

hist(unlist(z)[names(unlist(z))=="wt"],breaks=seq(-5,5,0.2))
abline(v=abs(mean.table.obs[2,2] - mean.table.obs[1,2]))
abline(v=-abs(mean.table.obs[2,2] - mean.table.obs[1,2]))


From bbolker at gmail.com  Sat Feb 25 02:50:19 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 25 Feb 2012 01:50:19 +0000 (UTC)
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
Message-ID: <loom.20120225T023057-270@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> I learned about the impending release of the new version of lme4 
> (or lme4a) from Dr. Bates' post here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007499.html
> 
> Firstly, just to make sure, is this based on lme4a? 
> I have the source tarball of lme4a 0.999375-65 and found
> that a new optimizer, BOBYQA, is now in use, instead of the nlminb. 
> The announcement above also mentioned
> the same change. 
> So, I suspect that the older lme4 is supplanted with lme4a. Is this true?

  I'm not quite sure what you mean.  There are three versions of lme4:

* lme4 "classic" (version 0.999375-42 is the latest) lme4, built on nlminb
  (as was Bates's previous mixed-models package, nlme)

*** lme4 will be preserved on CRAN and (probably) renamed "lme4.0" after
the new version (see below) is released as lme4, for users who
need backward compatibility (we thought this was a reasonable
name: there are still a few issues with package names containing
dots, so we may need to change this ...). 

* lme4a (0.9996875-1) uses bobyqa

* lmeEigen (to be renamed lme4 when released, sometime soon ...)  uses
a mixture of bobyqa and a new Nelder-Mead implementation that allows box 
constraints, adapted from the nloptr package, which in turn wraps the 
NLopt open-source optimization codes 
(http://ab-initio.mit.edu/wiki/index.php/NLopt_Introduction).

> Secondly, I would like to get a source tarball of the latest 
> bleeding edge release to play with (or even
> read-only SVN access). I found from some sniff tests the lmer outputs of 
> lme4a to be closely matched with
> those of SAS than those of the lme4 (with nlminb optimizer), except for 
> the lack of p-values. I would love to
> play with the new version and even give you comparisons with the old 
> version. The problem I am facing with
> lme4a 0.999375-65 is that it sometimes crashes (core dumps).

  That's easy: just go here for instructions on SVN access:

http://r-forge.r-project.org/scm/?group_id=60

(the package is *so* bleeding edge that if you get it right now,
you should roll back to SVN release 1618; releases 1619+ are
currently broken ...)

> Thirdly, I also would love to see the Satterthwaite or
> Kenward-Rogers DF estimation. I would like to try to add these
> features into lme4, if you will. I don't know much about the
> formulas to compute the DFs from quantities output by lmer /
> glmer. Any pointers?

 Doug Bates is on record as saying that adapting the Kenward-Roger
formulation to work with his code would be difficult
<https://stat.ethz.ch/pipermail/r-help/2008-February/155372.html>, 
but Ulrich Halekoh and S?ren H?jsgaard have an implementation in 
the pbkrtest package
<http://cran.r-project.org/web/packages/pbkrtest/index.html>
which you could look at.  Perhaps that would give you a hint about
a Satterthwaite implementation as well ...

[PS there is no "s" in "Kenward-Roger" -- this is a very common mistake,
Kenward-Roger gets 1.03 million google hits while Kenward-Rogers
gets 438K ...]


> 
> Thank you.
> 
> Sincerely,
> Roby
>



From bbolker at gmail.com  Sat Feb 25 02:52:02 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 25 Feb 2012 01:52:02 +0000 (UTC)
Subject: [R-sig-ME] errors in mcmcpvalue
References: <F15A9A546A827B4FAB4FED0B256BE9A3461933427C@XCH-NW-08V.nw.nos.boeing.com>
Message-ID: <loom.20120225T025102-211@post.gmane.org>

Hightower, Joe C <joe.c.hightower at ...> writes:

> I am stuck, after installing R2.14.0 
> and lme4 0.999375-42, I am getting the following errors:
> 
> > mcmcpvalue(as.matrix(M4diag[,1:4]))
> Error in as.matrix(M4diag[, 1:4]) :
>   error in evaluating the argument 'x' in 
> selecting a method for function 'as.matrix': Error in M4diag[,
> 1:4] : object of type 'S4' is not subsettable

  [snip]

  Can you please post a reproducible example?
  http://tinyurl.com/reproducible-000



From bbolker at gmail.com  Sat Feb 25 22:41:41 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 25 Feb 2012 16:41:41 -0500
Subject: [R-sig-ME] fitting a distribution to zero-inflated catch per
 unit effort mixed model
In-Reply-To: <CABMU9jxVCD85-Bmq_C-A4xvBCcEA7bFjcLitvGY_hDFi9ua=Gw@mail.gmail.com>
References: <CABMU9jxFFYtyHX5reHkrdgvv+3zLz9Ddm3CxhnvYcaSotuq8mA@mail.gmail.com>
	<loom.20120224T000238-482@post.gmane.org>
	<CABMU9jxVCD85-Bmq_C-A4xvBCcEA7bFjcLitvGY_hDFi9ua=Gw@mail.gmail.com>
Message-ID: <4F495595.9050408@gmail.com>

  [cc'ing back to r-sig-mixed-models]

On 12-02-25 03:53 PM, Karla Letto wrote:
> Thank you Ben for the detailed response. I greatly appreciate it. I will
> let you know how it goes after I give each a try. In answer to your
> questions. My sample size is 25 Meadow Voles. 

  Meaning you caught a total of 25 voles in the whole study?  Be warned,
you may find that your model is overfitted -- typically you can fit
about/at most 1 parameter per 10 (effective) data points, which is
something between 25 (the number of voles) and 48 (observations) -- so
your fixed-effect parameters (line+habitat+type = 6 parameters) are
already on the verge of more information than you can estimate, even
before you start counting random effects (3 variances, for
site/cycle/observation-level variation).

> I calculated CPUE for each
> line. So I have a total of 48 observations (3 lines for 8 sites and each
> site was visited twice. I thought I had to use cycle as a random factor
> to account for temporal pseudoreplication.  I can see how your idea of
> nesting cycle within site as a random factor will work better though. 
> 
> I tested for normality using a normal q-q plot and homogeneity by
> plotting the residuals and fitted values (I kept getting a cone shape).

  Hmm.  A cone shape does imply heteroscedasticity that isn't handled by
the model assumptions ... I *think* resid() should give you Pearson
residuals (i.e. already corrected assuming variance=mean). So that's a
little puzzling.  I don't expect normality at all in residuals from a
model with a mean of ~ 2 individuals per sample ...

> 
>> qqnorm(resid(model))
> 
>> qqline(resid(model))
> 
> 
>> plot(fitted(model),resid(model))
> 
> Can you please tell me why I have to use LOG(effort) as an offset
> instead of just effort as the offset? That is not the first time I heard
> that it had to be LOG(effort) but I cannot find a reason for why. 

  Because the offset is added on the scale of the linear predictor,
which in this case is the log scale -- i.e., the expected mean number of
counts is

  exp([fixed effect terms] + [random effect terms] + offset) =
exp([fixed effect terms] + [random effect terms])* exp(offset)

> 
> Thank you, 
> 
> Karla 
> 
> On Thu, Feb 23, 2012 at 7:40 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>     Karla Letto <karla.letto at ...> writes:
> 
>     > I am having trouble fitting a distribution to my mixed model for
>     meadow
>     > vole catch per unit effort (CPUE) data. I have tried several
>     families and
>     > cannot find one that does not violate both the homogeneity and
>     normality
>     > assumptions. NOTE: The data set is zero-inflated (no captures).
>     > Here is my study design:
>     >
>     > I am trying to determine if the CPUE of meadow voles differ among
>     lines
>     > (line = near,mid, or far) at increasing distances from a linear
>     feature
>     > (type = road, trail or powerline corridor) in two different
>     habitat types
>     > (habitat=forest or barren).
>     > Response variable: catch per unit effort (non-integer values)
>     > Fixed explanatory variables: line (3 categories), habitat (2
>     categories),
>     > type (3 categories)
>     > Random explanatory variable: site (8 categories), cycle (2 categories)
> 
> 
>     > The random variable site is for the 8 different sites I sampled in (4
>     > barren and 4 forest) and the cycle is there because I visited each
>     site
>     > twice.
> 
>      Practically speaking you probably can't use cycle as a random
>     effect; you can include cycle as a fixed effect (specifying the
>     difference between first & second visits), and possibly
>     nesting it within site as a random effect (if you have more than
>     one observation per site/sample combination).
> 
>      What is the total size (number of observations) in your data set?
> 
>     > Here is an excerpt of my data set:
>     >    CE2  catch effort site line   cycle habitat      type
>     > 0.000000     0   57.5    A near  first   forest     trail
>     > 3.278689     2   61.0    A   mid   first   forest     trail
>     > 0.000000     0   60.5    A   far   first   forest     trail
>     > 0.000000     0   66.5    G near  first   barren       road
>     > 0.000000     0   74.5    G   mid   first   barren       road
>     > 0.000000     0   74.0    G   far   first   barren       road
>     > 1.449275     1   69.0    E near second  barren powerline
>     > 0.000000     0   73.0    E   mid second  barren powerline
>     > 0.000000     0   71.5    E   far second  barren powerline
>     >
>     > I tried the lme4 package using the following syntax:
>     >
>      [snip]
>     >
>     > I then tried using a poisson error structure using catch (the
>     actual number
>     > of animals) as the response and incorporated effort as an offset.
>     Effort as
>     > an offset is commonly used for analysis of CPUE data.
>     >
>     > Model2<-
>     > glmer(catch~line+habitat+type+(1|site)+(1|cycle)+
>     >  offset(effort),family=poisson)
> 
>      This is a good way to do it, but you need to incorporate the
>     LOG of effort.  You may also need to account for overdispersion
>     and/or zero-inflation; the former via incorporating an observation-level
>     random effect (in glmer, glmmadmb, or MCMCglmm) or negative binomial
>     distribution (in glmmadmb), the latter (if necessary) via zero-inflation
>     or hurdle models (in glmmadmb or MCMCglmm).
> 
>      [snip snip snip]
> 
>     > Does anyone have any suggestions on how I can analyze
>     zero-inflated CPUE
>     > data? I have been trying to figure out how to do a Monte Carlo
>     permutation
>     > test for a mixed model but I am having trouble figuring out the
>     syntax. Any
>     > help would be greatly appreciated.
> 
>      What are you using to assess homogeneity of variance and normality?
>     Normality of residuals can only be expected approximately (and in
>     the case of
>     large mean counts) in this case.
> 
>       I would start off this way:
> 
>     mydata$obs <- factor(seq(nrow(mydata)))
>     glmer(catch~line+habitat+type+cycle+(1|site/cycle)+(1|obs)+
>      offset(log(effort)),family=poisson, data=mydata)
> 
>     You can use the simulate() method to simulate data sets, count
>     the proportion of zeros expected, and see if your observed
>     proportion of zeros is off ...
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>



From arshad4uonly at gmail.com  Sun Feb 26 23:19:37 2012
From: arshad4uonly at gmail.com (Muhammad Arshad)
Date: Mon, 27 Feb 2012 05:19:37 +0700
Subject: [R-sig-ME] =?utf-8?q?Need_help_to_find_multifactors_influence?=
	=?utf-8?b?4oCP?=
In-Reply-To: <CADkfwos-nCV8yCExF_NhAfgpqBfi-5h8TrbNyCYxFRpG5AppEg@mail.gmail.com>
References: <CADkfwos-nCV8yCExF_NhAfgpqBfi-5h8TrbNyCYxFRpG5AppEg@mail.gmail.com>
Message-ID: <CADkfwosHOhXKJEZpHrvehf-ORxyS9Wc0zUB-6=bbUbwiGn5sJA@mail.gmail.com>

Dear friends,

1-I have B.I value (Dependent variable).
2-I have land cover types in the form of % area against each B.I (that was
clipped through buffer for each B.I ). Buffer was put by considering B.I
behavior that can be influence by land type.
3- I want to see the influence of land type on B.I.
4- Suppose B.I value varies with the change in (area) one or more types of
land cover. This change may be linear up to some extent but can also
increase with the combination of land types. Land types can also differ
from one buffer to other buffer.
5- I want to develop a Predication Model\Regression Equation to predict B.I
value with the combined influence of different land use types.
6- I am confused which Regression model (Linear, Logistic, and Poisson,
Exponential etc...)  Should be adopted to develop this type of relationship
where factors are varying.
7- Total study map consists of 77 land cover types and each buffer gets
some land type.

Please see the attached data having values extracted for each land type
(a1~a77 are land type names against each BI).

I already tried to solve it with different methods. Even I made groups in
term of B.I & also in term of land cover types. But still failed to
find correlation with reasonable factors.

I will happy for your informative response to solve my this problem. Please
let me know if my question is not clear.

Warm Regards,
Malik\Arshad

From slu at ccsr.uchicago.edu  Mon Feb 27 22:02:31 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 27 Feb 2012 15:02:31 -0600
Subject: [R-sig-ME] How to calculate predictions
Message-ID: <1330376551.19171.23.camel@localhost>

Hello, I have modeled student math growth curves with lmer with a model
like this. It predicts math achievement by age (centered at age 11) with
a linear and quadratic term, with both these and the intercept varying
randomly across students:

math.lme3 <- lmer(data=allmathgains, math ~ I(age-11) + I((age-11)^2) +
old4gr + (I(age-11) + I((age-11)^2) | sid))

where sid is the student ID and old4gr take a value of 1 if the student
is old for grade, 0 otherwise. I want to get a prediction of each
student's achievement at age 15. I have done this kind of thing:

random.effects3 <- ranef(math.lme3)
fixed.effects3 <- fixef(math.lme3)

## Just try it for the first 100 students for now
test <- random.effects3$sid[1:100,]
test2 <- cbind(as.numeric(rownames(test)),
               test[,1]+fixed.effects3[1],
               test[,2]+fixed.effects3[2],
               test[,3]+fixed.effects3[3])
 
test3 <- cbind(test2, allmathgains[1:100, "old4gr"])
 
to.predict <- as.data.frame(cbind(rep(1, 100), rep(4, 100), rep(16,
100)))
to.predict2 <- cbind(to.predict, allmathgains[1:100, "old4gr"])

my.predictions <- numeric(100)
for (i in 1:100) {
  my.predictions[i] <- test3[i, 2:5] %*% t(as.matrix(to.predict2[i,]))
}

My questions: 
1) Is my idea to add each random effect to the fixed effects (to make
data.frame test2) correct? 
2) Is there a more efficient way of doing this? This is a big issue
because I am working with a data set of about 240,000 students. 

Thanks in advance.
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
For the S system, which has forever altered the way
 people analyze, visualize, and manipulate data
 .... S is an elegant, widely accepted, and
 enduring software system, with conceptual
 integrity, thanks to the insight, taste, and
 effort of John Chambers.    -- Association for
 Computing Machinery       ACM/Software System
 Award citation (1998)



From jake987722 at hotmail.com  Mon Feb 27 22:20:36 2012
From: jake987722 at hotmail.com (Jake Westfall)
Date: Mon, 27 Feb 2012 14:20:36 -0700
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <1330376551.19171.23.camel@localhost>
References: <1330376551.19171.23.camel@localhost>
Message-ID: <SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120227/07200f51/attachment-0001.pl>

From slu at ccsr.uchicago.edu  Mon Feb 27 23:42:48 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 27 Feb 2012 16:42:48 -0600
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>
References: <1330376551.19171.23.camel@localhost>
	<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>
Message-ID: <1330382568.19171.27.camel@localhost>

On Mon, 2012-02-27 at 14:20 -0700, Jake Westfall wrote:
> 1) Yes2) ?fitted

I don't think fitted is what I want. According to the docs, fitted
returns the fitted conditional means of the responses. I want the
predicted value when age-11 is 4, (age-11)^2 is 16, old4gr has the
appropriate value, and all the individual random effects are included.

> > From: slu at ccsr.uchicago.edu
> > To: r-sig-mixed-models at r-project.org
> > Date: Mon, 27 Feb 2012 15:02:31 -0600
> > Subject: [R-sig-ME] How to calculate predictions
> > 
> > Hello, I have modeled student math growth curves with lmer with a model
> > like this. It predicts math achievement by age (centered at age 11) with
> > a linear and quadratic term, with both these and the intercept varying
> > randomly across students:
> > 
> > math.lme3 <- lmer(data=allmathgains, math ~ I(age-11) + I((age-11)^2) +
> > old4gr + (I(age-11) + I((age-11)^2) | sid))
> > 
> > where sid is the student ID and old4gr take a value of 1 if the student
> > is old for grade, 0 otherwise. I want to get a prediction of each
> > student's achievement at age 15. I have done this kind of thing:
> > 
> > random.effects3 <- ranef(math.lme3)
> > fixed.effects3 <- fixef(math.lme3)
> > 
> > ## Just try it for the first 100 students for now
> > test <- random.effects3$sid[1:100,]
> > test2 <- cbind(as.numeric(rownames(test)),
> >                test[,1]+fixed.effects3[1],
> >                test[,2]+fixed.effects3[2],
> >                test[,3]+fixed.effects3[3])
> >  
> > test3 <- cbind(test2, allmathgains[1:100, "old4gr"])
> >  
> > to.predict <- as.data.frame(cbind(rep(1, 100), rep(4, 100), rep(16,
> > 100)))
> > to.predict2 <- cbind(to.predict, allmathgains[1:100, "old4gr"])
> > 
> > my.predictions <- numeric(100)
> > for (i in 1:100) {
> >   my.predictions[i] <- test3[i, 2:5] %*% t(as.matrix(to.predict2[i,]))
> > }
> > 
> > My questions: 
> > 1) Is my idea to add each random effect to the fixed effects (to make
> > data.frame test2) correct? 
> > 2) Is there a more efficient way of doing this? This is a big issue
> > because I am working with a data set of about 240,000 students. 
> > 
> > Thanks in advance.
> > -- 
> > Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
> > University of Chicago -=- CCSR 
> > ???????? -=-    Kernel 3.2.1-gentoo-r2                
> > For the S system, which has forever altered the way
> >  people analyze, visualize, and manipulate data
> >  .... S is an elegant, widely accepted, and
> >  enduring software system, with conceptual
> >  integrity, thanks to the insight, taste, and
> >  effort of John Chambers.    -- Association for
> >  Computing Machinery       ACM/Software System
> >  Award citation (1998)
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  		 	   		  


-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
My institution has a particularly diabolical policy
 on intellectual property, especially on software. 
 -- Ross Ihaka       R-help (August 2003)



From roby.joehanes at nih.gov  Mon Feb 27 23:48:02 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 27 Feb 2012 17:48:02 -0500
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
In-Reply-To: <loom.20120225T023057-270@post.gmane.org>
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
Message-ID: <99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>

Hi Ben:

Thank you very much. I think I will familiarize myself with the lme4Eigen code for a while. A few more questions:

1. I noticed that there is lme4Eigen version 0.9996875-9 in the repository:
http://lme4.r-forge.r-project.org/repos/src/contrib/
Which SVN revision does it correspond to? I am currently using it and it appears to be quite stable.

2. It seems that the code for revision 1618 isn't that much different than the HEAD branch (I believe 1621 at the moment). Is it really that buggy? I am primarily interested in the lmer, not glmer.

3. (A different topic) Is there any way to speed up calling lmer on the same X and Z matrices but thousands of different y columns? In general linear model, we can invoke QR decomposition and use Q and R matrices to speed the calculations up. Is there such a decomposition (or method) that we can exploit to speed up the calculation?

Finally, thank you for the pointer on Kenward-Roger DF estimation.

Sincerely,
Roby

--------
Roby Joehanes
Research Associate
Roby.Joehanes at nih.gov
Building 12A, Room 2007
National Institutes of Health (NIH)
Bethesda, MD 20892
P: (301) 402-8702
F: (301) 480-0028 or (301) 402-2867


On Feb 24, 2012, at 8:50 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
> 
>> I learned about the impending release of the new version of lme4 
>> (or lme4a) from Dr. Bates' post here:
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007499.html
>> 
>> Firstly, just to make sure, is this based on lme4a? 
>> I have the source tarball of lme4a 0.999375-65 and found
>> that a new optimizer, BOBYQA, is now in use, instead of the nlminb. 
>> The announcement above also mentioned
>> the same change. 
>> So, I suspect that the older lme4 is supplanted with lme4a. Is this true?
> 
>  I'm not quite sure what you mean.  There are three versions of lme4:
> 
> * lme4 "classic" (version 0.999375-42 is the latest) lme4, built on nlminb
>  (as was Bates's previous mixed-models package, nlme)
> 
> *** lme4 will be preserved on CRAN and (probably) renamed "lme4.0" after
> the new version (see below) is released as lme4, for users who
> need backward compatibility (we thought this was a reasonable
> name: there are still a few issues with package names containing
> dots, so we may need to change this ...). 
> 
> * lme4a (0.9996875-1) uses bobyqa
> 
> * lmeEigen (to be renamed lme4 when released, sometime soon ...)  uses
> a mixture of bobyqa and a new Nelder-Mead implementation that allows box 
> constraints, adapted from the nloptr package, which in turn wraps the 
> NLopt open-source optimization codes 
> (http://ab-initio.mit.edu/wiki/index.php/NLopt_Introduction).
> 
>> Secondly, I would like to get a source tarball of the latest 
>> bleeding edge release to play with (or even
>> read-only SVN access). I found from some sniff tests the lmer outputs of 
>> lme4a to be closely matched with
>> those of SAS than those of the lme4 (with nlminb optimizer), except for 
>> the lack of p-values. I would love to
>> play with the new version and even give you comparisons with the old 
>> version. The problem I am facing with
>> lme4a 0.999375-65 is that it sometimes crashes (core dumps).
> 
>  That's easy: just go here for instructions on SVN access:
> 
> http://r-forge.r-project.org/scm/?group_id=60
> 
> (the package is *so* bleeding edge that if you get it right now,
> you should roll back to SVN release 1618; releases 1619+ are
> currently broken ...)
> 
>> Thirdly, I also would love to see the Satterthwaite or
>> Kenward-Rogers DF estimation. I would like to try to add these
>> features into lme4, if you will. I don't know much about the
>> formulas to compute the DFs from quantities output by lmer /
>> glmer. Any pointers?
> 
> Doug Bates is on record as saying that adapting the Kenward-Roger
> formulation to work with his code would be difficult
> <https://stat.ethz.ch/pipermail/r-help/2008-February/155372.html>, 
> but Ulrich Halekoh and S?ren H?jsgaard have an implementation in 
> the pbkrtest package
> <http://cran.r-project.org/web/packages/pbkrtest/index.html>
> which you could look at.  Perhaps that would give you a hint about
> a Satterthwaite implementation as well ...
> 
> [PS there is no "s" in "Kenward-Roger" -- this is a very common mistake,
> Kenward-Roger gets 1.03 million google hits while Kenward-Rogers
> gets 438K ...]



From bates at stat.wisc.edu  Tue Feb 28 00:03:58 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Feb 2012 17:03:58 -0600
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
In-Reply-To: <99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
Message-ID: <CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>

On Mon, Feb 27, 2012 at 4:48 PM, Joehanes, Roby (NIH/NHLBI) [F]
<roby.joehanes at nih.gov> wrote:
> Hi Ben:
>
> Thank you very much. I think I will familiarize myself with the lme4Eigen code for a while. A few more questions:
>
> 1. I noticed that there is lme4Eigen version 0.9996875-9 in the repository:
> http://lme4.r-forge.r-project.org/repos/src/contrib/
> Which SVN revision does it correspond to? I am currently using it and it appears to be quite stable.

The SVN revision number is stored in the DESCRIPTION file for recent
versions of lme4Eigen.  It is actually the revision number for the
last check-in of the DESCRIPTION file but that gets updated fairly
frequently so the revision number in there is a pretty tight lower
bound.

> 2. It seems that the code for revision 1618 isn't that much different than the HEAD branch (I believe 1621 at the moment). Is it really that buggy? I am primarily interested in the lmer, not glmer.

The current revision (1623) should compile.  The breakage was
something I did on Friday and needed to commit because it was only on
my laptop.  I realized later that I had a modified version of
RcppEigen on my laptop and without those modifications the compilation
croaked. I created a version that doesn't use those particular
modifications, at least for now.

> 3. (A different topic) Is there any way to speed up calling lmer on the same X and Z matrices but thousands of different y columns? In general linear model, we can invoke QR decomposition and use Q and R matrices to speed the calculations up. Is there such a decomposition (or method) that we can exploit to speed up the calculation?

Yes, check out the refit function.  I just saw that the documentation
suffers from cut-and-paste errors but the general idea is to give a
fitted model a new response and run only the optimization step.

> (fm1 <- lmer(Yield ~ 1|Batch, Dyestuff))
Linear mixed model fit by REML ['lmerMod']
Formula: Yield ~ 1 | Batch
   Data: Dyestuff

REML criterion at convergence: 319.6543

Random effects:
 Groups   Name        Variance Std.Dev.
 Batch    (Intercept) 1764     42.00
 Residual             2451     49.51
Number of obs: 30, groups: Batch, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1527.50      19.38    78.8
> refit(fm1, Dyestuff2$Yield)
Linear mixed model fit by REML ['lmerMod']
Formula: Yield ~ 1 | Batch
   Data: Dyestuff

REML criterion at convergence: 161.8283

Random effects:
 Groups   Name        Variance Std.Dev.
 Batch    (Intercept)  0.00    0.000
 Residual             13.81    3.716
Number of obs: 30, groups: Batch, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   5.6656     0.6784   8.352

> Finally, thank you for the pointer on Kenward-Roger DF estimation.
>
> Sincerely,
> Roby
>
> --------
> Roby Joehanes
> Research Associate
> Roby.Joehanes at nih.gov
> Building 12A, Room 2007
> National Institutes of Health (NIH)
> Bethesda, MD 20892
> P: (301) 402-8702
> F: (301) 480-0028 or (301) 402-2867
>
>
> On Feb 24, 2012, at 8:50 PM, Ben Bolker wrote:
>
>> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
>>
>>> I learned about the impending release of the new version of lme4
>>> (or lme4a) from Dr. Bates' post here:
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007499.html
>>>
>>> Firstly, just to make sure, is this based on lme4a?
>>> I have the source tarball of lme4a 0.999375-65 and found
>>> that a new optimizer, BOBYQA, is now in use, instead of the nlminb.
>>> The announcement above also mentioned
>>> the same change.
>>> So, I suspect that the older lme4 is supplanted with lme4a. Is this true?
>>
>> ?I'm not quite sure what you mean. ?There are three versions of lme4:
>>
>> * lme4 "classic" (version 0.999375-42 is the latest) lme4, built on nlminb
>> ?(as was Bates's previous mixed-models package, nlme)
>>
>> *** lme4 will be preserved on CRAN and (probably) renamed "lme4.0" after
>> the new version (see below) is released as lme4, for users who
>> need backward compatibility (we thought this was a reasonable
>> name: there are still a few issues with package names containing
>> dots, so we may need to change this ...).
>>
>> * lme4a (0.9996875-1) uses bobyqa
>>
>> * lmeEigen (to be renamed lme4 when released, sometime soon ...) ?uses
>> a mixture of bobyqa and a new Nelder-Mead implementation that allows box
>> constraints, adapted from the nloptr package, which in turn wraps the
>> NLopt open-source optimization codes
>> (http://ab-initio.mit.edu/wiki/index.php/NLopt_Introduction).
>>
>>> Secondly, I would like to get a source tarball of the latest
>>> bleeding edge release to play with (or even
>>> read-only SVN access). I found from some sniff tests the lmer outputs of
>>> lme4a to be closely matched with
>>> those of SAS than those of the lme4 (with nlminb optimizer), except for
>>> the lack of p-values. I would love to
>>> play with the new version and even give you comparisons with the old
>>> version. The problem I am facing with
>>> lme4a 0.999375-65 is that it sometimes crashes (core dumps).
>>
>> ?That's easy: just go here for instructions on SVN access:
>>
>> http://r-forge.r-project.org/scm/?group_id=60
>>
>> (the package is *so* bleeding edge that if you get it right now,
>> you should roll back to SVN release 1618; releases 1619+ are
>> currently broken ...)
>>
>>> Thirdly, I also would love to see the Satterthwaite or
>>> Kenward-Rogers DF estimation. I would like to try to add these
>>> features into lme4, if you will. I don't know much about the
>>> formulas to compute the DFs from quantities output by lmer /
>>> glmer. Any pointers?
>>
>> Doug Bates is on record as saying that adapting the Kenward-Roger
>> formulation to work with his code would be difficult
>> <https://stat.ethz.ch/pipermail/r-help/2008-February/155372.html>,
>> but Ulrich Halekoh and S?ren H?jsgaard have an implementation in
>> the pbkrtest package
>> <http://cran.r-project.org/web/packages/pbkrtest/index.html>
>> which you could look at. ?Perhaps that would give you a hint about
>> a Satterthwaite implementation as well ...
>>
>> [PS there is no "s" in "Kenward-Roger" -- this is a very common mistake,
>> Kenward-Roger gets 1.03 million google hits while Kenward-Rogers
>> gets 438K ...]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jake987722 at hotmail.com  Tue Feb 28 00:07:30 2012
From: jake987722 at hotmail.com (Jake Westfall)
Date: Mon, 27 Feb 2012 16:07:30 -0700
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <1330382568.19171.27.camel@localhost>
References: <1330376551.19171.23.camel@localhost>,
	<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>,
	<1330382568.19171.27.camel@localhost>
Message-ID: <SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120227/792d912c/attachment-0001.pl>

From slu at ccsr.uchicago.edu  Tue Feb 28 00:31:04 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 27 Feb 2012 17:31:04 -0600
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
References: <1330376551.19171.23.camel@localhost>
	,<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>
	,<1330382568.19171.27.camel@localhost>
	<SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
Message-ID: <1330385464.19171.31.camel@localhost>

On Mon, 2012-02-27 at 16:07 -0700, Jake Westfall wrote:
> Unless I am misunderstanding what you're after, one thing you can do
> is just append the fitted values to the data frame (you will want to
> use math.lme3 at frame in case of dropped observations) and from there
> pick out the predicted value for each student at age 15. All of the
> appropriate other effects should be factored in.

I believe that fitted() is giving fitted values for each observation. 

 length(fitted(math.lme3))
[1] 520573
 length(unique(math.lme3 at frame$sid))
[1] 236994

I have about 520,000 observations nested within 236,994 students. I want
a fitted value for each student at age 15 (which may or may not be
actually observed).
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
1st mail: One of the reasons that SAM is popular,
 is that it is popular (i.e. since everyone has
 heard of it, it makes reviewers happy). So, it
 would be nice to be able to point to publications 
 in good journals so that reviewers will be
 comfortable. (I personally, am quite comfortable
 with SAM). 2nd mail: Oops, must have been a
 Freudian slip. Actually, I am not perfectly
 comfortable with SAM. But I am quite comfortable



From bbolker at gmail.com  Tue Feb 28 05:26:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 28 Feb 2012 04:26:16 +0000 (UTC)
Subject: [R-sig-ME] How to calculate predictions
References: <1330376551.19171.23.camel@localhost> ,
	<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl> ,
	<1330382568.19171.27.camel@localhost>
	<SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
	<1330385464.19171.31.camel@localhost>
Message-ID: <loom.20120228T052455-583@post.gmane.org>

Stuart Luppescu <slu at ...> writes:

> 
> On Mon, 2012-02-27 at 16:07 -0700, Jake Westfall wrote:
> 
> I believe that fitted() is giving fitted values for each observation. 
> 
>  length(fitted(math.lme3))
> [1] 520573
>  length(unique(math.lme3 <at> frame$sid))
> [1] 236994
> 
> I have about 520,000 observations nested within 236,994 students. I want
> a fitted value for each student at age 15 (which may or may not be
> actually observed).

  Have you looked at the code on http://glmm.wikidot.com/faq ... ?
Also, the new lme4Eigen package does have a ?predict method ...
  
  Ben Bolker



From Kevin_J_Ryan at umit.maine.edu  Tue Feb 28 17:44:15 2012
From: Kevin_J_Ryan at umit.maine.edu (Kevin J. Ryan)
Date: Tue, 28 Feb 2012 11:44:15 -0500
Subject: [R-sig-ME]
 =?iso-8859-1?q?Incorporating_a_Temporal_Correlation_St?=
 =?iso-8859-1?q?ructure_in_=09a=09=09GLM?=
In-Reply-To: <155F553A-8E23-470A-A182-90D61105BD88@wisc.edu>
References: <fc.004c4d194d3477bb004c4d194d3477bb.4d3492fa@umit.maine.edu> <	>
	<loom.20120222T020754-835@post.gmane.org>
	<155F553A-8E23-470A-A182-90D61105BD88@wisc.edu>
Message-ID: <fc.004c4d194d51c01b004c4d194d3477bb.4d51c236@umit.maine.edu>

Hello,

Thank you all very much for taking the time to give advice on my statistical issues.  So far I have run logistic regression models using glm, lmer, and glmmPQL.  I used pacf to look at autocorrelation of the residuals of these models and they do not
appear to be so (assuming pacf is suitable for use on residuals of a logistic regression).  Something may be going wrong with the lmer model however.  (The output of which is below this message.)  I included ?Toad? as a random effect and the
variance and SD are output as 0.  Perhaps because of this, the coefficients of the glm model and the lmer model are exactly the same.    

So if my residuals are okay, then perhaps an ordinary glm (pooling all toads) is the way to go.  I would have liked to model proportion of toads emerged but I only had two monitoring devices, which more often than not were not deployed
simultaneously.   

Thanks again everyone,

 - Kevin

> summary(Tavg.lmer)

Generalized linear mixed model fit by the Laplace approximation 

Formula: Emergence ~ Tavg + (1 | Toad) 

   AIC BIC logLik deviance

 481.2 493 -237.6    475.2

Random effects:

 Groups Name        Variance Std.Dev.

 Toad   (Intercept)  0        0      

Number of obs: 371, groups: Toad, 16


Fixed effects:

            Estimate Std. Error z value Pr(>|z|)    

(Intercept) -5.14598    0.95134  -5.409 6.33e-08 ***

Tavg         0.07202    0.01392   5.174 2.29e-07 ***

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

 
Correlation of Fixed Effects:

     (Intr)

Tavg -0.993

 
Anthony R Ives <arives at wisc.edu> writes:
>Kevin,
>
>It is not clear to me that this problem requires accounting for  
>temporal autocorrelation, although I might be missing something.  You  
>say that the weather variables are autocorrelated, but if these are  
>used as predictor variables, this doesn't necessarily mean that you  
>need a model incorporating autocorrelation; autocorrelation of the  
>errors (residuals) is what matters.  Also, it is not clear to me why  
>you would want to use logistic regression on each individual  
>separately.  I would suspect that there is correlation among  
>individuals beyond that explained by the weather variables you  
>included.  It might be simpler to analyze all individuals together  
>(i.e., proportion of emergences on a given day).
>
>That being said, there are three more approaches to Ben's list of  
>logistic regression with temporal autocorrelation:
>
>1. You could use an extended Kalman filter with a measurement  
>equation accounting for the variance structure of a binary process.   
>An advantage here is that it is simple to include gaps in the  
>observations.  I have seen this done in the literature, but a quick  
>check didn't turn up a reference.
>
>2. There is a largish literature on integer-valued ARMA models,  
>though I don't know of code that will do this easily.
>
>3. With colleagues, I've worked out two flavors of logistic  
>regression with phylogenetic correlations.  These could be used by  
>replacing the phylogenetic covariance matrix with a autocovariance  
>matrix.
>
>All of these will require a little custom programming.
>
>Cheers, Tony
>
>On Feb 21, 2012, at 7:15 PM, Ben Bolker wrote:
>
>> Kevin J. Ryan <Kevin_J_Ryan at ...> writes:
>>
>>
>>> I'm attempting to use mixed-model logistic regression to model
>>> spadefoot emergence as a function of weather variables (individuals
>>> are monitored continuously from 1-84 days [with gaps]).  However,
>>> the weather variables are serially autocorrelated, apparently at a
>>> lag of 12 days or so.  Does anyone have experience incorporating a
>>> temporal autocorrelation structure of predictor variables into a
>>> glm?  I've been examining the lme4 package but it does not appear to
>>> be able to do this.
>>
>>   A couple of quick thoughts:
>>
>> * you could use glmmPQL (in the MASS package), which does allow any
>> of the correlation structures that are defined in the nlme
>> package (including corCAR1, which allows for gappy data). This
>> is not preferred for binary data, but probably (?) correcting
>> for correlation and using a slightly questionable estimation method
>> is better than ignoring correlation.
>>
>> * if your responses are measured without error you might
>> be able to use emergences at a previous time point as
>> a predictor.
>>
>> * you could just use glm (or whatever) and evaluate the correlations
>> among the residuals -- if there's nothing going on there then you
>> have a reasonable excuse for proceeding without a correlation model.
>>
>> * the fact that the _predictor_ variables are autocorrelated isn't
>> that much of a big deal -- it's really the response (or rather the
>> residuals of the response) that you should be worried about, although
>> there is always a bit of an issue in time-series analysis in
>> looking at relationships of autocorrelated series with other
>> autocorrelated series ...
>>
>> * generalized estimating equations (GEE: see geepack etc.) are
>> another approach, although I don't know if any of the R packages
>> that do GEEs have an option for autocorrelations on unevenly
>> spaced data (try installing the "sos" package and searching
>> via something like findFn("gee uneven"))
>>
>> * in my opinion the gold standard (if the data are rich enough
>> to warrant it) is to build a hierarchical model with a latent
>> normally distributed variable with temporal autocorrelation and
>> an observed binary variable (emergence) on top of it, but this
>> is fairly hard work -- you'd need AD Model Builder or some
>> dialect of BUGS.
>>
>>  I will be interested to see if anyone has better suggestions.
>>
>>  I would check the books from Highland Statistics (Zuur et al.)
>> to see if they have anything useful ...
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>Anthony Ragnar Ives
>Department of Zoology
>UW-Madison
>(608) 262-1519
>
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From slu at ccsr.uchicago.edu  Tue Feb 28 19:54:36 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 28 Feb 2012 12:54:36 -0600
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <loom.20120228T052455-583@post.gmane.org>
References: <1330376551.19171.23.camel@localhost>
	, <SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>
	, <1330382568.19171.27.camel@localhost>
	<SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
	<1330385464.19171.31.camel@localhost>
	<loom.20120228T052455-583@post.gmane.org>
Message-ID: <1330455276.13060.3.camel@localhost>

On Tue, 2012-02-28 at 04:26 +0000, Ben Bolker wrote:
> Stuart Luppescu <slu at ...> writes:
> 
> > 
> > On Mon, 2012-02-27 at 16:07 -0700, Jake Westfall wrote:
> > 
> > I believe that fitted() is giving fitted values for each observation. 
> > 
> >  length(fitted(math.lme3))
> > [1] 520573
> >  length(unique(math.lme3 <at> frame$sid))
> > [1] 236994
> > 
> > I have about 520,000 observations nested within 236,994 students. I want
> > a fitted value for each student at age 15 (which may or may not be
> > actually observed).
> 
>   Have you looked at the code on http://glmm.wikidot.com/faq ... ?

Yes, I have. Unless I'm missing something (which is very possible) it
doesn't seem that the code includes the individual random effects.

> Also, the new lme4Eigen package does have a ?predict method ...

Doesn't seem to be available on CRAN -- only on R-forge? I don't think I
can convince our sysadmin to install a non-stable package.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
1st mail: One of the reasons that SAM is popular,
 is that it is popular (i.e. since everyone has
 heard of it, it makes reviewers happy). So, it
 would be nice to be able to point to publications 
 in good journals so that reviewers will be
 comfortable. (I personally, am quite comfortable
 with SAM). 2nd mail: Oops, must have been a
 Freudian slip. Actually, I am not perfectly
 comfortable with SAM. But I am quite comfortable



From Rachel.Gibson at bristol.ac.uk  Wed Feb 29 14:58:27 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson)
Date: Wed, 29 Feb 2012 13:58:27 -0000 (GMT)
Subject: [R-sig-ME] error message using glmmadmb
Message-ID: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>

I am trying to use glmmadmb to build a model.

Code used:

m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+(1|Site),family="nbinom")

"Site" is a categorical variable and is a factor (non numeric).

I get the error message:

Error in eval(expr, envir, enclos) : could not find function "Droplevels"
In addition: Warning message:
In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'

Can anyone tell me why I am getting this message, please?






--



From bbolker at gmail.com  Wed Feb 29 15:54:30 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Feb 2012 14:54:30 +0000 (UTC)
Subject: [R-sig-ME] error message using glmmadmb
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
Message-ID: <loom.20120229T155325-260@post.gmane.org>

RH Gibson <Rachel.Gibson at ...> writes:

> 
> I am trying to use glmmadmb to build a model.
> 
> Code used:
> 
> m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+
> fsize+(1|Site),family="nbinom")
> 
> "Site" is a categorical variable and is a factor (non numeric).
> 
> I get the error message:
> 
> Error in eval(expr, envir, enclos) : could not find function "Droplevels"
> In addition: Warning message:
> In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
> 
> Can anyone tell me why I am getting this message, please?

  What version are you using?  This is reminiscent of a problem with
a recent (but not-the-very-latest) version.  Can you try

update.packages(repos="http://r-forge.r-project.org")

(or just reinstalling glmmADMB)
or at least give the results of sessionInfo() ?

  Ben Bolker



From bbolker at gmail.com  Wed Feb 29 15:58:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Feb 2012 14:58:21 +0000 (UTC)
Subject: [R-sig-ME] How to calculate predictions
References: <1330376551.19171.23.camel@localhost> ,
	<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl> ,
	<1330382568.19171.27.camel@localhost>
	<SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
	<1330385464.19171.31.camel@localhost>
	<loom.20120228T052455-583@post.gmane.org>
	<1330455276.13060.3.camel@localhost>
Message-ID: <loom.20120229T155445-887@post.gmane.org>

Stuart Luppescu <slu at ...> writes:

> 
> On Tue, 2012-02-28 at 04:26 +0000, Ben Bolker wrote:
> > Stuart Luppescu <slu at ...> writes:
> > 
> > > 
> > > On Mon, 2012-02-27 at 16:07 -0700, Jake Westfall wrote:
> > > 
> > > I believe that fitted() is giving fitted values for each observation. 
> > > 
> > >  length(fitted(math.lme3))
> > > [1] 520573
> > >  length(unique(math.lme3 <at> frame$sid))
> > > [1] 236994
> > > 
> > > I have about 520,000 observations nested within 236,994 students. I want
> > > a fitted value for each student at age 15 (which may or may not be
> > > actually observed).
> > 
> >   Have you looked at the code on http://glmm.wikidot.com/faq ... ?
> 
> Yes, I have. Unless I'm missing something (which is very possible) it
> doesn't seem that the code includes the individual random effects.

  Hmm.  If you're comfortable doing a bit of coding, you can certainly
extract the random effects with ranef() and apply them to the predictions ...
if you wanted to get fancy you could create a sparse model matrix yourself
and use it (although in this case just taking ranef(math.lme3)[[1]]
out manually and doing the sensible thing with it should work.

> 
> > Also, the new lme4Eigen package does have a ?predict method ...
> 
> Doesn't seem to be available on CRAN -- only on R-forge? I don't think I
> can convince our sysadmin to install a non-stable package.
> 

  Yes, it's on r-forge.

  Maybe you can try installing it to a local directory and seeing
if it does what you want?

  Ben Bolker



From bbolker at gmail.com  Wed Feb 29 19:41:19 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Feb 2012 13:41:19 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
Message-ID: <4F4E714F.3020001@gmail.com>


  (1) detach("package:glmmadmb") , or start a clean R session, before
trying to update or install (you generally can't change a package while
it's loaded; (2) I'm not sure what's up with the directory not being
writable.  Usually if R finds that the package directory isn't writable
it offers to install to a different directory for you ...

   What happens if you simply update.packages() [without specifying
r-forge, i.e. update your regular packages]?  If not, then there's
something else funny about your R installation.

  I think I would definitely try an install.packages() in a clean R
session before trying to do any more diagnosis/troubleshooting.
(glmmADMB version 0.3 is really old -- where did you get it?)

  Ben Bolker

On 12-02-29 10:12 AM, RH Gibson wrote:
> I have done what you suggested and here is what happened:
> 
>> update.packages(repos="http://r-forge.r-project.org")
> glmmADMB :
>  Version 0.3 installed in C:/Program Files/R/R-2.14.1/library
>  Version 0.7.2.6 available at http://r-forge.r-project.org
> Update (y/N/c)?  y
> lattice :
>  Version 0.20-0 installed in C:/Program Files/R/R-2.14.1/library
>  Version 0.20-3 available at http://r-forge.r-project.org
> Update (y/N/c)?  y
> Matrix :
>  Version 1.0-2 installed in C:/Program Files/R/R-2.14.1/library
>  Version 1.0-4 available at http://r-forge.r-project.org
> Update (y/N/c)?  y
> Warning in install.packages(update[instlib == l, "Package"], l, contriburl
> = contriburl,  :
>   'lib = "C:/Program Files/R/R-2.14.1/library"' is not writable
> Error in install.packages(update[instlib == l, "Package"], l, contriburl =
> contriburl,  :
>   unable to install packages
>> sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] glmmADMB_0.7.2.6 R2admb_0.7.5     MASS_7.3-16
> 
> loaded via a namespace (and not attached):
> [1] grid_2.14.1    lattice_0.20-0 nlme_3.1-102   tools_2.14.1
> 
> 
> On Wed, February 29, 2012 2:54 pm, Ben Bolker wrote:
>> RH Gibson <Rachel.Gibson at ...> writes:
>>
>>>
>>> I am trying to use glmmadmb to build a model.
>>>
>>> Code used:
>>>
>>> m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+
>>> fsize+(1|Site),family="nbinom")
>>>
>>> "Site" is a categorical variable and is a factor (non numeric).
>>>
>>> I get the error message:
>>>
>>> Error in eval(expr, envir, enclos) : could not find function
>>> "Droplevels"
>>> In addition: Warning message:
>>> In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
>>>
>>> Can anyone tell me why I am getting this message, please?
>>
>>   What version are you using?  This is reminiscent of a problem with
>> a recent (but not-the-very-latest) version.  Can you try
>>
>> update.packages(repos="http://r-forge.r-project.org")
>>
>> (or just reinstalling glmmADMB)
>> or at least give the results of sessionInfo() ?
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>



From rimian85 at hotmail.com  Thu Mar  1 09:42:43 2012
From: rimian85 at hotmail.com (rajibul islam)
Date: Thu, 1 Mar 2012 19:42:43 +1100
Subject: [R-sig-ME] partner
Message-ID: <BLU141-W1515AA4FC6A3C0B95DCD50D26C0@phx.gbl>


hey pal I discovered this incredible program it truly made my life worry-free

Im make $4,000 /month with an easy to use program and its risk free receiving the kit which practically costs nothing

http://tiny.cc/jy7tv

Sign up to get your kit before the holidays

Your pal
rajibul









































 		 	   		  


From hcspol at gmail.com  Thu Mar  1 12:44:40 2012
From: hcspol at gmail.com (Chang Seok Han)
Date: Thu, 1 Mar 2012 22:44:40 +1100
Subject: [R-sig-ME] Comparison of random coefficients between groups
Message-ID: <CACG6zYHSzvwmHuk9+ZEANndYuXjACExp-TLVCBC_FkfbmX8pig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120301/79949d08/attachment-0001.pl>

From cabrittain at ucdavis.edu  Thu Mar  1 04:21:14 2012
From: cabrittain at ucdavis.edu (Claire Brittain)
Date: Wed, 29 Feb 2012 19:21:14 -0800
Subject: [R-sig-ME] decimal data with nested random effects
Message-ID: <00ab01ccf75a$5c1b92d0$1452b870$@edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120229/6c51cba1/attachment-0001.pl>

From Rachel.Gibson at bristol.ac.uk  Wed Feb 29 11:06:55 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson)
Date: Wed, 29 Feb 2012 10:06:55 -0000 (GMT)
Subject: [R-sig-ME] General question about GLMM and heterogeneity of variance
Message-ID: <50574.82.32.40.117.1330510015.squirrel@webmail.bris.ac.uk>

GibsonR <rachel.gibson <at> bristol.ac.uk> writes:

>
> My data have heterogeneity of variance (in a categorical variable), do I
need
> to specify a variance structure accounting for this in my model or do GLMMs
> by their nature account for such heterogeneity (as a result of using
> deviances rather than variances)? And if I do need to do this, how do I do
> it (e.g. using something like the VarIdent function in nlme) and in what
> package?


Added 29.02.2012


Sorry, I was not particularly clear.

 I ran my data through a GLM (the response variable is a proportion, and I
ignored the random effects for the purposes of data exploration), and
plotted the residuals against each of my predictor variables (some of
which are continuous, some categorical). The heterogeneity showed up in
the residuals of the response variable plotted against a categorical
predictor variable (Insect functional group).

Do I need to use something other than the GLMM in this case?

Thank you very much for your help.

--



From bates at stat.wisc.edu  Thu Mar  1 15:46:32 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Mar 2012 08:46:32 -0600
Subject: [R-sig-ME] partner
In-Reply-To: <BLU141-W1515AA4FC6A3C0B95DCD50D26C0@phx.gbl>
References: <BLU141-W1515AA4FC6A3C0B95DCD50D26C0@phx.gbl>
Message-ID: <CAO7JsnRJMWk0UfaRG6AT=dYDEPt1KHObaxsYvyLr6r2=mJe01w@mail.gmail.com>

Looks like Rajib's hotmail account has been compromised.  I have
changed his status on the list to require moderator approval of his
postings.

On Thu, Mar 1, 2012 at 2:42 AM, rajibul islam <rimian85 at hotmail.com> wrote:
>
> hey pal I discovered this incredible program it truly made my life worry-free
>
> Im make $4,000 /month with an easy to use program and its risk free receiving the kit which practically costs nothing
>
> http://tiny.cc/jy7tv
>
> Sign up to get your kit before the holidays
>
> Your pal
> rajibul
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Thu Mar  1 17:13:07 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 01 Mar 2012 11:13:07 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <4F4FA013.4090804@gmail.com>

  I figured out the problem.

  I almost always use glmmadmb with the data= argument, putting my data
into a data frame rather than having my variables attach()ed (almost
always a bad idea) or floating around in the global workspace.  If you
do this:

mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")

it ought to work.  However, it *should* work the way you specified -- I
will work on fixing the bug.

  thanks
    Ben Bolker


On 12-03-01 09:19 AM, RH Gibson, School Biological Sciences wrote:
> Hi Ben - latest attempt below . . .
> 
> 
>> local({pkg <- select.list(sort(.packages(all.available = 
> TRUE)),graphics=TRUE)
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> Loading required package: MASS
> Loading required package: R2admb
> 
> Attaching package: 'glmmADMB'
> 
> The following object(s) are masked from 'package:R2admb':
> 
>    stdEr
> 
>> data1<-read.table("F:/work/Gottingen2010/Pollen 
> analysis/beepollenq.txt",header=T)
>> attach(data1)
>>
>>
> m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+(1|Site),family="nbinom")
> 
> Error in eval(expr, envir, enclos) : could not find function "Droplevels"
> In addition: Warning message:
> In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
>> summary(m1)
> Error in summary(m1) : object 'm1' not found
>> list.files(.libPaths(),pattern="glmm",full.names=TRUE)
> [1] "C:/Program Files/R/R-2.14.2/library/glmmADMB"
>>  i1 <- installed.packages()
>> i1[grep("^glmm",rownames(i1)]
> Error: unexpected ']' in "i1[grep("^glmm",rownames(i1)]"
>>   sessionInfo()
> R version 2.14.2 (2012-02-29)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] glmmADMB_0.7.2.6 R2admb_0.7.5     MASS_7.3-17
> 
> loaded via a namespace (and not attached):
> [1] grid_2.14.2    lattice_0.20-0 nlme_3.1-103   tools_2.14.2
>>
> 
> 
> Rachel.
> 
> --On 01 March 2012 08:12 -0500 Ben Bolker <bbolker at gmail.com> wrote:
> 
>> On 12-03-01 04:49 AM, RH Gibson, School Biological Sciences wrote:
>>> Tried this morning on work PC, with latest versions of R and glmmADMB:
>>>
>>>
>>>>
>>> m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize
>>> +(1|Site)+offset(log(Total.grains)),family="nbinom")
>>>
>>> Error in eval(expr, envir, enclos) : could not find function
>>> "Droplevels"
>>> In addition: Warning message:
>>> In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
>>>
>>>
>>>> list.files(.libPaths(),pattern="glmm",full.names=TRUE)
>>> [1] "C:/Program Files/R/R-2.14.2/library/glmmADMB"
>>>> i1 <- installed.packages()
>>>> i1[grep("^glmm",rownames(i1),]
>>> Error: unexpected ']' in "i1[grep("^glmm",rownames(i1),]"
>>
>>   extra comma before the final square bracket: try
>>
>> i1[grep("^glmm",rownames(i1)]
>>
>>   The first command at least confirms for me that you only have one copy
>> of glmmADMB installed.  What are the results of
>>
>>   sessionInfo()
>>
>>  when you have glmmADMB installed?
>>
>>   Ben
>>>
>>>
>>>
>>>
>>>
>>> --On 29 February 2012 15:32 -0500 Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>>> i1[grep("^glmm",rownames(i1)),]
>>>
>>>
>>>
>>> ----------------------
>>> RH Gibson, School Biological Sciences
>>> Rachel.Gibson at bristol.ac.uk
>>
> 
> 
> 
> ----------------------
> RH Gibson, School Biological Sciences
> Rachel.Gibson at bristol.ac.uk



From roby.joehanes at nih.gov  Thu Mar  1 18:44:30 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 12:44:30 -0500
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
In-Reply-To: <CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
	<CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
Message-ID: <AE8B81FD-D308-40EA-ABC8-2DB8293E9864@nih.gov>

Dr Bates,

Thank you for your reply.

I discovered a bug on your lme4Eigen's refit function. This is on version 0.9996875-9 (Description revision 169). I hope I got this right. If the original data matrix has some missing data in it, somehow the X and Z matrices (and y column) are correctly trimmed (i.e., the rows with missing data are removed). However, if I fit it with another y column, it reports error due to length mismatch. The error is as follows:
Error: length(newresp <- as.numeric(as.vector(newresp))) == length(rr$y) is not TRUE

Should I try the latest version and see if this bug has been fixed?

Also, will update method speed up computation if I changed the X (or Z) matrix a little bit by swapping or adding up to three columns (from about 40+ columns)?

Thank you,
Roby

On Feb 27, 2012, at 6:03 PM, Douglas Bates wrote:

> Yes, check out the refit function.  I just saw that the documentation
> suffers from cut-and-paste errors but the general idea is to give a
> fitted model a new response and run only the optimization step.



From bbolker at gmail.com  Thu Mar  1 19:10:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 1 Mar 2012 18:10:08 +0000 (UTC)
Subject: [R-sig-ME] error message using glmmadmb
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com>
Message-ID: <loom.20120301T190854-931@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

 [snip]

> If you do this:
> 
> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")
> 
> it ought to work.  However, it *should* work the way you specified -- I
> will work on fixing the bug.
> 
>   thanks
>     Ben Bolker

  This should be fixed now (i.e. in glmmADMB 0.7.2.7).
  It's still a good idea to use the data= argument.



From bbolker at gmail.com  Thu Mar  1 20:05:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 1 Mar 2012 19:05:34 +0000 (UTC)
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
	<CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
	<AE8B81FD-D308-40EA-ABC8-2DB8293E9864@nih.gov>
Message-ID: <loom.20120301T191141-982@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> I discovered a bug on your lme4Eigen's refit function. 
> This is on version 0.9996875-9 (Description
> revision 169). I hope I got this right. If the original data
>  matrix has some missing data in it, somehow the X
> and Z matrices (and y column) are correctly trimmed (i.e., the rows
>  with missing data are removed).
> However, if I fit it with another y column, it reports error due 
> to length mismatch. The error is as follows:
> Error: length(newresp <- as.numeric(as.vector(newresp))) == length(rr$y) 
> is not TRUE
> 
> Should I try the latest version and see if this bug has been fixed?

  It probably hasn't.  It would be very helpful if you could send a small
self-contained example to lme4-authors <at> r-forge.wu-wien.ac.at --
we could probably make one up ourselves, but it would be quicker/
more motivational if you did it.

> 
> Also, will update method speed up computation
>  if I changed the X (or Z) matrix a little bit by swapping or
> adding up to three columns (from about 40+ columns)? 

  Probably not -- refit saves time by (1) starting from previous
starting values and (2) not having to rebuild X and Z components.
You could do #1 yourself by doing something like setting

update(...,start=getME(prevfit,"theta"),...)

(I think).



From roby.joehanes at nih.gov  Thu Mar  1 20:11:30 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 14:11:30 -0500
Subject: [R-sig-ME] Contribution to lme4Eigen
Message-ID: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>

Hi lme4 developers,

I hope I can contribute to something positive to the community. I noticed that even in the latest version of lme4Eigen the lmer function only use Nelder-Mead optimizer. I would like to get Bobyqa optimizer back as an option (because I really like Bobyqa optimizer). So, I patched the code a little bit. I used the (hopefully) latest revision from SVN version 1631. I also added control for xst and xt factor multiplier (a FIXME item list). I hope this change is also acceptable. If you feel I am ignorant of your code style, I apologize.

Here is the code (only the lmer function). I clearly marked my changes. If you need a diff file with the current HEAD, I'll be happy to provide you with one. The function seems to be running happily without error or warning on my machine. I hope the changes can make it to the main trunk.

Sincerely,
Roby


From roby.joehanes at nih.gov  Thu Mar  1 20:15:54 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 14:15:54 -0500
Subject: [R-sig-ME] Contribution to lme4Eigen
In-Reply-To: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
Message-ID: <2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>

Ouch. Apparently, the mail daemon ate my attachment.

So, here it is (pasted). Sorry for the mail bomb.

-----------------------
lmer <- function(formula, data, REML = TRUE, sparseX = FALSE,
control = list(), start = NULL,
verbose = 0L, subset, weights, na.action, offset,
contrasts = NULL, devFunOnly=FALSE, optimizer=c("NelderMead","bobyqa"), ...)
{
    if (sparseX) warning("sparseX = TRUE has no effect at present")
    mf <- mc <- match.call()
    ## '...' handling up front, safe-guarding against typos ("familiy") :
    if(length(l... <- list(...))) {
		if (!is.null(l...$family)) {  # call glmer if family specified
			mc[[1]] <- as.name("glmer")
			return(eval(mc, parent.frame()) )
		}
		## Check for method argument which is no longer used
		if (!is.null(method <- l...$method)) {
			msg <- paste("Argument", sQuote("method"), "is deprecated.")
			if (match.arg(method, c("Laplace", "AGQ")) == "Laplace") {
				warning(msg)
				l... <- l...[names(l...) != "method"]
			} else stop(msg)
		}
		if(length(l...))
	    warning("extra argument(s) ",
		paste(sQuote(names(l...)), collapse=", "),
		" disregarded")
    }
	
    stopifnot(length(formula <- as.formula(formula)) == 3)
    if (missing(data)) data <- environment(formula)
	# evaluate and install the model frame :
    m <- match(c("data", "subset", "weights", "na.action", "offset"),
	names(mf), 0)
    mf <- mf[c(1, m)]
    mf$drop.unused.levels <- TRUE
    mf[[1]] <- as.name("model.frame")
    fr.form <- subbars(formula) # substituted "|" by "+" -
    environment(fr.form) <- environment(formula)
    mf$formula <- fr.form
    fr <- eval(mf, parent.frame())
	# random effects and terms modules
    reTrms <- mkReTrms(findbars(formula[[3]]), fr)
    if (any(unlist(lapply(reTrms$flist, nlevels)) >= nrow(fr)))
	stop("number of levels of each grouping factor must be less than number of obs")
    ## fixed-effects model matrix X - remove random effects from formula:
    form <- formula
    form[[3]] <- if(is.null(nb <- nobars(form[[3]]))) 1 else nb
    X <- model.matrix(form, fr, contrasts)#, sparse = FALSE, row.names = FALSE) ## sparseX not yet
    p <- ncol(X)
    if ((qrX <- qr(X))$rank < p)
	stop(gettextf("rank of X = %d < ncol(X) = %d", qrX$rank, p))
    rho <- new.env(parent=parent.env(environment()))
    rho$pp <- do.call(merPredD$new, c(reTrms[c("Zt","theta","Lambdat","Lind")], n=nrow(X), list(X=X)))
    rho$resp <- mkRespMod(fr, if(REML) p else 0L)
	
    devfun <- mkdevfun(rho, 0L)
    devfun(reTrms$theta) # one evaluation to ensure all values are set
	
    if (devFunOnly) return(devfun)
	
    lower <- reTrms$lower
	# RJ's changes begin
	opt <- switch(match.arg(optimizer),
		bobyqa = {
			if(!is.numeric(control$rhobeg)) control$rhobeg <- 0.0002
			if(!is.numeric(control$rhoend)) control$rhoend <- 2e-7
			rho$control <- control
			# Delete unused options to prevent warning from showing up
			control$FtolAbs <- NULL
			control$FtolRel <- NULL
			bobyqa(rho$pp$theta, devfun, lower, control=control)
		},
		NelderMead = {
			## FIXME: this code is replicated in lmer/glmer/nlmer ...
			## it seems good to have it in R rather than C++ code but maybe it should go within Nelder_Mead() ??
			control$iprint <- switch(as.character(min(verbose,3L)), "0"=0, "1"=20,"2"=10,"3"=1)
			xst <- rep.int(0.1, length(lower))
			# RJ -- allow user control of xst, xt
			ctl <- control
			if(!is.numeric(control$xstFactor))
				xstFactor <- 0.2
			else
				xstFactor <- control$xstFactor
			if(!is.numeric(control$xtFactor))
				xtFactor <- 0.0001
			else
				xtFactor <- control$xtFactor
			ctl$xstFactor <- NULL
			ctl$xtFactor <- NULL
			Nelder_Mead(devfun, x0=rho$pp$theta, xst=xstFactor*xst, xt=xst*xtFactor, lower=lower, control=ctl)
		})

	if(optimizer=="NelderMead") {
	    if (opt$ierr < 0L) {
			if (opt$ierr > -4L)
			stop("convergence failure, code ", opt$ierr, " in NelderMead")
			else
			warning("failure to converge in", opt$control$maxfun, "evaluations")
		}
	} else if (optimizer=="bobyqa") {
		if (opt$ierr > 0L)
			warning("convergence problem, code ", opt$ierr, " in bobyqa")
	}
	# RJ's changes end
    mkMerMod(environment(devfun), opt, reTrms, fr, mc)
}## { lmer }



On Mar 1, 2012, at 2:11 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi lme4 developers,
> 
> I hope I can contribute to something positive to the community. I noticed that even in the latest version of lme4Eigen the lmer function only use Nelder-Mead optimizer. I would like to get Bobyqa optimizer back as an option (because I really like Bobyqa optimizer). So, I patched the code a little bit. I used the (hopefully) latest revision from SVN version 1631. I also added control for xst and xt factor multiplier (a FIXME item list). I hope this change is also acceptable. If you feel I am ignorant of your code style, I apologize.
> 
> Here is the code (only the lmer function). I clearly marked my changes. If you need a diff file with the current HEAD, I'll be happy to provide you with one. The function seems to be running happily without error or warning on my machine. I hope the changes can make it to the main trunk.
> 
> Sincerely,
> Roby



From roby.joehanes at nih.gov  Thu Mar  1 20:21:35 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 14:21:35 -0500
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
In-Reply-To: <loom.20120301T191141-982@post.gmane.org>
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
	<CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
	<AE8B81FD-D308-40EA-ABC8-2DB8293E9864@nih.gov>
	<loom.20120301T191141-982@post.gmane.org>
Message-ID: <2CB1E4E0-3246-4EFE-AECC-A53CA95F2796@nih.gov>

Hi Ben,

On Mar 1, 2012, at 2:05 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
> 
>> I discovered a bug on your lme4Eigen's refit function. 
>> This is on version 0.9996875-9 (Description
>> revision 169). I hope I got this right. If the original data
>> matrix has some missing data in it, somehow the X
>> and Z matrices (and y column) are correctly trimmed (i.e., the rows
>> with missing data are removed).
>> However, if I fit it with another y column, it reports error due 
>> to length mismatch. The error is as follows:
>> Error: length(newresp <- as.numeric(as.vector(newresp))) == length(rr$y) 
>> is not TRUE
>> 
>> Should I try the latest version and see if this bug has been fixed?
> 
>  It probably hasn't.  It would be very helpful if you could send a small
> self-contained example to lme4-authors <at> r-forge.wu-wien.ac.at --
> we could probably make one up ourselves, but it would be quicker/
> more motivational if you did it.

Unfortunately, my data is considered classified. I am not authorized to give one out. I hope I can compose an example real soon.

>> 
>> Also, will update method speed up computation
>> if I changed the X (or Z) matrix a little bit by swapping or
>> adding up to three columns (from about 40+ columns)? 
> 
>  Probably not -- refit saves time by (1) starting from previous
> starting values and (2) not having to rebuild X and Z components.
> You could do #1 yourself by doing something like setting
> 
> update(...,start=getME(prevfit,"theta"),...)
> 
> (I think).

Thank you. I will try it out.

Sincerely,
Roby


From roby.joehanes at nih.gov  Thu Mar  1 21:17:54 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 15:17:54 -0500
Subject: [R-sig-ME] Contribution to lme4Eigen
In-Reply-To: <2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
	<2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>
Message-ID: <C6BC780B-E522-4497-9F74-CA2AB379E188@nih.gov>

Apologies again. I submitted the changes to the tracker here:
https://r-forge.r-project.org/tracker/index.php?func=detail&aid=1861&group_id=60&atid=300

On Mar 1, 2012, at 2:15 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Ouch. Apparently, the mail daemon ate my attachment.
> 
> So, here it is (pasted). Sorry for the mail bomb.
<snip>


From bbolker at gmail.com  Thu Mar  1 21:32:48 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 1 Mar 2012 20:32:48 +0000 (UTC)
Subject: [R-sig-ME] Contribution to lme4Eigen
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
	<2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>
Message-ID: <loom.20120301T212041-625@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> 
> Ouch. Apparently, the mail daemon ate my attachment.
> 

  Would you be willing to send this as an SVN diff to
lme4-authors <at> r-forge.wu-wien.ac.at ?  Or post it to the issue tracker
on r-forge ?

  Ben



From roby.joehanes at nih.gov  Thu Mar  1 21:44:58 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 15:44:58 -0500
Subject: [R-sig-ME] Contribution to lme4Eigen
In-Reply-To: <loom.20120301T212041-625@post.gmane.org>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
	<2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>
	<loom.20120301T212041-625@post.gmane.org>
Message-ID: <6A7516BA-B82A-42BA-B7FF-05CD89A6EA55@nih.gov>

Hi Ben,

Thank you for the reply. I've added the diff patch against SVN rev 1631 in the issue tracker:
https://r-forge.r-project.org/tracker/download.php/60/300/1861/147/lmer-svn1631-patch.txt

See the corresponding page here:
https://r-forge.r-project.org/tracker/index.php?func=detail&aid=1861&group_id=60&atid=300

Also attached (cc-ed to the e-mail you mentioned). Apologies about the line ending. I am currently using a Mac.

Roby

On Mar 1, 2012, at 3:32 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
>
>>
>> Ouch. Apparently, the mail daemon ate my attachment.
>>
>
>  Would you be willing to send this as an SVN diff to
> lme4-authors <at> r-forge.wu-wien.ac.at ?  Or post it to the issue tracker
> on r-forge ?
>
>  Ben

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lmer-svn1631-patch.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120301/385ad7d1/attachment-0001.txt>

From rlaforge at mail.uri.edu  Thu Mar  1 23:20:24 2012
From: rlaforge at mail.uri.edu (Robert Laforge)
Date: Thu, 01 Mar 2012 17:20:24 -0500
Subject: [R-sig-ME] glmmADMB package
Message-ID: <000001ccf7f9$8249e520$86ddaf60$@uri.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120301/5fdc5687/attachment-0001.pl>

From roby.joehanes at nih.gov  Thu Mar  1 23:52:07 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 17:52:07 -0500
Subject: [R-sig-ME] PedigreeMM question
In-Reply-To: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
Message-ID: <66CC0141-0818-4781-A353-DB6679C6E928@nih.gov>

Hi,

I would like to do something like this in pedigreemm:

result <- pedigreemm(y ~ ...<the other factors>... + (1 | id), data=mydata, pedigree=list(id=mypedigree), na.action=na.omit)

To my impression after reading pedigreemm's code, I need several observations with the same ID number and I cannot have each observation to have a different ID. Is this correct? Then, is it possible to have 1 observation having 1 ID? I don't think it is, given how the Z matrix for ID is encoded in lmer (and thereby pedigreemm) and how examples in the paper accompanying the package are constructed. Maybe I am incorrect or maybe I am doing an incorrect encoding.

What I am getting at is genome-wide association study (GWAS)-like analysis that account for familial correlation matrix. Here, each observation comes from one individual, which is associated an individual ID and a pedigree ID. One pedigree ID contains essentially a family tree from great grandparents down to the little ones. The pedigree is somewhat complicated by step-parents (indicated by siblings sharing one parent, but not the other) and a few members of one pedigree intermarrying those of another. I have the inclination to specify the model as:

result <- pedigreemm(y ~ ...<the other factors>... + (1 | ped_id), data=mydata, pedigree=list(ped_id =mypedigree), na.action=na.omit)

To me, it doesn't seem to be correct since pedigreemm will treat observations having the same ped_id as repeat observations. If I understand the code correctly, pedigreemm will tie ped_id with the mypedigree$id. I cannot put in individual IDs into mypedigree$id since it will make pedigreemm associate IDs incorrectly. However, I cannot put in pedigree ID into mypedigree$id either since one pedigree ID consists of the whole family tree.

The questions are: How can I deal with this problem? Should I break up the pedigree into nuclear families? How can I deal with the step-parents and intermarriage complications above? If pedigreemm was not designed for problems of this class, which other packages should I look into?

Thank you,
Roby


From chris at trickysolutions.com.au  Fri Mar  2 00:48:01 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 2 Mar 2012 10:48:01 +1100
Subject: [R-sig-ME] General question about GLMM and heterogeneity of
	variance
In-Reply-To: <50574.82.32.40.117.1330510015.squirrel@webmail.bris.ac.uk>
References: <50574.82.32.40.117.1330510015.squirrel@webmail.bris.ac.uk>
Message-ID: <-6156322436662673238@unknownmsgid>

How bad is it? And do u have equal sample size in each cat group?

I ask because if the sample sizes are very different it may look like
the larger sample sizes have greater variance but this is only because
they have more sample and it's therefore more likely u will see
extreme values.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 02/03/2012, at 1:45, RH Gibson <Rachel.Gibson at bristol.ac.uk> wrote:

> GibsonR <rachel.gibson <at> bristol.ac.uk> writes:
>
>>
>> My data have heterogeneity of variance (in a categorical variable), do I
> need
>> to specify a variance structure accounting for this in my model or do GLMMs
>> by their nature account for such heterogeneity (as a result of using
>> deviances rather than variances)? And if I do need to do this, how do I do
>> it (e.g. using something like the VarIdent function in nlme) and in what
>> package?
>
>
> Added 29.02.2012
>
>
> Sorry, I was not particularly clear.
>
> I ran my data through a GLM (the response variable is a proportion, and I
> ignored the random effects for the purposes of data exploration), and
> plotted the residuals against each of my predictor variables (some of
> which are continuous, some categorical). The heterogeneity showed up in
> the residuals of the response variable plotted against a categorical
> predictor variable (Insect functional group).
>
> Do I need to use something other than the GLMM in this case?
>
> Thank you very much for your help.
>
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jwiley.psych at gmail.com  Fri Mar  2 03:03:49 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 1 Mar 2012 18:03:49 -0800
Subject: [R-sig-ME] glmmADMB package
In-Reply-To: <000001ccf7f9$8249e520$86ddaf60$@uri.edu>
References: <000001ccf7f9$8249e520$86ddaf60$@uri.edu>
Message-ID: <FC9F1C2B-2A9A-45D1-953B-927574412864@gmail.com>

Hi Bob,

I would recommend you upgrade to R 2.14.1 (it's easy and free!).  What OS are you using?  It is relevant for this type of problem.  I'm not familiar with otter research, but I have not had difficulty with glmmadmb from r forge on win x64.

Give us some more details on your version of R, what you tried, and the error and we should be able to help out.

Cheers,

Josh 

On Mar 1, 2012, at 14:20, "Robert Laforge" <rlaforge at mail.uri.edu> wrote:

> Hi,   I am using R version 2.14 and I am having trouble installing glmmADMB
> that I just downloaded from Otter Research.   Do you know if this package
> works with V.2.14?    Thanks,   Bob
> 
> 
> 
> Robert Laforge, Sc.D.
> 
> Professor of Behavioral Epidemiology
> 
> Department of Psychology
> 
> Director of Survey Research, CPRC, Rm. 48W
> 
> University of Rhode Island
> 
> Kingston, RI 02818.
> 
> <mailto:rlaforge at uri.edu> rlaforge at uri.edu
> 
> (401) 874-5571
> 
> Fax (401) 874-5562
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Fri Mar  2 03:08:21 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 2 Mar 2012 12:08:21 +1000 (EST)
Subject: [R-sig-ME] PedigreeMM question
In-Reply-To: <66CC0141-0818-4781-A353-DB6679C6E928@nih.gov>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
	<66CC0141-0818-4781-A353-DB6679C6E928@nih.gov>
Message-ID: <Pine.LNX.4.64.1203021157430.20151@orpheus.qimr.edu.au>

On Thu, 1 Mar 2012, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi,
>
> I would like to do something like this in pedigreemm:
>
> To my impression after reading pedigreemm's code, I need several 
> observations with the same ID number and I cannot have each observation 
> to have a different ID. Is this correct?
>
> What I am getting at is genome-wide association study (GWAS)-like 
> analysis that account for familial correlation matrix. Here, each 
> observation comes from one individual, which is associated an individual 
> ID and a pedigree ID. One pedigree ID
>
> The questions are: How can I deal with this problem? Should I break up 
> the pedigree into nuclear families? How can I deal with the step-parents 
> and intermarriage complications above? If pedigreemm was not designed 
> for problems of this class, which other packages should I look into?
>

The pedigree() constructor is set up as animal breeders do things: the 
entire dataset is one big pedigree, even though there may be subcomponents 
that do not connect to one another.  This is why sparse matrix 
representations are used.  So, you just need unique IDs for everybody (eg 
concatenate pedigree with individual ID).  This allows for intermarriage 
etc.  If you think step-parents transmit your phenotype to step-children, 
then you need to add in a family environmental random effect (ie common to 
all members of an extended family, or perhaps just to that "nongenetic" 
nuclear family).  If you have repeat measures on individuals, then you 
include multiple records with the same unique ID.

Cheers, David Duffy

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Fri Mar  2 05:04:30 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Mar 2012 04:04:30 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB package
References: <000001ccf7f9$8249e520$86ddaf60$@uri.edu>
Message-ID: <loom.20120302T050202-921@post.gmane.org>

Robert Laforge <rlaforge at ...> writes:

> 
> Hi,   I am using R version 2.14 and I am having trouble installing glmmADMB
> that I just downloaded from Otter Research.   Do you know if this package
> works with V.2.14?    Thanks,   Bob
> 

  The version on the Otter Research page is very old -- I think the web page
tells you that.   (Did you get it from
http://otter-rsch.com/admbre/examples/glmmadmb/glmmADMB.html , which does indeed
have a banner to that effect?)  http://glmmadmb.r-forge.r-project.org/ is the
new / authoritative web page.

  Ben Bolker



From bbolker at gmail.com  Fri Mar  2 05:11:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Mar 2012 04:11:34 +0000 (UTC)
Subject: [R-sig-ME] decimal data with nested random effects
References: <00ab01ccf75a$5c1b92d0$1452b870$@edu>
Message-ID: <loom.20120302T050527-235@post.gmane.org>

Claire Brittain <cabrittain at ...> writes:

> I have some decimal data (a diversity index) with nested random effects
> (sites within years).
> 
> There are a lot of zeros in the diversity index (19 out of 61 data points).
> 
> I would like to investigate the effects of two variables (one continuous,
> one categorical) on the diversity index.
> 
> I am more familiar with modeling count data and would set up a mixed model
> with Poisson error and a subject level random variable for overdispersion
> (there is one data point per site, per year so in the model below the random
> effects are at the subject level).
> 
> model1<-lmer(DiversityIndex~categorical_variable*continuous_variable+(1|Year
> /Site),family=poisson)
> 
> However I get the error that the poisson distribution is for integers only -
> although if I look at the summary of the model the output still looks
> sensible. Can I use the poisson distribution on non-integer data?

  It's dicey.  You _could_ make the argument that you're just trying
to get the mean-variance relationship right (although in that case
you would probably be better off using lme with a varPower() variance
structure ...)

> The diversity index cannot be transformed to normal and I need to keep the
> nested random effects in the model so I am not sure what error distribution
> I should be using for non integer, non normal data with nested random
> effects?
> 
> Any suggestions as to the type of model/family I should be using would be
> much appreciated.

  It's pretty tough.  Tweedie distributions are possible (and there is
a cplm package that implements mixed models with Tweedie distributions),
but with a non-huge data set I might be tempted just to use something
simple (e.g. linear models) and do some kind of resampling solution
(bootstrapping, permutation test, etc.) to get confidence intervals/p
values -- the hard part being that you have to be careful with
resampling when you have blocking in your data.



From bbolker at gmail.com  Fri Mar  2 05:18:48 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Mar 2012 04:18:48 +0000 (UTC)
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
	<CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
	<AE8B81FD-D308-40EA-ABC8-2DB8293E9864@nih.gov>
	<loom.20120301T191141-982@post.gmane.org>
	<2CB1E4E0-3246-4EFE-AECC-A53CA95F2796@nih.gov>
Message-ID: <loom.20120302T051743-306@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> 
> Hi Ben,
> 
> On Mar 1, 2012, at 2:05 PM, Ben Bolker wrote:
> 
> > Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
> > 
> >> I discovered a bug on your lme4Eigen's refit function. 
> >> This is on version 0.9996875-9 (Description
> >> revision 169). I hope I got this right. If the original data
> >> matrix has some missing data in it, somehow the X
> >> and Z matrices (and y column) are correctly trimmed (i.e., the rows
> >> with missing data are removed).
> >> However, if I fit it with another y column, it reports error due 
> >> to length mismatch. The error is as follows:
> >> Error: length(newresp <- as.numeric(as.vector(newresp))) == length(rr$y) 
> >> is not TRUE
> >> 
> >> Should I try the latest version and see if this bug has been fixed?
> > 
> >  It probably hasn't.  It would be very helpful if you could send a small
> > self-contained example to lme4-authors <at> r-forge.wu-wien.ac.at --
> > we could probably make one up ourselves, but it would be quicker/
> > more motivational if you did it.
> 
> Unfortunately, my data is considered classified. 
> I am not authorized to give one out. I hope I can compose an
> example real soon.

  It's not hard to make up an example:

library(lme4Eigen)
d <- data.frame(x=runif(100),f=factor(rep(1:10,10)))
set.seed(101)
u <- rnorm(10)
d <- transform(d,y=rnorm(100,1+2*x+u[f],0.2))
d[c(3,5,7),"x"] <- NA

fm1 <- lmer(y~x+(1|f),data=d)

refit(fm1,runif(100))


   The obvious workaround for now is to use na.omit() on the
data in advance ...



From amelie.pinet at gmail.com  Fri Mar  2 14:58:32 2012
From: amelie.pinet at gmail.com (amelie pinet)
Date: Fri, 2 Mar 2012 14:58:32 +0100
Subject: [R-sig-ME] error in nlme()
Message-ID: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120302/5fdc312f/attachment-0001.pl>

From bbolker at gmail.com  Fri Mar  2 16:41:27 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Mar 2012 15:41:27 +0000 (UTC)
Subject: [R-sig-ME] error in nlme()
References: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>
Message-ID: <loom.20120302T163732-975@post.gmane.org>

amelie pinet <amelie.pinet at ...> writes:

> 
> Hello,
> When using nlme () function I have a error message that I don't understand:
> 
> Mod2 <- nlme(Nb_phyto ~dbleseg1(JourJulien,a0,b0,a1,T,a0a),data =
> dataAna,fixed=a0+b0+a1+T+a0a~1,
> random=pdDiag(b0~1),
> start=c(a0=a0init,b0=b0init,a1=a1init,T=Tinit,a0a=a0ainit),na.action=na.omit)
> 
> Erreur dans X[, fmap[[nm]]] <- gradnm :
>   le nombre d'objets ? remplacer n'est pas multiple de la taille du
> remplacement
> De plus : Il y a eu 47 avis (utilisez warnings() pour les visionner)


   It's hard to answer without a reproducible example:
http://tinyurl.com/reproducible-000 ... the problem *could* be inside
your dbleseg1 function.  Does it work outside of nls/nlme?  Are there
any simplified versions that you have gotten to work?
  
> I use the following packages:
> 
> R version 2.11.1 (2010-05-31)
> x86_64-pc-linux-gnu
> nlme_3.1-96 rj_1.0.3-7
> 

  It's not necessarily *the* problem, but it would generally be advised
to update to a more recent version of nlme -- especially if we have
trouble reproducing your problem with more recent versions.

  You can use traceback() to try to see where the error came from,
although it's probably pretty deep within a nested set of function
calls ...



From galizur at gmail.com  Sat Mar  3 11:41:52 2012
From: galizur at gmail.com (Christopher D. Long)
Date: Sat, 3 Mar 2012 02:41:52 -0800
Subject: [R-sig-ME] Quadratic with Random Offset in One Dimension
Message-ID: <CA+b8XEKEaQT6DNMNBtjKTVxs3GfQTcbUN7e8O+MXKmLXWnjHow@mail.gmail.com>

Hi,

I'm looking to fit a family of quadratics in (x,y) with a random factor
offset in one variable. The model would look like this:

outcome ~ x^2 + x*(y+F) + (y+F)^2 + 1

with F a random factor.

If this were linear in x,y it'd be no problem:

outcome ~ x + y + 1|F.

Is there a way to get either lme4 to estimate a model like this?
If not, what's my best route?
-- 
Christopher D. Long, San Diego Padres, 100 Park Blvd, San Diego CA

"Tick, clong, tick, clong, tick, clong, went the night." - Thurber



From steven.brady at yale.edu  Sat Mar  3 19:54:28 2012
From: steven.brady at yale.edu (Steven Brady)
Date: Sat, 3 Mar 2012 13:54:28 -0500
Subject: [R-sig-ME] Family specification - MCMCglmm survival analysis
Message-ID: <9E240F94-4263-446F-B6E4-51248E69F8FD@yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120303/273d4b35/attachment-0001.pl>

From bates at stat.wisc.edu  Sat Mar  3 22:28:09 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 3 Mar 2012 15:28:09 -0600
Subject: [R-sig-ME] Fit SGLMM by lme4 package
In-Reply-To: <1330803862830777500@modares.ac.ir>
References: <1330803862830777500@modares.ac.ir>
Message-ID: <CAO7JsnR0eS=ZXDraByoroyVs+QFzjLhnRhtePhgYJrab7TNTSw@mail.gmail.com>

I am taking the opportunity to cc: this reply to the
R-SIG-Mixed-Models mailing list.  Members of that list are often more
knowledgeable and quicker to respond than am I.

On Sat, Mar 3, 2012 at 1:44 PM,  <hbaghishani at modares.ac.ir> wrote:
> Dear Professor Bates,

> I would like to fit an spatial generalized linear mixed model, for example
> to model spatial count responses, by Laplace approximation and by using lme4
> R package. I'm very enthusiastic if it is possible to implement this fitting
> by?glmer in lme4 package?

I'm not exactly sure what a spatial generalized linear mixed model is.
 Could you or someone else on the list elaborate, please?



From john.maindonald at anu.edu.au  Sat Mar  3 23:30:38 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 4 Mar 2012 09:30:38 +1100
Subject: [R-sig-ME] Fit SGLMM by lme4 package
In-Reply-To: <CAO7JsnR0eS=ZXDraByoroyVs+QFzjLhnRhtePhgYJrab7TNTSw@mail.gmail.com>
References: <1330803862830777500@modares.ac.ir>
	<CAO7JsnR0eS=ZXDraByoroyVs+QFzjLhnRhtePhgYJrab7TNTSw@mail.gmail.com>
Message-ID: <A05EB10B-61C2-475A-B7DE-8CC5843A63C4@anu.edu.au>

The first place to look is surely under "Point pattern analysis"
on the Spatial task view (http://cran.csiro.au/web/views/)
Note especially the spatstat package.

But I am puzzled also.  A model that takes account os spatial
correlation might I suppose be described as some kind of
'spatial generalized linear mixed model'
Do you have something more in mind?  And why the Laplace
approximation in particular?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 04/03/2012, at 8:28 AM, Douglas Bates wrote:

> I am taking the opportunity to cc: this reply to the
> R-SIG-Mixed-Models mailing list.  Members of that list are often more
> knowledgeable and quicker to respond than am I.
> 
> On Sat, Mar 3, 2012 at 1:44 PM,  <hbaghishani at modares.ac.ir> wrote:
>> Dear Professor Bates,
> 
>> I would like to fit an spatial generalized linear mixed model, for example
>> to model spatial count responses, by Laplace approximation and by using lme4
>> R package. I'm very enthusiastic if it is possible to implement this fitting
>> by glmer in lme4 package?
> 
> I'm not exactly sure what a spatial generalized linear mixed model is.
> Could you or someone else on the list elaborate, please?
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From A.Robinson at ms.unimelb.edu.au  Sun Mar  4 00:46:09 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 4 Mar 2012 10:46:09 +1100
Subject: [R-sig-ME] Fit SGLMM by lme4 package
In-Reply-To: <A05EB10B-61C2-475A-B7DE-8CC5843A63C4@anu.edu.au>
References: <1330803862830777500@modares.ac.ir>
	<CAO7JsnR0eS=ZXDraByoroyVs+QFzjLhnRhtePhgYJrab7TNTSw@mail.gmail.com>
	<A05EB10B-61C2-475A-B7DE-8CC5843A63C4@anu.edu.au>
Message-ID: <20120303234609.GJ988@ms.unimelb.edu.au>

The original poseter might find INLA of use:

http://www.r-inla.org/

Best wishes

Andrew

On Sun, Mar 04, 2012 at 09:30:38AM +1100, John Maindonald wrote:
> The first place to look is surely under "Point pattern analysis"
> on the Spatial task view (http://cran.csiro.au/web/views/)
> Note especially the spatstat package.
> 
> But I am puzzled also.  A model that takes account os spatial
> correlation might I suppose be described as some kind of
> 'spatial generalized linear mixed model'
> Do you have something more in mind?  And why the Laplace
> approximation in particular?
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
> 
> On 04/03/2012, at 8:28 AM, Douglas Bates wrote:
> 
> > I am taking the opportunity to cc: this reply to the
> > R-SIG-Mixed-Models mailing list.  Members of that list are often more
> > knowledgeable and quicker to respond than am I.
> > 
> > On Sat, Mar 3, 2012 at 1:44 PM,  <hbaghishani at modares.ac.ir> wrote:
> >> Dear Professor Bates,
> > 
> >> I would like to fit an spatial generalized linear mixed model, for example
> >> to model spatial count responses, by Laplace approximation and by using lme4
> >> R package. I'm very enthusiastic if it is possible to implement this fitting
> >> by glmer in lme4 package?
> > 
> > I'm not exactly sure what a spatial generalized linear mixed model is.
> > Could you or someone else on the list elaborate, please?
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Deputy Director, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/



From j.hadfield at ed.ac.uk  Sun Mar  4 18:14:26 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 04 Mar 2012 17:14:26 +0000
Subject: [R-sig-ME] Family specification - MCMCglmm survival analysis
In-Reply-To: <9E240F94-4263-446F-B6E4-51248E69F8FD@yale.edu>
References: <9E240F94-4263-446F-B6E4-51248E69F8FD@yale.edu>
Message-ID: <20120304171426.124657sdd0i0mvwg@www.staffmail.ed.ac.uk>

Hi Steve,

"ordinal" has only been implemented for categorical data: you could  
expand each observation out into a series of zeros and ones and then  
fit an additional random effect pertaining to the original  
observation. However, that would be very inefficient computationally,  
and so if you're happy to use a logit link I would stick with  
"multinomial2".

Cheers,

Jarrod



probit link, "multinomial2" for logit link.


Quoting Steven Brady <steven.brady at yale.edu> on Sat, 3 Mar 2012  
13:54:28 -0500:

> Dear All:
> I have an experiment in which a suite of field enclosures were each  
> stocked with approximately 100 frog embryos. I would like to analyze  
> survival from this experiment as a two column response, e.g.  
> cbind(survived, died). Is it possible to use a probit link (i.e.  
> family = "ordinal") for a non-binary response such as this? If not,  
> would "multinomial2" be an appropriate family for this analysis? For  
> example:
> MCMCglmm(cbind(survived,(died))~x, random = ~clutch + block, family  
> = "multinomial2", data = xx)
>
> Many thanks,
> Steve
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Rachel.Gibson at bristol.ac.uk  Mon Mar  5 09:08:54 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Mon, 05 Mar 2012 08:08:54 +0000
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <loom.20120301T190854-931@post.gmane.org>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com> <loom.20120301T190854-931@post.gmane.org>
Message-ID: <A69D1D9335D92E102AD2AD79@bio-bzjxm-0501.bio.bris.ac.uk>

Thank you, I will let you know how I get on!


--On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com> wrote:

> Ben Bolker <bbolker at ...> writes:
>
>  [snip]
>
>> If you do this:
>>
>> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")
>>
>> it ought to work.  However, it *should* work the way you specified -- I
>> will work on fixing the bug.
>>
>>   thanks
>>     Ben Bolker
>
>   This should be fixed now (i.e. in glmmADMB 0.7.2.7).
>   It's still a good idea to use the data= argument.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From Rachel.Gibson at bristol.ac.uk  Mon Mar  5 12:00:56 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Mon, 05 Mar 2012 11:00:56 +0000
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <loom.20120301T190854-931@post.gmane.org>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com> <loom.20120301T190854-931@post.gmane.org>
Message-ID: <FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>

Updated to latest version and now having new problems:

m3<- 
glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offset(logTotal.grains)+(1|Site),data=data1, 
zeroInflation=TRUE, family="binomial")
Error in glmmadmb(x ~ nsn * Insect.type + ara * Insect.type + rap * 
Insect.type +  :
  The function maximizer failed (couldn't find STD file)
In addition: Warning message:
running command 'C:\WINDOWS\system32\cmd.exe /c "C:/Program 
Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500 
-maxph 5 -noinit -shess' had status 1


Can you help with this?

Many thanks, Rachel.

--On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com> wrote:

> Ben Bolker <bbolker at ...> writes:
>
>  [snip]
>
>> If you do this:
>>
>> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")
>>
>> it ought to work.  However, it *should* work the way you specified -- I
>> will work on fixing the bug.
>>
>>   thanks
>>     Ben Bolker
>
>   This should be fixed now (i.e. in glmmADMB 0.7.2.7).
>   It's still a good idea to use the data= argument.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From bbolker at gmail.com  Mon Mar  5 14:25:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 05 Mar 2012 08:25:08 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com>
	<loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <4F54BEB4.7060500@gmail.com>

On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences wrote:
> Updated to latest version and now having new problems:
> 
> m3<-
> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offset(logTotal.grains)+(1|Site),data=data1,
> zeroInflation=TRUE, family="binomial")
> Error in glmmadmb(x ~ nsn * Insect.type + ara * Insect.type + rap *
> Insect.type +  :
>  The function maximizer failed (couldn't find STD file)
> In addition: Warning message:
> running command 'C:\WINDOWS\system32\cmd.exe /c "C:/Program
> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500
> -maxph 5 -noinit -shess' had status 1
> 

  This now means that the optimization failed for some reason.
  There are many reasons this can happen, mostly having to do with
too-sparse or unusual data.  Without knowing anything about your data,
the one thing that pops out is you are using a binomial family with
zeroInflation=TRUE.  If your response is a matrix of successes and
failures, that's unusual but plausible; if your response is a single 0/1
vector, then it doesn't make sense to use zero-inflation.  (If your
response is anything else it's odd too, although that probably would
have been caught earlier.)
  Try working through the troubleshooting steps under ?admbControl (and
running with verbose=TRUE to see exactly what AD Model Builder reports
as the problem).

  Ben Bolker


> 
> Can you help with this?
> 
> Many thanks, Rachel.
> 
> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com> wrote:
> 
>> Ben Bolker <bbolker at ...> writes:
>>
>>  [snip]
>>
>>> If you do this:
>>>
>>> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")
>>>
>>> it ought to work.  However, it *should* work the way you specified -- I
>>> will work on fixing the bug.
>>>
>>>   thanks
>>>     Ben Bolker
>>
>>   This should be fixed now (i.e. in glmmADMB 0.7.2.7).
>>   It's still a good idea to use the data= argument.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> ----------------------
> RH Gibson, School Biological Sciences
> Rachel.Gibson at bristol.ac.uk



From Rachel.Gibson at bristol.ac.uk  Mon Mar  5 14:52:16 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Mon, 05 Mar 2012 13:52:16 +0000
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <4F54BEB4.7060500@gmail.com>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com> <loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54BEB4.7060500@gmail.com>
Message-ID: <E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>

That would make sense as I am able to fit a zero-inflated negative binomial 
model, but not just the binomial. I have tried poisson too, but this gave 
me the same error message as trying to fit the binomial.

The y variable is a count, offset by a sample total. There is 
overdispersion and a lot of zeros in the data. Does using the zero-inflated 
negative binomial make sense here?

Thanks.


--On 05 March 2012 08:25 -0500 Ben Bolker <bbolker at gmail.com> wrote:

> On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences wrote:
>> Updated to latest version and now having new problems:
>>
>> m3<-
>> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offset(
>> logTotal.grains)+(1|Site),data=data1, zeroInflation=TRUE,
>> family="binomial")
>> Error in glmmadmb(x ~ nsn * Insect.type + ara * Insect.type + rap *
>> Insect.type +  :
>>  The function maximizer failed (couldn't find STD file)
>> In addition: Warning message:
>> running command 'C:\WINDOWS\system32\cmd.exe /c "C:/Program
>> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500
>> -maxph 5 -noinit -shess' had status 1
>>
>
>   This now means that the optimization failed for some reason.
>   There are many reasons this can happen, mostly having to do with
> too-sparse or unusual data.  Without knowing anything about your data,
> the one thing that pops out is you are using a binomial family with
> zeroInflation=TRUE.  If your response is a matrix of successes and
> failures, that's unusual but plausible; if your response is a single 0/1
> vector, then it doesn't make sense to use zero-inflation.  (If your
> response is anything else it's odd too, although that probably would
> have been caught earlier.)
>   Try working through the troubleshooting steps under ?admbControl (and
> running with verbose=TRUE to see exactly what AD Model Builder reports
> as the problem).
>
>   Ben Bolker
>
>
>>
>> Can you help with this?
>>
>> Many thanks, Rachel.
>>
>> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> Ben Bolker <bbolker at ...> writes:
>>>
>>>  [snip]
>>>
>>>> If you do this:
>>>>
>>>> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom
>>>> ")
>>>>
>>>> it ought to work.  However, it *should* work the way you specified -- I
>>>> will work on fixing the bug.
>>>>
>>>>   thanks
>>>>     Ben Bolker
>>>
>>>   This should be fixed now (i.e. in glmmADMB 0.7.2.7).
>>>   It's still a good idea to use the data= argument.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> ----------------------
>> RH Gibson, School Biological Sciences
>> Rachel.Gibson at bristol.ac.uk
>



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From bbolker at gmail.com  Mon Mar  5 15:22:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 05 Mar 2012 09:22:28 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com>
	<loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54BEB4.7060500@gmail.com>
	<E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <4F54CC24.4000901@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12-03-05 08:52 AM, RH Gibson, School Biological Sciences wrote:
> That would make sense as I am able to fit a zero-inflated negative 
> binomial model, but not just the binomial. I have tried poisson
> too, but this gave me the same error message as trying to fit the
> binomial.
> 
> The y variable is a count, offset by a sample total. There is 
> overdispersion and a lot of zeros in the data. Does using the 
> zero-inflated negative binomial make sense here?
> 
> Thanks.

  It very rarely makes sense to use the binomial and the negative
binomial to fit the same set of data; the binomial has a fixed
(typically known) upper limit, the Poisson and NB do not.  (The
exception to this is that people will sometimes use Poisson/NB models
when the upper limit is known but the observed frequency is very low
- -- this is especially common e.g. in epidemiology.)  ZINB, or plain
old NB, probably make the most sense.

  It's more interesting that you get an error message with the
Poisson, which may indicate some glmmADMB instability.  What are the
results of summary(data1)?  How many sites do you have?

  Ben Bolker
> 
> 
> --On 05 March 2012 08:25 -0500 Ben Bolker <bbolker at gmail.com>
> wrote:
> 
>> On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences
>> wrote:
>>> Updated to latest version and now having new problems:
>>> 
>>> m3<- 
>>> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offset(
>>>
>>> 
logTotal.grains)+(1|Site),data=data1, zeroInflation=TRUE,
>>> family="binomial") Error in glmmadmb(x ~ nsn * Insect.type +
>>> ara * Insect.type + rap * Insect.type +  : The function
>>> maximizer failed (couldn't find STD file) In addition: Warning
>>> message: running command 'C:\WINDOWS\system32\cmd.exe /c
>>> "C:/Program 
>>> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe"
>>> -maxfn 500 -maxph 5 -noinit -shess' had status 1
>>> 
>> 
>> This now means that the optimization failed for some reason. 
>> There are many reasons this can happen, mostly having to do with 
>> too-sparse or unusual data.  Without knowing anything about your
>> data, the one thing that pops out is you are using a binomial
>> family with zeroInflation=TRUE.  If your response is a matrix of
>> successes and failures, that's unusual but plausible; if your
>> response is a single 0/1 vector, then it doesn't make sense to
>> use zero-inflation.  (If your response is anything else it's odd
>> too, although that probably would have been caught earlier.) Try
>> working through the troubleshooting steps under ?admbControl
>> (and running with verbose=TRUE to see exactly what AD Model
>> Builder reports as the problem).
>> 
>> Ben Bolker
>> 
>> 
>>> 
>>> Can you help with this?
>>> 
>>> Many thanks, Rachel.
>>> 
>>> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com>
>>> wrote:
>>> 
>>>> Ben Bolker <bbolker at ...> writes:
>>>> 
>>>> [snip]
>>>> 
>>>>> If you do this:
>>>>> 
>>>>> mydata <-
>>>>> data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site) 
>>>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom
>>>>>
>>>>> 
")
>>>>> 
>>>>> it ought to work.  However, it *should* work the way you
>>>>> specified -- I will work on fixing the bug.
>>>>> 
>>>>> thanks Ben Bolker
>>>> 
>>>> This should be fixed now (i.e. in glmmADMB 0.7.2.7). It's
>>>> still a good idea to use the data= argument.
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> 
>>> ---------------------- RH Gibson, School Biological Sciences 
>>> Rachel.Gibson at bristol.ac.uk
>> 
> 
> 
> 
> ---------------------- RH Gibson, School Biological Sciences 
> Rachel.Gibson at bristol.ac.uk

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPVMwkAAoJED2whTVMEyK9uVIIAIWj65sTlLNJWgOXsI1xZNaQ
pFD7dAOCotHlcFfDhulOZwuvcMwS5jnN459GMURSuyriQDrW1itQyqZ2y6EGpBuh
wj3OHG9vYBSUenkPBe+lBN5uXD62JPyKmfzp7djHs6zPeIWOGoxVXMTLHDBgmfky
kas5eOq91b/N88DpeL+duYAqjo+rtgD/h1kjMlELUwQXC3M3aeA1k78Lxx+Bahye
hsbTFJm/7cc7moBv9SpgO//qDJDqhKUa4z01XljibHl9J57m76/TY2M8/sFrOBDB
ig3h4Yc6ajoaSegaTn1NmzaISMMdTWVi1RWI4PL5Uu/SqLLxt4sloXuXMoF+4fY=
=xOtC
-----END PGP SIGNATURE-----



From Rachel.Gibson at bristol.ac.uk  Mon Mar  5 16:22:39 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Mon, 05 Mar 2012 15:22:39 +0000
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <4F54CC24.4000901@gmail.com>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com> <loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54BEB4.7060500@gmail.com>
	<E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54CC24.4000901@gmail.com>
Message-ID: <E8AF898129FE6A3949ECEFF9@bio-bzjxm-0501.bio.bris.ac.uk>

here is what happens when I tried the poisson:

> 
m7<-glmmadmb(x~nsn*Insect.type+ara*Insect.type+offset(logTotal.grains)+(1|Site),data=data1, 
zeroInflation=TRUE, family="poisson")
Warning message:
In glmmadmb(x ~ nsn * Insect.type + ara * Insect.type + 
offset(logTotal.grains) +  :
  Convergence failed:log-likelihood of gradient= -223.949

I will email you the summary(data1) output separately.

I have 8 sites only.

Thanks for all the help.


--On 05 March 2012 09:22 -0500 Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 12-03-05 08:52 AM, RH Gibson, School Biological Sciences wrote:
>> That would make sense as I am able to fit a zero-inflated negative
>> binomial model, but not just the binomial. I have tried poisson
>> too, but this gave me the same error message as trying to fit the
>> binomial.
>>
>> The y variable is a count, offset by a sample total. There is
>> overdispersion and a lot of zeros in the data. Does using the
>> zero-inflated negative binomial make sense here?
>>
>> Thanks.
>
>   It very rarely makes sense to use the binomial and the negative
> binomial to fit the same set of data; the binomial has a fixed
> (typically known) upper limit, the Poisson and NB do not.  (The
> exception to this is that people will sometimes use Poisson/NB models
> when the upper limit is known but the observed frequency is very low
> - -- this is especially common e.g. in epidemiology.)  ZINB, or plain
> old NB, probably make the most sense.
>
>   It's more interesting that you get an error message with the
> Poisson, which may indicate some glmmADMB instability.  What are the
> results of summary(data1)?  How many sites do you have?
>
>   Ben Bolker
>>
>>
>> --On 05 March 2012 08:25 -0500 Ben Bolker <bbolker at gmail.com>
>> wrote:
>>
>>> On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences
>>> wrote:
>>>> Updated to latest version and now having new problems:
>>>>
>>>> m3<-
>>>> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offse
>>>> t(
>>>>
>>>>
> logTotal.grains)+(1|Site),data=data1, zeroInflation=TRUE,
>>>> family="binomial") Error in glmmadmb(x ~ nsn * Insect.type +
>>>> ara * Insect.type + rap * Insect.type +  : The function
>>>> maximizer failed (couldn't find STD file) In addition: Warning
>>>> message: running command 'C:\WINDOWS\system32\cmd.exe /c
>>>> "C:/Program
>>>> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe"
>>>> -maxfn 500 -maxph 5 -noinit -shess' had status 1
>>>>
>>>
>>> This now means that the optimization failed for some reason.
>>> There are many reasons this can happen, mostly having to do with
>>> too-sparse or unusual data.  Without knowing anything about your
>>> data, the one thing that pops out is you are using a binomial
>>> family with zeroInflation=TRUE.  If your response is a matrix of
>>> successes and failures, that's unusual but plausible; if your
>>> response is a single 0/1 vector, then it doesn't make sense to
>>> use zero-inflation.  (If your response is anything else it's odd
>>> too, although that probably would have been caught earlier.) Try
>>> working through the troubleshooting steps under ?admbControl
>>> (and running with verbose=TRUE to see exactly what AD Model
>>> Builder reports as the problem).
>>>
>>> Ben Bolker
>>>
>>>
>>>>
>>>> Can you help with this?
>>>>
>>>> Many thanks, Rachel.
>>>>
>>>> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com>
>>>> wrote:
>>>>
>>>>> Ben Bolker <bbolker at ...> writes:
>>>>>
>>>>> [snip]
>>>>>
>>>>>> If you do this:
>>>>>>
>>>>>> mydata <-
>>>>>> data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>>>>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbin
>>>>>> om
>>>>>>
>>>>>>
> ")
>>>>>>
>>>>>> it ought to work.  However, it *should* work the way you
>>>>>> specified -- I will work on fixing the bug.
>>>>>>
>>>>>> thanks Ben Bolker
>>>>>
>>>>> This should be fixed now (i.e. in glmmADMB 0.7.2.7). It's
>>>>> still a good idea to use the data= argument.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>>> ---------------------- RH Gibson, School Biological Sciences
>>>> Rachel.Gibson at bristol.ac.uk
>>>
>>
>>
>>
>> ---------------------- RH Gibson, School Biological Sciences
>> Rachel.Gibson at bristol.ac.uk
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iQEcBAEBAgAGBQJPVMwkAAoJED2whTVMEyK9uVIIAIWj65sTlLNJWgOXsI1xZNaQ
> pFD7dAOCotHlcFfDhulOZwuvcMwS5jnN459GMURSuyriQDrW1itQyqZ2y6EGpBuh
> wj3OHG9vYBSUenkPBe+lBN5uXD62JPyKmfzp7djHs6zPeIWOGoxVXMTLHDBgmfky
> kas5eOq91b/N88DpeL+duYAqjo+rtgD/h1kjMlELUwQXC3M3aeA1k78Lxx+Bahye
> hsbTFJm/7cc7moBv9SpgO//qDJDqhKUa4z01XljibHl9J57m76/TY2M8/sFrOBDB
> ig3h4Yc6ajoaSegaTn1NmzaISMMdTWVi1RWI4PL5Uu/SqLLxt4sloXuXMoF+4fY=
> =xOtC
> -----END PGP SIGNATURE-----



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From amelie.pinet at gmail.com  Tue Mar  6 09:42:26 2012
From: amelie.pinet at gmail.com (amelie pinet)
Date: Tue, 6 Mar 2012 09:42:26 +0100
Subject: [R-sig-ME] error in nlme()
In-Reply-To: <loom.20120302T163732-975@post.gmane.org>
References: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>
	<loom.20120302T163732-975@post.gmane.org>
Message-ID: <CAKNZCKFGHNNOwEzuAg2nFwDLFE_CPyjF3NJv8WUEvyVh7_055Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120306/210bf6be/attachment-0001.pl>

From statsstud8 at gmail.com  Tue Mar  6 07:42:23 2012
From: statsstud8 at gmail.com (Student Stats)
Date: Mon, 5 Mar 2012 22:42:23 -0800
Subject: [R-sig-ME] Covariance models with lme and gls
Message-ID: <CAGspFjBGkR80Na_hxCnMYRRom0fqzQ_b4j9xxXDGUiN+AZgmYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120305/cebe8128/attachment-0001.pl>

From bbolker at gmail.com  Tue Mar  6 17:44:03 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 6 Mar 2012 16:44:03 +0000 (UTC)
Subject: [R-sig-ME] Covariance models with lme and gls
References: <CAGspFjBGkR80Na_hxCnMYRRom0fqzQ_b4j9xxXDGUiN+AZgmYA@mail.gmail.com>
Message-ID: <loom.20120306T173742-387@post.gmane.org>

Student Stats <statsstud8 at ...> writes:


> I'm trying to fit several covariance models using gls and lme. My aim is to
> identify which covariance model fits my data better. I'm afraid, however,
> that I'm not specifying the code properly. Could someone take a look on my
> code and help me figuring out whether I'm pursuing everything correctly?
> 

 You just posted this to StackOverflow.  It isn't explicitly proscribed
(as cross-posting among R help lists is), but I don't like it because it
diffuses information and potentially wastes effort.  I told you there that
this seems like a bit of a "please debug my code for me question" -- what
have you tried already in order to figure out whether you're doing it
right or not?  Do you have reasons to suspect you're doing something
wrong?  It's easier to answer a specific question than to look over
a big hunk of code.

   I suggested to you on Stack Overflow that using update() would
make it easier to look at your code.  In fact you can structure it
a bit further:

vs <- varIdent(form=~1|time)
cs <- corSymm(form=~1|id)
ccs <- corCompSymm(form=~1|id)
car1 <- corAR1(form=~1|id)

> # Independence covariance matrix
> IN <- gls(y ~ ses + time, data, corr=NULL, weights=NULL, method="REML",
> control=lmeControl(msMaxIter = 500, msVerbose = TRUE))
> 

UN <- update(IN, corr=cs, weights=vs)

> # Fit Random Intercept Model (RI)
> RI <- lme(y ~ ses + time, data, na.action=na.omit, method="REML",
> random=~1|id, control=lmeControl(msMaxIter = 200, msVerbose = TRUE))
> 

RIAS <- update(RI, random=~time|id)
CS <- update(IN,correlation=ccs)
CSH <- update(CS,weights=vs)
AR1 <- update(IN,correlation=car1)

  et cetera.



From bbolker at gmail.com  Tue Mar  6 18:05:41 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 6 Mar 2012 17:05:41 +0000 (UTC)
Subject: [R-sig-ME] error in nlme()
References: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>
	<loom.20120302T163732-975@post.gmane.org>
	<CAKNZCKFGHNNOwEzuAg2nFwDLFE_CPyjF3NJv8WUEvyVh7_055Q@mail.gmail.com>
Message-ID: <loom.20120306T180030-171@post.gmane.org>

amelie pinet <amelie.pinet at ...> writes:

> 
> Hello,
> 
> *Here it is a copy of my data:*
> 
  [snip]

> 
> *I also post my data here (be careful, it's a .xls file)*
> http://www.fichier-xls.fr/2012/03/06/7gvwshi/*
> 
> The code used is as follow:*
> 

  The main problem with your code is that you used DATA$Traitement
within the functions; when na.omit() scrubbed NAs from the input
data, it led to a mismatch between the data length and the length
of the 'Traitement' variable.  In general it's often simpler/more
robust to scrub NAs explicitly beforehand (using na.omit()) unless
you have particular reasons to need to retain those data throughout
the modeling process.  You can also (as I have done below) add
'Traitement' as a variable in your functions; in general it is 
bad practice to refer directly to global variables in your
nls functions, for exactly this reason ...

library(gdata)
## http://www.fichier-xls.fr/2012/03/06/7gvwshi/Phyllocrone_AP.xls
DATA <- read.xls("Phyllocrone_AP.xls",na.strings=c("NA","#VALUE!"),
comment.char="")

## for some reason I couldn't get #VALUE! read in as NA ...
DATA <- transform(DATA,Nb_phyto=as.numeric(as.character(Nb_phyto)))

# broken line with no effet of traitement
dbleseg0 <- function (JourJulien,a0,b0,a1,T) (a0*JourJulien+b0) +
  a1*(JourJulien >T)*(T-JourJulien)

# broken line with effet of traitement on a0 parameter
dbleseg1 <- function (JourJulien,a0,b0,a1,T,a0a,Traitement) {
    (((a0+a0a*(Traitement!="Control"))*JourJulien)+b0) +
a1*(JourJulien >T)*(T-JourJulien)
}

# broken line with effet of traitement on b0 parameter
dbleseg2 <- function (JourJulien,a0,b0,a1,T,b0a,Traitement) {
    ((a0*JourJulien)+(b0+b0a*(Traitement!="Control"))) +
a1*(JourJulien >T)*(T-JourJulien)
                }

# broken line with effet of traitement on a0 and b0 parameters
dbleseg3 <- function (JourJulien,a0,b0,a1,T,a0a,b0a,Traitement) {

  (((a0+a0a*(Traitement!="Control"))*JourJulien)+
    (b0+b0a*(Traitement!="Control")))+ a1*(JourJulien >T)*(T-JourJulien)
}

a0init <- 0.49
b0init <- -65
a1init <- 0.30
Tinit <- 239
a0ainit <- -0.40
b0ainit <- 6
a1ainit <- -0.1

library(nlme)

start1 <- c(a0=a0init,b0=b0init,a1=a1init,T=Tinit)
with(c(DATA,as.list(start1)),dbleseg0(JourJulien,a0,b0,a1,T))
Mod1 <- nls(Nb_phyto ~dbleseg0(JourJulien,a0,b0,a1,T),
data =DATA,start=start1,na.action=na.omit)

Mod2 <- nls(Nb_phyto ~dbleseg1(JourJulien,a0,b0,a1,T,a0a,Traitement),
data =DATA,start=start1,
na.action=na.omit)

Mod3 <- nls(Nb_phyto ~dbleseg2(JourJulien,a0,b0,a1,T,b0a,Traitement),
data =DATA,start=c(a0=a0init,b0=b0init,a1=a1init,T=Tinit,b0a=b0ainit),
na.action=na.omit)

Mod4 <- nls(Nb_phyto ~dbleseg3(JourJulien,a0,b0,a1,T,a0a,b0a,Traitement),
data = DATA,start1,na.action=na.omit)

*Mod2, Mod3, Mod4 ran but I obtained this warnings:
Il y a eu 50 avis ou plus (utilisez warnings() pour voir les 50 premiers)

  Did you look at the warnings????

  I had a problem with Mod4 ("singular gradient matrix
at initial parameter estimates") -- you should look at your
initial values and see whether they give rise to a sensible
estimate or not ...

Then I tried to use nlme()* (with the same start values) :

dataAna <- groupedData(Nb_phyto ~1|Plante,data=DATA)

Mod5 <- nlme(Nb_phyto ~dbleseg0(JourJulien,a0,b0,a1,T),data =
dataAna,fixed=a0+b0+a1+T~1,random=pdDiag(b0~1),
start=c(a0=a0init,b0=b0init,a1=a1init,T=Tinit),na.action=na.omit)

Mod6 <- nlme(Nb_phyto ~dbleseg1(JourJulien,a0,b0,a1,T,a0a,Traitement),data =
dataAna,fixed=a0+b0+a1+T+a0a~1,random=pdDiag(a0~1),
start=c(a0=a0init,b0=b0init,a1=a1init,T=Tinit,a0a=a0ainit),na.action=na.omit)

  these worked for me.



From Mohand-Larbi.Feddag at univ-nantes.fr  Tue Mar  6 17:17:33 2012
From: Mohand-Larbi.Feddag at univ-nantes.fr (Feddag Mohand-Larbi)
Date: Tue, 06 Mar 2012 17:17:33 +0100
Subject: [R-sig-ME] Question on the glmer function of the lme4  R package
Message-ID: <4F56389D.9060905@univ-nantes.fr>

Dear all,

Could you please help me in the estimation of the different parameters of the
Bradley-Terry model with random effects by the glmer function of the lme4 R package.

The model, the marginal likelihood and the real data and the main question are described in the attached file.

Best regards


 Dr Feddag



-------------- next part --------------
A non-text attachment was scrubbed...
Name: Feddag_glmer_BT.pdf
Type: application/pdf
Size: 50353 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120306/abac9b61/attachment-0001.pdf>

From annebj at gmail.com  Wed Mar  7 02:30:48 2012
From: annebj at gmail.com (Anne Bjorkman)
Date: Tue, 6 Mar 2012 17:30:48 -0800
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB, and cloglog
Message-ID: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120306/c9f21cb7/attachment-0001.pl>

From Yanwei.Zhang at cna.com  Wed Mar  7 04:37:56 2012
From: Yanwei.Zhang at cna.com (Zhang,Yanwei)
Date: Tue, 6 Mar 2012 21:37:56 -0600
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB,
 and cloglog
In-Reply-To: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
References: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
Message-ID: <330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>

Hi, 

The cplm package may be a good place to look at for the first problem. It handles zero-inflated continuous data using the compound Poisson distribution, and the mixed-model version (cpglmm) is developed based on glmer. 

Regards, 
Wayne Zhang
 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Anne Bjorkman
Sent: Tuesday, March 06, 2012 7:31 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB, and cloglog

Dear Mixed Modelers,


I have a few questions about various aspects of a dataset I am working on,
and I was hoping to get some feedback from the experts.  I apologize for
not being able to provide my data, but if anyone is interested I would be
happy to share it off-line.


My overall question is about changes in crop species abundances and
presence/absence over a 40 year period in 154 countries in the world, with
the measurements occurring at 10 year intervals (so, 1967, 1977, 1987,
1997, and 2007).  I would like to analyze these data in terms of both
abundance AND presence/absence, as they answer slightly different questions
(the first about abundance, the second about spread/distribution).  A
subset of my data look like this:


            Country             Item_general Total    Percent_of_Total Year
pres.abs

28465 Albania                Apples  6.45       0.002903365 1967        1

28466 Albania   Bananas_and_plantains  0.00       0.000000000 1967        0

28467 Albania                Barley 17.09      0.007692792 1967        1

28468 Albania                 Beans 41.80      0.018815610 1967        1

28469 Albania   Beverages_Alcoholic  5.60       0.002520751 1967        1

28470 Albania   Beverages_Fermented  0.00       0.000000000 1967        0


The abundance metric ("Total") here is number of Kcalories consumed of that
crop in that country in that year.  I have already looked at multivariate
changes in composition, but now I want to know about the change that occurs
for each crop species (i.e., which crop species have increased or decreased
the most over the past 40 years?).  My goal is to model each crop species
separately and extract slope parameters and standard errors for the slopes,
which would then tell me about the magnitude and direction of change for
each crop.  However, there are three complications:


1) The data for most crops are zero-inflated.  The zero-inflation is not
equal throughout the years, because overall countries have been increasing
in the number of crops they use, so there are more 0's in 1967 than in 2007
for a given crop.  This is true of most crops, but there are some that have
been decreasing.


2) I have repeated measurements on individual countries over the 40 year (5
sampling times) period. Thus I have been trying to account for this by
using "Country" as a random effect in a mixed model.


3) The data for each crop are not distributed in the same way.  Some crops
(such as corn) approach a nearly-normal distribution, while other crops
(e.g., Tea) are extremely zero-inflated.


I have attempted to use glmmADMB to model these data, as I understand this
is one of the few ways you can have random effects and account for
zero-inflation, using a negative binomial distribution and
zeroInflation=TRUE.


admb.model<-glmmadmb(Total_Rnd~I(Year-1967),random=~1|Country,family=
"nbinom",zeroInflation=TRUE,data=mydata)


where Total_Rnd is the "Total" column (total abundance) rounded to the
nearest integer using "ceiling".  This usually works on a subset of the
data that includes only one crop species, but if I try to model the entire
dataset (all crops together) I get the error:


Error in glmmadmb(Rel.Total.Rnd ~ I(Year - 1967), random = ~1 | Country,  :

  The function maximizer failed (couldn't find STD file)

In addition: Warning message:

running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status
1

Need to increase the maximum number of separable calls allowed to at least
20001

Current value is 20000

Use the -ndi N command line option


The output from just one crop species (Peas in this case) looks like this:


Call:

glmmadmb(formula = Total_Rnd ~ I(Year - 1967), data = subset(kcal.sub.test,

    Item_general == "Pulses_Other"), family = "nbinom", random = ~1 |

    Country, zeroInflation = TRUE)



Coefficients:

               Estimate Std. Error z value Pr(>|z|)

(Intercept)     2.64530    0.13035   20.29   <2e-16 ***

I(Year - 1967) -0.00107    0.00136   -0.78     0.43

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Number of observations: total=745, Country=154

Random effect variance(s):

$Country

            (Intercept)

(Intercept)      2.3298


Negative binomial dispersion parameter: 5.8899 (std. err.: 0.48002)

Zero-inflation: 0.013045  (std. err.:  0.0050869 )


Log-likelihood: -2788


This seems to match up somewhat with the raw data:


> mean(kcal.sub.test$Total_Rnd[kcal.sub.test$Item_general=="Pulses_Other" &
kcal.sub.test$Year==1967])

[1] 31.81208

> mean(kcal.sub.test$Total_Rnd[kcal.sub.test$Item_general=="Pulses_Other" &
kcal.sub.test$Year==2007])

[1] 29.69799


(so there has been a decrease in mean abundance from 1967 to 2007)


In addition, when I plot fitted values vs. residuals for a given crop to
try to check the assumptions for these models, they do not look good (a
very serious fanning-out from left to right):


admb.model.fit<-fitted(admb.model)

admb.model.res<-resid(admb.model)

plot(admb.model.fit,admb.model.res)


I have read on the mixed-models help list and elsewhere that plotting the
fitted v. residual values is not as straightforward with mixed effects
models, so I'm not entirely sure this is the right code to use, or what is
a better way to check how well this model fits (other than comparing AIC
values of a bunch of different models with the same data).


Of course, as I mentioned above, the data for each crop are distributed
differently, and I would be enormously appreciative if someone could
comment on whether I could use different models (in other words, some of
them with zeroInflation=TRUE and some with just a normal family="nbinom"
without zero inflation) for the different crops and still compare their
slopes.  Is my priority to find the best model for each crop, or is it to
use the same model for each crop so that the slopes are directly
comparable?  I have the same question about transforming the data.  Some of
the crops (not the zero-inflated ones, of course) would be better fit by
transforming to a square root of abundance, but I'm unsure whether I could
then compare the slope parameters with non-square-root-transformed crops. I
remember reading somewhere (but can't remember where) that
back-transforming the parameters is not a simple matter with mixed models,
thus making differently-transformed slope values comparable to each other
might not be possible.


To make matters more complicated, I would really like to model this as *
relative* abundance (or, "Percent of Total") to account for the fact that
people have been eating more over the years (total Kcalories has increased
over time). I would still be dealing with zero-inflation here, and my
understanding is that I could still use the same model described above,
since negative binomial and poisson distributions are for counts, and
proportions can be modeled like counts, even though they have an upper
limit?


The second part of the data, the presence-absence data, are a bit more
straightforward.  I transformed the data to presence-absence to try to get
away from the zero-inflation issue, and have been performing logistic
regression using lmer:


pres.abs.mod<-lmer(pres.abs~I(Year-1967)+(1|Country),data=mydata,family=
binomial)


For one crop, Peas, the output looks like this:


Generalized linear mixed model fit by the Laplace approximation

Formula: pres.abs ~ I(Year - 1967) + (1 | Country)

   Data: subset(pres.abs.kcal, Item_general == "Pulses_Other")

   AIC   BIC logLik deviance

 255.2 269.1 -124.6    249.2

Random effects:

 Groups  Name        Variance Std.Dev.

 Country (Intercept) 60.785   7.7965

Number of obs: 760, groups: Country, 152


Fixed effects:

               Estimate Std. Error z value Pr(>|z|)

(Intercept)     7.64468    1.47113   5.196 2.03e-07 ***

I(Year - 1967)  0.06714    0.01747   3.843 0.000122 ***

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Correlation of Fixed Effects:

            (Intr)

I(Yer-1967) -0.196


When I try to transform the Intercept term using plogis(7.64468) I get a
value of 0.9995216 (which, if I understand correctly, is like the expected
proportion of countries that have that crop) which I know from the data is
much too high.


My data do NOT have equal numbers of 1's and 0's, so if I try
family=binomial(link="cloglog") I get a much more reasonable estimate:


Generalized linear mixed model fit by the Laplace approximation

Formula: pres.abs ~ I(Year - 1967) + (1 | Country)

   Data: subset(pres.abs.kcal, Item_general == "Pulses_Other")

   AIC   BIC logLik deviance

 229.8 243.7 -111.9    223.8

Random effects:

 Groups  Name        Variance Std.Dev.

 Country (Intercept) 10.482   3.2376

Number of obs: 760, groups: Country, 152


Fixed effects:

               Estimate Std. Error z value Pr(>|z|)

(Intercept)    2.458405   0.696478    3.53 0.000416 ***

I(Year - 1967) 0.028910   0.009901    2.92 0.003503 **

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Correlation of Fixed Effects:

            (Intr)

I(Yer-1967) -0.292


which matches up almost perfectly with the mean of the raw data (which is
what I think the Intercept term estimates...):


> plogis(2.458405)

[1] 0.9211739


> mean(pres.abs.kcal$pres.abs[pres.abs.kcal$Item_general=="Pulses_Other"])

[1] 0.9276316



the problem is, I get an error that says


Warning message:

In mer_finalize(ans) : false convergence (8)


Can I still use the output of the link="cloglog" model, since it seems to
fit my model better (incidentally, the AIC is lower and the plot of fitted
v. residuals looks more even - even though of course for logistic models
the plots of fitted v. residuals aren't exactly straightforward to
interpret!).  Or can someone advise me as to what I am doing wrong to get
this error?


Finally, similarly to my question posed above, can I still compare the
slope parameters from my logistic regression models if I use link="logit"
for some and link="cloglog" for others, depending on which one provides a
better model fit, or should I use the same model for all crop species, even
if some are fit better than others.


I sincerely apologize for the novel-like length of this email, I have been
battling these questions for over a month now, searching R-list archives
and reading every (layman's) book I can get my hands on, and I've gotten to
the point now where, for every new thing I learn, I forget something I read
yesterday.


Enormous thanks in advance to anyone who feels willing to tackle my
statistical novel!


Best,

Anne

	[[alternative HTML version deleted]]


NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.



From s.blomberg1 at uq.edu.au  Wed Mar  7 05:42:35 2012
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 07 Mar 2012 14:42:35 +1000
Subject: [R-sig-ME] [R-sig-phylo] possible issue when incorporating a
 phylogenetic correlation structure (corPagel) in a linear mixed effect
 model (lme)
In-Reply-To: <4F4E3A7B.2050808@ebd.csic.es>
References: <4F4E3A7B.2050808@ebd.csic.es>
Message-ID: <4F56E73B.7090202@uq.edu.au>

Hi,

I'm not sure why this is occurring (and I've cc'ed the r-sig-me list as 
they might know more). It appears to me that there is some problem with 
the parameterisation of the random effects, and how that interacts with 
the correlation structure. The usual random=~1|date parameterisation 
uses a log-Cholesky factorisation, which is different to the pdIdent 
parameterisation, but as you say in this case should give the same 
answers. It looks like there may be something going on deep in the lme 
internals. Maybe someone on r-sig-me can help.

Sorry I can't be of more help. It's an interesting problem and I would 
like to see it resolved too.

Best,

Simon.

On 01/03/12 00:47, Rudolf Philippe Rohr wrote:
> Hello.
>
> I'm writing about a possible issue when incorporating a phylogenetic 
> correlation structure (corPagel) in a linear mixed effect model (lme).
>
> There are two techniques for incorporating a random effect in a linear 
> model:
>
> t1 (it is the traditional way): m1 <- lme( y ~ x, random = ~1|date)
>
> t2: u = gl(1,1,length(y))
> m2 <- lme(y ~ x, random = list(u = pdIdent(form=~factor(date)-1)))
>
> (http://www.mail-archive.com/r-help at stat.math.ethz.ch/msg11749.html)
>
> > str(d)
> 'data.frame': 446 obs. of 3 variables:
> $ y : num 2.197 0.693 0.693 0 0.693 ...
> $ x : Factor w/ 2 levels "N","Y": 2 1 1 1 1 2 2 2 2 2 ...
> $ date: Factor w/ 7 levels "12","16","21",..: 5 6 7 4 7 6 2 7 3 6 ...
>
> These two techniques have to give the same output, and it is exactly 
> what happens (same parameter estimations, same log-like, same 
> p-values, same values for the random factor, ?)
>
> > summary(m1)
> Linear mixed-effects model fit by REML
> Data: d
> AIC BIC logLik
> 1366.617 1383 -679.3083
>
> Random effects:
> Formula: ~1 | date
> (Intercept) Residual
> StdDev: 0.4283086 1.086683
>
> Fixed effects: y ~ x
> Value Std.Error DF t-value p-value
> (Intercept) 1.4430143 0.1856287 438 7.773658 0.0000
> xY 0.0700834 0.1119626 438 0.625953 0.5317
> Correlation:
> (Intr)
> xY -0.397
>
> > summary(m2)
> Linear mixed-effects model fit by REML
> Data: d
> AIC BIC logLik
> 1366.617 1383 -679.3083
>
> Random effects:
> Formula: ~factor(date) - 1 | u
> Structure: Multiple of an Identity
> factor(date)12 factor(date)16 factor(date)21 factor(date)26 
> factor(date)30 factor(date)35 factor(date)38
> StdDev: 0.4283086 0.4283086 0.4283086 0.4283086 0.4283086 0.4283086 
> 0.4283086
> Residual
> StdDev: 1.086683
>
> Fixed effects: y ~ x
> Value Std.Error DF t-value p-value
> (Intercept) 1.4430143 0.1856287 444 7.773658 0.0000
> xY 0.0700834 0.1119626 444 0.625953 0.5317
> Correlation:
> (Intr)
> xY -0.397
>
>
> Things get strange when incorporating a phylogenetic correlation 
> structure with corPagel (and also with corGrafen):
>
> t1: m3 <- lme( y ~ x, random = ~1|date, correlation = 
> corPagel(0.5,tree,fixed=FALSE))
>
> t2: u = gl(1,1,length(y))
> m4 <- lme(y ~ x, random = list(u = pdIdent(form=~factor(date)-1)), 
> correlation = corPagel(0.5,tree,fixed=FALSE)))
>
> Again, these two methods should give the same output, however here:
>
> t1 always gives the following error message:
>
> Error in corFactor.corStruct(object) :
> NA/NaN/Inf in foreign function call (arg 1)
>
> t2: the optimization process converges, and gives reasonable output.
>
> > summary(m4)
> Linear mixed-effects model fit by REML
> Data: d
> AIC BIC logLik
> 1350.275 1370.754 -670.1376
>
> Random effects:
> Formula: ~factor(date) - 1 | u
> Structure: Multiple of an Identity
> factor(date)12 factor(date)16 factor(date)21 factor(date)26 
> factor(date)30 factor(date)35 factor(date)38
> StdDev: 0.3966233 0.3966233 0.3966233 0.3966233 0.3966233 0.3966233 
> 0.3966233
> Residual
> StdDev: 1.141081
>
> Correlation Structure: corPagel
> Formula: ~1 | u
> Parameter estimate(s):
> lambda
> 0.2846964
> Fixed effects: y ~ x
> Value Std.Error DF t-value p-value
> (Intercept) 1.1950145 0.3493305 444 3.420871 0.0007
> xY -0.0312983 0.1139128 444 -0.274757 0.7836
> Correlation:
> (Intr)
> xY -0.18
>
> First question: why is it that t1 does not work, while t2 does?
>
>
> To go a step forward with this problem, we can set the lambda value in 
> t1 with the value obtained from t2.
>
> t1bis: m3bis <-lme( y ~ x, random = ~1|date, correlation = 
> corPagel(0.2846964,tree,fixed=TRUE))
>
> This time, t1bis converges. However the output is completely different 
> from t2.
>
> > summary(m3bis)
> Linear mixed-effects model fit by REML
> Data: d
> AIC BIC logLik
> 14907.8 14924.19 -7449.902
>
> Random effects:
> Formula: ~1 | date
> (Intercept) Residual
> StdDev: 809763.6 4632624
>
> Correlation Structure: corPagel
> Formula: ~1 | date
> Parameter estimate(s):
> lambda
> 0.2846964
> Fixed effects: y ~ x
> Value Std.Error DF t-value p-value
> (Intercept) -329242.7 324363.4 438 -1.01504 0.3106
> xY 3.7 0.0 438 127.43249 0.0000
> Correlation:
> (Intr)
> xY 0.014
>
> Second question: how is that possible? The two outputs should be the 
> same.
>
>
> To try to understand what is going on, we can compute the profile 
> log-likelihood curve, as a function of lambda, for both techniques.
>
> lambda <- seq(0,1,0.01)
>
> loglike.t1 <- rep(NA,length(lambda))
> loglike.t2 <- rep(NA,length(lambda))
>
> for (i in 1:length(lambda)){
>
> m1 <- lme(y ~ x, random = ~1|date, correlation = 
> corPagel(lambda[i],tree,fixed=TRUE))
> loglike.t1[i] <- m1$logLik
>
> u = gl(1,1,length(d$y))
> m2 <- lme(y ~ x,random = list(u = pdIdent(form=~factor(date)-1)), 
> correlation = corPagel(lambda[i],tree,fixed=TRUE))
> loglike.t2[i] <- m2$logLik
>
> }
>
> The two curves are completely different:
>
> With t2, we obtain a reasonable curve, with a maximum at the 
> previously estimated lambda value.
>
> With t1, the curve looks really strange: there is a discontinuity at 
> the origin, i.e., for lambda=0 the log-like value is higher than for 
> lambda>0, and for lambda>0 the log-like is only increasing with lambda.
>
> Thus a third question: why are these two profile log-likelihood curves 
> different?
>
> The final question is: in which technique can we believe?
>
> I?m using the version 2.14.1 of R, 3.1-96 of nlme, and 3.0-1 of ape.
>
> Best,
> Rudolf
>

-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat, AStat.
Lecturer and Consultant Statistician
School of Biological Sciences
The University of Queensland
St. Lucia Queensland 4072
Australia
T: +61 7 3365 2506
email: S.Blomberg1_at_uq.edu.au
http://www.uq.edu.au/~uqsblomb/

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

Statistics is the grammar of science - Karl Pearson.



From kedwards at ucdavis.edu  Wed Mar  7 08:38:02 2012
From: kedwards at ucdavis.edu (Kyle Edwards)
Date: Tue, 6 Mar 2012 23:38:02 -0800
Subject: [R-sig-ME] MCMCglmm: multivariate response with phylogenetic
	structure
Message-ID: <E9A2C3E8-A632-4E53-BB2A-26C9DCA34C5E@ucdavis.edu>

Hello,

I am looking for some advice on how to specify an MCMCglmm model with a multivariate response, while accounting for potential phylogenetic structure in the residuals. The data consist of 4 traits (tr1 - tr4), with each trait measured a maximum of one time for each of 27 species (there is some missing data, but that does not appear to be problematic for these analyses). To begin with, following chapter 5 in the course notes, I fit the following model without phylogenetic information:

mod = MCMCglmm(cbind(tr1, tr2, tr3, tr4) ~ trait-1, rcov = ~us(trait):units, data = my.data, family = rep("gaussian", 4))

This model converges quickly and gives sensible results similar to those I have found using other approaches. 

I would next like to incorporate a phylogenetic tree for these species, to test whether this alters the estimated trait correlations. If I understand correctly, this is implemented in MCMCglmm using a combination of the 'random' and 'pedigree' arguments, or a combination of the 'random' and 'ginverse' arguments. So I would expect to include these terms in the model: 

random =~ us(trait):species, pedigree = my.phylogeny,

where the names of the species are the tips of the phylogeny. 

However, I am confused about how to model the 'rcov' argument, once this random effect term is introduced. Because each species is only observed once, there is no residual variation within species, and so it seems this random effect term should make the rcov term in my original model redundant. How should one specify the residual variation in this case? If I fit a model with "rcov = ~us(trait):units, random =~ us(trait):species", it is much slower to converge and the posterior distributions of the trait correlations at both levels are much wider than in the original model. This occurs with or without the pedigree argument included, and it makes sense that I shouldn't be able to separately estimate all these parameters. 

Thanks for any insight into this issue,

Kyle

Kyle Edwards
Postdoctoral Research Associate
Kellogg Biological Station
Michigan State University

edwar466 at msu.edu



From j.hadfield at ed.ac.uk  Wed Mar  7 10:11:14 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 07 Mar 2012 09:11:14 +0000
Subject: [R-sig-ME] MCMCglmm: multivariate response with phylogenetic
 structure
In-Reply-To: <E9A2C3E8-A632-4E53-BB2A-26C9DCA34C5E@ucdavis.edu>
References: <E9A2C3E8-A632-4E53-BB2A-26C9DCA34C5E@ucdavis.edu>
Message-ID: <20120307091114.153469jaj610j280@www.staffmail.ed.ac.uk>

Hi,

If you use the pedigree option you need to make sure that the column  
of species names is called "animal". The pedigree option has been  
superseded by the ginverse argument which allows more flexibility. To  
use this you can retain species in your random formula and then pass  
ginverse(species=Ainv) to MCMCglmm where Ainv can be obtained using  
inverseA(tree)$Ainv.

If you have just modelled species effects as uncorrelated random  
effects then they are equivalent to the residuals and so the two  
covariance matrices cannot be separately estimated as you state. This  
is not the case with a phylogenetic effect because the correlation  
structure allows the effects to be separated. However, separating them  
can still be difficult so you should expect wider credible intervals.  
With 27 species and two 4x4 covariance matrices I think the precision  
of the estimates will be very low and the prior will have a large  
effect.

Cheers,

Jarrod





Quoting Kyle Edwards <kedwards at ucdavis.edu> on Tue, 6 Mar 2012 23:38:02 -0800:

> Hello,
>
> I am looking for some advice on how to specify an MCMCglmm model  
> with a multivariate response, while accounting for potential  
> phylogenetic structure in the residuals. The data consist of 4  
> traits (tr1 - tr4), with each trait measured a maximum of one time  
> for each of 27 species (there is some missing data, but that does  
> not appear to be problematic for these analyses). To begin with,  
> following chapter 5 in the course notes, I fit the following model  
> without phylogenetic information:
>
> mod = MCMCglmm(cbind(tr1, tr2, tr3, tr4) ~ trait-1, rcov =  
> ~us(trait):units, data = my.data, family = rep("gaussian", 4))
>
> This model converges quickly and gives sensible results similar to  
> those I have found using other approaches.
>
> I would next like to incorporate a phylogenetic tree for these  
> species, to test whether this alters the estimated trait  
> correlations. If I understand correctly, this is implemented in  
> MCMCglmm using a combination of the 'random' and 'pedigree'  
> arguments, or a combination of the 'random' and 'ginverse'  
> arguments. So I would expect to include these terms in the model:
>
> random =~ us(trait):species, pedigree = my.phylogeny,
>
> where the names of the species are the tips of the phylogeny.
>
> However, I am confused about how to model the 'rcov' argument, once  
> this random effect term is introduced. Because each species is only  
> observed once, there is no residual variation within species, and so  
> it seems this random effect term should make the rcov term in my  
> original model redundant. How should one specify the residual  
> variation in this case? If I fit a model with "rcov =  
> ~us(trait):units, random =~ us(trait):species", it is much slower to  
> converge and the posterior distributions of the trait correlations  
> at both levels are much wider than in the original model. This  
> occurs with or without the pedigree argument included, and it makes  
> sense that I shouldn't be able to separately estimate all these  
> parameters.
>
> Thanks for any insight into this issue,
>
> Kyle
>
> Kyle Edwards
> Postdoctoral Research Associate
> Kellogg Biological Station
> Michigan State University
>
> edwar466 at msu.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Thierry.ONKELINX at inbo.be  Wed Mar  7 10:36:25 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 7 Mar 2012 09:36:25 +0000
Subject: [R-sig-ME] Question on the glmer function of the lme4 R package
In-Reply-To: <4F56389D.9060905@univ-nantes.fr>
References: <4F56389D.9060905@univ-nantes.fr>
Message-ID: <AA818EAD2576BC488B4F623941DA74275734D895@inbomail.inbo.be>

We need more information to connect your data to the model. What is the interpretation of the subscript i and j and U in connection to your data? How does your dataset look like?

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Feddag Mohand-Larbi
Verzonden: dinsdag 6 maart 2012 17:18
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Question on the glmer function of the lme4 R package

Dear all,

Could you please help me in the estimation of the different parameters of the Bradley-Terry model with random effects by the glmer function of the lme4 R package.

The model, the marginal likelihood and the real data and the main question are described in the attached file.

Best regards


 Dr Feddag



From Thierry.ONKELINX at inbo.be  Wed Mar  7 12:13:37 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 7 Mar 2012 11:13:37 +0000
Subject: [R-sig-ME] Quadratic with Random Offset in One Dimension
In-Reply-To: <CA+b8XEKEaQT6DNMNBtjKTVxs3GfQTcbUN7e8O+MXKmLXWnjHow@mail.gmail.com>
References: <CA+b8XEKEaQT6DNMNBtjKTVxs3GfQTcbUN7e8O+MXKmLXWnjHow@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275734DC96@inbomail.inbo.be>

Dear Christopher,

I think this can be done with a non-linear mixed model (nlmer in lme4).

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Christopher D. Long
Verzonden: zaterdag 3 maart 2012 11:42
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Quadratic with Random Offset in One Dimension

Hi,

I'm looking to fit a family of quadratics in (x,y) with a random factor offset in one variable. The model would look like this:

outcome ~ x^2 + x*(y+F) + (y+F)^2 + 1

with F a random factor.

If this were linear in x,y it'd be no problem:

outcome ~ x + y + 1|F.

Is there a way to get either lme4 to estimate a model like this?
If not, what's my best route?
--
Christopher D. Long, San Diego Padres, 100 Park Blvd, San Diego CA

"Tick, clong, tick, clong, tick, clong, went the night." - Thurber

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From amelie.pinet at gmail.com  Wed Mar  7 14:08:33 2012
From: amelie.pinet at gmail.com (amelie pinet)
Date: Wed, 7 Mar 2012 14:08:33 +0100
Subject: [R-sig-ME] error in nlme()
In-Reply-To: <loom.20120306T180030-171@post.gmane.org>
References: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>
	<loom.20120302T163732-975@post.gmane.org>
	<CAKNZCKFGHNNOwEzuAg2nFwDLFE_CPyjF3NJv8WUEvyVh7_055Q@mail.gmail.com>
	<loom.20120306T180030-171@post.gmane.org>
Message-ID: <CAKNZCKG6LikjjjunjPf0kTjPmHNcp8=8ZGHXRU+JrA6ZtBcqOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120307/119cffc0/attachment-0001.pl>

From Rachel.Gibson at bristol.ac.uk  Wed Mar  7 15:47:24 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Wed, 07 Mar 2012 14:47:24 +0000
Subject: [R-sig-ME] model comparison in glmmADMB
Message-ID: <629F673052B60E61A668B04E@bio-bzjxm-0501.bio.bris.ac.uk>

I am trying to compare two models to see whether the random effect is 
significant, using the anova command I get the following output:

> anova(m7,m8)
Analysis of Variance Table

Model 1: xx ~ nsn * Insect.type + ara * Insect.type + 
offset(logTotal.grains)
Model 2: xx ~ nsn * Insect.type + ara * Insect.type + 
offset(logTotal.grains)
  NoPar  LogLik Df -2logQ P.value
1    12 -2427.4
2    11 -2427.9 -1  -0.96
Warning message:
In pchisq(q, df, lower.tail, log.p) : NaNs produced

Why might this be happening? Can I still use the log likelihood ratio as a 
comparison method? And more generally is this an appropriate test of the 
random effect?

The full models are as follows:

> 
m7<-glmmadmb(x~nsn*Insect.type+ara*Insect.type+offset(logTotal.grains)+(1|Site),data=data1, 
zeroInflation=TRUE, family="nbinom")
>m8<-glmmadmb(x~nsn*Insect.type+ara*Insect.type+offset(logTotal.grains),data=data1, 
zeroInflation=TRUE, family="nbinom")



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From bbolker at gmail.com  Wed Mar  7 16:14:35 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 07 Mar 2012 10:14:35 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <5960F8DE7D578930986AAAAC@bio-bzjxm-0501.bio.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com>
	<loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54BEB4.7060500@gmail.com>
	<E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54CC24.4000901@gmail.com>
	<D1D8247B6F782A74CE134F7D@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54DDD7.6060400@gmail.com>
	<5960F8DE7D578930986AAAAC@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <4F577B5B.2070401@gmail.com>


  After looking at these data a bit I think (this may sound funny coming
from me) that all the fancy mixed-model stuff is overkill in this
situation.  The key is that you have a *nested* design -- your predictor
variables nsn and ara only vary across your 8 sites, not within them.
That means that in a classical analysis of variance you would get the
same answer if you just aggregated the data by site and ran a
fixed-effect model on the site averages, which is what I would recommend
here.  Aggregating the data in this way also takes care of a lot of the
distributional complexity; even if your individual samples have a funny
distribution, their averages (you have at least 8 samples per insect
type per site, and on average about 30) will be approximately normal
unless something really weird is happening.

Murtaugh, Paul A. 2007. ?Simplicity and Complexity in Ecological Data
Analysis.? Ecology 88 (1): 56?62.
http://www.esajournals.org/doi/abs/10.1890/0012-9658%282007%2988%5B56%3ASACIED%5D2.0.CO%3B2.

  It's a secondary question (in my mind) to try to figure out why
glmmADMB isn't converging ...

  PS -- since your proportions sometimes approach 1, the
Poisson/negative binomial + offset approach won't work very well -- it
only works when counts are a small fraction of the total possible.

==========
data1 <- read.table("beepollenq.txt",header=TRUE)

## calculate proportions
data1 <- transform(data1,x=round(x),prop=x/Total.grains)
library(ggplot2)
library(mgcv)

g1 <- ggplot(data1,aes(x=ara,y=prop,colour=Insect.type))+
  geom_point(aes(size=Total.grains),alpha=0.8)+theme_bw()

## all together
g1 + geom_smooth(method="gam",family="binomial",aes(weight=Total.grains))

## separately:  one value of 'ara' per site
g1 +  facet_wrap(~Site)

## the same, but putting nsn on the x axis
g2 <- ggplot(data1,aes(x=nsn,y=prop,colour=Insect.type))+
  geom_point(aes(size=Total.grains),alpha=0.8)+theme_bw()
g2 + geom_smooth(method="gam",family="binomial",aes(weight=Total.grains))
g2 +  facet_wrap(~Site) ## one value of 'nsn' per site

## create aggregated version of data -- mean proportion
library(reshape)
m1 <- melt(subset(data1,select=c(Site,Insect.type,prop,nsn,ara)),
     id.var=c("Site","Insect.type"))
m2 <- cast(m1,Site+Insect.type~...,fun.agg=mean)
m2 <- m2[order(m2$Insect.type),]

ggplot(m2,aes(x=nsn,y=ara,size=prop))+
  geom_point(alpha=0.5)+facet_grid(.~Insect.type)+
  theme_bw()

ggplot(m2,aes(x=nsn,colour=ara,y=prop))+
  geom_point(alpha=0.5)+facet_wrap(~Insect.type,scale="free")+
  theme_bw()+geom_smooth(method="lm")

ggplot(m2,aes(x=ara,colour=nsn,y=prop))+
  geom_point(alpha=0.5)+facet_wrap(~Insect.type,scale="free")+
  theme_bw()+geom_smooth(method="lm")

On 12-03-07 09:23 AM, RH Gibson, School Biological Sciences wrote:
> Hi Ben,
> 
> I have attached the data.
> variable x is the number of strawberry grains out of Total.grains.
> The code is:
> 
> logTotal.grains<-log(Total.grains)
> 
> m7<-glmmadmb(x~nsn*Insect.type+ara*Insect.type+offset(logTotal.grains)+(1|Site),data=data1,
> zeroInflation=TRUE, family="nbinom")
> 
> summary(m7)
> 
> 
> Thanks,
> 
> Rachel.
> 
> 
> 
> 
> --On 05 March 2012 10:37 -0500 Ben Bolker <bbolker at gmail.com> wrote:
> 
>> On 12-03-05 10:24 AM, RH Gibson, School Biological Sciences wrote:
>>> summary(data1) file attached.
>>>
>>> Hope this can shed some light on the problem.
>>>
>>> Rachel.
>>>
>>
>>   Can you send the data themselves?
>>   The summary is good for sanity-checking but to go farther I would need
>> to look at the actual data.  (And, the format of the summary got mangled
>> in transmission ...)
>>
>>>
>>> --On 05 March 2012 09:22 -0500 Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>> On 12-03-05 08:52 AM, RH Gibson, School Biological Sciences wrote:
>>>>>> That would make sense as I am able to fit a zero-inflated negative
>>>>>> binomial model, but not just the binomial. I have tried poisson
>>>>>> too, but this gave me the same error message as trying to fit the
>>>>>> binomial.
>>>>>>
>>>>>> The y variable is a count, offset by a sample total. There is
>>>>>> overdispersion and a lot of zeros in the data. Does using the
>>>>>> zero-inflated negative binomial make sense here?
>>>>>>
>>>>>> Thanks.
>>>
>>>   It very rarely makes sense to use the binomial and the negative
>>> binomial to fit the same set of data; the binomial has a fixed
>>> (typically known) upper limit, the Poisson and NB do not.  (The
>>> exception to this is that people will sometimes use Poisson/NB models
>>> when the upper limit is known but the observed frequency is very low
>>> -- this is especially common e.g. in epidemiology.)  ZINB, or plain
>>> old NB, probably make the most sense.
>>>
>>>   It's more interesting that you get an error message with the
>>> Poisson, which may indicate some glmmADMB instability.  What are the
>>> results of summary(data1)?  How many sites do you have?
>>>
>>>   Ben Bolker
>>>>>>
>>>>>>
>>>>>> --On 05 March 2012 08:25 -0500 Ben Bolker <bbolker at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences
>>>>>>> wrote:
>>>>>>>> Updated to latest version and now having new problems:
>>>>>>>>
>>>>>>>> m3<-
>>>>>>>> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+of
>>>>>>>> fse t(
>>>>>>>>
>>>>>>>>
>>> logTotal.grains)+(1|Site),data=data1, zeroInflation=TRUE,
>>>>>>>> family="binomial") Error in glmmadmb(x ~ nsn * Insect.type +
>>>>>>>> ara * Insect.type + rap * Insect.type +  : The function
>>>>>>>> maximizer failed (couldn't find STD file) In addition: Warning
>>>>>>>> message: running command 'C:\WINDOWS\system32\cmd.exe /c
>>>>>>>> "C:/Program
>>>>>>>> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe"
>>>>>>>> -maxfn 500 -maxph 5 -noinit -shess' had status 1
>>>>>>>>
>>>>>>>
>>>>>>> This now means that the optimization failed for some reason.
>>>>>>> There are many reasons this can happen, mostly having to do with
>>>>>>> too-sparse or unusual data.  Without knowing anything about your
>>>>>>> data, the one thing that pops out is you are using a binomial
>>>>>>> family with zeroInflation=TRUE.  If your response is a matrix of
>>>>>>> successes and failures, that's unusual but plausible; if your
>>>>>>> response is a single 0/1 vector, then it doesn't make sense to
>>>>>>> use zero-inflation.  (If your response is anything else it's odd
>>>>>>> too, although that probably would have been caught earlier.) Try
>>>>>>> working through the troubleshooting steps under ?admbControl
>>>>>>> (and running with verbose=TRUE to see exactly what AD Model
>>>>>>> Builder reports as the problem).
>>>>>>>
>>>>>>> Ben Bolker
>>>>>>>
>>>>>>>
>>>>>>>>
>>>>>>>> Can you help with this?
>>>>>>>>
>>>>>>>> Many thanks, Rachel.
>>>>>>>>
>>>>>>>> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>> Ben Bolker <bbolker at ...> writes:
>>>>>>>>>
>>>>>>>>> [snip]
>>>>>>>>>
>>>>>>>>>> If you do this:
>>>>>>>>>>
>>>>>>>>>> mydata <-
>>>>>>>>>> data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>>>>>>>>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="n
>>>>>>>>>> bin om
>>>>>>>>>>
>>>>>>>>>>
>>> ")
>>>>>>>>>>
>>>>>>>>>> it ought to work.  However, it *should* work the way you
>>>>>>>>>> specified -- I will work on fixing the bug.
>>>>>>>>>>
>>>>>>>>>> thanks Ben Bolker
>>>>>>>>>
>>>>>>>>> This should be fixed now (i.e. in glmmADMB 0.7.2.7). It's
>>>>>>>>> still a good idea to use the data= argument.
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> ---------------------- RH Gibson, School Biological Sciences
>>>>>>>> Rachel.Gibson at bristol.ac.uk
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ---------------------- RH Gibson, School Biological Sciences
>>>>>> Rachel.Gibson at bristol.ac.uk
>>>
>>>
>>>
>>>
>>> ----------------------
>>> RH Gibson, School Biological Sciences
>>> Rachel.Gibson at bristol.ac.uk
>>
> 
> 
> 
> ----------------------
> RH Gibson, School Biological Sciences
> Rachel.Gibson at bristol.ac.uk



From dadrivr at gmail.com  Wed Mar  7 16:15:24 2012
From: dadrivr at gmail.com (Isaac Petersen)
Date: Wed, 7 Mar 2012 10:15:24 -0500
Subject: [R-sig-ME] Comparing the effect size of parameters across
 non-nested models with different outcomes
Message-ID: <CAPBn5Xv8vfKXpj3AKekVc25EtQiyR-16djQdE3nTveSaT=RmMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120307/9f1ecf19/attachment-0001.pl>

From bbolker at gmail.com  Wed Mar  7 17:39:02 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2012 16:39:02 +0000 (UTC)
Subject: [R-sig-ME] model comparison in glmmADMB
References: <629F673052B60E61A668B04E@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <loom.20120307T170528-76@post.gmane.org>

RH Gibson, School Biological Sciences <Rachel.Gibson at ...> writes:

> 
> I am trying to compare two models to see whether the random effect is 
> significant, using the anova command I get the following output:
> 
> > anova(m7,m8)
> Analysis of Variance Table
> 
 [snip]

>   NoPar  LogLik Df -2logQ P.value
> 1    12 -2427.4
> 2    11 -2427.9 -1  -0.96
> Warning message:
> In pchisq(q, df, lower.tail, log.p) : NaNs produced
> 
> Why might this be happening? Can I still use the log likelihood ratio as a 
> comparison method? And more generally is this an appropriate test of the 
> random effect?

  anova.glmmadmb is not smart enough to put the terms in order of
increasing complexity, and it expects you to do so.  This will be
clarified/fixed in the next version.

  More generally, LRTs of random effects are OK but not great; they are
known to be conservative (see http://glmm.wikidot.com/faq both for ways
to test random effects and for questions as to why you would be wanting
to test the significance of a random effect in the first place).



From bbolker at gmail.com  Wed Mar  7 17:41:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2012 16:41:44 +0000 (UTC)
Subject: [R-sig-ME] Comparing the effect size of parameters across
	non-nested models with different outcomes
References: <CAPBn5Xv8vfKXpj3AKekVc25EtQiyR-16djQdE3nTveSaT=RmMA@mail.gmail.com>
Message-ID: <loom.20120307T174034-34@post.gmane.org>

Isaac Petersen <dadrivr at ...> writes:

> 
> Hi,
> 
> Is there a way to compare the effect size of parameters across non-nested
> models with different outcomes?  I would like to test statistically whether
> one parameter is larger than another.  I'm currently using nlme, so that
> would be preferable if possible.  Thanks guys!


 You could standardize both your predictors and your outcomes to all
have standard deviations of 1, then do a t-test between the effects ...



From biowahl at gmail.com  Wed Mar  7 21:20:32 2012
From: biowahl at gmail.com (Colin Wahl)
Date: Wed, 7 Mar 2012 12:20:32 -0800
Subject: [R-sig-ME] lmer/glmer standard error interpretation and
	visualization
Message-ID: <CACu_zZkMuCOHQ6kabDi9f19JkJ+rrH=rgig_PFOY8N4X4okFbA@mail.gmail.com>

Hello,
I am in the process of finalizing figures for my thesis on stream
invertebrate distributions among watershed and riparian types. See
below for additional information on the design. I'm having difficulty
including standard errors from the lmer modeling as error bars in the
figures. Here is the table I've created from the lmer output:
estimates of %EPT and St Error are back transformed from logits and
converted from fractions to percents. Estimates are also absolute (not
relative to the intercept).

 Watershed ? ? Effect ? ? ? ? ? ? ? ? ?Estimate ?St. Error? z score ?p value

 Forested  ? ? Intercept: F vs. 0 ? ?   28.23 ?    59.6 ? ? -2.346 ? ? 0.019*
 ? ? ? ? ? ? ?? ? ? Riparian: ?F vs. NF ? 16.017 ?   62.3 ? ? -1.436 ?   0.151
 Cultivated ? ?Watershed: C vs. F ? ?1.351 ?   65.3 ? ? -5.297 ? ?<0.000*
 ? ? ? ? ? ?  ? ? ? Riparian: ?F vs. NF ? ?1.555 ?    69.2 ? ? ?1.071 ? ?0.284
 Developed ? Watershed: D vs. F ? ?0.175 ?    66.8 ? ? -7.714 ?  <0.000*
 ? ? ? ? ? ? ?? ? ? Riparian: ?F vs. NF ? ?0.292 ?    70.9 ? ? ?1.391 ?   0.164
 Grassland ? ?Watershed: G vs. F ?  28.94 ?   66.6 ?     0.05 ?   ?0.960
 ? ? ? ? ? ? ?  ? ? Riparian: ?F vs. NF ? ? 1.967 ? ? 70.7 ? ? -2.595  ?? 0.009*

The st. errors are huge. I initially used standard error calculations
in excel for error bars (stdev(x)/sqrt(n(x))), which look very
reasonable, and are reflective of significant differences.

Does anyone have any advice to offer for visualizing these glmer
results? Should I use the huge model St. Errors? My inclination is
yes, because they are used to calculated significant differences, but
28 + or - 59.6 with a significant p value seems ridiculous.

Thank you,
Colin Wahl
M.S. Candidate
Dept. of Biology
Western Washington University



From bbolker at gmail.com  Wed Mar  7 23:59:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2012 22:59:51 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lmer/glmer_standard_error_interpretation_and?=
	=?utf-8?q?=09visualization?=
References: <CACu_zZkMuCOHQ6kabDi9f19JkJ+rrH=rgig_PFOY8N4X4okFbA@mail.gmail.com>
Message-ID: <loom.20120307T234946-200@post.gmane.org>

Colin Wahl <biowahl at ...> writes:

> I am in the process of finalizing figures for my thesis on stream
> invertebrate distributions among watershed and riparian types. See
> below for additional information on the design. I'm having difficulty
> including standard errors from the lmer modeling as error bars in the
> figures. Here is the table I've created from the lmer output:
> estimates of %EPT and St Error are back transformed from logits and
> converted from fractions to percents. Estimates are also absolute (not
> relative to the intercept).
> 

 [snip]
 
> The st. errors are huge. I initially used standard error calculations
> in excel for error bars (stdev(x)/sqrt(n(x))), which look very
> reasonable, and are reflective of significant differences.
> 
> Does anyone have any advice to offer for visualizing these glmer
> results? Should I use the huge model St. Errors? My inclination is
> yes, because they are used to calculated significant differences, but
> 28 + or - 59.6 with a significant p value seems ridiculous.

  How did you back-calculate the standard errors?  It simply doesn't
make sense to compute plogis([standard error]) to get the standard
error on the response scale; you can either use the delta method as
one of the variants of predict.glm() does [i.e. multiply the standard
error by the *derivative* of the link function], or calculate the
confidence intervals on the link scale (i.e. estimate plus/minus CI)
and back-transform them (they will not in general be symmetric).

  This is not an lmer issue, this is a general issue with generalized
linear models, or any other model that works on a transformed scale
and for which one wants to backtransform the parameters.



From bbolker at gmail.com  Thu Mar  8 00:07:26 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2012 23:07:26 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lmer/glmer_standard_error_interpretation_and?=
	=?utf-8?q?=09visualization?=
References: <CACu_zZkMuCOHQ6kabDi9f19JkJ+rrH=rgig_PFOY8N4X4okFbA@mail.gmail.com>
	<loom.20120307T234946-200@post.gmane.org>
Message-ID: <loom.20120308T000447-861@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Colin Wahl <biowahl at ...> writes:
> 
>   This is not an lmer issue, this is a general issue with generalized
> linear models, or any other model that works on a transformed scale
> and for which one wants to backtransform the parameters.

 PS  this is why epidemiologists spend so much time learning about
odds ratios and log-odds -- you can back-transform from logit effects
to odds-ratio effects, but once you get there there's just not any
perfect way to transform back to a probability scale in a way that
is completely general ... http://lesswrong.com/lw/8lr/logodds_or_logits/



From charla at uoguelph.ca  Thu Mar  8 05:49:37 2012
From: charla at uoguelph.ca (Charla Patterson)
Date: Wed, 7 Mar 2012 23:49:37 -0500 (EST)
Subject: [R-sig-ME] Mixed Effects Logistic Regression Model and finding
	p-values
In-Reply-To: <325606998.530471.1331179327904.JavaMail.root@simcoe.cs.uoguelph.ca>
Message-ID: <2134804838.532357.1331182177431.JavaMail.root@simcoe.cs.uoguelph.ca>

Hello List Members,

I am a masters student that is relatively new to R and am currently working on the analysis of my project. For my project, I collected data on individual birds every year (sex, migratory or resident) along with environmental measurements from their breeding grounds (average min. winter temperature, total winter precipitation, ect.). I am interested in finding out whether the decision to migrate in this population is affected by environmental cures.  

Here is a sample of my data from the original .csv file:

bnum	sex 	ystat 	year	wintering site	breeding site  direct.  minall  totprecall
39	1	1	1991.92	Burlington	Wye marsh	S	-4.5	98.75
39	1	1	1991.92	Burlington	Wye marsh	N	-4.5	98.75
75	0	1	1991.92	Aurora	        Wye marsh	        -4.5	98.75
78	1	0	1991.92	Wye Marsh	Wye Marsh		-4.5	98.75
79	0	0	1991.92	Wye Marsh	Wye Marsh		-4.5	98.75
80	1	0	1991.92	Wye Marsh	Wye Marsh		-4.5	98.75
961	0	1	1991.92	Burlington	Wye Marsh	S	-4.5	98.75
961	0	1	1991.92	Burlington	Wye Marsh	N	-4.5	98.75
74	1	0	1992.93	Wye marsh	Wye marsh		-3.9	125.65
75	0	0	1992.93	Wye marsh	Wye marsh		-3.9	125.65
78	1	0	1992.93	Wye Marsh	Wye Marsh		-3.9	125.65


Where bnum is the bird ID, sex (Female=1, male=0) and ystat is the decision to migrate (migrant=1, resident=0), minall is average minimum winter temperature for the year and totprecall is total winter precipitation for the year.

I wanted to use a mixed effects logistic regression model where ystat is the response (binary), the fixed effects would be sex, minall and totprecall  and the random effects would be bnum and year.

my proposed model and the corresponding results are:

> yr<- as.factor(year)
> mod3<- glmer(ystat~minall + totprecall+ (1 |yr)+(1 | bnum), data=birds,family=binomial(link='logit'))
> summary(mod3) 

Generalized linear mixed model fit by the Laplace approximation 
Formula: ystat ~ minall + totprecall + (1 | yr) + (1 | bnum) 
   Data: birds 
   AIC   BIC logLik deviance
 857.3 881.9 -423.6    847.3
Random effects:
 Groups Name        Variance Std.Dev.
 bnum   (Intercept) 20.0576  4.4786  
 yr     (Intercept)  2.2188  1.4896  
Number of obs: 1014, groups: bnum, 209; yr, 19

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)  
(Intercept) -1.423079   2.088999  -0.681   0.4957  
minall      -0.419361   0.212170  -1.976   0.0481 *
totprecall  -0.006249   0.022842  -0.274   0.7844  
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

Correlation of Fixed Effects:
           (Intr) minall
minall     -0.046       
totprecall -0.904  0.408


Although I think my model is okay, I was struggling with a couple things:

1. When I use year as a fixed effect in my model instead of as a random effect, the p-values for all other parameters are much lower. I don't understand why and it makes me apprehensive about the model and p-values I have. Are the p-values I reported here reliable?

2. I read that a good alternative is to use mcmcglmm to get p-values and HPDintervals, but I'm finding it tricky as well.

I tried to use mcmcsamp along with the pvals.fnc(mod3, nsim=10000) function, but it turns out that this doesn't work with lme4 package. I read that mcmcglmm is a good alternative, so I read the R notes but found that I can't get it to work. Here is my code and the associated warning messages:

m <- MCMCglmm(ystat ~ minall, random = ~bnum+yr, data = birds, family = "categorical")

Error in buildZ(rmodel.terms[r], data = data, formZ = TRUE, nginverse = names(ginverse)) : 
  missing values in random predictors

I have no idea what this means? I am really stuck and I feel like I'm missing something really important here.

3. This may be a very basic question, but could someone provide directions or a reference as to how to plot the logistic curve representing the relationship between minall and ystat? I used plot(minall,ystat) along with some other more complicated codes; however, I have not been able to produce a plot that shows the logistic curve.


Any guidance on any of these issues would be greatly appreciated! Thank you in advance for your time,

Charla



From annebj at gmail.com  Thu Mar  8 06:34:31 2012
From: annebj at gmail.com (Anne Bjorkman)
Date: Wed, 7 Mar 2012 21:34:31 -0800
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB,
	and cloglog
In-Reply-To: <330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>
References: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>
Message-ID: <CAHem2OG8G_Xg9gkA2Dn4K=hB=z6aPhFkiSxrfzDGA+uFAQ-wMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120307/26019138/attachment-0001.pl>

From bbolker at gmail.com  Thu Mar  8 19:36:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 8 Mar 2012 18:36:22 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?zero-inflation_with_mixed-effects=2C_glmmADM?=
	=?utf-8?q?B=2C=09and_cloglog?=
References: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>
	<CAHem2OG8G_Xg9gkA2Dn4K=hB=z6aPhFkiSxrfzDGA+uFAQ-wMg@mail.gmail.com>
Message-ID: <loom.20120308T192749-966@post.gmane.org>

Anne Bjorkman <annebj at ...> writes:


> 

 [snip]

> Do you (or anyone else from the list) have any advice for me about using
> the slope parameters from the mixed-effects models? My original email was
> probably far to long for anyone to read, so I will paraphrase my primary
> question here very briefly:
> 
> I am interested in change over time, so I would like to use slope
> parameters for a number of different species (abundance data for 154
> locations of 42 different species, measured in 5 equally-spaced years, the
> same locations are measured in each year, thus the need for a random effect
> of location).  I would like to model each species separately and use the
> slope parameter from each model as an estimate of the direction and
> magnitude of change over time for that species.  However, the distribution
> of the data for each species are quite different - some are highly
> zero-inflated, others are nearly normal.
> 
> My question is this: should I use the same model specifications for every
> species (e.g., use negative binomial/zero-inflated distributions even for
> those species that appear more normally distributed), or can I use the
> "best" model for each species (based on the distribution of the data for
> that species) and still compare the slope values to each other?  The
> important thing is that the slope values are comparable, because I am
> interested in how much each species has changed relative to the other
> species.
> I don't often see slope parameters from mixed models used in this way, so I
> am a little hesitant about the feasibility of what I'm trying to do. Any
> insight would be hugely appreciated.
> 
> Thanks very much!
> Anne
> 

  It depends a bit on what you mean by "compare". In any case you need
to make sure that the slope parameters are measuring the same thing --
so for example it would be a bad idea to compare (1) parameters
estimated using a model with a log link (e.g. negative binomial), so
that the parameter represented an exponential growth rate or
per-capita proportional change per year and parameters estimated on a
raw scale and (2) parameters estimated on the data or identity scale
(e.g. ordinary least-squares regression), so that the parameter
representing a linear rate of increase -- then you would be comparing
apples and oranges.  Similarly, if you have a model that incorporates
zero-inflation, you need to make sure that you're comparing a quantity
that reflects the change in the _mean_ density over time. On the
other hand if you use a zero-inflation model with a constant level of
zero-inflation over time, then the means at times t and t+1 will be
(1-p_z)*mu(t) and (1-p_z)*mu(t+1), so you should be able to disregard the
zero-inflation if you're comparing the proportional growth rate.
  At this level, just making sure that you know what your slope
parameter means, and that you are comparing comparable things, should
be sufficient.

  The next-level issue is doing _statistical_ comparisons among
species (i.e. species A is shrinking significantly faster than
species B).  Ideally you would do this by incorporating all of the
data in a single model and testing the significance of the
species*time interaction coefficients, but that would be hard
with your data.  It's a bit crude, but you could do _post hoc_
t-tests based on the estimated slope parameters and their
standard errors ...



From kay.cichini at gmail.com  Thu Mar  8 20:04:55 2012
From: kay.cichini at gmail.com (Kay Cichini)
Date: Thu, 8 Mar 2012 20:04:55 +0100
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB,
	and cloglog
In-Reply-To: <CAHem2OG8G_Xg9gkA2Dn4K=hB=z6aPhFkiSxrfzDGA+uFAQ-wMg@mail.gmail.com>
References: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>
	<CAHem2OG8G_Xg9gkA2Dn4K=hB=z6aPhFkiSxrfzDGA+uFAQ-wMg@mail.gmail.com>
Message-ID: <CADcQ+Rou9+cg8cOmsPXofXJzJ3_S61tmx10CyxvzBr8LvYZ7bg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120308/46a1243e/attachment-0001.pl>

From chantepie at mnhn.fr  Fri Mar  9 10:33:42 2012
From: chantepie at mnhn.fr (chantepie at mnhn.fr)
Date: Fri, 09 Mar 2012 10:33:42 +0100
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned G/R
 structure" and "Mixed model equations singular" errors
Message-ID: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>

Dear all,

I am using MCMCglmm function to construct bivariate animal models of  
bustard sperm production according to age-classes.

The problem is that the models can stochastically crash before the end  
of the run  (at 2000 iterations or 120000 or other) or can finish. For  
the model which does not finish, R returns different errors as:
-Mixed model equations singular: use a (stronger) prior
-ill-conditioned G/R structure: use proper priors if you haven't or  
rescale data if you have

For the models which reach the end, the estimations of genetic  
additive variance appear quite good (nice bell shaped posterior  
disctribution).

The problem still remains when I remove the animal term.
When I run univariate models, it works fine and the posteriors  
distributions look very good.

Strangely, the more data I have, the more models crash (the largest  
amount of data I have is 65000 data for 2400 individuals for one model).

The model looks like:

priorExp<-list(G=list(G1=list(V=diag(2), nu=2,  
alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
G2=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
G3=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000)),
R=list(V=diag(2), nu=2))

spz<-MCMCglmm(cbind(age1_2,age5_6)~trait-1 + trait:tse+  
trait:I(tse^2)+ trait:joe + trait:I(joe^2),
    random=~us(trait):animal+us(trait):ID+us(trait):annee ,
    rcov=~us(trait):units,nitt=150000, thin=1000, burnin=100000,  
prior=priorExp, verbose=TRUE, pedigree=ped,
    family=c("gaussian","gaussian"), data=dat)

For the fixed effects : I use 4 continuous parameters as correction  
for each trait
For the random effects: I use, individuals, years and animal parameters

I have also tried more informative prior (as described in WAMWIKI) but  
the problem was the same.


To give you an example :

Because of computing limitation, I use multi-chain process. I run  
several times the same model (as above) and concatenate results (same  
prior,same burning, same thin and random seed) to obtain at least 1000  
estimates (50 estimates by model). In this context, I ran 50  
bivariable models with the age-class age1_2 and the age-class age5_6  
but only 9 models of the 50 models reached the end.

When we look fixed parameters estimates (estimate are binded for the  
nine models : http://ubuntuone.com/3Gi8GwjcRk3P01MxJp2qLe ), we can  
see that the estimates are really close to 0. Could it be the problem?
When we look ramdom parameters estimates (estimate are binded for the  
nine models : http://ubuntuone.com/42oaP9euG1m2LNipMawcHX ), the  
residual estimates do not look very good. Could it be the problem?

Last thing, if I try to add a cubic effect, all the models crash (same  
error than before or memory mapped error).

I really do not know where the problem comes from. Do you have an idea?

Thanks

--
Stephane Chantepie
CNRS Phd  candidate
Mus?um national d'Histoire naturelle
55 rue Buffon
75005 paris
E-mail : chantepie_at_mnhn.fr
--



From j.hadfield at ed.ac.uk  Fri Mar  9 10:42:23 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 09 Mar 2012 09:42:23 +0000
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned
 G/R structure" and "Mixed model equations singular" errors
In-Reply-To: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
References: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
Message-ID: <20120309094223.53002azjabyja7pc@www.staffmail.ed.ac.uk>

Dear Stephane,

When you say crash do you mean crash in the sense of a segfault or in  
the sense that it stops with the errors:

  -Mixed model equations singular: use a (stronger) prior
  -ill-conditioned G/R structure: use proper priors if you haven't or  
rescale data if you have

If the latter, it may just require a rescaling of your continuous  
covariates by using something like scale(). If the former, it would be  
good for me to have a reproducible example as it means there is a bug.

Cheers,

Jarrod





uoting chantepie at mnhn.fr on Fri, 09 Mar 2012 10:33:42 +0100:

> Dear all,
>
> I am using MCMCglmm function to construct bivariate animal models of  
> bustard sperm production according to age-classes.
>
> The problem is that the models can stochastically crash before the  
> end of the run  (at 2000 iterations or 120000 or other) or can  
> finish. For the model which does not finish, R returns different  
> errors as:
> -Mixed model equations singular: use a (stronger) prior
> -ill-conditioned G/R structure: use proper priors if you haven't or  
> rescale data if you have
>
> For the models which reach the end, the estimations of genetic  
> additive variance appear quite good (nice bell shaped posterior  
> disctribution).
>
> The problem still remains when I remove the animal term.
> When I run univariate models, it works fine and the posteriors  
> distributions look very good.
>
> Strangely, the more data I have, the more models crash (the largest  
> amount of data I have is 65000 data for 2400 individuals for one  
> model).
>
> The model looks like:
>
> priorExp<-list(G=list(G1=list(V=diag(2), nu=2,  
> alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
> G2=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
> G3=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000)),
> R=list(V=diag(2), nu=2))
>
> spz<-MCMCglmm(cbind(age1_2,age5_6)~trait-1 + trait:tse+  
> trait:I(tse^2)+ trait:joe + trait:I(joe^2),
>    random=~us(trait):animal+us(trait):ID+us(trait):annee ,
>    rcov=~us(trait):units,nitt=150000, thin=1000, burnin=100000,  
> prior=priorExp, verbose=TRUE, pedigree=ped,
>    family=c("gaussian","gaussian"), data=dat)
>
> For the fixed effects : I use 4 continuous parameters as correction  
> for each trait
> For the random effects: I use, individuals, years and animal parameters
>
> I have also tried more informative prior (as described in WAMWIKI)  
> but the problem was the same.
>
>
> To give you an example :
>
> Because of computing limitation, I use multi-chain process. I run  
> several times the same model (as above) and concatenate results  
> (same prior,same burning, same thin and random seed) to obtain at  
> least 1000 estimates (50 estimates by model). In this context, I ran  
> 50 bivariable models with the age-class age1_2 and the age-class  
> age5_6 but only 9 models of the 50 models reached the end.
>
> When we look fixed parameters estimates (estimate are binded for the  
> nine models : http://ubuntuone.com/3Gi8GwjcRk3P01MxJp2qLe ), we can  
> see that the estimates are really close to 0. Could it be the problem?
> When we look ramdom parameters estimates (estimate are binded for  
> the nine models : http://ubuntuone.com/42oaP9euG1m2LNipMawcHX ), the  
> residual estimates do not look very good. Could it be the problem?
>
> Last thing, if I try to add a cubic effect, all the models crash  
> (same error than before or memory mapped error).
>
> I really do not know where the problem comes from. Do you have an idea?
>
> Thanks
>
> --
> Stephane Chantepie
> CNRS Phd  candidate
> Mus?um national d'Histoire naturelle
> 55 rue Buffon
> 75005 paris
> E-mail : chantepie_at_mnhn.fr
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Mike.Lawrence at dal.ca  Fri Mar  9 14:44:58 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 9 Mar 2012 09:44:58 -0400
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
Message-ID: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>

Hi folks,

I'm playing with lme4Eigen (version 0.9996875-8, running on Mac OS
10.7.3 using R 2.14.2) and am quite excited by the new bootMer()
function. However, when I try to run it, regardless of what fit I
provide for the argument "x" or function I provide for the argument
"FUN" (including running the examples), I get the error:

Error in envRefInferField(x, what, getClass(class(x)), selfEnv) :
  "resp" is not a valid field or method name for reference class ?lmerResp?

I presume that this is why the bootMer documentation example section
says "## Not run: %%--- fails for now --- FIXME"? I just thought I'd
double-check.

Also, I thought I'd make sure the devs know that the latest svn
version doesn't build on mac; when I try to do so, I get the error:

glmFamily.cpp: In member function ?virtual const Eigen::ArrayXd
glm::negativeBinomialDist::variance(const Eigen::ArrayXd&) const?:
glmFamily.cpp:228: error: ?Rcout? is not a member of ?Rcpp?

Cheers,

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar: http://goo.gl/BYH99

~ Certainty is folly... I think. ~



From chantepie at mnhn.fr  Fri Mar  9 17:33:52 2012
From: chantepie at mnhn.fr (chantepie at mnhn.fr)
Date: Fri, 09 Mar 2012 17:33:52 +0100
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned
 G/R structure" and "Mixed model equations singular" errors
In-Reply-To: <20120309094223.53002azjabyja7pc@www.staffmail.ed.ac.uk>
References: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
	<20120309094223.53002azjabyja7pc@www.staffmail.ed.ac.uk>
Message-ID: <20120309173352.168215srxwe8241c@dsiwebmail.mnhn.fr>

Dear Jarrod and others,

It is not a segfault error, the runs actually stop with one of these two
errors.

My covariates have already been rescaled (centered to be precise). I have
tried to center-reduce the covariates (by usind scale) but the result was the
same.

Also, when I use cubic term for "tse" and "joe" , the models stop running
before 1000 iterations.

Could the problem come from the number of fixed parameters to estimate? It
seems strange because I have a quiet big data set.

kind regards

stephane

Jarrod Hadfield <j.hadfield at ed.ac.uk> a ?crit?:

> Dear Stephane,
>
> When you say crash do you mean crash in the sense of a segfault or  
> in the sense that it stops with the errors:
>
>  -Mixed model equations singular: use a (stronger) prior
>  -ill-conditioned G/R structure: use proper priors if you haven't or  
> rescale data if you have
>
> If the latter, it may just require a rescaling of your continuous  
> covariates by using something like scale(). If the former, it would  
> be good for me to have a reproducible example as it means there is a  
> bug.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> uoting chantepie at mnhn.fr on Fri, 09 Mar 2012 10:33:42 +0100:
>
>> Dear all,
>>
>> I am using MCMCglmm function to construct bivariate animal models  
>> of bustard sperm production according to age-classes.
>>
>> The problem is that the models can stochastically crash before the  
>> end of the run  (at 2000 iterations or 120000 or other) or can  
>> finish. For the model which does not finish, R returns different  
>> errors as:
>> -Mixed model equations singular: use a (stronger) prior
>> -ill-conditioned G/R structure: use proper priors if you haven't or  
>> rescale data if you have
>>
>> For the models which reach the end, the estimations of genetic  
>> additive variance appear quite good (nice bell shaped posterior  
>> disctribution).
>>
>> The problem still remains when I remove the animal term.
>> When I run univariate models, it works fine and the posteriors  
>> distributions look very good.
>>
>> Strangely, the more data I have, the more models crash (the largest  
>> amount of data I have is 65000 data for 2400 individuals for one  
>> model).
>>
>> The model looks like:
>>
>> priorExp<-list(G=list(G1=list(V=diag(2), nu=2,  
>> alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
>> G2=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
>> G3=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000)),
>> R=list(V=diag(2), nu=2))
>>
>> spz<-MCMCglmm(cbind(age1_2,age5_6)~trait-1 + trait:tse+  
>> trait:I(tse^2)+ trait:joe + trait:I(joe^2),
>>   random=~us(trait):animal+us(trait):ID+us(trait):annee ,
>>   rcov=~us(trait):units,nitt=150000, thin=1000, burnin=100000,  
>> prior=priorExp, verbose=TRUE, pedigree=ped,
>>   family=c("gaussian","gaussian"), data=dat)
>>
>> For the fixed effects : I use 4 continuous parameters as correction  
>> for each trait
>> For the random effects: I use, individuals, years and animal parameters
>>
>> I have also tried more informative prior (as described in WAMWIKI)  
>> but the problem was the same.
>>
>>
>> To give you an example :
>>
>> Because of computing limitation, I use multi-chain process. I run  
>> several times the same model (as above) and concatenate results  
>> (same prior,same burning, same thin and random seed) to obtain at  
>> least 1000 estimates (50 estimates by model). In this context, I  
>> ran 50 bivariable models with the age-class age1_2 and the  
>> age-class age5_6 but only 9 models of the 50 models reached the end.
>>
>> When we look fixed parameters estimates (estimate are binded for  
>> the nine models : http://ubuntuone.com/3Gi8GwjcRk3P01MxJp2qLe ), we  
>> can see that the estimates are really close to 0. Could it be the  
>> problem?
>> When we look ramdom parameters estimates (estimate are binded for  
>> the nine models : http://ubuntuone.com/42oaP9euG1m2LNipMawcHX ),  
>> the residual estimates do not look very good. Could it be the  
>> problem?
>>
>> Last thing, if I try to add a cubic effect, all the models crash  
>> (same error than before or memory mapped error).
>>
>> I really do not know where the problem comes from. Do you have an idea?
>>
>> Thanks
>>
>> --
>> Stephane Chantepie
>> CNRS Phd  candidate
>> Mus?um national d'Histoire naturelle
>> 55 rue Buffon
>> 75005 paris
>> E-mail : chantepie_at_mnhn.fr
>> --
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>



From bbolker at gmail.com  Fri Mar  9 23:44:58 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 9 Mar 2012 22:44:58 +0000 (UTC)
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
References: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>
Message-ID: <loom.20120309T234321-724@post.gmane.org>

Mike Lawrence <Mike.Lawrence at ...> writes:

> I'm playing with lme4Eigen (version 0.9996875-8, running on Mac OS
> 10.7.3 using R 2.14.2) and am quite excited by the new bootMer()
> function. However, when I try to run it, regardless of what fit I
> provide for the argument "x" or function I provide for the argument
> "FUN" (including running the examples), I get the error:
> 
> Error in envRefInferField(x, what, getClass(class(x)), selfEnv) :
>   "resp" is not a valid field or method name for reference class ?lmerResp?
> 
> I presume that this is why the bootMer documentation example section
> says "## Not run: %%--- fails for now --- FIXME"? I just thought I'd
> double-check.

  More recently (version 12) this should work ...
> 
> Also, I thought I'd make sure the devs know that the latest svn
> version doesn't build on mac; when I try to do so, I get the error:
> 
> glmFamily.cpp: In member function ?virtual const Eigen::ArrayXd
> glm::negativeBinomialDist::variance(const Eigen::ArrayXd&) const?:
> glmFamily.cpp:228: error: ?Rcout? is not a member of ?Rcpp?


 Thanks for the heads-up.  I will check into it and try to see about
getting new binary versions of RcppEigen and lme4Eigen up on the
repository -- although possibly not before Monday.

  cheers
    Ben



From Mike.Lawrence at dal.ca  Sat Mar 10 09:20:52 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sat, 10 Mar 2012 04:20:52 -0400
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
In-Reply-To: <loom.20120309T234321-724@post.gmane.org>
References: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>
	<loom.20120309T234321-724@post.gmane.org>
Message-ID: <CAB+QPJCn60Oq_ogQ3bjFV68Zf9VLKU6kOkoDgXyq7DeX8j-Y=g@mail.gmail.com>

On Fri, Mar 9, 2012 at 6:44 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Also, I thought I'd make sure the devs know that the latest svn
>> version doesn't build on mac; when I try to do so, I get the error:
>>
>> glmFamily.cpp: In member function ?virtual const Eigen::ArrayXd
>> glm::negativeBinomialDist::variance(const Eigen::ArrayXd&) const?:
>> glmFamily.cpp:228: error: ?Rcout? is not a member of ?Rcpp?
>
>
> ?Thanks for the heads-up. ?I will check into it and try to see about
> getting new binary versions of RcppEigen and lme4Eigen up on the
> repository -- although possibly not before Monday.

While I'm not super familiar with C++, I took a look at the
"glmFamily.cpp" file indicated by the error message, and it seems that
all that has happened is that a few lines (used for debugging?)
starting "Rcpp::Rcout" need to be be commented out to "//Rcpp::Rcout"
in "glmFamily.cpp" and also "optimizer.cpp". Once this is done, the
current svn builds fine on mac.

Mike



From dmcastil at umail.iu.edu  Sat Mar 10 16:59:35 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Sat, 10 Mar 2012 10:59:35 -0500
Subject: [R-sig-ME] glmmADMB mcmc output
Message-ID: <CAMmHrnz_BUG4e3W3rqXp30q+wSVjk2-yN00gdW3RjtPX-+GaEw@mail.gmail.com>

Dear list members,

I have run the ML and mcmc for my model. I am wondering if there is a
simple transformation between the the ML coefficients and mcmc
coefficients. Or in general how do I interpret the mcmc coefficients
(I know how to interpret the ml coefficients). For example e^4.03 is
not in the range of the HPD for beta1 of the mcmc

nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
family="nbinom1")
> summary(nb1)

Call:
glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
   (1 | Pop), data = data, family = "nbinom1")


Coefficients:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)          4.03120    0.26620   15.14  < 2e-16 ***
D2_female            0.05115    0.00532    9.62  < 2e-16 ***
BacteriaE            0.13913    0.25159    0.55     0.58
EnviroEC             1.06900    0.22090    4.84  1.3e-06 ***
D2_female:BacteriaE  0.02622    0.00578    4.54  5.7e-06 ***
D2_female:EnviroEC  -0.03357    0.00471   -7.13  9.7e-13 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=95, Pop=16
Random effect variance(s):
Group=Pop
           Variance StdDev
(Intercept)  0.04716 0.2172
Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)

Log-likelihood: -572.814

>nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data, family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
> m<-as.mcmc(nb_mcmc$mcmc)
> head(HPDinterval(m))
           lower     upper
beta.1 50.4190302 55.231164
beta.2  6.3920598  9.033473
beta.3  0.5165269  4.145737
beta.4  1.7327276  5.167999
beta.5  1.6289002  3.791544
beta.6 -3.9886068 -2.057463

Thanks

Dean



From j.hadfield at ed.ac.uk  Sun Mar 11 10:20:29 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 11 Mar 2012 09:20:29 +0000
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned
 G/R structure" and "Mixed model equations singular" errors
In-Reply-To: <20120309173352.168215srxwe8241c@dsiwebmail.mnhn.fr>
References: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
	<20120309094223.53002azjabyja7pc@www.staffmail.ed.ac.uk>
	<20120309173352.168215srxwe8241c@dsiwebmail.mnhn.fr>
Message-ID: <20120311092028.13357jqqer7t0k08@www.staffmail.ed.ac.uk>

Hi Stephane,

Its very hard to know what could be causing the problem with out  
having the data. The three things that you could try are:


  a) scale the response variable

  b) work out if some terms really are weakly identified (MCMCglmm  
drops non-identified terms in the fixed effects by default)

  c) the error can appear I think if the residual covariance matrix  
becomes singular. This could happen, amongst other reasons, because  
non-modelled non-genetic effects are contributing to the resemblance  
between relatives and inflating Va by so much that Ve goes to zero.

Either i) running it for some iterations before it terminates or ii)  
fit the model in ASReml should give you some idea which of these  
problems are most likely.

Cheers,

Jarrod




Quoting chantepie at mnhn.fr on Fri, 09 Mar 2012 17:33:52 +0100:

> Dear Jarrod and others,
>
> It is not a segfault error, the runs actually stop with one of these two
> errors.
>
> My covariates have already been rescaled (centered to be precise). I have
> tried to center-reduce the covariates (by usind scale) but the result was the
> same.
>
> Also, when I use cubic term for "tse" and "joe" , the models stop running
> before 1000 iterations.
>
> Could the problem come from the number of fixed parameters to estimate? It
> seems strange because I have a quiet big data set.
>
> kind regards
>
> stephane
>
> Jarrod Hadfield <j.hadfield at ed.ac.uk> a ?crit?:
>
>> Dear Stephane,
>>
>> When you say crash do you mean crash in the sense of a segfault or  
>> in the sense that it stops with the errors:
>>
>> -Mixed model equations singular: use a (stronger) prior
>> -ill-conditioned G/R structure: use proper priors if you haven't or  
>> rescale data if you have
>>
>> If the latter, it may just require a rescaling of your continuous  
>> covariates by using something like scale(). If the former, it would  
>> be good for me to have a reproducible example as it means there is  
>> a bug.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>> uoting chantepie at mnhn.fr on Fri, 09 Mar 2012 10:33:42 +0100:
>>
>>> Dear all,
>>>
>>> I am using MCMCglmm function to construct bivariate animal models  
>>> of bustard sperm production according to age-classes.
>>>
>>> The problem is that the models can stochastically crash before the  
>>> end of the run  (at 2000 iterations or 120000 or other) or can  
>>> finish. For the model which does not finish, R returns different  
>>> errors as:
>>> -Mixed model equations singular: use a (stronger) prior
>>> -ill-conditioned G/R structure: use proper priors if you haven't  
>>> or rescale data if you have
>>>
>>> For the models which reach the end, the estimations of genetic  
>>> additive variance appear quite good (nice bell shaped posterior  
>>> disctribution).
>>>
>>> The problem still remains when I remove the animal term.
>>> When I run univariate models, it works fine and the posteriors  
>>> distributions look very good.
>>>
>>> Strangely, the more data I have, the more models crash (the  
>>> largest amount of data I have is 65000 data for 2400 individuals  
>>> for one model).
>>>
>>> The model looks like:
>>>
>>> priorExp<-list(G=list(G1=list(V=diag(2), nu=2,  
>>> alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
>>> G2=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
>>> G3=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000)),
>>> R=list(V=diag(2), nu=2))
>>>
>>> spz<-MCMCglmm(cbind(age1_2,age5_6)~trait-1 + trait:tse+  
>>> trait:I(tse^2)+ trait:joe + trait:I(joe^2),
>>>  random=~us(trait):animal+us(trait):ID+us(trait):annee ,
>>>  rcov=~us(trait):units,nitt=150000, thin=1000, burnin=100000,  
>>> prior=priorExp, verbose=TRUE, pedigree=ped,
>>>  family=c("gaussian","gaussian"), data=dat)
>>>
>>> For the fixed effects : I use 4 continuous parameters as  
>>> correction for each trait
>>> For the random effects: I use, individuals, years and animal parameters
>>>
>>> I have also tried more informative prior (as described in WAMWIKI)  
>>> but the problem was the same.
>>>
>>>
>>> To give you an example :
>>>
>>> Because of computing limitation, I use multi-chain process. I run  
>>> several times the same model (as above) and concatenate results  
>>> (same prior,same burning, same thin and random seed) to obtain at  
>>> least 1000 estimates (50 estimates by model). In this context, I  
>>> ran 50 bivariable models with the age-class age1_2 and the  
>>> age-class age5_6 but only 9 models of the 50 models reached the end.
>>>
>>> When we look fixed parameters estimates (estimate are binded for  
>>> the nine models : http://ubuntuone.com/3Gi8GwjcRk3P01MxJp2qLe ),  
>>> we can see that the estimates are really close to 0. Could it be  
>>> the problem?
>>> When we look ramdom parameters estimates (estimate are binded for  
>>> the nine models : http://ubuntuone.com/42oaP9euG1m2LNipMawcHX ),  
>>> the residual estimates do not look very good. Could it be the  
>>> problem?
>>>
>>> Last thing, if I try to add a cubic effect, all the models crash  
>>> (same error than before or memory mapped error).
>>>
>>> I really do not know where the problem comes from. Do you have an idea?
>>>
>>> Thanks
>>>
>>> --
>>> Stephane Chantepie
>>> CNRS Phd  candidate
>>> Mus?um national d'Histoire naturelle
>>> 55 rue Buffon
>>> 75005 paris
>>> E-mail : chantepie_at_mnhn.fr
>>> --
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Mohand-Larbi.Feddag at univ-nantes.fr  Mon Mar 12 10:29:32 2012
From: Mohand-Larbi.Feddag at univ-nantes.fr (Feddag Mohand-Larbi)
Date: Mon, 12 Mar 2012 10:29:32 +0100
Subject: [R-sig-ME] Fwd: Re: Question on the glmer function of the lme4 R
 package
Message-ID: <4F5DC1FC.8040506@univ-nantes.fr>



	

	

	

	

Dear Thiery

Thanks for your email.

The subscripts i and j are the subject i and j (in our case the subjects
are the lizards (players)). U is the n vector of the random effects
(U1,...,Un). Each random effect Ui is supposed to be distributed as
normal with mean 0 and variance sigma^2.

For our data (attached in Data.txt file), the matrix is of order
(77*77), and contains  only 100 non missing data (all the remaining are
missing (NA)).

The matrix of covariates (attached in Covariates.txt) is of order (77*4).

We would like to estimate the four fixed effects parameters associated
to the covariate matrix and the variance of the random effects Ui.


Best regards


Dr Feddag






On 07/03/2012 10:36, ONKELINX, Thierry wrote:
> We need more information to connect your data to the model. What is the interpretation of the subscript i and j and U in connection to your data? How does your dataset look like?
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Feddag Mohand-Larbi
> Verzonden: dinsdag 6 maart 2012 17:18
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Question on the glmer function of the lme4 R package
>
> Dear all,
>
> Could you please help me in the estimation of the different parameters of the Bradley-Terry model with random effects by the glmer function of the lme4 R package.
>
> The model, the marginal likelihood and the real data and the main question are described in the attached file.
>
> Best regards
>
>
>  Dr Feddag
>
>
>


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Data.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120312/fed118aa/attachment-0002.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Covariates.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120312/fed118aa/attachment-0003.txt>

From ken.knoblauch at inserm.fr  Mon Mar 12 14:36:18 2012
From: ken.knoblauch at inserm.fr (Ken knoblauch)
Date: Mon, 12 Mar 2012 13:36:18 +0000 (UTC)
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
References: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>
	<loom.20120309T234321-724@post.gmane.org>
Message-ID: <loom.20120312T142327-813@post.gmane.org>

Ben Bolker <bbolker at ...> writes:
> Mike Lawrence <Mike.Lawrence at ...> writes:
> > I'm playing with lme4Eigen (version 0.9996875-8, running on Mac OS
> > 10.7.3 using R 2.14.2) and am quite excited by the new bootMer()
> > function. However, when I try to run it, regardless of what fit I
> > provide for the argument "x" or function I provide for the argument
> > "FUN" (including running the examples), I get the error:
> > Error in envRefInferField(x, what, getClass(class(x)), selfEnv) :
> >   "resp" is not a valid field or method name for reference class ?lmerResp?
> > I presume that this is why the bootMer documentation example section
> > says "## Not run: %%--- fails for now --- FIXME"? I just thought I'd
> > double-check.
>   More recently (version 12) this should work ...
> > Also, I thought I'd make sure the devs know that the latest svn
> > version doesn't build on mac; when I try to do so, I get the error:
> > glmFamily.cpp: In member function ?virtual const Eigen::ArrayXd
> > glm::negativeBinomialDist::variance(const Eigen::ArrayXd&) const?:
> > glmFamily.cpp:228: error: ?Rcout? is not a member of ?Rcpp?
>  Thanks for the heads-up.  I will check into it and try to see about
> getting new binary versions of RcppEigen and lme4Eigen up on the
> repository -- although possibly not before Monday.
>   cheers
>     Ben

I was able to get lme4Eigen_0.9996875-13  to compile this (Monday)
morning on my Mac from source after first compiling version 0.2.0
of RcppEigen, which is available on CRAN but I don't see it on Rforge.
(R version 2.14.2 Patched (2012-02-29 r58552)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
Lion 10.7.3).

On an issue from a while back (and going off subject), 
I'm pleased to say that the links from
the psyphy package that allow non-zero lower asymptotes for binomial
families seem to  work with lme4Eigen, at least for binomial aggregated
data.  So far, I get errors for binary responses.  For example to use the
mafc.probit link for a 4-alternative forced-choice experiment, where
one might want to limit the lower asymptote of the link function to 0.25,
I first do the following:

Bi4 <- glmFamily$new(family = binomial(mafc.probit( 4 )))

and then use the argument 

family = Bi4$family

in the arguments to glmer.

It seems to produce promising results in simulated data when I aggregate the
binary responses but when I try it with a binary response variable, I get:

Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite

I would be happy to share the simulation script, if anyone is interested.

Thanks.

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From Bryan.Danson at MyFWC.com  Mon Mar 12 16:42:06 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Mon, 12 Mar 2012 11:42:06 -0400
Subject: [R-sig-ME] glmm with continuous data
Message-ID: <62C3C5515A02CB438EE737153DEF27D209A6808342@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120312/e3aca691/attachment-0001.pl>

From dmcastil at umail.iu.edu  Mon Mar 12 17:04:53 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Mon, 12 Mar 2012 12:04:53 -0400
Subject: [R-sig-ME] glmADMB mcmc output
Message-ID: <CAMmHrnxjvxx8CDN6FPAwXdNW5tcsG4=mnnYD_PVRUvoxg2bpvQ@mail.gmail.com>

Dear list members,

I have run the ML and mcmc for my model. I am wondering if there is a
simple transformation between the the ML coefficients and mcmc
coefficients. Or in general how do I interpret the mcmc coefficients
(I know how to interpret the ml coefficients). For example e^4.03 is
not in the range of the HPD for beta1 of the mcmc

nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
family="nbinom1")
> summary(nb1)

Call:
glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
  (1 | Pop), data = data, family = "nbinom1")


Coefficients:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)          4.03120    0.26620   15.14  < 2e-16 ***
D2_female            0.05115    0.00532    9.62  < 2e-16 ***
BacteriaE            0.13913    0.25159    0.55     0.58
EnviroEC             1.06900    0.22090    4.84  1.3e-06 ***
D2_female:BacteriaE  0.02622    0.00578    4.54  5.7e-06 ***
D2_female:EnviroEC  -0.03357    0.00471   -7.13  9.7e-13 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=95, Pop=16
Random effect variance(s):
Group=Pop
          Variance StdDev
(Intercept)  0.04716 0.2172
Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)

Log-likelihood: -572.814

>nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data, family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
> m<-as.mcmc(nb_mcmc$mcmc)
> head(HPDinterval(m))
          lower     upper
beta.1 50.4190302 55.231164
beta.2  6.3920598  9.033473
beta.3  0.5165269  4.145737
beta.4  1.7327276  5.167999
beta.5  1.6289002  3.791544
beta.6 -3.9886068 -2.057463

Thanks

Dean



From bates at stat.wisc.edu  Mon Mar 12 17:13:20 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 Mar 2012 11:13:20 -0500
Subject: [R-sig-ME] Fwd: Re: Question on the glmer function of the lme4
	R package
In-Reply-To: <4F5DC1FC.8040506@univ-nantes.fr>
References: <4F5DC1FC.8040506@univ-nantes.fr>
Message-ID: <CAO7JsnSMRKMTaT33A43hGNowGnLoPEt-CX9prBB_MHsrJK3nPA@mail.gmail.com>

Have you considered using the BradleyTerry2 package from CRAN?



From dmcastil at umail.iu.edu  Sun Mar 11 20:12:28 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Sun, 11 Mar 2012 15:12:28 -0400
Subject: [R-sig-ME] glmmADMB mcmc output
Message-ID: <CAMmHrnwetCuqwTxGtt8y3fCsUYEHFLT8djADCMqFBrw_GutYpQ@mail.gmail.com>

Dear list members,

I have run the ML and mcmc for my model. I am wondering if there is a
simple transformation between the the ML coefficients and mcmc
coefficients. Or in general how do I interpret the mcmc coefficients
(I know how to interpret the ml coefficients). For example e^4.03 is
not in the range of the HPD for beta1 of the mcmc

nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
family="nbinom1")
> summary(nb1)

Call:
glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
  (1 | Pop), data = data, family = "nbinom1")


Coefficients:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)          4.03120    0.26620   15.14  < 2e-16 ***
D2_female            0.05115    0.00532    9.62  < 2e-16 ***
BacteriaE            0.13913    0.25159    0.55     0.58
EnviroEC             1.06900    0.22090    4.84  1.3e-06 ***
D2_female:BacteriaE  0.02622    0.00578    4.54  5.7e-06 ***
D2_female:EnviroEC  -0.03357    0.00471   -7.13  9.7e-13 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=95, Pop=16
Random effect variance(s):
Group=Pop
          Variance StdDev
(Intercept)  0.04716 0.2172
Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)

Log-likelihood: -572.814

>nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data, family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
> m<-as.mcmc(nb_mcmc$mcmc)
> head(HPDinterval(m))
          lower     upper
beta.1 50.4190302 55.231164
beta.2  6.3920598  9.033473
beta.3  0.5165269  4.145737
beta.4  1.7327276  5.167999
beta.5  1.6289002  3.791544
beta.6 -3.9886068 -2.057463

Thanks



From bates at stat.wisc.edu  Tue Mar 13 17:12:04 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 Mar 2012 11:12:04 -0500
Subject: [R-sig-ME] (no subject)
In-Reply-To: <SNT106-W16E243E83122F2D35DE2EEE580@phx.gbl>
References: <SNT106-W16E243E83122F2D35DE2EEE580@phx.gbl>
Message-ID: <CAO7JsnRfmgUNj+UzJ17WCamMUbiQNExhVQAHPWT27YjognxSDg@mail.gmail.com>

I have switched Brian Edward's status so that every posting must be
approved by the moderator as it looks as though his email account has
been hacked.

On Tue, Mar 13, 2012 at 8:34 AM, Brian Edward <b.edward at live.com> wrote:
> Your own internet money making machines
> http://dezinecube.com/opqk12/httrhttpjobs-ab.php?oloCIDID=867
>
>
>
>
> __________________
> "His investigation should take in every part of themechanism; he should understand about the planesurface, what the stresses are upon its surface,what is the duty of each strut, or brace or wireand be able to make the proper repairs." (c) jahvaughan visszaadta
> Tue, 13 Mar 2012 14:34:34
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From cmgast at gmail.com  Tue Mar 13 18:44:57 2012
From: cmgast at gmail.com (Chris Gast)
Date: Tue, 13 Mar 2012 10:44:57 -0700
Subject: [R-sig-ME] Incorrect reporting of variance component from weighted
	LMM with lme4?
Message-ID: <CAPedOKg4Gp=gshX59RLk9yDM01b7NB5QkhSFKGNZKqsn_ihQWw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120313/23eda5cb/attachment-0001.pl>

From bbolker at gmail.com  Tue Mar 13 18:55:36 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 17:55:36 +0000 (UTC)
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
References: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>
	<loom.20120309T234321-724@post.gmane.org>
	<loom.20120312T142327-813@post.gmane.org>
Message-ID: <loom.20120313T185315-959@post.gmane.org>

Ken knoblauch <ken.knoblauch at ...> writes:

> 
> Ben Bolker <bbolker at ...> writes:
> > Mike Lawrence <Mike.Lawrence at ...> writes:

  [snip]
> > > Also, I thought I'd make sure the devs know that the latest svn
> > > version doesn't build on mac; 

  [snip] 

> >  Thanks for the heads-up.  I will check into it and try to see about
> > getting new binary versions of RcppEigen and lme4Eigen up on the
> > repository -- although possibly not before Monday.
> 
> I was able to get lme4Eigen_0.9996875-13  to compile this (Monday)
> morning on my Mac from source after first compiling version 0.2.0
> of RcppEigen, which is available on CRAN but I don't see it on Rforge.
> (R version 2.14.2 Patched (2012-02-29 r58552)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> Lion 10.7.3).
> 
 
 [snip]

  For what it's worth, binaries of lme4Eigen...13  and Rcpp 0.2.0 should
be available now from http://lme4.r-forge.r-project.org/repos ...

  Ben



From juliet.hannah at gmail.com  Tue Mar 13 19:34:48 2012
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Tue, 13 Mar 2012 14:34:48 -0400
Subject: [R-sig-ME] observation level random effects/kinship model
Message-ID: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>

All,

I was reading the following post:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005184.html

which discusses why an observation-level random effect does not make
sense in the linear mixed model
case.

Does anyone know of any references that discuss this?

And for the genetics folks out there, isn't this what the kinship
model is: an observation-level random effect
that is correlated by degree of relatedness?

Thanks,

Juliet Hannah



From bbolker at gmail.com  Tue Mar 13 21:02:14 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 20:02:14 +0000 (UTC)
Subject: [R-sig-ME] glmADMB mcmc output
References: <CAMmHrnxjvxx8CDN6FPAwXdNW5tcsG4=mnnYD_PVRUvoxg2bpvQ@mail.gmail.com>
Message-ID: <loom.20120313T185551-892@post.gmane.org>

Dean Castillo <dmcastil at ...> writes:

> I have run the ML and mcmc for my model. I am wondering if there is a
> simple transformation between the the ML coefficients and mcmc
> coefficients. Or in general how do I interpret the mcmc coefficients
> (I know how to interpret the ml coefficients). For example e^4.03 is
> not in the range of the HPD for beta1 of the mcmc
> 
> nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
> family="nbinom1")
> > summary(nb1)
> 
> Call:
> glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
>   (1 | Pop), data = data, family = "nbinom1")
> 

  [snip]

> Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)

  (This very large NB dispersion parameter is a little bit worrying.
Have you examined your data for weirdness/zero-inflation etc.?  Do
you results look reasonable?)


> >nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
> family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
> > m<-as.mcmc(nb_mcmc$mcmc)
> > head(HPDinterval(m))
>           lower     upper
> beta.1 50.4190302 55.231164
> beta.2  6.3920598  9.033473
> beta.3  0.5165269  4.145737
> beta.4  1.7327276  5.167999
> beta.5  1.6289002  3.791544
> beta.6 -3.9886068 -2.057463

  I haven't fully implemented this yet, but here is an embryonic
function for transforming an mcmc object (m) based on a glmmADMB fit
(fit).  At the moment it only does some of the easy stuff
(transforming fixed-effect parameters to their original scale, and
variance parameters to the standard deviation scale)

  There will be a bit more detail about this in the vignette in
the next release.

mcmc_transform <- function(m,fit) {
  if (missing(fit)) {
    fit0 <- fit
    m <- fit$mcmc
    fit <- fit0
  }
  if (!is(m,"mcmc")) stop("m must be an 'mcmc' object")
  if (!is(fit,"glmmadmb")) stop("fit must a 'glmmadmb' object")
  ## zero-inflation
  pz <- m[,"pz",drop=FALSE]
  t_pz <- pz  ## (not transformed)
  ## fixed effects
  fixed <- m[,grep("^beta",colnames(m)),drop=FALSE]
  t_fixed <- as.mcmc(fixed %*% fit$phi)
  colnames(t_fixed) <- names(fixef(fit))
  ## variance parameters: log std dev
  theta <- m[,grep("^tmpL",colnames(m)),drop=FALSE]
  t_theta <- exp(theta)
  ## corr parameters ("offdiagonal elements of cholesky-factor of correlation
matrix")
  corr <- m[,grep("^tmpL1",colnames(m)),drop=FALSE]
  t_corr <- corr
  ## scale/overdispersion parameter
  logalpha <- m[,grep("^log_alpha",colnames(m)),drop=FALSE]
  t_alpha <- matrix(exp(logalpha),dimnames=list(NULL,"alpha"))
  ## random effects
  re <- m[,grep("^u\\.[0-9]+",colnames(m)),drop=FALSE]
  t_re <- re
  mcmc(cbind(t_pz,t_fixed,t_theta,t_corr,t_alpha,t_re),
       start=start(m),end=end(m),thin=frequency(m))
}



From bbolker at gmail.com  Tue Mar 13 21:39:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 20:39:10 +0000 (UTC)
Subject: [R-sig-ME] observation level random effects/kinship model
References: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>
Message-ID: <loom.20120313T212846-759@post.gmane.org>

Juliet Hannah <juliet.hannah at ...> writes:

> 
> All,
> 
> I was reading the following post:
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005184.html
> 
> which discusses why an observation-level random effect does not make
> sense in the linear mixed model
> case.
> 
> Does anyone know of any references that discuss this?
> 
> And for the genetics folks out there, isn't this what the kinship
> model is: an observation-level random effect
> that is correlated by degree of relatedness?

  I don't know of an immediately useful reference (other than, say,
the theory sections of Pinheiro and Bates 2000 or Littell et al or
some other mixed-model book -- and these wouldn't specifically answer
your question, they would just answer it implicitly).  But I would
be happy to hear about one.

  The issue is that in the standard definition of the mixed model
there are random effects (sometimes called "G-side" effects, for
grouping terms) and there is *also always* assumed to be a residual error
term, which is normally distributed independently among
observations in typical cases but can be multivariate normally
distributed (so-called "R-side" effects, "R" for residuals)
in some examples.
   Because mixed models always include a residual term by
convention, including an observation-level random effect would
just amount to partitioning the residual variance into two (unidentifiable)
terms, one corresponding to the residual (R) term and the other
corresponding to the grouping term.
  I'm not a geneticist, but I believe that the kinship model
is inducing a correlation on the *residuals* (an R-side effect)
rather than on a variance associated with a grouping factor.
If you could eliminate the residual error term or equivalently
fix its variance to zero (or very small), you could add a correlated
random effect as a G-side effect (although I think you would have
a hard time finding a mixed model package that allows for correlation
among G-side effects -- you'd probably have to code your own model
via ADMB or WinBUGS ...) -- but at least the standard R packages
(nlme, lme4, glmmADMB) don't let you do that.

  In GLMMs for families that do *not* have an adjustable scale parameter
(e.g. the most typical examples -- Poisson, binomial), there is
no normal residual error term included in the model, so it's OK to 
include an observation-level random effect.



From dmcastil at umail.iu.edu  Tue Mar 13 22:42:13 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Tue, 13 Mar 2012 17:42:13 -0400
Subject: [R-sig-ME] glmADMB mcmc output
In-Reply-To: <loom.20120313T185551-892@post.gmane.org>
References: <CAMmHrnxjvxx8CDN6FPAwXdNW5tcsG4=mnnYD_PVRUvoxg2bpvQ@mail.gmail.com>
	<loom.20120313T185551-892@post.gmane.org>
Message-ID: <CAMmHrnxdB0KRiMsa-MMia-XnODRf7SwgajDcoV8tmUjhA9TxPQ@mail.gmail.com>

Ben, Thank you for your response and the code you included. I think
this is what I was looking for.

I have tried the zero-inflated model in another package and the fit
for the zeroinflated negative binomial is better than negative
binomial alone.
I am having trouble fitting the zeroinflated model in the glmmADMB
package and I am getting an error I have seen come up in the list
archives. I have not had time to trouble shoot this just yet.

Dean

On Tue, Mar 13, 2012 at 4:02 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Dean Castillo <dmcastil at ...> writes:
>
>> I have run the ML and mcmc for my model. I am wondering if there is a
>> simple transformation between the the ML coefficients and mcmc
>> coefficients. Or in general how do I interpret the mcmc coefficients
>> (I know how to interpret the ml coefficients). For example e^4.03 is
>> not in the range of the HPD for beta1 of the mcmc
>>
>> nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
>> family="nbinom1")
>> > summary(nb1)
>>
>> Call:
>> glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
>> ? (1 | Pop), data = data, family = "nbinom1")
>>
>
> ?[snip]
>
>> Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)
>
> ?(This very large NB dispersion parameter is a little bit worrying.
> Have you examined your data for weirdness/zero-inflation etc.? ?Do
> you results look reasonable?)
>
>
>> >nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
>> family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
>> > m<-as.mcmc(nb_mcmc$mcmc)
>> > head(HPDinterval(m))
>> ? ? ? ? ? lower ? ? upper
>> beta.1 50.4190302 55.231164
>> beta.2 ?6.3920598 ?9.033473
>> beta.3 ?0.5165269 ?4.145737
>> beta.4 ?1.7327276 ?5.167999
>> beta.5 ?1.6289002 ?3.791544
>> beta.6 -3.9886068 -2.057463
>
> ?I haven't fully implemented this yet, but here is an embryonic
> function for transforming an mcmc object (m) based on a glmmADMB fit
> (fit). ?At the moment it only does some of the easy stuff
> (transforming fixed-effect parameters to their original scale, and
> variance parameters to the standard deviation scale)
>
> ?There will be a bit more detail about this in the vignette in
> the next release.
>
> mcmc_transform <- function(m,fit) {
> ?if (missing(fit)) {
> ? ?fit0 <- fit
> ? ?m <- fit$mcmc
> ? ?fit <- fit0
> ?}
> ?if (!is(m,"mcmc")) stop("m must be an 'mcmc' object")
> ?if (!is(fit,"glmmadmb")) stop("fit must a 'glmmadmb' object")
> ?## zero-inflation
> ?pz <- m[,"pz",drop=FALSE]
> ?t_pz <- pz ?## (not transformed)
> ?## fixed effects
> ?fixed <- m[,grep("^beta",colnames(m)),drop=FALSE]
> ?t_fixed <- as.mcmc(fixed %*% fit$phi)
> ?colnames(t_fixed) <- names(fixef(fit))
> ?## variance parameters: log std dev
> ?theta <- m[,grep("^tmpL",colnames(m)),drop=FALSE]
> ?t_theta <- exp(theta)
> ?## corr parameters ("offdiagonal elements of cholesky-factor of correlation
> matrix")
> ?corr <- m[,grep("^tmpL1",colnames(m)),drop=FALSE]
> ?t_corr <- corr
> ?## scale/overdispersion parameter
> ?logalpha <- m[,grep("^log_alpha",colnames(m)),drop=FALSE]
> ?t_alpha <- matrix(exp(logalpha),dimnames=list(NULL,"alpha"))
> ?## random effects
> ?re <- m[,grep("^u\\.[0-9]+",colnames(m)),drop=FALSE]
> ?t_re <- re
> ?mcmc(cbind(t_pz,t_fixed,t_theta,t_corr,t_alpha,t_re),
> ? ? ? start=start(m),end=end(m),thin=frequency(m))
> }
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From klasen at mpipz.mpg.de  Tue Mar 13 22:55:43 2012
From: klasen at mpipz.mpg.de (Jonas Klasen)
Date: Tue, 13 Mar 2012 22:55:43 +0100
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>
References: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>
Message-ID: <fbfed66376d0.4f5fd06f@mpiz-koeln.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120313/386dd3de/attachment-0001.pl>

From jzl106 at gmail.com  Wed Mar 14 00:33:07 2012
From: jzl106 at gmail.com (Junyan Luo)
Date: Tue, 13 Mar 2012 19:33:07 -0400
Subject: [R-sig-ME] No need to handle between-group correlation structure in
	glmm in general?
Message-ID: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>

Hi,
Recently I have been working with a data set that contains individual
samples from a set of connected geographical areal units. While I plan
to use glmm to model the data with individuals as the 1st level units
and the areal units as the 2nd level units, I am concerned with the
potential spatial autocorrelation among the geographical areal units
(i.e., at the second level). It is reasonable to think that the random
effects at the second level will be spatial autocorrelated. I know
nlme has the option to specify "within-group" correlation structure,
but I couldn't figure out a way to specify "between-group"
correlations structure for the geographical areal units.

However, one of my colleagues told me it was totally unnecessary to
specify a correlation structure at the second level. This is because
the two assumptions of multi-level models are (1) the individual error
term is independent; (2) the individual error term is uncorrelated
with the random effects. It does NOT assume that the random effects
should be independent. So unless (2) is violated, generally we don't
need to worry about autocorrelation in the random effects. That's
probably why nlme only has the option for specifying "within-group"
correlation structure. I feel the assessment is reasonable, but I am
unsure if that is correct. Can anybody help me clarify this? Thanks!



From bbolker at gmail.com  Wed Mar 14 01:30:43 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 20:30:43 -0400
Subject: [R-sig-ME] Fwd: Re: [R] how to write crossed and nested random
 effects in a model
In-Reply-To: <1331684739.94898.YahooMailNeo@web36604.mail.mud.yahoo.com>
References: <1331684739.94898.YahooMailNeo@web36604.mail.mud.yahoo.com>
Message-ID: <4F5FE6B3.9050102@gmail.com>


 [forwarded to r-sig-mixed-models at r-project.org: it is much better to
keep these discussions on a public, archived list]

-------- Original Message --------
Subject: 	Re: [R] how to write crossed and nested random effects in a model
Date: 	Tue, 13 Mar 2012 17:25:39 -0700 (PDT)
From: 	withanage Niroshan perera <wnnkp at yahoo.com>
Reply-To: 	withanage Niroshan perera <wnnkp at yahoo.com>
To: 	Ben Bolker <bbolker at gmail.com>



Dear Professor,

Thanks lot for your valuable idea, Could you please let me know the your
explanation in a model. I guess that would be much more informative for
me to get it understood.

  [snip]

BMB>  Well, if you're a PhD student in mathematics & statistics you
BMB> be able to do some of this yourself -- there must be some expertise
BMB> in mixed models (although possibly not in mixed models in R)
BMB> at your institution in order for you to be working in this line
BMB> of research ...

BMB> I did, more or less, give you the model formula below.

Something like:
glmer (resp ~ pathology + (pathology|reader)+(pathology|patient/eye),
   family=binomial(link="probit"),data=mydata)

  I would *strongly* recommend that you work out how to simulate some
data with known variance components so that you can see whether you
are getting the right sorts of answers ...

Niroshan <wnnperer <at> ucalgary.ca> writes:

> I have a question based on my research. I am analyzing reader-based 
> diagnostic data set.  My study involves diabetic patients who were 
> evaluated for treatable diabetic retinopathy based on the presence
> or absence of two pathologies in their eyes.  Pathologies were 
> identified using the clinical examination (Gold standard method). In 
> addition it can be identified by taking digital images of patients? 
> eyes and this method is cost effective. Finally two readers go over 
> the images independently and patients are diagnosed as either 
> positive or negative for the pathologies. My objective is,
> estimation the sensitivity and specificity of reader-based diagnostic
> method.

> I am going to fit multivariate probit model. But the problem has 
> complex correlation structure. We have three different correlation: 
> readers results  are correlated, patients left and right eyes are 
> correlated and pathologies are correlated since all based on the 
> retina in the eye.

 [snip]

> Also I think patients and readers are crossed each other since each 
> reader go over each patients? images. And [snip] eyes are nested with
> patients and pathologies are nested with in the eye.  Is this crossed
> and nested interpretation true?  If then how can I include these
> effects as random terms to the model?
> 
> My response is readers ? diagnosed values. Per patient I have 8 
> values (2 pathologies, left and right eye and 2 readers) Explanatory
>  variables are actual disease status of each pathology for left and 
> right eyes.
> 


  I think that *in principle* (if you are using lme4, which is
probably the most convenient option for dealing with crossed REs) you
probably want

~ pathology + (pathology|reader)+(pathology|patient/eye)

  The fixed effect term says that pathologies may vary in their
overall frequency.  The first RE term says that different readers can
vary, in a pathology-specific way (if they just differed overall in
their sensitivity you would want (1|reader) instead); the second says
that there is variance among eyes (within patients) in all pathologies
(and that they may be correlated).

  A few cautions about this:

* I'm not sure I got it right

* You might want to forward this (along with my answer, so we're not
starting from scratch) to r-sig-mixed-models at r-project.org
<mailto:r-sig-mixed-models at r-project.org> , where
there is more expertise in mixed models.

* if you have the _same_ two readers for all of your patients (as
opposed to two different readers chosen at random out of a large,
possibly overlapping pool), then it isn't be practical to treat them
as a random effect, no matter how much sense it makes philosophically
-- use pathology*reader instead.

* You may need a moderately large amount of data to fit this model ...



From nprause at mrn.org  Wed Mar 14 02:52:13 2012
From: nprause at mrn.org (Nicole Prause)
Date: Tue, 13 Mar 2012 19:52:13 -0600
Subject: [R-sig-ME] Specifying continuous covariates and predictors in lmer
Message-ID: <CANPy+hfWd4ou+r-aeA2MupG_Qk2tBzxsuYG8icd=7gVXb+t53w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120313/1d25e904/attachment-0001.pl>

From rudolf.rohr at ebd.csic.es  Wed Mar 14 09:27:00 2012
From: rudolf.rohr at ebd.csic.es (Rudolf Philippe Rohr)
Date: Wed, 14 Mar 2012 09:27:00 +0100
Subject: [R-sig-ME] issue when incorporating a phylogenetic correlation
 structure (corPagel) in a linear mixed effect model (lme)
Message-ID: <4F605654.7070808@ebd.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/f0e19aaa/attachment-0001.pl>

From yvesrousselle at gmail.com  Wed Mar 14 11:05:14 2012
From: yvesrousselle at gmail.com (Yves Rousselle)
Date: Wed, 14 Mar 2012 14:05:14 +0400
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <fbfed66376d0.4f5fd06f@mpiz-koeln.mpg.de>
References: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>
	<fbfed66376d0.4f5fd06f@mpiz-koeln.mpg.de>
Message-ID: <CAA8=r0DAnaByMy23C8tPuZn4W-PeccjTHviG7UtOwT8k40MoXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/b871c3d4/attachment-0001.pl>

From par.ingvarsson at emg.umu.se  Wed Mar 14 11:24:24 2012
From: par.ingvarsson at emg.umu.se (=?iso-8859-1?Q?=22P=E4r_K=2E_Ingvarsson=22?=)
Date: Wed, 14 Mar 2012 11:24:24 +0100
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <mailman.3008.1331719534.4502.r-sig-mixed-models@r-project.org>
References: <mailman.3008.1331719534.4502.r-sig-mixed-models@r-project.org>
Message-ID: <3FDE1CA9-E720-44AE-BB45-09DB199BFCBE@emg.umu.se>


> Date: Wed, 14 Mar 2012 14:05:14 +0400
> From: Yves Rousselle <yvesrousselle at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] observation level random effects/kinship model
> Message-ID:
>        <CAA8=r0DAnaByMy23C8tPuZn4W-PeccjTHviG7UtOwT8k40MoXw at mail.gmail.com>
> Content-Type: text/plain
> 
> Hi,
> 
> If I understand well, if you want to take into account the kinship between
> individuals in genetics models, you have to specify a random effect that is
> the individuals levels and specify that this effect follows a distribution
> with a variance/covariance matrix equal to 2*K*Vg (basically). 2*Vg is just
> a number and K is the kinship matrix.
> I am currently using R to do such genetics models to do association
> mapping. I ask to other people that have done that before me and if I
> understand well, no packages allows to specify such a variance/covariance
> matrix for a random effect except ASREML. But you have to pay a license to
> use it. I am using this package for my study.

There are several packages that can handle kinship matrices for doing association studies in R. Of the top of my head I can come up with:

kinship (http://cran.r-project.org/web/packages/kinship/index.html)
EMMA (http://mouse.cs.ucla.edu/emma/news.html)
GenABEL (http://www.genabel.org/)


> 
> Concerning the question of putting an observation-level effect, I begin to
> understand it but you have to check with others perhaps. I will take the
> association mapping case as an example (I hope you know it a bit). You have
> a sample of individuals that are evaluated within a repeated block design
> for example. So each individuals is repeated end therefore, the
> observations level is not **yet** the individual level. The classical first
> step is to estimate (predict is the good word I guess) BLUP for the
> individual level with a model that takes into account the experimental
> design parameters. After this step, you obtain a dataset in which the
> observation level is the individual level. The second step consists in
> testing the association between the BLUP and some markers. In this model,
> you specify a random effect which is the individual level for with you
> specify the variance/covariance matrix 2KVg. So, at this step, you use a
> random effect at the observation level. I talked about that with
> biostatiticians (I hope this traduction is good) because I was surprised
> that an effect could be at the same level as the observations level because
> there won't be enough degree of freedom in the model. They explained me
> that, the correlation between individuals, specified in the kinship matrix,
> acts like repeating each individuals in their common part in other
> individuals. Well, I am sorry that I'm not able to put this idea in words
> in a better way, I hope it will help.

You can do the analyses directly without going through the BLUPs estimation step, but that generally leads to similar results as with the two-step method. See for instance http://www.genetics.org/content/178/3/1745.abstract for more details


-Pelle

--
P?r K. Ingvarsson
Professor, Evolutionary Genetics
Ume? Plant Science Centre
Department of Ecology and Environmental Science
Linneaus v?g 6
Ume? University, SE-901 87 Ume?, Sweden
tel. +46-(0)90-786-7414, fax. +46-(0)90-786-6705



From c.ryan.king at gmail.com  Wed Mar 14 13:28:00 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Wed, 14 Mar 2012 07:28:00 -0500
Subject: [R-sig-ME] observation level random effects/kinship model
Message-ID: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com>

When the observation-level random effects are independent then they
are the same as the noise. i.e.
y = xb + u +e can just be rewritten y= xb + e', with e' = u+e. Since
the sum of two normals is normal, the model is unchanged from usual
OLS.

With kinship that symmetry breaks, and observation-level random
effects are identifiable.

.I am currently using R to do such genetics models to do association
.mapping. I ask to other people that have done that before me and if I
.understand well, no packages allows to specify such a variance/covariance
.matrix for a random effect except ASREML.

You can also use MCMCglmm and R-INLA.

Ryan King



From pierces1 at msu.edu  Wed Mar 14 13:37:03 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 14 Mar 2012 08:37:03 -0400
Subject: [R-sig-ME] No need to handle between-group correlation
	structure in	glmm in general?
In-Reply-To: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>
References: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>
Message-ID: <003001cd01df$290c7730$7b256590$@msu.edu>

The best thing to do would be to empirically test whether modeling the
spatial autocorrelation in the level 2 random effects improves model fit
compared with a simpler model that assumes independence of those random
effects. In my dissertation work, adding spatial autocorrelation at level 2
improved a model (but not dramatically). 

Check out the following resources:

Beard, J. R. (2008). New approaches to multilevel analysis. Journal of Urban
Health, 85(6), 805-806. doi: 10.1007/s11524-008-9314-7

Browne, W., & Goldstein, H. (2010). MCMC sampling for a multilevel model
with non-independent residuals within and between cluster units. Journal of
Educational and Behavioral Statistics, 35(4), 453-473. doi:
10.3102/1076998609359788

Chaix, B., Leyland, A. H., Sabel, C. E., Chauvin, P., R?stam, L.,
Kristersson, H., & Merlo, J. (2006). Spatial clustering of mental disorders
and associated characteristics of the neighbourhood context in Malm?,
Sweden, in 2001. Journal of Epidemiology and Community Health, 60(5),
427-435. doi: 10.1136/jech.2005.040360

Chaix, B., Merlo, J., & Chauvin, P. (2005). Comparison of a spatial approach
with the multilevel approach for investigating place effects on health: The
example of healthcare utilisation in France. Journal of Epidemiology and
Community Health, 59(6), 517-526. doi: 10.1136/jech.2004.025478

Chaix, B., Merlo, J., Evans, D., Leal, C., & Havard, S. (2009).
Neighborhoods in eco-epidemiologic research: Delimiting personal exposure
areas. A response to Riva, Gauvin, Apparicio and Brodeur. Social Science &
Medicine, 69(9), 1306-1310. doi: 10.1016/j.socscimed.2009.07.018

Chaix, B., Merlo, J., Subramanian, S. V., Lynch, J., & Chauvin, P. (2005).
Comparison of a spatial perspective with the multilevel analytical approach
in neighborhood studies: The case of mental and behavioral disorders due to
psychoactive substance use in Malm?, Sweden, 2001. American Journal of
Epidemiology, 162(2), 171-182. doi: 10.1093/aje/kwi175

Fagg, J., Curtis, S., Clark, C., Congdon, P., & Stansfeld, S. A. (2008).
Neighbourhood perceptions among inner-city adolescents: Relationships with
their individual characteristics and with independently assessed
neighbourhood conditions. Journal of Environmental Psychology, 28(2),
128-142. doi: 10.1016/j.jenvp.2007.10.004



Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Junyan Luo [mailto:jzl106 at gmail.com] 
Sent: Tuesday, March 13, 2012 7:33 PM
To: R-sig-mixed-models at r-project.org
Subject: [R-sig-ME] No need to handle between-group correlation structure in
glmm in general?

Hi,
Recently I have been working with a data set that contains individual
samples from a set of connected geographical areal units. While I plan
to use glmm to model the data with individuals as the 1st level units
and the areal units as the 2nd level units, I am concerned with the
potential spatial autocorrelation among the geographical areal units
(i.e., at the second level). It is reasonable to think that the random
effects at the second level will be spatial autocorrelated. I know
nlme has the option to specify "within-group" correlation structure,
but I couldn't figure out a way to specify "between-group"
correlations structure for the geographical areal units.

However, one of my colleagues told me it was totally unnecessary to
specify a correlation structure at the second level. This is because
the two assumptions of multi-level models are (1) the individual error
term is independent; (2) the individual error term is uncorrelated
with the random effects. It does NOT assume that the random effects
should be independent. So unless (2) is violated, generally we don't
need to worry about autocorrelation in the random effects. That's
probably why nlme only has the option for specifying "within-group"
correlation structure. I feel the assessment is reasonable, but I am
unsure if that is correct. Can anybody help me clarify this? Thanks!



From jzl106 at gmail.com  Wed Mar 14 14:15:36 2012
From: jzl106 at gmail.com (Junyan Luo)
Date: Wed, 14 Mar 2012 09:15:36 -0400
Subject: [R-sig-ME] No need to handle between-group correlation
 structure in glmm in general?
In-Reply-To: <003001cd01df$290c7730$7b256590$@msu.edu>
References: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>
	<003001cd01df$290c7730$7b256590$@msu.edu>
Message-ID: <CAFT_Lc26NK26j4hDL42JbLAeZDVp-ntf1LJer=O1vFyW9MLFOw@mail.gmail.com>

Hi Dr. Pierce,

Thanks for the reply! And the information you provided is very useful!
Do you know if any existing R tools can handle this type of analysis?

The suggestion of comparing model fit is a good idea, but probably a
more important issue is whether the presence of correlated random
effects biases the parameter estimation. I am aware of a few test
techniques related to this, but totally unsure about their
implications. For example, is it a good idea to perform Moran's I test
on the second level residuals? (Or random effects directly?) A more
important question is, if Moran's I suggests autocorrelation in second
level residuals, would it be corrected by incorporating an correlation
structure for random effects?

REGARDS,
Junyan

On Wed, Mar 14, 2012 at 8:37 AM, Steven J. Pierce <pierces1 at msu.edu> wrote:
> The best thing to do would be to empirically test whether modeling the
> spatial autocorrelation in the level 2 random effects improves model fit
> compared with a simpler model that assumes independence of those random
> effects. In my dissertation work, adding spatial autocorrelation at level 2
> improved a model (but not dramatically).
>
> Check out the following resources:
>
> Beard, J. R. (2008). New approaches to multilevel analysis. Journal of Urban
> Health, 85(6), 805-806. doi: 10.1007/s11524-008-9314-7
>
> Browne, W., & Goldstein, H. (2010). MCMC sampling for a multilevel model
> with non-independent residuals within and between cluster units. Journal of
> Educational and Behavioral Statistics, 35(4), 453-473. doi:
> 10.3102/1076998609359788
>
> Chaix, B., Leyland, A. H., Sabel, C. E., Chauvin, P., R?stam, L.,
> Kristersson, H., & Merlo, J. (2006). Spatial clustering of mental disorders
> and associated characteristics of the neighbourhood context in Malm?,
> Sweden, in 2001. Journal of Epidemiology and Community Health, 60(5),
> 427-435. doi: 10.1136/jech.2005.040360
>
> Chaix, B., Merlo, J., & Chauvin, P. (2005). Comparison of a spatial approach
> with the multilevel approach for investigating place effects on health: The
> example of healthcare utilisation in France. Journal of Epidemiology and
> Community Health, 59(6), 517-526. doi: 10.1136/jech.2004.025478
>
> Chaix, B., Merlo, J., Evans, D., Leal, C., & Havard, S. (2009).
> Neighborhoods in eco-epidemiologic research: Delimiting personal exposure
> areas. A response to Riva, Gauvin, Apparicio and Brodeur. Social Science &
> Medicine, 69(9), 1306-1310. doi: 10.1016/j.socscimed.2009.07.018
>
> Chaix, B., Merlo, J., Subramanian, S. V., Lynch, J., & Chauvin, P. (2005).
> Comparison of a spatial perspective with the multilevel analytical approach
> in neighborhood studies: The case of mental and behavioral disorders due to
> psychoactive substance use in Malm?, Sweden, 2001. American Journal of
> Epidemiology, 162(2), 171-182. doi: 10.1093/aje/kwi175
>
> Fagg, J., Curtis, S., Clark, C., Congdon, P., & Stansfeld, S. A. (2008).
> Neighbourhood perceptions among inner-city adolescents: Relationships with
> their individual characteristics and with independently assessed
> neighbourhood conditions. Journal of Environmental Psychology, 28(2),
> 128-142. doi: 10.1016/j.jenvp.2007.10.004
>
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Junyan Luo [mailto:jzl106 at gmail.com]
> Sent: Tuesday, March 13, 2012 7:33 PM
> To: R-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] No need to handle between-group correlation structure in
> glmm in general?
>
> Hi,
> Recently I have been working with a data set that contains individual
> samples from a set of connected geographical areal units. While I plan
> to use glmm to model the data with individuals as the 1st level units
> and the areal units as the 2nd level units, I am concerned with the
> potential spatial autocorrelation among the geographical areal units
> (i.e., at the second level). It is reasonable to think that the random
> effects at the second level will be spatial autocorrelated. I know
> nlme has the option to specify "within-group" correlation structure,
> but I couldn't figure out a way to specify "between-group"
> correlations structure for the geographical areal units.
>
> However, one of my colleagues told me it was totally unnecessary to
> specify a correlation structure at the second level. This is because
> the two assumptions of multi-level models are (1) the individual error
> term is independent; (2) the individual error term is uncorrelated
> with the random effects. It does NOT assume that the random effects
> should be independent. So unless (2) is violated, generally we don't
> need to worry about autocorrelation in the random effects. That's
> probably why nlme only has the option for specifying "within-group"
> correlation structure. I feel the assessment is reasonable, but I am
> unsure if that is correct. Can anybody help me clarify this? Thanks!
>
>
>



From wnnkp at yahoo.com  Wed Mar 14 01:03:34 2012
From: wnnkp at yahoo.com (withanage Niroshan perera)
Date: Tue, 13 Mar 2012 17:03:34 -0700 (PDT)
Subject: [R-sig-ME] How to write crossed and nested random effects in a model
Message-ID: <1331683414.39699.YahooMailNeo@web36606.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120313/1bd154b6/attachment-0001.pl>

From harkiran.bhogal07 at imperial.ac.uk  Wed Mar 14 21:41:48 2012
From: harkiran.bhogal07 at imperial.ac.uk (Bhogal, Harkiran)
Date: Wed, 14 Mar 2012 20:41:48 +0000
Subject: [R-sig-ME] lme code
Message-ID: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/79a70aad/attachment-0001.pl>

From f.calboli at imperial.ac.uk  Wed Mar 14 22:04:51 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 14 Mar 2012 21:04:51 +0000
Subject: [R-sig-ME] lme code
In-Reply-To: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>
References: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>
Message-ID: <1B848EC0-AEC4-4F4F-B44F-E59DA8F2C7EF@imperial.ac.uk>

On 14 Mar 2012, at 20:41, Bhogal, Harkiran wrote:

> Please help!
> 
> 
> 
> Got a few days left and I need to model a random effect of species on the body mass (logM) and temperature (K) slopes. This is what i've done so far that works:
>    model1<-lme(logSSP~logM + K,random=~1|species,data=data1)
>    model2<-lme(logSSP~logM + K,random=~K|species,data=data1)
>    model3<-lme(logSSP~logM + K,random=~logM|species,data=data1)
> 
> 
> The one I now want is:
>    model4<-lme(logSSP~logM + K,random=~logM|species,K|species,data=data1)

random ~ logM + species|K/species

????

please explain what you are trying to do in the random part, you code for model 4 does not just not make sense as R code, it just does not make sense period.

F


>    #I need the random effect of spp on both slopes of logM and K, but this code doesn't work so how do i change the code??????
>    :( Any help will be greatly appreciated
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From gangchen at mail.nih.gov  Wed Mar 14 22:08:45 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Wed, 14 Mar 2012 17:08:45 -0400
Subject: [R-sig-ME] lme code
In-Reply-To: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>
References: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>
Message-ID: <CAHmzXO4b2rGe7CsVBGc3VdhYLjY+GOmv9RsAq1iP5HNaHAg=_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/2d8a3a14/attachment-0001.pl>

From shyunuw at gmail.com  Thu Mar 15 02:38:42 2012
From: shyunuw at gmail.com (Saang-Yoon Hyun)
Date: Wed, 14 Mar 2012 21:38:42 -0400
Subject: [R-sig-ME] a good book?
Message-ID: <CAFh292PfF76qch9XyWmLHO0rg9nAJY2bRRv=RrHHTORhqn-peA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/02898cc3/attachment-0001.pl>

From kw.stat at gmail.com  Thu Mar 15 03:37:50 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 14 Mar 2012 21:37:50 -0500
Subject: [R-sig-ME] a good book?
In-Reply-To: <CAFh292PfF76qch9XyWmLHO0rg9nAJY2bRRv=RrHHTORhqn-peA@mail.gmail.com>
References: <CAFh292PfF76qch9XyWmLHO0rg9nAJY2bRRv=RrHHTORhqn-peA@mail.gmail.com>
Message-ID: <CAKFxdiTkEwHYRT+P9WFORdnzZ5A8-GUo6bPksGW8iEh8Rreq1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/496685a1/attachment-0001.pl>

From aghaynes at gmail.com  Thu Mar 15 09:34:26 2012
From: aghaynes at gmail.com (Alan Haynes)
Date: Thu, 15 Mar 2012 09:34:26 +0100
Subject: [R-sig-ME] a good book?
In-Reply-To: <CAKFxdiTkEwHYRT+P9WFORdnzZ5A8-GUo6bPksGW8iEh8Rreq1Q@mail.gmail.com>
References: <CAFh292PfF76qch9XyWmLHO0rg9nAJY2bRRv=RrHHTORhqn-peA@mail.gmail.com>
	<CAKFxdiTkEwHYRT+P9WFORdnzZ5A8-GUo6bPksGW8iEh8Rreq1Q@mail.gmail.com>
Message-ID: <CAPdSD+7ir8W7pvt+qEhBrB5dyYR5MVSmr1g9_q2V=72gcGEm8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120315/fa9bb7c4/attachment-0001.pl>

From pierces1 at msu.edu  Thu Mar 15 14:04:42 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Thu, 15 Mar 2012 09:04:42 -0400
Subject: [R-sig-ME] No need to handle between-group correlation
	structure in glmm in general?
In-Reply-To: <CAFT_Lc26NK26j4hDL42JbLAeZDVp-ntf1LJer=O1vFyW9MLFOw@mail.gmail.com>
References: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>	<003001cd01df$290c7730$7b256590$@msu.edu>
	<CAFT_Lc26NK26j4hDL42JbLAeZDVp-ntf1LJer=O1vFyW9MLFOw@mail.gmail.com>
Message-ID: <002f01cd02ac$300951c0$901bf540$@msu.edu>

Junyan,

Hofmann et al. (2000) and Raudenbush & Bryk (2002) both specifically say
that level 2 residuals are supposed to be independent in a 2-level model.
So, I think it is very important to directly test that assumption and modify
the model to account for autocorrelation if it is present. It may not always
make a huge difference in practice, but I consider that the conceptually
appropriate way to proceed. Ultimately geostatistical models performed
better than adding a conditional autoregressive (CAR) structure to a
traditional multilevel model in my own work. 

My dissertation (Pierce, 2010) was contrasting different ways of modeling
neighborhood effects on residents and lays out an argument for why
geostatistical approaches may be better tools than traditional multilevel
models for answering some kinds of questions. I used an exact Moran's I test
for regression residuals to detect autocorrelation in level 2 residuals in
my own work (see Bivand, Pebesma, & Gomez-Rubio, 2008, pp. 258-264 and the
lm.morantest.exact function from the spdep package in R). In terms of
software, I used a combination of R and WinBUGS to run my multilevel models
because I wanted to use Bayesian methods as similar as possible to the
geostatistical models implemented in the spBayes package. WinBUGS did the
real estimation work, but I used R for data management, calling WinBUGS,
then post-processing the WinBUGS results. 

Bivand, R. S., Pebesma, E. J., & G?mez-Rubio, V. (2008). Applied spatial
data analysis with R. New York, NY: Springer Science+Business Media.

Hofmann, D. A., Griffin, M. A., & Gavin, M. B. (2000). The application of
hierarchical linear modeling to organizational research. In K. J. Klein & S.
W. J. Kozlowski (Eds.), Multilevel theory, research, and methods in
organizations: Foundations, extensions, and new directions (pp. 467-511).
San Francisco, CA: Jossey-Bass.

Pierce, S. J. (2010). Using geostatistical models to study neighborhood
effects: An alternative to hierarchical linear models. (Doctoral
dissertation).  Available from ProQuest Dissertations and Theses database.
(UMI No. 3417821)
https://www.msu.edu/~pierces1/S_Pierce_Final_Dissertation_2010.pdf 

Raudenbush, S. W., & Bryk, A. S. (2002). Hierarchical linear models:
Applications and data analysis methods (2nd ed.). Thousand Oaks, CA: Sage
Publications.

Regards,

Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Junyan Luo [mailto:jzl106 at gmail.com] 
Sent: Wednesday, March 14, 2012 9:16 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] No need to handle between-group correlation
structure in glmm in general?

Hi Dr. Pierce,

Thanks for the reply! And the information you provided is very useful!
Do you know if any existing R tools can handle this type of analysis?

The suggestion of comparing model fit is a good idea, but probably a
more important issue is whether the presence of correlated random
effects biases the parameter estimation. I am aware of a few test
techniques related to this, but totally unsure about their
implications. For example, is it a good idea to perform Moran's I test
on the second level residuals? (Or random effects directly?) A more
important question is, if Moran's I suggests autocorrelation in second
level residuals, would it be corrected by incorporating an correlation
structure for random effects?

REGARDS,
Junyan

On Wed, Mar 14, 2012 at 8:37 AM, Steven J. Pierce <pierces1 at msu.edu> wrote:
> The best thing to do would be to empirically test whether modeling the
> spatial autocorrelation in the level 2 random effects improves model fit
> compared with a simpler model that assumes independence of those random
> effects. In my dissertation work, adding spatial autocorrelation at level
2
> improved a model (but not dramatically).
>
> Check out the following resources:
>
> Beard, J. R. (2008). New approaches to multilevel analysis. Journal of
Urban
> Health, 85(6), 805-806. doi: 10.1007/s11524-008-9314-7
>
> Browne, W., & Goldstein, H. (2010). MCMC sampling for a multilevel model
> with non-independent residuals within and between cluster units. Journal
of
> Educational and Behavioral Statistics, 35(4), 453-473. doi:
> 10.3102/1076998609359788
>
> Chaix, B., Leyland, A. H., Sabel, C. E., Chauvin, P., R?stam, L.,
> Kristersson, H., & Merlo, J. (2006). Spatial clustering of mental
disorders
> and associated characteristics of the neighbourhood context in Malm?,
> Sweden, in 2001. Journal of Epidemiology and Community Health, 60(5),
> 427-435. doi: 10.1136/jech.2005.040360
>
> Chaix, B., Merlo, J., & Chauvin, P. (2005). Comparison of a spatial
approach
> with the multilevel approach for investigating place effects on health:
The
> example of healthcare utilisation in France. Journal of Epidemiology and
> Community Health, 59(6), 517-526. doi: 10.1136/jech.2004.025478
>
> Chaix, B., Merlo, J., Evans, D., Leal, C., & Havard, S. (2009).
> Neighborhoods in eco-epidemiologic research: Delimiting personal exposure
> areas. A response to Riva, Gauvin, Apparicio and Brodeur. Social Science &
> Medicine, 69(9), 1306-1310. doi: 10.1016/j.socscimed.2009.07.018
>
> Chaix, B., Merlo, J., Subramanian, S. V., Lynch, J., & Chauvin, P. (2005).
> Comparison of a spatial perspective with the multilevel analytical
approach
> in neighborhood studies: The case of mental and behavioral disorders due
to
> psychoactive substance use in Malm?, Sweden, 2001. American Journal of
> Epidemiology, 162(2), 171-182. doi: 10.1093/aje/kwi175
>
> Fagg, J., Curtis, S., Clark, C., Congdon, P., & Stansfeld, S. A. (2008).
> Neighbourhood perceptions among inner-city adolescents: Relationships with
> their individual characteristics and with independently assessed
> neighbourhood conditions. Journal of Environmental Psychology, 28(2),
> 128-142. doi: 10.1016/j.jenvp.2007.10.004
>
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Junyan Luo [mailto:jzl106 at gmail.com]
> Sent: Tuesday, March 13, 2012 7:33 PM
> To: R-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] No need to handle between-group correlation structure
in
> glmm in general?
>
> Hi,
> Recently I have been working with a data set that contains individual
> samples from a set of connected geographical areal units. While I plan
> to use glmm to model the data with individuals as the 1st level units
> and the areal units as the 2nd level units, I am concerned with the
> potential spatial autocorrelation among the geographical areal units
> (i.e., at the second level). It is reasonable to think that the random
> effects at the second level will be spatial autocorrelated. I know
> nlme has the option to specify "within-group" correlation structure,
> but I couldn't figure out a way to specify "between-group"
> correlations structure for the geographical areal units.
>
> However, one of my colleagues told me it was totally unnecessary to
> specify a correlation structure at the second level. This is because
> the two assumptions of multi-level models are (1) the individual error
> term is independent; (2) the individual error term is uncorrelated
> with the random effects. It does NOT assume that the random effects
> should be independent. So unless (2) is violated, generally we don't
> need to worry about autocorrelation in the random effects. That's
> probably why nlme only has the option for specifying "within-group"
> correlation structure. I feel the assessment is reasonable, but I am
> unsure if that is correct. Can anybody help me clarify this? Thanks!
>
>
>



From bates at stat.wisc.edu  Thu Mar 15 16:43:34 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Mar 2012 10:43:34 -0500
Subject: [R-sig-ME] help with lme4
In-Reply-To: <CABTnRNBfR5++5=cP0J87D9yWhwRzZk8wtg687Fj4XhAC9sM5JA@mail.gmail.com>
References: <CABTnRNBfR5++5=cP0J87D9yWhwRzZk8wtg687Fj4XhAC9sM5JA@mail.gmail.com>
Message-ID: <CAO7JsnRCisxhjSBmHWAjzT6KX-JB9WA63z=Z5DyFxV1gudNa9g@mail.gmail.com>

On Thu, Mar 15, 2012 at 10:35 AM, S?bastien Bonthoux
<bonthoux.sebastien at gmail.com> wrote:
> Dear D.Bates,
> I am using your package lme4 and the function lmer(). I link a metric of
> ecological community specialisation (gaussian distribution) with several
> land use variables and I add a random intercept because my plots are
> clustered. Can you explain me why I obtain a negative deviance (positive
> logLik) ? Is there any problem ?

Generally it is best to send questions like this to the
R-SIG-Mixed-Models at R-project.org mailing list (see instructions at
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models).  Many of
those who read that list can reply and often much faster than I am
able to.

The short answer to your question is that a negative deviance for a
model with a response measured on a continuous scale is not a problem.
 Probability mass functions for discrete random variables cannot
exceed 1 but probability density functions for continuous random
variables can.  Thus the log-likelihood for a continuous response can
be positive and the deviance negative.

> Thank you for you reply.
> Best regards
>
> --
> S?bastien Bonthoux
>
> Docteur en Ecologie - PhD in Ecology
>
> 02 54 78 05 74
> Ecole Nationale Sup?rieure de la Nature et du Paysage
> 9 rue de la chocolaterie
> 41 000 Blois
>
>
>



From chantepie at mnhn.fr  Thu Mar 15 17:22:28 2012
From: chantepie at mnhn.fr (Stephane Chantepie)
Date: Thu, 15 Mar 2012 17:22:28 +0100
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned
	G/R structure" and "Mixed model equations singular" errors
In-Reply-To: <20120311092028.13357jqqer7t0k08@www.staffmail.ed.ac.uk>
References: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
	<20120309173352.168215srxwe8241c@dsiwebmail.mnhn.fr>
	<20120311092028.13357jqqer7t0k08@www.staffmail.ed.ac.uk>
Message-ID: <201203151722.28254.chantepie@mnhn.fr>

Dear all,

I have tried the different solutions you proposed.

I have tried to scale fixed parameters and the response variables between 0 
and 1 but the problem remained

However, using ASREML, it seems that the problem comes from the residual 
covariance matrix. As supposed by Jarrod the residual covariance matrix is 
singular. I am pretty sure that it is due the structure of my data but I 
really don't know how I can fix this problem.


I use several age classes (which represent my traits) and I have intra-annual 
repeated measurements for several years and for each individual. 
The fixed parameters I use are: 
-tse : time since the last ejaculation collect: it is used to take into 
account the pressure due to the repeated collect.
-joe : day of ejaculation : represents the time since the first ejaculation of 
the year. I use this parameter to take into account the seasonal variation of 
sperm production.
The model is AgeClass1 AgeClass2 ~ at.level(trait,1): tse+ at.level(trait,2): 
tse+ at.level(trait,1): joe + at.level(trait,2): joe, 
random=~us(trait):animal+us(trait):ID+us(trait):Year, rcov = ~us(trait):units


With the data structure I have, it is impossible to have measurements of the 
same individual on the same line (snapshot to help comprehension: 
http://ubuntuone.com/1W19vErC5jUtHqMn1dtmPg ), likely making it impossible to 
estimate a residual covariance. One of the issues is that I can not see really 
how to change the structure of the data so it?s estimable. 
Is there a solution? I?m afraid if I fix the residuals covariance matrix to 0, 
I will inflate Va.

Do you have an idea?

many thanks for your help

stephane



From bates at stat.wisc.edu  Thu Mar 15 22:54:18 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Mar 2012 16:54:18 -0500
Subject: [R-sig-ME] Package name changes on the SVN repository at
	lme4.R-forge.R-project.org
Message-ID: <CAO7JsnTbBT1BpooRA-emEz7gVFJZyZYmq0BLrc6f+iNYMRBGPA@mail.gmail.com>

This message is only important to those who follow the development
version of the lme4 package at its R-forge SVN repository.

The released version of lme4 is now called lme4.0 and the development
version that was called lme4Eigen is now called lme4.  As the new lme4
gains stability we will release the old version to CRAN as lme4.0

The reason for keeping the old version available as lme4.0 is because
of other software and some publications that depend on the structure
and component or slot names from that package.



From Mike.Lawrence at dal.ca  Fri Mar 16 13:32:54 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 16 Mar 2012 09:32:54 -0300
Subject: [R-sig-ME] multicore lmer: any changes since 2007?
In-Reply-To: <4E149E29.10006@gmail.com>
References: <CAB+QPJB7b8qYrHs1O7crK6kTiEoCHixdonVFw2kN9qTPCLsgjw@mail.gmail.com>
	<CAO7JsnSGENOn9uKtuH45Q916QA_yNH4BSEvAg8ZynY+sk3Ex2g@mail.gmail.com>
	<CAB+QPJCGVO=4kR4V6f7dCNs=QqLUjA40H3b7UGHC3ZzxbJ+6Gg@mail.gmail.com>
	<4E149E29.10006@gmail.com>
Message-ID: <CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>

Apologies for resurrecting a months-old thread, but I thought I'd note
that DEoptim has now been made parallel:

http://blog.fosstrading.com/2012/03/deoptim-in-parallel.html


On Wed, Jul 6, 2011 at 2:40 PM, Ben Bolker <bbolker at gmail.com> wrote:
> On 07/06/2011 11:40 AM, Mike Lawrence wrote:
>> Thanks for the detailed reply.
>>
>> According to the comment by Joshua Ulrich (one of the DEoptim
>> developers) on this stackoverflow post
>> (http://stackoverflow.com/questions/3759878/parallel-optimization-in-r),
>> it seems that DEoptim might be a parallel-izable optimizer, and as I
>> recall you can put box constraints on parameters with DEoptim. I just
>> sent off an email to the DEoptim developers to see if there's been any
>> progress on the parallel front.
>>
>> Mike
>
> ?I have used differential evolution in the past (although not in
> decades (!!)), although not the DEoptim() package, but I don't think
> DEoptim() will be appropriate for this purpose. ?I'm actually not
> entirely clear on what DB means by "parallel evaluation of the objective
> function". ?In the simplest derivative-free case for example (the
> Nelder-Mead simplex), it's hard to see how one could evaluate the
> objective function in parallel because each evaluation changes the
> structure of the simplex and determines where the next evaluation should
> be. ?A very quick look at BOBYQA (source code in the minqa package, or
> formal description at
> <http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf>) suggests
> the same one-point-at-a-time updating scheme.
>
> ?But DB says
>
>>> In many cases you know several points where you will be
>>> evaluating the objective so you could split those
>>> off into different threads.
>
> ?Since he has (probably literally) forgotten more about numerical
> computation than I ever knew, he's probably right, but I don't know of
> those examples.
>
> ?Interesting discussion ...
>
>
>>
>> On Wed, Jul 6, 2011 at 11:59 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> On Tue, Jul 5, 2011 at 4:52 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>> Back in 2007 (http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17777.html)
>>>> Dr. Bates suggested that using a multithreaded BLAS was the only
>>>> option for speeding lmer computations on multicore machines (and even
>>>> then, it might even cause a slow down under some circumstances).
>>>>
>>>> Is this advice still current, or have other means of speeding lmer
>>>> computations on multicore machines arisen in more recent years?
>>>
>>> As always, the problem with trying to parallelize a particular
>>> calculation is to determine how and when to start more than one
>>> thread.
>>>
>>> After the setup stage the calculations in fitting an lmer model
>>> involve optimizing the profiled deviance or profiled REML criterion.
>>> Each evaluation of the criterion involves updating the components of
>>> the relative covariance factor, updating the sparse Cholesky
>>> decomposition and solving a couple of systems of equations involving
>>> the sparse Cholesky factor.
>>>
>>> There are a couple of calculations involving dense matrices but in
>>> most cases the time spent on them is negligible relative to the
>>> calculations involving the sparse matrices.
>>>
>>> A multithreaded BLAS will only help speed up the calculations on dense
>>> matrices. ?The "supernodal" form of the Cholesky factorization can use
>>> the BLAS for some calculations but usually on small blocks. ?Most of
>>> the time the software chooses the "simplicial" form of the
>>> factorization because the supernodal form would not be efficient and
>>> the simplicial form doesn't use the BLAS at all. ?Even if the
>>> supernodal form is chosen, the block sizes are usually small and a
>>> multithreaded BLAS can actually slow down operations on small blocks
>>> because the communication and synchronization overhead cancels out any
>>> gain from using multiple cores.
>>>
>>> Of course, your mileage may vary and only by profiling both the R code
>>> and the compiled code will you be able to determine how things could
>>> be sped up.
>>>
>>> If I had to guess, I would say that the best hope for parallelizing
>>> the computation would be to find an optimizer that allows for parallel
>>> evaluation of the objective function. ?The lme4 package requires
>>> optimization of a nonlinear objective subject to "box constraints"
>>> (meaning that some of the parameters can have upper and/or lower
>>> bounds). ?Actually it is simpler than that, some of the parameters
>>> must be positive. ?We do not provide gradient evaluations. ?I once*
>>> worked out the gradient of the criterion (I think it was the best
>>> mathematics I ever did) and then found that it ended up slowing the
>>> optimization to a crawl in the difficult cases. ?A bit of reflection
>>> showed that each evaluation of the gradient could be hundreds or
>>> thousands of times more complex than an evaluation of the objective
>>> itself so you might as well use a gradient free method and just do
>>> more function evaluations. ?In many cases you know several points
>>> where you will be evaluating the objective so you could split those
>>> off into different threads.
>>>
>>> I don't know of such a mulithreaded optimizer (many of the optimizers
>>> that I find are still being written in Fortran 77, God help us) but
>>> that would be my best bet if one could be found. ?However, I am saying
>>> this without having done the profiling of the calculation myself so
>>> that is still a guess.
>>>
>>> * Bates and DebRoy, "Linear mixed models and penalized least squares",
>>> Journal of Multivariate Analysis, 91 (2004) 1-17
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Mike.Lawrence at dal.ca  Fri Mar 16 14:14:02 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 16 Mar 2012 10:14:02 -0300
Subject: [R-sig-ME] multicore lmer: any changes since 2007?
In-Reply-To: <CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>
References: <CAB+QPJB7b8qYrHs1O7crK6kTiEoCHixdonVFw2kN9qTPCLsgjw@mail.gmail.com>
	<CAO7JsnSGENOn9uKtuH45Q916QA_yNH4BSEvAg8ZynY+sk3Ex2g@mail.gmail.com>
	<CAB+QPJCGVO=4kR4V6f7dCNs=QqLUjA40H3b7UGHC3ZzxbJ+6Gg@mail.gmail.com>
	<4E149E29.10006@gmail.com>
	<CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>
Message-ID: <CAB+QPJBzRzkRc8=UxPBXpvLOXq4Zo91bJm189uCQEv7FkM8dHg@mail.gmail.com>

Oh, and here's a gist showing how to use it using doMC for those of us
on unix systems:
https://gist.github.com/2050019


On Fri, Mar 16, 2012 at 9:32 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Apologies for resurrecting a months-old thread, but I thought I'd note
> that DEoptim has now been made parallel:
>
> http://blog.fosstrading.com/2012/03/deoptim-in-parallel.html
>
>
> On Wed, Jul 6, 2011 at 2:40 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> On 07/06/2011 11:40 AM, Mike Lawrence wrote:
>>> Thanks for the detailed reply.
>>>
>>> According to the comment by Joshua Ulrich (one of the DEoptim
>>> developers) on this stackoverflow post
>>> (http://stackoverflow.com/questions/3759878/parallel-optimization-in-r),
>>> it seems that DEoptim might be a parallel-izable optimizer, and as I
>>> recall you can put box constraints on parameters with DEoptim. I just
>>> sent off an email to the DEoptim developers to see if there's been any
>>> progress on the parallel front.
>>>
>>> Mike
>>
>> ?I have used differential evolution in the past (although not in
>> decades (!!)), although not the DEoptim() package, but I don't think
>> DEoptim() will be appropriate for this purpose. ?I'm actually not
>> entirely clear on what DB means by "parallel evaluation of the objective
>> function". ?In the simplest derivative-free case for example (the
>> Nelder-Mead simplex), it's hard to see how one could evaluate the
>> objective function in parallel because each evaluation changes the
>> structure of the simplex and determines where the next evaluation should
>> be. ?A very quick look at BOBYQA (source code in the minqa package, or
>> formal description at
>> <http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf>) suggests
>> the same one-point-at-a-time updating scheme.
>>
>> ?But DB says
>>
>>>> In many cases you know several points where you will be
>>>> evaluating the objective so you could split those
>>>> off into different threads.
>>
>> ?Since he has (probably literally) forgotten more about numerical
>> computation than I ever knew, he's probably right, but I don't know of
>> those examples.
>>
>> ?Interesting discussion ...
>>
>>
>>>
>>> On Wed, Jul 6, 2011 at 11:59 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>>> On Tue, Jul 5, 2011 at 4:52 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>>> Back in 2007 (http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17777.html)
>>>>> Dr. Bates suggested that using a multithreaded BLAS was the only
>>>>> option for speeding lmer computations on multicore machines (and even
>>>>> then, it might even cause a slow down under some circumstances).
>>>>>
>>>>> Is this advice still current, or have other means of speeding lmer
>>>>> computations on multicore machines arisen in more recent years?
>>>>
>>>> As always, the problem with trying to parallelize a particular
>>>> calculation is to determine how and when to start more than one
>>>> thread.
>>>>
>>>> After the setup stage the calculations in fitting an lmer model
>>>> involve optimizing the profiled deviance or profiled REML criterion.
>>>> Each evaluation of the criterion involves updating the components of
>>>> the relative covariance factor, updating the sparse Cholesky
>>>> decomposition and solving a couple of systems of equations involving
>>>> the sparse Cholesky factor.
>>>>
>>>> There are a couple of calculations involving dense matrices but in
>>>> most cases the time spent on them is negligible relative to the
>>>> calculations involving the sparse matrices.
>>>>
>>>> A multithreaded BLAS will only help speed up the calculations on dense
>>>> matrices. ?The "supernodal" form of the Cholesky factorization can use
>>>> the BLAS for some calculations but usually on small blocks. ?Most of
>>>> the time the software chooses the "simplicial" form of the
>>>> factorization because the supernodal form would not be efficient and
>>>> the simplicial form doesn't use the BLAS at all. ?Even if the
>>>> supernodal form is chosen, the block sizes are usually small and a
>>>> multithreaded BLAS can actually slow down operations on small blocks
>>>> because the communication and synchronization overhead cancels out any
>>>> gain from using multiple cores.
>>>>
>>>> Of course, your mileage may vary and only by profiling both the R code
>>>> and the compiled code will you be able to determine how things could
>>>> be sped up.
>>>>
>>>> If I had to guess, I would say that the best hope for parallelizing
>>>> the computation would be to find an optimizer that allows for parallel
>>>> evaluation of the objective function. ?The lme4 package requires
>>>> optimization of a nonlinear objective subject to "box constraints"
>>>> (meaning that some of the parameters can have upper and/or lower
>>>> bounds). ?Actually it is simpler than that, some of the parameters
>>>> must be positive. ?We do not provide gradient evaluations. ?I once*
>>>> worked out the gradient of the criterion (I think it was the best
>>>> mathematics I ever did) and then found that it ended up slowing the
>>>> optimization to a crawl in the difficult cases. ?A bit of reflection
>>>> showed that each evaluation of the gradient could be hundreds or
>>>> thousands of times more complex than an evaluation of the objective
>>>> itself so you might as well use a gradient free method and just do
>>>> more function evaluations. ?In many cases you know several points
>>>> where you will be evaluating the objective so you could split those
>>>> off into different threads.
>>>>
>>>> I don't know of such a mulithreaded optimizer (many of the optimizers
>>>> that I find are still being written in Fortran 77, God help us) but
>>>> that would be my best bet if one could be found. ?However, I am saying
>>>> this without having done the profiling of the calculation myself so
>>>> that is still a guess.
>>>>
>>>> * Bates and DebRoy, "Linear mixed models and penalized least squares",
>>>> Journal of Multivariate Analysis, 91 (2004) 1-17
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Mar 16 15:45:53 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 16 Mar 2012 09:45:53 -0500
Subject: [R-sig-ME] multicore lmer: any changes since 2007?
In-Reply-To: <CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>
References: <CAB+QPJB7b8qYrHs1O7crK6kTiEoCHixdonVFw2kN9qTPCLsgjw@mail.gmail.com>
	<CAO7JsnSGENOn9uKtuH45Q916QA_yNH4BSEvAg8ZynY+sk3Ex2g@mail.gmail.com>
	<CAB+QPJCGVO=4kR4V6f7dCNs=QqLUjA40H3b7UGHC3ZzxbJ+6Gg@mail.gmail.com>
	<4E149E29.10006@gmail.com>
	<CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>
Message-ID: <CAO7JsnSnKEGfTuzBgs9kRtgpVrT1K4R=epp1hn6dNedXhGf=dw@mail.gmail.com>

On Fri, Mar 16, 2012 at 7:32 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Apologies for resurrecting a months-old thread, but I thought I'd note
> that DEoptim has now been made parallel:
>
> http://blog.fosstrading.com/2012/03/deoptim-in-parallel.html

Before trying any of the options for speeding up execution one should
first profile the execution ("profile" in the sense of Rprof and
profiling the underlying compiled code).  My guess is that the
calculations in the optimizer algorithm are not the bottleneck, it is
the evaluation of the deviance that takes the time.

Recently I switched to using the Google perftools
(http://code.google.com/p/gperftools/) for malloc/free to get a better
handle on potential memory errors in the development process.  It
should be possible to use the profiling of the compiled code from the
perftools too.

> On Wed, Jul 6, 2011 at 2:40 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> On 07/06/2011 11:40 AM, Mike Lawrence wrote:
>>> Thanks for the detailed reply.
>>>
>>> According to the comment by Joshua Ulrich (one of the DEoptim
>>> developers) on this stackoverflow post
>>> (http://stackoverflow.com/questions/3759878/parallel-optimization-in-r),
>>> it seems that DEoptim might be a parallel-izable optimizer, and as I
>>> recall you can put box constraints on parameters with DEoptim. I just
>>> sent off an email to the DEoptim developers to see if there's been any
>>> progress on the parallel front.
>>>
>>> Mike
>>
>> ?I have used differential evolution in the past (although not in
>> decades (!!)), although not the DEoptim() package, but I don't think
>> DEoptim() will be appropriate for this purpose. ?I'm actually not
>> entirely clear on what DB means by "parallel evaluation of the objective
>> function". ?In the simplest derivative-free case for example (the
>> Nelder-Mead simplex), it's hard to see how one could evaluate the
>> objective function in parallel because each evaluation changes the
>> structure of the simplex and determines where the next evaluation should
>> be. ?A very quick look at BOBYQA (source code in the minqa package, or
>> formal description at
>> <http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf>) suggests
>> the same one-point-at-a-time updating scheme.
>>
>> ?But DB says
>>
>>>> In many cases you know several points where you will be
>>>> evaluating the objective so you could split those
>>>> off into different threads.
>>
>> ?Since he has (probably literally) forgotten more about numerical
>> computation than I ever knew, he's probably right, but I don't know of
>> those examples.
>>
>> ?Interesting discussion ...
>>
>>
>>>
>>> On Wed, Jul 6, 2011 at 11:59 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>>> On Tue, Jul 5, 2011 at 4:52 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>>> Back in 2007 (http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17777.html)
>>>>> Dr. Bates suggested that using a multithreaded BLAS was the only
>>>>> option for speeding lmer computations on multicore machines (and even
>>>>> then, it might even cause a slow down under some circumstances).
>>>>>
>>>>> Is this advice still current, or have other means of speeding lmer
>>>>> computations on multicore machines arisen in more recent years?
>>>>
>>>> As always, the problem with trying to parallelize a particular
>>>> calculation is to determine how and when to start more than one
>>>> thread.
>>>>
>>>> After the setup stage the calculations in fitting an lmer model
>>>> involve optimizing the profiled deviance or profiled REML criterion.
>>>> Each evaluation of the criterion involves updating the components of
>>>> the relative covariance factor, updating the sparse Cholesky
>>>> decomposition and solving a couple of systems of equations involving
>>>> the sparse Cholesky factor.
>>>>
>>>> There are a couple of calculations involving dense matrices but in
>>>> most cases the time spent on them is negligible relative to the
>>>> calculations involving the sparse matrices.
>>>>
>>>> A multithreaded BLAS will only help speed up the calculations on dense
>>>> matrices. ?The "supernodal" form of the Cholesky factorization can use
>>>> the BLAS for some calculations but usually on small blocks. ?Most of
>>>> the time the software chooses the "simplicial" form of the
>>>> factorization because the supernodal form would not be efficient and
>>>> the simplicial form doesn't use the BLAS at all. ?Even if the
>>>> supernodal form is chosen, the block sizes are usually small and a
>>>> multithreaded BLAS can actually slow down operations on small blocks
>>>> because the communication and synchronization overhead cancels out any
>>>> gain from using multiple cores.
>>>>
>>>> Of course, your mileage may vary and only by profiling both the R code
>>>> and the compiled code will you be able to determine how things could
>>>> be sped up.
>>>>
>>>> If I had to guess, I would say that the best hope for parallelizing
>>>> the computation would be to find an optimizer that allows for parallel
>>>> evaluation of the objective function. ?The lme4 package requires
>>>> optimization of a nonlinear objective subject to "box constraints"
>>>> (meaning that some of the parameters can have upper and/or lower
>>>> bounds). ?Actually it is simpler than that, some of the parameters
>>>> must be positive. ?We do not provide gradient evaluations. ?I once*
>>>> worked out the gradient of the criterion (I think it was the best
>>>> mathematics I ever did) and then found that it ended up slowing the
>>>> optimization to a crawl in the difficult cases. ?A bit of reflection
>>>> showed that each evaluation of the gradient could be hundreds or
>>>> thousands of times more complex than an evaluation of the objective
>>>> itself so you might as well use a gradient free method and just do
>>>> more function evaluations. ?In many cases you know several points
>>>> where you will be evaluating the objective so you could split those
>>>> off into different threads.
>>>>
>>>> I don't know of such a mulithreaded optimizer (many of the optimizers
>>>> that I find are still being written in Fortran 77, God help us) but
>>>> that would be my best bet if one could be found. ?However, I am saying
>>>> this without having done the profiling of the calculation myself so
>>>> that is still a guess.
>>>>
>>>> * Bates and DebRoy, "Linear mixed models and penalized least squares",
>>>> Journal of Multivariate Analysis, 91 (2004) 1-17
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From gregoror at googlemail.com  Fri Mar 16 12:02:24 2012
From: gregoror at googlemail.com (Gregor Didenko)
Date: Fri, 16 Mar 2012 12:02:24 +0100
Subject: [R-sig-ME] With glmmPQL Error in corFactor.corSpatial(object)
Message-ID: <CAKqOgbeQi3HvKMrRHCipD2_BXQt=MsOsZ2C-+z2qOKRkL0Hsmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120316/f21d6ed9/attachment-0001.pl>

From slu at ccsr.uchicago.edu  Fri Mar 16 23:38:15 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Fri, 16 Mar 2012 17:38:15 -0500
Subject: [R-sig-ME] Unacceptibly high autocorrelation in MCMCglmm
Message-ID: <1331937495.455.18.camel@localhost>

Hello, I'm running this ordered category outcome model:

glme5.very.len <- MCMCglmm(very.len.summative.o ~ 1 ,
                   prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0) )),
                   random = ~emplid + deptid + grade.f + subject.f ,
                   family = "ordinal",
                   nitt=300000,
                   data = summative.ratings.prin.yr1.full)

I ran it first with nitt=100000 but had very high autocorrelations and
non-sensical variance components and fixed effects, so I increased nitt
to 200000 and then to 300000 but got no change. Here's the summary
output:

 summary(glme5.very.len)

 Iterations = 3001:299991
 Thinning interval  = 10
 Sample size  = 29700 

 DIC: -13239.32 

 G-structure:  ~emplid

       post.mean  l-95% CI u-95% CI eff.samp
emplid     405.3 1.493e-11     1106    7.909

               ~deptid

       post.mean  l-95% CI u-95% CI eff.samp
deptid     131.8 1.118e-16    475.2    42.65

               ~grade.f

        post.mean  l-95% CI u-95% CI eff.samp
grade.f    0.9143 1.405e-17    1.575    15784

               ~subject.f

          post.mean  l-95% CI u-95% CI eff.samp
subject.f     1.633 1.951e-17    2.748    10101

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: very.len.summative.o ~ 1 

            post.mean l-95% CI u-95% CI eff.samp  pMCMC    
(Intercept)    29.007    2.091   54.969    2.381 <3e-05 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

 Cutpoints: 
                                     post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitvery.len.summative.o.1     14.06   0.8102    27.38    9.382
cutpoint.traitvery.len.summative.o.2     40.34   2.9611    76.04    2.694

Here are some of the autocorrs:

 autocorr(glme5.very.len$VCV)
, , emplid

           emplid    deptid    grade.f  subject.f units
Lag 0   1.0000000 0.5860851 0.04668197 0.06081864   NaN
Lag 10  0.9514313 0.6132116 0.04345287 0.05652945   NaN
Lag 50  0.9459831 0.6259477 0.04881253 0.06093640   NaN
Lag 100 0.9433509 0.6282599 0.04492884 0.06037288   NaN
Lag 500 0.9267886 0.6373151 0.03873992 0.05371885   NaN

, , deptid

           emplid    deptid    grade.f  subject.f units
Lag 0   0.5860851 1.0000000 0.03070680 0.03453008   NaN
Lag 10  0.6137187 0.7579551 0.03233992 0.04139315   NaN
Lag 50  0.6255810 0.7169468 0.02903334 0.03960446   NaN
Lag 100 0.6269979 0.7029498 0.03244468 0.04857241   NaN
Lag 500 0.6322900 0.6650247 0.04049514 0.04306019   NaN

Is there a problem in my data or in the model?

Thank you.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
Benjamin Lloyd-Hughes: Has anyone had any joy
 getting the rgdal package to compile under
<windows? Roger Bivand: The closest anyone has got 
 so far is Hisaji Ono, who used MSYS
 (http://www.mingw.org/) to build PROJ.4 and GDAL
 (GDAL depends on PROJ.4, PROJ.4 needs a PATH to
 metadata files for projection and transformation),
 and then hand-pasted the paths to the GDAL headers
 and library into src/Makevars, running Rcmd



From j.hadfield at ed.ac.uk  Sat Mar 17 11:29:16 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 17 Mar 2012 10:29:16 +0000
Subject: [R-sig-ME] Unacceptibly high autocorrelation in MCMCglmm
In-Reply-To: <1331937495.455.18.camel@localhost>
References: <1331937495.455.18.camel@localhost>
Message-ID: <20120317102916.64036j23f48cdugw@www.staffmail.ed.ac.uk>

HI,

It looks like the probit has underflowed/overflowed - you can check  
this by saving the latent variables and looking to see whether the  
range of the absolute values exceeds 7 (See Section 8.08 of  
CourseNotes).

This can happen with weak priors and (near) complete separation and/or  
with weak priors for effects that are heavily confounded.

I'm not sure how to proceed with underflow/overflow problems  
generally.  I could terminate the procedure, or I could truncate the  
latent variables at their overflow/underflow points. The latter is  
used by some WinBUGS users, but then WinBUGS handles the fact that the  
response is from a truncated normal not a normal - something which  
would be hard to program in MCMCglmm. Any thoughts would be useful.

Cheers,

Jarrod



Quoting Stuart Luppescu <slu at ccsr.uchicago.edu> on Fri, 16 Mar 2012  
17:38:15 -0500:

> Hello, I'm running this ordered category outcome model:
>
> glme5.very.len <- MCMCglmm(very.len.summative.o ~ 1 ,
>                    prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
> nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0) )),
>                    random = ~emplid + deptid + grade.f + subject.f ,
>                    family = "ordinal",
>                    nitt=300000,
>                    data = summative.ratings.prin.yr1.full)
>
> I ran it first with nitt=100000 but had very high autocorrelations and
> non-sensical variance components and fixed effects, so I increased nitt
> to 200000 and then to 300000 but got no change. Here's the summary
> output:
>
>  summary(glme5.very.len)
>
>  Iterations = 3001:299991
>  Thinning interval  = 10
>  Sample size  = 29700
>
>  DIC: -13239.32
>
>  G-structure:  ~emplid
>
>        post.mean  l-95% CI u-95% CI eff.samp
> emplid     405.3 1.493e-11     1106    7.909
>
>                ~deptid
>
>        post.mean  l-95% CI u-95% CI eff.samp
> deptid     131.8 1.118e-16    475.2    42.65
>
>                ~grade.f
>
>         post.mean  l-95% CI u-95% CI eff.samp
> grade.f    0.9143 1.405e-17    1.575    15784
>
>                ~subject.f
>
>           post.mean  l-95% CI u-95% CI eff.samp
> subject.f     1.633 1.951e-17    2.748    10101
>
>  R-structure:  ~units
>
>       post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
>
>  Location effects: very.len.summative.o ~ 1
>
>             post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)    29.007    2.091   54.969    2.381 <3e-05 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>  Cutpoints:
>                                      post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitvery.len.summative.o.1     14.06   0.8102    27.38    9.382
> cutpoint.traitvery.len.summative.o.2     40.34   2.9611    76.04    2.694
>
> Here are some of the autocorrs:
>
>  autocorr(glme5.very.len$VCV)
> , , emplid
>
>            emplid    deptid    grade.f  subject.f units
> Lag 0   1.0000000 0.5860851 0.04668197 0.06081864   NaN
> Lag 10  0.9514313 0.6132116 0.04345287 0.05652945   NaN
> Lag 50  0.9459831 0.6259477 0.04881253 0.06093640   NaN
> Lag 100 0.9433509 0.6282599 0.04492884 0.06037288   NaN
> Lag 500 0.9267886 0.6373151 0.03873992 0.05371885   NaN
>
> , , deptid
>
>            emplid    deptid    grade.f  subject.f units
> Lag 0   0.5860851 1.0000000 0.03070680 0.03453008   NaN
> Lag 10  0.6137187 0.7579551 0.03233992 0.04139315   NaN
> Lag 50  0.6255810 0.7169468 0.02903334 0.03960446   NaN
> Lag 100 0.6269979 0.7029498 0.03244468 0.04857241   NaN
> Lag 500 0.6322900 0.6650247 0.04049514 0.04306019   NaN
>
> Is there a problem in my data or in the model?
>
> Thank you.
>
> --
> Stuart Luppescu -=- slu .at. ccsr.uchicago.edu
> University of Chicago -=- CCSR
> ???????? -=-    Kernel 3.2.1-gentoo-r2
> Benjamin Lloyd-Hughes: Has anyone had any joy
>  getting the rgdal package to compile under
> <windows? Roger Bivand: The closest anyone has got
>  so far is Hisaji Ono, who used MSYS
>  (http://www.mingw.org/) to build PROJ.4 and GDAL
>  (GDAL depends on PROJ.4, PROJ.4 needs a PATH to
>  metadata files for projection and transformation),
>  and then hand-pasted the paths to the GDAL headers
>  and library into src/Makevars, running Rcmd
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From lucianolasala at yahoo.com.ar  Sat Mar 17 20:25:50 2012
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Sat, 17 Mar 2012 16:25:50 -0300
Subject: [R-sig-ME] Poisson GLMM: where is the deviance?
Message-ID: <000a01cd0473$c45e7fd0$4d1b7f70$@com.ar>

Dear R experts:

I need to fit the following GLMM with Poisson distribution: glmer(yobs~year
+ (year|stake), data=mibase,family=poisson)


Where "stake" (plots where the number of birds is measured) is as random
effect, and "yobs" is the abundance of birds. I need an estimation of slope
an intercept for the random term.

I specified my model as follows:

glmer(yobs~year + (year|stake), data=mibase,family=poisson)

and I get the following (it does not calculate the deviance)

? Generalized linear mixed model fit by the Laplace approximation

? Formula: yobs ~ year + (year | stake)
? ? ?Data: mibase
? ?AIC BIC logLik deviance
? ?NaN NaN ? ?NaN ? ? ?NaN

? Random effects:
? ?Groups Name ? ? ? ?Variance ? Std.Dev. ? Corr
? ?stake ?(Intercept) 1.4165e-01 0.37636766
? ? ? ? ? year ? ? ? ?3.5469e-08 0.00018833 0.000
? Number of obs: 1186, groups: stake, 63
? Fixed effects:
? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
? (Intercept) ?3.213e+01 ?6.445e+08 ? ? ? 0 ? ? ? ?1
? year ? ? ? ?-1.952e-01 ?3.225e+05 ? ? ? 0 ? ? ? ?1

- Ignored:

? Correlation of Fixed Effects:
? ? ? ?(Intr)
? year -1.000
? Mensajes de aviso perdidos
? In mer_finalize(ans) : singular convergence (7)


Q. What does this error mean and how can I solve it?

By the way, if I run the same model but only estimating the intercept of
random effects as
glmer(yobs~year + (1|stake), data=mibase,family=poisson) it seems to work
properly.


I look forward for your response and thanks in advance.

Luciana



From bbolker at gmail.com  Sat Mar 17 22:03:55 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 17 Mar 2012 21:03:55 +0000 (UTC)
Subject: [R-sig-ME] Poisson GLMM: where is the deviance?
References: <000a01cd0473$c45e7fd0$4d1b7f70$@com.ar>
Message-ID: <loom.20120317T212658-250@post.gmane.org>

Luciano La Sala <lucianolasala at ...> writes:

>
 
 [snip]

> Where "stake" (plots where the number of birds is measured) is as random
> effect, and "yobs" is the abundance of birds. I need an estimation of slope
> an intercept for the random term.
> 
> I specified my model as follows:
> 
> glmer(yobs~year + (year|stake), data=mibase,family=poisson)
> 
> and I get the following (it does not calculate the deviance)
> 
> ? Generalized linear mixed model fit by the Laplace approximation
> 
  [snip]

> Q. What does this error mean and how can I solve it?
> 
> By the way, if I run the same model but only estimating the intercept of
> random effects as
> glmer(yobs~year + (1|stake), data=mibase,family=poisson) it seems to work
> properly.

  You aren't doing anything obviously silly, that I can see.

  Can we see a str() of your data?  I wonder if your 'year' variable
got turned into a factor by mistake.

  How many stakes do you have?  If it is fewer than 5-6 you are likely
to have numerical problems ...

  When in doubt plot your data ...



From awillcor at gmail.com  Fri Mar 16 22:54:02 2012
From: awillcor at gmail.com (Andrew Correia)
Date: Fri, 16 Mar 2012 17:54:02 -0400
Subject: [R-sig-ME] Measures of dispersion for random effects
Message-ID: <CAOhHVi1QQ1ZZ_jxJB68nF1gw+22_QP3o10C1eYpCdbRNnm11DQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120316/4b589267/attachment-0001.pl>

From jwiley.psych at gmail.com  Sun Mar 18 05:35:35 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 17 Mar 2012 21:35:35 -0700
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
Message-ID: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>

Hi,

I am trying to use a multivariate mixed effects linear model to
examine mediation.  This works fine.  The final step is to compute the
indirect effect and its standard error.  The indirect effect is easy
(product of coefficients plus their covariance).  For the standard
error, I need the gradient (D) and the hessian (H):
the variance is then:

D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}

This is all given in the Appendix of
http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf

Is there a way to get this out of a mer class object?  Looking at
class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$.  @V
seems like it would give me the gradient but is null for a basic lmer
model.

Thanks,

Josh

-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From m.fairbrother at bristol.ac.uk  Sun Mar 18 14:31:04 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 18 Mar 2012 13:31:04 +0000
Subject: [R-sig-ME] modelling proportions, with aggregated data,
	and the new/old lme4
In-Reply-To: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
Message-ID: <15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>

Dear list,

I have a question for which a more theoretical or more technical answer may be helpful--I'm not sure. Any assistance would be appreciated.

I am trying to model Census data, where individual responses to a question with two answer options have been aggregated up to the community level, and communities are nested in subdistricts. So the outcome of interest is a proportion (randing from 0 to 1), and I know the absolute number of "successes" and "failures". For each community, the data are available in a slightly disaggregated form for different categories of people (I'll use the separate numbers of successes and failures for women and men as an example). Thus the data look like:

head(dat)
  successes failures id sex subdist
1       560      726  1   F       4
2       844      510  1   M       4
3       340      438  2   F       4
4       616      273  2   M       4
5         7        0  3   F       4
6         3        1  3   M       4

In community #1, which is in subdistrict #4, there are 560 women who are "successes" and 726 who are "failures" on this social indicator, etc. (The data are available via a link below.)

How should I model these data? I was originally thinking to use a binomial distribution, and a call defining the outcome as "cbind(successes, failures)", with each observation/row nested in (a) "id" and (b) "subdist".

(The idea of nesting the separate Census categories like this, and using a multilevel approach, comes from: http://www.hsph.harvard.edu/faculty/sv-subramanian/files/epa2001_33_3_399_417.pdf. There was a recent discussion of the use of "cbind" like this, but it seems workable in this case as a way to reduce tends of millions of observations to a few tens of thousands, with no loss of information: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007552.html.)

However, I gather that the binomial distribution is only appropriate where one is sampling a number of Bernoulli trials (i.e., people in this case) with replacement, making them independent. As I understand it, even if the sampling is not actually done with replacement, if N >> n (say at least 10x larger) then the binomial approach can be justified, as the trials are independent enough to be treated as such. However, in my case, I have no sample at all--I have data on the population--so the binomial approach appears to be a non-starter. Is that right?

I further gather that the less-well-known hypergeometric distribution is really most appropriate in cases where sampling is done without replacement, though I believe that neither lme4 nor MCMCglmm allows for this distribution, and again I have population rather than sample data.

I have a vague idea that another possibility would be to use the logit of each row (e.g., log(560/726) for the first row), and then simply model the logit with Normal errors. But what would I do then with rows that have proportions of 0 or 1? And, setting that issue aside, is the logit in principle an appropriate way to go?

Can anybody suggest a way forward, and/or explain where my thinking above has gone wrong? For a final twist, the code below shows the binomial approach, where the old lme4 (now lme4.0) quickly returns seemingly sensible results, but the new lme4 (formerly lme4Eigen) returns an interesting error.

Many thanks,
Malcolm


load(url("http://dl.dropbox.com/u/46385700/dat.RData"))
closeAllConnections()

M1 <- glm(cbind(successes, failures) ~ sex, dat, family=binomial)
cbind(as.numeric(by(dat, dat$sex, function(x) sum(x$successes)/(sum(x$successes)+sum(x$failures)))), plogis(cumsum(coef(M1))))

library(lme4.0) # lme4.0_0.9999-1

system.time(M2 <- lmer(cbind(successes, failures) ~ sex + (1 | subdist), dat, family=binomial))
cbind(as.numeric(by(dat, dat$sex, function(x) sum(x$successes)/(sum(x$successes)+sum(x$failures)))), plogis(cumsum(fixef(M2))))

system.time(M3 <- lmer(cbind(successes, failures) ~ sex + (1 | id) + (1 | subdist), dat, family=binomial))
cbind(as.numeric(by(dat, dat$sex, function(x) sum(x$successes)/(sum(x$successes)+sum(x$failures)))), plogis(cumsum(fixef(M3))))

detach(package:lme4.0)
library(lme4) # lme4_0.99990234375-0

# however, with the new lme4 (former lme4Eigen) I get an error:

system.time(M4 <- lmer(cbind(successes, failures) ~ sex + (1 | subdist), dat, family=binomial))
Error in fn(nM$xeval()) : 
  step factor reduced below 0.001 without reducing pwrss
Timing stopped at: 16.159 0.639 16.787 



From bbolker at gmail.com  Sun Mar 18 19:10:15 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 18 Mar 2012 18:10:15 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?modelling_proportions=2C_with_aggregated_dat?=
	=?utf-8?q?a=2C=09and_the_new/old_lme4?=
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
Message-ID: <loom.20120318T185026-397@post.gmane.org>

Malcolm Fairbrother <m.fairbrother at ...> writes:

> 

[snip]

> I am trying to model Census data, where individual responses to a
> question with two answer options have been aggregated up to the
> community level, and communities are nested in subdistricts. So the
> outcome of interest is a proportion (ranging from 0 to 1), and I
> know the absolute number of "successes" and "failures". For each
> community, the data are available in a slightly disaggregated form
> for different categories of people (I'll use the separate numbers of
> successes and failures for women and men as an example). Thus the
> data look like:

> head(dat)
>   successes failures id sex subdist
> 1       560      726  1   F       4
> 2       844      510  1   M       4
> 3       340      438  2   F       4
> 4       616      273  2   M       4
> 5         7        0  3   F       4
> 6         3        1  3   M       4
> 
> In community #1, which is in subdistrict #4, there are 560 women 

  you mean 510, right?

> who are "successes" and 726 who are "failures" on this social
> indicator, etc. (The data are available via a link below.)
 
> How should I model these data? I was originally thinking to use a
> binomial distribution, and a call defining the outcome as
> "cbind(successes, failures)", with each observation/row nested in
> (a) "id" and (b) "subdist".
 
> (The idea of nesting the separate Census categories like this, and
> using a multilevel approach, comes from:
> http://www.hsph.harvard.edu/faculty/
>     sv-subramanian/files/epa2001_33_3_399_417.pdf.
> There was a recent discussion of the use of "cbind" like this, but
> it seems workable in this case as a way to reduce tends of millions
> of observations to a few tens of thousands, with no loss of
> information:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007552.html.)

 
> However, I gather that the binomial distribution is only appropriate
> where one is sampling a number of Bernoulli trials (i.e., people in
> this case) with replacement, making them independent. As I
> understand it, even if the sampling is not actually done with
> replacement, if N >> n (say at least 10x larger) then the binomial
> approach can be justified, as the trials are independent enough to
> be treated as such. However, in my case, I have no sample at all--I
> have data on the population--so the binomial approach appears to be
> a non-starter. Is that right?

   Hmmm. For better or worse, I've seen the binomial distribution
used in (I think) a reasonable way in cases where strict independence
is not reasonable (e.g. in ecological predation trials where the
prey are all in a single tank with the predator).  Technically you're
assuming both independence *and* homogeneity ... I would probably do
it this way, perhaps testing for overdispersion and/or adding
an individual-level random effect.
 
> I further gather that the less-well-known hypergeometric
> distribution is really most appropriate in cases where sampling is
> done without replacement, though I believe that neither lme4 nor
> MCMCglmm allows for this distribution, and again I have population
> rather than sample data.

  I think this would be a lot harder ... 
 
> I have a vague idea that another possibility would be to use the
> logit of each row (e.g., log(560/726) for the first row), and then
> simply model the logit with Normal errors. But what would I do then
> with rows that have proportions of 0 or 1? And, setting that issue
> aside, is the logit in principle an appropriate way to go?

  I don't think it's ridiculous, but yes, you have to deal with the
0/1 cases.  This fussing-with-zeros-and-ones stuff applies even if you
were to use a Beta regression (which you can do via glmmADMB, although
it'll probably be a lot slower than lme4), which would in some sense
be a more principled way to deal with proportion data.  I like the
idea of keeping the denominators in there and using a binomial model.
I don't think you're missing anything obvious, though.

 
> Can anybody suggest a way forward, and/or explain where my thinking
> above has gone wrong? For a final twist, the code below shows the
> binomial approach, where the old lme4 (now lme4.0) quickly returns
> seemingly sensible results, but the new lme4 (formerly lme4Eigen)
> returns an interesting error.

  For a quick answer, try optimizer="bobyqa", and/or varying tolPwrss
settings, but please be very cautious/compare your answers.  We're still
working on adjusting optimizer choice/settings to make GLMMs in the
new version fast, robust, and accurate ...

  Ben



From r.turner at auckland.ac.nz  Sun Mar 18 19:51:14 2012
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 19 Mar 2012 07:51:14 +1300
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <loom.20120318T185026-397@post.gmane.org>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
Message-ID: <4F662EA2.2090305@auckland.ac.nz>

On 19/03/12 07:10, Ben Bolker wrote:

<SNIP>

>> head(dat)
>>    successes failures id sex subdist
>> 1       560      726  1   F       4
>> 2       844      510  1   M       4
>> 3       340      438  2   F       4
>> 4       616      273  2   M       4
>> 5         7        0  3   F       4
>> 6         3        1  3   M       4
>>
>> In community #1, which is in subdistrict #4, there are 560 women
>    you mean 510, right?
<SNIP>

Sure looks like 560 to me.  Time for a trek to the optometrist, Ben?

     cheers,

         Rolf



From joerg.luedicke at gmail.com  Sun Mar 18 23:06:49 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Sun, 18 Mar 2012 15:06:49 -0700
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <4F662EA2.2090305@auckland.ac.nz>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
Message-ID: <CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>

I would certainly check out a Poisson model with the number of
successes as outcome and successes+failures as an offset.

Joerg

On Sun, Mar 18, 2012 at 11:51 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 19/03/12 07:10, Ben Bolker wrote:
>
> <SNIP>
>
>
>>> head(dat)
>>> ? successes failures id sex subdist
>>> 1 ? ? ? 560 ? ? ?726 ?1 ? F ? ? ? 4
>>> 2 ? ? ? 844 ? ? ?510 ?1 ? M ? ? ? 4
>>> 3 ? ? ? 340 ? ? ?438 ?2 ? F ? ? ? 4
>>> 4 ? ? ? 616 ? ? ?273 ?2 ? M ? ? ? 4
>>> 5 ? ? ? ? 7 ? ? ? ?0 ?3 ? F ? ? ? 4
>>> 6 ? ? ? ? 3 ? ? ? ?1 ?3 ? M ? ? ? 4
>>>
>>> In community #1, which is in subdistrict #4, there are 560 women
>>
>> ? you mean 510, right?
>
> <SNIP>
>
> Sure looks like 560 to me. ?Time for a trek to the optometrist, Ben?
>
> ? ?cheers,
>
> ? ? ? ?Rolf
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Mon Mar 19 02:40:53 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2012 01:40:53 +0000 (UTC)
Subject: [R-sig-ME] modelling proportions, with aggregated data,
	and the new/old lme4
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
Message-ID: <loom.20120319T023745-978@post.gmane.org>

Joerg Luedicke <joerg.luedicke at ...> writes:

> I would certainly check out a Poisson model with the number of
> successes as outcome and successes+failures as an offset.

  That seems odd to me; the Poisson+offset model
should be appropriate when p<<1 (i.e. for very small p,
the Poisson variance mu=n*p is approximately the same as
the binomial variance n*p*(1-p); in this case p is not small.

  Of course, I could be wrong.

> 
> On Sun, Mar 18, 2012 at 11:51 AM, Rolf Turner <r.turner at ...> wrote:
> > On 19/03/12 07:10, Ben Bolker wrote:
> >
> > <SNIP>
> >
> >
> >>> head(dat)
> >>> ? successes failures id sex subdist
> >>> 1 ? ? ? 560 ? ? ?726 ?1 ? F ? ? ? 4
> >>> 2 ? ? ? 844 ? ? ?510 ?1 ? M ? ? ? 4

  [snip]

> >>>
> >>> In community #1, which is in subdistrict #4, there are 560 women
> >>
> >> ? you mean 510, right?
> >
> > <SNIP>
> >
> > Sure looks like 560 to me. ?Time for a trek to the optometrist, Ben?

  Looked at the wrong line (failures in men rather than successes in women).



From laf.nilsson at gmail.com  Mon Mar 19 11:09:17 2012
From: laf.nilsson at gmail.com (Fredrik Nilsson)
Date: Mon, 19 Mar 2012 11:09:17 +0100
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <loom.20120319T023745-978@post.gmane.org>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
	<loom.20120319T023745-978@post.gmane.org>
Message-ID: <CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>

Joerg,

What is the point in the Poisson model in that way (assuming
log(total) as offset)? This would be a binomial model; if you observe
N events from a Poisson distribution of which X are successes (or
marked in some way) with probability p, then X will be binomial(p, N).

Best regards,
Fredrik Nilsson

PS. Here's a practical "proof", the real is sketched below.
invlogit<-function(x) exp(x)/(1+exp(x))
n<-10
nn<-ceiling(exp(rnorm(n)+3))
pp<-seq(0.25,.75,length=n)
ca<-rbinom(rep(1,n),nn,prob=pp)
co<-nn-ca
fa<-gl(n,1)

#binomial model
test.glm<-glm(cbind(ca,co)~fa-1, family=binomial)
#conditional poisson
ptest.glm<-glm(ca~fa-1+offset(log(nn)), family=poisson)
summary(ptest.glm)
exp(coef(ptest.glm))
invlogit(coef(test.glm))

all.equal(exp(coef(ptest.glm)), invlogit(coef(test.glm)))

# proof.
X~Poisson(a) and  Y~Poisson(b), X & Y independent -> X+Y~Poisson(a+b)
(e.g. by generating functions).

Prob(X=x| X+Y=n) = Prob(X=x, Y=n-x)/Prob(X+Y=n) =
Prob(X=x)*Prob(Y=n-x)/Prob(X+Y=n) = a^x/x! exp(a) b^(n-x)/(n-x)!
exp(b) /((a+b)^n/n! exp(a+b)) =
n!/x!/(n-x)! (a/(a+b))^x (b/(a+b))^(n-x) = n!/x!/(n-x)! (a/(a+b))^x
(1-a/(a+b))^(n-x) , i.e. binomial(x,n,p) with p=a/(a+b).


2012/3/19 Ben Bolker <bbolker at gmail.com>:
> Joerg Luedicke <joerg.luedicke at ...> writes:
>
>> I would certainly check out a Poisson model with the number of
>> successes as outcome and successes+failures as an offset.
>
> ?That seems odd to me; the Poisson+offset model
> should be appropriate when p<<1 (i.e. for very small p,
> the Poisson variance mu=n*p is approximately the same as
> the binomial variance n*p*(1-p); in this case p is not small.
>
> ?Of course, I could be wrong.
>
>>
>> On Sun, Mar 18, 2012 at 11:51 AM, Rolf Turner <r.turner at ...> wrote:
>> > On 19/03/12 07:10, Ben Bolker wrote:
>> >
>> > <SNIP>
>> >
>> >
>> >>> head(dat)
>> >>> ? successes failures id sex subdist
>> >>> 1 ? ? ? 560 ? ? ?726 ?1 ? F ? ? ? 4
>> >>> 2 ? ? ? 844 ? ? ?510 ?1 ? M ? ? ? 4
>
> ?[snip]
>
>> >>>
>> >>> In community #1, which is in subdistrict #4, there are 560 women
>> >>
>> >> ? you mean 510, right?
>> >
>> > <SNIP>
>> >
>> > Sure looks like 560 to me. ?Time for a trek to the optometrist, Ben?
>
> ?Looked at the wrong line (failures in men rather than successes in women).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From juliet.hannah at gmail.com  Mon Mar 19 15:57:40 2012
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Mon, 19 Mar 2012 10:57:40 -0400
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com>
References: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com>
Message-ID: <CALzuZRQinGU4V91bNjiwM44GuY8hWt9=N9vb0oph6t6gvhF2AA@mail.gmail.com>

Thanks for all the responses. I'll study this further and will report back.

On Wed, Mar 14, 2012 at 8:28 AM, Ryan King <c.ryan.king at gmail.com> wrote:
> When the observation-level random effects are independent then they
> are the same as the noise. i.e.
> y = xb + u +e can just be rewritten y= xb + e', with e' = u+e. Since
> the sum of two normals is normal, the model is unchanged from usual
> OLS.
>
> With kinship that symmetry breaks, and observation-level random
> effects are identifiable.
>
> .I am currently using R to do such genetics models to do association
> .mapping. I ask to other people that have done that before me and if I
> .understand well, no packages allows to specify such a variance/covariance
> .matrix for a random effect except ASREML.
>
> You can also use MCMCglmm and R-INLA.
>
> Ryan King
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Bryan.Danson at MyFWC.com  Mon Mar 19 16:50:21 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Mon, 19 Mar 2012 11:50:21 -0400
Subject: [R-sig-ME] (no subject)
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAA4EF692@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/1ad0884e/attachment-0001.pl>

From joerg.luedicke at gmail.com  Mon Mar 19 18:22:48 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Mon, 19 Mar 2012 10:22:48 -0700
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
	<loom.20120319T023745-978@post.gmane.org>
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>
Message-ID: <CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>

Hi Ben and Fredrik,

Thanks for the comments and the proof! Next time I will be less hasty
in responding...

Cheers,

Joerg

On Mon, Mar 19, 2012 at 3:09 AM, Fredrik Nilsson <laf.nilsson at gmail.com> wrote:
> Joerg,
>
> What is the point in the Poisson model in that way (assuming
> log(total) as offset)? This would be a binomial model; if you observe
> N events from a Poisson distribution of which X are successes (or
> marked in some way) with probability p, then X will be binomial(p, N).
>
> Best regards,
> Fredrik Nilsson
>
> PS. Here's a practical "proof", the real is sketched below.
> invlogit<-function(x) exp(x)/(1+exp(x))
> n<-10
> nn<-ceiling(exp(rnorm(n)+3))
> pp<-seq(0.25,.75,length=n)
> ca<-rbinom(rep(1,n),nn,prob=pp)
> co<-nn-ca
> fa<-gl(n,1)
>
> #binomial model
> test.glm<-glm(cbind(ca,co)~fa-1, family=binomial)
> #conditional poisson
> ptest.glm<-glm(ca~fa-1+offset(log(nn)), family=poisson)
> summary(ptest.glm)
> exp(coef(ptest.glm))
> invlogit(coef(test.glm))
>
> all.equal(exp(coef(ptest.glm)), invlogit(coef(test.glm)))
>
> # proof.
> X~Poisson(a) and ?Y~Poisson(b), X & Y independent -> X+Y~Poisson(a+b)
> (e.g. by generating functions).
>
> Prob(X=x| X+Y=n) = Prob(X=x, Y=n-x)/Prob(X+Y=n) =
> Prob(X=x)*Prob(Y=n-x)/Prob(X+Y=n) = a^x/x! exp(a) b^(n-x)/(n-x)!
> exp(b) /((a+b)^n/n! exp(a+b)) =
> n!/x!/(n-x)! (a/(a+b))^x (b/(a+b))^(n-x) = n!/x!/(n-x)! (a/(a+b))^x
> (1-a/(a+b))^(n-x) , i.e. binomial(x,n,p) with p=a/(a+b).
>
>
> 2012/3/19 Ben Bolker <bbolker at gmail.com>:
>> Joerg Luedicke <joerg.luedicke at ...> writes:
>>
>>> I would certainly check out a Poisson model with the number of
>>> successes as outcome and successes+failures as an offset.
>>
>> ?That seems odd to me; the Poisson+offset model
>> should be appropriate when p<<1 (i.e. for very small p,
>> the Poisson variance mu=n*p is approximately the same as
>> the binomial variance n*p*(1-p); in this case p is not small.
>>
>> ?Of course, I could be wrong.
>>
>>>
>>> On Sun, Mar 18, 2012 at 11:51 AM, Rolf Turner <r.turner at ...> wrote:
>>> > On 19/03/12 07:10, Ben Bolker wrote:
>>> >
>>> > <SNIP>
>>> >
>>> >
>>> >>> head(dat)
>>> >>> ? successes failures id sex subdist
>>> >>> 1 ? ? ? 560 ? ? ?726 ?1 ? F ? ? ? 4
>>> >>> 2 ? ? ? 844 ? ? ?510 ?1 ? M ? ? ? 4
>>
>> ?[snip]
>>
>>> >>>
>>> >>> In community #1, which is in subdistrict #4, there are 560 women
>>> >>
>>> >> ? you mean 510, right?
>>> >
>>> > <SNIP>
>>> >
>>> > Sure looks like 560 to me. ?Time for a trek to the optometrist, Ben?
>>
>> ?Looked at the wrong line (failures in men rather than successes in women).
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From slu at ccsr.uchicago.edu  Mon Mar 19 18:25:59 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 19 Mar 2012 12:25:59 -0500
Subject: [R-sig-ME] Unacceptibly high autocorrelation in MCMCglmm
In-Reply-To: <20120317102916.64036j23f48cdugw@www.staffmail.ed.ac.uk>
References: <1331937495.455.18.camel@localhost>
	<20120317102916.64036j23f48cdugw@www.staffmail.ed.ac.uk>
Message-ID: <1332177959.25409.13.camel@localhost>

On Sat, 2012-03-17 at 10:29 +0000, Jarrod Hadfield wrote:
> HI,
> 
> It looks like the probit has underflowed/overflowed - you can check  
> this by saving the latent variables and looking to see whether the  
> range of the absolute values exceeds 7 (See Section 8.08 of  
> CourseNotes).
> 
> This can happen with weak priors and (near) complete separation and/or  
> with weak priors for effects that are heavily confounded.
> 
> I'm not sure how to proceed with underflow/overflow problems  
> generally.  I could terminate the procedure, or I could truncate the  
> latent variables at their overflow/underflow points. The latter is  
> used by some WinBUGS users, but then WinBUGS handles the fact that the  
> response is from a truncated normal not a normal - something which  
> would be hard to program in MCMCglmm. Any thoughts would be useful.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> Quoting Stuart Luppescu <slu at ccsr.uchicago.edu> on Fri, 16 Mar 2012  
> 17:38:15 -0500:
> 
> > Hello, I'm running this ordered category outcome model:
> >
> > glme5.very.len <- MCMCglmm(very.len.summative.o ~ 1 ,
> >                    prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
> > nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0) )),
> >                    random = ~emplid + deptid + grade.f + subject.f ,
> >                    family = "ordinal",
> >                    nitt=300000,
> >                    data = summative.ratings.prin.yr1.full)

Hi Jarrod, I think I've figured out why this is not working. I hope you
or someone can suggest a fix.

I am analyzing ratings data of observations of teacher performance.
Teachers are rated on more than one occasion on a 1-4 scale on 10
components. The object is to calculate the ICC as a measure of
interrater reliablility (the percent of total variance attributed to
differences in teacher performance = variance in emplid/total variance).
This analysis worked perfectly
fine using MCMCglmm with the 10 components as fixed effects.

What I'm doing now (which is NOT working) is calculating one single
summative rating per teacher based on combinations of all the component
ratings a teacher received in a year. That means only one datum per
teacher per year: no separate components and no multiple observations.
So, including the teacher ID (emplid) as a random effect will screw
things up because there is only one datum per teacher and no
within-teacher variance. 

Do you have any idea how to get around this problem?

Thank you very much for your help.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
Please do think hard before you tell other people
 what they 'should' do for you.    -- Brian D.
 Ripley       R-devel (January 2006)



From bbolker at gmail.com  Mon Mar 19 19:50:24 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2012 18:50:24 +0000 (UTC)
Subject: [R-sig-ME] modelling proportions, with aggregated data,
	and the new/old lme4
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
	<loom.20120319T023745-978@post.gmane.org>
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>
	<CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>
Message-ID: <loom.20120319T194724-653@post.gmane.org>

Joerg Luedicke <joerg.luedicke at ...> writes:

> 
> Hi Ben and Fredrik,
> 
> Thanks for the comments and the proof! Next time I will be less hasty
> in responding...
> 
> Cheers,
> 
> Joerg

   Don't forget that I was wrong too (I forgot about the conditioning). 
 I know that this (i.e. using the Poisson model with an offset to
model binomial data) is a common practice, maybe it was done in the past for
computational reasons?

library("fortunes")
fortune("great-great grandchildren")

  cheers
    Ben



From bbolker at gmail.com  Mon Mar 19 20:15:35 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2012 19:15:35 +0000 (UTC)
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
Message-ID: <loom.20120319T195110-259@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> 
> Hi,
> 
> I am trying to use a multivariate mixed effects linear model to
> examine mediation.  This works fine.  The final step is to compute the
> indirect effect and its standard error.  The indirect effect is easy
> (product of coefficients plus their covariance).  For the standard
> error, I need the gradient (D) and the hessian (H):
> the variance is then:
> 
> D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}
> 
> This is all given in the Appendix of
> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
> 
> Is there a way to get this out of a mer class object?  Looking at
> class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$.  @V
> seems like it would give me the gradient but is null for a basic lmer
> model.

  If you're willing to try out the development version (i.e., lme4
from r-forge), I think you can do this as follows:

fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm1Fun <- update(fm1,devFunOnly=TRUE)
library(numDeriv)
fm1_thpar <- getME(fm1,"theta")
h <- hessian(fm1Fun,fm1_thpar)

  and similarly for the gradient.

  Let me know how it goes.

  Ben Bolker



From tom.gijssels at gmail.com  Mon Mar 19 20:25:08 2012
From: tom.gijssels at gmail.com (Tom Gijssels)
Date: Mon, 19 Mar 2012 15:25:08 -0400
Subject: [R-sig-ME] Conflicting p-values from pvals.fnc
Message-ID: <CAPB_MR1-ZZHD93Vya_Mg_60HppF5Sg3rSma_1cS3KjqHd3mwHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/b68636a2/attachment-0001.pl>

From Bryan.Danson at MyFWC.com  Mon Mar 19 21:06:57 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Mon, 19 Mar 2012 16:06:57 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/b28f4b28/attachment-0001.pl>

From thomas.merkling at cict.fr  Mon Mar 19 21:16:22 2012
From: thomas.merkling at cict.fr (Thomas Merkling)
Date: Mon, 19 Mar 2012 21:16:22 +0100
Subject: [R-sig-ME] Wald tests GLMM with glmer
Message-ID: <4F679416.4070808@cict.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/e485a5cd/attachment-0001.pl>

From bbolker at gmail.com  Mon Mar 19 22:18:11 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2012 21:18:11 +0000 (UTC)
Subject: [R-sig-ME] glmm with a tweedie distribution
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>
Message-ID: <loom.20120319T221655-53@post.gmane.org>

Danson, Bryan <Bryan.Danson at ...> writes:

> 
> Is there a way to run a GLMM with a tweedie distribution?
> 

  Yes, using the 'cplm' package.  I expanded the section on
ZIGLMMs on http://glmm.wikidot.com/faq to include a bit more
stuff on ZIGLMMs, including a bit on ZIGLMMs with a continuous
response for the non-zero data.

  Ben



From lemoine.nathan at gmail.com  Mon Mar 19 22:31:59 2012
From: lemoine.nathan at gmail.com (Nathan Lemoine)
Date: Mon, 19 Mar 2012 17:31:59 -0400
Subject: [R-sig-ME] repeated measures: lme(r) vs manova
Message-ID: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>

Hi all,
Sorry in advance for the length of this post, but I've searched around and couldn't find anything that addressed this issue:

I recently ran into the issue of deciding on the appropriate way to analyze a repeated measures design. We enriched quadrats to measure productivity and we monitored them for three years. Four quadrats were nested within plots. Here are the data:

"plot" "quad" "nut" "t1" "t3" "t4"
"1" 1 "A" "nut" 17.69130435 70.4 57.8
"2" 1 "A" "no nut" 65.4173913 125.8 109.9
"3" 1 "B" "nut" 19.56521739 103.2 100.8
"4" 1 "B" "no nut" 89.03636364 131.3 99.1
"5" 1 "C" "nut" 29.88723404 25.7 29.9
"6" 1 "C" "no nut" 45.45454545 113.1 110.6
"7" 1 "D" "nut" 18.28181818 60.9 67.7
"8" 1 "D" "no nut" 68.88888889 136 95
"9" 2 "A" "nut" 35.41666667 61.6 16
"10" 2 "A" "no nut" 40.90909091 59.4 64.7
"11" 2 "B" "nut" 34.14255319 26.7 23.1
"12" 2 "B" "no nut" 36.27021277 71.6 47.2
"13" 2 "C" "nut" 13.33333333 20.9 26.4
"14" 2 "C" "no nut" 7.118181818 31.2 19.1
"15" 2 "D" "nut" 20 30.9 27.8
"16" 2 "D" "no nut" 19.34893617 31.3 16.7
"17" 3 "A" "nut" 22.22222222 130.7 163.6
"18" 3 "A" "no nut" 32.90869565 83.8 86.2
"19" 3 "B" "nut" 38.29787234 99 110.1
"20" 3 "B" "no nut" 38.83636364 127.1 115.2
"21" 3 "C" "nut" 38.88888889 81.7 193.7
"22" 3 "C" "no nut" 28.98888889 72.1 103.8
"23" 3 "D" "nut" 50 111.3 117.7
"24" 3 "D" "no nut" 26.86666667 94.2 113
"25" 4 "A" "nut" 63.63636364 128.4 114.8
"26" 4 "A" "no nut" 108.8956522 121 80.7
"27" 4 "B" "nut" 104.4444444 146.5 102.2
"28" 4 "B" "no nut" 84.74444444 111.5 109.9
"29" 4 "C" "nut" 71.31111111 86.2 118.4
"30" 4 "C" "no nut" 115.9555556 131.4 141.9
"31" 4 "D" "nut" 75.65555556 141.5 92.5
"32" 4 "D" "no nut" 108.9888889 146.6 122.2
"33" 5 "A" "nut" 20.2 57.4 14.6
"34" 5 "A" "no nut" 12.34489796 55.4 13.4
"35" 5 "B" "nut" 48.98888889 56.3 28.7
"36" 5 "B" "no nut" 35.65555556 55.8 17.6
"37" 5 "C" "nut" 22.22222222 45.9 7.3
"38" 5 "C" "no nut" 9.088888889 55.6 20.5
"39" 5 "D" "nut" 64.44444444 86.1 61.7
"40" 5 "D" "no nut" 15.65555556 75.7 41.8
"41" 6 "A" "nut" 22.22222222 101.1 69.8
"42" 6 "A" "no nut" 53.33333333 171.2 113.5
"43" 6 "B" "nut" 37.87777778 111.1 66.8
"44" 6 "B" "no nut" 46.96666667 120.8 83.8
"45" 6 "C" "nut" 17.87777778 120.7 84
"46" 6 "C" "no nut" 21.21212121 116.3 76.8
"47" 6 "D" "nut" 24.01304348 86.1 64.6
"48" 6 "D" "no nut" 29.51034483 112.5 51.9

The basic question is: When is it appropriate to use a MANOVA-based repeated measures design over a mixed effects model? 

For example, the MANOVA approach:
library(car)
repeated.manova <- lm(cbind(t1,t3,t4)~nut+plot+quad, data=manova.data)
Manova(repeated.manova)

nut is not significant and there are 40 denominator df. 

If I set up the data and run lme:

mixed.dat <- melt(manova.data, id=c("plot","quad","nut"))
colnames(mixed.dat)[4:5] <- c("time","prod")
mixed.dat$time <- as.numeric(mixed.dat$time))

library(nlme)
lme.repeated <- lme(prod~nut, random=~nut|time, data=mixed.dat)
anova(lme.repeated)

Gives 140 denominator df. I'm also not sure this is the appropriate set up for a repeated measures design. Running the following code seems more in line with what I've read to take into account the correlation in observations within the same plot:

lme.repeated2 <- lme(prod~nut*time, random=~time|plot, data=mixed.dat)
anova(lme.repeated2)

This model seems much more appropriate, as observations within plots are now allowed to be correlated, but there is still a huge difference between the MANOVA-based approach and the mixed-effects-based approach, as the mixed-effects model gives me a significant result. The MANOVA assumes that I have three (correlated) observations on 48 independent units, whereas the lme approach assumes that I have 144 observations on correlated units. Also not sure if that interpretation is correct.

Alternatively, I used lmer() for non-nested, multilevel models allowing observations to be correlated in space and time:

repeated.mixed3 <- lmer(prod~nut + (1|plot) + (1|time), data=mixed.dat)
repeated.mixed4 <- lmer(prod~ (1|plot) + (1|time), data=mixed.dat)
anova(repeated.mixed3, repeated.mixed4)

This approach also gives me a significant result. Which of these is the most appropriate? The differences between lme and lmer are trivial (in this case), but the difference between the MANOVA approach and mixed-effects is substantial. I figure the MANOVA approach is probably in correct on account of the nested design, but my question extends to situations when the design is not nested. 

Thanks in advance for your help,

Nathan


 


From billpikounis at gmail.com  Mon Mar 19 22:56:16 2012
From: billpikounis at gmail.com (Bill Pikounis)
Date: Mon, 19 Mar 2012 17:56:16 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <loom.20120319T221655-53@post.gmane.org>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>
	<loom.20120319T221655-53@post.gmane.org>
Message-ID: <CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>

Bryan,
You might also wish to try the glmmPQL function in Venables and
Ripley's MASS package. Someone reported success with it on the SIG-ECO
R list nearly a year ago:

https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html

Hope that helps.

Bill

On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
> Danson, Bryan <Bryan.Danson at ...> writes:
>
>>
>> Is there a way to run a GLMM with a tweedie distribution?
>>
>
> ?Yes, using the 'cplm' package. ?I expanded the section on
> ZIGLMMs on http://glmm.wikidot.com/faq to include a bit more
> stuff on ZIGLMMs, including a bit on ZIGLMMs with a continuous
> response for the non-zero data.
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Yanwei.Zhang at cna.com  Mon Mar 19 23:16:35 2012
From: Yanwei.Zhang at cna.com (Zhang,Yanwei)
Date: Mon, 19 Mar 2012 17:16:35 -0500
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>
	<loom.20120319T221655-53@post.gmane.org>
	<CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
Message-ID: <330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>

One problem with the "glmmPQL" is that the variance function can not be estimated - you need to pre-specify it in an ad hoc way. The "cpglmm" function in the "cplm" package estimates it directly from the data along with other parameters using MLE. But of course, you can use glmmPQL to generate starting values that are fed to cpglmm.   

Regards, 
Wayne 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bill Pikounis
Sent: Monday, March 19, 2012 4:56 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

Bryan,
You might also wish to try the glmmPQL function in Venables and
Ripley's MASS package. Someone reported success with it on the SIG-ECO
R list nearly a year ago:

https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html

Hope that helps.

Bill

On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
> Danson, Bryan <Bryan.Danson at ...> writes:
>
>>
>> Is there a way to run a GLMM with a tweedie distribution?
>>
>
> ?Yes, using the 'cplm' package. ?I expanded the section on
> ZIGLMMs on http://glmm.wikidot.com/faq to include a bit more
> stuff on ZIGLMMs, including a bit on ZIGLMMs with a continuous
> response for the non-zero data.
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.



From billpikounis at gmail.com  Mon Mar 19 23:18:16 2012
From: billpikounis at gmail.com (Bill Pikounis)
Date: Mon, 19 Mar 2012 18:18:16 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>
	<loom.20120319T221655-53@post.gmane.org>
	<CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
Message-ID: <CADY6hMU1EWD6TsvJ=7Pvu-Rgfehywgg0ZnwBUZm4G81cimQuzA@mail.gmail.com>

And I overlooked that Ben Bolker was part of that sig-eco thread and
was the one who reported the success... Sorry for my lack of
attribution, Ben....

Bill

On Mon, Mar 19, 2012 at 17:56, Bill Pikounis <billpikounis at gmail.com> wrote:
> Bryan,
> You might also wish to try the glmmPQL function in Venables and
> Ripley's MASS package. Someone reported success with it on the SIG-ECO
> R list nearly a year ago:
>
> https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html
>
> Hope that helps.
>
> Bill
>
> On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
>> Danson, Bryan <Bryan.Danson at ...> writes:
>>
>>>
>>> Is there a way to run a GLMM with a tweedie distribution?
>>>
>>
>> ?Yes, using the 'cplm' package. ?I expanded the section on
>> ZIGLMMs on http://glmm.wikidot.com/faq to include a bit more
>> stuff on ZIGLMMs, including a bit on ZIGLMMs with a continuous
>> response for the non-zero data.
>>
>> ?Ben
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rroa at azti.es  Tue Mar 20 08:34:59 2012
From: rroa at azti.es (=?iso-8859-1?Q?Rub=E9n_Roa?=)
Date: Tue, 20 Mar 2012 08:34:59 +0100
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us><loom.20120319T221655-53@post.gmane.org><CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>
Message-ID: <5CD78996B8F8844D963C875D3159B94A034B7493@DSRCORREO.azti.local>

I wouldn't call it ad hoc. The power parameter p in the variance function that defines the Tweedie family of exponential distributions, v(mu)=phi*mu^p, can be estimated via profile likelihood, and then the maximum profile likelihood estimate of the p parameter can be inserted in the glmm, essentially estimating the glmm by an estimated likelihood. So there are two stages of approximation but the approximation methods are not ad hoc, they are pretty much mainstream approximation methods to complex likelihoods. Here is a pseudo code using the tweedie package and glmmPQL from MASS (plus msm). For a published application you can see Tascheri, Saavedra-Nievas, Roa-Ureta. 2010. Statistical models to standardize catch rates in the multi-species trawl fishery for Patagonian grenadier (Macruronus magellanicus) off Southern Chile. Fisheries Research 105:200-214.

HTH

Ruben

--
Dr. Ruben H. Roa-Ureta
Senior Researcher, AZTI Tecnalia,
Marine Research Division,
Txatxarramendi Ugartea z/g, 48395, Sukarrieta,
Bizkaia, Spain

##################################  Tweedie ####################################
#estimating variance power parameter

#libraries

library(tweedie)

library(MASS)

library(msm)

MyCaseStudy.Tweedie.prof <- tweedie.profile(MyResponseVar ~ log(Y) + log(Z) + ... + Factor1 + Factor2 + ... ,
p.vec=seq(1.0,2.0,by=0.1), data=MyData, link.power=0, fit.glm=FALSE, do.smooth=TRUE, do.plot=TRUE,
method="inversion",conf.level=0.95, phi.method= "mle",verbose=TRUE)

#distributional plot

y <- rtweedie(1000, p= MyCaseStudy.Tweedie.prof $p.max, mu=1, phi= MyCaseStudy.Tweedie.prof $phi.max)
tweedie.plot(seq(0, max(y), length=100), mu=mean(y), p= MyCaseStudy.Tweedie.prof $p.max, phi= MyCaseStudy.Tweedie.prof $phi.max)

#fitting the glmm
MyCaseStudy..Tweedie.mix <- glmmPQL(fixed = MyResponseVar ~ log(Y) + log(Z) + ... + Factor1 + Factor2 + ... ,
random = list(~1|RE), family=tweedie(var.power = MyCaseStudy.Tweedie.prof$p.max, link.power=0), data= MyData)

MyCaseStudy.Tweedie.mix.sum  <- summary(MyCaseStudy.Tweedie.mix)

#estimated covariance of estimates of a subset of coefficients, [3:11]

MyCaseStudy.Tweedie.mix.year.cov <- round(deltamethod(g=list(~exp(x1),~exp(x2),~exp(x3),~exp(x4),~exp(x5),
~exp(x6),~exp(x7),~exp(x8),~exp(x9)), mean= MyCaseStudy.Tweedie.mix.sum$coef$fixed[3:11], cov=vcov(MyCaseStudy.Tweedie.mix)[3:11,3:11],
ses=FALSE),5)

MyCaseStudy.Tweedie.mix.year.se  <- sqrt(diag(MyCaseStudy.Tweedie.mix.year.cov))

MyCaseStudy.Tweedie.mix.year.cor <- cov2cor(MyCaseStudy.Tweedie.mix.year.cov)

-----Mensaje original-----
De: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Zhang,Yanwei
Enviado el: lunes, 19 de marzo de 2012 23:17
Para: Bill Pikounis; r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] glmm with a tweedie distribution

One problem with the "glmmPQL" is that the variance function can not be estimated - you need to pre-specify it in an ad hoc way. The "cpglmm" function in the "cplm" package estimates it directly from the data along with other parameters using MLE. But of course, you can use glmmPQL to generate starting values that are fed to cpglmm.   

Regards,
Wayne 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bill Pikounis
Sent: Monday, March 19, 2012 4:56 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

Bryan,
You might also wish to try the glmmPQL function in Venables and Ripley's MASS package. Someone reported success with it on the SIG-ECO R list nearly a year ago:

https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html

Hope that helps.

Bill

On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
> Danson, Bryan <Bryan.Danson at ...> writes:
>
>>
>> Is there a way to run a GLMM with a tweedie distribution?
>>
>
> ?Yes, using the 'cplm' package. ?I expanded the section on ZIGLMMs on 
> http://glmm.wikidot.com/faq to include a bit more stuff on ZIGLMMs, 
> including a bit on ZIGLMMs with a continuous response for the non-zero 
> data.
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From m.fairbrother at bristol.ac.uk  Tue Mar 20 10:58:34 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 20 Mar 2012 09:58:34 +0000
Subject: [R-sig-ME] Wald tests GLMM with glmer
In-Reply-To: <mailman.4085.1332195502.4502.r-sig-mixed-models@r-project.org>
References: <mailman.4085.1332195502.4502.r-sig-mixed-models@r-project.org>
Message-ID: <3CC49BDD-F0B9-44EF-9C34-81364164404A@bristol.ac.uk>

Dear Thomas,

There are others on this list who are more knowledgeable than me, but I can suggest a couple things:


> I couldn't use mcmcsamp function neither mcsamp function. What are the other possibilities ?

With the new lme4, try:
? bootMer


> Finally, I tried to use MCMCglmm package, despite my poor familiarity 
> with these techniques (maybe a mistake). When specifying 
> family="categorical" (as my response variable is binary) the plot of the 
> traces were really bad , while there were really better with 
> family="gaussian". Does it make any sense ? Not really to me ...
> Moreover, I also have a problem with one of the 2 random effects (traces 
> stucked at zero). It has only 5 levels and I think I read that there 
> might some problems with random effects with few levels.

Five levels is not enough. In most instances, I think, you need at least 20, and ideally more than that. Though it depends on the context, and to some extent who you ask.


> How to deal with this kind of problem ?

Could you turn this random classification into a series of fixed effects, using dummy variables?

Hope that's useful.
- Malcolm



From bbolker at gmail.com  Tue Mar 20 16:01:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 20 Mar 2012 15:01:44 +0000 (UTC)
Subject: [R-sig-ME] glmm with a tweedie distribution
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us><loom.20120319T221655-53@post.gmane.org><CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>
	<5CD78996B8F8844D963C875D3159B94A034B7493@DSRCORREO.azti.local>
Message-ID: <loom.20120320T154531-578@post.gmane.org>

Rub?n Roa <rroa at ...> writes:

>  I wouldn't call it ad hoc. The power parameter p in the variance
> function that defines the Tweedie family of exponential
> distributions, v(mu)=phi*mu^p, can be estimated via profile
> likelihood, and then the maximum profile likelihood estimate of the
> p parameter can be inserted in the glmm, essentially estimating the
> glmm by an estimated likelihood. So there are two stages of
> approximation but the approximation methods are not ad hoc, they are
> pretty much mainstream approximation methods to complex
> likelihoods. Here is a pseudo code using the tweedie package and
> glmmPQL from MASS (plus msm). For a published application you can
> see Tascheri, Saavedra-Nievas, Roa-Ureta. 2010. Statistical models
> to standardize catch rates in the multi-species trawl fishery for
> Patagonian grenadier (Macruronus magellanicus) off Southern
> Chile. Fisheries Research 105:200-214.

  For what it's worth, the upcoming/development version of 
lme4 (now on R-forge) should work with custom family arguments,
so this approach *should* be possible with glmer as well as
glmmPQL ... (but I would also definitely give a thumbs-up
to cplm, which looks quite powerful).

  Anyone who wants to do some http://glmm.wikidot.com/faq - editing
is welcome ...



From Bryan.Danson at MyFWC.com  Tue Mar 20 17:00:08 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Tue, 20 Mar 2012 12:00:08 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAA4EF87F@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120320/f0203932/attachment-0001.pl>

From schmettow at web.de  Tue Mar 20 17:32:35 2012
From: schmettow at web.de (Martin Schmettow)
Date: Tue, 20 Mar 2012 17:32:35 +0100
Subject: [R-sig-ME] repeated measures: lme(r) vs manova
In-Reply-To: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>
References: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>
Message-ID: <008301cd06b7$0e79af50$2b6d0df0$@web.de>

Hi Nathan,

Here is a nice simulation study comparing LME to MANOVA and several other
traditional methods (I hope you don't mind the interdisciplinary transfer):
Gueorguieva, R., & Krystal, J. H. (2004). Move Over ANOVA. Archives of
General Psychiatry, 61, 310-317.

The bottom line: In longitudinal designs, LME has better power in presence
of missing values.

CU, Martin



> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Nathan Lemoine
> Sent: Monday, March 19, 2012 10:32 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] repeated measures: lme(r) vs manova
> 
> Hi all,
> Sorry in advance for the length of this post, but I've searched around and
> couldn't find anything that addressed this issue:
> 
> I recently ran into the issue of deciding on the appropriate way to
analyze a
> repeated measures design. We enriched quadrats to measure productivity
> and we monitored them for three years. Four quadrats were nested within
> plots. Here are the data:
> 
> "plot" "quad" "nut" "t1" "t3" "t4"
> "1" 1 "A" "nut" 17.69130435 70.4 57.8
> "2" 1 "A" "no nut" 65.4173913 125.8 109.9 "3" 1 "B" "nut" 19.56521739
103.2
> 100.8 "4" 1 "B" "no nut" 89.03636364 131.3 99.1 "5" 1 "C" "nut"
29.88723404
> 25.7 29.9 "6" 1 "C" "no nut" 45.45454545 113.1 110.6 "7" 1 "D" "nut"
> 18.28181818 60.9 67.7 "8" 1 "D" "no nut" 68.88888889 136 95 "9" 2 "A"
"nut"
> 35.41666667 61.6 16 "10" 2 "A" "no nut" 40.90909091 59.4 64.7 "11" 2 "B"
"nut"
> 34.14255319 26.7 23.1 "12" 2 "B" "no nut" 36.27021277 71.6 47.2 "13" 2 "C"
> "nut" 13.33333333 20.9 26.4 "14" 2 "C" "no nut" 7.118181818 31.2 19.1 "15"
2
> "D" "nut" 20 30.9 27.8 "16" 2 "D" "no nut" 19.34893617 31.3 16.7 "17" 3
"A"
> "nut" 22.22222222 130.7 163.6 "18" 3 "A" "no nut" 32.90869565 83.8 86.2
"19" 3
> "B" "nut" 38.29787234 99 110.1 "20" 3 "B" "no nut" 38.83636364 127.1 115.2
> "21" 3 "C" "nut" 38.88888889 81.7 193.7 "22" 3 "C" "no nut" 28.98888889
72.1
> 103.8 "23" 3 "D" "nut" 50 111.3 117.7 "24" 3 "D" "no nut" 26.86666667 94.2
113
> "25" 4 "A" "nut" 63.63636364 128.4 114.8 "26" 4 "A" "no nut" 108.8956522
121
> 80.7 "27" 4 "B" "nut" 104.4444444 146.5 102.2 "28" 4 "B" "no nut"
84.74444444
> 111.5 109.9 "29" 4 "C" "nut" 71.31111111 86.2 118.4 "30" 4 "C" "no nut"
> 115.9555556 131.4 141.9 "31" 4 "D" "nut" 75.65555556 141.5 92.5 "32" 4 "D"
> "no nut" 108.9888889 146.6 122.2 "33" 5 "A" "nut" 20.2 57.4 14.6 "34" 5
"A" "no
> nut" 12.34489796 55.4 13.4 "35" 5 "B" "nut" 48.98888889 56.3 28.7 "36" 5
"B"
> "no nut" 35.65555556 55.8 17.6 "37" 5 "C" "nut" 22.22222222 45.9 7.3 "38"
5
> "C" "no nut" 9.088888889 55.6 20.5 "39" 5 "D" "nut" 64.44444444 86.1 61.7
"40"
> 5 "D" "no nut" 15.65555556 75.7 41.8 "41" 6 "A" "nut" 22.22222222 101.1
69.8
> "42" 6 "A" "no nut" 53.33333333 171.2 113.5 "43" 6 "B" "nut" 37.87777778
> 111.1 66.8 "44" 6 "B" "no nut" 46.96666667 120.8 83.8 "45" 6 "C" "nut"
> 17.87777778 120.7 84 "46" 6 "C" "no nut" 21.21212121 116.3 76.8 "47" 6 "D"
> "nut" 24.01304348 86.1 64.6 "48" 6 "D" "no nut" 29.51034483 112.5 51.9
> 
> The basic question is: When is it appropriate to use a MANOVA-based
> repeated measures design over a mixed effects model?
> 
> For example, the MANOVA approach:
> library(car)
> repeated.manova <- lm(cbind(t1,t3,t4)~nut+plot+quad, data=manova.data)
> Manova(repeated.manova)
> 
> nut is not significant and there are 40 denominator df.
> 
> If I set up the data and run lme:
> 
> mixed.dat <- melt(manova.data, id=c("plot","quad","nut"))
> colnames(mixed.dat)[4:5] <- c("time","prod") mixed.dat$time <-
> as.numeric(mixed.dat$time))
> 
> library(nlme)
> lme.repeated <- lme(prod~nut, random=~nut|time, data=mixed.dat)
> anova(lme.repeated)
> 
> Gives 140 denominator df. I'm also not sure this is the appropriate set up
for
> a repeated measures design. Running the following code seems more in line
> with what I've read to take into account the correlation in observations
> within the same plot:
> 
> lme.repeated2 <- lme(prod~nut*time, random=~time|plot,
> data=mixed.dat)
> anova(lme.repeated2)
> 
> This model seems much more appropriate, as observations within plots are
> now allowed to be correlated, but there is still a huge difference between
> the MANOVA-based approach and the mixed-effects-based approach, as
> the mixed-effects model gives me a significant result. The MANOVA assumes
> that I have three (correlated) observations on 48 independent units,
> whereas the lme approach assumes that I have 144 observations on
> correlated units. Also not sure if that interpretation is correct.
> 
> Alternatively, I used lmer() for non-nested, multilevel models allowing
> observations to be correlated in space and time:
> 
> repeated.mixed3 <- lmer(prod~nut + (1|plot) + (1|time), data=mixed.dat)
> repeated.mixed4 <- lmer(prod~ (1|plot) + (1|time), data=mixed.dat)
> anova(repeated.mixed3, repeated.mixed4)
> 
> This approach also gives me a significant result. Which of these is the
most
> appropriate? The differences between lme and lmer are trivial (in this
case),
> but the difference between the MANOVA approach and mixed-effects is
> substantial. I figure the MANOVA approach is probably in correct on
account
> of the nested design, but my question extends to situations when the
design
> is not nested.
> 
> Thanks in advance for your help,
> 
> Nathan
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From thomas.merkling at cict.fr  Tue Mar 20 19:32:11 2012
From: thomas.merkling at cict.fr (Thomas Merkling)
Date: Tue, 20 Mar 2012 19:32:11 +0100
Subject: [R-sig-ME] Anova/deviance table in glmmADMB
Message-ID: <4F68CD2B.9020104@cict.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120320/45ddbe3a/attachment-0001.pl>

From jfox at mcmaster.ca  Tue Mar 20 19:45:52 2012
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 20 Mar 2012 14:45:52 -0400
Subject: [R-sig-ME] Anova/deviance table in glmmADMB
In-Reply-To: <4F68CD2B.9020104@cict.fr>
References: <4F68CD2B.9020104@cict.fr>
Message-ID: <web-398921101@cgpsrv2.cis.mcmaster.ca>

Dear Thomas,

The Anova() function in the car package doesn't have a specific method for objects produced by glmmADMB() (with which I'm unfamiliar). If there are coef() and vcov() methods for those objects, then the default Anova() method should produce Wald tests.

Best,
 John

------------------------------------------------
John Fox
Sen. William McMaster Prof. of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/

On Tue, 20 Mar 2012 19:32:11 +0100
 Thomas Merkling <thomas.merkling at cict.fr> wrote:
> Dear Ben and other list members,
> 
> - Is there any way to produce a Anova/deviance table for a model fitted 
> with glmmADMB ? I used the Anova() function from the car library for 
> glmer models, but it does not seem to work with glmmadmb (I'm using 
> glmmADMB 0.7) and I would like only one p-value for each term and 
> interaction and NOT one p-value for each level of the interaction.
> 
> - I also tried to compare nested models via LRT using 
> anova(model1,model2) for glmmADMB models but I didn't get any p-values, 
> it produced NaN, although it apparently calculate the differences in 
> likelihood. Where can this come from ?
> 
> - I tried to use the coefplot2 library (downloaded from 
> http://www.math.mcmaster.ca/bolker/R/src/contrib) as showed on the 
> glmmADMB home page ("getting started with glmmADMB"), but I couldn't use 
> it and got this error message : unable to find an inherited method for 
> function "coefplot2", for signature "glmmadmb". Is it normal ?
> It worked fine with glmer output.
> 
>   Thanks for your help !
> Thomas
> -- 
> ****NEW ADDRESS AND PHONE NUMBER ****
> 
> Thomas Merkling, Doctorant (PhD Student)
> Web Page <http://www.edb.ups-tlse.fr/Merkling-Thomas.html>
> 
> Laboratoire "Evolution et Diversit? Biologique" -EDB
> UMR 5174 - b?t 4R1 - bureau 33 RDC
> 
> Universit? Paul Sabatier Toulouse 3
> 118, route de Narbonne
> 31062 TOULOUSE Cedex O9, FRANCE
> 
> T?l: 33 5-61-55-67-56
> Fax: 33 5-61-55-73-27
> 
> 	[[alternative HTML version deleted]]
>



From bbolker at gmail.com  Tue Mar 20 22:43:30 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 20 Mar 2012 17:43:30 -0400
Subject: [R-sig-ME] Anova/deviance table in glmmADMB
In-Reply-To: <4F68CD2B.9020104@cict.fr>
References: <4F68CD2B.9020104@cict.fr>
Message-ID: <4F68FA02.60100@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12-03-20 02:32 PM, Thomas Merkling wrote:
> Dear Ben and other list members,
> 
> - Is there any way to produce a Anova/deviance table for a model
> fitted with glmmADMB ? I used the Anova() function from the car
> library for glmer models, but it does not seem to work with
> glmmadmb (I'm using glmmADMB 0.7) and I would like only one p-value
> for each term and interaction and NOT one p-value for each level of
> the interaction.

  Hmmm.

  car::Anova() should work now -- I had to add a model.frame() and a
df.residual() method for glmmadmb objects.  (The df.residual number
may be a little dodgy -- I'm not sure I counted the parameters right
- -- but I don't think it's actually used for much by default, cause you
get Wald chi-square tests)

  The newest version of glmmADMB is 0.7.5.1 -- it may take a little
while for r-forge to catch up, and I was having a few dependency
issues.  If you don't see it there in ~ 24 hours, drop me a line.

> 
> - I also tried to compare nested models via LRT using 
> anova(model1,model2) for glmmADMB models but I didn't get any
> p-values, it produced NaN, although it apparently calculate the
> differences in likelihood. Where can this come from ?

  This ought to have worked: perhaps you had the models in the wrong
order?

> 
> - I tried to use the coefplot2 library (downloaded from 
> http://www.math.mcmaster.ca/bolker/R/src/contrib) as showed on the 
> glmmADMB home page ("getting started with glmmADMB"), but I
> couldn't use it and got this error message : unable to find an
> inherited method for function "coefplot2", for signature
> "glmmadmb". Is it normal ? It worked fine with glmer output.

  Can you try getting it from r-forge?

  Again, if the problem persists let me know.

  Ben

> 
> Thanks for your help ! Thomas

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPaPoCAAoJED2whTVMEyK9qAYIAJZKoj3hh8fdTR7U22I64HhM
SmLeTSCmauRzlQXbgSeKx720UGsJtGUzu9Sw9AHiTKqpGrujOj48balEf1MF3Crk
vkTsdDM7Pp5y36xsqw6Ps122DnDQ30ctYh6IDD0+XJX7BebEK5P9or4xoy1lvbOj
L6STkB3wmCYKtJMhFJkvvmCu/+S4dSzOb148edSuO0WFwIC4+Gax7UtHhoj1vgkm
2Gfz3uHre+1aEh0CantGyFgAYBxEIA0F/5AloWQLCRCtqSIi8eNCS0HBt9hmzxLW
455R8PXJyVmtrRn2fWO8Fa5/Two56WMeQwYV8DenBtydM+bGe0NHTEiirHtvf/g=
=dVAk
-----END PGP SIGNATURE-----



From bbolker at gmail.com  Wed Mar 21 02:59:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 21 Mar 2012 01:59:16 +0000 (UTC)
Subject: [R-sig-ME] glmm with a tweedie distribution
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF87F@FWC-TLEX10.fwc.state.fl.us>
Message-ID: <loom.20120321T025450-751@post.gmane.org>

Danson, Bryan <Bryan.Danson at ...> writes:

> 

[snip]
>  however I received the following warning:
> 
> glm.fit: algorithm did not converge

  This is probably harmless -- it means that an intermediate
GLM step didn't quite work, probably because you have strongly
separated data (i.e. some places/factor combinations
etc. with all-zero or all-one data)
 
> Does anyone have any suggestions on how to address this?  My data is
> fairly simple, a distance measurement for each of several trap types
> on different dates.
 
> Also, I was trying to produce a summary of the model, however I cannot get the
commands to work.  I tried
> summary(model) which returned:

 
> Error in UseMethod("fixef") : no applicable method for 'fixef'
>   applied to an object of class "c('cpglmm', 'mer', 'cplm')"
 
> >From reading through the literature on the "cplm" package, it suggests:
> 
> summary signature(object = "cpglm")
> 

  Can we see the results of sessionInfo()? I suspect you have a
problem with methods from some packages masking others.  If you have
installed lme4 from r-forge, I suspect you should re-install it from
CRAN ...

  Ben



From yvesrousselle at gmail.com  Wed Mar 21 08:14:04 2012
From: yvesrousselle at gmail.com (Yves Rousselle)
Date: Wed, 21 Mar 2012 11:14:04 +0400
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <CALzuZRQinGU4V91bNjiwM44GuY8hWt9=N9vb0oph6t6gvhF2AA@mail.gmail.com>
References: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com>
	<CALzuZRQinGU4V91bNjiwM44GuY8hWt9=N9vb0oph6t6gvhF2AA@mail.gmail.com>
Message-ID: <CAA8=r0D-DV9yZmNrLpJ96pinVmNVtNp+OmkAv8JvzA6mBESf3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/3d65e3d2/attachment-0001.pl>

From David.Duffy at qimr.edu.au  Wed Mar 21 13:42:43 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 21 Mar 2012 22:42:43 +1000 (EST)
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <CAA8=r0D-DV9yZmNrLpJ96pinVmNVtNp+OmkAv8JvzA6mBESf3Q@mail.gmail.com>
References: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com><CALzuZRQinGU4V91bNjiwM44GuY8hWt9=N9vb0oph6t6gvhF2AA@mail.gmail.com>
	<CAA8=r0D-DV9yZmNrLpJ96pinVmNVtNp+OmkAv8JvzA6mBESf3Q@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1203212222390.16033@orpheus.qimr.edu.au>

On Wed, 21 Mar 2012, Yves Rousselle wrote:

> When I was saying that ASREML was the only package allowing something, it
> was not association mapping but the possibility to specify a
> variance/covariance matrix by directly importing the entire matrix (as in
> the example of specifying an external kinship matrix for a genetic effect).
>
> On Wed, Mar 14, 2012 at 8:28 AM, Ryan King <c.ryan.king at gmail.com> wrote:
>>> You can also use MCMCglmm and R-INLA.
>
> Ryan, have you got some links for what you talk about ? I'm quite surprised
> that there are already packages for doing that because a lot of geneticists
> are using ASREML even if they have to pay for it. I really hope that there
> is a good reason for that !

ASREML is pretty quick and robust for large problems.

I am guessing you want to specify a large (nonsparse) empirical kinship 
matrix.  Then lmekin, in the kinship package, is one R package that allows 
you to do this, but it gets slow for large datasets.  I have hypothesized, 
but never got round to trying, that coxme() in the same package could be 
abused to give a binomial GLMM ;).  AnimalINLA allows one to fit 
arbitrary matrices too:

  If not using compute.Ainverse to calculate the precision matrix
  [the inverse relationship matrix], the precision matrix has to be
  on the form sparseMatrix(i = ,j = , x =), the two first (i ,j)
  are the individuals compared in the relationship matrix (remember
  the individual numbers must match in the relationship matrix and
  the individual number in data (genetic)), third list element
  (values) are the precision values (the corresponding element of the
  precision matrix).


The regress package does gaussian mixed models only.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From phedberg at biol.uw.edu.pl  Wed Mar 21 14:07:46 2012
From: phedberg at biol.uw.edu.pl (Petter Hedberg)
Date: Wed, 21 Mar 2012 14:07:46 +0100
Subject: [R-sig-ME] Question regarding lme repeated measures error in case 1,
 but not case 2
Message-ID: <CAO5UtxOwwCf2fdKviZ_Dg0Km=TN1Gf60fR5vPFMF47zywGQTQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/41552a92/attachment-0001.pl>

From phedberg at biol.uw.edu.pl  Wed Mar 21 14:26:38 2012
From: phedberg at biol.uw.edu.pl (Petter Hedberg)
Date: Wed, 21 Mar 2012 14:26:38 +0100
Subject: [R-sig-ME] Question regarding lme mixed model, error in case 1,
	not in case 2
Message-ID: <CAO5UtxMdQE0+rL3HwwN7-gDbQ9wSxTVmO_QExUZoP4UfS2OE9w@mail.gmail.com>

Hi all subscribing to the r-sig-mixed-model list.
I have questions regarding the model I use, weather it makes sense, and why
I receive an error message in case 1 but not in case 2. It is a repeated
measure experiment.

The experiment consists of two fields, that are divided up in stripes were
every 2nd stripe has been treated with hay-transfer and every 2nd is a
control were no hay transfer has been conducted.
In each stripe 2 permanent plots of 2 m x 2 m were placed out, and
vegetation monitored for three years. Due to that there are differences in
elevation between the plot, each plots elevation has been measured.

The Explanatory variables I have is then Year (2009,2010,2011),Treatment
(Hay/No Hay), and (Elevation).
The response variables are % cover of different vegetation groups.
If I take the vegetation group sedges as an example.

Case 1: mydata<-lme(Sedges~as.factor(Year)*Treatment*Elevation) gives me
this error message

"Error in getGroups.data.frame(dataMix, groups) :
  Invalid formula for groups"

If I however include Site Number (There are 2 sites, with identical design)
I don?t get any error message at all.
Including it as a random is in my opinion not wrong, but not necessary for
this experiment.


Case 2:
mydata<-lme(Sedges~as.factor(Year)*Treatment*Elevation,random=~1|SiteNumber)

Would greatly appreciate any help on this issue.

Best regards, Petter Hedberg



From joerg.luedicke at gmail.com  Wed Mar 21 15:37:13 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Wed, 21 Mar 2012 07:37:13 -0700
Subject: [R-sig-ME] Question regarding lme mixed model, error in case 1,
 not in case 2
In-Reply-To: <CAO5UtxMdQE0+rL3HwwN7-gDbQ9wSxTVmO_QExUZoP4UfS2OE9w@mail.gmail.com>
References: <CAO5UtxMdQE0+rL3HwwN7-gDbQ9wSxTVmO_QExUZoP4UfS2OE9w@mail.gmail.com>
Message-ID: <CAEn158TY97H6+3MPQwsYNfJUwX2WUdUJeU3kxkurZoE=txuNdg@mail.gmail.com>

Some thoughts:

1) In "Case 1" you don't specify a random effect and thus your model
would reduce to a simple linear model. I have never tried it but I can
imagine that specifying at least one random effect is required by
-lme-.

2) Did you look at main effects and 2-way interactions first before
including the 3-way interaction effect?

3) With only 2 fields, estimating a random effect will not be very
useful. But what about stripes? I think you should have varying
intercepts and/or slopes across stripes (or at least check if there is
variation across stripes). If you have perfectly balanced data and no
variation across stripes, I would believe you do not really need a
mixed effects model here. But I might very well miss something since I
am not familiar with agricultural research.

4) If your dependent variable is a percentage/ proportion, a linear
model might not be suitable. How are your outcome variables measured
exactly?

J.

On Wed, Mar 21, 2012 at 6:26 AM, Petter Hedberg <phedberg at biol.uw.edu.pl> wrote:
> Hi all subscribing to the r-sig-mixed-model list.
> I have questions regarding the model I use, weather it makes sense, and why
> I receive an error message in case 1 but not in case 2. It is a repeated
> measure experiment.
>
> The experiment consists of two fields, that are divided up in stripes were
> every 2nd stripe has been treated with hay-transfer and every 2nd is a
> control were no hay transfer has been conducted.
> In each stripe 2 permanent plots of 2 m x 2 m were placed out, and
> vegetation monitored for three years. Due to that there are differences in
> elevation between the plot, each plots elevation has been measured.
>
> The Explanatory variables I have is then Year (2009,2010,2011),Treatment
> (Hay/No Hay), and (Elevation).
> The response variables are % cover of different vegetation groups.
> If I take the vegetation group sedges as an example.
>
> Case 1: mydata<-lme(Sedges~as.factor(Year)*Treatment*Elevation) gives me
> this error message
>
> "Error in getGroups.data.frame(dataMix, groups) :
> ?Invalid formula for groups"
>
> If I however include Site Number (There are 2 sites, with identical design)
> I don?t get any error message at all.
> Including it as a random is in my opinion not wrong, but not necessary for
> this experiment.
>
>
> Case 2:
> mydata<-lme(Sedges~as.factor(Year)*Treatment*Elevation,random=~1|SiteNumber)
>
> Would greatly appreciate any help on this issue.
>
> Best regards, Petter Hedberg
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From juan.santos at vi.ieo.es  Wed Mar 21 16:49:45 2012
From: juan.santos at vi.ieo.es (=?iso-8859-1?Q?Juan_Jos=E9_Santos_Blanco?=)
Date: Wed, 21 Mar 2012 16:49:45 +0100
Subject: [R-sig-ME] coefplot2 package not available
References: <mailman.7.1332327602.21459.r-sig-mixed-models@r-project.org>
Message-ID: <CB98987E6A626A42A92C02833553DEF501679802@ieovigo1.vi.ieo.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/2508ec37/attachment-0001.pl>

From raptorbio at hotmail.com  Wed Mar 21 17:06:40 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Wed, 21 Mar 2012 12:06:40 -0400
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <loom.20120319T194724-653@post.gmane.org>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>,
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>,
	<loom.20120318T185026-397@post.gmane.org>,
	<4F662EA2.2090305@auckland.ac.nz>,
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>,
	<loom.20120319T023745-978@post.gmane.org>,
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>,
	<CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>,
	<loom.20120319T194724-653@post.gmane.org>
Message-ID: <BAY170-W46AC47612EE83EB437B6D1A1400@phx.gbl>


Not sure what I'm missing here, but I'm not finding the offset Poisson and binomial to be equal with my dataset.? 

> sessionInfo()

R version 2.14.1 (2011-12-22)

Platform: x86_64-pc-mingw32/x64 (64-bit)



locale:

[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United 
States.1252??? LC_MONETARY=English_United States.1252 
LC_NUMERIC=C????????????????????????? 

[5] LC_TIME=English_United States.1252??? 



attached base packages:

?[1] stats4??? splines?? tcltk???? stats???? graphics? grDevices utils???? datasets? methods?? base???? 



other attached packages:

?[1] lme4_0.999375-42?? bbmle_1.0.4.1????? numDeriv_2010.11-1 
R2admb_0.7.5?????? Hmisc_3.9-1??????? survival_2.36-10?? 
NCStats_0.2-7????? sciplot_1.0-9???? 

?[9] mgcv_1.7-13??????? Matrix_1.0-3?????? lattice_0.20-0???? 
MASS_7.3-16??????? AED_1.0??????????? circular_0.4-3???? 
boot_1.3-4???????? plotrix_3.3-3???? 



loaded via a namespace (and not attached):

?[1] car_2.0-12??????? cluster_1.14.1??? gamm4_0.1-5?????? 
gdata_2.8.2?????? glmmADMB_0.7.2.5? gplots_2.10.1???? grid_2.14.1?????? 
gtools_2.6.2????? multcomp_1.2-9?? 

[10] nlme_3.1-103????? TeachingDemos_2.7 tools_2.14.1???? 

> #
> # Compare offset Poisson with binomial
> invlogit<-function(x) exp(x)/(1+exp(x))
> test <- read.csv("http://dl.dropbox.com/u/23278690/test.csv", header=T)
> b.glm <- glm(cbind(success,total) ~ (a+b+c)^2 - 1, family="binomial", data=test)
> p.glm <- glm(success ~ (a+b+c)^2 - 1 + offset(log(total)), family="poisson", data=test)
> #
> exp(coef(p.glm))
???????? a????????? b????????? c??????? a:b??????? a:c??????? b:c 
0.03225038 0.15195288 1.40174126 3.48192066 1.01892662 0.97212475 
> #
> inv.logit(coef(b.glm))
???????? a????????? b????????? c??????? a:b??????? a:c??????? b:c 
0.03158208 0.13227007 0.58381656 0.77643718 0.50446378 0.49263445 
> #
> all.equal(exp(coef(p.glm)), invlogit(coef(b.glm)))
[1] "Mean relative difference: 0.6428341"

Could it be related to the number of zeros?

Adam Smith
Dept. Natural Resources Science
University of Rhode Island


 		 	   		  


From Bryan.Danson at MyFWC.com  Wed Mar 21 17:08:51 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Wed, 21 Mar 2012 12:08:51 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAB12F7C1@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/b5db4a41/attachment-0001.pl>

From raptorbio at hotmail.com  Wed Mar 21 17:10:39 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Wed, 21 Mar 2012 12:10:39 -0400
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <BAY170-W46AC47612EE83EB437B6D1A1400@phx.gbl>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>,
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>,
	<loom.20120318T185026-397@post.gmane.org>,
	<4F662EA2.2090305@auckland.ac.nz>,
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>,
	<loom.20120319T023745-978@post.gmane.org>,
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>,
	<CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>,
	<loom.20120319T194724-653@post.gmane.org>,
	<BAY170-W46AC47612EE83EB437B6D1A1400@phx.gbl>
Message-ID: <BAY170-W1616B2331C572FEB3907EAA1400@phx.gbl>


Sorry, the binomial model should have read:

b.glm <- glm(cbind(success,total-success) ~ (a+b+c)^2 - 1, family="binomial", data=test)

But the outcome is little changed...

Adam 
 		 	   		  


From c.ryan.king at gmail.com  Wed Mar 21 18:19:44 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Wed, 21 Mar 2012 12:19:44 -0500
Subject: [R-sig-ME] observation level random effects/kinship model
Message-ID: <CAEQ+J25bwdUFmOuHXFTmrAOgGSbqWeJK+hOxBCLaJ9jrdKhRCg@mail.gmail.com>

> Ryan, have you got some links for what you talk about ? I'm quite surprised
> that there are already packages for doing that because a lot of geneticists
> are using ASREML even if they have to pay for it. I really hope that there
> is a good reason for that !

Sorry, I missed this the first time. MCMCglmm allows an arbitrary
correlation matrix for random effects (ginverse options) and has a
built-in for numerator-relatedness-matrix given pedigree. AnimalINLA
also has a built-in for numerator-relatedness-matrix given pedigree.

If that parameterization is awkward/slow, you can also use the
decomposition trick in either.  That is, let K be your matrix, and U
%*% D %*%  t(U) its cholesky factorization. Then you can set the RE
design matrix Z = U %*% sqrt(D) with an identity covariance matrix; in
MCMCglmm that's idv(Z) and in inla a  f( ..., model="z") .

Both these packages rely for speed on Z and or COV(RE) or its inverse
being sparse, so I sometimes play with using the PMA package to
compute a sparse approximate SVD. Presumably an incomplete cholesky
factorization could do the same thing.

ASREML is probably worth the (NIH's) money; my understanding is that
it's fast, flexible, and robust. I don't know if the above have been
designed with very large datasets in mind.

Ryan King



From bbolker at gmail.com  Wed Mar 21 20:28:20 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 21 Mar 2012 15:28:20 -0400
Subject: [R-sig-ME] Anova/deviance table in glmmADMB
In-Reply-To: <4F6A0633.5070809@cict.fr>
References: <4F68CD2B.9020104@cict.fr> <4F68FA02.60100@gmail.com>
	<4F6A0633.5070809@cict.fr>
Message-ID: <4F6A2BD4.7010501@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  [cc'ing to r-sig-mixed-models]

On 12-03-21 12:47 PM, Thomas Merkling wrote:
> 
> 
> Le 20/03/2012 22:43, Ben Bolker a ?crit : On 12-03-20 02:32 PM,
> Thomas Merkling wrote:
>>>> Dear Ben and other list members,
>>>> 
>>>> - Is there any way to produce a Anova/deviance table for a
>>>> model fitted with glmmADMB ? I used the Anova() function from
>>>> the car library for glmer models, but it does not seem to
>>>> work with glmmadmb (I'm using glmmADMB 0.7) and I would like
>>>> only one p-value for each term and interaction and NOT one
>>>> p-value for each level of the interaction.
> Hmmm.
> 
> car::Anova() should work now -- I had to add a model.frame() and a 
> df.residual() method for glmmadmb objects.  (The df.residual
> number may be a little dodgy -- I'm not sure I counted the
> parameters right -- but I don't think it's actually used for much
> by default, cause you get Wald chi-square tests)
> 
> The newest version of glmmADMB is 0.7.5.1 -- it may take a little 
> while for r-forge to catch up, and I was having a few dependency 
> issues.  If you don't see it there in ~ 24 hours, drop me a line.
>> I used glmmADMB 0.7 because some models did not converge with
>> glmmADMB 0.7.2.4 ("function maximizer failed (couldn't find the
>> STD file)")  and I read that with it might work with previous
>> versions ... which was the case .. until today .... Models that
>> were fitted without problem yesterday did not convernge today:
>> "Memory allocation error -- Perhaps you are trying to allocate 
>> too much memory in your program"  and  "function maximizer
>> failed (couldn't find the STD file)"


  Argh.  (That's frustration with software and Murphy's Law, not with
you ...)  What changed between yesterday and today?  You could be
running out of memory simply because you have more large objects
loaded in your R session (or because you're doing something else
memory-intensive on your computer at the same time?), other than that
I don't have a good guess.  If necessary you can squeeze memory a
little bit more by running glmmADMB within R to generate the
appropriate files, running the 'glmmadmb' executable outside of R,
then going back into R to read the results, but I find it very
annoying to work that way.

> 
>> I was never able to download the package via
> 
>> install.packages("glmmADMB", 
>> repos="http://r-forge.r-project.org",type="source")
> 
>> I got a warning :
> 
>> In getDependencies(pkgs, dependencies, available, lib) : package
>> 'glmmADMB' is not available (for R version 2.14.2)
> 
>> And on theR-forge packages page for the glmmADMB project 
>> <https://r-forge.r-project.org/R/?group_id=847>  the build status
>> is "Failed to build" and I never found any source package, but
>> maybe I was not looking at the right place ...
> 

  I am still fighting with R-forge. If necessary I will build some
more recent versions myself and put them up in the other repository space.

>> I will have a look tomorrow if things have changed ...
> 
> 
>>>> - I also tried to compare nested models via LRT using 
>>>> anova(model1,model2) for glmmADMB models but I didn't get
>>>> any p-values, it produced NaN, although it apparently
>>>> calculate the differences in likelihood. Where can this come
>>>> from ?
> This ought to have worked: perhaps you had the models in the wrong 
> order?
>> I think I did it right .... Here is an example
> 
>> modmean=glmmadmb(MeanAggr~Date + Age+ Obs+ 
>> (1|Nest),family="Gamma",data=YESaggr,verbose=FALSE) modmean1=
>> glmmadmb(MeanAggr~Date + Age+ 
>> (1|Nest),family="Gamma",data=YESaggr,verbose=FALSE)
> 
>> anova(modmean,modmean1) Analysis of Variance Table
> 
>> Model 1: MeanAggr ~ Date + Age + Obs Model 2: MeanAggr ~ Date +
>> Age NoPar  LogLik Df  -2logQ P.value 1     9 -726.22 2     5
>> -731.23 -4 -10.012 Message d'avis : In pchisq(q, df, lower.tail,
>> log.p) : production de NaN

  What do you get from anova(modmean1,modmean) ?  In general the
*simpler* model should come first -- in more recent versions of
glmmADMB, the program will rearrange them for you (and warn you).

> 
>> If is specify "test="Chisq"", I got this error message : Erreur
>> dans x$random : $ operator is invalid for atomic vectors

  Yes, in this case glmmADMB is interpreting this argument as another
model you want to consider in the nested sequence.

>>>> - I tried to use the coefplot2 library (downloaded from 
>>>> http://www.math.mcmaster.ca/bolker/R/src/contrib) as showed
>>>> on the glmmADMB home page ("getting started with glmmADMB"),
>>>> but I couldn't use it and got this error message : unable to
>>>> find an inherited method for function "coefplot2", for
>>>> signature "glmmadmb". Is it normal ? It worked fine with
>>>> glmer output.
> Can you try getting it from r-forge?
> 
> Again, if the problem persists let me know.
> 
> Ben
> 
>> on theR-forge packages page for the coefplot2 project 
>> <https://r-forge.r-project.org/R/?group_id=847>  the build status
>> is offline and I got the same error message as for glmmADMB when
>> trying
> 
>> install.packages("coefplot2", 
>> repos="http://r-forge.r-project.org",type="source")
> 

  Double argh.  I will try to get this back up.

 Ben

>> Cheers, Thomas
> 
> 
> 
>>>> Thanks for your help ! Thomas
>> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPaivUAAoJED2whTVMEyK92D0H/1OyF3jbQw3QFjeV3XBCBf51
V6lhoCfq4LFyzk5yp6rQG3VG+lSC1xmtc0kjAp9ei/OGYpb9Wogsqu53U8e3uurQ
J1z+3XRl7DDlmPcf2DDgrLHirQYa7TqwLIzmpY+g8qBM/qgMbY5RyAm0FuRB2lpj
jdBQebHQqKs9ZCa5bW8xBPD6kvNnoFm0H+aGrxORjHRyM1OI+4ye8zmTXHz3CwH/
8ZaPB6tWbd2h0Ga21YhH4EcTNoqGDs83uf/FGmJcwDtUoc+esOnQ3H/gvqAJdmv5
tz+6IZaQX3dPDzf6/H+bTI61c9lYnWphBPEWQDBFDLMccGDcUzH35GYulQGjJko=
=Vm7s
-----END PGP SIGNATURE-----



From livia.audino at gmail.com  Thu Mar 22 02:26:50 2012
From: livia.audino at gmail.com (=?ISO-8859-1?Q?L=EDvia_Dorneles_Audino?=)
Date: Wed, 21 Mar 2012 22:26:50 -0300
Subject: [R-sig-ME] Doubts about the construction of mixed models
In-Reply-To: <CA+FvBS9OCraSBxj4GX+-B-mHY4wreXHExRXa9phezRp8z23-_A@mail.gmail.com>
References: <CA+FvBS9OCraSBxj4GX+-B-mHY4wreXHExRXa9phezRp8z23-_A@mail.gmail.com>
Message-ID: <CA+FvBS9CBhEFiujzX0U-HjmWoXbG-3HHENXgjXgzhGeM5kBczg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/b7cbb8a6/attachment-0001.pl>

From Yanwei.Zhang at cna.com  Thu Mar 22 03:58:22 2012
From: Yanwei.Zhang at cna.com (Zhang,Yanwei)
Date: Wed, 21 Mar 2012 21:58:22 -0500
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <62C3C5515A02CB438EE737153DEF27D20BAB12F7C1@FWC-TLEX10.fwc.state.fl.us>
References: <62C3C5515A02CB438EE737153DEF27D20BAB12F7C1@FWC-TLEX10.fwc.state.fl.us>
Message-ID: <330F1BE39EE22C418B76986DFEC5F8F42BDD223BDB@E2K7CLSTB.cna.com>

Hi Bryan, 

The "cpglmm" uses the "glm.fit" function to generate initial values. So the "glm.fit does not converge" message means that when generating the initial values using GLM, the model does not converge. But this should not be a problem as long as you get a converged "cpglmm" estimate - the final estimates are independent of the initial values. I suspect if you supply initial values, this message will go away. But thank you for reporting this - I will suppress this kind of message in the new release to make it less confusing. 

I believe the "summary" function does not work because you have the "nlme" package in front of the "cplm" package in the search path. If you just detach the "nlme" package, it should work. 

You might want to use the Bayesian tweedie mixed models to assess the "p-values". The function "bcpglmm" does that, but the released version is not quite stable. I was using a block Metropolis update for the random effects, but this oftentimes leads to poor convergence because of the difficulty in tuning the proposal covariance matrix. In the development version, I have added an option to perform the na?ve Gibbs sampler, which proves to be much easier to tune, although at the cost of slower speed. The new version should be released within a month. 

Thanks.

Regards, 
Wayne   
 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Danson, Bryan
Sent: Wednesday, March 21, 2012 11:09 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

>  This is probably harmless -- it means that an intermediate GLM step didn't quite work,

>  probably because you have strongly separated data (i.e. some places/factor combinations etc.

>  with all-zero or all-one data)

I do have strongly separated data, as some trap types did not move at all (therefore all zeros), and others moved a lot.


>  Can we see the results of sessionInfo()? I suspect you have a problem with methods from some

>  packages masking others.  If you have installed lme4 from r-forge, I suspect you should re-

>  install it from CRAN ...

The results from sessionInfo(model) are:

Error in as.list.default(X) :
  no method for coercing this S4 class to a vector

The packages in my workspace were (installed in order):

car
ggplot2
sos
glmmADMB
lme4
nlme
plotrix
cplm

I tried removing all that had to do with GLMMs (glmmADMB, lme4, nlme, cplm) and reinstalling only 'cplm' and have been able to get the summary() function to work.  This results in a list of t-values for each trap type.  From my background reading, I understand that p-values are difficult to determine in GLMMs, however, I am not sure how to interpret the t-values to estimate which trap type is different from the wood traps.  Here are the resulting t-values:

                                                    Estimate Std. Error   t value
(Intercept)                               0.05134    0.68273     0.075
trap_type5-slat                     -1.59469    0.44568    -3.578
trap_typevw-6                      -3.79851    0.71923    -5.281
trap_typevw-sponge         -2.41591    0.52667    -4.587
trap_typewire basket      -27.93281  386.0848    -0.072
trap_typewire on frame   -4.77199    0.90967    -5.246
trap_typewood-6                  0.29933    0.32652     0.917
trap_typewood-thick          0.27437    0.34785     0.789
trap_typeyb-6                      -4.27295    0.80548     -5.305
trap_typeyf-6                       -2.88076    0.58270     -4.944

According to the exploratory plot, it is likely that the wood-6 and wood-thick traps are not different from the standard control.  The others are probably different.

Is there a way to know for sure?

Thank you again,

Bryan


_____________________
Bryan Danson
Biological Scientist I
Fish and Wildlife Research Institute
Florida Fish and Wildlife Conservation Commission

"The significant problems we have cannot be solved at the same level of thinking with which we created them."
~Albert Einstein




	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.



From Yanwei.Zhang at cna.com  Thu Mar 22 04:34:50 2012
From: Yanwei.Zhang at cna.com (Zhang,Yanwei)
Date: Wed, 21 Mar 2012 22:34:50 -0500
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <5CD78996B8F8844D963C875D3159B94A034B7493@DSRCORREO.azti.local>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us><loom.20120319T221655-53@post.gmane.org><CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>
	<5CD78996B8F8844D963C875D3159B94A034B7493@DSRCORREO.azti.local>
Message-ID: <330F1BE39EE22C418B76986DFEC5F8F42BDD223BDE@E2K7CLSTB.cna.com>

Hi Ruben, 

Thank you for the input and the reference. The profile likelihood approach is of course a standard way to estimate the variance function. Because it's so fast, I'm planning to use this to generate starting values in the new version of the cplm package. Indeed, there is another much easier way - since the p parameter is only related to the shape parameter in the underlying gamma distribution and it changes little as the mean varies, you can fit a Gamma regression to the severity data (the positive catch rates only) to get a rough estimate of the shape parameter and then derive the value of p. 

That being said, I still prefer the likelihood-based approach for the Tweedie mixed models.  There is some  philosophical gap when using the PQL approach with the profile likelihood. 1) it's an approximation to the model rather than the underlying likelihood, but the profile likelihood approach depends on the approximated likelihood. 2) it's a quasi-likelihood - glmmPQL reports NA on the likelihood - so a more appropriate way is to use the extended quasi-likelihood. But this will need some ad hoc adjustment because the extended quasi-likelihood does not allow zeros. See the argument in Dunn and Smyth (2005): Series evaluation of Tweedie exponential dispersion models densities. Statistics and Computing, 15, 267-280.    
Doing this via the new glmer function may be a better way. Although the results may not be quite different, the latter has more conceptual clarity. 

Wayne
 

-----Original Message-----
From: Rub?n Roa [mailto:rroa at azti.es] 
Sent: Tuesday, March 20, 2012 2:35 AM
To: Zhang,Yanwei; Bill Pikounis; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] glmm with a tweedie distribution

I wouldn't call it ad hoc. The power parameter p in the variance function that defines the Tweedie family of exponential distributions, v(mu)=phi*mu^p, can be estimated via profile likelihood, and then the maximum profile likelihood estimate of the p parameter can be inserted in the glmm, essentially estimating the glmm by an estimated likelihood. So there are two stages of approximation but the approximation methods are not ad hoc, they are pretty much mainstream approximation methods to complex likelihoods. Here is a pseudo code using the tweedie package and glmmPQL from MASS (plus msm). For a published application you can see Tascheri, Saavedra-Nievas, Roa-Ureta. 2010. Statistical models to standardize catch rates in the multi-species trawl fishery for Patagonian grenadier (Macruronus magellanicus) off Southern Chile. Fisheries Research 105:200-214.

HTH

Ruben

--
Dr. Ruben H. Roa-Ureta
Senior Researcher, AZTI Tecnalia,
Marine Research Division,
Txatxarramendi Ugartea z/g, 48395, Sukarrieta,
Bizkaia, Spain

##################################  Tweedie ####################################
#estimating variance power parameter

#libraries

library(tweedie)

library(MASS)

library(msm)

MyCaseStudy.Tweedie.prof <- tweedie.profile(MyResponseVar ~ log(Y) + log(Z) + ... + Factor1 + Factor2 + ... ,
p.vec=seq(1.0,2.0,by=0.1), data=MyData, link.power=0, fit.glm=FALSE, do.smooth=TRUE, do.plot=TRUE,
method="inversion",conf.level=0.95, phi.method= "mle",verbose=TRUE)

#distributional plot

y <- rtweedie(1000, p= MyCaseStudy.Tweedie.prof $p.max, mu=1, phi= MyCaseStudy.Tweedie.prof $phi.max)
tweedie.plot(seq(0, max(y), length=100), mu=mean(y), p= MyCaseStudy.Tweedie.prof $p.max, phi= MyCaseStudy.Tweedie.prof $phi.max)

#fitting the glmm
MyCaseStudy..Tweedie.mix <- glmmPQL(fixed = MyResponseVar ~ log(Y) + log(Z) + ... + Factor1 + Factor2 + ... ,
random = list(~1|RE), family=tweedie(var.power = MyCaseStudy.Tweedie.prof$p.max, link.power=0), data= MyData)

MyCaseStudy.Tweedie.mix.sum  <- summary(MyCaseStudy.Tweedie.mix)

#estimated covariance of estimates of a subset of coefficients, [3:11]

MyCaseStudy.Tweedie.mix.year.cov <- round(deltamethod(g=list(~exp(x1),~exp(x2),~exp(x3),~exp(x4),~exp(x5),
~exp(x6),~exp(x7),~exp(x8),~exp(x9)), mean= MyCaseStudy.Tweedie.mix.sum$coef$fixed[3:11], cov=vcov(MyCaseStudy.Tweedie.mix)[3:11,3:11],
ses=FALSE),5)

MyCaseStudy.Tweedie.mix.year.se  <- sqrt(diag(MyCaseStudy.Tweedie.mix.year.cov))

MyCaseStudy.Tweedie.mix.year.cor <- cov2cor(MyCaseStudy.Tweedie.mix.year.cov)

-----Mensaje original-----
De: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Zhang,Yanwei
Enviado el: lunes, 19 de marzo de 2012 23:17
Para: Bill Pikounis; r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] glmm with a tweedie distribution

One problem with the "glmmPQL" is that the variance function can not be estimated - you need to pre-specify it in an ad hoc way. The "cpglmm" function in the "cplm" package estimates it directly from the data along with other parameters using MLE. But of course, you can use glmmPQL to generate starting values that are fed to cpglmm.   

Regards,
Wayne 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bill Pikounis
Sent: Monday, March 19, 2012 4:56 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

Bryan,
You might also wish to try the glmmPQL function in Venables and Ripley's MASS package. Someone reported success with it on the SIG-ECO R list nearly a year ago:

https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html

Hope that helps.

Bill

On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
> Danson, Bryan <Bryan.Danson at ...> writes:
>
>>
>> Is there a way to run a GLMM with a tweedie distribution?
>>
>
> ?Yes, using the 'cplm' package. ?I expanded the section on ZIGLMMs on 
> http://glmm.wikidot.com/faq to include a bit more stuff on ZIGLMMs, 
> including a bit on ZIGLMMs with a continuous response for the non-zero 
> data.
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From livia.audino at gmail.com  Wed Mar 21 23:59:09 2012
From: livia.audino at gmail.com (=?ISO-8859-1?Q?L=EDvia_Dorneles_Audino?=)
Date: Wed, 21 Mar 2012 19:59:09 -0300
Subject: [R-sig-ME] Doubts about the construction of mixed models
Message-ID: <CA+FvBS9OCraSBxj4GX+-B-mHY4wreXHExRXa9phezRp8z23-_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/bafbbc9b/attachment-0001.pl>

From nicole.prause at gmail.com  Mon Mar 19 17:12:34 2012
From: nicole.prause at gmail.com (Nikky)
Date: Mon, 19 Mar 2012 10:12:34 -0600
Subject: [R-sig-ME] Specifying continuous covariates and predictors in lmer
Message-ID: <CAHskT4qiewO9+=BqzZQty2GSziqAoHRpYu-eqeHKnMccHTmv=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/76f9822d/attachment-0001.pl>

From livia.audino at gmail.com  Thu Mar 22 12:15:15 2012
From: livia.audino at gmail.com (=?ISO-8859-1?Q?L=EDvia_Dorneles_Audino?=)
Date: Thu, 22 Mar 2012 08:15:15 -0300
Subject: [R-sig-ME] GLMM - how to consider temporal pseudo-replication in
	the analyses?
Message-ID: <CA+FvBS8eii_xvZL_KT3aAh=p0Y+fYG+ZhTJsV6qdV6fJyXX15g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120322/4cc7ae39/attachment-0001.pl>

From laf.nilsson at gmail.com  Thu Mar 22 15:06:49 2012
From: laf.nilsson at gmail.com (Fredrik Nilsson)
Date: Thu, 22 Mar 2012 15:06:49 +0100
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <BAY170-W1616B2331C572FEB3907EAA1400@phx.gbl>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
	<loom.20120319T023745-978@post.gmane.org>
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>
	<CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>
	<loom.20120319T194724-653@post.gmane.org>
	<BAY170-W46AC47612EE83EB437B6D1A1400@phx.gbl>
	<BAY170-W1616B2331C572FEB3907EAA1400@phx.gbl>
Message-ID: <CANMF+4S+xDM2nJ-Rr-be9E18v4H62P0VAZPpzum2CENQngpw3A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120322/eb4d3ef2/attachment-0001.pl>

From Bryan.Danson at MyFWC.com  Thu Mar 22 16:40:25 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Thu, 22 Mar 2012 11:40:25 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <330F1BE39EE22C418B76986DFEC5F8F42BDD223BDB@E2K7CLSTB.cna.com>
References: <62C3C5515A02CB438EE737153DEF27D20BAB12F7C1@FWC-TLEX10.fwc.state.fl.us>
	<330F1BE39EE22C418B76986DFEC5F8F42BDD223BDB@E2K7CLSTB.cna.com>
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAB12F944@FWC-TLEX10.fwc.state.fl.us>

Hi Wayne,

Thank you for the help.  The summary function does work once the "nlme" package is removed.  I was able to get the bcpglmm() function to work as well.  However, the results give a "Mean", "SD", "Na?ve SE", and "Time-series SE" for each trap type.  And I am confused to how to interpret this.

I supposed I should have prefaced all of these emails with the fact that I have very little statistical background.  I have taken courses in undergrad and graduate school, however they are introductory courses and fall far short of this level of mixed-modeling.  I am therefore trying to teach myself this modeling.  I have ordered a few books that have been mentioned on this list to help, I am just waiting on them to come in.  

But with that in mind, thank you all so much for your help. I have learned a great deal so far.  

Bryan

-----Original Message-----
From: Zhang,Yanwei [mailto:Yanwei.Zhang at cna.com] 
Sent: Wednesday, March 21, 2012 10:58 PM
To: Danson, Bryan; r-sig-mixed-models at r-project.org
Subject: RE: Re: [R-sig-ME] glmm with a tweedie distribution

Hi Bryan, 

The "cpglmm" uses the "glm.fit" function to generate initial values. So the "glm.fit does not converge" message means that when generating the initial values using GLM, the model does not converge. But this should not be a problem as long as you get a converged "cpglmm" estimate - the final estimates are independent of the initial values. I suspect if you supply initial values, this message will go away. But thank you for reporting this - I will suppress this kind of message in the new release to make it less confusing. 

I believe the "summary" function does not work because you have the "nlme" package in front of the "cplm" package in the search path. If you just detach the "nlme" package, it should work. 

You might want to use the Bayesian tweedie mixed models to assess the "p-values". The function "bcpglmm" does that, but the released version is not quite stable. I was using a block Metropolis update for the random effects, but this oftentimes leads to poor convergence because of the difficulty in tuning the proposal covariance matrix. In the development version, I have added an option to perform the na?ve Gibbs sampler, which proves to be much easier to tune, although at the cost of slower speed. The new version should be released within a month. 

Thanks.

Regards, 
Wayne   
 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Danson, Bryan
Sent: Wednesday, March 21, 2012 11:09 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

>  This is probably harmless -- it means that an intermediate GLM step 
> didn't quite work,

>  probably because you have strongly separated data (i.e. some places/factor combinations etc.

>  with all-zero or all-one data)

I do have strongly separated data, as some trap types did not move at all (therefore all zeros), and others moved a lot.


>  Can we see the results of sessionInfo()? I suspect you have a problem 
> with methods from some

>  packages masking others.  If you have installed lme4 from r-forge, I 
> suspect you should re-

>  install it from CRAN ...

The results from sessionInfo(model) are:

Error in as.list.default(X) :
  no method for coercing this S4 class to a vector

The packages in my workspace were (installed in order):

car
ggplot2
sos
glmmADMB
lme4
nlme
plotrix
cplm

I tried removing all that had to do with GLMMs (glmmADMB, lme4, nlme, cplm) and reinstalling only 'cplm' and have been able to get the summary() function to work.  This results in a list of t-values for each trap type.  From my background reading, I understand that p-values are difficult to determine in GLMMs, however, I am not sure how to interpret the t-values to estimate which trap type is different from the wood traps.  Here are the resulting t-values:

                                                    Estimate Std. Error   t value
(Intercept)                               0.05134    0.68273     0.075
trap_type5-slat                     -1.59469    0.44568    -3.578
trap_typevw-6                      -3.79851    0.71923    -5.281
trap_typevw-sponge         -2.41591    0.52667    -4.587
trap_typewire basket      -27.93281  386.0848    -0.072
trap_typewire on frame   -4.77199    0.90967    -5.246
trap_typewood-6                  0.29933    0.32652     0.917
trap_typewood-thick          0.27437    0.34785     0.789
trap_typeyb-6                      -4.27295    0.80548     -5.305
trap_typeyf-6                       -2.88076    0.58270     -4.944

According to the exploratory plot, it is likely that the wood-6 and wood-thick traps are not different from the standard control.  The others are probably different.

Is there a way to know for sure?

Thank you again,

Bryan


_____________________
Bryan Danson
Biological Scientist I
Fish and Wildlife Research Institute
Florida Fish and Wildlife Conservation Commission

"The significant problems we have cannot be solved at the same level of thinking with which we created them."
~Albert Einstein




	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.



From a.hayward at sheffield.ac.uk  Fri Mar 23 11:03:28 2012
From: a.hayward at sheffield.ac.uk (Adam Hayward)
Date: Fri, 23 Mar 2012 10:03:28 +0000
Subject: [R-sig-ME] Back-transforming binomial standard errors
Message-ID: <CALQiR0_dED86zBTHmrx8g=ZUq9WRJP_osG+AJfkNWNzLg27Vng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120323/60583daf/attachment-0001.pl>

From Thierry.ONKELINX at inbo.be  Fri Mar 23 12:03:08 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 23 Mar 2012 11:03:08 +0000
Subject: [R-sig-ME] Back-transforming binomial standard errors
In-Reply-To: <CALQiR0_dED86zBTHmrx8g=ZUq9WRJP_osG+AJfkNWNzLg27Vng@mail.gmail.com>
References: <CALQiR0_dED86zBTHmrx8g=ZUq9WRJP_osG+AJfkNWNzLg27Vng@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742757357FD5@inbomail.inbo.be>

Dear Adam,

Personally I would keep the data in the logit scale. If you want some kind of se measurement in the original scale, then I suggest to calculate confidence interval in the logit scale, back-transform the interval and then calculate the width of the interval.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Adam Hayward
Verzonden: vrijdag 23 maart 2012 11:03
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Back-transforming binomial standard errors

Dear R users,

I am using model predictions from binomial GLMMs and Gaussian LMMs to run GAMs to describe the change in several traits across ages. I can back-transform the binomial model predictions, to rescale them for GAM analysis, but then want to weight these predictions by the standard error of the prediction (because less confidence is attached to older ages because fewer individuals are measured). Because I have standard errors from both Gaussian and binomial models, I feel the standard errors from the binomial GLMMs should also be transformed back to the normal scale, but cannot find information on the proper way to do this. I wonder if anyone knows of a solution to this problem?

Best wishes,
Adam


--
Adam Hayward
Post-Doctoral Research Associate
Department of Animal and Plant Sciences
Alfred Denny Building
University of Sheffield
Western Bank
Sheffield S10 2TN
UK

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From teplitsky at mnhn.fr  Fri Mar 23 12:22:57 2012
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Fri, 23 Mar 2012 12:22:57 +0100
Subject: [R-sig-ME] covariances between non normal traits
Message-ID: <4F6C5D11.1040406@mnhn.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120323/2f19ee3a/attachment-0001.pl>

From i.m.s.white at ed.ac.uk  Fri Mar 23 13:45:08 2012
From: i.m.s.white at ed.ac.uk (i white)
Date: Fri, 23 Mar 2012 12:45:08 +0000
Subject: [R-sig-ME] covariances between non normal traits
In-Reply-To: <4F6C5D11.1040406@mnhn.fr>
References: <4F6C5D11.1040406@mnhn.fr>
Message-ID: <4F6C7054.6030304@ed.ac.uk>

Celine,

We can estimate (tetrachoric) correlations between two binomial traits, 
by assuming probits have bivariate normal distribution. I don't know 
whether this fits into GLMM framework.

Celine Teplitsky wrote:
> Dear all,
> 
> I have seen this post by Arthur Gilmour in an ASReml related forum:
>> GLMM models have only been developed for the case of a single GLMM 
>> trait. It is difficult to conceive what is the appropriate error 
>> structure for bivariate GLMM traits when the variances are defined as 
>> functions of the mean. 
> 
> I would like to know what people on this list think about these issues 
> e.g. if we want to estimate correlations between 2 traits with a poisson 
> distribution, are there some special issues to take into account?
> 
> Thanks a lot in advance for your help,
> 
> All the best
> 
> Celine
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From cristiana1710vieira at hotmail.com  Thu Mar 22 17:49:50 2012
From: cristiana1710vieira at hotmail.com (cristiana vieira)
Date: Thu, 22 Mar 2012 16:49:50 +0000
Subject: [R-sig-ME] problem in the implementation of the function "lmer" of
 the "lme4" package - Important
In-Reply-To: <CAO7JsnQZFdA35_65QM_Kf=yLf6PM_-FhmGH2hxOMcMDfyNSeCA@mail.gmail.com>
References: <DUB112-W8E9974D6F1EEDF1BB9B86B05E0@phx.gbl>,
	<CAO7JsnQZFdA35_65QM_Kf=yLf6PM_-FhmGH2hxOMcMDfyNSeCA@mail.gmail.com>
Message-ID: <DUB112-W3371D1556CCBDCE0EABE47B0410@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120322/d262acb3/attachment-0001.pl>

From emm.charpentier at free.fr  Sat Mar 24 10:39:32 2012
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Sat, 24 Mar 2012 09:39:32 +0000 (UTC)
Subject: [R-sig-ME] covariances between non normal traits
References: <4F6C5D11.1040406@mnhn.fr>
Message-ID: <jkk4ok$u4m$1@dough.gmane.org>

Dear Celine, dear list,

That kind of multivariable modeling is (relatively) easy to do in 
(Win)BUGS/JAGS, by programming a logistic model for each trait, whose 
linear predictor could be modeled as (say) a multivariate normal. This 
could provide some kind of comparison standard to which you could compare 
other results obtained by (say) maximum likelihood (see for example the 
dclone package for a possible approach).

I'd recommend you take a look at Gelman's & Hill's (2007) book on 
multilevel regression, whose part 2 discusses that kind of Bayesian 
modeling. Using "weakly informative" priors (e. g. inverse-Wishart priors 
for variances) should give you estimations (point estimates and 
credibility intervals) close to those of a frequentist analysis (but no p-
values : for that, you'll have to do that yourself (not easily : ask 
Douglas Bates...) or resort to Bayes factors). 

HTH,

					Emmanuel Charpentier

On Fri, 23 Mar 2012 12:22:57 +0100, Celine Teplitsky wrote?:

> Dear all,
> 
> I have seen this post by Arthur Gilmour in an ASReml related forum:
>> GLMM models have only been developed for the case of a single GLMM
>> trait. It is difficult to conceive what is the appropriate error
>> structure for bivariate GLMM traits when the variances are defined as
>> functions of the mean.
> 
> I would like to know what people on this list think about these issues
> e.g. if we want to estimate correlations between 2 traits with a poisson
> distribution, are there some special issues to take into account?
> 
> Thanks a lot in advance for your help,
> 
> All the best
> 
> Celine



From bbolker at gmail.com  Mon Mar 26 14:22:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Mar 2012 12:22:08 +0000 (UTC)
Subject: [R-sig-ME] problem in the implementation of the function
References: <DUB112-W8E9974D6F1EEDF1BB9B86B05E0@phx.gbl>,
	<CAO7JsnQZFdA35_65QM_Kf=yLf6PM_-FhmGH2hxOMcMDfyNSeCA@mail.gmail.com>
	<DUB112-W3371D1556CCBDCE0EABE47B0410@phx.gbl>
Message-ID: <loom.20120326T141552-67@post.gmane.org>

cristiana vieira <cristiana1710vieira at ...> writes:

> 
> 

[snip]
 
> When i ran the example given in the help of the software R and I
> obtained the same error: > library(lme4)Loading required package:
> MatrixLoading required package: lattice Attaching package:
> ?Matrix? The following object(s) are masked from
> ?package:base?: det Attaching package: ?lme4? The
> following object(s) are masked from ?package:stats?: AIC, BIC
> > ?lmerstarting httpd help server ... done > (fm1 <- lmer(Reaction ~
> Days + (Days|Subject), sleepstudy))Error in as(ff, "sparseMatrix") :
> unused argument(s) ("sparseMatrix") > sessionInfo()R version 2.14.2
> (2012-02-29)Platform: i386-pc-mingw32/i386 (32-bit) locale:[1]
> LC_COLLATE=Portuguese_Portugal.1252
> LC_CTYPE=Portuguese_Portugal.1252 [3]
> LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C [5]
> LC_TIME=Portuguese_Portugal.1252 attached base packages:[1] stats
> graphics grDevices utils datasets methods base other attached
> packages:[1] lme4_0.999375-42 Matrix_1.0-4 lattice_0.20-0 loaded via
> a namespace (and not attached):[1] grid_2.14.2 nlme_3.1-103
> stats4_2.14.2 tools_2.14.2 


  (Sorry about the mangling of the example format below.)
  I very strongly suspect that this is due to a mismatch with
the version of the Matrix package.  Version 1.0-5 is available
on CRAN; could you please install it (either via update.packages(),
or via install.packages(), or via the appropriate menu item
if you are running in a GUI -- they should all be equivalent)
and report back if the problem persists?
  
   (The listed dependency of the package is only
Matrix >=0.9996875-1 ; we should probably update this, although
we are also working hard to replace the current version of lme4 ...)

  Ben Bolker



From maechler at stat.math.ethz.ch  Mon Mar 26 15:05:28 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 26 Mar 2012 15:05:28 +0200
Subject: [R-sig-ME] problem in the implementation of the function
In-Reply-To: <loom.20120326T141552-67@post.gmane.org>
References: <DUB112-W8E9974D6F1EEDF1BB9B86B05E0@phx.gbl>
	<CAO7JsnQZFdA35_65QM_Kf=yLf6PM_-FhmGH2hxOMcMDfyNSeCA@mail.gmail.com>
	<DUB112-W3371D1556CCBDCE0EABE47B0410@phx.gbl>
	<loom.20120326T141552-67@post.gmane.org>
Message-ID: <20336.27032.434842.590648@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Mon, 26 Mar 2012 12:22:08 +0000 (UTC) writes:

    > cristiana vieira <cristiana1710vieira at ...> writes:
    >> 
    >> 

    > [snip]
 
    >> When i ran the example given in the help of the software
    >> R and I obtained the same error: > library(lme4)Loading
    >> required package: MatrixLoading required package: lattice
    >> Attaching package: ?Matrix? The following object(s)
    >> are masked from ?package:base?: det Attaching
    >> package: ?lme4? The following object(s) are masked
    >> from ?package:stats?: AIC, BIC > ?lmerstarting
    >> httpd help server ... done > (fm1 <- lmer(Reaction ~ Days
    >> + (Days|Subject), sleepstudy))Error in as(ff,
    >> "sparseMatrix") : unused argument(s) ("sparseMatrix") >
    >> sessionInfo()R version 2.14.2 (2012-02-29)Platform:
    >> i386-pc-mingw32/i386 (32-bit) locale:[1]
    >> LC_COLLATE=Portuguese_Portugal.1252
    >> LC_CTYPE=Portuguese_Portugal.1252 [3]
    >> LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C [5]
    >> LC_TIME=Portuguese_Portugal.1252 attached base
    >> packages:[1] stats graphics grDevices utils datasets
    >> methods base other attached packages:[1] lme4_0.999375-42
    >> Matrix_1.0-4 lattice_0.20-0 loaded via a namespace (and
    >> not attached):[1] grid_2.14.2 nlme_3.1-103 stats4_2.14.2
    >> tools_2.14.2


    >   (Sorry about the mangling of the example format below.)
    > I very strongly suspect that this is due to a mismatch
    > with the version of the Matrix package.  Version 1.0-5 is
    > available on CRAN; could you please install it (either via
    > update.packages(), or via install.packages(), or via the
    > appropriate menu item if you are running in a GUI -- they
    > should all be equivalent) and report back if the problem
    > persists?

Hmm,  R-2.14.2  *comes* with Matrix 1.0-4 
*included* (as it is a recommended package).

And many other people have been using the same combination
without any such fundamental problems

Somehow you must really have done something bad to your R (2.14.2)
installation, or to your lme4 installation.  Maybe you should
reinstall R,  or at least re-install lme4 -- for *that* version of R.
I don't think you should reinstall Matrix.

  
    >    (The listed dependency of the package is only Matrix
    > >=0.9996875-1 ; we should probably update this,

we have updated it for lme4.0
however, lme4 (the current one on CRAN) has worked with many
versions of Matrix in the past, and has not depended
specifically on any recent version of Matrix.

    > although we are also working hard to replace the current version of
    > lme4 ...)
[indeed!]



From bbolker at gmail.com  Mon Mar 26 16:53:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Mar 2012 10:53:28 -0400
Subject: [R-sig-ME] help with ordinal mixed model (reposted from r-help)
Message-ID: <4F7082E8.4080109@mcmaster.ca>

[forwarded to r-sig-mixed]

Ivan Allaman <ivanalaman <at> yahoo.com.br> writes:

>
> Good afternoon, gentlemen!

 (Note that we are not all gentlemen here ...)

> After several days studying and researching on categorical data
> (various forums with answers from the owner of the library - all
> incipient) how to interpret the output the function MCMCglmm, come
> to enlist the help of you, if someone has already worked with
> MCMCglmm function in the case of variables ordinal dependent. I've
> read and reread all the pdf's of the package, the coursenotes
> Jarrod, finally, I'm exhausted. To clarify the database, the
> treatment (called fases) consist of three levels (1-pre, 2-propolis
> and 3-vincris) and the ordinal variable response has three
> categories (1-normal, 2-agudo, 3 - cronico). See table!

  Thank you for the reproducible example.

  I'm forwarding this to r-sig-mixed-models at r-project.org,
which is really more appropriate.

  Your biggest problem is that your chain is mixing really, really
badly, probably because your data set is too small/the model is
overfitted ...  you may need to use some informative priors to get
things back on track, or you may need to try something simpler ...

  Ben Bolker

##  a few tweaks for prettier code: set factor labels right away
du <- transform(
read.table('http://dl.dropbox.com/u/33619290/Dados/Dtest.txt',
                           header=TRUE),
                FASES=factor(FASES,
                 labels=c('Normal','Aguda','Cr?nica')),
                ANIMAIS=factor(ANIMAIS),
                ALT.RENAIS=ordered(ALT.RENAIS,
                labels=c('Pre','Propolis','Vincr')))
summary(du)
du <- na.omit(du)

(tabela <- with(du,table(FASES,ALT.RENAIS)))

## this shows that there really isn't very much information
## in the data set ...

library(ggplot2)
ggplot(du,aes(FASES,ALT.RENAIS,group=ANIMAIS))+
    geom_point()+geom_line()+facet_wrap(~ANIMAIS)


library('MCMCglmm')

#the mixed model:
set.seed(1)
mod1 <- MCMCglmm(ALT.RENAIS ~-1+FASES, random= ~ ANIMAIS,
     family='ordinal',pl=TRUE,data=du)
summary(mod1)

xyplot(mod1$Sol)  ## NOT mixing well

## run for longer ...
mod2 <- MCMCglmm(ALT.RENAIS ~-1+FASES, random= ~ ANIMAIS,
     family='ordinal',pl=TRUE,data=du,nitt=100000)
xyplot(mod2$Sol)
xyplot(mod2$CP)  ## !!!

> Then the pain starts, since the documentation is insufficient in
> this case.  According to him Jarrod (forums), the a posteriori means
> of the coefficients of the covariates are the probit
> scale. According to my study, these coefficients are the scores of
> standard normal distribution. More scores should not correspond to
> cutpoints? In this case, we would have j (response variable
> categories) -1 cutpoints, ie, two cutpoints. The output shows me
> only one cutpoint. How can then calculate the probabilities with
> only one cutpoint? According to the documentation (Vignettes, page
> 22), if P (y = k) = F (yk | l (vlatente), 1) - F (yk-1 | l, 1), this
> '1' would probably be the category '1' of the dependent variable?
> Anyway gentlemen, how can I extract the probabilities for the stages
> for each category of the dependent variable? I thank everyone's
> attention.

From
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003671.html :

[for a four-category model]
If l=Xb+Zu+e, the probabilities of falling into each of the four
categories are:

## pnorm(-l)
## pnorm(cp[1]-l)-pnorm(-l)
## pnorm(cp[2]-l)-pnorm(cp[1]-l)
## 1-pnorm(cp[2]-l)

For an unknown individual in category 1 (i.e. set u=0) the prediction
would be

l = -3.605

## category 1: pnorm(-l) = pnorm(3.605) = 0.999
summary(pnorm(-mod2$Sol[,1]))

## category 2: pnorm(cp[1]-l)-pnorm(-l)
summary(pnorm(mod2$CP-mod2$Sol[,1])-pnorm(-mod2$Sol[,1]))

## category 3: pnorm(cp[1]-l) [OR pnorm(cp[1]-l,lower.tail=FALSE)]
summary(pnorm(mod2$CP,lower.tail=FALSE))

library(ordinal) ## model MUST have an intercept according to ?clm
mod3 <- clmm(ALT.RENAIS ~FASES+(1|ANIMAIS),data=du,link="probit")
summary(mod3)

This is not quite working either -- maybe the model is just plain
overfitted?



From j.hadfield at ed.ac.uk  Mon Mar 26 17:15:32 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 26 Mar 2012 16:15:32 +0100
Subject: [R-sig-ME] help with ordinal mixed model (reposted from r-help)
In-Reply-To: <4F7082E8.4080109@mcmaster.ca>
References: <4F7082E8.4080109@mcmaster.ca>
Message-ID: <8FB24AF6-94C0-4B31-876B-3B936D9FBFC8@ed.ac.uk>

Hi,

You do not seem to specify a prior? With ordinal data the residual/ 
units variance is not identified - you need to fix it at something  
(e.g. 1):

prior=list(R=list(V=1, fix=1), G=list(G1=list(....)))

where I will leave ... to your judgement.

If you don't it will generate nonsense.

Jarrod

On 26 Mar 2012, at 15:53, Ben Bolker wrote:

> [forwarded to r-sig-mixed]
>
> Ivan Allaman <ivanalaman <at> yahoo.com.br> writes:
>
>>
>> Good afternoon, gentlemen!
>
> (Note that we are not all gentlemen here ...)
>
>> After several days studying and researching on categorical data
>> (various forums with answers from the owner of the library - all
>> incipient) how to interpret the output the function MCMCglmm, come
>> to enlist the help of you, if someone has already worked with
>> MCMCglmm function in the case of variables ordinal dependent. I've
>> read and reread all the pdf's of the package, the coursenotes
>> Jarrod, finally, I'm exhausted. To clarify the database, the
>> treatment (called fases) consist of three levels (1-pre, 2-propolis
>> and 3-vincris) and the ordinal variable response has three
>> categories (1-normal, 2-agudo, 3 - cronico). See table!
>
>  Thank you for the reproducible example.
>
>  I'm forwarding this to r-sig-mixed-models at r-project.org,
> which is really more appropriate.
>
>  Your biggest problem is that your chain is mixing really, really
> badly, probably because your data set is too small/the model is
> overfitted ...  you may need to use some informative priors to get
> things back on track, or you may need to try something simpler ...
>
>  Ben Bolker
>
> ##  a few tweaks for prettier code: set factor labels right away
> du <- transform(
> read.table('http://dl.dropbox.com/u/33619290/Dados/Dtest.txt',
>                           header=TRUE),
>                FASES=factor(FASES,
>                 labels=c('Normal','Aguda','Cr?nica')),
>                ANIMAIS=factor(ANIMAIS),
>                ALT.RENAIS=ordered(ALT.RENAIS,
>                labels=c('Pre','Propolis','Vincr')))
> summary(du)
> du <- na.omit(du)
>
> (tabela <- with(du,table(FASES,ALT.RENAIS)))
>
> ## this shows that there really isn't very much information
> ## in the data set ...
>
> library(ggplot2)
> ggplot(du,aes(FASES,ALT.RENAIS,group=ANIMAIS))+
>    geom_point()+geom_line()+facet_wrap(~ANIMAIS)
>
>
> library('MCMCglmm')
>
> #the mixed model:
> set.seed(1)
> mod1 <- MCMCglmm(ALT.RENAIS ~-1+FASES, random= ~ ANIMAIS,
>     family='ordinal',pl=TRUE,data=du)
> summary(mod1)
>
> xyplot(mod1$Sol)  ## NOT mixing well
>
> ## run for longer ...
> mod2 <- MCMCglmm(ALT.RENAIS ~-1+FASES, random= ~ ANIMAIS,
>     family='ordinal',pl=TRUE,data=du,nitt=100000)
> xyplot(mod2$Sol)
> xyplot(mod2$CP)  ## !!!
>
>> Then the pain starts, since the documentation is insufficient in
>> this case.  According to him Jarrod (forums), the a posteriori means
>> of the coefficients of the covariates are the probit
>> scale. According to my study, these coefficients are the scores of
>> standard normal distribution. More scores should not correspond to
>> cutpoints? In this case, we would have j (response variable
>> categories) -1 cutpoints, ie, two cutpoints. The output shows me
>> only one cutpoint. How can then calculate the probabilities with
>> only one cutpoint? According to the documentation (Vignettes, page
>> 22), if P (y = k) = F (yk | l (vlatente), 1) - F (yk-1 | l, 1), this
>> '1' would probably be the category '1' of the dependent variable?
>> Anyway gentlemen, how can I extract the probabilities for the stages
>> for each category of the dependent variable? I thank everyone's
>> attention.
>
> From
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003671.html :
>
> [for a four-category model]
> If l=Xb+Zu+e, the probabilities of falling into each of the four
> categories are:
>
> ## pnorm(-l)
> ## pnorm(cp[1]-l)-pnorm(-l)
> ## pnorm(cp[2]-l)-pnorm(cp[1]-l)
> ## 1-pnorm(cp[2]-l)
>
> For an unknown individual in category 1 (i.e. set u=0) the prediction
> would be
>
> l = -3.605
>
> ## category 1: pnorm(-l) = pnorm(3.605) = 0.999
> summary(pnorm(-mod2$Sol[,1]))
>
> ## category 2: pnorm(cp[1]-l)-pnorm(-l)
> summary(pnorm(mod2$CP-mod2$Sol[,1])-pnorm(-mod2$Sol[,1]))
>
> ## category 3: pnorm(cp[1]-l) [OR pnorm(cp[1]-l,lower.tail=FALSE)]
> summary(pnorm(mod2$CP,lower.tail=FALSE))
>
> library(ordinal) ## model MUST have an intercept according to ?clm
> mod3 <- clmm(ALT.RENAIS ~FASES+(1|ANIMAIS),data=du,link="probit")
> summary(mod3)
>
> This is not quite working either -- maybe the model is just plain
> overfitted?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Mon Mar 26 18:12:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Mar 2012 12:12:28 -0400
Subject: [R-sig-ME] [ADMB Users] Anova table for glmm.admb objects
In-Reply-To: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
References: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
Message-ID: <4F70956C.1050009@gmail.com>

On 12-03-26 10:37 AM, Paula Rosewarne wrote:
> 
> Dear All,
> 
> I came across this posting (below) on a different list- how to get an
> Anova table from glmm.admb model objects- but I cannot get the
> car::Anova function to work for my model, or for the owl example I
> worked through from the glmmadmb package help notes, so I am guessing
> my code is wrong
> 
> When I tried it with the owl example I get the following message, the
> same as when I try for my model:
> 
>> car::Anova(fit_zipoiss)
> Error in data.frame(df, teststat, p) : arguments imply differing
> number of rows: 5, 6 In addition: Warning message: In Ops.factor(1,
> Nest) : | not meaningful for factors
> 
> 
> 
> (I am using glmm.admb v0.7.2.4)
> 
> 
> 
> Please could you advise, many thanks,
> 
> Paula
> 

 [cross-posted to ADMB users and r-sig-mixed because I didn't want to
write it twice]

   Before I answer the question I want to strongly caution people about
using the Anova() (Wald) tests on glmmADMB output. I am generally of the
"give people the tools, let them do what they want" [in other words
"give them enough rope"] philosophy (which is why I tweaked glmmADMB to
allow car::Anova() to work), but Wald tests are the most approximate
approach to model comparison and inference.  For vanilla (non-mixed)
linear models they are identical to standard marginal F tests, but for
mixed/generalized/zero-inflated models they are sometimes very poor
approximations. Using anova() on alternative models instead gives a
likelihood ratio test, which is still approximate but is generally much
better (it relies on the normality of the likelihood itself, rather than
on the normality of the sampling distribution of the parameters).  It is
a bit tedious to use in glmmADMB at the moment because I haven't got the
drop1() functionality working yet, but it should be much more reliable.
 Even that is not perfect, though, because it does depend on the
approximate normality of the likelihood estimate; MCMC and parametric
bootstrap approaches are more accurate.

   You need at least version 0.7.2.9.  I am currently struggling to get
the newest version to build properly on r-forge; in the meantime, below
is a helper function to check which versions are available where.  You
may want to use the optional argument  type="source" (as documented at
http://glmmadmb.r-forge.r-project.org) ...

  In the meantime I've put 0.7.2.10 (source only, use type="source") at
the bolker-mcmaster repository and on the alternative r-forge location
(where it should show up within 24 hours).

## helper function to check availability
favail <- function(repos="r-forge.r-project.org",
                   pkg="glmmADMB",
                   ...) {
    hdr <- "http://"
    if (!substr(repos,1,8)==hdr) repos <- paste(hdr,repos,sep="")
    a <- available.packages(contriburl=contrib.url(repos),...)
    if (length(grep(pkg,rownames(a)))==0)
        stop(sprintf("%s unavailable at repos %s",pkg,repos))
    a[pkg,"Version"]
}

favail()  ## unavailable
favail("www.math.mcmaster.ca/bolker/R")  ## 0.7.2.10
favail("glmmadmb.r-forge.r-project.org/repos")  ## 0.6.4

> 
> 
> From the r-sig-mixed-models list: Le 20/03/2012 22:43, Ben Bolker a
> ?crit : On 12-03-20 02:32 PM,
>> Thomas Merkling wrote:
>>>>> Dear Ben and other list members,
>>>>> 
>>>>> - Is there any way to produce a Anova/deviance table for a 
>>>>> model fitted with glmmADMB ? I used the Anova() function
>>>>> from the car library for glmer models, but it does not seem
>>>>> to work with glmmadmb (I'm using glmmADMB 0.7) and I would
>>>>> like only one p-value for each term and interaction and NOT
>>>>> one p-value for each level of the interaction.
> Ben's reply:
>> car::Anova() should work now -- I had to add a model.frame() and a 
>> df.residual() method for glmmadmb objects.  (The df.residual number
>> may be a little dodgy -- I'm not sure I counted the parameters
>> right -- but I don't think it's actually used for much by default,
>> cause you get Wald chi-square tests)
> 
> 
> 
> 
> Paula Rosewarne, PhD researcher, Faculty of Biological Sciences 
> Manton Building 8.17 Clarendon Way University of Leeds LS2 9JT UK
> 
> Email: bspjr at leeds.ac.uk<mailto:bspjr at leeds.ac.uk> 
> _______________________________________________ Users mailing list 
> Users at admb-project.org 
> http://lists.admb-project.org/mailman/listinfo/users



From broog731 at newschool.edu  Mon Mar 26 19:35:41 2012
From: broog731 at newschool.edu (Geoff Brookshire)
Date: Mon, 26 Mar 2012 13:35:41 -0400
Subject: [R-sig-ME] Conflicting p-values from pvals.fnc
In-Reply-To: <CAPB_MR1-ZZHD93Vya_Mg_60HppF5Sg3rSma_1cS3KjqHd3mwHw@mail.gmail.com>
References: <CAPB_MR1-ZZHD93Vya_Mg_60HppF5Sg3rSma_1cS3KjqHd3mwHw@mail.gmail.com>
Message-ID: <CAE1hoOpf8aLY61W48h_p7T=oDBhaiZF-mrrrQHEpSw3mWnT9sQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120326/b887aaad/attachment-0001.pl>

From istazahn at gmail.com  Tue Mar 27 04:18:26 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 26 Mar 2012 22:18:26 -0400
Subject: [R-sig-ME] Help understanding residual variance
Message-ID: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>

Hi all,

I'm trying to understand what the residual variance in this model:

tmp <- subset(sleepstudy, Days == 1 | Days == 9)
m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
tmp$fitted1 <- fitted(m1)

represents. The way I read this specification, an intercept and a
slope is estimated for each subject. Since each subject only has two
measurements, I would expect the Reaction scores to be completely
accounted for by the slopes and intercepts. Yet they are not: the
Residual variance estimate is 440.278.

This is probably a stupid question, but I hope you will be kind enough
to humor me.

Best,
Ista



From 538280 at gmail.com  Tue Mar 27 17:32:10 2012
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 27 Mar 2012 09:32:10 -0600
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
Message-ID: <CAFEqCdzxmBgdFGLN6Hbhsz1BF278-JE11vbkjs27ZQW2=Lztvg@mail.gmail.com>

Yes, each person has their own slope and intercept estimated, however
the slope and intercept are not determined solely by the 2 data points
for that person, but also are affected by the slope and intercept
estimates across all subjects (this is why lmer gives value beyond
lmList).

You can see this if you refit using the nlme package (only because it
has the augPred function which has not been implemented in lme4 yet):

library(nlme)
m2 <- lme( Reaction ~ Days, data=tmp, random=~Days|Subject)
plot(augPred(m2, ~Days, level=c(0,1)))

comparing the m2 model to your m1 gives the same fixed effects, but
slightly different random effects (I probably did not do something
that was needed to make the models exactly the same) but is probably
close enough.

Look at the plot and you will see the fixed effects line, the line for
each subject that includes the random effects, and the data.  The line
for the individual subjects are pulled slightly towards the fixed
effects line and so does not hit the 2 points exactly.  This shows how
the estimate of each individuals values are influenced by the overall
fit.


On Mon, Mar 26, 2012 at 8:18 PM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi all,
>
> I'm trying to understand what the residual variance in this model:
>
> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
> tmp$fitted1 <- fitted(m1)
>
> represents. The way I read this specification, an intercept and a
> slope is estimated for each subject. Since each subject only has two
> measurements, I would expect the Reaction scores to be completely
> accounted for by the slopes and intercepts. Yet they are not: the
> Residual variance estimate is 440.278.
>
> This is probably a stupid question, but I hope you will be kind enough
> to humor me.
>
> Best,
> Ista
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From thomas.merkling at cict.fr  Tue Mar 27 18:29:51 2012
From: thomas.merkling at cict.fr (Thomas Merkling)
Date: Tue, 27 Mar 2012 18:29:51 +0200
Subject: [R-sig-ME] [ADMB Users] Anova table for glmm.admb objects
In-Reply-To: <4F70956C.1050009@gmail.com>
References: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
	<4F70956C.1050009@gmail.com>
Message-ID: <4F71EAFF.1000302@cict.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120327/0c0ae54c/attachment-0001.pl>

From livia.audino at gmail.com  Tue Mar 27 19:14:15 2012
From: livia.audino at gmail.com (=?ISO-8859-1?Q?L=EDvia_Dorneles_Audino?=)
Date: Tue, 27 Mar 2012 14:14:15 -0300
Subject: [R-sig-ME] What error distribution should I use?
In-Reply-To: <CA+FvBS8=mStdtZsiZus1SreWnyRD8Njv-s=7HWr_JoZeww_umQ@mail.gmail.com>
References: <CA+FvBS8=mStdtZsiZus1SreWnyRD8Njv-s=7HWr_JoZeww_umQ@mail.gmail.com>
Message-ID: <CA+FvBS_Fx+nniAYXdgVyH067O+PDG2zXQpMGH58bxk1NUVBHRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120327/3a2e8098/attachment-0001.pl>

From istazahn at gmail.com  Tue Mar 27 20:55:57 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 27 Mar 2012 14:55:57 -0400
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CAFEqCdzxmBgdFGLN6Hbhsz1BF278-JE11vbkjs27ZQW2=Lztvg@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAFEqCdzxmBgdFGLN6Hbhsz1BF278-JE11vbkjs27ZQW2=Lztvg@mail.gmail.com>
Message-ID: <CA+vqiLGVyQpkXHic_spquqWNg3-JMxEVQk696Oy0OVxUsQREEg@mail.gmail.com>

Thank you Greg, that helps.

-Ista

On Tue, Mar 27, 2012 at 11:32 AM, Greg Snow <538280 at gmail.com> wrote:
>
> Yes, each person has their own slope and intercept estimated, however
> the slope and intercept are not determined solely by the 2 data points
> for that person, but also are affected by the slope and intercept
> estimates across all subjects (this is why lmer gives value beyond
> lmList).
>
> You can see this if you refit using the nlme package (only because it
> has the augPred function which has not been implemented in lme4 yet):
>
> library(nlme)
> m2 <- lme( Reaction ~ Days, data=tmp, random=~Days|Subject)
> plot(augPred(m2, ~Days, level=c(0,1)))
>
> comparing the m2 model to your m1 gives the same fixed effects, but
> slightly different random effects (I probably did not do something
> that was needed to make the models exactly the same) but is probably
> close enough.
>
> Look at the plot and you will see the fixed effects line, the line for
> each subject that includes the random effects, and the data. ?The line
> for the individual subjects are pulled slightly towards the fixed
> effects line and so does not hit the 2 points exactly. ?This shows how
> the estimate of each individuals values are influenced by the overall
> fit.
>
>
> On Mon, Mar 26, 2012 at 8:18 PM, Ista Zahn <istazahn at gmail.com> wrote:
> > Hi all,
> >
> > I'm trying to understand what the residual variance in this model:
> >
> > tmp <- subset(sleepstudy, Days == 1 | Days == 9)
> > m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
> > tmp$fitted1 <- fitted(m1)
> >
> > represents. The way I read this specification, an intercept and a
> > slope is estimated for each subject. Since each subject only has two
> > measurements, I would expect the Reaction scores to be completely
> > accounted for by the slopes and intercepts. Yet they are not: the
> > Residual variance estimate is 440.278.
> >
> > This is probably a stupid question, but I hope you will be kind enough
> > to humor me.
> >
> > Best,
> > Ista
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com



From bbolker at gmail.com  Tue Mar 27 23:42:03 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 27 Mar 2012 17:42:03 -0400
Subject: [R-sig-ME] [ADMB Users] Anova table for glmm.admb objects
In-Reply-To: <4F71EAFF.1000302@cict.fr>
References: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
	<4F70956C.1050009@gmail.com> <4F71EAFF.1000302@cict.fr>
Message-ID: <4F72342B.9000800@gmail.com>

  A couple of things.

  (1) can you update.packages() or re-install R2admb and see if that
helps with the R2admb/dat_write problem?

  (2) I would like to recant the Bolker et al decision tree somewhat.
At the time I wrote it, I was somewhat confused (!!!!) about the
distinction between the two difficulties with inference in the GLMM
situation.

  * model comparisons are better than curvature-based approaches
  * approaches that allow for finite-sample effects are better than
asymptotic approaches
  * there are two different kinds of finite size issues, one applying
more to LMMs (the residual variance parameter used to scale the
likelihood is estimated with uncertainty, hence we get an F statistic
for the null hypothesis) and the other to GLM(M)s (the 'numerator' of
the likelihood itself is only asymptotically normal)  -- this is
detailed a little more carefully at http://glmm.wikidot.com/faq (search
for "degrees of freedom"

  When we wrote the TREE paper I thought it might be OK to use the
classical experimental design 'denominator df' to correct for
finite-size samples, but I'm no longer sure this is a good idea.  In any
case, car::Anova(glmerfit) gives Wald *CHI-SQUARE* tests (not F tests),
so there's no advantage over drop1() except for computational speed.

  Hope that helps.

  Ben Bolker



On 12-03-27 12:29 PM, Thomas Merkling wrote:
> Dear all,
> 
> I'm a bit confused about last comments from Ben Bolker.
> I read Bolker et al., 2009 TREE and what I remembered is that it was
> advised to use Wald tests instead of LRT whent testing for fixed effects
> (and the contrary when testing for random effects). Hence, I'm surprised
> that Ben just said the contrary: is it just true for glmmADMB or for any
> packages ?
> 
> If we want to use more accurate approaches, but if possible not MCMC
> techniques, are there any possibilities with glmmADMB ?
> 
> I tried to install glmmADMB_0.7.2.10 from  bolker-mcmaster repository,
> but I got the following error message:
>  
> Installation d(es) package(s) dans ?C:/Users/thomas
> merkling/Documents/R/win-library/2.14?
> (car ?lib? n'est pas sp?cifi?)
> * installing *source* package 'glmmADMB' ...
> ** R
> ** data
> **  moving datasets to lazyload DB
> 
> Error : l'objet 'dat_write' n'est pas export? par 'namespace:R2admb'
> ERROR: lazydata failed for package 'glmmADMB'
> 
> * removing 'C:/Users/thomas merkling/Documents/R/win-library/2.14/glmmADMB'
> * restoring previous 'C:/Users/thomas
> merkling/Documents/R/win-library/2.14/glmmADMB'
> 
> 
> Thanks in advance !
> Thomas
> 
> 
> Le 26/03/2012 18:12, Ben Bolker a ?crit :
>> On 12-03-26 10:37 AM, Paula Rosewarne wrote:
>>> Dear All,
>>>
>>> I came across this posting (below) on a different list- how to get an
>>> Anova table from glmm.admb model objects- but I cannot get the
>>> car::Anova function to work for my model, or for the owl example I
>>> worked through from the glmmadmb package help notes, so I am guessing
>>> my code is wrong
>>>
>>> When I tried it with the owl example I get the following message, the
>>> same as when I try for my model:
>>>
>>>> car::Anova(fit_zipoiss)
>>> Error in data.frame(df, teststat, p) : arguments imply differing
>>> number of rows: 5, 6 In addition: Warning message: In Ops.factor(1,
>>> Nest) : | not meaningful for factors
>>>
>>>
>>>
>>> (I am using glmm.admb v0.7.2.4)
>>>
>>>
>>>
>>> Please could you advise, many thanks,
>>>
>>> Paula
>>>
>>  [cross-posted to ADMB users and r-sig-mixed because I didn't want to
>> write it twice]
>>
>>    Before I answer the question I want to strongly caution people about
>> using the Anova() (Wald) tests on glmmADMB output. I am generally of the
>> "give people the tools, let them do what they want" [in other words
>> "give them enough rope"] philosophy (which is why I tweaked glmmADMB to
>> allow car::Anova() to work), but Wald tests are the most approximate
>> approach to model comparison and inference.  For vanilla (non-mixed)
>> linear models they are identical to standard marginal F tests, but for
>> mixed/generalized/zero-inflated models they are sometimes very poor
>> approximations. Using anova() on alternative models instead gives a
>> likelihood ratio test, which is still approximate but is generally much
>> better (it relies on the normality of the likelihood itself, rather than
>> on the normality of the sampling distribution of the parameters).  It is
>> a bit tedious to use in glmmADMB at the moment because I haven't got the
>> drop1() functionality working yet, but it should be much more reliable.
>>  Even that is not perfect, though, because it does depend on the
>> approximate normality of the likelihood estimate; MCMC and parametric
>> bootstrap approaches are more accurate.
>>
>>    You need at least version 0.7.2.9.  I am currently struggling to get
>> the newest version to build properly on r-forge; in the meantime, below
>> is a helper function to check which versions are available where.  You
>> may want to use the optional argument  type="source" (as documented at
>> http://glmmadmb.r-forge.r-project.org) ...
>>
>>   In the meantime I've put 0.7.2.10 (source only, use type="source") at
>> the bolker-mcmaster repository and on the alternative r-forge location
>> (where it should show up within 24 hours).
>>
>> ## helper function to check availability
>> favail <- function(repos="r-forge.r-project.org",
>>                    pkg="glmmADMB",
>>                    ...) {
>>     hdr <- "http://"
>>     if (!substr(repos,1,8)==hdr) repos <- paste(hdr,repos,sep="")
>>     a <- available.packages(contriburl=contrib.url(repos),...)
>>     if (length(grep(pkg,rownames(a)))==0)
>>         stop(sprintf("%s unavailable at repos %s",pkg,repos))
>>     a[pkg,"Version"]
>> }
>>
>> favail()  ## unavailable
>> favail("www.math.mcmaster.ca/bolker/R")  ## 0.7.2.10
>> favail("glmmadmb.r-forge.r-project.org/repos")  ## 0.6.4
>>
>>>
>>> From the r-sig-mixed-models list: Le 20/03/2012 22:43, Ben Bolker a
>>> ?crit : On 12-03-20 02:32 PM,
>>>> Thomas Merkling wrote:
>>>>>>> Dear Ben and other list members,
>>>>>>>
>>>>>>> - Is there any way to produce a Anova/deviance table for a 
>>>>>>> model fitted with glmmADMB ? I used the Anova() function
>>>>>>> from the car library for glmer models, but it does not seem
>>>>>>> to work with glmmadmb (I'm using glmmADMB 0.7) and I would
>>>>>>> like only one p-value for each term and interaction and NOT
>>>>>>> one p-value for each level of the interaction.
>>> Ben's reply:
>>>> car::Anova() should work now -- I had to add a model.frame() and a 
>>>> df.residual() method for glmmadmb objects.  (The df.residual number
>>>> may be a little dodgy -- I'm not sure I counted the parameters
>>>> right -- but I don't think it's actually used for much by default,
>>>> cause you get Wald chi-square tests)
>>>
>>>
>>>
>>> Paula Rosewarne, PhD researcher, Faculty of Biological Sciences 
>>> Manton Building 8.17 Clarendon Way University of Leeds LS2 9JT UK
>>>
>>> Email: bspjr at leeds.ac.uk<mailto:bspjr at leeds.ac.uk> 
>>> _______________________________________________ Users mailing list 
>>> Users at admb-project.org 
>>> http://lists.admb-project.org/mailman/listinfo/users
>>
> 
> -- 
> ****NEW ADDRESS AND PHONE NUMBER ****
> 
> Thomas Merkling, Doctorant (PhD Student)
> Web Page <http://www.edb.ups-tlse.fr/Merkling-Thomas.html>
> 
> Laboratoire "Evolution et Diversit? Biologique" -EDB
> UMR 5174 - b?t 4R1 - bureau 33 RDC
> 
> Universit? Paul Sabatier Toulouse 3
> 118, route de Narbonne
> 31062 TOULOUSE Cedex O9, FRANCE
> 
> T?l: 33 5-61-55-67-56
> Fax: 33 5-61-55-73-27



From jfox at mcmaster.ca  Wed Mar 28 00:19:05 2012
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 27 Mar 2012 18:19:05 -0400
Subject: [R-sig-ME] [ADMB Users] Anova table for glmm.admb objects
In-Reply-To: <4F72342B.9000800@gmail.com>
References: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
	<4F70956C.1050009@gmail.com> <4F71EAFF.1000302@cict.fr>
	<4F72342B.9000800@gmail.com>
Message-ID: <web-400061457@cgpsrv2.cis.mcmaster.ca>

Dear Ben and Thomas,

As a brief addendum to Ben's helpful message, Anova.mer() in the development version of the car package on CRAN, which requires the development version of the pbkrtest package, can optionally compute F-tests for linear mixed models fit by REML, using Kenward-Roger df. The implementation may change before the current development version of car is released to CRAN.

Best,
 John

On Tue, 27 Mar 2012 17:42:03 -0400
 Ben Bolker <bbolker at gmail.com> wrote:
>   A couple of things.
> 
>   (1) can you update.packages() or re-install R2admb and see if that
> helps with the R2admb/dat_write problem?
> 
>   (2) I would like to recant the Bolker et al decision tree somewhat.
> At the time I wrote it, I was somewhat confused (!!!!) about the
> distinction between the two difficulties with inference in the GLMM
> situation.
> 
>   * model comparisons are better than curvature-based approaches
>   * approaches that allow for finite-sample effects are better than
> asymptotic approaches
>   * there are two different kinds of finite size issues, one applying
> more to LMMs (the residual variance parameter used to scale the
> likelihood is estimated with uncertainty, hence we get an F statistic
> for the null hypothesis) and the other to GLM(M)s (the 'numerator' of
> the likelihood itself is only asymptotically normal)  -- this is
> detailed a little more carefully at http://glmm.wikidot.com/faq (search
> for "degrees of freedom"
> 
>   When we wrote the TREE paper I thought it might be OK to use the
> classical experimental design 'denominator df' to correct for
> finite-size samples, but I'm no longer sure this is a good idea.  In any
> case, car::Anova(glmerfit) gives Wald *CHI-SQUARE* tests (not F tests),
> so there's no advantage over drop1() except for computational speed.
> 
>   Hope that helps.
> 
>   Ben Bolker
> 
> 
> 
> On 12-03-27 12:29 PM, Thomas Merkling wrote:
> > Dear all,
> > 
> > I'm a bit confused about last comments from Ben Bolker.
> > I read Bolker et al., 2009 TREE and what I remembered is that it was
> > advised to use Wald tests instead of LRT whent testing for fixed effects
> > (and the contrary when testing for random effects). Hence, I'm surprised
> > that Ben just said the contrary: is it just true for glmmADMB or for any
> > packages ?
> > 
> > If we want to use more accurate approaches, but if possible not MCMC
> > techniques, are there any possibilities with glmmADMB ?
> > 
> > I tried to install glmmADMB_0.7.2.10 from  bolker-mcmaster repository,
> > but I got the following error message:
> >  
> > Installation d(es) package(s) dans ?C:/Users/thomas
> > merkling/Documents/R/win-library/2.14?
> > (car ?lib? n'est pas sp?cifi?)
> > * installing *source* package 'glmmADMB' ...
> > ** R
> > ** data
> > **  moving datasets to lazyload DB
> > 
> > Error : l'objet 'dat_write' n'est pas export? par 'namespace:R2admb'
> > ERROR: lazydata failed for package 'glmmADMB'
> > 
> > * removing 'C:/Users/thomas merkling/Documents/R/win-library/2.14/glmmADMB'
> > * restoring previous 'C:/Users/thomas
> > merkling/Documents/R/win-library/2.14/glmmADMB'
> > 
> > 
> > Thanks in advance !
> > Thomas
> > 
> > 
> > Le 26/03/2012 18:12, Ben Bolker a ?crit :
> >> On 12-03-26 10:37 AM, Paula Rosewarne wrote:
> >>> Dear All,
> >>>
> >>> I came across this posting (below) on a different list- how to get an
> >>> Anova table from glmm.admb model objects- but I cannot get the
> >>> car::Anova function to work for my model, or for the owl example I
> >>> worked through from the glmmadmb package help notes, so I am guessing
> >>> my code is wrong
> >>>
> >>> When I tried it with the owl example I get the following message, the
> >>> same as when I try for my model:
> >>>
> >>>> car::Anova(fit_zipoiss)
> >>> Error in data.frame(df, teststat, p) : arguments imply differing
> >>> number of rows: 5, 6 In addition: Warning message: In Ops.factor(1,
> >>> Nest) : | not meaningful for factors
> >>>
> >>>
> >>>
> >>> (I am using glmm.admb v0.7.2.4)
> >>>
> >>>
> >>>
> >>> Please could you advise, many thanks,
> >>>
> >>> Paula
> >>>
> >>  [cross-posted to ADMB users and r-sig-mixed because I didn't want to
> >> write it twice]
> >>
> >>    Before I answer the question I want to strongly caution people about
> >> using the Anova() (Wald) tests on glmmADMB output. I am generally of the
> >> "give people the tools, let them do what they want" [in other words
> >> "give them enough rope"] philosophy (which is why I tweaked glmmADMB to
> >> allow car::Anova() to work), but Wald tests are the most approximate
> >> approach to model comparison and inference.  For vanilla (non-mixed)
> >> linear models they are identical to standard marginal F tests, but for
> >> mixed/generalized/zero-inflated models they are sometimes very poor
> >> approximations. Using anova() on alternative models instead gives a
> >> likelihood ratio test, which is still approximate but is generally much
> >> better (it relies on the normality of the likelihood itself, rather than
> >> on the normality of the sampling distribution of the parameters).  It is
> >> a bit tedious to use in glmmADMB at the moment because I haven't got the
> >> drop1() functionality working yet, but it should be much more reliable.
> >>  Even that is not perfect, though, because it does depend on the
> >> approximate normality of the likelihood estimate; MCMC and parametric
> >> bootstrap approaches are more accurate.
> >>
> >>    You need at least version 0.7.2.9.  I am currently struggling to get
> >> the newest version to build properly on r-forge; in the meantime, below
> >> is a helper function to check which versions are available where.  You
> >> may want to use the optional argument  type="source" (as documented at
> >> http://glmmadmb.r-forge.r-project.org) ...
> >>
> >>   In the meantime I've put 0.7.2.10 (source only, use type="source") at
> >> the bolker-mcmaster repository and on the alternative r-forge location
> >> (where it should show up within 24 hours).
> >>
> >> ## helper function to check availability
> >> favail <- function(repos="r-forge.r-project.org",
> >>                    pkg="glmmADMB",
> >>                    ...) {
> >>     hdr <- "http://"
> >>     if (!substr(repos,1,8)==hdr) repos <- paste(hdr,repos,sep="")
> >>     a <- available.packages(contriburl=contrib.url(repos),...)
> >>     if (length(grep(pkg,rownames(a)))==0)
> >>         stop(sprintf("%s unavailable at repos %s",pkg,repos))
> >>     a[pkg,"Version"]
> >> }
> >>
> >> favail()  ## unavailable
> >> favail("www.math.mcmaster.ca/bolker/R")  ## 0.7.2.10
> >> favail("glmmadmb.r-forge.r-project.org/repos")  ## 0.6.4
> >>
> >>>
> >>> From the r-sig-mixed-models list: Le 20/03/2012 22:43, Ben Bolker a
> >>> ?crit : On 12-03-20 02:32 PM,
> >>>> Thomas Merkling wrote:
> >>>>>>> Dear Ben and other list members,
> >>>>>>>
> >>>>>>> - Is there any way to produce a Anova/deviance table for a 
> >>>>>>> model fitted with glmmADMB ? I used the Anova() function
> >>>>>>> from the car library for glmer models, but it does not seem
> >>>>>>> to work with glmmadmb (I'm using glmmADMB 0.7) and I would
> >>>>>>> like only one p-value for each term and interaction and NOT
> >>>>>>> one p-value for each level of the interaction.
> >>> Ben's reply:
> >>>> car::Anova() should work now -- I had to add a model.frame() and a 
> >>>> df.residual() method for glmmadmb objects.  (The df.residual number
> >>>> may be a little dodgy -- I'm not sure I counted the parameters
> >>>> right -- but I don't think it's actually used for much by default,
> >>>> cause you get Wald chi-square tests)
> >>>
> >>>
> >>>
> >>> Paula Rosewarne, PhD researcher, Faculty of Biological Sciences 
> >>> Manton Building 8.17 Clarendon Way University of Leeds LS2 9JT UK
> >>>
> >>> Email: bspjr at leeds.ac.uk<mailto:bspjr at leeds.ac.uk> 
> >>> _______________________________________________ Users mailing list 
> >>> Users at admb-project.org 
> >>> http://lists.admb-project.org/mailman/listinfo/users
> >>
> > 
> > -- 
> > ****NEW ADDRESS AND PHONE NUMBER ****
> > 
> > Thomas Merkling, Doctorant (PhD Student)
> > Web Page <http://www.edb.ups-tlse.fr/Merkling-Thomas.html>
> > 
> > Laboratoire "Evolution et Diversit? Biologique" -EDB
> > UMR 5174 - b?t 4R1 - bureau 33 RDC
> > 
> > Universit? Paul Sabatier Toulouse 3
> > 118, route de Narbonne
> > 31062 TOULOUSE Cedex O9, FRANCE
> > 
> > T?l: 33 5-61-55-67-56
> > Fax: 33 5-61-55-73-27
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From aramidopsis at gmail.com  Wed Mar 28 02:27:28 2012
From: aramidopsis at gmail.com (Bert Harris)
Date: Tue, 27 Mar 2012 19:27:28 -0500
Subject: [R-sig-ME] Zero inflated GAMM
In-Reply-To: <CA+ZdaBJPSyYCsiGb_UYEK3DxLboBZd_fx4zYad8PjmYP_6eryw@mail.gmail.com>
References: <CA+ZdaBJPSyYCsiGb_UYEK3DxLboBZd_fx4zYad8PjmYP_6eryw@mail.gmail.com>
Message-ID: <CA+ZdaBJU6JuQUyq5xW05SdReAAGhb-6gh_ZFMArFe_7LcjgZuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120327/b6d94013/attachment-0001.pl>

From ivanalaman at yahoo.com.br  Sun Mar 25 22:24:48 2012
From: ivanalaman at yahoo.com.br (Ivan Bezerra Allaman)
Date: Sun, 25 Mar 2012 13:24:48 -0700 (PDT)
Subject: [R-sig-ME] Help ordinal mixed model!
Message-ID: <1332707088.81464.YahooMailNeo@web161804.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120325/e2546b7b/attachment-0001.pl>

From emre_marmara2002 at yahoo.com  Mon Mar 26 10:33:24 2012
From: emre_marmara2002 at yahoo.com (emre karaman)
Date: Mon, 26 Mar 2012 01:33:24 -0700 (PDT)
Subject: [R-sig-ME] question on MCMCglmm
Message-ID: <1332750804.39650.YahooMailClassic@web161405.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120326/5aca9b7e/attachment-0001.pl>

From hannatenbrink at gmail.com  Tue Mar 27 14:58:57 2012
From: hannatenbrink at gmail.com (Hanna ten Brink)
Date: Tue, 27 Mar 2012 14:58:57 +0200
Subject: [R-sig-ME] Dispersion parameter negbin1 in glmmADMB
Message-ID: <CAFVkfMWebic-2RWAOBxHfRK3XyjZGDJiy+cNtpnd4M=5LsKXow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120327/69f24d6e/attachment-0001.pl>

From j.hadfield at ed.ac.uk  Wed Mar 28 10:34:21 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 28 Mar 2012 09:34:21 +0100
Subject: [R-sig-ME] question on MCMCglmm
In-Reply-To: <1332750804.39650.YahooMailClassic@web161405.mail.bf1.yahoo.com>
References: <1332750804.39650.YahooMailClassic@web161405.mail.bf1.yahoo.com>
Message-ID: <20120328093421.60182fymqz7e71gk@www.staffmail.ed.ac.uk>

Hi,

The prior for the fixed effects is (multivariate) normal, specified as:

prior=list(B=list(mu=mu, V=V))

where mu are your prior means, and V your prior (co)variances. The  
default is mu=0 and V = I*1e+10: depending on the scale of your data  
this is probably close to uniform.

The random effects also have a (multivariate) normal prior, determined  
by the estimated variances. You place a hyper-prior on these variances  
by specifying the G element in the prior.

Cheers,

Jarrod


Quoting emre karaman <emre_marmara2002 at yahoo.com> on Mon, 26 Mar 2012  
01:33:24 -0700 (PDT):

> Dear Dr.,
> For one-way anova model I assume a uniform distribution for overall  
> mean, that is p(mu)=1, and a normal distribution for random effects.  
> However, prior specification for
> overall mean
> is not clear, at least yet for me. Could you please tell the way to  
> overcome this problem.
> Best Wishes.?
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From dmcastil at umail.iu.edu  Wed Mar 28 13:02:41 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Wed, 28 Mar 2012 07:02:41 -0400
Subject: [R-sig-ME] Dispersion parameter negbin1 in glmmADMB
In-Reply-To: <CAFVkfMWebic-2RWAOBxHfRK3XyjZGDJiy+cNtpnd4M=5LsKXow@mail.gmail.com>
References: <CAFVkfMWebic-2RWAOBxHfRK3XyjZGDJiy+cNtpnd4M=5LsKXow@mail.gmail.com>
Message-ID: <CAMmHrnyz2sST2WbbLbgW-wftU6qRKSRqWNoMr9wRPx9tFMBaeQ@mail.gmail.com>

HI Hanna,

It may be very well that GLM and glmm ADMB calculate the
overdispersion parameter in a different way, but the quasipoisson and
negative binomial are not the same.
Quasipoisson uses a mean regression function (like normal poisson) but
leaves the overdispersion parameter unrestricted. Negative binomial
can be represented as a gamma mixture of poisson distributions.

The pscl package has some documentation explaining different types of
count models. It is called: "Regression models for count data in R".
It is useful to help understand count models.

Dean

On Tue, Mar 27, 2012 at 8:58 AM, Hanna ten Brink
<hannatenbrink at gmail.com> wrote:
> Dear R users
>
> I am trying to understand how the dispersion parameter in the glmmADBM
> package is calculated for the negbin1 family.
> Is it correct that the negbin1 family is the same as the quasipoisson
> family?
> Because when I run a simple model in GLM(family=quasipoisson) or in
> glmmADMB(family=negbin) for the Owls-dataset, it gives different dispersion
> parameters.
>
> e.g.
>
> ADBM_binom1 <- glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+
> offset(logBroodSize),
> data=Owls,
> zeroInflation=FALSE,
> family="nbinom1")
>
> Dispersion parameter=8.2014
>
> GLM_quasipois <- glm(NCalls~(FoodTreatment+ArrivalTime)*SexParent+
> offset(logBroodSize),
> data=Owls,
> family=quasipoisson)
>
> Dispersion parameter= 6.259856
>
> Does this mean that the negbin1 and quasipoisson family are not the same?
> Or does the glmmADMB package calculates the dispersion parameter in a
> different way?
>
> Thank you!
>
> Hanna ten Brink
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Wed Mar 28 15:36:05 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 28 Mar 2012 13:36:05 +0000 (UTC)
Subject: [R-sig-ME] Dispersion parameter negbin1 in glmmADMB
References: <CAFVkfMWebic-2RWAOBxHfRK3XyjZGDJiy+cNtpnd4M=5LsKXow@mail.gmail.com>
	<CAMmHrnyz2sST2WbbLbgW-wftU6qRKSRqWNoMr9wRPx9tFMBaeQ@mail.gmail.com>
Message-ID: <loom.20120328T152852-653@post.gmane.org>

Dean Castillo <dmcastil at ...> writes:

> 
> HI Hanna,
> 
> It may be very well that GLM and glmm ADMB calculate the
> overdispersion parameter in a different way, but the quasipoisson and
> negative binomial are not the same.
> Quasipoisson uses a mean regression function (like normal poisson) but
> leaves the overdispersion parameter unrestricted. Negative binomial
> can be represented as a gamma mixture of poisson distributions.

  Yes, but: the negative binomial 'type I', which is fitted here,
is parameterized so that it has the same expected mean-variance
relationship as the quasi-Poisson model, variance=phi*mean.

  Using GLM/quasi-Poisson fits the parameters by iteratively
reweighted least squares (IRLS), then calculates the dispersion
parameter according to

sum(residuals(g2,"pearson")^2)/df.residual(g2)

  Using glmmADMB with type="nbinom1" does a maximum-likelihood
fit to a full model using the aforementioned distribution.
I'm slightly but not terribly surprised that the results are
as different as they are.  I believe (but can't prove right now)
that the max. likelihood and IRLS estimates are the same as long
as you stay in the exponential family, but I think nbinom1 is
*not* in the exponential family.

  Also, when I run glmmADMB I get warning about 

Estimated covariance matrix may not be positive definite

which suggests the possibility that glmmADMB might have
gotten stuck at not-quite-the-optimum value.

> 
> The pscl package has some documentation explaining different types of
> count models. It is called: "Regression models for count data in R".
> It is useful to help understand count models.
> 
> Dean
> 
> On Tue, Mar 27, 2012 at 8:58 AM, Hanna ten Brink
> <hannatenbrink at ...> wrote:
> > Dear R users
> >
> > I am trying to understand how the dispersion parameter in the glmmADBM
> > package is calculated for the negbin1 family.
> > Is it correct that the negbin1 family is the same as the quasipoisson
> > family?
> > Because when I run a simple model in GLM(family=quasipoisson) or in
> > glmmADMB(family=negbin) for the Owls-dataset, it gives different dispersion
> > parameters.
> >
> > e.g.
> >
> > ADBM_binom1 <- glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+
> > offset(logBroodSize),
> > data=Owls,
> > zeroInflation=FALSE,
> > family="nbinom1")
> >
> > Dispersion parameter=8.2014
> >
> > GLM_quasipois <- glm(NCalls~(FoodTreatment+ArrivalTime)*SexParent+
> > offset(logBroodSize),
> > data=Owls,
> > family=quasipoisson)
> >
> > Dispersion parameter= 6.259856
> >
> > Does this mean that the negbin1 and quasipoisson family are not the same?
> > Or does the glmmADMB package calculates the dispersion parameter in a
> > different way?
> >



From bbolker at gmail.com  Wed Mar 28 19:36:11 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 28 Mar 2012 13:36:11 -0400
Subject: [R-sig-ME] coefplot2/glmmADMB
Message-ID: <4F734C0B.3080702@gmail.com>


  For general information:

  I am still struggling to get R-forge to build everything.  glmmADMB
0.7.2.11 , and coefplot2 0.1.3 (on which it generally depends, although
I have removed the dependence for the moment) should be available on the
McMaster repository (via
install.packages(...,repos="http://www.math.mcmaster.ca/bolker/R",type="source")
for now.  I will get stuff working on R-forge as fast as I can, but
remote debugging is a big nuisance.

  Do let me know if you experience difficulty with installation
(continue to direct general questions to the lists; generally
r-sig-mixed-models is best for GLMM- or R-focused questions, ADMB list
should be reserved for technical ADMB questions).

  Ben Bolker



From rajasimhan at gmail.com  Wed Mar 28 20:22:34 2012
From: rajasimhan at gmail.com (Rajasimhan Rajagovindan)
Date: Wed, 28 Mar 2012 13:22:34 -0500
Subject: [R-sig-ME] discrepancy between paired t test and glht on lme models
Message-ID: <CAGf6ir4kr7qij4U6a83zvMi=h1xjBMDV=eeP4yGC+H=HdkQ6PQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/6a45811f/attachment-0001.pl>

From ramos.grad.student at gmail.com  Wed Mar 28 21:52:05 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 28 Mar 2012 12:52:05 -0700
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <4F734C0B.3080702@gmail.com>
References: <4F734C0B.3080702@gmail.com>
Message-ID: <CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/862c7d45/attachment-0001.pl>

From agalecki at umich.edu  Wed Mar 28 22:49:38 2012
From: agalecki at umich.edu (Andrzej)
Date: Wed, 28 Mar 2012 16:49:38 -0400
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
References: <4F734C0B.3080702@gmail.com>
	<CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
Message-ID: <4F737962.6020804@umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/3efbc616/attachment-0001.pl>

From ramos.grad.student at gmail.com  Wed Mar 28 22:53:28 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 28 Mar 2012 13:53:28 -0700
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <4F737962.6020804@umich.edu>
References: <4F734C0B.3080702@gmail.com>
	<CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
	<4F737962.6020804@umich.edu>
Message-ID: <CAHawB9sDaJM3bqKCiVTSO1xCkwxX8azPgBWGBAKvwJxfd99yQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/0771161f/attachment-0001.pl>

From antoine.tardif at usherbrooke.ca  Wed Mar 28 22:54:51 2012
From: antoine.tardif at usherbrooke.ca (Antoine TARDIF)
Date: Wed, 28 Mar 2012 16:54:51 -0400
Subject: [R-sig-ME] structure of a lmer code
Message-ID: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/a094e9e7/attachment-0001.pl>

From A.Robinson at ms.unimelb.edu.au  Wed Mar 28 23:29:23 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 29 Mar 2012 08:29:23 +1100
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <CAHawB9sDaJM3bqKCiVTSO1xCkwxX8azPgBWGBAKvwJxfd99yQA@mail.gmail.com>
References: <4F734C0B.3080702@gmail.com>
	<CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
	<4F737962.6020804@umich.edu>
	<CAHawB9sDaJM3bqKCiVTSO1xCkwxX8azPgBWGBAKvwJxfd99yQA@mail.gmail.com>
Message-ID: <20120328212923.GW56999@ms.unimelb.edu.au>

I suspect that the problem might be that you're using R 2.12.  Time to
upgrade!  Then try again.

Cheers

Andrew

On Wed, Mar 28, 2012 at 01:53:28PM -0700, Antonio P. Ramos wrote:
> Hi Andrzej,
> 
> I doesn't work:
> 
> > install.packages("lme4.0", repos="http://R-Forge.R-project.org")
> Installing package(s) into ?/Users/tournillon/Library/R/2.12/library?
> (as ?lib? is unspecified)
> Warning in install.packages :
>   cannot open: HTTP status was '404 Not Found'
> Warning in install.packages :
>   cannot open: HTTP status was '404 Not Found'
> Warning in install.packages :
>   unable to access index for repository
> http://R-Forge.R-project.org/bin/macosx/leopard/contrib/2.12
> Warning in install.packages :
>   package ?lme4.0? is not available
> 
> On Wed, Mar 28, 2012 at 1:49 PM, Andrzej <agalecki at umich.edu> wrote:
> 
> >  Hi Antonio,
> >
> > lme4.0 is not available from cran.
> >
> > Try
> >
> > install.packages("lme4.0", repos="http://R-Forge.R-project.org"<http://R-Forge.R-project.org>
> > )
> >
> > You are also saying that you have lme4.
> >
> > Note that currently there are two lme4.  The 'old'  and 'new' one.
> >
> > Old lme4 is available at cran and will become deprecated in near future.
> >
> > New can be installed using:
> >
> > install.packages("lme4", repos="http://R-Forge.R-project.org"<http://R-Forge.R-project.org>
> > )
> >
> > Hope it helps
> >
> > Andrzej
> >
> >
> > On 3/28/2012 3:52 PM, Antonio P. Ramos wrote:
> >
> > Hi Ben,
> >
> > I am trying to install your package but it is not working:
> >
> >
> >  install.packages("coefplot2",repos="http://www.math.mcmaster.ca/bolker/R
> >
> >  ",type="source")
> > Installing package(s) into ?/Users/tournillon/Library/R/2.12/library?
> > (as ?lib? is unspecified)
> > Warning: dependency ?lme4.0? is not available
> > trying URL 'http://www.math.mcmaster.ca/bolker/R/src/contrib/coefplot2_0.1.3.tar.gz'
> > Content type 'application/x-gzip' length 616170 bytes (601 Kb)
> > opened URL
> > ==================================================
> > downloaded 601 Kb
> >
> > ERROR: dependency ?lme4.0? is not available for package ?coefplot2?
> > * removing ?/Users/tournillon/Library/R/2.12/library/coefplot2?
> >
> >
> > Then I tried
> >
> > install.packages("lme4.0")
> > Installing package(s) into ?/Users/tournillon/Library/R/2.12/library?
> > (as ?lib? is unspecified)
> > Warning message:
> > In getDependencies(pkgs, dependencies, available, lib) :
> >   package ?lme4.0? is not available
> >
> > but it does not work either. Am I missing something? I do have lme4
> > installed though.
> >
> >
> > On Wed, Mar 28, 2012 at 10:36 AM, Ben Bolker <bbolker at gmail.com> <bbolker at gmail.com> wrote:
> >
> >
> >   For general information:
> >
> >  I am still struggling to get R-forge to build everything.  glmmADMB
> > 0.7.2.11 , and coefplot2 0.1.3 (on which it generally depends, although
> > I have removed the dependence for the moment) should be available on the
> > McMaster repository (via
> > install.packages(...,repos="http://www.math.mcmaster.ca/bolker/R
> > " <http://www.math.mcmaster.ca/bolker/R>,type="source")
> > for now.  I will get stuff working on R-forge as fast as I can, but
> > remote debugging is a big nuisance.
> >
> >  Do let me know if you experience difficulty with installation
> > (continue to direct general questions to the lists; generally
> > r-sig-mixed-models is best for GLMM- or R-focused questions, ADMB list
> > should be reserved for technical ADMB questions).
> >
> >  Ben Bolker
> >
> > _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >  	[[alternative HTML version deleted]]
> >
> >
> >
> >
> > _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 

> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Andrew Robinson  
Deputy Director, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/



From ramos.grad.student at gmail.com  Wed Mar 28 23:58:32 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 28 Mar 2012 14:58:32 -0700
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <CAHawB9t-JULGDqkLOKA-mJYqQMMaUqUYPGHpsdMWwBQo=k8bww@mail.gmail.com>
References: <4F734C0B.3080702@gmail.com>
	<CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
	<4F73710D.2070508@gmail.com>
	<CAHawB9uNQgvNK1udTEVh1+TWpYKOJ7ihMymnn9SgX+Z1ApfVqA@mail.gmail.com>
	<4F73820E.2040902@gmail.com>
	<CAHawB9uE5DLFbTknYTy_DaMRR4gcFb=PF96nYFCJ-Yf0MfPL7Q@mail.gmail.com>
	<4F7385E0.1000803@gmail.com>
	<CAHawB9t-JULGDqkLOKA-mJYqQMMaUqUYPGHpsdMWwBQo=k8bww@mail.gmail.com>
Message-ID: <CAHawB9vxP=PauEypYnN1c2qdjz4Wc5FjhxCOWtR9K7r6gaCPpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/48751b61/attachment-0001.pl>

From istazahn at gmail.com  Thu Mar 29 00:46:34 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 28 Mar 2012 18:46:34 -0400
Subject: [R-sig-ME] structure of a lmer code
In-Reply-To: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
Message-ID: <CA+vqiLGpcosCxdtOHktddeDscfTA1r-2VmQFyeJ_psdBp8Q-rg@mail.gmail.com>

Hi Antoine,

I think you want

fm2<-lmer(log(y)~-1+x+(-1+x|group), na.action="na.omit", data=...)

no?

Best,
Ista
2012/3/28 Antoine TARDIF <antoine.tardif at usherbrooke.ca>:
> Dear all,
>
> I would like to fit a multilevel linear model, with varying slope but
> with intercepts fixed at zero (in my experiment, all the samples have
> the same value at time=0).
>
> I have both nested and non-nested factors, but in a first step, we
> would like to fit a lmer model "fm2" equivalent to this lme model
> "fm1" :
>
> library(nlme)
> fm1<-lme(log(y)~x, random=~-1+x|group, na.action="na.omit", data=...)
>
> I tried this code for the lmer function :
> library(lme4)
> fm2<-lmer(log(y)~-1+x+(-1+y|group), na.action="na.omit", data=...)
>
> 1. Instead of providing similar results to fm1, fm2 results do not
> make sense. Is there a mistake in the structure of the fm2 code ?
>
> 2. I also have an other question :
>
> ?> coef(fm1) works, but
> ?> coef(fm2) shows this error message : "unable to align random and
> fixed effects"
>
> What does it mean ?
>
> If someone could help me, thanks a lot in advance..
>
> Antoine Tardif
>
> --
> ? ? ?Antoine TARDIF
> ? D?partement de Biologie
> ? Universit? de Sherbrooke
> ? Sherbrooke (Qc)
> ? J1K 2R1 Canada
>
> ? Bureau D5-0204
> ? (+ 1) 819 821 8000 poste 61928
> ? antoine.tardif at usherbrooke.ca
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kfrost at wisc.edu  Thu Mar 29 00:54:59 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Wed, 28 Mar 2012 17:54:59 -0500
Subject: [R-sig-ME] structure of a lmer code
In-Reply-To: <76c0af142be45.4f7396ad@wiscmail.wisc.edu>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
	<CA+vqiLGpcosCxdtOHktddeDscfTA1r-2VmQFyeJ_psdBp8Q-rg@mail.gmail.com>
	<76c0af142be45.4f7396ad@wiscmail.wisc.edu>
Message-ID: <7690ee202c316.4f735073@wiscmail.wisc.edu>

I think the equivalent to fm1 is actually 

fm2<-lmer(log(y)~1+x+(-1+x|group), na.action="na.omit", data=...)


On 03/28/12, Ista Zahn   wrote:
> Hi Antoine,
> 
> I think you want
> 
> fm2<-lmer(log(y)~-1+x+(-1+x|group), na.action="na.omit", data=...)
> 
> no?
> 
> Best,
> Ista
> 2012/3/28 Antoine TARDIF <antoine.tardif at usherbrooke.ca>:
> > Dear all,
> >
> > I would like to fit a multilevel linear model, with varying slope but
> > with intercepts fixed at zero (in my experiment, all the samples have
> > the same value at time=0).
> >
> > I have both nested and non-nested factors, but in a first step, we
> > would like to fit a lmer model "fm2" equivalent to this lme model
> > "fm1" :
> >
> > library(nlme)
> > fm1<-lme(log(y)~x, random=~-1+x|group, na.action="na.omit", data=...)
> >
> > I tried this code for the lmer function :
> > library(lme4)
> > fm2<-lmer(log(y)~-1+x+(-1+y|group), na.action="na.omit", data=...)
> >
> > 1. Instead of providing similar results to fm1, fm2 results do not
> > make sense. Is there a mistake in the structure of the fm2 code ?
> >
> > 2. I also have an other question :
> >
> > ?> coef(fm1) works, but
> > ?> coef(fm2) shows this error message : "unable to align random and
> > fixed effects"
> >
> > What does it mean ?
> >
> > If someone could help me, thanks a lot in advance..
> >
> > Antoine Tardif
> >
> > --
> > ? ? ?Antoine TARDIF
> > ? D?partement de Biologie
> > ? Universit? de Sherbrooke
> > ? Sherbrooke (Qc)
> > ? J1K 2R1 Canada
> >
> > ? Bureau D5-0204
> > ? (+ 1) 819 821 8000 poste 61928
> > ? antoine.tardif at usherbrooke.ca
> >
> >
> > ? ? ? ?[[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rlevy at ucsd.edu  Thu Mar 29 04:36:32 2012
From: rlevy at ucsd.edu (Levy, Roger)
Date: Thu, 29 Mar 2012 02:36:32 +0000
Subject: [R-sig-ME] Conflicting p-values from pvals.fnc
In-Reply-To: <CAE1hoOpf8aLY61W48h_p7T=oDBhaiZF-mrrrQHEpSw3mWnT9sQ@mail.gmail.com>
References: <CAPB_MR1-ZZHD93Vya_Mg_60HppF5Sg3rSma_1cS3KjqHd3mwHw@mail.gmail.com>
	<CAE1hoOpf8aLY61W48h_p7T=oDBhaiZF-mrrrQHEpSw3mWnT9sQ@mail.gmail.com>
Message-ID: <69314B8E-09C0-4603-8B5F-7DF05C3CC0DD@ucsd.edu>

Hi all,

This example has gotten me pretty confused about how the "weights" argument works for lmer.  I'd always assumed that setting a weight of k for an observation would cause lmer to act as if it had seen k replicates of that observation (i.e., the contribution of the observation to the likelihood would be taken to the k-th power).  After reading this query I found the following post that they are "precision weights not sampling weights":

http://tolstoy.newcastle.edu.au/R/e17/help/12/01/2099.html

I'm not sure what that means -- was my interpretation one of "sampling weights"?

Regardless, I'm noticing what seems to me to be inconsistent behavior in how setting the weights argument affects the t statistic in lmer() output and how the output of pvals.fnc() is affected.  I'm including an example below with a fixed effect of "x" and a random intercept of "a": the higher one sets the weights, the larger the t statistic for x becomes (which is what I'd originally expected given my assumptions about the weights semantics), but the broader the posterior on x becomes in the MCMC output.  This doesn't seem right, does it?  (I also don't understand why the estimate of the random-intercept variance but not the residual variance reported in the lmer output changes.)

> set.seed(1)
> dat <- data.frame(x=rep(c(0,1),each=4),a=factor(rep(c("a","b"),4)),w=1)
> dat$y <- with(dat,10*x+10*(a=="a") + rnorm(8))
> print(m1 <- lmer(y~x+(1|a),dat,weights=1*w))
Linear mixed model fit by REML 
Formula: y ~ x + (1 | a) 
   Data: dat 
   AIC   BIC logLik deviance REMLdev
 32.32 32.64 -12.16    29.97   24.32
Random effects:
 Groups   Name        Variance Std.Dev.
 a        (Intercept) 44.09718 6.64057 
 Residual              0.87763 0.93682 
Number of obs: 8, groups: a, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)   5.0792     4.7186   1.076
x            10.1045     0.6624  15.254

Correlation of Fixed Effects:
  (Intr)
x -0.070
> pvals.fnc(m1)
$fixed
            Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)    5.079    5.037     -1.553      11.32 0.1004   0.3231
x             10.104   10.110      4.917      15.28 0.0038   0.0000

$random
    Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1        a (Intercept)   6.6406     2.6325   3.3750     0.0000     7.6330
2 Residual               0.9368     2.8649   3.2042     0.8809     6.0746

> print(m2 <- lmer(y~x+(1|a),dat,weights=100*w))
Linear mixed model fit by REML 
Formula: y ~ x + (1 | a) 
   Data: dat 
   AIC   BIC logLik deviance REMLdev
 69.17 69.48 -30.58    66.81   61.17
Random effects:
 Groups   Name        Variance Std.Dev.
 a        (Intercept) 0.44097  0.66406 
 Residual             0.87763  0.93682 
Number of obs: 8, groups: a, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)  5.07921    0.47185   10.76
x           10.10449    0.06624  152.54

Correlation of Fixed Effects:
  (Intr)
x -0.070
> pvals.fnc(m2)
$fixed
            Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)    5.079     5.38    -23.816      38.45 0.3434        0
x             10.104    10.11      4.115      16.06 0.0068        0

$random
    Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1        a (Intercept)   0.6641     5.8216  15.7201     0.0000    61.7422
2 Residual               0.9368    23.8808  30.8847     5.2868    71.7694

> print(m3 <- lmer(y~x+(1|a),dat,weights=w/100))
Linear mixed model fit by REML 
Formula: y ~ x + (1 | a) 
   Data: dat 
    AIC    BIC logLik deviance REMLdev
 -4.516 -4.199  6.258   -6.868  -12.52
Random effects:
 Groups   Name        Variance   Std.Dev.
 a        (Intercept) 4409.71731 66.40570
 Residual                0.87763  0.93682
Number of obs: 8, groups: a, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)    5.079     47.187   0.108
x             10.104      6.624   1.525

Correlation of Fixed Effects:
  (Intr)
x -0.070
> pvals.fnc(m3)
$fixed
            Estimate MCMCmean HPD95lower HPD95upper pMCMC Pr(>|t|)
(Intercept)    5.079    5.053    -0.8904      11.28 0.085   0.9178
x             10.104   10.107     5.3060      15.21 0.002   0.1780

$random
    Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1        a (Intercept)  66.4057     2.6379   3.1098     1.1580     6.5406
2 Residual               0.9368     0.2828   0.3121     0.1214     0.5694


I'd be glad to be enlightened...!

Best

Roger



On Mar 26, 2012, at 10:35 AM PDT, Geoff Brookshire wrote:

> Hi listers,
> 
> If you get p-vals using Wald chi-square tests with lme4::anova, they look
> pretty close to the pMCMC output.
> fm.1 <- lmer(y ~ block * condition + (1 | as.factor(subject)),
>             weights = weights, REML = FALSE)
> fm.2 <- lmer(y ~ block + condition + (1 | as.factor(subject)),
>             weights = weights, REML = FALSE)
> anova(fm.1, fm.2)
> 
> This gives p = .35 for the block*condition interaction. For comparison,
> pvals.fnc gave pMCMC = .3 and p(<|t|) < .001. So it looks like p-vals
> derived from t-tests are just way off.
> 
> It seems to me like we should just totally ignore the P(<|t|) output. Does
> anyone who knows more about how these work think otherwise?
> 
> -- geoff
> 
> 
> On Mon, Mar 19, 2012 at 3:25 PM, Tom Gijssels <tom.gijssels at gmail.com>wrote:
> 
>> Dear R-listers,
>> 
>> I'm trying to run a mixed effect model using the lmer() function and have
>> run into some issues in interpreting the p-values generated by
>> pvals.fnc(). The design is a between-subjects design, with two fixed
>> effects (condition & block; each with two levels), and one random effect
>> (subject). Additionally, I have a set of weights that I want to include.
>> 
>> When looking at the pvals.fnc() output,there appears to be a large
>> discrepancy between the pMCMC values and the t-statistic p-values. Whereas
>> one of the main effects and the interaction are far from significant
>> judging by the pMCMC values, they are highly significant when looking at
>> the t-statistic p-values (e.g. Condition: pMCMC = 0.2294; Pr(>|t|) = 0.0000
>> & Condition*Block: pMCMC = 0.3296; Pr(>|t|) = 0.0000) . I have read that
>> the t-statistic based p-values are less conservative, but the difference
>> between these two values seems really extreme.
>> 
>> Below some code that simulates the model and the data. The original data
>> set has two precise characteristics that might influence the results, so I
>> tried to simulate those characteristics in the mock data. That is: 1)
>> there's fewer observations in block A than in block B; and 2) the weights
>> for observations in block A generally are lower than those for block B.
>> 
>> Running this code reproduces the original observation of conflicting pMCMC
>> and p-T-test values. However, when excluding the weights argument from the
>> lmer model, these values seem to converge, suggesting that the weights
>> specification might be underlying these problems.
>> 
>> In short, my question is whether anyone knows why these values diverge and
>> what I could do to address this issue.
>> 
>> Many thanks in advance!
>> 
>> Tom
>> 
>> block <- as.factor(c(rep('a', times = 20), rep('b', times = 200)))
>> condition <- as.factor(c(rep(c('x', 'y'), each = 10), rep(c('x','y'), each
>> = 100)))
>> contrasts(block) <- c(-0.5, 0.5)
>> contrasts(condition) <- c(-0.5, 0.5)
>> 
>> subject <- c(rep(1:4, each = 5), rep(1:4, each = 50))
>> 
>> intercept <- 100
>> block.me <- 20
>> condition.me <- 30
>> err <- rnorm(length(block), sd = 20)
>> weights <- c(rep(1, times = 20), rep(10, times = 200))
>> 
>> y <- intercept + ifelse(block == 'a', block.me, 0) + ifelse(condition ==
>> 'x', condition.me, 0) +
>>   ifelse(block == 'a' & condition == 'x', 30, 0) + (subject * 10) + err
>> 
>> 
>> fm.1 <- lmer(y ~ block * condition + (1 | as.factor(subject)),
>>            weights = weights, REML = FALSE)
>> fm.1.mcmc <- pvals.fnc(fm.1, addPlot=F)
>> 
>>       [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

Roger Levy                      Email: rlevy at ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://idiom.ucsd.edu/~rlevy



From istazahn at gmail.com  Thu Mar 29 05:02:58 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 28 Mar 2012 23:02:58 -0400
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CA+vqiLGVyQpkXHic_spquqWNg3-JMxEVQk696Oy0OVxUsQREEg@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAFEqCdzxmBgdFGLN6Hbhsz1BF278-JE11vbkjs27ZQW2=Lztvg@mail.gmail.com>
	<CA+vqiLGVyQpkXHic_spquqWNg3-JMxEVQk696Oy0OVxUsQREEg@mail.gmail.com>
Message-ID: <CA+vqiLHsJPFXHFkTRSdXjpX=DtvL+quq4bFVoP66K08DeSt7ZA@mail.gmail.com>

Hello again,

Sorry for bringing this up again. The thing is that a statistician
consulting with my research group insists that you cannot have both
random intercepts and random slopes when there are only two
observations per group. Clearly I can fit such a model using lmer(),
but this only serves to convince my local statistician that "R is
doing something strange". I suspect that this is a hopelessly vague
question, but is R doing something strange? Or is my statistician
incorrect in claiming that you can't fit both random intercepts and
random slopes with only two observations per group?

Again, I realize this is not a great question, but I would really
appreciate any thoughts on the matter.

Best,
Ista
On Tue, Mar 27, 2012 at 2:55 PM, Ista Zahn <istazahn at gmail.com> wrote:
> Thank you Greg, that helps.
>
> -Ista
>
> On Tue, Mar 27, 2012 at 11:32 AM, Greg Snow <538280 at gmail.com> wrote:
>>
>> Yes, each person has their own slope and intercept estimated, however
>> the slope and intercept are not determined solely by the 2 data points
>> for that person, but also are affected by the slope and intercept
>> estimates across all subjects (this is why lmer gives value beyond
>> lmList).
>>
>> You can see this if you refit using the nlme package (only because it
>> has the augPred function which has not been implemented in lme4 yet):
>>
>> library(nlme)
>> m2 <- lme( Reaction ~ Days, data=tmp, random=~Days|Subject)
>> plot(augPred(m2, ~Days, level=c(0,1)))
>>
>> comparing the m2 model to your m1 gives the same fixed effects, but
>> slightly different random effects (I probably did not do something
>> that was needed to make the models exactly the same) but is probably
>> close enough.
>>
>> Look at the plot and you will see the fixed effects line, the line for
>> each subject that includes the random effects, and the data. ?The line
>> for the individual subjects are pulled slightly towards the fixed
>> effects line and so does not hit the 2 points exactly. ?This shows how
>> the estimate of each individuals values are influenced by the overall
>> fit.
>>
>>
>> On Mon, Mar 26, 2012 at 8:18 PM, Ista Zahn <istazahn at gmail.com> wrote:
>> > Hi all,
>> >
>> > I'm trying to understand what the residual variance in this model:
>> >
>> > tmp <- subset(sleepstudy, Days == 1 | Days == 9)
>> > m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
>> > tmp$fitted1 <- fitted(m1)
>> >
>> > represents. The way I read this specification, an intercept and a
>> > slope is estimated for each subject. Since each subject only has two
>> > measurements, I would expect the Reaction scores to be completely
>> > accounted for by the slopes and intercepts. Yet they are not: the
>> > Residual variance estimate is 440.278.
>> >
>> > This is probably a stupid question, but I hope you will be kind enough
>> > to humor me.
>> >
>> > Best,
>> > Ista
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com



From reinhold.kliegl at gmail.com  Thu Mar 29 07:45:43 2012
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 29 Mar 2012 07:45:43 +0200
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
Message-ID: <CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>

But why is Greg Snow's response inadequate?

Restating his argument:  In an LMM we are not estimating individual
random effects (means, slopes) and individual residuals, but variance
of random effects and variance of residuals. So there can be
differences between a subject's observed random effect and random
slope  and conditional modes of the distribution of the random effects
(i.e., the point of maximum density), given the observed data and
evaluated at the parameter estimates.

I think your statistician's answer is a good argument that you must
not treat conditional modes as independent observations in a
subsequent analyses. For example, we showed with simulations that
correlations between conditional modes of slopes and intercepts are
larger than the correlation parameter estimated in the LMM (Kliegl,
Masson, & Richer, Visual Cognition, 2010).

Reinhold Kliegl

--
Reinhold Kliegl
http://read.psych.uni-potsdam.de/pmr2

On Tue, Mar 27, 2012 at 4:18 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi all,
>
> I'm trying to understand what the residual variance in this model:
>
> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
> tmp$fitted1 <- fitted(m1)
>
> represents. The way I read this specification, an intercept and a
> slope is estimated for each subject. Since each subject only has two
> measurements, I would expect the Reaction scores to be completely
> accounted for by the slopes and intercepts. Yet they are not: the
> Residual variance estimate is 440.278.
>
> This is probably a stupid question, but I hope you will be kind enough
> to humor me.
>
> Best,
> Ista
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From denis.vile at supagro.inra.fr  Thu Mar 29 10:09:09 2012
From: denis.vile at supagro.inra.fr (Denis Vile)
Date: Thu, 29 Mar 2012 10:09:09 +0200
Subject: [R-sig-ME] crossed effects with lmer but correlation structure with
 lme
In-Reply-To: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
Message-ID: <4F7418A5.7050500@supagro.inra.fr>

Dear R users,

I'm trying to fit a crossed-effects mixed model that would include a 
spatial correlation structure..
The data come from four controlled experiments (control, treatment1, 
treatment2, treatment1+treatment2) on plants grown in a growth chamber.  
Individual replicates of different genotypes were grown together and 
response traits were measured. A covariate X is included in the model 
with a quadratic form.

We fitted the following model using lmer:

fm1 <- lmer(Y ~ 1 + Trt1*Trt2*poly(X, degree=2, raw=T) +
(1|idGenotype) + (1|Trt2:idGenotype) + (1|Trt1:idGenotype) +
             (1|Trt1:Trt2:idGenotype), data=...)

This model is very interesting because we can extract the BLUPs for each 
genotype in each (crossed) environment.

After discussion with colleagues, it appeared that we should try to 
include the possible spatial heterogeneityof the micro-environmentwithin 
the growth chamber. To this end, we tried to fit a model with lme() 
because we cannot easily (if possible) include a correlation structure 
using lmer(). The model is:

fm2 <- lme(Y ~ (X+I(X^2))*idCondition,
             random =~1|idGenotype/idCondition,
             correlation=corGaus(c(15,0.95), 
form=~x+y|idGenotype/idCondition, nugget=T),
             data =...)

where x and y are the coordinates of the plants within the growth chamber.

Since I was unable to fit the crossed effects Trt1 x Trt2 in lme() I 
coded a new variable idCondition which is the combination of Trt1 and 
Trt2, and treated genotypes within idCondition. This is not entirely 
satisfying because it is impossible to extract all BLUPs as in fm1.

Could you please tell me if I missed something and ifthere is a trick to 
specify crossed effects using lme()?
I assume that this should use pdClasses but I'm not at all at ease with 
the matrix specification of mixed models.
Alternatively, include a correlation structure in lmer seems to be 
unfeasible, am I wrong?

Thank you very much for your help,

Denis


-- 

*Denis VILE*
Charg? de Recherche
Laboratoire d'Ecophysiologie des Plantes sous Stress Environnementaux 
(*LEPSE*)
UMR 759 *INRA*-SUPAGRO // Institut de Biologie Int?grative des Plantes 
(IBIP, b?t 7)
2 place Pierre Viala
34060 Montpellier Cedex 2
Tel +33 (0)4 99 61 31 87
Fax +33 (0)4 67 52 21 16
http://www1.montpellier.inra.fr/ibip/lepse/



From giulia.dottisani at gmail.com  Thu Mar 29 10:58:16 2012
From: giulia.dottisani at gmail.com (Giulia Dotti Sani)
Date: Thu, 29 Mar 2012 10:58:16 +0200
Subject: [R-sig-ME] SUR in lmer
Message-ID: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>

Hello everyone,

is there a way of running a seemingly unrelated regression under lme4
or other multilevel packages?

Thank you!

Giulia



From markus.jantti at iki.fi  Thu Mar 29 11:06:38 2012
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Thu, 29 Mar 2012 11:06:38 +0200
Subject: [R-sig-ME] SUR in lmer
In-Reply-To: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>
References: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>
Message-ID: <4F74261E.4050102@iki.fi>

On 03/29/2012 10:58 AM, Giulia Dotti Sani wrote:
> Hello everyone,
>
> is there a way of running a seemingly unrelated regression under lme4
> or other multilevel packages?

Take a look at glm in nlme. You need to specify both a correlation structure (to 
allow the seemingly unrelated units to be correlated through their error terns) 
and a variance function (to allow for different residual variances for the units).

Best,

Markus
>
> Thank you!
>
> Giulia
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Markus Jantti
Professor of Economics
Swedish Institute for Social Research
Stockholm University



From istazahn at gmail.com  Thu Mar 29 12:29:11 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 29 Mar 2012 06:29:11 -0400
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
Message-ID: <CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>

Hi Reinhold,

Good question. My consultant didn't seem impressed when I tried to
articulate that explanation, but perhaps I wasn't clear.

Thanks,
Ista
On Thu, Mar 29, 2012 at 1:45 AM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> But why is Greg Snow's response inadequate?
>
> Restating his argument: ?In an LMM we are not estimating individual
> random effects (means, slopes) and individual residuals, but variance
> of random effects and variance of residuals. So there can be
> differences between a subject's observed random effect and random
> slope ?and conditional modes of the distribution of the random effects
> (i.e., the point of maximum density), given the observed data and
> evaluated at the parameter estimates.
>
> I think your statistician's answer is a good argument that you must
> not treat conditional modes as independent observations in a
> subsequent analyses. For example, we showed with simulations that
> correlations between conditional modes of slopes and intercepts are
> larger than the correlation parameter estimated in the LMM (Kliegl,
> Masson, & Richer, Visual Cognition, 2010).
>
> Reinhold Kliegl
>
> --
> Reinhold Kliegl
> http://read.psych.uni-potsdam.de/pmr2
>
> On Tue, Mar 27, 2012 at 4:18 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> Hi all,
>>
>> I'm trying to understand what the residual variance in this model:
>>
>> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
>> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
>> tmp$fitted1 <- fitted(m1)
>>
>> represents. The way I read this specification, an intercept and a
>> slope is estimated for each subject. Since each subject only has two
>> measurements, I would expect the Reaction scores to be completely
>> accounted for by the slopes and intercepts. Yet they are not: the
>> Residual variance estimate is 440.278.
>>
>> This is probably a stupid question, but I hope you will be kind enough
>> to humor me.
>>
>> Best,
>> Ista
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From giulia.dottisani at gmail.com  Thu Mar 29 17:08:09 2012
From: giulia.dottisani at gmail.com (Giulia Dotti Sani)
Date: Thu, 29 Mar 2012 17:08:09 +0200
Subject: [R-sig-ME] SUR in lmer
In-Reply-To: <4F74261E.4050102@iki.fi>
References: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>
	<4F74261E.4050102@iki.fi>
Message-ID: <CAKz8HvkRYqQai24E0iG2cuNxBn-RC5UnRS8NeyMv3_SaAfgygQ@mail.gmail.com>

Thank you. However, I can't see how I can specify two dependent  variables.

On Thu, Mar 29, 2012 at 11:06 AM, Markus J?ntti <markus.jantti at iki.fi> wrote:
> On 03/29/2012 10:58 AM, Giulia Dotti Sani wrote:
>>
>> Hello everyone,
>>
>> is there a way of running a seemingly unrelated regression under lme4
>> or other multilevel packages?
>
>
> Take a look at glm in nlme. You need to specify both a correlation structure
> (to allow the seemingly unrelated units to be correlated through their error
> terns) and a variance function (to allow for different residual variances
> for the units).
>
> Best,
>
> Markus
>>
>>
>> Thank you!
>>
>> Giulia
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Markus Jantti
> Professor of Economics
> Swedish Institute for Social Research
> Stockholm University
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From markus.jantti at iki.fi  Thu Mar 29 17:26:38 2012
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Thu, 29 Mar 2012 17:26:38 +0200
Subject: [R-sig-ME] SUR in lmer
In-Reply-To: <CAKz8HvkRYqQai24E0iG2cuNxBn-RC5UnRS8NeyMv3_SaAfgygQ@mail.gmail.com>
References: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>
	<4F74261E.4050102@iki.fi>
	<CAKz8HvkRYqQai24E0iG2cuNxBn-RC5UnRS8NeyMv3_SaAfgygQ@mail.gmail.com>
Message-ID: <4F747F2E.8000200@iki.fi>

On 03/29/2012 05:08 PM, Giulia Dotti Sani wrote:
> Thank you. However, I can't see how I can specify two dependent  variables.
>

You don't. You  reshape the data into "long" format, have a factor that 
indicates which unit's observations you are using, interact the explanatory 
variables with that indicator and also use that indicator for the variance 
function.

Markus
> On Thu, Mar 29, 2012 at 11:06 AM, Markus J?ntti<markus.jantti at iki.fi>  wrote:
>> On 03/29/2012 10:58 AM, Giulia Dotti Sani wrote:
>>>
>>> Hello everyone,
>>>
>>> is there a way of running a seemingly unrelated regression under lme4
>>> or other multilevel packages?
>>
>>
>> Take a look at glm in nlme. You need to specify both a correlation structure
>> (to allow the seemingly unrelated units to be correlated through their error
>> terns) and a variance function (to allow for different residual variances
>> for the units).
>>
>> Best,
>>
>> Markus
>>>
>>>
>>> Thank you!
>>>
>>> Giulia
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Markus Jantti
>> Professor of Economics
>> Swedish Institute for Social Research
>> Stockholm University
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Markus Jantti
Professor of Economics
Swedish Institute for Social Research
Stockholm University



From jwiley.psych at gmail.com  Thu Mar 29 17:29:52 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 29 Mar 2012 08:29:52 -0700
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
	<CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
Message-ID: <CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>

Hi Ista,

To me the onis is on the statistician consultant to explain *why* you
cannot have both random intercepts and slopes.  Does the consultant
have papers to reference or proofs?

In any case, this is hardly exclusive to 'R doing something strange'.
SAS and Stata happily join the gang.  See the attached file for code
and output from all three using a minidataset simulated in R.

I suppose one could bicker over whether a random intercept and slope
is a good idea, but possible it certainly is.  You might suggest that
it is poor fare to voice strong opinions about matters which one does
not understand.

Cheers,

Josh

On Thu, Mar 29, 2012 at 3:29 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi Reinhold,
>
> Good question. My consultant didn't seem impressed when I tried to
> articulate that explanation, but perhaps I wasn't clear.
>
> Thanks,
> Ista
> On Thu, Mar 29, 2012 at 1:45 AM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
>> But why is Greg Snow's response inadequate?
>>
>> Restating his argument: ?In an LMM we are not estimating individual
>> random effects (means, slopes) and individual residuals, but variance
>> of random effects and variance of residuals. So there can be
>> differences between a subject's observed random effect and random
>> slope ?and conditional modes of the distribution of the random effects
>> (i.e., the point of maximum density), given the observed data and
>> evaluated at the parameter estimates.
>>
>> I think your statistician's answer is a good argument that you must
>> not treat conditional modes as independent observations in a
>> subsequent analyses. For example, we showed with simulations that
>> correlations between conditional modes of slopes and intercepts are
>> larger than the correlation parameter estimated in the LMM (Kliegl,
>> Masson, & Richer, Visual Cognition, 2010).
>>
>> Reinhold Kliegl
>>
>> --
>> Reinhold Kliegl
>> http://read.psych.uni-potsdam.de/pmr2
>>
>> On Tue, Mar 27, 2012 at 4:18 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>> Hi all,
>>>
>>> I'm trying to understand what the residual variance in this model:
>>>
>>> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
>>> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
>>> tmp$fitted1 <- fitted(m1)
>>>
>>> represents. The way I read this specification, an intercept and a
>>> slope is estimated for each subject. Since each subject only has two
>>> measurements, I would expect the Reaction scores to be completely
>>> accounted for by the slopes and intercepts. Yet they are not: the
>>> Residual variance estimate is 440.278.
>>>
>>> This is probably a stupid question, but I hope you will be kind enough
>>> to humor me.
>>>
>>> Best,
>>> Ista
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/
-------------- next part --------------
############################################################
#                             R                            #
############################################################
set.seed(1)
d <- data.frame(y = c(y <- rnorm(100), y + rnorm(100)),
  x = rep(0:1, each = 100), id = factor(rep(1:100, 2)))

d <- d[order(d$id), ]

require(lme4)
summary(lmer(y ~ 1 + (1 + x | id), data = d))
## > summary(lmer(y ~ 1 + (1 + x | id), data = d))
## Linear mixed model fit by REML
## Formula: y ~ 1 + (1 + x | id)
##    Data: d
##    AIC   BIC logLik deviance REMLdev
##  548.6 565.1 -269.3    535.6   538.6
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  id       (Intercept) 0.60384  0.77707
##           x           0.50393  0.70988  0.366
##  Residual             0.20293  0.45047
## Number of obs: 200, groups: id, 100

## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  0.10885    0.08982   1.212


require(nlme)
summary(lme(y ~ 1, random = ~ 1 + x | id, data = d))

## > summary(lme(y ~ 1, random = ~ 1 + x | id, data = d))
## Linear mixed-effects model fit by REML
##  Data: d
##        AIC      BIC    logLik
##   548.6301 565.0967 -269.3151

## Random effects:
##  Formula: ~1 + x | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr
## (Intercept) 0.8231605 (Intr)
## x           0.8071236 0.193
## Residual    0.3594008

## Fixed effects: y ~ 1
##                 Value  Std.Error  DF  t-value p-value
## (Intercept) 0.1088521 0.08981989 100 1.211893  0.2284

## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max
## -1.18533542 -0.26837701 -0.03513932  0.29186404  1.25726715

## Number of Observations: 200
## Number of Groups: 100

require(foreign)
write.dta(d, file = "d:/d.dta")
write.csv(d, file = "d:/d.csv", row.names = FALSE)


############################################################
#                            SAS                           #
############################################################

# options nocenter nolabel nodate formchar="|----|+|---+=|-/\<>";
# PROC IMPORT OUT= WORK.d
#             DATAFILE= "D:\d.csv"
#             DBMS=CSV REPLACE;
#      GETNAMES=YES;
#      DATAROW=2;
# RUN;
#
# proc mixed data=d method=reml noclprint;
#   class id;
#   model y = / solution;
#   random int x / subject=id type=un;
# run;

## The Mixed Procedure
##                   Model Information
## Data Set                     WORK.D
## Dependent Variable           y
## Covariance Structure         Unstructured
## Subject Effect               id
## Estimation Method            REML
## Residual Variance Method     Profile
## Fixed Effects SE Method      Model-Based
## Degrees of Freedom Method    Containment

##             Dimensions
## Covariance Parameters             4
## Columns in X                      1
## Columns in Z Per Subject          2
## Subjects                        100
## Max Obs Per Subject               2

## Number of Observations
## Number of Observations Read             200
## Number of Observations Used             200
## Number of Observations Not Used           0
##                      Iteration History
## Iteration    Evaluations    -2 Res Log Like       Criterion
##         0              1       615.81799232
##         1              4       545.16825286      0.05801788
##         2              1       539.21410924      0.00597671
##         3              1       538.64539097      0.00017233
##         4              1       538.63016700      0.00000020
##         5              1       538.63014985      0.00000000
##                    Convergence criteria met.

##  Covariance Parameter Estimates
## Cov Parm     Subject    Estimate
## UN(1,1)      id           0.3519
## UN(2,1)      id           0.4540
## UN(2,2)      id                0
## Residual                  0.4549

##            Fit Statistics
## -2 Res Log Likelihood           538.6
## AIC (smaller is better)         544.6
## AICC (smaller is better)        544.8
## BIC (smaller is better)         552.4

##   Null Model Likelihood Ratio Test
##     DF    Chi-Square      Pr > ChiSq
##      2         77.19          <.0001

##                    Solution for Fixed Effects
##                          Standard
## Effect       Estimate       Error      DF    t Value    Pr > |t|
## Intercept      0.1089     0.08982      99       1.21      0.2284


############################################################
#                          Stata                           #
############################################################

# use "d:/d.dta", clear
# xtmixed y || id: x, cov(un) reml
# di -2*e(ll)

## . use "d:/d.dta", clear
## (Written by R.              )

## . xtmixed y || id: x, cov(un) reml

## Performing EM optimization:

## Performing gradient-based optimization:

## Iteration 0:   log restricted-likelihood = -269.31507
## Iteration 1:   log restricted-likelihood = -269.31507  (backed up)

## Computing standard errors:

## Mixed-effects REML regression                   Number of obs      =       200
## Group variable: id                              Number of groups   =       100

##                                                 Obs per group: min =         2
##                                                                avg =       2.0
##                                                                max =         2


##                                                 Wald chi2(0)       =         .
## Log restricted-likelihood = -269.31507          Prob > chi2        =         .

## ------------------------------------------------------------------------------
##            y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##        _cons |   .1088521   .0898198     1.21   0.226    -.0671914    .2848956
## ------------------------------------------------------------------------------

## ------------------------------------------------------------------------------
##   Random-effects Parameters  |   Estimate   Std. Err.     [95% Conf. Interval]
## -----------------------------+------------------------------------------------
## id: Unstructured             |
##                        sd(x) |   .8071714   31.05985      1.42e-33    4.58e+32
##                    sd(_cons) |   .8231815   15.22811      1.48e-16    4.59e+15
##                corr(x,_cons) |   .1930683   48.73245            -1           1
## -----------------------------+------------------------------------------------
##                 sd(Residual) |   .3593491    34.8834      8.44e-84    1.53e+82
## ------------------------------------------------------------------------------
## LR test vs. linear regression:       chi2(3) =    77.19   Prob > chi2 = 0.0000

## Note: LR test is conservative and provided only for reference.

## . di -2*e(ll)
## 538.63015

From istazahn at gmail.com  Thu Mar 29 18:28:36 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 29 Mar 2012 12:28:36 -0400
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
	<CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
	<CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>
Message-ID: <CA+vqiLHSBD3U0uJcLVAd_Ugb+=oGHHBFEhBOfsgye=0XnJN++w@mail.gmail.com>

Thanks Josh, the comparison with SAS and Stata is very useful. I'll
see what my consultant has to say about this example.

Best,
Ista

On Thu, Mar 29, 2012 at 11:29 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Ista,
>
> To me the onis is on the statistician consultant to explain *why* you
> cannot have both random intercepts and slopes. ?Does the consultant
> have papers to reference or proofs?
>
> In any case, this is hardly exclusive to 'R doing something strange'.
> SAS and Stata happily join the gang. ?See the attached file for code
> and output from all three using a minidataset simulated in R.
>
> I suppose one could bicker over whether a random intercept and slope
> is a good idea, but possible it certainly is. ?You might suggest that
> it is poor fare to voice strong opinions about matters which one does
> not understand.
>
> Cheers,
>
> Josh
>
> On Thu, Mar 29, 2012 at 3:29 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> Hi Reinhold,
>>
>> Good question. My consultant didn't seem impressed when I tried to
>> articulate that explanation, but perhaps I wasn't clear.
>>
>> Thanks,
>> Ista
>> On Thu, Mar 29, 2012 at 1:45 AM, Reinhold Kliegl
>> <reinhold.kliegl at gmail.com> wrote:
>>> But why is Greg Snow's response inadequate?
>>>
>>> Restating his argument: ?In an LMM we are not estimating individual
>>> random effects (means, slopes) and individual residuals, but variance
>>> of random effects and variance of residuals. So there can be
>>> differences between a subject's observed random effect and random
>>> slope ?and conditional modes of the distribution of the random effects
>>> (i.e., the point of maximum density), given the observed data and
>>> evaluated at the parameter estimates.
>>>
>>> I think your statistician's answer is a good argument that you must
>>> not treat conditional modes as independent observations in a
>>> subsequent analyses. For example, we showed with simulations that
>>> correlations between conditional modes of slopes and intercepts are
>>> larger than the correlation parameter estimated in the LMM (Kliegl,
>>> Masson, & Richer, Visual Cognition, 2010).
>>>
>>> Reinhold Kliegl
>>>
>>> --
>>> Reinhold Kliegl
>>> http://read.psych.uni-potsdam.de/pmr2
>>>
>>> On Tue, Mar 27, 2012 at 4:18 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>>> Hi all,
>>>>
>>>> I'm trying to understand what the residual variance in this model:
>>>>
>>>> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
>>>> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
>>>> tmp$fitted1 <- fitted(m1)
>>>>
>>>> represents. The way I read this specification, an intercept and a
>>>> slope is estimated for each subject. Since each subject only has two
>>>> measurements, I would expect the Reaction scores to be completely
>>>> accounted for by the slopes and intercepts. Yet they are not: the
>>>> Residual variance estimate is 440.278.
>>>>
>>>> This is probably a stupid question, but I hope you will be kind enough
>>>> to humor me.
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/



From bbolker at gmail.com  Thu Mar 29 20:25:27 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Mar 2012 18:25:27 +0000 (UTC)
Subject: [R-sig-ME] Help understanding residual variance
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
	<CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
	<CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>
Message-ID: <loom.20120329T202325-652@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> 
> Hi Ista,
> 
> To me the onis is on the statistician consultant to explain *why* you
> cannot have both random intercepts and slopes.  Does the consultant
> have papers to reference or proofs?
> 
> In any case, this is hardly exclusive to 'R doing something strange'.
> SAS and Stata happily join the gang.  See the attached file for code
> and output from all three using a minidataset simulated in R.
> 
> I suppose one could bicker over whether a random intercept and slope
> is a good idea, but possible it certainly is.  You might suggest that
> it is poor fare to voice strong opinions about matters which one does
> not understand.
> 
> Cheers,
> 
> Josh

  Very nice example.  Do note that while R::lme and Stata give
the same point estimates, Stata also provides estimated confidence
intervals, which are enormous -- suggesting that, while one can
do this, the resulting model might be unidentifiable.

  Doug Bates commented off-list that:

> I believe that the estimates for such a model are at least ill-defined
> if not unidentifiable.

  cheers
    Ben



From rlevy at ucsd.edu  Thu Mar 29 21:23:16 2012
From: rlevy at ucsd.edu (Levy, Roger)
Date: Thu, 29 Mar 2012 19:23:16 +0000
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <loom.20120329T202325-652@post.gmane.org>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
	<CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
	<CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>
	<loom.20120329T202325-652@post.gmane.org>
Message-ID: <B5DE3287-D5D6-4768-8B71-B03E0D304D03@ucsd.edu>


On Mar 29, 2012, at 11:25 AM PDT, Ben Bolker wrote:

> Joshua Wiley <jwiley.psych at ...> writes:
> 
>> 
>> Hi Ista,
>> 
>> To me the onis is on the statistician consultant to explain *why* you
>> cannot have both random intercepts and slopes.  Does the consultant
>> have papers to reference or proofs?
>> 
>> In any case, this is hardly exclusive to 'R doing something strange'.
>> SAS and Stata happily join the gang.  See the attached file for code
>> and output from all three using a minidataset simulated in R.
>> 
>> I suppose one could bicker over whether a random intercept and slope
>> is a good idea, but possible it certainly is.  You might suggest that
>> it is poor fare to voice strong opinions about matters which one does
>> not understand.
>> 
>> Cheers,
>> 
>> Josh
> 
>  Very nice example.  Do note that while R::lme and Stata give
> the same point estimates, Stata also provides estimated confidence
> intervals, which are enormous -- suggesting that, while one can
> do this, the resulting model might be unidentifiable.
> 
>  Doug Bates commented off-list that:
> 
>> I believe that the estimates for such a model are at least ill-defined
>> if not unidentifiable.

I concur with this -- I believe that the statistician consultant is right in this case, and that with only two observations per subject (plus crucially, no pair of observations for a given subject having the same value of Days), the model is actually unidentifiable given the dataset.  Here's one way of thinking about it: imagine that we represent the Days==1 and Days==9 observations for each subject as a 2-vector, (y_1 y_9).  If the residual variance is s^2 and the covariance matrix for the subject-level means for Days==1 and Days==9 as

 | t1^2             rho*t1t9     |
 | rho*t1t9             t9^2     |

then the marginal distribution for the total contribution of subject-level and residual error to the two observations for a given subject is bivariate normal with covariance matrix

 | t1^2 + s^2       rho*t1t9 |
 | rho*t1t9         t9^2+s^2 |

But as this illustrates, there's no way of distinguishing the residual error term s^2 from the subject random effects t1^2 and t9^2.  (This problem would not arise if there were at least two observations for one value of Days in at least one subject, because for that subject one would not be able to represent the data such that there is effectively only one multivariate observation per subject.)

I'll be interested to know whether this explanation helps shed light on the matter!

Best

Roger

--

Roger Levy                      Email: rlevy at ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://idiom.ucsd.edu/~rlevy



From bpederse at gmail.com  Thu Mar 29 23:59:47 2012
From: bpederse at gmail.com (Brent Pedersen)
Date: Thu, 29 Mar 2012 15:59:47 -0600
Subject: [R-sig-ME] error on example
Message-ID: <CAAp4xwryq4-a7jpRZ6X3S4tSXzeMv9veMO7u056iwnRp-vP_BA@mail.gmail.com>

Hi, I'm running this code:

library(lme4a)
data(ergoStool,package="MEMSS")
ergoStool$Subject <- factor(ergoStool$Subject)
fm01 <- lmer(effort~1 + Type + (1|Subject), ergoStool, REML=0)

And getting this error:

Error: is.numeric(u <- attr(fval, "u")) is not TRUE
Execution halted


My sessionInfo is below. Any ideas on how to fix this? I'm having
trouble calling
lmer() on any data.

thanks,
-Brent

R version 2.14.1 (2011-12-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4a_0.9996875-1  MatrixModels_0.3-1 minqa_1.2.0        Rcpp_0.9.10
[5] Matrix_1.0-5       lattice_0.20-6

loaded via a namespace (and not attached):
[1] codetools_0.2-8 grid_2.14.1     nlme_3.1-103    splines_2.14.1



From bbolker at gmail.com  Fri Mar 30 04:48:25 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Mar 2012 02:48:25 +0000 (UTC)
Subject: [R-sig-ME] error on example
References: <CAAp4xwryq4-a7jpRZ6X3S4tSXzeMv9veMO7u056iwnRp-vP_BA@mail.gmail.com>
Message-ID: <loom.20120330T044453-262@post.gmane.org>

Brent Pedersen <bpederse at ...> writes:

> 
> Hi, I'm running this code:
> 
> library(lme4a)
> data(ergoStool,package="MEMSS")
> ergoStool$Subject <- factor(ergoStool$Subject)
> fm01 <- lmer(effort~1 + Type + (1|Subject), ergoStool, REML=0)
> 

  I haven't checked, but I *think* that the development version
of lme4 (formerly lme4Eigen) now dominates lme4a -- and it works
on this example.  If there are things that you want to do that 
lme4a does that the development (r-forge) version of lme4 *doesn't*
do, please let the maintainers know and we will fix them ASAP ...

  cheers
    Ben Bolker



> And getting this error:
> 
> Error: is.numeric(u <- attr(fval, "u")) is not TRUE
> Execution halted
> 
> My sessionInfo is below. Any ideas on how to fix this? I'm having
> trouble calling
> lmer() on any data.
>



From natalia.vizcaino.palomar at gmail.com  Fri Mar 30 10:41:58 2012
From: natalia.vizcaino.palomar at gmail.com (=?ISO-8859-1?Q?Natalia_Vizca=EDno_Palomar?=)
Date: Fri, 30 Mar 2012 10:41:58 +0200
Subject: [R-sig-ME] problems to install glmmADMB
Message-ID: <CAOh1aTwi9sqF2oZu+f1iEZa5VwZhF_QUskEbhaBLDYrYq5D1Ag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120330/8571b6cb/attachment-0001.pl>

From ggrothendieck at gmail.com  Fri Mar 30 12:49:10 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Mar 2012 06:49:10 -0400
Subject: [R-sig-ME] problems to install glmmADMB
In-Reply-To: <CAOh1aTwi9sqF2oZu+f1iEZa5VwZhF_QUskEbhaBLDYrYq5D1Ag@mail.gmail.com>
References: <CAOh1aTwi9sqF2oZu+f1iEZa5VwZhF_QUskEbhaBLDYrYq5D1Ag@mail.gmail.com>
Message-ID: <CAP01uRmZV_cxw+XgpyodbFcRKuFGaz4_7E2dUD-nUkgXwxdDGw@mail.gmail.com>

On Fri, Mar 30, 2012 at 4:41 AM, Natalia Vizca?no Palomar
<natalia.vizcaino.palomar at gmail.com> wrote:
> Dear Ben,
>
> I have ?read many posts concerning the problems to install glmmADMB,
> but I am very sorry to write you another mail with this question.
> I have tried every advice to upload glmmADMB from
> http://glmmadmb.r-forge.r-project.org/ web page
> but I don?t know which problem I am running with.
> One of the last messages I got was:
>
> install.packages("glmmADMB_0.7.3.tar.gz",repos=NULL,type="source")
> Installing package(s) into ?C:/Users/Natalia/Documents/R/win-library/2.14?
> (as ?lib? is unspecified)
> Aviso: invalid package 'glmmADMB_0.7.3.tar.gz'
> Error: ERROR: no packages specified
> Mensajes de aviso perdidos
> 1: comando ejecutado 'C:/PROGRA~1/R/R-214~1.2/bin/i386/R CMD INSTALL -l
> "C:/Users/Natalia/Documents/R/win-library/2.14" ? "glmmADMB_0.7.3.tar.gz"'
> tiene estatus 1
> 2: In install.packages("glmmADMB_0.7.3.tar.gz", repos = NULL, type =
> "source") :
> ?installation of package ?glmmADMB_0.7.3.tar.gz? had non-zero exit status
>

See if you have better luck with this one:

http://www.math.mcmaster.ca/~bolker/R/src/contrib/glmmADMB_0.7.2.11.tar.gz

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From denis.vile at supagro.inra.fr  Fri Mar 30 13:10:57 2012
From: denis.vile at supagro.inra.fr (Denis Vile)
Date: Fri, 30 Mar 2012 13:10:57 +0200
Subject: [R-sig-ME] crossed effects with lmer but correlation structure
 with lme
In-Reply-To: <4F7418A5.7050500@supagro.inra.fr>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
	<4F7418A5.7050500@supagro.inra.fr>
Message-ID: <4F7594C1.1000101@supagro.inra.fr>

Hi all,

Was my problem not sufficiently well exposed or no one could help me ?

Sincerely,

Denis

Le 29/03/2012 10:09, Denis Vile a ?crit :
> Dear R users,
>
> I'm trying to fit a crossed-effects mixed model that would include a 
> spatial correlation structure..
> The data come from four controlled experiments (control, treatment1, 
> treatment2, treatment1+treatment2) on plants grown in a growth 
> chamber.  Individual replicates of different genotypes were grown 
> together and response traits were measured. A covariate X is included 
> in the model with a quadratic form.
>
> We fitted the following model using lmer:
>
> fm1 <- lmer(Y ~ 1 + Trt1*Trt2*poly(X, degree=2, raw=T) +
> (1|idGenotype) + (1|Trt2:idGenotype) + (1|Trt1:idGenotype) +
>             (1|Trt1:Trt2:idGenotype), data=...)
>
> This model is very interesting because we can extract the BLUPs for 
> each genotype in each (crossed) environment.
>
> After discussion with colleagues, it appeared that we should try to 
> include the possible spatial heterogeneityof the 
> micro-environmentwithin the growth chamber. To this end, we tried to 
> fit a model with lme() because we cannot easily (if possible) include 
> a correlation structure using lmer(). The model is:
>
> fm2 <- lme(Y ~ (X+I(X^2))*idCondition,
>             random =~1|idGenotype/idCondition,
>             correlation=corGaus(c(15,0.95), 
> form=~x+y|idGenotype/idCondition, nugget=T),
>             data =...)
>
> where x and y are the coordinates of the plants within the growth 
> chamber.
>
> Since I was unable to fit the crossed effects Trt1 x Trt2 in lme() I 
> coded a new variable idCondition which is the combination of Trt1 and 
> Trt2, and treated genotypes within idCondition. This is not entirely 
> satisfying because it is impossible to extract all BLUPs as in fm1.
>
> Could you please tell me if I missed something and ifthere is a trick 
> to specify crossed effects using lme()?
> I assume that this should use pdClasses but I'm not at all at ease 
> with the matrix specification of mixed models.
> Alternatively, include a correlation structure in lmer seems to be 
> unfeasible, am I wrong?
>
> Thank you very much for your help,
>
> Denis
>
>

-- 

*Denis VILE*
Charg? de Recherche
Laboratoire d'Ecophysiologie des Plantes sous Stress Environnementaux 
(*LEPSE*)
UMR 759 *INRA*-SUPAGRO // Institut de Biologie Int?grative des Plantes 
(IBIP, b?t 7)
2 place Pierre Viala
34060 Montpellier Cedex 2
Tel +33 (0)4 99 61 31 87
Fax +33 (0)4 67 52 21 16
http://www1.montpellier.inra.fr/ibip/lepse/



From vcadavez at ipb.pt  Fri Mar 30 13:37:09 2012
From: vcadavez at ipb.pt (Vasco Cadavez)
Date: Fri, 30 Mar 2012 12:37:09 +0100
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
 package?
In-Reply-To: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <4F759AE5.4050500@ipb.pt>

Hi,

I would like to know if is possible to solve simultaneous equations in lme4?

Thanks,

Vasco

-- 
Vasco Cadavez, PhD
Departamento de Ci?ncia Animal&
Centro de Investiga??o de Montanha (CIMO)
Escola Superior Agr?ria, Instituto Polit?cnico de Bragan?a
Campus de Santa Apol?nia, Apartado 1172
5301-854 BRAGAN?A
PORTUGAL
Telefone: (+351) 273 303 304
Fax: (+351) 273 325 405
e-mail: vcadavez at ipb.pt



From bpederse at gmail.com  Fri Mar 30 20:06:46 2012
From: bpederse at gmail.com (Brent Pedersen)
Date: Fri, 30 Mar 2012 12:06:46 -0600
Subject: [R-sig-ME] error on example
In-Reply-To: <loom.20120330T044453-262@post.gmane.org>
References: <CAAp4xwryq4-a7jpRZ6X3S4tSXzeMv9veMO7u056iwnRp-vP_BA@mail.gmail.com>
	<loom.20120330T044453-262@post.gmane.org>
Message-ID: <CAAp4xwrFRawci4J2vF08rtZLKw3Y3ejfeDpcao1XunUgAfpV3A@mail.gmail.com>

On Thu, Mar 29, 2012 at 8:48 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Brent Pedersen <bpederse at ...> writes:
>
>>
>> Hi, I'm running this code:
>>
>> library(lme4a)
>> data(ergoStool,package="MEMSS")
>> ergoStool$Subject <- factor(ergoStool$Subject)
>> fm01 <- lmer(effort~1 + Type + (1|Subject), ergoStool, REML=0)
>>
>
> ?I haven't checked, but I *think* that the development version
> of lme4 (formerly lme4Eigen) now dominates lme4a -- and it works
> on this example. ?If there are things that you want to do that
> lme4a does that the development (r-forge) version of lme4 *doesn't*
> do, please let the maintainers know and we will fix them ASAP ...
>
> ?cheers
> ? ?Ben Bolker
>

I substituted lme4 for lme4a and all works as expected on the example and
on my data.
Thanks very much.


>
>
>> And getting this error:
>>
>> Error: is.numeric(u <- attr(fval, "u")) is not TRUE
>> Execution halted
>>
>> My sessionInfo is below. Any ideas on how to fix this? I'm having
>> trouble calling
>> lmer() on any data.
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Fri Mar 30 22:09:33 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Mar 2012 20:09:33 +0000 (UTC)
Subject: [R-sig-ME] crossed effects with lmer but correlation structure
	with lme
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
	<4F7418A5.7050500@supagro.inra.fr>
	<4F7594C1.1000101@supagro.inra.fr>
Message-ID: <loom.20120330T215721-195@post.gmane.org>

Denis Vile <denis.vile at ...> writes:

> 
> Hi all,
> 
> Was my problem not sufficiently well exposed or no one could help me ?
> 
> Sincerely,
> 
> Denis

  The canonical reference for this is p. 163ff of Pinheiro
and Bates 2000 (section 4.2.2,  http://tinyurl.com/crossedRE )
You are correct that lme4 doesn't handle 'R-side' correlation
structures, nor will it in the near future ...


 (I've added this information to glmm.wikidot.com/faq ...)

  Ben Bolker


> 
> Le 29/03/2012 10:09, Denis Vile a ?crit :
> > Dear R users,
> >
> > I'm trying to fit a crossed-effects mixed model that would include a 
> > spatial correlation structure..
> > The data come from four controlled experiments (control, treatment1, 
> > treatment2, treatment1+treatment2) on plants grown in a growth 
> > chamber.  Individual replicates of different genotypes were grown 
> > together and response traits were measured. A covariate X is included 
> > in the model with a quadratic form.
> >
> > We fitted the following model using lmer:
> >
> > fm1 <- lmer(Y ~ 1 + Trt1*Trt2*poly(X, degree=2, raw=T) +
> > (1|idGenotype) + (1|Trt2:idGenotype) + (1|Trt1:idGenotype) +
> >             (1|Trt1:Trt2:idGenotype), data=...)
> >

  [snip snip snip]



From jwiley.psych at gmail.com  Fri Mar 30 22:44:44 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 30 Mar 2012 13:44:44 -0700
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
In-Reply-To: <loom.20120319T195110-259@post.gmane.org>
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
	<loom.20120319T195110-259@post.gmane.org>
Message-ID: <CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>

Hi Ben,

Many thanks for the help.  I tried your suggestion out and it seemed
to work (and I learned a bit about lme4 in the process :)

library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm1Fun <- update(fm1,devFunOnly=TRUE)
library(numDeriv)
fm1_thpar <- getME(fm1,"theta")
h <- hessian(fm1Fun, fm1_thpar)
g <- grad(fm1Fun, fm1_thpar)

which I can use (I think) to get standard errors of the variance parameters.

library(MASS)
sqrt(diag(ginv(h)))

which plug into a longer formula that attempts to test the
significance of indirect effects.  Given that the variance parameters
are not normally distributed, my hunch is that even though both fixed
and random effects (and their variances/standard errors) are being
built into the mediation test, it is probably not well-behaved either,
but it is nice to be able to try to replicate models in the article.
Even if they are not perfectly accurate, I am hoping I can use them as
a sanity check for when I play with some mcmc and bootstrapping.

Thanks again!

Josh

Session info below just for the record if anyone else is trying to try this.

R Under development (unstable) (2012-03-29 r58868)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] MASS_7.3-17        reshape2_1.2.1     numDeriv_2012.3-1  lme4_0.999902344-0
[5] Matrix_1.0-6       lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.16.0    minqa_1.2.0    nlme_3.1-103   plyr_1.7.1     splines_2.16.0
[6] stringr_0.6    tools_2.16.0

On Mon, Mar 19, 2012 at 12:15 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Joshua Wiley <jwiley.psych at ...> writes:
>
>>
>> Hi,
>>
>> I am trying to use a multivariate mixed effects linear model to
>> examine mediation. ?This works fine. ?The final step is to compute the
>> indirect effect and its standard error. ?The indirect effect is easy
>> (product of coefficients plus their covariance). ?For the standard
>> error, I need the gradient (D) and the hessian (H):
>> the variance is then:
>>
>> D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}
>>
>> This is all given in the Appendix of
>> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
>>
>> Is there a way to get this out of a mer class object? ?Looking at
>> class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$. ?@V
>> seems like it would give me the gradient but is null for a basic lmer
>> model.
>
> ?If you're willing to try out the development version (i.e., lme4
> from r-forge), I think you can do this as follows:
>
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fm1Fun <- update(fm1,devFunOnly=TRUE)
> library(numDeriv)
> fm1_thpar <- getME(fm1,"theta")
> h <- hessian(fm1Fun,fm1_thpar)
>
> ?and similarly for the gradient.
>
> ?Let me know how it goes.
>
> ?Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From danner.ray at gmail.com  Sat Mar 31 20:24:17 2012
From: danner.ray at gmail.com (Ray Danner)
Date: Sat, 31 Mar 2012 14:24:17 -0400
Subject: [R-sig-ME] MCMC model selection reference
Message-ID: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>

Dear list,

I'm looking for guidance on model selection using DIC values.  I'm
particularly interested in comparing mixed models created with the
package MCMCglmm.  I currently use AIC for my models built with lme
and (g)lmer and like the ability to calculate evidence ratios and
model average predictions, which are very easy for readers to
conceptualize.  AICcmodavg is great for these things.

Can anyone recommend a resource that describes the appropriate use of
DIC for model selection (and its limitations)?  I'm mainly an
ecologist, so a less-technical treatment would be ideal.

My main questions are:
1. Can DIC be used to select among mixed models?
Kery and Schaub (2012 p. 42) raise concerns about counting the correct
number of parameters and state that WinBUGS does not calculate them
appropriately, though Millar (2009) provides a method that is
appropriate for hierarchical models.  On the other hand, Saveliev et
al. (2009) use DIC to compare models with random effects built with
the BRugs package.  Hadfield's MCMCglmm Tutorial says that lower DIC
is better, but doesn't give details about use.

2. Any rules of thumb on what constitutes sufficiently large deltaDIC
values?  Are evidence ratios acceptable?

3. Can DIC be used to calculate model average predictions?

Thanks in advance and please forgive me if I missed your publication.
Ray


Refs
Kery and Schaub. 2012. Bayesian Population Analysis Using WinBUGS: A
Hierarchical Perspective.
Millar. 2009. Comparison of hierarchical Bayesian models for
overdispersed count data using DIC and Bayes' Factors. Biometrics
65:962-969.
Saveliev et al. 2009. Ch. 23 in Zuur, Mixed Effects Models and
Extensions in Ecology with R.



From boris at bshor.com  Sat Mar 31 00:00:07 2012
From: boris at bshor.com (Boris Shor)
Date: Fri, 30 Mar 2012 15:00:07 -0700
Subject: [R-sig-ME] lme4a installation
Message-ID: <CAGddWLSagQiG9zr93SYaCd0GjuyyftPCrPp_=fZ6bfUkEPy3LQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120330/e105bcf5/attachment-0001.pl>

From ramos.grad.student at gmail.com  Mon Jan  2 09:41:39 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 2 Jan 2012 00:41:39 -0800
Subject: [R-sig-ME] covariance structures for longitudinal models
Message-ID: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120102/2f1f39eb/attachment-0004.pl>

From jwiley.psych at gmail.com  Mon Jan  2 17:13:59 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 2 Jan 2012 08:13:59 -0800
Subject: [R-sig-ME] covariance structures for longitudinal models
In-Reply-To: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
Message-ID: <CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>

Hi Antonio,

I am not familiar with antedependence models so no comment there.

For factor analysis and that genre, I like OpenMx (also see sem and
lavaan).  One thing I like about OpenMx is while it caters to SEM, it
is a general purpose matrix optimizer, and it really is not difficult
to access that power.  So in principal, you can have whatever matrices
you want, roll your own objective function, and away it'll go.

For BUGS you have a lot of options including: R2OpenBUGS and R2WinBUGS
among others.

Cheers,

Josh

On Mon, Jan 2, 2012 at 12:41 AM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> Hi all,
>
> I've trying to use R to fit some longitudinal models, mostly via lme and
> nlme packages. However, it seems that many standard models are lacking,
> such as antedependence models or factor analytic models for covariance
> matrices. These models are readily available in SAS. Does an recommend
> other packages for the job in R? I don't really care if I am in frequentist
> or bayesian world as long as I have more modeling flexibility. I would also
> be interested in doing that in WINBUGS/JAGS.
>
> All the best,
>
> Antonio.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From ramos.grad.student at gmail.com  Mon Jan  2 21:16:38 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 2 Jan 2012 12:16:38 -0800
Subject: [R-sig-ME] covariance structures for longitudinal models
In-Reply-To: <CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
	<CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>
Message-ID: <CAHawB9utWpzVSgTBz82M1O4ss5Th+NvZtt4bLCJGe581uitHPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120102/d19f3da0/attachment-0002.pl>

From ramos.grad.student at gmail.com  Wed Jan  4 02:52:47 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 3 Jan 2012 17:52:47 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
	over 146
Message-ID: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120103/0755b9c2/attachment-0002.pl>

From jwiley.psych at gmail.com  Wed Jan  4 03:51:00 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 3 Jan 2012 18:51:00 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
 over 146
In-Reply-To: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
References: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
Message-ID: <CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>

Hi Antonio,

Look at the error message: "function evaluation limit reached without
convergence" you increased the number of iterations, but the objective
function reached its limit for max evaluations prior to convergance.
The 'brute force' approach would be to use the msMaxEval argument of
lmeControl to up that, but I would suggest carefully scrutinizing your
data and model prior before blindly asking the optimizer to run
longer.

Have you graphed your data?  What sort of variables are time and
maternal_educ?  If you send us data, we can show you some examples of
how you might graph and examine your data.  Also, do you really want a
random interaction?

Finally, in model formulae, * behaves specially, so x * z expands to:
x + z + x:z, thus a simplified writing of your model (not really
important and if the other way is clearer to you, by all means use it,
but you can save a few keystrokes; also note I show the msMaxEval
argument):

model.c2 <- lme(log(child_mortality) ~  time * log(maternal_educ),
  control = lmeControl(msMaxIter = 200, msMaxEval = 500 msVerbose = TRUE),
  merged1, random = ~ log(maternal_educ) * time | country.x,
  na.action = na.omit, method = "ML")

Cheers,

Josh

On Tue, Jan 3, 2012 at 5:52 PM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> Hi all,
>
> I am trying to fit a simple mixed model for longitudinal data, but the
> algorithm is not converging. When I add additional commands in the call I
> am able to increase the number of iterations from the default of 50 to 146,
> but no more than that. Does anyway have an idea about what is going on? ?I
> can provided data if needed.
>
> Best, Antonio.
>
>> model.c2 <- lme(log(child_mortality) ~ ?time + log(maternal_educ) +
> log(maternal_educ)*time,
> + ? ? ? ? ? ? ? ?control=lmeControl(msMaxIter = 200, msVerbose = TRUE),
> + ? ? ? ? ? ? ? ?merged1, random= ~time + log(maternal_educ)*time
> |country.x, na.action=na.omit,method="ML")
> ?0: ? ? 11378.396: -1.65670 ?2.44758 -3.03894 ?2.00310 -34.0487 0.186837
> 0.0637447 ?49.2689 -10.3311 ?5.94936
> ?1: ? ? 11375.740: -1.68701 ?2.45171 -3.03866 ?2.00265 -34.0499 0.302840
> 0.0305228 ?49.2682 -10.3309 ?5.94934
> ?2: ? ? 11375.323: -1.68664 ?2.45188 -3.03838 ?2.00234 -34.0499 0.302036
> 0.0279806 ?49.2682 -10.3309 ?5.94934
> ?3: ? ? 11375.161: -1.68509 ?2.45164 -3.03478 ?1.99830 -34.0500 0.301491
> 0.0299300 ?49.2682 -10.3309 ?5.94939
> ?4: ? ? 11374.835: -1.68137 ?2.45134 -3.03272 ?1.99601 -34.0499 0.290639
> 0.0313596 ?49.2682 -10.3310 ?5.94943
> ?5: ? ? 11361.671: -1.63878 ?2.45243 -2.66545 ?1.58982 -34.0573 0.726526
> -0.0906120 ?49.2606 -10.3367 ?5.95909
> ?6: ? ? 11359.791: -1.65178 ?2.44927 -2.57664 ?1.47997 -34.0610 0.975864
> -0.170656 ?49.2572 -10.3386 ?5.96736
> ?7: ? ? 11359.595: -1.65004 ?2.45965 -2.56790 ?1.46837 -34.0612 ?1.00787
> -0.168258 ?49.2564 -10.3397 ?5.97066
>
>
>
> 132: ? ? 11307.797: -1.39340 ?3.37422 0.317114 0.526105 -90.6641 ?44.6928
> -13.9187 ?667.927 -208.799 ?26.9546
> 133: ? ? 11307.797: -1.39346 ?3.38002 0.320773 0.526102 -91.1985 ?45.1140
> -14.0518 ?675.133 -211.078 ?27.0564
> 134: ? ? 11307.796: -1.39350 ?3.38197 0.321697 0.525758 -91.3801 ?45.2651
> -14.0996 ?677.663 -211.877 ?27.0798
> 135: ? ? 11307.795: -1.39360 ?3.38872 0.325211 0.525153 -92.0139 ?45.7838
> -14.2635 ?686.411 -214.643 ?27.1729
> 136: ? ? 11307.794: -1.39365 ?3.39553 0.329183 0.525088 -92.6545 ?46.2974
> -14.4259 ?695.158 -217.409 ?27.2829
> 137: ? ? 11307.792: -1.39368 ?3.40218 0.332937 0.525082 -93.2910 ?46.8111
> -14.5883 ?703.905 -220.176 ?27.3876
> 138: ? ? 11307.791: -1.39373 ?3.40895 0.337031 0.525186 -93.9332 ?47.3224
> -14.7500 ?712.652 -222.942 ?27.5031
> 139: ? ? 11307.790: -1.39378 ?3.41494 0.341038 0.525609 -94.5084 ?47.7708
> -14.8918 ?720.413 -225.398 ?27.6206
> 140: ? ? 11307.789: -1.39382 ?3.41930 0.344713 0.526541 -94.9384 ?48.0868
> -14.9919 ?726.060 -227.188 ?27.7364
> 141: ? ? 11307.788: -1.39387 ?3.42361 0.347375 0.526566 -95.3534 ?48.4155
> -15.0959 ?731.709 -228.975 ?27.8133
> 142: ? ? 11307.788: -1.39393 ?3.42785 0.349776 0.526344 -95.7643 ?48.7467
> -15.2006 ?737.357 -230.762 ?27.8810
> 143: ? ? 11307.787: -1.39401 ?3.43137 0.351265 0.525645 -96.1084 ?49.0365
> -15.2922 ?742.207 -232.294 ?27.9192
> 144: ? ? 11307.786: -1.39407 ?3.43484 0.352910 0.525314 -96.4518 ?49.3214
> -15.3823 ?747.014 -233.815 ?27.9635
> 145: ? ? 11307.786: -1.39410 ?3.43839 0.354938 0.525329 -96.8011 ?49.6024
> -15.4711 ?751.820 -235.335 ?28.0217
> 146: ? ? 11307.786: -1.39410 ?3.43839 0.354938 0.525329 -96.8011 ?49.6024
> -15.4711 ?751.820 -235.335 ?28.0217
> Error in lme.formula(log(child_mortality) ~ time + log(maternal_educ) + ?:
> ?nlminb problem, convergence error code = 1
> ?message = function evaluation limit reached without convergence (9)
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From ramos.grad.student at gmail.com  Wed Jan  4 04:20:30 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 3 Jan 2012 19:20:30 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
 over 146
In-Reply-To: <CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>
References: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
	<CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>
Message-ID: <CAHawB9tkjXpY=kZvxtcrpHPTCg+1t+95a4_5PC_am+7gRpRdTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120103/f2cff3f9/attachment-0002.pl>

From jwiley.psych at gmail.com  Wed Jan  4 06:09:42 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 3 Jan 2012 21:09:42 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
 over 146
In-Reply-To: <CAHawB9tkjXpY=kZvxtcrpHPTCg+1t+95a4_5PC_am+7gRpRdTw@mail.gmail.com>
References: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
	<CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>
	<CAHawB9tkjXpY=kZvxtcrpHPTCg+1t+95a4_5PC_am+7gRpRdTw@mail.gmail.com>
Message-ID: <CANz9Z_J_hk_s+zHK5d3bQ3UAD3MgM7Ug9t+bC4fx_62piQO34A@mail.gmail.com>

On Tue, Jan 3, 2012 at 7:20 PM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
[snip]
 at end of the day, it still don't undertand why it
> doesn't obey my instructions and increase the number of interactions, even
> if to crash.

It does increase the number of iterations---you reached a function
evaluation limit, not an iteration limit.  There is not a 1:1
relationship between function evaluations and iterations.  If you're
curious, you may enjoy: http://netlib.bell-labs.com/cm/cs/cstr/153.pdf
 or http://www.numerical-recipes.com/ the first is some documentation
for the PORT routines which are used by nlimnb(), the latter is goes
into more detail about optimization.  There are other (possibly much
better) books out there, but it is the only one I am personally
familiar with.

Cheers,

Josh

-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From ramos.grad.student at gmail.com  Wed Jan  4 06:19:12 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 3 Jan 2012 21:19:12 -0800
Subject: [R-sig-ME] cannot increase the number of iterations in lme call
 over 146
In-Reply-To: <CANz9Z_J_hk_s+zHK5d3bQ3UAD3MgM7Ug9t+bC4fx_62piQO34A@mail.gmail.com>
References: <CAHawB9sHsUuZYHqp6Rh_J=gD8L5_44=a48=HjHVERaVT0DhRxw@mail.gmail.com>
	<CANz9Z_Kn3SpfSak5rToOHASYBrGYEodPOxZNTL-WfLm_cyx=dw@mail.gmail.com>
	<CAHawB9tkjXpY=kZvxtcrpHPTCg+1t+95a4_5PC_am+7gRpRdTw@mail.gmail.com>
	<CANz9Z_J_hk_s+zHK5d3bQ3UAD3MgM7Ug9t+bC4fx_62piQO34A@mail.gmail.com>
Message-ID: <CAHawB9sNiaxJqKKV6UbOhC8kjN59yXH2Mep6CN3kA9JEwZ5dLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120103/08816d95/attachment-0002.pl>

From kevinjspring at gmail.com  Wed Jan  4 12:56:50 2012
From: kevinjspring at gmail.com (Kevin Spring)
Date: Wed, 4 Jan 2012 05:56:50 -0600
Subject: [R-sig-ME] extracting values from lmer
Message-ID: <CAPv6FHgzdYBKsagM7Svy3zP+Q7T33LgSaS3BcUYenx6fS8Av-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120104/64888082/attachment-0002.pl>

From robert.espesser at lpl-aix.fr  Wed Jan  4 13:44:26 2012
From: robert.espesser at lpl-aix.fr (espesser)
Date: Wed, 04 Jan 2012 13:44:26 +0100
Subject: [R-sig-ME] extracting values from lmer
In-Reply-To: <CAPv6FHgzdYBKsagM7Svy3zP+Q7T33LgSaS3BcUYenx6fS8Av-w@mail.gmail.com>
References: <CAPv6FHgzdYBKsagM7Svy3zP+Q7T33LgSaS3BcUYenx6fS8Av-w@mail.gmail.com>
Message-ID: <4F0449AA.7000102@lpl-aix.fr>

  Hi Kevin,
Maybe there is a better way (a function) , but you can use:

yourmodel at deviance["sigmaREML"]

it returns the residual std. dev.   :  0.13636
(in case of the default setting for lmer()  , i.e. REML=TRUE)
More generally,  " str(yourmodel)   "   gives useful informations  .
R


Le 04/01/2012 12:56, Kevin Spring a ?crit :
> I am trying to extract the residual variance from the lmer function in the
> package lme4.
>
> For example, I have the following response from lmer:
>
> Random effects:
>>   Groups                  Name            Variance    Std.Dev.
>>   Cell.line:DNA.extract (Intercept)  0.130554    0.36132
>>   Residual                                    *0.018595*     0.13636
>
> I want to extract 0.018595 from this output.
>
> VarCorr allows me to extract the variance 0.130554, but I want to be able
> to extract the Residual variance and I don't see a function that does this
> in lme4.  Any ideas?
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Robert Espesser
CNRS UMR 6057 - Universit? de Provence
5 Avenue Pasteur
13100 AIX-EN-PROVENCE

Tel: +33 (0)413 55 36 26



From esnm2 at mnhn.fr  Wed Jan  4 17:35:31 2012
From: esnm2 at mnhn.fr (esnm2 at mnhn.fr)
Date: Wed, 04 Jan 2012 17:35:31 +0100
Subject: [R-sig-ME] Problems in using GEEs
Message-ID: <20120104173531.93322gdpsqaatntf@dsiwebmail.mnhn.fr>

Dear list

I?m puzzled with running GEEs with a small dataset. I use R 2.11.1
My data (a subset given below- ?muskerbis?) are seasonal abundances of  
two small vertebrate populations on two distinct sites (gui and coc)  
differing by habitat quality (for the animals) and collected over 10  
years (1999-2010, except 2 years ? 2004 and 2006) that I want to  
correlate with climatic variables. I suspect a serial correlation, and  
tried running a GLS with a corAR1 structure within the ?ile? group,  
but even with ranking the dependent variable (absmay ? summer animal  
abundances), i didn?t reached good distribution in residuals and  
homoskedasticity. The best I could get was using a GLM neg.bin  
approach ? but couldn?t include an AR1. I therefore tried GEEs poisson  
with rounded square rooted dependent variable and ?ile? as cluster  
using yags, geepack, and gee packages. The results are below:

> print(muskerbis)
enr	yr	ile	absmay	abssep	ps
1	1999	bgui	288	89	200.8
2	2000	bgui	157	1	133.6
3	2001	bgui	186	34	145.4
4	2002	bgui	102	9	83.4
5	2003	bgui	27	7	134.2
6	2005	bgui	52	6	129.2
7	2007	bgui	75	6	113.8
8	2008	bgui	272	19	254.6
9	2009	bgui	55	16	111.8
10	2010	bgui	104	7	171
11	1999	acoc	361	83	200.8
12	2000	acoc	173	117	133.6
13	2001	acoc	187	29	145.4
14	2002	acoc	292	48	83.4
15	2003	acoc	382	34	134.2
16	2005	acoc	313	138	129.2
17	2007	acoc	202	3	113.8
18	2008	acoc	312	14	254.6
19	2009	acoc	239	4	111.8
20	2010	acoc	211	58	171

cile=as.factor(ile)	##transform ? ile ? as a factor

Using GEEPACK:
guicocgeeglmsumps1=geeglm(as.integer(sqrt(absmay))~cile+ps+cile:ps,  
corstr="ar1", id=cile, family=poisson(link = "log"),
na.action=na.omit, data=muskerbis)
summary(guicocgeeglmsumps1)
Call:
geeglm(formula = as.integer(sqrt(absmay)) ~ cile + ps + cile:ps,
     family = poisson(link = "log"), data = muskerbis, na.action = na.omit,
     id = cile, corstr = "ar1")
Coefficients:
              Estimate   Std.err Wald Pr(>|W|)
(Intercept)  2.621597  0.000000  Inf   <2e-16 ***
cilebgui    -1.002342  0.000000  Inf   <2e-16 ***
ps           0.000935  0.000000  Inf   <2e-16 ***
cilebgui:ps  0.003796  0.000000  Inf   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
Estimated Scale Parameters:
             Estimate Std.err
(Intercept)    0.457   0.171
Correlation: Structure = ar1  Link = identity
Estimated Correlation Parameters:
       Estimate Std.err
alpha    0.235   0.093
Number of clusters:   2   Maximum cluster size: 10

Using YAGS:
guicocyagssumtps1<-yags(as.integer(sqrt(absmay))~cile+ps+cile:ps,  
corstr="ar1", cor.met=rank(yr), id=cile, family=poisson,
data=muskerbis, alphainit=0.)
guicocyagssumtps1
YAGS (yet another GEE solver) $Date: 2004/10/22 18:49:23 $
Call:
yags(formula = as.integer(sqrt(absmay)) ~ cile + ps + cile:ps,
     id = cile, cor.met = rank(yr), family = poisson, corstruct = "ar1",
     alphainit = 0, data = muskerbis)
Regression estimates:
                 est. naive s.e. naive z sand. s.e. sand. z
(Intercept)  2.60549    0.17431   14.95   1.90e-06 1369761
cilebgui    -0.97181    0.28518   -3.41   4.45e-06 -218230
ps           0.00104    0.00095    1.10   1.28e-08   81387
cilebgui:ps  0.00362    0.00146    2.47   2.36e-08  153630
Working correlation model: ar1
alpha est: 0.654
NULL
Pan QIC(R): -3365.819
QLS: 38.87
Rotnitzky-Jewell: 0, 0
yags/R: $Id: yags.R,v 1.5 2004/10/22 18:49:23 stvjc Exp $

Using GEE
guicocgeesumps1<-gee(as.integer(sqrt(absmay))~cile+ps+cile:ps,  
corstr="AR-M", Mv=1, id=cile, family=poisson(link = "log"),
na.action=na.omit, data=muskerbis)
summary(guicocgeesumps1)
GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA
  gee S-function, version 4.13 modified 98/01/27 (1998)
Model:
  Link:                      Logarithm
  Variance to Mean Relation: Poisson
  Correlation Structure:     AR-M , M = 1
Call:
gee(formula = as.integer(sqrt(absmay)) ~ cile + ps + cile:ps,
     id = cile, data = muskerbis, na.action = na.omit, family =  
poisson(link = "log"),
     corstr = "AR-M", Mv = 1)
Summary of Residuals:
    Min     1Q Median     3Q    Max
-4.562 -1.750 -0.649  2.364  3.422
Coefficients:
             Estimate Naive S.E. Naive z Robust S.E. Robust z
(Intercept)  2.60935    0.17772   14.68    9.27e-07  2816177
cilebgui    -0.98027    0.28867   -3.40    2.32e-06  -422088
ps           0.00102    0.00100    1.01    6.49e-09   156718
cilebgui:ps  0.00367    0.00154    2.38    1.31e-08   279242
Estimated Scale Parameter:  0.572
Number of Iterations:  3
Working Correlation
           [,1]     [,2]     [,3]    [,4]    [,5]    [,6]    [,7]      
[,8]     [,9]    [,10]
  [1,] 1.000000 0.369769 0.136729 0.05056 0.01869 0.00691 0.00256  
0.000945 0.000349 0.000129


I believe to have a good design of my model, as geepack ?tells? me I  
have 2 clusters with each 10 obs. residuals rather well behave, so for  
homoskedasticity (not shown). However, I don?t understand why it does  
not produce estimation of the se?s estimates and corresponding Wald  
statistics;
I also do not understand the differences in estimating alpha between  
all packages: 0.235 with geepack, 0.654 with yags, and 0.370 with gee  
??? also for the scale parameter given in gee (0.572) and yags (0.457)  
??
Moreover, although estimates are reliable between packages, it seems  
that na?ve z-values from yags and gee perform better than from  
robust-z ???
Finally, could also someone give me some advice on what to use for  
?fixed? effects selection ? more specifically how to compute a  
?working Wald test? or a ?na?ve likelihood ratio test? as proposed by  
on page 135 by Ballinger 2004 (Organizational Research Methods 2004 7:  
127-150 DOI: 10.1177/1094428104263672) ? as I may have such situation  
here (ie fewer covariates than obs per group ?)

Many thanks by advance for helping me (I?m at the limit of my  
knowledge in maths and informatics ?) and happy new year to everyone
ben



From stefanie.kuchinsky at gmail.com  Wed Jan  4 20:34:38 2012
From: stefanie.kuchinsky at gmail.com (Stefanie Kuchinsky)
Date: Wed, 4 Jan 2012 14:34:38 -0500
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
Message-ID: <CABhs0QY+c0LQkifK80D4W_JjumBWQ1WUmtCYYMrneV5AQpyBEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120104/6ca31548/attachment-0002.pl>

From kevinjspring at gmail.com  Thu Jan  5 00:22:23 2012
From: kevinjspring at gmail.com (Kevin Spring)
Date: Wed, 4 Jan 2012 17:22:23 -0600
Subject: [R-sig-ME] bootstrap variance component in a mixed linear model
Message-ID: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120104/7cc303fb/attachment-0002.pl>

From bbolker at gmail.com  Fri Jan  6 00:01:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 5 Jan 2012 23:01:22 +0000 (UTC)
Subject: [R-sig-ME] extracting values from lmer
References: <CAPv6FHgzdYBKsagM7Svy3zP+Q7T33LgSaS3BcUYenx6fS8Av-w@mail.gmail.com>
	<4F0449AA.7000102@lpl-aix.fr>
Message-ID: <loom.20120106T000059-115@post.gmane.org>

espesser <robert.espesser at ...> writes:

> 
>   Hi Kevin,
> Maybe there is a better way (a function) , but you can use:
> 
> yourmodel <at> deviance["sigmaREML"]
> 
> it returns the residual std. dev.   :  0.13636
> (in case of the default setting for lmer()  , i.e. REML=TRUE)
> More generally,  " str(yourmodel)   "   gives useful informations  .
> R
> 
> Le 04/01/2012 12:56, Kevin Spring a ?crit :
> > I am trying to extract the residual variance from the lmer function in the
> > package lme4.
> >
> > For example, I have the following response from lmer:
> >
> > Random effects:
> >>   Groups                  Name            Variance    Std.Dev.
> >>   Cell.line:DNA.extract (Intercept)  0.130554    0.36132
> >>   Residual                                    *0.018595*     0.13636
> >
> > I want to extract 0.018595 from this output.
> >
> > VarCorr allows me to extract the variance 0.130554, but I want to be able
> > to extract the Residual variance and I don't see a function that does this
> > in lme4.  Any ideas?


   You shouldn't have to work this hard to get it, but I would
suggest:

library(lme4)
example(lmer)  ## to get some examples to work with

attr(VarCorr(fm1),"sc")
[1] 25.59182

fm1 at deviance["sigmaREML"]
sigmaREML 
 25.59182 

both of these count a bit as digging into the internals
(which you're not supposed to do if you can help it, but
in this case you don't have a choice), but the former
is digging slightly less deep.

  Ben Bolker



From Alen.Hajnal at usm.edu  Fri Jan  6 01:22:22 2012
From: Alen.Hajnal at usm.edu (Alen Hajnal)
Date: Thu, 5 Jan 2012 18:22:22 -0600
Subject: [R-sig-ME] Tukey after lme does not match
Message-ID: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1111@CCRMBX01.usmexchange.loc>

Dear R users:
I have a simple lme model based on the following data:
sub	trial	angle	RMSy
1	1	30	3.745084
1	2	0	7.520667
1	3	90	11.17038
1	4	15	7.581526
1	5	60	11.17822
1	6	75	8.440891
1	7	45	13.19024
1	8	15	9.822035
1	9	60	6.002665
1	10	75	4.393961
1	11	0	7.436676

When I run the model the results show that 0vs45, 0vs60, 0vs75, and 0vs90 are all significant main effects:

> m.base01<-lme(RMSy ~ angle+trial, data=data,  random=~ trial|sub,method='ML')
> summary(m.base01)
Fixed effects: RMSy ~ angle + trial 
                	Value 	Std.Error  	DF     t-value     p-value
(Intercept)  5.236020 	0.6312637 	267  8.294505  0.0000
angle15     -0.687669 	0.4140277 	267 -1.660925  0.0979
angle30     -0.571092 	0.4129365 	267 -1.383001  0.1678
angle45     -0.984597 	0.4139330 	267 -2.378638  0.0181
angle60     -0.874718 	0.4135615 	267 -2.115085  0.0353
angle75     -1.389835 	0.4113411 	267 -3.378788  0.0008
angle90     -1.620493 	0.4133209 	267 -3.920666  0.0001
trial       -0.009372 	0.0299782 	267 -0.312620  0.7548

However, when I try to run a Tukey posthoc test, I get different results (notice that the estimates are the same as the main effect values above): ONLY 0vs90 is significant at p<.05 :

> summary(glht(m.base01, linfct=mcp(angle = "Tukey")))

         Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lme.formula(fixed = RMSy ~ angle + trial, data = data, random = ~trial | 
    sub, method = "ML")

Linear Hypotheses:
             Estimate Std. Error z value Pr(>|z|)   
15 - 0 == 0   -0.6877     0.4082  -1.684  0.62652   
30 - 0 == 0   -0.5711     0.4072  -1.403  0.80077   
45 - 0 == 0   -0.9846     0.4081  -2.412  0.19329   
60 - 0 == 0   -0.8747     0.4078  -2.145  0.32592   
75 - 0 == 0   -1.3898     0.4056  -3.427  0.01070 * 
90 - 0 == 0   -1.6205     0.4075  -3.976  0.00138 **
30 - 15 == 0   0.1166     0.4079   0.286  0.99996   
45 - 15 == 0  -0.2969     0.4078  -0.728  0.99090   
60 - 15 == 0  -0.1870     0.4078  -0.459  0.99931   
75 - 15 == 0  -0.7022     0.4050  -1.734  0.59342   
90 - 15 == 0  -0.9328     0.4073  -2.290  0.24842   
45 - 30 == 0  -0.4135     0.4082  -1.013  0.95124   
60 - 30 == 0  -0.3036     0.4074  -0.745  0.98971   
75 - 30 == 0  -0.8187     0.4052  -2.021  0.40123   
90 - 30 == 0  -1.0494     0.4076  -2.574  0.13377   
60 - 45 == 0   0.1099     0.4077   0.269  0.99997   
75 - 45 == 0  -0.4052     0.4059  -0.998  0.95449   
90 - 45 == 0  -0.6359     0.4078  -1.559  0.70835   
75 - 60 == 0  -0.5151     0.4050  -1.272  0.86496   
90 - 60 == 0  -0.7458     0.4074  -1.831  0.52730   
90 - 75 == 0  -0.2307     0.4049  -0.570  0.99763  

Why does the Tukey not match the lme results?
Any help would be much appreciated!
Thanks, Alen




----------
Alen Hajnal, PhD.
Department of Psychology
The University of Southern Mississippi
118 College Drive #5025
Hattiesburg, MS 39406
USA
Tel. +1 (601) 266-4617
alen.hajnal @ usm.edu
http://ocean.otr.usm.edu/~w785427/lab.html


From Alen.Hajnal at usm.edu  Fri Jan  6 01:28:59 2012
From: Alen.Hajnal at usm.edu (Alen Hajnal)
Date: Thu, 5 Jan 2012 18:28:59 -0600
Subject: [R-sig-ME] (SMALL CORRECTION): Tukey after lme does not match
Message-ID: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1112@CCRMBX01.usmexchange.loc>

Actually 0vs75 is also significant according to Tukey, but there is still no perfect match with the initial lme analysis.


----------
Alen Hajnal, PhD.
Department of Psychology
The University of Southern Mississippi
118 College Drive #5025
Hattiesburg, MS 39406
USA
Tel. +1 (601) 266-4617
alen.hajnal @ usm.edu
http://ocean.otr.usm.edu/~w785427/lab.html


From A.Robinson at ms.unimelb.edu.au  Fri Jan  6 01:54:42 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 6 Jan 2012 11:54:42 +1100
Subject: [R-sig-ME] (SMALL CORRECTION): Tukey after lme does not match
In-Reply-To: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1112@CCRMBX01.usmexchange.loc>
References: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1112@CCRMBX01.usmexchange.loc>
Message-ID: <CAHyGmd6L6L-+ug5FdmiPQPH4qi7GKh-xMbfOkWOBuGO181pb7A@mail.gmail.com>

Dear Alen,

I suggest that it might be useful for you to do some background
reading on the purposes and interpretations of Wald tests (which are
the tests that you are interpreting directly from lme) and
Tukey-corrected tests (from the Tukey output).

But, very briefly, it would be very surprising if the two were to
agree.  The Wald tests p-values are computed for each test as though
it were the only one under consideration, whereas the Tukey p-values
are computed taking account of the inference of the other tests.  So,
the more comparisons being performed at the same time (here, 6 + 5 + 4
+ 3 + 2 + 1 = 21), the more conservative Tukey will be, whereas the
Wald test will not change.

I hope that this helps --- but I reiterate my recommendation for
background reading.

Andrew

On Fri, Jan 6, 2012 at 11:28 AM, Alen Hajnal <Alen.Hajnal at usm.edu> wrote:
> Actually 0vs75 is also significant according to Tukey, but there is still no perfect match with the initial lme analysis.
>
>
> ----------
> Alen Hajnal, PhD.
> Department of Psychology
> The University of Southern Mississippi
> 118 College Drive #5025
> Hattiesburg, MS 39406
> USA
> Tel. +1 (601) 266-4617
> alen.hajnal @ usm.edu
> http://ocean.otr.usm.edu/~w785427/lab.html
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Andrew Robinson
Deputy Director, ACERA
Senior Lecturer in Applied Statistics??????????? ? ? ? ? ? Tel: +61-3-8344-6410
Department of Mathematics and Statistics??????????? Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au??? Website: http://www.ms.unimelb.edu.au

FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/



From djmuser at gmail.com  Fri Jan  6 05:36:41 2012
From: djmuser at gmail.com (Dennis Murphy)
Date: Thu, 5 Jan 2012 20:36:41 -0800
Subject: [R-sig-ME] Tukey after lme does not match
In-Reply-To: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1111@CCRMBX01.usmexchange.loc>
References: <4A593B57C2A1A948B04891C5B8F0F26B12BB5F1111@CCRMBX01.usmexchange.loc>
Message-ID: <CADv2QyF0TYAR9=D2__cXDcWuxYDapE+m6pzqMP4rw2-9A72AkQ@mail.gmail.com>

Hi:

In addition to Dr. Robinson's comments, I would add the following:

(i) Your model specification indicates that you want random slopes for
trial by subject with correlated intercepts. Is that what you
intended?
(ii) I'm wondering why you're not treating angle as a continuous
variable and looking for potential trends in the response as a
function of angle. If you have a discernable trend, its form would be
more useful than a collection of multiple comparisons. Did you plot
the response by subject and angle (either a conditioning plot by
subject or a 'spaghetti plot' of individual profiles of (angle, RMSy)
pairs)?

My 2c,
Dennis

On Thu, Jan 5, 2012 at 4:22 PM, Alen Hajnal <Alen.Hajnal at usm.edu> wrote:
> Dear R users:
> I have a simple lme model based on the following data:
> sub ? ? trial ? angle ? RMSy
> 1 ? ? ? 1 ? ? ? 30 ? ? ?3.745084
> 1 ? ? ? 2 ? ? ? 0 ? ? ? 7.520667
> 1 ? ? ? 3 ? ? ? 90 ? ? ?11.17038
> 1 ? ? ? 4 ? ? ? 15 ? ? ?7.581526
> 1 ? ? ? 5 ? ? ? 60 ? ? ?11.17822
> 1 ? ? ? 6 ? ? ? 75 ? ? ?8.440891
> 1 ? ? ? 7 ? ? ? 45 ? ? ?13.19024
> 1 ? ? ? 8 ? ? ? 15 ? ? ?9.822035
> 1 ? ? ? 9 ? ? ? 60 ? ? ?6.002665
> 1 ? ? ? 10 ? ? ?75 ? ? ?4.393961
> 1 ? ? ? 11 ? ? ?0 ? ? ? 7.436676
>
> When I run the model the results show that 0vs45, 0vs60, 0vs75, and 0vs90 are all significant main effects:
>
>> m.base01<-lme(RMSy ~ angle+trial, data=data, ?random=~ trial|sub,method='ML')
>> summary(m.base01)
> Fixed effects: RMSy ~ angle + trial
> ? ? ? ? ? ? ? ? ? ? ? ?Value ? Std.Error ? ? ? DF ? ? t-value ? ? p-value
> (Intercept) ?5.236020 ? 0.6312637 ? ? ? 267 8.294505 ?0.0000
> angle15 ? ? -0.687669 ? 0.4140277 ? ? ? 267 -1.660925 ?0.0979
> angle30 ? ? -0.571092 ? 0.4129365 ? ? ? 267 -1.383001 ?0.1678
> angle45 ? ? -0.984597 ? 0.4139330 ? ? ? 267 -2.378638 ?0.0181
> angle60 ? ? -0.874718 ? 0.4135615 ? ? ? 267 -2.115085 ?0.0353
> angle75 ? ? -1.389835 ? 0.4113411 ? ? ? 267 -3.378788 ?0.0008
> angle90 ? ? -1.620493 ? 0.4133209 ? ? ? 267 -3.920666 ?0.0001
> trial ? ? ? -0.009372 ? 0.0299782 ? ? ? 267 -0.312620 ?0.7548
>
> However, when I try to run a Tukey posthoc test, I get different results (notice that the estimates are the same as the main effect values above): ONLY 0vs90 is significant at p<.05 :
>
>> summary(glht(m.base01, linfct=mcp(angle = "Tukey")))
>
> ? ? ? ? Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: lme.formula(fixed = RMSy ~ angle + trial, data = data, random = ~trial |
> ? ?sub, method = "ML")
>
> Linear Hypotheses:
> ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> 15 - 0 == 0 ? -0.6877 ? ? 0.4082 ?-1.684 ?0.62652
> 30 - 0 == 0 ? -0.5711 ? ? 0.4072 ?-1.403 ?0.80077
> 45 - 0 == 0 ? -0.9846 ? ? 0.4081 ?-2.412 ?0.19329
> 60 - 0 == 0 ? -0.8747 ? ? 0.4078 ?-2.145 ?0.32592
> 75 - 0 == 0 ? -1.3898 ? ? 0.4056 ?-3.427 ?0.01070 *
> 90 - 0 == 0 ? -1.6205 ? ? 0.4075 ?-3.976 ?0.00138 **
> 30 - 15 == 0 ? 0.1166 ? ? 0.4079 ? 0.286 ?0.99996
> 45 - 15 == 0 ?-0.2969 ? ? 0.4078 ?-0.728 ?0.99090
> 60 - 15 == 0 ?-0.1870 ? ? 0.4078 ?-0.459 ?0.99931
> 75 - 15 == 0 ?-0.7022 ? ? 0.4050 ?-1.734 ?0.59342
> 90 - 15 == 0 ?-0.9328 ? ? 0.4073 ?-2.290 ?0.24842
> 45 - 30 == 0 ?-0.4135 ? ? 0.4082 ?-1.013 ?0.95124
> 60 - 30 == 0 ?-0.3036 ? ? 0.4074 ?-0.745 ?0.98971
> 75 - 30 == 0 ?-0.8187 ? ? 0.4052 ?-2.021 ?0.40123
> 90 - 30 == 0 ?-1.0494 ? ? 0.4076 ?-2.574 ?0.13377
> 60 - 45 == 0 ? 0.1099 ? ? 0.4077 ? 0.269 ?0.99997
> 75 - 45 == 0 ?-0.4052 ? ? 0.4059 ?-0.998 ?0.95449
> 90 - 45 == 0 ?-0.6359 ? ? 0.4078 ?-1.559 ?0.70835
> 75 - 60 == 0 ?-0.5151 ? ? 0.4050 ?-1.272 ?0.86496
> 90 - 60 == 0 ?-0.7458 ? ? 0.4074 ?-1.831 ?0.52730
> 90 - 75 == 0 ?-0.2307 ? ? 0.4049 ?-0.570 ?0.99763
>
> Why does the Tukey not match the lme results?
> Any help would be much appreciated!
> Thanks, Alen
>
>
>
>
> ----------
> Alen Hajnal, PhD.
> Department of Psychology
> The University of Southern Mississippi
> 118 College Drive #5025
> Hattiesburg, MS 39406
> USA
> Tel. +1 (601) 266-4617
> alen.hajnal @ usm.edu
> http://ocean.otr.usm.edu/~w785427/lab.html
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From sorenh at math.aau.dk  Thu Jan  5 13:27:41 2012
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Thu, 5 Jan 2012 12:27:41 +0000
Subject: [R-sig-ME] bootstrap variance component in a mixed linear model
In-Reply-To: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>
References: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3F75B6D@AD-EXCHMBX2-1.aau.dk>

Hi Kevin,

In the pbkrtest package there is function PBmodcomp for calculating p-values using parametric bootstrap and in the implementation of this function I have also observed the same phenomenon. I guess that what happens is simply that some of the bootstrap samples lead to "singularities" somewhere in the estimation algorithms. My solution in PBmodcomp has been to use the suppressWarnings() function...

Cheers
S?ren
 

-----Oprindelig meddelelse-----
Fra: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] P? vegne af Kevin Spring
Sendt: 5. januar 2012 00:22
Til: r-sig-mixed-models at r-project.org
Emne: [R-sig-ME] bootstrap variance component in a mixed linear model

Hi, everyone.  I don't know what is going wrong with my bootstrap.  Could anyone help me find out what is wrong?

I am trying to bootstrap the variance component in a mixed linear model.

My statistic for the bootstrap is the following:

varcomp <- function ( formula, data, indices ) {
>     d <- data[indices,] #sample for boot
>     fit <- lmer(formula, data=d) #linear model
>     return (attr (VarCorr(fit), "sc")^2) #output random effects 
> residual var }


The formula for the model is: log( y ) ~ ( 1 | a:b ) + a, where '*b*' is a
random effect nested within '*a';* which is a fixed effect.

When I run the linear model on its own it works fine, but when I try to run
the bootstrap I get warning messages of false convergence.

Warning messages:
> 1: In mer_finalize(ans) : false convergence (8)
> 2: In mer_finalize(ans) : false convergence (8)
> 3: In mer_finalize(ans) : false convergence (8)
> 4: In mer_finalize(ans) : false convergence (8)
> 5: In mer_finalize(ans) : false convergence (8)
> 6: In mer_finalize(ans) : false convergence (8)


The example data I used can be downloaded at:
http://www.mediafire.com/?77xb24rmul90k5d

The R code I actually did:

library(boot)
library(lme4)
#
#Load data
#
fp1 <- read.csv("desktop/p1f.csv")
#Set as factors
fp1$Cell.line <- as.factor(fp1$Cell.line)
fp1$DNA.extract <- as.factor(fp1$DNA.extract)
#test mixed model
lm1 <- lmer(formula=log(CNPC)~(1|Cell.line:DNA.extract)+Cell.line,data=fp1)
attr (VarCorr(lm1), "sc")
#
##Bootstrap statistic
#
varcomp <- function ( formula, data, indices ) {
    d <- data[indices,] #sample for boot
    fit <- lmer(formula, data=d) #linear model
    return (attr (VarCorr(fit), "sc")) #output random effects residual
standard deviation
}
##Bootstrap with 1000 replicates
fp1.boot <- boot ( data = fp1, statistic=varcomp, R=1000,
formula=log(CNPC)~(1|Cell.line:DNA.extract)+Cell.line)

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From geralttee at gmail.com  Fri Jan  6 19:08:28 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Fri, 6 Jan 2012 19:08:28 +0100
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
Message-ID: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/53f952ee/attachment-0002.pl>

From bbolker at gmail.com  Fri Jan  6 19:40:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Jan 2012 18:40:28 +0000 (UTC)
Subject: [R-sig-ME] covariance structures for longitudinal models
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
	<CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>
	<CAHawB9utWpzVSgTBz82M1O4ss5Th+NvZtt4bLCJGe581uitHPA@mail.gmail.com>
Message-ID: <loom.20120106T191953-19@post.gmane.org>

Antonio P. Ramos <ramos.grad.student at ...> writes:

> 
> Thanks for your replies. To complement my own question: would  MCMCglmm do
> the job?

  I don't think so, because your models all seem to be expressed in
terms of R-side correlation, and MCMCglmm (although quite a bit more
flexible than lmer) does not seem to be as flexible as lme (or GLIMMIX/
NLMIXED) in specifying R-side correlations.  There aren't a huge
number of examples of the use of the 'rcov' argument in the MCMCglmm
course notes, but the examples there are show things like

  rcov=~us(trait):units 

  this is for a multi-response model, so the residual variance is
modeled within units, with 'us' (unstructured) and different variances
for each trait (so, e.g. ~us(time):units should fit an unstructured
correlation model)

  rcov=~idh(trait):units allows different variances by trait but
enforces independence

  The only other option that makes sense here is ~idv (equal variances)
which basically reduces to unstructured residuals.

    I started working on a 'corClass' definition that follows
the antecedent model you requested (and, if it worked, could serve
as a model for implementing other possibilities, such as the
anisotropic spatial correlation models people have asked about
previously on the list).  It's not quite working -- I still
have some confusions about when transformed vs untransformed
(or in lme's terminology "unconstrained" vs "constrained"
parameters are used -- but it's a start, and in case I don't
get around to doing anything further with it I thought I
would make it available at 
<http://www.math.mcmaster.ca/bolker/R/misc/newcorstruct.R>

> 
> On Mon, Jan 2, 2012 at 8:13 AM, Joshua Wiley <jwiley.psych at ...> wrote:
> 
> > Hi Antonio,
> >
> > I am not familiar with antedependence models so no comment there.
> >
> > For factor analysis and that genre, I like OpenMx (also see sem and
> > lavaan).  One thing I like about OpenMx is while it caters to SEM, it
> > is a general purpose matrix optimizer, and it really is not difficult
> > to access that power.  So in principal, you can have whatever matrices
> > you want, roll your own objective function, and away it'll go.
> >
> > For BUGS you have a lot of options including: R2OpenBUGS and R2WinBUGS
> > among others.
> >
> > Cheers,
> >
> > Josh
> >
> > On Mon, Jan 2, 2012 at 12:41 AM, Antonio P. Ramos
> > <ramos.grad.student at ...> wrote:
> > > Hi all,
> > >
> > > I've trying to use R to fit some longitudinal models, mostly via lme and
> > > nlme packages. However, it seems that many standard models are lacking,
> > > such as antedependence models or factor analytic models for covariance
> > > matrices. These models are readily available in SAS. Does an recommend
> > > other packages for the job in R? I don't really care if I am in
> > frequentist
> > > or bayesian world as long as I have more modeling flexibility. I would
> > also
> > > be interested in doing that in WINBUGS/JAGS.
> > >
> > > All the best,
> > >
> > > Antonio.
> > >
> > >        [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at ... mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> > --
> > Joshua Wiley
> > Ph.D. Student, Health Psychology
> > Programmer Analyst II, Statistical Consulting Group
> > University of California, Los Angeles
> > https://joshuawiley.com/
> >
> 
> 	[[alternative HTML version deleted]]
> 
>



From m.lee.davis at gmail.com  Fri Jan  6 19:54:01 2012
From: m.lee.davis at gmail.com (Lee Davis)
Date: Fri, 6 Jan 2012 13:54:01 -0500
Subject: [R-sig-ME] Correlated count data technique advice
Message-ID: <CAPiP9jVXdjnMT-+ipPArd8yZ_zpmhy5dden6hZU7gYOXyrdZpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/e9a18c65/attachment-0002.pl>

From stefanie.kuchinsky at gmail.com  Fri Jan  6 19:55:44 2012
From: stefanie.kuchinsky at gmail.com (Stefanie Kuchinsky)
Date: Fri, 6 Jan 2012 13:55:44 -0500
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
In-Reply-To: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>
References: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>
Message-ID: <CABhs0QZ7x0AGBtqJ-QmoCoV=xZPgRd5kSi3nJY=9aCukuwF6=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/64f5b1cd/attachment-0002.pl>

From stefanie.kuchinsky at gmail.com  Fri Jan  6 20:40:34 2012
From: stefanie.kuchinsky at gmail.com (Stefanie Kuchinsky)
Date: Fri, 6 Jan 2012 14:40:34 -0500
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
In-Reply-To: <CABhs0QZ7x0AGBtqJ-QmoCoV=xZPgRd5kSi3nJY=9aCukuwF6=Q@mail.gmail.com>
References: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>
	<CABhs0QZ7x0AGBtqJ-QmoCoV=xZPgRd5kSi3nJY=9aCukuwF6=Q@mail.gmail.com>
Message-ID: <CABhs0QYvR4yQ87GhozjDAc5ZW6eXbWEEU+PH4-1WMU1r4pf3jg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/b741879d/attachment-0002.pl>

From geralttee at gmail.com  Fri Jan  6 21:05:38 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Fri, 6 Jan 2012 21:05:38 +0100
Subject: [R-sig-ME] question regarding summary output with three-way
	interactions
In-Reply-To: <CABhs0QYvR4yQ87GhozjDAc5ZW6eXbWEEU+PH4-1WMU1r4pf3jg@mail.gmail.com>
References: <CANXb-o5Y8jaysBK9g3WX8JW4yE2Zh5hxoi8+B8SKV8aD86wK2w@mail.gmail.com>
	<CABhs0QZ7x0AGBtqJ-QmoCoV=xZPgRd5kSi3nJY=9aCukuwF6=Q@mail.gmail.com>
	<CABhs0QYvR4yQ87GhozjDAc5ZW6eXbWEEU+PH4-1WMU1r4pf3jg@mail.gmail.com>
Message-ID: <CANXb-o6-Wwv9eaGq1ofGxPyODtKFQpLayJJpCVOzBF_QSk6=aw@mail.gmail.com>

Hi again,

you're right. usually when terms are missing in our output - it means
the're not identifiable from our data (e.g. there's not enough
replication or specific combinations of factors are missing) - that's
why your'e getting some interactions tested after removing some other
terms. As for which terms to include - my conservative way of doing
things is to include lower terms always when I want to have higher
terms. What happens when you remove the triple interactions? Also I
wouldn;t say that interpretation of continous:categorical interactions
?should be avoided in cases similar to yours: such interactions
quantify differences in betas at respective levels of the categorical
variable and provide useful valuable insight to how your response
changes with the covariate. What however should be avoided (or better
said - applied with caution) is drawing conclusions about categorical
variables (i.e. A or B in your model) if the're involved in
significant interactions with continous variables (problem similar to
heterogenous slopes in classical ANCOVA).

Cheers,
sz.

On 6 January 2012 20:40, Stefanie Kuchinsky
<stefanie.kuchinsky at gmail.com> wrote:
>
> I just realized a probable explanation.
>
> For the time3 term for which it only displayed half of the interaction term, the lower order time3:A and time3:B had been included in the model.
>
> However, there was no time4:A in the model (though there was time4:B). When I removed this effect, I now get both parts of the interaction term output [and the F test df are now correct (2, 9294) instead of (1, 9294)]. I assume that this means the higher order terms are redundant with the lower order terms in the model.
>
> Is it then appropriate to remove the lower order interactions from the model (even though they appear significant when I run anova() and given their betas)? I believe I should not be theoretically interpreting time3:A when there is a time3:A:B interaction, anyway.
>
> So, I would interpret the betas for these terms very generally:
> time3:A1:B0 -- The effect of the cubic polynomial modulated by A (1 > 0) when B is held constant at 0.
> time3:A1:B1 -- The effect of the cubic polynomial as modulated by A (1>0) when B is held constant at 1.
>
> Thanks again for your input-- I wouldn't have thought of this is you hadn't mentioned looking at the lower order terms.
>
>
>
> On Fri, Jan 6, 2012 at 1:55 PM, Stefanie Kuchinsky <stefanie.kuchinsky at gmail.com> wrote:
>>
>> Thanks so much for your response. I had not included some of the output table to save space in the original email, but the model does include the lower order terms. I've pasted the full table at the bottom of this email. The polynomial terms were indeed created with the poly() function.
>>
>> You were exactly right about the continuous vs. factor error in my second dataset. I had a typo in my code and so B had never been converted to a factor. I really appreciate you catching that!
>>
>> However, I'm still confused about the interpretation of time4:A1:B1-- specifically why there is no beta for time4:A1:B0 when there is both a beta for time3:A1:B1 and time3:A1:B0?
>>
>>
>> Again, snippet of dataset 1 output:
>>
>> time3:A1:B1?? -68.6999? 33.14614 9294? -2.07264? 0.0382
>> time4:A1:B0?? 132.5765? 23.43786 9294?? 5.65651? 0.0000
>> time4:A1:B1? -124.2845? 23.43786 9294? -5.30272? 0.0000
>>
>> Corrected output for dataset 2:
>> time3:A1:B1?? 135.0679?? 46.2636 9294?? 2.91953? 0.0035
>> time4:A1:B0??? 80.8813?? 32.7133 9294?? 2.47243? 0.0134
>> time4:A1:B1? -108.9340?? 32.7133 9294? -3.32996? 0.0009
>>
>>
>> Full table for dataset 1(minus the correlation tables):
>>
>> > summary(m.int4e)
>> Linear mixed-effects model fit by maximum likelihood
>> ?Data: Data
>> ?????? AIC????? BIC??? logLik
>> ? 109842.6 110837.5 -54782.28
>>
>> Random effects:
>> ?Formula: ~time1 | subjAB
>> ?Structure: General positive-definite, Log-Cholesky parametrization
>> ??????????? StdDev??? Corr
>> (Intercept)? 38.33670 (Intr)
>> time1???????? 434.94747 0.488
>> Residual???? 75.40533
>>
>> Fixed effects: pupil1000 ~ time1 + time2 + time3 + time4 + time5 + subj + subj:time1 + subj:time2 +????? subj:time3 + subj:time4 + subj:time5 + A:time1 + A:time2 + A:time3 +????? A:time5 + B:time3 + B:time4 + A:B:time3 + A:B:time4
>> ?????????????????????? Value Std.Error?? DF?? t-value p-value
>> (Intercept)???????? 976.6327? 19.63384 9294? 49.74231? 0.0000
>> time1???????????????? 891.8779 226.37671 9294?? 3.93980? 0.0001
>> time2??????????????? -917.0701? 38.86729 9294 -23.59491? 0.0000
>> time3??????????????? -131.3754? 40.59556 9294? -3.23620? 0.0012
>> time4???????????????? 459.9003? 40.59556 9294? 11.32883? 0.0000
>> time5??????????????? -444.2458? 38.86729 9294 -11.42981? 0.0000
>> subj2??????????????? 47.7965? 27.76645?? 63?? 1.72137? 0.0901
>> subj3??????????????? 65.4712? 27.76645?? 63?? 2.35793? 0.0215
>> subj4?????????????? 130.2721? 27.76645?? 63?? 4.69171? 0.0000
>> subj5??????????????? 57.2987? 27.76645?? 63?? 2.06359? 0.0432
>> subj6??????????????? 25.6571? 27.76645?? 63?? 0.92403? 0.3590
>> subj7??????????????? -7.6969? 27.76645?? 63? -0.27720? 0.7825
>> subj8??????????????? 81.3031? 27.76645?? 63?? 2.92811? 0.0047
>> subj9??????????????? 15.1726? 27.76645?? 63?? 0.54644? 0.5867
>> subj10?????????????? 62.5996? 27.76645?? 63?? 2.25450? 0.0276
>> subj11????????????? -64.4270? 27.76645?? 63? -2.32032? 0.0236
>> subj12?????????????? 10.0465? 27.76645?? 63?? 0.36182? 0.7187
>> subj13?????????????? 43.7500? 27.76645?? 63?? 1.57564? 0.1201
>> subj14?????????????? 26.4845? 27.76645?? 63?? 0.95383? 0.3438
>> subj15????????????? -46.7323? 27.76645?? 63? -1.68305? 0.0973
>> subj16????????????? 137.6261? 27.76645?? 63?? 4.95656? 0.0000
>> subj17?????????????? 14.9735? 27.76645?? 63?? 0.53926? 0.5916
>> subj18?????????????? 26.3230? 27.76645?? 63?? 0.94802? 0.3467
>> subj19?????????????? 55.4912? 27.76645?? 63?? 1.99850? 0.0500
>> subj20?????????????? 98.4027? 27.76645?? 63?? 3.54394? 0.0007
>> subj21????????????? 162.8186? 27.76645?? 63?? 5.86386? 0.0000
>> time1:subj2????????? -848.2627 314.38569 9294? -2.69816? 0.0070
>> time1:subj3????????? -462.8857 314.38569 9294? -1.47235? 0.1410
>> time1:subj4????????? -286.9459 314.38569 9294? -0.91272? 0.3614
>> time1:subj5????????? -350.9655 314.38569 9294? -1.11635? 0.2643
>> time1:subj6???????? -1079.1256 314.38569 9294? -3.43249? 0.0006
>> time1:subj7????????? -958.1396 314.38569 9294? -3.04766? 0.0023
>> time1:subj8?????????? 396.6793 314.38569 9294?? 1.26176? 0.2071
>> time1:subj9?????????? 870.7418 314.38569 9294?? 2.76966? 0.0056
>> time1:subj10???????? 2433.2401 314.38569 9294?? 7.73967? 0.0000
>> time1:subj11????????? 518.0574 314.38569 9294?? 1.64784? 0.0994
>> time1:subj12???????? -544.9605 314.38569 9294? -1.73341? 0.0831
>> time1:subj13???????? -142.6669 314.38569 9294? -0.45380? 0.6500
>> time1:subj14???????? -447.2835 314.38569 9294? -1.42272? 0.1549
>> time1:subj15?????????? 73.0371 314.38569 9294?? 0.23232? 0.8163
>> time1:subj16???????? -147.8436 314.38569 9294? -0.47026? 0.6382
>> time1:subj17???????? -321.5527 314.38569 9294? -1.02280? 0.3064
>> time1:subj18??????? -1104.0885 314.38569 9294? -3.51189? 0.0004
>> time1:subj19???????? -500.0802 314.38569 9294? -1.59066? 0.1117
>> time1:subj20?????????? 73.0061 314.38569 9294?? 0.23222? 0.8164
>> time1:subj21???????? -977.4932 314.38569 9294? -3.10922? 0.0019
>> time2:subj2?????????? 103.9564? 53.70288 9294?? 1.93577? 0.0529
>> time2:subj3?????????? 462.7823? 53.70288 9294?? 8.61746? 0.0000
>> time2:subj4?????????? 133.1718? 53.70288 9294?? 2.47979? 0.0132
>> time2:subj5?????????? 435.4522? 53.70288 9294?? 8.10854? 0.0000
>> time2:subj6?????????? 866.3608? 53.70288 9294? 16.13248? 0.0000
>> time2:subj7????????? 1040.2131? 53.70288 9294? 19.36978? 0.0000
>> time2:subj8?????????? -48.0412? 53.70288 9294? -0.89457? 0.3710
>> time2:subj9?????????? -33.9246? 53.70288 9294? -0.63171? 0.5276
>> time2:subj10????????? 575.5907? 53.70288 9294? 10.71806? 0.0000
>> time2:subj11???????? -534.9280? 53.70288 9294? -9.96088? 0.0000
>> time2:subj12????????? 180.5477? 53.70288 9294?? 3.36197? 0.0008
>> time2:subj13???????? -919.1235? 53.70288 9294 -17.11498? 0.0000
>> time2:subj14????????? 585.8640? 53.70288 9294? 10.90936? 0.0000
>> time2:subj15????????? 405.6596? 53.70288 9294?? 7.55378? 0.0000
>> time2:subj16??????? -1104.0865? 53.70288 9294 -20.55917? 0.0000
>> time2:subj17????????? 877.9724? 53.70288 9294? 16.34870? 0.0000
>> time2:subj18???????? 1828.7923? 53.70288 9294? 34.05389? 0.0000
>> time2:subj19????????? 820.0829? 53.70288 9294? 15.27074? 0.0000
>> time2:subj20?????????? 44.1932? 53.70288 9294?? 0.82292? 0.4106
>> time2:subj21????????? 845.2039? 53.70288 9294? 15.73852? 0.0000
>> time3:subj2?????????? 658.7997? 53.70288 9294? 12.26749? 0.0000
>> time3:subj3??????????? 30.3625? 53.70288 9294?? 0.56538? 0.5718
>> time3:subj4?????????? 595.8939? 53.70288 9294? 11.09612? 0.0000
>> time3:subj5?????????? 243.5716? 53.70288 9294?? 4.53554? 0.0000
>> time3:subj6?????????? 350.5870? 53.70288 9294?? 6.52827? 0.0000
>> time3:subj7??????????? 62.7208? 53.70288 9294?? 1.16792? 0.2429
>> time3:subj8?????????? 187.1384? 53.70288 9294?? 3.48470? 0.0005
>> time3:subj9????????? -745.5636? 53.70288 9294 -13.88312? 0.0000
>> time3:subj10???????? -937.4916? 53.70288 9294 -17.45701? 0.0000
>> time3:subj11????????? 349.5809? 53.70288 9294?? 6.50954? 0.0000
>> time3:subj12???????? -419.0377? 53.70288 9294? -7.80289? 0.0000
>> time3:subj13????????? 812.8245? 53.70288 9294? 15.13558? 0.0000
>> time3:subj14????????? 179.8396? 53.70288 9294?? 3.34879? 0.0008
>> time3:subj15???????? -150.8652? 53.70288 9294? -2.80926? 0.0050
>> time3:subj16???????? 1267.6097? 53.70288 9294? 23.60413? 0.0000
>> time3:subj17????????? 223.1138? 53.70288 9294?? 4.15460? 0.0000
>> time3:subj18?????????? 83.5245? 53.70288 9294?? 1.55531? 0.1199
>> time3:subj19???????? 1295.0211? 53.70288 9294? 24.11455? 0.0000
>> time3:subj20????????? 599.0144? 53.70288 9294? 11.15423? 0.0000
>> time3:subj21????????? 142.3725? 53.70288 9294?? 2.65111? 0.0080
>> time4:subj2????????? -357.4785? 53.70288 9294? -6.65660? 0.0000
>> time4:subj3????????? -343.2897? 53.70288 9294? -6.39239? 0.0000
>> time4:subj4????????? -705.7852? 53.70288 9294 -13.14241? 0.0000
>> time4:subj5????????? -445.1367? 53.70288 9294? -8.28888? 0.0000
>> time4:subj6????????? -602.6113? 53.70288 9294 -11.22121? 0.0000
>> time4:subj7????????? -421.4880? 53.70288 9294? -7.84852? 0.0000
>> time4:subj8??????????? 30.3527? 53.70288 9294?? 0.56520? 0.5720
>> time4:subj9?????????? 563.3041? 53.70288 9294? 10.48927? 0.0000
>> time4:subj10???????? -206.4712? 53.70288 9294? -3.84470? 0.0001
>> time4:subj11????????? 515.5052? 53.70288 9294?? 9.59921? 0.0000
>> time4:subj12????????? 184.6193? 53.70288 9294?? 3.43779? 0.0006
>> time4:subj13????????? 293.2901? 53.70288 9294?? 5.46135? 0.0000
>> time4:subj14???????? -478.9555? 53.70288 9294? -8.91862? 0.0000
>> time4:subj15???????? -240.5382? 53.70288 9294? -4.47906? 0.0000
>> time4:subj16???????? -975.5266? 53.70288 9294 -18.16526? 0.0000
>> time4:subj17???????? -403.4663? 53.70288 9294? -7.51294? 0.0000
>> time4:subj18???????? -876.2704? 53.70288 9294 -16.31701? 0.0000
>> time4:subj19??????? -1979.2893? 53.70288 9294 -36.85629? 0.0000
>> time4:subj20???????? -534.4526? 53.70288 9294? -9.95203? 0.0000
>> time4:subj21???????? -448.4306? 53.70288 9294? -8.35022? 0.0000
>> time5:subj2?????????? -10.8598? 53.70288 9294? -0.20222? 0.8397
>> time5:subj3?????????? 356.3984? 53.70288 9294?? 6.63649? 0.0000
>> time5:subj4?????????? 321.0171? 53.70288 9294?? 5.97765? 0.0000
>> time5:subj5?????????? 159.0899? 53.70288 9294?? 2.96241? 0.0031
>> time5:subj6?????????? 277.8362? 53.70288 9294?? 5.17358? 0.0000
>> time5:subj7?????????? 392.0390? 53.70288 9294?? 7.30015? 0.0000
>> time5:subj8??????????? 76.0262? 53.70288 9294?? 1.41568? 0.1569
>> time5:subj9?????????? 675.6410? 53.70288 9294? 12.58109? 0.0000
>> time5:subj10????????? 739.3099? 53.70288 9294? 13.76667? 0.0000
>> time5:subj11???????? -218.8505? 53.70288 9294? -4.07521? 0.0000
>> time5:subj12????????? 315.8796? 53.70288 9294?? 5.88199? 0.0000
>> time5:subj13???????? -248.9957? 53.70288 9294? -4.63654? 0.0000
>> time5:subj14????????? 396.2154? 53.70288 9294?? 7.37792? 0.0000
>> time5:subj15????????? 231.0236? 53.70288 9294?? 4.30188? 0.0000
>> time5:subj16????????? 224.9218? 53.70288 9294?? 4.18826? 0.0000
>> time5:subj17????????? 209.4774? 53.70288 9294?? 3.90067? 0.0001
>> time5:subj18????????? 505.3070? 53.70288 9294?? 9.40931? 0.0000
>> time5:subj19????????? 369.0887? 53.70288 9294?? 6.87279? 0.0000
>> time5:subj20????????? 275.5678? 53.70288 9294?? 5.13134? 0.0000
>> time5:subj21????????? 480.7268? 53.70288 9294?? 8.95160? 0.0000
>>
>>
>> time1:A1??????????? 353.1338? 85.49229 9294?? 4.13059? 0.0000
>> time2:A1??????????? -68.5389? 16.57307 9294? -4.13556? 0.0000
>> time3:A1?????????? -154.4407? 23.43786 9294? -6.58937? 0.0000
>> time5:A1??????????? 123.8607? 16.57307 9294?? 7.47361? 0.0000
>> time3:B1??????? 100.1996? 23.43786 9294?? 4.27512? 0.0000
>> time4:B1??????? 201.6411? 23.43786 9294?? 8.60322? 0.0000
>> time3:A1:B1?? -68.6999? 33.14614 9294? -2.07264? 0.0382
>> time4:A1:B0?? 132.5765? 23.43786 9294?? 5.65651? 0.0000
>> time4:A1:B1? -124.2845? 23.43786 9294? -5.30272? 0.0000
>>
>>
>>
>>
>>
>> On Fri, Jan 6, 2012 at 1:08 PM, Szymek Drobniak <geralttee at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> for me it's unclear how you specify your data and your model. in general - it seems that you're using user-made polynomial terms? or have you used the poly() function to form them? I'm asking because you don't have most of the lower-order terms in your output. as for the interaction - it's interpretation is fairly straightforward. E.g. interaction of time4:A1:B1 contains the fourth order coefficient of regression for your relationship in the objects from both A1 and B1 groups. The lack of 0/1 next to B in the second example may be caused by accidental conversion of B into numerical (rather than factor) variable - in such a situation it would be treated as continous variable and just a single regression coefficient would be returned.
>>>
>>> cheers,
>>> sz.
>>>
>>> --
>>> Szymon Drobniak || Population Ecology Group
>>> Institute of Environmental Sciences,?Jagiellonian University
>>> ul. Gronostajowa 7, 30-387 Krak?w, POLAND
>>> tel.: +48 12 664 51 79 fax: +48 12 664 69 12
>>>
>>> www.eko.uj.edu.pl/drobniak
>>
>>
>



--
Szymon Drobniak || Population Ecology Group
Institute of Environmental Sciences,?Jagiellonian University
ul. Gronostajowa 7, 30-387 Krak?w, POLAND
tel.: +48 12 664 51 79 fax: +48 12 664 69 12

www.eko.uj.edu.pl/drobniak



From ramos.grad.student at gmail.com  Fri Jan  6 21:41:08 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Fri, 6 Jan 2012 12:41:08 -0800
Subject: [R-sig-ME] covariance structures for longitudinal models
In-Reply-To: <loom.20120106T191953-19@post.gmane.org>
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
	<CANz9Z_KdnkJD=-KSVHAaUHn=Wf5B5bOqRVXvaGddRtSTH15PCA@mail.gmail.com>
	<CAHawB9utWpzVSgTBz82M1O4ss5Th+NvZtt4bLCJGe581uitHPA@mail.gmail.com>
	<loom.20120106T191953-19@post.gmane.org>
Message-ID: <CAHawB9u-9aVYcGsmuNQyFVfbZmpD1Vbf+erPvpS81pqnMnE01Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/c87bae39/attachment-0002.pl>

From kw.stat at gmail.com  Fri Jan  6 22:01:50 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 6 Jan 2012 15:01:50 -0600
Subject: [R-sig-ME] covariance structures for longitudinal models
In-Reply-To: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
References: <CAHawB9vnqnRiE6HZX2GVMKbmqKg1_kG3Sfz3ciDOVwY17C+4vA@mail.gmail.com>
Message-ID: <CAKFxdiRZZb1Wuy8MCbvnmmJovm47KZpMW4_RaK81nnbYHOAeSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120106/ebfc6712/attachment-0002.pl>

From jens.astrom at slu.se  Sun Jan  8 08:55:03 2012
From: jens.astrom at slu.se (=?UTF-8?B?SmVucyDDhXN0csO2bQ==?=)
Date: Sun, 08 Jan 2012 08:55:03 +0100
Subject: [R-sig-ME] Mean of random effects same as fixed effect?
Message-ID: <4F094BD7.1080408@slu.se>

Hi all,

A couple of weeks ago I posted a question but got no answers. Here goes
a second attempt, now shorter and more general.


Are the following two model specifications interchangeable, or is there
a statistical reason for why it is not OK to express model 1 in the form
of model 2?

Model 1)
y=fixed.intercept+fixed.slope*x+random.intercept+random.slope*x

Model 2)
y=random.intercept*x+random.slope*x
fixed.intercept=mean(random.intercept)
fixed.slope=mean(random.slope)



The reasons for my asking is that I have trouble getting convergence
with model specification 1, when the random intercepts and random slopes
are correlated, but specifying it as model 2 seemed to work. This is me
trying to implement some standard mixed models in BUGS/JAGS. Original
post with complete working example is here:
http://markmail.org/message/vhqeq4j3kldttlt5



I'm happy for any comments, with or without BUGS/JAGS code.

/Jens Astrom



From Thierry.ONKELINX at inbo.be  Mon Jan  9 10:07:21 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 9 Jan 2012 09:07:21 +0000
Subject: [R-sig-ME] Correlated count data technique advice
In-Reply-To: <CAPiP9jVXdjnMT-+ipPArd8yZ_zpmhy5dden6hZU7gYOXyrdZpA@mail.gmail.com>
References: <CAPiP9jVXdjnMT-+ipPArd8yZ_zpmhy5dden6hZU7gYOXyrdZpA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742757324440@inbomail.inbo.be>

Dear Lee,

A large numbers of zero do not imply zero-inflation. E.g.
> mean(rpois(10000, 0.01) == 0)
[1] 0.9902
This simulation has 99% zero's and is not zero-inflated.

Since you have a timeserie at only one location and one measurement per year there is no point in using a mixed model.

Wouldn't it be more relevant to look directly at the temperature than using a derived variable?

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Lee Davis
Verzonden: vrijdag 6 januari 2012 19:54
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Correlated count data technique advice

Please excuse me for having posted a similar question on ecolog, but thus far I have received few useful answers there.

I am looking for some advice concerning techniques in R that are appropriate for correlated count data.

Specifically, I have some "freezing days" data, which is a count of the number of days each spring that were below freezing. The counts were taken at the same location over a period of years. The data set is highly zero inflated and over-dispersed; glm with a quasipoisson error structure would seem to be appropriate, except that there is a high degree of correlation at lags of 1 making something like a corAR1 structure appropriate. My difficulty is that glm() does not take an argument for correlation.

I could use  lmer() to fit a model like:

freezing days~years+(1|years), family=quasipoisson, correlation=corAR1

but lmer (and glmer) don't seem to be operating on quasi families anymore; I've found plenty of old posts here where lmer seems to have accepted quasi families in the past, but I get an error message that indicates lmer does not in fact accept quasi families.

I should note that I have run the following model:

 freeze.glmmPQL3<-glmmPQL(num.
freeze.days~years, random= ~1|years,
       family=quasipoisson,correlation=corAR1())

My gut says this is not the correct approach and I am unconvinced by the tiny p values that have been returned, especially as specification of poisson vs quasipoisson and the specification of corAR1() seem to make no difference to parameter estimation or p vals for said pars--it would seem that the random term for varying intercept by year is dominant. Maybe this is OK, but my above glm models return non-significant results and I expected handling the correlation to increase my p vals rather than decrease them. Perhaps an incorrect assumption.

Therefore I need some alternative to look at trends in this data over time that allows for quasipoisson error and something along the lines of a
corAR1() structure (or a mixed model that handles temporal pseudo-replication, but I am hesitant here).

Thank you in advance,
Lee

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From g.leckie at bristol.ac.uk  Mon Jan  9 13:51:46 2012
From: g.leckie at bristol.ac.uk (George Leckie)
Date: Mon, 9 Jan 2012 12:51:46 +0000 (UTC)
Subject: [R-sig-ME] =?utf-8?b?cGFja2FnZSDigJhsbWU0YeKAmSBpcyBub3QgYXZhaWxh?=
	=?utf-8?q?ble_=28for_R_version_2=2E14=2E1=29?=
Message-ID: <loom.20120109T134811-751@post.gmane.org>

Hi All,

I am having problems installing lme4a

> install.packages("lme4a", repos="http://R-Forge.R-project.org")
Installing package(s) into ?D:/Program Files/R/R-2.14.1/library?
(as ?lib? is unspecified)
Warning in install.packages :
 package ?lme4a? is not available (for R version 2.14.1)

I tried this on 2.13.0 and this produced the same error

Any ideas? Aplogies in advanced if I am making a trivial error (I am new to R).

Many thanks

George



From bates at stat.wisc.edu  Mon Jan  9 21:02:06 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 9 Jan 2012 14:02:06 -0600
Subject: [R-sig-ME] Mean of random effects same as fixed effect?
In-Reply-To: <4F094BD7.1080408@slu.se>
References: <4F094BD7.1080408@slu.se>
Message-ID: <CAO7JsnT+9YeewXf1izJ41Fh_uSMPweLOCsi4TDNjr=OgT6wSjw@mail.gmail.com>

On Sun, Jan 8, 2012 at 1:55 AM, Jens ?str?m <jens.astrom at slu.se> wrote:
> Hi all,
>
> A couple of weeks ago I posted a question but got no answers. Here goes
> a second attempt, now shorter and more general.
>
>
> Are the following two model specifications interchangeable, or is there
> a statistical reason for why it is not OK to express model 1 in the form
> of model 2?
>
> Model 1)
> y=fixed.intercept+fixed.slope*x+random.intercept+random.slope*x
>
> Model 2)
> y=random.intercept*x+random.slope*x
> fixed.intercept=mean(random.intercept)
> fixed.slope=mean(random.slope)

You would need at least equal group sizes and identical values of the
covariate with respect to which you have a random slope to be able to
count on this.  Even then I'm not entirely sure it would work.

Generally the unconditional distribution of the random effects is
defined to have a mean of zero.  I don't know how you are defining
yours (and prefer not to wade through BUGS/JAGS model specifications
to find out).

> The reasons for my asking is that I have trouble getting convergence
> with model specification 1, when the random intercepts and random slopes
> are correlated, but specifying it as model 2 seemed to work. This is me
> trying to implement some standard mixed models in BUGS/JAGS. Original
> post with complete working example is here:
> http://markmail.org/message/vhqeq4j3kldttlt5
>
>
>
> I'm happy for any comments, with or without BUGS/JAGS code.
>
> /Jens Astrom
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From m.lee.davis at gmail.com  Tue Jan 10 02:47:11 2012
From: m.lee.davis at gmail.com (Lee Davis)
Date: Mon, 9 Jan 2012 20:47:11 -0500
Subject: [R-sig-ME] Correlated Count Data
Message-ID: <CAPiP9jWWMyKoLq72ugF-_Kk6ziQL3E5Wm2vVoW7Lr0vJD7T1CA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120109/332499b9/attachment-0002.pl>

From Thierry.ONKELINX at inbo.be  Tue Jan 10 09:58:16 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 10 Jan 2012 08:58:16 +0000
Subject: [R-sig-ME] Correlated Count Data
In-Reply-To: <CAPiP9jWWMyKoLq72ugF-_Kk6ziQL3E5Wm2vVoW7Lr0vJD7T1CA@mail.gmail.com>
References: <CAPiP9jWWMyKoLq72ugF-_Kk6ziQL3E5Wm2vVoW7Lr0vJD7T1CA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742757327E37@inbomail.inbo.be>

Lee,

I don't think you can use glmgee either because that is also designed to handle multiple timelines.

So you probabily need some kind of timeseries approach that can handle poisson data. But that is outside my expertise.

A new post on another list seems a good idea.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Lee Davis
Verzonden: dinsdag 10 januari 2012 2:47
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Correlated Count Data

Thierry,

I agree that the data is not actually zero-inflated and so I haven't worried with something like a ZIP. I also have no desire to use a mixed model for the very reason you state-that the measures were made at one location.

As for using temperature rather than a derived variable--as much as I may agree, that one's not my call.

What would your opinion be one the use of geeglm() for this data?

Perhaps it may be more appropriate to move this thread to the general help list.

Thank you,

Lee



---------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 9 Jan 2012 09:07:21 +0000
> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> To: Lee Davis <m.lee.davis at gmail.com>,
>        "r-sig-mixed-models at r-project.org"      <
> r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Correlated count data technique advice
> Message-ID:
>        <AA818EAD2576BC488B4F623941DA742757324440 at inbomail.inbo.be>
> Content-Type: text/plain; charset="us-ascii"
>
> Dear Lee,
>
> A large numbers of zero do not imply zero-inflation. E.g.
> > mean(rpois(10000, 0.01) == 0)
> [1] 0.9902
> This simulation has 99% zero's and is not zero-inflated.
>
> Since you have a timeserie at only one location and one measurement 
> per year there is no point in using a mixed model.
>
> Wouldn't it be more relevant to look directly at the temperature than 
> using a derived variable?
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] Namens Lee Davis
> Verzonden: vrijdag 6 januari 2012 19:54
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Correlated count data technique advice
>
> Please excuse me for having posted a similar question on ecolog, but 
> thus far I have received few useful answers there.
>
> I am looking for some advice concerning techniques in R that are 
> appropriate for correlated count data.
>
> Specifically, I have some "freezing days" data, which is a count of 
> the number of days each spring that were below freezing. The counts 
> were taken at the same location over a period of years. The data set 
> is highly zero inflated and over-dispersed; glm with a quasipoisson 
> error structure would seem to be appropriate, except that there is a 
> high degree of correlation at lags of 1 making something like a corAR1 
> structure appropriate. My difficulty is that glm() does not take an argument for correlation.
>
> I could use  lmer() to fit a model like:
>
> freezing days~years+(1|years), family=quasipoisson, correlation=corAR1
>
> but lmer (and glmer) don't seem to be operating on quasi families 
> anymore; I've found plenty of old posts here where lmer seems to have 
> accepted quasi families in the past, but I get an error message that 
> indicates lmer does not in fact accept quasi families.
>
> I should note that I have run the following model:
>
>  freeze.glmmPQL3<-glmmPQL(num.
> freeze.days~years, random= ~1|years,
>       family=quasipoisson,correlation=corAR1())
>
> My gut says this is not the correct approach and I am unconvinced by 
> the tiny p values that have been returned, especially as specification 
> of poisson vs quasipoisson and the specification of corAR1() seem to 
> make no difference to parameter estimation or p vals for said pars--it 
> would seem that the random term for varying intercept by year is 
> dominant. Maybe this is OK, but my above glm models return 
> non-significant results and I expected handling the correlation to 
> increase my p vals rather than decrease them. Perhaps an incorrect assumption.
>
> Therefore I need some alternative to look at trends in this data over 
> time that allows for quasipoisson error and something along the lines 
> of a
> corAR1() structure (or a mixed model that handles temporal 
> pseudo-replication, but I am hesitant here).
>
> Thank you in advance,
> Lee
>
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From highstat at highstat.com  Tue Jan 10 13:52:06 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 10 Jan 2012 08:52:06 -0400
Subject: [R-sig-ME] Correlated Count Data
Message-ID: <4F0C3476.70601@highstat.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120110/bd9a2097/attachment-0002.pl>

From Michelle.Gosse at foodstandards.gov.au  Tue Jan 10 20:05:47 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Wed, 11 Jan 2012 06:05:47 +1100
Subject: [R-sig-ME] nlme model not working but lme models are fine
	[SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4EC@EXCHANGE07.foodstandards.gov.au>

Hi all,

I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.

My working lme4 code is:
Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
	data=Male.Data,
	weights = SampleWeight)

Where:
BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.

I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.

In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):

Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.

male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
		data = Male.Group,
		random = ~ 1 | RespondentID)
		

When I run the next bit,I get an error. Error and traceback() provided after the syntax:

Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
		fixed = ordered(AgeFactor) + IntakeDay ~ 1,
		random = RespondentID ~ 1,
		data = Male.Group,
		start= fixef(male.lme2)
		)

I get the error message:
Error in eval(expr, envir, enclos) : object 'AgeFactor' not found

The results of traceback() are:
8: eval(expr, envir, enclos)
7: eval(x[[length(x)]], dat)
6: FUN(X[[1L]], ...)
5: lapply(form, function(x, dat, N) {
       val <- eval(x[[length(x)]], dat)
       if (length(val) == 1) {
           return(as.factor(rep(val, N)))
       }
       else {
           return(as.factor(val)[drop = TRUE])
       }
   }, dat = object, N = nrow(object))
4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1", deparse(groups[[2]]), 
       sep = "|"))))
3: getGroups(dataMix, eval(parse(text = paste("~1", deparse(groups[[2]]), 
       sep = "|"))))
2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed = ordered(AgeFactor) + 
       IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group, 
       start = fixef(male.lme2))
1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed = ordered(AgeFactor) + 
       IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group, 
       start = fixef(male.lme2))

Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.

cheers
Michelle

UNCLASSIFIED
**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}



From bates at stat.wisc.edu  Tue Jan 10 20:56:05 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 10 Jan 2012 13:56:05 -0600
Subject: [R-sig-ME] nlme model not working but lme models are fine
	[SEC=UNCLASSIFIED]
In-Reply-To: <12E932690323AB4EBEEB21BAA28D90DE369E10A4EC@EXCHANGE07.foodstandards.gov.au>
References: <12E932690323AB4EBEEB21BAA28D90DE369E10A4EC@EXCHANGE07.foodstandards.gov.au>
Message-ID: <CAO7JsnT5qmFPz04jKcubgNOW+Xa6R0AAWueGvW+AvfpYuP45bA@mail.gmail.com>

On Tue, Jan 10, 2012 at 1:05 PM, Gosse, Michelle
<Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi all,
>
> I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.

So what is the nonlinear model?  You haven't specified it in your call to nlme.

> My working lme4 code is:
> Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
> ? ? ? ?data=Male.Data,
> ? ? ? ?weights = SampleWeight)
>
> Where:
> BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
> IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.
>
> I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.
>
> In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):
>
> Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.
>
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?random = ~ 1 | RespondentID)
>
>
> When I run the next bit,I get an error. Error and traceback() provided after the syntax:
>
> Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?fixed = ordered(AgeFactor) + IntakeDay ~ 1,
> ? ? ? ? ? ? ? ?random = RespondentID ~ 1,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?start= fixef(male.lme2)
> ? ? ? ? ? ? ? ?)

Your formula is not an nlme specification.  The right hand side of the
formula should be a function call using nonlinear model parameters and
covariates.  You are using a linear model formula on the right hand
side and this will not give the result you are expecting.

> I get the error message:
> Error in eval(expr, envir, enclos) : object 'AgeFactor' not found
>
> The results of traceback() are:
> 8: eval(expr, envir, enclos)
> 7: eval(x[[length(x)]], dat)
> 6: FUN(X[[1L]], ...)
> 5: lapply(form, function(x, dat, N) {
> ? ? ? val <- eval(x[[length(x)]], dat)
> ? ? ? if (length(val) == 1) {
> ? ? ? ? ? return(as.factor(rep(val, N)))
> ? ? ? }
> ? ? ? else {
> ? ? ? ? ? return(as.factor(val)[drop = TRUE])
> ? ? ? }
> ? }, dat = object, N = nrow(object))
> 4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1", deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 3: getGroups(dataMix, eval(parse(text = paste("~1", deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed = ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
> 1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed = ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
>
> Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.



From bates at stat.wisc.edu  Tue Jan 10 21:32:10 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 10 Jan 2012 14:32:10 -0600
Subject: [R-sig-ME] bootstrap variance component in a mixed linear model
In-Reply-To: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>
References: <CAPv6FHhxLpr7MtP2rQsO67r38mn=Xi7fWjHTi2Si2SFWM7kosg@mail.gmail.com>
Message-ID: <CAO7JsnSgMvfiv7gq676-P4uO2LDXS5=hzkgp_5_7xQcyEezrNg@mail.gmail.com>

On Wed, Jan 4, 2012 at 5:22 PM, Kevin Spring <kevinjspring at gmail.com> wrote:
> Hi, everyone. ?I don't know what is going wrong with my bootstrap. ?Could
> anyone help me find out what is wrong?
>
> I am trying to bootstrap the variance component in a mixed linear model.
>
> My statistic for the bootstrap is the following:
>
> varcomp <- function ( formula, data, indices ) {
>> ? ? d <- data[indices,] #sample for boot
>> ? ? fit <- lmer(formula, data=d) #linear model
>> ? ? return (attr (VarCorr(fit), "sc")^2) #output random effects residual
>> var
>> }
>
>
> The formula for the model is: log( y ) ~ ( 1 | a:b ) + a, where '*b*' is a
> random effect nested within '*a';* which is a fixed effect.
>
> When I run the linear model on its own it works fine, but when I try to run
> the bootstrap I get warning messages of false convergence.
>
> Warning messages:
>> 1: In mer_finalize(ans) : false convergence (8)
>> 2: In mer_finalize(ans) : false convergence (8)
>> 3: In mer_finalize(ans) : false convergence (8)
>> 4: In mer_finalize(ans) : false convergence (8)
>> 5: In mer_finalize(ans) : false convergence (8)
>> 6: In mer_finalize(ans) : false convergence (8)
>

Those warnings are coming from the optimizer used in lme4 (the same
one as in the R function nlminb).  Finding reliable code for
optimizing a nonlinear function subject to box constraints (in this
case, standard deviations being greater than zero) is not easy.
Eventually I gave up and created an implementation of the Nelder-Mead
simplex method (the version used in the optim function in R doesn't
handle constraints) which can be a bit slower but is also more
reliable.  This is used in the development version of lme4 called
lme4Eigen. (I know - "not ANOTHER development version".  I have a
rather severe "best is the enemy of the good" problem.)

For some GLMMs the version of glmer in lme4Eigen is both faster and
more reliable.

Ben has set a deadline of January for releasing what is now lme4Eigen
as lme4.  I hope he means the end of January and not the beginning of
January.

We would appreciate feedback on lme4Eigen.  Unfortunately you need to
compile it to be able to use it on Windows or on Mac OS X (sigh).  On
Windows there is a problem with compiling the 64-bit version which
traces back to something in Rcpp.  It may be possible to make a small
change in Rcpp to bypass that.  On Mac OS X the compilation of
RcppEigen, on which lme4Eigen depends, croaks because the decade-old
compiler that Apple still uses has bugs.  Apparently Apple is going to
replace gcc-4.2.1 with clang in a new release of Xcode so that logjam
may be freed up too.


> The example data I used can be downloaded at:
> http://www.mediafire.com/?77xb24rmul90k5d
>
> The R code I actually did:
>
> library(boot)
> library(lme4)
> #
> #Load data
> #
> fp1 <- read.csv("desktop/p1f.csv")
> #Set as factors
> fp1$Cell.line <- as.factor(fp1$Cell.line)
> fp1$DNA.extract <- as.factor(fp1$DNA.extract)
> #test mixed model
> lm1 <- lmer(formula=log(CNPC)~(1|Cell.line:DNA.extract)+Cell.line,data=fp1)
> attr (VarCorr(lm1), "sc")
> #
> ##Bootstrap statistic
> #
> varcomp <- function ( formula, data, indices ) {
> ? ?d <- data[indices,] #sample for boot
> ? ?fit <- lmer(formula, data=d) #linear model
> ? ?return (attr (VarCorr(fit), "sc")) #output random effects residual
> standard deviation
> }
> ##Bootstrap with 1000 replicates
> fp1.boot <- boot ( data = fp1, statistic=varcomp, R=1000,
> formula=log(CNPC)~(1|Cell.line:DNA.extract)+Cell.line)
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Stefan.Schreiber at ales.ualberta.ca  Tue Jan 10 23:30:34 2012
From: Stefan.Schreiber at ales.ualberta.ca (Schreiber, Stefan)
Date: Tue, 10 Jan 2012 15:30:34 -0700
Subject: [R-sig-ME] lmer model for repeated measure in RCB design
Message-ID: <70F02259E17B6242B15D81E58EB7EB11087B5A17@afhe-ex.afhe.ualberta.ca>


Hi all,

I have a questions about the following situation and was hoping to find
clarification here.

I have a data frame with the following variables:

id, genotype, group, block, climate, response

I measured a response of 7 genotypes in a randomized complete block
design. I measured each genotype 8 times (n=48). I grouped my 7
genotypes into 3 for me more reasonable groups. I measured the response
on the same 7 genotypes 3 times under different climatic conditions.

I specified block and genotype as random and group as fixed. I believe
the proper random statement should look like: block, genotype nested
within group.

I came up with the following code:

fit1 <- lmer(weight ~ group*climate + (1|block) + (1|group/genotype) ,
data=df)

The problem I have now is how can I include the fact that I measured the
same genotypes at three different times? Can I say (1|group/genotype/id)
instead of (1|group/genotype)?

Thanks for any comments on this!

Stefan



From Michelle.Gosse at foodstandards.gov.au  Wed Jan 11 04:04:33 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Wed, 11 Jan 2012 14:04:33 +1100
Subject: [R-sig-ME] nlme model not working but lme models are fine
 [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F0@EXCHANGE07.foodstandards.gov.au>

Hi,

Thanks for the help.  I'm now trying to figure out (1) the function and (2) how to specify it in nlme. 

cheers
Michelle

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Wednesday, January 11, 2012 8:56 AM
To: Gosse, Michelle
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]

On Tue, Jan 10, 2012 at 1:05 PM, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi all,
>
> I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.

So what is the nonlinear model?  You haven't specified it in your call to nlme.

> My working lme4 code is:
> Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
> ? ? ? ?data=Male.Data,
> ? ? ? ?weights = SampleWeight)
>
> Where:
> BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
> IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.
>
> I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.
>
> In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):
>
> Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.
>
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?random = ~ 1 | RespondentID)
>
>
> When I run the next bit,I get an error. Error and traceback() provided after the syntax:
>
> Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?fixed = ordered(AgeFactor) + IntakeDay ~ 1,
> ? ? ? ? ? ? ? ?random = RespondentID ~ 1,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?start= fixef(male.lme2)
> ? ? ? ? ? ? ? ?)

Your formula is not an nlme specification.  The right hand side of the formula should be a function call using nonlinear model parameters and covariates.  You are using a linear model formula on the right hand side and this will not give the result you are expecting.

> I get the error message:
> Error in eval(expr, envir, enclos) : object 'AgeFactor' not found
>
> The results of traceback() are:
> 8: eval(expr, envir, enclos)
> 7: eval(x[[length(x)]], dat)
> 6: FUN(X[[1L]], ...)
> 5: lapply(form, function(x, dat, N) {
> ? ? ? val <- eval(x[[length(x)]], dat)
> ? ? ? if (length(val) == 1) {
> ? ? ? ? ? return(as.factor(rep(val, N)))
> ? ? ? }
> ? ? ? else {
> ? ? ? ? ? return(as.factor(val)[drop = TRUE])
> ? ? ? }
> ? }, dat = object, N = nrow(object))
> 4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1", 
> deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 3: getGroups(dataMix, eval(parse(text = paste("~1", 
> deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
> ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
> 1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
> ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
>
> Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.

UNCLASSIFIED

**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}



From h.l.ward at qmul.ac.uk  Wed Jan 11 16:59:46 2012
From: h.l.ward at qmul.ac.uk (Helen Ward)
Date: Wed, 11 Jan 2012 15:59:46 +0000
Subject: [R-sig-ME] Mixed model with zero truncated Poisson distributed data
Message-ID: <4F0DB1F2.70406@qmul.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120111/be8d1be9/attachment-0002.pl>

From bonny.marica at gmail.com  Wed Jan 11 17:29:55 2012
From: bonny.marica at gmail.com (Bonny Marica)
Date: Thu, 12 Jan 2012 00:29:55 +0800
Subject: [R-sig-ME] Mixed model with zero truncated Poisson distributed
	data
In-Reply-To: <4F0DB1F2.70406@qmul.ac.uk>
References: <4F0DB1F2.70406@qmul.ac.uk>
Message-ID: <CAO-DCq9p8rprV9MWHS1evQR9H+=vLwFAnixCbELK8Gwueqn8aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/2e83396c/attachment-0002.pl>

From bbolker at gmail.com  Wed Jan 11 19:46:46 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Jan 2012 18:46:46 +0000 (UTC)
Subject: [R-sig-ME] Mixed model with zero truncated Poisson distributed
	data
References: <4F0DB1F2.70406@qmul.ac.uk>
Message-ID: <loom.20120111T194340-544@post.gmane.org>

Helen Ward <h.l.ward at ...> writes:

> I would like to describe the relationship between age and male 
> reproductive success in a population of greater horseshoe bats.
> 
> My data consists of three columns: MaleID, Age, NumberofPups (at that 
> age). Many of the males appear multiple times in the data set, so I 
> believe I need to derive a mixed model with MaleID as a random variable.
> 
> The data is Poisson distributed, but zero-truncated. So far I have only 
> succeeded in making a mixed model with a poisson distribution (using 
> glmmPQL in the MASS package), and a zero truncated poisson model (using 
> vglm in the VGAM package), but not a mixed model capable of handling 
> zero truncated Poisson data.
> 
> It has been suggested that I could just minus 1 from each value in the 
> NumberofPups column to make a more usual Poisson distribution, so I can 
> ignore the zero truncated bit. I have tried this and it changes the 
> results of the model, but is this an acceptable transformation?
> 
> If not, can anyone advise me on a mixed model that can handle zero 
> truncated Poisson data please?
> 
  
  Thanks for letting us know about cross-posting.

  You should be able to do this in either the MCMCglmm package or
(recent versions of) the glmmADMB package.  In MCMCglmm, use
family="ztpoisson"; in glmmADMB, use family="truncpoiss" ...

  Ben Bolker



From bbolker at gmail.com  Wed Jan 11 20:13:15 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Jan 2012 19:13:15 +0000 (UTC)
Subject: [R-sig-ME] lmer model for repeated measure in RCB design
References: <70F02259E17B6242B15D81E58EB7EB11087B5A17@afhe-ex.afhe.ualberta.ca>
Message-ID: <loom.20120111T195022-335@post.gmane.org>

Schreiber, Stefan <Stefan.Schreiber at ...> writes:

> 
> 
> Hi all,
> 
> I have a questions about the following situation and was hoping to find
> clarification here.
> 
> I have a data frame with the following variables:
> 
> id, genotype, group, block, climate, response
> 
> I measured a response of 7 genotypes in a randomized complete block
> design. I measured each genotype 8 times (n=48). 

    You have some missing combinations?  (8*7=56, right?) 

> I grouped my 7
> genotypes into 3 for me more reasonable groups. I measured the response
> on the same 7 genotypes 3 times under different climatic conditions.
> 
> I specified block and genotype as random and group as fixed.  I believe
> the proper random statement should look like: block, genotype nested
> within group.
> 
> I came up with the following code:
> 
> fit1 <- lmer(weight ~ group*climate + (1|block) + (1|group/genotype) ,
> data=df)
> 
> The problem I have now is how can I include the fact that I measured the
> same genotypes at three different times? Can I say (1|group/genotype/id)
> instead of (1|group/genotype)?

  Is id a unique identifier for each observation?  In that
case it's definitely redundant with the residual variance and
should not be included in the model statement.

  I'm still a little bit uncertain about your experimental design
(thanks for the careful explanation, though).  I'm going to make up
one possible explanation.  How unbalanced is it?  Does climate
represent another level of replication (e.g. are there three climate
conditions that are measured for each group*genotype*block
combination), or does it vary in an unbalanced way across
group*genotype*block combinations?  Would your total number
of observations be 8 (blocks) * 7 (genotypes) * 3 (climate conditions)?

  You shouldn't include group both as a fixed effect (your
fixed group*climate term expands to group+climate+group:climate)
and a random effect (your group/genotype term expands to 
group+group:genotype).  You should probably use
(1|group:genotype) instead (make sure group and genotype
are both stored as factors).

  Even if it weren't redundant, including a random effect of
group (with only three groups) is likely to give you an
estimated group-level variance of zero -- there aren't enough
levels to estimate variance reliably.

  If genotypes have unique IDs then you don't need the explicit
nesting or interaction syntax.  If so, my best guess is that

weight ~ group*climate + (1|block) + (1|genotype)

is what you want.

You might consider whether it's worth including other random terms --
the most complex model would include (group*climate|block)
and (climate|genotype) -- but you might find that you were running
out of signal ...



From Stefan.Schreiber at ales.ualberta.ca  Wed Jan 11 21:49:00 2012
From: Stefan.Schreiber at ales.ualberta.ca (Schreiber, Stefan)
Date: Wed, 11 Jan 2012 13:49:00 -0700
Subject: [R-sig-ME] lmer model for repeated measure in RCB design
References: <70F02259E17B6242B15D81E58EB7EB11087B5A17@afhe-ex.afhe.ualberta.ca>
	<loom.20120111T195022-335@post.gmane.org>
Message-ID: <70F02259E17B6242B15D81E58EB7EB1107B35E6E@afhe-ex.afhe.ualberta.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120111/d913c6e7/attachment-0002.pl>

From bbolker at gmail.com  Wed Jan 11 21:58:57 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Jan 2012 15:58:57 -0500
Subject: [R-sig-ME] lmer model for repeated measure in RCB design
In-Reply-To: <70F02259E17B6242B15D81E58EB7EB1107B35E6D@afhe-ex.afhe.ualberta.ca>
References: <70F02259E17B6242B15D81E58EB7EB11087B5A17@afhe-ex.afhe.ualberta.ca>
	<loom.20120111T195022-335@post.gmane.org>
	<70F02259E17B6242B15D81E58EB7EB1107B35E6D@afhe-ex.afhe.ualberta.ca>
Message-ID: <4F0DF811.20303@gmail.com>

  [cc'ing back to r-sig-mixed-models]


On 12-01-11 03:47 PM, Schreiber, Stefan wrote:
> Thanks Ben!
> 
> Yes, you are right, n=56. I don't know what happened there ;)
> 
> As for the ID, yes it is unique for each observation and identifies
> the sampled genotype in its respective block. The ID is build as
> "Genotype_Block".

  Technically, I would say that ID is not technically unique for each
observation since there are three observations (fall, winter, and
spring) for each ID ... ?  (You confirm this below: "each ID is
replicated three times ...") (By "observation", I mean the smallest
sampling unit -- one row of the data frame, in long format)

> Each genotype was replicated 5 times within each
> block. That way I was able to sample 8 genotypes by only having 5
> blocks. That means I sampled three blocks twice for the respective
> genotype.

  Makes sense.
> 
> Then I measured a physiological response on these genotypes in fall,
> winter and spring, representing different climate conditions. I
> always measured the same IDs over three different conditions (56*3).
> So each ID is replicated three times in my ID column.
> 
> Also, I grouped these 7 genotypes into 3 groups since I would rather
> compare the groups within each climatic condition and across the
> climatic conditions instead of all the genotypes.

  That makes perfect sense.
> 
> Since the ID is replicated 3 times, id is nested within genotype,
> correct?
> 
> response ~ group*climate + (1|block) + (1|genotype/id)

  This looks reasonable, although since id is *implicitly* nested (i.e.
it contains the genotype info) you should also be able to write it as
(1|genotype) + (1|id) .

   When you run this, lmer should report appropriate numbers of levels
in each group (block=5, genotype=8, genotype:id = 56? or 40? I'm not
sure ...) ... check these values and see that they are as you expect.
> 
> 
> Thanks again! Stefan
> 
> 
> 
> -----Original Message----- From:
> r-sig-mixed-models-bounces at r-project.org on behalf of Ben Bolker 
> Sent: Wed 1/11/2012 12:13 PM To: r-sig-mixed-models at r-project.org 
> Subject: Re: [R-sig-ME] lmer model for repeated measure in RCB
> design
> 
> Schreiber, Stefan <Stefan.Schreiber at ...> writes:
> 
>> 
>> 
>> Hi all,
>> 
>> I have a questions about the following situation and was hoping to
>> find clarification here.
>> 
>> I have a data frame with the following variables:
>> 
>> id, genotype, group, block, climate, response
>> 
>> I measured a response of 7 genotypes in a randomized complete
>> block design. I measured each genotype 8 times (n=48).
> 
> You have some missing combinations?  (8*7=56, right?)
> 
>> I grouped my 7 genotypes into 3 for me more reasonable groups. I
>> measured the response on the same 7 genotypes 3 times under
>> different climatic conditions.
>> 
>> I specified block and genotype as random and group as fixed.  I
>> believe the proper random statement should look like: block,
>> genotype nested within group.
>> 
>> I came up with the following code:
>> 
>> fit1 <- lmer(weight ~ group*climate + (1|block) +
>> (1|group/genotype) , data=df)
>> 
>> The problem I have now is how can I include the fact that I
>> measured the same genotypes at three different times? Can I say
>> (1|group/genotype/id) instead of (1|group/genotype)?
> 
> Is id a unique identifier for each observation?  In that case it's
> definitely redundant with the residual variance and should not be
> included in the model statement.
> 
> I'm still a little bit uncertain about your experimental design 
> (thanks for the careful explanation, though).  I'm going to make up 
> one possible explanation.  How unbalanced is it?  Does climate 
> represent another level of replication (e.g. are there three climate 
> conditions that are measured for each group*genotype*block 
> combination), or does it vary in an unbalanced way across 
> group*genotype*block combinations?  Would your total number of
> observations be 8 (blocks) * 7 (genotypes) * 3 (climate conditions)?
> 
> You shouldn't include group both as a fixed effect (your fixed
> group*climate term expands to group+climate+group:climate) and a
> random effect (your group/genotype term expands to 
> group+group:genotype).  You should probably use (1|group:genotype)
> instead (make sure group and genotype are both stored as factors).
> 
> Even if it weren't redundant, including a random effect of group
> (with only three groups) is likely to give you an estimated
> group-level variance of zero -- there aren't enough levels to
> estimate variance reliably.
> 
> If genotypes have unique IDs then you don't need the explicit nesting
> or interaction syntax.  If so, my best guess is that
> 
> weight ~ group*climate + (1|block) + (1|genotype)
> 
> is what you want.
> 
> You might consider whether it's worth including other random terms
> -- the most complex model would include (group*climate|block) and
> (climate|genotype) -- but you might find that you were running out of
> signal ...
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
>



From Michelle.Gosse at foodstandards.gov.au  Wed Jan 11 23:35:08 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Thu, 12 Jan 2012 09:35:08 +1100
Subject: [R-sig-ME] nlme model not working but lme models are fine
 [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F5@EXCHANGE07.foodstandards.gov.au>

Hi all,

I've replied to my message so hopefully the archive will stay tracking this as a single question.

Having examined the log likelihood formulae I was given for the SAS code, read Chapter 7 of Pinheiro & Bates, and searching for help,  I have got as far as (note, I am not using a grouped data frame as I get an error in nlme.fomula message saying that the "starting values for the fixed component are the wrong length" when I do this):

male.lme3 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
	data=Male.Data,
	random= ~1|RespondentID)

and then I am trying to run the following, and yes I wish the covariates to be additive the model I am basing this on (from SAS) has additive covariates:
Male.nlme <- nlme(BoxCoxXY ~ A + B*factor(AgeFactor) + C*factor(IntakeDay),
	data=Male.Data,
	fixed= A + B + C ~ 1,
	random=A ~1,
	group=RespondentID,
	start=fixef(male.lme3)
	)

I get the error " Error in eval(expr, envir, enclos) : object 'A' not found"

I don't have a more complicated model as the REML is taking care of it. Using the Wafer example in Chapter 8 of Pinheiro & Bates, and also this thread:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005473.html

I thought I just had to show how the coefficients relate to the covariates and intercept. Clearly I have made an error of judgement, and I'm still not sure where I have gone wrong with the model. The Wafer nlme model uses A, B, and C in its model statement and the linked thread uses b0,...,b5. 

Would someone mind pointing out where I have gone wrong this time?

cheers
Michelle

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Gosse, Michelle
Sent: Wednesday, January 11, 2012 4:05 PM
To: 'Douglas Bates'
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]

Hi,

Thanks for the help.  I'm now trying to figure out (1) the function and (2) how to specify it in nlme. 

cheers
Michelle

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Wednesday, January 11, 2012 8:56 AM
To: Gosse, Michelle
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]

On Tue, Jan 10, 2012 at 1:05 PM, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi all,
>
> I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.

So what is the nonlinear model?  You haven't specified it in your call to nlme.

> My working lme4 code is:
> Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
> ? ? ? ?data=Male.Data,
> ? ? ? ?weights = SampleWeight)
>
> Where:
> BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
> IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.
>
> I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.
>
> In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):
>
> Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.
>
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?random = ~ 1 | RespondentID)
>
>
> When I run the next bit,I get an error. Error and traceback() provided after the syntax:
>
> Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ?fixed = ordered(AgeFactor) + IntakeDay ~ 1,
> ? ? ? ? ? ? ? ?random = RespondentID ~ 1,
> ? ? ? ? ? ? ? ?data = Male.Group,
> ? ? ? ? ? ? ? ?start= fixef(male.lme2)
> ? ? ? ? ? ? ? ?)

Your formula is not an nlme specification.  The right hand side of the formula should be a function call using nonlinear model parameters and covariates.  You are using a linear model formula on the right hand side and this will not give the result you are expecting.

> I get the error message:
> Error in eval(expr, envir, enclos) : object 'AgeFactor' not found
>
> The results of traceback() are:
> 8: eval(expr, envir, enclos)
> 7: eval(x[[length(x)]], dat)
> 6: FUN(X[[1L]], ...)
> 5: lapply(form, function(x, dat, N) {
> ? ? ? val <- eval(x[[length(x)]], dat)
> ? ? ? if (length(val) == 1) {
> ? ? ? ? ? return(as.factor(rep(val, N)))
> ? ? ? }
> ? ? ? else {
> ? ? ? ? ? return(as.factor(val)[drop = TRUE])
> ? ? ? }
> ? }, dat = object, N = nrow(object))
> 4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1", 
> deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 3: getGroups(dataMix, eval(parse(text = paste("~1", 
> deparse(groups[[2]]),
> ? ? ? sep = "|"))))
> 2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
> ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
> 1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
> ordered(AgeFactor) +
> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
> ? ? ? start = fixef(male.lme2))
>
> Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.

UNCLASSIFIED

**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

UNCLASSIFIED

**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}



From mhm2002 at med.cornell.edu  Thu Jan 12 03:06:07 2012
From: mhm2002 at med.cornell.edu (Matthew Malter Cohen)
Date: Wed, 11 Jan 2012 21:06:07 -0500
Subject: [R-sig-ME] Mixed model formulation
Message-ID: <CAA=9ftUqedZ-t+_HeijKUcBwYptcBgWkwMsnovOjKbw9m_PRFA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120111/a56e92ec/attachment-0002.pl>

From ramos.grad.student at gmail.com  Thu Jan 12 03:57:56 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 11 Jan 2012 18:57:56 -0800
Subject: [R-sig-ME] how to get predicted values from a lme call with random
 intercepts and AR(1) for the residuals ?
Message-ID: <CAHawB9v4EKoPaJWx+uyQRhysgcnOQiaXJSRVM2bpdKk30piSQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120111/d61e8ec7/attachment-0002.pl>

From Michelle.Gosse at foodstandards.gov.au  Thu Jan 12 04:13:43 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Thu, 12 Jan 2012 14:13:43 +1100
Subject: [R-sig-ME] start values for starting parameters,
	factors [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F9@EXCHANGE07.foodstandards.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/d2f43dd7/attachment-0002.pl>

From isa.blasco.costa at gmail.com  Thu Jan 12 06:13:52 2012
From: isa.blasco.costa at gmail.com (Isa Blasco)
Date: Thu, 12 Jan 2012 18:13:52 +1300
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
Message-ID: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/79a03cc8/attachment-0002.pl>

From marta.m.rufino at gmail.com  Thu Jan 12 12:03:29 2012
From: marta.m.rufino at gmail.com (marta rufino)
Date: Thu, 12 Jan 2012 11:03:29 +0000
Subject: [R-sig-ME] SE for predictions in lme
Message-ID: <CAKSASLC+DK9oWkx3Prz71t8=krNfTuJ1jOF-r2FgcY9ri6Ux+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/81293b99/attachment-0002.pl>

From mails00000 at gmail.com  Thu Jan 12 15:07:18 2012
From: mails00000 at gmail.com (mails)
Date: Thu, 12 Jan 2012 14:07:18 +0000
Subject: [R-sig-ME] Interpreting linear models
Message-ID: <48966A32-1DF0-4B37-B560-A18184032DE0@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120112/74754b5d/attachment-0002.pl>

From bbolker at gmail.com  Thu Jan 12 17:42:59 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Jan 2012 16:42:59 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
Message-ID: <loom.20120112T173419-47@post.gmane.org>

Isa Blasco <isa.blasco.costa at ...> writes:

> 
> Hi,
> I am using glmmADMB to fit a negative binomial model to my data. My
> explanatory variable is an ordered factor with 10 levels and I also
> included a random factor (numeric) and Zero inflation.
> This is the code I used: m7 <- glmmadmb (abun~odist + (1|sl), data=apa,
> zeroInflation=TRUE, family="nbinom")
> 
> When I run it I got this error:
> Error in UseMethod("droplevels") :
>   no applicable method for 'droplevels' applied to an object of class
> "c('double', 'numeric')"
> 
> I do not know what the 'double' means but I checked the glmmADMB manual and
> they use the same kind of variables in their example. Any guess on what it
> is happening? How can I solve it?
> I hope somebody knows!

  It means that it doesn't make sense to use a numeric variable as
a grouping variable for a random factor (which is what you've done):
if sl is a discrete numeric code that identifies groups of observations,
then you should convert it to a factor.  If it's a continuous variable,
then you need to go back and read/think some more about the meanings
of random factors ...

  It also means that I made some changes to glmmADMB recently that
got in the way of an informative error message (you should have
received an error message that told you this).  I will try to 
catch that error in a more informative way.

  Ben Bolker



From ctr4g2 at mail.missouri.edu  Thu Jan 12 18:27:22 2012
From: ctr4g2 at mail.missouri.edu (Christopher Rota)
Date: Thu, 12 Jan 2012 11:27:22 -0600
Subject: [R-sig-ME] glmmADMB v 0.7.1
Message-ID: <4F0F17FA.2090403@mail.missouri.edu>

Dear R Users,

I am running into some trouble when using glmmADMB version 0.7.1 and am 
hoping someone in the R community may have some insight.

I am trying to fit a rather large negative binomial mixed-effects 
model.  I have 3980 observations (counts of foraging attempts).  My 
'global' model has 17 fixed effects and 2 random effects.  Fixed effects 
consist of both continuous and categorical variables.  Each categorical 
variable has at least 22 observations, most have considerably more.  One 
random effect is an 'observer' effect consisting of 11 different 
observers.  Each observer made at least 29 observations, but most made 
considerably more.  The other random effect in an 'individual bird' 
effect consisting of 78 individual birds.  There are at least 20 
observations made on each bird.

Here is my call to glmmadmb:
fit <- glmmadmb(formula=count~BrnLight + BrnMod + BrnMPB + BrnSev + 
GrnHit + GryHit + RedHit + Autumn + Spring + Winter + Yr01 + Yr12 + Yr23 
+ Yr34 + Yr45 + Est.DBH.in + Start.Time + (1|Color.Combo) + 
(1|Observers), data=beh.data, family='nbinom')

The variables 'BrnLight' through 'RedHit' represent categorical 
variables describing tree condition.  They are coded as dummy variables, 
and one tree condition category (Green) is omitted from model 
specification and interpreted as the intercept.  The season (Autumn, 
Spring, Winter) and year (Yr01, etc.) variables are coded in an 
identical manner (note that I also coded categorical variables as 
factors, and encountered the same problem described below).  DBH and 
Start.Time are continuous variables.

This global model runs for about 10 minutes, then fails with the 
following message:
Memory allocation error -- Perhaps you are trying to allocate too much 
memory in your program

When I monitor my computer performance with Windows Task Manager while 
the model is running, I can watch Physical Memory Usage slowly tick up. 
All of that increased memory use is attributed to glmmadmb.exe.  I will 
watch memory use for this program tick up to about 1.7GB, and that is 
when the model fails.  I am using a computer with a Windows Vista 32-bit 
operating system with 4GB RAM.  Is the problem simply that I do not have 
enough memory on my computer to run this model?  If indeed the problem 
is a shortage of memory, is there any way to make glmmadmb.exe use 
memory differently, or do I need to use a more powerful computer?

Thank you for any insight.

Chris Rota

-- 
Christopher Rota
Ph.D. Student

University of Missouri
Fisheries and Wildlife Science
302 Anheuser-Busch Natural Resources Building
Columbia, MO 65211

Office:  303O Anheuser-Busch Natural Resources Buildling
Email:  ctr4g2 at mail.missouri.edu
Phone:  573-239-6975
Website:  http://www.biosci.missouri.edu/avianecology/rota/index.html
Calendar:  http://www.google.com/calendar/embed?src=christopher.rota%40gmail.com&ctz=America/Chicago



From bbolker at gmail.com  Thu Jan 12 19:24:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Jan 2012 13:24:44 -0500
Subject: [R-sig-ME] Mixed model with zero truncated Poisson distributed
 data
In-Reply-To: <4F0F1DE7.9000603@qmul.ac.uk>
References: <4F0DB1F2.70406@qmul.ac.uk>
	<loom.20120111T194340-544@post.gmane.org>
	<4F0F1DE7.9000603@qmul.ac.uk>
Message-ID: <4F0F256C.1090101@gmail.com>

  [I'm taking the liberty of cc'ing this to the r-sig-mixed-models
mailing list, where it can be archived]

On 12-01-12 12:52 PM, Helen Ward wrote:
> Dear Ben,
> 
> Thank you for your speedy response. I've been having a go with MCMCglmm
> today, but I suspect I have over simplified the model (I'm new to
> Bayesian statistics), as I now get three suspiciously significant
> results...
> 
> The model I've tried (included below with its summary) runs, but my
> reading of the help file and the vignette make me suspect that I need to
> give some sort of prior of something to make it sensible. Am I on the
> right track?
> 
> I have also had a quick go with glmmADMB, trying the following models,
> 
>>  model1<-glmmadmb(RSperYr~Age+I(Age^2),data,family="truncpoiss",~1|DadID)
> 
> Error in switch(link, log = log, logit = qlogis, probit = qnorm, inverse
> = function(x) { :
> 
> EXPR must be a length 1 vector

   Here the problem is that you are specifying the random effect without
giving its name (i.e. random=~1|DadID), so R is trying to interpret it
as your desired link function (which is the fourth argument to the
glmmadmb() function: see ?glmmadmb).

> 
>>  model1<-glmmadmb(RSperYr~Age+I(Age^2)+(1|DadID),data,family="truncpoiss")
>>
> 
> Error in UseMethod("droplevels") :
> 
> no applicable method for 'droplevels' applied to an object of class
> "c('integer', 'numeric')",
> 
> but as you can see from the error mesddages I am obviously doing
> something a bit wrong here as well.

  As mentioned in another message on this list this morning, the problem
here is that you need to explicitly convert "DadID" to a factor from a
numeric value [e.g. data$DadID <- factor(data$DadID)] -- the current
error message is not very informative.

> I'll keep trying!, but are there any more obvious pointers you can give
> me please?
> 
> All the best,
> Helen
> 
> 
> This is the model I've tried using MCMCglmm.
>>
> model2<-MCMCglmm(RSperYr~Age+I(Age^2),random=~DadID,family="ztpoisson",data=data)
> 
>>  summary(model2)
> 
> Iterations = 3001:12991
> Thinning interval= 10
> Sample size= 1000
> 
> DIC: 808.5343
> 
> G-structure:~DadID
> 
> post.meanl-95% CI u-95% CI eff.samp
> 
> DadID0.07409 0.00057460.182239.75
> 
> R-structure:~units
> 
> post.mean l-95% CI u-95% CI eff.samp
> 
> units0.06205 0.0014050.176322.55
> 
> Location effects: RSperYr ~ Age + I(Age^2)
> 
> post.meanl-95% CIu-95% CI eff.samp pMCMC
> 
> (Intercept) -0.694625 -1.321090 -0.16384737.17 0.004 **
> 
> Age0.1978390.0667140.33041768.64 0.002 **
> 
> I(Age^2)-0.008292 -0.014887 -0.00158971.46 0.010 **
> 
> 

  At a *quick* glance this looks reasonable.  Try plot(model2$Sol) and
plot(model2$VCV) to see if the trace and density plots look reasonable
(compare them with the results from example("MCMCglmm"). You should take
a quick look at the Overview and CourseNotes vignettes (e.g.
vignette("Overview",package="MCMCglmm")) (the latter in particular is a
bit overwhelming but well worth digging into if you're going to use
these methods)

> 
> 
> 
> On 11/01/2012 18:46, Ben Bolker wrote:
>> Helen Ward<h.l.ward at ...>  writes:
>>
>>> I would like to describe the relationship between age and male
>>> reproductive success in a population of greater horseshoe bats.
>>>
>>> My data consists of three columns: MaleID, Age, NumberofPups (at that
>>> age). Many of the males appear multiple times in the data set, so I
>>> believe I need to derive a mixed model with MaleID as a random variable.
>>>
>>> The data is Poisson distributed, but zero-truncated. So far I have only
>>> succeeded in making a mixed model with a poisson distribution (using
>>> glmmPQL in the MASS package), and a zero truncated poisson model (using
>>> vglm in the VGAM package), but not a mixed model capable of handling
>>> zero truncated Poisson data.
>>>
>>> It has been suggested that I could just minus 1 from each value in the
>>> NumberofPups column to make a more usual Poisson distribution, so I can
>>> ignore the zero truncated bit. I have tried this and it changes the
>>> results of the model, but is this an acceptable transformation?
>>>
>>> If not, can anyone advise me on a mixed model that can handle zero
>>> truncated Poisson data please?
>>>
>>
>>    Thanks for letting us know about cross-posting.
>>
>>    You should be able to do this in either the MCMCglmm package or
>> (recent versions of) the glmmADMB package.  In MCMCglmm, use
>> family="ztpoisson"; in glmmADMB, use family="truncpoiss" ...
>>
>>    Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From giulia.dottisani at gmail.com  Thu Jan 12 19:36:39 2012
From: giulia.dottisani at gmail.com (Giulia Dotti Sani)
Date: Thu, 12 Jan 2012 19:36:39 +0100
Subject: [R-sig-ME] In II[, ii] + REmat$codes[[i]] :
Message-ID: <CAKz8Hv=jZvhNxijKV-X7eWkViTCfVghe0HdoPGEcRCzzpBoyPw@mail.gmail.com>

Hello,

I'm running the following poisson and I keep getting the same error.
M01 <- glmmadmb(chi_hh ~ age_m + educ +(1 |country_y), data=data,
family="poisson")

In II[, ii] + REmat$codes[[i]] :
  longer object length is not a multiple of shorter object length

I think it has to do with the grouping variable but I don't see what's
the problem.
Thank you for any suggestions,

Giulia



From bates at stat.wisc.edu  Thu Jan 12 20:38:23 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 12 Jan 2012 13:38:23 -0600
Subject: [R-sig-ME] nlme model not working but lme models are fine
	[SEC=UNCLASSIFIED]
In-Reply-To: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F5@EXCHANGE07.foodstandards.gov.au>
References: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F5@EXCHANGE07.foodstandards.gov.au>
Message-ID: <CAO7JsnTKGSBqOZ6J-NF0dEcMH4d866XnhXTuNR6hqCp0bfhi0g@mail.gmail.com>

On Wed, Jan 11, 2012 at 4:35 PM, Gosse, Michelle
<Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi all,
>
> I've replied to my message so hopefully the archive will stay tracking this as a single question.
>
> Having examined the log likelihood formulae I was given for the SAS code, read Chapter 7 of Pinheiro & Bates, and searching for help, ?I have got as far as (note, I am not using a grouped data frame as I get an error in nlme.fomula message saying that the "starting values for the fixed component are the wrong length" when I do this):
>
> male.lme3 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ?data=Male.Data,
> ? ? ? ?random= ~1|RespondentID)
>
> and then I am trying to run the following, and yes I wish the covariates to be additive the model I am basing this on (from SAS) has additive covariates:
> Male.nlme <- nlme(BoxCoxXY ~ A + B*factor(AgeFactor) + C*factor(IntakeDay),
> ? ? ? ?data=Male.Data,
> ? ? ? ?fixed= A + B + C ~ 1,
> ? ? ? ?random=A ~1,
> ? ? ? ?group=RespondentID,
> ? ? ? ?start=fixef(male.lme3)
> ? ? ? ?)
>
> I get the error " Error in eval(expr, envir, enclos) : object 'A' not found"
>
> I don't have a more complicated model as the REML is taking care of it. Using the Wafer example in Chapter 8 of Pinheiro & Bates, and also this thread:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005473.html
>
> I thought I just had to show how the coefficients relate to the covariates and intercept. Clearly I have made an error of judgement, and I'm still not sure where I have gone wrong with the model. The Wafer nlme model uses A, B, and C in its model statement and the linked thread uses b0,...,b5.
>
> Would someone mind pointing out where I have gone wrong this time?

The names of your starting values must correspond to the names used in
the formula (A, B and C).  I don't think that formula is what you want
because ordered(AgeFactor) will be converted to integer values 1, 2,
..., # of levels of AgeFactor and the same with factor(IntakeDay).
It is highly unlikely that this model does what you expect it to do.

In the end you would just end up with an awkward nonlinear model
formula representing a linear model.

You said that you were asked to fit a nonlinear mixed-effects model.
I recommend that you go back to the person who suggested this and get
clarification on what model they intended.  Converting a linear
mixed-effects model to a nonlinear model formula, in which all the
parameters occur linearly, and fitting that is not a nonlinear
mixed-effects model.  It is the same linear mixed-effects model fit
inefficiently.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Gosse, Michelle
> Sent: Wednesday, January 11, 2012 4:05 PM
> To: 'Douglas Bates'
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]
>
> Hi,
>
> Thanks for the help. ?I'm now trying to figure out (1) the function and (2) how to specify it in nlme.
>
> cheers
> Michelle
>
> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
> Sent: Wednesday, January 11, 2012 8:56 AM
> To: Gosse, Michelle
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] nlme model not working but lme models are fine [SEC=UNCLASSIFIED]
>
> On Tue, Jan 10, 2012 at 1:05 PM, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
>> Hi all,
>>
>> I have a nicely working lme model from the lme4 package, however I have been requested to produce a nonlinear model and I am having problems with the model specification.
>
> So what is the nonlinear model? ?You haven't specified it in your call to nlme.
>
>> My working lme4 code is:
>> Male.lme1 <- lmer(BoxCoxXY ~ AgeFactor + IntakeDay + (1|RespondentID),
>> ? ? ? ?data=Male.Data,
>> ? ? ? ?weights = SampleWeight)
>>
>> Where:
>> BoxCoxXY are transformed nutrient intake values AgeFactor is the age band for the subject, this has been converted to a factor. There are 4 agebands in the current dataset, and these are in ascending order. The values for AgeFactor are 1,2,3,4.
>> IntakeDay is either "IntakeDay1" or IntakeDay2", depending on whether it is the first 24-hour recall period or the second, for food intake (used to calculate the raw nutrient intake) RespondentID is the subject number, this has been converted to a factor I'm doing the analysis separately by gender, so all my data relate to males, hence the data frame names.
>>
>> I am now trying to fit this data using nlme in the nlme package. I've been taking hints from the Machines and Wafers data, as these seem closest to my data frame. I just can't get the nlme model to work.
>>
>> In my R session, at this point I've detached lme4 and attached nlme. These two bits of code work fine, and the lme coefficient estimates from the nlme package are exactly the same as those from the lme in the lme4 package, so I believe I have the linear model specified correctly in nlme, the issue seems to be getting the nlme model to work. The working code in nlme is (I am using lme to generate the fixed effect coefficients to put into the nlme model as the starting parameters):
>>
>> Male.Group <- groupedData(BoxCoxXY ~ RespondentID|AgeFactor, data=Male.Data) # This seems to be the most sensible grouping as the subjects are grouped within age, with repeated intake measures grouped within subject.
>>
>> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
>> ? ? ? ? ? ? ? ?data = Male.Group,
>> ? ? ? ? ? ? ? ?random = ~ 1 | RespondentID)
>>
>>
>> When I run the next bit,I get an error. Error and traceback() provided after the syntax:
>>
>> Male.nlme <- nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
>> ? ? ? ? ? ? ? ?fixed = ordered(AgeFactor) + IntakeDay ~ 1,
>> ? ? ? ? ? ? ? ?random = RespondentID ~ 1,
>> ? ? ? ? ? ? ? ?data = Male.Group,
>> ? ? ? ? ? ? ? ?start= fixef(male.lme2)
>> ? ? ? ? ? ? ? ?)
>
> Your formula is not an nlme specification. ?The right hand side of the formula should be a function call using nonlinear model parameters and covariates. ?You are using a linear model formula on the right hand side and this will not give the result you are expecting.
>
>> I get the error message:
>> Error in eval(expr, envir, enclos) : object 'AgeFactor' not found
>>
>> The results of traceback() are:
>> 8: eval(expr, envir, enclos)
>> 7: eval(x[[length(x)]], dat)
>> 6: FUN(X[[1L]], ...)
>> 5: lapply(form, function(x, dat, N) {
>> ? ? ? val <- eval(x[[length(x)]], dat)
>> ? ? ? if (length(val) == 1) {
>> ? ? ? ? ? return(as.factor(rep(val, N)))
>> ? ? ? }
>> ? ? ? else {
>> ? ? ? ? ? return(as.factor(val)[drop = TRUE])
>> ? ? ? }
>> ? }, dat = object, N = nrow(object))
>> 4: getGroups.data.frame(dataMix, eval(parse(text = paste("~1",
>> deparse(groups[[2]]),
>> ? ? ? sep = "|"))))
>> 3: getGroups(dataMix, eval(parse(text = paste("~1",
>> deparse(groups[[2]]),
>> ? ? ? sep = "|"))))
>> 2: nlme.formula(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
>> ordered(AgeFactor) +
>> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
>> ? ? ? start = fixef(male.lme2))
>> 1: nlme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay, fixed =
>> ordered(AgeFactor) +
>> ? ? ? IntakeDay ~ 1, random = RespondentID ~ 1, data = Male.Group,
>> ? ? ? start = fixef(male.lme2))
>>
>> Could someone advise me where I have gone wrong? I don't understand how nlme cannot find AgeFactor where the other syntax didn't have an issue.
>
> UNCLASSIFIED
>
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:9}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> UNCLASSIFIED
>
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:9}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Thu Jan 12 20:50:45 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 12 Jan 2012 13:50:45 -0600
Subject: [R-sig-ME] start values for starting parameters,
	factors [SEC=UNCLASSIFIED]
In-Reply-To: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F9@EXCHANGE07.foodstandards.gov.au>
References: <12E932690323AB4EBEEB21BAA28D90DE369E10A4F9@EXCHANGE07.foodstandards.gov.au>
Message-ID: <CAO7JsnRMp6HLJ0U8uM6-RfNL23jy0w-4Eieqon8sJf9UR06iSg@mail.gmail.com>

On Wed, Jan 11, 2012 at 9:13 PM, Gosse, Michelle
<Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi again,
>
> More reading later, and I have the following model with the log likelihood function specified:
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random= ~1|RespondentID)
>
> male.nlme <- nlme(IntakeAmt ~ log(1/sqrt(2*pi*(Scale^2))) +
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?(-(A*BoxCoxXY-(B*AgeFactor + C*IntakeDay))^2)/(2*Scale)+(Lambda.Value-1)*log(IntakeAmt),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?fixed = A - B + C ~ 1,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = A ~ 1|RespondentID,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?start=fixef(male.lme2)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)
>
> The nlme syntax gives me the error:
> "Error in nlme.formula(IntakeAmt ~ log(1/sqrt(2 * pi * (Scale^2))) + (-(A * :
> ? ? ? ? ? ?starting values for the fixed component are not the correct length"
>
> Reading on the internet made me understand that this is because there needs to be 3 fixed component start parameters, as confirmed by the model below not giving that error:
> male.nlme <- nlme(IntakeAmt ~ log(1/sqrt(2*pi*(Scale^2))) +
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?(-(A*BoxCoxXY-(B*AgeFactor + C*IntakeDay))^2)/(2*Scale)+(Lambda.Value-1)*log(IntakeAmt),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?fixed = A - B + C ~ 1,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = A ~ 1|RespondentID,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?start=c(A=1,B=1,C=1)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)
>
> The test model immediately above gives the error:
> "Error in chol.default((value + t(value))/2) :
> ? ? ? ? ? ?the leading minor of order 1 is not positive definite"
>
> Which I think is occurring because of the warning messages:
> 1: In Ops.ordered(B, AgeFactor) :
> ? ? ? ? ? ?'*' is not meaningful for ordered factors
> 2: In Ops.factor(C, IntakeDay) : * not meaningful for factors
>
> Given that I have 3 AgeFactor and 1 IntakeDay parameters, as there are 4 and 2 factor levels respectively (lowest level omitted for each), how do I specify the nlme model and fixed effects without changing to dummy variable coding?
>
> Sorry for all my questions on this, at least this time I get the error on step 14 of the traceback() so I feel I am coming to grips with nlme slowly.

Well, as the messages say, it doesn't make sense to multiply AgeFactor
by B and IntakeDay by C.

You really should start from the beginning and decide what the model
you are trying to fit is.  It must be an expression in which every
name is a parameter or a covariate name or the name of a function.
The names of the parameters are determined by the names of the start
argument.  The names of the covariates are those in Male.Group.  Do
these include IntakeAmt, Scale and Lambda?

Also, it is unusual and generally misguided to include IntakeAmt on
both the left and the right hand side of the formula.

We don't know why you are using the expressions that you are and it
probably won't be productive to continue to guess what form the model
expression should be then report error messages to us.



From davef at otter-rsch.com  Thu Jan 12 20:54:26 2012
From: davef at otter-rsch.com (dave fournier)
Date: Thu, 12 Jan 2012 11:54:26 -0800
Subject: [R-sig-ME] glmmADMB v 0.7.1
In-Reply-To: <4F0F17FA.2090403@mail.missouri.edu>
References: <4F0F17FA.2090403@mail.missouri.edu>
Message-ID: <4F0F3A72.5080808@otter-rsch.com>

When you run glmmadmb in R, R writes ADMB's files and runs the glmmadmb 
program
via system(). There is an option to keep these files and then to run 
glmmadmb from outside
R. You can then read the results back into R. Doing it this way (i.e. 
exiting R before
running glmmadmb) will give you a bit more memory. It may be enough.
That is the simplest first thing to try I think.



From Stefan.Schreiber at ales.ualberta.ca  Thu Jan 12 21:02:50 2012
From: Stefan.Schreiber at ales.ualberta.ca (Schreiber, Stefan)
Date: Thu, 12 Jan 2012 13:02:50 -0700
Subject: [R-sig-ME] TukeyHSD on aov(fit.lmer)
In-Reply-To: <4F0DF811.20303@gmail.com>
References: <70F02259E17B6242B15D81E58EB7EB1107B35E6D@afhe-ex.afhe.ualberta.ca>
	<4F0DF811.20303@gmail.com>
Message-ID: <70F02259E17B6242B15D81E58EB7EB11087B5A1E@afhe-ex.afhe.ualberta.ca>

Hi all,

I have the following mixed model for my data (Thanks Ben!):

lmer.fit<- response ~ group*climate + (1|block) + (1|genotype) + (1|id)

Here's the summary:

Linear mixed model fit by REML 
Formula: response ~ group*climate + (1|block) + (1|genotype) + (1|id) 
   Data: plc 
  AIC  BIC logLik deviance REMLdev
 1275 1325   -622     1296    1243
Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept)  10.25    3.20   
 clone    (Intercept)   2.75    1.66   
 rep      (Intercept)   5.34    2.31   
 Residual             148.21   12.17   
Number of obs: 168, groups: id, 56; genotype, 7; block, 5

Then I ran TukeyHSD(aov(lmer.fit)) and it gives me no error and an
output that "looks" ok. However, I am uncertain whether this is correct
to do, or not.

Here is an made up example:
d.fr<-data.frame(id=rep(1:16,3),treat1=rep(as.factor(LETTERS[1:3]),each=
16),treat2=rep(as.factor(letters[4:7]),each=4),response=rnorm(48))
fit1<-lmer(response~treat1*treat2+(1|id),data=d.fr)
TukeyHSD(aov(fit1))

I hope to get some advice on whether this is a valid thing to do.

Thanks!
Stefan



From Michelle.Gosse at foodstandards.gov.au  Thu Jan 12 21:09:19 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Fri, 13 Jan 2012 07:09:19 +1100
Subject: [R-sig-ME] start values for starting parameters,
 factors [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A4FB@EXCHANGE07.foodstandards.gov.au>

Hi Doug,

Thanks for replying and thanks also to Steve for his comments.

I agree with your comments below, and am following this point up with the people who made the request to use this method. In case anyone is interested, the method is outlined in this paper, section  3.2: http://www.stat.tamu.edu/~carroll/ftp/2011.papers.directory/NCIMethod_aspublished.pdf

I appreciate the time that people have put into this for me, it has helped me out a lot on the conceptual perspective as well as the nlme specification perspective.

Cheers
Michelle



-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Friday, January 13, 2012 8:51 AM
To: Gosse, Michelle
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] start values for starting parameters, factors [SEC=UNCLASSIFIED]

On Wed, Jan 11, 2012 at 9:13 PM, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
> Hi again,
>
> More reading later, and I have the following model with the log likelihood function specified:
> male.lme2 <- lme(BoxCoxXY ~ ordered(AgeFactor) + IntakeDay,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random= ~1|RespondentID)
>
> male.nlme <- nlme(IntakeAmt ~ log(1/sqrt(2*pi*(Scale^2))) +
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
> (-(A*BoxCoxXY-(B*AgeFactor +
> C*IntakeDay))^2)/(2*Scale)+(Lambda.Value-1)*log(IntakeAmt),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?fixed = A - B + C ~ 1,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = A ~ 1|RespondentID,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?start=fixef(male.lme2)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)
>
> The nlme syntax gives me the error:
> "Error in nlme.formula(IntakeAmt ~ log(1/sqrt(2 * pi * (Scale^2))) + (-(A * :
> ? ? ? ? ? ?starting values for the fixed component are not the correct length"
>
> Reading on the internet made me understand that this is because there needs to be 3 fixed component start parameters, as confirmed by the model below not giving that error:
> male.nlme <- nlme(IntakeAmt ~ log(1/sqrt(2*pi*(Scale^2))) +
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
> (-(A*BoxCoxXY-(B*AgeFactor +
> C*IntakeDay))^2)/(2*Scale)+(Lambda.Value-1)*log(IntakeAmt),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data=Male.Group,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?fixed = A - B + C ~ 1,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = A ~ 1|RespondentID,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?start=c(A=1,B=1,C=1)
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)
>
> The test model immediately above gives the error:
> "Error in chol.default((value + t(value))/2) :
> ? ? ? ? ? ?the leading minor of order 1 is not positive definite"
>
> Which I think is occurring because of the warning messages:
> 1: In Ops.ordered(B, AgeFactor) :
> ? ? ? ? ? ?'*' is not meaningful for ordered factors
> 2: In Ops.factor(C, IntakeDay) : * not meaningful for factors
>
> Given that I have 3 AgeFactor and 1 IntakeDay parameters, as there are 4 and 2 factor levels respectively (lowest level omitted for each), how do I specify the nlme model and fixed effects without changing to dummy variable coding?
>
> Sorry for all my questions on this, at least this time I get the error on step 14 of the traceback() so I feel I am coming to grips with nlme slowly.

Well, as the messages say, it doesn't make sense to multiply AgeFactor by B and IntakeDay by C.

You really should start from the beginning and decide what the model you are trying to fit is.  It must be an expression in which every name is a parameter or a covariate name or the name of a function.
The names of the parameters are determined by the names of the start argument.  The names of the covariates are those in Male.Group.  Do these include IntakeAmt, Scale and Lambda?

Also, it is unusual and generally misguided to include IntakeAmt on both the left and the right hand side of the formula.

We don't know why you are using the expressions that you are and it probably won't be productive to continue to guess what form the model expression should be then report error messages to us.

UNCLASSIFIED

**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}



From john.maindonald at anu.edu.au  Thu Jan 12 23:15:47 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 13 Jan 2012 09:15:47 +1100
Subject: [R-sig-ME] SE for predictions in lme
In-Reply-To: <CAKSASLC+DK9oWkx3Prz71t8=krNfTuJ1jOF-r2FgcY9ri6Ux+g@mail.gmail.com>
References: <CAKSASLC+DK9oWkx3Prz71t8=krNfTuJ1jOF-r2FgcY9ri6Ux+g@mail.gmail.com>
Message-ID: <61516561-3577-443C-9789-EF288C3CDF69@anu.edu.au>

On 12/01/2012, at 10:03 PM, marta rufino wrote:

> Hi,
> 
> This topic has been discussed in several posts in this list before, but I
> could not completely understand if there was a clear answer. Also, I
> searched the books (Pinheiro, Faraway and Zuur) I could not reach a
> conclusion. I guess I am missing some point here :) so I am sorry for
> recover this topic again.
> I will start by providing an example code and then put my questions, as
> clear as possible.
> 
> Following the code provided in previous posts (see for example):
> http://markmail.org/message/lhtols3t5wrleewc
> using another dataset, for example:
> 
>            # Example to ask the list
>            data(iris)
>            kk=data.frame(stack(iris[,1:3]),sp=rep(iris$Species),
> subject=rep(1:dim(iris)[1],3))
>            summary(kk)
>            require(nlme)
>            kk2=lme(values~ind*sp, kk, weights = varIdent(form= ~ 1|ind),
> random=~1|subject)
>            kk2
>            anova(kk2) #all factors are significant.
> 
>            # Calculate model predictions    and plot it ==== this is from
> Ben's code
>                newdat <- expand.grid(ind=levels(kk$ind), sp=levels(kk$sp))
>                newdat$pred <- predict(kk2, newdat, level = 0)
> 
>                Designmat <- model.matrix(eval(eval(kk2$call$fixed)[-2]),
> newdat[-3])
>                predvar <- diag(Designmat %*% kk2$varFix %*% t(Designmat))
>                newdat$SE <- sqrt(predvar)

Prediction for a new observation on one of the subjects in the sample data

>                newdat$SE2 <- sqrt(predvar+kk2$sigma^2)

Prediction for a new observation on a new subject

Exercise: What is the SE for the average of 3 observations on a new subject?

(It is the way the SE changes depending on what exactly one is predicting
that raises questions about what exactly AIC and related statistics are 
designed to optimise, when such statistics are used to compare models.)

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

>                #install.packages("ggplot2")
>                library(ggplot2)
>                pd <- position_dodge(width=0.4)
>                ggplot(newdat,aes(x=ind, y=pred, colour=sp))+
>                geom_point(aes(x=kk$ind,y=kk$values, colour=kk$sp),
> size=.3, shape=2, position=pd)+
>                geom_point(position=pd)+
>                geom_linerange(aes(ymin=pred-2*SE2,
> ymax=pred+2*SE2),col="red", position=pd)+
>                geom_errorbar(aes(ymin=pred-2*SE, ymax=pred+2*SE),
> col="black", width=.1, position=pd)
> 
> So, we can see the actual points, the SE and SE2 modelled and respective
> means, I think.
> My questions are:
> What is exactly the SE and SE2 (how do we call it in an article legend, for
> example) and how can these be interpreted?
> Can we consider that when the 'lines' do not overlap the species (or
> varieties) are different?
> The SE2 are larger than the actual data in setosa/Petal.Length and overlap
> in the remaining variaties--- how can these show significant differences
> than?
> 
> I think I am getting confused or I am missing something important, because
> the results do not appear congruent in my head.
> 
> Any help will be much appreciated,
> 
> All the best,
> Marta
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From chris at trickysolutions.com.au  Thu Jan 12 23:42:44 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 13 Jan 2012 09:42:44 +1100
Subject: [R-sig-ME] glmmADMB v 0.7.1
In-Reply-To: <4F0F17FA.2090403@mail.missouri.edu>
References: <4F0F17FA.2090403@mail.missouri.edu>
Message-ID: <0b578b720fcc8d94403cca1de8888e6c@mail.gmail.com>

Hi Chris,

If it's getting upto 2GB that's about the limit on your machine unless U
manually change it (see ?memory-limit for more info)

Have u tried removing all unnecessary objects from the workspace and then
garbage collecting: gc()?

The following code may help:

# Set Memory parameters
# Help on memory limits
?Memory-limits
# Remove unneccessary objects (in this call everything)
rm(list=ls())
ls()
# Garbage collection, this can increase available memory after a call to
rm()
gc()
# Set Memory Limit to Max on a 4GB machine
memory.limit(size=4095)
# report memory limit
memory.limit(size=NA)
# maximum amount of memory obtained from the OS is reported
memory.limit(size=TRUE)
# amount currently in use
memory.limit(size=FALSE)

Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Christopher
Rota
Sent: Friday, 13 January 2012 4:27 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] glmmADMB v 0.7.1

Dear R Users,

I am running into some trouble when using glmmADMB version 0.7.1 and am
hoping someone in the R community may have some insight.

I am trying to fit a rather large negative binomial mixed-effects
model.  I have 3980 observations (counts of foraging attempts).  My
'global' model has 17 fixed effects and 2 random effects.  Fixed effects
consist of both continuous and categorical variables.  Each categorical
variable has at least 22 observations, most have considerably more.  One
random effect is an 'observer' effect consisting of 11 different
observers.  Each observer made at least 29 observations, but most made
considerably more.  The other random effect in an 'individual bird'
effect consisting of 78 individual birds.  There are at least 20
observations made on each bird.

Here is my call to glmmadmb:
fit <- glmmadmb(formula=count~BrnLight + BrnMod + BrnMPB + BrnSev +
GrnHit + GryHit + RedHit + Autumn + Spring + Winter + Yr01 + Yr12 + Yr23
+ Yr34 + Yr45 + Est.DBH.in + Start.Time + (1|Color.Combo) +
(1|Observers), data=beh.data, family='nbinom')

The variables 'BrnLight' through 'RedHit' represent categorical
variables describing tree condition.  They are coded as dummy variables,
and one tree condition category (Green) is omitted from model
specification and interpreted as the intercept.  The season (Autumn,
Spring, Winter) and year (Yr01, etc.) variables are coded in an
identical manner (note that I also coded categorical variables as
factors, and encountered the same problem described below).  DBH and
Start.Time are continuous variables.

This global model runs for about 10 minutes, then fails with the
following message:
Memory allocation error -- Perhaps you are trying to allocate too much
memory in your program

When I monitor my computer performance with Windows Task Manager while
the model is running, I can watch Physical Memory Usage slowly tick up.
All of that increased memory use is attributed to glmmadmb.exe.  I will
watch memory use for this program tick up to about 1.7GB, and that is
when the model fails.  I am using a computer with a Windows Vista 32-bit
operating system with 4GB RAM.  Is the problem simply that I do not have
enough memory on my computer to run this model?  If indeed the problem
is a shortage of memory, is there any way to make glmmadmb.exe use
memory differently, or do I need to use a more powerful computer?

Thank you for any insight.

Chris Rota

--
Christopher Rota
Ph.D. Student

University of Missouri
Fisheries and Wildlife Science
302 Anheuser-Busch Natural Resources Building
Columbia, MO 65211

Office:  303O Anheuser-Busch Natural Resources Buildling
Email:  ctr4g2 at mail.missouri.edu
Phone:  573-239-6975
Website:  http://www.biosci.missouri.edu/avianecology/rota/index.html
Calendar:
http://www.google.com/calendar/embed?src=christopher.rota%40gmail.com&ctz=
America/Chicago

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Jan 13 16:52:02 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Jan 2012 09:52:02 -0600
Subject: [R-sig-ME] Fwd: lme4 and sample size
In-Reply-To: <CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
References: <6C86BD70D72CB449A189A18EED3037CA057EE65B@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
Message-ID: <CAO7JsnQ4rRgjQAU_aFzMmoUjjGAifo+qrYb+gg0s5LVY6Es9og@mail.gmail.com>

After saying I would cc: the list on this reply, I didn't.


---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Fri, Jan 13, 2012 at 9:51 AM
Subject: Re: lme4 and sample size
To: "Bouwmeester, W." <W.Bouwmeester at umcutrecht.nl>


I have taken the liberty of copying the reply to the
R-SIG-Mixed-Models at R-Project.org mailing list so that it will be
available in a searchable archive.

On Fri, Jan 13, 2012 at 9:37 AM, Bouwmeester, W.
<W.Bouwmeester at umcutrecht.nl> wrote:
> Dear professor Bates,
>
> I will incvestigate the required sample size to develop a prediction model in hierarchical data, using a simulation study. One of the model evaluation criteria will be whether the model converged. R will give warning messages if no or singular convergence appeared.
> Is it possible to evaluate model convergence from the cvg column in attr(mix.model,"dims")? Has this "cvg" anything to do with convergence?
>
> I saw this "cvg" output from attr(mix.model, "dims") in your publication on October 4, 2011, Linear mixed model implementation in lme4, page 6 and 20.

I would strongly recommend using lmer instead of lme to fit
heirarchical linear models in a simulation study. ?The lmer function
in the lme4 package is much faster and more reliable than the lme
function from the nlme package.

The current version of lme4 on CRAN can sometimes encounter a warning
about "false convergence". ?The version named lme4Eigen on the R-forge
site is, in our preliminary tests, more reliable and usually faster
than the released version. ?You do need to be able to build an R
package from source to be able to use the lme4Eigen at present.



From bates at stat.wisc.edu  Fri Jan 13 17:05:52 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Jan 2012 10:05:52 -0600
Subject: [R-sig-ME] lme4 and sample size
In-Reply-To: <6C86BD70D72CB449A189A18EED3037CA057EE66C@EXMB1501.ds.umcutrecht.nl>
References: <6C86BD70D72CB449A189A18EED3037CA057EE65B@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
	<6C86BD70D72CB449A189A18EED3037CA057EE66C@EXMB1501.ds.umcutrecht.nl>
Message-ID: <CAO7JsnSBCo4exTRgzCaB54udtM0RBQh668zc_NOqXpaRhH93fg@mail.gmail.com>

On Fri, Jan 13, 2012 at 9:58 AM, Bouwmeester, W.
<W.Bouwmeester at umcutrecht.nl> wrote:
> Dear professor Bates,
>
> I'am using the lmer function indeed. Can I use 'cvg' from the output attr(model, "dims") to evaluate convergence? (here, the object "model" is fitted with the lmer function)

Yes, but do bear in mind that the cvg indicator is from the optimizer,
which is nlminb in the case of the released lme4.  We have encountered
difficulties with nlminb failing to converge or giving the false
convergence message or getting stuck at boundary values.  We later
switched to the bobyqa optimizer from the minqa package and then to a
local implementation of the Nelder-Mead simplex optimizer.

Failure to converge is a property of the optimizer being used, not the
overall design of lme4.  It happens that good optimizers that are
available to Open Source projects are difficult to come by.

> Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
> Verzonden: vrijdag 13 januari 2012 16:51
> To: Bouwmeester, W.
> Onderwerp: Re: lme4 and sample size
>
> I have taken the liberty of copying the reply to the
> R-SIG-Mixed-Models at R-Project.org mailing list so that it will be
> available in a searchable archive.
>
> On Fri, Jan 13, 2012 at 9:37 AM, Bouwmeester, W.
> <W.Bouwmeester at umcutrecht.nl> wrote:
>> Dear professor Bates,
>>
>> I will incvestigate the required sample size to develop a prediction model in hierarchical data, using a simulation study. One of the model evaluation criteria will be whether the model converged. R will give warning messages if no or singular convergence appeared.
>> Is it possible to evaluate model convergence from the cvg column in attr(mix.model,"dims")? Has this "cvg" anything to do with convergence?
>>
>> I saw this "cvg" output from attr(mix.model, "dims") in your publication on October 4, 2011, Linear mixed model implementation in lme4, page 6 and 20.
>
> I would strongly recommend using lmer instead of lme to fit
> heirarchical linear models in a simulation study. ?The lmer function
> in the lme4 package is much faster and more reliable than the lme
> function from the nlme package.
>
> The current version of lme4 on CRAN can sometimes encounter a warning
> about "false convergence". ?The version named lme4Eigen on the R-forge
> site is, in our preliminary tests, more reliable and usually faster
> than the released version. ?You do need to be able to build an R
> package from source to be able to use the lme4Eigen at present.
> ------------------------------------------------------------------------------
>
> De informatie opgenomen in dit bericht kan vertrouwelijk zijn en is
> uitsluitend bestemd voor de geadresseerde. Indien u dit bericht onterecht
> ontvangt, wordt u verzocht de inhoud niet te gebruiken en de afzender direct
> te informeren door het bericht te retourneren. Het Universitair Medisch
> Centrum Utrecht is een publiekrechtelijke rechtspersoon in de zin van de W.H.W.
> (Wet Hoger Onderwijs en Wetenschappelijk Onderzoek) en staat geregistreerd bij
> de Kamer van Koophandel voor Midden-Nederland onder nr. 30244197.
>
> Denk s.v.p aan het milieu voor u deze e-mail afdrukt.
>
> ------------------------------------------------------------------------------
>
> This message may contain confidential information and ...{{dropped:12}}



From pharriso at uwaterloo.ca  Fri Jan 13 17:46:40 2012
From: pharriso at uwaterloo.ca (Philip Harrison)
Date: Fri, 13 Jan 2012 11:46:40 -0500
Subject: [R-sig-ME] SE for predictions in lme
Message-ID: <20120113114640.14594y0zdj0x1nwo@www.nexusmail.uwaterloo.ca>

Hi Marta,

My understanding of this is that the SE*2 gives 95% confidence  
intervals on predictions. You can add a bonferroni type adjustment by  
varying the *2 (which is really 1.96)

The SE2 gives prediction intervals. Confidence intervals of  
predictions tell you how well you have predicted the mean. Prediction  
intervals tell where you could expect the next to see the next value  
sampled. The key point is that the prediction interval tells you about  
the distribution of values, not the uncertainty in determining the  
population mean.

Therefore as far as I can tell, the CIs are the most useful for making  
inferences about differences in the conditional means/BLUPs

You can also use the function predictSE.lme from the package  
AICcmodavg to produce prediction and SEs from an lme object and then  
calculate CIs accordingly. I like this method as it gives a reference  
to the method:

"predictSE.lme? computes predicted values based on fixed effects and  
associated standard errors.
Standard errors are approximated using the delta method (Oehlert 1992)"

These two methods result in identical predictions and almost identical  
SEs for my dataset

Some confusion arise for me because the predict.lme function calls the  
prediction Best linear Unbiased Predictions (BLUPs) which combine  
random and fixed effects, and the predictSE.lme function states that  
these predictions do not incorporate the random effects. Yet they give  
identical predictions for me.

Hope this helps

Phil


Quoting marta rufino <marta.m.rufino at gmail.com>:

> Hi,
>
> This topic has been discussed in several posts in this list before, but I
> could not completely understand if there was a clear answer. Also, I
> searched the books (Pinheiro, Faraway and Zuur) I could not reach a
> conclusion. I guess I am missing some point here :) so I am sorry for
> recover this topic again.
> I will start by providing an example code and then put my questions, as
> clear as possible.
>
> Following the code provided in previous posts (see for example):
> http://markmail.org/message/lhtols3t5wrleewc
> using another dataset, for example:
>
>            # Example to ask the list
>            data(iris)
>            kk=data.frame(stack(iris[,1:3]),sp=rep(iris$Species),
> subject=rep(1:dim(iris)[1],3))
>            summary(kk)
>            require(nlme)
>            kk2=lme(values~ind*sp, kk, weights = varIdent(form= ~ 1|ind),
> random=~1|subject)
>            kk2
>            anova(kk2) #all factors are significant.
>
>            # Calculate model predictions    and plot it ==== this is from
> Ben's code
>                newdat <- expand.grid(ind=levels(kk$ind), sp=levels(kk$sp))
>                newdat$pred <- predict(kk2, newdat, level = 0)
>
>                Designmat <- model.matrix(eval(eval(kk2$call$fixed)[-2]),
> newdat[-3])
>                predvar <- diag(Designmat %*% kk2$varFix %*% t(Designmat))
>                newdat$SE <- sqrt(predvar)
>                newdat$SE2 <- sqrt(predvar+kk2$sigma^2)
>
>                #install.packages("ggplot2")
>                library(ggplot2)
>                pd <- position_dodge(width=0.4)
>                ggplot(newdat,aes(x=ind, y=pred, colour=sp))+
>                geom_point(aes(x=kk$ind,y=kk$values, colour=kk$sp),
> size=.3, shape=2, position=pd)+
>                geom_point(position=pd)+
>                geom_linerange(aes(ymin=pred-2*SE2,
> ymax=pred+2*SE2),col="red", position=pd)+
>                geom_errorbar(aes(ymin=pred-2*SE, ymax=pred+2*SE),
> col="black", width=.1, position=pd)
>
> So, we can see the actual points, the SE and SE2 modelled and respective
> means, I think.
> My questions are:
> What is exactly the SE and SE2 (how do we call it in an article legend, for
> example) and how can these be interpreted?
> Can we consider that when the 'lines' do not overlap the species (or
> varieties) are different?
> The SE2 are larger than the actual data in setosa/Petal.Length and overlap
> in the remaining variaties--- how can these show significant differences
> than?
>
> I think I am getting confused or I am missing something important, because
> the results do not appear congruent in my head.
>
> Any help will be much appreciated,
>
> All the best,
> Marta
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



Philip Harrison MSc
PhD student (Fisheries Ecology)
Department of Biology
University of Waterloo
200 University Avenue West
Waterloo, Ontario, Canada
N2L 3G1
Cell:226-808-2309
Email:pharriso at uwaterloo.ca



From bbolker at gmail.com  Fri Jan 13 18:32:17 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Jan 2012 17:32:17 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB v 0.7.1
References: <4F0F17FA.2090403@mail.missouri.edu>
	<4F0F3A72.5080808@otter-rsch.com>
Message-ID: <loom.20120113T180228-511@post.gmane.org>

dave fournier <davef at ...> writes:

> 
> When you run glmmadmb in R, R writes ADMB's files and runs the glmmadmb 
> program
> via system(). There is an option to keep these files and then to run 
> glmmadmb from outside
> R. You can then read the results back into R. Doing it this way (i.e. 
> exiting R before
> running glmmadmb) will give you a bit more memory. It may be enough.
> That is the simplest first thing to try I think.
> 
> 
  specifically, you should be able to specify 

..., save.dir="tmp", admb.opts=admbControl(run=FALSE), ...

which will create the temp directory with everything you need in it.
Then run ADMB from the terminal/command window.

  Here's an example:

data(bacteria,package="MASS")
bacteria$present <- as.numeric(bacteria$y)-1
## run to generate files
glmmadmb(present ~ trt + I(week > 2), random = ~ 1 | ID,
                     family = "binomial", data = bacteria,
         save.dir="tmp",admb.opts=admbControl(run=FALSE),
         debug=TRUE)
## now run glmmadmb outside of R ...
## ./glmmadmb -maxfn 500 -maxph 5 -noinit -shess
## run to read in data
result <- glmmadmb(present ~ trt + I(week > 2), random = ~ 1 | ID,
                     family = "binomial", data = bacteria,
         save.dir="tmp",admb.opts=admbControl(run=FALSE))



From bbolker at gmail.com  Fri Jan 13 18:35:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Jan 2012 17:35:44 +0000 (UTC)
Subject: [R-sig-ME] In II[, ii] + REmat$codes[[i]] :
References: <CAKz8Hv=jZvhNxijKV-X7eWkViTCfVghe0HdoPGEcRCzzpBoyPw@mail.gmail.com>
Message-ID: <loom.20120113T183322-344@post.gmane.org>

Giulia Dotti Sani <giulia.dottisani at ...> writes:

> I'm running the following poisson and I keep getting the same error.
> M01 <- glmmadmb(chi_hh ~ age_m + educ +(1 |country_y), data=data,
> family="poisson")
> 
> In II[, ii] + REmat$codes[[i]] :
>   longer object length is not a multiple of shorter object length
> 
> I think it has to do with the grouping variable but I don't see what's
> the problem.

  Not reproducible ... post the data somewhere or send them to me?
  Results of sessionInfo() please (i.e. what version of glmmADMB
are you using?)
  For what it's worth, for this problem you could also use glmer,
which might be faster.  glmmADMB really comes into its own for
extended models (zero-inflated or truncated, negative binomial, Beta, etc.) that
glmer can't handle.

  Ben Bolker



From bbolker at gmail.com  Fri Jan 13 19:44:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Jan 2012 13:44:21 -0500
Subject: [R-sig-ME] In II[, ii] + REmat$codes[[i]] :
In-Reply-To: <CAKz8Hv=5Usr9FwFVJO6CjUzFVGfA4pvv5_wEXJU5O6thPY2cbA@mail.gmail.com>
References: <CAKz8Hv=jZvhNxijKV-X7eWkViTCfVghe0HdoPGEcRCzzpBoyPw@mail.gmail.com>	<loom.20120113T183322-344@post.gmane.org>
	<CAKz8Hv=5Usr9FwFVJO6CjUzFVGfA4pvv5_wEXJU5O6thPY2cbA@mail.gmail.com>
Message-ID: <4F107B85.3000602@gmail.com>

 [cc'ing back to r-sig-mixed-models]

  A few things:

* the basic problem is that you have NA values in your data: these get
removed automatically in one place in the code and not in the other,
hence the length mismatch.  This is not absolutely trivial to fix
automatically -- the fixed and random effect predictors are handled
separately, and there may be extra variables in the data that should be
disregarded completely -- but in the meantime I have at least put in an
informative warning message in this case (for the next release).  The
simplest solution is to use na.omit() to get rid of these values (which
can't be used in the fit anyway).

 * it's not advisable to fit a random effect to a factor with only three
levels, although in this case it seems not to do anything disastrous
(ADMB does issue one warning, although in this case it seems harmless)

 * for this problem glmer works *much* faster than glmmADMB (glmmADMB
used to work faster, but we made it slower in the process of adapting it
to be more general and flexible) -- about 2 seconds vs. 2 minutes on my
computer.  quasi-likelihood is unreliable (and no longer possible) in
glmer, but you should check http://glmm.wikidot.com/faq for other
alternatives for handling overdispersion [and for more on the previous
point about numbers of levels of random effects] (although it is still
true that glmmADMB allows a wider range of options than glmer)

 * the data set you sent didn't have a 'chi_hh' variable in it, only an
'ave_chi_hh' variable -- I used it instead for the fitting. *However*,
ave_chi_hh is not integer-valued.  Unless you're absolutely sure you
know what you're doing, you shouldn't use a Poisson GLMM to fit
non-integer data.  (I'm adding a test and a warning for this too.)

library(glmmADMB)
## best not to call data 'data', this masks a built-in R function
ddat <- read.csv("dottisani_data.csv")
summary(ddat)
ddat <- na.omit(ddat)

library(lme4)
t1 <- system.time(g1 <- glmer(ave_chi_hh ~ age + educ +(1 |country_y),
data=ddat,
         family="poisson"))

t2 <- system.time(g2 <- glmmadmb(ave_chi_hh ~ age + educ +(1
|country_y), data=ddat,
         family="poisson"))


On 12-01-13 01:08 PM, Giulia Dotti Sani wrote:
> Hello and thanks for the answer
> I'm attaching a subset of the data I'm using.  I was using lmer, but I
> moved to glmm to tackle overdispersion, since I've been reading that
> the quasipoisson families for lmer are not reliable.
> 
> thank you
> Giulia
> 
> 
>>  sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
> [5] LC_TIME=Italian_Italy.1252
> 
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods
> [8] base
> 
> other attached packages:
>  [1] glmmADMB_0.7.2   R2admb_0.7.5     car_2.0-11       survival_2.36-10
>  [5] nnet_7.3-1       foreign_0.8-48   arm_1.4-14       abind_1.4-0
>  [9] R2WinBUGS_2.1-18 coda_0.14-6      MASS_7.3-16      lmtest_0.9-29
> [13] zoo_1.7-6        lme4_0.999375-42 Matrix_1.0-2     lattice_0.20-0
> 
> loaded via a namespace (and not attached):
> [1] grid_2.14.1   nlme_3.1-102  stats4_2.14.1 tools_2.14.1
> 
> 
> On Fri, Jan 13, 2012 at 6:35 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Giulia Dotti Sani <giulia.dottisani at ...> writes:
>>
>>> I'm running the following poisson and I keep getting the same error.
>>> M01 <- glmmadmb(chi_hh ~ age_m + educ +(1 |country_y), data=data,
>>> family="poisson")
>>>
>>> In II[, ii] + REmat$codes[[i]] :
>>>   longer object length is not a multiple of shorter object length
>>>
>>> I think it has to do with the grouping variable but I don't see what's
>>> the problem.
>>
>>  Not reproducible ... post the data somewhere or send them to me?
>>  Results of sessionInfo() please (i.e. what version of glmmADMB
>> are you using?)
>>  For what it's worth, for this problem you could also use glmer,
>> which might be faster.  glmmADMB really comes into its own for
>> extended models (zero-inflated or truncated, negative binomial, Beta, etc.) that
>> glmer can't handle.
>>
>>  Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From mrmetz at ucdavis.edu  Fri Jan 13 21:41:14 2012
From: mrmetz at ucdavis.edu (Margaret Metz)
Date: Fri, 13 Jan 2012 12:41:14 -0800
Subject: [R-sig-ME] specifying/interpreting random effects with near-zero
	variance in glmer()
Message-ID: <A9F0FB10-577E-4719-80C2-CDE2E0B19987@ucdavis.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120113/ea160f77/attachment-0002.pl>

From bbolker at gmail.com  Fri Jan 13 23:37:52 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Jan 2012 17:37:52 -0500
Subject: [R-sig-ME] In II[, ii] + REmat$codes[[i]] :
In-Reply-To: <CAKz8HvmaZ97CEOOVBiiDX7Sfn_dBcZCQ2HvTP2iqAnvrE-Y1_A@mail.gmail.com>
References: <CAKz8Hv=jZvhNxijKV-X7eWkViTCfVghe0HdoPGEcRCzzpBoyPw@mail.gmail.com>	<loom.20120113T183322-344@post.gmane.org>	<CAKz8Hv=5Usr9FwFVJO6CjUzFVGfA4pvv5_wEXJU5O6thPY2cbA@mail.gmail.com>	<4F107B85.3000602@gmail.com>
	<CAKz8HvmaZ97CEOOVBiiDX7Sfn_dBcZCQ2HvTP2iqAnvrE-Y1_A@mail.gmail.com>
Message-ID: <4F10B240.5020104@gmail.com>


  [cc'd back to r-sig-mixed-models again: I strongly prefer to have
these conversations on the record so they can be archived and so that
others can benefit from them]

On 12-01-13 05:13 PM, Giulia Dotti Sani wrote:
> Thank you for the suggestions,
> 
> *Indeed getting rid of NA's solved that problem.
> 
> * I actually have 37 groups, but it didn't seem useful to send you a
> gigantic dataset for this purpose. I apologize if this was misleading.
> 
> *I'm trying out glmmPQL for overdispersion at the moment to see if
> works faster (and it seems to)

  I'm sure glmmPQL is faster than glmmADMB for these problems, but I
repeat that there are at least some options (the primary one being
adding an observation-level random effect) for handling overdispersion
in glmer.  Furthermore, in general the Laplace approximation (glmer's
default algorithm is more accurate than PQL, and AGQ (an option with
glmer) is more accurate still, although it may not matter much in your
case (I would definitely do at least a brief comparison between the
results of the different methods on a test data set to see how much they
differ).

> *I'm using a Poisson with non integers beacause the dependent var is
> the ratio of time in a / time in b. It necessarily has values between
> 0 and 1, but also greater than 1. time-use data literature suggests to
> use the poisson because it wouldn't make sense to have negative
> estimates.

  I won't say this makes *no* sense, but I claim it's not necessarily
sensible.  If you're really analyzing ratios then beta regression has a
better theoretical foundation (it is supported in glmmADMB, although not
in glmer), although it's not without its practical problems.  Gamma
regression (supported in both glmmADMB and glmer, although somewhat
finicky in glmer) also assumes a non-negative response, although it
assumes a continuous response (which seems more sensible).  Log-normal
(i.e. simply transform the data) is also a possibility.
  Looking at the marginal distribution of your response variable, it
seems to have values up to 57?  Are these on a percentage scale?

  I wonder if the zeros are a different category or simply represent
censoring/lack of resolution ...

ggplot(ddat,aes(x=age,y=0.001+ave_chi_hh,colour=country_y))+stat_sum(alpha=0.3)+geom_smooth()+facet_wrap(~educ)+
  scale_y_log10()+theme_bw()


> 
> 
> On Fri, Jan 13, 2012 at 7:44 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>  [cc'ing back to r-sig-mixed-models]
>>
>>  A few things:
>>
>> * the basic problem is that you have NA values in your data: these get
>> removed automatically in one place in the code and not in the other,
>> hence the length mismatch.  This is not absolutely trivial to fix
>> automatically -- the fixed and random effect predictors are handled
>> separately, and there may be extra variables in the data that should be
>> disregarded completely -- but in the meantime I have at least put in an
>> informative warning message in this case (for the next release).  The
>> simplest solution is to use na.omit() to get rid of these values (which
>> can't be used in the fit anyway).
>>
>>  * it's not advisable to fit a random effect to a factor with only three
>> levels, although in this case it seems not to do anything disastrous
>> (ADMB does issue one warning, although in this case it seems harmless)
>>
>>  * for this problem glmer works *much* faster than glmmADMB (glmmADMB
>> used to work faster, but we made it slower in the process of adapting it
>> to be more general and flexible) -- about 2 seconds vs. 2 minutes on my
>> computer.  quasi-likelihood is unreliable (and no longer possible) in
>> glmer, but you should check http://glmm.wikidot.com/faq for other
>> alternatives for handling overdispersion [and for more on the previous
>> point about numbers of levels of random effects] (although it is still
>> true that glmmADMB allows a wider range of options than glmer)
>>
>>  * the data set you sent didn't have a 'chi_hh' variable in it, only an
>> 'ave_chi_hh' variable -- I used it instead for the fitting. *However*,
>> ave_chi_hh is not integer-valued.  Unless you're absolutely sure you
>> know what you're doing, you shouldn't use a Poisson GLMM to fit
>> non-integer data.  (I'm adding a test and a warning for this too.)
>>
>> library(glmmADMB)
>> ## best not to call data 'data', this masks a built-in R function
>> ddat <- read.csv("dottisani_data.csv")
>> summary(ddat)
>> ddat <- na.omit(ddat)
>>
>> library(lme4)
>> t1 <- system.time(g1 <- glmer(ave_chi_hh ~ age + educ +(1 |country_y),
>> data=ddat,
>>         family="poisson"))
>>
>> t2 <- system.time(g2 <- glmmadmb(ave_chi_hh ~ age + educ +(1
>> |country_y), data=ddat,
>>         family="poisson"))
>>
>>
>> On 12-01-13 01:08 PM, Giulia Dotti Sani wrote:
>>> Hello and thanks for the answer
>>> I'm attaching a subset of the data I'm using.  I was using lmer, but I
>>> moved to glmm to tackle overdispersion, since I've been reading that
>>> the quasipoisson families for lmer are not reliable.
>>>
>>> thank you
>>> Giulia
>>>
>>>
>>>>  sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
>>> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
>>> [5] LC_TIME=Italian_Italy.1252
>>>
>>> attached base packages:
>>> [1] splines   stats     graphics  grDevices utils     datasets  methods
>>> [8] base
>>>
>>> other attached packages:
>>>  [1] glmmADMB_0.7.2   R2admb_0.7.5     car_2.0-11       survival_2.36-10
>>>  [5] nnet_7.3-1       foreign_0.8-48   arm_1.4-14       abind_1.4-0
>>>  [9] R2WinBUGS_2.1-18 coda_0.14-6      MASS_7.3-16      lmtest_0.9-29
>>> [13] zoo_1.7-6        lme4_0.999375-42 Matrix_1.0-2     lattice_0.20-0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.14.1   nlme_3.1-102  stats4_2.14.1 tools_2.14.1
>>>
>>>
>>> On Fri, Jan 13, 2012 at 6:35 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>> Giulia Dotti Sani <giulia.dottisani at ...> writes:
>>>>
>>>>> I'm running the following poisson and I keep getting the same error.
>>>>> M01 <- glmmadmb(chi_hh ~ age_m + educ +(1 |country_y), data=data,
>>>>> family="poisson")
>>>>>
>>>>> In II[, ii] + REmat$codes[[i]] :
>>>>>   longer object length is not a multiple of shorter object length
>>>>>
>>>>> I think it has to do with the grouping variable but I don't see what's
>>>>> the problem.
>>>>
>>>>  Not reproducible ... post the data somewhere or send them to me?
>>>>  Results of sessionInfo() please (i.e. what version of glmmADMB
>>>> are you using?)
>>>>  For what it's worth, for this problem you could also use glmer,
>>>> which might be faster.  glmmADMB really comes into its own for
>>>> extended models (zero-inflated or truncated, negative binomial, Beta, etc.) that
>>>> glmer can't handle.
>>>>
>>>>  Ben Bolker
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From bbolker at gmail.com  Sat Jan 14 01:49:38 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 14 Jan 2012 00:49:38 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?specifying/interpreting_random_effects_with_?=
	=?utf-8?q?near-zero=09variance_in_glmer=28=29?=
References: <A9F0FB10-577E-4719-80C2-CDE2E0B19987@ucdavis.edu>
Message-ID: <loom.20120114T013651-497@post.gmane.org>

Margaret Metz <mrmetz at ...> writes:

[snip]
 
> I am using glmer() and a logit link for the survival model,
> including fixed factors of 3 topographic models ("topo1", "topo2",
> and "topo3" for simplicity), starting height ("ht") I have 130+
> species ("sp") found at 200 census stations ("station").  Not all
> species are found at all stations, and the sample size per species
> ranges from 10 - 1200 individuals (and I could restrict these
> further to ones with a sample size greater than some threshold).

  The topo variables are continuous, right?

  You probably don't need to -- this is one of the strengths of 
the mixed modeling approach.

>  I would like to know whether the topographic variables are
> significant predictors of mortality while including the random
> factors of census station to account for non-independence of
> seedlings at the same location (which have the same topo
> measurements) and species to allow for variation in species'
> responses.  I expect that both the slope and intercept of species'
> responses to each variable could be quite different.  To allow for
> different slopes/intercepts among species, I have centered the
> continuous variables and specified the model as:

 
> glmer(survival ~ topo1 + topo2 + topo3 + ht + 
> (0 + topo1 | sp) + (0 + topo2 | sp) + (0 + topo3 | sp) + (1 | sp) + 
> (1 | station), data=seedlingdata, family=binomial)

  This looks reasonable, you might want to check for overdispersion.

> Questions: When I do this, there is a random intercept for station,
> a random intercept for species, and then random slopes among species
> for the relationship with the topographic variables as follows in
> the model output.  I believe this is allowing for the variation
> among species that I intend, but would like confirmation of this
> specification vs. something like (topo1 | sp) or (1 + topo1 | sp) as
> someone else has suggested to me.

(topo1 | sp) is equivalent to (1 | topo1 | sp) (as
(0 + topo1 | sp) is equivalent to (topo1 - 1 | sp)

  If you have enough data you could try

(topo1 + topo2 + topo3 | sp ) 

which allows for correlation among the effects of the topographic
variables -- although you can run out of data pretty quickly in
some cases, and it sounds from stuff below as though you're running
low on signal anyway.  (This model has (n+1)*(n+2)/2 = 10 parameters --
4 variances (topo[1-3] plus intercept) and 6 covariances -- as opposed
to the 4 variances of the model you are using.) (I'm not counting
the station variable in these totals.)
 
> Any version of these models that I have run results in significant
> fixed factors and zero or near-zero variances for the random
> effects.  I interpret this to mean that the topographic variables
> are important predictors of seedling mortality, but that the
> relationship does not vary among species groups nor census
> locations.  Is this your interpretation too or need I worry about
> model specification or the sample size or variance structure of my
> variables?

   This is a reasonable interpretation.  However, be aware that this
is signal-to-noise / sample-size dependent.  There could be (is, by
definition, in an ecological system) some among-species and
among-station variance that you just can't detect with this data set.
(In a classical model with a balanced, nested, etc. design you would
probably just find a small (non-significant) variance in this case,
rather than a practically-zero one -- on the other hand, there are
other classical models where you would actually estimate a *negative*
variance.)

>  A suggestion was made to confirm a lack of spatial autocorrelation
> in the residuals of this model, but I am not sure that is
> appropriate given the inclusion of the random effect of census
> station and the fixed effects of topography, which are shared by
> seedlings at the same station.  Can anyone suggest an appropriate
> reference to support or refute this suggestion?

  I don't have a reference but I would suggest that checking for
spatial autocorrelation might be worthwhile. Spatial autocorrelation
would detect the effects of _unmeasured_ covariates that were more
similar among nearby stations.


> Finally, if the response to topography DID significantly vary among
> species, where in this model would I see it?  In a large variance
> for the species slopes or intercept?  
 
  Exactly (variance among species in responses to topo1, topo2, topo3)

Or would I need to include
> species as a fixed factor crossed with the topographic variables?

  (topo1 | sp) is effectively crossing topo with species.

  I would consider looking (at least graphically) for evidence
of nonlinearity in the responses to the continuous variables ...
you could fit a GAM without *too* much extra effort, and with
this size dataset it might produce interesting results.



From bates at stat.wisc.edu  Sat Jan 14 17:27:41 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 14 Jan 2012 10:27:41 -0600
Subject: [R-sig-ME] specifying/interpreting random effects with
 near-zero variance in glmer()
In-Reply-To: <loom.20120114T013651-497@post.gmane.org>
References: <A9F0FB10-577E-4719-80C2-CDE2E0B19987@ucdavis.edu>
	<loom.20120114T013651-497@post.gmane.org>
Message-ID: <CAO7JsnRjZ2=wcZNMYuAxuHQKBj8Leaon6d4=hUWcdmJzSyndww@mail.gmail.com>

On Fri, Jan 13, 2012 at 6:49 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Margaret Metz <mrmetz at ...> writes:
>
> [snip]
>
>> I am using glmer() and a logit link for the survival model,
>> including fixed factors of 3 topographic models ("topo1", "topo2",
>> and "topo3" for simplicity), starting height ("ht") I have 130+
>> species ("sp") found at 200 census stations ("station"). ?Not all
>> species are found at all stations, and the sample size per species
>> ranges from 10 - 1200 individuals (and I could restrict these
>> further to ones with a sample size greater than some threshold).
>
> ?The topo variables are continuous, right?
>
> ?You probably don't need to -- this is one of the strengths of
> the mixed modeling approach.
>
>> ?I would like to know whether the topographic variables are
>> significant predictors of mortality while including the random
>> factors of census station to account for non-independence of
>> seedlings at the same location (which have the same topo
>> measurements) and species to allow for variation in species'
>> responses. ?I expect that both the slope and intercept of species'
>> responses to each variable could be quite different. ?To allow for
>> different slopes/intercepts among species, I have centered the
>> continuous variables and specified the model as:
>
>
>> glmer(survival ~ topo1 + topo2 + topo3 + ht +
>> (0 + topo1 | sp) + (0 + topo2 | sp) + (0 + topo3 | sp) + (1 | sp) +
>> (1 | station), data=seedlingdata, family=binomial)
>
> ?This looks reasonable, you might want to check for overdispersion.
>
>> Questions: When I do this, there is a random intercept for station,
>> a random intercept for species, and then random slopes among species
>> for the relationship with the topographic variables as follows in
>> the model output. ?I believe this is allowing for the variation
>> among species that I intend, but would like confirmation of this
>> specification vs. something like (topo1 | sp) or (1 + topo1 | sp) as
>> someone else has suggested to me.
>
> (topo1 | sp) is equivalent to (1 | topo1 | sp) (as
> (0 + topo1 | sp) is equivalent to (topo1 - 1 | sp)

To forestall future confusion, I think you meant that (topo1 | sp) is
equivalent to (1 + topo1 | sp)

> ?If you have enough data you could try
>
> (topo1 + topo2 + topo3 | sp )
>
> which allows for correlation among the effects of the topographic
> variables -- although you can run out of data pretty quickly in
> some cases, and it sounds from stuff below as though you're running
> low on signal anyway. ?(This model has (n+1)*(n+2)/2 = 10 parameters --
> 4 variances (topo[1-3] plus intercept) and 6 covariances -- as opposed
> to the 4 variances of the model you are using.) (I'm not counting
> the station variable in these totals.)
>
>> Any version of these models that I have run results in significant
>> fixed factors and zero or near-zero variances for the random
>> effects. ?I interpret this to mean that the topographic variables
>> are important predictors of seedling mortality, but that the
>> relationship does not vary among species groups nor census
>> locations. ?Is this your interpretation too or need I worry about
>> model specification or the sample size or variance structure of my
>> variables?
>
> ? This is a reasonable interpretation. ?However, be aware that this
> is signal-to-noise / sample-size dependent. ?There could be (is, by
> definition, in an ecological system) some among-species and
> among-station variance that you just can't detect with this data set.
> (In a classical model with a balanced, nested, etc. design you would
> probably just find a small (non-significant) variance in this case,
> rather than a practically-zero one -- on the other hand, there are
> other classical models where you would actually estimate a *negative*
> variance.)
>
>> ?A suggestion was made to confirm a lack of spatial autocorrelation
>> in the residuals of this model, but I am not sure that is
>> appropriate given the inclusion of the random effect of census
>> station and the fixed effects of topography, which are shared by
>> seedlings at the same station. ?Can anyone suggest an appropriate
>> reference to support or refute this suggestion?
>
> ?I don't have a reference but I would suggest that checking for
> spatial autocorrelation might be worthwhile. Spatial autocorrelation
> would detect the effects of _unmeasured_ covariates that were more
> similar among nearby stations.
>
>
>> Finally, if the response to topography DID significantly vary among
>> species, where in this model would I see it? ?In a large variance
>> for the species slopes or intercept?
>
> ?Exactly (variance among species in responses to topo1, topo2, topo3)
>
> Or would I need to include
>> species as a fixed factor crossed with the topographic variables?
>
> ?(topo1 | sp) is effectively crossing topo with species.
>
> ?I would consider looking (at least graphically) for evidence
> of nonlinearity in the responses to the continuous variables ...
> you could fit a GAM without *too* much extra effort, and with
> this size dataset it might produce interesting results.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From lontrenzo at gmail.com  Sat Jan 14 17:31:32 2012
From: lontrenzo at gmail.com (Lorenzo Quaglietta)
Date: Sat, 14 Jan 2012 16:31:32 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod(
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
	<loom.20120112T173419-47@post.gmane.org>
Message-ID: <loom.20120114T172522-882@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Isa Blasco <isa.blasco.costa at ...> writes:
> 
> > 
> > Hi,
> > I am using glmmADMB to fit a negative binomial model to my data. My
> > explanatory variable is an ordered factor with 10 levels and I also
> > included a random factor (numeric) and Zero inflation.
> > This is the code I used: m7 <- glmmadmb (abun~odist + (1|sl), data=apa,
> > zeroInflation=TRUE, family="nbinom")
> > 
> > When I run it I got this error:
> > Error in UseMethod("droplevels") :
> >   no applicable method for 'droplevels' applied to an object of class
> > "c('double', 'numeric')"
> > 
> > I do not know what the 'double' means but I checked the glmmADMB manual and
> > they use the same kind of variables in their example. Any guess on what it
> > is happening? How can I solve it?
> > I hope somebody knows!
> 
>   It means that it doesn't make sense to use a numeric variable as
> a grouping variable for a random factor (which is what you've done):
> if sl is a discrete numeric code that identifies groups of observations,
> then you should convert it to a factor.  If it's a continuous variable,
> then you need to go back and read/think some more about the meanings
> of random factors ...
> 
>   It also means that I made some changes to glmmADMB recently that
> got in the way of an informative error message (you should have
> received an error message that told you this).  I will try to 
> catch that error in a more informative way.
> 
>   Ben Bolker
> 
> 


Hi,

I'm having  a similar problem.

My model formula is:

glmmADMB1 <- glmmadmb(Fix ~ log_BIO_F * log_BIO_P + log_drs + fperp + log_pr +
log_la + (1 | ANIMALE) + (1 | ID) + (1 | Time), data=otters, zeroInflation=TRUE,
family="poisson").

and I got the following error message:

"Error in UseMethod("droplevels") : 
  no applicable method for 'droplevels' applied to an object of class
"c('integer', 'numeric')".

My random terms are not categorical nor fitted as factors. Which could be the
problem?

Many thanks in advance, best regards,

Lorenzo Quaglietta



From biowahl at gmail.com  Sun Jan 15 01:22:55 2012
From: biowahl at gmail.com (Colin Wahl)
Date: Sat, 14 Jan 2012 16:22:55 -0800
Subject: [R-sig-ME] Comparing results from glmer and glht
Message-ID: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>

I will try to make this concise.

Background: I am testing the effects of land use and forested riparian
buffers on stream invertebrates and in-stream variables. There are 4
watershed types (defined by 4 types of land use) and two riparian
types (forested and non). Percent EPT (relative abundance) was my main
response variable. I also measured a variety of in-stream variables
like temperature, nutrients, and toxicity. There are 72 observations
for invertebrates, and 24 for in-stream variables.

I am curious of how acceptable p values are from pairwise comparisons
using glht() from the multcomp package

I used glmer with a binomial error structure and an observation-level
random effect (to account for overdispersion), to model invertebrates:

modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs),
data=ept, family=binomial(link="logit"))

   AIC   BIC logLik deviance
 284.4 309.5 -131.2    262.4
Random effects:
 Groups     Name        Variance Std.Dev.
 obs        (Intercept) 0.30186  0.54942
 stream:rip (Intercept) 0.40229  0.63427
 stream     (Intercept) 0.12788  0.35760
Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12

Fixed effects:
                 Estimate Std. Error z value Pr(>|z|)
(Intercept)   -4.2906     0.4935   -8.694  < 2e-16 ***
wshd           -2.0557     0.7601  -2.705  0.00684 **
wshf            3.3575     0.6339   5.297  1.18e-07 ***
wshg           3.3923     0.7486    4.531  5.86e-06 ***
ripN             0.1425     0.6323   0.225  0.82165
wshd:ripN     0.3708     0.9682   0.383  0.70170
wshf:ripN    -0.8665     0.8087   -1.071  0.28400
wshg:ripN    -3.1530     0.9601  -3.284  0.00102 **
---

Correlation of Fixed Effects:
                 (Intr)  wshd   wshf   wshg   ripN   wshd:N wshf:N
wshd        -0.649
wshf        -0.779  0.505
wshg        -0.659  0.428  0.513
ripN         -0.644  0.418  0.501  0.424
wshd:ripN  0.421 -0.672 -0.327 -0.277 -0.653
wshf:ripN  0.503 -0.327 -0.638 -0.332 -0.782  0.511
wshg:ripN  0.424 -0.275 -0.330 -0.632 -0.659  0.430  0.515


I then used this model to do Tukey's HSD contrasts between watershed types:

summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))
Linear Hypotheses:

                Estimate Std. Error z value Pr(>|z|)
d - c == 0 -2.05573    0.76010  -2.705   0.0341 *
f - c == 0  3.35753    0.63386   5.297   <0.001 ***
g - c == 0  3.39231    0.74862   4.531   <0.001 ***
f - d == 0  5.41326    0.70176   7.714   <0.001 ***
g - d == 0  5.44804    0.80692   6.752   <0.001 ***
g - f == 0  0.03479    0.68931   0.050   1.0000

and riparian types:

                                                          Estimate
Std. Error z value Pr(>|z|)
C: Forested vs. Non-Forested == 0         0.1425     0.6323   0.225  0.99999
D: Forested vs. Non-Forested == 0         0.5134     0.7332   0.700  0.98659
F: Forested vs. Non-Forested == 0        -0.7239     0.5042  -1.436  0.69625
G: Forested vs. Non-Forested == 0        -3.0105     0.7225  -4.167  < 0.001 ***

Are these p values accurate? Or is that a personal judgement I have to
make based on the clarity of the patterns they reflect?

I've shown these results in my figures and explained them in my
results. I've basically explained that though these p values
reasonably reflect patterns in my data, effects sizes, and variances,
that they are inexact and potentially anti-conservative due to the
issues with degrees of freedom in mixed models.

>From what I understand from my research in the last year is that
Douglas Bates and others advocate something of a paradigm shift away
from the petagogically reinforced reliance on cryptic p values toward
more in depth discussions of effects sizes and variances. The use of
MCMC sampling and HPD intervals are suggested, but these are not
available for generalized models.

I am interested in publishing these results as an ecologist, not a
statistician (pardon the somewhat artificial distinction), and, I am
very interested in what kind of a discussion the statisticians and
ecologists of the r-sig-mixed-models mailing list would like to see as
potential reviewers.

Thank you,

Colin Wahl

M.S. candidate,
Dept. of Biology
Western Washington University
Bellingham, WA



From jens.astrom at slu.se  Sun Jan 15 13:04:18 2012
From: jens.astrom at slu.se (=?ISO-8859-1?Q?Jens_=C5str=F6m?=)
Date: Sun, 15 Jan 2012 13:04:18 +0100
Subject: [R-sig-ME] Mean of random effects same as fixed effect?
In-Reply-To: <CAO7JsnT+9YeewXf1izJ41Fh_uSMPweLOCsi4TDNjr=OgT6wSjw@mail.gmail.com>
References: <4F094BD7.1080408@slu.se>
	<CAO7JsnT+9YeewXf1izJ41Fh_uSMPweLOCsi4TDNjr=OgT6wSjw@mail.gmail.com>
Message-ID: <4F12C0C2.3050708@slu.se>

Thanks for the input! It is appreciated. In practice, my problem is
solved but there still remains some questions.

I was shown off list the conventional way of modelling this in a
Bayesian framework (below). It seems I was barking in the right general
direction, but not at the right tree. Prof. Bates objections may explain
the slight differences in results between my hack version and the more
conventional, but I am not sure.

I realise now that simply taking the mean of observations defined to be
normally distributed is not the same as estimating the mean of that
underlying distribution. For instance, there may be extreme values that
could be given undue influence by just taking the mean.

I believe that the conventional BUGS approach deals with this problem,
but I am curious if it is still subject to any of Prof. Bates
objections. The unconditional means of the random effects is here
defined as the fixed intercept and slope values. Remember, the initial
problem was that doing differently resulted in non-convergence.

When I manipulate the sleepstudy data set to produce a non-balanced data
set, the three methods (my hack version, the conventional BUGS, and
lmer) all gives slightly different answers, otherwise pretty much the
same. This leaves me curious if one can be considered more correct than
the other.

Any other suggestions of model specifications or other thoughts are
appreciated, otherwise I will settle with the conventional for now.



For future reference, this appears to be a conventional way to implement
models of the form
fm1<-lmer(Reaction~Days+(Days|Subject),data=sleepstudy)
in BUGS/JAGS (thanks again Kent!). (Inverse wishart is another way)




model{

   for (i in 1:length(Reaction)){
     Reaction[i] ~ dnorm (mu[i], tau.Reaction)
     mu[i] <-subj.inter[subj[i]] + subj.Days[subj[i]]*Days[i]
   }
   tau.Reaction~dgamma(0.001,0.001)

   sigma.Reaction<-sqrt(1/tau.Reaction)

   for (j in 1:nr.subj){
     subj.inter[j] <- B[j,1]
     subj.Days[j] <- B[j,2]
     B[j,1:2] ~ dmnorm (B.hat[j,], Tau.B[,])
     B.hat[j,1] <- intercept
     B.hat[j,2] <- Days.par
   }
   intercept ~ dnorm(0, 1.0e-6)
   Days.par ~ dnorm(0, 1.0e-6)

   ## hack.intercept<-mean(subj.inter[])
   ## hack.Days.par<-mean(subj.Days[])

   Tau.B[1:2,1:2] <- inverse(Sigma.B[,])
   Sigma.B[1,1] <- pow(sigma.subj.inter, 2)
   sigma.subj.inter ~ dunif (0, 100)
   Sigma.B[2,2] <- pow(sigma.subj.Days, 2)
   sigma.subj.Days ~ dunif (0, 100)
   Sigma.B[1,2] <- rho*sigma.subj.inter*sigma.subj.Days
   Sigma.B[2,1] <- Sigma.B[1,2]
   rho ~ dunif (-1, 1)
   #rho<-0 #set this at zero for non correlated random effects
}


/Jens




On 01/09/2012 09:02 PM, Douglas Bates wrote:
> On Sun, Jan 8, 2012 at 1:55 AM, Jens ?str?m <jens.astrom at slu.se> wrote:
>> Hi all,
>>
>> A couple of weeks ago I posted a question but got no answers. Here goes
>> a second attempt, now shorter and more general.
>>
>>
>> Are the following two model specifications interchangeable, or is there
>> a statistical reason for why it is not OK to express model 1 in the form
>> of model 2?
>>
>> Model 1)
>> y=fixed.intercept+fixed.slope*x+random.intercept+random.slope*x
>>
>> Model 2)
>> y=random.intercept*x+random.slope*x
>> fixed.intercept=mean(random.intercept)
>> fixed.slope=mean(random.slope)
> 
> You would need at least equal group sizes and identical values of the
> covariate with respect to which you have a random slope to be able to
> count on this.  Even then I'm not entirely sure it would work.
> 
> Generally the unconditional distribution of the random effects is
> defined to have a mean of zero.  I don't know how you are defining
> yours (and prefer not to wade through BUGS/JAGS model specifications
> to find out).
> 
>> The reasons for my asking is that I have trouble getting convergence
>> with model specification 1, when the random intercepts and random slopes
>> are correlated, but specifying it as model 2 seemed to work. This is me
>> trying to implement some standard mixed models in BUGS/JAGS. Original
>> post with complete working example is here:
>> http://markmail.org/message/vhqeq4j3kldttlt5
>>
>>
>>
>> I'm happy for any comments, with or without BUGS/JAGS code.
>>
>> /Jens Astrom
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From erikfrenzel at gmail.com  Sun Jan 15 18:10:43 2012
From: erikfrenzel at gmail.com (Erik Frenzel)
Date: Sun, 15 Jan 2012 09:10:43 -0800
Subject: [R-sig-ME] Advice on GLS model specification
Message-ID: <CANJAy05uQtpa=oOTzojL8BJ6S_JOgQH5WGx56ryQWH3_g=1GDw@mail.gmail.com>

Hello mixed modellers:
I'm helping a coworker analyze some toxicology data and would
appreciate any feedback on my proposed analysis, particularly in
regards to how I've specified a contrast.

He collected 1 blood sample from each of 79 animals at 7 sites in 2
regions. He would like to know the difference in the response variable
(concentration of a chemical in the blood) between regions after
accounting for two covariates (mass and temperature) which were
measured for each animal. The data are unbalanced and the variance of
the response variable also differs between sites.

My plan is to fit a GLS model with fixed effects of the two covariates
and site, specify the correlation and variance structures, and test
for the difference between regions using a contrast between the sites
in two regions. Reproducible code with data from dput() is at the end
of the message.

> str(data) #  each record is a blood sample
'data.frame':   79 obs. of  5 variables:
 $ region: Factor w/ 2 levels "north","south": 1 1 1 1 1 1 1 1 1 1 ...
 $ site  : Factor w/ 7 levels "a","b","c","d",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ resp  : num  0.1672 0.0733 0.1637 0.0836 0.1195 ...
 $ mass  : num  185 450 718 388 250 410 602 315 462 637 ...
 $ temp  : num  25.2 24.2 23.8 25.2 23.4 24.8 24 23.5 26.2 27.1 ...

> xtabs(~region+site, data=data) # unequal number of observations between sites
       site
region   a  b  c  d  e  f  g
  north 11 20  8  0  0  0  0
  south  0  0  0 10 24  4  2

> library(nlme)
> contrasts(data$site) <- c(-1/3, -1/3, -1/3, 1/4, 1/4, 1/4, 1/4) # test the difference between 3 northern and 4 southern sites, other contrasts may be of interest but I'm starting with this one.

> gls1 <- gls(resp ~ mass + temp + site, weights = varIdent(site), correlation = corCompSymm(form = ~ 1|site), method = "REML", data = data)

> summary(gls1)
Generalized least squares fit by REML
  Model: resp ~ mass + temp + site
  Data: data
   AIC  BIC logLik
  -231 -207    127

Correlation Structure: Compound symmetry
 Formula: ~1 | site
 Parameter estimate(s):
    Rho
3.8e-08

Coefficients:
              Value Std.Error t-value p-value
(Intercept)  0.1143    0.0442   2.587  0.0118
mass         0.0000    0.0000   1.072  0.2875
temp        -0.0004    0.0018  -0.215  0.8305
site1       -0.0538    0.0179  -3.008  0.0037
site2       -0.0061    0.0108  -0.563  0.5755
site3       -0.0122    0.0108  -1.127  0.2638
site4       -0.0039    0.0097  -0.403  0.6882
site5        0.0171    0.0153   1.122  0.2658
site6       -0.0038    0.0189  -0.204  0.8391

 Correlation:
      (Intr) mass   temp   site1  site2  site3  site4  site5
mass  -0.221
temp  -0.969 -0.001
site1 -0.318  0.443  0.267
site2 -0.350  0.199  0.329  0.051
site3 -0.065  0.110  0.003 -0.167  0.073
site4 -0.237 -0.112  0.207 -0.371  0.102  0.329
site5  0.399  0.121 -0.437  0.004 -0.084 -0.067 -0.100
site6 -0.077 -0.336  0.199  0.255  0.028 -0.387 -0.239 -0.497

Standardized residuals:
    Min      Q1     Med      Q3     Max
-2.4083 -0.5903 -0.0519  0.5830  2.0042

Residual standard error: 0.0305
Degrees of freedom: 79 total; 70 residual


I would interpret this as a difference between the two regions
(contrast = "site1") which is significantly different from 0.  The
effects of mass and temperature don't appear to be significanly
different from zero. Spread of the residuals is still somewhat greater
for some groups. I would welcome any thoughts on the suitability of
this approach. Thanks, Erik


########### reproducible code
data <-

structure(list(region = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("north", "south"), class =
"factor"),
    site = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
    5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L), .Label = c("a", "b",
    "c", "d", "e", "f", "g"), class = "factor"), resp = c(0.1672,
    0.0733, 0.1637, 0.0836, 0.1195, 0.1855, 0.1502, 0.12, 0.1985,
    0.1083, 0.1522, 0.1387, 0.109, 0.0712, 0.1724, 0.1775, 0.1071,
    0.1641, 0.13, 0.1845, 0.1348, 0.1808, 0.1841, 0.0739, 0.0888,
    0.1421, 0.1883, 0.1305, 0.1173, 0.1875, 0.114, 0.1365, 0.1443,
    0.1601, 0.1272, 0.1313, 0.1269, 0.0903, 0.1218, 0.0533, 0.0963,
    0.0868, 0.1259, 0.086, 0.0828, 0.0792, 0.0818, 0.0878, 0.0843,
    0.0963, 0.1138, 0.084, 0.0698, 0.1098, 0.0848, 0.1077, 0.1458,
    0.0896, 0.1045, 0.0719, 0.0771, 0.0868, 0.0743, 0.0868, 0.092,
    0.0774, 0.1591, 0.0858, 0.0734, 0.1256, 0.1027, 0.0988, 0.1234,
    0.0896, 0.1202, 0.1134, 0.1311, 0.1398, 0.0674), mass = c(185,
    450, 718, 388, 250, 410, 602, 315, 462, 637, 861, 423, 764,
    806, 892, 630, 622, 595, 314, 586, 796, 502, 803, 440, 256,
    695, 476, 664, 530, 646, 745, 144, 449, 566, 398, 542, 568,
    198, 649, 160, 248, 244, 211, 259, 178, 230, 216, 254, 269,
    232, 282, 309, 504, 294, 544, 296, 378, 309, 364, 313, 352,
    507, 163, 422, 126, 345, 397, 288, 95, 384, 336, 192, 240,
    359, 133, 208, 101, 560, 509), temp = c(25.2, 24.2, 23.8,
    25.2, 23.4, 24.8, 24, 23.5, 26.2, 27.1, 23.7, 23.4, 25, 25.6,
    25.8, 27.2, 25.4, 25.6, 24.8, 23.6, 23, 24.6, 24.8, 23.2,
    23.8, 25.4, 24.8, 28, 26.6, 26.4, 23.9, 23.2, 23, 20.8, 21.4,
    21.2, 23.2, 23.4, 23.8, 23.8, 22.8, 23.6, 22.2, 21.6, 21.8,
    21.6, 22.8, 21.6, 22.4, 24.4, 20.4, 21, 22.4, 22.2, 22.4,
    22.8, 14.4, 14.2, 15.4, 21, 21.6, 21.4, 20.8, 21.4, 23, 21.3,
    22.6, 22.8, 22.4, 23.6, 22.8, 24.4, 23.8, 28.6, 28.6, 24.4,
    22.6, 21.2, 19.6)), .Names = c("region", "site", "resp",
"mass", "temp"), row.names = c(NA, 79L), class = "data.frame")

str(data)
xtabs(~region+site, data=data) # very unequal number of observations
between sites
library(nlme)
contrasts(data$site) <- c(-1/3, -1/3, -1/3, 1/4, 1/4, 1/4, 1/4) # test
the difference between 3 northern and 4 southern sites
gls1 <- gls(resp ~ mass + temp + site, weights = varIdent(site),
correlation = corCompSymm(form = ~ 1|site), method = "REML", data =
data)
summary(gls1)



From Michelle.Gosse at foodstandards.gov.au  Sun Jan 15 19:50:46 2012
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Mon, 16 Jan 2012 05:50:46 +1100
Subject: [R-sig-ME] MC, sample weights,
	and mixed effect models [SEC=UNCLASSIFIED]
Message-ID: <12E932690323AB4EBEEB21BAA28D90DE369E10A504@EXCHANGE07.foodstandards.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120116/b8b1b892/attachment-0002.pl>

From c.ryan.king at gmail.com  Sun Jan 15 20:35:40 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Sun, 15 Jan 2012 13:35:40 -0600
Subject: [R-sig-ME] MCMCglmm output 1) on right scale? 2) produces huge
	deviance spread?
Message-ID: <CAEQ+J25=0+CaK8hUMcyOqvM88GTTvU+eOpkqEqKmg_Aa=Nmw2Q@mail.gmail.com>

Hi, I have an MCMCglmm run predicting a binary outcome with a single
fixed effect and two groups of random effects like so

testprior4<-list( R=list(V=1, fix=1), G=list(G1=list(V=1, nu=1,
alpha.mu=0, alpha.v=.5^2 ), G2=list(V=1, nu=1, alpha.mu=0, alpha.v=1 )
), B=list(mu=c(0,0), V=diag(2)*4 ) )

testmcmc5b<-MCMCglmm(fixed=myy2~myx,random=~idv(myz)+idv(newz3)   ,
family = "ordinal", prior= testprior4, data=mydata, nitt=6000,
thin=10, burnin=5000 , pr=TRUE)

I can provide the full simulation details, but hope that this is a
general rather than specific problem.

The first set of random effects have large effects, but the second set
is just noise.

I'm setting up a bridge sampler to get a bayes factor, which means I
need to get a log-likelihood + log-prior for my proposal.

I tested my log-likelihood calculation with  MCMC output and got
atrociously spread out log-likelihoods (sd of 15-20). That seems like
rather a lot on the log scale, and means that numerical problems are
likely for the bridge sampler. GLM produces the same deviance up to a
constant (regressing the outcome versus the linear predictor), so that
function is fine. This problem is much smaller when using only the
true predictors (sd = 6) .  The estimated variance component for the
noise predictors never goes above .015, so that they cause this
problem is surprising. Is there a handy explanation / work around?

More troubling, a calibration exercise in the deviance calculation
showed that the groups of linear predictors were not on the right
scale.
That is, multiplying through the two sets of random effects and design
matrices to get batches of linear predictors, and running a glm of the
binary outcome versus the linear predictors using a probit (or logit)
link gets coefficients consistently not 1. The true random effects get
a coefficient of about .65, and the noise random effects between .7
and .4 depending on how I set them up. I don't think it's a bad mixing
problem, because 1) I have gotten the same thing on independent
chains, 2) effectiveSize() reports large effective samples 3) there is
quite a bit of spread in the deviances.  This problem persists if I
run with family="categorical".

When I plug in the re-calibrated linear predictor, the sd of the
log-likelihood goes down a lot, from 15 to 6 in the
two-predictor-group case and from 6 to 3 when using only the true
predictors. That's much better, but still quite a premium for having a
group of noise predictors.

Thanks,
Ryan King
Dept Health Studies
University of Chicago



From Thierry.ONKELINX at inbo.be  Mon Jan 16 09:58:40 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 16 Jan 2012 08:58:40 +0000
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275732B97D@inbomail.inbo.be>

Dear Colin,

I don't think your Tukey tests are very informative. Because you are testing main effects how have an interaction with another variable. So you are not testing the overall effect of a variable but the effect when all other variable are 0 (continuous) or at the reference level (factor).

A better way of doing this could bet o create a new variable which is the interaction between wsh and rip and use that in your model instead of wsh * rip. Then you can use glht() with user defined contrasts so that the contrasts test what you want to test.

Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Colin Wahl
Verzonden: zondag 15 januari 2012 1:23
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Comparing results from glmer and glht

I will try to make this concise.

Background: I am testing the effects of land use and forested riparian buffers on stream invertebrates and in-stream variables. There are 4 watershed types (defined by 4 types of land use) and two riparian types (forested and non). Percent EPT (relative abundance) was my main response variable. I also measured a variety of in-stream variables like temperature, nutrients, and toxicity. There are 72 observations for invertebrates, and 24 for in-stream variables.

I am curious of how acceptable p values are from pairwise comparisons using glht() from the multcomp package

I used glmer with a binomial error structure and an observation-level random effect (to account for overdispersion), to model invertebrates:

modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs), data=ept, family=binomial(link="logit"))

   AIC   BIC logLik deviance
 284.4 309.5 -131.2    262.4
Random effects:
 Groups     Name        Variance Std.Dev.
 obs        (Intercept) 0.30186  0.54942
 stream:rip (Intercept) 0.40229  0.63427
 stream     (Intercept) 0.12788  0.35760
Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12

Fixed effects:
                 Estimate Std. Error z value Pr(>|z|)
(Intercept)   -4.2906     0.4935   -8.694  < 2e-16 ***
wshd           -2.0557     0.7601  -2.705  0.00684 **
wshf            3.3575     0.6339   5.297  1.18e-07 ***
wshg           3.3923     0.7486    4.531  5.86e-06 ***
ripN             0.1425     0.6323   0.225  0.82165
wshd:ripN     0.3708     0.9682   0.383  0.70170
wshf:ripN    -0.8665     0.8087   -1.071  0.28400
wshg:ripN    -3.1530     0.9601  -3.284  0.00102 **
---

Correlation of Fixed Effects:
                 (Intr)  wshd   wshf   wshg   ripN   wshd:N wshf:N
wshd        -0.649
wshf        -0.779  0.505
wshg        -0.659  0.428  0.513
ripN         -0.644  0.418  0.501  0.424
wshd:ripN  0.421 -0.672 -0.327 -0.277 -0.653 wshf:ripN  0.503 -0.327 -0.638 -0.332 -0.782  0.511 wshg:ripN  0.424 -0.275 -0.330 -0.632 -0.659  0.430  0.515


I then used this model to do Tukey's HSD contrasts between watershed types:

summary(glht(modelEPT, linfct=mcp(wsh="Tukey"))) Linear Hypotheses:

                Estimate Std. Error z value Pr(>|z|)
d - c == 0 -2.05573    0.76010  -2.705   0.0341 *
f - c == 0  3.35753    0.63386   5.297   <0.001 ***
g - c == 0  3.39231    0.74862   4.531   <0.001 ***
f - d == 0  5.41326    0.70176   7.714   <0.001 ***
g - d == 0  5.44804    0.80692   6.752   <0.001 ***
g - f == 0  0.03479    0.68931   0.050   1.0000

and riparian types:

                                                          Estimate Std. Error z value Pr(>|z|)
C: Forested vs. Non-Forested == 0         0.1425     0.6323   0.225  0.99999
D: Forested vs. Non-Forested == 0         0.5134     0.7332   0.700  0.98659
F: Forested vs. Non-Forested == 0        -0.7239     0.5042  -1.436  0.69625
G: Forested vs. Non-Forested == 0        -3.0105     0.7225  -4.167  < 0.001 ***

Are these p values accurate? Or is that a personal judgement I have to make based on the clarity of the patterns they reflect?

I've shown these results in my figures and explained them in my results. I've basically explained that though these p values reasonably reflect patterns in my data, effects sizes, and variances, that they are inexact and potentially anti-conservative due to the issues with degrees of freedom in mixed models.

>From what I understand from my research in the last year is that
Douglas Bates and others advocate something of a paradigm shift away from the petagogically reinforced reliance on cryptic p values toward more in depth discussions of effects sizes and variances. The use of MCMC sampling and HPD intervals are suggested, but these are not available for generalized models.

I am interested in publishing these results as an ecologist, not a statistician (pardon the somewhat artificial distinction), and, I am very interested in what kind of a discussion the statisticians and ecologists of the r-sig-mixed-models mailing list would like to see as potential reviewers.

Thank you,

Colin Wahl

M.S. candidate,
Dept. of Biology
Western Washington University
Bellingham, WA

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From i.m.s.white at ed.ac.uk  Mon Jan 16 12:06:17 2012
From: i.m.s.white at ed.ac.uk (i white)
Date: Mon, 16 Jan 2012 11:06:17 +0000
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
Message-ID: <4F1404A9.7010107@ed.ac.uk>

Colin,

A simple graph of means for your eight combinations of 4 watershed types 
and two riparian types shows there are significant differences between 
watershed types c, d and f, and that for those types of watershed, 
riparian type makes no difference to the response. For watershed g, 
response is similar to watershed f for forested streams, but 
significantly lower at non-forested streams (if I have interpreted your 
factor labels correctly). These conclusions are based on inspection of a 
very simple graph with say a white dot for forested stream, black dot 
for unforested stream, and different locations along x axis for the 4 
watershed types. Somewhere on the graph there needs to be a bar whose 
length represents a rough estimate of the average standard error of a 
mean (or difference between two means). Note that neither p-values nor 
multiple comparisons have been mentioned.

Colin Wahl wrote:
> I will try to make this concise.
> 
> Background: I am testing the effects of land use and forested riparian
> buffers on stream invertebrates and in-stream variables. There are 4
> watershed types (defined by 4 types of land use) and two riparian
> types (forested and non). Percent EPT (relative abundance) was my main
> response variable. I also measured a variety of in-stream variables
> like temperature, nutrients, and toxicity. There are 72 observations
> for invertebrates, and 24 for in-stream variables.
> 
> I am curious of how acceptable p values are from pairwise comparisons
> using glht() from the multcomp package
> 
> I used glmer with a binomial error structure and an observation-level
> random effect (to account for overdispersion), to model invertebrates:
> 
> modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs),
> data=ept, family=binomial(link="logit"))
> 
>    AIC   BIC logLik deviance
>  284.4 309.5 -131.2    262.4
> Random effects:
>  Groups     Name        Variance Std.Dev.
>  obs        (Intercept) 0.30186  0.54942
>  stream:rip (Intercept) 0.40229  0.63427
>  stream     (Intercept) 0.12788  0.35760
> Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12
> 
> Fixed effects:
>                  Estimate Std. Error z value Pr(>|z|)
> (Intercept)   -4.2906     0.4935   -8.694  < 2e-16 ***
> wshd           -2.0557     0.7601  -2.705  0.00684 **
> wshf            3.3575     0.6339   5.297  1.18e-07 ***
> wshg           3.3923     0.7486    4.531  5.86e-06 ***
> ripN             0.1425     0.6323   0.225  0.82165
> wshd:ripN     0.3708     0.9682   0.383  0.70170
> wshf:ripN    -0.8665     0.8087   -1.071  0.28400
> wshg:ripN    -3.1530     0.9601  -3.284  0.00102 **
> ---
> 
> Correlation of Fixed Effects:
>                  (Intr)  wshd   wshf   wshg   ripN   wshd:N wshf:N
> wshd        -0.649
> wshf        -0.779  0.505
> wshg        -0.659  0.428  0.513
> ripN         -0.644  0.418  0.501  0.424
> wshd:ripN  0.421 -0.672 -0.327 -0.277 -0.653
> wshf:ripN  0.503 -0.327 -0.638 -0.332 -0.782  0.511
> wshg:ripN  0.424 -0.275 -0.330 -0.632 -0.659  0.430  0.515
> 
> 
> I then used this model to do Tukey's HSD contrasts between watershed types:
> 
> summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))
> Linear Hypotheses:
> 
>                 Estimate Std. Error z value Pr(>|z|)
> d - c == 0 -2.05573    0.76010  -2.705   0.0341 *
> f - c == 0  3.35753    0.63386   5.297   <0.001 ***
> g - c == 0  3.39231    0.74862   4.531   <0.001 ***
> f - d == 0  5.41326    0.70176   7.714   <0.001 ***
> g - d == 0  5.44804    0.80692   6.752   <0.001 ***
> g - f == 0  0.03479    0.68931   0.050   1.0000
> 
> and riparian types:
> 
>                                                           Estimate
> Std. Error z value Pr(>|z|)
> C: Forested vs. Non-Forested == 0         0.1425     0.6323   0.225  0.99999
> D: Forested vs. Non-Forested == 0         0.5134     0.7332   0.700  0.98659
> F: Forested vs. Non-Forested == 0        -0.7239     0.5042  -1.436  0.69625
> G: Forested vs. Non-Forested == 0        -3.0105     0.7225  -4.167  < 0.001 ***
> 
> Are these p values accurate? Or is that a personal judgement I have to
> make based on the clarity of the patterns they reflect?
> 
> I've shown these results in my figures and explained them in my
> results. I've basically explained that though these p values
> reasonably reflect patterns in my data, effects sizes, and variances,
> that they are inexact and potentially anti-conservative due to the
> issues with degrees of freedom in mixed models.
> 
>>From what I understand from my research in the last year is that
> Douglas Bates and others advocate something of a paradigm shift away
> from the petagogically reinforced reliance on cryptic p values toward
> more in depth discussions of effects sizes and variances. The use of
> MCMC sampling and HPD intervals are suggested, but these are not
> available for generalized models.
> 
> I am interested in publishing these results as an ecologist, not a
> statistician (pardon the somewhat artificial distinction), and, I am
> very interested in what kind of a discussion the statisticians and
> ecologists of the r-sig-mixed-models mailing list would like to see as
> potential reviewers.
> 
> Thank you,
> 
> Colin Wahl
> 
> M.S. candidate,
> Dept. of Biology
> Western Washington University
> Bellingham, WA
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From rstuff.miles at gmail.com  Mon Jan 16 16:25:45 2012
From: rstuff.miles at gmail.com (Andrew Miles)
Date: Mon, 16 Jan 2012 10:25:45 -0500
Subject: [R-sig-ME] Log-likelihood and mixed models in glmer
Message-ID: <0015790A-4E33-4458-A7AE-15650CFC4473@gmail.com>

Can someone point me to a reference that will explain why, when using mixed models (glmer and lmer) adding explanatory variables decreases the log likelihood?  This makes no sense to me, as adding explanatory power should make the model fit the data worse.  I've attached the data I am using, which contains no missing values, and here are the models I am running, and the results:

Any help is appreciated.  Thanks!

#note, models do not fully converge, but examination of estimates using verbose=T suggests they are resonable

mod.null = glmer(res.lifesat.last5 ~ 1 + (1|hhidpn) + (1|hhid), data=data.nomiss, family=binomial(link="probit"))
mod1 = glmer(res.lifesat.last5 ~ networth2.gmc + (1|hhidpn) + (1|hhid), data=data.nomiss, family=binomial(link="probit"))
mod2 = glmer(res.lifesat.last5 ~ networth2.gmc + married + (1|hhidpn) + (1|hhid), data=data.nomiss, family=binomial(link="probit"))
mod3 = glmer(res.lifesat.last5 ~ networth2.gmc + married + depscore + selfhealth + (1|hhidpn) + (1|hhid), data=data.nomiss, family=binomial(link="probit"))

#note that mod2 and mod3 have lower log-likelihoods than mod1, and mod3 has a lower LL than the null model
anova(mod.null, mod1, mod2, mod3)

Andrew Miles




From bbolker at gmail.com  Mon Jan 16 18:09:53 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 Jan 2012 17:09:53 +0000 (UTC)
Subject: [R-sig-ME] Log-likelihood and mixed models in glmer
References: <0015790A-4E33-4458-A7AE-15650CFC4473@gmail.com>
Message-ID: <loom.20120116T180506-44@post.gmane.org>

Andrew Miles <rstuff.miles at ...> writes:

>  Can someone point me to a reference that will explain why, when
> using mixed models (glmer and lmer) adding explanatory variables
> decreases the log likelihood?  This makes no sense to me, as adding
> explanatory power should make the model fit the data worse.  I've
                        ^^^^^
                        never?

> attached the data I am using, which contains no missing values, and
> here are the models I am running, and the results:

  The attachment didn't make it through to the mailing list.
Could you post it somewhere (or send it to me)?

> #note, models do not fully converge, but examination of estimates
>   using verbose=T suggests they are resonable

    The fact that they didn't converge (combined with your observation)
seems like a giant warning message to me ...  hard to say more without
seeing the data (see above)

> mod.null = glmer(res.lifesat.last5 ~ 1 + (1|hhidpn) + 
> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
> mod1 = glmer(res.lifesat.last5 ~ networth2.gmc + (1|hhidpn) + 
>  (1|hhid), data=data.nomiss, family=binomial(link="probit"))
> mod2 = glmer(res.lifesat.last5 ~ networth2.gmc + married + (1|hhidpn) +
>  (1|hhid), data=data.nomiss, family=binomial(link="probit"))
> mod3 = glmer(res.lifesat.last5 ~ networth2.gmc + married + depscore + 
> selfhealth + (1|hhidpn) +
> (1|hhid), data=data.nomiss, family=binomial(link="probit"))

  I have to add some text so the Gmane portal will be happy,
so let me just add that

  mod1 <- update(mod.null, . ~ . + networth2.gmc)
  mod2 <- update(mod1, . ~ . + married)
  mod3 <- update(mod2, . ~ . + depscore + selfhealth)

  would be a little bit clearer.

  Have you tried centering any continuous predictors?
 
> #note that mod2 and mod3 have lower log-likelihoods than mod1, 
>  and mod3 has a lower LL than the null model
> anova(mod.null, mod1, mod2, mod3)

   Do you get the same results from just using logLik() ?  Perhaps
anova() is scrambling things up?



From biowahl at gmail.com  Mon Jan 16 21:14:56 2012
From: biowahl at gmail.com (Colin Wahl)
Date: Mon, 16 Jan 2012 12:14:56 -0800
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <4F1404A9.7010107@ed.ac.uk>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
	<4F1404A9.7010107@ed.ac.uk>
Message-ID: <CACu_zZnXjrG-8Ld-dij4J3Y22d=BkBC_nP8L0cgj+OEGNtVBGQ@mail.gmail.com>

Good. This is the same conclusion I've made with a boxplot/graph of
the EPT data. The pattern is very clear. However, if not using p
values, how do you conclude that the differences are "significant?"
The patterns are less clear with other variables.

For example, nutrients, are clearly higher in cultivated streams, but
doing mcmc sampling and using HPD intervals to calculate 95%
confidence intervals results in huge conf. intervals. I've discussed
this with Thierry on this list before, where he asserted that with an
n of 24, the model lacks the power to find significance. However, a
child could look at the graph and tell you that nutrients are way
higher in cultivated streams. Also, the variance/st. deviation is zero
for the random stream variable. Does that mean it should be excluded?
Here are the results of the Nitrate/nitrite model, where nitrates are
higher in non-forested reaches in cultivated streams:

Linear mixed model fit by REML
Formula: LN ~ wsh * rip + (1 | stream)
   Data: all24
   AIC   BIC logLik deviance REMLdev
 43.89 55.24 -11.94    14.12   23.89
Random effects:
 Groups   Name        Variance Std.Dev.
 stream   (Intercept) 0.00000  0.00000
 Residual             0.16589  0.40729
Number of obs: 23, groups: stream, 12

Fixed effects:
            Estimate Std. Error t value
(Intercept)   0.5726     0.2351   2.435
wshD         -0.1040     0.3326  -0.313
wshF         -0.2562     0.3326  -0.770
wshG         -0.2758     0.3718  -0.742
ripN          0.8442     0.3326   2.538
wshD:ripN    -0.6730     0.4703  -1.431
wshF:ripN    -0.7653     0.4554  -1.681
wshG:ripN    -1.1080     0.5258  -2.107

Correlation of Fixed Effects:
          (Intr) wshD   wshF   wshG   ripN   wshD:N wshF:N
wshD      -0.707
wshF      -0.707  0.500
wshG      -0.632  0.447  0.447
ripN      -0.707  0.500  0.500  0.447
wshD:ripN  0.500 -0.707 -0.354 -0.316 -0.707
wshF:ripN  0.516 -0.365 -0.730 -0.327 -0.730  0.516
wshG:ripN  0.447 -0.316 -0.316 -0.707 -0.632  0.447  0.462

On Mon, Jan 16, 2012 at 3:06 AM, i white <i.m.s.white at ed.ac.uk> wrote:
> Colin,
>
> A simple graph of means for your eight combinations of 4 watershed types and
> two riparian types shows there are significant differences between watershed
> types c, d and f, and that for those types of watershed, riparian type makes
> no difference to the response. For watershed g, response is similar to
> watershed f for forested streams, but significantly lower at non-forested
> streams (if I have interpreted your factor labels correctly). These
> conclusions are based on inspection of a very simple graph with say a white
> dot for forested stream, black dot for unforested stream, and different
> locations along x axis for the 4 watershed types. Somewhere on the graph
> there needs to be a bar whose length represents a rough estimate of the
> average standard error of a mean (or difference between two means). Note
> that neither p-values nor multiple comparisons have been mentioned.
>
> Colin Wahl wrote:
>>
>> I will try to make this concise.
>>
>> Background: I am testing the effects of land use and forested riparian
>> buffers on stream invertebrates and in-stream variables. There are 4
>> watershed types (defined by 4 types of land use) and two riparian
>> types (forested and non). Percent EPT (relative abundance) was my main
>> response variable. I also measured a variety of in-stream variables
>> like temperature, nutrients, and toxicity. There are 72 observations
>> for invertebrates, and 24 for in-stream variables.
>>
>> I am curious of how acceptable p values are from pairwise comparisons
>> using glht() from the multcomp package
>>
>> I used glmer with a binomial error structure and an observation-level
>> random effect (to account for overdispersion), to model invertebrates:
>>
>> modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs),
>> data=ept, family=binomial(link="logit"))
>>
>> ? AIC ? BIC logLik deviance
>> ?284.4 309.5 -131.2 ? ?262.4
>> Random effects:
>> ?Groups ? ? Name ? ? ? ?Variance Std.Dev.
>> ?obs ? ? ? ?(Intercept) 0.30186 ?0.54942
>> ?stream:rip (Intercept) 0.40229 ?0.63427
>> ?stream ? ? (Intercept) 0.12788 ?0.35760
>> Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12
>>
>> Fixed effects:
>> ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ? -4.2906 ? ? 0.4935 ? -8.694 ?< 2e-16 ***
>> wshd ? ? ? ? ? -2.0557 ? ? 0.7601 ?-2.705 0.00684 **
>> wshf ? ? ? ? ? ?3.3575 ? ? 0.6339 ? 5.297 ?1.18e-07 ***
>> wshg ? ? ? ? ? 3.3923 ? ? 0.7486 ? ?4.531 ?5.86e-06 ***
>> ripN ? ? ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?0.82165
>> wshd:ripN ? ? 0.3708 ? ? 0.9682 ? 0.383 ?0.70170
>> wshf:ripN ? ?-0.8665 ? ? 0.8087 ? -1.071 ?0.28400
>> wshg:ripN ? ?-3.1530 ? ? 0.9601 ?-3.284 ?0.00102 **
>> ---
>>
>> Correlation of Fixed Effects:
>> ? ? ? ? ? ? ? ? (Intr) ?wshd ? wshf ? wshg ? ripN ? wshd:N wshf:N
>> wshd ? ? ? ?-0.649
>> wshf ? ? ? ?-0.779 ?0.505
>> wshg ? ? ? ?-0.659 ?0.428 ?0.513
>> ripN ? ? ? ? -0.644 ?0.418 ?0.501 ?0.424
>> wshd:ripN ?0.421 -0.672 -0.327 -0.277 -0.653
>> wshf:ripN ?0.503 -0.327 -0.638 -0.332 -0.782 ?0.511
>> wshg:ripN ?0.424 -0.275 -0.330 -0.632 -0.659 ?0.430 ?0.515
>>
>>
>> I then used this model to do Tukey's HSD contrasts between watershed
>> types:
>>
>> summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))
>> Linear Hypotheses:
>>
>> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> d - c == 0 -2.05573 ? ?0.76010 ?-2.705 ? 0.0341 *
>> f - c == 0 ?3.35753 ? ?0.63386 ? 5.297 ? <0.001 ***
>> g - c == 0 ?3.39231 ? ?0.74862 ? 4.531 ? <0.001 ***
>> f - d == 0 ?5.41326 ? ?0.70176 ? 7.714 ? <0.001 ***
>> g - d == 0 ?5.44804 ? ?0.80692 ? 6.752 ? <0.001 ***
>> g - f == 0 ?0.03479 ? ?0.68931 ? 0.050 ? 1.0000
>>
>> and riparian types:
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate
>> Std. Error z value Pr(>|z|)
>> C: Forested vs. Non-Forested == 0 ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225
>> ?0.99999
>> D: Forested vs. Non-Forested == 0 ? ? ? ? 0.5134 ? ? 0.7332 ? 0.700
>> ?0.98659
>> F: Forested vs. Non-Forested == 0 ? ? ? ?-0.7239 ? ? 0.5042 ?-1.436
>> ?0.69625
>> G: Forested vs. Non-Forested == 0 ? ? ? ?-3.0105 ? ? 0.7225 ?-4.167 ?<
>> 0.001 ***
>>
>> Are these p values accurate? Or is that a personal judgement I have to
>> make based on the clarity of the patterns they reflect?
>>
>> I've shown these results in my figures and explained them in my
>> results. I've basically explained that though these p values
>> reasonably reflect patterns in my data, effects sizes, and variances,
>> that they are inexact and potentially anti-conservative due to the
>> issues with degrees of freedom in mixed models.
>>
>>> From what I understand from my research in the last year is that
>>
>> Douglas Bates and others advocate something of a paradigm shift away
>> from the petagogically reinforced reliance on cryptic p values toward
>> more in depth discussions of effects sizes and variances. The use of
>> MCMC sampling and HPD intervals are suggested, but these are not
>> available for generalized models.
>>
>> I am interested in publishing these results as an ecologist, not a
>> statistician (pardon the somewhat artificial distinction), and, I am
>> very interested in what kind of a discussion the statisticians and
>> ecologists of the r-sig-mixed-models mailing list would like to see as
>> potential reviewers.
>>
>> Thank you,
>>
>> Colin Wahl
>>
>> M.S. candidate,
>> Dept. of Biology
>> Western Washington University
>> Bellingham, WA
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>



From biowahl at gmail.com  Mon Jan 16 21:54:48 2012
From: biowahl at gmail.com (Colin Wahl)
Date: Mon, 16 Jan 2012 12:54:48 -0800
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <AA818EAD2576BC488B4F623941DA74275732B97D@inbomail.inbo.be>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74275732B97D@inbomail.inbo.be>
Message-ID: <CACu_zZnP-pjY9N733ZkqGz9k9OPbxtY5e7LfpNYeGg-JkQqnnw@mail.gmail.com>

Thierry,
Thank you for the suggestion. I think I understand, though creating
user defined contrasts will be difficult.

I create a combined variable:
wshrip <-c bind(wsh, rip)

Resulting in a new model
modelEPT<-glmer(EPT ~ wshrip + (1|stream) + (1|stream:rip) + (1|obs),
data=ept, family=binomial(link="logit"))

The user defined contrasts I tried previously were:
wsh <- rbind("C vs. D" = c(1,0,0,0,0,0,0,0),
            "C vs. F" = c(0,1,0,0,0,0,0,0),
            "C vs. G" = c(0,0,1,0,0,0,0,0),
            "D vs. F" = c(-1,1,0,0,0,0,0,0),
            "D vs. G" = c(-1,0,1,0,0,0,0,1),
            "F vs. G" = c(0,-1,1,0,0,0,0,0))

This did not give me reasonable results, prompting me to use built-in
contrasts:

summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))

For riparian contrasts I used:
rip <- rbind("C: Forested vs. Non-Forested" = c(0,0,0,0,1,0,0,0),
            "D: Forested vs. Non-Forested" = c(0,0,0,0,1,1,0,0),
            "F: Forested vs. Non-Forested" = c(0,0,0,0,1,0,1,0),
            "G: Forested vs. Non-Forested" = c(0,0,0,0,1,0,0,1))

I dont understand how these contrasts are defined, but based them on
contrasts on an almost identical design found here:
http://thebiobucket.blogspot.com/2011/06/glmm-with-custom-multiple-comparisons.html#more

Could you please explain how to use user-defined for the model with a
wshrip combined variable? I cant find a clear example of how to do
this. The parameter length is different from the original model now
that there is a combined variable, correct?

Thank you very much, I'd be lost in the dark without this mailing list.

Colin






On Mon, Jan 16, 2012 at 12:58 AM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> Dear Colin,
>
> I don't think your Tukey tests are very informative. Because you are testing main effects how have an interaction with another variable. So you are not testing the overall effect of a variable but the effect when all other variable are 0 (continuous) or at the reference level (factor).
>
> A better way of doing this could bet o create a new variable which is the interaction between wsh and rip and use that in your model instead of wsh * rip. Then you can use glht() with user defined contrasts so that the contrasts test what you want to test.
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Colin Wahl
> Verzonden: zondag 15 januari 2012 1:23
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Comparing results from glmer and glht
>
> I will try to make this concise.
>
> Background: I am testing the effects of land use and forested riparian buffers on stream invertebrates and in-stream variables. There are 4 watershed types (defined by 4 types of land use) and two riparian types (forested and non). Percent EPT (relative abundance) was my main response variable. I also measured a variety of in-stream variables like temperature, nutrients, and toxicity. There are 72 observations for invertebrates, and 24 for in-stream variables.
>
> I am curious of how acceptable p values are from pairwise comparisons using glht() from the multcomp package
>
> I used glmer with a binomial error structure and an observation-level random effect (to account for overdispersion), to model invertebrates:
>
> modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs), data=ept, family=binomial(link="logit"))
>
> ? AIC ? BIC logLik deviance
> ?284.4 309.5 -131.2 ? ?262.4
> Random effects:
> ?Groups ? ? Name ? ? ? ?Variance Std.Dev.
> ?obs ? ? ? ?(Intercept) 0.30186 ?0.54942
> ?stream:rip (Intercept) 0.40229 ?0.63427
> ?stream ? ? (Intercept) 0.12788 ?0.35760
> Number of obs: 72, groups: obs, 72; stream:rip, 24; stream, 12
>
> Fixed effects:
> ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? -4.2906 ? ? 0.4935 ? -8.694 ?< 2e-16 ***
> wshd ? ? ? ? ? -2.0557 ? ? 0.7601 ?-2.705 0.00684 **
> wshf ? ? ? ? ? ?3.3575 ? ? 0.6339 ? 5.297 ?1.18e-07 ***
> wshg ? ? ? ? ? 3.3923 ? ? 0.7486 ? ?4.531 ?5.86e-06 ***
> ripN ? ? ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?0.82165
> wshd:ripN ? ? 0.3708 ? ? 0.9682 ? 0.383 ?0.70170
> wshf:ripN ? ?-0.8665 ? ? 0.8087 ? -1.071 ?0.28400
> wshg:ripN ? ?-3.1530 ? ? 0.9601 ?-3.284 ?0.00102 **
> ---
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ? ? ? (Intr) ?wshd ? wshf ? wshg ? ripN ? wshd:N wshf:N
> wshd ? ? ? ?-0.649
> wshf ? ? ? ?-0.779 ?0.505
> wshg ? ? ? ?-0.659 ?0.428 ?0.513
> ripN ? ? ? ? -0.644 ?0.418 ?0.501 ?0.424
> wshd:ripN ?0.421 -0.672 -0.327 -0.277 -0.653 wshf:ripN ?0.503 -0.327 -0.638 -0.332 -0.782 ?0.511 wshg:ripN ?0.424 -0.275 -0.330 -0.632 -0.659 ?0.430 ?0.515
>
>
> I then used this model to do Tukey's HSD contrasts between watershed types:
>
> summary(glht(modelEPT, linfct=mcp(wsh="Tukey"))) Linear Hypotheses:
>
> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> d - c == 0 -2.05573 ? ?0.76010 ?-2.705 ? 0.0341 *
> f - c == 0 ?3.35753 ? ?0.63386 ? 5.297 ? <0.001 ***
> g - c == 0 ?3.39231 ? ?0.74862 ? 4.531 ? <0.001 ***
> f - d == 0 ?5.41326 ? ?0.70176 ? 7.714 ? <0.001 ***
> g - d == 0 ?5.44804 ? ?0.80692 ? 6.752 ? <0.001 ***
> g - f == 0 ?0.03479 ? ?0.68931 ? 0.050 ? 1.0000
>
> and riparian types:
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> C: Forested vs. Non-Forested == 0 ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?0.99999
> D: Forested vs. Non-Forested == 0 ? ? ? ? 0.5134 ? ? 0.7332 ? 0.700 ?0.98659
> F: Forested vs. Non-Forested == 0 ? ? ? ?-0.7239 ? ? 0.5042 ?-1.436 ?0.69625
> G: Forested vs. Non-Forested == 0 ? ? ? ?-3.0105 ? ? 0.7225 ?-4.167 ?< 0.001 ***
>
> Are these p values accurate? Or is that a personal judgement I have to make based on the clarity of the patterns they reflect?
>
> I've shown these results in my figures and explained them in my results. I've basically explained that though these p values reasonably reflect patterns in my data, effects sizes, and variances, that they are inexact and potentially anti-conservative due to the issues with degrees of freedom in mixed models.
>
> >From what I understand from my research in the last year is that
> Douglas Bates and others advocate something of a paradigm shift away from the petagogically reinforced reliance on cryptic p values toward more in depth discussions of effects sizes and variances. The use of MCMC sampling and HPD intervals are suggested, but these are not available for generalized models.
>
> I am interested in publishing these results as an ecologist, not a statistician (pardon the somewhat artificial distinction), and, I am very interested in what kind of a discussion the statisticians and ecologists of the r-sig-mixed-models mailing list would like to see as potential reviewers.
>
> Thank you,
>
> Colin Wahl
>
> M.S. candidate,
> Dept. of Biology
> Western Washington University
> Bellingham, WA
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From giaguarenzo at yahoo.it  Tue Jan 17 00:46:59 2012
From: giaguarenzo at yahoo.it (Lorenzo Quaglietta)
Date: Mon, 16 Jan 2012 23:46:59 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
	<loom.20120112T173419-47@post.gmane.org>
Message-ID: <loom.20120117T004350-179@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Isa Blasco <isa.blasco.costa at ...> writes:
> 
> > 
> > Hi,
> > I am using glmmADMB to fit a negative binomial model to my data. My
> > explanatory variable is an ordered factor with 10 levels and I also
> > included a random factor (numeric) and Zero inflation.
> > This is the code I used: m7 <- glmmadmb (abun~odist + (1|sl), data=apa,
> > zeroInflation=TRUE, family="nbinom")
> > 
> > When I run it I got this error:
> > Error in UseMethod("droplevels") :
> >   no applicable method for 'droplevels' applied to an object of class
> > "c('double', 'numeric')"
> > 
> > I do not know what the 'double' means but I checked the glmmADMB manual and
> > they use the same kind of variables in their example. Any guess on what it
> > is happening? How can I solve it?
> > I hope somebody knows!
> 
>   It means that it doesn't make sense to use a numeric variable as
> a grouping variable for a random factor (which is what you've done):
> if sl is a discrete numeric code that identifies groups of observations,
> then you should convert it to a factor.  If it's a continuous variable,
> then you need to go back and read/think some more about the meanings
> of random factors ...
> 
>   It also means that I made some changes to glmmADMB recently that
> got in the way of an informative error message (you should have
> received an error message that told you this).  I will try to 
> catch that error in a more informative way.
> 
>   Ben Bolker
> 
> 

Hi,

I'm having  a similar problem.

My model formula is:

glmmADMB1 <- glmmadmb(Fix ~ log_BIO_F * log_BIO_P + log_drs + fperp + log_pr +
log_la + (1 | ANIMALE) + (1 | ID) + (1 | Time), data=otters, zeroInflation=TRUE,
family="poisson").

and I got the following error message:

"Error in UseMethod("droplevels") : 
  no applicable method for 'droplevels' applied to an object of class
"c('integer', 'numeric')".

My random terms are not categorical nor fitted as factors. Covariates are
continous (the log_ ones) and a factor (fperp). Any clue about what can be the
problem would be very appreciated.

Many thanks in advance, best regards,

Lorenzo Quaglietta



From schmettow at web.de  Tue Jan 17 14:51:25 2012
From: schmettow at web.de (Martin Schmettow)
Date: Tue, 17 Jan 2012 14:51:25 +0100
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
Message-ID: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120117/c45f15a7/attachment-0002.pl>

From Thierry.ONKELINX at inbo.be  Tue Jan 17 15:28:00 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 17 Jan 2012 14:28:00 +0000
Subject: [R-sig-ME] Comparing results from glmer and glht
In-Reply-To: <CACu_zZnP-pjY9N733ZkqGz9k9OPbxtY5e7LfpNYeGg-JkQqnnw@mail.gmail.com>
References: <CACu_zZmJoiwhGk=bHiZPVqkDmZOpC82Cv=Ok8L65_jyZ9cow+w@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74275732B97D@inbomail.inbo.be>
	<CACu_zZnP-pjY9N733ZkqGz9k9OPbxtY5e7LfpNYeGg-JkQqnnw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275732D564@inbomail.inbo.be>

Hi Colin,

This is what I would do. The example is on a simple lm() but is similar to a mixed model.
I find it easier to define contrasts on models without the intercept.

set.seed(12345)
dataset <- expand.grid(wsh = c("C", "D", "F", "G"), rip = c("Forest", "Non-forest"), id = seq_len(10))
dataset$wshrip <- with(dataset, wsh:rip)
dataset$Y <- runif(4, min = -10, max = 10)[dataset$wsh] + runif(2, min = -2, max = 2)[dataset$rip] + runif(8, min = -1, max = 1)[dataset$wshrip] + rnorm(nrow(dataset))
model <- lm(Y ~ 0 + wshrip, data = dataset)
library(multcomp)
K <- rbind(
  c(1, 1, -1, -1, 0, 0, 0, 0),
  c(0, 0, 1, 1, 0, 0, -1, -1), 
  c(1, -1, 1, -1, 1, -1, 1, -1))
rownames(K) <- c("C - D = 0", "D - G = 0", "Forest - non-forest = 0")
summary(glht(model, K))

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Colin Wahl [mailto:biowahl at gmail.com] 
Verzonden: maandag 16 januari 2012 21:55
Aan: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Comparing results from glmer and glht

Thierry,
Thank you for the suggestion. I think I understand, though creating user defined contrasts will be difficult.

I create a combined variable:
wshrip <-c bind(wsh, rip)

Resulting in a new model
modelEPT<-glmer(EPT ~ wshrip + (1|stream) + (1|stream:rip) + (1|obs), data=ept, family=binomial(link="logit"))

The user defined contrasts I tried previously were:
wsh <- rbind("C vs. D" = c(1,0,0,0,0,0,0,0),
            "C vs. F" = c(0,1,0,0,0,0,0,0),
            "C vs. G" = c(0,0,1,0,0,0,0,0),
            "D vs. F" = c(-1,1,0,0,0,0,0,0),
            "D vs. G" = c(-1,0,1,0,0,0,0,1),
            "F vs. G" = c(0,-1,1,0,0,0,0,0))

This did not give me reasonable results, prompting me to use built-in
contrasts:

summary(glht(modelEPT, linfct=mcp(wsh="Tukey")))

For riparian contrasts I used:
rip <- rbind("C: Forested vs. Non-Forested" = c(0,0,0,0,1,0,0,0),
            "D: Forested vs. Non-Forested" = c(0,0,0,0,1,1,0,0),
            "F: Forested vs. Non-Forested" = c(0,0,0,0,1,0,1,0),
            "G: Forested vs. Non-Forested" = c(0,0,0,0,1,0,0,1))

I dont understand how these contrasts are defined, but based them on contrasts on an almost identical design found here:
http://thebiobucket.blogspot.com/2011/06/glmm-with-custom-multiple-comparisons.html#more

Could you please explain how to use user-defined for the model with a wshrip combined variable? I cant find a clear example of how to do this. The parameter length is different from the original model now that there is a combined variable, correct?

Thank you very much, I'd be lost in the dark without this mailing list.

Colin






On Mon, Jan 16, 2012 at 12:58 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> Dear Colin,
>
> I don't think your Tukey tests are very informative. Because you are testing main effects how have an interaction with another variable. So you are not testing the overall effect of a variable but the effect when all other variable are 0 (continuous) or at the reference level (factor).
>
> A better way of doing this could bet o create a new variable which is the interaction between wsh and rip and use that in your model instead of wsh * rip. Then you can use glht() with user defined contrasts so that the contrasts test what you want to test.
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Colin Wahl
> Verzonden: zondag 15 januari 2012 1:23
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Comparing results from glmer and glht
>
> I will try to make this concise.
>
> Background: I am testing the effects of land use and forested riparian buffers on stream invertebrates and in-stream variables. There are 4 watershed types (defined by 4 types of land use) and two riparian types (forested and non). Percent EPT (relative abundance) was my main response variable. I also measured a variety of in-stream variables like temperature, nutrients, and toxicity. There are 72 observations for invertebrates, and 24 for in-stream variables.
>
> I am curious of how acceptable p values are from pairwise comparisons 
> using glht() from the multcomp package
>
> I used glmer with a binomial error structure and an observation-level random effect (to account for overdispersion), to model invertebrates:
>
> modelEPT<-glmer(EPT ~ wsh*rip + (1|stream) + (1|stream:rip) + (1|obs), 
> data=ept, family=binomial(link="logit"))
>
> ? AIC ? BIC logLik deviance
> ?284.4 309.5 -131.2 ? ?262.4
> Random effects:
> ?Groups ? ? Name ? ? ? ?Variance Std.Dev.
> ?obs ? ? ? ?(Intercept) 0.30186 ?0.54942
> ?stream:rip (Intercept) 0.40229 ?0.63427
> ?stream ? ? (Intercept) 0.12788 ?0.35760 Number of obs: 72, groups: 
> obs, 72; stream:rip, 24; stream, 12
>
> Fixed effects:
> ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? -4.2906 ? ? 0.4935 ? -8.694 ?< 2e-16 *** wshd ? ? ? ? ? 
> -2.0557 ? ? 0.7601 ?-2.705 0.00684 ** wshf ? ? ? ? ? ?3.3575 ? ? 
> 0.6339 ? 5.297 ?1.18e-07 *** wshg ? ? ? ? ? 3.3923 ? ? 0.7486 ? ?4.531 ?
> 5.86e-06 *** ripN ? ? ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?0.82165 
> wshd:ripN ? ? 0.3708 ? ? 0.9682 ? 0.383 ?0.70170 wshf:ripN ? ?-0.8665 ? ? 
> 0.8087 ? -1.071 ?0.28400 wshg:ripN ? ?-3.1530 ? ? 0.9601 ?-3.284 ?
> 0.00102 **
> ---
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ? ? ? (Intr) ?wshd ? wshf ? wshg ? ripN ? wshd:N wshf:N wshd ? ? ? ?
> -0.649 wshf ? ? ? ?-0.779 ?0.505 wshg ? ? ? ?-0.659 ?0.428 ?0.513 ripN ? ? ? ? 
> -0.644 ?0.418 ?0.501 ?0.424 wshd:ripN ?0.421 -0.672 -0.327 -0.277 
> -0.653 wshf:ripN ?0.503 -0.327 -0.638 -0.332 -0.782 ?0.511 wshg:ripN ?
> 0.424 -0.275 -0.330 -0.632 -0.659 ?0.430 ?0.515
>
>
> I then used this model to do Tukey's HSD contrasts between watershed types:
>
> summary(glht(modelEPT, linfct=mcp(wsh="Tukey"))) Linear Hypotheses:
>
> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|) d - c == 0 
> -2.05573 ? ?0.76010 ?-2.705 ? 0.0341 * f - c == 0 ?3.35753 ? ?0.63386 ? 
> 5.297 ? <0.001 *** g - c == 0 ?3.39231 ? ?0.74862 ? 4.531 ? <0.001 *** 
> f - d == 0 ?5.41326 ? ?0.70176 ? 7.714 ? <0.001 *** g - d == 0 ?
> 5.44804 ? ?0.80692 ? 6.752 ? <0.001 *** g - f == 0 ?0.03479 ? ?0.68931 ? 
> 0.050 ? 1.0000
>
> and riparian types:
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. 
> Error z value Pr(>|z|)
> C: Forested vs. Non-Forested == 0 ? ? ? ? 0.1425 ? ? 0.6323 ? 0.225 ?
> 0.99999
> D: Forested vs. Non-Forested == 0 ? ? ? ? 0.5134 ? ? 0.7332 ? 0.700 ?
> 0.98659
> F: Forested vs. Non-Forested == 0 ? ? ? ?-0.7239 ? ? 0.5042 ?-1.436 ?
> 0.69625
> G: Forested vs. Non-Forested == 0 ? ? ? ?-3.0105 ? ? 0.7225 ?-4.167 ?< 
> 0.001 ***
>
> Are these p values accurate? Or is that a personal judgement I have to make based on the clarity of the patterns they reflect?
>
> I've shown these results in my figures and explained them in my results. I've basically explained that though these p values reasonably reflect patterns in my data, effects sizes, and variances, that they are inexact and potentially anti-conservative due to the issues with degrees of freedom in mixed models.
>
> >From what I understand from my research in the last year is that
> Douglas Bates and others advocate something of a paradigm shift away from the petagogically reinforced reliance on cryptic p values toward more in depth discussions of effects sizes and variances. The use of MCMC sampling and HPD intervals are suggested, but these are not available for generalized models.
>
> I am interested in publishing these results as an ecologist, not a statistician (pardon the somewhat artificial distinction), and, I am very interested in what kind of a discussion the statisticians and ecologists of the r-sig-mixed-models mailing list would like to see as potential reviewers.
>
> Thank you,
>
> Colin Wahl
>
> M.S. candidate,
> Dept. of Biology
> Western Washington University
> Bellingham, WA
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From 20736466 at student.uwa.edu.au  Tue Jan 17 05:04:37 2012
From: 20736466 at student.uwa.edu.au (Angela Eads)
Date: Tue, 17 Jan 2012 12:04:37 +0800
Subject: [R-sig-ME] Interpreting HPD intervals to determine confidence of
	variance components
Message-ID: <CALtYuRaSgPFeQp03v64GuTJOCMkoRSr9Uu_Oondk9wuUcQQb7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120117/92ce7131/attachment-0002.pl>

From rstuff.miles at gmail.com  Tue Jan 17 00:37:14 2012
From: rstuff.miles at gmail.com (Andrew Miles)
Date: Mon, 16 Jan 2012 18:37:14 -0500
Subject: [R-sig-ME] Log-likelihood and mixed models in glmer
In-Reply-To: <loom.20120116T180506-44@post.gmane.org>
References: <0015790A-4E33-4458-A7AE-15650CFC4473@gmail.com>
	<loom.20120116T180506-44@post.gmane.org>
Message-ID: <EB58422B-EB1E-49B5-BDC0-55FE7476EEBB@gmail.com>

Here's the data.  In answer to your questions:

1. Yes, I meant adding predictors should "never" make the model fit the data worse.
2. The variable networth2.gmc is grand-mean centered - actually, I divided the original variable by 100,000 and then centered it to reduce the variable range and make estimation (and interpretation) easier.  Married  is dichotomous, depscore ranges from 0-8, and selfhealth from 0-5.  I did not center the last two since their range is already quite limited.
3. I tried the logLik function, and it returns the same values as anova().

I'm not sure about the convergence problems.  Based on some of the comments I've read about lmer, a convergence problem doesn't mean the estimates aren't reasonable, they only mean the fitting function stalled out without meeting its internal criteria for what an optimal fit looks like (i.e., a clear maximum).  Hence I looked at the parameters estimated at each step, they look to be converging to a set of reasonable parameters, and so I assume the models are reliable.  But if I'm wrong, I'd love to know it, and to know why.

Thanks in advance for all your help!

Andrew Miles


On Jan 16, 2012, at 12:09 PM, Ben Bolker wrote:

> Andrew Miles <rstuff.miles at ...> writes:
> 
>> Can someone point me to a reference that will explain why, when
>> using mixed models (glmer and lmer) adding explanatory variables
>> decreases the log likelihood?  This makes no sense to me, as adding
>> explanatory power should make the model fit the data worse.  I've
>                        ^^^^^
>                        never?
> 
>> attached the data I am using, which contains no missing values, and
>> here are the models I am running, and the results:
> 
>  The attachment didn't make it through to the mailing list.
> Could you post it somewhere (or send it to me)?
> 
>> #note, models do not fully converge, but examination of estimates
>>  using verbose=T suggests they are resonable
> 
>    The fact that they didn't converge (combined with your observation)
> seems like a giant warning message to me ...  hard to say more without
> seeing the data (see above)
> 
>> mod.null = glmer(res.lifesat.last5 ~ 1 + (1|hhidpn) + 
>> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
>> mod1 = glmer(res.lifesat.last5 ~ networth2.gmc + (1|hhidpn) + 
>> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
>> mod2 = glmer(res.lifesat.last5 ~ networth2.gmc + married + (1|hhidpn) +
>> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
>> mod3 = glmer(res.lifesat.last5 ~ networth2.gmc + married + depscore + 
>> selfhealth + (1|hhidpn) +
>> (1|hhid), data=data.nomiss, family=binomial(link="probit"))
> 
>  I have to add some text so the Gmane portal will be happy,
> so let me just add that
> 
>  mod1 <- update(mod.null, . ~ . + networth2.gmc)
>  mod2 <- update(mod1, . ~ . + married)
>  mod3 <- update(mod2, . ~ . + depscore + selfhealth)
> 
>  would be a little bit clearer.
> 
>  Have you tried centering any continuous predictors?
> 
>> #note that mod2 and mod3 have lower log-likelihoods than mod1, 
>> and mod3 has a lower LL than the null model
>> anova(mod.null, mod1, mod2, mod3)
> 
>   Do you get the same results from just using logLik() ?  Perhaps
> anova() is scrambling things up?
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Tue Jan 17 17:38:49 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 17 Jan 2012 10:38:49 -0600
Subject: [R-sig-ME] Fwd: questions about mixed logit models with R
In-Reply-To: <CAO7JsnTBnkoONYVVPceW-Yh13s1-Kfi-ZnzQ_t5v_LOKcdqbwg@mail.gmail.com>
References: <1326812665.2197.YahooMailNeo@web36801.mail.mud.yahoo.com>
	<CAO7JsnTBnkoONYVVPceW-Yh13s1-Kfi-ZnzQ_t5v_LOKcdqbwg@mail.gmail.com>
Message-ID: <CAO7JsnT+HXzFqUjjX=uUt+HgvejURC_XDM8WNwfVkMw1Wd9hEg@mail.gmail.com>

Yet another occasion when I said I would cc: the list and forgot to.


---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Tue, Jan 17, 2012 at 10:38 AM
Subject: Re: questions about mixed logit models with R
To: Angel Tabullo <angeltabullo at yahoo.com>


I suggest that you send such a request to the
R-SIG-Mixed-Models at R-project.org mailing list, which I am copying on
this reply. ?There are several experts who read that list and may be
able to provide help more readily than I can.

On Tue, Jan 17, 2012 at 9:04 AM, Angel Tabullo <angeltabullo at yahoo.com> wrote:
> Dear professor Bates
>
> My name's Angel Tabullo, I'm a phd student and I'm currently working on
> neurolinguistics and experimental psychology. I'm trying to run a mixed
> effects model analysis on some behavioral data with R, but I'm quite new to
> this kind of statistics and I'm having trouble to interpret the results. I'm
> writing to you because I found your tutorial in the web and it was very
> helpful. ?I also wrote to the R-lang mailing list. I will be very thankful
> for any advice you could give me in this matter.
>
> In my experiment, subjects were exposed to artificial languages with
> different word orders (two of them frequent among world languages: SOV, SVO
> and two of them infrequent: VSO, OSV). After training, subject had to
> classify new sentences as "correct" or incorrect, according to what they
> have learned. Sentences could either be correct, contain a syntax violation
> or a semantic violation (mismatch between a scene and the sentences
> describing it). Dependent variables were response latency and accuracy
> (right or wrong answer). I'm trying to analyze the accuracy (1 = right
> answer, 0 = wrong answer) data using a mixed logit model with "word order
> (OSV, SVO, SOV, VSO)" and "type of sentence" (correct, semantic violation,
> syntax violation) as fixed factors, and subject as a random factor. Word
> order is a between subjects variable, while type of sentences is a repeated
> measures factor.
>
> My questions are:
>
> 1) In order to contrast each level of each factor with all the others, as
> well as their interactions: should I ran different models changing the
> reference category? Does this mean I should run 4 x 3 = 12 models?
> 2) Would it be correct to compare interaction levels with post hoc Tukey
> contrasts (for instance: OSV - correct vs. OSV semantic violation, SVO
> correct vs. OSV correct and so on?).
> 3) How do I interpret a significant interaction? For instance:
>
> ModeloAngel = lmer(respuest=="1" ~ grupo * tipoF + (1|sujeto),
> data=DatosAngel, family="binomial")
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? ? ? ? ? ? 1.79585 ? ?0.19196 ? 9.356 ?< 2e-16 ***
> grupoOSV ? ? ? ? ? ? ? ?0.25816 ? ?0.26740 ? 0.965 ? 0.3343
> grupoSOV ? ? ? ? ? ? ? ?0.70875 ? ?0.29315 ? 2.418 ? 0.0156 *
> grupoSVO ? ? ? ? ? ? ? ?0.59607 ? ?0.26769 ? 2.227 ? 0.0260 *
> tipoFVsemanti ? ? ? ? ?-1.01756 ? ?0.14765 ?-6.892 5.51e-12 ***
> tipoFVsintact ? ? ? ? ?-1.46088 ? ?0.14566 -10.029 ?< 2e-16 ***
> grupoOSV:tipoFVsemanti -0.29214 ? ?0.20841 ?-1.402 ? 0.1610
> grupoSOV:tipoFVsemanti -0.39714 ? ?0.23265 ?-1.707 ? 0.0878 .
> grupoSVO:tipoFVsemanti ?0.03181 ? ?0.21459 ? 0.148 ? 0.8821
> grupoOSV:tipoFVsintact ?0.83284 ? ?0.21107 ? 3.946 7.95e-05 ***
> grupoSOV:tipoFVsintact ?0.42079 ? ?0.23408 ? 1.798 ? 0.0722 .
> grupoSVO:tipoFVsintact ?0.16667 ? ?0.21136 ? 0.789 ? 0.4304
>
> If the reference levels are VSO and "correct": does this mean that
> performance of OSV in syntax violations trials is better than that of VSO in
> syntax violation trials. Or does this mean that OSV - syntax violations
> performance is better than VSO - "correct" performance?
>
> Thank you again for your kind attention, I look forward to your answer.



From diegobilski at gmail.com  Tue Jan 17 20:35:11 2012
From: diegobilski at gmail.com (Diego Bilski)
Date: Tue, 17 Jan 2012 17:35:11 -0200
Subject: [R-sig-ME] convergence problems and model averaging
Message-ID: <CA+ViX4r_UuJvpyf5iB_RSzUswyZj5sG4RDdrar5GUUg7L7NF4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120117/cb6ddae8/attachment-0002.pl>

From David.Duffy at qimr.edu.au  Wed Jan 18 00:02:04 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 18 Jan 2012 09:02:04 +1000 (EST)
Subject: [R-sig-ME] convergence problems and model averaging
In-Reply-To: <CA+ViX4r_UuJvpyf5iB_RSzUswyZj5sG4RDdrar5GUUg7L7NF4g@mail.gmail.com>
References: <CA+ViX4r_UuJvpyf5iB_RSzUswyZj5sG4RDdrar5GUUg7L7NF4g@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1201180854020.14745@orpheus.qimr.edu.au>

On Tue, 17 Jan 2012, Diego Bilski wrote:

> Dear list,
>
> I have 1340 observations of animal survival (binomial), and 10 variables in
> my full model (with no interactions between variables). Using lmer() this
> full model didn't converged, then I removed 2 variables that were highly
> correlated (r=0.75 and 0.49) with two other, and this model presented no
> convergence problems.
>
> I standardized variables dividing by 2SD, in the "arm" package, and used
> the dredge() function of "MuMIn" to perform all combinations of variables,
> then selected those with deltaAIC <= 4. But from the 27 models with this
> deltaAIC, 19 presented false convergence warnings.

So, the 8 variable model works, but submodels of this are failing to 
converge?  If you have false convergence warnings, and you are interested 
in that model, you will need to crosscheck that solution using another 
package.  Since you just have a simple random intercept model, you can use
glmmML, glmmADMB, hglm...

Just 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From mcfarlas at uoguelph.ca  Wed Jan 18 00:14:26 2012
From: mcfarlas at uoguelph.ca (Eryn McFarlane)
Date: Tue, 17 Jan 2012 18:14:26 -0500
Subject: [R-sig-ME] BLUPs from MCMCglmm
Message-ID: <04AC4F09-CC5D-47BB-8FD0-8381BD56CAE3@uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120117/1e3ac997/attachment-0002.pl>

From David.Duffy at qimr.edu.au  Wed Jan 18 00:27:56 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 18 Jan 2012 09:27:56 +1000 (EST)
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
In-Reply-To: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de>
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de>
Message-ID: <Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>

On Tue, 17 Jan 2012, Martin Schmettow wrote:

> The problem I have is similar to the capture-recapture approach for
> estimating abundance. In my case the captured animals are design flaws of
> software.
>
> A given number of testers independently tries to find these flaws, which
> makes it a binomial problem. However, flaws that were never discovered
> during the study are not known to the experimenter.

> Furthermore this is a crossed mixed-effects 
> situation as
> discovery trials are repeated over testers and flaws.
>
> (1)    Does effectiveness of testers increases with years of experience?
> (2)    Are certain classes of flaws easier to find than others?
>
> A general finding of previous research is that testers as well as flaws are
> heterogeneous. Some flaws are less visible than others and testers differ in
> overall effectiveness. Hence, random effects are needed to account for
> overdispersion, right?

I may be corrected, but I think your setup is "actually" a Rasch type 
model with each flaw being an item.  Some flaws are just too difficult to 
see, ie the item is "too hard".  I presume, given your research questions, 
you are not actually interested in estimating the number of undetected 
flaws from each class, so a missing data type setup is not really needed.

http://www.jstatsoft.org/v20/a02/paper

is one paper from our esteemed leader ;)

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From jwiley.psych at gmail.com  Wed Jan 18 08:52:11 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 17 Jan 2012 23:52:11 -0800
Subject: [R-sig-ME] family for random coefficients in glmmADMB?
Message-ID: <CANz9Z_LMG_Dkt6HVxwORLUZkw+ZV2_t8qzFP9oOpswUd049vhA@mail.gmail.com>

Hi All,

Apologies if this is an obvious question.  I have been playing with
some random coefficient count models using the glmmADMB package.  I
can specify the family for the response (poisson or negative binomial,
in my case), but I am wondering what distribution is assumed for the
random parameters?  I know it is common to use the conjugate prior of
the response family (gamma for poisson or beta for negative binomial),
but others are theoretically possible, no?

Looking through the documentation did not give me any hints (not to
say they were not there, but at least did not register for me).

Thanks!

Josh


-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From bbolker at gmail.com  Wed Jan 18 15:43:11 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Jan 2012 14:43:11 +0000 (UTC)
Subject: [R-sig-ME] family for random coefficients in glmmADMB?
References: <CANz9Z_LMG_Dkt6HVxwORLUZkw+ZV2_t8qzFP9oOpswUd049vhA@mail.gmail.com>
Message-ID: <loom.20120118T153809-471@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> Apologies if this is an obvious question.  I have been playing with
> some random coefficient count models using the glmmADMB package.  I
> can specify the family for the response (poisson or negative binomial,
> in my case), but I am wondering what distribution is assumed for the
> random parameters?  I know it is common to use the conjugate prior of
> the response family (gamma for poisson or beta for negative binomial),
> but others are theoretically possible, no?

  The random variables are assumed to be normally distributed
on the linear predictor scale (as is almost always the case for GLMMs --
there is a little bit of literature on nonparametric estimation of
mixing/random-effects distributions, and some for different frailty
distributions in survival analysis, but the standard definition of
GLMMs is as I stated).  So in your case the assumed RE distribution
would be lognormal (unless you're using a nonstandard link for your
Poisson or NB models).

If you wanted badly enough to change this it might be hackable, but
I'm not sure how the math underlying the Laplace approximation (or
other approximations used) would hold up under this variation.  If
you really want to experiment with different RE distributions I think
I would suggest the Bayesian (BUGS/JAGS etc. route).



From bbolker at gmail.com  Wed Jan 18 15:51:36 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Jan 2012 14:51:36 +0000 (UTC)
Subject: [R-sig-ME] BLUPs from MCMCglmm
References: <04AC4F09-CC5D-47BB-8FD0-8381BD56CAE3@uoguelph.ca>
Message-ID: <loom.20120118T154325-109@post.gmane.org>

Eryn McFarlane <mcfarlas at ...> writes:

> 
> Dear list,
> 
> I was wondering if anyone knew of a way to estimate BLUPs
>  from an MCMCglmm model? I would just like to eyeball
> the individuals with high and low BLUPs for my trait to 
> see if there are other relationships that I can see
> (i.e. year effects, affect of territory). Does this make sense to try to do
from these models?


  I *think* you can just look at the $Liab component of the fit,
which as stated is the posterior distribution of the latent variables --
you need to set pl=TRUE.

  This should get you started (although HPDinterval() isn't
behaving sensibly in this case -- not quite sure why not)

 data(PlodiaPO)  
     model1<-MCMCglmm(PO~1, random=~FSfamily, data=PlodiaPO, 
    verbose=FALSE, pl=TRUE)
str(model1$Liab)
mm <- data.frame(m=colMeans(model1$Liab),HPDinterval(model1$Liab))
plot(mm[order(mm$m),"m")



From schmettow at web.de  Thu Jan 19 11:53:54 2012
From: schmettow at web.de (Martin Schmettow)
Date: Thu, 19 Jan 2012 11:53:54 +0100
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
In-Reply-To: <Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de>
	<Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
Message-ID: <000301ccd698$a32bee00$e983ca00$@web.de>

> > The problem I have is similar to the capture-recapture approach for
> > estimating abundance. In my case the captured animals are design flaws
> > of software.
> >
> > A given number of testers independently tries to find these flaws,
> > which makes it a binomial problem. However, flaws that were never
> > discovered during the study are not known to the experimenter.
> 
> I may be corrected, but I think your setup is "actually" a Rasch type
model
> with each flaw being an item.  Some flaws are just too difficult to see,
ie the
> item is "too hard".  I presume, given your research questions, you are not
> actually interested in estimating the number of undetected flaws from each
> class, so a missing data type setup is not really needed.
> 
> http://www.jstatsoft.org/v20/a02/paper
> 
> is one paper from our esteemed leader ;)

In one of my works on that topic I, indeed, viewed this as a Rasch type
model. And I well remember how excited I got when reading above paper,
because that would allow me to deal with predictors in a straight forward
way.

However, the number of undetected flaws is crucial by itself as it means to
go on testing. Capture-recapture models are a good way to estimate these,
but they don't allow for predictors. So, if I run a crossed mixed effects
logistic regression on my data, I have missing values.

So, while the above paper merges IRT models with (crossed) mixed effects
models (and that's great!), I would need sth. that merges the latter with
C-R models. C-R models do deal with sort of random effects: the
heterogeneous capturability of animals (denoted "h") and variability in
trials ("t"). So called Mht models could thus be viewed as crossed random
effects models, but: C-R models (afaik) don't deal with predictors and
mixed-effects models require at least missing-at-random, which is not the
case.

Any ideas?

CU, Martin



From j.hadfield at ed.ac.uk  Thu Jan 19 12:29:02 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 19 Jan 2012 11:29:02 +0000
Subject: [R-sig-ME] MCMCglmm output 1) on right scale? 2) produces huge
	deviance spread?
In-Reply-To: <CAEQ+J25=0+CaK8hUMcyOqvM88GTTvU+eOpkqEqKmg_Aa=Nmw2Q@mail.gmail.com>
References: <CAEQ+J25=0+CaK8hUMcyOqvM88GTTvU+eOpkqEqKmg_Aa=Nmw2Q@mail.gmail.com>
Message-ID: <DCD97396-3404-4568-88FD-6736C53375E9@ed.ac.uk>

Hi Ryan,

Sorry for not replying earlier - I've been away for two months. I'm  
having trouble understanding the issues but my gut feeling (especially  
for the second issue) is that they arise because of the error variance  
being set to one in MCMCglmm rather than zero as in glm.  For example,

id<-gl(100,2)  # 100 individuals observed twice
u<-rnorm(100)  # individual random effects ~ N(0,1)
lp<-u[id]+rnorm(200)  # linear predictor includes error ~ N(0,1)

y<-rbinom(200, 1, plogis(lp))  # response (with logit link)

glm(y~lp, family="binomial")$coef[2]

# regression on linear predictor should have coefficient of 1 on  
average as you suggest

glm(y~u[id], family="binomial")$coef[2]

# regression on linear predictor omitting noise has a coefficient < 1

Section 2.5 has ways of obtaining a rescaled linear predictor for the  
logit link, but the probit link may be a bit easier to work with in  
this respect as you can set the variance of the normal in the cdf  
calculation to 2 rather than 1.

Alternatively you could extract the latent variables (pl=TRUE) stored  
under Liab, which are the linear predictors including the noise term

Note sure this helps for the first problem though - perhaps you could  
provide the simulation code together with comments on what you expect  
to happen?

Cheers,

Jarrod







On 15 Jan 2012, at 19:35, Ryan King wrote:

> Hi, I have an MCMCglmm run predicting a binary outcome with a single
> fixed effect and two groups of random effects like so
>
> testprior4<-list( R=list(V=1, fix=1), G=list(G1=list(V=1, nu=1,
> alpha.mu=0, alpha.v=.5^2 ), G2=list(V=1, nu=1, alpha.mu=0, alpha.v=1 )
> ), B=list(mu=c(0,0), V=diag(2)*4 ) )
>
> testmcmc5b<-MCMCglmm(fixed=myy2~myx,random=~idv(myz)+idv(newz3)   ,
> family = "ordinal", prior= testprior4, data=mydata, nitt=6000,
> thin=10, burnin=5000 , pr=TRUE)
>
> I can provide the full simulation details, but hope that this is a
> general rather than specific problem.
>
> The first set of random effects have large effects, but the second set
> is just noise.
>
> I'm setting up a bridge sampler to get a bayes factor, which means I
> need to get a log-likelihood + log-prior for my proposal.
>
> I tested my log-likelihood calculation with  MCMC output and got
> atrociously spread out log-likelihoods (sd of 15-20). That seems like
> rather a lot on the log scale, and means that numerical problems are
> likely for the bridge sampler. GLM produces the same deviance up to a
> constant (regressing the outcome versus the linear predictor), so that
> function is fine. This problem is much smaller when using only the
> true predictors (sd = 6) .  The estimated variance component for the
> noise predictors never goes above .015, so that they cause this
> problem is surprising. Is there a handy explanation / work around?
>
> More troubling, a calibration exercise in the deviance calculation
> showed that the groups of linear predictors were not on the right
> scale.
> That is, multiplying through the two sets of random effects and design
> matrices to get batches of linear predictors, and running a glm of the
> binary outcome versus the linear predictors using a probit (or logit)
> link gets coefficients consistently not 1. The true random effects get
> a coefficient of about .65, and the noise random effects between .7
> and .4 depending on how I set them up. I don't think it's a bad mixing
> problem, because 1) I have gotten the same thing on independent
> chains, 2) effectiveSize() reports large effective samples 3) there is
> quite a bit of spread in the deviances.  This problem persists if I
> run with family="categorical".
>
> When I plug in the re-calibrated linear predictor, the sd of the
> log-likelihood goes down a lot, from 15 to 6 in the
> two-predictor-group case and from 6 to 3 when using only the true
> predictors. That's much better, but still quite a premium for having a
> group of noise predictors.
>
> Thanks,
> Ryan King
> Dept Health Studies
> University of Chicago
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Thu Jan 19 12:34:43 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 19 Jan 2012 11:34:43 +0000
Subject: [R-sig-ME] BLUPs from MCMCglmm
In-Reply-To: <loom.20120118T154325-109@post.gmane.org>
References: <04AC4F09-CC5D-47BB-8FD0-8381BD56CAE3@uoguelph.ca>
	<loom.20120118T154325-109@post.gmane.org>
Message-ID: <AF39FC02-9621-4928-9871-ED8343C91FFC@ed.ac.uk>

Hi,

The random effects are actually stored in Sol (solutions) and will be  
saved if you use the argument pr=TRUE.  The marginal posterior modes  
of the random effects should coincide with BLUPs if the variances are  
fixed a priori to the value used when obtaining BLUPs and the fixed  
effects are either fixed a priori or are given improper flat priors.  
However, in practice (i.e. when the variances are not fixed etc.) the  
correlation between BLUPs and marginal posterior modes is usually very  
very high.

Be aware that if you have many (m) random effects and you store many  
(n) iterations you end up with a lot (m*n) of numbers  to store.

Cheers,

Jarrod




On 18 Jan 2012, at 14:51, Ben Bolker wrote:

> Eryn McFarlane <mcfarlas at ...> writes:
>
>>
>> Dear list,
>>
>> I was wondering if anyone knew of a way to estimate BLUPs
>> from an MCMCglmm model? I would just like to eyeball
>> the individuals with high and low BLUPs for my trait to
>> see if there are other relationships that I can see
>> (i.e. year effects, affect of territory). Does this make sense to  
>> try to do
> from these models?
>
>
>  I *think* you can just look at the $Liab component of the fit,
> which as stated is the posterior distribution of the latent  
> variables --
> you need to set pl=TRUE.
>
>  This should get you started (although HPDinterval() isn't
> behaving sensibly in this case -- not quite sure why not)
>
> data(PlodiaPO)
>     model1<-MCMCglmm(PO~1, random=~FSfamily, data=PlodiaPO,
>    verbose=FALSE, pl=TRUE)
> str(model1$Liab)
> mm <- data.frame(m=colMeans(model1$Liab),HPDinterval(model1$Liab))
> plot(mm[order(mm$m),"m")
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Thu Jan 19 14:07:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 19 Jan 2012 13:07:22 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
	<loom.20120112T173419-47@post.gmane.org>
	<loom.20120117T004350-179@post.gmane.org>
Message-ID: <loom.20120119T140202-20@post.gmane.org>

Lorenzo Quaglietta <giaguarenzo at ...> writes:

> 
> Ben Bolker <bbolker at ...> writes:
> 
> >   It means that it doesn't make sense to use a numeric variable as
> > a grouping variable for a random factor (which is what you've done):
> > if sl is a discrete numeric code that identifies groups of observations,
> > then you should convert it to a factor.  If it's a continuous variable,
> > then you need to go back and read/think some more about the meanings
> > of random factors ...
> > 
> >   It also means that I made some changes to glmmADMB recently that
> > got in the way of an informative error message (you should have
> > received an error message that told you this).  I will try to 
> > catch that error in a more informative way.
> > 
> My model formula is:
> 
> glmmADMB1 <- glmmadmb(Fix ~ log_BIO_F * log_BIO_P + log_drs + fperp + log_pr +
> log_la + (1 | ANIMALE) + (1 | ID) + (1 | Time), 
> data=otters, zeroInflation=TRUE,
> family="poisson").
> 
> and I got the following error message:
> 
> "Error in UseMethod("droplevels") : 
>   no applicable method for 'droplevels' applied to an object of class
> "c('integer', 'numeric')".
> 
> My random terms are not categorical nor fitted as factors. Covariates are
> continous (the log_ ones) and a factor (fperp). Any clue about what can be the
> problem would be very appreciated.

  Can you be clearer about what you mean by "my random terms are not 
categorical nor fitted as factors"?  Grouping terms in glmmADMB
*must* be defined as factors (i.e. you must convert ANIMALE, ID,
Time to factors).
   I could have made glmmADMB make this conversion internally,
but I thought it was better to make this the user's responsibility,
so that if someone were doing something strange (like trying to
use a continuous variable as a grouping factor, on the right side
of the bar in (1|g)) it would be more immediately obvious.

  In general, it would be very helpful if you can include the
version of glmmADMB in any query, as the package is evolving very
quickly.  If you install the latest version (0.7.2.5) you should
still get an error, but the error will be (slightly) more
informative -- it will tell you that all grouping variables
must be factors.

  Ben Bolker



From jwiley.psych at gmail.com  Thu Jan 19 17:29:20 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 19 Jan 2012 08:29:20 -0800
Subject: [R-sig-ME] family for random coefficients in glmmADMB?
In-Reply-To: <loom.20120118T153809-471@post.gmane.org>
References: <CANz9Z_LMG_Dkt6HVxwORLUZkw+ZV2_t8qzFP9oOpswUd049vhA@mail.gmail.com>
	<loom.20120118T153809-471@post.gmane.org>
Message-ID: <CANz9Z_LYCnjhAo_=vq+x=1xvL28Xxi9faUOfq+2P=c5_vF5LKw@mail.gmail.com>

Hi Ben,

Thanks for the information.  If normal is the usual case, that is
fine.  Mostly I just wanted to know what was done---from reading
Agresti's book on Categorical Data Analysis, I got the sense that
different distributions were used, but I could have just misread.

Thanks again,

Josh

On Wed, Jan 18, 2012 at 6:43 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Joshua Wiley <jwiley.psych at ...> writes:
>
>> Apologies if this is an obvious question. ?I have been playing with
>> some random coefficient count models using the glmmADMB package. ?I
>> can specify the family for the response (poisson or negative binomial,
>> in my case), but I am wondering what distribution is assumed for the
>> random parameters? ?I know it is common to use the conjugate prior of
>> the response family (gamma for poisson or beta for negative binomial),
>> but others are theoretically possible, no?
>
> ?The random variables are assumed to be normally distributed
> on the linear predictor scale (as is almost always the case for GLMMs --
> there is a little bit of literature on nonparametric estimation of
> mixing/random-effects distributions, and some for different frailty
> distributions in survival analysis, but the standard definition of
> GLMMs is as I stated). ?So in your case the assumed RE distribution
> would be lognormal (unless you're using a nonstandard link for your
> Poisson or NB models).
>
> If you wanted badly enough to change this it might be hackable, but
> I'm not sure how the math underlying the Laplace approximation (or
> other approximations used) would hold up under this variation. ?If
> you really want to experiment with different RE distributions I think
> I would suggest the Bayesian (BUGS/JAGS etc. route).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From bbolker at gmail.com  Thu Jan 19 17:44:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 19 Jan 2012 16:44:16 +0000 (UTC)
Subject: [R-sig-ME] family for random coefficients in glmmADMB?
References: <CANz9Z_LMG_Dkt6HVxwORLUZkw+ZV2_t8qzFP9oOpswUd049vhA@mail.gmail.com>
	<loom.20120118T153809-471@post.gmane.org>
	<CANz9Z_LYCnjhAo_=vq+x=1xvL28Xxi9faUOfq+2P=c5_vF5LKw@mail.gmail.com>
Message-ID: <loom.20120119T173642-530@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> 
> Hi Ben,
> 
> Thanks for the information.  If normal is the usual case, that is
> fine.  Mostly I just wanted to know what was done---from reading
> Agresti's book on Categorical Data Analysis, I got the sense that
> different distributions were used, but I could have just misread.
> 

  I think it depends on whether you focus on ch 12 of Agresti (which
is about classical GLMMs) or ch 13 (which is about other kinds of mixture
models).  One possible confusion is that negative binomial models are
right at the edge of what one can define as GLMMs, because the NB
with unspecified overdispersion parameter (k) is not in the exponential
family -- NB models like those in MASS::glm.nb() use an outer loop
over possible values.  The NB mixed models that glmmADMB fits are
a bit of a hybrid -- one can think of them as models with Poisson
responses that use Gamma-distributed random effects at the
among-individual level, and log-normal distributed random effects
at all of the other levels.

   Ben

> 
> On Wed, Jan 18, 2012 at 6:43 AM, Ben Bolker <bbolker <at> gmail.com> wrote:
> > Joshua Wiley <jwiley.psych at ...> writes:
> >
> >> Apologies if this is an obvious question. ?I have been playing with
> >> some random coefficient count models using the glmmADMB package. ?I
> >> can specify the family for the response (poisson or negative binomial,
> >> in my case), but I am wondering what distribution is assumed for the
> >> random parameters? ?I know it is common to use the conjugate prior of
> >> the response family (gamma for poisson or beta for negative binomial),
> >> but others are theoretically possible, no?
> >
> > ?The random variables are assumed to be normally distributed
> > on the linear predictor scale (as is almost always the case for GLMMs --
> > there is a little bit of literature on nonparametric estimation of
> > mixing/random-effects distributions, and some for different frailty
> > distributions in survival analysis, but the standard definition of
> > GLMMs is as I stated). ?So in your case the assumed RE distribution
> > would be lognormal (unless you're using a nonstandard link for your
> > Poisson or NB models).
> >
> > If you wanted badly enough to change this it might be hackable, but
> > I'm not sure how the math underlying the Laplace approximation (or
> > other approximations used) would hold up under this variation. ?If
> > you really want to experiment with different RE distributions I think
> > I would suggest the Bayesian (BUGS/JAGS etc. route).
> >
> > _______________________________________________
> > R-sig-mixed-models <at> r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From David.Duffy at qimr.edu.au  Fri Jan 20 00:42:19 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 20 Jan 2012 09:42:19 +1000
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de><Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
	<000301ccd698$a32bee00$e983ca00$@web.de>
Message-ID: <6F35A958A12B9149BD16E3C2F3B0AD0DB37864@SPHINX.adqimr.ad.lan>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120120/63f0d4b1/attachment-0002.pl>

From raptorbio at hotmail.com  Fri Jan 20 05:22:00 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Thu, 19 Jan 2012 23:22:00 -0500
Subject: [R-sig-ME] GLMM parameter interpretation
Message-ID: <BAY170-W226D02A52B38596C044A97A1870@phx.gbl>


All,

A quick question, and an easy one I expect.

Suppose the following generic overdispersed log-linear model:

Count ~ A + B + C + (1|level1) + (1|level2) + (1|obs)

A, B, and C are all factors.
A does not vary within level1 subjects.
B does not vary within level2 subjects.
C varies within level 1 and level 2 subjects.

Does the conditional nature of the GLMM and the lack of variation in A (within level 1 subjects) and B (within level 2 subjects) result in nonsensical or uninterpretable coefficients for these two covariates?

Thanks,

Adam Smith
Dept. Natural Resources Science
105 Coastal Institute in Kingston
University of Rhode Island
 		 	   		  


From Thierry.ONKELINX at inbo.be  Fri Jan 20 09:31:03 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 20 Jan 2012 08:31:03 +0000
Subject: [R-sig-ME] GLMM parameter interpretation
In-Reply-To: <BAY170-W226D02A52B38596C044A97A1870@phx.gbl>
References: <BAY170-W226D02A52B38596C044A97A1870@phx.gbl>
Message-ID: <AA818EAD2576BC488B4F623941DA74275732F45B@inbomail.inbo.be>

A quick answer: No

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Adam Smith
Verzonden: vrijdag 20 januari 2012 5:22
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] GLMM parameter interpretation


All,

A quick question, and an easy one I expect.

Suppose the following generic overdispersed log-linear model:

Count ~ A + B + C + (1|level1) + (1|level2) + (1|obs)

A, B, and C are all factors.
A does not vary within level1 subjects.
B does not vary within level2 subjects.
C varies within level 1 and level 2 subjects.

Does the conditional nature of the GLMM and the lack of variation in A (within level 1 subjects) and B (within level 2 subjects) result in nonsensical or uninterpretable coefficients for these two covariates?

Thanks,

Adam Smith
Dept. Natural Resources Science
105 Coastal Institute in Kingston
University of Rhode Island
 		 	   		  
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From giorgio.arcara at gmail.com  Fri Jan 20 11:53:37 2012
From: giorgio.arcara at gmail.com (Giorgio Arcara)
Date: Fri, 20 Jan 2012 11:53:37 +0100
Subject: [R-sig-ME] lme or lmer?
Message-ID: <43825DBA-F86F-4732-AFE1-4B139B572331@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120120/2ceb0486/attachment-0002.pl>

From Julia.Sommerfeld at utas.edu.au  Fri Jan 20 15:11:46 2012
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Fri, 20 Jan 2012 15:11:46 +0100
Subject: [R-sig-ME] Off the topic: Problem with ISOdatetime
Message-ID: <CAOCHjhSBrbpdf-r+OsUMMw_sizTM=JhR+hZnCM+EBpAq7-UC0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120120/31631e0d/attachment-0002.pl>

From Thierry.ONKELINX at inbo.be  Fri Jan 20 15:27:29 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 20 Jan 2012 14:27:29 +0000
Subject: [R-sig-ME] Off the topic: Problem with ISOdatetime
In-Reply-To: <CAOCHjhSBrbpdf-r+OsUMMw_sizTM=JhR+hZnCM+EBpAq7-UC0A@mail.gmail.com>
References: <CAOCHjhSBrbpdf-r+OsUMMw_sizTM=JhR+hZnCM+EBpAq7-UC0A@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275732F7EA@inbomail.inbo.be>

Dear Julia,

R-help is a better forum for this kind of questions.

Have a look at the timezones and daylight saving time. That might be the problem.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Julia Sommerfeld
Verzonden: vrijdag 20 januari 2012 15:12
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Off the topic: Problem with ISOdatetime

Dear list,

This question is probably off the topic, but in order to test my data with GLMM, I need to transform the DateTime of my GPS data from:

"666.1751" into yyyy/mm/dd hh:mm:ss

I have the following code:

d$Date <- ISOdatetime(2009, 1, 1, 0, 0, 0, tz = "GMT")+d$Date*(24*3600)

This gives me: 2010-10-29 04:12:09, which is wrong. It should be 2010-10-29
06:12:09

Another example:

418.3219 corresponds to: 2010-02-23 07:43:30, but it should be 2010-02-23 08:43:30.

Any ideas or suggestions, where I could find the answer, are very much appreciated.

Best regards,

Julia

PS. I've tried to find the answer in all sorts of R help forums and also in my R books - no luck so far. Maybe I'm missunderstanding the entire ISOdatetime function?



--
Julia Sommerfeld - PhD Candidate
Institute for Marine and Antarctic Studies University of Tasmania Private Bag 129, Hobart TAS 7001

Phone: +61 477 289 301
Email: julia.somma at gmx.de
Julia.Sommerfeld at utas.edu.au

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rense.nieuwenhuis at gmail.com  Fri Jan 20 15:35:41 2012
From: rense.nieuwenhuis at gmail.com (Rense Nieuwenhuis)
Date: Fri, 20 Jan 2012 15:35:41 +0100
Subject: [R-sig-ME] Sresid with lme4
Message-ID: <ACC83A31-75F9-4938-A1C1-7D94A5D0E815@gmail.com>

Dear All,

I was hoping anyone knows if it is possible to extract or calculate studentized residuals (sresid) for mixed effects models estimated with the lme4 package? 

Any help or suggestions would be greatly appreciated. 

With kind regards,
Rense


From d.rizopoulos at erasmusmc.nl  Fri Jan 20 15:45:37 2012
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Fri, 20 Jan 2012 15:45:37 +0100
Subject: [R-sig-ME] Sresid with lme4
In-Reply-To: <ACC83A31-75F9-4938-A1C1-7D94A5D0E815@gmail.com>
References: <ACC83A31-75F9-4938-A1C1-7D94A5D0E815@gmail.com>
Message-ID: <4F197E11.9050602@erasmusmc.nl>

Several types of residuals for linear mixed models are mentioned in the 
following article:

@Article{nobre.singer:07,
   author    = {Nobre, J. and Singer, J.},
   journal   = {Biometrical Journal},
   pages     = {863--875},
   title     = {Residuals analysis for linear mixed models},
   volume    = {6},
   year      = {2007}
}

Probably it would be feasible to calculate them by extracting the 
required components from an 'mer' object.

Best,
Dimitris


On 1/20/2012 3:35 PM, Rense Nieuwenhuis wrote:
> Dear All,
>
> I was hoping anyone knows if it is possible to extract or calculate studentized residuals (sresid) for mixed effects models estimated with the lme4 package?
>
> Any help or suggestions would be greatly appreciated.
>
> With kind regards,
> Rense
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web: http://www.erasmusmc.nl/biostatistiek/



From lborger at cebc.cnrs.fr  Fri Jan 20 16:08:17 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Fri, 20 Jan 2012 16:08:17 +0100
Subject: [R-sig-ME] Sresid with lme4
In-Reply-To: <4F197E11.9050602@erasmusmc.nl>
References: <ACC83A31-75F9-4938-A1C1-7D94A5D0E815@gmail.com>
	<4F197E11.9050602@erasmusmc.nl>
Message-ID: <4F198361.7060003@cebc.cnrs.fr>




Codes employed for the analysis of the example and the simulation
developed in R (function lmmresdidual ) and can be obtained directly
from the authors
 >Probably it would be feasible to calculate them by extracting the 
required components from an 'mer' object.

In case this is useful, the slides of a recent presentation on residual 
analysis for LMMs by Singer&Nobre are available online 
(http://www.ime.usp.br/~jmsinger/MAE0610/Mixedmodelresiduals.pdf 
<http://www.ime.usp.br/%7Ejmsinger/MAE0610/Mixedmodelresiduals.pdf>) and 
the authors state at the end:

"Codes employed for the analysis of the example and the simulation
developed in R (function lmmresdidual ) and can be obtained directly
from the authors"


Cheers,

Luca




* forthcoming conference "Ecology and Behaviour"
* April 2-6 2012 Chize (France)
* http://serl2012.org
---------------------------------------------------------------------
Luca Borger
Postdoctoral Research Fellow
Centre d'Etudes Biologiques de Chiz?
CNRS (UPR1934); INRA (USC1339)
79360 Beauvoir-sur-Niort, France

Tel: +33 (0)549 09 96 13
Fax: +33 (0)549 09 65 26
email: lborger at cebc.cnrs.fr
Web: http://cnrs.academia.edu/LucaBorger
Researcher ID: http://www.researcherid.com/rid/C-6003-2008
Google Scholar: http://scholar.google.com/citations?user=D5CTvNUAAAAJ
---------------------------------------------------------------------
# Newly published! Animal Migration: A synthesis (ch. 8):
# http://ukcatalogue.oup.com/product/9780199568994.do



Le 20/01/2012 15:45, Dimitris Rizopoulos a ?crit :
> Several types of residuals for linear mixed models are mentioned in 
> the following article:
>
> @Article{nobre.singer:07,
>   author    = {Nobre, J. and Singer, J.},
>   journal   = {Biometrical Journal},
>   pages     = {863--875},
>   title     = {Residuals analysis for linear mixed models},
>   volume    = {6},
>   year      = {2007}
> }
>
> Probably it would be feasible to calculate them by extracting the 
> required components from an 'mer' object.
>
> Best,
> Dimitris
>
>
> On 1/20/2012 3:35 PM, Rense Nieuwenhuis wrote:
>> Dear All,
>>
>> I was hoping anyone knows if it is possible to extract or calculate 
>> studentized residuals (sresid) for mixed effects models estimated 
>> with the lme4 package?
>>
>> Any help or suggestions would be greatly appreciated.
>>
>> With kind regards,
>> Rense
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From raptorbio at hotmail.com  Fri Jan 20 16:18:31 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Fri, 20 Jan 2012 10:18:31 -0500
Subject: [R-sig-ME] GLMM parameter interpretation
In-Reply-To: <AA818EAD2576BC488B4F623941DA74275732F45B@inbomail.inbo.be>
References: <BAY170-W226D02A52B38596C044A97A1870@phx.gbl>,
	<AA818EAD2576BC488B4F623941DA74275732F45B@inbomail.inbo.be>
Message-ID: <BAY170-W5E71DBF9459672E20E74BA1870@phx.gbl>


Thanks, although I should correct an omission in my description.? Factor A does not vary within level 1 OR level 2 subjects.? Does this change anything for that covariate?

Adam

----------------------------------------
> From: Thierry.ONKELINX at inbo.be
> To: raptorbio at hotmail.com; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] GLMM parameter interpretation
> Date: Fri, 20 Jan 2012 08:31:03 +0000
>
> A quick answer: No
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Adam Smith
> Verzonden: vrijdag 20 januari 2012 5:22
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] GLMM parameter interpretation
>
>
> All,
>
> A quick question, and an easy one I expect.
>
> Suppose the following generic overdispersed log-linear model:
>
> Count ~ A + B + C + (1|level1) + (1|level2) + (1|obs)
>
> A, B, and C are all factors.
> A does not vary within level1 subjects.
> B does not vary within level2 subjects.
> C varies within level 1 and level 2 subjects.
>
> Does the conditional nature of the GLMM and the lack of variation in A (within level 1 subjects) and B (within level 2 subjects) result in nonsensical or uninterpretable coefficients for these two covariates?
>
> Thanks,
>
> Adam Smith
> Dept. Natural Resources Science
> 105 Coastal Institute in Kingston
> University of Rhode Island
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  


From erikfrenzel at gmail.com  Fri Jan 20 17:29:08 2012
From: erikfrenzel at gmail.com (Erik Frenzel)
Date: Fri, 20 Jan 2012 08:29:08 -0800
Subject: [R-sig-ME]  GLMM parameter interpretation
Message-ID: <CANJAy045CYuHy60BLm92TFVKpUnTNRvpy-0H==Arb5i_mnkUOQ@mail.gmail.com>

Adam,
I had a similar question and found this post helpful:

http://r.789695.n4.nabble.com/lme4-and-Variable-level-detection-td881680.html

Erik

> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 19 Jan 2012 23:22:00 -0500
> From: Adam Smith <raptorbio at hotmail.com>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] GLMM parameter interpretation
> Message-ID: <BAY170-W226D02A52B38596C044A97A1870 at phx.gbl>
> Content-Type: text/plain; charset="iso-8859-1"
>
>
> All,
>
> A quick question, and an easy one I expect.
>
> Suppose the following generic overdispersed log-linear model:
>
> Count ~ A + B + C + (1|level1) + (1|level2) + (1|obs)
>
> A, B, and C are all factors.
> A does not vary within level1 subjects.
> B does not vary within level2 subjects.
> C varies within level 1 and level 2 subjects.
>
> Does the conditional nature of the GLMM and the lack of variation in A (within level 1 subjects) and B (within level 2 subjects) result in nonsensical or uninterpretable coefficients for these two covariates?
>
> Thanks,
>
> Adam Smith
> Dept. Natural Resources Science
> 105 Coastal Institute in Kingston
> University of Rhode Island



From slu at ccsr.uchicago.edu  Fri Jan 20 20:06:05 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Fri, 20 Jan 2012 13:06:05 -0600
Subject: [R-sig-ME] Confusion specifiying random effect interactions
Message-ID: <1327086365.3052.27.camel@localhost>

Hello, I'm interested in determining whether teachers are better at
teaching one subject than another. I have a data set of reading and math
value-added measures for students grouped by classroom. Here is a
portion of the dataset:

            vam grade  classroom Subject
9    0.246568321     4   2860A104    Math
10   0.282774796     4    3510108    Math
25   0.203518951     4   5180A111    Math
26   0.924048731     4   8000A201    Math
27   0.005249245     4   5140A213    Math
37   0.145352029     4   3430A205    Math
46   0.015531502     4   6100A202    Math
47   0.412358095     4   6370A111    Math
51   0.165086054     4   6950A103    Math
56   0.830843297     4   3040A200    Math
59   0.259168594     4   6610A202    Math
62   0.497570314     4   3360A203    Math
961  0.872717363     4   3240A207    Math


My aim is to get the within-classroom, between-subject correlation, and
the fixed effect for subject. I ran two models:

lme1 <- lmer(data=data.all,
     formula=vam ~ grade + Subject +  (Subject|classroom))
     
lme2 <- lmer(data=data.all,
     formula=vam ~ grade + Subject +  (0 + Subject|classroom))
     
lme1 gives these variance components:

Linear mixed model fit by REML 
Formula: vam ~ grade + Subject + (Subject | classroom) 
   Data: data.all 
   AIC   BIC logLik deviance REMLdev
 42844 42924 -21414    42787   42828
Random effects:
 Groups    Name        Variance  Std.Dev. Corr  
 classroom (Intercept) 0.0079163 0.088974       
           SubjectRead 0.0069161 0.083163 0.041 
 Residual              0.0721588 0.268624       
Number of obs: 161031, groups: classroom, 3786

If I'm interpreting this correctly, this gives the between-classroom
variance, and the between-subject variance, and the correlation between
the intercept and the subject effect. (The fixed effect for Subject is
insignificantly small.)

The second model gives this:
Linear mixed model fit by REML 
Formula: vam ~ grade + Subject + (0 + Subject | classroom) 
   Data: data.all 
   AIC   BIC logLik deviance REMLdev
 42844 42924 -21414    42787   42828
Random effects:
 Groups    Name        Variance  Std.Dev. Corr  
 classroom SubjectMath 0.0079163 0.088974       
           SubjectRead 0.0154327 0.124228 0.743 
 Residual              0.0721588 0.268624       
Number of obs: 161031, groups: classroom, 3786

This one gives the correlation between Reading and Math, but puts all
the between-classroom variance into the subject-classroom interaction.
I'm thinking that in order to make the correct inferences I should have
a combination of these two with a between-classroom variance component,
and a subject-by-classroom component, but I can't figure out how to do
it in one model. I would appreciate any help I can get.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.1.6-gentoo                
I'm always thrilled when people discover what
 lexical scoping really means.    -- Robert
 Gentleman       Statistical Computing 2003,
 Reisensburg (June 2003)



From bbolker at gmail.com  Sat Jan 21 16:54:00 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Jan 2012 15:54:00 +0000 (UTC)
Subject: [R-sig-ME] lme or lmer?
References: <43825DBA-F86F-4732-AFE1-4B139B572331@gmail.com>
Message-ID: <loom.20120121T041825-883@post.gmane.org>

Giorgio Arcara <giorgio.arcara at ...> writes:

> I would like to use mixed models in R to analyze EEG data, but I don't  
> know if it is more correct to use lme or lmer.
> My data have the following structure
> 
> Subject	Electrode	 Interval	Trial 	Condition	Ampl
> 1		Fp1		200-300		1	A		3.5
> 1		Fp1		200-300		2	B		4.2
> 1		Fp2		400-600		1	A		6.5
> 1		Fp2		400-600		2	B		3.3
> 2		Fp1		200-300		1	A		2.1
> 2		Fp1		200-300		2	B		-5.4
> 2		Fp2		400-600		1	A		-5.6
> 2		Fp2		400-600		2	B		-3.2

 [snip]

  In general if you *can* use either lme or lmer (i.e. the random effects are
not nested, there is no heteroscedasticity or correlation structure at the
level of residuals ...) then either is OK.  I generally recommend lme in 
these cases (with apologies to Doug Bates) because it is better documented,
although it's slower.

> For sake of simplicity, here I include only 2 Trials but in the real  
> dataset they are many more.
> In this hypothetical dataset Ampl is the depentent variable. Electrode  
> and Interval are two predictors. I expect that levels of Electrode  
> will be highly correlated as well the levels of Interval.

  ?? Meaning that most instances of FP1 have Interval 200-300, most
of Fp2 have 400-500, and there are few 'crossover' instances where you
have FP1 with 400-500 and FP2 with 200-300?  This will in general make
it hard to estimate to distinguish the two effects ... but presumably
you know that.

> My goal is to study if Condition influence Ampl and if interact with  
> Electrode variable and Interval Variable.
> 
> I would fit a model on these data with lmer with the following structure
> 
> mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject) 
> +(1+Interval|Subject))
> If I'm correct the corresponding lme model would be
> 
> mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition| 
> Subject, ~1+Interval|Subject))

  Why not (Electrode+Interval|Subject)?  That (a) avoids a duplicated intercept
term and (b) estimates correlations between the intercept, electrode, and
Interval RE.

> Any suggestion for covariance matrix specification in lme?

  Do you need one other than the default -- i.e. do you expect
any particular correlation structure?



From trea26 at gmail.com  Sat Jan 21 17:55:50 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sat, 21 Jan 2012 12:55:50 -0400
Subject: [R-sig-ME] lme or lmer?
In-Reply-To: <mailman.3.1327057203.19517.r-sig-mixed-models@r-project.org>
References: <mailman.3.1327057203.19517.r-sig-mixed-models@r-project.org>
Message-ID: <4F1AEE16.3090801@gmail.com>

Hey Giorgio!

I have one published paper in JoCN where we analyzed ERP data using 
LMER, another one is on the way, and a methods paper is almost finished 
and submitted to NeuroImage regarding the addition of by-item random 
intercepts and slopes to the model. I'm sending you a copy of the JoCN 
paper (proofs for now, it'll be officially out any time soon) and a copy 
of the almost finished NeuroImage paper. If others are interested, 
please let me know and I can send them to you (trea26 at gmail dot com).

So LMER-wise, adding (1+Electtrode|Subject), which you could simply 
write (Electrode|Subject) is correct, but fitting a model with such a 
random effect will take forever.

In NewmanTremblay2011 paper we collapsed Electrode into 9 ROIs: left 
anterior, midline anterior, right anterior, left central, midline 
central, right central, left posterior, midline posterior, and right 
posterior and use that new variable (ROI) instead of Electrode. Note 
that we are not averaging at all! The main reason for this is 
computation time: With 9 levels of ROI in the model as (ROI|Subject) it 
takes A LOT of time to fit, tried once with (Electrode|Subject) and 
would run for sooooo long, actually killed it after like two or three 
days. Even the model with ROI takes what seems to be forever.

Then, once fitted, you'll see with print(model) that in the random 
effects portion of the summary there's a table of correlations between 
levels of ROI, something like this from one of our models (incomplete):

Linear mixed model fit by REML
Formula: Ampl ~ rProficiency * Condition * ROI * Group + (Condition | 
  Subject) + (1 | Subject) + (ROI | Subject)
    Data: dat
      AIC     BIC  logLik deviance REMLdev
  1011929 1013147 -505843  1011340 1011685
Random effects:
  Groups   Name          Variance   Std.Dev. Corr
  Subject  (Intercept)   2.5852e-01 0.508447
           ConditionGood 1.4045e+00 1.185133 -0.681
  Subject  (Intercept)   1.8638e-04 0.013652
  Subject  (Intercept)   2.8105e+00 1.676449
           ROILcent      9.4985e-01 0.974604 -0.423
           ROILpost      3.2123e+00 1.792281 -0.644  0.833
           ROIMant       3.3728e-01 0.580755 -0.240  0.150  0.258
           ROIMcent      1.8586e+00 1.363301 -0.249  0.687  ...
           ROIMpost      2.8172e+00 1.678445 -0.577  0.746  ...
           ROIRant       7.5682e-01 0.869957 -0.421 -0.171  ...
           ROIRcent      1.4031e+00 1.184519 -0.840  0.531  ...
           ROIRpost      3.0983e+00 1.760201 -0.797  0.578  ...
  Residual               3.3207e+01 5.762530
Number of obs: 159374, groups: Subject, 44

I'm attaching a complete report (using Sweave) for your reference.

There's one other paper where they used lme with a corSpher function in 
Davidson2007 (attached here, see page 90). The problem i see with using 
lme is that you can't really add crossed by-item random effect, which 
you should as demonstrated in Tremblay2012. Basically, adding by-item 
random effects substantially decreases the amount of (partial) 
autocorrelation in the model residuals (i.e., better approximation of 
the assumption of independence of errors. Note that the data used in 
that paper is available on CRAN (data package LCFdata) and I can send 
you the .Rnw file that contains the R code used for data manipulation, 
analysis and plotting in Tremblay2012, so it's fully replicable. Note 
that for simplicity, analyses in Tremblay2012 are on a single electrode, 
and that I'm not comparing (ROI|Subject) in LMER to corSpher in LME. 
Would like to eventually look a variograms to see how well the two take 
care of spatial correlation and also compare them with a model that 
doesn't account for this correlation.

Note that, as I demonstrate in Tremblay2012, by-item random effect 
should be added if warranted (by Log-likelihood Ratio Test or other; I 
suspect it will always be).


Cheers,

Antoine


On 12-01-20 07:00 AM, r-sig-mixed-models-request at r-project.org wrote:
> ------------------------------
>
> Message: 3
> Date: Fri, 20 Jan 2012 11:53:37 +0100
> From: Giorgio Arcara<giorgio.arcara at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme or lmer?
> Message-ID:<43825DBA-F86F-4732-AFE1-4B139B572331 at gmail.com>
> Content-Type: text/plain
>
>
> I would like to use mixed models in R to analyze EEG data, but I don't
> know if it is more correct to use lme or lmer.
> My data have the following structure
>
>
> Subject	Electrode	 Interval		Trial 	Condition		Ampl
> 1		Fp1		200-300		1		A			3.5
> 1		Fp1		200-300		2		B			4.2
> 1		Fp2		400-600		1		A			6.5
> 1		Fp2		400-600		2		B			3.3
> 2		Fp1		200-300		1		A			2.1
> 2		Fp1		200-300		2		B			-5.4
> 2		Fp2		400-600		1		A			-5.6
> 2		Fp2		400-600		2		B			-3.2
> .
> .
> .
>
> For sake of simplicity, here I include only 2 Trials but in the real
> dataset they are many more.
> In this hypothetical dataset Ampl is the depentent variable. Electrode
> and Interval are two predictors. I expect that levels of Electrode
> will be highly correlated as well the levels of Interval.
> My goal is to study if Condition influence Ampl and if interact with
> Electrode variable and Interval Variable.
>
>
> I would fit a model on these data with lmer with the following structure
>
> mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject)
> +(1+Interval|Subject))
>
> If I'm correct the corresponding lme model would be
>
> mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition|
> Subject, ~1+Interval|Subject))
>
>
> So my questions are:
> Are these specification corrects?
> Should I use lmer or lme?
> Any suggestion for covariance matrix specification in lme?
>
> Thanks in advance!!!
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> ___________
>
> Giorgio Arcara
> Ph.D.
>
> Department of General Psychology, University of Padua
> Via Venezia 15, 35131 Padova - Italy
> e-mail: giorgio.arcara at unipd.it
> Phone:  +39 049 8276149
> http://lcnl.psy.unipd.it/people/arcara.htm
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 61, Issue 29
> **************************************************
>



From trea26 at gmail.com  Sat Jan 21 18:05:52 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sat, 21 Jan 2012 13:05:52 -0400
Subject: [R-sig-ME] lme or lmer?
Message-ID: <4F1AF070.5040209@gmail.com>

Hey Giorgio!

I have one published paper in JoCN where we analyzed ERP data using 
LMER, another one is on the way, and a methods paper is almost finished 
and submitted to NeuroImage regarding the addition of by-item random 
intercepts and slopes to the model. I'm sending you a copy of the JoCN 
paper (proofs for now, it'll be officially out any time soon) and a copy 
of the almost finished NeuroImage paper. If others are interested, 
please let me know and I can send them to you (trea26 at gmail dot com).

So LMER-wise, adding (1+Electtrode|Subject), which you could simply 
write (Electrode|Subject) is correct, but fitting a model with such a 
random effect will take forever.

In NewmanTremblay2011 paper we collapsed Electrode into 9 ROIs: left 
anterior, midline anterior, right anterior, left central, midline 
central, right central, left posterior, midline posterior, and right 
posterior and use that new variable (ROI) instead of Electrode. Note 
that we are not averaging at all! The main reason for this is 
computation time: With 9 levels of ROI in the model as (ROI|Subject) it 
takes A LOT of time to fit, tried once with (Electrode|Subject) and 
would run for sooooo long, actually killed it after like two or three 
days. Even the model with ROI takes what seems to be forever.

Then, once fitted, you'll see with print(model) that in the random 
effects portion of the summary there's a table of correlations between 
levels of ROI, something like this from one of our models (incomplete):

Linear mixed model fit by REML
Formula: Ampl ~ rProficiency * Condition * ROI * Group + (Condition | 
Subject) + (1 | Subject) + (ROI | Subject)
    Data: dat
      AIC     BIC  logLik deviance REMLdev
  1011929 1013147 -505843  1011340 1011685
Random effects:
  Groups   Name          Variance   Std.Dev. Corr
  Subject  (Intercept)   2.5852e-01 0.508447
           ConditionGood 1.4045e+00 1.185133 -0.681
  Subject  (Intercept)   1.8638e-04 0.013652
  Subject  (Intercept)   2.8105e+00 1.676449
           ROILcent      9.4985e-01 0.974604 -0.423
           ROILpost      3.2123e+00 1.792281 -0.644  0.833
           ROIMant       3.3728e-01 0.580755 -0.240  0.150  0.258
           ROIMcent      1.8586e+00 1.363301 -0.249  0.687  ...
           ROIMpost      2.8172e+00 1.678445 -0.577  0.746  ...
           ROIRant       7.5682e-01 0.869957 -0.421 -0.171  ...
           ROIRcent      1.4031e+00 1.184519 -0.840  0.531  ...
           ROIRpost      3.0983e+00 1.760201 -0.797  0.578  ...
  Residual               3.3207e+01 5.762530
Number of obs: 159374, groups: Subject, 44

I'm attaching a complete report (using Sweave) for your reference.

There's one other paper where they used lme with a corSpher function in 
Davidson2007 (attached here, see page 90). The problem i see with using 
lme is that you can't really add crossed by-item random effect, which 
you should as demonstrated in Tremblay2012. Basically, adding by-item 
random effects substantially decreases the amount of (partial) 
autocorrelation in the model residuals (i.e., better approximation of 
the assumption of independence of errors. Note that the data used in 
that paper is available on CRAN (data package LCFdata) and I can send 
you the .Rnw file that contains the R code used for data manipulation, 
analysis and plotting in Tremblay2012, so it's fully replicable. Note 
that for simplicity, analyses in Tremblay2012 are on a single electrode, 
and that I'm not comparing (ROI|Subject) in LMER to corSpher in LME. 
Would like to eventually look a variograms to see how well the two take 
care of spatial correlation and also compare them with a model that 
doesn't account for this correlation.

Note that, as I demonstrate in Tremblay2012, by-item random effect 
should be added if warranted (by Log-likelihood Ratio Test or other; I 
suspect it will always be).


Cheers,

Antoine


On 12-01-20 07:00 AM, r-sig-mixed-models-request at r-project.org wrote:
 > ------------------------------
 >
 > Message: 3
 > Date: Fri, 20 Jan 2012 11:53:37 +0100
 > From: Giorgio Arcara<giorgio.arcara at gmail.com>
 > To: r-sig-mixed-models at r-project.org
 > Subject: [R-sig-ME] lme or lmer?
 > Message-ID:<43825DBA-F86F-4732-AFE1-4B139B572331 at gmail.com>
 > Content-Type: text/plain
 >
 >
 > I would like to use mixed models in R to analyze EEG data, but I don't
 > know if it is more correct to use lme or lmer.
 > My data have the following structure
 >
 >
 > Subject    Electrode     Interval        Trial     Condition        Ampl
 > 1        Fp1        200-300        1        A            3.5
 > 1        Fp1        200-300        2        B            4.2
 > 1        Fp2        400-600        1        A            6.5
 > 1        Fp2        400-600        2        B            3.3
 > 2        Fp1        200-300        1        A            2.1
 > 2        Fp1        200-300        2        B            -5.4
 > 2        Fp2        400-600        1        A            -5.6
 > 2        Fp2        400-600        2        B            -3.2
 > .
 > .
 > .
 >
 > For sake of simplicity, here I include only 2 Trials but in the real
 > dataset they are many more.
 > In this hypothetical dataset Ampl is the depentent variable. Electrode
 > and Interval are two predictors. I expect that levels of Electrode
 > will be highly correlated as well the levels of Interval.
 > My goal is to study if Condition influence Ampl and if interact with
 > Electrode variable and Interval Variable.
 >
 >
 > I would fit a model on these data with lmer with the following structure
 >
 > mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject)
 > +(1+Interval|Subject))
 >
 > If I'm correct the corresponding lme model would be
 >
 > mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition|
 > Subject, ~1+Interval|Subject))
 >
 >
 > So my questions are:
 > Are these specification corrects?
 > Should I use lmer or lme?
 > Any suggestion for covariance matrix specification in lme?
 >
 > Thanks in advance!!!
 >
 >
 > ___________
 >
 > Giorgio Arcara
 > Ph.D.
 >
 > Department of General Psychology, University of Padua
 > Via Venezia 15, 35131 Padova - Italy
 > e-mail: giorgio.arcara at unipd.it
 > Phone:  +39 049 8276149
 > http://lcnl.psy.unipd.it/people/arcara.htm
 >
 >
 >     [[alternative HTML version deleted]]
 >
 >
 >
 > ------------------------------
 >
 > _______________________________________________
 > R-sig-mixed-models mailing list
 > R-sig-mixed-models at r-project.org
 > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 >
 >
 > End of R-sig-mixed-models Digest, Vol 61, Issue 29
 > **************************************************
 >



From c.ryan.king at gmail.com  Sat Jan 21 18:55:33 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Sat, 21 Jan 2012 11:55:33 -0600
Subject: [R-sig-ME] MCMCglmm output 1) on right scale? 2) produces huge
 deviance spread? (Jarrod Hadfield)
Message-ID: <CAEQ+J253wJKVTQNFaB5Y3itpvR+qG7EAFczEdrZrS1_L3R5AaA@mail.gmail.com>

For posterity / google: It turns out the key issues were
1) The R component specified in the model is not the latent
gaussian(0,1)  noise inherent in a probit regression, but in addition
to that quantity. Setting it to near zero results in the answers I
expected, but very poor mixing of the chain. Fixing it at some value,
and doing the deviance calculation with residual variance 1 +
mcmcoutput$VCV[,"units"] does what I want.

2) The mcmcoutput$Dev and $DIC are the deviance treating the R
component as a real piece of the model and not a computational device.
That is, there are effectively hundreds of additional parameters. If
you want the deviance treating R as a computational device, you have
to calculate it by hand as above.

3) I had a typo in my prior specification, G1=list(V=1, nu=1,
alpha.mu=0, alpha.v=number) does not trigger parameter expansion or an
error; it has to be alpha.V=number.

4) Near-singular variance components are possible in parameter
expanded models (ie a cauchy prior and data supporting the null G=0)
and lead to unstable calculations; the mixed model equation solver in
the block-gibbs update of random effects computes G^-1. There are
other formulations of the MME which don't require inverting G, but
they tend to be less sparse.

Ryan King



From dhocking at unh.edu  Sat Jan 21 21:44:13 2012
From: dhocking at unh.edu (Daniel Hocking)
Date: Sat, 21 Jan 2012 15:44:13 -0500
Subject: [R-sig-ME] Using Observations as Random Effect in GLMM?
Message-ID: <8362F277-4517-41B8-B1D8-14F9C35DAA37@unh.edu>

Hi everyone,

I am having trouble with overdispersion when trying to model count  
data using a GLMM. Beyond going to a negative binomial or Poisson- 
lognormal distribution, I have seen the suggestion (from Ben Bolker I  
believe) to include observation as a random effect. For example using  
the lme4 package my code would look something like this:

glmer(count ~ SoilT + SoilT2 + RH + rain24 + drought +
rain24*SoilT + drought*rain24 + (1 | plot) + (1 | obs), data = Data,
family = poisson)

When I try this I get a fitted vs. residual plot with large residuals  
at low fitted values funneling down to small residuals as the fitted  
values get larger. This indicates heterogeneity. I was wondering if  
that is expected for some reason with observation-level random effects  
or if this model just doesn't meet the assumptions of GLMM for my data?

Thanks,
Dan
------------------------------------------------------------------------------------
Daniel J. Hocking
122 James  Hall
Department of Natural Resources & the Environment
University of New Hampshire
Durham, NH 03824

dhocking at unh.edu
http://sites.google.com/site/danieljhocking/
http://quantitativeecology.blogspot.com/
http://richnessoflife.blogspot.com/

"Without data, you are just another person with an opinion."



From giaguarenzo at yahoo.it  Sun Jan 22 00:37:49 2012
From: giaguarenzo at yahoo.it (Lorenzo Quaglietta)
Date: Sat, 21 Jan 2012 23:37:49 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB: Error in UseMethod("droplevels")
References: <CAN27_exebMuydyzYc2OWr=Bn1aC9-oCWyRCAyEC5Oi4msTwLmA@mail.gmail.com>
	<loom.20120112T173419-47@post.gmane.org>
	<loom.20120117T004350-179@post.gmane.org>
	<loom.20120119T140202-20@post.gmane.org>
Message-ID: <loom.20120122T003109-499@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Lorenzo Quaglietta <giaguarenzo at ...> writes:
> 
> > 
> > Ben Bolker <bbolker at ...> writes:
> > 
> > >   It means that it doesn't make sense to use a numeric variable as
> > > a grouping variable for a random factor (which is what you've done):
> > > if sl is a discrete numeric code that identifies groups of observations,
> > > then you should convert it to a factor.  If it's a continuous variable,
> > > then you need to go back and read/think some more about the meanings
> > > of random factors ...
> > > 
> > >   It also means that I made some changes to glmmADMB recently that
> > > got in the way of an informative error message (you should have
> > > received an error message that told you this).  I will try to 
> > > catch that error in a more informative way.
> > > 
> > My model formula is:
> > 
> > glmmADMB1 <- glmmadmb(Fix ~ log_BIO_F * log_BIO_P + log_drs + fperp + 
log_pr +
> > log_la + (1 | ANIMALE) + (1 | ID) + (1 | Time), 
> > data=otters, zeroInflation=TRUE,
> > family="poisson").
> > 
> > and I got the following error message:
> > 
> > "Error in UseMethod("droplevels") : 
> >   no applicable method for 'droplevels' applied to an object of class
> > "c('integer', 'numeric')".
> > 
> > My random terms are not categorical nor fitted as factors. Covariates are
> > continous (the log_ ones) and a factor (fperp). Any clue about what can be 
the
> > problem would be very appreciated.
> 
>   Can you be clearer about what you mean by "my random terms are not 
> categorical nor fitted as factors"?  Grouping terms in glmmADMB
> *must* be defined as factors (i.e. you must convert ANIMALE, ID,
> Time to factors).
>    I could have made glmmADMB make this conversion internally,
> but I thought it was better to make this the user's responsibility,
> so that if someone were doing something strange (like trying to
> use a continuous variable as a grouping factor, on the right side
> of the bar in (1|g)) it would be more immediately obvious.
> 
>   In general, it would be very helpful if you can include the
> version of glmmADMB in any query, as the package is evolving very
> quickly.  If you install the latest version (0.7.2.5) you should
> still get an error, but the error will be (slightly) more
> informative -- it will tell you that all grouping variables
> must be factors.
> 
>   Ben Bolker

Thank you very much. I've defined the random terms as factors and that error 
did not appear anymore.
However, I've encountered another message of error, which I copy here below 
(there's a very long series of codes of which I've copied only the last part 
and below the error):

Newton raphson 1   f = 344.5193892398689 max g = 2.123148492572113e-07
Newton raphson 2   f = 344.5193892398687 max g = 4.356515148629114e-13
 inner maxg = 0.0007671776212085923  Inner second time = 
0.0007671776212085923  Inner f = 344.5055506201622
 f = 344.5055506201622 max g = 0.0007671776212085923
Newton raphson 1   f = 344.505550121035 max g = 9.045343487557034e-07
Newton raphson 2   f = 344.5055501210349 max g = 7.366329768387914e-12
Warning -- Hessian does not appear to be positive definite
Error in run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary = !
use_tmp_dir,  : 
  object "sys.result" not found
then: Warning messages:
1: running command 'C:\WINDOWS\system32\cmd.exe /c "C:/Programmi/R/R-
2.14.1/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500 -maxph 4 -
noinit -shess' had status 1 
2: In shell(cmd, invisible = TRUE) :
  '"C:/Programmi/R/R-2.14.1/library/glmmADMB/bin/windows32/glmmadmb.exe" -
maxfn 500 -maxph 4 -noinit -shess' execution failed with error code 1

I ignore what all this may means, so any help would be great.

glmmADMB version is 0.7.2.

Thanks in advance, best,

Lorenzo



From john.maindonald at anu.edu.au  Sun Jan 22 01:25:20 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 22 Jan 2012 11:25:20 +1100
Subject: [R-sig-ME] Using Observations as Random Effect in GLMM?
In-Reply-To: <8362F277-4517-41B8-B1D8-14F9C35DAA37@unh.edu>
References: <8362F277-4517-41B8-B1D8-14F9C35DAA37@unh.edu>
Message-ID: <1AB5EE71-B5CA-4C49-A492-F3FCB41AA9D6@anu.edu.au>

I've been looking recently at animal count data that I've modeled
as Poisson with an observation level random effect, and have
worried a bit about such issues.

The observation level random effects model and the over-dispersion 
model add variances on different scales -- for the observation level
random effects random effects model the added variance is 
proportional to the square of the Poisson mean, whereas for the
over-dispersion model it is proportional to the mean. (These 
comments assume small additional error; but they do delineate
the broad ballparks in which the two models operate.   The glmer() 
function is making its own very specific assumptions about the 
scale on which to add the additional normal error.

The models are thus pretty much equivalent only if the range of 
expected values is small.  It would be useful to have more flexibility,
at the observation level at least, in the modelling of the extra-Poisson
error.  Among the various packages that handle GLMMs, do any of
them offer such flexibility, maybe allowing e.g. a quasi-Poisson error? 

(Sure, there are issues about how legit quasi-Poisson errors are.  
I expect however someone will sometime work out how to give them 
full theoretical respectability, and they will duly be admitted to the part 
of the statistical pantheon allocated to those models that are thus 
theoretically respectable.)


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 22/01/2012, at 7:44 AM, Daniel Hocking wrote:

> Hi everyone,
> 
> I am having trouble with overdispersion when trying to model count data using a GLMM. Beyond going to a negative binomial or Poisson-lognormal distribution, I have seen the suggestion (from Ben Bolker I believe) to include observation as a random effect. For example using the lme4 package my code would look something like this:
> 
> glmer(count ~ SoilT + SoilT2 + RH + rain24 + drought +
> rain24*SoilT + drought*rain24 + (1 | plot) + (1 | obs), data = Data,
> family = poisson)
> 
> When I try this I get a fitted vs. residual plot with large residuals at low fitted values funneling down to small residuals as the fitted values get larger. This indicates heterogeneity. I was wondering if that is expected for some reason with observation-level random effects or if this model just doesn't meet the assumptions of GLMM for my data?
> 
> Thanks,
> Dan
> ------------------------------------------------------------------------------------
> Daniel J. Hocking
> 122 James  Hall
> Department of Natural Resources & the Environment
> University of New Hampshire
> Durham, NH 03824
> 
> dhocking at unh.edu
> http://sites.google.com/site/danieljhocking/
> http://quantitativeecology.blogspot.com/
> http://richnessoflife.blogspot.com/
> 
> "Without data, you are just another person with an opinion."
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Sun Jan 22 16:30:31 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Jan 2012 15:30:31 +0000 (UTC)
Subject: [R-sig-ME] Using Observations as Random Effect in GLMM?
References: <8362F277-4517-41B8-B1D8-14F9C35DAA37@unh.edu>
	<1AB5EE71-B5CA-4C49-A492-F3FCB41AA9D6@anu.edu.au>
Message-ID: <loom.20120122T162516-479@post.gmane.org>

John Maindonald <john.maindonald at ...> writes:

> 
> I've been looking recently at animal count data that I've modeled
> as Poisson with an observation level random effect, and have
> worried a bit about such issues.
> 
> The observation level random effects model and the over-dispersion 
> model add variances on different scales -- for the observation level
> random effects random effects model the added variance is 
> proportional to the square of the Poisson mean, whereas for the
> over-dispersion model it is proportional to the mean. (These 
> comments assume small additional error; but they do delineate
> the broad ballparks in which the two models operate.   The glmer() 
> function is making its own very specific assumptions about the 
> scale on which to add the additional normal error.
> 
> The models are thus pretty much equivalent only if the range of 
> expected values is small.  It would be useful to have more flexibility,
> at the observation level at least, in the modelling of the extra-Poisson
> error.  Among the various packages that handle GLMMs, do any of
> them offer such flexibility, maybe allowing e.g. a quasi-Poisson error? 

  Recent versions of the glmmADMB package offer two flavors of negative
binomial model, either with variance = mu*(1+mu/k) (the classic
'quadratic' (almost) parameterization, which Hardin and Hilbe call
NB2) or with variance = phi*mu (which Hardin and Hilbe call
NB1; I believe this is what you are calling "quasi-Poisson" above).
The variance-mean relationship of NB2 and of the lognormal-Poisson
model are the same, although the details do differ ...

> (Sure, there are issues about how legit quasi-Poisson errors are.  
> I expect however someone will sometime work out how to give them 
> full theoretical respectability, and they will duly be admitted to the part 
> of the statistical pantheon allocated to those models that are thus 
> theoretically respectable.)

  I haven't tried it yet, but my response to the original poster
would have been to try a well-behaved simulation and see whether
the same phenomenon occurred ...



From trea26 at gmail.com  Sun Jan 22 19:13:56 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sun, 22 Jan 2012 14:13:56 -0400
Subject: [R-sig-ME] lme or lmer?
In-Reply-To: <mailman.5087.1327178663.4521.r-sig-mixed-models@r-project.org>
References: <mailman.5087.1327178663.4521.r-sig-mixed-models@r-project.org>
Message-ID: <4F1C51E4.7030707@gmail.com>

Giorgio, another thing regarding the Interval variable that came to my 
attention after reading Ben Bolker's reply to your question.

Were you planning on adding Interval to your model specification? 
Because it *shouldn't* be in the model. From what I can see, you'd be 
performing an analysis on the 200-300 time window, then another one on 
the 400-600 time window, and so forth, and in each analysis you'd 
include all electrodes (which, as I mentioned in my reply, is probably 
best re-coded as ROI with 9 levels).

I'm assuming you chose these time windows because you were expecting to 
find amplitude differences between your two conditions with respect to 
ERPs found in these time windows (e.g., maybe a late N400 in the 400-600 
window?).

So, for *each* time window the model would look something like this 
(after recoding Electrode to ROI and your datya frame is named eeg):

m1 <- lmer(Ampl ~ Condition * ROI + (1|Subject) + (1|Item) + 
(ROI|Subject), data = eeg)

Would check model assumptions using e.g., function mcp.fnc from package 
LMERConvenienceFunctions.

mcp.fnc(m1, trim = 2.5)

Typically the qq plot top right isn't good and there are a lot of data 
points with undue influence (bottom right panel). But after removing 
outliers +/- 2.5 std. dev. below and above the m1 residuals mean (could 
use function romr.fnc from package LMERConvenienceFunctions) the plots 
look much, much better.

eeg<- romr.fnc(model = m1, data = eeg, trim = 2.5)$data

Typically 1.5% to 2.5% of the data is removed this way (the function 
tells you the percentage). Then refit the model:

m1 <- update(m1)

Then look at the model criticism plot:

mcp.fnc(m1, trim = 2.5)


In addition, you could start with a simple model with only (1|Subject) 
then fit a more complex model with (1|Subject) + (1|Item) then a more 
complex one with (1|Subject) + (1|Item) + (ROI|Subject) ... and test 
whether the inclusion of the random effects is warranted using a log 
likelihood ratio test (anova(m1,m2) ...). I'd bet that (1|Subject) + 
(1|Item) + (ROI|Subject) will be warranted, maybe also (Condition|Subject).

Sincerely,

Antoine Tremblay
NeuroCognitive Imaging Laboratory
Dalhousie university
Halifax, Canada

> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 21 Jan 2012 15:54:00 +0000 (UTC)
> From: Ben Bolker<bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme or lmer?
> Message-ID:<loom.20120121T041825-883 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
>
> Giorgio Arcara<giorgio.arcara at ...>  writes:
>
>> I would like to use mixed models in R to analyze EEG data, but I don't
>> know if it is more correct to use lme or lmer.
>> My data have the following structure
>>
>> Subject	Electrode	 Interval	Trial 	Condition	Ampl
>> 1		Fp1		200-300		1	A		3.5
>> 1		Fp1		200-300		2	B		4.2
>> 1		Fp2		400-600		1	A		6.5
>> 1		Fp2		400-600		2	B		3.3
>> 2		Fp1		200-300		1	A		2.1
>> 2		Fp1		200-300		2	B		-5.4
>> 2		Fp2		400-600		1	A		-5.6
>> 2		Fp2		400-600		2	B		-3.2
>
>   [snip]
>
>    In general if you *can* use either lme or lmer (i.e. the random effects are
> not nested, there is no heteroscedasticity or correlation structure at the
> level of residuals ...) then either is OK.  I generally recommend lme in
> these cases (with apologies to Doug Bates) because it is better documented,
> although it's slower.
>
>> For sake of simplicity, here I include only 2 Trials but in the real
>> dataset they are many more.
>> In this hypothetical dataset Ampl is the depentent variable. Electrode
>> and Interval are two predictors. I expect that levels of Electrode
>> will be highly correlated as well the levels of Interval.
>
>    ?? Meaning that most instances of FP1 have Interval 200-300, most
> of Fp2 have 400-500, and there are few 'crossover' instances where you
> have FP1 with 400-500 and FP2 with 200-300?  This will in general make
> it hard to estimate to distinguish the two effects ... but presumably
> you know that.
>
>> My goal is to study if Condition influence Ampl and if interact with
>> Electrode variable and Interval Variable.
>>
>> I would fit a model on these data with lmer with the following structure
>>
>> mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject)
>> +(1+Interval|Subject))
>> If I'm correct the corresponding lme model would be
>>
>> mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition|
>> Subject, ~1+Interval|Subject))
>
>    Why not (Electrode+Interval|Subject)?  That (a) avoids a duplicated intercept
> term and (b) estimates correlations between the intercept, electrode, and
> Interval RE.
>
>> Any suggestion for covariance matrix specification in lme?
>
>    Do you need one other than the default -- i.e. do you expect
> any particular correlation structure?
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 21 Jan 2012 12:55:50 -0400
> From: Antoine Tremblay<trea26 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Cc: r-sig-mixed-models-request at r-project.org
> Subject: Re: [R-sig-ME] lme or lmer?
> Message-ID:<4F1AEE16.3090801 at gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hey Giorgio!
>
> I have one published paper in JoCN where we analyzed ERP data using
> LMER, another one is on the way, and a methods paper is almost finished
> and submitted to NeuroImage regarding the addition of by-item random
> intercepts and slopes to the model. I'm sending you a copy of the JoCN
> paper (proofs for now, it'll be officially out any time soon) and a copy
> of the almost finished NeuroImage paper. If others are interested,
> please let me know and I can send them to you (trea26 at gmail dot com).
>
> So LMER-wise, adding (1+Electtrode|Subject), which you could simply
> write (Electrode|Subject) is correct, but fitting a model with such a
> random effect will take forever.
>
> In NewmanTremblay2011 paper we collapsed Electrode into 9 ROIs: left
> anterior, midline anterior, right anterior, left central, midline
> central, right central, left posterior, midline posterior, and right
> posterior and use that new variable (ROI) instead of Electrode. Note
> that we are not averaging at all! The main reason for this is
> computation time: With 9 levels of ROI in the model as (ROI|Subject) it
> takes A LOT of time to fit, tried once with (Electrode|Subject) and
> would run for sooooo long, actually killed it after like two or three
> days. Even the model with ROI takes what seems to be forever.
>
> Then, once fitted, you'll see with print(model) that in the random
> effects portion of the summary there's a table of correlations between
> levels of ROI, something like this from one of our models (incomplete):
>
> Linear mixed model fit by REML
> Formula: Ampl ~ rProficiency * Condition * ROI * Group + (Condition |
>    Subject) + (1 | Subject) + (ROI | Subject)
>      Data: dat
>        AIC     BIC  logLik deviance REMLdev
>    1011929 1013147 -505843  1011340 1011685
> Random effects:
>    Groups   Name          Variance   Std.Dev. Corr
>    Subject  (Intercept)   2.5852e-01 0.508447
>             ConditionGood 1.4045e+00 1.185133 -0.681
>    Subject  (Intercept)   1.8638e-04 0.013652
>    Subject  (Intercept)   2.8105e+00 1.676449
>             ROILcent      9.4985e-01 0.974604 -0.423
>             ROILpost      3.2123e+00 1.792281 -0.644  0.833
>             ROIMant       3.3728e-01 0.580755 -0.240  0.150  0.258
>             ROIMcent      1.8586e+00 1.363301 -0.249  0.687  ...
>             ROIMpost      2.8172e+00 1.678445 -0.577  0.746  ...
>             ROIRant       7.5682e-01 0.869957 -0.421 -0.171  ...
>             ROIRcent      1.4031e+00 1.184519 -0.840  0.531  ...
>             ROIRpost      3.0983e+00 1.760201 -0.797  0.578  ...
>    Residual               3.3207e+01 5.762530
> Number of obs: 159374, groups: Subject, 44
>
> I'm attaching a complete report (using Sweave) for your reference.
>
> There's one other paper where they used lme with a corSpher function in
> Davidson2007 (attached here, see page 90). The problem i see with using
> lme is that you can't really add crossed by-item random effect, which
> you should as demonstrated in Tremblay2012. Basically, adding by-item
> random effects substantially decreases the amount of (partial)
> autocorrelation in the model residuals (i.e., better approximation of
> the assumption of independence of errors. Note that the data used in
> that paper is available on CRAN (data package LCFdata) and I can send
> you the .Rnw file that contains the R code used for data manipulation,
> analysis and plotting in Tremblay2012, so it's fully replicable. Note
> that for simplicity, analyses in Tremblay2012 are on a single electrode,
> and that I'm not comparing (ROI|Subject) in LMER to corSpher in LME.
> Would like to eventually look a variograms to see how well the two take
> care of spatial correlation and also compare them with a model that
> doesn't account for this correlation.
>
> Note that, as I demonstrate in Tremblay2012, by-item random effect
> should be added if warranted (by Log-likelihood Ratio Test or other; I
> suspect it will always be).
>
>
> Cheers,
>
> Antoine
>
>
> End of R-sig-mixed-models Digest, Vol 61, Issue 31
> **************************************************
>



From eef201 at exeter.ac.uk  Sun Jan 22 23:38:35 2012
From: eef201 at exeter.ac.uk (Flores-de-Gracia, Eric)
Date: Sun, 22 Jan 2012 22:38:35 +0000
Subject: [R-sig-ME] Using lmer in survival
Message-ID: <8395A297256F694B9308A0446D3CF6A520435A5128@EXCHMBS03.isad.isadroot.ex.ac.uk>

Hi there

I?m trying to fit a lmer model to a data on survival (1=death, 0=alive) of artificial frog models deployed in the field. At this early point want to know if "size" has an general effect on survival

I have found difficult to understand the model goodness of fit using the model simplification. Using a randomized block design, my response variable is "surv" and my predictor is "size".

model1<-lmer(surv~size+(1|block/size),family="binomial")
summary(model1)

model2<-update(model1,~.-size)

anova(model1,model2)

But the plot of residuals against the predicted values looks quite strange, perhaps due to the huge amount of "0" in the dataset! (562 ceros vs 35 ones).

Is there any other error structure that can be implemented to deal with the huge amount of ceros?

Any suggestion welcome, thanks.
 
Eric Flores De Gracia
School of Biosciences
University of Exeter, Cornwall Campus
Penryn, Cornwall
TR10 9EZ
United Kingdom
Mobilephone: +044 07578724705
http://biosciences.exeter.ac.uk/staff/postgradresearch/ericflores/
________________________________________
De: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] En nombre de Antoine Tremblay [trea26 at gmail.com]
Enviado el: domingo, 22 de enero de 2012 18:13
Para: r-sig-mixed-models at r-project.org
CC: r-sig-mixed-models-request at r-project.org
Asunto: Re: [R-sig-ME] lme or lmer?

Giorgio, another thing regarding the Interval variable that came to my
attention after reading Ben Bolker's reply to your question.

Were you planning on adding Interval to your model specification?
Because it *shouldn't* be in the model. From what I can see, you'd be
performing an analysis on the 200-300 time window, then another one on
the 400-600 time window, and so forth, and in each analysis you'd
include all electrodes (which, as I mentioned in my reply, is probably
best re-coded as ROI with 9 levels).

I'm assuming you chose these time windows because you were expecting to
find amplitude differences between your two conditions with respect to
ERPs found in these time windows (e.g., maybe a late N400 in the 400-600
window?).

So, for *each* time window the model would look something like this
(after recoding Electrode to ROI and your datya frame is named eeg):

m1 <- lmer(Ampl ~ Condition * ROI + (1|Subject) + (1|Item) +
(ROI|Subject), data = eeg)

Would check model assumptions using e.g., function mcp.fnc from package
LMERConvenienceFunctions.

mcp.fnc(m1, trim = 2.5)

Typically the qq plot top right isn't good and there are a lot of data
points with undue influence (bottom right panel). But after removing
outliers +/- 2.5 std. dev. below and above the m1 residuals mean (could
use function romr.fnc from package LMERConvenienceFunctions) the plots
look much, much better.

eeg<- romr.fnc(model = m1, data = eeg, trim = 2.5)$data

Typically 1.5% to 2.5% of the data is removed this way (the function
tells you the percentage). Then refit the model:

m1 <- update(m1)

Then look at the model criticism plot:

mcp.fnc(m1, trim = 2.5)


In addition, you could start with a simple model with only (1|Subject)
then fit a more complex model with (1|Subject) + (1|Item) then a more
complex one with (1|Subject) + (1|Item) + (ROI|Subject) ... and test
whether the inclusion of the random effects is warranted using a log
likelihood ratio test (anova(m1,m2) ...). I'd bet that (1|Subject) +
(1|Item) + (ROI|Subject) will be warranted, maybe also (Condition|Subject).

Sincerely,

Antoine Tremblay
NeuroCognitive Imaging Laboratory
Dalhousie university
Halifax, Canada

> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 21 Jan 2012 15:54:00 +0000 (UTC)
> From: Ben Bolker<bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme or lmer?
> Message-ID:<loom.20120121T041825-883 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
>
> Giorgio Arcara<giorgio.arcara at ...>  writes:
>
>> I would like to use mixed models in R to analyze EEG data, but I don't
>> know if it is more correct to use lme or lmer.
>> My data have the following structure
>>
>> Subject      Electrode        Interval       Trial   Condition       Ampl
>> 1            Fp1             200-300         1       A               3.5
>> 1            Fp1             200-300         2       B               4.2
>> 1            Fp2             400-600         1       A               6.5
>> 1            Fp2             400-600         2       B               3.3
>> 2            Fp1             200-300         1       A               2.1
>> 2            Fp1             200-300         2       B               -5.4
>> 2            Fp2             400-600         1       A               -5.6
>> 2            Fp2             400-600         2       B               -3.2
>
>   [snip]
>
>    In general if you *can* use either lme or lmer (i.e. the random effects are
> not nested, there is no heteroscedasticity or correlation structure at the
> level of residuals ...) then either is OK.  I generally recommend lme in
> these cases (with apologies to Doug Bates) because it is better documented,
> although it's slower.
>
>> For sake of simplicity, here I include only 2 Trials but in the real
>> dataset they are many more.
>> In this hypothetical dataset Ampl is the depentent variable. Electrode
>> and Interval are two predictors. I expect that levels of Electrode
>> will be highly correlated as well the levels of Interval.
>
>    ?? Meaning that most instances of FP1 have Interval 200-300, most
> of Fp2 have 400-500, and there are few 'crossover' instances where you
> have FP1 with 400-500 and FP2 with 200-300?  This will in general make
> it hard to estimate to distinguish the two effects ... but presumably
> you know that.
>
>> My goal is to study if Condition influence Ampl and if interact with
>> Electrode variable and Interval Variable.
>>
>> I would fit a model on these data with lmer with the following structure
>>
>> mod=lmer(Ampl~Electrode*Interval*Condition+(1+Electrode|Subject)
>> +(1+Interval|Subject))
>> If I'm correct the corresponding lme model would be
>>
>> mod=lme(Ampl~Electrode*Interval*Condition, random=list(~1+condition|
>> Subject, ~1+Interval|Subject))
>
>    Why not (Electrode+Interval|Subject)?  That (a) avoids a duplicated intercept
> term and (b) estimates correlations between the intercept, electrode, and
> Interval RE.
>
>> Any suggestion for covariance matrix specification in lme?
>
>    Do you need one other than the default -- i.e. do you expect
> any particular correlation structure?
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 21 Jan 2012 12:55:50 -0400
> From: Antoine Tremblay<trea26 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Cc: r-sig-mixed-models-request at r-project.org
> Subject: Re: [R-sig-ME] lme or lmer?
> Message-ID:<4F1AEE16.3090801 at gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hey Giorgio!
>
> I have one published paper in JoCN where we analyzed ERP data using
> LMER, another one is on the way, and a methods paper is almost finished
> and submitted to NeuroImage regarding the addition of by-item random
> intercepts and slopes to the model. I'm sending you a copy of the JoCN
> paper (proofs for now, it'll be officially out any time soon) and a copy
> of the almost finished NeuroImage paper. If others are interested,
> please let me know and I can send them to you (trea26 at gmail dot com).
>
> So LMER-wise, adding (1+Electtrode|Subject), which you could simply
> write (Electrode|Subject) is correct, but fitting a model with such a
> random effect will take forever.
>
> In NewmanTremblay2011 paper we collapsed Electrode into 9 ROIs: left
> anterior, midline anterior, right anterior, left central, midline
> central, right central, left posterior, midline posterior, and right
> posterior and use that new variable (ROI) instead of Electrode. Note
> that we are not averaging at all! The main reason for this is
> computation time: With 9 levels of ROI in the model as (ROI|Subject) it
> takes A LOT of time to fit, tried once with (Electrode|Subject) and
> would run for sooooo long, actually killed it after like two or three
> days. Even the model with ROI takes what seems to be forever.
>
> Then, once fitted, you'll see with print(model) that in the random
> effects portion of the summary there's a table of correlations between
> levels of ROI, something like this from one of our models (incomplete):
>
> Linear mixed model fit by REML
> Formula: Ampl ~ rProficiency * Condition * ROI * Group + (Condition |
>    Subject) + (1 | Subject) + (ROI | Subject)
>      Data: dat
>        AIC     BIC  logLik deviance REMLdev
>    1011929 1013147 -505843  1011340 1011685
> Random effects:
>    Groups   Name          Variance   Std.Dev. Corr
>    Subject  (Intercept)   2.5852e-01 0.508447
>             ConditionGood 1.4045e+00 1.185133 -0.681
>    Subject  (Intercept)   1.8638e-04 0.013652
>    Subject  (Intercept)   2.8105e+00 1.676449
>             ROILcent      9.4985e-01 0.974604 -0.423
>             ROILpost      3.2123e+00 1.792281 -0.644  0.833
>             ROIMant       3.3728e-01 0.580755 -0.240  0.150  0.258
>             ROIMcent      1.8586e+00 1.363301 -0.249  0.687  ...
>             ROIMpost      2.8172e+00 1.678445 -0.577  0.746  ...
>             ROIRant       7.5682e-01 0.869957 -0.421 -0.171  ...
>             ROIRcent      1.4031e+00 1.184519 -0.840  0.531  ...
>             ROIRpost      3.0983e+00 1.760201 -0.797  0.578  ...
>    Residual               3.3207e+01 5.762530
> Number of obs: 159374, groups: Subject, 44
>
> I'm attaching a complete report (using Sweave) for your reference.
>
> There's one other paper where they used lme with a corSpher function in
> Davidson2007 (attached here, see page 90). The problem i see with using
> lme is that you can't really add crossed by-item random effect, which
> you should as demonstrated in Tremblay2012. Basically, adding by-item
> random effects substantially decreases the amount of (partial)
> autocorrelation in the model residuals (i.e., better approximation of
> the assumption of independence of errors. Note that the data used in
> that paper is available on CRAN (data package LCFdata) and I can send
> you the .Rnw file that contains the R code used for data manipulation,
> analysis and plotting in Tremblay2012, so it's fully replicable. Note
> that for simplicity, analyses in Tremblay2012 are on a single electrode,
> and that I'm not comparing (ROI|Subject) in LMER to corSpher in LME.
> Would like to eventually look a variograms to see how well the two take
> care of spatial correlation and also compare them with a model that
> doesn't account for this correlation.
>
> Note that, as I demonstrate in Tremblay2012, by-item random effect
> should be added if warranted (by Log-likelihood Ratio Test or other; I
> suspect it will always be).
>
>
> Cheers,
>
> Antoine
>
>
> End of R-sig-mixed-models Digest, Vol 61, Issue 31
> **************************************************
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From geralttee at gmail.com  Mon Jan 23 00:50:46 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Mon, 23 Jan 2012 00:50:46 +0100
Subject: [R-sig-ME] Using lmer in survival
Message-ID: <CANXb-o6KsbChhU5+FPzozE5T37H9LURHAbSoYBZ2Cn_LnF-5Cw@mail.gmail.com>

Hi,

Try using MCMCglmm - it fits zero-inflated binomial models. Just be
careful with priors - you might have big separation in your data so
use appropriate priors for fixed effects (see Jarrod Hadfiel's Course
Notes for details). you could also try vgam library (as far as I know
vglm fits zero-inflated binomial models but I haven't use it yet).

Cheers,
sz.

-- 
Szymon Drobniak || Population Ecology Group
Institute of Environmental Sciences,?Jagiellonian University
ul. Gronostajowa 7, 30-387 Krak?w, POLAND
tel.: +48 12 664 51 79 fax: +48 12 664 69 12
szymek.dronbiak at uj.edu.pl
www.eko.uj.edu.pl/drobniak



From bbolker at gmail.com  Mon Jan 23 17:41:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 23 Jan 2012 16:41:16 +0000 (UTC)
Subject: [R-sig-ME] Using lmer in survival
References: <CANXb-o6KsbChhU5+FPzozE5T37H9LURHAbSoYBZ2Cn_LnF-5Cw@mail.gmail.com>
Message-ID: <loom.20120123T174001-856@post.gmane.org>

Szymek Drobniak <geralttee at ...> writes:

> 
> Hi,
> 
> Try using MCMCglmm - it fits zero-inflated binomial models. Just be
> careful with priors - you might have big separation in your data so
> use appropriate priors for fixed effects (see Jarrod Hadfiel's Course
> Notes for details). you could also try vgam library (as far as I know
> vglm fits zero-inflated binomial models but I haven't use it yet).
> 

  glmmADMB is also a possibility.
  I would consider carefully whether you really need zero-inflation --
remember that not all zero-rich data sets are actually zero-inflated.
  The blme package might also be useful for strongly separated data
sets.



From jianyun.fred.wu at gmail.com  Tue Jan 24 01:57:22 2012
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Tue, 24 Jan 2012 11:57:22 +1100
Subject: [R-sig-ME] Bootstrapping linear mixed model
Message-ID: <CAOMGRDLSLzcYPJLCfM=BFERRHOTPSD0FJPzXo=X9JQsNgafXsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/b53eb5d4/attachment-0002.pl>

From arives at wisc.edu  Tue Jan 24 02:19:25 2012
From: arives at wisc.edu (Anthony R Ives)
Date: Mon, 23 Jan 2012 19:19:25 -0600
Subject: [R-sig-ME] Bootstrapping linear mixed model
In-Reply-To: <CAOMGRDLSLzcYPJLCfM=BFERRHOTPSD0FJPzXo=X9JQsNgafXsQ@mail.gmail.com>
References: <CAOMGRDLSLzcYPJLCfM=BFERRHOTPSD0FJPzXo=X9JQsNgafXsQ@mail.gmail.com>
Message-ID: <61D31289-32A4-4243-A50A-4A6D7A0B7487@wisc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120123/7ee91fd8/attachment-0002.pl>

From schmettow at web.de  Tue Jan 24 14:52:09 2012
From: schmettow at web.de (Martin Schmettow)
Date: Tue, 24 Jan 2012 14:52:09 +0100
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
In-Reply-To: <6F35A958A12B9149BD16E3C2F3B0AD0DB37864@SPHINX.adqimr.ad.lan>
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de><Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
	<000301ccd698$a32bee00$e983ca00$@web.de>
	<6F35A958A12B9149BD16E3C2F3B0AD0DB37864@SPHINX.adqimr.ad.lan>
Message-ID: <00ca01ccda9f$5e04f460$1a0edd20$@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/47b0a87e/attachment-0002.pl>

From tavgar at uoguelph.ca  Tue Jan 24 20:07:14 2012
From: tavgar at uoguelph.ca (Tal Avgar)
Date: Tue, 24 Jan 2012 14:07:14 -0500
Subject: [R-sig-ME] accounting for residual autocorrelation
Message-ID: <007201ccdacb$61d7ca50$25875ef0$@ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/963379d4/attachment-0002.pl>

From kw.stat at gmail.com  Tue Jan 24 21:40:05 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 24 Jan 2012 14:40:05 -0600
Subject: [R-sig-ME] accounting for residual autocorrelation
In-Reply-To: <007201ccdacb$61d7ca50$25875ef0$@ca>
References: <007201ccdacb$61d7ca50$25875ef0$@ca>
Message-ID: <CAKFxdiSfBkF7P4vAJixc2sog868HrCmUTX+kYxLCksn8P+jU5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/1327c4b0/attachment-0002.pl>

From mhorton at uchicago.edu  Tue Jan 24 22:35:58 2012
From: mhorton at uchicago.edu (mhorton at uchicago.edu)
Date: Tue, 24 Jan 2012 15:35:58 -0600 (CST)
Subject: [R-sig-ME] adding a kinship matrix to a GLMM
Message-ID: <20120124153558.BDK79131@mstore03.uchicago.edu>

Hello,

I'd like to test the mixed-model approach taken in EMMA (-X):
http://www.nature.com/ng/journal/v42/n4/abs/ng.548.html

in a GLMM framework to analyze non-normal data (e.g. count data; sometimes 
there are lots of zeros). I'm trying this with MASS' glmmPQL, which seems to 
allow the user to provide an "an optional correlation structure".

There are a few classes that extend corStruct, but if I try corSymm, things seem 
to work with:

K <- read.table("kinship.txt",...); # an n x n 'identity by state' matrix
cs.K <- corSymm(K[lower.tri(K)],fixed=T);
cs.K <- Initialize(cs.K,data=data.init);
test <- glmmPQL( response ~ snps_i + offset(log(offset)),
          random=~1|subject,correlation=cs.K, family="quasipoisson" );

# data.init is a 1-column matrix of unique subject ids.
# there are between 1-4 biological replicates per subject

I'm writing to ask is this the best model formulation?
Also, if I add a co-factor 'block', which has 6 levels (subjects do not occur in all 
blocks), I get a lot of NA errors:
test <- glmmPQL( response ~ snps_i + as.factor(block)+ offset(log(offset)), 
          random=~1|subject,correlation=cs.K, family="quasipoisson" );
iteration 1
iteration 2
iteration 3
Error in na.fail.default(list(subject = c(1L, 1L, 1L, 2L, 2L, 2L, 3L,  : 
  missing values in object

Again, is there a better model formula?  Is corSymm even doing what I think it is 
doing here? 

Thanks for your time and any comments!
Matt



From deter088 at umn.edu  Wed Jan 25 03:32:07 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 24 Jan 2012 20:32:07 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
Message-ID: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120124/c00c0e1d/attachment-0002.pl>

From Paul.Thompson at SanfordHealth.org  Wed Jan 25 03:48:25 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Wed, 25 Jan 2012 02:48:25 +0000
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B1D622A@SFSMCEXMBX2.sanfordhealth.org>

In the CS model, the F values for Gender and Gender*age are really close, but age is quite discrepant. That seems problematic.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles Determan Jr
Sent: Tuesday, January 24, 2012 8:32 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R

Greetings,

I have been working on R for some time now and I have begun the endeavor of
trying to replicate some SAS code in R.  I have scoured the forums but
haven't been able to find an answer.  I hope one of you could be so kind as
to enlighten me.

I am attempting to replicate a repeated measures experiment using some
standard data.  I have posted the SAS code and output directly from a
publication as well as my attempts in R to replicate it.  My main issue
comes with the 'unstructured' component.

The 'dental' dataset from 'mixedQF' package,
equivalent to formixed data in SAS

    distance age Subject    Sex
1       26.0   8     M01   Male
2       25.0  10     M01   Male
3       29.0  12     M01   Male
4       31.0  14     M01   Male
5       21.5   8     M02   Male
6       22.5  10     M02   Male
7       23.0  12     M02   Male
8       26.5  14     M02   Male
9       23.0   8     M03   Male
10      22.5  10     M03   Male
11      24.0  12     M03   Male
12      27.5  14     M03   Male
13      25.5   8     M04   Male
14      27.5  10     M04   Male
15      26.5  12     M04   Male
16      27.0  14     M04   Male
17      20.0   8     M05   Male
18      23.5  10     M05   Male
19      22.5  12     M05   Male
20      26.0  14     M05   Male
21      24.5   8     M06   Male
22      25.5  10     M06   Male
23      27.0  12     M06   Male
24      28.5  14     M06   Male
25      22.0   8     M07   Male
26      22.0  10     M07   Male
27      24.5  12     M07   Male
28      26.5  14     M07   Male
29      24.0   8     M08   Male
30      21.5  10     M08   Male
31      24.5  12     M08   Male
32      25.5  14     M08   Male
33      23.0   8     M09   Male
34      20.5  10     M09   Male
35      31.0  12     M09   Male
36      26.0  14     M09   Male
37      27.5   8     M10   Male
38      28.0  10     M10   Male
39      31.0  12     M10   Male
40      31.5  14     M10   Male
41      23.0   8     M11   Male
42      23.0  10     M11   Male
43      23.5  12     M11   Male
44      25.0  14     M11   Male
45      21.5   8     M12   Male
46      23.5  10     M12   Male
47      24.0  12     M12   Male
48      28.0  14     M12   Male
49      17.0   8     M13   Male
50      24.5  10     M13   Male
51      26.0  12     M13   Male
52      29.5  14     M13   Male
53      22.5   8     M14   Male
54      25.5  10     M14   Male
55      25.5  12     M14   Male
56      26.0  14     M14   Male
57      23.0   8     M15   Male
58      24.5  10     M15   Male
59      26.0  12     M15   Male
60      30.0  14     M15   Male
61      22.0   8     M16   Male
62      21.5  10     M16   Male
63      23.5  12     M16   Male
64      25.0  14     M16   Male
65      21.0   8     F01 Female
66      20.0  10     F01 Female
67      21.5  12     F01 Female
68      23.0  14     F01 Female
69      21.0   8     F02 Female
70      21.5  10     F02 Female
71      24.0  12     F02 Female
72      25.5  14     F02 Female
73      20.5   8     F03 Female
74      24.0  10     F03 Female
75      24.5  12     F03 Female
76      26.0  14     F03 Female
77      23.5   8     F04 Female
78      24.5  10     F04 Female
79      25.0  12     F04 Female
80      26.5  14     F04 Female
81      21.5   8     F05 Female
82      23.0  10     F05 Female
83      22.5  12     F05 Female
84      23.5  14     F05 Female
85      20.0   8     F06 Female
86      21.0  10     F06 Female
87      21.0  12     F06 Female
88      22.5  14     F06 Female
89      21.5   8     F07 Female
90      22.5  10     F07 Female
91      23.0  12     F07 Female
92      25.0  14     F07 Female
93      23.0   8     F08 Female
94      23.0  10     F08 Female
95      23.5  12     F08 Female
96      24.0  14     F08 Female
97      20.0   8     F09 Female
98      21.0  10     F09 Female
99      22.0  12     F09 Female
100     21.5  14     F09 Female
101     16.5   8     F10 Female
102     19.0  10     F10 Female
103     19.0  12     F10 Female
104     19.5  14     F10 Female
105     24.5   8     F11 Female
106     25.0  10     F11 Female
107     28.0  12     F11 Female
108     28.0  14     F11 Female

*Mixed modeling and fixed effect test*
SAS
proc mixed data=formixed;
class gender age person;
model y = gender|age;
repeated / type=cs sub=person;
run;

output of interest to me
          Tests of Fixed Effects
Source             NDF   DDF    Type III F    Pr > F
GENDER           1        25        9.29        0.0054
AGE                  3        75       35.35       0.0001
GENDER*AGE   3        75        2.36        0.0781

R (nlme package)
y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
anova(y)

            numDF denDF  F-value p-value
(Intercept)     1    75 4123.156  <.0001
Sex              1    25    9.292  0.0054
age               3    75   40.032  <.0001
Sex:age        3    75    2.362  0.0781

Now this isn't exact but it is extremely close, however when I try to
replicate the unstructured,

SAS
proc mixed data=formixed;
class gender age person;
model y = gender|age;
repeated / type=un sub=person;
run;

             Tests of Fixed Effects
Source          NDF DDF Type III F Pr > F
GENDER         1    25     9.29    0.0054
AGE                3    25    34.45   0.0001
GENDER*AGE 3    25     2.93    0.0532

R
either
y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
data=dental)
anova(y)
or
z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(), data=dental)
anova(z)

gives the output

            numDF denDF  F-value    p-value
(Intercept)     1    75     4052.028  <.0001
Sex              1    25       8.462      0.0075
age               3    75      39.022    <.0001
Sex:age        3    75       2.868      0.0421

What am I doing wrong to replicate the unstructured linear mixed model from
SAS?

Regards,

Charles

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From deter088 at umn.edu  Wed Jan 25 15:35:41 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 25 Jan 2012 08:35:41 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1D622A@SFSMCEXMBX2.sanfordhealth.org>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D622A@SFSMCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJph=evRi_LsgXJZyEAKqsD3apCFkY9FTFdPRYSeoHa-LcTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120125/bbae2d1f/attachment-0002.pl>

From W.Bouwmeester at umcutrecht.nl  Wed Jan 25 12:02:18 2012
From: W.Bouwmeester at umcutrecht.nl (Bouwmeester, W.)
Date: Wed, 25 Jan 2012 11:02:18 +0000
Subject: [R-sig-ME] lme4 and sample size
In-Reply-To: <CAO7JsnSBCo4exTRgzCaB54udtM0RBQh668zc_NOqXpaRhH93fg@mail.gmail.com>
References: <6C86BD70D72CB449A189A18EED3037CA057EE65B@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
	<6C86BD70D72CB449A189A18EED3037CA057EE66C@EXMB1501.ds.umcutrecht.nl>,
	<CAO7JsnSBCo4exTRgzCaB54udtM0RBQh668zc_NOqXpaRhH93fg@mail.gmail.com>
Message-ID: <6C86BD70D72CB449A189A18EED3037CA05803CA7@EXMB2501.ds.umcutrecht.nl>

Dear professor Bates,

Is it possible to put the iteration information in an R object (this is printed when verbose=TRUE in the lmer function)? 

I like to monitor this output during simulations.

Kind regards, 
Walter



________________________________________
Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
Verzonden: vrijdag 13 januari 2012 17:05
To: Bouwmeester, W.
Cc: R-mixed models mailing list
Onderwerp: Re: lme4 and sample size

On Fri, Jan 13, 2012 at 9:58 AM, Bouwmeester, W.
<W.Bouwmeester at umcutrecht.nl> wrote:
> Dear professor Bates,
>
> I'am using the lmer function indeed. Can I use 'cvg' from the output attr(model, "dims") to evaluate convergence? (here, the object "model" is fitted with the lmer function)

Yes, but do bear in mind that the cvg indicator is from the optimizer,
which is nlminb in the case of the released lme4.  We have encountered
difficulties with nlminb failing to converge or giving the false
convergence message or getting stuck at boundary values.  We later
switched to the bobyqa optimizer from the minqa package and then to a
local implementation of the Nelder-Mead simplex optimizer.

Failure to converge is a property of the optimizer being used, not the
overall design of lme4.  It happens that good optimizers that are
available to Open Source projects are difficult to come by.

> Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
> Verzonden: vrijdag 13 januari 2012 16:51
> To: Bouwmeester, W.
> Onderwerp: Re: lme4 and sample size
>
> I have taken the liberty of copying the reply to the
> R-SIG-Mixed-Models at R-Project.org mailing list so that it will be
> available in a searchable archive.
>
> On Fri, Jan 13, 2012 at 9:37 AM, Bouwmeester, W.
> <W.Bouwmeester at umcutrecht.nl> wrote:
>> Dear professor Bates,
>>
>> I will incvestigate the required sample size to develop a prediction model in hierarchical data, using a simulation study. One of the model evaluation criteria will be whether the model converged. R will give warning messages if no or singular convergence appeared.
>> Is it possible to evaluate model convergence from the cvg column in attr(mix.model,"dims")? Has this "cvg" anything to do with convergence?
>>
>> I saw this "cvg" output from attr(mix.model, "dims") in your publication on October 4, 2011, Linear mixed model implementation in lme4, page 6 and 20.
>
> I would strongly recommend using lmer instead of lme to fit
> heirarchical linear models in a simulation study.  The lmer function
> in the lme4 package is much faster and more reliable than the lme
> function from the nlme package.
>
> The current version of lme4 on CRAN can sometimes encounter a warning
> about "false convergence".  The version named lme4Eigen on the R-forge
> site is, in our preliminary tests, more reliable and usually faster
> than the released version.  You do need to be able to build an R
> package from source to be able to use the lme4Eigen at present.
> ------------------------------------------------------------------------------
>
> De informatie opgenomen in dit bericht kan vertrouwelijk zijn en is
> uitsluitend bestemd voor de geadresseerde. Indien u dit bericht onterecht
> ontvangt, wordt u verzocht de inhoud niet te gebruiken en de afzender direct
> te informeren door het bericht te retourneren. Het Universitair Medisch
> Centrum Utrecht is een publiekrechtelijke rechtspersoon in de zin van de W.H.W.
> (Wet Hoger Onderwijs en Wetenschappelijk Onderzoek) en staat geregistreerd bij
> de Kamer van Koophandel voor Midden-Nederland onder nr. 30244197.
>
> Denk s.v.p aan het milieu voor u deze e-mail afdrukt.
>
> ------------------------------------------------------------------------------
>
> This message may contain confidential information and ...{{dropped:12}}



From datkins at u.washington.edu  Wed Jan 25 20:39:56 2012
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 25 Jan 2012 11:39:56 -0800
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
Message-ID: <4F205A8C.4010303@u.washington.edu>


Hi Charles--

So, I don't know SAS at all, so just providing the SAS code and anova 
table don't tell me (at least) all that much about what SAS is doing. 
Also keep in mind that the anova table summary will depend on the "type" 
of sums of squares (and there have been some diatribes about this and 
type III sums of squares in the past on this list).

I find it a bit more informative to look at the summary output from lme(r):

 > y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
 >
 > summary(y)
Linear mixed-effects model fit by REML
  Data: dental
        AIC      BIC    logLik
   445.7572 461.6236 -216.8786

Random effects:
  Formula: ~1 | Subject
         (Intercept) Residual
StdDev:    1.816214 1.386382

Fixed effects: distance ~ Sex * age
                   Value Std.Error DF   t-value p-value
(Intercept)   16.340625 0.9813122 79 16.651810  0.0000
SexFemale      1.032102 1.5374208 25  0.671321  0.5082
age            0.784375 0.0775011 79 10.120823  0.0000
SexFemale:age -0.304830 0.1214209 79 -2.510520  0.0141
  Correlation:
               (Intr) SexFml age
SexFemale     -0.638
age           -0.869  0.555
SexFemale:age  0.555 -0.869 -0.638

Standardized Within-Group Residuals:
         Min          Q1         Med          Q3         Max
-3.59804400 -0.45461690  0.01578365  0.50244658  3.68620792

Number of Observations: 108
Number of Groups: 27

DAVE: so, we fit a random-intercept, residual error, and 4 fixed-effects 
(N = 27 people and 108 observations)

Here is your second model:

 > y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
+ data=dental)
 > summary(y)
Linear mixed-effects model fit by REML
  Data: dental
        AIC      BIC    logLik
   450.1706 481.9033 -213.0853

Random effects:
  Formula: ~1 | Subject
         (Intercept) Residual
StdDev:    1.827112 1.375353

Correlation Structure: General
  Formula: ~1 | Subject
  Parameter estimate(s):
  Correlation:
   1      2      3
2 -0.174
3 -0.002 -0.177
4 -0.342  0.306  0.227
Fixed effects: distance ~ Sex * age
                   Value Std.Error DF   t-value p-value
(Intercept)   15.932927 0.9978753 79 15.966852  0.0000
SexFemale      1.473662 1.5633701 25  0.942619  0.3549
age            0.824339 0.0824260 79 10.000962  0.0000
SexFemale:age -0.348100 0.1291367 79 -2.695594  0.0086
  Correlation:
               (Intr) SexFml age
SexFemale     -0.638
age           -0.874  0.558
SexFemale:age  0.558 -0.874 -0.638

Standardized Within-Group Residuals:
          Min           Q1          Med           Q3          Max
-3.180968424 -0.544002662  0.001195789  0.495264398  3.730242930

Number of Observations: 108
Number of Groups: 27

DAVE: Now, in addition to earlier parameters, we have an unstructured 
covariance matrix for repeated measures.  By all indications this is a 
*worse* fitting model...

Finally, I wonder whether SAS is fitting random-effects at all (no idea, 
just a guess).  If so, you might check it relative to a gls() fit, a la:

 > y2=gls(distance~Sex*age, corr=corSymm(,~1|Subject),
+ data=dental)
 > summary(y2)
Generalized least squares fit by REML
   Model: distance ~ Sex * age
   Data: dental
        AIC      BIC    logLik
   448.1706 477.2589 -213.0853

Correlation Structure: General
  Formula: ~1 | Subject
  Parameter estimate(s):
  Correlation:
   1     2     3
2 0.575
3 0.638 0.574
4 0.515 0.749 0.721

Coefficients:
                   Value Std.Error   t-value p-value
(Intercept)   15.932911 0.9978729 15.966874  0.0000
SexFemale      1.473679 1.5633664  0.942632  0.3481
age            0.824340 0.0824258 10.001000  0.0000
SexFemale:age -0.348102 0.1291364 -2.695611  0.0082

  Correlation:
               (Intr) SexFml age
SexFemale     -0.638
age           -0.874  0.558
SexFemale:age  0.558 -0.874 -0.638

Standardized residuals:
         Min          Q1         Med          Q3         Max
-2.41707752 -0.64439706 -0.07388955  0.58480683  2.26288228

Residual standard error: 2.286908
Degrees of freedom: 108 total; 104 residual

So, not sure if this is helpful, but perhaps you could provide 
additional output / commentary on what exactly SAS is doing (beyond 
anova table).

cheers, Dave


Greetings,

I have been working on R for some time now and I have begun the endeavor of
trying to replicate some SAS code in R.  I have scoured the forums but
haven't been able to find an answer.  I hope one of you could be so kind as
to enlighten me.

I am attempting to replicate a repeated measures experiment using some
standard data.  I have posted the SAS code and output directly from a
publication as well as my attempts in R to replicate it.  My main issue
comes with the 'unstructured' component.

The 'dental' dataset from 'mixedQF' package,
equivalent to formixed data in SAS

     distance age Subject    Sex
1       26.0   8     M01   Male
2       25.0  10     M01   Male
3       29.0  12     M01   Male
4       31.0  14     M01   Male
5       21.5   8     M02   Male
6       22.5  10     M02   Male
7       23.0  12     M02   Male
8       26.5  14     M02   Male
9       23.0   8     M03   Male
10      22.5  10     M03   Male
11      24.0  12     M03   Male
12      27.5  14     M03   Male
13      25.5   8     M04   Male
14      27.5  10     M04   Male
15      26.5  12     M04   Male
16      27.0  14     M04   Male
17      20.0   8     M05   Male
18      23.5  10     M05   Male
19      22.5  12     M05   Male
20      26.0  14     M05   Male
21      24.5   8     M06   Male
22      25.5  10     M06   Male
23      27.0  12     M06   Male
24      28.5  14     M06   Male
25      22.0   8     M07   Male
26      22.0  10     M07   Male
27      24.5  12     M07   Male
28      26.5  14     M07   Male
29      24.0   8     M08   Male
30      21.5  10     M08   Male
31      24.5  12     M08   Male
32      25.5  14     M08   Male
33      23.0   8     M09   Male
34      20.5  10     M09   Male
35      31.0  12     M09   Male
36      26.0  14     M09   Male
37      27.5   8     M10   Male
38      28.0  10     M10   Male
39      31.0  12     M10   Male
40      31.5  14     M10   Male
41      23.0   8     M11   Male
42      23.0  10     M11   Male
43      23.5  12     M11   Male
44      25.0  14     M11   Male
45      21.5   8     M12   Male
46      23.5  10     M12   Male
47      24.0  12     M12   Male
48      28.0  14     M12   Male
49      17.0   8     M13   Male
50      24.5  10     M13   Male
51      26.0  12     M13   Male
52      29.5  14     M13   Male
53      22.5   8     M14   Male
54      25.5  10     M14   Male
55      25.5  12     M14   Male
56      26.0  14     M14   Male
57      23.0   8     M15   Male
58      24.5  10     M15   Male
59      26.0  12     M15   Male
60      30.0  14     M15   Male
61      22.0   8     M16   Male
62      21.5  10     M16   Male
63      23.5  12     M16   Male
64      25.0  14     M16   Male
65      21.0   8     F01 Female
66      20.0  10     F01 Female
67      21.5  12     F01 Female
68      23.0  14     F01 Female
69      21.0   8     F02 Female
70      21.5  10     F02 Female
71      24.0  12     F02 Female
72      25.5  14     F02 Female
73      20.5   8     F03 Female
74      24.0  10     F03 Female
75      24.5  12     F03 Female
76      26.0  14     F03 Female
77      23.5   8     F04 Female
78      24.5  10     F04 Female
79      25.0  12     F04 Female
80      26.5  14     F04 Female
81      21.5   8     F05 Female
82      23.0  10     F05 Female
83      22.5  12     F05 Female
84      23.5  14     F05 Female
85      20.0   8     F06 Female
86      21.0  10     F06 Female
87      21.0  12     F06 Female
88      22.5  14     F06 Female
89      21.5   8     F07 Female
90      22.5  10     F07 Female
91      23.0  12     F07 Female
92      25.0  14     F07 Female
93      23.0   8     F08 Female
94      23.0  10     F08 Female
95      23.5  12     F08 Female
96      24.0  14     F08 Female
97      20.0   8     F09 Female
98      21.0  10     F09 Female
99      22.0  12     F09 Female
100     21.5  14     F09 Female
101     16.5   8     F10 Female
102     19.0  10     F10 Female
103     19.0  12     F10 Female
104     19.5  14     F10 Female
105     24.5   8     F11 Female
106     25.0  10     F11 Female
107     28.0  12     F11 Female
108     28.0  14     F11 Female

*Mixed modeling and fixed effect test*
SAS
proc mixed data=formixed;
class gender age person;
model y = gender|age;
repeated / type=cs sub=person;
run;

output of interest to me
           Tests of Fixed Effects
Source             NDF   DDF    Type III F    Pr > F
GENDER           1        25        9.29        0.0054
AGE                  3        75       35.35       0.0001
GENDER*AGE   3        75        2.36        0.0781

R (nlme package)
y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
anova(y)

             numDF denDF  F-value p-value
(Intercept)     1    75 4123.156  <.0001
Sex              1    25    9.292  0.0054
age               3    75   40.032  <.0001
Sex:age        3    75    2.362  0.0781

Now this isn't exact but it is extremely close, however when I try to
replicate the unstructured,

SAS
proc mixed data=formixed;
class gender age person;
model y = gender|age;
repeated / type=un sub=person;
run;

              Tests of Fixed Effects
Source          NDF DDF Type III F Pr > F
GENDER         1    25     9.29    0.0054
AGE                3    25    34.45   0.0001
GENDER*AGE 3    25     2.93    0.0532

R
either
y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
data=dental)
anova(y)
or
z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(), data=dental)
anova(z)

gives the output

             numDF denDF  F-value    p-value
(Intercept)     1    75     4052.028  <.0001
Sex              1    25       8.462      0.0075
age               3    75      39.022    <.0001
Sex:age        3    75       2.868      0.0421

What am I doing wrong to replicate the unstructured linear mixed model from
SAS?

Regards,

Charles

	[[alternative HTML version deleted]]

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From David.Duffy at qimr.edu.au  Thu Jan 26 01:33:21 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 26 Jan 2012 10:33:21 +1000 (EST)
Subject: [R-sig-ME] adding a kinship matrix to a GLMM
In-Reply-To: <20120124153558.BDK79131@mstore03.uchicago.edu>
References: <20120124153558.BDK79131@mstore03.uchicago.edu>
Message-ID: <Pine.LNX.4.64.1201261010410.16419@orpheus.qimr.edu.au>

On Tue, 24 Jan 2012, mhorton at uchicago.edu wrote:

> I'm trying this with MASS' glmmPQL, which seems to
> allow the user to provide an "an optional correlation structure".
>
> There are a few classes that extend corStruct, but if I try corSymm, things seem
> to work with:
>
> I'm writing to ask is this the best model formulation?
> Also, if I add a co-factor 'block', which has 6 levels (subjects do not occur in all
> blocks), I get a lot of NA errors:
> test <- glmmPQL( response ~ snps_i + as.factor(block)+ offset(log(offset)),
>          random=~1|subject,correlation=cs.K, family="quasipoisson" );
> iteration 1
> iteration 2
> iteration 3
> Error in na.fail.default(list(subject = c(1L, 1L, 1L, 2L, 2L, 2L, 3L,  :
>  missing values in object
>
> Again, is there a better model formula?  Is corSymm even doing what I think it is
> doing here?

I think so.  That error might be arising from incomplete data, as it says 
(do debug(lme) to see where, as this is what glmmPQL calls).  PQL might 
not be giving brilliant estimates of the random effects, but I presume you 
are most interested in snps_1.  Here is one result from a simulation of 
mine for a binomial trait, using R GLMM packages, augmented by your 
PQL

head(x)
   ped id fa mo sex trait locus
1   1  1 NA NA   m  <NA>   1/2
2   1  2 NA NA   f  <NA>   1/2
3   1  3  1  2   f     n   1/2
4   1  4  1  2   f     y   1/1
5   1  5  1  2   f     n   1/1
6   2  6 NA NA   f  <NA>   1/2


library(pedigreemm)
ped <- pedigree(x$fa, x$mo, x$id)
pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), family=binomial(), 
data=x)
pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), 
family=binomial(link=probit), data=x)

library(AnimalINLA)
ped2 <- x[,2:4]
ped2[is.na(ped2)] <- 0
Ainv <- compute.Ainverse(ped2)
pheno <- data.frame(id=x$id, trait=(x$trait=="y"), Individual=x$id)
pheno <- pheno[complete.cases(pheno$trait),]
m1 <- animal.inla("trait", genetic="id", Ainverse=Ainv, data=pheno, 
type.data = "binomial")
summary(m1)

library(MASS)
library(kinship)
K <- kinship(x$id, x$fa, x$mo)
observed <- !is.na(x$trait)
K <- K[observed, observed]
cs.K <- corSymm(2*K[lower.tri(K)],fixed=T)
id <- as.matrix(as.factor(x$id[observed]))
colnames(id) <- "id"
cs.K <- Initialize(cs.K,data=id)
pql1 <- glmmPQL(trait ~ 1, random=~1|id,
                 correlation=cs.K,
                 data=x[observed,], family="binomial
summary(pql1)

library(MCMCglmm)
pheno <- data.frame(animal=x$id, sire=x$fa, dam=x$mo, y=(x$trait=="y"))
g1 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
                family="categorical", data=pheno, verbose=FALSE)
summary(g1)
g2 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
                family="ordinal", data=pheno, verbose=FALSE)
summary(g2)

-----------------------------
logistic-normal
                  RE SD
pedigreemm       0.847
AnimalINLA       0.671
glmmPQL          1.185
MCMCglmm         1.389


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From David.Duffy at qimr.edu.au  Thu Jan 26 03:54:48 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 26 Jan 2012 12:54:48 +1000 (EST)
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>

On Tue, 24 Jan 2012, Charles Determan Jr wrote:

> Greetings,
>
> I have been working on R for some time now and I have begun the endeavor of
> trying to replicate some SAS code in R.  I have scoured the forums but
>
This is also the Orthodont dataset, distributed with nlme.

As David Atkins pointed out, R defaults to Type I SS. so you would need to 
use, for example, the Anova() command from the car package.  The other 
thing is that the SAS F statistics are only approximate, depending on 
which covariance structure is chosen (perhaps John Maindonald or someone 
clever could comment), so SAS offers different possibilities for ddf eg

http://www2.sas.com/proceedings/sugi26/p262-26.pdf

while lme and lmer offer one or none.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From john.maindonald at anu.edu.au  Thu Jan 26 06:19:22 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 26 Jan 2012 16:19:22 +1100
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
Message-ID: <1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>

It is well to note that type III sums of squares are problematic.
For testing the effects of a main effect, the null model is constraining
the main effect in a manner that depends on the parameterisation.

There are situations where it makes sense to fit interactions without
main effects, and it is clear what constraint on the main effect is the
relevant null (with an interaction between a factor and a variable,
does one want all lines to go though the same point, or through
perhaps the origin?), but that situation is unusual.  For lines that 
are separate or all through the one point, one does not need 
type III sums of squares.

Analyses often or frequently have enough genuine complications 
worrying (unless it is blindingly obvious that one ought to worry
about it) without the rarely relevant complication of attending to a 
type III sum of squares.  

I'd guess that SAS and lme are, effectively, making different
assumptions about the intended generalisation.  They are
clearly using different denominator degrees of freedom for F.
As one is looking for consistency across the 27 different youths,
SAS's denominator degrees of freedom for the interaction seem 
more or less right, pretty much equivalent to calculating slopes 
for females and slopes for males and using a t-test to compare 
them.  (Sure, in the analyses presented, age has been treated 
as a categorical variable, but the comment still applies.)

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 26/01/2012, at 1:54 PM, David Duffy wrote:

> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
> 
>> Greetings,
>> 
>> I have been working on R for some time now and I have begun the endeavor of
>> trying to replicate some SAS code in R.  I have scoured the forums but
>> 
> This is also the Orthodont dataset, distributed with nlme.
> 
> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
> 
> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
> 
> while lme and lmer offer one or none.
> 
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From deter088 at umn.edu  Thu Jan 26 15:24:11 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 08:24:11 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
Message-ID: <CAOLJphkNxMLK2bfa5cx7S7OSyU0_1qLrcgiTv-u04pE-7d4_tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/f2c20fbd/attachment-0002.pl>

From Paul.Thompson at SanfordHealth.org  Thu Jan 26 15:52:01 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Thu, 26 Jan 2012 14:52:01 +0000
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>

I am unfamiliar with this critique of Type III SS. Can you point me to a reference discussing the difficulties with Type III SS?

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
Sent: Wednesday, January 25, 2012 11:19 PM
To: David Duffy
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R

It is well to note that type III sums of squares are problematic.
For testing the effects of a main effect, the null model is constraining
the main effect in a manner that depends on the parameterisation.

There are situations where it makes sense to fit interactions without
main effects, and it is clear what constraint on the main effect is the
relevant null (with an interaction between a factor and a variable,
does one want all lines to go though the same point, or through
perhaps the origin?), but that situation is unusual.  For lines that 
are separate or all through the one point, one does not need 
type III sums of squares.

Analyses often or frequently have enough genuine complications 
worrying (unless it is blindingly obvious that one ought to worry
about it) without the rarely relevant complication of attending to a 
type III sum of squares.  

I'd guess that SAS and lme are, effectively, making different
assumptions about the intended generalisation.  They are
clearly using different denominator degrees of freedom for F.
As one is looking for consistency across the 27 different youths,
SAS's denominator degrees of freedom for the interaction seem 
more or less right, pretty much equivalent to calculating slopes 
for females and slopes for males and using a t-test to compare 
them.  (Sure, in the analyses presented, age has been treated 
as a categorical variable, but the comment still applies.)

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 26/01/2012, at 1:54 PM, David Duffy wrote:

> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
> 
>> Greetings,
>> 
>> I have been working on R for some time now and I have begun the endeavor of
>> trying to replicate some SAS code in R.  I have scoured the forums but
>> 
> This is also the Orthodont dataset, distributed with nlme.
> 
> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
> 
> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
> 
> while lme and lmer offer one or none.
> 
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From lborger at cebc.cnrs.fr  Thu Jan 26 16:02:48 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Thu, 26 Jan 2012 16:02:48 +0100
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
Message-ID: <4F216B18.6030405@cebc.cnrs.fr>

I think:

http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

HTH
Luca



Le 26/01/2012 15:52, Thompson,Paul a ?crit :
> I am unfamiliar with this critique of Type III SS. Can you point me to a reference discussing the difficulties with Type III SS?
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
> Sent: Wednesday, January 25, 2012 11:19 PM
> To: David Duffy
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
>
> It is well to note that type III sums of squares are problematic.
> For testing the effects of a main effect, the null model is constraining
> the main effect in a manner that depends on the parameterisation.
>
> There are situations where it makes sense to fit interactions without
> main effects, and it is clear what constraint on the main effect is the
> relevant null (with an interaction between a factor and a variable,
> does one want all lines to go though the same point, or through
> perhaps the origin?), but that situation is unusual.  For lines that
> are separate or all through the one point, one does not need
> type III sums of squares.
>
> Analyses often or frequently have enough genuine complications
> worrying (unless it is blindingly obvious that one ought to worry
> about it) without the rarely relevant complication of attending to a
> type III sum of squares.
>
> I'd guess that SAS and lme are, effectively, making different
> assumptions about the intended generalisation.  They are
> clearly using different denominator degrees of freedom for F.
> As one is looking for consistency across the 27 different youths,
> SAS's denominator degrees of freedom for the interaction seem
> more or less right, pretty much equivalent to calculating slopes
> for females and slopes for males and using a t-test to compare
> them.  (Sure, in the analyses presented, age has been treated
> as a categorical variable, but the comment still applies.)
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 26/01/2012, at 1:54 PM, David Duffy wrote:
>
>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
>>
>>> Greetings,
>>>
>>> I have been working on R for some time now and I have begun the endeavor of
>>> trying to replicate some SAS code in R.  I have scoured the forums but
>>>
>> This is also the Orthodont dataset, distributed with nlme.
>>
>> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
>>
>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
>>
>> while lme and lmer offer one or none.
>>
>> -- 
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>



From Paul.Thompson at SanfordHealth.org  Thu Jan 26 16:41:10 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Thu, 26 Jan 2012 15:41:10 +0000
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <4F216B18.6030405@cebc.cnrs.fr>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>

OK, I've looked at that reference. 

There are 2 aspects of an estimate like a SS. The first is the stability of the estimate, and the second is the interpretation of the estimate. The issues with the interpretation of the different estimates go back to 1970, and they are simply a matter of interpretation. The point of the Venables discussion is that he does not like Type III SS, not that they are wrong. He does not agree with the interpretation.

The issue here is the accuracy of the Type III or Type I or Type II or whatever. Accuracy comes before interpretation. If the r module and SAS do not arrive at the same estimates, that is an important thing. 

Once we agree upon computation, we can argue about interpretation. Charles Determan is inquiring as to computational accuracy. The use and interpretation of the various Type I, II, III, IV, LVX SS are secondary.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
Sent: Thursday, January 26, 2012 9:03 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R

I think:

http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

HTH
Luca



Le 26/01/2012 15:52, Thompson,Paul a ?crit :
> I am unfamiliar with this critique of Type III SS. Can you point me to a reference discussing the difficulties with Type III SS?
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
> Sent: Wednesday, January 25, 2012 11:19 PM
> To: David Duffy
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
>
> It is well to note that type III sums of squares are problematic.
> For testing the effects of a main effect, the null model is constraining
> the main effect in a manner that depends on the parameterisation.
>
> There are situations where it makes sense to fit interactions without
> main effects, and it is clear what constraint on the main effect is the
> relevant null (with an interaction between a factor and a variable,
> does one want all lines to go though the same point, or through
> perhaps the origin?), but that situation is unusual.  For lines that
> are separate or all through the one point, one does not need
> type III sums of squares.
>
> Analyses often or frequently have enough genuine complications
> worrying (unless it is blindingly obvious that one ought to worry
> about it) without the rarely relevant complication of attending to a
> type III sum of squares.
>
> I'd guess that SAS and lme are, effectively, making different
> assumptions about the intended generalisation.  They are
> clearly using different denominator degrees of freedom for F.
> As one is looking for consistency across the 27 different youths,
> SAS's denominator degrees of freedom for the interaction seem
> more or less right, pretty much equivalent to calculating slopes
> for females and slopes for males and using a t-test to compare
> them.  (Sure, in the analyses presented, age has been treated
> as a categorical variable, but the comment still applies.)
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 26/01/2012, at 1:54 PM, David Duffy wrote:
>
>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
>>
>>> Greetings,
>>>
>>> I have been working on R for some time now and I have begun the endeavor of
>>> trying to replicate some SAS code in R.  I have scoured the forums but
>>>
>> This is also the Orthodont dataset, distributed with nlme.
>>
>> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
>>
>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
>>
>> while lme and lmer offer one or none.
>>
>> -- 
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From mhorton at uchicago.edu  Thu Jan 26 17:10:45 2012
From: mhorton at uchicago.edu (mhorton at uchicago.edu)
Date: Thu, 26 Jan 2012 10:10:45 -0600 (CST)
Subject: [R-sig-ME] adding a kinship matrix to a GLMM
In-Reply-To: <Pine.LNX.4.64.1201261010410.16419@orpheus.qimr.edu.au>
References: <20120124153558.BDK79131@mstore03.uchicago.edu>
	<Pine.LNX.4.64.1201261010410.16419@orpheus.qimr.edu.au>
Message-ID: <20120126101045.BDN88330@mstore03.uchicago.edu>

Thanks David. I'll see if I can fit a kinship matrix using the other packages you show. 
It would also be great to setup the same test case to see how quickly any of this will 
actually run. I can't do that immediately, but I will try to post the results next week.

---- Original message ----
>Date: Thu, 26 Jan 2012 10:33:21 +1000 (EST)
>From: "David Duffy" <David.Duffy at qimr.edu.au>  
>Subject: Re: [R-sig-ME] adding a kinship matrix to a GLMM  
>To: <mhorton at uchicago.edu>
>Cc: <r-sig-mixed-models at r-project.org>
>
>On Tue, 24 Jan 2012, mhorton at uchicago.edu wrote:
>
>> I'm trying this with MASS' glmmPQL, which seems to
>> allow the user to provide an "an optional correlation structure".
>>
>> There are a few classes that extend corStruct, but if I try corSymm, things seem
>> to work with:
>>
>> I'm writing to ask is this the best model formulation?
>> Also, if I add a co-factor 'block', which has 6 levels (subjects do not occur in all
>> blocks), I get a lot of NA errors:
>> test <- glmmPQL( response ~ snps_i + as.factor(block)+ offset(log(offset)),
>>          random=~1|subject,correlation=cs.K, family="quasipoisson" );
>> iteration 1
>> iteration 2
>> iteration 3
>> Error in na.fail.default(list(subject = c(1L, 1L, 1L, 2L, 2L, 2L, 3L,  :
>>  missing values in object
>>
>> Again, is there a better model formula?  Is corSymm even doing what I think it is
>> doing here?
>
>I think so.  That error might be arising from incomplete data, as it says 
>(do debug(lme) to see where, as this is what glmmPQL calls).  PQL might 
>not be giving brilliant estimates of the random effects, but I presume you 
>are most interested in snps_1.  Here is one result from a simulation of 
>mine for a binomial trait, using R GLMM packages, augmented by your 
>PQL
>
>head(x)
>   ped id fa mo sex trait locus
>1   1  1 NA NA   m  <NA>   1/2
>2   1  2 NA NA   f  <NA>   1/2
>3   1  3  1  2   f     n   1/2
>4   1  4  1  2   f     y   1/1
>5   1  5  1  2   f     n   1/1
>6   2  6 NA NA   f  <NA>   1/2
>
>
>library(pedigreemm)
>ped <- pedigree(x$fa, x$mo, x$id)
>pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), family=binomial(), 
>data=x)
>pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), 
>family=binomial(link=probit), data=x)
>
>library(AnimalINLA)
>ped2 <- x[,2:4]
>ped2[is.na(ped2)] <- 0
>Ainv <- compute.Ainverse(ped2)
>pheno <- data.frame(id=x$id, trait=(x$trait=="y"), Individual=x$id)
>pheno <- pheno[complete.cases(pheno$trait),]
>m1 <- animal.inla("trait", genetic="id", Ainverse=Ainv, data=pheno, 
>type.data = "binomial")
>summary(m1)
>
>library(MASS)
>library(kinship)
>K <- kinship(x$id, x$fa, x$mo)
>observed <- !is.na(x$trait)
>K <- K[observed, observed]
>cs.K <- corSymm(2*K[lower.tri(K)],fixed=T)
>id <- as.matrix(as.factor(x$id[observed]))
>colnames(id) <- "id"
>cs.K <- Initialize(cs.K,data=id)
>pql1 <- glmmPQL(trait ~ 1, random=~1|id,
>                 correlation=cs.K,
>                 data=x[observed,], family="binomial
>summary(pql1)
>
>library(MCMCglmm)
>pheno <- data.frame(animal=x$id, sire=x$fa, dam=x$mo, y=(x$trait=="y"))
>g1 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
>                family="categorical", data=pheno, verbose=FALSE)
>summary(g1)
>g2 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
>                family="ordinal", data=pheno, verbose=FALSE)
>summary(g2)
>
>-----------------------------
>logistic-normal
>                  RE SD
>pedigreemm       0.847
>AnimalINLA       0.671
>glmmPQL          1.185
>MCMCglmm         1.389
>
>
>-- 
>| David Duffy (MBBS PhD)                                         ,-_|\
>| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From byrnes at nceas.ucsb.edu  Thu Jan 26 17:43:05 2012
From: byrnes at nceas.ucsb.edu (Jarrett Byrnes)
Date: Thu, 26 Jan 2012 11:43:05 -0500
Subject: [R-sig-ME] Visualizing coefficients
Message-ID: <39AA5C0F-39EF-47B2-876F-C16FA484A557@nceas.ucsb.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/591803aa/attachment-0002.pl>

From bbolker at gmail.com  Thu Jan 26 17:46:53 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 26 Jan 2012 11:46:53 -0500
Subject: [R-sig-ME] [R-SIG-Mac] Visualizing coefficients
In-Reply-To: <60BAAAAE-BDA2-42F4-921D-280A09D82D38@nceas.ucsb.edu>
References: <60BAAAAE-BDA2-42F4-921D-280A09D82D38@nceas.ucsb.edu>
Message-ID: <4F21837D.6000803@gmail.com>

On 12-01-26 10:52 AM, Jarrett Byrnes wrote:
> Before I re-invent a well built wheel, has anyone on this list put
> together a good set of functions for visualizing net effects and the
> variation in the estimates for a fitter lmer or glmer model?  I
> realize that this can be done to some extent via simulation and then
> putting the results into coda or R2WinBUGS, but, has anyone gone
> about it via a different route?  I'm also curious to track down other
> resources for visualizing the results of fitted mer objects.
> 
> -Jarrett
> 

  Did you send this to r-sig-mac rather than r-sig-mixed-models by
mistake? [Forwarding to r-sig-mixed-models]

   in addition to John Fox's suggestion of the 'effects' package I would
mention coefplot (in the arm package: Gelman is the first author,
Yu-Sung Su is the maintainer) and coefplot2 (package of the same name).

  Ben



From byrnes at nceas.ucsb.edu  Thu Jan 26 17:52:18 2012
From: byrnes at nceas.ucsb.edu (Jarrett Byrnes)
Date: Thu, 26 Jan 2012 11:52:18 -0500
Subject: [R-sig-ME] [R-SIG-Mac] Visualizing coefficients
In-Reply-To: <4F21837D.6000803@gmail.com>
References: <60BAAAAE-BDA2-42F4-921D-280A09D82D38@nceas.ucsb.edu>
	<4F21837D.6000803@gmail.com>
Message-ID: <1CA350AC-0745-4823-B342-3CDE0AFC7C35@nceas.ucsb.edu>

Yes, it was indeed a mistake.

Do not trust autocomplete.

On Jan 26, 2012, at 11:46 AM, Ben Bolker wrote:

> On 12-01-26 10:52 AM, Jarrett Byrnes wrote:
>> Before I re-invent a well built wheel, has anyone on this list put
>> together a good set of functions for visualizing net effects and the
>> variation in the estimates for a fitter lmer or glmer model?  I
>> realize that this can be done to some extent via simulation and then
>> putting the results into coda or R2WinBUGS, but, has anyone gone
>> about it via a different route?  I'm also curious to track down other
>> resources for visualizing the results of fitted mer objects.
>> 
>> -Jarrett
>> 
> 
>  Did you send this to r-sig-mac rather than r-sig-mixed-models by
> mistake? [Forwarding to r-sig-mixed-models]
> 
>   in addition to John Fox's suggestion of the 'effects' package I would
> mention coefplot (in the arm package: Gelman is the first author,
> Yu-Sung Su is the maintainer) and coefplot2 (package of the same name).
> 
>  Ben



From j.hadfield at ed.ac.uk  Thu Jan 26 18:16:00 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 26 Jan 2012 17:16:00 +0000
Subject: [R-sig-ME] adding a kinship matrix to a GLMM
In-Reply-To: <20120126101045.BDN88330@mstore03.uchicago.edu>
References: <20120124153558.BDK79131@mstore03.uchicago.edu>
	<Pine.LNX.4.64.1201261010410.16419@orpheus.qimr.edu.au>
	<20120126101045.BDN88330@mstore03.uchicago.edu>
Message-ID: <20120126171600.10829954j10so7yo@www.staffmail.ed.ac.uk>

Hi,

Just a quick note on the MCMCglmm syntax: it is best to fix the  
residual variance a priori with binary data since it cannot be  
estimated. In order to make the variance comparable with the other  
methods you also need to rescale by 1/(1+a) for probit models or  
1/(1+c2*a) for logit models where "a" is the residual varaiance (I  
usually fix at one) and c2 is:

((16 * sqrt(3))/(15 * pi))^2

Cheers,

Jarrod


Quoting mhorton at uchicago.edu on Thu, 26 Jan 2012 10:10:45 -0600 (CST):

> Thanks David. I'll see if I can fit a kinship matrix using the other  
> packages you show.
> It would also be great to setup the same test case to see how  
> quickly any of this will
> actually run. I can't do that immediately, but I will try to post  
> the results next week.
>
> ---- Original message ----
>> Date: Thu, 26 Jan 2012 10:33:21 +1000 (EST)
>> From: "David Duffy" <David.Duffy at qimr.edu.au>
>> Subject: Re: [R-sig-ME] adding a kinship matrix to a GLMM
>> To: <mhorton at uchicago.edu>
>> Cc: <r-sig-mixed-models at r-project.org>
>>
>> On Tue, 24 Jan 2012, mhorton at uchicago.edu wrote:
>>
>>> I'm trying this with MASS' glmmPQL, which seems to
>>> allow the user to provide an "an optional correlation structure".
>>>
>>> There are a few classes that extend corStruct, but if I try  
>>> corSymm, things seem
>>> to work with:
>>>
>>> I'm writing to ask is this the best model formulation?
>>> Also, if I add a co-factor 'block', which has 6 levels (subjects  
>>> do not occur in all
>>> blocks), I get a lot of NA errors:
>>> test <- glmmPQL( response ~ snps_i + as.factor(block)+ offset(log(offset)),
>>>          random=~1|subject,correlation=cs.K, family="quasipoisson" );
>>> iteration 1
>>> iteration 2
>>> iteration 3
>>> Error in na.fail.default(list(subject = c(1L, 1L, 1L, 2L, 2L, 2L, 3L,  :
>>>  missing values in object
>>>
>>> Again, is there a better model formula?  Is corSymm even doing  
>>> what I think it is
>>> doing here?
>>
>> I think so.  That error might be arising from incomplete data, as it says
>> (do debug(lme) to see where, as this is what glmmPQL calls).  PQL might
>> not be giving brilliant estimates of the random effects, but I presume you
>> are most interested in snps_1.  Here is one result from a simulation of
>> mine for a binomial trait, using R GLMM packages, augmented by your
>> PQL
>>
>> head(x)
>>   ped id fa mo sex trait locus
>> 1   1  1 NA NA   m  <NA>   1/2
>> 2   1  2 NA NA   f  <NA>   1/2
>> 3   1  3  1  2   f     n   1/2
>> 4   1  4  1  2   f     y   1/1
>> 5   1  5  1  2   f     n   1/1
>> 6   2  6 NA NA   f  <NA>   1/2
>>
>>
>> library(pedigreemm)
>> ped <- pedigree(x$fa, x$mo, x$id)
>> pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped), family=binomial(),
>> data=x)
>> pedigreemm(trait=="y" ~ (1|id), pedigree=list(id=ped),
>> family=binomial(link=probit), data=x)
>>
>> library(AnimalINLA)
>> ped2 <- x[,2:4]
>> ped2[is.na(ped2)] <- 0
>> Ainv <- compute.Ainverse(ped2)
>> pheno <- data.frame(id=x$id, trait=(x$trait=="y"), Individual=x$id)
>> pheno <- pheno[complete.cases(pheno$trait),]
>> m1 <- animal.inla("trait", genetic="id", Ainverse=Ainv, data=pheno,
>> type.data = "binomial")
>> summary(m1)
>>
>> library(MASS)
>> library(kinship)
>> K <- kinship(x$id, x$fa, x$mo)
>> observed <- !is.na(x$trait)
>> K <- K[observed, observed]
>> cs.K <- corSymm(2*K[lower.tri(K)],fixed=T)
>> id <- as.matrix(as.factor(x$id[observed]))
>> colnames(id) <- "id"
>> cs.K <- Initialize(cs.K,data=id)
>> pql1 <- glmmPQL(trait ~ 1, random=~1|id,
>>                 correlation=cs.K,
>>                 data=x[observed,], family="binomial
>> summary(pql1)
>>
>> library(MCMCglmm)
>> pheno <- data.frame(animal=x$id, sire=x$fa, dam=x$mo, y=(x$trait=="y"))
>> g1 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
>>                family="categorical", data=pheno, verbose=FALSE)
>> summary(g1)
>> g2 <- MCMCglmm(y~1, random=~animal, pedigree=pheno[,1:3],
>>                family="ordinal", data=pheno, verbose=FALSE)
>> summary(g2)
>>
>> -----------------------------
>> logistic-normal
>>                  RE SD
>> pedigreemm       0.847
>> AnimalINLA       0.671
>> glmmPQL          1.185
>> MCMCglmm         1.389
>>
>>
>> --
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ramos.grad.student at gmail.com  Thu Jan 26 18:50:19 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 26 Jan 2012 09:50:19 -0800
Subject: [R-sig-ME] [R-SIG-Mac] Visualizing coefficients
In-Reply-To: <1CA350AC-0745-4823-B342-3CDE0AFC7C35@nceas.ucsb.edu>
References: <60BAAAAE-BDA2-42F4-921D-280A09D82D38@nceas.ucsb.edu>
	<4F21837D.6000803@gmail.com>
	<1CA350AC-0745-4823-B342-3CDE0AFC7C35@nceas.ucsb.edu>
Message-ID: <CAHawB9ucMDL89DchNDPy8CsShjFc8E3v92AO2jqY_Jicr88ofQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/190d22ef/attachment-0002.pl>

From bates at stat.wisc.edu  Thu Jan 26 20:03:03 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 26 Jan 2012 13:03:03 -0600
Subject: [R-sig-ME] lme4 and sample size
In-Reply-To: <6C86BD70D72CB449A189A18EED3037CA05803CA7@EXMB2501.ds.umcutrecht.nl>
References: <6C86BD70D72CB449A189A18EED3037CA057EE65B@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnQMJOma-_2SuOGxjN5qiE-uKCNxCrqsokg6d=a1z70rqg@mail.gmail.com>
	<6C86BD70D72CB449A189A18EED3037CA057EE66C@EXMB1501.ds.umcutrecht.nl>
	<CAO7JsnSBCo4exTRgzCaB54udtM0RBQh668zc_NOqXpaRhH93fg@mail.gmail.com>
	<6C86BD70D72CB449A189A18EED3037CA05803CA7@EXMB2501.ds.umcutrecht.nl>
Message-ID: <CAO7JsnSHo7gYuipani3hpdxSfK4Jon4X3yJXASrLh0UZz_68KA@mail.gmail.com>

On Wed, Jan 25, 2012 at 5:02 AM, Bouwmeester, W.
<W.Bouwmeester at umcutrecht.nl> wrote:
> Dear professor Bates,

> Is it possible to put the iteration information in an R object (this is printed when verbose=TRUE in the lmer function)?

> I like to monitor this output during simulations.

About the only way to do that is to use capture.output().  The
information on iterations comes from the optimizer, not from lmer.

> ________________________________________
> Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
> Verzonden: vrijdag 13 januari 2012 17:05
> To: Bouwmeester, W.
> Cc: R-mixed models mailing list
> Onderwerp: Re: lme4 and sample size
>
> On Fri, Jan 13, 2012 at 9:58 AM, Bouwmeester, W.
> <W.Bouwmeester at umcutrecht.nl> wrote:
>> Dear professor Bates,
>>
>> I'am using the lmer function indeed. Can I use 'cvg' from the output attr(model, "dims") to evaluate convergence? (here, the object "model" is fitted with the lmer function)
>
> Yes, but do bear in mind that the cvg indicator is from the optimizer,
> which is nlminb in the case of the released lme4. ?We have encountered
> difficulties with nlminb failing to converge or giving the false
> convergence message or getting stuck at boundary values. ?We later
> switched to the bobyqa optimizer from the minqa package and then to a
> local implementation of the Nelder-Mead simplex optimizer.
>
> Failure to converge is a property of the optimizer being used, not the
> overall design of lme4. ?It happens that good optimizers that are
> available to Open Source projects are difficult to come by.
>
>> Van: dmbates at gmail.com [dmbates at gmail.com] namens Douglas Bates [bates at stat.wisc.edu]
>> Verzonden: vrijdag 13 januari 2012 16:51
>> To: Bouwmeester, W.
>> Onderwerp: Re: lme4 and sample size
>>
>> I have taken the liberty of copying the reply to the
>> R-SIG-Mixed-Models at R-Project.org mailing list so that it will be
>> available in a searchable archive.
>>
>> On Fri, Jan 13, 2012 at 9:37 AM, Bouwmeester, W.
>> <W.Bouwmeester at umcutrecht.nl> wrote:
>>> Dear professor Bates,
>>>
>>> I will incvestigate the required sample size to develop a prediction model in hierarchical data, using a simulation study. One of the model evaluation criteria will be whether the model converged. R will give warning messages if no or singular convergence appeared.
>>> Is it possible to evaluate model convergence from the cvg column in attr(mix.model,"dims")? Has this "cvg" anything to do with convergence?
>>>
>>> I saw this "cvg" output from attr(mix.model, "dims") in your publication on October 4, 2011, Linear mixed model implementation in lme4, page 6 and 20.
>>
>> I would strongly recommend using lmer instead of lme to fit
>> heirarchical linear models in a simulation study. ?The lmer function
>> in the lme4 package is much faster and more reliable than the lme
>> function from the nlme package.
>>
>> The current version of lme4 on CRAN can sometimes encounter a warning
>> about "false convergence". ?The version named lme4Eigen on the R-forge
>> site is, in our preliminary tests, more reliable and usually faster
>> than the released version. ?You do need to be able to build an R
>> package from source to be able to use the lme4Eigen at present.
>> ------------------------------------------------------------------------------
>>
>> De informatie opgenomen in dit bericht kan vertrouwelijk zijn en is
>> uitsluitend bestemd voor de geadresseerde. Indien u dit bericht onterecht
>> ontvangt, wordt u verzocht de inhoud niet te gebruiken en de afzender direct
>> te informeren door het bericht te retourneren. Het Universitair Medisch
>> Centrum Utrecht is een publiekrechtelijke rechtspersoon in de zin van de W.H.W.
>> (Wet Hoger Onderwijs en Wetenschappelijk Onderzoek) en staat geregistreerd bij
>> de Kamer van Koophandel voor Midden-Nederland onder nr. 30244197.
>>
>> Denk s.v.p aan het milieu voor u deze e-mail afdrukt.
>>
>> ------------------------------------------------------------------------------
>>
>> This message may contain confidential information and is intended exclusively
>> for the addressee. If you receive this message unintentionally, please do not
>> use the contents but notify the sender immediately by return e-mail. University
>> Medical Center Utrecht is a legal person by public law and is registered at
>> the Chamber of Commerce for Midden-Nederland under no. 30244197.
>>
>> Please consider the environment before printing this e-mail.



From smccracken at tadpoleorg.org  Thu Jan 26 20:16:12 2012
From: smccracken at tadpoleorg.org (Shawn McCracken)
Date: Thu, 26 Jan 2012 13:16:12 -0600
Subject: [R-sig-ME] GLMM distribution family model comparison using Poisson
 w/observation level random effect
Message-ID: <CAE+9gVGEtv6coOG1Un=pWVKWyd2s=cZQGZv3SeCgMvvENVjbWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/c3232823/attachment-0002.pl>

From john.maindonald at anu.edu.au  Thu Jan 26 23:37:21 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 27 Jan 2012 09:37:21 +1100
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
Message-ID: <7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>

It is not really a matter of computational accuracy.  One can get highly
accurate values for an inappropriate statistic.  

Or if there is insistence on using the word, accuracy, what is the 
meaning?

i) the wrong formula is used?  Then in what sense is it 'wrong'?

ii) there is a numerical inaccuracy in the calculation?  This is almost
never an issue in a relatively simple calculation such as this, given
the care taken by the code writers in such matters.

iii) where an approximation is used, as in using an F-distribution
approximation, is the best choice of degrees of freedom  made to
for use of this approximation?  I judge that the degrees of freedom 
for lme's F-statistic for the interaction are not well chosen.  Users
really have to sort this out for themselves, rather than relying on
what may be a fairly wild approximation that appears in lm's
output.  Using 75df rather than 25df does not however make the 
difference that a choice between (e.g.) 5df and 25df would.

A further and more basic issue is whether the statistic that is 
provided is appropriate to the intended generalisation.  I'd take
this to be generalisation to another sample of youths from the
same population.  In order to understand why R and SAS are 
giving different F-statistics for the interaction, one needs to
understand just what variance-covariance structure is assumed
in each case.  One might extract the two estimates of the 
var-cov structure and compare them. Look for terms in one that
do not appear, or maybe that are zero, in the other.

Finally, it is not just that Venables does not like type III SS.
He is saying that they almost never correspond to a null
hypothesis that makes any sense.  Those who disagree try to 
write down the model to which the null hypothesis corresponds
in testing for the main effect of factor1 with a factor1:factor2
interaction.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 27/01/2012, at 2:41 AM, Thompson,Paul wrote:

> OK, I've looked at that reference. 
> 
> There are 2 aspects of an estimate like a SS. The first is the stability of the estimate, and the second is the interpretation of the estimate. The issues with the interpretation of the different estimates go back to 1970, and they are simply a matter of interpretation. The point of the Venables discussion is that he does not like Type III SS, not that they are wrong. He does not agree with the interpretation.
> 
> The issue here is the accuracy of the Type III or Type I or Type II or whatever. Accuracy comes before interpretation. If the r module and SAS do not arrive at the same estimates, that is an important thing. 
> 
> Once we agree upon computation, we can argue about interpretation. Charles Determan is inquiring as to computational accuracy. The use and interpretation of the various Type I, II, III, IV, LVX SS are secondary.
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
> Sent: Thursday, January 26, 2012 9:03 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
> 
> I think:
> 
> http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
> 
> HTH
> Luca
> 
> 
> 
> Le 26/01/2012 15:52, Thompson,Paul a ?crit :
>> I am unfamiliar with this critique of Type III SS. Can you point me to a reference discussing the difficulties with Type III SS?
>> 
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
>> Sent: Wednesday, January 25, 2012 11:19 PM
>> To: David Duffy
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
>> 
>> It is well to note that type III sums of squares are problematic.
>> For testing the effects of a main effect, the null model is constraining
>> the main effect in a manner that depends on the parameterisation.
>> 
>> There are situations where it makes sense to fit interactions without
>> main effects, and it is clear what constraint on the main effect is the
>> relevant null (with an interaction between a factor and a variable,
>> does one want all lines to go though the same point, or through
>> perhaps the origin?), but that situation is unusual.  For lines that
>> are separate or all through the one point, one does not need
>> type III sums of squares.
>> 
>> Analyses often or frequently have enough genuine complications
>> worrying (unless it is blindingly obvious that one ought to worry
>> about it) without the rarely relevant complication of attending to a
>> type III sum of squares.
>> 
>> I'd guess that SAS and lme are, effectively, making different
>> assumptions about the intended generalisation.  They are
>> clearly using different denominator degrees of freedom for F.
>> As one is looking for consistency across the 27 different youths,
>> SAS's denominator degrees of freedom for the interaction seem
>> more or less right, pretty much equivalent to calculating slopes
>> for females and slopes for males and using a t-test to compare
>> them.  (Sure, in the analyses presented, age has been treated
>> as a categorical variable, but the comment still applies.)
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics&  Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> On 26/01/2012, at 1:54 PM, David Duffy wrote:
>> 
>>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
>>> 
>>>> Greetings,
>>>> 
>>>> I have been working on R for some time now and I have begun the endeavor of
>>>> trying to replicate some SAS code in R.  I have scoured the forums but
>>>> 
>>> This is also the Orthodont dataset, distributed with nlme.
>>> 
>>> As David Atkins pointed out, R defaults to Type I SS. so you would need to use, for example, the Anova() command from the car package.  The other thing is that the SAS F statistics are only approximate, depending on which covariance structure is chosen (perhaps John Maindonald or someone clever could comment), so SAS offers different possibilities for ddf eg
>>> 
>>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
>>> 
>>> while lme and lmer offer one or none.
>>> 
>>> -- 
>>> | David Duffy (MBBS PhD)                                         ,-_|\
>>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> -----------------------------------------------------------------------
>> Confidentiality Notice: This e-mail message, including any attachments,
>> is for the sole use of the intended recipient(s) and may contain
>> privileged and confidential information.  Any unauthorized review, use,
>> disclosure or distribution is prohibited.  If you are not the intended
>> recipient, please contact the sender by reply e-mail and destroy
>> all copies of the original message.
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From deter088 at umn.edu  Fri Jan 27 01:06:45 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 18:06:45 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
Message-ID: <CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/26eaf876/attachment-0002.pl>

From smckinney at bccrc.ca  Fri Jan 27 01:36:15 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 26 Jan 2012 16:36:15 -0800
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>

Since SAS does not publish its source code,
replicating SAS code is not always possible
(nor always desirable).  

R code is completely open, so can be studied,
debated and replicated or modified - very useful when
people want to engage in scientific discussions
of statistical issues.  Doing good science and
data analysis is challenging when you are working with 
a black box of mysterious computer code.  That's
why statisticians have worked so hard for years to
set up open source computational tools such as R.


Steven McKinney
Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Charles Determan Jr
> Sent: January-26-12 4:07 PM
> To: John Maindonald
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in
> R
> 
> The only thing I am looking for is the appropriate R code to replicate the
> SAS analysis shown in the previously mentioned paper.  That is all I ask.
> What should the code be in order to analyze this 'dental' data to replicate
> the 'UN' or 'unstructured' analysis in the prior paper.
> 
> Regards,
> 
> Charles
> 
> On Thu, Jan 26, 2012 at 4:37 PM, John Maindonald
> <john.maindonald at anu.edu.au
> > wrote:
> 
> > It is not really a matter of computational accuracy.  One can get highly
> > accurate values for an inappropriate statistic.
> >
> > Or if there is insistence on using the word, accuracy, what is the
> > meaning?
> >
> > i) the wrong formula is used?  Then in what sense is it 'wrong'?
> >
> > ii) there is a numerical inaccuracy in the calculation?  This is almost
> > never an issue in a relatively simple calculation such as this, given
> > the care taken by the code writers in such matters.
> >
> > iii) where an approximation is used, as in using an F-distribution
> > approximation, is the best choice of degrees of freedom  made to
> > for use of this approximation?  I judge that the degrees of freedom
> > for lme's F-statistic for the interaction are not well chosen.  Users
> > really have to sort this out for themselves, rather than relying on
> > what may be a fairly wild approximation that appears in lm's
> > output.  Using 75df rather than 25df does not however make the
> > difference that a choice between (e.g.) 5df and 25df would.
> >
> > A further and more basic issue is whether the statistic that is
> > provided is appropriate to the intended generalisation.  I'd take
> > this to be generalisation to another sample of youths from the
> > same population.  In order to understand why R and SAS are
> > giving different F-statistics for the interaction, one needs to
> > understand just what variance-covariance structure is assumed
> > in each case.  One might extract the two estimates of the
> > var-cov structure and compare them. Look for terms in one that
> > do not appear, or maybe that are zero, in the other.
> >
> > Finally, it is not just that Venables does not like type III SS.
> > He is saying that they almost never correspond to a null
> > hypothesis that makes any sense.  Those who disagree try to
> > write down the model to which the null hypothesis corresponds
> > in testing for the main effect of factor1 with a factor1:factor2
> > interaction.
> >
> > John Maindonald             email: john.maindonald at anu.edu.au
> > phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> > Centre for Mathematics & Its Applications, Room 1194,
> > John Dedman Mathematical Sciences Building (Building 27)
> > Australian National University, Canberra ACT 0200.
> > http://www.maths.anu.edu.au/~johnm
> >
> > On 27/01/2012, at 2:41 AM, Thompson,Paul wrote:
> >
> > > OK, I've looked at that reference.
> > >
> > > There are 2 aspects of an estimate like a SS. The first is the
> stability
> > of the estimate, and the second is the interpretation of the estimate.
> The
> > issues with the interpretation of the different estimates go back to
> 1970,
> > and they are simply a matter of interpretation. The point of the Venables
> > discussion is that he does not like Type III SS, not that they are wrong.
> > He does not agree with the interpretation.
> > >
> > > The issue here is the accuracy of the Type III or Type I or Type II or
> > whatever. Accuracy comes before interpretation. If the r module and SAS
> do
> > not arrive at the same estimates, that is an important thing.
> > >
> > > Once we agree upon computation, we can argue about interpretation.
> > Charles Determan is inquiring as to computational accuracy. The use and
> > interpretation of the various Type I, II, III, IV, LVX SS are secondary.
> > >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
> > > Sent: Thursday, January 26, 2012 9:03 AM
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
> Procedure
> > in R
> > >
> > > I think:
> > >
> > > http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
> > >
> > > HTH
> > > Luca
> > >
> > >
> > >
> > > Le 26/01/2012 15:52, Thompson,Paul a ?crit :
> > >> I am unfamiliar with this critique of Type III SS. Can you point me to
> > a reference discussing the difficulties with Type III SS?
> > >>
> > >> -----Original Message-----
> > >> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
> > >> Sent: Wednesday, January 25, 2012 11:19 PM
> > >> To: David Duffy
> > >> Cc: r-sig-mixed-models at r-project.org
> > >> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
> > Procedure in R
> > >>
> > >> It is well to note that type III sums of squares are problematic.
> > >> For testing the effects of a main effect, the null model is
> constraining
> > >> the main effect in a manner that depends on the parameterisation.
> > >>
> > >> There are situations where it makes sense to fit interactions without
> > >> main effects, and it is clear what constraint on the main effect is
> the
> > >> relevant null (with an interaction between a factor and a variable,
> > >> does one want all lines to go though the same point, or through
> > >> perhaps the origin?), but that situation is unusual.  For lines that
> > >> are separate or all through the one point, one does not need
> > >> type III sums of squares.
> > >>
> > >> Analyses often or frequently have enough genuine complications
> > >> worrying (unless it is blindingly obvious that one ought to worry
> > >> about it) without the rarely relevant complication of attending to a
> > >> type III sum of squares.
> > >>
> > >> I'd guess that SAS and lme are, effectively, making different
> > >> assumptions about the intended generalisation.  They are
> > >> clearly using different denominator degrees of freedom for F.
> > >> As one is looking for consistency across the 27 different youths,
> > >> SAS's denominator degrees of freedom for the interaction seem
> > >> more or less right, pretty much equivalent to calculating slopes
> > >> for females and slopes for males and using a t-test to compare
> > >> them.  (Sure, in the analyses presented, age has been treated
> > >> as a categorical variable, but the comment still applies.)
> > >>
> > >> John Maindonald             email: john.maindonald at anu.edu.au
> > >> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> > >> Centre for Mathematics&  Its Applications, Room 1194,
> > >> John Dedman Mathematical Sciences Building (Building 27)
> > >> Australian National University, Canberra ACT 0200.
> > >> http://www.maths.anu.edu.au/~johnm
> > >>
> > >> On 26/01/2012, at 1:54 PM, David Duffy wrote:
> > >>
> > >>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
> > >>>
> > >>>> Greetings,
> > >>>>
> > >>>> I have been working on R for some time now and I have begun the
> > endeavor of
> > >>>> trying to replicate some SAS code in R.  I have scoured the forums
> but
> > >>>>
> > >>> This is also the Orthodont dataset, distributed with nlme.
> > >>>
> > >>> As David Atkins pointed out, R defaults to Type I SS. so you would
> > need to use, for example, the Anova() command from the car package.  The
> > other thing is that the SAS F statistics are only approximate, depending
> on
> > which covariance structure is chosen (perhaps John Maindonald or someone
> > clever could comment), so SAS offers different possibilities for ddf eg
> > >>>
> > >>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
> > >>>
> > >>> while lme and lmer offer one or none.
> > >>>
> > >>> --
> > >>> | David Duffy (MBBS PhD)                                         ,-
> _|\
> > >>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /
> > *
> > >>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-
> ._/
> > >>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A
> v
> > >>>
> > >>> _______________________________________________
> > >>> R-sig-mixed-models at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >> ----------------------------------------------------------------------
> -
> > >> Confidentiality Notice: This e-mail message, including any
> attachments,
> > >> is for the sole use of the intended recipient(s) and may contain
> > >> privileged and confidential information.  Any unauthorized review,
> use,
> > >> disclosure or distribution is prohibited.  If you are not the intended
> > >> recipient, please contact the sender by reply e-mail and destroy
> > >> all copies of the original message.
> > >>
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >>
> > >>
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > -----------------------------------------------------------------------
> > > Confidentiality Notice: This e-mail message, including any attachments,
> > > is for the sole use of the intended recipient(s) and may contain
> > > privileged and confidential information.  Any unauthorized review, use,
> > > disclosure or distribution is prohibited.  If you are not the intended
> > > recipient, please contact the sender by reply e-mail and destroy
> > > all copies of the original message.
> > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 	[[alternative HTML version deleted]]



From deter088 at umn.edu  Fri Jan 27 01:50:26 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 18:50:26 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
Message-ID: <CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/4adecd42/attachment-0002.pl>

From smckinney at bccrc.ca  Fri Jan 27 02:20:53 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 26 Jan 2012 17:20:53 -0800
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
	<CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>

Here's a typical agreement that users of SAS must agree to:


Subject to the provisions contained herein, EMPLOYEE may use the SAS copyrighted computer software products which LICENSEE has provided in accordance with its agreement with SAS.

EMPLOYEE acknowledges that these products are copyrighted and that SAS retains all title and ownership rights to the products.  EMPLOYEE agrees not to copy or permit others to copy the products, in whole or in part.

EMPLOYEE agrees to use the products under this agreement only on a computer which is owned or leased by LICENSEE and controlled by LICENSEE.  EMPLOYEE further agrees that the products must remain under EMPLOYEE's control, and that resale or other transfer is explicitly prohibited.

EMPLOYEE agrees to use the products only for EMPLOYEE's or LICENSEE's own data processing requirements, and not for commercial time-sharing, rental or service bureau use.

EMPLOYEE agrees not to create, or attempt to create, or permit or help others to create, the source code from the products furnished under this agreement.  EMPLOYEE agrees that it will not reverse engineer or decompile the products.


(source: http://www.mcmaster.ca/uts/software_downloads/docs/SAS/saslicendform.doc )

Note that last paragraph.  You can find it in other SAS end user license agreements.

So anyone who tries to "replicate PROC MIXED for repeated measures set as unstructured in R"
is then subject to legal action by the largest wealthiest statistical software company ever in
existence.  I personally am not up for that challenge, especially when the code has
debateable merits.

I'd rather write code from scratch using sound statistical first principles,
which I can do thanks to the amazing amount of hard work by the R core group,
none of whom have ever asked me to sign any agreement (though they do insist
that I distribute source code and the GNU General Public License with any
copies I modify and/or distribute).


Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre




From: Charles Determan Jr [mailto:deter088 at umn.edu]
Sent: January-26-12 4:50 PM
To: Steven McKinney
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R

So am I to assume that this implies that there isn't any known way to replicate PROC MIXED for repeated measures set as unstructured in R?

Charles
On Thu, Jan 26, 2012 at 6:36 PM, Steven McKinney <smckinney at bccrc.ca> wrote:
Since SAS does not publish its source code,
replicating SAS code is not always possible
(nor always desirable).

R code is completely open, so can be studied,
debated and replicated or modified - very useful when
people want to engage in scientific discussions
of statistical issues.  Doing good science and
data analysis is challenging when you are working with
a black box of mysterious computer code.  That's
why statisticians have worked so hard for years to
set up open source computational tools such as R.


Steven McKinney
Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Charles Determan Jr
> Sent: January-26-12 4:07 PM
> To: John Maindonald
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in
> R
>
> The only thing I am looking for is the appropriate R code to replicate the
> SAS analysis shown in the previously mentioned paper.  That is all I ask.
> What should the code be in order to analyze this 'dental' data to replicate
> the 'UN' or 'unstructured' analysis in the prior paper.
>
> Regards,
>
> Charles
>
> On Thu, Jan 26, 2012 at 4:37 PM, John Maindonald
> <john.maindonald at anu.edu.au
> > wrote:
>
> > It is not really a matter of computational accuracy.  One can get highly
> > accurate values for an inappropriate statistic.
> >
> > Or if there is insistence on using the word, accuracy, what is the
> > meaning?
> >
> > i) the wrong formula is used?  Then in what sense is it 'wrong'?
> >
> > ii) there is a numerical inaccuracy in the calculation?  This is almost
> > never an issue in a relatively simple calculation such as this, given
> > the care taken by the code writers in such matters.
> >
> > iii) where an approximation is used, as in using an F-distribution
> > approximation, is the best choice of degrees of freedom  made to
> > for use of this approximation?  I judge that the degrees of freedom
> > for lme's F-statistic for the interaction are not well chosen.  Users
> > really have to sort this out for themselves, rather than relying on
> > what may be a fairly wild approximation that appears in lm's
> > output.  Using 75df rather than 25df does not however make the
> > difference that a choice between (e.g.) 5df and 25df would.
> >
> > A further and more basic issue is whether the statistic that is
> > provided is appropriate to the intended generalisation.  I'd take
> > this to be generalisation to another sample of youths from the
> > same population.  In order to understand why R and SAS are
> > giving different F-statistics for the interaction, one needs to
> > understand just what variance-covariance structure is assumed
> > in each case.  One might extract the two estimates of the
> > var-cov structure and compare them. Look for terms in one that
> > do not appear, or maybe that are zero, in the other.
> >
> > Finally, it is not just that Venables does not like type III SS.
> > He is saying that they almost never correspond to a null
> > hypothesis that makes any sense.  Those who disagree try to
> > write down the model to which the null hypothesis corresponds
> > in testing for the main effect of factor1 with a factor1:factor2
> > interaction.
> >
> > John Maindonald             email: john.maindonald at anu.edu.au
> > phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> > Centre for Mathematics & Its Applications, Room 1194,
> > John Dedman Mathematical Sciences Building (Building 27)
> > Australian National University, Canberra ACT 0200.
> > http://www.maths.anu.edu.au/~johnm
> >
> > On 27/01/2012, at 2:41 AM, Thompson,Paul wrote:
> >
> > > OK, I've looked at that reference.
> > >
> > > There are 2 aspects of an estimate like a SS. The first is the
> stability
> > of the estimate, and the second is the interpretation of the estimate.
> The
> > issues with the interpretation of the different estimates go back to
> 1970,
> > and they are simply a matter of interpretation. The point of the Venables
> > discussion is that he does not like Type III SS, not that they are wrong.
> > He does not agree with the interpretation.
> > >
> > > The issue here is the accuracy of the Type III or Type I or Type II or
> > whatever. Accuracy comes before interpretation. If the r module and SAS
> do
> > not arrive at the same estimates, that is an important thing.
> > >
> > > Once we agree upon computation, we can argue about interpretation.
> > Charles Determan is inquiring as to computational accuracy. The use and
> > interpretation of the various Type I, II, III, IV, LVX SS are secondary.
> > >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
> > > Sent: Thursday, January 26, 2012 9:03 AM
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
> Procedure
> > in R
> > >
> > > I think:
> > >
> > > http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
> > >
> > > HTH
> > > Luca
> > >
> > >
> > >
> > > Le 26/01/2012 15:52, Thompson,Paul a ?crit :
> > >> I am unfamiliar with this critique of Type III SS. Can you point me to
> > a reference discussing the difficulties with Type III SS?
> > >>
> > >> -----Original Message-----
> > >> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
> > >> Sent: Wednesday, January 25, 2012 11:19 PM
> > >> To: David Duffy
> > >> Cc: r-sig-mixed-models at r-project.org
> > >> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
> > Procedure in R
> > >>
> > >> It is well to note that type III sums of squares are problematic.
> > >> For testing the effects of a main effect, the null model is
> constraining
> > >> the main effect in a manner that depends on the parameterisation.
> > >>
> > >> There are situations where it makes sense to fit interactions without
> > >> main effects, and it is clear what constraint on the main effect is
> the
> > >> relevant null (with an interaction between a factor and a variable,
> > >> does one want all lines to go though the same point, or through
> > >> perhaps the origin?), but that situation is unusual.  For lines that
> > >> are separate or all through the one point, one does not need
> > >> type III sums of squares.
> > >>
> > >> Analyses often or frequently have enough genuine complications
> > >> worrying (unless it is blindingly obvious that one ought to worry
> > >> about it) without the rarely relevant complication of attending to a
> > >> type III sum of squares.
> > >>
> > >> I'd guess that SAS and lme are, effectively, making different
> > >> assumptions about the intended generalisation.  They are
> > >> clearly using different denominator degrees of freedom for F.
> > >> As one is looking for consistency across the 27 different youths,
> > >> SAS's denominator degrees of freedom for the interaction seem
> > >> more or less right, pretty much equivalent to calculating slopes
> > >> for females and slopes for males and using a t-test to compare
> > >> them.  (Sure, in the analyses presented, age has been treated
> > >> as a categorical variable, but the comment still applies.)
> > >>
> > >> John Maindonald             email: john.maindonald at anu.edu.au
> > >> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> > >> Centre for Mathematics&  Its Applications, Room 1194,
> > >> John Dedman Mathematical Sciences Building (Building 27)
> > >> Australian National University, Canberra ACT 0200.
> > >> http://www.maths.anu.edu.au/~johnm
> > >>
> > >> On 26/01/2012, at 1:54 PM, David Duffy wrote:
> > >>
> > >>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
> > >>>
> > >>>> Greetings,
> > >>>>
> > >>>> I have been working on R for some time now and I have begun the
> > endeavor of
> > >>>> trying to replicate some SAS code in R.  I have scoured the forums
> but
> > >>>>
> > >>> This is also the Orthodont dataset, distributed with nlme.
> > >>>
> > >>> As David Atkins pointed out, R defaults to Type I SS. so you would
> > need to use, for example, the Anova() command from the car package.  The
> > other thing is that the SAS F statistics are only approximate, depending
> on
> > which covariance structure is chosen (perhaps John Maindonald or someone
> > clever could comment), so SAS offers different possibilities for ddf eg
> > >>>
> > >>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
> > >>>
> > >>> while lme and lmer offer one or none.
> > >>>
> > >>> --
> > >>> | David Duffy (MBBS PhD)                                         ,-
> _|\
> > >>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /
> > *
> > >>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-
> ._/
> > >>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A
> v
> > >>>
> > >>> _______________________________________________
> > >>> R-sig-mixed-models at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >> ----------------------------------------------------------------------
> -
> > >> Confidentiality Notice: This e-mail message, including any
> attachments,
> > >> is for the sole use of the intended recipient(s) and may contain
> > >> privileged and confidential information.  Any unauthorized review,
> use,
> > >> disclosure or distribution is prohibited.  If you are not the intended
> > >> recipient, please contact the sender by reply e-mail and destroy
> > >> all copies of the original message.
> > >>
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >>
> > >>
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > -----------------------------------------------------------------------
> > > Confidentiality Notice: This e-mail message, including any attachments,
> > > is for the sole use of the intended recipient(s) and may contain
> > > privileged and confidential information.  Any unauthorized review, use,
> > > disclosure or distribution is prohibited.  If you are not the intended
> > > recipient, please contact the sender by reply e-mail and destroy
> > > all copies of the original message.
> > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>       [[alternative HTML version deleted]]



From deter088 at umn.edu  Fri Jan 27 02:37:30 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 19:37:30 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
	<CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
Message-ID: <CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/fceb609f/attachment-0002.pl>

From mbrooks at ufl.edu  Fri Jan 27 02:45:13 2012
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Thu, 26 Jan 2012 20:45:13 -0500
Subject: [R-sig-ME] GLMM distribution family model comparison using
	Poisson w/observation level random effect
In-Reply-To: <mailman.268.1327622817.4475.r-sig-mixed-models@r-project.org>
References: <mailman.268.1327622817.4475.r-sig-mixed-models@r-project.org>
Message-ID: <BCC5E2AB-FC36-4B3A-B339-C6111292A41A@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/72d75ca2/attachment-0002.pl>

From David.Duffy at qimr.edu.au  Fri Jan 27 03:21:47 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 27 Jan 2012 12:21:47 +1000 (EST)
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com><Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au><1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au><9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org><4F216B18.6030405@cebc.cnrs.fr><9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org><7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au><20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com><DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA><CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com><DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
	<CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1201271217010.18082@orpheus.qimr.edu.au>

On Thu, 26 Jan 2012, Charles Determan Jr wrote:

> I see, thank you Steven for your response.  Perhaps I should start a new
> question on here for what people would recommend currently in R for
> analyzing a repeated measures data set.

If you Google on "Orthodont" and R, you will find several analyses of this 
dataset, including one in John Maindonald's book.  In those analyses, age 
has been treated as a continuous covariate, rather than the SAS example's 
approach.



-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From jwiley.psych at gmail.com  Fri Jan 27 04:11:22 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 26 Jan 2012 19:11:22 -0800
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
	<CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
	<CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
Message-ID: <CANz9Z_KLX9J=2D9w2Jncswu9B43J8UX67cOY5i2ibQ7c-9h9FQ@mail.gmail.com>

Hi Charles,

Caveat emptor: I have not read John Maindonalds analysis of this data.
 There may well be problems with this, but here are some of the things
I would try with the data.

By the way, if you want us to help you fit the same model as SAS, it
would help to know what SAS is fitting.  If you could provide the
formula for the model and covariance structure, that would help.  If
you do not know, perhaps first try to replicate in SAS using something
more explicit than the 'repeated' option.

Cheers,

Josh

dat <- structure(list(distance = c(26, 25, 29, 31, 21.5, 22.5, 23, 26.5,
23, 22.5, 24, 27.5, 25.5, 27.5, 26.5, 27, 20, 23.5, 22.5, 26,
24.5, 25.5, 27, 28.5, 22, 22, 24.5, 26.5, 24, 21.5, 24.5, 25.5,
23, 20.5, 31, 26, 27.5, 28, 31, 31.5, 23, 23, 23.5, 25, 21.5,
23.5, 24, 28, 17, 24.5, 26, 29.5, 22.5, 25.5, 25.5, 26, 23, 24.5,
26, 30, 22, 21.5, 23.5, 25, 21, 20, 21.5, 23, 21, 21.5, 24, 25.5,
20.5, 24, 24.5, 26, 23.5, 24.5, 25, 26.5, 21.5, 23, 22.5, 23.5,
20, 21, 21, 22.5, 21.5, 22.5, 23, 25, 23, 23, 23.5, 24, 20, 21,
22, 21.5, 16.5, 19, 19, 19.5, 24.5, 25, 28, 28), age = c(8L,
10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L,
12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L,
14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L,
8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L,
10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L,
12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L,
14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L,
8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L, 10L, 12L, 14L, 8L,
10L, 12L, 14L), Subject = structure(c(12L, 12L, 12L, 12L, 13L,
13L, 13L, 13L, 14L, 14L, 14L, 14L, 15L, 15L, 15L, 15L, 16L, 16L,
16L, 16L, 17L, 17L, 17L, 17L, 18L, 18L, 18L, 18L, 19L, 19L, 19L,
19L, 20L, 20L, 20L, 20L, 21L, 21L, 21L, 21L, 22L, 22L, 22L, 22L,
23L, 23L, 23L, 23L, 24L, 24L, 24L, 24L, 25L, 25L, 25L, 25L, 26L,
26L, 26L, 26L, 27L, 27L, 27L, 27L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L,
6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L,
10L, 10L, 11L, 11L, 11L, 11L), .Label = c("F01", "F02", "F03",
"F04", "F05", "F06", "F07", "F08", "F09", "F10", "F11", "M01",
"M02", "M03", "M04", "M05", "M06", "M07", "M08", "M09", "M10",
"M11", "M12", "M13", "M14", "M15", "M16"), class = "factor"),
    Sex = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("Female", "Male"
    ), class = "factor")), .Names = c("distance", "age", "Subject",
"Sex"), class = "data.frame", row.names = c("1", "2", "3", "4",
"5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15",
"16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26",
"27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37",
"38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48",
"49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59",
"60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "70",
"71", "72", "73", "74", "75", "76", "77", "78", "79", "80", "81",
"82", "83", "84", "85", "86", "87", "88", "89", "90", "91", "92",
"93", "94", "95", "96", "97", "98", "99", "100", "101", "102",
"103", "104", "105", "106", "107", "108"))

require(ggplot2)
require(mgcv)

## intercepts and slopes seem different between sexes
## but there is no evidence of a nonlinear relationship between
## age and distance
ggplot(dat, aes(x = age, y = distance, colour = Sex)) +
  geom_point() +
  stat_smooth(method = "gam", formula = y ~ s(x))

## reorder data by initial distance value
dat$Subject <- with(dat, reorder(Subject,
  distance[ifelse(age == min(age), TRUE, NA)],
  FUN = mean, na.rm = TRUE))

## slight evidence that lower intercepts may be
## associated with more positive slopes
ggplot(dat, aes(x = age, y = distance, colour = Sex)) +
  geom_point() +
  stat_smooth(method = "gam", formula = y ~ s(x)) +
  facet_wrap(~ Subject)

## lme4 package for mixed effects models
require(lme4)

mnull <- lmer(distance ~ 1 + (1 | Subject), data = dat)
m1 <- update(mnull, . ~ . + age * Sex)
m2 <- update(m2, . ~ . + (0 + age | Subject))
m3 <- lmer(distance ~ age * Sex + (1 + age | Subject), data = dat)

## compare different models, m1 seems good
anova(mnull, m1, m2, m3)

plot(dat$distance, fitted(m1))

## examine residuals and random effects
qqnorm(resid(m1))
plot(dat$age, resid(m1))
qqnorm(ranef(m1)$Subject[,1])

## view the summary
summary(m1)
## Linear mixed model fit by REML
## Formula: distance ~ (1 | Subject) + age + Sex + age:Sex
##    Data: dat
##    AIC   BIC logLik deviance REMLdev
##  445.8 461.9 -216.9    428.7   433.8
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Subject  (Intercept) 3.2986   1.8162
##  Residual             1.9221   1.3864
## Number of obs: 108, groups: Subject, 27

## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 17.37273    1.18349  14.679
## age          0.47955    0.09347   5.130
## SexMale     -1.03210    1.53740  -0.671
## age:SexMale  0.30483    0.12142   2.511

## Correlation of Fixed Effects:
##             (Intr) age    SexMal
## age         -0.869
## SexMale     -0.770  0.669
## age:SexMale  0.669 -0.770 -0.869


On Thu, Jan 26, 2012 at 5:37 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> I see, thank you Steven for your response. ?Perhaps I should start a new
> question on here for what people would recommend currently in R for
> analyzing a repeated measures data set. ?Would that be an appropriate
> request without infringing upon any possible legal ramifications? ?Perhaps
> there is a slightly different method that is built on 'sound statistical
> first principles'. ?Or does anyone currently following this thread know an
> appropriate repeated measures analysis of this 'dental' data that would be
> similar to the SAS results?
>
> Charles
>
> On Thu, Jan 26, 2012 at 7:20 PM, Steven McKinney <smckinney at bccrc.ca> wrote:
>
>> Here's a typical agreement that users of SAS must agree to:
>>
>>
>> Subject to the provisions contained herein, EMPLOYEE may use the SAS
>> copyrighted computer software products which LICENSEE has provided in
>> accordance with its agreement with SAS.
>>
>> EMPLOYEE acknowledges that these products are copyrighted and that SAS
>> retains all title and ownership rights to the products. ?EMPLOYEE agrees
>> not to copy or permit others to copy the products, in whole or in part.
>>
>> EMPLOYEE agrees to use the products under this agreement only on a
>> computer which is owned or leased by LICENSEE and controlled by LICENSEE.
>> ?EMPLOYEE further agrees that the products must remain under EMPLOYEE's
>> control, and that resale or other transfer is explicitly prohibited.
>>
>> EMPLOYEE agrees to use the products only for EMPLOYEE's or LICENSEE's own
>> data processing requirements, and not for commercial time-sharing, rental
>> or service bureau use.
>>
>> EMPLOYEE agrees not to create, or attempt to create, or permit or help
>> others to create, the source code from the products furnished under this
>> agreement. ?EMPLOYEE agrees that it will not reverse engineer or decompile
>> the products.
>>
>>
>> (source:
>> http://www.mcmaster.ca/uts/software_downloads/docs/SAS/saslicendform.doc )
>>
>> Note that last paragraph. ?You can find it in other SAS end user license
>> agreements.
>>
>> So anyone who tries to "replicate PROC MIXED for repeated measures set as
>> unstructured in R"
>> is then subject to legal action by the largest wealthiest statistical
>> software company ever in
>> existence. ?I personally am not up for that challenge, especially when the
>> code has
>> debateable merits.
>>
>> I'd rather write code from scratch using sound statistical first
>> principles,
>> which I can do thanks to the amazing amount of hard work by the R core
>> group,
>> none of whom have ever asked me to sign any agreement (though they do
>> insist
>> that I distribute source code and the GNU General Public License with any
>> copies I modify and/or distribute).
>>
>>
>> Steven McKinney
>>
>> Statistician
>> Molecular Oncology and Breast Cancer Program
>> British Columbia Cancer Research Centre
>>
>>
>>
>>
>> From: Charles Determan Jr [mailto:deter088 at umn.edu]
>> Sent: January-26-12 4:50 PM
>> To: Steven McKinney
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure
>> in R
>>
>> So am I to assume that this implies that there isn't any known way to
>> replicate PROC MIXED for repeated measures set as unstructured in R?
>>
>> Charles
>> On Thu, Jan 26, 2012 at 6:36 PM, Steven McKinney <smckinney at bccrc.ca>
>> wrote:
>> Since SAS does not publish its source code,
>> replicating SAS code is not always possible
>> (nor always desirable).
>>
>> R code is completely open, so can be studied,
>> debated and replicated or modified - very useful when
>> people want to engage in scientific discussions
>> of statistical issues. ?Doing good science and
>> data analysis is challenging when you are working with
>> a black box of mysterious computer code. ?That's
>> why statisticians have worked so hard for years to
>> set up open source computational tools such as R.
>>
>>
>> Steven McKinney
>> Statistician
>> Molecular Oncology and Breast Cancer Program
>> British Columbia Cancer Research Centre
>>
>> > -----Original Message-----
>> > From: r-sig-mixed-models-bounces at r-project.org [mailto:
>> r-sig-mixed-models-
>> > bounces at r-project.org] On Behalf Of Charles Determan Jr
>> > Sent: January-26-12 4:07 PM
>> > To: John Maindonald
>> > Cc: r-sig-mixed-models at r-project.org
>> > Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure
>> in
>> > R
>> >
>> > The only thing I am looking for is the appropriate R code to replicate
>> the
>> > SAS analysis shown in the previously mentioned paper. ?That is all I ask.
>> > What should the code be in order to analyze this 'dental' data to
>> replicate
>> > the 'UN' or 'unstructured' analysis in the prior paper.
>> >
>> > Regards,
>> >
>> > Charles
>> >
>> > On Thu, Jan 26, 2012 at 4:37 PM, John Maindonald
>> > <john.maindonald at anu.edu.au
>> > > wrote:
>> >
>> > > It is not really a matter of computational accuracy. ?One can get
>> highly
>> > > accurate values for an inappropriate statistic.
>> > >
>> > > Or if there is insistence on using the word, accuracy, what is the
>> > > meaning?
>> > >
>> > > i) the wrong formula is used? ?Then in what sense is it 'wrong'?
>> > >
>> > > ii) there is a numerical inaccuracy in the calculation? ?This is almost
>> > > never an issue in a relatively simple calculation such as this, given
>> > > the care taken by the code writers in such matters.
>> > >
>> > > iii) where an approximation is used, as in using an F-distribution
>> > > approximation, is the best choice of degrees of freedom ?made to
>> > > for use of this approximation? ?I judge that the degrees of freedom
>> > > for lme's F-statistic for the interaction are not well chosen. ?Users
>> > > really have to sort this out for themselves, rather than relying on
>> > > what may be a fairly wild approximation that appears in lm's
>> > > output. ?Using 75df rather than 25df does not however make the
>> > > difference that a choice between (e.g.) 5df and 25df would.
>> > >
>> > > A further and more basic issue is whether the statistic that is
>> > > provided is appropriate to the intended generalisation. ?I'd take
>> > > this to be generalisation to another sample of youths from the
>> > > same population. ?In order to understand why R and SAS are
>> > > giving different F-statistics for the interaction, one needs to
>> > > understand just what variance-covariance structure is assumed
>> > > in each case. ?One might extract the two estimates of the
>> > > var-cov structure and compare them. Look for terms in one that
>> > > do not appear, or maybe that are zero, in the other.
>> > >
>> > > Finally, it is not just that Venables does not like type III SS.
>> > > He is saying that they almost never correspond to a null
>> > > hypothesis that makes any sense. ?Those who disagree try to
>> > > write down the model to which the null hypothesis corresponds
>> > > in testing for the main effect of factor1 with a factor1:factor2
>> > > interaction.
>> > >
>> > > John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>> > > phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>> > > Centre for Mathematics & Its Applications, Room 1194,
>> > > John Dedman Mathematical Sciences Building (Building 27)
>> > > Australian National University, Canberra ACT 0200.
>> > > http://www.maths.anu.edu.au/~johnm
>> > >
>> > > On 27/01/2012, at 2:41 AM, Thompson,Paul wrote:
>> > >
>> > > > OK, I've looked at that reference.
>> > > >
>> > > > There are 2 aspects of an estimate like a SS. The first is the
>> > stability
>> > > of the estimate, and the second is the interpretation of the estimate.
>> > The
>> > > issues with the interpretation of the different estimates go back to
>> > 1970,
>> > > and they are simply a matter of interpretation. The point of the
>> Venables
>> > > discussion is that he does not like Type III SS, not that they are
>> wrong.
>> > > He does not agree with the interpretation.
>> > > >
>> > > > The issue here is the accuracy of the Type III or Type I or Type II
>> or
>> > > whatever. Accuracy comes before interpretation. If the r module and SAS
>> > do
>> > > not arrive at the same estimates, that is an important thing.
>> > > >
>> > > > Once we agree upon computation, we can argue about interpretation.
>> > > Charles Determan is inquiring as to computational accuracy. The use and
>> > > interpretation of the various Type I, II, III, IV, LVX SS are
>> secondary.
>> > > >
>> > > > -----Original Message-----
>> > > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
>> > > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
>> > > > Sent: Thursday, January 26, 2012 9:03 AM
>> > > > To: r-sig-mixed-models at r-project.org
>> > > > Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
>> > Procedure
>> > > in R
>> > > >
>> > > > I think:
>> > > >
>> > > > http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
>> > > >
>> > > > HTH
>> > > > Luca
>> > > >
>> > > >
>> > > >
>> > > > Le 26/01/2012 15:52, Thompson,Paul a ?crit :
>> > > >> I am unfamiliar with this critique of Type III SS. Can you point me
>> to
>> > > a reference discussing the difficulties with Type III SS?
>> > > >>
>> > > >> -----Original Message-----
>> > > >> From: r-sig-mixed-models-bounces at r-project.org [mailto:
>> > > r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
>> > > >> Sent: Wednesday, January 25, 2012 11:19 PM
>> > > >> To: David Duffy
>> > > >> Cc: r-sig-mixed-models at r-project.org
>> > > >> Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed
>> > > Procedure in R
>> > > >>
>> > > >> It is well to note that type III sums of squares are problematic.
>> > > >> For testing the effects of a main effect, the null model is
>> > constraining
>> > > >> the main effect in a manner that depends on the parameterisation.
>> > > >>
>> > > >> There are situations where it makes sense to fit interactions
>> without
>> > > >> main effects, and it is clear what constraint on the main effect is
>> > the
>> > > >> relevant null (with an interaction between a factor and a variable,
>> > > >> does one want all lines to go though the same point, or through
>> > > >> perhaps the origin?), but that situation is unusual. ?For lines that
>> > > >> are separate or all through the one point, one does not need
>> > > >> type III sums of squares.
>> > > >>
>> > > >> Analyses often or frequently have enough genuine complications
>> > > >> worrying (unless it is blindingly obvious that one ought to worry
>> > > >> about it) without the rarely relevant complication of attending to a
>> > > >> type III sum of squares.
>> > > >>
>> > > >> I'd guess that SAS and lme are, effectively, making different
>> > > >> assumptions about the intended generalisation. ?They are
>> > > >> clearly using different denominator degrees of freedom for F.
>> > > >> As one is looking for consistency across the 27 different youths,
>> > > >> SAS's denominator degrees of freedom for the interaction seem
>> > > >> more or less right, pretty much equivalent to calculating slopes
>> > > >> for females and slopes for males and using a t-test to compare
>> > > >> them. ?(Sure, in the analyses presented, age has been treated
>> > > >> as a categorical variable, but the comment still applies.)
>> > > >>
>> > > >> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>> > > >> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>> > > >> Centre for Mathematics& ?Its Applications, Room 1194,
>> > > >> John Dedman Mathematical Sciences Building (Building 27)
>> > > >> Australian National University, Canberra ACT 0200.
>> > > >> http://www.maths.anu.edu.au/~johnm
>> > > >>
>> > > >> On 26/01/2012, at 1:54 PM, David Duffy wrote:
>> > > >>
>> > > >>> On Tue, 24 Jan 2012, Charles Determan Jr wrote:
>> > > >>>
>> > > >>>> Greetings,
>> > > >>>>
>> > > >>>> I have been working on R for some time now and I have begun the
>> > > endeavor of
>> > > >>>> trying to replicate some SAS code in R. ?I have scoured the forums
>> > but
>> > > >>>>
>> > > >>> This is also the Orthodont dataset, distributed with nlme.
>> > > >>>
>> > > >>> As David Atkins pointed out, R defaults to Type I SS. so you would
>> > > need to use, for example, the Anova() command from the car package.
>> ?The
>> > > other thing is that the SAS F statistics are only approximate,
>> depending
>> > on
>> > > which covariance structure is chosen (perhaps John Maindonald or
>> someone
>> > > clever could comment), so SAS offers different possibilities for ddf eg
>> > > >>>
>> > > >>> http://www2.sas.com/proceedings/sugi26/p262-26.pdf
>> > > >>>
>> > > >>> while lme and lmer offer one or none.
>> > > >>>
>> > > >>> --
>> > > >>> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-
>> > _|\
>> > > >>> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/
>> > > *
>> > > >>> | Epidemiology Unit, Queensland Institute of Medical Research
>> \_,-
>> > ._/
>> > > >>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG
>> 4D0B994A
>> > v
>> > > >>>
>> > > >>> _______________________________________________
>> > > >>> R-sig-mixed-models at r-project.org mailing list
>> > > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > > >> _______________________________________________
>> > > >> R-sig-mixed-models at r-project.org mailing list
>> > > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > > >>
>> > > >>
>> ----------------------------------------------------------------------
>> > -
>> > > >> Confidentiality Notice: This e-mail message, including any
>> > attachments,
>> > > >> is for the sole use of the intended recipient(s) and may contain
>> > > >> privileged and confidential information. ?Any unauthorized review,
>> > use,
>> > > >> disclosure or distribution is prohibited. ?If you are not the
>> intended
>> > > >> recipient, please contact the sender by reply e-mail and destroy
>> > > >> all copies of the original message.
>> > > >>
>> > > >>
>> > > >> _______________________________________________
>> > > >> R-sig-mixed-models at r-project.org mailing list
>> > > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > > >>
>> > > >>
>> > > >>
>> > > >
>> > > > _______________________________________________
>> > > > R-sig-mixed-models at r-project.org mailing list
>> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > > >
>> > > >
>> -----------------------------------------------------------------------
>> > > > Confidentiality Notice: This e-mail message, including any
>> attachments,
>> > > > is for the sole use of the intended recipient(s) and may contain
>> > > > privileged and confidential information. ?Any unauthorized review,
>> use,
>> > > > disclosure or distribution is prohibited. ?If you are not the
>> intended
>> > > > recipient, please contact the sender by reply e-mail and destroy
>> > > > all copies of the original message.
>> > > >
>> > > >
>> > > > _______________________________________________
>> > > > R-sig-mixed-models at r-project.org mailing list
>> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> >
>> > ? ? ? [[alternative HTML version deleted]]
>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From deter088 at umn.edu  Fri Jan 27 04:18:20 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 26 Jan 2012 21:18:20 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CANz9Z_KLX9J=2D9w2Jncswu9B43J8UX67cOY5i2ibQ7c-9h9FQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<Pine.LNX.4.64.1201261204040.16419@orpheus.qimr.edu.au>
	<1E58DE64-2F40-4B5D-91EB-914A25036478@anu.edu.au>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7A5C@SFSMCEXMBX2.sanfordhealth.org>
	<4F216B18.6030405@cebc.cnrs.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1D7AA5@SFSMCEXMBX2.sanfordhealth.org>
	<7D1F0839-6B66-4922-B894-1CCBAFEB9802@anu.edu.au>
	<20319_1327622833_1327622833_CAOLJphn77FB69kGTW1RWLg=CE90gG6A=Fm9Av-vWhWCa6ZOX7A@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082D@crcmail4.BCCRC.CA>
	<CAOLJphnMcx0AVb-9H=cbicrccXvC+EsDQSkYqQJ4wxpj_CbygQ@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A7082E@crcmail4.BCCRC.CA>
	<CAOLJphm-D1j8+zJk3k-RoRJfzmBbW1KbrpF6k1G_WKubk47UqQ@mail.gmail.com>
	<CANz9Z_KLX9J=2D9w2Jncswu9B43J8UX67cOY5i2ibQ7c-9h9FQ@mail.gmail.com>
Message-ID: <CAOLJphkR2Z9koar2RknwcxG4kWCS=313H0rMEDKeLFkGCBWCAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/9725d363/attachment-0002.pl>

From kw.stat at gmail.com  Fri Jan 27 06:03:17 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 26 Jan 2012 23:03:17 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
Message-ID: <CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/75056ae5/attachment-0002.pl>

From john.maindonald at anu.edu.au  Fri Jan 27 07:10:18 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 27 Jan 2012 17:10:18 +1100
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
Message-ID: <7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>

I've twigged that "unstructured" means a variance-covariance matrix 
that ignores the time structure, i.e., each element is estimated 
separately.  One can do this in lme4, thus:

Orthodont$Age <- factor(Orthodont$age)
> orth.lmer <- lmer(distance ~ Sex*Age+((Sex*Age)|Subject), 
+ data=Orthodont)
> anova(orth.lmer)
Analysis of Variance Table
        Df Sum Sq Mean Sq F value
Sex      1  9.591  9.5905 33.9645
Age      3 34.876 11.6252 41.1703
Sex:Age  3  2.930  0.9768  3.4594

The sum of squares for the Sex*Age interaction agrees with that from SAS.
lmer() leaves the user to work out an appropriate df for the F-statistic.  One
has, in agreement with the SAS output:
> 1-pf(2.93, 3, 25)
[1] 0.05318945

The main effects SS and F's are of course not expected to agree and 
indeed, in my strong view, true SAS type III SS's are inappropriate.

I regard this R analysis however as an inelegant use of the data, with low
power.  My book with John Braun (3rd edn and if I recall correctly, 2nd)
has an analysis that I am prepared to defend that uses lmer() from lme4.
Several years ago, I placed on the web a version of the analysis that uses
 lme() from nlme:
   http://maths.anu.edu.au/~johnm/r-book/xtras/mlm-lme.pdf
I'd forgotten that it was there.

This is a list for R users.  You will not necessarily find folk here with a high
level of SAS expertise, maybe not even enough to understand what the
SAS documentation means when it uses the term "unstructured".  Charles,
I think you've done pretty well in the amount of free advice that you have
received.  I think too that Steven McKinney's point is well made.  Kevin's
interpretation of the EULA is probably more or less correct, but the 
document comes across rather more ferociously than he suggests, and it
is not a good starting point for scientific assessment of the respective 
methodologies.  Many of us have other reasons why we are not very
interested in SAS does.  The implied threat in the EULA provides, even
if we are not party to any such agreement, just one more reason why SAS
is not to any large extent in our path ahead to the future.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 27/01/2012, at 4:03 PM, Kevin Wright wrote:

> Dear Charles,
> 
> First, I hope you are not put off by the tone of some the responses in this
> email thread.  Sometimes people have strong opinions and it might come
> across aggressively.
> 
> Second, be sure to understand that reproducing a SAS analysis with lme in
> no way violates any legal agreements that SAS may have, if for no other
> reason than you never signed an agreement with SAS!  That bit in the EULA
> about decompiling and reverse engineering means that people are prohibited
> from creating a new version of PROC MIXED that does the same thing.  The
> nlme package uses different methods than SAS. E.g. different optimizers,
> even uses a log-parameterization deep in the code so that negative variance
> components cannot happen.
> 
> Third, by now you've probably figured out that PROC MIXED and lme have very
> different ideas about degrees of freedom.  Also, the loglikelihoods are on
> different scales.  For that reason, when I try to reproduce an analysis, I
> find the best way to compare is to look at the variance components.
> 
> Here is what PROC MIXED says:
> 
>    Cov Parm Estimate     Std Error       Z  Pr > |Z|
> UN(1,1)     5.41545455    1.53172185    3.54    0.0004
> UN(2,1)     2.71681818    1.09623989    2.48    0.0132
> UN(2,2)     4.18477273    1.18363247    3.54    0.0004
> UN(3,1)     3.91022727    1.41775367    2.76    0.0058
> UN(3,2)     2.92715909    1.19304751    2.45    0.0141
> UN(3,3)     6.45573864    1.82595863    3.54    0.0004
> UN(4,1)     2.71022727    1.17209851    2.31    0.0208
> UN(4,2)     3.31715909    1.12903016    2.94    0.0033
> UN(4,3)     4.13073864    1.40356157    2.94    0.0033
> UN(4,4)     4.98573864    1.41017984    3.54    0.0004
> Residual         1.00000000 .       .         .
> 
> That's our target, and here is the lme code to get us there.
> 
> library(nlme)
> orth <- as.data.frame(Orthodont)
> m1 <- gls(distance ~ Sex*age,
>          correlation=corSymm(form = ~ 1 | Subject),
>          weights = varIdent(form = ~ 1 | age),
>          data = orth)
> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
> cors*covs
> 
> Now, some explanations will surely help, so let's step through the code
> with comments.
> 
> The Orthodont data is a groupedData object, which can be helpful, but
> sometimes confusing, so coercing to a data.frame removes the formula--you
> can see it with 'formula(Orthodont)'.
> 
> orth <- as.data.frame(Orthodont)
> 
> Since there is no "random" line in the PROC MIXED code, we don't want to
> use 'lme' (also why I removed the formula from the data), but instead use
> 'gls' for generalized least squares.  The 'corSymm' part specifies a
> symmetric correlation matrix with 1 on the diagonal.  Looking at the MIXED
> parameters, the results are given a covariances, not correlations.  Note
> how the variances UN(1,1), UN(2,2,), etc are different, not constant along
> the diagonal.  We use the 'weights' statement to specify different stratum
> variances.
> 
> m1 <- gls(distance ~ Sex*age,
>          correlation=corSymm(form = ~ 1 | Subject),
>          weights = varIdent(form = ~ 1 | age),
>          data = orth)
> 
> Now we have to convert the correlations and standard deviations of lme into
> covariance parameters of MIXED.
> 
> First, extract the correlation matrix from lme.
> 
> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
> 
> Now, hard-code the stratum std deviations and square them to get
> variances.  Multiply by the square of the residual std dev.  (There's a way
> to extract all these values from the fitted model instead of hand-typing
> them, but I can't find them at the moment.)
> 
> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
> 
> Now create a matrix of variances and covariances.
> 
> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
> 
> Finally, multiply the correlations by the covariances.  Let's compare
> results:
> 
> PROC MIXED:
> 
> Row Col1 Col2 Col3 Col4
> 1 5.415 2.716 3.910 2.710
> 2 2.716 4.184 2.927 3.317
> 3 3.910 2.927 6.455 4.130
> 4 2.710 3.317 4.130 4.985
> 
> R> round(cors*covs,3)
>      [,1]  [,2]  [,3]  [,4]
> [1,] 5.425 2.709 3.841 2.715
> [2,] 2.709 4.191 2.975 3.314
> [3,] 3.841 2.975 6.263 4.133
> [4,] 2.715 3.314 4.133 4.986
> 
> In my experience, the small differences in the results are typical for
> unstructured models.
> 
> Hope this helps.
> 
> Kevin Wright
> 
> 
> On Tue, Jan 24, 2012 at 8:32 PM, Charles Determan Jr <deter088 at umn.edu>wrote:
> 
>> Greetings,
>> 
>> I have been working on R for some time now and I have begun the endeavor of
>> trying to replicate some SAS code in R.  I have scoured the forums but
>> haven't been able to find an answer.  I hope one of you could be so kind as
>> to enlighten me.
>> 
>> I am attempting to replicate a repeated measures experiment using some
>> standard data.  I have posted the SAS code and output directly from a
>> publication as well as my attempts in R to replicate it.  My main issue
>> comes with the 'unstructured' component.
>> 
>> The 'dental' dataset from 'mixedQF' package,
>> equivalent to formixed data in SAS
>> 
>>   distance age Subject    Sex
>> 1       26.0   8     M01   Male
>> 2       25.0  10     M01   Male
>> 3       29.0  12     M01   Male
>> 4       31.0  14     M01   Male
>> 5       21.5   8     M02   Male
>> 6       22.5  10     M02   Male
>> 7       23.0  12     M02   Male
>> 8       26.5  14     M02   Male
>> 9       23.0   8     M03   Male
>> 10      22.5  10     M03   Male
>> 11      24.0  12     M03   Male
>> 12      27.5  14     M03   Male
>> 13      25.5   8     M04   Male
>> 14      27.5  10     M04   Male
>> 15      26.5  12     M04   Male
>> 16      27.0  14     M04   Male
>> 17      20.0   8     M05   Male
>> 18      23.5  10     M05   Male
>> 19      22.5  12     M05   Male
>> 20      26.0  14     M05   Male
>> 21      24.5   8     M06   Male
>> 22      25.5  10     M06   Male
>> 23      27.0  12     M06   Male
>> 24      28.5  14     M06   Male
>> 25      22.0   8     M07   Male
>> 26      22.0  10     M07   Male
>> 27      24.5  12     M07   Male
>> 28      26.5  14     M07   Male
>> 29      24.0   8     M08   Male
>> 30      21.5  10     M08   Male
>> 31      24.5  12     M08   Male
>> 32      25.5  14     M08   Male
>> 33      23.0   8     M09   Male
>> 34      20.5  10     M09   Male
>> 35      31.0  12     M09   Male
>> 36      26.0  14     M09   Male
>> 37      27.5   8     M10   Male
>> 38      28.0  10     M10   Male
>> 39      31.0  12     M10   Male
>> 40      31.5  14     M10   Male
>> 41      23.0   8     M11   Male
>> 42      23.0  10     M11   Male
>> 43      23.5  12     M11   Male
>> 44      25.0  14     M11   Male
>> 45      21.5   8     M12   Male
>> 46      23.5  10     M12   Male
>> 47      24.0  12     M12   Male
>> 48      28.0  14     M12   Male
>> 49      17.0   8     M13   Male
>> 50      24.5  10     M13   Male
>> 51      26.0  12     M13   Male
>> 52      29.5  14     M13   Male
>> 53      22.5   8     M14   Male
>> 54      25.5  10     M14   Male
>> 55      25.5  12     M14   Male
>> 56      26.0  14     M14   Male
>> 57      23.0   8     M15   Male
>> 58      24.5  10     M15   Male
>> 59      26.0  12     M15   Male
>> 60      30.0  14     M15   Male
>> 61      22.0   8     M16   Male
>> 62      21.5  10     M16   Male
>> 63      23.5  12     M16   Male
>> 64      25.0  14     M16   Male
>> 65      21.0   8     F01 Female
>> 66      20.0  10     F01 Female
>> 67      21.5  12     F01 Female
>> 68      23.0  14     F01 Female
>> 69      21.0   8     F02 Female
>> 70      21.5  10     F02 Female
>> 71      24.0  12     F02 Female
>> 72      25.5  14     F02 Female
>> 73      20.5   8     F03 Female
>> 74      24.0  10     F03 Female
>> 75      24.5  12     F03 Female
>> 76      26.0  14     F03 Female
>> 77      23.5   8     F04 Female
>> 78      24.5  10     F04 Female
>> 79      25.0  12     F04 Female
>> 80      26.5  14     F04 Female
>> 81      21.5   8     F05 Female
>> 82      23.0  10     F05 Female
>> 83      22.5  12     F05 Female
>> 84      23.5  14     F05 Female
>> 85      20.0   8     F06 Female
>> 86      21.0  10     F06 Female
>> 87      21.0  12     F06 Female
>> 88      22.5  14     F06 Female
>> 89      21.5   8     F07 Female
>> 90      22.5  10     F07 Female
>> 91      23.0  12     F07 Female
>> 92      25.0  14     F07 Female
>> 93      23.0   8     F08 Female
>> 94      23.0  10     F08 Female
>> 95      23.5  12     F08 Female
>> 96      24.0  14     F08 Female
>> 97      20.0   8     F09 Female
>> 98      21.0  10     F09 Female
>> 99      22.0  12     F09 Female
>> 100     21.5  14     F09 Female
>> 101     16.5   8     F10 Female
>> 102     19.0  10     F10 Female
>> 103     19.0  12     F10 Female
>> 104     19.5  14     F10 Female
>> 105     24.5   8     F11 Female
>> 106     25.0  10     F11 Female
>> 107     28.0  12     F11 Female
>> 108     28.0  14     F11 Female
>> 
>> *Mixed modeling and fixed effect test*
>> SAS
>> proc mixed data=formixed;
>> class gender age person;
>> model y = gender|age;
>> repeated / type=cs sub=person;
>> run;
>> 
>> output of interest to me
>>         Tests of Fixed Effects
>> Source             NDF   DDF    Type III F    Pr > F
>> GENDER           1        25        9.29        0.0054
>> AGE                  3        75       35.35       0.0001
>> GENDER*AGE   3        75        2.36        0.0781
>> 
>> R (nlme package)
>> y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
>> anova(y)
>> 
>>           numDF denDF  F-value p-value
>> (Intercept)     1    75 4123.156  <.0001
>> Sex              1    25    9.292  0.0054
>> age               3    75   40.032  <.0001
>> Sex:age        3    75    2.362  0.0781
>> 
>> Now this isn't exact but it is extremely close, however when I try to
>> replicate the unstructured,
>> 
>> SAS
>> proc mixed data=formixed;
>> class gender age person;
>> model y = gender|age;
>> repeated / type=un sub=person;
>> run;
>> 
>>            Tests of Fixed Effects
>> Source          NDF DDF Type III F Pr > F
>> GENDER         1    25     9.29    0.0054
>> AGE                3    25    34.45   0.0001
>> GENDER*AGE 3    25     2.93    0.0532
>> 
>> R
>> either
>> y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
>> data=dental)
>> anova(y)
>> or
>> z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(), data=dental)
>> anova(z)
>> 
>> gives the output
>> 
>>           numDF denDF  F-value    p-value
>> (Intercept)     1    75     4052.028  <.0001
>> Sex              1    25       8.462      0.0075
>> age               3    75      39.022    <.0001
>> Sex:age        3    75       2.868      0.0421
>> 
>> What am I doing wrong to replicate the unstructured linear mixed model from
>> SAS?
>> 
>> Regards,
>> 
>> Charles
>> 
>>       [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 
> -- 
> Kevin Wright
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Gustaf.Granath at ebc.uu.se  Fri Jan 27 12:58:55 2012
From: Gustaf.Granath at ebc.uu.se (Gustaf Granath)
Date: Fri, 27 Jan 2012 12:58:55 +0100
Subject: [R-sig-ME] Problems with parametric bootstrap, glmer
Message-ID: <4F22917F.5060908@ebc.uu.se>

Hi all,
A few times a have encountered a problem when I try to perform a 
parametric bootstrap to obtain a "corrected" p-value for a fixed effect 
using glmer, like (lmer(y~x+x1+x2+(1|ran)+(1|id),data,family="poisson"). 
I can run the model without errors but when a use simulate(model) as 
response (y) I sometimes get the classic " Cholmod warning 'not positive 
definite'". Even more peculiar is that when I use refit() (e.g. as 
described in the lme4 documentation under 'simulate-mer'), then this 
happens more often compared to if I use the update() function.

So I can get a p-value based on the LR  (anova(model1,model2)) but if I 
run a parametric bootstrap (n=1000), maybe only 600-700 runs converge. 
My models are not particularly overparametrized (maximum 16 fix coef, 2 
random, N=500), random effects are not close to zero and centering data 
does not help (actually, it made it worse in some cases...?). Has anyone 
else encountered this problem? I assume that it is wrong to use the 
600-700 successful bootstrap runs to calculate a parametric bootstrap 
P-value. Any alternative ideas how to proceed?

I tried to put together test code (see below), I hope it works. It 
should show that update() works better than refit() but I wasnt able to 
reproduce that update() can fail as well (maybe I didnt run it long 
enough though).

Cheers,

Gustaf Granath (PhD student)

##############CODE
set.seed(100)
dat<-expand.grid(y=c(1:5),site=as.factor(c(1:10)),tree=c("spruce","pine"))
i=9
for (i in 0:i) {
     dat$y[(1+i*5):(5+5*i)]<- rpois(5,(5+1*i))+round(rnorm(5,0,2))
     dat$y[(51+i*5):(50+(5+5*i))]<- rpois(5,(9+1*i))+round(rnorm(5,0,2))
}
dat$cov<-rnorm(100,100,10)
dat$id<- 1:nrow(dat)

#run models
m1<-lmer(y~tree+cov+(1|site)+(1|id),dat,family="poisson")
m0<-lmer(y~cov+(1|site)+(1|id),dat,family="poisson")

#function for refit()
pboot2 <- function(m0,m1) {
     s <- simulate(m0)
     L0 <- logLik(refit(m0,s),REML=F)
     L1 <- logLik(refit(m1,s),REML=F)
     c(2*(L1-L0))
}
dist1<-replicate(10,pboot2(m0,m1))

#use update() instead (no errors now)
dist2=numeric(10)
for (i in 1:10) {
     dat$s <- simulate(m0)$sim_1
     m0.refit <-    update(m0,s~.,data=dat)
     L0 <- logLik(m0.refit,REML=F)
     m1.refit <-    update(m1,s~.,data=dat)
     L1 <- logLik(m1.refit,REML=F)
     dist2[i]<- c(2*(L1-L0))
}

#compare refit() and update()
dist1 #with refit()
dist2 #with update()



From deter088 at umn.edu  Fri Jan 27 13:02:49 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 27 Jan 2012 06:02:49 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
Message-ID: <CAOLJphnyNerUf1OR15XoAgDz7uUAawZQL4t+tNsXmss=2CmRig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120127/b326ed53/attachment-0002.pl>

From deter088 at umn.edu  Fri Jan 27 13:08:24 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 27 Jan 2012 06:08:24 -0600
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
	<7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>
Message-ID: <CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120127/ebcca832/attachment-0002.pl>

From i.m.s.white at ed.ac.uk  Fri Jan 27 14:38:46 2012
From: i.m.s.white at ed.ac.uk (i white)
Date: Fri, 27 Jan 2012 13:38:46 +0000
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>	<7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>
	<CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>
Message-ID: <4F22A8E6.9090600@ed.ac.uk>

Charles,

I guess that SAS is using the Satterthwaite formula to approximate 
denominator degrees of freedom (google 'Satterthwaite'). See Kenward and 
Roger (1997) Biometrics 53 983-997 for another approach.

Charles Determan Jr wrote:
> Thank you John, I truly appreciate all the advice I have received.  At no
> point to I feel entitled for someone to provide this for me.  I do hope
> that others may find this thread useful as well.  If I may just as one more
> question.  Is there an accepted way to calculate the degrees of freedom in
> this case to come to the value of 25?  This has been something I have been
> trying to determine.
> 
> Again, thank you to all for providing me with all the information you have,
> 
> Charles
> 
> On Fri, Jan 27, 2012 at 12:10 AM, John Maindonald <
> john.maindonald at anu.edu.au> wrote:
> 
>> I've twigged that "unstructured" means a variance-covariance matrix
>> that ignores the time structure, i.e., each element is estimated
>> separately.  One can do this in lme4, thus:
>>
>> Orthodont$Age <- factor(Orthodont$age)
>>> orth.lmer <- lmer(distance ~ Sex*Age+((Sex*Age)|Subject),
>> + data=Orthodont)
>>> anova(orth.lmer)
>> Analysis of Variance Table
>>        Df Sum Sq Mean Sq F value
>> Sex      1  9.591  9.5905 33.9645
>> Age      3 34.876 11.6252 41.1703
>> Sex:Age  3  2.930  0.9768  3.4594
>>
>> The sum of squares for the Sex*Age interaction agrees with that from SAS.
>> lmer() leaves the user to work out an appropriate df for the F-statistic.
>>  One
>> has, in agreement with the SAS output:
>>> 1-pf(2.93, 3, 25)
>> [1] 0.05318945
>>
>> The main effects SS and F's are of course not expected to agree and
>> indeed, in my strong view, true SAS type III SS's are inappropriate.
>>
>> I regard this R analysis however as an inelegant use of the data, with low
>> power.  My book with John Braun (3rd edn and if I recall correctly, 2nd)
>> has an analysis that I am prepared to defend that uses lmer() from lme4.
>> Several years ago, I placed on the web a version of the analysis that uses
>>  lme() from nlme:
>>   http://maths.anu.edu.au/~johnm/r-book/xtras/mlm-lme.pdf
>> I'd forgotten that it was there.
>>
>> This is a list for R users.  You will not necessarily find folk here with
>> a high
>> level of SAS expertise, maybe not even enough to understand what the
>> SAS documentation means when it uses the term "unstructured".  Charles,
>> I think you've done pretty well in the amount of free advice that you have
>> received.  I think too that Steven McKinney's point is well made.  Kevin's
>> interpretation of the EULA is probably more or less correct, but the
>> document comes across rather more ferociously than he suggests, and it
>> is not a good starting point for scientific assessment of the respective
>> methodologies.  Many of us have other reasons why we are not very
>> interested in SAS does.  The implied threat in the EULA provides, even
>> if we are not party to any such agreement, just one more reason why SAS
>> is not to any large extent in our path ahead to the future.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> On 27/01/2012, at 4:03 PM, Kevin Wright wrote:
>>
>>> Dear Charles,
>>>
>>> First, I hope you are not put off by the tone of some the responses in
>> this
>>> email thread.  Sometimes people have strong opinions and it might come
>>> across aggressively.
>>>
>>> Second, be sure to understand that reproducing a SAS analysis with lme in
>>> no way violates any legal agreements that SAS may have, if for no other
>>> reason than you never signed an agreement with SAS!  That bit in the EULA
>>> about decompiling and reverse engineering means that people are
>> prohibited
>>> from creating a new version of PROC MIXED that does the same thing.  The
>>> nlme package uses different methods than SAS. E.g. different optimizers,
>>> even uses a log-parameterization deep in the code so that negative
>> variance
>>> components cannot happen.
>>>
>>> Third, by now you've probably figured out that PROC MIXED and lme have
>> very
>>> different ideas about degrees of freedom.  Also, the loglikelihoods are
>> on
>>> different scales.  For that reason, when I try to reproduce an analysis,
>> I
>>> find the best way to compare is to look at the variance components.
>>>
>>> Here is what PROC MIXED says:
>>>
>>>    Cov Parm Estimate     Std Error       Z  Pr > |Z|
>>> UN(1,1)     5.41545455    1.53172185    3.54    0.0004
>>> UN(2,1)     2.71681818    1.09623989    2.48    0.0132
>>> UN(2,2)     4.18477273    1.18363247    3.54    0.0004
>>> UN(3,1)     3.91022727    1.41775367    2.76    0.0058
>>> UN(3,2)     2.92715909    1.19304751    2.45    0.0141
>>> UN(3,3)     6.45573864    1.82595863    3.54    0.0004
>>> UN(4,1)     2.71022727    1.17209851    2.31    0.0208
>>> UN(4,2)     3.31715909    1.12903016    2.94    0.0033
>>> UN(4,3)     4.13073864    1.40356157    2.94    0.0033
>>> UN(4,4)     4.98573864    1.41017984    3.54    0.0004
>>> Residual         1.00000000 .       .         .
>>>
>>> That's our target, and here is the lme code to get us there.
>>>
>>> library(nlme)
>>> orth <- as.data.frame(Orthodont)
>>> m1 <- gls(distance ~ Sex*age,
>>>          correlation=corSymm(form = ~ 1 | Subject),
>>>          weights = varIdent(form = ~ 1 | age),
>>>          data = orth)
>>> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
>>> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
>>> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
>>> cors*covs
>>>
>>> Now, some explanations will surely help, so let's step through the code
>>> with comments.
>>>
>>> The Orthodont data is a groupedData object, which can be helpful, but
>>> sometimes confusing, so coercing to a data.frame removes the formula--you
>>> can see it with 'formula(Orthodont)'.
>>>
>>> orth <- as.data.frame(Orthodont)
>>>
>>> Since there is no "random" line in the PROC MIXED code, we don't want to
>>> use 'lme' (also why I removed the formula from the data), but instead use
>>> 'gls' for generalized least squares.  The 'corSymm' part specifies a
>>> symmetric correlation matrix with 1 on the diagonal.  Looking at the
>> MIXED
>>> parameters, the results are given a covariances, not correlations.  Note
>>> how the variances UN(1,1), UN(2,2,), etc are different, not constant
>> along
>>> the diagonal.  We use the 'weights' statement to specify different
>> stratum
>>> variances.
>>>
>>> m1 <- gls(distance ~ Sex*age,
>>>          correlation=corSymm(form = ~ 1 | Subject),
>>>          weights = varIdent(form = ~ 1 | age),
>>>          data = orth)
>>>
>>> Now we have to convert the correlations and standard deviations of lme
>> into
>>> covariance parameters of MIXED.
>>>
>>> First, extract the correlation matrix from lme.
>>>
>>> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
>>>
>>> Now, hard-code the stratum std deviations and square them to get
>>> variances.  Multiply by the square of the residual std dev.  (There's a
>> way
>>> to extract all these values from the fitted model instead of hand-typing
>>> them, but I can't find them at the moment.)
>>>
>>> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
>>>
>>> Now create a matrix of variances and covariances.
>>>
>>> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
>>>
>>> Finally, multiply the correlations by the covariances.  Let's compare
>>> results:
>>>
>>> PROC MIXED:
>>>
>>> Row Col1 Col2 Col3 Col4
>>> 1 5.415 2.716 3.910 2.710
>>> 2 2.716 4.184 2.927 3.317
>>> 3 3.910 2.927 6.455 4.130
>>> 4 2.710 3.317 4.130 4.985
>>>
>>> R> round(cors*covs,3)
>>>      [,1]  [,2]  [,3]  [,4]
>>> [1,] 5.425 2.709 3.841 2.715
>>> [2,] 2.709 4.191 2.975 3.314
>>> [3,] 3.841 2.975 6.263 4.133
>>> [4,] 2.715 3.314 4.133 4.986
>>>
>>> In my experience, the small differences in the results are typical for
>>> unstructured models.
>>>
>>> Hope this helps.
>>>
>>> Kevin Wright
>>>
>>>
>>> On Tue, Jan 24, 2012 at 8:32 PM, Charles Determan Jr <deter088 at umn.edu
>>> wrote:
>>>
>>>> Greetings,
>>>>
>>>> I have been working on R for some time now and I have begun the
>> endeavor of
>>>> trying to replicate some SAS code in R.  I have scoured the forums but
>>>> haven't been able to find an answer.  I hope one of you could be so
>> kind as
>>>> to enlighten me.
>>>>
>>>> I am attempting to replicate a repeated measures experiment using some
>>>> standard data.  I have posted the SAS code and output directly from a
>>>> publication as well as my attempts in R to replicate it.  My main issue
>>>> comes with the 'unstructured' component.
>>>>
>>>> The 'dental' dataset from 'mixedQF' package,
>>>> equivalent to formixed data in SAS
>>>>
>>>>   distance age Subject    Sex
>>>> 1       26.0   8     M01   Male
>>>> 2       25.0  10     M01   Male
>>>> 3       29.0  12     M01   Male
>>>> 4       31.0  14     M01   Male
>>>> 5       21.5   8     M02   Male
>>>> 6       22.5  10     M02   Male
>>>> 7       23.0  12     M02   Male
>>>> 8       26.5  14     M02   Male
>>>> 9       23.0   8     M03   Male
>>>> 10      22.5  10     M03   Male
>>>> 11      24.0  12     M03   Male
>>>> 12      27.5  14     M03   Male
>>>> 13      25.5   8     M04   Male
>>>> 14      27.5  10     M04   Male
>>>> 15      26.5  12     M04   Male
>>>> 16      27.0  14     M04   Male
>>>> 17      20.0   8     M05   Male
>>>> 18      23.5  10     M05   Male
>>>> 19      22.5  12     M05   Male
>>>> 20      26.0  14     M05   Male
>>>> 21      24.5   8     M06   Male
>>>> 22      25.5  10     M06   Male
>>>> 23      27.0  12     M06   Male
>>>> 24      28.5  14     M06   Male
>>>> 25      22.0   8     M07   Male
>>>> 26      22.0  10     M07   Male
>>>> 27      24.5  12     M07   Male
>>>> 28      26.5  14     M07   Male
>>>> 29      24.0   8     M08   Male
>>>> 30      21.5  10     M08   Male
>>>> 31      24.5  12     M08   Male
>>>> 32      25.5  14     M08   Male
>>>> 33      23.0   8     M09   Male
>>>> 34      20.5  10     M09   Male
>>>> 35      31.0  12     M09   Male
>>>> 36      26.0  14     M09   Male
>>>> 37      27.5   8     M10   Male
>>>> 38      28.0  10     M10   Male
>>>> 39      31.0  12     M10   Male
>>>> 40      31.5  14     M10   Male
>>>> 41      23.0   8     M11   Male
>>>> 42      23.0  10     M11   Male
>>>> 43      23.5  12     M11   Male
>>>> 44      25.0  14     M11   Male
>>>> 45      21.5   8     M12   Male
>>>> 46      23.5  10     M12   Male
>>>> 47      24.0  12     M12   Male
>>>> 48      28.0  14     M12   Male
>>>> 49      17.0   8     M13   Male
>>>> 50      24.5  10     M13   Male
>>>> 51      26.0  12     M13   Male
>>>> 52      29.5  14     M13   Male
>>>> 53      22.5   8     M14   Male
>>>> 54      25.5  10     M14   Male
>>>> 55      25.5  12     M14   Male
>>>> 56      26.0  14     M14   Male
>>>> 57      23.0   8     M15   Male
>>>> 58      24.5  10     M15   Male
>>>> 59      26.0  12     M15   Male
>>>> 60      30.0  14     M15   Male
>>>> 61      22.0   8     M16   Male
>>>> 62      21.5  10     M16   Male
>>>> 63      23.5  12     M16   Male
>>>> 64      25.0  14     M16   Male
>>>> 65      21.0   8     F01 Female
>>>> 66      20.0  10     F01 Female
>>>> 67      21.5  12     F01 Female
>>>> 68      23.0  14     F01 Female
>>>> 69      21.0   8     F02 Female
>>>> 70      21.5  10     F02 Female
>>>> 71      24.0  12     F02 Female
>>>> 72      25.5  14     F02 Female
>>>> 73      20.5   8     F03 Female
>>>> 74      24.0  10     F03 Female
>>>> 75      24.5  12     F03 Female
>>>> 76      26.0  14     F03 Female
>>>> 77      23.5   8     F04 Female
>>>> 78      24.5  10     F04 Female
>>>> 79      25.0  12     F04 Female
>>>> 80      26.5  14     F04 Female
>>>> 81      21.5   8     F05 Female
>>>> 82      23.0  10     F05 Female
>>>> 83      22.5  12     F05 Female
>>>> 84      23.5  14     F05 Female
>>>> 85      20.0   8     F06 Female
>>>> 86      21.0  10     F06 Female
>>>> 87      21.0  12     F06 Female
>>>> 88      22.5  14     F06 Female
>>>> 89      21.5   8     F07 Female
>>>> 90      22.5  10     F07 Female
>>>> 91      23.0  12     F07 Female
>>>> 92      25.0  14     F07 Female
>>>> 93      23.0   8     F08 Female
>>>> 94      23.0  10     F08 Female
>>>> 95      23.5  12     F08 Female
>>>> 96      24.0  14     F08 Female
>>>> 97      20.0   8     F09 Female
>>>> 98      21.0  10     F09 Female
>>>> 99      22.0  12     F09 Female
>>>> 100     21.5  14     F09 Female
>>>> 101     16.5   8     F10 Female
>>>> 102     19.0  10     F10 Female
>>>> 103     19.0  12     F10 Female
>>>> 104     19.5  14     F10 Female
>>>> 105     24.5   8     F11 Female
>>>> 106     25.0  10     F11 Female
>>>> 107     28.0  12     F11 Female
>>>> 108     28.0  14     F11 Female
>>>>
>>>> *Mixed modeling and fixed effect test*
>>>> SAS
>>>> proc mixed data=formixed;
>>>> class gender age person;
>>>> model y = gender|age;
>>>> repeated / type=cs sub=person;
>>>> run;
>>>>
>>>> output of interest to me
>>>>         Tests of Fixed Effects
>>>> Source             NDF   DDF    Type III F    Pr > F
>>>> GENDER           1        25        9.29        0.0054
>>>> AGE                  3        75       35.35       0.0001
>>>> GENDER*AGE   3        75        2.36        0.0781
>>>>
>>>> R (nlme package)
>>>> y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
>>>> anova(y)
>>>>
>>>>           numDF denDF  F-value p-value
>>>> (Intercept)     1    75 4123.156  <.0001
>>>> Sex              1    25    9.292  0.0054
>>>> age               3    75   40.032  <.0001
>>>> Sex:age        3    75    2.362  0.0781
>>>>
>>>> Now this isn't exact but it is extremely close, however when I try to
>>>> replicate the unstructured,
>>>>
>>>> SAS
>>>> proc mixed data=formixed;
>>>> class gender age person;
>>>> model y = gender|age;
>>>> repeated / type=un sub=person;
>>>> run;
>>>>
>>>>            Tests of Fixed Effects
>>>> Source          NDF DDF Type III F Pr > F
>>>> GENDER         1    25     9.29    0.0054
>>>> AGE                3    25    34.45   0.0001
>>>> GENDER*AGE 3    25     2.93    0.0532
>>>>
>>>> R
>>>> either
>>>> y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
>>>> data=dental)
>>>> anova(y)
>>>> or
>>>> z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(),
>> data=dental)
>>>> anova(z)
>>>>
>>>> gives the output
>>>>
>>>>           numDF denDF  F-value    p-value
>>>> (Intercept)     1    75     4052.028  <.0001
>>>> Sex              1    25       8.462      0.0075
>>>> age               3    75      39.022    <.0001
>>>> Sex:age        3    75       2.868      0.0421
>>>>
>>>> What am I doing wrong to replicate the unstructured linear mixed model
>> from
>>>> SAS?
>>>>
>>>> Regards,
>>>>
>>>> Charles
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>> Kevin Wright
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From kmancuso88 at gmail.com  Fri Jan 27 02:11:22 2012
From: kmancuso88 at gmail.com (Kristen Mancuso)
Date: Thu, 26 Jan 2012 20:11:22 -0500
Subject: [R-sig-ME] checking overdispersion when modelling proportions
Message-ID: <CA+Z8Yv+_suX-_RPLLjW3U00JxXj19f43m-GjbM2T8pFm991gyw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120126/7319db7c/attachment-0002.pl>

From pierces1 at msu.edu  Fri Jan 27 17:31:34 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Fri, 27 Jan 2012 11:31:34 -0500
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>	<7E32D229-6DEC-4022-A2D4-659A599113A0@anu.edu.au>
	<CAOLJphkdoUXhgFWpGMbusY_P_4W0oB3LoBgb_4J8nP6HH1uUVQ@mail.gmail.com>
Message-ID: <004b01ccdd11$22836240$678a26c0$@msu.edu>

It seems to me that the SAS documentation ought to tell you what algorithm
it uses to compute the degrees of freedom. Perhaps they do that by
referencing a published paper. If so, just read the original source to get
the relevant formulas. The only reliable way to get the same DF that SAS
provides is to use the same formula for calculating it. There may or may not
be existing R code that implements the required formulas, but you need to
know what you're looking for in order to find it. 

Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 


-----Original Message-----
From: Charles Determan Jr [mailto:deter088 at umn.edu] 
Sent: Friday, January 27, 2012 7:08 AM
To: John Maindonald
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in
R

Thank you John, I truly appreciate all the advice I have received.  At no
point to I feel entitled for someone to provide this for me.  I do hope
that others may find this thread useful as well.  If I may just as one more
question.  Is there an accepted way to calculate the degrees of freedom in
this case to come to the value of 25?  This has been something I have been
trying to determine.

Again, thank you to all for providing me with all the information you have,

Charles



From juliet.hannah at gmail.com  Fri Jan 27 20:00:39 2012
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Fri, 27 Jan 2012 14:00:39 -0500
Subject: [R-sig-ME] Trouble Replicating Unstructured Mixed Procedure in R
In-Reply-To: <CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
References: <CAOLJphk_-aJiB=DCF5ZRUG+8VnrRD20RNnAja8wU3011Y0jw-w@mail.gmail.com>
	<CAKFxdiRsS-fEeOCsEck51st2sxZfTURWnaBT17Jd4aDihARijg@mail.gmail.com>
Message-ID: <CALzuZRTz9PVQz2Fa9XCrAqLwaD6-mtadHAa2rOGr1v12myz9+A@mail.gmail.com>

My post may be redundant, but just in case I wanted to comment.  I
think Kevin's post
addressed a few things that are helpful to start with.

The original proc mixed syntax did not have a random statement. This
is similar to what
Pinheiro and Bates (Chapter 5) describe as an extended linear model.
Therefore, it seems we should not be able
to reproduce this with  lme and nlme. Instead, we use gls. I think
some people do not like to call this
a mixed effect model because the intercept or slope are not random,
but I can see why SAS would include
it with proc mixed because of the similarities. The SAS reference for
this is Littell (SAS for mixed models) Chapter 5.

proc mixed data=formixed;
class gender person;
model y = gender|age/solution;
repeated / type=un sub=person;
run;

gives me a similar result to

 gls( y ~ gender + age + gender*age , formixed, correlation =
corSymm(form = ~ 1 | person))

SAS output:

Intercept 15.84
gender 1.58
age 0.82
age*gender -.35

nlme output:

Coefficients:

(Intercept)      15.93
genderFemale      1.47
age               0.82
genderFemale:age -0.35



On Fri, Jan 27, 2012 at 12:03 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> Dear Charles,
>
> First, I hope you are not put off by the tone of some the responses in this
> email thread. ?Sometimes people have strong opinions and it might come
> across aggressively.
>
> Second, be sure to understand that reproducing a SAS analysis with lme in
> no way violates any legal agreements that SAS may have, if for no other
> reason than you never signed an agreement with SAS! ?That bit in the EULA
> about decompiling and reverse engineering means that people are prohibited
> from creating a new version of PROC MIXED that does the same thing. ?The
> nlme package uses different methods than SAS. E.g. different optimizers,
> even uses a log-parameterization deep in the code so that negative variance
> components cannot happen.
>
> Third, by now you've probably figured out that PROC MIXED and lme have very
> different ideas about degrees of freedom. ?Also, the loglikelihoods are on
> different scales. ?For that reason, when I try to reproduce an analysis, I
> find the best way to compare is to look at the variance components.
>
> Here is what PROC MIXED says:
>
> ? ?Cov Parm Estimate ? ? Std Error ? ? ? Z ?Pr > |Z|
> UN(1,1) ? ? 5.41545455 ? ?1.53172185 ? ?3.54 ? ?0.0004
> UN(2,1) ? ? 2.71681818 ? ?1.09623989 ? ?2.48 ? ?0.0132
> UN(2,2) ? ? 4.18477273 ? ?1.18363247 ? ?3.54 ? ?0.0004
> UN(3,1) ? ? 3.91022727 ? ?1.41775367 ? ?2.76 ? ?0.0058
> UN(3,2) ? ? 2.92715909 ? ?1.19304751 ? ?2.45 ? ?0.0141
> UN(3,3) ? ? 6.45573864 ? ?1.82595863 ? ?3.54 ? ?0.0004
> UN(4,1) ? ? 2.71022727 ? ?1.17209851 ? ?2.31 ? ?0.0208
> UN(4,2) ? ? 3.31715909 ? ?1.12903016 ? ?2.94 ? ?0.0033
> UN(4,3) ? ? 4.13073864 ? ?1.40356157 ? ?2.94 ? ?0.0033
> UN(4,4) ? ? 4.98573864 ? ?1.41017984 ? ?3.54 ? ?0.0004
> Residual ? ? ? ? 1.00000000 . ? ? ? . ? ? ? ? .
>
> That's our target, and here is the lme code to get us there.
>
> library(nlme)
> orth <- as.data.frame(Orthodont)
> m1 <- gls(distance ~ Sex*age,
> ? ? ? ? ?correlation=corSymm(form = ~ 1 | Subject),
> ? ? ? ? ?weights = varIdent(form = ~ 1 | age),
> ? ? ? ? ?data = orth)
> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
> cors*covs
>
> Now, some explanations will surely help, so let's step through the code
> with comments.
>
> The Orthodont data is a groupedData object, which can be helpful, but
> sometimes confusing, so coercing to a data.frame removes the formula--you
> can see it with 'formula(Orthodont)'.
>
> orth <- as.data.frame(Orthodont)
>
> Since there is no "random" line in the PROC MIXED code, we don't want to
> use 'lme' (also why I removed the formula from the data), but instead use
> 'gls' for generalized least squares. ?The 'corSymm' part specifies a
> symmetric correlation matrix with 1 on the diagonal. ?Looking at the MIXED
> parameters, the results are given a covariances, not correlations. ?Note
> how the variances UN(1,1), UN(2,2,), etc are different, not constant along
> the diagonal. ?We use the 'weights' statement to specify different stratum
> variances.
>
> m1 <- gls(distance ~ Sex*age,
> ? ? ? ? ?correlation=corSymm(form = ~ 1 | Subject),
> ? ? ? ? ?weights = varIdent(form = ~ 1 | age),
> ? ? ? ? ?data = orth)
>
> Now we have to convert the correlations and standard deviations of lme into
> covariance parameters of MIXED.
>
> First, extract the correlation matrix from lme.
>
> cors <- corMatrix(m1$modelStruct$corStruct)[[1]]
>
> Now, hard-code the stratum std deviations and square them to get
> variances. ?Multiply by the square of the residual std dev. ?(There's a way
> to extract all these values from the fitted model instead of hand-typing
> them, but I can't find them at the moment.)
>
> vars <- c(1.0000000, 0.8788793, 1.0744596, 0.9586878)^2 * 2.329213^2
>
> Now create a matrix of variances and covariances.
>
> covs <- outer(vars,vars, function(x,y) sqrt(x)*sqrt(y))
>
> Finally, multiply the correlations by the covariances. ?Let's compare
> results:
>
> PROC MIXED:
>
> Row Col1 Col2 Col3 Col4
> 1 5.415 2.716 3.910 2.710
> 2 2.716 4.184 2.927 3.317
> 3 3.910 2.927 6.455 4.130
> 4 2.710 3.317 4.130 4.985
>
> R> round(cors*covs,3)
> ? ? ?[,1] ?[,2] ?[,3] ?[,4]
> [1,] 5.425 2.709 3.841 2.715
> [2,] 2.709 4.191 2.975 3.314
> [3,] 3.841 2.975 6.263 4.133
> [4,] 2.715 3.314 4.133 4.986
>
> In my experience, the small differences in the results are typical for
> unstructured models.
>
> Hope this helps.
>
> Kevin Wright
>
>
> On Tue, Jan 24, 2012 at 8:32 PM, Charles Determan Jr <deter088 at umn.edu>wrote:
>
>> Greetings,
>>
>> I have been working on R for some time now and I have begun the endeavor of
>> trying to replicate some SAS code in R. ?I have scoured the forums but
>> haven't been able to find an answer. ?I hope one of you could be so kind as
>> to enlighten me.
>>
>> I am attempting to replicate a repeated measures experiment using some
>> standard data. ?I have posted the SAS code and output directly from a
>> publication as well as my attempts in R to replicate it. ?My main issue
>> comes with the 'unstructured' component.
>>
>> The 'dental' dataset from 'mixedQF' package,
>> equivalent to formixed data in SAS
>>
>> ? ?distance age Subject ? ?Sex
>> 1 ? ? ? 26.0 ? 8 ? ? M01 ? Male
>> 2 ? ? ? 25.0 ?10 ? ? M01 ? Male
>> 3 ? ? ? 29.0 ?12 ? ? M01 ? Male
>> 4 ? ? ? 31.0 ?14 ? ? M01 ? Male
>> 5 ? ? ? 21.5 ? 8 ? ? M02 ? Male
>> 6 ? ? ? 22.5 ?10 ? ? M02 ? Male
>> 7 ? ? ? 23.0 ?12 ? ? M02 ? Male
>> 8 ? ? ? 26.5 ?14 ? ? M02 ? Male
>> 9 ? ? ? 23.0 ? 8 ? ? M03 ? Male
>> 10 ? ? ?22.5 ?10 ? ? M03 ? Male
>> 11 ? ? ?24.0 ?12 ? ? M03 ? Male
>> 12 ? ? ?27.5 ?14 ? ? M03 ? Male
>> 13 ? ? ?25.5 ? 8 ? ? M04 ? Male
>> 14 ? ? ?27.5 ?10 ? ? M04 ? Male
>> 15 ? ? ?26.5 ?12 ? ? M04 ? Male
>> 16 ? ? ?27.0 ?14 ? ? M04 ? Male
>> 17 ? ? ?20.0 ? 8 ? ? M05 ? Male
>> 18 ? ? ?23.5 ?10 ? ? M05 ? Male
>> 19 ? ? ?22.5 ?12 ? ? M05 ? Male
>> 20 ? ? ?26.0 ?14 ? ? M05 ? Male
>> 21 ? ? ?24.5 ? 8 ? ? M06 ? Male
>> 22 ? ? ?25.5 ?10 ? ? M06 ? Male
>> 23 ? ? ?27.0 ?12 ? ? M06 ? Male
>> 24 ? ? ?28.5 ?14 ? ? M06 ? Male
>> 25 ? ? ?22.0 ? 8 ? ? M07 ? Male
>> 26 ? ? ?22.0 ?10 ? ? M07 ? Male
>> 27 ? ? ?24.5 ?12 ? ? M07 ? Male
>> 28 ? ? ?26.5 ?14 ? ? M07 ? Male
>> 29 ? ? ?24.0 ? 8 ? ? M08 ? Male
>> 30 ? ? ?21.5 ?10 ? ? M08 ? Male
>> 31 ? ? ?24.5 ?12 ? ? M08 ? Male
>> 32 ? ? ?25.5 ?14 ? ? M08 ? Male
>> 33 ? ? ?23.0 ? 8 ? ? M09 ? Male
>> 34 ? ? ?20.5 ?10 ? ? M09 ? Male
>> 35 ? ? ?31.0 ?12 ? ? M09 ? Male
>> 36 ? ? ?26.0 ?14 ? ? M09 ? Male
>> 37 ? ? ?27.5 ? 8 ? ? M10 ? Male
>> 38 ? ? ?28.0 ?10 ? ? M10 ? Male
>> 39 ? ? ?31.0 ?12 ? ? M10 ? Male
>> 40 ? ? ?31.5 ?14 ? ? M10 ? Male
>> 41 ? ? ?23.0 ? 8 ? ? M11 ? Male
>> 42 ? ? ?23.0 ?10 ? ? M11 ? Male
>> 43 ? ? ?23.5 ?12 ? ? M11 ? Male
>> 44 ? ? ?25.0 ?14 ? ? M11 ? Male
>> 45 ? ? ?21.5 ? 8 ? ? M12 ? Male
>> 46 ? ? ?23.5 ?10 ? ? M12 ? Male
>> 47 ? ? ?24.0 ?12 ? ? M12 ? Male
>> 48 ? ? ?28.0 ?14 ? ? M12 ? Male
>> 49 ? ? ?17.0 ? 8 ? ? M13 ? Male
>> 50 ? ? ?24.5 ?10 ? ? M13 ? Male
>> 51 ? ? ?26.0 ?12 ? ? M13 ? Male
>> 52 ? ? ?29.5 ?14 ? ? M13 ? Male
>> 53 ? ? ?22.5 ? 8 ? ? M14 ? Male
>> 54 ? ? ?25.5 ?10 ? ? M14 ? Male
>> 55 ? ? ?25.5 ?12 ? ? M14 ? Male
>> 56 ? ? ?26.0 ?14 ? ? M14 ? Male
>> 57 ? ? ?23.0 ? 8 ? ? M15 ? Male
>> 58 ? ? ?24.5 ?10 ? ? M15 ? Male
>> 59 ? ? ?26.0 ?12 ? ? M15 ? Male
>> 60 ? ? ?30.0 ?14 ? ? M15 ? Male
>> 61 ? ? ?22.0 ? 8 ? ? M16 ? Male
>> 62 ? ? ?21.5 ?10 ? ? M16 ? Male
>> 63 ? ? ?23.5 ?12 ? ? M16 ? Male
>> 64 ? ? ?25.0 ?14 ? ? M16 ? Male
>> 65 ? ? ?21.0 ? 8 ? ? F01 Female
>> 66 ? ? ?20.0 ?10 ? ? F01 Female
>> 67 ? ? ?21.5 ?12 ? ? F01 Female
>> 68 ? ? ?23.0 ?14 ? ? F01 Female
>> 69 ? ? ?21.0 ? 8 ? ? F02 Female
>> 70 ? ? ?21.5 ?10 ? ? F02 Female
>> 71 ? ? ?24.0 ?12 ? ? F02 Female
>> 72 ? ? ?25.5 ?14 ? ? F02 Female
>> 73 ? ? ?20.5 ? 8 ? ? F03 Female
>> 74 ? ? ?24.0 ?10 ? ? F03 Female
>> 75 ? ? ?24.5 ?12 ? ? F03 Female
>> 76 ? ? ?26.0 ?14 ? ? F03 Female
>> 77 ? ? ?23.5 ? 8 ? ? F04 Female
>> 78 ? ? ?24.5 ?10 ? ? F04 Female
>> 79 ? ? ?25.0 ?12 ? ? F04 Female
>> 80 ? ? ?26.5 ?14 ? ? F04 Female
>> 81 ? ? ?21.5 ? 8 ? ? F05 Female
>> 82 ? ? ?23.0 ?10 ? ? F05 Female
>> 83 ? ? ?22.5 ?12 ? ? F05 Female
>> 84 ? ? ?23.5 ?14 ? ? F05 Female
>> 85 ? ? ?20.0 ? 8 ? ? F06 Female
>> 86 ? ? ?21.0 ?10 ? ? F06 Female
>> 87 ? ? ?21.0 ?12 ? ? F06 Female
>> 88 ? ? ?22.5 ?14 ? ? F06 Female
>> 89 ? ? ?21.5 ? 8 ? ? F07 Female
>> 90 ? ? ?22.5 ?10 ? ? F07 Female
>> 91 ? ? ?23.0 ?12 ? ? F07 Female
>> 92 ? ? ?25.0 ?14 ? ? F07 Female
>> 93 ? ? ?23.0 ? 8 ? ? F08 Female
>> 94 ? ? ?23.0 ?10 ? ? F08 Female
>> 95 ? ? ?23.5 ?12 ? ? F08 Female
>> 96 ? ? ?24.0 ?14 ? ? F08 Female
>> 97 ? ? ?20.0 ? 8 ? ? F09 Female
>> 98 ? ? ?21.0 ?10 ? ? F09 Female
>> 99 ? ? ?22.0 ?12 ? ? F09 Female
>> 100 ? ? 21.5 ?14 ? ? F09 Female
>> 101 ? ? 16.5 ? 8 ? ? F10 Female
>> 102 ? ? 19.0 ?10 ? ? F10 Female
>> 103 ? ? 19.0 ?12 ? ? F10 Female
>> 104 ? ? 19.5 ?14 ? ? F10 Female
>> 105 ? ? 24.5 ? 8 ? ? F11 Female
>> 106 ? ? 25.0 ?10 ? ? F11 Female
>> 107 ? ? 28.0 ?12 ? ? F11 Female
>> 108 ? ? 28.0 ?14 ? ? F11 Female
>>
>> *Mixed modeling and fixed effect test*
>> SAS
>> proc mixed data=formixed;
>> class gender age person;
>> model y = gender|age;
>> repeated / type=cs sub=person;
>> run;
>>
>> output of interest to me
>> ? ? ? ? ?Tests of Fixed Effects
>> Source ? ? ? ? ? ? NDF ? DDF ? ?Type III F ? ?Pr > F
>> GENDER ? ? ? ? ? 1 ? ? ? ?25 ? ? ? ?9.29 ? ? ? ?0.0054
>> AGE ? ? ? ? ? ? ? ? ?3 ? ? ? ?75 ? ? ? 35.35 ? ? ? 0.0001
>> GENDER*AGE ? 3 ? ? ? ?75 ? ? ? ?2.36 ? ? ? ?0.0781
>>
>> R (nlme package)
>> y=lme(distance~Sex*age, random=(~1|Subject), data=dental)
>> anova(y)
>>
>> ? ? ? ? ? ?numDF denDF ?F-value p-value
>> (Intercept) ? ? 1 ? ?75 4123.156 ?<.0001
>> Sex ? ? ? ? ? ? ?1 ? ?25 ? ?9.292 ?0.0054
>> age ? ? ? ? ? ? ? 3 ? ?75 ? 40.032 ?<.0001
>> Sex:age ? ? ? ?3 ? ?75 ? ?2.362 ?0.0781
>>
>> Now this isn't exact but it is extremely close, however when I try to
>> replicate the unstructured,
>>
>> SAS
>> proc mixed data=formixed;
>> class gender age person;
>> model y = gender|age;
>> repeated / type=un sub=person;
>> run;
>>
>> ? ? ? ? ? ? Tests of Fixed Effects
>> Source ? ? ? ? ?NDF DDF Type III F Pr > F
>> GENDER ? ? ? ? 1 ? ?25 ? ? 9.29 ? ?0.0054
>> AGE ? ? ? ? ? ? ? ?3 ? ?25 ? ?34.45 ? 0.0001
>> GENDER*AGE 3 ? ?25 ? ? 2.93 ? ?0.0532
>>
>> R
>> either
>> y=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(,~1|Subject),
>> data=dental)
>> anova(y)
>> or
>> z=lme(distance~Sex*age, random=(~1|Subject), corr=corSymm(), data=dental)
>> anova(z)
>>
>> gives the output
>>
>> ? ? ? ? ? ?numDF denDF ?F-value ? ?p-value
>> (Intercept) ? ? 1 ? ?75 ? ? 4052.028 ?<.0001
>> Sex ? ? ? ? ? ? ?1 ? ?25 ? ? ? 8.462 ? ? ?0.0075
>> age ? ? ? ? ? ? ? 3 ? ?75 ? ? ?39.022 ? ?<.0001
>> Sex:age ? ? ? ?3 ? ?75 ? ? ? 2.868 ? ? ?0.0421
>>
>> What am I doing wrong to replicate the unstructured linear mixed model from
>> SAS?
>>
>> Regards,
>>
>> Charles
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Kevin Wright
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Sun Jan 29 02:09:40 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 28 Jan 2012 20:09:40 -0500
Subject: [R-sig-ME] r-sig-mixed-models answer
Message-ID: <4F249C54.8000803@ufl.edu>

> Date: Thu, 26 Jan 2012 13:16:12 -0600 From: Shawn McCracken 
> <smccracken at ...> To: r-sig-mixed-models at ... Subject: [R-sig-ME] GLMM
>  distribution family model comparison using Poisson w/observation 
> level random effect Message-ID: 
> <CAE+9gVGEtv6coOG1Un=pWVKWyd2s=cZQGZv3SeCgMvvENVjbWA at ...> 
> Content-Type: text/plain
> 
> Dear R mixed model users,
> 
> I have been using package glmmADMB to run a full model and then 
> reduced model versions with the following distribution families: 
> poisson, zero-inflated poisson, poisson w/observation level random 
> effect, negative binomial, zero-inflated negative binomial, negative
>  binomial type 1, and zero-inflated negative binomial type 1. The 
> models using poisson w/observation level random effect give the best
>  fit according to AIC values but I am wondering if this is a fair 
> comparison since it has an additional random variable (observation)?

  If you look, I believe you will find that the Poisson with
observation-level random effect is counted as having the same number of
parameters as the negative binomial.  The number of parameters *should* be:

  Poisson           N
  ZIP              N+1
  Poisson w/ obs   N+1
  NB               N+1
  ZINB             N+2
  NB1              N+1
  ZINB1            N+2

I just tried running this with a relatively trivial example (intercept +
1 continuous covariate + 1 intercept-only random effect, so N=3),
and glmmADMB appears to agree with what I thought it should do:

  poiss     ZIP LNPoiss      NB    ZINB     NB1   ZINB1
      3       4       4       4       5       4       5

The particular example I ran had a true NB2 distribution with N=500, 10
blocks, intercept=1, slope=2, RE variance=1, overdispersion parameter
=1.2, and this was the AIC table:

> AICtab(mlist)
        dAIC   df
NB         0.0 4
ZINB       0.9 5
LNPoiss   43.4 4
ZINB1    104.6 5
NB1      115.4 4
ZIP     1854.7 4
poiss   4730.9 3

  This is somewhat comforting.  The only thing I find surprising here is
that LNPoiss (= lognormal Poisson = Poisson with observation-level
error) is so much worse, since it has exactly the same mean-variance
relationship as NB2.  Everything else is about as I expected.

  As Mollie hints, there are two issues with applying AIC to mixed
models (one of which also applies to ZI models): (1) boundary effects
and (2) counting number of parameters.  There's more on this on
http://glmm.wikidot.com/faq as well as in the paper Mollie cites.

=========================
Since no one has responded yet, I'll take a stab at this.

You are correct that it's not quite fair, but it's not straightforward.
I'm guessing that negative binomial is the 2nd runner up because it also
is based on a Poisson distribution with a mean that comes from a
right skewed distribution (Gamma distribution). The difference is that
by including an observation level random effect, you have somewhere
between 1 and nobs-1 parameters. I believe this gives more flexibility
than the 1 extra parameter of the negative binomial model
and ideally the model would be penalized for this, but estimating
degrees of freedom in mixed models is not straightforward (see Box 3 of
Bolker et al 2009 doi:10.1016/j.tree.2008.10.008). By running a glmmadmb
example I see that the df only counts 1 parameter for the random effect
(it's standard deviation). Approximations of df are controversial.



Mollie
>



From bbolker at gmail.com  Sun Jan 29 02:44:09 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 29 Jan 2012 01:44:09 +0000 (UTC)
Subject: [R-sig-ME] checking overdispersion when modelling proportions
References: <CA+Z8Yv+_suX-_RPLLjW3U00JxXj19f43m-GjbM2T8pFm991gyw@mail.gmail.com>
Message-ID: <loom.20120129T024258-513@post.gmane.org>

Kristen Mancuso <kmancuso88 at ...> writes:

> 
> Hi,
> 
> When looking at the R book, it suggests one should be able to check for
> overdispersion when looking at the summary output of a mixed model with
> proportional data, but I am confused about how to assess this since it does
> not give residual deviance or degrees of freedom.  Any help on this would
> be greatly appreciated!
> 
> Here is the output I receive after fitting the model:
> 
> > model<-lmer(y~ Treatment*Type + (1|Site), family=binomial)
> > summary(model)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: y ~ Treatment * Type + (1 | Site)
>    AIC   BIC logLik deviance
>  37.39 47.99 -9.694    19.39
> Random effects:
>  Groups Name        Variance  Std.Dev.
>  Site   (Intercept) 0.0023005 0.047964
> Number of obs: 24, groups: Site, 12
> 
> Fixed effects:

  I just added this to http://glmm.wikidot.com/faq -- comments welcome.
 
How can I test for overdispersion?

    with the usual caveats (e.g. see Venables and Ripley MASS p. 209), plus a
few extras ? counting degrees of freedom, etc. ? the usual procedure of
calculating the sum of squared Pearson residuals and comparing it to the
residual degrees of freedom should give at least a crude idea of overdispersion.
The following crude attempt counts each variance or covariance parameter as one
model degree of freedom and presents the sum of squared Pearson residuals, the
ratio of (SSQ residuals/rdf), the residual df, and the $$p$$-value based on the
(approximately!!) appropriate $$\chi^2$ distribution.

overdisp_fun <- function(model) {
  ## number of variance parameters in 
  ##   an n-by-n variance-covariance matrix
  vpars <- function(m) {
    nrow(m)*(nrow(m)+1)/2
  }
  model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
  (rdf <- nrow(model at frame)-model.df)
  rp <- residuals(model)
  Pearson.chisq <- sum(rp^2)
  prat <- Pearson.chisq/rdf
  pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
  c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}



From deter088 at umn.edu  Mon Jan 30 19:44:29 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 30 Jan 2012 12:44:29 -0600
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
Message-ID: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120130/97069ef9/attachment-0002.pl>

From kw.stat at gmail.com  Mon Jan 30 20:30:35 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 30 Jan 2012 13:30:35 -0600
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
In-Reply-To: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
References: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
Message-ID: <CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120130/29dede4f/attachment-0002.pl>

From Paul.Thompson at SanfordHealth.org  Mon Jan 30 20:38:59 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Mon, 30 Jan 2012 19:38:59 +0000
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
In-Reply-To: <CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>
References: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
	<CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B1E2E85@SFPCEXMBX2.sanfordhealth.org>

Another approach to the problem of interactions with missing cells would be to design specific contrasts which assess interactions in those cases, but which exclude the missing cells. To do that, you would need to define the entire experiment as a single factor situation, and write the appropriate contrasts.


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Kevin Wright
Sent: Monday, January 30, 2012 1:31 PM
To: Charles Determan Jr
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lmer on dataset with missing values 'not at random'

Charles,

You are trying to fit fixed effects for two-way and three-way interactions
when, as you have shown, there are no data for certain combinations of
those factors.  Generally, to estimate fixed-effect interactions you need
data in every cell of the interaction xtabs table.

You can start by removing the interactions from your model.  If the
interactions are of interest, you could try fitting the interactions as
random effects, but you need to understand this leads to a different model
with different interpretations and inferences...

Kevin


On Mon, Jan 30, 2012 at 12:44 PM, Charles Determan Jr <deter088 at umn.edu>wrote:

> Greetings R users,
>
> I have been trying to fit a mixed model on the following dataset.  All
> columns are factors except 'met'.  When I try to run a full model with
> lmer, I get the error 'Error in mer_finalize(ans) : Downdated X'X is not
> positive definite, 27.'  I took a quick look at the dataset and I can see
> there are 4 '0's in the survival 2 group.  This makes sense as not all
> experiments made it to the end, therefore if they didn't finish then they
> didn't have any further timepoints.  I have read about missing data at
> random but I can't find a way to run lmer on a dataset that has values
> missing 'not at random'.  Is there a way to modify the lmer statement
> without cutting out data points?
>
> My sincere thanks,
>
> x
>    time group survival subj met
> 1      1     2        1      2   1.3954
> 2      2     2        1      2   1.8063
> 3      3     2        1      2   1.3684
> 4      4     2        1      2   2.0046
> 5      5     2        1      2   1.0334
> 6      6     2        1      2   0.3644
> 7      7     2        1      2   0.4819
> 8      8     2        1      2   1.4558
> 9      9     2        1     2   0.9718
> 10     1     1        2    5   0.7771
> 11     2     1        2    5   1.2439
> 12     1     2        2    8   1.0980
> 13     2     2        2    8   0.9511
> 14     1     2        1    9   1.0534
> 15     2     2        1    9   1.7279
> 16     3     2        1    9   1.4904
> 17     4     2        1    9   1.2737
> 18     5     2        1    9   0.8929
> 19     6     2        1    9   0.5828
> 20     7     2        1    9   0.3260
> 21     8     2        1    9   1.0373
> 22     9     2        1    9   0.9624
> 23     1     2        2   10   1.1391
> 24     2     2        2   10   1.3945
> 25     3     2        2   10   0.9414
> 26     4     2        2   10   1.1152
> 27     5     2        2   10   0.8222
> 28     6     2        2   10   0.4417
> 29     7     2        2   10   0.4126
> 30     1     1        1   12   1.3024
> 31     2     1        1   12   1.1811
> 32     3     1        1   12   0.9379
> 33     4     1        1   12   1.3000
> 34     5     1        1   12   1.2977
> 35     6     1        1   12   0.4949
> 36     7     1        1   12   0.5238
> 37     8     1        1   12   1.3862
> 38     1     1        1   16   1.2259
> 39     2     1        1   16   0.8681
> 40     3     1        1   16   1.2645
> 41     4     1        1   16   0.7316
> 42     5     1        1   16   0.6648
> 43     6     1        1   16   0.9671
> 44     7     1        1   16   1.0131
> 45     8     1        1   16   1.1762
> 46     9     1        1   16   0.8776
> 47     1     2        2   18   1.1231
> 48     2     2        2   18   1.2133
> 49     3     2        2   18   1.2005
> 50     4     2        2   18   0.7198
> 51     5     2        2   18   0.6620
> 52     6     2        2   18   0.5908
> 53     7     2        2   18   0.3945
> 54     1     2        2   19   0.7852
> 55     2     2        2   19   0.6758
> 56     3     2        2   19   0.5246
> 57     4     2        2   19   0.5263
> 58     1     2        2   20   1.2284
> 59     2     2        2   20   0.7017
> 60     1     2        1   23   0.9604
> 61     2     2        1   23   0.7977
> 62     3     2        1   23   1.2267
> 63     4     2        1   23   1.3857
> 64     5     2        1   23   0.9486
> 65     6     2        1   23   0.3571
> 66     7     2        1   23   0.3134
> 67     8     2        1   23   1.9984
> 68     9     2        1   23   0.4837
> 69     1     1        1   24   1.1793
> 70     2     1        1   24   1.3883
> 71     3     1        1   24   2.1080
> 72     4     1        1   24   0.8810
> 73     5     1        1   24   0.8825
> 74     6     1        1   24   0.4124
> 75     7     1        1   24   0.5270
> 76     8     1        1   24   1.9003
> 77     9     1        1   24   1.4344
> 78     1     1        1   27   1.1905
> 79     2     1        1   27   1.1033
> 80     3     1        1   27   1.4976
> 81     4     1        1   27   1.9018
> 82     5     1        1   27   0.5815
> 83     6     1        1   27   0.4428
> 84     7     1        1   27   0.4728
> 85     8     1        1   27   1.6309
> 86     9     1        1   27   0.4054
> 87     1     1        1   28   0.9538
> 88     2     1        1   28   0.7796
> 89     3     1        1   28   1.7906
> 90     5     1        1   28   0.4715
> 91     6     1        1   28   0.4214
> 92     7     1        1   28   0.4120
> 93     8     1        1   28   1.3111
> 94     9     1        1   28   0.3677
> 95     1     1        2    1   1.3853
> 96     2     1        2    1   1.5966
> 97     3     1        2    1   1.4542
> 98     4     1        2    1   1.3084
> 99     5     1        2    1   1.2826
> 100    6     1        2    1   0.6835
> 101    7     1        2    1   0.9709
> 102    1     1        1    3   1.3175
> 103    2     1        1    3   0.7792
> 104    3     1        1    3   1.8763
> 105    5     1        1    3   1.4633
> 106    6     1        1    3   0.0735
> 107    7     1        1    3   0.5612
> 108    8     1        1    3   1.3777
> 109    9     1        1    3   0.3810
> 110    1     1        2    4   1.3486
> 111    1     1        1    6   1.2635
> 112    2     1        1    6   0.7572
> 113    3     1        1    6   1.5011
> 114    5     1        1    6   0.6873
> 115    6     1        1    6   0.3778
> 116    7     1        1    6   0.4231
> 117    8     1        1    6   1.3817
> 118    9     1        1    6   0.5850
> 119    1     2        2    7   0.7362
> 120    2     2        2    7   0.5495
> 121    3     2        2    7   0.7621
> 122    4     2        2    7   0.8421
> 123    5     2        2    7   1.0438
> 124    6     2        2    7   0.9802
> 125    7     2        2    7   0.5627
> 126    1     1        1   11   1.5575
> 127    2     1        1   11   2.1356
> 128    3     1        1   11   1.3575
> 129    4     1        1   11   1.3056
> 130    5     1        1   11   0.8144
> 131    6     1        1   11   0.5876
> 132    7     1        1   11   0.4104
> 133    9     1        1   11   0.4942
> 134    1     2        1   13   1.0046
> 135    2     2        1   13   0.8805
> 136    3     2        1   13   0.7685
> 137    4     2        1   13   0.8786
> 138    5     2        1   13   1.4249
> 139    6     2        1   13   0.5339
> 140    7     2        1   13   0.5480
> 141    8     2        1   13   2.6369
> 142    9     2        1   13   1.7159
> 143    1     2        1   14   0.7161
> 144    2     2        1   14   0.3968
> 145    3     2        1   14   0.8142
> 146    4     2        1   14   0.6140
> 147    5     2        1   14   0.6585
> 148    6     2        1   14   0.7176
> 149    7     2        1   14   0.6613
> 150    8     2        1   14   1.6494
> 151    9     2        1   14   0.3903
> 152    1     1        1   15   1.4357
> 153    2     1        1   15   1.4772
> 154    3     1        1   15   1.3156
> 155    4     1        1   15   0.9654
> 156    5     1        1   15   1.2709
> 157    6     1        1   15   0.9330
> 158    7     1        1   15   0.3515
> 159    8     1        1   15   1.6801
> 160    9     1        1   15   0.3584
> 161    1     2        2   17   0.8077
> 162    2     2        2   17   0.7560
> 163    1     1        1   21   1.1890
> 164    2     1        1   21   0.9631
> 165    3     1        1   21   0.9753
> 166    4     1        1   21   0.9519
> 167    5     1        1   21   0.6348
> 168    6     1        1   21   0.8516
> 169    7     1        1   21   0.2366
> 170    8     1        1   21   1.0440
> 171    9     1        1   21   0.5360
> 172    1     2        1   22   1.0747
> 173    2     2        1   22   0.6451
> 174    3     2        1   22   0.8408
> 175    5     2        1   22   0.8730
> 176    6     2        1   22   0.3594
> 177    7     2        1   22   0.3019
> 178    9     2        1   22   1.2053
> 179    1     2        2   25   0.4654
> 180    2     2        2   25   0.3024
> 181    3     2        2   25   0.7525
> 182    4     2        2   25   0.7808
> 183    5     2        2   25   0.6294
> 184    6     2        2   25   0.3016
> 185    7     2        2   25   0.3223
> 186    1     2        1   26   0.5363
> 187    2     2        1   26   0.2279
> 188    3     2        1   26   0.4756
> 189    4     2        1   26   0.6644
> 190    5     2        1   26   0.6631
> 191    6     2        1   26   0.3419
> 192    7     2        1   26   0.4188
> 193    8     2        1   26   0.3199
> 194    9     2        1   26   0.2889
> 195    1     1        2   29   1.2765
> 196    2     1        2   29   1.0653
> 197    3     1        2   29   1.5607
> 198    1     1        1   30   0.8641
> 199    2     1        1   30   0.9250
> 200    3     1        1   30   1.0887
> 201    4     1        1   30   0.5537
> 202    5     1        1   30   0.7930
> 203    6     1        1   30   0.3960
> 204    7     1        1   30   0.3917
> 205    8     1        1   30   1.2687
> 206    9     1        1   30   0.5328
> 207    1     2        1   31   1.0765
> 208    2     2        1   31   0.8778
> 209    3     2        1   31   0.8228
> 210    4     2        1   31   1.2017
> 211    5     2        1   31   1.1787
> 212    6     2        1   31   0.4037
> 213    7     2        1   31   0.2625
> 214    8     2        1   31   2.2690
> 215    9     2        1   31   0.4423
> 216    1     1        2   32   1.2880
> 217    2     1        2   32   0.8537
>
> ds=lmer(met~group*time*survival + (1|subj), data=x)
> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 27.
>
> xtabs(~group+time+survival, x)
> , , survival = 1
>
>     time
> group  1  2  3  4  5  6  7  8  9
>    1 11 11 11  8 11 11 11 10 10
>    2  8  8  8  7  8  8  8  7  8
>
> , , survival = 2
>
>     time
> group  1  2  3  4  5  6  7  8  9
>    1  5  4  2  1  1  1  1  0  0
>    2  8  8  5  5  4  4  4  0  0
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From deter088 at umn.edu  Mon Jan 30 20:43:10 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 30 Jan 2012 13:43:10 -0600
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1E2E85@SFPCEXMBX2.sanfordhealth.org>
References: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
	<CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E2E85@SFPCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJph=V-5P9s0xgrqqJuOfveYmJzNY04svfiVsA00oP14KEow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120130/a0e91844/attachment-0002.pl>

From m.dossena at qmul.ac.uk  Mon Jan 30 21:05:18 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Mon, 30 Jan 2012 20:05:18 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
Message-ID: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>

Dear All,

I'm having a some doubts on how to properly specify the random effect  in lmer for the following experiment:

I have 10 subject assigned to treatment A and 10 assigned to treatment B. For each subject I measured 2 variables, V1 and V2, and these measures were repeated in season A and season B.

I'm interested in assessing the effect of treatment, season and their interaction on the relationship between the two variables. 

I'm a little confused on how I have to specify the random structure.

According to the design  I identified the following random structure

(1 + V2 | treatment/subject) + (1 + V2 | season)

where the first term account for the nested design and temporal pseudorplication
and the second term for the other unmeasured variable that covary with season and could affect the within season relationship between V1 and V2

correct?

Then i performed a model selection procedure, to investigate which would be the best random structure. To do so I subsequently removed each term from the random structure, and  compared the AIC score.
From this procedure it turned out that the best random structure is:  (1 + var2 | season).

My concern here is, if subject is no longer included in the random structure, i'm no longer accounting for the pseudorplication, am I?

Is the fact that the term (1 + V2 | treatment/subject) does not improve the model fit telling that in fact there is no significant correlation between measures on the same subject?


To further explore the issue, i also analysed the following random structure:

(1 + V2 | subject) + (1 + V2 | season)

and in this case the model selection procedure identified this as the best random structure.

So here is where i got confused.
My question is how do i properly specify the random structure?

Searching for an answer to my doubt in the literature, in Crawley 2007, i came across a further way to account  for temporal pseudoreplication (in lme: random = ~ season | subject) translated in lmer would it be

(season | subject) ? 

at this stage I had to give up and ask for help.
Could anyone give me some advice? is my strategy somehow wrong?

Cheers 
matteo


From Thierry.ONKELINX at inbo.be  Tue Jan 31 13:02:22 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 31 Jan 2012 12:02:22 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
Message-ID: <AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>

Dear Matteo,

You want to know the effect of treatment and season: then you should use them as fixed effect. Here a some models

V1 ~ treatment * season + V2 + (1|subject)
V1 ~ treatment * season + V2 + (1 + V2|subject) #interaction between subject and V2
V1 ~ treatment * season + V2 + (1|subject/season) #interaction between subject and season

You way want to do some reading on mixed models. E.g. Zuur et al (2009)

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens matteo dossena
Verzonden: maandag 30 januari 2012 21:05
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] repeated measure in partially crossed design

Dear All,

I'm having a some doubts on how to properly specify the random effect  in lmer for the following experiment:

I have 10 subject assigned to treatment A and 10 assigned to treatment B. For each subject I measured 2 variables, V1 and V2, and these measures were repeated in season A and season B.

I'm interested in assessing the effect of treatment, season and their interaction on the relationship between the two variables. 

I'm a little confused on how I have to specify the random structure.

According to the design  I identified the following random structure

(1 + V2 | treatment/subject) + (1 + V2 | season)

where the first term account for the nested design and temporal pseudorplication and the second term for the other unmeasured variable that covary with season and could affect the within season relationship between V1 and V2

correct?

Then i performed a model selection procedure, to investigate which would be the best random structure. To do so I subsequently removed each term from the random structure, and  compared the AIC score.
>From this procedure it turned out that the best random structure is:  (1 + var2 | season).

My concern here is, if subject is no longer included in the random structure, i'm no longer accounting for the pseudorplication, am I?

Is the fact that the term (1 + V2 | treatment/subject) does not improve the model fit telling that in fact there is no significant correlation between measures on the same subject?


To further explore the issue, i also analysed the following random structure:

(1 + V2 | subject) + (1 + V2 | season)

and in this case the model selection procedure identified this as the best random structure.

So here is where i got confused.
My question is how do i properly specify the random structure?

Searching for an answer to my doubt in the literature, in Crawley 2007, i came across a further way to account  for temporal pseudoreplication (in lme: random = ~ season | subject) translated in lmer would it be

(season | subject) ? 

at this stage I had to give up and ask for help.
Could anyone give me some advice? is my strategy somehow wrong?

Cheers
matteo
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From natalia.vizcaino.palomar at gmail.com  Tue Jan 31 13:02:46 2012
From: natalia.vizcaino.palomar at gmail.com (=?ISO-8859-1?Q?Natalia_Vizca=EDno_Palomar?=)
Date: Tue, 31 Jan 2012 13:02:46 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
	positive definite, 9
Message-ID: <CAOh1aTwMhp8EexKATiJp81kA_+6-LyxZShkuZa-8jiN--59ONw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120131/50e23fa7/attachment-0002.pl>

From m.dossena at qmul.ac.uk  Tue Jan 31 13:43:42 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Tue, 31 Jan 2012 12:43:42 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
Message-ID: <8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>

Thierry,
thanks for the answer.
I apologize for having omitted the fixed effect from the model posted previously.

My doubts are regarding the specification of the random structure.
more specifically should i specify in the random structure that subject is nested within treatment?
Correct me if I'm wrong, but , doesn't the syntax: (1|subject/season) means season nested within subject? 

second
Having repeated measures on subject, including subject in the random effect, am I already accounting for the non independence of the residuals?
or should I also add the correlation structure?

sorry for the incompleteness of my previous post, hope this hep to clarify my question.

best regards
m.


Il giorno 31 Jan 2012, alle ore 12:02, ONKELINX, Thierry ha scritto:

> Dear Matteo,
> 
> You want to know the effect of treatment and season: then you should use them as fixed effect. Here a some models
> 
> V1 ~ treatment * season + V2 + (1|subject)
> V1 ~ treatment * season + V2 + (1 + V2|subject) #interaction between subject and V2
> V1 ~ treatment * season + V2 + (1|subject/season) #interaction between subject and season
> 
> You way want to do some reading on mixed models. E.g. Zuur et al (2009)
> 
> Best regards,
> 
> Thierry
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens matteo dossena
> Verzonden: maandag 30 januari 2012 21:05
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] repeated measure in partially crossed design
> 
> Dear All,
> 
> I'm having a some doubts on how to properly specify the random effect  in lmer for the following experiment:
> 
> I have 10 subject assigned to treatment A and 10 assigned to treatment B. For each subject I measured 2 variables, V1 and V2, and these measures were repeated in season A and season B.
> 
> I'm interested in assessing the effect of treatment, season and their interaction on the relationship between the two variables. 
> 
> I'm a little confused on how I have to specify the random structure.
> 
> According to the design  I identified the following random structure
> 
> (1 + V2 | treatment/subject) + (1 + V2 | season)
> 
> where the first term account for the nested design and temporal pseudorplication and the second term for the other unmeasured variable that covary with season and could affect the within season relationship between V1 and V2
> 
> correct?
> 
> Then i performed a model selection procedure, to investigate which would be the best random structure. To do so I subsequently removed each term from the random structure, and  compared the AIC score.
> From this procedure it turned out that the best random structure is:  (1 + var2 | season).
> 
> My concern here is, if subject is no longer included in the random structure, i'm no longer accounting for the pseudorplication, am I?
> 
> Is the fact that the term (1 + V2 | treatment/subject) does not improve the model fit telling that in fact there is no significant correlation between measures on the same subject?
> 
> 
> To further explore the issue, i also analysed the following random structure:
> 
> (1 + V2 | subject) + (1 + V2 | season)
> 
> and in this case the model selection procedure identified this as the best random structure.
> 
> So here is where i got confused.
> My question is how do i properly specify the random structure?
> 
> Searching for an answer to my doubt in the literature, in Crawley 2007, i came across a further way to account  for temporal pseudoreplication (in lme: random = ~ season | subject) translated in lmer would it be
> 
> (season | subject) ? 
> 
> at this stage I had to give up and ask for help.
> Could anyone give me some advice? is my strategy somehow wrong?
> 
> Cheers
> matteo
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From m.dossena at qmul.ac.uk  Tue Jan 31 14:58:33 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Tue, 31 Jan 2012 13:58:33 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
Message-ID: <F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120131/4124209c/attachment-0002.pl>

From deter088 at umn.edu  Tue Jan 31 16:01:17 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 31 Jan 2012 09:01:17 -0600
Subject: [R-sig-ME] lmer on dataset with missing values 'not at random'
In-Reply-To: <CAOLJphkvfuD2CLwbvGUVedWWi+rpUKmxq-hgWCmLr=Tn=WCgGg@mail.gmail.com>
References: <CAOLJphmuPOXbgP--JajAEt85Rtxf9d9HwwYzncf4eic+mGoCLQ@mail.gmail.com>
	<CAKFxdiQSCULfa29Tkak6QpY0WqGD6h9C6fVB=2rGKj7G3nd7+g@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E2E85@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJph=V-5P9s0xgrqqJuOfveYmJzNY04svfiVsA00oP14KEow@mail.gmail.com>
	<CAKFxdiSn43NBkrAbh5CSzLuhH_TFrnfN+79E3s1-ds3HEM0YPA@mail.gmail.com>
	<CAOLJphkvfuD2CLwbvGUVedWWi+rpUKmxq-hgWCmLr=Tn=WCgGg@mail.gmail.com>
Message-ID: <CAOLJphnN0s6JqGpUYHgCzqfcyBKf2s50jQFpxVxX5_eb-6t_Cg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120131/93d3c7aa/attachment-0002.pl>

From agalecki at umich.edu  Tue Jan 31 17:43:18 2012
From: agalecki at umich.edu (Andrzej Galecki)
Date: Tue, 31 Jan 2012 11:43:18 -0500
Subject: [R-sig-ME] Book about linear mixed effects models using R
In-Reply-To: <4EC2C691.9080800@umich.edu>
References: <4EC2C691.9080800@umich.edu>
Message-ID: <4F281A26.9040401@umich.edu>

Dear Mixed Models Experts,

My colleague Tomasz Burzykowski from the Hasselt University, Belgium and 
I are in a final stage of writing a book about linear mixed effects 
models using R. The book focuses on applications of lme() function from 
nlme package, but there are some examples of using  lmer() function from 
lme4 package. Part I of the book is available at:

http://www-personal.umich.edu/~agalecki/BookPartI120131.pdf.

The book underwent two rounds of ''official'' review and selected 
portions of it have been read by some members of this list. At this 
point, we are getting ready to submit the manuscript to Springer for a 
final editorial review.

If  you are willing/be able within the next 4-6 weeks to read selected 
chapters of the manuscript, share your comments, suggestions, catch 
mistakes, omissions, make syntax more efficient, make sure we are using 
proper terminology etc please contact me directly at agalecki at umich.edu.

With warm regards,

Andrzej Galecki
University of Michigan
http://www-personal.umich.edu/~agalecki



From oneil.shawnt at gmail.com  Tue Jan 31 01:03:00 2012
From: oneil.shawnt at gmail.com (Shawn O'Neil)
Date: Mon, 30 Jan 2012 19:03:00 -0500
Subject: [R-sig-ME] setting corStruct range in a mixed effects model
Message-ID: <CAHJOu+pv_ZhsYozDwo0OUM+ak_OFZL6y31-GqoJoV0-_vnELsg@mail.gmail.com>

Hello all,

I have a question regarding the use of the available correlation structures
in package nlme.  We are using mixed effects models to relate information
from lesser scaup kernel density distributions to underlying habitat
covariates.  Based on semivariogram and correlogram examinations, we find
spatial autocorrelation between the residuals of our full linear mixed
effects model.  We have tried to follow an example given by Pinheiro &
Bates (2000, pp 262-264) where a spherical correlation structure is fitted
to a sample semivariogram by imposing a user-defined range and nugget.  We
are trying this approach in an attempt to ignore some potentially spurious
autocorrelation effects occurring at large lag distances.  However, we
cannot achieve the result that the authors do in forcing a specific range.

For example,  we run a random intercept model using all of our covariates
including a surface trend:


FormXY <- formula(logUDval ~ DEP + I(DEP^2) + log(EDGE+0.5) + H2O:SUB +
log(CATTR+0.5) + NHOT +
    I(NHOT^2) + H2O*NDENS + I(NDENS^2) + Year_ + BCIndex + Age + X_ST*Y_ST
+ I(X_ST^2) + I(Y_ST^2) + I(X_ST^3)
    + I(Y_ST^3))

m11.lme<-lme(FormXY, random = ~1 | BirdID, method = "REML", data=hrdata)

Next, we examine the sample semivariogram (Figure 1) and determine that the
range should be approximately 900 and we do not see a significant nugget
effect.  At distances > 3500, there are some odd things occurring that for
now we would like to ignore.  We are primarily concerned with modeling the
spatial autocorrelation that is evident between 0 and 900 so we try to
specify this using the spherical correlation structure (as an example).  I
had to use lmeControl to get around false convergence errors:

m11.lme.spher<-lme(FormXY, random = ~1 | BirdID, correlation =
corSpher(c(900), form = ~X_COORD + Y_COORD | BirdID), method =
"REML",       data=hrdata,
control = lmeControl(opt = c("optim")))

The model finishes but we can see by the sample semivariogram (Figure 2)
and the sample semivariogram of normalized residuals (Figure 3) that the
correlation structure did not fit the way we wanted it to.  Also, the range
in the model summary does not match the value that we put in:

> summary(m11.lme.spher)
Linear mixed-effects model fit by REML
 Data: hrdata
        AIC       BIC   logLik
  -26755.58 -26562.75 13402.79

Random effects:
 Formula: ~1 | BirdID
        (Intercept)  Residual
StdDev:   0.5524643 0.3513228

Correlation Structure: Spherical spatial correlation
 Formula: ~X_COORD + Y_COORD | BirdID
 Parameter estimate(s):
   range
1950.937

Am I making a mistake somewhere?  We have tried all the other corStructs
and also tried setting the nugget in addition to the range but we never get
to a result that models the spatial autocorrelation trend accurately at
distances 0 - 900.  Any advice is greatly appreciated!

Thank you,
Shawn

-- 
Shawn O'Neil
Research Assistant, Applied Ecology
Forest Resources and Environmental Science
Michigan Technological University
701-741-4361

From slu at ccsr.uchicago.edu  Tue Jan 31 18:51:03 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 31 Jan 2012 11:51:03 -0600
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
Message-ID: <1328032263.8250.12.camel@localhost>

Hello, I have a dataset with outcomes {1, 2, 3, 4}. The outcome variable
is actually ordered categories, but as point of reference for
comparison, I analyzed it as numeric in lmer, and got these results:

Linear mixed model fit by REML 
Formula: rating ~ comp.f + grade.f + subject.f + obsord.f + (1 | obsid)
+      (1 | tid) + (1 | grade.f) + (1 | subject.f) + (1 | obsord.f) 
   Data: ratings.prin 
  AIC  BIC logLik deviance REMLdev
 6886 7058  -3416     6740    6832
Random effects:
 Groups    Name        Variance   Std.Dev.
 tid       (Intercept) 0.19082494 0.436835
 obsid     (Intercept) 0.10405718 0.322579
 subject.f (Intercept) 0.00075553 0.027487
 grade.f   (Intercept) 0.00075435 0.027465
 obsord.f  (Intercept) 0.00060346 0.024565
 Residual              0.24073207 0.490645
Number of obs: 4253, groups: tid, 245; obsid, 94; subject.f, 5; grade.f,
5; obsord.f, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept)  3.261329   0.140592  23.197
comp.f2     -0.095729   0.033461  -2.861
comp.f3     -0.061422   0.033316  -1.844
comp.f4     -0.144613   0.033364  -4.334
comp.f5     -0.059794   0.033599  -1.780
comp.f6     -0.074454   0.033249  -2.239
comp.f7     -0.325454   0.033274  -9.781
comp.f8     -0.186724   0.033187  -5.626
comp.f9     -0.320803   0.033741  -9.508
comp.f10    -0.226328   0.034056  -6.646
grade.f2    -0.203406   0.140249  -1.450
grade.f3    -0.227049   0.134389  -1.689
grade.f4    -0.377642   0.137710  -2.742
grade.f5    -0.225643   0.140196  -1.609
subject.f2  -0.009939   0.053291  -0.187
subject.f3   0.289519   0.061324   4.721
subject.f4  -0.223719   0.107737  -2.077
subject.f5  -0.025963   0.073520  -0.353
obsord.f2    0.004840   0.038436   0.126
obsord.f3    0.112110   0.052707   2.127
obsord.f4    0.156406   0.078614   1.990

These results seem somewhat reasonable to me. But when I analyze the
very same dataset using the same model in MCMCglmm I get very different
results:

glme5 <- MCMCglmm(rating.o ~ comp.f + grade.f + subject.f + obsord.f ,
                  prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0),
G5=list(V=1, nu=0) )),
               random = ~tid + obsid + grade.f + subject.f + obsord.f ,
               family = "ordinal",
               nitt=100000,
               data = ratings.prin)


 Iterations = 3001:99991
 Thinning interval  = 10
 Sample size  = 9700 

 DIC: 5701.873 

 G-structure:  ~tid

    post.mean l-95% CI u-95% CI eff.samp
tid     2.423    1.821    3.063     2759

               ~obsid

      post.mean l-95% CI u-95% CI eff.samp
obsid     1.521   0.7707    2.331     5227

               ~grade.f

        post.mean  l-95% CI  u-95% CI eff.samp
grade.f  95365148 2.234e-17 104888830     2296

               ~subject.f

          post.mean  l-95% CI  u-95% CI eff.samp
subject.f   7.5e+07 1.502e-17 101313849     3950

               ~obsord.f

         post.mean  l-95% CI u-95% CI eff.samp
obsord.f 122278523 2.079e-17 64065615     3851

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: rating.o ~ comp.f + grade.f + subject.f + obsord.f 

             post.mean   l-95% CI   u-95% CI eff.samp    pMCMC    
(Intercept)  1.430e+02 -2.218e+04  1.781e+04    10178 0.607629    
comp.f2     -3.448e-01 -5.854e-01 -1.161e-01     6220 0.004124 ** 
comp.f3     -2.219e-01 -4.527e-01  1.402e-02     6328 0.064124 .  
comp.f4     -5.166e-01 -7.459e-01 -2.831e-01     6454 0.000206 ***
comp.f5     -2.087e-01 -4.431e-01  2.333e-02     6338 0.084536 .  
comp.f6     -2.692e-01 -5.091e-01 -4.112e-02     6290 0.024948 *  
comp.f7     -1.163e+00 -1.403e+00 -9.395e-01     4027  < 1e-04 ***
comp.f8     -6.682e-01 -9.011e-01 -4.368e-01     5448  < 1e-04 ***
comp.f9     -1.157e+00 -1.392e+00 -9.171e-01     4253  < 1e-04 ***
comp.f10    -8.167e-01 -1.056e+00 -5.742e-01     6152  < 1e-04 ***
grade.f2    -2.417e+00 -7.966e+03  8.888e+03    13314 0.396082    
grade.f3     1.304e+02 -7.486e+03  9.484e+03    10314 0.342062    
grade.f4    -1.684e+02 -9.879e+03  6.926e+03    12352 0.283711    
grade.f5     1.218e+02 -8.380e+03  7.895e+03     8740 0.351546    
subject.f2  -9.163e+01 -7.562e+03  7.806e+03    12224 0.930309    
subject.f3   1.699e+01 -7.411e+03  8.238e+03    12320 0.344536    
subject.f4   3.477e+01 -9.427e+03  7.519e+03    13106 0.372165    
subject.f5  -1.203e+02 -7.618e+03  8.837e+03     9071 0.848247    
obsord.f2   -5.860e+01 -7.058e+03  5.605e+03     9290 0.819794    
obsord.f3   -9.302e+01 -5.852e+03  5.641e+03     7386 0.332990    
obsord.f4   -1.243e+02 -6.891e+03  6.093e+03    10073 0.343299    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

 Cutpoints: 
                         post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitrating.o.1     3.309    3.101    3.517    172.5
cutpoint.traitrating.o.2     6.790    6.552    7.056    150.1


Obviously, something has gone kablooey here. The confidence intervals
for the grade, subject and obsord random effects range over 25 orders of
magnitude, and the fixed effects are also extremely large (but with
correspondingly large standard errors). The intercept is 143, while the
outcomes only range between 1 and 4. Can anyone tell me what I have
screwed up here?

TIA.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
To paraphrase provocatively, 'machine learning is
 statistics minus any checking of models and
 assumptions'.    -- Brian D. Ripley (about the
 difference between machine learning and      
 statistics)       useR! 2004, Vienna (May 2004)



From Thierry.ONKELINX at inbo.be  Tue Jan 31 20:43:47 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 31 Jan 2012 19:43:47 +0000
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
In-Reply-To: <1328032263.8250.12.camel@localhost>
References: <1328032263.8250.12.camel@localhost>
Message-ID: <AA818EAD2576BC488B4F623941DA74275733A260@inbomail.inbo.be>

Dear Stuart,

A few remarks on the model itself. You are adding 3 factors both as fixed and random effect. That is not a good idea since they will be competing for exact the same information. Hence the huge CI with the MCMC model. 

I'm a bit surprised with the lmer results as well. I would expect to see zero variances for these random effects.

Best regards,

Thierry


________________________________________
Van: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] namens Stuart Luppescu [slu at ccsr.uchicago.edu]
Verzonden: dinsdag 31 januari 2012 18:51
Aan: r-sig-mixed-models
Onderwerp: [R-sig-ME] Very different results from lmer and MCMCglmm

Hello, I have a dataset with outcomes {1, 2, 3, 4}. The outcome variable
is actually ordered categories, but as point of reference for
comparison, I analyzed it as numeric in lmer, and got these results:

Linear mixed model fit by REML
Formula: rating ~ comp.f + grade.f + subject.f + obsord.f + (1 | obsid)
+      (1 | tid) + (1 | grade.f) + (1 | subject.f) + (1 | obsord.f)
   Data: ratings.prin
  AIC  BIC logLik deviance REMLdev
 6886 7058  -3416     6740    6832
Random effects:
 Groups    Name        Variance   Std.Dev.
 tid       (Intercept) 0.19082494 0.436835
 obsid     (Intercept) 0.10405718 0.322579
 subject.f (Intercept) 0.00075553 0.027487
 grade.f   (Intercept) 0.00075435 0.027465
 obsord.f  (Intercept) 0.00060346 0.024565
 Residual              0.24073207 0.490645
Number of obs: 4253, groups: tid, 245; obsid, 94; subject.f, 5; grade.f,
5; obsord.f, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept)  3.261329   0.140592  23.197
comp.f2     -0.095729   0.033461  -2.861
comp.f3     -0.061422   0.033316  -1.844
comp.f4     -0.144613   0.033364  -4.334
comp.f5     -0.059794   0.033599  -1.780
comp.f6     -0.074454   0.033249  -2.239
comp.f7     -0.325454   0.033274  -9.781
comp.f8     -0.186724   0.033187  -5.626
comp.f9     -0.320803   0.033741  -9.508
comp.f10    -0.226328   0.034056  -6.646
grade.f2    -0.203406   0.140249  -1.450
grade.f3    -0.227049   0.134389  -1.689
grade.f4    -0.377642   0.137710  -2.742
grade.f5    -0.225643   0.140196  -1.609
subject.f2  -0.009939   0.053291  -0.187
subject.f3   0.289519   0.061324   4.721
subject.f4  -0.223719   0.107737  -2.077
subject.f5  -0.025963   0.073520  -0.353
obsord.f2    0.004840   0.038436   0.126
obsord.f3    0.112110   0.052707   2.127
obsord.f4    0.156406   0.078614   1.990

These results seem somewhat reasonable to me. But when I analyze the
very same dataset using the same model in MCMCglmm I get very different
results:

glme5 <- MCMCglmm(rating.o ~ comp.f + grade.f + subject.f + obsord.f ,
                  prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0),
G5=list(V=1, nu=0) )),
               random = ~tid + obsid + grade.f + subject.f + obsord.f ,
               family = "ordinal",
               nitt=100000,
               data = ratings.prin)


 Iterations = 3001:99991
 Thinning interval  = 10
 Sample size  = 9700

 DIC: 5701.873

 G-structure:  ~tid

    post.mean l-95% CI u-95% CI eff.samp
tid     2.423    1.821    3.063     2759

               ~obsid

      post.mean l-95% CI u-95% CI eff.samp
obsid     1.521   0.7707    2.331     5227

               ~grade.f

        post.mean  l-95% CI  u-95% CI eff.samp
grade.f  95365148 2.234e-17 104888830     2296

               ~subject.f

          post.mean  l-95% CI  u-95% CI eff.samp
subject.f   7.5e+07 1.502e-17 101313849     3950

               ~obsord.f

         post.mean  l-95% CI u-95% CI eff.samp
obsord.f 122278523 2.079e-17 64065615     3851

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: rating.o ~ comp.f + grade.f + subject.f + obsord.f

             post.mean   l-95% CI   u-95% CI eff.samp    pMCMC
(Intercept)  1.430e+02 -2.218e+04  1.781e+04    10178 0.607629
comp.f2     -3.448e-01 -5.854e-01 -1.161e-01     6220 0.004124 **
comp.f3     -2.219e-01 -4.527e-01  1.402e-02     6328 0.064124 .
comp.f4     -5.166e-01 -7.459e-01 -2.831e-01     6454 0.000206 ***
comp.f5     -2.087e-01 -4.431e-01  2.333e-02     6338 0.084536 .
comp.f6     -2.692e-01 -5.091e-01 -4.112e-02     6290 0.024948 *
comp.f7     -1.163e+00 -1.403e+00 -9.395e-01     4027  < 1e-04 ***
comp.f8     -6.682e-01 -9.011e-01 -4.368e-01     5448  < 1e-04 ***
comp.f9     -1.157e+00 -1.392e+00 -9.171e-01     4253  < 1e-04 ***
comp.f10    -8.167e-01 -1.056e+00 -5.742e-01     6152  < 1e-04 ***
grade.f2    -2.417e+00 -7.966e+03  8.888e+03    13314 0.396082
grade.f3     1.304e+02 -7.486e+03  9.484e+03    10314 0.342062
grade.f4    -1.684e+02 -9.879e+03  6.926e+03    12352 0.283711
grade.f5     1.218e+02 -8.380e+03  7.895e+03     8740 0.351546
subject.f2  -9.163e+01 -7.562e+03  7.806e+03    12224 0.930309
subject.f3   1.699e+01 -7.411e+03  8.238e+03    12320 0.344536
subject.f4   3.477e+01 -9.427e+03  7.519e+03    13106 0.372165
subject.f5  -1.203e+02 -7.618e+03  8.837e+03     9071 0.848247
obsord.f2   -5.860e+01 -7.058e+03  5.605e+03     9290 0.819794
obsord.f3   -9.302e+01 -5.852e+03  5.641e+03     7386 0.332990
obsord.f4   -1.243e+02 -6.891e+03  6.093e+03    10073 0.343299
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

 Cutpoints:
                         post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitrating.o.1     3.309    3.101    3.517    172.5
cutpoint.traitrating.o.2     6.790    6.552    7.056    150.1


Obviously, something has gone kablooey here. The confidence intervals
for the grade, subject and obsord random effects range over 25 orders of
magnitude, and the fixed effects are also extremely large (but with
correspondingly large standard errors). The intercept is 143, while the
outcomes only range between 1 and 4. Can anyone tell me what I have
screwed up here?

TIA.

--
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu
University of Chicago -=- CCSR
???????? -=-    Kernel 3.2.1-gentoo-r2
To paraphrase provocatively, 'machine learning is
 statistics minus any checking of models and
 assumptions'.    -- Brian D. Ripley (about the
 difference between machine learning and
 statistics)       useR! 2004, Vienna (May 2004)

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From slu at ccsr.uchicago.edu  Tue Jan 31 23:08:18 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 31 Jan 2012 16:08:18 -0600
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
In-Reply-To: <AA818EAD2576BC488B4F623941DA74275733A260@inbomail.inbo.be>
References: <1328032263.8250.12.camel@localhost>
	<AA818EAD2576BC488B4F623941DA74275733A260@inbomail.inbo.be>
Message-ID: <1328047698.8250.18.camel@localhost>

On Tue, 2012-01-31 at 19:43 +0000, ONKELINX, Thierry wrote:
> A few remarks on the model itself. You are adding 3 factors both as
> fixed and random effect. That is not a good idea since they will be
> competing for exact the same information. Hence the huge CI with the
> MCMC model. 

Ah, right. I reran it without the fixed effects and the results were
much better.

> I'm a bit surprised with the lmer results as well. I would expect to
> see zero variances for these random effects.

Wow. lmer is really robust!

Thanks very much for the help.
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
If I were to be treated by a cure created by
 stepwise regression, I would prefer voodoo.    -- 
 Dieter Menne (in a thread about regressions with
 many variables)       R-help (October 2009)



From David.Duffy at qimr.edu.au  Tue Jan 31 23:33:30 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 1 Feb 2012 08:33:30 +1000 (EST)
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
In-Reply-To: <1328032263.8250.12.camel@localhost>
References: <1328032263.8250.12.camel@localhost>
Message-ID: <Pine.LNX.4.64.1202010821140.13091@orpheus.qimr.edu.au>

What did you get from MCMCglmm(...family="gaussian")?

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Wed Feb  1 03:15:12 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 1 Feb 2012 02:15:12 +0000 (UTC)
Subject: [R-sig-ME] repeated measure in partially crossed design
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
	<F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>
Message-ID: <loom.20120201T030103-410@post.gmane.org>

matteo dossena <m.dossena at ...> writes:

> Dear all,
 
> sorry to write again on this topic, but i feel like I haven't make
> myself clear.  I try to rephrase my question, hope I'm not annoying
> you.  So given that each level of season - e.g. April and Oct -
> occurs at each level of subject while each level of treatment
> -e.g. high or control - only occurs on a half of the the subjects
> respectively and randomly, should I specify the random effects in
> the model as

If you really want to "... assess[] the effect of treatment, season
and their interaction on the relationship between the two variables",
you may want treatment*season*V2 as fixed effect (so you can tell whether 
the V1~V2 relationship changes with treatment and season)

  Having any *factor* included as both a fixed effect and a random
effect will cause trouble, e.g. in your model (2).  (On the other
hand, it does sometimes make sense to include a _continuous_ predictor
as both fixed (which will estimate a linear trend) and random (which
will consider variation around the linear trend -- this only makes
sense if you have multiple measurements per value of the predictor,
though.  Another apparent exception to this is subject in the
(1|treatment/subject) term, which is only included as subject nested
within treatment.
 
> (1) having subject nested within treatment and crossed with date, 
>  V1 ~ treatment * season + V2 + (1|treatment/subject) + (1|season)

  Here both treatment and season are included as both fixed and random --
probably not a good idea.

> (2) subject crossed with date ignoring the nesting with treatment,
> (3) random effects on subject only ignoring the crossed and nested
> data structure V1 ~ treatment * season + V2 + (1|subject) +
> (1|season)

  Still probably don't want season and (1|season)
> 

> (3) random effects on subject only ignoring the crossed and nested
> data structure V1 ~ treatment * season + V2 + (1|subject)

   This is not unreasonable.  You could consider (season|subject),
or (1|subject)+(0+season|subject) [which fits the intercept and slope
independently], since you have both seasons assessed for each individual.

   This gets raised a lot on this list, but: I would generally only
drop a random effect from the model if it actually appears overfitted
(i.e.  estimated as zeros, or a perfect +1/-1 correlation between
random effects), and not if it is merely non-significant (Hurlbert
calls this "sacrificial pseudoreplication").  I've been very impressed
by the results from the blme package, which incorporates a weak
Bayesian prior to push underdetermined variance components away from
zero ...



From bbolker at gmail.com  Wed Feb  1 03:17:45 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 1 Feb 2012 02:17:45 +0000 (UTC)
Subject: [R-sig-ME] zero-truncated mixed effects logistic regression?
References: <00ca01ccd51f$1aa8e300$4ffaa900$@web.de><Pine.LNX.4.64.1201180905590.14745@orpheus.qimr.edu.au>
	<000301ccd698$a32bee00$e983ca00$@web.de>
	<6F35A958A12B9149BD16E3C2F3B0AD0DB37864@SPHINX.adqimr.ad.lan>
	<00ca01ccda9f$5e04f460$1a0edd20$@web.de>
Message-ID: <loom.20120201T031617-765@post.gmane.org>

Martin Schmettow <schmettow at ...> writes:

> 
> Thank you for your ideas. 
> 
> You seem to suggest that I use a C-R model to estimate the number of missing
> values per category and then impute these values?
> 
> Sounds feasible, although I was in hope for a more straight forward way to
> deal with zero trunc. binomial data like seemingly is available for Poisson
> data.
> 
> Since zero trunc. Poisson  is available in glmmADMB, would it also be an
> option to treat binomial data as Poisson by using a per class offset?
> 
> CU, Martin.

  Seems reasonable.  I would try it on some simulations ...

  glmmADMB has (in principle) zero-inflated binomial (although I've
never tested it ...), and truncated binomial could be implemented
without a great deal of trouble ...



From geralttee at gmail.com  Wed Feb  1 11:10:18 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Wed, 1 Feb 2012 11:10:18 +0100
Subject: [R-sig-ME] Very different results from lmer and MCMCglmm
Message-ID: <CANXb-o5boKLq_JaSbVduhPts+PEr-YFNXSXJspJaBUWPz6VysQ@mail.gmail.com>

Hi, one more thing (although it turned out not to be important_ -
you're using improper (nu=0) priors which in some situations might be
problematic. in general try using proper ones (see Jarrod's Course
Notes for details) or parameter expansion, especially if you expect
close-to-zero variances.

Cheers,
sz.

--
Szymon Drobniak || Population Ecology Group
Institute of Environmental Sciences,?Jagiellonian University
ul. Gronostajowa 7, 30-387 Krak?w, POLAND
tel.: +48 12 664 51 79 fax: +48 12 664 69 12
szymek.dronbiak at uj.edu.pl
www.eko.uj.edu.pl/drobniak



From m.dossena at qmul.ac.uk  Wed Feb  1 11:53:16 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Wed, 1 Feb 2012 10:53:16 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <loom.20120201T030103-410@post.gmane.org>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
	<F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>
	<loom.20120201T030103-410@post.gmane.org>
Message-ID: <8B77AD44-9DF0-4EE4-911D-AAA1A3948A4E@qmul.ac.uk>

Really appreciate Ben,

this really make things clearer now, seems like (season|subject), could be the appropriate structure.

However, a last doubt still trouble me.

Having (season|subject) fitted as random effect, is it taking in consideration pseudoreplication (repeated measures on subject)?
If I would do this analysis with lme() I would fit a model with the argument correlation=CorCompSymm(form=~1|subject),
and a model without correlation than compared the two to assess wether or not  there is violation of the independence.
Is this a sensible things to do?

Since i'm working with lmer(), how can I check if correlation has to be included in the model?

Cheers
m.

Il giorno 1 Feb 2012, alle ore 02:15, Ben Bolker ha scritto:

> matteo dossena <m.dossena at ...> writes:
> 
>> Dear all,
> 
>> sorry to write again on this topic, but i feel like I haven't make
>> myself clear.  I try to rephrase my question, hope I'm not annoying
>> you.  So given that each level of season - e.g. April and Oct -
>> occurs at each level of subject while each level of treatment
>> -e.g. high or control - only occurs on a half of the the subjects
>> respectively and randomly, should I specify the random effects in
>> the model as
> 
> If you really want to "... assess[] the effect of treatment, season
> and their interaction on the relationship between the two variables",
> you may want treatment*season*V2 as fixed effect (so you can tell whether 
> the V1~V2 relationship changes with treatment and season)
> 
>  Having any *factor* included as both a fixed effect and a random
> effect will cause trouble, e.g. in your model (2).  (On the other
> hand, it does sometimes make sense to include a _continuous_ predictor
> as both fixed (which will estimate a linear trend) and random (which
> will consider variation around the linear trend -- this only makes
> sense if you have multiple measurements per value of the predictor,
> though.  Another apparent exception to this is subject in the
> (1|treatment/subject) term, which is only included as subject nested
> within treatment.
> 
>> (1) having subject nested within treatment and crossed with date, 
>> V1 ~ treatment * season + V2 + (1|treatment/subject) + (1|season)
> 
>  Here both treatment and season are included as both fixed and random --
> probably not a good idea.
> 
>> (2) subject crossed with date ignoring the nesting with treatment,
>> (3) random effects on subject only ignoring the crossed and nested
>> data structure V1 ~ treatment * season + V2 + (1|subject) +
>> (1|season)
> 
>  Still probably don't want season and (1|season)
>> 
> 
>> (3) random effects on subject only ignoring the crossed and nested
>> data structure V1 ~ treatment * season + V2 + (1|subject)
> 
>   This is not unreasonable.  You could consider (season|subject),
> or (1|subject)+(0+season|subject) [which fits the intercept and slope
> independently], since you have both seasons assessed for each individual.
> 
>   This gets raised a lot on this list, but: I would generally only
> drop a random effect from the model if it actually appears overfitted
> (i.e.  estimated as zeros, or a perfect +1/-1 correlation between
> random effects), and not if it is merely non-significant (Hurlbert
> calls this "sacrificial pseudoreplication").  I've been very impressed
> by the results from the blme package, which incorporates a weak
> Bayesian prior to push underdetermined variance components away from
> zero ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From pjmiller_57 at yahoo.com  Wed Feb  1 16:32:56 2012
From: pjmiller_57 at yahoo.com (Paul Miller)
Date: Wed, 1 Feb 2012 07:32:56 -0800 (PST)
Subject: [R-sig-ME] Mixed Model Version of Two-Stage Least Squares Analysis
In-Reply-To: <8B77AD44-9DF0-4EE4-911D-AAA1A3948A4E@qmul.ac.uk>
Message-ID: <1328110376.89784.YahooMailClassic@web161603.mail.bf1.yahoo.com>

Hello Everyone,

I'm familiar with the use of Two-Stage Least Squares Analysis to obtain results like one gets with SEM. I was wondering if anyone knows how to extend this approach to nested data. My data contain multiple observations from cancer patients. The number of observations varies by patient and the intervals between observations are not equally spaced.

Is it possible to apply a 2SLS approach to my data? If so, are there measures of model fit from the standard 2SLS approach that will work if I'm using a mixed model to account for non-independence of observations in my data? Or are there maybe some other measures I could use?

Thanks,

Paul



From odirrodriguezvillagra at gmail.com  Wed Feb  1 17:34:15 2012
From: odirrodriguezvillagra at gmail.com (=?ISO-8859-1?Q?Odir_Rodr=EDguez_Villagra?=)
Date: Wed, 1 Feb 2012 17:34:15 +0100
Subject: [R-sig-ME] question about random intercept reflecting mean value of
 between subject factor
Message-ID: <CAGDkQnb0LLTrHfFQVGFOAz5nXSv8ejy1jkanR1D_tNN5PKHKTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120201/0460f4c3/attachment-0002.pl>

From maggie.neff at gmail.com  Wed Feb  1 19:54:20 2012
From: maggie.neff at gmail.com (Maggie Neff)
Date: Wed, 1 Feb 2012 13:54:20 -0500
Subject: [R-sig-ME] Estimating variance in linear mixed models
Message-ID: <CAH3MgyL_8snnonps579mo9AtiyYJhJ-a=Q1fr1UQW113ZW9mTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120201/f21c9467/attachment-0002.pl>

From ljkjar at hotmail.com  Wed Feb  1 21:00:11 2012
From: ljkjar at hotmail.com (Lene Jung)
Date: Wed, 1 Feb 2012 21:00:11 +0100
Subject: [R-sig-ME] non-parametric mixed model
Message-ID: <BLU0-SMTP34095B4B35D4B3D1402D31CDB730@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120201/5622979b/attachment-0002.pl>

From rstuff.miles at gmail.com  Wed Feb  1 21:31:05 2012
From: rstuff.miles at gmail.com (Andrew Miles)
Date: Wed, 1 Feb 2012 15:31:05 -0500
Subject: [R-sig-ME] Estimating variance in linear mixed models
In-Reply-To: <CAH3MgyL_8snnonps579mo9AtiyYJhJ-a=Q1fr1UQW113ZW9mTw@mail.gmail.com>
References: <CAH3MgyL_8snnonps579mo9AtiyYJhJ-a=Q1fr1UQW113ZW9mTw@mail.gmail.com>
Message-ID: <85BBAFD8-A893-4A45-960C-6241B43ACB44@gmail.com>

A linear multilevel model like you are using can be used to estimate the between-year variance, like so (note I'm using the lmer function, not lme, which I am less familiar with):

library(lme4)
mod=lmer(cont ~ 1 + (1|year), data=fish)

The Random Effects for (Intercept) will give you the variance of the estimates of contaminants in each year.  However, with only 9 different years (and hence 9 different estimates of contaminants), the random effect might not be very reliable.  You can get model predicted estimates for each of the years like so:
coef(mod)

I can't immediately think of a way to estimate within-year variance using a MLM, but you could get estimates of the within-year variance doing something like this:
tapply(cont, year, var)

This should break down cont by year, and then estimate the variance in each year.

I hope this helps.

Andrew Miles


On Feb 1, 2012, at 1:54 PM, Maggie Neff wrote:

> Hello,
> 
> This is both an R and stats question.  I have some data covering
> contaminant concentrations in fish over a time period of ~35 years.  Each
> year, multiple samples of fish were taken (with varying sample sizes each
> year). The trend is modeled using a linear regression on ln[contaminant]
> and year.  The ultimate goal of this project is to do a power analysis for
> a monitoring program, and to do this, I need an estimation of both random
> within-year variation and random between-year variation.
> 
> I used a linear mixed model to estimate these variances.  My questions is
> whether the function as I've set it up will return the estimates that I'm
> looking for, and if so, which values within the output reflect those
> estimates.  If someone knows of a better/alternative way to estimate these
> values, that would also be useful.
> 
>> fish<-read.csv("data.csv",header=TRUE)
>> fish
>   SPECIES YEAR CONT
> 1  Walleye 1970 2.83
> 2  Walleye 1970 2.56
> 3  Walleye 1970 2.83
> 4  Walleye 1970 2.56
> 5  Walleye 1970 2.77
> 6  Walleye 1970 2.56
> 7  Walleye 1970 2.64
> 8  Walleye 1970 2.22
> 9  Walleye 1970 2.56
> 10 Walleye 1970 2.40
> 11 Walleye 1975 1.59
> 12 Walleye 1975 1.53
> 13 Walleye 1975 2.16
> 14 Walleye 1975 1.60
> 15 Walleye 1975 2.16
> 16 Walleye 1976 2.03
> 17 Walleye 1976 1.97
> 18 Walleye 1976 1.95
> 19 Walleye 1976 2.36
> 20 Walleye 1976 1.82
> 21 Walleye 1976 1.99
> 22 Walleye 1977 1.06
> 23 Walleye 1977 2.00
> 24 Walleye 1977 1.97
> 25 Walleye 1977 2.00
> 26 Walleye 1977 1.99
> 27 Walleye 1977 1.95
> 28 Walleye 1977 2.10
> 29 Walleye 1977 2.29
> 30 Walleye 1977 2.20
> 31 Walleye 1979 1.90
> 32 Walleye 1979 1.98
> 33 Walleye 1979 2.00
> 34 Walleye 1979 2.11
> 35 Walleye 1980 1.92
> 36 Walleye 1980 2.00
> 37 Walleye 1980 1.98
> 38 Walleye 1980 2.25
> 39 Walleye 1981 1.22
> 40 Walleye 1981 1.36
> 41 Walleye 1981 1.48
> 42 Walleye 1981 1.86
> 43 Walleye 1981 1.41
> 44 Walleye 1982 1.25
> 45 Walleye 1982 1.10
> 46 Walleye 1982 1.28
> 47 Walleye 1982 1.28
> 48 Walleye 1982 1.77
> 49 Walleye 1982 1.59
> 50 Walleye 1982 1.61
> 51 Walleye 1982 1.55
> 52 Walleye 1984 1.25
> 53 Walleye 1984 1.41
> 54 Walleye 1984 1.50
> 55 Walleye 1984 1.39
>> year<-fish$YEAR
>> cont<-fish$CONT
>> reg3<-lme(year~cont,random=~1|year,method="REML")
>> reg3
> Linear mixed-effects model fit by REML
>  Data: NULL
>  Log-restricted-likelihood: 1243.336
>  Fixed: year ~ cont
> (Intercept)         cont
> 1.978213e+03 4.947785e-14
> 
> Random effects:
> Formula: ~1 | year
>        (Intercept)    Residual
> StdDev:     4.23609 1.18049e-13
> 
> Number of Observations: 55
> Number of Groups: 9
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Thu Feb  2 04:07:22 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 2 Feb 2012 13:07:22 +1000 (EST)
Subject: [R-sig-ME] non-parametric mixed model
In-Reply-To: <BLU0-SMTP34095B4B35D4B3D1402D31CDB730@phx.gbl>
References: <BLU0-SMTP34095B4B35D4B3D1402D31CDB730@phx.gbl>
Message-ID: <Pine.LNX.4.64.1202021302240.17444@orpheus.qimr.edu.au>

On Wed, 1 Feb 2012, Lene Jung wrote:

> variables. For all variables, I have repeated measurements from individuals
> (multiple seasons) and 2 different study sites, so I am using a mixed-model
> approach with individual as subject (random effect) to test for differences
> between sites and seasons.
>
> My problem is that I have 2 variables that are cosines which means that
> they are in the interval -1 to 1. One of the variables have many ties (many
> 1s) whereas the other doesn't.

This is circular data?  There apparently are mixed models eg for 
longitudinal circular data, and there are nonparametric tests of 
homogeneity.

eg http://www.omicsonline.org/2155-6180/2155-6180-1-107.php,
R CircStats package.

Or am I completely misunderstanding?

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From istazahn at gmail.com  Thu Feb  2 13:16:51 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 02 Feb 2012 07:16:51 -0500
Subject: [R-sig-ME] Estimating variance in linear mixed models
In-Reply-To: <85BBAFD8-A893-4A45-960C-6241B43ACB44@gmail.com>
References: <CAH3MgyL_8snnonps579mo9AtiyYJhJ-a=Q1fr1UQW113ZW9mTw@mail.gmail.com>
	<85BBAFD8-A893-4A45-960C-6241B43ACB44@gmail.com>
Message-ID: <6960314.PpG1NVmF94@arch-desktop>

Hi Andrew and Maggie,

On Wednesday, February 01, 2012 03:31:05 PM Andrew Miles wrote:
> A linear multilevel model like you are using can be used to estimate the
> between-year variance, like so (note I'm using the lmer function, not lme,
> which I am less familiar with):
> 
> library(lme4)
> mod=lmer(cont ~ 1 + (1|year), data=fish)
> 
> The Random Effects for (Intercept) will give you the variance of the
> estimates of contaminants in each year.  However, with only 9 different
> years (and hence 9 different estimates of contaminants), the random effect
> might not be very reliable.  You can get model predicted estimates for each
> of the years like so: coef(mod)
> 
> I can't immediately think of a way to estimate within-year variance using a
> MLM, but you could get estimates of the within-year variance doing
> something like this: tapply(cont, year, var)

The residual variance from the lmer model is the within-year variance, no?

> 
> This should break down cont by year, and then estimate the variance in each
> year.
> 
> I hope this helps.
> 
> Andrew Miles
> 
> On Feb 1, 2012, at 1:54 PM, Maggie Neff wrote:
> > Hello,
> > 
> > This is both an R and stats question.  I have some data covering
> > contaminant concentrations in fish over a time period of ~35 years.  Each
> > year, multiple samples of fish were taken (with varying sample sizes each
> > year). The trend is modeled using a linear regression on ln[contaminant]
> > and year.  The ultimate goal of this project is to do a power analysis for
> > a monitoring program, and to do this, I need an estimation of both random
> > within-year variation and random between-year variation.
> > 
> > I used a linear mixed model to estimate these variances.  My questions is
> > whether the function as I've set it up will return the estimates that I'm
> > looking for, and if so, which values within the output reflect those
> > estimates.  If someone knows of a better/alternative way to estimate these
> > values, that would also be useful.
> > 
> >> fish<-read.csv("data.csv",header=TRUE)
> >> fish
> >> 
> >   SPECIES YEAR CONT
> > 
> > 1  Walleye 1970 2.83
> > 2  Walleye 1970 2.56
> > 3  Walleye 1970 2.83
> > 4  Walleye 1970 2.56
> > 5  Walleye 1970 2.77
> > 6  Walleye 1970 2.56
> > 7  Walleye 1970 2.64
> > 8  Walleye 1970 2.22
> > 9  Walleye 1970 2.56
> > 10 Walleye 1970 2.40
> > 11 Walleye 1975 1.59
> > 12 Walleye 1975 1.53
> > 13 Walleye 1975 2.16
> > 14 Walleye 1975 1.60
> > 15 Walleye 1975 2.16
> > 16 Walleye 1976 2.03
> > 17 Walleye 1976 1.97
> > 18 Walleye 1976 1.95
> > 19 Walleye 1976 2.36
> > 20 Walleye 1976 1.82
> > 21 Walleye 1976 1.99
> > 22 Walleye 1977 1.06
> > 23 Walleye 1977 2.00
> > 24 Walleye 1977 1.97
> > 25 Walleye 1977 2.00
> > 26 Walleye 1977 1.99
> > 27 Walleye 1977 1.95
> > 28 Walleye 1977 2.10
> > 29 Walleye 1977 2.29
> > 30 Walleye 1977 2.20
> > 31 Walleye 1979 1.90
> > 32 Walleye 1979 1.98
> > 33 Walleye 1979 2.00
> > 34 Walleye 1979 2.11
> > 35 Walleye 1980 1.92
> > 36 Walleye 1980 2.00
> > 37 Walleye 1980 1.98
> > 38 Walleye 1980 2.25
> > 39 Walleye 1981 1.22
> > 40 Walleye 1981 1.36
> > 41 Walleye 1981 1.48
> > 42 Walleye 1981 1.86
> > 43 Walleye 1981 1.41
> > 44 Walleye 1982 1.25
> > 45 Walleye 1982 1.10
> > 46 Walleye 1982 1.28
> > 47 Walleye 1982 1.28
> > 48 Walleye 1982 1.77
> > 49 Walleye 1982 1.59
> > 50 Walleye 1982 1.61
> > 51 Walleye 1982 1.55
> > 52 Walleye 1984 1.25
> > 53 Walleye 1984 1.41
> > 54 Walleye 1984 1.50
> > 55 Walleye 1984 1.39
> > 
> >> year<-fish$YEAR
> >> cont<-fish$CONT
> >> reg3<-lme(year~cont,random=~1|year,method="REML")
> >> reg3
> > 
> > Linear mixed-effects model fit by REML
> > 
> >  Data: NULL
> >  Log-restricted-likelihood: 1243.336
> >  Fixed: year ~ cont
> > 
> > (Intercept)         cont
> > 1.978213e+03 4.947785e-14
> > 
> > Random effects:
> > Formula: ~1 | year
> > 
> >        (Intercept)    Residual
> > 
> > StdDev:     4.23609 1.18049e-13
> > 
> > Number of Observations: 55
> > Number of Groups: 9
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From c.ryan.king at gmail.com  Thu Feb  2 18:53:01 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Thu, 2 Feb 2012 11:53:01 -0600
Subject: [R-sig-ME] MCMCglmm rcov specifications
Message-ID: <CAEQ+J26csPh_-O3Pc_fz_Kfs1L_9Rg3kJiFmotYLyPDY_FnsXw@mail.gmail.com>

Hi list,
If I want to specify heterogeneous variances proportional to a known
factor in MCMCglmm, it seems like mev is the correct option, but
looking at the code it appears to add person-level random effects with
variance fixed at the specified value:

random = ~us(leg(MCMC_mev, -1, FALSE)):MCMC_meta
prior$G<-list(G1=list(V=as.matrix(1), nu=1, fix=1))

I've used the same trick to specify a known co-variance function.
However, the updates for this specification seem to go slowly and
induce bad mixing in my binary outcomes problem. The unidentified
residual variance certainly isn't helping. Is there a trick to
directly specify a matrix R and avoid inducing the identification
headache and slow MME solving?

Thanks,
Ryan King



From j.hadfield at ed.ac.uk  Thu Feb  2 19:05:34 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 2 Feb 2012 18:05:34 +0000
Subject: [R-sig-ME] MCMCglmm rcov specifications
In-Reply-To: <CAEQ+J26csPh_-O3Pc_fz_Kfs1L_9Rg3kJiFmotYLyPDY_FnsXw@mail.gmail.com>
References: <CAEQ+J26csPh_-O3Pc_fz_Kfs1L_9Rg3kJiFmotYLyPDY_FnsXw@mail.gmail.com>
Message-ID: <3A75ECEA-7E9F-4B9A-9A2B-9BCDAD31E78F@ed.ac.uk>

Hi,

see the schools example in the course notes:

rcov=~idh(units):units

prior=list(R=list(V=diag(mev), fix=1))

Cheers,

Jarrod

On 2 Feb 2012, at 17:53, Ryan King wrote:

> Hi list,
> If I want to specify heterogeneous variances proportional to a known
> factor in MCMCglmm, it seems like mev is the correct option, but
> looking at the code it appears to add person-level random effects with
> variance fixed at the specified value:
>
> random = ~us(leg(MCMC_mev, -1, FALSE)):MCMC_meta
> prior$G<-list(G1=list(V=as.matrix(1), nu=1, fix=1))
>
> I've used the same trick to specify a known co-variance function.
> However, the updates for this specification seem to go slowly and
> induce bad mixing in my binary outcomes problem. The unidentified
> residual variance certainly isn't helping. Is there a trick to
> directly specify a matrix R and avoid inducing the identification
> headache and slow MME solving?
>
> Thanks,
> Ryan King
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From j.hadfield at ed.ac.uk  Thu Feb  2 19:11:03 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 02 Feb 2012 18:11:03 +0000
Subject: [R-sig-ME] MCMCglmm rcov specifications
In-Reply-To: <3A75ECEA-7E9F-4B9A-9A2B-9BCDAD31E78F@ed.ac.uk>
References: <CAEQ+J26csPh_-O3Pc_fz_Kfs1L_9Rg3kJiFmotYLyPDY_FnsXw@mail.gmail.com>
	<3A75ECEA-7E9F-4B9A-9A2B-9BCDAD31E78F@ed.ac.uk>
Message-ID: <20120202181103.15470w7u4trln9o0@www.staffmail.ed.ac.uk>

HI,

Sorry - I was to quick. The residual variances will not be  
proportional to mev, they will be mev. Its not possible to fit the  
proportional model currently/easily, although I could imagine with  
some thought you could trick MCMCglmm into doing it via a SIR model. See

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/004916.html

for a solution to a similar problem. Not very elegant I'm afraid!

Jarrod





Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Thu, 2 Feb 2012  
18:05:34 +0000:

> Hi,
>
> see the schools example in the course notes:
>
> rcov=~idh(units):units
>
> prior=list(R=list(V=diag(mev), fix=1))
>
> Cheers,
>
> Jarrod
>
> On 2 Feb 2012, at 17:53, Ryan King wrote:
>
>> Hi list,
>> If I want to specify heterogeneous variances proportional to a known
>> factor in MCMCglmm, it seems like mev is the correct option, but
>> looking at the code it appears to add person-level random effects with
>> variance fixed at the specified value:
>>
>> random = ~us(leg(MCMC_mev, -1, FALSE)):MCMC_meta
>> prior$G<-list(G1=list(V=as.matrix(1), nu=1, fix=1))
>>
>> I've used the same trick to specify a known co-variance function.
>> However, the updates for this specification seem to go slowly and
>> induce bad mixing in my binary outcomes problem. The unidentified
>> residual variance certainly isn't helping. Is there a trick to
>> directly specify a matrix R and avoid inducing the identification
>> headache and slow MME solving?
>>
>> Thanks,
>> Ryan King
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From smccracken at tadpoleorg.org  Fri Feb  3 00:05:32 2012
From: smccracken at tadpoleorg.org (Shawn McCracken)
Date: Thu, 2 Feb 2012 17:05:32 -0600
Subject: [R-sig-ME] r-sig-mixed-models answer
In-Reply-To: <4F249C54.8000803@ufl.edu>
References: <4F249C54.8000803@ufl.edu>
Message-ID: <CAE+9gVHvy_ow2+syyGsuxAKV=_kmZaK+yOmH5OrFOZNZTQr=ow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120202/410335d1/attachment-0002.pl>

From deter088 at umn.edu  Fri Feb  3 14:05:57 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 07:05:57 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
Message-ID: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/51ef360d/attachment-0002.pl>

From deter088 at umn.edu  Fri Feb  3 15:35:52 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 08:35:52 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/d234bef9/attachment-0002.pl>

From deter088 at umn.edu  Fri Feb  3 16:17:55 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 09:17:55 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/8326c69b/attachment-0002.pl>

From jbaldwin at fs.fed.us  Fri Feb  3 16:25:43 2012
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Fri, 3 Feb 2012 15:25:43 +0000
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>

I think the only way to resolve this is to provide a specific example.

Jim Baldwin
Station Statistician
USDA Forest Service
Albany, California

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles Determan Jr
Sent: Friday, February 03, 2012 7:18 AM
To: Thompson,Paul; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lme capable of running with missing data?

So, is there a way in which I can alter the design matrix so the mixed model will work or is this something that can only be done in SAS currently?  The output from the SAS run did provide Type III fixed effect test values.

On Fri, Feb 3, 2012 at 9:14 AM, Thompson,Paul < Paul.Thompson at sanfordhealth.org> wrote:

>  That's interesting. SAS uses the sweep approach (it was in fact 
> devised by Goodnight). The method used in construction of various 
> types of SS does allow you to estimate when cells are missing. I would 
> wonder if Type II SS can be done. Type III (despite the incorrect 
> statement that they are
> illegitimate) and Type IV would work fine. ****
>
> ** **
>
> It's really an issue of the manner in which the design matrix is
> contructed.****
>
> ** **
>
> *From:* Charles Determan Jr [mailto:deter088 at umn.edu]
> *Sent:* Friday, February 03, 2012 8:36 AM
> *To:* Thompson,Paul; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] lme capable of running with missing 
> data?****
>
> ** **
>
> Thank you Paul, I do appreciate your response and especially your time.
> The reason I am so persistent is that I know the prior data I posted 
> was run in SAS (however I don't have the exact coding although I do 
> know it was done with PROC MIXED with an unstructured covariance 
> structure and REML estimation method) and it provided all the 
> interactions.  As such, I have scoured the web and literature as to 
> how this could be done with the missing data (timepoints as a result 
> of survival).  Perhaps this simply has not yet been done in R and I am 
> stuck for the time being.  None-the-less, I want to be certain before I give up on running this type of analysis in R.
>
> Thanks again,****
>
> On Fri, Feb 3, 2012 at 8:26 AM, Thompson,Paul < 
> Paul.Thompson at sanfordhealth.org> wrote:****
>
> Charles:
>
> I did suggest the use of specific contrasts to do the analysis with 
> missing cells. I played around, and just have to admit that this is 
> not possible. I tried to use standard construction techniques to 
> produce main effects using contrast coding, and then multiply those to 
> produce interactions. This does not work. It may be possible to use 
> orthonormalization and the sweep operator to produce a consistent 
> estimator, but I ran out of time to work on this.
>
> What you can do is convert the design to a single factor, and do the 
> analysis with specific contrasts, recognizing that this will not 
> enable you to get to specific things like interaction effects. To 
> understand why, consider the situation with a 2 x 2, where one cell is entirely missing.
> You have lost 1 df for the design, and the interaction is entirely missing.
> You can estimate and test specific contrasts, but you can't even 
> really test the A factor or the B factor. If Cell(2,2) is missing, you 
> can test Cell (1,1) v Cell(1,2) and you can test Cell (2,1) v Cell 
> (1,1), but neither of these is the test of the "main effect" of A or 
> B. When you have larger designs with 2 or 3 factors, the comparisons 
> again have fewer df than should be encountered. This means that the 
> interactions are not defined properly.
>
> Do you NEED the interactions for theoretical purposes, or are they 
> there simply for completedness? Are the cells missing due to your 
> design or due to happenstance?
>
> It is the case that fractional factorial designs eliminate cells from 
> the design to estimate main effects and losing the ability to estimate 
> interactions. So, missing cells, when planned for appropriately, can 
> result in appropriate analysis. I am not sure how to run mixed models 
> with fractional factorials, however.****
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles 
> Determan Jr
> Sent: Friday, February 03, 2012 7:06 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme capable of running with missing data?
>
> Greetings,
>
> Some of you may recognize my name from a few related posts but I just 
> have general question that perhaps can be clarified.  I have read 
> several times that 'lme' and 'lmer' are techniques capable of running 
> data sets with missing values.  Is this true?  I have put up similar 
> posts where when I try to run a two or three way interaction mixed 
> model I get an error of singularities or X'X not positive.  Does the 
> data set need to be formatted in some way where the mixed model can be run with all interactions?
> Furthermore, if the missing values are 'not missing at random' is 
> there another method to follow for generating the mixed model?  I am 
> just confused why I see posts that lme can be run when data is missing.
>
> Regards,****
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ----------------------------------------------------------------------
> - Confidentiality Notice: This e-mail message, including any 
> attachments, is for the sole use of the intended recipient(s) and may 
> contain privileged and confidential information.  Any unauthorized 
> review, use, disclosure or distribution is prohibited.  If you are not 
> the intended recipient, please contact the sender by reply e-mail and 
> destroy all copies of the original message.****
>
> ** **
>
>
> ----------------------------------------------------------------------
> - Confidentiality Notice: This e-mail message, including any 
> attachments, is for the sole use of the intended recipient(s) and may 
> contain privileged and confidential information. Any unauthorized 
> review, use, disclosure or distribution is prohibited. If you are not 
> the intended recipient, please contact the sender by reply e-mail and 
> destroy all copies of the original message.
>

	[[alternative HTML version deleted]]



From deter088 at umn.edu  Fri Feb  3 16:31:03 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 09:31:03 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
Message-ID: <CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/e0b0429b/attachment-0002.pl>

From deter088 at umn.edu  Fri Feb  3 17:18:59 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 10:18:59 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
Message-ID: <CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/ab5adf74/attachment-0002.pl>

From numashankar at gsu.edu  Fri Feb  3 14:42:47 2012
From: numashankar at gsu.edu (Nita Umashankar)
Date: Fri, 3 Feb 2012 13:42:47 +0000
Subject: [R-sig-ME] Heckit for HLM models
Message-ID: <7B82ADECF221B54B952F768A84D70B742929EC92@BL2PRD0510MB362.namprd05.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/47c9a1ec/attachment-0002.pl>

From kw.stat at gmail.com  Fri Feb  3 17:58:27 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 3 Feb 2012 10:58:27 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
Message-ID: <CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/f32680e9/attachment-0002.pl>

From deter088 at umn.edu  Fri Feb  3 18:06:32 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 3 Feb 2012 11:06:32 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
Message-ID: <CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/b65757ee/attachment-0002.pl>

From jbaldwin at fs.fed.us  Fri Feb  3 18:08:51 2012
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Fri, 3 Feb 2012 17:08:51 +0000
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45690E2C1FEF@001FSN2MPN1-016.001f.mgd2.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120203/751cf7c8/attachment-0002.pl>

From aslacksmith2 at gmail.com  Fri Feb  3 18:18:35 2012
From: aslacksmith2 at gmail.com (Andrew Slack-Smith)
Date: Sat, 4 Feb 2012 04:18:35 +1100
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
Message-ID: <002701cce297$e04ccb50$a0e661f0$@gmail.com>


Charles

As you suggest SAS will run the data. I just put it into SAS and all OK.

SAS uses the Satterthwaite "degrees of freedom method". If that helps at
all. 

>From the web page  http://glmm.wikidot.com/faq I grabbed the following which
may relate to your problem.


 - Other df approximation schemes that have been suggested (Satterthwaite,
Kenward-Roger, etc.) would apparently be fairly hard to implement in
lme4/nlme, both because of a difference in notational framework and because
naive approaches would be computationally difficult in the case of large
data sets. (The Kenward-Roger approach has now been implemented in the
pbkrtest package (as KRmodcomp): note that it was derived for LMMs and is
not necessarily applicable to GLMMs!)

 - When the data are not classical (crossed, unbalanced, R-side effects), we
might still guess that the deviances etc. are approximately F-distributed
but that we don't know the real degrees of freedom - this is what the
Satterthwaite, Kenward-Roger, Fai-Cornelius, etc. approximations are
supposed to do.


All the best

Andrew


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Kevin Wright
Sent: Saturday, 4 February 2012 3:58 AM
To: Charles Determan Jr
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lme capable of running with missing data?

Charles,

Here's a simple thought example.  Use a piece of graph paper (or just a
simple sketch).  Write the following letters at the coordinates specified:

A1  (1,1)
A2 (3,2)
B1 (1,2)
B2 (missing)

Draw a line from A1 to A2.  Imagine a line from B1 to the missing value of
B2.

By looking at this, you could calculate an overall mean for the A factor.
You could also estimate an overall mean for the B factor, if you assume the
lines are parallel.  This is what happens with fixed effects, as in lme (
... A + B, ...).
But, when you specify lme(... A*B, ...) which is the same as lme(... A + B
+ A:B, ...), you are essentially saying to the computer, "The A1-A2 and
B1-B2 lines are not parallel, but please give me an estimate of the slope of
the B1-B2 line."

Could _you_ draw the B1-B2 line?  No.  Neither can lme.

It's okay that B2 is missing if you don't want to fit an interaction, but
when B2 is missing, there is no way to estimate an interaction (non-parallel
slope).

Kevin





On Fri, Feb 3, 2012 at 10:18 AM, Charles Determan Jr
<deter088 at umn.edu>wrote:

> After the data is input, and factors are assigned,
>
> model=lme(arginine~group*time*survival, random=~1|subj, method="REML",
> data=x)
>
> Error in MEEM(object, conLin, control$niterEM) : Singularity in 
> backsolve at level 0, block 1
>
>
>
> On Fri, Feb 3, 2012 at 10:01 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>
>> Providing the data is not a "reproducible example".  Complete data 
>> and R-code are helpful.
>>
>> Kevin
>>
>>
>>
>> On Fri, Feb 3, 2012 at 9:31 AM, Charles Determan Jr
<deter088 at umn.edu>wrote:
>>
>>> Here is the dataset, everything should be run as a factor except 'met'
>>> which is numeric.  Thanks for the assistance,
>>>
>>>    time group survival subj met
>>> 1      1     2        1      2   1.3954
>>> 2      2     2        1      2   1.8063
>>> 3      3     2        1      2   1.3684
>>> 4      4     2        1      2   2.0046
>>> 5      5     2        1      2   1.0334
>>> 6      6     2        1      2   0.3644
>>> 7      7     2        1      2   0.4819
>>> 8      8     2        1      2   1.4558
>>> 9      9     2        1     2   0.9718
>>> 10     1     1        2    5   0.7771
>>> 11     2     1        2    5   1.2439
>>> 12     1     2        2    8   1.0980
>>> 13     2     2        2    8   0.9511
>>> 14     1     2        1    9   1.0534
>>> 15     2     2        1    9   1.7279
>>> 16     3     2        1    9   1.4904
>>> 17     4     2        1    9   1.2737
>>> 18     5     2        1    9   0.8929
>>> 19     6     2        1    9   0.5828
>>> 20     7     2        1    9   0.3260
>>> 21     8     2        1    9   1.0373
>>> 22     9     2        1    9   0.9624
>>> 23     1     2        2   10   1.1391
>>> 24     2     2        2   10   1.3945
>>> 25     3     2        2   10   0.9414
>>> 26     4     2        2   10   1.1152
>>> 27     5     2        2   10   0.8222
>>> 28     6     2        2   10   0.4417
>>> 29     7     2        2   10   0.4126
>>> 30     1     1        1   12   1.3024
>>> 31     2     1        1   12   1.1811
>>> 32     3     1        1   12   0.9379
>>> 33     4     1        1   12   1.3000
>>> 34     5     1        1   12   1.2977
>>> 35     6     1        1   12   0.4949
>>> 36     7     1        1   12   0.5238
>>> 37     8     1        1   12   1.3862
>>> 38     1     1        1   16   1.2259
>>> 39     2     1        1   16   0.8681
>>> 40     3     1        1   16   1.2645
>>> 41     4     1        1   16   0.7316
>>> 42     5     1        1   16   0.6648
>>> 43     6     1        1   16   0.9671
>>> 44     7     1        1   16   1.0131
>>> 45     8     1        1   16   1.1762
>>> 46     9     1        1   16   0.8776
>>> 47     1     2        2   18   1.1231
>>> 48     2     2        2   18   1.2133
>>> 49     3     2        2   18   1.2005
>>> 50     4     2        2   18   0.7198
>>> 51     5     2        2   18   0.6620
>>> 52     6     2        2   18   0.5908
>>> 53     7     2        2   18   0.3945
>>> 54     1     2        2   19   0.7852
>>> 55     2     2        2   19   0.6758
>>> 56     3     2        2   19   0.5246
>>> 57     4     2        2   19   0.5263
>>> 58     1     2        2   20   1.2284
>>> 59     2     2        2   20   0.7017
>>> 60     1     2        1   23   0.9604
>>> 61     2     2        1   23   0.7977
>>> 62     3     2        1   23   1.2267
>>> 63     4     2        1   23   1.3857
>>> 64     5     2        1   23   0.9486
>>> 65     6     2        1   23   0.3571
>>> 66     7     2        1   23   0.3134
>>> 67     8     2        1   23   1.9984
>>> 68     9     2        1   23   0.4837
>>> 69     1     1        1   24   1.1793
>>> 70     2     1        1   24   1.3883
>>> 71     3     1        1   24   2.1080
>>> 72     4     1        1   24   0.8810
>>> 73     5     1        1   24   0.8825
>>> 74     6     1        1   24   0.4124
>>> 75     7     1        1   24   0.5270
>>> 76     8     1        1   24   1.9003
>>> 77     9     1        1   24   1.4344
>>> 78     1     1        1   27   1.1905
>>> 79     2     1        1   27   1.1033
>>> 80     3     1        1   27   1.4976
>>> 81     4     1        1   27   1.9018
>>> 82     5     1        1   27   0.5815
>>> 83     6     1        1   27   0.4428
>>> 84     7     1        1   27   0.4728
>>> 85     8     1        1   27   1.6309
>>> 86     9     1        1   27   0.4054
>>> 87     1     1        1   28   0.9538
>>> 88     2     1        1   28   0.7796
>>> 89     3     1        1   28   1.7906
>>> 90     5     1        1   28   0.4715
>>> 91     6     1        1   28   0.4214
>>> 92     7     1        1   28   0.4120
>>> 93     8     1        1   28   1.3111
>>> 94     9     1        1   28   0.3677
>>> 95     1     1        2    1   1.3853
>>> 96     2     1        2    1   1.5966
>>> 97     3     1        2    1   1.4542
>>> 98     4     1        2    1   1.3084
>>> 99     5     1        2    1   1.2826
>>> 100    6     1        2    1   0.6835
>>> 101    7     1        2    1   0.9709
>>> 102    1     1        1    3   1.3175
>>> 103    2     1        1    3   0.7792
>>> 104    3     1        1    3   1.8763
>>> 105    5     1        1    3   1.4633
>>> 106    6     1        1    3   0.0735
>>> 107    7     1        1    3   0.5612
>>> 108    8     1        1    3   1.3777
>>> 109    9     1        1    3   0.3810
>>> 110    1     1        2    4   1.3486
>>> 111    1     1        1    6   1.2635
>>> 112    2     1        1    6   0.7572
>>> 113    3     1        1    6   1.5011
>>> 114    5     1        1    6   0.6873
>>> 115    6     1        1    6   0.3778
>>> 116    7     1        1    6   0.4231
>>> 117    8     1        1    6   1.3817
>>> 118    9     1        1    6   0.5850
>>> 119    1     2        2    7   0.7362
>>> 120    2     2        2    7   0.5495
>>> 121    3     2        2    7   0.7621
>>> 122    4     2        2    7   0.8421
>>> 123    5     2        2    7   1.0438
>>> 124    6     2        2    7   0.9802
>>> 125    7     2        2    7   0.5627
>>> 126    1     1        1   11   1.5575
>>> 127    2     1        1   11   2.1356
>>> 128    3     1        1   11   1.3575
>>> 129    4     1        1   11   1.3056
>>> 130    5     1        1   11   0.8144
>>> 131    6     1        1   11   0.5876
>>> 132    7     1        1   11   0.4104
>>> 133    9     1        1   11   0.4942
>>> 134    1     2        1   13   1.0046
>>> 135    2     2        1   13   0.8805
>>> 136    3     2        1   13   0.7685
>>> 137    4     2        1   13   0.8786
>>> 138    5     2        1   13   1.4249
>>> 139    6     2        1   13   0.5339
>>> 140    7     2        1   13   0.5480
>>> 141    8     2        1   13   2.6369
>>> 142    9     2        1   13   1.7159
>>> 143    1     2        1   14   0.7161
>>> 144    2     2        1   14   0.3968
>>> 145    3     2        1   14   0.8142
>>> 146    4     2        1   14   0.6140
>>> 147    5     2        1   14   0.6585
>>> 148    6     2        1   14   0.7176
>>> 149    7     2        1   14   0.6613
>>> 150    8     2        1   14   1.6494
>>> 151    9     2        1   14   0.3903
>>> 152    1     1        1   15   1.4357
>>> 153    2     1        1   15   1.4772
>>> 154    3     1        1   15   1.3156
>>> 155    4     1        1   15   0.9654
>>> 156    5     1        1   15   1.2709
>>> 157    6     1        1   15   0.9330
>>> 158    7     1        1   15   0.3515
>>> 159    8     1        1   15   1.6801
>>> 160    9     1        1   15   0.3584
>>> 161    1     2        2   17   0.8077
>>> 162    2     2        2   17   0.7560
>>> 163    1     1        1   21   1.1890
>>> 164    2     1        1   21   0.9631
>>> 165    3     1        1   21   0.9753
>>> 166    4     1        1   21   0.9519
>>> 167    5     1        1   21   0.6348
>>> 168    6     1        1   21   0.8516
>>> 169    7     1        1   21   0.2366
>>> 170    8     1        1   21   1.0440
>>> 171    9     1        1   21   0.5360
>>> 172    1     2        1   22   1.0747
>>> 173    2     2        1   22   0.6451
>>> 174    3     2        1   22   0.8408
>>> 175    5     2        1   22   0.8730
>>> 176    6     2        1   22   0.3594
>>> 177    7     2        1   22   0.3019
>>> 178    9     2        1   22   1.2053
>>> 179    1     2        2   25   0.4654
>>> 180    2     2        2   25   0.3024
>>> 181    3     2        2   25   0.7525
>>> 182    4     2        2   25   0.7808
>>> 183    5     2        2   25   0.6294
>>> 184    6     2        2   25   0.3016
>>> 185    7     2        2   25   0.3223
>>> 186    1     2        1   26   0.5363
>>> 187    2     2        1   26   0.2279
>>> 188    3     2        1   26   0.4756
>>> 189    4     2        1   26   0.6644
>>> 190    5     2        1   26   0.6631
>>> 191    6     2        1   26   0.3419
>>> 192    7     2        1   26   0.4188
>>> 193    8     2        1   26   0.3199
>>> 194    9     2        1   26   0.2889
>>> 195    1     1        2   29   1.2765
>>> 196    2     1        2   29   1.0653
>>> 197    3     1        2   29   1.5607
>>> 198    1     1        1   30   0.8641
>>> 199    2     1        1   30   0.9250
>>> 200    3     1        1   30   1.0887
>>> 201    4     1        1   30   0.5537
>>> 202    5     1        1   30   0.7930
>>> 203    6     1        1   30   0.3960
>>> 204    7     1        1   30   0.3917
>>> 205    8     1        1   30   1.2687
>>> 206    9     1        1   30   0.5328
>>> 207    1     2        1   31   1.0765
>>> 208    2     2        1   31   0.8778
>>> 209    3     2        1   31   0.8228
>>> 210    4     2        1   31   1.2017
>>> 211    5     2        1   31   1.1787
>>> 212    6     2        1   31   0.4037
>>> 213    7     2        1   31   0.2625
>>> 214    8     2        1   31   2.2690
>>> 215    9     2        1   31   0.4423
>>> 216    1     1        2   32   1.2880
>>> 217    2     1        2   32   0.8537
>>>
>>> On Fri, Feb 3, 2012 at 9:25 AM, Baldwin, Jim -FS 
>>> <jbaldwin at fs.fed.us>
>>> wrote:
>>>
>>> > I think the only way to resolve this is to provide a specific example.
>>> >
>>> > Jim Baldwin
>>> > Station Statistician
>>> > USDA Forest Service
>>> > Albany, California
>>> >
>>> > -----Original Message-----
>>> > From: r-sig-mixed-models-bounces at r-project.org [mailto:
>>> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles
>>> Determan Jr
>>> > Sent: Friday, February 03, 2012 7:18 AM
>>> > To: Thompson,Paul; r-sig-mixed-models at r-project.org
>>> > Subject: Re: [R-sig-ME] lme capable of running with missing data?
>>> >
>>> > So, is there a way in which I can alter the design matrix so the 
>>> > mixed model will work or is this something that can only be done 
>>> > in SAS currently?  The output from the SAS run did provide Type 
>>> > III fixed
>>> effect
>>> > test values.
>>> >
>>> > On Fri, Feb 3, 2012 at 9:14 AM, Thompson,Paul < 
>>> > Paul.Thompson at sanfordhealth.org> wrote:
>>> >
>>> > >  That's interesting. SAS uses the sweep approach (it was in fact 
>>> > > devised by Goodnight). The method used in construction of 
>>> > > various types of SS does allow you to estimate when cells are 
>>> > > missing. I
>>> would
>>> > > wonder if Type II SS can be done. Type III (despite the 
>>> > > incorrect statement that they are
>>> > > illegitimate) and Type IV would work fine. ****
>>> > >
>>> > > ** **
>>> > >
>>> > > It's really an issue of the manner in which the design matrix is
>>> > > contructed.****
>>> > >
>>> > > ** **
>>> > >
>>> > > *From:* Charles Determan Jr [mailto:deter088 at umn.edu]
>>> > > *Sent:* Friday, February 03, 2012 8:36 AM
>>> > > *To:* Thompson,Paul; r-sig-mixed-models at r-project.org
>>> > > *Subject:* Re: [R-sig-ME] lme capable of running with missing
>>> > > data?****
>>> > >
>>> > > ** **
>>> > >
>>> > > Thank you Paul, I do appreciate your response and especially 
>>> > > your
>>> time.
>>> > > The reason I am so persistent is that I know the prior data I 
>>> > > posted was run in SAS (however I don't have the exact coding 
>>> > > although I do know it was done with PROC MIXED with an 
>>> > > unstructured covariance structure and REML estimation method) 
>>> > > and it provided all the interactions.  As such, I have scoured 
>>> > > the web and literature as to how this could be done with the 
>>> > > missing data (timepoints as a result of survival).  Perhaps this 
>>> > > simply has not yet been done in R and I
>>> am
>>> > > stuck for the time being.  None-the-less, I want to be certain
>>> before I
>>> > give up on running this type of analysis in R.
>>> > >
>>> > > Thanks again,****
>>> > >
>>> > > On Fri, Feb 3, 2012 at 8:26 AM, Thompson,Paul < 
>>> > > Paul.Thompson at sanfordhealth.org> wrote:****
>>> > >
>>> > > Charles:
>>> > >
>>> > > I did suggest the use of specific contrasts to do the analysis 
>>> > > with missing cells. I played around, and just have to admit that 
>>> > > this is not possible. I tried to use standard construction 
>>> > > techniques to produce main effects using contrast coding, and 
>>> > > then multiply those
>>> to
>>> > > produce interactions. This does not work. It may be possible to 
>>> > > use orthonormalization and the sweep operator to produce a 
>>> > > consistent estimator, but I ran out of time to work on this.
>>> > >
>>> > > What you can do is convert the design to a single factor, and do 
>>> > > the analysis with specific contrasts, recognizing that this will 
>>> > > not enable you to get to specific things like interaction 
>>> > > effects. To understand why, consider the situation with a 2 x 2, 
>>> > > where one cell
>>> is
>>> > entirely missing.
>>> > > You have lost 1 df for the design, and the interaction is 
>>> > > entirely
>>> > missing.
>>> > > You can estimate and test specific contrasts, but you can't even 
>>> > > really test the A factor or the B factor. If Cell(2,2) is 
>>> > > missing,
>>> you
>>> > > can test Cell (1,1) v Cell(1,2) and you can test Cell (2,1) v 
>>> > > Cell (1,1), but neither of these is the test of the "main 
>>> > > effect" of A or B. When you have larger designs with 2 or 3 
>>> > > factors, the comparisons again have fewer df than should be 
>>> > > encountered. This means that the interactions are not defined
properly.
>>> > >
>>> > > Do you NEED the interactions for theoretical purposes, or are 
>>> > > they there simply for completedness? Are the cells missing due 
>>> > > to your design or due to happenstance?
>>> > >
>>> > > It is the case that fractional factorial designs eliminate cells 
>>> > > from the design to estimate main effects and losing the ability 
>>> > > to
>>> estimate
>>> > > interactions. So, missing cells, when planned for appropriately, 
>>> > > can result in appropriate analysis. I am not sure how to run 
>>> > > mixed models with fractional factorials, however.****
>>> > >
>>> > >
>>> > > -----Original Message-----
>>> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
>>> > > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles 
>>> > > Determan Jr
>>> > > Sent: Friday, February 03, 2012 7:06 AM
>>> > > To: r-sig-mixed-models at r-project.org
>>> > > Subject: [R-sig-ME] lme capable of running with missing data?
>>> > >
>>> > > Greetings,
>>> > >
>>> > > Some of you may recognize my name from a few related posts but I 
>>> > > just have general question that perhaps can be clarified.  I 
>>> > > have read several times that 'lme' and 'lmer' are techniques 
>>> > > capable of running data sets with missing values.  Is this true?  
>>> > > I have put up similar posts where when I try to run a two or 
>>> > > three way interaction mixed model I get an error of 
>>> > > singularities or X'X not positive.  Does the data set need to be 
>>> > > formatted in some way where the mixed model can
>>> be
>>> > run with all interactions?
>>> > > Furthermore, if the missing values are 'not missing at random' 
>>> > > is there another method to follow for generating the mixed 
>>> > > model?  I am just confused why I see posts that lme can be run 
>>> > > when data is
>>> missing.
>>> > >
>>> > > Regards,****
>>> > >
>>> > >        [[alternative HTML version deleted]]
>>> > >
>>> > > _______________________________________________
>>> > > R-sig-mixed-models at r-project.org mailing list 
>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> > >
>>> > >
>>> --------------------------------------------------------------------
>>> --
>>> > > - Confidentiality Notice: This e-mail message, including any 
>>> > > attachments, is for the sole use of the intended recipient(s) 
>>> > > and may contain privileged and confidential information.  Any 
>>> > > unauthorized review, use, disclosure or distribution is 
>>> > > prohibited.  If you are
>>> not
>>> > > the intended recipient, please contact the sender by reply 
>>> > > e-mail and destroy all copies of the original message.****
>>> > >
>>> > > ** **
>>> > >
>>> > >
>>> > >
>>> --------------------------------------------------------------------
>>> --
>>> > > - Confidentiality Notice: This e-mail message, including any 
>>> > > attachments, is for the sole use of the intended recipient(s) 
>>> > > and may contain privileged and confidential information. Any 
>>> > > unauthorized review, use, disclosure or distribution is 
>>> > > prohibited. If you are not the intended recipient, please 
>>> > > contact the sender by reply e-mail and destroy all copies of the
original message.
>>> > >
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> >
>>> >
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> Kevin Wright
>>
>>
>


--
Kevin Wright

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From joerg.luedicke at gmail.com  Fri Feb  3 19:54:42 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Fri, 3 Feb 2012 13:54:42 -0500
Subject: [R-sig-ME] GLMM with lme4/ marginal predictions
Message-ID: <CAEn158Ri+=q5xJKyMNNuXN5aBtbTJ+J9Gd4sK_yOMCS8H9BOpQ@mail.gmail.com>

Hi everybody,

I have a (overdispersed) Poisson GLMM  and would like to calculate
marginal predictions while taking random effects into account. To do
that, I am following a simulation based approach which is briefly
described in the technical appendix of the following paper by David
Atkins and colleagues (p. 26):

http://depts.washington.edu/cshrb/newweb/stats%20documents/Draft.Longitudinal.Regression.pdf

The basic idea is to draw N number of samples from the posterior
distributions of the random effects and then averaging the predictions
over all N realizations of the data. So far so good. My problem is now
that I would like to get marginal counts from a model that, besides
including my main variable of interest, includes other covariates as
well. Now, if I would just doing predictions from fixed effects, I
would just average the predictions across my data. However, I cannot
think of a way to average across the random draws from the posterior
random effects distributions _and_ averaging predictions across my
data at the same time? That is, integrating out the random effects
_and_ integrating predictions over other covariates.

I was hoping that somebody here may have done something similar in the
past and could give me a hint?


To be a bit more concrete, I will post some code to illustrate the problem:

My data are yearly observations (5 years) from (~900) schools that are
nested within (~170) school districts.
So, a model with only my independent variable of interest (hfc2) could
look like this:

model.1=glmer(paidcount ~ hfc2  +
    (1|obs_effect) + (1+hfc2|school.id) + (1+hfc2|dist.id), family="poisson",
    offset=log(offspaid0), verbose=FALSE, data=mc1)

What follows is the code to draw from the posterior random effects
distributions and averaging predictions across draws:

(This code is mostly adopted from the above mentioned paper's
accompanying webpage:
http://depts.washington.edu/cshrb/newweb/stats%20documents/Rcode2011.R )

#-------------START-----------#

### Number of simulations
M <- 10000

### Fixed-effect estimates
beta <- fixef(model.1)

### Variance-covariance information
vc <- VarCorr(model.1)

### Pull-out over-dispersion term (as SD)
sdover <- as.numeric(attr(vc$obs_effect, "stddev"))

### Pull-out var-cov of random-effects as matrix (school level)
sdid.school <- as.matrix(vc$school.id)[1:2, 1:2]

### Pull-out var-cov of random-effects as matrix (district level)
sdid.dist <- as.matrix(vc$dist.id)[1:2, 1:2]

### Generate M random draws from variances
rover <- rnorm(M, sd = sdover)
rid1 <- mvrnorm(M, mu = rep(0,2), Sigma = sdid.school)
rid2 <- mvrnorm(M, mu = rep(0,2), Sigma = sdid.dist)

### Get predictions including fixed-effects as well as M
### simulations from random-effects (and averaging)

mean.offset=mean(mc1$offspaid0) #for multiplication with exponentiated baseline

marg.nohfc <- mean(exp(beta[1])*mean.offset * #baseline
              exp(rover + rid1 + rid2 ))

marg.hfc <- mean(exp(beta[1])*mean.offset * #baseline
              exp(beta[2] + #covariate
              rover + rid1 + rid2 ))

#Displaying marginal counts
round(cbind(marg.hfc.el, marg.nohfc.el), 2)

#-------------END-----------#

At this point, I get the marginal counts for my independent (binary)
variable. I am just not sure how to average predictions across my data
as well, if I have other covariates in the model?

Any help is much appreciated!

Joerg



From kfrost at wisc.edu  Sat Feb  4 02:45:14 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Fri, 03 Feb 2012 19:45:14 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
	<CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>
	<75e0d743133e90.4f2c8d0f@wiscmail.wisc.edu>
	<767093351351e8.4f2c8d4d@wiscmail.wisc.edu>
	<7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
Message-ID: <7620a004131150.4f2c394a@wiscmail.wisc.edu>

On 02/03/12, Charles Determan Jr   wrote:
> Kevin,
> 
> I understand that but then how is SAS accomplishing the interactions?


I have been following this conversation a little bit and this seems to be the right question to ask. I would also like to know the answer. However, this could be the wrong venue to get an answer to this question.

?
> On Fri, Feb 3, 2012 at 10:58 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> 
> > Charles,
> >
> > Here's a simple thought example.  Use a piece of graph paper (or just a
> > simple sketch).  Write the following letters at the coordinates specified:
> >
> > A1  (1,1)
> > A2 (3,2)
> > B1 (1,2)
> > B2 (missing)
> >
> > Draw a line from A1 to A2.  Imagine a line from B1 to the missing value of
> > B2.
> >
> > By looking at this, you could calculate an overall mean for the A factor.
> > You could also estimate an overall mean for the B factor, if you assume the
> > lines are parallel.  This is what happens with fixed effects, as in lme (
> > ... A + B, ...).
> > But, when you specify lme(... A*B, ...) which is the same as lme(... A + B
> > + A:B, ...), you are essentially saying to the computer, "The A1-A2 and
> > B1-B2 lines are not parallel, but please give me an estimate of the slope
> > of the B1-B2 line."
> >
> > Could _you_ draw the B1-B2 line?  No.  Neither can lme.
> >
> > It's okay that B2 is missing if you don't want to fit an interaction, but
> > when B2 is missing, there is no way to estimate an interaction
> > (non-parallel slope).
> >
> > Kevin
> >
> >
> >
> >
> >
> >
> > On Fri, Feb 3, 2012 at 10:18 AM, Charles Determan Jr <deter088 at umn.edu>wrote:
> >
> >> After the data is input, and factors are assigned,
> >>
> >> model=lme(arginine~group*time*survival, random=~1|subj, method="REML",
> >> data=x)
> >>
> >> Error in MEEM(object, conLin, control$niterEM) : Singularity in backsolve
> >> at level 0, block 1
> >>
> >>
> >>
> >> On Fri, Feb 3, 2012 at 10:01 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> >>
> >>> Providing the data is not a "reproducible example".  Complete data and
> >>> R-code are helpful.
> >>>
> >>> Kevin
> >>>
> >>>
> >>>
> >>> On Fri, Feb 3, 2012 at 9:31 AM, Charles Determan Jr <deter088 at umn.edu>wrote:
> >>>
> >>>> Here is the dataset, everything should be run as a factor except 'met'
> >>>> which is numeric.  Thanks for the assistance,
> >>>>
> >>>>    time group survival subj met
> >>>> 1      1     2        1      2   1.3954
> >>>> 2      2     2        1      2   1.8063
> >>>> 3      3     2        1      2   1.3684
> >>>> 4      4     2        1      2   2.0046
> >>>> 5      5     2        1      2   1.0334
> >>>> 6      6     2        1      2   0.3644
> >>>> 7      7     2        1      2   0.4819
> >>>> 8      8     2        1      2   1.4558
> >>>> 9      9     2        1     2   0.9718
> >>>> 10     1     1        2    5   0.7771
> >>>> 11     2     1        2    5   1.2439
> >>>> 12     1     2        2    8   1.0980
> >>>> 13     2     2        2    8   0.9511
> >>>> 14     1     2        1    9   1.0534
> >>>> 15     2     2        1    9   1.7279
> >>>> 16     3     2        1    9   1.4904
> >>>> 17     4     2        1    9   1.2737
> >>>> 18     5     2        1    9   0.8929
> >>>> 19     6     2        1    9   0.5828
> >>>> 20     7     2        1    9   0.3260
> >>>> 21     8     2        1    9   1.0373
> >>>> 22     9     2        1    9   0.9624
> >>>> 23     1     2        2   10   1.1391
> >>>> 24     2     2        2   10   1.3945
> >>>> 25     3     2        2   10   0.9414
> >>>> 26     4     2        2   10   1.1152
> >>>> 27     5     2        2   10   0.8222
> >>>> 28     6     2        2   10   0.4417
> >>>> 29     7     2        2   10   0.4126
> >>>> 30     1     1        1   12   1.3024
> >>>> 31     2     1        1   12   1.1811
> >>>> 32     3     1        1   12   0.9379
> >>>> 33     4     1        1   12   1.3000
> >>>> 34     5     1        1   12   1.2977
> >>>> 35     6     1        1   12   0.4949
> >>>> 36     7     1        1   12   0.5238
> >>>> 37     8     1        1   12   1.3862
> >>>> 38     1     1        1   16   1.2259
> >>>> 39     2     1        1   16   0.8681
> >>>> 40     3     1        1   16   1.2645
> >>>> 41     4     1        1   16   0.7316
> >>>> 42     5     1        1   16   0.6648
> >>>> 43     6     1        1   16   0.9671
> >>>> 44     7     1        1   16   1.0131
> >>>> 45     8     1        1   16   1.1762
> >>>> 46     9     1        1   16   0.8776
> >>>> 47     1     2        2   18   1.1231
> >>>> 48     2     2        2   18   1.2133
> >>>> 49     3     2        2   18   1.2005
> >>>> 50     4     2        2   18   0.7198
> >>>> 51     5     2        2   18   0.6620
> >>>> 52     6     2        2   18   0.5908
> >>>> 53     7     2        2   18   0.3945
> >>>> 54     1     2        2   19   0.7852
> >>>> 55     2     2        2   19   0.6758
> >>>> 56     3     2        2   19   0.5246
> >>>> 57     4     2        2   19   0.5263
> >>>> 58     1     2        2   20   1.2284
> >>>> 59     2     2        2   20   0.7017
> >>>> 60     1     2        1   23   0.9604
> >>>> 61     2     2        1   23   0.7977
> >>>> 62     3     2        1   23   1.2267
> >>>> 63     4     2        1   23   1.3857
> >>>> 64     5     2        1   23   0.9486
> >>>> 65     6     2        1   23   0.3571
> >>>> 66     7     2        1   23   0.3134
> >>>> 67     8     2        1   23   1.9984
> >>>> 68     9     2        1   23   0.4837
> >>>> 69     1     1        1   24   1.1793
> >>>> 70     2     1        1   24   1.3883
> >>>> 71     3     1        1   24   2.1080
> >>>> 72     4     1        1   24   0.8810
> >>>> 73     5     1        1   24   0.8825
> >>>> 74     6     1        1   24   0.4124
> >>>> 75     7     1        1   24   0.5270
> >>>> 76     8     1        1   24   1.9003
> >>>> 77     9     1        1   24   1.4344
> >>>> 78     1     1        1   27   1.1905
> >>>> 79     2     1        1   27   1.1033
> >>>> 80     3     1        1   27   1.4976
> >>>> 81     4     1        1   27   1.9018
> >>>> 82     5     1        1   27   0.5815
> >>>> 83     6     1        1   27   0.4428
> >>>> 84     7     1        1   27   0.4728
> >>>> 85     8     1        1   27   1.6309
> >>>> 86     9     1        1   27   0.4054
> >>>> 87     1     1        1   28   0.9538
> >>>> 88     2     1        1   28   0.7796
> >>>> 89     3     1        1   28   1.7906
> >>>> 90     5     1        1   28   0.4715
> >>>> 91     6     1        1   28   0.4214
> >>>> 92     7     1        1   28   0.4120
> >>>> 93     8     1        1   28   1.3111
> >>>> 94     9     1        1   28   0.3677
> >>>> 95     1     1        2    1   1.3853
> >>>> 96     2     1        2    1   1.5966
> >>>> 97     3     1        2    1   1.4542
> >>>> 98     4     1        2    1   1.3084
> >>>> 99     5     1        2    1   1.2826
> >>>> 100    6     1        2    1   0.6835
> >>>> 101    7     1        2    1   0.9709
> >>>> 102    1     1        1    3   1.3175
> >>>> 103    2     1        1    3   0.7792
> >>>> 104    3     1        1    3   1.8763
> >>>> 105    5     1        1    3   1.4633
> >>>> 106    6     1        1    3   0.0735
> >>>> 107    7     1        1    3   0.5612
> >>>> 108    8     1        1    3   1.3777
> >>>> 109    9     1        1    3   0.3810
> >>>> 110    1     1        2    4   1.3486
> >>>> 111    1     1        1    6   1.2635
> >>>> 112    2     1        1    6   0.7572
> >>>> 113    3     1        1    6   1.5011
> >>>> 114    5     1        1    6   0.6873
> >>>> 115    6     1        1    6   0.3778
> >>>> 116    7     1        1    6   0.4231
> >>>> 117    8     1        1    6   1.3817
> >>>> 118    9     1        1    6   0.5850
> >>>> 119    1     2        2    7   0.7362
> >>>> 120    2     2        2    7   0.5495
> >>>> 121    3     2        2    7   0.7621
> >>>> 122    4     2        2    7   0.8421
> >>>> 123    5     2        2    7   1.0438
> >>>> 124    6     2        2    7   0.9802
> >>>> 125    7     2        2    7   0.5627
> >>>> 126    1     1        1   11   1.5575
> >>>> 127    2     1        1   11   2.1356
> >>>> 128    3     1        1   11   1.3575
> >>>> 129    4     1        1   11   1.3056
> >>>> 130    5     1        1   11   0.8144
> >>>> 131    6     1        1   11   0.5876
> >>>> 132    7     1        1   11   0.4104
> >>>> 133    9     1        1   11   0.4942
> >>>> 134    1     2        1   13   1.0046
> >>>> 135    2     2        1   13   0.8805
> >>>> 136    3     2        1   13   0.7685
> >>>> 137    4     2        1   13   0.8786
> >>>> 138    5     2        1   13   1.4249
> >>>> 139    6     2        1   13   0.5339
> >>>> 140    7     2        1   13   0.5480
> >>>> 141    8     2        1   13   2.6369
> >>>> 142    9     2        1   13   1.7159
> >>>> 143    1     2        1   14   0.7161
> >>>> 144    2     2        1   14   0.3968
> >>>> 145    3     2        1   14   0.8142
> >>>> 146    4     2        1   14   0.6140
> >>>> 147    5     2        1   14   0.6585
> >>>> 148    6     2        1   14   0.7176
> >>>> 149    7     2        1   14   0.6613
> >>>> 150    8     2        1   14   1.6494
> >>>> 151    9     2        1   14   0.3903
> >>>> 152    1     1        1   15   1.4357
> >>>> 153    2     1        1   15   1.4772
> >>>> 154    3     1        1   15   1.3156
> >>>> 155    4     1        1   15   0.9654
> >>>> 156    5     1        1   15   1.2709
> >>>> 157    6     1        1   15   0.9330
> >>>> 158    7     1        1   15   0.3515
> >>>> 159    8     1        1   15   1.6801
> >>>> 160    9     1        1   15   0.3584
> >>>> 161    1     2        2   17   0.8077
> >>>> 162    2     2        2   17   0.7560
> >>>> 163    1     1        1   21   1.1890
> >>>> 164    2     1        1   21   0.9631
> >>>> 165    3     1        1   21   0.9753
> >>>> 166    4     1        1   21   0.9519
> >>>> 167    5     1        1   21   0.6348
> >>>> 168    6     1        1   21   0.8516
> >>>> 169    7     1        1   21   0.2366
> >>>> 170    8     1        1   21   1.0440
> >>>> 171    9     1        1   21   0.5360
> >>>> 172    1     2        1   22   1.0747
> >>>> 173    2     2        1   22   0.6451
> >>>> 174    3     2        1   22   0.8408
> >>>> 175    5     2        1   22   0.8730
> >>>> 176    6     2        1   22   0.3594
> >>>> 177    7     2        1   22   0.3019
> >>>> 178    9     2        1   22   1.2053
> >>>> 179    1     2        2   25   0.4654
> >>>> 180    2     2        2   25   0.3024
> >>>> 181    3     2        2   25   0.7525
> >>>> 182    4     2        2   25   0.7808
> >>>> 183    5     2        2   25   0.6294
> >>>> 184    6     2        2   25   0.3016
> >>>> 185    7     2        2   25   0.3223
> >>>> 186    1     2        1   26   0.5363
> >>>> 187    2     2        1   26   0.2279
> >>>> 188    3     2        1   26   0.4756
> >>>> 189    4     2        1   26   0.6644
> >>>> 190    5     2        1   26   0.6631
> >>>> 191    6     2        1   26   0.3419
> >>>> 192    7     2        1   26   0.4188
> >>>> 193    8     2        1   26   0.3199
> >>>> 194    9     2        1   26   0.2889
> >>>> 195    1     1        2   29   1.2765
> >>>> 196    2     1        2   29   1.0653
> >>>> 197    3     1        2   29   1.5607
> >>>> 198    1     1        1   30   0.8641
> >>>> 199    2     1        1   30   0.9250
> >>>> 200    3     1        1   30   1.0887
> >>>> 201    4     1        1   30   0.5537
> >>>> 202    5     1        1   30   0.7930
> >>>> 203    6     1        1   30   0.3960
> >>>> 204    7     1        1   30   0.3917
> >>>> 205    8     1        1   30   1.2687
> >>>> 206    9     1        1   30   0.5328
> >>>> 207    1     2        1   31   1.0765
> >>>> 208    2     2        1   31   0.8778
> >>>> 209    3     2        1   31   0.8228
> >>>> 210    4     2        1   31   1.2017
> >>>> 211    5     2        1   31   1.1787
> >>>> 212    6     2        1   31   0.4037
> >>>> 213    7     2        1   31   0.2625
> >>>> 214    8     2        1   31   2.2690
> >>>> 215    9     2        1   31   0.4423
> >>>> 216    1     1        2   32   1.2880
> >>>> 217    2     1        2   32   0.8537
> >>>>
> >>>> On Fri, Feb 3, 2012 at 9:25 AM, Baldwin, Jim -FS <jbaldwin at fs.fed.us>
> >>>> wrote:
> >>>>
> >>>> > I think the only way to resolve this is to provide a specific example.
> >>>> >
> >>>> > Jim Baldwin
> >>>> > Station Statistician
> >>>> > USDA Forest Service
> >>>> > Albany, California
> >>>> >
> >>>> > -----Original Message-----
> >>>> > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> >>>> > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles
> >>>> Determan Jr
> >>>> > Sent: Friday, February 03, 2012 7:18 AM
> >>>> > To: Thompson,Paul; r-sig-mixed-models at r-project.org
> >>>> > Subject: Re: [R-sig-ME] lme capable of running with missing data?
> >>>> >
> >>>> > So, is there a way in which I can alter the design matrix so the mixed
> >>>> > model will work or is this something that can only be done in SAS
> >>>> > currently?  The output from the SAS run did provide Type III fixed
> >>>> effect
> >>>> > test values.
> >>>> >
> >>>> > On Fri, Feb 3, 2012 at 9:14 AM, Thompson,Paul <
> >>>> > Paul.Thompson at sanfordhealth.org> wrote:
> >>>> >
> >>>> > >  That's interesting. SAS uses the sweep approach (it was in fact
> >>>> > > devised by Goodnight). The method used in construction of various
> >>>> > > types of SS does allow you to estimate when cells are missing. I
> >>>> would
> >>>> > > wonder if Type II SS can be done. Type III (despite the incorrect
> >>>> > > statement that they are
> >>>> > > illegitimate) and Type IV would work fine. ****
> >>>> > >
> >>>> > > ** **
> >>>> > >
> >>>> > > It's really an issue of the manner in which the design matrix is
> >>>> > > contructed.****
> >>>> > >
> >>>> > > ** **
> >>>> > >
> >>>> > > *From:* Charles Determan Jr [mailto:deter088 at umn.edu](javascript:main.compose()
> >>>> > > *Sent:* Friday, February 03, 2012 8:36 AM
> >>>> > > *To:* Thompson,Paul; r-sig-mixed-models at r-project.org
> >>>> > > *Subject:* Re: [R-sig-ME] lme capable of running with missing
> >>>> > > data?****
> >>>> > >
> >>>> > > ** **
> >>>> > >
> >>>> > > Thank you Paul, I do appreciate your response and especially your
> >>>> time.
> >>>> > > The reason I am so persistent is that I know the prior data I posted
> >>>> > > was run in SAS (however I don't have the exact coding although I do
> >>>> > > know it was done with PROC MIXED with an unstructured covariance
> >>>> > > structure and REML estimation method) and it provided all the
> >>>> > > interactions.  As such, I have scoured the web and literature as to
> >>>> > > how this could be done with the missing data (timepoints as a result
> >>>> > > of survival).  Perhaps this simply has not yet been done in R and I
> >>>> am
> >>>> > > stuck for the time being.  None-the-less, I want to be certain
> >>>> before I
> >>>> > give up on running this type of analysis in R.
> >>>> > >
> >>>> > > Thanks again,****
> >>>> > >
> >>>> > > On Fri, Feb 3, 2012 at 8:26 AM, Thompson,Paul <
> >>>> > > Paul.Thompson at sanfordhealth.org> wrote:****
> >>>> > >
> >>>> > > Charles:
> >>>> > >
> >>>> > > I did suggest the use of specific contrasts to do the analysis with
> >>>> > > missing cells. I played around, and just have to admit that this is
> >>>> > > not possible. I tried to use standard construction techniques to
> >>>> > > produce main effects using contrast coding, and then multiply those
> >>>> to
> >>>> > > produce interactions. This does not work. It may be possible to use
> >>>> > > orthonormalization and the sweep operator to produce a consistent
> >>>> > > estimator, but I ran out of time to work on this.
> >>>> > >
> >>>> > > What you can do is convert the design to a single factor, and do the
> >>>> > > analysis with specific contrasts, recognizing that this will not
> >>>> > > enable you to get to specific things like interaction effects. To
> >>>> > > understand why, consider the situation with a 2 x 2, where one cell
> >>>> is
> >>>> > entirely missing.
> >>>> > > You have lost 1 df for the design, and the interaction is entirely
> >>>> > missing.
> >>>> > > You can estimate and test specific contrasts, but you can't even
> >>>> > > really test the A factor or the B factor. If Cell(2,2) is missing,
> >>>> you
> >>>> > > can test Cell (1,1) v Cell(1,2) and you can test Cell (2,1) v Cell
> >>>> > > (1,1), but neither of these is the test of the "main effect" of A or
> >>>> > > B. When you have larger designs with 2 or 3 factors, the comparisons
> >>>> > > again have fewer df than should be encountered. This means that the
> >>>> > > interactions are not defined properly.
> >>>> > >
> >>>> > > Do you NEED the interactions for theoretical purposes, or are they
> >>>> > > there simply for completedness? Are the cells missing due to your
> >>>> > > design or due to happenstance?
> >>>> > >
> >>>> > > It is the case that fractional factorial designs eliminate cells
> >>>> from
> >>>> > > the design to estimate main effects and losing the ability to
> >>>> estimate
> >>>> > > interactions. So, missing cells, when planned for appropriately, can
> >>>> > > result in appropriate analysis. I am not sure how to run mixed
> >>>> models
> >>>> > > with fractional factorials, however.****
> >>>> > >
> >>>> > >
> >>>> > > -----Original Message-----
> >>>> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> >>>> > > r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles
> >>>> > > Determan Jr
> >>>> > > Sent: Friday, February 03, 2012 7:06 AM
> >>>> > > To: r-sig-mixed-models at r-project.org
> >>>> > > Subject: [R-sig-ME] lme capable of running with missing data?
> >>>> > >
> >>>> > > Greetings,
> >>>> > >
> >>>> > > Some of you may recognize my name from a few related posts but I
> >>>> just
> >>>> > > have general question that perhaps can be clarified.  I have read
> >>>> > > several times that 'lme' and 'lmer' are techniques capable of
> >>>> running
> >>>> > > data sets with missing values.  Is this true?  I have put up similar
> >>>> > > posts where when I try to run a two or three way interaction mixed
> >>>> > > model I get an error of singularities or X'X not positive.  Does the
> >>>> > > data set need to be formatted in some way where the mixed model can
> >>>> be
> >>>> > run with all interactions?
> >>>> > > Furthermore, if the missing values are 'not missing at random' is
> >>>> > > there another method to follow for generating the mixed model?  I am
> >>>> > > just confused why I see posts that lme can be run when data is
> >>>> missing.
> >>>> > >
> >>>> > > Regards,****
> >>>> > >
> >>>> > >        [[alternative HTML version deleted]]
> >>>> > >
> >>>> > > _______________________________________________
> >>>> > > R-sig-mixed-models at r-project.org mailing list
> >>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>> > >
> >>>> > >
> >>>> ----------------------------------------------------------------------
> >>>> > > - Confidentiality Notice: This e-mail message, including any
> >>>> > > attachments, is for the sole use of the intended recipient(s) and
> >>>> may
> >>>> > > contain privileged and confidential information.  Any unauthorized
> >>>> > > review, use, disclosure or distribution is prohibited.  If you are
> >>>> not
> >>>> > > the intended recipient, please contact the sender by reply e-mail
> >>>> and
> >>>> > > destroy all copies of the original message.****
> >>>> > >
> >>>> > > ** **
> >>>> > >
> >>>> > >
> >>>> > >
> >>>> ----------------------------------------------------------------------
> >>>> > > - Confidentiality Notice: This e-mail message, including any
> >>>> > > attachments, is for the sole use of the intended recipient(s) and
> >>>> may
> >>>> > > contain privileged and confidential information. Any unauthorized
> >>>> > > review, use, disclosure or distribution is prohibited. If you are
> >>>> not
> >>>> > > the intended recipient, please contact the sender by reply e-mail
> >>>> and
> >>>> > > destroy all copies of the original message.
> >>>> > >
> >>>> >
> >>>> >         [[alternative HTML version deleted]]
> >>>> >
> >>>> >
> >>>> >
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>>
> >>>
> >>> --
> >>> Kevin Wright
> >>>
> >>>
> >>
> >
> >
> > --
> > Kevin Wright
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r.turner at auckland.ac.nz  Sat Feb  4 03:20:45 2012
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 04 Feb 2012 15:20:45 +1300
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <7620a004131150.4f2c394a@wiscmail.wisc.edu>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>	<CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>	<75e0d743133e90.4f2c8d0f@wiscmail.wisc.edu>	<767093351351e8.4f2c8d4d@wiscmail.wisc.edu>	<7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
	<7620a004131150.4f2c394a@wiscmail.wisc.edu>
Message-ID: <4F2C95FD.3040405@auckland.ac.nz>

On 04/02/12 14:45, Kenneth Frost wrote:
> On 02/03/12, Charles Determan Jr   wrote:
>> Kevin,
>>
>> I understand that but then how is SAS accomplishing the interactions?
>
> I have been following this conversation a little bit and this seems to be the right question to ask. I would also like to know the answer. However, this could be the wrong venue to get an answer to this question.
<SNIP>

It may be the case that fortune(203) is relevant here! :-)

     cheers,

         Rolf Turner



From stat.list at yahoo.co.uk  Sun Feb  5 19:41:14 2012
From: stat.list at yahoo.co.uk (Rachel Cohen)
Date: Sun, 5 Feb 2012 18:41:14 +0000 (GMT)
Subject: [R-sig-ME] cross-validation of linear mixed effect models
Message-ID: <1328467274.87331.YahooMailNeo@web132202.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120205/e3a1b264/attachment-0002.pl>

From Mike.Lawrence at dal.ca  Sun Feb  5 19:55:10 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sun, 5 Feb 2012 14:55:10 -0400
Subject: [R-sig-ME] cross-validation of linear mixed effect models
In-Reply-To: <1328467274.87331.YahooMailNeo@web132202.mail.ird.yahoo.com>
References: <1328467274.87331.YahooMailNeo@web132202.mail.ird.yahoo.com>
Message-ID: <CAB+QPJDEbO_XjoexgC1miDYWapJfCy27uF9LLr2CY25cXH87pw@mail.gmail.com>

One thought is that according to Fang (2011,
http://www.jds-online.com/file_download/278/JDS-652a.pdf), AIC for a
mixed effects model is asymptotically equivalent to
leave-one-cluster-out cross-validation, so possibly you already have a
metric of cross-validated prediction accuracy in your AIC scores. Now
that I think of it though, I see Fang makes a distinction between
marginal vs conditional AIC, and I'm not sure though which is
implemented when you submit an lmer model to the AIC() function in R.
Also, I'm not sure if the use of REML in fitting the model affects the
equivalence asserted by Fang; certainly I've been advised on this list
before that if I want to compare nested models on AIC scores, I needed
to ensure that REML=F in the fitted models.


On Sun, Feb 5, 2012 at 2:41 PM, Rachel Cohen <stat.list at yahoo.co.uk> wrote:
> Hi, I am a PhD student who is using mixed effect models (and R) for the first time so apologies if my question is a bit basic.? I also haven't used this forum much so if this topic has already been covered in depth in the past and there is an easy answer out there that I've missed then additional apologies!
>
> I am using a linear mixed model (structure as below) to predict total tree biomass (log.mass) using tree diameter (dbh) and height as explanatory variables, allowing the intercept and the slope of height to vary by my grouping factor (species_site).
>
> Model:
>
> lmer((log.mass)~centre.log.dbh+centre.log.height+(1+centre.log.height|species_site),data=data3,REML=T)
>
> This model structure was chosen as 'the best' primarily on the basis of AIC value.?? Residual plots look fairly OK.
>
> I would now like to check the predictive performance of my model (by cross-validation?) and wonder how to go about this in the context of a linear mixed effect model?.? Is there a package/function in R which deals with this?
>
> Any advice on how to proceed would be greatly appreciated!
>
> Regards,
>
> Rachel Cohen
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From tahtg6 at gmail.com  Mon Feb  6 02:49:17 2012
From: tahtg6 at gmail.com (Tiffanie Cross)
Date: Sun, 5 Feb 2012 17:49:17 -0800
Subject: [R-sig-ME] lmer blocking by subject?
Message-ID: <CALBCd4h+6u1a5fFkQ1uATGPZRQ4KxGC68WYE7rDm5M0gjUR4Mg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120205/32cf47f4/attachment-0002.pl>

From bbolker at gmail.com  Mon Feb  6 04:50:52 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 6 Feb 2012 03:50:52 +0000 (UTC)
Subject: [R-sig-ME] lmer blocking by subject?
References: <CALBCd4h+6u1a5fFkQ1uATGPZRQ4KxGC68WYE7rDm5M0gjUR4Mg@mail.gmail.com>
Message-ID: <loom.20120206T043305-347@post.gmane.org>

Tiffanie Cross <tahtg6 at ...> writes:

> I am new to R and would like some guidance on how to block by subject.
> 
> I collected presence/absence 24 hrs/day for 44 birds, denoted "bird", at 5
> stations, denoted "colony" for the duration of a breeding season. The
> breeding season was broken into biologically relevant time periods (3
> levels), denoted "period". The birds were captured on 2 different colonies,
> 22 on each colony, denoted "homecolony". I also have the variable, "sex". I
> have about 300,000 total observations for these 44 birds. This data is
> temporally auto-correlated because it is VHF radio-telemetry data recorded
> continually throughout the study.

  What is the temporal resolution?  Based on a guess at the length
of the breeding season (60 days), I'm guessing about every 10-12 minutes.
This isn't essential information but would help get a feel for the
data.

   Be aware that modeling temporal autocorrelation in a binary
variable may be a little bit tricky -- there are a variety of
approaches, but none are quite as easy as the way one builds
autocorrelation into a normal-response model, by making the residuals
within blocks multivariate normal with a specified autocorrelation.  A
few possibilities that spring to mind are (1) because there is
presumably no error in the observations themselves, you could
condition on the previous observation (i.e. put it in as a predictor);
(2) aggregate the data to a coarser temporal scale and fit the data as
binomial (e.g.  number of presence/absence values per 2-hour period,
or per day, or some other appropriate period that balances resolution
and lack of autocorrelation); (3) if there are long 'runs' of
presence/absences, aggregate the data down to times when birds entered
or left; (4) [fanciest, but not necessarily worth the trouble or most
appropriate] assume an underlying multivariate normal distribution
that *is* autocorrelated and controls probability of presence
(i.e. a hierarchical model with autocorrelation in the level
below the observation level).
 
> I have a binary response variable, "present", with independent variables
> "sex" at 2 levels, "homecolony" at 2 levels, "colony" at 5 levels, and
> "period" at 3 levels. I would like to incorporate "period", "bird" and
> "colony" as random effects. Fixed effects are "sex" and "homecolony". The
> "bird" variable is what I want the model blocked by.

   Practically speaking, you can't treat period as a random effect --
not enough levels.

> I am trying to answer the following questions: "Are there differences in
> presence between sexes, homecolony, and period?" "Do birds from one
> homecolony differ in their use of other colonies (colony)?"
> 
> I cannot figure out how to specify that I want the model to block by
> subject, i.e. "bird". I have tried incorporating "bird" as a random effect,
> but the degrees of freedom still come out to be close to 300,000 which is
> near the total number of observations. Can anyone show me syntax that will
> incorporate bird as a random effect that the model blocks by subject?

   Where are you seeing the degrees of freedom?
> 
> I tried following examples from Doug Bates' LME4 book, Chapter 4:

> Glmm_FD <- lmer(present ~ 1 + gender + period + homecolony + colony + (1 +
> period|bird), data = FD, family = binomial, REML = 0)
> I know that the (1+period|bird) term is probably incorrect.

  REML=0 is meaningless in this case (lmer doesn't use REML
or an analogue of it when fitting a non-Gaussian model), but
otherwise your model specification seems to be on the right track.

  Since I'm guessing the birds can only be detected at a single
station at a time, this is a bit more of a categorical response
(i.e., is bird X present at colony 1-5 or "none of the above"
at time T?)  Have you thought about multistate mark-recapture
models ... ?

   This seems like a fairly complex problem.  How have others
in your field handled these kinds of data?  With lots of data
on each bird, you may be able to simplify your life a bit by
analyzing each bird separately -- i.e. a two-stage model rather
than a mixed/multilevel model -- Murtaugh 2007 _Ecology_ recommends
this, although I don't always agree with him ...

  I would recommend Zuur et al for messy/complex ecological
data, although I don't agree with all of that either ...



From raquel.benavides at mncn.csic.es  Mon Feb  6 16:34:32 2012
From: raquel.benavides at mncn.csic.es (Raquel Benavides)
Date: Mon, 6 Feb 2012 16:34:32 +0100
Subject: [R-sig-ME] glmmADMB error
Message-ID: <00df01cce4e4$d2d829c0$78887d40$@mncn.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/4e455f6d/attachment-0002.pl>

From bbolker at gmail.com  Mon Feb  6 18:09:11 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 6 Feb 2012 17:09:11 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB error
References: <00df01cce4e4$d2d829c0$78887d40$@mncn.csic.es>
Message-ID: <loom.20120206T180459-92@post.gmane.org>

Raquel Benavides <raquel.benavides at ...> writes:

> Dear all, 
> 
> I am trying to run glmmADMB for the first time to check the effect of some
> fixed effects over the number of seedlings in some plots (my random factors
> are site/transect/plot). However I have some errors. I show what I obtained
> with the simplest model (just one fixed and random variable). See that very
> long assessments, and at the end the error I get. Does anybody understand
> what it means or what does it do? 
> 
> seed_glmmADMB<-glmmadmb(seedling~Tanual+(1|name),data=datos,zeroInflation=TR
> UE,family="poisson")

  [snip]
> 
> Error in run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary =
> !use_tmp_dir,  : 
> 
>   object 'sys.result' not found
> 
> > 
> 
> Hope somebody could tell me what I am doing wrong!!


   Using a slightly out-dated version of glmmADMB that has a bug in it.  
Please update to version 0.7.2.5 ( see <http://glmmadmb.r-forge.r-project.org/>
for detailed instructions if necessary ).

  Ben Bolker



From federico.tettamanti at gmail.com  Mon Feb  6 11:16:19 2012
From: federico.tettamanti at gmail.com (Federico Tettamanti)
Date: Mon, 6 Feb 2012 11:16:19 +0100
Subject: [R-sig-ME] Modeling ecological observations
Message-ID: <CACNpG7tncy=+c9zgCzBV-VozAr3R3c1=PFKEY1Zh6s7zfYztbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/99898fbf/attachment-0002.pl>

From jianyun.fred.wu at gmail.com  Mon Feb  6 20:13:25 2012
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Tue, 7 Feb 2012 06:13:25 +1100
Subject: [R-sig-ME] fixed-effects models or mixed-effects models for
	population data
Message-ID: <CAOMGRD+FPUvBD1h73ggz2JjWs1ACioK4h2mR5KCXY9C9+mFzTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/145a208f/attachment-0002.pl>

From deter088 at umn.edu  Mon Feb  6 22:14:04 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 6 Feb 2012 15:14:04 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <DDC5EC9B78340042B0D5A0C3789D45690E2C1FEF@001FSN2MPN1-016.001f.mgd2.msft.net>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FEF@001FSN2MPN1-016.001f.mgd2.msft.net>
Message-ID: <CAOLJphno5iBKQJLJouSAS1xSvPwnuQZi+TfYreaK-ekXchAEjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/1ae1e40e/attachment-0002.pl>

From kevinjspring at gmail.com  Mon Feb  6 22:32:35 2012
From: kevinjspring at gmail.com (Kevin Spring)
Date: Mon, 6 Feb 2012 15:32:35 -0600
Subject: [R-sig-ME] Bootstrap the variance difference
Message-ID: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/559e7bb6/attachment-0002.pl>

From jwiley.psych at gmail.com  Mon Feb  6 23:08:35 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 6 Feb 2012 14:08:35 -0800
Subject: [R-sig-ME] Bootstrap the variance difference
In-Reply-To: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
References: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
Message-ID: <CANz9Z_LrWoO2f-dO6GioHsupB=q_WWT4bsXstD2fW4oGsSnHVA@mail.gmail.com>

Hi Kevin,

I worry a bit that your model is correctly specified and you are doing
what you really want to be doing, but that is a bit of a different
question (perhaps worth checking).  In any case, your models did not
run on my system with your example data.  Supposing all works well in
the full data and you are confident with what you have, then this is
one approach to dealing with the boot issue:

rather than pass two data sets, pass one wide data set in.  Use
slightly different names and pass in two formulae to use the correct
variables.

Hope this helps,

Josh

P.S. If real data is large, this may be somewhat slow and would easily
benefit from parallelizing if you have multiple cores and sufficient
memory----check out the parallel option to boot().

#####################################################

dat1 <- read.csv(file.choose()) ## final
dat2 <- read.csv(file.choose()) ## initial

colnames(dat1) <- paste("f", colnames(dat1), sep = '')
colnames(dat2) <- paste("i", colnames(dat2), sep = '')

dat <- cbind(dat2, dat1)

varcomp <- function (lformula, dat, indices) {
  d <- dat[indices, ]
  fit1 <- lmer(lformula[[1]], data=d) #linear model
  fit2 <- lmer(lformula[[2]], data=d) #linear model
  a <- (attr (VarCorr(fit1), "sc")^2) #output variance estimation
  b <- (attr (VarCorr(fit2), "sc")^2) #output variance estimation
  drv <- (a - b) #difference between the variance estimations
  return(drv)
}

require(lme4)
require(boot)

system.time(ip1.boot <- boot (data = dat, statistic = varcomp, R =
100, lformula = list(
  initial = iCNPC ~ (1 | iCell.line) + (1 | iDNA.extract) + iCell.line,
  final = fCNPC ~ (1 | fCell.line) + (1 | fDNA.extract) + fCell.line)))



On Mon, Feb 6, 2012 at 1:32 PM, Kevin Spring <kevinjspring at gmail.com> wrote:
> ?I asked this question on Stack Exchange, but I think it might be too
> specialized. ?Hopefully someone in the mixed model group can help me out.
>
> I want to be able to bootstrap the variance differences between two data
> sets obtained at different times while taking out the error in a random
> effect.
>
> I have 2 sets of experimental data, where the data was measured at 2 time
> points (initial and final). I also have a set of simulation data. I want to
> compare the variance of the simulated date with the variance difference
> between the experimental data (final - initial). The idea is to get
> confidence intervals from the bootstrap to compare the experimental data
> with the simulation.
>
> I am having trouble making the statistic for the bootstrap function in the
> boot package for R. So far I have.
>
> varcomp <- function ( formula, data, indices ) {
> ? ?d <- data[indices,] #sample for boot
> ? ?fit <- lmer(formula, data=d) #linear model
> ? ?res.var = (attr (VarCorr(fit), "sc")^2) # variance estimation
> ? ?return(res.var)
> ? ?}
>
> But this function only returns the variance of a single data set. I want to
> be able to input 2 sets of data and have it return the difference between
> the two data sets' variance.
>
> When I try something like:
>
> varcomp <- function ( formula, data1, data2, indices ) {
> d1 <- data1[indices,] #sample for boot
> d2 <- data2[indices,] #sample for boot
> fit1 <- lmer(formula, data=d1) #linear model
> fit2 <- lmer(formula, data=d2) #linear model
> a = (attr (VarCorr(fit1), "sc")^2) #output variance estimation
> b = (attr (VarCorr(fit2), "sc")^2) #output variance estimation
> drv = a - b #difference between the variance estimations
> return(drv)
> }
>
> I would then put it into boot such as:
>
> ip1.boot <- boot ( data = ip1, statistic=varcomp, R=100,
> formula=CNPC~(1|Cell.line:DNA.extract)+Cell.line)
>
> I can't do it this way because the boot function only allows for one data
> set to be inputted.
>
> *Does anyone know how to create the correct statistic function for this?*
>
> An example of the data can also be downloaded
> here<http://www.mediafire.com/file/68a3ro1cfneiy2r/data.zip.zip>(2 csv
> files zipped 1.22KB.)
>
> My data looks something like the following:
>
> Initial
>
> ? ? ? Cell.line ? ?Time DNA.extract ? Gene ? ? ?CNPC
> 1 ? ? ? ? ?9 initial ? ? ? ? ? 1 atubP1 1778.4589
> 2 ? ? ? ? ?9 initial ? ? ? ? ? 1 atubP1 2108.0552
> 3 ? ? ? ? ?9 initial ? ? ? ? ? 1 atubP1 2118.6725
> 4 ? ? ? ? ?9 initial ? ? ? ? ? 2 atubP1 2018.6593
> 5 ? ? ? ? ?9 initial ? ? ? ? ? 2 atubP1 1935.9008
> 6 ? ? ? ? ?9 initial ? ? ? ? ? 2 atubP1 1749.9158
> 7 ? ? ? ? ?9 initial ? ? ? ? ? 3 atubP1 1524.7475
> 8 ? ? ? ? ?9 initial ? ? ? ? ? 3 atubP1 1532.9781
> 9 ? ? ? ? ?9 initial ? ? ? ? ? 3 atubP1 1693.3098
> 10 ? ? ? ?17 initial ? ? ? ? ? 1 atubP1 1076.4720
> 11 ? ? ? ?17 initial ? ? ? ? ? 1 atubP1 1101.3315
> 12 ? ? ? ?17 initial ? ? ? ? ? 1 atubP1 1185.3606
> 13 ? ? ? ?17 initial ? ? ? ? ? 2 atubP1 1131.1118
> 14 ? ? ? ?17 initial ? ? ? ? ? 2 atubP1 ?892.7087
> 15 ? ? ? ?17 initial ? ? ? ? ? 2 atubP1 1028.5465
> 16 ? ? ? ?17 initial ? ? ? ? ? 3 atubP1 ?887.9972
> 17 ? ? ? ?17 initial ? ? ? ? ? 3 atubP1 ?732.9646
> 18 ? ? ? ?17 initial ? ? ? ? ? 3 atubP1 ?680.6724
>
> Final
>
> ? Cell.line ?Time DNA.extract ? Gene ? ? ?CNPC
> 1 ? ? ? ? ?9 final ? ? ? ? ? 1 atubP1 1262.2378
> 2 ? ? ? ? ?9 final ? ? ? ? ? 1 atubP1 1261.9858
> 3 ? ? ? ? ?9 final ? ? ? ? ? 1 atubP1 1390.6873
> 4 ? ? ? ? ?9 final ? ? ? ? ? 2 atubP1 1539.7180
> 5 ? ? ? ? ?9 final ? ? ? ? ? 2 atubP1 1510.5405
> 6 ? ? ? ? ?9 final ? ? ? ? ? 2 atubP1 1443.1767
> 7 ? ? ? ? ?9 final ? ? ? ? ? 3 atubP1 1456.2050
> 8 ? ? ? ? ?9 final ? ? ? ? ? 3 atubP1 1578.6396
> 9 ? ? ? ? ?9 final ? ? ? ? ? 3 atubP1 1656.1822
> 10 ? ? ? ?17 final ? ? ? ? ? 1 atubP1 1462.5179
> 11 ? ? ? ?17 final ? ? ? ? ? 1 atubP1 1580.9956
> 12 ? ? ? ?17 final ? ? ? ? ? 1 atubP1 1255.9020
> 13 ? ? ? ?17 final ? ? ? ? ? 2 atubP1 ?886.7579
> 14 ? ? ? ?17 final ? ? ? ? ? 2 atubP1 ?581.8116
> 15 ? ? ? ?17 final ? ? ? ? ? 2 atubP1 ?722.0526
> 16 ? ? ? ?17 final ? ? ? ? ? 3 atubP1 4168.7895
> 17 ? ? ? ?17 final ? ? ? ? ? 3 atubP1 3266.2105
> 18 ? ? ? ?17 final ? ? ? ? ? 3 atubP1 4219.5645
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From David.Duffy at qimr.edu.au  Mon Feb  6 23:03:22 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 7 Feb 2012 08:03:22 +1000 (EST)
Subject: [R-sig-ME] Bootstrap the variance difference
In-Reply-To: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
References: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1202070802350.13671@orpheus.qimr.edu.au>

On Mon, 6 Feb 2012, Kevin Spring wrote:

> I can't do it this way because the boot function only allows for one data
> set to be inputted.

So you tried one combined dataset and subset?



From chris.eckert at queensu.ca  Mon Feb  6 23:26:56 2012
From: chris.eckert at queensu.ca (Chris Eckert)
Date: Mon, 06 Feb 2012 17:26:56 -0500
Subject: [R-sig-ME] Extracting means and SEs from an lmer object
Message-ID: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/84d7f594/attachment-0002.pl>

From A.Robinson at ms.unimelb.edu.au  Mon Feb  6 23:43:26 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 7 Feb 2012 09:43:26 +1100
Subject: [R-sig-ME] Bootstrap the variance difference
In-Reply-To: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
References: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
Message-ID: <20120206224326.GF1242@ms.unimelb.edu.au>

Hi Kevin,

add an indicator to each dataset and then rbind them. The indicator
variable then distinguishes between the sources. Pass it to boot as
the strata= argument.  Then also use that indicator in the varcomp
function to distinguish between the two datasets, e.g. using the
subset= arguments in lmer..

Cheers

Andrew

On Mon, Feb 06, 2012 at 03:32:35PM -0600, Kevin Spring wrote:
>  I asked this question on Stack Exchange, but I think it might be too
> specialized.  Hopefully someone in the mixed model group can help me out.
> 
> I want to be able to bootstrap the variance differences between two data
> sets obtained at different times while taking out the error in a random
> effect.
> 
> I have 2 sets of experimental data, where the data was measured at 2 time
> points (initial and final). I also have a set of simulation data. I want to
> compare the variance of the simulated date with the variance difference
> between the experimental data (final - initial). The idea is to get
> confidence intervals from the bootstrap to compare the experimental data
> with the simulation.
> 
> I am having trouble making the statistic for the bootstrap function in the
> boot package for R. So far I have.
> 
> varcomp <- function ( formula, data, indices ) {
>     d <- data[indices,] #sample for boot
>     fit <- lmer(formula, data=d) #linear model
>     res.var = (attr (VarCorr(fit), "sc")^2) # variance estimation
>     return(res.var)
>     }
> 
> But this function only returns the variance of a single data set. I want to
> be able to input 2 sets of data and have it return the difference between
> the two data sets' variance.
> 
> When I try something like:
> 
> varcomp <- function ( formula, data1, data2, indices ) {
> d1 <- data1[indices,] #sample for boot
> d2 <- data2[indices,] #sample for boot
> fit1 <- lmer(formula, data=d1) #linear model
> fit2 <- lmer(formula, data=d2) #linear model
> a = (attr (VarCorr(fit1), "sc")^2) #output variance estimation
> b = (attr (VarCorr(fit2), "sc")^2) #output variance estimation
> drv = a - b #difference between the variance estimations
> return(drv)
> }
> 
> I would then put it into boot such as:
> 
> ip1.boot <- boot ( data = ip1, statistic=varcomp, R=100,
> formula=CNPC~(1|Cell.line:DNA.extract)+Cell.line)
> 
> I can't do it this way because the boot function only allows for one data
> set to be inputted.
> 
> *Does anyone know how to create the correct statistic function for this?*
> 
> An example of the data can also be downloaded
> here<http://www.mediafire.com/file/68a3ro1cfneiy2r/data.zip.zip>(2 csv
> files zipped 1.22KB.)
> 
> My data looks something like the following:
> 
> Initial
> 
>        Cell.line    Time DNA.extract   Gene      CNPC
> 1          9 initial           1 atubP1 1778.4589
> 2          9 initial           1 atubP1 2108.0552
> 3          9 initial           1 atubP1 2118.6725
> 4          9 initial           2 atubP1 2018.6593
> 5          9 initial           2 atubP1 1935.9008
> 6          9 initial           2 atubP1 1749.9158
> 7          9 initial           3 atubP1 1524.7475
> 8          9 initial           3 atubP1 1532.9781
> 9          9 initial           3 atubP1 1693.3098
> 10        17 initial           1 atubP1 1076.4720
> 11        17 initial           1 atubP1 1101.3315
> 12        17 initial           1 atubP1 1185.3606
> 13        17 initial           2 atubP1 1131.1118
> 14        17 initial           2 atubP1  892.7087
> 15        17 initial           2 atubP1 1028.5465
> 16        17 initial           3 atubP1  887.9972
> 17        17 initial           3 atubP1  732.9646
> 18        17 initial           3 atubP1  680.6724
> 
> Final
> 
>    Cell.line  Time DNA.extract   Gene      CNPC
> 1          9 final           1 atubP1 1262.2378
> 2          9 final           1 atubP1 1261.9858
> 3          9 final           1 atubP1 1390.6873
> 4          9 final           2 atubP1 1539.7180
> 5          9 final           2 atubP1 1510.5405
> 6          9 final           2 atubP1 1443.1767
> 7          9 final           3 atubP1 1456.2050
> 8          9 final           3 atubP1 1578.6396
> 9          9 final           3 atubP1 1656.1822
> 10        17 final           1 atubP1 1462.5179
> 11        17 final           1 atubP1 1580.9956
> 12        17 final           1 atubP1 1255.9020
> 13        17 final           2 atubP1  886.7579
> 14        17 final           2 atubP1  581.8116
> 15        17 final           2 atubP1  722.0526
> 16        17 final           3 atubP1 4168.7895
> 17        17 final           3 atubP1 3266.2105
> 18        17 final           3 atubP1 4219.5645
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Deputy Director, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/



From kevinjspring at gmail.com  Mon Feb  6 23:43:43 2012
From: kevinjspring at gmail.com (Kevin Spring)
Date: Mon, 6 Feb 2012 16:43:43 -0600
Subject: [R-sig-ME] Bootstrap the variance difference
In-Reply-To: <CAPv6FHjZ37gmx7EAOAfQHCkahgJe1N1vZzKFT5OAajYKStgT1A@mail.gmail.com>
References: <CAPv6FHg-mODTqZ0yvCPipn574mC3F_bu7KdB49dry1pE4beB9A@mail.gmail.com>
	<Pine.LNX.4.64.1202070802350.13671@orpheus.qimr.edu.au>
	<CAPv6FHjZ37gmx7EAOAfQHCkahgJe1N1vZzKFT5OAajYKStgT1A@mail.gmail.com>
Message-ID: <CAPv6FHiBUcAe1JaczZ3A1BpLS8nLCLgyFLffsoaA_iG0s6j=4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/a8714b67/attachment-0002.pl>

From bates at stat.wisc.edu  Tue Feb  7 00:00:22 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 6 Feb 2012 17:00:22 -0600
Subject: [R-sig-ME] Extracting means and SEs from an lmer object
In-Reply-To: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>
References: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>
Message-ID: <CAO7JsnTRCgruYbX4ux1iRRkWOhkxkdiwWyX1Rgjmok3kyKBm7A@mail.gmail.com>

On Mon, Feb 6, 2012 at 4:26 PM, Chris Eckert <chris.eckert at queensu.ca> wrote:
> Hi,
> I am trying to extract means and SEs from an lmer object.
> So, I followed the example code from http://glmm.wikidot.com/faq
> from the "Predictions and/or confidence (or prediction) intervals on predictions" section of the faq

> library(lme4)
> library(ggplot2) # Plotting
> library(MEMSS) # for Orthodont

The problem may be due to MEMSS bringing in other packages that mask
the definition of fixef in lme4.  It works for me (see enclosed) if I
use
data(Orthodont, package="MEMSS")
instead.

> fm1 = lmer(
> ? ?formula = distance ~ age*Sex + (age|Subject)
> ? ?, data = Orthodont
> )
> newdat <- expand.grid(
> ? ?age=c(8,10,12,14)
> ? ?, Sex=c("Male","Female")
> ? ?, distance = 0
> )
> mm = model.matrix(terms(fm1),newdat)
> newdat$distance = mm %*% fixef(fm1)
> pvar1 <- diag(mm %*% tcrossprod(vcov(fm1),mm))
> tvar1 <- pvar1+VarCorr(fm1)$Subject[1]
> newdat <- data.frame(
> ? ?newdat
> ? ?, plo = newdat$distance-2*sqrt(pvar1)
> ? ?, phi = newdat$distance+2*sqrt(pvar1)
> ? ?, tlo = newdat$distance-2*sqrt(tvar1)
> ? ?, thi = newdat$distance+2*sqrt(tvar1)
> )
> When I get to the "newdat$distance = mm %*% fixef(fm1)" I get the following error:
> "Error in UseMethod("fixef") :
> ?no applicable method for 'fixef' applied to an object of class "mer""
>
> I am using lme4 version version 0.999375-42 (the most recent version on Cran) with R version 2.14.0
>
> Any explanation for this would be greatly appreciated.
>
> Chris Eckert
> Department of Biology
> Queen's University
> Kingston, Ontario, Canada

Seeing that makes me nostalgic. I spend my formative years at Queen's.
-------------- next part --------------

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: ?Matrix?

The following object(s) are masked from ?package:base?:

    det


Attaching package: ?lme4?

The following object(s) are masked from ?package:stats?:

    AIC, BIC

> library(ggplot2) # Plotting
Loading required package: reshape
Loading required package: plyr

Attaching package: ?reshape?

The following object(s) are masked from ?package:plyr?:

    rename, round_any

The following object(s) are masked from ?package:Matrix?:

    expand

Loading required package: grid
Loading required package: proto
> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
[1] ggplot2_0.8.9    proto_0.3-9.2    reshape_0.8.4    plyr_1.7.1      
[5] lme4_0.999375-42 Matrix_1.0-3     lattice_0.20-0  

loaded via a namespace (and not attached):
[1] nlme_3.1-103  stats4_2.14.1
> data(Orthodont, package="MEMSS")
> fm1 <- lmer(
+    formula = distance ~ age*Sex + (age|Subject)
+    , data = Orthodont
+ )
> fixef(fm1)
(Intercept)         age     SexMale age:SexMale 
 17.3727273   0.4795455  -1.0321023   0.3048295 
> newdat <- expand.grid(
+    age=c(8,10,12,14)
+    , Sex=c("Male","Female")
+    , distance = 0
+ )
> mm <- model.matrix(terms(fm1),newdat)
> newdat$distance <- mm %*% fixef(fm1)
> pvar1 <- diag(mm %*% tcrossprod(vcov(fm1),mm))
> tvar1 <- pvar1+VarCorr(fm1)$Subject[1]
> newdat <- data.frame(
+    newdat
+    , plo = newdat$distance-2*sqrt(pvar1)
+    , phi = newdat$distance+2*sqrt(pvar1)
+    , tlo = newdat$distance-2*sqrt(tvar1)
+    , thi = newdat$distance+2*sqrt(tvar1)
+ )
> 
> proc.time()
   user  system elapsed 
  4.136   0.800   4.031 

From kw.stat at gmail.com  Tue Feb  7 00:29:02 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 6 Feb 2012 17:29:02 -0600
Subject: [R-sig-ME] Extracting means and SEs from an lmer object
In-Reply-To: <CAO7JsnTRCgruYbX4ux1iRRkWOhkxkdiwWyX1Rgjmok3kyKBm7A@mail.gmail.com>
References: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>
	<CAO7JsnTRCgruYbX4ux1iRRkWOhkxkdiwWyX1Rgjmok3kyKBm7A@mail.gmail.com>
Message-ID: <CAKFxdiThkd41kym8Ae9VzZFjetAhOU=o79=S1gzcZrM8PaT5Rg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120206/d9ccbd3f/attachment-0002.pl>

From bates at stat.wisc.edu  Tue Feb  7 00:39:01 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 6 Feb 2012 17:39:01 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <4F2C95FD.3040405@auckland.ac.nz>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
	<CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>
	<75e0d743133e90.4f2c8d0f@wiscmail.wisc.edu>
	<767093351351e8.4f2c8d4d@wiscmail.wisc.edu>
	<7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
	<7620a004131150.4f2c394a@wiscmail.wisc.edu>
	<4F2C95FD.3040405@auckland.ac.nz>
Message-ID: <CAO7JsnQL4o-G6vYq0mxWTLGYOgjA9oEOHrH_oH2yvdVQC7ThTA@mail.gmail.com>

On Fri, Feb 3, 2012 at 8:20 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 04/02/12 14:45, Kenneth Frost wrote:
>>
>> On 02/03/12, Charles Determan Jr ? wrote:
>>>
>>> Kevin,
>>>
>>> I understand that but then how is SAS accomplishing the interactions?
>>
>>
>> I have been following this conversation a little bit and this seems to be
>> the right question to ask. I would also like to know the answer. However,
>> this could be the wrong venue to get an answer to this question.
>
> <SNIP>
>
> It may be the case that fortune(203) is relevant here! :-)

Mathematical impossibilty, no (fortune(203) refers to obtaining
negative estimates of variance components, IIRC).  The problem here is
determining a full-rank model matrix for a model with interactions and
missing cells.  Because SAS uses the sweep operator in solving least
squares problems it does not encounter problems with rank deficiency.
(I am sorely tempted to make remarks about "sweeping them under the
carpet".)  In fact, SAS expects to handle rank deficiencies because it
generates a redundant set of indicators for each factor variable then
prunes them on the fly.

The approach in R is to generate a model matrix that should be of
full-rank except in circumstances like this and to check for rank
deficiency.  There is special code in the version of the QR
decomposition used with R to detect rank deficiency and pivot the
offending columns out but keep the others in their original order.

Dirk Eddelbuettel and I explored several approaches to handling such
rank deficiency in the vignette accompanying the RcppEigen package
(http://cran.us.r-project.org/web/packages/RcppEigen/vignettes/RcppEigen-intro-nojss.pdf).
 The development version of lme4 (called lme4Eigen on the R-forge
project site) detects rank deficiency earlier in the calculation but
does not yet repair the rank deficiency.  Using the column-pivoted QR
decomposition is probably the best approach but even then it would be
necessary to find the columns that are linear dependent on columns to
their left then drop only those columns.  It is not impossible by any
means, it just requires some work and is not high on the priority list
right now.

Regarding type III tests, I have forgotten which ones they are.  Are
they the sequential sums of squares or the ones where you drop the
main effect but keep the interactions thereby rendering your null
model nonsensical is most cases?
All the silliness about Types I, II, III and IV sums of squares and
tests was formulated when fitting any model was difficult (see
fortune("JCL")).  So doing a hypothesis test by fitting the null model
and fitting the alternative model and comparing the results would take
much much longer than doing a lot of linear algebra gymnastics on the
fit of the full or alternative model.  That is no longer the case.  If
you really want to perform a hypothesis test then formulate it in
terms of models, fit them and compare them.  It's not difficult and
has the undeniable advantage of forcing you to think about the model
and whether it makes sense.  Read Bill Venables' famous unpublished
paper "Exegeses on Linear Models" (just put the name in a search
engine).  (By the way, Bill is going to be at the useR conference in
Nashville in July so maybe if a bunch of us ganged up on him he could
be convinced to submit a version of that paper for publication.)



From kfrost at wisc.edu  Tue Feb  7 01:02:49 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Mon, 06 Feb 2012 18:02:49 -0600
Subject: [R-sig-ME] lme capable of running with missing data?
In-Reply-To: <7630f83985c35.4f306925@wiscmail.wisc.edu>
References: <CAOLJphnkY4+CAhuAM3P=g6TwSoxYL55y8T1vGPwKVZL8A+DPVQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C53@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphk88qwL4wdL70fOVjAh9aFaZRa-Ha_tj_OGZqedV+RbWQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B1E5C8E@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphmz=OUg3OP_S1+Rj8ELTZHqsTGbTo2S0buAZ3OMSf07MA@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690E2C1FAF@001FSN2MPN1-016.001f.mgd2.msft.net>
	<CAOLJph==okH1L1yATEO4dXruJkCCrXsbiGBaiqG_Cb+gXKghhw@mail.gmail.com>
	<CAKFxdiRF0d0MnRvFvZ604d443OWFgaEQ7O5kQfwgfYmA3ERGCA@mail.gmail.com>
	<CAOLJphmW7OH-o-Cn_fVb6LoB03rpbTzNVGB0d-aD2tZOOwk_FA@mail.gmail.com>
	<CAKFxdiS0BPHdj0qnKPzY2aZ3R+w2SeyyMwcqg5pmUEcE0C4wtw@mail.gmail.com>
	<CAOLJph=S7hD7KJq5qP68fTxLBRid+6zO3DZHzeWYjYaKK0362A@mail.gmail.com>
	<75e0d743133e90.4f2c8d0f@wiscmail.wisc.edu>
	<767093351351e8.4f2c8d4d@wiscmail.wisc.edu>
	<7590bf7c1328c8.4f2c8d8a@wiscmail.wisc.edu>
	<7620a004131150.4f2c394a@wiscmail.wisc.edu>
	<4F2C95FD.3040405@auckland.ac.nz>
	<CAO7JsnQL4o-G6vYq0mxWTLGYOgjA9oEOHrH_oH2yvdVQC7ThTA@mail.gmail.com>
	<7750887b86a4a.4f30668b@wiscmail.wisc.edu>
	<7780c32584739.4f306704@wiscmail.wisc.edu>
	<7630b99485277.4f306831@wiscmail.wisc.edu>
	<7750a59386776.4f30686e@wiscmail.wisc.edu>
	<7750ada685dda.4f3068ab@wiscmail.wisc.edu>
	<7750f596830b9.4f3068e8@wiscmail.wisc.edu>
	<7630f83985c35.4f306925@wiscmail.wisc.edu>
Message-ID: <763096e7864e1.4f3015c9@wiscmail.wisc.edu>

Doug-

Thanks for the explanation. I think I can understand what is happening in the column-pivoted QR decomposition you are describing.? I'm not sure if I understand how the sweep operator works (although I'm not too worried about it at the moment).

Ken
?

On 02/06/12, Douglas Bates   wrote:
> On Fri, Feb 3, 2012 at 8:20 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> > On 04/02/12 14:45, Kenneth Frost wrote:
> >>
> >> On 02/03/12, Charles Determan Jr ? wrote:
> >>>
> >>> Kevin,
> >>>
> >>> I understand that but then how is SAS accomplishing the interactions?
> >>
> >>
> >> I have been following this conversation a little bit and this seems to be
> >> the right question to ask. I would also like to know the answer. However,
> >> this could be the wrong venue to get an answer to this question.
> >
> > <SNIP>
> >
> > It may be the case that fortune(203) is relevant here! :-)
> 
> Mathematical impossibilty, no (fortune(203) refers to obtaining
> negative estimates of variance components, IIRC).  The problem here is
> determining a full-rank model matrix for a model with interactions and
> missing cells.  Because SAS uses the sweep operator in solving least
> squares problems it does not encounter problems with rank deficiency.
> (I am sorely tempted to make remarks about "sweeping them under the
> carpet".)  In fact, SAS expects to handle rank deficiencies because it
> generates a redundant set of indicators for each factor variable then
> prunes them on the fly.
> 
> The approach in R is to generate a model matrix that should be of
> full-rank except in circumstances like this and to check for rank
> deficiency.  There is special code in the version of the QR
> decomposition used with R to detect rank deficiency and pivot the
> offending columns out but keep the others in their original order.
> 
> Dirk Eddelbuettel and I explored several approaches to handling such
> rank deficiency in the vignette accompanying the RcppEigen package
> (http://cran.us.r-project.org/web/packages/RcppEigen/vignettes/RcppEigen-intro-nojss.pdf).
>  The development version of lme4 (called lme4Eigen on the R-forge
> project site) detects rank deficiency earlier in the calculation but
> does not yet repair the rank deficiency.  Using the column-pivoted QR
> decomposition is probably the best approach but even then it would be
> necessary to find the columns that are linear dependent on columns to
> their left then drop only those columns.  It is not impossible by any
> means, it just requires some work and is not high on the priority list
> right now.
> 
> Regarding type III tests, I have forgotten which ones they are.  Are
> they the sequential sums of squares or the ones where you drop the
> main effect but keep the interactions thereby rendering your null
> model nonsensical is most cases?
> All the silliness about Types I, II, III and IV sums of squares and
> tests was formulated when fitting any model was difficult (see
> fortune("JCL")).  So doing a hypothesis test by fitting the null model
> and fitting the alternative model and comparing the results would take
> much much longer than doing a lot of linear algebra gymnastics on the
> fit of the full or alternative model.  That is no longer the case.  If
> you really want to perform a hypothesis test then formulate it in
> terms of models, fit them and compare them.  It's not difficult and
> has the undeniable advantage of forcing you to think about the model
> and whether it makes sense.  Read Bill Venables' famous unpublished
> paper "Exegeses on Linear Models" (just put the name in a search
> engine).  (By the way, Bill is going to be at the useR conference in
> Nashville in July so maybe if a bunch of us ganged up on him he could
> be convinced to submit a version of that paper for publication.)


From fan.mongxie at gmail.com  Tue Feb  7 15:13:57 2012
From: fan.mongxie at gmail.com (Fan Mongxie)
Date: Tue, 7 Feb 2012 15:13:57 +0100
Subject: [R-sig-ME] Check the predictions of glmer
Message-ID: <CAAZy3PDSto8xttftUJPWb8W3ET11JQ55g1NmaVULVm_CY5+S0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/42313705/attachment-0002.pl>

From bbolker at gmail.com  Tue Feb  7 15:23:18 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 07 Feb 2012 09:23:18 -0500
Subject: [R-sig-ME] lmer blocking by subject?
In-Reply-To: <CALBCd4id6P7-A7rXGWfu0w0sizWfuAL5vx3EJq7LZGGmQkY0QA@mail.gmail.com>
References: <CALBCd4h+6u1a5fFkQ1uATGPZRQ4KxGC68WYE7rDm5M0gjUR4Mg@mail.gmail.com>
	<loom.20120206T043305-347@post.gmane.org>
	<CALBCd4id6P7-A7rXGWfu0w0sizWfuAL5vx3EJq7LZGGmQkY0QA@mail.gmail.com>
Message-ID: <4F3133D6.6010500@gmail.com>

  [cc'ing back to r-sig-mixed-models]

On 12-02-05 11:31 PM, Tiffanie Cross wrote:
> 
> 
> On Sun, Feb 5, 2012 at 7:50 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>     Tiffanie Cross <tahtg6 at ...> writes:
> 
>     > I am new to R and would like some guidance on how to block by subject.
>     >
>     > I collected presence/absence 24 hrs/day for 44 birds, denoted
>     "bird", at 5
>     > stations, denoted "colony" for the duration of a breeding season. The
>     > breeding season was broken into biologically relevant time periods (3
>     > levels), denoted "period". The birds were captured on 2 different
>     colonies,
>     > 22 on each colony, denoted "homecolony". I also have the variable,
>     "sex". I
>     > have about 300,000 total observations for these 44 birds. This data is
>     > temporally auto-correlated because it is VHF radio-telemetry data
>     recorded
>     > continually throughout the study.
> 
>      What is the temporal resolution?  Based on a guess at the length
>     of the breeding season (60 days), I'm guessing about every 10-12
>     minutes.
>     This isn't essential information but would help get a feel for the
>     data.
> 
> 
> The breeding season is from 22 May to 15 August. The maximum detection
> interval is 20 minutes in the case that all tagged birds are present,
> and the minimum is 3 minutes in the case that only one tagged bird is
> present.  


  So the samples are unevenly spaced too ... ?

> 
> 
>       Be aware that modeling temporal autocorrelation in a binary
>     variable may be a little bit tricky -- there are a variety of
>     approaches, but none are quite as easy as the way one builds
>     autocorrelation into a normal-response model, by making the residuals
>     within blocks multivariate normal with a specified autocorrelation.  A
>     few possibilities that spring to mind are (1) because there is
>     presumably no error in the observations themselves, you could
>     condition on the previous observation (i.e. put it in as a predictor);
>     (2) aggregate the data to a coarser temporal scale and fit the data as
>     binomial (e.g.  number of presence/absence values per 2-hour period,
>     or per day, or some other appropriate period that balances resolution
>     and lack of autocorrelation); (3) if there are long 'runs' of
>     presence/absences, aggregate the data down to times when birds entered
>     or left; (4) [fanciest, but not necessarily worth the trouble or most
>     appropriate] assume an underlying multivariate normal distribution
>     that *is* autocorrelated and controls probability of presence
>     (i.e. a hierarchical model with autocorrelation in the level
>     below the observation level).
> 
> 
> I had the model fitted as you describe in option 4 using PROC GLIMMIX in
> SAS. The next step in SAS was to look at residuals and I couldn't figure
> out how to do that. So, I consulted a colleague who turned me on to Zuur
> et al. which was helpful initially. And now I'm stuck in R, too. I'm
> supposed to defend soon and this is kind of ruining that, I fear. =( 

   The closest equivalent to PROC GLIMMIX in SAS is glmmPQL from the
MASS package, in R.  Most of what you can do in GLIMMIX you can also do
in glmmPQL.

  The model statement for blocking by bird and allowing for correlation
within birds across time would be something like

  glmmPQL(present ~  gender + period + homecolony + colony,
   random=~period|bird), correlation=corCAR1(form=~time|bird),
    data = FD, family = binomial)


>     > I know that the (1+period|bird) term is probably incorrect

  why do you think so?

  this allows for the effect of period to vary across birds.  I would
say you *might* want ~period+colony|bird , if your data can support it ...


   The two drawbacks with using glmmPQL or GLIMMIX are that (1) they
both use penalized quasi-likelihood, which are known to give biased
estimates of the variances for binary data; and (2) it's possible to fit
models that don't really make much sense in them.  However, both of
these are matters of taste (in my opinion) rather than absolute
show-stoppers.  I hate to say it, but if SAS was mostly working for you
and it was just a matter of getting residuals wouldn't that be an
easier problem to solve ... ?  (I

http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_glimmix_a0000001413.htm


  BTW GLIMMIX now does Laplace and quadrature methods too, but it does
not allow autocorrelation with these methods:

http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_glimmix_a0000001405.htm

 *  Because a valid conditional distribution is required, R-side random
 effects are not permitted for METHOD=LAPLACE in the GLIMMIX procedure.
In other words, the GLIMMIX procedure requires for METHOD=LAPLACE
conditional independence without R-side overdispersion or covariance
structure.

> 
> I did build a column into my data for "hour", so I guess I do have an
> "hour" variable that 'detections per hour' could be calculated for each
> individual. 
> 
> 
>     > I have a binary response variable, "present", with independent
>     variables
>     > "sex" at 2 levels, "homecolony" at 2 levels, "colony" at 5 levels, and
>     > "period" at 3 levels. I would like to incorporate "period", "bird" and
>     > "colony" as random effects. Fixed effects are "sex" and
>     "homecolony". The
>     > "bird" variable is what I want the model blocked by.
> 
>       Practically speaking, you can't treat period as a random effect --
>     not enough levels.
> 
> 
> Ok. I will specify it as fixed. :) Thanks! 
> 
> 
>     > I am trying to answer the following questions: "Are there
>     differences in
>     > presence between sexes, homecolony, and period?" "Do birds from one
>     > homecolony differ in their use of other colonies (colony)?"
>     >
>     > I cannot figure out how to specify that I want the model to block by
>     > subject, i.e. "bird". I have tried incorporating "bird" as a
>     random effect,
>     > but the degrees of freedom still come out to be close to 300,000
>     which is
>     > near the total number of observations. Can anyone show me syntax
>     that will
>     > incorporate bird as a random effect that the model blocks by subject?
> 
>       Where are you seeing the degrees of freedom?
> 
> 
> I don't remember and I didn't save the output.  
> 
>     >
>     > I tried following examples from Doug Bates' LME4 book, Chapter 4:
> 
>     > Glmm_FD <- lmer(present ~ 1 + gender + period + homecolony +
>     colony + (1 +
>     > period|bird), data = FD, family = binomial, REML = 0)
>     > I know that the (1+period|bird) term is probably incorrect.
> 
>      REML=0 is meaningless in this case (lmer doesn't use REML
>     or an analogue of it when fitting a non-Gaussian model), but
>     otherwise your model specification seems to be on the right track.
> 
>      Since I'm guessing the birds can only be detected at a single
>     station at a time, this is a bit more of a categorical response
>     (i.e., is bird X present at colony 1-5 or "none of the above"
>     at time T?)  Have you thought about multistate mark-recapture 
> 
>     models ... ?
> 
> 
> I'll take REML = 0 out of the model. The birds can only be detected at
> one station at time T. I don't know what multistate mark-recapture
> models are. I mentally steered clear of mark-recapture because they make
> me think of population estimates or homerange type analyses. I'm after
> mostly behavioral information here.

  Well, I think they could be useful, but no need to delve into
unnecessary complications ...
> 
> 
>       This seems like a fairly complex problem.  How have others
>     in your field handled these kinds of data?  With lots of data
>     on each bird, you may be able to simplify your life a bit by
>     analyzing each bird separately -- i.e. a two-stage model rather
>     than a mixed/multilevel model -- Murtaugh 2007 _Ecology_ recommends
>     this, although I don't always agree with him ...
> 
> 
> I haven't seen others in my field with this sort of data use GLM or GLMM
> at all. I actually disagreed with previous methods and if my memory
> serves I didn't see any statistical information provided. 
> 
> 
>      I would recommend Zuur et al for messy/complex ecological
>     data, although I don't agree with all of that either ...
> 
> 
> So is there no command like "Subject = bird" as there is in PROC GLIMMIX
> in SAS?

  Well, the point is that (1|bird) *is* more or less equivalent (as I
understand it) to "Subject=bird".

  I would definitely follow Murtaugh's advice here and use the
*simplest* method that you think will make sense.  Doing a two-stage
analysis might be just fine.

  Ben Bolker



From bbolker at gmail.com  Tue Feb  7 17:56:42 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Feb 2012 16:56:42 +0000 (UTC)
Subject: [R-sig-ME] repeated measure in partially crossed design
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
	<F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>
	<loom.20120201T030103-410@post.gmane.org>
	<8B77AD44-9DF0-4EE4-911D-AAA1A3948A4E@qmul.ac.uk>
Message-ID: <loom.20120207T175226-898@post.gmane.org>

matteo dossena <m.dossena at ...> writes:

> this really make things clearer now, seems like (season|subject), 
> could be the appropriate structure.
> 
> However, a last doubt still trouble me.
> 
> Having (season|subject) fitted as random effect, 
> is it taking in consideration pseudoreplication
> (repeated measures on subject)?

  Yes.

> If I would do this analysis with lme() I would fit a model with the
>  argument correlation=CorCompSymm(form=~1|subject),
> and a model without correlation than compared the two 
> to assess wether or not  there is violation of the independence.
> Is this a sensible things to do?

  I have to admit I don't quite understand why people fit
CorCompSymm models so much since they are *almost* equivalent to
just including a random effect of the form ~1|subject (with the
difference, I guess, that negative within-cluster correlations
are possible, while random=~1|subject enforces positive correlations).

> 
> Since i'm working with lmer(), how can I check if correlation
>  has to be included in the model?

  This is partly a philosophical question.  I would say that if
subject blocking is part of your experimental/sampling design then
you should include it in the model in any case, unless it causes
severe technical difficulties with the fitting.

   CorCompSymm is not a possibility in lmer.  In principle 
you can do a likelihood ratio test, but lmer won't fit models
without any random effects.  You could try the RLRsim package.
See also advice in <http://glmm.wikidot.com/faq> about how
(and whether) to test random effects.

> 
> Cheers
> m.
> 

 [snip snip]



From bates at stat.wisc.edu  Tue Feb  7 18:11:20 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Feb 2012 11:11:20 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
Message-ID: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>

We (the lme4 authors) have mentioned on this list that we are
preparing a new version of lme4 that will provide enhanced
capabilities.  That's the good news.  The bad news is that the
internal representation of the model has been changed yet again.  If
your use of the lme4 package is through the exported functions only
you should be okay.  However, if you find problems then please report
them to us either in email <lme4-authors at r-forge.wu-wien.ac.at> or on
the bug-tracker at R-forge,

https://r-forge.r-project.org/tracker/?func=add&group_id=60&atid=298

One major, and unfortunately inevitable, problem that will affect many
users is the inability of the new code to load saved objects created
with the old code.  Unfortunately that is what happens when you change
the class representation.  If possible it is best to save the code and
data that generated the fitted model and re-fit after the change.

If your usage involved access to components or slots in the object
then there will be changes.  To ease the transition, Martin created a
function called getME that is available in the current lme4 and in the
new lme4, available as lme4Eigen on R-forge.  This function takes a
fitted model and a character variable naming a component and returns
the desired component.  For example, if you want the fixed-effects
model matrix from fitted model fm1 then use

getME(fm1, "X")

Similarly for the random-effects model matrix, "Z", or its transpose,
"Zt", the sparse Cholesky factor, "L" and many others.  Use

library(lme4)
example(getME)

to get some examples.

The new lme4 will provide

 - profiling of the deviance function with respect to the parameters
   in a linear mixed model (and soon generalized linear mixed models).
   The profiles allow for creation of realistic confidence intervals
   on the parameters and for various plots that show the sensitivity
   of the deviance to the values of the parameters.

 - a more reliable and flexible implementation of generalized linear
   mixed models, including the use of adaptive Gauss-Hermite
   quadrature for evaluating an approximation to the deviance.

 - short-cut functions such as refitML and refit to re-evaluate a
   model under the maximum likelihood criterion or with a new response
   vector.

 - a cleaner internal representations that provides, in most cases,
   faster and more reliable model fits.

 - choice of optimizer when estimating the parameters.  Current
   choices are "NelderMead" and "bobyqa".  Both are generally faster
   and more reliable than the optimizer used in the current lme4,
   which is based on the code in R's nlminb() function, the one that
   gives those annoying "false convergence" messages.

 - smaller memory footprint.  The need for copying large objects is
   reduced through the use of reference classes in R.  In the past
   there were circumstances where it was possible to fit a model to a
   large data set but not to print or show the results because a new
   copy of the entire object was created during the process of
   creating a summary.  This no longer occurs.

 - nlmer has been improved and will, by the time of release, allow
   adaptive Gauss-Hermite quadrature.

An alpha-test release will be made available on the R-forge archive
but *not* uploaded to CRAN.  If you use lme4 extensively please test
this release by installing from the R-forge archive and telling us if
there are problems with your code.  This way you can still back out to
the current release by removing the lme4 package and reinstalling from
CRAN.  Once the new lme4 has been released to CRAN it will be much
more difficult to back out that installation.

Authors of packages that depend on lme4 will get a separate message
off-list about testing and suggested modifications.

Thanks for your cooperation.  We do honestly believe that this change
will provide an improved capability for fitting and analyzing
mixed-effects models.



From shaillymehrotra at gmail.com  Tue Feb  7 15:40:58 2012
From: shaillymehrotra at gmail.com (SHAILLY MEHROTRA)
Date: Tue, 7 Feb 2012 09:40:58 -0500
Subject: [R-sig-ME] nlme -95% CI of parameter estimates
Message-ID: <CAN8uQptfeq++wUU4H9dmL1k4E=gV+uNVB9+Hwro+QQbWo5+n1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/6565db6c/attachment-0002.pl>

From m.dossena at qmul.ac.uk  Tue Feb  7 18:28:39 2012
From: m.dossena at qmul.ac.uk (matteo dossena)
Date: Tue, 7 Feb 2012 17:28:39 +0000
Subject: [R-sig-ME] repeated measure in partially crossed design
In-Reply-To: <loom.20120207T175226-898@post.gmane.org>
References: <764036CF-0B4D-40FE-8465-14D8C4D839E4@qmul.ac.uk>
	<AA818EAD2576BC488B4F623941DA742757339C77@inbomail.inbo.be>
	<8216D3E7-76A6-4943-89F1-9172277FD909@qmul.ac.uk>
	<F77D0EEE-0840-4967-95EC-02BBC2F8BB70@qmul.ac.uk>
	<loom.20120201T030103-410@post.gmane.org>
	<8B77AD44-9DF0-4EE4-911D-AAA1A3948A4E@qmul.ac.uk>
	<loom.20120207T175226-898@post.gmane.org>
Message-ID: <1A61E9AE-211D-4D34-B39F-5FADFD2706E5@qmul.ac.uk>

Thanks a lot Ben,

most probably, my doubt rises from a still superficial comprehension of the topic.
I guess, the correlation matrix is more important when is not simply symmetric and 
when the analysis is actually investigating the temporal dynamics.
I my case I'm interested in fitting a model that properly accounts for the experimental design.

Cheers
m.

Il giorno 7 Feb 2012, alle ore 16:56, Ben Bolker ha scritto:

> matteo dossena <m.dossena at ...> writes:
> 
>> this really make things clearer now, seems like (season|subject), 
>> could be the appropriate structure.
>> 
>> However, a last doubt still trouble me.
>> 
>> Having (season|subject) fitted as random effect, 
>> is it taking in consideration pseudoreplication
>> (repeated measures on subject)?
> 
> Yes.
> 
>> If I would do this analysis with lme() I would fit a model with the
>> argument correlation=CorCompSymm(form=~1|subject),
>> and a model without correlation than compared the two 
>> to assess wether or not  there is violation of the independence.
>> Is this a sensible things to do?
> 
> I have to admit I don't quite understand why people fit
> CorCompSymm models so much since they are *almost* equivalent to
> just including a random effect of the form ~1|subject (with the
> difference, I guess, that negative within-cluster correlations
> are possible, while random=~1|subject enforces positive correlations).
> 
>> 
>> Since i'm working with lmer(), how can I check if correlation
>> has to be included in the model?
> 
> This is partly a philosophical question.  I would say that if
> subject blocking is part of your experimental/sampling design then
> you should include it in the model in any case, unless it causes
> severe technical difficulties with the fitting.
> 
>  CorCompSymm is not a possibility in lmer.  In principle 
> you can do a likelihood ratio test, but lmer won't fit models
> without any random effects.  You could try the RLRsim package.
> See also advice in <http://glmm.wikidot.com/faq> about how
> (and whether) to test random effects.
> 
>> 
>> Cheers
>> m.
>> 
> 
> [snip snip]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Tue Feb  7 18:47:59 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Feb 2012 11:47:59 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
Message-ID: <CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>

On Tue, Feb 7, 2012 at 11:11 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> We (the lme4 authors) have mentioned on this list that we are
> preparing a new version of lme4 that will provide enhanced
> capabilities. ?That's the good news. ?The bad news is that the
> internal representation of the model has been changed yet again. ?If
> your use of the lme4 package is through the exported functions only
> you should be okay. ?However, if you find problems then please report
> them to us either in email <lme4-authors at r-forge.wu-wien.ac.at> or on
> the bug-tracker at R-forge,
>
> https://r-forge.r-project.org/tracker/?func=add&group_id=60&atid=298
>
> One major, and unfortunately inevitable, problem that will affect many
> users is the inability of the new code to load saved objects created
> with the old code. ?Unfortunately that is what happens when you change
> the class representation. ?If possible it is best to save the code and
> data that generated the fitted model and re-fit after the change.
>
> If your usage involved access to components or slots in the object
> then there will be changes. ?To ease the transition, Martin created a
> function called getME that is available in the current lme4 and in the
> new lme4, available as lme4Eigen on R-forge. ?This function takes a
> fitted model and a character variable naming a component and returns
> the desired component. ?For example, if you want the fixed-effects
> model matrix from fitted model fm1 then use
>
> getME(fm1, "X")
>
> Similarly for the random-effects model matrix, "Z", or its transpose,
> "Zt", the sparse Cholesky factor, "L" and many others. ?Use
>
> library(lme4)
> example(getME)
>
> to get some examples.
>
> The new lme4 will provide
>
> ?- profiling of the deviance function with respect to the parameters
> ? in a linear mixed model (and soon generalized linear mixed models).
> ? The profiles allow for creation of realistic confidence intervals
> ? on the parameters and for various plots that show the sensitivity
> ? of the deviance to the values of the parameters.
>
> ?- a more reliable and flexible implementation of generalized linear
> ? mixed models, including the use of adaptive Gauss-Hermite
> ? quadrature for evaluating an approximation to the deviance.
>
> ?- short-cut functions such as refitML and refit to re-evaluate a
> ? model under the maximum likelihood criterion or with a new response
> ? vector.
>
> ?- a cleaner internal representations that provides, in most cases,
> ? faster and more reliable model fits.
>
> ?- choice of optimizer when estimating the parameters. ?Current
> ? choices are "NelderMead" and "bobyqa". ?Both are generally faster
> ? and more reliable than the optimizer used in the current lme4,
> ? which is based on the code in R's nlminb() function, the one that
> ? gives those annoying "false convergence" messages.
>
> ?- smaller memory footprint. ?The need for copying large objects is
> ? reduced through the use of reference classes in R. ?In the past
> ? there were circumstances where it was possible to fit a model to a
> ? large data set but not to print or show the results because a new
> ? copy of the entire object was created during the process of
> ? creating a summary. ?This no longer occurs.
>
> ?- nlmer has been improved and will, by the time of release, allow
> ? adaptive Gauss-Hermite quadrature.
>
> An alpha-test release will be made available on the R-forge archive
> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
> this release by installing from the R-forge archive and telling us if
> there are problems with your code. ?This way you can still back out to
> the current release by removing the lme4 package and reinstalling from
> CRAN. ?Once the new lme4 has been released to CRAN it will be much
> more difficult to back out that installation.
>
> Authors of packages that depend on lme4 will get a separate message
> off-list about testing and suggested modifications.
>
> Thanks for your cooperation. ?We do honestly believe that this change
> will provide an improved capability for fitting and analyzing
> mixed-effects models.

I forgot to mention an important point for Mac OS X users.  The new
lme4, which is based on the Eigen linear algebra library, requires the
RcppEigen package for which there is no binary Mac OS X package on
CRAN.  It's a ridiculous situation that comes about because Apple
ships an antique version of gcc in their XCode development
environment, and won't upgrade because of licensing disagreements.
Even that very old version of g++ compiles the package successfully
for Intel Macs but it croaks when trying to cross-compile for the ppc
architecture.  You can see at
http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-00install.html
that the advice it to inform Apple of the compiler error but they
ignore such reports.  Things may improve when XCode 4 is in use
because it provides clang++ in addition to the same very old version
of g++.  In the meantime we will provide a binary i386 Mac OS X
package for RcppEigen.



From mjgeha at huskers.unl.edu  Tue Feb  7 19:33:49 2012
From: mjgeha at huskers.unl.edu (mjgeha at huskers.unl.edu)
Date: Tue, 7 Feb 2012 18:33:49 +0000
Subject: [R-sig-ME] MCMCglmm with zibinomial
Message-ID: <D355D72185FD4941AAF21E72A017059E0170C029@SN2PRD0102MB131.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/74173676/attachment-0002.pl>

From smckinney at bccrc.ca  Tue Feb  7 20:40:08 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 7 Feb 2012 11:40:08 -0800
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <2359_1328636892_1328636892_CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<2359_1328636892_1328636892_CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A70846@crcmail4.BCCRC.CA>



> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Douglas Bates
> Sent: February-07-12 9:48 AM
> To: R-mixed models mailing list
> Subject: Re: [R-sig-ME] Upcoming changes in lme4
> 
> On Tue, Feb 7, 2012 at 11:11 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> > We (the lme4 authors) have mentioned on this list that we are
> > preparing a new version of lme4 that will provide enhanced
> > capabilities. ?That's the good news. ?

<snip>


> 
> I forgot to mention an important point for Mac OS X users.  The new
> lme4, which is based on the Eigen linear algebra library, requires the
> RcppEigen package for which there is no binary Mac OS X package on
> CRAN.  It's a ridiculous situation that comes about because Apple
> ships an antique version of gcc in their XCode development
> environment, and won't upgrade because of licensing disagreements.
> Even that very old version of g++ compiles the package successfully
> for Intel Macs but it croaks when trying to cross-compile for the ppc
> architecture.  You can see at
> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-
> 00install.html
> that the advice it to inform Apple of the compiler error but they
> ignore such reports.  Things may improve when XCode 4 is in use
> because it provides clang++ in addition to the same very old version
> of g++.  In the meantime we will provide a binary i386 Mac OS X
> package for RcppEigen.


Thanks for all your hard and good work on the lme4 package.
I use it regularly, but many of my data sets are huge and
64 bit processing is essential.

Would you be able to provide Intel binary i386 (32 bit) and 
x86_64 (64 bit) builds in your Mac OS X package?


Best

Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre


> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Tue Feb  7 21:12:19 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 07 Feb 2012 20:12:19 +0000
Subject: [R-sig-ME] MCMCglmm with zibinomial
In-Reply-To: <D355D72185FD4941AAF21E72A017059E0170C029@SN2PRD0102MB131.prod.exchangelabs.com>
References: <D355D72185FD4941AAF21E72A017059E0170C029@SN2PRD0102MB131.prod.exchangelabs.com>
Message-ID: <20120207201219.11651wsp09l5fp34@www.staffmail.ed.ac.uk>

Hi,


Below is a zero-inflated binomial example. I can only get your warning  
if the data are not positive integers. Are you sure this is not the  
case?

You can fit multiple correlation structures (e.g. animal and sire)  
using the ginverse argument.

Cheers,

Jarrod


library(VGAM)

n<-1000                                # number of observations
size<-rpois(n,1)+10            # number of trials per observation
prob<-rnorm(n, 1, sqrt(2))  # logit probability of success (with variance 2)
phi.logit<-(-1)  # logit probability of zero (ignoring the binomial  
distribution)

y<-rzibinom(n, size, plogis(prob), phi = plogis(phi.logit))

detach(package:VGAM) # detach: VGAM conflicts with everything

dat<-data.frame(success=y, failure=size-y)

prior<-list(R=list(V=diag(2), nu=0, fix=2))

# as in binary data the observation-level heterogeneity in  
zero-inflation cannot be estimated - the varaince of these effects  
I've arbitrarily set at 1.

m1<-MCMCglmm(c(success, failure)~trait-1, rcov=~idh(trait):units,  
data=dat, family="zibinomial", prior=prior)

# below posteriors with simulation value in red

hist(m1$Sol[,1])
abline(v=1, col="red")

c2 <- (16 * sqrt(3)/(15 * pi))^2  # correction fator because  
VGAM::rzbinom assumes the variance in logit zero-inflation  
probabilities is zero not one as in MCMCglmm

hist(m1$Sol[,2]/sqrt(1+c2))
abline(v=phi.logit, col="red")

hist(m1$VCV[,1])
abline(v=2, col="red")



Quoting "mjgeha at huskers.unl.edu" <mjgeha at huskers.unl.edu> on Tue, 7  
Feb 2012 18:33:49 +0000:

> I have been trying to fit a zibinomial distribution to a set of data I have.
>
> The response variable is in a single column and represents the  
> percentages of a certain incidence (ranging obviously between 0 and  
> 1).
>
> The data is assumed to be zero-inflated as > 40% of the data is made  
> up of zeroes.
>
> I have tried to fit the following:
>
> analysis.1<-MCMCglmm(response~1,random=~animal,rcov=~units,family="zibinomial",nitt=50000,burnin=5000,thin=25,data=source1,pedigree=ped.dat)
>
>
>
> I get the same error message as reported in a previous question  
> regarding the "zibinomial" :
>
> "Error in rowSums(data[, match(response.names[0:1 + nt], names(data))]) :
>   error in evaluating the argument 'x' in selecting a method for  
> function 'rowSums': Error in `[.data.frame`(data, ,  
> match(response.names[0:1 + nt], names(data))) :
>   undefined columns selected"
>
>
>
> I looked up the answer submitted to that question and tried creating  
>  "success" and "failure" variables and fit the following:
>
> MCMCglmm(cbind(success,failure)~  
> -1,random=~us(trait):animal,rcov=~us(trait):units,family=rep("zibinomial",2),nitt=50000,burnin=1000,thin=25,data=snap)
>
> Now I'm getting the following error message:
>
> "Error in MCMCglmm(cbind(success, failure) ~ - 1, random =  
> ~us(trait):animal,  :
>   binomial data must be non-negative integers"
>
> I'm sure I don't have any negative integers in my data set.
>
> I was wondering if it would be possible to get more  
> clarification/example/reference on fitting zibinomial in MCMCglmm.
>
>
>
> Also would it be possible to fit more than one pedigree relationship  
> matrix? The current example is for an animal model but what if we  
> had both an animal effect and a sire effect and we want to fit two  
> pedigree relationship matrices instead of just one?
>
>
>
> Any help on that issue is more than appreciated.
>
>
>
> Thanks,
>
>
>
> Mak
>
>
>
> Makram J. Geha,PhD
> Quantitative Geneticist
> Dow AgroSciences, LLC.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From f.calboli at imperial.ac.uk  Tue Feb  7 21:36:59 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 7 Feb 2012 20:36:59 +0000
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
Message-ID: <9F025792-02C8-4280-9FCA-627D54FC5B9A@imperial.ac.uk>

On 7 Feb 2012, at 17:47, Douglas Bates wrote:
> 
> I forgot to mention an important point for Mac OS X users.  The new
> lme4, which is based on the Eigen linear algebra library, requires the
> RcppEigen package for which there is no binary Mac OS X package on
> CRAN.  It's a ridiculous situation that comes about because Apple
> ships an antique version of gcc in their XCode development
> environment, and won't upgrade because of licensing disagreements.
> Even that very old version of g++ compiles the package successfully
> for Intel Macs but it croaks when trying to cross-compile for the ppc
> architecture.  You can see at
> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-00install.html
> that the advice it to inform Apple of the compiler error but they
> ignore such reports.  Things may improve when XCode 4 is in use
> because it provides clang++ in addition to the same very old version
> of g++.  In the meantime we will provide a binary i386 Mac OS X
> package for RcppEigen.


Thank you for the hard work, it is very much appreciated. I use R 64-bit more than R 32-bit, but I guess all I have to do is to compile the package by hand (I'm on OS 10.7.3, and have Xcode 4.2.1, i.e. intel mac + clang), right? 

I never had any problems compiling packages where binaries were not available, I do not see how RccpEigen should give me more grief. 

Best wishes and, again, many thanks

F

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From Mike.Lawrence at dal.ca  Tue Feb  7 21:41:17 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 7 Feb 2012 16:41:17 -0400
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <9F025792-02C8-4280-9FCA-627D54FC5B9A@imperial.ac.uk>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
	<9F025792-02C8-4280-9FCA-627D54FC5B9A@imperial.ac.uk>
Message-ID: <CAB+QPJC6y1-pyX8cHtCByaW8Uy6cvu5aNAjmYc6YMAZLxj3pyQ@mail.gmail.com>

I can at least confirm that on my system (Mac OS 10.7.2, xcode 4.1, R
2.14.2), RcppEigen builds fine while running the following in the
64-bit GUI:

install.packages('RcppEigen',type='source',INSTALL_opts='--byte-compile')



On Tue, Feb 7, 2012 at 4:36 PM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> On 7 Feb 2012, at 17:47, Douglas Bates wrote:
>>
>> I forgot to mention an important point for Mac OS X users. ?The new
>> lme4, which is based on the Eigen linear algebra library, requires the
>> RcppEigen package for which there is no binary Mac OS X package on
>> CRAN. ?It's a ridiculous situation that comes about because Apple
>> ships an antique version of gcc in their XCode development
>> environment, and won't upgrade because of licensing disagreements.
>> Even that very old version of g++ compiles the package successfully
>> for Intel Macs but it croaks when trying to cross-compile for the ppc
>> architecture. ?You can see at
>> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-00install.html
>> that the advice it to inform Apple of the compiler error but they
>> ignore such reports. ?Things may improve when XCode 4 is in use
>> because it provides clang++ in addition to the same very old version
>> of g++. ?In the meantime we will provide a binary i386 Mac OS X
>> package for RcppEigen.
>
>
> Thank you for the hard work, it is very much appreciated. I use R 64-bit more than R 32-bit, but I guess all I have to do is to compile the package by hand (I'm on OS 10.7.3, and have Xcode 4.2.1, i.e. intel mac + clang), right?
>
> I never had any problems compiling packages where binaries were not available, I do not see how RccpEigen should give me more grief.
>
> Best wishes and, again, many thanks
>
> F
>
> --
> Federico C. F. Calboli
> Neuroepidemiology and Ageing Research
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602 ? Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From reinhold.kliegl at gmail.com  Tue Feb  7 21:48:08 2012
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 7 Feb 2012 21:48:08 +0100
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAB+QPJC6y1-pyX8cHtCByaW8Uy6cvu5aNAjmYc6YMAZLxj3pyQ@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
	<9F025792-02C8-4280-9FCA-627D54FC5B9A@imperial.ac.uk>
	<CAB+QPJC6y1-pyX8cHtCByaW8Uy6cvu5aNAjmYc6YMAZLxj3pyQ@mail.gmail.com>
Message-ID: <CAG+WrExwSrOW=oFGZTeTNwTm=uJ8KOqMzY6=GtgN8NiniLy4Rw@mail.gmail.com>

I confirm Mike's report with high appreciation for this line of code.
Thank you very much, Mike!
Reinhold Kliegl

On Tue, Feb 7, 2012 at 9:41 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> I can at least confirm that on my system (Mac OS 10.7.2, xcode 4.1, R
> 2.14.2), RcppEigen builds fine while running the following in the
> 64-bit GUI:
>
> install.packages('RcppEigen',type='source',INSTALL_opts='--byte-compile')
>
>
>
> On Tue, Feb 7, 2012 at 4:36 PM, Federico Calboli
> <f.calboli at imperial.ac.uk> wrote:
>> On 7 Feb 2012, at 17:47, Douglas Bates wrote:
>>>
>>> I forgot to mention an important point for Mac OS X users. ?The new
>>> lme4, which is based on the Eigen linear algebra library, requires the
>>> RcppEigen package for which there is no binary Mac OS X package on
>>> CRAN. ?It's a ridiculous situation that comes about because Apple
>>> ships an antique version of gcc in their XCode development
>>> environment, and won't upgrade because of licensing disagreements.
>>> Even that very old version of g++ compiles the package successfully
>>> for Intel Macs but it croaks when trying to cross-compile for the ppc
>>> architecture. ?You can see at
>>> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/RcppEigen-00install.html
>>> that the advice it to inform Apple of the compiler error but they
>>> ignore such reports. ?Things may improve when XCode 4 is in use
>>> because it provides clang++ in addition to the same very old version
>>> of g++. ?In the meantime we will provide a binary i386 Mac OS X
>>> package for RcppEigen.
>>
>>
>> Thank you for the hard work, it is very much appreciated. I use R 64-bit more than R 32-bit, but I guess all I have to do is to compile the package by hand (I'm on OS 10.7.3, and have Xcode 4.2.1, i.e. intel mac + clang), right?
>>
>> I never had any problems compiling packages where binaries were not available, I do not see how RccpEigen should give me more grief.
>>
>> Best wishes and, again, many thanks
>>
>> F
>>
>> --
>> Federico C. F. Calboli
>> Neuroepidemiology and Ageing Research
>> Imperial College, St. Mary's Campus
>> Norfolk Place, London W2 1PG
>>
>> Tel +44 (0)20 75941602 ? Fax +44 (0)20 75943193
>>
>> f.calboli [.a.t] imperial.ac.uk
>> f.calboli [.a.t] gmail.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ken.knoblauch at inserm.fr  Tue Feb  7 22:20:34 2012
From: ken.knoblauch at inserm.fr (ken knoblauch)
Date: Tue, 7 Feb 2012 21:20:34 +0000 (UTC)
Subject: [R-sig-ME] Upcoming changes in lme4
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
Message-ID: <loom.20120207T221646-279@post.gmane.org>

Douglas Bates <bates at ...> writes:

> 
> We (the lme4 authors) have mentioned on this list that we are
> preparing a new version of lme4 that will provide enhanced
> capabilities.  That's the good news.  The bad news is that the
> internal representation of the model has been changed yet again.  If
> your use of the lme4 package is through the exported functions only
> you should be okay.  However, if you find problems then please report
> them to us either in email <lme4-authors at ...> or on
> the bug-tracker at R-forge,
> 
>>>>> snip for gmane >>>>>>>>

> 
> An alpha-test release will be made available on the R-forge archive
> but *not* uploaded to CRAN.  If you use lme4 extensively please test
> this release by installing from the R-forge archive and telling us if
> there are problems with your code.  This way you can still back out to
> the current release by removing the lme4 package and reinstalling from
> CRAN.  Once the new lme4 has been released to CRAN it will be much
> more difficult to back out that installation.
> 
> Authors of packages that depend on lme4 will get a separate message
> off-list about testing and suggested modifications.
> 
> Thanks for your cooperation.  We do honestly believe that this change
> will provide an improved capability for fitting and analyzing
> mixed-effects models.
> 
I echo the thanks and congratulations of the other members of the list.

Will the link functions for glmer be built-in as currently with lme4 or
will it be possible to provide customized links in R code as currently
with lme4a?

best,

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From lborger at cebc.cnrs.fr  Tue Feb  7 22:40:47 2012
From: lborger at cebc.cnrs.fr (lborger)
Date: Tue, 07 Feb 2012 22:40:47 +0100
Subject: [R-sig-ME] nlme -95% CI of parameter estimates
In-Reply-To: <CAN8uQptfeq++wUU4H9dmL1k4E=gV+uNVB9+Hwro+QQbWo5+n1A@mail.gmail.com>
References: <CAN8uQptfeq++wUU4H9dmL1k4E=gV+uNVB9+Hwro+QQbWo5+n1A@mail.gmail.com>
Message-ID: <WC20120207214047.29010C@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120207/90c2e226/attachment-0002.pl>

From bates at stat.wisc.edu  Tue Feb  7 22:49:11 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Feb 2012 15:49:11 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <loom.20120207T221646-279@post.gmane.org>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<loom.20120207T221646-279@post.gmane.org>
Message-ID: <CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>

On Tue, Feb 7, 2012 at 3:20 PM, ken knoblauch <ken.knoblauch at inserm.fr> wrote:
> Douglas Bates <bates at ...> writes:
>
>>
>> We (the lme4 authors) have mentioned on this list that we are
>> preparing a new version of lme4 that will provide enhanced
>> capabilities. ?That's the good news. ?The bad news is that the
>> internal representation of the model has been changed yet again. ?If
>> your use of the lme4 package is through the exported functions only
>> you should be okay. ?However, if you find problems then please report
>> them to us either in email <lme4-authors at ...> or on
>> the bug-tracker at R-forge,
>>
>>>>>> snip for gmane >>>>>>>>
>
>>
>> An alpha-test release will be made available on the R-forge archive
>> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
>> this release by installing from the R-forge archive and telling us if
>> there are problems with your code. ?This way you can still back out to
>> the current release by removing the lme4 package and reinstalling from
>> CRAN. ?Once the new lme4 has been released to CRAN it will be much
>> more difficult to back out that installation.
>>
>> Authors of packages that depend on lme4 will get a separate message
>> off-list about testing and suggested modifications.
>>
>> Thanks for your cooperation. ?We do honestly believe that this change
>> will provide an improved capability for fitting and analyzing
>> mixed-effects models.
>>
> I echo the thanks and congratulations of the other members of the list.
>
> Will the link functions for glmer be built-in as currently with lme4 or
> will it be possible to provide customized links in R code as currently
> with lme4a?

Both.  Standard families (binomial, Gamma, gaussian, inverse.gaussian)
with typical links are evaluated in compiled code.  If the family is
not available in compiled code then callbacks to the R functions in
the family are used.

We are quite interested in collaborating with you to ensure that your
families in the psyphy package that allow asymptotes on binomial
probabilities can be used.



From ken.knoblauch at inserm.fr  Tue Feb  7 22:55:05 2012
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Tue, 07 Feb 2012 22:55:05 +0100
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<loom.20120207T221646-279@post.gmane.org>
	<CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>
Message-ID: <20120207225505.y4jq137x8gowkgo0@imp.inserm.fr>

Quoting Douglas Bates <bates at stat.wisc.edu>:

> On Tue, Feb 7, 2012 at 3:20 PM, ken knoblauch   
> <ken.knoblauch at inserm.fr> wrote:
>> Douglas Bates <bates at ...> writes:
>>
>>>
>>> We (the lme4 authors) have mentioned on this list that we are
>>> preparing a new version of lme4 that will provide enhanced
>>> capabilities. ?That's the good news. ?The bad news is that the
>>> internal representation of the model has been changed yet again. ?If
>>> your use of the lme4 package is through the exported functions only
>>> you should be okay. ?However, if you find problems then please report
>>> them to us either in email <lme4-authors at ...> or on
>>> the bug-tracker at R-forge,
>>>
>>>>>>> snip for gmane >>>>>>>>
>>
>>>
>>> An alpha-test release will be made available on the R-forge archive
>>> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
>>> this release by installing from the R-forge archive and telling us if
>>> there are problems with your code. ?This way you can still back out to
>>> the current release by removing the lme4 package and reinstalling from
>>> CRAN. ?Once the new lme4 has been released to CRAN it will be much
>>> more difficult to back out that installation.
>>>
>>> Authors of packages that depend on lme4 will get a separate message
>>> off-list about testing and suggested modifications.
>>>
>>> Thanks for your cooperation. ?We do honestly believe that this change
>>> will provide an improved capability for fitting and analyzing
>>> mixed-effects models.
>>>
>> I echo the thanks and congratulations of the other members of the list.
>>
>> Will the link functions for glmer be built-in as currently with lme4 or
>> will it be possible to provide customized links in R code as currently
>> with lme4a?
>
> Both.  Standard families (binomial, Gamma, gaussian, inverse.gaussian)
> with typical links are evaluated in compiled code.  If the family is
> not available in compiled code then callbacks to the R functions in
> the family are used.
>
> We are quite interested in collaborating with you to ensure that your
> families in the psyphy package that allow asymptotes on binomial
> probabilities can be used.
>

Great.  Thanks, again.  I'm looking forward to testing these.

best wishes,

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From bates at stat.wisc.edu  Tue Feb  7 22:55:29 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Feb 2012 15:55:29 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<loom.20120207T221646-279@post.gmane.org>
	<CAO7JsnRwxvH4OYGj_wcRmruOa4oqwr00U6BztbZb_HAc4KAjRg@mail.gmail.com>
Message-ID: <CAO7JsnQUwUFuisW+8Leqq5oV4bPETSvk01p5hWpos7E--yr-9w@mail.gmail.com>

On Tue, Feb 7, 2012 at 3:49 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Feb 7, 2012 at 3:20 PM, ken knoblauch <ken.knoblauch at inserm.fr> wrote:
>> Douglas Bates <bates at ...> writes:
>>
>>>
>>> We (the lme4 authors) have mentioned on this list that we are
>>> preparing a new version of lme4 that will provide enhanced
>>> capabilities. ?That's the good news. ?The bad news is that the
>>> internal representation of the model has been changed yet again. ?If
>>> your use of the lme4 package is through the exported functions only
>>> you should be okay. ?However, if you find problems then please report
>>> them to us either in email <lme4-authors at ...> or on
>>> the bug-tracker at R-forge,
>>>
>>>>>>> snip for gmane >>>>>>>>
>>
>>>
>>> An alpha-test release will be made available on the R-forge archive
>>> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
>>> this release by installing from the R-forge archive and telling us if
>>> there are problems with your code. ?This way you can still back out to
>>> the current release by removing the lme4 package and reinstalling from
>>> CRAN. ?Once the new lme4 has been released to CRAN it will be much
>>> more difficult to back out that installation.
>>>
>>> Authors of packages that depend on lme4 will get a separate message
>>> off-list about testing and suggested modifications.
>>>
>>> Thanks for your cooperation. ?We do honestly believe that this change
>>> will provide an improved capability for fitting and analyzing
>>> mixed-effects models.
>>>
>> I echo the thanks and congratulations of the other members of the list.
>>
>> Will the link functions for glmer be built-in as currently with lme4 or
>> will it be possible to provide customized links in R code as currently
>> with lme4a?
>
> Both. ?Standard families (binomial, Gamma, gaussian, inverse.gaussian)

I forgot poisson.  It is available in compiled code too.

> with typical links are evaluated in compiled code. ?If the family is
> not available in compiled code then callbacks to the R functions in
> the family are used.
>
> We are quite interested in collaborating with you to ensure that your
> families in the psyphy package that allow asymptotes on binomial
> probabilities can be used.



From bbolker at gmail.com  Wed Feb  8 00:29:38 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Feb 2012 23:29:38 +0000 (UTC)
Subject: [R-sig-ME] Upcoming changes in lme4
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<2359_1328636892_1328636892_CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A70846@crcmail4.BCCRC.CA>
Message-ID: <loom.20120208T002622-219@post.gmane.org>

Steven McKinney <smckinney at ...> writes:

> 
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at ... [mailto:r-sig-mixed-models-
> > bounces at ...] On Behalf Of Douglas Bates
> > Sent: February-07-12 9:48 AM
> > Subject: Re: [R-sig-ME] Upcoming changes in lme4
> > 
> > On Tue, Feb 7, 2012 at 11:11 AM, Douglas Bates <bates at ...> wrote:
> > > We (the lme4 authors) have mentioned on this list that we are
> > > preparing a new version of lme4 that will provide enhanced
> > > capabilities. ?That's the good news. ?
> 
> <snip>
> 
>   In the meantime we will provide a binary i386 Mac OS X
> > package for RcppEigen.
> 

> Would you be able to provide Intel binary i386 (32 bit) and 
> x86_64 (64 bit) builds in your Mac OS X package?
> 


Try out the versions posted now at 

  http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/2.14/

I believe they include both 32- and 64-bit versions.

  Let me know if not.

  Ben Bolker



From smckinney at bccrc.ca  Wed Feb  8 00:42:01 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 7 Feb 2012 15:42:01 -0800
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <26630_1328657413_1328657413_loom.20120208T002622-219@post.gmane.org>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<2359_1328636892_1328636892_CAO7JsnQy6q=+UdvqfmKnTMX_EQ4bYdrttzP_p-+8rY0hHgrRKA@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0892A70846@crcmail4.BCCRC.CA>
	<26630_1328657413_1328657413_loom.20120208T002622-219@post.gmane.org>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A70847@crcmail4.BCCRC.CA>


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: February-07-12 3:30 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Upcoming changes in lme4
> 
> Steven McKinney <smckinney at ...> writes:
> 
> >
> >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at ... [mailto:r-sig-mixed-models-
> > > bounces at ...] On Behalf Of Douglas Bates
> > > Sent: February-07-12 9:48 AM
> > > Subject: Re: [R-sig-ME] Upcoming changes in lme4
> > >
> > > On Tue, Feb 7, 2012 at 11:11 AM, Douglas Bates <bates at ...> wrote:
> > > > We (the lme4 authors) have mentioned on this list that we are
> > > > preparing a new version of lme4 that will provide enhanced
> > > > capabilities. ?That's the good news.
> >
> > <snip>
> >
> >   In the meantime we will provide a binary i386 Mac OS X
> > > package for RcppEigen.
> >
> 
> > Would you be able to provide Intel binary i386 (32 bit) and
> > x86_64 (64 bit) builds in your Mac OS X package?
> >
> 
> 
> Try out the versions posted now at
> 
>   http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/2.14/
> 
> I believe they include both 32- and 64-bit versions.

They do indeed, thank you very much.

Steve McKinney

> 
>   Let me know if not.
> 
>   Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From ovitek at stat.purdue.edu  Tue Feb  7 21:03:47 2012
From: ovitek at stat.purdue.edu (Olga Vitek)
Date: Tue, 7 Feb 2012 15:03:47 -0500
Subject: [R-sig-ME] Error when using models with lmer
Message-ID: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>

Hello, 

I am executing the following code

> library("lme4")
> library(faraway)
> data(penicillin)
> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)

and the lines below generate error messages

> library(gmodels)
> ci(fit4)
Error in as.vector(data) : 
 no method for coercing this S4 class to a vector

> contrast.function <- c(0, -1, 0, 0)
> test.result <- estimable(fit4, contrast.function)
Error in as.vector(data) : 
 no method for coercing this S4 class to a vector


This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.

Would you have suggestions on how to make this work?
Thank you in advance
Olga Vitek

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] gmodels_2.15.1   faraway_1.0.5    lme4_0.999375-42 Matrix_1.0-3     lattice_0.20-0  

loaded via a namespace (and not attached):
[1] gdata_2.8.2   grid_2.14.1   gtools_2.6.2  MASS_7.3-16   nlme_3.1-102  stats4_2.14.1 tools_2.14.1


From bates at stat.wisc.edu  Wed Feb  8 17:51:30 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Feb 2012 10:51:30 -0600
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
Message-ID: <CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>

On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
> Hello,
>
> I am executing the following code
>
>> library("lme4")
>> library(faraway)
>> data(penicillin)
>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>
> and the lines below generate error messages
>
>> library(gmodels)
>> ci(fit4)

Yes.  Why would you want to try to create a vector from an S4 fitted
model object?

It almost never makes sense to use

c(foo)

Most of the time when people use that idiom what they really mean is

foo

(I say "almost never" because in the old days many of us would use
c(myMatrix) to create a vector from a matrix.  The preferred form is
now as.vector(myMatrix).)

> Error in as.vector(data) :
> ?no method for coercing this S4 class to a vector
>
>> contrast.function <- c(0, -1, 0, 0)
>> test.result <- estimable(fit4, contrast.function)
> Error in as.vector(data) :

I assume that the "estimable" function is in the gmodels package, so
you should contact the author of that package about this.

> ?no method for coercing this S4 class to a vector
>
>
> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>
> Would you have suggestions on how to make this work?
> Thank you in advance
> Olga Vitek
>
>> sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>
> loaded via a namespace (and not attached):
> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From shsarafzade at gmail.com  Wed Feb  8 17:13:23 2012
From: shsarafzade at gmail.com (sheida sarafzade)
Date: Wed, 8 Feb 2012 20:43:23 +0430
Subject: [R-sig-ME] A question
Message-ID: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>

Hello
I'm MSc. student in biostatistics and working on mixed effect models
I?m trying to add fitted line to scatter plot (x,y)
Here ?weight? is dependent variable and ?month? is time variable.
The program is:
Lme1<-Lme(weight~month+(month^2),data=DataSetName,random=~month|id)

When I use the code below:
Lines(month[order(month)],fitted.lme(lme1,level=0)[order(month)])

It draws a smooth line but when I add a covariate (like birth weight)
to my model as below:

Lme2<-lme(weight~BirthWeight+month+(month^2),data=DataSetName,random=~month|id)

And then write the code below:
Lines(month[order(month)],fitted.lme(lme2,level=0)[order(month)])

It doesn?t draw smooth line. the line is not smooth.

How can I fix this problem?
What is the role of term ?level? in this code? And what are it?s option?

for more information please see attachment
Thanks a lot
-------------- next part --------------
A non-text attachment was scrubbed...
Name: question.pdf
Type: application/pdf
Size: 8814 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120208/1fd098e1/attachment-0002.pdf>

From istazahn at gmail.com  Wed Feb  8 19:51:34 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 8 Feb 2012 13:51:34 -0500
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
Message-ID: <CA+vqiLFyCcBriy009K8MRJEUwKGZGqqNZjbqPYz4Jzn0AJwPpw@mail.gmail.com>

Hi all,

Prof. Bates, I think you missed the "i" in "ci". It took me a while to
figure out, but I think the OP is trying to use ci.mer from the
gmodels package.

Olga, the proper course of action is to contact the gmodels maintainer
to alert them to this bug / incompatibility, as even the ci examples
do not run:

## Example from ci() documentation

fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
ci(fm2)
Error in as.vector(data) :
  no method for coercing this S4 class to a vector

Best,
Ista

On Wed, Feb 8, 2012 at 11:51 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>> Hello,
>>
>> I am executing the following code
>>
>>> library("lme4")
>>> library(faraway)
>>> data(penicillin)
>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>>
>> and the lines below generate error messages
>>
>>> library(gmodels)
>>> ci(fit4)
>
> Yes. ?Why would you want to try to create a vector from an S4 fitted
> model object?
>
> It almost never makes sense to use
>
> c(foo)
>
> Most of the time when people use that idiom what they really mean is
>
> foo
>
> (I say "almost never" because in the old days many of us would use
> c(myMatrix) to create a vector from a matrix. ?The preferred form is
> now as.vector(myMatrix).)
>
>> Error in as.vector(data) :
>> ?no method for coercing this S4 class to a vector
>>
>>> contrast.function <- c(0, -1, 0, 0)
>>> test.result <- estimable(fit4, contrast.function)
>> Error in as.vector(data) :
>
> I assume that the "estimable" function is in the gmodels package, so
> you should contact the author of that package about this.
>
>> ?no method for coercing this S4 class to a vector
>>
>>
>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>>
>> Would you have suggestions on how to make this work?
>> Thank you in advance
>> Olga Vitek
>>
>>> sessionInfo()
>> R version 2.14.1 (2011-12-22)
>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>>
>> loaded via a namespace (and not attached):
>> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Wed Feb  8 19:57:54 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Feb 2012 12:57:54 -0600
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <CA+vqiLFyCcBriy009K8MRJEUwKGZGqqNZjbqPYz4Jzn0AJwPpw@mail.gmail.com>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
	<CA+vqiLFyCcBriy009K8MRJEUwKGZGqqNZjbqPYz4Jzn0AJwPpw@mail.gmail.com>
Message-ID: <CAO7JsnTecTCKyDvUGqj+qxCNHX6uR7O++TjGD2KVeeegygVMUA@mail.gmail.com>

On Wed, Feb 8, 2012 at 12:51 PM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi all,
>
> Prof. Bates, I think you missed the "i" in "ci". It took me a while to
> figure out, but I think the OP is trying to use ci.mer from the
> gmodels package.

You're right.  My old eyes are failing me.  Soon I will be reduced to
sitting in a coffee shop with a bunch of other old guys complaining
about the government full time.

> Olga, the proper course of action is to contact the gmodels maintainer
> to alert them to this bug / incompatibility, as even the ci examples
> do not run:
>
> ## Example from ci() documentation
>
> fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
> ci(fm2)
> Error in as.vector(data) :
> ?no method for coercing this S4 class to a vector
>
> Best,
> Ista
>
> On Wed, Feb 8, 2012 at 11:51 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>>> Hello,
>>>
>>> I am executing the following code
>>>
>>>> library("lme4")
>>>> library(faraway)
>>>> data(penicillin)
>>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>>>
>>> and the lines below generate error messages
>>>
>>>> library(gmodels)
>>>> ci(fit4)
>>
>> Yes. ?Why would you want to try to create a vector from an S4 fitted
>> model object?
>>
>> It almost never makes sense to use
>>
>> c(foo)
>>
>> Most of the time when people use that idiom what they really mean is
>>
>> foo
>>
>> (I say "almost never" because in the old days many of us would use
>> c(myMatrix) to create a vector from a matrix. ?The preferred form is
>> now as.vector(myMatrix).)
>>
>>> Error in as.vector(data) :
>>> ?no method for coercing this S4 class to a vector
>>>
>>>> contrast.function <- c(0, -1, 0, 0)
>>>> test.result <- estimable(fit4, contrast.function)
>>> Error in as.vector(data) :
>>
>> I assume that the "estimable" function is in the gmodels package, so
>> you should contact the author of that package about this.
>>
>>> ?no method for coercing this S4 class to a vector
>>>
>>>
>>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>>>
>>> Would you have suggestions on how to make this work?
>>> Thank you in advance
>>> Olga Vitek
>>>
>>>> sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> other attached packages:
>>> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ovitek at stat.purdue.edu  Wed Feb  8 19:52:33 2012
From: ovitek at stat.purdue.edu (Olga Vitek)
Date: Wed, 8 Feb 2012 13:52:33 -0500
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
Message-ID: <FEAC9E5D-C93B-4DD9-8723-4DFC56D8E21E@stat.purdue.edu>

Dear Dr. Bates,

May I ask you for a clarification? The two problematic functions are indeed from the package gmodels

ci(fit4)                                         # 'ci' stands for confidence intervals of the fixed effects
estimable(fit4, c(0, -1, 0, 0))       # produces estimates of SE of the linear combination of the fixed effects

The difficulty is that there was no change in the version of gmodels before or after the problem occurred. The code worked with lme4_0.999375-40 and R2.13.1, but not with lme4_0.999375-42 and R2.14.1.

Could you kindly let me know if there were changes in the structure of the class 'mer' since lme4_0.999375-40? Alternatively, could you recommend other options for calculating standard errors of linear combinations of fixed effects?

Many thanks in advance
Olga Vitek





On Feb 8, 2012, at 11:51 AM, Douglas Bates wrote:

> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>> Hello,
>> 
>> I am executing the following code
>> 
>>> library("lme4")
>>> library(faraway)
>>> data(penicillin)
>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>> 
>> and the lines below generate error messages
>> 
>>> library(gmodels)
>>> ci(fit4)
> 
> Yes.  Why would you want to try to create a vector from an S4 fitted
> model object?
> 
> It almost never makes sense to use
> 
> c(foo)
> 
> Most of the time when people use that idiom what they really mean is
> 
> foo
> 
> (I say "almost never" because in the old days many of us would use
> c(myMatrix) to create a vector from a matrix.  The preferred form is
> now as.vector(myMatrix).)
> 
>> Error in as.vector(data) :
>>  no method for coercing this S4 class to a vector
>> 
>>> contrast.function <- c(0, -1, 0, 0)
>>> test.result <- estimable(fit4, contrast.function)
>> Error in as.vector(data) :
> 
> I assume that the "estimable" function is in the gmodels package, so
> you should contact the author of that package about this.
> 
>>  no method for coercing this S4 class to a vector
>> 
>> 
>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>> 
>> Would you have suggestions on how to make this work?
>> Thank you in advance
>> Olga Vitek
>> 
>>> sessionInfo()
>> R version 2.14.1 (2011-12-22)
>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] gmodels_2.15.1   faraway_1.0.5    lme4_0.999375-42 Matrix_1.0-3     lattice_0.20-0
>> 
>> loaded via a namespace (and not attached):
>> [1] gdata_2.8.2   grid_2.14.1   gtools_2.6.2  MASS_7.3-16   nlme_3.1-102  stats4_2.14.1 tools_2.14.1
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Tom_Philippi at nps.gov  Wed Feb  8 20:33:12 2012
From: Tom_Philippi at nps.gov (Tom_Philippi at nps.gov)
Date: Wed, 8 Feb 2012 11:33:12 -0800
Subject: [R-sig-ME] A question
In-Reply-To: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>
References: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>
Message-ID: <OF4E8FD4AE.151D7179-ON8525799E.005F158E-8825799E.006B696B@nps.gov>

Sheida--

What you are drawing with your call to lines() is a connect-the-dots graph,
where you have a number of points with different values for weight at each
discrete value of month.  The vertical bar at each month value is zigging
and zagging among all of your points at that value for month.  The lines
from one month to the next are simply connecting the last value at one
month to the first at the next month.  Why do you have so many points?  I
suspect because you have multiple population-level predictions for
different values of BirthWeight.

What value of BirthWeight do you want your line to represent?  Your graph
is only weight v month, but your second model is a response surface of
BirthWeight and month+month^2.  Do you have perfectly balanced data (same
set of months for each subject)?  Do you want to show a line of the
predictions for only the mean value of BirthWeight?  For perhaps quantiles
of the BirthWeight distribution?  For each individual value of BirthWeight
(which may or may not be each individual subject id)?

If you want to see what is going on, break apart your call to lines() by
making the fitted result a separate object:
Yfit <- fitted.lme(lme2,level=0)[order(month)]
head(Yfit)
nrow(Yfit)# probably 9 in your model without BirthWeight much larger in
model with BirthWeight
Lines(month[order(month)],Yfit[order(month)])


?fitted.lme explains the level= parameter: level=0 extracted
population-level fitted values, in your case I believe that level=1 would
give subject-level (id) fitted values (you can perform the experiment with
level=c(0:1) as in the example).

I hope that this helps steer you in the right direction.

Tom 2

ps: also, see:
fortunes::fortune(285)
about selecting a subject line more likely to attract responses from the
real gurus (not me) on this list.

-------------------------------------------
Tom Philippi, Ph.D.
Quantitative Ecologist
Inventory and Monitoring Program
National Park Service
c/o Cabrillo National Monument
1800 Cabrillo Memorial Dr
San Diego, CA 92106
(619) 523-4576
Tom_philippi at NPS.gov
http://science.nature.nps.gov/im/monitor
-------------------------------------------



                                                                           
             sheida sarafzade                                              
             <shsarafzade at gmai                                             
             l.com>                                                     To 
             Sent by:                  r-sig-mixed-models at r-project.org    
             r-sig-mixed-model                                          cc 
             s-bounces at r-proje         shsarafzade <shsarafzade at gmail.com> 
             ct.org                                                Subject 
                                       [R-sig-ME] A question               
                                                                           
             02/08/2012 08:43                                              
             PM ZE4B                                                       
                                                                           
                                                                           
                                                                           




Hello
I'm MSc. student in biostatistics and working on mixed effect models
I?m trying to add fitted line to scatter plot (x,y)
Here ?weight? is dependent variable and ?month? is time variable.
The program is:
Lme1<-Lme(weight~month+(month^2),data=DataSetName,random=~month|id)

When I use the code below:
Lines(month[order(month)],fitted.lme(lme1,level=0)[order(month)])

It draws a smooth line but when I add a covariate (like birth weight)
to my model as below:

Lme2<-lme(weight~BirthWeight+month+(month^2),data=DataSetName,random=~month|id)


And then write the code below:
Lines(month[order(month)],fitted.lme(lme2,level=0)[order(month)])

It doesn?t draw smooth line. the line is not smooth.

How can I fix this problem?
What is the role of term ?level? in this code? And what are it?s option?

for more information please see attachment
Thanks a lot
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bates at stat.wisc.edu  Wed Feb  8 21:11:19 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Feb 2012 14:11:19 -0600
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <FEAC9E5D-C93B-4DD9-8723-4DFC56D8E21E@stat.purdue.edu>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
	<FEAC9E5D-C93B-4DD9-8723-4DFC56D8E21E@stat.purdue.edu>
Message-ID: <CAO7JsnThLz-Vp29ybByGG+Jii2Bw9KLPF=txQQeTSMD0_iK6VQ@mail.gmail.com>

On Wed, Feb 8, 2012 at 12:52 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
> Dear Dr. Bates,
>
> May I ask you for a clarification? The two problematic functions are indeed from the package gmodels
>
> ci(fit4) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # 'ci' stands for confidence intervals of the fixed effects
> estimable(fit4, c(0, -1, 0, 0)) ? ? ? # produces estimates of SE of the linear combination of the fixed effects
>
> The difficulty is that there was no change in the version of gmodels before or after the problem occurred. The code worked with lme4_0.999375-40 and R2.13.1, but not with lme4_0.999375-42 and R2.14.1.

You need to go through some hidden functions to find out where the
problem lies.  Eventually it boils down to a hidden function called
gmodels:::est.mer which calls mcmcsamp and that function is no longer
available.

> Could you kindly let me know if there were changes in the structure of the class 'mer' since lme4_0.999375-40? Alternatively, could you recommend other options for calculating standard errors of linear combinations of fixed effects?
>
> Many thanks in advance
> Olga Vitek
>
>
>
>
>
> On Feb 8, 2012, at 11:51 AM, Douglas Bates wrote:
>
>> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>>> Hello,
>>>
>>> I am executing the following code
>>>
>>>> library("lme4")
>>>> library(faraway)
>>>> data(penicillin)
>>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>>>
>>> and the lines below generate error messages
>>>
>>>> library(gmodels)
>>>> ci(fit4)
>>
>> Yes. ?Why would you want to try to create a vector from an S4 fitted
>> model object?
>>
>> It almost never makes sense to use
>>
>> c(foo)
>>
>> Most of the time when people use that idiom what they really mean is
>>
>> foo
>>
>> (I say "almost never" because in the old days many of us would use
>> c(myMatrix) to create a vector from a matrix. ?The preferred form is
>> now as.vector(myMatrix).)
>>
>>> Error in as.vector(data) :
>>> ?no method for coercing this S4 class to a vector
>>>
>>>> contrast.function <- c(0, -1, 0, 0)
>>>> test.result <- estimable(fit4, contrast.function)
>>> Error in as.vector(data) :
>>
>> I assume that the "estimable" function is in the gmodels package, so
>> you should contact the author of that package about this.
>>
>>> ?no method for coercing this S4 class to a vector
>>>
>>>
>>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>>>
>>> Would you have suggestions on how to make this work?
>>> Thank you in advance
>>> Olga Vitek
>>>
>>>> sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> other attached packages:
>>> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Feb  8 23:37:02 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Feb 2012 16:37:02 -0600
Subject: [R-sig-ME] Error when using models with lmer
In-Reply-To: <CAO7JsnThLz-Vp29ybByGG+Jii2Bw9KLPF=txQQeTSMD0_iK6VQ@mail.gmail.com>
References: <0D8B5FC0-A925-4D4A-A64E-B87E10AB8098@stat.purdue.edu>
	<CAO7JsnRoAtin6i395YhFRGgm_z21-WMhPXb9F=4PGyGcV6450Q@mail.gmail.com>
	<FEAC9E5D-C93B-4DD9-8723-4DFC56D8E21E@stat.purdue.edu>
	<CAO7JsnThLz-Vp29ybByGG+Jii2Bw9KLPF=txQQeTSMD0_iK6VQ@mail.gmail.com>
Message-ID: <CAO7JsnTMWeaqAm63fZY=hQihRKVUt0kEKPXdL_jEqT3eFtp=tw@mail.gmail.com>

On Wed, Feb 8, 2012 at 2:11 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Feb 8, 2012 at 12:52 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>> Dear Dr. Bates,
>>
>> May I ask you for a clarification? The two problematic functions are indeed from the package gmodels
>>
>> ci(fit4) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # 'ci' stands for confidence intervals of the fixed effects
>> estimable(fit4, c(0, -1, 0, 0)) ? ? ? # produces estimates of SE of the linear combination of the fixed effects
>>
>> The difficulty is that there was no change in the version of gmodels before or after the problem occurred. The code worked with lme4_0.999375-40 and R2.13.1, but not with lme4_0.999375-42 and R2.14.1.
>
> You need to go through some hidden functions to find out where the
> problem lies. ?Eventually it boils down to a hidden function called
> gmodels:::est.mer which calls mcmcsamp and that function is no longer
> available.

Again, I misspoke.  It's just not my day.  The mcmcsamp function is
still available in the released version of lme4.  Actually the code in
gmodels is trying to convert the merMCMC object to a matrix and
somehow isn't seeing the necessary method for as.matrix.  It will have
to do with namespaces and the best way to solve that would be in the
NAMESPACE file for the gmodels package.

>> Could you kindly let me know if there were changes in the structure of the class 'mer' since lme4_0.999375-40? Alternatively, could you recommend other options for calculating standard errors of linear combinations of fixed effects?
>>
>> Many thanks in advance
>> Olga Vitek
>>
>>
>>
>>
>>
>> On Feb 8, 2012, at 11:51 AM, Douglas Bates wrote:
>>
>>> On Tue, Feb 7, 2012 at 2:03 PM, Olga Vitek <ovitek at stat.purdue.edu> wrote:
>>>> Hello,
>>>>
>>>> I am executing the following code
>>>>
>>>>> library("lme4")
>>>>> library(faraway)
>>>>> data(penicillin)
>>>>> fit4 <- lmer(yield ~ treat + (1|blend), penicillin)
>>>>
>>>> and the lines below generate error messages
>>>>
>>>>> library(gmodels)
>>>>> ci(fit4)
>>>
>>> Yes. ?Why would you want to try to create a vector from an S4 fitted
>>> model object?
>>>
>>> It almost never makes sense to use
>>>
>>> c(foo)
>>>
>>> Most of the time when people use that idiom what they really mean is
>>>
>>> foo
>>>
>>> (I say "almost never" because in the old days many of us would use
>>> c(myMatrix) to create a vector from a matrix. ?The preferred form is
>>> now as.vector(myMatrix).)
>>>
>>>> Error in as.vector(data) :
>>>> ?no method for coercing this S4 class to a vector
>>>>
>>>>> contrast.function <- c(0, -1, 0, 0)
>>>>> test.result <- estimable(fit4, contrast.function)
>>>> Error in as.vector(data) :
>>>
>>> I assume that the "estimable" function is in the gmodels package, so
>>> you should contact the author of that package about this.
>>>
>>>> ?no method for coercing this S4 class to a vector
>>>>
>>>>
>>>> This worked with with lme4_0.999375-40 and R version 2.13.1, but not with lme4_0.999375-42 and R version 2.14.1.
>>>>
>>>> Would you have suggestions on how to make this work?
>>>> Thank you in advance
>>>> Olga Vitek
>>>>
>>>>> sessionInfo()
>>>> R version 2.14.1 (2011-12-22)
>>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>>
>>>> locale:
>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>>
>>>> other attached packages:
>>>> [1] gmodels_2.15.1 ? faraway_1.0.5 ? ?lme4_0.999375-42 Matrix_1.0-3 ? ? lattice_0.20-0
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] gdata_2.8.2 ? grid_2.14.1 ? gtools_2.6.2 ?MASS_7.3-16 ? nlme_3.1-102 ?stats4_2.14.1 tools_2.14.1
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From jwiley.psych at gmail.com  Thu Feb  9 01:32:25 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 8 Feb 2012 16:32:25 -0800
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
Message-ID: <CANz9Z_LPMXFT9me6CSZ7hXdbUnjWHcXoFEkxyaseUZdsZ933xg@mail.gmail.com>

Thanks to the authors for fantastic work.

Once the new version is pushed to CRAN, does anyone know if it will be
called lme4Eigen or the familiar lme4?

Josh

On Tue, Feb 7, 2012 at 9:11 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> We (the lme4 authors) have mentioned on this list that we are
> preparing a new version of lme4 that will provide enhanced
> capabilities. ?That's the good news. ?The bad news is that the
> internal representation of the model has been changed yet again. ?If
> your use of the lme4 package is through the exported functions only
> you should be okay. ?However, if you find problems then please report
> them to us either in email <lme4-authors at r-forge.wu-wien.ac.at> or on
> the bug-tracker at R-forge,
>
> https://r-forge.r-project.org/tracker/?func=add&group_id=60&atid=298
>
> One major, and unfortunately inevitable, problem that will affect many
> users is the inability of the new code to load saved objects created
> with the old code. ?Unfortunately that is what happens when you change
> the class representation. ?If possible it is best to save the code and
> data that generated the fitted model and re-fit after the change.
>
> If your usage involved access to components or slots in the object
> then there will be changes. ?To ease the transition, Martin created a
> function called getME that is available in the current lme4 and in the
> new lme4, available as lme4Eigen on R-forge. ?This function takes a
> fitted model and a character variable naming a component and returns
> the desired component. ?For example, if you want the fixed-effects
> model matrix from fitted model fm1 then use
>
> getME(fm1, "X")
>
> Similarly for the random-effects model matrix, "Z", or its transpose,
> "Zt", the sparse Cholesky factor, "L" and many others. ?Use
>
> library(lme4)
> example(getME)
>
> to get some examples.
>
> The new lme4 will provide
>
> ?- profiling of the deviance function with respect to the parameters
> ? in a linear mixed model (and soon generalized linear mixed models).
> ? The profiles allow for creation of realistic confidence intervals
> ? on the parameters and for various plots that show the sensitivity
> ? of the deviance to the values of the parameters.
>
> ?- a more reliable and flexible implementation of generalized linear
> ? mixed models, including the use of adaptive Gauss-Hermite
> ? quadrature for evaluating an approximation to the deviance.
>
> ?- short-cut functions such as refitML and refit to re-evaluate a
> ? model under the maximum likelihood criterion or with a new response
> ? vector.
>
> ?- a cleaner internal representations that provides, in most cases,
> ? faster and more reliable model fits.
>
> ?- choice of optimizer when estimating the parameters. ?Current
> ? choices are "NelderMead" and "bobyqa". ?Both are generally faster
> ? and more reliable than the optimizer used in the current lme4,
> ? which is based on the code in R's nlminb() function, the one that
> ? gives those annoying "false convergence" messages.
>
> ?- smaller memory footprint. ?The need for copying large objects is
> ? reduced through the use of reference classes in R. ?In the past
> ? there were circumstances where it was possible to fit a model to a
> ? large data set but not to print or show the results because a new
> ? copy of the entire object was created during the process of
> ? creating a summary. ?This no longer occurs.
>
> ?- nlmer has been improved and will, by the time of release, allow
> ? adaptive Gauss-Hermite quadrature.
>
> An alpha-test release will be made available on the R-forge archive
> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
> this release by installing from the R-forge archive and telling us if
> there are problems with your code. ?This way you can still back out to
> the current release by removing the lme4 package and reinstalling from
> CRAN. ?Once the new lme4 has been released to CRAN it will be much
> more difficult to back out that installation.
>
> Authors of packages that depend on lme4 will get a separate message
> off-list about testing and suggested modifications.
>
> Thanks for your cooperation. ?We do honestly believe that this change
> will provide an improved capability for fitting and analyzing
> mixed-effects models.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From acdelre at stanford.edu  Thu Feb  9 02:28:02 2012
From: acdelre at stanford.edu (AC Del Re)
Date: Wed, 8 Feb 2012 17:28:02 -0800
Subject: [R-sig-ME] LMM with Big data using binary DV
Message-ID: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120208/1b8ef48a/attachment-0002.pl>

From jwiley.psych at gmail.com  Thu Feb  9 03:28:13 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 8 Feb 2012 18:28:13 -0800
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
References: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
Message-ID: <CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>

Hi AC,

My personal preference would be glmer from the lme4 package.  I prefer
the Laplace approximation for the likelihood over the quasilikelihood
in glmmPQL.  To give some exemplary numbers, I simulated a dataset
with 2 million observations nested within 200 groups (10,000
observations per group).  I then ran an random intercepts model using:

system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))

where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
million, 6]; W = [2 million, 3]; G = [2 million, 1]

This took around 481 seconds to fit on a 1.6ghz dual core laptop.
With the OS and R running, my system used ~ 6GB of RAM for the model
and went up to ~7GB to show the summary (copies of the data are
made---changed in the upcoming version of lme4).

So as long as you have plenty of memory, you should have no trouble
modelling your data using glmer().  To initially make sure all your
code works, I might use a subset of your data (say 10k), once you are
convinced you have the model you want, run it on the full data.

Cheers,

Josh

On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
> Hi,
>
> I have a huge dataset (2.5 million patients nested within ?> 100
> facilities) and would like to examine variability across facilities in
> program utilization (0=n, 1=y; utilization rates are low in general), along
> with patient and facility predictors of utilization.
>
> I have 3 questions:
>
> 1. What program and/or package(s) do you recommend for running LMMs with
> big data (even if they are not R packages)?
>
> 2. Are there any clever work arounds (e.g., random sampling of subset of
> data, etc) that would allow me to use only R packages to run this dataset
> (assuming I need to use another program due to the size of the dataset)?
>
> 3. What type of LMM is recommended with a binary DV similar to the one I am
> wanting to examine? I know of two potential options (family=binomial option
> in lmer and the glmmPQL in the MASS package) but am not sure which is more
> appropriate or what other R packages and functions are available for this
> purpose?
>
> Thank you,
>
> AC
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From m.fenati at libero.it  Thu Feb  9 11:25:30 2012
From: m.fenati at libero.it (m.fenati at libero.it)
Date: Thu, 9 Feb 2012 11:25:30 +0100 (CET)
Subject: [R-sig-ME] ghlt different results for different hypotheses?
Message-ID: <5725262.8850411328783130878.JavaMail.defaultUser@defaultHost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/1233e3d4/attachment-0002.pl>

From raquel.benavides at mncn.csic.es  Thu Feb  9 12:01:21 2012
From: raquel.benavides at mncn.csic.es (Raquel Benavides)
Date: Thu, 9 Feb 2012 12:01:21 +0100
Subject: [R-sig-ME] hurdle model with glmmadmb
Message-ID: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/ff8e7127/attachment-0002.pl>

From j.hadfield at ed.ac.uk  Thu Feb  9 12:17:19 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 09 Feb 2012 11:17:19 +0000
Subject: [R-sig-ME] hurdle model with glmmadmb
In-Reply-To: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>
References: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>
Message-ID: <20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>

Hi,

missing bracket after parcela2?

Jarrod

Quoting Raquel Benavides <raquel.benavides at mncn.csic.es> on Thu, 9 Feb  
2012 12:01:21 +0100:

> Dear all,
>
>
>
> I am trying to run glmmADMB to check the effect of some fixed effects over
> the number of seedlings in some plots (my random factors are
> site/transect/plot). In particular, I want to run a hurdle model. I have
> tried to follow the instructions given in athe document uploaded in the
> webpage http://glmmadmb.r-forge.r-project.org/. However I have some errors,
> and I don?t really understand what do they mean. Does anybody understand
> what it means and how to avoid it?
>
>
>
>>
> seed_hurdle1<-glmmadmb(seedling~I(Tanual^2)+(1|site/transecto/parcela2,data=
> subset(datos,seedling>0),family="truncnbinom1")
>
>
>
> Error en glmmadmb(seedling ~ I(Tanual^2) + (1 | name/transecto/parcela),  :
>
>   The function maximizer failed (couldn't find STD file)
>
> Adem?s: Mensajes de aviso perdidos
>
> 1: In glmmadmb(seedling ~ I(Tanual2^2) + (1 | name/transecto/parcela),  :
>
>   zero response values in truncated family
>
> 2: comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c "C:/Archivos de
> programa/R/R-2.14.0/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500
> -maxph 5 -noinit -shess' tiene estatus 1
>
>
>
> Thanks
>
> Raquel
>
>
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From raquel.benavides at mncn.csic.es  Thu Feb  9 14:43:11 2012
From: raquel.benavides at mncn.csic.es (Raquel Benavides)
Date: Thu, 9 Feb 2012 14:43:11 +0100
Subject: [R-sig-ME] hurdle model with glmmadmb
In-Reply-To: <20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>
References: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>
	<20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>
Message-ID: <006101cce730$c3a7c3e0$4af74ba0$@mncn.csic.es>

I am afraid it isnt the problema, the bracket was missed during the copy process in the mail...Any other idea?

-----Mensaje original-----
De: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] 
Enviado el: jueves, 09 de febrero de 2012 12:17
Para: Raquel Benavides
CC: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] hurdle model with glmmadmb

Hi,

missing bracket after parcela2?

Jarrod

Quoting Raquel Benavides <raquel.benavides at mncn.csic.es> on Thu, 9 Feb
2012 12:01:21 +0100:

> Dear all,
>
>
>
> I am trying to run glmmADMB to check the effect of some fixed effects 
> over the number of seedlings in some plots (my random factors are 
> site/transect/plot). In particular, I want to run a hurdle model. I 
> have tried to follow the instructions given in athe document uploaded 
> in the webpage http://glmmadmb.r-forge.r-project.org/. However I have 
> some errors, and I don?t really understand what do they mean. Does 
> anybody understand what it means and how to avoid it?
>
>
>
>>
> seed_hurdle1<-glmmadmb(seedling~I(Tanual^2)+(1|site/transecto/parcela2
> ,data=
> subset(datos,seedling>0),family="truncnbinom1")
>
>
>
> Error en glmmadmb(seedling ~ I(Tanual^2) + (1 | name/transecto/parcela),  :
>
>   The function maximizer failed (couldn't find STD file)
>
> Adem?s: Mensajes de aviso perdidos
>
> 1: In glmmadmb(seedling ~ I(Tanual2^2) + (1 | name/transecto/parcela),  :
>
>   zero response values in truncated family
>
> 2: comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c "C:/Archivos de 
> programa/R/R-2.14.0/library/glmmADMB/bin/windows32/glmmadmb.exe" 
> -maxfn 500 -maxph 5 -noinit -shess' tiene estatus 1
>
>
>
> Thanks
>
> Raquel
>
>
> 	[[alternative HTML version deleted]]
>
>



--
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336.



From bbolker at gmail.com  Thu Feb  9 14:58:45 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 9 Feb 2012 13:58:45 +0000 (UTC)
Subject: [R-sig-ME] hurdle model with glmmadmb
References: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>
	<20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>
	<006101cce730$c3a7c3e0$4af74ba0$@mncn.csic.es>
Message-ID: <loom.20120209T145214-367@post.gmane.org>

Raquel Benavides <raquel.benavides at ...> writes:

> 
> I am afraid it isnt the problema, the bracket was missed during the copy
process in the mail...Any other idea?
> 
> -----Mensaje original-----
> De: Jarrod Hadfield [mailto:j.hadfield <at> ed.ac.uk] 
> 
> Hi,
> 
> missing bracket after parcela2?
> 
> Jarrod
> 
> Quoting Raquel Benavides <raquel.benavides <at> mncn.csic.es> on Thu, 9 Feb
> 2012 12:01:21 +0100:
> 
> > Dear all,
> >
> >
> >
> > I am trying to run glmmADMB to check the effect of some fixed effects 
> > over the number of seedlings in some plots (my random factors are 
> > site/transect/plot). In particular, I want to run a hurdle model. I 
> > have tried to follow the instructions given in athe document uploaded 
> > in the webpage http://glmmadmb.r-forge.r-project.org/. However I have 
> > some errors, and I don?t really understand what do they mean. Does 
> > anybody understand what it means and how to avoid it?
>
> > seed_hurdle1<-glmmadmb(seedling~I(Tanual^2)+(1|site/transecto/parcela2
> > ,data=
> > subset(datos,seedling>0),family="truncnbinom1")
> 
> > Error en glmmadmb(seedling ~ I(Tanual^2) + (1 | name/transecto/parcela),  :
> >
> >   The function maximizer failed (couldn't find STD file)
> >
> > Adem?s: Mensajes de aviso perdidos
> >
> > 1: In glmmadmb(seedling ~ I(Tanual2^2) + (1 | name/transecto/parcela),  :
> >
> >   zero response values in truncated family
> >
> > 2: comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c "C:/Archivos de 
> > programa/R/R-2.14.0/library/glmmADMB/bin/windows32/glmmadmb.exe" 
> > -maxfn 500 -maxph 5 -noinit -shess' tiene estatus 1

  Hmm.  It's surprising that you get the warning about zero response
values when you are explicitly using subset(datos, seedling>0).  Do you
by any chance have another copy of "seedling" lying around your
workspace, or have you attach()ed some data frames?  (This should
*not* break things, but it might anyway ...)

  You can try setting verbose=TRUE, although it will give you
loads of output where probably only the very end will be useful ...

  Are you willing to send me data?

  Ben Bolker



From andre.frainer at emg.umu.se  Thu Feb  9 17:33:14 2012
From: andre.frainer at emg.umu.se (=?Windows-1252?Q?Andr=E9_Barbosa?=)
Date: Thu, 9 Feb 2012 17:33:14 +0100
Subject: [R-sig-ME] random intercept and random slope
Message-ID: <5F7C032D-1E9E-453E-8898-4E059B8F8396@emg.umu.se>

Dear list members,
I have read several threads on this list about the use of random variables and its interpretation. I seem to have learned a lot about model fitting, from plotting the raw data and checking the slopes and intercepts, to getting rid of the p-value mindset in which I had had my basic statistics courses at university.
However, since my statistical courses never covered Mixed Effect Models, I am still unsure if I am doing the right thing or not. Having said that, would you please take a look at the following data and see if my rational is correct? The model is quite simple, I believe.
I have 8 different plant species, which were mixed two-by-two in all possible combinations. So, each species has 7 pairs + it being alone (monoculture). My response variable is a ratio (observed /expected productivity values, where observed is the productivity of species ?a? achieved when mixed with another species, and expected is its value when in monoculture).
Each species had its own nutrient content analyzed. As I had three nutrient variables measured from each plant, I calculated indices of dissimilarity for each of those pairs.
My starting model (without specifying random or fixed effects) would be:
ratio ~ dissimilarity | species
I expected, based on previous studies, that the relationship between ratio and dissimilarity would yield different slopes for each species, from negative to positive ? expectation confirmed by potting a xyplot function of my data. Thus, species should be random. Looking at the xyplot of my data, I also see that the intercepts are somehow variable, ranging between 0.5 and 1.5 (response data points do not extend much further from this range, either). For this reason, I thought on including intercepts as random, as well, which leave me without fixed variables.
So, I decided to test:
lmer(ratio ~ 1 + (dissimilarity|species))
Here follows a subset of my data:
species            pair            ratio            dissimilarity
a            a+b            1.090935            1.870297012
a            a+c            1.182509            0.691033781
a            a+d            1.505538            1.441237522
a            a+e            1.547295            0.953060747
a            a+f            1.463782            1.306913498
a            a+g            1.197587            1.331087471
a            a+h            1.113263            1.097840225
b            b+a            0.899969            1.870297012
b            b+c            1.102478            1.548604304
b            b+d            1.218110            1.669409077
b            b+e            1.095748            1.536191709
b            b+f            1.306822            1.579788658
b            b+g            1.299480            1.084382658
b            b+h            1.219945            1.137927922
c            c+a            1.092199            1.441237522
c            c+b            1.486702            1.669409077
c            c+d            0.847517            1.688612802
c            c+e            0.210150            0.651183878
c            c+f            1.459219            1.064428069
c            c+g            0.87810            0.590191888
c            c+h            0.91223            1.37455314
d            d+a            1.32486            0.953060747
d            d+b            1.37737            1.536191709
d            d+c            1.23869            1.310607287
d            d+e            1.15714            0.651183878
d            d+f            0.97390            1.22540051
d            d+g            0.92355            0.640371057
d            d+h            0.79097            1.224534999

The output from my model, using the whole data set is:
> summary(random.model)
Linear mixed model fit by REML
Formula: ratio~ 1 + (dissimilarity | species)
   Data: k
   AIC   BIC  logLik deviance REMLdev
 11.29 21.42 -0.6465   -3.273   1.293
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 species  (Intercept) 0.092206 0.30365
          dissimilarity        0.030348 0.17421  -1.000
 Residual             0.048348 0.21988
Number of obs: 56, groups: species, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.18024    0.04087   28.88

----

My questions:

1. Is my approach correct in plotting the independent variable ?dissimilarity? as random intercept, as in ~ 1 + (dissimilarity|species)?
2. On a publication, can I report the variance component of the random terms (in percentage) as the main result of the test?
3. Would it be possible to run McMC on a model that does not have Fixed Effects?
4. Would there be any other metrics that I should report as well?

I am sure that my questions are pretty basic, but I would strongly appreciate any input from you. Thank you!
Andre



From bates at stat.wisc.edu  Thu Feb  9 17:45:56 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 10:45:56 -0600
Subject: [R-sig-ME] Extracting means and SEs from an lmer object
In-Reply-To: <CAKFxdiThkd41kym8Ae9VzZFjetAhOU=o79=S1gzcZrM8PaT5Rg@mail.gmail.com>
References: <82BD0622-B375-4134-9F5C-467E4D647DBC@queensu.ca>
	<CAO7JsnTRCgruYbX4ux1iRRkWOhkxkdiwWyX1Rgjmok3kyKBm7A@mail.gmail.com>
	<CAKFxdiThkd41kym8Ae9VzZFjetAhOU=o79=S1gzcZrM8PaT5Rg@mail.gmail.com>
Message-ID: <CAO7JsnRaKO8Gwjd-O6jnF9oYzvZh4pvBXEfBbwkN-_ht1yVO6w@mail.gmail.com>

On Mon, Feb 6, 2012 at 5:29 PM, Kevin Wright <kw.stat at gmail.com> wrote:
> Doug,

> Relating to your comment below, there are getting to be quite a few R
> packages that fit mixed models in various forms.

> I have found myself often wishing that there was a generic 'fixef' and
> 'ranef' in the 'stats' package (similar to 'coef') to make it easier to work
> with different methods for these extractors.? The different class systems
> (S3, S4), different packages, and ever-changing R core (e.g. mandatory
> namespaces) have forced me to write and re-write multiple times the methods
> for fixef and ranef to support different packages.

> Any thoughts on this?

In lme4Eigen S3 methods are used even for S4 classes when method
dispatch is on the first argument only, which is the case for most
standard generics.  This avoids the problem of reconciling S4 generics
and S3 generics, which can get very complicated if more than one
package defines an S4 generic from the same S3 generic.  The majority
of the S3 generics are in the stats package, which is fine because the
stats package is usually attached.  As the nlme package is a
recommended package, it is assumed to be available but not always
loaded or attached.  I have opted for importing the S3 generics for
"fixef" and "ranef" and "VarCorr" from the nlme package but not
depending on the nlme package, which makes life too complicated.  The
generic is imported then exported and the method is declared in the
NAMESPACE file.  In other words, the NAMESPACE file has

importFrom(nlme, fixef)
export(fixef)
S3method(fixef,merMod)

and the same for ranef and VarCorr.  Right now that is the way that I
would recommend other package authors to handle the situation.  I'm
not sure if loading two such packages will give complaints about
masking the names - it may.

Eventually it might be best to move these generics to the stats
package.  Due to my own error I cannot currently change either the
stats package or the nlme package so I will need to wait for Martin to
return from vacation before making any changes.



>> The problem may be due to MEMSS bringing in other packages that mask
>> the definition of fixef in lme4. ?It works for me (see enclosed) if I
>> use
>> data(Orthodont, package="MEMSS")
>> instead.
>
>



From acdelre at stanford.edu  Thu Feb  9 17:48:15 2012
From: acdelre at stanford.edu (AC Del Re)
Date: Thu, 9 Feb 2012 08:48:15 -0800
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
References: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
	<CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
Message-ID: <CALsYQZe_Y0f0O8tq_P9EaxuE87ne6kAvHr=K33wMOZ8D0FbYJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/8310f852/attachment-0002.pl>

From ahmatias at gmail.com  Thu Feb  9 18:08:59 2012
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Thu, 9 Feb 2012 18:08:59 +0100
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
	convergence (7)"
Message-ID: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/2895ab26/attachment-0002.pl>

From bates at stat.wisc.edu  Thu Feb  9 18:16:47 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 11:16:47 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CANz9Z_LPMXFT9me6CSZ7hXdbUnjWHcXoFEkxyaseUZdsZ933xg@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CANz9Z_LPMXFT9me6CSZ7hXdbUnjWHcXoFEkxyaseUZdsZ933xg@mail.gmail.com>
Message-ID: <CAO7JsnRZGz2z2bCdKa6jaMGjZea=+ZdUgbzma1aJ0VmQ1BrgCA@mail.gmail.com>

On Wed, Feb 8, 2012 at 6:32 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Thanks to the authors for fantastic work.
>
> Once the new version is pushed to CRAN, does anyone know if it will be
> called lme4Eigen or the familiar lme4?

Current plan is that the new version will still be called lme4 but we
will also release to CRAN a package lme4preEigen as a bacikup for
users whose code gets broken by the new version.  At present Martin is
on vacation and the plan has not been confirmed by him (and he knows
more about the packaging system and CRAN than Ben or I do).  We will
wait until he returns next week before confirming.

> On Tue, Feb 7, 2012 at 9:11 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> We (the lme4 authors) have mentioned on this list that we are
>> preparing a new version of lme4 that will provide enhanced
>> capabilities. ?That's the good news. ?The bad news is that the
>> internal representation of the model has been changed yet again. ?If
>> your use of the lme4 package is through the exported functions only
>> you should be okay. ?However, if you find problems then please report
>> them to us either in email <lme4-authors at r-forge.wu-wien.ac.at> or on
>> the bug-tracker at R-forge,
>>
>> https://r-forge.r-project.org/tracker/?func=add&group_id=60&atid=298
>>
>> One major, and unfortunately inevitable, problem that will affect many
>> users is the inability of the new code to load saved objects created
>> with the old code. ?Unfortunately that is what happens when you change
>> the class representation. ?If possible it is best to save the code and
>> data that generated the fitted model and re-fit after the change.
>>
>> If your usage involved access to components or slots in the object
>> then there will be changes. ?To ease the transition, Martin created a
>> function called getME that is available in the current lme4 and in the
>> new lme4, available as lme4Eigen on R-forge. ?This function takes a
>> fitted model and a character variable naming a component and returns
>> the desired component. ?For example, if you want the fixed-effects
>> model matrix from fitted model fm1 then use
>>
>> getME(fm1, "X")
>>
>> Similarly for the random-effects model matrix, "Z", or its transpose,
>> "Zt", the sparse Cholesky factor, "L" and many others. ?Use
>>
>> library(lme4)
>> example(getME)
>>
>> to get some examples.
>>
>> The new lme4 will provide
>>
>> ?- profiling of the deviance function with respect to the parameters
>> ? in a linear mixed model (and soon generalized linear mixed models).
>> ? The profiles allow for creation of realistic confidence intervals
>> ? on the parameters and for various plots that show the sensitivity
>> ? of the deviance to the values of the parameters.
>>
>> ?- a more reliable and flexible implementation of generalized linear
>> ? mixed models, including the use of adaptive Gauss-Hermite
>> ? quadrature for evaluating an approximation to the deviance.
>>
>> ?- short-cut functions such as refitML and refit to re-evaluate a
>> ? model under the maximum likelihood criterion or with a new response
>> ? vector.
>>
>> ?- a cleaner internal representations that provides, in most cases,
>> ? faster and more reliable model fits.
>>
>> ?- choice of optimizer when estimating the parameters. ?Current
>> ? choices are "NelderMead" and "bobyqa". ?Both are generally faster
>> ? and more reliable than the optimizer used in the current lme4,
>> ? which is based on the code in R's nlminb() function, the one that
>> ? gives those annoying "false convergence" messages.
>>
>> ?- smaller memory footprint. ?The need for copying large objects is
>> ? reduced through the use of reference classes in R. ?In the past
>> ? there were circumstances where it was possible to fit a model to a
>> ? large data set but not to print or show the results because a new
>> ? copy of the entire object was created during the process of
>> ? creating a summary. ?This no longer occurs.
>>
>> ?- nlmer has been improved and will, by the time of release, allow
>> ? adaptive Gauss-Hermite quadrature.
>>
>> An alpha-test release will be made available on the R-forge archive
>> but *not* uploaded to CRAN. ?If you use lme4 extensively please test
>> this release by installing from the R-forge archive and telling us if
>> there are problems with your code. ?This way you can still back out to
>> the current release by removing the lme4 package and reinstalling from
>> CRAN. ?Once the new lme4 has been released to CRAN it will be much
>> more difficult to back out that installation.
>>
>> Authors of packages that depend on lme4 will get a separate message
>> off-list about testing and suggested modifications.
>>
>> Thanks for your cooperation. ?We do honestly believe that this change
>> will provide an improved capability for fitting and analyzing
>> mixed-effects models.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Thu Feb  9 19:44:27 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 09 Feb 2012 13:44:27 -0500
Subject: [R-sig-ME] hurdle model with glmmadmb
In-Reply-To: <007001cce73c$aedd1440$0c973cc0$@mncn.csic.es>
References: <004d01cce71a$282597a0$7870c6e0$@mncn.csic.es>	<20120209111719.14332lhrk4jjixyc@www.staffmail.ed.ac.uk>	<006101cce730$c3a7c3e0$4af74ba0$@mncn.csic.es>
	<loom.20120209T145214-367@post.gmane.org>
	<007001cce73c$aedd1440$0c973cc0$@mncn.csic.es>
Message-ID: <4F34140B.4090900@gmail.com>

  [cc'ing back to r-sig-mixed-models]

   There are a few different things going on here.

 (1) your attempt to drop data with zero seedlings failed, for the
following reason:
  (a) you defined new variables, seedling2, Tanual2, name2, etc. ...
*outside* of the datos2 data frame;
  (b) you passed data=subset(datos2,seedling2<0) to glmmADMB
  (c) but ... you used the new variables (seedling2 etc.) in your
formula, *not* names of variables from the data frame.  For example,
glmmADMB looks for a variable "seedling2" in the data frame specified by
the data= argument (which has been subsetted to remove the zero-seedling
cases); it doesn't find it, so it pulls the variable from the global
workspace.  But this variable (and the other variables) has *not* been
subsetted.

  I don't really know how to prevent this kind of error.  I could try to
make glmmADMB *only* look in the data frame specified by data= (at which
point you would get an error saying it couldn't find the 'seedling2'
variable or one of the other variables you specified), but that would be
a little bit tricky to program reliably, and is different (for better or
worse) from the way that the other modeling functions in R work (i.e.
they look first in 'data', then in other environments).  Checking for
length mismatches would work if you only specified *one* variable from
outside of the data frame, but not in the current case.  At least the
warning about zero cases alerts you that something is wrong ...

  Really the best advice is to try to manipulate variables *inside* the
data set, and keep things as clean as possible (see below).

  (2) if you did run glmmADMB with verbose=TRUE you would see the error:
42074072>=40000000
 No memory for dvar_vectors
 Need to increase ARRAY_MEMBLOCK_SIZE parameter

 This tells you the proximate reason why glmmADMB failed (although the
ultimate reason is as stated above).  There are 1717 total cases and
only 438 with seedlings>0, so this is a bigger data set.   If you did
want to run such a big model you would have to use extra.args="-ams
500000000" (I figured this out by poking around in the ADMB manual).
However, I had more trouble making the model work -- I stopped trying to
troubleshoot, knowing that I was working on the wrong data set anyway.

  (3) a couple of minor points: you may have trouble using 'name' as a
random effect, since it only has three levels; as long as you're going
to use the nesting syntax (name/transect/plot), you don't need to
construct the interaction terms yourself.

  Here is my recommended approach -- I manipulate the variables *only*
inside the data frame, and I do as little manipulation as I can get away
with (to keep things cleaner and easier to read).

## start from a CLEAN R session or rm(list=ls())
datos<-read.csv("regenerado_pisy.csv",header=TRUE,sep=";",dec=".")
datos2 <- transform(na.omit(datos),
                    name=factor(name),
                    transect=factor(transect),
                    plot=factor(plot))

library(glmmADMB)
seed_hurdle1<-glmmadmb(seedlings~I(Tmed_anual^2)+(1|name/transect/plot),
                       data=subset(datos2,seedlings>0),
                       family="truncnbinom1")


On 12-02-09 10:08 AM, Raquel Benavides wrote:
> Dear Ben, 
> I have attached the data and the script with the defined variables. The original ones, and then the variables excluding NAs, as previously I got a warning about different lengths of variables that disappeared with the new ones. 
> I tried to put verbose=TRUE and it told me where there were zeros. However, I can not understand why they were selected while I specified seedlings number >0.
> Thanks a lot
> Raquel
> 
> -----Mensaje original-----
> De: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Ben Bolker
> Enviado el: jueves, 09 de febrero de 2012 14:59
> Para: r-sig-mixed-models at r-project.org
> Asunto: Re: [R-sig-ME] hurdle model with glmmadmb
> 
> Raquel Benavides <raquel.benavides at ...> writes:
> 
>>
>> I am afraid it isnt the problema, the bracket was missed during the 
>> copy
> process in the mail...Any other idea?
>>
>> -----Mensaje original-----
>> De: Jarrod Hadfield [mailto:j.hadfield <at> ed.ac.uk]
>>
>> Hi,
>>
>> missing bracket after parcela2?
>>
>> Jarrod
>>
>> Quoting Raquel Benavides <raquel.benavides <at> mncn.csic.es> on Thu, 
>> 9 Feb
>> 2012 12:01:21 +0100:
>>
>>> Dear all,
>>>
>>>
>>>
>>> I am trying to run glmmADMB to check the effect of some fixed 
>>> effects over the number of seedlings in some plots (my random 
>>> factors are site/transect/plot). In particular, I want to run a 
>>> hurdle model. I have tried to follow the instructions given in athe 
>>> document uploaded in the webpage 
>>> http://glmmadmb.r-forge.r-project.org/. However I have some errors, 
>>> and I don?t really understand what do they mean. Does anybody understand what it means and how to avoid it?
>>
>>> seed_hurdle1<-glmmadmb(seedling~I(Tanual^2)+(1|site/transecto/parcel
>>> a2
>>> ,data=
>>> subset(datos,seedling>0),family="truncnbinom1")
>>
>>> Error en glmmadmb(seedling ~ I(Tanual^2) + (1 | name/transecto/parcela),  :
>>>
>>>   The function maximizer failed (couldn't find STD file)
>>>
>>> Adem?s: Mensajes de aviso perdidos
>>>
>>> 1: In glmmadmb(seedling ~ I(Tanual2^2) + (1 | name/transecto/parcela),  :
>>>
>>>   zero response values in truncated family
>>>
>>> 2: comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c "C:/Archivos de 
>>> programa/R/R-2.14.0/library/glmmADMB/bin/windows32/glmmadmb.exe"
>>> -maxfn 500 -maxph 5 -noinit -shess' tiene estatus 1
> 
>   Hmm.  It's surprising that you get the warning about zero response values when you are explicitly using subset(datos, seedling>0).  Do you by any chance have another copy of "seedling" lying around your workspace, or have you attach()ed some data frames?  (This should
> *not* break things, but it might anyway ...)
> 
>   You can try setting verbose=TRUE, although it will give you loads of output where probably only the very end will be useful ...
> 
>   Are you willing to send me data?
> 
>   Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kw.stat at gmail.com  Thu Feb  9 20:04:29 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 9 Feb 2012 13:04:29 -0600
Subject: [R-sig-ME] Upcoming changes in lme4
In-Reply-To: <CAO7JsnRZGz2z2bCdKa6jaMGjZea=+ZdUgbzma1aJ0VmQ1BrgCA@mail.gmail.com>
References: <CAO7JsnRjAg5Ux=WT3sH_BUS9e1TkU5aMDrRQh8MKs9RnzcP+TA@mail.gmail.com>
	<CANz9Z_LPMXFT9me6CSZ7hXdbUnjWHcXoFEkxyaseUZdsZ933xg@mail.gmail.com>
	<CAO7JsnRZGz2z2bCdKa6jaMGjZea=+ZdUgbzma1aJ0VmQ1BrgCA@mail.gmail.com>
Message-ID: <CAKFxdiRgOgzrZpC0xut5HjUd96kMsrPfe3hkRvM1iSV-kCgRHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120209/bf4715d7/attachment-0002.pl>

From bates at stat.wisc.edu  Thu Feb  9 21:03:49 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 14:03:49 -0600
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
 convergence (7)"
In-Reply-To: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
References: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
Message-ID: <CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>

On Thu, Feb 9, 2012 at 11:08 AM, Toni Hernandez-Matias
<ahmatias at gmail.com> wrote:
> Dear all,

> I am trying to fit a set of models with lmer function.
> My aim is to investigate the relationship between the abundance of a mammal
> species (count) and several environmental variables.
> The sample size is 648, but the observations are not independent and the
> random effect is nested: I have 10 study areas, within each area I
> performed 6 transects. I have 9-10 observations in all transects. So an
> example of a model with a single independent variable is:
> mod05<-lmer(cagaders~E_arb_alt+(1|ter)+(1|ter:trans),data=conill,family=poisson)

> When running this model I get the warning:
> In mer_finalize(ans) : singular convergence (7)

Try using verbose=TRUE to determine where the parameter values are
going during the iterative optimization process.

If your data could be made available, even in an anonymized form, we
could check the model fit against other optimizers that may be more
successful.

> I don't see an apparent reason for this warning.
> I would be very grateful if someone can help me to solve this problem and
> to know wether the results in the fitted model are credible.
>
> Thank you very much in advance,
>
> Toni
>
> --
> *********************************************************
>
> Antonio Hernandez Matias
>
> Departament de Biologia Animal (Vertebrats)
> Facultat de Biologia
> Universitat de Barcelona
> Av. Diagonal, 645
> Barcelona ? ? ?08028
> Spain
> Telephone: +34-934035857
> FAX: +34-934035740
> e-mail: ahernandezmatias at ub.edu
>
> ***********************************************************
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Thu Feb  9 21:13:24 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 14:13:24 -0600
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
References: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
	<CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
Message-ID: <CAO7JsnQVEiw9Y9SA6jNbhqejMxU87bWJL5MozfKzX++McOcyTA@mail.gmail.com>

On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi AC,
>
> My personal preference would be glmer from the lme4 package. ?I prefer
> the Laplace approximation for the likelihood over the quasilikelihood
> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
> with 2 million observations nested within 200 groups (10,000
> observations per group). ?I then ran an random intercepts model using:
>
> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>
> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>
> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
> With the OS and R running, my system used ~ 6GB of RAM for the model
> and went up to ~7GB to show the summary (copies of the data are
> made---changed in the upcoming version of lme4).
>
> So as long as you have plenty of memory, you should have no trouble
> modelling your data using glmer(). ?To initially make sure all your
> code works, I might use a subset of your data (say 10k), once you are
> convinced you have the model you want, run it on the full data.

If you would have an opportunity to run that model fit or a comparable
on lme4Eigen::glmer we would appreciate information about speed,
accuracy and memory usage.

In lme4Eigen::glmer there are different levels of precision in the
approximation to the deviance being optimizer.  These are controlled
by the nAGQ argument to the function.  The default, nAGQ=1, uses the
Laplace approximation.  The special value nAGQ=0 also uses the Laplace
approximation but profiles out the fixed-effects parameters.  This
profiling is not exact but usually gets you close to the optimum that
you would get from nAGQ=1, but much, much faster.  In a model like
this you can also use nAGQ>1 and <= 25.  On the model fits we have
tried we don't see a lot of difference in timing between, say, nAGQ=9
and nAGQ=25 but on a model fit like this you might.

As a fallback, we would appreciate the code that you used to simulate
the response.  We could generate something ourselves, of course, but
it is easier to compare when you copy someone else's simulation.
> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>> Hi,
>>
>> I have a huge dataset (2.5 million patients nested within ?> 100
>> facilities) and would like to examine variability across facilities in
>> program utilization (0=n, 1=y; utilization rates are low in general), along
>> with patient and facility predictors of utilization.
>>
>> I have 3 questions:
>>
>> 1. What program and/or package(s) do you recommend for running LMMs with
>> big data (even if they are not R packages)?
>>
>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>> data, etc) that would allow me to use only R packages to run this dataset
>> (assuming I need to use another program due to the size of the dataset)?
>>
>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>> wanting to examine? I know of two potential options (family=binomial option
>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>> appropriate or what other R packages and functions are available for this
>> purpose?
>>
>> Thank you,
>>
>> AC
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Thu Feb  9 21:59:13 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Feb 2012 14:59:13 -0600
Subject: [R-sig-ME] random intercept and random slope
In-Reply-To: <5F7C032D-1E9E-453E-8898-4E059B8F8396@emg.umu.se>
References: <5F7C032D-1E9E-453E-8898-4E059B8F8396@emg.umu.se>
Message-ID: <CAO7JsnTUAoZ8v-_6Ba+7Wjytx+Eh=oyi1Z=d2HQ-Fwhd1X=6AQ@mail.gmail.com>

2012/2/9 Andr? Barbosa <andre.frainer at emg.umu.se>:
> Dear list members,
> I have read several threads on this list about the use of random variables and its interpretation. I seem to have learned a lot about model fitting, from plotting the raw data and checking the slopes and intercepts, to getting rid of the p-value mindset in which I had had my basic statistics courses at university.
> However, since my statistical courses never covered Mixed Effect Models, I am still unsure if I am doing the right thing or not. Having said that, would you please take a look at the following data and see if my rational is correct? The model is quite simple, I believe.
> I have 8 different plant species, which were mixed two-by-two in all possible combinations. So, each species has 7 pairs + it being alone (monoculture). My response variable is a ratio (observed /expected productivity values, where observed is the productivity of species ?a? achieved when mixed with another species, and expected is its value when in monoculture).
> Each species had its own nutrient content analyzed. As I had three nutrient variables measured from each plant, I calculated indices of dissimilarity for each of those pairs.
> My starting model (without specifying random or fixed effects) would be:
> ratio ~ dissimilarity | species
> I expected, based on previous studies, that the relationship between ratio and dissimilarity would yield different slopes for each species, from negative to positive ? expectation confirmed by potting a xyplot function of my data. Thus, species should be random. Looking at the xyplot of my data, I also see that the intercepts are somehow variable, ranging between 0.5 and 1.5 (response data points do not extend much further from this range, either). For this reason, I thought on including intercepts as random, as well, which leave me without fixed variables.
> So, I decided to test:
> lmer(ratio ~ 1 + (dissimilarity|species))
> Here follows a subset of my data:
> species ? ? ? ? ? ?pair ? ? ? ? ? ?ratio ? ? ? ? ? ?dissimilarity
> a ? ? ? ? ? ?a+b ? ? ? ? ? ?1.090935 ? ? ? ? ? ?1.870297012
> a ? ? ? ? ? ?a+c ? ? ? ? ? ?1.182509 ? ? ? ? ? ?0.691033781
> a ? ? ? ? ? ?a+d ? ? ? ? ? ?1.505538 ? ? ? ? ? ?1.441237522
> a ? ? ? ? ? ?a+e ? ? ? ? ? ?1.547295 ? ? ? ? ? ?0.953060747
> a ? ? ? ? ? ?a+f ? ? ? ? ? ?1.463782 ? ? ? ? ? ?1.306913498
> a ? ? ? ? ? ?a+g ? ? ? ? ? ?1.197587 ? ? ? ? ? ?1.331087471
> a ? ? ? ? ? ?a+h ? ? ? ? ? ?1.113263 ? ? ? ? ? ?1.097840225
> b ? ? ? ? ? ?b+a ? ? ? ? ? ?0.899969 ? ? ? ? ? ?1.870297012
> b ? ? ? ? ? ?b+c ? ? ? ? ? ?1.102478 ? ? ? ? ? ?1.548604304
> b ? ? ? ? ? ?b+d ? ? ? ? ? ?1.218110 ? ? ? ? ? ?1.669409077
> b ? ? ? ? ? ?b+e ? ? ? ? ? ?1.095748 ? ? ? ? ? ?1.536191709
> b ? ? ? ? ? ?b+f ? ? ? ? ? ?1.306822 ? ? ? ? ? ?1.579788658
> b ? ? ? ? ? ?b+g ? ? ? ? ? ?1.299480 ? ? ? ? ? ?1.084382658
> b ? ? ? ? ? ?b+h ? ? ? ? ? ?1.219945 ? ? ? ? ? ?1.137927922
> c ? ? ? ? ? ?c+a ? ? ? ? ? ?1.092199 ? ? ? ? ? ?1.441237522
> c ? ? ? ? ? ?c+b ? ? ? ? ? ?1.486702 ? ? ? ? ? ?1.669409077
> c ? ? ? ? ? ?c+d ? ? ? ? ? ?0.847517 ? ? ? ? ? ?1.688612802
> c ? ? ? ? ? ?c+e ? ? ? ? ? ?0.210150 ? ? ? ? ? ?0.651183878
> c ? ? ? ? ? ?c+f ? ? ? ? ? ?1.459219 ? ? ? ? ? ?1.064428069
> c ? ? ? ? ? ?c+g ? ? ? ? ? ?0.87810 ? ? ? ? ? ?0.590191888
> c ? ? ? ? ? ?c+h ? ? ? ? ? ?0.91223 ? ? ? ? ? ?1.37455314
> d ? ? ? ? ? ?d+a ? ? ? ? ? ?1.32486 ? ? ? ? ? ?0.953060747
> d ? ? ? ? ? ?d+b ? ? ? ? ? ?1.37737 ? ? ? ? ? ?1.536191709
> d ? ? ? ? ? ?d+c ? ? ? ? ? ?1.23869 ? ? ? ? ? ?1.310607287
> d ? ? ? ? ? ?d+e ? ? ? ? ? ?1.15714 ? ? ? ? ? ?0.651183878
> d ? ? ? ? ? ?d+f ? ? ? ? ? ?0.97390 ? ? ? ? ? ?1.22540051
> d ? ? ? ? ? ?d+g ? ? ? ? ? ?0.92355 ? ? ? ? ? ?0.640371057
> d ? ? ? ? ? ?d+h ? ? ? ? ? ?0.79097 ? ? ? ? ? ?1.224534999
>
> The output from my model, using the whole data set is:
>> summary(random.model)
> Linear mixed model fit by REML
> Formula: ratio~ 1 + (dissimilarity | species)
> ? Data: k
> ? AIC ? BIC ?logLik deviance REMLdev
> ?11.29 21.42 -0.6465 ? -3.273 ? 1.293
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
> ?species ?(Intercept) 0.092206 0.30365
> ? ? ? ? ?dissimilarity ? ? ? ?0.030348 0.17421 ?-1.000
> ?Residual ? ? ? ? ? ? 0.048348 0.21988
> Number of obs: 56, groups: species, 8
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?1.18024 0.04087 ? 28.88
>
> ----
>
> My questions:
>
> 1. Is my approach correct in plotting the independent variable ?dissimilarity? as random intercept, as in ~ 1 + (dissimilarity|species)?

Probably not.  The random effects are defined to have mean 0 so any
non-zero mean must occur in the fixed effects.  Generally the model to
be fit is

ratio ~ 1 + dissumilarity + (1 + dissimilarlity|species)

which is equivalent to

ratio ~ dissimilarity + (dissimilarity|specties)

It is a matter of taste whether to include the 1+ or not in a model
formula like this.  I find that doing so emphasizes to me where each
of the parameters come from.

> 2. On a publication, can I report the variance component of the random terms (in percentage) as the main result of the test?
> 3. Would it be possible to run McMC on a model that does not have Fixed Effects?
> 4. Would there be any other metrics that I should report as well?
>
> I am sure that my questions are pretty basic, but I would strongly appreciate any input from you. Thank you!
> Andre
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ahmatias at gmail.com  Fri Feb 10 12:06:19 2012
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Fri, 10 Feb 2012 12:06:19 +0100
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
 convergence (7)"
In-Reply-To: <CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
References: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
	<CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
Message-ID: <CA+hwERn-9DHnOVr9omj50dRY-wfQ4aDBEDiqiktSBdmexf4_uw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120210/064c53c7/attachment-0002.pl>

From m.fairbrother at bristol.ac.uk  Fri Feb 10 13:20:45 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 10 Feb 2012 12:20:45 +0000
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
References: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
Message-ID: <FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>

Dear AC (and perhaps Doug),

>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>> data, etc) that would allow me to use only R packages to run this dataset
>>> (assuming I need to use another program due to the size of the dataset)?

You may be well aware of this, but one way of substantially speeding up the estimation of models with binary data is to use "cbind", though the feasibility of this depends on the nature of the model (number of predictors and number of unique values for each predictor variable). The kind of code you need for this is below. You'll see that the fixed effects estimates, standard errors, and random effects variances turn out the same.

> If you would have an opportunity to run that model fit or a comparable
> on lme4Eigen::glmer we would appreciate information about speed,
> accuracy and memory usage.

> As a fallback, we would appreciate the code that you used to simulate
> the response.  We could generate something ourselves, of course, but
> it is easier to compare when you copy someone else's simulation.

I've compared the speed of lme4 versus lme4Eigen, on a simulated dataset with 100,000 observations, using a 2GHz MacBook. Based on a handful of simulations, there doesn't appear to be much difference between the two packages in terms of speed (sometimes one is faster, sometimes the other). I have reported the results of one simulation here. The two packages generate identical results for this dataset.

Cheers,
Malcolm


N <- 100000
grps <- 100
dat <- data.frame(x1 = sample(1:10, N, replace=T), x2 = sample(18:23, N, replace=T), grp=rep(1:grps, each=N/grps))
dat$y <- rbinom(N, prob = plogis(-5 + 0.1*dat$x1 + 0.2*dat$x2 + rnorm(grps)[dat$grp]), size = 1)
failures <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==0))
successes <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==1))
dat2 <- expand.grid(x1=sort(unique(dat$x1)), x2=sort(unique(dat$x2)), grp=sort(unique(dat$grp)))
dat2$failures <- as.vector(failures)
dat2$successes <- as.vector(successes)
library(lme4)
system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
#   user  system elapsed 
# 22.918   0.660  24.441
system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
#   user  system elapsed 
#  1.833   0.017   1.855 
detach("package:lme4")
library(lme4Eigen)
system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
#   user  system elapsed 
# 24.824   1.811  26.773 
system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
#   user  system elapsed 
#  1.687   0.039   1.723



> Date: Thu, 9 Feb 2012 14:13:24 -0600
> From: Douglas Bates <bates at stat.wisc.edu>
> To: Joshua Wiley <jwiley.psych at gmail.com>
> Cc: AC Del Re <acdelre at stanford.edu>, r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] LMM with Big data using binary DV
> 
> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>> Hi AC,
>> 
>> My personal preference would be glmer from the lme4 package. ?I prefer
>> the Laplace approximation for the likelihood over the quasilikelihood
>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>> with 2 million observations nested within 200 groups (10,000
>> observations per group). ?I then ran an random intercepts model using:
>> 
>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>> 
>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>> 
>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>> With the OS and R running, my system used ~ 6GB of RAM for the model
>> and went up to ~7GB to show the summary (copies of the data are
>> made---changed in the upcoming version of lme4).
>> 
>> So as long as you have plenty of memory, you should have no trouble
>> modelling your data using glmer(). ?To initially make sure all your
>> code works, I might use a subset of your data (say 10k), once you are
>> convinced you have the model you want, run it on the full data.
> 
> If you would have an opportunity to run that model fit or a comparable
> on lme4Eigen::glmer we would appreciate information about speed,
> accuracy and memory usage.
> 
> In lme4Eigen::glmer there are different levels of precision in the
> approximation to the deviance being optimizer.  These are controlled
> by the nAGQ argument to the function.  The default, nAGQ=1, uses the
> Laplace approximation.  The special value nAGQ=0 also uses the Laplace
> approximation but profiles out the fixed-effects parameters.  This
> profiling is not exact but usually gets you close to the optimum that
> you would get from nAGQ=1, but much, much faster.  In a model like
> this you can also use nAGQ>1 and <= 25.  On the model fits we have
> tried we don't see a lot of difference in timing between, say, nAGQ=9
> and nAGQ=25 but on a model fit like this you might.
> 
> As a fallback, we would appreciate the code that you used to simulate
> the response.  We could generate something ourselves, of course, but
> it is easier to compare when you copy someone else's simulation.
>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>> Hi,
>>> 
>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>> facilities) and would like to examine variability across facilities in
>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>> with patient and facility predictors of utilization.
>>> 
>>> I have 3 questions:
>>> 
>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>> big data (even if they are not R packages)?
>>> 
>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>> data, etc) that would allow me to use only R packages to run this dataset
>>> (assuming I need to use another program due to the size of the dataset)?
>>> 
>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>> wanting to examine? I know of two potential options (family=binomial option
>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>> appropriate or what other R packages and functions are available for this
>>> purpose?
>>> 
>>> Thank you,
>>> 
>>> AC



From schmidt.fa at gmail.com  Fri Feb 10 14:37:04 2012
From: schmidt.fa at gmail.com (Fernando Schmidt)
Date: Fri, 10 Feb 2012 11:37:04 -0200
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
 convergence (7)"
In-Reply-To: <CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
References: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
	<CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
Message-ID: <CACddD7Bmkdcf+M-prA6PmLXynnh65AT7o-ZYigpHN=kK_q0SiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120210/0ff616ca/attachment-0002.pl>

From 538280 at gmail.com  Fri Feb 10 17:25:35 2012
From: 538280 at gmail.com (538280 at gmail.com)
Date: Fri, 10 Feb 2012 09:25:35 -0700
Subject: [R-sig-ME] A question
In-Reply-To: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>
References: <CALeYHHqLBqnh+mKHnbAiO1cF2KntnE5KdcimWvdkOz+z_x66hA@mail.gmail.com>
Message-ID: <CAFEqCdwog6swNu4jiJMuYpgokuUpAfhsfYFkfk53Us=g1p-6dw@mail.gmail.com>

Assuming that you are using the lme function from the nlme package,
you probably want to look at the augPred and plot.augPred functions in
the same package for more meaningful ways to make and plot predictions
from mixed effects models.

On Wed, Feb 8, 2012 at 9:13 AM, sheida sarafzade <shsarafzade at gmail.com> wrote:
> Hello
> I'm MSc. student in biostatistics and working on mixed effect models
> I?m trying to add fitted line to scatter plot (x,y)
> Here ?weight? is dependent variable and ?month? is time variable.
> The program is:
> Lme1<-Lme(weight~month+(month^2),data=DataSetName,random=~month|id)
>
> When I use the code below:
> Lines(month[order(month)],fitted.lme(lme1,level=0)[order(month)])
>
> It draws a smooth line but when I add a covariate (like birth weight)
> to my model as below:
>
> Lme2<-lme(weight~BirthWeight+month+(month^2),data=DataSetName,random=~month|id)
>
> And then write the code below:
> Lines(month[order(month)],fitted.lme(lme2,level=0)[order(month)])
>
> It doesn?t draw smooth line. the line is not smooth.
>
> How can I fix this problem?
> What is the role of term ?level? in this code? And what are it?s option?
>
> for more information please see attachment
> Thanks a lot
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From schmidt.fa at gmail.com  Fri Feb 10 18:25:26 2012
From: schmidt.fa at gmail.com (Fernando Schmidt)
Date: Fri, 10 Feb 2012 15:25:26 -0200
Subject: [R-sig-ME] Doubts about model.avg function at MuMin package
Message-ID: <CACddD7B=RGhY_tgzpdL+mR_wLt3vfw7W9pTwY9wSGMB4HY2LZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120210/a2fcf1b4/attachment-0002.pl>

From 538280 at gmail.com  Fri Feb 10 18:36:05 2012
From: 538280 at gmail.com (538280 at gmail.com)
Date: Fri, 10 Feb 2012 10:36:05 -0700
Subject: [R-sig-ME] ghlt different results for different hypotheses?
In-Reply-To: <5725262.8850411328783130878.JavaMail.defaultUser@defaultHost>
References: <5725262.8850411328783130878.JavaMail.defaultUser@defaultHost>
Message-ID: <CAFEqCdwUaqPATpxyo2dvL87PQL0F+uRLz5mzxYTQqUf_Sjv-1Q@mail.gmail.com>

The more comparisons/tests that you do the more opportunities you have
of getting a type I error.  The multiple comparisons procedures adjust
for the number of comparisons so that the overall probability of
making at least 1 type I error is fixed.  So the more comparisons the
more adjustment needs to be made.

Think of this simple example.  You are playing a game where you are
trying to throw a wadded up piece of paper into a basket, you win if
you get it in at least once.  What are your chances of winning if you
get 10 tries compared to if you get 20 tries (from the same spot)?  If
you want the same chance of winning with 20 tries as you had for 10
tries (or 1 try), then you need to move further away or some other
penalty.

So with glht there is a bigger penalty when you do more comparisons
since there are more opportunities of making a type I error.

On Thu, Feb 9, 2012 at 3:25 AM, m.fenati at libero.it <m.fenati at libero.it> wrote:
>
>
> Dear R users,
> I would like to understand a simple problem related to glht() multeplicity correction and linear Hypotheses testing. Given a simple lme model with two predictors (group = 3 levels; time = ?2 levels) and their interaction with treatment contrast, I see that the p-values are lower and higher when I test few or many hypotheses respectively. Because I dont't have a deep knowledge of multiple comparison theory, I ask you some suggestion or explanation about the different obtained results.
> As you can see in the example below, "m1" and "m2" test a different number of hypotheses but comparing the same hypothesis a different results occurred.
>
>
> time<-rep(c(rep(0,8),rep(1,8)),3)
> group<-c(rep(0,16),rep(1,16),rep(2,16))
> id<-c(rep(1:8,2),rep(9:16,2),rep(17:24,2))
> w<-c(172.9, 185.8, 173.1, 187.3, 161.6, 167.1, 168.4, 161.1, 166.5, 175.3, 167.1, 181.9, 163.0, 167.7, 172.1, 170.3, 167.2, 183.3, 160.7,167.8, 149.6, 159.1, 164.2, 171.0, 168.6, 173.5, 161.8, 166.5, 148.4, 167.1, 166.8, 166.6, 150.6, 178.4, 166.4, 159.2, 163.2, 167.8, 136.6, 161.8, 166.1, 175.8, 175.6, 166.2, 168.5, 170.5, 152.0, 164.4)
> dati<-data.frame(time,group,id,w)
> dati$time<-as.factor(dati$time)
> dati$group<-as.factor(dati$group)
> dati$id<-as.factor(dati$id)
>
>
>
>
> kp<-rbind("after Treatment: Group 1 - Controls"=c(0,1,0,0,0,0),
> ? ? ? ? "after Treatment: Group 2 - Controls"=c(0,0,1,0,0,0),
> ? ? ? ? "before Treatment: Group 1 - Controls"=c(0,1,0,0,1,0),
> ? ? ? ? "before Treatment: Group 2 - Controls"=c(0,0,1,0,0,1),
> ? ? ? ? "Controls: time trend (T1 - T0)"=c(0,0,0,-1,0,0),
> ? ? ? ? "Group 1: time trend (T1 - T0)"=c(0,0,0,-1,-1,0),
> ? ? ? ? "Group 2: time trend (T1 - T0)"=c(0,0,0,-1,0,-1))
>
>
> k<-rbind("after Treatment: Group 1 - Controls"=c(0,1,0,0,0,0),
> ? ? ? ? "after Treatment: Group 2 - Controls"=c(0,0,1,0,0,0),
> ? ? ? ? "before Treatment: Group 1 - Controls"=c(0,1,0,0,1,0),
> ? ? ? ? "before Treatment: Group 2 - Controls"=c(0,0,1,0,0,1)
> ? ? ? ? )
>
>
>
>
> w.lme<-lme(w~group*time,data=dati,random=~1|id)
> m1<-summary(glht(w.lme,kp))
> m2<-summary(glht(w.lme,k))
>
>
> Thank in advances for your suggestions
>
>
> Massimo
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From bates at stat.wisc.edu  Fri Feb 10 18:36:10 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 10 Feb 2012 11:36:10 -0600
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>
References: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
	<FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>
Message-ID: <CAO7JsnSDMS_unUTP+dECFJfkBnJSojkXixchyi1Y3GQVCH-1AA@mail.gmail.com>

On Fri, Feb 10, 2012 at 6:20 AM, Malcolm Fairbrother
<m.fairbrother at bristol.ac.uk> wrote:
> Dear AC (and perhaps Doug),
>
>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>> (assuming I need to use another program due to the size of the dataset)?
>
> You may be well aware of this, but one way of substantially speeding up the estimation of models with binary data is to use "cbind", though the feasibility of this depends on the nature of the model (number of predictors and number of unique values for each predictor variable). The kind of code you need for this is below. You'll see that the fixed effects estimates, standard errors, and random effects variances turn out the same.
>
>> If you would have an opportunity to run that model fit or a comparable
>> on lme4Eigen::glmer we would appreciate information about speed,
>> accuracy and memory usage.
>
>> As a fallback, we would appreciate the code that you used to simulate
>> the response. ?We could generate something ourselves, of course, but
>> it is easier to compare when you copy someone else's simulation.
>
> I've compared the speed of lme4 versus lme4Eigen, on a simulated dataset with 100,000 observations, using a 2GHz MacBook. Based on a handful of simulations, there doesn't appear to be much difference between the two packages in terms of speed (sometimes one is faster, sometimes the other). I have reported the results of one simulation here. The two packages generate identical results for this dataset.
>
> Cheers,
> Malcolm
>
>
> N <- 100000
> grps <- 100
> dat <- data.frame(x1 = sample(1:10, N, replace=T), x2 = sample(18:23, N, replace=T), grp=rep(1:grps, each=N/grps))
> dat$y <- rbinom(N, prob = plogis(-5 + 0.1*dat$x1 + 0.2*dat$x2 + rnorm(grps)[dat$grp]), size = 1)
> failures <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==0))
> successes <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==1))
> dat2 <- expand.grid(x1=sort(unique(dat$x1)), x2=sort(unique(dat$x2)), grp=sort(unique(dat$grp)))
> dat2$failures <- as.vector(failures)
> dat2$successes <- as.vector(successes)
> library(lme4)
> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
> # ? user ?system elapsed
> # 22.918 ? 0.660 ?24.441
> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
> # ? user ?system elapsed
> # ?1.833 ? 0.017 ? 1.855
> detach("package:lme4")
> library(lme4Eigen)
> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
> # ? user ?system elapsed
> # 24.824 ? 1.811 ?26.773
> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
> # ? user ?system elapsed
> # ?1.687 ? 0.039 ? 1.723

Thanks for sending that, Malcolm.

Your collapsing of the binary responses to the number of successes and
failures works in this case by can't be expected to work in general.
In establishing dat2 using expand.grid you are assuming that all
combinations of covariates occur in the data.  If not you would end up
with a successes=0, failures=0 row and that might cause problems in
glm or glmer finding the proportion of successes (I havent' gone back
to look at the code to determine this).  I am trying to think of a way
of doing this using the type of strategy in the hidden function
duplicated.data.frame.  If you have the model frame and you know that
there are only two unique values for the response you can get the
counts by determining the unique combinations of covariates and using
xtabs. If you look at duplicated.data.frame, you will see that getting
the unique combinations is done by pasting the text representation of
the row using a separator that will not occur in numeric data.  The C
function do_duplicated uses hash tables and hashing a character string
is very fast.

The end result looks like the enclosed.

Of course, there is probably a much cleaner way of doing this using
Hadley Wickham's reshape package but I haven't studied that package
enough yet.

As Malcolm said, the two sets of parameter estimates are very similar
but the deviance is different.  I am working on changes that will
create the proper value of the deviance from the model in terms of
successes and failure.  It is very confusing - the function in the glm
family that produces the deviance is called "aic" and the function
called "dev.resids" actually produces the square of the deviance
residuals and their sum should be the glm deviance, except when it
isn't.  It's disheartening at best.

I also include a timing of the model fit using nAGQ=25 which should be
a very accurate evaluation of the deviance.

The other version with nAGQ=0 uses a Laplace approximation and
(approximately) profiles out the fixed-effects parameters.  In many
situations this gets close enough to the correct deviance that the
results can be used for rough model comparisons.


>> Date: Thu, 9 Feb 2012 14:13:24 -0600
>> From: Douglas Bates <bates at stat.wisc.edu>
>> To: Joshua Wiley <jwiley.psych at gmail.com>
>> Cc: AC Del Re <acdelre at stanford.edu>, r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] LMM with Big data using binary DV
>>
>> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>> Hi AC,
>>>
>>> My personal preference would be glmer from the lme4 package. ?I prefer
>>> the Laplace approximation for the likelihood over the quasilikelihood
>>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>>> with 2 million observations nested within 200 groups (10,000
>>> observations per group). ?I then ran an random intercepts model using:
>>>
>>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>>>
>>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>>>
>>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>>> With the OS and R running, my system used ~ 6GB of RAM for the model
>>> and went up to ~7GB to show the summary (copies of the data are
>>> made---changed in the upcoming version of lme4).
>>>
>>> So as long as you have plenty of memory, you should have no trouble
>>> modelling your data using glmer(). ?To initially make sure all your
>>> code works, I might use a subset of your data (say 10k), once you are
>>> convinced you have the model you want, run it on the full data.
>>
>> If you would have an opportunity to run that model fit or a comparable
>> on lme4Eigen::glmer we would appreciate information about speed,
>> accuracy and memory usage.
>>
>> In lme4Eigen::glmer there are different levels of precision in the
>> approximation to the deviance being optimizer. ?These are controlled
>> by the nAGQ argument to the function. ?The default, nAGQ=1, uses the
>> Laplace approximation. ?The special value nAGQ=0 also uses the Laplace
>> approximation but profiles out the fixed-effects parameters. ?This
>> profiling is not exact but usually gets you close to the optimum that
>> you would get from nAGQ=1, but much, much faster. ?In a model like
>> this you can also use nAGQ>1 and <= 25. ?On the model fits we have
>> tried we don't see a lot of difference in timing between, say, nAGQ=9
>> and nAGQ=25 but on a model fit like this you might.
>>
>> As a fallback, we would appreciate the code that you used to simulate
>> the response. ?We could generate something ourselves, of course, but
>> it is easier to compare when you copy someone else's simulation.
>>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>>> Hi,
>>>>
>>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>>> facilities) and would like to examine variability across facilities in
>>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>>> with patient and facility predictors of utilization.
>>>>
>>>> I have 3 questions:
>>>>
>>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>>> big data (even if they are not R packages)?
>>>>
>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>> (assuming I need to use another program due to the size of the dataset)?
>>>>
>>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>>> wanting to examine? I know of two potential options (family=binomial option
>>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>>> appropriate or what other R packages and functions are available for this
>>>> purpose?
>>>>
>>>> Thank you,
>>>>
>>>> AC
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-------------- next part --------------

R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> N <- 100000
> ngrps <- 100
> set.seed(101)
> str(dat <- within(data.frame(x1   = sample(1:10, N, replace=TRUE),
+                              x2   = sample(18:23, N, replace=TRUE),
+                              grps = factor(sample.int(ngrps, N, replace=TRUE))),
+               {
+                   y <- rbinom(N,
+                               prob = plogis(-5 + 0.1 * x1 + 0.2 * x2 + rnorm(ngrps)[grps]),
+                               size = 1)
+                   covs <- do.call(paste, c(model.frame(~ x1 + x2 + grps), sep="\r"))
+               }))
'data.frame':	100000 obs. of  5 variables:
 $ x1  : int  4 1 8 7 3 4 6 4 7 6 ...
 $ x2  : int  21 20 19 21 19 22 23 22 22 23 ...
 $ grps: Factor w/ 100 levels "1","2","3","4",..: 94 13 40 95 43 53 31 72 43 21 ...
 $ covs: chr  "4\r21\r94" "1\r20\r13" "8\r19\r40" "7\r21\r95" ...
 $ y   : num  0 0 1 0 0 1 1 0 0 1 ...
> head(dat)
  x1 x2 grps      covs y
1  4 21   94 4\r21\r94 0
2  1 20   13 1\r20\r13 0
3  8 19   40 8\r19\r40 1
4  7 21   95 7\r21\r95 0
5  3 19   43 3\r19\r43 0
6  4 22   53 4\r22\r53 1
> str(freq <- xtabs(~ covs + y, dat))
 xtabs [1:6000, 1:2] 10 11 12 5 7 1 12 5 6 6 ...
 - attr(*, "dimnames")=List of 2
  ..$ covs: chr [1:6000] "10\r18\r1" "10\r18\r10" "10\r18\r100" "10\r18\r11" ...
  ..$ y   : chr [1:2] "0" "1"
 - attr(*, "class")= chr [1:2] "xtabs" "table"
 - attr(*, "call")= language xtabs(formula = ~covs + y, data = dat)
> head(freq)
             y
covs           0 1
  10\r18\r1   10 7
  10\r18\r10  11 1
  10\r18\r100 12 3
  10\r18\r11   5 7
  10\r18\r12   7 9
  10\r18\r13   1 6
> str(dat2 <- within(dat[!duplicated(dat$covs),],
+                {
+                    failure <- freq[covs, 1]
+                    success <- freq[covs, 2]
+                    y       <- NULL
+                    covs    <- NULL
+                }))
'data.frame':	6000 obs. of  5 variables:
 $ x1     : int  4 1 8 7 3 4 6 4 7 6 ...
 $ x2     : int  21 20 19 21 19 22 23 22 22 23 ...
 $ grps   : Factor w/ 100 levels "1","2","3","4",..: 94 13 40 95 43 53 31 72 43 21 ...
 $ success: num  4 8 12 6 4 8 11 9 4 12 ...
 $ failure: num  10 9 10 13 19 10 3 10 15 5 ...
> head(dat2)
  x1 x2 grps success failure
1  4 21   94       4      10
2  1 20   13       8       9
3  8 19   40      12      10
4  7 21   95       6      13
5  3 19   43       4      19
6  4 22   53       8      10
> xtabs(~ y, subset(dat, covs == "4\r21\r94"))  # corresponds to first row in dat2
y
 0  1 
10  4 
> 
> library(lme4Eigen)
Loading required package: lattice
> ## using the full data frame, dat
> 
> ## default fit using the Laplace approximation
> system.time(print(gm01a <- glmer(y ~ x1 + x2 + (1 | grps), dat, binomial), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: y ~ x1 + x2 + (1 | grps) 
   Data: dat 

      AIC       BIC    logLik  deviance 
113146.67 113184.73 -56569.34 113138.67 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 100000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.039837   0.137784  -36.58
x1           0.102856   0.002550   40.33
x2           0.195406   0.004307   45.37
   user  system elapsed 
 32.250   0.084  32.327 
> 
> ## faster but less accurate version that profiles out the fixed-effects parameters
> system.time(print(gm01b <- glmer(y ~ x1 + x2 + (1 | grps), dat, binomial, nAGQ=0L), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: y ~ x1 + x2 + (1 | grps) 
   Data: dat 

      AIC       BIC    logLik  deviance 
113146.68 113184.74 -56569.34 113138.68 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.077    1.038   
Number of obs: 100000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.034540   0.137930  -36.50
x1           0.102753   0.002550   40.30
x2           0.195209   0.004306   45.33
   user  system elapsed 
  4.824   0.020   4.841 
> 
> ## slowest but most accurate version
> system.time(print(gm01c <- glmer(y ~ x1 + x2 + (1 | grps), dat, binomial, nAGQ=25L), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: y ~ x1 + x2 + (1 | grps) 
   Data: dat 

     AIC      BIC   logLik deviance 
113146.6 113184.7 -56569.3 113138.6 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 100000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.039829   0.137783  -36.58
x1           0.102856   0.002550   40.33
x2           0.195406   0.004307   45.37
   user  system elapsed 
 81.589   0.088  81.726 
> 
> ## using the reduced data frame, dat2
> 
> ## default fit using the Laplace approximation
> system.time(print(gmsda <- glmer(cbind(success,failure) ~ x1 + x2 + (1 | grps), dat2, binomial),
+                   corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: cbind(success, failure) ~ x1 + x2 + (1 | grps) 
   Data: dat2 

      AIC       BIC    logLik  deviance 
 6890.896  6917.694 -3441.448  6882.896 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 6000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.039823   0.137783  -36.58
x1           0.102857   0.002550   40.33
x2           0.195406   0.004307   45.37
   user  system elapsed 
  1.508   0.012   1.513 
> ## fastest version profiling out the fixed-effects parameters
> system.time(print(gmsdb <- glmer(cbind(success,failure) ~ x1 + x2 + (1 | grps), dat2,
+                                  binomial, nAGQ=0L), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: cbind(success, failure) ~ x1 + x2 + (1 | grps) 
   Data: dat2 

      AIC       BIC    logLik  deviance 
 6890.901  6917.699 -3441.450  6882.901 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 6000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.034500   0.137780  -36.54
x1           0.102752   0.002550   40.30
x2           0.195207   0.004306   45.33
   user  system elapsed 
  0.220   0.008   0.223 
> ## slower but most accurate version
> system.time(print(gmsd25 <- glmer(cbind(success,failure) ~ x1 + x2 + (1 | grps), dat2,
+                                   binomial, nAGQ=25L), corr=FALSE))
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Formula: cbind(success, failure) ~ x1 + x2 + (1 | grps) 
   Data: dat2 

      AIC       BIC    logLik  deviance 
 6890.827  6917.625 -3441.414  6882.827 

Random effects:
 Groups Name        Variance Std.Dev.
 grps   (Intercept) 1.073    1.036   
Number of obs: 6000, groups: grps, 100

Fixed effects:
             Estimate Std. Error z value
(Intercept) -5.039829   0.137783  -36.58
x1           0.102857   0.002550   40.33
x2           0.195406   0.004307   45.37
   user  system elapsed 
  6.113   0.004   6.112 
> 
> proc.time()
   user  system elapsed 
131.684   1.040 131.792 

From m.fairbrother at bristol.ac.uk  Fri Feb 10 19:01:21 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 10 Feb 2012 18:01:21 +0000
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CAO7JsnSDMS_unUTP+dECFJfkBnJSojkXixchyi1Y3GQVCH-1AA@mail.gmail.com>
References: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
	<FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>
	<CAO7JsnSDMS_unUTP+dECFJfkBnJSojkXixchyi1Y3GQVCH-1AA@mail.gmail.com>
Message-ID: <3C5A8FE9-5547-409A-9F65-280385DA31FA@bristol.ac.uk>

Thanks very much for the correction. Just to clarify, are you saying there are two distinct problems:

(1) The possibility of rows with both zero successes and zero failures. This seems minor--one can just check for those and exclude them if there are any, no?

(2) Even if there are no rows with zero successes and zero failures, the optimisation could converge on some very inaccurate parameter estimates, because of the problems you mention with the deviance? (I hope this is roughly the right way to express this point.)

For problems like AC's, it would be quite helpful to have confidence that the "cbind(successes, failures)" approach is trustworthy, so thanks for looking into this.

- Malcolm



On 10 Feb 2012, at 17:36, Douglas Bates wrote:

> On Fri, Feb 10, 2012 at 6:20 AM, Malcolm Fairbrother
> <m.fairbrother at bristol.ac.uk> wrote:
>> Dear AC (and perhaps Doug),
>> 
>>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>>> (assuming I need to use another program due to the size of the dataset)?
>> 
>> You may be well aware of this, but one way of substantially speeding up the estimation of models with binary data is to use "cbind", though the feasibility of this depends on the nature of the model (number of predictors and number of unique values for each predictor variable). The kind of code you need for this is below. You'll see that the fixed effects estimates, standard errors, and random effects variances turn out the same.
>> 
>>> If you would have an opportunity to run that model fit or a comparable
>>> on lme4Eigen::glmer we would appreciate information about speed,
>>> accuracy and memory usage.
>> 
>>> As a fallback, we would appreciate the code that you used to simulate
>>> the response.  We could generate something ourselves, of course, but
>>> it is easier to compare when you copy someone else's simulation.
>> 
>> I've compared the speed of lme4 versus lme4Eigen, on a simulated dataset with 100,000 observations, using a 2GHz MacBook. Based on a handful of simulations, there doesn't appear to be much difference between the two packages in terms of speed (sometimes one is faster, sometimes the other). I have reported the results of one simulation here. The two packages generate identical results for this dataset.
>> 
>> Cheers,
>> Malcolm
>> 
>> 
>> N <- 100000
>> grps <- 100
>> dat <- data.frame(x1 = sample(1:10, N, replace=T), x2 = sample(18:23, N, replace=T), grp=rep(1:grps, each=N/grps))
>> dat$y <- rbinom(N, prob = plogis(-5 + 0.1*dat$x1 + 0.2*dat$x2 + rnorm(grps)[dat$grp]), size = 1)
>> failures <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==0))
>> successes <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==1))
>> dat2 <- expand.grid(x1=sort(unique(dat$x1)), x2=sort(unique(dat$x2)), grp=sort(unique(dat$grp)))
>> dat2$failures <- as.vector(failures)
>> dat2$successes <- as.vector(successes)
>> library(lme4)
>> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
>> #   user  system elapsed
>> # 22.918   0.660  24.441
>> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
>> #   user  system elapsed
>> #  1.833   0.017   1.855
>> detach("package:lme4")
>> library(lme4Eigen)
>> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
>> #   user  system elapsed
>> # 24.824   1.811  26.773
>> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
>> #   user  system elapsed
>> #  1.687   0.039   1.723
> 
> Thanks for sending that, Malcolm.
> 
> Your collapsing of the binary responses to the number of successes and
> failures works in this case by can't be expected to work in general.
> In establishing dat2 using expand.grid you are assuming that all
> combinations of covariates occur in the data.  If not you would end up
> with a successes=0, failures=0 row and that might cause problems in
> glm or glmer finding the proportion of successes (I havent' gone back
> to look at the code to determine this).  I am trying to think of a way
> of doing this using the type of strategy in the hidden function
> duplicated.data.frame.  If you have the model frame and you know that
> there are only two unique values for the response you can get the
> counts by determining the unique combinations of covariates and using
> xtabs. If you look at duplicated.data.frame, you will see that getting
> the unique combinations is done by pasting the text representation of
> the row using a separator that will not occur in numeric data.  The C
> function do_duplicated uses hash tables and hashing a character string
> is very fast.
> 
> The end result looks like the enclosed.
> 
> Of course, there is probably a much cleaner way of doing this using
> Hadley Wickham's reshape package but I haven't studied that package
> enough yet.
> 
> As Malcolm said, the two sets of parameter estimates are very similar
> but the deviance is different.  I am working on changes that will
> create the proper value of the deviance from the model in terms of
> successes and failure.  It is very confusing - the function in the glm
> family that produces the deviance is called "aic" and the function
> called "dev.resids" actually produces the square of the deviance
> residuals and their sum should be the glm deviance, except when it
> isn't.  It's disheartening at best.
> 
> I also include a timing of the model fit using nAGQ=25 which should be
> a very accurate evaluation of the deviance.
> 
> The other version with nAGQ=0 uses a Laplace approximation and
> (approximately) profiles out the fixed-effects parameters.  In many
> situations this gets close enough to the correct deviance that the
> results can be used for rough model comparisons.
> 
> 
>>> Date: Thu, 9 Feb 2012 14:13:24 -0600
>>> From: Douglas Bates <bates at stat.wisc.edu>
>>> To: Joshua Wiley <jwiley.psych at gmail.com>
>>> Cc: AC Del Re <acdelre at stanford.edu>, r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] LMM with Big data using binary DV
>>> 
>>> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>>> Hi AC,
>>>> 
>>>> My personal preference would be glmer from the lme4 package. ?I prefer
>>>> the Laplace approximation for the likelihood over the quasilikelihood
>>>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>>>> with 2 million observations nested within 200 groups (10,000
>>>> observations per group). ?I then ran an random intercepts model using:
>>>> 
>>>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>>>> 
>>>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>>>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>>>> 
>>>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>>>> With the OS and R running, my system used ~ 6GB of RAM for the model
>>>> and went up to ~7GB to show the summary (copies of the data are
>>>> made---changed in the upcoming version of lme4).
>>>> 
>>>> So as long as you have plenty of memory, you should have no trouble
>>>> modelling your data using glmer(). ?To initially make sure all your
>>>> code works, I might use a subset of your data (say 10k), once you are
>>>> convinced you have the model you want, run it on the full data.
>>> 
>>> If you would have an opportunity to run that model fit or a comparable
>>> on lme4Eigen::glmer we would appreciate information about speed,
>>> accuracy and memory usage.
>>> 
>>> In lme4Eigen::glmer there are different levels of precision in the
>>> approximation to the deviance being optimizer.  These are controlled
>>> by the nAGQ argument to the function.  The default, nAGQ=1, uses the
>>> Laplace approximation.  The special value nAGQ=0 also uses the Laplace
>>> approximation but profiles out the fixed-effects parameters.  This
>>> profiling is not exact but usually gets you close to the optimum that
>>> you would get from nAGQ=1, but much, much faster.  In a model like
>>> this you can also use nAGQ>1 and <= 25.  On the model fits we have
>>> tried we don't see a lot of difference in timing between, say, nAGQ=9
>>> and nAGQ=25 but on a model fit like this you might.
>>> 
>>> As a fallback, we would appreciate the code that you used to simulate
>>> the response.  We could generate something ourselves, of course, but
>>> it is easier to compare when you copy someone else's simulation.
>>>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>>>> Hi,
>>>>> 
>>>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>>>> facilities) and would like to examine variability across facilities in
>>>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>>>> with patient and facility predictors of utilization.
>>>>> 
>>>>> I have 3 questions:
>>>>> 
>>>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>>>> big data (even if they are not R packages)?
>>>>> 
>>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>>> (assuming I need to use another program due to the size of the dataset)?
>>>>> 
>>>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>>>> wanting to examine? I know of two potential options (family=binomial option
>>>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>>>> appropriate or what other R packages and functions are available for this
>>>>> purpose?
>>>>> 
>>>>> Thank you,
>>>>> 
>>>>> AC
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> <Malcolm_Rout.txt><Malcolm.R>



From eder at leg.ufpr.br  Fri Feb 10 19:51:49 2012
From: eder at leg.ufpr.br (Eder David Borges da Silva)
Date: Fri, 10 Feb 2012 16:51:49 -0200
Subject: [R-sig-ME] GWS in MCMCglmm and INLA
Message-ID: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>

Dear R user,
Just to better understand the GWS (genomic Wide Select), I would like
to adjust the model by making the inference in different ways, I could
adjust using the INLA, MCMC would like to use, especially with the
function MCMCglmm, but I could not understand if this is possible, so
I want your help.
The code is:
### Sele??o Genomica Ampla - Genomic Wide Select
#browseURL('http://www.infoteca.cnptia.embrapa.br/bitstream/doc/883425/1/Doc210.pdf')
#pg 54
###-----------------------------------------------------###
rm(list=ls())
require(INLA)
require(MCMCglmm)
###-----------------------------------------------------###
dados <- data.frame(ind=c(1:5),
                    diametro=c(9.87,14.48,8.91,14.64,9.55),
                    M1=c(2,1,0,1,1),
                    M2=c(0,1,2,0,0),
                    M3=c(0,0,0,1,0),
                    M4=c(0,0,0,0,1),
                    M5=c(2,1,0,1,1),
                    M6=c(0,1,0,0,1),
                    M7=c(0,0,2,0,0))
dados
###-----------------------------------------------------###
### Create Z matrix
Z  <- as.matrix(dados[,3:ncol(dados)])
### change effects de 0 1 2 para -1 0 1
Z <- apply(Z,2,function(x) ifelse(x==1,-1, ifelse(x!=0,1,0)))
Z
###-----------------------------------------------------###
### fit in INLA
rr.inla.fit = inla(diametro ~ 1 +
f(ind,model="z",Z=Z),data=dados,family="gaussian")
summary(rr.inla.fit)
rr.inla.fit$summary.random
###-----------------------------------------------------###
### fit MCMCglmm
rr.mcmc.fit = MCMCglmm(diametro ~ 1, random = Z,data=dados,family="gaussian")
summary(rr.mcmc.fit)

random = ????

Thanks
?der David Borges da Silva



From bates at stat.wisc.edu  Fri Feb 10 21:43:04 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 10 Feb 2012 14:43:04 -0600
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <3C5A8FE9-5547-409A-9F65-280385DA31FA@bristol.ac.uk>
References: <mailman.3.1328871602.12064.r-sig-mixed-models@r-project.org>
	<FFAFEA8B-FF9F-4F5A-B7C6-0CDE7401B3D0@bristol.ac.uk>
	<CAO7JsnSDMS_unUTP+dECFJfkBnJSojkXixchyi1Y3GQVCH-1AA@mail.gmail.com>
	<3C5A8FE9-5547-409A-9F65-280385DA31FA@bristol.ac.uk>
Message-ID: <CAO7JsnTidqcX7nUkE4VYS6BUB_Ce4vOD9wmKM_E4DL9y734LMg@mail.gmail.com>

On Fri, Feb 10, 2012 at 12:01 PM, Malcolm Fairbrother
<m.fairbrother at bristol.ac.uk> wrote:
> Thanks very much for the correction. Just to clarify, are you saying there are two distinct problems:

> (1) The possibility of rows with both zero successes and zero failures. This seems minor--one can just check for those and exclude them if there are any, no?

I'm just saying that it is best to avoid the zero successes/zero
failues rows if you can.  When you use expand.grid a covariate with a
large number of unique values can inflate the size of the resulting
array substantially, possibly resulting in most of the rows having
zero successes and zero failures.  (In such cases it is doubtful that
you would achieve much of a speed-up by going to the reduced form
anyway.) That is why I would choose to use what corresponds to
obtaining the unique combinations of covariates present in the data.
You can always generate the zero successes/zero failures rows and then
filter them but that is the sort of thing that J. Edwards Deming
called "burning the toast and then scraping it".

> (2) Even if there are no rows with zero successes and zero failures, the optimisation could converge on some very inaccurate parameter estimates, because of the problems you mention with the deviance? (I hope this is roughly the right way to express this point.)

The location of the optimum is the same but, in the case of the
binomial representation the calculation of the deviance is off from
the Bernoulli representation by an additive factor.  There are
actually two issues here.  One is that the deviance for the Bernoulli
model differs from the deviance for the binomial model by

> with(dat2, 2 * sum(lchoose(success + failure, success)))
[1] 89442.18

In other words, it is twice the sum of the logarithms of the "n choose
k" terms in the binomial probability density function.  The binomial
model deviance is for all possible combinations of patterns of
successes and failures.  The Bernoulli model deviance is for the
particular pattern that you observed.

There is a further additive constant related to the fact that deviance
of the binomial model is not the sum of the squared deviance
residuals.  This is why there is another function in the family called
"aic" which, naturally, returns the deviance.

When I first wrote this reply I had a long rant in here about the
design of the glm family structure in general but that is not very
illuminating.  Suffice it to say that it is a bad design because it is
a holdover from S and S-PLUS which did not have the ability to
evaluate functions in a shared environment.

The short version of the story is that if you use the aic member
function then the deviances from the two model fits agree up to the
difference caused by the "n choose k" terms

> (gmsdb at resp$aic() + with(dat2, 2 * sum(lchoose(success + failure, success))))
[1] 112510.5
> gm01b at resp$aic()
[1] 112510.5

(Please don't go off and copy that type of code - we'll create better
extractor functions.)

> For problems like AC's, it would be quite helpful to have confidence that the "cbind(successes, failures)" approach is trustworthy, so thanks for looking into this.
>
> - Malcolm
>
>
>
> On 10 Feb 2012, at 17:36, Douglas Bates wrote:
>
>> On Fri, Feb 10, 2012 at 6:20 AM, Malcolm Fairbrother
>> <m.fairbrother at bristol.ac.uk> wrote:
>>> Dear AC (and perhaps Doug),
>>>
>>>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>>>> (assuming I need to use another program due to the size of the dataset)?
>>>
>>> You may be well aware of this, but one way of substantially speeding up the estimation of models with binary data is to use "cbind", though the feasibility of this depends on the nature of the model (number of predictors and number of unique values for each predictor variable). The kind of code you need for this is below. You'll see that the fixed effects estimates, standard errors, and random effects variances turn out the same.
>>>
>>>> If you would have an opportunity to run that model fit or a comparable
>>>> on lme4Eigen::glmer we would appreciate information about speed,
>>>> accuracy and memory usage.
>>>
>>>> As a fallback, we would appreciate the code that you used to simulate
>>>> the response. ?We could generate something ourselves, of course, but
>>>> it is easier to compare when you copy someone else's simulation.
>>>
>>> I've compared the speed of lme4 versus lme4Eigen, on a simulated dataset with 100,000 observations, using a 2GHz MacBook. Based on a handful of simulations, there doesn't appear to be much difference between the two packages in terms of speed (sometimes one is faster, sometimes the other). I have reported the results of one simulation here. The two packages generate identical results for this dataset.
>>>
>>> Cheers,
>>> Malcolm
>>>
>>>
>>> N <- 100000
>>> grps <- 100
>>> dat <- data.frame(x1 = sample(1:10, N, replace=T), x2 = sample(18:23, N, replace=T), grp=rep(1:grps, each=N/grps))
>>> dat$y <- rbinom(N, prob = plogis(-5 + 0.1*dat$x1 + 0.2*dat$x2 + rnorm(grps)[dat$grp]), size = 1)
>>> failures <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==0))
>>> successes <- by(dat, list(dat$x1, dat$x2, dat$grp), function(x) sum(x$y==1))
>>> dat2 <- expand.grid(x1=sort(unique(dat$x1)), x2=sort(unique(dat$x2)), grp=sort(unique(dat$grp)))
>>> dat2$failures <- as.vector(failures)
>>> dat2$successes <- as.vector(successes)
>>> library(lme4)
>>> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
>>> # ? user ?system elapsed
>>> # 22.918 ? 0.660 ?24.441
>>> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
>>> # ? user ?system elapsed
>>> # ?1.833 ? 0.017 ? 1.855
>>> detach("package:lme4")
>>> library(lme4Eigen)
>>> system.time(glmer(y ~ x1 + x2 + (1 | grp), dat, family=binomial))
>>> # ? user ?system elapsed
>>> # 24.824 ? 1.811 ?26.773
>>> system.time(glmer(cbind(successes, failures) ~ x1 + x2 + (1 | grp), dat2, family=binomial))
>>> # ? user ?system elapsed
>>> # ?1.687 ? 0.039 ? 1.723
>>
>> Thanks for sending that, Malcolm.
>>
>> Your collapsing of the binary responses to the number of successes and
>> failures works in this case by can't be expected to work in general.
>> In establishing dat2 using expand.grid you are assuming that all
>> combinations of covariates occur in the data. ?If not you would end up
>> with a successes=0, failures=0 row and that might cause problems in
>> glm or glmer finding the proportion of successes (I havent' gone back
>> to look at the code to determine this). ?I am trying to think of a way
>> of doing this using the type of strategy in the hidden function
>> duplicated.data.frame. ?If you have the model frame and you know that
>> there are only two unique values for the response you can get the
>> counts by determining the unique combinations of covariates and using
>> xtabs. If you look at duplicated.data.frame, you will see that getting
>> the unique combinations is done by pasting the text representation of
>> the row using a separator that will not occur in numeric data. ?The C
>> function do_duplicated uses hash tables and hashing a character string
>> is very fast.
>>
>> The end result looks like the enclosed.
>>
>> Of course, there is probably a much cleaner way of doing this using
>> Hadley Wickham's reshape package but I haven't studied that package
>> enough yet.
>>
>> As Malcolm said, the two sets of parameter estimates are very similar
>> but the deviance is different. ?I am working on changes that will
>> create the proper value of the deviance from the model in terms of
>> successes and failure. ?It is very confusing - the function in the glm
>> family that produces the deviance is called "aic" and the function
>> called "dev.resids" actually produces the square of the deviance
>> residuals and their sum should be the glm deviance, except when it
>> isn't. ?It's disheartening at best.
>>
>> I also include a timing of the model fit using nAGQ=25 which should be
>> a very accurate evaluation of the deviance.
>>
>> The other version with nAGQ=0 uses a Laplace approximation and
>> (approximately) profiles out the fixed-effects parameters. ?In many
>> situations this gets close enough to the correct deviance that the
>> results can be used for rough model comparisons.
>>
>>
>>>> Date: Thu, 9 Feb 2012 14:13:24 -0600
>>>> From: Douglas Bates <bates at stat.wisc.edu>
>>>> To: Joshua Wiley <jwiley.psych at gmail.com>
>>>> Cc: AC Del Re <acdelre at stanford.edu>, r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] LMM with Big data using binary DV
>>>>
>>>> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>>>> Hi AC,
>>>>>
>>>>> My personal preference would be glmer from the lme4 package. ?I prefer
>>>>> the Laplace approximation for the likelihood over the quasilikelihood
>>>>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>>>>> with 2 million observations nested within 200 groups (10,000
>>>>> observations per group). ?I then ran an random intercepts model using:
>>>>>
>>>>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>>>>>
>>>>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>>>>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>>>>>
>>>>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>>>>> With the OS and R running, my system used ~ 6GB of RAM for the model
>>>>> and went up to ~7GB to show the summary (copies of the data are
>>>>> made---changed in the upcoming version of lme4).
>>>>>
>>>>> So as long as you have plenty of memory, you should have no trouble
>>>>> modelling your data using glmer(). ?To initially make sure all your
>>>>> code works, I might use a subset of your data (say 10k), once you are
>>>>> convinced you have the model you want, run it on the full data.
>>>>
>>>> If you would have an opportunity to run that model fit or a comparable
>>>> on lme4Eigen::glmer we would appreciate information about speed,
>>>> accuracy and memory usage.
>>>>
>>>> In lme4Eigen::glmer there are different levels of precision in the
>>>> approximation to the deviance being optimizer. ?These are controlled
>>>> by the nAGQ argument to the function. ?The default, nAGQ=1, uses the
>>>> Laplace approximation. ?The special value nAGQ=0 also uses the Laplace
>>>> approximation but profiles out the fixed-effects parameters. ?This
>>>> profiling is not exact but usually gets you close to the optimum that
>>>> you would get from nAGQ=1, but much, much faster. ?In a model like
>>>> this you can also use nAGQ>1 and <= 25. ?On the model fits we have
>>>> tried we don't see a lot of difference in timing between, say, nAGQ=9
>>>> and nAGQ=25 but on a model fit like this you might.
>>>>
>>>> As a fallback, we would appreciate the code that you used to simulate
>>>> the response. ?We could generate something ourselves, of course, but
>>>> it is easier to compare when you copy someone else's simulation.
>>>>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>>>>> facilities) and would like to examine variability across facilities in
>>>>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>>>>> with patient and facility predictors of utilization.
>>>>>>
>>>>>> I have 3 questions:
>>>>>>
>>>>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>>>>> big data (even if they are not R packages)?
>>>>>>
>>>>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>>>>> data, etc) that would allow me to use only R packages to run this dataset
>>>>>> (assuming I need to use another program due to the size of the dataset)?
>>>>>>
>>>>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>>>>> wanting to examine? I know of two potential options (family=binomial option
>>>>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>>>>> appropriate or what other R packages and functions are available for this
>>>>>> purpose?
>>>>>>
>>>>>> Thank you,
>>>>>>
>>>>>> AC
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> <Malcolm_Rout.txt><Malcolm.R>
>



From m.fenati at libero.it  Sat Feb 11 10:00:54 2012
From: m.fenati at libero.it (m.fenati at libero.it)
Date: Sat, 11 Feb 2012 10:00:54 +0100 (CET)
Subject: [R-sig-ME] ghlt different results for different hypotheses?
Message-ID: <17179796.25708831328950854693.JavaMail.defaultUser@defaultHost>

Thanks a lot also for your good example!

Regards

Massimo


>----Messaggio originale----
>Da: 538280 at gmail.com
>Data: 10/02/2012 18.36
>A: "m.fenati at libero.it"<m.fenati at libero.it>
>Cc: <r-sig-mixed-models at r-project.org>
>Ogg: Re: [R-sig-ME] ghlt different results for different hypotheses?
>
>The more comparisons/tests that you do the more opportunities you have
>of getting a type I error.  The multiple comparisons procedures adjust
>for the number of comparisons so that the overall probability of
>making at least 1 type I error is fixed.  So the more comparisons the
>more adjustment needs to be made.
>
>Think of this simple example.  You are playing a game where you are
>trying to throw a wadded up piece of paper into a basket, you win if
>you get it in at least once.  What are your chances of winning if you
>get 10 tries compared to if you get 20 tries (from the same spot)?  If
>you want the same chance of winning with 20 tries as you had for 10
>tries (or 1 try), then you need to move further away or some other
>penalty.
>
>So with glht there is a bigger penalty when you do more comparisons
>since there are more opportunities of making a type I error.
>
>On Thu, Feb 9, 2012 at 3:25 AM, m.fenati at libero.it <m.fenati at libero.it> 
wrote:
>>
>>
>> Dear R users,
>> I would like to understand a simple problem related to glht() multeplicity 
correction and linear Hypotheses testing. Given a simple lme model with two 
predictors (group = 3 levels; time = ?2 levels) and their interaction with 
treatment contrast, I see that the p-values are lower and higher when I test 
few or many hypotheses respectively. Because I dont't have a deep knowledge of 
multiple comparison theory, I ask you some suggestion or explanation about the 
different obtained results.
>> As you can see in the example below, "m1" and "m2" test a different number 
of hypotheses but comparing the same hypothesis a different results occurred.
>>
>>
>> time<-rep(c(rep(0,8),rep(1,8)),3)
>> group<-c(rep(0,16),rep(1,16),rep(2,16))
>> id<-c(rep(1:8,2),rep(9:16,2),rep(17:24,2))
>> w<-c(172.9, 185.8, 173.1, 187.3, 161.6, 167.1, 168.4, 161.1, 166.5, 175.3, 
167.1, 181.9, 163.0, 167.7, 172.1, 170.3, 167.2, 183.3, 160.7,167.8, 149.6, 
159.1, 164.2, 171.0, 168.6, 173.5, 161.8, 166.5, 148.4, 167.1, 166.8, 166.6, 
150.6, 178.4, 166.4, 159.2, 163.2, 167.8, 136.6, 161.8, 166.1, 175.8, 175.6, 
166.2, 168.5, 170.5, 152.0, 164.4)
>> dati<-data.frame(time,group,id,w)
>> dati$time<-as.factor(dati$time)
>> dati$group<-as.factor(dati$group)
>> dati$id<-as.factor(dati$id)
>>
>>
>>
>>
>> kp<-rbind("after Treatment: Group 1 - Controls"=c(0,1,0,0,0,0),
>> ? ? ? ? "after Treatment: Group 2 - Controls"=c(0,0,1,0,0,0),
>> ? ? ? ? "before Treatment: Group 1 - Controls"=c(0,1,0,0,1,0),
>> ? ? ? ? "before Treatment: Group 2 - Controls"=c(0,0,1,0,0,1),
>> ? ? ? ? "Controls: time trend (T1 - T0)"=c(0,0,0,-1,0,0),
>> ? ? ? ? "Group 1: time trend (T1 - T0)"=c(0,0,0,-1,-1,0),
>> ? ? ? ? "Group 2: time trend (T1 - T0)"=c(0,0,0,-1,0,-1))
>>
>>
>> k<-rbind("after Treatment: Group 1 - Controls"=c(0,1,0,0,0,0),
>> ? ? ? ? "after Treatment: Group 2 - Controls"=c(0,0,1,0,0,0),
>> ? ? ? ? "before Treatment: Group 1 - Controls"=c(0,1,0,0,1,0),
>> ? ? ? ? "before Treatment: Group 2 - Controls"=c(0,0,1,0,0,1)
>> ? ? ? ? )
>>
>>
>>
>>
>> w.lme<-lme(w~group*time,data=dati,random=~1|id)
>> m1<-summary(glht(w.lme,kp))
>> m2<-summary(glht(w.lme,k))
>>
>>
>> Thank in advances for your suggestions
>>
>>
>> Massimo
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>-- 
>Gregory (Greg) L. Snow Ph.D.
>538280 at gmail.com
>



From fan.mongxie at gmail.com  Sat Feb 11 11:12:51 2012
From: fan.mongxie at gmail.com (Fan Mongxie)
Date: Sat, 11 Feb 2012 11:12:51 +0100
Subject: [R-sig-ME] lmer correlation btw random effects
Message-ID: <CAAZy3PAg=nHwex+qUQ4ZN5cvBwsF9dSwzXfFDEgaVLTxROtShA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120211/3316b920/attachment-0002.pl>

From j.hadfield at ed.ac.uk  Sat Feb 11 16:15:37 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 11 Feb 2012 15:15:37 +0000
Subject: [R-sig-ME] GWS in MCMCglmm and INLA
In-Reply-To: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>
Message-ID: <20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>

Hi,

dados$Z<-Z
rr.mcmc.fit<-MCMCglmm(diametro~1,random=~idv(Z),data=dados,family="gaussian")

would be one way of dong it. Not very efficient for setting up the  
model, but once MCMCing it should be OK.

Cheers,

Jarrod

Quoting Eder David Borges da Silva <eder at leg.ufpr.br> on Fri, 10 Feb  
2012 16:51:49 -0200:

> Dear R user,
> Just to better understand the GWS (genomic Wide Select), I would like
> to adjust the model by making the inference in different ways, I could
> adjust using the INLA, MCMC would like to use, especially with the
> function MCMCglmm, but I could not understand if this is possible, so
> I want your help.
> The code is:
> ### Sele??o Genomica Ampla - Genomic Wide Select
> #browseURL('http://www.infoteca.cnptia.embrapa.br/bitstream/doc/883425/1/Doc210.pdf')
> #pg 54
> ###-----------------------------------------------------###
> rm(list=ls())
> require(INLA)
> require(MCMCglmm)
> ###-----------------------------------------------------###
> dados <- data.frame(ind=c(1:5),
>                     diametro=c(9.87,14.48,8.91,14.64,9.55),
>                     M1=c(2,1,0,1,1),
>                     M2=c(0,1,2,0,0),
>                     M3=c(0,0,0,1,0),
>                     M4=c(0,0,0,0,1),
>                     M5=c(2,1,0,1,1),
>                     M6=c(0,1,0,0,1),
>                     M7=c(0,0,2,0,0))
> dados
> ###-----------------------------------------------------###
> ### Create Z matrix
> Z  <- as.matrix(dados[,3:ncol(dados)])
> ### change effects de 0 1 2 para -1 0 1
> Z <- apply(Z,2,function(x) ifelse(x==1,-1, ifelse(x!=0,1,0)))
> Z
> ###-----------------------------------------------------###
> ### fit in INLA
> rr.inla.fit = inla(diametro ~ 1 +
> f(ind,model="z",Z=Z),data=dados,family="gaussian")
> summary(rr.inla.fit)
> rr.inla.fit$summary.random
> ###-----------------------------------------------------###
> ### fit MCMCglmm
> rr.mcmc.fit = MCMCglmm(diametro ~ 1, random =  
> Z,data=dados,family="gaussian")
> summary(rr.mcmc.fit)
>
> random = ????
>
> Thanks
> ?der David Borges da Silva
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From tulsipaudel at hotmail.com  Fri Feb 10 16:04:07 2012
From: tulsipaudel at hotmail.com (Tulsi Paudel)
Date: Fri, 10 Feb 2012 07:04:07 -0800
Subject: [R-sig-ME] mixed model-request for help
In-Reply-To: <BAY155-W5E044C71A2AA23214D496B1780@phx.gbl>
References: <BAY155-W5E044C71A2AA23214D496B1780@phx.gbl>
Message-ID: <BAY155-W71C2F8B88C6FBBE20AE10B1780@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120210/9cdb1717/attachment-0002.pl>

From ruzong.fan at nih.gov  Sun Feb 12 00:58:52 2012
From: ruzong.fan at nih.gov (Fan, Ruzong (NIH/NICHD) [E])
Date: Sat, 11 Feb 2012 18:58:52 -0500
Subject: [R-sig-ME] generalized linear mixed model for qualitative in R
Message-ID: <C9106BA831B26B4DA4E7B9054C1A705341107A43@NIHMLBX12.nih.gov>

Dear folks,

I wonder if  glmer can we do spline or model correlation for longitudinal data?

In lme, it is possible to do both spline and model correlation. For instance, I wrote a short codes as below: 
#################################################################
fit1E  <- lme( sbp ~ -1 + X.mean,
                random      = list(group = pdIdent(~-1+Z.mean), 
                                      id = ~1),
                correlation = corExp(form = ~ x | group/id), 
                    na.action   = na.exclude,
                method      = "ML",
                subset      = notmissing )
#################################################################
Basically, 'X.mean' models the fixed effect, and `Z.mean' models the spline random effect. The above codes will lead to 3 random variance estimations: one from Z.mean, one from id, and the other from the residual. 

In addition, 'correlation = corExp(form = ~ x | group/id)' models the correlation. 

I don't see there is something like `random = list( ... )' in glmer. So I am not sure how to do spline using glmer. 

Plus, I don't find similar things like `correlation = corExp(form = ~ x | group/id)' in glmer to model correlation?

Thanks. R.F


From eder at leg.ufpr.br  Sun Feb 12 19:46:23 2012
From: eder at leg.ufpr.br (Eder David Borges da Silva)
Date: Sun, 12 Feb 2012 16:46:23 -0200
Subject: [R-sig-ME] GWS in MCMCglmm and INLA
In-Reply-To: <20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>
	<20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>
Message-ID: <CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>

Thanks Jarrod,
My comparisons between MCMC and INLA worked perfectly
Thank you
?der

2012/2/11 Jarrod Hadfield <j.hadfield at ed.ac.uk>:
> Hi,
>
> dados$Z<-Z
> rr.mcmc.fit<-MCMCglmm(diametro~1,random=~idv(Z),data=dados,family="gaussian")
>
> would be one way of dong it. Not very efficient for setting up the model,
> but once MCMCing it should be OK.
>
> Cheers,
>
> Jarrod
>
>
> Quoting Eder David Borges da Silva <eder at leg.ufpr.br> on Fri, 10 Feb 2012
> 16:51:49 -0200:
>
>> Dear R user,
>> Just to better understand the GWS (genomic Wide Select), I would like
>> to adjust the model by making the inference in different ways, I could
>> adjust using the INLA, MCMC would like to use, especially with the
>> function MCMCglmm, but I could not understand if this is possible, so
>> I want your help.
>> The code is:
>> ### Sele??o Genomica Ampla - Genomic Wide Select
>>
>> #browseURL('http://www.infoteca.cnptia.embrapa.br/bitstream/doc/883425/1/Doc210.pdf')
>> #pg 54
>> ###-----------------------------------------------------###
>> rm(list=ls())
>> require(INLA)
>> require(MCMCglmm)
>> ###-----------------------------------------------------###
>> dados <- data.frame(ind=c(1:5),
>> ? ? ? ? ? ? ? ? ? ?diametro=c(9.87,14.48,8.91,14.64,9.55),
>> ? ? ? ? ? ? ? ? ? ?M1=c(2,1,0,1,1),
>> ? ? ? ? ? ? ? ? ? ?M2=c(0,1,2,0,0),
>> ? ? ? ? ? ? ? ? ? ?M3=c(0,0,0,1,0),
>> ? ? ? ? ? ? ? ? ? ?M4=c(0,0,0,0,1),
>> ? ? ? ? ? ? ? ? ? ?M5=c(2,1,0,1,1),
>> ? ? ? ? ? ? ? ? ? ?M6=c(0,1,0,0,1),
>> ? ? ? ? ? ? ? ? ? ?M7=c(0,0,2,0,0))
>> dados
>> ###-----------------------------------------------------###
>> ### Create Z matrix
>> Z ?<- as.matrix(dados[,3:ncol(dados)])
>> ### change effects de 0 1 2 para -1 0 1
>> Z <- apply(Z,2,function(x) ifelse(x==1,-1, ifelse(x!=0,1,0)))
>> Z
>> ###-----------------------------------------------------###
>> ### fit in INLA
>> rr.inla.fit = inla(diametro ~ 1 +
>> f(ind,model="z",Z=Z),data=dados,family="gaussian")
>> summary(rr.inla.fit)
>> rr.inla.fit$summary.random
>> ###-----------------------------------------------------###
>> ### fit MCMCglmm
>> rr.mcmc.fit = MCMCglmm(diametro ~ 1, random = Z
>> ,data=dados,family="gaussian")
>> summary(rr.mcmc.fit)
>>
>> random = ????
>>
>> Thanks
>> ?der David Borges da Silva
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>



From raptorbio at hotmail.com  Sun Feb 12 20:35:11 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Sun, 12 Feb 2012 14:35:11 -0500
Subject: [R-sig-ME] Considerable discrepancies between fixed and random
 effect estimates of lme4 (glmer) and glmmADMB
In-Reply-To: <CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>,
	<20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>,
	<CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>
Message-ID: <BAY170-W1321C2FA87E1FAFC47F40CDA17E0@phx.gbl>


I hope I'm not overlooking something elementary here, but estimated fixed and random effects are considerably different from the following Poisson model in lme4 and glmmADMB.? The fixed effects seem to differ most considerably...? Thanks for any thoughts...

Adam Smith

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-pc-mingw32/x64 (64-bit)

(SNIP)

other attached packages:
[1] glmmADMB_0.7.2.5?? lme4_0.999375-42?? Matrix_1.0-3?????? bbmle_1.0.4.1????? numDeriv_2010.11-1
[6] lattice_0.20-0???? R2admb_0.7.5?????? MASS_7.3-16?????? 

> str(cons09) # The dataset
'data.frame':?? 394 obs. of? 15 variables:
?$ plot?????? : Factor w/ 16 levels "n_10","n_2","n_3",..: 2 2 2 2 2 2 2 2 2 2 ...
?$ plot_trt?? : Factor w/ 32 levels "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
?$ geog?????? : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
?$ trt??????? : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
?$ count????? : Factor w/ 14 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
?$ total????? : int? 341 326 257 244 185 141 128 121 115 84 ...
?$ cons?????? : int? 12 52 8 57 36 8 0 1 20 27 ...
?$ dt???????? : int? 4 3 3 3 3 3 3 3 3 3 ...
?$ obs??????? : Factor w/ 394 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
?$ logtotal?? : num? 5.83 5.79 5.55 5.5 5.22 ...
?$ logdt????? : num? 1.39 1.1 1.1 1.1 1.1 ...

# The models
> Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt + count:geog + trt:geog + offset(logtotal) +
??? ??? offset(logdt) + (1|plot) + (1|plot_trt), zeroInflation=FALSE, family="poisson", data=cons09)

> P_glmer <- glmer(cons ~ count + geog + trt + count:trt + count:geog + trt:geog + offset(log(total)) +
??? ? offset(log(dt)) + (1|plot) + (1|plot_trt), family="poisson", data=cons09)

> fixef(Poiss)
?? (Intercept)???????? count2???????? count3???????? count4???????? count5???????? count6???????? count7???????? count8???????? count9??????? count10??????? count11??????? count12 
?????? 0.77333??????? 0.58885?????? -0.21547??????? 0.79101??????? 0.24924?????? -0.02565??????? 0.36004?????? -0.94852??????? 0.39442??????? 0.29032??????? 0.13658?????? -0.39564 
?????? count13??????? count14????????? geogs???????? trttrt? count2:trttrt? count3:trttrt? count4:trttrt? count5:trttrt? count6:trttrt? count7:trttrt? count8:trttrt? count9:trttrt 
????? -1.37470?????? -0.88496?????? -0.53259?????? -0.25434?????? -0.41033??????? 1.18840??????? 0.25678??????? 0.69734??????? 0.59823??????? 1.11430?????? -0.17330?????? -0.15364 
count10:trttrt count11:trttrt count12:trttrt count13:trttrt count14:trttrt?? count2:geogs?? count3:geogs?? count4:geogs?? count5:geogs?? count6:geogs?? count7:geogs?? count8:geogs 
?????? 0.98442??????? 0.51533?????? -0.99431?????? -1.63920?????? -0.40455?????? -1.55670??????? 0.15891??????? 0.35378??????? 0.45748??????? 0.92293??????? 0.78373??????? 1.05440 
? count9:geogs? count10:geogs? count11:geogs? count12:geogs? count13:geogs? count14:geogs?? geogs:trttrt 
?????? 0.39598??????? 0.32019??????? 1.41600??????? 0.86656??????? 2.45790??????? 1.07350?????? -0.31149 

# After detaching glmmADMB and lme4, then re-requiring lme4 to avoid masking of lme4's fixef function
> fixef(P_glmer)
?? (Intercept)???????? count2???????? count3???????? count4???????? count5???????? count6???????? count7???????? count8???????? count9??????? count10??????? count11??????? count12 
?? -5.00326871???? 0.69554781???? 0.17105622???? 1.29467717???? 0.97268949???? 0.87707266???? 1.39399967???? 0.22923370???? 1.61829807???? 1.84546906???? 1.99506279???? 1.37859852 
?????? count13??????? count14????????? geogs???????? trttrt? count2:trttrt? count3:trttrt? count4:trttrt? count5:trttrt? count6:trttrt? count7:trttrt? count8:trttrt? count9:trttrt 
??? 0.53987085???? 1.13282524??? -0.12901214???? 0.07021103??? -0.52669841???? 0.87378323???? 0.05397134???? 0.46901053???? 0.39863837???? 0.94486828??? -0.18146287??? -0.20340655 
count10:trttrt count11:trttrt count12:trttrt count13:trttrt count14:trttrt?? count2:geogs?? count3:geogs?? count4:geogs?? count5:geogs?? count6:geogs?? count7:geogs?? count8:geogs 
??? 0.77866847???? 0.49935778??? -0.65101999??? -1.05381279??? -0.05290984??? -1.54103716??? -0.03887633???? 0.04570463???? 0.02076874???? 0.47883964???? 0.23057821???? 0.49408747 
? count9:geogs? count10:geogs? count11:geogs? count12:geogs? count13:geogs? count14:geogs?? geogs:trttrt 
?? -0.15116087??? -0.32683907???? 0.50098187???? 0.14670125???? 1.63961096???? 0.40944384??? -0.22555478 

I juxtapose ranef() estimates here for comparison's sake...

> ranef(Poiss)$plot
?????? (Intercept)
n_10 -0.0943733643
n_2?? 0.1849966635
n_3?? 0.1925622397
n_4? -0.1873429084
n_5? -0.0522031304
n_6? -0.2297389315
n_7?? 0.1648785136
n_8?? 0.0944159043
n_9? -0.0556750492
s_1? -0.3023318134
s_2?? 0.0970108446
s_3? -0.2753679950
s_5?? 0.0909701639
s_6?? 0.4699361596
s_7? -0.0634075132
s_8?? 0.0007413087

> ranef(P_glmer)$plot

???? (Intercept)

n_10 -0.39846683

n_2?? 0.04002750

n_3?? 0.61876383

n_4? -0.15421355

n_5? -0.46932629

n_6? -0.40931865

n_7?? 0.97591378

n_8?? 0.10866846

n_9? -0.28021810

s_1? -0.17423214

s_2? -0.19732599

s_3? -0.85567064

s_5?? 0.12795497

s_6?? 1.34047871

s_7? -0.27174719

s_8?? 0.06440244

>ranef(Poiss)$plot_trt
????????? (Intercept)
cont_n_10 -0.35187629
cont_n_2?? 0.59527239
cont_n_3?? 0.85766093
cont_n_4? -0.53814502
cont_n_5? -0.66935729
cont_n_6? -0.26606817
cont_n_7?? 0.80261648
cont_n_8?? 0.02233052
cont_n_9? -0.41806768
cont_s_1? -0.23483630
cont_s_2? -0.02224468
cont_s_3? -0.17660444
cont_s_5? -0.58505585
cont_s_6?? 1.49490396
cont_s_7?? 0.07621585
cont_s_8? -0.52568948
trt_n_10?? 0.03431004
trt_n_2??? 0.02722629
trt_n_3?? -0.20972715
trt_n_4?? -0.09225497
trt_n_5??? 0.49368927
trt_n_6?? -0.50699118
trt_n_7?? -0.24780806
trt_n_8??? 0.29537319
trt_n_9??? 0.23071847
trt_s_1?? -0.78250755
trt_s_2??? 0.34867686
trt_s_3?? -0.74997310
trt_s_5??? 0.89115581
trt_s_6??? 0.08645040
trt_s_7?? -0.28957461
trt_s_8??? 0.52818059

> ranef(P_glmer)$plot_trt
??????????? (Intercept)
cont_n_10 -0.4813895272
cont_n_2?? 0.6307028124
cont_n_3?? 0.5442036884
cont_n_4? -0.5256622000
cont_n_5? -0.6562034135
cont_n_6?? 0.1186249885
cont_n_7?? 1.0098808410
cont_n_8? -0.2196620296
cont_n_9? -0.3985906214
cont_s_1? -0.1821209263
cont_s_2? -0.5517396588
cont_s_3?? 0.1368254894
cont_s_5? -0.1701340605
cont_s_6?? 1.8066871045
cont_s_7? -0.5317778373
cont_s_8? -0.4961046022
trt_n_10?? 0.0668058960
trt_n_2?? -0.5890563232
trt_n_3??? 0.0995873106
trt_n_4??? 0.3652111668
trt_n_5??? 0.1678942605
trt_n_6?? -0.5444993690
trt_n_7??? 0.0055057682
trt_n_8??? 0.3327258112
trt_n_9??? 0.1070385259
trt_s_1??? 0.0008416109
trt_s_2??? 0.3464324210
trt_s_3?? -1.0271054737
trt_s_5??? 0.3032644345
trt_s_6?? -0.4119899922
trt_s_7??? 0.2490392783
trt_s_8??? 0.5631119264

 		 	   		  


From Nick.Masca at effem.com  Mon Feb 13 13:33:42 2012
From: Nick.Masca at effem.com (Masca, Nick)
Date: Mon, 13 Feb 2012 12:33:42 +0000
Subject: [R-sig-ME] Comparing against a negative control in an LMM
Message-ID: <8295A4D50D4C644CAC4323DD070D9597106F2D@034-CH1MPN1-014.034d.mgd.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120213/e354dc21/attachment-0002.pl>

From agostino.moro99 at gmail.com  Mon Feb 13 16:02:20 2012
From: agostino.moro99 at gmail.com (Agostino Moro)
Date: Mon, 13 Feb 2012 15:02:20 +0000
Subject: [R-sig-ME] MCMCglmm with cross-classified random effects
In-Reply-To: <CAMS_pxuWBRgPZptGEoyJ7Cxvf1389jghA-6q_mBZN-23vM12cg@mail.gmail.com>
References: <CAMS_pxuWBRgPZptGEoyJ7Cxvf1389jghA-6q_mBZN-23vM12cg@mail.gmail.com>
Message-ID: <CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA@mail.gmail.com>

Dear R-users,

I would like to fit ?a glmm with cross-classified random effects with
the function MCMCglmm. Something along the lines:

model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)

where re1 and re2 should be crossed random effects. I was wondering
whether you could tell me specifying cross-classified random effects
in MCMCglmm requires a particular syntax? Are there any examples
somewhere? I have had a look at the manual and the package vignette,
but I have not been able to find any examples relevant to what I want
to do.

Thanks,

Agostino



From j.hadfield at ed.ac.uk  Mon Feb 13 16:19:07 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 13 Feb 2012 15:19:07 +0000
Subject: [R-sig-ME] MCMCglmm with cross-classified random effects
In-Reply-To: <CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA@mail.gmail.com>
References: <CAMS_pxuWBRgPZptGEoyJ7Cxvf1389jghA-6q_mBZN-23vM12cg@mail.gmail.com>
	<CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA@mail.gmail.com>
Message-ID: <20120213151907.57957fqy2tmlxcg8@www.staffmail.ed.ac.uk>

Hi,

As long as the levels of re1 and re2 are uniquely labelled any cross  
classification will be dealt with appropriately.

Cheers,

Jarrod


Quoting Agostino Moro <agostino.moro99 at gmail.com> on Mon, 13 Feb 2012  
15:02:20 +0000:

> Dear R-users,
>
> I would like to fit ?a glmm with cross-classified random effects with
> the function MCMCglmm. Something along the lines:
>
> model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)
>
> where re1 and re2 should be crossed random effects. I was wondering
> whether you could tell me specifying cross-classified random effects
> in MCMCglmm requires a particular syntax? Are there any examples
> somewhere? I have had a look at the manual and the package vignette,
> but I have not been able to find any examples relevant to what I want
> to do.
>
> Thanks,
>
> Agostino
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Mon Feb 13 17:43:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 13 Feb 2012 16:43:51 +0000 (UTC)
Subject: [R-sig-ME] Considerable discrepancies between fixed and random
	effect estimates of lme4 (glmer) and glmmADMB
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>,
	<20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>,
	<CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>
	<BAY170-W1321C2FA87E1FAFC47F40CDA17E0@phx.gbl>
Message-ID: <loom.20120213T045329-772@post.gmane.org>

Adam Smith <raptorbio at ...> writes:

 
> I hope I'm not overlooking something elementary here, but estimated
> fixed and random effects are considerably different from the
> following Poisson model in lme4 and glmmADMB.? The fixed effects
> seem to differ most considerably...? Thanks for any thoughts...
> Adam Smith

> > sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> (SNIP)
> 
> other attached packages:
> [1] glmmADMB_0.7.2.5?? lme4_0.999375-42?? Matrix_1.0-3??????
bbmle_1.0.4.1????? numDeriv_2010.11-1
> [6] lattice_0.20-0???? R2admb_0.7.5?????? MASS_7.3-16?????? 

 
> > str(cons09) # The dataset
> 'data.frame':?? 394 obs. of? 15 variables:
> ?$ plot?????? : Factor w/ 16 levels "n_10","n_2","n_3",..: 
> 2 2 2 2 2 2 2 2 2 2 ...
> ?$ plot_trt?? : Factor w/ 32 levels 
> "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
> ?$ geog?????? : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ trt??????? : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ count????? : Factor w/ 14 levels "1","2","3","4",..:
>  1 2 3 4 5 6 7 8 9 10 ...
> ?$ total????? : int? 341 326 257 244 185 141 128 121 115 84 ...
> ?$ cons?????? : int? 12 52 8 57 36 8 0 1 20 27 ...
> ?$ dt???????? : int? 4 3 3 3 3 3 3 3 3 3 ...
> ?$ obs??????? : Factor w/ 394 levels "1","2","3","4",..: 
> 1 2 3 4 5 6 7 8 9 10 ...
> ?$ logtotal?? : num? 5.83 5.79 5.55 5.5 5.22 ...
> ?$ logdt????? : num? 1.39 1.1 1.1 1.1 1.1 ...

 
> # The models
> > Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt + 
> count:geog + trt:geog + offset(logtotal) +
> ??? ??? offset(logdt) + (1|plot) + (1|plot_trt),
>  zeroInflation=FALSE, family="poisson", data=cons09)
> 
> > P_glmer <- glmer(cons ~ count + geog + trt + 
> count:trt + count:geog + trt:geog + offset(log(total)) +
> ??? ? offset(log(dt)) + (1|plot) + 
> (1|plot_trt), family="poisson", data=cons09)
 
By the way, you can specify these fixed effects 
more compactly as (count+geog+trt)^2 ...

> > fixef(Poiss)

>   0.77333  0.58885  -0.21547 0.79101  0.24924  -0.02565  0.36004 
> -0.94852  0.39442  0.29032  0.13658 -0.39564 
>   -1.37470  -0.88496  -0.53259  -0.25434 
> -0.41033  1.18840  0.25678  0.69734 
> 0.59823  1.11430  -0.17330  -0.15364 
>   0.98442  0.51533  -0.99431 -1.63920  -0.40455  -1.55670  0.15891 
> 0.35378  0.45748  0.92293  0.78373 1.05440 
>   0.39598  0.32019  1.41600 
> 0.86656  2.45790  1.07350  -0.31149 

> # After detaching glmmADMB and lme4, then 
> re-requiring lme4 to avoid masking of lme4's fixef function
> > fixef(P_glmer)
>   -5.00326871  0.69554781  0.17105622  1.29467717 
> 0.97268949  0.87707266  1.39399967  0.22923370 
> 1.61829807  1.84546906  1.99506279  1.37859852 
>   0.53987085  1.13282524  -0.12901214  0.07021103 
> -0.52669841  0.87378323  0.05397134  0.46901053 
> 0.39863837  0.94486828  -0.18146287  -0.20340655 
>   0.77866847  0.49935778  -0.65101999  -1.05381279 
> -0.05290984  -1.54103716  -0.03887633  0.04570463  0.02076874 
> 0.47883964  0.23057821  0.49408747 
>   -0.15116087  -0.32683907  0.50098187  0.14670125 
> 1.63961096  0.40944384  -0.22555478 
> 
> I juxtapose ranef() estimates here for comparison's sake...
> 
  [snip]

  There's nothing obviously wrong here.  It's not a full solution,
but I wonder how wide the confidence intervals are ... if they
are very wide, then the practical answer is that these are poorly
determined estimates.  You're probably overfitting the model --
2 random effects plus 43 fixed-effect coefficients is
quite a lot for 394 observations (the general rule of thumb
is N/(# params)>10), especially if the Poisson data are sparse
(although they don't look that way from the first few
values listed in str() -- is there anyway you can allow
'count' to be continuous, or ordinal, rather than insisting
on it being categorical?) But it would be best to try to answer
more definitively ... can you send data?

  Ben Bolker



From zt020200 at gmail.com  Mon Feb 13 18:22:24 2012
From: zt020200 at gmail.com (Tao Zhang)
Date: Mon, 13 Feb 2012 09:22:24 -0800
Subject: [R-sig-ME] Any package for best subset selection for random effects
	model
Message-ID: <CADMWRionUd97x-oUuUqj0nUStGiSZohudJLVh4kctEY0tC8=cw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120213/f23e37be/attachment-0002.pl>

From gangchen6 at gmail.com  Mon Feb 13 19:41:43 2012
From: gangchen6 at gmail.com (Gang Chen)
Date: Mon, 13 Feb 2012 13:41:43 -0500
Subject: [R-sig-ME] Interpretation of nonlinear mixed-effects modeling
	results
Message-ID: <CAHmzXO6hydefDRtcZAgbuHBhiJXGfM6zDxDfPkP=k8LouY5suQ@mail.gmail.com>

I'm fitting a nonlinear mixed-effects model to some data with two
groups (controls and patients) with something like

fm <- nlme(response ~  myFunc(time, a, b), data=myData, fixed = a + b
~ group, start=...)

myFunc is a nonlinear function defined with two parameters a and b.
I'm very confused with the results between summary(fm) and anova(fm):

> summary(fm)

...
Fixed effects: a + b ~ group
                        Value       Std.Error   DF     t-value      p-value
a.(Intercept) 29.905889 10.532769 2196  2.839319  0.0046
a.groupPat     6.437218 16.045223 2196  0.401192  0.6883
b.(Intercept)  0.290943  0.072544 2196  4.010559  0.0001
b.groupPat    -0.138361  0.077339 2196 -1.789010  0.0738
...

> anova(fm)
                 numDF denDF  F-value p-value
a.(Intercept)     1  2196 497.8594  <.0001
a.group           1  2196  12.6109  0.0004
b.(Intercept)     1  2196  45.2787  <.0001
b.group           1  2196   3.2006  0.0738

If I understand it correctly, the last row in the fixed effects table
of summary(fm) is the difference in parameter b between the two
groups, and the t-statistic (and p-value) matches the F-statistic (and
p-value) from the last row of anova(fm): (-1.789010)^2 = 3.2006.
However, I'm totally at a loss for the other three rows in the two
tables? For example, I thought a.groupPat (2nd row) in the summary(fm)
table is the amount in parameter a in Patient group that is more than
parameter a in the Control group (1st row); but this interpretation is
not consistent with what is shown in the 2nd row of anova(fm) table.
What am I missing here?

Thanks,
Gang



From raptorbio at hotmail.com  Mon Feb 13 20:06:57 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Mon, 13 Feb 2012 14:06:57 -0500
Subject: [R-sig-ME] Considerable discrepancies between fixed and random
 effect estimates of lme4 (glmer) and glmmADMB
In-Reply-To: <loom.20120213T045329-772@post.gmane.org>
References: <CALKkXXriTg4dVNKf5FStzCWbJ+Qkk4EuEc+pZPhkQJs=pvvbmw@mail.gmail.com>,
	, <20120211151537.17044ns3fi7duz2o@www.staffmail.ed.ac.uk>, ,
	<CALKkXXrZhkMXKN4ZntXRZq31Srsu+=bcy=pHz+JEat80KsYXpQ@mail.gmail.com>,
	<BAY170-W1321C2FA87E1FAFC47F40CDA17E0@phx.gbl>,
	<loom.20120213T045329-772@post.gmane.org>
Message-ID: <BAY170-W29F87F0CC98BFF5E9B7F8EA17F0@phx.gbl>



> > I hope I'm not overlooking something elementary here, but estimated
> > fixed and random effects are considerably different from the
> > following Poisson model in lme4 and glmmADMB.  The fixed effects
> > seem to differ most considerably...  Thanks for any thoughts...
> > Adam Smith
>
> > > sessionInfo()
> > R version 2.14.1 (2011-12-22)
> > Platform: x86_64-pc-mingw32/x64 (64-bit)
> >
> > (SNIP)
> >
> > other attached packages:
> > [1] glmmADMB_0.7.2.5   lme4_0.999375-42   Matrix_1.0-3
> bbmle_1.0.4.1      numDeriv_2010.11-1
> > [6] lattice_0.20-0     R2admb_0.7.5       MASS_7.3-16
>
>
> > > str(cons09) # The dataset
> > 'data.frame':   394 obs. of  15 variables:
> >  $ plot       : Factor w/ 16 levels "n_10","n_2","n_3",..:
> > 2 2 2 2 2 2 2 2 2 2 ...
> >  $ plot_trt   : Factor w/ 32 levels
> > "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
> >  $ geog       : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
> >  $ trt        : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
> >  $ count      : Factor w/ 14 levels "1","2","3","4",..:
> > 1 2 3 4 5 6 7 8 9 10 ...
> >  $ total      : int  341 326 257 244 185 141 128 121 115 84 ...
> >  $ cons       : int  12 52 8 57 36 8 0 1 20 27 ...
> >  $ dt         : int  4 3 3 3 3 3 3 3 3 3 ...
> >  $ obs        : Factor w/ 394 levels "1","2","3","4",..:
> > 1 2 3 4 5 6 7 8 9 10 ...
> >  $ logtotal   : num  5.83 5.79 5.55 5.5 5.22 ...
> >  $ logdt      : num  1.39 1.1 1.1 1.1 1.1 ...
>
>
> > # The models
> > > Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt +
> > count:geog + trt:geog + offset(logtotal) +
> >         offset(logdt) + (1|plot) + (1|plot_trt),
> > zeroInflation=FALSE, family="poisson", data=cons09)
> >
> > > P_glmer <- glmer(cons ~ count + geog + trt +
> > count:trt + count:geog + trt:geog + offset(log(total)) +
> >       offset(log(dt)) + (1|plot) +
> > (1|plot_trt), family="poisson", data=cons09)
>
> By the way, you can specify these fixed effects
> more compactly as (count+geog+trt)^2 ...

Indeed, I was being explicit for explicitness' sake...

>
> > > fixef(Poiss)
>
> > 0.77333 0.58885 -0.21547 0.79101 0.24924 -0.02565 0.36004
> > -0.94852 0.39442 0.29032 0.13658 -0.39564
> > -1.37470 -0.88496 -0.53259 -0.25434
> > -0.41033 1.18840 0.25678 0.69734
> > 0.59823 1.11430 -0.17330 -0.15364
> > 0.98442 0.51533 -0.99431 -1.63920 -0.40455 -1.55670 0.15891
> > 0.35378 0.45748 0.92293 0.78373 1.05440
> > 0.39598 0.32019 1.41600
> > 0.86656 2.45790 1.07350 -0.31149
>
> > # After detaching glmmADMB and lme4, then
> > re-requiring lme4 to avoid masking of lme4's fixef function
> > > fixef(P_glmer)
> > -5.00326871 0.69554781 0.17105622 1.29467717
> > 0.97268949 0.87707266 1.39399967 0.22923370
> > 1.61829807 1.84546906 1.99506279 1.37859852
> > 0.53987085 1.13282524 -0.12901214 0.07021103
> > -0.52669841 0.87378323 0.05397134 0.46901053
> > 0.39863837 0.94486828 -0.18146287 -0.20340655
> > 0.77866847 0.49935778 -0.65101999 -1.05381279
> > -0.05290984 -1.54103716 -0.03887633 0.04570463 0.02076874
> > 0.47883964 0.23057821 0.49408747
> > -0.15116087 -0.32683907 0.50098187 0.14670125
> > 1.63961096 0.40944384 -0.22555478
> >
> > I juxtapose ranef() estimates here for comparison's sake...
> >
> [snip]
>
> There's nothing obviously wrong here. It's not a full solution,
> but I wonder how wide the confidence intervals are ... if they
> are very wide, then the practical answer is that these are poorly
> determined estimates. You're probably overfitting the model --
> 2 random effects plus 43 fixed-effect coefficients is
> quite a lot for 394 observations (the general rule of thumb
> is N/(# params)>10), especially if the Poisson data are sparse
> (although they don't look that way from the first few
> values listed in str() -- is there anyway you can allow
> 'count' to be continuous, or ordinal, rather than insisting
> on it being categorical?) But it would be best to try to answer
> more definitively ... can you send data?

I started with a general specification of count expecting to model 
it with an additive term when I start comparing fixed effects.? I 
suppose I could model it as a lower order polynomial initially... 
Doing so should drastically reduce the number of fixed effects in 
the model.? I suppose I should center it before creating the
polynomial terms...

However, I'll still send the data off-list.? 

Thanks for looking this over.

>
> Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  


From sjtr at ceh.ac.uk  Mon Feb 13 21:18:38 2012
From: sjtr at ceh.ac.uk (Thackeray, Stephen J.)
Date: Mon, 13 Feb 2012 20:18:38 +0000
Subject: [R-sig-ME] Any package for best subset selection for random
 effects	model
In-Reply-To: <CADMWRionUd97x-oUuUqj0nUStGiSZohudJLVh4kctEY0tC8=cw@mail.gmail.com>
References: <CADMWRionUd97x-oUuUqj0nUStGiSZohudJLVh4kctEY0tC8=cw@mail.gmail.com>
Message-ID: <42AFDDFA3288A141B63C93EE7F138E97216D3BADF7@nerckwmb1.ad.nerc.ac.uk>

Hello Tao,

>From your question, I am unsure of quite what you want. If you are interested in determining from a global model (with all fixed effects included) the model(s) with the most optimal subset of these fixed effects then you could try the dredge function in the MuMIn package. This will accept lme and lmer mixed effects models...

All the best

Steve



________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Tao Zhang [zt020200 at gmail.com]
Sent: 13 February 2012 17:22
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Any package for best subset selection for random effects    model

 Hi Pros,
      I know leaps() computes the best subset selection for linear model,
and
 the bestglm() computes the best subset selection for generalized linear
 model. Is there any package for best subset selection on random effects
 model, or mixed effects model?

Thank you!

Tao

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models-- 
This message (and any attachments) is for the recipient only. NERC
is subject to the Freedom of Information Act 2000 and the contents
of this email and any reply you make may be disclosed by NERC unless
it is exempt from release under the Act. Any material supplied to
NERC may be stored in an electronic records management system.


From anthony.sealey at utoronto.ca  Mon Feb 13 21:40:09 2012
From: anthony.sealey at utoronto.ca (anthony.sealey at utoronto.ca)
Date: Mon, 13 Feb 2012 20:40:09 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 62, Issue 29
In-Reply-To: <mailman.3107.1329160031.4475.r-sig-mixed-models@r-project.org>
References: <mailman.3107.1329160031.4475.r-sig-mixed-models@r-project.org>
Message-ID: <354080429-1329165020-cardhu_decombobulator_blackberry.rim.net-278480037-@b25.c26.bise6.blackberry>

9sbnopoi
-----Original Message-----
From:	r-sig-mixed-models-request at r-project.org
Sender:	r-sig-mixed-models-bounces at r-project.org
Date:	Mon, 13 Feb 2012 20:07:11 
To: <r-sig-mixed-models at r-project.org>
Reply-To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 62, Issue 29

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Comparing against a negative control in an LMM (Masca, Nick)
   2. MCMCglmm with cross-classified random effects (Agostino Moro)
   3. Re: MCMCglmm with cross-classified random effects
      (Jarrod Hadfield)
   4. Re: Considerable discrepancies between fixed and random
      effect estimates of lme4 (glmer) and glmmADMB (Ben Bolker)
   5. Any package for best subset selection for random effects
      model (Tao Zhang)
   6. Interpretation of nonlinear mixed-effects modeling	results
      (Gang Chen)
   7. Re: Considerable discrepancies between fixed and random
      effect estimates of lme4 (glmer) and glmmADMB (Adam Smith)


----------------------------------------------------------------------

Message: 1
Date: Mon, 13 Feb 2012 12:33:42 +0000
From: "Masca, Nick" <Nick.Masca at effem.com>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Comparing against a negative control in an LMM
Message-ID:
	<8295A4D50D4C644CAC4323DD070D9597106F2D at 034-CH1MPN1-014.034d.mgd.msft.net>
	
Content-Type: text/plain

Hi all,

I have a problem based on a colleague's experiment that I've been asked to analyse, which is more of a general mixed modelling issue rather than specifically an R issue, and I would be extremely grateful for any help that any readers of this list can provide.

An experiment was conducted in which the aim was to compare 3 concentrations of 2 active treatments (i.e. 6 active treatments in total) to a negative control.  Three batches of each of the actives have been tested, and 3 reps tested for each batch.  In contrast, 20 replicates have been taken of the negative control - but, by definition, there is no "batch" for this treatment.

Here is some code to reproduce the experimental design:

Treat<- factor(c(rep("NC", 20), rep("A", 27), rep("B", 27)))
Conc<-factor(c(rep(1, 20), rep(1:3, each=9), rep(1:3, each=9)))
Batch<-factor(c(rep(1, 20), rep( rep(1:3, each=3), 6)))
Treatment<-factor(Treat:Conc)  #specify new treatment variable (so don't attempt to estimate Conc. 2&3 for NC)

I originally planned to analyses these data in a LMM, with Treat*Conc as a 7 level fixed effect (i.e. 3*2 actives + control), and with Treat:Conc:Batch as random.  The following code simulates my response variable assuming this model:

                Resp<-  rep(9, 74) + #simulate intercept
                                c( rep(rnorm(1, 0, sd=2.5), 20)^2, rep(rnorm(18, 0, sd=2.5), each=3)^2) + #simulate treat.conc.batch variance
                                rep(rnorm(74, 0, sd=.2)^2) + #simulate residual variance
                                c(rep(0,20), rep(c(-4, 0,0,-4, 0,0), each= 9)) #simulate fixed effects
                Data<-data.frame(Treatment, Conc, Batch, Resp)

While this code models the data using lme4:
                Mod<-lmer(Resp ~ Treatment + (1|Treatment:Batch), data=Data)

I can now obtain and plot treatment means/CIs using glht in the multcomp package:
library(multcomp)
                Mean.mat<-diag(rep(1,7))
                                Mean.mat[,1]<-rep(1,7)
                                rownames(Mean.mat)<-levels(Data$Treatment)
                Est.means<-glht(Mod, Mean.mat)
plot(Est.means)

Hopefully from the above plot you can see what my issue is.  The negative control, which I want to compare everything against, has by far the least precision around its estimate, despite the data for the control hardly varying at all.  This happens because the greatest source of variability in the model (by far) is the variability between batches, but different batches of the negative control don't exist.  As such, I'm not sure that this is a fair way to model the data, because the negative control is unfairly penalised by the variability between the batches of the other treatments.

I imagine that this kind of problem isn't particularly uncommon, but it's the first time I've had to deal with something like this myself.   The only potential solution I've come up with so far is to scrap the negative control from the model, and simply subtract the negative control's mean "count" from all other values (either by specifying this mean as an offset or by subtracting it from all data-points).  But this will probably give "anti-conservative" results, as it would assume the mean for the negative control doesn't vary.

I would be extremely grateful if anyone would care to share their thoughts on possible solutions to this problem - and whether anyone has dealt with this kind of issue before.  I feel that I may well be missing something obvious - but can't see at the moment how else to get around it!

Many thanks for any help you can provide.

Cheers,

Nick





	[[alternative HTML version deleted]]



------------------------------

Message: 2
Date: Mon, 13 Feb 2012 15:02:20 +0000
From: Agostino Moro <agostino.moro99 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] MCMCglmm with cross-classified random effects
Message-ID:
	<CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Dear R-users,

I would like to fit ?a glmm with cross-classified random effects with
the function MCMCglmm. Something along the lines:

model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)

where re1 and re2 should be crossed random effects. I was wondering
whether you could tell me specifying cross-classified random effects
in MCMCglmm requires a particular syntax? Are there any examples
somewhere? I have had a look at the manual and the package vignette,
but I have not been able to find any examples relevant to what I want
to do.

Thanks,

Agostino



------------------------------

Message: 3
Date: Mon, 13 Feb 2012 15:19:07 +0000
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
To: Agostino Moro <agostino.moro99 at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm with cross-classified random effects
Message-ID: <20120213151907.57957fqy2tmlxcg8 at www.staffmail.ed.ac.uk>
Content-Type: text/plain; charset=ISO-8859-1; DelSp="Yes";
	format="flowed"

Hi,

As long as the levels of re1 and re2 are uniquely labelled any cross  
classification will be dealt with appropriately.

Cheers,

Jarrod


Quoting Agostino Moro <agostino.moro99 at gmail.com> on Mon, 13 Feb 2012  
15:02:20 +0000:

> Dear R-users,
>
> I would like to fit ?a glmm with cross-classified random effects with
> the function MCMCglmm. Something along the lines:
>
> model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)
>
> where re1 and re2 should be crossed random effects. I was wondering
> whether you could tell me specifying cross-classified random effects
> in MCMCglmm requires a particular syntax? Are there any examples
> somewhere? I have had a look at the manual and the package vignette,
> but I have not been able to find any examples relevant to what I want
> to do.
>
> Thanks,
>
> Agostino
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



------------------------------

Message: 4
Date: Mon, 13 Feb 2012 16:43:51 +0000 (UTC)
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Considerable discrepancies between fixed and
	random	effect estimates of lme4 (glmer) and glmmADMB
Message-ID: <loom.20120213T045329-772 at post.gmane.org>
Content-Type: text/plain; charset=utf-8

Adam Smith <raptorbio at ...> writes:

 
> I hope I'm not overlooking something elementary here, but estimated
> fixed and random effects are considerably different from the
> following Poisson model in lme4 and glmmADMB.? The fixed effects
> seem to differ most considerably...? Thanks for any thoughts...
> Adam Smith

> > sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> (SNIP)
> 
> other attached packages:
> [1] glmmADMB_0.7.2.5?? lme4_0.999375-42?? Matrix_1.0-3??????
bbmle_1.0.4.1????? numDeriv_2010.11-1
> [6] lattice_0.20-0???? R2admb_0.7.5?????? MASS_7.3-16?????? 

 
> > str(cons09) # The dataset
> 'data.frame':?? 394 obs. of? 15 variables:
> ?$ plot?????? : Factor w/ 16 levels "n_10","n_2","n_3",..: 
> 2 2 2 2 2 2 2 2 2 2 ...
> ?$ plot_trt?? : Factor w/ 32 levels 
> "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
> ?$ geog?????? : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ trt??????? : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ count????? : Factor w/ 14 levels "1","2","3","4",..:
>  1 2 3 4 5 6 7 8 9 10 ...
> ?$ total????? : int? 341 326 257 244 185 141 128 121 115 84 ...
> ?$ cons?????? : int? 12 52 8 57 36 8 0 1 20 27 ...
> ?$ dt???????? : int? 4 3 3 3 3 3 3 3 3 3 ...
> ?$ obs??????? : Factor w/ 394 levels "1","2","3","4",..: 
> 1 2 3 4 5 6 7 8 9 10 ...
> ?$ logtotal?? : num? 5.83 5.79 5.55 5.5 5.22 ...
> ?$ logdt????? : num? 1.39 1.1 1.1 1.1 1.1 ...

 
> # The models
> > Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt + 
> count:geog + trt:geog + offset(logtotal) +
> ??? ??? offset(logdt) + (1|plot) + (1|plot_trt),
>  zeroInflation=FALSE, family="poisson", data=cons09)
> 
> > P_glmer <- glmer(cons ~ count + geog + trt + 
> count:trt + count:geog + trt:geog + offset(log(total)) +
> ??? ? offset(log(dt)) + (1|plot) + 
> (1|plot_trt), family="poisson", data=cons09)
 
By the way, you can specify these fixed effects 
more compactly as (count+geog+trt)^2 ...

> > fixef(Poiss)

>   0.77333  0.58885  -0.21547 0.79101  0.24924  -0.02565  0.36004 
> -0.94852  0.39442  0.29032  0.13658 -0.39564 
>   -1.37470  -0.88496  -0.53259  -0.25434 
> -0.41033  1.18840  0.25678  0.69734 
> 0.59823  1.11430  -0.17330  -0.15364 
>   0.98442  0.51533  -0.99431 -1.63920  -0.40455  -1.55670  0.15891 
> 0.35378  0.45748  0.92293  0.78373 1.05440 
>   0.39598  0.32019  1.41600 
> 0.86656  2.45790  1.07350  -0.31149 

> # After detaching glmmADMB and lme4, then 
> re-requiring lme4 to avoid masking of lme4's fixef function
> > fixef(P_glmer)
>   -5.00326871  0.69554781  0.17105622  1.29467717 
> 0.97268949  0.87707266  1.39399967  0.22923370 
> 1.61829807  1.84546906  1.99506279  1.37859852 
>   0.53987085  1.13282524  -0.12901214  0.07021103 
> -0.52669841  0.87378323  0.05397134  0.46901053 
> 0.39863837  0.94486828  -0.18146287  -0.20340655 
>   0.77866847  0.49935778  -0.65101999  -1.05381279 
> -0.05290984  -1.54103716  -0.03887633  0.04570463  0.02076874 
> 0.47883964  0.23057821  0.49408747 
>   -0.15116087  -0.32683907  0.50098187  0.14670125 
> 1.63961096  0.40944384  -0.22555478 
> 
> I juxtapose ranef() estimates here for comparison's sake...
> 
  [snip]

  There's nothing obviously wrong here.  It's not a full solution,
but I wonder how wide the confidence intervals are ... if they
are very wide, then the practical answer is that these are poorly
determined estimates.  You're probably overfitting the model --
2 random effects plus 43 fixed-effect coefficients is
quite a lot for 394 observations (the general rule of thumb
is N/(# params)>10), especially if the Poisson data are sparse
(although they don't look that way from the first few
values listed in str() -- is there anyway you can allow
'count' to be continuous, or ordinal, rather than insisting
on it being categorical?) But it would be best to try to answer
more definitively ... can you send data?

  Ben Bolker



------------------------------

Message: 5
Date: Mon, 13 Feb 2012 09:22:24 -0800
From: Tao Zhang <zt020200 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Any package for best subset selection for random
	effects	model
Message-ID:
	<CADMWRionUd97x-oUuUqj0nUStGiSZohudJLVh4kctEY0tC8=cw at mail.gmail.com>
Content-Type: text/plain

 Hi Pros,
      I know leaps() computes the best subset selection for linear model,
and
 the bestglm() computes the best subset selection for generalized linear
 model. Is there any package for best subset selection on random effects
 model, or mixed effects model?

Thank you!

Tao

	[[alternative HTML version deleted]]



------------------------------

Message: 6
Date: Mon, 13 Feb 2012 13:41:43 -0500
From: Gang Chen <gangchen6 at gmail.com>
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Interpretation of nonlinear mixed-effects modeling
	results
Message-ID:
	<CAHmzXO6hydefDRtcZAgbuHBhiJXGfM6zDxDfPkP=k8LouY5suQ at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

I'm fitting a nonlinear mixed-effects model to some data with two
groups (controls and patients) with something like

fm <- nlme(response ~  myFunc(time, a, b), data=myData, fixed = a + b
~ group, start=...)

myFunc is a nonlinear function defined with two parameters a and b.
I'm very confused with the results between summary(fm) and anova(fm):

> summary(fm)

...
Fixed effects: a + b ~ group
                        Value       Std.Error   DF     t-value      p-value
a.(Intercept) 29.905889 10.532769 2196  2.839319  0.0046
a.groupPat     6.437218 16.045223 2196  0.401192  0.6883
b.(Intercept)  0.290943  0.072544 2196  4.010559  0.0001
b.groupPat    -0.138361  0.077339 2196 -1.789010  0.0738
...

> anova(fm)
                 numDF denDF  F-value p-value
a.(Intercept)     1  2196 497.8594  <.0001
a.group           1  2196  12.6109  0.0004
b.(Intercept)     1  2196  45.2787  <.0001
b.group           1  2196   3.2006  0.0738

If I understand it correctly, the last row in the fixed effects table
of summary(fm) is the difference in parameter b between the two
groups, and the t-statistic (and p-value) matches the F-statistic (and
p-value) from the last row of anova(fm): (-1.789010)^2 = 3.2006.
However, I'm totally at a loss for the other three rows in the two
tables? For example, I thought a.groupPat (2nd row) in the summary(fm)
table is the amount in parameter a in Patient group that is more than
parameter a in the Control group (1st row); but this interpretation is
not consistent with what is shown in the 2nd row of anova(fm) table.
What am I missing here?

Thanks,
Gang



------------------------------

Message: 7
Date: Mon, 13 Feb 2012 14:06:57 -0500
From: Adam Smith <raptorbio at hotmail.com>
To: <bbolker at gmail.com>, <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Considerable discrepancies between fixed and
	random effect estimates of lme4 (glmer) and glmmADMB
Message-ID: <BAY170-W29F87F0CC98BFF5E9B7F8EA17F0 at phx.gbl>
Content-Type: text/plain; charset="iso-8859-1"



> > I hope I'm not overlooking something elementary here, but estimated
> > fixed and random effects are considerably different from the
> > following Poisson model in lme4 and glmmADMB.  The fixed effects
> > seem to differ most considerably...  Thanks for any thoughts...
> > Adam Smith
>
> > > sessionInfo()
> > R version 2.14.1 (2011-12-22)
> > Platform: x86_64-pc-mingw32/x64 (64-bit)
> >
> > (SNIP)
> >
> > other attached packages:
> > [1] glmmADMB_0.7.2.5   lme4_0.999375-42   Matrix_1.0-3
> bbmle_1.0.4.1      numDeriv_2010.11-1
> > [6] lattice_0.20-0     R2admb_0.7.5       MASS_7.3-16
>
>
> > > str(cons09) # The dataset
> > 'data.frame':   394 obs. of  15 variables:
> >  $ plot       : Factor w/ 16 levels "n_10","n_2","n_3",..:
> > 2 2 2 2 2 2 2 2 2 2 ...
> >  $ plot_trt   : Factor w/ 32 levels
> > "cont_n_10","cont_n_2",..: 2 2 2 2 2 2 2 2 2 2 ...
> >  $ geog       : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
> >  $ trt        : Factor w/ 2 levels "cont","trt": 1 1 1 1 1 1 1 1 1 1 ...
> >  $ count      : Factor w/ 14 levels "1","2","3","4",..:
> > 1 2 3 4 5 6 7 8 9 10 ...
> >  $ total      : int  341 326 257 244 185 141 128 121 115 84 ...
> >  $ cons       : int  12 52 8 57 36 8 0 1 20 27 ...
> >  $ dt         : int  4 3 3 3 3 3 3 3 3 3 ...
> >  $ obs        : Factor w/ 394 levels "1","2","3","4",..:
> > 1 2 3 4 5 6 7 8 9 10 ...
> >  $ logtotal   : num  5.83 5.79 5.55 5.5 5.22 ...
> >  $ logdt      : num  1.39 1.1 1.1 1.1 1.1 ...
>
>
> > # The models
> > > Poiss <- glmmadmb(cons ~ count + geog + trt + count:trt +
> > count:geog + trt:geog + offset(logtotal) +
> >         offset(logdt) + (1|plot) + (1|plot_trt),
> > zeroInflation=FALSE, family="poisson", data=cons09)
> >
> > > P_glmer <- glmer(cons ~ count + geog + trt +
> > count:trt + count:geog + trt:geog + offset(log(total)) +
> >       offset(log(dt)) + (1|plot) +
> > (1|plot_trt), family="poisson", data=cons09)
>
> By the way, you can specify these fixed effects
> more compactly as (count+geog+trt)^2 ...

Indeed, I was being explicit for explicitness' sake...

>
> > > fixef(Poiss)
>
> > 0.77333 0.58885 -0.21547 0.79101 0.24924 -0.02565 0.36004
> > -0.94852 0.39442 0.29032 0.13658 -0.39564
> > -1.37470 -0.88496 -0.53259 -0.25434
> > -0.41033 1.18840 0.25678 0.69734
> > 0.59823 1.11430 -0.17330 -0.15364
> > 0.98442 0.51533 -0.99431 -1.63920 -0.40455 -1.55670 0.15891
> > 0.35378 0.45748 0.92293 0.78373 1.05440
> > 0.39598 0.32019 1.41600
> > 0.86656 2.45790 1.07350 -0.31149
>
> > # After detaching glmmADMB and lme4, then
> > re-requiring lme4 to avoid masking of lme4's fixef function
> > > fixef(P_glmer)
> > -5.00326871 0.69554781 0.17105622 1.29467717
> > 0.97268949 0.87707266 1.39399967 0.22923370
> > 1.61829807 1.84546906 1.99506279 1.37859852
> > 0.53987085 1.13282524 -0.12901214 0.07021103
> > -0.52669841 0.87378323 0.05397134 0.46901053
> > 0.39863837 0.94486828 -0.18146287 -0.20340655
> > 0.77866847 0.49935778 -0.65101999 -1.05381279
> > -0.05290984 -1.54103716 -0.03887633 0.04570463 0.02076874
> > 0.47883964 0.23057821 0.49408747
> > -0.15116087 -0.32683907 0.50098187 0.14670125
> > 1.63961096 0.40944384 -0.22555478
> >
> > I juxtapose ranef() estimates here for comparison's sake...
> >
> [snip]
>
> There's nothing obviously wrong here. It's not a full solution,
> but I wonder how wide the confidence intervals are ... if they
> are very wide, then the practical answer is that these are poorly
> determined estimates. You're probably overfitting the model --
> 2 random effects plus 43 fixed-effect coefficients is
> quite a lot for 394 observations (the general rule of thumb
> is N/(# params)>10), especially if the Poisson data are sparse
> (although they don't look that way from the first few
> values listed in str() -- is there anyway you can allow
> 'count' to be continuous, or ordinal, rather than insisting
> on it being categorical?) But it would be best to try to answer
> more definitively ... can you send data?

I started with a general specification of count expecting to model 
it with an additive term when I start comparing fixed effects.? I 
suppose I could model it as a lower order polynomial initially... 
Doing so should drastically reduce the number of fixed effects in 
the model.? I suppose I should center it before creating the
polynomial terms...

However, I'll still send the data off-list.? 

Thanks for looking this over.

>
> Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  


------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 62, Issue 29
**************************************************

From trea26 at gmail.com  Mon Feb 13 21:45:06 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Mon, 13 Feb 2012 16:45:06 -0400
Subject: [R-sig-ME] Any package for best subset selection for,
 random effects model
In-Reply-To: <mailman.3116.1329165038.4475.r-sig-mixed-models@r-project.org>
References: <mailman.3116.1329165038.4475.r-sig-mixed-models@r-project.org>
Message-ID: <4F397652.40707@gmail.com>

Maybe function ffRanefLMER.fnc from package LMERConvenienceFunctions???

Antoine Tremblay, PhD
NeuroCognitive Imaging Laboratory
Dalhousie University
Halifax, NS B3H 3J5,
Canada

Tel.: (902) 494-1911
eom

On 12-02-13 04:30 PM, r-sig-mixed-models-request at r-project.org wrote:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>     1. Re: Any package for best subset selection for random effects
>        model (Thackeray, Stephen J.)
>     2. Re: R-sig-mixed-models Digest, Vol 62, Issue 29
>        (anthony.sealey at utoronto.ca)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 13 Feb 2012 20:18:38 +0000
> From: "Thackeray, Stephen J."<sjtr at ceh.ac.uk>
> To: Tao Zhang<zt020200 at gmail.com>, "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Any package for best subset selection for
> 	random effects	model
> Message-ID:
> 	<42AFDDFA3288A141B63C93EE7F138E97216D3BADF7 at nerckwmb1.ad.nerc.ac.uk>
> Content-Type: text/plain; charset="us-ascii"
>
> Hello Tao,
>
>> From your question, I am unsure of quite what you want. If you are interested in determining from a global model (with all fixed effects included) the model(s) with the most optimal subset of these fixed effects then you could try the dredge function in the MuMIn package. This will accept lme and lmer mixed effects models...
>
> All the best
>
> Steve
>
>
>
> ________________________________________
> From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Tao Zhang [zt020200 at gmail.com]
> Sent: 13 February 2012 17:22
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Any package for best subset selection for random effects    model
>
>   Hi Pros,
>        I know leaps() computes the best subset selection for linear model,
> and
>   the bestglm() computes the best subset selection for generalized linear
>   model. Is there any package for best subset selection on random effects
>   model, or mixed effects model?
>
> Thank you!
>
> Tao
>
>          [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models--
> This message (and any attachments) is for the recipient only. NERC
> is subject to the Freedom of Information Act 2000 and the contents
> of this email and any reply you make may be disclosed by NERC unless
> it is exempt from release under the Act. Any material supplied to
> NERC may be stored in an electronic records management system.
>
>
> ------------------------------
>
> Message: 2
> Date: Mon, 13 Feb 2012 20:40:09 +0000
> From: anthony.sealey at utoronto.ca
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 62, Issue 29
> Message-ID:
> 	<354080429-1329165020-cardhu_decombobulator_blackberry.rim.net-278480037- at b25.c26.bise6.blackberry>
> 	
> Content-Type: text/plain
>
> 9sbnopoi
> -----Original Message-----
> From:	r-sig-mixed-models-request at r-project.org
> Sender:	r-sig-mixed-models-bounces at r-project.org
> Date:	Mon, 13 Feb 2012 20:07:11
> To:<r-sig-mixed-models at r-project.org>
> Reply-To: r-sig-mixed-models at r-project.org
> Subject: R-sig-mixed-models Digest, Vol 62, Issue 29
>
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>     1. Comparing against a negative control in an LMM (Masca, Nick)
>     2. MCMCglmm with cross-classified random effects (Agostino Moro)
>     3. Re: MCMCglmm with cross-classified random effects
>        (Jarrod Hadfield)
>     4. Re: Considerable discrepancies between fixed and random
>        effect estimates of lme4 (glmer) and glmmADMB (Ben Bolker)
>     5. Any package for best subset selection for random effects
>        model (Tao Zhang)
>     6. Interpretation of nonlinear mixed-effects modeling	results
>        (Gang Chen)
>     7. Re: Considerable discrepancies between fixed and random
>        effect estimates of lme4 (glmer) and glmmADMB (Adam Smith)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 13 Feb 2012 12:33:42 +0000
> From: "Masca, Nick"<Nick.Masca at effem.com>
> To: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Comparing against a negative control in an LMM
> Message-ID:
> 	<8295A4D50D4C644CAC4323DD070D9597106F2D at 034-CH1MPN1-014.034d.mgd.msft.net>
> 	
> Content-Type: text/plain
>
> Hi all,
>
> I have a problem based on a colleague's experiment that I've been asked to analyse, which is more of a general mixed modelling issue rather than specifically an R issue, and I would be extremely grateful for any help that any readers of this list can provide.
>
> An experiment was conducted in which the aim was to compare 3 concentrations of 2 active treatments (i.e. 6 active treatments in total) to a negative control.  Three batches of each of the actives have been tested, and 3 reps tested for each batch.  In contrast, 20 replicates have been taken of the negative control - but, by definition, there is no "batch" for this treatment.
>
> Here is some code to reproduce the experimental design:
>
> Treat<- factor(c(rep("NC", 20), rep("A", 27), rep("B", 27)))
> Conc<-factor(c(rep(1, 20), rep(1:3, each=9), rep(1:3, each=9)))
> Batch<-factor(c(rep(1, 20), rep( rep(1:3, each=3), 6)))
> Treatment<-factor(Treat:Conc)  #specify new treatment variable (so don't attempt to estimate Conc. 2&3 for NC)
>
> I originally planned to analyses these data in a LMM, with Treat*Conc as a 7 level fixed effect (i.e. 3*2 actives + control), and with Treat:Conc:Batch as random.  The following code simulates my response variable assuming this model:
>
>                  Resp<-  rep(9, 74) + #simulate intercept
>                                  c( rep(rnorm(1, 0, sd=2.5), 20)^2, rep(rnorm(18, 0, sd=2.5), each=3)^2) + #simulate treat.conc.batch variance
>                                  rep(rnorm(74, 0, sd=.2)^2) + #simulate residual variance
>                                  c(rep(0,20), rep(c(-4, 0,0,-4, 0,0), each= 9)) #simulate fixed effects
>                  Data<-data.frame(Treatment, Conc, Batch, Resp)
>
> While this code models the data using lme4:
>                  Mod<-lmer(Resp ~ Treatment + (1|Treatment:Batch), data=Data)
>
> I can now obtain and plot treatment means/CIs using glht in the multcomp package:
> library(multcomp)
>                  Mean.mat<-diag(rep(1,7))
>                                  Mean.mat[,1]<-rep(1,7)
>                                  rownames(Mean.mat)<-levels(Data$Treatment)
>                  Est.means<-glht(Mod, Mean.mat)
> plot(Est.means)
>
> Hopefully from the above plot you can see what my issue is.  The negative control, which I want to compare everything against, has by far the least precision around its estimate, despite the data for the control hardly varying at all.  This happens because the greatest source of variability in the model (by far) is the variability between batches, but different batches of the negative control don't exist.  As such, I'm not sure that this is a fair way to model the data, because the negative control is unfairly penalised by the variability between the batches of the other treatments.
>
> I imagine that this kind of problem isn't particularly uncommon, but it's the first time I've had to deal with something like this myself.   The only potential solution I've come up with so far is to scrap the negative control from the model, and simply subtract the negative control's mean "count" from all other values (either by specifying this mean as an offset or by subtracting it from all data-points).  But this will probably give "anti-conservative" results, as it would assume the mean for the negative control doesn't vary.
>
> I would be extremely grateful if anyone would care to share their thoughts on possible solutions to this problem - and whether anyone has dealt with this kind of issue before.  I feel that I may well be missing something obvious - but can't see at the moment how else to get around it!
>
> Many thanks for any help you can provide.
>
> Cheers,
>
> Nick
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 2
> Date: Mon, 13 Feb 2012 15:02:20 +0000
> From: Agostino Moro<agostino.moro99 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] MCMCglmm with cross-classified random effects
> Message-ID:
> 	<CAMS_pxvdSZVhe_qSFgqsnkMofyTGxL6eLAY4g114VzS=k9HFpA at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Dear R-users,
>
> I would like to fit ?a glmm with cross-classified random effects with
> the function MCMCglmm. Something along the lines:
>
> model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)
>
> where re1 and re2 should be crossed random effects. I was wondering
> whether you could tell me specifying cross-classified random effects
> in MCMCglmm requires a particular syntax? Are there any examples
> somewhere? I have had a look at the manual and the package vignette,
> but I have not been able to find any examples relevant to what I want
> to do.
>
> Thanks,
>
> Agostino
>
>
>
> ------------------------------
>
> Message: 3
> Date: Mon, 13 Feb 2012 15:19:07 +0000
> From: Jarrod Hadfield<j.hadfield at ed.ac.uk>
> To: Agostino Moro<agostino.moro99 at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm with cross-classified random effects
> Message-ID:<20120213151907.57957fqy2tmlxcg8 at www.staffmail.ed.ac.uk>
> Content-Type: text/plain; charset=ISO-8859-1; DelSp="Yes";
> 	format="flowed"
>
> Hi,
>
> As long as the levels of re1 and re2 are uniquely labelled any cross
> classification will be dealt with appropriately.
>
> Cheers,
>
> Jarrod
>
>
> Quoting Agostino Moro<agostino.moro99 at gmail.com>  on Mon, 13 Feb 2012
> 15:02:20 +0000:
>
>> Dear R-users,
>>
>> I would like to fit ?a glmm with cross-classified random effects with
>> the function MCMCglmm. Something along the lines:
>>
>> model1<-MCMCglmm(response~pred1, random=~re1+re2, data=data)
>>
>> where re1 and re2 should be crossed random effects. I was wondering
>> whether you could tell me specifying cross-classified random effects
>> in MCMCglmm requires a particular syntax? Are there any examples
>> somewhere? I have had a look at the manual and the package vignette,
>> but I have not been able to find any examples relevant to what I want
>> to do.
>>
>> Thanks,
>>
>> Agostino
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>



From Jeffrey.Morris at sanofipasteur.com  Tue Feb 14 16:22:59 2012
From: Jeffrey.Morris at sanofipasteur.com (Jeffrey.Morris at sanofipasteur.com)
Date: Tue, 14 Feb 2012 10:22:59 -0500
Subject: [R-sig-ME] Simple Task: CI on Total Imprecision
Message-ID: <15B762F2463DA8429B5B5E7F128258E716A74E81@USSWTEXS102.pasteur.aventis.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120214/b460ada0/attachment-0002.pl>

From bates at stat.wisc.edu  Tue Feb 14 16:23:09 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 14 Feb 2012 09:23:09 -0600
Subject: [R-sig-ME] about warning "In mer_finalize(ans) : singular
 convergence (7)"
In-Reply-To: <CA+hwERn-9DHnOVr9omj50dRY-wfQ4aDBEDiqiktSBdmexf4_uw@mail.gmail.com>
References: <CA+hwERk+f=GG8zbzsTBt-6zv3p+oqNcgmL_rz9B4vBCvFq__KA@mail.gmail.com>
	<CAO7JsnSDXpK7w8UgA8xhrsV_w+SMgM+b1PMEvNjLa7bB8Q+p6g@mail.gmail.com>
	<CA+hwERn-9DHnOVr9omj50dRY-wfQ4aDBEDiqiktSBdmexf4_uw@mail.gmail.com>
Message-ID: <CAO7JsnRkL3abu1OiyoA7uP8rOWka-Sj3X4wXnQXe0VNOojrLWw@mail.gmail.com>

On Fri, Feb 10, 2012 at 5:06 AM, Toni Hernandez-Matias
<ahmatias at gmail.com> wrote:
> Dear Douglas,
>
> thank you very much for your message. If necessary I can send you my data
> set. Before let me show you the output of the verbose=TRUE and the summary
> of the model results (see below).
> I wonder wether the problem is that the variance estimated for the main
> random effect (study area: coded as 'ter') takes the value of 0 (third
> column in the results of the 'verbose'). If that would be the problem, I
> wonder whether it would be acceptable (dessing) that I would ommit this
> random effect in the models and only considering the random effect of the
> transects (coded as 'trans'). On the other hand, I don't understand why this
> problem only happens with some of the independent variables (other models
> fitted fine).
>
> Thank you very much in advance,
>
> Toni
>
> mod05<-lmer(cagaders~E_arb_alt+(1|ter)+(1|ter:trans),data=conill,family=poisson,verbose=TRUE)
>
> ?0:???? 1580.1040: 0.521157 0.212762 0.0146621 -0.00550703
> ?1:???? 1578.7769: 0.529048 0.217137 0.0121796 -0.00198275
> ?2:???? 1574.8963: 0.536915 0.221586 0.00963723 -0.00542672
> ?3:???? 1546.2308: 0.659172 0.290027 -0.0296622 -2.71216e-05
> ?4:???? 1544.4481: 0.659755 0.290395 -0.0299398 -0.00438446
> ?5:???? 1512.2918: 0.827224 0.356975 -0.453220 0.000576404
> ?6:???? 1506.1926:? 1.14082 0.0210690 -0.431339 -0.00365397
> ?7:???? 1500.5942:? 1.16992? 0.00000 -0.828777 0.00123612
> ?8:???? 1500.3060:? 1.20528? 0.00000 -0.790690 0.00198426
> ?9:???? 1499.5992:? 1.25168? 0.00000 -0.779210 0.000659413
> 10:???? 1499.3691:? 1.28723? 0.00000 -0.803391 0.000445819
> 11:???? 1499.2722:? 1.32511? 0.00000 -0.837827 0.000455882
> 12:???? 1499.2705:? 1.33004? 0.00000 -0.843619 0.000496015
> 13:???? 1499.2704:? 1.33032? 0.00000 -0.844199 0.000502862
> 14:???? 1499.2704:? 1.33030? 0.00000 -0.844231 0.000503448
> Mensajes de aviso perdidos

The fact that the second parameter is stuck at 0 indicates that the
random effect associated with ter is inert given that the random
effect associated with ter:trans is in the model.  You should try
fitting a model of the form

cagaders ~ E_arb_alt + (1|ter:trans)

> In mer_finalize(ans) : singular convergence (7)
>
>
>
> SUMMARY
> Generalized linear mixed model fit by the Laplace approximation Formula:
> cagaders ~ E_arb_alt + (1 | ter) + (1 | ter:trans)?? Data: conill? AIC? BIC
> logLik deviance
> 1507 1525 -749.6???? 1499
> Random effects:
> Groups??? Name??????? Variance Std.Dev.
> ter:trans (Intercept) 1.7697?? 1.3303? ter?????? (Intercept) 0.0000
> 0.0000? Number of obs: 648, groups: ter:trans, 66; ter, 11
>
> Fixed effects:
> ??????????? Estimate Std. Error z value Pr(>|z|)??? (Intercept) -0.8442310
> 0.1839531? -4.589 4.45e-06 ***
> E_arb_alt??? 0.0005023? 0.0029302?? 0.171??? 0.864??? ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Correlation of Fixed Effects:
> ??????? (Intr)
> E_arb_alt -0.247
>
>
>
>
>
>
> On Thu, Feb 9, 2012 at 9:03 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>> On Thu, Feb 9, 2012 at 11:08 AM, Toni Hernandez-Matias
>> <ahmatias at gmail.com> wrote:
>> > Dear all,
>>
>> > I am trying to fit a set of models with lmer function.
>> > My aim is to investigate the relationship between the abundance of a
>> > mammal
>> > species (count) and several environmental variables.
>> > The sample size is 648, but the observations are not independent and the
>> > random effect is nested: I have 10 study areas, within each area I
>> > performed 6 transects. I have 9-10 observations in all transects. So an
>> > example of a model with a single independent variable is:
>> >
>> > mod05<-lmer(cagaders~E_arb_alt+(1|ter)+(1|ter:trans),data=conill,family=poisson)
>>
>> > When running this model I get the warning:
>> > In mer_finalize(ans) : singular convergence (7)
>>
>> Try using verbose=TRUE to determine where the parameter values are
>> going during the iterative optimization process.
>>
>> If your data could be made available, even in an anonymized form, we
>> could check the model fit against other optimizers that may be more
>> successful.
>>
>> > I don't see an apparent reason for this warning.
>> > I would be very grateful if someone can help me to solve this problem
>> > and
>> > to know wether the results in the fitted model are credible.
>> >
>> > Thank you very much in advance,
>> >
>> > Toni
>> >
>
>
> --
> *********************************************************
>
> Antonio Hernandez Matias
>
> Departament de Biologia Animal (Vertebrats)
> Facultat de Biologia
> Universitat de Barcelona
> Av. Diagonal, 645
> Barcelona? ? ? 08028
> Spain
> Telephone: +34-934035857
> FAX: +34-934035740
> e-mail: ahernandezmatias at ub.edu
>
> ***********************************************************



From federico.tettamanti at gmail.com  Tue Feb 14 09:51:40 2012
From: federico.tettamanti at gmail.com (Federico Tettamanti)
Date: Tue, 14 Feb 2012 09:51:40 +0100
Subject: [R-sig-ME] Fwd: Modeling ecological observations
In-Reply-To: <CACNpG7tncy=+c9zgCzBV-VozAr3R3c1=PFKEY1Zh6s7zfYztbA@mail.gmail.com>
References: <CACNpG7tncy=+c9zgCzBV-VozAr3R3c1=PFKEY1Zh6s7zfYztbA@mail.gmail.com>
Message-ID: <CACNpG7s2QJOvYo=oMbQ4auBGm1gheOJpeM2qPq1q21AceZ4Kiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120214/804ab684/attachment-0002.pl>

From geetha_r at ces.iisc.ernet.in  Wed Feb 15 04:39:17 2012
From: geetha_r at ces.iisc.ernet.in (Geetha Ramaswami)
Date: Wed, 15 Feb 2012 09:09:17 +0530 (IST)
Subject: [R-sig-ME] Reg. interpretation of parameter CIs from lmer()
Message-ID: <41753.10.16.40.14.1329277157.squirrel@ces.iisc.ernet.in>

Dear All,

 I am working with an ecological data set wherein I am trying to compare
 the growth rate of seedlings in plots where an invasive species is present
 or absent. Repeated measures on seedlings were made every two months
 across 40 plots of which 20 had the invasive species while the remaining
 20 did not. Seedling growth is measured as log(proportion increment in
 height) per month. I am also interested in looking at how rainfall
 received between two consecutive growth measurements and seedling habitat
 preferences affect growth. I came up with the following mixed effects
 model

 growth ~ invasive density (2 levels) + seedling habitat preference (3
 levels) + rainfall (mm) + all two-way interactions + random intercept on
 repeatedly measured plots

 The residuals on this model are highly overdispersed and do not meet the
 normality criteria, so i decided to use nonparametric bootstrapping
 (refitting the model with 10000 random subsets of data) to obtain 95% CI
 on all the fixed effects parameters estimated (I assumed that the CIs
 non-overlapping with zero indicated significant fixed effects). Apart from
 the 'intercept', the 'rain' term and the 'invasive density' term, 95% Cis
 of all other parameters included zero. I am interested in graphically
 representing only these effects. Since the normality assumption of
 residuals is not satisfied, is it appropriate to simplify the model using
 anova (with REML = F)? Or can I create a new, simpler model with just the
 terms of interest, generate 95% CI for these parameters and use these for
 graphical representation?

 Thank you in advance for your help.
 Geetha

 Geetha Ramaswami
 PhD Student
 Centre for Ecological Sciences,
 Indian Institute of Science,
 Bangalore 560012,
 India


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From federico.tettamanti at gmail.com  Wed Feb 15 10:36:13 2012
From: federico.tettamanti at gmail.com (Federico Tettamanti)
Date: Wed, 15 Feb 2012 10:36:13 +0100
Subject: [R-sig-ME] Modeling of behavioural observation
Message-ID: <CACNpG7t+mDX6fuwnsSZ9UcOm8DApzKvsh+Agr_YjNSqrOW+jvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120215/423f806c/attachment-0002.pl>

From felipnunes at gmail.com  Wed Feb 15 18:31:57 2012
From: felipnunes at gmail.com (Felipe Nunes)
Date: Wed, 15 Feb 2012 09:31:57 -0800
Subject: [R-sig-ME] glmer error
Message-ID: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120215/aaf7edfd/attachment-0002.pl>

From jianyun.fred.wu at gmail.com  Wed Feb 15 22:05:42 2012
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Thu, 16 Feb 2012 08:05:42 +1100
Subject: [R-sig-ME] modelling seasonal patterns as random effects in a
	monthly time series
Message-ID: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120216/c67b59b6/attachment-0002.pl>

From kfrost at wisc.edu  Wed Feb 15 22:12:56 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Wed, 15 Feb 2012 15:12:56 -0600
Subject: [R-sig-ME] modelling seasonal patterns as random effects in
	a	monthly time series
In-Reply-To: <7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
References: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>
	<7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
Message-ID: <77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>

Hi, Fred-

The answer to your question is probably yes, but you need to provide more details about what you want to do.

Ken

On 02/15/12, Jianyun Wu   wrote:
> Dear All,
> 
> Is there any function or packages in R that I can treat seasonal patterns
> as random effects in a monthly time series?
> 
> Is this possible to formulate such a model using nlme, lme4 or other
> available mixed model packages?
> 
> Thanks and Regards
> 
> Fred
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jianyun.fred.wu at gmail.com  Wed Feb 15 22:33:36 2012
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Thu, 16 Feb 2012 08:33:36 +1100
Subject: [R-sig-ME] modelling seasonal patterns as random effects in a
 monthly time series
In-Reply-To: <77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>
References: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>
	<7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
	<77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>
Message-ID: <CAOMGRDL0SBpcCMOTqWRdFhDG2ucJL1aj-hKGOvJ3q0smEyscCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120216/4296ec08/attachment-0002.pl>

From chris at trickysolutions.com.au  Thu Feb 16 00:09:29 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Thu, 16 Feb 2012 10:09:29 +1100
Subject: [R-sig-ME] modelling seasonal patterns as random effects in a
 monthly time series
In-Reply-To: <CAOMGRDL0SBpcCMOTqWRdFhDG2ucJL1aj-hKGOvJ3q0smEyscCA@mail.gmail.com>
References: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>
	<7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
	<77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>
	<CAOMGRDL0SBpcCMOTqWRdFhDG2ucJL1aj-hKGOvJ3q0smEyscCA@mail.gmail.com>
Message-ID: <5983470160263463854@unknownmsgid>

Try lme and lme4. There is also a list calle r-sig-me.



Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 16/02/2012, at 8:35, Jianyun Wu <jianyun.fred.wu at gmail.com> wrote:

> Hi Ken,
> I have a monthly time series, and the seasonal pattern is obvious where
> peaks are in Dec and drops in Jan. However due to various "external"
> factors, the seasonal variation during the year may change from time to
> time. The traditional practice here is to use seasonal dummies to treat
> them deterministically.
> Therefore I am curious that instead of treating them as fixed effects,
> whether random effects model can apply for 12 month in each year.
> We do not use Box-Jenkin approach to difference the time series as we can
> hardly find a significant association on a variable of interest. But using
> determinstic trend and seasonal dummies do....
> Thanks
> Fred
>
> On Thu, Feb 16, 2012 at 8:12 AM, Kenneth Frost <kfrost at wisc.edu> wrote:
>
>> Hi, Fred-
>>
>> The answer to your question is probably yes, but you need to provide more
>> details about what you want to do.
>>
>> Ken
>>
>> On 02/15/12, Jianyun Wu   wrote:
>>> Dear All,
>>>
>>> Is there any function or packages in R that I can treat seasonal patterns
>>> as random effects in a monthly time series?
>>>
>>> Is this possible to formulate such a model using nlme, lme4 or other
>>> available mixed model packages?
>>>
>>> Thanks and Regards
>>>
>>> Fred
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>   [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From chris at trickysolutions.com.au  Thu Feb 16 00:16:07 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Thu, 16 Feb 2012 10:16:07 +1100
Subject: [R-sig-ME] modelling seasonal patterns as random effects in a
 monthly time series
In-Reply-To: <5983470160263463854@unknownmsgid>
References: <CAOMGRD+U=07KbkdohfRMrDH_UHZzHYZwOj7WQ1wqBRe3vvP97Q@mail.gmail.com>
	<7690f0d5178e29.4f3c1fc2@wiscmail.wisc.edu>
	<77c0fdc717d586.4f3bcb78@wiscmail.wisc.edu>
	<CAOMGRDL0SBpcCMOTqWRdFhDG2ucJL1aj-hKGOvJ3q0smEyscCA@mail.gmail.com>
	<5983470160263463854@unknownmsgid>
Message-ID: <943502692803007561@unknownmsgid>

Very Sorry everyone for the redundant reply to jianyun.

for some reason I thought that came from the r-sig-Eco list I'm on and
I also managed to not process  jianyun's last sentence.

I think I must still be half asleep, my only excuse is that I haven't
had my cup of tea yet.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 16/02/2012, at 10:09, Chris Howden <chris at trickysolutions.com.au> wrote:

> Try lme and lme4. There is also a list calle r-sig-me.
>
>
>
> Chris Howden
> Founding Partner
> Tricky Solutions
> Tricky Solutions 4 Tricky Problems
> Evidence Based Strategic Development, IP Commercialisation and
> Innovation, Data Analysis, Modelling and Training
>
> (mobile) 0410 689 945
> (fax / office)
> chris at trickysolutions.com.au
>
> Disclaimer: The information in this email and any attachments to it are
> confidential and may contain legally privileged information. If you are not
> the named or intended recipient, please delete this communication and
> contact us immediately. Please note you are not authorised to copy,
> use or disclose this communication or any attachments without our
> consent. Although this email has been checked by anti-virus software,
> there is a risk that email messages may be corrupted or infected by
> viruses or other
> interferences. No responsibility is accepted for such interference. Unless
> expressly stated, the views of the writer are not those of the
> company. Tricky Solutions always does our best to provide accurate
> forecasts and analyses based on the data supplied, however it is
> possible that some important predictors were not included in the data
> sent to us. Information provided by us should not be solely relied
> upon when making decisions and clients should use their own judgement.
>
> On 16/02/2012, at 8:35, Jianyun Wu <jianyun.fred.wu at gmail.com> wrote:
>
>> Hi Ken,
>> I have a monthly time series, and the seasonal pattern is obvious where
>> peaks are in Dec and drops in Jan. However due to various "external"
>> factors, the seasonal variation during the year may change from time to
>> time. The traditional practice here is to use seasonal dummies to treat
>> them deterministically.
>> Therefore I am curious that instead of treating them as fixed effects,
>> whether random effects model can apply for 12 month in each year.
>> We do not use Box-Jenkin approach to difference the time series as we can
>> hardly find a significant association on a variable of interest. But using
>> determinstic trend and seasonal dummies do....
>> Thanks
>> Fred
>>
>> On Thu, Feb 16, 2012 at 8:12 AM, Kenneth Frost <kfrost at wisc.edu> wrote:
>>
>>> Hi, Fred-
>>>
>>> The answer to your question is probably yes, but you need to provide more
>>> details about what you want to do.
>>>
>>> Ken
>>>
>>> On 02/15/12, Jianyun Wu   wrote:
>>>> Dear All,
>>>>
>>>> Is there any function or packages in R that I can treat seasonal patterns
>>>> as random effects in a monthly time series?
>>>>
>>>> Is this possible to formulate such a model using nlme, lme4 or other
>>>> available mixed model packages?
>>>>
>>>> Thanks and Regards
>>>>
>>>> Fred
>>>>
>>>>    [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>  [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Thu Feb 16 02:35:47 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 16 Feb 2012 11:35:47 +1000 (EST)
Subject: [R-sig-ME] glmer error
In-Reply-To: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
References: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1202161126140.19412@orpheus.qimr.edu.au>

On Wed, 15 Feb 2012, Felipe Nunes wrote:

> glmer(dummy ~ x + time + (time | subject), data, family=binomial(link
> = "logit"), REML=T, verbose=T)
>
> Error in glm.fit(fr$X, fr$Y, weights = wts, offset = offset, family =
> family,  :
>
> NA/NaN/Inf in foreign function call (arg 1)
>
> I omitted NAs, changed the model specification, transformed x to log(x) but
> nothing solved the problem. I think the problem is on variable 'x' given
> that is the only one that causes that problem.

You need to provide us with a subset of your dataset that causes the same 
problem.  Alternatively, debug(glm.fit) and look at the contents of 
"x[good,]" etc.  Maybe it's separation.



From John.Morrongiello at csiro.au  Thu Feb 16 02:59:16 2012
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Thu, 16 Feb 2012 12:59:16 +1100
Subject: [R-sig-ME] random effects structure and overfitting
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB159EFDFFA3@exvic-mbx03.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120216/36a0f586/attachment-0002.pl>

From rhbc at imm.dtu.dk  Thu Feb 16 07:26:28 2012
From: rhbc at imm.dtu.dk (Rune Haubo)
Date: Thu, 16 Feb 2012 07:26:28 +0100
Subject: [R-sig-ME] glmer error
In-Reply-To: <Pine.LNX.4.64.1202161126140.19412@orpheus.qimr.edu.au>
References: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
	<Pine.LNX.4.64.1202161126140.19412@orpheus.qimr.edu.au>
Message-ID: <CAG_uk91gGHk8VA4U58X06yDy5W7C+SXtbbDKzLng8fQXY2DNww@mail.gmail.com>

On 16 February 2012 02:35, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Wed, 15 Feb 2012, Felipe Nunes wrote:
>
>> glmer(dummy ~ x + time + (time | subject), data, family=binomial(link
>> = "logit"), REML=T, verbose=T)

Will data=pool solve it?

/Rune

PS: REML=T makes no sense for GLMMs and is, I believe, just ignored.

>>
>> Error in glm.fit(fr$X, fr$Y, weights = wts, offset = offset, family =
>> family, ?:
>>
>> NA/NaN/Inf in foreign function call (arg 1)
>>
>> I omitted NAs, changed the model specification, transformed x to log(x)
>> but
>> nothing solved the problem. I think the problem is on variable 'x' given
>> that is the only one that causes that problem.
>
>
> You need to provide us with a subset of your dataset that causes the same
> problem. ?Alternatively, debug(glm.fit) and look at the contents of
> "x[good,]" etc. ?Maybe it's separation.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jwiley.psych at gmail.com  Fri Feb 17 04:29:32 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 16 Feb 2012 19:29:32 -0800
Subject: [R-sig-ME] glmer error
In-Reply-To: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
References: <CAEYv63rym5k-rgv-VbGqFPei+=nsr9hYrVxM_ymxD9DQn8oJ5g@mail.gmail.com>
Message-ID: <CANz9Z_KOyaeZbowyWuxdCBfKtChPnRWjXqaaAf3cH2y4beTP7Q@mail.gmail.com>

Hi Felipe,

Your problem is probably not too difficult to fix given some data.
The error message comes from glm.fit.  glmer() actually fits a basic
logistic model prior to fitting the random coefficient model.  You are
running into problems at this stage.  You can get to this stage pretty
easily, which simplifies debugging.

Lacking data, I wrote a short function to simulate some binary data here:

https://gist.github.com/1850238

require(lme4)
## simulate data
dat <- bsim(reps = 10)

## your formula
f <- Y ~ X + W + (1 | G)
## your call to glmer (
mc <- call("glmer", formula = f, data = dat, family = binomial(link = "logit"))
m <- eval(mc) # evaluate the glmer call (works on my data, fails on
yours, presumably)

## use the glmer call to extract the frames passed to glm.fit
base <- lme4:::lmerFrames(mc, f, NULL)
## run the logistic model (the error suggests you run into problems here)
m2 <- glm.fit(base$X, base$Y, family = binomial(link = "logit"))
m2$converge ## should be true if it runs

you can do debugging, traceback() etc. at this stage, which should
make your life a little easier.  I would examine the X and Y matrices,
check for separation, etc.

if your x variable is categorical, try looking at at the crosstabs of
it with your outcome a l?:

xtabs(~ y + x)

also in any follow up emails to the list, please report the output of
sessionInfo() per the posting guide.  The version of R/lme4 you are
running may be relevant (alternately, upgrade to the latest stable
release of R and lme4).  Douglas Bates et al have been active working
on development, and it would be rather silly for us to spend time and
confusion because we are using one version and you are using another
and neither side realizes it.

Cheers,

Josh

On Wed, Feb 15, 2012 at 9:31 AM, Felipe Nunes <felipnunes at gmail.com> wrote:
> I'm trying to fit the model
>
> glmer(dummy ~ x + time + (time | subject), data, family=binomial(link
> = "logit"), REML=T, verbose=T)
>
> but I keep receiving the following error:
>
> Error in glm.fit(fr$X, fr$Y, weights = wts, offset = offset, family =
> family, ?:
>
> NA/NaN/Inf in foreign function call (arg 1)
>
> I omitted NAs, changed the model specification, transformed x to log(x) but
> nothing solved the problem. I think the problem is on variable 'x' given
> that is the only one that causes that problem.
>
> When I run
>
> mod6 <- glmer(dummy ~ a + I(b) + I(c) + d + e + time + (time |
> subject) + (time|subjectregion), data=pool, family=binomial(link =
> "logit"), REML=T, verbose=T)
>
> I don't have any problem.
>
> Any idea about what is happening?
> *
> *
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From longrob604 at gmail.com  Fri Feb 17 13:52:45 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 12:52:45 +0000
Subject: [R-sig-ME] LMER vs MLwiN
Message-ID: <4F3E4D9D.80707@gmail.com>

Hello

I'm new to using mixed models in R. Thus far I've been using MLwiN. I am 
trying to duplicate the results in MLwiN of a logistic mixed effects model.

At the moment I have no covariates, and a data hierarchy of
pupil within class within school within commune with random effects at 
each level above pupil.

There are 9000 observations in total;

300 classes
100 schools
20 communes
These have been set as factors with as.factor(). I'm not sure if this is 
correct as they were not categorical in MLwiN (they were just ints) but 
I was getting this error before I did that:
"Error: length(f1) == length(f2) is not TRUE"

I have tried to fit a model with glmer like this:

glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS/PUPIL),data=dt,family=binomial(link = 
"logit"))

However this generates the error
"Error: cannot allocate vector of size 9.5 Gb"

I have also tried glmmPQL in the MASS package:
glmmPQL(LOSS~1,data=dt, random = 
~1|COMMUNE/SCHOOL/CLASS/PUPIL,family=binomial(link = "logit"))

However this generates /completely/ wrong estimates so I can only assume 
that I am specifying the model incorrectly in R.

If anyone can advise, I would be very grateful
Thanks
RL



From f.calboli at imperial.ac.uk  Fri Feb 17 14:06:44 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Fri, 17 Feb 2012 13:06:44 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <4F3E4D9D.80707@gmail.com>
References: <4F3E4D9D.80707@gmail.com>
Message-ID: <D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>

On 17 Feb 2012, at 12:52, W Robert Long wrote:

> Hello
> 
> I'm new to using mixed models in R. Thus far I've been using MLwiN. I am trying to duplicate the results in MLwiN of a logistic mixed effects model.
> 
> At the moment I have no covariates, and a data hierarchy of
> pupil within class within school within commune with random effects at each level above pupil.
> 
> There are 9000 observations in total;
> 
> 300 classes
> 100 schools
> 20 communes
> These have been set as factors with as.factor(). I'm not sure if this is correct as they were not categorical in MLwiN (they were just ints) but I was getting this error before I did that:
> "Error: length(f1) == length(f2) is not TRUE"
> 
> I have tried to fit a model with glmer like this:
> 
> glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS/PUPIL),data=dt,family=binomial(link = "logit"))

you seem to specify COMMUNE and SCHOOL as random effects, with no fixed effects. If I were you I would:

1) code PUPIL from 1:n so that you never have two different pupils in two different classes coded with the same code. 
2) code CLASS from 1:n (see above)

then I'd try

glmer(LOSS~ COMMUNE + SCHOOL + (1|CLASS) + (1|PUPIL) ,data=dt,family=binomial(link = "logit")) #coding class and pupil as I said will automatically take care of the nesting

as see what happens.

If you are using R 32 bits you might want to use R 64 bits to have more RAM available.

BW

F



> 
> However this generates the error
> "Error: cannot allocate vector of size 9.5 Gb"
> 
> I have also tried glmmPQL in the MASS package:
> glmmPQL(LOSS~1,data=dt, random = ~1|COMMUNE/SCHOOL/CLASS/PUPIL,family=binomial(link = "logit"))
> 
> However this generates /completely/ wrong estimates so I can only assume that I am specifying the model incorrectly in R.
> 
> If anyone can advise, I would be very grateful
> Thanks
> RL
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bbolker at gmail.com  Fri Feb 17 15:49:32 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 Feb 2012 14:49:32 +0000 (UTC)
Subject: [R-sig-ME] LMER vs MLwiN
References: <4F3E4D9D.80707@gmail.com>
Message-ID: <loom.20120217T153412-117@post.gmane.org>

W Robert Long <longrob604 at ...> writes:

> I'm new to using mixed models in R. Thus far I've been using MLwiN. I am 
> trying to duplicate the results in MLwiN of a logistic mixed effects model.
> 
> At the moment I have no covariates, and a data hierarchy of
> pupil within class within school within commune with random effects at 
> each level above pupil.
> 
> There are 9000 observations in total;
> 
> 300 classes
> 100 schools
> 20 communes
> These have been set as factors with as.factor(). I'm not sure if this is 
> correct as they were not categorical in MLwiN (they were just ints) but 
> I was getting this error before I did that:
> "Error: length(f1) == length(f2) is not TRUE"
> 
> I have tried to fit a model with glmer like this:
> 
> glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS/PUPIL),data=dt,family=binomial(link = 
> "logit"))
> 
> However this generates the error
> "Error: cannot allocate vector of size 9.5 Gb"
> 
> I have also tried glmmPQL in the MASS package:
> glmmPQL(LOSS~1,data=dt, random = 
> ~1|COMMUNE/SCHOOL/CLASS/PUPIL,family=binomial(link = "logit"))
> 
> However this generates /completely/ wrong estimates so I can only assume 
> that I am specifying the model incorrectly in R.
> 

  Hmmm. I'm not quite sure what's wrong, since a made-up example
with the same structure as yours worked pretty well on my system
(13 seconds to run, on a Linux virtual machine with a *total* of
3G of RAM).

ncomm <- 20
nschool <- 100
nclass <- 300
ntot <- 9000

set.seed(101)

u.comm <- rnorm(ncomm)
u.school <- rnorm(nschool)
u.class <- rnorm(nclass)
u.obs <- rnorm(ntot)

dt <- expand.grid(commune=factor(1:ncomm),
                  school=factor(1:(nschool/ncomm)),
                  class=factor(1:(nclass/nschool)),
                  pupil=factor(1:(ntot/nclass)))

## here lower-level units are not numbered uniquely, but that's OK as
## long as we always using nested syntax to refer to them

eta <- with(dt,u.comm[commune]+u.school[commune:school]+
            u.class[commune:school:class]+u.obs)
dt$loss <- rbinom(ntot,plogis(eta),size=1)

summary(dt)

    commune     school   class        pupil           loss       
 1      : 450   1:1800   1:3000   1      : 300   Min.   :0.0000  
 2      : 450   2:1800   2:3000   2      : 300   1st Qu.:0.0000  
 3      : 450   3:1800   3:3000   3      : 300   Median :0.0000  
 4      : 450   4:1800            4      : 300   Mean   :0.4776  
 5      : 450   5:1800            5      : 300   3rd Qu.:1.0000  
 6      : 450                     6      : 300   Max.   :1.0000  
 (Other):6300                     (Other):7200


library(lme4)
t1 <- system.time(g1 <- glmer(loss~(1|commune/school/class/pupil),data=dt,
                        family=binomial))

library(MASS)
t2 <- system.time(g2 <- glmmPQL(loss~1,
                                random=~1|commune/school/class/pupil,data=dt,
                        family=binomial))
## Error in lme.formula(fixed = zz ~ 1, random = ~1 |
commune/school/class/pupil,  : 
##   nlminb problem, convergence error code = 1
##  message = iteration limit reached without convergence (10)

lmer appears to underestimate the true variances (which were all set
to 1.0):

unlist(VarCorr(g1))
## pupil:(class:(school:commune))         class:(school:commune) 
##                     0.0000000                      0.7556695 
##                 school:commune                        commune 
##                     0.5782637                      0.3326618 

I also tried this in the development version of lme4 (which has
very different machinery internally) and got the same answer,
at least to within about 0.3% ... (it took about 3 seconds longer).
                                                   
  Can you export this data set and try it in MLWiN?



From longrob604 at gmail.com  Fri Feb 17 15:50:11 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 14:50:11 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
Message-ID: <4F3E6923.5080508@gmail.com>

Hi Federico

Thank you very much.

However, the model I'm trying to fit has no fixed effects. The MLwiN 
output gives me:
beta_0_hat: 1.012(0.107)  conditional log odds
var_f0_hat: 0.031(0.066)  variance between communues
var_v0_hat: 0.760(0.141)  variance between schools within commune
var_u0_hat: 0.186(0.38)   variance between classes within schools

This is what I am trying to duplicate in R with the same data.

BTW I am using 64 bit R

Thanks again
RL

On 17/02/2012 1:06 PM, Federico Calboli wrote:
> On 17 Feb 2012, at 12:52, W Robert Long wrote:
>
>> Hello
>>
>> I'm new to using mixed models in R. Thus far I've been using MLwiN. I am trying to duplicate the results in MLwiN of a logistic mixed effects model.
>>
>> At the moment I have no covariates, and a data hierarchy of
>> pupil within class within school within commune with random effects at each level above pupil.
>>
>> There are 9000 observations in total;
>>
>> 300 classes
>> 100 schools
>> 20 communes
>> These have been set as factors with as.factor(). I'm not sure if this is correct as they were not categorical in MLwiN (they were just ints) but I was getting this error before I did that:
>> "Error: length(f1) == length(f2) is not TRUE"
>>
>> I have tried to fit a model with glmer like this:
>>
>> glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS/PUPIL),data=dt,family=binomial(link = "logit"))
>
> you seem to specify COMMUNE and SCHOOL as random effects, with no fixed effects. If I were you I would:
>
> 1) code PUPIL from 1:n so that you never have two different pupils in two different classes coded with the same code.
> 2) code CLASS from 1:n (see above)
>
> then I'd try
>
> glmer(LOSS~ COMMUNE + SCHOOL + (1|CLASS) + (1|PUPIL) ,data=dt,family=binomial(link = "logit")) #coding class and pupil as I said will automatically take care of the nesting
>
> as see what happens.
>
> If you are using R 32 bits you might want to use R 64 bits to have more RAM available.
>
> BW
>
> F
>
>
>
>>
>> However this generates the error
>> "Error: cannot allocate vector of size 9.5 Gb"
>>
>> I have also tried glmmPQL in the MASS package:
>> glmmPQL(LOSS~1,data=dt, random = ~1|COMMUNE/SCHOOL/CLASS/PUPIL,family=binomial(link = "logit"))
>>
>> However this generates /completely/ wrong estimates so I can only assume that I am specifying the model incorrectly in R.
>>
>> If anyone can advise, I would be very grateful
>> Thanks
>> RL
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Federico C. F. Calboli
> Neuroepidemiology and Ageing Research
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>



From bbolker at gmail.com  Fri Feb 17 16:15:15 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 Feb 2012 15:15:15 +0000 (UTC)
Subject: [R-sig-ME] LMER vs MLwiN
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>
Message-ID: <loom.20120217T161249-694@post.gmane.org>

W Robert Long <longrob604 at ...> writes:

> 
> Hi Federico
> 
> Thank you very much.
> 
> However, the model I'm trying to fit has no fixed effects. The MLwiN 
> output gives me:
> beta_0_hat: 1.012(0.107)  conditional log odds
> var_f0_hat: 0.031(0.066)  variance between communues
> var_v0_hat: 0.760(0.141)  variance between schools within commune
> var_u0_hat: 0.186(0.38)   variance between classes within schools
> 
> This is what I am trying to duplicate in R with the same data.
> 
> BTW I am using 64 bit R

  OK, based on this output you shouldn't include 'pupil' in your
random effects specification (now that I think of it, you probably
shouldn't anyway, because it's unidentifiable for a Bernoulli outcome).

  If you wanted you could redo my example with your observed effects
(e.g. u.commune = rnorm(n.comm,sd=sqrt(0.031)) ...)

  Note that it is a bit harder to get uncertainty estimates on the
variance parameters in lme4.

>



From jaime.undurraga at med.kuleuven.be  Fri Feb 17 16:36:26 2012
From: jaime.undurraga at med.kuleuven.be (Jaime Undurraga)
Date: Fri, 17 Feb 2012 16:36:26 +0100
Subject: [R-sig-ME] lmer and aovlmer.fnc
Message-ID: <CAKD3jcTMJ3ZNOFu9okCD5nKkqxwOEtB6UAZD_afE3hYT-7BsJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120217/d7adee5f/attachment-0002.pl>

From longrob604 at gmail.com  Fri Feb 17 17:06:39 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 16:06:39 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <loom.20120217T161249-694@post.gmane.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>
	<loom.20120217T161249-694@post.gmane.org>
Message-ID: <4F3E7B0F.3040604@gmail.com>

Hi Ben

Thanks very much.

I have removed PUPIL as random effect (makes 100% sense to me - it's 
variance is fixed - I should have realised that myself earlier !).

glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS),data=dt,family=binomial(link = "logit"))

The output is:

Generalized linear mixed model fit by the Laplace approximation
Formula: LOSS ~ (1 | COMMUNE/SCHOOL/CLASS)
    Data: dt
    AIC   BIC logLik deviance
  10380 10408  -5186    10372
Random effects:
  Groups                 Name        Variance Std.Dev.
  CLASS:(SCHOOL:COMMUNE) (Intercept) 0.173259 0.41624
  SCHOOL:COMMUNE         (Intercept) 0.736581 0.85824
  COMMUNE                (Intercept) 0.024233 0.15567
Number of obs: 9162, groups: CLASS:(SCHOOL:COMMUNE), 310; 
SCHOOL:COMMUNE, 98; COMMUNE, 20

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   0.9874     0.1030    9.59   <2e-16 ***

The estimates look pretty close, but the standard errors for the REs are 
quite different - I seem to remember the sampling variance of REs has a 
skewed distribution, but I don't know if this has anything to do with it 
? Was this what you were getting at when you said "Note that it is a bit 
harder to get uncertainty estimates on the variance parameters in lme4" ?

BTW, MLwiN is using penalised quasi-likelihood (order=2).

I was very interested to back-test using your simulated R code - would I 
need to change it, bearing in mind that pupil isn't a random effect ? I 
did export the data into MLwiN but it gave zero estimates for all the 
random effects (and SEs) and a negative estimate for the fixed effect :(

Thanks again
RL


On 17/02/2012 3:15 PM, Ben Bolker wrote:
> W Robert Long<longrob604 at ...>  writes:
>
>>
>> Hi Federico
>>
>> Thank you very much.
>>
>> However, the model I'm trying to fit has no fixed effects. The MLwiN
>> output gives me:
>> beta_0_hat: 1.012(0.107)  conditional log odds
>> var_f0_hat: 0.031(0.066)  variance between communues
>> var_v0_hat: 0.760(0.141)  variance between schools within commune
>> var_u0_hat: 0.186(0.38)   variance between classes within schools
>>
>> This is what I am trying to duplicate in R with the same data.
>>
>> BTW I am using 64 bit R
>
>    OK, based on this output you shouldn't include 'pupil' in your
> random effects specification (now that I think of it, you probably
> shouldn't anyway, because it's unidentifiable for a Bernoulli outcome).
>
>    If you wanted you could redo my example with your observed effects
> (e.g. u.commune = rnorm(n.comm,sd=sqrt(0.031)) ...)
>
>    Note that it is a bit harder to get uncertainty estimates on the
> variance parameters in lme4.
>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Feb 17 17:37:42 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 17 Feb 2012 10:37:42 -0600
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <4F3E7B0F.3040604@gmail.com>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>
	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
Message-ID: <CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>

On Fri, Feb 17, 2012 at 10:06 AM, W Robert Long <longrob604 at gmail.com> wrote:
> Hi Ben
>
> Thanks very much.
>
> I have removed PUPIL as random effect (makes 100% sense to me - it's
> variance is fixed - I should have realised that myself earlier !).
>
> glmer(LOSS~(1|COMMUNE/SCHOOL/CLASS),data=dt,family=binomial(link = "logit"))
>
> The output is:
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: LOSS ~ (1 | COMMUNE/SCHOOL/CLASS)
> ? Data: dt
> ? AIC ? BIC logLik deviance
> ?10380 10408 ?-5186 ? ?10372
> Random effects:
> ?Groups ? ? ? ? ? ? ? ? Name ? ? ? ?Variance Std.Dev.
> ?CLASS:(SCHOOL:COMMUNE) (Intercept) 0.173259 0.41624
> ?SCHOOL:COMMUNE ? ? ? ? (Intercept) 0.736581 0.85824
> ?COMMUNE ? ? ? ? ? ? ? ?(Intercept) 0.024233 0.15567
> Number of obs: 9162, groups: CLASS:(SCHOOL:COMMUNE), 310; SCHOOL:COMMUNE,
> 98; COMMUNE, 20
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? 0.9874 ? ? 0.1030 ? ?9.59 ? <2e-16 ***
>
> The estimates look pretty close, but the standard errors for the REs are
> quite different - I seem to remember the sampling variance of REs has a
> skewed distribution, but I don't know if this has anything to do with it ?

Those are not standard errors in the glmer output.  They are simply
the variance estimates on the standard deviation scale (i.e. 0.15567 =
sqrt(0.024233)).  The reason that glmer does not provide a standard
error for an estimate of a variance component is because they don't
make sense in most cases.  The distribution of the estimator is highly
skewed.

> Was this what you were getting at when you said "Note that it is a bit
> harder to get uncertainty estimates on the variance parameters in lme4" ?
>
> BTW, MLwiN is using penalised quasi-likelihood (order=2).
>
> I was very interested to back-test using your simulated R code - would I
> need to change it, bearing in mind that pupil isn't a random effect ? I did
> export the data into MLwiN but it gave zero estimates for all the random
> effects (and SEs) and a negative estimate for the fixed effect :(
>
> Thanks again
> RL
>
>
>
> On 17/02/2012 3:15 PM, Ben Bolker wrote:
>>
>> W Robert Long<longrob604 at ...> ?writes:
>>
>>>
>>> Hi Federico
>>>
>>> Thank you very much.
>>>
>>> However, the model I'm trying to fit has no fixed effects. The MLwiN
>>> output gives me:
>>> beta_0_hat: 1.012(0.107) ?conditional log odds
>>> var_f0_hat: 0.031(0.066) ?variance between communues
>>> var_v0_hat: 0.760(0.141) ?variance between schools within commune
>>> var_u0_hat: 0.186(0.38) ? variance between classes within schools
>>>
>>> This is what I am trying to duplicate in R with the same data.
>>>
>>> BTW I am using 64 bit R
>>
>>
>> ? OK, based on this output you shouldn't include 'pupil' in your
>> random effects specification (now that I think of it, you probably
>> shouldn't anyway, because it's unidentifiable for a Bernoulli outcome).
>>
>> ? If you wanted you could redo my example with your observed effects
>> (e.g. u.commune = rnorm(n.comm,sd=sqrt(0.031)) ...)
>>
>> ? Note that it is a bit harder to get uncertainty estimates on the
>> variance parameters in lme4.
>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From r.kozarski at gmail.com  Fri Feb 17 18:55:23 2012
From: r.kozarski at gmail.com (Robert Kozarski)
Date: Fri, 17 Feb 2012 17:55:23 +0000
Subject: [R-sig-ME] crossed random effect
Message-ID: <CAJBun_zut7kooCEuSGPs6TK7wAXcGgN-b4RQ=YnX6YmVFZRYJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120217/d2f3a4a5/attachment-0002.pl>

From longrob604 at gmail.com  Fri Feb 17 20:32:42 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 19:32:42 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>
	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
Message-ID: <4F3EAB5A.9040700@gmail.com>


On 17/02/2012 4:37 PM, Douglas Bates wrote:
<snip>
>> The estimates look pretty close, but the standard errors for the REs are
>> quite different - I seem to remember the sampling variance of REs has a
>> skewed distribution, but I don't know if this has anything to do with it ?
>
> Those are not standard errors in the glmer output.  They are simply
> the variance estimates on the standard deviation scale (i.e. 0.15567 =
> sqrt(0.024233)).  The reason that glmer does not provide a standard
> error for an estimate of a variance component is because they don't
> make sense in most cases.  The distribution of the estimator is highly
> skewed.
>
<snip>

Thank you for that. Could you provide a reference for this latter point 
? I have a copy of the Pinheiro and Bates (2000) book available in our 
library, if it's in there ? Otherwise, a published paper would be also 
be fine.



From HDoran at air.org  Fri Feb 17 20:55:17 2012
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Feb 2012 14:55:17 -0500
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <4F3EAB5A.9040700@gmail.com>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>

Raudenbush and Bryk do discuss this in their book if you require a text. But, it is quite easy to show. At one point, there was an example of how to do this using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice plots in that help page now. 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of W Robert Long
> Sent: Friday, February 17, 2012 2:33 PM
> To: r-sig-mixed-models at r-project.org; Douglas Bates
> Subject: Re: [R-sig-ME] LMER vs MLwiN
> 
> 
> On 17/02/2012 4:37 PM, Douglas Bates wrote:
> <snip>
> >> The estimates look pretty close, but the standard errors for the REs are
> >> quite different - I seem to remember the sampling variance of REs has a
> >> skewed distribution, but I don't know if this has anything to do with it ?
> >
> > Those are not standard errors in the glmer output.  They are simply
> > the variance estimates on the standard deviation scale (i.e. 0.15567 =
> > sqrt(0.024233)).  The reason that glmer does not provide a standard
> > error for an estimate of a variance component is because they don't
> > make sense in most cases.  The distribution of the estimator is highly
> > skewed.
> >
> <snip>
> 
> Thank you for that. Could you provide a reference for this latter point
> ? I have a copy of the Pinheiro and Bates (2000) book available in our
> library, if it's in there ? Otherwise, a published paper would be also
> be fine.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HDoran at air.org  Fri Feb 17 20:58:15 2012
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Feb 2012 14:58:15 -0500
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>

Sorry, meant to also add that you can try this as

> example(mcmcsamp)
> densityplot(samp0)
> qqmath(samp0)

I think you can then extend this your data to see if the distributional assumptions hold

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Doran, Harold
> Sent: Friday, February 17, 2012 2:55 PM
> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
> Subject: Re: [R-sig-ME] LMER vs MLwiN
> 
> Raudenbush and Bryk do discuss this in their book if you require a text. But,
> it is quite easy to show. At one point, there was an example of how to do this
> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
> plots in that help page now.
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> > bounces at r-project.org] On Behalf Of W Robert Long
> > Sent: Friday, February 17, 2012 2:33 PM
> > To: r-sig-mixed-models at r-project.org; Douglas Bates
> > Subject: Re: [R-sig-ME] LMER vs MLwiN
> >
> >
> > On 17/02/2012 4:37 PM, Douglas Bates wrote:
> > <snip>
> > >> The estimates look pretty close, but the standard errors for the REs are
> > >> quite different - I seem to remember the sampling variance of REs has a
> > >> skewed distribution, but I don't know if this has anything to do with it
> ?
> > >
> > > Those are not standard errors in the glmer output.  They are simply
> > > the variance estimates on the standard deviation scale (i.e. 0.15567 =
> > > sqrt(0.024233)).  The reason that glmer does not provide a standard
> > > error for an estimate of a variance component is because they don't
> > > make sense in most cases.  The distribution of the estimator is highly
> > > skewed.
> > >
> > <snip>
> >
> > Thank you for that. Could you provide a reference for this latter point
> > ? I have a copy of the Pinheiro and Bates (2000) book available in our
> > library, if it's in there ? Otherwise, a published paper would be also
> > be fine.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From longrob604 at gmail.com  Fri Feb 17 21:35:46 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 20:35:46 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
Message-ID: <4F3EBA22.90507@gmail.com>

Thanks, but sadly I don't have access to Raudenbush and Bryk book.
I need to write about this, so a reference would be appreciated, but I'm 
also interested to see/show it in my data.


On 17/02/2012 7:55 PM, Doran, Harold wrote:
> Raudenbush and Bryk do discuss this in their book if you require a text. But, it is quite easy to show. At one point, there was an example of how to do this using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice plots in that help page now.
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>> bounces at r-project.org] On Behalf Of W Robert Long
>> Sent: Friday, February 17, 2012 2:33 PM
>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>
>>
>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>> <snip>
>>>> The estimates look pretty close, but the standard errors for the REs are
>>>> quite different - I seem to remember the sampling variance of REs has a
>>>> skewed distribution, but I don't know if this has anything to do with it ?
>>>
>>> Those are not standard errors in the glmer output.  They are simply
>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>> error for an estimate of a variance component is because they don't
>>> make sense in most cases.  The distribution of the estimator is highly
>>> skewed.
>>>
>> <snip>
>>
>> Thank you for that. Could you provide a reference for this latter point
>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>> library, if it's in there ? Otherwise, a published paper would be also
>> be fine.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From longrob604 at gmail.com  Fri Feb 17 21:45:20 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 20:45:20 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>
Message-ID: <4F3EBC60.1090003@gmail.com>

Thank you. I tried mcmcsamp but I received the error "Update not yet 
written". A little searching revealed that mcmcsamp may not work with 
non-gaussian models ?

On 17/02/2012 7:58 PM, Doran, Harold wrote:
> Sorry, meant to also add that you can try this as
>
>> example(mcmcsamp)
>> densityplot(samp0)
>> qqmath(samp0)
>
> I think you can then extend this your data to see if the distributional assumptions hold
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>> bounces at r-project.org] On Behalf Of Doran, Harold
>> Sent: Friday, February 17, 2012 2:55 PM
>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>
>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>> it is quite easy to show. At one point, there was an example of how to do this
>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>> plots in that help page now.
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>> bounces at r-project.org] On Behalf Of W Robert Long
>>> Sent: Friday, February 17, 2012 2:33 PM
>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>
>>>
>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>> <snip>
>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>> skewed distribution, but I don't know if this has anything to do with it
>> ?
>>>>
>>>> Those are not standard errors in the glmer output.  They are simply
>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>> error for an estimate of a variance component is because they don't
>>>> make sense in most cases.  The distribution of the estimator is highly
>>>> skewed.
>>>>
>>> <snip>
>>>
>>> Thank you for that. Could you provide a reference for this latter point
>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>> library, if it's in there ? Otherwise, a published paper would be also
>>> be fine.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HDoran at air.org  Fri Feb 17 22:05:12 2012
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Feb 2012 16:05:12 -0500
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <4F3EBC60.1090003@gmail.com>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>,
	<4F3EBC60.1090003@gmail.com>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E063C614E20@DC1VEX07MB001.air.org>

It is straight forward to write your own resampling method for your fitted model. May be worth the effort for you
________________________________________
From: W Robert Long [longrob604 at gmail.com]
Sent: Friday, February 17, 2012 3:45 PM
To: Doran, Harold
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] LMER vs MLwiN

Thank you. I tried mcmcsamp but I received the error "Update not yet
written". A little searching revealed that mcmcsamp may not work with
non-gaussian models ?

On 17/02/2012 7:58 PM, Doran, Harold wrote:
> Sorry, meant to also add that you can try this as
>
>> example(mcmcsamp)
>> densityplot(samp0)
>> qqmath(samp0)
>
> I think you can then extend this your data to see if the distributional assumptions hold
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>> bounces at r-project.org] On Behalf Of Doran, Harold
>> Sent: Friday, February 17, 2012 2:55 PM
>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>
>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>> it is quite easy to show. At one point, there was an example of how to do this
>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>> plots in that help page now.
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>> bounces at r-project.org] On Behalf Of W Robert Long
>>> Sent: Friday, February 17, 2012 2:33 PM
>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>
>>>
>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>> <snip>
>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>> skewed distribution, but I don't know if this has anything to do with it
>> ?
>>>>
>>>> Those are not standard errors in the glmer output.  They are simply
>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>> error for an estimate of a variance component is because they don't
>>>> make sense in most cases.  The distribution of the estimator is highly
>>>> skewed.
>>>>
>>> <snip>
>>>
>>> Thank you for that. Could you provide a reference for this latter point
>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>> library, if it's in there ? Otherwise, a published paper would be also
>>> be fine.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From longrob604 at gmail.com  Fri Feb 17 22:11:35 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 21:11:35 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063C614E20@DC1VEX07MB001.air.org>
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD69B@DC1VEX07MB001.air.org>,
	<4F3EBC60.1090003@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063C614E20@DC1VEX07MB001.air.org>
Message-ID: <4F3EC287.6010907@gmail.com>

Thanks. Can you point me to any resources that would explain how to do 
that ? On the one hand it's great to know that it's straightforward, and 
I'm keen to learn,  but on the other it is rather depressing as I 
haven't a clue how to do it ;)

On 17/02/2012 9:05 PM, Doran, Harold wrote:
> It is straight forward to write your own resampling method for your fitted model. May be worth the effort for you
> ________________________________________
> From: W Robert Long [longrob604 at gmail.com]
> Sent: Friday, February 17, 2012 3:45 PM
> To: Doran, Harold
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] LMER vs MLwiN
>
> Thank you. I tried mcmcsamp but I received the error "Update not yet
> written". A little searching revealed that mcmcsamp may not work with
> non-gaussian models ?
>
> On 17/02/2012 7:58 PM, Doran, Harold wrote:
>> Sorry, meant to also add that you can try this as
>>
>>> example(mcmcsamp)
>>> densityplot(samp0)
>>> qqmath(samp0)
>>
>> I think you can then extend this your data to see if the distributional assumptions hold
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>> bounces at r-project.org] On Behalf Of Doran, Harold
>>> Sent: Friday, February 17, 2012 2:55 PM
>>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>
>>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>>> it is quite easy to show. At one point, there was an example of how to do this
>>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>>> plots in that help page now.
>>>
>>>> -----Original Message-----
>>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>>> bounces at r-project.org] On Behalf Of W Robert Long
>>>> Sent: Friday, February 17, 2012 2:33 PM
>>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>>
>>>>
>>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>>> <snip>
>>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>>> skewed distribution, but I don't know if this has anything to do with it
>>> ?
>>>>>
>>>>> Those are not standard errors in the glmer output.  They are simply
>>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>>> error for an estimate of a variance component is because they don't
>>>>> make sense in most cases.  The distribution of the estimator is highly
>>>>> skewed.
>>>>>
>>>> <snip>
>>>>
>>>> Thank you for that. Could you provide a reference for this latter point
>>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>>> library, if it's in there ? Otherwise, a published paper would be also
>>>> be fine.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HDoran at air.org  Fri Feb 17 22:18:05 2012
From: HDoran at air.org (Doran, Harold)
Date: Fri, 17 Feb 2012 16:18:05 -0500
Subject: [R-sig-ME] LMER vs MLwiN
Message-ID: <686DF18D10EF1C428C2760321FB5B69E063C757E49@DC1VEX07MB001.air.org>

I think you need to consult a local statistician who can help you at this point. This list really cannot do all the work for you. 

----- Original Message -----
From: W Robert Long <longrob604 at gmail.com>
To: Doran, Harold
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Sent: Fri Feb 17 16:11:35 2012
Subject: Re: [R-sig-ME] LMER vs MLwiN

Thanks. Can you point me to any resources that would explain how to do 
that ? On the one hand it's great to know that it's straightforward, and 
I'm keen to learn,  but on the other it is rather depressing as I 
haven't a clue how to do it ;)

On 17/02/2012 9:05 PM, Doran, Harold wrote:
> It is straight forward to write your own resampling method for your fitted model. May be worth the effort for you
> ________________________________________
> From: W Robert Long [longrob604 at gmail.com]
> Sent: Friday, February 17, 2012 3:45 PM
> To: Doran, Harold
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] LMER vs MLwiN
>
> Thank you. I tried mcmcsamp but I received the error "Update not yet
> written". A little searching revealed that mcmcsamp may not work with
> non-gaussian models ?
>
> On 17/02/2012 7:58 PM, Doran, Harold wrote:
>> Sorry, meant to also add that you can try this as
>>
>>> example(mcmcsamp)
>>> densityplot(samp0)
>>> qqmath(samp0)
>>
>> I think you can then extend this your data to see if the distributional assumptions hold
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>> bounces at r-project.org] On Behalf Of Doran, Harold
>>> Sent: Friday, February 17, 2012 2:55 PM
>>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>
>>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>>> it is quite easy to show. At one point, there was an example of how to do this
>>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>>> plots in that help page now.
>>>
>>>> -----Original Message-----
>>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>>> bounces at r-project.org] On Behalf Of W Robert Long
>>>> Sent: Friday, February 17, 2012 2:33 PM
>>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>>
>>>>
>>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>>> <snip>
>>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>>> skewed distribution, but I don't know if this has anything to do with it
>>> ?
>>>>>
>>>>> Those are not standard errors in the glmer output.  They are simply
>>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>>> error for an estimate of a variance component is because they don't
>>>>> make sense in most cases.  The distribution of the estimator is highly
>>>>> skewed.
>>>>>
>>>> <snip>
>>>>
>>>> Thank you for that. Could you provide a reference for this latter point
>>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>>> library, if it's in there ? Otherwise, a published paper would be also
>>>> be fine.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From longrob604 at gmail.com  Fri Feb 17 22:21:38 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Feb 2012 21:21:38 +0000
Subject: [R-sig-ME] LMER vs MLwiN
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E063C757E49@DC1VEX07MB001.air.org>
References: <686DF18D10EF1C428C2760321FB5B69E063C757E49@DC1VEX07MB001.air.org>
Message-ID: <4F3EC4E2.7090506@gmail.com>

I wasn't aware that I had asked anyone to  "do all the work" for me ! !

I am a statistics graduate student but I do not know R very well, so, in 
case anyone can point me towards any resources that can help, I would be 
most humbly grateful.


On 17/02/2012 9:18 PM, Doran, Harold wrote:
> I think you need to consult a local statistician who can help you at this point. This list really cannot do all the work for you.
>
> ----- Original Message -----
> From: W Robert Long<longrob604 at gmail.com>
> To: Doran, Harold
> Cc: r-sig-mixed-models at r-project.org<r-sig-mixed-models at r-project.org>
> Sent: Fri Feb 17 16:11:35 2012
> Subject: Re: [R-sig-ME] LMER vs MLwiN
>
> Thanks. Can you point me to any resources that would explain how to do
> that ? On the one hand it's great to know that it's straightforward, and
> I'm keen to learn,  but on the other it is rather depressing as I
> haven't a clue how to do it ;)
>
> On 17/02/2012 9:05 PM, Doran, Harold wrote:
>> It is straight forward to write your own resampling method for your fitted model. May be worth the effort for you
>> ________________________________________
>> From: W Robert Long [longrob604 at gmail.com]
>> Sent: Friday, February 17, 2012 3:45 PM
>> To: Doran, Harold
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>
>> Thank you. I tried mcmcsamp but I received the error "Update not yet
>> written". A little searching revealed that mcmcsamp may not work with
>> non-gaussian models ?
>>
>> On 17/02/2012 7:58 PM, Doran, Harold wrote:
>>> Sorry, meant to also add that you can try this as
>>>
>>>> example(mcmcsamp)
>>>> densityplot(samp0)
>>>> qqmath(samp0)
>>>
>>> I think you can then extend this your data to see if the distributional assumptions hold
>>>
>>>> -----Original Message-----
>>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>>> bounces at r-project.org] On Behalf Of Doran, Harold
>>>> Sent: Friday, February 17, 2012 2:55 PM
>>>> To: W Robert Long; r-sig-mixed-models at r-project.org; Douglas Bates
>>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>>
>>>> Raudenbush and Bryk do discuss this in their book if you require a text. But,
>>>> it is quite easy to show. At one point, there was an example of how to do this
>>>> using mcmcsamp() in the lme4 package (I think). But, I don't see the lattice
>>>> plots in that help page now.
>>>>
>>>>> -----Original Message-----
>>>>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>>>>> bounces at r-project.org] On Behalf Of W Robert Long
>>>>> Sent: Friday, February 17, 2012 2:33 PM
>>>>> To: r-sig-mixed-models at r-project.org; Douglas Bates
>>>>> Subject: Re: [R-sig-ME] LMER vs MLwiN
>>>>>
>>>>>
>>>>> On 17/02/2012 4:37 PM, Douglas Bates wrote:
>>>>> <snip>
>>>>>>> The estimates look pretty close, but the standard errors for the REs are
>>>>>>> quite different - I seem to remember the sampling variance of REs has a
>>>>>>> skewed distribution, but I don't know if this has anything to do with it
>>>> ?
>>>>>>
>>>>>> Those are not standard errors in the glmer output.  They are simply
>>>>>> the variance estimates on the standard deviation scale (i.e. 0.15567 =
>>>>>> sqrt(0.024233)).  The reason that glmer does not provide a standard
>>>>>> error for an estimate of a variance component is because they don't
>>>>>> make sense in most cases.  The distribution of the estimator is highly
>>>>>> skewed.
>>>>>>
>>>>> <snip>
>>>>>
>>>>> Thank you for that. Could you provide a reference for this latter point
>>>>> ? I have a copy of the Pinheiro and Bates (2000) book available in our
>>>>> library, if it's in there ? Otherwise, a published paper would be also
>>>>> be fine.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From llopezt2000 at yahoo.com.mx  Sat Feb 18 18:13:04 2012
From: llopezt2000 at yahoo.com.mx (lopez toledo)
Date: Sat, 18 Feb 2012 09:13:04 -0800 (PST)
Subject: [R-sig-ME] Need some help with glmer output
Message-ID: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120218/78204928/attachment-0002.pl>

From jennifer.s.lyon at gmail.com  Sat Feb 18 18:44:48 2012
From: jennifer.s.lyon at gmail.com (Jennifer Lyon)
Date: Sat, 18 Feb 2012 10:44:48 -0700
Subject: [R-sig-ME] Moving from lme4a to lme4Eigen correlation of random
	effects goes to 1
Message-ID: <CAKstpn6LX8OB+zAdZisHnz3XTYiC6449MsMXCCQrejp9eFht5w@mail.gmail.com>

Hi:

I am modeling the score participants in three conditions achieved at
three times.  The times are not equally spaced, with the difference
between t2 and t3 over an order of magnitude longer than the
difference between t1 and t2. The design is not balanced. The variable
LMNo is unique per individual.

         time
condition t1 t2 t3
        A 76 75 72
        B 18 18 17
        C 28 27 26

I've attached a plot of the data.

The literature suggests that there are individual differences
at the different times, so I fitted the following model:

me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)

When moving from lme4a to lme4Eigen, the correlations of the random
effects all went to 1.000. I was slightly surprised by this change of
events. Is this result indicating that the simpler model:

me.c.m0<-lmer(score~ 1+time + condition + (1|LMNo), me.c, REML = 0)

is sufficient? I ask because when I do a likelihood ratio test
using anova, the p-value is small and AIC prefers the more complex
model while BIC prefers the simpler model. Does the correlation
going to one also indicate a preference for the simpler model?

#run in lme4Eigen
anova(me.c.m0, me.c.m)
Data: me.c
Models:
me.c.m0: score ~ 1 + time + condition + (1 | LMNo)
me.c.m: score ~ 1 + time + condition + (1 + time | LMNo)
        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
me.c.m0  7 2069.8 2096.9 -1027.9   2055.8
me.c.m  12 2055.3 2101.9 -1015.7   2031.3 24.445      5  0.0001782 ***

I don't know if this is related, but when I run profile() on
the models in lme4a and lme4Eigen, I get an error (which is
shown below). I have additional information on the participants,
such as gender and which participants are siblings, but before
I go for a more complex model, I'd like to better understand
what this model is telling me.

Thanks for any and all insights.

Jen

Here are the details of fitting the models in lme4a and lme4Eigen:

In lme4a_0.9996875-1

> library(lme4a)
> me.c<-read.table("mixed-effects-data-clean.txt", header=T)

> me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
> summary(me.c.m)
Linear mixed model fit by maximum likelihood ['summary.mer']
Formula: score ~ 1 + time + condition + (1 + time | LMNo)
   Data: me.c
      AIC       BIC    logLik  deviance
 2049.704  2096.236 -1012.852  2025.704

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 LMNo     (Intercept) 41.280   6.425
          timet2       6.007   2.451    0.452
          timet3       5.174   2.275    0.382 0.997
 Residual              4.314   2.077
Number of obs: 357, groups: LMNo, 122

Fixed effects:
            Estimate Std. Error t value
(Intercept)  27.8800     0.7727   36.08
timet2       -3.6805     0.3492  -10.54
timet3       -4.2801     0.3429  -12.48
conditionB   -1.9732     1.7585   -1.12
conditionC  -10.0301     1.4833   -6.76

Correlation of Fixed Effects:
           (Intr) timet2 timet3 cndtnB
timet2      0.086
timet3      0.039  0.687
conditionB -0.436  0.000  0.000
conditionC -0.517 -0.001  0.000  0.227

> profile(me.c.m)
Error in rbind2(fillmat(pres, lowcut, zeta, wp1), fillmat(nres, lowcut,  :
  error in evaluating the argument 'y' in selecting a method for
function 'rbind2': Error in while (i < nr && abs(mat[i, ".zeta"]) <=
cutoff && mat[i, cc] >  :
  missing value where TRUE/FALSE needed

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4a_0.9996875-1  MatrixModels_0.3-1 minqa_1.1.18       Rcpp_0.9.10
[5] Matrix_1.0-3       lattice_0.20-0

loaded via a namespace (and not attached):
[1] codetools_0.2-8  colorspace_1.1-1 grid_2.14.1      int64_1.1.2
[5] nlme_3.1-103     splines_2.14.1

> q()

R --vanilla
> library(lme4Eigen)

> me.c<-read.table("mixed-effects-data-clean.txt", header=T)

> me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
> summary(me.c.m)
Linear mixed model fit by maximum likelihood ['summary.mer']
Formula: score ~ 1 + time + condition + (1 + time | LMNo)
   Data: me.c

      AIC       BIC    logLik  deviance
 2055.339  2101.872 -1015.669  2031.339

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 LMNo     (Intercept) 39.351   6.273
          timet2       2.440   1.562    1.000
          timet3       1.730   1.315    1.000 1.000
 Residual              5.507   2.347
Number of obs: 357, groups: LMNo, 122

Fixed effects:
            Estimate Std. Error t value
(Intercept)  27.7704     0.7639   36.35
timet2       -3.6838     0.3348  -11.00
timet3       -4.2865     0.3305  -12.97
conditionB   -1.9870     1.7285   -1.15
conditionC   -9.5437     1.4583   -6.54

Correlation of Fixed Effects:
           (Intr) timet2 timet3 cndtnB
timet2      0.138
timet3      0.089  0.569
conditionB -0.433  0.001  0.000
conditionC -0.514 -0.002 -0.001  0.227

> profile(me.c.m)
Warning message:
In sqrt(ores$fval - base) : NaNs produced
Error in rbind2(fillmat(pres, lowcut, zeta, wp1), fillmat(nres, lowcut,  :
  error in evaluating the argument 'x' in selecting a method for
function 'rbind2': Error in while (i < nr && abs(mat[i, ".zeta"]) <=
cutoff && mat[i, cc] >  :
  missing value where TRUE/FALSE needed

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4Eigen_0.9996875-9 lattice_0.20-0

loaded via a namespace (and not attached):
[1] colorspace_1.1-1 grid_2.14.1      Matrix_1.0-3     minqa_1.1.18
[5] nlme_3.1-103     Rcpp_0.9.10      splines_2.14.1
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mixed-model-participant-score-by-condition.pdf
Type: application/pdf
Size: 6002 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120218/b788c8a3/attachment-0002.pdf>

From jwiley.psych at gmail.com  Sat Feb 18 22:56:01 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 18 Feb 2012 13:56:01 -0800
Subject: [R-sig-ME] LMM with Big data using binary DV
In-Reply-To: <CAO7JsnQVEiw9Y9SA6jNbhqejMxU87bWJL5MozfKzX++McOcyTA@mail.gmail.com>
References: <CALsYQZfmyOgAA-nZ=TYheLVxSbg675UgFw0KpkpNUfJ9kKhseQ@mail.gmail.com>
	<CANz9Z_LOwg-Jh=A0v95RGpKVqLUCmQ3wHvUk77tXTrPP1KS93Q@mail.gmail.com>
	<CAO7JsnQVEiw9Y9SA6jNbhqejMxU87bWJL5MozfKzX++McOcyTA@mail.gmail.com>
Message-ID: <CANz9Z_JirWeYz5EFkQUXY6gV9uHjktFQDfxs5eXNmS67cb64NQ@mail.gmail.com>

Apologies for the delay.  I had not saved the process to simulate the
data.  I created a new simulation and spent several days trying to get
it working on my laptop, without much success.  My first simulation
appears to have been something of a fluke in terms of speed.  The
present simulation used a data set of 200 groups with 5,000
replications each, 6 'observation level' predictors and 3 'group'
level predictors.  I backed down from 2 million to 1 million because
it still took over an hour to run and I was tired of waiting.
Curiously, lme4Eigen::glmer reports Inf and -Inf deviance and
loglikeihood values.  The parameter estimates from all three versions
are similar, though not exact.  With nAGQ = 0, the loglikelihood and
deviance between lme4Eigen and lme4 are similar.  Full code, timings,
and commented output form my runs are in the script, but the synopsis
is:

lme4::glmer
## > system.time(m1 <- glmer(dat$Y ~ dat$X + dat$W + (1 | dat$G),
family = "binomial"))
##    user  system elapsed
## 4158.10  117.19 4313.85

lme4Eigen::glmer
## > system.time(m1 <- glmer(dat$Y ~ dat$X + dat$W + (1 | dat$G),
family = "binomial"))
##    user  system elapsed
##  129.03    9.67  140.62
## infinite deviance, otherwise same ball park as the other two

lme4Eigen::glmer with nAGQ = 0
## > system.time(mfast <- glmer(dat$Y ~ dat$X + dat$W + (1 | dat$G),
family = "binomial", nAGQ = 0))
##    user  system elapsed
##  128.51    9.59  139.61


System characteristics:

R Under development (unstable) (2012-02-03 r58258)
Platform: x86_64-pc-mingw32/x64 (64-bit)
lme4Eigen_0.9996875-9
lme4_0.999375-42

Windows 7 x64; 6GB memory @ 1066MHZ; intel core i7 920 @ 2.66GHZ



On Thu, Feb 9, 2012 at 12:13 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Feb 8, 2012 at 8:28 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>> Hi AC,
>>
>> My personal preference would be glmer from the lme4 package. ?I prefer
>> the Laplace approximation for the likelihood over the quasilikelihood
>> in glmmPQL. ?To give some exemplary numbers, I simulated a dataset
>> with 2 million observations nested within 200 groups (10,000
>> observations per group). ?I then ran an random intercepts model using:
>>
>> system.time(m <- glmer(Y ~ X + W + (1 | G), family = "binomial"))
>>
>> where the matrices/vectors are of sizes: Y = [2 million, 1]; X = [2
>> million, 6]; W = [2 million, 3]; G = [2 million, 1]
>>
>> This took around 481 seconds to fit on a 1.6ghz dual core laptop.
>> With the OS and R running, my system used ~ 6GB of RAM for the model
>> and went up to ~7GB to show the summary (copies of the data are
>> made---changed in the upcoming version of lme4).
>>
>> So as long as you have plenty of memory, you should have no trouble
>> modelling your data using glmer(). ?To initially make sure all your
>> code works, I might use a subset of your data (say 10k), once you are
>> convinced you have the model you want, run it on the full data.
>
> If you would have an opportunity to run that model fit or a comparable
> on lme4Eigen::glmer we would appreciate information about speed,
> accuracy and memory usage.
>
> In lme4Eigen::glmer there are different levels of precision in the
> approximation to the deviance being optimizer. ?These are controlled
> by the nAGQ argument to the function. ?The default, nAGQ=1, uses the
> Laplace approximation. ?The special value nAGQ=0 also uses the Laplace
> approximation but profiles out the fixed-effects parameters. ?This
> profiling is not exact but usually gets you close to the optimum that
> you would get from nAGQ=1, but much, much faster. ?In a model like
> this you can also use nAGQ>1 and <= 25. ?On the model fits we have
> tried we don't see a lot of difference in timing between, say, nAGQ=9
> and nAGQ=25 but on a model fit like this you might.
>
> As a fallback, we would appreciate the code that you used to simulate
> the response. ?We could generate something ourselves, of course, but
> it is easier to compare when you copy someone else's simulation.
>> On Wed, Feb 8, 2012 at 5:28 PM, AC Del Re <acdelre at stanford.edu> wrote:
>>> Hi,
>>>
>>> I have a huge dataset (2.5 million patients nested within ?> 100
>>> facilities) and would like to examine variability across facilities in
>>> program utilization (0=n, 1=y; utilization rates are low in general), along
>>> with patient and facility predictors of utilization.
>>>
>>> I have 3 questions:
>>>
>>> 1. What program and/or package(s) do you recommend for running LMMs with
>>> big data (even if they are not R packages)?
>>>
>>> 2. Are there any clever work arounds (e.g., random sampling of subset of
>>> data, etc) that would allow me to use only R packages to run this dataset
>>> (assuming I need to use another program due to the size of the dataset)?
>>>
>>> 3. What type of LMM is recommended with a binary DV similar to the one I am
>>> wanting to examine? I know of two potential options (family=binomial option
>>> in lmer and the glmmPQL in the MASS package) but am not sure which is more
>>> appropriate or what other R packages and functions are available for this
>>> purpose?
>>>
>>> Thank you,
>>>
>>> AC
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group
>> University of California, Los Angeles
>> https://joshuawiley.com/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/

From bbolker at gmail.com  Sun Feb 19 17:02:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 19 Feb 2012 16:02:08 +0000 (UTC)
Subject: [R-sig-ME] LMER vs MLwiN
References: <4F3E4D9D.80707@gmail.com>
	<D19F8A15-C4A6-4D2C-B63C-0A9DA1F2B161@imperial.ac.uk>
	<4F3E6923.5080508@gmail.com>	<loom.20120217T161249-694@post.gmane.org>
	<4F3E7B0F.3040604@gmail.com>
	<CAO7JsnSjL0OmV8Cynbtuxm0Q=zW6TXz4taMF3mfvfxhkPBzO5w@mail.gmail.com>
	<4F3EAB5A.9040700@gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E063CBFD698@DC1VEX07MB001.air.org>
	<4F3EBA22.90507@gmail.com>
Message-ID: <loom.20120219T163118-782@post.gmane.org>


W Robert Long <longrob604 at ...> writes:

> 
> Thanks, but sadly I don't have access to Raudenbush and Bryk book.
> I need to write about this, so a reference would be appreciated, but I'm 
> also interested to see/show it in my data.

 I have posted a worked example at http://glmm.wikidot.com/examples ,
specifically

http://glmm.wikidot.com/
http://glmm.wikidot.com/local--files/examples/biglogist.pdf

  I was able to see some relevant bits of Raudenbush and Bryk by
going to Google books, finding the book, and searching for "skewed",
the 7th hit, on p 55, is worth looking at.

>  On 17/02/2012 7:55 PM, Doran, Harold wrote: > Raudenbush and Bryk
> do discuss this in their book if you require a text. But, it is
> quite easy to show. At one point, there was an example of how to do
> this using mcmcsamp() in the lme4 package (I think). But, I don't
> see the lattice plots in that help page now.  >

mcmcsamp doesn't work for GLMMs at present ..



From ricr2 at cantab.net  Sun Feb 19 23:08:59 2012
From: ricr2 at cantab.net (Rebecca Ross)
Date: Sun, 19 Feb 2012 22:08:59 +0000
Subject: [R-sig-ME] GLMER - p values proportion data
Message-ID: <CALKh-7qA3quARH_8m+NP_0M04vbgGpa12UyUyHZb21Zsw4-yxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/8b3f9c83/attachment-0002.pl>

From hans at sociologi.cjb.net  Mon Feb 20 01:38:49 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 20 Feb 2012 01:38:49 +0100
Subject: [R-sig-ME] Use of mixed models when the causal relations are
	unclear?
Message-ID: <20120220003849.GA10481@isas.ltsp>

When I was looking at official statistics for level of education, for
native vs migrant populations in different areas of a city I'm
currently studying, it struck me that I could use mixed models to back
up an initial observation I did. After conducting the analysis, I was
unsure whether or not this was a proper thing to do. Perhaps you can
give some judgement on this?

Here are some rows from two tables of official statistics that gave me the idea:

native.education (educational level, measured in years)
            Area  -8    9   11   12   14   15+  NA   SUM
1       Gunnared 461 1772 1721 1427  557   532 104  6574
2     L?rjedalen 443 1568 1755 1587  802   830  84  7069
...
15        Styrs? 242  449  648  536  437   686  23  3021


migrant.education
            Area   -8    9   11   12   14  15+   NA  SUM
1       Gunnared 1474 1627 2166 1723  988 1097  817 9892
2     L?rjedalen 1839 1667 1947 1668  945  918 1008 9992
...
15        Styrs?    7   17   27   16   25   47   13  152

In the area "Styrs?", being migrant was associated with having a higher
level of education than the natives in the area. The same applies to
the area "Gunnared", but for the area "L?rjedalen" the reverse seems
to hold. I used lmer in lme4 to test my hypothesis.

Based on the tables I created a data.frame which you can get here:

print(load(url("http://code.cjb.net/temp/dotplottest.RData")))
[1] "test.df"
> str(test.df)
'data.frame':	362319 obs. of  3 variables:
 $ area     : Factor w/ 21 levels "Gunnared","L?rjedalen",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ native   : Factor w/ 2 levels "yes","no": 1 1 1 1 1 1 1 1 1 1 ...
 $ education: Ord.factor w/ 6 levels "Folkskola"<"Grundskola"<..: 1 1 1 1 1 1 1 1 1 1 ...

(I translated the labels of the education factor into a rough estimate
in years in the tables above, since the labels are only meaningful for
speakers of the swedish language)

I fitted the following model on the data:

library(lme4)
my.fit <- lmer(education ~ 1 + (native | area), data = test.df)

and I got an nice graph:

dotplot(ranef(my.fit, postVar = T))

The question I have is this: if education is a factor in the selection
of which area into which a migrant will move, then education is not
dependent on the area, and the model is not "true".

While the causal relations in this case thus are unclear, or mixed, is
it still reasonable to use the mixed model as I did to get proper
confidence intervals, for the mere correlation/association between
area, nativeness and educational level?



From hans at sociologi.cjb.net  Mon Feb 20 02:01:09 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 20 Feb 2012 02:01:09 +0100
Subject: [R-sig-ME] Need some help with glmer output
In-Reply-To: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
Message-ID: <20120220010109.GB10481@isas.ltsp>

On Sat, Feb 18, 2012 at 09:13:04AM -0800, lopez toledo wrote:
> Dears lme4 users:
> I'm doing a repeated measurement analysis, which seems pretty obvious to 
> me, but I'm getting some strange results, which I do not 
> understand. Hope you can help me!! Thanks in advance!
> 
> I'm evaluating the effects of Defoliation Treatments (4 levels), Gender 
> (Male/Female) and Time on several responses (Growth , leaf production, 
> inflorescence production, etc) of a palm dioecious species 
> 
> I have about 550 palms total which have been measured 3 times. My main question is whether the effects depends on the intensity of defoliation, palm gender and how this has changed through time. I am 
> considering the effects of repeated measurement as Palm/Time
> I am exploring with the model below, which include as fixed factors DT*G*Time and as 
> random factor Palm/Time to consider the effect of repeated measurements. 
> 
> In this case, I'm using glmer, 'cos I've have counts as response variables (number of leaves, number of inflorescences, etc).
> 
> Model1<-glmer(Total leaves ~ DT * G * Time + (1 | palm/Time), family=poisson)
> 
> 
> I've got two questions:
> 1) Am 
> I considering the random effects correctly or not? as when I run the model there is the following message
> 
> 
> "Number of levels of a grouping factor for the random effects
> is *equal* to n, the number of observations"

Is it not enough to define one simple random effect for palm? Wouldn't
that take care of the problem of repeated measurements of the same
palm?

Try:

Model1<-glmer(Total leaves ~ DT * G * Time + (1 | palm), family=poisson)



From hans at sociologi.cjb.net  Mon Feb 20 02:07:52 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 20 Feb 2012 02:07:52 +0100
Subject: [R-sig-ME] Need some help with glmer output
In-Reply-To: <20120220010109.GB10481@isas.ltsp>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
	<20120220010109.GB10481@isas.ltsp>
Message-ID: <20120220010752.GC10481@isas.ltsp>

On Mon, Feb 20, 2012 at 02:01:09AM +0100, Hans Ekbrand wrote:
> On Sat, Feb 18, 2012 at 09:13:04AM -0800, lopez toledo wrote:
> > Dears lme4 users:
> > I'm doing a repeated measurement analysis, which seems pretty obvious to 
> > me, but I'm getting some strange results, which I do not 
> > understand. Hope you can help me!! Thanks in advance!
> > 
> > I'm evaluating the effects of Defoliation Treatments (4 levels), Gender 
> > (Male/Female) and Time on several responses (Growth , leaf production, 
> > inflorescence production, etc) of a palm dioecious species 
> > 
> > I have about 550 palms total which have been measured 3 times. My main question is whether the effects depends on the intensity of defoliation, palm gender and how this has changed through time. 

Rereading this paragraph, and in particular "and how this has changed
through time", I think you might want to specify Time as a random
variable too. However, I think it should be on its own, like this:

Model1<-glmer(Total leaves ~ DT * G + (1 | Time) + (1 | palm), family=poisson)

> Is it not enough to define one simple random effect for palm? Wouldn't
> that take care of the problem of repeated measurements of the same
> palm?
> 
> Try:
> 
> Model1<-glmer(Total leaves ~ DT * G * Time + (1 | palm), family=poisson)



From llopezt2000 at yahoo.com.mx  Mon Feb 20 05:16:37 2012
From: llopezt2000 at yahoo.com.mx (lopez toledo)
Date: Sun, 19 Feb 2012 20:16:37 -0800 (PST)
Subject: [R-sig-ME] More help with glmer!
In-Reply-To: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
Message-ID: <1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/12d81da6/attachment-0002.pl>

From jwiley.psych at gmail.com  Mon Feb 20 05:43:37 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 19 Feb 2012 20:43:37 -0800
Subject: [R-sig-ME] More help with glmer!
In-Reply-To: <1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
	<1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>
Message-ID: <A13E908F-C3BF-40E8-813B-62F8A94040C9@gmail.com>

Hi,

The lack of residual variance is not a function of glmer per se, rather the distribution you used.  The poisson distribution only has parameter---the expectation and dispersion.

The variance of the random subject effect is the variability in intercepts by subject.  In your case something like the variability in expected log count when treatment is 0 for different subjects.  It is very small.

glmer does use a maximum likelihood estimator and returns maximum likelihood estimates.  The Laplace approximation is a numerical way to calculate them (optimize the likelihood function).

You can set nAGQ to some number higher than 1 to increase the number of points evaluated and obtain slightly more accurate estimates at the cost of speed.

Cheers,

Josh

On Feb 19, 2012, at 20:16, lopez toledo <llopezt2000 at yahoo.com.mx> wrote:

> Hi all:Hope you understand I'm not an statistician and hope my question is not very basic. I did have a deep look to old posts but could not find an appropriate response. So, let me ask my question!
> I'm doing some lmer and glmer (poisson) models, but I noticed that for glmer there is not residual variance for the random effects. So, how do variance values should be interpreted in a glmer? What does the 6.8578 e-06 mean in the example below? I understand the "Subject" factor is explaining 6.8 e-06 of the variance, but what is the total or the residual variance? This number does not say many to me. 
> Additionally, is it possible to fit a glmer with maximum likelihood? or is Laplace approximation the only option?
> 
> Thanks for your help and comprehension ? 
> 
>> summary(glmer1)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: Response ~ Treatment + (1 | Subject) 
> ?? AIC? BIC logLik deviance
> ?788.8 1052 -345.4??? 690.8
> Random effects:
> ?Groups Name??????? Variance?? Std.Dev. 
> Subject ?? (Intercept) 6.8578e-06 0.0026187
> Number of obs: 1604, groups: NNo, 555
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From llopezt2000 at yahoo.com.mx  Mon Feb 20 06:23:54 2012
From: llopezt2000 at yahoo.com.mx (lopez toledo)
Date: Sun, 19 Feb 2012 21:23:54 -0800 (PST)
Subject: [R-sig-ME] More help with glmer!
In-Reply-To: <A13E908F-C3BF-40E8-813B-62F8A94040C9@gmail.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
	<1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>
	<A13E908F-C3BF-40E8-813B-62F8A94040C9@gmail.com>
Message-ID: <1329715434.77201.YahooMailNeo@web161204.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/138fe487/attachment-0002.pl>

From llopezt2000 at yahoo.com.mx  Mon Feb 20 06:47:29 2012
From: llopezt2000 at yahoo.com.mx (lopez toledo)
Date: Sun, 19 Feb 2012 21:47:29 -0800 (PST)
Subject: [R-sig-ME] Need some help with glmer output (Hans Ekbrand)
Message-ID: <1329716849.85927.YahooMailNeo@web161204.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/813accdf/attachment-0002.pl>

From jwiley.psych at gmail.com  Mon Feb 20 07:56:54 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 19 Feb 2012 22:56:54 -0800
Subject: [R-sig-ME] More help with glmer!
In-Reply-To: <1329715434.77201.YahooMailNeo@web161204.mail.bf1.yahoo.com>
References: <1329585184.69874.YahooMailNeo@web161201.mail.bf1.yahoo.com>
	<1329711397.80883.YahooMailNeo@web161202.mail.bf1.yahoo.com>
	<A13E908F-C3BF-40E8-813B-62F8A94040C9@gmail.com>
	<1329715434.77201.YahooMailNeo@web161204.mail.bf1.yahoo.com>
Message-ID: <4B0AB5BA-42B0-4DF6-991C-81C4B3004972@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120219/52798c77/attachment-0002.pl>

From hans at sociologi.cjb.net  Mon Feb 20 08:41:01 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 20 Feb 2012 08:41:01 +0100
Subject: [R-sig-ME] Need some help with glmer output (Hans Ekbrand)
In-Reply-To: <1329716849.85927.YahooMailNeo@web161204.mail.bf1.yahoo.com>
References: <1329716849.85927.YahooMailNeo@web161204.mail.bf1.yahoo.com>
Message-ID: <20120220074101.GA25224@isas.ltsp>

On Sun, Feb 19, 2012 at 09:47:29PM -0800, lopez toledo wrote:
> Thanks Hans for your two messages to my question on glmer yesterday. May I ask another question?

Sure, I was just thinking about my second suggestion, it required the
Time variable to have certain properties that you did not explictly
state it had.

> In your first reply you suggested to include only one single random effects (Palm) and Time as Fixed factor (1). I like that model as I can see the effects among years.? However in your second suggested model, Time as random effect does not indicate to me whether there is difference among years. There is some variance, but variance does not say nothing to me, specially if there is not a total/residual variance to compare with!

If you like the first model, then use it. The second version only makes sense
if there are idiosyncracies of the years, e.g. very little rain in
year 2010 or something like that.

If you're only interested in general differences in growth rate
between plants that are 1, 2, and 3 years old, then the first model is
what you want.

> 1) Model1<-glmer(Total leaves ~ DT * G * Time + (1 | palm), family=poisson)
> 2) Model1<-glmer(Total leaves ~ DT * G + (1 | Time) + (1 | palm), family=poisson)
> 
> Can you let me know your thought?
> 
> Leo



From h.colleran at ucl.ac.uk  Mon Feb 20 17:08:03 2012
From: h.colleran at ucl.ac.uk (Heidi Colleran)
Date: Mon, 20 Feb 2012 16:08:03 +0000
Subject: [R-sig-ME] overlapping multiple membership specification in lme4
Message-ID: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120220/ae7d5105/attachment-0002.pl>

From datkins at u.washington.edu  Mon Feb 20 21:29:07 2012
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 20 Feb 2012 12:29:07 -0800
Subject: [R-sig-ME] overlapping multiple membership specification in lme4
In-Reply-To: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>
References: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>
Message-ID: <4F42AD13.9030708@u.washington.edu>


Hi Heidi--

This issue has come up before on the listserv, and last year there were 
responses on how to fit multiple membership models in both lmer() and 
MCMCglmm() -- though, both involve some fiddling to work properly.  Take 
a look at the various postings in the following thread:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q2/006318.html

Hope that helps.

cheers, Dave

Dear List,

I'm a PhD student writing to ask for some help on specifying a model in R.
I'm currently using the lme4 package.

I'm trying to analyse how migration effects womens fertility rates in a
sample of 22 groups (villages). I have a sample of ~1500 women who were
born and continue to live in one of the 22 groups. I treat the model as
women clustered within groups. Each woman has an origin group ID and a
current group ID, so for women who never migrated these ID numbers will be
the same. I want to obtain variance parameters for the different groupings,
to see whether origin or current group has a greater effect on fertility
rates, with a view to then seeing if other group-level predictors explain
some of the variance, but I'm not sure if I have specified the model
correctly, or if I need to make some changes to the data (for example
weighting the memberships somehow).

I started with (what I think is) a cross-classified model of the form
(y~1+(1|originGroupID)+(1|currentGroupID)),
but given that the groups themselves are exactly the same thing, and that
membership in them overlaps, I am worried that this will cause problems for
estimating the group variances and covariances, or that this specification
perhaps doesn't make sense. Should the groups be coded differently?

If anyone could point me in the direction of some references specific to
this kind of overlapping structure, or indeed offer some advice as to
different ways I could specify the model, or recode the data somehow, I
would be extremely grateful.

Many thanks,

Heidi
--

	[[alternative HTML version deleted]]

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From bbolker at gmail.com  Tue Feb 21 03:42:50 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Feb 2012 02:42:50 +0000 (UTC)
Subject: [R-sig-ME] GLMER - p values proportion data
References: <CALKh-7qA3quARH_8m+NP_0M04vbgGpa12UyUyHZb21Zsw4-yxg@mail.gmail.com>
Message-ID: <loom.20120221T033813-997@post.gmane.org>

Rebecca Ross <ricr2 at ...> writes:

> 
> Dear All,
> 
> I would like to analyse proportion data (number of trials, number of
> successes) with one fixed effect (continuous) and one random effect
> (categorical). I believe (using Bolker TREE paper analysis) that I should
> be using a GLMER model. Can I trust the p-values produced by this, and if
> not, what should I be doing?
> 
> I have tried to follow up on various R mailing lists, but I am not 100%
> sure what the right answer is.
> 

  Using glmer (i.e. a GLMM) seems perfectly reasonable.  The p values
produced by summary() for a glmer model are (as is typical in the context
of generalized linear models) asymptotic Wald test statistics.  They
may be OK for large, well behaved data sets.  To get more reliable
likelihood ratio test statistics, either fit reduced models and use
anova(), or use drop1().  However, these are still asymptotic.
If you have a large number of random-effect blocks (>40 or so) these
should be very reliable.  If you have a smaller number and you really
want reliable p-values you will probably need to do some form of
resampling (parametric or non-parametric bootstrap, MCMC, etc.).



From i.m.s.white at ed.ac.uk  Tue Feb 21 11:34:41 2012
From: i.m.s.white at ed.ac.uk (i white)
Date: Tue, 21 Feb 2012 10:34:41 +0000
Subject: [R-sig-ME] overlapping multiple membership specification in lme4
In-Reply-To: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>
References: <CAL27_THnJm3CMd2aXkypBV4=7g9hbzpVbMHBEzxsW1NdACm2EA@mail.gmail.com>
Message-ID: <4F437341.1020805@ed.ac.uk>

Heidi,

I know nothing about multiple membership models but your problem reminds 
me of what plant breeders call a diallel cross design, in which (e.g. 
22) different lines of plants are crossed and the progeny measured. If 
we allow different line effects for male and female parents, this is a 
conventional two-way anova, but if we assume that the line effect is the 
same whether parent is male or female, we have something like your 
situation, in that the model is

y(ij) = const + (alpha)i + (alpha)j + ...

instead of

        const + (alpha)i + (beta)j + ...

for the cross of male parent from line i and female parent from line j. 
Analysis requires a special model matrix which is the sum (overlay) of 
the model matrices for male and female parents, with rows corresponding 
to between-line crosses consisting of two 1s and (in this case) 20 zeros.

Heidi Colleran wrote:
> Dear List,
> 
> I'm a PhD student writing to ask for some help on specifying a model in R.
> I'm currently using the lme4 package.
> 
> I'm trying to analyse how migration effects womens fertility rates in a
> sample of 22 groups (villages). I have a sample of ~1500 women who were
> born and continue to live in one of the 22 groups. I treat the model as
> women clustered within groups. Each woman has an origin group ID and a
> current group ID, so for women who never migrated these ID numbers will be
> the same. I want to obtain variance parameters for the different groupings,
> to see whether origin or current group has a greater effect on fertility
> rates, with a view to then seeing if other group-level predictors explain
> some of the variance, but I'm not sure if I have specified the model
> correctly, or if I need to make some changes to the data (for example
> weighting the memberships somehow).
> 
> I started with (what I think is) a cross-classified model of the form
> (y~1+(1|originGroupID)+(1|currentGroupID)),
> but given that the groups themselves are exactly the same thing, and that
> membership in them overlaps, I am worried that this will cause problems for
> estimating the group variances and covariances, or that this specification
> perhaps doesn't make sense. Should the groups be coded differently?
> 
> If anyone could point me in the direction of some references specific to
> this kind of overlapping structure, or indeed offer some advice as to
> different ways I could specify the model, or recode the data somehow, I
> would be extremely grateful.
> 
> Many thanks,
> 
> Heidi
> --
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Kevin_J_Ryan at umit.maine.edu  Tue Feb 21 17:21:55 2012
From: Kevin_J_Ryan at umit.maine.edu (Kevin J. Ryan)
Date: Tue, 21 Feb 2012 11:21:55 -0500
Subject: [R-sig-ME] Incorporating a Temporal Correlation Structure in a GLM
Message-ID: <fc.004c4d194d3477bb004c4d194d3477bb.4d3492fa@umit.maine.edu>

Hello,

I'm attempting to use mixed-model logistic regression to model spadefoot emergence as a function of weather variables (individuals are monitored continuously from 1-84 days [with gaps]).  However, the weather variables are serially autocorrelated,
apparently at a lag of 12 days or so.  Does anyone have experience incorporating a temporal autocorrelation structure of predictor variables into a glm?  I've been examining the lme4 package but it does not appear to be able to do this.  

Any advice is greatly appreciated.

 - Kevin

Kevin J. Ryan
PhD Candidate
Wildlife Ecology Department
University of Maine
5755 Nutting Hall, Room 220
Orono, ME 04469
cell: (914) 907-7896



From bbolker at gmail.com  Wed Feb 22 02:07:45 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Feb 2012 01:07:45 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Moving_from_lme4a_to_lme4Eigen_correlation_o?=
	=?utf-8?q?f_random=09effects_goes_to_1?=
References: <CAKstpn6LX8OB+zAdZisHnz3XTYiC6449MsMXCCQrejp9eFht5w@mail.gmail.com>
Message-ID: <loom.20120222T004353-501@post.gmane.org>

Jennifer Lyon <jennifer.s.lyon at ...> writes:

> I am modeling the score participants in three conditions achieved at
> three times.  The times are not equally spaced, with the difference
> between t2 and t3 over an order of magnitude longer than the
> difference between t1 and t2. The design is not balanced. The variable
> LMNo is unique per individual.
> 
>          time
> condition t1 t2 t3
>         A 76 75 72
>         B 18 18 17
>         C 28 27 26

> I've attached a plot of the data.

  (didn't come through -- the mailing list discards a lot
of file types)

> The literature suggests that there are individual differences
> at the different times, so I fitted the following model:
> 
> me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
> 
 When moving from lme4a to lme4Eigen, the correlations of the random
 effects all went to 1.000. I was slightly surprised by this change of
 events. Is this result indicating that the simpler model:
 
 me.c.m0<-lmer(score~ 1+time + condition + (1|LMNo), me.c, REML = 0)
 
 is sufficient? 

   It typically would.  It does mean you're somewhere on the
edge of overfitting ...
   If time were used as a continuous predictor (i.e. linear regression),
it might make sense to try to fit the model with (1|LMNo)+(0+time|LMNo),
but I suspect it *doesn't* make sense when time is a factor.

 I ask because when I do a likelihood ratio test
 using anova, the p-value is small and AIC prefers the more complex
 model while BIC prefers the simpler model. Does the correlation
 going to one also indicate a preference for the simpler model?
 
 #run in lme4Eigen
 anova(me.c.m0, me.c.m)
 Data: me.c
 Models:
 me.c.m0: score ~ 1 + time + condition + (1 | LMNo)
 me.c.m: score ~ 1 + time + condition + (1 + time | LMNo)
         Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(Chisq)
 me.c.m0  7 2069.8 2096.9 -1027.9   2055.8
 me.c.m  12 2055.3 2101.9 -1015.7   2031.3 24.445      5  0.0001782 ***

  On the other hand, this seems to say pretty definitively that
the variation in time effects across individuals is doing something ...

 I don't know if this is related, but when I run profile() on
 the models in lme4a and lme4Eigen, I get an error (which is
 shown below). I have additional information on the participants,
 such as gender and which participants are siblings, but before
 I go for a more complex model, I'd like to better understand
 what this model is telling me.

  Very wise.


> Here are the details of fitting the models in lme4a and lme4Eigen:
> 
> In lme4a_0.9996875-1
> 
> > library(lme4a)
> > me.c<-read.table("mixed-effects-data-clean.txt", header=T)
> 
> > me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
> > summary(me.c.m)

 [snip]

>    Data: me.c
>       AIC       BIC    logLik  deviance
>  2049.704  2096.236 -1012.852  2025.704
> 
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  LMNo     (Intercept) 41.280   6.425
>           timet2       6.007   2.451    0.452
>           timet3       5.174   2.275    0.382 0.997
>  Residual              4.314   2.077
> Number of obs: 357, groups: LMNo, 122
> 
> Fixed effects:

 [snip]
 
> > profile(me.c.m)
> Error in rbind2(fillmat(pres, lowcut, zeta, wp1), fillmat(nres, lowcut,  :
>   error in evaluating the argument 'y' in selecting a method for
> function 'rbind2': Error in while (i < nr && abs(mat[i, ".zeta"]) <=
> cutoff && mat[i, cc] >  :
>   missing value where TRUE/FALSE needed

  Hmmm.  Are you willing to send data?

  As cross-checks on lme4a and lme4Eigen, you might try
the packages
* glmmADMB (recent versions can handle Gaussian responses,
although it's not well tested)
* regress
* lmm
* sabreR

  although all (except glmmADMB) have fairly different
interfaces, unfortunately. 

> 

 [snip]
 
 > me.c<-read.table("mixed-effects-data-clean.txt", header=T)
 
 > me.c.m<-lmer(score~ 1+time + condition + (1+time|LMNo), me.c, REML = 0)
 > summary(me.c.m)
 Linear mixed model fit by maximum likelihood ['summary.mer']
 Formula: score ~ 1 + time + condition + (1 + time | LMNo)
    Data: me.c
 
       AIC       BIC    logLik  deviance
  2055.339  2101.872 -1015.669  2031.339
 
 Random effects:
  Groups   Name        Variance Std.Dev. Corr
  LMNo     (Intercept) 39.351   6.273
           timet2       2.440   1.562    1.000
           timet3       1.730   1.315    1.000 1.000
  Residual              5.507   2.347
 Number of obs: 357, groups: LMNo, 122
 
 Fixed effects:

 [snip]
 
 > profile(me.c.m)
 Warning message:
 In sqrt(ores$fval - base) : NaNs produced
 Error in rbind2(fillmat(pres, lowcut, zeta, wp1), fillmat(nres, lowcut,  :
   error in evaluating the argument 'x' in selecting a method for
 function 'rbind2': Error in while (i < nr && abs(mat[i, ".zeta"]) <=
 cutoff && mat[i, cc] >  :
   missing value where TRUE/FALSE needed
 

[snip]



From bbolker at gmail.com  Wed Feb 22 02:15:49 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Feb 2012 01:15:49 +0000 (UTC)
Subject: [R-sig-ME] Incorporating a Temporal Correlation Structure in a
	GLM
References: <fc.004c4d194d3477bb004c4d194d3477bb.4d3492fa@umit.maine.edu>
Message-ID: <loom.20120222T020754-835@post.gmane.org>

Kevin J. Ryan <Kevin_J_Ryan at ...> writes:


> I'm attempting to use mixed-model logistic regression to model
> spadefoot emergence as a function of weather variables (individuals
> are monitored continuously from 1-84 days [with gaps]).  However,
> the weather variables are serially autocorrelated, apparently at a
> lag of 12 days or so.  Does anyone have experience incorporating a
> temporal autocorrelation structure of predictor variables into a
> glm?  I've been examining the lme4 package but it does not appear to
> be able to do this.

  A couple of quick thoughts:

* you could use glmmPQL (in the MASS package), which does allow any
of the correlation structures that are defined in the nlme
package (including corCAR1, which allows for gappy data). This
is not preferred for binary data, but probably (?) correcting
for correlation and using a slightly questionable estimation method
is better than ignoring correlation.

* if your responses are measured without error you might
be able to use emergences at a previous time point as
a predictor.

* you could just use glm (or whatever) and evaluate the correlations
among the residuals -- if there's nothing going on there then you
have a reasonable excuse for proceeding without a correlation model.

* the fact that the _predictor_ variables are autocorrelated isn't
that much of a big deal -- it's really the response (or rather the
residuals of the response) that you should be worried about, although
there is always a bit of an issue in time-series analysis in
looking at relationships of autocorrelated series with other
autocorrelated series ...

* generalized estimating equations (GEE: see geepack etc.) are
another approach, although I don't know if any of the R packages
that do GEEs have an option for autocorrelations on unevenly
spaced data (try installing the "sos" package and searching
via something like findFn("gee uneven"))

* in my opinion the gold standard (if the data are rich enough
to warrant it) is to build a hierarchical model with a latent
normally distributed variable with temporal autocorrelation and
an observed binary variable (emergence) on top of it, but this
is fairly hard work -- you'd need AD Model Builder or some
dialect of BUGS.

 I will be interested to see if anyone has better suggestions.

 I would check the books from Highland Statistics (Zuur et al.)
to see if they have anything useful ...



From arives at wisc.edu  Wed Feb 22 12:35:00 2012
From: arives at wisc.edu (Anthony R Ives)
Date: Wed, 22 Feb 2012 05:35:00 -0600
Subject: [R-sig-ME] Incorporating a Temporal Correlation Structure in
	a	GLM
In-Reply-To: <loom.20120222T020754-835@post.gmane.org>
References: <fc.004c4d194d3477bb004c4d194d3477bb.4d3492fa@umit.maine.edu>
	<loom.20120222T020754-835@post.gmane.org>
Message-ID: <155F553A-8E23-470A-A182-90D61105BD88@wisc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120222/fa041c76/attachment-0002.pl>

From highstat at highstat.com  Wed Feb 22 20:26:20 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 22 Feb 2012 21:26:20 +0200
Subject: [R-sig-ME] Incorporating a Temporal Correlation Structure,
	in a	GLM
In-Reply-To: <mailman.5.1329908402.15027.r-sig-mixed-models@r-project.org>
References: <mailman.5.1329908402.15027.r-sig-mixed-models@r-project.org>
Message-ID: <4F45415C.70301@highstat.com>


* you could just use glm (or whatever) and evaluate the correlations
among the residuals -- if there's nothing going on there then you
have a reasonable excuse for proceeding without a correlation model.

* the fact that the _predictor_ variables are autocorrelated isn't
that much of a big deal -- it's really the response (or rather the
residuals of the response) that you should be worried about, although
there is always a bit of an issue in time-series analysis in
looking at relationships of autocorrelated series with other
autocorrelated series ...

* generalized estimating equations (GEE: see geepack etc.) are
another approach, although I don't know if any of the R packages
that do GEEs have an option for autocorrelations on unevenly
spaced data (try installing the "sos" package and searching
via something like findFn("gee uneven"))

* in my opinion the gold standard (if the data are rich enough
to warrant it) is to build a hierarchical model with a latent
normally distributed variable with temporal autocorrelation and
an observed binary variable (emergence) on top of it, but this
is fairly hard work -- you'd need AD Model Builder or some
dialect of BUGS.

  I will be interested to see if anyone has better suggestions.



Kevin,

Ben..thanks for the advertisement..:-))

The last chapter in our 2009 book shows how a Poisson GLM can be 
extended with an AR1 correlation structure on the residuals. We took 
this further in our upcoming book "Zero inflated models and GLMM with 
R", which comes out in 2 weeks. We extend GLM models with spatial or 
temporal correlations by using CAR structures on the residuals. We have 
done it in a Poisson/NB GLM/GAM context...but also in a binomial context 
(which means that you can then also do it for a ZIP). These are models 
of the form:

Y_i ~ Poisson(mu_i)

log(mu_i) = alpha + beta * X_i + epsilon_i

where the epsilon_i are spatially correlated following a CAR. And you 
can also use this for time series. Some recent papers used CAR on the 
random effects.

The bad news is that this is indeed MCMC...and we used WinBUGS (the book 
actually starts with a beginner's intro to MCMC and WinBUGS). I am 
tempted to write an ADMB supplement as it seems to be much faster in 
fitting these models.  The ADMB guys were kind enough to provide code to 
fit some of the models used in the book.


In our experience adding a correlation to a GLM works fine as long as it 
represents small-scale correlation. As soon as you allow it to capture 
large scale correlation then it may start to fight with the covariates. 
And then you get very poor mixing of chains. So..it is a bit of an art. 
I think it also depends on what type of correlation you are trying to 
model...does the spatial (or temporal) correlation represent a missing 
covariate...it is small scale variation...or is it 'real' dependency 
(pseudo replication).

A paper from VerHoef and Janssen was quite inspiring.

Anyway...enough advertisement...

Kind regards,

Alain


>   I would check the books from Highland Statistics (Zuur et al.)
> to see if they have anything useful ...
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 62, Issue 43
> **************************************************
>


-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From David.Duffy at qimr.edu.au  Wed Feb 22 21:57:16 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 23 Feb 2012 06:57:16 +1000
Subject: [R-sig-ME] Use of mixed models when the causal relations
	areunclear?
Message-ID: <6F35A958A12B9149BD16E3C2F3B0AD0DB37866@SPHINX.adqimr.ad.lan>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/ae4f7ae8/attachment-0002.pl>

From amelie.pinet at gmail.com  Thu Feb 23 15:02:14 2012
From: amelie.pinet at gmail.com (amelie pinet)
Date: Thu, 23 Feb 2012 15:02:14 +0100
Subject: [R-sig-ME] Assumptions on within group errors in lme model
Message-ID: <CAKNZCKE5iOCddgBZQ0xhxP02yFGNZzODOag-ShpDXtqdWS6-Kw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/fff4bebf/attachment-0002.pl>

From Walter.Leite at coe.ufl.edu  Thu Feb 23 17:29:36 2012
From: Walter.Leite at coe.ufl.edu (Leite,Walter)
Date: Thu, 23 Feb 2012 16:29:36 +0000
Subject: [R-sig-ME] Problematic correlations between random effects
Message-ID: <FF9DF1CEDEBA874E96DB251402D6B416144B942E@UFEXCH-MBXN04.ad.ufl.edu>

Folks,

I fitted a model with several random affects to data with a cross-classification of students and schools using lmer. Two random effects have correlation of -1 and others near 1, as shown below. I thought that this would only occur if any random effects were not necessary in the model, but I built this model adding the random effects one at a time and comparing the fit with BIC and AIC. Also, none of the variances are very small. Could someone advise me on why these correlations occurred and ways I can solve this problem?

Thank you,

Walter

Random effects:
 Groups    Name             Variance  Std.Dev. Corr                 
 CHILDID   (Intercept)      333.63787 18.26576                      
           time.period        7.99838  2.82814 -1.000               
           I(time.period^2)  11.16830  3.34190 -0.514  0.514        
           I(time.period^3)   0.31869  0.56453 -0.189  0.189  0.938 
 School_ID (Intercept)       87.59255  9.35909                      
           time.period       33.30370  5.77094  0.093               
           I(time.period^2)   1.48008  1.21659 -0.171  0.960        
 Residual                    39.94649  6.32032                      
Number of obs: 11960, groups: CHILDID, 2990; School_ID, 996



From stat.list at yahoo.co.uk  Thu Feb 23 18:43:08 2012
From: stat.list at yahoo.co.uk (Rachel Cohen)
Date: Thu, 23 Feb 2012 17:43:08 +0000 (GMT)
Subject: [R-sig-ME] lme4a and Profile
Message-ID: <1330018988.69754.YahooMailNeo@web132205.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/29d19d57/attachment-0002.pl>

From agostino.moro99 at gmail.com  Thu Feb 23 18:53:14 2012
From: agostino.moro99 at gmail.com (Agostino Moro)
Date: Thu, 23 Feb 2012 17:53:14 +0000
Subject: [R-sig-ME] nlme Fixed Variance Function
Message-ID: <CAMS_pxsh41A=2WdfVU3267+iKZWP8xgDFuS4y1zaG9B6jo6cYg@mail.gmail.com>

Dear R users,

I am trying to fit a gls model and weight my data points using a
VarFixed structure. I have found many examples, but I do not
understand the difference between the following models with varFixed
specified in a different way:

mod<-gls(y~x,weights=varFixed(~1/invsigma)

mod<-gls(y~x,weights=varFixed(~invsigma)

In my case I would simply like to weigh my data points by their
inverse variance.

Any help would be greatly appreciated!

Cheers,

Agostino



From dadrivr at gmail.com  Thu Feb 23 20:46:39 2012
From: dadrivr at gmail.com (Isaac Petersen)
Date: Thu, 23 Feb 2012 14:46:39 -0500
Subject: [R-sig-ME] Calculating Pseudo R-squared from nlme
Message-ID: <CAPBn5Xtc-hf_Z+8ZXNPH4sLTXs2rWnwOtBR3v3FWq9cP553hSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/0d5ce7d1/attachment-0002.pl>

From bbolker at gmail.com  Thu Feb 23 22:12:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Feb 2012 21:12:22 +0000 (UTC)
Subject: [R-sig-ME] lme4a and Profile
References: <1330018988.69754.YahooMailNeo@web132205.mail.ird.yahoo.com>
Message-ID: <loom.20120223T220515-437@post.gmane.org>

Rachel Cohen <stat.list at ...> writes:

> Hi, I would like to try using the profile() function etc.
> to look at confidence intervals on mixed model
> parameters (as detailed in Douglas Bate's online book).? 
> Working through the book's example I get the
> following error message:

> Error in UseMethod("profile") : 
> ? no applicable method for 'profile' applied to an object of class "mer"

>  I believe I have to install lme4a in order to use these 
> new functions.? I can't seem to find any mention of
> this new version of lme4 on R-forge.
>  Does anyone know where I can obtain lme4a and if it's ready/reliable
> for use?

(1)  If you have the appropriate tools for building packages installed
you should be able to just

install.packages("lme4a",repos="http://r-forge.r-project.org",type="source")

(2) Otherwise, I would normally tell you to
see http://lme4.r-forge.r-project.org , but ... the binary versions
of lme4a there are somewhat out of date, so they won't be automatically
installed in R 2.14.  You can try poking around at 
http://lme4.r-forge.r-project.org/repos/bin/ , downloading versions for 
slightly older versions of R and installing the binaries locally --
it *might* work.

(3) lme4a is relatively stable, lme4Eigen (the new, new, new
development version) is getting so -- it should run all the
profiling examples in the book, although Doug Bates is working
on updating a few small details in the book to make them work
with lme4Eigen.  You could try lme4Eigen ...

(4) if all else fails, ask again here for lme4a binaries to be
provided (I'd slightly rather spend my effort providing binaries
for lme4Eigen, but would be willing to make some new lme4a binaries
in the interim).



From bbolker at gmail.com  Thu Feb 23 22:24:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Feb 2012 21:24:34 +0000 (UTC)
Subject: [R-sig-ME] nlme Fixed Variance Function
References: <CAMS_pxsh41A=2WdfVU3267+iKZWP8xgDFuS4y1zaG9B6jo6cYg@mail.gmail.com>
Message-ID: <loom.20120223T221850-645@post.gmane.org>

Agostino Moro <agostino.moro99 at ...> writes:

> 
> Dear R users,
> 
> I am trying to fit a gls model and weight my data points using a
> VarFixed structure. I have found many examples, but I do not
> understand the difference between the following models with varFixed
> specified in a different way:
> 
> mod<-gls(y~x,weights=varFixed(~1/invsigma)
> 
> mod<-gls(y~x,weights=varFixed(~invsigma)
> 
> In my case I would simply like to weigh my data points by their
> inverse variance.
> 

  It would be interesting to have links to examples that show
these two usages.  One of them must be wrong, or at least weird.
Have you looked at ?varFixed?  It says:

 Letting v denote the variance covariate defined in ?value?, the variance
     function s2(v) for this class is s2(v)=|v|. 

Thus if you know the variance _a priori_ is 'yvar' I think you want
weights=varFixed(~yvar) .  This will set the variance to yvar and
hence weight by 1/yvar.  (I'm using "yvar" rather than "sigma" or
"invsigma" because it's easy to get confused about whether "sigma"
represents variance or standard deviation ...)

  I would strongly recommend using the 'data' argument: have x, y, 
and yvar as columns in a data frame d and use

mod <- gls(y~x,weights=varFixed(~yvar),data=d)

  Taking a look at Pinheiro and Bates 2000 would be a good idea.
If you're too cheap or in too much of a hurry to buy it, you can
search for "varFixed" within the book on Google books (see p. 209)
for a slightly more extended discussion of the admittedly terse
example in ?varFixed ...



From karla.letto at gmail.com  Thu Feb 23 23:33:10 2012
From: karla.letto at gmail.com (Karla Letto)
Date: Thu, 23 Feb 2012 19:03:10 -0330
Subject: [R-sig-ME] fitting a distribution to zero-inflated catch per unit
	effort mixed model
Message-ID: <CABMU9jxFFYtyHX5reHkrdgvv+3zLz9Ddm3CxhnvYcaSotuq8mA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120223/0e7a918a/attachment-0002.pl>

From David.Duffy at qimr.edu.au  Thu Feb 23 23:42:11 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 24 Feb 2012 08:42:11 +1000 (EST)
Subject: [R-sig-ME] Problematic correlations between random effects
In-Reply-To: <FF9DF1CEDEBA874E96DB251402D6B416144B942E@UFEXCH-MBXN04.ad.ufl.edu>
References: <FF9DF1CEDEBA874E96DB251402D6B416144B942E@UFEXCH-MBXN04.ad.ufl.edu>
Message-ID: <Pine.LNX.4.64.1202240838220.11505@orpheus.qimr.edu.au>

On Thu, 23 Feb 2012, Leite,Walter wrote:

> Folks,
>
> I fitted a model with several random effects to data with a 
> cross-classification of students and schools using lmer. Two random 
> effects have correlation of -1 and others near 1, as shown below. I 
> thought that this would only occur if any random effects were not 
> necessary in the model, but I built this model adding the random effects 
> one at a time and comparing the fit with BIC and AIC. Also, none of the 
> variances are very small. Could someone advise me on why these 
> correlations occurred and ways I can solve this problem?
>
> Random effects:
> Groups    Name             Variance  Std.Dev. Corr
> CHILDID   (Intercept)      333.63787 18.26576
>           time.period        7.99838  2.82814 -1.000
>           I(time.period^2)  11.16830  3.34190 -0.514  0.514
>           I(time.period^3)   0.31869  0.56453 -0.189  0.189  0.938
> School_ID (Intercept)       87.59255  9.35909
>           time.period       33.30370  5.77094  0.093
>           I(time.period^2)   1.48008  1.21659 -0.171  0.960
> Residual                    39.94649  6.32032
> Number of obs: 11960, groups: CHILDID, 2990; School_ID, 996

Have you centred time.period?  My simple minded understanding is that 
polynomial terms like that will always be highly correlated unless you 
orthogonalize them, but the LR based criteria will still guide you 
correctly.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Fri Feb 24 00:10:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Feb 2012 23:10:21 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?fitting_a_distribution_to_zero-inflated_catc?=
	=?utf-8?q?h_per_unit=09effort_mixed_model?=
References: <CABMU9jxFFYtyHX5reHkrdgvv+3zLz9Ddm3CxhnvYcaSotuq8mA@mail.gmail.com>
Message-ID: <loom.20120224T000238-482@post.gmane.org>

Karla Letto <karla.letto at ...> writes:

> I am having trouble fitting a distribution to my mixed model for meadow
> vole catch per unit effort (CPUE) data. I have tried several families and
> cannot find one that does not violate both the homogeneity and normality
> assumptions. NOTE: The data set is zero-inflated (no captures).
> Here is my study design:
> 
> I am trying to determine if the CPUE of meadow voles differ among lines
> (line = near,mid, or far) at increasing distances from a linear feature
> (type = road, trail or powerline corridor) in two different habitat types
> (habitat=forest or barren).
> Response variable: catch per unit effort (non-integer values)
> Fixed explanatory variables: line (3 categories), habitat (2 categories),
> type (3 categories)
> Random explanatory variable: site (8 categories), cycle (2 categories)


> The random variable site is for the 8 different sites I sampled in (4
> barren and 4 forest) and the cycle is there because I visited each site
> twice.

  Practically speaking you probably can't use cycle as a random
effect; you can include cycle as a fixed effect (specifying the
difference between first & second visits), and possibly
nesting it within site as a random effect (if you have more than
one observation per site/sample combination).

  What is the total size (number of observations) in your data set?

> Here is an excerpt of my data set:
>    CE2  catch effort site line   cycle habitat      type
> 0.000000     0   57.5    A near  first   forest     trail
> 3.278689     2   61.0    A   mid   first   forest     trail
> 0.000000     0   60.5    A   far   first   forest     trail
> 0.000000     0   66.5    G near  first   barren       road
> 0.000000     0   74.5    G   mid   first   barren       road
> 0.000000     0   74.0    G   far   first   barren       road
> 1.449275     1   69.0    E near second  barren powerline
> 0.000000     0   73.0    E   mid second  barren powerline
> 0.000000     0   71.5    E   far second  barren powerline
> 
> I tried the lme4 package using the following syntax:
> 
 [snip]
> 
> I then tried using a poisson error structure using catch (the actual number
> of animals) as the response and incorporated effort as an offset. Effort as
> an offset is commonly used for analysis of CPUE data.
> 
> Model2<-
> glmer(catch~line+habitat+type+(1|site)+(1|cycle)+
>  offset(effort),family=poisson)

  This is a good way to do it, but you need to incorporate the
LOG of effort.  You may also need to account for overdispersion
and/or zero-inflation; the former via incorporating an observation-level
random effect (in glmer, glmmadmb, or MCMCglmm) or negative binomial
distribution (in glmmadmb), the latter (if necessary) via zero-inflation
or hurdle models (in glmmadmb or MCMCglmm).

 [snip snip snip]

> Does anyone have any suggestions on how I can analyze zero-inflated CPUE
> data? I have been trying to figure out how to do a Monte Carlo permutation
> test for a mixed model but I am having trouble figuring out the syntax. Any
> help would be greatly appreciated.

  What are you using to assess homogeneity of variance and normality?
Normality of residuals can only be expected approximately (and in the case of
large mean counts) in this case.

   I would start off this way:

mydata$obs <- factor(seq(nrow(mydata)))
glmer(catch~line+habitat+type+cycle+(1|site/cycle)+(1|obs)+
  offset(log(effort)),family=poisson, data=mydata)

You can use the simulate() method to simulate data sets, count
the proportion of zeros expected, and see if your observed 
proportion of zeros is off ...



From joe.c.hightower at boeing.com  Fri Feb 24 19:22:54 2012
From: joe.c.hightower at boeing.com (Hightower, Joe C)
Date: Fri, 24 Feb 2012 10:22:54 -0800
Subject: [R-sig-ME] errors in mcmcpvalue
Message-ID: <F15A9A546A827B4FAB4FED0B256BE9A3461933427C@XCH-NW-08V.nw.nos.boeing.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120224/509b440f/attachment-0002.pl>

From roby.joehanes at nih.gov  Fri Feb 24 22:37:40 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Fri, 24 Feb 2012 16:37:40 -0500
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
Message-ID: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>

Hi,

I learned about the impending release of the new version of lme4 (or lme4a) from Dr. Bates' post here:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007499.html

Firstly, just to make sure, is this based on lme4a? I have the source tarball of lme4a 0.999375-65 and found that a new optimizer, BOBYQA, is now in use, instead of the nlminb. The announcement above also mentioned the same change. So, I suspect that the older lme4 is supplanted with lme4a. Is this true?

Secondly, I would like to get a source tarball of the latest bleeding edge release to play with (or even read-only SVN access). I found from some sniff tests the lmer outputs of lme4a to be closely matched with those of SAS than those of the lme4 (with nlminb optimizer), except for the lack of p-values. I would love to play with the new version and even give you comparisons with the old version. The problem I am facing with lme4a 0.999375-65 is that it sometimes crashes (core dumps).

Thirdly, I also would love to see the Satterthwaite or Kenward-Rogers DF estimation. I would like to try to add these features into lme4, if you will. I don't know much about the formulas to compute the DFs from quantities output by lmer / glmer. Any pointers?

Thank you.

Sincerely,
Roby


From joe.c.hightower at boeing.com  Fri Feb 24 23:05:54 2012
From: joe.c.hightower at boeing.com (Hightower, Joe C)
Date: Fri, 24 Feb 2012 14:05:54 -0800
Subject: [R-sig-ME] influence.ME questions
Message-ID: <F15A9A546A827B4FAB4FED0B256BE9A3461933427E@XCH-NW-08V.nw.nos.boeing.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120224/89d45aa9/attachment-0002.pl>

From knozue at ucdavis.edu  Fri Feb 24 23:21:10 2012
From: knozue at ucdavis.edu (Kazunari Nozue)
Date: Fri, 24 Feb 2012 14:21:10 -0800
Subject: [R-sig-ME] permutation approach to know effect of one factor
	(factor A) to another (factor B) in each level of factor A
	(although it is slow)
Message-ID: <26472CCD-44BF-49F9-913A-1AF005C99D29@ucdavis.edu>

Hi all,

At first I will explain my linear mixed effects model;
lme1 <- lme(leaf_length ~ Treatment*Genotype*leaf,random=~Treatment|Set,data=data)

or
lmer1 <- lmer(leaf~Treatment*Genotype*leaf+(Treatment|Set),data=data)


Treatment factor has two conditions: mock (=Mo) and treatment(=Tr)
Leaf is position of leaf: 3rd leaf, 4th leaf, ....
Genotype is type of plant: wt, mut1, mut2, ....., mut72
Set is experimental replicates: A to J.
I would like to ask how to compare leaf length under condition A and one under condition B in each Genotype, i.e. know effect of one factor (factor A, ?Genotype?) to another (factor B, ?Treatment?) in each level of factor A (eg. ?wt?, ?mut1?, ?mut2?, ...).
Since my data is unbalanced data, I could not use TukeyHSD() multiple comparison (see its help).
My understanding is that pvalue in summary(lme1)$tTable is controversial and pvals.fnc(lmer1) # in languageR package
gave me an error (due to (Treatment|Set) because (1|Set) did not gave me an error, but (Treatment\SET) is essential in this model.).

As seen below, I would like to know my permutation method is OK or not.

I started from a simple permutation approach from Maindonald and Braun (2003) "Data Analysis and Graphics Using R." pg 98. (see scripts below) and I combined my mixed model and this approach with simulated data (omitting leaf factor to simplify, see scripts below). Disadvantage of this method is running time could be long in large data sets with many permutation (eg. 10000), I would like to know my method is OK. If I could have better methods (probably by using multcomp package, such as glht() function), I would really appreciate them.

Sorry for long message.

Thank you,

Kazu
##############################
### Maindonald nad Braun pg. 98
##############################
library(DAAG)
data(two65) # from DAAG package
x1 <- two65$ambient;x2<-two65$heated;x<-c(x1,x2)
n1<-length(x1);n2<-length(x2);n<-n1+n2
dbar<-mean(x2) - mean(x1)
z<-array(,2000)

for(i in 1:2000) {
mn<-sample(n,n2,replace=FALSE)
dbardash<-mean(x[mn])-mean(x[-mn])
z[i]<-dbardash
}

pval<-(sum(z > abs(dbar)) + sum(z< -abs(dbar)))/2000
plot(density(z),yaxs="i")
abline(v=dbar)
abline(v=-dbar,lty=2)
###############################
### my example with unbalanced data
###############################
library(lme4)
#simulate data. leaf length in Tr is longer than Mo. wt shows more dramatic response to Tr than mut. setA plants were longer than setB plants (set factor is significant in this model).
set.seed(1234)
data <- data.frame(Treatment=rep(c("Tr","Mo"),c(9,11)),leaf=c(rnorm(9,11),rnorm(11,10)),Set=rep(c("A","B"),times=10))
data$Genotype <- factor(rep(c("mut","wt"),each=5,length.out=20))
#add setA specific effect for shade and then for sun
data$leaf[data$Treatment=="Tr" & data$Set=="A"] <- data$leaf[data$Treatment=="Tr" & data$Set=="A"] + rnorm(length(data$leaf[data$Treatment=="Tr" & data$Set=="A"]),1)
data$leaf[data$Treatment=="Tr" & data$Genotype=="mut"] <- data$leaf[data$Treatment=="Tr" & data$Genotype=="mut"] + rnorm(length(data$leaf[data$Treatment=="Tr" & data$Genotype=="mut"]),-0.5)
data$leaf[data$Treatment=="Mo" & data$Set=="A"] <- data$leaf[data$Treatment=="Mo" & data$Set=="A"] + rnorm(length(data$leaf[data$Treatment=="Mo" & data$Set=="A"]),-0.25)
data
# mean from observed data
mean.table.obs<-tapply(data$leaf, list(data$Treatment,data$Genotype),mean)
# permutation
mean.table.PER<-list()
nreps<-1000
z<-list() # mean differences

for(i in 1:nreps) {
	new.data<-data.frame()
	new.wt<-sample(data[data$Genotype=="wt",]$leaf,sum(data$Genotype=="wt",na.rm=TRUE),replace=FALSE) # null hypothesis: leaf in Mo = Tr in wt
	new.mut<-sample(data[data$Genotype=="mut",]$leaf,sum(data$Genotype=="mut",na.rm=TRUE),replace=FALSE)
	new.data<-data.frame(leaf=c(new.wt,new.mut),Genotype=data$Genotype,Treatment=data$Treatment,Set=data$Set)
	# mixed effect model
	lmer.temp<- lmer(leaf~Treatment*Genotype+(Treatment|Set),data=new.data)
	#calculate mean of each group
	mean.table.PER[[i]]<-tapply(fitted(lmer.temp), list(new.data$Treatment,new.data$Genotype),mean)
	z[[i]]<-mean.table.PER[[i]][2,] - mean.table.PER[[i]][1,]
}

# calculate p value
TF1<-list()
TF2<-list()
p.value<-vector()

for(i in 1:length(levels(data$Genotype))) {
	for(n in 1:length(z)) {
	     TF1[[n]]<-          (z[[n]][i] > abs(mean.table.obs[2,i] - mean.table.obs[1,i]))*1
	     TF2[[n]]<-      (z[[n]][i] < -abs(mean.table.obs[2,i] - mean.table.obs[1,i]))*1
         }    
	p.value[i]<-(sum(as.numeric(TF1) + as.numeric(TF2)))/length(z)
}

names(p.value)<-levels(data$Genotype)
p.value
p.adjust<-p.adjust(p=p.value,method=?fdr?)
p.adjust
# graph
par(mfcol=c(2,1))
hist(unlist(z)[names(unlist(z))=="mut"],breaks=seq(-5,5,0.2))
abline(v=abs(mean.table.obs[2,1] - mean.table.obs[1,1]))
abline(v=-abs(mean.table.obs[2,1] - mean.table.obs[1,1]))

hist(unlist(z)[names(unlist(z))=="wt"],breaks=seq(-5,5,0.2))
abline(v=abs(mean.table.obs[2,2] - mean.table.obs[1,2]))
abline(v=-abs(mean.table.obs[2,2] - mean.table.obs[1,2]))


From bbolker at gmail.com  Sat Feb 25 02:50:19 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 25 Feb 2012 01:50:19 +0000 (UTC)
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
Message-ID: <loom.20120225T023057-270@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> I learned about the impending release of the new version of lme4 
> (or lme4a) from Dr. Bates' post here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007499.html
> 
> Firstly, just to make sure, is this based on lme4a? 
> I have the source tarball of lme4a 0.999375-65 and found
> that a new optimizer, BOBYQA, is now in use, instead of the nlminb. 
> The announcement above also mentioned
> the same change. 
> So, I suspect that the older lme4 is supplanted with lme4a. Is this true?

  I'm not quite sure what you mean.  There are three versions of lme4:

* lme4 "classic" (version 0.999375-42 is the latest) lme4, built on nlminb
  (as was Bates's previous mixed-models package, nlme)

*** lme4 will be preserved on CRAN and (probably) renamed "lme4.0" after
the new version (see below) is released as lme4, for users who
need backward compatibility (we thought this was a reasonable
name: there are still a few issues with package names containing
dots, so we may need to change this ...). 

* lme4a (0.9996875-1) uses bobyqa

* lmeEigen (to be renamed lme4 when released, sometime soon ...)  uses
a mixture of bobyqa and a new Nelder-Mead implementation that allows box 
constraints, adapted from the nloptr package, which in turn wraps the 
NLopt open-source optimization codes 
(http://ab-initio.mit.edu/wiki/index.php/NLopt_Introduction).

> Secondly, I would like to get a source tarball of the latest 
> bleeding edge release to play with (or even
> read-only SVN access). I found from some sniff tests the lmer outputs of 
> lme4a to be closely matched with
> those of SAS than those of the lme4 (with nlminb optimizer), except for 
> the lack of p-values. I would love to
> play with the new version and even give you comparisons with the old 
> version. The problem I am facing with
> lme4a 0.999375-65 is that it sometimes crashes (core dumps).

  That's easy: just go here for instructions on SVN access:

http://r-forge.r-project.org/scm/?group_id=60

(the package is *so* bleeding edge that if you get it right now,
you should roll back to SVN release 1618; releases 1619+ are
currently broken ...)

> Thirdly, I also would love to see the Satterthwaite or
> Kenward-Rogers DF estimation. I would like to try to add these
> features into lme4, if you will. I don't know much about the
> formulas to compute the DFs from quantities output by lmer /
> glmer. Any pointers?

 Doug Bates is on record as saying that adapting the Kenward-Roger
formulation to work with his code would be difficult
<https://stat.ethz.ch/pipermail/r-help/2008-February/155372.html>, 
but Ulrich Halekoh and S?ren H?jsgaard have an implementation in 
the pbkrtest package
<http://cran.r-project.org/web/packages/pbkrtest/index.html>
which you could look at.  Perhaps that would give you a hint about
a Satterthwaite implementation as well ...

[PS there is no "s" in "Kenward-Roger" -- this is a very common mistake,
Kenward-Roger gets 1.03 million google hits while Kenward-Rogers
gets 438K ...]


> 
> Thank you.
> 
> Sincerely,
> Roby
>



From bbolker at gmail.com  Sat Feb 25 02:52:02 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 25 Feb 2012 01:52:02 +0000 (UTC)
Subject: [R-sig-ME] errors in mcmcpvalue
References: <F15A9A546A827B4FAB4FED0B256BE9A3461933427C@XCH-NW-08V.nw.nos.boeing.com>
Message-ID: <loom.20120225T025102-211@post.gmane.org>

Hightower, Joe C <joe.c.hightower at ...> writes:

> I am stuck, after installing R2.14.0 
> and lme4 0.999375-42, I am getting the following errors:
> 
> > mcmcpvalue(as.matrix(M4diag[,1:4]))
> Error in as.matrix(M4diag[, 1:4]) :
>   error in evaluating the argument 'x' in 
> selecting a method for function 'as.matrix': Error in M4diag[,
> 1:4] : object of type 'S4' is not subsettable

  [snip]

  Can you please post a reproducible example?
  http://tinyurl.com/reproducible-000



From bbolker at gmail.com  Sat Feb 25 22:41:41 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 25 Feb 2012 16:41:41 -0500
Subject: [R-sig-ME] fitting a distribution to zero-inflated catch per
 unit effort mixed model
In-Reply-To: <CABMU9jxVCD85-Bmq_C-A4xvBCcEA7bFjcLitvGY_hDFi9ua=Gw@mail.gmail.com>
References: <CABMU9jxFFYtyHX5reHkrdgvv+3zLz9Ddm3CxhnvYcaSotuq8mA@mail.gmail.com>
	<loom.20120224T000238-482@post.gmane.org>
	<CABMU9jxVCD85-Bmq_C-A4xvBCcEA7bFjcLitvGY_hDFi9ua=Gw@mail.gmail.com>
Message-ID: <4F495595.9050408@gmail.com>

  [cc'ing back to r-sig-mixed-models]

On 12-02-25 03:53 PM, Karla Letto wrote:
> Thank you Ben for the detailed response. I greatly appreciate it. I will
> let you know how it goes after I give each a try. In answer to your
> questions. My sample size is 25 Meadow Voles. 

  Meaning you caught a total of 25 voles in the whole study?  Be warned,
you may find that your model is overfitted -- typically you can fit
about/at most 1 parameter per 10 (effective) data points, which is
something between 25 (the number of voles) and 48 (observations) -- so
your fixed-effect parameters (line+habitat+type = 6 parameters) are
already on the verge of more information than you can estimate, even
before you start counting random effects (3 variances, for
site/cycle/observation-level variation).

> I calculated CPUE for each
> line. So I have a total of 48 observations (3 lines for 8 sites and each
> site was visited twice. I thought I had to use cycle as a random factor
> to account for temporal pseudoreplication.  I can see how your idea of
> nesting cycle within site as a random factor will work better though. 
> 
> I tested for normality using a normal q-q plot and homogeneity by
> plotting the residuals and fitted values (I kept getting a cone shape).

  Hmm.  A cone shape does imply heteroscedasticity that isn't handled by
the model assumptions ... I *think* resid() should give you Pearson
residuals (i.e. already corrected assuming variance=mean). So that's a
little puzzling.  I don't expect normality at all in residuals from a
model with a mean of ~ 2 individuals per sample ...

> 
>> qqnorm(resid(model))
> 
>> qqline(resid(model))
> 
> 
>> plot(fitted(model),resid(model))
> 
> Can you please tell me why I have to use LOG(effort) as an offset
> instead of just effort as the offset? That is not the first time I heard
> that it had to be LOG(effort) but I cannot find a reason for why. 

  Because the offset is added on the scale of the linear predictor,
which in this case is the log scale -- i.e., the expected mean number of
counts is

  exp([fixed effect terms] + [random effect terms] + offset) =
exp([fixed effect terms] + [random effect terms])* exp(offset)

> 
> Thank you, 
> 
> Karla 
> 
> On Thu, Feb 23, 2012 at 7:40 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>     Karla Letto <karla.letto at ...> writes:
> 
>     > I am having trouble fitting a distribution to my mixed model for
>     meadow
>     > vole catch per unit effort (CPUE) data. I have tried several
>     families and
>     > cannot find one that does not violate both the homogeneity and
>     normality
>     > assumptions. NOTE: The data set is zero-inflated (no captures).
>     > Here is my study design:
>     >
>     > I am trying to determine if the CPUE of meadow voles differ among
>     lines
>     > (line = near,mid, or far) at increasing distances from a linear
>     feature
>     > (type = road, trail or powerline corridor) in two different
>     habitat types
>     > (habitat=forest or barren).
>     > Response variable: catch per unit effort (non-integer values)
>     > Fixed explanatory variables: line (3 categories), habitat (2
>     categories),
>     > type (3 categories)
>     > Random explanatory variable: site (8 categories), cycle (2 categories)
> 
> 
>     > The random variable site is for the 8 different sites I sampled in (4
>     > barren and 4 forest) and the cycle is there because I visited each
>     site
>     > twice.
> 
>      Practically speaking you probably can't use cycle as a random
>     effect; you can include cycle as a fixed effect (specifying the
>     difference between first & second visits), and possibly
>     nesting it within site as a random effect (if you have more than
>     one observation per site/sample combination).
> 
>      What is the total size (number of observations) in your data set?
> 
>     > Here is an excerpt of my data set:
>     >    CE2  catch effort site line   cycle habitat      type
>     > 0.000000     0   57.5    A near  first   forest     trail
>     > 3.278689     2   61.0    A   mid   first   forest     trail
>     > 0.000000     0   60.5    A   far   first   forest     trail
>     > 0.000000     0   66.5    G near  first   barren       road
>     > 0.000000     0   74.5    G   mid   first   barren       road
>     > 0.000000     0   74.0    G   far   first   barren       road
>     > 1.449275     1   69.0    E near second  barren powerline
>     > 0.000000     0   73.0    E   mid second  barren powerline
>     > 0.000000     0   71.5    E   far second  barren powerline
>     >
>     > I tried the lme4 package using the following syntax:
>     >
>      [snip]
>     >
>     > I then tried using a poisson error structure using catch (the
>     actual number
>     > of animals) as the response and incorporated effort as an offset.
>     Effort as
>     > an offset is commonly used for analysis of CPUE data.
>     >
>     > Model2<-
>     > glmer(catch~line+habitat+type+(1|site)+(1|cycle)+
>     >  offset(effort),family=poisson)
> 
>      This is a good way to do it, but you need to incorporate the
>     LOG of effort.  You may also need to account for overdispersion
>     and/or zero-inflation; the former via incorporating an observation-level
>     random effect (in glmer, glmmadmb, or MCMCglmm) or negative binomial
>     distribution (in glmmadmb), the latter (if necessary) via zero-inflation
>     or hurdle models (in glmmadmb or MCMCglmm).
> 
>      [snip snip snip]
> 
>     > Does anyone have any suggestions on how I can analyze
>     zero-inflated CPUE
>     > data? I have been trying to figure out how to do a Monte Carlo
>     permutation
>     > test for a mixed model but I am having trouble figuring out the
>     syntax. Any
>     > help would be greatly appreciated.
> 
>      What are you using to assess homogeneity of variance and normality?
>     Normality of residuals can only be expected approximately (and in
>     the case of
>     large mean counts) in this case.
> 
>       I would start off this way:
> 
>     mydata$obs <- factor(seq(nrow(mydata)))
>     glmer(catch~line+habitat+type+cycle+(1|site/cycle)+(1|obs)+
>      offset(log(effort)),family=poisson, data=mydata)
> 
>     You can use the simulate() method to simulate data sets, count
>     the proportion of zeros expected, and see if your observed
>     proportion of zeros is off ...
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>



From arshad4uonly at gmail.com  Sun Feb 26 23:19:37 2012
From: arshad4uonly at gmail.com (Muhammad Arshad)
Date: Mon, 27 Feb 2012 05:19:37 +0700
Subject: [R-sig-ME] =?utf-8?q?Need_help_to_find_multifactors_influence?=
	=?utf-8?b?4oCP?=
In-Reply-To: <CADkfwos-nCV8yCExF_NhAfgpqBfi-5h8TrbNyCYxFRpG5AppEg@mail.gmail.com>
References: <CADkfwos-nCV8yCExF_NhAfgpqBfi-5h8TrbNyCYxFRpG5AppEg@mail.gmail.com>
Message-ID: <CADkfwosHOhXKJEZpHrvehf-ORxyS9Wc0zUB-6=bbUbwiGn5sJA@mail.gmail.com>

Dear friends,

1-I have B.I value (Dependent variable).
2-I have land cover types in the form of % area against each B.I (that was
clipped through buffer for each B.I ). Buffer was put by considering B.I
behavior that can be influence by land type.
3- I want to see the influence of land type on B.I.
4- Suppose B.I value varies with the change in (area) one or more types of
land cover. This change may be linear up to some extent but can also
increase with the combination of land types. Land types can also differ
from one buffer to other buffer.
5- I want to develop a Predication Model\Regression Equation to predict B.I
value with the combined influence of different land use types.
6- I am confused which Regression model (Linear, Logistic, and Poisson,
Exponential etc...)  Should be adopted to develop this type of relationship
where factors are varying.
7- Total study map consists of 77 land cover types and each buffer gets
some land type.

Please see the attached data having values extracted for each land type
(a1~a77 are land type names against each BI).

I already tried to solve it with different methods. Even I made groups in
term of B.I & also in term of land cover types. But still failed to
find correlation with reasonable factors.

I will happy for your informative response to solve my this problem. Please
let me know if my question is not clear.

Warm Regards,
Malik\Arshad

From slu at ccsr.uchicago.edu  Mon Feb 27 22:02:31 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 27 Feb 2012 15:02:31 -0600
Subject: [R-sig-ME] How to calculate predictions
Message-ID: <1330376551.19171.23.camel@localhost>

Hello, I have modeled student math growth curves with lmer with a model
like this. It predicts math achievement by age (centered at age 11) with
a linear and quadratic term, with both these and the intercept varying
randomly across students:

math.lme3 <- lmer(data=allmathgains, math ~ I(age-11) + I((age-11)^2) +
old4gr + (I(age-11) + I((age-11)^2) | sid))

where sid is the student ID and old4gr take a value of 1 if the student
is old for grade, 0 otherwise. I want to get a prediction of each
student's achievement at age 15. I have done this kind of thing:

random.effects3 <- ranef(math.lme3)
fixed.effects3 <- fixef(math.lme3)

## Just try it for the first 100 students for now
test <- random.effects3$sid[1:100,]
test2 <- cbind(as.numeric(rownames(test)),
               test[,1]+fixed.effects3[1],
               test[,2]+fixed.effects3[2],
               test[,3]+fixed.effects3[3])
 
test3 <- cbind(test2, allmathgains[1:100, "old4gr"])
 
to.predict <- as.data.frame(cbind(rep(1, 100), rep(4, 100), rep(16,
100)))
to.predict2 <- cbind(to.predict, allmathgains[1:100, "old4gr"])

my.predictions <- numeric(100)
for (i in 1:100) {
  my.predictions[i] <- test3[i, 2:5] %*% t(as.matrix(to.predict2[i,]))
}

My questions: 
1) Is my idea to add each random effect to the fixed effects (to make
data.frame test2) correct? 
2) Is there a more efficient way of doing this? This is a big issue
because I am working with a data set of about 240,000 students. 

Thanks in advance.
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
For the S system, which has forever altered the way
 people analyze, visualize, and manipulate data
 .... S is an elegant, widely accepted, and
 enduring software system, with conceptual
 integrity, thanks to the insight, taste, and
 effort of John Chambers.    -- Association for
 Computing Machinery       ACM/Software System
 Award citation (1998)



From jake987722 at hotmail.com  Mon Feb 27 22:20:36 2012
From: jake987722 at hotmail.com (Jake Westfall)
Date: Mon, 27 Feb 2012 14:20:36 -0700
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <1330376551.19171.23.camel@localhost>
References: <1330376551.19171.23.camel@localhost>
Message-ID: <SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120227/07200f51/attachment-0002.pl>

From slu at ccsr.uchicago.edu  Mon Feb 27 23:42:48 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 27 Feb 2012 16:42:48 -0600
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>
References: <1330376551.19171.23.camel@localhost>
	<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>
Message-ID: <1330382568.19171.27.camel@localhost>

On Mon, 2012-02-27 at 14:20 -0700, Jake Westfall wrote:
> 1) Yes2) ?fitted

I don't think fitted is what I want. According to the docs, fitted
returns the fitted conditional means of the responses. I want the
predicted value when age-11 is 4, (age-11)^2 is 16, old4gr has the
appropriate value, and all the individual random effects are included.

> > From: slu at ccsr.uchicago.edu
> > To: r-sig-mixed-models at r-project.org
> > Date: Mon, 27 Feb 2012 15:02:31 -0600
> > Subject: [R-sig-ME] How to calculate predictions
> > 
> > Hello, I have modeled student math growth curves with lmer with a model
> > like this. It predicts math achievement by age (centered at age 11) with
> > a linear and quadratic term, with both these and the intercept varying
> > randomly across students:
> > 
> > math.lme3 <- lmer(data=allmathgains, math ~ I(age-11) + I((age-11)^2) +
> > old4gr + (I(age-11) + I((age-11)^2) | sid))
> > 
> > where sid is the student ID and old4gr take a value of 1 if the student
> > is old for grade, 0 otherwise. I want to get a prediction of each
> > student's achievement at age 15. I have done this kind of thing:
> > 
> > random.effects3 <- ranef(math.lme3)
> > fixed.effects3 <- fixef(math.lme3)
> > 
> > ## Just try it for the first 100 students for now
> > test <- random.effects3$sid[1:100,]
> > test2 <- cbind(as.numeric(rownames(test)),
> >                test[,1]+fixed.effects3[1],
> >                test[,2]+fixed.effects3[2],
> >                test[,3]+fixed.effects3[3])
> >  
> > test3 <- cbind(test2, allmathgains[1:100, "old4gr"])
> >  
> > to.predict <- as.data.frame(cbind(rep(1, 100), rep(4, 100), rep(16,
> > 100)))
> > to.predict2 <- cbind(to.predict, allmathgains[1:100, "old4gr"])
> > 
> > my.predictions <- numeric(100)
> > for (i in 1:100) {
> >   my.predictions[i] <- test3[i, 2:5] %*% t(as.matrix(to.predict2[i,]))
> > }
> > 
> > My questions: 
> > 1) Is my idea to add each random effect to the fixed effects (to make
> > data.frame test2) correct? 
> > 2) Is there a more efficient way of doing this? This is a big issue
> > because I am working with a data set of about 240,000 students. 
> > 
> > Thanks in advance.
> > -- 
> > Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
> > University of Chicago -=- CCSR 
> > ???????? -=-    Kernel 3.2.1-gentoo-r2                
> > For the S system, which has forever altered the way
> >  people analyze, visualize, and manipulate data
> >  .... S is an elegant, widely accepted, and
> >  enduring software system, with conceptual
> >  integrity, thanks to the insight, taste, and
> >  effort of John Chambers.    -- Association for
> >  Computing Machinery       ACM/Software System
> >  Award citation (1998)
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  		 	   		  


-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
My institution has a particularly diabolical policy
 on intellectual property, especially on software. 
 -- Ross Ihaka       R-help (August 2003)



From roby.joehanes at nih.gov  Mon Feb 27 23:48:02 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 27 Feb 2012 17:48:02 -0500
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
In-Reply-To: <loom.20120225T023057-270@post.gmane.org>
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
Message-ID: <99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>

Hi Ben:

Thank you very much. I think I will familiarize myself with the lme4Eigen code for a while. A few more questions:

1. I noticed that there is lme4Eigen version 0.9996875-9 in the repository:
http://lme4.r-forge.r-project.org/repos/src/contrib/
Which SVN revision does it correspond to? I am currently using it and it appears to be quite stable.

2. It seems that the code for revision 1618 isn't that much different than the HEAD branch (I believe 1621 at the moment). Is it really that buggy? I am primarily interested in the lmer, not glmer.

3. (A different topic) Is there any way to speed up calling lmer on the same X and Z matrices but thousands of different y columns? In general linear model, we can invoke QR decomposition and use Q and R matrices to speed the calculations up. Is there such a decomposition (or method) that we can exploit to speed up the calculation?

Finally, thank you for the pointer on Kenward-Roger DF estimation.

Sincerely,
Roby

--------
Roby Joehanes
Research Associate
Roby.Joehanes at nih.gov
Building 12A, Room 2007
National Institutes of Health (NIH)
Bethesda, MD 20892
P: (301) 402-8702
F: (301) 480-0028 or (301) 402-2867


On Feb 24, 2012, at 8:50 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
> 
>> I learned about the impending release of the new version of lme4 
>> (or lme4a) from Dr. Bates' post here:
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007499.html
>> 
>> Firstly, just to make sure, is this based on lme4a? 
>> I have the source tarball of lme4a 0.999375-65 and found
>> that a new optimizer, BOBYQA, is now in use, instead of the nlminb. 
>> The announcement above also mentioned
>> the same change. 
>> So, I suspect that the older lme4 is supplanted with lme4a. Is this true?
> 
>  I'm not quite sure what you mean.  There are three versions of lme4:
> 
> * lme4 "classic" (version 0.999375-42 is the latest) lme4, built on nlminb
>  (as was Bates's previous mixed-models package, nlme)
> 
> *** lme4 will be preserved on CRAN and (probably) renamed "lme4.0" after
> the new version (see below) is released as lme4, for users who
> need backward compatibility (we thought this was a reasonable
> name: there are still a few issues with package names containing
> dots, so we may need to change this ...). 
> 
> * lme4a (0.9996875-1) uses bobyqa
> 
> * lmeEigen (to be renamed lme4 when released, sometime soon ...)  uses
> a mixture of bobyqa and a new Nelder-Mead implementation that allows box 
> constraints, adapted from the nloptr package, which in turn wraps the 
> NLopt open-source optimization codes 
> (http://ab-initio.mit.edu/wiki/index.php/NLopt_Introduction).
> 
>> Secondly, I would like to get a source tarball of the latest 
>> bleeding edge release to play with (or even
>> read-only SVN access). I found from some sniff tests the lmer outputs of 
>> lme4a to be closely matched with
>> those of SAS than those of the lme4 (with nlminb optimizer), except for 
>> the lack of p-values. I would love to
>> play with the new version and even give you comparisons with the old 
>> version. The problem I am facing with
>> lme4a 0.999375-65 is that it sometimes crashes (core dumps).
> 
>  That's easy: just go here for instructions on SVN access:
> 
> http://r-forge.r-project.org/scm/?group_id=60
> 
> (the package is *so* bleeding edge that if you get it right now,
> you should roll back to SVN release 1618; releases 1619+ are
> currently broken ...)
> 
>> Thirdly, I also would love to see the Satterthwaite or
>> Kenward-Rogers DF estimation. I would like to try to add these
>> features into lme4, if you will. I don't know much about the
>> formulas to compute the DFs from quantities output by lmer /
>> glmer. Any pointers?
> 
> Doug Bates is on record as saying that adapting the Kenward-Roger
> formulation to work with his code would be difficult
> <https://stat.ethz.ch/pipermail/r-help/2008-February/155372.html>, 
> but Ulrich Halekoh and S?ren H?jsgaard have an implementation in 
> the pbkrtest package
> <http://cran.r-project.org/web/packages/pbkrtest/index.html>
> which you could look at.  Perhaps that would give you a hint about
> a Satterthwaite implementation as well ...
> 
> [PS there is no "s" in "Kenward-Roger" -- this is a very common mistake,
> Kenward-Roger gets 1.03 million google hits while Kenward-Rogers
> gets 438K ...]



From bates at stat.wisc.edu  Tue Feb 28 00:03:58 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Feb 2012 17:03:58 -0600
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
In-Reply-To: <99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
Message-ID: <CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>

On Mon, Feb 27, 2012 at 4:48 PM, Joehanes, Roby (NIH/NHLBI) [F]
<roby.joehanes at nih.gov> wrote:
> Hi Ben:
>
> Thank you very much. I think I will familiarize myself with the lme4Eigen code for a while. A few more questions:
>
> 1. I noticed that there is lme4Eigen version 0.9996875-9 in the repository:
> http://lme4.r-forge.r-project.org/repos/src/contrib/
> Which SVN revision does it correspond to? I am currently using it and it appears to be quite stable.

The SVN revision number is stored in the DESCRIPTION file for recent
versions of lme4Eigen.  It is actually the revision number for the
last check-in of the DESCRIPTION file but that gets updated fairly
frequently so the revision number in there is a pretty tight lower
bound.

> 2. It seems that the code for revision 1618 isn't that much different than the HEAD branch (I believe 1621 at the moment). Is it really that buggy? I am primarily interested in the lmer, not glmer.

The current revision (1623) should compile.  The breakage was
something I did on Friday and needed to commit because it was only on
my laptop.  I realized later that I had a modified version of
RcppEigen on my laptop and without those modifications the compilation
croaked. I created a version that doesn't use those particular
modifications, at least for now.

> 3. (A different topic) Is there any way to speed up calling lmer on the same X and Z matrices but thousands of different y columns? In general linear model, we can invoke QR decomposition and use Q and R matrices to speed the calculations up. Is there such a decomposition (or method) that we can exploit to speed up the calculation?

Yes, check out the refit function.  I just saw that the documentation
suffers from cut-and-paste errors but the general idea is to give a
fitted model a new response and run only the optimization step.

> (fm1 <- lmer(Yield ~ 1|Batch, Dyestuff))
Linear mixed model fit by REML ['lmerMod']
Formula: Yield ~ 1 | Batch
   Data: Dyestuff

REML criterion at convergence: 319.6543

Random effects:
 Groups   Name        Variance Std.Dev.
 Batch    (Intercept) 1764     42.00
 Residual             2451     49.51
Number of obs: 30, groups: Batch, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1527.50      19.38    78.8
> refit(fm1, Dyestuff2$Yield)
Linear mixed model fit by REML ['lmerMod']
Formula: Yield ~ 1 | Batch
   Data: Dyestuff

REML criterion at convergence: 161.8283

Random effects:
 Groups   Name        Variance Std.Dev.
 Batch    (Intercept)  0.00    0.000
 Residual             13.81    3.716
Number of obs: 30, groups: Batch, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   5.6656     0.6784   8.352

> Finally, thank you for the pointer on Kenward-Roger DF estimation.
>
> Sincerely,
> Roby
>
> --------
> Roby Joehanes
> Research Associate
> Roby.Joehanes at nih.gov
> Building 12A, Room 2007
> National Institutes of Health (NIH)
> Bethesda, MD 20892
> P: (301) 402-8702
> F: (301) 480-0028 or (301) 402-2867
>
>
> On Feb 24, 2012, at 8:50 PM, Ben Bolker wrote:
>
>> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
>>
>>> I learned about the impending release of the new version of lme4
>>> (or lme4a) from Dr. Bates' post here:
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007499.html
>>>
>>> Firstly, just to make sure, is this based on lme4a?
>>> I have the source tarball of lme4a 0.999375-65 and found
>>> that a new optimizer, BOBYQA, is now in use, instead of the nlminb.
>>> The announcement above also mentioned
>>> the same change.
>>> So, I suspect that the older lme4 is supplanted with lme4a. Is this true?
>>
>> ?I'm not quite sure what you mean. ?There are three versions of lme4:
>>
>> * lme4 "classic" (version 0.999375-42 is the latest) lme4, built on nlminb
>> ?(as was Bates's previous mixed-models package, nlme)
>>
>> *** lme4 will be preserved on CRAN and (probably) renamed "lme4.0" after
>> the new version (see below) is released as lme4, for users who
>> need backward compatibility (we thought this was a reasonable
>> name: there are still a few issues with package names containing
>> dots, so we may need to change this ...).
>>
>> * lme4a (0.9996875-1) uses bobyqa
>>
>> * lmeEigen (to be renamed lme4 when released, sometime soon ...) ?uses
>> a mixture of bobyqa and a new Nelder-Mead implementation that allows box
>> constraints, adapted from the nloptr package, which in turn wraps the
>> NLopt open-source optimization codes
>> (http://ab-initio.mit.edu/wiki/index.php/NLopt_Introduction).
>>
>>> Secondly, I would like to get a source tarball of the latest
>>> bleeding edge release to play with (or even
>>> read-only SVN access). I found from some sniff tests the lmer outputs of
>>> lme4a to be closely matched with
>>> those of SAS than those of the lme4 (with nlminb optimizer), except for
>>> the lack of p-values. I would love to
>>> play with the new version and even give you comparisons with the old
>>> version. The problem I am facing with
>>> lme4a 0.999375-65 is that it sometimes crashes (core dumps).
>>
>> ?That's easy: just go here for instructions on SVN access:
>>
>> http://r-forge.r-project.org/scm/?group_id=60
>>
>> (the package is *so* bleeding edge that if you get it right now,
>> you should roll back to SVN release 1618; releases 1619+ are
>> currently broken ...)
>>
>>> Thirdly, I also would love to see the Satterthwaite or
>>> Kenward-Rogers DF estimation. I would like to try to add these
>>> features into lme4, if you will. I don't know much about the
>>> formulas to compute the DFs from quantities output by lmer /
>>> glmer. Any pointers?
>>
>> Doug Bates is on record as saying that adapting the Kenward-Roger
>> formulation to work with his code would be difficult
>> <https://stat.ethz.ch/pipermail/r-help/2008-February/155372.html>,
>> but Ulrich Halekoh and S?ren H?jsgaard have an implementation in
>> the pbkrtest package
>> <http://cran.r-project.org/web/packages/pbkrtest/index.html>
>> which you could look at. ?Perhaps that would give you a hint about
>> a Satterthwaite implementation as well ...
>>
>> [PS there is no "s" in "Kenward-Roger" -- this is a very common mistake,
>> Kenward-Roger gets 1.03 million google hits while Kenward-Rogers
>> gets 438K ...]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jake987722 at hotmail.com  Tue Feb 28 00:07:30 2012
From: jake987722 at hotmail.com (Jake Westfall)
Date: Mon, 27 Feb 2012 16:07:30 -0700
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <1330382568.19171.27.camel@localhost>
References: <1330376551.19171.23.camel@localhost>,
	<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>,
	<1330382568.19171.27.camel@localhost>
Message-ID: <SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120227/792d912c/attachment-0002.pl>

From slu at ccsr.uchicago.edu  Tue Feb 28 00:31:04 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 27 Feb 2012 17:31:04 -0600
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
References: <1330376551.19171.23.camel@localhost>
	,<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>
	,<1330382568.19171.27.camel@localhost>
	<SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
Message-ID: <1330385464.19171.31.camel@localhost>

On Mon, 2012-02-27 at 16:07 -0700, Jake Westfall wrote:
> Unless I am misunderstanding what you're after, one thing you can do
> is just append the fitted values to the data frame (you will want to
> use math.lme3 at frame in case of dropped observations) and from there
> pick out the predicted value for each student at age 15. All of the
> appropriate other effects should be factored in.

I believe that fitted() is giving fitted values for each observation. 

 length(fitted(math.lme3))
[1] 520573
 length(unique(math.lme3 at frame$sid))
[1] 236994

I have about 520,000 observations nested within 236,994 students. I want
a fitted value for each student at age 15 (which may or may not be
actually observed).
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
1st mail: One of the reasons that SAM is popular,
 is that it is popular (i.e. since everyone has
 heard of it, it makes reviewers happy). So, it
 would be nice to be able to point to publications 
 in good journals so that reviewers will be
 comfortable. (I personally, am quite comfortable
 with SAM). 2nd mail: Oops, must have been a
 Freudian slip. Actually, I am not perfectly
 comfortable with SAM. But I am quite comfortable



From bbolker at gmail.com  Tue Feb 28 05:26:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 28 Feb 2012 04:26:16 +0000 (UTC)
Subject: [R-sig-ME] How to calculate predictions
References: <1330376551.19171.23.camel@localhost> ,
	<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl> ,
	<1330382568.19171.27.camel@localhost>
	<SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
	<1330385464.19171.31.camel@localhost>
Message-ID: <loom.20120228T052455-583@post.gmane.org>

Stuart Luppescu <slu at ...> writes:

> 
> On Mon, 2012-02-27 at 16:07 -0700, Jake Westfall wrote:
> 
> I believe that fitted() is giving fitted values for each observation. 
> 
>  length(fitted(math.lme3))
> [1] 520573
>  length(unique(math.lme3 <at> frame$sid))
> [1] 236994
> 
> I have about 520,000 observations nested within 236,994 students. I want
> a fitted value for each student at age 15 (which may or may not be
> actually observed).

  Have you looked at the code on http://glmm.wikidot.com/faq ... ?
Also, the new lme4Eigen package does have a ?predict method ...
  
  Ben Bolker



From Kevin_J_Ryan at umit.maine.edu  Tue Feb 28 17:44:15 2012
From: Kevin_J_Ryan at umit.maine.edu (Kevin J. Ryan)
Date: Tue, 28 Feb 2012 11:44:15 -0500
Subject: [R-sig-ME]
 =?iso-8859-1?q?Incorporating_a_Temporal_Correlation_St?=
 =?iso-8859-1?q?ructure_in_=09a=09=09GLM?=
In-Reply-To: <155F553A-8E23-470A-A182-90D61105BD88@wisc.edu>
References: <fc.004c4d194d3477bb004c4d194d3477bb.4d3492fa@umit.maine.edu> <	>
	<loom.20120222T020754-835@post.gmane.org>
	<155F553A-8E23-470A-A182-90D61105BD88@wisc.edu>
Message-ID: <fc.004c4d194d51c01b004c4d194d3477bb.4d51c236@umit.maine.edu>

Hello,

Thank you all very much for taking the time to give advice on my statistical issues.  So far I have run logistic regression models using glm, lmer, and glmmPQL.  I used pacf to look at autocorrelation of the residuals of these models and they do not
appear to be so (assuming pacf is suitable for use on residuals of a logistic regression).  Something may be going wrong with the lmer model however.  (The output of which is below this message.)  I included ?Toad? as a random effect and the
variance and SD are output as 0.  Perhaps because of this, the coefficients of the glm model and the lmer model are exactly the same.    

So if my residuals are okay, then perhaps an ordinary glm (pooling all toads) is the way to go.  I would have liked to model proportion of toads emerged but I only had two monitoring devices, which more often than not were not deployed
simultaneously.   

Thanks again everyone,

 - Kevin

> summary(Tavg.lmer)

Generalized linear mixed model fit by the Laplace approximation 

Formula: Emergence ~ Tavg + (1 | Toad) 

   AIC BIC logLik deviance

 481.2 493 -237.6    475.2

Random effects:

 Groups Name        Variance Std.Dev.

 Toad   (Intercept)  0        0      

Number of obs: 371, groups: Toad, 16


Fixed effects:

            Estimate Std. Error z value Pr(>|z|)    

(Intercept) -5.14598    0.95134  -5.409 6.33e-08 ***

Tavg         0.07202    0.01392   5.174 2.29e-07 ***

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

 
Correlation of Fixed Effects:

     (Intr)

Tavg -0.993

 
Anthony R Ives <arives at wisc.edu> writes:
>Kevin,
>
>It is not clear to me that this problem requires accounting for  
>temporal autocorrelation, although I might be missing something.  You  
>say that the weather variables are autocorrelated, but if these are  
>used as predictor variables, this doesn't necessarily mean that you  
>need a model incorporating autocorrelation; autocorrelation of the  
>errors (residuals) is what matters.  Also, it is not clear to me why  
>you would want to use logistic regression on each individual  
>separately.  I would suspect that there is correlation among  
>individuals beyond that explained by the weather variables you  
>included.  It might be simpler to analyze all individuals together  
>(i.e., proportion of emergences on a given day).
>
>That being said, there are three more approaches to Ben's list of  
>logistic regression with temporal autocorrelation:
>
>1. You could use an extended Kalman filter with a measurement  
>equation accounting for the variance structure of a binary process.   
>An advantage here is that it is simple to include gaps in the  
>observations.  I have seen this done in the literature, but a quick  
>check didn't turn up a reference.
>
>2. There is a largish literature on integer-valued ARMA models,  
>though I don't know of code that will do this easily.
>
>3. With colleagues, I've worked out two flavors of logistic  
>regression with phylogenetic correlations.  These could be used by  
>replacing the phylogenetic covariance matrix with a autocovariance  
>matrix.
>
>All of these will require a little custom programming.
>
>Cheers, Tony
>
>On Feb 21, 2012, at 7:15 PM, Ben Bolker wrote:
>
>> Kevin J. Ryan <Kevin_J_Ryan at ...> writes:
>>
>>
>>> I'm attempting to use mixed-model logistic regression to model
>>> spadefoot emergence as a function of weather variables (individuals
>>> are monitored continuously from 1-84 days [with gaps]).  However,
>>> the weather variables are serially autocorrelated, apparently at a
>>> lag of 12 days or so.  Does anyone have experience incorporating a
>>> temporal autocorrelation structure of predictor variables into a
>>> glm?  I've been examining the lme4 package but it does not appear to
>>> be able to do this.
>>
>>   A couple of quick thoughts:
>>
>> * you could use glmmPQL (in the MASS package), which does allow any
>> of the correlation structures that are defined in the nlme
>> package (including corCAR1, which allows for gappy data). This
>> is not preferred for binary data, but probably (?) correcting
>> for correlation and using a slightly questionable estimation method
>> is better than ignoring correlation.
>>
>> * if your responses are measured without error you might
>> be able to use emergences at a previous time point as
>> a predictor.
>>
>> * you could just use glm (or whatever) and evaluate the correlations
>> among the residuals -- if there's nothing going on there then you
>> have a reasonable excuse for proceeding without a correlation model.
>>
>> * the fact that the _predictor_ variables are autocorrelated isn't
>> that much of a big deal -- it's really the response (or rather the
>> residuals of the response) that you should be worried about, although
>> there is always a bit of an issue in time-series analysis in
>> looking at relationships of autocorrelated series with other
>> autocorrelated series ...
>>
>> * generalized estimating equations (GEE: see geepack etc.) are
>> another approach, although I don't know if any of the R packages
>> that do GEEs have an option for autocorrelations on unevenly
>> spaced data (try installing the "sos" package and searching
>> via something like findFn("gee uneven"))
>>
>> * in my opinion the gold standard (if the data are rich enough
>> to warrant it) is to build a hierarchical model with a latent
>> normally distributed variable with temporal autocorrelation and
>> an observed binary variable (emergence) on top of it, but this
>> is fairly hard work -- you'd need AD Model Builder or some
>> dialect of BUGS.
>>
>>  I will be interested to see if anyone has better suggestions.
>>
>>  I would check the books from Highland Statistics (Zuur et al.)
>> to see if they have anything useful ...
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>Anthony Ragnar Ives
>Department of Zoology
>UW-Madison
>(608) 262-1519
>
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From slu at ccsr.uchicago.edu  Tue Feb 28 19:54:36 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 28 Feb 2012 12:54:36 -0600
Subject: [R-sig-ME] How to calculate predictions
In-Reply-To: <loom.20120228T052455-583@post.gmane.org>
References: <1330376551.19171.23.camel@localhost>
	, <SNT107-W192B1226AEB26648F431E1CB690@phx.gbl>
	, <1330382568.19171.27.camel@localhost>
	<SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
	<1330385464.19171.31.camel@localhost>
	<loom.20120228T052455-583@post.gmane.org>
Message-ID: <1330455276.13060.3.camel@localhost>

On Tue, 2012-02-28 at 04:26 +0000, Ben Bolker wrote:
> Stuart Luppescu <slu at ...> writes:
> 
> > 
> > On Mon, 2012-02-27 at 16:07 -0700, Jake Westfall wrote:
> > 
> > I believe that fitted() is giving fitted values for each observation. 
> > 
> >  length(fitted(math.lme3))
> > [1] 520573
> >  length(unique(math.lme3 <at> frame$sid))
> > [1] 236994
> > 
> > I have about 520,000 observations nested within 236,994 students. I want
> > a fitted value for each student at age 15 (which may or may not be
> > actually observed).
> 
>   Have you looked at the code on http://glmm.wikidot.com/faq ... ?

Yes, I have. Unless I'm missing something (which is very possible) it
doesn't seem that the code includes the individual random effects.

> Also, the new lme4Eigen package does have a ?predict method ...

Doesn't seem to be available on CRAN -- only on R-forge? I don't think I
can convince our sysadmin to install a non-stable package.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
1st mail: One of the reasons that SAM is popular,
 is that it is popular (i.e. since everyone has
 heard of it, it makes reviewers happy). So, it
 would be nice to be able to point to publications 
 in good journals so that reviewers will be
 comfortable. (I personally, am quite comfortable
 with SAM). 2nd mail: Oops, must have been a
 Freudian slip. Actually, I am not perfectly
 comfortable with SAM. But I am quite comfortable



From Rachel.Gibson at bristol.ac.uk  Wed Feb 29 14:58:27 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson)
Date: Wed, 29 Feb 2012 13:58:27 -0000 (GMT)
Subject: [R-sig-ME] error message using glmmadmb
Message-ID: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>

I am trying to use glmmadmb to build a model.

Code used:

m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+(1|Site),family="nbinom")

"Site" is a categorical variable and is a factor (non numeric).

I get the error message:

Error in eval(expr, envir, enclos) : could not find function "Droplevels"
In addition: Warning message:
In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'

Can anyone tell me why I am getting this message, please?






--



From bbolker at gmail.com  Wed Feb 29 15:54:30 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Feb 2012 14:54:30 +0000 (UTC)
Subject: [R-sig-ME] error message using glmmadmb
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
Message-ID: <loom.20120229T155325-260@post.gmane.org>

RH Gibson <Rachel.Gibson at ...> writes:

> 
> I am trying to use glmmadmb to build a model.
> 
> Code used:
> 
> m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+
> fsize+(1|Site),family="nbinom")
> 
> "Site" is a categorical variable and is a factor (non numeric).
> 
> I get the error message:
> 
> Error in eval(expr, envir, enclos) : could not find function "Droplevels"
> In addition: Warning message:
> In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
> 
> Can anyone tell me why I am getting this message, please?

  What version are you using?  This is reminiscent of a problem with
a recent (but not-the-very-latest) version.  Can you try

update.packages(repos="http://r-forge.r-project.org")

(or just reinstalling glmmADMB)
or at least give the results of sessionInfo() ?

  Ben Bolker



From bbolker at gmail.com  Wed Feb 29 15:58:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Feb 2012 14:58:21 +0000 (UTC)
Subject: [R-sig-ME] How to calculate predictions
References: <1330376551.19171.23.camel@localhost> ,
	<SNT107-W192B1226AEB26648F431E1CB690@phx.gbl> ,
	<1330382568.19171.27.camel@localhost>
	<SNT107-W33FC849D531EB735F6FB57CB690@phx.gbl>
	<1330385464.19171.31.camel@localhost>
	<loom.20120228T052455-583@post.gmane.org>
	<1330455276.13060.3.camel@localhost>
Message-ID: <loom.20120229T155445-887@post.gmane.org>

Stuart Luppescu <slu at ...> writes:

> 
> On Tue, 2012-02-28 at 04:26 +0000, Ben Bolker wrote:
> > Stuart Luppescu <slu at ...> writes:
> > 
> > > 
> > > On Mon, 2012-02-27 at 16:07 -0700, Jake Westfall wrote:
> > > 
> > > I believe that fitted() is giving fitted values for each observation. 
> > > 
> > >  length(fitted(math.lme3))
> > > [1] 520573
> > >  length(unique(math.lme3 <at> frame$sid))
> > > [1] 236994
> > > 
> > > I have about 520,000 observations nested within 236,994 students. I want
> > > a fitted value for each student at age 15 (which may or may not be
> > > actually observed).
> > 
> >   Have you looked at the code on http://glmm.wikidot.com/faq ... ?
> 
> Yes, I have. Unless I'm missing something (which is very possible) it
> doesn't seem that the code includes the individual random effects.

  Hmm.  If you're comfortable doing a bit of coding, you can certainly
extract the random effects with ranef() and apply them to the predictions ...
if you wanted to get fancy you could create a sparse model matrix yourself
and use it (although in this case just taking ranef(math.lme3)[[1]]
out manually and doing the sensible thing with it should work.

> 
> > Also, the new lme4Eigen package does have a ?predict method ...
> 
> Doesn't seem to be available on CRAN -- only on R-forge? I don't think I
> can convince our sysadmin to install a non-stable package.
> 

  Yes, it's on r-forge.

  Maybe you can try installing it to a local directory and seeing
if it does what you want?

  Ben Bolker



From bbolker at gmail.com  Wed Feb 29 19:41:19 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Feb 2012 13:41:19 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
Message-ID: <4F4E714F.3020001@gmail.com>


  (1) detach("package:glmmadmb") , or start a clean R session, before
trying to update or install (you generally can't change a package while
it's loaded; (2) I'm not sure what's up with the directory not being
writable.  Usually if R finds that the package directory isn't writable
it offers to install to a different directory for you ...

   What happens if you simply update.packages() [without specifying
r-forge, i.e. update your regular packages]?  If not, then there's
something else funny about your R installation.

  I think I would definitely try an install.packages() in a clean R
session before trying to do any more diagnosis/troubleshooting.
(glmmADMB version 0.3 is really old -- where did you get it?)

  Ben Bolker

On 12-02-29 10:12 AM, RH Gibson wrote:
> I have done what you suggested and here is what happened:
> 
>> update.packages(repos="http://r-forge.r-project.org")
> glmmADMB :
>  Version 0.3 installed in C:/Program Files/R/R-2.14.1/library
>  Version 0.7.2.6 available at http://r-forge.r-project.org
> Update (y/N/c)?  y
> lattice :
>  Version 0.20-0 installed in C:/Program Files/R/R-2.14.1/library
>  Version 0.20-3 available at http://r-forge.r-project.org
> Update (y/N/c)?  y
> Matrix :
>  Version 1.0-2 installed in C:/Program Files/R/R-2.14.1/library
>  Version 1.0-4 available at http://r-forge.r-project.org
> Update (y/N/c)?  y
> Warning in install.packages(update[instlib == l, "Package"], l, contriburl
> = contriburl,  :
>   'lib = "C:/Program Files/R/R-2.14.1/library"' is not writable
> Error in install.packages(update[instlib == l, "Package"], l, contriburl =
> contriburl,  :
>   unable to install packages
>> sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] glmmADMB_0.7.2.6 R2admb_0.7.5     MASS_7.3-16
> 
> loaded via a namespace (and not attached):
> [1] grid_2.14.1    lattice_0.20-0 nlme_3.1-102   tools_2.14.1
> 
> 
> On Wed, February 29, 2012 2:54 pm, Ben Bolker wrote:
>> RH Gibson <Rachel.Gibson at ...> writes:
>>
>>>
>>> I am trying to use glmmadmb to build a model.
>>>
>>> Code used:
>>>
>>> m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+
>>> fsize+(1|Site),family="nbinom")
>>>
>>> "Site" is a categorical variable and is a factor (non numeric).
>>>
>>> I get the error message:
>>>
>>> Error in eval(expr, envir, enclos) : could not find function
>>> "Droplevels"
>>> In addition: Warning message:
>>> In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
>>>
>>> Can anyone tell me why I am getting this message, please?
>>
>>   What version are you using?  This is reminiscent of a problem with
>> a recent (but not-the-very-latest) version.  Can you try
>>
>> update.packages(repos="http://r-forge.r-project.org")
>>
>> (or just reinstalling glmmADMB)
>> or at least give the results of sessionInfo() ?
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>



From rimian85 at hotmail.com  Thu Mar  1 09:42:43 2012
From: rimian85 at hotmail.com (rajibul islam)
Date: Thu, 1 Mar 2012 19:42:43 +1100
Subject: [R-sig-ME] partner
Message-ID: <BLU141-W1515AA4FC6A3C0B95DCD50D26C0@phx.gbl>


hey pal I discovered this incredible program it truly made my life worry-free

Im make $4,000 /month with an easy to use program and its risk free receiving the kit which practically costs nothing

http://tiny.cc/jy7tv

Sign up to get your kit before the holidays

Your pal
rajibul









































 		 	   		  


From hcspol at gmail.com  Thu Mar  1 12:44:40 2012
From: hcspol at gmail.com (Chang Seok Han)
Date: Thu, 1 Mar 2012 22:44:40 +1100
Subject: [R-sig-ME] Comparison of random coefficients between groups
Message-ID: <CACG6zYHSzvwmHuk9+ZEANndYuXjACExp-TLVCBC_FkfbmX8pig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120301/79949d08/attachment-0002.pl>

From cabrittain at ucdavis.edu  Thu Mar  1 04:21:14 2012
From: cabrittain at ucdavis.edu (Claire Brittain)
Date: Wed, 29 Feb 2012 19:21:14 -0800
Subject: [R-sig-ME] decimal data with nested random effects
Message-ID: <00ab01ccf75a$5c1b92d0$1452b870$@edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120229/6c51cba1/attachment-0002.pl>

From Rachel.Gibson at bristol.ac.uk  Wed Feb 29 11:06:55 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson)
Date: Wed, 29 Feb 2012 10:06:55 -0000 (GMT)
Subject: [R-sig-ME] General question about GLMM and heterogeneity of variance
Message-ID: <50574.82.32.40.117.1330510015.squirrel@webmail.bris.ac.uk>

GibsonR <rachel.gibson <at> bristol.ac.uk> writes:

>
> My data have heterogeneity of variance (in a categorical variable), do I
need
> to specify a variance structure accounting for this in my model or do GLMMs
> by their nature account for such heterogeneity (as a result of using
> deviances rather than variances)? And if I do need to do this, how do I do
> it (e.g. using something like the VarIdent function in nlme) and in what
> package?


Added 29.02.2012


Sorry, I was not particularly clear.

 I ran my data through a GLM (the response variable is a proportion, and I
ignored the random effects for the purposes of data exploration), and
plotted the residuals against each of my predictor variables (some of
which are continuous, some categorical). The heterogeneity showed up in
the residuals of the response variable plotted against a categorical
predictor variable (Insect functional group).

Do I need to use something other than the GLMM in this case?

Thank you very much for your help.

--



From bates at stat.wisc.edu  Thu Mar  1 15:46:32 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Mar 2012 08:46:32 -0600
Subject: [R-sig-ME] partner
In-Reply-To: <BLU141-W1515AA4FC6A3C0B95DCD50D26C0@phx.gbl>
References: <BLU141-W1515AA4FC6A3C0B95DCD50D26C0@phx.gbl>
Message-ID: <CAO7JsnRJMWk0UfaRG6AT=dYDEPt1KHObaxsYvyLr6r2=mJe01w@mail.gmail.com>

Looks like Rajib's hotmail account has been compromised.  I have
changed his status on the list to require moderator approval of his
postings.

On Thu, Mar 1, 2012 at 2:42 AM, rajibul islam <rimian85 at hotmail.com> wrote:
>
> hey pal I discovered this incredible program it truly made my life worry-free
>
> Im make $4,000 /month with an easy to use program and its risk free receiving the kit which practically costs nothing
>
> http://tiny.cc/jy7tv
>
> Sign up to get your kit before the holidays
>
> Your pal
> rajibul
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Thu Mar  1 17:13:07 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 01 Mar 2012 11:13:07 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <4F4FA013.4090804@gmail.com>

  I figured out the problem.

  I almost always use glmmadmb with the data= argument, putting my data
into a data frame rather than having my variables attach()ed (almost
always a bad idea) or floating around in the global workspace.  If you
do this:

mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")

it ought to work.  However, it *should* work the way you specified -- I
will work on fixing the bug.

  thanks
    Ben Bolker


On 12-03-01 09:19 AM, RH Gibson, School Biological Sciences wrote:
> Hi Ben - latest attempt below . . .
> 
> 
>> local({pkg <- select.list(sort(.packages(all.available = 
> TRUE)),graphics=TRUE)
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> Loading required package: MASS
> Loading required package: R2admb
> 
> Attaching package: 'glmmADMB'
> 
> The following object(s) are masked from 'package:R2admb':
> 
>    stdEr
> 
>> data1<-read.table("F:/work/Gottingen2010/Pollen 
> analysis/beepollenq.txt",header=T)
>> attach(data1)
>>
>>
> m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+(1|Site),family="nbinom")
> 
> Error in eval(expr, envir, enclos) : could not find function "Droplevels"
> In addition: Warning message:
> In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
>> summary(m1)
> Error in summary(m1) : object 'm1' not found
>> list.files(.libPaths(),pattern="glmm",full.names=TRUE)
> [1] "C:/Program Files/R/R-2.14.2/library/glmmADMB"
>>  i1 <- installed.packages()
>> i1[grep("^glmm",rownames(i1)]
> Error: unexpected ']' in "i1[grep("^glmm",rownames(i1)]"
>>   sessionInfo()
> R version 2.14.2 (2012-02-29)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] glmmADMB_0.7.2.6 R2admb_0.7.5     MASS_7.3-17
> 
> loaded via a namespace (and not attached):
> [1] grid_2.14.2    lattice_0.20-0 nlme_3.1-103   tools_2.14.2
>>
> 
> 
> Rachel.
> 
> --On 01 March 2012 08:12 -0500 Ben Bolker <bbolker at gmail.com> wrote:
> 
>> On 12-03-01 04:49 AM, RH Gibson, School Biological Sciences wrote:
>>> Tried this morning on work PC, with latest versions of R and glmmADMB:
>>>
>>>
>>>>
>>> m1<-glmmadmb(spdiv~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize
>>> +(1|Site)+offset(log(Total.grains)),family="nbinom")
>>>
>>> Error in eval(expr, envir, enclos) : could not find function
>>> "Droplevels"
>>> In addition: Warning message:
>>> In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
>>>
>>>
>>>> list.files(.libPaths(),pattern="glmm",full.names=TRUE)
>>> [1] "C:/Program Files/R/R-2.14.2/library/glmmADMB"
>>>> i1 <- installed.packages()
>>>> i1[grep("^glmm",rownames(i1),]
>>> Error: unexpected ']' in "i1[grep("^glmm",rownames(i1),]"
>>
>>   extra comma before the final square bracket: try
>>
>> i1[grep("^glmm",rownames(i1)]
>>
>>   The first command at least confirms for me that you only have one copy
>> of glmmADMB installed.  What are the results of
>>
>>   sessionInfo()
>>
>>  when you have glmmADMB installed?
>>
>>   Ben
>>>
>>>
>>>
>>>
>>>
>>> --On 29 February 2012 15:32 -0500 Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>>> i1[grep("^glmm",rownames(i1)),]
>>>
>>>
>>>
>>> ----------------------
>>> RH Gibson, School Biological Sciences
>>> Rachel.Gibson at bristol.ac.uk
>>
> 
> 
> 
> ----------------------
> RH Gibson, School Biological Sciences
> Rachel.Gibson at bristol.ac.uk



From roby.joehanes at nih.gov  Thu Mar  1 18:44:30 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 12:44:30 -0500
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
In-Reply-To: <CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
	<CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
Message-ID: <AE8B81FD-D308-40EA-ABC8-2DB8293E9864@nih.gov>

Dr Bates,

Thank you for your reply.

I discovered a bug on your lme4Eigen's refit function. This is on version 0.9996875-9 (Description revision 169). I hope I got this right. If the original data matrix has some missing data in it, somehow the X and Z matrices (and y column) are correctly trimmed (i.e., the rows with missing data are removed). However, if I fit it with another y column, it reports error due to length mismatch. The error is as follows:
Error: length(newresp <- as.numeric(as.vector(newresp))) == length(rr$y) is not TRUE

Should I try the latest version and see if this bug has been fixed?

Also, will update method speed up computation if I changed the X (or Z) matrix a little bit by swapping or adding up to three columns (from about 40+ columns)?

Thank you,
Roby

On Feb 27, 2012, at 6:03 PM, Douglas Bates wrote:

> Yes, check out the refit function.  I just saw that the documentation
> suffers from cut-and-paste errors but the general idea is to give a
> fitted model a new response and run only the optimization step.



From bbolker at gmail.com  Thu Mar  1 19:10:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 1 Mar 2012 18:10:08 +0000 (UTC)
Subject: [R-sig-ME] error message using glmmadmb
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com>
Message-ID: <loom.20120301T190854-931@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

 [snip]

> If you do this:
> 
> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")
> 
> it ought to work.  However, it *should* work the way you specified -- I
> will work on fixing the bug.
> 
>   thanks
>     Ben Bolker

  This should be fixed now (i.e. in glmmADMB 0.7.2.7).
  It's still a good idea to use the data= argument.



From bbolker at gmail.com  Thu Mar  1 20:05:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 1 Mar 2012 19:05:34 +0000 (UTC)
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
	<CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
	<AE8B81FD-D308-40EA-ABC8-2DB8293E9864@nih.gov>
Message-ID: <loom.20120301T191141-982@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> I discovered a bug on your lme4Eigen's refit function. 
> This is on version 0.9996875-9 (Description
> revision 169). I hope I got this right. If the original data
>  matrix has some missing data in it, somehow the X
> and Z matrices (and y column) are correctly trimmed (i.e., the rows
>  with missing data are removed).
> However, if I fit it with another y column, it reports error due 
> to length mismatch. The error is as follows:
> Error: length(newresp <- as.numeric(as.vector(newresp))) == length(rr$y) 
> is not TRUE
> 
> Should I try the latest version and see if this bug has been fixed?

  It probably hasn't.  It would be very helpful if you could send a small
self-contained example to lme4-authors <at> r-forge.wu-wien.ac.at --
we could probably make one up ourselves, but it would be quicker/
more motivational if you did it.

> 
> Also, will update method speed up computation
>  if I changed the X (or Z) matrix a little bit by swapping or
> adding up to three columns (from about 40+ columns)? 

  Probably not -- refit saves time by (1) starting from previous
starting values and (2) not having to rebuild X and Z components.
You could do #1 yourself by doing something like setting

update(...,start=getME(prevfit,"theta"),...)

(I think).



From roby.joehanes at nih.gov  Thu Mar  1 20:11:30 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 14:11:30 -0500
Subject: [R-sig-ME] Contribution to lme4Eigen
Message-ID: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>

Hi lme4 developers,

I hope I can contribute to something positive to the community. I noticed that even in the latest version of lme4Eigen the lmer function only use Nelder-Mead optimizer. I would like to get Bobyqa optimizer back as an option (because I really like Bobyqa optimizer). So, I patched the code a little bit. I used the (hopefully) latest revision from SVN version 1631. I also added control for xst and xt factor multiplier (a FIXME item list). I hope this change is also acceptable. If you feel I am ignorant of your code style, I apologize.

Here is the code (only the lmer function). I clearly marked my changes. If you need a diff file with the current HEAD, I'll be happy to provide you with one. The function seems to be running happily without error or warning on my machine. I hope the changes can make it to the main trunk.

Sincerely,
Roby


From roby.joehanes at nih.gov  Thu Mar  1 20:15:54 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 14:15:54 -0500
Subject: [R-sig-ME] Contribution to lme4Eigen
In-Reply-To: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
Message-ID: <2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>

Ouch. Apparently, the mail daemon ate my attachment.

So, here it is (pasted). Sorry for the mail bomb.

-----------------------
lmer <- function(formula, data, REML = TRUE, sparseX = FALSE,
control = list(), start = NULL,
verbose = 0L, subset, weights, na.action, offset,
contrasts = NULL, devFunOnly=FALSE, optimizer=c("NelderMead","bobyqa"), ...)
{
    if (sparseX) warning("sparseX = TRUE has no effect at present")
    mf <- mc <- match.call()
    ## '...' handling up front, safe-guarding against typos ("familiy") :
    if(length(l... <- list(...))) {
		if (!is.null(l...$family)) {  # call glmer if family specified
			mc[[1]] <- as.name("glmer")
			return(eval(mc, parent.frame()) )
		}
		## Check for method argument which is no longer used
		if (!is.null(method <- l...$method)) {
			msg <- paste("Argument", sQuote("method"), "is deprecated.")
			if (match.arg(method, c("Laplace", "AGQ")) == "Laplace") {
				warning(msg)
				l... <- l...[names(l...) != "method"]
			} else stop(msg)
		}
		if(length(l...))
	    warning("extra argument(s) ",
		paste(sQuote(names(l...)), collapse=", "),
		" disregarded")
    }
	
    stopifnot(length(formula <- as.formula(formula)) == 3)
    if (missing(data)) data <- environment(formula)
	# evaluate and install the model frame :
    m <- match(c("data", "subset", "weights", "na.action", "offset"),
	names(mf), 0)
    mf <- mf[c(1, m)]
    mf$drop.unused.levels <- TRUE
    mf[[1]] <- as.name("model.frame")
    fr.form <- subbars(formula) # substituted "|" by "+" -
    environment(fr.form) <- environment(formula)
    mf$formula <- fr.form
    fr <- eval(mf, parent.frame())
	# random effects and terms modules
    reTrms <- mkReTrms(findbars(formula[[3]]), fr)
    if (any(unlist(lapply(reTrms$flist, nlevels)) >= nrow(fr)))
	stop("number of levels of each grouping factor must be less than number of obs")
    ## fixed-effects model matrix X - remove random effects from formula:
    form <- formula
    form[[3]] <- if(is.null(nb <- nobars(form[[3]]))) 1 else nb
    X <- model.matrix(form, fr, contrasts)#, sparse = FALSE, row.names = FALSE) ## sparseX not yet
    p <- ncol(X)
    if ((qrX <- qr(X))$rank < p)
	stop(gettextf("rank of X = %d < ncol(X) = %d", qrX$rank, p))
    rho <- new.env(parent=parent.env(environment()))
    rho$pp <- do.call(merPredD$new, c(reTrms[c("Zt","theta","Lambdat","Lind")], n=nrow(X), list(X=X)))
    rho$resp <- mkRespMod(fr, if(REML) p else 0L)
	
    devfun <- mkdevfun(rho, 0L)
    devfun(reTrms$theta) # one evaluation to ensure all values are set
	
    if (devFunOnly) return(devfun)
	
    lower <- reTrms$lower
	# RJ's changes begin
	opt <- switch(match.arg(optimizer),
		bobyqa = {
			if(!is.numeric(control$rhobeg)) control$rhobeg <- 0.0002
			if(!is.numeric(control$rhoend)) control$rhoend <- 2e-7
			rho$control <- control
			# Delete unused options to prevent warning from showing up
			control$FtolAbs <- NULL
			control$FtolRel <- NULL
			bobyqa(rho$pp$theta, devfun, lower, control=control)
		},
		NelderMead = {
			## FIXME: this code is replicated in lmer/glmer/nlmer ...
			## it seems good to have it in R rather than C++ code but maybe it should go within Nelder_Mead() ??
			control$iprint <- switch(as.character(min(verbose,3L)), "0"=0, "1"=20,"2"=10,"3"=1)
			xst <- rep.int(0.1, length(lower))
			# RJ -- allow user control of xst, xt
			ctl <- control
			if(!is.numeric(control$xstFactor))
				xstFactor <- 0.2
			else
				xstFactor <- control$xstFactor
			if(!is.numeric(control$xtFactor))
				xtFactor <- 0.0001
			else
				xtFactor <- control$xtFactor
			ctl$xstFactor <- NULL
			ctl$xtFactor <- NULL
			Nelder_Mead(devfun, x0=rho$pp$theta, xst=xstFactor*xst, xt=xst*xtFactor, lower=lower, control=ctl)
		})

	if(optimizer=="NelderMead") {
	    if (opt$ierr < 0L) {
			if (opt$ierr > -4L)
			stop("convergence failure, code ", opt$ierr, " in NelderMead")
			else
			warning("failure to converge in", opt$control$maxfun, "evaluations")
		}
	} else if (optimizer=="bobyqa") {
		if (opt$ierr > 0L)
			warning("convergence problem, code ", opt$ierr, " in bobyqa")
	}
	# RJ's changes end
    mkMerMod(environment(devfun), opt, reTrms, fr, mc)
}## { lmer }



On Mar 1, 2012, at 2:11 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi lme4 developers,
> 
> I hope I can contribute to something positive to the community. I noticed that even in the latest version of lme4Eigen the lmer function only use Nelder-Mead optimizer. I would like to get Bobyqa optimizer back as an option (because I really like Bobyqa optimizer). So, I patched the code a little bit. I used the (hopefully) latest revision from SVN version 1631. I also added control for xst and xt factor multiplier (a FIXME item list). I hope this change is also acceptable. If you feel I am ignorant of your code style, I apologize.
> 
> Here is the code (only the lmer function). I clearly marked my changes. If you need a diff file with the current HEAD, I'll be happy to provide you with one. The function seems to be running happily without error or warning on my machine. I hope the changes can make it to the main trunk.
> 
> Sincerely,
> Roby



From roby.joehanes at nih.gov  Thu Mar  1 20:21:35 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 14:21:35 -0500
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
In-Reply-To: <loom.20120301T191141-982@post.gmane.org>
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
	<CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
	<AE8B81FD-D308-40EA-ABC8-2DB8293E9864@nih.gov>
	<loom.20120301T191141-982@post.gmane.org>
Message-ID: <2CB1E4E0-3246-4EFE-AECC-A53CA95F2796@nih.gov>

Hi Ben,

On Mar 1, 2012, at 2:05 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
> 
>> I discovered a bug on your lme4Eigen's refit function. 
>> This is on version 0.9996875-9 (Description
>> revision 169). I hope I got this right. If the original data
>> matrix has some missing data in it, somehow the X
>> and Z matrices (and y column) are correctly trimmed (i.e., the rows
>> with missing data are removed).
>> However, if I fit it with another y column, it reports error due 
>> to length mismatch. The error is as follows:
>> Error: length(newresp <- as.numeric(as.vector(newresp))) == length(rr$y) 
>> is not TRUE
>> 
>> Should I try the latest version and see if this bug has been fixed?
> 
>  It probably hasn't.  It would be very helpful if you could send a small
> self-contained example to lme4-authors <at> r-forge.wu-wien.ac.at --
> we could probably make one up ourselves, but it would be quicker/
> more motivational if you did it.

Unfortunately, my data is considered classified. I am not authorized to give one out. I hope I can compose an example real soon.

>> 
>> Also, will update method speed up computation
>> if I changed the X (or Z) matrix a little bit by swapping or
>> adding up to three columns (from about 40+ columns)? 
> 
>  Probably not -- refit saves time by (1) starting from previous
> starting values and (2) not having to rebuild X and Z components.
> You could do #1 yourself by doing something like setting
> 
> update(...,start=getME(prevfit,"theta"),...)
> 
> (I think).

Thank you. I will try it out.

Sincerely,
Roby


From roby.joehanes at nih.gov  Thu Mar  1 21:17:54 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 15:17:54 -0500
Subject: [R-sig-ME] Contribution to lme4Eigen
In-Reply-To: <2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
	<2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>
Message-ID: <C6BC780B-E522-4497-9F74-CA2AB379E188@nih.gov>

Apologies again. I submitted the changes to the tracker here:
https://r-forge.r-project.org/tracker/index.php?func=detail&aid=1861&group_id=60&atid=300

On Mar 1, 2012, at 2:15 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Ouch. Apparently, the mail daemon ate my attachment.
> 
> So, here it is (pasted). Sorry for the mail bomb.
<snip>


From bbolker at gmail.com  Thu Mar  1 21:32:48 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 1 Mar 2012 20:32:48 +0000 (UTC)
Subject: [R-sig-ME] Contribution to lme4Eigen
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
	<2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>
Message-ID: <loom.20120301T212041-625@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> 
> Ouch. Apparently, the mail daemon ate my attachment.
> 

  Would you be willing to send this as an SVN diff to
lme4-authors <at> r-forge.wu-wien.ac.at ?  Or post it to the issue tracker
on r-forge ?

  Ben



From roby.joehanes at nih.gov  Thu Mar  1 21:44:58 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 15:44:58 -0500
Subject: [R-sig-ME] Contribution to lme4Eigen
In-Reply-To: <loom.20120301T212041-625@post.gmane.org>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
	<2FBC7F38-6A50-4B3C-BB11-B1A2DDD43884@nih.gov>
	<loom.20120301T212041-625@post.gmane.org>
Message-ID: <6A7516BA-B82A-42BA-B7FF-05CD89A6EA55@nih.gov>

Hi Ben,

Thank you for the reply. I've added the diff patch against SVN rev 1631 in the issue tracker:
https://r-forge.r-project.org/tracker/download.php/60/300/1861/147/lmer-svn1631-patch.txt

See the corresponding page here:
https://r-forge.r-project.org/tracker/index.php?func=detail&aid=1861&group_id=60&atid=300

Also attached (cc-ed to the e-mail you mentioned). Apologies about the line ending. I am currently using a Mac.

Roby

On Mar 1, 2012, at 3:32 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
>
>>
>> Ouch. Apparently, the mail daemon ate my attachment.
>>
>
>  Would you be willing to send this as an SVN diff to
> lme4-authors <at> r-forge.wu-wien.ac.at ?  Or post it to the issue tracker
> on r-forge ?
>
>  Ben

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lmer-svn1631-patch.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120301/385ad7d1/attachment-0002.txt>

From rlaforge at mail.uri.edu  Thu Mar  1 23:20:24 2012
From: rlaforge at mail.uri.edu (Robert Laforge)
Date: Thu, 01 Mar 2012 17:20:24 -0500
Subject: [R-sig-ME] glmmADMB package
Message-ID: <000001ccf7f9$8249e520$86ddaf60$@uri.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120301/5fdc5687/attachment-0002.pl>

From roby.joehanes at nih.gov  Thu Mar  1 23:52:07 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 1 Mar 2012 17:52:07 -0500
Subject: [R-sig-ME] PedigreeMM question
In-Reply-To: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
Message-ID: <66CC0141-0818-4781-A353-DB6679C6E928@nih.gov>

Hi,

I would like to do something like this in pedigreemm:

result <- pedigreemm(y ~ ...<the other factors>... + (1 | id), data=mydata, pedigree=list(id=mypedigree), na.action=na.omit)

To my impression after reading pedigreemm's code, I need several observations with the same ID number and I cannot have each observation to have a different ID. Is this correct? Then, is it possible to have 1 observation having 1 ID? I don't think it is, given how the Z matrix for ID is encoded in lmer (and thereby pedigreemm) and how examples in the paper accompanying the package are constructed. Maybe I am incorrect or maybe I am doing an incorrect encoding.

What I am getting at is genome-wide association study (GWAS)-like analysis that account for familial correlation matrix. Here, each observation comes from one individual, which is associated an individual ID and a pedigree ID. One pedigree ID contains essentially a family tree from great grandparents down to the little ones. The pedigree is somewhat complicated by step-parents (indicated by siblings sharing one parent, but not the other) and a few members of one pedigree intermarrying those of another. I have the inclination to specify the model as:

result <- pedigreemm(y ~ ...<the other factors>... + (1 | ped_id), data=mydata, pedigree=list(ped_id =mypedigree), na.action=na.omit)

To me, it doesn't seem to be correct since pedigreemm will treat observations having the same ped_id as repeat observations. If I understand the code correctly, pedigreemm will tie ped_id with the mypedigree$id. I cannot put in individual IDs into mypedigree$id since it will make pedigreemm associate IDs incorrectly. However, I cannot put in pedigree ID into mypedigree$id either since one pedigree ID consists of the whole family tree.

The questions are: How can I deal with this problem? Should I break up the pedigree into nuclear families? How can I deal with the step-parents and intermarriage complications above? If pedigreemm was not designed for problems of this class, which other packages should I look into?

Thank you,
Roby


From chris at trickysolutions.com.au  Fri Mar  2 00:48:01 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 2 Mar 2012 10:48:01 +1100
Subject: [R-sig-ME] General question about GLMM and heterogeneity of
	variance
In-Reply-To: <50574.82.32.40.117.1330510015.squirrel@webmail.bris.ac.uk>
References: <50574.82.32.40.117.1330510015.squirrel@webmail.bris.ac.uk>
Message-ID: <-6156322436662673238@unknownmsgid>

How bad is it? And do u have equal sample size in each cat group?

I ask because if the sample sizes are very different it may look like
the larger sample sizes have greater variance but this is only because
they have more sample and it's therefore more likely u will see
extreme values.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 02/03/2012, at 1:45, RH Gibson <Rachel.Gibson at bristol.ac.uk> wrote:

> GibsonR <rachel.gibson <at> bristol.ac.uk> writes:
>
>>
>> My data have heterogeneity of variance (in a categorical variable), do I
> need
>> to specify a variance structure accounting for this in my model or do GLMMs
>> by their nature account for such heterogeneity (as a result of using
>> deviances rather than variances)? And if I do need to do this, how do I do
>> it (e.g. using something like the VarIdent function in nlme) and in what
>> package?
>
>
> Added 29.02.2012
>
>
> Sorry, I was not particularly clear.
>
> I ran my data through a GLM (the response variable is a proportion, and I
> ignored the random effects for the purposes of data exploration), and
> plotted the residuals against each of my predictor variables (some of
> which are continuous, some categorical). The heterogeneity showed up in
> the residuals of the response variable plotted against a categorical
> predictor variable (Insect functional group).
>
> Do I need to use something other than the GLMM in this case?
>
> Thank you very much for your help.
>
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jwiley.psych at gmail.com  Fri Mar  2 03:03:49 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 1 Mar 2012 18:03:49 -0800
Subject: [R-sig-ME] glmmADMB package
In-Reply-To: <000001ccf7f9$8249e520$86ddaf60$@uri.edu>
References: <000001ccf7f9$8249e520$86ddaf60$@uri.edu>
Message-ID: <FC9F1C2B-2A9A-45D1-953B-927574412864@gmail.com>

Hi Bob,

I would recommend you upgrade to R 2.14.1 (it's easy and free!).  What OS are you using?  It is relevant for this type of problem.  I'm not familiar with otter research, but I have not had difficulty with glmmadmb from r forge on win x64.

Give us some more details on your version of R, what you tried, and the error and we should be able to help out.

Cheers,

Josh 

On Mar 1, 2012, at 14:20, "Robert Laforge" <rlaforge at mail.uri.edu> wrote:

> Hi,   I am using R version 2.14 and I am having trouble installing glmmADMB
> that I just downloaded from Otter Research.   Do you know if this package
> works with V.2.14?    Thanks,   Bob
> 
> 
> 
> Robert Laforge, Sc.D.
> 
> Professor of Behavioral Epidemiology
> 
> Department of Psychology
> 
> Director of Survey Research, CPRC, Rm. 48W
> 
> University of Rhode Island
> 
> Kingston, RI 02818.
> 
> <mailto:rlaforge at uri.edu> rlaforge at uri.edu
> 
> (401) 874-5571
> 
> Fax (401) 874-5562
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Fri Mar  2 03:08:21 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 2 Mar 2012 12:08:21 +1000 (EST)
Subject: [R-sig-ME] PedigreeMM question
In-Reply-To: <66CC0141-0818-4781-A353-DB6679C6E928@nih.gov>
References: <958C9FF9-6FA8-4391-98C6-4A46CE9BA509@nih.gov>
	<66CC0141-0818-4781-A353-DB6679C6E928@nih.gov>
Message-ID: <Pine.LNX.4.64.1203021157430.20151@orpheus.qimr.edu.au>

On Thu, 1 Mar 2012, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi,
>
> I would like to do something like this in pedigreemm:
>
> To my impression after reading pedigreemm's code, I need several 
> observations with the same ID number and I cannot have each observation 
> to have a different ID. Is this correct?
>
> What I am getting at is genome-wide association study (GWAS)-like 
> analysis that account for familial correlation matrix. Here, each 
> observation comes from one individual, which is associated an individual 
> ID and a pedigree ID. One pedigree ID
>
> The questions are: How can I deal with this problem? Should I break up 
> the pedigree into nuclear families? How can I deal with the step-parents 
> and intermarriage complications above? If pedigreemm was not designed 
> for problems of this class, which other packages should I look into?
>

The pedigree() constructor is set up as animal breeders do things: the 
entire dataset is one big pedigree, even though there may be subcomponents 
that do not connect to one another.  This is why sparse matrix 
representations are used.  So, you just need unique IDs for everybody (eg 
concatenate pedigree with individual ID).  This allows for intermarriage 
etc.  If you think step-parents transmit your phenotype to step-children, 
then you need to add in a family environmental random effect (ie common to 
all members of an extended family, or perhaps just to that "nongenetic" 
nuclear family).  If you have repeat measures on individuals, then you 
include multiple records with the same unique ID.

Cheers, David Duffy

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Fri Mar  2 05:04:30 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Mar 2012 04:04:30 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB package
References: <000001ccf7f9$8249e520$86ddaf60$@uri.edu>
Message-ID: <loom.20120302T050202-921@post.gmane.org>

Robert Laforge <rlaforge at ...> writes:

> 
> Hi,   I am using R version 2.14 and I am having trouble installing glmmADMB
> that I just downloaded from Otter Research.   Do you know if this package
> works with V.2.14?    Thanks,   Bob
> 

  The version on the Otter Research page is very old -- I think the web page
tells you that.   (Did you get it from
http://otter-rsch.com/admbre/examples/glmmadmb/glmmADMB.html , which does indeed
have a banner to that effect?)  http://glmmadmb.r-forge.r-project.org/ is the
new / authoritative web page.

  Ben Bolker



From bbolker at gmail.com  Fri Mar  2 05:11:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Mar 2012 04:11:34 +0000 (UTC)
Subject: [R-sig-ME] decimal data with nested random effects
References: <00ab01ccf75a$5c1b92d0$1452b870$@edu>
Message-ID: <loom.20120302T050527-235@post.gmane.org>

Claire Brittain <cabrittain at ...> writes:

> I have some decimal data (a diversity index) with nested random effects
> (sites within years).
> 
> There are a lot of zeros in the diversity index (19 out of 61 data points).
> 
> I would like to investigate the effects of two variables (one continuous,
> one categorical) on the diversity index.
> 
> I am more familiar with modeling count data and would set up a mixed model
> with Poisson error and a subject level random variable for overdispersion
> (there is one data point per site, per year so in the model below the random
> effects are at the subject level).
> 
> model1<-lmer(DiversityIndex~categorical_variable*continuous_variable+(1|Year
> /Site),family=poisson)
> 
> However I get the error that the poisson distribution is for integers only -
> although if I look at the summary of the model the output still looks
> sensible. Can I use the poisson distribution on non-integer data?

  It's dicey.  You _could_ make the argument that you're just trying
to get the mean-variance relationship right (although in that case
you would probably be better off using lme with a varPower() variance
structure ...)

> The diversity index cannot be transformed to normal and I need to keep the
> nested random effects in the model so I am not sure what error distribution
> I should be using for non integer, non normal data with nested random
> effects?
> 
> Any suggestions as to the type of model/family I should be using would be
> much appreciated.

  It's pretty tough.  Tweedie distributions are possible (and there is
a cplm package that implements mixed models with Tweedie distributions),
but with a non-huge data set I might be tempted just to use something
simple (e.g. linear models) and do some kind of resampling solution
(bootstrapping, permutation test, etc.) to get confidence intervals/p
values -- the hard part being that you have to be careful with
resampling when you have blocking in your data.



From bbolker at gmail.com  Fri Mar  2 05:18:48 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Mar 2012 04:18:48 +0000 (UTC)
Subject: [R-sig-ME] Bleeding edge lme4 (or lme4a) plus DF estimation
References: <0590ACB9-9325-4028-9648-2D9FFC8E8D81@nih.gov>
	<loom.20120225T023057-270@post.gmane.org>
	<99703522-9DD9-4E10-9A63-11C38F8A01B1@nih.gov>
	<CAO7JsnRJ+dsFkU_sYh-Eo=xR-RT7R5HLJdAWyMyqJr5qymAjyQ@mail.gmail.com>
	<AE8B81FD-D308-40EA-ABC8-2DB8293E9864@nih.gov>
	<loom.20120301T191141-982@post.gmane.org>
	<2CB1E4E0-3246-4EFE-AECC-A53CA95F2796@nih.gov>
Message-ID: <loom.20120302T051743-306@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> 
> Hi Ben,
> 
> On Mar 1, 2012, at 2:05 PM, Ben Bolker wrote:
> 
> > Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
> > 
> >> I discovered a bug on your lme4Eigen's refit function. 
> >> This is on version 0.9996875-9 (Description
> >> revision 169). I hope I got this right. If the original data
> >> matrix has some missing data in it, somehow the X
> >> and Z matrices (and y column) are correctly trimmed (i.e., the rows
> >> with missing data are removed).
> >> However, if I fit it with another y column, it reports error due 
> >> to length mismatch. The error is as follows:
> >> Error: length(newresp <- as.numeric(as.vector(newresp))) == length(rr$y) 
> >> is not TRUE
> >> 
> >> Should I try the latest version and see if this bug has been fixed?
> > 
> >  It probably hasn't.  It would be very helpful if you could send a small
> > self-contained example to lme4-authors <at> r-forge.wu-wien.ac.at --
> > we could probably make one up ourselves, but it would be quicker/
> > more motivational if you did it.
> 
> Unfortunately, my data is considered classified. 
> I am not authorized to give one out. I hope I can compose an
> example real soon.

  It's not hard to make up an example:

library(lme4Eigen)
d <- data.frame(x=runif(100),f=factor(rep(1:10,10)))
set.seed(101)
u <- rnorm(10)
d <- transform(d,y=rnorm(100,1+2*x+u[f],0.2))
d[c(3,5,7),"x"] <- NA

fm1 <- lmer(y~x+(1|f),data=d)

refit(fm1,runif(100))


   The obvious workaround for now is to use na.omit() on the
data in advance ...



From amelie.pinet at gmail.com  Fri Mar  2 14:58:32 2012
From: amelie.pinet at gmail.com (amelie pinet)
Date: Fri, 2 Mar 2012 14:58:32 +0100
Subject: [R-sig-ME] error in nlme()
Message-ID: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120302/5fdc312f/attachment-0002.pl>

From bbolker at gmail.com  Fri Mar  2 16:41:27 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Mar 2012 15:41:27 +0000 (UTC)
Subject: [R-sig-ME] error in nlme()
References: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>
Message-ID: <loom.20120302T163732-975@post.gmane.org>

amelie pinet <amelie.pinet at ...> writes:

> 
> Hello,
> When using nlme () function I have a error message that I don't understand:
> 
> Mod2 <- nlme(Nb_phyto ~dbleseg1(JourJulien,a0,b0,a1,T,a0a),data =
> dataAna,fixed=a0+b0+a1+T+a0a~1,
> random=pdDiag(b0~1),
> start=c(a0=a0init,b0=b0init,a1=a1init,T=Tinit,a0a=a0ainit),na.action=na.omit)
> 
> Erreur dans X[, fmap[[nm]]] <- gradnm :
>   le nombre d'objets ? remplacer n'est pas multiple de la taille du
> remplacement
> De plus : Il y a eu 47 avis (utilisez warnings() pour les visionner)


   It's hard to answer without a reproducible example:
http://tinyurl.com/reproducible-000 ... the problem *could* be inside
your dbleseg1 function.  Does it work outside of nls/nlme?  Are there
any simplified versions that you have gotten to work?
  
> I use the following packages:
> 
> R version 2.11.1 (2010-05-31)
> x86_64-pc-linux-gnu
> nlme_3.1-96 rj_1.0.3-7
> 

  It's not necessarily *the* problem, but it would generally be advised
to update to a more recent version of nlme -- especially if we have
trouble reproducing your problem with more recent versions.

  You can use traceback() to try to see where the error came from,
although it's probably pretty deep within a nested set of function
calls ...



From galizur at gmail.com  Sat Mar  3 11:41:52 2012
From: galizur at gmail.com (Christopher D. Long)
Date: Sat, 3 Mar 2012 02:41:52 -0800
Subject: [R-sig-ME] Quadratic with Random Offset in One Dimension
Message-ID: <CA+b8XEKEaQT6DNMNBtjKTVxs3GfQTcbUN7e8O+MXKmLXWnjHow@mail.gmail.com>

Hi,

I'm looking to fit a family of quadratics in (x,y) with a random factor
offset in one variable. The model would look like this:

outcome ~ x^2 + x*(y+F) + (y+F)^2 + 1

with F a random factor.

If this were linear in x,y it'd be no problem:

outcome ~ x + y + 1|F.

Is there a way to get either lme4 to estimate a model like this?
If not, what's my best route?
-- 
Christopher D. Long, San Diego Padres, 100 Park Blvd, San Diego CA

"Tick, clong, tick, clong, tick, clong, went the night." - Thurber



From steven.brady at yale.edu  Sat Mar  3 19:54:28 2012
From: steven.brady at yale.edu (Steven Brady)
Date: Sat, 3 Mar 2012 13:54:28 -0500
Subject: [R-sig-ME] Family specification - MCMCglmm survival analysis
Message-ID: <9E240F94-4263-446F-B6E4-51248E69F8FD@yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120303/273d4b35/attachment-0002.pl>

From bates at stat.wisc.edu  Sat Mar  3 22:28:09 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 3 Mar 2012 15:28:09 -0600
Subject: [R-sig-ME] Fit SGLMM by lme4 package
In-Reply-To: <1330803862830777500@modares.ac.ir>
References: <1330803862830777500@modares.ac.ir>
Message-ID: <CAO7JsnR0eS=ZXDraByoroyVs+QFzjLhnRhtePhgYJrab7TNTSw@mail.gmail.com>

I am taking the opportunity to cc: this reply to the
R-SIG-Mixed-Models mailing list.  Members of that list are often more
knowledgeable and quicker to respond than am I.

On Sat, Mar 3, 2012 at 1:44 PM,  <hbaghishani at modares.ac.ir> wrote:
> Dear Professor Bates,

> I would like to fit an spatial generalized linear mixed model, for example
> to model spatial count responses, by Laplace approximation and by using lme4
> R package. I'm very enthusiastic if it is possible to implement this fitting
> by?glmer in lme4 package?

I'm not exactly sure what a spatial generalized linear mixed model is.
 Could you or someone else on the list elaborate, please?



From john.maindonald at anu.edu.au  Sat Mar  3 23:30:38 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 4 Mar 2012 09:30:38 +1100
Subject: [R-sig-ME] Fit SGLMM by lme4 package
In-Reply-To: <CAO7JsnR0eS=ZXDraByoroyVs+QFzjLhnRhtePhgYJrab7TNTSw@mail.gmail.com>
References: <1330803862830777500@modares.ac.ir>
	<CAO7JsnR0eS=ZXDraByoroyVs+QFzjLhnRhtePhgYJrab7TNTSw@mail.gmail.com>
Message-ID: <A05EB10B-61C2-475A-B7DE-8CC5843A63C4@anu.edu.au>

The first place to look is surely under "Point pattern analysis"
on the Spatial task view (http://cran.csiro.au/web/views/)
Note especially the spatstat package.

But I am puzzled also.  A model that takes account os spatial
correlation might I suppose be described as some kind of
'spatial generalized linear mixed model'
Do you have something more in mind?  And why the Laplace
approximation in particular?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 04/03/2012, at 8:28 AM, Douglas Bates wrote:

> I am taking the opportunity to cc: this reply to the
> R-SIG-Mixed-Models mailing list.  Members of that list are often more
> knowledgeable and quicker to respond than am I.
> 
> On Sat, Mar 3, 2012 at 1:44 PM,  <hbaghishani at modares.ac.ir> wrote:
>> Dear Professor Bates,
> 
>> I would like to fit an spatial generalized linear mixed model, for example
>> to model spatial count responses, by Laplace approximation and by using lme4
>> R package. I'm very enthusiastic if it is possible to implement this fitting
>> by glmer in lme4 package?
> 
> I'm not exactly sure what a spatial generalized linear mixed model is.
> Could you or someone else on the list elaborate, please?
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From A.Robinson at ms.unimelb.edu.au  Sun Mar  4 00:46:09 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 4 Mar 2012 10:46:09 +1100
Subject: [R-sig-ME] Fit SGLMM by lme4 package
In-Reply-To: <A05EB10B-61C2-475A-B7DE-8CC5843A63C4@anu.edu.au>
References: <1330803862830777500@modares.ac.ir>
	<CAO7JsnR0eS=ZXDraByoroyVs+QFzjLhnRhtePhgYJrab7TNTSw@mail.gmail.com>
	<A05EB10B-61C2-475A-B7DE-8CC5843A63C4@anu.edu.au>
Message-ID: <20120303234609.GJ988@ms.unimelb.edu.au>

The original poseter might find INLA of use:

http://www.r-inla.org/

Best wishes

Andrew

On Sun, Mar 04, 2012 at 09:30:38AM +1100, John Maindonald wrote:
> The first place to look is surely under "Point pattern analysis"
> on the Spatial task view (http://cran.csiro.au/web/views/)
> Note especially the spatstat package.
> 
> But I am puzzled also.  A model that takes account os spatial
> correlation might I suppose be described as some kind of
> 'spatial generalized linear mixed model'
> Do you have something more in mind?  And why the Laplace
> approximation in particular?
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
> 
> On 04/03/2012, at 8:28 AM, Douglas Bates wrote:
> 
> > I am taking the opportunity to cc: this reply to the
> > R-SIG-Mixed-Models mailing list.  Members of that list are often more
> > knowledgeable and quicker to respond than am I.
> > 
> > On Sat, Mar 3, 2012 at 1:44 PM,  <hbaghishani at modares.ac.ir> wrote:
> >> Dear Professor Bates,
> > 
> >> I would like to fit an spatial generalized linear mixed model, for example
> >> to model spatial count responses, by Laplace approximation and by using lme4
> >> R package. I'm very enthusiastic if it is possible to implement this fitting
> >> by glmer in lme4 package?
> > 
> > I'm not exactly sure what a spatial generalized linear mixed model is.
> > Could you or someone else on the list elaborate, please?
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Deputy Director, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/



From j.hadfield at ed.ac.uk  Sun Mar  4 18:14:26 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 04 Mar 2012 17:14:26 +0000
Subject: [R-sig-ME] Family specification - MCMCglmm survival analysis
In-Reply-To: <9E240F94-4263-446F-B6E4-51248E69F8FD@yale.edu>
References: <9E240F94-4263-446F-B6E4-51248E69F8FD@yale.edu>
Message-ID: <20120304171426.124657sdd0i0mvwg@www.staffmail.ed.ac.uk>

Hi Steve,

"ordinal" has only been implemented for categorical data: you could  
expand each observation out into a series of zeros and ones and then  
fit an additional random effect pertaining to the original  
observation. However, that would be very inefficient computationally,  
and so if you're happy to use a logit link I would stick with  
"multinomial2".

Cheers,

Jarrod



probit link, "multinomial2" for logit link.


Quoting Steven Brady <steven.brady at yale.edu> on Sat, 3 Mar 2012  
13:54:28 -0500:

> Dear All:
> I have an experiment in which a suite of field enclosures were each  
> stocked with approximately 100 frog embryos. I would like to analyze  
> survival from this experiment as a two column response, e.g.  
> cbind(survived, died). Is it possible to use a probit link (i.e.  
> family = "ordinal") for a non-binary response such as this? If not,  
> would "multinomial2" be an appropriate family for this analysis? For  
> example:
> MCMCglmm(cbind(survived,(died))~x, random = ~clutch + block, family  
> = "multinomial2", data = xx)
>
> Many thanks,
> Steve
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Rachel.Gibson at bristol.ac.uk  Mon Mar  5 09:08:54 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Mon, 05 Mar 2012 08:08:54 +0000
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <loom.20120301T190854-931@post.gmane.org>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com> <loom.20120301T190854-931@post.gmane.org>
Message-ID: <A69D1D9335D92E102AD2AD79@bio-bzjxm-0501.bio.bris.ac.uk>

Thank you, I will let you know how I get on!


--On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com> wrote:

> Ben Bolker <bbolker at ...> writes:
>
>  [snip]
>
>> If you do this:
>>
>> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")
>>
>> it ought to work.  However, it *should* work the way you specified -- I
>> will work on fixing the bug.
>>
>>   thanks
>>     Ben Bolker
>
>   This should be fixed now (i.e. in glmmADMB 0.7.2.7).
>   It's still a good idea to use the data= argument.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From Rachel.Gibson at bristol.ac.uk  Mon Mar  5 12:00:56 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Mon, 05 Mar 2012 11:00:56 +0000
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <loom.20120301T190854-931@post.gmane.org>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com> <loom.20120301T190854-931@post.gmane.org>
Message-ID: <FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>

Updated to latest version and now having new problems:

m3<- 
glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offset(logTotal.grains)+(1|Site),data=data1, 
zeroInflation=TRUE, family="binomial")
Error in glmmadmb(x ~ nsn * Insect.type + ara * Insect.type + rap * 
Insect.type +  :
  The function maximizer failed (couldn't find STD file)
In addition: Warning message:
running command 'C:\WINDOWS\system32\cmd.exe /c "C:/Program 
Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500 
-maxph 5 -noinit -shess' had status 1


Can you help with this?

Many thanks, Rachel.

--On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com> wrote:

> Ben Bolker <bbolker at ...> writes:
>
>  [snip]
>
>> If you do this:
>>
>> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")
>>
>> it ought to work.  However, it *should* work the way you specified -- I
>> will work on fixing the bug.
>>
>>   thanks
>>     Ben Bolker
>
>   This should be fixed now (i.e. in glmmADMB 0.7.2.7).
>   It's still a good idea to use the data= argument.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From bbolker at gmail.com  Mon Mar  5 14:25:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 05 Mar 2012 08:25:08 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com>
	<loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <4F54BEB4.7060500@gmail.com>

On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences wrote:
> Updated to latest version and now having new problems:
> 
> m3<-
> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offset(logTotal.grains)+(1|Site),data=data1,
> zeroInflation=TRUE, family="binomial")
> Error in glmmadmb(x ~ nsn * Insect.type + ara * Insect.type + rap *
> Insect.type +  :
>  The function maximizer failed (couldn't find STD file)
> In addition: Warning message:
> running command 'C:\WINDOWS\system32\cmd.exe /c "C:/Program
> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500
> -maxph 5 -noinit -shess' had status 1
> 

  This now means that the optimization failed for some reason.
  There are many reasons this can happen, mostly having to do with
too-sparse or unusual data.  Without knowing anything about your data,
the one thing that pops out is you are using a binomial family with
zeroInflation=TRUE.  If your response is a matrix of successes and
failures, that's unusual but plausible; if your response is a single 0/1
vector, then it doesn't make sense to use zero-inflation.  (If your
response is anything else it's odd too, although that probably would
have been caught earlier.)
  Try working through the troubleshooting steps under ?admbControl (and
running with verbose=TRUE to see exactly what AD Model Builder reports
as the problem).

  Ben Bolker


> 
> Can you help with this?
> 
> Many thanks, Rachel.
> 
> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com> wrote:
> 
>> Ben Bolker <bbolker at ...> writes:
>>
>>  [snip]
>>
>>> If you do this:
>>>
>>> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom")
>>>
>>> it ought to work.  However, it *should* work the way you specified -- I
>>> will work on fixing the bug.
>>>
>>>   thanks
>>>     Ben Bolker
>>
>>   This should be fixed now (i.e. in glmmADMB 0.7.2.7).
>>   It's still a good idea to use the data= argument.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> ----------------------
> RH Gibson, School Biological Sciences
> Rachel.Gibson at bristol.ac.uk



From Rachel.Gibson at bristol.ac.uk  Mon Mar  5 14:52:16 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Mon, 05 Mar 2012 13:52:16 +0000
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <4F54BEB4.7060500@gmail.com>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com> <loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54BEB4.7060500@gmail.com>
Message-ID: <E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>

That would make sense as I am able to fit a zero-inflated negative binomial 
model, but not just the binomial. I have tried poisson too, but this gave 
me the same error message as trying to fit the binomial.

The y variable is a count, offset by a sample total. There is 
overdispersion and a lot of zeros in the data. Does using the zero-inflated 
negative binomial make sense here?

Thanks.


--On 05 March 2012 08:25 -0500 Ben Bolker <bbolker at gmail.com> wrote:

> On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences wrote:
>> Updated to latest version and now having new problems:
>>
>> m3<-
>> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offset(
>> logTotal.grains)+(1|Site),data=data1, zeroInflation=TRUE,
>> family="binomial")
>> Error in glmmadmb(x ~ nsn * Insect.type + ara * Insect.type + rap *
>> Insect.type +  :
>>  The function maximizer failed (couldn't find STD file)
>> In addition: Warning message:
>> running command 'C:\WINDOWS\system32\cmd.exe /c "C:/Program
>> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500
>> -maxph 5 -noinit -shess' had status 1
>>
>
>   This now means that the optimization failed for some reason.
>   There are many reasons this can happen, mostly having to do with
> too-sparse or unusual data.  Without knowing anything about your data,
> the one thing that pops out is you are using a binomial family with
> zeroInflation=TRUE.  If your response is a matrix of successes and
> failures, that's unusual but plausible; if your response is a single 0/1
> vector, then it doesn't make sense to use zero-inflation.  (If your
> response is anything else it's odd too, although that probably would
> have been caught earlier.)
>   Try working through the troubleshooting steps under ?admbControl (and
> running with verbose=TRUE to see exactly what AD Model Builder reports
> as the problem).
>
>   Ben Bolker
>
>
>>
>> Can you help with this?
>>
>> Many thanks, Rachel.
>>
>> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> Ben Bolker <bbolker at ...> writes:
>>>
>>>  [snip]
>>>
>>>> If you do this:
>>>>
>>>> mydata <- data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom
>>>> ")
>>>>
>>>> it ought to work.  However, it *should* work the way you specified -- I
>>>> will work on fixing the bug.
>>>>
>>>>   thanks
>>>>     Ben Bolker
>>>
>>>   This should be fixed now (i.e. in glmmADMB 0.7.2.7).
>>>   It's still a good idea to use the data= argument.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> ----------------------
>> RH Gibson, School Biological Sciences
>> Rachel.Gibson at bristol.ac.uk
>



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From bbolker at gmail.com  Mon Mar  5 15:22:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 05 Mar 2012 09:22:28 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com>
	<loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54BEB4.7060500@gmail.com>
	<E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <4F54CC24.4000901@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12-03-05 08:52 AM, RH Gibson, School Biological Sciences wrote:
> That would make sense as I am able to fit a zero-inflated negative 
> binomial model, but not just the binomial. I have tried poisson
> too, but this gave me the same error message as trying to fit the
> binomial.
> 
> The y variable is a count, offset by a sample total. There is 
> overdispersion and a lot of zeros in the data. Does using the 
> zero-inflated negative binomial make sense here?
> 
> Thanks.

  It very rarely makes sense to use the binomial and the negative
binomial to fit the same set of data; the binomial has a fixed
(typically known) upper limit, the Poisson and NB do not.  (The
exception to this is that people will sometimes use Poisson/NB models
when the upper limit is known but the observed frequency is very low
- -- this is especially common e.g. in epidemiology.)  ZINB, or plain
old NB, probably make the most sense.

  It's more interesting that you get an error message with the
Poisson, which may indicate some glmmADMB instability.  What are the
results of summary(data1)?  How many sites do you have?

  Ben Bolker
> 
> 
> --On 05 March 2012 08:25 -0500 Ben Bolker <bbolker at gmail.com>
> wrote:
> 
>> On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences
>> wrote:
>>> Updated to latest version and now having new problems:
>>> 
>>> m3<- 
>>> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offset(
>>>
>>> 
logTotal.grains)+(1|Site),data=data1, zeroInflation=TRUE,
>>> family="binomial") Error in glmmadmb(x ~ nsn * Insect.type +
>>> ara * Insect.type + rap * Insect.type +  : The function
>>> maximizer failed (couldn't find STD file) In addition: Warning
>>> message: running command 'C:\WINDOWS\system32\cmd.exe /c
>>> "C:/Program 
>>> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe"
>>> -maxfn 500 -maxph 5 -noinit -shess' had status 1
>>> 
>> 
>> This now means that the optimization failed for some reason. 
>> There are many reasons this can happen, mostly having to do with 
>> too-sparse or unusual data.  Without knowing anything about your
>> data, the one thing that pops out is you are using a binomial
>> family with zeroInflation=TRUE.  If your response is a matrix of
>> successes and failures, that's unusual but plausible; if your
>> response is a single 0/1 vector, then it doesn't make sense to
>> use zero-inflation.  (If your response is anything else it's odd
>> too, although that probably would have been caught earlier.) Try
>> working through the troubleshooting steps under ?admbControl
>> (and running with verbose=TRUE to see exactly what AD Model
>> Builder reports as the problem).
>> 
>> Ben Bolker
>> 
>> 
>>> 
>>> Can you help with this?
>>> 
>>> Many thanks, Rachel.
>>> 
>>> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com>
>>> wrote:
>>> 
>>>> Ben Bolker <bbolker at ...> writes:
>>>> 
>>>> [snip]
>>>> 
>>>>> If you do this:
>>>>> 
>>>>> mydata <-
>>>>> data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site) 
>>>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbinom
>>>>>
>>>>> 
")
>>>>> 
>>>>> it ought to work.  However, it *should* work the way you
>>>>> specified -- I will work on fixing the bug.
>>>>> 
>>>>> thanks Ben Bolker
>>>> 
>>>> This should be fixed now (i.e. in glmmADMB 0.7.2.7). It's
>>>> still a good idea to use the data= argument.
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> 
>>> ---------------------- RH Gibson, School Biological Sciences 
>>> Rachel.Gibson at bristol.ac.uk
>> 
> 
> 
> 
> ---------------------- RH Gibson, School Biological Sciences 
> Rachel.Gibson at bristol.ac.uk

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPVMwkAAoJED2whTVMEyK9uVIIAIWj65sTlLNJWgOXsI1xZNaQ
pFD7dAOCotHlcFfDhulOZwuvcMwS5jnN459GMURSuyriQDrW1itQyqZ2y6EGpBuh
wj3OHG9vYBSUenkPBe+lBN5uXD62JPyKmfzp7djHs6zPeIWOGoxVXMTLHDBgmfky
kas5eOq91b/N88DpeL+duYAqjo+rtgD/h1kjMlELUwQXC3M3aeA1k78Lxx+Bahye
hsbTFJm/7cc7moBv9SpgO//qDJDqhKUa4z01XljibHl9J57m76/TY2M8/sFrOBDB
ig3h4Yc6ajoaSegaTn1NmzaISMMdTWVi1RWI4PL5Uu/SqLLxt4sloXuXMoF+4fY=
=xOtC
-----END PGP SIGNATURE-----



From Rachel.Gibson at bristol.ac.uk  Mon Mar  5 16:22:39 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Mon, 05 Mar 2012 15:22:39 +0000
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <4F54CC24.4000901@gmail.com>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com> <loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54BEB4.7060500@gmail.com>
	<E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54CC24.4000901@gmail.com>
Message-ID: <E8AF898129FE6A3949ECEFF9@bio-bzjxm-0501.bio.bris.ac.uk>

here is what happens when I tried the poisson:

> 
m7<-glmmadmb(x~nsn*Insect.type+ara*Insect.type+offset(logTotal.grains)+(1|Site),data=data1, 
zeroInflation=TRUE, family="poisson")
Warning message:
In glmmadmb(x ~ nsn * Insect.type + ara * Insect.type + 
offset(logTotal.grains) +  :
  Convergence failed:log-likelihood of gradient= -223.949

I will email you the summary(data1) output separately.

I have 8 sites only.

Thanks for all the help.


--On 05 March 2012 09:22 -0500 Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 12-03-05 08:52 AM, RH Gibson, School Biological Sciences wrote:
>> That would make sense as I am able to fit a zero-inflated negative
>> binomial model, but not just the binomial. I have tried poisson
>> too, but this gave me the same error message as trying to fit the
>> binomial.
>>
>> The y variable is a count, offset by a sample total. There is
>> overdispersion and a lot of zeros in the data. Does using the
>> zero-inflated negative binomial make sense here?
>>
>> Thanks.
>
>   It very rarely makes sense to use the binomial and the negative
> binomial to fit the same set of data; the binomial has a fixed
> (typically known) upper limit, the Poisson and NB do not.  (The
> exception to this is that people will sometimes use Poisson/NB models
> when the upper limit is known but the observed frequency is very low
> - -- this is especially common e.g. in epidemiology.)  ZINB, or plain
> old NB, probably make the most sense.
>
>   It's more interesting that you get an error message with the
> Poisson, which may indicate some glmmADMB instability.  What are the
> results of summary(data1)?  How many sites do you have?
>
>   Ben Bolker
>>
>>
>> --On 05 March 2012 08:25 -0500 Ben Bolker <bbolker at gmail.com>
>> wrote:
>>
>>> On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences
>>> wrote:
>>>> Updated to latest version and now having new problems:
>>>>
>>>> m3<-
>>>> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+offse
>>>> t(
>>>>
>>>>
> logTotal.grains)+(1|Site),data=data1, zeroInflation=TRUE,
>>>> family="binomial") Error in glmmadmb(x ~ nsn * Insect.type +
>>>> ara * Insect.type + rap * Insect.type +  : The function
>>>> maximizer failed (couldn't find STD file) In addition: Warning
>>>> message: running command 'C:\WINDOWS\system32\cmd.exe /c
>>>> "C:/Program
>>>> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe"
>>>> -maxfn 500 -maxph 5 -noinit -shess' had status 1
>>>>
>>>
>>> This now means that the optimization failed for some reason.
>>> There are many reasons this can happen, mostly having to do with
>>> too-sparse or unusual data.  Without knowing anything about your
>>> data, the one thing that pops out is you are using a binomial
>>> family with zeroInflation=TRUE.  If your response is a matrix of
>>> successes and failures, that's unusual but plausible; if your
>>> response is a single 0/1 vector, then it doesn't make sense to
>>> use zero-inflation.  (If your response is anything else it's odd
>>> too, although that probably would have been caught earlier.) Try
>>> working through the troubleshooting steps under ?admbControl
>>> (and running with verbose=TRUE to see exactly what AD Model
>>> Builder reports as the problem).
>>>
>>> Ben Bolker
>>>
>>>
>>>>
>>>> Can you help with this?
>>>>
>>>> Many thanks, Rachel.
>>>>
>>>> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com>
>>>> wrote:
>>>>
>>>>> Ben Bolker <bbolker at ...> writes:
>>>>>
>>>>> [snip]
>>>>>
>>>>>> If you do this:
>>>>>>
>>>>>> mydata <-
>>>>>> data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>>>>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="nbin
>>>>>> om
>>>>>>
>>>>>>
> ")
>>>>>>
>>>>>> it ought to work.  However, it *should* work the way you
>>>>>> specified -- I will work on fixing the bug.
>>>>>>
>>>>>> thanks Ben Bolker
>>>>>
>>>>> This should be fixed now (i.e. in glmmADMB 0.7.2.7). It's
>>>>> still a good idea to use the data= argument.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>>> ---------------------- RH Gibson, School Biological Sciences
>>>> Rachel.Gibson at bristol.ac.uk
>>>
>>
>>
>>
>> ---------------------- RH Gibson, School Biological Sciences
>> Rachel.Gibson at bristol.ac.uk
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iQEcBAEBAgAGBQJPVMwkAAoJED2whTVMEyK9uVIIAIWj65sTlLNJWgOXsI1xZNaQ
> pFD7dAOCotHlcFfDhulOZwuvcMwS5jnN459GMURSuyriQDrW1itQyqZ2y6EGpBuh
> wj3OHG9vYBSUenkPBe+lBN5uXD62JPyKmfzp7djHs6zPeIWOGoxVXMTLHDBgmfky
> kas5eOq91b/N88DpeL+duYAqjo+rtgD/h1kjMlELUwQXC3M3aeA1k78Lxx+Bahye
> hsbTFJm/7cc7moBv9SpgO//qDJDqhKUa4z01XljibHl9J57m76/TY2M8/sFrOBDB
> ig3h4Yc6ajoaSegaTn1NmzaISMMdTWVi1RWI4PL5Uu/SqLLxt4sloXuXMoF+4fY=
> =xOtC
> -----END PGP SIGNATURE-----



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From amelie.pinet at gmail.com  Tue Mar  6 09:42:26 2012
From: amelie.pinet at gmail.com (amelie pinet)
Date: Tue, 6 Mar 2012 09:42:26 +0100
Subject: [R-sig-ME] error in nlme()
In-Reply-To: <loom.20120302T163732-975@post.gmane.org>
References: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>
	<loom.20120302T163732-975@post.gmane.org>
Message-ID: <CAKNZCKFGHNNOwEzuAg2nFwDLFE_CPyjF3NJv8WUEvyVh7_055Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120306/210bf6be/attachment-0002.pl>

From statsstud8 at gmail.com  Tue Mar  6 07:42:23 2012
From: statsstud8 at gmail.com (Student Stats)
Date: Mon, 5 Mar 2012 22:42:23 -0800
Subject: [R-sig-ME] Covariance models with lme and gls
Message-ID: <CAGspFjBGkR80Na_hxCnMYRRom0fqzQ_b4j9xxXDGUiN+AZgmYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120305/cebe8128/attachment-0002.pl>

From bbolker at gmail.com  Tue Mar  6 17:44:03 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 6 Mar 2012 16:44:03 +0000 (UTC)
Subject: [R-sig-ME] Covariance models with lme and gls
References: <CAGspFjBGkR80Na_hxCnMYRRom0fqzQ_b4j9xxXDGUiN+AZgmYA@mail.gmail.com>
Message-ID: <loom.20120306T173742-387@post.gmane.org>

Student Stats <statsstud8 at ...> writes:


> I'm trying to fit several covariance models using gls and lme. My aim is to
> identify which covariance model fits my data better. I'm afraid, however,
> that I'm not specifying the code properly. Could someone take a look on my
> code and help me figuring out whether I'm pursuing everything correctly?
> 

 You just posted this to StackOverflow.  It isn't explicitly proscribed
(as cross-posting among R help lists is), but I don't like it because it
diffuses information and potentially wastes effort.  I told you there that
this seems like a bit of a "please debug my code for me question" -- what
have you tried already in order to figure out whether you're doing it
right or not?  Do you have reasons to suspect you're doing something
wrong?  It's easier to answer a specific question than to look over
a big hunk of code.

   I suggested to you on Stack Overflow that using update() would
make it easier to look at your code.  In fact you can structure it
a bit further:

vs <- varIdent(form=~1|time)
cs <- corSymm(form=~1|id)
ccs <- corCompSymm(form=~1|id)
car1 <- corAR1(form=~1|id)

> # Independence covariance matrix
> IN <- gls(y ~ ses + time, data, corr=NULL, weights=NULL, method="REML",
> control=lmeControl(msMaxIter = 500, msVerbose = TRUE))
> 

UN <- update(IN, corr=cs, weights=vs)

> # Fit Random Intercept Model (RI)
> RI <- lme(y ~ ses + time, data, na.action=na.omit, method="REML",
> random=~1|id, control=lmeControl(msMaxIter = 200, msVerbose = TRUE))
> 

RIAS <- update(RI, random=~time|id)
CS <- update(IN,correlation=ccs)
CSH <- update(CS,weights=vs)
AR1 <- update(IN,correlation=car1)

  et cetera.



From bbolker at gmail.com  Tue Mar  6 18:05:41 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 6 Mar 2012 17:05:41 +0000 (UTC)
Subject: [R-sig-ME] error in nlme()
References: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>
	<loom.20120302T163732-975@post.gmane.org>
	<CAKNZCKFGHNNOwEzuAg2nFwDLFE_CPyjF3NJv8WUEvyVh7_055Q@mail.gmail.com>
Message-ID: <loom.20120306T180030-171@post.gmane.org>

amelie pinet <amelie.pinet at ...> writes:

> 
> Hello,
> 
> *Here it is a copy of my data:*
> 
  [snip]

> 
> *I also post my data here (be careful, it's a .xls file)*
> http://www.fichier-xls.fr/2012/03/06/7gvwshi/*
> 
> The code used is as follow:*
> 

  The main problem with your code is that you used DATA$Traitement
within the functions; when na.omit() scrubbed NAs from the input
data, it led to a mismatch between the data length and the length
of the 'Traitement' variable.  In general it's often simpler/more
robust to scrub NAs explicitly beforehand (using na.omit()) unless
you have particular reasons to need to retain those data throughout
the modeling process.  You can also (as I have done below) add
'Traitement' as a variable in your functions; in general it is 
bad practice to refer directly to global variables in your
nls functions, for exactly this reason ...

library(gdata)
## http://www.fichier-xls.fr/2012/03/06/7gvwshi/Phyllocrone_AP.xls
DATA <- read.xls("Phyllocrone_AP.xls",na.strings=c("NA","#VALUE!"),
comment.char="")

## for some reason I couldn't get #VALUE! read in as NA ...
DATA <- transform(DATA,Nb_phyto=as.numeric(as.character(Nb_phyto)))

# broken line with no effet of traitement
dbleseg0 <- function (JourJulien,a0,b0,a1,T) (a0*JourJulien+b0) +
  a1*(JourJulien >T)*(T-JourJulien)

# broken line with effet of traitement on a0 parameter
dbleseg1 <- function (JourJulien,a0,b0,a1,T,a0a,Traitement) {
    (((a0+a0a*(Traitement!="Control"))*JourJulien)+b0) +
a1*(JourJulien >T)*(T-JourJulien)
}

# broken line with effet of traitement on b0 parameter
dbleseg2 <- function (JourJulien,a0,b0,a1,T,b0a,Traitement) {
    ((a0*JourJulien)+(b0+b0a*(Traitement!="Control"))) +
a1*(JourJulien >T)*(T-JourJulien)
                }

# broken line with effet of traitement on a0 and b0 parameters
dbleseg3 <- function (JourJulien,a0,b0,a1,T,a0a,b0a,Traitement) {

  (((a0+a0a*(Traitement!="Control"))*JourJulien)+
    (b0+b0a*(Traitement!="Control")))+ a1*(JourJulien >T)*(T-JourJulien)
}

a0init <- 0.49
b0init <- -65
a1init <- 0.30
Tinit <- 239
a0ainit <- -0.40
b0ainit <- 6
a1ainit <- -0.1

library(nlme)

start1 <- c(a0=a0init,b0=b0init,a1=a1init,T=Tinit)
with(c(DATA,as.list(start1)),dbleseg0(JourJulien,a0,b0,a1,T))
Mod1 <- nls(Nb_phyto ~dbleseg0(JourJulien,a0,b0,a1,T),
data =DATA,start=start1,na.action=na.omit)

Mod2 <- nls(Nb_phyto ~dbleseg1(JourJulien,a0,b0,a1,T,a0a,Traitement),
data =DATA,start=start1,
na.action=na.omit)

Mod3 <- nls(Nb_phyto ~dbleseg2(JourJulien,a0,b0,a1,T,b0a,Traitement),
data =DATA,start=c(a0=a0init,b0=b0init,a1=a1init,T=Tinit,b0a=b0ainit),
na.action=na.omit)

Mod4 <- nls(Nb_phyto ~dbleseg3(JourJulien,a0,b0,a1,T,a0a,b0a,Traitement),
data = DATA,start1,na.action=na.omit)

*Mod2, Mod3, Mod4 ran but I obtained this warnings:
Il y a eu 50 avis ou plus (utilisez warnings() pour voir les 50 premiers)

  Did you look at the warnings????

  I had a problem with Mod4 ("singular gradient matrix
at initial parameter estimates") -- you should look at your
initial values and see whether they give rise to a sensible
estimate or not ...

Then I tried to use nlme()* (with the same start values) :

dataAna <- groupedData(Nb_phyto ~1|Plante,data=DATA)

Mod5 <- nlme(Nb_phyto ~dbleseg0(JourJulien,a0,b0,a1,T),data =
dataAna,fixed=a0+b0+a1+T~1,random=pdDiag(b0~1),
start=c(a0=a0init,b0=b0init,a1=a1init,T=Tinit),na.action=na.omit)

Mod6 <- nlme(Nb_phyto ~dbleseg1(JourJulien,a0,b0,a1,T,a0a,Traitement),data =
dataAna,fixed=a0+b0+a1+T+a0a~1,random=pdDiag(a0~1),
start=c(a0=a0init,b0=b0init,a1=a1init,T=Tinit,a0a=a0ainit),na.action=na.omit)

  these worked for me.



From Mohand-Larbi.Feddag at univ-nantes.fr  Tue Mar  6 17:17:33 2012
From: Mohand-Larbi.Feddag at univ-nantes.fr (Feddag Mohand-Larbi)
Date: Tue, 06 Mar 2012 17:17:33 +0100
Subject: [R-sig-ME] Question on the glmer function of the lme4  R package
Message-ID: <4F56389D.9060905@univ-nantes.fr>

Dear all,

Could you please help me in the estimation of the different parameters of the
Bradley-Terry model with random effects by the glmer function of the lme4 R package.

The model, the marginal likelihood and the real data and the main question are described in the attached file.

Best regards


 Dr Feddag



-------------- next part --------------
A non-text attachment was scrubbed...
Name: Feddag_glmer_BT.pdf
Type: application/pdf
Size: 50353 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120306/abac9b61/attachment-0002.pdf>

From annebj at gmail.com  Wed Mar  7 02:30:48 2012
From: annebj at gmail.com (Anne Bjorkman)
Date: Tue, 6 Mar 2012 17:30:48 -0800
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB, and cloglog
Message-ID: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120306/c9f21cb7/attachment-0002.pl>

From Yanwei.Zhang at cna.com  Wed Mar  7 04:37:56 2012
From: Yanwei.Zhang at cna.com (Zhang,Yanwei)
Date: Tue, 6 Mar 2012 21:37:56 -0600
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB,
 and cloglog
In-Reply-To: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
References: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
Message-ID: <330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>

Hi, 

The cplm package may be a good place to look at for the first problem. It handles zero-inflated continuous data using the compound Poisson distribution, and the mixed-model version (cpglmm) is developed based on glmer. 

Regards, 
Wayne Zhang
 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Anne Bjorkman
Sent: Tuesday, March 06, 2012 7:31 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB, and cloglog

Dear Mixed Modelers,


I have a few questions about various aspects of a dataset I am working on,
and I was hoping to get some feedback from the experts.  I apologize for
not being able to provide my data, but if anyone is interested I would be
happy to share it off-line.


My overall question is about changes in crop species abundances and
presence/absence over a 40 year period in 154 countries in the world, with
the measurements occurring at 10 year intervals (so, 1967, 1977, 1987,
1997, and 2007).  I would like to analyze these data in terms of both
abundance AND presence/absence, as they answer slightly different questions
(the first about abundance, the second about spread/distribution).  A
subset of my data look like this:


            Country             Item_general Total    Percent_of_Total Year
pres.abs

28465 Albania                Apples  6.45       0.002903365 1967        1

28466 Albania   Bananas_and_plantains  0.00       0.000000000 1967        0

28467 Albania                Barley 17.09      0.007692792 1967        1

28468 Albania                 Beans 41.80      0.018815610 1967        1

28469 Albania   Beverages_Alcoholic  5.60       0.002520751 1967        1

28470 Albania   Beverages_Fermented  0.00       0.000000000 1967        0


The abundance metric ("Total") here is number of Kcalories consumed of that
crop in that country in that year.  I have already looked at multivariate
changes in composition, but now I want to know about the change that occurs
for each crop species (i.e., which crop species have increased or decreased
the most over the past 40 years?).  My goal is to model each crop species
separately and extract slope parameters and standard errors for the slopes,
which would then tell me about the magnitude and direction of change for
each crop.  However, there are three complications:


1) The data for most crops are zero-inflated.  The zero-inflation is not
equal throughout the years, because overall countries have been increasing
in the number of crops they use, so there are more 0's in 1967 than in 2007
for a given crop.  This is true of most crops, but there are some that have
been decreasing.


2) I have repeated measurements on individual countries over the 40 year (5
sampling times) period. Thus I have been trying to account for this by
using "Country" as a random effect in a mixed model.


3) The data for each crop are not distributed in the same way.  Some crops
(such as corn) approach a nearly-normal distribution, while other crops
(e.g., Tea) are extremely zero-inflated.


I have attempted to use glmmADMB to model these data, as I understand this
is one of the few ways you can have random effects and account for
zero-inflation, using a negative binomial distribution and
zeroInflation=TRUE.


admb.model<-glmmadmb(Total_Rnd~I(Year-1967),random=~1|Country,family=
"nbinom",zeroInflation=TRUE,data=mydata)


where Total_Rnd is the "Total" column (total abundance) rounded to the
nearest integer using "ceiling".  This usually works on a subset of the
data that includes only one crop species, but if I try to model the entire
dataset (all crops together) I get the error:


Error in glmmadmb(Rel.Total.Rnd ~ I(Year - 1967), random = ~1 | Country,  :

  The function maximizer failed (couldn't find STD file)

In addition: Warning message:

running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status
1

Need to increase the maximum number of separable calls allowed to at least
20001

Current value is 20000

Use the -ndi N command line option


The output from just one crop species (Peas in this case) looks like this:


Call:

glmmadmb(formula = Total_Rnd ~ I(Year - 1967), data = subset(kcal.sub.test,

    Item_general == "Pulses_Other"), family = "nbinom", random = ~1 |

    Country, zeroInflation = TRUE)



Coefficients:

               Estimate Std. Error z value Pr(>|z|)

(Intercept)     2.64530    0.13035   20.29   <2e-16 ***

I(Year - 1967) -0.00107    0.00136   -0.78     0.43

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Number of observations: total=745, Country=154

Random effect variance(s):

$Country

            (Intercept)

(Intercept)      2.3298


Negative binomial dispersion parameter: 5.8899 (std. err.: 0.48002)

Zero-inflation: 0.013045  (std. err.:  0.0050869 )


Log-likelihood: -2788


This seems to match up somewhat with the raw data:


> mean(kcal.sub.test$Total_Rnd[kcal.sub.test$Item_general=="Pulses_Other" &
kcal.sub.test$Year==1967])

[1] 31.81208

> mean(kcal.sub.test$Total_Rnd[kcal.sub.test$Item_general=="Pulses_Other" &
kcal.sub.test$Year==2007])

[1] 29.69799


(so there has been a decrease in mean abundance from 1967 to 2007)


In addition, when I plot fitted values vs. residuals for a given crop to
try to check the assumptions for these models, they do not look good (a
very serious fanning-out from left to right):


admb.model.fit<-fitted(admb.model)

admb.model.res<-resid(admb.model)

plot(admb.model.fit,admb.model.res)


I have read on the mixed-models help list and elsewhere that plotting the
fitted v. residual values is not as straightforward with mixed effects
models, so I'm not entirely sure this is the right code to use, or what is
a better way to check how well this model fits (other than comparing AIC
values of a bunch of different models with the same data).


Of course, as I mentioned above, the data for each crop are distributed
differently, and I would be enormously appreciative if someone could
comment on whether I could use different models (in other words, some of
them with zeroInflation=TRUE and some with just a normal family="nbinom"
without zero inflation) for the different crops and still compare their
slopes.  Is my priority to find the best model for each crop, or is it to
use the same model for each crop so that the slopes are directly
comparable?  I have the same question about transforming the data.  Some of
the crops (not the zero-inflated ones, of course) would be better fit by
transforming to a square root of abundance, but I'm unsure whether I could
then compare the slope parameters with non-square-root-transformed crops. I
remember reading somewhere (but can't remember where) that
back-transforming the parameters is not a simple matter with mixed models,
thus making differently-transformed slope values comparable to each other
might not be possible.


To make matters more complicated, I would really like to model this as *
relative* abundance (or, "Percent of Total") to account for the fact that
people have been eating more over the years (total Kcalories has increased
over time). I would still be dealing with zero-inflation here, and my
understanding is that I could still use the same model described above,
since negative binomial and poisson distributions are for counts, and
proportions can be modeled like counts, even though they have an upper
limit?


The second part of the data, the presence-absence data, are a bit more
straightforward.  I transformed the data to presence-absence to try to get
away from the zero-inflation issue, and have been performing logistic
regression using lmer:


pres.abs.mod<-lmer(pres.abs~I(Year-1967)+(1|Country),data=mydata,family=
binomial)


For one crop, Peas, the output looks like this:


Generalized linear mixed model fit by the Laplace approximation

Formula: pres.abs ~ I(Year - 1967) + (1 | Country)

   Data: subset(pres.abs.kcal, Item_general == "Pulses_Other")

   AIC   BIC logLik deviance

 255.2 269.1 -124.6    249.2

Random effects:

 Groups  Name        Variance Std.Dev.

 Country (Intercept) 60.785   7.7965

Number of obs: 760, groups: Country, 152


Fixed effects:

               Estimate Std. Error z value Pr(>|z|)

(Intercept)     7.64468    1.47113   5.196 2.03e-07 ***

I(Year - 1967)  0.06714    0.01747   3.843 0.000122 ***

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Correlation of Fixed Effects:

            (Intr)

I(Yer-1967) -0.196


When I try to transform the Intercept term using plogis(7.64468) I get a
value of 0.9995216 (which, if I understand correctly, is like the expected
proportion of countries that have that crop) which I know from the data is
much too high.


My data do NOT have equal numbers of 1's and 0's, so if I try
family=binomial(link="cloglog") I get a much more reasonable estimate:


Generalized linear mixed model fit by the Laplace approximation

Formula: pres.abs ~ I(Year - 1967) + (1 | Country)

   Data: subset(pres.abs.kcal, Item_general == "Pulses_Other")

   AIC   BIC logLik deviance

 229.8 243.7 -111.9    223.8

Random effects:

 Groups  Name        Variance Std.Dev.

 Country (Intercept) 10.482   3.2376

Number of obs: 760, groups: Country, 152


Fixed effects:

               Estimate Std. Error z value Pr(>|z|)

(Intercept)    2.458405   0.696478    3.53 0.000416 ***

I(Year - 1967) 0.028910   0.009901    2.92 0.003503 **

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Correlation of Fixed Effects:

            (Intr)

I(Yer-1967) -0.292


which matches up almost perfectly with the mean of the raw data (which is
what I think the Intercept term estimates...):


> plogis(2.458405)

[1] 0.9211739


> mean(pres.abs.kcal$pres.abs[pres.abs.kcal$Item_general=="Pulses_Other"])

[1] 0.9276316



the problem is, I get an error that says


Warning message:

In mer_finalize(ans) : false convergence (8)


Can I still use the output of the link="cloglog" model, since it seems to
fit my model better (incidentally, the AIC is lower and the plot of fitted
v. residuals looks more even - even though of course for logistic models
the plots of fitted v. residuals aren't exactly straightforward to
interpret!).  Or can someone advise me as to what I am doing wrong to get
this error?


Finally, similarly to my question posed above, can I still compare the
slope parameters from my logistic regression models if I use link="logit"
for some and link="cloglog" for others, depending on which one provides a
better model fit, or should I use the same model for all crop species, even
if some are fit better than others.


I sincerely apologize for the novel-like length of this email, I have been
battling these questions for over a month now, searching R-list archives
and reading every (layman's) book I can get my hands on, and I've gotten to
the point now where, for every new thing I learn, I forget something I read
yesterday.


Enormous thanks in advance to anyone who feels willing to tackle my
statistical novel!


Best,

Anne

	[[alternative HTML version deleted]]


NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.



From s.blomberg1 at uq.edu.au  Wed Mar  7 05:42:35 2012
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 07 Mar 2012 14:42:35 +1000
Subject: [R-sig-ME] [R-sig-phylo] possible issue when incorporating a
 phylogenetic correlation structure (corPagel) in a linear mixed effect
 model (lme)
In-Reply-To: <4F4E3A7B.2050808@ebd.csic.es>
References: <4F4E3A7B.2050808@ebd.csic.es>
Message-ID: <4F56E73B.7090202@uq.edu.au>

Hi,

I'm not sure why this is occurring (and I've cc'ed the r-sig-me list as 
they might know more). It appears to me that there is some problem with 
the parameterisation of the random effects, and how that interacts with 
the correlation structure. The usual random=~1|date parameterisation 
uses a log-Cholesky factorisation, which is different to the pdIdent 
parameterisation, but as you say in this case should give the same 
answers. It looks like there may be something going on deep in the lme 
internals. Maybe someone on r-sig-me can help.

Sorry I can't be of more help. It's an interesting problem and I would 
like to see it resolved too.

Best,

Simon.

On 01/03/12 00:47, Rudolf Philippe Rohr wrote:
> Hello.
>
> I'm writing about a possible issue when incorporating a phylogenetic 
> correlation structure (corPagel) in a linear mixed effect model (lme).
>
> There are two techniques for incorporating a random effect in a linear 
> model:
>
> t1 (it is the traditional way): m1 <- lme( y ~ x, random = ~1|date)
>
> t2: u = gl(1,1,length(y))
> m2 <- lme(y ~ x, random = list(u = pdIdent(form=~factor(date)-1)))
>
> (http://www.mail-archive.com/r-help at stat.math.ethz.ch/msg11749.html)
>
> > str(d)
> 'data.frame': 446 obs. of 3 variables:
> $ y : num 2.197 0.693 0.693 0 0.693 ...
> $ x : Factor w/ 2 levels "N","Y": 2 1 1 1 1 2 2 2 2 2 ...
> $ date: Factor w/ 7 levels "12","16","21",..: 5 6 7 4 7 6 2 7 3 6 ...
>
> These two techniques have to give the same output, and it is exactly 
> what happens (same parameter estimations, same log-like, same 
> p-values, same values for the random factor, ?)
>
> > summary(m1)
> Linear mixed-effects model fit by REML
> Data: d
> AIC BIC logLik
> 1366.617 1383 -679.3083
>
> Random effects:
> Formula: ~1 | date
> (Intercept) Residual
> StdDev: 0.4283086 1.086683
>
> Fixed effects: y ~ x
> Value Std.Error DF t-value p-value
> (Intercept) 1.4430143 0.1856287 438 7.773658 0.0000
> xY 0.0700834 0.1119626 438 0.625953 0.5317
> Correlation:
> (Intr)
> xY -0.397
>
> > summary(m2)
> Linear mixed-effects model fit by REML
> Data: d
> AIC BIC logLik
> 1366.617 1383 -679.3083
>
> Random effects:
> Formula: ~factor(date) - 1 | u
> Structure: Multiple of an Identity
> factor(date)12 factor(date)16 factor(date)21 factor(date)26 
> factor(date)30 factor(date)35 factor(date)38
> StdDev: 0.4283086 0.4283086 0.4283086 0.4283086 0.4283086 0.4283086 
> 0.4283086
> Residual
> StdDev: 1.086683
>
> Fixed effects: y ~ x
> Value Std.Error DF t-value p-value
> (Intercept) 1.4430143 0.1856287 444 7.773658 0.0000
> xY 0.0700834 0.1119626 444 0.625953 0.5317
> Correlation:
> (Intr)
> xY -0.397
>
>
> Things get strange when incorporating a phylogenetic correlation 
> structure with corPagel (and also with corGrafen):
>
> t1: m3 <- lme( y ~ x, random = ~1|date, correlation = 
> corPagel(0.5,tree,fixed=FALSE))
>
> t2: u = gl(1,1,length(y))
> m4 <- lme(y ~ x, random = list(u = pdIdent(form=~factor(date)-1)), 
> correlation = corPagel(0.5,tree,fixed=FALSE)))
>
> Again, these two methods should give the same output, however here:
>
> t1 always gives the following error message:
>
> Error in corFactor.corStruct(object) :
> NA/NaN/Inf in foreign function call (arg 1)
>
> t2: the optimization process converges, and gives reasonable output.
>
> > summary(m4)
> Linear mixed-effects model fit by REML
> Data: d
> AIC BIC logLik
> 1350.275 1370.754 -670.1376
>
> Random effects:
> Formula: ~factor(date) - 1 | u
> Structure: Multiple of an Identity
> factor(date)12 factor(date)16 factor(date)21 factor(date)26 
> factor(date)30 factor(date)35 factor(date)38
> StdDev: 0.3966233 0.3966233 0.3966233 0.3966233 0.3966233 0.3966233 
> 0.3966233
> Residual
> StdDev: 1.141081
>
> Correlation Structure: corPagel
> Formula: ~1 | u
> Parameter estimate(s):
> lambda
> 0.2846964
> Fixed effects: y ~ x
> Value Std.Error DF t-value p-value
> (Intercept) 1.1950145 0.3493305 444 3.420871 0.0007
> xY -0.0312983 0.1139128 444 -0.274757 0.7836
> Correlation:
> (Intr)
> xY -0.18
>
> First question: why is it that t1 does not work, while t2 does?
>
>
> To go a step forward with this problem, we can set the lambda value in 
> t1 with the value obtained from t2.
>
> t1bis: m3bis <-lme( y ~ x, random = ~1|date, correlation = 
> corPagel(0.2846964,tree,fixed=TRUE))
>
> This time, t1bis converges. However the output is completely different 
> from t2.
>
> > summary(m3bis)
> Linear mixed-effects model fit by REML
> Data: d
> AIC BIC logLik
> 14907.8 14924.19 -7449.902
>
> Random effects:
> Formula: ~1 | date
> (Intercept) Residual
> StdDev: 809763.6 4632624
>
> Correlation Structure: corPagel
> Formula: ~1 | date
> Parameter estimate(s):
> lambda
> 0.2846964
> Fixed effects: y ~ x
> Value Std.Error DF t-value p-value
> (Intercept) -329242.7 324363.4 438 -1.01504 0.3106
> xY 3.7 0.0 438 127.43249 0.0000
> Correlation:
> (Intr)
> xY 0.014
>
> Second question: how is that possible? The two outputs should be the 
> same.
>
>
> To try to understand what is going on, we can compute the profile 
> log-likelihood curve, as a function of lambda, for both techniques.
>
> lambda <- seq(0,1,0.01)
>
> loglike.t1 <- rep(NA,length(lambda))
> loglike.t2 <- rep(NA,length(lambda))
>
> for (i in 1:length(lambda)){
>
> m1 <- lme(y ~ x, random = ~1|date, correlation = 
> corPagel(lambda[i],tree,fixed=TRUE))
> loglike.t1[i] <- m1$logLik
>
> u = gl(1,1,length(d$y))
> m2 <- lme(y ~ x,random = list(u = pdIdent(form=~factor(date)-1)), 
> correlation = corPagel(lambda[i],tree,fixed=TRUE))
> loglike.t2[i] <- m2$logLik
>
> }
>
> The two curves are completely different:
>
> With t2, we obtain a reasonable curve, with a maximum at the 
> previously estimated lambda value.
>
> With t1, the curve looks really strange: there is a discontinuity at 
> the origin, i.e., for lambda=0 the log-like value is higher than for 
> lambda>0, and for lambda>0 the log-like is only increasing with lambda.
>
> Thus a third question: why are these two profile log-likelihood curves 
> different?
>
> The final question is: in which technique can we believe?
>
> I?m using the version 2.14.1 of R, 3.1-96 of nlme, and 3.0-1 of ape.
>
> Best,
> Rudolf
>

-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat, AStat.
Lecturer and Consultant Statistician
School of Biological Sciences
The University of Queensland
St. Lucia Queensland 4072
Australia
T: +61 7 3365 2506
email: S.Blomberg1_at_uq.edu.au
http://www.uq.edu.au/~uqsblomb/

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

Statistics is the grammar of science - Karl Pearson.



From kedwards at ucdavis.edu  Wed Mar  7 08:38:02 2012
From: kedwards at ucdavis.edu (Kyle Edwards)
Date: Tue, 6 Mar 2012 23:38:02 -0800
Subject: [R-sig-ME] MCMCglmm: multivariate response with phylogenetic
	structure
Message-ID: <E9A2C3E8-A632-4E53-BB2A-26C9DCA34C5E@ucdavis.edu>

Hello,

I am looking for some advice on how to specify an MCMCglmm model with a multivariate response, while accounting for potential phylogenetic structure in the residuals. The data consist of 4 traits (tr1 - tr4), with each trait measured a maximum of one time for each of 27 species (there is some missing data, but that does not appear to be problematic for these analyses). To begin with, following chapter 5 in the course notes, I fit the following model without phylogenetic information:

mod = MCMCglmm(cbind(tr1, tr2, tr3, tr4) ~ trait-1, rcov = ~us(trait):units, data = my.data, family = rep("gaussian", 4))

This model converges quickly and gives sensible results similar to those I have found using other approaches. 

I would next like to incorporate a phylogenetic tree for these species, to test whether this alters the estimated trait correlations. If I understand correctly, this is implemented in MCMCglmm using a combination of the 'random' and 'pedigree' arguments, or a combination of the 'random' and 'ginverse' arguments. So I would expect to include these terms in the model: 

random =~ us(trait):species, pedigree = my.phylogeny,

where the names of the species are the tips of the phylogeny. 

However, I am confused about how to model the 'rcov' argument, once this random effect term is introduced. Because each species is only observed once, there is no residual variation within species, and so it seems this random effect term should make the rcov term in my original model redundant. How should one specify the residual variation in this case? If I fit a model with "rcov = ~us(trait):units, random =~ us(trait):species", it is much slower to converge and the posterior distributions of the trait correlations at both levels are much wider than in the original model. This occurs with or without the pedigree argument included, and it makes sense that I shouldn't be able to separately estimate all these parameters. 

Thanks for any insight into this issue,

Kyle

Kyle Edwards
Postdoctoral Research Associate
Kellogg Biological Station
Michigan State University

edwar466 at msu.edu



From j.hadfield at ed.ac.uk  Wed Mar  7 10:11:14 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 07 Mar 2012 09:11:14 +0000
Subject: [R-sig-ME] MCMCglmm: multivariate response with phylogenetic
 structure
In-Reply-To: <E9A2C3E8-A632-4E53-BB2A-26C9DCA34C5E@ucdavis.edu>
References: <E9A2C3E8-A632-4E53-BB2A-26C9DCA34C5E@ucdavis.edu>
Message-ID: <20120307091114.153469jaj610j280@www.staffmail.ed.ac.uk>

Hi,

If you use the pedigree option you need to make sure that the column  
of species names is called "animal". The pedigree option has been  
superseded by the ginverse argument which allows more flexibility. To  
use this you can retain species in your random formula and then pass  
ginverse(species=Ainv) to MCMCglmm where Ainv can be obtained using  
inverseA(tree)$Ainv.

If you have just modelled species effects as uncorrelated random  
effects then they are equivalent to the residuals and so the two  
covariance matrices cannot be separately estimated as you state. This  
is not the case with a phylogenetic effect because the correlation  
structure allows the effects to be separated. However, separating them  
can still be difficult so you should expect wider credible intervals.  
With 27 species and two 4x4 covariance matrices I think the precision  
of the estimates will be very low and the prior will have a large  
effect.

Cheers,

Jarrod





Quoting Kyle Edwards <kedwards at ucdavis.edu> on Tue, 6 Mar 2012 23:38:02 -0800:

> Hello,
>
> I am looking for some advice on how to specify an MCMCglmm model  
> with a multivariate response, while accounting for potential  
> phylogenetic structure in the residuals. The data consist of 4  
> traits (tr1 - tr4), with each trait measured a maximum of one time  
> for each of 27 species (there is some missing data, but that does  
> not appear to be problematic for these analyses). To begin with,  
> following chapter 5 in the course notes, I fit the following model  
> without phylogenetic information:
>
> mod = MCMCglmm(cbind(tr1, tr2, tr3, tr4) ~ trait-1, rcov =  
> ~us(trait):units, data = my.data, family = rep("gaussian", 4))
>
> This model converges quickly and gives sensible results similar to  
> those I have found using other approaches.
>
> I would next like to incorporate a phylogenetic tree for these  
> species, to test whether this alters the estimated trait  
> correlations. If I understand correctly, this is implemented in  
> MCMCglmm using a combination of the 'random' and 'pedigree'  
> arguments, or a combination of the 'random' and 'ginverse'  
> arguments. So I would expect to include these terms in the model:
>
> random =~ us(trait):species, pedigree = my.phylogeny,
>
> where the names of the species are the tips of the phylogeny.
>
> However, I am confused about how to model the 'rcov' argument, once  
> this random effect term is introduced. Because each species is only  
> observed once, there is no residual variation within species, and so  
> it seems this random effect term should make the rcov term in my  
> original model redundant. How should one specify the residual  
> variation in this case? If I fit a model with "rcov =  
> ~us(trait):units, random =~ us(trait):species", it is much slower to  
> converge and the posterior distributions of the trait correlations  
> at both levels are much wider than in the original model. This  
> occurs with or without the pedigree argument included, and it makes  
> sense that I shouldn't be able to separately estimate all these  
> parameters.
>
> Thanks for any insight into this issue,
>
> Kyle
>
> Kyle Edwards
> Postdoctoral Research Associate
> Kellogg Biological Station
> Michigan State University
>
> edwar466 at msu.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Thierry.ONKELINX at inbo.be  Wed Mar  7 10:36:25 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 7 Mar 2012 09:36:25 +0000
Subject: [R-sig-ME] Question on the glmer function of the lme4 R package
In-Reply-To: <4F56389D.9060905@univ-nantes.fr>
References: <4F56389D.9060905@univ-nantes.fr>
Message-ID: <AA818EAD2576BC488B4F623941DA74275734D895@inbomail.inbo.be>

We need more information to connect your data to the model. What is the interpretation of the subscript i and j and U in connection to your data? How does your dataset look like?

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Feddag Mohand-Larbi
Verzonden: dinsdag 6 maart 2012 17:18
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Question on the glmer function of the lme4 R package

Dear all,

Could you please help me in the estimation of the different parameters of the Bradley-Terry model with random effects by the glmer function of the lme4 R package.

The model, the marginal likelihood and the real data and the main question are described in the attached file.

Best regards


 Dr Feddag



From Thierry.ONKELINX at inbo.be  Wed Mar  7 12:13:37 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 7 Mar 2012 11:13:37 +0000
Subject: [R-sig-ME] Quadratic with Random Offset in One Dimension
In-Reply-To: <CA+b8XEKEaQT6DNMNBtjKTVxs3GfQTcbUN7e8O+MXKmLXWnjHow@mail.gmail.com>
References: <CA+b8XEKEaQT6DNMNBtjKTVxs3GfQTcbUN7e8O+MXKmLXWnjHow@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275734DC96@inbomail.inbo.be>

Dear Christopher,

I think this can be done with a non-linear mixed model (nlmer in lme4).

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Christopher D. Long
Verzonden: zaterdag 3 maart 2012 11:42
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Quadratic with Random Offset in One Dimension

Hi,

I'm looking to fit a family of quadratics in (x,y) with a random factor offset in one variable. The model would look like this:

outcome ~ x^2 + x*(y+F) + (y+F)^2 + 1

with F a random factor.

If this were linear in x,y it'd be no problem:

outcome ~ x + y + 1|F.

Is there a way to get either lme4 to estimate a model like this?
If not, what's my best route?
--
Christopher D. Long, San Diego Padres, 100 Park Blvd, San Diego CA

"Tick, clong, tick, clong, tick, clong, went the night." - Thurber

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From amelie.pinet at gmail.com  Wed Mar  7 14:08:33 2012
From: amelie.pinet at gmail.com (amelie pinet)
Date: Wed, 7 Mar 2012 14:08:33 +0100
Subject: [R-sig-ME] error in nlme()
In-Reply-To: <loom.20120306T180030-171@post.gmane.org>
References: <CAKNZCKFxCmH=MgZ2LrCT_VXgC2cR7jg3P3W9bV+QCnfnyq-wQA@mail.gmail.com>
	<loom.20120302T163732-975@post.gmane.org>
	<CAKNZCKFGHNNOwEzuAg2nFwDLFE_CPyjF3NJv8WUEvyVh7_055Q@mail.gmail.com>
	<loom.20120306T180030-171@post.gmane.org>
Message-ID: <CAKNZCKG6LikjjjunjPf0kTjPmHNcp8=8ZGHXRU+JrA6ZtBcqOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120307/119cffc0/attachment-0002.pl>

From Rachel.Gibson at bristol.ac.uk  Wed Mar  7 15:47:24 2012
From: Rachel.Gibson at bristol.ac.uk (RH Gibson, School Biological Sciences)
Date: Wed, 07 Mar 2012 14:47:24 +0000
Subject: [R-sig-ME] model comparison in glmmADMB
Message-ID: <629F673052B60E61A668B04E@bio-bzjxm-0501.bio.bris.ac.uk>

I am trying to compare two models to see whether the random effect is 
significant, using the anova command I get the following output:

> anova(m7,m8)
Analysis of Variance Table

Model 1: xx ~ nsn * Insect.type + ara * Insect.type + 
offset(logTotal.grains)
Model 2: xx ~ nsn * Insect.type + ara * Insect.type + 
offset(logTotal.grains)
  NoPar  LogLik Df -2logQ P.value
1    12 -2427.4
2    11 -2427.9 -1  -0.96
Warning message:
In pchisq(q, df, lower.tail, log.p) : NaNs produced

Why might this be happening? Can I still use the log likelihood ratio as a 
comparison method? And more generally is this an appropriate test of the 
random effect?

The full models are as follows:

> 
m7<-glmmadmb(x~nsn*Insect.type+ara*Insect.type+offset(logTotal.grains)+(1|Site),data=data1, 
zeroInflation=TRUE, family="nbinom")
>m8<-glmmadmb(x~nsn*Insect.type+ara*Insect.type+offset(logTotal.grains),data=data1, 
zeroInflation=TRUE, family="nbinom")



----------------------
RH Gibson, School Biological Sciences
Rachel.Gibson at bristol.ac.uk



From bbolker at gmail.com  Wed Mar  7 16:14:35 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 07 Mar 2012 10:14:35 -0500
Subject: [R-sig-ME] error message using glmmadmb
In-Reply-To: <5960F8DE7D578930986AAAAC@bio-bzjxm-0501.bio.bris.ac.uk>
References: <52028.82.32.40.117.1330523907.squirrel@webmail.bris.ac.uk>
	<loom.20120229T155325-260@post.gmane.org>
	<52979.82.32.40.117.1330528354.squirrel@webmail.bris.ac.uk>
	<4F4E714F.3020001@gmail.com>
	<49318.82.32.40.117.1330543940.squirrel@webmail.bris.ac.uk>
	<4F4E8B52.3040804@gmail.com>
	<087A138439005FEBA5F122DB@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4F75B3.2000403@gmail.com>
	<CFADCBF0D3CE294827F7480F@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F4FA013.4090804@gmail.com>
	<loom.20120301T190854-931@post.gmane.org>
	<FDC0E49E34701FC696C2B53A@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54BEB4.7060500@gmail.com>
	<E3753E12CF4337B1F5982357@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54CC24.4000901@gmail.com>
	<D1D8247B6F782A74CE134F7D@bio-bzjxm-0501.bio.bris.ac.uk>
	<4F54DDD7.6060400@gmail.com>
	<5960F8DE7D578930986AAAAC@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <4F577B5B.2070401@gmail.com>


  After looking at these data a bit I think (this may sound funny coming
from me) that all the fancy mixed-model stuff is overkill in this
situation.  The key is that you have a *nested* design -- your predictor
variables nsn and ara only vary across your 8 sites, not within them.
That means that in a classical analysis of variance you would get the
same answer if you just aggregated the data by site and ran a
fixed-effect model on the site averages, which is what I would recommend
here.  Aggregating the data in this way also takes care of a lot of the
distributional complexity; even if your individual samples have a funny
distribution, their averages (you have at least 8 samples per insect
type per site, and on average about 30) will be approximately normal
unless something really weird is happening.

Murtaugh, Paul A. 2007. ?Simplicity and Complexity in Ecological Data
Analysis.? Ecology 88 (1): 56?62.
http://www.esajournals.org/doi/abs/10.1890/0012-9658%282007%2988%5B56%3ASACIED%5D2.0.CO%3B2.

  It's a secondary question (in my mind) to try to figure out why
glmmADMB isn't converging ...

  PS -- since your proportions sometimes approach 1, the
Poisson/negative binomial + offset approach won't work very well -- it
only works when counts are a small fraction of the total possible.

==========
data1 <- read.table("beepollenq.txt",header=TRUE)

## calculate proportions
data1 <- transform(data1,x=round(x),prop=x/Total.grains)
library(ggplot2)
library(mgcv)

g1 <- ggplot(data1,aes(x=ara,y=prop,colour=Insect.type))+
  geom_point(aes(size=Total.grains),alpha=0.8)+theme_bw()

## all together
g1 + geom_smooth(method="gam",family="binomial",aes(weight=Total.grains))

## separately:  one value of 'ara' per site
g1 +  facet_wrap(~Site)

## the same, but putting nsn on the x axis
g2 <- ggplot(data1,aes(x=nsn,y=prop,colour=Insect.type))+
  geom_point(aes(size=Total.grains),alpha=0.8)+theme_bw()
g2 + geom_smooth(method="gam",family="binomial",aes(weight=Total.grains))
g2 +  facet_wrap(~Site) ## one value of 'nsn' per site

## create aggregated version of data -- mean proportion
library(reshape)
m1 <- melt(subset(data1,select=c(Site,Insect.type,prop,nsn,ara)),
     id.var=c("Site","Insect.type"))
m2 <- cast(m1,Site+Insect.type~...,fun.agg=mean)
m2 <- m2[order(m2$Insect.type),]

ggplot(m2,aes(x=nsn,y=ara,size=prop))+
  geom_point(alpha=0.5)+facet_grid(.~Insect.type)+
  theme_bw()

ggplot(m2,aes(x=nsn,colour=ara,y=prop))+
  geom_point(alpha=0.5)+facet_wrap(~Insect.type,scale="free")+
  theme_bw()+geom_smooth(method="lm")

ggplot(m2,aes(x=ara,colour=nsn,y=prop))+
  geom_point(alpha=0.5)+facet_wrap(~Insect.type,scale="free")+
  theme_bw()+geom_smooth(method="lm")

On 12-03-07 09:23 AM, RH Gibson, School Biological Sciences wrote:
> Hi Ben,
> 
> I have attached the data.
> variable x is the number of strawberry grains out of Total.grains.
> The code is:
> 
> logTotal.grains<-log(Total.grains)
> 
> m7<-glmmadmb(x~nsn*Insect.type+ara*Insect.type+offset(logTotal.grains)+(1|Site),data=data1,
> zeroInflation=TRUE, family="nbinom")
> 
> summary(m7)
> 
> 
> Thanks,
> 
> Rachel.
> 
> 
> 
> 
> --On 05 March 2012 10:37 -0500 Ben Bolker <bbolker at gmail.com> wrote:
> 
>> On 12-03-05 10:24 AM, RH Gibson, School Biological Sciences wrote:
>>> summary(data1) file attached.
>>>
>>> Hope this can shed some light on the problem.
>>>
>>> Rachel.
>>>
>>
>>   Can you send the data themselves?
>>   The summary is good for sanity-checking but to go farther I would need
>> to look at the actual data.  (And, the format of the summary got mangled
>> in transmission ...)
>>
>>>
>>> --On 05 March 2012 09:22 -0500 Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>> On 12-03-05 08:52 AM, RH Gibson, School Biological Sciences wrote:
>>>>>> That would make sense as I am able to fit a zero-inflated negative
>>>>>> binomial model, but not just the binomial. I have tried poisson
>>>>>> too, but this gave me the same error message as trying to fit the
>>>>>> binomial.
>>>>>>
>>>>>> The y variable is a count, offset by a sample total. There is
>>>>>> overdispersion and a lot of zeros in the data. Does using the
>>>>>> zero-inflated negative binomial make sense here?
>>>>>>
>>>>>> Thanks.
>>>
>>>   It very rarely makes sense to use the binomial and the negative
>>> binomial to fit the same set of data; the binomial has a fixed
>>> (typically known) upper limit, the Poisson and NB do not.  (The
>>> exception to this is that people will sometimes use Poisson/NB models
>>> when the upper limit is known but the observed frequency is very low
>>> -- this is especially common e.g. in epidemiology.)  ZINB, or plain
>>> old NB, probably make the most sense.
>>>
>>>   It's more interesting that you get an error message with the
>>> Poisson, which may indicate some glmmADMB instability.  What are the
>>> results of summary(data1)?  How many sites do you have?
>>>
>>>   Ben Bolker
>>>>>>
>>>>>>
>>>>>> --On 05 March 2012 08:25 -0500 Ben Bolker <bbolker at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> On 12-03-05 06:00 AM, RH Gibson, School Biological Sciences
>>>>>>> wrote:
>>>>>>>> Updated to latest version and now having new problems:
>>>>>>>>
>>>>>>>> m3<-
>>>>>>>> glmmadmb(x~nsn*Insect.type+ara*Insect.type+rap*Insect.type+fsize+of
>>>>>>>> fse t(
>>>>>>>>
>>>>>>>>
>>> logTotal.grains)+(1|Site),data=data1, zeroInflation=TRUE,
>>>>>>>> family="binomial") Error in glmmadmb(x ~ nsn * Insect.type +
>>>>>>>> ara * Insect.type + rap * Insect.type +  : The function
>>>>>>>> maximizer failed (couldn't find STD file) In addition: Warning
>>>>>>>> message: running command 'C:\WINDOWS\system32\cmd.exe /c
>>>>>>>> "C:/Program
>>>>>>>> Files/R/R-2.14.2/library/glmmADMB/bin/windows32/glmmadmb.exe"
>>>>>>>> -maxfn 500 -maxph 5 -noinit -shess' had status 1
>>>>>>>>
>>>>>>>
>>>>>>> This now means that the optimization failed for some reason.
>>>>>>> There are many reasons this can happen, mostly having to do with
>>>>>>> too-sparse or unusual data.  Without knowing anything about your
>>>>>>> data, the one thing that pops out is you are using a binomial
>>>>>>> family with zeroInflation=TRUE.  If your response is a matrix of
>>>>>>> successes and failures, that's unusual but plausible; if your
>>>>>>> response is a single 0/1 vector, then it doesn't make sense to
>>>>>>> use zero-inflation.  (If your response is anything else it's odd
>>>>>>> too, although that probably would have been caught earlier.) Try
>>>>>>> working through the troubleshooting steps under ?admbControl
>>>>>>> (and running with verbose=TRUE to see exactly what AD Model
>>>>>>> Builder reports as the problem).
>>>>>>>
>>>>>>> Ben Bolker
>>>>>>>
>>>>>>>
>>>>>>>>
>>>>>>>> Can you help with this?
>>>>>>>>
>>>>>>>> Many thanks, Rachel.
>>>>>>>>
>>>>>>>> --On 01 March 2012 18:10 +0000 Ben Bolker <bbolker at gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>> Ben Bolker <bbolker at ...> writes:
>>>>>>>>>
>>>>>>>>> [snip]
>>>>>>>>>
>>>>>>>>>> If you do this:
>>>>>>>>>>
>>>>>>>>>> mydata <-
>>>>>>>>>> data.frame(spdiv,nsn,ara,rap,Insect.type,fsize,Site)
>>>>>>>>>> glmmadmb(spdiv~(nsn+ara+rap)*Insect.type+fsize+(1|Site),family="n
>>>>>>>>>> bin om
>>>>>>>>>>
>>>>>>>>>>
>>> ")
>>>>>>>>>>
>>>>>>>>>> it ought to work.  However, it *should* work the way you
>>>>>>>>>> specified -- I will work on fixing the bug.
>>>>>>>>>>
>>>>>>>>>> thanks Ben Bolker
>>>>>>>>>
>>>>>>>>> This should be fixed now (i.e. in glmmADMB 0.7.2.7). It's
>>>>>>>>> still a good idea to use the data= argument.
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> ---------------------- RH Gibson, School Biological Sciences
>>>>>>>> Rachel.Gibson at bristol.ac.uk
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ---------------------- RH Gibson, School Biological Sciences
>>>>>> Rachel.Gibson at bristol.ac.uk
>>>
>>>
>>>
>>>
>>> ----------------------
>>> RH Gibson, School Biological Sciences
>>> Rachel.Gibson at bristol.ac.uk
>>
> 
> 
> 
> ----------------------
> RH Gibson, School Biological Sciences
> Rachel.Gibson at bristol.ac.uk



From dadrivr at gmail.com  Wed Mar  7 16:15:24 2012
From: dadrivr at gmail.com (Isaac Petersen)
Date: Wed, 7 Mar 2012 10:15:24 -0500
Subject: [R-sig-ME] Comparing the effect size of parameters across
 non-nested models with different outcomes
Message-ID: <CAPBn5Xv8vfKXpj3AKekVc25EtQiyR-16djQdE3nTveSaT=RmMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120307/9f1ecf19/attachment-0002.pl>

From bbolker at gmail.com  Wed Mar  7 17:39:02 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2012 16:39:02 +0000 (UTC)
Subject: [R-sig-ME] model comparison in glmmADMB
References: <629F673052B60E61A668B04E@bio-bzjxm-0501.bio.bris.ac.uk>
Message-ID: <loom.20120307T170528-76@post.gmane.org>

RH Gibson, School Biological Sciences <Rachel.Gibson at ...> writes:

> 
> I am trying to compare two models to see whether the random effect is 
> significant, using the anova command I get the following output:
> 
> > anova(m7,m8)
> Analysis of Variance Table
> 
 [snip]

>   NoPar  LogLik Df -2logQ P.value
> 1    12 -2427.4
> 2    11 -2427.9 -1  -0.96
> Warning message:
> In pchisq(q, df, lower.tail, log.p) : NaNs produced
> 
> Why might this be happening? Can I still use the log likelihood ratio as a 
> comparison method? And more generally is this an appropriate test of the 
> random effect?

  anova.glmmadmb is not smart enough to put the terms in order of
increasing complexity, and it expects you to do so.  This will be
clarified/fixed in the next version.

  More generally, LRTs of random effects are OK but not great; they are
known to be conservative (see http://glmm.wikidot.com/faq both for ways
to test random effects and for questions as to why you would be wanting
to test the significance of a random effect in the first place).



From bbolker at gmail.com  Wed Mar  7 17:41:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2012 16:41:44 +0000 (UTC)
Subject: [R-sig-ME] Comparing the effect size of parameters across
	non-nested models with different outcomes
References: <CAPBn5Xv8vfKXpj3AKekVc25EtQiyR-16djQdE3nTveSaT=RmMA@mail.gmail.com>
Message-ID: <loom.20120307T174034-34@post.gmane.org>

Isaac Petersen <dadrivr at ...> writes:

> 
> Hi,
> 
> Is there a way to compare the effect size of parameters across non-nested
> models with different outcomes?  I would like to test statistically whether
> one parameter is larger than another.  I'm currently using nlme, so that
> would be preferable if possible.  Thanks guys!


 You could standardize both your predictors and your outcomes to all
have standard deviations of 1, then do a t-test between the effects ...



From biowahl at gmail.com  Wed Mar  7 21:20:32 2012
From: biowahl at gmail.com (Colin Wahl)
Date: Wed, 7 Mar 2012 12:20:32 -0800
Subject: [R-sig-ME] lmer/glmer standard error interpretation and
	visualization
Message-ID: <CACu_zZkMuCOHQ6kabDi9f19JkJ+rrH=rgig_PFOY8N4X4okFbA@mail.gmail.com>

Hello,
I am in the process of finalizing figures for my thesis on stream
invertebrate distributions among watershed and riparian types. See
below for additional information on the design. I'm having difficulty
including standard errors from the lmer modeling as error bars in the
figures. Here is the table I've created from the lmer output:
estimates of %EPT and St Error are back transformed from logits and
converted from fractions to percents. Estimates are also absolute (not
relative to the intercept).

 Watershed ? ? Effect ? ? ? ? ? ? ? ? ?Estimate ?St. Error? z score ?p value

 Forested  ? ? Intercept: F vs. 0 ? ?   28.23 ?    59.6 ? ? -2.346 ? ? 0.019*
 ? ? ? ? ? ? ?? ? ? Riparian: ?F vs. NF ? 16.017 ?   62.3 ? ? -1.436 ?   0.151
 Cultivated ? ?Watershed: C vs. F ? ?1.351 ?   65.3 ? ? -5.297 ? ?<0.000*
 ? ? ? ? ? ?  ? ? ? Riparian: ?F vs. NF ? ?1.555 ?    69.2 ? ? ?1.071 ? ?0.284
 Developed ? Watershed: D vs. F ? ?0.175 ?    66.8 ? ? -7.714 ?  <0.000*
 ? ? ? ? ? ? ?? ? ? Riparian: ?F vs. NF ? ?0.292 ?    70.9 ? ? ?1.391 ?   0.164
 Grassland ? ?Watershed: G vs. F ?  28.94 ?   66.6 ?     0.05 ?   ?0.960
 ? ? ? ? ? ? ?  ? ? Riparian: ?F vs. NF ? ? 1.967 ? ? 70.7 ? ? -2.595  ?? 0.009*

The st. errors are huge. I initially used standard error calculations
in excel for error bars (stdev(x)/sqrt(n(x))), which look very
reasonable, and are reflective of significant differences.

Does anyone have any advice to offer for visualizing these glmer
results? Should I use the huge model St. Errors? My inclination is
yes, because they are used to calculated significant differences, but
28 + or - 59.6 with a significant p value seems ridiculous.

Thank you,
Colin Wahl
M.S. Candidate
Dept. of Biology
Western Washington University



From bbolker at gmail.com  Wed Mar  7 23:59:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2012 22:59:51 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lmer/glmer_standard_error_interpretation_and?=
	=?utf-8?q?=09visualization?=
References: <CACu_zZkMuCOHQ6kabDi9f19JkJ+rrH=rgig_PFOY8N4X4okFbA@mail.gmail.com>
Message-ID: <loom.20120307T234946-200@post.gmane.org>

Colin Wahl <biowahl at ...> writes:

> I am in the process of finalizing figures for my thesis on stream
> invertebrate distributions among watershed and riparian types. See
> below for additional information on the design. I'm having difficulty
> including standard errors from the lmer modeling as error bars in the
> figures. Here is the table I've created from the lmer output:
> estimates of %EPT and St Error are back transformed from logits and
> converted from fractions to percents. Estimates are also absolute (not
> relative to the intercept).
> 

 [snip]
 
> The st. errors are huge. I initially used standard error calculations
> in excel for error bars (stdev(x)/sqrt(n(x))), which look very
> reasonable, and are reflective of significant differences.
> 
> Does anyone have any advice to offer for visualizing these glmer
> results? Should I use the huge model St. Errors? My inclination is
> yes, because they are used to calculated significant differences, but
> 28 + or - 59.6 with a significant p value seems ridiculous.

  How did you back-calculate the standard errors?  It simply doesn't
make sense to compute plogis([standard error]) to get the standard
error on the response scale; you can either use the delta method as
one of the variants of predict.glm() does [i.e. multiply the standard
error by the *derivative* of the link function], or calculate the
confidence intervals on the link scale (i.e. estimate plus/minus CI)
and back-transform them (they will not in general be symmetric).

  This is not an lmer issue, this is a general issue with generalized
linear models, or any other model that works on a transformed scale
and for which one wants to backtransform the parameters.



From bbolker at gmail.com  Thu Mar  8 00:07:26 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2012 23:07:26 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lmer/glmer_standard_error_interpretation_and?=
	=?utf-8?q?=09visualization?=
References: <CACu_zZkMuCOHQ6kabDi9f19JkJ+rrH=rgig_PFOY8N4X4okFbA@mail.gmail.com>
	<loom.20120307T234946-200@post.gmane.org>
Message-ID: <loom.20120308T000447-861@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Colin Wahl <biowahl at ...> writes:
> 
>   This is not an lmer issue, this is a general issue with generalized
> linear models, or any other model that works on a transformed scale
> and for which one wants to backtransform the parameters.

 PS  this is why epidemiologists spend so much time learning about
odds ratios and log-odds -- you can back-transform from logit effects
to odds-ratio effects, but once you get there there's just not any
perfect way to transform back to a probability scale in a way that
is completely general ... http://lesswrong.com/lw/8lr/logodds_or_logits/



From charla at uoguelph.ca  Thu Mar  8 05:49:37 2012
From: charla at uoguelph.ca (Charla Patterson)
Date: Wed, 7 Mar 2012 23:49:37 -0500 (EST)
Subject: [R-sig-ME] Mixed Effects Logistic Regression Model and finding
	p-values
In-Reply-To: <325606998.530471.1331179327904.JavaMail.root@simcoe.cs.uoguelph.ca>
Message-ID: <2134804838.532357.1331182177431.JavaMail.root@simcoe.cs.uoguelph.ca>

Hello List Members,

I am a masters student that is relatively new to R and am currently working on the analysis of my project. For my project, I collected data on individual birds every year (sex, migratory or resident) along with environmental measurements from their breeding grounds (average min. winter temperature, total winter precipitation, ect.). I am interested in finding out whether the decision to migrate in this population is affected by environmental cures.  

Here is a sample of my data from the original .csv file:

bnum	sex 	ystat 	year	wintering site	breeding site  direct.  minall  totprecall
39	1	1	1991.92	Burlington	Wye marsh	S	-4.5	98.75
39	1	1	1991.92	Burlington	Wye marsh	N	-4.5	98.75
75	0	1	1991.92	Aurora	        Wye marsh	        -4.5	98.75
78	1	0	1991.92	Wye Marsh	Wye Marsh		-4.5	98.75
79	0	0	1991.92	Wye Marsh	Wye Marsh		-4.5	98.75
80	1	0	1991.92	Wye Marsh	Wye Marsh		-4.5	98.75
961	0	1	1991.92	Burlington	Wye Marsh	S	-4.5	98.75
961	0	1	1991.92	Burlington	Wye Marsh	N	-4.5	98.75
74	1	0	1992.93	Wye marsh	Wye marsh		-3.9	125.65
75	0	0	1992.93	Wye marsh	Wye marsh		-3.9	125.65
78	1	0	1992.93	Wye Marsh	Wye Marsh		-3.9	125.65


Where bnum is the bird ID, sex (Female=1, male=0) and ystat is the decision to migrate (migrant=1, resident=0), minall is average minimum winter temperature for the year and totprecall is total winter precipitation for the year.

I wanted to use a mixed effects logistic regression model where ystat is the response (binary), the fixed effects would be sex, minall and totprecall  and the random effects would be bnum and year.

my proposed model and the corresponding results are:

> yr<- as.factor(year)
> mod3<- glmer(ystat~minall + totprecall+ (1 |yr)+(1 | bnum), data=birds,family=binomial(link='logit'))
> summary(mod3) 

Generalized linear mixed model fit by the Laplace approximation 
Formula: ystat ~ minall + totprecall + (1 | yr) + (1 | bnum) 
   Data: birds 
   AIC   BIC logLik deviance
 857.3 881.9 -423.6    847.3
Random effects:
 Groups Name        Variance Std.Dev.
 bnum   (Intercept) 20.0576  4.4786  
 yr     (Intercept)  2.2188  1.4896  
Number of obs: 1014, groups: bnum, 209; yr, 19

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)  
(Intercept) -1.423079   2.088999  -0.681   0.4957  
minall      -0.419361   0.212170  -1.976   0.0481 *
totprecall  -0.006249   0.022842  -0.274   0.7844  
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

Correlation of Fixed Effects:
           (Intr) minall
minall     -0.046       
totprecall -0.904  0.408


Although I think my model is okay, I was struggling with a couple things:

1. When I use year as a fixed effect in my model instead of as a random effect, the p-values for all other parameters are much lower. I don't understand why and it makes me apprehensive about the model and p-values I have. Are the p-values I reported here reliable?

2. I read that a good alternative is to use mcmcglmm to get p-values and HPDintervals, but I'm finding it tricky as well.

I tried to use mcmcsamp along with the pvals.fnc(mod3, nsim=10000) function, but it turns out that this doesn't work with lme4 package. I read that mcmcglmm is a good alternative, so I read the R notes but found that I can't get it to work. Here is my code and the associated warning messages:

m <- MCMCglmm(ystat ~ minall, random = ~bnum+yr, data = birds, family = "categorical")

Error in buildZ(rmodel.terms[r], data = data, formZ = TRUE, nginverse = names(ginverse)) : 
  missing values in random predictors

I have no idea what this means? I am really stuck and I feel like I'm missing something really important here.

3. This may be a very basic question, but could someone provide directions or a reference as to how to plot the logistic curve representing the relationship between minall and ystat? I used plot(minall,ystat) along with some other more complicated codes; however, I have not been able to produce a plot that shows the logistic curve.


Any guidance on any of these issues would be greatly appreciated! Thank you in advance for your time,

Charla



From annebj at gmail.com  Thu Mar  8 06:34:31 2012
From: annebj at gmail.com (Anne Bjorkman)
Date: Wed, 7 Mar 2012 21:34:31 -0800
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB,
	and cloglog
In-Reply-To: <330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>
References: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>
Message-ID: <CAHem2OG8G_Xg9gkA2Dn4K=hB=z6aPhFkiSxrfzDGA+uFAQ-wMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120307/26019138/attachment-0002.pl>

From bbolker at gmail.com  Thu Mar  8 19:36:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 8 Mar 2012 18:36:22 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?zero-inflation_with_mixed-effects=2C_glmmADM?=
	=?utf-8?q?B=2C=09and_cloglog?=
References: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>
	<CAHem2OG8G_Xg9gkA2Dn4K=hB=z6aPhFkiSxrfzDGA+uFAQ-wMg@mail.gmail.com>
Message-ID: <loom.20120308T192749-966@post.gmane.org>

Anne Bjorkman <annebj at ...> writes:


> 

 [snip]

> Do you (or anyone else from the list) have any advice for me about using
> the slope parameters from the mixed-effects models? My original email was
> probably far to long for anyone to read, so I will paraphrase my primary
> question here very briefly:
> 
> I am interested in change over time, so I would like to use slope
> parameters for a number of different species (abundance data for 154
> locations of 42 different species, measured in 5 equally-spaced years, the
> same locations are measured in each year, thus the need for a random effect
> of location).  I would like to model each species separately and use the
> slope parameter from each model as an estimate of the direction and
> magnitude of change over time for that species.  However, the distribution
> of the data for each species are quite different - some are highly
> zero-inflated, others are nearly normal.
> 
> My question is this: should I use the same model specifications for every
> species (e.g., use negative binomial/zero-inflated distributions even for
> those species that appear more normally distributed), or can I use the
> "best" model for each species (based on the distribution of the data for
> that species) and still compare the slope values to each other?  The
> important thing is that the slope values are comparable, because I am
> interested in how much each species has changed relative to the other
> species.
> I don't often see slope parameters from mixed models used in this way, so I
> am a little hesitant about the feasibility of what I'm trying to do. Any
> insight would be hugely appreciated.
> 
> Thanks very much!
> Anne
> 

  It depends a bit on what you mean by "compare". In any case you need
to make sure that the slope parameters are measuring the same thing --
so for example it would be a bad idea to compare (1) parameters
estimated using a model with a log link (e.g. negative binomial), so
that the parameter represented an exponential growth rate or
per-capita proportional change per year and parameters estimated on a
raw scale and (2) parameters estimated on the data or identity scale
(e.g. ordinary least-squares regression), so that the parameter
representing a linear rate of increase -- then you would be comparing
apples and oranges.  Similarly, if you have a model that incorporates
zero-inflation, you need to make sure that you're comparing a quantity
that reflects the change in the _mean_ density over time. On the
other hand if you use a zero-inflation model with a constant level of
zero-inflation over time, then the means at times t and t+1 will be
(1-p_z)*mu(t) and (1-p_z)*mu(t+1), so you should be able to disregard the
zero-inflation if you're comparing the proportional growth rate.
  At this level, just making sure that you know what your slope
parameter means, and that you are comparing comparable things, should
be sufficient.

  The next-level issue is doing _statistical_ comparisons among
species (i.e. species A is shrinking significantly faster than
species B).  Ideally you would do this by incorporating all of the
data in a single model and testing the significance of the
species*time interaction coefficients, but that would be hard
with your data.  It's a bit crude, but you could do _post hoc_
t-tests based on the estimated slope parameters and their
standard errors ...



From kay.cichini at gmail.com  Thu Mar  8 20:04:55 2012
From: kay.cichini at gmail.com (Kay Cichini)
Date: Thu, 8 Mar 2012 20:04:55 +0100
Subject: [R-sig-ME] zero-inflation with mixed-effects, glmmADMB,
	and cloglog
In-Reply-To: <CAHem2OG8G_Xg9gkA2Dn4K=hB=z6aPhFkiSxrfzDGA+uFAQ-wMg@mail.gmail.com>
References: <CAHem2OEUZF=8A3wusvFL-KgO91qXGZvL5REJyz=dbs7qOwgzbw@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BD7CB813E@E2K7CLSTB.cna.com>
	<CAHem2OG8G_Xg9gkA2Dn4K=hB=z6aPhFkiSxrfzDGA+uFAQ-wMg@mail.gmail.com>
Message-ID: <CADcQ+Rou9+cg8cOmsPXofXJzJ3_S61tmx10CyxvzBr8LvYZ7bg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120308/46a1243e/attachment-0002.pl>

From chantepie at mnhn.fr  Fri Mar  9 10:33:42 2012
From: chantepie at mnhn.fr (chantepie at mnhn.fr)
Date: Fri, 09 Mar 2012 10:33:42 +0100
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned G/R
 structure" and "Mixed model equations singular" errors
Message-ID: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>

Dear all,

I am using MCMCglmm function to construct bivariate animal models of  
bustard sperm production according to age-classes.

The problem is that the models can stochastically crash before the end  
of the run  (at 2000 iterations or 120000 or other) or can finish. For  
the model which does not finish, R returns different errors as:
-Mixed model equations singular: use a (stronger) prior
-ill-conditioned G/R structure: use proper priors if you haven't or  
rescale data if you have

For the models which reach the end, the estimations of genetic  
additive variance appear quite good (nice bell shaped posterior  
disctribution).

The problem still remains when I remove the animal term.
When I run univariate models, it works fine and the posteriors  
distributions look very good.

Strangely, the more data I have, the more models crash (the largest  
amount of data I have is 65000 data for 2400 individuals for one model).

The model looks like:

priorExp<-list(G=list(G1=list(V=diag(2), nu=2,  
alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
G2=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
G3=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000)),
R=list(V=diag(2), nu=2))

spz<-MCMCglmm(cbind(age1_2,age5_6)~trait-1 + trait:tse+  
trait:I(tse^2)+ trait:joe + trait:I(joe^2),
    random=~us(trait):animal+us(trait):ID+us(trait):annee ,
    rcov=~us(trait):units,nitt=150000, thin=1000, burnin=100000,  
prior=priorExp, verbose=TRUE, pedigree=ped,
    family=c("gaussian","gaussian"), data=dat)

For the fixed effects : I use 4 continuous parameters as correction  
for each trait
For the random effects: I use, individuals, years and animal parameters

I have also tried more informative prior (as described in WAMWIKI) but  
the problem was the same.


To give you an example :

Because of computing limitation, I use multi-chain process. I run  
several times the same model (as above) and concatenate results (same  
prior,same burning, same thin and random seed) to obtain at least 1000  
estimates (50 estimates by model). In this context, I ran 50  
bivariable models with the age-class age1_2 and the age-class age5_6  
but only 9 models of the 50 models reached the end.

When we look fixed parameters estimates (estimate are binded for the  
nine models : http://ubuntuone.com/3Gi8GwjcRk3P01MxJp2qLe ), we can  
see that the estimates are really close to 0. Could it be the problem?
When we look ramdom parameters estimates (estimate are binded for the  
nine models : http://ubuntuone.com/42oaP9euG1m2LNipMawcHX ), the  
residual estimates do not look very good. Could it be the problem?

Last thing, if I try to add a cubic effect, all the models crash (same  
error than before or memory mapped error).

I really do not know where the problem comes from. Do you have an idea?

Thanks

--
Stephane Chantepie
CNRS Phd  candidate
Mus?um national d'Histoire naturelle
55 rue Buffon
75005 paris
E-mail : chantepie_at_mnhn.fr
--



From j.hadfield at ed.ac.uk  Fri Mar  9 10:42:23 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 09 Mar 2012 09:42:23 +0000
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned
 G/R structure" and "Mixed model equations singular" errors
In-Reply-To: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
References: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
Message-ID: <20120309094223.53002azjabyja7pc@www.staffmail.ed.ac.uk>

Dear Stephane,

When you say crash do you mean crash in the sense of a segfault or in  
the sense that it stops with the errors:

  -Mixed model equations singular: use a (stronger) prior
  -ill-conditioned G/R structure: use proper priors if you haven't or  
rescale data if you have

If the latter, it may just require a rescaling of your continuous  
covariates by using something like scale(). If the former, it would be  
good for me to have a reproducible example as it means there is a bug.

Cheers,

Jarrod





uoting chantepie at mnhn.fr on Fri, 09 Mar 2012 10:33:42 +0100:

> Dear all,
>
> I am using MCMCglmm function to construct bivariate animal models of  
> bustard sperm production according to age-classes.
>
> The problem is that the models can stochastically crash before the  
> end of the run  (at 2000 iterations or 120000 or other) or can  
> finish. For the model which does not finish, R returns different  
> errors as:
> -Mixed model equations singular: use a (stronger) prior
> -ill-conditioned G/R structure: use proper priors if you haven't or  
> rescale data if you have
>
> For the models which reach the end, the estimations of genetic  
> additive variance appear quite good (nice bell shaped posterior  
> disctribution).
>
> The problem still remains when I remove the animal term.
> When I run univariate models, it works fine and the posteriors  
> distributions look very good.
>
> Strangely, the more data I have, the more models crash (the largest  
> amount of data I have is 65000 data for 2400 individuals for one  
> model).
>
> The model looks like:
>
> priorExp<-list(G=list(G1=list(V=diag(2), nu=2,  
> alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
> G2=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
> G3=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000)),
> R=list(V=diag(2), nu=2))
>
> spz<-MCMCglmm(cbind(age1_2,age5_6)~trait-1 + trait:tse+  
> trait:I(tse^2)+ trait:joe + trait:I(joe^2),
>    random=~us(trait):animal+us(trait):ID+us(trait):annee ,
>    rcov=~us(trait):units,nitt=150000, thin=1000, burnin=100000,  
> prior=priorExp, verbose=TRUE, pedigree=ped,
>    family=c("gaussian","gaussian"), data=dat)
>
> For the fixed effects : I use 4 continuous parameters as correction  
> for each trait
> For the random effects: I use, individuals, years and animal parameters
>
> I have also tried more informative prior (as described in WAMWIKI)  
> but the problem was the same.
>
>
> To give you an example :
>
> Because of computing limitation, I use multi-chain process. I run  
> several times the same model (as above) and concatenate results  
> (same prior,same burning, same thin and random seed) to obtain at  
> least 1000 estimates (50 estimates by model). In this context, I ran  
> 50 bivariable models with the age-class age1_2 and the age-class  
> age5_6 but only 9 models of the 50 models reached the end.
>
> When we look fixed parameters estimates (estimate are binded for the  
> nine models : http://ubuntuone.com/3Gi8GwjcRk3P01MxJp2qLe ), we can  
> see that the estimates are really close to 0. Could it be the problem?
> When we look ramdom parameters estimates (estimate are binded for  
> the nine models : http://ubuntuone.com/42oaP9euG1m2LNipMawcHX ), the  
> residual estimates do not look very good. Could it be the problem?
>
> Last thing, if I try to add a cubic effect, all the models crash  
> (same error than before or memory mapped error).
>
> I really do not know where the problem comes from. Do you have an idea?
>
> Thanks
>
> --
> Stephane Chantepie
> CNRS Phd  candidate
> Mus?um national d'Histoire naturelle
> 55 rue Buffon
> 75005 paris
> E-mail : chantepie_at_mnhn.fr
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Mike.Lawrence at dal.ca  Fri Mar  9 14:44:58 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 9 Mar 2012 09:44:58 -0400
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
Message-ID: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>

Hi folks,

I'm playing with lme4Eigen (version 0.9996875-8, running on Mac OS
10.7.3 using R 2.14.2) and am quite excited by the new bootMer()
function. However, when I try to run it, regardless of what fit I
provide for the argument "x" or function I provide for the argument
"FUN" (including running the examples), I get the error:

Error in envRefInferField(x, what, getClass(class(x)), selfEnv) :
  "resp" is not a valid field or method name for reference class ?lmerResp?

I presume that this is why the bootMer documentation example section
says "## Not run: %%--- fails for now --- FIXME"? I just thought I'd
double-check.

Also, I thought I'd make sure the devs know that the latest svn
version doesn't build on mac; when I try to do so, I get the error:

glmFamily.cpp: In member function ?virtual const Eigen::ArrayXd
glm::negativeBinomialDist::variance(const Eigen::ArrayXd&) const?:
glmFamily.cpp:228: error: ?Rcout? is not a member of ?Rcpp?

Cheers,

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar: http://goo.gl/BYH99

~ Certainty is folly... I think. ~



From chantepie at mnhn.fr  Fri Mar  9 17:33:52 2012
From: chantepie at mnhn.fr (chantepie at mnhn.fr)
Date: Fri, 09 Mar 2012 17:33:52 +0100
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned
 G/R structure" and "Mixed model equations singular" errors
In-Reply-To: <20120309094223.53002azjabyja7pc@www.staffmail.ed.ac.uk>
References: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
	<20120309094223.53002azjabyja7pc@www.staffmail.ed.ac.uk>
Message-ID: <20120309173352.168215srxwe8241c@dsiwebmail.mnhn.fr>

Dear Jarrod and others,

It is not a segfault error, the runs actually stop with one of these two
errors.

My covariates have already been rescaled (centered to be precise). I have
tried to center-reduce the covariates (by usind scale) but the result was the
same.

Also, when I use cubic term for "tse" and "joe" , the models stop running
before 1000 iterations.

Could the problem come from the number of fixed parameters to estimate? It
seems strange because I have a quiet big data set.

kind regards

stephane

Jarrod Hadfield <j.hadfield at ed.ac.uk> a ?crit?:

> Dear Stephane,
>
> When you say crash do you mean crash in the sense of a segfault or  
> in the sense that it stops with the errors:
>
>  -Mixed model equations singular: use a (stronger) prior
>  -ill-conditioned G/R structure: use proper priors if you haven't or  
> rescale data if you have
>
> If the latter, it may just require a rescaling of your continuous  
> covariates by using something like scale(). If the former, it would  
> be good for me to have a reproducible example as it means there is a  
> bug.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> uoting chantepie at mnhn.fr on Fri, 09 Mar 2012 10:33:42 +0100:
>
>> Dear all,
>>
>> I am using MCMCglmm function to construct bivariate animal models  
>> of bustard sperm production according to age-classes.
>>
>> The problem is that the models can stochastically crash before the  
>> end of the run  (at 2000 iterations or 120000 or other) or can  
>> finish. For the model which does not finish, R returns different  
>> errors as:
>> -Mixed model equations singular: use a (stronger) prior
>> -ill-conditioned G/R structure: use proper priors if you haven't or  
>> rescale data if you have
>>
>> For the models which reach the end, the estimations of genetic  
>> additive variance appear quite good (nice bell shaped posterior  
>> disctribution).
>>
>> The problem still remains when I remove the animal term.
>> When I run univariate models, it works fine and the posteriors  
>> distributions look very good.
>>
>> Strangely, the more data I have, the more models crash (the largest  
>> amount of data I have is 65000 data for 2400 individuals for one  
>> model).
>>
>> The model looks like:
>>
>> priorExp<-list(G=list(G1=list(V=diag(2), nu=2,  
>> alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
>> G2=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
>> G3=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000)),
>> R=list(V=diag(2), nu=2))
>>
>> spz<-MCMCglmm(cbind(age1_2,age5_6)~trait-1 + trait:tse+  
>> trait:I(tse^2)+ trait:joe + trait:I(joe^2),
>>   random=~us(trait):animal+us(trait):ID+us(trait):annee ,
>>   rcov=~us(trait):units,nitt=150000, thin=1000, burnin=100000,  
>> prior=priorExp, verbose=TRUE, pedigree=ped,
>>   family=c("gaussian","gaussian"), data=dat)
>>
>> For the fixed effects : I use 4 continuous parameters as correction  
>> for each trait
>> For the random effects: I use, individuals, years and animal parameters
>>
>> I have also tried more informative prior (as described in WAMWIKI)  
>> but the problem was the same.
>>
>>
>> To give you an example :
>>
>> Because of computing limitation, I use multi-chain process. I run  
>> several times the same model (as above) and concatenate results  
>> (same prior,same burning, same thin and random seed) to obtain at  
>> least 1000 estimates (50 estimates by model). In this context, I  
>> ran 50 bivariable models with the age-class age1_2 and the  
>> age-class age5_6 but only 9 models of the 50 models reached the end.
>>
>> When we look fixed parameters estimates (estimate are binded for  
>> the nine models : http://ubuntuone.com/3Gi8GwjcRk3P01MxJp2qLe ), we  
>> can see that the estimates are really close to 0. Could it be the  
>> problem?
>> When we look ramdom parameters estimates (estimate are binded for  
>> the nine models : http://ubuntuone.com/42oaP9euG1m2LNipMawcHX ),  
>> the residual estimates do not look very good. Could it be the  
>> problem?
>>
>> Last thing, if I try to add a cubic effect, all the models crash  
>> (same error than before or memory mapped error).
>>
>> I really do not know where the problem comes from. Do you have an idea?
>>
>> Thanks
>>
>> --
>> Stephane Chantepie
>> CNRS Phd  candidate
>> Mus?um national d'Histoire naturelle
>> 55 rue Buffon
>> 75005 paris
>> E-mail : chantepie_at_mnhn.fr
>> --
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>



From bbolker at gmail.com  Fri Mar  9 23:44:58 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 9 Mar 2012 22:44:58 +0000 (UTC)
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
References: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>
Message-ID: <loom.20120309T234321-724@post.gmane.org>

Mike Lawrence <Mike.Lawrence at ...> writes:

> I'm playing with lme4Eigen (version 0.9996875-8, running on Mac OS
> 10.7.3 using R 2.14.2) and am quite excited by the new bootMer()
> function. However, when I try to run it, regardless of what fit I
> provide for the argument "x" or function I provide for the argument
> "FUN" (including running the examples), I get the error:
> 
> Error in envRefInferField(x, what, getClass(class(x)), selfEnv) :
>   "resp" is not a valid field or method name for reference class ?lmerResp?
> 
> I presume that this is why the bootMer documentation example section
> says "## Not run: %%--- fails for now --- FIXME"? I just thought I'd
> double-check.

  More recently (version 12) this should work ...
> 
> Also, I thought I'd make sure the devs know that the latest svn
> version doesn't build on mac; when I try to do so, I get the error:
> 
> glmFamily.cpp: In member function ?virtual const Eigen::ArrayXd
> glm::negativeBinomialDist::variance(const Eigen::ArrayXd&) const?:
> glmFamily.cpp:228: error: ?Rcout? is not a member of ?Rcpp?


 Thanks for the heads-up.  I will check into it and try to see about
getting new binary versions of RcppEigen and lme4Eigen up on the
repository -- although possibly not before Monday.

  cheers
    Ben



From Mike.Lawrence at dal.ca  Sat Mar 10 09:20:52 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sat, 10 Mar 2012 04:20:52 -0400
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
In-Reply-To: <loom.20120309T234321-724@post.gmane.org>
References: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>
	<loom.20120309T234321-724@post.gmane.org>
Message-ID: <CAB+QPJCn60Oq_ogQ3bjFV68Zf9VLKU6kOkoDgXyq7DeX8j-Y=g@mail.gmail.com>

On Fri, Mar 9, 2012 at 6:44 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Also, I thought I'd make sure the devs know that the latest svn
>> version doesn't build on mac; when I try to do so, I get the error:
>>
>> glmFamily.cpp: In member function ?virtual const Eigen::ArrayXd
>> glm::negativeBinomialDist::variance(const Eigen::ArrayXd&) const?:
>> glmFamily.cpp:228: error: ?Rcout? is not a member of ?Rcpp?
>
>
> ?Thanks for the heads-up. ?I will check into it and try to see about
> getting new binary versions of RcppEigen and lme4Eigen up on the
> repository -- although possibly not before Monday.

While I'm not super familiar with C++, I took a look at the
"glmFamily.cpp" file indicated by the error message, and it seems that
all that has happened is that a few lines (used for debugging?)
starting "Rcpp::Rcout" need to be be commented out to "//Rcpp::Rcout"
in "glmFamily.cpp" and also "optimizer.cpp". Once this is done, the
current svn builds fine on mac.

Mike



From dmcastil at umail.iu.edu  Sat Mar 10 16:59:35 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Sat, 10 Mar 2012 10:59:35 -0500
Subject: [R-sig-ME] glmmADMB mcmc output
Message-ID: <CAMmHrnz_BUG4e3W3rqXp30q+wSVjk2-yN00gdW3RjtPX-+GaEw@mail.gmail.com>

Dear list members,

I have run the ML and mcmc for my model. I am wondering if there is a
simple transformation between the the ML coefficients and mcmc
coefficients. Or in general how do I interpret the mcmc coefficients
(I know how to interpret the ml coefficients). For example e^4.03 is
not in the range of the HPD for beta1 of the mcmc

nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
family="nbinom1")
> summary(nb1)

Call:
glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
   (1 | Pop), data = data, family = "nbinom1")


Coefficients:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)          4.03120    0.26620   15.14  < 2e-16 ***
D2_female            0.05115    0.00532    9.62  < 2e-16 ***
BacteriaE            0.13913    0.25159    0.55     0.58
EnviroEC             1.06900    0.22090    4.84  1.3e-06 ***
D2_female:BacteriaE  0.02622    0.00578    4.54  5.7e-06 ***
D2_female:EnviroEC  -0.03357    0.00471   -7.13  9.7e-13 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=95, Pop=16
Random effect variance(s):
Group=Pop
           Variance StdDev
(Intercept)  0.04716 0.2172
Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)

Log-likelihood: -572.814

>nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data, family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
> m<-as.mcmc(nb_mcmc$mcmc)
> head(HPDinterval(m))
           lower     upper
beta.1 50.4190302 55.231164
beta.2  6.3920598  9.033473
beta.3  0.5165269  4.145737
beta.4  1.7327276  5.167999
beta.5  1.6289002  3.791544
beta.6 -3.9886068 -2.057463

Thanks

Dean



From j.hadfield at ed.ac.uk  Sun Mar 11 10:20:29 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 11 Mar 2012 09:20:29 +0000
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned
 G/R structure" and "Mixed model equations singular" errors
In-Reply-To: <20120309173352.168215srxwe8241c@dsiwebmail.mnhn.fr>
References: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
	<20120309094223.53002azjabyja7pc@www.staffmail.ed.ac.uk>
	<20120309173352.168215srxwe8241c@dsiwebmail.mnhn.fr>
Message-ID: <20120311092028.13357jqqer7t0k08@www.staffmail.ed.ac.uk>

Hi Stephane,

Its very hard to know what could be causing the problem with out  
having the data. The three things that you could try are:


  a) scale the response variable

  b) work out if some terms really are weakly identified (MCMCglmm  
drops non-identified terms in the fixed effects by default)

  c) the error can appear I think if the residual covariance matrix  
becomes singular. This could happen, amongst other reasons, because  
non-modelled non-genetic effects are contributing to the resemblance  
between relatives and inflating Va by so much that Ve goes to zero.

Either i) running it for some iterations before it terminates or ii)  
fit the model in ASReml should give you some idea which of these  
problems are most likely.

Cheers,

Jarrod




Quoting chantepie at mnhn.fr on Fri, 09 Mar 2012 17:33:52 +0100:

> Dear Jarrod and others,
>
> It is not a segfault error, the runs actually stop with one of these two
> errors.
>
> My covariates have already been rescaled (centered to be precise). I have
> tried to center-reduce the covariates (by usind scale) but the result was the
> same.
>
> Also, when I use cubic term for "tse" and "joe" , the models stop running
> before 1000 iterations.
>
> Could the problem come from the number of fixed parameters to estimate? It
> seems strange because I have a quiet big data set.
>
> kind regards
>
> stephane
>
> Jarrod Hadfield <j.hadfield at ed.ac.uk> a ?crit?:
>
>> Dear Stephane,
>>
>> When you say crash do you mean crash in the sense of a segfault or  
>> in the sense that it stops with the errors:
>>
>> -Mixed model equations singular: use a (stronger) prior
>> -ill-conditioned G/R structure: use proper priors if you haven't or  
>> rescale data if you have
>>
>> If the latter, it may just require a rescaling of your continuous  
>> covariates by using something like scale(). If the former, it would  
>> be good for me to have a reproducible example as it means there is  
>> a bug.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>> uoting chantepie at mnhn.fr on Fri, 09 Mar 2012 10:33:42 +0100:
>>
>>> Dear all,
>>>
>>> I am using MCMCglmm function to construct bivariate animal models  
>>> of bustard sperm production according to age-classes.
>>>
>>> The problem is that the models can stochastically crash before the  
>>> end of the run  (at 2000 iterations or 120000 or other) or can  
>>> finish. For the model which does not finish, R returns different  
>>> errors as:
>>> -Mixed model equations singular: use a (stronger) prior
>>> -ill-conditioned G/R structure: use proper priors if you haven't  
>>> or rescale data if you have
>>>
>>> For the models which reach the end, the estimations of genetic  
>>> additive variance appear quite good (nice bell shaped posterior  
>>> disctribution).
>>>
>>> The problem still remains when I remove the animal term.
>>> When I run univariate models, it works fine and the posteriors  
>>> distributions look very good.
>>>
>>> Strangely, the more data I have, the more models crash (the  
>>> largest amount of data I have is 65000 data for 2400 individuals  
>>> for one model).
>>>
>>> The model looks like:
>>>
>>> priorExp<-list(G=list(G1=list(V=diag(2), nu=2,  
>>> alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
>>> G2=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000),
>>> G3=list(V=diag(2), nu=2, alpha.mu=rep(0,2),alpha.V=diag(2)*100000)),
>>> R=list(V=diag(2), nu=2))
>>>
>>> spz<-MCMCglmm(cbind(age1_2,age5_6)~trait-1 + trait:tse+  
>>> trait:I(tse^2)+ trait:joe + trait:I(joe^2),
>>>  random=~us(trait):animal+us(trait):ID+us(trait):annee ,
>>>  rcov=~us(trait):units,nitt=150000, thin=1000, burnin=100000,  
>>> prior=priorExp, verbose=TRUE, pedigree=ped,
>>>  family=c("gaussian","gaussian"), data=dat)
>>>
>>> For the fixed effects : I use 4 continuous parameters as  
>>> correction for each trait
>>> For the random effects: I use, individuals, years and animal parameters
>>>
>>> I have also tried more informative prior (as described in WAMWIKI)  
>>> but the problem was the same.
>>>
>>>
>>> To give you an example :
>>>
>>> Because of computing limitation, I use multi-chain process. I run  
>>> several times the same model (as above) and concatenate results  
>>> (same prior,same burning, same thin and random seed) to obtain at  
>>> least 1000 estimates (50 estimates by model). In this context, I  
>>> ran 50 bivariable models with the age-class age1_2 and the  
>>> age-class age5_6 but only 9 models of the 50 models reached the end.
>>>
>>> When we look fixed parameters estimates (estimate are binded for  
>>> the nine models : http://ubuntuone.com/3Gi8GwjcRk3P01MxJp2qLe ),  
>>> we can see that the estimates are really close to 0. Could it be  
>>> the problem?
>>> When we look ramdom parameters estimates (estimate are binded for  
>>> the nine models : http://ubuntuone.com/42oaP9euG1m2LNipMawcHX ),  
>>> the residual estimates do not look very good. Could it be the  
>>> problem?
>>>
>>> Last thing, if I try to add a cubic effect, all the models crash  
>>> (same error than before or memory mapped error).
>>>
>>> I really do not know where the problem comes from. Do you have an idea?
>>>
>>> Thanks
>>>
>>> --
>>> Stephane Chantepie
>>> CNRS Phd  candidate
>>> Mus?um national d'Histoire naturelle
>>> 55 rue Buffon
>>> 75005 paris
>>> E-mail : chantepie_at_mnhn.fr
>>> --
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Mohand-Larbi.Feddag at univ-nantes.fr  Mon Mar 12 10:29:32 2012
From: Mohand-Larbi.Feddag at univ-nantes.fr (Feddag Mohand-Larbi)
Date: Mon, 12 Mar 2012 10:29:32 +0100
Subject: [R-sig-ME] Fwd: Re: Question on the glmer function of the lme4 R
 package
Message-ID: <4F5DC1FC.8040506@univ-nantes.fr>



	

	

	

	

Dear Thiery

Thanks for your email.

The subscripts i and j are the subject i and j (in our case the subjects
are the lizards (players)). U is the n vector of the random effects
(U1,...,Un). Each random effect Ui is supposed to be distributed as
normal with mean 0 and variance sigma^2.

For our data (attached in Data.txt file), the matrix is of order
(77*77), and contains  only 100 non missing data (all the remaining are
missing (NA)).

The matrix of covariates (attached in Covariates.txt) is of order (77*4).

We would like to estimate the four fixed effects parameters associated
to the covariate matrix and the variance of the random effects Ui.


Best regards


Dr Feddag






On 07/03/2012 10:36, ONKELINX, Thierry wrote:
> We need more information to connect your data to the model. What is the interpretation of the subscript i and j and U in connection to your data? How does your dataset look like?
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Feddag Mohand-Larbi
> Verzonden: dinsdag 6 maart 2012 17:18
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Question on the glmer function of the lme4 R package
>
> Dear all,
>
> Could you please help me in the estimation of the different parameters of the Bradley-Terry model with random effects by the glmer function of the lme4 R package.
>
> The model, the marginal likelihood and the real data and the main question are described in the attached file.
>
> Best regards
>
>
>  Dr Feddag
>
>
>


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Data.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120312/fed118aa/attachment-0004.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Covariates.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120312/fed118aa/attachment-0005.txt>

From ken.knoblauch at inserm.fr  Mon Mar 12 14:36:18 2012
From: ken.knoblauch at inserm.fr (Ken knoblauch)
Date: Mon, 12 Mar 2012 13:36:18 +0000 (UTC)
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
References: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>
	<loom.20120309T234321-724@post.gmane.org>
Message-ID: <loom.20120312T142327-813@post.gmane.org>

Ben Bolker <bbolker at ...> writes:
> Mike Lawrence <Mike.Lawrence at ...> writes:
> > I'm playing with lme4Eigen (version 0.9996875-8, running on Mac OS
> > 10.7.3 using R 2.14.2) and am quite excited by the new bootMer()
> > function. However, when I try to run it, regardless of what fit I
> > provide for the argument "x" or function I provide for the argument
> > "FUN" (including running the examples), I get the error:
> > Error in envRefInferField(x, what, getClass(class(x)), selfEnv) :
> >   "resp" is not a valid field or method name for reference class ?lmerResp?
> > I presume that this is why the bootMer documentation example section
> > says "## Not run: %%--- fails for now --- FIXME"? I just thought I'd
> > double-check.
>   More recently (version 12) this should work ...
> > Also, I thought I'd make sure the devs know that the latest svn
> > version doesn't build on mac; when I try to do so, I get the error:
> > glmFamily.cpp: In member function ?virtual const Eigen::ArrayXd
> > glm::negativeBinomialDist::variance(const Eigen::ArrayXd&) const?:
> > glmFamily.cpp:228: error: ?Rcout? is not a member of ?Rcpp?
>  Thanks for the heads-up.  I will check into it and try to see about
> getting new binary versions of RcppEigen and lme4Eigen up on the
> repository -- although possibly not before Monday.
>   cheers
>     Ben

I was able to get lme4Eigen_0.9996875-13  to compile this (Monday)
morning on my Mac from source after first compiling version 0.2.0
of RcppEigen, which is available on CRAN but I don't see it on Rforge.
(R version 2.14.2 Patched (2012-02-29 r58552)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
Lion 10.7.3).

On an issue from a while back (and going off subject), 
I'm pleased to say that the links from
the psyphy package that allow non-zero lower asymptotes for binomial
families seem to  work with lme4Eigen, at least for binomial aggregated
data.  So far, I get errors for binary responses.  For example to use the
mafc.probit link for a 4-alternative forced-choice experiment, where
one might want to limit the lower asymptote of the link function to 0.25,
I first do the following:

Bi4 <- glmFamily$new(family = binomial(mafc.probit( 4 )))

and then use the argument 

family = Bi4$family

in the arguments to glmer.

It seems to produce promising results in simulated data when I aggregate the
binary responses but when I try it with a binary response variable, I get:

Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite

I would be happy to share the simulation script, if anyone is interested.

Thanks.

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From Bryan.Danson at MyFWC.com  Mon Mar 12 16:42:06 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Mon, 12 Mar 2012 11:42:06 -0400
Subject: [R-sig-ME] glmm with continuous data
Message-ID: <62C3C5515A02CB438EE737153DEF27D209A6808342@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120312/e3aca691/attachment-0002.pl>

From dmcastil at umail.iu.edu  Mon Mar 12 17:04:53 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Mon, 12 Mar 2012 12:04:53 -0400
Subject: [R-sig-ME] glmADMB mcmc output
Message-ID: <CAMmHrnxjvxx8CDN6FPAwXdNW5tcsG4=mnnYD_PVRUvoxg2bpvQ@mail.gmail.com>

Dear list members,

I have run the ML and mcmc for my model. I am wondering if there is a
simple transformation between the the ML coefficients and mcmc
coefficients. Or in general how do I interpret the mcmc coefficients
(I know how to interpret the ml coefficients). For example e^4.03 is
not in the range of the HPD for beta1 of the mcmc

nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
family="nbinom1")
> summary(nb1)

Call:
glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
  (1 | Pop), data = data, family = "nbinom1")


Coefficients:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)          4.03120    0.26620   15.14  < 2e-16 ***
D2_female            0.05115    0.00532    9.62  < 2e-16 ***
BacteriaE            0.13913    0.25159    0.55     0.58
EnviroEC             1.06900    0.22090    4.84  1.3e-06 ***
D2_female:BacteriaE  0.02622    0.00578    4.54  5.7e-06 ***
D2_female:EnviroEC  -0.03357    0.00471   -7.13  9.7e-13 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=95, Pop=16
Random effect variance(s):
Group=Pop
          Variance StdDev
(Intercept)  0.04716 0.2172
Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)

Log-likelihood: -572.814

>nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data, family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
> m<-as.mcmc(nb_mcmc$mcmc)
> head(HPDinterval(m))
          lower     upper
beta.1 50.4190302 55.231164
beta.2  6.3920598  9.033473
beta.3  0.5165269  4.145737
beta.4  1.7327276  5.167999
beta.5  1.6289002  3.791544
beta.6 -3.9886068 -2.057463

Thanks

Dean



From bates at stat.wisc.edu  Mon Mar 12 17:13:20 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 Mar 2012 11:13:20 -0500
Subject: [R-sig-ME] Fwd: Re: Question on the glmer function of the lme4
	R package
In-Reply-To: <4F5DC1FC.8040506@univ-nantes.fr>
References: <4F5DC1FC.8040506@univ-nantes.fr>
Message-ID: <CAO7JsnSMRKMTaT33A43hGNowGnLoPEt-CX9prBB_MHsrJK3nPA@mail.gmail.com>

Have you considered using the BradleyTerry2 package from CRAN?



From dmcastil at umail.iu.edu  Sun Mar 11 20:12:28 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Sun, 11 Mar 2012 15:12:28 -0400
Subject: [R-sig-ME] glmmADMB mcmc output
Message-ID: <CAMmHrnwetCuqwTxGtt8y3fCsUYEHFLT8djADCMqFBrw_GutYpQ@mail.gmail.com>

Dear list members,

I have run the ML and mcmc for my model. I am wondering if there is a
simple transformation between the the ML coefficients and mcmc
coefficients. Or in general how do I interpret the mcmc coefficients
(I know how to interpret the ml coefficients). For example e^4.03 is
not in the range of the HPD for beta1 of the mcmc

nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
family="nbinom1")
> summary(nb1)

Call:
glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
  (1 | Pop), data = data, family = "nbinom1")


Coefficients:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)          4.03120    0.26620   15.14  < 2e-16 ***
D2_female            0.05115    0.00532    9.62  < 2e-16 ***
BacteriaE            0.13913    0.25159    0.55     0.58
EnviroEC             1.06900    0.22090    4.84  1.3e-06 ***
D2_female:BacteriaE  0.02622    0.00578    4.54  5.7e-06 ***
D2_female:EnviroEC  -0.03357    0.00471   -7.13  9.7e-13 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=95, Pop=16
Random effect variance(s):
Group=Pop
          Variance StdDev
(Intercept)  0.04716 0.2172
Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)

Log-likelihood: -572.814

>nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data, family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
> m<-as.mcmc(nb_mcmc$mcmc)
> head(HPDinterval(m))
          lower     upper
beta.1 50.4190302 55.231164
beta.2  6.3920598  9.033473
beta.3  0.5165269  4.145737
beta.4  1.7327276  5.167999
beta.5  1.6289002  3.791544
beta.6 -3.9886068 -2.057463

Thanks



From bates at stat.wisc.edu  Tue Mar 13 17:12:04 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 Mar 2012 11:12:04 -0500
Subject: [R-sig-ME] (no subject)
In-Reply-To: <SNT106-W16E243E83122F2D35DE2EEE580@phx.gbl>
References: <SNT106-W16E243E83122F2D35DE2EEE580@phx.gbl>
Message-ID: <CAO7JsnRfmgUNj+UzJ17WCamMUbiQNExhVQAHPWT27YjognxSDg@mail.gmail.com>

I have switched Brian Edward's status so that every posting must be
approved by the moderator as it looks as though his email account has
been hacked.

On Tue, Mar 13, 2012 at 8:34 AM, Brian Edward <b.edward at live.com> wrote:
> Your own internet money making machines
> http://dezinecube.com/opqk12/httrhttpjobs-ab.php?oloCIDID=867
>
>
>
>
> __________________
> "His investigation should take in every part of themechanism; he should understand about the planesurface, what the stresses are upon its surface,what is the duty of each strut, or brace or wireand be able to make the proper repairs." (c) jahvaughan visszaadta
> Tue, 13 Mar 2012 14:34:34
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From cmgast at gmail.com  Tue Mar 13 18:44:57 2012
From: cmgast at gmail.com (Chris Gast)
Date: Tue, 13 Mar 2012 10:44:57 -0700
Subject: [R-sig-ME] Incorrect reporting of variance component from weighted
	LMM with lme4?
Message-ID: <CAPedOKg4Gp=gshX59RLk9yDM01b7NB5QkhSFKGNZKqsn_ihQWw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120313/23eda5cb/attachment-0002.pl>

From bbolker at gmail.com  Tue Mar 13 18:55:36 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 17:55:36 +0000 (UTC)
Subject: [R-sig-ME] lme4Eigen's bootMer & installing latest svn
References: <CAB+QPJC8TF48yEp0ifEfsak5JcVYpj55nDTSr_XVj7s==nq=0w@mail.gmail.com>
	<loom.20120309T234321-724@post.gmane.org>
	<loom.20120312T142327-813@post.gmane.org>
Message-ID: <loom.20120313T185315-959@post.gmane.org>

Ken knoblauch <ken.knoblauch at ...> writes:

> 
> Ben Bolker <bbolker at ...> writes:
> > Mike Lawrence <Mike.Lawrence at ...> writes:

  [snip]
> > > Also, I thought I'd make sure the devs know that the latest svn
> > > version doesn't build on mac; 

  [snip] 

> >  Thanks for the heads-up.  I will check into it and try to see about
> > getting new binary versions of RcppEigen and lme4Eigen up on the
> > repository -- although possibly not before Monday.
> 
> I was able to get lme4Eigen_0.9996875-13  to compile this (Monday)
> morning on my Mac from source after first compiling version 0.2.0
> of RcppEigen, which is available on CRAN but I don't see it on Rforge.
> (R version 2.14.2 Patched (2012-02-29 r58552)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> Lion 10.7.3).
> 
 
 [snip]

  For what it's worth, binaries of lme4Eigen...13  and Rcpp 0.2.0 should
be available now from http://lme4.r-forge.r-project.org/repos ...

  Ben



From juliet.hannah at gmail.com  Tue Mar 13 19:34:48 2012
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Tue, 13 Mar 2012 14:34:48 -0400
Subject: [R-sig-ME] observation level random effects/kinship model
Message-ID: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>

All,

I was reading the following post:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005184.html

which discusses why an observation-level random effect does not make
sense in the linear mixed model
case.

Does anyone know of any references that discuss this?

And for the genetics folks out there, isn't this what the kinship
model is: an observation-level random effect
that is correlated by degree of relatedness?

Thanks,

Juliet Hannah



From bbolker at gmail.com  Tue Mar 13 21:02:14 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 20:02:14 +0000 (UTC)
Subject: [R-sig-ME] glmADMB mcmc output
References: <CAMmHrnxjvxx8CDN6FPAwXdNW5tcsG4=mnnYD_PVRUvoxg2bpvQ@mail.gmail.com>
Message-ID: <loom.20120313T185551-892@post.gmane.org>

Dean Castillo <dmcastil at ...> writes:

> I have run the ML and mcmc for my model. I am wondering if there is a
> simple transformation between the the ML coefficients and mcmc
> coefficients. Or in general how do I interpret the mcmc coefficients
> (I know how to interpret the ml coefficients). For example e^4.03 is
> not in the range of the HPD for beta1 of the mcmc
> 
> nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
> family="nbinom1")
> > summary(nb1)
> 
> Call:
> glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
>   (1 | Pop), data = data, family = "nbinom1")
> 

  [snip]

> Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)

  (This very large NB dispersion parameter is a little bit worrying.
Have you examined your data for weirdness/zero-inflation etc.?  Do
you results look reasonable?)


> >nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
> family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
> > m<-as.mcmc(nb_mcmc$mcmc)
> > head(HPDinterval(m))
>           lower     upper
> beta.1 50.4190302 55.231164
> beta.2  6.3920598  9.033473
> beta.3  0.5165269  4.145737
> beta.4  1.7327276  5.167999
> beta.5  1.6289002  3.791544
> beta.6 -3.9886068 -2.057463

  I haven't fully implemented this yet, but here is an embryonic
function for transforming an mcmc object (m) based on a glmmADMB fit
(fit).  At the moment it only does some of the easy stuff
(transforming fixed-effect parameters to their original scale, and
variance parameters to the standard deviation scale)

  There will be a bit more detail about this in the vignette in
the next release.

mcmc_transform <- function(m,fit) {
  if (missing(fit)) {
    fit0 <- fit
    m <- fit$mcmc
    fit <- fit0
  }
  if (!is(m,"mcmc")) stop("m must be an 'mcmc' object")
  if (!is(fit,"glmmadmb")) stop("fit must a 'glmmadmb' object")
  ## zero-inflation
  pz <- m[,"pz",drop=FALSE]
  t_pz <- pz  ## (not transformed)
  ## fixed effects
  fixed <- m[,grep("^beta",colnames(m)),drop=FALSE]
  t_fixed <- as.mcmc(fixed %*% fit$phi)
  colnames(t_fixed) <- names(fixef(fit))
  ## variance parameters: log std dev
  theta <- m[,grep("^tmpL",colnames(m)),drop=FALSE]
  t_theta <- exp(theta)
  ## corr parameters ("offdiagonal elements of cholesky-factor of correlation
matrix")
  corr <- m[,grep("^tmpL1",colnames(m)),drop=FALSE]
  t_corr <- corr
  ## scale/overdispersion parameter
  logalpha <- m[,grep("^log_alpha",colnames(m)),drop=FALSE]
  t_alpha <- matrix(exp(logalpha),dimnames=list(NULL,"alpha"))
  ## random effects
  re <- m[,grep("^u\\.[0-9]+",colnames(m)),drop=FALSE]
  t_re <- re
  mcmc(cbind(t_pz,t_fixed,t_theta,t_corr,t_alpha,t_re),
       start=start(m),end=end(m),thin=frequency(m))
}



From bbolker at gmail.com  Tue Mar 13 21:39:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 20:39:10 +0000 (UTC)
Subject: [R-sig-ME] observation level random effects/kinship model
References: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>
Message-ID: <loom.20120313T212846-759@post.gmane.org>

Juliet Hannah <juliet.hannah at ...> writes:

> 
> All,
> 
> I was reading the following post:
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005184.html
> 
> which discusses why an observation-level random effect does not make
> sense in the linear mixed model
> case.
> 
> Does anyone know of any references that discuss this?
> 
> And for the genetics folks out there, isn't this what the kinship
> model is: an observation-level random effect
> that is correlated by degree of relatedness?

  I don't know of an immediately useful reference (other than, say,
the theory sections of Pinheiro and Bates 2000 or Littell et al or
some other mixed-model book -- and these wouldn't specifically answer
your question, they would just answer it implicitly).  But I would
be happy to hear about one.

  The issue is that in the standard definition of the mixed model
there are random effects (sometimes called "G-side" effects, for
grouping terms) and there is *also always* assumed to be a residual error
term, which is normally distributed independently among
observations in typical cases but can be multivariate normally
distributed (so-called "R-side" effects, "R" for residuals)
in some examples.
   Because mixed models always include a residual term by
convention, including an observation-level random effect would
just amount to partitioning the residual variance into two (unidentifiable)
terms, one corresponding to the residual (R) term and the other
corresponding to the grouping term.
  I'm not a geneticist, but I believe that the kinship model
is inducing a correlation on the *residuals* (an R-side effect)
rather than on a variance associated with a grouping factor.
If you could eliminate the residual error term or equivalently
fix its variance to zero (or very small), you could add a correlated
random effect as a G-side effect (although I think you would have
a hard time finding a mixed model package that allows for correlation
among G-side effects -- you'd probably have to code your own model
via ADMB or WinBUGS ...) -- but at least the standard R packages
(nlme, lme4, glmmADMB) don't let you do that.

  In GLMMs for families that do *not* have an adjustable scale parameter
(e.g. the most typical examples -- Poisson, binomial), there is
no normal residual error term included in the model, so it's OK to 
include an observation-level random effect.



From dmcastil at umail.iu.edu  Tue Mar 13 22:42:13 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Tue, 13 Mar 2012 17:42:13 -0400
Subject: [R-sig-ME] glmADMB mcmc output
In-Reply-To: <loom.20120313T185551-892@post.gmane.org>
References: <CAMmHrnxjvxx8CDN6FPAwXdNW5tcsG4=mnnYD_PVRUvoxg2bpvQ@mail.gmail.com>
	<loom.20120313T185551-892@post.gmane.org>
Message-ID: <CAMmHrnxdB0KRiMsa-MMia-XnODRf7SwgajDcoV8tmUjhA9TxPQ@mail.gmail.com>

Ben, Thank you for your response and the code you included. I think
this is what I was looking for.

I have tried the zero-inflated model in another package and the fit
for the zeroinflated negative binomial is better than negative
binomial alone.
I am having trouble fitting the zeroinflated model in the glmmADMB
package and I am getting an error I have seen come up in the list
archives. I have not had time to trouble shoot this just yet.

Dean

On Tue, Mar 13, 2012 at 4:02 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Dean Castillo <dmcastil at ...> writes:
>
>> I have run the ML and mcmc for my model. I am wondering if there is a
>> simple transformation between the the ML coefficients and mcmc
>> coefficients. Or in general how do I interpret the mcmc coefficients
>> (I know how to interpret the ml coefficients). For example e^4.03 is
>> not in the range of the HPD for beta1 of the mcmc
>>
>> nb1<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
>> family="nbinom1")
>> > summary(nb1)
>>
>> Call:
>> glmmadmb(formula = D2_eggs ~ D2_female * (Bacteria + Enviro) +
>> ? (1 | Pop), data = data, family = "nbinom1")
>>
>
> ?[snip]
>
>> Negative binomial dispersion parameter: 243.68 (std. err.: 48.422)
>
> ?(This very large NB dispersion parameter is a little bit worrying.
> Have you examined your data for weirdness/zero-inflation etc.? ?Do
> you results look reasonable?)
>
>
>> >nb_mcmc<-glmmadmb(D2_eggs~D2_female*(Bacteria+Enviro)+(1|Pop), data=data,
>> family="nbinom1",mcmc=T, mcmc.opts=mcmcControl(mcmc=10000))
>> > m<-as.mcmc(nb_mcmc$mcmc)
>> > head(HPDinterval(m))
>> ? ? ? ? ? lower ? ? upper
>> beta.1 50.4190302 55.231164
>> beta.2 ?6.3920598 ?9.033473
>> beta.3 ?0.5165269 ?4.145737
>> beta.4 ?1.7327276 ?5.167999
>> beta.5 ?1.6289002 ?3.791544
>> beta.6 -3.9886068 -2.057463
>
> ?I haven't fully implemented this yet, but here is an embryonic
> function for transforming an mcmc object (m) based on a glmmADMB fit
> (fit). ?At the moment it only does some of the easy stuff
> (transforming fixed-effect parameters to their original scale, and
> variance parameters to the standard deviation scale)
>
> ?There will be a bit more detail about this in the vignette in
> the next release.
>
> mcmc_transform <- function(m,fit) {
> ?if (missing(fit)) {
> ? ?fit0 <- fit
> ? ?m <- fit$mcmc
> ? ?fit <- fit0
> ?}
> ?if (!is(m,"mcmc")) stop("m must be an 'mcmc' object")
> ?if (!is(fit,"glmmadmb")) stop("fit must a 'glmmadmb' object")
> ?## zero-inflation
> ?pz <- m[,"pz",drop=FALSE]
> ?t_pz <- pz ?## (not transformed)
> ?## fixed effects
> ?fixed <- m[,grep("^beta",colnames(m)),drop=FALSE]
> ?t_fixed <- as.mcmc(fixed %*% fit$phi)
> ?colnames(t_fixed) <- names(fixef(fit))
> ?## variance parameters: log std dev
> ?theta <- m[,grep("^tmpL",colnames(m)),drop=FALSE]
> ?t_theta <- exp(theta)
> ?## corr parameters ("offdiagonal elements of cholesky-factor of correlation
> matrix")
> ?corr <- m[,grep("^tmpL1",colnames(m)),drop=FALSE]
> ?t_corr <- corr
> ?## scale/overdispersion parameter
> ?logalpha <- m[,grep("^log_alpha",colnames(m)),drop=FALSE]
> ?t_alpha <- matrix(exp(logalpha),dimnames=list(NULL,"alpha"))
> ?## random effects
> ?re <- m[,grep("^u\\.[0-9]+",colnames(m)),drop=FALSE]
> ?t_re <- re
> ?mcmc(cbind(t_pz,t_fixed,t_theta,t_corr,t_alpha,t_re),
> ? ? ? start=start(m),end=end(m),thin=frequency(m))
> }
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From klasen at mpipz.mpg.de  Tue Mar 13 22:55:43 2012
From: klasen at mpipz.mpg.de (Jonas Klasen)
Date: Tue, 13 Mar 2012 22:55:43 +0100
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>
References: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>
Message-ID: <fbfed66376d0.4f5fd06f@mpiz-koeln.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120313/386dd3de/attachment-0002.pl>

From jzl106 at gmail.com  Wed Mar 14 00:33:07 2012
From: jzl106 at gmail.com (Junyan Luo)
Date: Tue, 13 Mar 2012 19:33:07 -0400
Subject: [R-sig-ME] No need to handle between-group correlation structure in
	glmm in general?
Message-ID: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>

Hi,
Recently I have been working with a data set that contains individual
samples from a set of connected geographical areal units. While I plan
to use glmm to model the data with individuals as the 1st level units
and the areal units as the 2nd level units, I am concerned with the
potential spatial autocorrelation among the geographical areal units
(i.e., at the second level). It is reasonable to think that the random
effects at the second level will be spatial autocorrelated. I know
nlme has the option to specify "within-group" correlation structure,
but I couldn't figure out a way to specify "between-group"
correlations structure for the geographical areal units.

However, one of my colleagues told me it was totally unnecessary to
specify a correlation structure at the second level. This is because
the two assumptions of multi-level models are (1) the individual error
term is independent; (2) the individual error term is uncorrelated
with the random effects. It does NOT assume that the random effects
should be independent. So unless (2) is violated, generally we don't
need to worry about autocorrelation in the random effects. That's
probably why nlme only has the option for specifying "within-group"
correlation structure. I feel the assessment is reasonable, but I am
unsure if that is correct. Can anybody help me clarify this? Thanks!



From bbolker at gmail.com  Wed Mar 14 01:30:43 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 20:30:43 -0400
Subject: [R-sig-ME] Fwd: Re: [R] how to write crossed and nested random
 effects in a model
In-Reply-To: <1331684739.94898.YahooMailNeo@web36604.mail.mud.yahoo.com>
References: <1331684739.94898.YahooMailNeo@web36604.mail.mud.yahoo.com>
Message-ID: <4F5FE6B3.9050102@gmail.com>


 [forwarded to r-sig-mixed-models at r-project.org: it is much better to
keep these discussions on a public, archived list]

-------- Original Message --------
Subject: 	Re: [R] how to write crossed and nested random effects in a model
Date: 	Tue, 13 Mar 2012 17:25:39 -0700 (PDT)
From: 	withanage Niroshan perera <wnnkp at yahoo.com>
Reply-To: 	withanage Niroshan perera <wnnkp at yahoo.com>
To: 	Ben Bolker <bbolker at gmail.com>



Dear Professor,

Thanks lot for your valuable idea, Could you please let me know the your
explanation in a model. I guess that would be much more informative for
me to get it understood.

  [snip]

BMB>  Well, if you're a PhD student in mathematics & statistics you
BMB> be able to do some of this yourself -- there must be some expertise
BMB> in mixed models (although possibly not in mixed models in R)
BMB> at your institution in order for you to be working in this line
BMB> of research ...

BMB> I did, more or less, give you the model formula below.

Something like:
glmer (resp ~ pathology + (pathology|reader)+(pathology|patient/eye),
   family=binomial(link="probit"),data=mydata)

  I would *strongly* recommend that you work out how to simulate some
data with known variance components so that you can see whether you
are getting the right sorts of answers ...

Niroshan <wnnperer <at> ucalgary.ca> writes:

> I have a question based on my research. I am analyzing reader-based 
> diagnostic data set.  My study involves diabetic patients who were 
> evaluated for treatable diabetic retinopathy based on the presence
> or absence of two pathologies in their eyes.  Pathologies were 
> identified using the clinical examination (Gold standard method). In 
> addition it can be identified by taking digital images of patients? 
> eyes and this method is cost effective. Finally two readers go over 
> the images independently and patients are diagnosed as either 
> positive or negative for the pathologies. My objective is,
> estimation the sensitivity and specificity of reader-based diagnostic
> method.

> I am going to fit multivariate probit model. But the problem has 
> complex correlation structure. We have three different correlation: 
> readers results  are correlated, patients left and right eyes are 
> correlated and pathologies are correlated since all based on the 
> retina in the eye.

 [snip]

> Also I think patients and readers are crossed each other since each 
> reader go over each patients? images. And [snip] eyes are nested with
> patients and pathologies are nested with in the eye.  Is this crossed
> and nested interpretation true?  If then how can I include these
> effects as random terms to the model?
> 
> My response is readers ? diagnosed values. Per patient I have 8 
> values (2 pathologies, left and right eye and 2 readers) Explanatory
>  variables are actual disease status of each pathology for left and 
> right eyes.
> 


  I think that *in principle* (if you are using lme4, which is
probably the most convenient option for dealing with crossed REs) you
probably want

~ pathology + (pathology|reader)+(pathology|patient/eye)

  The fixed effect term says that pathologies may vary in their
overall frequency.  The first RE term says that different readers can
vary, in a pathology-specific way (if they just differed overall in
their sensitivity you would want (1|reader) instead); the second says
that there is variance among eyes (within patients) in all pathologies
(and that they may be correlated).

  A few cautions about this:

* I'm not sure I got it right

* You might want to forward this (along with my answer, so we're not
starting from scratch) to r-sig-mixed-models at r-project.org
<mailto:r-sig-mixed-models at r-project.org> , where
there is more expertise in mixed models.

* if you have the _same_ two readers for all of your patients (as
opposed to two different readers chosen at random out of a large,
possibly overlapping pool), then it isn't be practical to treat them
as a random effect, no matter how much sense it makes philosophically
-- use pathology*reader instead.

* You may need a moderately large amount of data to fit this model ...



From nprause at mrn.org  Wed Mar 14 02:52:13 2012
From: nprause at mrn.org (Nicole Prause)
Date: Tue, 13 Mar 2012 19:52:13 -0600
Subject: [R-sig-ME] Specifying continuous covariates and predictors in lmer
Message-ID: <CANPy+hfWd4ou+r-aeA2MupG_Qk2tBzxsuYG8icd=7gVXb+t53w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120313/1d25e904/attachment-0002.pl>

From rudolf.rohr at ebd.csic.es  Wed Mar 14 09:27:00 2012
From: rudolf.rohr at ebd.csic.es (Rudolf Philippe Rohr)
Date: Wed, 14 Mar 2012 09:27:00 +0100
Subject: [R-sig-ME] issue when incorporating a phylogenetic correlation
 structure (corPagel) in a linear mixed effect model (lme)
Message-ID: <4F605654.7070808@ebd.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/f0e19aaa/attachment-0002.pl>

From yvesrousselle at gmail.com  Wed Mar 14 11:05:14 2012
From: yvesrousselle at gmail.com (Yves Rousselle)
Date: Wed, 14 Mar 2012 14:05:14 +0400
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <fbfed66376d0.4f5fd06f@mpiz-koeln.mpg.de>
References: <CALzuZRQ5YdoLfAEb+ct6DmqdT0jQCWK7cMB5HFGex+GCW71-=g@mail.gmail.com>
	<fbfed66376d0.4f5fd06f@mpiz-koeln.mpg.de>
Message-ID: <CAA8=r0DAnaByMy23C8tPuZn4W-PeccjTHviG7UtOwT8k40MoXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/b871c3d4/attachment-0002.pl>

From par.ingvarsson at emg.umu.se  Wed Mar 14 11:24:24 2012
From: par.ingvarsson at emg.umu.se (=?iso-8859-1?Q?=22P=E4r_K=2E_Ingvarsson=22?=)
Date: Wed, 14 Mar 2012 11:24:24 +0100
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <mailman.3008.1331719534.4502.r-sig-mixed-models@r-project.org>
References: <mailman.3008.1331719534.4502.r-sig-mixed-models@r-project.org>
Message-ID: <3FDE1CA9-E720-44AE-BB45-09DB199BFCBE@emg.umu.se>


> Date: Wed, 14 Mar 2012 14:05:14 +0400
> From: Yves Rousselle <yvesrousselle at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] observation level random effects/kinship model
> Message-ID:
>        <CAA8=r0DAnaByMy23C8tPuZn4W-PeccjTHviG7UtOwT8k40MoXw at mail.gmail.com>
> Content-Type: text/plain
> 
> Hi,
> 
> If I understand well, if you want to take into account the kinship between
> individuals in genetics models, you have to specify a random effect that is
> the individuals levels and specify that this effect follows a distribution
> with a variance/covariance matrix equal to 2*K*Vg (basically). 2*Vg is just
> a number and K is the kinship matrix.
> I am currently using R to do such genetics models to do association
> mapping. I ask to other people that have done that before me and if I
> understand well, no packages allows to specify such a variance/covariance
> matrix for a random effect except ASREML. But you have to pay a license to
> use it. I am using this package for my study.

There are several packages that can handle kinship matrices for doing association studies in R. Of the top of my head I can come up with:

kinship (http://cran.r-project.org/web/packages/kinship/index.html)
EMMA (http://mouse.cs.ucla.edu/emma/news.html)
GenABEL (http://www.genabel.org/)


> 
> Concerning the question of putting an observation-level effect, I begin to
> understand it but you have to check with others perhaps. I will take the
> association mapping case as an example (I hope you know it a bit). You have
> a sample of individuals that are evaluated within a repeated block design
> for example. So each individuals is repeated end therefore, the
> observations level is not **yet** the individual level. The classical first
> step is to estimate (predict is the good word I guess) BLUP for the
> individual level with a model that takes into account the experimental
> design parameters. After this step, you obtain a dataset in which the
> observation level is the individual level. The second step consists in
> testing the association between the BLUP and some markers. In this model,
> you specify a random effect which is the individual level for with you
> specify the variance/covariance matrix 2KVg. So, at this step, you use a
> random effect at the observation level. I talked about that with
> biostatiticians (I hope this traduction is good) because I was surprised
> that an effect could be at the same level as the observations level because
> there won't be enough degree of freedom in the model. They explained me
> that, the correlation between individuals, specified in the kinship matrix,
> acts like repeating each individuals in their common part in other
> individuals. Well, I am sorry that I'm not able to put this idea in words
> in a better way, I hope it will help.

You can do the analyses directly without going through the BLUPs estimation step, but that generally leads to similar results as with the two-step method. See for instance http://www.genetics.org/content/178/3/1745.abstract for more details


-Pelle

--
P?r K. Ingvarsson
Professor, Evolutionary Genetics
Ume? Plant Science Centre
Department of Ecology and Environmental Science
Linneaus v?g 6
Ume? University, SE-901 87 Ume?, Sweden
tel. +46-(0)90-786-7414, fax. +46-(0)90-786-6705



From c.ryan.king at gmail.com  Wed Mar 14 13:28:00 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Wed, 14 Mar 2012 07:28:00 -0500
Subject: [R-sig-ME] observation level random effects/kinship model
Message-ID: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com>

When the observation-level random effects are independent then they
are the same as the noise. i.e.
y = xb + u +e can just be rewritten y= xb + e', with e' = u+e. Since
the sum of two normals is normal, the model is unchanged from usual
OLS.

With kinship that symmetry breaks, and observation-level random
effects are identifiable.

.I am currently using R to do such genetics models to do association
.mapping. I ask to other people that have done that before me and if I
.understand well, no packages allows to specify such a variance/covariance
.matrix for a random effect except ASREML.

You can also use MCMCglmm and R-INLA.

Ryan King



From pierces1 at msu.edu  Wed Mar 14 13:37:03 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 14 Mar 2012 08:37:03 -0400
Subject: [R-sig-ME] No need to handle between-group correlation
	structure in	glmm in general?
In-Reply-To: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>
References: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>
Message-ID: <003001cd01df$290c7730$7b256590$@msu.edu>

The best thing to do would be to empirically test whether modeling the
spatial autocorrelation in the level 2 random effects improves model fit
compared with a simpler model that assumes independence of those random
effects. In my dissertation work, adding spatial autocorrelation at level 2
improved a model (but not dramatically). 

Check out the following resources:

Beard, J. R. (2008). New approaches to multilevel analysis. Journal of Urban
Health, 85(6), 805-806. doi: 10.1007/s11524-008-9314-7

Browne, W., & Goldstein, H. (2010). MCMC sampling for a multilevel model
with non-independent residuals within and between cluster units. Journal of
Educational and Behavioral Statistics, 35(4), 453-473. doi:
10.3102/1076998609359788

Chaix, B., Leyland, A. H., Sabel, C. E., Chauvin, P., R?stam, L.,
Kristersson, H., & Merlo, J. (2006). Spatial clustering of mental disorders
and associated characteristics of the neighbourhood context in Malm?,
Sweden, in 2001. Journal of Epidemiology and Community Health, 60(5),
427-435. doi: 10.1136/jech.2005.040360

Chaix, B., Merlo, J., & Chauvin, P. (2005). Comparison of a spatial approach
with the multilevel approach for investigating place effects on health: The
example of healthcare utilisation in France. Journal of Epidemiology and
Community Health, 59(6), 517-526. doi: 10.1136/jech.2004.025478

Chaix, B., Merlo, J., Evans, D., Leal, C., & Havard, S. (2009).
Neighborhoods in eco-epidemiologic research: Delimiting personal exposure
areas. A response to Riva, Gauvin, Apparicio and Brodeur. Social Science &
Medicine, 69(9), 1306-1310. doi: 10.1016/j.socscimed.2009.07.018

Chaix, B., Merlo, J., Subramanian, S. V., Lynch, J., & Chauvin, P. (2005).
Comparison of a spatial perspective with the multilevel analytical approach
in neighborhood studies: The case of mental and behavioral disorders due to
psychoactive substance use in Malm?, Sweden, 2001. American Journal of
Epidemiology, 162(2), 171-182. doi: 10.1093/aje/kwi175

Fagg, J., Curtis, S., Clark, C., Congdon, P., & Stansfeld, S. A. (2008).
Neighbourhood perceptions among inner-city adolescents: Relationships with
their individual characteristics and with independently assessed
neighbourhood conditions. Journal of Environmental Psychology, 28(2),
128-142. doi: 10.1016/j.jenvp.2007.10.004



Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Junyan Luo [mailto:jzl106 at gmail.com] 
Sent: Tuesday, March 13, 2012 7:33 PM
To: R-sig-mixed-models at r-project.org
Subject: [R-sig-ME] No need to handle between-group correlation structure in
glmm in general?

Hi,
Recently I have been working with a data set that contains individual
samples from a set of connected geographical areal units. While I plan
to use glmm to model the data with individuals as the 1st level units
and the areal units as the 2nd level units, I am concerned with the
potential spatial autocorrelation among the geographical areal units
(i.e., at the second level). It is reasonable to think that the random
effects at the second level will be spatial autocorrelated. I know
nlme has the option to specify "within-group" correlation structure,
but I couldn't figure out a way to specify "between-group"
correlations structure for the geographical areal units.

However, one of my colleagues told me it was totally unnecessary to
specify a correlation structure at the second level. This is because
the two assumptions of multi-level models are (1) the individual error
term is independent; (2) the individual error term is uncorrelated
with the random effects. It does NOT assume that the random effects
should be independent. So unless (2) is violated, generally we don't
need to worry about autocorrelation in the random effects. That's
probably why nlme only has the option for specifying "within-group"
correlation structure. I feel the assessment is reasonable, but I am
unsure if that is correct. Can anybody help me clarify this? Thanks!



From jzl106 at gmail.com  Wed Mar 14 14:15:36 2012
From: jzl106 at gmail.com (Junyan Luo)
Date: Wed, 14 Mar 2012 09:15:36 -0400
Subject: [R-sig-ME] No need to handle between-group correlation
 structure in glmm in general?
In-Reply-To: <003001cd01df$290c7730$7b256590$@msu.edu>
References: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>
	<003001cd01df$290c7730$7b256590$@msu.edu>
Message-ID: <CAFT_Lc26NK26j4hDL42JbLAeZDVp-ntf1LJer=O1vFyW9MLFOw@mail.gmail.com>

Hi Dr. Pierce,

Thanks for the reply! And the information you provided is very useful!
Do you know if any existing R tools can handle this type of analysis?

The suggestion of comparing model fit is a good idea, but probably a
more important issue is whether the presence of correlated random
effects biases the parameter estimation. I am aware of a few test
techniques related to this, but totally unsure about their
implications. For example, is it a good idea to perform Moran's I test
on the second level residuals? (Or random effects directly?) A more
important question is, if Moran's I suggests autocorrelation in second
level residuals, would it be corrected by incorporating an correlation
structure for random effects?

REGARDS,
Junyan

On Wed, Mar 14, 2012 at 8:37 AM, Steven J. Pierce <pierces1 at msu.edu> wrote:
> The best thing to do would be to empirically test whether modeling the
> spatial autocorrelation in the level 2 random effects improves model fit
> compared with a simpler model that assumes independence of those random
> effects. In my dissertation work, adding spatial autocorrelation at level 2
> improved a model (but not dramatically).
>
> Check out the following resources:
>
> Beard, J. R. (2008). New approaches to multilevel analysis. Journal of Urban
> Health, 85(6), 805-806. doi: 10.1007/s11524-008-9314-7
>
> Browne, W., & Goldstein, H. (2010). MCMC sampling for a multilevel model
> with non-independent residuals within and between cluster units. Journal of
> Educational and Behavioral Statistics, 35(4), 453-473. doi:
> 10.3102/1076998609359788
>
> Chaix, B., Leyland, A. H., Sabel, C. E., Chauvin, P., R?stam, L.,
> Kristersson, H., & Merlo, J. (2006). Spatial clustering of mental disorders
> and associated characteristics of the neighbourhood context in Malm?,
> Sweden, in 2001. Journal of Epidemiology and Community Health, 60(5),
> 427-435. doi: 10.1136/jech.2005.040360
>
> Chaix, B., Merlo, J., & Chauvin, P. (2005). Comparison of a spatial approach
> with the multilevel approach for investigating place effects on health: The
> example of healthcare utilisation in France. Journal of Epidemiology and
> Community Health, 59(6), 517-526. doi: 10.1136/jech.2004.025478
>
> Chaix, B., Merlo, J., Evans, D., Leal, C., & Havard, S. (2009).
> Neighborhoods in eco-epidemiologic research: Delimiting personal exposure
> areas. A response to Riva, Gauvin, Apparicio and Brodeur. Social Science &
> Medicine, 69(9), 1306-1310. doi: 10.1016/j.socscimed.2009.07.018
>
> Chaix, B., Merlo, J., Subramanian, S. V., Lynch, J., & Chauvin, P. (2005).
> Comparison of a spatial perspective with the multilevel analytical approach
> in neighborhood studies: The case of mental and behavioral disorders due to
> psychoactive substance use in Malm?, Sweden, 2001. American Journal of
> Epidemiology, 162(2), 171-182. doi: 10.1093/aje/kwi175
>
> Fagg, J., Curtis, S., Clark, C., Congdon, P., & Stansfeld, S. A. (2008).
> Neighbourhood perceptions among inner-city adolescents: Relationships with
> their individual characteristics and with independently assessed
> neighbourhood conditions. Journal of Environmental Psychology, 28(2),
> 128-142. doi: 10.1016/j.jenvp.2007.10.004
>
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Junyan Luo [mailto:jzl106 at gmail.com]
> Sent: Tuesday, March 13, 2012 7:33 PM
> To: R-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] No need to handle between-group correlation structure in
> glmm in general?
>
> Hi,
> Recently I have been working with a data set that contains individual
> samples from a set of connected geographical areal units. While I plan
> to use glmm to model the data with individuals as the 1st level units
> and the areal units as the 2nd level units, I am concerned with the
> potential spatial autocorrelation among the geographical areal units
> (i.e., at the second level). It is reasonable to think that the random
> effects at the second level will be spatial autocorrelated. I know
> nlme has the option to specify "within-group" correlation structure,
> but I couldn't figure out a way to specify "between-group"
> correlations structure for the geographical areal units.
>
> However, one of my colleagues told me it was totally unnecessary to
> specify a correlation structure at the second level. This is because
> the two assumptions of multi-level models are (1) the individual error
> term is independent; (2) the individual error term is uncorrelated
> with the random effects. It does NOT assume that the random effects
> should be independent. So unless (2) is violated, generally we don't
> need to worry about autocorrelation in the random effects. That's
> probably why nlme only has the option for specifying "within-group"
> correlation structure. I feel the assessment is reasonable, but I am
> unsure if that is correct. Can anybody help me clarify this? Thanks!
>
>
>



From wnnkp at yahoo.com  Wed Mar 14 01:03:34 2012
From: wnnkp at yahoo.com (withanage Niroshan perera)
Date: Tue, 13 Mar 2012 17:03:34 -0700 (PDT)
Subject: [R-sig-ME] How to write crossed and nested random effects in a model
Message-ID: <1331683414.39699.YahooMailNeo@web36606.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120313/1bd154b6/attachment-0002.pl>

From harkiran.bhogal07 at imperial.ac.uk  Wed Mar 14 21:41:48 2012
From: harkiran.bhogal07 at imperial.ac.uk (Bhogal, Harkiran)
Date: Wed, 14 Mar 2012 20:41:48 +0000
Subject: [R-sig-ME] lme code
Message-ID: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/79a70aad/attachment-0002.pl>

From f.calboli at imperial.ac.uk  Wed Mar 14 22:04:51 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 14 Mar 2012 21:04:51 +0000
Subject: [R-sig-ME] lme code
In-Reply-To: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>
References: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>
Message-ID: <1B848EC0-AEC4-4F4F-B44F-E59DA8F2C7EF@imperial.ac.uk>

On 14 Mar 2012, at 20:41, Bhogal, Harkiran wrote:

> Please help!
> 
> 
> 
> Got a few days left and I need to model a random effect of species on the body mass (logM) and temperature (K) slopes. This is what i've done so far that works:
>    model1<-lme(logSSP~logM + K,random=~1|species,data=data1)
>    model2<-lme(logSSP~logM + K,random=~K|species,data=data1)
>    model3<-lme(logSSP~logM + K,random=~logM|species,data=data1)
> 
> 
> The one I now want is:
>    model4<-lme(logSSP~logM + K,random=~logM|species,K|species,data=data1)

random ~ logM + species|K/species

????

please explain what you are trying to do in the random part, you code for model 4 does not just not make sense as R code, it just does not make sense period.

F


>    #I need the random effect of spp on both slopes of logM and K, but this code doesn't work so how do i change the code??????
>    :( Any help will be greatly appreciated
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From gangchen at mail.nih.gov  Wed Mar 14 22:08:45 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Wed, 14 Mar 2012 17:08:45 -0400
Subject: [R-sig-ME] lme code
In-Reply-To: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>
References: <B8043F7C81614A45B44867706B3AF9DF22912E4F@icexch-m1.ic.ac.uk>
Message-ID: <CAHmzXO4b2rGe7CsVBGc3VdhYLjY+GOmv9RsAq1iP5HNaHAg=_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/2d8a3a14/attachment-0002.pl>

From shyunuw at gmail.com  Thu Mar 15 02:38:42 2012
From: shyunuw at gmail.com (Saang-Yoon Hyun)
Date: Wed, 14 Mar 2012 21:38:42 -0400
Subject: [R-sig-ME] a good book?
Message-ID: <CAFh292PfF76qch9XyWmLHO0rg9nAJY2bRRv=RrHHTORhqn-peA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/02898cc3/attachment-0002.pl>

From kw.stat at gmail.com  Thu Mar 15 03:37:50 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 14 Mar 2012 21:37:50 -0500
Subject: [R-sig-ME] a good book?
In-Reply-To: <CAFh292PfF76qch9XyWmLHO0rg9nAJY2bRRv=RrHHTORhqn-peA@mail.gmail.com>
References: <CAFh292PfF76qch9XyWmLHO0rg9nAJY2bRRv=RrHHTORhqn-peA@mail.gmail.com>
Message-ID: <CAKFxdiTkEwHYRT+P9WFORdnzZ5A8-GUo6bPksGW8iEh8Rreq1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120314/496685a1/attachment-0002.pl>

From aghaynes at gmail.com  Thu Mar 15 09:34:26 2012
From: aghaynes at gmail.com (Alan Haynes)
Date: Thu, 15 Mar 2012 09:34:26 +0100
Subject: [R-sig-ME] a good book?
In-Reply-To: <CAKFxdiTkEwHYRT+P9WFORdnzZ5A8-GUo6bPksGW8iEh8Rreq1Q@mail.gmail.com>
References: <CAFh292PfF76qch9XyWmLHO0rg9nAJY2bRRv=RrHHTORhqn-peA@mail.gmail.com>
	<CAKFxdiTkEwHYRT+P9WFORdnzZ5A8-GUo6bPksGW8iEh8Rreq1Q@mail.gmail.com>
Message-ID: <CAPdSD+7ir8W7pvt+qEhBrB5dyYR5MVSmr1g9_q2V=72gcGEm8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120315/fa9bb7c4/attachment-0002.pl>

From pierces1 at msu.edu  Thu Mar 15 14:04:42 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Thu, 15 Mar 2012 09:04:42 -0400
Subject: [R-sig-ME] No need to handle between-group correlation
	structure in glmm in general?
In-Reply-To: <CAFT_Lc26NK26j4hDL42JbLAeZDVp-ntf1LJer=O1vFyW9MLFOw@mail.gmail.com>
References: <CAFT_Lc3q+23CudsS5Sre3Ck9dehro2r2YMyJ06gLXYfhH1KVhQ@mail.gmail.com>	<003001cd01df$290c7730$7b256590$@msu.edu>
	<CAFT_Lc26NK26j4hDL42JbLAeZDVp-ntf1LJer=O1vFyW9MLFOw@mail.gmail.com>
Message-ID: <002f01cd02ac$300951c0$901bf540$@msu.edu>

Junyan,

Hofmann et al. (2000) and Raudenbush & Bryk (2002) both specifically say
that level 2 residuals are supposed to be independent in a 2-level model.
So, I think it is very important to directly test that assumption and modify
the model to account for autocorrelation if it is present. It may not always
make a huge difference in practice, but I consider that the conceptually
appropriate way to proceed. Ultimately geostatistical models performed
better than adding a conditional autoregressive (CAR) structure to a
traditional multilevel model in my own work. 

My dissertation (Pierce, 2010) was contrasting different ways of modeling
neighborhood effects on residents and lays out an argument for why
geostatistical approaches may be better tools than traditional multilevel
models for answering some kinds of questions. I used an exact Moran's I test
for regression residuals to detect autocorrelation in level 2 residuals in
my own work (see Bivand, Pebesma, & Gomez-Rubio, 2008, pp. 258-264 and the
lm.morantest.exact function from the spdep package in R). In terms of
software, I used a combination of R and WinBUGS to run my multilevel models
because I wanted to use Bayesian methods as similar as possible to the
geostatistical models implemented in the spBayes package. WinBUGS did the
real estimation work, but I used R for data management, calling WinBUGS,
then post-processing the WinBUGS results. 

Bivand, R. S., Pebesma, E. J., & G?mez-Rubio, V. (2008). Applied spatial
data analysis with R. New York, NY: Springer Science+Business Media.

Hofmann, D. A., Griffin, M. A., & Gavin, M. B. (2000). The application of
hierarchical linear modeling to organizational research. In K. J. Klein & S.
W. J. Kozlowski (Eds.), Multilevel theory, research, and methods in
organizations: Foundations, extensions, and new directions (pp. 467-511).
San Francisco, CA: Jossey-Bass.

Pierce, S. J. (2010). Using geostatistical models to study neighborhood
effects: An alternative to hierarchical linear models. (Doctoral
dissertation).  Available from ProQuest Dissertations and Theses database.
(UMI No. 3417821)
https://www.msu.edu/~pierces1/S_Pierce_Final_Dissertation_2010.pdf 

Raudenbush, S. W., & Bryk, A. S. (2002). Hierarchical linear models:
Applications and data analysis methods (2nd ed.). Thousand Oaks, CA: Sage
Publications.

Regards,

Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Junyan Luo [mailto:jzl106 at gmail.com] 
Sent: Wednesday, March 14, 2012 9:16 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] No need to handle between-group correlation
structure in glmm in general?

Hi Dr. Pierce,

Thanks for the reply! And the information you provided is very useful!
Do you know if any existing R tools can handle this type of analysis?

The suggestion of comparing model fit is a good idea, but probably a
more important issue is whether the presence of correlated random
effects biases the parameter estimation. I am aware of a few test
techniques related to this, but totally unsure about their
implications. For example, is it a good idea to perform Moran's I test
on the second level residuals? (Or random effects directly?) A more
important question is, if Moran's I suggests autocorrelation in second
level residuals, would it be corrected by incorporating an correlation
structure for random effects?

REGARDS,
Junyan

On Wed, Mar 14, 2012 at 8:37 AM, Steven J. Pierce <pierces1 at msu.edu> wrote:
> The best thing to do would be to empirically test whether modeling the
> spatial autocorrelation in the level 2 random effects improves model fit
> compared with a simpler model that assumes independence of those random
> effects. In my dissertation work, adding spatial autocorrelation at level
2
> improved a model (but not dramatically).
>
> Check out the following resources:
>
> Beard, J. R. (2008). New approaches to multilevel analysis. Journal of
Urban
> Health, 85(6), 805-806. doi: 10.1007/s11524-008-9314-7
>
> Browne, W., & Goldstein, H. (2010). MCMC sampling for a multilevel model
> with non-independent residuals within and between cluster units. Journal
of
> Educational and Behavioral Statistics, 35(4), 453-473. doi:
> 10.3102/1076998609359788
>
> Chaix, B., Leyland, A. H., Sabel, C. E., Chauvin, P., R?stam, L.,
> Kristersson, H., & Merlo, J. (2006). Spatial clustering of mental
disorders
> and associated characteristics of the neighbourhood context in Malm?,
> Sweden, in 2001. Journal of Epidemiology and Community Health, 60(5),
> 427-435. doi: 10.1136/jech.2005.040360
>
> Chaix, B., Merlo, J., & Chauvin, P. (2005). Comparison of a spatial
approach
> with the multilevel approach for investigating place effects on health:
The
> example of healthcare utilisation in France. Journal of Epidemiology and
> Community Health, 59(6), 517-526. doi: 10.1136/jech.2004.025478
>
> Chaix, B., Merlo, J., Evans, D., Leal, C., & Havard, S. (2009).
> Neighborhoods in eco-epidemiologic research: Delimiting personal exposure
> areas. A response to Riva, Gauvin, Apparicio and Brodeur. Social Science &
> Medicine, 69(9), 1306-1310. doi: 10.1016/j.socscimed.2009.07.018
>
> Chaix, B., Merlo, J., Subramanian, S. V., Lynch, J., & Chauvin, P. (2005).
> Comparison of a spatial perspective with the multilevel analytical
approach
> in neighborhood studies: The case of mental and behavioral disorders due
to
> psychoactive substance use in Malm?, Sweden, 2001. American Journal of
> Epidemiology, 162(2), 171-182. doi: 10.1093/aje/kwi175
>
> Fagg, J., Curtis, S., Clark, C., Congdon, P., & Stansfeld, S. A. (2008).
> Neighbourhood perceptions among inner-city adolescents: Relationships with
> their individual characteristics and with independently assessed
> neighbourhood conditions. Journal of Environmental Psychology, 28(2),
> 128-142. doi: 10.1016/j.jenvp.2007.10.004
>
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Junyan Luo [mailto:jzl106 at gmail.com]
> Sent: Tuesday, March 13, 2012 7:33 PM
> To: R-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] No need to handle between-group correlation structure
in
> glmm in general?
>
> Hi,
> Recently I have been working with a data set that contains individual
> samples from a set of connected geographical areal units. While I plan
> to use glmm to model the data with individuals as the 1st level units
> and the areal units as the 2nd level units, I am concerned with the
> potential spatial autocorrelation among the geographical areal units
> (i.e., at the second level). It is reasonable to think that the random
> effects at the second level will be spatial autocorrelated. I know
> nlme has the option to specify "within-group" correlation structure,
> but I couldn't figure out a way to specify "between-group"
> correlations structure for the geographical areal units.
>
> However, one of my colleagues told me it was totally unnecessary to
> specify a correlation structure at the second level. This is because
> the two assumptions of multi-level models are (1) the individual error
> term is independent; (2) the individual error term is uncorrelated
> with the random effects. It does NOT assume that the random effects
> should be independent. So unless (2) is violated, generally we don't
> need to worry about autocorrelation in the random effects. That's
> probably why nlme only has the option for specifying "within-group"
> correlation structure. I feel the assessment is reasonable, but I am
> unsure if that is correct. Can anybody help me clarify this? Thanks!
>
>
>



From bates at stat.wisc.edu  Thu Mar 15 16:43:34 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Mar 2012 10:43:34 -0500
Subject: [R-sig-ME] help with lme4
In-Reply-To: <CABTnRNBfR5++5=cP0J87D9yWhwRzZk8wtg687Fj4XhAC9sM5JA@mail.gmail.com>
References: <CABTnRNBfR5++5=cP0J87D9yWhwRzZk8wtg687Fj4XhAC9sM5JA@mail.gmail.com>
Message-ID: <CAO7JsnRCisxhjSBmHWAjzT6KX-JB9WA63z=Z5DyFxV1gudNa9g@mail.gmail.com>

On Thu, Mar 15, 2012 at 10:35 AM, S?bastien Bonthoux
<bonthoux.sebastien at gmail.com> wrote:
> Dear D.Bates,
> I am using your package lme4 and the function lmer(). I link a metric of
> ecological community specialisation (gaussian distribution) with several
> land use variables and I add a random intercept because my plots are
> clustered. Can you explain me why I obtain a negative deviance (positive
> logLik) ? Is there any problem ?

Generally it is best to send questions like this to the
R-SIG-Mixed-Models at R-project.org mailing list (see instructions at
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models).  Many of
those who read that list can reply and often much faster than I am
able to.

The short answer to your question is that a negative deviance for a
model with a response measured on a continuous scale is not a problem.
 Probability mass functions for discrete random variables cannot
exceed 1 but probability density functions for continuous random
variables can.  Thus the log-likelihood for a continuous response can
be positive and the deviance negative.

> Thank you for you reply.
> Best regards
>
> --
> S?bastien Bonthoux
>
> Docteur en Ecologie - PhD in Ecology
>
> 02 54 78 05 74
> Ecole Nationale Sup?rieure de la Nature et du Paysage
> 9 rue de la chocolaterie
> 41 000 Blois
>
>
>



From chantepie at mnhn.fr  Thu Mar 15 17:22:28 2012
From: chantepie at mnhn.fr (Stephane Chantepie)
Date: Thu, 15 Mar 2012 17:22:28 +0100
Subject: [R-sig-ME] Bivariate animal models with both "ill-conditioned
	G/R structure" and "Mixed model equations singular" errors
In-Reply-To: <20120311092028.13357jqqer7t0k08@www.staffmail.ed.ac.uk>
References: <20120309103342.12781g5xk16y0gom@dsiwebmail.mnhn.fr>
	<20120309173352.168215srxwe8241c@dsiwebmail.mnhn.fr>
	<20120311092028.13357jqqer7t0k08@www.staffmail.ed.ac.uk>
Message-ID: <201203151722.28254.chantepie@mnhn.fr>

Dear all,

I have tried the different solutions you proposed.

I have tried to scale fixed parameters and the response variables between 0 
and 1 but the problem remained

However, using ASREML, it seems that the problem comes from the residual 
covariance matrix. As supposed by Jarrod the residual covariance matrix is 
singular. I am pretty sure that it is due the structure of my data but I 
really don't know how I can fix this problem.


I use several age classes (which represent my traits) and I have intra-annual 
repeated measurements for several years and for each individual. 
The fixed parameters I use are: 
-tse : time since the last ejaculation collect: it is used to take into 
account the pressure due to the repeated collect.
-joe : day of ejaculation : represents the time since the first ejaculation of 
the year. I use this parameter to take into account the seasonal variation of 
sperm production.
The model is AgeClass1 AgeClass2 ~ at.level(trait,1): tse+ at.level(trait,2): 
tse+ at.level(trait,1): joe + at.level(trait,2): joe, 
random=~us(trait):animal+us(trait):ID+us(trait):Year, rcov = ~us(trait):units


With the data structure I have, it is impossible to have measurements of the 
same individual on the same line (snapshot to help comprehension: 
http://ubuntuone.com/1W19vErC5jUtHqMn1dtmPg ), likely making it impossible to 
estimate a residual covariance. One of the issues is that I can not see really 
how to change the structure of the data so it?s estimable. 
Is there a solution? I?m afraid if I fix the residuals covariance matrix to 0, 
I will inflate Va.

Do you have an idea?

many thanks for your help

stephane



From bates at stat.wisc.edu  Thu Mar 15 22:54:18 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Mar 2012 16:54:18 -0500
Subject: [R-sig-ME] Package name changes on the SVN repository at
	lme4.R-forge.R-project.org
Message-ID: <CAO7JsnTbBT1BpooRA-emEz7gVFJZyZYmq0BLrc6f+iNYMRBGPA@mail.gmail.com>

This message is only important to those who follow the development
version of the lme4 package at its R-forge SVN repository.

The released version of lme4 is now called lme4.0 and the development
version that was called lme4Eigen is now called lme4.  As the new lme4
gains stability we will release the old version to CRAN as lme4.0

The reason for keeping the old version available as lme4.0 is because
of other software and some publications that depend on the structure
and component or slot names from that package.



From Mike.Lawrence at dal.ca  Fri Mar 16 13:32:54 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 16 Mar 2012 09:32:54 -0300
Subject: [R-sig-ME] multicore lmer: any changes since 2007?
In-Reply-To: <4E149E29.10006@gmail.com>
References: <CAB+QPJB7b8qYrHs1O7crK6kTiEoCHixdonVFw2kN9qTPCLsgjw@mail.gmail.com>
	<CAO7JsnSGENOn9uKtuH45Q916QA_yNH4BSEvAg8ZynY+sk3Ex2g@mail.gmail.com>
	<CAB+QPJCGVO=4kR4V6f7dCNs=QqLUjA40H3b7UGHC3ZzxbJ+6Gg@mail.gmail.com>
	<4E149E29.10006@gmail.com>
Message-ID: <CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>

Apologies for resurrecting a months-old thread, but I thought I'd note
that DEoptim has now been made parallel:

http://blog.fosstrading.com/2012/03/deoptim-in-parallel.html


On Wed, Jul 6, 2011 at 2:40 PM, Ben Bolker <bbolker at gmail.com> wrote:
> On 07/06/2011 11:40 AM, Mike Lawrence wrote:
>> Thanks for the detailed reply.
>>
>> According to the comment by Joshua Ulrich (one of the DEoptim
>> developers) on this stackoverflow post
>> (http://stackoverflow.com/questions/3759878/parallel-optimization-in-r),
>> it seems that DEoptim might be a parallel-izable optimizer, and as I
>> recall you can put box constraints on parameters with DEoptim. I just
>> sent off an email to the DEoptim developers to see if there's been any
>> progress on the parallel front.
>>
>> Mike
>
> ?I have used differential evolution in the past (although not in
> decades (!!)), although not the DEoptim() package, but I don't think
> DEoptim() will be appropriate for this purpose. ?I'm actually not
> entirely clear on what DB means by "parallel evaluation of the objective
> function". ?In the simplest derivative-free case for example (the
> Nelder-Mead simplex), it's hard to see how one could evaluate the
> objective function in parallel because each evaluation changes the
> structure of the simplex and determines where the next evaluation should
> be. ?A very quick look at BOBYQA (source code in the minqa package, or
> formal description at
> <http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf>) suggests
> the same one-point-at-a-time updating scheme.
>
> ?But DB says
>
>>> In many cases you know several points where you will be
>>> evaluating the objective so you could split those
>>> off into different threads.
>
> ?Since he has (probably literally) forgotten more about numerical
> computation than I ever knew, he's probably right, but I don't know of
> those examples.
>
> ?Interesting discussion ...
>
>
>>
>> On Wed, Jul 6, 2011 at 11:59 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> On Tue, Jul 5, 2011 at 4:52 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>> Back in 2007 (http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17777.html)
>>>> Dr. Bates suggested that using a multithreaded BLAS was the only
>>>> option for speeding lmer computations on multicore machines (and even
>>>> then, it might even cause a slow down under some circumstances).
>>>>
>>>> Is this advice still current, or have other means of speeding lmer
>>>> computations on multicore machines arisen in more recent years?
>>>
>>> As always, the problem with trying to parallelize a particular
>>> calculation is to determine how and when to start more than one
>>> thread.
>>>
>>> After the setup stage the calculations in fitting an lmer model
>>> involve optimizing the profiled deviance or profiled REML criterion.
>>> Each evaluation of the criterion involves updating the components of
>>> the relative covariance factor, updating the sparse Cholesky
>>> decomposition and solving a couple of systems of equations involving
>>> the sparse Cholesky factor.
>>>
>>> There are a couple of calculations involving dense matrices but in
>>> most cases the time spent on them is negligible relative to the
>>> calculations involving the sparse matrices.
>>>
>>> A multithreaded BLAS will only help speed up the calculations on dense
>>> matrices. ?The "supernodal" form of the Cholesky factorization can use
>>> the BLAS for some calculations but usually on small blocks. ?Most of
>>> the time the software chooses the "simplicial" form of the
>>> factorization because the supernodal form would not be efficient and
>>> the simplicial form doesn't use the BLAS at all. ?Even if the
>>> supernodal form is chosen, the block sizes are usually small and a
>>> multithreaded BLAS can actually slow down operations on small blocks
>>> because the communication and synchronization overhead cancels out any
>>> gain from using multiple cores.
>>>
>>> Of course, your mileage may vary and only by profiling both the R code
>>> and the compiled code will you be able to determine how things could
>>> be sped up.
>>>
>>> If I had to guess, I would say that the best hope for parallelizing
>>> the computation would be to find an optimizer that allows for parallel
>>> evaluation of the objective function. ?The lme4 package requires
>>> optimization of a nonlinear objective subject to "box constraints"
>>> (meaning that some of the parameters can have upper and/or lower
>>> bounds). ?Actually it is simpler than that, some of the parameters
>>> must be positive. ?We do not provide gradient evaluations. ?I once*
>>> worked out the gradient of the criterion (I think it was the best
>>> mathematics I ever did) and then found that it ended up slowing the
>>> optimization to a crawl in the difficult cases. ?A bit of reflection
>>> showed that each evaluation of the gradient could be hundreds or
>>> thousands of times more complex than an evaluation of the objective
>>> itself so you might as well use a gradient free method and just do
>>> more function evaluations. ?In many cases you know several points
>>> where you will be evaluating the objective so you could split those
>>> off into different threads.
>>>
>>> I don't know of such a mulithreaded optimizer (many of the optimizers
>>> that I find are still being written in Fortran 77, God help us) but
>>> that would be my best bet if one could be found. ?However, I am saying
>>> this without having done the profiling of the calculation myself so
>>> that is still a guess.
>>>
>>> * Bates and DebRoy, "Linear mixed models and penalized least squares",
>>> Journal of Multivariate Analysis, 91 (2004) 1-17
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Mike.Lawrence at dal.ca  Fri Mar 16 14:14:02 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 16 Mar 2012 10:14:02 -0300
Subject: [R-sig-ME] multicore lmer: any changes since 2007?
In-Reply-To: <CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>
References: <CAB+QPJB7b8qYrHs1O7crK6kTiEoCHixdonVFw2kN9qTPCLsgjw@mail.gmail.com>
	<CAO7JsnSGENOn9uKtuH45Q916QA_yNH4BSEvAg8ZynY+sk3Ex2g@mail.gmail.com>
	<CAB+QPJCGVO=4kR4V6f7dCNs=QqLUjA40H3b7UGHC3ZzxbJ+6Gg@mail.gmail.com>
	<4E149E29.10006@gmail.com>
	<CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>
Message-ID: <CAB+QPJBzRzkRc8=UxPBXpvLOXq4Zo91bJm189uCQEv7FkM8dHg@mail.gmail.com>

Oh, and here's a gist showing how to use it using doMC for those of us
on unix systems:
https://gist.github.com/2050019


On Fri, Mar 16, 2012 at 9:32 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Apologies for resurrecting a months-old thread, but I thought I'd note
> that DEoptim has now been made parallel:
>
> http://blog.fosstrading.com/2012/03/deoptim-in-parallel.html
>
>
> On Wed, Jul 6, 2011 at 2:40 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> On 07/06/2011 11:40 AM, Mike Lawrence wrote:
>>> Thanks for the detailed reply.
>>>
>>> According to the comment by Joshua Ulrich (one of the DEoptim
>>> developers) on this stackoverflow post
>>> (http://stackoverflow.com/questions/3759878/parallel-optimization-in-r),
>>> it seems that DEoptim might be a parallel-izable optimizer, and as I
>>> recall you can put box constraints on parameters with DEoptim. I just
>>> sent off an email to the DEoptim developers to see if there's been any
>>> progress on the parallel front.
>>>
>>> Mike
>>
>> ?I have used differential evolution in the past (although not in
>> decades (!!)), although not the DEoptim() package, but I don't think
>> DEoptim() will be appropriate for this purpose. ?I'm actually not
>> entirely clear on what DB means by "parallel evaluation of the objective
>> function". ?In the simplest derivative-free case for example (the
>> Nelder-Mead simplex), it's hard to see how one could evaluate the
>> objective function in parallel because each evaluation changes the
>> structure of the simplex and determines where the next evaluation should
>> be. ?A very quick look at BOBYQA (source code in the minqa package, or
>> formal description at
>> <http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf>) suggests
>> the same one-point-at-a-time updating scheme.
>>
>> ?But DB says
>>
>>>> In many cases you know several points where you will be
>>>> evaluating the objective so you could split those
>>>> off into different threads.
>>
>> ?Since he has (probably literally) forgotten more about numerical
>> computation than I ever knew, he's probably right, but I don't know of
>> those examples.
>>
>> ?Interesting discussion ...
>>
>>
>>>
>>> On Wed, Jul 6, 2011 at 11:59 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>>> On Tue, Jul 5, 2011 at 4:52 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>>> Back in 2007 (http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17777.html)
>>>>> Dr. Bates suggested that using a multithreaded BLAS was the only
>>>>> option for speeding lmer computations on multicore machines (and even
>>>>> then, it might even cause a slow down under some circumstances).
>>>>>
>>>>> Is this advice still current, or have other means of speeding lmer
>>>>> computations on multicore machines arisen in more recent years?
>>>>
>>>> As always, the problem with trying to parallelize a particular
>>>> calculation is to determine how and when to start more than one
>>>> thread.
>>>>
>>>> After the setup stage the calculations in fitting an lmer model
>>>> involve optimizing the profiled deviance or profiled REML criterion.
>>>> Each evaluation of the criterion involves updating the components of
>>>> the relative covariance factor, updating the sparse Cholesky
>>>> decomposition and solving a couple of systems of equations involving
>>>> the sparse Cholesky factor.
>>>>
>>>> There are a couple of calculations involving dense matrices but in
>>>> most cases the time spent on them is negligible relative to the
>>>> calculations involving the sparse matrices.
>>>>
>>>> A multithreaded BLAS will only help speed up the calculations on dense
>>>> matrices. ?The "supernodal" form of the Cholesky factorization can use
>>>> the BLAS for some calculations but usually on small blocks. ?Most of
>>>> the time the software chooses the "simplicial" form of the
>>>> factorization because the supernodal form would not be efficient and
>>>> the simplicial form doesn't use the BLAS at all. ?Even if the
>>>> supernodal form is chosen, the block sizes are usually small and a
>>>> multithreaded BLAS can actually slow down operations on small blocks
>>>> because the communication and synchronization overhead cancels out any
>>>> gain from using multiple cores.
>>>>
>>>> Of course, your mileage may vary and only by profiling both the R code
>>>> and the compiled code will you be able to determine how things could
>>>> be sped up.
>>>>
>>>> If I had to guess, I would say that the best hope for parallelizing
>>>> the computation would be to find an optimizer that allows for parallel
>>>> evaluation of the objective function. ?The lme4 package requires
>>>> optimization of a nonlinear objective subject to "box constraints"
>>>> (meaning that some of the parameters can have upper and/or lower
>>>> bounds). ?Actually it is simpler than that, some of the parameters
>>>> must be positive. ?We do not provide gradient evaluations. ?I once*
>>>> worked out the gradient of the criterion (I think it was the best
>>>> mathematics I ever did) and then found that it ended up slowing the
>>>> optimization to a crawl in the difficult cases. ?A bit of reflection
>>>> showed that each evaluation of the gradient could be hundreds or
>>>> thousands of times more complex than an evaluation of the objective
>>>> itself so you might as well use a gradient free method and just do
>>>> more function evaluations. ?In many cases you know several points
>>>> where you will be evaluating the objective so you could split those
>>>> off into different threads.
>>>>
>>>> I don't know of such a mulithreaded optimizer (many of the optimizers
>>>> that I find are still being written in Fortran 77, God help us) but
>>>> that would be my best bet if one could be found. ?However, I am saying
>>>> this without having done the profiling of the calculation myself so
>>>> that is still a guess.
>>>>
>>>> * Bates and DebRoy, "Linear mixed models and penalized least squares",
>>>> Journal of Multivariate Analysis, 91 (2004) 1-17
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Mar 16 15:45:53 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 16 Mar 2012 09:45:53 -0500
Subject: [R-sig-ME] multicore lmer: any changes since 2007?
In-Reply-To: <CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>
References: <CAB+QPJB7b8qYrHs1O7crK6kTiEoCHixdonVFw2kN9qTPCLsgjw@mail.gmail.com>
	<CAO7JsnSGENOn9uKtuH45Q916QA_yNH4BSEvAg8ZynY+sk3Ex2g@mail.gmail.com>
	<CAB+QPJCGVO=4kR4V6f7dCNs=QqLUjA40H3b7UGHC3ZzxbJ+6Gg@mail.gmail.com>
	<4E149E29.10006@gmail.com>
	<CAB+QPJAj-rx7hV+M9YiKDnGnrp38SL+Yf1BjfOrzheXX_nS2vg@mail.gmail.com>
Message-ID: <CAO7JsnSnKEGfTuzBgs9kRtgpVrT1K4R=epp1hn6dNedXhGf=dw@mail.gmail.com>

On Fri, Mar 16, 2012 at 7:32 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Apologies for resurrecting a months-old thread, but I thought I'd note
> that DEoptim has now been made parallel:
>
> http://blog.fosstrading.com/2012/03/deoptim-in-parallel.html

Before trying any of the options for speeding up execution one should
first profile the execution ("profile" in the sense of Rprof and
profiling the underlying compiled code).  My guess is that the
calculations in the optimizer algorithm are not the bottleneck, it is
the evaluation of the deviance that takes the time.

Recently I switched to using the Google perftools
(http://code.google.com/p/gperftools/) for malloc/free to get a better
handle on potential memory errors in the development process.  It
should be possible to use the profiling of the compiled code from the
perftools too.

> On Wed, Jul 6, 2011 at 2:40 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> On 07/06/2011 11:40 AM, Mike Lawrence wrote:
>>> Thanks for the detailed reply.
>>>
>>> According to the comment by Joshua Ulrich (one of the DEoptim
>>> developers) on this stackoverflow post
>>> (http://stackoverflow.com/questions/3759878/parallel-optimization-in-r),
>>> it seems that DEoptim might be a parallel-izable optimizer, and as I
>>> recall you can put box constraints on parameters with DEoptim. I just
>>> sent off an email to the DEoptim developers to see if there's been any
>>> progress on the parallel front.
>>>
>>> Mike
>>
>> ?I have used differential evolution in the past (although not in
>> decades (!!)), although not the DEoptim() package, but I don't think
>> DEoptim() will be appropriate for this purpose. ?I'm actually not
>> entirely clear on what DB means by "parallel evaluation of the objective
>> function". ?In the simplest derivative-free case for example (the
>> Nelder-Mead simplex), it's hard to see how one could evaluate the
>> objective function in parallel because each evaluation changes the
>> structure of the simplex and determines where the next evaluation should
>> be. ?A very quick look at BOBYQA (source code in the minqa package, or
>> formal description at
>> <http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf>) suggests
>> the same one-point-at-a-time updating scheme.
>>
>> ?But DB says
>>
>>>> In many cases you know several points where you will be
>>>> evaluating the objective so you could split those
>>>> off into different threads.
>>
>> ?Since he has (probably literally) forgotten more about numerical
>> computation than I ever knew, he's probably right, but I don't know of
>> those examples.
>>
>> ?Interesting discussion ...
>>
>>
>>>
>>> On Wed, Jul 6, 2011 at 11:59 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>>> On Tue, Jul 5, 2011 at 4:52 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>>> Back in 2007 (http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17777.html)
>>>>> Dr. Bates suggested that using a multithreaded BLAS was the only
>>>>> option for speeding lmer computations on multicore machines (and even
>>>>> then, it might even cause a slow down under some circumstances).
>>>>>
>>>>> Is this advice still current, or have other means of speeding lmer
>>>>> computations on multicore machines arisen in more recent years?
>>>>
>>>> As always, the problem with trying to parallelize a particular
>>>> calculation is to determine how and when to start more than one
>>>> thread.
>>>>
>>>> After the setup stage the calculations in fitting an lmer model
>>>> involve optimizing the profiled deviance or profiled REML criterion.
>>>> Each evaluation of the criterion involves updating the components of
>>>> the relative covariance factor, updating the sparse Cholesky
>>>> decomposition and solving a couple of systems of equations involving
>>>> the sparse Cholesky factor.
>>>>
>>>> There are a couple of calculations involving dense matrices but in
>>>> most cases the time spent on them is negligible relative to the
>>>> calculations involving the sparse matrices.
>>>>
>>>> A multithreaded BLAS will only help speed up the calculations on dense
>>>> matrices. ?The "supernodal" form of the Cholesky factorization can use
>>>> the BLAS for some calculations but usually on small blocks. ?Most of
>>>> the time the software chooses the "simplicial" form of the
>>>> factorization because the supernodal form would not be efficient and
>>>> the simplicial form doesn't use the BLAS at all. ?Even if the
>>>> supernodal form is chosen, the block sizes are usually small and a
>>>> multithreaded BLAS can actually slow down operations on small blocks
>>>> because the communication and synchronization overhead cancels out any
>>>> gain from using multiple cores.
>>>>
>>>> Of course, your mileage may vary and only by profiling both the R code
>>>> and the compiled code will you be able to determine how things could
>>>> be sped up.
>>>>
>>>> If I had to guess, I would say that the best hope for parallelizing
>>>> the computation would be to find an optimizer that allows for parallel
>>>> evaluation of the objective function. ?The lme4 package requires
>>>> optimization of a nonlinear objective subject to "box constraints"
>>>> (meaning that some of the parameters can have upper and/or lower
>>>> bounds). ?Actually it is simpler than that, some of the parameters
>>>> must be positive. ?We do not provide gradient evaluations. ?I once*
>>>> worked out the gradient of the criterion (I think it was the best
>>>> mathematics I ever did) and then found that it ended up slowing the
>>>> optimization to a crawl in the difficult cases. ?A bit of reflection
>>>> showed that each evaluation of the gradient could be hundreds or
>>>> thousands of times more complex than an evaluation of the objective
>>>> itself so you might as well use a gradient free method and just do
>>>> more function evaluations. ?In many cases you know several points
>>>> where you will be evaluating the objective so you could split those
>>>> off into different threads.
>>>>
>>>> I don't know of such a mulithreaded optimizer (many of the optimizers
>>>> that I find are still being written in Fortran 77, God help us) but
>>>> that would be my best bet if one could be found. ?However, I am saying
>>>> this without having done the profiling of the calculation myself so
>>>> that is still a guess.
>>>>
>>>> * Bates and DebRoy, "Linear mixed models and penalized least squares",
>>>> Journal of Multivariate Analysis, 91 (2004) 1-17
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From gregoror at googlemail.com  Fri Mar 16 12:02:24 2012
From: gregoror at googlemail.com (Gregor Didenko)
Date: Fri, 16 Mar 2012 12:02:24 +0100
Subject: [R-sig-ME] With glmmPQL Error in corFactor.corSpatial(object)
Message-ID: <CAKqOgbeQi3HvKMrRHCipD2_BXQt=MsOsZ2C-+z2qOKRkL0Hsmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120316/f21d6ed9/attachment-0002.pl>

From slu at ccsr.uchicago.edu  Fri Mar 16 23:38:15 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Fri, 16 Mar 2012 17:38:15 -0500
Subject: [R-sig-ME] Unacceptibly high autocorrelation in MCMCglmm
Message-ID: <1331937495.455.18.camel@localhost>

Hello, I'm running this ordered category outcome model:

glme5.very.len <- MCMCglmm(very.len.summative.o ~ 1 ,
                   prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0) )),
                   random = ~emplid + deptid + grade.f + subject.f ,
                   family = "ordinal",
                   nitt=300000,
                   data = summative.ratings.prin.yr1.full)

I ran it first with nitt=100000 but had very high autocorrelations and
non-sensical variance components and fixed effects, so I increased nitt
to 200000 and then to 300000 but got no change. Here's the summary
output:

 summary(glme5.very.len)

 Iterations = 3001:299991
 Thinning interval  = 10
 Sample size  = 29700 

 DIC: -13239.32 

 G-structure:  ~emplid

       post.mean  l-95% CI u-95% CI eff.samp
emplid     405.3 1.493e-11     1106    7.909

               ~deptid

       post.mean  l-95% CI u-95% CI eff.samp
deptid     131.8 1.118e-16    475.2    42.65

               ~grade.f

        post.mean  l-95% CI u-95% CI eff.samp
grade.f    0.9143 1.405e-17    1.575    15784

               ~subject.f

          post.mean  l-95% CI u-95% CI eff.samp
subject.f     1.633 1.951e-17    2.748    10101

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: very.len.summative.o ~ 1 

            post.mean l-95% CI u-95% CI eff.samp  pMCMC    
(Intercept)    29.007    2.091   54.969    2.381 <3e-05 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

 Cutpoints: 
                                     post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitvery.len.summative.o.1     14.06   0.8102    27.38    9.382
cutpoint.traitvery.len.summative.o.2     40.34   2.9611    76.04    2.694

Here are some of the autocorrs:

 autocorr(glme5.very.len$VCV)
, , emplid

           emplid    deptid    grade.f  subject.f units
Lag 0   1.0000000 0.5860851 0.04668197 0.06081864   NaN
Lag 10  0.9514313 0.6132116 0.04345287 0.05652945   NaN
Lag 50  0.9459831 0.6259477 0.04881253 0.06093640   NaN
Lag 100 0.9433509 0.6282599 0.04492884 0.06037288   NaN
Lag 500 0.9267886 0.6373151 0.03873992 0.05371885   NaN

, , deptid

           emplid    deptid    grade.f  subject.f units
Lag 0   0.5860851 1.0000000 0.03070680 0.03453008   NaN
Lag 10  0.6137187 0.7579551 0.03233992 0.04139315   NaN
Lag 50  0.6255810 0.7169468 0.02903334 0.03960446   NaN
Lag 100 0.6269979 0.7029498 0.03244468 0.04857241   NaN
Lag 500 0.6322900 0.6650247 0.04049514 0.04306019   NaN

Is there a problem in my data or in the model?

Thank you.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
Benjamin Lloyd-Hughes: Has anyone had any joy
 getting the rgdal package to compile under
<windows? Roger Bivand: The closest anyone has got 
 so far is Hisaji Ono, who used MSYS
 (http://www.mingw.org/) to build PROJ.4 and GDAL
 (GDAL depends on PROJ.4, PROJ.4 needs a PATH to
 metadata files for projection and transformation),
 and then hand-pasted the paths to the GDAL headers
 and library into src/Makevars, running Rcmd



From j.hadfield at ed.ac.uk  Sat Mar 17 11:29:16 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 17 Mar 2012 10:29:16 +0000
Subject: [R-sig-ME] Unacceptibly high autocorrelation in MCMCglmm
In-Reply-To: <1331937495.455.18.camel@localhost>
References: <1331937495.455.18.camel@localhost>
Message-ID: <20120317102916.64036j23f48cdugw@www.staffmail.ed.ac.uk>

HI,

It looks like the probit has underflowed/overflowed - you can check  
this by saving the latent variables and looking to see whether the  
range of the absolute values exceeds 7 (See Section 8.08 of  
CourseNotes).

This can happen with weak priors and (near) complete separation and/or  
with weak priors for effects that are heavily confounded.

I'm not sure how to proceed with underflow/overflow problems  
generally.  I could terminate the procedure, or I could truncate the  
latent variables at their overflow/underflow points. The latter is  
used by some WinBUGS users, but then WinBUGS handles the fact that the  
response is from a truncated normal not a normal - something which  
would be hard to program in MCMCglmm. Any thoughts would be useful.

Cheers,

Jarrod



Quoting Stuart Luppescu <slu at ccsr.uchicago.edu> on Fri, 16 Mar 2012  
17:38:15 -0500:

> Hello, I'm running this ordered category outcome model:
>
> glme5.very.len <- MCMCglmm(very.len.summative.o ~ 1 ,
>                    prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
> nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0) )),
>                    random = ~emplid + deptid + grade.f + subject.f ,
>                    family = "ordinal",
>                    nitt=300000,
>                    data = summative.ratings.prin.yr1.full)
>
> I ran it first with nitt=100000 but had very high autocorrelations and
> non-sensical variance components and fixed effects, so I increased nitt
> to 200000 and then to 300000 but got no change. Here's the summary
> output:
>
>  summary(glme5.very.len)
>
>  Iterations = 3001:299991
>  Thinning interval  = 10
>  Sample size  = 29700
>
>  DIC: -13239.32
>
>  G-structure:  ~emplid
>
>        post.mean  l-95% CI u-95% CI eff.samp
> emplid     405.3 1.493e-11     1106    7.909
>
>                ~deptid
>
>        post.mean  l-95% CI u-95% CI eff.samp
> deptid     131.8 1.118e-16    475.2    42.65
>
>                ~grade.f
>
>         post.mean  l-95% CI u-95% CI eff.samp
> grade.f    0.9143 1.405e-17    1.575    15784
>
>                ~subject.f
>
>           post.mean  l-95% CI u-95% CI eff.samp
> subject.f     1.633 1.951e-17    2.748    10101
>
>  R-structure:  ~units
>
>       post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
>
>  Location effects: very.len.summative.o ~ 1
>
>             post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)    29.007    2.091   54.969    2.381 <3e-05 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>  Cutpoints:
>                                      post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitvery.len.summative.o.1     14.06   0.8102    27.38    9.382
> cutpoint.traitvery.len.summative.o.2     40.34   2.9611    76.04    2.694
>
> Here are some of the autocorrs:
>
>  autocorr(glme5.very.len$VCV)
> , , emplid
>
>            emplid    deptid    grade.f  subject.f units
> Lag 0   1.0000000 0.5860851 0.04668197 0.06081864   NaN
> Lag 10  0.9514313 0.6132116 0.04345287 0.05652945   NaN
> Lag 50  0.9459831 0.6259477 0.04881253 0.06093640   NaN
> Lag 100 0.9433509 0.6282599 0.04492884 0.06037288   NaN
> Lag 500 0.9267886 0.6373151 0.03873992 0.05371885   NaN
>
> , , deptid
>
>            emplid    deptid    grade.f  subject.f units
> Lag 0   0.5860851 1.0000000 0.03070680 0.03453008   NaN
> Lag 10  0.6137187 0.7579551 0.03233992 0.04139315   NaN
> Lag 50  0.6255810 0.7169468 0.02903334 0.03960446   NaN
> Lag 100 0.6269979 0.7029498 0.03244468 0.04857241   NaN
> Lag 500 0.6322900 0.6650247 0.04049514 0.04306019   NaN
>
> Is there a problem in my data or in the model?
>
> Thank you.
>
> --
> Stuart Luppescu -=- slu .at. ccsr.uchicago.edu
> University of Chicago -=- CCSR
> ???????? -=-    Kernel 3.2.1-gentoo-r2
> Benjamin Lloyd-Hughes: Has anyone had any joy
>  getting the rgdal package to compile under
> <windows? Roger Bivand: The closest anyone has got
>  so far is Hisaji Ono, who used MSYS
>  (http://www.mingw.org/) to build PROJ.4 and GDAL
>  (GDAL depends on PROJ.4, PROJ.4 needs a PATH to
>  metadata files for projection and transformation),
>  and then hand-pasted the paths to the GDAL headers
>  and library into src/Makevars, running Rcmd
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From lucianolasala at yahoo.com.ar  Sat Mar 17 20:25:50 2012
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Sat, 17 Mar 2012 16:25:50 -0300
Subject: [R-sig-ME] Poisson GLMM: where is the deviance?
Message-ID: <000a01cd0473$c45e7fd0$4d1b7f70$@com.ar>

Dear R experts:

I need to fit the following GLMM with Poisson distribution: glmer(yobs~year
+ (year|stake), data=mibase,family=poisson)


Where "stake" (plots where the number of birds is measured) is as random
effect, and "yobs" is the abundance of birds. I need an estimation of slope
an intercept for the random term.

I specified my model as follows:

glmer(yobs~year + (year|stake), data=mibase,family=poisson)

and I get the following (it does not calculate the deviance)

? Generalized linear mixed model fit by the Laplace approximation

? Formula: yobs ~ year + (year | stake)
? ? ?Data: mibase
? ?AIC BIC logLik deviance
? ?NaN NaN ? ?NaN ? ? ?NaN

? Random effects:
? ?Groups Name ? ? ? ?Variance ? Std.Dev. ? Corr
? ?stake ?(Intercept) 1.4165e-01 0.37636766
? ? ? ? ? year ? ? ? ?3.5469e-08 0.00018833 0.000
? Number of obs: 1186, groups: stake, 63
? Fixed effects:
? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
? (Intercept) ?3.213e+01 ?6.445e+08 ? ? ? 0 ? ? ? ?1
? year ? ? ? ?-1.952e-01 ?3.225e+05 ? ? ? 0 ? ? ? ?1

- Ignored:

? Correlation of Fixed Effects:
? ? ? ?(Intr)
? year -1.000
? Mensajes de aviso perdidos
? In mer_finalize(ans) : singular convergence (7)


Q. What does this error mean and how can I solve it?

By the way, if I run the same model but only estimating the intercept of
random effects as
glmer(yobs~year + (1|stake), data=mibase,family=poisson) it seems to work
properly.


I look forward for your response and thanks in advance.

Luciana



From bbolker at gmail.com  Sat Mar 17 22:03:55 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 17 Mar 2012 21:03:55 +0000 (UTC)
Subject: [R-sig-ME] Poisson GLMM: where is the deviance?
References: <000a01cd0473$c45e7fd0$4d1b7f70$@com.ar>
Message-ID: <loom.20120317T212658-250@post.gmane.org>

Luciano La Sala <lucianolasala at ...> writes:

>
 
 [snip]

> Where "stake" (plots where the number of birds is measured) is as random
> effect, and "yobs" is the abundance of birds. I need an estimation of slope
> an intercept for the random term.
> 
> I specified my model as follows:
> 
> glmer(yobs~year + (year|stake), data=mibase,family=poisson)
> 
> and I get the following (it does not calculate the deviance)
> 
> ? Generalized linear mixed model fit by the Laplace approximation
> 
  [snip]

> Q. What does this error mean and how can I solve it?
> 
> By the way, if I run the same model but only estimating the intercept of
> random effects as
> glmer(yobs~year + (1|stake), data=mibase,family=poisson) it seems to work
> properly.

  You aren't doing anything obviously silly, that I can see.

  Can we see a str() of your data?  I wonder if your 'year' variable
got turned into a factor by mistake.

  How many stakes do you have?  If it is fewer than 5-6 you are likely
to have numerical problems ...

  When in doubt plot your data ...



From awillcor at gmail.com  Fri Mar 16 22:54:02 2012
From: awillcor at gmail.com (Andrew Correia)
Date: Fri, 16 Mar 2012 17:54:02 -0400
Subject: [R-sig-ME] Measures of dispersion for random effects
Message-ID: <CAOhHVi1QQ1ZZ_jxJB68nF1gw+22_QP3o10C1eYpCdbRNnm11DQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120316/4b589267/attachment-0002.pl>

From jwiley.psych at gmail.com  Sun Mar 18 05:35:35 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 17 Mar 2012 21:35:35 -0700
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
Message-ID: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>

Hi,

I am trying to use a multivariate mixed effects linear model to
examine mediation.  This works fine.  The final step is to compute the
indirect effect and its standard error.  The indirect effect is easy
(product of coefficients plus their covariance).  For the standard
error, I need the gradient (D) and the hessian (H):
the variance is then:

D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}

This is all given in the Appendix of
http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf

Is there a way to get this out of a mer class object?  Looking at
class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$.  @V
seems like it would give me the gradient but is null for a basic lmer
model.

Thanks,

Josh

-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From m.fairbrother at bristol.ac.uk  Sun Mar 18 14:31:04 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 18 Mar 2012 13:31:04 +0000
Subject: [R-sig-ME] modelling proportions, with aggregated data,
	and the new/old lme4
In-Reply-To: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
Message-ID: <15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>

Dear list,

I have a question for which a more theoretical or more technical answer may be helpful--I'm not sure. Any assistance would be appreciated.

I am trying to model Census data, where individual responses to a question with two answer options have been aggregated up to the community level, and communities are nested in subdistricts. So the outcome of interest is a proportion (randing from 0 to 1), and I know the absolute number of "successes" and "failures". For each community, the data are available in a slightly disaggregated form for different categories of people (I'll use the separate numbers of successes and failures for women and men as an example). Thus the data look like:

head(dat)
  successes failures id sex subdist
1       560      726  1   F       4
2       844      510  1   M       4
3       340      438  2   F       4
4       616      273  2   M       4
5         7        0  3   F       4
6         3        1  3   M       4

In community #1, which is in subdistrict #4, there are 560 women who are "successes" and 726 who are "failures" on this social indicator, etc. (The data are available via a link below.)

How should I model these data? I was originally thinking to use a binomial distribution, and a call defining the outcome as "cbind(successes, failures)", with each observation/row nested in (a) "id" and (b) "subdist".

(The idea of nesting the separate Census categories like this, and using a multilevel approach, comes from: http://www.hsph.harvard.edu/faculty/sv-subramanian/files/epa2001_33_3_399_417.pdf. There was a recent discussion of the use of "cbind" like this, but it seems workable in this case as a way to reduce tends of millions of observations to a few tens of thousands, with no loss of information: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007552.html.)

However, I gather that the binomial distribution is only appropriate where one is sampling a number of Bernoulli trials (i.e., people in this case) with replacement, making them independent. As I understand it, even if the sampling is not actually done with replacement, if N >> n (say at least 10x larger) then the binomial approach can be justified, as the trials are independent enough to be treated as such. However, in my case, I have no sample at all--I have data on the population--so the binomial approach appears to be a non-starter. Is that right?

I further gather that the less-well-known hypergeometric distribution is really most appropriate in cases where sampling is done without replacement, though I believe that neither lme4 nor MCMCglmm allows for this distribution, and again I have population rather than sample data.

I have a vague idea that another possibility would be to use the logit of each row (e.g., log(560/726) for the first row), and then simply model the logit with Normal errors. But what would I do then with rows that have proportions of 0 or 1? And, setting that issue aside, is the logit in principle an appropriate way to go?

Can anybody suggest a way forward, and/or explain where my thinking above has gone wrong? For a final twist, the code below shows the binomial approach, where the old lme4 (now lme4.0) quickly returns seemingly sensible results, but the new lme4 (formerly lme4Eigen) returns an interesting error.

Many thanks,
Malcolm


load(url("http://dl.dropbox.com/u/46385700/dat.RData"))
closeAllConnections()

M1 <- glm(cbind(successes, failures) ~ sex, dat, family=binomial)
cbind(as.numeric(by(dat, dat$sex, function(x) sum(x$successes)/(sum(x$successes)+sum(x$failures)))), plogis(cumsum(coef(M1))))

library(lme4.0) # lme4.0_0.9999-1

system.time(M2 <- lmer(cbind(successes, failures) ~ sex + (1 | subdist), dat, family=binomial))
cbind(as.numeric(by(dat, dat$sex, function(x) sum(x$successes)/(sum(x$successes)+sum(x$failures)))), plogis(cumsum(fixef(M2))))

system.time(M3 <- lmer(cbind(successes, failures) ~ sex + (1 | id) + (1 | subdist), dat, family=binomial))
cbind(as.numeric(by(dat, dat$sex, function(x) sum(x$successes)/(sum(x$successes)+sum(x$failures)))), plogis(cumsum(fixef(M3))))

detach(package:lme4.0)
library(lme4) # lme4_0.99990234375-0

# however, with the new lme4 (former lme4Eigen) I get an error:

system.time(M4 <- lmer(cbind(successes, failures) ~ sex + (1 | subdist), dat, family=binomial))
Error in fn(nM$xeval()) : 
  step factor reduced below 0.001 without reducing pwrss
Timing stopped at: 16.159 0.639 16.787 



From bbolker at gmail.com  Sun Mar 18 19:10:15 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 18 Mar 2012 18:10:15 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?modelling_proportions=2C_with_aggregated_dat?=
	=?utf-8?q?a=2C=09and_the_new/old_lme4?=
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
Message-ID: <loom.20120318T185026-397@post.gmane.org>

Malcolm Fairbrother <m.fairbrother at ...> writes:

> 

[snip]

> I am trying to model Census data, where individual responses to a
> question with two answer options have been aggregated up to the
> community level, and communities are nested in subdistricts. So the
> outcome of interest is a proportion (ranging from 0 to 1), and I
> know the absolute number of "successes" and "failures". For each
> community, the data are available in a slightly disaggregated form
> for different categories of people (I'll use the separate numbers of
> successes and failures for women and men as an example). Thus the
> data look like:

> head(dat)
>   successes failures id sex subdist
> 1       560      726  1   F       4
> 2       844      510  1   M       4
> 3       340      438  2   F       4
> 4       616      273  2   M       4
> 5         7        0  3   F       4
> 6         3        1  3   M       4
> 
> In community #1, which is in subdistrict #4, there are 560 women 

  you mean 510, right?

> who are "successes" and 726 who are "failures" on this social
> indicator, etc. (The data are available via a link below.)
 
> How should I model these data? I was originally thinking to use a
> binomial distribution, and a call defining the outcome as
> "cbind(successes, failures)", with each observation/row nested in
> (a) "id" and (b) "subdist".
 
> (The idea of nesting the separate Census categories like this, and
> using a multilevel approach, comes from:
> http://www.hsph.harvard.edu/faculty/
>     sv-subramanian/files/epa2001_33_3_399_417.pdf.
> There was a recent discussion of the use of "cbind" like this, but
> it seems workable in this case as a way to reduce tends of millions
> of observations to a few tens of thousands, with no loss of
> information:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/007552.html.)

 
> However, I gather that the binomial distribution is only appropriate
> where one is sampling a number of Bernoulli trials (i.e., people in
> this case) with replacement, making them independent. As I
> understand it, even if the sampling is not actually done with
> replacement, if N >> n (say at least 10x larger) then the binomial
> approach can be justified, as the trials are independent enough to
> be treated as such. However, in my case, I have no sample at all--I
> have data on the population--so the binomial approach appears to be
> a non-starter. Is that right?

   Hmmm. For better or worse, I've seen the binomial distribution
used in (I think) a reasonable way in cases where strict independence
is not reasonable (e.g. in ecological predation trials where the
prey are all in a single tank with the predator).  Technically you're
assuming both independence *and* homogeneity ... I would probably do
it this way, perhaps testing for overdispersion and/or adding
an individual-level random effect.
 
> I further gather that the less-well-known hypergeometric
> distribution is really most appropriate in cases where sampling is
> done without replacement, though I believe that neither lme4 nor
> MCMCglmm allows for this distribution, and again I have population
> rather than sample data.

  I think this would be a lot harder ... 
 
> I have a vague idea that another possibility would be to use the
> logit of each row (e.g., log(560/726) for the first row), and then
> simply model the logit with Normal errors. But what would I do then
> with rows that have proportions of 0 or 1? And, setting that issue
> aside, is the logit in principle an appropriate way to go?

  I don't think it's ridiculous, but yes, you have to deal with the
0/1 cases.  This fussing-with-zeros-and-ones stuff applies even if you
were to use a Beta regression (which you can do via glmmADMB, although
it'll probably be a lot slower than lme4), which would in some sense
be a more principled way to deal with proportion data.  I like the
idea of keeping the denominators in there and using a binomial model.
I don't think you're missing anything obvious, though.

 
> Can anybody suggest a way forward, and/or explain where my thinking
> above has gone wrong? For a final twist, the code below shows the
> binomial approach, where the old lme4 (now lme4.0) quickly returns
> seemingly sensible results, but the new lme4 (formerly lme4Eigen)
> returns an interesting error.

  For a quick answer, try optimizer="bobyqa", and/or varying tolPwrss
settings, but please be very cautious/compare your answers.  We're still
working on adjusting optimizer choice/settings to make GLMMs in the
new version fast, robust, and accurate ...

  Ben



From r.turner at auckland.ac.nz  Sun Mar 18 19:51:14 2012
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 19 Mar 2012 07:51:14 +1300
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <loom.20120318T185026-397@post.gmane.org>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
Message-ID: <4F662EA2.2090305@auckland.ac.nz>

On 19/03/12 07:10, Ben Bolker wrote:

<SNIP>

>> head(dat)
>>    successes failures id sex subdist
>> 1       560      726  1   F       4
>> 2       844      510  1   M       4
>> 3       340      438  2   F       4
>> 4       616      273  2   M       4
>> 5         7        0  3   F       4
>> 6         3        1  3   M       4
>>
>> In community #1, which is in subdistrict #4, there are 560 women
>    you mean 510, right?
<SNIP>

Sure looks like 560 to me.  Time for a trek to the optometrist, Ben?

     cheers,

         Rolf



From joerg.luedicke at gmail.com  Sun Mar 18 23:06:49 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Sun, 18 Mar 2012 15:06:49 -0700
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <4F662EA2.2090305@auckland.ac.nz>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
Message-ID: <CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>

I would certainly check out a Poisson model with the number of
successes as outcome and successes+failures as an offset.

Joerg

On Sun, Mar 18, 2012 at 11:51 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 19/03/12 07:10, Ben Bolker wrote:
>
> <SNIP>
>
>
>>> head(dat)
>>> ? successes failures id sex subdist
>>> 1 ? ? ? 560 ? ? ?726 ?1 ? F ? ? ? 4
>>> 2 ? ? ? 844 ? ? ?510 ?1 ? M ? ? ? 4
>>> 3 ? ? ? 340 ? ? ?438 ?2 ? F ? ? ? 4
>>> 4 ? ? ? 616 ? ? ?273 ?2 ? M ? ? ? 4
>>> 5 ? ? ? ? 7 ? ? ? ?0 ?3 ? F ? ? ? 4
>>> 6 ? ? ? ? 3 ? ? ? ?1 ?3 ? M ? ? ? 4
>>>
>>> In community #1, which is in subdistrict #4, there are 560 women
>>
>> ? you mean 510, right?
>
> <SNIP>
>
> Sure looks like 560 to me. ?Time for a trek to the optometrist, Ben?
>
> ? ?cheers,
>
> ? ? ? ?Rolf
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Mon Mar 19 02:40:53 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2012 01:40:53 +0000 (UTC)
Subject: [R-sig-ME] modelling proportions, with aggregated data,
	and the new/old lme4
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
Message-ID: <loom.20120319T023745-978@post.gmane.org>

Joerg Luedicke <joerg.luedicke at ...> writes:

> I would certainly check out a Poisson model with the number of
> successes as outcome and successes+failures as an offset.

  That seems odd to me; the Poisson+offset model
should be appropriate when p<<1 (i.e. for very small p,
the Poisson variance mu=n*p is approximately the same as
the binomial variance n*p*(1-p); in this case p is not small.

  Of course, I could be wrong.

> 
> On Sun, Mar 18, 2012 at 11:51 AM, Rolf Turner <r.turner at ...> wrote:
> > On 19/03/12 07:10, Ben Bolker wrote:
> >
> > <SNIP>
> >
> >
> >>> head(dat)
> >>> ? successes failures id sex subdist
> >>> 1 ? ? ? 560 ? ? ?726 ?1 ? F ? ? ? 4
> >>> 2 ? ? ? 844 ? ? ?510 ?1 ? M ? ? ? 4

  [snip]

> >>>
> >>> In community #1, which is in subdistrict #4, there are 560 women
> >>
> >> ? you mean 510, right?
> >
> > <SNIP>
> >
> > Sure looks like 560 to me. ?Time for a trek to the optometrist, Ben?

  Looked at the wrong line (failures in men rather than successes in women).



From laf.nilsson at gmail.com  Mon Mar 19 11:09:17 2012
From: laf.nilsson at gmail.com (Fredrik Nilsson)
Date: Mon, 19 Mar 2012 11:09:17 +0100
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <loom.20120319T023745-978@post.gmane.org>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
	<loom.20120319T023745-978@post.gmane.org>
Message-ID: <CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>

Joerg,

What is the point in the Poisson model in that way (assuming
log(total) as offset)? This would be a binomial model; if you observe
N events from a Poisson distribution of which X are successes (or
marked in some way) with probability p, then X will be binomial(p, N).

Best regards,
Fredrik Nilsson

PS. Here's a practical "proof", the real is sketched below.
invlogit<-function(x) exp(x)/(1+exp(x))
n<-10
nn<-ceiling(exp(rnorm(n)+3))
pp<-seq(0.25,.75,length=n)
ca<-rbinom(rep(1,n),nn,prob=pp)
co<-nn-ca
fa<-gl(n,1)

#binomial model
test.glm<-glm(cbind(ca,co)~fa-1, family=binomial)
#conditional poisson
ptest.glm<-glm(ca~fa-1+offset(log(nn)), family=poisson)
summary(ptest.glm)
exp(coef(ptest.glm))
invlogit(coef(test.glm))

all.equal(exp(coef(ptest.glm)), invlogit(coef(test.glm)))

# proof.
X~Poisson(a) and  Y~Poisson(b), X & Y independent -> X+Y~Poisson(a+b)
(e.g. by generating functions).

Prob(X=x| X+Y=n) = Prob(X=x, Y=n-x)/Prob(X+Y=n) =
Prob(X=x)*Prob(Y=n-x)/Prob(X+Y=n) = a^x/x! exp(a) b^(n-x)/(n-x)!
exp(b) /((a+b)^n/n! exp(a+b)) =
n!/x!/(n-x)! (a/(a+b))^x (b/(a+b))^(n-x) = n!/x!/(n-x)! (a/(a+b))^x
(1-a/(a+b))^(n-x) , i.e. binomial(x,n,p) with p=a/(a+b).


2012/3/19 Ben Bolker <bbolker at gmail.com>:
> Joerg Luedicke <joerg.luedicke at ...> writes:
>
>> I would certainly check out a Poisson model with the number of
>> successes as outcome and successes+failures as an offset.
>
> ?That seems odd to me; the Poisson+offset model
> should be appropriate when p<<1 (i.e. for very small p,
> the Poisson variance mu=n*p is approximately the same as
> the binomial variance n*p*(1-p); in this case p is not small.
>
> ?Of course, I could be wrong.
>
>>
>> On Sun, Mar 18, 2012 at 11:51 AM, Rolf Turner <r.turner at ...> wrote:
>> > On 19/03/12 07:10, Ben Bolker wrote:
>> >
>> > <SNIP>
>> >
>> >
>> >>> head(dat)
>> >>> ? successes failures id sex subdist
>> >>> 1 ? ? ? 560 ? ? ?726 ?1 ? F ? ? ? 4
>> >>> 2 ? ? ? 844 ? ? ?510 ?1 ? M ? ? ? 4
>
> ?[snip]
>
>> >>>
>> >>> In community #1, which is in subdistrict #4, there are 560 women
>> >>
>> >> ? you mean 510, right?
>> >
>> > <SNIP>
>> >
>> > Sure looks like 560 to me. ?Time for a trek to the optometrist, Ben?
>
> ?Looked at the wrong line (failures in men rather than successes in women).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From juliet.hannah at gmail.com  Mon Mar 19 15:57:40 2012
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Mon, 19 Mar 2012 10:57:40 -0400
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com>
References: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com>
Message-ID: <CALzuZRQinGU4V91bNjiwM44GuY8hWt9=N9vb0oph6t6gvhF2AA@mail.gmail.com>

Thanks for all the responses. I'll study this further and will report back.

On Wed, Mar 14, 2012 at 8:28 AM, Ryan King <c.ryan.king at gmail.com> wrote:
> When the observation-level random effects are independent then they
> are the same as the noise. i.e.
> y = xb + u +e can just be rewritten y= xb + e', with e' = u+e. Since
> the sum of two normals is normal, the model is unchanged from usual
> OLS.
>
> With kinship that symmetry breaks, and observation-level random
> effects are identifiable.
>
> .I am currently using R to do such genetics models to do association
> .mapping. I ask to other people that have done that before me and if I
> .understand well, no packages allows to specify such a variance/covariance
> .matrix for a random effect except ASREML.
>
> You can also use MCMCglmm and R-INLA.
>
> Ryan King
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Bryan.Danson at MyFWC.com  Mon Mar 19 16:50:21 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Mon, 19 Mar 2012 11:50:21 -0400
Subject: [R-sig-ME] (no subject)
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAA4EF692@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/1ad0884e/attachment-0002.pl>

From joerg.luedicke at gmail.com  Mon Mar 19 18:22:48 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Mon, 19 Mar 2012 10:22:48 -0700
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
	<loom.20120319T023745-978@post.gmane.org>
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>
Message-ID: <CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>

Hi Ben and Fredrik,

Thanks for the comments and the proof! Next time I will be less hasty
in responding...

Cheers,

Joerg

On Mon, Mar 19, 2012 at 3:09 AM, Fredrik Nilsson <laf.nilsson at gmail.com> wrote:
> Joerg,
>
> What is the point in the Poisson model in that way (assuming
> log(total) as offset)? This would be a binomial model; if you observe
> N events from a Poisson distribution of which X are successes (or
> marked in some way) with probability p, then X will be binomial(p, N).
>
> Best regards,
> Fredrik Nilsson
>
> PS. Here's a practical "proof", the real is sketched below.
> invlogit<-function(x) exp(x)/(1+exp(x))
> n<-10
> nn<-ceiling(exp(rnorm(n)+3))
> pp<-seq(0.25,.75,length=n)
> ca<-rbinom(rep(1,n),nn,prob=pp)
> co<-nn-ca
> fa<-gl(n,1)
>
> #binomial model
> test.glm<-glm(cbind(ca,co)~fa-1, family=binomial)
> #conditional poisson
> ptest.glm<-glm(ca~fa-1+offset(log(nn)), family=poisson)
> summary(ptest.glm)
> exp(coef(ptest.glm))
> invlogit(coef(test.glm))
>
> all.equal(exp(coef(ptest.glm)), invlogit(coef(test.glm)))
>
> # proof.
> X~Poisson(a) and ?Y~Poisson(b), X & Y independent -> X+Y~Poisson(a+b)
> (e.g. by generating functions).
>
> Prob(X=x| X+Y=n) = Prob(X=x, Y=n-x)/Prob(X+Y=n) =
> Prob(X=x)*Prob(Y=n-x)/Prob(X+Y=n) = a^x/x! exp(a) b^(n-x)/(n-x)!
> exp(b) /((a+b)^n/n! exp(a+b)) =
> n!/x!/(n-x)! (a/(a+b))^x (b/(a+b))^(n-x) = n!/x!/(n-x)! (a/(a+b))^x
> (1-a/(a+b))^(n-x) , i.e. binomial(x,n,p) with p=a/(a+b).
>
>
> 2012/3/19 Ben Bolker <bbolker at gmail.com>:
>> Joerg Luedicke <joerg.luedicke at ...> writes:
>>
>>> I would certainly check out a Poisson model with the number of
>>> successes as outcome and successes+failures as an offset.
>>
>> ?That seems odd to me; the Poisson+offset model
>> should be appropriate when p<<1 (i.e. for very small p,
>> the Poisson variance mu=n*p is approximately the same as
>> the binomial variance n*p*(1-p); in this case p is not small.
>>
>> ?Of course, I could be wrong.
>>
>>>
>>> On Sun, Mar 18, 2012 at 11:51 AM, Rolf Turner <r.turner at ...> wrote:
>>> > On 19/03/12 07:10, Ben Bolker wrote:
>>> >
>>> > <SNIP>
>>> >
>>> >
>>> >>> head(dat)
>>> >>> ? successes failures id sex subdist
>>> >>> 1 ? ? ? 560 ? ? ?726 ?1 ? F ? ? ? 4
>>> >>> 2 ? ? ? 844 ? ? ?510 ?1 ? M ? ? ? 4
>>
>> ?[snip]
>>
>>> >>>
>>> >>> In community #1, which is in subdistrict #4, there are 560 women
>>> >>
>>> >> ? you mean 510, right?
>>> >
>>> > <SNIP>
>>> >
>>> > Sure looks like 560 to me. ?Time for a trek to the optometrist, Ben?
>>
>> ?Looked at the wrong line (failures in men rather than successes in women).
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From slu at ccsr.uchicago.edu  Mon Mar 19 18:25:59 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 19 Mar 2012 12:25:59 -0500
Subject: [R-sig-ME] Unacceptibly high autocorrelation in MCMCglmm
In-Reply-To: <20120317102916.64036j23f48cdugw@www.staffmail.ed.ac.uk>
References: <1331937495.455.18.camel@localhost>
	<20120317102916.64036j23f48cdugw@www.staffmail.ed.ac.uk>
Message-ID: <1332177959.25409.13.camel@localhost>

On Sat, 2012-03-17 at 10:29 +0000, Jarrod Hadfield wrote:
> HI,
> 
> It looks like the probit has underflowed/overflowed - you can check  
> this by saving the latent variables and looking to see whether the  
> range of the absolute values exceeds 7 (See Section 8.08 of  
> CourseNotes).
> 
> This can happen with weak priors and (near) complete separation and/or  
> with weak priors for effects that are heavily confounded.
> 
> I'm not sure how to proceed with underflow/overflow problems  
> generally.  I could terminate the procedure, or I could truncate the  
> latent variables at their overflow/underflow points. The latter is  
> used by some WinBUGS users, but then WinBUGS handles the fact that the  
> response is from a truncated normal not a normal - something which  
> would be hard to program in MCMCglmm. Any thoughts would be useful.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> Quoting Stuart Luppescu <slu at ccsr.uchicago.edu> on Fri, 16 Mar 2012  
> 17:38:15 -0500:
> 
> > Hello, I'm running this ordered category outcome model:
> >
> > glme5.very.len <- MCMCglmm(very.len.summative.o ~ 1 ,
> >                    prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1,
> > nu=0), G2=list(V=1, nu=0), G3=list(V=1, nu=0), G4=list(V=1, nu=0) )),
> >                    random = ~emplid + deptid + grade.f + subject.f ,
> >                    family = "ordinal",
> >                    nitt=300000,
> >                    data = summative.ratings.prin.yr1.full)

Hi Jarrod, I think I've figured out why this is not working. I hope you
or someone can suggest a fix.

I am analyzing ratings data of observations of teacher performance.
Teachers are rated on more than one occasion on a 1-4 scale on 10
components. The object is to calculate the ICC as a measure of
interrater reliablility (the percent of total variance attributed to
differences in teacher performance = variance in emplid/total variance).
This analysis worked perfectly
fine using MCMCglmm with the 10 components as fixed effects.

What I'm doing now (which is NOT working) is calculating one single
summative rating per teacher based on combinations of all the component
ratings a teacher received in a year. That means only one datum per
teacher per year: no separate components and no multiple observations.
So, including the teacher ID (emplid) as a random effect will screw
things up because there is only one datum per teacher and no
within-teacher variance. 

Do you have any idea how to get around this problem?

Thank you very much for your help.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
Please do think hard before you tell other people
 what they 'should' do for you.    -- Brian D.
 Ripley       R-devel (January 2006)



From bbolker at gmail.com  Mon Mar 19 19:50:24 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2012 18:50:24 +0000 (UTC)
Subject: [R-sig-ME] modelling proportions, with aggregated data,
	and the new/old lme4
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
	<loom.20120319T023745-978@post.gmane.org>
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>
	<CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>
Message-ID: <loom.20120319T194724-653@post.gmane.org>

Joerg Luedicke <joerg.luedicke at ...> writes:

> 
> Hi Ben and Fredrik,
> 
> Thanks for the comments and the proof! Next time I will be less hasty
> in responding...
> 
> Cheers,
> 
> Joerg

   Don't forget that I was wrong too (I forgot about the conditioning). 
 I know that this (i.e. using the Poisson model with an offset to
model binomial data) is a common practice, maybe it was done in the past for
computational reasons?

library("fortunes")
fortune("great-great grandchildren")

  cheers
    Ben



From bbolker at gmail.com  Mon Mar 19 20:15:35 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2012 19:15:35 +0000 (UTC)
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
Message-ID: <loom.20120319T195110-259@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> 
> Hi,
> 
> I am trying to use a multivariate mixed effects linear model to
> examine mediation.  This works fine.  The final step is to compute the
> indirect effect and its standard error.  The indirect effect is easy
> (product of coefficients plus their covariance).  For the standard
> error, I need the gradient (D) and the hessian (H):
> the variance is then:
> 
> D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}
> 
> This is all given in the Appendix of
> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
> 
> Is there a way to get this out of a mer class object?  Looking at
> class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$.  @V
> seems like it would give me the gradient but is null for a basic lmer
> model.

  If you're willing to try out the development version (i.e., lme4
from r-forge), I think you can do this as follows:

fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm1Fun <- update(fm1,devFunOnly=TRUE)
library(numDeriv)
fm1_thpar <- getME(fm1,"theta")
h <- hessian(fm1Fun,fm1_thpar)

  and similarly for the gradient.

  Let me know how it goes.

  Ben Bolker



From tom.gijssels at gmail.com  Mon Mar 19 20:25:08 2012
From: tom.gijssels at gmail.com (Tom Gijssels)
Date: Mon, 19 Mar 2012 15:25:08 -0400
Subject: [R-sig-ME] Conflicting p-values from pvals.fnc
Message-ID: <CAPB_MR1-ZZHD93Vya_Mg_60HppF5Sg3rSma_1cS3KjqHd3mwHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/b68636a2/attachment-0002.pl>

From Bryan.Danson at MyFWC.com  Mon Mar 19 21:06:57 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Mon, 19 Mar 2012 16:06:57 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/b28f4b28/attachment-0002.pl>

From thomas.merkling at cict.fr  Mon Mar 19 21:16:22 2012
From: thomas.merkling at cict.fr (Thomas Merkling)
Date: Mon, 19 Mar 2012 21:16:22 +0100
Subject: [R-sig-ME] Wald tests GLMM with glmer
Message-ID: <4F679416.4070808@cict.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/e485a5cd/attachment-0002.pl>

From bbolker at gmail.com  Mon Mar 19 22:18:11 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2012 21:18:11 +0000 (UTC)
Subject: [R-sig-ME] glmm with a tweedie distribution
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>
Message-ID: <loom.20120319T221655-53@post.gmane.org>

Danson, Bryan <Bryan.Danson at ...> writes:

> 
> Is there a way to run a GLMM with a tweedie distribution?
> 

  Yes, using the 'cplm' package.  I expanded the section on
ZIGLMMs on http://glmm.wikidot.com/faq to include a bit more
stuff on ZIGLMMs, including a bit on ZIGLMMs with a continuous
response for the non-zero data.

  Ben



From lemoine.nathan at gmail.com  Mon Mar 19 22:31:59 2012
From: lemoine.nathan at gmail.com (Nathan Lemoine)
Date: Mon, 19 Mar 2012 17:31:59 -0400
Subject: [R-sig-ME] repeated measures: lme(r) vs manova
Message-ID: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>

Hi all,
Sorry in advance for the length of this post, but I've searched around and couldn't find anything that addressed this issue:

I recently ran into the issue of deciding on the appropriate way to analyze a repeated measures design. We enriched quadrats to measure productivity and we monitored them for three years. Four quadrats were nested within plots. Here are the data:

"plot" "quad" "nut" "t1" "t3" "t4"
"1" 1 "A" "nut" 17.69130435 70.4 57.8
"2" 1 "A" "no nut" 65.4173913 125.8 109.9
"3" 1 "B" "nut" 19.56521739 103.2 100.8
"4" 1 "B" "no nut" 89.03636364 131.3 99.1
"5" 1 "C" "nut" 29.88723404 25.7 29.9
"6" 1 "C" "no nut" 45.45454545 113.1 110.6
"7" 1 "D" "nut" 18.28181818 60.9 67.7
"8" 1 "D" "no nut" 68.88888889 136 95
"9" 2 "A" "nut" 35.41666667 61.6 16
"10" 2 "A" "no nut" 40.90909091 59.4 64.7
"11" 2 "B" "nut" 34.14255319 26.7 23.1
"12" 2 "B" "no nut" 36.27021277 71.6 47.2
"13" 2 "C" "nut" 13.33333333 20.9 26.4
"14" 2 "C" "no nut" 7.118181818 31.2 19.1
"15" 2 "D" "nut" 20 30.9 27.8
"16" 2 "D" "no nut" 19.34893617 31.3 16.7
"17" 3 "A" "nut" 22.22222222 130.7 163.6
"18" 3 "A" "no nut" 32.90869565 83.8 86.2
"19" 3 "B" "nut" 38.29787234 99 110.1
"20" 3 "B" "no nut" 38.83636364 127.1 115.2
"21" 3 "C" "nut" 38.88888889 81.7 193.7
"22" 3 "C" "no nut" 28.98888889 72.1 103.8
"23" 3 "D" "nut" 50 111.3 117.7
"24" 3 "D" "no nut" 26.86666667 94.2 113
"25" 4 "A" "nut" 63.63636364 128.4 114.8
"26" 4 "A" "no nut" 108.8956522 121 80.7
"27" 4 "B" "nut" 104.4444444 146.5 102.2
"28" 4 "B" "no nut" 84.74444444 111.5 109.9
"29" 4 "C" "nut" 71.31111111 86.2 118.4
"30" 4 "C" "no nut" 115.9555556 131.4 141.9
"31" 4 "D" "nut" 75.65555556 141.5 92.5
"32" 4 "D" "no nut" 108.9888889 146.6 122.2
"33" 5 "A" "nut" 20.2 57.4 14.6
"34" 5 "A" "no nut" 12.34489796 55.4 13.4
"35" 5 "B" "nut" 48.98888889 56.3 28.7
"36" 5 "B" "no nut" 35.65555556 55.8 17.6
"37" 5 "C" "nut" 22.22222222 45.9 7.3
"38" 5 "C" "no nut" 9.088888889 55.6 20.5
"39" 5 "D" "nut" 64.44444444 86.1 61.7
"40" 5 "D" "no nut" 15.65555556 75.7 41.8
"41" 6 "A" "nut" 22.22222222 101.1 69.8
"42" 6 "A" "no nut" 53.33333333 171.2 113.5
"43" 6 "B" "nut" 37.87777778 111.1 66.8
"44" 6 "B" "no nut" 46.96666667 120.8 83.8
"45" 6 "C" "nut" 17.87777778 120.7 84
"46" 6 "C" "no nut" 21.21212121 116.3 76.8
"47" 6 "D" "nut" 24.01304348 86.1 64.6
"48" 6 "D" "no nut" 29.51034483 112.5 51.9

The basic question is: When is it appropriate to use a MANOVA-based repeated measures design over a mixed effects model? 

For example, the MANOVA approach:
library(car)
repeated.manova <- lm(cbind(t1,t3,t4)~nut+plot+quad, data=manova.data)
Manova(repeated.manova)

nut is not significant and there are 40 denominator df. 

If I set up the data and run lme:

mixed.dat <- melt(manova.data, id=c("plot","quad","nut"))
colnames(mixed.dat)[4:5] <- c("time","prod")
mixed.dat$time <- as.numeric(mixed.dat$time))

library(nlme)
lme.repeated <- lme(prod~nut, random=~nut|time, data=mixed.dat)
anova(lme.repeated)

Gives 140 denominator df. I'm also not sure this is the appropriate set up for a repeated measures design. Running the following code seems more in line with what I've read to take into account the correlation in observations within the same plot:

lme.repeated2 <- lme(prod~nut*time, random=~time|plot, data=mixed.dat)
anova(lme.repeated2)

This model seems much more appropriate, as observations within plots are now allowed to be correlated, but there is still a huge difference between the MANOVA-based approach and the mixed-effects-based approach, as the mixed-effects model gives me a significant result. The MANOVA assumes that I have three (correlated) observations on 48 independent units, whereas the lme approach assumes that I have 144 observations on correlated units. Also not sure if that interpretation is correct.

Alternatively, I used lmer() for non-nested, multilevel models allowing observations to be correlated in space and time:

repeated.mixed3 <- lmer(prod~nut + (1|plot) + (1|time), data=mixed.dat)
repeated.mixed4 <- lmer(prod~ (1|plot) + (1|time), data=mixed.dat)
anova(repeated.mixed3, repeated.mixed4)

This approach also gives me a significant result. Which of these is the most appropriate? The differences between lme and lmer are trivial (in this case), but the difference between the MANOVA approach and mixed-effects is substantial. I figure the MANOVA approach is probably in correct on account of the nested design, but my question extends to situations when the design is not nested. 

Thanks in advance for your help,

Nathan


 


From billpikounis at gmail.com  Mon Mar 19 22:56:16 2012
From: billpikounis at gmail.com (Bill Pikounis)
Date: Mon, 19 Mar 2012 17:56:16 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <loom.20120319T221655-53@post.gmane.org>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>
	<loom.20120319T221655-53@post.gmane.org>
Message-ID: <CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>

Bryan,
You might also wish to try the glmmPQL function in Venables and
Ripley's MASS package. Someone reported success with it on the SIG-ECO
R list nearly a year ago:

https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html

Hope that helps.

Bill

On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
> Danson, Bryan <Bryan.Danson at ...> writes:
>
>>
>> Is there a way to run a GLMM with a tweedie distribution?
>>
>
> ?Yes, using the 'cplm' package. ?I expanded the section on
> ZIGLMMs on http://glmm.wikidot.com/faq to include a bit more
> stuff on ZIGLMMs, including a bit on ZIGLMMs with a continuous
> response for the non-zero data.
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Yanwei.Zhang at cna.com  Mon Mar 19 23:16:35 2012
From: Yanwei.Zhang at cna.com (Zhang,Yanwei)
Date: Mon, 19 Mar 2012 17:16:35 -0500
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>
	<loom.20120319T221655-53@post.gmane.org>
	<CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
Message-ID: <330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>

One problem with the "glmmPQL" is that the variance function can not be estimated - you need to pre-specify it in an ad hoc way. The "cpglmm" function in the "cplm" package estimates it directly from the data along with other parameters using MLE. But of course, you can use glmmPQL to generate starting values that are fed to cpglmm.   

Regards, 
Wayne 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bill Pikounis
Sent: Monday, March 19, 2012 4:56 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

Bryan,
You might also wish to try the glmmPQL function in Venables and
Ripley's MASS package. Someone reported success with it on the SIG-ECO
R list nearly a year ago:

https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html

Hope that helps.

Bill

On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
> Danson, Bryan <Bryan.Danson at ...> writes:
>
>>
>> Is there a way to run a GLMM with a tweedie distribution?
>>
>
> ?Yes, using the 'cplm' package. ?I expanded the section on
> ZIGLMMs on http://glmm.wikidot.com/faq to include a bit more
> stuff on ZIGLMMs, including a bit on ZIGLMMs with a continuous
> response for the non-zero data.
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.



From billpikounis at gmail.com  Mon Mar 19 23:18:16 2012
From: billpikounis at gmail.com (Bill Pikounis)
Date: Mon, 19 Mar 2012 18:18:16 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us>
	<loom.20120319T221655-53@post.gmane.org>
	<CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
Message-ID: <CADY6hMU1EWD6TsvJ=7Pvu-Rgfehywgg0ZnwBUZm4G81cimQuzA@mail.gmail.com>

And I overlooked that Ben Bolker was part of that sig-eco thread and
was the one who reported the success... Sorry for my lack of
attribution, Ben....

Bill

On Mon, Mar 19, 2012 at 17:56, Bill Pikounis <billpikounis at gmail.com> wrote:
> Bryan,
> You might also wish to try the glmmPQL function in Venables and
> Ripley's MASS package. Someone reported success with it on the SIG-ECO
> R list nearly a year ago:
>
> https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html
>
> Hope that helps.
>
> Bill
>
> On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
>> Danson, Bryan <Bryan.Danson at ...> writes:
>>
>>>
>>> Is there a way to run a GLMM with a tweedie distribution?
>>>
>>
>> ?Yes, using the 'cplm' package. ?I expanded the section on
>> ZIGLMMs on http://glmm.wikidot.com/faq to include a bit more
>> stuff on ZIGLMMs, including a bit on ZIGLMMs with a continuous
>> response for the non-zero data.
>>
>> ?Ben
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rroa at azti.es  Tue Mar 20 08:34:59 2012
From: rroa at azti.es (=?iso-8859-1?Q?Rub=E9n_Roa?=)
Date: Tue, 20 Mar 2012 08:34:59 +0100
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us><loom.20120319T221655-53@post.gmane.org><CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>
Message-ID: <5CD78996B8F8844D963C875D3159B94A034B7493@DSRCORREO.azti.local>

I wouldn't call it ad hoc. The power parameter p in the variance function that defines the Tweedie family of exponential distributions, v(mu)=phi*mu^p, can be estimated via profile likelihood, and then the maximum profile likelihood estimate of the p parameter can be inserted in the glmm, essentially estimating the glmm by an estimated likelihood. So there are two stages of approximation but the approximation methods are not ad hoc, they are pretty much mainstream approximation methods to complex likelihoods. Here is a pseudo code using the tweedie package and glmmPQL from MASS (plus msm). For a published application you can see Tascheri, Saavedra-Nievas, Roa-Ureta. 2010. Statistical models to standardize catch rates in the multi-species trawl fishery for Patagonian grenadier (Macruronus magellanicus) off Southern Chile. Fisheries Research 105:200-214.

HTH

Ruben

--
Dr. Ruben H. Roa-Ureta
Senior Researcher, AZTI Tecnalia,
Marine Research Division,
Txatxarramendi Ugartea z/g, 48395, Sukarrieta,
Bizkaia, Spain

##################################  Tweedie ####################################
#estimating variance power parameter

#libraries

library(tweedie)

library(MASS)

library(msm)

MyCaseStudy.Tweedie.prof <- tweedie.profile(MyResponseVar ~ log(Y) + log(Z) + ... + Factor1 + Factor2 + ... ,
p.vec=seq(1.0,2.0,by=0.1), data=MyData, link.power=0, fit.glm=FALSE, do.smooth=TRUE, do.plot=TRUE,
method="inversion",conf.level=0.95, phi.method= "mle",verbose=TRUE)

#distributional plot

y <- rtweedie(1000, p= MyCaseStudy.Tweedie.prof $p.max, mu=1, phi= MyCaseStudy.Tweedie.prof $phi.max)
tweedie.plot(seq(0, max(y), length=100), mu=mean(y), p= MyCaseStudy.Tweedie.prof $p.max, phi= MyCaseStudy.Tweedie.prof $phi.max)

#fitting the glmm
MyCaseStudy..Tweedie.mix <- glmmPQL(fixed = MyResponseVar ~ log(Y) + log(Z) + ... + Factor1 + Factor2 + ... ,
random = list(~1|RE), family=tweedie(var.power = MyCaseStudy.Tweedie.prof$p.max, link.power=0), data= MyData)

MyCaseStudy.Tweedie.mix.sum  <- summary(MyCaseStudy.Tweedie.mix)

#estimated covariance of estimates of a subset of coefficients, [3:11]

MyCaseStudy.Tweedie.mix.year.cov <- round(deltamethod(g=list(~exp(x1),~exp(x2),~exp(x3),~exp(x4),~exp(x5),
~exp(x6),~exp(x7),~exp(x8),~exp(x9)), mean= MyCaseStudy.Tweedie.mix.sum$coef$fixed[3:11], cov=vcov(MyCaseStudy.Tweedie.mix)[3:11,3:11],
ses=FALSE),5)

MyCaseStudy.Tweedie.mix.year.se  <- sqrt(diag(MyCaseStudy.Tweedie.mix.year.cov))

MyCaseStudy.Tweedie.mix.year.cor <- cov2cor(MyCaseStudy.Tweedie.mix.year.cov)

-----Mensaje original-----
De: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Zhang,Yanwei
Enviado el: lunes, 19 de marzo de 2012 23:17
Para: Bill Pikounis; r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] glmm with a tweedie distribution

One problem with the "glmmPQL" is that the variance function can not be estimated - you need to pre-specify it in an ad hoc way. The "cpglmm" function in the "cplm" package estimates it directly from the data along with other parameters using MLE. But of course, you can use glmmPQL to generate starting values that are fed to cpglmm.   

Regards,
Wayne 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bill Pikounis
Sent: Monday, March 19, 2012 4:56 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

Bryan,
You might also wish to try the glmmPQL function in Venables and Ripley's MASS package. Someone reported success with it on the SIG-ECO R list nearly a year ago:

https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html

Hope that helps.

Bill

On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
> Danson, Bryan <Bryan.Danson at ...> writes:
>
>>
>> Is there a way to run a GLMM with a tweedie distribution?
>>
>
> ?Yes, using the 'cplm' package. ?I expanded the section on ZIGLMMs on 
> http://glmm.wikidot.com/faq to include a bit more stuff on ZIGLMMs, 
> including a bit on ZIGLMMs with a continuous response for the non-zero 
> data.
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From m.fairbrother at bristol.ac.uk  Tue Mar 20 10:58:34 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 20 Mar 2012 09:58:34 +0000
Subject: [R-sig-ME] Wald tests GLMM with glmer
In-Reply-To: <mailman.4085.1332195502.4502.r-sig-mixed-models@r-project.org>
References: <mailman.4085.1332195502.4502.r-sig-mixed-models@r-project.org>
Message-ID: <3CC49BDD-F0B9-44EF-9C34-81364164404A@bristol.ac.uk>

Dear Thomas,

There are others on this list who are more knowledgeable than me, but I can suggest a couple things:


> I couldn't use mcmcsamp function neither mcsamp function. What are the other possibilities ?

With the new lme4, try:
? bootMer


> Finally, I tried to use MCMCglmm package, despite my poor familiarity 
> with these techniques (maybe a mistake). When specifying 
> family="categorical" (as my response variable is binary) the plot of the 
> traces were really bad , while there were really better with 
> family="gaussian". Does it make any sense ? Not really to me ...
> Moreover, I also have a problem with one of the 2 random effects (traces 
> stucked at zero). It has only 5 levels and I think I read that there 
> might some problems with random effects with few levels.

Five levels is not enough. In most instances, I think, you need at least 20, and ideally more than that. Though it depends on the context, and to some extent who you ask.


> How to deal with this kind of problem ?

Could you turn this random classification into a series of fixed effects, using dummy variables?

Hope that's useful.
- Malcolm



From bbolker at gmail.com  Tue Mar 20 16:01:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 20 Mar 2012 15:01:44 +0000 (UTC)
Subject: [R-sig-ME] glmm with a tweedie distribution
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us><loom.20120319T221655-53@post.gmane.org><CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>
	<5CD78996B8F8844D963C875D3159B94A034B7493@DSRCORREO.azti.local>
Message-ID: <loom.20120320T154531-578@post.gmane.org>

Rub?n Roa <rroa at ...> writes:

>  I wouldn't call it ad hoc. The power parameter p in the variance
> function that defines the Tweedie family of exponential
> distributions, v(mu)=phi*mu^p, can be estimated via profile
> likelihood, and then the maximum profile likelihood estimate of the
> p parameter can be inserted in the glmm, essentially estimating the
> glmm by an estimated likelihood. So there are two stages of
> approximation but the approximation methods are not ad hoc, they are
> pretty much mainstream approximation methods to complex
> likelihoods. Here is a pseudo code using the tweedie package and
> glmmPQL from MASS (plus msm). For a published application you can
> see Tascheri, Saavedra-Nievas, Roa-Ureta. 2010. Statistical models
> to standardize catch rates in the multi-species trawl fishery for
> Patagonian grenadier (Macruronus magellanicus) off Southern
> Chile. Fisheries Research 105:200-214.

  For what it's worth, the upcoming/development version of 
lme4 (now on R-forge) should work with custom family arguments,
so this approach *should* be possible with glmer as well as
glmmPQL ... (but I would also definitely give a thumbs-up
to cplm, which looks quite powerful).

  Anyone who wants to do some http://glmm.wikidot.com/faq - editing
is welcome ...



From Bryan.Danson at MyFWC.com  Tue Mar 20 17:00:08 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Tue, 20 Mar 2012 12:00:08 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAA4EF87F@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120320/f0203932/attachment-0002.pl>

From schmettow at web.de  Tue Mar 20 17:32:35 2012
From: schmettow at web.de (Martin Schmettow)
Date: Tue, 20 Mar 2012 17:32:35 +0100
Subject: [R-sig-ME] repeated measures: lme(r) vs manova
In-Reply-To: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>
References: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>
Message-ID: <008301cd06b7$0e79af50$2b6d0df0$@web.de>

Hi Nathan,

Here is a nice simulation study comparing LME to MANOVA and several other
traditional methods (I hope you don't mind the interdisciplinary transfer):
Gueorguieva, R., & Krystal, J. H. (2004). Move Over ANOVA. Archives of
General Psychiatry, 61, 310-317.

The bottom line: In longitudinal designs, LME has better power in presence
of missing values.

CU, Martin



> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Nathan Lemoine
> Sent: Monday, March 19, 2012 10:32 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] repeated measures: lme(r) vs manova
> 
> Hi all,
> Sorry in advance for the length of this post, but I've searched around and
> couldn't find anything that addressed this issue:
> 
> I recently ran into the issue of deciding on the appropriate way to
analyze a
> repeated measures design. We enriched quadrats to measure productivity
> and we monitored them for three years. Four quadrats were nested within
> plots. Here are the data:
> 
> "plot" "quad" "nut" "t1" "t3" "t4"
> "1" 1 "A" "nut" 17.69130435 70.4 57.8
> "2" 1 "A" "no nut" 65.4173913 125.8 109.9 "3" 1 "B" "nut" 19.56521739
103.2
> 100.8 "4" 1 "B" "no nut" 89.03636364 131.3 99.1 "5" 1 "C" "nut"
29.88723404
> 25.7 29.9 "6" 1 "C" "no nut" 45.45454545 113.1 110.6 "7" 1 "D" "nut"
> 18.28181818 60.9 67.7 "8" 1 "D" "no nut" 68.88888889 136 95 "9" 2 "A"
"nut"
> 35.41666667 61.6 16 "10" 2 "A" "no nut" 40.90909091 59.4 64.7 "11" 2 "B"
"nut"
> 34.14255319 26.7 23.1 "12" 2 "B" "no nut" 36.27021277 71.6 47.2 "13" 2 "C"
> "nut" 13.33333333 20.9 26.4 "14" 2 "C" "no nut" 7.118181818 31.2 19.1 "15"
2
> "D" "nut" 20 30.9 27.8 "16" 2 "D" "no nut" 19.34893617 31.3 16.7 "17" 3
"A"
> "nut" 22.22222222 130.7 163.6 "18" 3 "A" "no nut" 32.90869565 83.8 86.2
"19" 3
> "B" "nut" 38.29787234 99 110.1 "20" 3 "B" "no nut" 38.83636364 127.1 115.2
> "21" 3 "C" "nut" 38.88888889 81.7 193.7 "22" 3 "C" "no nut" 28.98888889
72.1
> 103.8 "23" 3 "D" "nut" 50 111.3 117.7 "24" 3 "D" "no nut" 26.86666667 94.2
113
> "25" 4 "A" "nut" 63.63636364 128.4 114.8 "26" 4 "A" "no nut" 108.8956522
121
> 80.7 "27" 4 "B" "nut" 104.4444444 146.5 102.2 "28" 4 "B" "no nut"
84.74444444
> 111.5 109.9 "29" 4 "C" "nut" 71.31111111 86.2 118.4 "30" 4 "C" "no nut"
> 115.9555556 131.4 141.9 "31" 4 "D" "nut" 75.65555556 141.5 92.5 "32" 4 "D"
> "no nut" 108.9888889 146.6 122.2 "33" 5 "A" "nut" 20.2 57.4 14.6 "34" 5
"A" "no
> nut" 12.34489796 55.4 13.4 "35" 5 "B" "nut" 48.98888889 56.3 28.7 "36" 5
"B"
> "no nut" 35.65555556 55.8 17.6 "37" 5 "C" "nut" 22.22222222 45.9 7.3 "38"
5
> "C" "no nut" 9.088888889 55.6 20.5 "39" 5 "D" "nut" 64.44444444 86.1 61.7
"40"
> 5 "D" "no nut" 15.65555556 75.7 41.8 "41" 6 "A" "nut" 22.22222222 101.1
69.8
> "42" 6 "A" "no nut" 53.33333333 171.2 113.5 "43" 6 "B" "nut" 37.87777778
> 111.1 66.8 "44" 6 "B" "no nut" 46.96666667 120.8 83.8 "45" 6 "C" "nut"
> 17.87777778 120.7 84 "46" 6 "C" "no nut" 21.21212121 116.3 76.8 "47" 6 "D"
> "nut" 24.01304348 86.1 64.6 "48" 6 "D" "no nut" 29.51034483 112.5 51.9
> 
> The basic question is: When is it appropriate to use a MANOVA-based
> repeated measures design over a mixed effects model?
> 
> For example, the MANOVA approach:
> library(car)
> repeated.manova <- lm(cbind(t1,t3,t4)~nut+plot+quad, data=manova.data)
> Manova(repeated.manova)
> 
> nut is not significant and there are 40 denominator df.
> 
> If I set up the data and run lme:
> 
> mixed.dat <- melt(manova.data, id=c("plot","quad","nut"))
> colnames(mixed.dat)[4:5] <- c("time","prod") mixed.dat$time <-
> as.numeric(mixed.dat$time))
> 
> library(nlme)
> lme.repeated <- lme(prod~nut, random=~nut|time, data=mixed.dat)
> anova(lme.repeated)
> 
> Gives 140 denominator df. I'm also not sure this is the appropriate set up
for
> a repeated measures design. Running the following code seems more in line
> with what I've read to take into account the correlation in observations
> within the same plot:
> 
> lme.repeated2 <- lme(prod~nut*time, random=~time|plot,
> data=mixed.dat)
> anova(lme.repeated2)
> 
> This model seems much more appropriate, as observations within plots are
> now allowed to be correlated, but there is still a huge difference between
> the MANOVA-based approach and the mixed-effects-based approach, as
> the mixed-effects model gives me a significant result. The MANOVA assumes
> that I have three (correlated) observations on 48 independent units,
> whereas the lme approach assumes that I have 144 observations on
> correlated units. Also not sure if that interpretation is correct.
> 
> Alternatively, I used lmer() for non-nested, multilevel models allowing
> observations to be correlated in space and time:
> 
> repeated.mixed3 <- lmer(prod~nut + (1|plot) + (1|time), data=mixed.dat)
> repeated.mixed4 <- lmer(prod~ (1|plot) + (1|time), data=mixed.dat)
> anova(repeated.mixed3, repeated.mixed4)
> 
> This approach also gives me a significant result. Which of these is the
most
> appropriate? The differences between lme and lmer are trivial (in this
case),
> but the difference between the MANOVA approach and mixed-effects is
> substantial. I figure the MANOVA approach is probably in correct on
account
> of the nested design, but my question extends to situations when the
design
> is not nested.
> 
> Thanks in advance for your help,
> 
> Nathan
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From thomas.merkling at cict.fr  Tue Mar 20 19:32:11 2012
From: thomas.merkling at cict.fr (Thomas Merkling)
Date: Tue, 20 Mar 2012 19:32:11 +0100
Subject: [R-sig-ME] Anova/deviance table in glmmADMB
Message-ID: <4F68CD2B.9020104@cict.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120320/45ddbe3a/attachment-0002.pl>

From jfox at mcmaster.ca  Tue Mar 20 19:45:52 2012
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 20 Mar 2012 14:45:52 -0400
Subject: [R-sig-ME] Anova/deviance table in glmmADMB
In-Reply-To: <4F68CD2B.9020104@cict.fr>
References: <4F68CD2B.9020104@cict.fr>
Message-ID: <web-398921101@cgpsrv2.cis.mcmaster.ca>

Dear Thomas,

The Anova() function in the car package doesn't have a specific method for objects produced by glmmADMB() (with which I'm unfamiliar). If there are coef() and vcov() methods for those objects, then the default Anova() method should produce Wald tests.

Best,
 John

------------------------------------------------
John Fox
Sen. William McMaster Prof. of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/

On Tue, 20 Mar 2012 19:32:11 +0100
 Thomas Merkling <thomas.merkling at cict.fr> wrote:
> Dear Ben and other list members,
> 
> - Is there any way to produce a Anova/deviance table for a model fitted 
> with glmmADMB ? I used the Anova() function from the car library for 
> glmer models, but it does not seem to work with glmmadmb (I'm using 
> glmmADMB 0.7) and I would like only one p-value for each term and 
> interaction and NOT one p-value for each level of the interaction.
> 
> - I also tried to compare nested models via LRT using 
> anova(model1,model2) for glmmADMB models but I didn't get any p-values, 
> it produced NaN, although it apparently calculate the differences in 
> likelihood. Where can this come from ?
> 
> - I tried to use the coefplot2 library (downloaded from 
> http://www.math.mcmaster.ca/bolker/R/src/contrib) as showed on the 
> glmmADMB home page ("getting started with glmmADMB"), but I couldn't use 
> it and got this error message : unable to find an inherited method for 
> function "coefplot2", for signature "glmmadmb". Is it normal ?
> It worked fine with glmer output.
> 
>   Thanks for your help !
> Thomas
> -- 
> ****NEW ADDRESS AND PHONE NUMBER ****
> 
> Thomas Merkling, Doctorant (PhD Student)
> Web Page <http://www.edb.ups-tlse.fr/Merkling-Thomas.html>
> 
> Laboratoire "Evolution et Diversit? Biologique" -EDB
> UMR 5174 - b?t 4R1 - bureau 33 RDC
> 
> Universit? Paul Sabatier Toulouse 3
> 118, route de Narbonne
> 31062 TOULOUSE Cedex O9, FRANCE
> 
> T?l: 33 5-61-55-67-56
> Fax: 33 5-61-55-73-27
> 
> 	[[alternative HTML version deleted]]
>



From bbolker at gmail.com  Tue Mar 20 22:43:30 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 20 Mar 2012 17:43:30 -0400
Subject: [R-sig-ME] Anova/deviance table in glmmADMB
In-Reply-To: <4F68CD2B.9020104@cict.fr>
References: <4F68CD2B.9020104@cict.fr>
Message-ID: <4F68FA02.60100@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12-03-20 02:32 PM, Thomas Merkling wrote:
> Dear Ben and other list members,
> 
> - Is there any way to produce a Anova/deviance table for a model
> fitted with glmmADMB ? I used the Anova() function from the car
> library for glmer models, but it does not seem to work with
> glmmadmb (I'm using glmmADMB 0.7) and I would like only one p-value
> for each term and interaction and NOT one p-value for each level of
> the interaction.

  Hmmm.

  car::Anova() should work now -- I had to add a model.frame() and a
df.residual() method for glmmadmb objects.  (The df.residual number
may be a little dodgy -- I'm not sure I counted the parameters right
- -- but I don't think it's actually used for much by default, cause you
get Wald chi-square tests)

  The newest version of glmmADMB is 0.7.5.1 -- it may take a little
while for r-forge to catch up, and I was having a few dependency
issues.  If you don't see it there in ~ 24 hours, drop me a line.

> 
> - I also tried to compare nested models via LRT using 
> anova(model1,model2) for glmmADMB models but I didn't get any
> p-values, it produced NaN, although it apparently calculate the
> differences in likelihood. Where can this come from ?

  This ought to have worked: perhaps you had the models in the wrong
order?

> 
> - I tried to use the coefplot2 library (downloaded from 
> http://www.math.mcmaster.ca/bolker/R/src/contrib) as showed on the 
> glmmADMB home page ("getting started with glmmADMB"), but I
> couldn't use it and got this error message : unable to find an
> inherited method for function "coefplot2", for signature
> "glmmadmb". Is it normal ? It worked fine with glmer output.

  Can you try getting it from r-forge?

  Again, if the problem persists let me know.

  Ben

> 
> Thanks for your help ! Thomas

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPaPoCAAoJED2whTVMEyK9qAYIAJZKoj3hh8fdTR7U22I64HhM
SmLeTSCmauRzlQXbgSeKx720UGsJtGUzu9Sw9AHiTKqpGrujOj48balEf1MF3Crk
vkTsdDM7Pp5y36xsqw6Ps122DnDQ30ctYh6IDD0+XJX7BebEK5P9or4xoy1lvbOj
L6STkB3wmCYKtJMhFJkvvmCu/+S4dSzOb148edSuO0WFwIC4+Gax7UtHhoj1vgkm
2Gfz3uHre+1aEh0CantGyFgAYBxEIA0F/5AloWQLCRCtqSIi8eNCS0HBt9hmzxLW
455R8PXJyVmtrRn2fWO8Fa5/Two56WMeQwYV8DenBtydM+bGe0NHTEiirHtvf/g=
=dVAk
-----END PGP SIGNATURE-----



From bbolker at gmail.com  Wed Mar 21 02:59:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 21 Mar 2012 01:59:16 +0000 (UTC)
Subject: [R-sig-ME] glmm with a tweedie distribution
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF87F@FWC-TLEX10.fwc.state.fl.us>
Message-ID: <loom.20120321T025450-751@post.gmane.org>

Danson, Bryan <Bryan.Danson at ...> writes:

> 

[snip]
>  however I received the following warning:
> 
> glm.fit: algorithm did not converge

  This is probably harmless -- it means that an intermediate
GLM step didn't quite work, probably because you have strongly
separated data (i.e. some places/factor combinations
etc. with all-zero or all-one data)
 
> Does anyone have any suggestions on how to address this?  My data is
> fairly simple, a distance measurement for each of several trap types
> on different dates.
 
> Also, I was trying to produce a summary of the model, however I cannot get the
commands to work.  I tried
> summary(model) which returned:

 
> Error in UseMethod("fixef") : no applicable method for 'fixef'
>   applied to an object of class "c('cpglmm', 'mer', 'cplm')"
 
> >From reading through the literature on the "cplm" package, it suggests:
> 
> summary signature(object = "cpglm")
> 

  Can we see the results of sessionInfo()? I suspect you have a
problem with methods from some packages masking others.  If you have
installed lme4 from r-forge, I suspect you should re-install it from
CRAN ...

  Ben



From yvesrousselle at gmail.com  Wed Mar 21 08:14:04 2012
From: yvesrousselle at gmail.com (Yves Rousselle)
Date: Wed, 21 Mar 2012 11:14:04 +0400
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <CALzuZRQinGU4V91bNjiwM44GuY8hWt9=N9vb0oph6t6gvhF2AA@mail.gmail.com>
References: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com>
	<CALzuZRQinGU4V91bNjiwM44GuY8hWt9=N9vb0oph6t6gvhF2AA@mail.gmail.com>
Message-ID: <CAA8=r0D-DV9yZmNrLpJ96pinVmNVtNp+OmkAv8JvzA6mBESf3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/3d65e3d2/attachment-0002.pl>

From David.Duffy at qimr.edu.au  Wed Mar 21 13:42:43 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 21 Mar 2012 22:42:43 +1000 (EST)
Subject: [R-sig-ME] observation level random effects/kinship model
In-Reply-To: <CAA8=r0D-DV9yZmNrLpJ96pinVmNVtNp+OmkAv8JvzA6mBESf3Q@mail.gmail.com>
References: <CAEQ+J26HD9-7X=v7TdDhdh5WaMd49xmbXPXMPyUqfHorWJ=z7w@mail.gmail.com><CALzuZRQinGU4V91bNjiwM44GuY8hWt9=N9vb0oph6t6gvhF2AA@mail.gmail.com>
	<CAA8=r0D-DV9yZmNrLpJ96pinVmNVtNp+OmkAv8JvzA6mBESf3Q@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1203212222390.16033@orpheus.qimr.edu.au>

On Wed, 21 Mar 2012, Yves Rousselle wrote:

> When I was saying that ASREML was the only package allowing something, it
> was not association mapping but the possibility to specify a
> variance/covariance matrix by directly importing the entire matrix (as in
> the example of specifying an external kinship matrix for a genetic effect).
>
> On Wed, Mar 14, 2012 at 8:28 AM, Ryan King <c.ryan.king at gmail.com> wrote:
>>> You can also use MCMCglmm and R-INLA.
>
> Ryan, have you got some links for what you talk about ? I'm quite surprised
> that there are already packages for doing that because a lot of geneticists
> are using ASREML even if they have to pay for it. I really hope that there
> is a good reason for that !

ASREML is pretty quick and robust for large problems.

I am guessing you want to specify a large (nonsparse) empirical kinship 
matrix.  Then lmekin, in the kinship package, is one R package that allows 
you to do this, but it gets slow for large datasets.  I have hypothesized, 
but never got round to trying, that coxme() in the same package could be 
abused to give a binomial GLMM ;).  AnimalINLA allows one to fit 
arbitrary matrices too:

  If not using compute.Ainverse to calculate the precision matrix
  [the inverse relationship matrix], the precision matrix has to be
  on the form sparseMatrix(i = ,j = , x =), the two first (i ,j)
  are the individuals compared in the relationship matrix (remember
  the individual numbers must match in the relationship matrix and
  the individual number in data (genetic)), third list element
  (values) are the precision values (the corresponding element of the
  precision matrix).


The regress package does gaussian mixed models only.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From phedberg at biol.uw.edu.pl  Wed Mar 21 14:07:46 2012
From: phedberg at biol.uw.edu.pl (Petter Hedberg)
Date: Wed, 21 Mar 2012 14:07:46 +0100
Subject: [R-sig-ME] Question regarding lme repeated measures error in case 1,
 but not case 2
Message-ID: <CAO5UtxOwwCf2fdKviZ_Dg0Km=TN1Gf60fR5vPFMF47zywGQTQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/41552a92/attachment-0002.pl>

From phedberg at biol.uw.edu.pl  Wed Mar 21 14:26:38 2012
From: phedberg at biol.uw.edu.pl (Petter Hedberg)
Date: Wed, 21 Mar 2012 14:26:38 +0100
Subject: [R-sig-ME] Question regarding lme mixed model, error in case 1,
	not in case 2
Message-ID: <CAO5UtxMdQE0+rL3HwwN7-gDbQ9wSxTVmO_QExUZoP4UfS2OE9w@mail.gmail.com>

Hi all subscribing to the r-sig-mixed-model list.
I have questions regarding the model I use, weather it makes sense, and why
I receive an error message in case 1 but not in case 2. It is a repeated
measure experiment.

The experiment consists of two fields, that are divided up in stripes were
every 2nd stripe has been treated with hay-transfer and every 2nd is a
control were no hay transfer has been conducted.
In each stripe 2 permanent plots of 2 m x 2 m were placed out, and
vegetation monitored for three years. Due to that there are differences in
elevation between the plot, each plots elevation has been measured.

The Explanatory variables I have is then Year (2009,2010,2011),Treatment
(Hay/No Hay), and (Elevation).
The response variables are % cover of different vegetation groups.
If I take the vegetation group sedges as an example.

Case 1: mydata<-lme(Sedges~as.factor(Year)*Treatment*Elevation) gives me
this error message

"Error in getGroups.data.frame(dataMix, groups) :
  Invalid formula for groups"

If I however include Site Number (There are 2 sites, with identical design)
I don?t get any error message at all.
Including it as a random is in my opinion not wrong, but not necessary for
this experiment.


Case 2:
mydata<-lme(Sedges~as.factor(Year)*Treatment*Elevation,random=~1|SiteNumber)

Would greatly appreciate any help on this issue.

Best regards, Petter Hedberg



From joerg.luedicke at gmail.com  Wed Mar 21 15:37:13 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Wed, 21 Mar 2012 07:37:13 -0700
Subject: [R-sig-ME] Question regarding lme mixed model, error in case 1,
 not in case 2
In-Reply-To: <CAO5UtxMdQE0+rL3HwwN7-gDbQ9wSxTVmO_QExUZoP4UfS2OE9w@mail.gmail.com>
References: <CAO5UtxMdQE0+rL3HwwN7-gDbQ9wSxTVmO_QExUZoP4UfS2OE9w@mail.gmail.com>
Message-ID: <CAEn158TY97H6+3MPQwsYNfJUwX2WUdUJeU3kxkurZoE=txuNdg@mail.gmail.com>

Some thoughts:

1) In "Case 1" you don't specify a random effect and thus your model
would reduce to a simple linear model. I have never tried it but I can
imagine that specifying at least one random effect is required by
-lme-.

2) Did you look at main effects and 2-way interactions first before
including the 3-way interaction effect?

3) With only 2 fields, estimating a random effect will not be very
useful. But what about stripes? I think you should have varying
intercepts and/or slopes across stripes (or at least check if there is
variation across stripes). If you have perfectly balanced data and no
variation across stripes, I would believe you do not really need a
mixed effects model here. But I might very well miss something since I
am not familiar with agricultural research.

4) If your dependent variable is a percentage/ proportion, a linear
model might not be suitable. How are your outcome variables measured
exactly?

J.

On Wed, Mar 21, 2012 at 6:26 AM, Petter Hedberg <phedberg at biol.uw.edu.pl> wrote:
> Hi all subscribing to the r-sig-mixed-model list.
> I have questions regarding the model I use, weather it makes sense, and why
> I receive an error message in case 1 but not in case 2. It is a repeated
> measure experiment.
>
> The experiment consists of two fields, that are divided up in stripes were
> every 2nd stripe has been treated with hay-transfer and every 2nd is a
> control were no hay transfer has been conducted.
> In each stripe 2 permanent plots of 2 m x 2 m were placed out, and
> vegetation monitored for three years. Due to that there are differences in
> elevation between the plot, each plots elevation has been measured.
>
> The Explanatory variables I have is then Year (2009,2010,2011),Treatment
> (Hay/No Hay), and (Elevation).
> The response variables are % cover of different vegetation groups.
> If I take the vegetation group sedges as an example.
>
> Case 1: mydata<-lme(Sedges~as.factor(Year)*Treatment*Elevation) gives me
> this error message
>
> "Error in getGroups.data.frame(dataMix, groups) :
> ?Invalid formula for groups"
>
> If I however include Site Number (There are 2 sites, with identical design)
> I don?t get any error message at all.
> Including it as a random is in my opinion not wrong, but not necessary for
> this experiment.
>
>
> Case 2:
> mydata<-lme(Sedges~as.factor(Year)*Treatment*Elevation,random=~1|SiteNumber)
>
> Would greatly appreciate any help on this issue.
>
> Best regards, Petter Hedberg
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From juan.santos at vi.ieo.es  Wed Mar 21 16:49:45 2012
From: juan.santos at vi.ieo.es (=?iso-8859-1?Q?Juan_Jos=E9_Santos_Blanco?=)
Date: Wed, 21 Mar 2012 16:49:45 +0100
Subject: [R-sig-ME] coefplot2 package not available
References: <mailman.7.1332327602.21459.r-sig-mixed-models@r-project.org>
Message-ID: <CB98987E6A626A42A92C02833553DEF501679802@ieovigo1.vi.ieo.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/2508ec37/attachment-0002.pl>

From raptorbio at hotmail.com  Wed Mar 21 17:06:40 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Wed, 21 Mar 2012 12:06:40 -0400
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <loom.20120319T194724-653@post.gmane.org>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>,
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>,
	<loom.20120318T185026-397@post.gmane.org>,
	<4F662EA2.2090305@auckland.ac.nz>,
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>,
	<loom.20120319T023745-978@post.gmane.org>,
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>,
	<CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>,
	<loom.20120319T194724-653@post.gmane.org>
Message-ID: <BAY170-W46AC47612EE83EB437B6D1A1400@phx.gbl>


Not sure what I'm missing here, but I'm not finding the offset Poisson and binomial to be equal with my dataset.? 

> sessionInfo()

R version 2.14.1 (2011-12-22)

Platform: x86_64-pc-mingw32/x64 (64-bit)



locale:

[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United 
States.1252??? LC_MONETARY=English_United States.1252 
LC_NUMERIC=C????????????????????????? 

[5] LC_TIME=English_United States.1252??? 



attached base packages:

?[1] stats4??? splines?? tcltk???? stats???? graphics? grDevices utils???? datasets? methods?? base???? 



other attached packages:

?[1] lme4_0.999375-42?? bbmle_1.0.4.1????? numDeriv_2010.11-1 
R2admb_0.7.5?????? Hmisc_3.9-1??????? survival_2.36-10?? 
NCStats_0.2-7????? sciplot_1.0-9???? 

?[9] mgcv_1.7-13??????? Matrix_1.0-3?????? lattice_0.20-0???? 
MASS_7.3-16??????? AED_1.0??????????? circular_0.4-3???? 
boot_1.3-4???????? plotrix_3.3-3???? 



loaded via a namespace (and not attached):

?[1] car_2.0-12??????? cluster_1.14.1??? gamm4_0.1-5?????? 
gdata_2.8.2?????? glmmADMB_0.7.2.5? gplots_2.10.1???? grid_2.14.1?????? 
gtools_2.6.2????? multcomp_1.2-9?? 

[10] nlme_3.1-103????? TeachingDemos_2.7 tools_2.14.1???? 

> #
> # Compare offset Poisson with binomial
> invlogit<-function(x) exp(x)/(1+exp(x))
> test <- read.csv("http://dl.dropbox.com/u/23278690/test.csv", header=T)
> b.glm <- glm(cbind(success,total) ~ (a+b+c)^2 - 1, family="binomial", data=test)
> p.glm <- glm(success ~ (a+b+c)^2 - 1 + offset(log(total)), family="poisson", data=test)
> #
> exp(coef(p.glm))
???????? a????????? b????????? c??????? a:b??????? a:c??????? b:c 
0.03225038 0.15195288 1.40174126 3.48192066 1.01892662 0.97212475 
> #
> inv.logit(coef(b.glm))
???????? a????????? b????????? c??????? a:b??????? a:c??????? b:c 
0.03158208 0.13227007 0.58381656 0.77643718 0.50446378 0.49263445 
> #
> all.equal(exp(coef(p.glm)), invlogit(coef(b.glm)))
[1] "Mean relative difference: 0.6428341"

Could it be related to the number of zeros?

Adam Smith
Dept. Natural Resources Science
University of Rhode Island


 		 	   		  


From Bryan.Danson at MyFWC.com  Wed Mar 21 17:08:51 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Wed, 21 Mar 2012 12:08:51 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAB12F7C1@FWC-TLEX10.fwc.state.fl.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/b5db4a41/attachment-0002.pl>

From raptorbio at hotmail.com  Wed Mar 21 17:10:39 2012
From: raptorbio at hotmail.com (Adam Smith)
Date: Wed, 21 Mar 2012 12:10:39 -0400
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <BAY170-W46AC47612EE83EB437B6D1A1400@phx.gbl>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>,
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>,
	<loom.20120318T185026-397@post.gmane.org>,
	<4F662EA2.2090305@auckland.ac.nz>,
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>,
	<loom.20120319T023745-978@post.gmane.org>,
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>,
	<CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>,
	<loom.20120319T194724-653@post.gmane.org>,
	<BAY170-W46AC47612EE83EB437B6D1A1400@phx.gbl>
Message-ID: <BAY170-W1616B2331C572FEB3907EAA1400@phx.gbl>


Sorry, the binomial model should have read:

b.glm <- glm(cbind(success,total-success) ~ (a+b+c)^2 - 1, family="binomial", data=test)

But the outcome is little changed...

Adam 
 		 	   		  


From c.ryan.king at gmail.com  Wed Mar 21 18:19:44 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Wed, 21 Mar 2012 12:19:44 -0500
Subject: [R-sig-ME] observation level random effects/kinship model
Message-ID: <CAEQ+J25bwdUFmOuHXFTmrAOgGSbqWeJK+hOxBCLaJ9jrdKhRCg@mail.gmail.com>

> Ryan, have you got some links for what you talk about ? I'm quite surprised
> that there are already packages for doing that because a lot of geneticists
> are using ASREML even if they have to pay for it. I really hope that there
> is a good reason for that !

Sorry, I missed this the first time. MCMCglmm allows an arbitrary
correlation matrix for random effects (ginverse options) and has a
built-in for numerator-relatedness-matrix given pedigree. AnimalINLA
also has a built-in for numerator-relatedness-matrix given pedigree.

If that parameterization is awkward/slow, you can also use the
decomposition trick in either.  That is, let K be your matrix, and U
%*% D %*%  t(U) its cholesky factorization. Then you can set the RE
design matrix Z = U %*% sqrt(D) with an identity covariance matrix; in
MCMCglmm that's idv(Z) and in inla a  f( ..., model="z") .

Both these packages rely for speed on Z and or COV(RE) or its inverse
being sparse, so I sometimes play with using the PMA package to
compute a sparse approximate SVD. Presumably an incomplete cholesky
factorization could do the same thing.

ASREML is probably worth the (NIH's) money; my understanding is that
it's fast, flexible, and robust. I don't know if the above have been
designed with very large datasets in mind.

Ryan King



From bbolker at gmail.com  Wed Mar 21 20:28:20 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 21 Mar 2012 15:28:20 -0400
Subject: [R-sig-ME] Anova/deviance table in glmmADMB
In-Reply-To: <4F6A0633.5070809@cict.fr>
References: <4F68CD2B.9020104@cict.fr> <4F68FA02.60100@gmail.com>
	<4F6A0633.5070809@cict.fr>
Message-ID: <4F6A2BD4.7010501@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  [cc'ing to r-sig-mixed-models]

On 12-03-21 12:47 PM, Thomas Merkling wrote:
> 
> 
> Le 20/03/2012 22:43, Ben Bolker a ?crit : On 12-03-20 02:32 PM,
> Thomas Merkling wrote:
>>>> Dear Ben and other list members,
>>>> 
>>>> - Is there any way to produce a Anova/deviance table for a
>>>> model fitted with glmmADMB ? I used the Anova() function from
>>>> the car library for glmer models, but it does not seem to
>>>> work with glmmadmb (I'm using glmmADMB 0.7) and I would like
>>>> only one p-value for each term and interaction and NOT one
>>>> p-value for each level of the interaction.
> Hmmm.
> 
> car::Anova() should work now -- I had to add a model.frame() and a 
> df.residual() method for glmmadmb objects.  (The df.residual
> number may be a little dodgy -- I'm not sure I counted the
> parameters right -- but I don't think it's actually used for much
> by default, cause you get Wald chi-square tests)
> 
> The newest version of glmmADMB is 0.7.5.1 -- it may take a little 
> while for r-forge to catch up, and I was having a few dependency 
> issues.  If you don't see it there in ~ 24 hours, drop me a line.
>> I used glmmADMB 0.7 because some models did not converge with
>> glmmADMB 0.7.2.4 ("function maximizer failed (couldn't find the
>> STD file)")  and I read that with it might work with previous
>> versions ... which was the case .. until today .... Models that
>> were fitted without problem yesterday did not convernge today:
>> "Memory allocation error -- Perhaps you are trying to allocate 
>> too much memory in your program"  and  "function maximizer
>> failed (couldn't find the STD file)"


  Argh.  (That's frustration with software and Murphy's Law, not with
you ...)  What changed between yesterday and today?  You could be
running out of memory simply because you have more large objects
loaded in your R session (or because you're doing something else
memory-intensive on your computer at the same time?), other than that
I don't have a good guess.  If necessary you can squeeze memory a
little bit more by running glmmADMB within R to generate the
appropriate files, running the 'glmmadmb' executable outside of R,
then going back into R to read the results, but I find it very
annoying to work that way.

> 
>> I was never able to download the package via
> 
>> install.packages("glmmADMB", 
>> repos="http://r-forge.r-project.org",type="source")
> 
>> I got a warning :
> 
>> In getDependencies(pkgs, dependencies, available, lib) : package
>> 'glmmADMB' is not available (for R version 2.14.2)
> 
>> And on theR-forge packages page for the glmmADMB project 
>> <https://r-forge.r-project.org/R/?group_id=847>  the build status
>> is "Failed to build" and I never found any source package, but
>> maybe I was not looking at the right place ...
> 

  I am still fighting with R-forge. If necessary I will build some
more recent versions myself and put them up in the other repository space.

>> I will have a look tomorrow if things have changed ...
> 
> 
>>>> - I also tried to compare nested models via LRT using 
>>>> anova(model1,model2) for glmmADMB models but I didn't get
>>>> any p-values, it produced NaN, although it apparently
>>>> calculate the differences in likelihood. Where can this come
>>>> from ?
> This ought to have worked: perhaps you had the models in the wrong 
> order?
>> I think I did it right .... Here is an example
> 
>> modmean=glmmadmb(MeanAggr~Date + Age+ Obs+ 
>> (1|Nest),family="Gamma",data=YESaggr,verbose=FALSE) modmean1=
>> glmmadmb(MeanAggr~Date + Age+ 
>> (1|Nest),family="Gamma",data=YESaggr,verbose=FALSE)
> 
>> anova(modmean,modmean1) Analysis of Variance Table
> 
>> Model 1: MeanAggr ~ Date + Age + Obs Model 2: MeanAggr ~ Date +
>> Age NoPar  LogLik Df  -2logQ P.value 1     9 -726.22 2     5
>> -731.23 -4 -10.012 Message d'avis : In pchisq(q, df, lower.tail,
>> log.p) : production de NaN

  What do you get from anova(modmean1,modmean) ?  In general the
*simpler* model should come first -- in more recent versions of
glmmADMB, the program will rearrange them for you (and warn you).

> 
>> If is specify "test="Chisq"", I got this error message : Erreur
>> dans x$random : $ operator is invalid for atomic vectors

  Yes, in this case glmmADMB is interpreting this argument as another
model you want to consider in the nested sequence.

>>>> - I tried to use the coefplot2 library (downloaded from 
>>>> http://www.math.mcmaster.ca/bolker/R/src/contrib) as showed
>>>> on the glmmADMB home page ("getting started with glmmADMB"),
>>>> but I couldn't use it and got this error message : unable to
>>>> find an inherited method for function "coefplot2", for
>>>> signature "glmmadmb". Is it normal ? It worked fine with
>>>> glmer output.
> Can you try getting it from r-forge?
> 
> Again, if the problem persists let me know.
> 
> Ben
> 
>> on theR-forge packages page for the coefplot2 project 
>> <https://r-forge.r-project.org/R/?group_id=847>  the build status
>> is offline and I got the same error message as for glmmADMB when
>> trying
> 
>> install.packages("coefplot2", 
>> repos="http://r-forge.r-project.org",type="source")
> 

  Double argh.  I will try to get this back up.

 Ben

>> Cheers, Thomas
> 
> 
> 
>>>> Thanks for your help ! Thomas
>> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPaivUAAoJED2whTVMEyK92D0H/1OyF3jbQw3QFjeV3XBCBf51
V6lhoCfq4LFyzk5yp6rQG3VG+lSC1xmtc0kjAp9ei/OGYpb9Wogsqu53U8e3uurQ
J1z+3XRl7DDlmPcf2DDgrLHirQYa7TqwLIzmpY+g8qBM/qgMbY5RyAm0FuRB2lpj
jdBQebHQqKs9ZCa5bW8xBPD6kvNnoFm0H+aGrxORjHRyM1OI+4ye8zmTXHz3CwH/
8ZaPB6tWbd2h0Ga21YhH4EcTNoqGDs83uf/FGmJcwDtUoc+esOnQ3H/gvqAJdmv5
tz+6IZaQX3dPDzf6/H+bTI61c9lYnWphBPEWQDBFDLMccGDcUzH35GYulQGjJko=
=Vm7s
-----END PGP SIGNATURE-----



From livia.audino at gmail.com  Thu Mar 22 02:26:50 2012
From: livia.audino at gmail.com (=?ISO-8859-1?Q?L=EDvia_Dorneles_Audino?=)
Date: Wed, 21 Mar 2012 22:26:50 -0300
Subject: [R-sig-ME] Doubts about the construction of mixed models
In-Reply-To: <CA+FvBS9OCraSBxj4GX+-B-mHY4wreXHExRXa9phezRp8z23-_A@mail.gmail.com>
References: <CA+FvBS9OCraSBxj4GX+-B-mHY4wreXHExRXa9phezRp8z23-_A@mail.gmail.com>
Message-ID: <CA+FvBS9CBhEFiujzX0U-HjmWoXbG-3HHENXgjXgzhGeM5kBczg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/b7cbb8a6/attachment-0002.pl>

From Yanwei.Zhang at cna.com  Thu Mar 22 03:58:22 2012
From: Yanwei.Zhang at cna.com (Zhang,Yanwei)
Date: Wed, 21 Mar 2012 21:58:22 -0500
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <62C3C5515A02CB438EE737153DEF27D20BAB12F7C1@FWC-TLEX10.fwc.state.fl.us>
References: <62C3C5515A02CB438EE737153DEF27D20BAB12F7C1@FWC-TLEX10.fwc.state.fl.us>
Message-ID: <330F1BE39EE22C418B76986DFEC5F8F42BDD223BDB@E2K7CLSTB.cna.com>

Hi Bryan, 

The "cpglmm" uses the "glm.fit" function to generate initial values. So the "glm.fit does not converge" message means that when generating the initial values using GLM, the model does not converge. But this should not be a problem as long as you get a converged "cpglmm" estimate - the final estimates are independent of the initial values. I suspect if you supply initial values, this message will go away. But thank you for reporting this - I will suppress this kind of message in the new release to make it less confusing. 

I believe the "summary" function does not work because you have the "nlme" package in front of the "cplm" package in the search path. If you just detach the "nlme" package, it should work. 

You might want to use the Bayesian tweedie mixed models to assess the "p-values". The function "bcpglmm" does that, but the released version is not quite stable. I was using a block Metropolis update for the random effects, but this oftentimes leads to poor convergence because of the difficulty in tuning the proposal covariance matrix. In the development version, I have added an option to perform the na?ve Gibbs sampler, which proves to be much easier to tune, although at the cost of slower speed. The new version should be released within a month. 

Thanks.

Regards, 
Wayne   
 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Danson, Bryan
Sent: Wednesday, March 21, 2012 11:09 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

>  This is probably harmless -- it means that an intermediate GLM step didn't quite work,

>  probably because you have strongly separated data (i.e. some places/factor combinations etc.

>  with all-zero or all-one data)

I do have strongly separated data, as some trap types did not move at all (therefore all zeros), and others moved a lot.


>  Can we see the results of sessionInfo()? I suspect you have a problem with methods from some

>  packages masking others.  If you have installed lme4 from r-forge, I suspect you should re-

>  install it from CRAN ...

The results from sessionInfo(model) are:

Error in as.list.default(X) :
  no method for coercing this S4 class to a vector

The packages in my workspace were (installed in order):

car
ggplot2
sos
glmmADMB
lme4
nlme
plotrix
cplm

I tried removing all that had to do with GLMMs (glmmADMB, lme4, nlme, cplm) and reinstalling only 'cplm' and have been able to get the summary() function to work.  This results in a list of t-values for each trap type.  From my background reading, I understand that p-values are difficult to determine in GLMMs, however, I am not sure how to interpret the t-values to estimate which trap type is different from the wood traps.  Here are the resulting t-values:

                                                    Estimate Std. Error   t value
(Intercept)                               0.05134    0.68273     0.075
trap_type5-slat                     -1.59469    0.44568    -3.578
trap_typevw-6                      -3.79851    0.71923    -5.281
trap_typevw-sponge         -2.41591    0.52667    -4.587
trap_typewire basket      -27.93281  386.0848    -0.072
trap_typewire on frame   -4.77199    0.90967    -5.246
trap_typewood-6                  0.29933    0.32652     0.917
trap_typewood-thick          0.27437    0.34785     0.789
trap_typeyb-6                      -4.27295    0.80548     -5.305
trap_typeyf-6                       -2.88076    0.58270     -4.944

According to the exploratory plot, it is likely that the wood-6 and wood-thick traps are not different from the standard control.  The others are probably different.

Is there a way to know for sure?

Thank you again,

Bryan


_____________________
Bryan Danson
Biological Scientist I
Fish and Wildlife Research Institute
Florida Fish and Wildlife Conservation Commission

"The significant problems we have cannot be solved at the same level of thinking with which we created them."
~Albert Einstein




	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.



From Yanwei.Zhang at cna.com  Thu Mar 22 04:34:50 2012
From: Yanwei.Zhang at cna.com (Zhang,Yanwei)
Date: Wed, 21 Mar 2012 22:34:50 -0500
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <5CD78996B8F8844D963C875D3159B94A034B7493@DSRCORREO.azti.local>
References: <62C3C5515A02CB438EE737153DEF27D20BAA4EF782@FWC-TLEX10.fwc.state.fl.us><loom.20120319T221655-53@post.gmane.org><CADY6hMU+_riUB8QVDPG_VYwQmEfG5GJ2esHcn5Y6=KeSXk1csQ@mail.gmail.com>
	<330F1BE39EE22C418B76986DFEC5F8F42BDD082C67@E2K7CLSTB.cna.com>
	<5CD78996B8F8844D963C875D3159B94A034B7493@DSRCORREO.azti.local>
Message-ID: <330F1BE39EE22C418B76986DFEC5F8F42BDD223BDE@E2K7CLSTB.cna.com>

Hi Ruben, 

Thank you for the input and the reference. The profile likelihood approach is of course a standard way to estimate the variance function. Because it's so fast, I'm planning to use this to generate starting values in the new version of the cplm package. Indeed, there is another much easier way - since the p parameter is only related to the shape parameter in the underlying gamma distribution and it changes little as the mean varies, you can fit a Gamma regression to the severity data (the positive catch rates only) to get a rough estimate of the shape parameter and then derive the value of p. 

That being said, I still prefer the likelihood-based approach for the Tweedie mixed models.  There is some  philosophical gap when using the PQL approach with the profile likelihood. 1) it's an approximation to the model rather than the underlying likelihood, but the profile likelihood approach depends on the approximated likelihood. 2) it's a quasi-likelihood - glmmPQL reports NA on the likelihood - so a more appropriate way is to use the extended quasi-likelihood. But this will need some ad hoc adjustment because the extended quasi-likelihood does not allow zeros. See the argument in Dunn and Smyth (2005): Series evaluation of Tweedie exponential dispersion models densities. Statistics and Computing, 15, 267-280.    
Doing this via the new glmer function may be a better way. Although the results may not be quite different, the latter has more conceptual clarity. 

Wayne
 

-----Original Message-----
From: Rub?n Roa [mailto:rroa at azti.es] 
Sent: Tuesday, March 20, 2012 2:35 AM
To: Zhang,Yanwei; Bill Pikounis; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] glmm with a tweedie distribution

I wouldn't call it ad hoc. The power parameter p in the variance function that defines the Tweedie family of exponential distributions, v(mu)=phi*mu^p, can be estimated via profile likelihood, and then the maximum profile likelihood estimate of the p parameter can be inserted in the glmm, essentially estimating the glmm by an estimated likelihood. So there are two stages of approximation but the approximation methods are not ad hoc, they are pretty much mainstream approximation methods to complex likelihoods. Here is a pseudo code using the tweedie package and glmmPQL from MASS (plus msm). For a published application you can see Tascheri, Saavedra-Nievas, Roa-Ureta. 2010. Statistical models to standardize catch rates in the multi-species trawl fishery for Patagonian grenadier (Macruronus magellanicus) off Southern Chile. Fisheries Research 105:200-214.

HTH

Ruben

--
Dr. Ruben H. Roa-Ureta
Senior Researcher, AZTI Tecnalia,
Marine Research Division,
Txatxarramendi Ugartea z/g, 48395, Sukarrieta,
Bizkaia, Spain

##################################  Tweedie ####################################
#estimating variance power parameter

#libraries

library(tweedie)

library(MASS)

library(msm)

MyCaseStudy.Tweedie.prof <- tweedie.profile(MyResponseVar ~ log(Y) + log(Z) + ... + Factor1 + Factor2 + ... ,
p.vec=seq(1.0,2.0,by=0.1), data=MyData, link.power=0, fit.glm=FALSE, do.smooth=TRUE, do.plot=TRUE,
method="inversion",conf.level=0.95, phi.method= "mle",verbose=TRUE)

#distributional plot

y <- rtweedie(1000, p= MyCaseStudy.Tweedie.prof $p.max, mu=1, phi= MyCaseStudy.Tweedie.prof $phi.max)
tweedie.plot(seq(0, max(y), length=100), mu=mean(y), p= MyCaseStudy.Tweedie.prof $p.max, phi= MyCaseStudy.Tweedie.prof $phi.max)

#fitting the glmm
MyCaseStudy..Tweedie.mix <- glmmPQL(fixed = MyResponseVar ~ log(Y) + log(Z) + ... + Factor1 + Factor2 + ... ,
random = list(~1|RE), family=tweedie(var.power = MyCaseStudy.Tweedie.prof$p.max, link.power=0), data= MyData)

MyCaseStudy.Tweedie.mix.sum  <- summary(MyCaseStudy.Tweedie.mix)

#estimated covariance of estimates of a subset of coefficients, [3:11]

MyCaseStudy.Tweedie.mix.year.cov <- round(deltamethod(g=list(~exp(x1),~exp(x2),~exp(x3),~exp(x4),~exp(x5),
~exp(x6),~exp(x7),~exp(x8),~exp(x9)), mean= MyCaseStudy.Tweedie.mix.sum$coef$fixed[3:11], cov=vcov(MyCaseStudy.Tweedie.mix)[3:11,3:11],
ses=FALSE),5)

MyCaseStudy.Tweedie.mix.year.se  <- sqrt(diag(MyCaseStudy.Tweedie.mix.year.cov))

MyCaseStudy.Tweedie.mix.year.cor <- cov2cor(MyCaseStudy.Tweedie.mix.year.cov)

-----Mensaje original-----
De: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Zhang,Yanwei
Enviado el: lunes, 19 de marzo de 2012 23:17
Para: Bill Pikounis; r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] glmm with a tweedie distribution

One problem with the "glmmPQL" is that the variance function can not be estimated - you need to pre-specify it in an ad hoc way. The "cpglmm" function in the "cplm" package estimates it directly from the data along with other parameters using MLE. But of course, you can use glmmPQL to generate starting values that are fed to cpglmm.   

Regards,
Wayne 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bill Pikounis
Sent: Monday, March 19, 2012 4:56 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

Bryan,
You might also wish to try the glmmPQL function in Venables and Ripley's MASS package. Someone reported success with it on the SIG-ECO R list nearly a year ago:

https://stat.ethz.ch/pipermail/r-sig-ecology/2011-May/002158.html

Hope that helps.

Bill

On Mon, Mar 19, 2012 at 17:18, Ben Bolker <bbolker at gmail.com> wrote:
> Danson, Bryan <Bryan.Danson at ...> writes:
>
>>
>> Is there a way to run a GLMM with a tweedie distribution?
>>
>
> ?Yes, using the 'cplm' package. ?I expanded the section on ZIGLMMs on 
> http://glmm.wikidot.com/faq to include a bit more stuff on ZIGLMMs, 
> including a bit on ZIGLMMs with a continuous response for the non-zero 
> data.
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From livia.audino at gmail.com  Wed Mar 21 23:59:09 2012
From: livia.audino at gmail.com (=?ISO-8859-1?Q?L=EDvia_Dorneles_Audino?=)
Date: Wed, 21 Mar 2012 19:59:09 -0300
Subject: [R-sig-ME] Doubts about the construction of mixed models
Message-ID: <CA+FvBS9OCraSBxj4GX+-B-mHY4wreXHExRXa9phezRp8z23-_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120321/bafbbc9b/attachment-0002.pl>

From nicole.prause at gmail.com  Mon Mar 19 17:12:34 2012
From: nicole.prause at gmail.com (Nikky)
Date: Mon, 19 Mar 2012 10:12:34 -0600
Subject: [R-sig-ME] Specifying continuous covariates and predictors in lmer
Message-ID: <CAHskT4qiewO9+=BqzZQty2GSziqAoHRpYu-eqeHKnMccHTmv=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120319/76f9822d/attachment-0002.pl>

From livia.audino at gmail.com  Thu Mar 22 12:15:15 2012
From: livia.audino at gmail.com (=?ISO-8859-1?Q?L=EDvia_Dorneles_Audino?=)
Date: Thu, 22 Mar 2012 08:15:15 -0300
Subject: [R-sig-ME] GLMM - how to consider temporal pseudo-replication in
	the analyses?
Message-ID: <CA+FvBS8eii_xvZL_KT3aAh=p0Y+fYG+ZhTJsV6qdV6fJyXX15g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120322/4cc7ae39/attachment-0002.pl>

From laf.nilsson at gmail.com  Thu Mar 22 15:06:49 2012
From: laf.nilsson at gmail.com (Fredrik Nilsson)
Date: Thu, 22 Mar 2012 15:06:49 +0100
Subject: [R-sig-ME] modelling proportions, with aggregated data,
 and the new/old lme4
In-Reply-To: <BAY170-W1616B2331C572FEB3907EAA1400@phx.gbl>
References: <mailman.2928.1331674939.4502.r-sig-mixed-models@r-project.org>
	<15BD8C5A-D46B-496A-B2CB-A617D0E9927F@bristol.ac.uk>
	<loom.20120318T185026-397@post.gmane.org>
	<4F662EA2.2090305@auckland.ac.nz>
	<CAEn158Tu2cz+5Q_eq8Aj+3CdWwn6O3n6b8oOu-vERYLh1b_mcA@mail.gmail.com>
	<loom.20120319T023745-978@post.gmane.org>
	<CANMF+4QzLPdekJzQSsqZYLnvuZso+Z=G-gPcGvb2b5J7iF_kFA@mail.gmail.com>
	<CAEn158TWrk67p3O_13QS0K_43xqxMhMrEnNfuLBs7iG9rT3SMw@mail.gmail.com>
	<loom.20120319T194724-653@post.gmane.org>
	<BAY170-W46AC47612EE83EB437B6D1A1400@phx.gbl>
	<BAY170-W1616B2331C572FEB3907EAA1400@phx.gbl>
Message-ID: <CANMF+4S+xDM2nJ-Rr-be9E18v4H62P0VAZPpzum2CENQngpw3A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120322/eb4d3ef2/attachment-0002.pl>

From Bryan.Danson at MyFWC.com  Thu Mar 22 16:40:25 2012
From: Bryan.Danson at MyFWC.com (Danson, Bryan)
Date: Thu, 22 Mar 2012 11:40:25 -0400
Subject: [R-sig-ME] glmm with a tweedie distribution
In-Reply-To: <330F1BE39EE22C418B76986DFEC5F8F42BDD223BDB@E2K7CLSTB.cna.com>
References: <62C3C5515A02CB438EE737153DEF27D20BAB12F7C1@FWC-TLEX10.fwc.state.fl.us>
	<330F1BE39EE22C418B76986DFEC5F8F42BDD223BDB@E2K7CLSTB.cna.com>
Message-ID: <62C3C5515A02CB438EE737153DEF27D20BAB12F944@FWC-TLEX10.fwc.state.fl.us>

Hi Wayne,

Thank you for the help.  The summary function does work once the "nlme" package is removed.  I was able to get the bcpglmm() function to work as well.  However, the results give a "Mean", "SD", "Na?ve SE", and "Time-series SE" for each trap type.  And I am confused to how to interpret this.

I supposed I should have prefaced all of these emails with the fact that I have very little statistical background.  I have taken courses in undergrad and graduate school, however they are introductory courses and fall far short of this level of mixed-modeling.  I am therefore trying to teach myself this modeling.  I have ordered a few books that have been mentioned on this list to help, I am just waiting on them to come in.  

But with that in mind, thank you all so much for your help. I have learned a great deal so far.  

Bryan

-----Original Message-----
From: Zhang,Yanwei [mailto:Yanwei.Zhang at cna.com] 
Sent: Wednesday, March 21, 2012 10:58 PM
To: Danson, Bryan; r-sig-mixed-models at r-project.org
Subject: RE: Re: [R-sig-ME] glmm with a tweedie distribution

Hi Bryan, 

The "cpglmm" uses the "glm.fit" function to generate initial values. So the "glm.fit does not converge" message means that when generating the initial values using GLM, the model does not converge. But this should not be a problem as long as you get a converged "cpglmm" estimate - the final estimates are independent of the initial values. I suspect if you supply initial values, this message will go away. But thank you for reporting this - I will suppress this kind of message in the new release to make it less confusing. 

I believe the "summary" function does not work because you have the "nlme" package in front of the "cplm" package in the search path. If you just detach the "nlme" package, it should work. 

You might want to use the Bayesian tweedie mixed models to assess the "p-values". The function "bcpglmm" does that, but the released version is not quite stable. I was using a block Metropolis update for the random effects, but this oftentimes leads to poor convergence because of the difficulty in tuning the proposal covariance matrix. In the development version, I have added an option to perform the na?ve Gibbs sampler, which proves to be much easier to tune, although at the cost of slower speed. The new version should be released within a month. 

Thanks.

Regards, 
Wayne   
 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Danson, Bryan
Sent: Wednesday, March 21, 2012 11:09 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmm with a tweedie distribution

>  This is probably harmless -- it means that an intermediate GLM step 
> didn't quite work,

>  probably because you have strongly separated data (i.e. some places/factor combinations etc.

>  with all-zero or all-one data)

I do have strongly separated data, as some trap types did not move at all (therefore all zeros), and others moved a lot.


>  Can we see the results of sessionInfo()? I suspect you have a problem 
> with methods from some

>  packages masking others.  If you have installed lme4 from r-forge, I 
> suspect you should re-

>  install it from CRAN ...

The results from sessionInfo(model) are:

Error in as.list.default(X) :
  no method for coercing this S4 class to a vector

The packages in my workspace were (installed in order):

car
ggplot2
sos
glmmADMB
lme4
nlme
plotrix
cplm

I tried removing all that had to do with GLMMs (glmmADMB, lme4, nlme, cplm) and reinstalling only 'cplm' and have been able to get the summary() function to work.  This results in a list of t-values for each trap type.  From my background reading, I understand that p-values are difficult to determine in GLMMs, however, I am not sure how to interpret the t-values to estimate which trap type is different from the wood traps.  Here are the resulting t-values:

                                                    Estimate Std. Error   t value
(Intercept)                               0.05134    0.68273     0.075
trap_type5-slat                     -1.59469    0.44568    -3.578
trap_typevw-6                      -3.79851    0.71923    -5.281
trap_typevw-sponge         -2.41591    0.52667    -4.587
trap_typewire basket      -27.93281  386.0848    -0.072
trap_typewire on frame   -4.77199    0.90967    -5.246
trap_typewood-6                  0.29933    0.32652     0.917
trap_typewood-thick          0.27437    0.34785     0.789
trap_typeyb-6                      -4.27295    0.80548     -5.305
trap_typeyf-6                       -2.88076    0.58270     -4.944

According to the exploratory plot, it is likely that the wood-6 and wood-thick traps are not different from the standard control.  The others are probably different.

Is there a way to know for sure?

Thank you again,

Bryan


_____________________
Bryan Danson
Biological Scientist I
Fish and Wildlife Research Institute
Florida Fish and Wildlife Conservation Commission

"The significant problems we have cannot be solved at the same level of thinking with which we created them."
~Albert Einstein




	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

NOTICE:  This e-mail message, including any attachments and appended messages, is for the sole use of the intended recipients and may contain confidential and legally privileged information.
If you are not the intended recipient, any review, dissemination, distribution, copying, storage or other use of all or any portion of this message is strictly prohibited.
If you received this message in error, please immediately notify the sender by reply e-mail and delete this message in its entirety.



From a.hayward at sheffield.ac.uk  Fri Mar 23 11:03:28 2012
From: a.hayward at sheffield.ac.uk (Adam Hayward)
Date: Fri, 23 Mar 2012 10:03:28 +0000
Subject: [R-sig-ME] Back-transforming binomial standard errors
Message-ID: <CALQiR0_dED86zBTHmrx8g=ZUq9WRJP_osG+AJfkNWNzLg27Vng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120323/60583daf/attachment-0002.pl>

From Thierry.ONKELINX at inbo.be  Fri Mar 23 12:03:08 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 23 Mar 2012 11:03:08 +0000
Subject: [R-sig-ME] Back-transforming binomial standard errors
In-Reply-To: <CALQiR0_dED86zBTHmrx8g=ZUq9WRJP_osG+AJfkNWNzLg27Vng@mail.gmail.com>
References: <CALQiR0_dED86zBTHmrx8g=ZUq9WRJP_osG+AJfkNWNzLg27Vng@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742757357FD5@inbomail.inbo.be>

Dear Adam,

Personally I would keep the data in the logit scale. If you want some kind of se measurement in the original scale, then I suggest to calculate confidence interval in the logit scale, back-transform the interval and then calculate the width of the interval.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Adam Hayward
Verzonden: vrijdag 23 maart 2012 11:03
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Back-transforming binomial standard errors

Dear R users,

I am using model predictions from binomial GLMMs and Gaussian LMMs to run GAMs to describe the change in several traits across ages. I can back-transform the binomial model predictions, to rescale them for GAM analysis, but then want to weight these predictions by the standard error of the prediction (because less confidence is attached to older ages because fewer individuals are measured). Because I have standard errors from both Gaussian and binomial models, I feel the standard errors from the binomial GLMMs should also be transformed back to the normal scale, but cannot find information on the proper way to do this. I wonder if anyone knows of a solution to this problem?

Best wishes,
Adam


--
Adam Hayward
Post-Doctoral Research Associate
Department of Animal and Plant Sciences
Alfred Denny Building
University of Sheffield
Western Bank
Sheffield S10 2TN
UK

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From teplitsky at mnhn.fr  Fri Mar 23 12:22:57 2012
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Fri, 23 Mar 2012 12:22:57 +0100
Subject: [R-sig-ME] covariances between non normal traits
Message-ID: <4F6C5D11.1040406@mnhn.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120323/2f19ee3a/attachment-0002.pl>

From i.m.s.white at ed.ac.uk  Fri Mar 23 13:45:08 2012
From: i.m.s.white at ed.ac.uk (i white)
Date: Fri, 23 Mar 2012 12:45:08 +0000
Subject: [R-sig-ME] covariances between non normal traits
In-Reply-To: <4F6C5D11.1040406@mnhn.fr>
References: <4F6C5D11.1040406@mnhn.fr>
Message-ID: <4F6C7054.6030304@ed.ac.uk>

Celine,

We can estimate (tetrachoric) correlations between two binomial traits, 
by assuming probits have bivariate normal distribution. I don't know 
whether this fits into GLMM framework.

Celine Teplitsky wrote:
> Dear all,
> 
> I have seen this post by Arthur Gilmour in an ASReml related forum:
>> GLMM models have only been developed for the case of a single GLMM 
>> trait. It is difficult to conceive what is the appropriate error 
>> structure for bivariate GLMM traits when the variances are defined as 
>> functions of the mean. 
> 
> I would like to know what people on this list think about these issues 
> e.g. if we want to estimate correlations between 2 traits with a poisson 
> distribution, are there some special issues to take into account?
> 
> Thanks a lot in advance for your help,
> 
> All the best
> 
> Celine
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From cristiana1710vieira at hotmail.com  Thu Mar 22 17:49:50 2012
From: cristiana1710vieira at hotmail.com (cristiana vieira)
Date: Thu, 22 Mar 2012 16:49:50 +0000
Subject: [R-sig-ME] problem in the implementation of the function "lmer" of
 the "lme4" package - Important
In-Reply-To: <CAO7JsnQZFdA35_65QM_Kf=yLf6PM_-FhmGH2hxOMcMDfyNSeCA@mail.gmail.com>
References: <DUB112-W8E9974D6F1EEDF1BB9B86B05E0@phx.gbl>,
	<CAO7JsnQZFdA35_65QM_Kf=yLf6PM_-FhmGH2hxOMcMDfyNSeCA@mail.gmail.com>
Message-ID: <DUB112-W3371D1556CCBDCE0EABE47B0410@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120322/d262acb3/attachment-0002.pl>

From emm.charpentier at free.fr  Sat Mar 24 10:39:32 2012
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Sat, 24 Mar 2012 09:39:32 +0000 (UTC)
Subject: [R-sig-ME] covariances between non normal traits
References: <4F6C5D11.1040406@mnhn.fr>
Message-ID: <jkk4ok$u4m$1@dough.gmane.org>

Dear Celine, dear list,

That kind of multivariable modeling is (relatively) easy to do in 
(Win)BUGS/JAGS, by programming a logistic model for each trait, whose 
linear predictor could be modeled as (say) a multivariate normal. This 
could provide some kind of comparison standard to which you could compare 
other results obtained by (say) maximum likelihood (see for example the 
dclone package for a possible approach).

I'd recommend you take a look at Gelman's & Hill's (2007) book on 
multilevel regression, whose part 2 discusses that kind of Bayesian 
modeling. Using "weakly informative" priors (e. g. inverse-Wishart priors 
for variances) should give you estimations (point estimates and 
credibility intervals) close to those of a frequentist analysis (but no p-
values : for that, you'll have to do that yourself (not easily : ask 
Douglas Bates...) or resort to Bayes factors). 

HTH,

					Emmanuel Charpentier

On Fri, 23 Mar 2012 12:22:57 +0100, Celine Teplitsky wrote?:

> Dear all,
> 
> I have seen this post by Arthur Gilmour in an ASReml related forum:
>> GLMM models have only been developed for the case of a single GLMM
>> trait. It is difficult to conceive what is the appropriate error
>> structure for bivariate GLMM traits when the variances are defined as
>> functions of the mean.
> 
> I would like to know what people on this list think about these issues
> e.g. if we want to estimate correlations between 2 traits with a poisson
> distribution, are there some special issues to take into account?
> 
> Thanks a lot in advance for your help,
> 
> All the best
> 
> Celine



From bbolker at gmail.com  Mon Mar 26 14:22:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Mar 2012 12:22:08 +0000 (UTC)
Subject: [R-sig-ME] problem in the implementation of the function
References: <DUB112-W8E9974D6F1EEDF1BB9B86B05E0@phx.gbl>,
	<CAO7JsnQZFdA35_65QM_Kf=yLf6PM_-FhmGH2hxOMcMDfyNSeCA@mail.gmail.com>
	<DUB112-W3371D1556CCBDCE0EABE47B0410@phx.gbl>
Message-ID: <loom.20120326T141552-67@post.gmane.org>

cristiana vieira <cristiana1710vieira at ...> writes:

> 
> 

[snip]
 
> When i ran the example given in the help of the software R and I
> obtained the same error: > library(lme4)Loading required package:
> MatrixLoading required package: lattice Attaching package:
> ?Matrix? The following object(s) are masked from
> ?package:base?: det Attaching package: ?lme4? The
> following object(s) are masked from ?package:stats?: AIC, BIC
> > ?lmerstarting httpd help server ... done > (fm1 <- lmer(Reaction ~
> Days + (Days|Subject), sleepstudy))Error in as(ff, "sparseMatrix") :
> unused argument(s) ("sparseMatrix") > sessionInfo()R version 2.14.2
> (2012-02-29)Platform: i386-pc-mingw32/i386 (32-bit) locale:[1]
> LC_COLLATE=Portuguese_Portugal.1252
> LC_CTYPE=Portuguese_Portugal.1252 [3]
> LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C [5]
> LC_TIME=Portuguese_Portugal.1252 attached base packages:[1] stats
> graphics grDevices utils datasets methods base other attached
> packages:[1] lme4_0.999375-42 Matrix_1.0-4 lattice_0.20-0 loaded via
> a namespace (and not attached):[1] grid_2.14.2 nlme_3.1-103
> stats4_2.14.2 tools_2.14.2 


  (Sorry about the mangling of the example format below.)
  I very strongly suspect that this is due to a mismatch with
the version of the Matrix package.  Version 1.0-5 is available
on CRAN; could you please install it (either via update.packages(),
or via install.packages(), or via the appropriate menu item
if you are running in a GUI -- they should all be equivalent)
and report back if the problem persists?
  
   (The listed dependency of the package is only
Matrix >=0.9996875-1 ; we should probably update this, although
we are also working hard to replace the current version of lme4 ...)

  Ben Bolker



From maechler at stat.math.ethz.ch  Mon Mar 26 15:05:28 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 26 Mar 2012 15:05:28 +0200
Subject: [R-sig-ME] problem in the implementation of the function
In-Reply-To: <loom.20120326T141552-67@post.gmane.org>
References: <DUB112-W8E9974D6F1EEDF1BB9B86B05E0@phx.gbl>
	<CAO7JsnQZFdA35_65QM_Kf=yLf6PM_-FhmGH2hxOMcMDfyNSeCA@mail.gmail.com>
	<DUB112-W3371D1556CCBDCE0EABE47B0410@phx.gbl>
	<loom.20120326T141552-67@post.gmane.org>
Message-ID: <20336.27032.434842.590648@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Mon, 26 Mar 2012 12:22:08 +0000 (UTC) writes:

    > cristiana vieira <cristiana1710vieira at ...> writes:
    >> 
    >> 

    > [snip]
 
    >> When i ran the example given in the help of the software
    >> R and I obtained the same error: > library(lme4)Loading
    >> required package: MatrixLoading required package: lattice
    >> Attaching package: ?Matrix? The following object(s)
    >> are masked from ?package:base?: det Attaching
    >> package: ?lme4? The following object(s) are masked
    >> from ?package:stats?: AIC, BIC > ?lmerstarting
    >> httpd help server ... done > (fm1 <- lmer(Reaction ~ Days
    >> + (Days|Subject), sleepstudy))Error in as(ff,
    >> "sparseMatrix") : unused argument(s) ("sparseMatrix") >
    >> sessionInfo()R version 2.14.2 (2012-02-29)Platform:
    >> i386-pc-mingw32/i386 (32-bit) locale:[1]
    >> LC_COLLATE=Portuguese_Portugal.1252
    >> LC_CTYPE=Portuguese_Portugal.1252 [3]
    >> LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C [5]
    >> LC_TIME=Portuguese_Portugal.1252 attached base
    >> packages:[1] stats graphics grDevices utils datasets
    >> methods base other attached packages:[1] lme4_0.999375-42
    >> Matrix_1.0-4 lattice_0.20-0 loaded via a namespace (and
    >> not attached):[1] grid_2.14.2 nlme_3.1-103 stats4_2.14.2
    >> tools_2.14.2


    >   (Sorry about the mangling of the example format below.)
    > I very strongly suspect that this is due to a mismatch
    > with the version of the Matrix package.  Version 1.0-5 is
    > available on CRAN; could you please install it (either via
    > update.packages(), or via install.packages(), or via the
    > appropriate menu item if you are running in a GUI -- they
    > should all be equivalent) and report back if the problem
    > persists?

Hmm,  R-2.14.2  *comes* with Matrix 1.0-4 
*included* (as it is a recommended package).

And many other people have been using the same combination
without any such fundamental problems

Somehow you must really have done something bad to your R (2.14.2)
installation, or to your lme4 installation.  Maybe you should
reinstall R,  or at least re-install lme4 -- for *that* version of R.
I don't think you should reinstall Matrix.

  
    >    (The listed dependency of the package is only Matrix
    > >=0.9996875-1 ; we should probably update this,

we have updated it for lme4.0
however, lme4 (the current one on CRAN) has worked with many
versions of Matrix in the past, and has not depended
specifically on any recent version of Matrix.

    > although we are also working hard to replace the current version of
    > lme4 ...)
[indeed!]



From bbolker at gmail.com  Mon Mar 26 16:53:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Mar 2012 10:53:28 -0400
Subject: [R-sig-ME] help with ordinal mixed model (reposted from r-help)
Message-ID: <4F7082E8.4080109@mcmaster.ca>

[forwarded to r-sig-mixed]

Ivan Allaman <ivanalaman <at> yahoo.com.br> writes:

>
> Good afternoon, gentlemen!

 (Note that we are not all gentlemen here ...)

> After several days studying and researching on categorical data
> (various forums with answers from the owner of the library - all
> incipient) how to interpret the output the function MCMCglmm, come
> to enlist the help of you, if someone has already worked with
> MCMCglmm function in the case of variables ordinal dependent. I've
> read and reread all the pdf's of the package, the coursenotes
> Jarrod, finally, I'm exhausted. To clarify the database, the
> treatment (called fases) consist of three levels (1-pre, 2-propolis
> and 3-vincris) and the ordinal variable response has three
> categories (1-normal, 2-agudo, 3 - cronico). See table!

  Thank you for the reproducible example.

  I'm forwarding this to r-sig-mixed-models at r-project.org,
which is really more appropriate.

  Your biggest problem is that your chain is mixing really, really
badly, probably because your data set is too small/the model is
overfitted ...  you may need to use some informative priors to get
things back on track, or you may need to try something simpler ...

  Ben Bolker

##  a few tweaks for prettier code: set factor labels right away
du <- transform(
read.table('http://dl.dropbox.com/u/33619290/Dados/Dtest.txt',
                           header=TRUE),
                FASES=factor(FASES,
                 labels=c('Normal','Aguda','Cr?nica')),
                ANIMAIS=factor(ANIMAIS),
                ALT.RENAIS=ordered(ALT.RENAIS,
                labels=c('Pre','Propolis','Vincr')))
summary(du)
du <- na.omit(du)

(tabela <- with(du,table(FASES,ALT.RENAIS)))

## this shows that there really isn't very much information
## in the data set ...

library(ggplot2)
ggplot(du,aes(FASES,ALT.RENAIS,group=ANIMAIS))+
    geom_point()+geom_line()+facet_wrap(~ANIMAIS)


library('MCMCglmm')

#the mixed model:
set.seed(1)
mod1 <- MCMCglmm(ALT.RENAIS ~-1+FASES, random= ~ ANIMAIS,
     family='ordinal',pl=TRUE,data=du)
summary(mod1)

xyplot(mod1$Sol)  ## NOT mixing well

## run for longer ...
mod2 <- MCMCglmm(ALT.RENAIS ~-1+FASES, random= ~ ANIMAIS,
     family='ordinal',pl=TRUE,data=du,nitt=100000)
xyplot(mod2$Sol)
xyplot(mod2$CP)  ## !!!

> Then the pain starts, since the documentation is insufficient in
> this case.  According to him Jarrod (forums), the a posteriori means
> of the coefficients of the covariates are the probit
> scale. According to my study, these coefficients are the scores of
> standard normal distribution. More scores should not correspond to
> cutpoints? In this case, we would have j (response variable
> categories) -1 cutpoints, ie, two cutpoints. The output shows me
> only one cutpoint. How can then calculate the probabilities with
> only one cutpoint? According to the documentation (Vignettes, page
> 22), if P (y = k) = F (yk | l (vlatente), 1) - F (yk-1 | l, 1), this
> '1' would probably be the category '1' of the dependent variable?
> Anyway gentlemen, how can I extract the probabilities for the stages
> for each category of the dependent variable? I thank everyone's
> attention.

From
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003671.html :

[for a four-category model]
If l=Xb+Zu+e, the probabilities of falling into each of the four
categories are:

## pnorm(-l)
## pnorm(cp[1]-l)-pnorm(-l)
## pnorm(cp[2]-l)-pnorm(cp[1]-l)
## 1-pnorm(cp[2]-l)

For an unknown individual in category 1 (i.e. set u=0) the prediction
would be

l = -3.605

## category 1: pnorm(-l) = pnorm(3.605) = 0.999
summary(pnorm(-mod2$Sol[,1]))

## category 2: pnorm(cp[1]-l)-pnorm(-l)
summary(pnorm(mod2$CP-mod2$Sol[,1])-pnorm(-mod2$Sol[,1]))

## category 3: pnorm(cp[1]-l) [OR pnorm(cp[1]-l,lower.tail=FALSE)]
summary(pnorm(mod2$CP,lower.tail=FALSE))

library(ordinal) ## model MUST have an intercept according to ?clm
mod3 <- clmm(ALT.RENAIS ~FASES+(1|ANIMAIS),data=du,link="probit")
summary(mod3)

This is not quite working either -- maybe the model is just plain
overfitted?



From j.hadfield at ed.ac.uk  Mon Mar 26 17:15:32 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 26 Mar 2012 16:15:32 +0100
Subject: [R-sig-ME] help with ordinal mixed model (reposted from r-help)
In-Reply-To: <4F7082E8.4080109@mcmaster.ca>
References: <4F7082E8.4080109@mcmaster.ca>
Message-ID: <8FB24AF6-94C0-4B31-876B-3B936D9FBFC8@ed.ac.uk>

Hi,

You do not seem to specify a prior? With ordinal data the residual/ 
units variance is not identified - you need to fix it at something  
(e.g. 1):

prior=list(R=list(V=1, fix=1), G=list(G1=list(....)))

where I will leave ... to your judgement.

If you don't it will generate nonsense.

Jarrod

On 26 Mar 2012, at 15:53, Ben Bolker wrote:

> [forwarded to r-sig-mixed]
>
> Ivan Allaman <ivanalaman <at> yahoo.com.br> writes:
>
>>
>> Good afternoon, gentlemen!
>
> (Note that we are not all gentlemen here ...)
>
>> After several days studying and researching on categorical data
>> (various forums with answers from the owner of the library - all
>> incipient) how to interpret the output the function MCMCglmm, come
>> to enlist the help of you, if someone has already worked with
>> MCMCglmm function in the case of variables ordinal dependent. I've
>> read and reread all the pdf's of the package, the coursenotes
>> Jarrod, finally, I'm exhausted. To clarify the database, the
>> treatment (called fases) consist of three levels (1-pre, 2-propolis
>> and 3-vincris) and the ordinal variable response has three
>> categories (1-normal, 2-agudo, 3 - cronico). See table!
>
>  Thank you for the reproducible example.
>
>  I'm forwarding this to r-sig-mixed-models at r-project.org,
> which is really more appropriate.
>
>  Your biggest problem is that your chain is mixing really, really
> badly, probably because your data set is too small/the model is
> overfitted ...  you may need to use some informative priors to get
> things back on track, or you may need to try something simpler ...
>
>  Ben Bolker
>
> ##  a few tweaks for prettier code: set factor labels right away
> du <- transform(
> read.table('http://dl.dropbox.com/u/33619290/Dados/Dtest.txt',
>                           header=TRUE),
>                FASES=factor(FASES,
>                 labels=c('Normal','Aguda','Cr?nica')),
>                ANIMAIS=factor(ANIMAIS),
>                ALT.RENAIS=ordered(ALT.RENAIS,
>                labels=c('Pre','Propolis','Vincr')))
> summary(du)
> du <- na.omit(du)
>
> (tabela <- with(du,table(FASES,ALT.RENAIS)))
>
> ## this shows that there really isn't very much information
> ## in the data set ...
>
> library(ggplot2)
> ggplot(du,aes(FASES,ALT.RENAIS,group=ANIMAIS))+
>    geom_point()+geom_line()+facet_wrap(~ANIMAIS)
>
>
> library('MCMCglmm')
>
> #the mixed model:
> set.seed(1)
> mod1 <- MCMCglmm(ALT.RENAIS ~-1+FASES, random= ~ ANIMAIS,
>     family='ordinal',pl=TRUE,data=du)
> summary(mod1)
>
> xyplot(mod1$Sol)  ## NOT mixing well
>
> ## run for longer ...
> mod2 <- MCMCglmm(ALT.RENAIS ~-1+FASES, random= ~ ANIMAIS,
>     family='ordinal',pl=TRUE,data=du,nitt=100000)
> xyplot(mod2$Sol)
> xyplot(mod2$CP)  ## !!!
>
>> Then the pain starts, since the documentation is insufficient in
>> this case.  According to him Jarrod (forums), the a posteriori means
>> of the coefficients of the covariates are the probit
>> scale. According to my study, these coefficients are the scores of
>> standard normal distribution. More scores should not correspond to
>> cutpoints? In this case, we would have j (response variable
>> categories) -1 cutpoints, ie, two cutpoints. The output shows me
>> only one cutpoint. How can then calculate the probabilities with
>> only one cutpoint? According to the documentation (Vignettes, page
>> 22), if P (y = k) = F (yk | l (vlatente), 1) - F (yk-1 | l, 1), this
>> '1' would probably be the category '1' of the dependent variable?
>> Anyway gentlemen, how can I extract the probabilities for the stages
>> for each category of the dependent variable? I thank everyone's
>> attention.
>
> From
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003671.html :
>
> [for a four-category model]
> If l=Xb+Zu+e, the probabilities of falling into each of the four
> categories are:
>
> ## pnorm(-l)
> ## pnorm(cp[1]-l)-pnorm(-l)
> ## pnorm(cp[2]-l)-pnorm(cp[1]-l)
> ## 1-pnorm(cp[2]-l)
>
> For an unknown individual in category 1 (i.e. set u=0) the prediction
> would be
>
> l = -3.605
>
> ## category 1: pnorm(-l) = pnorm(3.605) = 0.999
> summary(pnorm(-mod2$Sol[,1]))
>
> ## category 2: pnorm(cp[1]-l)-pnorm(-l)
> summary(pnorm(mod2$CP-mod2$Sol[,1])-pnorm(-mod2$Sol[,1]))
>
> ## category 3: pnorm(cp[1]-l) [OR pnorm(cp[1]-l,lower.tail=FALSE)]
> summary(pnorm(mod2$CP,lower.tail=FALSE))
>
> library(ordinal) ## model MUST have an intercept according to ?clm
> mod3 <- clmm(ALT.RENAIS ~FASES+(1|ANIMAIS),data=du,link="probit")
> summary(mod3)
>
> This is not quite working either -- maybe the model is just plain
> overfitted?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Mon Mar 26 18:12:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Mar 2012 12:12:28 -0400
Subject: [R-sig-ME] [ADMB Users] Anova table for glmm.admb objects
In-Reply-To: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
References: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
Message-ID: <4F70956C.1050009@gmail.com>

On 12-03-26 10:37 AM, Paula Rosewarne wrote:
> 
> Dear All,
> 
> I came across this posting (below) on a different list- how to get an
> Anova table from glmm.admb model objects- but I cannot get the
> car::Anova function to work for my model, or for the owl example I
> worked through from the glmmadmb package help notes, so I am guessing
> my code is wrong
> 
> When I tried it with the owl example I get the following message, the
> same as when I try for my model:
> 
>> car::Anova(fit_zipoiss)
> Error in data.frame(df, teststat, p) : arguments imply differing
> number of rows: 5, 6 In addition: Warning message: In Ops.factor(1,
> Nest) : | not meaningful for factors
> 
> 
> 
> (I am using glmm.admb v0.7.2.4)
> 
> 
> 
> Please could you advise, many thanks,
> 
> Paula
> 

 [cross-posted to ADMB users and r-sig-mixed because I didn't want to
write it twice]

   Before I answer the question I want to strongly caution people about
using the Anova() (Wald) tests on glmmADMB output. I am generally of the
"give people the tools, let them do what they want" [in other words
"give them enough rope"] philosophy (which is why I tweaked glmmADMB to
allow car::Anova() to work), but Wald tests are the most approximate
approach to model comparison and inference.  For vanilla (non-mixed)
linear models they are identical to standard marginal F tests, but for
mixed/generalized/zero-inflated models they are sometimes very poor
approximations. Using anova() on alternative models instead gives a
likelihood ratio test, which is still approximate but is generally much
better (it relies on the normality of the likelihood itself, rather than
on the normality of the sampling distribution of the parameters).  It is
a bit tedious to use in glmmADMB at the moment because I haven't got the
drop1() functionality working yet, but it should be much more reliable.
 Even that is not perfect, though, because it does depend on the
approximate normality of the likelihood estimate; MCMC and parametric
bootstrap approaches are more accurate.

   You need at least version 0.7.2.9.  I am currently struggling to get
the newest version to build properly on r-forge; in the meantime, below
is a helper function to check which versions are available where.  You
may want to use the optional argument  type="source" (as documented at
http://glmmadmb.r-forge.r-project.org) ...

  In the meantime I've put 0.7.2.10 (source only, use type="source") at
the bolker-mcmaster repository and on the alternative r-forge location
(where it should show up within 24 hours).

## helper function to check availability
favail <- function(repos="r-forge.r-project.org",
                   pkg="glmmADMB",
                   ...) {
    hdr <- "http://"
    if (!substr(repos,1,8)==hdr) repos <- paste(hdr,repos,sep="")
    a <- available.packages(contriburl=contrib.url(repos),...)
    if (length(grep(pkg,rownames(a)))==0)
        stop(sprintf("%s unavailable at repos %s",pkg,repos))
    a[pkg,"Version"]
}

favail()  ## unavailable
favail("www.math.mcmaster.ca/bolker/R")  ## 0.7.2.10
favail("glmmadmb.r-forge.r-project.org/repos")  ## 0.6.4

> 
> 
> From the r-sig-mixed-models list: Le 20/03/2012 22:43, Ben Bolker a
> ?crit : On 12-03-20 02:32 PM,
>> Thomas Merkling wrote:
>>>>> Dear Ben and other list members,
>>>>> 
>>>>> - Is there any way to produce a Anova/deviance table for a 
>>>>> model fitted with glmmADMB ? I used the Anova() function
>>>>> from the car library for glmer models, but it does not seem
>>>>> to work with glmmadmb (I'm using glmmADMB 0.7) and I would
>>>>> like only one p-value for each term and interaction and NOT
>>>>> one p-value for each level of the interaction.
> Ben's reply:
>> car::Anova() should work now -- I had to add a model.frame() and a 
>> df.residual() method for glmmadmb objects.  (The df.residual number
>> may be a little dodgy -- I'm not sure I counted the parameters
>> right -- but I don't think it's actually used for much by default,
>> cause you get Wald chi-square tests)
> 
> 
> 
> 
> Paula Rosewarne, PhD researcher, Faculty of Biological Sciences 
> Manton Building 8.17 Clarendon Way University of Leeds LS2 9JT UK
> 
> Email: bspjr at leeds.ac.uk<mailto:bspjr at leeds.ac.uk> 
> _______________________________________________ Users mailing list 
> Users at admb-project.org 
> http://lists.admb-project.org/mailman/listinfo/users



From broog731 at newschool.edu  Mon Mar 26 19:35:41 2012
From: broog731 at newschool.edu (Geoff Brookshire)
Date: Mon, 26 Mar 2012 13:35:41 -0400
Subject: [R-sig-ME] Conflicting p-values from pvals.fnc
In-Reply-To: <CAPB_MR1-ZZHD93Vya_Mg_60HppF5Sg3rSma_1cS3KjqHd3mwHw@mail.gmail.com>
References: <CAPB_MR1-ZZHD93Vya_Mg_60HppF5Sg3rSma_1cS3KjqHd3mwHw@mail.gmail.com>
Message-ID: <CAE1hoOpf8aLY61W48h_p7T=oDBhaiZF-mrrrQHEpSw3mWnT9sQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120326/b887aaad/attachment-0002.pl>

From istazahn at gmail.com  Tue Mar 27 04:18:26 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 26 Mar 2012 22:18:26 -0400
Subject: [R-sig-ME] Help understanding residual variance
Message-ID: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>

Hi all,

I'm trying to understand what the residual variance in this model:

tmp <- subset(sleepstudy, Days == 1 | Days == 9)
m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
tmp$fitted1 <- fitted(m1)

represents. The way I read this specification, an intercept and a
slope is estimated for each subject. Since each subject only has two
measurements, I would expect the Reaction scores to be completely
accounted for by the slopes and intercepts. Yet they are not: the
Residual variance estimate is 440.278.

This is probably a stupid question, but I hope you will be kind enough
to humor me.

Best,
Ista



From 538280 at gmail.com  Tue Mar 27 17:32:10 2012
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 27 Mar 2012 09:32:10 -0600
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
Message-ID: <CAFEqCdzxmBgdFGLN6Hbhsz1BF278-JE11vbkjs27ZQW2=Lztvg@mail.gmail.com>

Yes, each person has their own slope and intercept estimated, however
the slope and intercept are not determined solely by the 2 data points
for that person, but also are affected by the slope and intercept
estimates across all subjects (this is why lmer gives value beyond
lmList).

You can see this if you refit using the nlme package (only because it
has the augPred function which has not been implemented in lme4 yet):

library(nlme)
m2 <- lme( Reaction ~ Days, data=tmp, random=~Days|Subject)
plot(augPred(m2, ~Days, level=c(0,1)))

comparing the m2 model to your m1 gives the same fixed effects, but
slightly different random effects (I probably did not do something
that was needed to make the models exactly the same) but is probably
close enough.

Look at the plot and you will see the fixed effects line, the line for
each subject that includes the random effects, and the data.  The line
for the individual subjects are pulled slightly towards the fixed
effects line and so does not hit the 2 points exactly.  This shows how
the estimate of each individuals values are influenced by the overall
fit.


On Mon, Mar 26, 2012 at 8:18 PM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi all,
>
> I'm trying to understand what the residual variance in this model:
>
> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
> tmp$fitted1 <- fitted(m1)
>
> represents. The way I read this specification, an intercept and a
> slope is estimated for each subject. Since each subject only has two
> measurements, I would expect the Reaction scores to be completely
> accounted for by the slopes and intercepts. Yet they are not: the
> Residual variance estimate is 440.278.
>
> This is probably a stupid question, but I hope you will be kind enough
> to humor me.
>
> Best,
> Ista
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From thomas.merkling at cict.fr  Tue Mar 27 18:29:51 2012
From: thomas.merkling at cict.fr (Thomas Merkling)
Date: Tue, 27 Mar 2012 18:29:51 +0200
Subject: [R-sig-ME] [ADMB Users] Anova table for glmm.admb objects
In-Reply-To: <4F70956C.1050009@gmail.com>
References: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
	<4F70956C.1050009@gmail.com>
Message-ID: <4F71EAFF.1000302@cict.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120327/0c0ae54c/attachment-0002.pl>

From livia.audino at gmail.com  Tue Mar 27 19:14:15 2012
From: livia.audino at gmail.com (=?ISO-8859-1?Q?L=EDvia_Dorneles_Audino?=)
Date: Tue, 27 Mar 2012 14:14:15 -0300
Subject: [R-sig-ME] What error distribution should I use?
In-Reply-To: <CA+FvBS8=mStdtZsiZus1SreWnyRD8Njv-s=7HWr_JoZeww_umQ@mail.gmail.com>
References: <CA+FvBS8=mStdtZsiZus1SreWnyRD8Njv-s=7HWr_JoZeww_umQ@mail.gmail.com>
Message-ID: <CA+FvBS_Fx+nniAYXdgVyH067O+PDG2zXQpMGH58bxk1NUVBHRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120327/3a2e8098/attachment-0002.pl>

From istazahn at gmail.com  Tue Mar 27 20:55:57 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 27 Mar 2012 14:55:57 -0400
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CAFEqCdzxmBgdFGLN6Hbhsz1BF278-JE11vbkjs27ZQW2=Lztvg@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAFEqCdzxmBgdFGLN6Hbhsz1BF278-JE11vbkjs27ZQW2=Lztvg@mail.gmail.com>
Message-ID: <CA+vqiLGVyQpkXHic_spquqWNg3-JMxEVQk696Oy0OVxUsQREEg@mail.gmail.com>

Thank you Greg, that helps.

-Ista

On Tue, Mar 27, 2012 at 11:32 AM, Greg Snow <538280 at gmail.com> wrote:
>
> Yes, each person has their own slope and intercept estimated, however
> the slope and intercept are not determined solely by the 2 data points
> for that person, but also are affected by the slope and intercept
> estimates across all subjects (this is why lmer gives value beyond
> lmList).
>
> You can see this if you refit using the nlme package (only because it
> has the augPred function which has not been implemented in lme4 yet):
>
> library(nlme)
> m2 <- lme( Reaction ~ Days, data=tmp, random=~Days|Subject)
> plot(augPred(m2, ~Days, level=c(0,1)))
>
> comparing the m2 model to your m1 gives the same fixed effects, but
> slightly different random effects (I probably did not do something
> that was needed to make the models exactly the same) but is probably
> close enough.
>
> Look at the plot and you will see the fixed effects line, the line for
> each subject that includes the random effects, and the data. ?The line
> for the individual subjects are pulled slightly towards the fixed
> effects line and so does not hit the 2 points exactly. ?This shows how
> the estimate of each individuals values are influenced by the overall
> fit.
>
>
> On Mon, Mar 26, 2012 at 8:18 PM, Ista Zahn <istazahn at gmail.com> wrote:
> > Hi all,
> >
> > I'm trying to understand what the residual variance in this model:
> >
> > tmp <- subset(sleepstudy, Days == 1 | Days == 9)
> > m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
> > tmp$fitted1 <- fitted(m1)
> >
> > represents. The way I read this specification, an intercept and a
> > slope is estimated for each subject. Since each subject only has two
> > measurements, I would expect the Reaction scores to be completely
> > accounted for by the slopes and intercepts. Yet they are not: the
> > Residual variance estimate is 440.278.
> >
> > This is probably a stupid question, but I hope you will be kind enough
> > to humor me.
> >
> > Best,
> > Ista
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com



From bbolker at gmail.com  Tue Mar 27 23:42:03 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 27 Mar 2012 17:42:03 -0400
Subject: [R-sig-ME] [ADMB Users] Anova table for glmm.admb objects
In-Reply-To: <4F71EAFF.1000302@cict.fr>
References: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
	<4F70956C.1050009@gmail.com> <4F71EAFF.1000302@cict.fr>
Message-ID: <4F72342B.9000800@gmail.com>

  A couple of things.

  (1) can you update.packages() or re-install R2admb and see if that
helps with the R2admb/dat_write problem?

  (2) I would like to recant the Bolker et al decision tree somewhat.
At the time I wrote it, I was somewhat confused (!!!!) about the
distinction between the two difficulties with inference in the GLMM
situation.

  * model comparisons are better than curvature-based approaches
  * approaches that allow for finite-sample effects are better than
asymptotic approaches
  * there are two different kinds of finite size issues, one applying
more to LMMs (the residual variance parameter used to scale the
likelihood is estimated with uncertainty, hence we get an F statistic
for the null hypothesis) and the other to GLM(M)s (the 'numerator' of
the likelihood itself is only asymptotically normal)  -- this is
detailed a little more carefully at http://glmm.wikidot.com/faq (search
for "degrees of freedom"

  When we wrote the TREE paper I thought it might be OK to use the
classical experimental design 'denominator df' to correct for
finite-size samples, but I'm no longer sure this is a good idea.  In any
case, car::Anova(glmerfit) gives Wald *CHI-SQUARE* tests (not F tests),
so there's no advantage over drop1() except for computational speed.

  Hope that helps.

  Ben Bolker



On 12-03-27 12:29 PM, Thomas Merkling wrote:
> Dear all,
> 
> I'm a bit confused about last comments from Ben Bolker.
> I read Bolker et al., 2009 TREE and what I remembered is that it was
> advised to use Wald tests instead of LRT whent testing for fixed effects
> (and the contrary when testing for random effects). Hence, I'm surprised
> that Ben just said the contrary: is it just true for glmmADMB or for any
> packages ?
> 
> If we want to use more accurate approaches, but if possible not MCMC
> techniques, are there any possibilities with glmmADMB ?
> 
> I tried to install glmmADMB_0.7.2.10 from  bolker-mcmaster repository,
> but I got the following error message:
>  
> Installation d(es) package(s) dans ?C:/Users/thomas
> merkling/Documents/R/win-library/2.14?
> (car ?lib? n'est pas sp?cifi?)
> * installing *source* package 'glmmADMB' ...
> ** R
> ** data
> **  moving datasets to lazyload DB
> 
> Error : l'objet 'dat_write' n'est pas export? par 'namespace:R2admb'
> ERROR: lazydata failed for package 'glmmADMB'
> 
> * removing 'C:/Users/thomas merkling/Documents/R/win-library/2.14/glmmADMB'
> * restoring previous 'C:/Users/thomas
> merkling/Documents/R/win-library/2.14/glmmADMB'
> 
> 
> Thanks in advance !
> Thomas
> 
> 
> Le 26/03/2012 18:12, Ben Bolker a ?crit :
>> On 12-03-26 10:37 AM, Paula Rosewarne wrote:
>>> Dear All,
>>>
>>> I came across this posting (below) on a different list- how to get an
>>> Anova table from glmm.admb model objects- but I cannot get the
>>> car::Anova function to work for my model, or for the owl example I
>>> worked through from the glmmadmb package help notes, so I am guessing
>>> my code is wrong
>>>
>>> When I tried it with the owl example I get the following message, the
>>> same as when I try for my model:
>>>
>>>> car::Anova(fit_zipoiss)
>>> Error in data.frame(df, teststat, p) : arguments imply differing
>>> number of rows: 5, 6 In addition: Warning message: In Ops.factor(1,
>>> Nest) : | not meaningful for factors
>>>
>>>
>>>
>>> (I am using glmm.admb v0.7.2.4)
>>>
>>>
>>>
>>> Please could you advise, many thanks,
>>>
>>> Paula
>>>
>>  [cross-posted to ADMB users and r-sig-mixed because I didn't want to
>> write it twice]
>>
>>    Before I answer the question I want to strongly caution people about
>> using the Anova() (Wald) tests on glmmADMB output. I am generally of the
>> "give people the tools, let them do what they want" [in other words
>> "give them enough rope"] philosophy (which is why I tweaked glmmADMB to
>> allow car::Anova() to work), but Wald tests are the most approximate
>> approach to model comparison and inference.  For vanilla (non-mixed)
>> linear models they are identical to standard marginal F tests, but for
>> mixed/generalized/zero-inflated models they are sometimes very poor
>> approximations. Using anova() on alternative models instead gives a
>> likelihood ratio test, which is still approximate but is generally much
>> better (it relies on the normality of the likelihood itself, rather than
>> on the normality of the sampling distribution of the parameters).  It is
>> a bit tedious to use in glmmADMB at the moment because I haven't got the
>> drop1() functionality working yet, but it should be much more reliable.
>>  Even that is not perfect, though, because it does depend on the
>> approximate normality of the likelihood estimate; MCMC and parametric
>> bootstrap approaches are more accurate.
>>
>>    You need at least version 0.7.2.9.  I am currently struggling to get
>> the newest version to build properly on r-forge; in the meantime, below
>> is a helper function to check which versions are available where.  You
>> may want to use the optional argument  type="source" (as documented at
>> http://glmmadmb.r-forge.r-project.org) ...
>>
>>   In the meantime I've put 0.7.2.10 (source only, use type="source") at
>> the bolker-mcmaster repository and on the alternative r-forge location
>> (where it should show up within 24 hours).
>>
>> ## helper function to check availability
>> favail <- function(repos="r-forge.r-project.org",
>>                    pkg="glmmADMB",
>>                    ...) {
>>     hdr <- "http://"
>>     if (!substr(repos,1,8)==hdr) repos <- paste(hdr,repos,sep="")
>>     a <- available.packages(contriburl=contrib.url(repos),...)
>>     if (length(grep(pkg,rownames(a)))==0)
>>         stop(sprintf("%s unavailable at repos %s",pkg,repos))
>>     a[pkg,"Version"]
>> }
>>
>> favail()  ## unavailable
>> favail("www.math.mcmaster.ca/bolker/R")  ## 0.7.2.10
>> favail("glmmadmb.r-forge.r-project.org/repos")  ## 0.6.4
>>
>>>
>>> From the r-sig-mixed-models list: Le 20/03/2012 22:43, Ben Bolker a
>>> ?crit : On 12-03-20 02:32 PM,
>>>> Thomas Merkling wrote:
>>>>>>> Dear Ben and other list members,
>>>>>>>
>>>>>>> - Is there any way to produce a Anova/deviance table for a 
>>>>>>> model fitted with glmmADMB ? I used the Anova() function
>>>>>>> from the car library for glmer models, but it does not seem
>>>>>>> to work with glmmadmb (I'm using glmmADMB 0.7) and I would
>>>>>>> like only one p-value for each term and interaction and NOT
>>>>>>> one p-value for each level of the interaction.
>>> Ben's reply:
>>>> car::Anova() should work now -- I had to add a model.frame() and a 
>>>> df.residual() method for glmmadmb objects.  (The df.residual number
>>>> may be a little dodgy -- I'm not sure I counted the parameters
>>>> right -- but I don't think it's actually used for much by default,
>>>> cause you get Wald chi-square tests)
>>>
>>>
>>>
>>> Paula Rosewarne, PhD researcher, Faculty of Biological Sciences 
>>> Manton Building 8.17 Clarendon Way University of Leeds LS2 9JT UK
>>>
>>> Email: bspjr at leeds.ac.uk<mailto:bspjr at leeds.ac.uk> 
>>> _______________________________________________ Users mailing list 
>>> Users at admb-project.org 
>>> http://lists.admb-project.org/mailman/listinfo/users
>>
> 
> -- 
> ****NEW ADDRESS AND PHONE NUMBER ****
> 
> Thomas Merkling, Doctorant (PhD Student)
> Web Page <http://www.edb.ups-tlse.fr/Merkling-Thomas.html>
> 
> Laboratoire "Evolution et Diversit? Biologique" -EDB
> UMR 5174 - b?t 4R1 - bureau 33 RDC
> 
> Universit? Paul Sabatier Toulouse 3
> 118, route de Narbonne
> 31062 TOULOUSE Cedex O9, FRANCE
> 
> T?l: 33 5-61-55-67-56
> Fax: 33 5-61-55-73-27



From jfox at mcmaster.ca  Wed Mar 28 00:19:05 2012
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 27 Mar 2012 18:19:05 -0400
Subject: [R-sig-ME] [ADMB Users] Anova table for glmm.admb objects
In-Reply-To: <4F72342B.9000800@gmail.com>
References: <422822288DE88B4BB61E2776DAE3EE1D9ED79CD1F8@HERMES7.ds.leeds.ac.uk>
	<4F70956C.1050009@gmail.com> <4F71EAFF.1000302@cict.fr>
	<4F72342B.9000800@gmail.com>
Message-ID: <web-400061457@cgpsrv2.cis.mcmaster.ca>

Dear Ben and Thomas,

As a brief addendum to Ben's helpful message, Anova.mer() in the development version of the car package on CRAN, which requires the development version of the pbkrtest package, can optionally compute F-tests for linear mixed models fit by REML, using Kenward-Roger df. The implementation may change before the current development version of car is released to CRAN.

Best,
 John

On Tue, 27 Mar 2012 17:42:03 -0400
 Ben Bolker <bbolker at gmail.com> wrote:
>   A couple of things.
> 
>   (1) can you update.packages() or re-install R2admb and see if that
> helps with the R2admb/dat_write problem?
> 
>   (2) I would like to recant the Bolker et al decision tree somewhat.
> At the time I wrote it, I was somewhat confused (!!!!) about the
> distinction between the two difficulties with inference in the GLMM
> situation.
> 
>   * model comparisons are better than curvature-based approaches
>   * approaches that allow for finite-sample effects are better than
> asymptotic approaches
>   * there are two different kinds of finite size issues, one applying
> more to LMMs (the residual variance parameter used to scale the
> likelihood is estimated with uncertainty, hence we get an F statistic
> for the null hypothesis) and the other to GLM(M)s (the 'numerator' of
> the likelihood itself is only asymptotically normal)  -- this is
> detailed a little more carefully at http://glmm.wikidot.com/faq (search
> for "degrees of freedom"
> 
>   When we wrote the TREE paper I thought it might be OK to use the
> classical experimental design 'denominator df' to correct for
> finite-size samples, but I'm no longer sure this is a good idea.  In any
> case, car::Anova(glmerfit) gives Wald *CHI-SQUARE* tests (not F tests),
> so there's no advantage over drop1() except for computational speed.
> 
>   Hope that helps.
> 
>   Ben Bolker
> 
> 
> 
> On 12-03-27 12:29 PM, Thomas Merkling wrote:
> > Dear all,
> > 
> > I'm a bit confused about last comments from Ben Bolker.
> > I read Bolker et al., 2009 TREE and what I remembered is that it was
> > advised to use Wald tests instead of LRT whent testing for fixed effects
> > (and the contrary when testing for random effects). Hence, I'm surprised
> > that Ben just said the contrary: is it just true for glmmADMB or for any
> > packages ?
> > 
> > If we want to use more accurate approaches, but if possible not MCMC
> > techniques, are there any possibilities with glmmADMB ?
> > 
> > I tried to install glmmADMB_0.7.2.10 from  bolker-mcmaster repository,
> > but I got the following error message:
> >  
> > Installation d(es) package(s) dans ?C:/Users/thomas
> > merkling/Documents/R/win-library/2.14?
> > (car ?lib? n'est pas sp?cifi?)
> > * installing *source* package 'glmmADMB' ...
> > ** R
> > ** data
> > **  moving datasets to lazyload DB
> > 
> > Error : l'objet 'dat_write' n'est pas export? par 'namespace:R2admb'
> > ERROR: lazydata failed for package 'glmmADMB'
> > 
> > * removing 'C:/Users/thomas merkling/Documents/R/win-library/2.14/glmmADMB'
> > * restoring previous 'C:/Users/thomas
> > merkling/Documents/R/win-library/2.14/glmmADMB'
> > 
> > 
> > Thanks in advance !
> > Thomas
> > 
> > 
> > Le 26/03/2012 18:12, Ben Bolker a ?crit :
> >> On 12-03-26 10:37 AM, Paula Rosewarne wrote:
> >>> Dear All,
> >>>
> >>> I came across this posting (below) on a different list- how to get an
> >>> Anova table from glmm.admb model objects- but I cannot get the
> >>> car::Anova function to work for my model, or for the owl example I
> >>> worked through from the glmmadmb package help notes, so I am guessing
> >>> my code is wrong
> >>>
> >>> When I tried it with the owl example I get the following message, the
> >>> same as when I try for my model:
> >>>
> >>>> car::Anova(fit_zipoiss)
> >>> Error in data.frame(df, teststat, p) : arguments imply differing
> >>> number of rows: 5, 6 In addition: Warning message: In Ops.factor(1,
> >>> Nest) : | not meaningful for factors
> >>>
> >>>
> >>>
> >>> (I am using glmm.admb v0.7.2.4)
> >>>
> >>>
> >>>
> >>> Please could you advise, many thanks,
> >>>
> >>> Paula
> >>>
> >>  [cross-posted to ADMB users and r-sig-mixed because I didn't want to
> >> write it twice]
> >>
> >>    Before I answer the question I want to strongly caution people about
> >> using the Anova() (Wald) tests on glmmADMB output. I am generally of the
> >> "give people the tools, let them do what they want" [in other words
> >> "give them enough rope"] philosophy (which is why I tweaked glmmADMB to
> >> allow car::Anova() to work), but Wald tests are the most approximate
> >> approach to model comparison and inference.  For vanilla (non-mixed)
> >> linear models they are identical to standard marginal F tests, but for
> >> mixed/generalized/zero-inflated models they are sometimes very poor
> >> approximations. Using anova() on alternative models instead gives a
> >> likelihood ratio test, which is still approximate but is generally much
> >> better (it relies on the normality of the likelihood itself, rather than
> >> on the normality of the sampling distribution of the parameters).  It is
> >> a bit tedious to use in glmmADMB at the moment because I haven't got the
> >> drop1() functionality working yet, but it should be much more reliable.
> >>  Even that is not perfect, though, because it does depend on the
> >> approximate normality of the likelihood estimate; MCMC and parametric
> >> bootstrap approaches are more accurate.
> >>
> >>    You need at least version 0.7.2.9.  I am currently struggling to get
> >> the newest version to build properly on r-forge; in the meantime, below
> >> is a helper function to check which versions are available where.  You
> >> may want to use the optional argument  type="source" (as documented at
> >> http://glmmadmb.r-forge.r-project.org) ...
> >>
> >>   In the meantime I've put 0.7.2.10 (source only, use type="source") at
> >> the bolker-mcmaster repository and on the alternative r-forge location
> >> (where it should show up within 24 hours).
> >>
> >> ## helper function to check availability
> >> favail <- function(repos="r-forge.r-project.org",
> >>                    pkg="glmmADMB",
> >>                    ...) {
> >>     hdr <- "http://"
> >>     if (!substr(repos,1,8)==hdr) repos <- paste(hdr,repos,sep="")
> >>     a <- available.packages(contriburl=contrib.url(repos),...)
> >>     if (length(grep(pkg,rownames(a)))==0)
> >>         stop(sprintf("%s unavailable at repos %s",pkg,repos))
> >>     a[pkg,"Version"]
> >> }
> >>
> >> favail()  ## unavailable
> >> favail("www.math.mcmaster.ca/bolker/R")  ## 0.7.2.10
> >> favail("glmmadmb.r-forge.r-project.org/repos")  ## 0.6.4
> >>
> >>>
> >>> From the r-sig-mixed-models list: Le 20/03/2012 22:43, Ben Bolker a
> >>> ?crit : On 12-03-20 02:32 PM,
> >>>> Thomas Merkling wrote:
> >>>>>>> Dear Ben and other list members,
> >>>>>>>
> >>>>>>> - Is there any way to produce a Anova/deviance table for a 
> >>>>>>> model fitted with glmmADMB ? I used the Anova() function
> >>>>>>> from the car library for glmer models, but it does not seem
> >>>>>>> to work with glmmadmb (I'm using glmmADMB 0.7) and I would
> >>>>>>> like only one p-value for each term and interaction and NOT
> >>>>>>> one p-value for each level of the interaction.
> >>> Ben's reply:
> >>>> car::Anova() should work now -- I had to add a model.frame() and a 
> >>>> df.residual() method for glmmadmb objects.  (The df.residual number
> >>>> may be a little dodgy -- I'm not sure I counted the parameters
> >>>> right -- but I don't think it's actually used for much by default,
> >>>> cause you get Wald chi-square tests)
> >>>
> >>>
> >>>
> >>> Paula Rosewarne, PhD researcher, Faculty of Biological Sciences 
> >>> Manton Building 8.17 Clarendon Way University of Leeds LS2 9JT UK
> >>>
> >>> Email: bspjr at leeds.ac.uk<mailto:bspjr at leeds.ac.uk> 
> >>> _______________________________________________ Users mailing list 
> >>> Users at admb-project.org 
> >>> http://lists.admb-project.org/mailman/listinfo/users
> >>
> > 
> > -- 
> > ****NEW ADDRESS AND PHONE NUMBER ****
> > 
> > Thomas Merkling, Doctorant (PhD Student)
> > Web Page <http://www.edb.ups-tlse.fr/Merkling-Thomas.html>
> > 
> > Laboratoire "Evolution et Diversit? Biologique" -EDB
> > UMR 5174 - b?t 4R1 - bureau 33 RDC
> > 
> > Universit? Paul Sabatier Toulouse 3
> > 118, route de Narbonne
> > 31062 TOULOUSE Cedex O9, FRANCE
> > 
> > T?l: 33 5-61-55-67-56
> > Fax: 33 5-61-55-73-27
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From aramidopsis at gmail.com  Wed Mar 28 02:27:28 2012
From: aramidopsis at gmail.com (Bert Harris)
Date: Tue, 27 Mar 2012 19:27:28 -0500
Subject: [R-sig-ME] Zero inflated GAMM
In-Reply-To: <CA+ZdaBJPSyYCsiGb_UYEK3DxLboBZd_fx4zYad8PjmYP_6eryw@mail.gmail.com>
References: <CA+ZdaBJPSyYCsiGb_UYEK3DxLboBZd_fx4zYad8PjmYP_6eryw@mail.gmail.com>
Message-ID: <CA+ZdaBJU6JuQUyq5xW05SdReAAGhb-6gh_ZFMArFe_7LcjgZuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120327/b6d94013/attachment-0002.pl>

From ivanalaman at yahoo.com.br  Sun Mar 25 22:24:48 2012
From: ivanalaman at yahoo.com.br (Ivan Bezerra Allaman)
Date: Sun, 25 Mar 2012 13:24:48 -0700 (PDT)
Subject: [R-sig-ME] Help ordinal mixed model!
Message-ID: <1332707088.81464.YahooMailNeo@web161804.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120325/e2546b7b/attachment-0002.pl>

From emre_marmara2002 at yahoo.com  Mon Mar 26 10:33:24 2012
From: emre_marmara2002 at yahoo.com (emre karaman)
Date: Mon, 26 Mar 2012 01:33:24 -0700 (PDT)
Subject: [R-sig-ME] question on MCMCglmm
Message-ID: <1332750804.39650.YahooMailClassic@web161405.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120326/5aca9b7e/attachment-0002.pl>

From hannatenbrink at gmail.com  Tue Mar 27 14:58:57 2012
From: hannatenbrink at gmail.com (Hanna ten Brink)
Date: Tue, 27 Mar 2012 14:58:57 +0200
Subject: [R-sig-ME] Dispersion parameter negbin1 in glmmADMB
Message-ID: <CAFVkfMWebic-2RWAOBxHfRK3XyjZGDJiy+cNtpnd4M=5LsKXow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120327/69f24d6e/attachment-0002.pl>

From j.hadfield at ed.ac.uk  Wed Mar 28 10:34:21 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 28 Mar 2012 09:34:21 +0100
Subject: [R-sig-ME] question on MCMCglmm
In-Reply-To: <1332750804.39650.YahooMailClassic@web161405.mail.bf1.yahoo.com>
References: <1332750804.39650.YahooMailClassic@web161405.mail.bf1.yahoo.com>
Message-ID: <20120328093421.60182fymqz7e71gk@www.staffmail.ed.ac.uk>

Hi,

The prior for the fixed effects is (multivariate) normal, specified as:

prior=list(B=list(mu=mu, V=V))

where mu are your prior means, and V your prior (co)variances. The  
default is mu=0 and V = I*1e+10: depending on the scale of your data  
this is probably close to uniform.

The random effects also have a (multivariate) normal prior, determined  
by the estimated variances. You place a hyper-prior on these variances  
by specifying the G element in the prior.

Cheers,

Jarrod


Quoting emre karaman <emre_marmara2002 at yahoo.com> on Mon, 26 Mar 2012  
01:33:24 -0700 (PDT):

> Dear Dr.,
> For one-way anova model I assume a uniform distribution for overall  
> mean, that is p(mu)=1, and a normal distribution for random effects.  
> However, prior specification for
> overall mean
> is not clear, at least yet for me. Could you please tell the way to  
> overcome this problem.
> Best Wishes.?
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From dmcastil at umail.iu.edu  Wed Mar 28 13:02:41 2012
From: dmcastil at umail.iu.edu (Dean Castillo)
Date: Wed, 28 Mar 2012 07:02:41 -0400
Subject: [R-sig-ME] Dispersion parameter negbin1 in glmmADMB
In-Reply-To: <CAFVkfMWebic-2RWAOBxHfRK3XyjZGDJiy+cNtpnd4M=5LsKXow@mail.gmail.com>
References: <CAFVkfMWebic-2RWAOBxHfRK3XyjZGDJiy+cNtpnd4M=5LsKXow@mail.gmail.com>
Message-ID: <CAMmHrnyz2sST2WbbLbgW-wftU6qRKSRqWNoMr9wRPx9tFMBaeQ@mail.gmail.com>

HI Hanna,

It may be very well that GLM and glmm ADMB calculate the
overdispersion parameter in a different way, but the quasipoisson and
negative binomial are not the same.
Quasipoisson uses a mean regression function (like normal poisson) but
leaves the overdispersion parameter unrestricted. Negative binomial
can be represented as a gamma mixture of poisson distributions.

The pscl package has some documentation explaining different types of
count models. It is called: "Regression models for count data in R".
It is useful to help understand count models.

Dean

On Tue, Mar 27, 2012 at 8:58 AM, Hanna ten Brink
<hannatenbrink at gmail.com> wrote:
> Dear R users
>
> I am trying to understand how the dispersion parameter in the glmmADBM
> package is calculated for the negbin1 family.
> Is it correct that the negbin1 family is the same as the quasipoisson
> family?
> Because when I run a simple model in GLM(family=quasipoisson) or in
> glmmADMB(family=negbin) for the Owls-dataset, it gives different dispersion
> parameters.
>
> e.g.
>
> ADBM_binom1 <- glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+
> offset(logBroodSize),
> data=Owls,
> zeroInflation=FALSE,
> family="nbinom1")
>
> Dispersion parameter=8.2014
>
> GLM_quasipois <- glm(NCalls~(FoodTreatment+ArrivalTime)*SexParent+
> offset(logBroodSize),
> data=Owls,
> family=quasipoisson)
>
> Dispersion parameter= 6.259856
>
> Does this mean that the negbin1 and quasipoisson family are not the same?
> Or does the glmmADMB package calculates the dispersion parameter in a
> different way?
>
> Thank you!
>
> Hanna ten Brink
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Wed Mar 28 15:36:05 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 28 Mar 2012 13:36:05 +0000 (UTC)
Subject: [R-sig-ME] Dispersion parameter negbin1 in glmmADMB
References: <CAFVkfMWebic-2RWAOBxHfRK3XyjZGDJiy+cNtpnd4M=5LsKXow@mail.gmail.com>
	<CAMmHrnyz2sST2WbbLbgW-wftU6qRKSRqWNoMr9wRPx9tFMBaeQ@mail.gmail.com>
Message-ID: <loom.20120328T152852-653@post.gmane.org>

Dean Castillo <dmcastil at ...> writes:

> 
> HI Hanna,
> 
> It may be very well that GLM and glmm ADMB calculate the
> overdispersion parameter in a different way, but the quasipoisson and
> negative binomial are not the same.
> Quasipoisson uses a mean regression function (like normal poisson) but
> leaves the overdispersion parameter unrestricted. Negative binomial
> can be represented as a gamma mixture of poisson distributions.

  Yes, but: the negative binomial 'type I', which is fitted here,
is parameterized so that it has the same expected mean-variance
relationship as the quasi-Poisson model, variance=phi*mean.

  Using GLM/quasi-Poisson fits the parameters by iteratively
reweighted least squares (IRLS), then calculates the dispersion
parameter according to

sum(residuals(g2,"pearson")^2)/df.residual(g2)

  Using glmmADMB with type="nbinom1" does a maximum-likelihood
fit to a full model using the aforementioned distribution.
I'm slightly but not terribly surprised that the results are
as different as they are.  I believe (but can't prove right now)
that the max. likelihood and IRLS estimates are the same as long
as you stay in the exponential family, but I think nbinom1 is
*not* in the exponential family.

  Also, when I run glmmADMB I get warning about 

Estimated covariance matrix may not be positive definite

which suggests the possibility that glmmADMB might have
gotten stuck at not-quite-the-optimum value.

> 
> The pscl package has some documentation explaining different types of
> count models. It is called: "Regression models for count data in R".
> It is useful to help understand count models.
> 
> Dean
> 
> On Tue, Mar 27, 2012 at 8:58 AM, Hanna ten Brink
> <hannatenbrink at ...> wrote:
> > Dear R users
> >
> > I am trying to understand how the dispersion parameter in the glmmADBM
> > package is calculated for the negbin1 family.
> > Is it correct that the negbin1 family is the same as the quasipoisson
> > family?
> > Because when I run a simple model in GLM(family=quasipoisson) or in
> > glmmADMB(family=negbin) for the Owls-dataset, it gives different dispersion
> > parameters.
> >
> > e.g.
> >
> > ADBM_binom1 <- glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+
> > offset(logBroodSize),
> > data=Owls,
> > zeroInflation=FALSE,
> > family="nbinom1")
> >
> > Dispersion parameter=8.2014
> >
> > GLM_quasipois <- glm(NCalls~(FoodTreatment+ArrivalTime)*SexParent+
> > offset(logBroodSize),
> > data=Owls,
> > family=quasipoisson)
> >
> > Dispersion parameter= 6.259856
> >
> > Does this mean that the negbin1 and quasipoisson family are not the same?
> > Or does the glmmADMB package calculates the dispersion parameter in a
> > different way?
> >



From bbolker at gmail.com  Wed Mar 28 19:36:11 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 28 Mar 2012 13:36:11 -0400
Subject: [R-sig-ME] coefplot2/glmmADMB
Message-ID: <4F734C0B.3080702@gmail.com>


  For general information:

  I am still struggling to get R-forge to build everything.  glmmADMB
0.7.2.11 , and coefplot2 0.1.3 (on which it generally depends, although
I have removed the dependence for the moment) should be available on the
McMaster repository (via
install.packages(...,repos="http://www.math.mcmaster.ca/bolker/R",type="source")
for now.  I will get stuff working on R-forge as fast as I can, but
remote debugging is a big nuisance.

  Do let me know if you experience difficulty with installation
(continue to direct general questions to the lists; generally
r-sig-mixed-models is best for GLMM- or R-focused questions, ADMB list
should be reserved for technical ADMB questions).

  Ben Bolker



From rajasimhan at gmail.com  Wed Mar 28 20:22:34 2012
From: rajasimhan at gmail.com (Rajasimhan Rajagovindan)
Date: Wed, 28 Mar 2012 13:22:34 -0500
Subject: [R-sig-ME] discrepancy between paired t test and glht on lme models
Message-ID: <CAGf6ir4kr7qij4U6a83zvMi=h1xjBMDV=eeP4yGC+H=HdkQ6PQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/6a45811f/attachment-0002.pl>

From ramos.grad.student at gmail.com  Wed Mar 28 21:52:05 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 28 Mar 2012 12:52:05 -0700
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <4F734C0B.3080702@gmail.com>
References: <4F734C0B.3080702@gmail.com>
Message-ID: <CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/862c7d45/attachment-0002.pl>

From agalecki at umich.edu  Wed Mar 28 22:49:38 2012
From: agalecki at umich.edu (Andrzej)
Date: Wed, 28 Mar 2012 16:49:38 -0400
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
References: <4F734C0B.3080702@gmail.com>
	<CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
Message-ID: <4F737962.6020804@umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/3efbc616/attachment-0002.pl>

From ramos.grad.student at gmail.com  Wed Mar 28 22:53:28 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 28 Mar 2012 13:53:28 -0700
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <4F737962.6020804@umich.edu>
References: <4F734C0B.3080702@gmail.com>
	<CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
	<4F737962.6020804@umich.edu>
Message-ID: <CAHawB9sDaJM3bqKCiVTSO1xCkwxX8azPgBWGBAKvwJxfd99yQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/0771161f/attachment-0002.pl>

From antoine.tardif at usherbrooke.ca  Wed Mar 28 22:54:51 2012
From: antoine.tardif at usherbrooke.ca (Antoine TARDIF)
Date: Wed, 28 Mar 2012 16:54:51 -0400
Subject: [R-sig-ME] structure of a lmer code
Message-ID: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/a094e9e7/attachment-0002.pl>

From A.Robinson at ms.unimelb.edu.au  Wed Mar 28 23:29:23 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 29 Mar 2012 08:29:23 +1100
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <CAHawB9sDaJM3bqKCiVTSO1xCkwxX8azPgBWGBAKvwJxfd99yQA@mail.gmail.com>
References: <4F734C0B.3080702@gmail.com>
	<CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
	<4F737962.6020804@umich.edu>
	<CAHawB9sDaJM3bqKCiVTSO1xCkwxX8azPgBWGBAKvwJxfd99yQA@mail.gmail.com>
Message-ID: <20120328212923.GW56999@ms.unimelb.edu.au>

I suspect that the problem might be that you're using R 2.12.  Time to
upgrade!  Then try again.

Cheers

Andrew

On Wed, Mar 28, 2012 at 01:53:28PM -0700, Antonio P. Ramos wrote:
> Hi Andrzej,
> 
> I doesn't work:
> 
> > install.packages("lme4.0", repos="http://R-Forge.R-project.org")
> Installing package(s) into ?/Users/tournillon/Library/R/2.12/library?
> (as ?lib? is unspecified)
> Warning in install.packages :
>   cannot open: HTTP status was '404 Not Found'
> Warning in install.packages :
>   cannot open: HTTP status was '404 Not Found'
> Warning in install.packages :
>   unable to access index for repository
> http://R-Forge.R-project.org/bin/macosx/leopard/contrib/2.12
> Warning in install.packages :
>   package ?lme4.0? is not available
> 
> On Wed, Mar 28, 2012 at 1:49 PM, Andrzej <agalecki at umich.edu> wrote:
> 
> >  Hi Antonio,
> >
> > lme4.0 is not available from cran.
> >
> > Try
> >
> > install.packages("lme4.0", repos="http://R-Forge.R-project.org"<http://R-Forge.R-project.org>
> > )
> >
> > You are also saying that you have lme4.
> >
> > Note that currently there are two lme4.  The 'old'  and 'new' one.
> >
> > Old lme4 is available at cran and will become deprecated in near future.
> >
> > New can be installed using:
> >
> > install.packages("lme4", repos="http://R-Forge.R-project.org"<http://R-Forge.R-project.org>
> > )
> >
> > Hope it helps
> >
> > Andrzej
> >
> >
> > On 3/28/2012 3:52 PM, Antonio P. Ramos wrote:
> >
> > Hi Ben,
> >
> > I am trying to install your package but it is not working:
> >
> >
> >  install.packages("coefplot2",repos="http://www.math.mcmaster.ca/bolker/R
> >
> >  ",type="source")
> > Installing package(s) into ?/Users/tournillon/Library/R/2.12/library?
> > (as ?lib? is unspecified)
> > Warning: dependency ?lme4.0? is not available
> > trying URL 'http://www.math.mcmaster.ca/bolker/R/src/contrib/coefplot2_0.1.3.tar.gz'
> > Content type 'application/x-gzip' length 616170 bytes (601 Kb)
> > opened URL
> > ==================================================
> > downloaded 601 Kb
> >
> > ERROR: dependency ?lme4.0? is not available for package ?coefplot2?
> > * removing ?/Users/tournillon/Library/R/2.12/library/coefplot2?
> >
> >
> > Then I tried
> >
> > install.packages("lme4.0")
> > Installing package(s) into ?/Users/tournillon/Library/R/2.12/library?
> > (as ?lib? is unspecified)
> > Warning message:
> > In getDependencies(pkgs, dependencies, available, lib) :
> >   package ?lme4.0? is not available
> >
> > but it does not work either. Am I missing something? I do have lme4
> > installed though.
> >
> >
> > On Wed, Mar 28, 2012 at 10:36 AM, Ben Bolker <bbolker at gmail.com> <bbolker at gmail.com> wrote:
> >
> >
> >   For general information:
> >
> >  I am still struggling to get R-forge to build everything.  glmmADMB
> > 0.7.2.11 , and coefplot2 0.1.3 (on which it generally depends, although
> > I have removed the dependence for the moment) should be available on the
> > McMaster repository (via
> > install.packages(...,repos="http://www.math.mcmaster.ca/bolker/R
> > " <http://www.math.mcmaster.ca/bolker/R>,type="source")
> > for now.  I will get stuff working on R-forge as fast as I can, but
> > remote debugging is a big nuisance.
> >
> >  Do let me know if you experience difficulty with installation
> > (continue to direct general questions to the lists; generally
> > r-sig-mixed-models is best for GLMM- or R-focused questions, ADMB list
> > should be reserved for technical ADMB questions).
> >
> >  Ben Bolker
> >
> > _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >  	[[alternative HTML version deleted]]
> >
> >
> >
> >
> > _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 

> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Andrew Robinson  
Deputy Director, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/



From ramos.grad.student at gmail.com  Wed Mar 28 23:58:32 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 28 Mar 2012 14:58:32 -0700
Subject: [R-sig-ME] coefplot2/glmmADMB
In-Reply-To: <CAHawB9t-JULGDqkLOKA-mJYqQMMaUqUYPGHpsdMWwBQo=k8bww@mail.gmail.com>
References: <4F734C0B.3080702@gmail.com>
	<CAHawB9vBOMUYyURdJ1wiNa9Oz-2qXso_-bYNvz8oGDj4ewGzog@mail.gmail.com>
	<4F73710D.2070508@gmail.com>
	<CAHawB9uNQgvNK1udTEVh1+TWpYKOJ7ihMymnn9SgX+Z1ApfVqA@mail.gmail.com>
	<4F73820E.2040902@gmail.com>
	<CAHawB9uE5DLFbTknYTy_DaMRR4gcFb=PF96nYFCJ-Yf0MfPL7Q@mail.gmail.com>
	<4F7385E0.1000803@gmail.com>
	<CAHawB9t-JULGDqkLOKA-mJYqQMMaUqUYPGHpsdMWwBQo=k8bww@mail.gmail.com>
Message-ID: <CAHawB9vxP=PauEypYnN1c2qdjz4Wc5FjhxCOWtR9K7r6gaCPpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120328/48751b61/attachment-0002.pl>

From istazahn at gmail.com  Thu Mar 29 00:46:34 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 28 Mar 2012 18:46:34 -0400
Subject: [R-sig-ME] structure of a lmer code
In-Reply-To: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
Message-ID: <CA+vqiLGpcosCxdtOHktddeDscfTA1r-2VmQFyeJ_psdBp8Q-rg@mail.gmail.com>

Hi Antoine,

I think you want

fm2<-lmer(log(y)~-1+x+(-1+x|group), na.action="na.omit", data=...)

no?

Best,
Ista
2012/3/28 Antoine TARDIF <antoine.tardif at usherbrooke.ca>:
> Dear all,
>
> I would like to fit a multilevel linear model, with varying slope but
> with intercepts fixed at zero (in my experiment, all the samples have
> the same value at time=0).
>
> I have both nested and non-nested factors, but in a first step, we
> would like to fit a lmer model "fm2" equivalent to this lme model
> "fm1" :
>
> library(nlme)
> fm1<-lme(log(y)~x, random=~-1+x|group, na.action="na.omit", data=...)
>
> I tried this code for the lmer function :
> library(lme4)
> fm2<-lmer(log(y)~-1+x+(-1+y|group), na.action="na.omit", data=...)
>
> 1. Instead of providing similar results to fm1, fm2 results do not
> make sense. Is there a mistake in the structure of the fm2 code ?
>
> 2. I also have an other question :
>
> ?> coef(fm1) works, but
> ?> coef(fm2) shows this error message : "unable to align random and
> fixed effects"
>
> What does it mean ?
>
> If someone could help me, thanks a lot in advance..
>
> Antoine Tardif
>
> --
> ? ? ?Antoine TARDIF
> ? D?partement de Biologie
> ? Universit? de Sherbrooke
> ? Sherbrooke (Qc)
> ? J1K 2R1 Canada
>
> ? Bureau D5-0204
> ? (+ 1) 819 821 8000 poste 61928
> ? antoine.tardif at usherbrooke.ca
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kfrost at wisc.edu  Thu Mar 29 00:54:59 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Wed, 28 Mar 2012 17:54:59 -0500
Subject: [R-sig-ME] structure of a lmer code
In-Reply-To: <76c0af142be45.4f7396ad@wiscmail.wisc.edu>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
	<CA+vqiLGpcosCxdtOHktddeDscfTA1r-2VmQFyeJ_psdBp8Q-rg@mail.gmail.com>
	<76c0af142be45.4f7396ad@wiscmail.wisc.edu>
Message-ID: <7690ee202c316.4f735073@wiscmail.wisc.edu>

I think the equivalent to fm1 is actually 

fm2<-lmer(log(y)~1+x+(-1+x|group), na.action="na.omit", data=...)


On 03/28/12, Ista Zahn   wrote:
> Hi Antoine,
> 
> I think you want
> 
> fm2<-lmer(log(y)~-1+x+(-1+x|group), na.action="na.omit", data=...)
> 
> no?
> 
> Best,
> Ista
> 2012/3/28 Antoine TARDIF <antoine.tardif at usherbrooke.ca>:
> > Dear all,
> >
> > I would like to fit a multilevel linear model, with varying slope but
> > with intercepts fixed at zero (in my experiment, all the samples have
> > the same value at time=0).
> >
> > I have both nested and non-nested factors, but in a first step, we
> > would like to fit a lmer model "fm2" equivalent to this lme model
> > "fm1" :
> >
> > library(nlme)
> > fm1<-lme(log(y)~x, random=~-1+x|group, na.action="na.omit", data=...)
> >
> > I tried this code for the lmer function :
> > library(lme4)
> > fm2<-lmer(log(y)~-1+x+(-1+y|group), na.action="na.omit", data=...)
> >
> > 1. Instead of providing similar results to fm1, fm2 results do not
> > make sense. Is there a mistake in the structure of the fm2 code ?
> >
> > 2. I also have an other question :
> >
> > ?> coef(fm1) works, but
> > ?> coef(fm2) shows this error message : "unable to align random and
> > fixed effects"
> >
> > What does it mean ?
> >
> > If someone could help me, thanks a lot in advance..
> >
> > Antoine Tardif
> >
> > --
> > ? ? ?Antoine TARDIF
> > ? D?partement de Biologie
> > ? Universit? de Sherbrooke
> > ? Sherbrooke (Qc)
> > ? J1K 2R1 Canada
> >
> > ? Bureau D5-0204
> > ? (+ 1) 819 821 8000 poste 61928
> > ? antoine.tardif at usherbrooke.ca
> >
> >
> > ? ? ? ?[[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rlevy at ucsd.edu  Thu Mar 29 04:36:32 2012
From: rlevy at ucsd.edu (Levy, Roger)
Date: Thu, 29 Mar 2012 02:36:32 +0000
Subject: [R-sig-ME] Conflicting p-values from pvals.fnc
In-Reply-To: <CAE1hoOpf8aLY61W48h_p7T=oDBhaiZF-mrrrQHEpSw3mWnT9sQ@mail.gmail.com>
References: <CAPB_MR1-ZZHD93Vya_Mg_60HppF5Sg3rSma_1cS3KjqHd3mwHw@mail.gmail.com>
	<CAE1hoOpf8aLY61W48h_p7T=oDBhaiZF-mrrrQHEpSw3mWnT9sQ@mail.gmail.com>
Message-ID: <69314B8E-09C0-4603-8B5F-7DF05C3CC0DD@ucsd.edu>

Hi all,

This example has gotten me pretty confused about how the "weights" argument works for lmer.  I'd always assumed that setting a weight of k for an observation would cause lmer to act as if it had seen k replicates of that observation (i.e., the contribution of the observation to the likelihood would be taken to the k-th power).  After reading this query I found the following post that they are "precision weights not sampling weights":

http://tolstoy.newcastle.edu.au/R/e17/help/12/01/2099.html

I'm not sure what that means -- was my interpretation one of "sampling weights"?

Regardless, I'm noticing what seems to me to be inconsistent behavior in how setting the weights argument affects the t statistic in lmer() output and how the output of pvals.fnc() is affected.  I'm including an example below with a fixed effect of "x" and a random intercept of "a": the higher one sets the weights, the larger the t statistic for x becomes (which is what I'd originally expected given my assumptions about the weights semantics), but the broader the posterior on x becomes in the MCMC output.  This doesn't seem right, does it?  (I also don't understand why the estimate of the random-intercept variance but not the residual variance reported in the lmer output changes.)

> set.seed(1)
> dat <- data.frame(x=rep(c(0,1),each=4),a=factor(rep(c("a","b"),4)),w=1)
> dat$y <- with(dat,10*x+10*(a=="a") + rnorm(8))
> print(m1 <- lmer(y~x+(1|a),dat,weights=1*w))
Linear mixed model fit by REML 
Formula: y ~ x + (1 | a) 
   Data: dat 
   AIC   BIC logLik deviance REMLdev
 32.32 32.64 -12.16    29.97   24.32
Random effects:
 Groups   Name        Variance Std.Dev.
 a        (Intercept) 44.09718 6.64057 
 Residual              0.87763 0.93682 
Number of obs: 8, groups: a, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)   5.0792     4.7186   1.076
x            10.1045     0.6624  15.254

Correlation of Fixed Effects:
  (Intr)
x -0.070
> pvals.fnc(m1)
$fixed
            Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)    5.079    5.037     -1.553      11.32 0.1004   0.3231
x             10.104   10.110      4.917      15.28 0.0038   0.0000

$random
    Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1        a (Intercept)   6.6406     2.6325   3.3750     0.0000     7.6330
2 Residual               0.9368     2.8649   3.2042     0.8809     6.0746

> print(m2 <- lmer(y~x+(1|a),dat,weights=100*w))
Linear mixed model fit by REML 
Formula: y ~ x + (1 | a) 
   Data: dat 
   AIC   BIC logLik deviance REMLdev
 69.17 69.48 -30.58    66.81   61.17
Random effects:
 Groups   Name        Variance Std.Dev.
 a        (Intercept) 0.44097  0.66406 
 Residual             0.87763  0.93682 
Number of obs: 8, groups: a, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)  5.07921    0.47185   10.76
x           10.10449    0.06624  152.54

Correlation of Fixed Effects:
  (Intr)
x -0.070
> pvals.fnc(m2)
$fixed
            Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)    5.079     5.38    -23.816      38.45 0.3434        0
x             10.104    10.11      4.115      16.06 0.0068        0

$random
    Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1        a (Intercept)   0.6641     5.8216  15.7201     0.0000    61.7422
2 Residual               0.9368    23.8808  30.8847     5.2868    71.7694

> print(m3 <- lmer(y~x+(1|a),dat,weights=w/100))
Linear mixed model fit by REML 
Formula: y ~ x + (1 | a) 
   Data: dat 
    AIC    BIC logLik deviance REMLdev
 -4.516 -4.199  6.258   -6.868  -12.52
Random effects:
 Groups   Name        Variance   Std.Dev.
 a        (Intercept) 4409.71731 66.40570
 Residual                0.87763  0.93682
Number of obs: 8, groups: a, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)    5.079     47.187   0.108
x             10.104      6.624   1.525

Correlation of Fixed Effects:
  (Intr)
x -0.070
> pvals.fnc(m3)
$fixed
            Estimate MCMCmean HPD95lower HPD95upper pMCMC Pr(>|t|)
(Intercept)    5.079    5.053    -0.8904      11.28 0.085   0.9178
x             10.104   10.107     5.3060      15.21 0.002   0.1780

$random
    Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1        a (Intercept)  66.4057     2.6379   3.1098     1.1580     6.5406
2 Residual               0.9368     0.2828   0.3121     0.1214     0.5694


I'd be glad to be enlightened...!

Best

Roger



On Mar 26, 2012, at 10:35 AM PDT, Geoff Brookshire wrote:

> Hi listers,
> 
> If you get p-vals using Wald chi-square tests with lme4::anova, they look
> pretty close to the pMCMC output.
> fm.1 <- lmer(y ~ block * condition + (1 | as.factor(subject)),
>             weights = weights, REML = FALSE)
> fm.2 <- lmer(y ~ block + condition + (1 | as.factor(subject)),
>             weights = weights, REML = FALSE)
> anova(fm.1, fm.2)
> 
> This gives p = .35 for the block*condition interaction. For comparison,
> pvals.fnc gave pMCMC = .3 and p(<|t|) < .001. So it looks like p-vals
> derived from t-tests are just way off.
> 
> It seems to me like we should just totally ignore the P(<|t|) output. Does
> anyone who knows more about how these work think otherwise?
> 
> -- geoff
> 
> 
> On Mon, Mar 19, 2012 at 3:25 PM, Tom Gijssels <tom.gijssels at gmail.com>wrote:
> 
>> Dear R-listers,
>> 
>> I'm trying to run a mixed effect model using the lmer() function and have
>> run into some issues in interpreting the p-values generated by
>> pvals.fnc(). The design is a between-subjects design, with two fixed
>> effects (condition & block; each with two levels), and one random effect
>> (subject). Additionally, I have a set of weights that I want to include.
>> 
>> When looking at the pvals.fnc() output,there appears to be a large
>> discrepancy between the pMCMC values and the t-statistic p-values. Whereas
>> one of the main effects and the interaction are far from significant
>> judging by the pMCMC values, they are highly significant when looking at
>> the t-statistic p-values (e.g. Condition: pMCMC = 0.2294; Pr(>|t|) = 0.0000
>> & Condition*Block: pMCMC = 0.3296; Pr(>|t|) = 0.0000) . I have read that
>> the t-statistic based p-values are less conservative, but the difference
>> between these two values seems really extreme.
>> 
>> Below some code that simulates the model and the data. The original data
>> set has two precise characteristics that might influence the results, so I
>> tried to simulate those characteristics in the mock data. That is: 1)
>> there's fewer observations in block A than in block B; and 2) the weights
>> for observations in block A generally are lower than those for block B.
>> 
>> Running this code reproduces the original observation of conflicting pMCMC
>> and p-T-test values. However, when excluding the weights argument from the
>> lmer model, these values seem to converge, suggesting that the weights
>> specification might be underlying these problems.
>> 
>> In short, my question is whether anyone knows why these values diverge and
>> what I could do to address this issue.
>> 
>> Many thanks in advance!
>> 
>> Tom
>> 
>> block <- as.factor(c(rep('a', times = 20), rep('b', times = 200)))
>> condition <- as.factor(c(rep(c('x', 'y'), each = 10), rep(c('x','y'), each
>> = 100)))
>> contrasts(block) <- c(-0.5, 0.5)
>> contrasts(condition) <- c(-0.5, 0.5)
>> 
>> subject <- c(rep(1:4, each = 5), rep(1:4, each = 50))
>> 
>> intercept <- 100
>> block.me <- 20
>> condition.me <- 30
>> err <- rnorm(length(block), sd = 20)
>> weights <- c(rep(1, times = 20), rep(10, times = 200))
>> 
>> y <- intercept + ifelse(block == 'a', block.me, 0) + ifelse(condition ==
>> 'x', condition.me, 0) +
>>   ifelse(block == 'a' & condition == 'x', 30, 0) + (subject * 10) + err
>> 
>> 
>> fm.1 <- lmer(y ~ block * condition + (1 | as.factor(subject)),
>>            weights = weights, REML = FALSE)
>> fm.1.mcmc <- pvals.fnc(fm.1, addPlot=F)
>> 
>>       [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

Roger Levy                      Email: rlevy at ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://idiom.ucsd.edu/~rlevy



From istazahn at gmail.com  Thu Mar 29 05:02:58 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 28 Mar 2012 23:02:58 -0400
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CA+vqiLGVyQpkXHic_spquqWNg3-JMxEVQk696Oy0OVxUsQREEg@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAFEqCdzxmBgdFGLN6Hbhsz1BF278-JE11vbkjs27ZQW2=Lztvg@mail.gmail.com>
	<CA+vqiLGVyQpkXHic_spquqWNg3-JMxEVQk696Oy0OVxUsQREEg@mail.gmail.com>
Message-ID: <CA+vqiLHsJPFXHFkTRSdXjpX=DtvL+quq4bFVoP66K08DeSt7ZA@mail.gmail.com>

Hello again,

Sorry for bringing this up again. The thing is that a statistician
consulting with my research group insists that you cannot have both
random intercepts and random slopes when there are only two
observations per group. Clearly I can fit such a model using lmer(),
but this only serves to convince my local statistician that "R is
doing something strange". I suspect that this is a hopelessly vague
question, but is R doing something strange? Or is my statistician
incorrect in claiming that you can't fit both random intercepts and
random slopes with only two observations per group?

Again, I realize this is not a great question, but I would really
appreciate any thoughts on the matter.

Best,
Ista
On Tue, Mar 27, 2012 at 2:55 PM, Ista Zahn <istazahn at gmail.com> wrote:
> Thank you Greg, that helps.
>
> -Ista
>
> On Tue, Mar 27, 2012 at 11:32 AM, Greg Snow <538280 at gmail.com> wrote:
>>
>> Yes, each person has their own slope and intercept estimated, however
>> the slope and intercept are not determined solely by the 2 data points
>> for that person, but also are affected by the slope and intercept
>> estimates across all subjects (this is why lmer gives value beyond
>> lmList).
>>
>> You can see this if you refit using the nlme package (only because it
>> has the augPred function which has not been implemented in lme4 yet):
>>
>> library(nlme)
>> m2 <- lme( Reaction ~ Days, data=tmp, random=~Days|Subject)
>> plot(augPred(m2, ~Days, level=c(0,1)))
>>
>> comparing the m2 model to your m1 gives the same fixed effects, but
>> slightly different random effects (I probably did not do something
>> that was needed to make the models exactly the same) but is probably
>> close enough.
>>
>> Look at the plot and you will see the fixed effects line, the line for
>> each subject that includes the random effects, and the data. ?The line
>> for the individual subjects are pulled slightly towards the fixed
>> effects line and so does not hit the 2 points exactly. ?This shows how
>> the estimate of each individuals values are influenced by the overall
>> fit.
>>
>>
>> On Mon, Mar 26, 2012 at 8:18 PM, Ista Zahn <istazahn at gmail.com> wrote:
>> > Hi all,
>> >
>> > I'm trying to understand what the residual variance in this model:
>> >
>> > tmp <- subset(sleepstudy, Days == 1 | Days == 9)
>> > m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
>> > tmp$fitted1 <- fitted(m1)
>> >
>> > represents. The way I read this specification, an intercept and a
>> > slope is estimated for each subject. Since each subject only has two
>> > measurements, I would expect the Reaction scores to be completely
>> > accounted for by the slopes and intercepts. Yet they are not: the
>> > Residual variance estimate is 440.278.
>> >
>> > This is probably a stupid question, but I hope you will be kind enough
>> > to humor me.
>> >
>> > Best,
>> > Ista
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com



From reinhold.kliegl at gmail.com  Thu Mar 29 07:45:43 2012
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 29 Mar 2012 07:45:43 +0200
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
Message-ID: <CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>

But why is Greg Snow's response inadequate?

Restating his argument:  In an LMM we are not estimating individual
random effects (means, slopes) and individual residuals, but variance
of random effects and variance of residuals. So there can be
differences between a subject's observed random effect and random
slope  and conditional modes of the distribution of the random effects
(i.e., the point of maximum density), given the observed data and
evaluated at the parameter estimates.

I think your statistician's answer is a good argument that you must
not treat conditional modes as independent observations in a
subsequent analyses. For example, we showed with simulations that
correlations between conditional modes of slopes and intercepts are
larger than the correlation parameter estimated in the LMM (Kliegl,
Masson, & Richer, Visual Cognition, 2010).

Reinhold Kliegl

--
Reinhold Kliegl
http://read.psych.uni-potsdam.de/pmr2

On Tue, Mar 27, 2012 at 4:18 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi all,
>
> I'm trying to understand what the residual variance in this model:
>
> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
> tmp$fitted1 <- fitted(m1)
>
> represents. The way I read this specification, an intercept and a
> slope is estimated for each subject. Since each subject only has two
> measurements, I would expect the Reaction scores to be completely
> accounted for by the slopes and intercepts. Yet they are not: the
> Residual variance estimate is 440.278.
>
> This is probably a stupid question, but I hope you will be kind enough
> to humor me.
>
> Best,
> Ista
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From denis.vile at supagro.inra.fr  Thu Mar 29 10:09:09 2012
From: denis.vile at supagro.inra.fr (Denis Vile)
Date: Thu, 29 Mar 2012 10:09:09 +0200
Subject: [R-sig-ME] crossed effects with lmer but correlation structure with
 lme
In-Reply-To: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
Message-ID: <4F7418A5.7050500@supagro.inra.fr>

Dear R users,

I'm trying to fit a crossed-effects mixed model that would include a 
spatial correlation structure..
The data come from four controlled experiments (control, treatment1, 
treatment2, treatment1+treatment2) on plants grown in a growth chamber.  
Individual replicates of different genotypes were grown together and 
response traits were measured. A covariate X is included in the model 
with a quadratic form.

We fitted the following model using lmer:

fm1 <- lmer(Y ~ 1 + Trt1*Trt2*poly(X, degree=2, raw=T) +
(1|idGenotype) + (1|Trt2:idGenotype) + (1|Trt1:idGenotype) +
             (1|Trt1:Trt2:idGenotype), data=...)

This model is very interesting because we can extract the BLUPs for each 
genotype in each (crossed) environment.

After discussion with colleagues, it appeared that we should try to 
include the possible spatial heterogeneityof the micro-environmentwithin 
the growth chamber. To this end, we tried to fit a model with lme() 
because we cannot easily (if possible) include a correlation structure 
using lmer(). The model is:

fm2 <- lme(Y ~ (X+I(X^2))*idCondition,
             random =~1|idGenotype/idCondition,
             correlation=corGaus(c(15,0.95), 
form=~x+y|idGenotype/idCondition, nugget=T),
             data =...)

where x and y are the coordinates of the plants within the growth chamber.

Since I was unable to fit the crossed effects Trt1 x Trt2 in lme() I 
coded a new variable idCondition which is the combination of Trt1 and 
Trt2, and treated genotypes within idCondition. This is not entirely 
satisfying because it is impossible to extract all BLUPs as in fm1.

Could you please tell me if I missed something and ifthere is a trick to 
specify crossed effects using lme()?
I assume that this should use pdClasses but I'm not at all at ease with 
the matrix specification of mixed models.
Alternatively, include a correlation structure in lmer seems to be 
unfeasible, am I wrong?

Thank you very much for your help,

Denis


-- 

*Denis VILE*
Charg? de Recherche
Laboratoire d'Ecophysiologie des Plantes sous Stress Environnementaux 
(*LEPSE*)
UMR 759 *INRA*-SUPAGRO // Institut de Biologie Int?grative des Plantes 
(IBIP, b?t 7)
2 place Pierre Viala
34060 Montpellier Cedex 2
Tel +33 (0)4 99 61 31 87
Fax +33 (0)4 67 52 21 16
http://www1.montpellier.inra.fr/ibip/lepse/



From giulia.dottisani at gmail.com  Thu Mar 29 10:58:16 2012
From: giulia.dottisani at gmail.com (Giulia Dotti Sani)
Date: Thu, 29 Mar 2012 10:58:16 +0200
Subject: [R-sig-ME] SUR in lmer
Message-ID: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>

Hello everyone,

is there a way of running a seemingly unrelated regression under lme4
or other multilevel packages?

Thank you!

Giulia



From markus.jantti at iki.fi  Thu Mar 29 11:06:38 2012
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Thu, 29 Mar 2012 11:06:38 +0200
Subject: [R-sig-ME] SUR in lmer
In-Reply-To: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>
References: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>
Message-ID: <4F74261E.4050102@iki.fi>

On 03/29/2012 10:58 AM, Giulia Dotti Sani wrote:
> Hello everyone,
>
> is there a way of running a seemingly unrelated regression under lme4
> or other multilevel packages?

Take a look at glm in nlme. You need to specify both a correlation structure (to 
allow the seemingly unrelated units to be correlated through their error terns) 
and a variance function (to allow for different residual variances for the units).

Best,

Markus
>
> Thank you!
>
> Giulia
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Markus Jantti
Professor of Economics
Swedish Institute for Social Research
Stockholm University



From istazahn at gmail.com  Thu Mar 29 12:29:11 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 29 Mar 2012 06:29:11 -0400
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
Message-ID: <CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>

Hi Reinhold,

Good question. My consultant didn't seem impressed when I tried to
articulate that explanation, but perhaps I wasn't clear.

Thanks,
Ista
On Thu, Mar 29, 2012 at 1:45 AM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> But why is Greg Snow's response inadequate?
>
> Restating his argument: ?In an LMM we are not estimating individual
> random effects (means, slopes) and individual residuals, but variance
> of random effects and variance of residuals. So there can be
> differences between a subject's observed random effect and random
> slope ?and conditional modes of the distribution of the random effects
> (i.e., the point of maximum density), given the observed data and
> evaluated at the parameter estimates.
>
> I think your statistician's answer is a good argument that you must
> not treat conditional modes as independent observations in a
> subsequent analyses. For example, we showed with simulations that
> correlations between conditional modes of slopes and intercepts are
> larger than the correlation parameter estimated in the LMM (Kliegl,
> Masson, & Richer, Visual Cognition, 2010).
>
> Reinhold Kliegl
>
> --
> Reinhold Kliegl
> http://read.psych.uni-potsdam.de/pmr2
>
> On Tue, Mar 27, 2012 at 4:18 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> Hi all,
>>
>> I'm trying to understand what the residual variance in this model:
>>
>> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
>> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
>> tmp$fitted1 <- fitted(m1)
>>
>> represents. The way I read this specification, an intercept and a
>> slope is estimated for each subject. Since each subject only has two
>> measurements, I would expect the Reaction scores to be completely
>> accounted for by the slopes and intercepts. Yet they are not: the
>> Residual variance estimate is 440.278.
>>
>> This is probably a stupid question, but I hope you will be kind enough
>> to humor me.
>>
>> Best,
>> Ista
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From giulia.dottisani at gmail.com  Thu Mar 29 17:08:09 2012
From: giulia.dottisani at gmail.com (Giulia Dotti Sani)
Date: Thu, 29 Mar 2012 17:08:09 +0200
Subject: [R-sig-ME] SUR in lmer
In-Reply-To: <4F74261E.4050102@iki.fi>
References: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>
	<4F74261E.4050102@iki.fi>
Message-ID: <CAKz8HvkRYqQai24E0iG2cuNxBn-RC5UnRS8NeyMv3_SaAfgygQ@mail.gmail.com>

Thank you. However, I can't see how I can specify two dependent  variables.

On Thu, Mar 29, 2012 at 11:06 AM, Markus J?ntti <markus.jantti at iki.fi> wrote:
> On 03/29/2012 10:58 AM, Giulia Dotti Sani wrote:
>>
>> Hello everyone,
>>
>> is there a way of running a seemingly unrelated regression under lme4
>> or other multilevel packages?
>
>
> Take a look at glm in nlme. You need to specify both a correlation structure
> (to allow the seemingly unrelated units to be correlated through their error
> terns) and a variance function (to allow for different residual variances
> for the units).
>
> Best,
>
> Markus
>>
>>
>> Thank you!
>>
>> Giulia
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Markus Jantti
> Professor of Economics
> Swedish Institute for Social Research
> Stockholm University
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From markus.jantti at iki.fi  Thu Mar 29 17:26:38 2012
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Thu, 29 Mar 2012 17:26:38 +0200
Subject: [R-sig-ME] SUR in lmer
In-Reply-To: <CAKz8HvkRYqQai24E0iG2cuNxBn-RC5UnRS8NeyMv3_SaAfgygQ@mail.gmail.com>
References: <CAKz8Hvn03pqTHdAB9Zdmpb70AnY6=VBuzZ65bXtAT1z3-7eRmw@mail.gmail.com>
	<4F74261E.4050102@iki.fi>
	<CAKz8HvkRYqQai24E0iG2cuNxBn-RC5UnRS8NeyMv3_SaAfgygQ@mail.gmail.com>
Message-ID: <4F747F2E.8000200@iki.fi>

On 03/29/2012 05:08 PM, Giulia Dotti Sani wrote:
> Thank you. However, I can't see how I can specify two dependent  variables.
>

You don't. You  reshape the data into "long" format, have a factor that 
indicates which unit's observations you are using, interact the explanatory 
variables with that indicator and also use that indicator for the variance 
function.

Markus
> On Thu, Mar 29, 2012 at 11:06 AM, Markus J?ntti<markus.jantti at iki.fi>  wrote:
>> On 03/29/2012 10:58 AM, Giulia Dotti Sani wrote:
>>>
>>> Hello everyone,
>>>
>>> is there a way of running a seemingly unrelated regression under lme4
>>> or other multilevel packages?
>>
>>
>> Take a look at glm in nlme. You need to specify both a correlation structure
>> (to allow the seemingly unrelated units to be correlated through their error
>> terns) and a variance function (to allow for different residual variances
>> for the units).
>>
>> Best,
>>
>> Markus
>>>
>>>
>>> Thank you!
>>>
>>> Giulia
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Markus Jantti
>> Professor of Economics
>> Swedish Institute for Social Research
>> Stockholm University
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Markus Jantti
Professor of Economics
Swedish Institute for Social Research
Stockholm University



From jwiley.psych at gmail.com  Thu Mar 29 17:29:52 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 29 Mar 2012 08:29:52 -0700
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
	<CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
Message-ID: <CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>

Hi Ista,

To me the onis is on the statistician consultant to explain *why* you
cannot have both random intercepts and slopes.  Does the consultant
have papers to reference or proofs?

In any case, this is hardly exclusive to 'R doing something strange'.
SAS and Stata happily join the gang.  See the attached file for code
and output from all three using a minidataset simulated in R.

I suppose one could bicker over whether a random intercept and slope
is a good idea, but possible it certainly is.  You might suggest that
it is poor fare to voice strong opinions about matters which one does
not understand.

Cheers,

Josh

On Thu, Mar 29, 2012 at 3:29 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi Reinhold,
>
> Good question. My consultant didn't seem impressed when I tried to
> articulate that explanation, but perhaps I wasn't clear.
>
> Thanks,
> Ista
> On Thu, Mar 29, 2012 at 1:45 AM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
>> But why is Greg Snow's response inadequate?
>>
>> Restating his argument: ?In an LMM we are not estimating individual
>> random effects (means, slopes) and individual residuals, but variance
>> of random effects and variance of residuals. So there can be
>> differences between a subject's observed random effect and random
>> slope ?and conditional modes of the distribution of the random effects
>> (i.e., the point of maximum density), given the observed data and
>> evaluated at the parameter estimates.
>>
>> I think your statistician's answer is a good argument that you must
>> not treat conditional modes as independent observations in a
>> subsequent analyses. For example, we showed with simulations that
>> correlations between conditional modes of slopes and intercepts are
>> larger than the correlation parameter estimated in the LMM (Kliegl,
>> Masson, & Richer, Visual Cognition, 2010).
>>
>> Reinhold Kliegl
>>
>> --
>> Reinhold Kliegl
>> http://read.psych.uni-potsdam.de/pmr2
>>
>> On Tue, Mar 27, 2012 at 4:18 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>> Hi all,
>>>
>>> I'm trying to understand what the residual variance in this model:
>>>
>>> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
>>> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
>>> tmp$fitted1 <- fitted(m1)
>>>
>>> represents. The way I read this specification, an intercept and a
>>> slope is estimated for each subject. Since each subject only has two
>>> measurements, I would expect the Reaction scores to be completely
>>> accounted for by the slopes and intercepts. Yet they are not: the
>>> Residual variance estimate is 440.278.
>>>
>>> This is probably a stupid question, but I hope you will be kind enough
>>> to humor me.
>>>
>>> Best,
>>> Ista
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/
-------------- next part --------------
############################################################
#                             R                            #
############################################################
set.seed(1)
d <- data.frame(y = c(y <- rnorm(100), y + rnorm(100)),
  x = rep(0:1, each = 100), id = factor(rep(1:100, 2)))

d <- d[order(d$id), ]

require(lme4)
summary(lmer(y ~ 1 + (1 + x | id), data = d))
## > summary(lmer(y ~ 1 + (1 + x | id), data = d))
## Linear mixed model fit by REML
## Formula: y ~ 1 + (1 + x | id)
##    Data: d
##    AIC   BIC logLik deviance REMLdev
##  548.6 565.1 -269.3    535.6   538.6
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  id       (Intercept) 0.60384  0.77707
##           x           0.50393  0.70988  0.366
##  Residual             0.20293  0.45047
## Number of obs: 200, groups: id, 100

## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  0.10885    0.08982   1.212


require(nlme)
summary(lme(y ~ 1, random = ~ 1 + x | id, data = d))

## > summary(lme(y ~ 1, random = ~ 1 + x | id, data = d))
## Linear mixed-effects model fit by REML
##  Data: d
##        AIC      BIC    logLik
##   548.6301 565.0967 -269.3151

## Random effects:
##  Formula: ~1 + x | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev    Corr
## (Intercept) 0.8231605 (Intr)
## x           0.8071236 0.193
## Residual    0.3594008

## Fixed effects: y ~ 1
##                 Value  Std.Error  DF  t-value p-value
## (Intercept) 0.1088521 0.08981989 100 1.211893  0.2284

## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max
## -1.18533542 -0.26837701 -0.03513932  0.29186404  1.25726715

## Number of Observations: 200
## Number of Groups: 100

require(foreign)
write.dta(d, file = "d:/d.dta")
write.csv(d, file = "d:/d.csv", row.names = FALSE)


############################################################
#                            SAS                           #
############################################################

# options nocenter nolabel nodate formchar="|----|+|---+=|-/\<>";
# PROC IMPORT OUT= WORK.d
#             DATAFILE= "D:\d.csv"
#             DBMS=CSV REPLACE;
#      GETNAMES=YES;
#      DATAROW=2;
# RUN;
#
# proc mixed data=d method=reml noclprint;
#   class id;
#   model y = / solution;
#   random int x / subject=id type=un;
# run;

## The Mixed Procedure
##                   Model Information
## Data Set                     WORK.D
## Dependent Variable           y
## Covariance Structure         Unstructured
## Subject Effect               id
## Estimation Method            REML
## Residual Variance Method     Profile
## Fixed Effects SE Method      Model-Based
## Degrees of Freedom Method    Containment

##             Dimensions
## Covariance Parameters             4
## Columns in X                      1
## Columns in Z Per Subject          2
## Subjects                        100
## Max Obs Per Subject               2

## Number of Observations
## Number of Observations Read             200
## Number of Observations Used             200
## Number of Observations Not Used           0
##                      Iteration History
## Iteration    Evaluations    -2 Res Log Like       Criterion
##         0              1       615.81799232
##         1              4       545.16825286      0.05801788
##         2              1       539.21410924      0.00597671
##         3              1       538.64539097      0.00017233
##         4              1       538.63016700      0.00000020
##         5              1       538.63014985      0.00000000
##                    Convergence criteria met.

##  Covariance Parameter Estimates
## Cov Parm     Subject    Estimate
## UN(1,1)      id           0.3519
## UN(2,1)      id           0.4540
## UN(2,2)      id                0
## Residual                  0.4549

##            Fit Statistics
## -2 Res Log Likelihood           538.6
## AIC (smaller is better)         544.6
## AICC (smaller is better)        544.8
## BIC (smaller is better)         552.4

##   Null Model Likelihood Ratio Test
##     DF    Chi-Square      Pr > ChiSq
##      2         77.19          <.0001

##                    Solution for Fixed Effects
##                          Standard
## Effect       Estimate       Error      DF    t Value    Pr > |t|
## Intercept      0.1089     0.08982      99       1.21      0.2284


############################################################
#                          Stata                           #
############################################################

# use "d:/d.dta", clear
# xtmixed y || id: x, cov(un) reml
# di -2*e(ll)

## . use "d:/d.dta", clear
## (Written by R.              )

## . xtmixed y || id: x, cov(un) reml

## Performing EM optimization:

## Performing gradient-based optimization:

## Iteration 0:   log restricted-likelihood = -269.31507
## Iteration 1:   log restricted-likelihood = -269.31507  (backed up)

## Computing standard errors:

## Mixed-effects REML regression                   Number of obs      =       200
## Group variable: id                              Number of groups   =       100

##                                                 Obs per group: min =         2
##                                                                avg =       2.0
##                                                                max =         2


##                                                 Wald chi2(0)       =         .
## Log restricted-likelihood = -269.31507          Prob > chi2        =         .

## ------------------------------------------------------------------------------
##            y |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##        _cons |   .1088521   .0898198     1.21   0.226    -.0671914    .2848956
## ------------------------------------------------------------------------------

## ------------------------------------------------------------------------------
##   Random-effects Parameters  |   Estimate   Std. Err.     [95% Conf. Interval]
## -----------------------------+------------------------------------------------
## id: Unstructured             |
##                        sd(x) |   .8071714   31.05985      1.42e-33    4.58e+32
##                    sd(_cons) |   .8231815   15.22811      1.48e-16    4.59e+15
##                corr(x,_cons) |   .1930683   48.73245            -1           1
## -----------------------------+------------------------------------------------
##                 sd(Residual) |   .3593491    34.8834      8.44e-84    1.53e+82
## ------------------------------------------------------------------------------
## LR test vs. linear regression:       chi2(3) =    77.19   Prob > chi2 = 0.0000

## Note: LR test is conservative and provided only for reference.

## . di -2*e(ll)
## 538.63015

From istazahn at gmail.com  Thu Mar 29 18:28:36 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 29 Mar 2012 12:28:36 -0400
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
	<CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
	<CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>
Message-ID: <CA+vqiLHSBD3U0uJcLVAd_Ugb+=oGHHBFEhBOfsgye=0XnJN++w@mail.gmail.com>

Thanks Josh, the comparison with SAS and Stata is very useful. I'll
see what my consultant has to say about this example.

Best,
Ista

On Thu, Mar 29, 2012 at 11:29 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Ista,
>
> To me the onis is on the statistician consultant to explain *why* you
> cannot have both random intercepts and slopes. ?Does the consultant
> have papers to reference or proofs?
>
> In any case, this is hardly exclusive to 'R doing something strange'.
> SAS and Stata happily join the gang. ?See the attached file for code
> and output from all three using a minidataset simulated in R.
>
> I suppose one could bicker over whether a random intercept and slope
> is a good idea, but possible it certainly is. ?You might suggest that
> it is poor fare to voice strong opinions about matters which one does
> not understand.
>
> Cheers,
>
> Josh
>
> On Thu, Mar 29, 2012 at 3:29 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> Hi Reinhold,
>>
>> Good question. My consultant didn't seem impressed when I tried to
>> articulate that explanation, but perhaps I wasn't clear.
>>
>> Thanks,
>> Ista
>> On Thu, Mar 29, 2012 at 1:45 AM, Reinhold Kliegl
>> <reinhold.kliegl at gmail.com> wrote:
>>> But why is Greg Snow's response inadequate?
>>>
>>> Restating his argument: ?In an LMM we are not estimating individual
>>> random effects (means, slopes) and individual residuals, but variance
>>> of random effects and variance of residuals. So there can be
>>> differences between a subject's observed random effect and random
>>> slope ?and conditional modes of the distribution of the random effects
>>> (i.e., the point of maximum density), given the observed data and
>>> evaluated at the parameter estimates.
>>>
>>> I think your statistician's answer is a good argument that you must
>>> not treat conditional modes as independent observations in a
>>> subsequent analyses. For example, we showed with simulations that
>>> correlations between conditional modes of slopes and intercepts are
>>> larger than the correlation parameter estimated in the LMM (Kliegl,
>>> Masson, & Richer, Visual Cognition, 2010).
>>>
>>> Reinhold Kliegl
>>>
>>> --
>>> Reinhold Kliegl
>>> http://read.psych.uni-potsdam.de/pmr2
>>>
>>> On Tue, Mar 27, 2012 at 4:18 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>>> Hi all,
>>>>
>>>> I'm trying to understand what the residual variance in this model:
>>>>
>>>> tmp <- subset(sleepstudy, Days == 1 | Days == 9)
>>>> m1 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), data = tmp)
>>>> tmp$fitted1 <- fitted(m1)
>>>>
>>>> represents. The way I read this specification, an intercept and a
>>>> slope is estimated for each subject. Since each subject only has two
>>>> measurements, I would expect the Reaction scores to be completely
>>>> accounted for by the slopes and intercepts. Yet they are not: the
>>>> Residual variance estimate is 440.278.
>>>>
>>>> This is probably a stupid question, but I hope you will be kind enough
>>>> to humor me.
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/



From bbolker at gmail.com  Thu Mar 29 20:25:27 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Mar 2012 18:25:27 +0000 (UTC)
Subject: [R-sig-ME] Help understanding residual variance
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
	<CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
	<CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>
Message-ID: <loom.20120329T202325-652@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> 
> Hi Ista,
> 
> To me the onis is on the statistician consultant to explain *why* you
> cannot have both random intercepts and slopes.  Does the consultant
> have papers to reference or proofs?
> 
> In any case, this is hardly exclusive to 'R doing something strange'.
> SAS and Stata happily join the gang.  See the attached file for code
> and output from all three using a minidataset simulated in R.
> 
> I suppose one could bicker over whether a random intercept and slope
> is a good idea, but possible it certainly is.  You might suggest that
> it is poor fare to voice strong opinions about matters which one does
> not understand.
> 
> Cheers,
> 
> Josh

  Very nice example.  Do note that while R::lme and Stata give
the same point estimates, Stata also provides estimated confidence
intervals, which are enormous -- suggesting that, while one can
do this, the resulting model might be unidentifiable.

  Doug Bates commented off-list that:

> I believe that the estimates for such a model are at least ill-defined
> if not unidentifiable.

  cheers
    Ben



From rlevy at ucsd.edu  Thu Mar 29 21:23:16 2012
From: rlevy at ucsd.edu (Levy, Roger)
Date: Thu, 29 Mar 2012 19:23:16 +0000
Subject: [R-sig-ME] Help understanding residual variance
In-Reply-To: <loom.20120329T202325-652@post.gmane.org>
References: <CA+vqiLH8GDL58M=0nNSRDwVroTLV=4WFsfv176LwhMPsbWbV8g@mail.gmail.com>
	<CAG+WrEwFWxfPoxjxXHpEUCwhE+n3OFCd-i3RKjgJw7MAKZ-oDg@mail.gmail.com>
	<CA+vqiLF2o3H5WtPi5jCFdooLEF1FnhPr9+c7My92NomkdSq+TQ@mail.gmail.com>
	<CANz9Z_L5mREcZMUtx-sRyuzEo88r9voeuM8V35K5uTXGFAidDw@mail.gmail.com>
	<loom.20120329T202325-652@post.gmane.org>
Message-ID: <B5DE3287-D5D6-4768-8B71-B03E0D304D03@ucsd.edu>


On Mar 29, 2012, at 11:25 AM PDT, Ben Bolker wrote:

> Joshua Wiley <jwiley.psych at ...> writes:
> 
>> 
>> Hi Ista,
>> 
>> To me the onis is on the statistician consultant to explain *why* you
>> cannot have both random intercepts and slopes.  Does the consultant
>> have papers to reference or proofs?
>> 
>> In any case, this is hardly exclusive to 'R doing something strange'.
>> SAS and Stata happily join the gang.  See the attached file for code
>> and output from all three using a minidataset simulated in R.
>> 
>> I suppose one could bicker over whether a random intercept and slope
>> is a good idea, but possible it certainly is.  You might suggest that
>> it is poor fare to voice strong opinions about matters which one does
>> not understand.
>> 
>> Cheers,
>> 
>> Josh
> 
>  Very nice example.  Do note that while R::lme and Stata give
> the same point estimates, Stata also provides estimated confidence
> intervals, which are enormous -- suggesting that, while one can
> do this, the resulting model might be unidentifiable.
> 
>  Doug Bates commented off-list that:
> 
>> I believe that the estimates for such a model are at least ill-defined
>> if not unidentifiable.

I concur with this -- I believe that the statistician consultant is right in this case, and that with only two observations per subject (plus crucially, no pair of observations for a given subject having the same value of Days), the model is actually unidentifiable given the dataset.  Here's one way of thinking about it: imagine that we represent the Days==1 and Days==9 observations for each subject as a 2-vector, (y_1 y_9).  If the residual variance is s^2 and the covariance matrix for the subject-level means for Days==1 and Days==9 as

 | t1^2             rho*t1t9     |
 | rho*t1t9             t9^2     |

then the marginal distribution for the total contribution of subject-level and residual error to the two observations for a given subject is bivariate normal with covariance matrix

 | t1^2 + s^2       rho*t1t9 |
 | rho*t1t9         t9^2+s^2 |

But as this illustrates, there's no way of distinguishing the residual error term s^2 from the subject random effects t1^2 and t9^2.  (This problem would not arise if there were at least two observations for one value of Days in at least one subject, because for that subject one would not be able to represent the data such that there is effectively only one multivariate observation per subject.)

I'll be interested to know whether this explanation helps shed light on the matter!

Best

Roger

--

Roger Levy                      Email: rlevy at ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://idiom.ucsd.edu/~rlevy



From bpederse at gmail.com  Thu Mar 29 23:59:47 2012
From: bpederse at gmail.com (Brent Pedersen)
Date: Thu, 29 Mar 2012 15:59:47 -0600
Subject: [R-sig-ME] error on example
Message-ID: <CAAp4xwryq4-a7jpRZ6X3S4tSXzeMv9veMO7u056iwnRp-vP_BA@mail.gmail.com>

Hi, I'm running this code:

library(lme4a)
data(ergoStool,package="MEMSS")
ergoStool$Subject <- factor(ergoStool$Subject)
fm01 <- lmer(effort~1 + Type + (1|Subject), ergoStool, REML=0)

And getting this error:

Error: is.numeric(u <- attr(fval, "u")) is not TRUE
Execution halted


My sessionInfo is below. Any ideas on how to fix this? I'm having
trouble calling
lmer() on any data.

thanks,
-Brent

R version 2.14.1 (2011-12-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4a_0.9996875-1  MatrixModels_0.3-1 minqa_1.2.0        Rcpp_0.9.10
[5] Matrix_1.0-5       lattice_0.20-6

loaded via a namespace (and not attached):
[1] codetools_0.2-8 grid_2.14.1     nlme_3.1-103    splines_2.14.1



From bbolker at gmail.com  Fri Mar 30 04:48:25 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Mar 2012 02:48:25 +0000 (UTC)
Subject: [R-sig-ME] error on example
References: <CAAp4xwryq4-a7jpRZ6X3S4tSXzeMv9veMO7u056iwnRp-vP_BA@mail.gmail.com>
Message-ID: <loom.20120330T044453-262@post.gmane.org>

Brent Pedersen <bpederse at ...> writes:

> 
> Hi, I'm running this code:
> 
> library(lme4a)
> data(ergoStool,package="MEMSS")
> ergoStool$Subject <- factor(ergoStool$Subject)
> fm01 <- lmer(effort~1 + Type + (1|Subject), ergoStool, REML=0)
> 

  I haven't checked, but I *think* that the development version
of lme4 (formerly lme4Eigen) now dominates lme4a -- and it works
on this example.  If there are things that you want to do that 
lme4a does that the development (r-forge) version of lme4 *doesn't*
do, please let the maintainers know and we will fix them ASAP ...

  cheers
    Ben Bolker



> And getting this error:
> 
> Error: is.numeric(u <- attr(fval, "u")) is not TRUE
> Execution halted
> 
> My sessionInfo is below. Any ideas on how to fix this? I'm having
> trouble calling
> lmer() on any data.
>



From natalia.vizcaino.palomar at gmail.com  Fri Mar 30 10:41:58 2012
From: natalia.vizcaino.palomar at gmail.com (=?ISO-8859-1?Q?Natalia_Vizca=EDno_Palomar?=)
Date: Fri, 30 Mar 2012 10:41:58 +0200
Subject: [R-sig-ME] problems to install glmmADMB
Message-ID: <CAOh1aTwi9sqF2oZu+f1iEZa5VwZhF_QUskEbhaBLDYrYq5D1Ag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120330/8571b6cb/attachment-0002.pl>

From ggrothendieck at gmail.com  Fri Mar 30 12:49:10 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Mar 2012 06:49:10 -0400
Subject: [R-sig-ME] problems to install glmmADMB
In-Reply-To: <CAOh1aTwi9sqF2oZu+f1iEZa5VwZhF_QUskEbhaBLDYrYq5D1Ag@mail.gmail.com>
References: <CAOh1aTwi9sqF2oZu+f1iEZa5VwZhF_QUskEbhaBLDYrYq5D1Ag@mail.gmail.com>
Message-ID: <CAP01uRmZV_cxw+XgpyodbFcRKuFGaz4_7E2dUD-nUkgXwxdDGw@mail.gmail.com>

On Fri, Mar 30, 2012 at 4:41 AM, Natalia Vizca?no Palomar
<natalia.vizcaino.palomar at gmail.com> wrote:
> Dear Ben,
>
> I have ?read many posts concerning the problems to install glmmADMB,
> but I am very sorry to write you another mail with this question.
> I have tried every advice to upload glmmADMB from
> http://glmmadmb.r-forge.r-project.org/ web page
> but I don?t know which problem I am running with.
> One of the last messages I got was:
>
> install.packages("glmmADMB_0.7.3.tar.gz",repos=NULL,type="source")
> Installing package(s) into ?C:/Users/Natalia/Documents/R/win-library/2.14?
> (as ?lib? is unspecified)
> Aviso: invalid package 'glmmADMB_0.7.3.tar.gz'
> Error: ERROR: no packages specified
> Mensajes de aviso perdidos
> 1: comando ejecutado 'C:/PROGRA~1/R/R-214~1.2/bin/i386/R CMD INSTALL -l
> "C:/Users/Natalia/Documents/R/win-library/2.14" ? "glmmADMB_0.7.3.tar.gz"'
> tiene estatus 1
> 2: In install.packages("glmmADMB_0.7.3.tar.gz", repos = NULL, type =
> "source") :
> ?installation of package ?glmmADMB_0.7.3.tar.gz? had non-zero exit status
>

See if you have better luck with this one:

http://www.math.mcmaster.ca/~bolker/R/src/contrib/glmmADMB_0.7.2.11.tar.gz

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From denis.vile at supagro.inra.fr  Fri Mar 30 13:10:57 2012
From: denis.vile at supagro.inra.fr (Denis Vile)
Date: Fri, 30 Mar 2012 13:10:57 +0200
Subject: [R-sig-ME] crossed effects with lmer but correlation structure
 with lme
In-Reply-To: <4F7418A5.7050500@supagro.inra.fr>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
	<4F7418A5.7050500@supagro.inra.fr>
Message-ID: <4F7594C1.1000101@supagro.inra.fr>

Hi all,

Was my problem not sufficiently well exposed or no one could help me ?

Sincerely,

Denis

Le 29/03/2012 10:09, Denis Vile a ?crit :
> Dear R users,
>
> I'm trying to fit a crossed-effects mixed model that would include a 
> spatial correlation structure..
> The data come from four controlled experiments (control, treatment1, 
> treatment2, treatment1+treatment2) on plants grown in a growth 
> chamber.  Individual replicates of different genotypes were grown 
> together and response traits were measured. A covariate X is included 
> in the model with a quadratic form.
>
> We fitted the following model using lmer:
>
> fm1 <- lmer(Y ~ 1 + Trt1*Trt2*poly(X, degree=2, raw=T) +
> (1|idGenotype) + (1|Trt2:idGenotype) + (1|Trt1:idGenotype) +
>             (1|Trt1:Trt2:idGenotype), data=...)
>
> This model is very interesting because we can extract the BLUPs for 
> each genotype in each (crossed) environment.
>
> After discussion with colleagues, it appeared that we should try to 
> include the possible spatial heterogeneityof the 
> micro-environmentwithin the growth chamber. To this end, we tried to 
> fit a model with lme() because we cannot easily (if possible) include 
> a correlation structure using lmer(). The model is:
>
> fm2 <- lme(Y ~ (X+I(X^2))*idCondition,
>             random =~1|idGenotype/idCondition,
>             correlation=corGaus(c(15,0.95), 
> form=~x+y|idGenotype/idCondition, nugget=T),
>             data =...)
>
> where x and y are the coordinates of the plants within the growth 
> chamber.
>
> Since I was unable to fit the crossed effects Trt1 x Trt2 in lme() I 
> coded a new variable idCondition which is the combination of Trt1 and 
> Trt2, and treated genotypes within idCondition. This is not entirely 
> satisfying because it is impossible to extract all BLUPs as in fm1.
>
> Could you please tell me if I missed something and ifthere is a trick 
> to specify crossed effects using lme()?
> I assume that this should use pdClasses but I'm not at all at ease 
> with the matrix specification of mixed models.
> Alternatively, include a correlation structure in lmer seems to be 
> unfeasible, am I wrong?
>
> Thank you very much for your help,
>
> Denis
>
>

-- 

*Denis VILE*
Charg? de Recherche
Laboratoire d'Ecophysiologie des Plantes sous Stress Environnementaux 
(*LEPSE*)
UMR 759 *INRA*-SUPAGRO // Institut de Biologie Int?grative des Plantes 
(IBIP, b?t 7)
2 place Pierre Viala
34060 Montpellier Cedex 2
Tel +33 (0)4 99 61 31 87
Fax +33 (0)4 67 52 21 16
http://www1.montpellier.inra.fr/ibip/lepse/



From vcadavez at ipb.pt  Fri Mar 30 13:37:09 2012
From: vcadavez at ipb.pt (Vasco Cadavez)
Date: Fri, 30 Mar 2012 12:37:09 +0100
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
 package?
In-Reply-To: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <4F759AE5.4050500@ipb.pt>

Hi,

I would like to know if is possible to solve simultaneous equations in lme4?

Thanks,

Vasco

-- 
Vasco Cadavez, PhD
Departamento de Ci?ncia Animal&
Centro de Investiga??o de Montanha (CIMO)
Escola Superior Agr?ria, Instituto Polit?cnico de Bragan?a
Campus de Santa Apol?nia, Apartado 1172
5301-854 BRAGAN?A
PORTUGAL
Telefone: (+351) 273 303 304
Fax: (+351) 273 325 405
e-mail: vcadavez at ipb.pt



From bpederse at gmail.com  Fri Mar 30 20:06:46 2012
From: bpederse at gmail.com (Brent Pedersen)
Date: Fri, 30 Mar 2012 12:06:46 -0600
Subject: [R-sig-ME] error on example
In-Reply-To: <loom.20120330T044453-262@post.gmane.org>
References: <CAAp4xwryq4-a7jpRZ6X3S4tSXzeMv9veMO7u056iwnRp-vP_BA@mail.gmail.com>
	<loom.20120330T044453-262@post.gmane.org>
Message-ID: <CAAp4xwrFRawci4J2vF08rtZLKw3Y3ejfeDpcao1XunUgAfpV3A@mail.gmail.com>

On Thu, Mar 29, 2012 at 8:48 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Brent Pedersen <bpederse at ...> writes:
>
>>
>> Hi, I'm running this code:
>>
>> library(lme4a)
>> data(ergoStool,package="MEMSS")
>> ergoStool$Subject <- factor(ergoStool$Subject)
>> fm01 <- lmer(effort~1 + Type + (1|Subject), ergoStool, REML=0)
>>
>
> ?I haven't checked, but I *think* that the development version
> of lme4 (formerly lme4Eigen) now dominates lme4a -- and it works
> on this example. ?If there are things that you want to do that
> lme4a does that the development (r-forge) version of lme4 *doesn't*
> do, please let the maintainers know and we will fix them ASAP ...
>
> ?cheers
> ? ?Ben Bolker
>

I substituted lme4 for lme4a and all works as expected on the example and
on my data.
Thanks very much.


>
>
>> And getting this error:
>>
>> Error: is.numeric(u <- attr(fval, "u")) is not TRUE
>> Execution halted
>>
>> My sessionInfo is below. Any ideas on how to fix this? I'm having
>> trouble calling
>> lmer() on any data.
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Fri Mar 30 22:09:33 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Mar 2012 20:09:33 +0000 (UTC)
Subject: [R-sig-ME] crossed effects with lmer but correlation structure
	with lme
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
	<4F7418A5.7050500@supagro.inra.fr>
	<4F7594C1.1000101@supagro.inra.fr>
Message-ID: <loom.20120330T215721-195@post.gmane.org>

Denis Vile <denis.vile at ...> writes:

> 
> Hi all,
> 
> Was my problem not sufficiently well exposed or no one could help me ?
> 
> Sincerely,
> 
> Denis

  The canonical reference for this is p. 163ff of Pinheiro
and Bates 2000 (section 4.2.2,  http://tinyurl.com/crossedRE )
You are correct that lme4 doesn't handle 'R-side' correlation
structures, nor will it in the near future ...


 (I've added this information to glmm.wikidot.com/faq ...)

  Ben Bolker


> 
> Le 29/03/2012 10:09, Denis Vile a ?crit :
> > Dear R users,
> >
> > I'm trying to fit a crossed-effects mixed model that would include a 
> > spatial correlation structure..
> > The data come from four controlled experiments (control, treatment1, 
> > treatment2, treatment1+treatment2) on plants grown in a growth 
> > chamber.  Individual replicates of different genotypes were grown 
> > together and response traits were measured. A covariate X is included 
> > in the model with a quadratic form.
> >
> > We fitted the following model using lmer:
> >
> > fm1 <- lmer(Y ~ 1 + Trt1*Trt2*poly(X, degree=2, raw=T) +
> > (1|idGenotype) + (1|Trt2:idGenotype) + (1|Trt1:idGenotype) +
> >             (1|Trt1:Trt2:idGenotype), data=...)
> >

  [snip snip snip]



From jwiley.psych at gmail.com  Fri Mar 30 22:44:44 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 30 Mar 2012 13:44:44 -0700
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
In-Reply-To: <loom.20120319T195110-259@post.gmane.org>
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
	<loom.20120319T195110-259@post.gmane.org>
Message-ID: <CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>

Hi Ben,

Many thanks for the help.  I tried your suggestion out and it seemed
to work (and I learned a bit about lme4 in the process :)

library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm1Fun <- update(fm1,devFunOnly=TRUE)
library(numDeriv)
fm1_thpar <- getME(fm1,"theta")
h <- hessian(fm1Fun, fm1_thpar)
g <- grad(fm1Fun, fm1_thpar)

which I can use (I think) to get standard errors of the variance parameters.

library(MASS)
sqrt(diag(ginv(h)))

which plug into a longer formula that attempts to test the
significance of indirect effects.  Given that the variance parameters
are not normally distributed, my hunch is that even though both fixed
and random effects (and their variances/standard errors) are being
built into the mediation test, it is probably not well-behaved either,
but it is nice to be able to try to replicate models in the article.
Even if they are not perfectly accurate, I am hoping I can use them as
a sanity check for when I play with some mcmc and bootstrapping.

Thanks again!

Josh

Session info below just for the record if anyone else is trying to try this.

R Under development (unstable) (2012-03-29 r58868)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] MASS_7.3-17        reshape2_1.2.1     numDeriv_2012.3-1  lme4_0.999902344-0
[5] Matrix_1.0-6       lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.16.0    minqa_1.2.0    nlme_3.1-103   plyr_1.7.1     splines_2.16.0
[6] stringr_0.6    tools_2.16.0

On Mon, Mar 19, 2012 at 12:15 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Joshua Wiley <jwiley.psych at ...> writes:
>
>>
>> Hi,
>>
>> I am trying to use a multivariate mixed effects linear model to
>> examine mediation. ?This works fine. ?The final step is to compute the
>> indirect effect and its standard error. ?The indirect effect is easy
>> (product of coefficients plus their covariance). ?For the standard
>> error, I need the gradient (D) and the hessian (H):
>> the variance is then:
>>
>> D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}
>>
>> This is all given in the Appendix of
>> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
>>
>> Is there a way to get this out of a mer class object? ?Looking at
>> class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$. ?@V
>> seems like it would give me the gradient but is null for a basic lmer
>> model.
>
> ?If you're willing to try out the development version (i.e., lme4
> from r-forge), I think you can do this as follows:
>
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fm1Fun <- update(fm1,devFunOnly=TRUE)
> library(numDeriv)
> fm1_thpar <- getME(fm1,"theta")
> h <- hessian(fm1Fun,fm1_thpar)
>
> ?and similarly for the gradient.
>
> ?Let me know how it goes.
>
> ?Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From danner.ray at gmail.com  Sat Mar 31 20:24:17 2012
From: danner.ray at gmail.com (Ray Danner)
Date: Sat, 31 Mar 2012 14:24:17 -0400
Subject: [R-sig-ME] MCMC model selection reference
Message-ID: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>

Dear list,

I'm looking for guidance on model selection using DIC values.  I'm
particularly interested in comparing mixed models created with the
package MCMCglmm.  I currently use AIC for my models built with lme
and (g)lmer and like the ability to calculate evidence ratios and
model average predictions, which are very easy for readers to
conceptualize.  AICcmodavg is great for these things.

Can anyone recommend a resource that describes the appropriate use of
DIC for model selection (and its limitations)?  I'm mainly an
ecologist, so a less-technical treatment would be ideal.

My main questions are:
1. Can DIC be used to select among mixed models?
Kery and Schaub (2012 p. 42) raise concerns about counting the correct
number of parameters and state that WinBUGS does not calculate them
appropriately, though Millar (2009) provides a method that is
appropriate for hierarchical models.  On the other hand, Saveliev et
al. (2009) use DIC to compare models with random effects built with
the BRugs package.  Hadfield's MCMCglmm Tutorial says that lower DIC
is better, but doesn't give details about use.

2. Any rules of thumb on what constitutes sufficiently large deltaDIC
values?  Are evidence ratios acceptable?

3. Can DIC be used to calculate model average predictions?

Thanks in advance and please forgive me if I missed your publication.
Ray


Refs
Kery and Schaub. 2012. Bayesian Population Analysis Using WinBUGS: A
Hierarchical Perspective.
Millar. 2009. Comparison of hierarchical Bayesian models for
overdispersed count data using DIC and Bayes' Factors. Biometrics
65:962-969.
Saveliev et al. 2009. Ch. 23 in Zuur, Mixed Effects Models and
Extensions in Ecology with R.



From boris at bshor.com  Sat Mar 31 00:00:07 2012
From: boris at bshor.com (Boris Shor)
Date: Fri, 30 Mar 2012 15:00:07 -0700
Subject: [R-sig-ME] lme4a installation
Message-ID: <CAGddWLSagQiG9zr93SYaCd0GjuyyftPCrPp_=fZ6bfUkEPy3LQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120330/e105bcf5/attachment-0002.pl>

