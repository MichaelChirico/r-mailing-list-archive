From eandresens at gmail.com  Fri Oct  2 20:53:27 2015
From: eandresens at gmail.com (Ellen Andresen)
Date: Fri, 2 Oct 2015 13:53:27 -0500
Subject: [R-sig-ME] [R] glmm: random term, overdispersion and comparisons
In-Reply-To: <CAJuCY5xVxvR0OhmGiNYAmvN0fKVBoMOfCTbf8fKYeSMX8PUUew@mail.gmail.com>
References: <CANfdbE20MLACstrd-HJzpg9s81BOu4nso4HiJCB-mDSMB6r_3Q@mail.gmail.com>
	<CAJuCY5xVxvR0OhmGiNYAmvN0fKVBoMOfCTbf8fKYeSMX8PUUew@mail.gmail.com>
Message-ID: <CANfdbE3FW0JRK6zrnoJTq8HYpBn0r0kXhT1dFCZ9q0x7Uw3NXg@mail.gmail.com>

Dear Thierry,
Thank you for your advice. So, using (1|site) should suffice, even
though it was always the same sites sampled? I really worry about not
specifying the random part correctly.
Finally, do you know of a good tutorial on how to speciffy contrast
coefficients to do the comparisons I am interested in?
Thanks again.
Ellen

2015-10-02 3:03 GMT-05:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> Dear Ellen,
>
> You're using the Poisson distribution. There is no error (noise) term in a
> glmm with Poisson distribution.
>
> 1) The random part seems to be quite complicated given the sample size.
> (1|site) is probably sufficient. Note that your design is not nested but
> crossed.
> 2) Overdispersion is likely in bird abundance. You could use a negative
> binomial distribution instead of a Poisson distribution. Then the
> overdispersion is modeled. Use the glmer.nb() function.
> 3) Have a look at the glht() function in the multcomp package. That allows
> you to test specific contrasts of your model parameters.
>
> Note that the r-sig-mixedmodels list is more appropriate for follow-up
> questions.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-01 16:59 GMT+02:00 Ellen Andresen <eandresens at gmail.com>:
>>
>> Hello,
>> I studied the effect of a hurricane in Cozumel on understory birds. I
>> have bird abundances (i.e. counts) registered always on the SAME six
>> sites (i.e. blocks). I have data for: before the hurricane, first year
>> after the hurricane, second year after the hurricane. I each of these
>> time periods, I also have data for summer season and for winter
>> season. I do not have a balanced design, in one of the time periods I
>> only have data for 5 of the six sites, and for another period I only
>> have data for 3 of the six sites.
>> I am defining Poisson error distrubution for the response variable.
>> I am using 'glmer' with two fixed factors, and I am interested in
>> their interaction:
>> - factor hurricane (three levels: before, after 1 y, after 2 y)
>> - factor season (two levels: summer, winter)
>> I am also specifying a random factor (sites), and I am specifying the
>> nested structure of the design. However, I don't know if I am
>> specifying the random part of the model in the correct way; this is
>> what I am doing:
>>        abundance ~ hurricane*season + (1|site/hurricane/season)
>>
>> I have three questions:
>> 1. Is the random part specified correctly?
>> 2. How do I check for overdispersion, and how can I correct for it?
>> (for each site I only have one observation; sites are my replicates)
>> 3. How do I make the following comparisons: I am interested in testing
>> for each season separately, after 1 y vs. before the hurricane, and
>> after 2 years vs. before the hurricane.
>>
>> Thank you so much!
>> Ellen Andresen
>> UNAM-Mexico
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From gangchen at mail.nih.gov  Sat Oct  3 20:38:07 2015
From: gangchen at mail.nih.gov (Chen, Gang (NIH/NIMH) [C])
Date: Sat, 3 Oct 2015 18:38:07 +0000
Subject: [R-sig-ME] fixed effects
Message-ID: <2DF23039AABC714B865A63F67141C0943E167FF9@msgb06.nih.gov>

With the following generalized linear mixed-effects model:

fm <- glmer( Y ~ Treatment + ( Treatment  | Subject) + (1|Trial), family=poisson))

How can I obtain the estimated fixed effects? fitted() seems to provide the sum of fixed and random effects, while predict() does not seem to work because I'm modeling the overdispersion with (1|Trial). I could manually compute the fixed effects based on the coefficients, but is there a function available for this purpose?

Thanks,
Gang

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Oct  4 03:44:03 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 3 Oct 2015 21:44:03 -0400
Subject: [R-sig-ME] fixed effects
In-Reply-To: <2DF23039AABC714B865A63F67141C0943E167FF9@msgb06.nih.gov>
References: <2DF23039AABC714B865A63F67141C0943E167FF9@msgb06.nih.gov>
Message-ID: <CABghstTY-_d_i7DF734eiVB7dfOtvXoCY495oUZqCbVqqjTUjw@mail.gmail.com>

    Perhaps you want

  predict(fm,re.form=~0)

?


On Sat, Oct 3, 2015 at 2:38 PM, Chen, Gang (NIH/NIMH) [C]
<gangchen at mail.nih.gov> wrote:
> With the following generalized linear mixed-effects model:
>
> fm <- glmer( Y ~ Treatment + ( Treatment  | Subject) + (1|Trial), family=poisson))
>
> How can I obtain the estimated fixed effects? fitted() seems to provide the sum of fixed and random effects, while predict() does not seem to work because I'm modeling the overdispersion with (1|Trial). I could manually compute the fixed effects based on the coefficients, but is there a function available for this purpose?
>
> Thanks,
> Gang
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mmalten at gmail.com  Sun Oct  4 03:58:18 2015
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Sat, 3 Oct 2015 21:58:18 -0400
Subject: [R-sig-ME] fixed effects
In-Reply-To: <CABghstTY-_d_i7DF734eiVB7dfOtvXoCY495oUZqCbVqqjTUjw@mail.gmail.com>
References: <2DF23039AABC714B865A63F67141C0943E167FF9@msgb06.nih.gov>
	<CABghstTY-_d_i7DF734eiVB7dfOtvXoCY495oUZqCbVqqjTUjw@mail.gmail.com>
Message-ID: <CANOgrHYm8GwTGH5zQswc956G+gOEFt=N6faMajCW=Hir9QMqcg@mail.gmail.com>

What is the difference between re.form = ~0 and re.form = NA ?

On Saturday, October 3, 2015, Ben Bolker <bbolker at gmail.com> wrote:

>     Perhaps you want
>
>   predict(fm,re.form=~0)
>
> ?
>
>
> On Sat, Oct 3, 2015 at 2:38 PM, Chen, Gang (NIH/NIMH) [C]
> <gangchen at mail.nih.gov <javascript:;>> wrote:
> > With the following generalized linear mixed-effects model:
> >
> > fm <- glmer( Y ~ Treatment + ( Treatment  | Subject) + (1|Trial),
> family=poisson))
> >
> > How can I obtain the estimated fixed effects? fitted() seems to provide
> the sum of fixed and random effects, while predict() does not seem to work
> because I'm modeling the overdispersion with (1|Trial). I could manually
> compute the fixed effects based on the coefficients, but is there a
> function available for this purpose?
> >
> > Thanks,
> > Gang
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org <javascript:;> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Oct  4 04:13:55 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 3 Oct 2015 22:13:55 -0400
Subject: [R-sig-ME] fixed effects
In-Reply-To: <CANOgrHYm8GwTGH5zQswc956G+gOEFt=N6faMajCW=Hir9QMqcg@mail.gmail.com>
References: <2DF23039AABC714B865A63F67141C0943E167FF9@msgb06.nih.gov>
	<CABghstTY-_d_i7DF734eiVB7dfOtvXoCY495oUZqCbVqqjTUjw@mail.gmail.com>
	<CANOgrHYm8GwTGH5zQswc956G+gOEFt=N6faMajCW=Hir9QMqcg@mail.gmail.com>
Message-ID: <CABghstRx12oNVpc-vYsks-JAZBLCF-maQVW7i4XF-QqC7e1Q1g@mail.gmail.com>

None (as indicated by the documentation ...)

On Sat, Oct 3, 2015 at 9:58 PM, Mitchell Maltenfort <mmalten at gmail.com> wrote:
> What is the difference between re.form = ~0 and re.form = NA ?
>
>
> On Saturday, October 3, 2015, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     Perhaps you want
>>
>>   predict(fm,re.form=~0)
>>
>> ?
>>
>>
>> On Sat, Oct 3, 2015 at 2:38 PM, Chen, Gang (NIH/NIMH) [C]
>> <gangchen at mail.nih.gov> wrote:
>> > With the following generalized linear mixed-effects model:
>> >
>> > fm <- glmer( Y ~ Treatment + ( Treatment  | Subject) + (1|Trial),
>> > family=poisson))
>> >
>> > How can I obtain the estimated fixed effects? fitted() seems to provide
>> > the sum of fixed and random effects, while predict() does not seem to work
>> > because I'm modeling the overdispersion with (1|Trial). I could manually
>> > compute the fixed effects based on the coefficients, but is there a function
>> > available for this purpose?
>> >
>> > Thanks,
>> > Gang
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Sent from Gmail Mobile


From thierry.onkelinx at inbo.be  Mon Oct  5 09:26:11 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 5 Oct 2015 09:26:11 +0200
Subject: [R-sig-ME] [R] glmm: random term, overdispersion and comparisons
In-Reply-To: <CANfdbE3FW0JRK6zrnoJTq8HYpBn0r0kXhT1dFCZ9q0x7Uw3NXg@mail.gmail.com>
References: <CANfdbE20MLACstrd-HJzpg9s81BOu4nso4HiJCB-mDSMB6r_3Q@mail.gmail.com>
	<CAJuCY5xVxvR0OhmGiNYAmvN0fKVBoMOfCTbf8fKYeSMX8PUUew@mail.gmail.com>
	<CANfdbE3FW0JRK6zrnoJTq8HYpBn0r0kXhT1dFCZ9q0x7Uw3NXg@mail.gmail.com>
Message-ID: <CAJuCY5x76+HH0vyEvwMtF9h-RxOUJ=5wkuqfx0Ac5tRaUQA8Pw@mail.gmail.com>

Dear Ellen,

I think that you need to do some reading on mixed models. Zuur et al 2009
is a great book on mixed models. It written with ecologists in mind.

(1|site) estimates the common site effect within the observations. So it
models the dependence on site.

Have you looked a the examples in the helpfile of glht() and the vignettes
in the multcomp package?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-02 20:53 GMT+02:00 Ellen Andresen <eandresens at gmail.com>:

> Dear Thierry,
> Thank you for your advice. So, using (1|site) should suffice, even
> though it was always the same sites sampled? I really worry about not
> specifying the random part correctly.
> Finally, do you know of a good tutorial on how to speciffy contrast
> coefficients to do the comparisons I am interested in?
> Thanks again.
> Ellen
>
> 2015-10-02 3:03 GMT-05:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> > Dear Ellen,
> >
> > You're using the Poisson distribution. There is no error (noise) term in
> a
> > glmm with Poisson distribution.
> >
> > 1) The random part seems to be quite complicated given the sample size.
> > (1|site) is probably sufficient. Note that your design is not nested but
> > crossed.
> > 2) Overdispersion is likely in bird abundance. You could use a negative
> > binomial distribution instead of a Poisson distribution. Then the
> > overdispersion is modeled. Use the glmer.nb() function.
> > 3) Have a look at the glht() function in the multcomp package. That
> allows
> > you to test specific contrasts of your model parameters.
> >
> > Note that the r-sig-mixedmodels list is more appropriate for follow-up
> > questions.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> than
> > asking him to perform a post-mortem examination: he may be able to say
> what
> > the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2015-10-01 16:59 GMT+02:00 Ellen Andresen <eandresens at gmail.com>:
> >>
> >> Hello,
> >> I studied the effect of a hurricane in Cozumel on understory birds. I
> >> have bird abundances (i.e. counts) registered always on the SAME six
> >> sites (i.e. blocks). I have data for: before the hurricane, first year
> >> after the hurricane, second year after the hurricane. I each of these
> >> time periods, I also have data for summer season and for winter
> >> season. I do not have a balanced design, in one of the time periods I
> >> only have data for 5 of the six sites, and for another period I only
> >> have data for 3 of the six sites.
> >> I am defining Poisson error distrubution for the response variable.
> >> I am using 'glmer' with two fixed factors, and I am interested in
> >> their interaction:
> >> - factor hurricane (three levels: before, after 1 y, after 2 y)
> >> - factor season (two levels: summer, winter)
> >> I am also specifying a random factor (sites), and I am specifying the
> >> nested structure of the design. However, I don't know if I am
> >> specifying the random part of the model in the correct way; this is
> >> what I am doing:
> >>        abundance ~ hurricane*season + (1|site/hurricane/season)
> >>
> >> I have three questions:
> >> 1. Is the random part specified correctly?
> >> 2. How do I check for overdispersion, and how can I correct for it?
> >> (for each site I only have one observation; sites are my replicates)
> >> 3. How do I make the following comparisons: I am interested in testing
> >> for each season separately, after 1 y vs. before the hurricane, and
> >> after 2 years vs. before the hurricane.
> >>
> >> Thank you so much!
> >> Ellen Andresen
> >> UNAM-Mexico
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Mon Oct  5 13:22:00 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 5 Oct 2015 09:22:00 -0200
Subject: [R-sig-ME] modeling the effect of grass height on insect biomass
Message-ID: <CAMM93=Kaq1RVFf_00dhvM_zDgD0of2WirHfgoDqB3yWG2hv0Uw@mail.gmail.com>

Dear all, I want to see the effect of grass height on insect biomass in a
farm close to a coastal lagoon in Uruguay. For that I chose 5 pairs of
fields. Each pair consist on a field with tall grass and the other with
short grass. Each pair of fields are close to each other, in order to
reduce the effect of soil type and other confounding variables. In each
field I installed 6 pitfall traps, separated 100 m each. I collected
insects for 30 days.

Is the following modeling approach correct?: I called Site to each field
pair (as they are geographically separated)

model=lme(insect biomass~grass height + (1|Site\Field), data)

Alternatively I thought of doing paired t-test..

Thankyou very much for your help.

Joaqu?n.

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Oct  5 13:40:37 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 5 Oct 2015 13:40:37 +0200
Subject: [R-sig-ME] modeling the effect of grass height on insect biomass
In-Reply-To: <CAMM93=Kaq1RVFf_00dhvM_zDgD0of2WirHfgoDqB3yWG2hv0Uw@mail.gmail.com>
References: <CAMM93=Kaq1RVFf_00dhvM_zDgD0of2WirHfgoDqB3yWG2hv0Uw@mail.gmail.com>
Message-ID: <CAJuCY5x+a18HCiPnaA0ax_=mA9VF9viu3hH+3phr9Zxgxe5-rw@mail.gmail.com>

Dear Joaquin

Your model seems reasonable, assuming that you measure the pitfalls only
once.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-05 13:22 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> Dear all, I want to see the effect of grass height on insect biomass in a
> farm close to a coastal lagoon in Uruguay. For that I chose 5 pairs of
> fields. Each pair consist on a field with tall grass and the other with
> short grass. Each pair of fields are close to each other, in order to
> reduce the effect of soil type and other confounding variables. In each
> field I installed 6 pitfall traps, separated 100 m each. I collected
> insects for 30 days.
>
> Is the following modeling approach correct?: I called Site to each field
> pair (as they are geographically separated)
>
> model=lme(insect biomass~grass height + (1|Site\Field), data)
>
> Alternatively I thought of doing paired t-test..
>
> Thankyou very much for your help.
>
> Joaqu?n.
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Oct  5 14:31:22 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 5 Oct 2015 14:31:22 +0200
Subject: [R-sig-ME] modeling the effect of grass height on insect biomass
In-Reply-To: <CAMM93=+++-g6CrBM8zJB0-gzaNLiSa_iFZQ1MT9sj0dKd2n1zA@mail.gmail.com>
References: <CAMM93=Kaq1RVFf_00dhvM_zDgD0of2WirHfgoDqB3yWG2hv0Uw@mail.gmail.com>
	<CAJuCY5x+a18HCiPnaA0ax_=mA9VF9viu3hH+3phr9Zxgxe5-rw@mail.gmail.com>
	<CAMM93=+++-g6CrBM8zJB0-gzaNLiSa_iFZQ1MT9sj0dKd2n1zA@mail.gmail.com>
Message-ID: <CAJuCY5yUigoUeXyfZtz5+1XkGEE1s6f4RCwtsO4VtkFfGNsOOQ@mail.gmail.com>

Dear Joaquin,

Please keep the mailinglist in cc.

I'd rather think of the weeks being crossed with the fields than nested.
E.g. the effect of a week is probably similar on all fields. Then the model
looks like biomas~grass height +(1|Site/Field) + (1|Week). Note that you'll
need lme4 to fit that. crossed random effects are to straightforward in
nlme.

Random effects with as little as 4 or 5 levels might have unreliable
variance estimates. Keep that in mind when examining the modeloutput.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-05 14:00 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> Thanks Thierry. Acutually, I collected each trap once a week, but decided
> to sum the the whole content (30 days). Should I conserve the weekly
> sampling? if so I guess the model could be insect biomas~grass height
> +(1|Site\Field\Week) ?
> Thanks again.
> Joaqu?n.
>
> 2015-10-05 9:40 GMT-02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Joaquin
>>
>> Your model seems reasonable, assuming that you measure the pitfalls only
>> once.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-10-05 13:22 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>
>>> Dear all, I want to see the effect of grass height on insect biomass in a
>>> farm close to a coastal lagoon in Uruguay. For that I chose 5 pairs of
>>> fields. Each pair consist on a field with tall grass and the other with
>>> short grass. Each pair of fields are close to each other, in order to
>>> reduce the effect of soil type and other confounding variables. In each
>>> field I installed 6 pitfall traps, separated 100 m each. I collected
>>> insects for 30 days.
>>>
>>> Is the following modeling approach correct?: I called Site to each field
>>> pair (as they are geographically separated)
>>>
>>> model=lme(insect biomass~grass height + (1|Site\Field), data)
>>>
>>> Alternatively I thought of doing paired t-test..
>>>
>>> Thankyou very much for your help.
>>>
>>> Joaqu?n.
>>>
>>> --
>>> *Joaqu?n Aldabe*
>>>
>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>
>>> *Departamento de Conservaci?n*
>>> Aves Uruguay
>>> BirdLife International
>>> Canelones 1164, Montevideo
>>>
>>> https://sites.google.com/site/joaquin.aldabe
>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Mon Oct  5 14:41:33 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 5 Oct 2015 10:41:33 -0200
Subject: [R-sig-ME] modeling the effect of grass height on insect biomass
In-Reply-To: <CAJuCY5yUigoUeXyfZtz5+1XkGEE1s6f4RCwtsO4VtkFfGNsOOQ@mail.gmail.com>
References: <CAMM93=Kaq1RVFf_00dhvM_zDgD0of2WirHfgoDqB3yWG2hv0Uw@mail.gmail.com>
	<CAJuCY5x+a18HCiPnaA0ax_=mA9VF9viu3hH+3phr9Zxgxe5-rw@mail.gmail.com>
	<CAMM93=+++-g6CrBM8zJB0-gzaNLiSa_iFZQ1MT9sj0dKd2n1zA@mail.gmail.com>
	<CAJuCY5yUigoUeXyfZtz5+1XkGEE1s6f4RCwtsO4VtkFfGNsOOQ@mail.gmail.com>
Message-ID: <CAMM93=LaurJTi_GSycpQhK+TXcw6DWKKC+V1kACbWN9R85aOJg@mail.gmail.com>

Thankyou very much Thierry.
All the best,
Joaqu?n

2015-10-05 10:31 GMT-02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Joaquin,
>
> Please keep the mailinglist in cc.
>
> I'd rather think of the weeks being crossed with the fields than nested.
> E.g. the effect of a week is probably similar on all fields. Then the model
> looks like biomas~grass height +(1|Site/Field) + (1|Week). Note that
> you'll need lme4 to fit that. crossed random effects are to straightforward
> in nlme.
>
> Random effects with as little as 4 or 5 levels might have unreliable
> variance estimates. Keep that in mind when examining the modeloutput.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-05 14:00 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>
>> Thanks Thierry. Acutually, I collected each trap once a week, but decided
>> to sum the the whole content (30 days). Should I conserve the weekly
>> sampling? if so I guess the model could be insect biomas~grass height
>> +(1|Site\Field\Week) ?
>> Thanks again.
>> Joaqu?n.
>>
>> 2015-10-05 9:40 GMT-02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>>> Dear Joaquin
>>>
>>> Your model seems reasonable, assuming that you measure the pitfalls only
>>> once.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2015-10-05 13:22 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>>
>>>> Dear all, I want to see the effect of grass height on insect biomass in
>>>> a
>>>> farm close to a coastal lagoon in Uruguay. For that I chose 5 pairs of
>>>> fields. Each pair consist on a field with tall grass and the other with
>>>> short grass. Each pair of fields are close to each other, in order to
>>>> reduce the effect of soil type and other confounding variables. In each
>>>> field I installed 6 pitfall traps, separated 100 m each. I collected
>>>> insects for 30 days.
>>>>
>>>> Is the following modeling approach correct?: I called Site to each field
>>>> pair (as they are geographically separated)
>>>>
>>>> model=lme(insect biomass~grass height + (1|Site\Field), data)
>>>>
>>>> Alternatively I thought of doing paired t-test..
>>>>
>>>> Thankyou very much for your help.
>>>>
>>>> Joaqu?n.
>>>>
>>>> --
>>>> *Joaqu?n Aldabe*
>>>>
>>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>>
>>>> *Departamento de Conservaci?n*
>>>> Aves Uruguay
>>>> BirdLife International
>>>> Canelones 1164, Montevideo
>>>>
>>>> https://sites.google.com/site/joaquin.aldabe
>>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *Departamento de Conservaci?n*
>> Aves Uruguay
>> BirdLife International
>> Canelones 1164, Montevideo
>>
>> https://sites.google.com/site/joaquin.aldabe
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>
>>
>


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From maxxx848 at umn.edu  Tue Oct  6 17:15:18 2015
From: maxxx848 at umn.edu (Yizhou Ma)
Date: Tue, 6 Oct 2015 10:15:18 -0500
Subject: [R-sig-ME] LMM diagnostics: conditional residuals correlated highly
	with fitted values
Message-ID: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>

Dear LMM experts:

I am pretty new to using LMM and I have found the following situation
bewildering as I was trying to do diagnostics with my fitted model: my
conditional residuals correlated highly with the fitted values.

I have a dataset with multiple families, each has 1-4 siblings. I am trying
to regress Y onto EVs include Drink, Gender, & Age, while using random
intercept for family. This is the model I used:
model<-lmer(Y~Drink*Gender+Age
                      +(1|Family_ID),data,REML=FALSE)

After fitting the model, I used
plot(model)
to see the relationship between conditional residuals and fitted values. I
expect them to be uncorrelated and I expect to see homoscedasticity.

Yet to my surprise there is a high correlation (~0.5) between the residuals
and the fitted values. (see here <http://imgur.com/pPsG4aR>). I know from
GLM that this usually suggest nonlinear relationships between the EVs and
the DV.

I read some online posts (post1
<http://stats.stackexchange.com/questions/43566/strange-pattern-in-residual-plot-from-mixed-effect-model>
post2
<http://stats.stackexchange.com/questions/168179/correlation-between-standardized-residuals-and-fitted-values-in-a-linear-mixed-e/168210#168210>)
that suggest this can result from a poor model fit. So I tried a few
different models, including: 1) log transform Drink, which is originally
positively skewed; 2) add random slopes for Drink, Age, etc. None of these
changes have led to a substantial difference for the residual & fitted
value correlation.

Some other info:
1) my overall model fit is not poor as indicated by the correlation between
fitted values & Y. It is around 0.8;
2) most variables in my model has a normal, or at least symmetrical,
distribution.
3) conditional residuals are normally distributed as shown in qqplots.
4) conditional residuals are not correlated with any fixed effects, such as
Drink or Age.

I have two guesses as to what is going on:
1) maybe the fact that each family is a different size actually violates
assumptions of the model?
2) or maybe there is something wrong with estimation of the random effect
(family intercept)?

I'd really appreciate your insights as to what is going on here and if
there is any problems with my model.

Thank you very much,
Cherry

	[[alternative HTML version deleted]]


From chaco001 at umn.edu  Tue Oct  6 21:06:52 2015
From: chaco001 at umn.edu (Jeremy Chacon)
Date: Tue, 6 Oct 2015 14:06:52 -0500
Subject: [R-sig-ME] lmer model construction
Message-ID: <CAH65v72--dcK6imO3HyrLkV4swaauUHSDBrWubLem6m=6R=99w@mail.gmail.com>

Hello all,

I would appreciate any advice on how to construct and analyze my model.

I have conducted a study where I put bacterial colonies onto petri dishes.
The colonies were randomly spread across the petri dishes, and the number
of colonies varied slightly across each petri dish. Some petri dishes
received one bacterial species, some petri dishes received another species.
Additionally, half of the petri dishes contained one type of growth media,
and the other half contained a different media.

So my experimental design is basically a two-factor design:

2 levels of species X 2 levels of media.

The design is balanced.

The complicated part is that my response of interest is how the proximity
of one bacterial colony to its neighbors affects the size of the bacterial
colony, and importantly, how this relationship is affected by the bacterial
species, growth media, and their interaction.

In other words, I have a nested design where my measurements of interest
(bacterial colonies) are nested with the truly independent replicates
(petri dishes), which is why I intend to use a mixed model.

So the data look like this:

results =

species    media    colonySize    proximityToNeighbor    petriDishID
  A        A        12            4                      1
  A        A        38            42                     1
  A        B        18            50                     2

etc, with one observation per colony, and typically about 100 colonies per
petri dish.

I am trying to correctly construct the model using lme4. I would appreciate
suggestion on my model. Also, I would appreciate suggestions on
interpretations.

My current thought: use a random intercept for each petri dish:

m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
petriDishID), data = results)

but this does not describe the nesting of each colony within a petri dish
(at least as far as I understand). Do I need to do this?

In terms of interpretation, I have been (1) looking at plots to get a feel
for effect size and then (2) getting significance values by doing a
predictor removal model comparison, like below:

m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
petriDishID), data = results)

m2 = lmer(colonySize ~ proximityToNeighbor * species + media + (1 |
petriDishID), data = results)

anova(m1, m2, test = "F")


When I do this, I get a tiny p-value, which (along with plots) suggests to
me that the interaction between species and media in their effect on
proximityToNeighbor's effect on colonySize is important. Does this sound
correct? Any better ways to do this?

Thanks very much!

Jeremy


-- 

*___________________________________________________________________________Jeremy
M. Chacon, Ph.D.*

*Post-Doctoral Associate, Harcombe Lab*
*University of Minnesota*
*Ecology, Evolution and Behavior*

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Oct  7 07:39:18 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 07 Oct 2015 06:39:18 +0100
Subject: [R-sig-ME] MCMCglmm update
Message-ID: <20151007063918.962839289w3srp6o@www.staffmail.ed.ac.uk>

Hi,

MCMCglmm has been updated to version 2.22. A lot of minor annoying  
bugs have been fixed, but as far as I am aware no major bugs have been  
found. Quite a bit of new functionality has been added:

1) Antedependence structures.

Structured antedependence models can now be fitted using the new  
variance structure ante[]. The suffix [] takes a number, giving the  
order of the antedependence model (e.g ante1 and ante2 give first and  
second order antedependence models), and the number can be prefixed by  
a '&#128;&#152;c'&#128;&#153; to hold all regression coefficients of  
the same order equal. The number can also be suffixed by a  
'v'&#128;&#153; to hold all innovation variances equal. For example,  
antec2v has 3 parameters: a constant innovation variance, and two  
constant regression coefficients (one 1-lagged, and one 2-lagged).

Priors for antedependence structures allow priors to be placed  
directly on the regression parameters via a beta.mu (a vector of prior  
means) and a beta.V (a matrix of prior variances) element to the prior  
list

2) Path analysis.

Path analysis could be performed previously using the sir function,  
but it was cumbersome and did not work if all response variables were  
not Gaussian and completely observed. The path function is less  
flexible than the sir function, but it is easier to use and works with  
non-Gaussian data. Paths are allowed between observations within the  
same residual block, and  path(cause, effect, k) specifies which of  
the k variables affect each other. For example, if a three-response  
model was fitted then

cbind(a,b,c)~trait+path(1,2,3)+path(1,3,3), rcov=~us(trait):units

then states that a[i] determines b[i] and c[i].

3) Simulate

A simulate method now exists and can be used to simulate observations  
from a  model defined by a MCMCglmm object.

4) Predict

The predict method is now more complete and accepts new data

5)  Random effect - residual correlations

Random effect - residual correlations can now be fitted by specifying  
covu=TRUE in the prior specification for the residual structure. The  
set of residuals defined by this structure are allowed to covary with  
the random effects specified by the final random effect structure. If  
the residual (co)variance matrix is of dimension n, and the final  
random effect (co)variance matrix is of dimension m, then the residual  
prior specification must be of dimension n+m. The final random effect  
(co)variance matrix should not have a prior specification.

6) Random effect Bradley-Terry models

Bradley-Terry models without random effects could already be fitted in  
previous versions by simply taking the difference between the two  
opponents predictors (and potentially fixing the intercept at zero if  
no order effects were modelled). Random effects can now be fitted  
using the multimembership model formulation mm(opponent1-opponent2),  
which now allows a `-' as well as the traditional `+'.

Cheers,

Jarrod


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Wed Oct  7 07:48:09 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 07 Oct 2015 06:48:09 +0100
Subject: [R-sig-ME] MCMCglmm update
In-Reply-To: <20151007063918.962839289w3srp6o@www.staffmail.ed.ac.uk>
References: <20151007063918.962839289w3srp6o@www.staffmail.ed.ac.uk>
Message-ID: <20151007064809.663817qdoy7r3hfk@www.staffmail.ed.ac.uk>

Sorry - not sure how the non Ascii text creeped in ...1) should read:

1) Antedependence structures.

Structured antedependence models can now be fitted using the new  
variance structure ante[]. The suffix [] takes a number, giving the  
order of the antedependence model (e.g ante1 and ante2 give first and  
second order antedependence models), and the number can be prefixed by  
a ?c? to hold all regression coefficients of the same order equal. The  
number can also be suffixed by a 'v' to hold all innovation variances  
equal. For example, antec2v has 3 parameters: a constant innovation  
variance, and two constant regression coefficients (one 1-lagged, and  
one 2-lagged).

Cheers,

Jarrod



Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Wed, 07 Oct 2015  
06:39:18 +0100:

> Hi,
>
> MCMCglmm has been updated to version 2.22. A lot of minor annoying  
> bugs have been fixed, but as far as I am aware no major bugs have  
> been found. Quite a bit of new functionality has been added:
>
> 1) Antedependence structures.
>
> Structured antedependence models can now be fitted using the new  
> variance structure ante[]. The suffix [] takes a number, giving the  
> order of the antedependence model (e.g ante1 and ante2 give first  
> and second order antedependence models), and the number can be  
> prefixed by a '&#128;&#152;c'&#128;&#153; to hold all regression  
> coefficients of the same order equal. The number can also be  
> suffixed by a 'v'&#128;&#153; to hold all innovation variances  
> equal. For example, antec2v has 3 parameters: a constant innovation  
> variance, and two constant regression coefficients (one 1-lagged,  
> and one 2-lagged).
>
> Priors for antedependence structures allow priors to be placed  
> directly on the regression parameters via a beta.mu (a vector of  
> prior means) and a beta.V (a matrix of prior variances) element to  
> the prior list
>
> 2) Path analysis.
>
> Path analysis could be performed previously using the sir function,  
> but it was cumbersome and did not work if all response variables  
> were not Gaussian and completely observed. The path function is less  
> flexible than the sir function, but it is easier to use and works  
> with non-Gaussian data. Paths are allowed between observations  
> within the same residual block, and  path(cause, effect, k)  
> specifies which of the k variables affect each other. For example,  
> if a three-response model was fitted then
>
> cbind(a,b,c)~trait+path(1,2,3)+path(1,3,3), rcov=~us(trait):units
>
> then states that a[i] determines b[i] and c[i].
>
> 3) Simulate
>
> A simulate method now exists and can be used to simulate  
> observations from a  model defined by a MCMCglmm object.
>
> 4) Predict
>
> The predict method is now more complete and accepts new data
>
> 5)  Random effect - residual correlations
>
> Random effect - residual correlations can now be fitted by  
> specifying covu=TRUE in the prior specification for the residual  
> structure. The set of residuals defined by this structure are  
> allowed to covary with the random effects specified by the final  
> random effect structure. If the residual (co)variance matrix is of  
> dimension n, and the final random effect (co)variance matrix is of  
> dimension m, then the residual prior specification must be of  
> dimension n+m. The final random effect (co)variance matrix should  
> not have a prior specification.
>
> 6) Random effect Bradley-Terry models
>
> Bradley-Terry models without random effects could already be fitted  
> in previous versions by simply taking the difference between the two  
> opponents predictors (and potentially fixing the intercept at zero  
> if no order effects were modelled). Random effects can now be fitted  
> using the multimembership model formulation mm(opponent1-opponent2),  
> which now allows a `-' as well as the traditional `+'.
>
> Cheers,
>
> Jarrod
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From thierry.onkelinx at inbo.be  Wed Oct  7 12:10:04 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 7 Oct 2015 12:10:04 +0200
Subject: [R-sig-ME] lmer model construction
In-Reply-To: <CAH65v72--dcK6imO3HyrLkV4swaauUHSDBrWubLem6m=6R=99w@mail.gmail.com>
References: <CAH65v72--dcK6imO3HyrLkV4swaauUHSDBrWubLem6m=6R=99w@mail.gmail.com>
Message-ID: <CAJuCY5yzbV_xL5e21uE=a-Oe0PKvuaZJSDrodajq_W7k3ouXhA@mail.gmail.com>

Dear Jeremy,

Adding a random effect for petridish takes the nested design into account.

P * S * M expands to P + S + M + P:S + P:M + S:M + P:S:M. So it includes
the threeway interaction. I'm not sure if you want that.
P * S + M expands to P + S + M + P:S. Hence the difference with P * S * M
is P:M + P:S:M. So a LRT between P * S * M and P * S + M tests the combined
effect of P:M and P:S:M.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-06 21:06 GMT+02:00 Jeremy Chacon <chaco001 at umn.edu>:

> Hello all,
>
> I would appreciate any advice on how to construct and analyze my model.
>
> I have conducted a study where I put bacterial colonies onto petri dishes.
> The colonies were randomly spread across the petri dishes, and the number
> of colonies varied slightly across each petri dish. Some petri dishes
> received one bacterial species, some petri dishes received another species.
> Additionally, half of the petri dishes contained one type of growth media,
> and the other half contained a different media.
>
> So my experimental design is basically a two-factor design:
>
> 2 levels of species X 2 levels of media.
>
> The design is balanced.
>
> The complicated part is that my response of interest is how the proximity
> of one bacterial colony to its neighbors affects the size of the bacterial
> colony, and importantly, how this relationship is affected by the bacterial
> species, growth media, and their interaction.
>
> In other words, I have a nested design where my measurements of interest
> (bacterial colonies) are nested with the truly independent replicates
> (petri dishes), which is why I intend to use a mixed model.
>
> So the data look like this:
>
> results =
>
> species    media    colonySize    proximityToNeighbor    petriDishID
>   A        A        12            4                      1
>   A        A        38            42                     1
>   A        B        18            50                     2
>
> etc, with one observation per colony, and typically about 100 colonies per
> petri dish.
>
> I am trying to correctly construct the model using lme4. I would appreciate
> suggestion on my model. Also, I would appreciate suggestions on
> interpretations.
>
> My current thought: use a random intercept for each petri dish:
>
> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
> petriDishID), data = results)
>
> but this does not describe the nesting of each colony within a petri dish
> (at least as far as I understand). Do I need to do this?
>
> In terms of interpretation, I have been (1) looking at plots to get a feel
> for effect size and then (2) getting significance values by doing a
> predictor removal model comparison, like below:
>
> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
> petriDishID), data = results)
>
> m2 = lmer(colonySize ~ proximityToNeighbor * species + media + (1 |
> petriDishID), data = results)
>
> anova(m1, m2, test = "F")
>
>
> When I do this, I get a tiny p-value, which (along with plots) suggests to
> me that the interaction between species and media in their effect on
> proximityToNeighbor's effect on colonySize is important. Does this sound
> correct? Any better ways to do this?
>
> Thanks very much!
>
> Jeremy
>
>
> --
>
>
> *___________________________________________________________________________Jeremy
> M. Chacon, Ph.D.*
>
> *Post-Doctoral Associate, Harcombe Lab*
> *University of Minnesota*
> *Ecology, Evolution and Behavior*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Oct  7 12:14:31 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 7 Oct 2015 12:14:31 +0200
Subject: [R-sig-ME] LMM diagnostics: conditional residuals correlated
 highly with fitted values
In-Reply-To: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>
References: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>
Message-ID: <CAJuCY5wQGha+T9R6vsrZvB+HGW0XOc04BgV=+Bzg736J2eSHuw@mail.gmail.com>

Dear Cherry,

Please don't post in HTML. Have a look at the posting guide.

You'll need to provide more information. What is the class of each variable
(continuous, count, presence/absence, factor, ...)? What is the output of
summary(model)?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-06 17:15 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:

> Dear LMM experts:
>
> I am pretty new to using LMM and I have found the following situation
> bewildering as I was trying to do diagnostics with my fitted model: my
> conditional residuals correlated highly with the fitted values.
>
> I have a dataset with multiple families, each has 1-4 siblings. I am trying
> to regress Y onto EVs include Drink, Gender, & Age, while using random
> intercept for family. This is the model I used:
> model<-lmer(Y~Drink*Gender+Age
>                       +(1|Family_ID),data,REML=FALSE)
>
> After fitting the model, I used
> plot(model)
> to see the relationship between conditional residuals and fitted values. I
> expect them to be uncorrelated and I expect to see homoscedasticity.
>
> Yet to my surprise there is a high correlation (~0.5) between the residuals
> and the fitted values. (see here <http://imgur.com/pPsG4aR>). I know from
> GLM that this usually suggest nonlinear relationships between the EVs and
> the DV.
>
> I read some online posts (post1
> <
> http://stats.stackexchange.com/questions/43566/strange-pattern-in-residual-plot-from-mixed-effect-model
> >
> post2
> <
> http://stats.stackexchange.com/questions/168179/correlation-between-standardized-residuals-and-fitted-values-in-a-linear-mixed-e/168210#168210
> >)
> that suggest this can result from a poor model fit. So I tried a few
> different models, including: 1) log transform Drink, which is originally
> positively skewed; 2) add random slopes for Drink, Age, etc. None of these
> changes have led to a substantial difference for the residual & fitted
> value correlation.
>
> Some other info:
> 1) my overall model fit is not poor as indicated by the correlation between
> fitted values & Y. It is around 0.8;
> 2) most variables in my model has a normal, or at least symmetrical,
> distribution.
> 3) conditional residuals are normally distributed as shown in qqplots.
> 4) conditional residuals are not correlated with any fixed effects, such as
> Drink or Age.
>
> I have two guesses as to what is going on:
> 1) maybe the fact that each family is a different size actually violates
> assumptions of the model?
> 2) or maybe there is something wrong with estimation of the random effect
> (family intercept)?
>
> I'd really appreciate your insights as to what is going on here and if
> there is any problems with my model.
>
> Thank you very much,
> Cherry
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From chaco001 at umn.edu  Wed Oct  7 15:55:18 2015
From: chaco001 at umn.edu (Jeremy Chacon)
Date: Wed, 7 Oct 2015 08:55:18 -0500
Subject: [R-sig-ME] lmer model construction
In-Reply-To: <CAJuCY5yzbV_xL5e21uE=a-Oe0PKvuaZJSDrodajq_W7k3ouXhA@mail.gmail.com>
References: <CAH65v72--dcK6imO3HyrLkV4swaauUHSDBrWubLem6m=6R=99w@mail.gmail.com>
	<CAJuCY5yzbV_xL5e21uE=a-Oe0PKvuaZJSDrodajq_W7k3ouXhA@mail.gmail.com>
Message-ID: <CAH65v71JLh6ff1uvgvMyVJ8szqHpTZdGyTJTu_khCy=bF5yPCQ@mail.gmail.com>

Dear Thierry,

Thanks for your help. You are correct, my LRT was incorrectly dropping more
than one term--I've fixed that now.  And good to hear I setup the nested
part of the model correctly.

My more general question is how do I know whether terms such as main
effects are important? I understand there is disagreement about whether to
assign p-values to terms in a mixed model due to the degrees of freedom not
being fully known, but I would still like some measure of how important a
term is.

Is a good way to keep doing likelihood-ratio tests all the way down to a
single-intercept model? Or is there another, perhaps better way to
interpret importance in the results of a mixed model?

Thanks again,

Jeremy

On Wed, Oct 7, 2015 at 5:10 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Jeremy,
>
> Adding a random effect for petridish takes the nested design into account.
>
> P * S * M expands to P + S + M + P:S + P:M + S:M + P:S:M. So it includes
> the threeway interaction. I'm not sure if you want that.
> P * S + M expands to P + S + M + P:S. Hence the difference with P * S * M
> is P:M + P:S:M. So a LRT between P * S * M and P * S + M tests the combined
> effect of P:M and P:S:M.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-06 21:06 GMT+02:00 Jeremy Chacon <chaco001 at umn.edu>:
>
>> Hello all,
>>
>> I would appreciate any advice on how to construct and analyze my model.
>>
>> I have conducted a study where I put bacterial colonies onto petri dishes.
>> The colonies were randomly spread across the petri dishes, and the number
>> of colonies varied slightly across each petri dish. Some petri dishes
>> received one bacterial species, some petri dishes received another
>> species.
>> Additionally, half of the petri dishes contained one type of growth media,
>> and the other half contained a different media.
>>
>> So my experimental design is basically a two-factor design:
>>
>> 2 levels of species X 2 levels of media.
>>
>> The design is balanced.
>>
>> The complicated part is that my response of interest is how the proximity
>> of one bacterial colony to its neighbors affects the size of the bacterial
>> colony, and importantly, how this relationship is affected by the
>> bacterial
>> species, growth media, and their interaction.
>>
>> In other words, I have a nested design where my measurements of interest
>> (bacterial colonies) are nested with the truly independent replicates
>> (petri dishes), which is why I intend to use a mixed model.
>>
>> So the data look like this:
>>
>> results =
>>
>> species    media    colonySize    proximityToNeighbor    petriDishID
>>   A        A        12            4                      1
>>   A        A        38            42                     1
>>   A        B        18            50                     2
>>
>> etc, with one observation per colony, and typically about 100 colonies per
>> petri dish.
>>
>> I am trying to correctly construct the model using lme4. I would
>> appreciate
>> suggestion on my model. Also, I would appreciate suggestions on
>> interpretations.
>>
>> My current thought: use a random intercept for each petri dish:
>>
>> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
>> petriDishID), data = results)
>>
>> but this does not describe the nesting of each colony within a petri dish
>> (at least as far as I understand). Do I need to do this?
>>
>> In terms of interpretation, I have been (1) looking at plots to get a feel
>> for effect size and then (2) getting significance values by doing a
>> predictor removal model comparison, like below:
>>
>> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
>> petriDishID), data = results)
>>
>> m2 = lmer(colonySize ~ proximityToNeighbor * species + media + (1 |
>> petriDishID), data = results)
>>
>> anova(m1, m2, test = "F")
>>
>>
>> When I do this, I get a tiny p-value, which (along with plots) suggests to
>> me that the interaction between species and media in their effect on
>> proximityToNeighbor's effect on colonySize is important. Does this sound
>> correct? Any better ways to do this?
>>
>> Thanks very much!
>>
>> Jeremy
>>
>>
>> --
>>
>>
>> *___________________________________________________________________________Jeremy
>> M. Chacon, Ph.D.*
>>
>> *Post-Doctoral Associate, Harcombe Lab*
>> *University of Minnesota*
>> *Ecology, Evolution and Behavior*
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 

*___________________________________________________________________________Jeremy
M. Chacon, Ph.D.*

*Post-Doctoral Associate, Harcombe Lab*
*University of Minnesota*
*Ecology, Evolution and Behavior*

	[[alternative HTML version deleted]]


From xavier.paoletti at curie.fr  Wed Oct  7 16:03:11 2015
From: xavier.paoletti at curie.fr (xavier.paoletti at curie.fr)
Date: Wed, 7 Oct 2015 16:03:11 +0200
Subject: [R-sig-ME] AUTO : No longer at Institut Curie
Message-ID: <OFDC8B4B8E.6C9EEA3B-ONC1257ED7.004D3268-C1257ED7.004D3268@curie.net>


Je suis absent(e) du bureau jusqu'au 31/12/2015

I do not work at Curie any more.
For any questions not related to the activity at Curie, you can reach me at
xavier.paoletti at gustaveroussy.fr.
Best regards,

Xavier Paoletti


Remarque?: ceci est une r?ponse automatique ? votre message
"R-sig-mixed-models Digest, Vol 106, Issue 5" envoy? le 07/10/2015 12:00:01
.

C'est la seule notification que vous recevrez pendant l'absence de cette
personne.


L'int?grit? de ce message n'?tant pas assur?e sur Internet, l'Institut Curie ne peut ?tre tenu responsable de son contenu. 
Si vous n'?tes pas destinataire de ce message confidentiel, merci de le d?truire et d'avertir imm?diatement l'exp?diteur.
Afin de contribuer au respect de l'environnement, merci de n'imprimer ce mail qu'en cas de n?cessit?.


From thierry.onkelinx at inbo.be  Wed Oct  7 16:06:57 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 7 Oct 2015 16:06:57 +0200
Subject: [R-sig-ME] lmer model construction
In-Reply-To: <CAH65v71JLh6ff1uvgvMyVJ8szqHpTZdGyTJTu_khCy=bF5yPCQ@mail.gmail.com>
References: <CAH65v72--dcK6imO3HyrLkV4swaauUHSDBrWubLem6m=6R=99w@mail.gmail.com>
	<CAJuCY5yzbV_xL5e21uE=a-Oe0PKvuaZJSDrodajq_W7k3ouXhA@mail.gmail.com>
	<CAH65v71JLh6ff1uvgvMyVJ8szqHpTZdGyTJTu_khCy=bF5yPCQ@mail.gmail.com>
Message-ID: <CAJuCY5wDacZRP7CcLyUxJSYjXHZJ9TYzUpCAq-+PD0FGT-rP0A@mail.gmail.com>

Dear Jeremy,

The parameters of the main effects are conditional on the interaction. So
you can't compare them directly. I suggest that you read 'Regression
Modeling Strategies' (Harrell, 2001) for more details on this topic.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-07 15:55 GMT+02:00 Jeremy Chacon <chaco001 at umn.edu>:

> Dear Thierry,
>
> Thanks for your help. You are correct, my LRT was incorrectly dropping
> more than one term--I've fixed that now.  And good to hear I setup the
> nested part of the model correctly.
>
> My more general question is how do I know whether terms such as main
> effects are important? I understand there is disagreement about whether to
> assign p-values to terms in a mixed model due to the degrees of freedom not
> being fully known, but I would still like some measure of how important a
> term is.
>
> Is a good way to keep doing likelihood-ratio tests all the way down to a
> single-intercept model? Or is there another, perhaps better way to
> interpret importance in the results of a mixed model?
>
> Thanks again,
>
> Jeremy
>
> On Wed, Oct 7, 2015 at 5:10 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> > wrote:
>
>> Dear Jeremy,
>>
>> Adding a random effect for petridish takes the nested design into account.
>>
>> P * S * M expands to P + S + M + P:S + P:M + S:M + P:S:M. So it includes
>> the threeway interaction. I'm not sure if you want that.
>> P * S + M expands to P + S + M + P:S. Hence the difference with P * S * M
>> is P:M + P:S:M. So a LRT between P * S * M and P * S + M tests the combined
>> effect of P:M and P:S:M.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-10-06 21:06 GMT+02:00 Jeremy Chacon <chaco001 at umn.edu>:
>>
>>> Hello all,
>>>
>>> I would appreciate any advice on how to construct and analyze my model.
>>>
>>> I have conducted a study where I put bacterial colonies onto petri
>>> dishes.
>>> The colonies were randomly spread across the petri dishes, and the number
>>> of colonies varied slightly across each petri dish. Some petri dishes
>>> received one bacterial species, some petri dishes received another
>>> species.
>>> Additionally, half of the petri dishes contained one type of growth
>>> media,
>>> and the other half contained a different media.
>>>
>>> So my experimental design is basically a two-factor design:
>>>
>>> 2 levels of species X 2 levels of media.
>>>
>>> The design is balanced.
>>>
>>> The complicated part is that my response of interest is how the proximity
>>> of one bacterial colony to its neighbors affects the size of the
>>> bacterial
>>> colony, and importantly, how this relationship is affected by the
>>> bacterial
>>> species, growth media, and their interaction.
>>>
>>> In other words, I have a nested design where my measurements of interest
>>> (bacterial colonies) are nested with the truly independent replicates
>>> (petri dishes), which is why I intend to use a mixed model.
>>>
>>> So the data look like this:
>>>
>>> results =
>>>
>>> species    media    colonySize    proximityToNeighbor    petriDishID
>>>   A        A        12            4                      1
>>>   A        A        38            42                     1
>>>   A        B        18            50                     2
>>>
>>> etc, with one observation per colony, and typically about 100 colonies
>>> per
>>> petri dish.
>>>
>>> I am trying to correctly construct the model using lme4. I would
>>> appreciate
>>> suggestion on my model. Also, I would appreciate suggestions on
>>> interpretations.
>>>
>>> My current thought: use a random intercept for each petri dish:
>>>
>>> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
>>> petriDishID), data = results)
>>>
>>> but this does not describe the nesting of each colony within a petri dish
>>> (at least as far as I understand). Do I need to do this?
>>>
>>> In terms of interpretation, I have been (1) looking at plots to get a
>>> feel
>>> for effect size and then (2) getting significance values by doing a
>>> predictor removal model comparison, like below:
>>>
>>> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
>>> petriDishID), data = results)
>>>
>>> m2 = lmer(colonySize ~ proximityToNeighbor * species + media + (1 |
>>> petriDishID), data = results)
>>>
>>> anova(m1, m2, test = "F")
>>>
>>>
>>> When I do this, I get a tiny p-value, which (along with plots) suggests
>>> to
>>> me that the interaction between species and media in their effect on
>>> proximityToNeighbor's effect on colonySize is important. Does this sound
>>> correct? Any better ways to do this?
>>>
>>> Thanks very much!
>>>
>>> Jeremy
>>>
>>>
>>> --
>>>
>>>
>>> *___________________________________________________________________________Jeremy
>>> M. Chacon, Ph.D.*
>>>
>>> *Post-Doctoral Associate, Harcombe Lab*
>>> *University of Minnesota*
>>> *Ecology, Evolution and Behavior*
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
>
> *___________________________________________________________________________Jeremy
> M. Chacon, Ph.D.*
>
> *Post-Doctoral Associate, Harcombe Lab*
> *University of Minnesota*
> *Ecology, Evolution and Behavior*
>
>

	[[alternative HTML version deleted]]


From jake987722 at hotmail.com  Wed Oct  7 16:08:06 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 7 Oct 2015 09:08:06 -0500
Subject: [R-sig-ME] lmer model construction
In-Reply-To: <CAH65v71JLh6ff1uvgvMyVJ8szqHpTZdGyTJTu_khCy=bF5yPCQ@mail.gmail.com>
References: <CAH65v72--dcK6imO3HyrLkV4swaauUHSDBrWubLem6m=6R=99w@mail.gmail.com>,
	<CAJuCY5yzbV_xL5e21uE=a-Oe0PKvuaZJSDrodajq_W7k3ouXhA@mail.gmail.com>,
	<CAH65v71JLh6ff1uvgvMyVJ8szqHpTZdGyTJTu_khCy=bF5yPCQ@mail.gmail.com>
Message-ID: <COL129-W5875B4B7005E053ECC2659CB360@phx.gbl>

I guess the first step is to try to decide on some reasonably precise definition of what it means for a variable to be "important." I think this is a fundamental problem plaguing most discussions of "variable importance." Are you just talking about getting an indication of the strength of association between a predictor and the response variable--like an effect size? In that case I would recommend just looking at and interpreting the slope and its standard error and using your scientific judgment. Standardized effect size is kind of a fraught issue in linear mixed models.

Jake

> Date: Wed, 7 Oct 2015 08:55:18 -0500
> From: chaco001 at umn.edu
> To: thierry.onkelinx at inbo.be
> CC: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lmer model construction
> 
> Dear Thierry,
> 
> Thanks for your help. You are correct, my LRT was incorrectly dropping more
> than one term--I've fixed that now.  And good to hear I setup the nested
> part of the model correctly.
> 
> My more general question is how do I know whether terms such as main
> effects are important? I understand there is disagreement about whether to
> assign p-values to terms in a mixed model due to the degrees of freedom not
> being fully known, but I would still like some measure of how important a
> term is.
> 
> Is a good way to keep doing likelihood-ratio tests all the way down to a
> single-intercept model? Or is there another, perhaps better way to
> interpret importance in the results of a mixed model?
> 
> Thanks again,
> 
> Jeremy
> 
> On Wed, Oct 7, 2015 at 5:10 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
> 
> > Dear Jeremy,
> >
> > Adding a random effect for petridish takes the nested design into account.
> >
> > P * S * M expands to P + S + M + P:S + P:M + S:M + P:S:M. So it includes
> > the threeway interaction. I'm not sure if you want that.
> > P * S + M expands to P + S + M + P:S. Hence the difference with P * S * M
> > is P:M + P:S:M. So a LRT between P * S * M and P * S + M tests the combined
> > effect of P:M and P:S:M.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of data.
> > ~ John Tukey
> >
> > 2015-10-06 21:06 GMT+02:00 Jeremy Chacon <chaco001 at umn.edu>:
> >
> >> Hello all,
> >>
> >> I would appreciate any advice on how to construct and analyze my model.
> >>
> >> I have conducted a study where I put bacterial colonies onto petri dishes.
> >> The colonies were randomly spread across the petri dishes, and the number
> >> of colonies varied slightly across each petri dish. Some petri dishes
> >> received one bacterial species, some petri dishes received another
> >> species.
> >> Additionally, half of the petri dishes contained one type of growth media,
> >> and the other half contained a different media.
> >>
> >> So my experimental design is basically a two-factor design:
> >>
> >> 2 levels of species X 2 levels of media.
> >>
> >> The design is balanced.
> >>
> >> The complicated part is that my response of interest is how the proximity
> >> of one bacterial colony to its neighbors affects the size of the bacterial
> >> colony, and importantly, how this relationship is affected by the
> >> bacterial
> >> species, growth media, and their interaction.
> >>
> >> In other words, I have a nested design where my measurements of interest
> >> (bacterial colonies) are nested with the truly independent replicates
> >> (petri dishes), which is why I intend to use a mixed model.
> >>
> >> So the data look like this:
> >>
> >> results =
> >>
> >> species    media    colonySize    proximityToNeighbor    petriDishID
> >>   A        A        12            4                      1
> >>   A        A        38            42                     1
> >>   A        B        18            50                     2
> >>
> >> etc, with one observation per colony, and typically about 100 colonies per
> >> petri dish.
> >>
> >> I am trying to correctly construct the model using lme4. I would
> >> appreciate
> >> suggestion on my model. Also, I would appreciate suggestions on
> >> interpretations.
> >>
> >> My current thought: use a random intercept for each petri dish:
> >>
> >> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
> >> petriDishID), data = results)
> >>
> >> but this does not describe the nesting of each colony within a petri dish
> >> (at least as far as I understand). Do I need to do this?
> >>
> >> In terms of interpretation, I have been (1) looking at plots to get a feel
> >> for effect size and then (2) getting significance values by doing a
> >> predictor removal model comparison, like below:
> >>
> >> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
> >> petriDishID), data = results)
> >>
> >> m2 = lmer(colonySize ~ proximityToNeighbor * species + media + (1 |
> >> petriDishID), data = results)
> >>
> >> anova(m1, m2, test = "F")
> >>
> >>
> >> When I do this, I get a tiny p-value, which (along with plots) suggests to
> >> me that the interaction between species and media in their effect on
> >> proximityToNeighbor's effect on colonySize is important. Does this sound
> >> correct? Any better ways to do this?
> >>
> >> Thanks very much!
> >>
> >> Jeremy
> >>
> >>
> >> --
> >>
> >>
> >> *___________________________________________________________________________Jeremy
> >> M. Chacon, Ph.D.*
> >>
> >> *Post-Doctoral Associate, Harcombe Lab*
> >> *University of Minnesota*
> >> *Ecology, Evolution and Behavior*
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> 
> 
> -- 
> 
> *___________________________________________________________________________Jeremy
> M. Chacon, Ph.D.*
> 
> *Post-Doctoral Associate, Harcombe Lab*
> *University of Minnesota*
> *Ecology, Evolution and Behavior*
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From a.abrain at gmail.com  Wed Oct  7 16:12:27 2015
From: a.abrain at gmail.com (=?UTF-8?Q?Alejandro_Mart=C3=ADnez_Abra=C3=ADn?=)
Date: Wed, 7 Oct 2015 16:12:27 +0200
Subject: [R-sig-ME] please remove my email from this list
Message-ID: <CAHrfa+xXD4ZzQZW8sAS=LDDJRfwqbbe+w5CCYBTDhLsf-fur2w@mail.gmail.com>

*********************************************
Alejandro Mart?nez Abra?n, PhD

Evolutionary Biology Group

http://www.udc.es/grupos/gibe

*http://ellenguajedelabiosfera.blogspot.com.es/
<http://ellenguajedelabiosfera.blogspot.com.es/>*

http://escolanatesporles.blogspot.com.es/

"*The careful foot can walk anywhere*"

	[[alternative HTML version deleted]]


From chaco001 at umn.edu  Wed Oct  7 16:33:21 2015
From: chaco001 at umn.edu (Jeremy Chacon)
Date: Wed, 7 Oct 2015 09:33:21 -0500
Subject: [R-sig-ME] lmer model construction
In-Reply-To: <COL129-W5875B4B7005E053ECC2659CB360@phx.gbl>
References: <CAH65v72--dcK6imO3HyrLkV4swaauUHSDBrWubLem6m=6R=99w@mail.gmail.com>
	<CAJuCY5yzbV_xL5e21uE=a-Oe0PKvuaZJSDrodajq_W7k3ouXhA@mail.gmail.com>
	<CAH65v71JLh6ff1uvgvMyVJ8szqHpTZdGyTJTu_khCy=bF5yPCQ@mail.gmail.com>
	<COL129-W5875B4B7005E053ECC2659CB360@phx.gbl>
Message-ID: <CAH65v70s4-LRTco=4jehZQ+ej9pb3Q9_C4hqR6SZC_qPqYYHgw@mail.gmail.com>

Thierry, Jake, thank you both for your help.

Jake, you are correct, what is important to me is an effect size. I'll
stick with interpreting these and their SEs for now.

I appreciate all your help.

Best,

Jeremy

On Wed, Oct 7, 2015 at 9:08 AM, Jake Westfall <jake987722 at hotmail.com>
wrote:

> I guess the first step is to try to decide on some reasonably precise
> definition of what it means for a variable to be "important." I think this
> is a fundamental problem plaguing most discussions of "variable
> importance." Are you just talking about getting an indication of the
> strength of association between a predictor and the response variable--like
> an effect size? In that case I would recommend just looking at and
> interpreting the slope and its standard error and using your scientific
> judgment. Standardized effect size is kind of a fraught issue in linear
> mixed models.
>
> Jake
>
> > Date: Wed, 7 Oct 2015 08:55:18 -0500
> > From: chaco001 at umn.edu
> > To: thierry.onkelinx at inbo.be
> > CC: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] lmer model construction
> >
> > Dear Thierry,
> >
> > Thanks for your help. You are correct, my LRT was incorrectly dropping
> more
> > than one term--I've fixed that now.  And good to hear I setup the nested
> > part of the model correctly.
> >
> > My more general question is how do I know whether terms such as main
> > effects are important? I understand there is disagreement about whether
> to
> > assign p-values to terms in a mixed model due to the degrees of freedom
> not
> > being fully known, but I would still like some measure of how important a
> > term is.
> >
> > Is a good way to keep doing likelihood-ratio tests all the way down to a
> > single-intercept model? Or is there another, perhaps better way to
> > interpret importance in the results of a mixed model?
> >
> > Thanks again,
> >
> > Jeremy
> >
> > On Wed, Oct 7, 2015 at 5:10 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
> > wrote:
> >
> > > Dear Jeremy,
> > >
> > > Adding a random effect for petridish takes the nested design into
> account.
> > >
> > > P * S * M expands to P + S + M + P:S + P:M + S:M + P:S:M. So it
> includes
> > > the threeway interaction. I'm not sure if you want that.
> > > P * S + M expands to P + S + M + P:S. Hence the difference with P * S
> * M
> > > is P:M + P:S:M. So a LRT between P * S * M and P * S + M tests the
> combined
> > > effect of P:M and P:S:M.
> > >
> > > Best regards,
> > >
> > > ir. Thierry Onkelinx
> > > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > > Forest
> > > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > > Kliniekstraat 25
> > > 1070 Anderlecht
> > > Belgium
> > >
> > > To call in the statistician after the experiment is done may be no more
> > > than asking him to perform a post-mortem examination: he may be able
> to say
> > > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > > The plural of anecdote is not data. ~ Roger Brinner
> > > The combination of some data and an aching desire for an answer does
> not
> > > ensure that a reasonable answer can be extracted from a given body of
> data.
> > > ~ John Tukey
> > >
> > > 2015-10-06 21:06 GMT+02:00 Jeremy Chacon <chaco001 at umn.edu>:
> > >
> > >> Hello all,
> > >>
> > >> I would appreciate any advice on how to construct and analyze my
> model.
> > >>
> > >> I have conducted a study where I put bacterial colonies onto petri
> dishes.
> > >> The colonies were randomly spread across the petri dishes, and the
> number
> > >> of colonies varied slightly across each petri dish. Some petri dishes
> > >> received one bacterial species, some petri dishes received another
> > >> species.
> > >> Additionally, half of the petri dishes contained one type of growth
> media,
> > >> and the other half contained a different media.
> > >>
> > >> So my experimental design is basically a two-factor design:
> > >>
> > >> 2 levels of species X 2 levels of media.
> > >>
> > >> The design is balanced.
> > >>
> > >> The complicated part is that my response of interest is how the
> proximity
> > >> of one bacterial colony to its neighbors affects the size of the
> bacterial
> > >> colony, and importantly, how this relationship is affected by the
> > >> bacterial
> > >> species, growth media, and their interaction.
> > >>
> > >> In other words, I have a nested design where my measurements of
> interest
> > >> (bacterial colonies) are nested with the truly independent replicates
> > >> (petri dishes), which is why I intend to use a mixed model.
> > >>
> > >> So the data look like this:
> > >>
> > >> results =
> > >>
> > >> species    media    colonySize    proximityToNeighbor    petriDishID
> > >>   A        A        12            4                      1
> > >>   A        A        38            42                     1
> > >>   A        B        18            50                     2
> > >>
> > >> etc, with one observation per colony, and typically about 100
> colonies per
> > >> petri dish.
> > >>
> > >> I am trying to correctly construct the model using lme4. I would
> > >> appreciate
> > >> suggestion on my model. Also, I would appreciate suggestions on
> > >> interpretations.
> > >>
> > >> My current thought: use a random intercept for each petri dish:
> > >>
> > >> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
> > >> petriDishID), data = results)
> > >>
> > >> but this does not describe the nesting of each colony within a petri
> dish
> > >> (at least as far as I understand). Do I need to do this?
> > >>
> > >> In terms of interpretation, I have been (1) looking at plots to get a
> feel
> > >> for effect size and then (2) getting significance values by doing a
> > >> predictor removal model comparison, like below:
> > >>
> > >> m1 = lmer(colonySize ~ proximityToNeighbor * species * media + (1 |
> > >> petriDishID), data = results)
> > >>
> > >> m2 = lmer(colonySize ~ proximityToNeighbor * species + media + (1 |
> > >> petriDishID), data = results)
> > >>
> > >> anova(m1, m2, test = "F")
> > >>
> > >>
> > >> When I do this, I get a tiny p-value, which (along with plots)
> suggests to
> > >> me that the interaction between species and media in their effect on
> > >> proximityToNeighbor's effect on colonySize is important. Does this
> sound
> > >> correct? Any better ways to do this?
> > >>
> > >> Thanks very much!
> > >>
> > >> Jeremy
> > >>
> > >>
> > >> --
> > >>
> > >>
> > >>
> *___________________________________________________________________________Jeremy
> > >> M. Chacon, Ph.D.*
> > >>
> > >> *Post-Doctoral Associate, Harcombe Lab*
> > >> *University of Minnesota*
> > >> *Ecology, Evolution and Behavior*
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >
> > >
> >
> >
> > --
> >
> >
> *___________________________________________________________________________Jeremy
> > M. Chacon, Ph.D.*
> >
> > *Post-Doctoral Associate, Harcombe Lab*
> > *University of Minnesota*
> > *Ecology, Evolution and Behavior*
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*___________________________________________________________________________Jeremy
M. Chacon, Ph.D.*

*Post-Doctoral Associate, Harcombe Lab*
*University of Minnesota*
*Ecology, Evolution and Behavior*

	[[alternative HTML version deleted]]


From maxxx848 at umn.edu  Wed Oct  7 17:09:07 2015
From: maxxx848 at umn.edu (Yizhou Ma)
Date: Wed, 7 Oct 2015 10:09:07 -0500
Subject: [R-sig-ME] LMM diagnostics: conditional residuals correlated
 highly with fitted values
In-Reply-To: <CAJuCY5wQGha+T9R6vsrZvB+HGW0XOc04BgV=+Bzg736J2eSHuw@mail.gmail.com>
References: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>
	<CAJuCY5wQGha+T9R6vsrZvB+HGW0XOc04BgV=+Bzg736J2eSHuw@mail.gmail.com>
Message-ID: <CAKJqZMoS3MgegJV7dEj_zFyJD7uFdVxM4FcxUgrYiVaLOcnp3w@mail.gmail.com>

Hi Thierry,

Thank you for your reply and sorry for the HTML thing. Below is my
summary(model) output.

Y, Drink, and Age are continuous variables
Gender is F & M.
Family_ID is a factor.

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: Y ~ Drink * Gender + Age + (1 | Family_ID)
   Data: data

     AIC      BIC   logLik deviance df.resid
  1046.4   1074.0   -516.2   1032.4      372

Scaled residuals:
     Min       1Q   Median       3Q      Max
-2.67228 -0.56085 -0.02968  0.66166  2.91452

Random effects:
 Groups    Name        Variance Std.Dev.
 Family_ID (Intercept) 0.3550   0.5958
 Residual                    0.6162   0.7850
Number of obs: 379, groups:  Family_ID, 189

Fixed effects:
                          Estimate Std. Error t value
(Intercept)          1.10309    0.43921   2.511
Drink                  0.16425    0.08031   2.045
Gender.M          -0.19364    0.10874  -1.781
Age                    -0.03377    0.01489  -2.268
Drink:Gender.M -0.13647    0.10681  -1.278

Correlation of Fixed Effects:
                (Intr)     Drnk   Gndr.M  Age
Drink        -0.098
Gender.M -0.040 -0.249
Age           -0.985  0.158 -0.054
Drnk:G.M  0.042 -0.737 -0.021 -0.085

Thank you very much,
Cherry

On Wed, Oct 7, 2015 at 5:14 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear Cherry,
>
> Please don't post in HTML. Have a look at the posting guide.
>
> You'll need to provide more information. What is the class of each variable
> (continuous, count, presence/absence, factor, ...)? What is the output of
> summary(model)?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-06 17:15 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>>
>> Dear LMM experts:
>>
>> I am pretty new to using LMM and I have found the following situation
>> bewildering as I was trying to do diagnostics with my fitted model: my
>> conditional residuals correlated highly with the fitted values.
>>
>> I have a dataset with multiple families, each has 1-4 siblings. I am
>> trying
>> to regress Y onto EVs include Drink, Gender, & Age, while using random
>> intercept for family. This is the model I used:
>> model<-lmer(Y~Drink*Gender+Age
>>                       +(1|Family_ID),data,REML=FALSE)
>>
>> After fitting the model, I used
>> plot(model)
>> to see the relationship between conditional residuals and fitted values. I
>> expect them to be uncorrelated and I expect to see homoscedasticity.
>>
>> Yet to my surprise there is a high correlation (~0.5) between the
>> residuals
>> and the fitted values. (see here <http://imgur.com/pPsG4aR>). I know from
>> GLM that this usually suggest nonlinear relationships between the EVs and
>> the DV.
>>
>> I read some online posts (post1
>>
>> <http://stats.stackexchange.com/questions/43566/strange-pattern-in-residual-plot-from-mixed-effect-model>
>> post2
>>
>> <http://stats.stackexchange.com/questions/168179/correlation-between-standardized-residuals-and-fitted-values-in-a-linear-mixed-e/168210#168210>)
>> that suggest this can result from a poor model fit. So I tried a few
>> different models, including: 1) log transform Drink, which is originally
>> positively skewed; 2) add random slopes for Drink, Age, etc. None of these
>> changes have led to a substantial difference for the residual & fitted
>> value correlation.
>>
>> Some other info:
>> 1) my overall model fit is not poor as indicated by the correlation
>> between
>> fitted values & Y. It is around 0.8;
>> 2) most variables in my model has a normal, or at least symmetrical,
>> distribution.
>> 3) conditional residuals are normally distributed as shown in qqplots.
>> 4) conditional residuals are not correlated with any fixed effects, such
>> as
>> Drink or Age.
>>
>> I have two guesses as to what is going on:
>> 1) maybe the fact that each family is a different size actually violates
>> assumptions of the model?
>> 2) or maybe there is something wrong with estimation of the random effect
>> (family intercept)?
>>
>> I'd really appreciate your insights as to what is going on here and if
>> there is any problems with my model.
>>
>> Thank you very much,
>> Cherry
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From thierry.onkelinx at inbo.be  Wed Oct  7 17:15:21 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 7 Oct 2015 17:15:21 +0200
Subject: [R-sig-ME] LMM diagnostics: conditional residuals correlated
 highly with fitted values
In-Reply-To: <CAKJqZMoS3MgegJV7dEj_zFyJD7uFdVxM4FcxUgrYiVaLOcnp3w@mail.gmail.com>
References: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>
	<CAJuCY5wQGha+T9R6vsrZvB+HGW0XOc04BgV=+Bzg736J2eSHuw@mail.gmail.com>
	<CAKJqZMoS3MgegJV7dEj_zFyJD7uFdVxM4FcxUgrYiVaLOcnp3w@mail.gmail.com>
Message-ID: <CAJuCY5w-rNX_hzr0HWf-wq=QPiAtbEfJbnMsxsfNFfnd6ZKELg@mail.gmail.com>

Can you elaborate on what Y is? Does it has a lower boundary? And if so, do
you have observations near that boundary? E.g. Y must be non-negative and
the dataset contains observations close to 0. A densityplot would be useful.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-07 17:09 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:

> Hi Thierry,
>
> Thank you for your reply and sorry for the HTML thing. Below is my
> summary(model) output.
>
> Y, Drink, and Age are continuous variables
> Gender is F & M.
> Family_ID is a factor.
>
> Linear mixed model fit by maximum likelihood  ['lmerMod']
> Formula: Y ~ Drink * Gender + Age + (1 | Family_ID)
>    Data: data
>
>      AIC      BIC   logLik deviance df.resid
>   1046.4   1074.0   -516.2   1032.4      372
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -2.67228 -0.56085 -0.02968  0.66166  2.91452
>
> Random effects:
>  Groups    Name        Variance Std.Dev.
>  Family_ID (Intercept) 0.3550   0.5958
>  Residual                    0.6162   0.7850
> Number of obs: 379, groups:  Family_ID, 189
>
> Fixed effects:
>                           Estimate Std. Error t value
> (Intercept)          1.10309    0.43921   2.511
> Drink                  0.16425    0.08031   2.045
> Gender.M          -0.19364    0.10874  -1.781
> Age                    -0.03377    0.01489  -2.268
> Drink:Gender.M -0.13647    0.10681  -1.278
>
> Correlation of Fixed Effects:
>                 (Intr)     Drnk   Gndr.M  Age
> Drink        -0.098
> Gender.M -0.040 -0.249
> Age           -0.985  0.158 -0.054
> Drnk:G.M  0.042 -0.737 -0.021 -0.085
>
> Thank you very much,
> Cherry
>
> On Wed, Oct 7, 2015 at 5:14 AM, Thierry Onkelinx
> <thierry.onkelinx at inbo.be> wrote:
> > Dear Cherry,
> >
> > Please don't post in HTML. Have a look at the posting guide.
> >
> > You'll need to provide more information. What is the class of each
> variable
> > (continuous, count, presence/absence, factor, ...)? What is the output of
> > summary(model)?
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> than
> > asking him to perform a post-mortem examination: he may be able to say
> what
> > the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2015-10-06 17:15 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
> >>
> >> Dear LMM experts:
> >>
> >> I am pretty new to using LMM and I have found the following situation
> >> bewildering as I was trying to do diagnostics with my fitted model: my
> >> conditional residuals correlated highly with the fitted values.
> >>
> >> I have a dataset with multiple families, each has 1-4 siblings. I am
> >> trying
> >> to regress Y onto EVs include Drink, Gender, & Age, while using random
> >> intercept for family. This is the model I used:
> >> model<-lmer(Y~Drink*Gender+Age
> >>                       +(1|Family_ID),data,REML=FALSE)
> >>
> >> After fitting the model, I used
> >> plot(model)
> >> to see the relationship between conditional residuals and fitted
> values. I
> >> expect them to be uncorrelated and I expect to see homoscedasticity.
> >>
> >> Yet to my surprise there is a high correlation (~0.5) between the
> >> residuals
> >> and the fitted values. (see here <http://imgur.com/pPsG4aR>). I know
> from
> >> GLM that this usually suggest nonlinear relationships between the EVs
> and
> >> the DV.
> >>
> >> I read some online posts (post1
> >>
> >> <
> http://stats.stackexchange.com/questions/43566/strange-pattern-in-residual-plot-from-mixed-effect-model
> >
> >> post2
> >>
> >> <
> http://stats.stackexchange.com/questions/168179/correlation-between-standardized-residuals-and-fitted-values-in-a-linear-mixed-e/168210#168210
> >)
> >> that suggest this can result from a poor model fit. So I tried a few
> >> different models, including: 1) log transform Drink, which is originally
> >> positively skewed; 2) add random slopes for Drink, Age, etc. None of
> these
> >> changes have led to a substantial difference for the residual & fitted
> >> value correlation.
> >>
> >> Some other info:
> >> 1) my overall model fit is not poor as indicated by the correlation
> >> between
> >> fitted values & Y. It is around 0.8;
> >> 2) most variables in my model has a normal, or at least symmetrical,
> >> distribution.
> >> 3) conditional residuals are normally distributed as shown in qqplots.
> >> 4) conditional residuals are not correlated with any fixed effects, such
> >> as
> >> Drink or Age.
> >>
> >> I have two guesses as to what is going on:
> >> 1) maybe the fact that each family is a different size actually violates
> >> assumptions of the model?
> >> 2) or maybe there is something wrong with estimation of the random
> effect
> >> (family intercept)?
> >>
> >> I'd really appreciate your insights as to what is going on here and if
> >> there is any problems with my model.
> >>
> >> Thank you very much,
> >> Cherry
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>

	[[alternative HTML version deleted]]


From maxxx848 at umn.edu  Wed Oct  7 17:29:00 2015
From: maxxx848 at umn.edu (Yizhou Ma)
Date: Wed, 7 Oct 2015 10:29:00 -0500
Subject: [R-sig-ME] LMM diagnostics: conditional residuals correlated
 highly with fitted values
In-Reply-To: <CAJuCY5w-rNX_hzr0HWf-wq=QPiAtbEfJbnMsxsfNFfnd6ZKELg@mail.gmail.com>
References: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>
	<CAJuCY5wQGha+T9R6vsrZvB+HGW0XOc04BgV=+Bzg736J2eSHuw@mail.gmail.com>
	<CAKJqZMoS3MgegJV7dEj_zFyJD7uFdVxM4FcxUgrYiVaLOcnp3w@mail.gmail.com>
	<CAJuCY5w-rNX_hzr0HWf-wq=QPiAtbEfJbnMsxsfNFfnd6ZKELg@mail.gmail.com>
Message-ID: <CAKJqZMoXgeberiS=WRSp+=zZi_2za9dt2E=F9qEGs4KC2JxbCw@mail.gmail.com>

Y is a brain measure that has been standardized. A histogram of Y is here:
http://imgur.com/Um8yyuu

I am confused about the "Y must be non-negative and the dataset
contains observations close to 0" part. Is that the requirements for
Y? Is so, then my model could be wrong.

On Wed, Oct 7, 2015 at 10:15 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Can you elaborate on what Y is? Does it has a lower boundary? And if so, do
> you have observations near that boundary? E.g. Y must be non-negative and
> the dataset contains observations close to 0. A densityplot would be useful.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-07 17:09 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>>
>> Hi Thierry,
>>
>> Thank you for your reply and sorry for the HTML thing. Below is my
>> summary(model) output.
>>
>> Y, Drink, and Age are continuous variables
>> Gender is F & M.
>> Family_ID is a factor.
>>
>> Linear mixed model fit by maximum likelihood  ['lmerMod']
>> Formula: Y ~ Drink * Gender + Age + (1 | Family_ID)
>>    Data: data
>>
>>      AIC      BIC   logLik deviance df.resid
>>   1046.4   1074.0   -516.2   1032.4      372
>>
>> Scaled residuals:
>>      Min       1Q   Median       3Q      Max
>> -2.67228 -0.56085 -0.02968  0.66166  2.91452
>>
>> Random effects:
>>  Groups    Name        Variance Std.Dev.
>>  Family_ID (Intercept) 0.3550   0.5958
>>  Residual                    0.6162   0.7850
>> Number of obs: 379, groups:  Family_ID, 189
>>
>> Fixed effects:
>>                           Estimate Std. Error t value
>> (Intercept)          1.10309    0.43921   2.511
>> Drink                  0.16425    0.08031   2.045
>> Gender.M          -0.19364    0.10874  -1.781
>> Age                    -0.03377    0.01489  -2.268
>> Drink:Gender.M -0.13647    0.10681  -1.278
>>
>> Correlation of Fixed Effects:
>>                 (Intr)     Drnk   Gndr.M  Age
>> Drink        -0.098
>> Gender.M -0.040 -0.249
>> Age           -0.985  0.158 -0.054
>> Drnk:G.M  0.042 -0.737 -0.021 -0.085
>>
>> Thank you very much,
>> Cherry
>>
>> On Wed, Oct 7, 2015 at 5:14 AM, Thierry Onkelinx
>> <thierry.onkelinx at inbo.be> wrote:
>> > Dear Cherry,
>> >
>> > Please don't post in HTML. Have a look at the posting guide.
>> >
>> > You'll need to provide more information. What is the class of each
>> > variable
>> > (continuous, count, presence/absence, factor, ...)? What is the output
>> > of
>> > summary(model)?
>> >
>> > Best regards,
>> >
>> > ir. Thierry Onkelinx
>> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> > and
>> > Forest
>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> > Kliniekstraat 25
>> > 1070 Anderlecht
>> > Belgium
>> >
>> > To call in the statistician after the experiment is done may be no more
>> > than
>> > asking him to perform a post-mortem examination: he may be able to say
>> > what
>> > the experiment died of. ~ Sir Ronald Aylmer Fisher
>> > The plural of anecdote is not data. ~ Roger Brinner
>> > The combination of some data and an aching desire for an answer does not
>> > ensure that a reasonable answer can be extracted from a given body of
>> > data.
>> > ~ John Tukey
>> >
>> > 2015-10-06 17:15 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>> >>
>> >> Dear LMM experts:
>> >>
>> >> I am pretty new to using LMM and I have found the following situation
>> >> bewildering as I was trying to do diagnostics with my fitted model: my
>> >> conditional residuals correlated highly with the fitted values.
>> >>
>> >> I have a dataset with multiple families, each has 1-4 siblings. I am
>> >> trying
>> >> to regress Y onto EVs include Drink, Gender, & Age, while using random
>> >> intercept for family. This is the model I used:
>> >> model<-lmer(Y~Drink*Gender+Age
>> >>                       +(1|Family_ID),data,REML=FALSE)
>> >>
>> >> After fitting the model, I used
>> >> plot(model)
>> >> to see the relationship between conditional residuals and fitted
>> >> values. I
>> >> expect them to be uncorrelated and I expect to see homoscedasticity.
>> >>
>> >> Yet to my surprise there is a high correlation (~0.5) between the
>> >> residuals
>> >> and the fitted values. (see here <http://imgur.com/pPsG4aR>). I know
>> >> from
>> >> GLM that this usually suggest nonlinear relationships between the EVs
>> >> and
>> >> the DV.
>> >>
>> >> I read some online posts (post1
>> >>
>> >>
>> >> <http://stats.stackexchange.com/questions/43566/strange-pattern-in-residual-plot-from-mixed-effect-model>
>> >> post2
>> >>
>> >>
>> >> <http://stats.stackexchange.com/questions/168179/correlation-between-standardized-residuals-and-fitted-values-in-a-linear-mixed-e/168210#168210>)
>> >> that suggest this can result from a poor model fit. So I tried a few
>> >> different models, including: 1) log transform Drink, which is
>> >> originally
>> >> positively skewed; 2) add random slopes for Drink, Age, etc. None of
>> >> these
>> >> changes have led to a substantial difference for the residual & fitted
>> >> value correlation.
>> >>
>> >> Some other info:
>> >> 1) my overall model fit is not poor as indicated by the correlation
>> >> between
>> >> fitted values & Y. It is around 0.8;
>> >> 2) most variables in my model has a normal, or at least symmetrical,
>> >> distribution.
>> >> 3) conditional residuals are normally distributed as shown in qqplots.
>> >> 4) conditional residuals are not correlated with any fixed effects,
>> >> such
>> >> as
>> >> Drink or Age.
>> >>
>> >> I have two guesses as to what is going on:
>> >> 1) maybe the fact that each family is a different size actually
>> >> violates
>> >> assumptions of the model?
>> >> 2) or maybe there is something wrong with estimation of the random
>> >> effect
>> >> (family intercept)?
>> >>
>> >> I'd really appreciate your insights as to what is going on here and if
>> >> there is any problems with my model.
>> >>
>> >> Thank you very much,
>> >> Cherry
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>
>


From thierry.onkelinx at inbo.be  Wed Oct  7 17:54:01 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 7 Oct 2015 17:54:01 +0200
Subject: [R-sig-ME] LMM diagnostics: conditional residuals correlated
 highly with fitted values
In-Reply-To: <CAKJqZMoXgeberiS=WRSp+=zZi_2za9dt2E=F9qEGs4KC2JxbCw@mail.gmail.com>
References: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>
	<CAJuCY5wQGha+T9R6vsrZvB+HGW0XOc04BgV=+Bzg736J2eSHuw@mail.gmail.com>
	<CAKJqZMoS3MgegJV7dEj_zFyJD7uFdVxM4FcxUgrYiVaLOcnp3w@mail.gmail.com>
	<CAJuCY5w-rNX_hzr0HWf-wq=QPiAtbEfJbnMsxsfNFfnd6ZKELg@mail.gmail.com>
	<CAKJqZMoXgeberiS=WRSp+=zZi_2za9dt2E=F9qEGs4KC2JxbCw@mail.gmail.com>
Message-ID: <CAJuCY5xgUqN4HBz8hcH52SSSNwzqbbbgrwxa8qiPMN22yjGzBQ@mail.gmail.com>

My example is not a requirement of a LMM but rather an example of a
distribution of a variable which can cause troubles with a LMM. Think of an
area. An area cannot be negative. This can cause artefacts into the
residuals when you have lots of values near zero. Have a look at this
example.

n <- 200
dataset <- data.frame(
  X = runif(n)
)
dataset$eta <- -.1 + 3 * dataset$X
dataset$Y <- rpois(n, lambda = exp(dataset$eta))
model <- lm(Y~ X, data = dataset) #wrong analysis for this kind of data,
here just an illustration of the problem
plot(fitted(model), resid(model))

But this doesn't seems to be the problem in your case.

I would recommend that you see if there are patterns in the residuals when
you plot them against the covariates. Maybe you are missing an interaction
or even an important covariate.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-07 17:29 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:

> Y is a brain measure that has been standardized. A histogram of Y is here:
> http://imgur.com/Um8yyuu
>
> I am confused about the "Y must be non-negative and the dataset
> contains observations close to 0" part. Is that the requirements for
> Y? Is so, then my model could be wrong.
>
> On Wed, Oct 7, 2015 at 10:15 AM, Thierry Onkelinx
> <thierry.onkelinx at inbo.be> wrote:
> > Can you elaborate on what Y is? Does it has a lower boundary? And if so,
> do
> > you have observations near that boundary? E.g. Y must be non-negative and
> > the dataset contains observations close to 0. A densityplot would be
> useful.
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> than
> > asking him to perform a post-mortem examination: he may be able to say
> what
> > the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2015-10-07 17:09 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
> >>
> >> Hi Thierry,
> >>
> >> Thank you for your reply and sorry for the HTML thing. Below is my
> >> summary(model) output.
> >>
> >> Y, Drink, and Age are continuous variables
> >> Gender is F & M.
> >> Family_ID is a factor.
> >>
> >> Linear mixed model fit by maximum likelihood  ['lmerMod']
> >> Formula: Y ~ Drink * Gender + Age + (1 | Family_ID)
> >>    Data: data
> >>
> >>      AIC      BIC   logLik deviance df.resid
> >>   1046.4   1074.0   -516.2   1032.4      372
> >>
> >> Scaled residuals:
> >>      Min       1Q   Median       3Q      Max
> >> -2.67228 -0.56085 -0.02968  0.66166  2.91452
> >>
> >> Random effects:
> >>  Groups    Name        Variance Std.Dev.
> >>  Family_ID (Intercept) 0.3550   0.5958
> >>  Residual                    0.6162   0.7850
> >> Number of obs: 379, groups:  Family_ID, 189
> >>
> >> Fixed effects:
> >>                           Estimate Std. Error t value
> >> (Intercept)          1.10309    0.43921   2.511
> >> Drink                  0.16425    0.08031   2.045
> >> Gender.M          -0.19364    0.10874  -1.781
> >> Age                    -0.03377    0.01489  -2.268
> >> Drink:Gender.M -0.13647    0.10681  -1.278
> >>
> >> Correlation of Fixed Effects:
> >>                 (Intr)     Drnk   Gndr.M  Age
> >> Drink        -0.098
> >> Gender.M -0.040 -0.249
> >> Age           -0.985  0.158 -0.054
> >> Drnk:G.M  0.042 -0.737 -0.021 -0.085
> >>
> >> Thank you very much,
> >> Cherry
> >>
> >> On Wed, Oct 7, 2015 at 5:14 AM, Thierry Onkelinx
> >> <thierry.onkelinx at inbo.be> wrote:
> >> > Dear Cherry,
> >> >
> >> > Please don't post in HTML. Have a look at the posting guide.
> >> >
> >> > You'll need to provide more information. What is the class of each
> >> > variable
> >> > (continuous, count, presence/absence, factor, ...)? What is the output
> >> > of
> >> > summary(model)?
> >> >
> >> > Best regards,
> >> >
> >> > ir. Thierry Onkelinx
> >> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> >> > and
> >> > Forest
> >> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> > Kliniekstraat 25
> >> > 1070 Anderlecht
> >> > Belgium
> >> >
> >> > To call in the statistician after the experiment is done may be no
> more
> >> > than
> >> > asking him to perform a post-mortem examination: he may be able to say
> >> > what
> >> > the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> > The plural of anecdote is not data. ~ Roger Brinner
> >> > The combination of some data and an aching desire for an answer does
> not
> >> > ensure that a reasonable answer can be extracted from a given body of
> >> > data.
> >> > ~ John Tukey
> >> >
> >> > 2015-10-06 17:15 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
> >> >>
> >> >> Dear LMM experts:
> >> >>
> >> >> I am pretty new to using LMM and I have found the following situation
> >> >> bewildering as I was trying to do diagnostics with my fitted model:
> my
> >> >> conditional residuals correlated highly with the fitted values.
> >> >>
> >> >> I have a dataset with multiple families, each has 1-4 siblings. I am
> >> >> trying
> >> >> to regress Y onto EVs include Drink, Gender, & Age, while using
> random
> >> >> intercept for family. This is the model I used:
> >> >> model<-lmer(Y~Drink*Gender+Age
> >> >>                       +(1|Family_ID),data,REML=FALSE)
> >> >>
> >> >> After fitting the model, I used
> >> >> plot(model)
> >> >> to see the relationship between conditional residuals and fitted
> >> >> values. I
> >> >> expect them to be uncorrelated and I expect to see homoscedasticity.
> >> >>
> >> >> Yet to my surprise there is a high correlation (~0.5) between the
> >> >> residuals
> >> >> and the fitted values. (see here <http://imgur.com/pPsG4aR>). I know
> >> >> from
> >> >> GLM that this usually suggest nonlinear relationships between the EVs
> >> >> and
> >> >> the DV.
> >> >>
> >> >> I read some online posts (post1
> >> >>
> >> >>
> >> >> <
> http://stats.stackexchange.com/questions/43566/strange-pattern-in-residual-plot-from-mixed-effect-model
> >
> >> >> post2
> >> >>
> >> >>
> >> >> <
> http://stats.stackexchange.com/questions/168179/correlation-between-standardized-residuals-and-fitted-values-in-a-linear-mixed-e/168210#168210
> >)
> >> >> that suggest this can result from a poor model fit. So I tried a few
> >> >> different models, including: 1) log transform Drink, which is
> >> >> originally
> >> >> positively skewed; 2) add random slopes for Drink, Age, etc. None of
> >> >> these
> >> >> changes have led to a substantial difference for the residual &
> fitted
> >> >> value correlation.
> >> >>
> >> >> Some other info:
> >> >> 1) my overall model fit is not poor as indicated by the correlation
> >> >> between
> >> >> fitted values & Y. It is around 0.8;
> >> >> 2) most variables in my model has a normal, or at least symmetrical,
> >> >> distribution.
> >> >> 3) conditional residuals are normally distributed as shown in
> qqplots.
> >> >> 4) conditional residuals are not correlated with any fixed effects,
> >> >> such
> >> >> as
> >> >> Drink or Age.
> >> >>
> >> >> I have two guesses as to what is going on:
> >> >> 1) maybe the fact that each family is a different size actually
> >> >> violates
> >> >> assumptions of the model?
> >> >> 2) or maybe there is something wrong with estimation of the random
> >> >> effect
> >> >> (family intercept)?
> >> >>
> >> >> I'd really appreciate your insights as to what is going on here and
> if
> >> >> there is any problems with my model.
> >> >>
> >> >> Thank you very much,
> >> >> Cherry
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> _______________________________________________
> >> >> R-sig-mixed-models at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >> >
> >
> >
>

	[[alternative HTML version deleted]]


From maxxx848 at umn.edu  Wed Oct  7 18:05:12 2015
From: maxxx848 at umn.edu (Yizhou Ma)
Date: Wed, 7 Oct 2015 11:05:12 -0500
Subject: [R-sig-ME] LMM diagnostics: conditional residuals correlated
 highly with fitted values
In-Reply-To: <CAJuCY5xgUqN4HBz8hcH52SSSNwzqbbbgrwxa8qiPMN22yjGzBQ@mail.gmail.com>
References: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>
	<CAJuCY5wQGha+T9R6vsrZvB+HGW0XOc04BgV=+Bzg736J2eSHuw@mail.gmail.com>
	<CAKJqZMoS3MgegJV7dEj_zFyJD7uFdVxM4FcxUgrYiVaLOcnp3w@mail.gmail.com>
	<CAJuCY5w-rNX_hzr0HWf-wq=QPiAtbEfJbnMsxsfNFfnd6ZKELg@mail.gmail.com>
	<CAKJqZMoXgeberiS=WRSp+=zZi_2za9dt2E=F9qEGs4KC2JxbCw@mail.gmail.com>
	<CAJuCY5xgUqN4HBz8hcH52SSSNwzqbbbgrwxa8qiPMN22yjGzBQ@mail.gmail.com>
Message-ID: <CAKJqZMoxoCdYgFDpL38q5a_9=LOQiW1Hgfe_eqTj2MYu+TPRrA@mail.gmail.com>

Hi Thierry,

Thank you for clarifying. I agree that high skewness can lead to
nonlinear relationship which can not be properly modeled in linear
models.

I have plotted the residuals against all my fixed factors and I cannot
find any nonlinear relationship. It is possible that I am missing an
important covariate though.

Thanks a lot,
Cherry


On Wed, Oct 7, 2015 at 10:54 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> My example is not a requirement of a LMM but rather an example of a
> distribution of a variable which can cause troubles with a LMM. Think of an
> area. An area cannot be negative. This can cause artefacts into the
> residuals when you have lots of values near zero. Have a look at this
> example.
>
> n <- 200
> dataset <- data.frame(
>   X = runif(n)
> )
> dataset$eta <- -.1 + 3 * dataset$X
> dataset$Y <- rpois(n, lambda = exp(dataset$eta))
> model <- lm(Y~ X, data = dataset) #wrong analysis for this kind of data,
> here just an illustration of the problem
> plot(fitted(model), resid(model))
>
> But this doesn't seems to be the problem in your case.
>
> I would recommend that you see if there are patterns in the residuals when
> you plot them against the covariates. Maybe you are missing an interaction
> or even an important covariate.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-07 17:29 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>>
>> Y is a brain measure that has been standardized. A histogram of Y is here:
>> http://imgur.com/Um8yyuu
>>
>> I am confused about the "Y must be non-negative and the dataset
>> contains observations close to 0" part. Is that the requirements for
>> Y? Is so, then my model could be wrong.
>>
>> On Wed, Oct 7, 2015 at 10:15 AM, Thierry Onkelinx
>> <thierry.onkelinx at inbo.be> wrote:
>> > Can you elaborate on what Y is? Does it has a lower boundary? And if so,
>> > do
>> > you have observations near that boundary? E.g. Y must be non-negative
>> > and
>> > the dataset contains observations close to 0. A densityplot would be
>> > useful.
>> >
>> > ir. Thierry Onkelinx
>> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> > and
>> > Forest
>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> > Kliniekstraat 25
>> > 1070 Anderlecht
>> > Belgium
>> >
>> > To call in the statistician after the experiment is done may be no more
>> > than
>> > asking him to perform a post-mortem examination: he may be able to say
>> > what
>> > the experiment died of. ~ Sir Ronald Aylmer Fisher
>> > The plural of anecdote is not data. ~ Roger Brinner
>> > The combination of some data and an aching desire for an answer does not
>> > ensure that a reasonable answer can be extracted from a given body of
>> > data.
>> > ~ John Tukey
>> >
>> > 2015-10-07 17:09 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>> >>
>> >> Hi Thierry,
>> >>
>> >> Thank you for your reply and sorry for the HTML thing. Below is my
>> >> summary(model) output.
>> >>
>> >> Y, Drink, and Age are continuous variables
>> >> Gender is F & M.
>> >> Family_ID is a factor.
>> >>
>> >> Linear mixed model fit by maximum likelihood  ['lmerMod']
>> >> Formula: Y ~ Drink * Gender + Age + (1 | Family_ID)
>> >>    Data: data
>> >>
>> >>      AIC      BIC   logLik deviance df.resid
>> >>   1046.4   1074.0   -516.2   1032.4      372
>> >>
>> >> Scaled residuals:
>> >>      Min       1Q   Median       3Q      Max
>> >> -2.67228 -0.56085 -0.02968  0.66166  2.91452
>> >>
>> >> Random effects:
>> >>  Groups    Name        Variance Std.Dev.
>> >>  Family_ID (Intercept) 0.3550   0.5958
>> >>  Residual                    0.6162   0.7850
>> >> Number of obs: 379, groups:  Family_ID, 189
>> >>
>> >> Fixed effects:
>> >>                           Estimate Std. Error t value
>> >> (Intercept)          1.10309    0.43921   2.511
>> >> Drink                  0.16425    0.08031   2.045
>> >> Gender.M          -0.19364    0.10874  -1.781
>> >> Age                    -0.03377    0.01489  -2.268
>> >> Drink:Gender.M -0.13647    0.10681  -1.278
>> >>
>> >> Correlation of Fixed Effects:
>> >>                 (Intr)     Drnk   Gndr.M  Age
>> >> Drink        -0.098
>> >> Gender.M -0.040 -0.249
>> >> Age           -0.985  0.158 -0.054
>> >> Drnk:G.M  0.042 -0.737 -0.021 -0.085
>> >>
>> >> Thank you very much,
>> >> Cherry
>> >>
>> >> On Wed, Oct 7, 2015 at 5:14 AM, Thierry Onkelinx
>> >> <thierry.onkelinx at inbo.be> wrote:
>> >> > Dear Cherry,
>> >> >
>> >> > Please don't post in HTML. Have a look at the posting guide.
>> >> >
>> >> > You'll need to provide more information. What is the class of each
>> >> > variable
>> >> > (continuous, count, presence/absence, factor, ...)? What is the
>> >> > output
>> >> > of
>> >> > summary(model)?
>> >> >
>> >> > Best regards,
>> >> >
>> >> > ir. Thierry Onkelinx
>> >> > Instituut voor natuur- en bosonderzoek / Research Institute for
>> >> > Nature
>> >> > and
>> >> > Forest
>> >> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> >> > Kliniekstraat 25
>> >> > 1070 Anderlecht
>> >> > Belgium
>> >> >
>> >> > To call in the statistician after the experiment is done may be no
>> >> > more
>> >> > than
>> >> > asking him to perform a post-mortem examination: he may be able to
>> >> > say
>> >> > what
>> >> > the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> > The plural of anecdote is not data. ~ Roger Brinner
>> >> > The combination of some data and an aching desire for an answer does
>> >> > not
>> >> > ensure that a reasonable answer can be extracted from a given body of
>> >> > data.
>> >> > ~ John Tukey
>> >> >
>> >> > 2015-10-06 17:15 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>> >> >>
>> >> >> Dear LMM experts:
>> >> >>
>> >> >> I am pretty new to using LMM and I have found the following
>> >> >> situation
>> >> >> bewildering as I was trying to do diagnostics with my fitted model:
>> >> >> my
>> >> >> conditional residuals correlated highly with the fitted values.
>> >> >>
>> >> >> I have a dataset with multiple families, each has 1-4 siblings. I am
>> >> >> trying
>> >> >> to regress Y onto EVs include Drink, Gender, & Age, while using
>> >> >> random
>> >> >> intercept for family. This is the model I used:
>> >> >> model<-lmer(Y~Drink*Gender+Age
>> >> >>                       +(1|Family_ID),data,REML=FALSE)
>> >> >>
>> >> >> After fitting the model, I used
>> >> >> plot(model)
>> >> >> to see the relationship between conditional residuals and fitted
>> >> >> values. I
>> >> >> expect them to be uncorrelated and I expect to see homoscedasticity.
>> >> >>
>> >> >> Yet to my surprise there is a high correlation (~0.5) between the
>> >> >> residuals
>> >> >> and the fitted values. (see here <http://imgur.com/pPsG4aR>). I know
>> >> >> from
>> >> >> GLM that this usually suggest nonlinear relationships between the
>> >> >> EVs
>> >> >> and
>> >> >> the DV.
>> >> >>
>> >> >> I read some online posts (post1
>> >> >>
>> >> >>
>> >> >>
>> >> >> <http://stats.stackexchange.com/questions/43566/strange-pattern-in-residual-plot-from-mixed-effect-model>
>> >> >> post2
>> >> >>
>> >> >>
>> >> >>
>> >> >> <http://stats.stackexchange.com/questions/168179/correlation-between-standardized-residuals-and-fitted-values-in-a-linear-mixed-e/168210#168210>)
>> >> >> that suggest this can result from a poor model fit. So I tried a few
>> >> >> different models, including: 1) log transform Drink, which is
>> >> >> originally
>> >> >> positively skewed; 2) add random slopes for Drink, Age, etc. None of
>> >> >> these
>> >> >> changes have led to a substantial difference for the residual &
>> >> >> fitted
>> >> >> value correlation.
>> >> >>
>> >> >> Some other info:
>> >> >> 1) my overall model fit is not poor as indicated by the correlation
>> >> >> between
>> >> >> fitted values & Y. It is around 0.8;
>> >> >> 2) most variables in my model has a normal, or at least symmetrical,
>> >> >> distribution.
>> >> >> 3) conditional residuals are normally distributed as shown in
>> >> >> qqplots.
>> >> >> 4) conditional residuals are not correlated with any fixed effects,
>> >> >> such
>> >> >> as
>> >> >> Drink or Age.
>> >> >>
>> >> >> I have two guesses as to what is going on:
>> >> >> 1) maybe the fact that each family is a different size actually
>> >> >> violates
>> >> >> assumptions of the model?
>> >> >> 2) or maybe there is something wrong with estimation of the random
>> >> >> effect
>> >> >> (family intercept)?
>> >> >>
>> >> >> I'd really appreciate your insights as to what is going on here and
>> >> >> if
>> >> >> there is any problems with my model.
>> >> >>
>> >> >> Thank you very much,
>> >> >> Cherry
>> >> >>
>> >> >>         [[alternative HTML version deleted]]
>> >> >>
>> >> >> _______________________________________________
>> >> >> R-sig-mixed-models at r-project.org mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >
>> >> >
>> >
>> >
>
>


From ukoether at uke.de  Wed Oct  7 18:38:01 2015
From: ukoether at uke.de (=?UTF-8?Q?Ulf_K=c3=b6ther?=)
Date: Wed, 7 Oct 2015 18:38:01 +0200
Subject: [R-sig-ME] LMM diagnostics: conditional residuals correlated
 highly with fitted values
In-Reply-To: <CAKJqZMoxoCdYgFDpL38q5a_9=LOQiW1Hgfe_eqTj2MYu+TPRrA@mail.gmail.com>
References: <CAKJqZMqRNtjLofvXr1KChLwnGv99=u0J98vP2QScSyaHoRcabA@mail.gmail.com>
	<CAJuCY5wQGha+T9R6vsrZvB+HGW0XOc04BgV=+Bzg736J2eSHuw@mail.gmail.com>
	<CAKJqZMoS3MgegJV7dEj_zFyJD7uFdVxM4FcxUgrYiVaLOcnp3w@mail.gmail.com>
	<CAJuCY5w-rNX_hzr0HWf-wq=QPiAtbEfJbnMsxsfNFfnd6ZKELg@mail.gmail.com>
	<CAKJqZMoXgeberiS=WRSp+=zZi_2za9dt2E=F9qEGs4KC2JxbCw@mail.gmail.com>
	<CAJuCY5xgUqN4HBz8hcH52SSSNwzqbbbgrwxa8qiPMN22yjGzBQ@mail.gmail.com>
	<CAKJqZMoxoCdYgFDpL38q5a_9=LOQiW1Hgfe_eqTj2MYu+TPRrA@mail.gmail.com>
Message-ID: <56154A69.3000200@uke.de>

Dear Cherry,

maybe the correlation - which by the way seemed not that excessive to me
according to the first plot you posted but regardless of the r = 0.5
value (and I might be wrong with that totally!) - between your fitted
values and the residuals is coming from something like a non-linear
effect of age or drink on Y? To test this (in kind of half-formal way),
try this:

library(mgcv)
Res1 <- resid(model, scaled = TRUE)
L1 <- gam(Res1 ~ s(age), data = data)
plot(L1, xlab = "age")
points(x = data$age, y = Res1)
abline(h = 0)

...and then the same for drink. If there is no remaining non-linear age
effect in the residuals then this smoother should be around the
horizontal line at 0 for all age values, and the p-value of the smoother
should then indicate a non-significant age effect.

Good luck,

Ulf




Am 07.10.2015 um 18:05 schrieb Yizhou Ma:
> Hi Thierry,
> 
> Thank you for clarifying. I agree that high skewness can lead to
> nonlinear relationship which can not be properly modeled in linear
> models.
> 
> I have plotted the residuals against all my fixed factors and I cannot
> find any nonlinear relationship. It is possible that I am missing an
> important covariate though.
> 
> Thanks a lot,
> Cherry
> 
> 
> On Wed, Oct 7, 2015 at 10:54 AM, Thierry Onkelinx
> <thierry.onkelinx at inbo.be> wrote:
>> My example is not a requirement of a LMM but rather an example of a
>> distribution of a variable which can cause troubles with a LMM. Think of an
>> area. An area cannot be negative. This can cause artefacts into the
>> residuals when you have lots of values near zero. Have a look at this
>> example.
>>
>> n <- 200
>> dataset <- data.frame(
>>   X = runif(n)
>> )
>> dataset$eta <- -.1 + 3 * dataset$X
>> dataset$Y <- rpois(n, lambda = exp(dataset$eta))
>> model <- lm(Y~ X, data = dataset) #wrong analysis for this kind of data,
>> here just an illustration of the problem
>> plot(fitted(model), resid(model))
>>
>> But this doesn't seems to be the problem in your case.
>>
>> I would recommend that you see if there are patterns in the residuals when
>> you plot them against the covariates. Maybe you are missing an interaction
>> or even an important covariate.
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more than
>> asking him to perform a post-mortem examination: he may be able to say what
>> the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-10-07 17:29 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>>>
>>> Y is a brain measure that has been standardized. A histogram of Y is here:
>>> http://imgur.com/Um8yyuu
>>>
>>> I am confused about the "Y must be non-negative and the dataset
>>> contains observations close to 0" part. Is that the requirements for
>>> Y? Is so, then my model could be wrong.
>>>
>>> On Wed, Oct 7, 2015 at 10:15 AM, Thierry Onkelinx
>>> <thierry.onkelinx at inbo.be> wrote:
>>>> Can you elaborate on what Y is? Does it has a lower boundary? And if so,
>>>> do
>>>> you have observations near that boundary? E.g. Y must be non-negative
>>>> and
>>>> the dataset contains observations close to 0. A densityplot would be
>>>> useful.
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and
>>>> Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than
>>>> asking him to perform a post-mortem examination: he may be able to say
>>>> what
>>>> the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of
>>>> data.
>>>> ~ John Tukey
>>>>
>>>> 2015-10-07 17:09 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>>>>>
>>>>> Hi Thierry,
>>>>>
>>>>> Thank you for your reply and sorry for the HTML thing. Below is my
>>>>> summary(model) output.
>>>>>
>>>>> Y, Drink, and Age are continuous variables
>>>>> Gender is F & M.
>>>>> Family_ID is a factor.
>>>>>
>>>>> Linear mixed model fit by maximum likelihood  ['lmerMod']
>>>>> Formula: Y ~ Drink * Gender + Age + (1 | Family_ID)
>>>>>    Data: data
>>>>>
>>>>>      AIC      BIC   logLik deviance df.resid
>>>>>   1046.4   1074.0   -516.2   1032.4      372
>>>>>
>>>>> Scaled residuals:
>>>>>      Min       1Q   Median       3Q      Max
>>>>> -2.67228 -0.56085 -0.02968  0.66166  2.91452
>>>>>
>>>>> Random effects:
>>>>>  Groups    Name        Variance Std.Dev.
>>>>>  Family_ID (Intercept) 0.3550   0.5958
>>>>>  Residual                    0.6162   0.7850
>>>>> Number of obs: 379, groups:  Family_ID, 189
>>>>>
>>>>> Fixed effects:
>>>>>                           Estimate Std. Error t value
>>>>> (Intercept)          1.10309    0.43921   2.511
>>>>> Drink                  0.16425    0.08031   2.045
>>>>> Gender.M          -0.19364    0.10874  -1.781
>>>>> Age                    -0.03377    0.01489  -2.268
>>>>> Drink:Gender.M -0.13647    0.10681  -1.278
>>>>>
>>>>> Correlation of Fixed Effects:
>>>>>                 (Intr)     Drnk   Gndr.M  Age
>>>>> Drink        -0.098
>>>>> Gender.M -0.040 -0.249
>>>>> Age           -0.985  0.158 -0.054
>>>>> Drnk:G.M  0.042 -0.737 -0.021 -0.085
>>>>>
>>>>> Thank you very much,
>>>>> Cherry
>>>>>
>>>>> On Wed, Oct 7, 2015 at 5:14 AM, Thierry Onkelinx
>>>>> <thierry.onkelinx at inbo.be> wrote:
>>>>>> Dear Cherry,
>>>>>>
>>>>>> Please don't post in HTML. Have a look at the posting guide.
>>>>>>
>>>>>> You'll need to provide more information. What is the class of each
>>>>>> variable
>>>>>> (continuous, count, presence/absence, factor, ...)? What is the
>>>>>> output
>>>>>> of
>>>>>> summary(model)?
>>>>>>
>>>>>> Best regards,
>>>>>>
>>>>>> ir. Thierry Onkelinx
>>>>>> Instituut voor natuur- en bosonderzoek / Research Institute for
>>>>>> Nature
>>>>>> and
>>>>>> Forest
>>>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>> Kliniekstraat 25
>>>>>> 1070 Anderlecht
>>>>>> Belgium
>>>>>>
>>>>>> To call in the statistician after the experiment is done may be no
>>>>>> more
>>>>>> than
>>>>>> asking him to perform a post-mortem examination: he may be able to
>>>>>> say
>>>>>> what
>>>>>> the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>>> The combination of some data and an aching desire for an answer does
>>>>>> not
>>>>>> ensure that a reasonable answer can be extracted from a given body of
>>>>>> data.
>>>>>> ~ John Tukey
>>>>>>
>>>>>> 2015-10-06 17:15 GMT+02:00 Yizhou Ma <maxxx848 at umn.edu>:
>>>>>>>
>>>>>>> Dear LMM experts:
>>>>>>>
>>>>>>> I am pretty new to using LMM and I have found the following
>>>>>>> situation
>>>>>>> bewildering as I was trying to do diagnostics with my fitted model:
>>>>>>> my
>>>>>>> conditional residuals correlated highly with the fitted values.
>>>>>>>
>>>>>>> I have a dataset with multiple families, each has 1-4 siblings. I am
>>>>>>> trying
>>>>>>> to regress Y onto EVs include Drink, Gender, & Age, while using
>>>>>>> random
>>>>>>> intercept for family. This is the model I used:
>>>>>>> model<-lmer(Y~Drink*Gender+Age
>>>>>>>                       +(1|Family_ID),data,REML=FALSE)
>>>>>>>
>>>>>>> After fitting the model, I used
>>>>>>> plot(model)
>>>>>>> to see the relationship between conditional residuals and fitted
>>>>>>> values. I
>>>>>>> expect them to be uncorrelated and I expect to see homoscedasticity.
>>>>>>>
>>>>>>> Yet to my surprise there is a high correlation (~0.5) between the
>>>>>>> residuals
>>>>>>> and the fitted values. (see here <http://imgur.com/pPsG4aR>). I know
>>>>>>> from
>>>>>>> GLM that this usually suggest nonlinear relationships between the
>>>>>>> EVs
>>>>>>> and
>>>>>>> the DV.
>>>>>>>
>>>>>>> I read some online posts (post1
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> <http://stats.stackexchange.com/questions/43566/strange-pattern-in-residual-plot-from-mixed-effect-model>
>>>>>>> post2
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> <http://stats.stackexchange.com/questions/168179/correlation-between-standardized-residuals-and-fitted-values-in-a-linear-mixed-e/168210#168210>)
>>>>>>> that suggest this can result from a poor model fit. So I tried a few
>>>>>>> different models, including: 1) log transform Drink, which is
>>>>>>> originally
>>>>>>> positively skewed; 2) add random slopes for Drink, Age, etc. None of
>>>>>>> these
>>>>>>> changes have led to a substantial difference for the residual &
>>>>>>> fitted
>>>>>>> value correlation.
>>>>>>>
>>>>>>> Some other info:
>>>>>>> 1) my overall model fit is not poor as indicated by the correlation
>>>>>>> between
>>>>>>> fitted values & Y. It is around 0.8;
>>>>>>> 2) most variables in my model has a normal, or at least symmetrical,
>>>>>>> distribution.
>>>>>>> 3) conditional residuals are normally distributed as shown in
>>>>>>> qqplots.
>>>>>>> 4) conditional residuals are not correlated with any fixed effects,
>>>>>>> such
>>>>>>> as
>>>>>>> Drink or Age.
>>>>>>>
>>>>>>> I have two guesses as to what is going on:
>>>>>>> 1) maybe the fact that each family is a different size actually
>>>>>>> violates
>>>>>>> assumptions of the model?
>>>>>>> 2) or maybe there is something wrong with estimation of the random
>>>>>>> effect
>>>>>>> (family intercept)?
>>>>>>>
>>>>>>> I'd really appreciate your insights as to what is going on here and
>>>>>>> if
>>>>>>> there is any problems with my model.
>>>>>>>
>>>>>>> Thank you very much,
>>>>>>> Cherry
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>>
>>>>
>>>>
>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .
> 
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From wphantomfr at gmail.com  Thu Oct  8 10:59:38 2015
From: wphantomfr at gmail.com (wphantomfr)
Date: Thu, 08 Oct 2015 10:59:38 +0200
Subject: [R-sig-ME] Advise on mixed effect model for a longitudinal study
	(with lme4)
Message-ID: <5616307A.5060906@gmail.com>

Dear list members,

I currently trying to apply mixed effects models to a longitudinal 
studies with a treatment period.

The study is :
Several evaluation of a participants characteristic (let's call it DV) 
at different times (in week) : 0 (1 evaluaition), 1 , 3, 6, 8 10.

We have 3 different groups of participants (randomized controlled study) 
: a control group without treatment and groupA and groupB which received 
a different treatment.

The treatment is applied to the groupA & B during weeks 2-5 therefore :
     - evaluations at w0 and w1 are "baseline measures" (pre-treatment)
     - evaluation at w3 is during treatment
     - evaluation at w6 is post treatment
     - evaluation at w8 & w10 are follow-up evaluation.



After reading a lot on mixed effects model I arrived to the following 
model (using lme4 package):

best_model<-lmer(DV ~ (time+I(time^2))*GROUP 
+(1+(time+I(time^2))|SUBJECT),data=brut)

It includes a quadratic effect of time (continuous variable) and both 
intercept and "slopes" (not a good word for the quadratic par) of the 
effects of time (both linear and quadratic) are estimated for the random 
effects of SUBJECT.

This model seems to be the best compared to models including only parts 
of these terms (model comparison with anova ). The summary report of the 
model is pasted at the end of this message


My hypothesis are :
     - that I should see a superior effect of time in group A & B (if 
the treatment increases DV, I should have a positive coeficient for time 
and a negative coeficient for time^2)
     - that the effect of time may be superior in group B compared to 
group A
     - I would also like to see if one of the treatment have a more 
long-term effect (sustained effect in the foloup evaluations)

     I'm not sure how to test/answer my questions from my model.




My guesses :
- the fact that GROUPA et GROUPB have low t-values is a sign that my 
groups are quite similar at the begining of the study
- The coeficient of time:GROUP(A & B) and I(time^2):group(A&B) are in 
line with my hypothesis
- I don't know how, in this context, I can answer to the question of 
long-term effects...


My questions :

Am I totally wrong ?

How to best assess my hypothesis ?

Any more advises ?


Thanks in advance




Here is the model report :


summary(bestM)
Linear mixed model fit by REML
t-tests use  Satterthwaite approximations to degrees of freedom ['lmerMod']
Formula: DV ~ (time + I(time^2)) * GROUP + (1 + (time + I(time^2)) 
|      SUBJECT)
    Data: brut

REML criterion at convergence: -458.9

Scaled residuals:
     Min      1Q  Median      3Q     Max
-3.1714 -0.3972  0.0660  0.4385  2.7059

Random effects:
  Groups   Name        Variance  Std.Dev. Corr
  SUBJECT  (Intercept) 6.201e-02 0.24902
           time        2.042e-03 0.04519  -0.45
           I(time^2)   1.162e-05 0.00341   0.41 -0.95
  Residual             1.314e-02 0.11462
Number of obs: 710, groups:  CODE, 117

Fixed effects:
                          Estimate Std. Error         df t value Pr(>|t|)
(Intercept)             1.858e-01  4.557e-02  1.140e+02   4.078 8.44e-05 ***
time                    1.960e-03  1.159e-02  1.138e+02   0.169  0.86599
I(time^2)               2.149e-04  1.032e-03  1.137e+02   0.208  0.83547
GROUPA                     -2.006e-02  6.198e-02  1.140e+02  -0.324  
0.74681
GROUPB                    -2.898e-02  6.094e-02  1.138e+02  -0.476  0.63531
time:GROUPA                3.837e-02  1.576e-02  1.138e+02   2.435  
0.01645 *
time:GROUPB                4.212e-02  1.546e-02  1.120e+02   2.724  
0.00748 **
I(time^2):GROUPA        -2.749e-03  1.404e-03  1.137e+02  -1.957  0.05277 .
I(time^2):GROUPB          -3.222e-03  1.377e-03  1.113e+02  -2.340  
0.02108 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
              (Intr) time   I(t^2) GROUPA GROUPB t:GROUPA t:GROUPB 
I(^2):GROUPA
time         -0.467
I(time^2)     0.379 -0.951
GROUPA          -0.735  0.343 -0.279
GROUPB       -0.748  0.349 -0.283  0.550
t:GROUPA      0.343 -0.735  0.699 -0.467 -0.257
t:GROUPB      0.350 -0.749  0.712 -0.257 -0.467  0.551
I(^2):GROUPA -0.279  0.699 -0.735  0.379  0.208 -0.951   -0.524
I(^2):GROUPB -0.284  0.713 -0.750  0.209  0.379 -0.524   -0.951    0.551


	[[alternative HTML version deleted]]


From chirleu at gmail.com  Thu Oct  8 11:47:12 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 8 Oct 2015 11:47:12 +0200
Subject: [R-sig-ME] residual covariance structure and long format data in
	MCMCglmm
Message-ID: <CALC46t8MuJ506aq9SKN+o5u-2AUD-fAwUZYaR5eXEnvYDPAfeA@mail.gmail.com>

Hi all,

I'r trying to run a multivariate MCMCglmm with 3 traits. I was suggested to
use the long format since I have unequal number of replicates per trait.
Trait 1 and 2 were replicated twice, trait 3 was replicated five times.
Traits are gaussian.

The way I measured the trait for each individual is as follows:

day 1: trait1
day 2: trait1 and trait 2
day 3: trait1 and trait 3
day 4: trait1 and trait 2
day 5: trait1 and trait 3

>From the model, I'm interested in extracting the between-individual
variances/covariances and if possible, the within-individual
variances/covariances.

This is my attemp so far. Letter identifies the trait.

mod1=MCMCglmm(value~(letter-1), random=~us(letter):id,
rcov=~idh(letter):xxxx, family=c("gaussian"), data=ALL)

My questions are about the rcov bit, the residual variances/covariances...

- First I don't know if with my experimental design, it makes sense to
estimate residual covariances ("us" structure) or constrain them as in the
model above ("idh" structure)

- Second, I don't know how to define the xxxx variable according to my
experimental design.

I guess both questions are related.

Any advise will be appreciated.

Thanks


David

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Oct  8 13:57:30 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 8 Oct 2015 13:57:30 +0200
Subject: [R-sig-ME] Advise on mixed effect model for a longitudinal
 study (with lme4)
In-Reply-To: <5616307A.5060906@gmail.com>
References: <5616307A.5060906@gmail.com>
Message-ID: <CAJuCY5x7Amz2PeATXXb+1uMm5-X4vbeQn=YY2dQByemi74Lqtw@mail.gmail.com>

Dear anonymous.

Your random effects seem a bit to complicated for your data. A random slope
with 6 observations per subject is pushing the limits. A second degree
polynomial on 6 observations is nonsense. I can understand that is does
make sense on a conceptual level, but you just don't have enough data to
get sensible estimates on such a complex model.

My advice would be to restrict the random effect to just a random
intercept. The benefit is that you gain 5 parameters and their associated
degrees of freedom. Note that a second order polynomial on the fixed effect
might be feasible.

You probably want to translate your hypotheses in a set of linear
combination of model parameters. Then you can test those hypotheses. Have a
look at the examples in the glht() function fom the mulcomp package.

PS Please don't post in HTML. It mangles up the output and code.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-08 10:59 GMT+02:00 wphantomfr <wphantomfr at gmail.com>:

> Dear list members,
>
> I currently trying to apply mixed effects models to a longitudinal
> studies with a treatment period.
>
> The study is :
> Several evaluation of a participants characteristic (let's call it DV)
> at different times (in week) : 0 (1 evaluaition), 1 , 3, 6, 8 10.
>
> We have 3 different groups of participants (randomized controlled study)
> : a control group without treatment and groupA and groupB which received
> a different treatment.
>
> The treatment is applied to the groupA & B during weeks 2-5 therefore :
>      - evaluations at w0 and w1 are "baseline measures" (pre-treatment)
>      - evaluation at w3 is during treatment
>      - evaluation at w6 is post treatment
>      - evaluation at w8 & w10 are follow-up evaluation.
>
>
>
> After reading a lot on mixed effects model I arrived to the following
> model (using lme4 package):
>
> best_model<-lmer(DV ~ (time+I(time^2))*GROUP
> +(1+(time+I(time^2))|SUBJECT),data=brut)
>
> It includes a quadratic effect of time (continuous variable) and both
> intercept and "slopes" (not a good word for the quadratic par) of the
> effects of time (both linear and quadratic) are estimated for the random
> effects of SUBJECT.
>
> This model seems to be the best compared to models including only parts
> of these terms (model comparison with anova ). The summary report of the
> model is pasted at the end of this message
>
>
> My hypothesis are :
>      - that I should see a superior effect of time in group A & B (if
> the treatment increases DV, I should have a positive coeficient for time
> and a negative coeficient for time^2)
>      - that the effect of time may be superior in group B compared to
> group A
>      - I would also like to see if one of the treatment have a more
> long-term effect (sustained effect in the foloup evaluations)
>
>      I'm not sure how to test/answer my questions from my model.
>
>
>
>
> My guesses :
> - the fact that GROUPA et GROUPB have low t-values is a sign that my
> groups are quite similar at the begining of the study
> - The coeficient of time:GROUP(A & B) and I(time^2):group(A&B) are in
> line with my hypothesis
> - I don't know how, in this context, I can answer to the question of
> long-term effects...
>
>
> My questions :
>
> Am I totally wrong ?
>
> How to best assess my hypothesis ?
>
> Any more advises ?
>
>
> Thanks in advance
>
>
>
>
> Here is the model report :
>
>
> summary(bestM)
> Linear mixed model fit by REML
> t-tests use  Satterthwaite approximations to degrees of freedom ['lmerMod']
> Formula: DV ~ (time + I(time^2)) * GROUP + (1 + (time + I(time^2))
> |      SUBJECT)
>     Data: brut
>
> REML criterion at convergence: -458.9
>
> Scaled residuals:
>      Min      1Q  Median      3Q     Max
> -3.1714 -0.3972  0.0660  0.4385  2.7059
>
> Random effects:
>   Groups   Name        Variance  Std.Dev. Corr
>   SUBJECT  (Intercept) 6.201e-02 0.24902
>            time        2.042e-03 0.04519  -0.45
>            I(time^2)   1.162e-05 0.00341   0.41 -0.95
>   Residual             1.314e-02 0.11462
> Number of obs: 710, groups:  CODE, 117
>
> Fixed effects:
>                           Estimate Std. Error         df t value Pr(>|t|)
> (Intercept)             1.858e-01  4.557e-02  1.140e+02   4.078 8.44e-05
> ***
> time                    1.960e-03  1.159e-02  1.138e+02   0.169  0.86599
> I(time^2)               2.149e-04  1.032e-03  1.137e+02   0.208  0.83547
> GROUPA                     -2.006e-02  6.198e-02  1.140e+02  -0.324
> 0.74681
> GROUPB                    -2.898e-02  6.094e-02  1.138e+02  -0.476  0.63531
> time:GROUPA                3.837e-02  1.576e-02  1.138e+02   2.435
> 0.01645 *
> time:GROUPB                4.212e-02  1.546e-02  1.120e+02   2.724
> 0.00748 **
> I(time^2):GROUPA        -2.749e-03  1.404e-03  1.137e+02  -1.957  0.05277 .
> I(time^2):GROUPB          -3.222e-03  1.377e-03  1.113e+02  -2.340
> 0.02108 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>               (Intr) time   I(t^2) GROUPA GROUPB t:GROUPA t:GROUPB
> I(^2):GROUPA
> time         -0.467
> I(time^2)     0.379 -0.951
> GROUPA          -0.735  0.343 -0.279
> GROUPB       -0.748  0.349 -0.283  0.550
> t:GROUPA      0.343 -0.735  0.699 -0.467 -0.257
> t:GROUPB      0.350 -0.749  0.712 -0.257 -0.467  0.551
> I(^2):GROUPA -0.279  0.699 -0.735  0.379  0.208 -0.951   -0.524
> I(^2):GROUPB -0.284  0.713 -0.750  0.209  0.379 -0.524   -0.951    0.551
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From xavier.paoletti at curie.fr  Thu Oct  8 16:03:09 2015
From: xavier.paoletti at curie.fr (xavier.paoletti at curie.fr)
Date: Thu, 8 Oct 2015 16:03:09 +0200
Subject: [R-sig-ME] AUTO : No longer at Institut Curie
Message-ID: <OF9638B018.D479788A-ONC1257ED8.004D319E-C1257ED8.004D319E@curie.net>


Je suis absent(e) du bureau jusqu'au 31/12/2015

I do not work at Curie any more.
For any questions not related to the activity at Curie, you can reach me at
xavier.paoletti at gustaveroussy.fr.
Best regards,

Xavier Paoletti


Remarque?: ceci est une r?ponse automatique ? votre message
"R-sig-mixed-models Digest, Vol 106, Issue 9" envoy? le 08/10/2015 11:00:07
.

C'est la seule notification que vous recevrez pendant l'absence de cette
personne.


L'int?grit? de ce message n'?tant pas assur?e sur Internet, l'Institut Curie ne peut ?tre tenu responsable de son contenu. 
Si vous n'?tes pas destinataire de ce message confidentiel, merci de le d?truire et d'avertir imm?diatement l'exp?diteur.
Afin de contribuer au respect de l'environnement, merci de n'imprimer ce mail qu'en cas de n?cessit?.


From xavier.paoletti at curie.fr  Thu Oct  8 16:03:09 2015
From: xavier.paoletti at curie.fr (xavier.paoletti at curie.fr)
Date: Thu, 8 Oct 2015 16:03:09 +0200
Subject: [R-sig-ME] AUTO : No longer at Institut Curie
Message-ID: <OF3CA59C79.79AED8D8-ONC1257ED8.004D31A4-C1257ED8.004D31A4@curie.net>


Je suis absent(e) du bureau jusqu'au 31/12/2015

I do not work at Curie any more.
For any questions not related to the activity at Curie, you can reach me at
xavier.paoletti at gustaveroussy.fr.
Best regards,

Xavier Paoletti


Remarque?: ceci est une r?ponse automatique ? votre message
"R-sig-mixed-models Digest, Vol 106, Issue 10" envoy? le 08/10/2015
12:00:01.

C'est la seule notification que vous recevrez pendant l'absence de cette
personne.


L'int?grit? de ce message n'?tant pas assur?e sur Internet, l'Institut Curie ne peut ?tre tenu responsable de son contenu. 
Si vous n'?tes pas destinataire de ce message confidentiel, merci de le d?truire et d'avertir imm?diatement l'exp?diteur.
Afin de contribuer au respect de l'environnement, merci de n'imprimer ce mail qu'en cas de n?cessit?.


From wphantomfr at gmail.com  Thu Oct  8 16:12:38 2015
From: wphantomfr at gmail.com (wphantomfr)
Date: Thu, 08 Oct 2015 16:12:38 +0200
Subject: [R-sig-ME] Advise on mixed effect model for a longitudinal
 study (with lme4)
In-Reply-To: <CAJuCY5x7Amz2PeATXXb+1uMm5-X4vbeQn=YY2dQByemi74Lqtw@mail.gmail.com>
References: <5616307A.5060906@gmail.com>
	<CAJuCY5x7Amz2PeATXXb+1uMm5-X4vbeQn=YY2dQByemi74Lqtw@mail.gmail.com>
Message-ID: <561679D6.5090905@gmail.com>

Dear Thierry,

First thanks a lot for taking time to answer me.

Thierry Onkelinx wrote:
> Dear anonymous.
oups.. I forgot to Sign


>
> Your random effects seem a bit to complicated for your data. A random
> slope with 6 observations per subject is pushing the limits. A second
> degree polynomial on 6 observations is nonsense. I can understand that
> is does make sense on a conceptual level, but you just don't have enough
> data to get sensible estimates on such a complex model.
>
> My advice would be to restrict the random effect to just a random
> intercept. The benefit is that you gain 5 parameters and their
> associated degrees of freedom. Note that a second order polynomial on
> the fixed effect might be feasible.

I think I understand the problem but did not realize I was pushing the 
limits doing this because (1) it was making sense to use random slopes 
when looking at the data and (2) I was probably too much focused on the 
results of model comparisons that indicated a better fit for this 
complex model.

But is there a way to know that we are pushing too much the limits ? 
Would only the random intercept + linear slope be acceptable (however 
the linear slope is probably optimal with our design)

>
> You probably want to translate your hypotheses in a set of linear
> combination of model parameters. Then you can test those hypotheses.
> Have a look at the examples in the glht() function fom the mulcomp package.

Well that's exactly that... I just didn't realise that glht could work 
with lme models
>
> PS Please don't post in HTML. It mangles up the output and code.
sorry. I think I have now disabled the default HTML mode.


Thank you very much for your help !

Sylvain CLEMENT
PSITEC (EA 4072) laboratory
"Neuropsychologie : Audition, Cognition, Action (NACA)" team
University of Lille, France.


>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
>
> 2015-10-08 10:59 GMT+02:00 wphantomfr <wphantomfr at gmail.com
> <mailto:wphantomfr at gmail.com>>:
>
>     Dear list members,
>
>     I currently trying to apply mixed effects models to a longitudinal
>     studies with a treatment period.
>
>     The study is :
>     Several evaluation of a participants characteristic (let's call it DV)
>     at different times (in week) : 0 (1 evaluaition), 1 , 3, 6, 8 10.
>
>     We have 3 different groups of participants (randomized controlled study)
>     : a control group without treatment and groupA and groupB which received
>     a different treatment.
>
>     The treatment is applied to the groupA & B during weeks 2-5 therefore :
>           - evaluations at w0 and w1 are "baseline measures" (pre-treatment)
>           - evaluation at w3 is during treatment
>           - evaluation at w6 is post treatment
>           - evaluation at w8 & w10 are follow-up evaluation.
>
>
>
>     After reading a lot on mixed effects model I arrived to the following
>     model (using lme4 package):
>
>     best_model<-lmer(DV ~ (time+I(time^2))*GROUP
>     +(1+(time+I(time^2))|SUBJECT),data=brut)
>
>     It includes a quadratic effect of time (continuous variable) and both
>     intercept and "slopes" (not a good word for the quadratic par) of the
>     effects of time (both linear and quadratic) are estimated for the random
>     effects of SUBJECT.
>
>     This model seems to be the best compared to models including only parts
>     of these terms (model comparison with anova ). The summary report of the
>     model is pasted at the end of this message
>
>
>     My hypothesis are :
>           - that I should see a superior effect of time in group A & B (if
>     the treatment increases DV, I should have a positive coeficient for time
>     and a negative coeficient for time^2)
>           - that the effect of time may be superior in group B compared to
>     group A
>           - I would also like to see if one of the treatment have a more
>     long-term effect (sustained effect in the foloup evaluations)
>
>           I'm not sure how to test/answer my questions from my model.
>
>
>
>
>     My guesses :
>     - the fact that GROUPA et GROUPB have low t-values is a sign that my
>     groups are quite similar at the begining of the study
>     - The coeficient of time:GROUP(A & B) and I(time^2):group(A&B) are in
>     line with my hypothesis
>     - I don't know how, in this context, I can answer to the question of
>     long-term effects...
>
>
>     My questions :
>
>     Am I totally wrong ?
>
>     How to best assess my hypothesis ?
>
>     Any more advises ?
>
>
>     Thanks in advance
>
>
>
>
>     Here is the model report :
>
>
>     summary(bestM)
>     Linear mixed model fit by REML
>     t-tests use  Satterthwaite approximations to degrees of freedom
>     ['lmerMod']
>     Formula: DV ~ (time + I(time^2)) * GROUP + (1 + (time + I(time^2))
>     |      SUBJECT)
>          Data: brut
>
>     REML criterion at convergence: -458.9
>
>     Scaled residuals:
>           Min      1Q  Median      3Q     Max
>     -3.1714 -0.3972  0.0660  0.4385  2.7059
>
>     Random effects:
>        Groups   Name        Variance  Std.Dev. Corr
>        SUBJECT  (Intercept) 6.201e-02 0.24902
>                 time        2.042e-03 0.04519  -0.45
>                 I(time^2)   1.162e-05 0.00341   0.41 -0.95
>        Residual             1.314e-02 0.11462
>     Number of obs: 710, groups:  CODE, 117
>
>     Fixed effects:
>                                Estimate Std. Error         df t value
>     Pr(>|t|)
>     (Intercept)             1.858e-01  4.557e-02  1.140e+02   4.078
>     8.44e-05 ***
>     time                    1.960e-03  1.159e-02  1.138e+02   0.169  0.86599
>     I(time^2)               2.149e-04  1.032e-03  1.137e+02   0.208  0.83547
>     GROUPA                     -2.006e-02  6.198e-02  1.140e+02  -0.324
>     0.74681
>     GROUPB                    -2.898e-02  6.094e-02  1.138e+02  -0.476
>     0.63531
>     time:GROUPA                3.837e-02  1.576e-02  1.138e+02   2.435
>     0.01645 *
>     time:GROUPB                4.212e-02  1.546e-02  1.120e+02   2.724
>     0.00748 **
>     I(time^2):GROUPA        -2.749e-03  1.404e-03  1.137e+02  -1.957
>     0.05277 .
>     I(time^2):GROUPB          -3.222e-03  1.377e-03  1.113e+02  -2.340
>     0.02108 *
>     ---
>     Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>     Correlation of Fixed Effects:
>                    (Intr) time   I(t^2) GROUPA GROUPB t:GROUPA t:GROUPB
>     I(^2):GROUPA
>     time         -0.467
>     I(time^2)     0.379 -0.951
>     GROUPA          -0.735  0.343 -0.279
>     GROUPB       -0.748  0.349 -0.283  0.550
>     t:GROUPA      0.343 -0.735  0.699 -0.467 -0.257
>     t:GROUPB      0.350 -0.749  0.712 -0.257 -0.467  0.551
>     I(^2):GROUPA -0.279  0.699 -0.735  0.379  0.208 -0.951   -0.524
>     I(^2):GROUPB -0.284  0.713 -0.750  0.209  0.379 -0.524   -0.951    0.551
>
>
>              [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From j.hadfield at ed.ac.uk  Thu Oct  8 17:27:09 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 08 Oct 2015 16:27:09 +0100
Subject: [R-sig-ME] residual covariance structure and long format data
 in MCMCglmm
In-Reply-To: <CALC46t8MuJ506aq9SKN+o5u-2AUD-fAwUZYaR5eXEnvYDPAfeA@mail.gmail.com>
References: <CALC46t8MuJ506aq9SKN+o5u-2AUD-fAwUZYaR5eXEnvYDPAfeA@mail.gmail.com>
Message-ID: <20151008162709.13833ufod5icqdkw@www.staffmail.ed.ac.uk>

Hi,

The appropriate residual syntax would be:

rcov=~idh(letter):day

although I would estimate the residual covariances, given that you  
assume the individual-level random effects for the three traits can be  
correlated.

However, this raises an issue because trait 2 and trait 3 have never  
been measured on the same individual on the same day and so you cannot  
estimate their residual covariance. The covariance matrix looks like:

   x x x
   x x 0
   x 0 x

where I have x's for things that can be estimated and 0 for the things  
that cannot. Older versions of MCMCglmm didn't allow you to fit this  
type of constraint (i.e. in the absence of information fix the  
unidentifiable covariance to zero). However, you can trick it into  
doing this using an antedependence model. Reorder your traits so trait  
1 is last, and so the constraint you want is:

   x 0 x
   0 x x
   x x x

Then fit a second order autoregressive model:

rcov=~ante2(letter):day

and fix the regression of trait 3 on trait 2 to be zero (with the new  
ordering this would be 2 on 1, i.e. the first regression coefficient).

prior$R<-list(V=diag(3), nu=0, beta.mu=rep(0,3), beta.V=diag(3)*100)
prior$R$beta.V[1,1]<-1e-8

To see why this works, define the matrix B where B[i,j] is the  
regression of j on i. In this case B has the form:

   .  .  .
   0  .  .
   x  x  .

where 0 is the regression coefficient set to zero, and . are  
regression coefficients that are zero by design in an antependence  
model.  The residual covariance matrix has the same sparse structure  
as solve(I-B)%*%t(solve(I-B)) which is

   x 0 x
   0 x x
   x x x

as desired. I believe (could be wrong, so it would be good to get  
confirmation) that the only other constraint imposed on the x's is  
that they result in a positive definite matrix irrespective of the  
true value of the covariance between trait 2 and trait 3.

Note that MCMCglmm will return the residual covariance matrix. If you  
want the matrix in terms of regression coefficients (and innovation  
variances) you can use posterior.ante(mod1$VCV[,9:18], k=2).

Note that you may want to increase/decrease the prior variance on the  
identifiable regression coefficients depending on scale, and you may  
not want flat improper priors on the innovation variances.

Cheers,

Jarrod













Quoting David Villegas R?os <chirleu at gmail.com> on Thu, 8 Oct 2015  
11:47:12 +0200:

> Hi all,
>
> I'r trying to run a multivariate MCMCglmm with 3 traits. I was suggested to
> use the long format since I have unequal number of replicates per trait.
> Trait 1 and 2 were replicated twice, trait 3 was replicated five times.
> Traits are gaussian.
>
> The way I measured the trait for each individual is as follows:
>
> day 1: trait1
> day 2: trait1 and trait 2
> day 3: trait1 and trait 3
> day 4: trait1 and trait 2
> day 5: trait1 and trait 3
>
>> From the model, I'm interested in extracting the between-individual
> variances/covariances and if possible, the within-individual
> variances/covariances.
>
> This is my attemp so far. Letter identifies the trait.
>
> mod1=MCMCglmm(value~(letter-1), random=~us(letter):id,
> rcov=~idh(letter):xxxx, family=c("gaussian"), data=ALL)
>
> My questions are about the rcov bit, the residual variances/covariances...
>
> - First I don't know if with my experimental design, it makes sense to
> estimate residual covariances ("us" structure) or constrain them as in the
> model above ("idh" structure)
>
> - Second, I don't know how to define the xxxx variable according to my
> experimental design.
>
> I guess both questions are related.
>
> Any advise will be appreciated.
>
> Thanks
>
>
> David
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From thierry.onkelinx at inbo.be  Fri Oct  9 10:05:31 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 9 Oct 2015 10:05:31 +0200
Subject: [R-sig-ME] Advise on mixed effect model for a longitudinal
 study (with lme4)
In-Reply-To: <561679D6.5090905@gmail.com>
References: <5616307A.5060906@gmail.com>
	<CAJuCY5x7Amz2PeATXXb+1uMm5-X4vbeQn=YY2dQByemi74Lqtw@mail.gmail.com>
	<561679D6.5090905@gmail.com>
Message-ID: <CAJuCY5yoycDhGp7Y8+caZ+6bfqK0a3yv+o8Fg4k6h5m=19ue5w@mail.gmail.com>

Dear Sylvain,

You can look at ratio of the number of effective observations and the
number of parameters. The number of effective observations depend on the
distribution: Gaussian = number of observations, Poisson = number of non
zero observations, binomial = min(number absences, number presences). A
common rule of thumb is to have at least 10 effective observations per
parameter.

Best regards,



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-08 16:12 GMT+02:00 wphantomfr <wphantomfr at gmail.com>:

> Dear Thierry,
>
> First thanks a lot for taking time to answer me.
>
> Thierry Onkelinx wrote:
>
>> Dear anonymous.
>>
> oups.. I forgot to Sign
>
>
>
>> Your random effects seem a bit to complicated for your data. A random
>> slope with 6 observations per subject is pushing the limits. A second
>> degree polynomial on 6 observations is nonsense. I can understand that
>> is does make sense on a conceptual level, but you just don't have enough
>> data to get sensible estimates on such a complex model.
>>
>> My advice would be to restrict the random effect to just a random
>> intercept. The benefit is that you gain 5 parameters and their
>> associated degrees of freedom. Note that a second order polynomial on
>> the fixed effect might be feasible.
>>
>
> I think I understand the problem but did not realize I was pushing the
> limits doing this because (1) it was making sense to use random slopes when
> looking at the data and (2) I was probably too much focused on the results
> of model comparisons that indicated a better fit for this complex model.
>
> But is there a way to know that we are pushing too much the limits ? Would
> only the random intercept + linear slope be acceptable (however the linear
> slope is probably optimal with our design)
>
>
>> You probably want to translate your hypotheses in a set of linear
>> combination of model parameters. Then you can test those hypotheses.
>> Have a look at the examples in the glht() function fom the mulcomp
>> package.
>>
>
> Well that's exactly that... I just didn't realise that glht could work
> with lme models
>
>>
>> PS Please don't post in HTML. It mangles up the output and code.
>>
> sorry. I think I have now disabled the default HTML mode.
>
>
> Thank you very much for your help !
>
> Sylvain CLEMENT
> PSITEC (EA 4072) laboratory
> "Neuropsychologie : Audition, Cognition, Action (NACA)" team
> University of Lille, France.
>
>
>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data. ~ John Tukey
>>
>> 2015-10-08 10:59 GMT+02:00 wphantomfr <wphantomfr at gmail.com
>> <mailto:wphantomfr at gmail.com>>:
>>
>>
>>     Dear list members,
>>
>>     I currently trying to apply mixed effects models to a longitudinal
>>     studies with a treatment period.
>>
>>     The study is :
>>     Several evaluation of a participants characteristic (let's call it DV)
>>     at different times (in week) : 0 (1 evaluaition), 1 , 3, 6, 8 10.
>>
>>     We have 3 different groups of participants (randomized controlled
>> study)
>>     : a control group without treatment and groupA and groupB which
>> received
>>     a different treatment.
>>
>>     The treatment is applied to the groupA & B during weeks 2-5 therefore
>> :
>>           - evaluations at w0 and w1 are "baseline measures"
>> (pre-treatment)
>>           - evaluation at w3 is during treatment
>>           - evaluation at w6 is post treatment
>>           - evaluation at w8 & w10 are follow-up evaluation.
>>
>>
>>
>>     After reading a lot on mixed effects model I arrived to the following
>>     model (using lme4 package):
>>
>>     best_model<-lmer(DV ~ (time+I(time^2))*GROUP
>>     +(1+(time+I(time^2))|SUBJECT),data=brut)
>>
>>     It includes a quadratic effect of time (continuous variable) and both
>>     intercept and "slopes" (not a good word for the quadratic par) of the
>>     effects of time (both linear and quadratic) are estimated for the
>> random
>>     effects of SUBJECT.
>>
>>     This model seems to be the best compared to models including only
>> parts
>>     of these terms (model comparison with anova ). The summary report of
>> the
>>     model is pasted at the end of this message
>>
>>
>>     My hypothesis are :
>>           - that I should see a superior effect of time in group A & B (if
>>     the treatment increases DV, I should have a positive coeficient for
>> time
>>     and a negative coeficient for time^2)
>>           - that the effect of time may be superior in group B compared to
>>     group A
>>           - I would also like to see if one of the treatment have a more
>>     long-term effect (sustained effect in the foloup evaluations)
>>
>>           I'm not sure how to test/answer my questions from my model.
>>
>>
>>
>>
>>     My guesses :
>>     - the fact that GROUPA et GROUPB have low t-values is a sign that my
>>     groups are quite similar at the begining of the study
>>     - The coeficient of time:GROUP(A & B) and I(time^2):group(A&B) are in
>>     line with my hypothesis
>>     - I don't know how, in this context, I can answer to the question of
>>     long-term effects...
>>
>>
>>     My questions :
>>
>>     Am I totally wrong ?
>>
>>     How to best assess my hypothesis ?
>>
>>     Any more advises ?
>>
>>
>>     Thanks in advance
>>
>>
>>
>>
>>     Here is the model report :
>>
>>
>>     summary(bestM)
>>     Linear mixed model fit by REML
>>     t-tests use  Satterthwaite approximations to degrees of freedom
>>     ['lmerMod']
>>     Formula: DV ~ (time + I(time^2)) * GROUP + (1 + (time + I(time^2))
>>     |      SUBJECT)
>>          Data: brut
>>
>>     REML criterion at convergence: -458.9
>>
>>     Scaled residuals:
>>           Min      1Q  Median      3Q     Max
>>     -3.1714 -0.3972  0.0660  0.4385  2.7059
>>
>>     Random effects:
>>        Groups   Name        Variance  Std.Dev. Corr
>>        SUBJECT  (Intercept) 6.201e-02 0.24902
>>                 time        2.042e-03 0.04519  -0.45
>>                 I(time^2)   1.162e-05 0.00341   0.41 -0.95
>>        Residual             1.314e-02 0.11462
>>     Number of obs: 710, groups:  CODE, 117
>>
>>     Fixed effects:
>>                                Estimate Std. Error         df t value
>>     Pr(>|t|)
>>     (Intercept)             1.858e-01  4.557e-02  1.140e+02   4.078
>>     8.44e-05 ***
>>     time                    1.960e-03  1.159e-02  1.138e+02   0.169
>> 0.86599
>>     I(time^2)               2.149e-04  1.032e-03  1.137e+02   0.208
>> 0.83547
>>     GROUPA                     -2.006e-02  6.198e-02  1.140e+02  -0.324
>>     0.74681
>>     GROUPB                    -2.898e-02  6.094e-02  1.138e+02  -0.476
>>     0.63531
>>     time:GROUPA                3.837e-02  1.576e-02  1.138e+02   2.435
>>     0.01645 *
>>     time:GROUPB                4.212e-02  1.546e-02  1.120e+02   2.724
>>     0.00748 **
>>     I(time^2):GROUPA        -2.749e-03  1.404e-03  1.137e+02  -1.957
>>     0.05277 .
>>     I(time^2):GROUPB          -3.222e-03  1.377e-03  1.113e+02  -2.340
>>     0.02108 *
>>     ---
>>     Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>     Correlation of Fixed Effects:
>>                    (Intr) time   I(t^2) GROUPA GROUPB t:GROUPA t:GROUPB
>>     I(^2):GROUPA
>>     time         -0.467
>>     I(time^2)     0.379 -0.951
>>     GROUPA          -0.735  0.343 -0.279
>>     GROUPB       -0.748  0.349 -0.283  0.550
>>     t:GROUPA      0.343 -0.735  0.699 -0.467 -0.257
>>     t:GROUPB      0.350 -0.749  0.712 -0.257 -0.467  0.551
>>     I(^2):GROUPA -0.279  0.699 -0.735  0.379  0.208 -0.951   -0.524
>>     I(^2):GROUPB -0.284  0.713 -0.750  0.209  0.379 -0.524   -0.951
>> 0.551
>>
>>
>>              [[alternative HTML version deleted]]
>>
>>     _______________________________________________
>>     R-sig-mixed-models at r-project.org
>>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Fri Oct  9 10:24:00 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Fri, 9 Oct 2015 10:24:00 +0200
Subject: [R-sig-ME] residual covariance structure and long format data
	in MCMCglmm
In-Reply-To: <20151008162709.13833ufod5icqdkw@www.staffmail.ed.ac.uk>
References: <CALC46t8MuJ506aq9SKN+o5u-2AUD-fAwUZYaR5eXEnvYDPAfeA@mail.gmail.com>
	<20151008162709.13833ufod5icqdkw@www.staffmail.ed.ac.uk>
Message-ID: <CALC46t-WrfwByHfAQ7jrufAYnPth6-SDov+pnWE7ZfwsCV1ySg@mail.gmail.com>

Thanks Jarrod, this seems exactly what I need.
I'm trying to implement it now, but for some reason I get an error

prior$R<-list(V=diag(3), nu=0, beta.mu=rep(0,3), beta.V=diag(3)*100)
prior$R$beta.V[1,1]<-1e-8

mod1=MCMCglmm(value~(letter-1), random=~us(letter):id,
rcov=~ante2(letter):day,family="gaussian", data=ALL2,
nitt=510000,burnin=10000, thin=500,verbose=FALSE, prior=prior,pr=TRUE)

Error in MCMCglmm(value ~ (letter - 1), random = ~us(letter):id, rcov =
~ante2(letter):day,  :
  R-structure miss-specified: each residual must be unique to a data point

An example of the data for two individuals:

    id       value      letter day
1  379 -0.52909133      mirror   2
2  379 -0.36287842      mirror   4
3  379 -0.43505872 exploration   1
4  379 -0.31524632 exploration   4
5  379 -1.12034977    boldness   5
6  379 -0.15906279 exploration   5
7  379 -0.50567659    boldness   3
8  379 -0.51900960 exploration   3
9  379  0.03790821 exploration   2
10 380 -0.18712819      mirror   2
11 380 -0.05894661 exploration   5
12 380 -0.77426854      mirror   4
13 380 -0.61255224 exploration   4
14 380 -0.65062409 exploration   3
15 380 -0.06765472 exploration   2
16 380 -0.21452781 exploration   1
17 380 -0.72320719    boldness   3
18 380 -0.41338280    boldness   5

Can you see where the error comes from?

Thanks

2015-10-08 17:27 GMT+02:00 Jarrod Hadfield <j.hadfield at ed.ac.uk>:

> Hi,
>
> The appropriate residual syntax would be:
>
> rcov=~idh(letter):day
>
> although I would estimate the residual covariances, given that you assume
> the individual-level random effects for the three traits can be correlated.
>
> However, this raises an issue because trait 2 and trait 3 have never been
> measured on the same individual on the same day and so you cannot estimate
> their residual covariance. The covariance matrix looks like:
>
>   x x x
>   x x 0
>   x 0 x
>
> where I have x's for things that can be estimated and 0 for the things
> that cannot. Older versions of MCMCglmm didn't allow you to fit this type
> of constraint (i.e. in the absence of information fix the unidentifiable
> covariance to zero). However, you can trick it into doing this using an
> antedependence model. Reorder your traits so trait 1 is last, and so the
> constraint you want is:
>
>   x 0 x
>   0 x x
>   x x x
>
> Then fit a second order autoregressive model:
>
> rcov=~ante2(letter):day
>
> and fix the regression of trait 3 on trait 2 to be zero (with the new
> ordering this would be 2 on 1, i.e. the first regression coefficient).
>
> prior$R<-list(V=diag(3), nu=0, beta.mu=rep(0,3), beta.V=diag(3)*100)
> prior$R$beta.V[1,1]<-1e-8
>
> To see why this works, define the matrix B where B[i,j] is the regression
> of j on i. In this case B has the form:
>
>   .  .  .
>   0  .  .
>   x  x  .
>
> where 0 is the regression coefficient set to zero, and . are regression
> coefficients that are zero by design in an antependence model.  The
> residual covariance matrix has the same sparse structure as
> solve(I-B)%*%t(solve(I-B)) which is
>
>   x 0 x
>   0 x x
>   x x x
>
> as desired. I believe (could be wrong, so it would be good to get
> confirmation) that the only other constraint imposed on the x's is that
> they result in a positive definite matrix irrespective of the true value of
> the covariance between trait 2 and trait 3.
>
> Note that MCMCglmm will return the residual covariance matrix. If you want
> the matrix in terms of regression coefficients (and innovation variances)
> you can use posterior.ante(mod1$VCV[,9:18], k=2).
>
> Note that you may want to increase/decrease the prior variance on the
> identifiable regression coefficients depending on scale, and you may not
> want flat improper priors on the innovation variances.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> Quoting David Villegas R?os <chirleu at gmail.com> on Thu, 8 Oct 2015
> 11:47:12 +0200:
>
> Hi all,
>>
>> I'r trying to run a multivariate MCMCglmm with 3 traits. I was suggested
>> to
>> use the long format since I have unequal number of replicates per trait.
>> Trait 1 and 2 were replicated twice, trait 3 was replicated five times.
>> Traits are gaussian.
>>
>> The way I measured the trait for each individual is as follows:
>>
>> day 1: trait1
>> day 2: trait1 and trait 2
>> day 3: trait1 and trait 3
>> day 4: trait1 and trait 2
>> day 5: trait1 and trait 3
>>
>> From the model, I'm interested in extracting the between-individual
>>>
>> variances/covariances and if possible, the within-individual
>> variances/covariances.
>>
>> This is my attemp so far. Letter identifies the trait.
>>
>> mod1=MCMCglmm(value~(letter-1), random=~us(letter):id,
>> rcov=~idh(letter):xxxx, family=c("gaussian"), data=ALL)
>>
>> My questions are about the rcov bit, the residual variances/covariances...
>>
>> - First I don't know if with my experimental design, it makes sense to
>> estimate residual covariances ("us" structure) or constrain them as in the
>> model above ("idh" structure)
>>
>> - Second, I don't know how to define the xxxx variable according to my
>> experimental design.
>>
>> I guess both questions are related.
>>
>> Any advise will be appreciated.
>>
>> Thanks
>>
>>
>> David
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Fri Oct  9 10:29:20 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 09 Oct 2015 09:29:20 +0100
Subject: [R-sig-ME] residual covariance structure and long format data
 in MCMCglmm
In-Reply-To: <CALC46t-WrfwByHfAQ7jrufAYnPth6-SDov+pnWE7ZfwsCV1ySg@mail.gmail.com>
References: <CALC46t8MuJ506aq9SKN+o5u-2AUD-fAwUZYaR5eXEnvYDPAfeA@mail.gmail.com>
	<20151008162709.13833ufod5icqdkw@www.staffmail.ed.ac.uk>
	<CALC46t-WrfwByHfAQ7jrufAYnPth6-SDov+pnWE7ZfwsCV1ySg@mail.gmail.com>
Message-ID: <20151009092920.12897f5eunr176kg@www.staffmail.ed.ac.uk>

Hi David,

My fault. It should be ante2(letter):day:id.

Cheers,

Jarrod



Quoting David Villegas R?os <chirleu at gmail.com> on Fri, 9 Oct 2015  
10:24:00 +0200:

> Thanks Jarrod, this seems exactly what I need.
> I'm trying to implement it now, but for some reason I get an error
>
> prior$R<-list(V=diag(3), nu=0, beta.mu=rep(0,3), beta.V=diag(3)*100)
> prior$R$beta.V[1,1]<-1e-8
>
> mod1=MCMCglmm(value~(letter-1), random=~us(letter):id,
> rcov=~ante2(letter):day,family="gaussian", data=ALL2,
> nitt=510000,burnin=10000, thin=500,verbose=FALSE, prior=prior,pr=TRUE)
>
> Error in MCMCglmm(value ~ (letter - 1), random = ~us(letter):id, rcov =
> ~ante2(letter):day,  :
>   R-structure miss-specified: each residual must be unique to a data point
>
> An example of the data for two individuals:
>
>     id       value      letter day
> 1  379 -0.52909133      mirror   2
> 2  379 -0.36287842      mirror   4
> 3  379 -0.43505872 exploration   1
> 4  379 -0.31524632 exploration   4
> 5  379 -1.12034977    boldness   5
> 6  379 -0.15906279 exploration   5
> 7  379 -0.50567659    boldness   3
> 8  379 -0.51900960 exploration   3
> 9  379  0.03790821 exploration   2
> 10 380 -0.18712819      mirror   2
> 11 380 -0.05894661 exploration   5
> 12 380 -0.77426854      mirror   4
> 13 380 -0.61255224 exploration   4
> 14 380 -0.65062409 exploration   3
> 15 380 -0.06765472 exploration   2
> 16 380 -0.21452781 exploration   1
> 17 380 -0.72320719    boldness   3
> 18 380 -0.41338280    boldness   5
>
> Can you see where the error comes from?
>
> Thanks
>
> 2015-10-08 17:27 GMT+02:00 Jarrod Hadfield <j.hadfield at ed.ac.uk>:
>
>> Hi,
>>
>> The appropriate residual syntax would be:
>>
>> rcov=~idh(letter):day
>>
>> although I would estimate the residual covariances, given that you assume
>> the individual-level random effects for the three traits can be correlated.
>>
>> However, this raises an issue because trait 2 and trait 3 have never been
>> measured on the same individual on the same day and so you cannot estimate
>> their residual covariance. The covariance matrix looks like:
>>
>>   x x x
>>   x x 0
>>   x 0 x
>>
>> where I have x's for things that can be estimated and 0 for the things
>> that cannot. Older versions of MCMCglmm didn't allow you to fit this type
>> of constraint (i.e. in the absence of information fix the unidentifiable
>> covariance to zero). However, you can trick it into doing this using an
>> antedependence model. Reorder your traits so trait 1 is last, and so the
>> constraint you want is:
>>
>>   x 0 x
>>   0 x x
>>   x x x
>>
>> Then fit a second order autoregressive model:
>>
>> rcov=~ante2(letter):day
>>
>> and fix the regression of trait 3 on trait 2 to be zero (with the new
>> ordering this would be 2 on 1, i.e. the first regression coefficient).
>>
>> prior$R<-list(V=diag(3), nu=0, beta.mu=rep(0,3), beta.V=diag(3)*100)
>> prior$R$beta.V[1,1]<-1e-8
>>
>> To see why this works, define the matrix B where B[i,j] is the regression
>> of j on i. In this case B has the form:
>>
>>   .  .  .
>>   0  .  .
>>   x  x  .
>>
>> where 0 is the regression coefficient set to zero, and . are regression
>> coefficients that are zero by design in an antependence model.  The
>> residual covariance matrix has the same sparse structure as
>> solve(I-B)%*%t(solve(I-B)) which is
>>
>>   x 0 x
>>   0 x x
>>   x x x
>>
>> as desired. I believe (could be wrong, so it would be good to get
>> confirmation) that the only other constraint imposed on the x's is that
>> they result in a positive definite matrix irrespective of the true value of
>> the covariance between trait 2 and trait 3.
>>
>> Note that MCMCglmm will return the residual covariance matrix. If you want
>> the matrix in terms of regression coefficients (and innovation variances)
>> you can use posterior.ante(mod1$VCV[,9:18], k=2).
>>
>> Note that you may want to increase/decrease the prior variance on the
>> identifiable regression coefficients depending on scale, and you may not
>> want flat improper priors on the innovation variances.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Quoting David Villegas R?os <chirleu at gmail.com> on Thu, 8 Oct 2015
>> 11:47:12 +0200:
>>
>> Hi all,
>>>
>>> I'r trying to run a multivariate MCMCglmm with 3 traits. I was suggested
>>> to
>>> use the long format since I have unequal number of replicates per trait.
>>> Trait 1 and 2 were replicated twice, trait 3 was replicated five times.
>>> Traits are gaussian.
>>>
>>> The way I measured the trait for each individual is as follows:
>>>
>>> day 1: trait1
>>> day 2: trait1 and trait 2
>>> day 3: trait1 and trait 3
>>> day 4: trait1 and trait 2
>>> day 5: trait1 and trait 3
>>>
>>> From the model, I'm interested in extracting the between-individual
>>>>
>>> variances/covariances and if possible, the within-individual
>>> variances/covariances.
>>>
>>> This is my attemp so far. Letter identifies the trait.
>>>
>>> mod1=MCMCglmm(value~(letter-1), random=~us(letter):id,
>>> rcov=~idh(letter):xxxx, family=c("gaussian"), data=ALL)
>>>
>>> My questions are about the rcov bit, the residual variances/covariances...
>>>
>>> - First I don't know if with my experimental design, it makes sense to
>>> estimate residual covariances ("us" structure) or constrain them as in the
>>> model above ("idh" structure)
>>>
>>> - Second, I don't know how to define the xxxx variable according to my
>>> experimental design.
>>>
>>> I guess both questions are related.
>>>
>>> Any advise will be appreciated.
>>>
>>> Thanks
>>>
>>>
>>> David
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From heffner at umd.edu  Fri Oct  9 20:58:49 2015
From: heffner at umd.edu (Chris Heffner)
Date: Fri, 09 Oct 2015 18:58:49 +0000
Subject: [R-sig-ME] Convergence Error: 0 Fixed Correlations and More
In-Reply-To: <CABghstQ6Qx1XxdMDLYZEJTUPMQRwna1BwTt7LE_RYx7XyA8bzw@mail.gmail.com>
References: <CA+6pzmdcRW7Yx_RgvuSSR3kTFUPz2AeSep2x50_r-LpCXH0tfA@mail.gmail.com>
	<CAJuCY5zh0VwzUPU+3HVPy_oKeKUNaYf+yziLWzdqyQPGS9egEA@mail.gmail.com>
	<CABghstQ6Qx1XxdMDLYZEJTUPMQRwna1BwTt7LE_RYx7XyA8bzw@mail.gmail.com>
Message-ID: <CA+6pzmdwepRGZMUyQf_EJftrdmwwff40ofZ4QpzgVxMe9HZsaw@mail.gmail.com>

Hello all,

Just wanted to update in case anyone else has a similar problem in the
future.  I got some input off the listserv to remove any items/participants
with a proportion of responses either uniformly at 0% or at 100% across all
conditions, which was true for a couple of my items.  I went ahead and did
that, and it fixed all of my convergence issues.  Ben's description of how
to suppress the correlations between random effects were right on; the
exact syntax was actually (0 + dummy(factorC,"S") | item), but they worked
like a charm.

Thanks all for all of your input,

Chris

On Tue, Sep 22, 2015 at 9:40 AM Ben Bolker <bbolker at gmail.com> wrote:

> On Tue, Sep 22, 2015 at 3:33 AM, Thierry Onkelinx
> <thierry.onkelinx at inbo.be> wrote:
> > Dear Chris,
> >
> > The correct syntax is (1 + FactorC | item) not (1 + FactorC || item).
> > Use a single |. I find the item.1 strange in the output. This might be
> > due to the syntax error.
>
>    Chris might be trying to suppress the correlations between
> random-effect component:
> the double-bar notation expands to (1|item) + (0 + FactorC | item),
> but there's a problem here: there's not *really* a way to do this with the
> double-bar syntax.  If FactorC has two levels (B and S), then the
> right (tedious)
> way to do this is
>
> ( 1|item)+(0+dummy(FactorC,"C")|item)
>
> or maybe (?)
>
> (0+dummy(FactorC,"C")|item)(0+dummy(FactorC,"C")|item)
>
>
>
> (I think the current model is overparameterized)
>
> >
> > The item random effect variances are quit high. You might have a
> > problem of quasi-complete separation. (1 + FactorC | item) might be
> > too complex for your data. Does (1 | item) converge?
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
>
>
>   [snip]
>
> >
> >
> > 2015-09-21 18:37 GMT+02:00 Chris Heffner <heffner at umd.edu>:
> >> Hi,
> >>
> >> I'm running a psychology experiment with a few fixed effects and random
> >> factors, but for some of the models that I'm comparing I get an output
> that
> >> looks something like this:
> >>
> >> Generalized linear mixed model fit by maximum likelihood (Laplace
> >> Approximation) ['glmerMod']
> >>  Family: binomial  ( logit )
> >> Formula: FW ~ FactorA + FactorB + FactorC + FactorA:FactorC +
> >> FactorB:FactorC +      (1 | participant) + (1 + FactorC || item)
> >>    Data: east.acc1.subset
> >> Control: glmerControl(optCtrl = list(maxfun = 30000))
> >>
> >>      AIC      BIC   logLik deviance df.resid
> >>   1001.5   1066.9   -487.7    975.5     1120
> >>
> >> Scaled residuals:
> >>     Min      1Q  Median      3Q     Max
> >> -3.8335 -0.3041  0.1416  0.3566  2.8851
> >>
> >> Random effects:
> >>  Groups      Name        Variance  Std.Dev.  Corr
> >>  item     FactorCB       5.454e+00 2.3352985
> >>              FactorCS       3.097e+00 1.7597629 -0.81
> >>  item.1   (Intercept) 5.437e+00 2.3316731
> >>  participant (Intercept) 2.595e-08 0.0001611
> >> Number of obs: 1133, groups:  item, 55; participant, 23
> >>
> >> (Intercept)            0.1928833  0.0006222   310.0   <2e-16 ***
> >> FactorAInitial        1.8077886  0.0006222  2905.5   <2e-16 ***
> >> FactorB150        -0.4506653  0.0006220  -724.5   <2e-16 ***
> >> FactorB200        -0.5485114  0.0006220  -881.9   <2e-16 ***
> >> FactorCS                 -0.3923921  0.0006221  -630.8   <2e-16 ***
> >> FactorAInitial:FactorCS -0.0889474  0.0006221  -143.0   <2e-16 ***
> >> FactorB150:FactorCS   0.1347207  0.0006221   216.6   <2e-16 ***
> >> FactorB200:FactorCS   0.0682518  0.0006221   109.7   <2e-16 ***
> >> ---
> >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>
> >> Correlation of Fixed Effects:
> >>             (Intr) FAIn FB150 FB200 FCS FAI:FCS FB150:FCS
> >> FAIntl 0.000
> >> FB150 0.000  0.000
> >> FB200 0.000  0.000  0.000
> >> FCS       0.000  0.000  0.000  0.000
> >> FaInt:FCS 0.000  0.000  0.000  0.000  0.000
> >> FB150:FCS 0.000  0.000  0.000  0.000  0.000 0.000
> >> FB200:FCS 0.000  0.000  0.000  0.000  0.000 0.000  0.000
> >>
> >> convergence code: 0
> >> Model failed to converge with max|grad| = 0.113738 (tol = 0.001,
> component
> >> 1)
> >> Model is nearly unidentifiable: very large eigenvalue
> >>  - Rescale variables?
> >>
> >> I've tried look through my data, as my first thought was that data was
> >> somehow miscoded, but I can't see anything that would be the matter.  A
> >> more complicated version of the model had the same problem until I got
> rid
> >> of a single participant (who seemed otherwise entirely unexceptional).
> The
> >> more complicated model now converges fine, but this simpler one now has
> >> these issues.  I have an almost identical dataset that I've been doing
> >> almost exactly the same models with that hasn't been giving me similar
> >> problems.
> >>
> >> Any thoughts?
> >>
> >> Thank you,
> >>
> >> Chris
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mcypsy at gmail.com  Mon Oct 12 00:37:06 2015
From: mcypsy at gmail.com (Chunyun Ma)
Date: Sun, 11 Oct 2015 18:37:06 -0400
Subject: [R-sig-ME] Model is nearly unidentifiable with lmer
Message-ID: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>

?Dear all,

?This is my first post in the mailing list. ?
I have been running some model ?with lmer and came across this warning
message:

In checkConv(attr(opt, ?derivs?), opt$par, ctrl = control$checkConv, :
Model is nearly unidentifiable: very large eigenvalue

   - Rescale variables?

Here is the formula of my model (I substituted variables names with generic
names):

y ~ Intercept + Xc + Xd1 + Xd2 + Xc:Xd1 + Xc:Xd2 + Zd + Zd:Xc + Zd:Xd1 +
Zd:Xd2 + (1 + Xc + Xd1 + Xd2 | sub)

Xc: continuous var
Xd: level-1 dummy variable(s)
Zd: level-2 dummy variable

A snapshot of data. I can also provide the full dataset if necessary.
sub Xc Xd1 Xd2 Zd y 1 36 0 0 1 1346 1 45 0 1 1 1508 1 72 1 0 1 1246 1 12 1 0
1 1164 1 24 1 0 1 1295 1 36 1 0 1 1403

When I reduced the # of random effect to (1+Xc|sub), the warning message
disappeared, but the model fit became poorer.
My question is: which variable(s) should I rescale? I?d be happy to
? better understand t
he
??
warning message if anyone could
? kindly?
suggest
?some
 reference paper/book.

Thank you very for your help!!

Chunyun
?

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Oct 12 02:18:38 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 11 Oct 2015 20:18:38 -0400
Subject: [R-sig-ME] Model is nearly unidentifiable with lmer
In-Reply-To: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>
References: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>
Message-ID: <CABghstTZOr-vDwTJ6LZiLjoWQcDC2zdQA=jk3cL2ahLd3XzP8g@mail.gmail.com>

Short answer: try rescaling all of your continuous variables.  It
can't hurt/will change only the interpretation.  If you get the same
log-likelihood with the rescaled variables, that indicates that the
large eigenvalue was not actually a problem in the first place.

   I don't think the standard citation from the R citation file
<https://cran.r-project.org/web/packages/lme4/citation.html>, or the
book chapter I wrote recently (chapter 13 of Fox et al, Oxford
University Press 2015 -- online supplements at
<http://ms.mcmaster.ca/~bolker/R%/misc/foxchapter/bolker_chap.html>)
cover rescaling in much detail. Schielzeth 2010
doi:10.1111/j.2041-210X.2010.00012.x gives a coherent argument about
the interpretive advantages of scaling.

   Ben Bolker


On Sun, Oct 11, 2015 at 6:37 PM, Chunyun Ma <mcypsy at gmail.com> wrote:
> Dear all,
>
> This is my first post in the mailing list.
> I have been running some model with lmer and came across this warning
> message:
>
> In checkConv(attr(opt, ?derivs?), opt$par, ctrl = control$checkConv, :
> Model is nearly unidentifiable: very large eigenvalue
>
>    - Rescale variables?
>
> Here is the formula of my model (I substituted variables names with generic
> names):
>
> y ~ Intercept + Xc + Xd1 + Xd2 + Xc:Xd1 + Xc:Xd2 + Zd + Zd:Xc + Zd:Xd1 +
> Zd:Xd2 + (1 + Xc + Xd1 + Xd2 | sub)
>
> Xc: continuous var
> Xd: level-1 dummy variable(s)
> Zd: level-2 dummy variable
>
> A snapshot of data. I can also provide the full dataset if necessary.
> sub Xc Xd1 Xd2 Zd y 1 36 0 0 1 1346 1 45 0 1 1 1508 1 72 1 0 1 1246 1 12 1 0
> 1 1164 1 24 1 0 1 1295 1 36 1 0 1 1403
>
> When I reduced the # of random effect to (1+Xc|sub), the warning message
> disappeared, but the model fit became poorer.
> My question is: which variable(s) should I rescale? I?d be happy to
> better understand t
> he
>
> warning message if anyone could
> kindly
> suggest
> some
>  reference paper/book.
>
> Thank you very for your help!!
>
> Chunyun
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From abfine at gmail.com  Mon Oct 12 02:28:38 2015
From: abfine at gmail.com (Alex Fine)
Date: Sun, 11 Oct 2015 20:28:38 -0400
Subject: [R-sig-ME] Model is nearly unidentifiable with lmer
In-Reply-To: <CABghstTZOr-vDwTJ6LZiLjoWQcDC2zdQA=jk3cL2ahLd3XzP8g@mail.gmail.com>
References: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>
	<CABghstTZOr-vDwTJ6LZiLjoWQcDC2zdQA=jk3cL2ahLd3XzP8g@mail.gmail.com>
Message-ID: <CAJ6ui+M8MdA5c5Qw9sc4nCW3UjipykYS0ZTVMSts9pebTCOhfw@mail.gmail.com>

You might also try using sum-coding rather than (the default) dummy coding
with the categorical predictors.  Assuming the design is roughly balanced,
this is like mean-centering the categorical variables.  This will change
the interpretation of the coefficients.

Here is some further reading:  http://talklab.psy.gla.ac.uk/tvw/catpred/

On Sun, Oct 11, 2015 at 8:18 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Short answer: try rescaling all of your continuous variables.  It
> can't hurt/will change only the interpretation.  If you get the same
> log-likelihood with the rescaled variables, that indicates that the
> large eigenvalue was not actually a problem in the first place.
>
>    I don't think the standard citation from the R citation file
> <https://cran.r-project.org/web/packages/lme4/citation.html>, or the
> book chapter I wrote recently (chapter 13 of Fox et al, Oxford
> University Press 2015 -- online supplements at
> <http://ms.mcmaster.ca/~bolker/R%/misc/foxchapter/bolker_chap.html>)
> cover rescaling in much detail. Schielzeth 2010
> doi:10.1111/j.2041-210X.2010.00012.x gives a coherent argument about
> the interpretive advantages of scaling.
>
>    Ben Bolker
>
>
> On Sun, Oct 11, 2015 at 6:37 PM, Chunyun Ma <mcypsy at gmail.com> wrote:
> > Dear all,
> >
> > This is my first post in the mailing list.
> > I have been running some model with lmer and came across this warning
> > message:
> >
> > In checkConv(attr(opt, ?derivs?), opt$par, ctrl = control$checkConv, :
> > Model is nearly unidentifiable: very large eigenvalue
> >
> >    - Rescale variables?
> >
> > Here is the formula of my model (I substituted variables names with
> generic
> > names):
> >
> > y ~ Intercept + Xc + Xd1 + Xd2 + Xc:Xd1 + Xc:Xd2 + Zd + Zd:Xc + Zd:Xd1 +
> > Zd:Xd2 + (1 + Xc + Xd1 + Xd2 | sub)
> >
> > Xc: continuous var
> > Xd: level-1 dummy variable(s)
> > Zd: level-2 dummy variable
> >
> > A snapshot of data. I can also provide the full dataset if necessary.
> > sub Xc Xd1 Xd2 Zd y 1 36 0 0 1 1346 1 45 0 1 1 1508 1 72 1 0 1 1246 1 12
> 1 0
> > 1 1164 1 24 1 0 1 1295 1 36 1 0 1 1403
> >
> > When I reduced the # of random effect to (1+Xc|sub), the warning message
> > disappeared, but the model fit became poorer.
> > My question is: which variable(s) should I rescale? I?d be happy to
> > better understand t
> > he
> >
> > warning message if anyone could
> > kindly
> > suggest
> > some
> >  reference paper/book.
> >
> > Thank you very for your help!!
> >
> > Chunyun
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Alex Fine
Ph. (336) 302-3251
web:  http://internal.psychology.illinois.edu/~abfine/
<http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Oct 12 03:19:56 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 11 Oct 2015 21:19:56 -0400
Subject: [R-sig-ME] Model is nearly unidentifiable with lmer
In-Reply-To: <D1E6778D25CD784EA2712EEB3606118A9D85416E@EX01.net.ucsf.edu>
References: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>
	<CABghstTZOr-vDwTJ6LZiLjoWQcDC2zdQA=jk3cL2ahLd3XzP8g@mail.gmail.com>
	<D1E6778D25CD784EA2712EEB3606118A9D85416E@EX01.net.ucsf.edu>
Message-ID: <561B0ABC.3040304@gmail.com>


  The link to the chapter supplement should be

<http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html>

  sorry about that
    Ben Bolker


On 15-10-11 08:27 PM, Porco, Travis wrote:
> Sorry to bother you; the hyper link to your chapter supplements is
> giving Bad Request/ error 400. --tcp 
> ________________________________________ From: R-sig-mixed-models
> [r-sig-mixed-models-bounces at r-project.org] on behalf of Ben Bolker
> [bbolker at gmail.com] Sent: Sunday, October 11, 2015 5:18 PM To:
> Chunyun Ma Cc: r-sig-mixed-models at r-project.org Subject: Re:
> [R-sig-ME] Model is nearly unidentifiable with lmer
> 
> Short answer: try rescaling all of your continuous variables.  It 
> can't hurt/will change only the interpretation.  If you get the
> same log-likelihood with the rescaled variables, that indicates
> that the large eigenvalue was not actually a problem in the first
> place.
> 
> I don't think the standard citation from the R citation file 
> <https://cran.r-project.org/web/packages/lme4/citation.html>, or
> the book chapter I wrote recently (chapter 13 of Fox et al, Oxford 
> University Press 2015 -- online supplements at 
> <http://ms.mcmaster.ca/~bolker/R%/misc/foxchapter/bolker_chap.html>)
>
> 
cover rescaling in much detail. Schielzeth 2010
> doi:10.1111/j.2041-210X.2010.00012.x gives a coherent argument
> about the interpretive advantages of scaling.
> 
> Ben Bolker
> 
> 
> On Sun, Oct 11, 2015 at 6:37 PM, Chunyun Ma <mcypsy at gmail.com>
> wrote:
>> Dear all,
>> 
>> This is my first post in the mailing list. I have been running
>> some model with lmer and came across this warning message:
>> 
>> In checkConv(attr(opt, ?derivs?), opt$par, ctrl =
>> control$checkConv, : Model is nearly unidentifiable: very large
>> eigenvalue
>> 
>> - Rescale variables?
>> 
>> Here is the formula of my model (I substituted variables names
>> with generic names):
>> 
>> y ~ Intercept + Xc + Xd1 + Xd2 + Xc:Xd1 + Xc:Xd2 + Zd + Zd:Xc +
>> Zd:Xd1 + Zd:Xd2 + (1 + Xc + Xd1 + Xd2 | sub)
>> 
>> Xc: continuous var Xd: level-1 dummy variable(s) Zd: level-2
>> dummy variable
>> 
>> A snapshot of data. I can also provide the full dataset if
>> necessary. sub Xc Xd1 Xd2 Zd y 1 36 0 0 1 1346 1 45 0 1 1 1508 1
>> 72 1 0 1 1246 1 12 1 0 1 1164 1 24 1 0 1 1295 1 36 1 0 1 1403
>> 
>> When I reduced the # of random effect to (1+Xc|sub), the warning
>> message disappeared, but the model fit became poorer. My question
>> is: which variable(s) should I rescale? I?d be happy to better
>> understand t he
>> 
>> warning message if anyone could kindly suggest some reference
>> paper/book.
>> 
>> Thank you very for your help!!
>> 
>> Chunyun
>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From karraspito at yahoo.es  Mon Oct 12 12:34:01 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Mon, 12 Oct 2015 10:34:01 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm prior specification
References: <80037041.2029532.1444646041101.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <80037041.2029532.1444646041101.JavaMail.yahoo@mail.yahoo.com>

?? Hello everyone,
?? I am reading a lot of documentation at the moment about prior specification in MCMCglmm, and there is still something I have not very clear. According to some sources, there are mainly two elements to take into account when defining a prior:?? - An R structure that needs to be specified for each fixed effect. And
?? - A G structure for each random effect.
?? However, in other sources another element, B, is introduced as well, which refers to fixed effects too. In Jarrod's Course Notes, I see that both R and B have to do with fixed effects: R specifies V and nu arguments for the variance, and B specifies V and mu elements for the mean.
?? 
?? My confusion comes from the fact that almost every time I see an example of a prior, it just has two elements, R (for fixed effects) and G (for random effects). Why is this? Is it not so important to define a prior for the mean? Is it enough with a prior specification for the variance of fixed effects and another one for all the random effects?
?? Thank you very much in advance.?? Iker

? 
__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Oct 12 12:56:20 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 12 Oct 2015 11:56:20 +0100
Subject: [R-sig-ME] MCMCglmm prior specification
In-Reply-To: <80037041.2029532.1444646041101.JavaMail.yahoo@mail.yahoo.com>
References: <80037041.2029532.1444646041101.JavaMail.yahoo@mail.yahoo.com>
	<80037041.2029532.1444646041101.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20151012115620.12494vukb363au34@www.staffmail.ed.ac.uk>

Hi,

R defines the prior for the residual covariance matrices. B specifies  
the prior for the `fixed' effects.

Cheers,

Jarrod



Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Mon, 12 Oct 2015  
10:34:01 +0000 (UTC):

> ?? Hello everyone,
> ?? I am reading a lot of documentation at the moment about prior  
> specification in MCMCglmm, and there is still something I have not  
> very clear. According to some sources, there are mainly two elements  
> to take into account when defining a prior:?? - An R structure that  
> needs to be specified for each fixed effect. And
> ?? - A G structure for each random effect.
> ?? However, in other sources another element, B, is introduced as  
> well, which refers to fixed effects too. In Jarrod's Course Notes, I  
> see that both R and B have to do with fixed effects: R specifies V  
> and nu arguments for the variance, and B specifies V and mu elements  
> for the mean.
> ??
> ?? My confusion comes from the fact that almost every time I see an  
> example of a prior, it just has two elements, R (for fixed effects)  
> and G (for random effects). Why is this? Is it not so important to  
> define a prior for the mean? Is it enough with a prior specification  
> for the variance of fixed effects and another one for all the random  
> effects?
> ?? Thank you very much in advance.?? Iker
>
> ?
> __________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From karraspito at yahoo.es  Mon Oct 12 13:05:58 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Mon, 12 Oct 2015 11:05:58 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm prior specification
In-Reply-To: <20151012115620.12494vukb363au34@www.staffmail.ed.ac.uk>
References: <20151012115620.12494vukb363au34@www.staffmail.ed.ac.uk>
Message-ID: <503334194.3573040.1444647958644.JavaMail.yahoo@mail.yahoo.com>


?? Hi Jarrod,?? Thanks a lot for your reply. I had actually found information about it in another post and wanted to "fix" my own question, but for some reason individual posts don't arrive to my email even if I have that option activated, so I couldn't reply to myself.?? My question, then, would be: most of the times I see priors with just R and G elements, but not B. Is it not necessary to specify B? Also, if my model does not have random effects, then would it be enough with a prior for R element? 

?? Thank you very much.?? Iker.


__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381




     De: Jarrod Hadfield <j.hadfield at ed.ac.uk>

CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Enviado: Lunes 12 de octubre de 2015 11:56
 Asunto: Re: [R-sig-ME] MCMCglmm prior specification
   
Hi,

R defines the prior for the residual covariance matrices. B specifies?
the prior for the `fixed' effects.

Cheers,

Jarrod




10:34:01 +0000 (UTC):



> ?? Hello everyone,
> ?? I am reading a lot of documentation at the moment about prior? 
> specification in MCMCglmm, and there is still something I have not?
> very clear. According to some sources, there are mainly two elements? 
> to take into account when defining a prior:?? - An R structure that? 
> needs to be specified for each fixed effect. And
> ?? - A G structure for each random effect.
> ?? However, in other sources another element, B, is introduced as? 
> well, which refers to fixed effects too. In Jarrod's Course Notes, I? 
> see that both R and B have to do with fixed effects: R specifies V?
> and nu arguments for the variance, and B specifies V and mu elements? 
> for the mean.
> ??
> ?? My confusion comes from the fact that almost every time I see an? 
> example of a prior, it just has two elements, R (for fixed effects)?
> and G (for random effects). Why is this? Is it not so important to?
> define a prior for the mean? Is it enough with a prior specification? 
> for the variance of fixed effects and another one for all the random? 
> effects?
> ?? Thank you very much in advance.?? Iker
>
> ?
> __________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> ??? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.




  
	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Oct 12 13:40:46 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 12 Oct 2015 12:40:46 +0100
Subject: [R-sig-ME] MCMCglmm prior specification
In-Reply-To: <503334194.3573040.1444647958644.JavaMail.yahoo@mail.yahoo.com>
References: <20151012115620.12494vukb363au34@www.staffmail.ed.ac.uk>
	<503334194.3573040.1444647958644.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20151012124046.145512z9cntzukw0@www.staffmail.ed.ac.uk>

Hi,

Usually people think the default priors for the fixed effects (zero  
mean, high variance) are reasonable. However, there are cases where  
stronger priors are useful. For example, a) you might actually have  
some prior information or b) you might have near or complete  
separation in a GLMM (usually with categorical data) and you might  
want to constrain the fixed effects so they don't result in extreme  
predictions.

Cheers,

Jarrod




  Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Mon, 12 Oct 2015  
11:05:58 +0000 (UTC):

>
> ?? Hi Jarrod,?? Thanks a lot for your reply. I had actually found  
> information about it in another post and wanted to "fix" my own  
> question, but for some reason individual posts don't arrive to my  
> email even if I have that option activated, so I couldn't reply to  
> myself.?? My question, then, would be: most of the times I see  
> priors with just R and G elements, but not B. Is it not necessary to  
> specify B? Also, if my model does not have random effects, then  
> would it be enough with a prior for R element?
>
> ?? Thank you very much.?? Iker.
>
>
> __________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
>
>
>      De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>  Para: Iker Vaquero Alba <karraspito at yahoo.es>
> CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
>  Enviado: Lunes 12 de octubre de 2015 11:56
>  Asunto: Re: [R-sig-ME] MCMCglmm prior specification
>
> Hi,
>
> R defines the prior for the residual covariance matrices. B specifies?
> the prior for the `fixed' effects.
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Mon, 12 Oct 2015?
> 10:34:01 +0000 (UTC):
>
>
>
>> ?? Hello everyone,
>> ?? I am reading a lot of documentation at the moment about prior?
>> specification in MCMCglmm, and there is still something I have not?
>> very clear. According to some sources, there are mainly two elements?
>> to take into account when defining a prior:?? - An R structure that?
>> needs to be specified for each fixed effect. And
>> ?? - A G structure for each random effect.
>> ?? However, in other sources another element, B, is introduced as?
>> well, which refers to fixed effects too. In Jarrod's Course Notes, I?
>> see that both R and B have to do with fixed effects: R specifies V?
>> and nu arguments for the variance, and B specifies V and mu elements?
>> for the mean.
>> ??
>> ?? My confusion comes from the fact that almost every time I see an?
>> example of a prior, it just has two elements, R (for fixed effects)?
>> and G (for random effects). Why is this? Is it not so important to?
>> define a prior for the mean? Is it enough with a prior specification?
>> for the variance of fixed effects and another one for all the random?
>> effects?
>> ?? Thank you very much in advance.?? Iker
>>
>> ?
>> __________________________________________________________________
>>
>> ?? Iker Vaquero-Alba
>> ?? Visiting Postdoctoral Research Associate
>> ?? Laboratory of Evolutionary Ecology of Adaptations
>> ?? Joseph Banks Laboratories
>> ?? School of Life Sciences
>> ?? University of Lincoln?? Brayford Campus, Lincoln
>> ?? LN6 7DL
>> ?? United Kingdom
>>
>> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From karraspito at yahoo.es  Mon Oct 12 13:47:53 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Mon, 12 Oct 2015 11:47:53 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm prior specification
In-Reply-To: <20151012124046.145512z9cntzukw0@www.staffmail.ed.ac.uk>
References: <20151012124046.145512z9cntzukw0@www.staffmail.ed.ac.uk>
Message-ID: <850858497.3650421.1444650473103.JavaMail.yahoo@mail.yahoo.com>


?? Ok, thank you very much. I am actually asking all this because I am trying to write a very quick guide to MCMCglmm so that people can achieve in a pair of hours what cost me more than two weeks, this is, being able to specify an extremely simple model that at least runs and gives more or less reasonable results, including things like categorical data and bivariate responses. Obviously I don't want to do it too complicated (I wouldn't be able anyway, I have so much to learn myself yet!), so I suppose I will just give a pair of examples of uninformative priors for univariate and multivariate responses.?? I will post the guide here when it's finished so that you guys can point at the multiple errors it will surely have.
?? Thank you very much,?? Iker
?__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


      De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
 Para: Iker Vaquero Alba <karraspito at yahoo.es> 
CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Enviado: Lunes 12 de octubre de 2015 12:40
 Asunto: Re: [R-sig-ME] MCMCglmm prior specification
   
Hi,

Usually people think the default priors for the fixed effects (zero? 
mean, high variance) are reasonable. However, there are cases where? 
stronger priors are useful. For example, a) you might actually have? 
some prior information or b) you might have near or complete? 
separation in a GLMM (usually with categorical data) and you might? 
want to constrain the fixed effects so they don't result in extreme? 
predictions.

Cheers,

Jarrod




? Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Mon, 12 Oct 2015? 
11:05:58 +0000 (UTC):

>
> ?? Hi Jarrod,?? Thanks a lot for your reply. I had actually found? 
> information about it in another post and wanted to "fix" my own? 
> question, but for some reason individual posts don't arrive to my? 
> email even if I have that option activated, so I couldn't reply to? 
> myself.?? My question, then, would be: most of the times I see? 
> priors with just R and G elements, but not B. Is it not necessary to? 
> specify B? Also, if my model does not have random effects, then? 
> would it be enough with a prior for R element?
>
> ?? Thank you very much.?? Iker.
>
>
> __________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
>
>
>? ? ? De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>? Para: Iker Vaquero Alba <karraspito at yahoo.es>
> CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
>? Enviado: Lunes 12 de octubre de 2015 11:56
>? Asunto: Re: [R-sig-ME] MCMCglmm prior specification
>
> Hi,
>
> R defines the prior for the residual covariance matrices. B specifies?
> the prior for the `fixed' effects.
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Mon, 12 Oct 2015?
> 10:34:01 +0000 (UTC):
>
>
>
>> ?? Hello everyone,
>> ?? I am reading a lot of documentation at the moment about prior?
>> specification in MCMCglmm, and there is still something I have not?
>> very clear. According to some sources, there are mainly two elements?
>> to take into account when defining a prior:?? - An R structure that?
>> needs to be specified for each fixed effect. And
>> ?? - A G structure for each random effect.
>> ?? However, in other sources another element, B, is introduced as?
>> well, which refers to fixed effects too. In Jarrod's Course Notes, I?
>> see that both R and B have to do with fixed effects: R specifies V?
>> and nu arguments for the variance, and B specifies V and mu elements?
>> for the mean.
>> ??
>> ?? My confusion comes from the fact that almost every time I see an?
>> example of a prior, it just has two elements, R (for fixed effects)?
>> and G (for random effects). Why is this? Is it not so important to?
>> define a prior for the mean? Is it enough with a prior specification?
>> for the variance of fixed effects and another one for all the random?
>> effects?
>> ?? Thank you very much in advance.?? Iker
>>
>> ?
>> __________________________________________________________________
>>
>> ?? Iker Vaquero-Alba
>> ?? Visiting Postdoctoral Research Associate
>> ?? Laboratory of Evolutionary Ecology of Adaptations
>> ?? Joseph Banks Laboratories
>> ?? School of Life Sciences
>> ?? University of Lincoln?? Brayford Campus, Lincoln
>> ?? LN6 7DL
>> ?? United Kingdom
>>
>> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


>
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.




  
	[[alternative HTML version deleted]]


From holtermann at hwwi.org  Mon Oct 12 15:58:46 2015
From: holtermann at hwwi.org (Linus Holtermann)
Date: Mon, 12 Oct 2015 13:58:46 +0000
Subject: [R-sig-ME] mixed probit and rare events (MCMCglmm)
Message-ID: <5fa0e47f9eb2432ab155055cfb181361@winhexbeeu15.win.mail>

Hello,



I like to estimate a mixed model via MCMCglmm. My model is a binomial model (probit). There are more than 3000 observations in my data, but for some investigations the dependent variable is one for only 320 observations (zero otherwise). Is this a problem in a MCMC setup? How can I solve this problem of rare events in a probit model? Note, I want to stick to MCMC. Is a Gelman-Prior a proper choice? Are there other solutions that are implemented in MCMCglmm (or in other packages)?

Best regards,

Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org<http://www.hwwi.org/>
Email: holtermann at hwwi.org<mailto:holtermann at hwwi.org>

Amtsgericht Hamburg HRB 94303
Gesch?ftsf?hrer: Prof. Dr. Henning V?pel
Prokura: Dipl. Kauffrau Alexis Malchin
Umsatzsteuer-ID: DE 241849425


	[[alternative HTML version deleted]]


From westm490 at gmail.com  Mon Oct 12 19:42:19 2015
From: westm490 at gmail.com (M West)
Date: Mon, 12 Oct 2015 13:42:19 -0400
Subject: [R-sig-ME] mixed effects model proportion data that are not 0 and
	1's
Message-ID: <CAFJT+3JPahMw0bi4YCsb62vgEgk-s87mfRt5kPB6Q4ptjvC0Uw@mail.gmail.com>

Hello,

I am trying to decide the best approach for analyzing a short time series.

The goal is to see if there is a significant relationship between the
percentage change in females (# females/total population during epidemic -
# females/total population pre-epidemic) and disease prevalence (continuous
variable: percentage infected).

Samples are across 15 sites and 5 months. So a very short time series.

Here's the model and weights that I've used thus far.
v3 <- varComb(varIdent(form =~ 1 | Month) , varExp(form =~
Proportion_infected))
mod <- lme(Change_in_proportion_females ~ Proportion_infected + Month,
random = ~ 1 |Site/Month, weights = v3)

The main problems are:
1) If I plot the residuals vs. the fitted values, there is a strong
relationship demonstrating that the variance increase with the mean. How do
I account for this in a mixed effects model? I've tried the weights option
(with a couple of variations), however, I receive an error message:
"iteration limit reached without convergence"

2) I also have a question about the way that R treats proportion data that
are not 0 and 1's when using glm (or glmer) with the binomial distribution.
Crawley, for example, suggests that you create a y variable where you
account for the total number of observations (e.g., y <- cbind(total
females, (total population - total females)) and then run a glm (or in may
case, a generalized linear mixed model) using the binomial distribution.

But what is actually going on under the hood here? Is R running some sort
of proportion test?  All the examples that I have found for proportion data
or non-normal residuals suggest using a logistic regression approach with
the binomial distribution. Is this also the best option for proportion data
that are not 0 and 1's (i.e., my data on the percentage change would not
match the typical logistic regression plot)?

Many thanks in advance.
M.

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Mon Oct 12 20:15:17 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 12 Oct 2015 14:15:17 -0400
Subject: [R-sig-ME] mixed effects model proportion data that are not 0
 and 1's
In-Reply-To: <CAFJT+3JPahMw0bi4YCsb62vgEgk-s87mfRt5kPB6Q4ptjvC0Uw@mail.gmail.com>
References: <CAFJT+3JPahMw0bi4YCsb62vgEgk-s87mfRt5kPB6Q4ptjvC0Uw@mail.gmail.com>
Message-ID: <561BC075020000CB0013BFBC@smtp.medicine.umaryland.edu>

Would a log-linear model (e.g. Poisson regression) with an offset (to allow for fractions rather than counts) do what you want to do?John



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

>>> M West <westm490 at gmail.com> 10/12/15 1:42 PM >>>
Hello,

I am trying to decide the best approach for analyzing a short time series.

The goal is to see if there is a significant relationship between the
percentage change in females (# females/total population during epidemic -
# females/total population pre-epidemic) and disease prevalence (continuous
variable: percentage infected).

Samples are across 15 sites and 5 months. So a very short time series.

Here's the model and weights that I've used thus far.
v3 <- varComb(varIdent(form =~ 1 | Month) , varExp(form =~
Proportion_infected))
mod <- lme(Change_in_proportion_females ~ Proportion_infected + Month,
random = ~ 1 |Site/Month, weights = v3)

The main problems are:
1) If I plot the residuals vs. the fitted values, there is a strong
relationship demonstrating that the variance increase with the mean. How do
I account for this in a mixed effects model? I've tried the weights option
(with a couple of variations), however, I receive an error message:
"iteration limit reached without convergence"

2) I also have a question about the way that R treats proportion data that
are not 0 and 1's when using glm (or glmer) with the binomial distribution.
Crawley, for example, suggests that you create a y variable where you
account for the total number of observations (e.g., y <- cbind(total
females, (total population - total females)) and then run a glm (or in may
case, a generalized linear mixed model) using the binomial distribution.

But what is actually going on under the hood here? Is R running some sort
of proportion test?  All the examples that I have found for proportion data
or non-normal residuals suggest using a logistic regression approach with
the binomial distribution. Is this also the best option for proportion data
that are not 0 and 1's (i.e., my data on the percentage change would not
match the typical logistic regression plot)?

Many thanks in advance.
M.

    [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From bbolker at gmail.com  Mon Oct 12 20:16:35 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 12 Oct 2015 14:16:35 -0400
Subject: [R-sig-ME] mixed effects model proportion data that are not 0
 and 1's
In-Reply-To: <CAFJT+3JPahMw0bi4YCsb62vgEgk-s87mfRt5kPB6Q4ptjvC0Uw@mail.gmail.com>
References: <CAFJT+3JPahMw0bi4YCsb62vgEgk-s87mfRt5kPB6Q4ptjvC0Uw@mail.gmail.com>
Message-ID: <561BF903.4060508@gmail.com>

On 15-10-12 01:42 PM, M West wrote:
> Hello,
> 
> I am trying to decide the best approach for analyzing a short time series.
> 
> The goal is to see if there is a significant relationship between the
> percentage change in females (# females/total population during epidemic -
> # females/total population pre-epidemic) and disease prevalence (continuous
> variable: percentage infected).
> 
> Samples are across 15 sites and 5 months. So a very short time series.
> 
> Here's the model and weights that I've used thus far.
> v3 <- varComb(varIdent(form =~ 1 | Month) , varExp(form =~
> Proportion_infected))
> mod <- lme(Change_in_proportion_females ~ Proportion_infected + Month,
> random = ~ 1 |Site/Month, weights = v3)
> 
> The main problems are:
> 1) If I plot the residuals vs. the fitted values, there is a strong
> relationship demonstrating that the variance increase with the mean. How do
> I account for this in a mixed effects model? I've tried the weights option
> (with a couple of variations), however, I receive an error message:
> "iteration limit reached without convergence"

  weights= is the right way to go about it; we'd have to see more
details to know what the problem is in your particular case.

 Your model looks like it might be overfitted: if you only have one
observation per Site/Month combination, then the Site-by-Month
interaction term (Site/Month expands to "Site plus Site-by-Month")
will be confounded with the residual variance.  I have found in the
past that lme may allow you to fit the overfitted model without
complaining; one way of diagnosing this problem is to try intervals() on
your fitted model (try it without the weights= argument for
simplicity) and see if you get warnings/errors.

> 
> 2) I also have a question about the way that R treats proportion data that
> are not 0 and 1's when using glm (or glmer) with the binomial distribution.
> Crawley, for example, suggests that you create a y variable where you
> account for the total number of observations (e.g., y <- cbind(total
> females, (total population - total females)) and then run a glm (or in may
> case, a generalized linear mixed model) using the binomial distribution.
> 
> But what is actually going on under the hood here? Is R running some sort
> of proportion test?  All the examples that I have found for proportion data
> or non-normal residuals suggest using a logistic regression approach with
> the binomial distribution. Is this also the best option for proportion data
> that are not 0 and 1's (i.e., my data on the percentage change would not
> match the typical logistic regression plot)?

  Binomial and Bernoulli (binary) logistic regression are basically
equivalent; when you have multiple individuals observed for a particular
set of predictor variables (e.g. month/site), it's practical
and computationally efficient to collapse them to a binomial regression.
Under the hood there is indeed the equivalent of a proportion test --
not necessarily quite as accurate for small numbers of counts as some
classical proportion tests, but much more flexible.  In lme4 (the
successor to nlme, which implements generalized linear MMs that can
handle a binomial response), the 'weights' argument is simpler/can be
used to specify the denominator or total number of counts:

library(lme4)
 mod <- glmer(Change_in_proportion_females ~ Proportion_infected + Month
+ (1 |Site/Month),
family=binomial, weights = total_counts, data=...)

 (here, including the site-by-month interaction is OK -- it represents
the possibility of extra-binomial variance (overdispersion).)


From lmpitombo at ufscar.br  Fri Oct  9 20:02:53 2015
From: lmpitombo at ufscar.br (lmpitombo)
Date: Fri, 09 Oct 2015 15:02:53 -0300
Subject: [R-sig-ME] Fwd: RE: static vs dynamic factors together?
In-Reply-To: <7539129727B06D42A9F1A56D2C597F851139BEEE@FHSDB2D11-2.csu.mcmaster.ca>
References: <d8b38429dd5207fa25903cbed3431a6f@ufscar.br>
	<7539129727B06D42A9F1A56D2C597F851139BEEE@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <52c91876f42784c469c40d42ef6a8900@ufscar.br>

Dear Dr. Bolker,

When I specify the fixed effects I usually include both treatments and 
covariates in the same analysis - I?m looking for which factors better 
explain y. For instance, I have treatments 0, 50, 75 and 100 and the 
covariate "alpha". The treatments explain my variable much more often 
than the covariate.

So, the question that arises is if it is right give the same weight for 
treatments and covariates... Should be included some penalty for 
treatments?


Thanks again,
---
      Leonardo M. Pitombo
       UFSCar - Sorocaba
          Lab. de Solos

-------- Mensagem original --------
Assunto: RE: static vs dynamic factors together?
Data: 2015-10-08 23:05
De: "Bolker, Benjamin" <bolkerb at mcmaster.ca>
Para: lmpitombo <lmpitombo at ufscar.br>

   I don't really understand the question.  It might be better for
r-sig-mixed-models at r-project.org ... As far as I understand what
you're asking, I don't see any conceptual difference between static and
time-varying predictor variables ...

   cheers
     Ben Bolker

________________________________________
 From: lmpitombo [lmpitombo at ufscar.br]
Sent: Wednesday, October 07, 2015 9:17 AM
To: bolker at mcmaster.ca
Subject: static vs dynamic factors together?

Dear Dr. Bolker,

You always have payed attention in my questions in the "github" about
practival issues. Now, I have submmited a manuscript and one reviewer
asked something that I imagine I might reply but I would like your
(informal) input/ advice.

Here we go:

I have treatments (static factors) and environmental parameters (dynamic
factors)

To test which factors better explain the variable in test, usually I put
all together. Is it right, once the dynamic factors are associated with
a variance and the static parameters not? Is there any penalty in the
models for the static parameters?

Best Regards,
--
       Leonardo M. Pitombo
        UFSCar - Sorocaba
          Lab. de Solos
         (15) 3229 8842


From westm490 at gmail.com  Tue Oct 13 13:37:23 2015
From: westm490 at gmail.com (M West)
Date: Tue, 13 Oct 2015 07:37:23 -0400
Subject: [R-sig-ME] mixed effects model proportion data that are not 0
	and 1's
In-Reply-To: <561BF903.4060508@gmail.com>
References: <CAFJT+3JPahMw0bi4YCsb62vgEgk-s87mfRt5kPB6Q4ptjvC0Uw@mail.gmail.com>
	<561BF903.4060508@gmail.com>
Message-ID: <CAFJT+3JiouRDYpm_UvZNJQYw8PCmptu2=rF88RsyAV_RLHKn_Q@mail.gmail.com>

Thanks all for these great answers - I really appreciate it!

M

On Mon, Oct 12, 2015 at 2:16 PM, Ben Bolker <bbolker at gmail.com> wrote:

> On 15-10-12 01:42 PM, M West wrote:
> > Hello,
> >
> > I am trying to decide the best approach for analyzing a short time
> series.
> >
> > The goal is to see if there is a significant relationship between the
> > percentage change in females (# females/total population during epidemic
> -
> > # females/total population pre-epidemic) and disease prevalence
> (continuous
> > variable: percentage infected).
> >
> > Samples are across 15 sites and 5 months. So a very short time series.
> >
> > Here's the model and weights that I've used thus far.
> > v3 <- varComb(varIdent(form =~ 1 | Month) , varExp(form =~
> > Proportion_infected))
> > mod <- lme(Change_in_proportion_females ~ Proportion_infected + Month,
> > random = ~ 1 |Site/Month, weights = v3)
> >
> > The main problems are:
> > 1) If I plot the residuals vs. the fitted values, there is a strong
> > relationship demonstrating that the variance increase with the mean. How
> do
> > I account for this in a mixed effects model? I've tried the weights
> option
> > (with a couple of variations), however, I receive an error message:
> > "iteration limit reached without convergence"
>
>   weights= is the right way to go about it; we'd have to see more
> details to know what the problem is in your particular case.
>
>  Your model looks like it might be overfitted: if you only have one
> observation per Site/Month combination, then the Site-by-Month
> interaction term (Site/Month expands to "Site plus Site-by-Month")
> will be confounded with the residual variance.  I have found in the
> past that lme may allow you to fit the overfitted model without
> complaining; one way of diagnosing this problem is to try intervals() on
> your fitted model (try it without the weights= argument for
> simplicity) and see if you get warnings/errors.
>
> >
> > 2) I also have a question about the way that R treats proportion data
> that
> > are not 0 and 1's when using glm (or glmer) with the binomial
> distribution.
> > Crawley, for example, suggests that you create a y variable where you
> > account for the total number of observations (e.g., y <- cbind(total
> > females, (total population - total females)) and then run a glm (or in
> may
> > case, a generalized linear mixed model) using the binomial distribution.
> >
> > But what is actually going on under the hood here? Is R running some sort
> > of proportion test?  All the examples that I have found for proportion
> data
> > or non-normal residuals suggest using a logistic regression approach with
> > the binomial distribution. Is this also the best option for proportion
> data
> > that are not 0 and 1's (i.e., my data on the percentage change would not
> > match the typical logistic regression plot)?
>
>   Binomial and Bernoulli (binary) logistic regression are basically
> equivalent; when you have multiple individuals observed for a particular
> set of predictor variables (e.g. month/site), it's practical
> and computationally efficient to collapse them to a binomial regression.
> Under the hood there is indeed the equivalent of a proportion test --
> not necessarily quite as accurate for small numbers of counts as some
> classical proportion tests, but much more flexible.  In lme4 (the
> successor to nlme, which implements generalized linear MMs that can
> handle a binomial response), the 'weights' argument is simpler/can be
> used to specify the denominator or total number of counts:
>
> library(lme4)
>  mod <- glmer(Change_in_proportion_females ~ Proportion_infected + Month
> + (1 |Site/Month),
> family=binomial, weights = total_counts, data=...)
>
>  (here, including the site-by-month interaction is OK -- it represents
> the possibility of extra-binomial variance (overdispersion).)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From westm490 at gmail.com  Tue Oct 13 14:43:25 2015
From: westm490 at gmail.com (M West)
Date: Tue, 13 Oct 2015 08:43:25 -0400
Subject: [R-sig-ME] mixed effects model proportion data that are not 0
	and 1's
In-Reply-To: <CAFJT+3JiouRDYpm_UvZNJQYw8PCmptu2=rF88RsyAV_RLHKn_Q@mail.gmail.com>
References: <CAFJT+3JPahMw0bi4YCsb62vgEgk-s87mfRt5kPB6Q4ptjvC0Uw@mail.gmail.com>
	<561BF903.4060508@gmail.com>
	<CAFJT+3JiouRDYpm_UvZNJQYw8PCmptu2=rF88RsyAV_RLHKn_Q@mail.gmail.com>
Message-ID: <CAFJT+3+SxM1=fXS-vtURr3OKwoCzDT0QvUPxTrfMCsbnkr72KA@mail.gmail.com>

Ok running this model:

y <- with(juv2, cbind(total females during, (total_counts_during - total
females during)))

 mod <- glmer(y ~ Proportion_infected + Month
+ (1 |Site/Month), family=binomial, weights = total_counts, data=d3)

gives the following warning:
 Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

Overfit again?

On Tue, Oct 13, 2015 at 7:37 AM, M West <westm490 at gmail.com> wrote:

> Thanks all for these great answers - I really appreciate it!
>
> M
>
> On Mon, Oct 12, 2015 at 2:16 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> On 15-10-12 01:42 PM, M West wrote:
>> > Hello,
>> >
>> > I am trying to decide the best approach for analyzing a short time
>> series.
>> >
>> > The goal is to see if there is a significant relationship between the
>> > percentage change in females (# females/total population during
>> epidemic -
>> > # females/total population pre-epidemic) and disease prevalence
>> (continuous
>> > variable: percentage infected).
>> >
>> > Samples are across 15 sites and 5 months. So a very short time series.
>> >
>> > Here's the model and weights that I've used thus far.
>> > v3 <- varComb(varIdent(form =~ 1 | Month) , varExp(form =~
>> > Proportion_infected))
>> > mod <- lme(Change_in_proportion_females ~ Proportion_infected + Month,
>> > random = ~ 1 |Site/Month, weights = v3)
>> >
>> > The main problems are:
>> > 1) If I plot the residuals vs. the fitted values, there is a strong
>> > relationship demonstrating that the variance increase with the mean.
>> How do
>> > I account for this in a mixed effects model? I've tried the weights
>> option
>> > (with a couple of variations), however, I receive an error message:
>> > "iteration limit reached without convergence"
>>
>>   weights= is the right way to go about it; we'd have to see more
>> details to know what the problem is in your particular case.
>>
>>  Your model looks like it might be overfitted: if you only have one
>> observation per Site/Month combination, then the Site-by-Month
>> interaction term (Site/Month expands to "Site plus Site-by-Month")
>> will be confounded with the residual variance.  I have found in the
>> past that lme may allow you to fit the overfitted model without
>> complaining; one way of diagnosing this problem is to try intervals() on
>> your fitted model (try it without the weights= argument for
>> simplicity) and see if you get warnings/errors.
>>
>> >
>> > 2) I also have a question about the way that R treats proportion data
>> that
>> > are not 0 and 1's when using glm (or glmer) with the binomial
>> distribution.
>> > Crawley, for example, suggests that you create a y variable where you
>> > account for the total number of observations (e.g., y <- cbind(total
>> > females, (total population - total females)) and then run a glm (or in
>> may
>> > case, a generalized linear mixed model) using the binomial distribution.
>> >
>> > But what is actually going on under the hood here? Is R running some
>> sort
>> > of proportion test?  All the examples that I have found for proportion
>> data
>> > or non-normal residuals suggest using a logistic regression approach
>> with
>> > the binomial distribution. Is this also the best option for proportion
>> data
>> > that are not 0 and 1's (i.e., my data on the percentage change would not
>> > match the typical logistic regression plot)?
>>
>>   Binomial and Bernoulli (binary) logistic regression are basically
>> equivalent; when you have multiple individuals observed for a particular
>> set of predictor variables (e.g. month/site), it's practical
>> and computationally efficient to collapse them to a binomial regression.
>> Under the hood there is indeed the equivalent of a proportion test --
>> not necessarily quite as accurate for small numbers of counts as some
>> classical proportion tests, but much more flexible.  In lme4 (the
>> successor to nlme, which implements generalized linear MMs that can
>> handle a binomial response), the 'weights' argument is simpler/can be
>> used to specify the denominator or total number of counts:
>>
>> library(lme4)
>>  mod <- glmer(Change_in_proportion_females ~ Proportion_infected + Month
>> + (1 |Site/Month),
>> family=binomial, weights = total_counts, data=...)
>>
>>  (here, including the site-by-month interaction is OK -- it represents
>> the possibility of extra-binomial variance (overdispersion).)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From Chris.Knight at manchester.ac.uk  Tue Oct 13 15:57:32 2015
From: Chris.Knight at manchester.ac.uk (Christopher Knight)
Date: Tue, 13 Oct 2015 13:57:32 +0000
Subject: [R-sig-ME] Random effects correlations and factor reference levels
Message-ID: <4749B551-949C-4E4D-A630-C9C9F44453D2@manchester.ac.uk>

I am fitting mixed effects models where there is a random effect which acts differently on each level of a factor, much as in the Machines example from the nlme package:

library(nlme)

> M1 <- lme(fixed = score ~ Machine, random = ~Machine|Worker, data=Machines)
> VarCorr(M1)
Worker = pdLogChol(Machine)
            Variance   StdDev    Corr
(Intercept) 16.6405306 4.0792806 (Intr) MachnB
MachineB    34.5466908 5.8776433  0.484
MachineC    13.6150244 3.6898543 -0.365  0.297
Residual     0.9246296 0.9615766

I was interpreting these correlations to mean that the estimate of workers? scores on Machine B (or more precisely their BLUPS, interpreted as something like their residuals from the average on Machine B) are weakly positively correlated with their scores on Machine C (r=0.297). Because Machine A is the reference level of the factor ?Machine? (with treatment contrasts), I was also interpreting the ?(Intercept)? to represent Machine A, i.e. that the scores of the workers on Machine A are somewhat positively correlated with their scores on Machine B (r=0.484), but negatively with their scores on Machine C (r=-0.365).

If this were true, I would expect these conclusions to be robust to exactly which machine is the reference level in the contrasts for the Machine factor, but apparently they are not:

> Machines$Machine <- relevel(Machines$Machine, ref = "B")
> M2 <- update(M1)
> VarCorr(M2)
Worker = pdLogChol(Machine)
            Variance   StdDev    Corr
(Intercept) 74.3956398 8.6252907 (Intr) MachnA
MachineA    34.5466902 5.8776433 -0.910
MachineC    35.2950235 5.9409615 -0.882  0.805
Residual     0.9246296 0.9615766

What is going on here/what am I misinterpreting?

As expected, these two models appear to be equivalent by anova(M1,M2), yet the correlation among workers between machines A and B appears to be strongly negative in the second case (r = -0.91), where it seems moderately positive in the first case (r=0.484) and intervals() on the two models suggests no overlap of (admittedly pretty broad) confidence intervals in this case. Add to that the differences in the estimated variance components/standard deviations ? each model has an identical residual, but very different individual values (that for Machine C going from 13.6 to 35) and totals; at the same time the estimate for the variance among workers on Machine B in model M1 (34.5466908)  is suspiciously similar (albeit not quite identical) to the estimate for variance among workers on Machine A in model M2 (34.5466902).

The values are pretty much the same fitting with lmer (though in practice I need the correlation and weights arguments available with lme), which makes it feel like a problem with my interpretation. Or is it really just a case of too little data to resolve such ?subtle parameters clearly?

Dropping the fixed effect doesn?t make things much better and, on the models I am running in anger, there is more data and the differences are even more pronounced. It looks a bit like this issue: http://stats.stackexchange.com/questions/82102/changing-reference-level-for-contrasts-changes-results-in-r-3-0-2-lme4-1-1-2-vs
which was framed in terms of versions but, given that I get very similar issues using nlme and lme4, it doesn?t seem likely to be a version issue here (albeit I don?t have old versions immediately to hand to test this on).

Any insights much appreciated,

Chris

running nlme_3.1-122 in R 3.2.2 on OS X 10.10.5


------------------------------------------------------------------------
Dr Christopher Knight                             Michael Smith Building
Lecturer                                        Faculty of Life Sciences
Tel:  +44 (0)161 2755378                    The University of Manchester
room B.2012                                                  Oxford Road
tinyurl.com/knightFLS/<http://tinyurl.com/knightFLS/>                                Manchester M13 9PT
? . ,,><(((?>                                                         UK
------------------------------------------------------------------------





	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Tue Oct 13 17:08:18 2015
From: paul.debes at utu.fi (paul debes)
Date: Tue, 13 Oct 2015 18:08:18 +0300
Subject: [R-sig-ME] Random effects correlations and factor reference
	levels
In-Reply-To: <4749B551-949C-4E4D-A630-C9C9F44453D2@manchester.ac.uk>
References: <4749B551-949C-4E4D-A630-C9C9F44453D2@manchester.ac.uk>
Message-ID: <op.x6f9n4p8a3mgvf@armadillo>

Hi Chris,

do you really need the treatment contrast?
I think the results based on the treatment contrasts for the random  
effects are more difficult to interpret than what you suggested (I can't  
interpret them either). If you simply remove the intercept: "random =  
~Machine-1|Worker" your interpretations of the worker-score correlations  
between machine levels hold and you get the actual variance estimates for  
each level of machine.

Best,
Paul




On Tue, 13 Oct 2015 16:57:32 +0300, Christopher Knight  
<Chris.Knight at manchester.ac.uk> wrote:

> I am fitting mixed effects models where there is a random effect which  
> acts differently on each level of a factor, much as in the Machines  
> example from the nlme package:
>
> library(nlme)
>
>> M1 <- lme(fixed = score ~ Machine, random = ~Machine|Worker,  
>> data=Machines)
>> VarCorr(M1)
> Worker = pdLogChol(Machine)
>             Variance   StdDev    Corr
> (Intercept) 16.6405306 4.0792806 (Intr) MachnB
> MachineB    34.5466908 5.8776433  0.484
> MachineC    13.6150244 3.6898543 -0.365  0.297
> Residual     0.9246296 0.9615766
>
> I was interpreting these correlations to mean that the estimate of  
> workers? scores on Machine B (or more precisely their BLUPS, interpreted  
> as something like their residuals from the average on Machine B) are  
> weakly positively correlated with their scores on Machine C (r=0.297).  
> Because Machine A is the reference level of the factor ?Machine? (with  
> treatment contrasts), I was also interpreting the ?(Intercept)? to  
> represent Machine A, i.e. that the scores of the workers on Machine A  
> are somewhat positively correlated with their scores on Machine B  
> (r=0.484), but negatively with their scores on Machine C (r=-0.365).
>
> If this were true, I would expect these conclusions to be robust to  
> exactly which machine is the reference level in the contrasts for the  
> Machine factor, but apparently they are not:
>
>> Machines$Machine <- relevel(Machines$Machine, ref = "B")
>> M2 <- update(M1)
>> VarCorr(M2)
> Worker = pdLogChol(Machine)
>             Variance   StdDev    Corr
> (Intercept) 74.3956398 8.6252907 (Intr) MachnA
> MachineA    34.5466902 5.8776433 -0.910
> MachineC    35.2950235 5.9409615 -0.882  0.805
> Residual     0.9246296 0.9615766
>
> What is going on here/what am I misinterpreting?
>
> As expected, these two models appear to be equivalent by anova(M1,M2),  
> yet the correlation among workers between machines A and B appears to be  
> strongly negative in the second case (r = -0.91), where it seems  
> moderately positive in the first case (r=0.484) and intervals() on the  
> two models suggests no overlap of (admittedly pretty broad) confidence  
> intervals in this case. Add to that the differences in the estimated  
> variance components/standard deviations ? each model has an identical  
> residual, but very different individual values (that for Machine C going  
> from 13.6 to 35) and totals; at the same time the estimate for the  
> variance among workers on Machine B in model M1 (34.5466908)  is  
> suspiciously similar (albeit not quite identical) to the estimate for  
> variance among workers on Machine A in model M2 (34.5466902).
>
> The values are pretty much the same fitting with lmer (though in  
> practice I need the correlation and weights arguments available with  
> lme), which makes it feel like a problem with my interpretation. Or is  
> it really just a case of too little data to resolve such ?subtle  
> parameters clearly?
>
> Dropping the fixed effect doesn?t make things much better and, on the  
> models I am running in anger, there is more data and the differences are  
> even more pronounced. It looks a bit like this issue:  
> http://stats.stackexchange.com/questions/82102/changing-reference-level-for-contrasts-changes-results-in-r-3-0-2-lme4-1-1-2-vs
> which was framed in terms of versions but, given that I get very similar  
> issues using nlme and lme4, it doesn?t seem likely to be a version issue  
> here (albeit I don?t have old versions immediately to hand to test this  
> on).
>
> Any insights much appreciated,
>
> Chris
>
> running nlme_3.1-122 in R 3.2.2 on OS X 10.10.5
>
>
> ------------------------------------------------------------------------
> Dr Christopher Knight                             Michael Smith Building
> Lecturer                                        Faculty of Life Sciences
> Tel:  +44 (0)161 2755378                    The University of Manchester
> room B.2012                                                  Oxford Road
> tinyurl.com/knightFLS/<http://tinyurl.com/knightFLS/>                                 
> Manchester M13 9PT
> ? . ,,><(((?>                                                         UK
> ------------------------------------------------------------------------
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland


From Chris.Knight at manchester.ac.uk  Wed Oct 14 12:17:16 2015
From: Chris.Knight at manchester.ac.uk (Christopher Knight)
Date: Wed, 14 Oct 2015 10:17:16 +0000
Subject: [R-sig-ME] Random effects correlations and factor
	reference	levels
In-Reply-To: <op.x6f9n4p8a3mgvf@armadillo>
References: <4749B551-949C-4E4D-A630-C9C9F44453D2@manchester.ac.uk>
	<op.x6f9n4p8a3mgvf@armadillo>
Message-ID: <8536A356-0C09-4A1C-9BA8-850F8907BEAB@manchester.ac.uk>

Thank you, that does indeed make a whole lot more sense!

It would be good to get my head around what the intercept was doing originally (certainly not adding any extra parameters, which is perhaps why I hadn?t tried it), but it seems that that solves the interpretation problem in my real data too (albeit that, unlike the simpler example, the precise numbers aren?t entirely stable to re-specifying the reference level, but changes are associated with changes in the log likelihood and can be tweaked by changing the optimiser).

Thanks again,

Chris


> On 13 Oct 2015, at 16:08, paul debes <paul.debes at utu.fi> wrote:
> 
> Hi Chris,
> 
> do you really need the treatment contrast?
> I think the results based on the treatment contrasts for the random effects are more difficult to interpret than what you suggested (I can't interpret them either). If you simply remove the intercept: "random = ~Machine-1|Worker" your interpretations of the worker-score correlations between machine levels hold and you get the actual variance estimates for each level of machine.
> 
> Best,
> Paul
> 
> 
> 
> 
> On Tue, 13 Oct 2015 16:57:32 +0300, Christopher Knight <Chris.Knight at manchester.ac.uk> wrote:
> 
>> I am fitting mixed effects models where there is a random effect which acts differently on each level of a factor, much as in the Machines example from the nlme package:
>> 
>> library(nlme)
>> 
>>> M1 <- lme(fixed = score ~ Machine, random = ~Machine|Worker, data=Machines)
>>> VarCorr(M1)
>> Worker = pdLogChol(Machine)
>>            Variance   StdDev    Corr
>> (Intercept) 16.6405306 4.0792806 (Intr) MachnB
>> MachineB    34.5466908 5.8776433  0.484
>> MachineC    13.6150244 3.6898543 -0.365  0.297
>> Residual     0.9246296 0.9615766
>> 
>> I was interpreting these correlations to mean that the estimate of workers? scores on Machine B (or more precisely their BLUPS, interpreted as something like their residuals from the average on Machine B) are weakly positively correlated with their scores on Machine C (r=0.297). Because Machine A is the reference level of the factor ?Machine? (with treatment contrasts), I was also interpreting the ?(Intercept)? to represent Machine A, i.e. that the scores of the workers on Machine A are somewhat positively correlated with their scores on Machine B (r=0.484), but negatively with their scores on Machine C (r=-0.365).
>> 
>> If this were true, I would expect these conclusions to be robust to exactly which machine is the reference level in the contrasts for the Machine factor, but apparently they are not:
>> 
>>> Machines$Machine <- relevel(Machines$Machine, ref = "B")
>>> M2 <- update(M1)
>>> VarCorr(M2)
>> Worker = pdLogChol(Machine)
>>            Variance   StdDev    Corr
>> (Intercept) 74.3956398 8.6252907 (Intr) MachnA
>> MachineA    34.5466902 5.8776433 -0.910
>> MachineC    35.2950235 5.9409615 -0.882  0.805
>> Residual     0.9246296 0.9615766
>> 
>> What is going on here/what am I misinterpreting?
>> 
>> As expected, these two models appear to be equivalent by anova(M1,M2), yet the correlation among workers between machines A and B appears to be strongly negative in the second case (r = -0.91), where it seems moderately positive in the first case (r=0.484) and intervals() on the two models suggests no overlap of (admittedly pretty broad) confidence intervals in this case. Add to that the differences in the estimated variance components/standard deviations ? each model has an identical residual, but very different individual values (that for Machine C going from 13.6 to 35) and totals; at the same time the estimate for the variance among workers on Machine B in model M1 (34.5466908)  is suspiciously similar (albeit not quite identical) to the estimate for variance among workers on Machine A in model M2 (34.5466902).
>> 
>> The values are pretty much the same fitting with lmer (though in practice I need the correlation and weights arguments available with lme), which makes it feel like a problem with my interpretation. Or is it really just a case of too little data to resolve such ?subtle parameters clearly?
>> 
>> Dropping the fixed effect doesn?t make things much better and, on the models I am running in anger, there is more data and the differences are even more pronounced. It looks a bit like this issue: http://stats.stackexchange.com/questions/82102/changing-reference-level-for-contrasts-changes-results-in-r-3-0-2-lme4-1-1-2-vs
>> which was framed in terms of versions but, given that I get very similar issues using nlme and lme4, it doesn?t seem likely to be a version issue here (albeit I don?t have old versions immediately to hand to test this on).
>> 
>> Any insights much appreciated,
>> 
>> Chris
>> 
>> running nlme_3.1-122 in R 3.2.2 on OS X 10.10.5
>> 
>> 
>> ------------------------------------------------------------------------
>> Dr Christopher Knight                             Michael Smith Building
>> Lecturer                                        Faculty of Life Sciences
>> Tel:  +44 (0)161 2755378                    The University of Manchester
>> room B.2012                                                  Oxford Road
>> tinyurl.com/knightFLS/<http://tinyurl.com/knightFLS/>                                Manchester M13 9PT
>> ? . ,,><(((?>                                                         UK
>> ------------------------------------------------------------------------
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -- 
> Paul Debes
> DFG Research Fellow
> University of Turku
> Department of Biology
> It?inen Pitk?katu 4
> 20520 Turku
> Finland
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From lindeh at uw.edu  Mon Oct 12 21:13:44 2015
From: lindeh at uw.edu (Hannah L. Linder)
Date: Mon, 12 Oct 2015 12:13:44 -0700
Subject: [R-sig-ME] GAMM convergence issue with temporal covariate
Message-ID: <CAF0=RbauKGU3JOsPxBkuka=MBZZU0rZNkAyYt_or4p1h25wmBQ@mail.gmail.com>

Hello,

I am working with a fairly simple model:

gamm(sv~s(day,bs="cr")+range+s(time,bs="cc"),correlation=corARMA(p=2,q=2)

In which day is Julian Day over one month, range is tidal range, and time
is coded 1-24 for hour of day.

I continually have singularity convergence problems with this model (the
error is:  nlminb
problem, convergence error code = 1 message = false convergence (8).

Increasing iterations does not help. When I run msVerbose I notice that
"day" covariate output values (there are two but I'm not completely sure
how to interpret them) keep increasing until the convergence errors occur.
I have also noticed that setting k=5 for the "day" covariate does not help
the convergence problem, but k=9 does (the default is 10) or k =20. I would
greatly appreciate any advice or recommendations on what may be causing the
problem.

Thank-you very much,
Hannah

	[[alternative HTML version deleted]]


From jfhenson1 at gmail.com  Wed Oct 14 18:46:43 2015
From: jfhenson1 at gmail.com (James Henson)
Date: Wed, 14 Oct 2015 11:46:43 -0500
Subject: [R-sig-ME] contrasts among simple effects
Message-ID: <CABPq8JMYg79N_My8ue50OYkgjyZO3g=cgyXxieXG+Ti8750DPg@mail.gmail.com>

Greetings R Community

Apologize for previously sending a csv file.

My goal is to make orthogonal contrasts among simple effects in analysis of
repeated measures data.  The SAS publication, on page 1224, shows how to
make this type of contrasts in SAS.  But, my search of books about repeated
measures analysis using R, and on-line has not yielded a methodology.
Hopefully, someone can direct me to a book or publication that will show me
a methodology.

Statistical Analysis of Repeated Measures Data Using SAS Procedures

http://cslras.pbworks.com/f/littell_j_anim_sci_76_4_analysis_of_repeated_measures_using_sas.pdf



Attached is a txt data file (file name = heart_rate.txt).  My code for the
repeated measures analysis is below.

library("nlme")

# with AR1 variance/covariance structure, with ordered statement

heartRate$time <- factor(heartRate$time)

model2a <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
=corAR1(, form=~1|person), data = heartRate)

summary(model2a)

anova(model2a)

Making a new variable ?simple? that merges the variables drug and time will
enable me to make orthogonal contrasts among the simple effects.  But, when
using the variable ?simple? as the independent variable, the data will no
longer be fitted to the AR1 variance/covariance structure.

Thanks.

Best regards,

James F.Henson
-------------- next part --------------
drug	person	time	HR
a	1	1	72
a	4	1	78
a	7	1	71
a	10	1	72
a	13	1	66
a	16	1	74
a	19	1	62
a	22	1	69
b	2	1	85
b	5	1	82
b	8	1	71
b	11	1	83
b	14	1	86
b	17	1	85
b	20	1	79
b	23	1	83
c	3	1	69
c	6	1	66
c	9	1	84
c	12	1	80
c	15	1	72
c	18	1	65
c	21	1	75
c	24	1	71
a	1	2	86
a	4	2	83
a	7	2	82
a	10	2	83
a	13	2	79
a	16	2	83
a	19	2	73
a	22	2	75
b	2	2	86
b	5	2	86
b	8	2	78
b	11	2	88
b	14	2	85
b	17	2	82
b	20	2	83
b	23	2	84
c	3	2	73
c	6	2	62
c	9	2	90
c	12	2	81
c	15	2	72
c	18	2	62
c	21	2	69
c	24	2	70
a	1	3	81
a	4	3	88
a	7	3	81
a	10	3	83
a	13	3	77
a	16	3	84
a	19	3	78
a	22	3	76
b	2	3	83
b	5	3	80
b	8	3	70
b	11	3	79
b	14	3	76
b	17	3	83
b	20	3	80
b	23	3	78
c	3	3	72
c	6	3	67
c	9	3	88
c	12	3	77
c	15	3	69
c	18	3	65
c	21	3	69
c	24	3	65
a	1	4	77
a	4	4	81
a	7	4	75
a	10	4	69
a	13	4	66
a	16	4	77
a	19	4	70
a	22	4	70
b	2	4	80
b	5	4	84
b	8	4	75
b	11	4	81
b	14	4	76
b	17	4	80
b	20	4	81
b	23	4	81
c	3	4	74
c	6	4	73
c	9	4	87
c	12	4	72
c	15	4	70
c	18	4	61
c	21	4	68
c	24	4	63

From pauljohn32 at gmail.com  Wed Oct 14 19:02:13 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 14 Oct 2015 12:02:13 -0500
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
Message-ID: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>

Every now and then, I come back to my old project that simulates
multi-level data.  I've asked about this from time to time here.

Today I noticed some unfamiliar convergence problems in lme4_1.1-9.  I
updated to lme4-1.1-10 and got new and different problems. Rescaling
variables did solve convergence issues in penultimate version, but not
any more.

Here's my data simulation code. Appears to me this should work.  I'm
giving lots of groups, plenty of observations in each one. Maybe my
random effect variance is too small, but it seems to me that should
not drive convergence problems. I've got Stata output for comparison
below.

Am I setting conditions that make this illconditioned?


library(MASS) ## for rmvnorm
set.seed(1234)

## Clusters
M <- 100
## Minimum per cluster
Mmin <- 134
## Variance in number of members per cluster
Mvar <- 20
N <- Mmin + rpois(M, lambda = Mvar)

Mcolors <- rainbow(M)


## Create Mind and Iind indexes for book keeping.
Mind <- unlist(lapply(1:M, function(x) rep(x, each = N[x])))
Iind <- unlist(lapply(1:M, function(x) seq(1, N[x], by = 1)))

##Create 3 variables from a multivariate Normal with these
## characteristics
Xmeans <- c(100, 200, 150)
Xsds <- c(20, 30, 40)
Xrho12 <- 0.4
Xrho13 <- 0.2
Xrho23 <- 0.0
Xcorr.mat <- diag(1, 3)
Xcorr.mat[1,2] <- Xcorr.mat[2,1] <- Xrho12
Xcorr.mat[1,3] <- Xcorr.mat[3,1] <- Xrho13
Xcorr.mat[2,3] <- Xcorr.mat[3,2] <- Xrho23
if(!isSymmetric(Xcorr.mat))stop("Xcorr.mat is not symmetric")

Xsigma <- diag(Xsds) %*% Xcorr.mat %*% diag(Xsds)
X.mat <- mvrnorm(n = sum(N), mu = Xmeans, Sigma = Xsigma)
dimnames(X.mat)[[2]] <- c("x1", "x2", "x3")

## The true fixed effects of beta0, beta1, beta2, beta3 in
## y = beta0 + beta1*x1 + beta2*x2 + beta3*x3
beta <- c(1.5, 0.25, -0.2, 0.05)

## Standard deviation of error term at individual level
STDE <- 25

## Create a dependent variable that has no clustering effects.
##     FIXED Part                 +  RANDOM PART
y1 <- cbind(1, X.mat) %*% beta + rnorm(sum(N), m = 0, s = STDE)
dat <- cbind(data.frame(Mind, Iind, y1), as.data.frame(X.mat))
rownames(dat) <- paste(dat$Mind, dat$Iind, sep=".") ##may help bookkeeping later
rm(Mind, Iind, y1, X.mat) ## cleanup workspace

summary(lm(y1 ~ x1 + x2 + x3, data=dat))

## Layer on additive group level error in y2 and y3
## Parameters for random effects:
## STDEb0: standard deviation of clustered intercepts.
STDEb0 <- 0.5
## STDEb1: standard deviation of slopes across cluster units
STDEb1 <- 0.25
Mrho <- 0.2
## I'm tempted to get fancy here with a matrix for STDEb0, STDEb1, and
## Mrho. It would pay off, I expect. But be harder to teach.
Msigma <- diag(c(STDEb0, STDEb1)) %*% matrix(c(1, Mrho, Mrho, 1), 2,
2) %*% diag(c(STDEb0, STDEb1))
Mreffects <- mvrnorm(M, mu = c(0, 0), Sigma = Msigma)
colnames(Mreffects) <- c("b0", "b1")

## In y2, include random intercept
dat$y2 <- dat$y1 + Mreffects[ ,"b0"][dat$Mind]

## In y3, add in random slope effect
dat$y3 <- dat$y2 +  dat$x1 * Mreffects[ ,"b1"][dat$Mind]

## Do some diagnostics on Mreffects
plot(Mreffects[, 1], Mreffects[,2], xlab = "Intercept Random Effect",
ylab = "Slope Random Effect",  main = "True Random Effects")
## library(rockchalk)
## summarize(Mreffects)
summary(Mreffects)
apply(Mreffects, 2, sd)
cor(Mreffects)

plot(Mreffects[ ,"b0"][dat$Mind], dat$x1 * Mreffects[
,"b1"][dat$Mind], col=dat$Mind,
     main = "Random Slopes and Intercepts",
     xlab = "Intercept Random Effect (b0)",
     ylab = "Slope Random Effect (b1*x)")

## The "grand" regression?
m1 <- lm(y3 ~ x1 + x2 + x3, data=dat)
summary(m1)

## The "dummy variable" regression?
m2 <- lm(y3 ~ x1 + x2 + x3 + as.factor(Mind), data=dat)
summary(m2)


library(lme4)
## M separate regressions, with 3 predictors
m3list <- lmList(y3 ~ x1 + x2 + x3 | Mind, data = dat, pool = FALSE)

## Predicted values set x2 and x3 at their cluster-specific means.

plot(y3 ~ x1, data = dat, col = Mcolors[Mind], lwd = 0.6, main = "lm
on Separate Clusters")
for( i in seq_along(m3list)){
    m3mf <- model.frame(m3list[[i]]) #data set for group i
    x1range <- range(m3mf$x1) ## use group-specific ranges this time
    pgroup <- predict( m3list[[i]], newdata = data.frame(x1=x1range,
x2=mean(m3mf$x2), x3=mean(m3mf$x3)))
    lines(x1range, pgroup, col=Mcolors[i])
}

## If a cluster has 3 or fewer cases, this warning will appear
## Warning message:
## In predict.lm(m3list[[i]], newdata = data.frame(x1 = x1range, x2 =
mean(m3mf$x2),  :
##   prediction from a rank-deficient fit may be misleading


## Record keeping
m3newdat <- lapply(m3list, function(x) {
    m3mf <- model.frame(x)
    ndf = data.frame(x1 = range(m3mf$x1), x2 = mean(m3mf$x2), x3 =
mean(m3mf$x3))
    ndf$m3pred <- predict(x, newdata = ndf)
    ndf} )
m3newdat <- do.call("rbind", m3newdat)
## Recover the Mind value by butchering the row names
m3newdat$Mind <-  as.integer(gsub("\\.[0-9].*", "", row.names(m3newdat)))

## Draw new graphs on a new device, so we can compare
dev.new()


##
## Estimate this as a mixed-effects model with lme4

## mm2: Just the random intercept, no random slope
mm2 <- lmer(y2 ~ x1 + x2 + x3 + (1 | Mind), data=dat)
summary(mm2)
mm2VarCorr <- VarCorr(mm2)
mm2VarCorr

cor(fitted(mm2), dat$y2)

## Both random intercept and random slope, not correlated with each other
mm3 <- lmer( y3 ~ x1 + x2 + x3 + (1|Mind) + (0 + x1 | Mind), data=dat,
verbose=3)

## That produces a non-convergent model.
## At return
## eval: 479 fn:      153252.65 par: 0.0237800 0.00122944
## Warning messages:
## 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
##   Model failed to converge with max|grad| = 1.54298 (tol = 0.002,
component 1)
## 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
##   Model is nearly unidentifiable: very large eigenvalue
##  - Rescale variables?

## Ok, lets scale them
dat[ , c("x1s", "x2s", "x3s")] <- lapply(dat[, c("x1", "x2", "x3")], scale)
dat$y3s <- scale(dat$y3)
mm3s <- lmer( y3s ~ x1s + x2s + x3s + (1 | Mind) + (0 + x1 | Mind),
            data=dat, verbose = 3)

mm4 <- lmer( y3 ~ x1 + x2 + x3 + (x1 | Mind), data = dat, verbose = 2)
summary(mm4)

mm4s <- lmer( y3s ~ x1s + x2s + x3s + (x1s | Mind), data = dat, verbose = 2)
summary(mm4)

Here's what I see at the end.

At return
eval: 453 fn:      34253.131 par: 1.45320e-05 0.00891596
Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00204447 (tol = 0.002,
component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 15.04

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.1-10  Matrix_1.2-2 MASS_7.3-44

loaded via a namespace (and not attached):
[1] compiler_3.2.2  minqa_1.2.4     tools_3.2.2     Rcpp_0.12.1
[5] splines_3.2.2   nlme_3.1-122    grid_3.2.2      nloptr_1.0.4
[9] lattice_0.20-33


Earlier today, with the previous lme4, the scaling of the variables
produced a convergent model.

Upon exporting the data to Stata 14, we observe:


. mixed y1 x1 x2 x3 || Mind: x1, cov(unstruct)

Performing EM optimization:

Performing gradient-based optimization:

Iteration 0:   log likelihood = -71367.808
Iteration 1:   log likelihood = -71366.333
Iteration 2:   log likelihood = -71366.311
Iteration 3:   log likelihood = -71366.308
Iteration 4:   log likelihood = -71366.304
Iteration 5:   log likelihood = -71366.304

Computing standard errors:

Mixed-effects ML regression                     Number of obs      =     15419
Group variable: Mind                            Number of groups   =       100

                                                Obs per group: min =       146
                                                               avg =     154.2
                                                               max =       169


                                                Wald chi2(3)       =   1095.11
Log likelihood = -71366.304                     Prob > chi2        =    0.0000

------------------------------------------------------------------------------
          y1 |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |   .2534893   .0110537    22.93   0.000     .2318245    .2751541
          x2 |  -.1914348   .0072503   -26.40   0.000    -.2056452   -.1772245
          x3 |    .050516   .0051398     9.83   0.000     .0404421    .0605899
       _cons |  -.8820319   1.575815    -0.56   0.576    -3.970573    2.206509
------------------------------------------------------------------------------

------------------------------------------------------------------------------
  Random-effects Parameters  |   Estimate   Std. Err.     [95% Conf. Interval]
-----------------------------+------------------------------------------------
Mind: Unstructured           |
                     var(x1) |   7.47e-07          .             .           .
                  var(_cons) |   .2079643          .             .           .
               cov(x1,_cons) |  -.0003941          .             .           .
-----------------------------+------------------------------------------------
               var(Residual) |   613.2876          .             .           .
------------------------------------------------------------------------------
LR test vs. linear regression:       chi2(3) =     0.06   Prob > chi2 = 0.9964

Note: LR test is conservative and provided only for reference.


Fixed parameter estimates are good, and the residual variance is not
far wrong.  The estimated variance of the slope random effect is
miniscule. But there's no convergence error.

Maybe I'm not generating the random effect for the regression on x1
correctly.  In the simulated data,

> rockchalk::summarize(Mreffects)
$numerics
     Mreffects_1 Mreffects_2
0%       -1.4122     -0.8380
25%      -0.3799     -0.1887
50%      -0.0438     -0.0244
75%       0.2899      0.0976
100%      0.9951      0.5505
mean     -0.0615     -0.0495
sd        0.4650      0.2455
var       0.2162      0.0602
NA's      0.0000      0.0000
N       100.0000    100.0000

$factors
NULL

> cor(Mreffects)
          b0        b1
b0 1.0000000 0.1445065
b1 0.1445065 1.0000000



-- 
Paul E. Johnson
Professor, Political Science        Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org              http://crmda.ku.edu


From highstat at highstat.com  Wed Oct 14 19:19:40 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 14 Oct 2015 19:19:40 +0200
Subject: [R-sig-ME] GAMM convergence issue with temporal covariate
In-Reply-To: <mailman.5651.1444842140.3797.r-sig-mixed-models@r-project.org>
References: <mailman.5651.1444842140.3797.r-sig-mixed-models@r-project.org>
Message-ID: <561E8EAC.70004@highstat.com>











------------------------------

Message: 2
Date: Mon, 12 Oct 2015 12:13:44 -0700
From: "Hannah L. Linder" <lindeh at uw.edu>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] GAMM convergence issue with temporal covariate
Message-ID:
	<CAF0=RbauKGU3JOsPxBkuka=MBZZU0rZNkAyYt_or4p1h25wmBQ at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hello,

I am working with a fairly simple model:

gamm(sv~s(day,bs="cr")+range+s(time,bs="cc"),correlation=corARMA(p=2,q=2)

In which day is Julian Day over one month, range is tidal range, and time
is coded 1-24 for hour of day.

I continually have singularity convergence problems with this model (the
error is:  nlminb
problem, convergence error code = 1 message = false convergence (8).

Increasing iterations does not help. When I run msVerbose I notice that
"day" covariate output values (there are two but I'm not completely sure
how to interpret them) keep increasing until the convergence errors occur.
I have also noticed that setting k=5 for the "day" covariate does not help
the convergence problem, but k=9 does (the default is 10) or k =20. I would
greatly appreciate any advice or recommendations on what may be causing the
problem.

Thank-you very much,
Hannah
--------



Hannah,

CorARMA(p = 2, q = 2) is not an easy one for the optimisation routine. Try simplifying it.
Additionally...the ARMA residual correlation structure may be competing with the time smoothers.
You could try to use fixed values for the ARMA parameters.


Alain Zuur


From tom_philippi at nps.gov  Wed Oct 14 20:49:49 2015
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Wed, 14 Oct 2015 11:49:49 -0700
Subject: [R-sig-ME] GAMM convergence issue with temporal covariate
In-Reply-To: <561E8EAC.70004@highstat.com>
References: <mailman.5651.1444842140.3797.r-sig-mixed-models@r-project.org>
	<561E8EAC.70004@highstat.com>
Message-ID: <CAM9kYqhu7imctbicJ1=J4AnScmrnxh2db6CkgU2OnG45vKfQ2w@mail.gmail.com>

Is your range tidal height at the same location at the time of sampling
(time & day), or variation among sites in elevation above some datum at the
(same) time of sampling?  Or does it vary by day but not by time?

If the former, given the predictable way that the tide cycle shifts from
one day to the next, for some times of the year you're going to have a
tough time separating out an effect of range from smoothed effects of day
and time.  If you need to visualize this, pull the NOAA 6 minute tidal
predictions from somewhere near your site (I can send R code to do this).
Or, plot a simple heatmap of your data:
    lattice::levelplot(range~day+time,data=dsn)

Also, be careful with your cyclic fit on time of day.
    s(time,bs="cc")
If your time values are not evenly spaced (e.g., full 0:24) you are likely
to need to specify knots to let gamm know that 0 and 24 are the ends to
match.  My first guess would be that you need:
   knots=list(time=c(0,24))
but I don't know your data, so your mileage will vary.

Tom 2

On Wed, Oct 14, 2015 at 10:19 AM, Highland Statistics Ltd <
highstat at highstat.com> wrote:

>
>
>
>
>
>
>
>
>
>
> ------------------------------
>
> Message: 2
> Date: Mon, 12 Oct 2015 12:13:44 -0700
> From: "Hannah L. Linder" <lindeh at uw.edu>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] GAMM convergence issue with temporal covariate
> Message-ID:
>         <CAF0=RbauKGU3JOsPxBkuka=
> MBZZU0rZNkAyYt_or4p1h25wmBQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Hello,
>
> I am working with a fairly simple model:
>
> gamm(sv~s(day,bs="cr")+range+s(time,bs="cc"),correlation=corARMA(p=2,q=2)
>
> In which day is Julian Day over one month, range is tidal range, and time
> is coded 1-24 for hour of day.
>
> I continually have singularity convergence problems with this model (the
> error is:  nlminb
> problem, convergence error code = 1 message = false convergence (8).
>
> Increasing iterations does not help. When I run msVerbose I notice that
> "day" covariate output values (there are two but I'm not completely sure
> how to interpret them) keep increasing until the convergence errors occur.
> I have also noticed that setting k=5 for the "day" covariate does not help
> the convergence problem, but k=9 does (the default is 10) or k =20. I would
> greatly appreciate any advice or recommendations on what may be causing the
> problem.
>
> Thank-you very much,
> Hannah
> --------
>
>
>
> Hannah,
>
> CorARMA(p = 2, q = 2) is not an easy one for the optimisation routine. Try
> simplifying it.
> Additionally...the ARMA residual correlation structure may be competing
> with the time smoothers.
> You could try to use fixed values for the ARMA parameters.
>
>
> Alain Zuur
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Thu Oct 15 15:26:34 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 15 Oct 2015 15:26:34 +0200
Subject: [R-sig-ME] error in MCMCglmm (regarding priors)
Message-ID: <CALC46t95H0iNmUw1oYwV6CWjHy+j9P_C5uUd5-Y=9XFxmXK_Sw@mail.gmail.com>

Hi all,
I'm running this model with this prior:

prior1=list(R=list(V=diag(4),nu=1.002),G=list(G1=list(V=diag(4),nu=1.002)))

mcmc1=MCMCglmm(cbind(t1,t2,t3,t4)~(trait-1)+trait:season+trait:tl_s+trait:year,
               random=~us(trait):id,
               rcov=~us(trait):units,
               data=widew2t,
               family=c("gaussian","gaussian","gaussian","gaussian"),
               nitt=100000,thin=100,burnin=10000,
               prior=prior1,
               pr=TRUE)

And I get two different errors (sometimes one, sometimes the other):

Error in MCMCglmm(cbind(t1,t2,t3,t4) ~ (trait - 1) +  :
  Mixed model equations singular: use a (stronger) prior

Error in MCMCglmm(cbind(t1,t2,t3,t4) ~ (trait - 1) +  :
  ill-conditioned cross-product: can't form Cholesky factor

I tried other priors like this one:

prior1b<-list(R=list(V=diag(4), nu=4,
alpha.mu=c(0,0),alpha.V=diag(4)*1000),G=list(G1=list(V=diag(4),
nu=4, alpha.mu=c(0,0),alpha.V=diag(4)*1000)))

But still I get the same error messages. I tried with scaled response
variables and still it doesn't work. The only continuous explanatory
variable is already scaled.

Can anyone please help to specify correct priors for this model? Where does
the problme come from?

Thanks

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Thu Oct 15 16:49:51 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 15 Oct 2015 09:49:51 -0500
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
In-Reply-To: <alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>
References: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
	<alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>
Message-ID: <CAErODj_rZM0frhbJ0rExZhmZUyeMfwOaKNVQ1LijAi9+omQhUw@mail.gmail.com>

On Wed, Oct 14, 2015 at 7:19 PM, David Duffy
<David.Duffy at qimrberghofer.edu.au> wrote:
> Is it because Mind is not declared a factor?
>
> dat$Mind <- factor(dat$Mind)
> lmer( y3s ~ x1s + x2s + x3s + (x1s | Mind), data = dat)
> Linear mixed model fit by REML ['lmerMod']
> Formula: y3s ~ x1s + x2s + x3s + (x1s | Mind)
>    Data: dat
> REML criterion at convergence: 33271.78
> Random effects:
>  Groups   Name        Std.Dev. Corr
>  Mind     (Intercept) 0.6837
>           x1s         0.1373   1.00
>  Residual             0.6997
> Number of obs: 15419, groups:  Mind, 100
> Fixed Effects:
> (Intercept)          x1s          x2s          x3s
>   -0.003039     0.117080    -0.163680     0.055911
>
>
> | David Duffy (MBBS PhD)
> | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
> | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
> | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A

Interesting. I think there's a ghost in the machine.

I see no benefit.

The unscaled one still fails:

> dat$Mind <- as.factor(dat$Mind)
> mm3 <- lmer( y3 ~ x1 + x2 + x3 + (1|Mind) + (0 + x1 | Mind), data=dat, verbose=3)

...
350:     143253.09: 9.88456e-06 0.00975148
351:     143253.09: 9.88260e-06 0.00975168
352:     143253.09: 9.69049e-06 0.00975152
353:     143253.09: 9.44279e-06 0.00975152
354:     143253.09: 9.61561e-06 0.00975152
At return
eval: 354 fn:      143253.09 par: 9.44279e-06 0.00975152
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?

And the scaled one is still a failure on my system

dat[ , c("x1s", "x2s", "x3s")] <- lapply(dat[, c("x1", "x2", "x3")], scale)
dat$y3s <- scale(dat$y3)
mm3 <- lmer( y3s ~ x1s + x2s + x3s + (1 | Mind) + (0 + x1 | Mind),
            data=dat, verbose = 3)

rho:  2.0e-07 eval: 186 fn:      33271.8 par: 0.00000 0.00975124
187:     33271.783:  0.00000 0.00975151
188:     33271.783: 5.40934e-07 0.00975153
189:     33271.783: 1.08231e-06 0.00975153
190:     33271.783: 6.32312e-07 0.00975153
At return
eval: 190 fn:      33271.783 par: 5.40934e-07 0.00975153
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?


Since you don't get errors, I wonder if it means you are using
different version of R, or lmer?  Can we see your sessionInfo for
comparison:


> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 15.04

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.1-10  Matrix_1.2-2 MASS_7.3-44

loaded via a namespace (and not attached):
[1] minqa_1.2.4     compiler_3.2.2  tools_3.2.2     Rcpp_0.12.1
[5] splines_3.2.2   nlme_3.1-122    grid_3.2.2      nloptr_1.0.4
[9] lattice_0.20-33


-- 
Paul E. Johnson
Professor, Political Science        Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org              http://crmda.ku.edu


From qiujing2004 at gmail.com  Fri Oct 16 05:13:50 2015
From: qiujing2004 at gmail.com (qiujing2004 at gmail.com)
Date: Thu, 15 Oct 2015 23:13:50 -0400
Subject: [R-sig-ME] How to check the iterative history of convergence and
	change convergence criterion in glmmadmb
Message-ID: <2C406E16-AAF6-48D9-ABCB-AB8156B19E4A@gmail.com>

Dear listers,
> 
> I am using glmmadmb to fit negative binomial mixed effects model to my data. However it fails to converge sometimes. I want to understand what is causing the failure of convergence by first of all checking  whether it really fails to converge or just converges very slowly?? when I fit the data using was glmmmix?? the iteration history  shows that my model does converges but fail to meet the default convergency criteria. When I relax the convergence criterion, it converges well.  
> 
> Is there anyway I can find the iteration history in glmmadmb as well? And can I change the default convergence criterion?
> 
> Thanks!
> 
> Jing

Jing
	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Oct 16 11:56:24 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 16 Oct 2015 11:56:24 +0200
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
In-Reply-To: <CAErODj_rZM0frhbJ0rExZhmZUyeMfwOaKNVQ1LijAi9+omQhUw@mail.gmail.com>
References: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
	<alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>
	<CAErODj_rZM0frhbJ0rExZhmZUyeMfwOaKNVQ1LijAi9+omQhUw@mail.gmail.com>
Message-ID: <CAJuCY5z0sawkR+7Tt3g0ynB6j4fpcjRN6o+f8iF2wcAhxBqb-A@mail.gmail.com>

Dear Paul,

I can reproduce the problem with lme4_1.1-9 and Matrix_1.2-3.

Lowering the SE of the noise solved the covergence issues. So I expect that
a low signal to noise ratio is causing the false convergence.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-15 16:49 GMT+02:00 Paul Johnson <pauljohn32 at gmail.com>:

> On Wed, Oct 14, 2015 at 7:19 PM, David Duffy
> <David.Duffy at qimrberghofer.edu.au> wrote:
> > Is it because Mind is not declared a factor?
> >
> > dat$Mind <- factor(dat$Mind)
> > lmer( y3s ~ x1s + x2s + x3s + (x1s | Mind), data = dat)
> > Linear mixed model fit by REML ['lmerMod']
> > Formula: y3s ~ x1s + x2s + x3s + (x1s | Mind)
> >    Data: dat
> > REML criterion at convergence: 33271.78
> > Random effects:
> >  Groups   Name        Std.Dev. Corr
> >  Mind     (Intercept) 0.6837
> >           x1s         0.1373   1.00
> >  Residual             0.6997
> > Number of obs: 15419, groups:  Mind, 100
> > Fixed Effects:
> > (Intercept)          x1s          x2s          x3s
> >   -0.003039     0.117080    -0.163680     0.055911
> >
> >
> > | David Duffy (MBBS PhD)
> > | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax:
> -0101
> > | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
> > | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A
>
> Interesting. I think there's a ghost in the machine.
>
> I see no benefit.
>
> The unscaled one still fails:
>
> > dat$Mind <- as.factor(dat$Mind)
> > mm3 <- lmer( y3 ~ x1 + x2 + x3 + (1|Mind) + (0 + x1 | Mind), data=dat,
> verbose=3)
>
> ...
> 350:     143253.09: 9.88456e-06 0.00975148
> 351:     143253.09: 9.88260e-06 0.00975168
> 352:     143253.09: 9.69049e-06 0.00975152
> 353:     143253.09: 9.44279e-06 0.00975152
> 354:     143253.09: 9.61561e-06 0.00975152
> At return
> eval: 354 fn:      143253.09 par: 9.44279e-06 0.00975152
> Warning message:
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
>
> And the scaled one is still a failure on my system
>
> dat[ , c("x1s", "x2s", "x3s")] <- lapply(dat[, c("x1", "x2", "x3")], scale)
> dat$y3s <- scale(dat$y3)
> mm3 <- lmer( y3s ~ x1s + x2s + x3s + (1 | Mind) + (0 + x1 | Mind),
>             data=dat, verbose = 3)
>
> rho:  2.0e-07 eval: 186 fn:      33271.8 par: 0.00000 0.00975124
> 187:     33271.783:  0.00000 0.00975151
> 188:     33271.783: 5.40934e-07 0.00975153
> 189:     33271.783: 1.08231e-06 0.00975153
> 190:     33271.783: 6.32312e-07 0.00975153
> At return
> eval: 190 fn:      33271.783 par: 5.40934e-07 0.00975153
> Warning message:
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
>
>
> Since you don't get errors, I wonder if it means you are using
> different version of R, or lmer?  Can we see your sessionInfo for
> comparison:
>
>
> > sessionInfo()
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 15.04
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_1.1-10  Matrix_1.2-2 MASS_7.3-44
>
> loaded via a namespace (and not attached):
> [1] minqa_1.2.4     compiler_3.2.2  tools_3.2.2     Rcpp_0.12.1
> [5] splines_3.2.2   nlme_3.1-122    grid_3.2.2      nloptr_1.0.4
> [9] lattice_0.20-33
>
>
> --
> Paul E. Johnson
> Professor, Political Science        Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org              http://crmda.ku.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Oct 16 13:24:23 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 16 Oct 2015 13:24:23 +0200
Subject: [R-sig-ME] contrasts among simple effects
In-Reply-To: <CABPq8JMYg79N_My8ue50OYkgjyZO3g=cgyXxieXG+Ti8750DPg@mail.gmail.com>
References: <CABPq8JMYg79N_My8ue50OYkgjyZO3g=cgyXxieXG+Ti8750DPg@mail.gmail.com>
Message-ID: <CAJuCY5zCNCDTf1jQh6ZkPv35pb321Bg0xvrXm2jA4XSwDFqUdg@mail.gmail.com>

Dear James,

I think that you need to specify the order of the data as well. corAR1(form
= ~time|person). Otherwise the order of the observations as present in the
data is used.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-14 18:46 GMT+02:00 James Henson <jfhenson1 at gmail.com>:

> Greetings R Community
>
> Apologize for previously sending a csv file.
>
> My goal is to make orthogonal contrasts among simple effects in analysis of
> repeated measures data.  The SAS publication, on page 1224, shows how to
> make this type of contrasts in SAS.  But, my search of books about repeated
> measures analysis using R, and on-line has not yielded a methodology.
> Hopefully, someone can direct me to a book or publication that will show me
> a methodology.
>
> Statistical Analysis of Repeated Measures Data Using SAS Procedures
>
>
> http://cslras.pbworks.com/f/littell_j_anim_sci_76_4_analysis_of_repeated_measures_using_sas.pdf
>
>
>
> Attached is a txt data file (file name = heart_rate.txt).  My code for the
> repeated measures analysis is below.
>
> library("nlme")
>
> # with AR1 variance/covariance structure, with ordered statement
>
> heartRate$time <- factor(heartRate$time)
>
> model2a <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~1|person), data = heartRate)
>
> summary(model2a)
>
> anova(model2a)
>
> Making a new variable ?simple? that merges the variables drug and time will
> enable me to make orthogonal contrasts among the simple effects.  But, when
> using the variable ?simple? as the independent variable, the data will no
> longer be fitted to the AR1 variance/covariance structure.
>
> Thanks.
>
> Best regards,
>
> James F.Henson
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Fri Oct 16 19:44:09 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 16 Oct 2015 17:44:09 +0000
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
In-Reply-To: <CAJuCY5z0sawkR+7Tt3g0ynB6j4fpcjRN6o+f8iF2wcAhxBqb-A@mail.gmail.com>
References: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
	<alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>
	<CAErODj_rZM0frhbJ0rExZhmZUyeMfwOaKNVQ1LijAi9+omQhUw@mail.gmail.com>
	<CAJuCY5z0sawkR+7Tt3g0ynB6j4fpcjRN6o+f8iF2wcAhxBqb-A@mail.gmail.com>
Message-ID: <CAO7JsnS=7zLOSxtEPP2f5r5zZ8ZrwnRAj8gY10rzyTixAUJjiw@mail.gmail.com>

Instead of saying  "the unscaled one still fails", Paul, it would be better
to say that the unscaled model produces an warning about convergence.  In
some cases it is easy to verify that the algorithm has converged; in other
cases it isn't.

As an aside, when we were developing nlme I often needed to alert people to
the other case - declaring convergence when in fact the algorithm had not
converged.  Many people told us how superior the nonmem software was to the
nlme package because nonmem always converged, which was true in the sense
that it always declared convergence but it did that whether or not it was
anywhere close to the optimum.

If you look at the trace of the parameters for your unscaled case, the
fiinal values are effectively on the boundary.  Those two parameters are
ratios of standard deviations and must be non-negative.  The first value is
the standard deviation of the random effects for the intercept divided by
the standard deviation of the per-observation random noise term.  There two
standard deviations are on the same scale, which is the scale of the
response.  A value of 5e-7 is essentially zero.  In the MixedModels package
for Julia I check after convergence has been declared whether there are
small values in the parameter vector and, if so, set them to zero and check
that the objective has not been increased.  Almost all the time setting
these small values to zero decreases the objective so, instead of reporting
this ratio as 5e-7 it reports the more easily recognized value of zero.

Regarding the warning I don't think the calculations used here are
meaningful for convergence on the boundary.  There are different conditions
to be met when you converge to an interior point and when you converge on
the boundary.

Colin Longhurst and i have been checking the performance of various
optimizers used in R and in Julia for fitting linear mixed-effects models.
The approach is simple - we use whatever examples we can find in the
literature and fit them using different optimizers that are available in
the two languages.  The results are in a package called "Timings" available
at

https://github.com/Stat990-033/Timings

The results are in a directory called JSON of the installed package.  (Not
surprisingly, the results are saved in Javascript Object Notation,
abbreviated JSON).

I would like to add your example and its timings if i may.  To be sure that
we are fitting the same model I have

> str(dat)'data.frame':	15419 obs. of  8 variables:
 $ Mind: int  1 1 1 1 1 1 1 1 1 1 ...
 $ Iind: num  1 2 3 4 5 6 7 8 9 10 ...
 $ y1  : num  -37.037 -24.231 -0.254 -41.583 26.973 ...
 $ x1  : num  75.3 120 103.2 106.5 89.6 ...
 $ x2  : num  199 202 214 232 226 ...
 $ x3  : num  128 156 190 158 103 ...
 $ y2  : num  -38.45 -25.64 -1.67 -43 25.56 ...

$ y3 : num -31.74 -14.96 7.52 -33.51 33.54 ...

and the result of fitting

lmer(formula = y3 ~ 1 + x1 + x2 + x3 + (1 | Mind) + (0 + x1 | Mind),
data = dat, verbose = 3L)


ends with

318:     143253.09: 1.22600e-06 0.00975153
319:     143253.09:  0.00000 0.00975152
320:     143253.09: 1.12044e-07 0.00975136
321:     143253.09: 1.82473e-07 0.00975160
322:     143253.09:  0.00000 0.00975153
At return
eval: 322 fn:      143253.09 par:  0.00000 0.00975153Warning
message:In checkConv(attr(opt, "derivs"), opt$par, ctrl =
control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?


(Notice that in my case the first value does come out as 0.  Also the
number of iterations are different.)


I am using

other attached packages:

[1] lme4_1.1-10  Matrix_1.2-2 MASS_7.3-44


loaded via a namespace (and not attached):

[1] minqa_1.2.4


In summary, I don't think there is anything to worry about from those
warnings.  You can go back and refit the model omitting the (1|Mind)
term and you should get the same value of the REML criterion.


On Fri, Oct 16, 2015 at 4:57 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Paul,
>
> I can reproduce the problem with lme4_1.1-9 and Matrix_1.2-3.
>
> Lowering the SE of the noise solved the covergence issues. So I expect that
> a low signal to noise ratio is causing the false convergence.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-15 16:49 GMT+02:00 Paul Johnson <pauljohn32 at gmail.com>:
>
> > On Wed, Oct 14, 2015 at 7:19 PM, David Duffy
> > <David.Duffy at qimrberghofer.edu.au> wrote:
> > > Is it because Mind is not declared a factor?
> > >
> > > dat$Mind <- factor(dat$Mind)
> > > lmer( y3s ~ x1s + x2s + x3s + (x1s | Mind), data = dat)
> > > Linear mixed model fit by REML ['lmerMod']
> > > Formula: y3s ~ x1s + x2s + x3s + (x1s | Mind)
> > >    Data: dat
> > > REML criterion at convergence: 33271.78
> > > Random effects:
> > >  Groups   Name        Std.Dev. Corr
> > >  Mind     (Intercept) 0.6837
> > >           x1s         0.1373   1.00
> > >  Residual             0.6997
> > > Number of obs: 15419, groups:  Mind, 100
> > > Fixed Effects:
> > > (Intercept)          x1s          x2s          x3s
> > >   -0.003039     0.117080    -0.163680     0.055911
> > >
> > >
> > > | David Duffy (MBBS PhD)
> > > | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax:
> > -0101
> > > | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
> > > | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A
> >
> > Interesting. I think there's a ghost in the machine.
> >
> > I see no benefit.
> >
> > The unscaled one still fails:
> >
> > > dat$Mind <- as.factor(dat$Mind)
> > > mm3 <- lmer( y3 ~ x1 + x2 + x3 + (1|Mind) + (0 + x1 | Mind), data=dat,
> > verbose=3)
> >
> > ...
> > 350:     143253.09: 9.88456e-06 0.00975148
> > 351:     143253.09: 9.88260e-06 0.00975168
> > 352:     143253.09: 9.69049e-06 0.00975152
> > 353:     143253.09: 9.44279e-06 0.00975152
> > 354:     143253.09: 9.61561e-06 0.00975152
> > At return
> > eval: 354 fn:      143253.09 par: 9.44279e-06 0.00975152
> > Warning message:
> > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >   Model is nearly unidentifiable: very large eigenvalue
> >  - Rescale variables?
> >
> > And the scaled one is still a failure on my system
> >
> > dat[ , c("x1s", "x2s", "x3s")] <- lapply(dat[, c("x1", "x2", "x3")],
> scale)
> > dat$y3s <- scale(dat$y3)
> > mm3 <- lmer( y3s ~ x1s + x2s + x3s + (1 | Mind) + (0 + x1 | Mind),
> >             data=dat, verbose = 3)
> >
> > rho:  2.0e-07 eval: 186 fn:      33271.8 par: 0.00000 0.00975124
> > 187:     33271.783:  0.00000 0.00975151
> > 188:     33271.783: 5.40934e-07 0.00975153
> > 189:     33271.783: 1.08231e-06 0.00975153
> > 190:     33271.783: 6.32312e-07 0.00975153
> > At return
> > eval: 190 fn:      33271.783 par: 5.40934e-07 0.00975153
> > Warning message:
> > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >   Model is nearly unidentifiable: very large eigenvalue
> >  - Rescale variables?
> >
> >
> > Since you don't get errors, I wonder if it means you are using
> > different version of R, or lmer?  Can we see your sessionInfo for
> > comparison:
> >
> >
> > > sessionInfo()
> > R version 3.2.2 (2015-08-14)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> > Running under: Ubuntu 15.04
> >
> > locale:
> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] lme4_1.1-10  Matrix_1.2-2 MASS_7.3-44
> >
> > loaded via a namespace (and not attached):
> > [1] minqa_1.2.4     compiler_3.2.2  tools_3.2.2     Rcpp_0.12.1
> > [5] splines_3.2.2   nlme_3.1-122    grid_3.2.2      nloptr_1.0.4
> > [9] lattice_0.20-33
> >
> >
> > --
> > Paul E. Johnson
> > Professor, Political Science        Director
> > 1541 Lilac Lane, Room 504      Center for Research Methods
> > University of Kansas                 University of Kansas
> > http://pj.freefaculty.org              http://crmda.ku.edu
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Fri Oct 16 19:55:18 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 16 Oct 2015 17:55:18 +0000
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
In-Reply-To: <CAO7JsnS=7zLOSxtEPP2f5r5zZ8ZrwnRAj8gY10rzyTixAUJjiw@mail.gmail.com>
References: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
	<alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>
	<CAErODj_rZM0frhbJ0rExZhmZUyeMfwOaKNVQ1LijAi9+omQhUw@mail.gmail.com>
	<CAJuCY5z0sawkR+7Tt3g0ynB6j4fpcjRN6o+f8iF2wcAhxBqb-A@mail.gmail.com>
	<CAO7JsnS=7zLOSxtEPP2f5r5zZ8ZrwnRAj8gY10rzyTixAUJjiw@mail.gmail.com>
Message-ID: <CAO7JsnSwMaMdEefH-ozGWoYPOenoDhW70+9BbX4PsiiSKqJtig@mail.gmail.com>

I did do the follow-up fit omitting the (1|Mind) term and got the same
results and the same warning.  Neither of those warnings make sense to me.
They are based on evaluations of an approximate Hessian formed (I think) by
finite differences of gradients evaluated by finite difference and those
are very noisy estimates.  In this case the estimated Hessian is diagonal
for the full model and 1 by 1 for the reduced model.  It should not be
problematic to have a large eigenvalue.  All that means is that small
differences in the second parameter (the only parameter in the reduced
model) cause large changes in the objective function, which is okay.

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Fri Oct 16 20:35:40 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 16 Oct 2015 18:35:40 +0000
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
In-Reply-To: <CAO7JsnSwMaMdEefH-ozGWoYPOenoDhW70+9BbX4PsiiSKqJtig@mail.gmail.com>
References: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
	<alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>
	<CAErODj_rZM0frhbJ0rExZhmZUyeMfwOaKNVQ1LijAi9+omQhUw@mail.gmail.com>
	<CAJuCY5z0sawkR+7Tt3g0ynB6j4fpcjRN6o+f8iF2wcAhxBqb-A@mail.gmail.com>
	<CAO7JsnS=7zLOSxtEPP2f5r5zZ8ZrwnRAj8gY10rzyTixAUJjiw@mail.gmail.com>
	<CAO7JsnSwMaMdEefH-ozGWoYPOenoDhW70+9BbX4PsiiSKqJtig@mail.gmail.com>
Message-ID: <CAO7JsnQrhnUkBFgBu6-uaENF3g2HxA9=XCypsU9LceCy5d5H1A@mail.gmail.com>

For those who may be interested, these are the results of timing the fits
of two models on these simulated data.  For consistency within the timings
I have renamed the grouping factor Mind to G and named the three continuous
covariates as S, T and U.  The optimizers whose names start with LN_ are
timings from the Julia MixedModels package using the NLopt package for
optimization.  Those whose names start with NLOPT_LN_ are the same
optimizer code accessed through the nloptr package for R.  The others are
from the optimx package, bobyqa from the minqa package (the default for
lmer) and the build-in Nelder_Mead optimizer, which is generally pretty bad
and I can say that because I wrote it.

dsname = "paulsim"
form = Formula: Y ~ 1 + S + T + U + (1 | G) + ((0 + S) | G)
-2log(likelihood) time(s) feval geval optimizer
   143232.6341     1.5120   606     0 bobyqa
   143564.1597     0.2770    70     0 Nelder_Mead
   143232.9465     0.2680    66     0 NLOPT_LN_BOBYQA
   143272.7444     0.2430    53     0 NLOPT_LN_COBYLA
   143803.9823     0.3420    40     0 NLOPT_LN_NELDERMEAD
   143232.6341     0.4570   147     0 NLOPT_LN_SBPLX
   143232.6582     0.6320    58     0 optimx:L-BFGS-B
   143232.6341     0.5480   104     0 optimx:nlminb
   143232.6341     6.7930    NA     0 optimx:spg
   143232.6341     1.6930    NA     0 optimx:bobyqa
   143232.6341     0.0489   107     0 LN_BOBYQA
   143232.6382     1.9885 69711     0 LN_COBYLA
   143803.9823     0.0474    56     0 LN_NELDERMEAD
   143232.6341     0.0527   147     0 LN_SBPLX
form = Formula: Y ~ 1 + S + T + U + ((0 + S) | G)
-2log(likelihood) time(s) feval geval optimizer
   143232.6341     0.1400    41     0 bobyqa
   143232.6341     0.1510    49     0 Nelder_Mead
   143232.6343     0.1360    36     0 NLOPT_LN_BOBYQA
   143232.6503     0.1170    24     0 NLOPT_LN_COBYLA
   143232.6341     0.1540    48     0 NLOPT_LN_NELDERMEAD
   143232.6341     0.1900    74     0 NLOPT_LN_SBPLX
   143232.6368     0.3560    70     0 optimx:L-BFGS-B
   143232.6341     0.2470    29     0 optimx:nlminb
   143232.6341     0.3660    NA     0 optimx:spg
   143232.6341     0.2650    NA     0 optimx:bobyqa
   143232.6341     0.0240    43     0 LN_BOBYQA
   143232.6341     0.0240    34     0 LN_COBYLA
   143232.6341     0.0242    52     0 LN_NELDERMEAD
   143232.6341     0.0246    81     0 LN_SBPLX

	[[alternative HTML version deleted]]


From saah500 at york.ac.uk  Fri Oct 16 21:24:33 2015
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Fri, 16 Oct 2015 22:24:33 +0300
Subject: [R-sig-ME] GLMM model failing to converge
Message-ID: <CACrevpk7TyMzb_LfVyq+OCF0pK92AaNp9LSjVZjWhNnrEDM=5g@mail.gmail.com>

Hello,


I?m novice in using R in general and generalized logistic regression models
with mixed effects in particular.

At any rate, I?m testing how close the linguistic perception (response
vowels) of different Turkish listeners (T [monolingual Turkish speakers],
TA [bilingual Turkish-Arabic speakers] and TQ [Turkish speakers with some
knowledge of Arabic through Quran recitation]) is to observed mappings
(predicted vowels) in my research qualitative corpus. In the data, this is
reflected in the binary variable match (1=match, 0=mismatch).


Having said this, my dependent variable is ?match? which interacts with
some +20 independent variables, some of which are factors with up to 12
levels.


Now, the basic model I?ve used is as follows and works just fine.


m0.1 <- glmer(match ~ Listgp + (1|Listener), data = PATdata1, family =
"binomial")

However, all subsequent models such as the one below crash.

cf. m0.4 <- glmer(match~ Listgp + stimulus + st.context + st.length + age +
gender + level.of.education + reading.A + comprehension.A + speaking.A +
writing.A + (1|Listener), data = PATdata1, family = "binomial")

Once I start parsing in the other factors especially the ones with
mutli-levels such as ?stimulus? , the model fails to converge and I
get a number of warning messages as follows.

1.    fixed-effect model matrix is rank deficient so dropping 4
columns / coefficients?

2.    In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

  Model failed to converge with max|grad| = 0.151201 (tol = 0.001,
component 7).

3. (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :

  failure to converge in 10000 evaluations



Any advice on how to go about this?


Thank you,


Shadiya

	[[alternative HTML version deleted]]


From highstat at highstat.com  Fri Oct 16 21:46:30 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Fri, 16 Oct 2015 20:46:30 +0100
Subject: [R-sig-ME] GLMM model failing to converge
In-Reply-To: <mailman.5822.1445023512.3797.r-sig-mixed-models@r-project.org>
References: <mailman.5822.1445023512.3797.r-sig-mixed-models@r-project.org>
Message-ID: <56215416.8030401@highstat.com>





------------------------------

Message: 5
Date: Fri, 16 Oct 2015 22:24:33 +0300
From: Shadiya Al Hashmi <saah500 at york.ac.uk>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] GLMM model failing to converge
Message-ID:
	<CACrevpk7TyMzb_LfVyq+OCF0pK92AaNp9LSjVZjWhNnrEDM=5g at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hello,


I?m novice in using R in general and generalized logistic regression models
with mixed effects in particular.

At any rate, I?m testing how close the linguistic perception (response
vowels) of different Turkish listeners (T [monolingual Turkish speakers],
TA [bilingual Turkish-Arabic speakers] and TQ [Turkish speakers with some
knowledge of Arabic through Quran recitation]) is to observed mappings
(predicted vowels) in my research qualitative corpus. In the data, this is
reflected in the binary variable match (1=match, 0=mismatch).


Having said this, my dependent variable is ?match? which interacts with
some +20 independent variables, some of which are factors with up to 12
levels.


Now, the basic model I?ve used is as follows and works just fine.


m0.1 <- glmer(match ~ Listgp + (1|Listener), data = PATdata1, family =
"binomial")

However, all subsequent models such as the one below crash.

cf. m0.4 <- glmer(match~ Listgp + stimulus + st.context + st.length + age +
gender + level.of.education + reading.A + comprehension.A + speaking.A +
writing.A + (1|Listener), data = PATdata1, family = "binomial")

Once I start parsing in the other factors especially the ones with
mutli-levels such as ?stimulus? , the model fails to converge and I
get a number of warning messages as follows.

1.    fixed-effect model matrix is rank deficient so dropping 4
columns / coefficients?

2.    In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

   Model failed to converge with max|grad| = 0.151201 (tol = 0.001,
component 7).

3. (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :

   failure to converge in 10000 evaluations



Any advice on how to go about this?


Thank you,


Shadiya

	[[alternative HTML version deleted]]





Shadiya,


You answered your own question already....your model is too complicated. Simplify your categorical covariates.
And simplify the set of covariates. And try to have at least 15 observations per regression parameter.
And do a good data exploration to see which of these categorical covariates may be linked to each other.

And without reproducible code + data I doubt whether anyone is going to give you a more detailed answer.


Alain Zuur


From bbolker at gmail.com  Fri Oct 16 21:53:41 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 16 Oct 2015 15:53:41 -0400
Subject: [R-sig-ME] GLMM model failing to converge
In-Reply-To: <CACrevpk7TyMzb_LfVyq+OCF0pK92AaNp9LSjVZjWhNnrEDM=5g@mail.gmail.com>
References: <CACrevpk7TyMzb_LfVyq+OCF0pK92AaNp9LSjVZjWhNnrEDM=5g@mail.gmail.com>
Message-ID: <CABghstTB=NxJKT-7HH5o8ws1_fb=82DVbN6i_Xn3hjFqXyTVGQ@mail.gmail.com>

On Fri, Oct 16, 2015 at 3:24 PM, Shadiya Al Hashmi <saah500 at york.ac.uk> wrote:
> Hello,
>
>
> I?m novice in using R in general and generalized logistic regression models
> with mixed effects in particular.
>
> At any rate, I?m testing how close the linguistic perception (response
> vowels) of different Turkish listeners (T [monolingual Turkish speakers],
> TA [bilingual Turkish-Arabic speakers] and TQ [Turkish speakers with some
> knowledge of Arabic through Quran recitation]) is to observed mappings
> (predicted vowels) in my research qualitative corpus. In the data, this is
> reflected in the binary variable match (1=match, 0=mismatch).
>
>
> Having said this, my dependent variable is ?match? which interacts with
> some +20 independent variables, some of which are factors with up to 12
> levels.
>
>
> Now, the basic model I?ve used is as follows and works just fine.
>
>
> m0.1 <- glmer(match ~ Listgp + (1|Listener), data = PATdata1, family =
> "binomial")
>
> However, all subsequent models such as the one below crash.
>
> cf. m0.4 <- glmer(match~ Listgp + stimulus + st.context + st.length + age +
> gender + level.of.education + reading.A + comprehension.A + speaking.A +
> writing.A + (1|Listener), data = PATdata1, family = "binomial")

  What does "crash" mean? Precision is important here -- you could mean:

* a warning (which should certainly concern you, but it might be a
false positive ...) -- in this case you *will* get a result, which you
can use if you conclude that the warnings don't actually represent a
serious problem;
* an error -- in this case you won't get an answer at all, you need to
deal with/work around the error before you can get results;
* a true crash, where the R process actually stops.  This is by
definition a bug in the package, or (much more unlikely) in R itself.


>
> Once I start parsing in the other factors especially the ones with
> mutli-levels such as ?stimulus? , the model fails to converge and I
> get a number of warning messages as follows.
>
> 1.    fixed-effect model matrix is rank deficient so dropping 4
> columns / coefficients?

  This means you have collinear predictors -- most likely, some
combinations of factors are aliased with each other.

>
> 2.    In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>
>   Model failed to converge with max|grad| = 0.151201 (tol = 0.001,
> component 7).

  This is a "medium-sized" gradient; it may be OK, hard to know.  How big
is your data set?
   As suggested in ?convergence, the gold standard is to try your model
with one or more different optimizers and see if it gets to a sufficiently
(for your purposes) similar answer.

> 3. (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
>
>   failure to converge in 10000 evaluations

  See ?lmerControl for advice about how to increase the number of
evaluations.

>
>
>
> Any advice on how to go about this?
>
>
> Thank you,
>
>
> Shadiya
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From saah500 at york.ac.uk  Fri Oct 16 22:13:22 2015
From: saah500 at york.ac.uk (Shadiya)
Date: Fri, 16 Oct 2015 23:13:22 +0300
Subject: [R-sig-ME] GLMM model failing to converge
In-Reply-To: <CABghstTB=NxJKT-7HH5o8ws1_fb=82DVbN6i_Xn3hjFqXyTVGQ@mail.gmail.com>
References: <CACrevpk7TyMzb_LfVyq+OCF0pK92AaNp9LSjVZjWhNnrEDM=5g@mail.gmail.com>
	<CABghstTB=NxJKT-7HH5o8ws1_fb=82DVbN6i_Xn3hjFqXyTVGQ@mail.gmail.com>
Message-ID: <CECBF7DD-8961-4809-A5E2-5844E3190B7F@york.ac.uk>

Thanks a lot Ben for the swift response. Will definitely try out different optimizers and check lmerControl.

Best wishes,

Shadiya

Sent from my iPhone

> On Oct 16, 2015, at 10:53 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> On Fri, Oct 16, 2015 at 3:24 PM, Shadiya Al Hashmi <saah500 at york.ac.uk> wrote:
>> Hello,
>> 
>> 
>> I?m novice in using R in general and generalized logistic regression models
>> with mixed effects in particular.
>> 
>> At any rate, I?m testing how close the linguistic perception (response
>> vowels) of different Turkish listeners (T [monolingual Turkish speakers],
>> TA [bilingual Turkish-Arabic speakers] and TQ [Turkish speakers with some
>> knowledge of Arabic through Quran recitation]) is to observed mappings
>> (predicted vowels) in my research qualitative corpus. In the data, this is
>> reflected in the binary variable match (1=match, 0=mismatch).
>> 
>> 
>> Having said this, my dependent variable is ?match? which interacts with
>> some +20 independent variables, some of which are factors with up to 12
>> levels.
>> 
>> 
>> Now, the basic model I?ve used is as follows and works just fine.
>> 
>> 
>> m0.1 <- glmer(match ~ Listgp + (1|Listener), data = PATdata1, family =
>> "binomial")
>> 
>> However, all subsequent models such as the one below crash.
>> 
>> cf. m0.4 <- glmer(match~ Listgp + stimulus + st.context + st.length + age +
>> gender + level.of.education + reading.A + comprehension.A + speaking.A +
>> writing.A + (1|Listener), data = PATdata1, family = "binomial")
> 
>  What does "crash" mean? Precision is important here -- you could mean:
> 
> * a warning (which should certainly concern you, but it might be a
> false positive ...) -- in this case you *will* get a result, which you
> can use if you conclude that the warnings don't actually represent a
> serious problem;
> * an error -- in this case you won't get an answer at all, you need to
> deal with/work around the error before you can get results;
> * a true crash, where the R process actually stops.  This is by
> definition a bug in the package, or (much more unlikely) in R itself.
> 
> 
>> 
>> Once I start parsing in the other factors especially the ones with
>> mutli-levels such as ?stimulus? , the model fails to converge and I
>> get a number of warning messages as follows.
>> 
>> 1.    fixed-effect model matrix is rank deficient so dropping 4
>> columns / coefficients?
> 
>  This means you have collinear predictors -- most likely, some
> combinations of factors are aliased with each other.
> 
>> 
>> 2.    In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>> 
>>  Model failed to converge with max|grad| = 0.151201 (tol = 0.001,
>> component 7).
> 
>  This is a "medium-sized" gradient; it may be OK, hard to know.  How big
> is your data set?
>   As suggested in ?convergence, the gold standard is to try your model
> with one or more different optimizers and see if it gets to a sufficiently
> (for your purposes) similar answer.
> 
>> 3. (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
>> 
>>  failure to converge in 10000 evaluations
> 
>  See ?lmerControl for advice about how to increase the number of
> evaluations.
> 
>> 
>> 
>> 
>> Any advice on how to go about this?
>> 
>> 
>> Thank you,
>> 
>> 
>> Shadiya
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Sat Oct 17 00:30:00 2015
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Fri, 16 Oct 2015 22:30:00 +0000
Subject: [R-sig-ME] contrasts among simple effects
Message-ID: <BY2PR0401MB0919DF84D57A2E0B5F7BC728F13D0@BY2PR0401MB0919.namprd04.prod.outlook.com>

I think we tend to highly overrate the idea of trying to engineer factor codings in order to get estimates of interesting contrasts among the regression coefficients. It gets confusing when there are multiple factors, and often, only some of the contrasts of interest can be estimated this way unless more than one version of the model is fitted. There are good packages that can handles such things -- multcomp, lsmeans, effects, etc. With your example, you could do, for example:

	library(lsmeans)
	lsm <- lsmeans(model2a, ~ drug | time)
	lsm 
	pairs(lsm)                   # compare drugs at each time
	pairs(lsm, by = "drug")  # compare times for each drug

Russ
--
Russell V. Lenth ?- ?Professor Emeritus
Department of Statistics and Actuarial Science ??
The University of Iowa ?- ?Iowa City, IA 52242 ?USA ??
Voice (319)335-0712 ?- ?FAX (319)335-3017
russell-lenth at uiowa.edu??- ?http://www.stat.uiowa.edu/~rlenth/?

> Greetings R Community
>
> Apologize for previously sending a csv file.
>
> My goal is to make orthogonal contrasts among simple effects in 
> analysis of repeated measures data.  The SAS publication, on page 
> 1224, shows how to make this type of contrasts in SAS.  But, my search 
> of books about repeated measures analysis using R, and on-line has not yielded a methodology.
> Hopefully, someone can direct me to a book or publication that will 
> show me a methodology.
>
> Statistical Analysis of Repeated Measures Data Using SAS Procedures
>
>
> http://cslras.pbworks.com/f/littell_j_anim_sci_76_4_analysis_of_repeat
> ed_measures_using_sas.pdf
>
>
>
> Attached is a txt data file (file name = heart_rate.txt).  My code for 
> the repeated measures analysis is below.
>
> library("nlme")
>
> # with AR1 variance/covariance structure, with ordered statement
>
> heartRate$time <- factor(heartRate$time)
>
> model2a <- lme(HR ~ drug*ordered(time), random =~1|person, correlation 
> =corAR1(, form=~1|person), data = heartRate)
>
> summary(model2a)
>
> anova(model2a)
>
> Making a new variable ?simple? that merges the variables drug and time 
> will enable me to make orthogonal contrasts among the simple effects.  
> But, when using the variable ?simple? as the independent variable, the 
> data will no longer be fitted to the AR1 variance/covariance structure.
>
> Thanks.
>
> Best regards,
>
> James F.Henson


From aslihans at hacettepe.edu.tr  Thu Oct 15 15:02:14 2015
From: aslihans at hacettepe.edu.tr (=?UTF-8?Q?Asl=C4=B1han_=C5=9Eent=C3=BCrk_Acar?=)
Date: Thu, 15 Oct 2015 16:02:14 +0300
Subject: [R-sig-ME] about: GLMM for continuous response
Message-ID: <ddd61b0f83219a2f68c61adea60fe7d5@hacettepe.edu.tr>


Dear Sir,

I am a Phd student working on GLMM implementation for continuous 
response of insurance claim size. I have some problems to implement GLMM 
in R. I would be very glad if you could answer.

Response variable y_ij: jth claim amount of individual i. People can 
have just one claim or more than one claim (max. claim number is 136. so 
j=1,2,...,136).

There are 22 000 individuals in the sample. Explanatory variables are 
(fixed effects): claim number in one year (integer), age(integer), 
gender (0-1,factor), provience (0-6,factor), package (0-3,factor), 
marital status (0-1,factor).

*I use only random intercept as random effect.

I am using R 3.0.3, MASS, lme4,nlme and lm4.0 packages.

My questions are:


1- I use GLMMPQL (MASS package) that generally converges. But laplace 
and quadrature never converges. I did not understand the reason. What 
can be the reason? While implementing GLMM are the individuals that have 
just one claim problem for model convergence?

note: gamma glm, log transform and linear mixed model, gamma GEE all 
converges.

2- I simulated gamma distributed response variable and used a few 
covariates to test convergence error. Laplace converges, Quadrature does 
not converge again. While PQL gives 0.2632854 for standard deviation of 
random intercept, glmer (laplace) gives std. dev 1028.16. Why is so huge 
difference between two methods?

3- GLMMPQL converges with all explanatory variables. Province and gender 
are not significant. When I exclude only province GLMMPQL does not 
converge. But when I exclude gender and both province+gender it 
converges. Why is this contradiction?

4- I could not see any paper on GLMM applications for continuous 
response. I am afraid of doing something wrong but I ca not find any 
reference. Can you give me any references to understand detail of GLMM 
implementation for continuous response and general idea for 
implementation of GLMM.

5- I do not want to make logarithmic transform and fit linear mixed 
models, I want to use data on original scale. Do you offer any other 
distribution exempt gamma GLMM?


I appreciate any help.

Thank you very much.

Best wishes,

Aslihan


-- 
Aslihan Senturk Acar

Research Assistant
Hacettepe University
Department of Actuarial Sciences
Beytepe, Ankara
08600

Phone: (+90) 312 297 6160 / 119
Email: aslihans at hacettepe.edu.tr


From qiujing at udel.edu  Fri Oct 16 04:58:02 2015
From: qiujing at udel.edu (qiujing at udel.edu)
Date: Thu, 15 Oct 2015 22:58:02 -0400
Subject: [R-sig-ME] How to check the iterative history of convergence and
	change convergence criterion in glmmadmb
Message-ID: <9A2CF004-0707-4B6E-BBD8-5A5ADA818C16@udel.edu>

I am using glmmadmb to fit negative binomial mixed effects model to my data. However it fails to converge sometimes. I want to understand what is causing the failure of convergence by first of all check whether it really fails to converge or just converges very slowly? when I fit the data using was glmmmix? the iteration history reply shows that my model does converges but fail to meet the default convergency criteria. When I relax the convergence criterion, it converges well.  

Is there anyway I can find the iteration history in glmmadmb as well? And can I change the default convergence criterion?

Thanks!

Jing

Jing qiu

From lindeh at uw.edu  Thu Oct 15 06:14:37 2015
From: lindeh at uw.edu (Hannah L. Linder)
Date: Wed, 14 Oct 2015 21:14:37 -0700
Subject: [R-sig-ME] GAMM convergence issue with temporal covariate
In-Reply-To: <CAM9kYqhu7imctbicJ1=J4AnScmrnxh2db6CkgU2OnG45vKfQ2w@mail.gmail.com>
References: <mailman.5651.1444842140.3797.r-sig-mixed-models@r-project.org>
	<561E8EAC.70004@highstat.com>
	<CAM9kYqhu7imctbicJ1=J4AnScmrnxh2db6CkgU2OnG45vKfQ2w@mail.gmail.com>
Message-ID: <CAF0=RbYk6fKGt_uAOPDk-7KVAMsRKWOBrKOXnkOwRzi_GgMj1w@mail.gmail.com>

Great, thank-you both very much for your time and help!

Tom- I appreciate the extra pointers, and will have a deeper look at each.

In addition, I am aware that there are also possible concurvity issues with
time smoother variables. From reading Wood (2011) and the R package
information it seems that the default smoother estimation method protects
against any incorrect parameter estimations due to possible concurvity.
Does this hold true for gamm in mgcv? I could not quite tell based on the
package information.

Thank-you,
Hannah

On Wed, Oct 14, 2015 at 11:49 AM, Philippi, Tom <tom_philippi at nps.gov>
wrote:

> Is your range tidal height at the same location at the time of sampling
> (time & day), or variation among sites in elevation above some datum at the
> (same) time of sampling?  Or does it vary by day but not by time?
>
> If the former, given the predictable way that the tide cycle shifts from
> one day to the next, for some times of the year you're going to have a
> tough time separating out an effect of range from smoothed effects of day
> and time.  If you need to visualize this, pull the NOAA 6 minute tidal
> predictions from somewhere near your site (I can send R code to do this).
> Or, plot a simple heatmap of your data:
>     lattice::levelplot(range~day+time,data=dsn)
>
> Also, be careful with your cyclic fit on time of day.
>     s(time,bs="cc")
> If your time values are not evenly spaced (e.g., full 0:24) you are likely
> to need to specify knots to let gamm know that 0 and 24 are the ends to
> match.  My first guess would be that you need:
>    knots=list(time=c(0,24))
> but I don't know your data, so your mileage will vary.
>
> Tom 2
>
> On Wed, Oct 14, 2015 at 10:19 AM, Highland Statistics Ltd <
> highstat at highstat.com> wrote:
>
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > ------------------------------
> >
> > Message: 2
> > Date: Mon, 12 Oct 2015 12:13:44 -0700
> > From: "Hannah L. Linder" <lindeh at uw.edu>
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] GAMM convergence issue with temporal covariate
> > Message-ID:
> >         <CAF0=RbauKGU3JOsPxBkuka=
> > MBZZU0rZNkAyYt_or4p1h25wmBQ at mail.gmail.com>
> > Content-Type: text/plain; charset="UTF-8"
> >
> > Hello,
> >
> > I am working with a fairly simple model:
> >
> > gamm(sv~s(day,bs="cr")+range+s(time,bs="cc"),correlation=corARMA(p=2,q=2)
> >
> > In which day is Julian Day over one month, range is tidal range, and time
> > is coded 1-24 for hour of day.
> >
> > I continually have singularity convergence problems with this model (the
> > error is:  nlminb
> > problem, convergence error code = 1 message = false convergence (8).
> >
> > Increasing iterations does not help. When I run msVerbose I notice that
> > "day" covariate output values (there are two but I'm not completely sure
> > how to interpret them) keep increasing until the convergence errors
> occur.
> > I have also noticed that setting k=5 for the "day" covariate does not
> help
> > the convergence problem, but k=9 does (the default is 10) or k =20. I
> would
> > greatly appreciate any advice or recommendations on what may be causing
> the
> > problem.
> >
> > Thank-you very much,
> > Hannah
> > --------
> >
> >
> >
> > Hannah,
> >
> > CorARMA(p = 2, q = 2) is not an easy one for the optimisation routine.
> Try
> > simplifying it.
> > Additionally...the ARMA residual correlation structure may be competing
> > with the time smoothers.
> > You could try to use fixed values for the ARMA parameters.
> >
> >
> > Alain Zuur
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Thu Oct 15 02:19:41 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Thu, 15 Oct 2015 10:19:41 +1000
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
In-Reply-To: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
References: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>

Is it because Mind is not declared a factor?

dat$Mind <- factor(dat$Mind)
lmer( y3s ~ x1s + x2s + x3s + (x1s | Mind), data = dat)
Linear mixed model fit by REML ['lmerMod']
Formula: y3s ~ x1s + x2s + x3s + (x1s | Mind)
    Data: dat
REML criterion at convergence: 33271.78
Random effects:
  Groups   Name        Std.Dev. Corr
  Mind     (Intercept) 0.6837
           x1s         0.1373   1.00
  Residual             0.6997
Number of obs: 15419, groups:  Mind, 100
Fixed Effects:
(Intercept)          x1s          x2s          x3s
   -0.003039     0.117080    -0.163680     0.055911


| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From dwinsemius at comcast.net  Sat Oct 17 22:24:51 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 17 Oct 2015 13:24:51 -0700
Subject: [R-sig-ME] about: GLMM for continuous response
In-Reply-To: <ddd61b0f83219a2f68c61adea60fe7d5@hacettepe.edu.tr>
References: <ddd61b0f83219a2f68c61adea60fe7d5@hacettepe.edu.tr>
Message-ID: <C3F9763A-8F30-4B38-A245-E609209E0FB0@comcast.net>


On Oct 15, 2015, at 6:02 AM, Asl?han ?ent?rk Acar wrote:

> 
> Dear Sir,
> 
> I am a Phd student working on GLMM implementation for continuous response of insurance claim size. I have some problems to implement GLMM in R. I would be very glad if you could answer.
> 
> Response variable y_ij: jth claim amount of individual i. People can have just one claim or more than one claim (max. claim number is 136. so j=1,2,...,136).

What about zero claims? Those are the policy holders who are paying for persons or entities who did have non-zero claims. 

> 
> There are 22 000 individuals in the sample. Explanatory variables are (fixed effects): claim number in one year (integer), age(integer), gender (0-1,factor), provience (0-6,factor), package (0-3,factor), marital status (0-1,factor).
> 

Including 'claim number' as a fixed effect would seem to be highly questionable. It presumes you could have known in advance who would become the high claim policyholders.


> *I use only random intercept as random effect.
> 
> I am using R 3.0.3, MASS, lme4,nlme and lm4.0 packages.
> 
> My questions are:
> 
> 
> 1- I use GLMMPQL (MASS package) that generally converges. But laplace and quadrature never converges. I did not understand the reason. What can be the reason? While implementing GLMM are the individuals that have just one claim problem for model convergence?
> 

You should offer actual code samples. I get the impression you are using more than just the glmmPQL function, since ?glmmPQL says options are passed to lme and those are not offered as options in the ?lmeControl page.

> note: gamma glm, log transform and linear mixed model, gamma GEE all converges.
> 
> 2- I simulated gamma distributed response variable and used a few covariates to test convergence error. Laplace converges, Quadrature does not converge again. While PQL gives 0.2632854 for standard deviation of random intercept, glmer (laplace) gives std. dev 1028.16. Why is so huge difference between two methods?

Wouldn't the data and code be needed for an answer? The FAQ says gamma models can be "difficult": http://glmm.wikidot.com/faq. It makes me wonder whether you have achieved complete separation in one of the models through excessive control for the claim-number variable.


> 
> 3- GLMMPQL converges with all explanatory variables. Province and gender are not significant. When I exclude only province GLMMPQL does not converge. But when I exclude gender and both province+gender it converges. Why is this contradiction?

Wouldn't we need to see the data to answer such a question?

> 
> 4- I could not see any paper on GLMM applications for continuous response.

???  Gamma is not a continuous response? Log-normal as well?

https://www.researchgate.net/profile/Jostein_Paulsen/publication/222532925_Fitting_mixed-effects_models_when_data_are_left_truncated/links/0c96052542940503ac000000.pdf


> I am afraid of doing something wrong but I ca not find any reference. Can you give me any references to understand detail of GLMM implementation for continuous response and general idea for implementation of GLMM.
> 

Wouldn't that simply depend on what `family` (or link) argument was offered to your regression function?

> 5- I do not want to make logarithmic transform and fit linear mixed models, I want to use data on original scale. Do you offer any other distribution exempt gamma GLMM?

Do you have some descriptive data regarding the response? Seems that insurance claims problems should be using truncated distributions if at all possible. (See the citation above.)  There is often both a minimum and maximum value for coverage.

> 
> 
> I appreciate any help.
> 
> Thank you very much.
> 
> Best wishes,
> 
> Aslihan
> 
> 
> -- 
> Aslihan Senturk Acar
> 
> Research Assistant
> Hacettepe University
> Department of Actuarial Sciences
> Beytepe, Ankara
> 08600
> 
> Phone: (+90) 312 297 6160 / 119
> Email: aslihans at hacettepe.edu.tr
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA


From bbolker at gmail.com  Sat Oct 17 22:25:19 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 17 Oct 2015 16:25:19 -0400
Subject: [R-sig-ME] How to check the iterative history of convergence
 and change convergence criterion in glmmadmb
In-Reply-To: <9A2CF004-0707-4B6E-BBD8-5A5ADA818C16@udel.edu>
References: <9A2CF004-0707-4B6E-BBD8-5A5ADA818C16@udel.edu>
Message-ID: <CABghstQ0t3GPDBT0pJxgg9J18NKgTNr9nBv6e+7jX=tobQhEqA@mail.gmail.com>

If you specify verbose=TRUE when running the model you will see (quite
a lot of) interim output describing the optimization progress.  See
?admbControl for more control options; you can also use the
"extra.args" argument to pass additional arguments to ADMB, but you'll
need to look at the ADMB documentation
<http://www.admb-project.org/documentation> to figure out what to do:
from chapter 12 of the manual
<http://ftp.admb-project.org/admb-11.4/manuals/admb-11.4.1.pdf>, it
looks like  extra.args="-crit xxx" (where xxx is a numerical
convergence criterion -- not sure what makes sense).

See also <https://www.google.ca/url?sa=t&rct=j&q=&esrc=s&source=web&cd=9&cad=rja&uact=8&ved=0CEgQFjAIahUKEwju072Lq8rIAhVMGx4KHW5yAPU&url=ftp%3A%2F%2Fglpd.fw.msu.edu%2FQFC%2FADMB-Videos%2FCurrent_ADMB_Video_Release%2FDefault%2520Convergence%2520Criterion%2FADMB%2520-%2520Default%2520Convergence%2520Criterion%2520Video%2520Handout.pdf&usg=AFQjCNGcJXjNmcgBgu--8tMkxX__d6RMgQ&sig2=smswu71Be-z7X-PVMK-kGA>
, and consider asking about convergence criteria on the ADMB list if
you can't figure it out.


On Thu, Oct 15, 2015 at 10:58 PM,  <qiujing at udel.edu> wrote:
> I am using glmmadmb to fit negative binomial mixed effects model to my data. However it fails to converge sometimes. I want to understand what is causing the failure of convergence by first of all check whether it really fails to converge or just converges very slowly? when I fit the data using was glmmmix? the iteration history reply shows that my model does converges but fail to meet the default convergency criteria. When I relax the convergence criterion, it converges well.
>
> Is there anyway I can find the iteration history in glmmadmb as well? And can I change the default convergence criterion?
>
> Thanks!
>
> Jing
>
> Jing qiu
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jbukoski1 at gmail.com  Sun Oct 18 16:02:15 2015
From: jbukoski1 at gmail.com (Jacob Bukoski)
Date: Sun, 18 Oct 2015 10:02:15 -0400
Subject: [R-sig-ME] Hierarchical structure for preservation of observations
Message-ID: <CAOES0VipWaQuoJqyLQnY0gzPdx1zn6mLwXfXgbp42RyTW5y=0A@mail.gmail.com>

Dear all,

I am currently trying to develop a predictive model of ecosystem carbon
stocks for forests of Southeast Asia. The difficult part is that the
dataset I've compiled (from published data in the peer-reviewed literature)
only consists of 65 or so observations.

I've resorted to a mixed effects model under the understanding that I can
specify a grouping structure and maintain spatially correlated observations
within each study. However, I'm not sure that my specification of the
hierarchical structure is acceptable, as this is my first attempt at using
mixed models.

I am using R version 3.2.2., and the lmer() function of the "lme4" package.

I have specified basal area (a metric of tree stem cross sectional area at
1.3 meters height), latitude, and categorical variables for small (mean
stem diameter < 5 cm) and large (mean stem diameter > 15 cm) forests as
fixed effects.

I have specified the dominant genus of tree in plots and the site as random
effects. My thinking here is that plots with the same dominant genera of
tree would not be independent of one another, nor would plots within the
same site. Thus, by specifying random effects for Genus in Site... I can
maintain the individual observations.

The model I have specified as follows:

*lmer1 <- lmer(Biomass ~ Basal.area + Latitude + Small + Large +
(1|Site/Genus), REML=FALSE)*

*My two-part question is*: (i) Does the logic behind my random effect
specification hold, and (ii) have I specified it under the lmer() function
correctly?

Additionally, I am unsure of whether the number of groups has an impact on
the degrees of freedom. The summary reports 34 groups for Genus:Site, and
21 for Site. My specified model has 40 residual degrees of freedom. Have I
violated my degrees of freedom?

Any advice and external resources will be hugely appreciated!

Many kind thanks,
Jacob

-- 
Jacob J. Bukoski
Master of Environmental Science Candidate, 2016
School of Forestry and Environmental Studies, Yale University
jbukoski1 at gmail.com | jacob.bukoski at yale.edu | LinkedIn
<https://www.linkedin.com/profile/view?id=AAIAAAdWVW8BMzqU_2EGNbEkyuy8O7K1Jyhd8ps&trk=nav_responsive_tab_profile_pic>

	[[alternative HTML version deleted]]


From mcypsy at gmail.com  Sun Oct 18 17:46:59 2015
From: mcypsy at gmail.com (Chunyun Ma)
Date: Sun, 18 Oct 2015 11:46:59 -0400
Subject: [R-sig-ME] Model is nearly unidentifiable with lmer
In-Reply-To: <CAJ6ui+M8MdA5c5Qw9sc4nCW3UjipykYS0ZTVMSts9pebTCOhfw@mail.gmail.com>
References: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>
	<CABghstTZOr-vDwTJ6LZiLjoWQcDC2zdQA=jk3cL2ahLd3XzP8g@mail.gmail.com>
	<CAJ6ui+M8MdA5c5Qw9sc4nCW3UjipykYS0ZTVMSts9pebTCOhfw@mail.gmail.com>
Message-ID: <CAFS3taTJD9C7ZSxCtfo+v+vsq6uQhM7=W0jGUQBvR9R4ea=ysQ@mail.gmail.com>

Hi dear Ben and Alex!

Thank you very much for your help and guidance! I just started reading your
references. As I was exploring the alternatives you have suggested, another
question came up. This may sounds silly, but I haven't found a definitive
answer online: in the lmer formula, is it necessary to convert the random
factor into factor using factor()?  Given that I have a RM design, my
random factor will always be subject, which is numerical unless I force it
into factor...

Thank you again!

Warmly,  Chunyun

On Sun, Oct 11, 2015 at 8:28 PM, Alex Fine <abfine at gmail.com> wrote:

> You might also try using sum-coding rather than (the default) dummy coding
> with the categorical predictors.  Assuming the design is roughly balanced,
> this is like mean-centering the categorical variables.  This will change
> the interpretation of the coefficients.
>
> Here is some further reading:  http://talklab.psy.gla.ac.uk/tvw/catpred/
>
> On Sun, Oct 11, 2015 at 8:18 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> Short answer: try rescaling all of your continuous variables.  It
>> can't hurt/will change only the interpretation.  If you get the same
>> log-likelihood with the rescaled variables, that indicates that the
>> large eigenvalue was not actually a problem in the first place.
>>
>>    I don't think the standard citation from the R citation file
>> <https://cran.r-project.org/web/packages/lme4/citation.html>, or the
>> book chapter I wrote recently (chapter 13 of Fox et al, Oxford
>> University Press 2015 -- online supplements at
>> <http://ms.mcmaster.ca/~bolker/R%/misc/foxchapter/bolker_chap.html>)
>> cover rescaling in much detail. Schielzeth 2010
>> doi:10.1111/j.2041-210X.2010.00012.x gives a coherent argument about
>> the interpretive advantages of scaling.
>>
>>    Ben Bolker
>>
>>
>> On Sun, Oct 11, 2015 at 6:37 PM, Chunyun Ma <mcypsy at gmail.com> wrote:
>> > Dear all,
>> >
>> > This is my first post in the mailing list.
>> > I have been running some model with lmer and came across this warning
>> > message:
>> >
>> > In checkConv(attr(opt, ?derivs?), opt$par, ctrl = control$checkConv, :
>> > Model is nearly unidentifiable: very large eigenvalue
>> >
>> >    - Rescale variables?
>> >
>> > Here is the formula of my model (I substituted variables names with
>> generic
>> > names):
>> >
>> > y ~ Intercept + Xc + Xd1 + Xd2 + Xc:Xd1 + Xc:Xd2 + Zd + Zd:Xc + Zd:Xd1 +
>> > Zd:Xd2 + (1 + Xc + Xd1 + Xd2 | sub)
>> >
>> > Xc: continuous var
>> > Xd: level-1 dummy variable(s)
>> > Zd: level-2 dummy variable
>> >
>> > A snapshot of data. I can also provide the full dataset if necessary.
>> > sub Xc Xd1 Xd2 Zd y 1 36 0 0 1 1346 1 45 0 1 1 1508 1 72 1 0 1 1246 1
>> 12 1 0
>> > 1 1164 1 24 1 0 1 1295 1 36 1 0 1 1403
>> >
>> > When I reduced the # of random effect to (1+Xc|sub), the warning message
>> > disappeared, but the model fit became poorer.
>> > My question is: which variable(s) should I rescale? I?d be happy to
>> > better understand t
>> > he
>> >
>> > warning message if anyone could
>> > kindly
>> > suggest
>> > some
>> >  reference paper/book.
>> >
>> > Thank you very for your help!!
>> >
>> > Chunyun
>> >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Alex Fine
> Ph. (336) 302-3251
> web:  http://internal.psychology.illinois.edu/~abfine/
> <http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>
>

	[[alternative HTML version deleted]]


From mcypsy at gmail.com  Sun Oct 18 19:06:27 2015
From: mcypsy at gmail.com (Chunyun Ma)
Date: Sun, 18 Oct 2015 13:06:27 -0400
Subject: [R-sig-ME] Model is nearly unidentifiable with lmer
In-Reply-To: <CAFS3taTJD9C7ZSxCtfo+v+vsq6uQhM7=W0jGUQBvR9R4ea=ysQ@mail.gmail.com>
References: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>
	<CABghstTZOr-vDwTJ6LZiLjoWQcDC2zdQA=jk3cL2ahLd3XzP8g@mail.gmail.com>
	<CAJ6ui+M8MdA5c5Qw9sc4nCW3UjipykYS0ZTVMSts9pebTCOhfw@mail.gmail.com>
	<CAFS3taTJD9C7ZSxCtfo+v+vsq6uQhM7=W0jGUQBvR9R4ea=ysQ@mail.gmail.com>
Message-ID: <CAFS3taQoK8e_F=-duOcWXtt_zi6hGaCECRx5gMMpOP8SbG2btA@mail.gmail.com>

Hi again dear Ben and Alex!

I scaled the continuous predictor (Xc) using scale(Xc, centre=T, scale=T)
and the warning did disappear! Also, the log likelihood remains the same.
As Ben suggested, this indicates the large eigenvalue was not actually a
problem in the first place, although I still feel hazy about why the
warning appeared previously (I need to refresh my memory of what
eigenvalues are).

I also converted the subject using factor(). I would love to better
understand when it is necessary to factor a variable. I did find a post
from stackoverflow
<http://stackoverflow.com/questions/21226069/when-are-factors-necessary-appropriate-in-r>
on a similar topic, but it did not mention the random factor in a lmer
formula.

Alex, I tried both dummy coding and sum coding as you suggested. I got the
same warning message with either coding scheme. I still need to carefully
read your full paper to understand what ?maximal random-effect structure?
is.

To recap, my remaining questions are:

   - Can I ignore the eigenvalue warning and proceed with the raw variable
   (because the rescaling makes it hard to interpret) since the log likelihood
   does not change?
   - In using lmer for RM design, if the random factor is
   subject/participant, should I always makes sure subject has been converted
   to factor using factor()? Any further reference would be appreciated.

Many thanks!

Warmly, Chunyun

On Sun, Oct 18, 2015 at 11:46 AM, Chunyun Ma <mcypsy at gmail.com> wrote:

Hi dear Ben and Alex!
>
> Thank you very much for your help and guidance! I just started reading
> your references. As I was exploring the alternatives you have suggested,
> another question came up. This may sounds silly, but I haven't found a
> definitive answer online: in the lmer formula, is it necessary to convert
> the random factor into factor using factor()?  Given that I have a RM
> design, my random factor will always be subject, which is numerical unless
> I force it into factor...
>
> Thank you again!
>
> Warmly,  Chunyun
>
> On Sun, Oct 11, 2015 at 8:28 PM, Alex Fine <abfine at gmail.com> wrote:
>
>> You might also try using sum-coding rather than (the default) dummy
>> coding with the categorical predictors.  Assuming the design is roughly
>> balanced, this is like mean-centering the categorical variables.  This will
>> change the interpretation of the coefficients.
>>
>> Here is some further reading:  http://talklab.psy.gla.ac.uk/tvw/catpred/
>>
>> On Sun, Oct 11, 2015 at 8:18 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> Short answer: try rescaling all of your continuous variables.  It
>>> can't hurt/will change only the interpretation.  If you get the same
>>> log-likelihood with the rescaled variables, that indicates that the
>>> large eigenvalue was not actually a problem in the first place.
>>>
>>>    I don't think the standard citation from the R citation file
>>> <https://cran.r-project.org/web/packages/lme4/citation.html>, or the
>>> book chapter I wrote recently (chapter 13 of Fox et al, Oxford
>>> University Press 2015 -- online supplements at
>>> <http://ms.mcmaster.ca/~bolker/R%/misc/foxchapter/bolker_chap.html>)
>>> cover rescaling in much detail. Schielzeth 2010
>>> doi:10.1111/j.2041-210X.2010.00012.x gives a coherent argument about
>>> the interpretive advantages of scaling.
>>>
>>>    Ben Bolker
>>>
>>>
>>> On Sun, Oct 11, 2015 at 6:37 PM, Chunyun Ma <mcypsy at gmail.com> wrote:
>>> > Dear all,
>>> >
>>> > This is my first post in the mailing list.
>>> > I have been running some model with lmer and came across this warning
>>> > message:
>>> >
>>> > In checkConv(attr(opt, ?derivs?), opt$par, ctrl = control$checkConv, :
>>> > Model is nearly unidentifiable: very large eigenvalue
>>> >
>>> >    - Rescale variables?
>>> >
>>> > Here is the formula of my model (I substituted variables names with
>>> generic
>>> > names):
>>> >
>>> > y ~ Intercept + Xc + Xd1 + Xd2 + Xc:Xd1 + Xc:Xd2 + Zd + Zd:Xc + Zd:Xd1
>>> +
>>> > Zd:Xd2 + (1 + Xc + Xd1 + Xd2 | sub)
>>> >
>>> > Xc: continuous var
>>> > Xd: level-1 dummy variable(s)
>>> > Zd: level-2 dummy variable
>>> >
>>> > A snapshot of data. I can also provide the full dataset if necessary.
>>> > sub Xc Xd1 Xd2 Zd y 1 36 0 0 1 1346 1 45 0 1 1 1508 1 72 1 0 1 1246 1
>>> 12 1 0
>>> > 1 1164 1 24 1 0 1 1295 1 36 1 0 1 1403
>>> >
>>> > When I reduced the # of random effect to (1+Xc|sub), the warning
>>> message
>>> > disappeared, but the model fit became poorer.
>>> > My question is: which variable(s) should I rescale? I?d be happy to
>>> > better understand t
>>> > he
>>> >
>>> > warning message if anyone could
>>> > kindly
>>> > suggest
>>> > some
>>> >  reference paper/book.
>>> >
>>> > Thank you very for your help!!
>>> >
>>> > Chunyun
>>> >
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> Alex Fine
>> Ph. (336) 302-3251
>> web:  http://internal.psychology.illinois.edu/~abfine/
>> <http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>
>>
>
> ?

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Oct 18 19:47:57 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 18 Oct 2015 13:47:57 -0400
Subject: [R-sig-ME] Model is nearly unidentifiable with lmer
In-Reply-To: <CAFS3taTJD9C7ZSxCtfo+v+vsq6uQhM7=W0jGUQBvR9R4ea=ysQ@mail.gmail.com>
References: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>
	<CABghstTZOr-vDwTJ6LZiLjoWQcDC2zdQA=jk3cL2ahLd3XzP8g@mail.gmail.com>
	<CAJ6ui+M8MdA5c5Qw9sc4nCW3UjipykYS0ZTVMSts9pebTCOhfw@mail.gmail.com>
	<CAFS3taTJD9C7ZSxCtfo+v+vsq6uQhM7=W0jGUQBvR9R4ea=ysQ@mail.gmail.com>
Message-ID: <CABghstTcsAUTA3m4TcKfx3CqYFkMQJhWBpedyABCL6ZLkH1EUA@mail.gmail.com>

lme4 always treats grouping variables (those on the right side of a
bar in a random-effects term such as (1|g) ) as factors, no matter
what their underlying type is.  This is particularly useful for models
such as  z ~ year + (1|year), which treats year as numeric (i.e.
fitting a linear regression line) in the fixed-effects part of the
model but as a categorical grouping variable (i.e. fitting year-level
deviations from the regression line) in the random-effects part of the
model.

  That said, if you have variables that are numeric in appearance but
are always going to be treated as categorical (e.g. subject IDs that
are arbitrary numeric codes), it's best practice to explicitly convert
them to factors early in your workflow.


On Sun, Oct 18, 2015 at 11:46 AM, Chunyun Ma <mcypsy at gmail.com> wrote:
> Hi dear Ben and Alex!
>
> Thank you very much for your help and guidance! I just started reading your
> references. As I was exploring the alternatives you have suggested, another
> question came up. This may sounds silly, but I haven't found a definitive
> answer online: in the lmer formula, is it necessary to convert the random
> factor into factor using factor()?  Given that I have a RM design, my random
> factor will always be subject, which is numerical unless I force it into
> factor...
>
> Thank you again!
>
> Warmly,  Chunyun
>
> On Sun, Oct 11, 2015 at 8:28 PM, Alex Fine <abfine at gmail.com> wrote:
>>
>> You might also try using sum-coding rather than (the default) dummy coding
>> with the categorical predictors.  Assuming the design is roughly balanced,
>> this is like mean-centering the categorical variables.  This will change the
>> interpretation of the coefficients.
>>
>> Here is some further reading:  http://talklab.psy.gla.ac.uk/tvw/catpred/
>>
>> On Sun, Oct 11, 2015 at 8:18 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>> Short answer: try rescaling all of your continuous variables.  It
>>> can't hurt/will change only the interpretation.  If you get the same
>>> log-likelihood with the rescaled variables, that indicates that the
>>> large eigenvalue was not actually a problem in the first place.
>>>
>>>    I don't think the standard citation from the R citation file
>>> <https://cran.r-project.org/web/packages/lme4/citation.html>, or the
>>> book chapter I wrote recently (chapter 13 of Fox et al, Oxford
>>> University Press 2015 -- online supplements at
>>> <http://ms.mcmaster.ca/~bolker/R%/misc/foxchapter/bolker_chap.html>)
>>> cover rescaling in much detail. Schielzeth 2010
>>> doi:10.1111/j.2041-210X.2010.00012.x gives a coherent argument about
>>> the interpretive advantages of scaling.
>>>
>>>    Ben Bolker
>>>
>>>
>>> On Sun, Oct 11, 2015 at 6:37 PM, Chunyun Ma <mcypsy at gmail.com> wrote:
>>> > Dear all,
>>> >
>>> > This is my first post in the mailing list.
>>> > I have been running some model with lmer and came across this warning
>>> > message:
>>> >
>>> > In checkConv(attr(opt, ?derivs?), opt$par, ctrl = control$checkConv, :
>>> > Model is nearly unidentifiable: very large eigenvalue
>>> >
>>> >    - Rescale variables?
>>> >
>>> > Here is the formula of my model (I substituted variables names with
>>> > generic
>>> > names):
>>> >
>>> > y ~ Intercept + Xc + Xd1 + Xd2 + Xc:Xd1 + Xc:Xd2 + Zd + Zd:Xc + Zd:Xd1
>>> > +
>>> > Zd:Xd2 + (1 + Xc + Xd1 + Xd2 | sub)
>>> >
>>> > Xc: continuous var
>>> > Xd: level-1 dummy variable(s)
>>> > Zd: level-2 dummy variable
>>> >
>>> > A snapshot of data. I can also provide the full dataset if necessary.
>>> > sub Xc Xd1 Xd2 Zd y 1 36 0 0 1 1346 1 45 0 1 1 1508 1 72 1 0 1 1246 1
>>> > 12 1 0
>>> > 1 1164 1 24 1 0 1 1295 1 36 1 0 1 1403
>>> >
>>> > When I reduced the # of random effect to (1+Xc|sub), the warning
>>> > message
>>> > disappeared, but the model fit became poorer.
>>> > My question is: which variable(s) should I rescale? I?d be happy to
>>> > better understand t
>>> > he
>>> >
>>> > warning message if anyone could
>>> > kindly
>>> > suggest
>>> > some
>>> >  reference paper/book.
>>> >
>>> > Thank you very for your help!!
>>> >
>>> > Chunyun
>>> >
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>> --
>> Alex Fine
>> Ph. (336) 302-3251
>> web:  http://internal.psychology.illinois.edu/~abfine/
>
>


From bbolker at gmail.com  Sun Oct 18 19:48:55 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 18 Oct 2015 13:48:55 -0400
Subject: [R-sig-ME] Model is nearly unidentifiable with lmer
In-Reply-To: <CAFS3taQoK8e_F=-duOcWXtt_zi6hGaCECRx5gMMpOP8SbG2btA@mail.gmail.com>
References: <CAFS3taQE0jQADLetQ4Khbh87Vu3v7JoCKS1Qantz8W29mU46Aw@mail.gmail.com>
	<CABghstTZOr-vDwTJ6LZiLjoWQcDC2zdQA=jk3cL2ahLd3XzP8g@mail.gmail.com>
	<CAJ6ui+M8MdA5c5Qw9sc4nCW3UjipykYS0ZTVMSts9pebTCOhfw@mail.gmail.com>
	<CAFS3taTJD9C7ZSxCtfo+v+vsq6uQhM7=W0jGUQBvR9R4ea=ysQ@mail.gmail.com>
	<CAFS3taQoK8e_F=-duOcWXtt_zi6hGaCECRx5gMMpOP8SbG2btA@mail.gmail.com>
Message-ID: <CABghstT4dHn+3YoD7Se9J76qPpX16csqHLcE2Jbsye-KN0y11w@mail.gmail.com>

[cc'd to r-sig-mixed-models]

On Sun, Oct 18, 2015 at 1:06 PM, Chunyun Ma <mcypsy at gmail.com> wrote:
>
> I scaled the continuous predictor (Xc) using scale(Xc, centre=T, scale=T)
> and the warning did disappear! Also, the log likelihood remains the same. As
> Ben suggested, this indicates the large eigenvalue was not actually a
> problem in the first place, although I still feel hazy about why the warning
> appeared previously (I need to refresh my memory of what eigenvalues are).
>
> I also converted the subject using factor(). I would love to better
> understand when it is necessary to factor a variable. I did find a post from
> stackoverflow on a similar topic, but it did not mention the random factor
> in a lmer formula.
>
> Alex, I tried both dummy coding and sum coding as you suggested. I got the
> same warning message with either coding scheme. I still need to carefully
> read your full paper to understand what ?maximal random-effect structure?
> is.
>
> To recap, my remaining questions are:
>
> Can I ignore the eigenvalue warning and proceed with the raw variable
> (because the rescaling makes it hard to interpret) since the log likelihood
> does not change?

  Yes.

> In using lmer for RM design, if the random factor is subject/participant,
> should I always makes sure subject has been converted to factor using
> factor()? Any further reference would be appreciated.

  See previous e-mail.

>
> Many thanks!
>
> Warmly, Chunyun
>
> On Sun, Oct 18, 2015 at 11:46 AM, Chunyun Ma <mcypsy at gmail.com> wrote:
>>
>> Hi dear Ben and Alex!
>>
>> Thank you very much for your help and guidance! I just started reading
>> your references. As I was exploring the alternatives you have suggested,
>> another question came up. This may sounds silly, but I haven't found a
>> definitive answer online: in the lmer formula, is it necessary to convert
>> the random factor into factor using factor()?  Given that I have a RM
>> design, my random factor will always be subject, which is numerical unless I
>> force it into factor...
>>
>> Thank you again!
>>
>> Warmly,  Chunyun
>>
>> On Sun, Oct 11, 2015 at 8:28 PM, Alex Fine <abfine at gmail.com> wrote:
>>>
>>> You might also try using sum-coding rather than (the default) dummy
>>> coding with the categorical predictors.  Assuming the design is roughly
>>> balanced, this is like mean-centering the categorical variables.  This will
>>> change the interpretation of the coefficients.
>>>
>>> Here is some further reading:  http://talklab.psy.gla.ac.uk/tvw/catpred/
>>>
>>> On Sun, Oct 11, 2015 at 8:18 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>> Short answer: try rescaling all of your continuous variables.  It
>>>> can't hurt/will change only the interpretation.  If you get the same
>>>> log-likelihood with the rescaled variables, that indicates that the
>>>> large eigenvalue was not actually a problem in the first place.
>>>>
>>>>    I don't think the standard citation from the R citation file
>>>> <https://cran.r-project.org/web/packages/lme4/citation.html>, or the
>>>> book chapter I wrote recently (chapter 13 of Fox et al, Oxford
>>>> University Press 2015 -- online supplements at
>>>> <http://ms.mcmaster.ca/~bolker/R%/misc/foxchapter/bolker_chap.html>)
>>>> cover rescaling in much detail. Schielzeth 2010
>>>> doi:10.1111/j.2041-210X.2010.00012.x gives a coherent argument about
>>>> the interpretive advantages of scaling.
>>>>
>>>>    Ben Bolker
>>>>
>>>>
>>>> On Sun, Oct 11, 2015 at 6:37 PM, Chunyun Ma <mcypsy at gmail.com> wrote:
>>>> > Dear all,
>>>> >
>>>> > This is my first post in the mailing list.
>>>> > I have been running some model with lmer and came across this warning
>>>> > message:
>>>> >
>>>> > In checkConv(attr(opt, ?derivs?), opt$par, ctrl = control$checkConv, :
>>>> > Model is nearly unidentifiable: very large eigenvalue
>>>> >
>>>> >    - Rescale variables?
>>>> >
>>>> > Here is the formula of my model (I substituted variables names with
>>>> > generic
>>>> > names):
>>>> >
>>>> > y ~ Intercept + Xc + Xd1 + Xd2 + Xc:Xd1 + Xc:Xd2 + Zd + Zd:Xc + Zd:Xd1
>>>> > +
>>>> > Zd:Xd2 + (1 + Xc + Xd1 + Xd2 | sub)
>>>> >
>>>> > Xc: continuous var
>>>> > Xd: level-1 dummy variable(s)
>>>> > Zd: level-2 dummy variable
>>>> >
>>>> > A snapshot of data. I can also provide the full dataset if necessary.
>>>> > sub Xc Xd1 Xd2 Zd y 1 36 0 0 1 1346 1 45 0 1 1 1508 1 72 1 0 1 1246 1
>>>> > 12 1 0
>>>> > 1 1164 1 24 1 0 1 1295 1 36 1 0 1 1403
>>>> >
>>>> > When I reduced the # of random effect to (1+Xc|sub), the warning
>>>> > message
>>>> > disappeared, but the model fit became poorer.
>>>> > My question is: which variable(s) should I rescale? I?d be happy to
>>>> > better understand t
>>>> > he
>>>> >
>>>> > warning message if anyone could
>>>> > kindly
>>>> > suggest
>>>> > some
>>>> >  reference paper/book.
>>>> >
>>>> > Thank you very for your help!!
>>>> >
>>>> > Chunyun
>>>> >
>>>> >
>>>> >         [[alternative HTML version deleted]]
>>>> >
>>>> > _______________________________________________
>>>> > R-sig-mixed-models at r-project.org mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>>
>>> --
>>> Alex Fine
>>> Ph. (336) 302-3251
>>> web:  http://internal.psychology.illinois.edu/~abfine/
>>
>>
>


From thierry.onkelinx at inbo.be  Mon Oct 19 08:39:55 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 19 Oct 2015 08:39:55 +0200
Subject: [R-sig-ME] contrasts among simple effects
In-Reply-To: <CABPq8JMwmzTXVZDLF_c6JNHtOx_75XHh=WQWWzAzhsDVHpFCLw@mail.gmail.com>
References: <CABPq8JMYg79N_My8ue50OYkgjyZO3g=cgyXxieXG+Ti8750DPg@mail.gmail.com>
	<CAJuCY5zCNCDTf1jQh6ZkPv35pb321Bg0xvrXm2jA4XSwDFqUdg@mail.gmail.com>
	<CABPq8JMwmzTXVZDLF_c6JNHtOx_75XHh=WQWWzAzhsDVHpFCLw@mail.gmail.com>
Message-ID: <CAJuCY5zS-z8Z-z92hn8MFMjKYYxywU8rzAWSqGnvc=CxUN10ew@mail.gmail.com>

Dear James,

Please keep the mailing list in cc. Most likely someone else would have
told you that the errors are due to a syntax error. You want lme(HR ~
drug*ordered(time), random =~1|person, correlation =
corAR1(form=~time|person), data = heartRate)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-16 19:07 GMT+02:00 James Henson <jfhenson1 at gmail.com>:

> Dear Thierry,
>
> Thank you for the counsel. However, my perplexity persists.  Many
> variations of adding 'corAR1(form = ~time|person)' return an error
> message.  Some of these variations are below.
>
> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~1|person) =corAR1(, form=~time|person), data = heartRate)
>
> Error: unexpected '=' in "model2b <- lme(HR ~ drug*ordered(time), random
> =~1|person, correlation =corAR1(, form=~1|person) ="
>
>
>
> > model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~1|person) corAR1(, form=~time|person), data = heartRate)
>
> Error: unexpected symbol in "model2b <- lme(HR ~ drug*ordered(time),
> random =~1|person, correlation =corAR1(, form=~1|person) corAR1"
>
>
>
> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~1|person), =corAR1(, form=~time|person), data = heartRate)
>
> Error: unexpected '=' in "model2b <- lme(HR ~ drug*ordered(time), random
> =~1|person, correlation =corAR1(, form=~1|person), ="
>
>
>
> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~time|person), data = heartRate)
>
> Error in structure(res, levels = lv, names = nm, class = "factor") :
> 'names' attribute [72] must be the same length as the vector [0]
>
>
>
> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~1|person, time|person), data = heartRate)
>
> Error in time | person :  operations are possible only for numeric,
> logical or complex types
>
>
>
> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~1|person, form=~time|person), data = heartRate)
>
> Error in corAR1(, form = ~1 | person, form = ~time | person) :  formal
> argument "form" matched by multiple actual arguments
>
>
>
> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~1|person), correlation= corAR1(, form=~time|person), data =
> heartRate)
>
> Error in lme(HR ~ drug * ordered(time), random = ~1 | person, correlation
> = corAR1(,  :   formal argument "correlation" matched by multiple actual
> arguments
>
>
> Hopefully, you can help.
>
> Books on my shelve show R examples from behavioral science.  Need a
> cookbook with R examples from  biology/agriculture, but have not found one.
>
>
> Best regards,
>
> James F. Henson
>
> Research Scientist
>
> Southern University
>
> Baton Rouge, USA
>
> Wisdom is knowing what you don't know. ~ Socrates
>
>
>
>
>
> On Fri, Oct 16, 2015 at 6:24 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear James,
>>
>> I think that you need to specify the order of the data as well.
>> corAR1(form = ~time|person). Otherwise the order of the observations as
>> present in the data is used.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-10-14 18:46 GMT+02:00 James Henson <jfhenson1 at gmail.com>:
>>
>>> Greetings R Community
>>>
>>> Apologize for previously sending a csv file.
>>>
>>> My goal is to make orthogonal contrasts among simple effects in analysis
>>> of
>>> repeated measures data.  The SAS publication, on page 1224, shows how to
>>> make this type of contrasts in SAS.  But, my search of books about
>>> repeated
>>> measures analysis using R, and on-line has not yielded a methodology.
>>> Hopefully, someone can direct me to a book or publication that will show
>>> me
>>> a methodology.
>>>
>>> Statistical Analysis of Repeated Measures Data Using SAS Procedures
>>>
>>>
>>> http://cslras.pbworks.com/f/littell_j_anim_sci_76_4_analysis_of_repeated_measures_using_sas.pdf
>>>
>>>
>>>
>>> Attached is a txt data file (file name = heart_rate.txt).  My code for
>>> the
>>> repeated measures analysis is below.
>>>
>>> library("nlme")
>>>
>>> # with AR1 variance/covariance structure, with ordered statement
>>>
>>> heartRate$time <- factor(heartRate$time)
>>>
>>> model2a <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>>> =corAR1(, form=~1|person), data = heartRate)
>>>
>>> summary(model2a)
>>>
>>> anova(model2a)
>>>
>>> Making a new variable ?simple? that merges the variables drug and time
>>> will
>>> enable me to make orthogonal contrasts among the simple effects.  But,
>>> when
>>> using the variable ?simple? as the independent variable, the data will no
>>> longer be fitted to the AR1 variance/covariance structure.
>>>
>>> Thanks.
>>>
>>> Best regards,
>>>
>>> James F.Henson
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Oct 19 08:49:54 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 19 Oct 2015 08:49:54 +0200
Subject: [R-sig-ME] Hierarchical structure for preservation of
	observations
In-Reply-To: <CAOES0VipWaQuoJqyLQnY0gzPdx1zn6mLwXfXgbp42RyTW5y=0A@mail.gmail.com>
References: <CAOES0VipWaQuoJqyLQnY0gzPdx1zn6mLwXfXgbp42RyTW5y=0A@mail.gmail.com>
Message-ID: <CAJuCY5yuG5HW58u=pr90T9j1fRH_5e884ip+Vk+NFF+vRObT9w@mail.gmail.com>

Dear Jacob,

The random effect specification is correct for the model that you have in
mind.

I'd rather think of the effects of site and genus as crossed rather nested.
The formula would become (1|Site) + (1|Genus). Assuming that you have 5 or
more genera. If not, then it better to add Genus to the fixed effects or
keep your current model.

I'm a bit worried about the complexity of your model. 65 observations is
not a lot for a model with 6 parameters.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-18 16:02 GMT+02:00 Jacob Bukoski <jbukoski1 at gmail.com>:

> Dear all,
>
> I am currently trying to develop a predictive model of ecosystem carbon
> stocks for forests of Southeast Asia. The difficult part is that the
> dataset I've compiled (from published data in the peer-reviewed literature)
> only consists of 65 or so observations.
>
> I've resorted to a mixed effects model under the understanding that I can
> specify a grouping structure and maintain spatially correlated observations
> within each study. However, I'm not sure that my specification of the
> hierarchical structure is acceptable, as this is my first attempt at using
> mixed models.
>
> I am using R version 3.2.2., and the lmer() function of the "lme4" package.
>
> I have specified basal area (a metric of tree stem cross sectional area at
> 1.3 meters height), latitude, and categorical variables for small (mean
> stem diameter < 5 cm) and large (mean stem diameter > 15 cm) forests as
> fixed effects.
>
> I have specified the dominant genus of tree in plots and the site as random
> effects. My thinking here is that plots with the same dominant genera of
> tree would not be independent of one another, nor would plots within the
> same site. Thus, by specifying random effects for Genus in Site... I can
> maintain the individual observations.
>
> The model I have specified as follows:
>
> *lmer1 <- lmer(Biomass ~ Basal.area + Latitude + Small + Large +
> (1|Site/Genus), REML=FALSE)*
>
> *My two-part question is*: (i) Does the logic behind my random effect
> specification hold, and (ii) have I specified it under the lmer() function
> correctly?
>
> Additionally, I am unsure of whether the number of groups has an impact on
> the degrees of freedom. The summary reports 34 groups for Genus:Site, and
> 21 for Site. My specified model has 40 residual degrees of freedom. Have I
> violated my degrees of freedom?
>
> Any advice and external resources will be hugely appreciated!
>
> Many kind thanks,
> Jacob
>
> --
> Jacob J. Bukoski
> Master of Environmental Science Candidate, 2016
> School of Forestry and Environmental Studies, Yale University
> jbukoski1 at gmail.com | jacob.bukoski at yale.edu | LinkedIn
> <
> https://www.linkedin.com/profile/view?id=AAIAAAdWVW8BMzqU_2EGNbEkyuy8O7K1Jyhd8ps&trk=nav_responsive_tab_profile_pic
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From david.tn.jones at gmail.com  Mon Oct 19 14:59:40 2015
From: david.tn.jones at gmail.com (David Jones)
Date: Mon, 19 Oct 2015 08:59:40 -0400
Subject: [R-sig-ME] How to know if random intercepts and slopes are
 necessary for glmer.nb model
Message-ID: <CAJgUswL0mkbgpv-Xt1MsPtVbm9qGUZ+uaJ+wugPZw8Dvh-XcLA@mail.gmail.com>

I am receiving a number of different warnings/errors when running glmer.nb
on a fairly large dataset (N>500,000). For some of the models I have run,
program-reported errors prevent the generation of estimates. I suspect that
it is because the random effects are very small. I have tried models with
random intercepts, as well as models with both random intercepts and slopes
(all models include fixed effects). I am running models on a dataset which
in theory would include random effects (patients nested within hospitals).

My question is: how do you know if random intercepts and slopes are
necessary, if you can't even estimate the random effects models (and thus
use a model comparison test)? As I am aware you can look at design effects
to evaluate if a random intercept is necessary (though please correct me if
I am wrong here).

Some example code I have used is below - many thanks.

a2 <- as.factor(analysis$Location)
NBIntercept<- glmer.nb(y ~ a2 + (1 | Hospital), data = analysis)
NBInterceptSlope <- glmer.nb(y ~ a2 + (1 | Hospital) + (1 + a2 | Hospital),
data = analysis)

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Oct 19 16:04:52 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Oct 2015 10:04:52 -0400
Subject: [R-sig-ME] How to know if random intercepts and slopes are
 necessary for glmer.nb model
In-Reply-To: <CAJgUswL0mkbgpv-Xt1MsPtVbm9qGUZ+uaJ+wugPZw8Dvh-XcLA@mail.gmail.com>
References: <CAJgUswL0mkbgpv-Xt1MsPtVbm9qGUZ+uaJ+wugPZw8Dvh-XcLA@mail.gmail.com>
Message-ID: <CABghstSnJLBw8W0d4hR7NL8WZEUPRNFrC6JUmE5w+jYGseZoxg@mail.gmail.com>

Some relatively stream-of-consciousness thoughts:

* what kind of errors?  glmer.nb is still not as robust as we (or
you!) would like, e.g. see <https://github.com/lme4/lme4/issues/319>
... information on the kinds of warnings & errors you're getting would
be useful.
* in general I would say that you should *try* to keep the random
effects in if you can -- it is a bit of a catch-22 if you can't fit
the models though ...
* do you get similar results for simulated data with similar structure?
* you could try alternative fitting platforms _or_ alternative models
to account for dispersion, specifically
    * glmmADMB (could be slow for large data sets?)
    * glmmTMB (experimental! <https://github.com/glmmTMB/glmmTMB> )
    (any other suggestions welcome ...)
    * using an observation-level random effect rather than NB to
account for dispersion (in my experience these tend to give similar
results: Harrison 2015 <https://peerj.com/articles/1114/> does a
simulation study for the analogous case of overdispersed binomial
models and concludes "use with caution ...")

On Mon, Oct 19, 2015 at 8:59 AM, David Jones <david.tn.jones at gmail.com> wrote:
> I am receiving a number of different warnings/errors when running glmer.nb
> on a fairly large dataset (N>500,000). For some of the models I have run,
> program-reported errors prevent the generation of estimates. I suspect that
> it is because the random effects are very small. I have tried models with
> random intercepts, as well as models with both random intercepts and slopes
> (all models include fixed effects). I am running models on a dataset which
> in theory would include random effects (patients nested within hospitals).
>
> My question is: how do you know if random intercepts and slopes are
> necessary, if you can't even estimate the random effects models (and thus
> use a model comparison test)? As I am aware you can look at design effects
> to evaluate if a random intercept is necessary (though please correct me if
> I am wrong here).
>
> Some example code I have used is below - many thanks.
>
> a2 <- as.factor(analysis$Location)
> NBIntercept<- glmer.nb(y ~ a2 + (1 | Hospital), data = analysis)
> NBInterceptSlope <- glmer.nb(y ~ a2 + (1 | Hospital) + (1 + a2 | Hospital),
> data = analysis)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dwinsemius at comcast.net  Mon Oct 19 22:57:05 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 19 Oct 2015 13:57:05 -0700
Subject: [R-sig-ME] about: GLMM for continuous response
In-Reply-To: <C3F9763A-8F30-4B38-A245-E609209E0FB0@comcast.net>
References: <ddd61b0f83219a2f68c61adea60fe7d5@hacettepe.edu.tr>
	<C3F9763A-8F30-4B38-A245-E609209E0FB0@comcast.net>
Message-ID: <CB92E787-CAF3-405D-AD3A-559D8F344F09@comcast.net>

When you responded to me privately, you included useful information and code that could have been assessed by other subscribers of this mailing list. I would encourage you to post that reply to the mailing list as well. I am by no means the most knowledgeable on `lmer` numerical stability questions.

I continue to think that using policy number as a random effect and also number of claims as a fixed effect is incorrect on methodological grounds and may also be the cause of your convergence errors and variations in the parameter estimates.

-- 
David 

On Oct 17, 2015, at 1:24 PM, David Winsemius wrote:

> 
> On Oct 15, 2015, at 6:02 AM, Asl?han ?ent?rk Acar wrote:
> 
>> 
>> Dear Sir,
>> 
>> I am a Phd student working on GLMM implementation for continuous response of insurance claim size. I have some problems to implement GLMM in R. I would be very glad if you could answer.
>> 
>> Response variable y_ij: jth claim amount of individual i. People can have just one claim or more than one claim (max. claim number is 136. so j=1,2,...,136).
> 
> What about zero claims? Those are the policy holders who are paying for persons or entities who did have non-zero claims. 
> 
>> 
>> There are 22 000 individuals in the sample. Explanatory variables are (fixed effects): claim number in one year (integer), age(integer), gender (0-1,factor), provience (0-6,factor), package (0-3,factor), marital status (0-1,factor).
>> 
> 
> Including 'claim number' as a fixed effect would seem to be highly questionable. It presumes you could have known in advance who would become the high claim policyholders.
> 
> 
>> *I use only random intercept as random effect.
>> 
>> I am using R 3.0.3, MASS, lme4,nlme and lm4.0 packages.
>> 
>> My questions are:
>> 
>> 
>> 1- I use GLMMPQL (MASS package) that generally converges. But laplace and quadrature never converges. I did not understand the reason. What can be the reason? While implementing GLMM are the individuals that have just one claim problem for model convergence?
>> 
> 
> You should offer actual code samples. I get the impression you are using more than just the glmmPQL function, since ?glmmPQL says options are passed to lme and those are not offered as options in the ?lmeControl page.
> 
>> note: gamma glm, log transform and linear mixed model, gamma GEE all converges.
>> 
>> 2- I simulated gamma distributed response variable and used a few covariates to test convergence error. Laplace converges, Quadrature does not converge again. While PQL gives 0.2632854 for standard deviation of random intercept, glmer (laplace) gives std. dev 1028.16. Why is so huge difference between two methods?
> 
> Wouldn't the data and code be needed for an answer? The FAQ says gamma models can be "difficult": http://glmm.wikidot.com/faq. It makes me wonder whether you have achieved complete separation in one of the models through excessive control for the claim-number variable.
> 
> 
>> 
>> 3- GLMMPQL converges with all explanatory variables. Province and gender are not significant. When I exclude only province GLMMPQL does not converge. But when I exclude gender and both province+gender it converges. Why is this contradiction?
> 
> Wouldn't we need to see the data to answer such a question?
> 
>> 
>> 4- I could not see any paper on GLMM applications for continuous response.
> 
> ???  Gamma is not a continuous response? Log-normal as well?
> 
> https://www.researchgate.net/profile/Jostein_Paulsen/publication/222532925_Fitting_mixed-effects_models_when_data_are_left_truncated/links/0c96052542940503ac000000.pdf
> 
> 
>> I am afraid of doing something wrong but I ca not find any reference. Can you give me any references to understand detail of GLMM implementation for continuous response and general idea for implementation of GLMM.
>> 
> 
> Wouldn't that simply depend on what `family` (or link) argument was offered to your regression function?
> 
>> 5- I do not want to make logarithmic transform and fit linear mixed models, I want to use data on original scale. Do you offer any other distribution exempt gamma GLMM?
> 
> Do you have some descriptive data regarding the response? Seems that insurance claims problems should be using truncated distributions if at all possible. (See the citation above.)  There is often both a minimum and maximum value for coverage.
> 
>> 
>> 
>> I appreciate any help.
>> 
>> Thank you very much.
>> 
>> Best wishes,
>> 
>> Aslihan
>> 
>> 
>> -- 
>> Aslihan Senturk Acar
>> 
>> Research Assistant
>> Hacettepe University
>> Department of Actuarial Sciences
>> Beytepe, Ankara
>> 08600
>> 
>> Phone: (+90) 312 297 6160 / 119
>> Email: aslihans at hacettepe.edu.tr
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> David Winsemius
> Alameda, CA, USA
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA


From saah500 at york.ac.uk  Tue Oct 20 11:51:07 2015
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Tue, 20 Oct 2015 12:51:07 +0300
Subject: [R-sig-ME] GLMM model failing to converge
Message-ID: <CACrevpmgHVabso4MFw-P6iTtNiE-0u8wt-4o2nTY03VtMN+HWA@mail.gmail.com>

Thanks a lot Alain for your response. For some reason I didn't see it
before.

Best regards,

-- 
Shadiya

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue Oct 20 12:18:18 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 20 Oct 2015 11:18:18 +0100
Subject: [R-sig-ME] How to know if random intercepts and slopes are,
 necessary for glmer.nb model
In-Reply-To: <mailman.1.1445335202.20581.r-sig-mixed-models@r-project.org>
References: <mailman.1.1445335202.20581.r-sig-mixed-models@r-project.org>
Message-ID: <562614EA.6050101@highstat.com>




> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 19 Oct 2015 08:59:40 -0400
> From: David Jones <david.tn.jones at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] How to know if random intercepts and slopes are
> 	necessary for glmer.nb model
> Message-ID:
> 	<CAJgUswL0mkbgpv-Xt1MsPtVbm9qGUZ+uaJ+wugPZw8Dvh-XcLA at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> I am receiving a number of different warnings/errors when running glmer.nb
> on a fairly large dataset (N>500,000). For some of the models I have run,
> program-reported errors prevent the generation of estimates. I suspect that
> it is because the random effects are very small. I have tried models with
> random intercepts, as well as models with both random intercepts and slopes
> (all models include fixed effects). I am running models on a dataset which
> in theory would include random effects (patients nested within hospitals).
>
> My question is: how do you know if random intercepts and slopes are
> necessary, if you can't even estimate the random effects models (and thus
> use a model comparison test)? As I am aware you can look at design effects
> to evaluate if a random intercept is necessary (though please correct me if
> I am wrong here).
>
> Some example code I have used is below - many thanks.
>
> a2 <- as.factor(analysis$Location)
> NBIntercept<- glmer.nb(y ~ a2 + (1 | Hospital), data = analysis)
> NBInterceptSlope <- glmer.nb(y ~ a2 + (1 | Hospital) + (1 + a2 | Hospital),
> data = analysis)
>
> 	[[alternative HTML version deleted]]
>

David....this is a little bit a 'Gandalf' question. Perhaps you should 
first figure out why the NB GLMM does not run. How many hospitals do you 
have. Perhaps you can set the theta parameter in glmer.nb to a fixed 
value (use an interval with nearly the same lower and upper limit).... 
and get the (log of ) theta from a nearby NB GLM model. That would 
certainly make the estimation process easier!

Why are you doing an NB GLMM? Do the Poisson GLMM equivalents run? I 
assume you had overdispersion. What was driving the overdispersion?

And if computing time is slow for the second NB GLMM model, fit the 
first model and see whether there are any a2 effects per hospital in the 
residuals of the first model.


Alain




-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From highstat at highstat.com  Tue Oct 20 12:42:48 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 20 Oct 2015 11:42:48 +0100
Subject: [R-sig-ME] How to know if random intercepts and slopes are,
 necessary for glmer.nb model
In-Reply-To: <CAJgUswJRJidAD1X3YbL4yVqSXgR6j+PQfppH3cJYG0ji1S-nmw@mail.gmail.com>
References: <mailman.1.1445335202.20581.r-sig-mixed-models@r-project.org>
	<562614EA.6050101@highstat.com>
	<CAJgUswJRJidAD1X3YbL4yVqSXgR6j+PQfppH3cJYG0ji1S-nmw@mail.gmail.com>
Message-ID: <56261AA8.2040005@highstat.com>



On 20/10/2015 11:32, David Jones wrote:
> Dear Alain - Thank you for these suggestions. In response to your 
> questions:
>
> Poisson GLMM equivalents often run for these models (though I get the 
> warning, "Model is nearly unidentifiable: very large eigenvalue"). For 
> the models that do fit without problems, overdispersion tests do 
> reflect overdispersion, and negative binomial model equivalents 
> reflect better fit based on a chi-square comparison of -2LL.

David...a better LL (or significant Chi-square test) is not an excuse 
for applying an NB GLM or NB GLMM. Overdispersion can be caused by at 
least 10 different causes (and each requiring a different 
solution)...and you need to pinpoint what is driving the overdispersion. 
If you pick the wrong cause, then you may up with a wrong model.

However....you state that the overdispersion is due to a few patients 
who stay for a long time in the hospital. That would be an argument in 
favour of using the NB GLMM. But also for using a Poisson GLMM with an 
observation level random intercept. The later one is much faster to 
estimate. It is not my favourite model....but being pragmatic......it is 
perhaps the way forward.

Setting the theta to a fixed value in glmer.nb will certainly help.


Kind regards,

Alain

PS...is length of stay in a hospital not strictly positive? Not that I 
want to suggest to use a zero truncated distribution for a data set with 
500,000 observations....:-)


> The DV is length of stay in hospital and the overdispersion is due to 
> some patients who stay for a very long time. For hospital count, there 
> are over 150 hospitals.
> //
>
> On Tue, Oct 20, 2015 at 6:18 AM, Highland Statistics Ltd 
> <highstat at highstat.com <mailto:highstat at highstat.com>> wrote:
>
>
>
>
>         ----------------------------------------------------------------------
>
>         Message: 1
>         Date: Mon, 19 Oct 2015 08:59:40 -0400
>         From: David Jones <david.tn.jones at gmail.com
>         <mailto:david.tn.jones at gmail.com>>
>         To: r-sig-mixed-models at r-project.org
>         <mailto:r-sig-mixed-models at r-project.org>
>         Subject: [R-sig-ME] How to know if random intercepts and
>         slopes are
>                 necessary for glmer.nb model
>         Message-ID:
>                
>         <CAJgUswL0mkbgpv-Xt1MsPtVbm9qGUZ+uaJ+wugPZw8Dvh-XcLA at mail.gmail.com
>         <mailto:CAJgUswL0mkbgpv-Xt1MsPtVbm9qGUZ%2BuaJ%2BwugPZw8Dvh-XcLA at mail.gmail.com>>
>         Content-Type: text/plain; charset="UTF-8"
>
>         I am receiving a number of different warnings/errors when
>         running glmer.nb
>         on a fairly large dataset (N>500,000). For some of the models
>         I have run,
>         program-reported errors prevent the generation of estimates. I
>         suspect that
>         it is because the random effects are very small. I have tried
>         models with
>         random intercepts, as well as models with both random
>         intercepts and slopes
>         (all models include fixed effects). I am running models on a
>         dataset which
>         in theory would include random effects (patients nested within
>         hospitals).
>
>         My question is: how do you know if random intercepts and
>         slopes are
>         necessary, if you can't even estimate the random effects
>         models (and thus
>         use a model comparison test)? As I am aware you can look at
>         design effects
>         to evaluate if a random intercept is necessary (though please
>         correct me if
>         I am wrong here).
>
>         Some example code I have used is below - many thanks.
>
>         a2 <- as.factor(analysis$Location)
>         NBIntercept<- glmer.nb(y ~ a2 + (1 | Hospital), data = analysis)
>         NBInterceptSlope <- glmer.nb(y ~ a2 + (1 | Hospital) + (1 + a2
>         | Hospital),
>         data = analysis)
>
>                 [[alternative HTML version deleted]]
>
>
>     David....this is a little bit a 'Gandalf' question. Perhaps you
>     should first figure out why the NB GLMM does not run. How many
>     hospitals do you have. Perhaps you can set the theta parameter in
>     glmer.nb to a fixed value (use an interval with nearly the same
>     lower and upper limit).... and get the (log of ) theta from a
>     nearby NB GLM model. That would certainly make the estimation
>     process easier!
>
>     Why are you doing an NB GLMM? Do the Poisson GLMM equivalents run?
>     I assume you had overdispersion. What was driving the overdispersion?
>
>     And if computing time is slow for the second NB GLMM model, fit
>     the first model and see whether there are any a2 effects per
>     hospital in the residuals of the first model.
>
>
>     Alain
>
>
>
>
>     -- 
>     Dr. Alain F. Zuur
>
>     First author of:
>     1. Beginner's Guide to GAMM with R (2014).
>     2. Beginner's Guide to GLM and GLMM with R (2013).
>     3. Beginner's Guide to GAM with R (2012).
>     4. Zero Inflated Models and GLMM with R (2012).
>     5. A Beginner's Guide to R (2009).
>     6. Mixed effects models and extensions in ecology with R (2009).
>     7. Analysing Ecological Data (2007).
>
>     Highland Statistics Ltd.
>     9 St Clair Wynd
>     UK - AB41 6DZ Newburgh
>     Tel:   0044 1358 788177
>     Email: highstat at highstat.com <mailto:highstat at highstat.com>
>     URL: www.highstat.com <http://www.highstat.com>
>
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From david.tn.jones at gmail.com  Tue Oct 20 13:24:02 2015
From: david.tn.jones at gmail.com (David Jones)
Date: Tue, 20 Oct 2015 07:24:02 -0400
Subject: [R-sig-ME] How to know if random intercepts and slopes are,
 necessary for glmer.nb model
In-Reply-To: <56261AA8.2040005@highstat.com>
References: <mailman.1.1445335202.20581.r-sig-mixed-models@r-project.org>
	<562614EA.6050101@highstat.com>
	<CAJgUswJRJidAD1X3YbL4yVqSXgR6j+PQfppH3cJYG0ji1S-nmw@mail.gmail.com>
	<56261AA8.2040005@highstat.com>
Message-ID: <CAJgUswLAEQnPWY-10NGfpUK0Z7tC4iaUehhvrwgrn8NtpW8vGw@mail.gmail.com>

Thank you for this input Alain - it will be very helpful as I hammer things
out. Reviewers did specifically ask for negative binomial so I am trying to
give them what they want ... not that this would be a good excuse if it
were the only rationale. I do share with you with a cringe at the prospects
of running a zero truncated model on this dataset :)

Also, following up on Ben Bolker's answers,

I found in a couple of previous posts by Ben that absolute gradient below
.001 or so is good (sorry I didn't see the first time when I had searched -
posts can be found at https://goo.gl/SxUev4 and https://goo.gl/LnyDGA). So,
correct me if I am wrong, but given that all of my absolute gradients were
well below this, looks like things are good for the random intercept models
at least! The random slopes model results are tough, but I probably can
live without them if necessary ... perhaps will eventually find a way to
see if it is negligible random slopes that is causing this or another
reason, and any suggestions given the warnings/errors are welcome (I am
happy to provide more info if it is helpful).

On Tue, Oct 20, 2015 at 6:42 AM, Highland Statistics Ltd <
highstat at highstat.com> wrote:

>
>
> On 20/10/2015 11:32, David Jones wrote:
>
> Dear Alain - Thank you for these suggestions. In response to your
> questions:
>
> Poisson GLMM equivalents often run for these models (though I get the
> warning, "Model is nearly unidentifiable: very large eigenvalue"). For the
> models that do fit without problems, overdispersion tests do reflect
> overdispersion, and negative binomial model equivalents reflect better fit
> based on a chi-square comparison of -2LL.
>
>
> David...a better LL (or significant Chi-square test) is not an excuse for
> applying an NB GLM or NB GLMM. Overdispersion can be caused by at least 10
> different causes (and each requiring a different solution)...and you need
> to pinpoint what is driving the overdispersion. If you pick the wrong
> cause, then you may up with a wrong model.
>
> However....you state that the overdispersion is due to a few patients who
> stay for a long time in the hospital. That would be an argument in favour
> of using the NB GLMM. But also for using a Poisson GLMM with an observation
> level random intercept. The later one is much faster to estimate. It is not
> my favourite model....but being pragmatic......it is perhaps the way
> forward.
>
> Setting the theta to a fixed value in glmer.nb will certainly help.
>
>
> Kind regards,
>
> Alain
>
> PS...is length of stay in a hospital not strictly positive? Not that I
> want to suggest to use a zero truncated distribution for a data set with
> 500,000 observations....:-)
>
>
>
> The DV is length of stay in hospital and the overdispersion is due to some
> patients who stay for a very long time. For hospital count, there are over
> 150 hospitals.
>
>
>
> On Tue, Oct 20, 2015 at 6:18 AM, Highland Statistics Ltd <
> <highstat at highstat.com>highstat at highstat.com> wrote:
>
>>
>>
>>
>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Mon, 19 Oct 2015 08:59:40 -0400
>>> From: David Jones <david.tn.jones at gmail.com>
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] How to know if random intercepts and slopes are
>>>         necessary for glmer.nb model
>>> Message-ID:
>>>         <
>>> CAJgUswL0mkbgpv-Xt1MsPtVbm9qGUZ+uaJ+wugPZw8Dvh-XcLA at mail.gmail.com>
>>> Content-Type: text/plain; charset="UTF-8"
>>>
>>> I am receiving a number of different warnings/errors when running
>>> glmer.nb
>>> on a fairly large dataset (N>500,000). For some of the models I have run,
>>> program-reported errors prevent the generation of estimates. I suspect
>>> that
>>> it is because the random effects are very small. I have tried models with
>>> random intercepts, as well as models with both random intercepts and
>>> slopes
>>> (all models include fixed effects). I am running models on a dataset
>>> which
>>> in theory would include random effects (patients nested within
>>> hospitals).
>>>
>>> My question is: how do you know if random intercepts and slopes are
>>> necessary, if you can't even estimate the random effects models (and thus
>>> use a model comparison test)? As I am aware you can look at design
>>> effects
>>> to evaluate if a random intercept is necessary (though please correct me
>>> if
>>> I am wrong here).
>>>
>>> Some example code I have used is below - many thanks.
>>>
>>> a2 <- as.factor(analysis$Location)
>>> NBIntercept<- glmer.nb(y ~ a2 + (1 | Hospital), data = analysis)
>>> NBInterceptSlope <- glmer.nb(y ~ a2 + (1 | Hospital) + (1 + a2 |
>>> Hospital),
>>> data = analysis)
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>> David....this is a little bit a 'Gandalf' question. Perhaps you should
>> first figure out why the NB GLMM does not run. How many hospitals do you
>> have. Perhaps you can set the theta parameter in glmer.nb to a fixed value
>> (use an interval with nearly the same lower and upper limit).... and get
>> the (log of ) theta from a nearby NB GLM model. That would certainly make
>> the estimation process easier!
>>
>> Why are you doing an NB GLMM? Do the Poisson GLMM equivalents run? I
>> assume you had overdispersion. What was driving the overdispersion?
>>
>> And if computing time is slow for the second NB GLMM model, fit the first
>> model and see whether there are any a2 effects per hospital in the
>> residuals of the first model.
>>
>>
>> Alain
>>
>>
>>
>>
>> --
>> Dr. Alain F. Zuur
>>
>> First author of:
>> 1. Beginner's Guide to GAMM with R (2014).
>> 2. Beginner's Guide to GLM and GLMM with R (2013).
>> 3. Beginner's Guide to GAM with R (2012).
>> 4. Zero Inflated Models and GLMM with R (2012).
>> 5. A Beginner's Guide to R (2009).
>> 6. Mixed effects models and extensions in ecology with R (2009).
>> 7. Analysing Ecological Data (2007).
>>
>> Highland Statistics Ltd.
>> 9 St Clair Wynd
>> UK - AB41 6DZ Newburgh
>> Tel:   0044 1358 788177
>> Email: highstat at highstat.com
>> URL:   www.highstat.com
>>
>>
>
> --
> Dr. Alain F. Zuur
>
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
>
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
>

	[[alternative HTML version deleted]]


From karraspito at yahoo.es  Tue Oct 20 14:11:38 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Tue, 20 Oct 2015 12:11:38 +0000 (UTC)
Subject: [R-sig-ME] Reserved variable "trait"
In-Reply-To: <20151012124046.145512z9cntzukw0@www.staffmail.ed.ac.uk>
References: <20151012124046.145512z9cntzukw0@www.staffmail.ed.ac.uk>
Message-ID: <1411383826.378609.1445343098855.JavaMail.yahoo@mail.yahoo.com>


?? Hello everyone, 

?? I am reading the Course Notes at the moment and tomorrow I will implement some bivariate categorical models, hopefully this time including all the elements that need to be included for the models to work optimally. I have two quick questions about the reserved variable "trait":?? 
?? 1. One is about its usage: in many places I've seen something like "model1<-cbind(x,y)~trait-1+indepvar1+indepvar2....etc". However, in some others I've seen  "model1<-cbind(x,y)~trait-1+trait:indepvar1+trait:indepvar2...."
?? My question: Do I need to add "trait" to each and every single one of my independent variables, or is it enough with adding "trait-1" and then the independent variables? I mean, I have six simple independent variables plus all the possible two-way interactions between them, it would be a bit complicated if it is the last option ? unless I do it like "trait:(indep1*indep2*indep3...etc)".
?? Additionaly, Jarrod says this in the Course Notes: "I usually suppress the intercept (-1) for these types of models so the second coefficient is not the dierence between the intercept for the 1st level of trait (y.hol) and the second level (y.car) but the actual trait specific intercepts." I suppose this depends on the type of model, but, in which type is it advisable to do it?
?? 2. The other one is just about the output: Once I have included the reserved variable "trait" in my model (and so I can get a different intercept for each of my responses), will I have any way of knowing which part of the observed variance applies to each of the two response variables looking at the summary output?
?? Thank you very much in advance,?? Iker
?__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


      De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
 Para: Iker Vaquero Alba <karraspito at yahoo.es> 
CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Enviado: Lunes 12 de octubre de 2015 12:40
 Asunto: Re: [R-sig-ME] MCMCglmm prior specification
   
Hi,

Usually people think the default priors for the fixed effects (zero? 
mean, high variance) are reasonable. However, there are cases where? 
stronger priors are useful. For example, a) you might actually have? 
some prior information or b) you might have near or complete? 
separation in a GLMM (usually with categorical data) and you might? 
want to constrain the fixed effects so they don't result in extreme? 
predictions.

Cheers,

Jarrod




? Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Mon, 12 Oct 2015? 
11:05:58 +0000 (UTC):

>
> ?? Hi Jarrod,?? Thanks a lot for your reply. I had actually found? 
> information about it in another post and wanted to "fix" my own? 
> question, but for some reason individual posts don't arrive to my? 
> email even if I have that option activated, so I couldn't reply to? 
> myself.?? My question, then, would be: most of the times I see? 
> priors with just R and G elements, but not B. Is it not necessary to? 
> specify B? Also, if my model does not have random effects, then? 
> would it be enough with a prior for R element?
>
> ?? Thank you very much.?? Iker.
>
>
> __________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
>
>
>? ? ? De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>? Para: Iker Vaquero Alba <karraspito at yahoo.es>
> CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
>? Enviado: Lunes 12 de octubre de 2015 11:56
>? Asunto: Re: [R-sig-ME] MCMCglmm prior specification
>
> Hi,
>
> R defines the prior for the residual covariance matrices. B specifies?
> the prior for the `fixed' effects.
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Mon, 12 Oct 2015?
> 10:34:01 +0000 (UTC):
>
>
>
>> ?? Hello everyone,
>> ?? I am reading a lot of documentation at the moment about prior?
>> specification in MCMCglmm, and there is still something I have not?
>> very clear. According to some sources, there are mainly two elements?
>> to take into account when defining a prior:?? - An R structure that?
>> needs to be specified for each fixed effect. And
>> ?? - A G structure for each random effect.
>> ?? However, in other sources another element, B, is introduced as?
>> well, which refers to fixed effects too. In Jarrod's Course Notes, I?
>> see that both R and B have to do with fixed effects: R specifies V?
>> and nu arguments for the variance, and B specifies V and mu elements?
>> for the mean.
>> ??
>> ?? My confusion comes from the fact that almost every time I see an?
>> example of a prior, it just has two elements, R (for fixed effects)?
>> and G (for random effects). Why is this? Is it not so important to?
>> define a prior for the mean? Is it enough with a prior specification?
>> for the variance of fixed effects and another one for all the random?
>> effects?
>> ?? Thank you very much in advance.?? Iker
>>
>> ?
>> __________________________________________________________________
>>
>> ?? Iker Vaquero-Alba
>> ?? Visiting Postdoctoral Research Associate
>> ?? Laboratory of Evolutionary Ecology of Adaptations
>> ?? Joseph Banks Laboratories
>> ?? School of Life Sciences
>> ?? University of Lincoln?? Brayford Campus, Lincoln
>> ?? LN6 7DL
>> ?? United Kingdom
>>
>> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


>
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.




  
	[[alternative HTML version deleted]]


From jfhenson1 at gmail.com  Mon Oct 19 21:24:05 2015
From: jfhenson1 at gmail.com (James Henson)
Date: Mon, 19 Oct 2015 14:24:05 -0500
Subject: [R-sig-ME] contrasts among simple effects
In-Reply-To: <CAJuCY5zS-z8Z-z92hn8MFMjKYYxywU8rzAWSqGnvc=CxUN10ew@mail.gmail.com>
References: <CABPq8JMYg79N_My8ue50OYkgjyZO3g=cgyXxieXG+Ti8750DPg@mail.gmail.com>
	<CAJuCY5zCNCDTf1jQh6ZkPv35pb321Bg0xvrXm2jA4XSwDFqUdg@mail.gmail.com>
	<CABPq8JMwmzTXVZDLF_c6JNHtOx_75XHh=WQWWzAzhsDVHpFCLw@mail.gmail.com>
	<CAJuCY5zS-z8Z-z92hn8MFMjKYYxywU8rzAWSqGnvc=CxUN10ew@mail.gmail.com>
Message-ID: <CABPq8JPF7mhEgKjfGH7xGKsJso8gMfoUOAkVU-wV9ZnGo_4z7w@mail.gmail.com>

Dear Russell,

Your assistance is appreciated. However, the code below returns an error
message. Maybe my model is inappropriate. It was necessary to remove the
ordered statement [ordered(time)], because apparently with the ordered
statement lsmeans did not read time as a factor.

library("nlme")

# with AR1 variance/covariance structure

heartRate$time <- factor(heartRate$time)

model2a <- lme(HR ~ drug*time, random =~1|person, correlation
=corAR1(form=~1|person), data = heartRate)

summary(model2a)

library("lsmeans")

anova(model2a)

lsm <- lsmeans(model2a, ~ drug|time)

lsm

Error in format.default(nm[j], width = nchar(m[1, j]), just = "left") :

  4 arguments passed to .Internal(nchar) which requires 3



pairs(lsm)

pairs(lsm, by = "drug")



The Using lsmeans tutorial (Oct 9, 2015) illustrates the usefulness of the
lsmeans package.

Best regards,

James F. Henson

On Mon, Oct 19, 2015 at 1:39 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear James,
>
> Please keep the mailing list in cc. Most likely someone else would have
> told you that the errors are due to a syntax error. You want lme(HR ~
> drug*ordered(time), random =~1|person, correlation =
> corAR1(form=~time|person), data = heartRate)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-16 19:07 GMT+02:00 James Henson <jfhenson1 at gmail.com>:
>
>> Dear Thierry,
>>
>> Thank you for the counsel. However, my perplexity persists.  Many
>> variations of adding 'corAR1(form = ~time|person)' return an error
>> message.  Some of these variations are below.
>>
>> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>> =corAR1(, form=~1|person) =corAR1(, form=~time|person), data = heartRate)
>>
>> Error: unexpected '=' in "model2b <- lme(HR ~ drug*ordered(time), random
>> =~1|person, correlation =corAR1(, form=~1|person) ="
>>
>>
>>
>> > model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>> =corAR1(, form=~1|person) corAR1(, form=~time|person), data = heartRate)
>>
>> Error: unexpected symbol in "model2b <- lme(HR ~ drug*ordered(time),
>> random =~1|person, correlation =corAR1(, form=~1|person) corAR1"
>>
>>
>>
>> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>> =corAR1(, form=~1|person), =corAR1(, form=~time|person), data = heartRate)
>>
>> Error: unexpected '=' in "model2b <- lme(HR ~ drug*ordered(time), random
>> =~1|person, correlation =corAR1(, form=~1|person), ="
>>
>>
>>
>> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>> =corAR1(, form=~time|person), data = heartRate)
>>
>> Error in structure(res, levels = lv, names = nm, class = "factor") :
>> 'names' attribute [72] must be the same length as the vector [0]
>>
>>
>>
>> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>> =corAR1(, form=~1|person, time|person), data = heartRate)
>>
>> Error in time | person :  operations are possible only for numeric,
>> logical or complex types
>>
>>
>>
>> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>> =corAR1(, form=~1|person, form=~time|person), data = heartRate)
>>
>> Error in corAR1(, form = ~1 | person, form = ~time | person) :  formal
>> argument "form" matched by multiple actual arguments
>>
>>
>>
>> model2b <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>> =corAR1(, form=~1|person), correlation= corAR1(, form=~time|person), data =
>> heartRate)
>>
>> Error in lme(HR ~ drug * ordered(time), random = ~1 | person, correlation
>> = corAR1(,  :   formal argument "correlation" matched by multiple actual
>> arguments
>>
>>
>> Hopefully, you can help.
>>
>> Books on my shelve show R examples from behavioral science.  Need a
>> cookbook with R examples from  biology/agriculture, but have not found one.
>>
>>
>> Best regards,
>>
>> James F. Henson
>>
>> Research Scientist
>>
>> Southern University
>>
>> Baton Rouge, USA
>>
>> Wisdom is knowing what you don't know. ~ Socrates
>>
>>
>>
>>
>>
>> On Fri, Oct 16, 2015 at 6:24 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear James,
>>>
>>> I think that you need to specify the order of the data as well.
>>> corAR1(form = ~time|person). Otherwise the order of the observations as
>>> present in the data is used.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2015-10-14 18:46 GMT+02:00 James Henson <jfhenson1 at gmail.com>:
>>>
>>>> Greetings R Community
>>>>
>>>> Apologize for previously sending a csv file.
>>>>
>>>> My goal is to make orthogonal contrasts among simple effects in
>>>> analysis of
>>>> repeated measures data.  The SAS publication, on page 1224, shows how to
>>>> make this type of contrasts in SAS.  But, my search of books about
>>>> repeated
>>>> measures analysis using R, and on-line has not yielded a methodology.
>>>> Hopefully, someone can direct me to a book or publication that will
>>>> show me
>>>> a methodology.
>>>>
>>>> Statistical Analysis of Repeated Measures Data Using SAS Procedures
>>>>
>>>>
>>>> http://cslras.pbworks.com/f/littell_j_anim_sci_76_4_analysis_of_repeated_measures_using_sas.pdf
>>>>
>>>>
>>>>
>>>> Attached is a txt data file (file name = heart_rate.txt).  My code for
>>>> the
>>>> repeated measures analysis is below.
>>>>
>>>> library("nlme")
>>>>
>>>> # with AR1 variance/covariance structure, with ordered statement
>>>>
>>>> heartRate$time <- factor(heartRate$time)
>>>>
>>>> model2a <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
>>>> =corAR1(, form=~1|person), data = heartRate)
>>>>
>>>> summary(model2a)
>>>>
>>>> anova(model2a)
>>>>
>>>> Making a new variable ?simple? that merges the variables drug and time
>>>> will
>>>> enable me to make orthogonal contrasts among the simple effects.  But,
>>>> when
>>>> using the variable ?simple? as the independent variable, the data will
>>>> no
>>>> longer be fitted to the AR1 variance/covariance structure.
>>>>
>>>> Thanks.
>>>>
>>>> Best regards,
>>>>
>>>> James F.Henson
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Wed Oct 21 17:37:00 2015
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Wed, 21 Oct 2015 15:37:00 +0000
Subject: [R-sig-ME] contrasts among simple effects
Message-ID: <BY2PR0401MB09191078F676829B3D11999CF1380@BY2PR0401MB0919.namprd04.prod.outlook.com>

I did not experience either of the problems you report running a very similar example -- see below. I wonder if you have some kind of masking problem, or need to start afresh or update your packages or your version of R. 

Russ
[PS - if you reply, please include me directly]
--
Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017


> library(nlme)
> Oats.lme <- lme(yield ~ Variety * ordered(nitro), ~ 1|Block/Variety, data = Oats)

> library(lsmeans)
> lsm <- lsmeans(Oats.lme, ~ Variety | nitro)

> lsm
nitro = 0.0:
 Variety        lsmean       SE df  lower.CL  upper.CL
 Golden Rain  80.00000 9.106959  5  56.58982 103.41018
 Marvellous   86.66667 9.106959  5  63.25648 110.07685
 Victory      71.50000 9.106959  5  48.08982  94.91018

nitro = 0.2:
 Variety        lsmean       SE df  lower.CL  upper.CL
 Golden Rain  98.50000 9.106959  5  75.08982 121.91018
 Marvellous  108.50000 9.106959  5  85.08982 131.91018
 Victory      89.66667 9.106959  5  66.25648 113.07685

nitro = 0.4:
 Variety        lsmean       SE df  lower.CL  upper.CL
 Golden Rain 114.66667 9.106959  5  91.25648 138.07685
 Marvellous  117.16667 9.106959  5  93.75648 140.57685
 Victory     110.83333 9.106959  5  87.42315 134.24352

nitro = 0.6:
 Variety        lsmean       SE df  lower.CL  upper.CL
 Golden Rain 124.83333 9.106959  5 101.42315 148.24352
 Marvellous  126.83333 9.106959  5 103.42315 150.24352
 Victory     118.50000 9.106959  5  95.08982 141.91018

Confidence level used: 0.95 


> pairs(lsm)
nitro = 0.0:
 contrast                   estimate       SE df t.ratio p.value
 Golden Rain - Marvellous  -6.666667 9.715029 10  -0.686  0.7766
 Golden Rain - Victory      8.500000 9.715029 10   0.875  0.6673
 Marvellous - Victory      15.166667 9.715029 10   1.561  0.3057

nitro = 0.2:
 contrast                   estimate       SE df t.ratio p.value
 Golden Rain - Marvellous -10.000000 9.715029 10  -1.029  0.5762
 Golden Rain - Victory      8.833333 9.715029 10   0.909  0.6470
 Marvellous - Victory      18.833333 9.715029 10   1.939  0.1783

nitro = 0.4:
 contrast                   estimate       SE df t.ratio p.value
 Golden Rain - Marvellous  -2.500000 9.715029 10  -0.257  0.9643
 Golden Rain - Victory      3.833333 9.715029 10   0.395  0.9184
 Marvellous - Victory       6.333333 9.715029 10   0.652  0.7955

nitro = 0.6:
 contrast                   estimate       SE df t.ratio p.value
 Golden Rain - Marvellous  -2.000000 9.715029 10  -0.206  0.9770
 Golden Rain - Victory      6.333333 9.715029 10   0.652  0.7955
 Marvellous - Victory       8.333333 9.715029 10   0.858  0.6775

P value adjustment: tukey method for comparing a family of 3 estimates 


> pairs(lsm, by = "Variety")
Variety = Golden Rain:
 contrast    estimate       SE df t.ratio p.value
 0 - 0.2   -18.500000 7.682957 45  -2.408  0.0900
 0 - 0.4   -34.666667 7.682957 45  -4.512  0.0003
 0 - 0.6   -44.833333 7.682957 45  -5.835  <.0001
 0.2 - 0.4 -16.166667 7.682957 45  -2.104  0.1673
 0.2 - 0.6 -26.333333 7.682957 45  -3.427  0.0069
 0.4 - 0.6 -10.166667 7.682957 45  -1.323  0.5533

Variety = Marvellous:
 contrast    estimate       SE df t.ratio p.value
 0 - 0.2   -21.833333 7.682957 45  -2.842  0.0328
 0 - 0.4   -30.500000 7.682957 45  -3.970  0.0014
 0 - 0.6   -40.166667 7.682957 45  -5.228  <.0001
 0.2 - 0.4  -8.666667 7.682957 45  -1.128  0.6744
 0.2 - 0.6 -18.333333 7.682957 45  -2.386  0.0944
 0.4 - 0.6  -9.666667 7.682957 45  -1.258  0.5938

Variety = Victory:
 contrast    estimate       SE df t.ratio p.value
 0 - 0.2   -18.166667 7.682957 45  -2.365  0.0988
 0 - 0.4   -39.333333 7.682957 45  -5.120  <.0001
 0 - 0.6   -47.000000 7.682957 45  -6.117  <.0001
 0.2 - 0.4 -21.166667 7.682957 45  -2.755  0.0406
 0.2 - 0.6 -28.833333 7.682957 45  -3.753  0.0027
 0.4 - 0.6  -7.666667 7.682957 45  -0.998  0.7514

P value adjustment: tukey method for comparing a family of 4 estimates



> Date: Mon, 19 Oct 2015 14:24:05 -0500
> From: James Henson <jfhenson1 at gmail.com>
> To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] contrasts among simple effects
> 
> Dear Russell,
> 
> Your assistance is appreciated. However, the code below returns an error message. Maybe my model is inappropriate. It was necessary to remove the ordered statement [ordered(time)], because apparently with the ordered statement lsmeans did not read time as a factor.
>
> library("nlme")
>
> # with AR1 variance/covariance structure
> heartRate$time <- factor(heartRate$time)
> 
> model2a <- lme(HR ~ drug*time, random =~1|person, correlation =corAR1(form=~1|person), data = heartRate)
> 
> summary(model2a)
>
> library("lsmeans")
> 
> anova(model2a)
> 
> lsm <- lsmeans(model2a, ~ drug|time)
> 
> lsm
>
> Error in format.default(nm[j], width = nchar(m[1, j]), just = "left") :
>   4 arguments passed to .Internal(nchar) which requires 3
> 
> 
> pairs(lsm)
>
> pairs(lsm, by = "drug")
> 
> The Using lsmeans tutorial (Oct 9, 2015) illustrates the usefulness of the lsmeans package.
> 
> Best regards,
> 
> James F. Henson


From pauljohn32 at gmail.com  Wed Oct 21 17:53:27 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 21 Oct 2015 10:53:27 -0500
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
In-Reply-To: <CAO7JsnQrhnUkBFgBu6-uaENF3g2HxA9=XCypsU9LceCy5d5H1A@mail.gmail.com>
References: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
	<alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>
	<CAErODj_rZM0frhbJ0rExZhmZUyeMfwOaKNVQ1LijAi9+omQhUw@mail.gmail.com>
	<CAJuCY5z0sawkR+7Tt3g0ynB6j4fpcjRN6o+f8iF2wcAhxBqb-A@mail.gmail.com>
	<CAO7JsnS=7zLOSxtEPP2f5r5zZ8ZrwnRAj8gY10rzyTixAUJjiw@mail.gmail.com>
	<CAO7JsnSwMaMdEefH-ozGWoYPOenoDhW70+9BbX4PsiiSKqJtig@mail.gmail.com>
	<CAO7JsnQrhnUkBFgBu6-uaENF3g2HxA9=XCypsU9LceCy5d5H1A@mail.gmail.com>
Message-ID: <CAErODj-2M07-FuHvhNao7O28Fb6DqVZYtmcxHQ5wYKvpAEzugw@mail.gmail.com>

Thanks to everybody for looking at the example. If that code can be
re-used in any way that helps lme4 development, I give permission to
re-use or edit it and put it to use. I'm happy to let everybody who
actually understands this debate it.  I don't (yet).

I need to explain to users why we have these warnings with lmer but
not SAS or Stata.  In the output I pasted in to the original email, it
reports convergence in a few steps of EM.  But lmer is going for a lot
more iterations.  How to explain that difference to students?

I'm reading through the papers that Doug has written in the last 10
years or so explaining the estimation process in PLS.   Bates and
Debroy makes this clear for LMM.  In comparison, the mainstream HLM
folks treated MLM a a GLS problem. Raudenbush & Bryk, for example, or
Snidjers & Bosker, describe calculation of predictions for the b's as
a posterior calculation, rather than an element of the optimization.

It appears to me Stata is written that GLS way.  Stata has a parameter
vector with fixed effects and variances of random effects (Beta,
Sigma).   In contrast, lmer i optimising over (Beta, Sigma, b).

Am I just making up a story here?

pj

On Fri, Oct 16, 2015 at 1:35 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> For those who may be interested, these are the results of timing the fits of
> two models on these simulated data.  For consistency within the timings I
> have renamed the grouping factor Mind to G and named the three continuous
> covariates as S, T and U.  The optimizers whose names start with LN_ are
> timings from the Julia MixedModels package using the NLopt package for
> optimization.  Those whose names start with NLOPT_LN_ are the same optimizer
> code accessed through the nloptr package for R.  The others are from the
> optimx package, bobyqa from the minqa package (the default for lmer) and the
> build-in Nelder_Mead optimizer, which is generally pretty bad and I can say
> that because I wrote it.
>
> dsname = "paulsim"
> form = Formula: Y ~ 1 + S + T + U + (1 | G) + ((0 + S) | G)
> -2log(likelihood) time(s) feval geval optimizer
>    143232.6341     1.5120   606     0 bobyqa
>    143564.1597     0.2770    70     0 Nelder_Mead
>    143232.9465     0.2680    66     0 NLOPT_LN_BOBYQA
>    143272.7444     0.2430    53     0 NLOPT_LN_COBYLA
>    143803.9823     0.3420    40     0 NLOPT_LN_NELDERMEAD
>    143232.6341     0.4570   147     0 NLOPT_LN_SBPLX
>    143232.6582     0.6320    58     0 optimx:L-BFGS-B
>    143232.6341     0.5480   104     0 optimx:nlminb
>    143232.6341     6.7930    NA     0 optimx:spg
>    143232.6341     1.6930    NA     0 optimx:bobyqa
>    143232.6341     0.0489   107     0 LN_BOBYQA
>    143232.6382     1.9885 69711     0 LN_COBYLA
>    143803.9823     0.0474    56     0 LN_NELDERMEAD
>    143232.6341     0.0527   147     0 LN_SBPLX
> form = Formula: Y ~ 1 + S + T + U + ((0 + S) | G)
> -2log(likelihood) time(s) feval geval optimizer
>    143232.6341     0.1400    41     0 bobyqa
>    143232.6341     0.1510    49     0 Nelder_Mead
>    143232.6343     0.1360    36     0 NLOPT_LN_BOBYQA
>    143232.6503     0.1170    24     0 NLOPT_LN_COBYLA
>    143232.6341     0.1540    48     0 NLOPT_LN_NELDERMEAD
>    143232.6341     0.1900    74     0 NLOPT_LN_SBPLX
>    143232.6368     0.3560    70     0 optimx:L-BFGS-B
>    143232.6341     0.2470    29     0 optimx:nlminb
>    143232.6341     0.3660    NA     0 optimx:spg
>    143232.6341     0.2650    NA     0 optimx:bobyqa
>    143232.6341     0.0240    43     0 LN_BOBYQA
>    143232.6341     0.0240    34     0 LN_COBYLA
>    143232.6341     0.0242    52     0 LN_NELDERMEAD
>    143232.6341     0.0246    81     0 LN_SBPLX
>



-- 
Paul E. Johnson
Professor, Political Science        Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org              http://crmda.ku.edu


From bates at stat.wisc.edu  Wed Oct 21 19:47:58 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 21 Oct 2015 17:47:58 +0000
Subject: [R-sig-ME] lmer nonconvergent: care to run and explain?
In-Reply-To: <CAErODj-2M07-FuHvhNao7O28Fb6DqVZYtmcxHQ5wYKvpAEzugw@mail.gmail.com>
References: <CAErODj_PeLtfKtSm7rzv98T8Hpo667b+9XAOBMqZm-=iJt0fBw@mail.gmail.com>
	<alpine.LMD.2.00.1510151019050.17633@orpheus.qimr.edu.au>
	<CAErODj_rZM0frhbJ0rExZhmZUyeMfwOaKNVQ1LijAi9+omQhUw@mail.gmail.com>
	<CAJuCY5z0sawkR+7Tt3g0ynB6j4fpcjRN6o+f8iF2wcAhxBqb-A@mail.gmail.com>
	<CAO7JsnS=7zLOSxtEPP2f5r5zZ8ZrwnRAj8gY10rzyTixAUJjiw@mail.gmail.com>
	<CAO7JsnSwMaMdEefH-ozGWoYPOenoDhW70+9BbX4PsiiSKqJtig@mail.gmail.com>
	<CAO7JsnQrhnUkBFgBu6-uaENF3g2HxA9=XCypsU9LceCy5d5H1A@mail.gmail.com>
	<CAErODj-2M07-FuHvhNao7O28Fb6DqVZYtmcxHQ5wYKvpAEzugw@mail.gmail.com>
Message-ID: <CAO7JsnTYh3nSXkG=C6RXdQjYVv9ikaVrJ=6z_VQUkqah+FH8Gw@mail.gmail.com>

Summary: We can't compare the performance of algorithms; we can only
compare implementations of algorithms.  Algorithms such as EM and GLS are
unnecessary because they are doing more work, in some cases much more work,
than the penalized least squares (PLS) approach.

tl;dr

It is best not to confuse the criterion being optimized with the particular
optimization method being used and with the particular implementation of
that method.  Even though we might like to compare optimization algorithms
and often write as if we had done so, we can only compare implementations.

The way that I think about the model and its implementation in the lme4
package is described in Bates, Maechler, Bolker and Walker (2015),
http://www.jstatsoft.org/article/view/v067i01.  See

> citation("lme4")

To cite lme4 in publications use:

  Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015).
  Fitting Linear Mixed-Effects Models Using lme4. Journal of
  Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01.

A BibTeX entry for LaTeX users is

  @Article{,
    title = {Fitting Linear Mixed-Effects Models Using {lme4}},
    author = {Douglas Bates and Martin M{\"a}chler and Ben Bolker and Steve
Walker},
    journal = {Journal of Statistical Software},
    year = {2015},
    volume = {67},
    number = {1},
    pages = {1--48},
    doi = {10.18637/jss.v067.i01},
  }

The probability model for linear mixed-effects and the derivation of
expressions for the log-likelihood and the REML criterion are given in
sections 1.1 and 3.1 to 3.4.  Note that once the probability model for the
responses is defined there is only one definition of the likelihood.  There
can be different formulas for it but they should all be equivalent.

Section 3.4 of that paper describes a way of evaluating the log-likelihood
and, more importantly, evaluating a profiled log-likelihood and a profiled
REML criterion.  The likelihood is a function of the parameters given the
observed data.  There are different ways of writing the parameters just as
there are different ways of writing the probability model.  We use the
fixed-effects parameter, ?, the scale parameter, ?, of the per-observation
noise and a covariance parameter vector, ?, that determines the covariance
matrix, ?, of the random effects.  The "profiled log-likelihood" is a
function of  ? only.  It is the minimum value of the log-likelihood over
all possible ? and ? for that particular value of ?.  The point is that
this can be be evaluated quickly and accurately by solving a penalized
least squares (PLS) problem for which the normal equations are very similar
to "Henderson's mixed-model equations".  Similar but with important
differences.  The idea of profiling the log-likelihood was present in Bates
and DebRoy (2004) but not in quite the same form and, again, the
differences are important.

In the MixedModels package for Julia I take this one step further and avoid
computing the solution to the PLS problem.  It turns out that the
information needed to evaluate the profiled log-likelihood is available at
an intermediate step in the solution.

Determining the maximum likelihood estimates is a matter of optimizing the
profiled log-likelihood with respect to ? only.  This is quite different
from the GLS approaches described in the hierarchical linear models or
multilevel models literature.  EM algorithms, etc. (including the ones that
co-authors and I have proposed) can be very slow to converge.  In fact it
is often difficult to tell whether such an algorithm has converged.
Essentially they alternate between optimizing ? given ? and optimizing ?
given ?.  The profiled log-likelihood approach builds the optimization of  ?
given ? into the evaluation of the criterion to be optimized.

Solving the PLS problem is a direct (i.e. non-iterative) calculation.  For
models with a large number of random effects the PLS solution requires
solving a large but very sparse positive definite system of equations.  In
lmer we use the sparse Cholesky decomposition, as implemented in the
CHOLMOD library of C functions by Tim Davis, to solve this.  In the
MixedModels package for Julia I use blocked matrix methods rather than
general sparse matrix methods.

To recap, in the lme4 package for R and in the MixedModels package for
Julia, determining the maximum likelihood estimates is a matter of
optimizing the profiled log-likelihood with respect to ?.  Usually the
dimension of ? is quite small.  Colin Longhurst and I have compared various
optimizers on several examples of linear mixed models from the literature
(including paulsim.json).  The dimension of ? for the different models is

Alfalfa.json:      "nopt": 1,
Animal.json:      "nopt": 2,
Assay.json:      "nopt": 2,
AvgDailyGain.json:      "nopt": 1,
AvgDailyGain.json:      "nopt": 1,
BIB.json:      "nopt": 1,
Bond.json:      "nopt": 1,
BS10.json:      "nopt": 20,
BS10.json:      "nopt": 8,
cake.json:      "nopt": 1,
Chem97.json:      "nopt": 2,
Chem97.json:      "nopt": 2,
Cultivation.json:      "nopt": 1,
d3.json:      "nopt": 9,
Demand.json:      "nopt": 2,
dialectNL.json:      "nopt": 6,
Dyestuff2.json:      "nopt": 1,
Dyestuff.json:      "nopt": 1,
egsingle.json:      "nopt": 2,
ergoStool.json:      "nopt": 1,
Exam.json:      "nopt": 1,
Exam.json:      "nopt": 1,
Gasoline.json:      "nopt": 1,
GB12.json:      "nopt": 20,
GB12.json:      "nopt": 8,
Genetics.json:      "nopt": 2,
HR.json:      "nopt": 3,
Hsb82.json:      "nopt": 1,
IncBlk.json:      "nopt": 1,
InstEval.json:      "nopt": 2,
InstEval.json:      "nopt": 3,
KB07.json:      "nopt": 72,
KB07.json:      "nopt": 16,
Mississippi.json:      "nopt": 1,
mm0.json:      "nopt": 6,
Oxboys.json:      "nopt": 3,
Pastes.json:      "nopt": 2,
paulsim.json:      "nopt": 2,
paulsim.json:      "nopt": 1,
PBIB.json:      "nopt": 1,
Penicillin.json:      "nopt": 2,
Poems.json:      "nopt": 3,
ScotsSec.json:      "nopt": 2,
Semi2.json:      "nopt": 2,
Semiconductor.json:      "nopt": 1,
SIMS.json:      "nopt": 3,
sleepstudy.json:      "nopt": 3,
sleepstudy.json:      "nopt": 2,
TeachingII.json:      "nopt": 1,
Weights.json:      "nopt": 3,
WWheat.json:      "nopt": 3,

For most of these examples the dimension of ? is 1, 2 or 3, which makes it
a very simple optimization problem.  The cases with a comparatively large
dimensional ? (say, 8 or more) are all examples of overparameterized
"maximal" models, in the sense of Barr et al. (2013), where convergence is
inevitably on the boundary of the parameter space, representing a singular
model.  If we ignore these meaningless models the problem of fitting linear
mixed-effects models can be reduced to a constrained optimization of a
function of a low-dimensional parameter vector, ?.

This is the point where you can only compare implementations, not
algorithms.   If you are going to compare, say, SAS vs Stata vs HLM5 vs
MLWin vs lmer vs lmm you must be careful to determine how the starting
values are set (I really wish I knew how SAS did this because they do it
very well) and, most importantly, what the convergence criteria are.   We
tend to be conservative in setting the convergence criteria, which means
that the algorithm gets into the neighborhood of the optimum quite quickly
but then requires many iterations to satisfy the convergence criteria.  The
easy way to cut down on the number of iterations is to relax the
convergence criteria.  For example, this is the trace of the iterations
when fitting a model to your simulated data

julia> fit!(lmm(Y ~ 1+S+T+U + (1|G) + (0+S|G), paulsim),true)
f_1: 144180.72425, [1.0,1.0]
f_2: 144274.57674, [1.75,1.0]
f_3: 144292.63941, [1.0,1.75]
f_4: 144067.78454, [0.25,1.0]
f_5: 143903.64334, [1.0,0.25]
f_6: 144446.67827, [0.292893,0.0]
f_7: 143529.46708, [1.30302,0.0290838]
f_8: 143877.77451, [2.05246,0.0]
f_9: 143795.73713, [1.19772,0.126175]
f_10: 143823.34211, [1.35678,0.0]
f_11: 143762.05604, [1.33438,0.097211]
f_12: 143691.53831, [1.24165,0.0721959]
f_13: 143814.84253, [1.23389,0.0]
f_14: 143644.50723, [1.3598,0.0523283]
f_15: 143587.62368, [1.29002,0.040578]
f_16: 143530.10373, [1.3131,0.0289719]
f_17: 143503.41482, [1.30555,0.0248514]
f_18: 143451.14914, [1.30452,0.0174227]
f_19: 143543.50332, [1.29842,0.00371975]
f_20: 143432.40261, [1.3115,0.0146834]
f_21: 143428.33727, [1.31289,0.0140573]
f_22: 143421.02525, [1.31567,0.01284]
f_23: 143416.50093, [1.31817,0.0119544]
f_24: 143415.43812, [1.31872,0.0117211]
f_25: 143415.77708, [1.31947,0.011772]
f_26: 143412.73718, [1.31834,0.0111002]
f_27: 143409.47407, [1.31848,0.00964196]
f_28: 143412.89517, [1.31829,0.00818943]
f_29: 143409.37014, [1.31776,0.00942966]
f_30: 143409.25932, [1.31702,0.00951907]
f_31: 143409.24635, [1.31692,0.00951671]
f_32: 143409.22105, [1.31672,0.00950082]
f_33: 143409.17595, [1.31633,0.00945426]
f_34: 143409.10778, [1.31554,0.00936069]
f_35: 143408.99981, [1.31395,0.00923051]
f_36: 143409.11111, [1.31185,0.00897081]
f_37: 143408.9328, [1.31439,0.00941748]
f_38: 143408.71263, [1.3128,0.00946254]
f_39: 143408.29263, [1.30962,0.00948033]
f_40: 143407.46398, [1.30325,0.00944035]
f_41: 143406.05675, [1.29052,0.00911243]
f_42: 143403.31125, [1.26506,0.00879603]
f_43: 143401.54026, [1.21415,0.00780416]
f_44: 143396.14586, [1.20279,0.00841878]
f_45: 143391.04011, [1.17739,0.0102159]
f_46: 143387.1939, [1.15196,0.00897777]
f_47: 143383.86535, [1.1265,0.00882717]
f_48: 143378.20151, [1.07558,0.00833507]
f_49: 143368.11174, [1.02468,0.00991746]
f_50: 143351.94197, [0.922835,0.0097862]
f_51: 143317.34013, [0.719146,0.0095397]
f_52: 143249.65238, [0.311767,0.0096406]
f_53: 143234.90081, [0.0,0.0108462]
f_54: 153266.3997, [0.0,0.0]
f_55: 143236.18137, [0.0108416,0.0111644]
f_56: 143312.91379, [0.0,0.0216925]
f_57: 143234.89379, [0.00542052,0.0108433]
f_58: 143260.48202, [0.00181902,0.0148979]
f_59: 143232.64299, [0.00487847,0.00975901]
f_60: 143234.66662, [0.00741215,0.00879308]
f_61: 143233.37725, [0.00509825,0.0103309]
f_62: 143234.28069, [0.00386846,0.0106634]
f_63: 143233.15163, [0.00514999,0.00922613]
f_64: 143232.79521, [0.00547335,0.00943397]
f_65: 143232.65672, [0.00475013,0.00980271]
f_66: 143232.63871, [0.00521639,0.00973263]
f_67: 143232.64022, [0.00555523,0.00974079]
f_68: 143232.63846, [0.00519816,0.00973069]
f_69: 143232.63849, [0.00516152,0.00973133]
f_70: 143232.64119, [0.00519516,0.00974877]
f_71: 143232.63707, [0.00519664,0.00971243]
f_72: 143232.63685, [0.00516081,0.00970472]
f_73: 143232.63677, [0.00508753,0.00970302]
f_74: 143232.6367, [0.00501424,0.00970158]
f_75: 143232.63662, [0.00494096,0.00970364]
f_76: 143232.63655, [0.00486769,0.00970559]
f_77: 143232.63649, [0.00479439,0.00970666]
f_78: 143232.63635, [0.00464778,0.00970688]
f_79: 143232.63626, [0.00450119,0.00970896]
f_80: 143232.6361, [0.00435459,0.00970816]
f_81: 143232.63591, [0.00406139,0.00971066]
f_82: 143232.63566, [0.00376818,0.0097104]
f_83: 143232.63537, [0.00318176,0.00971386]
f_84: 143232.63503, [0.00259534,0.00971415]
f_85: 143232.63463, [0.00142249,0.00971612]
f_86: 143232.63533, [0.000249701,0.00972778]
f_87: 143232.92661, [0.00142012,0.00934017]
f_88: 143232.63418, [0.000836292,0.00969989]
f_89: 143232.63431, [0.00142272,0.00970059]
f_90: 143232.80051, [0.000849809,0.00999279]
f_91: 143232.63446, [0.000952884,0.00971503]
f_92: 143232.64471, [0.000849105,0.00963252]
f_93: 143232.63416, [0.000888831,0.0097039]
f_94: 143232.63415, [0.000830049,0.00970325]
f_95: 143232.63418, [0.000771406,0.00970735]
f_96: 143232.63589, [0.000832025,0.0097322]
f_97: 143232.63415, [0.000835716,0.00970347]
f_98: 143232.63415, [0.00082632,0.00970365]
f_99: 143232.63415, [0.000824052,0.00970369]
f_100: 143232.63415, [0.000819517,0.00970378]
f_101: 143232.63415, [0.000816065,0.00970384]
f_102: 143232.63415, [0.000814649,0.00970387]
f_103: 143232.63415, [0.000811198,0.00970398]
f_104: 143232.63415, [0.000808462,0.009704]
f_105: 143232.63415, [0.000806745,0.00970404]
f_106: 143232.63415, [0.00080364,0.00970411]
f_107: 143232.63415, [0.000802646,0.00970413]
FTOL_REACHED

Officially the count of the number of function evaluations is 107 but
everything from 71 on is minor adjustments in the parameter values
affecting only the 9th significant digit of the criterion and beyond.
Also, the nature of the simulation is such that these parameter values are
so small that the differences are negligible.

The convergence warnings from lmer are often spurious and, because there
are so many false positives, they do more harm than good.  My approach in
the MixedModels package is to use a reliable, fast optimizer (LN_BOBYQA
from Steven Johnson's NLopt package) and set relatively stringent
tolerances for convergence.  This doesn't guarantee convergence to the
global optimum but there really is no good way of doing that.  Most of the
time the optimum is fairly well defined, in which case a good optimizer
algorithm gets you there quickly.

Regarding how to teach this: if your students are not frightened of vectors
and matrices, I would start with Henderson's mixed model equations because
they are well-established in the literature.  The profiled log-likelihood
can be expressed using the solution to those equations (although Henderson
didn't realize this) because all you need is the minimum penalized residual
sum-of-squares and the determinant of a matrix that looks rather benign.
The purpose of all of the contortions in lmer and lmm is to evaluate that
determinant efficiently as a by-product of solving the mixed-model equations


On Wed, Oct 21, 2015 at 10:53 AM Paul Johnson <pauljohn32 at gmail.com> wrote:

> Thanks to everybody for looking at the example. If that code can be
> re-used in any way that helps lme4 development, I give permission to
> re-use or edit it and put it to use. I'm happy to let everybody who
> actually understands this debate it.  I don't (yet).
>
> I need to explain to users why we have these warnings with lmer but
> not SAS or Stata.  In the output I pasted in to the original email, it
> reports convergence in a few steps of EM.  But lmer is going for a lot
> more iterations.  How to explain that difference to students?
>
> I'm reading through the papers that Doug has written in the last 10
> years or so explaining the estimation process in PLS.   Bates and
> Debroy makes this clear for LMM.  In comparison, the mainstream HLM
> folks treated MLM a a GLS problem. Raudenbush & Bryk, for example, or
> Snidjers & Bosker, describe calculation of predictions for the b's as
> a posterior calculation, rather than an element of the optimization.
>
> It appears to me Stata is written that GLS way.  Stata has a parameter
> vector with fixed effects and variances of random effects (Beta,
> Sigma).   In contrast, lmer i optimising over (Beta, Sigma, b).
>
> Am I just making up a story here?
>
> pj
>
> On Fri, Oct 16, 2015 at 1:35 PM, Douglas Bates <bates at stat.wisc.edu>
> wrote:
> > For those who may be interested, these are the results of timing the
> fits of
> > two models on these simulated data.  For consistency within the timings I
> > have renamed the grouping factor Mind to G and named the three continuous
> > covariates as S, T and U.  The optimizers whose names start with LN_ are
> > timings from the Julia MixedModels package using the NLopt package for
> > optimization.  Those whose names start with NLOPT_LN_ are the same
> optimizer
> > code accessed through the nloptr package for R.  The others are from the
> > optimx package, bobyqa from the minqa package (the default for lmer) and
> the
> > build-in Nelder_Mead optimizer, which is generally pretty bad and I can
> say
> > that because I wrote it.
> >
> > dsname = "paulsim"
> > form = Formula: Y ~ 1 + S + T + U + (1 | G) + ((0 + S) | G)
> > -2log(likelihood) time(s) feval geval optimizer
> >    143232.6341     1.5120   606     0 bobyqa
> >    143564.1597     0.2770    70     0 Nelder_Mead
> >    143232.9465     0.2680    66     0 NLOPT_LN_BOBYQA
> >    143272.7444     0.2430    53     0 NLOPT_LN_COBYLA
> >    143803.9823     0.3420    40     0 NLOPT_LN_NELDERMEAD
> >    143232.6341     0.4570   147     0 NLOPT_LN_SBPLX
> >    143232.6582     0.6320    58     0 optimx:L-BFGS-B
> >    143232.6341     0.5480   104     0 optimx:nlminb
> >    143232.6341     6.7930    NA     0 optimx:spg
> >    143232.6341     1.6930    NA     0 optimx:bobyqa
> >    143232.6341     0.0489   107     0 LN_BOBYQA
> >    143232.6382     1.9885 69711     0 LN_COBYLA
> >    143803.9823     0.0474    56     0 LN_NELDERMEAD
> >    143232.6341     0.0527   147     0 LN_SBPLX
> > form = Formula: Y ~ 1 + S + T + U + ((0 + S) | G)
> > -2log(likelihood) time(s) feval geval optimizer
> >    143232.6341     0.1400    41     0 bobyqa
> >    143232.6341     0.1510    49     0 Nelder_Mead
> >    143232.6343     0.1360    36     0 NLOPT_LN_BOBYQA
> >    143232.6503     0.1170    24     0 NLOPT_LN_COBYLA
> >    143232.6341     0.1540    48     0 NLOPT_LN_NELDERMEAD
> >    143232.6341     0.1900    74     0 NLOPT_LN_SBPLX
> >    143232.6368     0.3560    70     0 optimx:L-BFGS-B
> >    143232.6341     0.2470    29     0 optimx:nlminb
> >    143232.6341     0.3660    NA     0 optimx:spg
> >    143232.6341     0.2650    NA     0 optimx:bobyqa
> >    143232.6341     0.0240    43     0 LN_BOBYQA
> >    143232.6341     0.0240    34     0 LN_COBYLA
> >    143232.6341     0.0242    52     0 LN_NELDERMEAD
> >    143232.6341     0.0246    81     0 LN_SBPLX
> >
>
>
>
> --
> Paul E. Johnson
> Professor, Political Science        Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org              http://crmda.ku.edu
>

	[[alternative HTML version deleted]]


From jbukoski1 at gmail.com  Wed Oct 21 19:51:35 2015
From: jbukoski1 at gmail.com (Jacob Bukoski)
Date: Wed, 21 Oct 2015 13:51:35 -0400
Subject: [R-sig-ME] Hierarchical structure for preservation of
	observations
In-Reply-To: <CAJuCY5yuG5HW58u=pr90T9j1fRH_5e884ip+Vk+NFF+vRObT9w@mail.gmail.com>
References: <CAOES0VipWaQuoJqyLQnY0gzPdx1zn6mLwXfXgbp42RyTW5y=0A@mail.gmail.com>
	<CAJuCY5yuG5HW58u=pr90T9j1fRH_5e884ip+Vk+NFF+vRObT9w@mail.gmail.com>
Message-ID: <CAOES0Vhc78AZK2jyFQtu4y+=vVwLzZ9czDLw5=ba52CWORLb8A@mail.gmail.com>

Dear Thierry,

Thank you kindly for your advice. You were right in that the model is too
complex for the dataset. I began examining the intervals of the
coefficients and was getting "Non-positive definitive approximate
variance-covariance" errors. Hopefully I'll have more data that becomes
available in the future, but in the meantime will try to simplify the model.

Best wishes,
Jacob



On Mon, Oct 19, 2015 at 2:49 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Jacob,
>
> The random effect specification is correct for the model that you have in
> mind.
>
> I'd rather think of the effects of site and genus as crossed rather
> nested. The formula would become (1|Site) + (1|Genus). Assuming that you
> have 5 or more genera. If not, then it better to add Genus to the fixed
> effects or keep your current model.
>
> I'm a bit worried about the complexity of your model. 65 observations is
> not a lot for a model with 6 parameters.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-18 16:02 GMT+02:00 Jacob Bukoski <jbukoski1 at gmail.com>:
>
>> Dear all,
>>
>> I am currently trying to develop a predictive model of ecosystem carbon
>> stocks for forests of Southeast Asia. The difficult part is that the
>> dataset I've compiled (from published data in the peer-reviewed
>> literature)
>> only consists of 65 or so observations.
>>
>> I've resorted to a mixed effects model under the understanding that I can
>> specify a grouping structure and maintain spatially correlated
>> observations
>> within each study. However, I'm not sure that my specification of the
>> hierarchical structure is acceptable, as this is my first attempt at using
>> mixed models.
>>
>> I am using R version 3.2.2., and the lmer() function of the "lme4"
>> package.
>>
>> I have specified basal area (a metric of tree stem cross sectional area at
>> 1.3 meters height), latitude, and categorical variables for small (mean
>> stem diameter < 5 cm) and large (mean stem diameter > 15 cm) forests as
>> fixed effects.
>>
>> I have specified the dominant genus of tree in plots and the site as
>> random
>> effects. My thinking here is that plots with the same dominant genera of
>> tree would not be independent of one another, nor would plots within the
>> same site. Thus, by specifying random effects for Genus in Site... I can
>> maintain the individual observations.
>>
>> The model I have specified as follows:
>>
>> *lmer1 <- lmer(Biomass ~ Basal.area + Latitude + Small + Large +
>> (1|Site/Genus), REML=FALSE)*
>>
>> *My two-part question is*: (i) Does the logic behind my random effect
>> specification hold, and (ii) have I specified it under the lmer() function
>> correctly?
>>
>> Additionally, I am unsure of whether the number of groups has an impact on
>> the degrees of freedom. The summary reports 34 groups for Genus:Site, and
>> 21 for Site. My specified model has 40 residual degrees of freedom. Have I
>> violated my degrees of freedom?
>>
>> Any advice and external resources will be hugely appreciated!
>>
>> Many kind thanks,
>> Jacob
>>
>> --
>> Jacob J. Bukoski
>> Master of Environmental Science Candidate, 2016
>> School of Forestry and Environmental Studies, Yale University
>> jbukoski1 at gmail.com | jacob.bukoski at yale.edu | LinkedIn
>> <
>> https://www.linkedin.com/profile/view?id=AAIAAAdWVW8BMzqU_2EGNbEkyuy8O7K1Jyhd8ps&trk=nav_responsive_tab_profile_pic
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 
Jacob J. Bukoski
Master of Environmental Science Candidate, 2016
School of Forestry and Environmental Studies, Yale University
jbukoski1 at gmail.com | jacob.bukoski at yale.edu | LinkedIn
<https://www.linkedin.com/profile/view?id=AAIAAAdWVW8BMzqU_2EGNbEkyuy8O7K1Jyhd8ps&trk=nav_responsive_tab_profile_pic>

	[[alternative HTML version deleted]]


From francesco.sigona at unisalento.it  Fri Oct 23 17:40:06 2015
From: francesco.sigona at unisalento.it (Francesco Sigona)
Date: Fri, 23 Oct 2015 17:40:06 +0200
Subject: [R-sig-ME] Likelihood Ratio Test for non-nested mixed-effect-model
	comparison
Message-ID: <562A54D6.60204@unisalento.it>

Hi all,

I need to compare two mixed-effects-models that would explain a 
dependent variable by means of two completely different sets of fixed 
factors (my random intercept is the same in both models).

I understand that the anova() cannot be used to perform a comparison via 
LRTest in my case, because my models are non-nested.

Thus, I would take the model with the lowest AIC (o BIC) value, but I am 
worried about the statistical significance, so I would prefer a LRTest 
and the related p-value (as provided by anova() for nested models) to 
support my model selection.

My problem is that I don't know how to compare two non-nested 
mixed-effect-models via a LRTest.

Any suggestion?

Thank you in advance.

Francesco

-- 
*Francesco SIGONA*
Electronics engineer 	
Piazza Filippo Muratore
73100 - Lecce - Italy 	<https://maps.google.com/maps?q=40.331002,18.156462>
tel.: +39 0832 335006
fax.: +39 0832 335007

============================================================
*Center for Interdisciplinary Research on Language (CRIL) 
<http://www.cril.unisalento.it> &
Cognitive Neuroscience of Language and Speech Sciences Lab (CNLSS) * 	
*Dipartimento di Studi umanistici
Universit? del Salento * 	

============================================================
*Laboratorio Diffuso di Ricerca Interdisciplinare Applicata alla Medicina
(DReAM) * 	


From chirleu at gmail.com  Fri Oct 23 18:12:24 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Fri, 23 Oct 2015 18:12:24 +0200
Subject: [R-sig-ME] model selection in MCMCglmm
Message-ID: <CALC46t98rKCRgA7B13a6TpS0e4F0oZHYkyyRA8h-SkbxNkH+wQ@mail.gmail.com>

Hi all,
I'm running a bivariate model in MCMCglmm to estimate the covariance
between two traits and see if it is significant. For that purpose I run two
models:

In the first model, my random variance-covariance matrix is unconstrained
(us) so the variances and the covariance are estimated. This is the result:

mod1=MCMCglmm(cbind(beh1,beh2)~(trait-1), random=~*us*(trait):id,
rcov=~us(trait):units, data=widew2t, family=c("gaussian","gaussian"),
nitt=1100000, thin=100, burnin=100000, prior=prior1)

G-structure:  ~us(trait):id

                                         post.mean  l-95% CI   u-95% CI
 eff.samp
traitbeh1:traitbeh1.id        0.2120           0.1577       0.2715
8872
traitbeh2:traitbeh1.id        0.3437           0.2321       0.4804
10000
traitbeh1:traitbeh2.id        0.3437           0.2321       0.4804
10000
traitbeh2:traitbeh2.id        1.5800           1.2018       2.0011
10000

The DIC of this model is 20363.22. Note that the covariance between both
traits is positive (0.3437) and the confidence interval is far from
including the zero. So I'd have an argument to say that the covariance is
different from zero and therefore is ok to estimate it. If we translate
that covariance into a correlation, that would be 0.59

In my second model, my random variance-covariance matrix is constrained
(idh) so the variances are estimated but the covariance is constrained to
zero. This is the result:

mod2=MCMCglmm(cbind(beh1,beh2)~(trait-1), random=~*idh*(trait):id,
rcov=~us(trait):units, data=widew2t, family=c("gaussian","gaussian"),
nitt=1100000, thin=100, burnin=100000, prior=prior1)

 G-structure:  ~idh(trait):id

                      post.mean   l-95% CI   u-95% CI    eff.samp
traitbeh1.id           0.2062     0.1549         0.265       10000
traitbeh2.id           1.5310     1.1574         1.940       10000

The DIC of this model is 20364.96 . This is deltaDIC (unconstrained minus
constrained) is -1.74 (which is less than -2, the generally agreed thresold
to support the unconstrained model). So  I should prefer the second model.

So if I look at the confidence interval in model 1, I would assume that
both traits covary/are correlated. However if I look at the DICs, the
second model seems better and supports a covariance of zero.

Is there any preferred or better method to test the significance of the
covariance between beh1 and beh2 in this case?

Many thanks.

Regards

David

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Oct 23 20:18:43 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 23 Oct 2015 14:18:43 -0400
Subject: [R-sig-ME] Likelihood Ratio Test for non-nested
 mixed-effect-model comparison
In-Reply-To: <562A54D6.60204@unisalento.it>
References: <562A54D6.60204@unisalento.it>
Message-ID: <562A7A03.3080203@gmail.com>

  The Vuong test <https://en.wikipedia.org/wiki/Vuong's_closeness_test>
provides a likelihood-based framework for distinguishing between
non-nested models.  I'm not immediately aware of an implementation that
works with mixed models in R, but you could look around (library("sos");
findFn("vuong") and screen the results for applicability ...)

  As a crude alternative you could do something parametric bootstrap-y
by simulating from each fitted model, fitting each realization with both
fitted models, and comparing the goodness of fit distributions (that's
intentionally vague, I haven't thought about it very much ...)

  Ben Bolker

On 15-10-23 11:40 AM, Francesco Sigona wrote:
> Hi all,
> 
> I need to compare two mixed-effects-models that would explain a
> dependent variable by means of two completely different sets of fixed
> factors (my random intercept is the same in both models).
> 
> I understand that the anova() cannot be used to perform a comparison via
> LRTest in my case, because my models are non-nested.
> 
> Thus, I would take the model with the lowest AIC (o BIC) value, but I am
> worried about the statistical significance, so I would prefer a LRTest
> and the related p-value (as provided by anova() for nested models) to
> support my model selection.
> 
> My problem is that I don't know how to compare two non-nested
> mixed-effect-models via a LRTest.
> 
> Any suggestion?
> 
> Thank you in advance.
> 
> Francesco
>


From merklee at missouri.edu  Sat Oct 24 21:02:49 2015
From: merklee at missouri.edu (Merkle, Edgar C.)
Date: Sat, 24 Oct 2015 19:02:49 +0000
Subject: [R-sig-ME] Likelihood Ratio Test for non-nested
 mixed-effect-model comparison
In-Reply-To: <562A7A03.3080203@gmail.com>
References: <562A54D6.60204@unisalento.it>,<562A7A03.3080203@gmail.com>
Message-ID: <24882894B609E44C91A0A43F755F8C73013D7BBB15@UM-MBX-N02.um.umsystem.edu>

Ben, Francesco,

I have developed a package, nonnest2, that implements the Vuong tests (multiple test statistics) for many types of R models including glm() models.  I believe we will soon be able to add models estimated via lmer().  For an overview of the Vuong test statistics (mostly in the context of structural equation models, but the idea is the same regardless), see my paper here:

http://arxiv.org/pdf/1402.6720v3

We have also been interested in getting the tests to work with models estimated via glmer().  The problem is that the tests require scores of the fitted model (casewise first derivatives of the log-likelihood evaluated at the ML estimates), and it is difficult to obtain scores when the likelihood involves an intractable integral.  My students and I have tentatively concluded that there is no way to use the lme4 source in order to obtain the scores because pirls generally avoids dealing directly with the likelihood.  But I would be happy to hear hints otherwise.

Best,
Ed Merkle

________________________________________
From: Ben Bolker [bbolker at gmail.com]
Sent: Friday, October 23, 2015 1:18 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Likelihood Ratio Test for non-nested mixed-effect-model comparison

  The Vuong test <https://en.wikipedia.org/wiki/Vuong's_closeness_test>
provides a likelihood-based framework for distinguishing between
non-nested models.  I'm not immediately aware of an implementation that
works with mixed models in R, but you could look around (library("sos");
findFn("vuong") and screen the results for applicability ...)

  As a crude alternative you could do something parametric bootstrap-y
by simulating from each fitted model, fitting each realization with both
fitted models, and comparing the goodness of fit distributions (that's
intentionally vague, I haven't thought about it very much ...)

  Ben Bolker

On 15-10-23 11:40 AM, Francesco Sigona wrote:
> Hi all,
>
> I need to compare two mixed-effects-models that would explain a
> dependent variable by means of two completely different sets of fixed
> factors (my random intercept is the same in both models).
>
> I understand that the anova() cannot be used to perform a comparison via
> LRTest in my case, because my models are non-nested.
>
> Thus, I would take the model with the lowest AIC (o BIC) value, but I am
> worried about the statistical significance, so I would prefer a LRTest
> and the related p-value (as provided by anova() for nested models) to
> support my model selection.
>
> My problem is that I don't know how to compare two non-nested
> mixed-effect-models via a LRTest.
>
> Any suggestion?
>
> Thank you in advance.
>
> Francesco
>


From saah500 at york.ac.uk  Mon Oct 26 10:37:48 2015
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Mon, 26 Oct 2015 12:37:48 +0300
Subject: [R-sig-ME] Random vs. fixed effects
Message-ID: <CACrevpn1FOpU2e9ERtGWTV=D0xB1VpatVvMRsD-VuJ6eMAwo4Q@mail.gmail.com>

I'm using a binomial glmer mixed effects model.

One variable that I have, 'stimulus' has 12 levels. The levels were not
randomly selected but were rather chosen as per the study design, so I have
used the variable ?stimulus? as a fixed variable in the basic model but R
seems not to like it (at least this is my interpretation) given the way the
output looks and the amount of time R takes to process it.

m0.1 <- glmer(match ~ Listgp + stimulus + (1|Listener), data = PATdata,
family = "binomial")



summary(m0.1) Generalized linear mixed model fit by maximum likelihood
(Laplace Approximation) [ glmerMod] Family: binomial ( logit ) Formula:
match ~ Listgp + stimulus + (1 | Listener) Data: PATdata

 AIC      BIC   logLik deviance df.resid

5154.3 5259.5 -2562.2 5124.3 8193



Scaled residuals: Min 1Q Median 3Q Max -25.0764 -0.2706 -0.1939 0.2472
10.5131



Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.743
1.32

Number of obs: 8208, groups: Listener, 228



Fixed effects: Estimate Std. Error z value Pr(>|z|)

(Intercept) 2.7561 0.2657 10.371 < 2e-16 * ListgpTA 0.1741 0.3147 0.553
0.580128

ListgpTQ 0.0810 0.2575 0.315 0.753094

stimulushaaDD -5.4415 0.2071 -26.272 < 2e-16 stimulushad -4.2953 0.1822
-23.569 < 2e-16 stimulushaDD -5.4946 0.2086 -26.337 < 2e-16 stimulushid
-5.1519 0.1994 -25.832 < 2e-16 stimulushiDD -0.6708 0.1801 -3.724 0.000196
stimulushiid -5.8124 0.2186 -26.593 < 2e-16 stimulushiiDD -5.5101 0.2091
-26.353 < 2e-16 stimulushud -0.2016 0.1915 -1.053 0.292345

stimulushuDD -5.6188 0.2123 -26.462 < 2e-16 stimulushuud -5.6107 0.2121
-26.450 < 2e-16 *



stimulushuuDD -5.3207 0.2038 -26.109 < 2e-16 ***



Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1



Correlation of Fixed Effects: (Intr) LstgTA LstgTQ stimulushaaDD
stimulushad stimulushaDD ListgpTA -0.613

ListgpTQ -0.755 0.636

stimulushaaDD -0.394 -0.007 0.004

stimulushad -0.440 -0.006 0.005 0.605

stimulushaDD -0.392 -0.007 0.003 0.555 0.601

stimulushid -0.407 -0.007 0.004 0.572 0.624 0.569

stimulushiDD -0.414 0.000 0.001 0.534 0.606 0.530

stimulushiid -0.376 -0.006 0.003 0.536 0.578 0.533

stimulushiiDD -0.391 -0.007 0.003 0.554 0.600 0.551

stimulushud -0.386 0.000 0.000 0.497 0.564 0.493

stimulushuDD -0.385 -0.007 0.003 0.548 0.592 0.545

stimulushuud -0.386 -0.007 0.003 0.548 0.593 0.545

stimulushuuDD -0.400 -0.007 0.004 0.564 0.613 0.561

stimulushid stimulushiDD stimulushiid stimulushiiDD stimulushud ListgpTA

ListgpTQ

stimulushaaDD

stimulushad

stimulushaDD

stimulushid

stimulushiDD 0.554

stimulushiid 0.549 0.506

stimulushiiDD 0.568 0.529 0.533

stimulushud 0.516 0.569 0.471 0.492

stimulushuDD 0.562 0.521 0.527 0.544 0.484

stimulushuud 0.562 0.522 0.528 0.545 0.485

stimulushuuDD 0.579 0.543 0.542 0.560 0.505

stimulushuDD stimulushuud ListgpTA

ListgpTQ

stimulushaaDD

stimulushad

stimulushaDD

stimulushid

stimulushiDD

stimulushiid

stimulushiiDD

stimulushud

stimulushuDD

stimulushuud 0.539

stimulushuuDD 0.554 0.554

So, my question is, can I consider 'stimulus' as a random effect instead
since the model become more sensible from a programming point of view?

m0.1 <- glmer(match ~ Listgp + (1|stimulus) + (1|Listener), data = PATdata,
family = "binomial") summary(m0.1) Generalized linear mixed model fit by
maximum likelihood (Laplace Approximation) [ glmerMod] Family: binomial (
logit ) Formula: match ~ Listgp + (1 | stimulus) + (1 | Listener) Data:
PATdata

 AIC      BIC   logLik deviance df.resid

5218.3 5253.4 -2604.2 5208.3 8203



Scaled residuals: Min 1Q Median 3Q Max -21.9276 -0.2804 -0.2059 0.2740
9.4275



Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.676
1.294

stimulus (Intercept) 4.949 2.225

Number of obs: 8208, groups: Listener, 228; stimulus, 12



Fixed effects: Estimate Std. Error z value Pr(>|z|)

(Intercept) -1.3754 0.6792 -2.025 0.0429 * ListgpTA 0.2284 0.3073 0.743
0.4572



ListgpTQ 0.1432 0.2513 0.570 0.5687



Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1



Correlation of Fixed Effects: (Intr) LstgTA ListgpTA -0.235

ListgpTQ -0.288 0.636



Thank you,

Shad

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Oct 26 10:47:01 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 26 Oct 2015 10:47:01 +0100
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <CACrevpn1FOpU2e9ERtGWTV=D0xB1VpatVvMRsD-VuJ6eMAwo4Q@mail.gmail.com>
References: <CACrevpn1FOpU2e9ERtGWTV=D0xB1VpatVvMRsD-VuJ6eMAwo4Q@mail.gmail.com>
Message-ID: <CAJuCY5ydmmJ28HXhgKSzoOs5ZQfxBgn7bBTAd_RgECJHdV1PDw@mail.gmail.com>

Dear Shad,

Please don't post in HTML since it makes the model output unreadable.

You need to be more clear on "R seems not to like it".

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-26 10:37 GMT+01:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:

> I'm using a binomial glmer mixed effects model.
>
> One variable that I have, 'stimulus' has 12 levels. The levels were not
> randomly selected but were rather chosen as per the study design, so I have
> used the variable ?stimulus? as a fixed variable in the basic model but R
> seems not to like it (at least this is my interpretation) given the way the
> output looks and the amount of time R takes to process it.
>
> m0.1 <- glmer(match ~ Listgp + stimulus + (1|Listener), data = PATdata,
> family = "binomial")
>
>
>
> summary(m0.1) Generalized linear mixed model fit by maximum likelihood
> (Laplace Approximation) [ glmerMod] Family: binomial ( logit ) Formula:
> match ~ Listgp + stimulus + (1 | Listener) Data: PATdata
>
>  AIC      BIC   logLik deviance df.resid
>
> 5154.3 5259.5 -2562.2 5124.3 8193
>
>
>
> Scaled residuals: Min 1Q Median 3Q Max -25.0764 -0.2706 -0.1939 0.2472
> 10.5131
>
>
>
> Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.743
> 1.32
>
> Number of obs: 8208, groups: Listener, 228
>
>
>
> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>
> (Intercept) 2.7561 0.2657 10.371 < 2e-16 * ListgpTA 0.1741 0.3147 0.553
> 0.580128
>
> ListgpTQ 0.0810 0.2575 0.315 0.753094
>
> stimulushaaDD -5.4415 0.2071 -26.272 < 2e-16 stimulushad -4.2953 0.1822
> -23.569 < 2e-16 stimulushaDD -5.4946 0.2086 -26.337 < 2e-16 stimulushid
> -5.1519 0.1994 -25.832 < 2e-16 stimulushiDD -0.6708 0.1801 -3.724 0.000196
> stimulushiid -5.8124 0.2186 -26.593 < 2e-16 stimulushiiDD -5.5101 0.2091
> -26.353 < 2e-16 stimulushud -0.2016 0.1915 -1.053 0.292345
>
> stimulushuDD -5.6188 0.2123 -26.462 < 2e-16 stimulushuud -5.6107 0.2121
> -26.450 < 2e-16 *
>
>
>
> stimulushuuDD -5.3207 0.2038 -26.109 < 2e-16 ***
>
>
>
> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>
>
>
> Correlation of Fixed Effects: (Intr) LstgTA LstgTQ stimulushaaDD
> stimulushad stimulushaDD ListgpTA -0.613
>
> ListgpTQ -0.755 0.636
>
> stimulushaaDD -0.394 -0.007 0.004
>
> stimulushad -0.440 -0.006 0.005 0.605
>
> stimulushaDD -0.392 -0.007 0.003 0.555 0.601
>
> stimulushid -0.407 -0.007 0.004 0.572 0.624 0.569
>
> stimulushiDD -0.414 0.000 0.001 0.534 0.606 0.530
>
> stimulushiid -0.376 -0.006 0.003 0.536 0.578 0.533
>
> stimulushiiDD -0.391 -0.007 0.003 0.554 0.600 0.551
>
> stimulushud -0.386 0.000 0.000 0.497 0.564 0.493
>
> stimulushuDD -0.385 -0.007 0.003 0.548 0.592 0.545
>
> stimulushuud -0.386 -0.007 0.003 0.548 0.593 0.545
>
> stimulushuuDD -0.400 -0.007 0.004 0.564 0.613 0.561
>
> stimulushid stimulushiDD stimulushiid stimulushiiDD stimulushud ListgpTA
>
> ListgpTQ
>
> stimulushaaDD
>
> stimulushad
>
> stimulushaDD
>
> stimulushid
>
> stimulushiDD 0.554
>
> stimulushiid 0.549 0.506
>
> stimulushiiDD 0.568 0.529 0.533
>
> stimulushud 0.516 0.569 0.471 0.492
>
> stimulushuDD 0.562 0.521 0.527 0.544 0.484
>
> stimulushuud 0.562 0.522 0.528 0.545 0.485
>
> stimulushuuDD 0.579 0.543 0.542 0.560 0.505
>
> stimulushuDD stimulushuud ListgpTA
>
> ListgpTQ
>
> stimulushaaDD
>
> stimulushad
>
> stimulushaDD
>
> stimulushid
>
> stimulushiDD
>
> stimulushiid
>
> stimulushiiDD
>
> stimulushud
>
> stimulushuDD
>
> stimulushuud 0.539
>
> stimulushuuDD 0.554 0.554
>
> So, my question is, can I consider 'stimulus' as a random effect instead
> since the model become more sensible from a programming point of view?
>
> m0.1 <- glmer(match ~ Listgp + (1|stimulus) + (1|Listener), data = PATdata,
> family = "binomial") summary(m0.1) Generalized linear mixed model fit by
> maximum likelihood (Laplace Approximation) [ glmerMod] Family: binomial (
> logit ) Formula: match ~ Listgp + (1 | stimulus) + (1 | Listener) Data:
> PATdata
>
>  AIC      BIC   logLik deviance df.resid
>
> 5218.3 5253.4 -2604.2 5208.3 8203
>
>
>
> Scaled residuals: Min 1Q Median 3Q Max -21.9276 -0.2804 -0.2059 0.2740
> 9.4275
>
>
>
> Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.676
> 1.294
>
> stimulus (Intercept) 4.949 2.225
>
> Number of obs: 8208, groups: Listener, 228; stimulus, 12
>
>
>
> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>
> (Intercept) -1.3754 0.6792 -2.025 0.0429 * ListgpTA 0.2284 0.3073 0.743
> 0.4572
>
>
>
> ListgpTQ 0.1432 0.2513 0.570 0.5687
>
>
>
> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>
>
>
> Correlation of Fixed Effects: (Intr) LstgTA ListgpTA -0.235
>
> ListgpTQ -0.288 0.636
>
>
>
> Thank you,
>
> Shad
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From saah500 at york.ac.uk  Mon Oct 26 11:10:46 2015
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Mon, 26 Oct 2015 13:10:46 +0300
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <CAJuCY5ydmmJ28HXhgKSzoOs5ZQfxBgn7bBTAd_RgECJHdV1PDw@mail.gmail.com>
References: <CACrevpn1FOpU2e9ERtGWTV=D0xB1VpatVvMRsD-VuJ6eMAwo4Q@mail.gmail.com>
	<CAJuCY5ydmmJ28HXhgKSzoOs5ZQfxBgn7bBTAd_RgECJHdV1PDw@mail.gmail.com>
Message-ID: <CACrevpmwqyoh1QHS3+WpwsimiBmP6NovYwn_-bUgunVOi6-Ukg@mail.gmail.com>

Dear Thierry,

Thanks for your response. I meant that the way the levels of stimulus are
shown in the output does not look right. In addition, when I use stimulus
as a fixed effect, R takes such a long time to produce the output compared
to when I use it as a random effect.

Besides, I'm warned as follows.

In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.063422 (tol = 0.001,
component 4)

Here is how the output looks when stimulus is used as a fixed effect.

> summary(m0.1)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
glmerMod]
 Family: binomial  ( logit )
Formula: match ~ Listgp + stimulus + (1 | Listener)
   Data: PATdata

     AIC      BIC   logLik deviance df.resid
  5154.3   5259.5  -2562.2   5124.3     8193

Scaled residuals:
     Min       1Q   Median       3Q      Max
-25.0764  -0.2706  -0.1939   0.2472  10.5131

Random effects:
 Groups   Name        Variance Std.Dev.
 Listener (Intercept) 1.743    1.32
Number of obs: 8208, groups:  Listener, 228

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)     2.7561     0.2657  10.371  < 2e-16 ***
ListgpTA        0.1741     0.3147   0.553 0.580128
ListgpTQ        0.0810     0.2575   0.315 0.753094
stimulushaaDD  -5.4415     0.2071 -26.272  < 2e-16 ***
stimulushad    -4.2953     0.1822 -23.569  < 2e-16 ***
stimulushaDD   -5.4946     0.2086 -26.337  < 2e-16 ***
stimulushid    -5.1519     0.1994 -25.832  < 2e-16 ***
stimulushiDD   -0.6708     0.1801  -3.724 0.000196 ***
stimulushiid   -5.8124     0.2186 -26.593  < 2e-16 ***
stimulushiiDD  -5.5101     0.2091 -26.353  < 2e-16 ***
stimulushud    -0.2016     0.1915  -1.053 0.292345
stimulushuDD   -5.6188     0.2123 -26.462  < 2e-16 ***
stimulushuud   -5.6107     0.2121 -26.450  < 2e-16 ***
stimulushuuDD  -5.3207     0.2038 -26.109  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
              (Intr) LstgTA LstgTQ stimulushaaDD stimulushad stimulushaDD
ListgpTA      -0.613
ListgpTQ      -0.755  0.636
stimulushaaDD -0.394 -0.007  0.004
stimulushad   -0.440 -0.006  0.005  0.605
stimulushaDD  -0.392 -0.007  0.003  0.555         0.601
stimulushid   -0.407 -0.007  0.004  0.572         0.624       0.569
stimulushiDD  -0.414  0.000  0.001  0.534         0.606       0.530
stimulushiid  -0.376 -0.006  0.003  0.536         0.578       0.533
stimulushiiDD -0.391 -0.007  0.003  0.554         0.600       0.551
stimulushud   -0.386  0.000  0.000  0.497         0.564       0.493
stimulushuDD  -0.385 -0.007  0.003  0.548         0.592       0.545
stimulushuud  -0.386 -0.007  0.003  0.548         0.593       0.545
stimulushuuDD -0.400 -0.007  0.004  0.564         0.613       0.561
              stimulushid stimulushiDD stimulushiid stimulushiiDD
stimulushud
ListgpTA

ListgpTQ

stimulushaaDD

stimulushad

stimulushaDD

stimulushid

stimulushiDD   0.554

stimulushiid   0.549       0.506

stimulushiiDD  0.568       0.529        0.533

stimulushud    0.516       0.569        0.471        0.492

stimulushuDD   0.562       0.521        0.527        0.544         0.484

stimulushuud   0.562       0.522        0.528        0.545         0.485

stimulushuuDD  0.579       0.543        0.542        0.560         0.505

              stimulushuDD stimulushuud
ListgpTA
ListgpTQ
stimulushaaDD
stimulushad
stimulushaDD
stimulushid
stimulushiDD
stimulushiid
stimulushiiDD
stimulushud
stimulushuDD
stimulushuud   0.539
stimulushuuDD  0.554        0.554


Compared to when it is used as a random effect.

m0.1 <- glmer(match ~ Listgp + (1|stimulus) + (1|Listener), data = PATdata,
family = "binomial")
> summary(m0.1)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
glmerMod]
 Family: binomial  ( logit )
Formula: match ~ Listgp + (1 | stimulus) + (1 | Listener)
   Data: PATdata

     AIC      BIC   logLik deviance df.resid
  5218.3   5253.4  -2604.2   5208.3     8203

Scaled residuals:
     Min       1Q   Median       3Q      Max
-21.9276  -0.2804  -0.2059   0.2740   9.4275

Random effects:
 Groups   Name        Variance Std.Dev.
 Listener (Intercept) 1.676    1.294
 stimulus (Intercept) 4.949    2.225
Number of obs: 8208, groups:  Listener, 228; stimulus, 12

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -1.3754     0.6792  -2.025   0.0429 *
ListgpTA      0.2284     0.3073   0.743   0.4572
ListgpTQ      0.1432     0.2513   0.570   0.5687
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
         (Intr) LstgTA
ListgpTA -0.235
ListgpTQ -0.288  0.636


Thanks,

Shad


On 26 October 2015 at 12:47, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Shad,
>
> Please don't post in HTML since it makes the model output unreadable.
>
> You need to be more clear on "R seems not to like it".
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-10-26 10:37 GMT+01:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>
>> I'm using a binomial glmer mixed effects model.
>>
>> One variable that I have, 'stimulus' has 12 levels. The levels were not
>> randomly selected but were rather chosen as per the study design, so I
>> have
>> used the variable ?stimulus? as a fixed variable in the basic model but R
>> seems not to like it (at least this is my interpretation) given the way
>> the
>> output looks and the amount of time R takes to process it.
>>
>> m0.1 <- glmer(match ~ Listgp + stimulus + (1|Listener), data = PATdata,
>> family = "binomial")
>>
>>
>>
>> summary(m0.1) Generalized linear mixed model fit by maximum likelihood
>> (Laplace Approximation) [ glmerMod] Family: binomial ( logit ) Formula:
>> match ~ Listgp + stimulus + (1 | Listener) Data: PATdata
>>
>>  AIC      BIC   logLik deviance df.resid
>>
>> 5154.3 5259.5 -2562.2 5124.3 8193
>>
>>
>>
>> Scaled residuals: Min 1Q Median 3Q Max -25.0764 -0.2706 -0.1939 0.2472
>> 10.5131
>>
>>
>>
>> Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.743
>> 1.32
>>
>> Number of obs: 8208, groups: Listener, 228
>>
>>
>>
>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>>
>> (Intercept) 2.7561 0.2657 10.371 < 2e-16 * ListgpTA 0.1741 0.3147 0.553
>> 0.580128
>>
>> ListgpTQ 0.0810 0.2575 0.315 0.753094
>>
>> stimulushaaDD -5.4415 0.2071 -26.272 < 2e-16 stimulushad -4.2953 0.1822
>> -23.569 < 2e-16 stimulushaDD -5.4946 0.2086 -26.337 < 2e-16 stimulushid
>> -5.1519 0.1994 -25.832 < 2e-16 stimulushiDD -0.6708 0.1801 -3.724 0.000196
>> stimulushiid -5.8124 0.2186 -26.593 < 2e-16 stimulushiiDD -5.5101 0.2091
>> -26.353 < 2e-16 stimulushud -0.2016 0.1915 -1.053 0.292345
>>
>> stimulushuDD -5.6188 0.2123 -26.462 < 2e-16 stimulushuud -5.6107 0.2121
>> -26.450 < 2e-16 *
>>
>>
>>
>> stimulushuuDD -5.3207 0.2038 -26.109 < 2e-16 ***
>>
>>
>>
>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>
>> Correlation of Fixed Effects: (Intr) LstgTA LstgTQ stimulushaaDD
>> stimulushad stimulushaDD ListgpTA -0.613
>>
>> ListgpTQ -0.755 0.636
>>
>> stimulushaaDD -0.394 -0.007 0.004
>>
>> stimulushad -0.440 -0.006 0.005 0.605
>>
>> stimulushaDD -0.392 -0.007 0.003 0.555 0.601
>>
>> stimulushid -0.407 -0.007 0.004 0.572 0.624 0.569
>>
>> stimulushiDD -0.414 0.000 0.001 0.534 0.606 0.530
>>
>> stimulushiid -0.376 -0.006 0.003 0.536 0.578 0.533
>>
>> stimulushiiDD -0.391 -0.007 0.003 0.554 0.600 0.551
>>
>> stimulushud -0.386 0.000 0.000 0.497 0.564 0.493
>>
>> stimulushuDD -0.385 -0.007 0.003 0.548 0.592 0.545
>>
>> stimulushuud -0.386 -0.007 0.003 0.548 0.593 0.545
>>
>> stimulushuuDD -0.400 -0.007 0.004 0.564 0.613 0.561
>>
>> stimulushid stimulushiDD stimulushiid stimulushiiDD stimulushud ListgpTA
>>
>> ListgpTQ
>>
>> stimulushaaDD
>>
>> stimulushad
>>
>> stimulushaDD
>>
>> stimulushid
>>
>> stimulushiDD 0.554
>>
>> stimulushiid 0.549 0.506
>>
>> stimulushiiDD 0.568 0.529 0.533
>>
>> stimulushud 0.516 0.569 0.471 0.492
>>
>> stimulushuDD 0.562 0.521 0.527 0.544 0.484
>>
>> stimulushuud 0.562 0.522 0.528 0.545 0.485
>>
>> stimulushuuDD 0.579 0.543 0.542 0.560 0.505
>>
>> stimulushuDD stimulushuud ListgpTA
>>
>> ListgpTQ
>>
>> stimulushaaDD
>>
>> stimulushad
>>
>> stimulushaDD
>>
>> stimulushid
>>
>> stimulushiDD
>>
>> stimulushiid
>>
>> stimulushiiDD
>>
>> stimulushud
>>
>> stimulushuDD
>>
>> stimulushuud 0.539
>>
>> stimulushuuDD 0.554 0.554
>>
>> So, my question is, can I consider 'stimulus' as a random effect instead
>> since the model become more sensible from a programming point of view?
>>
>> m0.1 <- glmer(match ~ Listgp + (1|stimulus) + (1|Listener), data =
>> PATdata,
>> family = "binomial") summary(m0.1) Generalized linear mixed model fit by
>> maximum likelihood (Laplace Approximation) [ glmerMod] Family: binomial (
>> logit ) Formula: match ~ Listgp + (1 | stimulus) + (1 | Listener) Data:
>> PATdata
>>
>>  AIC      BIC   logLik deviance df.resid
>>
>> 5218.3 5253.4 -2604.2 5208.3 8203
>>
>>
>>
>> Scaled residuals: Min 1Q Median 3Q Max -21.9276 -0.2804 -0.2059 0.2740
>> 9.4275
>>
>>
>>
>> Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.676
>> 1.294
>>
>> stimulus (Intercept) 4.949 2.225
>>
>> Number of obs: 8208, groups: Listener, 228; stimulus, 12
>>
>>
>>
>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>>
>> (Intercept) -1.3754 0.6792 -2.025 0.0429 * ListgpTA 0.2284 0.3073 0.743
>> 0.4572
>>
>>
>>
>> ListgpTQ 0.1432 0.2513 0.570 0.5687
>>
>>
>>
>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>
>> Correlation of Fixed Effects: (Intr) LstgTA ListgpTA -0.235
>>
>> ListgpTQ -0.288 0.636
>>
>>
>>
>> Thank you,
>>
>> Shad
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon Oct 26 11:23:51 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 26 Oct 2015 10:23:51 +0000
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <mailman.6367.1445854256.3797.r-sig-mixed-models@r-project.org>
References: <mailman.6367.1445854256.3797.r-sig-mixed-models@r-project.org>
Message-ID: <562DFF37.1040702@highstat.com>



> ------------------------------
>
> Message: 3
> Date: Mon, 26 Oct 2015 13:10:46 +0300
> From: Shadiya Al Hashmi <saah500 at york.ac.uk>
> To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Cc: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Random vs. fixed effects
> Message-ID:
> 	<CACrevpmwqyoh1QHS3+WpwsimiBmP6NovYwn_-bUgunVOi6-Ukg at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear Thierry,
>
> Thanks for your response. I meant that the way the levels of stimulus are
> shown in the output does not look right.

What exactly 'doesn't look right'? How did you expect it to look? Do you 
mean the order of the levels?

>   In addition, when I use stimulus
> as a fixed effect, R takes such a long time to produce the output compared
> to when I use it as a random effect.


Maybe you want to share the information how many observations per level 
of your stimulus you have?
Without the data and R code it is not easy to give a sensible answer.

As to the warning message....see:

http://glmm.wikidot.com/faq


Alain Zuur




>
> Besides, I'm warned as follows.
>
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>    Model failed to converge with max|grad| = 0.063422 (tol = 0.001,
> component 4)
>
> Here is how the output looks when stimulus is used as a fixed effect.
>
>> summary(m0.1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> glmerMod]
>   Family: binomial  ( logit )
> Formula: match ~ Listgp + stimulus + (1 | Listener)
>     Data: PATdata
>
>       AIC      BIC   logLik deviance df.resid
>    5154.3   5259.5  -2562.2   5124.3     8193
>
> Scaled residuals:
>       Min       1Q   Median       3Q      Max
> -25.0764  -0.2706  -0.1939   0.2472  10.5131
>
> Random effects:
>   Groups   Name        Variance Std.Dev.
>   Listener (Intercept) 1.743    1.32
> Number of obs: 8208, groups:  Listener, 228
>
> Fixed effects:
>                Estimate Std. Error z value Pr(>|z|)
> (Intercept)     2.7561     0.2657  10.371  < 2e-16 ***
> ListgpTA        0.1741     0.3147   0.553 0.580128
> ListgpTQ        0.0810     0.2575   0.315 0.753094
> stimulushaaDD  -5.4415     0.2071 -26.272  < 2e-16 ***
> stimulushad    -4.2953     0.1822 -23.569  < 2e-16 ***
> stimulushaDD   -5.4946     0.2086 -26.337  < 2e-16 ***
> stimulushid    -5.1519     0.1994 -25.832  < 2e-16 ***
> stimulushiDD   -0.6708     0.1801  -3.724 0.000196 ***
> stimulushiid   -5.8124     0.2186 -26.593  < 2e-16 ***
> stimulushiiDD  -5.5101     0.2091 -26.353  < 2e-16 ***
> stimulushud    -0.2016     0.1915  -1.053 0.292345
> stimulushuDD   -5.6188     0.2123 -26.462  < 2e-16 ***
> stimulushuud   -5.6107     0.2121 -26.450  < 2e-16 ***
> stimulushuuDD  -5.3207     0.2038 -26.109  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>                (Intr) LstgTA LstgTQ stimulushaaDD stimulushad stimulushaDD
> ListgpTA      -0.613
> ListgpTQ      -0.755  0.636
> stimulushaaDD -0.394 -0.007  0.004
> stimulushad   -0.440 -0.006  0.005  0.605
> stimulushaDD  -0.392 -0.007  0.003  0.555         0.601
> stimulushid   -0.407 -0.007  0.004  0.572         0.624       0.569
> stimulushiDD  -0.414  0.000  0.001  0.534         0.606       0.530
> stimulushiid  -0.376 -0.006  0.003  0.536         0.578       0.533
> stimulushiiDD -0.391 -0.007  0.003  0.554         0.600       0.551
> stimulushud   -0.386  0.000  0.000  0.497         0.564       0.493
> stimulushuDD  -0.385 -0.007  0.003  0.548         0.592       0.545
> stimulushuud  -0.386 -0.007  0.003  0.548         0.593       0.545
> stimulushuuDD -0.400 -0.007  0.004  0.564         0.613       0.561
>                stimulushid stimulushiDD stimulushiid stimulushiiDD
> stimulushud
> ListgpTA
>
> ListgpTQ
>
> stimulushaaDD
>
> stimulushad
>
> stimulushaDD
>
> stimulushid
>
> stimulushiDD   0.554
>
> stimulushiid   0.549       0.506
>
> stimulushiiDD  0.568       0.529        0.533
>
> stimulushud    0.516       0.569        0.471        0.492
>
> stimulushuDD   0.562       0.521        0.527        0.544         0.484
>
> stimulushuud   0.562       0.522        0.528        0.545         0.485
>
> stimulushuuDD  0.579       0.543        0.542        0.560         0.505
>
>                stimulushuDD stimulushuud
> ListgpTA
> ListgpTQ
> stimulushaaDD
> stimulushad
> stimulushaDD
> stimulushid
> stimulushiDD
> stimulushiid
> stimulushiiDD
> stimulushud
> stimulushuDD
> stimulushuud   0.539
> stimulushuuDD  0.554        0.554
>
>
> Compared to when it is used as a random effect.
>
> m0.1 <- glmer(match ~ Listgp + (1|stimulus) + (1|Listener), data = PATdata,
> family = "binomial")
>> summary(m0.1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> glmerMod]
>   Family: binomial  ( logit )
> Formula: match ~ Listgp + (1 | stimulus) + (1 | Listener)
>     Data: PATdata
>
>       AIC      BIC   logLik deviance df.resid
>    5218.3   5253.4  -2604.2   5208.3     8203
>
> Scaled residuals:
>       Min       1Q   Median       3Q      Max
> -21.9276  -0.2804  -0.2059   0.2740   9.4275
>
> Random effects:
>   Groups   Name        Variance Std.Dev.
>   Listener (Intercept) 1.676    1.294
>   stimulus (Intercept) 4.949    2.225
> Number of obs: 8208, groups:  Listener, 228; stimulus, 12
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -1.3754     0.6792  -2.025   0.0429 *
> ListgpTA      0.2284     0.3073   0.743   0.4572
> ListgpTQ      0.1432     0.2513   0.570   0.5687
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>           (Intr) LstgTA
> ListgpTA -0.235
> ListgpTQ -0.288  0.636
>
>
> Thanks,
>
> Shad
>
>
> On 26 October 2015 at 12:47, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Shad,
>>
>> Please don't post in HTML since it makes the model output unreadable.
>>
>> You need to be more clear on "R seems not to like it".
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-10-26 10:37 GMT+01:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>>
>>> I'm using a binomial glmer mixed effects model.
>>>
>>> One variable that I have, 'stimulus' has 12 levels. The levels were not
>>> randomly selected but were rather chosen as per the study design, so I
>>> have
>>> used the variable ?stimulus? as a fixed variable in the basic model but R
>>> seems not to like it (at least this is my interpretation) given the way
>>> the
>>> output looks and the amount of time R takes to process it.
>>>
>>> m0.1 <- glmer(match ~ Listgp + stimulus + (1|Listener), data = PATdata,
>>> family = "binomial")
>>>
>>>
>>>
>>> summary(m0.1) Generalized linear mixed model fit by maximum likelihood
>>> (Laplace Approximation) [ glmerMod] Family: binomial ( logit ) Formula:
>>> match ~ Listgp + stimulus + (1 | Listener) Data: PATdata
>>>
>>>   AIC      BIC   logLik deviance df.resid
>>>
>>> 5154.3 5259.5 -2562.2 5124.3 8193
>>>
>>>
>>>
>>> Scaled residuals: Min 1Q Median 3Q Max -25.0764 -0.2706 -0.1939 0.2472
>>> 10.5131
>>>
>>>
>>>
>>> Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.743
>>> 1.32
>>>
>>> Number of obs: 8208, groups: Listener, 228
>>>
>>>
>>>
>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>>>
>>> (Intercept) 2.7561 0.2657 10.371 < 2e-16 * ListgpTA 0.1741 0.3147 0.553
>>> 0.580128
>>>
>>> ListgpTQ 0.0810 0.2575 0.315 0.753094
>>>
>>> stimulushaaDD -5.4415 0.2071 -26.272 < 2e-16 stimulushad -4.2953 0.1822
>>> -23.569 < 2e-16 stimulushaDD -5.4946 0.2086 -26.337 < 2e-16 stimulushid
>>> -5.1519 0.1994 -25.832 < 2e-16 stimulushiDD -0.6708 0.1801 -3.724 0.000196
>>> stimulushiid -5.8124 0.2186 -26.593 < 2e-16 stimulushiiDD -5.5101 0.2091
>>> -26.353 < 2e-16 stimulushud -0.2016 0.1915 -1.053 0.292345
>>>
>>> stimulushuDD -5.6188 0.2123 -26.462 < 2e-16 stimulushuud -5.6107 0.2121
>>> -26.450 < 2e-16 *
>>>
>>>
>>>
>>> stimulushuuDD -5.3207 0.2038 -26.109 < 2e-16 ***
>>>
>>>
>>>
>>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>>
>>> Correlation of Fixed Effects: (Intr) LstgTA LstgTQ stimulushaaDD
>>> stimulushad stimulushaDD ListgpTA -0.613
>>>
>>> ListgpTQ -0.755 0.636
>>>
>>> stimulushaaDD -0.394 -0.007 0.004
>>>
>>> stimulushad -0.440 -0.006 0.005 0.605
>>>
>>> stimulushaDD -0.392 -0.007 0.003 0.555 0.601
>>>
>>> stimulushid -0.407 -0.007 0.004 0.572 0.624 0.569
>>>
>>> stimulushiDD -0.414 0.000 0.001 0.534 0.606 0.530
>>>
>>> stimulushiid -0.376 -0.006 0.003 0.536 0.578 0.533
>>>
>>> stimulushiiDD -0.391 -0.007 0.003 0.554 0.600 0.551
>>>
>>> stimulushud -0.386 0.000 0.000 0.497 0.564 0.493
>>>
>>> stimulushuDD -0.385 -0.007 0.003 0.548 0.592 0.545
>>>
>>> stimulushuud -0.386 -0.007 0.003 0.548 0.593 0.545
>>>
>>> stimulushuuDD -0.400 -0.007 0.004 0.564 0.613 0.561
>>>
>>> stimulushid stimulushiDD stimulushiid stimulushiiDD stimulushud ListgpTA
>>>
>>> ListgpTQ
>>>
>>> stimulushaaDD
>>>
>>> stimulushad
>>>
>>> stimulushaDD
>>>
>>> stimulushid
>>>
>>> stimulushiDD 0.554
>>>
>>> stimulushiid 0.549 0.506
>>>
>>> stimulushiiDD 0.568 0.529 0.533
>>>
>>> stimulushud 0.516 0.569 0.471 0.492
>>>
>>> stimulushuDD 0.562 0.521 0.527 0.544 0.484
>>>
>>> stimulushuud 0.562 0.522 0.528 0.545 0.485
>>>
>>> stimulushuuDD 0.579 0.543 0.542 0.560 0.505
>>>
>>> stimulushuDD stimulushuud ListgpTA
>>>
>>> ListgpTQ
>>>
>>> stimulushaaDD
>>>
>>> stimulushad
>>>
>>> stimulushaDD
>>>
>>> stimulushid
>>>
>>> stimulushiDD
>>>
>>> stimulushiid
>>>
>>> stimulushiiDD
>>>
>>> stimulushud
>>>
>>> stimulushuDD
>>>
>>> stimulushuud 0.539
>>>
>>> stimulushuuDD 0.554 0.554
>>>
>>> So, my question is, can I consider 'stimulus' as a random effect instead
>>> since the model become more sensible from a programming point of view?
>>>
>>> m0.1 <- glmer(match ~ Listgp + (1|stimulus) + (1|Listener), data =
>>> PATdata,
>>> family = "binomial") summary(m0.1) Generalized linear mixed model fit by
>>> maximum likelihood (Laplace Approximation) [ glmerMod] Family: binomial (
>>> logit ) Formula: match ~ Listgp + (1 | stimulus) + (1 | Listener) Data:
>>> PATdata
>>>
>>>   AIC      BIC   logLik deviance df.resid
>>>
>>> 5218.3 5253.4 -2604.2 5208.3 8203
>>>
>>>
>>>
>>> Scaled residuals: Min 1Q Median 3Q Max -21.9276 -0.2804 -0.2059 0.2740
>>> 9.4275
>>>
>>>
>>>
>>> Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.676
>>> 1.294
>>>
>>> stimulus (Intercept) 4.949 2.225
>>>
>>> Number of obs: 8208, groups: Listener, 228; stimulus, 12
>>>
>>>
>>>
>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>>>
>>> (Intercept) -1.3754 0.6792 -2.025 0.0429 * ListgpTA 0.2284 0.3073 0.743
>>> 0.4572
>>>
>>>
>>>
>>> ListgpTQ 0.1432 0.2513 0.570 0.5687
>>>
>>>
>>>
>>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>>
>>> Correlation of Fixed Effects: (Intr) LstgTA ListgpTA -0.235
>>>
>>> ListgpTQ -0.288 0.636
>>>
>>>
>>>
>>> Thank you,
>>>
>>> Shad
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 106, Issue 33
> ***************************************************
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From thierry.onkelinx at inbo.be  Mon Oct 26 11:25:58 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 26 Oct 2015 11:25:58 +0100
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <CACrevpmwqyoh1QHS3+WpwsimiBmP6NovYwn_-bUgunVOi6-Ukg@mail.gmail.com>
References: <CACrevpn1FOpU2e9ERtGWTV=D0xB1VpatVvMRsD-VuJ6eMAwo4Q@mail.gmail.com>
	<CAJuCY5ydmmJ28HXhgKSzoOs5ZQfxBgn7bBTAd_RgECJHdV1PDw@mail.gmail.com>
	<CACrevpmwqyoh1QHS3+WpwsimiBmP6NovYwn_-bUgunVOi6-Ukg@mail.gmail.com>
Message-ID: <CAJuCY5xL-mGM=DLY0jGi6Z4Q8k8UCo9KHvDB2m1vMWfz7dbPDQ@mail.gmail.com>

Dear Shad,

It looks like you have complete separation in your dataset. Random effect
are slightly better at coping with that. But still the very high variance
of the random effect indicate that there is complete separation.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-26 11:10 GMT+01:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:

> Dear Thierry,
>
> Thanks for your response. I meant that the way the levels of stimulus are
> shown in the output does not look right. In addition, when I use stimulus
> as a fixed effect, R takes such a long time to produce the output compared
> to when I use it as a random effect.
>
> Besides, I'm warned as follows.
>
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.063422 (tol = 0.001,
> component 4)
>
> Here is how the output looks when stimulus is used as a fixed effect.
>
> > summary(m0.1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> glmerMod]
>  Family: binomial  ( logit )
> Formula: match ~ Listgp + stimulus + (1 | Listener)
>    Data: PATdata
>
>      AIC      BIC   logLik deviance df.resid
>   5154.3   5259.5  -2562.2   5124.3     8193
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -25.0764  -0.2706  -0.1939   0.2472  10.5131
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Listener (Intercept) 1.743    1.32
> Number of obs: 8208, groups:  Listener, 228
>
> Fixed effects:
>               Estimate Std. Error z value Pr(>|z|)
> (Intercept)     2.7561     0.2657  10.371  < 2e-16 ***
> ListgpTA        0.1741     0.3147   0.553 0.580128
> ListgpTQ        0.0810     0.2575   0.315 0.753094
> stimulushaaDD  -5.4415     0.2071 -26.272  < 2e-16 ***
> stimulushad    -4.2953     0.1822 -23.569  < 2e-16 ***
> stimulushaDD   -5.4946     0.2086 -26.337  < 2e-16 ***
> stimulushid    -5.1519     0.1994 -25.832  < 2e-16 ***
> stimulushiDD   -0.6708     0.1801  -3.724 0.000196 ***
> stimulushiid   -5.8124     0.2186 -26.593  < 2e-16 ***
> stimulushiiDD  -5.5101     0.2091 -26.353  < 2e-16 ***
> stimulushud    -0.2016     0.1915  -1.053 0.292345
> stimulushuDD   -5.6188     0.2123 -26.462  < 2e-16 ***
> stimulushuud   -5.6107     0.2121 -26.450  < 2e-16 ***
> stimulushuuDD  -5.3207     0.2038 -26.109  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>               (Intr) LstgTA LstgTQ stimulushaaDD stimulushad stimulushaDD
> ListgpTA      -0.613
> ListgpTQ      -0.755  0.636
> stimulushaaDD -0.394 -0.007  0.004
> stimulushad   -0.440 -0.006  0.005  0.605
> stimulushaDD  -0.392 -0.007  0.003  0.555         0.601
> stimulushid   -0.407 -0.007  0.004  0.572         0.624       0.569
> stimulushiDD  -0.414  0.000  0.001  0.534         0.606       0.530
> stimulushiid  -0.376 -0.006  0.003  0.536         0.578       0.533
> stimulushiiDD -0.391 -0.007  0.003  0.554         0.600       0.551
> stimulushud   -0.386  0.000  0.000  0.497         0.564       0.493
> stimulushuDD  -0.385 -0.007  0.003  0.548         0.592       0.545
> stimulushuud  -0.386 -0.007  0.003  0.548         0.593       0.545
> stimulushuuDD -0.400 -0.007  0.004  0.564         0.613       0.561
>               stimulushid stimulushiDD stimulushiid stimulushiiDD
> stimulushud
> ListgpTA
>
> ListgpTQ
>
> stimulushaaDD
>
> stimulushad
>
> stimulushaDD
>
> stimulushid
>
> stimulushiDD   0.554
>
> stimulushiid   0.549       0.506
>
> stimulushiiDD  0.568       0.529        0.533
>
> stimulushud    0.516       0.569        0.471        0.492
>
> stimulushuDD   0.562       0.521        0.527        0.544         0.484
>
> stimulushuud   0.562       0.522        0.528        0.545         0.485
>
> stimulushuuDD  0.579       0.543        0.542        0.560         0.505
>
>               stimulushuDD stimulushuud
> ListgpTA
> ListgpTQ
> stimulushaaDD
> stimulushad
> stimulushaDD
> stimulushid
> stimulushiDD
> stimulushiid
> stimulushiiDD
> stimulushud
> stimulushuDD
> stimulushuud   0.539
> stimulushuuDD  0.554        0.554
>
>
> Compared to when it is used as a random effect.
>
> m0.1 <- glmer(match ~ Listgp + (1|stimulus) + (1|Listener), data =
> PATdata, family = "binomial")
> > summary(m0.1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> glmerMod]
>  Family: binomial  ( logit )
> Formula: match ~ Listgp + (1 | stimulus) + (1 | Listener)
>    Data: PATdata
>
>      AIC      BIC   logLik deviance df.resid
>   5218.3   5253.4  -2604.2   5208.3     8203
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -21.9276  -0.2804  -0.2059   0.2740   9.4275
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Listener (Intercept) 1.676    1.294
>  stimulus (Intercept) 4.949    2.225
> Number of obs: 8208, groups:  Listener, 228; stimulus, 12
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -1.3754     0.6792  -2.025   0.0429 *
> ListgpTA      0.2284     0.3073   0.743   0.4572
> ListgpTQ      0.1432     0.2513   0.570   0.5687
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>          (Intr) LstgTA
> ListgpTA -0.235
> ListgpTQ -0.288  0.636
>
>
> Thanks,
>
> Shad
>
>
> On 26 October 2015 at 12:47, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Shad,
>>
>> Please don't post in HTML since it makes the model output unreadable.
>>
>> You need to be more clear on "R seems not to like it".
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-10-26 10:37 GMT+01:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>>
>>> I'm using a binomial glmer mixed effects model.
>>>
>>> One variable that I have, 'stimulus' has 12 levels. The levels were not
>>> randomly selected but were rather chosen as per the study design, so I
>>> have
>>> used the variable ?stimulus? as a fixed variable in the basic model but R
>>> seems not to like it (at least this is my interpretation) given the way
>>> the
>>> output looks and the amount of time R takes to process it.
>>>
>>> m0.1 <- glmer(match ~ Listgp + stimulus + (1|Listener), data = PATdata,
>>> family = "binomial")
>>>
>>>
>>>
>>> summary(m0.1) Generalized linear mixed model fit by maximum likelihood
>>> (Laplace Approximation) [ glmerMod] Family: binomial ( logit ) Formula:
>>> match ~ Listgp + stimulus + (1 | Listener) Data: PATdata
>>>
>>>  AIC      BIC   logLik deviance df.resid
>>>
>>> 5154.3 5259.5 -2562.2 5124.3 8193
>>>
>>>
>>>
>>> Scaled residuals: Min 1Q Median 3Q Max -25.0764 -0.2706 -0.1939 0.2472
>>> 10.5131
>>>
>>>
>>>
>>> Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.743
>>> 1.32
>>>
>>> Number of obs: 8208, groups: Listener, 228
>>>
>>>
>>>
>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>>>
>>> (Intercept) 2.7561 0.2657 10.371 < 2e-16 * ListgpTA 0.1741 0.3147 0.553
>>> 0.580128
>>>
>>> ListgpTQ 0.0810 0.2575 0.315 0.753094
>>>
>>> stimulushaaDD -5.4415 0.2071 -26.272 < 2e-16 stimulushad -4.2953 0.1822
>>> -23.569 < 2e-16 stimulushaDD -5.4946 0.2086 -26.337 < 2e-16 stimulushid
>>> -5.1519 0.1994 -25.832 < 2e-16 stimulushiDD -0.6708 0.1801 -3.724
>>> 0.000196
>>> stimulushiid -5.8124 0.2186 -26.593 < 2e-16 stimulushiiDD -5.5101 0.2091
>>> -26.353 < 2e-16 stimulushud -0.2016 0.1915 -1.053 0.292345
>>>
>>> stimulushuDD -5.6188 0.2123 -26.462 < 2e-16 stimulushuud -5.6107 0.2121
>>> -26.450 < 2e-16 *
>>>
>>>
>>>
>>> stimulushuuDD -5.3207 0.2038 -26.109 < 2e-16 ***
>>>
>>>
>>>
>>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>>
>>> Correlation of Fixed Effects: (Intr) LstgTA LstgTQ stimulushaaDD
>>> stimulushad stimulushaDD ListgpTA -0.613
>>>
>>> ListgpTQ -0.755 0.636
>>>
>>> stimulushaaDD -0.394 -0.007 0.004
>>>
>>> stimulushad -0.440 -0.006 0.005 0.605
>>>
>>> stimulushaDD -0.392 -0.007 0.003 0.555 0.601
>>>
>>> stimulushid -0.407 -0.007 0.004 0.572 0.624 0.569
>>>
>>> stimulushiDD -0.414 0.000 0.001 0.534 0.606 0.530
>>>
>>> stimulushiid -0.376 -0.006 0.003 0.536 0.578 0.533
>>>
>>> stimulushiiDD -0.391 -0.007 0.003 0.554 0.600 0.551
>>>
>>> stimulushud -0.386 0.000 0.000 0.497 0.564 0.493
>>>
>>> stimulushuDD -0.385 -0.007 0.003 0.548 0.592 0.545
>>>
>>> stimulushuud -0.386 -0.007 0.003 0.548 0.593 0.545
>>>
>>> stimulushuuDD -0.400 -0.007 0.004 0.564 0.613 0.561
>>>
>>> stimulushid stimulushiDD stimulushiid stimulushiiDD stimulushud ListgpTA
>>>
>>> ListgpTQ
>>>
>>> stimulushaaDD
>>>
>>> stimulushad
>>>
>>> stimulushaDD
>>>
>>> stimulushid
>>>
>>> stimulushiDD 0.554
>>>
>>> stimulushiid 0.549 0.506
>>>
>>> stimulushiiDD 0.568 0.529 0.533
>>>
>>> stimulushud 0.516 0.569 0.471 0.492
>>>
>>> stimulushuDD 0.562 0.521 0.527 0.544 0.484
>>>
>>> stimulushuud 0.562 0.522 0.528 0.545 0.485
>>>
>>> stimulushuuDD 0.579 0.543 0.542 0.560 0.505
>>>
>>> stimulushuDD stimulushuud ListgpTA
>>>
>>> ListgpTQ
>>>
>>> stimulushaaDD
>>>
>>> stimulushad
>>>
>>> stimulushaDD
>>>
>>> stimulushid
>>>
>>> stimulushiDD
>>>
>>> stimulushiid
>>>
>>> stimulushiiDD
>>>
>>> stimulushud
>>>
>>> stimulushuDD
>>>
>>> stimulushuud 0.539
>>>
>>> stimulushuuDD 0.554 0.554
>>>
>>> So, my question is, can I consider 'stimulus' as a random effect instead
>>> since the model become more sensible from a programming point of view?
>>>
>>> m0.1 <- glmer(match ~ Listgp + (1|stimulus) + (1|Listener), data =
>>> PATdata,
>>> family = "binomial") summary(m0.1) Generalized linear mixed model fit by
>>> maximum likelihood (Laplace Approximation) [ glmerMod] Family: binomial (
>>> logit ) Formula: match ~ Listgp + (1 | stimulus) + (1 | Listener) Data:
>>> PATdata
>>>
>>>  AIC      BIC   logLik deviance df.resid
>>>
>>> 5218.3 5253.4 -2604.2 5208.3 8203
>>>
>>>
>>>
>>> Scaled residuals: Min 1Q Median 3Q Max -21.9276 -0.2804 -0.2059 0.2740
>>> 9.4275
>>>
>>>
>>>
>>> Random effects: Groups Name Variance Std.Dev. Listener (Intercept) 1.676
>>> 1.294
>>>
>>> stimulus (Intercept) 4.949 2.225
>>>
>>> Number of obs: 8208, groups: Listener, 228; stimulus, 12
>>>
>>>
>>>
>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>>>
>>> (Intercept) -1.3754 0.6792 -2.025 0.0429 * ListgpTA 0.2284 0.3073 0.743
>>> 0.4572
>>>
>>>
>>>
>>> ListgpTQ 0.1432 0.2513 0.570 0.5687
>>>
>>>
>>>
>>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>>
>>> Correlation of Fixed Effects: (Intr) LstgTA ListgpTA -0.235
>>>
>>> ListgpTQ -0.288 0.636
>>>
>>>
>>>
>>> Thank you,
>>>
>>> Shad
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
>
>

	[[alternative HTML version deleted]]


From francescobryanromano at gmail.com  Mon Oct 26 11:56:48 2015
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Mon, 26 Oct 2015 11:56:48 +0100
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
Message-ID: <CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>

I wonder if anyone can help with the separation problem originally solved
by Ben Bolker (see thread).
The model and fitting I used previously was

trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family =
binomial, fixef.prior = normal(cov = diag(9,4))

which now has to change because the Syntax.Semantcs factor needs to be
split into separate
within-subjects variables, Syntax, a factor with two levels, and Animacy, a
factor with four levels.
In addition a new between-subjects factor called Group with two levels
(native vs non-native speaker)
has to be added which determines the following model, fit by bglmer:

trial<-bglmer(Correct ~ Syntax*Animacy*Group+ (1|Part.name)+(1|Item), data
= trialglm, family = binomial,
fixef.prior = normal(cov = diag???)

What values should I use for the cov=diag portion in order to continue
attempting convergence of a model
that includes the random effects?

R returns the following error because I don't know how to establish the
parameters when more than one
fixed effect is involved:

Error in normal(cov = cov, common.scale = FALSE) :
  normal prior covariance of improper length

Many thanks in advance for any help!





On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com> wrote:

>   I don't see your data -- I see a little tiny subset, but that's not
> really enough for a reproducible example.
>
> This is the example given in the URL I sent:
>
> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
>                        family=binomial,
>                        fixef.prior = normal(cov = diag(9,4)))
>
> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>           data =trialglm,
>          family = binomial,
>         fixef.prior = normal(cov=diag(9,8)))
>
> The last line specifies an 8x8 matrix (because you have 8 fixed effect
> parameters) with a value of 9 on the diagonal, meaning the priors for
> the fixed effects are independent and each is Normal with a sd of
> sqrt(9)=3.
>
>
> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
> <francescobryanromano at gmail.com> wrote:
> > Yes but this seems a bit above my head without your help. The data are in
> > the three variables at the bottom of my email but I forgot to mention the
> > random participant effect (n = 17). Thanks!
> >
> >
> > Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha scritto:
> >>
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA1
> >>
> >> On 15-05-28 06:55 AM, Francesco Romano wrote:
> >> > Many thanks to both.
> >> >
> >> > The approaches you suggest (and others online) help one deal with
> >> > the separation problem but don't offer any specific advice as to
> >> > how getting a valid p coefficient when comparing two levels of the
> >> > model vexed by separation.
> >> >
> >> > Ben, here's the output of the bglmer which by the way would be
> >> > ideal since it allows me to retain the random effect so that all my
> >> > pairwise comparisons are conducted using mixed effects.
> >> >
> >> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
> >> >> trialglm,
> >> > family = binomial) Warning message: package ?blme? was built under
> >> > R version 3.1.2
> >> >> summary(trial)
> >> > Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
> >> > posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
> >> >
> >> > Generalized linear mixed model fit by maximum likelihood (Laplace
> >> > Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
> >> > Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
> >> >
> >> > AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
> >> > 251.9      376
> >> >
> >> > Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
> >> > -0.4281 -0.2445 -0.0002  5.7872
> >> >
> >> > Random effects: Groups    Name        Variance Std.Dev. Part.name
> >> > (Intercept) 0.3836   0.6194 Number of obs: 385, groups:  Part.name,
> >> > 16
> >> >
> >> > Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >> > -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
> >> > 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
> >> > 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323     0.7462
> >> > -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
> >> > 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
> >> > Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
> >> > Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
> >> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >
> >> > Unfortunately the separation problem is still there. Should I be
> >> > constraining the parameter somehow? How would I do that? The data
> >> > is below.
> >>
> >>    Did you read the section in the URL I suggested?  Just using bglmer
> >> isn't enough; you also have to set a prior on the fixed effects.
> >>
> >>   Your data don't seem to be attached (note that the mailing list
> >> strips most non-ASCII file types).
> >>
> >> >
> >> > In passing I also tried brglm which solves the separation problem
> >> > but tells me comparison is significant which I don't believe one
> >> > bit (see the data below). I am pretty sure about this because when
> >> > I reveled and look at the comparisons I was able to compute using
> >> > glmer, these turn out to be non-significant, when glmer told me
> >> > they were:
> >> >
> >> >> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family
> >> >> =
> >> > binomial) Warning messages: 1: package ?elrm? was built under R
> >> > version 3.1.2 2: package ?coda? was built under R version 3.1.3
> >> >> summary(trial)
> >> >
> >> > Call: brglm(formula = Correct ~ Syntax.Semantics, family =
> >> > binomial, data = trialglm)
> >> >
> >> >
> >> > Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >> > -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A   0.6689
> >> > 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
> >> > -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
> >> > 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
> >> > Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
> >> > Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
> >> > Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 --- Signif.
> >> > codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >
> >> > (Dispersion parameter for binomial family taken to be 1)
> >> >
> >> > Null deviance: 262.51  on 384  degrees of freedom Residual
> >> > deviance: 256.22  on 377  degrees of freedom Penalized deviance:
> >> > 245.5554 AIC:  272.22
> >> >
> >> >
> >> > MCMCglmm is too complex for me.
> >> >
> >> > Wolfgang, I tried the penalized likelihood method (logistf
> >> > function) but output is hard to read:
> >> >
> >> >> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
> >> >> family =
> >> > binomial) Warning messages: 1: package ?logistf? was built under R
> >> > version 3.1.2 2: package ?mice? was built under R version 3.1.2
> >> >> summary(trial)
> >> > logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
> >> > family = binomial)
> >> >
> >> > Model fitted by Penalized ML Confidence intervals and p-values by
> >> > Profile Likelihood Profile Likelihood Profile Likelihood Profile
> >> > Likelihood Profile Likelihood Profile Likelihood Profile Likelihood
> >> > Profile Likelihood
> >> >
> >> > coef  se(coef) lower 0.95 upper 0.95 Chisq            p (Intercept)
> >> > 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00
> >> > Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
> >> > 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
> >> > -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
> >> > -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 1.000000e+00
> >> > Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
> >> > 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
> >> > -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
> >> > -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 1.000000e+00
> >> > Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
> >> > 0.000000 1.000000e+00
> >> >
> >> > Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
> >> > 5.334321 on 7 df, p = 0.6192356
> >> >
> >> > In particular, what is this model telling me? That Z (my ref level)
> >> > and B are significantly different?
> >> >
> >> > I'm happy to try the elrm function with exact logistic regression
> >> > but I am not capable of programming it. Besides, would it give me
> >> > valid estimates for the comparison between the Z and B levels? The
> >> > data frame should look like this:
> >> >
> >> > Outcome variable (Correct, incorrect) Predictor variable (A, B, C,
> >> > D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
> >> > 36,8; C:45,3; A: 34,13; F:65,22).
> >> >
> >> > Thank you! F.
> >> >
> >> > On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
> >> > wrote:
> >> >
> >> >> And for what it's worth, you can do this in conjunction with lme4
> >> >> by using the blme package instead (a thin Bayesian wrapper around
> >> >> lme4), or via the MCMCglmm package; see
> >> >> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
> >> >> for an example (search for "complete separation").
> >> >>
> >> >> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
> >> >> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >> >>> You may need to consider using an 'exact', Bayesian, or
> >> >>> penalized
> >> >> likelihood approach (along the lines proposed by Firth).
> >> >>>
> >> >>> Maybe a place to start:
> >> >>
> >> >>
> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
> >> >>>
> >> >>>
> >> >>
> >> Best,
> >> >>> Wolfgang
> >> >>>
> >> >>>> -----Original Message----- From: R-sig-mixed-models
> >> >>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
> >> >>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
> >> >>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
> >> >>>> cells in contrast matrix problem
> >> >>>>
> >> >>>> After giving up on a glmer for my data, I remembered a post
> >> >>>> by Roger
> >> >> Levy
> >> >>>> suggesting to try the use non mixed effects glm when one of
> >> >>>> the cells in a matrix is zero.
> >> >>>>
> >> >>>> To put this into perspective:
> >> >>>>
> >> >>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
> >> >>>>> data =
> >> >>>> trialglm, family = binomial)
> >> >>>>
> >> >>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
> >> >>>> opt$par, ctrl = control$checkConv, : Model failed to converge
> >> >>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
> >> >>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
> >> >>>> control$checkConv, : Model is nearly unidentifiable: large
> >> >>>> eigenvalue ratio - Rescale variables?
> >> >>>>
> >> >>>> My data has a binary outcome, correct or incorrect, a fixed
> >> >>>> effect predictor factor with 8 levels, and a random effect
> >> >>>> for participants. I believe the problem R is encountering is
> >> >>>> with one level of the factor (let us call it level B) which
> >> >>>> has no counts (no I won' t try to post the table from the
> >> >>>> paper with the counts because I know it will get garbled
> >> >>>> up!).
> >> >>>>
> >> >>>> I attempt a glm with the same data:
> >> >>>>
> >> >>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
> >> >>>>> family =
> >> >>>> binomial)
> >> >>>>> anova(trial)
> >> >>>> Analysis of Deviance Table
> >> >>>>
> >> >>>> Model: binomial, link: logit
> >> >>>>
> >> >>>> Response: Correct
> >> >>>>
> >> >>>> Terms added sequentially (first to last)
> >> >>>>
> >> >>>>
> >> >>>> Df Deviance Resid. Df Resid. Dev NULL
> >> >>>> 384     289.63 Syntax.Semantics  7   34.651       377
> >> >>>> 254.97
> >> >>>>> summary(trial)
> >> >>>>
> >> >>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
> >> >>>> binomial, data = trialglm)
> >> >>>>
> >> >>>> Deviance Residuals: Min        1Q    Median        3Q
> >> >>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
> >> >>>>
> >> >>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
> >> >>>> (Intercept)                 -1.6917     0.4113  -4.113
> >> >>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
> >> >>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
> >> >>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
> >> >>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
> >> >>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
> >> >>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
> >> >>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
> >> >>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
> >> >>>> ?.? 0.1 ? ? 1
> >> >>>>
> >> >>>> (Dispersion parameter for binomial family taken to be 1)
> >> >>>>
> >> >>>> Null deviance: 289.63  on 384  degrees of freedom Residual
> >> >>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
> >> >>>>
> >> >>>> Number of Fisher Scoring iterations: 17
> >> >>>>
> >> >>>> The comparison I'm interested in is between level B and the
> >> >>>> reference level but it cannot be estimated as shown by the
> >> >>>> ridiculously high estimate and SE value.
> >> >>>>
> >> >>>> Any suggestions on how to get a decent beta, SE, z, and p?
> >> >>>> It's the only comparison missing in the table for the levels
> >> >>>> I need so I think it
> >> >> would
> >> >>>> be a bit unacademic of me to close this deal saying 'the
> >> >>>> difference
> >> >> could
> >> >>>> not be estimated due to zero count'.
> >> >>>>
> >> >>>> And by the way I have seen this comparison being generated
> >> >>>> using other stats.
> >> >>>>
> >> >>>> Thanks in advance,
> >> >>>>
> >> >>>> Frank
> >> >>>>
> >> >>>> [[alternative HTML version deleted]]
> >> >>>>
> >> >>>> _______________________________________________
> >> >>>> R-sig-mixed-models at r-project.org mailing list
> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>> _______________________________________________
> >> >>> R-sig-mixed-models at r-project.org mailing list
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>
> >> >
> >>
> >> -----BEGIN PGP SIGNATURE-----
> >> Version: GnuPG v1.4.11 (GNU/Linux)
> >>
> >> iQEcBAEBAgAGBQJVZ2DeAAoJEOCV5YRblxUH9f0IAN/LTzJllxXqmdP4U2bbDNOR
> >> XnjYDsQ+cF6eR6aRMxWK1nj7Lgdi1pvqOU/3CSMVke2HW2Cr07wR2VDtqHwWRAgZ
> >> jTlzlJ/iA5o32T1U2Wm9jrle0E0RpTMrA8SZ8HsGVKT3cD/5TNo9eoPAw3DV45AO
> >> hmwUJf0NYLhZwOJ2QAsk1rAn06CBmrVSXFUmdGKpODELFJ4whAn95phE8pLY+aW9
> >> qfO4Rq4FcZt1wdRwlZmk8woEeqeySb+rBRxZCVQ0HuyoEGONHMq5Wa1hnffwVR3V
> >> yiIo1Vtd7sTbxAs96DeP8AItyHTvgsKRJphEK/PYguDQCGeR70sQEL53FTdHM60=
> >> =3UD2
> >> -----END PGP SIGNATURE-----
> >
> >
> >
> > --
> > Sent from Gmail for IPhone
>



-- 
Frank Romano Ph.D.

Tel. +39 3911639149

*LinkedIn*
https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162

*Academia.edu*
https://sheffield.academia.edu/FrancescoRomano

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Oct 26 12:06:33 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Oct 2015 07:06:33 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
Message-ID: <562E0939.3020904@gmail.com>

On 15-10-26 06:56 AM, Francesco Romano wrote:
> I wonder if anyone can help with the separation problem originally solved
> by Ben Bolker (see thread).
> The model and fitting I used previously was
> 
> trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family =
> binomial, fixef.prior = normal(cov = diag(9,4))
> 
> which now has to change because the Syntax.Semantcs factor needs to be
> split into separate
> within-subjects variables, Syntax, a factor with two levels, and Animacy, a
> factor with four levels.
> In addition a new between-subjects factor called Group with two levels
> (native vs non-native speaker)
> has to be added which determines the following model, fit by bglmer:
> 
> trial<-bglmer(Correct ~ Syntax*Animacy*Group+ (1|Part.name)+(1|Item), data
> = trialglm, family = binomial,
> fixef.prior = normal(cov = diag???)
> 
> What values should I use for the cov=diag portion in order to continue
> attempting convergence of a model
> that includes the random effects?

    In general a reasonable form is normal(cov = diag(v,np)) where v is
the prior variance (generally something reasonably
large/non-informative; 9 (=std dev of 3) is probably an OK default) and
np is the number of fixed-effect parameters.  You can figure this out via

ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)

or multiply 2*4*2 to get 16 ...

> 
> R returns the following error because I don't know how to establish the
> parameters when more than one
> fixed effect is involved:
> 
> Error in normal(cov = cov, common.scale = FALSE) :
>   normal prior covariance of improper length
> 
> Many thanks in advance for any help!
> 
> 
> 
> 
> 
> On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>>   I don't see your data -- I see a little tiny subset, but that's not
>> really enough for a reproducible example.
>>
>> This is the example given in the URL I sent:
>>
>> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
>>                        family=binomial,
>>                        fixef.prior = normal(cov = diag(9,4)))
>>
>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>>           data =trialglm,
>>          family = binomial,
>>         fixef.prior = normal(cov=diag(9,8)))
>>
>> The last line specifies an 8x8 matrix (because you have 8 fixed effect
>> parameters) with a value of 9 on the diagonal, meaning the priors for
>> the fixed effects are independent and each is Normal with a sd of
>> sqrt(9)=3.
>>
>>
>> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
>> <francescobryanromano at gmail.com> wrote:
>>> Yes but this seems a bit above my head without your help. The data are in
>>> the three variables at the bottom of my email but I forgot to mention the
>>> random participant effect (n = 17). Thanks!
>>>
>>>
>>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha scritto:
>>>>
> On 15-05-28 06:55 AM, Francesco Romano wrote:
>>>>>> Many thanks to both.
>>>>>>
>>>>>> The approaches you suggest (and others online) help one deal with
>>>>>> the separation problem but don't offer any specific advice as to
>>>>>> how getting a valid p coefficient when comparing two levels of the
>>>>>> model vexed by separation.
>>>>>>
>>>>>> Ben, here's the output of the bglmer which by the way would be
>>>>>> ideal since it allows me to retain the random effect so that all my
>>>>>> pairwise comparisons are conducted using mixed effects.
>>>>>>
>>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
>>>>>>> trialglm,
>>>>>> family = binomial) Warning message: package ?blme? was built under
>>>>>> R version 3.1.2
>>>>>>> summary(trial)
>>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
>>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
>>>>>>
>>>>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
>>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
>>>>>>
>>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
>>>>>> 251.9      376
>>>>>>
>>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
>>>>>> -0.4281 -0.2445 -0.0002  5.7872
>>>>>>
>>>>>> Random effects: Groups    Name        Variance Std.Dev. Part.name
>>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:  Part.name,
>>>>>> 16
>>>>>>
>>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
>>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
>>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323     0.7462
>>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
>>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
>>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
>>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
>>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>>
>>>>>> Unfortunately the separation problem is still there. Should I be
>>>>>> constraining the parameter somehow? How would I do that? The data
>>>>>> is below.
> 
>    Did you read the section in the URL I suggested?  Just using bglmer
> isn't enough; you also have to set a prior on the fixed effects.
> 
>   Your data don't seem to be attached (note that the mailing list
> strips most non-ASCII file types).
> 
>>>>>>
>>>>>> In passing I also tried brglm which solves the separation problem
>>>>>> but tells me comparison is significant which I don't believe one
>>>>>> bit (see the data below). I am pretty sure about this because when
>>>>>> I reveled and look at the comparisons I was able to compute using
>>>>>> glmer, these turn out to be non-significant, when glmer told me
>>>>>> they were:
>>>>>>
>>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family
>>>>>>> =
>>>>>> binomial) Warning messages: 1: package ?elrm? was built under R
>>>>>> version 3.1.2 2: package ?coda? was built under R version 3.1.3
>>>>>>> summary(trial)
>>>>>>
>>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
>>>>>> binomial, data = trialglm)
>>>>>>
>>>>>>
>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
>>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A   0.6689
>>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
>>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
>>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
>>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
>>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
>>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 --- Signif.
>>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>>
>>>>>> (Dispersion parameter for binomial family taken to be 1)
>>>>>>
>>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
>>>>>> deviance: 256.22  on 377  degrees of freedom Penalized deviance:
>>>>>> 245.5554 AIC:  272.22
>>>>>>
>>>>>>
>>>>>> MCMCglmm is too complex for me.
>>>>>>
>>>>>> Wolfgang, I tried the penalized likelihood method (logistf
>>>>>> function) but output is hard to read:
>>>>>>
>>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>>>>>>> family =
>>>>>> binomial) Warning messages: 1: package ?logistf? was built under R
>>>>>> version 3.1.2 2: package ?mice? was built under R version 3.1.2
>>>>>>> summary(trial)
>>>>>> logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
>>>>>> family = binomial)
>>>>>>
>>>>>> Model fitted by Penalized ML Confidence intervals and p-values by
>>>>>> Profile Likelihood Profile Likelihood Profile Likelihood Profile
>>>>>> Likelihood Profile Likelihood Profile Likelihood Profile Likelihood
>>>>>> Profile Likelihood
>>>>>>
>>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p (Intercept)
>>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00
>>>>>> Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
>>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
>>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
>>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 1.000000e+00
>>>>>> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
>>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
>>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
>>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 1.000000e+00
>>>>>> Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
>>>>>> 0.000000 1.000000e+00
>>>>>>
>>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
>>>>>> 5.334321 on 7 df, p = 0.6192356
>>>>>>
>>>>>> In particular, what is this model telling me? That Z (my ref level)
>>>>>> and B are significantly different?
>>>>>>
>>>>>> I'm happy to try the elrm function with exact logistic regression
>>>>>> but I am not capable of programming it. Besides, would it give me
>>>>>> valid estimates for the comparison between the Z and B levels? The
>>>>>> data frame should look like this:
>>>>>>
>>>>>> Outcome variable (Correct, incorrect) Predictor variable (A, B, C,
>>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
>>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
>>>>>>
>>>>>> Thank you! F.
>>>>>>
>>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> And for what it's worth, you can do this in conjunction with lme4
>>>>>>> by using the blme package instead (a thin Bayesian wrapper around
>>>>>>> lme4), or via the MCMCglmm package; see
>>>>>>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>>>>>>> for an example (search for "complete separation").
>>>>>>>
>>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
>>>>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>>>>>> You may need to consider using an 'exact', Bayesian, or
>>>>>>>> penalized
>>>>>>> likelihood approach (along the lines proposed by Firth).
>>>>>>>>
>>>>>>>> Maybe a place to start:
>>>>>>>
>>>>>>>
>>> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
>>>>>>>>
>>>>>>>>
>>>>>>>
> Best,
>>>>>>>> Wolfgang
>>>>>>>>
>>>>>>>>> -----Original Message----- From: R-sig-mixed-models
>>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
>>>>>>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
>>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>>>>>>>>> cells in contrast matrix problem
>>>>>>>>>
>>>>>>>>> After giving up on a glmer for my data, I remembered a post
>>>>>>>>> by Roger
>>>>>>> Levy
>>>>>>>>> suggesting to try the use non mixed effects glm when one of
>>>>>>>>> the cells in a matrix is zero.
>>>>>>>>>
>>>>>>>>> To put this into perspective:
>>>>>>>>>
>>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
>>>>>>>>>> data =
>>>>>>>>> trialglm, family = binomial)
>>>>>>>>>
>>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to converge
>>>>>>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
>>>>>>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>>>>>>> control$checkConv, : Model is nearly unidentifiable: large
>>>>>>>>> eigenvalue ratio - Rescale variables?
>>>>>>>>>
>>>>>>>>> My data has a binary outcome, correct or incorrect, a fixed
>>>>>>>>> effect predictor factor with 8 levels, and a random effect
>>>>>>>>> for participants. I believe the problem R is encountering is
>>>>>>>>> with one level of the factor (let us call it level B) which
>>>>>>>>> has no counts (no I won' t try to post the table from the
>>>>>>>>> paper with the counts because I know it will get garbled
>>>>>>>>> up!).
>>>>>>>>>
>>>>>>>>> I attempt a glm with the same data:
>>>>>>>>>
>>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>>>>>>>>>> family =
>>>>>>>>> binomial)
>>>>>>>>>> anova(trial)
>>>>>>>>> Analysis of Deviance Table
>>>>>>>>>
>>>>>>>>> Model: binomial, link: logit
>>>>>>>>>
>>>>>>>>> Response: Correct
>>>>>>>>>
>>>>>>>>> Terms added sequentially (first to last)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
>>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
>>>>>>>>> 254.97
>>>>>>>>>> summary(trial)
>>>>>>>>>
>>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>>>>>>>>> binomial, data = trialglm)
>>>>>>>>>
>>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
>>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>>>>>>>>>
>>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
>>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
>>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
>>>>>>>>> ?.? 0.1 ? ? 1
>>>>>>>>>
>>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
>>>>>>>>>
>>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom Residual
>>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>>>>>>>>>
>>>>>>>>> Number of Fisher Scoring iterations: 17
>>>>>>>>>
>>>>>>>>> The comparison I'm interested in is between level B and the
>>>>>>>>> reference level but it cannot be estimated as shown by the
>>>>>>>>> ridiculously high estimate and SE value.
>>>>>>>>>
>>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
>>>>>>>>> It's the only comparison missing in the table for the levels
>>>>>>>>> I need so I think it
>>>>>>> would
>>>>>>>>> be a bit unacademic of me to close this deal saying 'the
>>>>>>>>> difference
>>>>>>> could
>>>>>>>>> not be estimated due to zero count'.
>>>>>>>>>
>>>>>>>>> And by the way I have seen this comparison being generated
>>>>>>>>> using other stats.
>>>>>>>>>
>>>>>>>>> Thanks in advance,
>>>>>>>>>
>>>>>>>>> Frank
>>>>>>>>>
>>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>
> 
>>>
>>>
>>>
>>> --
>>> Sent from Gmail for IPhone
>>
> 
> 
>


From francescobryanromano at gmail.com  Mon Oct 26 12:10:27 2015
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Mon, 26 Oct 2015 12:10:27 +0100
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <562E0939.3020904@gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
Message-ID: <CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>

Many thanks Ben,

but I tried that already:

> revanaA<-
bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data =
revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
fixed-effect model matrix is rank deficient so dropping 2 columns /
coefficients
Error in normal(cov = cov, common.scale = FALSE) :
  normal prior covariance of improper length

On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com> wrote:

> On 15-10-26 06:56 AM, Francesco Romano wrote:
> > I wonder if anyone can help with the separation problem originally solved
> > by Ben Bolker (see thread).
> > The model and fitting I used previously was
> >
> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family =
> > binomial, fixef.prior = normal(cov = diag(9,4))
> >
> > which now has to change because the Syntax.Semantcs factor needs to be
> > split into separate
> > within-subjects variables, Syntax, a factor with two levels, and
> Animacy, a
> > factor with four levels.
> > In addition a new between-subjects factor called Group with two levels
> > (native vs non-native speaker)
> > has to be added which determines the following model, fit by bglmer:
> >
> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+ (1|Part.name)+(1|Item),
> data
> > = trialglm, family = binomial,
> > fixef.prior = normal(cov = diag???)
> >
> > What values should I use for the cov=diag portion in order to continue
> > attempting convergence of a model
> > that includes the random effects?
>
>     In general a reasonable form is normal(cov = diag(v,np)) where v is
> the prior variance (generally something reasonably
> large/non-informative; 9 (=std dev of 3) is probably an OK default) and
> np is the number of fixed-effect parameters.  You can figure this out via
>
> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
>
> or multiply 2*4*2 to get 16 ...
>
> >
> > R returns the following error because I don't know how to establish the
> > parameters when more than one
> > fixed effect is involved:
> >
> > Error in normal(cov = cov, common.scale = FALSE) :
> >   normal prior covariance of improper length
> >
> > Many thanks in advance for any help!
> >
> >
> >
> >
> >
> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >
> >>   I don't see your data -- I see a little tiny subset, but that's not
> >> really enough for a reproducible example.
> >>
> >> This is the example given in the URL I sent:
> >>
> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
> >>                        family=binomial,
> >>                        fixef.prior = normal(cov = diag(9,4)))
> >>
> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
> >>           data =trialglm,
> >>          family = binomial,
> >>         fixef.prior = normal(cov=diag(9,8)))
> >>
> >> The last line specifies an 8x8 matrix (because you have 8 fixed effect
> >> parameters) with a value of 9 on the diagonal, meaning the priors for
> >> the fixed effects are independent and each is Normal with a sd of
> >> sqrt(9)=3.
> >>
> >>
> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
> >> <francescobryanromano at gmail.com> wrote:
> >>> Yes but this seems a bit above my head without your help. The data are
> in
> >>> the three variables at the bottom of my email but I forgot to mention
> the
> >>> random participant effect (n = 17). Thanks!
> >>>
> >>>
> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha scritto:
> >>>>
> > On 15-05-28 06:55 AM, Francesco Romano wrote:
> >>>>>> Many thanks to both.
> >>>>>>
> >>>>>> The approaches you suggest (and others online) help one deal with
> >>>>>> the separation problem but don't offer any specific advice as to
> >>>>>> how getting a valid p coefficient when comparing two levels of the
> >>>>>> model vexed by separation.
> >>>>>>
> >>>>>> Ben, here's the output of the bglmer which by the way would be
> >>>>>> ideal since it allows me to retain the random effect so that all my
> >>>>>> pairwise comparisons are conducted using mixed effects.
> >>>>>>
> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
> >>>>>>> trialglm,
> >>>>>> family = binomial) Warning message: package ?blme? was built under
> >>>>>> R version 3.1.2
> >>>>>>> summary(trial)
> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
> >>>>>>
> >>>>>> Generalized linear mixed model fit by maximum likelihood (Laplace
> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
> >>>>>>
> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
> >>>>>> 251.9      376
> >>>>>>
> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
> >>>>>>
> >>>>>> Random effects: Groups    Name        Variance Std.Dev. Part.name
> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:  Part.name,
> >>>>>> 16
> >>>>>>
> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323     0.7462
> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>>>>
> >>>>>> Unfortunately the separation problem is still there. Should I be
> >>>>>> constraining the parameter somehow? How would I do that? The data
> >>>>>> is below.
> >
> >    Did you read the section in the URL I suggested?  Just using bglmer
> > isn't enough; you also have to set a prior on the fixed effects.
> >
> >   Your data don't seem to be attached (note that the mailing list
> > strips most non-ASCII file types).
> >
> >>>>>>
> >>>>>> In passing I also tried brglm which solves the separation problem
> >>>>>> but tells me comparison is significant which I don't believe one
> >>>>>> bit (see the data below). I am pretty sure about this because when
> >>>>>> I reveled and look at the comparisons I was able to compute using
> >>>>>> glmer, these turn out to be non-significant, when glmer told me
> >>>>>> they were:
> >>>>>>
> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family
> >>>>>>> =
> >>>>>> binomial) Warning messages: 1: package ?elrm? was built under R
> >>>>>> version 3.1.2 2: package ?coda? was built under R version 3.1.3
> >>>>>>> summary(trial)
> >>>>>>
> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
> >>>>>> binomial, data = trialglm)
> >>>>>>
> >>>>>>
> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A   0.6689
> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 --- Signif.
> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>>>>
> >>>>>> (Dispersion parameter for binomial family taken to be 1)
> >>>>>>
> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized deviance:
> >>>>>> 245.5554 AIC:  272.22
> >>>>>>
> >>>>>>
> >>>>>> MCMCglmm is too complex for me.
> >>>>>>
> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
> >>>>>> function) but output is hard to read:
> >>>>>>
> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
> >>>>>>> family =
> >>>>>> binomial) Warning messages: 1: package ?logistf? was built under R
> >>>>>> version 3.1.2 2: package ?mice? was built under R version 3.1.2
> >>>>>>> summary(trial)
> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
> >>>>>> family = binomial)
> >>>>>>
> >>>>>> Model fitted by Penalized ML Confidence intervals and p-values by
> >>>>>> Profile Likelihood Profile Likelihood Profile Likelihood Profile
> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile Likelihood
> >>>>>> Profile Likelihood
> >>>>>>
> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p (Intercept)
> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00
> >>>>>> Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 1.000000e+00
> >>>>>> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 1.000000e+00
> >>>>>> Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
> >>>>>> 0.000000 1.000000e+00
> >>>>>>
> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
> >>>>>> 5.334321 on 7 df, p = 0.6192356
> >>>>>>
> >>>>>> In particular, what is this model telling me? That Z (my ref level)
> >>>>>> and B are significantly different?
> >>>>>>
> >>>>>> I'm happy to try the elrm function with exact logistic regression
> >>>>>> but I am not capable of programming it. Besides, would it give me
> >>>>>> valid estimates for the comparison between the Z and B levels? The
> >>>>>> data frame should look like this:
> >>>>>>
> >>>>>> Outcome variable (Correct, incorrect) Predictor variable (A, B, C,
> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
> >>>>>>
> >>>>>> Thank you! F.
> >>>>>>
> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> And for what it's worth, you can do this in conjunction with lme4
> >>>>>>> by using the blme package instead (a thin Bayesian wrapper around
> >>>>>>> lme4), or via the MCMCglmm package; see
> >>>>>>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
> >>>>>>> for an example (search for "complete separation").
> >>>>>>>
> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
> >>>>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >>>>>>>> You may need to consider using an 'exact', Bayesian, or
> >>>>>>>> penalized
> >>>>>>> likelihood approach (along the lines proposed by Firth).
> >>>>>>>>
> >>>>>>>> Maybe a place to start:
> >>>>>>>
> >>>>>>>
> >>>
> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
> >>>>>>>>
> >>>>>>>>
> >>>>>>>
> > Best,
> >>>>>>>> Wolfgang
> >>>>>>>>
> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
> >>>>>>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
> >>>>>>>>> cells in contrast matrix problem
> >>>>>>>>>
> >>>>>>>>> After giving up on a glmer for my data, I remembered a post
> >>>>>>>>> by Roger
> >>>>>>> Levy
> >>>>>>>>> suggesting to try the use non mixed effects glm when one of
> >>>>>>>>> the cells in a matrix is zero.
> >>>>>>>>>
> >>>>>>>>> To put this into perspective:
> >>>>>>>>>
> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
> >>>>>>>>>> data =
> >>>>>>>>> trialglm, family = binomial)
> >>>>>>>>>
> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to converge
> >>>>>>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
> >>>>>>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
> >>>>>>>>> control$checkConv, : Model is nearly unidentifiable: large
> >>>>>>>>> eigenvalue ratio - Rescale variables?
> >>>>>>>>>
> >>>>>>>>> My data has a binary outcome, correct or incorrect, a fixed
> >>>>>>>>> effect predictor factor with 8 levels, and a random effect
> >>>>>>>>> for participants. I believe the problem R is encountering is
> >>>>>>>>> with one level of the factor (let us call it level B) which
> >>>>>>>>> has no counts (no I won' t try to post the table from the
> >>>>>>>>> paper with the counts because I know it will get garbled
> >>>>>>>>> up!).
> >>>>>>>>>
> >>>>>>>>> I attempt a glm with the same data:
> >>>>>>>>>
> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
> >>>>>>>>>> family =
> >>>>>>>>> binomial)
> >>>>>>>>>> anova(trial)
> >>>>>>>>> Analysis of Deviance Table
> >>>>>>>>>
> >>>>>>>>> Model: binomial, link: logit
> >>>>>>>>>
> >>>>>>>>> Response: Correct
> >>>>>>>>>
> >>>>>>>>> Terms added sequentially (first to last)
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
> >>>>>>>>> 254.97
> >>>>>>>>>> summary(trial)
> >>>>>>>>>
> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
> >>>>>>>>> binomial, data = trialglm)
> >>>>>>>>>
> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
> >>>>>>>>>
> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
> >>>>>>>>> ?.? 0.1 ? ? 1
> >>>>>>>>>
> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
> >>>>>>>>>
> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom Residual
> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
> >>>>>>>>>
> >>>>>>>>> Number of Fisher Scoring iterations: 17
> >>>>>>>>>
> >>>>>>>>> The comparison I'm interested in is between level B and the
> >>>>>>>>> reference level but it cannot be estimated as shown by the
> >>>>>>>>> ridiculously high estimate and SE value.
> >>>>>>>>>
> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
> >>>>>>>>> It's the only comparison missing in the table for the levels
> >>>>>>>>> I need so I think it
> >>>>>>> would
> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the
> >>>>>>>>> difference
> >>>>>>> could
> >>>>>>>>> not be estimated due to zero count'.
> >>>>>>>>>
> >>>>>>>>> And by the way I have seen this comparison being generated
> >>>>>>>>> using other stats.
> >>>>>>>>>
> >>>>>>>>> Thanks in advance,
> >>>>>>>>>
> >>>>>>>>> Frank
> >>>>>>>>>
> >>>>>>>>> [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> _______________________________________________
> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>> _______________________________________________
> >>>>>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>
> >>>>>>
> >
> >>>
> >>>
> >>>
> >>> --
> >>> Sent from Gmail for IPhone
> >>
> >
> >
> >
>
>


-- 
Frank Romano Ph.D.

Tel. +39 3911639149

*LinkedIn*
https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162

*Academia.edu*
https://sheffield.academia.edu/FrancescoRomano

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Oct 26 12:13:05 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Oct 2015 07:13:05 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
Message-ID: <CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>

Well, that's a separate problem (and not necessarily a "problem").   R
is telling you that you have 16 separate combinations of the factors,
but only 14 unique combinations represented in your data set, so it
can only estimate 14 parameters.  Unless there is a weird interaction
with blme I don't know about, this should still give you reasonable
answers.

On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano
<francescobryanromano at gmail.com> wrote:
> Many thanks Ben,
>
> but I tried that already:
>
>> revanaA<-
>> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data =
>> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
> fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> Error in normal(cov = cov, common.scale = FALSE) :
>   normal prior covariance of improper length
>
> On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> On 15-10-26 06:56 AM, Francesco Romano wrote:
>> > I wonder if anyone can help with the separation problem originally
>> > solved
>> > by Ben Bolker (see thread).
>> > The model and fitting I used previously was
>> >
>> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family =
>> > binomial, fixef.prior = normal(cov = diag(9,4))
>> >
>> > which now has to change because the Syntax.Semantcs factor needs to be
>> > split into separate
>> > within-subjects variables, Syntax, a factor with two levels, and
>> > Animacy, a
>> > factor with four levels.
>> > In addition a new between-subjects factor called Group with two levels
>> > (native vs non-native speaker)
>> > has to be added which determines the following model, fit by bglmer:
>> >
>> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+ (1|Part.name)+(1|Item),
>> > data
>> > = trialglm, family = binomial,
>> > fixef.prior = normal(cov = diag???)
>> >
>> > What values should I use for the cov=diag portion in order to continue
>> > attempting convergence of a model
>> > that includes the random effects?
>>
>>     In general a reasonable form is normal(cov = diag(v,np)) where v is
>> the prior variance (generally something reasonably
>> large/non-informative; 9 (=std dev of 3) is probably an OK default) and
>> np is the number of fixed-effect parameters.  You can figure this out via
>>
>> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
>>
>> or multiply 2*4*2 to get 16 ...
>>
>> >
>> > R returns the following error because I don't know how to establish the
>> > parameters when more than one
>> > fixed effect is involved:
>> >
>> > Error in normal(cov = cov, common.scale = FALSE) :
>> >   normal prior covariance of improper length
>> >
>> > Many thanks in advance for any help!
>> >
>> >
>> >
>> >
>> >
>> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> >
>> >>   I don't see your data -- I see a little tiny subset, but that's not
>> >> really enough for a reproducible example.
>> >>
>> >> This is the example given in the URL I sent:
>> >>
>> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
>> >>                        family=binomial,
>> >>                        fixef.prior = normal(cov = diag(9,4)))
>> >>
>> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>> >>           data =trialglm,
>> >>          family = binomial,
>> >>         fixef.prior = normal(cov=diag(9,8)))
>> >>
>> >> The last line specifies an 8x8 matrix (because you have 8 fixed effect
>> >> parameters) with a value of 9 on the diagonal, meaning the priors for
>> >> the fixed effects are independent and each is Normal with a sd of
>> >> sqrt(9)=3.
>> >>
>> >>
>> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
>> >> <francescobryanromano at gmail.com> wrote:
>> >>> Yes but this seems a bit above my head without your help. The data are
>> >>> in
>> >>> the three variables at the bottom of my email but I forgot to mention
>> >>> the
>> >>> random participant effect (n = 17). Thanks!
>> >>>
>> >>>
>> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha scritto:
>> >>>>
>> > On 15-05-28 06:55 AM, Francesco Romano wrote:
>> >>>>>> Many thanks to both.
>> >>>>>>
>> >>>>>> The approaches you suggest (and others online) help one deal with
>> >>>>>> the separation problem but don't offer any specific advice as to
>> >>>>>> how getting a valid p coefficient when comparing two levels of the
>> >>>>>> model vexed by separation.
>> >>>>>>
>> >>>>>> Ben, here's the output of the bglmer which by the way would be
>> >>>>>> ideal since it allows me to retain the random effect so that all my
>> >>>>>> pairwise comparisons are conducted using mixed effects.
>> >>>>>>
>> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
>> >>>>>>> trialglm,
>> >>>>>> family = binomial) Warning message: package ?blme? was built under
>> >>>>>> R version 3.1.2
>> >>>>>>> summary(trial)
>> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
>> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
>> >>>>>>
>> >>>>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
>> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
>> >>>>>>
>> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
>> >>>>>> 251.9      376
>> >>>>>>
>> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
>> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
>> >>>>>>
>> >>>>>> Random effects: Groups    Name        Variance Std.Dev. Part.name
>> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:  Part.name,
>> >>>>>> 16
>> >>>>>>
>> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
>> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
>> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323     0.7462
>> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
>> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
>> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
>> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
>> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >>>>>>
>> >>>>>> Unfortunately the separation problem is still there. Should I be
>> >>>>>> constraining the parameter somehow? How would I do that? The data
>> >>>>>> is below.
>> >
>> >    Did you read the section in the URL I suggested?  Just using bglmer
>> > isn't enough; you also have to set a prior on the fixed effects.
>> >
>> >   Your data don't seem to be attached (note that the mailing list
>> > strips most non-ASCII file types).
>> >
>> >>>>>>
>> >>>>>> In passing I also tried brglm which solves the separation problem
>> >>>>>> but tells me comparison is significant which I don't believe one
>> >>>>>> bit (see the data below). I am pretty sure about this because when
>> >>>>>> I reveled and look at the comparisons I was able to compute using
>> >>>>>> glmer, these turn out to be non-significant, when glmer told me
>> >>>>>> they were:
>> >>>>>>
>> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family
>> >>>>>>> =
>> >>>>>> binomial) Warning messages: 1: package ?elrm? was built under R
>> >>>>>> version 3.1.2 2: package ?coda? was built under R version 3.1.3
>> >>>>>>> summary(trial)
>> >>>>>>
>> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
>> >>>>>> binomial, data = trialglm)
>> >>>>>>
>> >>>>>>
>> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A   0.6689
>> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
>> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
>> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
>> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
>> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
>> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 --- Signif.
>> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >>>>>>
>> >>>>>> (Dispersion parameter for binomial family taken to be 1)
>> >>>>>>
>> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
>> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized deviance:
>> >>>>>> 245.5554 AIC:  272.22
>> >>>>>>
>> >>>>>>
>> >>>>>> MCMCglmm is too complex for me.
>> >>>>>>
>> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
>> >>>>>> function) but output is hard to read:
>> >>>>>>
>> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>> >>>>>>> family =
>> >>>>>> binomial) Warning messages: 1: package ?logistf? was built under R
>> >>>>>> version 3.1.2 2: package ?mice? was built under R version 3.1.2
>> >>>>>>> summary(trial)
>> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
>> >>>>>> family = binomial)
>> >>>>>>
>> >>>>>> Model fitted by Penalized ML Confidence intervals and p-values by
>> >>>>>> Profile Likelihood Profile Likelihood Profile Likelihood Profile
>> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile Likelihood
>> >>>>>> Profile Likelihood
>> >>>>>>
>> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p (Intercept)
>> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00
>> >>>>>> Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
>> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
>> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
>> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 1.000000e+00
>> >>>>>> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
>> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
>> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
>> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 1.000000e+00
>> >>>>>> Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
>> >>>>>> 0.000000 1.000000e+00
>> >>>>>>
>> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
>> >>>>>> 5.334321 on 7 df, p = 0.6192356
>> >>>>>>
>> >>>>>> In particular, what is this model telling me? That Z (my ref level)
>> >>>>>> and B are significantly different?
>> >>>>>>
>> >>>>>> I'm happy to try the elrm function with exact logistic regression
>> >>>>>> but I am not capable of programming it. Besides, would it give me
>> >>>>>> valid estimates for the comparison between the Z and B levels? The
>> >>>>>> data frame should look like this:
>> >>>>>>
>> >>>>>> Outcome variable (Correct, incorrect) Predictor variable (A, B, C,
>> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
>> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
>> >>>>>>
>> >>>>>> Thank you! F.
>> >>>>>>
>> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
>> >>>>>> wrote:
>> >>>>>>
>> >>>>>>> And for what it's worth, you can do this in conjunction with lme4
>> >>>>>>> by using the blme package instead (a thin Bayesian wrapper around
>> >>>>>>> lme4), or via the MCMCglmm package; see
>> >>>>>>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>> >>>>>>> for an example (search for "complete separation").
>> >>>>>>>
>> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
>> >>>>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >>>>>>>> You may need to consider using an 'exact', Bayesian, or
>> >>>>>>>> penalized
>> >>>>>>> likelihood approach (along the lines proposed by Firth).
>> >>>>>>>>
>> >>>>>>>> Maybe a place to start:
>> >>>>>>>
>> >>>>>>>
>> >>>
>> >>> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>
>> > Best,
>> >>>>>>>> Wolfgang
>> >>>>>>>>
>> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
>> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
>> >>>>>>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
>> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>> >>>>>>>>> cells in contrast matrix problem
>> >>>>>>>>>
>> >>>>>>>>> After giving up on a glmer for my data, I remembered a post
>> >>>>>>>>> by Roger
>> >>>>>>> Levy
>> >>>>>>>>> suggesting to try the use non mixed effects glm when one of
>> >>>>>>>>> the cells in a matrix is zero.
>> >>>>>>>>>
>> >>>>>>>>> To put this into perspective:
>> >>>>>>>>>
>> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
>> >>>>>>>>>> data =
>> >>>>>>>>> trialglm, family = binomial)
>> >>>>>>>>>
>> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to converge
>> >>>>>>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
>> >>>>>>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> >>>>>>>>> control$checkConv, : Model is nearly unidentifiable: large
>> >>>>>>>>> eigenvalue ratio - Rescale variables?
>> >>>>>>>>>
>> >>>>>>>>> My data has a binary outcome, correct or incorrect, a fixed
>> >>>>>>>>> effect predictor factor with 8 levels, and a random effect
>> >>>>>>>>> for participants. I believe the problem R is encountering is
>> >>>>>>>>> with one level of the factor (let us call it level B) which
>> >>>>>>>>> has no counts (no I won' t try to post the table from the
>> >>>>>>>>> paper with the counts because I know it will get garbled
>> >>>>>>>>> up!).
>> >>>>>>>>>
>> >>>>>>>>> I attempt a glm with the same data:
>> >>>>>>>>>
>> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>> >>>>>>>>>> family =
>> >>>>>>>>> binomial)
>> >>>>>>>>>> anova(trial)
>> >>>>>>>>> Analysis of Deviance Table
>> >>>>>>>>>
>> >>>>>>>>> Model: binomial, link: logit
>> >>>>>>>>>
>> >>>>>>>>> Response: Correct
>> >>>>>>>>>
>> >>>>>>>>> Terms added sequentially (first to last)
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
>> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
>> >>>>>>>>> 254.97
>> >>>>>>>>>> summary(trial)
>> >>>>>>>>>
>> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>> >>>>>>>>> binomial, data = trialglm)
>> >>>>>>>>>
>> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
>> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>> >>>>>>>>>
>> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
>> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
>> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
>> >>>>>>>>> ?.? 0.1 ? ? 1
>> >>>>>>>>>
>> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
>> >>>>>>>>>
>> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom Residual
>> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>> >>>>>>>>>
>> >>>>>>>>> Number of Fisher Scoring iterations: 17
>> >>>>>>>>>
>> >>>>>>>>> The comparison I'm interested in is between level B and the
>> >>>>>>>>> reference level but it cannot be estimated as shown by the
>> >>>>>>>>> ridiculously high estimate and SE value.
>> >>>>>>>>>
>> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
>> >>>>>>>>> It's the only comparison missing in the table for the levels
>> >>>>>>>>> I need so I think it
>> >>>>>>> would
>> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the
>> >>>>>>>>> difference
>> >>>>>>> could
>> >>>>>>>>> not be estimated due to zero count'.
>> >>>>>>>>>
>> >>>>>>>>> And by the way I have seen this comparison being generated
>> >>>>>>>>> using other stats.
>> >>>>>>>>>
>> >>>>>>>>> Thanks in advance,
>> >>>>>>>>>
>> >>>>>>>>> Frank
>> >>>>>>>>>
>> >>>>>>>>> [[alternative HTML version deleted]]
>> >>>>>>>>>
>> >>>>>>>>> _______________________________________________
>> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>>> _______________________________________________
>> >>>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>>
>> >>>>>>
>> >
>> >>>
>> >>>
>> >>>
>> >>> --
>> >>> Sent from Gmail for IPhone
>> >>
>> >
>> >
>> >
>>
>
>
>
> --
> Frank Romano Ph.D.
>
> Tel. +39 3911639149
>
> LinkedIn
> https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>
> Academia.edu
> https://sheffield.academia.edu/FrancescoRomano


From francescobryanromano at gmail.com  Mon Oct 26 12:18:02 2015
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Mon, 26 Oct 2015 12:18:02 +0100
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
	<CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
Message-ID: <CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>

For some reason the silly bugger didn't past the full command:

> revanaA<-
bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data =
revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
fixed-effect model matrix is rank deficient so dropping 2 columns /
coefficients
Error in normal(cov = cov, common.scale = FALSE) :
  normal prior covariance of improper length

To give more info on this, it is the Animacy factor that is causing
separation because two levels of it have zero counts in some cases.

On Mon, Oct 26, 2015 at 12:13 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Well, that's a separate problem (and not necessarily a "problem").   R
> is telling you that you have 16 separate combinations of the factors,
> but only 14 unique combinations represented in your data set, so it
> can only estimate 14 parameters.  Unless there is a weird interaction
> with blme I don't know about, this should still give you reasonable
> answers.
>
> On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano
> <francescobryanromano at gmail.com> wrote:
> > Many thanks Ben,
> >
> > but I tried that already:
> >
> >> revanaA<-
> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data
> =
> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> > coefficients
> > Error in normal(cov = cov, common.scale = FALSE) :
> >   normal prior covariance of improper length
> >
> > On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >> On 15-10-26 06:56 AM, Francesco Romano wrote:
> >> > I wonder if anyone can help with the separation problem originally
> >> > solved
> >> > by Ben Bolker (see thread).
> >> > The model and fitting I used previously was
> >> >
> >> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family =
> >> > binomial, fixef.prior = normal(cov = diag(9,4))
> >> >
> >> > which now has to change because the Syntax.Semantcs factor needs to be
> >> > split into separate
> >> > within-subjects variables, Syntax, a factor with two levels, and
> >> > Animacy, a
> >> > factor with four levels.
> >> > In addition a new between-subjects factor called Group with two levels
> >> > (native vs non-native speaker)
> >> > has to be added which determines the following model, fit by bglmer:
> >> >
> >> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+ (1|Part.name)+(1|Item),
> >> > data
> >> > = trialglm, family = binomial,
> >> > fixef.prior = normal(cov = diag???)
> >> >
> >> > What values should I use for the cov=diag portion in order to continue
> >> > attempting convergence of a model
> >> > that includes the random effects?
> >>
> >>     In general a reasonable form is normal(cov = diag(v,np)) where v is
> >> the prior variance (generally something reasonably
> >> large/non-informative; 9 (=std dev of 3) is probably an OK default) and
> >> np is the number of fixed-effect parameters.  You can figure this out
> via
> >>
> >> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
> >>
> >> or multiply 2*4*2 to get 16 ...
> >>
> >> >
> >> > R returns the following error because I don't know how to establish
> the
> >> > parameters when more than one
> >> > fixed effect is involved:
> >> >
> >> > Error in normal(cov = cov, common.scale = FALSE) :
> >> >   normal prior covariance of improper length
> >> >
> >> > Many thanks in advance for any help!
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com>
> wrote:
> >> >
> >> >>   I don't see your data -- I see a little tiny subset, but that's not
> >> >> really enough for a reproducible example.
> >> >>
> >> >> This is the example given in the URL I sent:
> >> >>
> >> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
> >> >>                        family=binomial,
> >> >>                        fixef.prior = normal(cov = diag(9,4)))
> >> >>
> >> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
> >> >>           data =trialglm,
> >> >>          family = binomial,
> >> >>         fixef.prior = normal(cov=diag(9,8)))
> >> >>
> >> >> The last line specifies an 8x8 matrix (because you have 8 fixed
> effect
> >> >> parameters) with a value of 9 on the diagonal, meaning the priors for
> >> >> the fixed effects are independent and each is Normal with a sd of
> >> >> sqrt(9)=3.
> >> >>
> >> >>
> >> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
> >> >> <francescobryanromano at gmail.com> wrote:
> >> >>> Yes but this seems a bit above my head without your help. The data
> are
> >> >>> in
> >> >>> the three variables at the bottom of my email but I forgot to
> mention
> >> >>> the
> >> >>> random participant effect (n = 17). Thanks!
> >> >>>
> >> >>>
> >> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha
> scritto:
> >> >>>>
> >> > On 15-05-28 06:55 AM, Francesco Romano wrote:
> >> >>>>>> Many thanks to both.
> >> >>>>>>
> >> >>>>>> The approaches you suggest (and others online) help one deal with
> >> >>>>>> the separation problem but don't offer any specific advice as to
> >> >>>>>> how getting a valid p coefficient when comparing two levels of
> the
> >> >>>>>> model vexed by separation.
> >> >>>>>>
> >> >>>>>> Ben, here's the output of the bglmer which by the way would be
> >> >>>>>> ideal since it allows me to retain the random effect so that all
> my
> >> >>>>>> pairwise comparisons are conducted using mixed effects.
> >> >>>>>>
> >> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
> >> >>>>>>> trialglm,
> >> >>>>>> family = binomial) Warning message: package ?blme? was built
> under
> >> >>>>>> R version 3.1.2
> >> >>>>>>> summary(trial)
> >> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
> >> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
> >> >>>>>>
> >> >>>>>> Generalized linear mixed model fit by maximum likelihood (Laplace
> >> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
> >> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
> >> >>>>>>
> >> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
> >> >>>>>> 251.9      376
> >> >>>>>>
> >> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
> >> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
> >> >>>>>>
> >> >>>>>> Random effects: Groups    Name        Variance Std.Dev. Part.name
> >> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:
> Part.name,
> >> >>>>>> 16
> >> >>>>>>
> >> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
> >> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
> >> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323
>  0.7462
> >> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
> >> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
> >> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
> >> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
> >> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >>>>>>
> >> >>>>>> Unfortunately the separation problem is still there. Should I be
> >> >>>>>> constraining the parameter somehow? How would I do that? The data
> >> >>>>>> is below.
> >> >
> >> >    Did you read the section in the URL I suggested?  Just using bglmer
> >> > isn't enough; you also have to set a prior on the fixed effects.
> >> >
> >> >   Your data don't seem to be attached (note that the mailing list
> >> > strips most non-ASCII file types).
> >> >
> >> >>>>>>
> >> >>>>>> In passing I also tried brglm which solves the separation problem
> >> >>>>>> but tells me comparison is significant which I don't believe one
> >> >>>>>> bit (see the data below). I am pretty sure about this because
> when
> >> >>>>>> I reveled and look at the comparisons I was able to compute using
> >> >>>>>> glmer, these turn out to be non-significant, when glmer told me
> >> >>>>>> they were:
> >> >>>>>>
> >> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family
> >> >>>>>>> =
> >> >>>>>> binomial) Warning messages: 1: package ?elrm? was built under R
> >> >>>>>> version 3.1.2 2: package ?coda? was built under R version 3.1.3
> >> >>>>>>> summary(trial)
> >> >>>>>>
> >> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
> >> >>>>>> binomial, data = trialglm)
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A
>  0.6689
> >> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
> >> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
> >> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
> >> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
> >> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
> >> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 ---
> Signif.
> >> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >>>>>>
> >> >>>>>> (Dispersion parameter for binomial family taken to be 1)
> >> >>>>>>
> >> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
> >> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized deviance:
> >> >>>>>> 245.5554 AIC:  272.22
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> MCMCglmm is too complex for me.
> >> >>>>>>
> >> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
> >> >>>>>> function) but output is hard to read:
> >> >>>>>>
> >> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
> >> >>>>>>> family =
> >> >>>>>> binomial) Warning messages: 1: package ?logistf? was built under
> R
> >> >>>>>> version 3.1.2 2: package ?mice? was built under R version 3.1.2
> >> >>>>>>> summary(trial)
> >> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
> >> >>>>>> family = binomial)
> >> >>>>>>
> >> >>>>>> Model fitted by Penalized ML Confidence intervals and p-values by
> >> >>>>>> Profile Likelihood Profile Likelihood Profile Likelihood Profile
> >> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile
> Likelihood
> >> >>>>>> Profile Likelihood
> >> >>>>>>
> >> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p
> (Intercept)
> >> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00
> >> >>>>>> Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
> >> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
> >> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
> >> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 1.000000e+00
> >> >>>>>> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
> >> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
> >> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
> >> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 1.000000e+00
> >> >>>>>> Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
> >> >>>>>> 0.000000 1.000000e+00
> >> >>>>>>
> >> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
> >> >>>>>> 5.334321 on 7 df, p = 0.6192356
> >> >>>>>>
> >> >>>>>> In particular, what is this model telling me? That Z (my ref
> level)
> >> >>>>>> and B are significantly different?
> >> >>>>>>
> >> >>>>>> I'm happy to try the elrm function with exact logistic regression
> >> >>>>>> but I am not capable of programming it. Besides, would it give me
> >> >>>>>> valid estimates for the comparison between the Z and B levels?
> The
> >> >>>>>> data frame should look like this:
> >> >>>>>>
> >> >>>>>> Outcome variable (Correct, incorrect) Predictor variable (A, B,
> C,
> >> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
> >> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
> >> >>>>>>
> >> >>>>>> Thank you! F.
> >> >>>>>>
> >> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
> >> >>>>>> wrote:
> >> >>>>>>
> >> >>>>>>> And for what it's worth, you can do this in conjunction with
> lme4
> >> >>>>>>> by using the blme package instead (a thin Bayesian wrapper
> around
> >> >>>>>>> lme4), or via the MCMCglmm package; see
> >> >>>>>>>
> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
> >> >>>>>>> for an example (search for "complete separation").
> >> >>>>>>>
> >> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
> >> >>>>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >> >>>>>>>> You may need to consider using an 'exact', Bayesian, or
> >> >>>>>>>> penalized
> >> >>>>>>> likelihood approach (along the lines proposed by Firth).
> >> >>>>>>>>
> >> >>>>>>>> Maybe a place to start:
> >> >>>>>>>
> >> >>>>>>>
> >> >>>
> >> >>>
> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>
> >> > Best,
> >> >>>>>>>> Wolfgang
> >> >>>>>>>>
> >> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
> >> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
> >> >>>>>>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
> >> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
> >> >>>>>>>>> cells in contrast matrix problem
> >> >>>>>>>>>
> >> >>>>>>>>> After giving up on a glmer for my data, I remembered a post
> >> >>>>>>>>> by Roger
> >> >>>>>>> Levy
> >> >>>>>>>>> suggesting to try the use non mixed effects glm when one of
> >> >>>>>>>>> the cells in a matrix is zero.
> >> >>>>>>>>>
> >> >>>>>>>>> To put this into perspective:
> >> >>>>>>>>>
> >> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
> >> >>>>>>>>>> data =
> >> >>>>>>>>> trialglm, family = binomial)
> >> >>>>>>>>>
> >> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to converge
> >> >>>>>>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
> >> >>>>>>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
> >> >>>>>>>>> control$checkConv, : Model is nearly unidentifiable: large
> >> >>>>>>>>> eigenvalue ratio - Rescale variables?
> >> >>>>>>>>>
> >> >>>>>>>>> My data has a binary outcome, correct or incorrect, a fixed
> >> >>>>>>>>> effect predictor factor with 8 levels, and a random effect
> >> >>>>>>>>> for participants. I believe the problem R is encountering is
> >> >>>>>>>>> with one level of the factor (let us call it level B) which
> >> >>>>>>>>> has no counts (no I won' t try to post the table from the
> >> >>>>>>>>> paper with the counts because I know it will get garbled
> >> >>>>>>>>> up!).
> >> >>>>>>>>>
> >> >>>>>>>>> I attempt a glm with the same data:
> >> >>>>>>>>>
> >> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
> >> >>>>>>>>>> family =
> >> >>>>>>>>> binomial)
> >> >>>>>>>>>> anova(trial)
> >> >>>>>>>>> Analysis of Deviance Table
> >> >>>>>>>>>
> >> >>>>>>>>> Model: binomial, link: logit
> >> >>>>>>>>>
> >> >>>>>>>>> Response: Correct
> >> >>>>>>>>>
> >> >>>>>>>>> Terms added sequentially (first to last)
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
> >> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
> >> >>>>>>>>> 254.97
> >> >>>>>>>>>> summary(trial)
> >> >>>>>>>>>
> >> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
> >> >>>>>>>>> binomial, data = trialglm)
> >> >>>>>>>>>
> >> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
> >> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
> >> >>>>>>>>>
> >> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
> >> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
> >> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
> >> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
> >> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
> >> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
> >> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
> >> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
> >> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
> >> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
> >> >>>>>>>>> ?.? 0.1 ? ? 1
> >> >>>>>>>>>
> >> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
> >> >>>>>>>>>
> >> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom Residual
> >> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
> >> >>>>>>>>>
> >> >>>>>>>>> Number of Fisher Scoring iterations: 17
> >> >>>>>>>>>
> >> >>>>>>>>> The comparison I'm interested in is between level B and the
> >> >>>>>>>>> reference level but it cannot be estimated as shown by the
> >> >>>>>>>>> ridiculously high estimate and SE value.
> >> >>>>>>>>>
> >> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
> >> >>>>>>>>> It's the only comparison missing in the table for the levels
> >> >>>>>>>>> I need so I think it
> >> >>>>>>> would
> >> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the
> >> >>>>>>>>> difference
> >> >>>>>>> could
> >> >>>>>>>>> not be estimated due to zero count'.
> >> >>>>>>>>>
> >> >>>>>>>>> And by the way I have seen this comparison being generated
> >> >>>>>>>>> using other stats.
> >> >>>>>>>>>
> >> >>>>>>>>> Thanks in advance,
> >> >>>>>>>>>
> >> >>>>>>>>> Frank
> >> >>>>>>>>>
> >> >>>>>>>>> [[alternative HTML version deleted]]
> >> >>>>>>>>>
> >> >>>>>>>>> _______________________________________________
> >> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list
> >> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>>>>>>> _______________________________________________
> >> >>>>>>>> R-sig-mixed-models at r-project.org mailing list
> >> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>>>>>>
> >> >>>>>>
> >> >
> >> >>>
> >> >>>
> >> >>>
> >> >>> --
> >> >>> Sent from Gmail for IPhone
> >> >>
> >> >
> >> >
> >> >
> >>
> >
> >
> >
> > --
> > Frank Romano Ph.D.
> >
> > Tel. +39 3911639149
> >
> > LinkedIn
> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
> >
> > Academia.edu
> > https://sheffield.academia.edu/FrancescoRomano
>



-- 
Frank Romano Ph.D.

Tel. +39 3911639149

*LinkedIn*
https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162

*Academia.edu*
https://sheffield.academia.edu/FrancescoRomano

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Oct 26 12:25:56 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Oct 2015 07:25:56 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
	<CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
	<CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
Message-ID: <CABghstT4xrrh83+9GGfVfYC2hEgca5uQen2+z0HMqZUtJwRoJw@mail.gmail.com>

Ah.  So try normal(cov=diag(9,14)) ...

On Mon, Oct 26, 2015 at 7:18 AM, Francesco Romano
<francescobryanromano at gmail.com> wrote:
> For some reason the silly bugger didn't past the full command:
>
>> revanaA<-
>> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data =
>> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
> fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> Error in normal(cov = cov, common.scale = FALSE) :
>   normal prior covariance of improper length
>
> To give more info on this, it is the Animacy factor that is causing
> separation because two levels of it have zero counts in some cases.
>
> On Mon, Oct 26, 2015 at 12:13 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> Well, that's a separate problem (and not necessarily a "problem").   R
>> is telling you that you have 16 separate combinations of the factors,
>> but only 14 unique combinations represented in your data set, so it
>> can only estimate 14 parameters.  Unless there is a weird interaction
>> with blme I don't know about, this should still give you reasonable
>> answers.
>>
>> On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano
>> <francescobryanromano at gmail.com> wrote:
>> > Many thanks Ben,
>> >
>> > but I tried that already:
>> >
>> >> revanaA<-
>> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data
>> >> =
>> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
>> > fixed-effect model matrix is rank deficient so dropping 2 columns /
>> > coefficients
>> > Error in normal(cov = cov, common.scale = FALSE) :
>> >   normal prior covariance of improper length
>> >
>> > On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> >>
>> >> On 15-10-26 06:56 AM, Francesco Romano wrote:
>> >> > I wonder if anyone can help with the separation problem originally
>> >> > solved
>> >> > by Ben Bolker (see thread).
>> >> > The model and fitting I used previously was
>> >> >
>> >> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family =
>> >> > binomial, fixef.prior = normal(cov = diag(9,4))
>> >> >
>> >> > which now has to change because the Syntax.Semantcs factor needs to
>> >> > be
>> >> > split into separate
>> >> > within-subjects variables, Syntax, a factor with two levels, and
>> >> > Animacy, a
>> >> > factor with four levels.
>> >> > In addition a new between-subjects factor called Group with two
>> >> > levels
>> >> > (native vs non-native speaker)
>> >> > has to be added which determines the following model, fit by bglmer:
>> >> >
>> >> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+ (1|Part.name)+(1|Item),
>> >> > data
>> >> > = trialglm, family = binomial,
>> >> > fixef.prior = normal(cov = diag???)
>> >> >
>> >> > What values should I use for the cov=diag portion in order to
>> >> > continue
>> >> > attempting convergence of a model
>> >> > that includes the random effects?
>> >>
>> >>     In general a reasonable form is normal(cov = diag(v,np)) where v is
>> >> the prior variance (generally something reasonably
>> >> large/non-informative; 9 (=std dev of 3) is probably an OK default) and
>> >> np is the number of fixed-effect parameters.  You can figure this out
>> >> via
>> >>
>> >> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
>> >>
>> >> or multiply 2*4*2 to get 16 ...
>> >>
>> >> >
>> >> > R returns the following error because I don't know how to establish
>> >> > the
>> >> > parameters when more than one
>> >> > fixed effect is involved:
>> >> >
>> >> > Error in normal(cov = cov, common.scale = FALSE) :
>> >> >   normal prior covariance of improper length
>> >> >
>> >> > Many thanks in advance for any help!
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com>
>> >> > wrote:
>> >> >
>> >> >>   I don't see your data -- I see a little tiny subset, but that's
>> >> >> not
>> >> >> really enough for a reproducible example.
>> >> >>
>> >> >> This is the example given in the URL I sent:
>> >> >>
>> >> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
>> >> >>                        family=binomial,
>> >> >>                        fixef.prior = normal(cov = diag(9,4)))
>> >> >>
>> >> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>> >> >>           data =trialglm,
>> >> >>          family = binomial,
>> >> >>         fixef.prior = normal(cov=diag(9,8)))
>> >> >>
>> >> >> The last line specifies an 8x8 matrix (because you have 8 fixed
>> >> >> effect
>> >> >> parameters) with a value of 9 on the diagonal, meaning the priors
>> >> >> for
>> >> >> the fixed effects are independent and each is Normal with a sd of
>> >> >> sqrt(9)=3.
>> >> >>
>> >> >>
>> >> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
>> >> >> <francescobryanromano at gmail.com> wrote:
>> >> >>> Yes but this seems a bit above my head without your help. The data
>> >> >>> are
>> >> >>> in
>> >> >>> the three variables at the bottom of my email but I forgot to
>> >> >>> mention
>> >> >>> the
>> >> >>> random participant effect (n = 17). Thanks!
>> >> >>>
>> >> >>>
>> >> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha
>> >> >>> scritto:
>> >> >>>>
>> >> > On 15-05-28 06:55 AM, Francesco Romano wrote:
>> >> >>>>>> Many thanks to both.
>> >> >>>>>>
>> >> >>>>>> The approaches you suggest (and others online) help one deal
>> >> >>>>>> with
>> >> >>>>>> the separation problem but don't offer any specific advice as to
>> >> >>>>>> how getting a valid p coefficient when comparing two levels of
>> >> >>>>>> the
>> >> >>>>>> model vexed by separation.
>> >> >>>>>>
>> >> >>>>>> Ben, here's the output of the bglmer which by the way would be
>> >> >>>>>> ideal since it allows me to retain the random effect so that all
>> >> >>>>>> my
>> >> >>>>>> pairwise comparisons are conducted using mixed effects.
>> >> >>>>>>
>> >> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
>> >> >>>>>>> trialglm,
>> >> >>>>>> family = binomial) Warning message: package ?blme? was built
>> >> >>>>>> under
>> >> >>>>>> R version 3.1.2
>> >> >>>>>>> summary(trial)
>> >> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
>> >> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
>> >> >>>>>>
>> >> >>>>>> Generalized linear mixed model fit by maximum likelihood
>> >> >>>>>> (Laplace
>> >> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit )
>> >> >>>>>> Formula:
>> >> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
>> >> >>>>>>
>> >> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
>> >> >>>>>> 251.9      376
>> >> >>>>>>
>> >> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
>> >> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
>> >> >>>>>>
>> >> >>>>>> Random effects: Groups    Name        Variance Std.Dev.
>> >> >>>>>> Part.name
>> >> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:
>> >> >>>>>> Part.name,
>> >> >>>>>> 16
>> >> >>>>>>
>> >> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> >> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
>> >> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
>> >> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323
>> >> >>>>>> 0.7462
>> >> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
>> >> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
>> >> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
>> >> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
>> >> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >> >>>>>>
>> >> >>>>>> Unfortunately the separation problem is still there. Should I be
>> >> >>>>>> constraining the parameter somehow? How would I do that? The
>> >> >>>>>> data
>> >> >>>>>> is below.
>> >> >
>> >> >    Did you read the section in the URL I suggested?  Just using
>> >> > bglmer
>> >> > isn't enough; you also have to set a prior on the fixed effects.
>> >> >
>> >> >   Your data don't seem to be attached (note that the mailing list
>> >> > strips most non-ASCII file types).
>> >> >
>> >> >>>>>>
>> >> >>>>>> In passing I also tried brglm which solves the separation
>> >> >>>>>> problem
>> >> >>>>>> but tells me comparison is significant which I don't believe one
>> >> >>>>>> bit (see the data below). I am pretty sure about this because
>> >> >>>>>> when
>> >> >>>>>> I reveled and look at the comparisons I was able to compute
>> >> >>>>>> using
>> >> >>>>>> glmer, these turn out to be non-significant, when glmer told me
>> >> >>>>>> they were:
>> >> >>>>>>
>> >> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >>>>>>> family
>> >> >>>>>>> =
>> >> >>>>>> binomial) Warning messages: 1: package ?elrm? was built under R
>> >> >>>>>> version 3.1.2 2: package ?coda? was built under R version 3.1.3
>> >> >>>>>>> summary(trial)
>> >> >>>>>>
>> >> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
>> >> >>>>>> binomial, data = trialglm)
>> >> >>>>>>
>> >> >>>>>>
>> >> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> >> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A
>> >> >>>>>> 0.6689
>> >> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
>> >> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
>> >> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
>> >> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
>> >> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
>> >> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 ---
>> >> >>>>>> Signif.
>> >> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >> >>>>>>
>> >> >>>>>> (Dispersion parameter for binomial family taken to be 1)
>> >> >>>>>>
>> >> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
>> >> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized deviance:
>> >> >>>>>> 245.5554 AIC:  272.22
>> >> >>>>>>
>> >> >>>>>>
>> >> >>>>>> MCMCglmm is too complex for me.
>> >> >>>>>>
>> >> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
>> >> >>>>>> function) but output is hard to read:
>> >> >>>>>>
>> >> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >>>>>>> family =
>> >> >>>>>> binomial) Warning messages: 1: package ?logistf? was built under
>> >> >>>>>> R
>> >> >>>>>> version 3.1.2 2: package ?mice? was built under R version 3.1.2
>> >> >>>>>>> summary(trial)
>> >> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
>> >> >>>>>> family = binomial)
>> >> >>>>>>
>> >> >>>>>> Model fitted by Penalized ML Confidence intervals and p-values
>> >> >>>>>> by
>> >> >>>>>> Profile Likelihood Profile Likelihood Profile Likelihood Profile
>> >> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile
>> >> >>>>>> Likelihood
>> >> >>>>>> Profile Likelihood
>> >> >>>>>>
>> >> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p
>> >> >>>>>> (Intercept)
>> >> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00
>> >> >>>>>> Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
>> >> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
>> >> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
>> >> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000
>> >> >>>>>> 1.000000e+00
>> >> >>>>>> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
>> >> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
>> >> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
>> >> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000
>> >> >>>>>> 1.000000e+00
>> >> >>>>>> Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
>> >> >>>>>> 0.000000 1.000000e+00
>> >> >>>>>>
>> >> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
>> >> >>>>>> 5.334321 on 7 df, p = 0.6192356
>> >> >>>>>>
>> >> >>>>>> In particular, what is this model telling me? That Z (my ref
>> >> >>>>>> level)
>> >> >>>>>> and B are significantly different?
>> >> >>>>>>
>> >> >>>>>> I'm happy to try the elrm function with exact logistic
>> >> >>>>>> regression
>> >> >>>>>> but I am not capable of programming it. Besides, would it give
>> >> >>>>>> me
>> >> >>>>>> valid estimates for the comparison between the Z and B levels?
>> >> >>>>>> The
>> >> >>>>>> data frame should look like this:
>> >> >>>>>>
>> >> >>>>>> Outcome variable (Correct, incorrect) Predictor variable (A, B,
>> >> >>>>>> C,
>> >> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
>> >> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
>> >> >>>>>>
>> >> >>>>>> Thank you! F.
>> >> >>>>>>
>> >> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
>> >> >>>>>> wrote:
>> >> >>>>>>
>> >> >>>>>>> And for what it's worth, you can do this in conjunction with
>> >> >>>>>>> lme4
>> >> >>>>>>> by using the blme package instead (a thin Bayesian wrapper
>> >> >>>>>>> around
>> >> >>>>>>> lme4), or via the MCMCglmm package; see
>> >> >>>>>>>
>> >> >>>>>>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>> >> >>>>>>> for an example (search for "complete separation").
>> >> >>>>>>>
>> >> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
>> >> >>>>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >> >>>>>>>> You may need to consider using an 'exact', Bayesian, or
>> >> >>>>>>>> penalized
>> >> >>>>>>> likelihood approach (along the lines proposed by Firth).
>> >> >>>>>>>>
>> >> >>>>>>>> Maybe a place to start:
>> >> >>>>>>>
>> >> >>>>>>>
>> >> >>>
>> >> >>>
>> >> >>> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
>> >> >>>>>>>>
>> >> >>>>>>>>
>> >> >>>>>>>
>> >> > Best,
>> >> >>>>>>>> Wolfgang
>> >> >>>>>>>>
>> >> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
>> >> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
>> >> >>>>>>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
>> >> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>> >> >>>>>>>>> cells in contrast matrix problem
>> >> >>>>>>>>>
>> >> >>>>>>>>> After giving up on a glmer for my data, I remembered a post
>> >> >>>>>>>>> by Roger
>> >> >>>>>>> Levy
>> >> >>>>>>>>> suggesting to try the use non mixed effects glm when one of
>> >> >>>>>>>>> the cells in a matrix is zero.
>> >> >>>>>>>>>
>> >> >>>>>>>>> To put this into perspective:
>> >> >>>>>>>>>
>> >> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
>> >> >>>>>>>>>> data =
>> >> >>>>>>>>> trialglm, family = binomial)
>> >> >>>>>>>>>
>> >> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to converge
>> >> >>>>>>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
>> >> >>>>>>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> >> >>>>>>>>> control$checkConv, : Model is nearly unidentifiable: large
>> >> >>>>>>>>> eigenvalue ratio - Rescale variables?
>> >> >>>>>>>>>
>> >> >>>>>>>>> My data has a binary outcome, correct or incorrect, a fixed
>> >> >>>>>>>>> effect predictor factor with 8 levels, and a random effect
>> >> >>>>>>>>> for participants. I believe the problem R is encountering is
>> >> >>>>>>>>> with one level of the factor (let us call it level B) which
>> >> >>>>>>>>> has no counts (no I won' t try to post the table from the
>> >> >>>>>>>>> paper with the counts because I know it will get garbled
>> >> >>>>>>>>> up!).
>> >> >>>>>>>>>
>> >> >>>>>>>>> I attempt a glm with the same data:
>> >> >>>>>>>>>
>> >> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >>>>>>>>>> family =
>> >> >>>>>>>>> binomial)
>> >> >>>>>>>>>> anova(trial)
>> >> >>>>>>>>> Analysis of Deviance Table
>> >> >>>>>>>>>
>> >> >>>>>>>>> Model: binomial, link: logit
>> >> >>>>>>>>>
>> >> >>>>>>>>> Response: Correct
>> >> >>>>>>>>>
>> >> >>>>>>>>> Terms added sequentially (first to last)
>> >> >>>>>>>>>
>> >> >>>>>>>>>
>> >> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
>> >> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
>> >> >>>>>>>>> 254.97
>> >> >>>>>>>>>> summary(trial)
>> >> >>>>>>>>>
>> >> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>> >> >>>>>>>>> binomial, data = trialglm)
>> >> >>>>>>>>>
>> >> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
>> >> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>> >> >>>>>>>>>
>> >> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>> >> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
>> >> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
>> >> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>> >> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>> >> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>> >> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>> >> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>> >> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>> >> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
>> >> >>>>>>>>> ?.? 0.1 ? ? 1
>> >> >>>>>>>>>
>> >> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
>> >> >>>>>>>>>
>> >> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom Residual
>> >> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>> >> >>>>>>>>>
>> >> >>>>>>>>> Number of Fisher Scoring iterations: 17
>> >> >>>>>>>>>
>> >> >>>>>>>>> The comparison I'm interested in is between level B and the
>> >> >>>>>>>>> reference level but it cannot be estimated as shown by the
>> >> >>>>>>>>> ridiculously high estimate and SE value.
>> >> >>>>>>>>>
>> >> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
>> >> >>>>>>>>> It's the only comparison missing in the table for the levels
>> >> >>>>>>>>> I need so I think it
>> >> >>>>>>> would
>> >> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the
>> >> >>>>>>>>> difference
>> >> >>>>>>> could
>> >> >>>>>>>>> not be estimated due to zero count'.
>> >> >>>>>>>>>
>> >> >>>>>>>>> And by the way I have seen this comparison being generated
>> >> >>>>>>>>> using other stats.
>> >> >>>>>>>>>
>> >> >>>>>>>>> Thanks in advance,
>> >> >>>>>>>>>
>> >> >>>>>>>>> Frank
>> >> >>>>>>>>>
>> >> >>>>>>>>> [[alternative HTML version deleted]]
>> >> >>>>>>>>>
>> >> >>>>>>>>> _______________________________________________
>> >> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >>>>>>>> _______________________________________________
>> >> >>>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >>>>>>>
>> >> >>>>>>
>> >> >
>> >> >>>
>> >> >>>
>> >> >>>
>> >> >>> --
>> >> >>> Sent from Gmail for IPhone
>> >> >>
>> >> >
>> >> >
>> >> >
>> >>
>> >
>> >
>> >
>> > --
>> > Frank Romano Ph.D.
>> >
>> > Tel. +39 3911639149
>> >
>> > LinkedIn
>> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>> >
>> > Academia.edu
>> > https://sheffield.academia.edu/FrancescoRomano
>
>
>
>
> --
> Frank Romano Ph.D.
>
> Tel. +39 3911639149
>
> LinkedIn
> https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>
> Academia.edu
> https://sheffield.academia.edu/FrancescoRomano


From bbolker at gmail.com  Mon Oct 26 13:57:42 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Oct 2015 08:57:42 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+Er7ayibuy4Vc_D+NLCTT3sPp59FjW7WfuBos6yNd_phA@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
	<CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
	<CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
	<CABghstT4xrrh83+9GGfVfYC2hEgca5uQen2+z0HMqZUtJwRoJw@mail.gmail.com>
	<CABZN5+Er7ayibuy4Vc_D+NLCTT3sPp59FjW7WfuBos6yNd_phA@mail.gmail.com>
Message-ID: <CABghstSOrBhObh7Hp6-B=NNDvdWkLb=g16vQ+xcuqssuVT-s1g@mail.gmail.com>

at this point, if I were you I would set

options(error=recover)

and debug at the point at which the program stops: this will be at
this point in the code:

if (length(cov) == p) {
      cov <- diag(cov, p)
    } else if (length(cov) != p^2) {
      stop("normal prior covariance of improper length")
    }

so you should be able to print(p) to find out the appropriate size.


On Mon, Oct 26, 2015 at 7:37 AM, Francesco Romano
<francescobryanromano at gmail.com> wrote:
> Nope.
>
>> revanaA<-
>> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data =
>> revana, family = binomial, fixef.prior = normal(cov = diag(9,14)))
> fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> Error in normal(cov = cov, common.scale = FALSE) :
>   normal prior covariance of improper length
>
> Could it be that I need three separate priors, one for each effect?
>
> On Mon, Oct 26, 2015 at 12:25 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> Ah.  So try normal(cov=diag(9,14)) ...
>>
>> On Mon, Oct 26, 2015 at 7:18 AM, Francesco Romano
>> <francescobryanromano at gmail.com> wrote:
>> > For some reason the silly bugger didn't past the full command:
>> >
>> >> revanaA<-
>> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data
>> >> =
>> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
>> > fixed-effect model matrix is rank deficient so dropping 2 columns /
>> > coefficients
>> > Error in normal(cov = cov, common.scale = FALSE) :
>> >   normal prior covariance of improper length
>> >
>> > To give more info on this, it is the Animacy factor that is causing
>> > separation because two levels of it have zero counts in some cases.
>> >
>> > On Mon, Oct 26, 2015 at 12:13 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> >>
>> >> Well, that's a separate problem (and not necessarily a "problem").   R
>> >> is telling you that you have 16 separate combinations of the factors,
>> >> but only 14 unique combinations represented in your data set, so it
>> >> can only estimate 14 parameters.  Unless there is a weird interaction
>> >> with blme I don't know about, this should still give you reasonable
>> >> answers.
>> >>
>> >> On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano
>> >> <francescobryanromano at gmail.com> wrote:
>> >> > Many thanks Ben,
>> >> >
>> >> > but I tried that already:
>> >> >
>> >> >> revanaA<-
>> >> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item),
>> >> >> data
>> >> >> =
>> >> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
>> >> > fixed-effect model matrix is rank deficient so dropping 2 columns /
>> >> > coefficients
>> >> > Error in normal(cov = cov, common.scale = FALSE) :
>> >> >   normal prior covariance of improper length
>> >> >
>> >> > On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com>
>> >> > wrote:
>> >> >>
>> >> >> On 15-10-26 06:56 AM, Francesco Romano wrote:
>> >> >> > I wonder if anyone can help with the separation problem originally
>> >> >> > solved
>> >> >> > by Ben Bolker (see thread).
>> >> >> > The model and fitting I used previously was
>> >> >> >
>> >> >> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family
>> >> >> > =
>> >> >> > binomial, fixef.prior = normal(cov = diag(9,4))
>> >> >> >
>> >> >> > which now has to change because the Syntax.Semantcs factor needs
>> >> >> > to
>> >> >> > be
>> >> >> > split into separate
>> >> >> > within-subjects variables, Syntax, a factor with two levels, and
>> >> >> > Animacy, a
>> >> >> > factor with four levels.
>> >> >> > In addition a new between-subjects factor called Group with two
>> >> >> > levels
>> >> >> > (native vs non-native speaker)
>> >> >> > has to be added which determines the following model, fit by
>> >> >> > bglmer:
>> >> >> >
>> >> >> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+
>> >> >> > (1|Part.name)+(1|Item),
>> >> >> > data
>> >> >> > = trialglm, family = binomial,
>> >> >> > fixef.prior = normal(cov = diag???)
>> >> >> >
>> >> >> > What values should I use for the cov=diag portion in order to
>> >> >> > continue
>> >> >> > attempting convergence of a model
>> >> >> > that includes the random effects?
>> >> >>
>> >> >>     In general a reasonable form is normal(cov = diag(v,np)) where v
>> >> >> is
>> >> >> the prior variance (generally something reasonably
>> >> >> large/non-informative; 9 (=std dev of 3) is probably an OK default)
>> >> >> and
>> >> >> np is the number of fixed-effect parameters.  You can figure this
>> >> >> out
>> >> >> via
>> >> >>
>> >> >> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
>> >> >>
>> >> >> or multiply 2*4*2 to get 16 ...
>> >> >>
>> >> >> >
>> >> >> > R returns the following error because I don't know how to
>> >> >> > establish
>> >> >> > the
>> >> >> > parameters when more than one
>> >> >> > fixed effect is involved:
>> >> >> >
>> >> >> > Error in normal(cov = cov, common.scale = FALSE) :
>> >> >> >   normal prior covariance of improper length
>> >> >> >
>> >> >> > Many thanks in advance for any help!
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com>
>> >> >> > wrote:
>> >> >> >
>> >> >> >>   I don't see your data -- I see a little tiny subset, but that's
>> >> >> >> not
>> >> >> >> really enough for a reproducible example.
>> >> >> >>
>> >> >> >> This is the example given in the URL I sent:
>> >> >> >>
>> >> >> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
>> >> >> >>                        family=binomial,
>> >> >> >>                        fixef.prior = normal(cov = diag(9,4)))
>> >> >> >>
>> >> >> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>> >> >> >>           data =trialglm,
>> >> >> >>          family = binomial,
>> >> >> >>         fixef.prior = normal(cov=diag(9,8)))
>> >> >> >>
>> >> >> >> The last line specifies an 8x8 matrix (because you have 8 fixed
>> >> >> >> effect
>> >> >> >> parameters) with a value of 9 on the diagonal, meaning the priors
>> >> >> >> for
>> >> >> >> the fixed effects are independent and each is Normal with a sd of
>> >> >> >> sqrt(9)=3.
>> >> >> >>
>> >> >> >>
>> >> >> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
>> >> >> >> <francescobryanromano at gmail.com> wrote:
>> >> >> >>> Yes but this seems a bit above my head without your help. The
>> >> >> >>> data
>> >> >> >>> are
>> >> >> >>> in
>> >> >> >>> the three variables at the bottom of my email but I forgot to
>> >> >> >>> mention
>> >> >> >>> the
>> >> >> >>> random participant effect (n = 17). Thanks!
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha
>> >> >> >>> scritto:
>> >> >> >>>>
>> >> >> > On 15-05-28 06:55 AM, Francesco Romano wrote:
>> >> >> >>>>>> Many thanks to both.
>> >> >> >>>>>>
>> >> >> >>>>>> The approaches you suggest (and others online) help one deal
>> >> >> >>>>>> with
>> >> >> >>>>>> the separation problem but don't offer any specific advice as
>> >> >> >>>>>> to
>> >> >> >>>>>> how getting a valid p coefficient when comparing two levels
>> >> >> >>>>>> of
>> >> >> >>>>>> the
>> >> >> >>>>>> model vexed by separation.
>> >> >> >>>>>>
>> >> >> >>>>>> Ben, here's the output of the bglmer which by the way would
>> >> >> >>>>>> be
>> >> >> >>>>>> ideal since it allows me to retain the random effect so that
>> >> >> >>>>>> all
>> >> >> >>>>>> my
>> >> >> >>>>>> pairwise comparisons are conducted using mixed effects.
>> >> >> >>>>>>
>> >> >> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data
>> >> >> >>>>>>> =
>> >> >> >>>>>>> trialglm,
>> >> >> >>>>>> family = binomial) Warning message: package ?blme? was built
>> >> >> >>>>>> under
>> >> >> >>>>>> R version 3.1.2
>> >> >> >>>>>>> summary(trial)
>> >> >> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
>> >> >> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  :
>> >> >> >>>>>> 1.4371
>> >> >> >>>>>>
>> >> >> >>>>>> Generalized linear mixed model fit by maximum likelihood
>> >> >> >>>>>> (Laplace
>> >> >> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit )
>> >> >> >>>>>> Formula:
>> >> >> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
>> >> >> >>>>>>
>> >> >> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5
>> >> >> >>>>>> -126.0
>> >> >> >>>>>> 251.9      376
>> >> >> >>>>>>
>> >> >> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
>> >> >> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
>> >> >> >>>>>>
>> >> >> >>>>>> Random effects: Groups    Name        Variance Std.Dev.
>> >> >> >>>>>> Part.name
>> >> >> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:
>> >> >> >>>>>> Part.name,
>> >> >> >>>>>> 16
>> >> >> >>>>>>
>> >> >> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>> >> >> >>>>>> (Intercept)
>> >> >> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
>> >> >> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B
>> >> >> >>>>>> -16.4391
>> >> >> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323
>> >> >> >>>>>> 0.7462
>> >> >> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853
>> >> >> >>>>>> 0.306
>> >> >> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076
>> >> >> >>>>>> 0.2819
>> >> >> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
>> >> >> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
>> >> >> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
>> >> >> >>>>>> 1
>> >> >> >>>>>>
>> >> >> >>>>>> Unfortunately the separation problem is still there. Should I
>> >> >> >>>>>> be
>> >> >> >>>>>> constraining the parameter somehow? How would I do that? The
>> >> >> >>>>>> data
>> >> >> >>>>>> is below.
>> >> >> >
>> >> >> >    Did you read the section in the URL I suggested?  Just using
>> >> >> > bglmer
>> >> >> > isn't enough; you also have to set a prior on the fixed effects.
>> >> >> >
>> >> >> >   Your data don't seem to be attached (note that the mailing list
>> >> >> > strips most non-ASCII file types).
>> >> >> >
>> >> >> >>>>>>
>> >> >> >>>>>> In passing I also tried brglm which solves the separation
>> >> >> >>>>>> problem
>> >> >> >>>>>> but tells me comparison is significant which I don't believe
>> >> >> >>>>>> one
>> >> >> >>>>>> bit (see the data below). I am pretty sure about this because
>> >> >> >>>>>> when
>> >> >> >>>>>> I reveled and look at the comparisons I was able to compute
>> >> >> >>>>>> using
>> >> >> >>>>>> glmer, these turn out to be non-significant, when glmer told
>> >> >> >>>>>> me
>> >> >> >>>>>> they were:
>> >> >> >>>>>>
>> >> >> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >> >>>>>>> family
>> >> >> >>>>>>> =
>> >> >> >>>>>> binomial) Warning messages: 1: package ?elrm? was built under
>> >> >> >>>>>> R
>> >> >> >>>>>> version 3.1.2 2: package ?coda? was built under R version
>> >> >> >>>>>> 3.1.3
>> >> >> >>>>>>> summary(trial)
>> >> >> >>>>>>
>> >> >> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
>> >> >> >>>>>> binomial, data = trialglm)
>> >> >> >>>>>>
>> >> >> >>>>>>
>> >> >> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>> >> >> >>>>>> (Intercept)
>> >> >> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A
>> >> >> >>>>>> 0.6689
>> >> >> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182
>> >> >> >>>>>> 1.4902
>> >> >> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889
>> >> >> >>>>>> -1.471
>> >> >> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272
>> >> >> >>>>>> 0.7857
>> >> >> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
>> >> >> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
>> >> >> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 ---
>> >> >> >>>>>> Signif.
>> >> >> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >> >> >>>>>>
>> >> >> >>>>>> (Dispersion parameter for binomial family taken to be 1)
>> >> >> >>>>>>
>> >> >> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
>> >> >> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized
>> >> >> >>>>>> deviance:
>> >> >> >>>>>> 245.5554 AIC:  272.22
>> >> >> >>>>>>
>> >> >> >>>>>>
>> >> >> >>>>>> MCMCglmm is too complex for me.
>> >> >> >>>>>>
>> >> >> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
>> >> >> >>>>>> function) but output is hard to read:
>> >> >> >>>>>>
>> >> >> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >> >>>>>>> family =
>> >> >> >>>>>> binomial) Warning messages: 1: package ?logistf? was built
>> >> >> >>>>>> under
>> >> >> >>>>>> R
>> >> >> >>>>>> version 3.1.2 2: package ?mice? was built under R version
>> >> >> >>>>>> 3.1.2
>> >> >> >>>>>>> summary(trial)
>> >> >> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data =
>> >> >> >>>>>> trialglm,
>> >> >> >>>>>> family = binomial)
>> >> >> >>>>>>
>> >> >> >>>>>> Model fitted by Penalized ML Confidence intervals and
>> >> >> >>>>>> p-values
>> >> >> >>>>>> by
>> >> >> >>>>>> Profile Likelihood Profile Likelihood Profile Likelihood
>> >> >> >>>>>> Profile
>> >> >> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile
>> >> >> >>>>>> Likelihood
>> >> >> >>>>>> Profile Likelihood
>> >> >> >>>>>>
>> >> >> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p
>> >> >> >>>>>> (Intercept)
>> >> >> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000
>> >> >> >>>>>> 1.000000e+00
>> >> >> >>>>>> Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
>> >> >> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602
>> >> >> >>>>>> 0.8959376
>> >> >> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics
>> >> >> >>>>>> C
>> >> >> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000
>> >> >> >>>>>> 1.000000e+00
>> >> >> >>>>>> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
>> >> >> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
>> >> >> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics
>> >> >> >>>>>> F
>> >> >> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000
>> >> >> >>>>>> 1.000000e+00
>> >> >> >>>>>> Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
>> >> >> >>>>>> 0.000000 1.000000e+00
>> >> >> >>>>>>
>> >> >> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test
>> >> >> >>>>>> =
>> >> >> >>>>>> 5.334321 on 7 df, p = 0.6192356
>> >> >> >>>>>>
>> >> >> >>>>>> In particular, what is this model telling me? That Z (my ref
>> >> >> >>>>>> level)
>> >> >> >>>>>> and B are significantly different?
>> >> >> >>>>>>
>> >> >> >>>>>> I'm happy to try the elrm function with exact logistic
>> >> >> >>>>>> regression
>> >> >> >>>>>> but I am not capable of programming it. Besides, would it
>> >> >> >>>>>> give
>> >> >> >>>>>> me
>> >> >> >>>>>> valid estimates for the comparison between the Z and B
>> >> >> >>>>>> levels?
>> >> >> >>>>>> The
>> >> >> >>>>>> data frame should look like this:
>> >> >> >>>>>>
>> >> >> >>>>>> Outcome variable (Correct, incorrect) Predictor variable (A,
>> >> >> >>>>>> B,
>> >> >> >>>>>> C,
>> >> >> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12;
>> >> >> >>>>>> D:
>> >> >> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
>> >> >> >>>>>>
>> >> >> >>>>>> Thank you! F.
>> >> >> >>>>>>
>> >> >> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker
>> >> >> >>>>>> <bbolker at gmail.com>
>> >> >> >>>>>> wrote:
>> >> >> >>>>>>
>> >> >> >>>>>>> And for what it's worth, you can do this in conjunction with
>> >> >> >>>>>>> lme4
>> >> >> >>>>>>> by using the blme package instead (a thin Bayesian wrapper
>> >> >> >>>>>>> around
>> >> >> >>>>>>> lme4), or via the MCMCglmm package; see
>> >> >> >>>>>>>
>> >> >> >>>>>>>
>> >> >> >>>>>>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>> >> >> >>>>>>> for an example (search for "complete separation").
>> >> >> >>>>>>>
>> >> >> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
>> >> >> >>>>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >> >> >>>>>>>> You may need to consider using an 'exact', Bayesian, or
>> >> >> >>>>>>>> penalized
>> >> >> >>>>>>> likelihood approach (along the lines proposed by Firth).
>> >> >> >>>>>>>>
>> >> >> >>>>>>>> Maybe a place to start:
>> >> >> >>>>>>>
>> >> >> >>>>>>>
>> >> >> >>>
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
>> >> >> >>>>>>>>
>> >> >> >>>>>>>>
>> >> >> >>>>>>>
>> >> >> > Best,
>> >> >> >>>>>>>> Wolfgang
>> >> >> >>>>>>>>
>> >> >> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
>> >> >> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On
>> >> >> >>>>>>>>> Behalf
>> >> >> >>>>>>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00
>> >> >> >>>>>>>>> To:
>> >> >> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>> >> >> >>>>>>>>> cells in contrast matrix problem
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> After giving up on a glmer for my data, I remembered a
>> >> >> >>>>>>>>> post
>> >> >> >>>>>>>>> by Roger
>> >> >> >>>>>>> Levy
>> >> >> >>>>>>>>> suggesting to try the use non mixed effects glm when one
>> >> >> >>>>>>>>> of
>> >> >> >>>>>>>>> the cells in a matrix is zero.
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> To put this into perspective:
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 |
>> >> >> >>>>>>>>>> Part.name),
>> >> >> >>>>>>>>>> data =
>> >> >> >>>>>>>>> trialglm, family = binomial)
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>> >> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to
>> >> >> >>>>>>>>> converge
>> >> >> >>>>>>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
>> >> >> >>>>>>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> >> >> >>>>>>>>> control$checkConv, : Model is nearly unidentifiable: large
>> >> >> >>>>>>>>> eigenvalue ratio - Rescale variables?
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> My data has a binary outcome, correct or incorrect, a
>> >> >> >>>>>>>>> fixed
>> >> >> >>>>>>>>> effect predictor factor with 8 levels, and a random effect
>> >> >> >>>>>>>>> for participants. I believe the problem R is encountering
>> >> >> >>>>>>>>> is
>> >> >> >>>>>>>>> with one level of the factor (let us call it level B)
>> >> >> >>>>>>>>> which
>> >> >> >>>>>>>>> has no counts (no I won' t try to post the table from the
>> >> >> >>>>>>>>> paper with the counts because I know it will get garbled
>> >> >> >>>>>>>>> up!).
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> I attempt a glm with the same data:
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >> >>>>>>>>>> family =
>> >> >> >>>>>>>>> binomial)
>> >> >> >>>>>>>>>> anova(trial)
>> >> >> >>>>>>>>> Analysis of Deviance Table
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Model: binomial, link: logit
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Response: Correct
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Terms added sequentially (first to last)
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
>> >> >> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
>> >> >> >>>>>>>>> 254.97
>> >> >> >>>>>>>>>> summary(trial)
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>> >> >> >>>>>>>>> binomial, data = trialglm)
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
>> >> >> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>> >> >> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
>> >> >> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241
>> >> >> >>>>>>>>> 1.338
>> >> >> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>> >> >> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>> >> >> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>> >> >> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>> >> >> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>> >> >> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>> >> >> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*?
>> >> >> >>>>>>>>> 0.05
>> >> >> >>>>>>>>> ?.? 0.1 ? ? 1
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom Residual
>> >> >> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Number of Fisher Scoring iterations: 17
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> The comparison I'm interested in is between level B and
>> >> >> >>>>>>>>> the
>> >> >> >>>>>>>>> reference level but it cannot be estimated as shown by the
>> >> >> >>>>>>>>> ridiculously high estimate and SE value.
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
>> >> >> >>>>>>>>> It's the only comparison missing in the table for the
>> >> >> >>>>>>>>> levels
>> >> >> >>>>>>>>> I need so I think it
>> >> >> >>>>>>> would
>> >> >> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the
>> >> >> >>>>>>>>> difference
>> >> >> >>>>>>> could
>> >> >> >>>>>>>>> not be estimated due to zero count'.
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> And by the way I have seen this comparison being generated
>> >> >> >>>>>>>>> using other stats.
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Thanks in advance,
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> Frank
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> [[alternative HTML version deleted]]
>> >> >> >>>>>>>>>
>> >> >> >>>>>>>>> _______________________________________________
>> >> >> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >> >> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >> >>>>>>>> _______________________________________________
>> >> >> >>>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >> >> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >> >>>>>>>
>> >> >> >>>>>>
>> >> >> >
>> >> >> >>>
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> --
>> >> >> >>> Sent from Gmail for IPhone
>> >> >> >>
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >>
>> >> >
>> >> >
>> >> >
>> >> > --
>> >> > Frank Romano Ph.D.
>> >> >
>> >> > Tel. +39 3911639149
>> >> >
>> >> > LinkedIn
>> >> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>> >> >
>> >> > Academia.edu
>> >> > https://sheffield.academia.edu/FrancescoRomano
>> >
>> >
>> >
>> >
>> > --
>> > Frank Romano Ph.D.
>> >
>> > Tel. +39 3911639149
>> >
>> > LinkedIn
>> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>> >
>> > Academia.edu
>> > https://sheffield.academia.edu/FrancescoRomano
>
>
>
>
> --
> Frank Romano Ph.D.
>
> Tel. +39 3911639149
>
> LinkedIn
> https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>
> Academia.edu
> https://sheffield.academia.edu/FrancescoRomano


From killver at gmail.com  Tue Oct 27 00:15:33 2015
From: killver at gmail.com (Philipp Singer)
Date: Mon, 26 Oct 2015 16:15:33 -0700
Subject: [R-sig-ME] Advice regarding model choice
Message-ID: <562EB415.4070708@gmail.com>

My current data to study looks like the following:

Suppose that we repeatedly let subjects write a piece of text. We are 
now mainly interested in whether the consecutive writing has an effect 
on features of the written text.

For example, we can hypothesize that the fifth text is shorter than the 
first.

To that end, the data looks like the following (based on only the text 
length feature):

subject | text_length (characters) | index | total_amount

I have identified that the total_amount is an important feature to 
consider as the e.g., text length is different for people writing the 
text 100 times vs. those writing it only 5 times; we have no balanced 
setting here.

Sample data for one subject could look like:
subject | text_length | index | total_amount
1 | 100 | 1 | 3
1 |   78 | 2 | 3
1 |   80 | 3 | 3

A reasonable model my experiments have suggested is the following:

text_length ~ 1 + index + total_amount + (1|subject)

Alternatively, it might be also reasonable to add (1|total_amount) 
instead of incorporating it as a fixed effect.

In this model, as hypothesized, the index shows a negative coefficient.

What my main reason for this post now is though, that I am unsure 
whether I can justify the usage of a linear model here. Actually, the 
data is not normally distributed and also the residuals are not.

In the following, I have plotted some qqplots with different fits (based 
on a large sample).

http://imgur.com/a/jinav

Usually, I would proceed with such "count" data by using a poisson glm, 
however it does not converge. Also, as the plots suggest, a poisson 
distribution does not seem to be a good fit here. Additionally, the 
poisson fit indicates strong overdispersion.

An important thing to note here, is that my real data is very, very 
large (imagine multiple millions of data points).

Do you guys have any suggestions on how to proceed?

Thanks!


From killver at gmail.com  Tue Oct 27 02:52:52 2015
From: killver at gmail.com (Philipp Singer)
Date: Mon, 26 Oct 2015 18:52:52 -0700
Subject: [R-sig-ME] Advice regarding model choice
In-Reply-To: <562EB415.4070708@gmail.com>
References: <562EB415.4070708@gmail.com>
Message-ID: <562ED8F4.9030105@gmail.com>

Dear David,

Thanks a lot for your response.

Actually, I have already tried the first solution you suggested by 
adding an observation random effect. Unfortunately, it ends up with an 
error that I have not yet found a solution for:

Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in 
pwrssUpdate

My overall data is also really large, something like 35mio. samples...I 
could work with samples though.

In general though, I am not sure whether the effort is even worth it 
based on the qqplots I have attached to my previous mail. The data does 
not seem to be fit well with either a poisson nor a negative binomial model.

Cheers Philipp

P.S.: David accidentally just replied to my mail which is why I continue 
the discussion here.

On 10/26/2015 04:55 PM, David Jones wrote:
> Dear Philipp - I recently had a similar situation, and here is my 2c.
>
> Regarding model, two common ways to account for model overdispersion 
> are negative binomial and poisson-lognormal models (for an easily 
> implemented poisson-lognormal model lme4, see the code that 
> corresponds to a Ben Bolker manuscript at 
> https://blogs.umass.edu/nrc697sa-finnj/2012/11/08/bolkers-reanalysis-of-owl-data/). 
> They will probably run very slowly with that size of sample (recently 
> when running a dataset of N=600k, it took me about 2 hours for a model 
> even on Amazon EC2 for a negative binomial model; may want to use the 
> verbose statement and system.time() function to get an idea that 
> progress is happening and to have a good idea of how long the model 
> took when it is completed). These models took much longer to run than 
> regular poisson on my machines.
>
> For the convergence issues, I found the following site very helpful: 
> https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
> In particular, recoding predictors was helpful (while mine were 
> categorical, changing the coding scheme helped some), and also using 
> prior model starting values in a second model run were enough to 
> eliminate the warnings (and at times, using the second model run as 
> starting values in a third model). Admittedly these issues may 
> disappear/change when you change modeling approaches.
>
> On Mon, Oct 26, 2015 at 7:15 PM, Philipp Singer <killver at gmail.com 
> <mailto:killver at gmail.com>> wrote:
>
>     My current data to study looks like the following:
>
>     Suppose that we repeatedly let subjects write a piece of text. We
>     are now mainly interested in whether the consecutive writing has
>     an effect on features of the written text.
>
>     For example, we can hypothesize that the fifth text is shorter
>     than the first.
>
>     To that end, the data looks like the following (based on only the
>     text length feature):
>
>     subject | text_length (characters) | index | total_amount
>
>     I have identified that the total_amount is an important feature to
>     consider as the e.g., text length is different for people writing
>     the text 100 times vs. those writing it only 5 times; we have no
>     balanced setting here.
>
>     Sample data for one subject could look like:
>     subject | text_length | index | total_amount
>     1 | 100 | 1 | 3
>     1 |   78 | 2 | 3
>     1 |   80 | 3 | 3
>
>     A reasonable model my experiments have suggested is the following:
>
>     text_length ~ 1 + index + total_amount + (1|subject)
>
>     Alternatively, it might be also reasonable to add (1|total_amount)
>     instead of incorporating it as a fixed effect.
>
>     In this model, as hypothesized, the index shows a negative
>     coefficient.
>
>     What my main reason for this post now is though, that I am unsure
>     whether I can justify the usage of a linear model here. Actually,
>     the data is not normally distributed and also the residuals are not.
>
>     In the following, I have plotted some qqplots with different fits
>     (based on a large sample).
>
>     http://imgur.com/a/jinav
>
>     Usually, I would proceed with such "count" data by using a poisson
>     glm, however it does not converge. Also, as the plots suggest, a
>     poisson distribution does not seem to be a good fit here.
>     Additionally, the poisson fit indicates strong overdispersion.
>
>     An important thing to note here, is that my real data is very,
>     very large (imagine multiple millions of data points).
>
>     Do you guys have any suggestions on how to proceed?
>
>     Thanks!
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


	[[alternative HTML version deleted]]


From francescobryanromano at gmail.com  Tue Oct 27 10:04:29 2015
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Tue, 27 Oct 2015 10:04:29 +0100
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABghstSOrBhObh7Hp6-B=NNDvdWkLb=g16vQ+xcuqssuVT-s1g@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
	<CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
	<CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
	<CABghstT4xrrh83+9GGfVfYC2hEgca5uQen2+z0HMqZUtJwRoJw@mail.gmail.com>
	<CABZN5+Er7ayibuy4Vc_D+NLCTT3sPp59FjW7WfuBos6yNd_phA@mail.gmail.com>
	<CABghstSOrBhObh7Hp6-B=NNDvdWkLb=g16vQ+xcuqssuVT-s1g@mail.gmail.com>
Message-ID: <CABZN5+EnN_x-cWhC0-rjdfpL1Ui_8taioC3BH4boRPj_j_UbLg@mail.gmail.com>

Hello again,

if I understand you correctly, you're trying to get R to tell you
what the p value should be. This is the result of using
the commands you indicated:

> options(error=recover)
> if (length(cov) == p) {cov <- diag(cov, p)} else if (length(cov) != p^2)
{stop("normal prior covariance of improper length")}
Error: object 'p' not found
No suitable frames for recover()

I'm not sure what I did wrong. I have both the bglmer and MCMCglmm packages
loaded.


On Mon, Oct 26, 2015 at 1:57 PM, Ben Bolker <bbolker at gmail.com> wrote:

> at this point, if I were you I would set
>
> options(error=recover)
>
> and debug at the point at which the program stops: this will be at
> this point in the code:
>
> if (length(cov) == p) {
>       cov <- diag(cov, p)
>     } else if (length(cov) != p^2) {
>       stop("normal prior covariance of improper length")
>     }
>
> so you should be able to print(p) to find out the appropriate size.
>
>
> On Mon, Oct 26, 2015 at 7:37 AM, Francesco Romano
> <francescobryanromano at gmail.com> wrote:
> > Nope.
> >
> >> revanaA<-
> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data
> =
> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,14)))
> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> > coefficients
> > Error in normal(cov = cov, common.scale = FALSE) :
> >   normal prior covariance of improper length
> >
> > Could it be that I need three separate priors, one for each effect?
> >
> > On Mon, Oct 26, 2015 at 12:25 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >> Ah.  So try normal(cov=diag(9,14)) ...
> >>
> >> On Mon, Oct 26, 2015 at 7:18 AM, Francesco Romano
> >> <francescobryanromano at gmail.com> wrote:
> >> > For some reason the silly bugger didn't past the full command:
> >> >
> >> >> revanaA<-
> >> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item),
> data
> >> >> =
> >> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
> >> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> >> > coefficients
> >> > Error in normal(cov = cov, common.scale = FALSE) :
> >> >   normal prior covariance of improper length
> >> >
> >> > To give more info on this, it is the Animacy factor that is causing
> >> > separation because two levels of it have zero counts in some cases.
> >> >
> >> > On Mon, Oct 26, 2015 at 12:13 PM, Ben Bolker <bbolker at gmail.com>
> wrote:
> >> >>
> >> >> Well, that's a separate problem (and not necessarily a "problem").
>  R
> >> >> is telling you that you have 16 separate combinations of the factors,
> >> >> but only 14 unique combinations represented in your data set, so it
> >> >> can only estimate 14 parameters.  Unless there is a weird interaction
> >> >> with blme I don't know about, this should still give you reasonable
> >> >> answers.
> >> >>
> >> >> On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano
> >> >> <francescobryanromano at gmail.com> wrote:
> >> >> > Many thanks Ben,
> >> >> >
> >> >> > but I tried that already:
> >> >> >
> >> >> >> revanaA<-
> >> >> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item),
> >> >> >> data
> >> >> >> =
> >> >> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
> >> >> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> >> >> > coefficients
> >> >> > Error in normal(cov = cov, common.scale = FALSE) :
> >> >> >   normal prior covariance of improper length
> >> >> >
> >> >> > On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com>
> >> >> > wrote:
> >> >> >>
> >> >> >> On 15-10-26 06:56 AM, Francesco Romano wrote:
> >> >> >> > I wonder if anyone can help with the separation problem
> originally
> >> >> >> > solved
> >> >> >> > by Ben Bolker (see thread).
> >> >> >> > The model and fitting I used previously was
> >> >> >> >
> >> >> >> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm,
> family
> >> >> >> > =
> >> >> >> > binomial, fixef.prior = normal(cov = diag(9,4))
> >> >> >> >
> >> >> >> > which now has to change because the Syntax.Semantcs factor needs
> >> >> >> > to
> >> >> >> > be
> >> >> >> > split into separate
> >> >> >> > within-subjects variables, Syntax, a factor with two levels, and
> >> >> >> > Animacy, a
> >> >> >> > factor with four levels.
> >> >> >> > In addition a new between-subjects factor called Group with two
> >> >> >> > levels
> >> >> >> > (native vs non-native speaker)
> >> >> >> > has to be added which determines the following model, fit by
> >> >> >> > bglmer:
> >> >> >> >
> >> >> >> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+
> >> >> >> > (1|Part.name)+(1|Item),
> >> >> >> > data
> >> >> >> > = trialglm, family = binomial,
> >> >> >> > fixef.prior = normal(cov = diag???)
> >> >> >> >
> >> >> >> > What values should I use for the cov=diag portion in order to
> >> >> >> > continue
> >> >> >> > attempting convergence of a model
> >> >> >> > that includes the random effects?
> >> >> >>
> >> >> >>     In general a reasonable form is normal(cov = diag(v,np))
> where v
> >> >> >> is
> >> >> >> the prior variance (generally something reasonably
> >> >> >> large/non-informative; 9 (=std dev of 3) is probably an OK
> default)
> >> >> >> and
> >> >> >> np is the number of fixed-effect parameters.  You can figure this
> >> >> >> out
> >> >> >> via
> >> >> >>
> >> >> >> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
> >> >> >>
> >> >> >> or multiply 2*4*2 to get 16 ...
> >> >> >>
> >> >> >> >
> >> >> >> > R returns the following error because I don't know how to
> >> >> >> > establish
> >> >> >> > the
> >> >> >> > parameters when more than one
> >> >> >> > fixed effect is involved:
> >> >> >> >
> >> >> >> > Error in normal(cov = cov, common.scale = FALSE) :
> >> >> >> >   normal prior covariance of improper length
> >> >> >> >
> >> >> >> > Many thanks in advance for any help!
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com
> >
> >> >> >> > wrote:
> >> >> >> >
> >> >> >> >>   I don't see your data -- I see a little tiny subset, but
> that's
> >> >> >> >> not
> >> >> >> >> really enough for a reproducible example.
> >> >> >> >>
> >> >> >> >> This is the example given in the URL I sent:
> >> >> >> >>
> >> >> >> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
> >> >> >> >>                        family=binomial,
> >> >> >> >>                        fixef.prior = normal(cov = diag(9,4)))
> >> >> >> >>
> >> >> >> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
> >> >> >> >>           data =trialglm,
> >> >> >> >>          family = binomial,
> >> >> >> >>         fixef.prior = normal(cov=diag(9,8)))
> >> >> >> >>
> >> >> >> >> The last line specifies an 8x8 matrix (because you have 8 fixed
> >> >> >> >> effect
> >> >> >> >> parameters) with a value of 9 on the diagonal, meaning the
> priors
> >> >> >> >> for
> >> >> >> >> the fixed effects are independent and each is Normal with a sd
> of
> >> >> >> >> sqrt(9)=3.
> >> >> >> >>
> >> >> >> >>
> >> >> >> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
> >> >> >> >> <francescobryanromano at gmail.com> wrote:
> >> >> >> >>> Yes but this seems a bit above my head without your help. The
> >> >> >> >>> data
> >> >> >> >>> are
> >> >> >> >>> in
> >> >> >> >>> the three variables at the bottom of my email but I forgot to
> >> >> >> >>> mention
> >> >> >> >>> the
> >> >> >> >>> random participant effect (n = 17). Thanks!
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha
> >> >> >> >>> scritto:
> >> >> >> >>>>
> >> >> >> > On 15-05-28 06:55 AM, Francesco Romano wrote:
> >> >> >> >>>>>> Many thanks to both.
> >> >> >> >>>>>>
> >> >> >> >>>>>> The approaches you suggest (and others online) help one
> deal
> >> >> >> >>>>>> with
> >> >> >> >>>>>> the separation problem but don't offer any specific advice
> as
> >> >> >> >>>>>> to
> >> >> >> >>>>>> how getting a valid p coefficient when comparing two levels
> >> >> >> >>>>>> of
> >> >> >> >>>>>> the
> >> >> >> >>>>>> model vexed by separation.
> >> >> >> >>>>>>
> >> >> >> >>>>>> Ben, here's the output of the bglmer which by the way would
> >> >> >> >>>>>> be
> >> >> >> >>>>>> ideal since it allows me to retain the random effect so
> that
> >> >> >> >>>>>> all
> >> >> >> >>>>>> my
> >> >> >> >>>>>> pairwise comparisons are conducted using mixed effects.
> >> >> >> >>>>>>
> >> >> >> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
> data
> >> >> >> >>>>>>> =
> >> >> >> >>>>>>> trialglm,
> >> >> >> >>>>>> family = binomial) Warning message: package ?blme? was
> built
> >> >> >> >>>>>> under
> >> >> >> >>>>>> R version 3.1.2
> >> >> >> >>>>>>> summary(trial)
> >> >> >> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
> >> >> >> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  :
> >> >> >> >>>>>> 1.4371
> >> >> >> >>>>>>
> >> >> >> >>>>>> Generalized linear mixed model fit by maximum likelihood
> >> >> >> >>>>>> (Laplace
> >> >> >> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit )
> >> >> >> >>>>>> Formula:
> >> >> >> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
> >> >> >> >>>>>>
> >> >> >> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5
> >> >> >> >>>>>> -126.0
> >> >> >> >>>>>> 251.9      376
> >> >> >> >>>>>>
> >> >> >> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max
> -0.9828
> >> >> >> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
> >> >> >> >>>>>>
> >> >> >> >>>>>> Random effects: Groups    Name        Variance Std.Dev.
> >> >> >> >>>>>> Part.name
> >> >> >> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:
> >> >> >> >>>>>> Part.name,
> >> >> >> >>>>>> 16
> >> >> >> >>>>>>
> >> >> >> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
> >> >> >> >>>>>> (Intercept)
> >> >> >> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
> >> >> >> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B
> >> >> >> >>>>>> -16.4391
> >> >> >> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323
> >> >> >> >>>>>> 0.7462
> >> >> >> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853
> >> >> >> >>>>>> 0.306
> >> >> >> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076
> >> >> >> >>>>>> 0.2819
> >> >> >> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
> >> >> >> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171
> ---
> >> >> >> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ?
> ?
> >> >> >> >>>>>> 1
> >> >> >> >>>>>>
> >> >> >> >>>>>> Unfortunately the separation problem is still there.
> Should I
> >> >> >> >>>>>> be
> >> >> >> >>>>>> constraining the parameter somehow? How would I do that?
> The
> >> >> >> >>>>>> data
> >> >> >> >>>>>> is below.
> >> >> >> >
> >> >> >> >    Did you read the section in the URL I suggested?  Just using
> >> >> >> > bglmer
> >> >> >> > isn't enough; you also have to set a prior on the fixed effects.
> >> >> >> >
> >> >> >> >   Your data don't seem to be attached (note that the mailing
> list
> >> >> >> > strips most non-ASCII file types).
> >> >> >> >
> >> >> >> >>>>>>
> >> >> >> >>>>>> In passing I also tried brglm which solves the separation
> >> >> >> >>>>>> problem
> >> >> >> >>>>>> but tells me comparison is significant which I don't
> believe
> >> >> >> >>>>>> one
> >> >> >> >>>>>> bit (see the data below). I am pretty sure about this
> because
> >> >> >> >>>>>> when
> >> >> >> >>>>>> I reveled and look at the comparisons I was able to compute
> >> >> >> >>>>>> using
> >> >> >> >>>>>> glmer, these turn out to be non-significant, when glmer
> told
> >> >> >> >>>>>> me
> >> >> >> >>>>>> they were:
> >> >> >> >>>>>>
> >> >> >> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm,
> >> >> >> >>>>>>> family
> >> >> >> >>>>>>> =
> >> >> >> >>>>>> binomial) Warning messages: 1: package ?elrm? was built
> under
> >> >> >> >>>>>> R
> >> >> >> >>>>>> version 3.1.2 2: package ?coda? was built under R version
> >> >> >> >>>>>> 3.1.3
> >> >> >> >>>>>>> summary(trial)
> >> >> >> >>>>>>
> >> >> >> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
> >> >> >> >>>>>> binomial, data = trialglm)
> >> >> >> >>>>>>
> >> >> >> >>>>>>
> >> >> >> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
> >> >> >> >>>>>> (Intercept)
> >> >> >> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A
> >> >> >> >>>>>> 0.6689
> >> >> >> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182
> >> >> >> >>>>>> 1.4902
> >> >> >> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889
> >> >> >> >>>>>> -1.471
> >> >> >> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272
> >> >> >> >>>>>> 0.7857
> >> >> >> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
> >> >> >> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
> >> >> >> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 ---
> >> >> >> >>>>>> Signif.
> >> >> >> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >> >> >>>>>>
> >> >> >> >>>>>> (Dispersion parameter for binomial family taken to be 1)
> >> >> >> >>>>>>
> >> >> >> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
> >> >> >> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized
> >> >> >> >>>>>> deviance:
> >> >> >> >>>>>> 245.5554 AIC:  272.22
> >> >> >> >>>>>>
> >> >> >> >>>>>>
> >> >> >> >>>>>> MCMCglmm is too complex for me.
> >> >> >> >>>>>>
> >> >> >> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
> >> >> >> >>>>>> function) but output is hard to read:
> >> >> >> >>>>>>
> >> >> >> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data =
> trialglm,
> >> >> >> >>>>>>> family =
> >> >> >> >>>>>> binomial) Warning messages: 1: package ?logistf? was built
> >> >> >> >>>>>> under
> >> >> >> >>>>>> R
> >> >> >> >>>>>> version 3.1.2 2: package ?mice? was built under R version
> >> >> >> >>>>>> 3.1.2
> >> >> >> >>>>>>> summary(trial)
> >> >> >> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data =
> >> >> >> >>>>>> trialglm,
> >> >> >> >>>>>> family = binomial)
> >> >> >> >>>>>>
> >> >> >> >>>>>> Model fitted by Penalized ML Confidence intervals and
> >> >> >> >>>>>> p-values
> >> >> >> >>>>>> by
> >> >> >> >>>>>> Profile Likelihood Profile Likelihood Profile Likelihood
> >> >> >> >>>>>> Profile
> >> >> >> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile
> >> >> >> >>>>>> Likelihood
> >> >> >> >>>>>> Profile Likelihood
> >> >> >> >>>>>>
> >> >> >> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p
> >> >> >> >>>>>> (Intercept)
> >> >> >> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000
> >> >> >> >>>>>> 1.000000e+00
> >> >> >> >>>>>> Syntax.Semantics A  4.1767737 6.3254344  0.4224696
> 12.0673987
> >> >> >> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602
> >> >> >> >>>>>> 0.8959376
> >> >> >> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00
> Syntax.Semantics
> >> >> >> >>>>>> C
> >> >> >> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000
> >> >> >> >>>>>> 1.000000e+00
> >> >> >> >>>>>> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535
> 0.6479908
> >> >> >> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907
> 0.9771824
> >> >> >> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00
> Syntax.Semantics
> >> >> >> >>>>>> F
> >> >> >> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000
> >> >> >> >>>>>> 1.000000e+00
> >> >> >> >>>>>> Syntax.Semantics G  0.9909046 1.3787175  0.5457741
> 1.5353981
> >> >> >> >>>>>> 0.000000 1.000000e+00
> >> >> >> >>>>>>
> >> >> >> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald
> test
> >> >> >> >>>>>> =
> >> >> >> >>>>>> 5.334321 on 7 df, p = 0.6192356
> >> >> >> >>>>>>
> >> >> >> >>>>>> In particular, what is this model telling me? That Z (my
> ref
> >> >> >> >>>>>> level)
> >> >> >> >>>>>> and B are significantly different?
> >> >> >> >>>>>>
> >> >> >> >>>>>> I'm happy to try the elrm function with exact logistic
> >> >> >> >>>>>> regression
> >> >> >> >>>>>> but I am not capable of programming it. Besides, would it
> >> >> >> >>>>>> give
> >> >> >> >>>>>> me
> >> >> >> >>>>>> valid estimates for the comparison between the Z and B
> >> >> >> >>>>>> levels?
> >> >> >> >>>>>> The
> >> >> >> >>>>>> data frame should look like this:
> >> >> >> >>>>>>
> >> >> >> >>>>>> Outcome variable (Correct, incorrect) Predictor variable
> (A,
> >> >> >> >>>>>> B,
> >> >> >> >>>>>> C,
> >> >> >> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12;
> >> >> >> >>>>>> D:
> >> >> >> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
> >> >> >> >>>>>>
> >> >> >> >>>>>> Thank you! F.
> >> >> >> >>>>>>
> >> >> >> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker
> >> >> >> >>>>>> <bbolker at gmail.com>
> >> >> >> >>>>>> wrote:
> >> >> >> >>>>>>
> >> >> >> >>>>>>> And for what it's worth, you can do this in conjunction
> with
> >> >> >> >>>>>>> lme4
> >> >> >> >>>>>>> by using the blme package instead (a thin Bayesian wrapper
> >> >> >> >>>>>>> around
> >> >> >> >>>>>>> lme4), or via the MCMCglmm package; see
> >> >> >> >>>>>>>
> >> >> >> >>>>>>>
> >> >> >> >>>>>>>
> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
> >> >> >> >>>>>>> for an example (search for "complete separation").
> >> >> >> >>>>>>>
> >> >> >> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang
> (STAT)
> >> >> >> >>>>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >> >> >> >>>>>>>> You may need to consider using an 'exact', Bayesian, or
> >> >> >> >>>>>>>> penalized
> >> >> >> >>>>>>> likelihood approach (along the lines proposed by Firth).
> >> >> >> >>>>>>>>
> >> >> >> >>>>>>>> Maybe a place to start:
> >> >> >> >>>>>>>
> >> >> >> >>>>>>>
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>>
> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
> >> >> >> >>>>>>>>
> >> >> >> >>>>>>>>
> >> >> >> >>>>>>>
> >> >> >> > Best,
> >> >> >> >>>>>>>> Wolfgang
> >> >> >> >>>>>>>>
> >> >> >> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
> >> >> >> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On
> >> >> >> >>>>>>>>> Behalf
> >> >> >> >>>>>>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00
> >> >> >> >>>>>>>>> To:
> >> >> >> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME]
> Zero
> >> >> >> >>>>>>>>> cells in contrast matrix problem
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> After giving up on a glmer for my data, I remembered a
> >> >> >> >>>>>>>>> post
> >> >> >> >>>>>>>>> by Roger
> >> >> >> >>>>>>> Levy
> >> >> >> >>>>>>>>> suggesting to try the use non mixed effects glm when one
> >> >> >> >>>>>>>>> of
> >> >> >> >>>>>>>>> the cells in a matrix is zero.
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> To put this into perspective:
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 |
> >> >> >> >>>>>>>>>> Part.name),
> >> >> >> >>>>>>>>>> data =
> >> >> >> >>>>>>>>> trialglm, family = binomial)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
> >> >> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to
> >> >> >> >>>>>>>>> converge
> >> >> >> >>>>>>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2:
> In
> >> >> >> >>>>>>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
> >> >> >> >>>>>>>>> control$checkConv, : Model is nearly unidentifiable:
> large
> >> >> >> >>>>>>>>> eigenvalue ratio - Rescale variables?
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> My data has a binary outcome, correct or incorrect, a
> >> >> >> >>>>>>>>> fixed
> >> >> >> >>>>>>>>> effect predictor factor with 8 levels, and a random
> effect
> >> >> >> >>>>>>>>> for participants. I believe the problem R is
> encountering
> >> >> >> >>>>>>>>> is
> >> >> >> >>>>>>>>> with one level of the factor (let us call it level B)
> >> >> >> >>>>>>>>> which
> >> >> >> >>>>>>>>> has no counts (no I won' t try to post the table from
> the
> >> >> >> >>>>>>>>> paper with the counts because I know it will get garbled
> >> >> >> >>>>>>>>> up!).
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> I attempt a glm with the same data:
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
> >> >> >> >>>>>>>>>> family =
> >> >> >> >>>>>>>>> binomial)
> >> >> >> >>>>>>>>>> anova(trial)
> >> >> >> >>>>>>>>> Analysis of Deviance Table
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Model: binomial, link: logit
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Response: Correct
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Terms added sequentially (first to last)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
> >> >> >> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
> >> >> >> >>>>>>>>> 254.97
> >> >> >> >>>>>>>>>> summary(trial)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
> >> >> >> >>>>>>>>> binomial, data = trialglm)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
> >> >> >> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
> >> >> >> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
> >> >> >> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241
> >> >> >> >>>>>>>>> 1.338
> >> >> >> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
> >> >> >> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
> >> >> >> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
> >> >> >> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
> >> >> >> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
> >> >> >> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
> >> >> >> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*?
> >> >> >> >>>>>>>>> 0.05
> >> >> >> >>>>>>>>> ?.? 0.1 ? ? 1
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom
> Residual
> >> >> >> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Number of Fisher Scoring iterations: 17
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> The comparison I'm interested in is between level B and
> >> >> >> >>>>>>>>> the
> >> >> >> >>>>>>>>> reference level but it cannot be estimated as shown by
> the
> >> >> >> >>>>>>>>> ridiculously high estimate and SE value.
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and
> p?
> >> >> >> >>>>>>>>> It's the only comparison missing in the table for the
> >> >> >> >>>>>>>>> levels
> >> >> >> >>>>>>>>> I need so I think it
> >> >> >> >>>>>>> would
> >> >> >> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the
> >> >> >> >>>>>>>>> difference
> >> >> >> >>>>>>> could
> >> >> >> >>>>>>>>> not be estimated due to zero count'.
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> And by the way I have seen this comparison being
> generated
> >> >> >> >>>>>>>>> using other stats.
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Thanks in advance,
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Frank
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> [[alternative HTML version deleted]]
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> _______________________________________________
> >> >> >> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list
> >> >> >> >>>>>>>>>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >> >>>>>>>> _______________________________________________
> >> >> >> >>>>>>>> R-sig-mixed-models at r-project.org mailing list
> >> >> >> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >> >>>>>>>
> >> >> >> >>>>>>
> >> >> >> >
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>> --
> >> >> >> >>> Sent from Gmail for IPhone
> >> >> >> >>
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >>
> >> >> >
> >> >> >
> >> >> >
> >> >> > --
> >> >> > Frank Romano Ph.D.
> >> >> >
> >> >> > Tel. +39 3911639149
> >> >> >
> >> >> > LinkedIn
> >> >> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
> >> >> >
> >> >> > Academia.edu
> >> >> > https://sheffield.academia.edu/FrancescoRomano
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > Frank Romano Ph.D.
> >> >
> >> > Tel. +39 3911639149
> >> >
> >> > LinkedIn
> >> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
> >> >
> >> > Academia.edu
> >> > https://sheffield.academia.edu/FrancescoRomano
> >
> >
> >
> >
> > --
> > Frank Romano Ph.D.
> >
> > Tel. +39 3911639149
> >
> > LinkedIn
> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
> >
> > Academia.edu
> > https://sheffield.academia.edu/FrancescoRomano
>



-- 
Frank Romano Ph.D.

Tel. +39 3911639149

*LinkedIn*
https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162

*Academia.edu*
https://sheffield.academia.edu/FrancescoRomano

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Oct 27 16:35:27 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 27 Oct 2015 11:35:27 -0400
Subject: [R-sig-ME] Fwd: Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+EnN_x-cWhC0-rjdfpL1Ui_8taioC3BH4boRPj_j_UbLg@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
	<CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
	<CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
	<CABghstT4xrrh83+9GGfVfYC2hEgca5uQen2+z0HMqZUtJwRoJw@mail.gmail.com>
	<CABZN5+Er7ayibuy4Vc_D+NLCTT3sPp59FjW7WfuBos6yNd_phA@mail.gmail.com>
	<CABghstSOrBhObh7Hp6-B=NNDvdWkLb=g16vQ+xcuqssuVT-s1g@mail.gmail.com>
	<CABZN5+EnN_x-cWhC0-rjdfpL1Ui_8taioC3BH4boRPj_j_UbLg@mail.gmail.com>
Message-ID: <CABghstQpvFK-4HHpFqW0kzPiURhcdtaPSqUwZcVcxtAoXe=EYw@mail.gmail.com>

---------- Forwarded message ----------
From: Francesco Romano <francescobryanromano at gmail.com>
Date: Tue, Oct 27, 2015 at 5:04 AM
Subject: Re: Zero cells in contrast matrix problem
To: Ben Bolker <bbolker at gmail.com>
Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>


Hello again,

if I understand you correctly, you're trying to get R to tell you
what the p value should be. This is the result of using
the commands you indicated:

> options(error=recover)
> if (length(cov) == p) {cov <- diag(cov, p)} else if (length(cov) != p^2) {stop("normal prior covariance of improper length")}
Error: object 'p' not found
No suitable frames for recover()

I'm not sure what I did wrong. I have both the bglmer and MCMCglmm
packages loaded.


   I wasn't sufficiently clear.
   I wasn't suggesting that you run that particular code: I was
suggesting that you should set options as specified, and then try to
run your model.  When you hit an error, it will drop you into a
browser (it will give you a choice of which "frame" to select, at
which you point you can print the value of the p variable.  I just
tried this, and my session looked like this:

> options(error=recover)
## run model with a bogus covariance matrix size
> bglmer(predation~ttt+(1|block),data=newdat,
                       family=binomial,
                       fixef.prior = normal(cov = diag(9,17)))

Error in normal(cov = cov, common.scale = FALSE) :
  normal prior covariance of improper length

Enter a frame number, or 0 to exit

1: bglmer(predation ~ ttt + (1 | block), data = newdat, family = binomial, fix
2: do.call(mkBglmerDevfun, c(glmod, glmod$X, glmod$reTrms, list(priors = list(
3: (function (fr, X, reTrms, family, nAGQ = 1, verbose = 0, maxit = 100, contr
4: evaluatePriorArguments(priors$covPriors, priors$fixefPrior, NULL, c(n = nro
5: evaluateFixefPrior(fixefPrior, defnEnv, evalEnv)
6: eval(fixefPrior, envir = evalEnv)
7: eval(expr, envir, enclos)
8: normal(cov = diag(9, 17))
9: normal(cov = cov, common.scale = FALSE)

## I chose i:

Selection: 8
Called from: top level
Browse[1]> ls()
[1] "cov"         "matchedCall" "normal"      "sd"
Browse[1]> print(p)
[1] 4

  This tells me that I should have specified a 4-by-4 covariance matrix.

On Mon, Oct 26, 2015 at 1:57 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
> at this point, if I were you I would set
>
> options(error=recover)
>
> and debug at the point at which the program stops: this will be at
> this point in the code:
>
> if (length(cov) == p) {
>       cov <- diag(cov, p)
>     } else if (length(cov) != p^2) {
>       stop("normal prior covariance of improper length")
>     }
>
> so you should be able to print(p) to find out the appropriate size.
>
>
> On Mon, Oct 26, 2015 at 7:37 AM, Francesco Romano
> <francescobryanromano at gmail.com> wrote:
> > Nope.
> >
> >> revanaA<-
> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data =
> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,14)))
> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> > coefficients
> > Error in normal(cov = cov, common.scale = FALSE) :
> >   normal prior covariance of improper length
> >
> > Could it be that I need three separate priors, one for each effect?
> >
> > On Mon, Oct 26, 2015 at 12:25 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >> Ah.  So try normal(cov=diag(9,14)) ...
> >>
> >> On Mon, Oct 26, 2015 at 7:18 AM, Francesco Romano
> >> <francescobryanromano at gmail.com> wrote:
> >> > For some reason the silly bugger didn't past the full command:
> >> >
> >> >> revanaA<-
> >> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data
> >> >> =
> >> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
> >> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> >> > coefficients
> >> > Error in normal(cov = cov, common.scale = FALSE) :
> >> >   normal prior covariance of improper length
> >> >
> >> > To give more info on this, it is the Animacy factor that is causing
> >> > separation because two levels of it have zero counts in some cases.
> >> >
> >> > On Mon, Oct 26, 2015 at 12:13 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >> >>
> >> >> Well, that's a separate problem (and not necessarily a "problem").   R
> >> >> is telling you that you have 16 separate combinations of the factors,
> >> >> but only 14 unique combinations represented in your data set, so it
> >> >> can only estimate 14 parameters.  Unless there is a weird interaction
> >> >> with blme I don't know about, this should still give you reasonable
> >> >> answers.
> >> >>
> >> >> On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano
> >> >> <francescobryanromano at gmail.com> wrote:
> >> >> > Many thanks Ben,
> >> >> >
> >> >> > but I tried that already:
> >> >> >
> >> >> >> revanaA<-
> >> >> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item),
> >> >> >> data
> >> >> >> =
> >> >> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
> >> >> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> >> >> > coefficients
> >> >> > Error in normal(cov = cov, common.scale = FALSE) :
> >> >> >   normal prior covariance of improper length
> >> >> >
> >> >> > On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com>
> >> >> > wrote:
> >> >> >>
> >> >> >> On 15-10-26 06:56 AM, Francesco Romano wrote:
> >> >> >> > I wonder if anyone can help with the separation problem originally
> >> >> >> > solved
> >> >> >> > by Ben Bolker (see thread).
> >> >> >> > The model and fitting I used previously was
> >> >> >> >
> >> >> >> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family
> >> >> >> > =
> >> >> >> > binomial, fixef.prior = normal(cov = diag(9,4))
> >> >> >> >
> >> >> >> > which now has to change because the Syntax.Semantcs factor needs
> >> >> >> > to
> >> >> >> > be
> >> >> >> > split into separate
> >> >> >> > within-subjects variables, Syntax, a factor with two levels, and
> >> >> >> > Animacy, a
> >> >> >> > factor with four levels.
> >> >> >> > In addition a new between-subjects factor called Group with two
> >> >> >> > levels
> >> >> >> > (native vs non-native speaker)
> >> >> >> > has to be added which determines the following model, fit by
> >> >> >> > bglmer:
> >> >> >> >
> >> >> >> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+
> >> >> >> > (1|Part.name)+(1|Item),
> >> >> >> > data
> >> >> >> > = trialglm, family = binomial,
> >> >> >> > fixef.prior = normal(cov = diag???)
> >> >> >> >
> >> >> >> > What values should I use for the cov=diag portion in order to
> >> >> >> > continue
> >> >> >> > attempting convergence of a model
> >> >> >> > that includes the random effects?
> >> >> >>
> >> >> >>     In general a reasonable form is normal(cov = diag(v,np)) where v
> >> >> >> is
> >> >> >> the prior variance (generally something reasonably
> >> >> >> large/non-informative; 9 (=std dev of 3) is probably an OK default)
> >> >> >> and
> >> >> >> np is the number of fixed-effect parameters.  You can figure this
> >> >> >> out
> >> >> >> via
> >> >> >>
> >> >> >> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
> >> >> >>
> >> >> >> or multiply 2*4*2 to get 16 ...
> >> >> >>
> >> >> >> >
> >> >> >> > R returns the following error because I don't know how to
> >> >> >> > establish
> >> >> >> > the
> >> >> >> > parameters when more than one
> >> >> >> > fixed effect is involved:
> >> >> >> >
> >> >> >> > Error in normal(cov = cov, common.scale = FALSE) :
> >> >> >> >   normal prior covariance of improper length
> >> >> >> >
> >> >> >> > Many thanks in advance for any help!
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com>
> >> >> >> > wrote:
> >> >> >> >
> >> >> >> >>   I don't see your data -- I see a little tiny subset, but that's
> >> >> >> >> not
> >> >> >> >> really enough for a reproducible example.
> >> >> >> >>
> >> >> >> >> This is the example given in the URL I sent:
> >> >> >> >>
> >> >> >> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
> >> >> >> >>                        family=binomial,
> >> >> >> >>                        fixef.prior = normal(cov = diag(9,4)))
> >> >> >> >>
> >> >> >> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
> >> >> >> >>           data =trialglm,
> >> >> >> >>          family = binomial,
> >> >> >> >>         fixef.prior = normal(cov=diag(9,8)))
> >> >> >> >>
> >> >> >> >> The last line specifies an 8x8 matrix (because you have 8 fixed
> >> >> >> >> effect
> >> >> >> >> parameters) with a value of 9 on the diagonal, meaning the priors
> >> >> >> >> for
> >> >> >> >> the fixed effects are independent and each is Normal with a sd of
> >> >> >> >> sqrt(9)=3.
> >> >> >> >>
> >> >> >> >>
> >> >> >> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
> >> >> >> >> <francescobryanromano at gmail.com> wrote:
> >> >> >> >>> Yes but this seems a bit above my head without your help. The
> >> >> >> >>> data
> >> >> >> >>> are
> >> >> >> >>> in
> >> >> >> >>> the three variables at the bottom of my email but I forgot to
> >> >> >> >>> mention
> >> >> >> >>> the
> >> >> >> >>> random participant effect (n = 17). Thanks!
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha
> >> >> >> >>> scritto:
> >> >> >> >>>>
> >> >> >> > On 15-05-28 06:55 AM, Francesco Romano wrote:
> >> >> >> >>>>>> Many thanks to both.
> >> >> >> >>>>>>
> >> >> >> >>>>>> The approaches you suggest (and others online) help one deal
> >> >> >> >>>>>> with
> >> >> >> >>>>>> the separation problem but don't offer any specific advice as
> >> >> >> >>>>>> to
> >> >> >> >>>>>> how getting a valid p coefficient when comparing two levels
> >> >> >> >>>>>> of
> >> >> >> >>>>>> the
> >> >> >> >>>>>> model vexed by separation.
> >> >> >> >>>>>>
> >> >> >> >>>>>> Ben, here's the output of the bglmer which by the way would
> >> >> >> >>>>>> be
> >> >> >> >>>>>> ideal since it allows me to retain the random effect so that
> >> >> >> >>>>>> all
> >> >> >> >>>>>> my
> >> >> >> >>>>>> pairwise comparisons are conducted using mixed effects.
> >> >> >> >>>>>>
> >> >> >> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data
> >> >> >> >>>>>>> =
> >> >> >> >>>>>>> trialglm,
> >> >> >> >>>>>> family = binomial) Warning message: package ?blme? was built
> >> >> >> >>>>>> under
> >> >> >> >>>>>> R version 3.1.2
> >> >> >> >>>>>>> summary(trial)
> >> >> >> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
> >> >> >> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  :
> >> >> >> >>>>>> 1.4371
> >> >> >> >>>>>>
> >> >> >> >>>>>> Generalized linear mixed model fit by maximum likelihood
> >> >> >> >>>>>> (Laplace
> >> >> >> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit )
> >> >> >> >>>>>> Formula:
> >> >> >> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
> >> >> >> >>>>>>
> >> >> >> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5
> >> >> >> >>>>>> -126.0
> >> >> >> >>>>>> 251.9      376
> >> >> >> >>>>>>
> >> >> >> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
> >> >> >> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
> >> >> >> >>>>>>
> >> >> >> >>>>>> Random effects: Groups    Name        Variance Std.Dev.
> >> >> >> >>>>>> Part.name
> >> >> >> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:
> >> >> >> >>>>>> Part.name,
> >> >> >> >>>>>> 16
> >> >> >> >>>>>>
> >> >> >> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
> >> >> >> >>>>>> (Intercept)
> >> >> >> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
> >> >> >> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B
> >> >> >> >>>>>> -16.4391
> >> >> >> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323
> >> >> >> >>>>>> 0.7462
> >> >> >> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853
> >> >> >> >>>>>> 0.306
> >> >> >> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076
> >> >> >> >>>>>> 0.2819
> >> >> >> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
> >> >> >> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
> >> >> >> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
> >> >> >> >>>>>> 1
> >> >> >> >>>>>>
> >> >> >> >>>>>> Unfortunately the separation problem is still there. Should I
> >> >> >> >>>>>> be
> >> >> >> >>>>>> constraining the parameter somehow? How would I do that? The
> >> >> >> >>>>>> data
> >> >> >> >>>>>> is below.
> >> >> >> >
> >> >> >> >    Did you read the section in the URL I suggested?  Just using
> >> >> >> > bglmer
> >> >> >> > isn't enough; you also have to set a prior on the fixed effects.
> >> >> >> >
> >> >> >> >   Your data don't seem to be attached (note that the mailing list
> >> >> >> > strips most non-ASCII file types).
> >> >> >> >
> >> >> >> >>>>>>
> >> >> >> >>>>>> In passing I also tried brglm which solves the separation
> >> >> >> >>>>>> problem
> >> >> >> >>>>>> but tells me comparison is significant which I don't believe
> >> >> >> >>>>>> one
> >> >> >> >>>>>> bit (see the data below). I am pretty sure about this because
> >> >> >> >>>>>> when
> >> >> >> >>>>>> I reveled and look at the comparisons I was able to compute
> >> >> >> >>>>>> using
> >> >> >> >>>>>> glmer, these turn out to be non-significant, when glmer told
> >> >> >> >>>>>> me
> >> >> >> >>>>>> they were:
> >> >> >> >>>>>>
> >> >> >> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm,
> >> >> >> >>>>>>> family
> >> >> >> >>>>>>> =
> >> >> >> >>>>>> binomial) Warning messages: 1: package ?elrm? was built under
> >> >> >> >>>>>> R
> >> >> >> >>>>>> version 3.1.2 2: package ?coda? was built under R version
> >> >> >> >>>>>> 3.1.3
> >> >> >> >>>>>>> summary(trial)
> >> >> >> >>>>>>
> >> >> >> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
> >> >> >> >>>>>> binomial, data = trialglm)
> >> >> >> >>>>>>
> >> >> >> >>>>>>
> >> >> >> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
> >> >> >> >>>>>> (Intercept)
> >> >> >> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A
> >> >> >> >>>>>> 0.6689
> >> >> >> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182
> >> >> >> >>>>>> 1.4902
> >> >> >> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889
> >> >> >> >>>>>> -1.471
> >> >> >> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272
> >> >> >> >>>>>> 0.7857
> >> >> >> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
> >> >> >> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
> >> >> >> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 ---
> >> >> >> >>>>>> Signif.
> >> >> >> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >> >> >>>>>>
> >> >> >> >>>>>> (Dispersion parameter for binomial family taken to be 1)
> >> >> >> >>>>>>
> >> >> >> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
> >> >> >> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized
> >> >> >> >>>>>> deviance:
> >> >> >> >>>>>> 245.5554 AIC:  272.22
> >> >> >> >>>>>>
> >> >> >> >>>>>>
> >> >> >> >>>>>> MCMCglmm is too complex for me.
> >> >> >> >>>>>>
> >> >> >> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
> >> >> >> >>>>>> function) but output is hard to read:
> >> >> >> >>>>>>
> >> >> >> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
> >> >> >> >>>>>>> family =
> >> >> >> >>>>>> binomial) Warning messages: 1: package ?logistf? was built
> >> >> >> >>>>>> under
> >> >> >> >>>>>> R
> >> >> >> >>>>>> version 3.1.2 2: package ?mice? was built under R version
> >> >> >> >>>>>> 3.1.2
> >> >> >> >>>>>>> summary(trial)
> >> >> >> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data =
> >> >> >> >>>>>> trialglm,
> >> >> >> >>>>>> family = binomial)
> >> >> >> >>>>>>
> >> >> >> >>>>>> Model fitted by Penalized ML Confidence intervals and
> >> >> >> >>>>>> p-values
> >> >> >> >>>>>> by
> >> >> >> >>>>>> Profile Likelihood Profile Likelihood Profile Likelihood
> >> >> >> >>>>>> Profile
> >> >> >> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile
> >> >> >> >>>>>> Likelihood
> >> >> >> >>>>>> Profile Likelihood
> >> >> >> >>>>>>
> >> >> >> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p
> >> >> >> >>>>>> (Intercept)
> >> >> >> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000
> >> >> >> >>>>>> 1.000000e+00
> >> >> >> >>>>>> Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
> >> >> >> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602
> >> >> >> >>>>>> 0.8959376
> >> >> >> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics
> >> >> >> >>>>>> C
> >> >> >> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000
> >> >> >> >>>>>> 1.000000e+00
> >> >> >> >>>>>> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
> >> >> >> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
> >> >> >> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics
> >> >> >> >>>>>> F
> >> >> >> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000
> >> >> >> >>>>>> 1.000000e+00
> >> >> >> >>>>>> Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
> >> >> >> >>>>>> 0.000000 1.000000e+00
> >> >> >> >>>>>>
> >> >> >> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test
> >> >> >> >>>>>> =
> >> >> >> >>>>>> 5.334321 on 7 df, p = 0.6192356
> >> >> >> >>>>>>
> >> >> >> >>>>>> In particular, what is this model telling me? That Z (my ref
> >> >> >> >>>>>> level)
> >> >> >> >>>>>> and B are significantly different?
> >> >> >> >>>>>>
> >> >> >> >>>>>> I'm happy to try the elrm function with exact logistic
> >> >> >> >>>>>> regression
> >> >> >> >>>>>> but I am not capable of programming it. Besides, would it
> >> >> >> >>>>>> give
> >> >> >> >>>>>> me
> >> >> >> >>>>>> valid estimates for the comparison between the Z and B
> >> >> >> >>>>>> levels?
> >> >> >> >>>>>> The
> >> >> >> >>>>>> data frame should look like this:
> >> >> >> >>>>>>
> >> >> >> >>>>>> Outcome variable (Correct, incorrect) Predictor variable (A,
> >> >> >> >>>>>> B,
> >> >> >> >>>>>> C,
> >> >> >> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12;
> >> >> >> >>>>>> D:
> >> >> >> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
> >> >> >> >>>>>>
> >> >> >> >>>>>> Thank you! F.
> >> >> >> >>>>>>
> >> >> >> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker
> >> >> >> >>>>>> <bbolker at gmail.com>
> >> >> >> >>>>>> wrote:
> >> >> >> >>>>>>
> >> >> >> >>>>>>> And for what it's worth, you can do this in conjunction with
> >> >> >> >>>>>>> lme4
> >> >> >> >>>>>>> by using the blme package instead (a thin Bayesian wrapper
> >> >> >> >>>>>>> around
> >> >> >> >>>>>>> lme4), or via the MCMCglmm package; see
> >> >> >> >>>>>>>
> >> >> >> >>>>>>>
> >> >> >> >>>>>>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
> >> >> >> >>>>>>> for an example (search for "complete separation").
> >> >> >> >>>>>>>
> >> >> >> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
> >> >> >> >>>>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >> >> >> >>>>>>>> You may need to consider using an 'exact', Bayesian, or
> >> >> >> >>>>>>>> penalized
> >> >> >> >>>>>>> likelihood approach (along the lines proposed by Firth).
> >> >> >> >>>>>>>>
> >> >> >> >>>>>>>> Maybe a place to start:
> >> >> >> >>>>>>>
> >> >> >> >>>>>>>
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
> >> >> >> >>>>>>>>
> >> >> >> >>>>>>>>
> >> >> >> >>>>>>>
> >> >> >> > Best,
> >> >> >> >>>>>>>> Wolfgang
> >> >> >> >>>>>>>>
> >> >> >> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
> >> >> >> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On
> >> >> >> >>>>>>>>> Behalf
> >> >> >> >>>>>>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00
> >> >> >> >>>>>>>>> To:
> >> >> >> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
> >> >> >> >>>>>>>>> cells in contrast matrix problem
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> After giving up on a glmer for my data, I remembered a
> >> >> >> >>>>>>>>> post
> >> >> >> >>>>>>>>> by Roger
> >> >> >> >>>>>>> Levy
> >> >> >> >>>>>>>>> suggesting to try the use non mixed effects glm when one
> >> >> >> >>>>>>>>> of
> >> >> >> >>>>>>>>> the cells in a matrix is zero.
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> To put this into perspective:
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 |
> >> >> >> >>>>>>>>>> Part.name),
> >> >> >> >>>>>>>>>> data =
> >> >> >> >>>>>>>>> trialglm, family = binomial)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
> >> >> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to
> >> >> >> >>>>>>>>> converge
> >> >> >> >>>>>>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
> >> >> >> >>>>>>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
> >> >> >> >>>>>>>>> control$checkConv, : Model is nearly unidentifiable: large
> >> >> >> >>>>>>>>> eigenvalue ratio - Rescale variables?
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> My data has a binary outcome, correct or incorrect, a
> >> >> >> >>>>>>>>> fixed
> >> >> >> >>>>>>>>> effect predictor factor with 8 levels, and a random effect
> >> >> >> >>>>>>>>> for participants. I believe the problem R is encountering
> >> >> >> >>>>>>>>> is
> >> >> >> >>>>>>>>> with one level of the factor (let us call it level B)
> >> >> >> >>>>>>>>> which
> >> >> >> >>>>>>>>> has no counts (no I won' t try to post the table from the
> >> >> >> >>>>>>>>> paper with the counts because I know it will get garbled
> >> >> >> >>>>>>>>> up!).
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> I attempt a glm with the same data:
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
> >> >> >> >>>>>>>>>> family =
> >> >> >> >>>>>>>>> binomial)
> >> >> >> >>>>>>>>>> anova(trial)
> >> >> >> >>>>>>>>> Analysis of Deviance Table
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Model: binomial, link: logit
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Response: Correct
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Terms added sequentially (first to last)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
> >> >> >> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
> >> >> >> >>>>>>>>> 254.97
> >> >> >> >>>>>>>>>> summary(trial)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
> >> >> >> >>>>>>>>> binomial, data = trialglm)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
> >> >> >> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
> >> >> >> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
> >> >> >> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241
> >> >> >> >>>>>>>>> 1.338
> >> >> >> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
> >> >> >> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
> >> >> >> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
> >> >> >> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
> >> >> >> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
> >> >> >> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
> >> >> >> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*?
> >> >> >> >>>>>>>>> 0.05
> >> >> >> >>>>>>>>> ?.? 0.1 ? ? 1
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom Residual
> >> >> >> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Number of Fisher Scoring iterations: 17
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> The comparison I'm interested in is between level B and
> >> >> >> >>>>>>>>> the
> >> >> >> >>>>>>>>> reference level but it cannot be estimated as shown by the
> >> >> >> >>>>>>>>> ridiculously high estimate and SE value.
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
> >> >> >> >>>>>>>>> It's the only comparison missing in the table for the
> >> >> >> >>>>>>>>> levels
> >> >> >> >>>>>>>>> I need so I think it
> >> >> >> >>>>>>> would
> >> >> >> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the
> >> >> >> >>>>>>>>> difference
> >> >> >> >>>>>>> could
> >> >> >> >>>>>>>>> not be estimated due to zero count'.
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> And by the way I have seen this comparison being generated
> >> >> >> >>>>>>>>> using other stats.
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Thanks in advance,
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> Frank
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> [[alternative HTML version deleted]]
> >> >> >> >>>>>>>>>
> >> >> >> >>>>>>>>> _______________________________________________
> >> >> >> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list
> >> >> >> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >> >>>>>>>> _______________________________________________
> >> >> >> >>>>>>>> R-sig-mixed-models at r-project.org mailing list
> >> >> >> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >> >>>>>>>
> >> >> >> >>>>>>
> >> >> >> >
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>>
> >> >> >> >>> --
> >> >> >> >>> Sent from Gmail for IPhone
> >> >> >> >>
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >>
> >> >> >
> >> >> >
> >> >> >
> >> >> > --
> >> >> > Frank Romano Ph.D.
> >> >> >
> >> >> > Tel. +39 3911639149
> >> >> >
> >> >> > LinkedIn
> >> >> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
> >> >> >
> >> >> > Academia.edu
> >> >> > https://sheffield.academia.edu/FrancescoRomano
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > Frank Romano Ph.D.
> >> >
> >> > Tel. +39 3911639149
> >> >
> >> > LinkedIn
> >> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
> >> >
> >> > Academia.edu
> >> > https://sheffield.academia.edu/FrancescoRomano
> >
> >
> >
> >
> > --
> > Frank Romano Ph.D.
> >
> > Tel. +39 3911639149
> >
> > LinkedIn
> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
> >
> > Academia.edu
> > https://sheffield.academia.edu/FrancescoRomano




--
Frank Romano Ph.D.

Tel. +39 3911639149

LinkedIn
https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162

Academia.edu
https://sheffield.academia.edu/FrancescoRomano


From Paul.Thompson at sanfordhealth.org  Tue Oct 27 17:01:21 2015
From: Paul.Thompson at sanfordhealth.org (Thompson,Paul)
Date: Tue, 27 Oct 2015 16:01:21 +0000
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
	<CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
	<CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D970197979C6C@SFSMCEXMBX3.sanfordhealth.org>

This is a problem in SAS as well. When you specify a contrast in a 2-factor design, things get screwed up with missing cells. In fact, the contrasts require a matrix multiplication, and if a cell isn't there, the matrix multiplication does not work correctly. They are not estimable, in the SAS terminology (which is standard statistical terminology as well).

One approach that can be used is to convert the 2-factor design to a one-factor design, and do everything with contrasts, main effects, in teractions, etc. A little more work, but since you are specifying the contrasts (and presuming that you do so correctly), you will get estimable contrasts.

Marginal effects must take the missing cells into account correctly.

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Francesco Romano
Sent: Monday, October 26, 2015 6:18 AM
To: Ben Bolker; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Zero cells in contrast matrix problem

For some reason the silly bugger didn't past the full command:

> revanaA<-
bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data = revana, family = binomial, fixef.prior = normal(cov = diag(9,16))) fixed-effect model matrix is rank deficient so dropping 2 columns / coefficients Error in normal(cov = cov, common.scale = FALSE) :
  normal prior covariance of improper length

To give more info on this, it is the Animacy factor that is causing separation because two levels of it have zero counts in some cases.

On Mon, Oct 26, 2015 at 12:13 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Well, that's a separate problem (and not necessarily a "problem").   R
> is telling you that you have 16 separate combinations of the factors, 
> but only 14 unique combinations represented in your data set, so it 
> can only estimate 14 parameters.  Unless there is a weird interaction 
> with blme I don't know about, this should still give you reasonable 
> answers.
>
> On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano 
> <francescobryanromano at gmail.com> wrote:
> > Many thanks Ben,
> >
> > but I tried that already:
> >
> >> revanaA<-
> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), 
> >> data
> =
> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
> > fixed-effect model matrix is rank deficient so dropping 2 columns / 
> > coefficients Error in normal(cov = cov, common.scale = FALSE) :
> >   normal prior covariance of improper length
> >
> > On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >> On 15-10-26 06:56 AM, Francesco Romano wrote:
> >> > I wonder if anyone can help with the separation problem 
> >> > originally solved by Ben Bolker (see thread).
> >> > The model and fitting I used previously was
> >> >
> >> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family 
> >> > = binomial, fixef.prior = normal(cov = diag(9,4))
> >> >
> >> > which now has to change because the Syntax.Semantcs factor needs 
> >> > to be split into separate within-subjects variables, Syntax, a 
> >> > factor with two levels, and Animacy, a factor with four levels.
> >> > In addition a new between-subjects factor called Group with two 
> >> > levels (native vs non-native speaker) has to be added which 
> >> > determines the following model, fit by bglmer:
> >> >
> >> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+ 
> >> > (1|Part.name)+(1|Item), data = trialglm, family = binomial, 
> >> > fixef.prior = normal(cov = diag???)
> >> >
> >> > What values should I use for the cov=diag portion in order to 
> >> > continue attempting convergence of a model that includes the 
> >> > random effects?
> >>
> >>     In general a reasonable form is normal(cov = diag(v,np)) where 
> >> v is the prior variance (generally something reasonably 
> >> large/non-informative; 9 (=std dev of 3) is probably an OK default) 
> >> and np is the number of fixed-effect parameters.  You can figure 
> >> this out
> via
> >>
> >> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
> >>
> >> or multiply 2*4*2 to get 16 ...
> >>
> >> >
> >> > R returns the following error because I don't know how to 
> >> > establish
> the
> >> > parameters when more than one
> >> > fixed effect is involved:
> >> >
> >> > Error in normal(cov = cov, common.scale = FALSE) :
> >> >   normal prior covariance of improper length
> >> >
> >> > Many thanks in advance for any help!
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com>
> wrote:
> >> >
> >> >>   I don't see your data -- I see a little tiny subset, but 
> >> >> that's not really enough for a reproducible example.
> >> >>
> >> >> This is the example given in the URL I sent:
> >> >>
> >> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
> >> >>                        family=binomial,
> >> >>                        fixef.prior = normal(cov = diag(9,4)))
> >> >>
> >> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
> >> >>           data =trialglm,
> >> >>          family = binomial,
> >> >>         fixef.prior = normal(cov=diag(9,8)))
> >> >>
> >> >> The last line specifies an 8x8 matrix (because you have 8 fixed
> effect
> >> >> parameters) with a value of 9 on the diagonal, meaning the 
> >> >> priors for the fixed effects are independent and each is Normal 
> >> >> with a sd of sqrt(9)=3.
> >> >>
> >> >>
> >> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano 
> >> >> <francescobryanromano at gmail.com> wrote:
> >> >>> Yes but this seems a bit above my head without your help. The 
> >> >>> data
> are
> >> >>> in
> >> >>> the three variables at the bottom of my email but I forgot to
> mention
> >> >>> the
> >> >>> random participant effect (n = 17). Thanks!
> >> >>>
> >> >>>
> >> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha
> scritto:
> >> >>>>
> >> > On 15-05-28 06:55 AM, Francesco Romano wrote:
> >> >>>>>> Many thanks to both.
> >> >>>>>>
> >> >>>>>> The approaches you suggest (and others online) help one deal 
> >> >>>>>> with the separation problem but don't offer any specific 
> >> >>>>>> advice as to how getting a valid p coefficient when 
> >> >>>>>> comparing two levels of
> the
> >> >>>>>> model vexed by separation.
> >> >>>>>>
> >> >>>>>> Ben, here's the output of the bglmer which by the way would 
> >> >>>>>> be ideal since it allows me to retain the random effect so 
> >> >>>>>> that all
> my
> >> >>>>>> pairwise comparisons are conducted using mixed effects.
> >> >>>>>>
> >> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), 
> >> >>>>>>> data = trialglm,
> >> >>>>>> family = binomial) Warning message: package ?blme? was built
> under
> >> >>>>>> R version 3.1.2
> >> >>>>>>> summary(trial)
> >> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf, 
> >> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  : 
> >> >>>>>> 1.4371
> >> >>>>>>
> >> >>>>>> Generalized linear mixed model fit by maximum likelihood 
> >> >>>>>> (Laplace
> >> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
> >> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
> >> >>>>>>
> >> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
> >> >>>>>> 251.9      376
> >> >>>>>>
> >> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
> >> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
> >> >>>>>>
> >> >>>>>> Random effects: Groups    Name        Variance Std.Dev. Part.name
> >> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:
> Part.name,
> >> >>>>>> 16
> >> >>>>>>
> >> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
> >> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
> >> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323
>  0.7462
> >> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
> >> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
> >> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
> >> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
> >> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 
> >> >>>>>> 1
> >> >>>>>>
> >> >>>>>> Unfortunately the separation problem is still there. Should 
> >> >>>>>> I be constraining the parameter somehow? How would I do 
> >> >>>>>> that? The data is below.
> >> >
> >> >    Did you read the section in the URL I suggested?  Just using 
> >> > bglmer isn't enough; you also have to set a prior on the fixed effects.
> >> >
> >> >   Your data don't seem to be attached (note that the mailing list 
> >> > strips most non-ASCII file types).
> >> >
> >> >>>>>>
> >> >>>>>> In passing I also tried brglm which solves the separation 
> >> >>>>>> problem but tells me comparison is significant which I don't 
> >> >>>>>> believe one bit (see the data below). I am pretty sure about 
> >> >>>>>> this because
> when
> >> >>>>>> I reveled and look at the comparisons I was able to compute 
> >> >>>>>> using glmer, these turn out to be non-significant, when 
> >> >>>>>> glmer told me they were:
> >> >>>>>>
> >> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, 
> >> >>>>>>> family =
> >> >>>>>> binomial) Warning messages: 1: package ?elrm? was built 
> >> >>>>>> under R version 3.1.2 2: package ?coda? was built under R 
> >> >>>>>> version 3.1.3
> >> >>>>>>> summary(trial)
> >> >>>>>>
> >> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family = 
> >> >>>>>> binomial, data = trialglm)
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A
>  0.6689
> >> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
> >> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
> >> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
> >> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
> >> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
> >> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 ---
> Signif.
> >> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >>>>>>
> >> >>>>>> (Dispersion parameter for binomial family taken to be 1)
> >> >>>>>>
> >> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
> >> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized deviance:
> >> >>>>>> 245.5554 AIC:  272.22
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> MCMCglmm is too complex for me.
> >> >>>>>>
> >> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
> >> >>>>>> function) but output is hard to read:
> >> >>>>>>
> >> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm, 
> >> >>>>>>> family =
> >> >>>>>> binomial) Warning messages: 1: package ?logistf? was built 
> >> >>>>>> under
> R
> >> >>>>>> version 3.1.2 2: package ?mice? was built under R version 
> >> >>>>>> 3.1.2
> >> >>>>>>> summary(trial)
> >> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data = 
> >> >>>>>> trialglm, family = binomial)
> >> >>>>>>
> >> >>>>>> Model fitted by Penalized ML Confidence intervals and 
> >> >>>>>> p-values by Profile Likelihood Profile Likelihood Profile 
> >> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile 
> >> >>>>>> Likelihood Profile
> Likelihood
> >> >>>>>> Profile Likelihood
> >> >>>>>>
> >> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p
> (Intercept)
> >> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 
> >> >>>>>> 1.000000e+00 Syntax.Semantics A  4.1767737 6.3254344  
> >> >>>>>> 0.4224696 12.0673987
> >> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 
> >> >>>>>> 0.8959376
> >> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00 
> >> >>>>>> Syntax.Semantics C
> >> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 
> >> >>>>>> 1.000000e+00 Syntax.Semantics D  0.2314740 1.1563731 
> >> >>>>>> -0.1704535  0.6479908
> >> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 
> >> >>>>>> 0.9771824
> >> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00 
> >> >>>>>> Syntax.Semantics F
> >> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 
> >> >>>>>> 1.000000e+00 Syntax.Semantics G  0.9909046 1.3787175  
> >> >>>>>> 0.5457741  1.5353981
> >> >>>>>> 0.000000 1.000000e+00
> >> >>>>>>
> >> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test 
> >> >>>>>> =
> >> >>>>>> 5.334321 on 7 df, p = 0.6192356
> >> >>>>>>
> >> >>>>>> In particular, what is this model telling me? That Z (my ref
> level)
> >> >>>>>> and B are significantly different?
> >> >>>>>>
> >> >>>>>> I'm happy to try the elrm function with exact logistic 
> >> >>>>>> regression but I am not capable of programming it. Besides, 
> >> >>>>>> would it give me valid estimates for the comparison between the Z and B levels?
> The
> >> >>>>>> data frame should look like this:
> >> >>>>>>
> >> >>>>>> Outcome variable (Correct, incorrect) Predictor variable (A, 
> >> >>>>>> B,
> C,
> >> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
> >> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
> >> >>>>>>
> >> >>>>>> Thank you! F.
> >> >>>>>>
> >> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker 
> >> >>>>>> <bbolker at gmail.com>
> >> >>>>>> wrote:
> >> >>>>>>
> >> >>>>>>> And for what it's worth, you can do this in conjunction 
> >> >>>>>>> with
> lme4
> >> >>>>>>> by using the blme package instead (a thin Bayesian wrapper
> around
> >> >>>>>>> lme4), or via the MCMCglmm package; see
> >> >>>>>>>
> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
> >> >>>>>>> for an example (search for "complete separation").
> >> >>>>>>>
> >> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang 
> >> >>>>>>> (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >> >>>>>>>> You may need to consider using an 'exact', Bayesian, or 
> >> >>>>>>>> penalized
> >> >>>>>>> likelihood approach (along the lines proposed by Firth).
> >> >>>>>>>>
> >> >>>>>>>> Maybe a place to start:
> >> >>>>>>>
> >> >>>>>>>
> >> >>>
> >> >>>
> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regres
> sion.html
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>
> >> > Best,
> >> >>>>>>>> Wolfgang
> >> >>>>>>>>
> >> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
> >> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On 
> >> >>>>>>>>> Behalf Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
> >> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero 
> >> >>>>>>>>> cells in contrast matrix problem
> >> >>>>>>>>>
> >> >>>>>>>>> After giving up on a glmer for my data, I remembered a 
> >> >>>>>>>>> post by Roger
> >> >>>>>>> Levy
> >> >>>>>>>>> suggesting to try the use non mixed effects glm when one 
> >> >>>>>>>>> of the cells in a matrix is zero.
> >> >>>>>>>>>
> >> >>>>>>>>> To put this into perspective:
> >> >>>>>>>>>
> >> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | 
> >> >>>>>>>>>> Part.name), data =
> >> >>>>>>>>> trialglm, family = binomial)
> >> >>>>>>>>>
> >> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"), 
> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to 
> >> >>>>>>>>> converge with max|grad| = 0.053657 (tol = 0.001, 
> >> >>>>>>>>> component 4) 2: In checkConv(attr(opt, "derivs"), 
> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model is nearly 
> >> >>>>>>>>> unidentifiable: large eigenvalue ratio - Rescale variables?
> >> >>>>>>>>>
> >> >>>>>>>>> My data has a binary outcome, correct or incorrect, a 
> >> >>>>>>>>> fixed effect predictor factor with 8 levels, and a random 
> >> >>>>>>>>> effect for participants. I believe the problem R is 
> >> >>>>>>>>> encountering is with one level of the factor (let us call 
> >> >>>>>>>>> it level B) which has no counts (no I won' t try to post 
> >> >>>>>>>>> the table from the paper with the counts because I know 
> >> >>>>>>>>> it will get garbled up!).
> >> >>>>>>>>>
> >> >>>>>>>>> I attempt a glm with the same data:
> >> >>>>>>>>>
> >> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm, 
> >> >>>>>>>>>> family =
> >> >>>>>>>>> binomial)
> >> >>>>>>>>>> anova(trial)
> >> >>>>>>>>> Analysis of Deviance Table
> >> >>>>>>>>>
> >> >>>>>>>>> Model: binomial, link: logit
> >> >>>>>>>>>
> >> >>>>>>>>> Response: Correct
> >> >>>>>>>>>
> >> >>>>>>>>> Terms added sequentially (first to last)
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
> >> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
> >> >>>>>>>>> 254.97
> >> >>>>>>>>>> summary(trial)
> >> >>>>>>>>>
> >> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family = 
> >> >>>>>>>>> binomial, data = trialglm)
> >> >>>>>>>>>
> >> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
> >> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
> >> >>>>>>>>>
> >> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
> >> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
> >> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
> >> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
> >> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
> >> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
> >> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
> >> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
> >> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
> >> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 
> >> >>>>>>>>> 0.05 ?.? 0.1 ? ? 1
> >> >>>>>>>>>
> >> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
> >> >>>>>>>>>
> >> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom 
> >> >>>>>>>>> Residual
> >> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
> >> >>>>>>>>>
> >> >>>>>>>>> Number of Fisher Scoring iterations: 17
> >> >>>>>>>>>
> >> >>>>>>>>> The comparison I'm interested in is between level B and 
> >> >>>>>>>>> the reference level but it cannot be estimated as shown 
> >> >>>>>>>>> by the ridiculously high estimate and SE value.
> >> >>>>>>>>>
> >> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
> >> >>>>>>>>> It's the only comparison missing in the table for the 
> >> >>>>>>>>> levels I need so I think it
> >> >>>>>>> would
> >> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the 
> >> >>>>>>>>> difference
> >> >>>>>>> could
> >> >>>>>>>>> not be estimated due to zero count'.
> >> >>>>>>>>>
> >> >>>>>>>>> And by the way I have seen this comparison being 
> >> >>>>>>>>> generated using other stats.
> >> >>>>>>>>>
> >> >>>>>>>>> Thanks in advance,
> >> >>>>>>>>>
> >> >>>>>>>>> Frank
> >> >>>>>>>>>
> >> >>>>>>>>> [[alternative HTML version deleted]]
> >> >>>>>>>>>
> >> >>>>>>>>> _______________________________________________
> >> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list 
> >> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>>>>>>> _______________________________________________
> >> >>>>>>>> R-sig-mixed-models at r-project.org mailing list 
> >> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>>>>>>
> >> >>>>>>
> >> >
> >> >>>
> >> >>>
> >> >>>
> >> >>> --
> >> >>> Sent from Gmail for IPhone
> >> >>
> >> >
> >> >
> >> >
> >>
> >
> >
> >
> > --
> > Frank Romano Ph.D.
> >
> > Tel. +39 3911639149
> >
> > LinkedIn
> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
> >
> > Academia.edu
> > https://sheffield.academia.edu/FrancescoRomano
>



--
Frank Romano Ph.D.

Tel. +39 3911639149

*LinkedIn*
https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162

*Academia.edu*
https://sheffield.academia.edu/FrancescoRomano

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.

From bbolker at gmail.com  Tue Oct 27 17:06:37 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 27 Oct 2015 12:06:37 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D970197979C6C@SFSMCEXMBX3.sanfordhealth.org>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
	<CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
	<CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D970197979C6C@SFSMCEXMBX3.sanfordhealth.org>
Message-ID: <CABghstSRdBJ6x0SZn14pQvExyAihziF-89fA0Re=3PiwKL15iw@mail.gmail.com>

I think this isn't as much of a problem as you think.  lme4
automatically drops non-estimable columns in the model matrix.  The
problem is just getting it to work right with blme.  (But yes,
collapsing this into a one-way design is one way of proceeding ...)

On Tue, Oct 27, 2015 at 12:01 PM, Thompson,Paul
<Paul.Thompson at sanfordhealth.org> wrote:
> This is a problem in SAS as well. When you specify a contrast in a 2-factor design, things get screwed up with missing cells. In fact, the contrasts require a matrix multiplication, and if a cell isn't there, the matrix multiplication does not work correctly. They are not estimable, in the SAS terminology (which is standard statistical terminology as well).
>
> One approach that can be used is to convert the 2-factor design to a one-factor design, and do everything with contrasts, main effects, in teractions, etc. A little more work, but since you are specifying the contrasts (and presuming that you do so correctly), you will get estimable contrasts.
>
> Marginal effects must take the missing cells into account correctly.
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Francesco Romano
> Sent: Monday, October 26, 2015 6:18 AM
> To: Ben Bolker; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Zero cells in contrast matrix problem
>
> For some reason the silly bugger didn't past the full command:
>
>> revanaA<-
> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data = revana, family = binomial, fixef.prior = normal(cov = diag(9,16))) fixed-effect model matrix is rank deficient so dropping 2 columns / coefficients Error in normal(cov = cov, common.scale = FALSE) :
>   normal prior covariance of improper length
>
> To give more info on this, it is the Animacy factor that is causing separation because two levels of it have zero counts in some cases.
>
> On Mon, Oct 26, 2015 at 12:13 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> Well, that's a separate problem (and not necessarily a "problem").   R
>> is telling you that you have 16 separate combinations of the factors,
>> but only 14 unique combinations represented in your data set, so it
>> can only estimate 14 parameters.  Unless there is a weird interaction
>> with blme I don't know about, this should still give you reasonable
>> answers.
>>
>> On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano
>> <francescobryanromano at gmail.com> wrote:
>> > Many thanks Ben,
>> >
>> > but I tried that already:
>> >
>> >> revanaA<-
>> >> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item),
>> >> data
>> =
>> >> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
>> > fixed-effect model matrix is rank deficient so dropping 2 columns /
>> > coefficients Error in normal(cov = cov, common.scale = FALSE) :
>> >   normal prior covariance of improper length
>> >
>> > On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> >>
>> >> On 15-10-26 06:56 AM, Francesco Romano wrote:
>> >> > I wonder if anyone can help with the separation problem
>> >> > originally solved by Ben Bolker (see thread).
>> >> > The model and fitting I used previously was
>> >> >
>> >> > trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family
>> >> > = binomial, fixef.prior = normal(cov = diag(9,4))
>> >> >
>> >> > which now has to change because the Syntax.Semantcs factor needs
>> >> > to be split into separate within-subjects variables, Syntax, a
>> >> > factor with two levels, and Animacy, a factor with four levels.
>> >> > In addition a new between-subjects factor called Group with two
>> >> > levels (native vs non-native speaker) has to be added which
>> >> > determines the following model, fit by bglmer:
>> >> >
>> >> > trial<-bglmer(Correct ~ Syntax*Animacy*Group+
>> >> > (1|Part.name)+(1|Item), data = trialglm, family = binomial,
>> >> > fixef.prior = normal(cov = diag???)
>> >> >
>> >> > What values should I use for the cov=diag portion in order to
>> >> > continue attempting convergence of a model that includes the
>> >> > random effects?
>> >>
>> >>     In general a reasonable form is normal(cov = diag(v,np)) where
>> >> v is the prior variance (generally something reasonably
>> >> large/non-informative; 9 (=std dev of 3) is probably an OK default)
>> >> and np is the number of fixed-effect parameters.  You can figure
>> >> this out
>> via
>> >>
>> >> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
>> >>
>> >> or multiply 2*4*2 to get 16 ...
>> >>
>> >> >
>> >> > R returns the following error because I don't know how to
>> >> > establish
>> the
>> >> > parameters when more than one
>> >> > fixed effect is involved:
>> >> >
>> >> > Error in normal(cov = cov, common.scale = FALSE) :
>> >> >   normal prior covariance of improper length
>> >> >
>> >> > Many thanks in advance for any help!
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com>
>> wrote:
>> >> >
>> >> >>   I don't see your data -- I see a little tiny subset, but
>> >> >> that's not really enough for a reproducible example.
>> >> >>
>> >> >> This is the example given in the URL I sent:
>> >> >>
>> >> >> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
>> >> >>                        family=binomial,
>> >> >>                        fixef.prior = normal(cov = diag(9,4)))
>> >> >>
>> >> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>> >> >>           data =trialglm,
>> >> >>          family = binomial,
>> >> >>         fixef.prior = normal(cov=diag(9,8)))
>> >> >>
>> >> >> The last line specifies an 8x8 matrix (because you have 8 fixed
>> effect
>> >> >> parameters) with a value of 9 on the diagonal, meaning the
>> >> >> priors for the fixed effects are independent and each is Normal
>> >> >> with a sd of sqrt(9)=3.
>> >> >>
>> >> >>
>> >> >> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
>> >> >> <francescobryanromano at gmail.com> wrote:
>> >> >>> Yes but this seems a bit above my head without your help. The
>> >> >>> data
>> are
>> >> >>> in
>> >> >>> the three variables at the bottom of my email but I forgot to
>> mention
>> >> >>> the
>> >> >>> random participant effect (n = 17). Thanks!
>> >> >>>
>> >> >>>
>> >> >>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha
>> scritto:
>> >> >>>>
>> >> > On 15-05-28 06:55 AM, Francesco Romano wrote:
>> >> >>>>>> Many thanks to both.
>> >> >>>>>>
>> >> >>>>>> The approaches you suggest (and others online) help one deal
>> >> >>>>>> with the separation problem but don't offer any specific
>> >> >>>>>> advice as to how getting a valid p coefficient when
>> >> >>>>>> comparing two levels of
>> the
>> >> >>>>>> model vexed by separation.
>> >> >>>>>>
>> >> >>>>>> Ben, here's the output of the bglmer which by the way would
>> >> >>>>>> be ideal since it allows me to retain the random effect so
>> >> >>>>>> that all
>> my
>> >> >>>>>> pairwise comparisons are conducted using mixed effects.
>> >> >>>>>>
>> >> >>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>> >> >>>>>>> data = trialglm,
>> >> >>>>>> family = binomial) Warning message: package ?blme? was built
>> under
>> >> >>>>>> R version 3.1.2
>> >> >>>>>>> summary(trial)
>> >> >>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
>> >> >>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  :
>> >> >>>>>> 1.4371
>> >> >>>>>>
>> >> >>>>>> Generalized linear mixed model fit by maximum likelihood
>> >> >>>>>> (Laplace
>> >> >>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
>> >> >>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
>> >> >>>>>>
>> >> >>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
>> >> >>>>>> 251.9      376
>> >> >>>>>>
>> >> >>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
>> >> >>>>>> -0.4281 -0.2445 -0.0002  5.7872
>> >> >>>>>>
>> >> >>>>>> Random effects: Groups    Name        Variance Std.Dev. Part.name
>> >> >>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:
>> Part.name,
>> >> >>>>>> 16
>> >> >>>>>>
>> >> >>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> >> >>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
>> >> >>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
>> >> >>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323
>>  0.7462
>> >> >>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
>> >> >>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
>> >> >>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
>> >> >>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
>> >> >>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
>> >> >>>>>> 1
>> >> >>>>>>
>> >> >>>>>> Unfortunately the separation problem is still there. Should
>> >> >>>>>> I be constraining the parameter somehow? How would I do
>> >> >>>>>> that? The data is below.
>> >> >
>> >> >    Did you read the section in the URL I suggested?  Just using
>> >> > bglmer isn't enough; you also have to set a prior on the fixed effects.
>> >> >
>> >> >   Your data don't seem to be attached (note that the mailing list
>> >> > strips most non-ASCII file types).
>> >> >
>> >> >>>>>>
>> >> >>>>>> In passing I also tried brglm which solves the separation
>> >> >>>>>> problem but tells me comparison is significant which I don't
>> >> >>>>>> believe one bit (see the data below). I am pretty sure about
>> >> >>>>>> this because
>> when
>> >> >>>>>> I reveled and look at the comparisons I was able to compute
>> >> >>>>>> using glmer, these turn out to be non-significant, when
>> >> >>>>>> glmer told me they were:
>> >> >>>>>>
>> >> >>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >>>>>>> family =
>> >> >>>>>> binomial) Warning messages: 1: package ?elrm? was built
>> >> >>>>>> under R version 3.1.2 2: package ?coda? was built under R
>> >> >>>>>> version 3.1.3
>> >> >>>>>>> summary(trial)
>> >> >>>>>>
>> >> >>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
>> >> >>>>>> binomial, data = trialglm)
>> >> >>>>>>
>> >> >>>>>>
>> >> >>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> >> >>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A
>>  0.6689
>> >> >>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
>> >> >>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
>> >> >>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
>> >> >>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
>> >> >>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
>> >> >>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 ---
>> Signif.
>> >> >>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >> >>>>>>
>> >> >>>>>> (Dispersion parameter for binomial family taken to be 1)
>> >> >>>>>>
>> >> >>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
>> >> >>>>>> deviance: 256.22  on 377  degrees of freedom Penalized deviance:
>> >> >>>>>> 245.5554 AIC:  272.22
>> >> >>>>>>
>> >> >>>>>>
>> >> >>>>>> MCMCglmm is too complex for me.
>> >> >>>>>>
>> >> >>>>>> Wolfgang, I tried the penalized likelihood method (logistf
>> >> >>>>>> function) but output is hard to read:
>> >> >>>>>>
>> >> >>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >>>>>>> family =
>> >> >>>>>> binomial) Warning messages: 1: package ?logistf? was built
>> >> >>>>>> under
>> R
>> >> >>>>>> version 3.1.2 2: package ?mice? was built under R version
>> >> >>>>>> 3.1.2
>> >> >>>>>>> summary(trial)
>> >> >>>>>> logistf(formula = Correct ~ Syntax.Semantics, data =
>> >> >>>>>> trialglm, family = binomial)
>> >> >>>>>>
>> >> >>>>>> Model fitted by Penalized ML Confidence intervals and
>> >> >>>>>> p-values by Profile Likelihood Profile Likelihood Profile
>> >> >>>>>> Likelihood Profile Likelihood Profile Likelihood Profile
>> >> >>>>>> Likelihood Profile
>> Likelihood
>> >> >>>>>> Profile Likelihood
>> >> >>>>>>
>> >> >>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p
>> (Intercept)
>> >> >>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000
>> >> >>>>>> 1.000000e+00 Syntax.Semantics A  4.1767737 6.3254344
>> >> >>>>>> 0.4224696 12.0673987
>> >> >>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602
>> >> >>>>>> 0.8959376
>> >> >>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00
>> >> >>>>>> Syntax.Semantics C
>> >> >>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000
>> >> >>>>>> 1.000000e+00 Syntax.Semantics D  0.2314740 1.1563731
>> >> >>>>>> -0.1704535  0.6479908
>> >> >>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907
>> >> >>>>>> 0.9771824
>> >> >>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00
>> >> >>>>>> Syntax.Semantics F
>> >> >>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000
>> >> >>>>>> 1.000000e+00 Syntax.Semantics G  0.9909046 1.3787175
>> >> >>>>>> 0.5457741  1.5353981
>> >> >>>>>> 0.000000 1.000000e+00
>> >> >>>>>>
>> >> >>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test
>> >> >>>>>> =
>> >> >>>>>> 5.334321 on 7 df, p = 0.6192356
>> >> >>>>>>
>> >> >>>>>> In particular, what is this model telling me? That Z (my ref
>> level)
>> >> >>>>>> and B are significantly different?
>> >> >>>>>>
>> >> >>>>>> I'm happy to try the elrm function with exact logistic
>> >> >>>>>> regression but I am not capable of programming it. Besides,
>> >> >>>>>> would it give me valid estimates for the comparison between the Z and B levels?
>> The
>> >> >>>>>> data frame should look like this:
>> >> >>>>>>
>> >> >>>>>> Outcome variable (Correct, incorrect) Predictor variable (A,
>> >> >>>>>> B,
>> C,
>> >> >>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
>> >> >>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
>> >> >>>>>>
>> >> >>>>>> Thank you! F.
>> >> >>>>>>
>> >> >>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker
>> >> >>>>>> <bbolker at gmail.com>
>> >> >>>>>> wrote:
>> >> >>>>>>
>> >> >>>>>>> And for what it's worth, you can do this in conjunction
>> >> >>>>>>> with
>> lme4
>> >> >>>>>>> by using the blme package instead (a thin Bayesian wrapper
>> around
>> >> >>>>>>> lme4), or via the MCMCglmm package; see
>> >> >>>>>>>
>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>> >> >>>>>>> for an example (search for "complete separation").
>> >> >>>>>>>
>> >> >>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang
>> >> >>>>>>> (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >> >>>>>>>> You may need to consider using an 'exact', Bayesian, or
>> >> >>>>>>>> penalized
>> >> >>>>>>> likelihood approach (along the lines proposed by Firth).
>> >> >>>>>>>>
>> >> >>>>>>>> Maybe a place to start:
>> >> >>>>>>>
>> >> >>>>>>>
>> >> >>>
>> >> >>>
>> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regres
>> sion.html
>> >> >>>>>>>>
>> >> >>>>>>>>
>> >> >>>>>>>
>> >> > Best,
>> >> >>>>>>>> Wolfgang
>> >> >>>>>>>>
>> >> >>>>>>>>> -----Original Message----- From: R-sig-mixed-models
>> >> >>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On
>> >> >>>>>>>>> Behalf Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
>> >> >>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>> >> >>>>>>>>> cells in contrast matrix problem
>> >> >>>>>>>>>
>> >> >>>>>>>>> After giving up on a glmer for my data, I remembered a
>> >> >>>>>>>>> post by Roger
>> >> >>>>>>> Levy
>> >> >>>>>>>>> suggesting to try the use non mixed effects glm when one
>> >> >>>>>>>>> of the cells in a matrix is zero.
>> >> >>>>>>>>>
>> >> >>>>>>>>> To put this into perspective:
>> >> >>>>>>>>>
>> >> >>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 |
>> >> >>>>>>>>>> Part.name), data =
>> >> >>>>>>>>> trialglm, family = binomial)
>> >> >>>>>>>>>
>> >> >>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to
>> >> >>>>>>>>> converge with max|grad| = 0.053657 (tol = 0.001,
>> >> >>>>>>>>> component 4) 2: In checkConv(attr(opt, "derivs"),
>> >> >>>>>>>>> opt$par, ctrl = control$checkConv, : Model is nearly
>> >> >>>>>>>>> unidentifiable: large eigenvalue ratio - Rescale variables?
>> >> >>>>>>>>>
>> >> >>>>>>>>> My data has a binary outcome, correct or incorrect, a
>> >> >>>>>>>>> fixed effect predictor factor with 8 levels, and a random
>> >> >>>>>>>>> effect for participants. I believe the problem R is
>> >> >>>>>>>>> encountering is with one level of the factor (let us call
>> >> >>>>>>>>> it level B) which has no counts (no I won' t try to post
>> >> >>>>>>>>> the table from the paper with the counts because I know
>> >> >>>>>>>>> it will get garbled up!).
>> >> >>>>>>>>>
>> >> >>>>>>>>> I attempt a glm with the same data:
>> >> >>>>>>>>>
>> >> >>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>> >> >>>>>>>>>> family =
>> >> >>>>>>>>> binomial)
>> >> >>>>>>>>>> anova(trial)
>> >> >>>>>>>>> Analysis of Deviance Table
>> >> >>>>>>>>>
>> >> >>>>>>>>> Model: binomial, link: logit
>> >> >>>>>>>>>
>> >> >>>>>>>>> Response: Correct
>> >> >>>>>>>>>
>> >> >>>>>>>>> Terms added sequentially (first to last)
>> >> >>>>>>>>>
>> >> >>>>>>>>>
>> >> >>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
>> >> >>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
>> >> >>>>>>>>> 254.97
>> >> >>>>>>>>>> summary(trial)
>> >> >>>>>>>>>
>> >> >>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>> >> >>>>>>>>> binomial, data = trialglm)
>> >> >>>>>>>>>
>> >> >>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
>> >> >>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>> >> >>>>>>>>>
>> >> >>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>> >> >>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
>> >> >>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
>> >> >>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>> >> >>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>> >> >>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>> >> >>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>> >> >>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>> >> >>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>> >> >>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*?
>> >> >>>>>>>>> 0.05 ?.? 0.1 ? ? 1
>> >> >>>>>>>>>
>> >> >>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
>> >> >>>>>>>>>
>> >> >>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom
>> >> >>>>>>>>> Residual
>> >> >>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>> >> >>>>>>>>>
>> >> >>>>>>>>> Number of Fisher Scoring iterations: 17
>> >> >>>>>>>>>
>> >> >>>>>>>>> The comparison I'm interested in is between level B and
>> >> >>>>>>>>> the reference level but it cannot be estimated as shown
>> >> >>>>>>>>> by the ridiculously high estimate and SE value.
>> >> >>>>>>>>>
>> >> >>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
>> >> >>>>>>>>> It's the only comparison missing in the table for the
>> >> >>>>>>>>> levels I need so I think it
>> >> >>>>>>> would
>> >> >>>>>>>>> be a bit unacademic of me to close this deal saying 'the
>> >> >>>>>>>>> difference
>> >> >>>>>>> could
>> >> >>>>>>>>> not be estimated due to zero count'.
>> >> >>>>>>>>>
>> >> >>>>>>>>> And by the way I have seen this comparison being
>> >> >>>>>>>>> generated using other stats.
>> >> >>>>>>>>>
>> >> >>>>>>>>> Thanks in advance,
>> >> >>>>>>>>>
>> >> >>>>>>>>> Frank
>> >> >>>>>>>>>
>> >> >>>>>>>>> [[alternative HTML version deleted]]
>> >> >>>>>>>>>
>> >> >>>>>>>>> _______________________________________________
>> >> >>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >>>>>>>> _______________________________________________
>> >> >>>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >>>>>>>
>> >> >>>>>>
>> >> >
>> >> >>>
>> >> >>>
>> >> >>>
>> >> >>> --
>> >> >>> Sent from Gmail for IPhone
>> >> >>
>> >> >
>> >> >
>> >> >
>> >>
>> >
>> >
>> >
>> > --
>> > Frank Romano Ph.D.
>> >
>> > Tel. +39 3911639149
>> >
>> > LinkedIn
>> > https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>> >
>> > Academia.edu
>> > https://sheffield.academia.edu/FrancescoRomano
>>
>
>
>
> --
> Frank Romano Ph.D.
>
> Tel. +39 3911639149
>
> *LinkedIn*
> https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>
> *Academia.edu*
> https://sheffield.academia.edu/FrancescoRomano
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.


From luiggi at gmail.com  Wed Oct 28 02:57:53 2015
From: luiggi at gmail.com (Luis Damiano)
Date: Tue, 27 Oct 2015 22:57:53 -0300
Subject: [R-sig-ME] Different within-group error correlation matrices per
	group
Message-ID: <CADD=QAttMrJpR=KSuG_Ff0jSS3HAhB_8nt4ZWYQ7SeO=nziy_Q@mail.gmail.com>

Dear all,

I am working with lme and I would like to have different within-group error
correlation matrices per group (\Lambda_i in 5.1 from Pinheiro & Bates).

Currently, my sentence looks like the following

correlation = corCompSymm(form = ~ 1 | ind)


which imposes the SC structure into the within-group error correlation
matrix, marking the individuals by "ind".

According to the following example in SAS given by an instructor, it is
possible to estimate different within-group error correlation matrices per
sex using the following sentences (see "group=gender" in fourth line):

proc mixed  data=dental;
>   class  child gender;
>   model distance = gender gender*age / noint solution;
>   repeated / group=gender subject=child;
>   random intercept age / type=un subject=child g gcorr v vcorr;
> run;


I cannot figure out how to reproduce this in R. I took a look at the
documentation as well as the first five chapters of Pinheiro & Bates (2000)
without luck.

Cheers!

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Wed Oct 28 18:59:02 2015
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 28 Oct 2015 12:59:02 -0500
Subject: [R-sig-ME] Different within-group error correlation matrices
	per group
In-Reply-To: <CADD=QAttMrJpR=KSuG_Ff0jSS3HAhB_8nt4ZWYQ7SeO=nziy_Q@mail.gmail.com>
References: <CADD=QAttMrJpR=KSuG_Ff0jSS3HAhB_8nt4ZWYQ7SeO=nziy_Q@mail.gmail.com>
Message-ID: <CAKFxdiS-FroJdRi_e5QHyZ7VrheoYyu65_oAnJ=6j1X3S82-EQ@mail.gmail.com>

You might find the following links contain some useful information.

http://stackoverflow.com/questions/11819720/converting-repeated-measures-mixed-model-formula-from-sas-to-r

Factor-specific variances in R
https://rpubs.com/bbolker/6298

Harris wateruse
http://www.inside-r.org/packages/cran/agridat/docs/harris.wateruse


On Tue, Oct 27, 2015 at 8:57 PM, Luis Damiano <luiggi at gmail.com> wrote:

> Dear all,
>
> I am working with lme and I would like to have different within-group error
> correlation matrices per group (\Lambda_i in 5.1 from Pinheiro & Bates).
>
> Currently, my sentence looks like the following
>
> correlation = corCompSymm(form = ~ 1 | ind)
>
>
> which imposes the SC structure into the within-group error correlation
> matrix, marking the individuals by "ind".
>
> According to the following example in SAS given by an instructor, it is
> possible to estimate different within-group error correlation matrices per
> sex using the following sentences (see "group=gender" in fourth line):
>
> proc mixed  data=dental;
> >   class  child gender;
> >   model distance = gender gender*age / noint solution;
> >   repeated / group=gender subject=child;
> >   random intercept age / type=un subject=child g gcorr v vcorr;
> > run;
>
>
> I cannot figure out how to reproduce this in R. I took a look at the
> documentation as well as the first five chapters of Pinheiro & Bates (2000)
> without luck.
>
> Cheers!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Oct 28 21:44:55 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 28 Oct 2015 16:44:55 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+E=qLDvbdMWdEJVqOaoMQfNK7ZH7GfW508d=Fe1McOcSg@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
	<CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>
	<CABZN5+EERzumfyVBYdB1rao4JPqbQyKyVk9U2J-oEdqhmahftw@mail.gmail.com>
	<562E0939.3020904@gmail.com>
	<CABZN5+FPN2AZg2BVD6kkiC1iBDBQd+5UBRdzbJWzxeyioB=rDQ@mail.gmail.com>
	<CABghstTZvio-uBBJFv+OAB__dmXbqd-+6YOfKa8bdDx_a7Nc8w@mail.gmail.com>
	<CABZN5+Fbt+XCc1RjiKqnV2JDXmZ5PMJEUkj7uye7WJYOOtVPOQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D970197979C6C@SFSMCEXMBX3.sanfordhealth.org>
	<CABghstSRdBJ6x0SZn14pQvExyAihziF-89fA0Re=3PiwKL15iw@mail.gmail.com>
	<CABZN5+E=qLDvbdMWdEJVqOaoMQfNK7ZH7GfW508d=Fe1McOcSg@mail.gmail.com>
Message-ID: <563133C7.3010508@gmail.com>

  Please keep r-sig-mixed-models in the cc: list ... thanks.

  I think you might have misrepresented the numbers of levels per
category slightly -- you said "Syntax, a factor with two levels, and
Animacy, a factor with four levels. In addition a new between-subjects
factor called Group with two levels (native vs non-native speaker) has
to be added".  If this is really the case, I don't see how you could get
22 fixed-effect variables (you should get a max of 2*4*2).  Maybe one of
these factors really has three levels, which would lead to 24-2
collinear = 22 ?

  If the collinearity is too high for your comfort, you could try
strengthening the prior a bit (i.e. make the variance of the prior
smaller).

On 15-10-28 01:56 PM, Francesco Romano wrote:
> Well, this used to be a single variable but the reviewers asked for a split.
> Ben, it turns out the magic number was...22
> Now, I've managed to obtain a model with random intercepts
> despite a few warnings being flagged up by R
> 
> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data =
> revana, family = binomial, fixef.prior = normal(cov = diag(9,22)),
> control=glmerControl(optCtrl=list(maxfun=100000))
> 
> but if you call up the full correlation table -you'll need vcov(name of
> model)- you'll see a good number of high intercorrelated fixed effects.
> Would you suggest I drop this structure for something simpler?
> Anything more complex takes ages to stop, in fact I've quit all of them.
> 
> I attach the data in cvs. Thanks again for any help you might have to offer.
> 
> 
> On Tue, Oct 27, 2015 at 5:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> I think this isn't as much of a problem as you think.  lme4
>> automatically drops non-estimable columns in the model matrix.  The
>> problem is just getting it to work right with blme.  (But yes,
>> collapsing this into a one-way design is one way of proceeding ...)
>>
>> On Tue, Oct 27, 2015 at 12:01 PM, Thompson,Paul
>> <Paul.Thompson at sanfordhealth.org> wrote:
>>> This is a problem in SAS as well. When you specify a contrast in a
>> 2-factor design, things get screwed up with missing cells. In fact, the
>> contrasts require a matrix multiplication, and if a cell isn't there, the
>> matrix multiplication does not work correctly. They are not estimable, in
>> the SAS terminology (which is standard statistical terminology as well).
>>>
>>> One approach that can be used is to convert the 2-factor design to a
>> one-factor design, and do everything with contrasts, main effects, in
>> teractions, etc. A little more work, but since you are specifying the
>> contrasts (and presuming that you do so correctly), you will get estimable
>> contrasts.
>>>
>>> Marginal effects must take the missing cells into account correctly.
>>>
>>> -----Original Message-----
>>> From: R-sig-mixed-models [mailto:
>> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Francesco Romano
>>> Sent: Monday, October 26, 2015 6:18 AM
>>> To: Ben Bolker; r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] Zero cells in contrast matrix problem
>>>
>>> For some reason the silly bugger didn't past the full command:
>>>
>>>> revanaA<-
>>> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item), data
>> = revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
>> fixed-effect model matrix is rank deficient so dropping 2 columns /
>> coefficients Error in normal(cov = cov, common.scale = FALSE) :
>>>   normal prior covariance of improper length
>>>
>>> To give more info on this, it is the Animacy factor that is causing
>> separation because two levels of it have zero counts in some cases.
>>>
>>> On Mon, Oct 26, 2015 at 12:13 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>> Well, that's a separate problem (and not necessarily a "problem").   R
>>>> is telling you that you have 16 separate combinations of the factors,
>>>> but only 14 unique combinations represented in your data set, so it
>>>> can only estimate 14 parameters.  Unless there is a weird interaction
>>>> with blme I don't know about, this should still give you reasonable
>>>> answers.
>>>>
>>>> On Mon, Oct 26, 2015 at 7:10 AM, Francesco Romano
>>>> <francescobryanromano at gmail.com> wrote:
>>>>> Many thanks Ben,
>>>>>
>>>>> but I tried that already:
>>>>>
>>>>>> revanaA<-
>>>>>> bglmer(Correct~Syntax*Animacy*Prof.group.2+(1|Part.name)+(1|Item),
>>>>>> data
>>>> =
>>>>>> revana, family = binomial, fixef.prior = normal(cov = diag(9,16)))
>>>>> fixed-effect model matrix is rank deficient so dropping 2 columns /
>>>>> coefficients Error in normal(cov = cov, common.scale = FALSE) :
>>>>>   normal prior covariance of improper length
>>>>>
>>>>> On Mon, Oct 26, 2015 at 12:06 PM, Ben Bolker <bbolker at gmail.com>
>> wrote:
>>>>>>
>>>>>> On 15-10-26 06:56 AM, Francesco Romano wrote:
>>>>>>> I wonder if anyone can help with the separation problem
>>>>>>> originally solved by Ben Bolker (see thread).
>>>>>>> The model and fitting I used previously was
>>>>>>>
>>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics, data = trialglm, family
>>>>>>> = binomial, fixef.prior = normal(cov = diag(9,4))
>>>>>>>
>>>>>>> which now has to change because the Syntax.Semantcs factor needs
>>>>>>> to be split into separate within-subjects variables, Syntax, a
>>>>>>> factor with two levels, and Animacy, a factor with four levels.
>>>>>>> In addition a new between-subjects factor called Group with two
>>>>>>> levels (native vs non-native speaker) has to be added which
>>>>>>> determines the following model, fit by bglmer:
>>>>>>>
>>>>>>> trial<-bglmer(Correct ~ Syntax*Animacy*Group+
>>>>>>> (1|Part.name)+(1|Item), data = trialglm, family = binomial,
>>>>>>> fixef.prior = normal(cov = diag???)
>>>>>>>
>>>>>>> What values should I use for the cov=diag portion in order to
>>>>>>> continue attempting convergence of a model that includes the
>>>>>>> random effects?
>>>>>>
>>>>>>     In general a reasonable form is normal(cov = diag(v,np)) where
>>>>>> v is the prior variance (generally something reasonably
>>>>>> large/non-informative; 9 (=std dev of 3) is probably an OK default)
>>>>>> and np is the number of fixed-effect parameters.  You can figure
>>>>>> this out
>>>> via
>>>>>>
>>>>>> ncol(model.matrix(~Syntax*Animacy*Group,data=trialglm)
>>>>>>
>>>>>> or multiply 2*4*2 to get 16 ...
>>>>>>
>>>>>>>
>>>>>>> R returns the following error because I don't know how to
>>>>>>> establish
>>>> the
>>>>>>> parameters when more than one
>>>>>>> fixed effect is involved:
>>>>>>>
>>>>>>> Error in normal(cov = cov, common.scale = FALSE) :
>>>>>>>   normal prior covariance of improper length
>>>>>>>
>>>>>>> Many thanks in advance for any help!
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Thu, May 28, 2015 at 10:46 PM, Ben Bolker <bbolker at gmail.com>
>>>> wrote:
>>>>>>>
>>>>>>>>   I don't see your data -- I see a little tiny subset, but
>>>>>>>> that's not really enough for a reproducible example.
>>>>>>>>
>>>>>>>> This is the example given in the URL I sent:
>>>>>>>>
>>>>>>>> cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
>>>>>>>>                        family=binomial,
>>>>>>>>                        fixef.prior = normal(cov = diag(9,4)))
>>>>>>>>
>>>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>>>>>>>>           data =trialglm,
>>>>>>>>          family = binomial,
>>>>>>>>         fixef.prior = normal(cov=diag(9,8)))
>>>>>>>>
>>>>>>>> The last line specifies an 8x8 matrix (because you have 8 fixed
>>>> effect
>>>>>>>> parameters) with a value of 9 on the diagonal, meaning the
>>>>>>>> priors for the fixed effects are independent and each is Normal
>>>>>>>> with a sd of sqrt(9)=3.
>>>>>>>>
>>>>>>>>
>>>>>>>> On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
>>>>>>>> <francescobryanromano at gmail.com> wrote:
>>>>>>>>> Yes but this seems a bit above my head without your help. The
>>>>>>>>> data
>>>> are
>>>>>>>>> in
>>>>>>>>> the three variables at the bottom of my email but I forgot to
>>>> mention
>>>>>>>>> the
>>>>>>>>> random participant effect (n = 17). Thanks!
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha
>>>> scritto:
>>>>>>>>>>
>>>>>>> On 15-05-28 06:55 AM, Francesco Romano wrote:
>>>>>>>>>>>> Many thanks to both.
>>>>>>>>>>>>
>>>>>>>>>>>> The approaches you suggest (and others online) help one deal
>>>>>>>>>>>> with the separation problem but don't offer any specific
>>>>>>>>>>>> advice as to how getting a valid p coefficient when
>>>>>>>>>>>> comparing two levels of
>>>> the
>>>>>>>>>>>> model vexed by separation.
>>>>>>>>>>>>
>>>>>>>>>>>> Ben, here's the output of the bglmer which by the way would
>>>>>>>>>>>> be ideal since it allows me to retain the random effect so
>>>>>>>>>>>> that all
>>>> my
>>>>>>>>>>>> pairwise comparisons are conducted using mixed effects.
>>>>>>>>>>>>
>>>>>>>>>>>>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
>>>>>>>>>>>>> data = trialglm,
>>>>>>>>>>>> family = binomial) Warning message: package ?blme? was built
>>>> under
>>>>>>>>>>>> R version 3.1.2
>>>>>>>>>>>>> summary(trial)
>>>>>>>>>>>> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
>>>>>>>>>>>> posterior.scale = cov, common.scale = TRUE) Prior dev  :
>>>>>>>>>>>> 1.4371
>>>>>>>>>>>>
>>>>>>>>>>>> Generalized linear mixed model fit by maximum likelihood
>>>>>>>>>>>> (Laplace
>>>>>>>>>>>> Approximation) ['bglmerMod'] Family: binomial  ( logit )
>> Formula:
>>>>>>>>>>>> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
>>>>>>>>>>>>
>>>>>>>>>>>> AIC      BIC   logLik deviance df.resid 269.9    305.5
>>  -126.0
>>>>>>>>>>>> 251.9      376
>>>>>>>>>>>>
>>>>>>>>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
>>>>>>>>>>>> -0.4281 -0.2445 -0.0002  5.7872
>>>>>>>>>>>>
>>>>>>>>>>>> Random effects: Groups    Name        Variance Std.Dev.
>> Part.name
>>>>>>>>>>>> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:
>>>> Part.name,
>>>>>>>>>>>> 16
>>>>>>>>>>>>
>>>>>>>>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>> (Intercept)
>>>>>>>>>>>> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
>>>>>>>>>>>> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B
>> -16.4391
>>>>>>>>>>>> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323
>>>>  0.7462
>>>>>>>>>>>> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853
>>  0.306
>>>>>>>>>>>> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076
>>  0.2819
>>>>>>>>>>>> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
>>>>>>>>>>>> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
>>>>>>>>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
>>>>>>>>>>>> 1
>>>>>>>>>>>>
>>>>>>>>>>>> Unfortunately the separation problem is still there. Should
>>>>>>>>>>>> I be constraining the parameter somehow? How would I do
>>>>>>>>>>>> that? The data is below.
>>>>>>>
>>>>>>>    Did you read the section in the URL I suggested?  Just using
>>>>>>> bglmer isn't enough; you also have to set a prior on the fixed
>> effects.
>>>>>>>
>>>>>>>   Your data don't seem to be attached (note that the mailing list
>>>>>>> strips most non-ASCII file types).
>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> In passing I also tried brglm which solves the separation
>>>>>>>>>>>> problem but tells me comparison is significant which I don't
>>>>>>>>>>>> believe one bit (see the data below). I am pretty sure about
>>>>>>>>>>>> this because
>>>> when
>>>>>>>>>>>> I reveled and look at the comparisons I was able to compute
>>>>>>>>>>>> using glmer, these turn out to be non-significant, when
>>>>>>>>>>>> glmer told me they were:
>>>>>>>>>>>>
>>>>>>>>>>>>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm,
>>>>>>>>>>>>> family =
>>>>>>>>>>>> binomial) Warning messages: 1: package ?elrm? was built
>>>>>>>>>>>> under R version 3.1.2 2: package ?coda? was built under R
>>>>>>>>>>>> version 3.1.3
>>>>>>>>>>>>> summary(trial)
>>>>>>>>>>>>
>>>>>>>>>>>> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
>>>>>>>>>>>> binomial, data = trialglm)
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
>>>>>>>>>>>> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A
>>>>  0.6689
>>>>>>>>>>>> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
>>>>>>>>>>>> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889
>> -1.471
>>>>>>>>>>>> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
>>>>>>>>>>>> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
>>>>>>>>>>>> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
>>>>>>>>>>>> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 ---
>>>> Signif.
>>>>>>>>>>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>>>>>>>>
>>>>>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
>>>>>>>>>>>>
>>>>>>>>>>>> Null deviance: 262.51  on 384  degrees of freedom Residual
>>>>>>>>>>>> deviance: 256.22  on 377  degrees of freedom Penalized
>> deviance:
>>>>>>>>>>>> 245.5554 AIC:  272.22
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> MCMCglmm is too complex for me.
>>>>>>>>>>>>
>>>>>>>>>>>> Wolfgang, I tried the penalized likelihood method (logistf
>>>>>>>>>>>> function) but output is hard to read:
>>>>>>>>>>>>
>>>>>>>>>>>>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>>>>>>>>>>>>> family =
>>>>>>>>>>>> binomial) Warning messages: 1: package ?logistf? was built
>>>>>>>>>>>> under
>>>> R
>>>>>>>>>>>> version 3.1.2 2: package ?mice? was built under R version
>>>>>>>>>>>> 3.1.2
>>>>>>>>>>>>> summary(trial)
>>>>>>>>>>>> logistf(formula = Correct ~ Syntax.Semantics, data =
>>>>>>>>>>>> trialglm, family = binomial)
>>>>>>>>>>>>
>>>>>>>>>>>> Model fitted by Penalized ML Confidence intervals and
>>>>>>>>>>>> p-values by Profile Likelihood Profile Likelihood Profile
>>>>>>>>>>>> Likelihood Profile Likelihood Profile Likelihood Profile
>>>>>>>>>>>> Likelihood Profile
>>>> Likelihood
>>>>>>>>>>>> Profile Likelihood
>>>>>>>>>>>>
>>>>>>>>>>>> coef  se(coef) lower 0.95 upper 0.95 Chisq            p
>>>> (Intercept)
>>>>>>>>>>>> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000
>>>>>>>>>>>> 1.000000e+00 Syntax.Semantics A  4.1767737 6.3254344
>>>>>>>>>>>> 0.4224696 12.0673987
>>>>>>>>>>>> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602
>>>>>>>>>>>> 0.8959376
>>>>>>>>>>>> -1.3963977 -0.7625216  0.000000 1.000000e+00
>>>>>>>>>>>> Syntax.Semantics C
>>>>>>>>>>>> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000
>>>>>>>>>>>> 1.000000e+00 Syntax.Semantics D  0.2314740 1.1563731
>>>>>>>>>>>> -0.1704535  0.6479908
>>>>>>>>>>>> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907
>>>>>>>>>>>> 0.9771824
>>>>>>>>>>>> -1.0076740 -0.3164066  0.000000 1.000000e+00
>>>>>>>>>>>> Syntax.Semantics F
>>>>>>>>>>>> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000
>>>>>>>>>>>> 1.000000e+00 Syntax.Semantics G  0.9909046 1.3787175
>>>>>>>>>>>> 0.5457741  1.5353981
>>>>>>>>>>>> 0.000000 1.000000e+00
>>>>>>>>>>>>
>>>>>>>>>>>> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test
>>>>>>>>>>>> =
>>>>>>>>>>>> 5.334321 on 7 df, p = 0.6192356
>>>>>>>>>>>>
>>>>>>>>>>>> In particular, what is this model telling me? That Z (my ref
>>>> level)
>>>>>>>>>>>> and B are significantly different?
>>>>>>>>>>>>
>>>>>>>>>>>> I'm happy to try the elrm function with exact logistic
>>>>>>>>>>>> regression but I am not capable of programming it. Besides,
>>>>>>>>>>>> would it give me valid estimates for the comparison between
>> the Z and B levels?
>>>> The
>>>>>>>>>>>> data frame should look like this:
>>>>>>>>>>>>
>>>>>>>>>>>> Outcome variable (Correct, incorrect) Predictor variable (A,
>>>>>>>>>>>> B,
>>>> C,
>>>>>>>>>>>> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
>>>>>>>>>>>> 36,8; C:45,3; A: 34,13; F:65,22).
>>>>>>>>>>>>
>>>>>>>>>>>> Thank you! F.
>>>>>>>>>>>>
>>>>>>>>>>>> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker
>>>>>>>>>>>> <bbolker at gmail.com>
>>>>>>>>>>>> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>> And for what it's worth, you can do this in conjunction
>>>>>>>>>>>>> with
>>>> lme4
>>>>>>>>>>>>> by using the blme package instead (a thin Bayesian wrapper
>>>> around
>>>>>>>>>>>>> lme4), or via the MCMCglmm package; see
>>>>>>>>>>>>>
>>>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>>>>>>>>>>>>> for an example (search for "complete separation").
>>>>>>>>>>>>>
>>>>>>>>>>>>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang
>>>>>>>>>>>>> (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>>>>>>>>>>>> You may need to consider using an 'exact', Bayesian, or
>>>>>>>>>>>>>> penalized
>>>>>>>>>>>>> likelihood approach (along the lines proposed by Firth).
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Maybe a place to start:
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regres
>>>> sion.html
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>> Best,
>>>>>>>>>>>>>> Wolfgang
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> -----Original Message----- From: R-sig-mixed-models
>>>>>>>>>>>>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On
>>>>>>>>>>>>>>> Behalf Of Francesco Romano Sent: Wednesday, May 27, 2015
>> 23:00 To:
>>>>>>>>>>>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>>>>>>>>>>>>>>> cells in contrast matrix problem
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> After giving up on a glmer for my data, I remembered a
>>>>>>>>>>>>>>> post by Roger
>>>>>>>>>>>>> Levy
>>>>>>>>>>>>>>> suggesting to try the use non mixed effects glm when one
>>>>>>>>>>>>>>> of the cells in a matrix is zero.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> To put this into perspective:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 |
>>>>>>>>>>>>>>>> Part.name), data =
>>>>>>>>>>>>>>> trialglm, family = binomial)
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>>>>>>>>>>>>>>> opt$par, ctrl = control$checkConv, : Model failed to
>>>>>>>>>>>>>>> converge with max|grad| = 0.053657 (tol = 0.001,
>>>>>>>>>>>>>>> component 4) 2: In checkConv(attr(opt, "derivs"),
>>>>>>>>>>>>>>> opt$par, ctrl = control$checkConv, : Model is nearly
>>>>>>>>>>>>>>> unidentifiable: large eigenvalue ratio - Rescale variables?
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> My data has a binary outcome, correct or incorrect, a
>>>>>>>>>>>>>>> fixed effect predictor factor with 8 levels, and a random
>>>>>>>>>>>>>>> effect for participants. I believe the problem R is
>>>>>>>>>>>>>>> encountering is with one level of the factor (let us call
>>>>>>>>>>>>>>> it level B) which has no counts (no I won' t try to post
>>>>>>>>>>>>>>> the table from the paper with the counts because I know
>>>>>>>>>>>>>>> it will get garbled up!).
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> I attempt a glm with the same data:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>>>>>>>>>>>>>>>> family =
>>>>>>>>>>>>>>> binomial)
>>>>>>>>>>>>>>>> anova(trial)
>>>>>>>>>>>>>>> Analysis of Deviance Table
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Model: binomial, link: logit
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Response: Correct
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Terms added sequentially (first to last)
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Df Deviance Resid. Df Resid. Dev NULL
>>>>>>>>>>>>>>> 384     289.63 Syntax.Semantics  7   34.651       377
>>>>>>>>>>>>>>> 254.97
>>>>>>>>>>>>>>>> summary(trial)
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>>>>>>>>>>>>>>> binomial, data = trialglm)
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Deviance Residuals: Min        1Q    Median        3Q
>>>>>>>>>>>>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>>>>>>>>>>>>>>> (Intercept)                 -1.6917     0.4113  -4.113
>>>>>>>>>>>>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
>>>>>>>>>>>>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>>>>>>>>>>>>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>>>>>>>>>>>>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>>>>>>>>>>>>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>>>>>>>>>>>>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>>>>>>>>>>>>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>>>>>>>>>>>>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*?
>>>>>>>>>>>>>>> 0.05 ?.? 0.1 ? ? 1
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> (Dispersion parameter for binomial family taken to be 1)
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Null deviance: 289.63  on 384  degrees of freedom
>>>>>>>>>>>>>>> Residual
>>>>>>>>>>>>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Number of Fisher Scoring iterations: 17
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> The comparison I'm interested in is between level B and
>>>>>>>>>>>>>>> the reference level but it cannot be estimated as shown
>>>>>>>>>>>>>>> by the ridiculously high estimate and SE value.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Any suggestions on how to get a decent beta, SE, z, and p?
>>>>>>>>>>>>>>> It's the only comparison missing in the table for the
>>>>>>>>>>>>>>> levels I need so I think it
>>>>>>>>>>>>> would
>>>>>>>>>>>>>>> be a bit unacademic of me to close this deal saying 'the
>>>>>>>>>>>>>>> difference
>>>>>>>>>>>>> could
>>>>>>>>>>>>>>> not be estimated due to zero count'.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> And by the way I have seen this comparison being
>>>>>>>>>>>>>>> generated using other stats.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Thanks in advance,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Frank
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> Sent from Gmail for IPhone
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Frank Romano Ph.D.
>>>>>
>>>>> Tel. +39 3911639149
>>>>>
>>>>> LinkedIn
>>>>> https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>>>>>
>>>>> Academia.edu
>>>>> https://sheffield.academia.edu/FrancescoRomano
>>>>
>>>
>>>
>>>
>>> --
>>> Frank Romano Ph.D.
>>>
>>> Tel. +39 3911639149
>>>
>>> *LinkedIn*
>>> https://it.linkedin.com/pub/francesco-bryan-romano/33/1/162
>>>
>>> *Academia.edu*
>>> https://sheffield.academia.edu/FrancescoRomano
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> -----------------------------------------------------------------------
>>> Confidentiality Notice: This e-mail message, including any attachments,
>>> is for the sole use of the intended recipient(s) and may contain
>>> privileged and confidential information.  Any unauthorized review, use,
>>> disclosure or distribution is prohibited.  If you are not the intended
>>> recipient, please contact the sender by reply e-mail and destroy
>>> all copies of the original message.
>>
> 
> 
>


From luiggi at gmail.com  Thu Oct 29 02:16:16 2015
From: luiggi at gmail.com (Luis Damiano)
Date: Wed, 28 Oct 2015 22:16:16 -0300
Subject: [R-sig-ME] Different within-group error correlation matrices
	per group
In-Reply-To: <CAKFxdiS-FroJdRi_e5QHyZ7VrheoYyu65_oAnJ=6j1X3S82-EQ@mail.gmail.com>
References: <CADD=QAttMrJpR=KSuG_Ff0jSS3HAhB_8nt4ZWYQ7SeO=nziy_Q@mail.gmail.com>
	<CAKFxdiS-FroJdRi_e5QHyZ7VrheoYyu65_oAnJ=6j1X3S82-EQ@mail.gmail.com>
Message-ID: <CADD=QAtEp9rwtnB9JBjw=CFzSe-6HkgogxfFjzKtekBpRfDMGw@mail.gmail.com>

Dear Kevin,

I must confess I found both sites on google before asking here, but I could
not make much sense out of them. It clicked now that I realised lme models
different variances per factor through variance functions and not through
the correlation structure. It is even covered in the book I searched on.

Just in case it is of help for future readers, the following model

> lme(fixed = y~1+time, random = ~1+time|ind, correlation = NULL, weights =
varIdent(form = ~ 1 | group))

has both fixed (intercept and slope) and random (again intercept and slope)

On 28 October 2015 at 14:59, Kevin Wright <kw.stat at gmail.com> wrote:

> You might find the following links contain some useful information.
>
>
> http://stackoverflow.com/questions/11819720/converting-repeated-measures-mixed-model-formula-from-sas-to-r
>
> Factor-specific variances in R
> https://rpubs.com/bbolker/6298
>
> Harris wateruse
> http://www.inside-r.org/packages/cran/agridat/docs/harris.wateruse
>
>
> On Tue, Oct 27, 2015 at 8:57 PM, Luis Damiano <luiggi at gmail.com> wrote:
>
>> Dear all,
>>
>> I am working with lme and I would like to have different within-group
>> error
>> correlation matrices per group (\Lambda_i in 5.1 from Pinheiro & Bates).
>>
>> Currently, my sentence looks like the following
>>
>> correlation = corCompSymm(form = ~ 1 | ind)
>>
>>
>> which imposes the SC structure into the within-group error correlation
>> matrix, marking the individuals by "ind".
>>
>> According to the following example in SAS given by an instructor, it is
>> possible to estimate different within-group error correlation matrices per
>> sex using the following sentences (see "group=gender" in fourth line):
>>
>> proc mixed  data=dental;
>> >   class  child gender;
>> >   model distance = gender gender*age / noint solution;
>> >   repeated / group=gender subject=child;
>> >   random intercept age / type=un subject=child g gcorr v vcorr;
>> > run;
>>
>>
>> I cannot figure out how to reproduce this in R. I took a look at the
>> documentation as well as the first five chapters of Pinheiro & Bates
>> (2000)
>> without luck.
>>
>> Cheers!
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Kevin Wright
>

	[[alternative HTML version deleted]]


From etnbot1 at gmail.com  Fri Oct 23 16:15:45 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Fri, 23 Oct 2015 15:15:45 +0100
Subject: [R-sig-ME] Linear mixed model - heterogeneity
Message-ID: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>

I have a run a linear mixed effects model in R to model clinical data,
however this model is heteroscedastic (as there excess zeros in the
response variable)....

I have tried transforming the data (log transform) and (sqrt), however
neither transformation resolve the issue (see residual versus fitted value
plot). I have not used cox proportional hazards model as the data is not
time-to-event data, the data measures force and there are a large number of
observations have a reading of zero. I cannot exclude these readings as
they are valid.

I have found a R package that runs Tobit regression (AER), however this
will not accommodate the random effects in the model. I cannot find any R
packages that run Weibull mixed effects models (or gamma mixed effects
models)...

Does anyone know if there is a package to run these type of models? (or can
they suggest any alternative approach).

Many thanks


Etn

	[[alternative HTML version deleted]]


From kanixwang at uchicago.edu  Tue Oct 27 21:39:51 2015
From: kanixwang at uchicago.edu (Kanix Wang)
Date: Tue, 27 Oct 2015 15:39:51 -0500
Subject: [R-sig-ME] Selecting a subset of data for binary mixed model
Message-ID: <CACTuc-dZZGqqThHRvUiGeyJaPymuhVnc6ANA68nH0iwkbHLRuw@mail.gmail.com>

Dear List,

I'm using MCMglmm to estimate heritability for binary traits with the model
below. Currently, it is not computationally feasible to use all data in the
model. I'm wondering what would be a good strategy to sample a subset of
data?

I'm currently selecting a subset of individuals with longer observation
periods (i.e. increased chance to observe traits). Would this strategy
introduce bias in the estimates? Should I just randomly sample a subset?

priorA <- list(R = list(V = 1, fix = 1), G = list(G1 =list(V = 1, nu =
1000, alpha.mu = 0, alpha.V = 1), G2 =list(V = 1, nu = 1000, alpha.mu = 0,
alpha.V = 1)))

modelbin <- MCMCglmm(pheno ~ sex + age, random = ~animal +fam , family =
"threshold", pedigree = pedigree, prior = priorA, data = databin, nitt =
nitt, burnin = burnin, thin = 500, slice=TRUE, pl=TRUE)

Sex and age are factor variables. The fam variable is for the common
environment effects in the descendants. All parents have their own fam
value.

Any help would be greatly appreciated.

Best,
Kanix Wang

	[[alternative HTML version deleted]]


From matz at utexas.edu  Tue Oct 27 14:32:37 2015
From: matz at utexas.edu (Mikhail Matz)
Date: Tue, 27 Oct 2015 08:32:37 -0500
Subject: [R-sig-ME] Posterior covariance matrix of fixed effects from
	MCMCglmm?
Message-ID: <AD0AF859-38B7-4504-AA07-B9F88E4D5525@utexas.edu>

Hopefully an easy question:
Is there a way in MCMCglmm to extract a posterior covariance matrix for fixed effects?
Many thanks in advance
- Mikhail

From msalmon at creal.cat  Thu Oct 29 14:41:37 2015
From: msalmon at creal.cat (=?utf-8?Q?Salmon=2C_Ma=C3=ABlle?=)
Date: Thu, 29 Oct 2015 14:41:37 +0100 (CET)
Subject: [R-sig-ME] Model with no random intercept?
Message-ID: <1882349122.2525905.1446126097767.JavaMail.zimbra@creal.cat>

Dear help-list,

Is it possible to have a random effect without random intercept?

My model is 
formula <- "cslt_sspref ~ 1 + epiPeriod + (epiPeriod|ss_pref)"
modelTest1 <- glmer(formula, dataCarambars, family=poisson())

But what I would like is something like
formula <- "cslt_sspref ~ 1 + epiPeriod + ((0+epiPeriod)|ss_pref)"
modelTest1 <- glmer(formula, dataCarambars, family=poisson())

i.e. only epiPeriod with a random effect of ss_pref. I have tried different syntaxes with 0, -1, etc. but I could not find the right syntax.

How can I avoid this issue and eliminate the random intercept? Maybe I cannot?

Thanks a lot in advance, best wishes

Ma?lle Salmon.


From killver at gmail.com  Thu Oct 29 18:32:19 2015
From: killver at gmail.com (Philipp Singer)
Date: Thu, 29 Oct 2015 10:32:19 -0700
Subject: [R-sig-ME] Model with no random intercept?
In-Reply-To: <1882349122.2525905.1446126097767.JavaMail.zimbra@creal.cat>
References: <1882349122.2525905.1446126097767.JavaMail.zimbra@creal.cat>
Message-ID: <56325823.5070503@gmail.com>

Your syntax is correct, you need to specify it as

cslt_sspref ~ 1 + epiPeriod + (0+epiPeriod|ss_pref)

Best,
Philipp

On 10/29/2015 06:41 AM, Salmon, Ma?lle wrote:
> Dear help-list,
>
> Is it possible to have a random effect without random intercept?
>
> My model is
> formula <- "cslt_sspref ~ 1 + epiPeriod + (epiPeriod|ss_pref)"
> modelTest1 <- glmer(formula, dataCarambars, family=poisson())
>
> But what I would like is something like
> formula <- "cslt_sspref ~ 1 + epiPeriod + ((0+epiPeriod)|ss_pref)"
> modelTest1 <- glmer(formula, dataCarambars, family=poisson())
>
> i.e. only epiPeriod with a random effect of ss_pref. I have tried different syntaxes with 0, -1, etc. but I could not find the right syntax.
>
> How can I avoid this issue and eliminate the random intercept? Maybe I cannot?
>
> Thanks a lot in advance, best wishes
>
> Ma?lle Salmon.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From maggenga at libero.it  Thu Oct 29 20:25:04 2015
From: maggenga at libero.it (Davide Guido)
Date: Thu, 29 Oct 2015 20:25:04 +0100 (CET)
Subject: [R-sig-ME] model building
Message-ID: <135954601.4889741446146704255.JavaMail.httpd@webmail-38.iol.local>

Hello Everyone!

I have a dataset with 150.000 statistical units (subjects) and 5 variables:

- Binary outcome (0/1) (y)
- municipality (string) (25 small areas)
- gender
- age
- copper concentration (in ppm) (25 level, one by municipality)

The last one, i.e. copper concentration, has been revealed per municipality 
(25 levels) and it is defined as municipalty mean of the different municipal 
sampling sites. I'm interested to the (conditional) copper effect on outcome 
and I have tried to specify this GLMM: 

gLMM <- glmer (y ~ gender + age + copper + (1 | municipality), family="
binomial", data=datiSM) 


Is it correct fit a model containing both disaggregated and aggregated 
variables? 

Unfortunately, I cannot measure the copper at disaggregated level (by 
subject). 

Thanks in advance

Davide


From karraspito at yahoo.es  Thu Oct 29 21:51:57 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Thu, 29 Oct 2015 20:51:57 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm diagnostics
References: <973778559.7587611.1446151917239.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <973778559.7587611.1446151917239.JavaMail.yahoo@mail.yahoo.com>


?? Hello everyone. Just 3 quick questions about MCMCglmm diagnostic tools:
?? 1. When using autocorrelation(), the result I get includes several lines marked as "Lag 1", "Lag 10", "Lag 50", "Lag 100" and so on. In Patrick Lam's fantastic "Convergence Diagnostics" I read this: "The lag k autocorrelation ?k is the correlation between every draw and its kth lag. So, according to this, "Lag 1" is the correlation between one sample and the sample inmediately posterior, "Lag 10" the correlation between a sample and the sample 10 positions after, and so on. Is that right??? 2. In the Course Notes, it says "I usually aim to store 1,000-2,000 iterations and have the autocorrelation between successive stored iterations less than 0.1." Does this mean thin=1,000-2,000? Because in that case, we would be storing every 1,000-2,000 iterations, right??? 3. Apart from autocorr() and trace and density plots, I have seen other diagnostic analyses described for mcmc objects, such as Gelman and Rubin, Geweke, Heidelberg-Lewis or Raftery-Lewis. However, when I try to implement this in my MCMCglmm models, R shows me the message "no applicable method applied to an object of class "MCMCglmm" or other error messages." Are there any diagnostics tools that can be applied to MCMCglmm objects other than the ones mentioned in the Course Notes, autocorr() and plot()?
?? Thank you very much in advance.
?? Iker.
?__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Oct 29 23:24:08 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 29 Oct 2015 22:24:08 +0000
Subject: [R-sig-ME] MCMCglmm diagnostics
In-Reply-To: <973778559.7587611.1446151917239.JavaMail.yahoo@mail.yahoo.com>
References: <973778559.7587611.1446151917239.JavaMail.yahoo@mail.yahoo.com>
	<973778559.7587611.1446151917239.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20151029222408.99433dlihwddqr2g@www.staffmail.ed.ac.uk>

Hi,

1/ yes
2/ no - it means choose the number of iterations such that the number  
of *stored* iterations is about 1000-2000.  You can of course save  
more, but then the memory for storage goes up.
3/ These are for assessing convergence from multiple chains. you can  
apply them to mcmc.list objects: for example mcmc.list(m1$VCV, m2$VCV)

Cheers,

Jarrod



Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Thu, 29 Oct 2015  
20:51:57 +0000 (UTC):

>
> ?? Hello everyone. Just 3 quick questions about MCMCglmm diagnostic tools:
> ?? 1. When using autocorrelation(), the result I get includes  
> several lines marked as "Lag 1", "Lag 10", "Lag 50", "Lag 100" and  
> so on. In Patrick Lam's fantastic "Convergence Diagnostics" I read  
> this: "The lag k autocorrelation ?k is the correlation between every  
> draw and its kth lag. So, according to this, "Lag 1" is the  
> correlation between one sample and the sample inmediately posterior,  
> "Lag 10" the correlation between a sample and the sample 10  
> positions after, and so on. Is that right??? 2. In the Course Notes,  
> it says "I usually aim to store 1,000-2,000 iterations and have the  
> autocorrelation between successive stored iterations less than 0.1."  
> Does this mean thin=1,000-2,000? Because in that case, we would be  
> storing every 1,000-2,000 iterations, right??? 3. Apart from  
> autocorr() and trace and density plots, I have seen other diagnostic  
> analyses described for mcmc objects, such as Gelman and Rubin,  
> Geweke, Heidelberg-Lewis or Raftery-Lewis. However, when I try to  
> implement this in my MCMCglmm models, R shows me the message "no  
> applicable method applied to an object of class "MCMCglmm" or other  
> error messages." Are there any diagnostics tools that can be applied  
> to MCMCglmm objects other than the ones mentioned in the Course  
> Notes, autocorr() and plot()?
> ?? Thank you very much in advance.
> ?? Iker.
> ?__________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Fri Oct 30 01:24:13 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Oct 2015 20:24:13 -0400
Subject: [R-sig-ME] Model with no random intercept?
In-Reply-To: <56325823.5070503@gmail.com>
References: <1882349122.2525905.1446126097767.JavaMail.zimbra@creal.cat>
	<56325823.5070503@gmail.com>
Message-ID: <CABghstQcTK-VWz_yRe33B-Rm47WBrA+fQ2z7MO+8FmJsVNvgOA@mail.gmail.com>

This seems like the right syntax, but it won't work correctly for
categorical input variables.  If epiPeriod is (e.g.) a two-level
factor with levels "before","after" then you might want

cslt_sspref ~ 1 + epiPeriod + (0+dummy(epiPeriod,"after")|ss_pref)

(see ?dummy) -- although I have to say I am suspicious of the
usefulness of this model ... why do you expect there to be no
variation among groups in the "before" period ... ?

  Ben Bolker



On Thu, Oct 29, 2015 at 1:32 PM, Philipp Singer <killver at gmail.com> wrote:
> Your syntax is correct, you need to specify it as
>
> cslt_sspref ~ 1 + epiPeriod + (0+epiPeriod|ss_pref)
>
> Best,
> Philipp
>
>
> On 10/29/2015 06:41 AM, Salmon, Ma?lle wrote:
>>
>> Dear help-list,
>>
>> Is it possible to have a random effect without random intercept?
>>
>> My model is
>> formula <- "cslt_sspref ~ 1 + epiPeriod + (epiPeriod|ss_pref)"
>> modelTest1 <- glmer(formula, dataCarambars, family=poisson())
>>
>> But what I would like is something like
>> formula <- "cslt_sspref ~ 1 + epiPeriod + ((0+epiPeriod)|ss_pref)"
>> modelTest1 <- glmer(formula, dataCarambars, family=poisson())
>>
>> i.e. only epiPeriod with a random effect of ss_pref. I have tried
>> different syntaxes with 0, -1, etc. but I could not find the right syntax.
>>
>> How can I avoid this issue and eliminate the random intercept? Maybe I
>> cannot?
>>
>> Thanks a lot in advance, best wishes
>>
>> Ma?lle Salmon.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Oct 30 02:03:49 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Oct 2015 21:03:49 -0400
Subject: [R-sig-ME] Posterior covariance matrix of fixed effects from
	MCMCglmm?
In-Reply-To: <AD0AF859-38B7-4504-AA07-B9F88E4D5525@utexas.edu>
References: <AD0AF859-38B7-4504-AA07-B9F88E4D5525@utexas.edu>
Message-ID: <CABghstTmVz9HOWBrZArm+0U5sFpBAFUHOCiW5H5Yd5xHWopjOg@mail.gmail.com>

What about

var(model$Sol)

?

On Tue, Oct 27, 2015 at 9:32 AM, Mikhail Matz <matz at utexas.edu> wrote:
> Hopefully an easy question:
> Is there a way in MCMCglmm to extract a posterior covariance matrix for fixed effects?
> Many thanks in advance
> - Mikhail
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Oct 30 02:10:09 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Oct 2015 21:10:09 -0400
Subject: [R-sig-ME] Linear mixed model - heterogeneity
In-Reply-To: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>
References: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>
Message-ID: <CABghstRSo0J4dD2mW77Nh6f+Bp1W00gnZnvRPjAsFXZX2cCR9w@mail.gmail.com>

lme4 will run Gamma mixed models, but these don't accomodate zeros.  I
don't think Weibull will either.  You're also right that
transformation won't generally solve these problems. There are very
few positive distributions, not considering censored variants of
real-valued distributions, that will naively allow zeros.   You could
run a two-stage model (Bernoulli model for zero vs non-zero, then a
positive-distribution model for the conditional effects on the
non-zero values only).

The cplm package allows tweedie mixed models, which might work for
you. AD Model Builder and Template Model Builder will allow you to fit
fixed models from any distribution you can specify (with a generic
Laplace approximation engine built in), but the learning curve is
pretty steep ...

It's important in this case to consider the source of your zeros.  Are
they below minimal detection limits (in which case something like a
Tobit is appropriate)?  Do they represent a separate process (in which
case two-stage models are sensible)? Or ... ?

On Fri, Oct 23, 2015 at 10:15 AM, Etn bot <etnbot1 at gmail.com> wrote:
> I have a run a linear mixed effects model in R to model clinical data,
> however this model is heteroscedastic (as there excess zeros in the
> response variable)....
>
> I have tried transforming the data (log transform) and (sqrt), however
> neither transformation resolve the issue (see residual versus fitted value
> plot). I have not used cox proportional hazards model as the data is not
> time-to-event data, the data measures force and there are a large number of
> observations have a reading of zero. I cannot exclude these readings as
> they are valid.
>
> I have found a R package that runs Tobit regression (AER), however this
> will not accommodate the random effects in the model. I cannot find any R
> packages that run Weibull mixed effects models (or gamma mixed effects
> models)...
>
> Does anyone know if there is a package to run these type of models? (or can
> they suggest any alternative approach).
>
> Many thanks
>
>
> Etn
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Fri Oct 30 08:35:18 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Fri, 30 Oct 2015 08:35:18 +0100
Subject: [R-sig-ME] Linear mixed model - heterogeneity (Etn bot)
In-Reply-To: <mailman.6604.1446157493.3797.r-sig-mixed-models@r-project.org>
References: <mailman.6604.1446157493.3797.r-sig-mixed-models@r-project.org>
Message-ID: <56331DB6.7010800@highstat.com>





> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 23 Oct 2015 15:15:45 +0100
> From: Etn bot <etnbot1 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Linear mixed model - heterogeneity
> Message-ID:
> 	<CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> I have a run a linear mixed effects model in R to model clinical data,
> however this model is heteroscedastic (as there excess zeros in the
> response variable)....
>
> I have tried transforming the data (log transform) and (sqrt), however
> neither transformation resolve the issue (see residual versus fitted value
> plot). I have not used cox proportional hazards model as the data is not
> time-to-event data, the data measures force and there are a large number of
> observations have a reading of zero. I cannot exclude these readings as
> they are valid.
>
> I have found a R package that runs Tobit regression (AER), however this
> will not accommodate the random effects in the model. I cannot find any R
> packages that run Weibull mixed effects models (or gamma mixed effects
> models)...
>
> Does anyone know if there is a package to run these type of models? (or can
> they suggest any alternative approach).
>
> Many thanks
>
>
> Etn

Hi,

Run a hurdle model that consists of:

1. A Logistic regression model on the absence/presence data (e.g. using 
glmer).
2. A Gamma GLMM on the presence only data

Then figure out the mean and variance of the zero altered Gamma 
distribution so that you have the fitted values of the combined model.

Alain

PS. This is also part of an exercise in the following course (which will 
run next week in Spain)..;-)

http://highstat.com/Courses/Flyers/Flyer2015_11Elche.pdf





-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From thierry.onkelinx at inbo.be  Fri Oct 30 09:24:48 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 30 Oct 2015 09:24:48 +0100
Subject: [R-sig-ME] model building
In-Reply-To: <135954601.4889741446146704255.JavaMail.httpd@webmail-38.iol.local>
References: <135954601.4889741446146704255.JavaMail.httpd@webmail-38.iol.local>
Message-ID: <CAJuCY5wE_2yUn7UcTcK07tHHBfxEmwZSaG44tud5WHe0+i6FXA@mail.gmail.com>

Dear Davide,

Your model formulation is OK.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-29 20:25 GMT+01:00 Davide Guido via R-sig-mixed-models <
r-sig-mixed-models at r-project.org>:

> Hello Everyone!
>
> I have a dataset with 150.000 statistical units (subjects) and 5 variables:
>
> - Binary outcome (0/1) (y)
> - municipality (string) (25 small areas)
> - gender
> - age
> - copper concentration (in ppm) (25 level, one by municipality)
>
> The last one, i.e. copper concentration, has been revealed per municipality
> (25 levels) and it is defined as municipalty mean of the different
> municipal
> sampling sites. I'm interested to the (conditional) copper effect on
> outcome
> and I have tried to specify this GLMM:
>
> gLMM <- glmer (y ~ gender + age + copper + (1 | municipality), family="
> binomial", data=datiSM)
>
>
> Is it correct fit a model containing both disaggregated and aggregated
> variables?
>
> Unfortunately, I cannot measure the copper at disaggregated level (by
> subject).
>
> Thanks in advance
>
> Davide
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From karraspito at yahoo.es  Fri Oct 30 12:33:20 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Fri, 30 Oct 2015 11:33:20 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm diagnostics
In-Reply-To: <20151029222408.99433dlihwddqr2g@www.staffmail.ed.ac.uk>
References: <20151029222408.99433dlihwddqr2g@www.staffmail.ed.ac.uk>
Message-ID: <8097983.7927003.1446204800377.JavaMail.yahoo@mail.yahoo.com>


?? Dear Jarrod and group members,
?? Thank you very much for your clarifying reply. Regarding 2, that's actually what I had understood on the first place. Which means, if I'm right, that if you are running 1000-2000 iterations, thin should be 1 (store every single iteration), thin=10 (at least) for 10,000-20,000 total iterations, thin=100 (at least) for 100,000-200,000 iterations, and so on. About 3, I had read it somewhere and forgotten it for the time I asked the question. So, autocorr() and plot() are the basic diagnostic tools for analysing a single chain, then. 

?? Thank you very much again,?? Iker
?__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


      De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
 Para: Iker Vaquero Alba <karraspito at yahoo.es> 
CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Enviado: Jueves 29 de octubre de 2015 22:24
 Asunto: Re: [R-sig-ME] MCMCglmm diagnostics
   
Hi,

1/ yes
2/ no - it means choose the number of iterations such that the number? 
of *stored* iterations is about 1000-2000.? You can of course save? 
more, but then the memory for storage goes up.
3/ These are for assessing convergence from multiple chains. you can? 
apply them to mcmc.list objects: for example mcmc.list(m1$VCV, m2$VCV)

Cheers,

Jarrod



Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Thu, 29 Oct 2015? 
20:51:57 +0000 (UTC):



>
> ?? Hello everyone. Just 3 quick questions about MCMCglmm diagnostic tools:
> ?? 1. When using autocorrelation(), the result I get includes? 
> several lines marked as "Lag 1", "Lag 10", "Lag 50", "Lag 100" and? 
> so on. In Patrick Lam's fantastic "Convergence Diagnostics" I read? 
> this: "The lag k autocorrelation ?k is the correlation between every? 
> draw and its kth lag. So, according to this, "Lag 1" is the? 
> correlation between one sample and the sample inmediately posterior,? 
> "Lag 10" the correlation between a sample and the sample 10? 
> positions after, and so on. Is that right??? 2. In the Course Notes,? 
> it says "I usually aim to store 1,000-2,000 iterations and have the? 
> autocorrelation between successive stored iterations less than 0.1."? 
> Does this mean thin=1,000-2,000? Because in that case, we would be? 
> storing every 1,000-2,000 iterations, right??? 3. Apart from? 
> autocorr() and trace and density plots, I have seen other diagnostic? 
> analyses described for mcmc objects, such as Gelman and Rubin,? 
> Geweke, Heidelberg-Lewis or Raftery-Lewis. However, when I try to? 
> implement this in my MCMCglmm models, R shows me the message "no? 
> applicable method applied to an object of class "MCMCglmm" or other? 
> error messages." Are there any diagnostics tools that can be applied? 
> to MCMCglmm objects other than the ones mentioned in the Course? 
> Notes, autocorr() and plot()?
> ?? Thank you very much in advance.
> ?? Iker.
> ?__________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> ??? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.




  
	[[alternative HTML version deleted]]


From francesco.sigona at unisalento.it  Fri Oct 30 13:48:55 2015
From: francesco.sigona at unisalento.it (Francesco Sigona)
Date: Fri, 30 Oct 2015 13:48:55 +0100
Subject: [R-sig-ME] main effect significance disappears when interaction is
	modeled
Message-ID: <56336737.3030802@unisalento.it>

Hi all,

I've searching the list but I could't find an answer.

In my design, where all my 3 fixed effects are categorical (binary), I 
found that HEIGHT is significant (also anova tell me the same), when I 
model main effects only.

STUDYING MODEL: X ~ HEIGHT + LOWNESS + PLACE + (1|Soggetto)
               Estimate Std. Error    t value
(Intercept) -52.204545   1.277885 -40.852292
HEIGHThigh    3.681818   1.475575   2.495175
LOWNESSlow   -7.386364   1.952002  -3.783994
PLACEback    -0.500000   1.475575  -0.338851

also, I get that  :
LOWNESS affected X (Chi2(1)=13.61, p=0.00023) adding about -7.39 ? 2 
(standard error) to it
HEIGHT affected X (Chi2(1)=6.335, p=0.012) adding about 3.68 ? 1.5 
(standard error) to it

(despite the names, LOWNESS is not the opposite of HEIGHT)

Then, if try to model the interaction between PLACE and HEIGHT this 
comes out:
STUDYING MODEL WITH INTERACTIONS:  X~LOWNESS + HEIGHT*PLACE + (1|Soggetto)
                        Estimate Std. Error    t value
(Intercept)          -48.909091   1.162784 -42.062068
LOWNESSlow            -4.090909   1.520004  -2.691380
HEIGHThigh            -2.909091   1.520004  -1.913870
PLACEback             -7.090909   1.520004  -4.665058
HEIGHThigh:PLACEback  13.181818   2.149611   6.132188
************HEIGHT*PLACE affected X (Chi2(1)=29.17, p=6.6e-08)

(then I am supposed to report the post-hoc that I would get by means of 
multcomp package.)

This posits the following questions to me:

a) Does HEIGHT is still significant? If I make an anova() comparison 
between X~LOWNESS + HEIGHT + PLACE + HEIGHT:PLACE +  (1|Soggetto) and 
X~LOWNESS + PLACE + HEIGHT:PLACE +  (1|Soggetto),    anova() thinks that 
the two models are the same.

b) Should I report that I found a main effect for HEIGHT (with 3.681818 
estimates) and an interaction with PLACE, or should I report that I 
found just the interaction?

c) Since I find the interaction, in this model the main effect of LOW is 
still significant but Chi2square related stuff changes to Chisq=7.3232, 
p=0.0068), as well the slope (now is -4.09). So , what I am supposed to 
report? WHat exactly you would report in my case?

I really need some direction about this, thank you in advance.

Francesco


-- 
*Francesco SIGONA*
Electronics engineer 	
Piazza Filippo Muratore
73100 - Lecce - Italy 	<https://maps.google.com/maps?q=40.331002,18.156462>
tel.: +39 0832 335006
fax.: +39 0832 335007

============================================================
*Center for Interdisciplinary Research on Language (CRIL) 
<http://www.cril.unisalento.it> &
Cognitive Neuroscience of Language and Speech Sciences Lab (CNLSS) * 	
*Dipartimento di Studi umanistici
Universit? del Salento * 	

============================================================
*Laboratorio Diffuso di Ricerca Interdisciplinare Applicata alla Medicina
(DReAM) * 	


From thierry.onkelinx at inbo.be  Fri Oct 30 13:46:19 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 30 Oct 2015 13:46:19 +0100
Subject: [R-sig-ME] main effect significance disappears when interaction
 is modeled
In-Reply-To: <56336737.3030802@unisalento.it>
References: <56336737.3030802@unisalento.it>
Message-ID: <CAJuCY5xDqDQH5voDgi1=MAc8tN0Wf94jb-n1-2-pWeH-+ujYgw@mail.gmail.com>

Dear Francesco,

It's not possible to get a significance of a main effect when it is part
from an interaction. See e.f. fortunes::fortune(55)

Your comparison in a) is the same model but with a different
parametrisation.

I'd report an estimate of the effect for each combination of height and
place, given that both are categorical. Use multcomp to get those or fit a
model like X~0 + HEIGHT:PLACE +  LOWNESS + (1|Soggetto) Yet another
parametrisation of the same model. These will directly estimate the effect
of each height/place interaction.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-30 13:48 GMT+01:00 Francesco Sigona <francesco.sigona at unisalento.it>
:

> Hi all,
>
> I've searching the list but I could't find an answer.
>
> In my design, where all my 3 fixed effects are categorical (binary), I
> found that HEIGHT is significant (also anova tell me the same), when I
> model main effects only.
>
> STUDYING MODEL: X ~ HEIGHT + LOWNESS + PLACE + (1|Soggetto)
>               Estimate Std. Error    t value
> (Intercept) -52.204545   1.277885 -40.852292
> HEIGHThigh    3.681818   1.475575   2.495175
> LOWNESSlow   -7.386364   1.952002  -3.783994
> PLACEback    -0.500000   1.475575  -0.338851
>
> also, I get that  :
> LOWNESS affected X (Chi2(1)=13.61, p=0.00023) adding about -7.39 ? 2
> (standard error) to it
> HEIGHT affected X (Chi2(1)=6.335, p=0.012) adding about 3.68 ? 1.5
> (standard error) to it
>
> (despite the names, LOWNESS is not the opposite of HEIGHT)
>
> Then, if try to model the interaction between PLACE and HEIGHT this comes
> out:
> STUDYING MODEL WITH INTERACTIONS:  X~LOWNESS + HEIGHT*PLACE + (1|Soggetto)
>                        Estimate Std. Error    t value
> (Intercept)          -48.909091   1.162784 -42.062068
> LOWNESSlow            -4.090909   1.520004  -2.691380
> HEIGHThigh            -2.909091   1.520004  -1.913870
> PLACEback             -7.090909   1.520004  -4.665058
> HEIGHThigh:PLACEback  13.181818   2.149611   6.132188
> ************HEIGHT*PLACE affected X (Chi2(1)=29.17, p=6.6e-08)
>
> (then I am supposed to report the post-hoc that I would get by means of
> multcomp package.)
>
> This posits the following questions to me:
>
> a) Does HEIGHT is still significant? If I make an anova() comparison
> between X~LOWNESS + HEIGHT + PLACE + HEIGHT:PLACE +  (1|Soggetto) and
> X~LOWNESS + PLACE + HEIGHT:PLACE +  (1|Soggetto),    anova() thinks that
> the two models are the same.
>
> b) Should I report that I found a main effect for HEIGHT (with 3.681818
> estimates) and an interaction with PLACE, or should I report that I found
> just the interaction?
>
> c) Since I find the interaction, in this model the main effect of LOW is
> still significant but Chi2square related stuff changes to Chisq=7.3232,
> p=0.0068), as well the slope (now is -4.09). So , what I am supposed to
> report? WHat exactly you would report in my case?
>
> I really need some direction about this, thank you in advance.
>
> Francesco
>
>
> --
> *Francesco SIGONA*
> Electronics engineer
> Piazza Filippo Muratore
> 73100 - Lecce - Italy   <
> https://maps.google.com/maps?q=40.331002,18.156462>
> tel.: +39 0832 335006
> fax.: +39 0832 335007
>
> ============================================================
> *Center for Interdisciplinary Research on Language (CRIL) <
> http://www.cril.unisalento.it> &
> Cognitive Neuroscience of Language and Speech Sciences Lab (CNLSS) *
> *Dipartimento di Studi umanistici
> Universit? del Salento *
>
> ============================================================
> *Laboratorio Diffuso di Ricerca Interdisciplinare Applicata alla Medicina
> (DReAM) *
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Fri Oct 30 14:56:41 2015
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Fri, 30 Oct 2015 14:56:41 +0100
Subject: [R-sig-ME] Linear mixed model - heterogeneity
In-Reply-To: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>
References: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>
Message-ID: <CAGoSky-LBM2W+QaRy6zqTzevWD3G+ZXrAei-s0ciNVp0WyrMRg@mail.gmail.com>

You may also try the brms package, which has a hurdle_gamma family that
might be helpful to you.

A sample hurdle_gamma model (using the epilepsy data of brms) may look like
this:

fit <- brm(count ~ 0 + trait * (log_Age_c + log_Base4_c * Trt_c)
            + (0+trait||patient),
            data = epilepsy, family = hurdle_gamma("log"))

The reserved variable "trait" has to levels, one for the gamma part and one
for the bernoulli part modeling zeros.

Currently, hurdle_gamma models are only available in the github version of
brms to be installed via

library(devtools)
install_github("paul-buerkner/brms")

Since brms is based on Stan, you will need a C++ compiler. Instructions on
how to get one are presented at the end of the README on
https://github.com/paul-buerkner/brms.



2015-10-23 16:15 GMT+02:00 Etn bot <etnbot1 at gmail.com>:

> I have a run a linear mixed effects model in R to model clinical data,
> however this model is heteroscedastic (as there excess zeros in the
> response variable)....
>
> I have tried transforming the data (log transform) and (sqrt), however
> neither transformation resolve the issue (see residual versus fitted value
> plot). I have not used cox proportional hazards model as the data is not
> time-to-event data, the data measures force and there are a large number of
> observations have a reading of zero. I cannot exclude these readings as
> they are valid.
>
> I have found a R package that runs Tobit regression (AER), however this
> will not accommodate the random effects in the model. I cannot find any R
> packages that run Weibull mixed effects models (or gamma mixed effects
> models)...
>
> Does anyone know if there is a package to run these type of models? (or can
> they suggest any alternative approach).
>
> Many thanks
>
>
> Etn
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Oct 30 21:00:11 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Oct 2015 16:00:11 -0400
Subject: [R-sig-ME] Posterior covariance matrix of fixed effects from
 MCMCglmm?
In-Reply-To: <5B3FE138-1C13-4A7E-AB3A-F43E401D656D@utexas.edu>
References: <AD0AF859-38B7-4504-AA07-B9F88E4D5525@utexas.edu>
	<CABghstTmVz9HOWBrZArm+0U5sFpBAFUHOCiW5H5Yd5xHWopjOg@mail.gmail.com>
	<5B3FE138-1C13-4A7E-AB3A-F43E401D656D@utexas.edu>
Message-ID: <5633CC4B.3000500@gmail.com>

  [please keep r-sig-mixed-models in Cc: list]

  In my mind they are the same thing, but to be sure you'd have to
define exactly what *you* mean by "[the] posterior covariance matrix for
fixed effects" and how you intend to use/interpret the results you get ...

  Ben Bolker

On 15-10-30 03:55 PM, Mikhail Matz wrote:
> Hi Ben - sounds super easy, but would not that not  be covariance
> among sampled parameter values along MCMC chain  rather than their
> covariance in the actual data? (or is it the same thing? I?m not
> sire)
> 
> Mikhail
> 
> On Oct 29, 2015, at 8:03 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> What about
>> 
>> var(model$Sol)
>> 
>> ?
>> 
>> On Tue, Oct 27, 2015 at 9:32 AM, Mikhail Matz <matz at utexas.edu>
>> wrote:
>>> Hopefully an easy question: Is there a way in MCMCglmm to extract
>>> a posterior covariance matrix for fixed effects? Many thanks in
>>> advance - Mikhail 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From rwwiley at gmail.com  Mon Nov  2 18:39:55 2015
From: rwwiley at gmail.com (Bob Wiley)
Date: Mon, 2 Nov 2015 12:39:55 -0500
Subject: [R-sig-ME] =?utf-8?q?glmer=3A_how_are_=E2=80=9Cnon-integer_=23suc?=
	=?utf-8?q?cesses_in_a_binomial_glm!=E2=80=9D_actually_modeled=3F?=
Message-ID: <CAH08407TrL7zdkr__u_DEqj_XBBj+gmx2ubOi-FRcd5mGG4Kqg@mail.gmail.com>

This is hopefully a clear question but I fear the answer may not be
simple... I have not been able to find anyone who can answer this for me. I
am using the weights= argument in glmer (family = binomial) and get the
non-integer successes warning. I know what this means and why I get it--
some of the weights I have produce values like 4.5 out of 5. This is not an
error, its because on some trials people were awarded partial credit,
essentially.

The estimates of the models seem good to me. And if I round-down or
round-up (i.e. model a 4.5 out of 5 as 4/5 or 5/5) the estimates only
change a little bit. So this makes me confident that whatever lme4 is
doing, it is reasonable. That being said... what IS it doing in these
cases? Should I be doing something other than what I am to model this data,
because of the simple fact that people could receive partial credit on some
trials?

Thanks so much for any help on this confusing issue...

	[[alternative HTML version deleted]]


From etnbot1 at gmail.com  Mon Nov  2 12:04:22 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Mon, 2 Nov 2015 11:04:22 +0000
Subject: [R-sig-ME] Linear mixed model - heterogeneity (Etn bot)
In-Reply-To: <56331DB6.7010800@highstat.com>
References: <mailman.6604.1446157493.3797.r-sig-mixed-models@r-project.org>
	<56331DB6.7010800@highstat.com>
Message-ID: <CAF79uv=pKRo4ei1auCRhzsdWfU7_W8M3AhBBejHEoKEn23bCfA@mail.gmail.com>

@ Alain, many thanks for your response.... I will check out this type of
model

On 30 October 2015 at 07:35, Highland Statistics Ltd <highstat at highstat.com>
wrote:

>
>
>
>
> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Fri, 23 Oct 2015 15:15:45 +0100
>> From: Etn bot <etnbot1 at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Linear mixed model - heterogeneity
>> Message-ID:
>>         <
>> CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg at mail.gmail.com>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> I have a run a linear mixed effects model in R to model clinical data,
>> however this model is heteroscedastic (as there excess zeros in the
>> response variable)....
>>
>> I have tried transforming the data (log transform) and (sqrt), however
>> neither transformation resolve the issue (see residual versus fitted value
>> plot). I have not used cox proportional hazards model as the data is not
>> time-to-event data, the data measures force and there are a large number
>> of
>> observations have a reading of zero. I cannot exclude these readings as
>> they are valid.
>>
>> I have found a R package that runs Tobit regression (AER), however this
>> will not accommodate the random effects in the model. I cannot find any R
>> packages that run Weibull mixed effects models (or gamma mixed effects
>> models)...
>>
>> Does anyone know if there is a package to run these type of models? (or
>> can
>> they suggest any alternative approach).
>>
>> Many thanks
>>
>>
>> Etn
>>
>
> Hi,
>
> Run a hurdle model that consists of:
>
> 1. A Logistic regression model on the absence/presence data (e.g. using
> glmer).
> 2. A Gamma GLMM on the presence only data
>
> Then figure out the mean and variance of the zero altered Gamma
> distribution so that you have the fitted values of the combined model.
>
> Alain
>
> PS. This is also part of an exercise in the following course (which will
> run next week in Spain)..;-)
>
> http://highstat.com/Courses/Flyers/Flyer2015_11Elche.pdf
>
>
>
>
>
> --
> Dr. Alain F. Zuur
>
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
>
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
>

	[[alternative HTML version deleted]]


From etnbot1 at gmail.com  Mon Nov  2 12:00:36 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Mon, 2 Nov 2015 11:00:36 +0000
Subject: [R-sig-ME] Linear mixed model - heterogeneity
In-Reply-To: <CAGoSky-LBM2W+QaRy6zqTzevWD3G+ZXrAei-s0ciNVp0WyrMRg@mail.gmail.com>
References: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>
	<CAGoSky-LBM2W+QaRy6zqTzevWD3G+ZXrAei-s0ciNVp0WyrMRg@mail.gmail.com>
Message-ID: <CAF79uv=3x+AKK9W_tDCZ97Cri2F6phi1oZc+TLhRmor8GDaYpA@mail.gmail.com>

@ Paul, many thanks for your response, I will check out the link you sent

On 30 October 2015 at 13:56, Paul Buerkner <paul.buerkner at gmail.com> wrote:

> You may also try the brms package, which has a hurdle_gamma family that
> might be helpful to you.
>
> A sample hurdle_gamma model (using the epilepsy data of brms) may look
> like this:
>
> fit <- brm(count ~ 0 + trait * (log_Age_c + log_Base4_c * Trt_c)
>             + (0+trait||patient),
>             data = epilepsy, family = hurdle_gamma("log"))
>
> The reserved variable "trait" has to levels, one for the gamma part and
> one for the bernoulli part modeling zeros.
>
> Currently, hurdle_gamma models are only available in the github version of
> brms to be installed via
>
> library(devtools)
> install_github("paul-buerkner/brms")
>
> Since brms is based on Stan, you will need a C++ compiler. Instructions on
> how to get one are presented at the end of the README on
> https://github.com/paul-buerkner/brms.
>
>
>
> 2015-10-23 16:15 GMT+02:00 Etn bot <etnbot1 at gmail.com>:
>
>> I have a run a linear mixed effects model in R to model clinical data,
>> however this model is heteroscedastic (as there excess zeros in the
>> response variable)....
>>
>> I have tried transforming the data (log transform) and (sqrt), however
>> neither transformation resolve the issue (see residual versus fitted value
>> plot). I have not used cox proportional hazards model as the data is not
>> time-to-event data, the data measures force and there are a large number
>> of
>> observations have a reading of zero. I cannot exclude these readings as
>> they are valid.
>>
>> I have found a R package that runs Tobit regression (AER), however this
>> will not accommodate the random effects in the model. I cannot find any R
>> packages that run Weibull mixed effects models (or gamma mixed effects
>> models)...
>>
>> Does anyone know if there is a package to run these type of models? (or
>> can
>> they suggest any alternative approach).
>>
>> Many thanks
>>
>>
>> Etn
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From etnbot1 at gmail.com  Mon Nov  2 11:58:53 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Mon, 2 Nov 2015 10:58:53 +0000
Subject: [R-sig-ME] Linear mixed model - heterogeneity
In-Reply-To: <CABghstRSo0J4dD2mW77Nh6f+Bp1W00gnZnvRPjAsFXZX2cCR9w@mail.gmail.com>
References: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>
	<CABghstRSo0J4dD2mW77Nh6f+Bp1W00gnZnvRPjAsFXZX2cCR9w@mail.gmail.com>
Message-ID: <CAF79uvmTtthne0iM4Sj=tsG+hvsq5EjZXZ2cF9mq6ASiUgtPrQ@mail.gmail.com>

@Ben many thanks or your response - with reference to the source of the
zeros - the clinical data: patients force is recorded using a machine, this
force reading is recorded 5 times for each patient at each time point (4
different visiting times). Sometimes the machine has a reading of zero (for
all 5 reps) and other times it has a zero reading for e.g. 1st rep, 3rd
rep. If there is a full zero reading (for all 5 reps at each of the four
time points), this is due to the patient having no force (true reading and
this does not happen very often in the data). If there is zero reading (for
some of the 5 reps) then this could be due to the patient not having
ability to consistently push hard enough for that reading and the machine
recorded zero.

On 30 October 2015 at 01:10, Ben Bolker <bbolker at gmail.com> wrote:

> lme4 will run Gamma mixed models, but these don't accomodate zeros.  I
> don't think Weibull will either.  You're also right that
> transformation won't generally solve these problems. There are very
> few positive distributions, not considering censored variants of
> real-valued distributions, that will naively allow zeros.   You could
> run a two-stage model (Bernoulli model for zero vs non-zero, then a
> positive-distribution model for the conditional effects on the
> non-zero values only).
>
> The cplm package allows tweedie mixed models, which might work for
> you. AD Model Builder and Template Model Builder will allow you to fit
> fixed models from any distribution you can specify (with a generic
> Laplace approximation engine built in), but the learning curve is
> pretty steep ...
>
> It's important in this case to consider the source of your zeros.  Are
> they below minimal detection limits (in which case something like a
> Tobit is appropriate)?  Do they represent a separate process (in which
> case two-stage models are sensible)? Or ... ?
>
> On Fri, Oct 23, 2015 at 10:15 AM, Etn bot <etnbot1 at gmail.com> wrote:
> > I have a run a linear mixed effects model in R to model clinical data,
> > however this model is heteroscedastic (as there excess zeros in the
> > response variable)....
> >
> > I have tried transforming the data (log transform) and (sqrt), however
> > neither transformation resolve the issue (see residual versus fitted
> value
> > plot). I have not used cox proportional hazards model as the data is not
> > time-to-event data, the data measures force and there are a large number
> of
> > observations have a reading of zero. I cannot exclude these readings as
> > they are valid.
> >
> > I have found a R package that runs Tobit regression (AER), however this
> > will not accommodate the random effects in the model. I cannot find any R
> > packages that run Weibull mixed effects models (or gamma mixed effects
> > models)...
> >
> > Does anyone know if there is a package to run these type of models? (or
> can
> > they suggest any alternative approach).
> >
> > Many thanks
> >
> >
> > Etn
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Nov  2 23:11:59 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Nov 2015 17:11:59 -0500
Subject: [R-sig-ME] Linear mixed model - heterogeneity
In-Reply-To: <CAF79uvmTtthne0iM4Sj=tsG+hvsq5EjZXZ2cF9mq6ASiUgtPrQ@mail.gmail.com>
References: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>
	<CABghstRSo0J4dD2mW77Nh6f+Bp1W00gnZnvRPjAsFXZX2cCR9w@mail.gmail.com>
	<CAF79uvmTtthne0iM4Sj=tsG+hvsq5EjZXZ2cF9mq6ASiUgtPrQ@mail.gmail.com>
Message-ID: <CABghstRb4WDu2eYAPb_PbYirSNSa1v0K0ZNeRos_YrqJQx6v9g@mail.gmail.com>

  If you have 5 reps per patient, unless those reps vary in some
interesting way or they have structure you need to know about (e.g.
you're trying to estimate slope of improvement over time, or
patient/rep instances having differing values of covariates you need
to adjust for), it would definitely help to just aggregate (i.e., take
the mean over reps: see Murtauch "Simplicity and complexity in
ecological data analysis") ...

On Mon, Nov 2, 2015 at 5:58 AM, Etn bot <etnbot1 at gmail.com> wrote:
> @Ben many thanks or your response - with reference to the source of the
> zeros - the clinical data: patients force is recorded using a machine, this
> force reading is recorded 5 times for each patient at each time point (4
> different visiting times). Sometimes the machine has a reading of zero (for
> all 5 reps) and other times it has a zero reading for e.g. 1st rep, 3rd rep.
> If there is a full zero reading (for all 5 reps at each of the four time
> points), this is due to the patient having no force (true reading and this
> does not happen very often in the data). If there is zero reading (for some
> of the 5 reps) then this could be due to the patient not having ability to
> consistently push hard enough for that reading and the machine recorded
> zero.
>
> On 30 October 2015 at 01:10, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> lme4 will run Gamma mixed models, but these don't accomodate zeros.  I
>> don't think Weibull will either.  You're also right that
>> transformation won't generally solve these problems. There are very
>> few positive distributions, not considering censored variants of
>> real-valued distributions, that will naively allow zeros.   You could
>> run a two-stage model (Bernoulli model for zero vs non-zero, then a
>> positive-distribution model for the conditional effects on the
>> non-zero values only).
>>
>> The cplm package allows tweedie mixed models, which might work for
>> you. AD Model Builder and Template Model Builder will allow you to fit
>> fixed models from any distribution you can specify (with a generic
>> Laplace approximation engine built in), but the learning curve is
>> pretty steep ...
>>
>> It's important in this case to consider the source of your zeros.  Are
>> they below minimal detection limits (in which case something like a
>> Tobit is appropriate)?  Do they represent a separate process (in which
>> case two-stage models are sensible)? Or ... ?
>>
>> On Fri, Oct 23, 2015 at 10:15 AM, Etn bot <etnbot1 at gmail.com> wrote:
>> > I have a run a linear mixed effects model in R to model clinical data,
>> > however this model is heteroscedastic (as there excess zeros in the
>> > response variable)....
>> >
>> > I have tried transforming the data (log transform) and (sqrt), however
>> > neither transformation resolve the issue (see residual versus fitted
>> > value
>> > plot). I have not used cox proportional hazards model as the data is not
>> > time-to-event data, the data measures force and there are a large number
>> > of
>> > observations have a reading of zero. I cannot exclude these readings as
>> > they are valid.
>> >
>> > I have found a R package that runs Tobit regression (AER), however this
>> > will not accommodate the random effects in the model. I cannot find any
>> > R
>> > packages that run Weibull mixed effects models (or gamma mixed effects
>> > models)...
>> >
>> > Does anyone know if there is a package to run these type of models? (or
>> > can
>> > they suggest any alternative approach).
>> >
>> > Many thanks
>> >
>> >
>> > Etn
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From bbolker at gmail.com  Tue Nov  3 00:37:51 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Nov 2015 18:37:51 -0500
Subject: [R-sig-ME]
	=?utf-8?q?glmer=3A_how_are_=E2=80=9Cnon-integer_=23suc?=
	=?utf-8?q?cesses_in_a_binomial_glm!=E2=80=9D_actually_modeled=3F?=
In-Reply-To: <CAH08407TrL7zdkr__u_DEqj_XBBj+gmx2ubOi-FRcd5mGG4Kqg@mail.gmail.com>
References: <CAH08407TrL7zdkr__u_DEqj_XBBj+gmx2ubOi-FRcd5mGG4Kqg@mail.gmail.com>
Message-ID: <CABghstR-51jH4Ls8q=XC8N4EHU5Ma=+61-C2tBStVjfGqoyPGQ@mail.gmail.com>

   In this case I think you should be fine, if it's really reasonable
to imagine that a trial is "partly successful".  lme4 is following
standard GLM practice in handling binomial models -- the variance of
the response is assumed to be p*(1-p)/W .  The warning is there
because *most* people who input non-integer values are making a
mistake (i.e., treating proportional data without a denominator as
binomial).

 We have seen a few cases where non-integer responses give weird
answers in lme4 (e.g. https://github.com/lme4/lme4/issues/180 ), but
as long as your answers seem reasonable I think you should feel
confident.


On Mon, Nov 2, 2015 at 12:39 PM, Bob Wiley <rwwiley at gmail.com> wrote:
> This is hopefully a clear question but I fear the answer may not be
> simple... I have not been able to find anyone who can answer this for me. I
> am using the weights= argument in glmer (family = binomial) and get the
> non-integer successes warning. I know what this means and why I get it--
> some of the weights I have produce values like 4.5 out of 5. This is not an
> error, its because on some trials people were awarded partial credit,
> essentially.
>
> The estimates of the models seem good to me. And if I round-down or
> round-up (i.e. model a 4.5 out of 5 as 4/5 or 5/5) the estimates only
> change a little bit. So this makes me confident that whatever lme4 is
> doing, it is reasonable. That being said... what IS it doing in these
> cases? Should I be doing something other than what
> I am to model this data,
> because of the simple fact that people could receive partial credit on some
> trials?
>
> Thanks so much for any help on this confusing issue...
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From etnbot1 at gmail.com  Tue Nov  3 11:30:53 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Tue, 3 Nov 2015 10:30:53 +0000
Subject: [R-sig-ME] Linear mixed model - heterogeneity
In-Reply-To: <CABghstRb4WDu2eYAPb_PbYirSNSa1v0K0ZNeRos_YrqJQx6v9g@mail.gmail.com>
References: <CAF79uvkRGaWXkzjPz9grTRhdQSVcqUmLrB+5QWUNS76JJLwmYg@mail.gmail.com>
	<CABghstRSo0J4dD2mW77Nh6f+Bp1W00gnZnvRPjAsFXZX2cCR9w@mail.gmail.com>
	<CAF79uvmTtthne0iM4Sj=tsG+hvsq5EjZXZ2cF9mq6ASiUgtPrQ@mail.gmail.com>
	<CABghstRb4WDu2eYAPb_PbYirSNSa1v0K0ZNeRos_YrqJQx6v9g@mail.gmail.com>
Message-ID: <CAF79uvmzWW953QjJbrqRvwaRAEkXptk0yGQwG=7mHX3_S0rdiw@mail.gmail.com>

Many thanks Ben, I will try this approach



On 2 November 2015 at 22:11, Ben Bolker <bbolker at gmail.com> wrote:

>   If you have 5 reps per patient, unless those reps vary in some
> interesting way or they have structure you need to know about (e.g.
> you're trying to estimate slope of improvement over time, or
> patient/rep instances having differing values of covariates you need
> to adjust for), it would definitely help to just aggregate (i.e., take
> the mean over reps: see Murtauch "Simplicity and complexity in
> ecological data analysis") ...
>
> On Mon, Nov 2, 2015 at 5:58 AM, Etn bot <etnbot1 at gmail.com> wrote:
> > @Ben many thanks or your response - with reference to the source of the
> > zeros - the clinical data: patients force is recorded using a machine,
> this
> > force reading is recorded 5 times for each patient at each time point (4
> > different visiting times). Sometimes the machine has a reading of zero
> (for
> > all 5 reps) and other times it has a zero reading for e.g. 1st rep, 3rd
> rep.
> > If there is a full zero reading (for all 5 reps at each of the four time
> > points), this is due to the patient having no force (true reading and
> this
> > does not happen very often in the data). If there is zero reading (for
> some
> > of the 5 reps) then this could be due to the patient not having ability
> to
> > consistently push hard enough for that reading and the machine recorded
> > zero.
> >
> > On 30 October 2015 at 01:10, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >> lme4 will run Gamma mixed models, but these don't accomodate zeros.  I
> >> don't think Weibull will either.  You're also right that
> >> transformation won't generally solve these problems. There are very
> >> few positive distributions, not considering censored variants of
> >> real-valued distributions, that will naively allow zeros.   You could
> >> run a two-stage model (Bernoulli model for zero vs non-zero, then a
> >> positive-distribution model for the conditional effects on the
> >> non-zero values only).
> >>
> >> The cplm package allows tweedie mixed models, which might work for
> >> you. AD Model Builder and Template Model Builder will allow you to fit
> >> fixed models from any distribution you can specify (with a generic
> >> Laplace approximation engine built in), but the learning curve is
> >> pretty steep ...
> >>
> >> It's important in this case to consider the source of your zeros.  Are
> >> they below minimal detection limits (in which case something like a
> >> Tobit is appropriate)?  Do they represent a separate process (in which
> >> case two-stage models are sensible)? Or ... ?
> >>
> >> On Fri, Oct 23, 2015 at 10:15 AM, Etn bot <etnbot1 at gmail.com> wrote:
> >> > I have a run a linear mixed effects model in R to model clinical data,
> >> > however this model is heteroscedastic (as there excess zeros in the
> >> > response variable)....
> >> >
> >> > I have tried transforming the data (log transform) and (sqrt), however
> >> > neither transformation resolve the issue (see residual versus fitted
> >> > value
> >> > plot). I have not used cox proportional hazards model as the data is
> not
> >> > time-to-event data, the data measures force and there are a large
> number
> >> > of
> >> > observations have a reading of zero. I cannot exclude these readings
> as
> >> > they are valid.
> >> >
> >> > I have found a R package that runs Tobit regression (AER), however
> this
> >> > will not accommodate the random effects in the model. I cannot find
> any
> >> > R
> >> > packages that run Weibull mixed effects models (or gamma mixed effects
> >> > models)...
> >> >
> >> > Does anyone know if there is a package to run these type of models?
> (or
> >> > can
> >> > they suggest any alternative approach).
> >> >
> >> > Many thanks
> >> >
> >> >
> >> > Etn
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>

	[[alternative HTML version deleted]]


From robgriffin247 at hotmail.com  Tue Nov  3 16:01:32 2015
From: robgriffin247 at hotmail.com (Robert Griffin)
Date: Tue, 3 Nov 2015 16:01:32 +0100
Subject: [R-sig-ME] Interaction variance from mcmcglmm
Message-ID: <CAMm5Haxd-eSELitCFQEunwYK1U-O_ZxXf0=A78Q5M-3KPamsEw@mail.gmail.com>

Dear list members,

I recently published work using mcmcglmm to test for Y linked genetic
variance, finding variance within a population. This data was collected by
measuring phenotypic data from randomly sampled Y chromosomes from within a
population, tested in a single genetic background, using lifespan as the
response, and Y chromosome as a random effect.

I have been trying to think of how I would improve such a study and
concluded that a more complete study would be done using
- Y chromosomes from multiple source populations (to test for among
population variance)
- multiple genetic backgrounds (to distinguish between [direct] genetic
effects, and epistatic effects)...

This got me thinking about the analysis of such data. I would need to
estimate how much of the Y-linked variance within and among populations is
genetic and epistatic. This has lead me to two main questions where I could
use some guidance:

1) can mcmcglmm be used to estimate the interaction (epistatic) variance?
- I think the answer is yes but I have as yet been unable to find clear
advice on this, how can I add interaction variance term in to mcmcglmm?
- I can add the variance explained by the genetic background by adding this
as a random effect too, but (how) can I find the interaction between two
random explanatory variables?

2) could I do it all from a single model or would I need multiple models?
- If I built a model where the trait (Lifespan) is the response variable,
with random effects of Y chromosome, Y chromosome source population,
genetic background, and the interactions between Y/Y-source and genetic
background, would I be able to get estimates of the direct genetic and
epistatic variances within and among the source populations?
- I could build two models, one with Y chromosome and genetic background as
random effects (including the interaction), and the other with Y-chromosome
source population and genetic background as random effects (including the
interaction). These two models would separately estimate the within and
among population variances. I think this would be the correct approach.
However, I'm unconvinced that the latter would give the desired division in
to direct and epistatic Y-linked variation.

Thanks,
Rob

*Please kindly note*, advice on prior specification when estimating
interaction effects would be also very highly appreciated, remembering that
the variance components are likely very small. I have included a
demonstration script which makes some dummy data, and shows some of the
proposed models. The script includes a filepath which you can edit if you
wish to save and load chains, and switches at line 56 to turn the chains
on/off when running scripts.

##############
## R SCRIPT ##
##############

# Y-background interaction dummy data
rm(list=ls())
library("lme4")
library("MCMCglmm")
set.seed(24)

# Set filepath (CUSTOMISE THIS IF YOU WISH TO BE ABLE TO SAVE AND LOAD
CHAINS)
filepath = paste0("C:\\Users\\Rob\\Notes\\Y_epistasis\\")

#### Description of dummy data ####
# 20 Y chromosomes randomly sampled from 3 populations (A1:A20, B1:B20,
C1:C20, n = 60)
# Test in genetic backgrounds (BG) from three populations (Canton [CN],
Zimbabwe [ZW], and Dahomey [DH])
# Measure a trait (Lifepsan) in 90 individuals per combination of Y & BG
# Measured across three replicate blocks (BL1, BL2, BL3), with two vials
each per block

n1 = 20 # Number of Y's sampled per source population
n2 = 30 # Number of measurements per block/line
n3 = 3  # Number of blocks (BL1, BL2, BL3)
n4 = 3 # Number of genetic backgrounds (CN, ZW, DH)
n5 = 3  # Number of Y source populations (A, B, C)
n6 = 2  # Number of vials per block/Y/BG

# Construction of data
dummy = data.frame(
as.factor(rep(c(paste0("A",1:n1), paste0("B",1:n1), paste0("C",1:n1)), each
= n2*n3, times = n4)),
as.factor(rep(c("A","B","C"), each = n1*n2*n3, times = n5)),
as.factor(rep(c("CN","ZW","DH"), each = n1*n2*n3*n4, times = 1)),
as.factor(rep(c("BL1","BL2","BL3"), each = n2)),
as.factor(rep(c("A","B"), each = n2 / n6)),
as.numeric(abs(round(rnorm(n1*n2*n3*n4*n5, 50, 15),0)))
)
colnames(dummy) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age")
dummy$Vial = paste(dummy$Y, dummy$Y.Source, dummy$BG, dummy$Block,
dummy$Vial, sep = "_")
head(dummy)

# Mean zero unit variance for Age (response variable)
dummy$Score = (dummy$Age - mean(dummy$Age)) / sd(dummy$Age)

# Subset DFs (Only one source population and one genetic background, as in
previous JEB paper)
dummy_A = data.frame(split(dummy , f = dummy$Y.Source)[1])
dummy_A_CN = data.frame(split(dummy_A , f = dummy_A$A.BG)[1])
colnames(dummy_A) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age",
"Score")
colnames(dummy_A_CN) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age",
"Score")

# MCMC Priors
prior1 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
R  = list(V = 1, nu=0.002))

prior2 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G3 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
R  = list(V = 1, nu=0.002))

# MCMC Switches
testing = "y"
runChain_A_CN1 = "y"
runChain_A1 = "y"
runChain_1 = "y"

# MCMC Details
if(testing == "y"){
nitt = 10000
burn = 1000
thin = 10
}else{
nitt = 100000
burn = 10000
thin = 100
}

# MCMC Chain (as in JEB Paper: One Y source population, One genetic
background)
# Within-population Y-linked variation
if(runChain_A_CN1=="y"){
Chain_A_CN1 = MCMCglmm(Score ~1 + Block,
random = ~Y + Vial,
rcov = ~units,
nitt = nitt,
thin = thin,
burnin = burn,
prior = prior1,
family = "gaussian",
start = list(QUASI = FALSE),
data = dummy_A_CN)
file = paste(filepath, "Chain_A_CN1.rda", sep = "")
save(Chain_A_CN1, file = file)
}else{}

##############################
#### Proposed MCMC Chains ####
##############################

# Within-population Y-linked variation split in to direct and epistatic
if(runChain_A1=="y"){
Chain_A1 = MCMCglmm(Score ~1 + Block,
random = ~Y + BG + Vial,
rcov = ~units,
nitt = nitt,
thin = thin,
burnin = burn,
prior = prior2,
family = "gaussian",
start = list(QUASI = FALSE),
data = dummy_A)
file = paste(filepath, "Chain_A1.rda", sep = "")
save(Chain_A1, file = file)
}else{}

# Among-population Y-linked variation split in to direct and epistatic
if(runChain_1=="y"){
Chain_1 = MCMCglmm(Score ~1 + Block,
random = ~Y.Source + BG + Vial,
rcov = ~units,
nitt = nitt,
thin = thin,
burnin = burn,
prior = prior2,
family = "gaussian",
start = list(QUASI = FALSE),
data = dummy)
file = paste(filepath, "Chain_1.rda", sep = "")
save(Chain_1, file = file)
}else{}

Chain.A_CN1 = load(paste(filepath, "Chain_A_CN1.rda", sep= ""))
Chain.A1 = load(paste(filepath, "Chain_A1.rda", sep= ""))
Chain.1 = load(paste(filepath, "Chain_1.rda", sep= ""))

	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Tue Nov  3 18:29:19 2015
From: paul.debes at utu.fi (paul debes)
Date: Tue, 03 Nov 2015 19:29:19 +0200
Subject: [R-sig-ME] Interaction variance from mcmcglmm
In-Reply-To: <CAMm5Haxd-eSELitCFQEunwYK1U-O_ZxXf0=A78Q5M-3KPamsEw@mail.gmail.com>
References: <CAMm5Haxd-eSELitCFQEunwYK1U-O_ZxXf0=A78Q5M-3KPamsEw@mail.gmail.com>
Message-ID: <op.x7jb65gra3mgvf@armadillo>

Dear Rob,

Unfortunately, I cannot help with the MCMCglmm prior specifications and  
hope someone else will do this, but maybe with the model.

I think that fitting two separate models might lead to different results  
than one common model when you have a significant but ignored covariance  
between effects across populations when estimating only the within  
population variance.

As the Y effects are nested within Y.Source effects (they are, right?),  
one initial full model to estimate within and across population variance,  
and including the interaction with the genetic background effects, could  
be:

fixed = Score ~ 1 + Block,
random = ~ BG + Y.Source/Y + BG:Y.Source/Y + Vial,

expanded:
random = ~ BG + Y.Source + Y.Source:Y + BG:Y.Source + BG:Y.Source:Y + Vial,


Best,
Paul


On Tue, 03 Nov 2015 17:01:32 +0200, Robert Griffin  
<robgriffin247 at hotmail.com> wrote:

> Dear list members,
>
> I recently published work using mcmcglmm to test for Y linked genetic
> variance, finding variance within a population. This data was collected  
> by
> measuring phenotypic data from randomly sampled Y chromosomes from  
> within a
> population, tested in a single genetic background, using lifespan as the
> response, and Y chromosome as a random effect.
>
> I have been trying to think of how I would improve such a study and
> concluded that a more complete study would be done using
> - Y chromosomes from multiple source populations (to test for among
> population variance)
> - multiple genetic backgrounds (to distinguish between [direct] genetic
> effects, and epistatic effects)...
>
> This got me thinking about the analysis of such data. I would need to
> estimate how much of the Y-linked variance within and among populations  
> is
> genetic and epistatic. This has lead me to two main questions where I  
> could
> use some guidance:
>
> 1) can mcmcglmm be used to estimate the interaction (epistatic) variance?
> - I think the answer is yes but I have as yet been unable to find clear
> advice on this, how can I add interaction variance term in to mcmcglmm?
> - I can add the variance explained by the genetic background by adding  
> this
> as a random effect too, but (how) can I find the interaction between two
> random explanatory variables?
>
> 2) could I do it all from a single model or would I need multiple models?
> - If I built a model where the trait (Lifespan) is the response variable,
> with random effects of Y chromosome, Y chromosome source population,
> genetic background, and the interactions between Y/Y-source and genetic
> background, would I be able to get estimates of the direct genetic and
> epistatic variances within and among the source populations?
> - I could build two models, one with Y chromosome and genetic background  
> as
> random effects (including the interaction), and the other with  
> Y-chromosome
> source population and genetic background as random effects (including the
> interaction). These two models would separately estimate the within and
> among population variances. I think this would be the correct approach.
> However, I'm unconvinced that the latter would give the desired division  
> in
> to direct and epistatic Y-linked variation.
>
> Thanks,
> Rob
>
> *Please kindly note*, advice on prior specification when estimating
> interaction effects would be also very highly appreciated, remembering  
> that
> the variance components are likely very small. I have included a
> demonstration script which makes some dummy data, and shows some of the
> proposed models. The script includes a filepath which you can edit if you
> wish to save and load chains, and switches at line 56 to turn the chains
> on/off when running scripts.
>
> ##############
> ## R SCRIPT ##
> ##############
>
> # Y-background interaction dummy data
> rm(list=ls())
> library("lme4")
> library("MCMCglmm")
> set.seed(24)
>
> # Set filepath (CUSTOMISE THIS IF YOU WISH TO BE ABLE TO SAVE AND LOAD
> CHAINS)
> filepath = paste0("C:\\Users\\Rob\\Notes\\Y_epistasis\\")
>
> #### Description of dummy data ####
> # 20 Y chromosomes randomly sampled from 3 populations (A1:A20, B1:B20,
> C1:C20, n = 60)
> # Test in genetic backgrounds (BG) from three populations (Canton [CN],
> Zimbabwe [ZW], and Dahomey [DH])
> # Measure a trait (Lifepsan) in 90 individuals per combination of Y & BG
> # Measured across three replicate blocks (BL1, BL2, BL3), with two vials
> each per block
>
> n1 = 20 # Number of Y's sampled per source population
> n2 = 30 # Number of measurements per block/line
> n3 = 3  # Number of blocks (BL1, BL2, BL3)
> n4 = 3 # Number of genetic backgrounds (CN, ZW, DH)
> n5 = 3  # Number of Y source populations (A, B, C)
> n6 = 2  # Number of vials per block/Y/BG
>
> # Construction of data
> dummy = data.frame(
> as.factor(rep(c(paste0("A",1:n1), paste0("B",1:n1), paste0("C",1:n1)),  
> each
> = n2*n3, times = n4)),
> as.factor(rep(c("A","B","C"), each = n1*n2*n3, times = n5)),
> as.factor(rep(c("CN","ZW","DH"), each = n1*n2*n3*n4, times = 1)),
> as.factor(rep(c("BL1","BL2","BL3"), each = n2)),
> as.factor(rep(c("A","B"), each = n2 / n6)),
> as.numeric(abs(round(rnorm(n1*n2*n3*n4*n5, 50, 15),0)))
> )
> colnames(dummy) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age")
> dummy$Vial = paste(dummy$Y, dummy$Y.Source, dummy$BG, dummy$Block,
> dummy$Vial, sep = "_")
> head(dummy)
>
> # Mean zero unit variance for Age (response variable)
> dummy$Score = (dummy$Age - mean(dummy$Age)) / sd(dummy$Age)
>
> # Subset DFs (Only one source population and one genetic background, as  
> in
> previous JEB paper)
> dummy_A = data.frame(split(dummy , f = dummy$Y.Source)[1])
> dummy_A_CN = data.frame(split(dummy_A , f = dummy_A$A.BG)[1])
> colnames(dummy_A) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age",
> "Score")
> colnames(dummy_A_CN) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age",
> "Score")
>
> # MCMC Priors
> prior1 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
> G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
> R  = list(V = 1, nu=0.002))
>
> prior2 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
> G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
> G3 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
> R  = list(V = 1, nu=0.002))
>
> # MCMC Switches
> testing = "y"
> runChain_A_CN1 = "y"
> runChain_A1 = "y"
> runChain_1 = "y"
>
> # MCMC Details
> if(testing == "y"){
> nitt = 10000
> burn = 1000
> thin = 10
> }else{
> nitt = 100000
> burn = 10000
> thin = 100
> }
>
> # MCMC Chain (as in JEB Paper: One Y source population, One genetic
> background)
> # Within-population Y-linked variation
> if(runChain_A_CN1=="y"){
> Chain_A_CN1 = MCMCglmm(Score ~1 + Block,
> random = ~Y + Vial,
> rcov = ~units,
> nitt = nitt,
> thin = thin,
> burnin = burn,
> prior = prior1,
> family = "gaussian",
> start = list(QUASI = FALSE),
> data = dummy_A_CN)
> file = paste(filepath, "Chain_A_CN1.rda", sep = "")
> save(Chain_A_CN1, file = file)
> }else{}
>
> ##############################
> #### Proposed MCMC Chains ####
> ##############################
>
> # Within-population Y-linked variation split in to direct and epistatic
> if(runChain_A1=="y"){
> Chain_A1 = MCMCglmm(Score ~1 + Block,
> random = ~Y + BG + Vial,
> rcov = ~units,
> nitt = nitt,
> thin = thin,
> burnin = burn,
> prior = prior2,
> family = "gaussian",
> start = list(QUASI = FALSE),
> data = dummy_A)
> file = paste(filepath, "Chain_A1.rda", sep = "")
> save(Chain_A1, file = file)
> }else{}
>
> # Among-population Y-linked variation split in to direct and epistatic
> if(runChain_1=="y"){
> Chain_1 = MCMCglmm(Score ~1 + Block,
> random = ~Y.Source + BG + Vial,
> rcov = ~units,
> nitt = nitt,
> thin = thin,
> burnin = burn,
> prior = prior2,
> family = "gaussian",
> start = list(QUASI = FALSE),
> data = dummy)
> file = paste(filepath, "Chain_1.rda", sep = "")
> save(Chain_1, file = file)
> }else{}
>
> Chain.A_CN1 = load(paste(filepath, "Chain_A_CN1.rda", sep= ""))
> Chain.A1 = load(paste(filepath, "Chain_A1.rda", sep= ""))
> Chain.1 = load(paste(filepath, "Chain_1.rda", sep= ""))
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland


From karljarvis at gmail.com  Wed Nov  4 23:50:31 2015
From: karljarvis at gmail.com (Karl Jarvis)
Date: Wed, 4 Nov 2015 15:50:31 -0700
Subject: [R-sig-ME] multiple random effects and correlation structure in nlme
Message-ID: <72E6F2A7-6DF5-4F9E-BE63-979482274BDA@gmail.com>

Hi all,
I am trying to build a model that includes two random effects while also using a correlation structure to account for spatial autocorrelation. It?s a full factorial study on simulations of wildlife where individuals are spread across landscapes, so one of the random effects (N) is crossed. 

If I use nlme I can do this by reusing creating a new group factor by pasting the three crossed factors together (would be land:barr:mort in lme4), which I call ?lr'. The parameter estimates are similar, so it seems ok. (Link to the data frame: https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg <https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg> )
	ibr4 <- read.csv(?~/ibr4.csv?)
	m1 <- lme(A ~ barr + mort, random = list(~cost | land, ~N | lr), data=ibr4, method = ?ML?)

Once I try to do that along with a correlation structure, it complains that there are incompatible formulas for ?random? and ?correlation?. 
	m2 <- lme(A ~ barr + mort, random = list(~cost | land, ~N | lr), data=ibr4, method = ?ML?,
	correlation = corExp(form = ~ x+y | lr))

I think it?s because it doesn?t know how to relate lr to land, because it complains the same way when the only random effect is '~cost | land?. However, when one random effect is in the model with a correlation structure nested as ~x+y | land/barr/mort, it does work. But it doesn?t seem to ever accept multiple random effects together with a correlation structure. I know Pinheiro and Bates say in their book (p.163) that you can build a crossed random-effects structure with pdBlocked and pdIdent, but (1) it?s not clear to me how to do this for a single random effect, and (2) it?s not clear to me that you could include multiple random effects in such a structure. Am I misunderstanding how correlation structures and/or random effects work? Let me know if you need more information about my data. 

Thanks,
Karl
	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Nov  5 09:45:24 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 5 Nov 2015 09:45:24 +0100
Subject: [R-sig-ME] multiple random effects and correlation structure in
	nlme
In-Reply-To: <72E6F2A7-6DF5-4F9E-BE63-979482274BDA@gmail.com>
References: <72E6F2A7-6DF5-4F9E-BE63-979482274BDA@gmail.com>
Message-ID: <CAJuCY5zr52duPmCjOxxH5+8THB2rgVT4=VTjPQAxc9a6AMm1Yw@mail.gmail.com>

Dear Karl,

You have only 2 levels of cost. So it better to move that to the fixed
effects. Then you'll have only one random effect.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-04 23:50 GMT+01:00 Karl Jarvis <karljarvis at gmail.com>:

> Hi all,
> I am trying to build a model that includes two random effects while also
> using a correlation structure to account for spatial autocorrelation. It?s
> a full factorial study on simulations of wildlife where individuals are
> spread across landscapes, so one of the random effects (N) is crossed.
>
> If I use nlme I can do this by reusing creating a new group factor by
> pasting the three crossed factors together (would be land:barr:mort in
> lme4), which I call ?lr'. The parameter estimates are similar, so it seems
> ok. (Link to the data frame:
> https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg <
> https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg> )
>         ibr4 <- read.csv(?~/ibr4.csv?)
>         m1 <- lme(A ~ barr + mort, random = list(~cost | land, ~N | lr),
> data=ibr4, method = ?ML?)
>
> Once I try to do that along with a correlation structure, it complains
> that there are incompatible formulas for ?random? and ?correlation?.
>         m2 <- lme(A ~ barr + mort, random = list(~cost | land, ~N | lr),
> data=ibr4, method = ?ML?,
>         correlation = corExp(form = ~ x+y | lr))
>
> I think it?s because it doesn?t know how to relate lr to land, because it
> complains the same way when the only random effect is '~cost | land?.
> However, when one random effect is in the model with a correlation
> structure nested as ~x+y | land/barr/mort, it does work. But it doesn?t
> seem to ever accept multiple random effects together with a correlation
> structure. I know Pinheiro and Bates say in their book (p.163) that you can
> build a crossed random-effects structure with pdBlocked and pdIdent, but
> (1) it?s not clear to me how to do this for a single random effect, and (2)
> it?s not clear to me that you could include multiple random effects in such
> a structure. Am I misunderstanding how correlation structures and/or random
> effects work? Let me know if you need more information about my data.
>
> Thanks,
> Karl
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From quentin.schorpp at ti.bund.de  Thu Nov  5 13:16:25 2015
From: quentin.schorpp at ti.bund.de (Quentin Schorpp)
Date: Thu, 5 Nov 2015 13:16:25 +0100
Subject: [R-sig-ME] Small sample Size; repeated measurements binomial glmer
Message-ID: <563B4899.3050705@ti.bund.de>

Hello,

I searched a lot in the internet, but i didn't find sufficient information.
I believe I've got a very simple study design, however there are some 
characteristics taking me to the brink of possible.

I have two sampling campaigns, autumn year 1 and autumn year 2,
I sampled five agricultural fields of different ages, but each age_class 
has got only 3 repetitions.
My response is proportion of fungal feeding species.

I am interested in the effect of age classes (increase over time) and if 
this effect is reflected during the time of sampling.
Since i should be able to observe an increase during a 1 year time 
interval, then.

My Model is:
glmer(response ~ age_class*autumn + (1|field), family="binomial", 
weights=total number of Individuals, data)

However, I have the following problems:

1 - My N = 30, but my N(group) = 3
1 - I don't know the power of my analysis
2 - I'm not able to drop Outliers from the data (or am I?)
3 - my random factor has only 2 levels, so N(random) = 2

I think in Bolker et al. (2008) und Zuur et al. (2009) st. is said about 
that there is no need to use random factors when N(random) = 2

Since I am quite confused about my opportunities to handle patterns in 
residuals of the above model, I'm asking you about your opinions. Have i 
chosen the right Model formulation?

I think I'd feel more confident with a non parametric test, sth. like a 
rank based estimation of mixed effects nested models (rlme package), for 
which i found not a single example how to use them with repeated 
measures (also for PERMANOVA), or sth. else.
At least i need to report an Anova table and pairwise comparisons

yours sincerely,
Quentin

-- 
Quentin Schorpp, M.Sc.
Th?nen-Institut f?r Biodiversit?t
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.

Quentin Schorpp, M.Sc.
Th?nen Institute of Biodiversity
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Nov  5 15:44:15 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 5 Nov 2015 09:44:15 -0500
Subject: [R-sig-ME] Small sample Size;
	repeated measurements binomial glmer
In-Reply-To: <563B4899.3050705@ti.bund.de>
References: <563B4899.3050705@ti.bund.de>
Message-ID: <CABghstTcriFqPCKV=qGfCd_9ujFiOV7ytBL85qntByPQ6cYRXQ@mail.gmail.com>

On Thu, Nov 5, 2015 at 7:16 AM, Quentin Schorpp
<quentin.schorpp at ti.bund.de> wrote:
> Hello,
>
> I searched a lot in the internet, but i didn't find sufficient information.
> I believe I've got a very simple study design, however there are some
> characteristics taking me to the brink of possible.
>
> I have two sampling campaigns, autumn year 1 and autumn year 2,
> I sampled five agricultural fields of different ages, but each age_class
> has got only 3 repetitions.
> My response is proportion of fungal feeding species.

  Each field has a different, i.e. unique age, e.g. field 1 = 1.5,
field 2 = 2.3, field 3 = 3, field 4= 7, field 5 = 10?   3 samples each
in 2 autumns?  (This would be 5 x 3 x 2 = 30, but I'm not sure if
that's the actual experimental design ...)

>
> I am interested in the effect of age classes (increase over time) and if
> this effect is reflected during the time of sampling.
> Since i should be able to observe an increase during a 1 year time
> interval, then.
>
> My Model is:
> glmer(response ~ age_class*autumn + (1|field), family="binomial",
> weights=total number of Individuals, data)
>
> However, I have the following problems:
>
> 1 - My N = 30, but my N(group) = 3

   That doesn't really matter.

> 1 - I don't know the power of my analysis

  To run a power analysis you need to decide what effect sizes you're
expecting.  There aren't simple canned power  analyses for mixed models
like ?power.t.test in base R, but

library("sos"); findFn("lme4 power analysis")

finds the hamlet, longpower, odprism, multiRR, pamm ... packages ...
or look at https://rpubs.com/bbolker/11703 ...


> 2 - I'm not able to drop Outliers from the data (or am I?)

  why not?

> 3 - my random factor has only 2 levels, so N(random) = 2

  I'm confused.  You have 'field' as your grouping variable above.
I thought you said you had 5 fields?

>
> I think in Bolker et al. (2008) und Zuur et al. (2009) st. is said about
> that there is no need to use random factors when N(random) = 2

  Indeed, if you have fewer than about 5 groups, random effect estimates
are going to be low-power/unreliable (unless you do something fancy like
impose a Bayesian prior on the variance)

>
> Since I am quite confused about my opportunities to handle patterns in
> residuals of the above model, I'm asking you about your opinions. Have i
> chosen the right Model formulation?
>
> I think I'd feel more confident with a non parametric test, sth. like a
> rank based estimation of mixed effects nested models (rlme package), for
> which i found not a single example how to use them with repeated
> measures (also for PERMANOVA), or sth. else.
> At least i need to report an Anova table and pairwise comparisons
>
> yours sincerely,
> Quentin
>
> --
> Quentin Schorpp, M.Sc.
> Th?nen-Institut f?r Biodiversit?t
> Bundesallee 50
> 38116 Braunschweig (Germany)
>
> Tel:  +49 531 596-2524
> Fax:  +49 531 596-2599
> Mail: quentin.schorpp at ti.bund.de
> Web:  http://www.ti.bund.de
>
> Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
> besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.
>
> Quentin Schorpp, M.Sc.
> Th?nen Institute of Biodiversity
> Bundesallee 50
> 38116 Braunschweig (Germany)
>
> Tel:  +49 531 596-2524
> Fax:  +49 531 596-2599
> Mail: quentin.schorpp at ti.bund.de
> Web:  http://www.ti.bund.de
>
> The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
> consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From F.Hintz at let.ru.nl  Thu Nov  5 15:55:51 2015
From: F.Hintz at let.ru.nl (Hintz, F. (Florian))
Date: Thu, 5 Nov 2015 14:55:51 +0000
Subject: [R-sig-ME] Simulating Data from a Linear Mixed Model
Message-ID: <6F7100EE1865B54CBF5181D95FD76AFD572F75@exprd02.hosting.ru.nl>

Hi,

I have a question that is very much related to an already existing post (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000293.html), however, I don?t seem to be able to get it to run for my purposes.

I would like to simulate additional data based on a linear mixed effect model that has the following structure:

model.full = lmer(rt_log ~ condition + (1+condition|item) + (1+condition|subj), data = data)

The dependent variable is continuous. The fixed factor ?condition? has two levels. Both random factors have random intercepts and random slopes by ?condition?.

Best,
Florian.

--
Florian Hintz
Centre for Language Studies
Radboud University
Nijmegen (The Netherlands)


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Nov  5 16:16:00 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 5 Nov 2015 10:16:00 -0500
Subject: [R-sig-ME] Simulating Data from a Linear Mixed Model
In-Reply-To: <6F7100EE1865B54CBF5181D95FD76AFD572F75@exprd02.hosting.ru.nl>
References: <6F7100EE1865B54CBF5181D95FD76AFD572F75@exprd02.hosting.ru.nl>
Message-ID: <CABghstQM3cbrh4WVDvrz4=vGbFRKriEQxudiZwV_7-4VD8nx0w@mail.gmail.com>

lme4 has gotten much better at simulating since 2007; there's now a built-in
simulation mechanism.

----------
dd <- expand.grid(item=factor(1:10),subj=factor(1:30),condition=factor(1:2))
form <- log.rt ~ condition + (1+condition|item) + (1+condition|subj)

set.seed(101)

library("lme4")

dd$log.rt <- simulate(form[-2], newdata=dd,
                newparams=list(beta=rep(0,2),
                theta=rep(1,6), ## length = 2 * (2*(2+1)/2)
                sigma=1),
                family=gaussian)[[1]]

ff <- lFormula(form,data=dd)
names(ff$reTrms$Ztlist) ## subj comes before item ...
m <- lmer(form,data=dd)

The hardest part is figuring out the proper order/configuration
of the theta (Cholesky factor) parameters (column wise/lower triangular/
subject first, then item).


From baron at psych.upenn.edu  Thu Nov  5 16:26:40 2015
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 5 Nov 2015 10:26:40 -0500
Subject: [R-sig-ME] correlation of two tests treating items of both tests as
	random effects?
Message-ID: <20151105152640.GA306@psych.upenn.edu>

I thought I had a solution to this problem, but I don't. The problem
is very simple to state. It is to find whether one test correlates
with another, when each test has several items sampled from a larger
population of potential items.

I give two psychological tests to a group of subjects. Each test can
be seen as a sample of items from a population. Vocabulary tests and
arithmetic problems are examples.[1] Usually researchers just get a
total score on each test and look at the Pearson correlation. And
usually this is fine because the correlation is high enough that its
existence is not in doubt, and the magnitude of the correlation is of
primary interest.

But sometimes some theoretical question hinges on whether the tests
correlate at all. They could correlate spuriously because of the
particular sample of items used in each test. So one way to handle
this is to think of items as random effects.

It is easy to do this with lmer() when ONE of the two tests is treated
as a random effect. Each observation is the subject's score on one
item of that test (test 1), and the summary score of the other test
(test 2) is the predictor. The model has crossed random effects for
subjects and test 1 items. The number of rows in the data frame is
(number of subjects) times (number of items in test 1).

I thought it might be possible to extend this idea by making each row
consist of a subject's score on one item of test 1 and her score on
one item of test 2. The total number of rows would be (number of
subjects) times (number of items in test 1) times (number of items in
test 2). And I would include crossed random effects for subjects, test
1 items, and test 2 items. But then what? Do I just predict one test
from the other, as before? (The direction may matter, but that is the
least of my worries.)

I'm stuck. And this may be a blind alley.

Jon

Note:

[1] Not all psychological tests are like this. Some are designed to
represent a balance between different items so that only the test as a
whole, not each item, measures the trait of interest correctly.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron


From quentin.schorpp at ti.bund.de  Thu Nov  5 17:08:25 2015
From: quentin.schorpp at ti.bund.de (Quentin Schorpp)
Date: Thu, 5 Nov 2015 17:08:25 +0100 (CET)
Subject: [R-sig-ME] Small sample Size;
 repeated measurements binomial glmer
In-Reply-To: <CABghstTcriFqPCKV=qGfCd_9ujFiOV7ytBL85qntByPQ6cYRXQ@mail.gmail.com>
References: <563B4899.3050705@ti.bund.de>
	<CABghstTcriFqPCKV=qGfCd_9ujFiOV7ytBL85qntByPQ6cYRXQ@mail.gmail.com>
Message-ID: <32333c0a1d4251dcda333709cac92689.squirrel@webmail.ti.bund.de>

Hello,

Thank you very much for your answer,
I'm so sorry, what I wrote was misleading: I did not sample five
agricultural fields, but 15 agricultural fields of five different
age_classes, hence each age_class was replicated 3times.

And, yes my total number of samples is 30, each of the 15 fields was
sampled two times repeatedly. Therfore each field (i.e. subject appears
twice in the data)

I thought since I compare five different populations (the age_classes),
and the sample size would be the number of real replicates, in fact 3.
If I would drop an outlier then, I would reduce the number of replicates
(i.e. sample size) to only 2.

But if the total sample size is what matters, then it would be 30 and I'll
have one Problem less. Because I will be able to drop some outliers.

Things become even more complicated, since one category was not sampled
two times repeatedly over time, but the three fields of category five were
switched in the second year to three different fields, so this group has
got 6 replicates indeed. I think this is called partly nested.

I'm going to read your recommendations of literature, I am very curious
about, what degree of trustability can i expect from that kind of
experimental design.

What's your opinion, can I use the model the way it is, or should i
analyse each time-point separately, or build the mean of both?
Do you know a tutoraial or a book about the inclusion of bayesian priors
in binomial glmm's, that you could recommend me?

Again, thank you very much for taking your time and answering my
questions, unless i won't bother you, i'd like to say, that you
contributed more than anybody else to a deeper understanding of glmms for
so many people, by writing comments on stackoverflow. That is incredible,
thank you very much for that.

Quentin

> On Thu, Nov 5, 2015 at 7:16 AM, Quentin Schorpp
> <quentin.schorpp at ti.bund.de> wrote:
>> Hello,
>>
>> I searched a lot in the internet, but i didn't find sufficient
>> information.
>> I believe I've got a very simple study design, however there are some
>> characteristics taking me to the brink of possible.
>>
>> I have two sampling campaigns, autumn year 1 and autumn year 2,
>> I sampled five agricultural fields of different ages, but each age_class
>> has got only 3 repetitions.
>> My response is proportion of fungal feeding species.
>
>   Each field has a different, i.e. unique age, e.g. field 1 = 1.5,
> field 2 = 2.3, field 3 = 3, field 4= 7, field 5 = 10?   3 samples each
> in 2 autumns?  (This would be 5 x 3 x 2 = 30, but I'm not sure if
> that's the actual experimental design ...)
>
>>
>> I am interested in the effect of age classes (increase over time) and if
>> this effect is reflected during the time of sampling.
>> Since i should be able to observe an increase during a 1 year time
>> interval, then.
>>
>> My Model is:
>> glmer(response ~ age_class*autumn + (1|field), family="binomial",
>> weights=total number of Individuals, data)
>>
>> However, I have the following problems:
>>
>> 1 - My N = 30, but my N(group) = 3
>
>    That doesn't really matter.
>
>> 1 - I don't know the power of my analysis
>
>   To run a power analysis you need to decide what effect sizes you're
> expecting.  There aren't simple canned power  analyses for mixed models
> like ?power.t.test in base R, but
>
> library("sos"); findFn("lme4 power analysis")
>
> finds the hamlet, longpower, odprism, multiRR, pamm ... packages ...
> or look at https://rpubs.com/bbolker/11703 ...
>
>
>> 2 - I'm not able to drop Outliers from the data (or am I?)
>
>   why not?
>
>> 3 - my random factor has only 2 levels, so N(random) = 2
>
>   I'm confused.  You have 'field' as your grouping variable above.
> I thought you said you had 5 fields?
>
>>
>> I think in Bolker et al. (2008) und Zuur et al. (2009) st. is said about
>> that there is no need to use random factors when N(random) = 2
>
>   Indeed, if you have fewer than about 5 groups, random effect estimates
> are going to be low-power/unreliable (unless you do something fancy like
> impose a Bayesian prior on the variance)
>
>>
>> Since I am quite confused about my opportunities to handle patterns in
>> residuals of the above model, I'm asking you about your opinions. Have i
>> chosen the right Model formulation?
>>
>> I think I'd feel more confident with a non parametric test, sth. like a
>> rank based estimation of mixed effects nested models (rlme package), for
>> which i found not a single example how to use them with repeated
>> measures (also for PERMANOVA), or sth. else.
>> At least i need to report an Anova table and pairwise comparisons
>>
>> yours sincerely,
>> Quentin
>>
>> --
>> Quentin Schorpp, M.Sc.
>> Th?nen-Institut f?r Biodiversit?t
>> Bundesallee 50
>> 38116 Braunschweig (Germany)
>>
>> Tel:  +49 531 596-2524
>> Fax:  +49 531 596-2599
>> Mail: quentin.schorpp at ti.bund.de
>> Web:  http://www.ti.bund.de
>>
>> Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r
>> L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
>> besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie
>> und Technologie forschen und die Politik beraten.
>>
>> Quentin Schorpp, M.Sc.
>> Th?nen Institute of Biodiversity
>> Bundesallee 50
>> 38116 Braunschweig (Germany)
>>
>> Tel:  +49 531 596-2524
>> Fax:  +49 531 596-2599
>> Mail: quentin.schorpp at ti.bund.de
>> Web:  http://www.ti.bund.de
>>
>> The Johann Heinrich von Th?nen Institute, Federal Research Institute for
>> Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
>> consists of 15 specialized institutes that carry out research and
>> provide policy advice in the fields of economy, ecology and technology.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From karljarvis at gmail.com  Thu Nov  5 17:32:49 2015
From: karljarvis at gmail.com (Karl Jarvis)
Date: Thu, 5 Nov 2015 09:32:49 -0700
Subject: [R-sig-ME] multiple random effects and correlation structure in
	nlme
In-Reply-To: <CAJuCY5zr52duPmCjOxxH5+8THB2rgVT4=VTjPQAxc9a6AMm1Yw@mail.gmail.com>
References: <72E6F2A7-6DF5-4F9E-BE63-979482274BDA@gmail.com>
	<CAJuCY5zr52duPmCjOxxH5+8THB2rgVT4=VTjPQAxc9a6AMm1Yw@mail.gmail.com>
Message-ID: <69716CEA-E1D7-4D7E-9279-F6D2CBDBC4D2@gmail.com>

Thierry,
Thanks for your reply. 

I hadn?t used ?cost? as a fixed effect because I thought it had to be considered random. I have 10 simulated landscapes composed a combination of costs 1 and 4 in random fractal patterns. My ?cost? column refers to the cost at regular points across the landscapes. Because they were randomly generated, I thought that meant that they should be random effects. But if that?s not the case, that could simplify things.

If I run it this way,
    lme(fixed = He ~ barr + mort + cost, random = ~ N | lr, data = ibr4, 
             correlation = corExp(form = ~ x + y | lr), method = ?ML?,
             control=lmeControl(opt = "nlminb"))

It gives this error:
Error in lme.formula(fixed = He ~ barr + mort + cost, random = ~N | lr,  : 
  nlminb problem, convergence error code = 1
  message = iteration limit reached without convergence (10)

And if I change the optimizer to ?optim? it gives me this error:
Error in logLik.reStruct(object, conLin) : 
  NA/NaN/Inf in foreign function call (arg 3)

However, it works for me to run it this way, with barr and mort merged into one grouping factor ?road?, nested in ?land":
    lme(fixed = He ~ barr + mort + cost, random = ~ N | land, data = ibr4, 
             correlation = corExp(form = ~ x + y | land/road), method = ?ML?,
             control=lmeControl(opt = "nlminb"))

    lme(fixed = He ~ barr + mort + cost, random = ~ N | land/road, data = ibr4, 
             correlation = corExp(form = ~ x + y | land/road), method = ?ML?,
             control=lmeControl(opt = "nlminb?))

I know that ?land" has a much greater influence on ?N" than either ?barr? or ?mort? does, but I know that all 3 (land, barr, and mort) affect N. But AIC tells me that ?land? works better as a grouping factor than land/road. So maybe I shouldn?t worry about nesting in that case and can ignore the issues with trying to cross the factors. Does that make sense, or do you have other ideas about getting it to work? 
Karl

> On Nov 5, 2015, at 1:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Karl,
> 
> You have only 2 levels of cost. So it better to move that to the fixed effects. Then you'll have only one random effect.
> 
> Best regards,
> 
> Thierry
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2015-11-04 23:50 GMT+01:00 Karl Jarvis <karljarvis at gmail.com <mailto:karljarvis at gmail.com>>:
> Hi all,
> I am trying to build a model that includes two random effects while also using a correlation structure to account for spatial autocorrelation. It?s a full factorial study on simulations of wildlife where individuals are spread across landscapes, so one of the random effects (N) is crossed.
> 
> If I use nlme I can do this by reusing creating a new group factor by pasting the three crossed factors together (would be land:barr:mort in lme4), which I call ?lr'. The parameter estimates are similar, so it seems ok. (Link to the data frame: https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg <https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg><https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg <https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg>> )
>         ibr4 <- read.csv(?~/ibr4.csv?)
>         m1 <- lme(A ~ barr + mort, random = list(~cost | land, ~N | lr), data=ibr4, method = ?ML?)
> 
> Once I try to do that along with a correlation structure, it complains that there are incompatible formulas for ?random? and ?correlation?.
>         m2 <- lme(A ~ barr + mort, random = list(~cost | land, ~N | lr), data=ibr4, method = ?ML?,
>         correlation = corExp(form = ~ x+y | lr))
> 
> I think it?s because it doesn?t know how to relate lr to land, because it complains the same way when the only random effect is '~cost | land?. However, when one random effect is in the model with a correlation structure nested as ~x+y | land/barr/mort, it does work. But it doesn?t seem to ever accept multiple random effects together with a correlation structure. I know Pinheiro and Bates say in their book (p.163) that you can build a crossed random-effects structure with pdBlocked and pdIdent, but (1) it?s not clear to me how to do this for a single random effect, and (2) it?s not clear to me that you could include multiple random effects in such a structure. Am I misunderstanding how correlation structures and/or random effects work? Let me know if you need more information about my data.
> 
> Thanks,
> Karl
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From jake987722 at hotmail.com  Thu Nov  5 23:57:32 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Thu, 5 Nov 2015 16:57:32 -0600
Subject: [R-sig-ME] correlation of two tests treating items of both
 tests as random effects?
In-Reply-To: <20151105152640.GA306@psych.upenn.edu>
References: <20151105152640.GA306@psych.upenn.edu>
Message-ID: <COL129-W808759A1C229732A64CD07CB290@phx.gbl>

Hi Jon,

It's an interesting problem. I just put up a github gist where I write a function to simulate data with the structure you describe, then fit what I think are the appropriate models (estimating OR ignoring random item variance) with lmer() and do the model comparisons:

https://gist.github.com/jake-westfall/3b9b4aee0c980a279acb

I ran the simulation 1000x with the true correlation at 0.5, and 1000x with the true correlation at 0. The true values are recovered quite well so it makes me think the approach is reasonable. However, at least for the parameter values I tried, adding random item variance made essentially no difference to the estimates/tests of the subject-level correlation in test scores. There's a little difference but it's hardly worth mentioning.

Basically I set up the data frame so that, if there are m items on each test, then each subject has 2*m rows in the data frame, m for each test. Then the model consists of two dummy variables indicating the test (no intercept/constant term), and these dummies vary randomly across subjects and items. You'll see in the model syntax that it's a bit hackish but it seems to work. Two other things to note about the approach I used: (a) the items from both tests are counted as a single random factor, although their variances are allowed to be different for each test; (b) the residual variance is constrained to be equal for observations from both tests, which is just an lmer() thing. In my sim I set parameter values as if the two tests are two different IQ tests, so it's fine. But this might be problematic for your actual data if the two tests are really different. You may need to scale items/observations before fitting the model or something.

Happy to hear comments from anyone else who read this far.

Jake

> Date: Thu, 5 Nov 2015 10:26:40 -0500
> From: baron at psych.upenn.edu
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] correlation of two tests treating items of both tests as	random effects?
> 
> I thought I had a solution to this problem, but I don't. The problem
> is very simple to state. It is to find whether one test correlates
> with another, when each test has several items sampled from a larger
> population of potential items.
> 
> I give two psychological tests to a group of subjects. Each test can
> be seen as a sample of items from a population. Vocabulary tests and
> arithmetic problems are examples.[1] Usually researchers just get a
> total score on each test and look at the Pearson correlation. And
> usually this is fine because the correlation is high enough that its
> existence is not in doubt, and the magnitude of the correlation is of
> primary interest.
> 
> But sometimes some theoretical question hinges on whether the tests
> correlate at all. They could correlate spuriously because of the
> particular sample of items used in each test. So one way to handle
> this is to think of items as random effects.
> 
> It is easy to do this with lmer() when ONE of the two tests is treated
> as a random effect. Each observation is the subject's score on one
> item of that test (test 1), and the summary score of the other test
> (test 2) is the predictor. The model has crossed random effects for
> subjects and test 1 items. The number of rows in the data frame is
> (number of subjects) times (number of items in test 1).
> 
> I thought it might be possible to extend this idea by making each row
> consist of a subject's score on one item of test 1 and her score on
> one item of test 2. The total number of rows would be (number of
> subjects) times (number of items in test 1) times (number of items in
> test 2). And I would include crossed random effects for subjects, test
> 1 items, and test 2 items. But then what? Do I just predict one test
> from the other, as before? (The direction may matter, but that is the
> least of my worries.)
> 
> I'm stuck. And this may be a blind alley.
> 
> Jon
> 
> Note:
> 
> [1] Not all psychological tests are like this. Some are designed to
> represent a balance between different items so that only the test as a
> whole, not each item, measures the trait of interest correctly.
> 
> -- 
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> Home page: http://www.sas.upenn.edu/~baron
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Fri Nov  6 01:31:04 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Fri, 6 Nov 2015 10:31:04 +1000
Subject: [R-sig-ME] correlation of two tests treating items of both
 tests asrandom effects?
In-Reply-To: <20151105152640.GA306@psych.upenn.edu>
References: <20151105152640.GA306@psych.upenn.edu>
Message-ID: <alpine.LMD.2.00.1511061022530.17587@orpheus.qimr.edu.au>

On Fri, 6 Nov 2015, Jonathan Baron wrote:

> I thought I had a solution to this problem, but I don't. The problem
> is very simple to state. It is to find whether one test correlates
> with another, when each test has several items sampled from a larger
> population of potential items.

Isn't this just the usual question about how to run a multivariate mixed 
model in lme4?  So you stack both tests with an appropriate indicator 
variable, and read off the correlations from the RE variances/covariances?

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From saroman at vims.edu  Fri Nov  6 19:58:57 2015
From: saroman at vims.edu (Sally A. Roman)
Date: Fri, 6 Nov 2015 18:58:57 +0000
Subject: [R-sig-ME] lme4 glmer convergence question
Message-ID: <F5884184AEB2BD44AC3307D5AD03A40E94D39E@mboxes2.campus.vims.edu>

Hello -
I am trying to use the lme4 package for a glmm and am getting a convergence code of 0 and a statement: Model failed to converge with max|grad| = 0.00791467 (tol = 0.001, component 1). I am interested in using the lme4 package because I would like to have AIC values to determine the appropriate model as I add in additional covariates.

Two weeks ago when I tried the same approach I got a warning message that the model failed to converge because of the max|grad| issue, but am not getting the warning message this time, just the statement at the end of the summary output.

Summary output below:
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
Family: Gamma  ( log )
Formula: Meat_Weight ~ logsh + SAMS_region_2015 + (1 | StationID)
   Data: datad
Control: glmerControl(optCtrl = list(maxfun = 100000))

    AIC      BIC   logLik deviance df.resid
 29841.2  29893.0 -14912.6  29825.2     4748

Scaled residuals:
    Min      1Q  Median      3Q     Max
-5.6389 -0.5089  0.0376  0.5660  7.3199

Random effects:
Groups    Name        Variance Std.Dev.
StationID (Intercept) 0.007073 0.0841
 Residual              0.026626 0.1632
Number of obs: 4756, groups:  StationID, 426

Fixed effects:
                     Estimate Std. Error t value             Pr(>|z|)
(Intercept)          -9.21833    0.10890  -84.65 < 0.0000000000000002
logsh                 2.62984    0.02223  118.33 < 0.0000000000000002
SAMS_region_2015ET    0.09299    0.03174    2.93             0.003393
SAMS_region_2015HC    0.12031    0.03347    3.59             0.000325
SAMS_region_2015HCsr  0.08405    0.03892    2.16             0.030810
SAMS_region_2015LI    0.07721    0.03209    2.41             0.016107

(Intercept)          ***
logsh                ***
SAMS_region_2015ET   **
SAMS_region_2015HC   ***
SAMS_region_2015HCsr *
SAMS_region_2015LI   *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
                 (Intr) logsh  SAMS__2015E SAMS_regn_2015HC
logsh            -0.968
SAMS__2015E      -0.179 -0.036
SAMS_regn_2015HC -0.166 -0.038  0.699
SAMS_rgn_2015HCs -0.139 -0.037  0.600       0.569
SAMS__2015L      -0.186 -0.027  0.728       0.691
                 SAMS_rgn_2015HCs
logsh
SAMS__2015E
SAMS_regn_2015HC
SAMS_rgn_2015HCs
SAMS__2015L       0.593
convergence code: 0
Model failed to converge with max|grad| = 0.00764043 (tol = 0.001, component 1)

Does this mean that the model is not converging? I also used the glmmPQL method. The coefficient parameter estimates are similar between the two model types.

Here is glmer (lme4) model code. I increased the maxfun to deal with other issues I had when I ran the model last time.

l1<-glmer(Meat_Weight~logsh+SAMS_region_2015+(1|StationID),
        family="Gamma"(link="log"),data=datad,control=glmerControl(optCtrl=list(maxfun=100000)))
Here is the glmmPQL code.

m1<-glmmPQL(fixed=Meat_Weight~logsh+SAMS_region_2015,random=~1|StationID,
        family=Gamma(link="log"),data=datad)

I am sure this is not information to diagnosis the problem, but if anyone has suggestions I can provide more data.

Thanks

Sally Roman
Fisheries Specialist
Virginia Institute of Marine Science
Marine Advisory Services

Phone: 804-684-7165
Fax: 804-684-7161

1375 Greate Road
Gloucester Point, VA 23062


	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Fri Nov  6 20:21:25 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 06 Nov 2015 19:21:25 +0000
Subject: [R-sig-ME] Simulating Data from a Linear Mixed Model
In-Reply-To: <6F7100EE1865B54CBF5181D95FD76AFD572F75@exprd02.hosting.ru.nl>
References: <6F7100EE1865B54CBF5181D95FD76AFD572F75@exprd02.hosting.ru.nl>
Message-ID: <CAO7JsnRyTD1w=F3zk+ngyCnUuXDzW4xAAV7tPPJT_b+nmvpzsQ@mail.gmail.com>

On Thu, Nov 5, 2015 at 8:56 AM Hintz, F. (Florian) <F.Hintz at let.ru.nl>
wrote:

> Hi,
>
> I have a question that is very much related to an already existing post (
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000293.html),
> however, I don?t seem to be able to get it to run for my purposes.
>
> I would like to simulate additional data based on a linear mixed effect
> model that has the following structure:
>
> model.full = lmer(rt_log ~ condition + (1+condition|item) +
> (1+condition|subj), data = data)
>
> The dependent variable is continuous. The fixed factor ?condition? has two
> levels. Both random factors have random intercepts and random slopes by
> ?condition?.
>
> Best,
> Florian.
>
> --
> Florian Hintz
> Centre for Language Studies
> Radboud University
> Nijmegen (The Netherlands)
>

It happens that http://arxiv.org/abs/1511.01864, which was uploaded
yesterday, happens to deal with exactly that same model.

	[[alternative HTML version deleted]]


From t.mondain-monval at lancaster.ac.uk  Thu Nov  5 17:23:24 2015
From: t.mondain-monval at lancaster.ac.uk (Mondain-Monval, Thomas)
Date: Thu, 5 Nov 2015 16:23:24 +0000
Subject: [R-sig-ME] Model Validation with glmmADMB
Message-ID: <309DE05AEBF50E46B1596965D19F285B37546B@EX-1-MB2.lancs.local>

Hi,

I am pretty new to mixed effects models and am using glmmADMB to analyse some bird reproductive success data. I have decided to use a hurdle model as I have a lot of true zeros in my dataset. I'm using the glmmadmb function with "truncnbinom2" as the family to analyse the non-zero part of the data first. However, now that I have my model and want to do validate it, I have run into a problem. When I call the residuals for the model all I get is a column of NAs with no actual values. All the model validation techniques I have previously used require residuals to do them, e.g. residuals vs fitted, residuals vs explanatory variables etc. What other validation techniques can you suggest? Or is there a way of getting residuals out of the model?

This is my full model:
non0ri<-glmmadmb(fledging.number~scnest.depth*scbrood.number + (1 | colony/burrow.code),
                 family="truncnbinom2",
                 data=subset(no.na, fledging.number>0))

Where fledging number is subsetted to only include non-zero data.

And I used residuals(non0ri) to try and get the residuals.

I hope you can help.

Thank you and best wishes,

Thomas

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Nov  6 22:04:03 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Nov 2015 16:04:03 -0500
Subject: [R-sig-ME] lme4 glmer convergence question
In-Reply-To: <F5884184AEB2BD44AC3307D5AD03A40E94D39E@mboxes2.campus.vims.edu>
References: <F5884184AEB2BD44AC3307D5AD03A40E94D39E@mboxes2.campus.vims.edu>
Message-ID: <CABghstQmzKeR13fw9xY-WnPnmpi_kT1f9kji48GwMfOAHdnubA@mail.gmail.com>

On Fri, Nov 6, 2015 at 1:58 PM, Sally A. Roman <saroman at vims.edu> wrote:
> Hello -
> I am trying to use the lme4 package for a glmm and am getting a convergence code of 0 and a statement: Model failed to converge with max|grad| = 0.00791467 (tol = 0.001, component 1). I am interested in using the lme4 package because I would like to have AIC values to determine the appropriate model as I add in additional covariates.

 In contrast to glmmPQL, I'm guessing?

> Two weeks ago when I tried the same approach I got a warning message that the model failed to converge because of the max|grad| issue, but am not getting the warning message this time, just the statement at the end of the summary output.
>
> Summary output below:
> Generalized linear mixed model fit by maximum likelihood (Laplace
>   Approximation) [glmerMod]
> Family: Gamma  ( log )
> Formula: Meat_Weight ~ logsh + SAMS_region_2015 + (1 | StationID)
>    Data: datad
> Control: glmerControl(optCtrl = list(maxfun = 100000))
>
>     AIC      BIC   logLik deviance df.resid
>  29841.2  29893.0 -14912.6  29825.2     4748
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -5.6389 -0.5089  0.0376  0.5660  7.3199
>
> Random effects:
> Groups    Name        Variance Std.Dev.
> StationID (Intercept) 0.007073 0.0841
>  Residual              0.026626 0.1632
> Number of obs: 4756, groups:  StationID, 426
>
> Fixed effects:
>                      Estimate Std. Error t value             Pr(>|z|)
> (Intercept)          -9.21833    0.10890  -84.65 < 0.0000000000000002
> logsh                 2.62984    0.02223  118.33 < 0.0000000000000002
> SAMS_region_2015ET    0.09299    0.03174    2.93             0.003393
> SAMS_region_2015HC    0.12031    0.03347    3.59             0.000325
> SAMS_region_2015HCsr  0.08405    0.03892    2.16             0.030810
> SAMS_region_2015LI    0.07721    0.03209    2.41             0.016107
>
> (Intercept)          ***
> logsh                ***
> SAMS_region_2015ET   **
> SAMS_region_2015HC   ***
> SAMS_region_2015HCsr *
> SAMS_region_2015LI   *
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>                  (Intr) logsh  SAMS__2015E SAMS_regn_2015HC
> logsh            -0.968
> SAMS__2015E      -0.179 -0.036
> SAMS_regn_2015HC -0.166 -0.038  0.699
> SAMS_rgn_2015HCs -0.139 -0.037  0.600       0.569
> SAMS__2015L      -0.186 -0.027  0.728       0.691
>                  SAMS_rgn_2015HCs
> logsh
> SAMS__2015E
> SAMS_regn_2015HC
> SAMS_rgn_2015HCs
> SAMS__2015L       0.593
> convergence code: 0
> Model failed to converge with max|grad| = 0.00764043 (tol = 0.001, component 1)
>
> Does this mean that the model is not converging? I also used the glmmPQL method. The coefficient parameter estimates are similar between the two model types.
>
> Here is glmer (lme4) model code. I increased the maxfun to deal with other issues I had when I ran the model last time.
>
> l1<-glmer(Meat_Weight~logsh+SAMS_region_2015+(1|StationID),
>         family="Gamma"(link="log"),data=datad,control=glmerControl(optCtrl=list(maxfun=100000)))
> Here is the glmmPQL code.
>
> m1<-glmmPQL(fixed=Meat_Weight~logsh+SAMS_region_2015,random=~1|StationID,
>         family=Gamma(link="log"),data=datad)
>
> I am sure this is not information to diagnosis the problem, but if anyone has suggestions I can provide more data.
>
> Thanks
>
> Sally Roman
> Fisheries Specialist
> Virginia Institute of Marine Science
> Marine Advisory Services
>
> Phone: 804-684-7165
> Fax: 804-684-7161


  Have you looked at ?convergence ?  The bottom line (as commented on
here recently by Doug Bates in this forum) is that the convergence
tests give a lot of false positives; I have thought a lot about
removing them, or at least about increasing the tolerances
considerably, but have been afraid to make changes that would lead to
a lot more false *negatives* (i.e. unreported problems with models)
without a lot more time & effort evaluating these rules and makng the
decision carefully (which I don't have right now ...)

  Especially if you are getting similar-enough results between glmmPQL
and glmer, I would feel free to ignore the warnings.


From pdevalpine at berkeley.edu  Tue Nov 10 01:38:28 2015
From: pdevalpine at berkeley.edu (Perry de Valpine)
Date: Mon, 9 Nov 2015 16:38:28 -0800
Subject: [R-sig-ME] Simulating Data from a Linear Mixed Model
In-Reply-To: <mailman.3.1446894001.27363.r-sig-mixed-models@r-project.org>
References: <mailman.3.1446894001.27363.r-sig-mixed-models@r-project.org>
Message-ID: <E7AB80C1-4831-4EC7-9200-4FF7649EDF73@berkeley.edu>

If you are willing to write the model in BUGS, you can use NIMBLE (R-nimble.org <http://r-nimble.org/>) to simulate from it.  One of the examples from the web site illustrates how to set up a GLMM in BUGS, and you can do it more compactly using linear algebra if you?d like.
Perry


> Date: Fri, 06 Nov 2015 19:21:25 +0000
> From: Douglas Bates <bates at stat.wisc.edu>
> To: "Hintz, F. (Florian)" <F.Hintz at let.ru.nl>,
> 	"r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Simulating Data from a Linear Mixed Model
> Message-ID:
> 	<CAO7JsnRyTD1w=F3zk+ngyCnUuXDzW4xAAV7tPPJT_b+nmvpzsQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> On Thu, Nov 5, 2015 at 8:56 AM Hintz, F. (Florian) <F.Hintz at let.ru.nl>
> wrote:
> 
>> Hi,
>> 
>> I have a question that is very much related to an already existing post (
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000293.html),
>> however, I don?t seem to be able to get it to run for my purposes.
>> 
>> I would like to simulate additional data based on a linear mixed effect
>> model that has the following structure:
>> 
>> model.full = lmer(rt_log ~ condition + (1+condition|item) +
>> (1+condition|subj), data = data)
>> 
>> The dependent variable is continuous. The fixed factor ?condition? has two
>> levels. Both random factors have random intercepts and random slopes by
>> ?condition?.
>> 
>> Best,
>> Florian.
>> 
>> --
>> Florian Hintz
>> Centre for Language Studies
>> Radboud University
>> Nijmegen (The Netherlands)
>> 
> 
> It happens that http://arxiv.org/abs/1511.01864, which was uploaded
> yesterday, happens to deal with exactly that same model.
> 
> 	[[alternative HTML version deleted]]
> 
> 


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Nov 10 01:57:19 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Nov 2015 19:57:19 -0500
Subject: [R-sig-ME] Simulating Data from a Linear Mixed Model
In-Reply-To: <6F7100EE1865B54CBF5181D95FD76AFD573029@exprd02.hosting.ru.nl>
References: <6F7100EE1865B54CBF5181D95FD76AFD572F75@exprd02.hosting.ru.nl>
	<CABghstQM3cbrh4WVDvrz4=vGbFRKriEQxudiZwV_7-4VD8nx0w@mail.gmail.com>
	<6F7100EE1865B54CBF5181D95FD76AFD573029@exprd02.hosting.ru.nl>
Message-ID: <CABghstRbD__ypBTnSmW8m6Etx+4dzO+4zaGB1Gc2TQ5w4Vf5Zw@mail.gmail.com>

  (please keep r-sig-mixed models in the Cc: line)

On Fri, Nov 6, 2015 at 3:54 AM, Hintz, F. (Florian) <F.Hintz at let.ru.nl> wrote:
> That's great! Thank you very much. I forgot to mention though that the experimental design was such that one subject was presented with one item in either condition 1 or condition 2. Would you know a way how to account for that in the expand.grid command? In the current version the data are simulated such that each 'new' subject has data points for one item in both conditions.

Something like this should do it:

dd <- expand.grid(item=factor(1:10),subj=factor(1:30))
dd <- transform(dd,condition=factor(ifelse(as.numeric(subj<=15,1,2)))

condition=factor(1:2))
>
> Many thanks!
>
> Florian.
>
> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: donderdag 5 november 2015 16:16
> To: Hintz, F. (Florian)
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Simulating Data from a Linear Mixed Model
>
> lme4 has gotten much better at simulating since 2007; there's now a built-in simulation mechanism.
>
> ----------
> dd <- expand.grid(item=factor(1:10),subj=factor(1:30),condition=factor(1:2))
> form <- log.rt ~ condition + (1+condition|item) + (1+condition|subj)
>
> set.seed(101)
>
> library("lme4")
>
> dd$log.rt <- simulate(form[-2], newdata=dd,
>                 newparams=list(beta=rep(0,2),
>                 theta=rep(1,6), ## length = 2 * (2*(2+1)/2)
>                 sigma=1),
>                 family=gaussian)[[1]]
>
> ff <- lFormula(form,data=dd)
> names(ff$reTrms$Ztlist) ## subj comes before item ...
> m <- lmer(form,data=dd)
>
> The hardest part is figuring out the proper order/configuration of the theta (Cholesky factor) parameters (column wise/lower triangular/ subject first, then item).


From luizernesto at gmail.com  Tue Nov 10 22:35:42 2015
From: luizernesto at gmail.com (Luiz Ernesto Costa Schmidt)
Date: Tue, 10 Nov 2015 19:35:42 -0200
Subject: [R-sig-ME] Plotting a glmmADMB model
Message-ID: <B1374D84-8B67-494C-8BC6-FB7D37A4D84E@gmail.com>

Dear users,
Thanks for your attention. I?m running a glmm model using the glmmadmb function provided in the package glmmADMB.
My dependent variable is the number of individuals belonging to a single species of an aquatic insect, sampled throughout two non-consecutive years. The samples were classified by the following fixed factors:
- year: two levels (2004, 2009);
- hydroperiod (hyd): classified in two levels (high and low flow);
- daytime (time): two levels, night or day;
- stratification (str): two levels, bottom and surface
- water current velocity (vel): quantitative variable used as an offset, since the sampling method is very sensitive for the amount of water filtered, which has a strong correlation with water current velocity.
A single random term was added to the model, named as sampleID, since sampling at the bottom and at the surface were performed at the same moment (as far as understand, the inclusion of such random factor will treta them as a sampling block). I also added two interaction terms (hydroperiod:daytime, hydroperiod:stratification).

The model that I tested was a confirmatory one, based on a very precise biological hypothesis, resulting in the following output:

-----------
glmmadmb(formula = Count ~ year + hyd * (time + str) + offset(vel) + (1 | sampleID),
			family = ?nbinom?, zeroInflation = T)

AIC: 1484.1 

Coefficients:
                               Estimate	Std. Error z value	Pr(>|z|)    
(Intercept)		-0.339	0.229	-1.48	0.13756    
year2009			-0.164	0.148	-1.11	0.26852    
hydlow			 0.197	0.259	 0.76	0.44747    
timenight			-0.556	0.254	-2.19	0.02851 *  
strsurf			 0.808	0.215	 3.75	0.00017 ***
hydlow:timenight	 0.709	0.311	 2.28	0.02270 *  
hydlow:strsurf		-0.195	0.263	-0.74	0.45832    
? 
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=366, sample=183 
Random effect variance(s):
Group=sampleID
            Variance StdDev
(Intercept)   0.2813 0.5304

Negative binomial dispersion parameter: 1.3265 (std. err.: 0.25595)
Zero-inflation: 1.0003e-06  (std. err.:  6.2823e-06 )

Log-likelihood: -732.046 
---------------

One graphical output that I opted to use shows the estimates provided by the model and their respective confidence intervals (I used the coefplot2 function).

Now I?m (desperately) trying to provide a better graphical representation about the predicted values from the model, in order to express graphically the magnitude and direction of variation explained by the model. However, I?m not sure if the data that I should use for such description comes from the following indexation 

model$fitted

or if I could use the command:

plot(interactionMeans(model))

Thank you so much for your attention,

Tch?

-- 
Luiz Ernesto Costa-Schmidt
http://lattes.cnpq.br/1402956553786728 <http://lattes.cnpq.br/1402956553786728>
P?s-doutorando - PNPD/CAPES
Universidade do Vale do Rio dos Sinos - UNISINOS
Programa de P?s-Gradua??o em Biologia
Avenida Unisinos, 950 - Sala E04 235
CEP 93022-000
S?o Leopoldo/RS - Brasil
Telefone: +55 51 3590.8477
http://www.unisinos.br/mestrado-e-doutorado/biologia <http://www.unisinos.br/mestrado-e-doutorado/biologia>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Nov 11 10:45:15 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 11 Nov 2015 09:45:15 +0000
Subject: [R-sig-ME] Mixed modelling course, Lisbon, Portugal
Message-ID: <56430E2B.9090702@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Linear mixed effects models,  GLMM and MCMC with R
Where:  Lisbon, Portugal
When:   15-19 February 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2016_02Lisbon_GLMM.pdf



Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From vdermauw at itg.be  Wed Nov 11 12:17:55 2015
From: vdermauw at itg.be (Veronique Dermauw)
Date: Wed, 11 Nov 2015 11:17:55 +0000
Subject: [R-sig-ME] glmmADMB
Message-ID: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>

Dear,

Recently I have been working on a dataset which seems to require a generalized linear mixed model with a negative binomial distribution.
I came across the glmmADMB package which seems ideal.
However, I am a bit stuck here (see codes and error message below).
The dataset I am working on, involves count variables (GIS) from animals from different villages who were allocated a treatment (Treatment) and were sampled at various Time point (hence Time and Time*Treatment).
I was wondering if you could assist me with this command?

Many thanks for your response,
Best regards,
Veronique Dermauw.

mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
summary(mod1b)
Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
  number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +  :
  NAs removed in constructing fixed-effect model frame: you should probably remove them manually, e.g. with na.omit()
2: In II[, ii] + REmat$codes[[i]] :
  longer object length is not a multiple of shorter object length


Veronique Dermauw
PhD, MSc Veterinary Medicine
Institute of Tropical Medicine
Nationalestraat 155
2000 Antwerp
+32(0)32476447


P Please consider the environment before printing this e-mail

Disclaimer: Http://www.itg.be/disclaimer

Directions to our location(s): http://g.co/maps/ua89b

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Nov 12 17:44:10 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 12 Nov 2015 17:44:10 +0100
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
References: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
Message-ID: <CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>

Dear Veronique,

It looks like your data contains missing values. Try to remove them. Your
syntax seems to be correct.

Note that Treatment + Time + Time * Treatment can be abbreviated to Time *
Treatment

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-11 12:17 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:

> Dear,
>
> Recently I have been working on a dataset which seems to require a
> generalized linear mixed model with a negative binomial distribution.
> I came across the glmmADMB package which seems ideal.
> However, I am a bit stuck here (see codes and error message below).
> The dataset I am working on, involves count variables (GIS) from animals
> from different villages who were allocated a treatment (Treatment) and were
> sampled at various Time point (hence Time and Time*Treatment).
> I was wondering if you could assist me with this command?
>
> Many thanks for your response,
> Best regards,
> Veronique Dermauw.
>
>
> mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
> summary(mod1b)
> Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
>   number of items to replace is not a multiple of replacement length
> In addition: Warning messages:
> 1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +
> :
>   NAs removed in constructing fixed-effect model frame: you should
> probably remove them manually, e.g. with na.omit()
> 2: In II[, ii] + REmat$codes[[i]] :
>   longer object length is not a multiple of shorter object length
>
>
> Veronique Dermauw
> PhD, MSc Veterinary Medicine
> Institute of Tropical Medicine
> Nationalestraat 155
> 2000 Antwerp
> +32(0)32476447
>
>
> P Please consider the environment before printing this e-mail
>
> Disclaimer: Http://www.itg.be/disclaimer
>
> Directions to our location(s): http://g.co/maps/ua89b
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From emmanuel.curis at parisdescartes.fr  Thu Nov 12 18:12:48 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Thu, 12 Nov 2015 18:12:48 +0100
Subject: [R-sig-ME] Question on random effects glm interpretation
Message-ID: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>

Dear all,

With a colleague, we are discussing about the appropriateness of a
random effects mixed effects generalized linear model (more
specifically, logistic regression) in a given experimental situation,
and wonder about it's correct interpretation.

Short version: is it correct to interpret random effects glm, with a
single random effect, as hierarchical models as random effects linear
models ?

Detailed version: our data consist of daily status of a set of
patients, the status beeing ? Infected ? or ? Not infected ?, during a
variable period of time. The aim is to see what changes the infection
probability.

A proposed approach was to use a random effect logistic regression to
evaluate this probability, with patient as a random effect.

However, we have one concern with that approach: interpretating it in
a hierarchical model idea, it seems that for a given patient, the
model should be a binomial one, in other words that the set of
Bernoulli variables observed each day for a given patient should be
independent, identically distributed. But this is obviously not the
case here: the variable is 0 until infection occurs (if it occurs),
and 1 after.  Consequently, we fear that the probability estimated in
the glmm will have no real meaningful interpretation.

Are we right with this hierarchical interpretation of the GLMM
(logistic) model, or is this fear not justified, and the
interpretation of the GLMM more complex, but would lead to correct and
interpretable estimations of infection probability?

As an alternative approach, we thought about a two-states Markov
chain, and working on transition probabilities from the ? non-infected ?
to the ? infected ? state. It seems to model what happens more
closely.  Is there any link between such a model and the logistic GLMM
described above, or another kind of GLMM model? 

And, semantic question, is such a model also in the scope of ? random
effects ? model and could be discussed here, in case help is needed, or
is it out of the scope of this list?

Thanks in advance for your opinions,
Best regards,

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From thierry.onkelinx at inbo.be  Thu Nov 12 21:59:18 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 12 Nov 2015 21:59:18 +0100
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
Message-ID: <CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>

Dear Emmanuel,

Maybe a survival analysis is more appropriate for that kind of data.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-12 18:12 GMT+01:00 Emmanuel Curis <emmanuel.curis at parisdescartes.fr>
:

> Dear all,
>
> With a colleague, we are discussing about the appropriateness of a
> random effects mixed effects generalized linear model (more
> specifically, logistic regression) in a given experimental situation,
> and wonder about it's correct interpretation.
>
> Short version: is it correct to interpret random effects glm, with a
> single random effect, as hierarchical models as random effects linear
> models ?
>
> Detailed version: our data consist of daily status of a set of
> patients, the status beeing ? Infected ? or ? Not infected ?, during a
> variable period of time. The aim is to see what changes the infection
> probability.
>
> A proposed approach was to use a random effect logistic regression to
> evaluate this probability, with patient as a random effect.
>
> However, we have one concern with that approach: interpretating it in
> a hierarchical model idea, it seems that for a given patient, the
> model should be a binomial one, in other words that the set of
> Bernoulli variables observed each day for a given patient should be
> independent, identically distributed. But this is obviously not the
> case here: the variable is 0 until infection occurs (if it occurs),
> and 1 after.  Consequently, we fear that the probability estimated in
> the glmm will have no real meaningful interpretation.
>
> Are we right with this hierarchical interpretation of the GLMM
> (logistic) model, or is this fear not justified, and the
> interpretation of the GLMM more complex, but would lead to correct and
> interpretable estimations of infection probability?
>
> As an alternative approach, we thought about a two-states Markov
> chain, and working on transition probabilities from the ? non-infected ?
> to the ? infected ? state. It seems to model what happens more
> closely.  Is there any link between such a model and the logistic GLMM
> described above, or another kind of GLMM model?
>
> And, semantic question, is such a model also in the scope of ? random
> effects ? model and could be discussed here, in case help is needed, or
> is it out of the scope of this list?
>
> Thanks in advance for your opinions,
> Best regards,
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From karraspito at yahoo.es  Thu Nov 12 23:08:00 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Thu, 12 Nov 2015 22:08:00 +0000 (UTC)
Subject: [R-sig-ME] Interpreting posterior mean and effective sample size
References: <1903235737.6476310.1447366080632.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1903235737.6476310.1447366080632.JavaMail.yahoo@mail.yahoo.com>


?? Hello everyone,
?? I would just like to ask some questions about the interpretation of the results of an MCMCglmm model. There is not so much information about that specific topic out there, after all!
?? This is my model:
?? extphenmodel5t<-MCMCglmm(cbind(appcareshort,appcarelong)~trait-1+trait:gender+trait:age+trait:religion+trait:sexor+trait:selfattr+trait:partnerattr+trait:gender:age+trait:gender:religion+trait:gender:sexor+trait:gender:selfattr+trait:gender:partnerattr+trait:age:religion+trait:age:sexor+trait:age:selfattr+trait:age:partnerattr+trait:religion:sexor+trait:religion:selfattr+trait:religion:partnerattr+trait:sexor:selfattr+trait:sexor:partnerattr+trait:selfattr:partnerattr,random=NULL,rcov=~corg(trait):units,family=c("threshold","threshold"),data=extphen,nitt=100000,singular.ok=TRUE)
?? And my results (a small part of them, the significant p was just made up for the sake of the question):
?? > summary(extphenmodel5t)? Iterations = 3001:99991 Thinning interval? = 10 Sample size? = 9700 ? DIC: ? R-structure:? ~corg(trait):units?????????????????????????????????????????? post.mean l-95% CI u-95% CI eff.samptraitappcareshort:traitappcareshort.units??? 1.0000?? 1.0000?? 1.0000??????? 0traitappcarelong:traitappcareshort.units???? 0.7409?? 0.6613?? 0.8096???? 7274traitappcareshort:traitappcarelong.units???? 0.7409?? 0.6613?? 0.8096?? ??7274traitappcarelong:traitappcarelong.units????? 1.0000?? 1.0000?? 1.0000??????? 0? Location effects: cbind(appcareshort, appcarelong) ~ trait - 1 + trait:gender + trait:age + trait:religion + trait:sexor + trait:selfattr + trait:partnerattr + trait:gender:age + trait:gender:religion + trait:gender:sexor + trait:gender:selfattr + trait:gender:partnerattr + trait:age:religion + trait:age:sexor + trait:age:selfattr + trait:age:partnerattr + trait:religion:sexor + trait:religion:selfattr + trait:religion:partnerattr + trait:sexor:selfattr + trait:sexor:partnerattr + trait:selfattr:partnerattr ????????????????????????????????????????  post.mean?? l-95% CI?? u-95% CI? eff.samp? pMCMC??? traitappcareshort??????????????????????? 3.242e+00 -3.209e+00? 9.638e+00? 9201.037 0.3247??? traitappcarelong???????????????????????? 3.700e+00 -2.789e+00? 1.034e+01? 8610.520 0.2625??? traitappcareshort:genderM?????????????? -1.128e-01 -2.526e+00? 2.356e+00? 9113.094 0.009**??? traitappcarelong:genderM???????????????? 1.273e-01 -2.270e+00? 2.663e+00? 8641.121 0.9243??? traitappcareshort:genderO??????????????? 1.005e+03 -1.787e+05? 1.873e+05? 9700.000 0.9872??? traitappcarelong:genderO??????????????? -2.177e+03 -1.895e+05? 1.855e+05 10368.220 0.9839??? traitappcareshort:age?????????????????? -7.331e-01 -3.681e+00? 2.267e+00 10202.025 0.6200??? traitappcarelong:age??????????????????? -1.433e+00 -4.507e+00? 1.571e+00? 8834.924 0.3546??? traitappcareshort:religionY???????????? -2.229e+00 -5.144e+00? 6.142e-01? 9157.812 0.1214??? traitappcarelong:religionY:sexorOT?????? 1.087e+02? 5.110e+00? 1.925e+02???? 1.404 <1e-04 ***??? 



   My first question is about the posterior mean. Could we somehow interpret it (with all the possible cautions and if you allow me) as kind of an effect size of each predictor? I mean, for example, the intercept for "appcareshort" (score from 1 to 5 given by participants in a survey to the attractiveness in a potential partner of appearance care for a short, casual relationship) is 3.242. So, is, for example, the effect of gender M on "appcareshort" more negative than the intercept? Or in other words, do male participants in the survey value care of appearance in potential partners significantly less than people of other gender?

   And my second question: as far as I can understand, the effective sample size is the number of iterations that MCMCglmm actually stores, and from which it "constructs" the posterior distribution. In this case, the total number of iterations was 100,000 and effective sample was always around 10,000 (which makes sense given that thin=10). My doubt is in that predictor with an effective sample size of 1.404. My experience tells me that when I plot the model for diagnostic purposes, that very predictor is going to show a clear lack of convergence. I would just like to ask whether I am right in what effective sample size means, what is the difference between the sample size (9700) and the effective sample size of the predictors, and how it's possible an effective sample size of 10,202 with 100,000 iterations and thin=10.

   Thank you very much in advance to everyone.

   Kind regards,
   Iker 
?? 

?? 


__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


	[[alternative HTML version deleted]]


From robgriffin247 at hotmail.com  Fri Nov 13 10:48:14 2015
From: robgriffin247 at hotmail.com (Robert Griffin)
Date: Fri, 13 Nov 2015 10:48:14 +0100
Subject: [R-sig-ME] Interaction variance from mcmcglmm
In-Reply-To: <op.x7jb65gra3mgvf@armadillo>
References: <CAMm5Haxd-eSELitCFQEunwYK1U-O_ZxXf0=A78Q5M-3KPamsEw@mail.gmail.com>
	<op.x7jb65gra3mgvf@armadillo>
Message-ID: <CAMm5HawYK+Lk_M6x2v2Y9ybynxxYYUrj6BnEObKp5oGaef79vA@mail.gmail.com>

Thanks Paul,

I have tried with the suggested expanded model, using simulated data where
I have added Y-source * Background interactions. See below. Is it correct
then to say that the variance estimate of "BG:Y.Source" is variance in
lifespan explained by the interaction between the genetic background
(autosomes and X source) and the source of the Y? Then the phenotypic
variance would be the sum of all components (2.910), and the interaction
BG*Y.Source would explain 100*(0.902/2.910) = 30.98% of the variance in
lifespan?

> colMeans(NestChain_Mod2$VCV)
           BG      Y.Source    Y.Source:Y   BG:Y.Source BG:Y.Source:Y
   Vial         units
 1.0029972054  0.4037536287  0.0008707007  0.9017016510  0.0002926541
 0.0013600115  0.5993455117


I also have a follow up on the nesting, I may need some explanation of the
syntax in the model you proposed (what are : and / doing?), but I read that
as having Y nested within Y.Source, which is then nested within the
background (BG). I understand that Y should be nested within Y.Source
(because each Y tested can only be from one source population), however,
given that all Y chromosomes are tested in all backgrounds (autosome and X
source), wouldn't it be inappropriate to nest within BG? i.e. Y's A1-A34
are all tested in CN, DH, and ZW, Y's B1-B34 are also all tested in CN, DH,
and ZW...

Thanks,
Rob

Here's the script I used:

############
prior3 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G3 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G4 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G5 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G6 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
R  = list(V = 1, nu=0.002))

# Y source * BG variance
dummy$Age2 = ifelse(dummy$Y.Source=="A"&dummy$BG=="CN", dummy$Age+15,
dummy$Age)
dummy$Age2 = ifelse(dummy$Y.Source=="B"&dummy$BG=="CN", abs(dummy$Age-15),
dummy$Age2)
dummy$Age2 = ifelse(dummy$Y.Source=="C"&dummy$BG=="DH", dummy$Age+15,
dummy$Age2)
dummy$Age2 = ifelse(dummy$Y.Source=="C"&dummy$BG=="ZW", abs(dummy$Age-15),
dummy$Age2)
dummy$Age2 = ifelse(dummy$Y.Source=="A"&dummy$BG=="DH", abs(dummy$Age-15),
dummy$Age2)
dummy$Age2 = ifelse(dummy$Y.Source=="B"&dummy$BG=="ZW", dummy$Age+15,
dummy$Age2)

boxplot(dummy$Age2 ~ dummy$Y.Source*dummy$BG)
dummy$Score2 = (dummy$Age2 - mean(dummy$Age2)) / sd(dummy$Age2)

# Chain
NestChain_Mod2 = MCMCglmm(Score2 ~1 + Block,
random = ~BG + Y.Source + Y.Source:Y + BG:Y.Source + BG:Y.Source:Y + Vial,
rcov = ~units,
nitt = 5000,
thin = 5,
burnin = 1000,
prior = prior3,
family = "gaussian",
start = list(QUASI = FALSE),
data = dummy)
file = paste(filepath, "NestChain_mod2.rda", sep = "")
save(NestChain_Mod2, file = file)

NestChain_mod2 = load(paste(filepath, "NestChain_mod2.rda", sep= ""))

# Variance components
colMeans(NestChain_Mod2$VCV)

colMeans(NestChain_Mod2$VCV)[1]/sum(colMeans(NestChain_Mod2$VCV))*100
colMeans(NestChain_Mod2$VCV)[2]/sum(colMeans(NestChain_Mod2$VCV))*100
colMeans(NestChain_Mod2$VCV)[3]/sum(colMeans(NestChain_Mod2$VCV))*100
colMeans(NestChain_Mod2$VCV)[4]/sum(colMeans(NestChain_Mod2$VCV))*100
colMeans(NestChain_Mod2$VCV)[5]/sum(colMeans(NestChain_Mod2$VCV))*100
colMeans(NestChain_Mod2$VCV)[6]/sum(colMeans(NestChain_Mod2$VCV))*100
colMeans(NestChain_Mod2$VCV)[7]/sum(colMeans(NestChain_Mod2$VCV))*100


---------------------------




---
Robert Griffin
PhD
griffinevo.wordpress.com

On Tue, Nov 3, 2015 at 6:29 PM, paul debes <paul.debes at utu.fi> wrote:

> Dear Rob,
>
> Unfortunately, I cannot help with the MCMCglmm prior specifications and
> hope someone else will do this, but maybe with the model.
>
> I think that fitting two separate models might lead to different results
> than one common model when you have a significant but ignored covariance
> between effects across populations when estimating only the within
> population variance.
>
> As the Y effects are nested within Y.Source effects (they are, right?),
> one initial full model to estimate within and across population variance,
> and including the interaction with the genetic background effects, could be:
>
> fixed = Score ~ 1 + Block,
> random = ~ BG + Y.Source/Y + BG:Y.Source/Y + Vial,
>
> expanded:
> random = ~ BG + Y.Source + Y.Source:Y + BG:Y.Source + BG:Y.Source:Y + Vial,
>
>
> Best,
> Paul
>
>
>
> On Tue, 03 Nov 2015 17:01:32 +0200, Robert Griffin <
> robgriffin247 at hotmail.com> wrote:
>
> Dear list members,
>>
>> I recently published work using mcmcglmm to test for Y linked genetic
>> variance, finding variance within a population. This data was collected by
>> measuring phenotypic data from randomly sampled Y chromosomes from within
>> a
>> population, tested in a single genetic background, using lifespan as the
>> response, and Y chromosome as a random effect.
>>
>> I have been trying to think of how I would improve such a study and
>> concluded that a more complete study would be done using
>> - Y chromosomes from multiple source populations (to test for among
>> population variance)
>> - multiple genetic backgrounds (to distinguish between [direct] genetic
>> effects, and epistatic effects)...
>>
>> This got me thinking about the analysis of such data. I would need to
>> estimate how much of the Y-linked variance within and among populations is
>> genetic and epistatic. This has lead me to two main questions where I
>> could
>> use some guidance:
>>
>> 1) can mcmcglmm be used to estimate the interaction (epistatic) variance?
>> - I think the answer is yes but I have as yet been unable to find clear
>> advice on this, how can I add interaction variance term in to mcmcglmm?
>> - I can add the variance explained by the genetic background by adding
>> this
>> as a random effect too, but (how) can I find the interaction between two
>> random explanatory variables?
>>
>> 2) could I do it all from a single model or would I need multiple models?
>> - If I built a model where the trait (Lifespan) is the response variable,
>> with random effects of Y chromosome, Y chromosome source population,
>> genetic background, and the interactions between Y/Y-source and genetic
>> background, would I be able to get estimates of the direct genetic and
>> epistatic variances within and among the source populations?
>> - I could build two models, one with Y chromosome and genetic background
>> as
>> random effects (including the interaction), and the other with
>> Y-chromosome
>> source population and genetic background as random effects (including the
>> interaction). These two models would separately estimate the within and
>> among population variances. I think this would be the correct approach.
>> However, I'm unconvinced that the latter would give the desired division
>> in
>> to direct and epistatic Y-linked variation.
>>
>> Thanks,
>> Rob
>>
>> *Please kindly note*, advice on prior specification when estimating
>>
>> interaction effects would be also very highly appreciated, remembering
>> that
>> the variance components are likely very small. I have included a
>> demonstration script which makes some dummy data, and shows some of the
>> proposed models. The script includes a filepath which you can edit if you
>> wish to save and load chains, and switches at line 56 to turn the chains
>> on/off when running scripts.
>>
>> ##############
>> ## R SCRIPT ##
>> ##############
>>
>> # Y-background interaction dummy data
>> rm(list=ls())
>> library("lme4")
>> library("MCMCglmm")
>> set.seed(24)
>>
>> # Set filepath (CUSTOMISE THIS IF YOU WISH TO BE ABLE TO SAVE AND LOAD
>> CHAINS)
>> filepath = paste0("C:\\Users\\Rob\\Notes\\Y_epistasis\\")
>>
>> #### Description of dummy data ####
>> # 20 Y chromosomes randomly sampled from 3 populations (A1:A20, B1:B20,
>> C1:C20, n = 60)
>> # Test in genetic backgrounds (BG) from three populations (Canton [CN],
>> Zimbabwe [ZW], and Dahomey [DH])
>> # Measure a trait (Lifepsan) in 90 individuals per combination of Y & BG
>> # Measured across three replicate blocks (BL1, BL2, BL3), with two vials
>> each per block
>>
>> n1 = 20 # Number of Y's sampled per source population
>> n2 = 30 # Number of measurements per block/line
>> n3 = 3  # Number of blocks (BL1, BL2, BL3)
>> n4 = 3 # Number of genetic backgrounds (CN, ZW, DH)
>> n5 = 3  # Number of Y source populations (A, B, C)
>> n6 = 2  # Number of vials per block/Y/BG
>>
>> # Construction of data
>> dummy = data.frame(
>> as.factor(rep(c(paste0("A",1:n1), paste0("B",1:n1), paste0("C",1:n1)),
>> each
>> = n2*n3, times = n4)),
>> as.factor(rep(c("A","B","C"), each = n1*n2*n3, times = n5)),
>> as.factor(rep(c("CN","ZW","DH"), each = n1*n2*n3*n4, times = 1)),
>> as.factor(rep(c("BL1","BL2","BL3"), each = n2)),
>> as.factor(rep(c("A","B"), each = n2 / n6)),
>> as.numeric(abs(round(rnorm(n1*n2*n3*n4*n5, 50, 15),0)))
>> )
>> colnames(dummy) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age")
>> dummy$Vial = paste(dummy$Y, dummy$Y.Source, dummy$BG, dummy$Block,
>> dummy$Vial, sep = "_")
>> head(dummy)
>>
>> # Mean zero unit variance for Age (response variable)
>> dummy$Score = (dummy$Age - mean(dummy$Age)) / sd(dummy$Age)
>>
>> # Subset DFs (Only one source population and one genetic background, as in
>> previous JEB paper)
>> dummy_A = data.frame(split(dummy , f = dummy$Y.Source)[1])
>> dummy_A_CN = data.frame(split(dummy_A , f = dummy_A$A.BG)[1])
>> colnames(dummy_A) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age",
>> "Score")
>> colnames(dummy_A_CN) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age",
>> "Score")
>>
>> # MCMC Priors
>> prior1 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
>> G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
>> R  = list(V = 1, nu=0.002))
>>
>> prior2 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
>> G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
>> G3 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
>> R  = list(V = 1, nu=0.002))
>>
>> # MCMC Switches
>> testing = "y"
>> runChain_A_CN1 = "y"
>> runChain_A1 = "y"
>> runChain_1 = "y"
>>
>> # MCMC Details
>> if(testing == "y"){
>> nitt = 10000
>> burn = 1000
>> thin = 10
>> }else{
>> nitt = 100000
>> burn = 10000
>> thin = 100
>> }
>>
>> # MCMC Chain (as in JEB Paper: One Y source population, One genetic
>> background)
>> # Within-population Y-linked variation
>> if(runChain_A_CN1=="y"){
>> Chain_A_CN1 = MCMCglmm(Score ~1 + Block,
>> random = ~Y + Vial,
>> rcov = ~units,
>> nitt = nitt,
>> thin = thin,
>> burnin = burn,
>> prior = prior1,
>> family = "gaussian",
>> start = list(QUASI = FALSE),
>> data = dummy_A_CN)
>> file = paste(filepath, "Chain_A_CN1.rda", sep = "")
>> save(Chain_A_CN1, file = file)
>> }else{}
>>
>> ##############################
>> #### Proposed MCMC Chains ####
>> ##############################
>>
>> # Within-population Y-linked variation split in to direct and epistatic
>> if(runChain_A1=="y"){
>> Chain_A1 = MCMCglmm(Score ~1 + Block,
>> random = ~Y + BG + Vial,
>> rcov = ~units,
>> nitt = nitt,
>> thin = thin,
>> burnin = burn,
>> prior = prior2,
>> family = "gaussian",
>> start = list(QUASI = FALSE),
>> data = dummy_A)
>> file = paste(filepath, "Chain_A1.rda", sep = "")
>> save(Chain_A1, file = file)
>> }else{}
>>
>> # Among-population Y-linked variation split in to direct and epistatic
>> if(runChain_1=="y"){
>> Chain_1 = MCMCglmm(Score ~1 + Block,
>> random = ~Y.Source + BG + Vial,
>> rcov = ~units,
>> nitt = nitt,
>> thin = thin,
>> burnin = burn,
>> prior = prior2,
>> family = "gaussian",
>> start = list(QUASI = FALSE),
>> data = dummy)
>> file = paste(filepath, "Chain_1.rda", sep = "")
>> save(Chain_1, file = file)
>> }else{}
>>
>> Chain.A_CN1 = load(paste(filepath, "Chain_A_CN1.rda", sep= ""))
>> Chain.A1 = load(paste(filepath, "Chain_A1.rda", sep= ""))
>> Chain.1 = load(paste(filepath, "Chain_1.rda", sep= ""))
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Paul Debes
> DFG Research Fellow
> University of Turku
> Department of Biology
> It?inen Pitk?katu 4
> 20520 Turku
> Finland
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Fri Nov 13 14:14:17 2015
From: paul.debes at utu.fi (paul debes)
Date: Fri, 13 Nov 2015 15:14:17 +0200
Subject: [R-sig-ME] Interaction variance from mcmcglmm
In-Reply-To: <CAMm5HawYK+Lk_M6x2v2Y9ybynxxYYUrj6BnEObKp5oGaef79vA@mail.gmail.com>
References: <CAMm5Haxd-eSELitCFQEunwYK1U-O_ZxXf0=A78Q5M-3KPamsEw@mail.gmail.com>
	<op.x7jb65gra3mgvf@armadillo>
	<CAMm5HawYK+Lk_M6x2v2Y9ybynxxYYUrj6BnEObKp5oGaef79vA@mail.gmail.com>
Message-ID: <op.x71i13d4a3mgvf@armadillo>

Hi Rob,

I'm not entirely certain about the biological interpretation (I don't work  
at the level of the chromosomes) but your interpretation appears right to  
me, although variance estimates are very unreliable given that some are  
based on only three levels (Y.source and BG).

In the case you have considered using many more levels than three for the  
BG factor in your actual experiment, you could also employ a more detailed  
covariance structure and test for differences in BG variance among  
Y.source levels and for different correlations between BG effects among  
Y.source pairs.
For a genetic model it can make sense to test for the first when  
demographic events within populations have been different (e.g., different  
population sizes / past events leading to different genetic diversities),  
and to test for the second when the genetic differentiation differs  
between population pairs (e.g., differences in shared ancestry /  
migration). Of course, both processes relate to each other and population  
size differences can also drive differentiation, etc. I think the present  
model assumes that the first and second are equal from a genetic  
perspective, but it is the easiest model to obtain the BG variance  
estimates within and among Y.source. I'm not sure, though, if a more  
complicated model fits with the interaction question you asked.  
Practically, you could simulate the BG effects for the Y.source levels  
drawn from a multivariate normal distribution.
You could then consider (there are several options here, this is one):

random = ~ Y.Source:Y + BG:us(Y.Source) + BG:Y.Source:Y + Vial

As for the other question:
'a/b' is short for 'a + a:b',
'a:b' does not include 'a' effects, in contrast to 'a/b',
and none of them does include b effects (b is nested).

In your case writing 'Y.source/Y' or 'Y.source + Y.source:Y' is even the  
same as 'Y.source + Y' because each Y does only occur in one level of  
Y.source (nesting by design). Writing 'Y.source + Y.source:Y' (or short:  
'Y.source/Y') makes it just visually clearer that 'Y' is within 'Y.source'  
but how you write it should not affect the model estimates (maybe in some  
programmes?). Because 'Y.source/Y' is like writing 'Y' this should solve  
the remaining question about the nesting of 'Y' within 'BG:Y.source' too.  
This means 'BG:Y.source:Y' is in your case the same as 'BG:Y'. Try it out,  
should give the same result.
Sorry if that confused you.

Hope this helps,
Paul

On Fri, 13 Nov 2015 11:48:14 +0200, Robert Griffin  
<robgriffin247 at hotmail.com> wrote:

> Thanks Paul,
>
> I have tried with the suggested expanded model, using simulated data  
> where
> I have added Y-source * Background interactions. See below. Is it correct
> then to say that the variance estimate of "BG:Y.Source" is variance in
> lifespan explained by the interaction between the genetic background
> (autosomes and X source) and the source of the Y? Then the phenotypic
> variance would be the sum of all components (2.910), and the interaction
> BG*Y.Source would explain 100*(0.902/2.910) = 30.98% of the variance in
> lifespan?
>
>> colMeans(NestChain_Mod2$VCV)
>            BG      Y.Source    Y.Source:Y   BG:Y.Source BG:Y.Source:Y
>    Vial         units
>  1.0029972054  0.4037536287  0.0008707007  0.9017016510  0.0002926541
>  0.0013600115  0.5993455117
>
>
> I also have a follow up on the nesting, I may need some explanation of  
> the
> syntax in the model you proposed (what are : and / doing?), but I read  
> that
> as having Y nested within Y.Source, which is then nested within the
> background (BG). I understand that Y should be nested within Y.Source
> (because each Y tested can only be from one source population), however,
> given that all Y chromosomes are tested in all backgrounds (autosome and  
> X
> source), wouldn't it be inappropriate to nest within BG? i.e. Y's A1-A34
> are all tested in CN, DH, and ZW, Y's B1-B34 are also all tested in CN,  
> DH,
> and ZW...
>
> Thanks,
> Rob
>
> Here's the script I used:
>
> ############
> prior3 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
> G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
> G3 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
> G4 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
> G5 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
> G6 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
> R  = list(V = 1, nu=0.002))
>
> # Y source * BG variance
> dummy$Age2 = ifelse(dummy$Y.Source=="A"&dummy$BG=="CN", dummy$Age+15,
> dummy$Age)
> dummy$Age2 = ifelse(dummy$Y.Source=="B"&dummy$BG=="CN",  
> abs(dummy$Age-15),
> dummy$Age2)
> dummy$Age2 = ifelse(dummy$Y.Source=="C"&dummy$BG=="DH", dummy$Age+15,
> dummy$Age2)
> dummy$Age2 = ifelse(dummy$Y.Source=="C"&dummy$BG=="ZW",  
> abs(dummy$Age-15),
> dummy$Age2)
> dummy$Age2 = ifelse(dummy$Y.Source=="A"&dummy$BG=="DH",  
> abs(dummy$Age-15),
> dummy$Age2)
> dummy$Age2 = ifelse(dummy$Y.Source=="B"&dummy$BG=="ZW", dummy$Age+15,
> dummy$Age2)
>
> boxplot(dummy$Age2 ~ dummy$Y.Source*dummy$BG)
> dummy$Score2 = (dummy$Age2 - mean(dummy$Age2)) / sd(dummy$Age2)
>
> # Chain
> NestChain_Mod2 = MCMCglmm(Score2 ~1 + Block,
> random = ~BG + Y.Source + Y.Source:Y + BG:Y.Source + BG:Y.Source:Y +  
> Vial,
> rcov = ~units,
> nitt = 5000,
> thin = 5,
> burnin = 1000,
> prior = prior3,
> family = "gaussian",
> start = list(QUASI = FALSE),
> data = dummy)
> file = paste(filepath, "NestChain_mod2.rda", sep = "")
> save(NestChain_Mod2, file = file)
>
> NestChain_mod2 = load(paste(filepath, "NestChain_mod2.rda", sep= ""))
>
> # Variance components
> colMeans(NestChain_Mod2$VCV)
>
> colMeans(NestChain_Mod2$VCV)[1]/sum(colMeans(NestChain_Mod2$VCV))*100
> colMeans(NestChain_Mod2$VCV)[2]/sum(colMeans(NestChain_Mod2$VCV))*100
> colMeans(NestChain_Mod2$VCV)[3]/sum(colMeans(NestChain_Mod2$VCV))*100
> colMeans(NestChain_Mod2$VCV)[4]/sum(colMeans(NestChain_Mod2$VCV))*100
> colMeans(NestChain_Mod2$VCV)[5]/sum(colMeans(NestChain_Mod2$VCV))*100
> colMeans(NestChain_Mod2$VCV)[6]/sum(colMeans(NestChain_Mod2$VCV))*100
> colMeans(NestChain_Mod2$VCV)[7]/sum(colMeans(NestChain_Mod2$VCV))*100
>
>
> ---------------------------
>
>
>
>
> ---
> Robert Griffin
> PhD
> griffinevo.wordpress.com
>
> On Tue, Nov 3, 2015 at 6:29 PM, paul debes <paul.debes at utu.fi> wrote:
>
>> Dear Rob,
>>
>> Unfortunately, I cannot help with the MCMCglmm prior specifications and
>> hope someone else will do this, but maybe with the model.
>>
>> I think that fitting two separate models might lead to different results
>> than one common model when you have a significant but ignored covariance
>> between effects across populations when estimating only the within
>> population variance.
>>
>> As the Y effects are nested within Y.Source effects (they are, right?),
>> one initial full model to estimate within and across population  
>> variance,
>> and including the interaction with the genetic background effects,  
>> could be:
>>
>> fixed = Score ~ 1 + Block,
>> random = ~ BG + Y.Source/Y + BG:Y.Source/Y + Vial,
>>
>> expanded:
>> random = ~ BG + Y.Source + Y.Source:Y + BG:Y.Source + BG:Y.Source:Y +  
>> Vial,
>>
>>
>> Best,
>> Paul
>>
>>
>>
>> On Tue, 03 Nov 2015 17:01:32 +0200, Robert Griffin <
>> robgriffin247 at hotmail.com> wrote:
>>
>> Dear list members,
>>>
>>> I recently published work using mcmcglmm to test for Y linked genetic
>>> variance, finding variance within a population. This data was  
>>> collected by
>>> measuring phenotypic data from randomly sampled Y chromosomes from  
>>> within
>>> a
>>> population, tested in a single genetic background, using lifespan as  
>>> the
>>> response, and Y chromosome as a random effect.
>>>
>>> I have been trying to think of how I would improve such a study and
>>> concluded that a more complete study would be done using
>>> - Y chromosomes from multiple source populations (to test for among
>>> population variance)
>>> - multiple genetic backgrounds (to distinguish between [direct] genetic
>>> effects, and epistatic effects)...
>>>
>>> This got me thinking about the analysis of such data. I would need to
>>> estimate how much of the Y-linked variance within and among  
>>> populations is
>>> genetic and epistatic. This has lead me to two main questions where I
>>> could
>>> use some guidance:
>>>
>>> 1) can mcmcglmm be used to estimate the interaction (epistatic)  
>>> variance?
>>> - I think the answer is yes but I have as yet been unable to find clear
>>> advice on this, how can I add interaction variance term in to mcmcglmm?
>>> - I can add the variance explained by the genetic background by adding
>>> this
>>> as a random effect too, but (how) can I find the interaction between  
>>> two
>>> random explanatory variables?
>>>
>>> 2) could I do it all from a single model or would I need multiple  
>>> models?
>>> - If I built a model where the trait (Lifespan) is the response  
>>> variable,
>>> with random effects of Y chromosome, Y chromosome source population,
>>> genetic background, and the interactions between Y/Y-source and genetic
>>> background, would I be able to get estimates of the direct genetic and
>>> epistatic variances within and among the source populations?
>>> - I could build two models, one with Y chromosome and genetic  
>>> background
>>> as
>>> random effects (including the interaction), and the other with
>>> Y-chromosome
>>> source population and genetic background as random effects (including  
>>> the
>>> interaction). These two models would separately estimate the within and
>>> among population variances. I think this would be the correct approach.
>>> However, I'm unconvinced that the latter would give the desired  
>>> division
>>> in
>>> to direct and epistatic Y-linked variation.
>>>
>>> Thanks,
>>> Rob
>>>
>>> *Please kindly note*, advice on prior specification when estimating
>>>
>>> interaction effects would be also very highly appreciated, remembering
>>> that
>>> the variance components are likely very small. I have included a
>>> demonstration script which makes some dummy data, and shows some of the
>>> proposed models. The script includes a filepath which you can edit if  
>>> you
>>> wish to save and load chains, and switches at line 56 to turn the  
>>> chains
>>> on/off when running scripts.
>>>
>>> ##############
>>> ## R SCRIPT ##
>>> ##############
>>>
>>> # Y-background interaction dummy data
>>> rm(list=ls())
>>> library("lme4")
>>> library("MCMCglmm")
>>> set.seed(24)
>>>
>>> # Set filepath (CUSTOMISE THIS IF YOU WISH TO BE ABLE TO SAVE AND LOAD
>>> CHAINS)
>>> filepath = paste0("C:\\Users\\Rob\\Notes\\Y_epistasis\\")
>>>
>>> #### Description of dummy data ####
>>> # 20 Y chromosomes randomly sampled from 3 populations (A1:A20, B1:B20,
>>> C1:C20, n = 60)
>>> # Test in genetic backgrounds (BG) from three populations (Canton [CN],
>>> Zimbabwe [ZW], and Dahomey [DH])
>>> # Measure a trait (Lifepsan) in 90 individuals per combination of Y &  
>>> BG
>>> # Measured across three replicate blocks (BL1, BL2, BL3), with two  
>>> vials
>>> each per block
>>>
>>> n1 = 20 # Number of Y's sampled per source population
>>> n2 = 30 # Number of measurements per block/line
>>> n3 = 3  # Number of blocks (BL1, BL2, BL3)
>>> n4 = 3 # Number of genetic backgrounds (CN, ZW, DH)
>>> n5 = 3  # Number of Y source populations (A, B, C)
>>> n6 = 2  # Number of vials per block/Y/BG
>>>
>>> # Construction of data
>>> dummy = data.frame(
>>> as.factor(rep(c(paste0("A",1:n1), paste0("B",1:n1), paste0("C",1:n1)),
>>> each
>>> = n2*n3, times = n4)),
>>> as.factor(rep(c("A","B","C"), each = n1*n2*n3, times = n5)),
>>> as.factor(rep(c("CN","ZW","DH"), each = n1*n2*n3*n4, times = 1)),
>>> as.factor(rep(c("BL1","BL2","BL3"), each = n2)),
>>> as.factor(rep(c("A","B"), each = n2 / n6)),
>>> as.numeric(abs(round(rnorm(n1*n2*n3*n4*n5, 50, 15),0)))
>>> )
>>> colnames(dummy) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age")
>>> dummy$Vial = paste(dummy$Y, dummy$Y.Source, dummy$BG, dummy$Block,
>>> dummy$Vial, sep = "_")
>>> head(dummy)
>>>
>>> # Mean zero unit variance for Age (response variable)
>>> dummy$Score = (dummy$Age - mean(dummy$Age)) / sd(dummy$Age)
>>>
>>> # Subset DFs (Only one source population and one genetic background,  
>>> as in
>>> previous JEB paper)
>>> dummy_A = data.frame(split(dummy , f = dummy$Y.Source)[1])
>>> dummy_A_CN = data.frame(split(dummy_A , f = dummy_A$A.BG)[1])
>>> colnames(dummy_A) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age",
>>> "Score")
>>> colnames(dummy_A_CN) = c("Y", "Y.Source", "BG", "Block", "Vial", "Age",
>>> "Score")
>>>
>>> # MCMC Priors
>>> prior1 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0,  
>>> alpha.V=1000),
>>> G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
>>> R  = list(V = 1, nu=0.002))
>>>
>>> prior2 = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0,  
>>> alpha.V=1000),
>>> G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
>>> G3 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
>>> R  = list(V = 1, nu=0.002))
>>>
>>> # MCMC Switches
>>> testing = "y"
>>> runChain_A_CN1 = "y"
>>> runChain_A1 = "y"
>>> runChain_1 = "y"
>>>
>>> # MCMC Details
>>> if(testing == "y"){
>>> nitt = 10000
>>> burn = 1000
>>> thin = 10
>>> }else{
>>> nitt = 100000
>>> burn = 10000
>>> thin = 100
>>> }
>>>
>>> # MCMC Chain (as in JEB Paper: One Y source population, One genetic
>>> background)
>>> # Within-population Y-linked variation
>>> if(runChain_A_CN1=="y"){
>>> Chain_A_CN1 = MCMCglmm(Score ~1 + Block,
>>> random = ~Y + Vial,
>>> rcov = ~units,
>>> nitt = nitt,
>>> thin = thin,
>>> burnin = burn,
>>> prior = prior1,
>>> family = "gaussian",
>>> start = list(QUASI = FALSE),
>>> data = dummy_A_CN)
>>> file = paste(filepath, "Chain_A_CN1.rda", sep = "")
>>> save(Chain_A_CN1, file = file)
>>> }else{}
>>>
>>> ##############################
>>> #### Proposed MCMC Chains ####
>>> ##############################
>>>
>>> # Within-population Y-linked variation split in to direct and epistatic
>>> if(runChain_A1=="y"){
>>> Chain_A1 = MCMCglmm(Score ~1 + Block,
>>> random = ~Y + BG + Vial,
>>> rcov = ~units,
>>> nitt = nitt,
>>> thin = thin,
>>> burnin = burn,
>>> prior = prior2,
>>> family = "gaussian",
>>> start = list(QUASI = FALSE),
>>> data = dummy_A)
>>> file = paste(filepath, "Chain_A1.rda", sep = "")
>>> save(Chain_A1, file = file)
>>> }else{}
>>>
>>> # Among-population Y-linked variation split in to direct and epistatic
>>> if(runChain_1=="y"){
>>> Chain_1 = MCMCglmm(Score ~1 + Block,
>>> random = ~Y.Source + BG + Vial,
>>> rcov = ~units,
>>> nitt = nitt,
>>> thin = thin,
>>> burnin = burn,
>>> prior = prior2,
>>> family = "gaussian",
>>> start = list(QUASI = FALSE),
>>> data = dummy)
>>> file = paste(filepath, "Chain_1.rda", sep = "")
>>> save(Chain_1, file = file)
>>> }else{}
>>>
>>> Chain.A_CN1 = load(paste(filepath, "Chain_A_CN1.rda", sep= ""))
>>> Chain.A1 = load(paste(filepath, "Chain_A1.rda", sep= ""))
>>> Chain.1 = load(paste(filepath, "Chain_1.rda", sep= ""))
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Paul Debes
>> DFG Research Fellow
>> University of Turku
>> Department of Biology
>> It?inen Pitk?katu 4
>> 20520 Turku
>> Finland
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>


-- 
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland


From emmanuel.curis at parisdescartes.fr  Fri Nov 13 14:41:50 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Fri, 13 Nov 2015 14:41:50 +0100
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
Message-ID: <20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>

Dear Thierry,

Thanks for the hint. 

Just for curiosity, is there any case in which survival analysis will
be equivalent to the Markov model or the GLM(M) model? I remember having
read somewhere that there are links  between survival analysis and
logistic regression, but can't remember exactly which link for the
moment...

Best regards,

On Thu, Nov 12, 2015 at 09:59:18PM +0100, Thierry Onkelinx wrote:
? Dear Emmanuel,
? 
? Maybe a survival analysis is more appropriate for that kind of data.
? 
? Best regards,
? 
? ir. Thierry Onkelinx
? Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
? Forest
? team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
? Kliniekstraat 25
? 1070 Anderlecht
? Belgium
? 
? To call in the statistician after the experiment is done may be no more
? than asking him to perform a post-mortem examination: he may be able to say
? what the experiment died of. ~ Sir Ronald Aylmer Fisher
? The plural of anecdote is not data. ~ Roger Brinner
? The combination of some data and an aching desire for an answer does not
? ensure that a reasonable answer can be extracted from a given body of data.
? ~ John Tukey
? 
? 2015-11-12 18:12 GMT+01:00 Emmanuel Curis <emmanuel.curis at parisdescartes.fr>
? :
? 
? > Dear all,
? >
? > With a colleague, we are discussing about the appropriateness of a
? > random effects mixed effects generalized linear model (more
? > specifically, logistic regression) in a given experimental situation,
? > and wonder about it's correct interpretation.
? >
? > Short version: is it correct to interpret random effects glm, with a
? > single random effect, as hierarchical models as random effects linear
? > models ?
? >
? > Detailed version: our data consist of daily status of a set of
? > patients, the status beeing ? Infected ? or ? Not infected ?, during a
? > variable period of time. The aim is to see what changes the infection
? > probability.
? >
? > A proposed approach was to use a random effect logistic regression to
? > evaluate this probability, with patient as a random effect.
? >
? > However, we have one concern with that approach: interpretating it in
? > a hierarchical model idea, it seems that for a given patient, the
? > model should be a binomial one, in other words that the set of
? > Bernoulli variables observed each day for a given patient should be
? > independent, identically distributed. But this is obviously not the
? > case here: the variable is 0 until infection occurs (if it occurs),
? > and 1 after.  Consequently, we fear that the probability estimated in
? > the glmm will have no real meaningful interpretation.
? >
? > Are we right with this hierarchical interpretation of the GLMM
? > (logistic) model, or is this fear not justified, and the
? > interpretation of the GLMM more complex, but would lead to correct and
? > interpretable estimations of infection probability?
? >
? > As an alternative approach, we thought about a two-states Markov
? > chain, and working on transition probabilities from the ? non-infected ?
? > to the ? infected ? state. It seems to model what happens more
? > closely.  Is there any link between such a model and the logistic GLMM
? > described above, or another kind of GLMM model?
? >
? > And, semantic question, is such a model also in the scope of ? random
? > effects ? model and could be discussed here, in case help is needed, or
? > is it out of the scope of this list?
? >
? > Thanks in advance for your opinions,
? > Best regards,
? >
? > --
? >                                 Emmanuel CURIS
? >                                 emmanuel.curis at parisdescartes.fr
? >
? > Page WWW: http://emmanuel.curis.online.fr/index.html
? >
? > _______________________________________________
? > R-sig-mixed-models at r-project.org mailing list
? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From thierry.onkelinx at inbo.be  Fri Nov 13 14:46:57 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 13 Nov 2015 14:46:57 +0100
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
	<20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>
Message-ID: <CAJuCY5yfe8L5foODnHNz4v9cdBZ23XJcLESwt7fQ6D9jZ7xFUA@mail.gmail.com>

Dear Emmanuel,

Survival analysis is outside my expertise. I can't help you further on the
topic.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-13 14:41 GMT+01:00 Emmanuel Curis <emmanuel.curis at parisdescartes.fr>
:

> Dear Thierry,
>
> Thanks for the hint.
>
> Just for curiosity, is there any case in which survival analysis will
> be equivalent to the Markov model or the GLM(M) model? I remember having
> read somewhere that there are links  between survival analysis and
> logistic regression, but can't remember exactly which link for the
> moment...
>
> Best regards,
>
> On Thu, Nov 12, 2015 at 09:59:18PM +0100, Thierry Onkelinx wrote:
> ? Dear Emmanuel,
> ?
> ? Maybe a survival analysis is more appropriate for that kind of data.
> ?
> ? Best regards,
> ?
> ? ir. Thierry Onkelinx
> ? Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> ? Forest
> ? team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> ? Kliniekstraat 25
> ? 1070 Anderlecht
> ? Belgium
> ?
> ? To call in the statistician after the experiment is done may be no more
> ? than asking him to perform a post-mortem examination: he may be able to
> say
> ? what the experiment died of. ~ Sir Ronald Aylmer Fisher
> ? The plural of anecdote is not data. ~ Roger Brinner
> ? The combination of some data and an aching desire for an answer does not
> ? ensure that a reasonable answer can be extracted from a given body of
> data.
> ? ~ John Tukey
> ?
> ? 2015-11-12 18:12 GMT+01:00 Emmanuel Curis <
> emmanuel.curis at parisdescartes.fr>
> ? :
> ?
> ? > Dear all,
> ? >
> ? > With a colleague, we are discussing about the appropriateness of a
> ? > random effects mixed effects generalized linear model (more
> ? > specifically, logistic regression) in a given experimental situation,
> ? > and wonder about it's correct interpretation.
> ? >
> ? > Short version: is it correct to interpret random effects glm, with a
> ? > single random effect, as hierarchical models as random effects linear
> ? > models ?
> ? >
> ? > Detailed version: our data consist of daily status of a set of
> ? > patients, the status beeing ? Infected ? or ? Not infected ?, during a
> ? > variable period of time. The aim is to see what changes the infection
> ? > probability.
> ? >
> ? > A proposed approach was to use a random effect logistic regression to
> ? > evaluate this probability, with patient as a random effect.
> ? >
> ? > However, we have one concern with that approach: interpretating it in
> ? > a hierarchical model idea, it seems that for a given patient, the
> ? > model should be a binomial one, in other words that the set of
> ? > Bernoulli variables observed each day for a given patient should be
> ? > independent, identically distributed. But this is obviously not the
> ? > case here: the variable is 0 until infection occurs (if it occurs),
> ? > and 1 after.  Consequently, we fear that the probability estimated in
> ? > the glmm will have no real meaningful interpretation.
> ? >
> ? > Are we right with this hierarchical interpretation of the GLMM
> ? > (logistic) model, or is this fear not justified, and the
> ? > interpretation of the GLMM more complex, but would lead to correct and
> ? > interpretable estimations of infection probability?
> ? >
> ? > As an alternative approach, we thought about a two-states Markov
> ? > chain, and working on transition probabilities from the ? non-infected
> ?
> ? > to the ? infected ? state. It seems to model what happens more
> ? > closely.  Is there any link between such a model and the logistic GLMM
> ? > described above, or another kind of GLMM model?
> ? >
> ? > And, semantic question, is such a model also in the scope of ? random
> ? > effects ? model and could be discussed here, in case help is needed, or
> ? > is it out of the scope of this list?
> ? >
> ? > Thanks in advance for your opinions,
> ? > Best regards,
> ? >
> ? > --
> ? >                                 Emmanuel CURIS
> ? >                                 emmanuel.curis at parisdescartes.fr
> ? >
> ? > Page WWW: http://emmanuel.curis.online.fr/index.html
> ? >
> ? > _______________________________________________
> ? > R-sig-mixed-models at r-project.org mailing list
> ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? >
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Nov 13 16:59:29 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Nov 2015 10:59:29 -0500
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
	<20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>
Message-ID: <564608E1.4070304@gmail.com>

  If you model the time until infection for each individual as
Gamma-distributed, that will be more or less equivalent to a Gamma
(parametric) survival model, with the big caveat that the GLMM framework
is not good at handling censored data in general.

  I believe there is also a connection between discrete-time Cox
proportional hazards models and binomial GLMMs with a complementary
log-log link and fixed effect of time period ...

  Ben Bolker

On 15-11-13 08:41 AM, Emmanuel Curis wrote:
> Dear Thierry,
> 
> Thanks for the hint. 
> 
> Just for curiosity, is there any case in which survival analysis will
> be equivalent to the Markov model or the GLM(M) model? I remember having
> read somewhere that there are links  between survival analysis and
> logistic regression, but can't remember exactly which link for the
> moment...
> 
> Best regards,
> 
> On Thu, Nov 12, 2015 at 09:59:18PM +0100, Thierry Onkelinx wrote:
> ? Dear Emmanuel,
> ? 
> ? Maybe a survival analysis is more appropriate for that kind of data.
> ? 
> ? Best regards,
> ? 
> ? ir. Thierry Onkelinx
> ? Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> ? Forest
> ? team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> ? Kliniekstraat 25
> ? 1070 Anderlecht
> ? Belgium
> ? 
> ? To call in the statistician after the experiment is done may be no more
> ? than asking him to perform a post-mortem examination: he may be able to say
> ? what the experiment died of. ~ Sir Ronald Aylmer Fisher
> ? The plural of anecdote is not data. ~ Roger Brinner
> ? The combination of some data and an aching desire for an answer does not
> ? ensure that a reasonable answer can be extracted from a given body of data.
> ? ~ John Tukey
> ? 
> ? 2015-11-12 18:12 GMT+01:00 Emmanuel Curis <emmanuel.curis at parisdescartes.fr>
> ? :
> ? 
> ? > Dear all,
> ? >
> ? > With a colleague, we are discussing about the appropriateness of a
> ? > random effects mixed effects generalized linear model (more
> ? > specifically, logistic regression) in a given experimental situation,
> ? > and wonder about it's correct interpretation.
> ? >
> ? > Short version: is it correct to interpret random effects glm, with a
> ? > single random effect, as hierarchical models as random effects linear
> ? > models ?
> ? >
> ? > Detailed version: our data consist of daily status of a set of
> ? > patients, the status beeing ? Infected ? or ? Not infected ?, during a
> ? > variable period of time. The aim is to see what changes the infection
> ? > probability.
> ? >
> ? > A proposed approach was to use a random effect logistic regression to
> ? > evaluate this probability, with patient as a random effect.
> ? >
> ? > However, we have one concern with that approach: interpretating it in
> ? > a hierarchical model idea, it seems that for a given patient, the
> ? > model should be a binomial one, in other words that the set of
> ? > Bernoulli variables observed each day for a given patient should be
> ? > independent, identically distributed. But this is obviously not the
> ? > case here: the variable is 0 until infection occurs (if it occurs),
> ? > and 1 after.  Consequently, we fear that the probability estimated in
> ? > the glmm will have no real meaningful interpretation.
> ? >
> ? > Are we right with this hierarchical interpretation of the GLMM
> ? > (logistic) model, or is this fear not justified, and the
> ? > interpretation of the GLMM more complex, but would lead to correct and
> ? > interpretable estimations of infection probability?
> ? >
> ? > As an alternative approach, we thought about a two-states Markov
> ? > chain, and working on transition probabilities from the ? non-infected ?
> ? > to the ? infected ? state. It seems to model what happens more
> ? > closely.  Is there any link between such a model and the logistic GLMM
> ? > described above, or another kind of GLMM model?
> ? >
> ? > And, semantic question, is such a model also in the scope of ? random
> ? > effects ? model and could be discussed here, in case help is needed, or
> ? > is it out of the scope of this list?
> ? >
> ? > Thanks in advance for your opinions,
> ? > Best regards,
> ? >
> ? > --
> ? >                                 Emmanuel CURIS
> ? >                                 emmanuel.curis at parisdescartes.fr
> ? >
> ? > Page WWW: http://emmanuel.curis.online.fr/index.html
> ? >
> ? > _______________________________________________
> ? > R-sig-mixed-models at r-project.org mailing list
> ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? >
>


From emmanuel.curis at parisdescartes.fr  Fri Nov 13 17:32:56 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Fri, 13 Nov 2015 17:32:56 +0100
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <564608E1.4070304@gmail.com>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
	<20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>
	<564608E1.4070304@gmail.com>
Message-ID: <20151113163255.GB10987@info124.pharmacie.univ-paris5.fr>

Thanks for these answers.

After thinking a little bit, I still have a concern with the survival
approach.  What is in interest in the data is not really the time
before patients are infected (at least, as far as I understood the
practicionners problem), but the proportion of patients that are
infected at a given moment (and, at the end, does this proportion
change with some covariates, including period in the year). I'm not
clear how the survival model can give this information (but I'm not
familiar with survival analysis), but I thought it was more oriented
toward modeling time-to-event?

Also, going back to the original question, for my own understanding of
these models: is it correct to say that for a binomial GLMM to apply,
with patient as the (only) random effect, then for a given patient the
different Bernoulli variables must be independant, identically
distributed as in a usual logistic regression? Or is this hierarchical
approach too simplist?

Thanks anyway for these quick answers,

On Fri, Nov 13, 2015 at 10:59:29AM -0500, Ben Bolker wrote:
?   If you model the time until infection for each individual as
? Gamma-distributed, that will be more or less equivalent to a Gamma
? (parametric) survival model, with the big caveat that the GLMM framework
? is not good at handling censored data in general.
? 
?   I believe there is also a connection between discrete-time Cox
? proportional hazards models and binomial GLMMs with a complementary
? log-log link and fixed effect of time period ...
? 
?   Ben Bolker
? 
? On 15-11-13 08:41 AM, Emmanuel Curis wrote:
? > Dear Thierry,
? > 
? > Thanks for the hint. 
? > 
? > Just for curiosity, is there any case in which survival analysis will
? > be equivalent to the Markov model or the GLM(M) model? I remember having
? > read somewhere that there are links  between survival analysis and
? > logistic regression, but can't remember exactly which link for the
? > moment...
? > 
? > Best regards,
? > 
? > On Thu, Nov 12, 2015 at 09:59:18PM +0100, Thierry Onkelinx wrote:
? > ? Dear Emmanuel,
? > ? 
? > ? Maybe a survival analysis is more appropriate for that kind of data.
? > ? 
? > ? Best regards,
? > ? 
? > ? ir. Thierry Onkelinx
? > ? Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
? > ? Forest
? > ? team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
? > ? Kliniekstraat 25
? > ? 1070 Anderlecht
? > ? Belgium

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bbolker at gmail.com  Fri Nov 13 22:09:00 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Nov 2015 16:09:00 -0500
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <20151113163255.GB10987@info124.pharmacie.univ-paris5.fr>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
	<20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>
	<564608E1.4070304@gmail.com>
	<20151113163255.GB10987@info124.pharmacie.univ-paris5.fr>
Message-ID: <5646516C.9020201@gmail.com>

On 15-11-13 11:32 AM, Emmanuel Curis wrote:
> Thanks for these answers.
> 
> After thinking a little bit, I still have a concern with the
> survival approach.  What is in interest in the data is not really
> the time before patients are infected (at least, as far as I
> understood the practicionners problem), but the proportion of
> patients that are infected at a given moment (and, at the end, does
> this proportion change with some covariates, including period in
> the year). I'm not clear how the survival model can give this
> information (but I'm not familiar with survival analysis), but I
> thought it was more oriented toward modeling time-to-event?

  Well, these are really just different representations of the same
information.  In a canned statistical formulation (e.g. GLMM *or*
survival analysis), it's easier to deal with the constraint that
individuals are represented by a string of 0s followed by a string of
1s in the time-to-event framework.

  Given a cohort of individuals, one could construct predictions for
the expected number infected at a given time from the results of a
survival analysis (although might be easiest to do via stochastic
simulation).

  The assumption of independence of the individuals also breaks down
for infectious disease, unless the population is large enough that you
can assume randomly sampled individuals/neglect the effect of
infection status of some individuals on others' probability of
becoming infected ...

> Also, going back to the original question, for my own understanding
> of these models: is it correct to say that for a binomial GLMM to
> apply, with patient as the (only) random effect, then for a given
> patient the different Bernoulli variables must be independant,
> identically distributed as in a usual logistic regression? Or is
> this hierarchical approach too simplist?

  I think that's correct, extending your conditions slightly to say
that the variables are conditionally iid given both the identity of
the individual (latent variable) and any applicable
(time/patient-specific) fixed effects.

> 
> Thanks anyway for these quick answers,
> 
> On Fri, Nov 13, 2015 at 10:59:29AM -0500, Ben Bolker wrote: ?   If
> you model the time until infection for each individual as ?
> Gamma-distributed, that will be more or less equivalent to a Gamma 
> ? (parametric) survival model, with the big caveat that the GLMM
> framework ? is not good at handling censored data in general. ? ?
> I believe there is also a connection between discrete-time Cox ?
> proportional hazards models and binomial GLMMs with a
> complementary ? log-log link and fixed effect of time period ... ?
>  ?   Ben Bolker ? ? On 15-11-13 08:41 AM, Emmanuel Curis wrote: ? >
> Dear Thierry, ? > ? > Thanks for the hint. ? > ? > Just for
> curiosity, is there any case in which survival analysis will ? > be
> equivalent to the Markov model or the GLM(M) model? I remember
> having ? > read somewhere that there are links  between survival
> analysis and ? > logistic regression, but can't remember exactly
> which link for the ? > moment... ? > ? > Best regards, ? > ? > On
> Thu, Nov 12, 2015 at 09:59:18PM +0100, Thierry Onkelinx wrote: ? >
> ? Dear Emmanuel, ? > ? ? > ? Maybe a survival analysis is more
> appropriate for that kind of data. ? > ? ? > ? Best regards, ? > ?
>  ? > ? ir. Thierry Onkelinx ? > ? Instituut voor natuur- en
> bosonderzoek / Research Institute for Nature and ? > ? Forest ? > ?
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance ? > ? Kliniekstraat 25 ? > ? 1070 Anderlecht ? > ?
> Belgium
>


From miseno77 at hotmail.com  Sat Nov 14 17:48:46 2015
From: miseno77 at hotmail.com (Simone)
Date: Sat, 14 Nov 2015 17:48:46 +0100
Subject: [R-sig-ME] glmer random effects structure: a case
In-Reply-To: <5646516C.9020201@gmail.com>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>,
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>,
	<20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>,
	<564608E1.4070304@gmail.com>,
	<20151113163255.GB10987@info124.pharmacie.univ-paris5.fr>,
	<5646516C.9020201@gmail.com>
Message-ID: <DUB122-W23B9A81CF0199D75E296E6DC100@phx.gbl>


Hi all,
I have a simple (but not that simple to me) question on how to specify the random structure in R.A binary response variable (Var1) has been measured from a number of individuals (IND) that have been susceptible of being captured over a number of dates (DATE). I suspect that Var1 might depend either on its sex (SEX), or age (AGE) or Var2 which is a continuous variable measured from each individual every time it is captured. Since Var2 is a measure of the quality of each individual, it is likely that some individuals will tend to have greater values of Var2 than others during the entire study period.Note that some individuals have been captured only one time, other two, other three and so on (very unbalanced). For each date an individual can be captured only one time.So, I have two groups: IND and DATE. I would think this is a two-level model with IND nested to DATE so that:
model1 <- glmer(Var1 ~ SEX + AGE + Var2 + (1|DATE/IND), family = binomial, data = mydata)
Does it make sense? I think i am not taking into account the fact that the mean of Var2 may be different among individuals but I don't know how to do that.I would really appreciate an answer to this question that I am sure would help me a lot to understand better how mixed models work.
 		 	   		  
	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Sun Nov 15 02:59:31 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Sun, 15 Nov 2015 11:59:31 +1000
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1511151123290.25288@orpheus.qimr.edu.au>

On Fri, 13 Nov 2015, Thierry Onkelinx wrote:

> Maybe a survival analysis is more appropriate for that kind of data.
>>
>> Detailed version: our data consist of daily status of a set of
>> patients, the status being ? Infected ? or ? Not infected ?, during a
>> variable period of time. The aim is to see what changes the infection
>> probability.

As Thierry suggested, this type of dataset (incidence of infection) can be 
modelled as a recurrent events survival analysis.  These can be 
represented as in a discrete time framework as a poisson GLMM, or as Cox 
or parametric mixed effects survival models. One example might be various 
analyses of the "kidney" dataset of McGilchrist and Aisbett that is 
included in the BUGS manual. In R as:

brms::kidney            Infections in kidney patients
frailtyHL::kidney       Kidney Infection Data
INLA::Kidney            Kidney infection data
survival::kidney

The Markovian model appears in bivariate survival analyses covering time 
to infection and time to recovery - each may have different relevant risk 
factors - the random effect (frailty) for each individual links them 
together appropriately. You will probably also want time varying 
covariates.

Cheers, David Duffy.


| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A

From M.Fairbrother at bristol.ac.uk  Sun Nov 15 16:41:28 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 15 Nov 2015 16:41:28 +0100
Subject: [R-sig-ME] glmer random effects structure: a case
Message-ID: <CAAH-yP__UqKDV=rSyGGBG-qgZ3JXgi--pSb0+MioW2tVz-9ANg@mail.gmail.com>

Dear Simone,
How many INDs and DATEs are in your dataset? It sounds like you have plenty
of INDs, but it's less clear how many DATEs you have. If you have a lot,
you may have a situation of cross-classification: observations are nested
both in INDs and DATEs, but neither of those is nested in the either.
If you don't have many DATEs, it will make more sense to use fixed effects
for those. And even if you have a lot, if the DATEs are located close to
each other in time, you may have a lot of autocorrelation, and that
requires other techniques. (In R, you may need to use the older package
nlme, which allows for correlated residuals.)
In any event, if INDs are in many cases captured on multiple DATEs, it
definitely doesn't make sense to nest INDs in DATEs. Clearly they aren't
nested. (Assuming I've understood your data structure correctly.)
It also sounds like you should be centering Var2 by IND. This is pretty
much de rigueur in multilevel models with x variables that vary within
clusters. Enders and Tofighi 2007 is a useful, clear paper on this issue,
and you might also want to look at these recent papers by me and colleagues
in the Centre for Multilevel Modelling at Bristol:
doi:10.1017/psrm.2014.7
doi:10.1017/psrm.2013.24
Basically, take the mean of Var2 for each individual, and enter that as a
covariate. Then take the difference between the original Var2 and its mean
for that individual, and enter that as a covariate as well. You'll get two
pieces of information in your fitted model: the distinct "between" and
"within" effects of Var2. It sounds like that is what you want.
Hope that's useful.
- Malcolm



Date: Sat, 14 Nov 2015 17:48:46 +0100
> From: Simone <miseno77 at hotmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] glmer random effects structure: a case
>
>
> Hi all,
> I have a simple (but not that simple to me) question on how to specify the
> random structure in R.A binary response variable (Var1) has been measured
> from a number of individuals (IND) that have been susceptible of being
> captured over a number of dates (DATE). I suspect that Var1 might depend
> either on its sex (SEX), or age (AGE) or Var2 which is a continuous
> variable measured from each individual every time it is captured. Since
> Var2 is a measure of the quality of each individual, it is likely that some
> individuals will tend to have greater values of Var2 than others during the
> entire study period.Note that some individuals have been captured only one
> time, other two, other three and so on (very unbalanced). For each date an
> individual can be captured only one time.So, I have two groups: IND and
> DATE. I would think this is a two-level model with IND nested to DATE so
> that:
> model1 <- glmer(Var1 ~ SEX + AGE + Var2 + (1|DATE/IND), family = binomial,
> data = mydata)
> Does it make sense? I think i am not taking into account the fact that the
> mean of Var2 may be different among individuals but I don't know how to do
> that.I would really appreciate an answer to this question that I am sure
> would help me a lot to understand better how mixed models work.
>

	[[alternative HTML version deleted]]


From john.morrongiello at unimelb.edu.au  Mon Nov 16 11:36:30 2015
From: john.morrongiello at unimelb.edu.au (John Morrongiello)
Date: Mon, 16 Nov 2015 10:36:30 +0000
Subject: [R-sig-ME] glmer random effects structure: a case
Message-ID: <DE0D2370A8DD1A44ABCC0AF0597EC2C913818F1C@000s-ex-mbx-qs1.unimelb.edu.au>

Hi Simone
Maybe  technique behavioural ecologists call 'within subject centring' might be of use? This allows you to decompose a mean response (var2 coefficient) into its within and among individual components. See the references below for further details

van de Pol, M. V., and J. Wright. 2009. A simple method for distinguishing within- versus between-subject effects using mixed models. Animal Behaviour 77:753-758.
Dingemanse, N. J., and N. A. Dochtermann. 2013. Quantifying individual variation in behaviour: mixed-effect modelling approaches. Journal of Animal Ecology 82:39-54.

Cheers
John
--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au
W: morrongiellolab.com

Message: 1
Date: Sat, 14 Nov 2015 17:48:46 +0100
From: Simone <miseno77 at hotmail.com>
Cc: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] glmer random effects structure: a case
Message-ID: <DUB122-W23B9A81CF0199D75E296E6DC100 at phx.gbl>
Content-Type: text/plain; charset="UTF-8"


Hi all,
I have a simple (but not that simple to me) question on how to specify the random structure in R.A binary response variable (Var1) has been measured from a number of individuals (IND) that have been susceptible of being captured over a number of dates (DATE). I suspect that Var1 might depend either on its sex (SEX), or age (AGE) or Var2 which is a continuous variable measured from each individual every time it is captured. Since Var2 is a measure of the quality of each individual, it is likely that some individuals will tend to have greater values of Var2 than others during the entire study period.Note that some individuals have been captured only one time, other two, other three and so on (very unbalanced). For each date an individual can be captured only one time.So, I have two groups: IND and DATE. I would think this is a two-level model with IND nested to DATE so that:
model1 <- glmer(Var1 ~ SEX + AGE + Var2 + (1|DATE/IND), family = binomial, data = mydata) Does it make sense? I think i am not taking into account the fact that the mean of Var2 may be different among individuals but I don't know how to do that.I would really appreciate an answer to this question that I am sure would help me a lot to understand better how mixed models work.
 		 	   		  
	[[alternative HTML version deleted]]


From henry.travers at zoo.ox.ac.uk  Mon Nov 16 11:56:59 2015
From: henry.travers at zoo.ox.ac.uk (Henry Travers)
Date: Mon, 16 Nov 2015 10:56:59 +0000
Subject: [R-sig-ME] calculation of confidence intervals for random slope
	model
Message-ID: <ADCAD56B-DF62-44C2-81B1-6BDC16125789@zoo.ox.ac.uk>

I have what I hope is a relatively straightforward question about how to interpret the results of a mixed effects model of the form:

fm1 <- lmer(Reaction ~ Days + (Days | Subject))

I am running an experiment such that I am most interested in the (equivalent of the) effect of Days for each Subject, rather than say fitted values. I understand how to derive the point estimates for this effect, but I am struggling to see how to calculate confidence intervals for these estimates that take account of both the standard error in the parameter estimate for Days and the uncertainty in the corresponding slope estimates for each Subject.

I would be very grateful if someone could point me in the right direction or to a suitable reference.

------------------------------------------------
Henry Travers, PhD
Research Associate

Interdisciplinary Centre for Conservation Science
Department of Zoology
University of Oxford






	[[alternative HTML version deleted]]


From karraspito at yahoo.es  Mon Nov 16 12:18:09 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Mon, 16 Nov 2015 11:18:09 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm: Question about posterior mean.
In-Reply-To: <mailman.1.1447671601.6219.r-sig-mixed-models@r-project.org>
References: <mailman.1.1447671601.6219.r-sig-mixed-models@r-project.org>
Message-ID: <450508246.8587063.1447672689747.JavaMail.yahoo@mail.yahoo.com>

Hello everyone,Just a quick question: Could we somehow interpret posterior mean in an MCMCgklmm summary (see below) as kind of an effect size of each predictor? I mean, for example, the intercept for "appcareshort" (score from 1 to 5 given by participants in a survey to the attractiveness in a potential partner of appearance care for a short, casual relationship) is 3.242. So, is, for example, the effect of gender M on "appcareshort" more negative than the intercept? Or in other words, do male participants in the survey value care of appearance in potential partners significantly less than people of other gender?
? 
???????????????????????????????????????  post.mean?? l-95% CI?? u-95% CI? eff.samp? pMCMC??? traitappcareshort??????????????????????? 3.242e+00 -3.209e+00? 9.638e+00? 9201.037 0.3247??? traitappcarelong???????????????????????? 3.700e+00 -2.789e+00? 1.034e+01? 8610.520 0.2625??? traitappcareshort:genderM?????????????? -1.128e-01 -2.526e+00? 2.356e+00? 9113.094 0.009**??? traitappcarelong:genderM???????????????? 1.273e-01 -2.270e+00? 2.663e+00? 8641.121 0.9243??? traitappcareshort:genderO??????????????? 1.005e+03 -1.787e+05? 1.873e+05? 9700.000 0.9872??? traitappcarelong:genderO??????????????? -2.177e+03 -1.895e+05? 1.855e+05 10368.220 0.9839??? traitappcareshort:age?????????????????? -7.331e-01 -3.681e+00? 2.267e+00 10202.025 0.6200??? traitappcarelong:age??????????????????? -1.433e+00 -4.507e+00? 1.571e+00? 8834.924 0.3546??? traitappcareshort:religionY???????????? -2.229e+00 -5.144e+00? 6.142e-01? 9157.812 0.1214??? 

Also: as far as I can understand, the effective sample size is the number of iterations that MCMCglmm actually stores, and from which it "constructs" the posterior distribution. In this case, the total number of iterations was 100,000 and effective sample was always around 10,000 (which makes sense given that thin=10). My doubt is in that predictor with an effective sample size of 1.404. My experience tells me that when I plot the model for diagnostic purposes, that very predictor is going to show a clear lack of convergence. I would just like to ask whether I am right in what effective sample size means, what is the difference between the sample size (9700) and the effective sample size of the predictors, and how it's possible an effective sample size of 10,368 with 100,000 iterations and thin=10.

Thank you very much in advance to everyone.

Kind regards,
Iker  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Nov 16 14:58:20 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 Nov 2015 08:58:20 -0500
Subject: [R-sig-ME] calculation of confidence intervals for random slope
	model
In-Reply-To: <ADCAD56B-DF62-44C2-81B1-6BDC16125789@zoo.ox.ac.uk>
References: <ADCAD56B-DF62-44C2-81B1-6BDC16125789@zoo.ox.ac.uk>
Message-ID: <CABghstRW92TYL1E3xZp7-jNqQtShzMVfekga_gza-XS9ov9oMQ@mail.gmail.com>

On Mon, Nov 16, 2015 at 5:56 AM, Henry Travers
<henry.travers at zoo.ox.ac.uk> wrote:
> I have what I hope is a relatively straightforward question about how to interpret the results of a mixed effects model of the form:
>
> fm1 <- lmer(Reaction ~ Days + (Days | Subject))
>
> I am running an experiment such that I am most interested in the (equivalent of the) effect of Days for each Subject, rather than say fitted values. I understand how to derive the point estimates for this effect, but I am struggling to see how to calculate confidence intervals for these estimates that take account of both the standard error in the parameter estimate for Days and the uncertainty in the corresponding slope estimates for each Subject.
>
> I would be very grateful if someone could point me in the right direction or to a suitable reference.

  This is a surprisingly difficult question to answer.
  There have been extended discussions in the mailing list (which I
don't have time to dig for now) about whether it's OK to add the
conditional variances of the conditional modes to the variances of the
fixed-effect predictions, and the circumstances under which this would
be (in)accurate/(anti)conservative.  The other alternative is to use
bootMer + predict to get confidence intervals ...

  This should probably be added to the FAQ ...

>
> ------------------------------------------------
> Henry Travers, PhD
> Research Associate
>
> Interdisciplinary Centre for Conservation Science
> Department of Zoology
> University of Oxford
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From miseno77 at hotmail.com  Mon Nov 16 16:07:51 2015
From: miseno77 at hotmail.com (Simone)
Date: Mon, 16 Nov 2015 16:07:51 +0100
Subject: [R-sig-ME] glmer random effects structure: a case
In-Reply-To: <CAAH-yP__UqKDV=rSyGGBG-qgZ3JXgi--pSb0+MioW2tVz-9ANg@mail.gmail.com>
References: <CAAH-yP__UqKDV=rSyGGBG-qgZ3JXgi--pSb0+MioW2tVz-9ANg@mail.gmail.com>
Message-ID: <DUB122-W40BC4589E167B41448BF7DC1E0@phx.gbl>

Dear Malcolm,

Thank you so much for your detailed (very
interesting references!) and helpful answer. I have centered Var2 by IND and I
have used both the individual-specific mean Var2 (Var2meanIND) as well as the
individual-specific centered Var2 (Var2varIND). I understand that this way I can
test if the variation among individuals (first case) or within them (second
case) relate to the response variable.

As you suspected, DATEs are often close
each other and it is quite probable I have autocorrelated data. You mentioned
that the nlme package handles correlated residuals and I have found the code to
do that but the problem is that I cannot do it for my case study since the
distribution I am using is a binomial and nlme is only for linear mixed model,
isn?it?

For now, I have being using the below syntax
and using LRT (anova) between reduced nested models to compute the p-value for
each predictor. I know that LRT is very criticized but I have been asked to
calculate p-values for each predictor.


Mod1<-glmer(Var1 ~ SEX + AGE +
Var2meanIND + Var2varIND + (1|DATE) + (1|IND) , data = mydata, family = binomial,
control = glmerControl(optimizer="bobyqa"))


This way I am not accounting at all for the
autocorrelation, do you have any suggestions?

Thanks again,

Simone
Date: Sun, 15 Nov 2015 16:41:28 +0100
Subject: Re: [R-sig-ME] glmer random effects structure: a case
From: M.Fairbrother at bristol.ac.uk
To: miseno77 at hotmail.com
CC: r-sig-mixed-models at r-project.org

Dear Simone,
How many INDs and DATEs are in your dataset? It sounds like you have plenty of INDs, but it's less clear how many DATEs you have. If you have a lot, you may have a situation of cross-classification: observations are nested both in INDs and DATEs, but neither of those is nested in the either.
If you don't have many DATEs, it will make more sense to use fixed effects for those. And even if you have a lot, if the DATEs are located close to each other in time, you may have a lot of autocorrelation, and that requires other techniques. (In R, you may need to use the older package nlme, which allows for correlated residuals.)
In any event, if INDs are in many cases captured on multiple DATEs, it definitely doesn't make sense to nest INDs in DATEs. Clearly they aren't nested. (Assuming I've understood your data structure correctly.)
It also sounds like you should be centering Var2 by IND. This is pretty much de rigueur in multilevel models with x variables that vary within clusters. Enders and Tofighi 2007 is a useful, clear paper on this issue, and you might also want to look at these recent papers by me and colleagues in the Centre for Multilevel Modelling at Bristol:
doi:10.1017/psrm.2014.7
doi:10.1017/psrm.2013.24
Basically, take the mean of Var2 for each individual, and enter that as a covariate. Then take the difference between the original Var2 and its mean for that individual, and enter that as a covariate as well. You'll get two pieces of information in your fitted model: the distinct "between" and "within" effects of Var2. It sounds like that is what you want.Hope that's useful.
- Malcolm


Date: Sat, 14 Nov 2015 17:48:46 +0100

From: Simone <miseno77 at hotmail.com>

Cc: "r-sig-mixed-models at r-project.org"

        <r-sig-mixed-models at r-project.org>

Subject: [R-sig-ME] glmer random effects structure: a case




Hi all,

I have a simple (but not that simple to me) question on how to specify the random structure in R.A binary response variable (Var1) has been measured from a number of individuals (IND) that have been susceptible of being captured over a number of dates (DATE). I suspect that Var1 might depend either on its sex (SEX), or age (AGE) or Var2 which is a continuous variable measured from each individual every time it is captured. Since Var2 is a measure of the quality of each individual, it is likely that some individuals will tend to have greater values of Var2 than others during the entire study period.Note that some individuals have been captured only one time, other two, other three and so on (very unbalanced). For each date an individual can be captured only one time.So, I have two groups: IND and DATE. I would think this is a two-level model with IND nested to DATE so that:

model1 <- glmer(Var1 ~ SEX + AGE + Var2 + (1|DATE/IND), family = binomial, data = mydata)

Does it make sense? I think i am not taking into account the fact that the mean of Var2 may be different among individuals but I don't know how to do that.I would really appreciate an answer to this question that I am sure would help me a lot to understand better how mixed models work.
  		 	   		  
	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Mon Nov 16 16:45:54 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 16 Nov 2015 16:45:54 +0100
Subject: [R-sig-ME] glmer random effects structure: a case
Message-ID: <CAAH-yP9=opn9Cw+oH8c-UyPSUqiHLqu0J1dYRKmsR3T+4kbRMg@mail.gmail.com>

Dear Simone,
Glad that was useful, and yes everything you say sounds right to me. For p
values, my understanding is that LRTs are fine, however. Or you could also
use a bootstrap, or MCMC.
As for autocorrelation, sorry, I hadn't been thinking through the
implications of your having a binary outcome variable. And I had been under
the impression that nlme could fit logit models, but a quick investigation
around the web suggests I was wrong about that. (If anyone knows otherwise,
please correct me/us.)
I am not an expert on dealing with autocorrelation in the case of binary
outcomes. Someone else may have advice about that, however.
Best wishes,
Malcolm


On 16 November 2015 at 16:07, Simone <miseno77 at hotmail.com> wrote:

> Dear Malcolm,
>
> Thank you so much for your detailed (very interesting references!) and
> helpful answer. I have centered Var2 by IND and I have used both the
> individual-specific mean Var2 (Var2meanIND) as well as the
> individual-specific centered Var2 (Var2varIND). I understand that this way
> I can test if the variation among individuals (first case) or within them
> (second case) relate to the response variable.
>
> As you suspected, DATEs are often close each other and it is quite
> probable I have autocorrelated data. You mentioned that the nlme package
> handles correlated residuals and I have found the code to do that but the
> problem is that I cannot do it for my case study since the distribution I
> am using is a binomial and nlme is only for linear mixed model, isn?it?
>
> For now, I have being using the below syntax and using LRT (anova) between
> reduced nested models to compute the p-value for each predictor. I know
> that LRT is very criticized but I have been asked to calculate p-values for
> each predictor.
>
>
> Mod1<-glmer(Var1 ~ SEX + AGE + Var2meanIND + Var2varIND + (1|DATE) +
> (1|IND) , data = mydata, family = binomial, control =
> glmerControl(optimizer="bobyqa"))
>
>
> This way I am not accounting at all for the autocorrelation, do you have
> any suggestions?
> Thanks again,
>
> Simone
>
> ------------------------------
> Date: Sun, 15 Nov 2015 16:41:28 +0100
> Subject: Re: [R-sig-ME] glmer random effects structure: a case
> From: M.Fairbrother at bristol.ac.uk
> To: miseno77 at hotmail.com
> CC: r-sig-mixed-models at r-project.org
>
>
> Dear Simone,
> How many INDs and DATEs are in your dataset? It sounds like you have
> plenty of INDs, but it's less clear how many DATEs you have. If you have a
> lot, you may have a situation of cross-classification: observations are
> nested both in INDs and DATEs, but neither of those is nested in the either.
> If you don't have many DATEs, it will make more sense to use fixed effects
> for those. And even if you have a lot, if the DATEs are located close to
> each other in time, you may have a lot of autocorrelation, and that
> requires other techniques. (In R, you may need to use the older package
> nlme, which allows for correlated residuals.)
> In any event, if INDs are in many cases captured on multiple DATEs, it
> definitely doesn't make sense to nest INDs in DATEs. Clearly they aren't
> nested. (Assuming I've understood your data structure correctly.)
> It also sounds like you should be centering Var2 by IND. This is pretty
> much de rigueur in multilevel models with x variables that vary within
> clusters. Enders and Tofighi 2007 is a useful, clear paper on this issue,
> and you might also want to look at these recent papers by me and colleagues
> in the Centre for Multilevel Modelling at Bristol:
> doi:10.1017/psrm.2014.7
> doi:10.1017/psrm.2013.24
> Basically, take the mean of Var2 for each individual, and enter that as a
> covariate. Then take the difference between the original Var2 and its mean
> for that individual, and enter that as a covariate as well. You'll get two
> pieces of information in your fitted model: the distinct "between" and
> "within" effects of Var2. It sounds like that is what you want.
> Hope that's useful.
> - Malcolm
>
>
>
> Date: Sat, 14 Nov 2015 17:48:46 +0100
> From: Simone <miseno77 at hotmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] glmer random effects structure: a case
>
>
> Hi all,
> I have a simple (but not that simple to me) question on how to specify the
> random structure in R.A binary response variable (Var1) has been measured
> from a number of individuals (IND) that have been susceptible of being
> captured over a number of dates (DATE). I suspect that Var1 might depend
> either on its sex (SEX), or age (AGE) or Var2 which is a continuous
> variable measured from each individual every time it is captured. Since
> Var2 is a measure of the quality of each individual, it is likely that some
> individuals will tend to have greater values of Var2 than others during the
> entire study period.Note that some individuals have been captured only one
> time, other two, other three and so on (very unbalanced). For each date an
> individual can be captured only one time.So, I have two groups: IND and
> DATE. I would think this is a two-level model with IND nested to DATE so
> that:
> model1 <- glmer(Var1 ~ SEX + AGE + Var2 + (1|DATE/IND), family = binomial,
> data = mydata)
> Does it make sense? I think i am not taking into account the fact that the
> mean of Var2 may be different among individuals but I don't know how to do
> that.I would really appreciate an answer to this question that I am sure
> would help me a lot to understand better how mixed models work.
>
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Nov 16 18:05:53 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 16 Nov 2015 18:05:53 +0100
Subject: [R-sig-ME] glmer random effects structure: a case
In-Reply-To: <CAAH-yP9=opn9Cw+oH8c-UyPSUqiHLqu0J1dYRKmsR3T+4kbRMg@mail.gmail.com>
References: <CAAH-yP9=opn9Cw+oH8c-UyPSUqiHLqu0J1dYRKmsR3T+4kbRMg@mail.gmail.com>
Message-ID: <CAJuCY5ya6yPpmjc+Yw7N7KzQNsw4T52X6bvr=7vTQwjdn40zoA@mail.gmail.com>

Dear Simone,

nlme models correlation structures on the residuals. Those are the epsilons
in the model. Y = X * beta + epsilon. Don't confuse them with the output of
resid(model). In the case of a Gaussian model, they happen to be the same.
In case of a binomial, and many other distributions, they are not. Because
there is not such thing as epsilon in a binomial model. Y = Binom(pi),
logit(pi) = X * beta. Since there are no epsilons in the binomial model,
the correlation structures for nlme don't work.

The correlation structures in nlme work within the finest level of the
random effects. So in your case within dates rather than among dates. Which
is not what you are looking for.

Also note that adding a random intercept is equivalent to a compound
symmetry correlation structure on that variable. Having some correlation
structure is often sufficient.

Have a look at the INLA package (www.rinla.org) if you want to model the
temporal autocorrelation and willing to go Bayesian. INLA can model
correlated random effects. Be warned: it not for the faint of heart.

inla(Var1 ~ SEX + AGE + Var2meanID + Var2varIND + f(DATE, model = "AR1") +
f(IND, model = "iid"), data = mydata, family = "binomial")

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-16 16:45 GMT+01:00 Malcolm Fairbrother <M.Fairbrother at bristol.ac.uk>
:

> Dear Simone,
> Glad that was useful, and yes everything you say sounds right to me. For p
> values, my understanding is that LRTs are fine, however. Or you could also
> use a bootstrap, or MCMC.
> As for autocorrelation, sorry, I hadn't been thinking through the
> implications of your having a binary outcome variable. And I had been under
> the impression that nlme could fit logit models, but a quick investigation
> around the web suggests I was wrong about that. (If anyone knows otherwise,
> please correct me/us.)
> I am not an expert on dealing with autocorrelation in the case of binary
> outcomes. Someone else may have advice about that, however.
> Best wishes,
> Malcolm
>
>
> On 16 November 2015 at 16:07, Simone <miseno77 at hotmail.com> wrote:
>
> > Dear Malcolm,
> >
> > Thank you so much for your detailed (very interesting references!) and
> > helpful answer. I have centered Var2 by IND and I have used both the
> > individual-specific mean Var2 (Var2meanIND) as well as the
> > individual-specific centered Var2 (Var2varIND). I understand that this
> way
> > I can test if the variation among individuals (first case) or within them
> > (second case) relate to the response variable.
> >
> > As you suspected, DATEs are often close each other and it is quite
> > probable I have autocorrelated data. You mentioned that the nlme package
> > handles correlated residuals and I have found the code to do that but the
> > problem is that I cannot do it for my case study since the distribution I
> > am using is a binomial and nlme is only for linear mixed model, isn?it?
> >
> > For now, I have being using the below syntax and using LRT (anova)
> between
> > reduced nested models to compute the p-value for each predictor. I know
> > that LRT is very criticized but I have been asked to calculate p-values
> for
> > each predictor.
> >
> >
> > Mod1<-glmer(Var1 ~ SEX + AGE + Var2meanIND + Var2varIND + (1|DATE) +
> > (1|IND) , data = mydata, family = binomial, control =
> > glmerControl(optimizer="bobyqa"))
> >
> >
> > This way I am not accounting at all for the autocorrelation, do you have
> > any suggestions?
> > Thanks again,
> >
> > Simone
> >
> > ------------------------------
> > Date: Sun, 15 Nov 2015 16:41:28 +0100
> > Subject: Re: [R-sig-ME] glmer random effects structure: a case
> > From: M.Fairbrother at bristol.ac.uk
> > To: miseno77 at hotmail.com
> > CC: r-sig-mixed-models at r-project.org
> >
> >
> > Dear Simone,
> > How many INDs and DATEs are in your dataset? It sounds like you have
> > plenty of INDs, but it's less clear how many DATEs you have. If you have
> a
> > lot, you may have a situation of cross-classification: observations are
> > nested both in INDs and DATEs, but neither of those is nested in the
> either.
> > If you don't have many DATEs, it will make more sense to use fixed
> effects
> > for those. And even if you have a lot, if the DATEs are located close to
> > each other in time, you may have a lot of autocorrelation, and that
> > requires other techniques. (In R, you may need to use the older package
> > nlme, which allows for correlated residuals.)
> > In any event, if INDs are in many cases captured on multiple DATEs, it
> > definitely doesn't make sense to nest INDs in DATEs. Clearly they aren't
> > nested. (Assuming I've understood your data structure correctly.)
> > It also sounds like you should be centering Var2 by IND. This is pretty
> > much de rigueur in multilevel models with x variables that vary within
> > clusters. Enders and Tofighi 2007 is a useful, clear paper on this issue,
> > and you might also want to look at these recent papers by me and
> colleagues
> > in the Centre for Multilevel Modelling at Bristol:
> > doi:10.1017/psrm.2014.7
> > doi:10.1017/psrm.2013.24
> > Basically, take the mean of Var2 for each individual, and enter that as a
> > covariate. Then take the difference between the original Var2 and its
> mean
> > for that individual, and enter that as a covariate as well. You'll get
> two
> > pieces of information in your fitted model: the distinct "between" and
> > "within" effects of Var2. It sounds like that is what you want.
> > Hope that's useful.
> > - Malcolm
> >
> >
> >
> > Date: Sat, 14 Nov 2015 17:48:46 +0100
> > From: Simone <miseno77 at hotmail.com>
> > Cc: "r-sig-mixed-models at r-project.org"
> >         <r-sig-mixed-models at r-project.org>
> > Subject: [R-sig-ME] glmer random effects structure: a case
> >
> >
> > Hi all,
> > I have a simple (but not that simple to me) question on how to specify
> the
> > random structure in R.A binary response variable (Var1) has been measured
> > from a number of individuals (IND) that have been susceptible of being
> > captured over a number of dates (DATE). I suspect that Var1 might depend
> > either on its sex (SEX), or age (AGE) or Var2 which is a continuous
> > variable measured from each individual every time it is captured. Since
> > Var2 is a measure of the quality of each individual, it is likely that
> some
> > individuals will tend to have greater values of Var2 than others during
> the
> > entire study period.Note that some individuals have been captured only
> one
> > time, other two, other three and so on (very unbalanced). For each date
> an
> > individual can be captured only one time.So, I have two groups: IND and
> > DATE. I would think this is a two-level model with IND nested to DATE so
> > that:
> > model1 <- glmer(Var1 ~ SEX + AGE + Var2 + (1|DATE/IND), family =
> binomial,
> > data = mydata)
> > Does it make sense? I think i am not taking into account the fact that
> the
> > mean of Var2 may be different among individuals but I don't know how to
> do
> > that.I would really appreciate an answer to this question that I am sure
> > would help me a lot to understand better how mixed models work.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Nov 17 10:32:45 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Nov 2015 10:32:45 +0100
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <29f8a487b50948c1a4aad2108c614c8f@ITGSRV017.itg.be>
References: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
	<CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>
	<29f8a487b50948c1a4aad2108c614c8f@ITGSRV017.itg.be>
Message-ID: <CAJuCY5x7bE3QT3rA97mnJWG2-Ui1HMKHN-aLCt2459bHuiQOzA@mail.gmail.com>

Dear Veronique,

We need more information. How many animals, villages, treatments,
timepoints, ...? How many observations per animal and per village? Can you
post the data or send it offline?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-17 10:09 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:

> Dear Thierry,
>
>
>
> Thank you for your response and advice.
>
> I?ve omitted missing values (94 out of 965), but I am getting another
> error message, see below:
>
> > cambNA<-na.omit(camb)
>
> >
> mod1b<-glmmadmb(GIS~Treatment*Time+(1|Animal)+(1|Village),family="nbinom",data=cambNA)
>
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
>
> Error in glmmadmb(GIS ~ Treatment * Time + (1 | Animal) +  :
>
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
>
> In addition: Warning message:
>
> running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
> 5 -noinit -shess' had status 1
>
>
>
> Thank you for your help,
>
> Best regards,
>
> Veronique Dermauw.
>
>
>
> *From:* Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> *Sent:* donderdag 12 november 2015 17:44
> *To:* Veronique Dermauw
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] glmmADMB
>
>
>
> Dear Veronique,
>
>
>
> It looks like your data contains missing values. Try to remove them. Your
> syntax seems to be correct.
>
>
>
> Note that Treatment + Time + Time * Treatment can be abbreviated to Time
> * Treatment
>
>
>
> Best regards,
>
>
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
> 2015-11-11 12:17 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:
>
> Dear,
>
> Recently I have been working on a dataset which seems to require a
> generalized linear mixed model with a negative binomial distribution.
> I came across the glmmADMB package which seems ideal.
> However, I am a bit stuck here (see codes and error message below).
> The dataset I am working on, involves count variables (GIS) from animals
> from different villages who were allocated a treatment (Treatment) and were
> sampled at various Time point (hence Time and Time*Treatment).
> I was wondering if you could assist me with this command?
>
> Many thanks for your response,
> Best regards,
> Veronique Dermauw.
>
>
> mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
> summary(mod1b)
> Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
>   number of items to replace is not a multiple of replacement length
> In addition: Warning messages:
> 1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +
> :
>   NAs removed in constructing fixed-effect model frame: you should
> probably remove them manually, e.g. with na.omit()
> 2: In II[, ii] + REmat$codes[[i]] :
>   longer object length is not a multiple of shorter object length
>
>
> Veronique Dermauw
> PhD, MSc Veterinary Medicine
> Institute of Tropical Medicine
> Nationalestraat 155
> 2000 Antwerp
> +32(0)32476447
>
>
> P Please consider the environment before printing this e-mail
>
> Disclaimer: Http://www.itg.be/disclaimer
>
> Directions to our location(s): http://g.co/maps/ua89b
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From miseno77 at hotmail.com  Tue Nov 17 10:41:14 2015
From: miseno77 at hotmail.com (Simone)
Date: Tue, 17 Nov 2015 10:41:14 +0100
Subject: [R-sig-ME] glmer random effects structure: a case
In-Reply-To: <CAJuCY5ya6yPpmjc+Yw7N7KzQNsw4T52X6bvr=7vTQwjdn40zoA@mail.gmail.com>
References: <CAAH-yP9=opn9Cw+oH8c-UyPSUqiHLqu0J1dYRKmsR3T+4kbRMg@mail.gmail.com>,
	<CAJuCY5ya6yPpmjc+Yw7N7KzQNsw4T52X6bvr=7vTQwjdn40zoA@mail.gmail.com>
Message-ID: <DUB122-W408E9B5934260805789038DC1D0@phx.gbl>

Dear Thierry,
I have been struggling a bit to understand this paragraph of your answer:"Also note that adding a random intercept is equivalent to a compound symmetry correlation structure on that variable. Having some correlation structure is often sufficient."
But after some googling I think I have grasped the concept and this has helped me to understand better the issue. Thanks you and the others for your suggestions and helpful comments.Simone
Date: Mon, 16 Nov 2015 18:05:53 +0100
Subject: Re: [R-sig-ME] glmer random effects structure: a case
From: thierry.onkelinx at inbo.be
To: M.Fairbrother at bristol.ac.uk
CC: miseno77 at hotmail.com; r-sig-mixed-models at r-project.org

Dear Simone,
nlme models correlation structures on the residuals. Those are the epsilons in the model. Y = X * beta + epsilon. Don't confuse them with the output of resid(model). In the case of a Gaussian model, they happen to be the same. In case of a binomial, and many other distributions, they are not. Because there is not such thing as epsilon in a binomial model. Y = Binom(pi), logit(pi) = X * beta. Since there are no epsilons in the binomial model, the correlation structures for nlme don't work.
The correlation structures in nlme work within the finest level of the random effects. So in your case within dates rather than among dates. Which is not what you are looking for.
Also note that adding a random intercept is equivalent to a compound symmetry correlation structure on that variable. Having some correlation structure is often sufficient.
Have a look at the INLA package (www.rinla.org) if you want to model the temporal autocorrelation and willing to go Bayesian. INLA can model correlated random effects. Be warned: it not for the faint of heart.
inla(Var1 ~ SEX + AGE + Var2meanID + Var2varIND + f(DATE, model = "AR1") + f(IND, model = "iid"), data = mydata, family = "binomial")
Best regards, ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-16 16:45 GMT+01:00 Malcolm Fairbrother <M.Fairbrother at bristol.ac.uk>:
Dear Simone,

Glad that was useful, and yes everything you say sounds right to me. For p

values, my understanding is that LRTs are fine, however. Or you could also

use a bootstrap, or MCMC.

As for autocorrelation, sorry, I hadn't been thinking through the

implications of your having a binary outcome variable. And I had been under

the impression that nlme could fit logit models, but a quick investigation

around the web suggests I was wrong about that. (If anyone knows otherwise,

please correct me/us.)

I am not an expert on dealing with autocorrelation in the case of binary

outcomes. Someone else may have advice about that, however.

Best wishes,

Malcolm





On 16 November 2015 at 16:07, Simone <miseno77 at hotmail.com> wrote:



> Dear Malcolm,

>

> Thank you so much for your detailed (very interesting references!) and

> helpful answer. I have centered Var2 by IND and I have used both the

> individual-specific mean Var2 (Var2meanIND) as well as the

> individual-specific centered Var2 (Var2varIND). I understand that this way

> I can test if the variation among individuals (first case) or within them

> (second case) relate to the response variable.

>

> As you suspected, DATEs are often close each other and it is quite

> probable I have autocorrelated data. You mentioned that the nlme package

> handles correlated residuals and I have found the code to do that but the

> problem is that I cannot do it for my case study since the distribution I

> am using is a binomial and nlme is only for linear mixed model, isn?it?

>

> For now, I have being using the below syntax and using LRT (anova) between

> reduced nested models to compute the p-value for each predictor. I know

> that LRT is very criticized but I have been asked to calculate p-values for

> each predictor.

>

>

> Mod1<-glmer(Var1 ~ SEX + AGE + Var2meanIND + Var2varIND + (1|DATE) +

> (1|IND) , data = mydata, family = binomial, control =

> glmerControl(optimizer="bobyqa"))

>

>

> This way I am not accounting at all for the autocorrelation, do you have

> any suggestions?

> Thanks again,

>

> Simone

>

> ------------------------------

> Date: Sun, 15 Nov 2015 16:41:28 +0100

> Subject: Re: [R-sig-ME] glmer random effects structure: a case

> From: M.Fairbrother at bristol.ac.uk

> To: miseno77 at hotmail.com

> CC: r-sig-mixed-models at r-project.org

>

>

> Dear Simone,

> How many INDs and DATEs are in your dataset? It sounds like you have

> plenty of INDs, but it's less clear how many DATEs you have. If you have a

> lot, you may have a situation of cross-classification: observations are

> nested both in INDs and DATEs, but neither of those is nested in the either.

> If you don't have many DATEs, it will make more sense to use fixed effects

> for those. And even if you have a lot, if the DATEs are located close to

> each other in time, you may have a lot of autocorrelation, and that

> requires other techniques. (In R, you may need to use the older package

> nlme, which allows for correlated residuals.)

> In any event, if INDs are in many cases captured on multiple DATEs, it

> definitely doesn't make sense to nest INDs in DATEs. Clearly they aren't

> nested. (Assuming I've understood your data structure correctly.)

> It also sounds like you should be centering Var2 by IND. This is pretty

> much de rigueur in multilevel models with x variables that vary within

> clusters. Enders and Tofighi 2007 is a useful, clear paper on this issue,

> and you might also want to look at these recent papers by me and colleagues

> in the Centre for Multilevel Modelling at Bristol:

> doi:10.1017/psrm.2014.7

> doi:10.1017/psrm.2013.24

> Basically, take the mean of Var2 for each individual, and enter that as a

> covariate. Then take the difference between the original Var2 and its mean

> for that individual, and enter that as a covariate as well. You'll get two

> pieces of information in your fitted model: the distinct "between" and

> "within" effects of Var2. It sounds like that is what you want.

> Hope that's useful.

> - Malcolm

>

>

>

> Date: Sat, 14 Nov 2015 17:48:46 +0100

> From: Simone <miseno77 at hotmail.com>

> Cc: "r-sig-mixed-models at r-project.org"

>         <r-sig-mixed-models at r-project.org>

> Subject: [R-sig-ME] glmer random effects structure: a case

>

>

> Hi all,

> I have a simple (but not that simple to me) question on how to specify the

> random structure in R.A binary response variable (Var1) has been measured

> from a number of individuals (IND) that have been susceptible of being

> captured over a number of dates (DATE). I suspect that Var1 might depend

> either on its sex (SEX), or age (AGE) or Var2 which is a continuous

> variable measured from each individual every time it is captured. Since

> Var2 is a measure of the quality of each individual, it is likely that some

> individuals will tend to have greater values of Var2 than others during the

> entire study period.Note that some individuals have been captured only one

> time, other two, other three and so on (very unbalanced). For each date an

> individual can be captured only one time.So, I have two groups: IND and

> DATE. I would think this is a two-level model with IND nested to DATE so

> that:

> model1 <- glmer(Var1 ~ SEX + AGE + Var2 + (1|DATE/IND), family = binomial,

> data = mydata)

> Does it make sense? I think i am not taking into account the fact that the

> mean of Var2 may be different among individuals but I don't know how to do

> that.I would really appreciate an answer to this question that I am sure

> would help me a lot to understand better how mixed models work.

>

>

>



        [[alternative HTML version deleted]]



_______________________________________________

R-sig-mixed-models at r-project.org mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Nov 17 10:43:57 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Nov 2015 10:43:57 +0100
Subject: [R-sig-ME] glmer random effects structure: a case
In-Reply-To: <DUB122-W408E9B5934260805789038DC1D0@phx.gbl>
References: <CAAH-yP9=opn9Cw+oH8c-UyPSUqiHLqu0J1dYRKmsR3T+4kbRMg@mail.gmail.com>
	<CAJuCY5ya6yPpmjc+Yw7N7KzQNsw4T52X6bvr=7vTQwjdn40zoA@mail.gmail.com>
	<DUB122-W408E9B5934260805789038DC1D0@phx.gbl>
Message-ID: <CAJuCY5x3if+uoUyZZTSeo76t5i1V2i-VeCHA=z8vBb1__ExTqQ@mail.gmail.com>

Dear Simone,

See chapter 5 of Zuur et al (2009) for more details.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-17 10:41 GMT+01:00 Simone <miseno77 at hotmail.com>:

> Dear Thierry,
>
> I have been struggling a bit to understand this paragraph of your answer:
> "Also note that adding a random intercept is equivalent to a compound
> symmetry correlation structure on that variable. Having some correlation
> structure is often sufficient."
>
> But after some googling I think I have grasped the concept and this has
> helped me to understand better the issue. Thanks you and the others for
> your suggestions and helpful comments.
> Simone
>
> ------------------------------
> Date: Mon, 16 Nov 2015 18:05:53 +0100
> Subject: Re: [R-sig-ME] glmer random effects structure: a case
> From: thierry.onkelinx at inbo.be
> To: M.Fairbrother at bristol.ac.uk
> CC: miseno77 at hotmail.com; r-sig-mixed-models at r-project.org
>
>
> Dear Simone,
>
> nlme models correlation structures on the residuals. Those are the
> epsilons in the model. Y = X * beta + epsilon. Don't confuse them with the
> output of resid(model). In the case of a Gaussian model, they happen to be
> the same. In case of a binomial, and many other distributions, they are
> not. Because there is not such thing as epsilon in a binomial model. Y =
> Binom(pi), logit(pi) = X * beta. Since there are no epsilons in the
> binomial model, the correlation structures for nlme don't work.
>
> The correlation structures in nlme work within the finest level of the
> random effects. So in your case within dates rather than among dates. Which
> is not what you are looking for.
>
> Also note that adding a random intercept is equivalent to a compound
> symmetry correlation structure on that variable. Having some correlation
> structure is often sufficient.
>
> Have a look at the INLA package (www.rinla.org) if you want to model the
> temporal autocorrelation and willing to go Bayesian. INLA can model
> correlated random effects. Be warned: it not for the faint of heart.
>
> inla(Var1 ~ SEX + AGE + Var2meanID + Var2varIND + f(DATE, model = "AR1") +
> f(IND, model = "iid"), data = mydata, family = "binomial")
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-11-16 16:45 GMT+01:00 Malcolm Fairbrother <
> M.Fairbrother at bristol.ac.uk>:
>
> Dear Simone,
> Glad that was useful, and yes everything you say sounds right to me. For p
> values, my understanding is that LRTs are fine, however. Or you could also
> use a bootstrap, or MCMC.
> As for autocorrelation, sorry, I hadn't been thinking through the
> implications of your having a binary outcome variable. And I had been under
> the impression that nlme could fit logit models, but a quick investigation
> around the web suggests I was wrong about that. (If anyone knows otherwise,
> please correct me/us.)
> I am not an expert on dealing with autocorrelation in the case of binary
> outcomes. Someone else may have advice about that, however.
> Best wishes,
> Malcolm
>
>
> On 16 November 2015 at 16:07, Simone <miseno77 at hotmail.com> wrote:
>
> > Dear Malcolm,
> >
> > Thank you so much for your detailed (very interesting references!) and
> > helpful answer. I have centered Var2 by IND and I have used both the
> > individual-specific mean Var2 (Var2meanIND) as well as the
> > individual-specific centered Var2 (Var2varIND). I understand that this
> way
> > I can test if the variation among individuals (first case) or within them
> > (second case) relate to the response variable.
> >
> > As you suspected, DATEs are often close each other and it is quite
> > probable I have autocorrelated data. You mentioned that the nlme package
> > handles correlated residuals and I have found the code to do that but the
> > problem is that I cannot do it for my case study since the distribution I
> > am using is a binomial and nlme is only for linear mixed model, isn?it?
> >
> > For now, I have being using the below syntax and using LRT (anova)
> between
> > reduced nested models to compute the p-value for each predictor. I know
> > that LRT is very criticized but I have been asked to calculate p-values
> for
> > each predictor.
> >
> >
> > Mod1<-glmer(Var1 ~ SEX + AGE + Var2meanIND + Var2varIND + (1|DATE) +
> > (1|IND) , data = mydata, family = binomial, control =
> > glmerControl(optimizer="bobyqa"))
> >
> >
> > This way I am not accounting at all for the autocorrelation, do you have
> > any suggestions?
> > Thanks again,
> >
> > Simone
> >
> > ------------------------------
> > Date: Sun, 15 Nov 2015 16:41:28 +0100
> > Subject: Re: [R-sig-ME] glmer random effects structure: a case
> > From: M.Fairbrother at bristol.ac.uk
> > To: miseno77 at hotmail.com
> > CC: r-sig-mixed-models at r-project.org
> >
> >
> > Dear Simone,
> > How many INDs and DATEs are in your dataset? It sounds like you have
> > plenty of INDs, but it's less clear how many DATEs you have. If you have
> a
> > lot, you may have a situation of cross-classification: observations are
> > nested both in INDs and DATEs, but neither of those is nested in the
> either.
> > If you don't have many DATEs, it will make more sense to use fixed
> effects
> > for those. And even if you have a lot, if the DATEs are located close to
> > each other in time, you may have a lot of autocorrelation, and that
> > requires other techniques. (In R, you may need to use the older package
> > nlme, which allows for correlated residuals.)
> > In any event, if INDs are in many cases captured on multiple DATEs, it
> > definitely doesn't make sense to nest INDs in DATEs. Clearly they aren't
> > nested. (Assuming I've understood your data structure correctly.)
> > It also sounds like you should be centering Var2 by IND. This is pretty
> > much de rigueur in multilevel models with x variables that vary within
> > clusters. Enders and Tofighi 2007 is a useful, clear paper on this issue,
> > and you might also want to look at these recent papers by me and
> colleagues
> > in the Centre for Multilevel Modelling at Bristol:
> > doi:10.1017/psrm.2014.7
> > doi:10.1017/psrm.2013.24
> > Basically, take the mean of Var2 for each individual, and enter that as a
> > covariate. Then take the difference between the original Var2 and its
> mean
> > for that individual, and enter that as a covariate as well. You'll get
> two
> > pieces of information in your fitted model: the distinct "between" and
> > "within" effects of Var2. It sounds like that is what you want.
> > Hope that's useful.
> > - Malcolm
> >
> >
> >
> > Date: Sat, 14 Nov 2015 17:48:46 +0100
> > From: Simone <miseno77 at hotmail.com>
> > Cc: "r-sig-mixed-models at r-project.org"
> >         <r-sig-mixed-models at r-project.org>
> > Subject: [R-sig-ME] glmer random effects structure: a case
> >
> >
> > Hi all,
> > I have a simple (but not that simple to me) question on how to specify
> the
> > random structure in R.A binary response variable (Var1) has been measured
> > from a number of individuals (IND) that have been susceptible of being
> > captured over a number of dates (DATE). I suspect that Var1 might depend
> > either on its sex (SEX), or age (AGE) or Var2 which is a continuous
> > variable measured from each individual every time it is captured. Since
> > Var2 is a measure of the quality of each individual, it is likely that
> some
> > individuals will tend to have greater values of Var2 than others during
> the
> > entire study period.Note that some individuals have been captured only
> one
> > time, other two, other three and so on (very unbalanced). For each date
> an
> > individual can be captured only one time.So, I have two groups: IND and
> > DATE. I would think this is a two-level model with IND nested to DATE so
> > that:
> > model1 <- glmer(Var1 ~ SEX + AGE + Var2 + (1|DATE/IND), family =
> binomial,
> > data = mydata)
> > Does it make sense? I think i am not taking into account the fact that
> the
> > mean of Var2 may be different among individuals but I don't know how to
> do
> > that.I would really appreciate an answer to this question that I am sure
> > would help me a lot to understand better how mixed models work.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Nov 17 11:17:40 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Nov 2015 11:17:40 +0100
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <39a421ccfeff439e94a1cd5fac6fe803@ITGSRV017.itg.be>
References: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
	<CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>
	<29f8a487b50948c1a4aad2108c614c8f@ITGSRV017.itg.be>
	<CAJuCY5x7bE3QT3rA97mnJWG2-Ui1HMKHN-aLCt2459bHuiQOzA@mail.gmail.com>
	<39a421ccfeff439e94a1cd5fac6fe803@ITGSRV017.itg.be>
Message-ID: <CAJuCY5wwohN1e158gi70pdbxPtWVHBqK+O5cn6L3cJUDF0CPow@mail.gmail.com>

Dear Veronique,

This is helpful. It looks like the small number of villages is the problem.
If the animals stay within one village you could try if explicitly nesting
them helps (1|village/animal) instead of (1|village) + (1|animal). It's a
wild guess and I don't expect it to work. A crossed random effect like
(1|village) + (1|animal) with unique id's for each animal is an implicit
nested random effect. Hence (1|village/animal) should be the same model as
(1|village) + (1|animal). But if it does work, please let us know.

Other options:
- try to supply starting values
- add village to the fixed effects
- simply removing village from the model
- look for a Bayesian solution (e.g. INLA)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-17 10:51 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:

> Dear Thierry,
>
>
>
> I don?t know if the following would already be helpful?
>
> 193 animals over 3 treatments and 6 villages (2 villages/treatment;
> variable amount of animals/village: 29-35), with observations on 5
> timepoints.
>
> There is no error message when I remove ?(1|Animal)+(1|Village)? or only ?
> +(1|Village)?.
>
> So I am assuming there is something wrong with the random effect of
> village, correct?
> Based on my data, I assume that I need a model with the animal nested in
> village (and now I am doubting this +(1|Animal)+(1|Village) is the right
> way to attain this (even though I had found this approach for a nested term
> online)).
>
>
>
> Best regards,
>
> Veronique.
>
>
>
>
>
> *From:* Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> *Sent:* dinsdag 17 november 2015 10:33
>
> *To:* Veronique Dermauw
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] glmmADMB
>
>
>
> Dear Veronique,
>
>
>
> We need more information. How many animals, villages, treatments,
> timepoints, ...? How many observations per animal and per village? Can you
> post the data or send it offline?
>
>
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
> 2015-11-17 10:09 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:
>
> Dear Thierry,
>
>
>
> Thank you for your response and advice.
>
> I?ve omitted missing values (94 out of 965), but I am getting another
> error message, see below:
>
> > cambNA<-na.omit(camb)
>
> >
> mod1b<-glmmadmb(GIS~Treatment*Time+(1|Animal)+(1|Village),family="nbinom",data=cambNA)
>
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
>
> Error in glmmadmb(GIS ~ Treatment * Time + (1 | Animal) +  :
>
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
>
> In addition: Warning message:
>
> running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
> 5 -noinit -shess' had status 1
>
>
>
> Thank you for your help,
>
> Best regards,
>
> Veronique Dermauw.
>
>
>
> *From:* Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> *Sent:* donderdag 12 november 2015 17:44
> *To:* Veronique Dermauw
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] glmmADMB
>
>
>
> Dear Veronique,
>
>
>
> It looks like your data contains missing values. Try to remove them. Your
> syntax seems to be correct.
>
>
>
> Note that Treatment + Time + Time * Treatment can be abbreviated to Time
> * Treatment
>
>
>
> Best regards,
>
>
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
> 2015-11-11 12:17 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:
>
> Dear,
>
> Recently I have been working on a dataset which seems to require a
> generalized linear mixed model with a negative binomial distribution.
> I came across the glmmADMB package which seems ideal.
> However, I am a bit stuck here (see codes and error message below).
> The dataset I am working on, involves count variables (GIS) from animals
> from different villages who were allocated a treatment (Treatment) and were
> sampled at various Time point (hence Time and Time*Treatment).
> I was wondering if you could assist me with this command?
>
> Many thanks for your response,
> Best regards,
> Veronique Dermauw.
>
>
> mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
> summary(mod1b)
> Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
>   number of items to replace is not a multiple of replacement length
> In addition: Warning messages:
> 1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +
> :
>   NAs removed in constructing fixed-effect model frame: you should
> probably remove them manually, e.g. with na.omit()
> 2: In II[, ii] + REmat$codes[[i]] :
>   longer object length is not a multiple of shorter object length
>
>
> Veronique Dermauw
> PhD, MSc Veterinary Medicine
> Institute of Tropical Medicine
> Nationalestraat 155
> 2000 Antwerp
> +32(0)32476447
>
>
> P Please consider the environment before printing this e-mail
>
> Disclaimer: Http://www.itg.be/disclaimer
>
> Directions to our location(s): http://g.co/maps/ua89b
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Tue Nov 17 11:23:58 2015
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Tue, 17 Nov 2015 11:23:58 +0100
Subject: [R-sig-ME] calculation of confidence intervals for random slope
	model
In-Reply-To: <ADCAD56B-DF62-44C2-81B1-6BDC16125789@zoo.ox.ac.uk>
References: <ADCAD56B-DF62-44C2-81B1-6BDC16125789@zoo.ox.ac.uk>
Message-ID: <CAGoSky85GGh4Ai4XQwxEgZ0kCFc=-o0rCRxN5wDXiRvsbRze9A@mail.gmail.com>

You may use Bayesian (MCMC) model fitting procedures to get what you want.
With the brms package you may do the following (using the sleepstudy
example):

# load packages
library(lme4)
library(brms)

# fit the sample model
fm1 <- brm(Reaction ~ Days + (Days|Subject), data = sleepstudy)

# get the desired CI for you first Subject
# the 1 in "r_Subject[1,2]" indicates that you look at the first Subject
# the 2 in "r_Subject[1,2]" indicates that you look at the second random
effect
# (random intercept is the 1st, random slope of Days is the 2nd random
effect)
hypothesis(fm1, "b_Days + r_Subject[1,2] = 0", class = NULL)

# write the hypotheses for all subjects at once
subject_numbers <- 1:length(unique(sleepstudy$Subject))
hyp <- paste0("b_Days + r_Subject[", subject_numbers, ",2] = 0")

# get desired CIs for all subjects
hypothesis(fm1, hyp, class = NULL)


The code above will only work with the github version of brms to be
installed via
devtools::install_github("paul-buerkner/brms")

Since brms is based on Stan, you will need a C++ compiler to get it
working.
Further information can be found at the bottom of the Readme at
https://github.com/paul-buerkner/brms

2015-11-16 11:56 GMT+01:00 Henry Travers <henry.travers at zoo.ox.ac.uk>:

> I have what I hope is a relatively straightforward question about how to
> interpret the results of a mixed effects model of the form:
>
> fm1 <- lmer(Reaction ~ Days + (Days | Subject))
>
> I am running an experiment such that I am most interested in the
> (equivalent of the) effect of Days for each Subject, rather than say fitted
> values. I understand how to derive the point estimates for this effect, but
> I am struggling to see how to calculate confidence intervals for these
> estimates that take account of both the standard error in the parameter
> estimate for Days and the uncertainty in the corresponding slope estimates
> for each Subject.
>
> I would be very grateful if someone could point me in the right direction
> or to a suitable reference.
>
> ------------------------------------------------
> Henry Travers, PhD
> Research Associate
>
> Interdisciplinary Centre for Conservation Science
> Department of Zoology
> University of Oxford
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Nov 17 11:53:00 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Nov 2015 11:53:00 +0100
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <b87b8c383dcf40bc99efb801aad54b68@ITGSRV017.itg.be>
References: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
	<CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>
	<29f8a487b50948c1a4aad2108c614c8f@ITGSRV017.itg.be>
	<CAJuCY5x7bE3QT3rA97mnJWG2-Ui1HMKHN-aLCt2459bHuiQOzA@mail.gmail.com>
	<39a421ccfeff439e94a1cd5fac6fe803@ITGSRV017.itg.be>
	<CAJuCY5wwohN1e158gi70pdbxPtWVHBqK+O5cn6L3cJUDF0CPow@mail.gmail.com>
	<b87b8c383dcf40bc99efb801aad54b68@ITGSRV017.itg.be>
Message-ID: <CAJuCY5z1G7acy5kb6Geock8yhd=2uDDJRQU4_Q0W2JiJB8YrZA@mail.gmail.com>

Dear Veronique,

Have a look at http://glmm.wikidot.com/faq and look for "Should I treat
factor xxx as fixed or random?"

I agree that village is a random effect from a theoretical point of view.
That would help you much if the model won't fit because of the low number
of levels. Omitting village from the model is probably the safest work
around. I expect minimal influence on the fixed effects parameters. The
random effects of animals will be probably large to capture the village
effects.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-17 11:40 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:

> Dear Thierry,
>
>
>
> Many thanks for your help.
>
> The animals do have an unique id number, so your expectations were correct
> and unfortunately the same error message popped up.
>
> With regards to your options, I am wondering if it is correct to insert
> village as fixed effect or completely omit it, it feels quite
> counterintuitive.
>
> I have no experience with the other two options, but will try to dig into
> it. If I encounter any additional questions, I will let you know.
>
>
>
> Thank you again,
>
> Best regards,
>
> Veronique Dermauw.
>
>
>
>
>
> *From:* Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> *Sent:* dinsdag 17 november 2015 11:18
>
> *To:* Veronique Dermauw
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] glmmADMB
>
>
>
> Dear Veronique,
>
>
>
> This is helpful. It looks like the small number of villages is the
> problem. If the animals stay within one village you could try if explicitly
> nesting them helps (1|village/animal) instead of (1|village) + (1|animal).
> It's a wild guess and I don't expect it to work. A crossed random effect
> like (1|village) + (1|animal) with unique id's for each animal is an
> implicit nested random effect. Hence (1|village/animal) should be the same
> model as (1|village) + (1|animal). But if it does work, please let us know.
>
>
>
> Other options:
>
> - try to supply starting values
>
> - add village to the fixed effects
>
> - simply removing village from the model
>
> - look for a Bayesian solution (e.g. INLA)
>
>
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
> 2015-11-17 10:51 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:
>
> Dear Thierry,
>
>
>
> I don?t know if the following would already be helpful?
>
> 193 animals over 3 treatments and 6 villages (2 villages/treatment;
> variable amount of animals/village: 29-35), with observations on 5
> timepoints.
>
> There is no error message when I remove ?(1|Animal)+(1|Village)? or only ?
> +(1|Village)?.
>
> So I am assuming there is something wrong with the random effect of
> village, correct?
> Based on my data, I assume that I need a model with the animal nested in
> village (and now I am doubting this +(1|Animal)+(1|Village) is the right
> way to attain this (even though I had found this approach for a nested term
> online)).
>
>
>
> Best regards,
>
> Veronique.
>
>
>
>
>
> *From:* Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> *Sent:* dinsdag 17 november 2015 10:33
>
>
> *To:* Veronique Dermauw
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] glmmADMB
>
>
>
> Dear Veronique,
>
>
>
> We need more information. How many animals, villages, treatments,
> timepoints, ...? How many observations per animal and per village? Can you
> post the data or send it offline?
>
>
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
> 2015-11-17 10:09 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:
>
> Dear Thierry,
>
>
>
> Thank you for your response and advice.
>
> I?ve omitted missing values (94 out of 965), but I am getting another
> error message, see below:
>
> > cambNA<-na.omit(camb)
>
> >
> mod1b<-glmmadmb(GIS~Treatment*Time+(1|Animal)+(1|Village),family="nbinom",data=cambNA)
>
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
>
> Error in glmmadmb(GIS ~ Treatment * Time + (1 | Animal) +  :
>
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
>
> In addition: Warning message:
>
> running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
> 5 -noinit -shess' had status 1
>
>
>
> Thank you for your help,
>
> Best regards,
>
> Veronique Dermauw.
>
>
>
> *From:* Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> *Sent:* donderdag 12 november 2015 17:44
> *To:* Veronique Dermauw
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] glmmADMB
>
>
>
> Dear Veronique,
>
>
>
> It looks like your data contains missing values. Try to remove them. Your
> syntax seems to be correct.
>
>
>
> Note that Treatment + Time + Time * Treatment can be abbreviated to Time
> * Treatment
>
>
>
> Best regards,
>
>
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
> 2015-11-11 12:17 GMT+01:00 Veronique Dermauw <vdermauw at itg.be>:
>
> Dear,
>
> Recently I have been working on a dataset which seems to require a
> generalized linear mixed model with a negative binomial distribution.
> I came across the glmmADMB package which seems ideal.
> However, I am a bit stuck here (see codes and error message below).
> The dataset I am working on, involves count variables (GIS) from animals
> from different villages who were allocated a treatment (Treatment) and were
> sampled at various Time point (hence Time and Time*Treatment).
> I was wondering if you could assist me with this command?
>
> Many thanks for your response,
> Best regards,
> Veronique Dermauw.
>
>
> mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
> summary(mod1b)
> Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
>   number of items to replace is not a multiple of replacement length
> In addition: Warning messages:
> 1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +
> :
>   NAs removed in constructing fixed-effect model frame: you should
> probably remove them manually, e.g. with na.omit()
> 2: In II[, ii] + REmat$codes[[i]] :
>   longer object length is not a multiple of shorter object length
>
>
> Veronique Dermauw
> PhD, MSc Veterinary Medicine
> Institute of Tropical Medicine
> Nationalestraat 155
> 2000 Antwerp
> +32(0)32476447
>
>
> P Please consider the environment before printing this e-mail
>
> Disclaimer: Http://www.itg.be/disclaimer
>
> Directions to our location(s): http://g.co/maps/ua89b
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From emmanuel.curis at parisdescartes.fr  Tue Nov 17 13:36:26 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Tue, 17 Nov 2015 13:36:26 +0100
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <alpine.LMD.2.00.1511151123290.25288@orpheus.qimr.edu.au>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
	<alpine.LMD.2.00.1511151123290.25288@orpheus.qimr.edu.au>
Message-ID: <20151117123626.GB1118@info124.pharmacie.univ-paris5.fr>

Dear David,

Thank you for the clarification and pointing out these R packages. We
will dig into this...

Best regards,

On Sun, Nov 15, 2015 at 11:59:31AM +1000, David Duffy wrote:
? On Fri, 13 Nov 2015, Thierry Onkelinx wrote:
? 
? >Maybe a survival analysis is more appropriate for that kind of data.
? >>
? >>Detailed version: our data consist of daily status of a set of
? >>patients, the status being ? Infected ? or ? Not infected ?, during a
? >>variable period of time. The aim is to see what changes the infection
? >>probability.
? 
? As Thierry suggested, this type of dataset (incidence of infection) can be
? modelled as a recurrent events survival analysis.  These can be represented
? as in a discrete time framework as a poisson GLMM, or as Cox or parametric
? mixed effects survival models. One example might be various analyses of the
? "kidney" dataset of McGilchrist and Aisbett that is included in the BUGS
? manual. In R as:
? 
? brms::kidney            Infections in kidney patients
? frailtyHL::kidney       Kidney Infection Data
? INLA::Kidney            Kidney infection data
? survival::kidney
? 
? The Markovian model appears in bivariate survival analyses covering time to
? infection and time to recovery - each may have different relevant risk
? factors - the random effect (frailty) for each individual links them
? together appropriately. You will probably also want time varying covariates.
? 
? Cheers, David Duffy.
? 
? 
? | David Duffy (MBBS PhD)
? | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
? | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
? | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From emmanuel.curis at parisdescartes.fr  Tue Nov 17 13:43:11 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Tue, 17 Nov 2015 13:43:11 +0100
Subject: [R-sig-ME] Question on random effects glm interpretation
In-Reply-To: <5646516C.9020201@gmail.com>
References: <20151112171248.GB19266@info124.pharmacie.univ-paris5.fr>
	<CAJuCY5wtyL1dmeV=ZQGPgHCF0gtBuWV3HmoaHp+gJHpAmgL16A@mail.gmail.com>
	<20151113134149.GA5291@info124.pharmacie.univ-paris5.fr>
	<564608E1.4070304@gmail.com>
	<20151113163255.GB10987@info124.pharmacie.univ-paris5.fr>
	<5646516C.9020201@gmail.com>
Message-ID: <20151117124311.GC1118@info124.pharmacie.univ-paris5.fr>

Dear Ben,

Thank you for these clarifications, and recalling in mind the problem
of independance between individuals in such contexts. We will going
back to the writing of these models to see exactly how to answer the
question using each of them...

Best regards,

On Fri, Nov 13, 2015 at 04:09:00PM -0500, Ben Bolker wrote:
? On 15-11-13 11:32 AM, Emmanuel Curis wrote:
? > Thanks for these answers.
? > 
? > After thinking a little bit, I still have a concern with the
? > survival approach.  What is in interest in the data is not really
? > the time before patients are infected (at least, as far as I
? > understood the practicionners problem), but the proportion of
? > patients that are infected at a given moment (and, at the end, does
? > this proportion change with some covariates, including period in
? > the year). I'm not clear how the survival model can give this
? > information (but I'm not familiar with survival analysis), but I
? > thought it was more oriented toward modeling time-to-event?
? 
?   Well, these are really just different representations of the same
? information.  In a canned statistical formulation (e.g. GLMM *or*
? survival analysis), it's easier to deal with the constraint that
? individuals are represented by a string of 0s followed by a string of
? 1s in the time-to-event framework.
? 
?   Given a cohort of individuals, one could construct predictions for
? the expected number infected at a given time from the results of a
? survival analysis (although might be easiest to do via stochastic
? simulation).
? 
?   The assumption of independence of the individuals also breaks down
? for infectious disease, unless the population is large enough that you
? can assume randomly sampled individuals/neglect the effect of
? infection status of some individuals on others' probability of
? becoming infected ...
? 
? > Also, going back to the original question, for my own understanding
? > of these models: is it correct to say that for a binomial GLMM to
? > apply, with patient as the (only) random effect, then for a given
? > patient the different Bernoulli variables must be independant,
? > identically distributed as in a usual logistic regression? Or is
? > this hierarchical approach too simplist?
? 
?   I think that's correct, extending your conditions slightly to say
? that the variables are conditionally iid given both the identity of
? the individual (latent variable) and any applicable
? (time/patient-specific) fixed effects.

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From jbukoski1 at gmail.com  Wed Nov 18 17:34:29 2015
From: jbukoski1 at gmail.com (Jacob Bukoski)
Date: Wed, 18 Nov 2015 11:34:29 -0500
Subject: [R-sig-ME] Standard errors of group-wise random effect intercepts
Message-ID: <CAOES0Vg-TWQfEWbiK-YoXbzN_wP+6JNWLuOHjB7nnBbwhAdXfg@mail.gmail.com>

Hi all,

I might be searching for something that doesn't exist -- but is there a way
to obtain group-specific standard errors for random effect intercept
estimates?

I have hierarchical data grouped by "site," for which I've generated unique
intercept coefficients. For example:

$random$Site
          (Intercept)
ab      -9.574204
am     -9.149834
ay      -2.238734
br        5.073831
...

Is there a way to extract some sort of confidence interval on these values?
I have attempted using VarCorr(), but am having trouble getting it to
return a standard error beyond that of the standard error across *all* site
intercept estimates.

If it helps, my model is specified as:

lme1 <- lme(Biomass ~ Basal.area*Latitude - Latitude -1,
            random = ~1|Site, method="REML")

?Many kind thanks,
Jacob?

-- 
Jacob J. Bukoski
Master of Environmental Science Candidate, 2016
School of Forestry and Environmental Studies, Yale University
jbukoski1 at gmail.com | jacob.bukoski at yale.edu | LinkedIn
<https://www.linkedin.com/profile/view?id=AAIAAAdWVW8BMzqU_2EGNbEkyuy8O7K1Jyhd8ps&trk=nav_responsive_tab_profile_pic>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Nov 18 17:46:22 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 18 Nov 2015 17:46:22 +0100
Subject: [R-sig-ME] Standard errors of group-wise random effect
	intercepts
In-Reply-To: <CAOES0Vg-TWQfEWbiK-YoXbzN_wP+6JNWLuOHjB7nnBbwhAdXfg@mail.gmail.com>
References: <CAOES0Vg-TWQfEWbiK-YoXbzN_wP+6JNWLuOHjB7nnBbwhAdXfg@mail.gmail.com>
Message-ID: <CAJuCY5x77hySZRp37BM8MCzcpeqqwudyZD28UoX2ugvt8JnfVg@mail.gmail.com>

Dear Jacob,

If you are willing to which to lme4, then you can use ranef(lme1, condVar =
TRUE). See its helpfile for the details.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-18 17:34 GMT+01:00 Jacob Bukoski <jbukoski1 at gmail.com>:

> Hi all,
>
> I might be searching for something that doesn't exist -- but is there a way
> to obtain group-specific standard errors for random effect intercept
> estimates?
>
> I have hierarchical data grouped by "site," for which I've generated unique
> intercept coefficients. For example:
>
> $random$Site
>           (Intercept)
> ab      -9.574204
> am     -9.149834
> ay      -2.238734
> br        5.073831
> ...
>
> Is there a way to extract some sort of confidence interval on these values?
> I have attempted using VarCorr(), but am having trouble getting it to
> return a standard error beyond that of the standard error across *all* site
> intercept estimates.
>
> If it helps, my model is specified as:
>
> lme1 <- lme(Biomass ~ Basal.area*Latitude - Latitude -1,
>             random = ~1|Site, method="REML")
>
> ?Many kind thanks,
> Jacob?
>
> --
> Jacob J. Bukoski
> Master of Environmental Science Candidate, 2016
> School of Forestry and Environmental Studies, Yale University
> jbukoski1 at gmail.com | jacob.bukoski at yale.edu | LinkedIn
> <
> https://www.linkedin.com/profile/view?id=AAIAAAdWVW8BMzqU_2EGNbEkyuy8O7K1Jyhd8ps&trk=nav_responsive_tab_profile_pic
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From jbukoski1 at gmail.com  Wed Nov 18 18:12:14 2015
From: jbukoski1 at gmail.com (Jacob Bukoski)
Date: Wed, 18 Nov 2015 12:12:14 -0500
Subject: [R-sig-ME] Standard errors of group-wise random effect
	intercepts
In-Reply-To: <CAJuCY5x77hySZRp37BM8MCzcpeqqwudyZD28UoX2ugvt8JnfVg@mail.gmail.com>
References: <CAOES0Vg-TWQfEWbiK-YoXbzN_wP+6JNWLuOHjB7nnBbwhAdXfg@mail.gmail.com>
	<CAJuCY5x77hySZRp37BM8MCzcpeqqwudyZD28UoX2ugvt8JnfVg@mail.gmail.com>
Message-ID: <CAOES0VjJWsfxoOhqdq7P041=w-HAAtu-DP4WVGv0T8X-Fiut-w@mail.gmail.com>

Hi Thierry,

Your suggestion is very helpful. Thanks!

Jacob

On Wed, Nov 18, 2015 at 11:46 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Jacob,
>
> If you are willing to which to lme4, then you can use ranef(lme1, condVar
> = TRUE). See its helpfile for the details.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-11-18 17:34 GMT+01:00 Jacob Bukoski <jbukoski1 at gmail.com>:
>
>> Hi all,
>>
>> I might be searching for something that doesn't exist -- but is there a
>> way
>> to obtain group-specific standard errors for random effect intercept
>> estimates?
>>
>> I have hierarchical data grouped by "site," for which I've generated
>> unique
>> intercept coefficients. For example:
>>
>> $random$Site
>>           (Intercept)
>> ab      -9.574204
>> am     -9.149834
>> ay      -2.238734
>> br        5.073831
>> ...
>>
>> Is there a way to extract some sort of confidence interval on these
>> values?
>> I have attempted using VarCorr(), but am having trouble getting it to
>> return a standard error beyond that of the standard error across *all*
>> site
>> intercept estimates.
>>
>> If it helps, my model is specified as:
>>
>> lme1 <- lme(Biomass ~ Basal.area*Latitude - Latitude -1,
>>             random = ~1|Site, method="REML")
>>
>> ?Many kind thanks,
>> Jacob?
>>
>> --
>> Jacob J. Bukoski
>> Master of Environmental Science Candidate, 2016
>> School of Forestry and Environmental Studies, Yale University
>> jbukoski1 at gmail.com | jacob.bukoski at yale.edu | LinkedIn
>> <
>> https://www.linkedin.com/profile/view?id=AAIAAAdWVW8BMzqU_2EGNbEkyuy8O7K1Jyhd8ps&trk=nav_responsive_tab_profile_pic
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 
Jacob J. Bukoski
Master of Environmental Science Candidate, 2016
School of Forestry and Environmental Studies, Yale University
jbukoski1 at gmail.com | jacob.bukoski at yale.edu | LinkedIn
<https://www.linkedin.com/profile/view?id=AAIAAAdWVW8BMzqU_2EGNbEkyuy8O7K1Jyhd8ps&trk=nav_responsive_tab_profile_pic>

	[[alternative HTML version deleted]]


From anne.overgaard at bios.au.dk  Thu Nov 19 12:42:42 2015
From: anne.overgaard at bios.au.dk (Anne Blach Overgaard)
Date: Thu, 19 Nov 2015 11:42:42 +0000
Subject: [R-sig-ME] Data structure issue for GLMM models
Message-ID: <dbc06d866a0241e183ff45530147d3cc@Exch16.uni.au.dk>


Dear List,
I hope that some of you may be able to help us with a data structure issue.
We have collected plant cover data (count data) for selected species along a climatic gradient in random stratified sampling plots. The hierarchical structure of the data is as follows:
We have sampled at five sites placed along a large-scale climatic gradient. Within each of the five sites we placed three plot groups 500 meters apart on each of the altitudes 20 m 100, 200, 300, 400 and 500 m above sea level, whenever possible, as not all isoclines were present at each site. Each plot group consisted of six plots that were placed 10 meters apart.
In total we have 5 sites x a varying number of altitudes per site x 3 plot groups per altitude x 6 plots = 414 plots in the entire data set.
Overall we would like to assess the relative importance of different predictor groups (altitude, climate, and biotic interactions) on the variation in cover per species. We are including the predictor groups as fixed effects in our models using lme4::glmer (family = poisson). We include site and plot group as nested random effects and plots as an observation-level random factor due to overdispersion in the data.
Our question is whether altitude should be entered as a random factor, as a fixed effect, or possibly as both a fixed and a random effect. Altitude is a part of the nested structure of the data, but we also have an interest in including it as a fixed effect to assess how much of the variation in the data is due to altitude.
We hope that some of you can guide us how to deal with altitude in this data analysis.
Thanking you in advance.
Best regards,
Anne & co-workers





	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Thu Nov 19 23:14:50 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 19 Nov 2015 22:14:50 +0000
Subject: [R-sig-ME] An RPubs document on lmer/lmm with 1 M observations
Message-ID: <CAO7JsnT+wrGXWRsM9pVPW80xYGwahFC4OHvYSvS9_LYU4Vw+cA@mail.gmail.com>

http://rpubs.com/dmbates/movielens

	[[alternative HTML version deleted]]


From m51988mnew at juno.com  Wed Nov 18 03:25:03 2015
From: m51988mnew at juno.com (m51988mnew at juno.com)
Date: Wed, 18 Nov 2015 02:25:03 GMT
Subject: [R-sig-ME] question about Type III sums of squares as computed in
	"CAR'
Message-ID: <20151117.212503.24792.0@webmail03.dca.untd.com>

When I use "Anova" from the car library, I cannot get Type III sums of
 squares for nested data.  Maybe I am using the program wrong. SAS gives the
 Type III sums of squares. Thanks for any thoughts.Stanley Shulman

____________________________________________________________
NetZero now offers 4G mobile broadband. Sign up now.
http://www.netzero.net/?refcd=NZINTISP0512T4GOUT1

	[[alternative HTML version deleted]]


From vdermauw at itg.be  Tue Nov 17 10:09:38 2015
From: vdermauw at itg.be (Veronique Dermauw)
Date: Tue, 17 Nov 2015 09:09:38 +0000
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>
References: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
	<CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>
Message-ID: <29f8a487b50948c1a4aad2108c614c8f@ITGSRV017.itg.be>

Dear Thierry,

Thank you for your response and advice.
I?ve omitted missing values (94 out of 965), but I am getting another error message, see below:
> cambNA<-na.omit(camb)
> mod1b<-glmmadmb(GIS~Treatment*Time+(1|Animal)+(1|Village),family="nbinom",data=cambNA)
Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(GIS ~ Treatment * Time + (1 | Animal) +  :
  The function maximizer failed (couldn't find parameter file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl';(3) re-run with debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1

Thank you for your help,
Best regards,
Veronique Dermauw.

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: donderdag 12 november 2015 17:44
To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

It looks like your data contains missing values. Try to remove them. Your syntax seems to be correct.

Note that Treatment + Time + Time * Treatment can be abbreviated to Time * Treatment

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-11 12:17 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear,

Recently I have been working on a dataset which seems to require a generalized linear mixed model with a negative binomial distribution.
I came across the glmmADMB package which seems ideal.
However, I am a bit stuck here (see codes and error message below).
The dataset I am working on, involves count variables (GIS) from animals from different villages who were allocated a treatment (Treatment) and were sampled at various Time point (hence Time and Time*Treatment).
I was wondering if you could assist me with this command?

Many thanks for your response,
Best regards,
Veronique Dermauw.

mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
summary(mod1b)
Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
  number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +  :
  NAs removed in constructing fixed-effect model frame: you should probably remove them manually, e.g. with na.omit()
2: In II[, ii] + REmat$codes[[i]] :
  longer object length is not a multiple of shorter object length


Veronique Dermauw
PhD, MSc Veterinary Medicine
Institute of Tropical Medicine
Nationalestraat 155
2000 Antwerp
+32(0)32476447


P Please consider the environment before printing this e-mail

Disclaimer: Http://www.itg.be/disclaimer

Directions to our location(s): http://g.co/maps/ua89b

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From vdermauw at itg.be  Tue Nov 17 10:51:55 2015
From: vdermauw at itg.be (Veronique Dermauw)
Date: Tue, 17 Nov 2015 09:51:55 +0000
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <CAJuCY5x7bE3QT3rA97mnJWG2-Ui1HMKHN-aLCt2459bHuiQOzA@mail.gmail.com>
References: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
	<CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>
	<29f8a487b50948c1a4aad2108c614c8f@ITGSRV017.itg.be>
	<CAJuCY5x7bE3QT3rA97mnJWG2-Ui1HMKHN-aLCt2459bHuiQOzA@mail.gmail.com>
Message-ID: <39a421ccfeff439e94a1cd5fac6fe803@ITGSRV017.itg.be>

Dear Thierry,

I don?t know if the following would already be helpful?
193 animals over 3 treatments and 6 villages (2 villages/treatment; variable amount of animals/village: 29-35), with observations on 5 timepoints.
There is no error message when I remove ?(1|Animal)+(1|Village)? or only ?+(1|Village)?.
So I am assuming there is something wrong with the random effect of village, correct?
Based on my data, I assume that I need a model with the animal nested in village (and now I am doubting this +(1|Animal)+(1|Village) is the right way to attain this (even though I had found this approach for a nested term online)).

Best regards,
Veronique.


From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: dinsdag 17 november 2015 10:33
To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

We need more information. How many animals, villages, treatments, timepoints, ...? How many observations per animal and per village? Can you post the data or send it offline?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-17 10:09 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear Thierry,

Thank you for your response and advice.
I?ve omitted missing values (94 out of 965), but I am getting another error message, see below:
> cambNA<-na.omit(camb)
> mod1b<-glmmadmb(GIS~Treatment*Time+(1|Animal)+(1|Village),family="nbinom",data=cambNA)
Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(GIS ~ Treatment * Time + (1 | Animal) +  :
  The function maximizer failed (couldn't find parameter file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl';(3) re-run with debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1

Thank you for your help,
Best regards,
Veronique Dermauw.

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>]
Sent: donderdag 12 november 2015 17:44
To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

It looks like your data contains missing values. Try to remove them. Your syntax seems to be correct.

Note that Treatment + Time + Time * Treatment can be abbreviated to Time * Treatment

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-11 12:17 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear,

Recently I have been working on a dataset which seems to require a generalized linear mixed model with a negative binomial distribution.
I came across the glmmADMB package which seems ideal.
However, I am a bit stuck here (see codes and error message below).
The dataset I am working on, involves count variables (GIS) from animals from different villages who were allocated a treatment (Treatment) and were sampled at various Time point (hence Time and Time*Treatment).
I was wondering if you could assist me with this command?

Many thanks for your response,
Best regards,
Veronique Dermauw.

mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
summary(mod1b)
Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
  number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +  :
  NAs removed in constructing fixed-effect model frame: you should probably remove them manually, e.g. with na.omit()
2: In II[, ii] + REmat$codes[[i]] :
  longer object length is not a multiple of shorter object length


Veronique Dermauw
PhD, MSc Veterinary Medicine
Institute of Tropical Medicine
Nationalestraat 155
2000 Antwerp
+32(0)32476447<tel:%2B32%280%2932476447>


P Please consider the environment before printing this e-mail

Disclaimer: Http://www.itg.be/disclaimer

Directions to our location(s): http://g.co/maps/ua89b

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From vdermauw at itg.be  Tue Nov 17 11:40:13 2015
From: vdermauw at itg.be (Veronique Dermauw)
Date: Tue, 17 Nov 2015 10:40:13 +0000
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <CAJuCY5wwohN1e158gi70pdbxPtWVHBqK+O5cn6L3cJUDF0CPow@mail.gmail.com>
References: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
	<CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>
	<29f8a487b50948c1a4aad2108c614c8f@ITGSRV017.itg.be>
	<CAJuCY5x7bE3QT3rA97mnJWG2-Ui1HMKHN-aLCt2459bHuiQOzA@mail.gmail.com>
	<39a421ccfeff439e94a1cd5fac6fe803@ITGSRV017.itg.be>
	<CAJuCY5wwohN1e158gi70pdbxPtWVHBqK+O5cn6L3cJUDF0CPow@mail.gmail.com>
Message-ID: <b87b8c383dcf40bc99efb801aad54b68@ITGSRV017.itg.be>

Dear Thierry,

Many thanks for your help.
The animals do have an unique id number, so your expectations were correct and unfortunately the same error message popped up.
With regards to your options, I am wondering if it is correct to insert village as fixed effect or completely omit it, it feels quite counterintuitive.
I have no experience with the other two options, but will try to dig into it. If I encounter any additional questions, I will let you know.

Thank you again,
Best regards,
Veronique Dermauw.


From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: dinsdag 17 november 2015 11:18
To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

This is helpful. It looks like the small number of villages is the problem. If the animals stay within one village you could try if explicitly nesting them helps (1|village/animal) instead of (1|village) + (1|animal). It's a wild guess and I don't expect it to work. A crossed random effect like (1|village) + (1|animal) with unique id's for each animal is an implicit nested random effect. Hence (1|village/animal) should be the same model as (1|village) + (1|animal). But if it does work, please let us know.

Other options:
- try to supply starting values
- add village to the fixed effects
- simply removing village from the model
- look for a Bayesian solution (e.g. INLA)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-17 10:51 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear Thierry,

I don?t know if the following would already be helpful?
193 animals over 3 treatments and 6 villages (2 villages/treatment; variable amount of animals/village: 29-35), with observations on 5 timepoints.
There is no error message when I remove ?(1|Animal)+(1|Village)? or only ?+(1|Village)?.
So I am assuming there is something wrong with the random effect of village, correct?
Based on my data, I assume that I need a model with the animal nested in village (and now I am doubting this +(1|Animal)+(1|Village) is the right way to attain this (even though I had found this approach for a nested term online)).

Best regards,
Veronique.


From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>]
Sent: dinsdag 17 november 2015 10:33

To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

We need more information. How many animals, villages, treatments, timepoints, ...? How many observations per animal and per village? Can you post the data or send it offline?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-17 10:09 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear Thierry,

Thank you for your response and advice.
I?ve omitted missing values (94 out of 965), but I am getting another error message, see below:
> cambNA<-na.omit(camb)
> mod1b<-glmmadmb(GIS~Treatment*Time+(1|Animal)+(1|Village),family="nbinom",data=cambNA)
Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(GIS ~ Treatment * Time + (1 | Animal) +  :
  The function maximizer failed (couldn't find parameter file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl';(3) re-run with debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1

Thank you for your help,
Best regards,
Veronique Dermauw.

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>]
Sent: donderdag 12 november 2015 17:44
To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

It looks like your data contains missing values. Try to remove them. Your syntax seems to be correct.

Note that Treatment + Time + Time * Treatment can be abbreviated to Time * Treatment

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-11 12:17 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear,

Recently I have been working on a dataset which seems to require a generalized linear mixed model with a negative binomial distribution.
I came across the glmmADMB package which seems ideal.
However, I am a bit stuck here (see codes and error message below).
The dataset I am working on, involves count variables (GIS) from animals from different villages who were allocated a treatment (Treatment) and were sampled at various Time point (hence Time and Time*Treatment).
I was wondering if you could assist me with this command?

Many thanks for your response,
Best regards,
Veronique Dermauw.

mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
summary(mod1b)
Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
  number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +  :
  NAs removed in constructing fixed-effect model frame: you should probably remove them manually, e.g. with na.omit()
2: In II[, ii] + REmat$codes[[i]] :
  longer object length is not a multiple of shorter object length


Veronique Dermauw
PhD, MSc Veterinary Medicine
Institute of Tropical Medicine
Nationalestraat 155
2000 Antwerp
+32(0)32476447<tel:%2B32%280%2932476447>


P Please consider the environment before printing this e-mail

Disclaimer: Http://www.itg.be/disclaimer

Directions to our location(s): http://g.co/maps/ua89b

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




	[[alternative HTML version deleted]]


From vdermauw at itg.be  Tue Nov 17 12:02:42 2015
From: vdermauw at itg.be (Veronique Dermauw)
Date: Tue, 17 Nov 2015 11:02:42 +0000
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <CAJuCY5z1G7acy5kb6Geock8yhd=2uDDJRQU4_Q0W2JiJB8YrZA@mail.gmail.com>
References: <97ab3fa02acc49c5892e858cb9bc2c71@ITGSRV017.itg.be>
	<CAJuCY5wFSm=8rrmtcOH5F7fV_H+S+yDaOK5jyYC=Vt91Z1bx_Q@mail.gmail.com>
	<29f8a487b50948c1a4aad2108c614c8f@ITGSRV017.itg.be>
	<CAJuCY5x7bE3QT3rA97mnJWG2-Ui1HMKHN-aLCt2459bHuiQOzA@mail.gmail.com>
	<39a421ccfeff439e94a1cd5fac6fe803@ITGSRV017.itg.be>
	<CAJuCY5wwohN1e158gi70pdbxPtWVHBqK+O5cn6L3cJUDF0CPow@mail.gmail.com>
	<b87b8c383dcf40bc99efb801aad54b68@ITGSRV017.itg.be>
	<CAJuCY5z1G7acy5kb6Geock8yhd=2uDDJRQU4_Q0W2JiJB8YrZA@mail.gmail.com>
Message-ID: <1cb604282e3a48dd8ddff8fa79f84da2@ITGSRV017.itg.be>

Dear Thierry,

This wikidot page seems quite comprehensive! Thanks a lot!
With regards to the village, I guess I should indeed try to omit it from the model (I agree that it should be the safest option).

Best regards,
Veronique Dermauw.

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: dinsdag 17 november 2015 11:53
To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

Have a look at http://glmm.wikidot.com/faq and look for "Should I treat factor xxx as fixed or random?"

I agree that village is a random effect from a theoretical point of view. That would help you much if the model won't fit because of the low number of levels. Omitting village from the model is probably the safest work around. I expect minimal influence on the fixed effects parameters. The random effects of animals will be probably large to capture the village effects.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-17 11:40 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear Thierry,

Many thanks for your help.
The animals do have an unique id number, so your expectations were correct and unfortunately the same error message popped up.
With regards to your options, I am wondering if it is correct to insert village as fixed effect or completely omit it, it feels quite counterintuitive.
I have no experience with the other two options, but will try to dig into it. If I encounter any additional questions, I will let you know.

Thank you again,
Best regards,
Veronique Dermauw.


From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>]
Sent: dinsdag 17 november 2015 11:18

To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

This is helpful. It looks like the small number of villages is the problem. If the animals stay within one village you could try if explicitly nesting them helps (1|village/animal) instead of (1|village) + (1|animal). It's a wild guess and I don't expect it to work. A crossed random effect like (1|village) + (1|animal) with unique id's for each animal is an implicit nested random effect. Hence (1|village/animal) should be the same model as (1|village) + (1|animal). But if it does work, please let us know.

Other options:
- try to supply starting values
- add village to the fixed effects
- simply removing village from the model
- look for a Bayesian solution (e.g. INLA)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-17 10:51 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear Thierry,

I don?t know if the following would already be helpful?
193 animals over 3 treatments and 6 villages (2 villages/treatment; variable amount of animals/village: 29-35), with observations on 5 timepoints.
There is no error message when I remove ?(1|Animal)+(1|Village)? or only ?+(1|Village)?.
So I am assuming there is something wrong with the random effect of village, correct?
Based on my data, I assume that I need a model with the animal nested in village (and now I am doubting this +(1|Animal)+(1|Village) is the right way to attain this (even though I had found this approach for a nested term online)).

Best regards,
Veronique.


From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>]
Sent: dinsdag 17 november 2015 10:33

To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

We need more information. How many animals, villages, treatments, timepoints, ...? How many observations per animal and per village? Can you post the data or send it offline?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-17 10:09 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear Thierry,

Thank you for your response and advice.
I?ve omitted missing values (94 out of 965), but I am getting another error message, see below:
> cambNA<-na.omit(camb)
> mod1b<-glmmadmb(GIS~Treatment*Time+(1|Animal)+(1|Village),family="nbinom",data=cambNA)
Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(GIS ~ Treatment * Time + (1 | Animal) +  :
  The function maximizer failed (couldn't find parameter file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl';(3) re-run with debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1

Thank you for your help,
Best regards,
Veronique Dermauw.

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>]
Sent: donderdag 12 november 2015 17:44
To: Veronique Dermauw
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmADMB

Dear Veronique,

It looks like your data contains missing values. Try to remove them. Your syntax seems to be correct.

Note that Treatment + Time + Time * Treatment can be abbreviated to Time * Treatment

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-11 12:17 GMT+01:00 Veronique Dermauw <vdermauw at itg.be<mailto:vdermauw at itg.be>>:
Dear,

Recently I have been working on a dataset which seems to require a generalized linear mixed model with a negative binomial distribution.
I came across the glmmADMB package which seems ideal.
However, I am a bit stuck here (see codes and error message below).
The dataset I am working on, involves count variables (GIS) from animals from different villages who were allocated a treatment (Treatment) and were sampled at various Time point (hence Time and Time*Treatment).
I was wondering if you could assist me with this command?

Many thanks for your response,
Best regards,
Veronique Dermauw.

mod1b<-glmmadmb(GIS~Treatment+Time+Time*Treatment+(1|Animal)+(1|Village),family="nbinom",data=camb)
summary(mod1b)
Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
  number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In glmmadmb(GIS ~ Treatment + Time + Time * Treatment + (1 | Animal) +  :
  NAs removed in constructing fixed-effect model frame: you should probably remove them manually, e.g. with na.omit()
2: In II[, ii] + REmat$codes[[i]] :
  longer object length is not a multiple of shorter object length


Veronique Dermauw
PhD, MSc Veterinary Medicine
Institute of Tropical Medicine
Nationalestraat 155
2000 Antwerp
+32(0)32476447<tel:%2B32%280%2932476447>


P Please consider the environment before printing this e-mail

Disclaimer: Http://www.itg.be/disclaimer

Directions to our location(s): http://g.co/maps/ua89b

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models





	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Fri Nov 20 00:17:30 2015
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Thu, 19 Nov 2015 23:17:30 +0000
Subject: [R-sig-ME] question about Type III sums of squares as computed
 in "CAR'
In-Reply-To: <20151117.212503.24792.0@webmail03.dca.untd.com>
References: <20151117.212503.24792.0@webmail03.dca.untd.com>
Message-ID: <1447975125.3062.2.camel@loki>

Can you be more specific about the structure of your data and which
object you're calling car::Anova() on? 

A small reproducible example is best, but details about the structure of
the data and how you calculated the mixed model are an absolute "must".
Perhaps you could include the relevant code snippet? 

Phillip 

On Wed, 2015-11-18 at 02:25 +0000, m51988mnew at juno.com wrote:
> When I use "Anova" from the car library, I cannot get Type III sums of
>  squares for nested data.  Maybe I am using the program wrong. SAS gives the
>  Type III sums of squares. Thanks for any thoughts.Stanley Shulman
> 
> ____________________________________________________________
> NetZero now offers 4G mobile broadband. Sign up now.
> http://www.netzero.net/?refcd=NZINTISP0512T4GOUT1
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From anne.overgaard at bios.au.dk  Fri Nov 20 09:24:03 2015
From: anne.overgaard at bios.au.dk (Anne Blach Overgaard)
Date: Fri, 20 Nov 2015 08:24:03 +0000
Subject: [R-sig-ME] Data structure issue for GLMM models
In-Reply-To: <CAJuCY5xsn28nb6MSMkOKnP4CQ1MD4JVzJcikyQ38xKkCkH3HpA@mail.gmail.com>
References: <dbc06d866a0241e183ff45530147d3cc@Exch16.uni.au.dk>
	<CAJuCY5xsn28nb6MSMkOKnP4CQ1MD4JVzJcikyQ38xKkCkH3HpA@mail.gmail.com>
Message-ID: <9bc60ae54a6b4e909fb5ab4abebb7861@Exch16.uni.au.dk>

Dear Thierry,

Thank you very much  for your reply.
Below is the syntax of the base model with altitude included as fixed effect:

GLMM.b.nan <- glmer(occ_Betula_nana ~ isotherm + Trange + Tsumm + Psumm + ddeg +
                                sri + slope + mosses +
  bet.nan.bio + alt
                               (1|fsite) + (1|fplotgr) + (1|fplot),
  data=env.sd.ran, family="poisson")

The alternative is to include altitude both as fixed effect and as random effect due to the nested structure of the data

GLMM.b.nan <- glmer(occ_Betula_nana ~ alt + isotherm + Trange + Tsumm + Psumm + ddeg +
                                sri + slope + mosses +
  bet.nan.bio +
                               (1|fsite) + (1|falt) + (1|fplotgr) + (1|fplot),
  data=env.sd.ran, family="poisson")

The response: occ_Betula_nana, is count data i.e., the number of individuals registered in a pin point frame in each plot (ranges from 0-25)
The fixed effects are represented by climate predictors:  isotherm + Trange + Tsumm + Psumm + ddeg (isothermality, annual temperature range, summer temperature, summer precipitation and growing degree days) as well as sri (solar radiation index), slope, mosses (occurrence of mosses in the plots), bet.nan.bio ( a species-specific biotic-interaction variable we have computed), and finally alt (altitude m. asl).

The random effects are site (fsite), plot group (fplotgr) and plots (fplot) and perhaps altitude (falt), but this is where we would appreciate some help to decide whether altitude should be include as fixed effect only , as random effect only or alternatively be included both as random and fixed effects. All random effects have been named individually which is why I haven?t used the code  (1|fsite/fplotgr/falt), but they are nested.

Site is named: S1-S5
Alt is named according to site and altitude e.g., 1_20 (for site 1 at altitude 20) ? NOTE: not all altitudes are present at each site!
Plot group is named according to site, altitude and which of the three repetitions it represents e.g., 1_1_20 (for site 1, plot group no 1 at altitude 20)
Plots are names (P1-P414)
In total we have 5 sites x a varying number of altitudes per site x 3 plot groups per altitude x 6 plots = 414 plots in the entire data set.

I hope this makes the issue a bit more clear

Best regards,

Anne

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: 19 November 2015 15:01
To: Anne Blach Overgaard
Subject: Re: [R-sig-ME] Data structure issue for GLMM models

Dear Anne,

Can you provide the syntax of your base model and/or those of the models you are thinking about? And add a clear specification to the variable names. That would make your question much more clear and easier to answer.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-11-19 12:42 GMT+01:00 Anne Blach Overgaard <anne.overgaard at bios.au.dk<mailto:anne.overgaard at bios.au.dk>>:

Dear List,
I hope that some of you may be able to help us with a data structure issue.
We have collected plant cover data (count data) for selected species along a climatic gradient in random stratified sampling plots. The hierarchical structure of the data is as follows:
We have sampled at five sites placed along a large-scale climatic gradient. Within each of the five sites we placed three plot groups 500 meters apart on each of the altitudes 20 m 100, 200, 300, 400 and 500 m above sea level, whenever possible, as not all isoclines were present at each site. Each plot group consisted of six plots that were placed 10 meters apart.
In total we have 5 sites x a varying number of altitudes per site x 3 plot groups per altitude x 6 plots = 414 plots in the entire data set.
Overall we would like to assess the relative importance of different predictor groups (altitude, climate, and biotic interactions) on the variation in cover per species. We are including the predictor groups as fixed effects in our models using lme4::glmer (family = poisson). We include site and plot group as nested random effects and plots as an observation-level random factor due to overdispersion in the data.
Our question is whether altitude should be entered as a random factor, as a fixed effect, or possibly as both a fixed and a random effect. Altitude is a part of the nested structure of the data, but we also have an interest in including it as a fixed effect to assess how much of the variation in the data is due to altitude.
We hope that some of you can guide us how to deal with altitude in this data analysis.
Thanking you in advance.
Best regards,
Anne & co-workers





        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Nov 20 11:37:24 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 20 Nov 2015 11:37:24 +0100
Subject: [R-sig-ME] Data structure issue for GLMM models
In-Reply-To: <9bc60ae54a6b4e909fb5ab4abebb7861@Exch16.uni.au.dk>
References: <dbc06d866a0241e183ff45530147d3cc@Exch16.uni.au.dk>
	<CAJuCY5xsn28nb6MSMkOKnP4CQ1MD4JVzJcikyQ38xKkCkH3HpA@mail.gmail.com>
	<9bc60ae54a6b4e909fb5ab4abebb7861@Exch16.uni.au.dk>
Message-ID: <CAJuCY5wmDd7cSb+5ou=fsYAPq06Dk7K5xuP3QiP5uC2bOZ96WA@mail.gmail.com>

Dear Anne,

I've posted an Rpubs on adding a variable to both the fixed and the random
effects. Have a look at http://rpubs.com/INBOstats/both_fixed_random I
think that it answers your question.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-20 9:24 GMT+01:00 Anne Blach Overgaard <anne.overgaard at bios.au.dk>:

> Dear Thierry,
>
>
>
> Thank you very much  for your reply.
>
> Below is the syntax of the base model with altitude included as fixed
> effect:
>
>
>
> GLMM.b.nan <- glmer(occ_Betula_nana ~ isotherm + Trange + Tsumm + Psumm +
> ddeg +
>
>                                 sri + slope + mosses +
>
>   bet.nan.bio + alt
>
>                                (1|fsite) + (1|fplotgr) + (1|fplot),
>
>   data=env.sd.ran, family="poisson")
>
>
>
> The alternative is to include altitude both as fixed effect and as random
> effect due to the nested structure of the data
>
>
>
> GLMM.b.nan <- glmer(occ_Betula_nana ~ alt + isotherm + Trange + Tsumm +
> Psumm + ddeg +
>
>                                 sri + slope + mosses +
>
>   bet.nan.bio +
>
>                                (1|fsite) + (1|falt) + (1|fplotgr) +
> (1|fplot),
>
>   data=env.sd.ran, family="poisson")
>
>
>
> The response: occ_Betula_nana, is count data i.e., the number of
> individuals registered in a pin point frame in each plot (ranges from 0-25)
>
> The fixed effects are represented by climate predictors:  isotherm +
> Trange + Tsumm + Psumm + ddeg (isothermality, annual temperature range,
> summer temperature, summer precipitation and growing degree days) as well
> as sri (solar radiation index), slope, mosses (occurrence of mosses in the
> plots), bet.nan.bio ( a species-specific biotic-interaction variable we
> have computed), and finally alt (altitude m. asl).
>
>
>
> The random effects are site (fsite), plot group (fplotgr) and plots
> (fplot) and perhaps altitude (falt), but this is where we would appreciate
> some help to decide whether altitude should be include as fixed effect only
> , as random effect only or alternatively be included both as random and
> fixed effects. All random effects have been named individually which is why
> I haven?t used the code  (1|fsite/fplotgr/falt), but they are nested.
>
>
>
> Site is named: S1-S5
>
> Alt is named according to site and altitude e.g., 1_20 (for site 1 at
> altitude 20) ? NOTE: not all altitudes are present at each site!
>
> Plot group is named according to site, altitude and which of the three
> repetitions it represents e.g., 1_1_20 (for site 1, plot group no 1 at
> altitude 20)
>
> Plots are names (P1-P414)
>
> In total we have 5 sites x a varying number of altitudes per site x 3 plot
> groups per altitude x 6 plots = 414 plots in the entire data set.
>
>
>
> I hope this makes the issue a bit more clear
>
>
>
> Best regards,
>
>
>
> Anne
>
>
>
> *From:* Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be
> <thierry.onkelinx at inbo.be>]
> *Sent:* 19 November 2015 15:01
> *To:* Anne Blach Overgaard
> *Subject:* Re: [R-sig-ME] Data structure issue for GLMM models
>
>
>
> Dear Anne,
>
>
>
> Can you provide the syntax of your base model and/or those of the models
> you are thinking about? And add a clear specification to the variable
> names. That would make your question much more clear and easier to answer.
>
>
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
> 2015-11-19 12:42 GMT+01:00 Anne Blach Overgaard <anne.overgaard at bios.au.dk
> >:
>
>
> Dear List,
> I hope that some of you may be able to help us with a data structure issue.
> We have collected plant cover data (count data) for selected species along
> a climatic gradient in random stratified sampling plots. The hierarchical
> structure of the data is as follows:
> We have sampled at five sites placed along a large-scale climatic
> gradient. Within each of the five sites we placed three plot groups 500
> meters apart on each of the altitudes 20 m 100, 200, 300, 400 and 500 m
> above sea level, whenever possible, as not all isoclines were present at
> each site. Each plot group consisted of six plots that were placed 10
> meters apart.
> In total we have 5 sites x a varying number of altitudes per site x 3 plot
> groups per altitude x 6 plots = 414 plots in the entire data set.
> Overall we would like to assess the relative importance of different
> predictor groups (altitude, climate, and biotic interactions) on the
> variation in cover per species. We are including the predictor groups as
> fixed effects in our models using lme4::glmer (family = poisson). We
> include site and plot group as nested random effects and plots as an
> observation-level random factor due to overdispersion in the data.
> Our question is whether altitude should be entered as a random factor, as
> a fixed effect, or possibly as both a fixed and a random effect. Altitude
> is a part of the nested structure of the data, but we also have an interest
> in including it as a fixed effect to assess how much of the variation in
> the data is due to altitude.
> We hope that some of you can guide us how to deal with altitude in this
> data analysis.
> Thanking you in advance.
> Best regards,
> Anne & co-workers
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Fri Nov 20 14:17:20 2015
From: killver at gmail.com (Philipp Singer)
Date: Fri, 20 Nov 2015 14:17:20 +0100
Subject: [R-sig-ME] Problems with model (assumptions)
Message-ID: <564F1D60.1000904@gmail.com>

Dear all,

I am currently trying to investigate the effect of time (in the sense of 
an index) on the length of a text that people write (body_length). So, 
e.g., my hypothesis is that the later someone writes a text, the shorter 
it is. All authors do not write the same amount of individual texts, 
thus I have an additional variable that captures the maximum index 
(length). One further thing to note is that authors can have several 
"sessions" on different days.

I have started to use a linear mixed-effects model. However, the basic 
assumptions of linear regression do not seem to hold (e.g., normality of 
residuals) which is to be expected for count data (text length).

Thus, I have tried several other GLMs and adaptions. However, for most 
of them, the assumptions do not hold as well. Also, I receive several 
odd errors for some models.

The best results can be achieved when I just log transform the outcome 
and use linear regression. However, as suggested in literature, this is 
not the proper way of treating count data.

One thing to note is, that my data is enormeous (50mio. data points). I 
have worked with a sample of 1mio datapoints here, results for the whole 
data are similar though.

Instead of now individually highlighting all the results in this mail, I 
have decided to prepare an iPython notebook (using R and lme4) that 
should convey my main procedure that I have conducted until now.

It can be found here:
https://nbviewer.jupyter.org/gist/anonymous/2897dd277a35a0df52ea

I am hoping for some advice on how to proceed.

Thanks in advance!


From m51988mnew at juno.com  Fri Nov 20 16:52:48 2015
From: m51988mnew at juno.com (m51988mnew at juno.com)
Date: Fri, 20 Nov 2015 15:52:48 GMT
Subject: [R-sig-ME] Fw: question about Type III sums of squares as computed
	in "CAR'
Message-ID: <20151120.105248.16002.0@webmail10.dca.untd.com>

I have attached the example data and the r-code and r messages.The data are example measurements of exposures on 2 occupations ( a and b)on 11 sampling days.  Each occupation  has one measurement per day.  The 11 sampling days are at 4 sites:  3 days at 3 of the sites and  2 days at 1 site.  In addition, there were three  workers who did the second occupation  , labelled 6,7,8, for the variable idb.  I need the SAS type III sums of squares for each of the variables in the model, but you can see the error message in the R code: there are aliased coefficients in the model In SAS I believe that this problem is dealt with by placing constraints on the parameters.I would appreciate any suggestions.  I think that maybe I am formulating the model wrong.  Thanks,Stanley Shulman       

---------- Forwarded Message ----------
From: "m51988mnew at juno.com" <m51988mnew at juno.com>
To: r-sig-mixed-models at r-project.org
Subject: question about Type III sums of squares as computed in "CAR' 
Date: Wed, 18 Nov 2015 02:25:03 GMT


When I use "Anova" from the car library, I cannot get Type III sums of
 squares for nested data.  Maybe I am using the program wrong. SAS gives the
 Type III sums of squares. Thanks for any thoughts.Stanley Shulman

____________________________________________________________
NetZero now offers 4G mobile broadband. Sign up now.
http://www.netzero.net/?refcd=NZINTISP0512T4GOUT1

From bates at stat.wisc.edu  Fri Nov 20 18:08:58 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 20 Nov 2015 17:08:58 +0000
Subject: [R-sig-ME] Fw: question about Type III sums of squares as
 computed in "CAR'
In-Reply-To: <20151120.105248.16002.0@webmail10.dca.untd.com>
References: <20151120.105248.16002.0@webmail10.dca.untd.com>
Message-ID: <CAO7JsnTWgcCyGrOH_r-AfpkZ7TUKPoBrtPf+oG0AEaQWA_4mzQ@mail.gmail.com>

I don't think your data, code, etc. made it through to the list.

If you need the SAS results, wouldn't it be easier to use SAS to get them?

On Fri, Nov 20, 2015 at 10:35 AM m51988mnew at juno.com <m51988mnew at juno.com>
wrote:

> I have attached the example data and the r-code and r messages.The data
> are example measurements of exposures on 2 occupations ( a and b)on 11
> sampling days.  Each occupation  has one measurement per day.  The 11
> sampling days are at 4 sites:  3 days at 3 of the sites and  2 days at 1
> site.  In addition, there were three  workers who did the second
> occupation  , labelled 6,7,8, for the variable idb.  I need the SAS type
> III sums of squares for each of the variables in the model, but you can see
> the error message in the R code: there are aliased coefficients in the
> model In SAS I believe that this problem is dealt with by placing
> constraints on the parameters.I would appreciate any suggestions.  I think
> that maybe I am formulating the model wrong.  Thanks,Stanley Shulman
>
> ---------- Forwarded Message ----------
> From: "m51988mnew at juno.com" <m51988mnew at juno.com>
> To: r-sig-mixed-models at r-project.org
> Subject: question about Type III sums of squares as computed in "CAR'
> Date: Wed, 18 Nov 2015 02:25:03 GMT
>
>
> When I use "Anova" from the car library, I cannot get Type III sums of
>  squares for nested data.  Maybe I am using the program wrong. SAS gives
> the
>  Type III sums of squares. Thanks for any thoughts.Stanley Shulman
>
> ____________________________________________________________
> NetZero now offers 4G mobile broadband. Sign up now.
> http://www.netzero.net/?refcd=NZINTISP0512T4GOUT1
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sun Nov 22 19:36:49 2015
From: hannah.hlx at gmail.com (li li)
Date: Sun, 22 Nov 2015 13:36:49 -0500
Subject: [R-sig-ME] Print out of function lmer
Message-ID: <CAHLnndZL5fif1vaTYky=ftnY-SeQ07DSuOqub07MTvWYwt2JVg@mail.gmail.com>

Hi all,
  I want to add the column for the variance of the random effect in the
printout of the lmer function.  For now only standard deviation is shown.
See example printout below. Is it possible to add a column for the variance?
   Thanks very much!!
    Hanna

> mod1
Linear mixed model fit by REML ['lmerMod']
Formula: result ~ 1 + (1 | analyst) + (1 | day1)
   Data: one1
REML criterion at convergence: 126.0852
Random effects:
 Groups   Name        Std.Dev.
 day1     (Intercept) 1.130e-08
 analyst  (Intercept) 9.547e-01
 Residual             1.079e+00
Number of obs: 40, groups:  day1, 20; analyst, 4
Fixed Effects:
(Intercept)
      7.823
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Nov 22 22:53:11 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Nov 2015 16:53:11 -0500
Subject: [R-sig-ME] Print out of function lmer
In-Reply-To: <CAHLnndZL5fif1vaTYky=ftnY-SeQ07DSuOqub07MTvWYwt2JVg@mail.gmail.com>
References: <CAHLnndZL5fif1vaTYky=ftnY-SeQ07DSuOqub07MTvWYwt2JVg@mail.gmail.com>
Message-ID: <CABghstRv2cv2B6Aiho5Gziwjd3TpeW-+w-La+eb7kywWZo1HMg@mail.gmail.com>

  Yes, you can:

library(lme4)
example(lmer)
print(summary(fm1),ranef.comp=c("Variance","Std.Dev."))



On Sun, Nov 22, 2015 at 1:36 PM, li li <hannah.hlx at gmail.com> wrote:
> Hi all,
>   I want to add the column for the variance of the random effect in the
> printout of the lmer function.  For now only standard deviation is shown.
> See example printout below. Is it possible to add a column for the variance?
>    Thanks very much!!
>     Hanna
>
>> mod1
> Linear mixed model fit by REML ['lmerMod']
> Formula: result ~ 1 + (1 | analyst) + (1 | day1)
>    Data: one1
> REML criterion at convergence: 126.0852
> Random effects:
>  Groups   Name        Std.Dev.
>  day1     (Intercept) 1.130e-08
>  analyst  (Intercept) 9.547e-01
>  Residual             1.079e+00
> Number of obs: 40, groups:  day1, 20; analyst, 4
> Fixed Effects:
> (Intercept)
>       7.823
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Sun Nov 22 23:31:00 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Nov 2015 17:31:00 -0500
Subject: [R-sig-ME] Print out of function lmer
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D9701979862D1@SFSMCEXMBX3.sanfordhealth.org>
References: <CAHLnndZL5fif1vaTYky=ftnY-SeQ07DSuOqub07MTvWYwt2JVg@mail.gmail.com>
	<CABghstRv2cv2B6Aiho5Gziwjd3TpeW-+w-La+eb7kywWZo1HMg@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D9701979862D1@SFSMCEXMBX3.sanfordhealth.org>
Message-ID: <CABghstQfGs3_TKXJxOv32fbp8uL2pEK899Sts3g09s=1o0a06g@mail.gmail.com>

 [keeping r-sig-mixed-models in cc: list]

  It's admittedly a bit obscure, but the ?summary.merMod page shows
that the 'print' method for 'summary.merMod' objects has an argument
called 'ranef.comp', which is described as follows:

ranef.comp: character vector of length one or two, indicating if
          random-effects parameters should be reported on the variance
          and/or standard deviation scale.

(This argument should probably be called varcorr.comp rather than
ranef.comp ...)

Similarly, the ?VarCorr.merMod help page has a note saying:

The ?print? method for ?VarCorr.merMod? objects has optional
     arguments ?digits? (specify digits of precision for printing) and
     ?comp?: the latter is a character vector with any combination of
     ?"Variance"? and ?"Std.Dev."?, to specify whether variances,
     standard deviations, or both should be printed.


On Sun, Nov 22, 2015 at 5:25 PM, Thompson,Paul
<Paul.Thompson at sanfordhealth.org> wrote:
> How would a person figure that out without you answering, Ben? What is the proper command to get help for that?
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Sunday, November 22, 2015 3:53 PM
> To: li li
> Cc: r-sig-mixed-models
> Subject: Re: [R-sig-ME] Print out of function lmer
>
>   Yes, you can:
>
> library(lme4)
> example(lmer)
> print(summary(fm1),ranef.comp=c("Variance","Std.Dev."))
>
>
>
> On Sun, Nov 22, 2015 at 1:36 PM, li li <hannah.hlx at gmail.com> wrote:
>> Hi all,
>>   I want to add the column for the variance of the random effect in
>> the printout of the lmer function.  For now only standard deviation is shown.
>> See example printout below. Is it possible to add a column for the variance?
>>    Thanks very much!!
>>     Hanna
>>
>>> mod1
>> Linear mixed model fit by REML ['lmerMod']
>> Formula: result ~ 1 + (1 | analyst) + (1 | day1)
>>    Data: one1
>> REML criterion at convergence: 126.0852 Random effects:
>>  Groups   Name        Std.Dev.
>>  day1     (Intercept) 1.130e-08
>>  analyst  (Intercept) 9.547e-01
>>  Residual             1.079e+00
>> Number of obs: 40, groups:  day1, 20; analyst, 4 Fixed Effects:
>> (Intercept)
>>       7.823
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
>


From thierry.onkelinx at inbo.be  Mon Nov 23 09:17:28 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 23 Nov 2015 09:17:28 +0100
Subject: [R-sig-ME] Problems with model (assumptions)
In-Reply-To: <564F1D60.1000904@gmail.com>
References: <564F1D60.1000904@gmail.com>
Message-ID: <CAJuCY5xjgam-EbhCdhY4CHbfyW-QY4LWafMqq3eh2NGk7KT49g@mail.gmail.com>

Dear Philipp,

I'm missing the graphs for the data exploration step in the notebook. So
you can get an idea if the relations of with the explanatory variables are
(log)linear.

The residual plot from the Gaussian model are typical when modelling count
data. So you need a Poisson or negative binomial distribution.

normal qqplots for glm models are irrelevant. residuals versus fit are
difficult to interpret. You should focus on residuals versus explanatory
variables (fixed and random).

You could consider using length as an offset factor. That seems to make
more sense than as a random effect. Since length is the maximum body length
per author, you would model the relative body length per author.

There are other R packages that can fit glmm. glmmADMB, INLA, ... You can
try them and see what happens.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-20 14:17 GMT+01:00 Philipp Singer <killver at gmail.com>:

> Dear all,
>
> I am currently trying to investigate the effect of time (in the sense of
> an index) on the length of a text that people write (body_length). So,
> e.g., my hypothesis is that the later someone writes a text, the shorter it
> is. All authors do not write the same amount of individual texts, thus I
> have an additional variable that captures the maximum index (length). One
> further thing to note is that authors can have several "sessions" on
> different days.
>
> I have started to use a linear mixed-effects model. However, the basic
> assumptions of linear regression do not seem to hold (e.g., normality of
> residuals) which is to be expected for count data (text length).
>
> Thus, I have tried several other GLMs and adaptions. However, for most of
> them, the assumptions do not hold as well. Also, I receive several odd
> errors for some models.
>
> The best results can be achieved when I just log transform the outcome and
> use linear regression. However, as suggested in literature, this is not the
> proper way of treating count data.
>
> One thing to note is, that my data is enormeous (50mio. data points). I
> have worked with a sample of 1mio datapoints here, results for the whole
> data are similar though.
>
> Instead of now individually highlighting all the results in this mail, I
> have decided to prepare an iPython notebook (using R and lme4) that should
> convey my main procedure that I have conducted until now.
>
> It can be found here:
> https://nbviewer.jupyter.org/gist/anonymous/2897dd277a35a0df52ea
>
> I am hoping for some advice on how to proceed.
>
> Thanks in advance!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Nov 23 14:59:45 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 23 Nov 2015 08:59:45 -0500
Subject: [R-sig-ME] Problems with model (assumptions)
In-Reply-To: <CAJuCY5xjgam-EbhCdhY4CHbfyW-QY4LWafMqq3eh2NGk7KT49g@mail.gmail.com>
References: <564F1D60.1000904@gmail.com>
	<CAJuCY5xjgam-EbhCdhY4CHbfyW-QY4LWafMqq3eh2NGk7KT49g@mail.gmail.com>
Message-ID: <CABghstR8yTVQ8qqYUGN0zZR0CbP3arPdV8YBZLUmB2szbNivCg@mail.gmail.com>

I *can* see the plots; it looks to me like Philipp's
log-transformation is almost perfect (the Q-Q plot shows a tiny bit of
a skew, but I wouldn't worry about it).  The model gives you a
convergence warning with magnitude 0.002, but we know from experience
(see ?convergence) that especially for 10^6 observations this is
probably a false positive.  I would definitely recommend proceeding
with

m_lmer_log = lmer(log(body_length)~1+index+(1|author)+(1|length),
data=data, REML=FALSE)

(i.e. line 84).


For count data with a large mean (your intercept is approx. 230),
log-transforming seems perfectly reasonable.

On Mon, Nov 23, 2015 at 3:17 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear Philipp,
>
> I'm missing the graphs for the data exploration step in the notebook. So
> you can get an idea if the relations of with the explanatory variables are
> (log)linear.
>
> The residual plot from the Gaussian model are typical when modelling count
> data. So you need a Poisson or negative binomial distribution.
>
> normal qqplots for glm models are irrelevant. residuals versus fit are
> difficult to interpret. You should focus on residuals versus explanatory
> variables (fixed and random).
>
> You could consider using length as an offset factor. That seems to make
> more sense than as a random effect. Since length is the maximum body length
> per author, you would model the relative body length per author.
>
> There are other R packages that can fit glmm. glmmADMB, INLA, ... You can
> try them and see what happens.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-11-20 14:17 GMT+01:00 Philipp Singer <killver at gmail.com>:
>
>> Dear all,
>>
>> I am currently trying to investigate the effect of time (in the sense of
>> an index) on the length of a text that people write (body_length). So,
>> e.g., my hypothesis is that the later someone writes a text, the shorter it
>> is. All authors do not write the same amount of individual texts, thus I
>> have an additional variable that captures the maximum index (length). One
>> further thing to note is that authors can have several "sessions" on
>> different days.
>>
>> I have started to use a linear mixed-effects model. However, the basic
>> assumptions of linear regression do not seem to hold (e.g., normality of
>> residuals) which is to be expected for count data (text length).
>>
>> Thus, I have tried several other GLMs and adaptions. However, for most of
>> them, the assumptions do not hold as well. Also, I receive several odd
>> errors for some models.
>>
>> The best results can be achieved when I just log transform the outcome and
>> use linear regression. However, as suggested in literature, this is not the
>> proper way of treating count data.
>>
>> One thing to note is, that my data is enormeous (50mio. data points). I
>> have worked with a sample of 1mio datapoints here, results for the whole
>> data are similar though.
>>
>> Instead of now individually highlighting all the results in this mail, I
>> have decided to prepare an iPython notebook (using R and lme4) that should
>> convey my main procedure that I have conducted until now.
>>
>> It can be found here:
>> https://nbviewer.jupyter.org/gist/anonymous/2897dd277a35a0df52ea
>>
>> I am hoping for some advice on how to proceed.
>>
>> Thanks in advance!
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From killver at gmail.com  Mon Nov 23 16:21:18 2015
From: killver at gmail.com (Philipp Singer)
Date: Mon, 23 Nov 2015 16:21:18 +0100
Subject: [R-sig-ME] Problems with model (assumptions)
In-Reply-To: <CABghstR8yTVQ8qqYUGN0zZR0CbP3arPdV8YBZLUmB2szbNivCg@mail.gmail.com>
References: <564F1D60.1000904@gmail.com>
	<CAJuCY5xjgam-EbhCdhY4CHbfyW-QY4LWafMqq3eh2NGk7KT49g@mail.gmail.com>
	<CABghstR8yTVQ8qqYUGN0zZR0CbP3arPdV8YBZLUmB2szbNivCg@mail.gmail.com>
Message-ID: <56532EEE.4080204@gmail.com>

Thanks for both of your answers.

I will proceed with the log transformed version then as this definitly 
provides the best fit.

One more question though regarding the point made by Thierry regarding 
the residuals:
I thought that when looking at scaled residuals (pearson or deviance) 
they should be distributed normally (at least asymptotically). Is this 
wrong?

Thanks a lot guys!
Philipp

On 11/23/2015 02:59 PM, Ben Bolker wrote:
> I *can* see the plots; it looks to me like Philipp's
> log-transformation is almost perfect (the Q-Q plot shows a tiny bit of
> a skew, but I wouldn't worry about it).  The model gives you a
> convergence warning with magnitude 0.002, but we know from experience
> (see ?convergence) that especially for 10^6 observations this is
> probably a false positive.  I would definitely recommend proceeding
> with
>
> m_lmer_log = lmer(log(body_length)~1+index+(1|author)+(1|length),
> data=data, REML=FALSE)
>
> (i.e. line 84).
>
>
> For count data with a large mean (your intercept is approx. 230),
> log-transforming seems perfectly reasonable.
>
> On Mon, Nov 23, 2015 at 3:17 AM, Thierry Onkelinx
> <thierry.onkelinx at inbo.be> wrote:
>> Dear Philipp,
>>
>> I'm missing the graphs for the data exploration step in the notebook. So
>> you can get an idea if the relations of with the explanatory variables are
>> (log)linear.
>>
>> The residual plot from the Gaussian model are typical when modelling count
>> data. So you need a Poisson or negative binomial distribution.
>>
>> normal qqplots for glm models are irrelevant. residuals versus fit are
>> difficult to interpret. You should focus on residuals versus explanatory
>> variables (fixed and random).
>>
>> You could consider using length as an offset factor. That seems to make
>> more sense than as a random effect. Since length is the maximum body length
>> per author, you would model the relative body length per author.
>>
>> There are other R packages that can fit glmm. glmmADMB, INLA, ... You can
>> try them and see what happens.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-11-20 14:17 GMT+01:00 Philipp Singer <killver at gmail.com>:
>>
>>> Dear all,
>>>
>>> I am currently trying to investigate the effect of time (in the sense of
>>> an index) on the length of a text that people write (body_length). So,
>>> e.g., my hypothesis is that the later someone writes a text, the shorter it
>>> is. All authors do not write the same amount of individual texts, thus I
>>> have an additional variable that captures the maximum index (length). One
>>> further thing to note is that authors can have several "sessions" on
>>> different days.
>>>
>>> I have started to use a linear mixed-effects model. However, the basic
>>> assumptions of linear regression do not seem to hold (e.g., normality of
>>> residuals) which is to be expected for count data (text length).
>>>
>>> Thus, I have tried several other GLMs and adaptions. However, for most of
>>> them, the assumptions do not hold as well. Also, I receive several odd
>>> errors for some models.
>>>
>>> The best results can be achieved when I just log transform the outcome and
>>> use linear regression. However, as suggested in literature, this is not the
>>> proper way of treating count data.
>>>
>>> One thing to note is, that my data is enormeous (50mio. data points). I
>>> have worked with a sample of 1mio datapoints here, results for the whole
>>> data are similar though.
>>>
>>> Instead of now individually highlighting all the results in this mail, I
>>> have decided to prepare an iPython notebook (using R and lme4) that should
>>> convey my main procedure that I have conducted until now.
>>>
>>> It can be found here:
>>> https://nbviewer.jupyter.org/gist/anonymous/2897dd277a35a0df52ea
>>>
>>> I am hoping for some advice on how to proceed.
>>>
>>> Thanks in advance!
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Katrijn.Delaruelle at UGent.be  Mon Nov 23 16:59:52 2015
From: Katrijn.Delaruelle at UGent.be (Katrijn Delaruelle)
Date: Mon, 23 Nov 2015 16:59:52 +0100
Subject: [R-sig-ME] MCMCglmm: Correct prior?
Message-ID: <010701d12607$fd5ad4f0$f8107ed0$@UGent.be>

Hello everyone,

 

I'm trying to run a multinomial MCMCglmm, but I'm having some problems with
specifying the prior.

My model consists of three levels and my dependent variable consists of four
categories.

 

I use the following model, in analogy to  this formulation:
https://hlplab.wordpress.com/2009/05/07/multinomial-random-effects-models-in
-r/

 

 

k <- length(levels(marital))

I <- diag(k-1)

J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))

 

 

Model1_Multi <-
MCMCglmm(marital~-1+trait+trait:Parent+trait:edu*trait:cohort.+
trait:edu*trait:age

                         +trait:employment+trait:Income, random
=~idh(trait):cntry+ idh(trait):PC +
idh(trait):cohorts,rcov=~idh(trait):units,family = "categorical", 

                         prior=list(R=list(V=0.5 * (I + J), n = 4,fix=1),
G=list(G1=list(V=diag(3), nu=0.002), G2=list(V=diag(3), nu=0.002),
G3=list(V=diag(3), nu=0.002))), data=data2, nitt=5000,  burnin =1000)

 

This model works well, but I don't know if I generated a correct prior (e.g.
Did I use correct values to specify V and n?)

I would be very thankful if someone could help me.

 

Kind regards,

Katrijn Delaruelle

Vakgroep Sociologie

Universiteit Gent

 

 

 

 


	[[alternative HTML version deleted]]


From m51988mnew at juno.com  Mon Nov 23 02:07:53 2015
From: m51988mnew at juno.com (m51988mnew at juno.com)
Date: Mon, 23 Nov 2015 01:07:53 GMT
Subject: [R-sig-ME] Fw: question about Type III sums of squares as
	computed	 in "CAR'
Message-ID: <20151122.200753.16147.0@webmail01.dca.untd.com>

Yes, in fact, I have used SAS . It happens that  it is more convenient for me to use R than SAS;  I have hoped that I could easily use R to get what I need (in the future) but there seems to be no easy way to do so, Thanks,Stanley Shulman   

---------- Original Message ----------
From: Douglas Bates <bates at stat.wisc.edu>
To: "m51988mnew at juno.com" <m51988mnew at juno.com>, r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Fw: question about Type III sums of squares as computed in "CAR'
Date: Fri, 20 Nov 2015 17:08:58 +0000


I don't think your data, code, etc. made it through to the list. If you need the SAS results, wouldn't it be easier to use SAS to get them? 
On Fri, Nov 20, 2015 at 10:35 AM m51988mnew at juno.com <m51988mnew at juno.com> wrote:I have attached the example data and the r-code and r messages.The data are example measurements of exposures on 2 occupations ( a and b)on 11 sampling days.  Each occupation  has one measurement per day.  The 11 sampling days are at 4 sites:  3 days at 3 of the sites and  2 days at 1 site.  In addition, there were three  workers who did the second occupation  , labelled 6,7,8, for the variable idb.  I need the SAS type III sums of squares for each of the variables in the model, but you can see the error message in the R code: there are aliased coefficients in the model In SAS I believe that this problem is dealt with by placing constraints on the parameters.I would appreciate any suggestions.  I think that maybe I am formulating the model wrong.  Thanks,Stanley Shulman
 
 ---------- Forwarded Message ----------
 From: "m51988mnew at juno.com" <m51988mnew at juno.com>
 To: r-sig-mixed-models at r-project.org
 Subject: question about Type III sums of squares as computed in "CAR'
 Date: Wed, 18 Nov 2015 02:25:03 GMT
 
 
 When I use "Anova" from the car library, I cannot get Type III sums of
  squares for nested data.  Maybe I am using the program wrong. SAS gives the
  Type III sums of squares. Thanks for any thoughts.Stanley Shulman
 
 ____________________________________________________________
 NetZero now offers 4G mobile broadband. Sign up now.
 http://www.netzero.net/?refcd=NZINTISP0512T4GOUT1
 _______________________________________________
 R-sig-mixed-models at r-project.org mailing list
 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

____________________________________________________________
NetZero now offers 4G mobile broadband. Sign up now.
http://www.netzero.net/?refcd=NZINTISP0512T4GOUT1

	[[alternative HTML version deleted]]


From m51988mnew at juno.com  Fri Nov 20 18:44:20 2015
From: m51988mnew at juno.com (m51988mnew at juno.com)
Date: Fri, 20 Nov 2015 17:44:20 GMT
Subject: [R-sig-ME] Fw: question about Type III sums of squares as computed
	in "CAR'
Message-ID: <20151120.124420.27452.1@webmail02.dca.untd.com>



Please note: forwarded message attached

From: "m51988mnew at juno.com" <m51988mnew at juno.com>
To: :r-sig-mixed-models at r-project.org
Cc: m51988mnew at juno.com
Subject: Fw: question about Type III sums of squares as computed in "CAR' 
Date: Fri, 20 Nov 2015 17:41:53 GMT

SiteDayyoccidbDate      110.004613a01      120.004555a02      130.001759a03      210.002755a04      220.00043a05      310.001138a06      320.005983a07      330.003027a08      410.001202a09      420.003261a010      430.00652a011      110.002368b61      120.001521b62      130.001381b73      210.004089b74      220.001139b75      310.000723b76      320.001017b77      330.001621b78      410.000562b89      420.002402b810      430.003053b811                              library(car)          exp <- read.table(file="example.csv",sep=",",header=TRUE)    exp$Site <- as.factor(exp$Site)        exp$Day <- as.factor(exp$Day)        exp$occ <- as.factor(exp$occ)        exp$idb  <- as.factor(exp$idb)        exp$Date <- as.factor(exp$Date)        exp.lm1 <- lm(log(y) ~ occ + Date + occ: idb,data=exp)      an_lm13 <- Anova(exp.lm1, type=c("III"))      an_lm12 <- Anova(exp.lm1, type=c("II"))       exp.lm2 <- lm(log(y) ~ occ + Site + Site:Day + occ:idb,data=exp)     an_lm23 <- Anova(exp.lm2, type=c("III"))      an_lm22 <- Anova(exp.lm2, type=c("II"))       exp.lm3 <- lm(log(y) ~  Site + Site:Day ,data=exp)       an_lm33 <- Anova(exp.lm3, type=c("III"))      an_lm32 <- Anova(exp.lm3, type=c("II"))                                           r output:          > library(car)          > exp <- read.table(file="example.csv",sep=",",header=TRUE)      > exp$Site <- as.factor(exp$Site)        > exp$Day <- as.factor(exp$Day)        > exp$occ <- as.factor(exp$occ)        > exp$idb  <- as.factor(exp$idb)        > exp$Date <- as.factor(exp$Date)        > exp.lm1 <- lm(log(y) ~ occ + Date + occ: idb,data=exp)      >  an_lm13 <- Anova(exp.lm1, type=c("III"))       Error in Anova.III.lm(mod, error, singular.ok = singular.ok, ...) :       there are aliased coefficients in the model       > an_lm12 <- Anova(exp.lm1, type=c("II"))       > exp.lm2 <- lm(log(y) ~ occ + Site + Site:Day + occ:idb,data=exp)     >  an_lm23 <- Anova(exp.lm2, type=c("III"))       Error in Anova.III.lm(mod, error, singular.ok = singular.ok, ...) :       there are aliased coefficients in the model       > an_lm22 <- Anova(exp.lm2, type=c("II"))       > exp.lm3 <- lm(log(y) ~  Site + Site:Day ,data=exp)       >  an_lm33 <- Anova(exp.lm3, type=c("III"))       Error in Anova.III.lm(mod, error, singular.ok = singular.ok, ...) :       there are aliased coefficients in the model       > an_lm32 <- Anova(exp.lm3, type=c("II"))       >            

Please note: forwarded message attached

From: "m51988mnew at juno.com" <m51988mnew at juno.com>
To: r-sig-mixed-models at r-project.org
Subject: Fw: question about Type III sums of squares as computed in "CAR' 
Date: Fri, 20 Nov 2015 15:52:48 GMT

I have attached the example data and the r-code and r messages.The data are example measurements of exposures on 2 occupations ( a and b)on 11 sampling days.  Each occupation  has one measurement per day.  The 11 sampling days are at 4 sites:  3 days at 3 of the sites and  2 days at 1 site.  In addition, there were three  workers who did the second occupation  , labelled 6,7,8, for the variable idb.  I need the SAS type III sums of squares for each of the variables in the model, but you can see the error message in the R code: there are aliased coefficients in the model In SAS I believe that this problem is dealt with by placing constraints on the parameters.I would appreciate any suggestions.  I think that maybe I am formulating the model wrong.  Thanks,Stanley Shulman       

---------- Forwarded Message ----------
From: "m51988mnew at juno.com" <m51988mnew at juno.com>
To: r-sig-mixed-models at r-project.org
Subject: question about Type III sums of squares as computed in "CAR' 
Date: Wed, 18 Nov 2015 02:25:03 GMT

When I use "Anova" from the car library, I cannot get Type III sums of
 squares for nested data.  Maybe I am using the program wrong. SAS gives the
 Type III sums of squares. Thanks for any thoughts.Stanley Shulman

____________________________________________________________
NetZero now offers 4G mobile broadband. Sign up now.
http://www.netzero.net/?refcd=NZINTISP0512T4GOUT1

From trichter at uni-bremen.de  Mon Nov 23 22:39:44 2015
From: trichter at uni-bremen.de (trichter at uni-bremen.de)
Date: Mon, 23 Nov 2015 22:39:44 +0100
Subject: [R-sig-ME] GLMMs to identify the pure seasonal effect in a repeated
 measurement
Message-ID: <20151123223944.Horde.ZGgk4c58-9gGUlnyuxBB0Ej@webmail.uni-bremen.de>


Dear list,

i am very new to mixed models. My data encompasses species composition  
matrices from six different time points with spatial correlation  
structure. For each species, i want to know if there is a pure effect  
by time, f.e. if abundance changes can be purely explained by time  
alone.
I used to glht() with time being a simple factor (so not accounting  
for the repetitive nature of my data), but this seems  
inapprobiate/wrong. So, i am actually trying to do:

fit <- lme(fixed=abundance ~ time, random=~1|time, data,  
correlation=corxxx(form=~x.pos + y.pos))

with time being a factor with 6 levels (a side question would be, if  
it would be better to use "time" as.time?)

Because my data is actually negative binomially distributed, i was  
advised to use glmmPQL, but this gives me only intercepts, no  
significancies or ways to compare models by log likelihood or AIC.

The basic question is, if that syntax is correct? Because i have seen  
many examples looking at interactions, but never anything where the  
only fixed predictor is also random. I do get an output, which i can  
interpret and which resembles what i can actually see from boxplots.

The overarching question is, if there are post-hoc tests for repeated  
measurements of spatially autocorrelated, non-normally distributed data.

Thank you, Tim


From thierry.onkelinx at inbo.be  Tue Nov 24 10:30:56 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 24 Nov 2015 10:30:56 +0100
Subject: [R-sig-ME] GLMMs to identify the pure seasonal effect in a
 repeated measurement
In-Reply-To: <20151123223944.Horde.ZGgk4c58-9gGUlnyuxBB0Ej@webmail.uni-bremen.de>
References: <20151123223944.Horde.ZGgk4c58-9gGUlnyuxBB0Ej@webmail.uni-bremen.de>
Message-ID: <CAJuCY5zmckbKjgmFQJtJ72-3Dic3Wn39ixEeVUk8cfAmRrdfDQ@mail.gmail.com>

Dear Tim,

Have a look at the INLA package (www.r-inla.org). It allows you to model
spatially correlated random effects, temporally correlated random effects,
use a negative binomial distribution and specify linear combination (needed
for the posthoc tests). Downside: it's not for the faint of heart.

Having time as factor both in the fixed and random part is useless. See
http://rpubs.com/INBOstats/both_fixed_random

Assuming that you revisited the same locations, then a reasonable simple
model would be:

fit <- lme4::glmer.nb(abundance ~ time + (1|locationID))

pro:
- negative binomial
- repeated visits to the locations acknowledged
- post hoc test of time via glht

contra:
- compound symmetry correlation for location instead of spatial correlation
- no temporal correlation

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-23 22:39 GMT+01:00 <trichter at uni-bremen.de>:

>
> Dear list,
>
> i am very new to mixed models. My data encompasses species composition
> matrices from six different time points with spatial correlation structure.
> For each species, i want to know if there is a pure effect by time, f.e. if
> abundance changes can be purely explained by time alone.
> I used to glht() with time being a simple factor (so not accounting for
> the repetitive nature of my data), but this seems inapprobiate/wrong. So, i
> am actually trying to do:
>
> fit <- lme(fixed=abundance ~ time, random=~1|time, data,
> correlation=corxxx(form=~x.pos + y.pos))
>
> with time being a factor with 6 levels (a side question would be, if it
> would be better to use "time" as.time?)
>
> Because my data is actually negative binomially distributed, i was advised
> to use glmmPQL, but this gives me only intercepts, no significancies or
> ways to compare models by log likelihood or AIC.
>
> The basic question is, if that syntax is correct? Because i have seen many
> examples looking at interactions, but never anything where the only fixed
> predictor is also random. I do get an output, which i can interpret and
> which resembles what i can actually see from boxplots.
>
> The overarching question is, if there are post-hoc tests for repeated
> measurements of spatially autocorrelated, non-normally distributed data.
>
> Thank you, Tim
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From trichter at uni-bremen.de  Tue Nov 24 11:27:20 2015
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Tue, 24 Nov 2015 11:27:20 +0100
Subject: [R-sig-ME] GLMMs to identify the pure seasonal effect in a
 repeated measurement
In-Reply-To: <CAJuCY5zmckbKjgmFQJtJ72-3Dic3Wn39ixEeVUk8cfAmRrdfDQ@mail.gmail.com>
References: <20151123223944.Horde.ZGgk4c58-9gGUlnyuxBB0Ej@webmail.uni-bremen.de>
	<CAJuCY5zmckbKjgmFQJtJ72-3Dic3Wn39ixEeVUk8cfAmRrdfDQ@mail.gmail.com>
Message-ID: <56543B88.6000401@uni-bremen.de>

Dear Thierry,

many thanks for your answer. I checked the output of my models again, 
and the random term when time was both fixed and random, indeed was 
always almost zero.
I think, i should clarify my sampling design briefly.
The plot was subdivided in 30 subplots.
A subplot was subdivided into 12  sampling locations on a regular grid.
For each time point, a unique pair of 2 neighboring sampling locations 
were sampled.
Meaning, the x,y-coordinates are different for each sampling date, 
together they form a perfect grid with 360
points.
I can see using locationIDs, but technically they are not from the same 
exact location for each date;
which is why i liked the 'correlation' argument in the lme models, in 
which i could use x,y coordinates.

Is there a way to incorporate this into the glmer.nb model you have 
proposed?

Thank you very much!

Tim

On 24.11.2015 10:30, Thierry Onkelinx wrote:
> Dear Tim,
>
> Have a look at the INLA package (www.r-inla.org 
> <http://www.r-inla.org>). It allows you to model spatially correlated 
> random effects, temporally correlated random effects, use a negative 
> binomial distribution and specify linear combination (needed for the 
> posthoc tests). Downside: it's not for the faint of heart.
>
> Having time as factor both in the fixed and random part is useless. 
> See http://rpubs.com/INBOstats/both_fixed_random
>
> Assuming that you revisited the same locations, then a reasonable 
> simple model would be:
>
> fit <- lme4::glmer.nb(abundance ~ time + (1|locationID))
>
> pro:
> - negative binomial
> - repeated visits to the locations acknowledged
> - post hoc test of time via glht
>
> contra:
> - compound symmetry correlation for location instead of spatial 
> correlation
> - no temporal correlation
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2015-11-23 22:39 GMT+01:00 <trichter at uni-bremen.de 
> <mailto:trichter at uni-bremen.de>>:
>
>
>     Dear list,
>
>     i am very new to mixed models. My data encompasses species
>     composition matrices from six different time points with spatial
>     correlation structure. For each species, i want to know if there
>     is a pure effect by time, f.e. if abundance changes can be purely
>     explained by time alone.
>     I used to glht() with time being a simple factor (so not
>     accounting for the repetitive nature of my data), but this seems
>     inapprobiate/wrong. So, i am actually trying to do:
>
>     fit <- lme(fixed=abundance ~ time, random=~1|time, data,
>     correlation=corxxx(form=~x.pos + y.pos))
>
>     with time being a factor with 6 levels (a side question would be,
>     if it would be better to use "time" as.time?)
>
>     Because my data is actually negative binomially distributed, i was
>     advised to use glmmPQL, but this gives me only intercepts, no
>     significancies or ways to compare models by log likelihood or AIC.
>
>     The basic question is, if that syntax is correct? Because i have
>     seen many examples looking at interactions, but never anything
>     where the only fixed predictor is also random. I do get an output,
>     which i can interpret and which resembles what i can actually see
>     from boxplots.
>
>     The overarching question is, if there are post-hoc tests for
>     repeated measurements of spatially autocorrelated, non-normally
>     distributed data.
>
>     Thank you, Tim
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
Tim Richter-Heitmann (M.Sc.)
PhD Candidate



International Max-Planck Research School for Marine Microbiology
University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


From jfox at mcmaster.ca  Tue Nov 24 18:26:36 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 24 Nov 2015 17:26:36 +0000
Subject: [R-sig-ME] Fw: question about Type III sums of squares as
 computed	in "CAR'
In-Reply-To: <20151120.124420.27452.1@webmail02.dca.untd.com>
References: <20151120.124420.27452.1@webmail02.dca.untd.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F3CA8E@FHSDB2D11-2.csu.mcmaster.ca>

Dear Stanley,

I've found it very hard to ascertain from your messages what you've done, which is why I didn't responded earlier. Even this last message didn't come through very clearly, and as far as I can see, you haven't included the data necessary to reproduce what you've done. Maybe I've somehow missed it.

Here, however, is a nonsense example of apparently the same structure as yours using the Mroz data set in the car package:

----------- snip ----------

> library(car)
> Mroz$k <- with(Mroz, factor(k5 != 0))
> options(contrasts=c("contr.sum", "contr.poly"))

> (mod <- lm(log(inc + 1) ~ wc + hc + hc:lfp + wc:k, data=Mroz))

Call:
lm(formula = log(inc + 1) ~ wc + hc + hc:lfp + wc:k, data = Mroz)

Coefficients:
(Intercept)          wc1          hc1    hcno:lfp1   hcyes:lfp1      wcno:k1     wcyes:k1  
   2.976605    -0.087079    -0.184151     0.086135     0.090067     0.076088     0.001294  

> Anova(mod)
Anova Table (Type II tests)

Response: log(inc + 1)
           Sum Sq  Df F value    Pr(>F)    
wc          1.879   1  8.5965  0.003471 ** 
hc         17.084   1 78.1708 < 2.2e-16 ***
hc:lfp      5.297   2 12.1190 6.614e-06 ***
wc:k        1.755   2  4.0146  0.018441 *  
Residuals 163.036 746                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

> Anova(mod, type=3)
Anova Table (Type III tests)

Response: log(inc + 1)
            Sum Sq  Df    F value    Pr(>F)    
(Intercept) 3621.1   1 16569.0315 < 2.2e-16 ***
wc             2.5   1    11.4747 0.0007425 ***
hc            16.9   1    77.1361 < 2.2e-16 ***
hc:lfp         5.3   2    12.1190 6.614e-06 ***
wc:k           1.8   2     4.0146 0.0184413 *  
Residuals    163.0 746                         
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 

> Mroz2 <- Mroz
> Mroz2[Mroz2$hc=="no" & Mroz2$lfp == "no", "lfp"] <- NA # introduce empty cell

> (mod2 <- lm(log(inc + 1) ~ wc + hc + hc:lfp + wc:k, data=Mroz2))

Call:
lm(formula = log(inc + 1) ~ wc + hc + hc:lfp + wc:k, data = Mroz2)

Coefficients:
(Intercept)          wc1          hc1    hcno:lfp1   hcyes:lfp1      wcno:k1     wcyes:k1  
    2.92816     -0.08765     -0.22868           NA      0.09230      0.08494      0.01049  

> Anova(mod2)
Anova Table (Type II tests)

Response: log(inc + 1)
           Sum Sq  Df F value    Pr(>F)    
wc          1.767   1  8.2230  0.004298 ** 
hc         19.398   1 90.2766 < 2.2e-16 ***
hc:lfp      2.261   1 10.5239  0.001251 ** 
wc:k        1.238   2  2.8799  0.057004 .  
Residuals 116.029 540                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

> Anova(mod2, type=3) # fails
Error in Anova.III.lm(mod, error, singular.ok = singular.ok, ...) : 
  there are aliased coefficients in the model

> Anova(mod2, type=3, singular.ok=TRUE)
Anova Table (Type III tests)

Response: log(inc + 1)
             Sum Sq  Df    F value    Pr(>F)    
(Intercept) 2513.20   1 11696.4835 < 2.2e-16 ***
wc             2.19   1    10.1934  0.001492 ** 
hc            20.68   1    96.2614 < 2.2e-16 ***
hc:lfp         2.26   1    10.5239  0.001251 ** 
wc:k           1.24   2     2.8799  0.057004 .  
Residuals    116.03 540                         
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

-------------- snip ------------

Note that you have to use contrasts, such as those generated by contr.sum(), that are orthogonal in the basis of the design matrix for the "type-III" tests computed by Anova() to make sense, and that the computational approach to type-III tests taken by Anova() probably doesn't make sense when there is an empty cell. Note as well that your model isn't a mixed-effects model.

Best,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of m51988mnew at juno.com
> Sent: Friday, November 20, 2015 12:44 PM
> To: r-sig-mixed-models at r-project.org
> Cc: m51988mnew at juno.com
> Subject: [R-sig-ME] Fw: question about Type III sums of squares as
> computed in "CAR'
> 
> 
> 
> Please note: forwarded message attached
> 
> From: "m51988mnew at juno.com" <m51988mnew at juno.com>
> To: :r-sig-mixed-models at r-project.org
> Cc: m51988mnew at juno.com
> Subject: Fw: question about Type III sums of squares as computed in
> "CAR'
> Date: Fri, 20 Nov 2015 17:41:53 GMT
> 
> SiteDayyoccidbDate      110.004613a01      120.004555a02
> 130.001759a03      210.002755a04      220.00043a05      310.001138a06
> 320.005983a07      330.003027a08      410.001202a09      420.003261a010
> 430.00652a011      110.002368b61      120.001521b62      130.001381b73
> 210.004089b74      220.001139b75      310.000723b76      320.001017b77
> 330.001621b78      410.000562b89      420.002402b810      430.003053b811
> library(car)          exp <-
> read.table(file="example.csv",sep=",",header=TRUE)    exp$Site <-
> as.factor(exp$Site)        exp$Day <- as.factor(exp$Day)        exp$occ
> <- as.factor(exp$occ)        exp$idb  <- as.factor(exp$idb)
> exp$Date <- as.factor(exp$Date)        exp.lm1 <- lm(log(y) ~ occ + Date
> + occ: idb,data=exp)      an_lm13 <- Anova(exp.lm1, type=c("III"))
> an_lm12 <- Anova(exp.lm1, type=c("II"))       exp.lm2 <- lm(log(y) ~ occ
> + Site + Site:Day + occ:idb,data=exp)     an_lm23 <- Anova(exp.lm2, t!
>  ype=c("III"))      an_lm22 <- Anova(exp.lm2, type=c("II"))
> exp.lm3 <- lm(log(y) ~  Site + Site:Day ,data=exp)       an_lm33 <-
> Anova(exp.lm3, type=c("III"))      an_lm32 <- Anova(exp.lm3,
> type=c("II"))                                           r output:
> > library(car)          > exp <-
> read.table(file="example.csv",sep=",",header=TRUE)      > exp$Site <-
> as.factor(exp$Site)        > exp$Day <- as.factor(exp$Day)        >
> exp$occ <- as.factor(exp$occ)        > exp$idb  <- as.factor(exp$idb)
> > exp$Date <- as.factor(exp$Date)        > exp.lm1 <- lm(log(y) ~ occ +
> Date + occ: idb,data=exp)      >  an_lm13 <- Anova(exp.lm1,
> type=c("III"))       Error in Anova.III.lm(mod, error, singular.ok =
> singular.ok, ...) :       there are aliased coefficients in the model
> > an_lm12 <- Anova(exp.lm1, type=c("II"))       > exp.lm2 <- lm(log(y) ~
> occ + Site + Site:Day + occ:idb,data=exp)     >  an_lm23 <-
> Anova(exp.lm2, type=c("III"))       Error in Anova.III.lm(mod!
>  , error, singular.ok = singular.ok, ...) :       there are aliased coe
> fficients in the model       > an_lm22 <- Anova(exp.lm2, type=c("II"))
> > exp.lm3 <- lm(log(y) ~  Site + Site:Day ,data=exp)       >  an_lm33 <-
> Anova(exp.lm3, type=c("III"))       Error in Anova.III.lm(mod, error,
> singular.ok = singular.ok, ...) :       there are aliased coefficients
> in the model       > an_lm32 <- Anova(exp.lm3, type=c("II"))       >
> 
> Please note: forwarded message attached
> 
> From: "m51988mnew at juno.com" <m51988mnew at juno.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Fw: question about Type III sums of squares as computed in
> "CAR'
> Date: Fri, 20 Nov 2015 15:52:48 GMT
> 
> I have attached the example data and the r-code and r messages.The data
> are example measurements of exposures on 2 occupations ( a and b)on 11
> sampling days.  Each occupation  has one measurement per day.  The 11
> sampling days are at 4 sites:  3 days at 3 of the sites and  2 days at 1
> site.  In addition, there were three  workers who did the second
> occupation  , labelled 6,7,8, for the variable idb.  I need the SAS type
> III sums of squares for each of the variables in the model, but you can
> see the error message in the R code: there are aliased coefficients in
> the model In SAS I believe that this problem is dealt with by placing
> constraints on the parameters.I would appreciate any suggestions.  I
> think that maybe I am formulating the model wrong.  Thanks,Stanley
> Shulman
> 
> ---------- Forwarded Message ----------
> From: "m51988mnew at juno.com" <m51988mnew at juno.com>
> To: r-sig-mixed-models at r-project.org
> Subject: question about Type III sums of squares as computed in "CAR'
> Date: Wed, 18 Nov 2015 02:25:03 GMT
> 
> When I use "Anova" from the car library, I cannot get Type III sums of
>  squares for nested data.  Maybe I am using the program wrong. SAS gives
> the
>  Type III sums of squares. Thanks for any thoughts.Stanley Shulman
> 
> ____________________________________________________________
> NetZero now offers 4G mobile broadband. Sign up now.
> http://www.netzero.net/?refcd=NZINTISP0512T4GOUT1
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Nov 24 19:42:39 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Nov 2015 13:42:39 -0500
Subject: [R-sig-ME] Problems with model (assumptions)
In-Reply-To: <56532EEE.4080204@gmail.com>
References: <564F1D60.1000904@gmail.com>
	<CAJuCY5xjgam-EbhCdhY4CHbfyW-QY4LWafMqq3eh2NGk7KT49g@mail.gmail.com>
	<CABghstR8yTVQ8qqYUGN0zZR0CbP3arPdV8YBZLUmB2szbNivCg@mail.gmail.com>
	<56532EEE.4080204@gmail.com>
Message-ID: <CABghstS4JX8BDb4A_ifUN4WyQ9qE0N7NS2qJ-xbyOXfKsa-jBQ@mail.gmail.com>

On Mon, Nov 23, 2015 at 10:21 AM, Philipp Singer <killver at gmail.com> wrote:
> Thanks for both of your answers.
>
> I will proceed with the log transformed version then as this definitly
> provides the best fit.
>
> One more question though regarding the point made by Thierry regarding the
> residuals:
> I thought that when looking at scaled residuals (pearson or deviance) they
> should be distributed normally (at least asymptotically). Is this wrong?


   Yes, asymptotically, but the relevant limit is "large samples per
point" rather than "large numbers of points" -- that is, Poisson or
negative binomial or binomial samples must have a large mean count [or
intermediate in the case of binomial, i.e. not to close to 100%], in
which case the conditional distribution converges to normality, but
with different variances depending on the mean, which gets corrected
by Pearson/deviance residual computation.    In the low-count case
(which is where most GLModeling gets done) the assumption may not
hold.  It's particularly terrible for Bernoulli responses.

   In looking at your model again, I wonder: why are you treating
length as a random effect?  I would think that lengths would be
generally better modeled as continuous covariates, e.g. via an
additive model/spline term in the linear model.


>
> Thanks a lot guys!
> Philipp
>
>
> On 11/23/2015 02:59 PM, Ben Bolker wrote:
>>
>> I *can* see the plots; it looks to me like Philipp's
>> log-transformation is almost perfect (the Q-Q plot shows a tiny bit of
>> a skew, but I wouldn't worry about it).  The model gives you a
>> convergence warning with magnitude 0.002, but we know from experience
>> (see ?convergence) that especially for 10^6 observations this is
>> probably a false positive.  I would definitely recommend proceeding
>> with
>>
>> m_lmer_log = lmer(log(body_length)~1+index+(1|author)+(1|length),
>> data=data, REML=FALSE)
>>
>> (i.e. line 84).
>>
>>
>> For count data with a large mean (your intercept is approx. 230),
>> log-transforming seems perfectly reasonable.
>>
>> On Mon, Nov 23, 2015 at 3:17 AM, Thierry Onkelinx
>> <thierry.onkelinx at inbo.be> wrote:
>>>
>>> Dear Philipp,
>>>
>>> I'm missing the graphs for the data exploration step in the notebook. So
>>> you can get an idea if the relations of with the explanatory variables
>>> are
>>> (log)linear.
>>>
>>> The residual plot from the Gaussian model are typical when modelling
>>> count
>>> data. So you need a Poisson or negative binomial distribution.
>>>
>>> normal qqplots for glm models are irrelevant. residuals versus fit are
>>> difficult to interpret. You should focus on residuals versus explanatory
>>> variables (fixed and random).
>>>
>>> You could consider using length as an offset factor. That seems to make
>>> more sense than as a random effect. Since length is the maximum body
>>> length
>>> per author, you would model the relative body length per author.
>>>
>>> There are other R packages that can fit glmm. glmmADMB, INLA, ... You can
>>> try them and see what happens.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and
>>> Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> 2015-11-20 14:17 GMT+01:00 Philipp Singer <killver at gmail.com>:
>>>
>>>> Dear all,
>>>>
>>>> I am currently trying to investigate the effect of time (in the sense of
>>>> an index) on the length of a text that people write (body_length). So,
>>>> e.g., my hypothesis is that the later someone writes a text, the shorter
>>>> it
>>>> is. All authors do not write the same amount of individual texts, thus I
>>>> have an additional variable that captures the maximum index (length).
>>>> One
>>>> further thing to note is that authors can have several "sessions" on
>>>> different days.
>>>>
>>>> I have started to use a linear mixed-effects model. However, the basic
>>>> assumptions of linear regression do not seem to hold (e.g., normality of
>>>> residuals) which is to be expected for count data (text length).
>>>>
>>>> Thus, I have tried several other GLMs and adaptions. However, for most
>>>> of
>>>> them, the assumptions do not hold as well. Also, I receive several odd
>>>> errors for some models.
>>>>
>>>> The best results can be achieved when I just log transform the outcome
>>>> and
>>>> use linear regression. However, as suggested in literature, this is not
>>>> the
>>>> proper way of treating count data.
>>>>
>>>> One thing to note is, that my data is enormeous (50mio. data points). I
>>>> have worked with a sample of 1mio datapoints here, results for the whole
>>>> data are similar though.
>>>>
>>>> Instead of now individually highlighting all the results in this mail, I
>>>> have decided to prepare an iPython notebook (using R and lme4) that
>>>> should
>>>> convey my main procedure that I have conducted until now.
>>>>
>>>> It can be found here:
>>>> https://nbviewer.jupyter.org/gist/anonymous/2897dd277a35a0df52ea
>>>>
>>>> I am hoping for some advice on how to proceed.
>>>>
>>>> Thanks in advance!
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From killver at gmail.com  Tue Nov 24 19:55:14 2015
From: killver at gmail.com (Philipp Singer)
Date: Tue, 24 Nov 2015 19:55:14 +0100
Subject: [R-sig-ME] Problems with model (assumptions)
In-Reply-To: <CABghstS4JX8BDb4A_ifUN4WyQ9qE0N7NS2qJ-xbyOXfKsa-jBQ@mail.gmail.com>
References: <564F1D60.1000904@gmail.com>
	<CAJuCY5xjgam-EbhCdhY4CHbfyW-QY4LWafMqq3eh2NGk7KT49g@mail.gmail.com>
	<CABghstR8yTVQ8qqYUGN0zZR0CbP3arPdV8YBZLUmB2szbNivCg@mail.gmail.com>
	<56532EEE.4080204@gmail.com>
	<CABghstS4JX8BDb4A_ifUN4WyQ9qE0N7NS2qJ-xbyOXfKsa-jBQ@mail.gmail.com>
Message-ID: <5654B292.7070400@gmail.com>



On 11/24/2015 07:42 PM, Ben Bolker wrote:
> In looking at your model again, I wonder: why are you treating length 
> as a random effect? I would think that lengths would be generally 
> better modeled as continuous covariates, e.g. via an additive 
> model/spline term in the linear model.

Actually, the length is basically the max index of the session, so 
session length.

I thought about whether to include it as a covariate or as a random effect.

I ended up with latter due to the fact that this should help with the 
stabilization of parameters which is specifically true in case of 
imbalance of lengths. Also, when comparing models, the one with the 
random effect performs better.

Maybe I should just incorporate it as a covariate as suggested, the 
inference on the index stays the same. I have actually also done that 
from time to time to speed up things and when crossed random effects 
made troubles.

Thanks!


From hughes.dupond at gmx.de  Tue Nov 24 23:06:51 2015
From: hughes.dupond at gmx.de (Lionel)
Date: Tue, 24 Nov 2015 23:06:51 +0100
Subject: [R-sig-ME] Time as both fixed and random term
Message-ID: <5654DF7B.5090704@gmx.de>

Dear List,

In my work we usually deals with measures sampled repeatedly on 
experimental units over several time points and with specific 
treatments. For example we sampled plant biomass on 100 experimental 
plots at 5 different time point (say season or year). Some people argue 
that in this context we should model time as both a fixed effect term 
(as continuous variable) and random effect term in order to compute the 
correct numbers of degrees of freedom to test our treatment effects 
(usually considered as a continuous variables).

This is how such a model would look like:

Biomass ~ Treatment + Time + (1|Plot) + (1|Time)

In my experience having the same term has both fixed and random results 
in very low estimated standard deviation for the random term, which 
makes me skeptical about this approach. But having very little knowledge 
about how to correctly estimate the numbers of degrees of freedom I 
would like to ask you:

(i) if such a model makes sense,
(ii) if the argument "we need to have time as both fixed and random term 
to get the correct number of degrees of freedom" is valid
(iii) if such an alternative model: "Biomass ~ Treatment + Time + 
(1|Plot)" would be more appropriate.

Thanks for your input,
Lionel


From shi_peijian at 163.com  Wed Nov 25 04:08:07 2015
From: shi_peijian at 163.com (shi_peijian)
Date: Wed, 25 Nov 2015 11:08:07 +0800 (CST)
Subject: [R-sig-ME] Time as both fixed and random term
In-Reply-To: <5654DF7B.5090704@gmx.de>
References: <5654DF7B.5090704@gmx.de>
Message-ID: <68d86bea.5ddb.1513c9ccb8a.Coremail.shi_peijian@163.com>

Dear all,


Could I additonally ask a question?
    fit1 <- Biomass ~ Treatment + Time + (1|Plot), where 'Time' is a continuous covariate
    fit2 <- Biomass ~ Treatment  + (1|Time/Plot), where 'Time' is a factor variable


    fit3 <- Biomass ~ Treatment + (1|Time), where 'Time' is also a factor variable


If AIC(fit3) is smaller than AIC(fit1) and AIC(fit2), can we choose fit3 rather than fit1?


Thanks a lot!


Best regards,


Joe



--


Peijian (Joe)  Shi, Ph.D.

Research interests: forest ecology; theoretical ecology; thermal biology

Member of China Ornithological Society from 2005 up to the present

Bamboo Research Institute, Nanjing Forestry University, P.R. China

159 Longpan Road, Nanjing City, Jiangsu Province 210037

Office:  60817  Biotechnology Building

Tel:  +86 25 85427231 

E-mail addresses:  peijianshi at gmail.com  

                               shi_peijian at 163.com      




At 2015-11-25 06:06:51, "Lionel" <hughes.dupond at gmx.de> wrote:
>Dear List,
>
>In my work we usually deals with measures sampled repeatedly on 
>experimental units over several time points and with specific 
>treatments. For example we sampled plant biomass on 100 experimental 
>plots at 5 different time point (say season or year). Some people argue 
>that in this context we should model time as both a fixed effect term 
>(as continuous variable) and random effect term in order to compute the 
>correct numbers of degrees of freedom to test our treatment effects 
>(usually considered as a continuous variables).
>
>This is how such a model would look like:
>
>Biomass ~ Treatment + Time + (1|Plot) + (1|Time)
>
>In my experience having the same term has both fixed and random results 
>in very low estimated standard deviation for the random term, which 
>makes me skeptical about this approach. But having very little knowledge 
>about how to correctly estimate the numbers of degrees of freedom I 
>would like to ask you:
>
>(i) if such a model makes sense,
>(ii) if the argument "we need to have time as both fixed and random term 
>to get the correct number of degrees of freedom" is valid
>(iii) if such an alternative model: "Biomass ~ Treatment + Time + 
>(1|Plot)" would be more appropriate.
>
>Thanks for your input,
>Lionel
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From kalakouentin at gmail.com  Wed Nov 25 04:59:50 2015
From: kalakouentin at gmail.com (Pantelis Hadjipantelis)
Date: Tue, 24 Nov 2015 19:59:50 -0800
Subject: [R-sig-ME] Time as both fixed and random term
In-Reply-To: <68d86bea.5ddb.1513c9ccb8a.Coremail.shi_peijian@163.com>
References: <5654DF7B.5090704@gmx.de>
	<68d86bea.5ddb.1513c9ccb8a.Coremail.shi_peijian@163.com>
Message-ID: <56553236.3000108@gmail.com>

Hello Joe,

I think that discretising a continuous variable can be unnatural and 
make a model hard to interpreter. AIC while extremely helpful is not a 
panacea.
Unless I had distinctly clustered measurement times and I could 
additionally assume that the time-dependence of the data is very 
weak/non-existent I would actively avoid treating time as factor.

Best regards,
Pantelis

On 11/24/2015 07:08 PM, shi_peijian wrote:
> Dear all,
>
>
> Could I additonally ask a question?
>      fit1 <- Biomass ~ Treatment + Time + (1|Plot), where 'Time' is a continuous covariate
>      fit2 <- Biomass ~ Treatment  + (1|Time/Plot), where 'Time' is a factor variable
>
>
>      fit3 <- Biomass ~ Treatment + (1|Time), where 'Time' is also a factor variable
>
>
> If AIC(fit3) is smaller than AIC(fit1) and AIC(fit2), can we choose fit3 rather than fit1?
>
>
> Thanks a lot!
>
>
> Best regards,
>
>
> Joe
>
>
>
> --
>
>
> Peijian (Joe)  Shi, Ph.D.
>
> Research interests: forest ecology; theoretical ecology; thermal biology
>
> Member of China Ornithological Society from 2005 up to the present
>
> Bamboo Research Institute, Nanjing Forestry University, P.R. China
>
> 159 Longpan Road, Nanjing City, Jiangsu Province 210037
>
> Office:  60817  Biotechnology Building
>
> Tel:  +86 25 85427231
>
> E-mail addresses:  peijianshi at gmail.com
>
>                                 shi_peijian at 163.com
>
>
>
>
> At 2015-11-25 06:06:51, "Lionel" <hughes.dupond at gmx.de> wrote:
>> Dear List,
>>
>> In my work we usually deals with measures sampled repeatedly on
>> experimental units over several time points and with specific
>> treatments. For example we sampled plant biomass on 100 experimental
>> plots at 5 different time point (say season or year). Some people argue
>> that in this context we should model time as both a fixed effect term
>> (as continuous variable) and random effect term in order to compute the
>> correct numbers of degrees of freedom to test our treatment effects
>> (usually considered as a continuous variables).
>>
>> This is how such a model would look like:
>>
>> Biomass ~ Treatment + Time + (1|Plot) + (1|Time)
>>
>> In my experience having the same term has both fixed and random results
>> in very low estimated standard deviation for the random term, which
>> makes me skeptical about this approach. But having very little knowledge
>> about how to correctly estimate the numbers of degrees of freedom I
>> would like to ask you:
>>
>> (i) if such a model makes sense,
>> (ii) if the argument "we need to have time as both fixed and random term
>> to get the correct number of degrees of freedom" is valid
>> (iii) if such an alternative model: "Biomass ~ Treatment + Time +
>> (1|Plot)" would be more appropriate.
>>
>> Thanks for your input,
>> Lionel
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.debes at utu.fi  Wed Nov 25 08:42:16 2015
From: paul.debes at utu.fi (paul debes)
Date: Wed, 25 Nov 2015 09:42:16 +0200
Subject: [R-sig-ME] Time as both fixed and random term
In-Reply-To: <5654DF7B.5090704@gmx.de>
References: <5654DF7B.5090704@gmx.de>
Message-ID: <op.x8nboqhya3mgvf@armadillo.utu.fi>

Hi Lionel & List,

An easy-to-implement approach estimating overall time trends (i.e.,  
including Time as a fixed effect) while accounting for deviations from  
this trend for each plot could be to include random Time-by-Plot trends.  
This will result in the 'right' degrees of freedom for the overall time  
trend (have you thought about possible Treatment-by-Time interactions?) so  
statement ii) may be true if the Time trend varies among Plots or if you  
want to account for your study design in terms of Time. Possible meanings  
of including "Time" as both a fixed and a random term was just recently  
discussed by the list, but I think here you actually refer to having a  
random Time-by-Plot interaction term in your model.

Nevertheless, you can model this potential within-plot across-time data  
correlation by many other different ways, depending on your data. The  
above-mentioned random coefficient model (fitting random Time trends for  
each Plot) is only one way and your data may fit other covariance models  
better (e.g., when treating Time as a factor: ar1, us, ante, etc). Maybe  
it is best you check a book on time series models to get a better overview  
what is possible and how to decide on an adequate covariance structure for  
your data.
Not all of the many possible covariance structures can be fitted in lme4,  
nlme may be more flexible.

One of the most complicated covariance structures (that needs loads of  
data) to start with would be:
Biomass ~ Treatment + Time + (factor(Time)|Plot)

One of the least complicated would be:
Biomass ~ Treatment + Time + (Time|Plot)

Hope this helps,
Paul



On Wed, 25 Nov 2015 00:06:51 +0200, Lionel <hughes.dupond at gmx.de> wrote:

> Dear List,
>
> In my work we usually deals with measures sampled repeatedly on  
> experimental units over several time points and with specific  
> treatments. For example we sampled plant biomass on 100 experimental  
> plots at 5 different time point (say season or year). Some people argue  
> that in this context we should model time as both a fixed effect term  
> (as continuous variable) and random effect term in order to compute the  
> correct numbers of degrees of freedom to test our treatment effects  
> (usually considered as a continuous variables).
>
> This is how such a model would look like:
>
> Biomass ~ Treatment + Time + (1|Plot) + (1|Time)
>
> In my experience having the same term has both fixed and random results  
> in very low estimated standard deviation for the random term, which  
> makes me skeptical about this approach. But having very little knowledge  
> about how to correctly estimate the numbers of degrees of freedom I  
> would like to ask you:
>
> (i) if such a model makes sense,
> (ii) if the argument "we need to have time as both fixed and random term  
> to get the correct number of degrees of freedom" is valid
> (iii) if such an alternative model: "Biomass ~ Treatment + Time +  
> (1|Plot)" would be more appropriate.
>
> Thanks for your input,
> Lionel
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland


From hughes.dupond at gmx.de  Wed Nov 25 17:50:50 2015
From: hughes.dupond at gmx.de (Lionel)
Date: Wed, 25 Nov 2015 17:50:50 +0100
Subject: [R-sig-ME] Time as both fixed and random term
In-Reply-To: <op.x8nboqhya3mgvf@armadillo.utu.fi>
References: <5654DF7B.5090704@gmx.de> <op.x8nboqhya3mgvf@armadillo.utu.fi>
Message-ID: <5655E6EA.505@gmx.de>

Hi Paul,

Thanks for your answer, there are (as always) some complexities:

- we usually measure and assume our units to be homogeneously affected 
by time (ie no time|plot terms), this is because our units are either on 
the same site or come from microcosm/mesocosm.

- we usually have limited time repetition (~5) so modelling it using 
complex autocorrelation structure is not possible.

Yours,
Lionel

On 25/11/2015 08:42, paul debes wrote:
> Hi Lionel & List,
>
> An easy-to-implement approach estimating overall time trends (i.e.,
> including Time as a fixed effect) while accounting for deviations from
> this trend for each plot could be to include random Time-by-Plot trends.
> This will result in the 'right' degrees of freedom for the overall time
> trend (have you thought about possible Treatment-by-Time interactions?)
> so statement ii) may be true if the Time trend varies among Plots or if
> you want to account for your study design in terms of Time. Possible
> meanings of including "Time" as both a fixed and a random term was just
> recently discussed by the list, but I think here you actually refer to
> having a random Time-by-Plot interaction term in your model.
>
> Nevertheless, you can model this potential within-plot across-time data
> correlation by many other different ways, depending on your data. The
> above-mentioned random coefficient model (fitting random Time trends for
> each Plot) is only one way and your data may fit other covariance models
> better (e.g., when treating Time as a factor: ar1, us, ante, etc). Maybe
> it is best you check a book on time series models to get a better
> overview what is possible and how to decide on an adequate covariance
> structure for your data.
> Not all of the many possible covariance structures can be fitted in
> lme4, nlme may be more flexible.
>
> One of the most complicated covariance structures (that needs loads of
> data) to start with would be:
> Biomass ~ Treatment + Time + (factor(Time)|Plot)
>
> One of the least complicated would be:
> Biomass ~ Treatment + Time + (Time|Plot)
>
> Hope this helps,
> Paul
>
>
>
> On Wed, 25 Nov 2015 00:06:51 +0200, Lionel <hughes.dupond at gmx.de> wrote:
>
>> Dear List,
>>
>> In my work we usually deals with measures sampled repeatedly on
>> experimental units over several time points and with specific
>> treatments. For example we sampled plant biomass on 100 experimental
>> plots at 5 different time point (say season or year). Some people
>> argue that in this context we should model time as both a fixed effect
>> term (as continuous variable) and random effect term in order to
>> compute the correct numbers of degrees of freedom to test our
>> treatment effects (usually considered as a continuous variables).
>>
>> This is how such a model would look like:
>>
>> Biomass ~ Treatment + Time + (1|Plot) + (1|Time)
>>
>> In my experience having the same term has both fixed and random
>> results in very low estimated standard deviation for the random term,
>> which makes me skeptical about this approach. But having very little
>> knowledge about how to correctly estimate the numbers of degrees of
>> freedom I would like to ask you:
>>
>> (i) if such a model makes sense,
>> (ii) if the argument "we need to have time as both fixed and random
>> term to get the correct number of degrees of freedom" is valid
>> (iii) if such an alternative model: "Biomass ~ Treatment + Time +
>> (1|Plot)" would be more appropriate.
>>
>> Thanks for your input,
>> Lionel
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From thierry.onkelinx at inbo.be  Thu Nov 26 09:23:16 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 26 Nov 2015 09:23:16 +0100
Subject: [R-sig-ME] GLMMs to identify the pure seasonal effect in a
 repeated measurement
In-Reply-To: <56543B88.6000401@uni-bremen.de>
References: <20151123223944.Horde.ZGgk4c58-9gGUlnyuxBB0Ej@webmail.uni-bremen.de>
	<CAJuCY5zmckbKjgmFQJtJ72-3Dic3Wn39ixEeVUk8cfAmRrdfDQ@mail.gmail.com>
	<56543B88.6000401@uni-bremen.de>
Message-ID: <CAJuCY5zdiUreHPRiSQy_rtjSP5yfhn1Dio5g1rHXZ0h6V21Eaw@mail.gmail.com>

Dear Tim,

lme4::glmer.nb(abundance ~ time + (1|SubplotID)) is as close as you can get
with lme4.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-24 11:27 GMT+01:00 Tim Richter-Heitmann <trichter at uni-bremen.de>:

> Dear Thierry,
>
> many thanks for your answer. I checked the output of my models again, and
> the random term when time was both fixed and random, indeed was always
> almost zero.
> I think, i should clarify my sampling design briefly.
> The plot was subdivided in 30 subplots.
> A subplot was subdivided into 12  sampling locations on a regular grid.
> For each time point, a unique pair of 2 neighboring sampling locations
> were sampled.
> Meaning, the x,y-coordinates are different for each sampling date,
> together they form a perfect grid with 360
> points.
> I can see using locationIDs, but technically they are not from the same
> exact location for each date;
> which is why i liked the 'correlation' argument in the lme models, in
> which i could use x,y coordinates.
>
> Is there a way to incorporate this into the glmer.nb model you have
> proposed?
>
> Thank you very much!
>
> Tim
>
> On 24.11.2015 10:30, Thierry Onkelinx wrote:
>
>> Dear Tim,
>>
>> Have a look at the INLA package (www.r-inla.org <http://www.r-inla.org>).
>> It allows you to model spatially correlated random effects, temporally
>> correlated random effects, use a negative binomial distribution and specify
>> linear combination (needed for the posthoc tests). Downside: it's not for
>> the faint of heart.
>>
>> Having time as factor both in the fixed and random part is useless. See
>> http://rpubs.com/INBOstats/both_fixed_random
>>
>> Assuming that you revisited the same locations, then a reasonable simple
>> model would be:
>>
>> fit <- lme4::glmer.nb(abundance ~ time + (1|locationID))
>>
>> pro:
>> - negative binomial
>> - repeated visits to the locations acknowledged
>> - post hoc test of time via glht
>>
>> contra:
>> - compound symmetry correlation for location instead of spatial
>> correlation
>> - no temporal correlation
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-11-23 22:39 GMT+01:00 <trichter at uni-bremen.de <mailto:
>> trichter at uni-bremen.de>>:
>>
>>
>>
>>     Dear list,
>>
>>     i am very new to mixed models. My data encompasses species
>>     composition matrices from six different time points with spatial
>>     correlation structure. For each species, i want to know if there
>>     is a pure effect by time, f.e. if abundance changes can be purely
>>     explained by time alone.
>>     I used to glht() with time being a simple factor (so not
>>     accounting for the repetitive nature of my data), but this seems
>>     inapprobiate/wrong. So, i am actually trying to do:
>>
>>     fit <- lme(fixed=abundance ~ time, random=~1|time, data,
>>     correlation=corxxx(form=~x.pos + y.pos))
>>
>>     with time being a factor with 6 levels (a side question would be,
>>     if it would be better to use "time" as.time?)
>>
>>     Because my data is actually negative binomially distributed, i was
>>     advised to use glmmPQL, but this gives me only intercepts, no
>>     significancies or ways to compare models by log likelihood or AIC.
>>
>>     The basic question is, if that syntax is correct? Because i have
>>     seen many examples looking at interactions, but never anything
>>     where the only fixed predictor is also random. I do get an output,
>>     which i can interpret and which resembles what i can actually see
>>     from boxplots.
>>
>>     The overarching question is, if there are post-hoc tests for
>>     repeated measurements of spatially autocorrelated, non-normally
>>     distributed data.
>>
>>     Thank you, Tim
>>
>>     _______________________________________________
>>     R-sig-mixed-models at r-project.org
>>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
> --
> Tim Richter-Heitmann (M.Sc.)
> PhD Candidate
>
>
>
> International Max-Planck Research School for Marine Microbiology
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
>
>

	[[alternative HTML version deleted]]


From gitumbui at gmail.com  Thu Nov 26 15:09:40 2015
From: gitumbui at gmail.com (Gitu wa Mbui)
Date: Fri, 27 Nov 2015 00:09:40 +1000
Subject: [R-sig-ME] Mixed modelling and Species Area Relationship (SAR)
Message-ID: <CAFPRYfCev4UPecF7ud7K8mu2P8q-8czX13zUFTMoFSFSQAYRyw@mail.gmail.com>

How does one account for the species area relationship in a mixed model of
predicting species richness?

Sampling was carried out using different methods - photoquadrats, transects
etc ( five different methods).

The area of the sampled plots differed and there were hundreds of plots. I
am constructing a glmm for predicting the species richness, overall, and
have configured the Method of sampling as a random intercept in the model.
I am wondering how I should construct the model such the influence of SAR
is taken into account - considering that SAR can not be a random factor.

~Gitu

	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Thu Nov 26 15:13:27 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 26 Nov 2015 15:13:27 +0100
Subject: [R-sig-ME] logistic regression with glmer, three ways
Message-ID: <CAAH-yP98VyAKs7qthN+c2UEu3Wp2hd3ajWkWvmJyARD5sXdmBA@mail.gmail.com>

Dear all,
I am trying to fit a logistic mixed model using lme4, and finding some
results I can't understand.
If I fit the model either using "cbind" (A) or representing counts using
weights (B), I get identical or virtually identical results. If I fit the
model with one observation per row (C), I also get the same random effects
variances and fixed effects estimates... but the standard errors are very
different.
What am I missing, that explains this?
Full code for replication is below. Any help/clarification would be greatly
appreciated.
- Malcolm



library(lme4)

obj <- structure(list(wi = c(10004, 20004, 30002, 30003, 30004, 40004,
50003, 50004, 60002, 60003, 60004, 70004, 80002, 80003, 80004,
90002, 100003, 100004, 110004, 120002, 120003, 120004, 130002,
130003, 130004, 140003, 140004, 150002, 150003, 150004, 160002,
160003, 160004, 170004, 180002, 180003, 180004, 190002, 190003,
190004, 200003, 200004, 210002, 210003, 210004, 220002, 220003,
220004, 230002, 230003, 230004, 240002, 240003, 240004, 250004,
260003, 260004, 270004, 280003, 280004, 290004, 300002, 300003,
300004, 310004, 320004, 330002, 330003, 330004, 350002, 350004,
360002, 360003, 360004, 370002, 370003, 370004, 380003, 380004,
390003, 390004, 400004, 410003, 410004, 420003, 420004, 430002,
430003, 430004, 440002, 440003, 440004, 450004, 460003, 460004,
470003, 470004, 480002), X0 = c(713L, 422L, 755L, 868L, 693L,
661L, 254L, 446L, 1399L, 684L, 312L, 484L, 223L, 274L, 429L,
615L, 467L, 536L, 473L, 846L, 830L, 731L, 648L, 563L, 554L, 490L,
747L, 394L, 598L, 560L, 379L, 479L, 325L, 337L, 2040L, 943L,
1012L, 453L, 506L, 366L, 923L, 1097L, 375L, 304L, 562L, 396L,
483L, 369L, 175L, 217L, 243L, 1061L, 927L, 425L, 337L, 434L,
715L, 730L, 524L, 630L, 492L, 20L, 76L, 79L, 535L, 494L, 481L,
328L, 319L, 833L, 700L, 230L, 436L, 783L, 297L, 218L, 184L, 157L,
410L, 932L, 540L, 409L, 376L, 420L, 534L, 637L, 872L, 474L, 325L,
820L, 738L, 704L, 421L, 411L, 809L, 340L, 468L, 413L), X1 = c(604L,
979L, 679L, 580L, 743L, 638L, 667L, 857L, 1363L, 1148L, 1194L,
901L, 792L, 618L, 765L, 1103L, 467L, 853L, 425L, 1232L, 908L,
844L, 347L, 348L, 894L, 379L, 623L, 140L, 384L, 352L, 551L, 1078L,
1163L, 901L, 1381L, 1008L, 926L, 1335L, 1414L, 1610L, 190L, 333L,
588L, 628L, 904L, 290L, 426L, 399L, 824L, 770L, 630L, 948L, 977L,
960L, 981L, 416L, 488L, 472L, 586L, 892L, 816L, 373L, 925L, 1225L,
735L, 807L, 530L, 669L, 1186L, 394L, 370L, 631L, 535L, 625L,
874L, 759L, 1341L, 854L, 832L, 1239L, 736L, 888L, 812L, 792L,
407L, 620L, 1741L, 625L, 1080L, 226L, 208L, 187L, 751L, 765L,
1251L, 617L, 693L, 1401L), be = c(1, 2, 3, 3, 3, 4, 5, 5, 6,
6, 6, 7, 8, 8, 8, 9, 10, 10, 11, 12, 12, 12, 13, 13, 13, 14,
14, 15, 15, 15, 16, 16, 16, 17, 18, 18, 18, 19, 19, 19, 20, 20,
21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24, 24, 25, 26, 26, 27,
28, 28, 29, 30, 30, 30, 31, 32, 33, 33, 33, 35, 35, 36, 36, 36,
37, 37, 37, 38, 38, 39, 39, 40, 41, 41, 42, 42, 43, 43, 43, 44,
44, 44, 45, 46, 46, 47, 47, 48), xD = c(0.524307559318364,
0.763542402955787,
-0.175670143766333, 0.00982801368753794, 0.171734367713831,
0.853465151804533,
-0.120558155492305, 0.564928392055597, -0.155064052602568,
0.00679037740374344,
0.111975199497572, 0.512877661043456, -0.157973257281779,
-0.171234692228043,
0.419036653726705, -0.132665914601771, -0.150714124150286,
0.24994498095932,
0.206700520630643, -0.208268170700368, -0.0750100628941794,
0.296858558168208,
-0.174592030130771, 0.0180614401400381, 0.128207276958865,
-0.214857479897565,
0.374642212780139, -0.134729936508285, 0.0533554402688754,
0.161401987751531,
-0.127379608982776, 0.008495320648783, 0.115214858592721, 0.42430939422253,
-0.134278135313655, -0.00190924064453402, 0.13491769790403,
-0.180932304380458,
-0.00605077384790365, 0.175496607807141, -0.0454797547642141,
0.242021561287634, -0.188556011418235, -0.061841275029169,
0.258249752442066,
-0.140950742135457, -0.0147706249172281, 0.191706749943735,
-0.457953860744226,
0.0707520487160007, 0.295169775614251, -0.118201446303778,
0.00559417031071785,
0.0187882678385503, 0.155675695667328, -0.254338988033491,
0.465851265111546,
0.115872339471522, 0.00880128187019125, 0.230608970064243,
0.225412467657899,
-0.267152578878703, 0.0646910643525653, 0.200582879060123,
0.21133836700213,
0.25249689149948, -0.189772066302413, 0.0244390231314893,
0.186314037458162,
-0.253461034585483, 0.156182014608826, -0.3060350195241,
0.00908366935986171,
0.37818509859163, -0.186216139704441, 0.0376706945549361,
0.127207172092761,
-0.182961496155655, 0.431715611799, -0.255051113988716, 0.380085409356923,
0.315317829875132, -0.0805760582482353, 0.414358344214618,
-0.097803077410747,
0.254981382125769, -0.191238180985892, 0.00488053924246579,
0.1715300555248,
-0.13917965385563, -0.00869608920645071, 0.139200601300228,
0.129019867839904,
-0.067090005487124, 0.178986504919836, -0.361092444872377,
0.306102862840488,
-0.167277811360057), xM = c(1.63256478157338, 1.23639947382672,
3.6113561255061, 3.6113561255061, 3.6113561255061, 1.81132913921155,
2.10837829325362, 2.10837829325362, 3.58252523980364, 3.58252523980364,
3.58252523980364, 1.72445279981385, 2.31322790712443, 2.31322790712443,
2.31322790712443, 3.57189978569991, 2.83531097614585, 2.83531097614585,
3.37202028911156, 3.07483904377024, 3.07483904377024, 3.07483904377024,
3.67882319468092, 3.67882319468092, 3.67882319468092, 2.83390807391282,
2.83390807391282, 3.48808505940913, 3.48808505940913, 3.48808505940913,
3.50918800324632, 3.50918800324632, 3.50918800324632, 1.35056965726225,
3.58350726435065, 3.58350726435065, 3.58350726435065, 3.45520042020839,
3.45520042020839, 3.45520042020839, 3.22983948291011, 3.22983948291011,
2.89167097993014, 2.89167097993014, 2.89167097993014, 3.49665408229335,
3.49665408229335, 3.49665408229335, 3.57003324070401, 3.57003324070401,
3.57003324070401, 3.54396756799594, 3.54396756799594, 3.54396756799594,
1.86800831970497, 2.57755160015926, 2.57755160015926, 3.02925424277375,
4.32327961159352, 4.32327961159352, 2.18172420173543, 3.12702563543265,
3.12702563543265, 3.12702563543265, 1.14700264441952, 2.39953372528027,
3.67205886070582, 3.67205886070582, 3.67205886070582, 4.0215200389434,
4.0215200389434, 2.61735400902176, 2.61735400902176, 2.61735400902176,
3.19592659160605, 3.19592659160605, 3.19592659160605, 2.46045386124236,
2.46045386124236, 2.73368404950427, 2.73368404950427, 2.21213125086224,
2.79123784432272, 2.79123784432272, 3.173043343244, 3.173043343244,
3.37451273144198, 3.37451273144198, 3.37451273144198, 3.569975263304,
3.569975263304, 3.569975263304, 3.8786709708336, 2.55946987580579,
2.55946987580579, 1.86429229550736, 1.86429229550736, 3.77987342556174
)), .Names = c("wi", "X0", "X1", "be", "xD", "xM"), row.names = c(1L,
2L, 3L, 4L, 5L, 6L, 7L, 8L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
18L, 19L, 20L, 21L, 22L, 23L, 24L, 26L, 27L, 28L, 29L, 30L, 31L,
32L, 33L, 35L, 36L, 37L, 38L, 40L, 41L, 42L, 44L, 45L, 46L, 47L,
48L, 49L, 50L, 51L, 53L, 54L, 55L, 57L, 58L, 59L, 61L, 62L, 63L,
64L, 65L, 66L, 69L, 70L, 71L, 72L, 74L, 75L, 76L, 77L, 78L, 80L,
81L, 82L, 85L, 86L, 87L, 88L, 89L, 90L, 91L, 92L, 93L, 94L, 95L,
96L, 97L, 99L, 100L, 102L, 103L, 105L, 106L, 107L, 109L, 110L,
111L, 112L, 113L, 114L, 115L, 116L, 118L), class = "data.frame", na.action
= structure(c(9L,
17L, 25L, 34L, 39L, 43L, 52L, 56L, 60L, 67L, 68L, 73L, 79L, 83L,
84L, 98L, 101L, 104L, 108L, 117L), .Names = c("9", "17", "25",
"34", "39", "43", "52", "56", "60", "67", "68", "73", "79", "83",
"84", "98", "101", "104", "108", "117"), class = "omit"))

objB <- reshape(obj, direction="long", varying=2:3, sep="", idvar="wi")
names(objB)[5:6] <- c("y", "count")
objC <- apply(obj, 1, function(Z) data.frame(rep(0:1, Z[2:3]),
matrix(rep(Z[c(1,4:6)], sum(Z[2:3])), ncol=4, byrow=T)))
objC <- do.call(rbind, objC)
names(objC) <- c("y", "wi", "be", "xD", "xM")
summary(glmer(cbind(X1, X0) ~ xD + xM + (1 | wi) + (1 | be), obj,
family=binomial))
summary(glmer(y ~ xD + xM + (1 | wi) + (1 | be), objB, family=binomial,
weights=count)) # throws a warning
summary(glmer(y ~ xD + xM + (1 | wi) + (1 | be), objC, family=binomial)) #
takes a minute or so on my machine

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Nov 26 15:21:07 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 26 Nov 2015 15:21:07 +0100
Subject: [R-sig-ME] Mixed modelling and Species Area Relationship (SAR)
In-Reply-To: <CAFPRYfCev4UPecF7ud7K8mu2P8q-8czX13zUFTMoFSFSQAYRyw@mail.gmail.com>
References: <CAFPRYfCev4UPecF7ud7K8mu2P8q-8czX13zUFTMoFSFSQAYRyw@mail.gmail.com>
Message-ID: <CAJuCY5yO5S_pm9oEYd0BFQG523PhZE5jrMWduDAJ+C2DJHue-A@mail.gmail.com>

Dear Gitu,

If the area is constant within each method, then the random effect of
method will model the area effect. If not you can add area to the fixed
effects of the model. You have several options: as an offset, as a
(log)linear trend, as a smoother, ... Much will depend on your assumption
on the relation between species richness and sample area.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-26 15:09 GMT+01:00 Gitu wa Mbui <gitumbui at gmail.com>:

> How does one account for the species area relationship in a mixed model of
> predicting species richness?
>
> Sampling was carried out using different methods - photoquadrats, transects
> etc ( five different methods).
>
> The area of the sampled plots differed and there were hundreds of plots. I
> am constructing a glmm for predicting the species richness, overall, and
> have configured the Method of sampling as a random intercept in the model.
> I am wondering how I should construct the model such the influence of SAR
> is taken into account - considering that SAR can not be a random factor.
>
> ~Gitu
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Nov 26 16:25:46 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 26 Nov 2015 10:25:46 -0500
Subject: [R-sig-ME] Mixed modelling and Species Area Relationship (SAR)
In-Reply-To: <CAFPRYfCev4UPecF7ud7K8mu2P8q-8czX13zUFTMoFSFSQAYRyw@mail.gmail.com>
References: <CAFPRYfCev4UPecF7ud7K8mu2P8q-8czX13zUFTMoFSFSQAYRyw@mail.gmail.com>
Message-ID: <5657247A.60708@gmail.com>

On 15-11-26 09:09 AM, Gitu wa Mbui wrote:
> How does one account for the species area relationship in a mixed model of
> predicting species richness?
> 
> Sampling was carried out using different methods - photoquadrats, transects
> etc ( five different methods).
> 
> The area of the sampled plots differed and there were hundreds of plots. I
> am constructing a glmm for predicting the species richness, overall, and
> have configured the Method of sampling as a random intercept in the model.
> I am wondering how I should construct the model such the influence of SAR
> is taken into account - considering that SAR can not be a random factor.
> 
> ~Gitu

  This is probably a little bit too vague for most of the people on the
list (who are not ecologists).

   Supposing that you're using a log link for the response (which would
make sense if you plan to treat species richness as Poisson or negative
binomial), try incorporating log(Area) as a covariate.  Then (ignoring
all the other stuff in your model for the moment)

  log(mu) = b0 + b1*log(area)

or

  mu = exp(b0)*exp(b1*log(area)) = C*area^b1

 which looks like a pretty respectable model for the species-area
relationship.

  Ben Bolker


From David.Duffy at qimrberghofer.edu.au  Fri Nov 27 00:11:44 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Fri, 27 Nov 2015 09:11:44 +1000
Subject: [R-sig-ME] logistic regression with glmer, three ways
In-Reply-To: <CAAH-yP98VyAKs7qthN+c2UEu3Wp2hd3ajWkWvmJyARD5sXdmBA@mail.gmail.com>
References: <CAAH-yP98VyAKs7qthN+c2UEu3Wp2hd3ajWkWvmJyARD5sXdmBA@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1511270846350.13116@orpheus.qimr.edu.au>

On Fri, 27 Nov 2015, Malcolm Fairbrother wrote:

> Dear all,
> I am trying to fit a logistic mixed model using lme4, and finding some
> results I can't understand.

FWIW, similar problems with just (1|wi). glmmML allows one RE, so it
can be run in a comparison:

A. cbind(X1, X0) ~ xD + xM + (1 | wi)

      glmer (laplace)  glmmML (laplace)
Int  1.2478 (0.4187)  1.2478 (0.4187)
xD  -0.3722 (0.3619) -0.3722 (0.3619)
xW  -0.2720 (0.1306) -0.2720 (0.1306)

C. y ~ xD + xM + (1 | wi)

      glmer (laplace)    glmmM (laplace)
Int  1.2478 (0.2240)  1.2714 (0.4175)
xD  -0.3722 (0.2842) -0.3894 (0.3608)
xW  -0.2720 (0.0732) -0.2794 (0.1302)


Most importantly, if you use AGQ instead of Laplace
the glmer SEs now all match.

glmer (nAGQ=10)

            Estimate Std. Error 
(Intercept)   1.2478     0.4196
xD           -0.3722     0.3627
xM           -0.2720     0.1309


| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From gitumbui at gmail.com  Fri Nov 27 03:22:37 2015
From: gitumbui at gmail.com (Gitu wa Mbui)
Date: Fri, 27 Nov 2015 12:22:37 +1000
Subject: [R-sig-ME] Mixed modelling and Species Area Relationship (SAR)
In-Reply-To: <CAJuCY5yO5S_pm9oEYd0BFQG523PhZE5jrMWduDAJ+C2DJHue-A@mail.gmail.com>
References: <CAFPRYfCev4UPecF7ud7K8mu2P8q-8czX13zUFTMoFSFSQAYRyw@mail.gmail.com>
	<CAJuCY5yO5S_pm9oEYd0BFQG523PhZE5jrMWduDAJ+C2DJHue-A@mail.gmail.com>
Message-ID: <CAFPRYfB2kBzm5DAE9PQx4KOqv=yp6NO7u9=xm+izGR+1N3dFvw@mail.gmail.com>

Thanks @TO and @BB. Sounds like there is a consensus that adding area as a
covariate (log area) is the way to go, considering a variable area among
methods. A few clarifications:

1. @TO - under what circumstances would you add area 'as an offset, as a
(log)linear trend, as a smoother'? please clarify

2. Would it make a difference if the model is smoothed spline? (i.e such
that: gamm4(response ~ s(Area) + s(b1, k..) +...)

~Gitu







On Fri, Nov 27, 2015 at 12:21 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Gitu,
>
> If the area is constant within each method, then the random effect of
> method will model the area effect. If not you can add area to the fixed
> effects of the model. You have several options: as an offset, as a
> (log)linear trend, as a smoother, ... Much will depend on your assumption
> on the relation between species richness and sample area.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-11-26 15:09 GMT+01:00 Gitu wa Mbui <gitumbui at gmail.com>:
>
>> How does one account for the species area relationship in a mixed model of
>> predicting species richness?
>>
>> Sampling was carried out using different methods - photoquadrats,
>> transects
>> etc ( five different methods).
>>
>> The area of the sampled plots differed and there were hundreds of plots. I
>> am constructing a glmm for predicting the species richness, overall, and
>> have configured the Method of sampling as a random intercept in the model.
>> I am wondering how I should construct the model such the influence of SAR
>> is taken into account - considering that SAR can not be a random factor.
>>
>> ~Gitu
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Fri Nov 27 15:11:13 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 27 Nov 2015 15:11:13 +0100
Subject: [R-sig-ME] logistic regression with glmer, three ways
In-Reply-To: <alpine.LMD.2.00.1511270846350.13116@orpheus.qimr.edu.au>
References: <CAAH-yP98VyAKs7qthN+c2UEu3Wp2hd3ajWkWvmJyARD5sXdmBA@mail.gmail.com>
	<alpine.LMD.2.00.1511270846350.13116@orpheus.qimr.edu.au>
Message-ID: <CAAH-yP8XSL-jeB8jEaOr_yRHjzaVO78p-=zSMEU5ox3HbOPwYA@mail.gmail.com>

Thanks to both Thierry and David for their suggestions.

I investigated the issue further, by fitting the same model using MCMCglmm
(which allows for approach A, with cbind, and C, with one Bernoulli trial
per row). The results are below.

The upshot is that the results from both A and C using MCMCglmm are similar
to each other, and to both of A and B using glmer (with Laplace).
Therefore, C with glmer (Laplace) appears to be the exception, and my
conclusion is that David is right that it's about the approximation.

- Malcolm



library(MCMCglmm)

prior <- list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=1, alpha.mu=0,
alpha.V=100), G2=list(V=1, nu=1, alpha.mu=0, alpha.V=100)))
modA.MC <- MCMCglmm(fixed=cbind(X1, X0) ~ xD + xM, random=~wi + be,
data=obj, family="multinomial2", prior=prior)

prior <- list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=1, alpha.mu=0,
alpha.V=100), G2=list(V=1, nu=1, alpha.mu=0, alpha.V=100)))
modC.MC <- MCMCglmm(fixed=y ~ xD + xM, random=~wi + be, data=objC,
family="categorical", prior=prior)

# note that residual variance is treated differently, so scales are
slightly different

> summary(modA.MC)
...
            post.mean l-95% CI u-95% CI eff.samp pMCMC
(Intercept)    0.9501   0.1047   1.8424   1000.0 0.040 *
xD            -0.0916  -0.4815   0.2895   1000.0 0.636
xM            -0.1903  -0.4585   0.1094    901.9 0.210

> summary(modC.MC)
...
            post.mean l-95% CI u-95% CI eff.samp pMCMC
(Intercept)   1.12976  0.05293  2.16752     1000 0.040 *
xD           -0.07997 -0.54759  0.35903     1000 0.732
xM           -0.22518 -0.57009  0.11479     1000 0.192

> summary(modA.MC$Sol)
...
               Mean     SD
(Intercept)  0.9501 0.4554
xD          -0.0916 0.2028
xM          -0.1903 0.1489

> summary(modC.MC$Sol)
...
                Mean     SD
(Intercept)  1.12976 0.5397
xD          -0.07997 0.2315
xM          -0.22518 0.1756




On 27 November 2015 at 00:11, David Duffy <David.Duffy at qimrberghofer.edu.au>
wrote:

> On Fri, 27 Nov 2015, Malcolm Fairbrother wrote:
>
> Dear all,
>> I am trying to fit a logistic mixed model using lme4, and finding some
>> results I can't understand.
>>
>
> FWIW, similar problems with just (1|wi). glmmML allows one RE, so it
> can be run in a comparison:
>
> A. cbind(X1, X0) ~ xD + xM + (1 | wi)
>
>      glmer (laplace)  glmmML (laplace)
> Int  1.2478 (0.4187)  1.2478 (0.4187)
> xD  -0.3722 (0.3619) -0.3722 (0.3619)
> xW  -0.2720 (0.1306) -0.2720 (0.1306)
>
> C. y ~ xD + xM + (1 | wi)
>
>      glmer (laplace)    glmmM (laplace)
> Int  1.2478 (0.2240)  1.2714 (0.4175)
> xD  -0.3722 (0.2842) -0.3894 (0.3608)
> xW  -0.2720 (0.0732) -0.2794 (0.1302)
>
>
> Most importantly, if you use AGQ instead of Laplace
> the glmer SEs now all match.
>
> glmer (nAGQ=10)
>
>            Estimate Std. Error (Intercept)   1.2478     0.4196
> xD           -0.3722     0.3627
> xM           -0.2720     0.1309
>
>
> | David Duffy (MBBS PhD)
> | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax:
> -0101
> | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
> | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A
>

	[[alternative HTML version deleted]]


From hans.ekbrand at gmail.com  Sat Nov 28 23:06:21 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sat, 28 Nov 2015 23:06:21 +0100
Subject: [R-sig-ME] glmer: var-cov estimated from RX
Message-ID: <20151128220621.GA24492@hans>

Dear list,

I ran glmer() on a large dataset (16 million rows), and after some
6000 minutes, it converged.

However, there were two (related) warnings:

1: In vcov.merMod(object, use.hessian = use.hessian) :
  variance-covariance matrix computed from finite-difference Hessian is
not positive definite: falling back to var-cov estimated from RX
2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
  variance-covariance matrix computed from finite-difference Hessian is
not positive definite: falling back to var-cov estimated from RX

I seek advice on where to go from here, and knowledge about the
concepts "MX" and "finite-difference Hessian" which I am unfamiliar
with.

Can I rely on the variance-covariance matrix I've got?

Should I try get rid of warning? If so, what could possibly help (is
it meaningful to try with a different optimizer?)? Since the
convergence time was about 5 days, trying out difference optimizers is
not very fun.

If it helps, here is the output of summary:

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: deprived.of.education ~ (1 | country) + (1 | lowest.regional.level) +  
    per.cent.muslim.in.country * sex + per.cent.hindu.in.country *  
    sex + per.cent.muslim.in.subregional.level * sex + per.cent.hindu.in.subregional.level *  
    sex + gdp.log + qog + wealth * sex * religion + mean.wealth.at.lowest.regional.level
   Data: my.df

     AIC      BIC   logLik deviance df.resid 
 4047602  4048056 -2023770  4047540 16959894 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-40.490   0.000   0.079   0.149   4.654 

Random effects:
 Groups                Name        Variance Std.Dev.
 lowest.regional.level (Intercept)  0.6495  0.8059  
 country               (Intercept) 39.2973  6.2688  
Number of obs: 16959925, groups:  lowest.regional.level, 3962; country, 31

Fixed effects:
                                               Estimate Std. Error z value Pr(>|z|)    
(Intercept)                                  -2.076e+01  1.150e+01   -1.81   0.0709 .  
per.cent.muslim.in.country                    9.057e-01  7.431e-01    1.22   0.2229    
sexMale                                       4.297e-02  5.193e-03    8.27  < 2e-16 ***
per.cent.hindu.in.country                    -4.599e-02  3.366e-02   -1.37   0.1718    
per.cent.muslim.in.subregional.level         -1.306e-02  9.290e-03   -1.41   0.1597    
per.cent.hindu.in.subregional.level          -1.234e-02  1.059e-03  -11.64  < 2e-16 ***
gdp.log                                       3.941e+00  1.548e+00    2.55   0.0109 *  
qog                                          -5.200e+00  3.048e+00   -1.71   0.0880 .  
wealthMiddle                                  1.166e+00  1.176e-02   99.10  < 2e-16 ***
wealthRichest                                 1.584e+00  1.752e-02   90.38  < 2e-16 ***
religionHinduism                             -9.585e-01  1.233e-01   -7.77 7.57e-15 ***
religionIslam                                -3.983e-01  6.893e-03  -57.78  < 2e-16 ***
mean.wealth.at.lowest.regional.level          1.258e+00  1.410e-01    8.93  < 2e-16 ***
per.cent.muslim. in.country:sexMale           -2.692e-01  5.185e-03  -51.93  < 2e-16 ***
sexMale:per.cent.hindu.in.country             3.684e-03  1.363e-04   27.03  < 2e-16 ***
sexMale:per.cent.muslim.in.subregional.level -1.504e-03  1.399e-03   -1.07   0.2826    
sexMale:per.cent.hindu.in.subregional.level  -1.350e-04  1.484e-04   -0.91   0.3632    
sexMale:wealthMiddle                         -6.542e-02  1.414e-02   -4.63 3.72e-06 ***
sexMale:wealthRichest                         1.553e-01  2.527e-02    6.15 7.99e-10 ***
wealthMiddle:religionHinduism                -2.468e-02  1.409e-01   -0.18   0.8609    
wealthRichest:religionHinduism                7.348e-01  1.472e-01    4.99 5.97e-07 ***
wealthMiddle:religionIslam                   -2.575e-01  1.434e-02  -17.96  < 2e-16 ***
wealthRichest:religionIslam                   1.183e-01  1.775e-02    6.66 2.70e-11 ***
sexMale:religionHinduism                      3.811e-01  1.816e-01    2.10   0.0358 *  
sexMale:religionIslam                         4.565e-02  9.674e-03    4.72 2.38e-06 ***
sexMale:wealthMiddle:religionHinduism        -1.038e-01  2.020e-01   -0.51   0.6074    
sexMale:wealthRichest:religionHinduism       -4.167e-01  2.117e-01   -1.97   0.0491 *  
sexMale:wealthMiddle:religionIslam            1.257e-01  1.789e-02    7.03 2.07e-12 ***
sexMale:wealthRichest:religionIslam          -1.642e-01  2.610e-02   -6.29 3.10e-10 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


I can provide the data, it would help to understand the matter.

-- 
Hans Ekbrand (http://hansekbrand.se/code) <hans.ekbrand at gmail.com>


From w.d.wadsworth at gmail.com  Sun Nov 29 00:18:00 2015
From: w.d.wadsworth at gmail.com (W. Duncan Wadsworth)
Date: Sat, 28 Nov 2015 17:18:00 -0600
Subject: [R-sig-ME] calculation of confidence intervals for random slope
	model
In-Reply-To: <CABghstRW92TYL1E3xZp7-jNqQtShzMVfekga_gza-XS9ov9oMQ@mail.gmail.com>
References: <ADCAD56B-DF62-44C2-81B1-6BDC16125789@zoo.ox.ac.uk>
	<CABghstRW92TYL1E3xZp7-jNqQtShzMVfekga_gza-XS9ov9oMQ@mail.gmail.com>
Message-ID: <CAFUzXDP_ZcMJ9ERCD4wCG-xb_sHAwBiGwf=a-m6W5PUhOeWfLA@mail.gmail.com>

Dr. Bolker,

Could you possibly expand on the statement "The other alternative is
to use bootMer
+ predict to get confidence intervals ..."? In particular, what do you mean
by using `predict` here?

My first stab at this would look like:

library(lme4)
library(ggplot2)
library(dplyr)
data("sleepstudy")
## visualize individual slopes
ggplot(sleepstudy, aes(x = Days, y = Reaction, group = factor(Subject))) +
  geom_smooth(aes(color = factor(Subject)), method = "lm", se = F) +
  theme(legend.position = "none")
sleepy = lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
## bootstrap summary function
sumfun = function(.){
  overall = fixef(.)
  individuals = ranef(.)$Subject
  return(c(overall["Days"] + individuals[,"Days"]))
}
## where the fun happens
booty = as.data.frame(bootMer(sleepy, sumfun, nsim = 99))
## for plotting
colnames(booty) = rownames(ranef(sleepy)$Subject)
slope_bs_distros = booty %>% tidyr::gather("Subject", "Value")
## bootstrap distributions of individual slope parameters (??)
ggplot(slope_bs_distros, aes(x = Value)) + geom_histogram() +
  facet_wrap(~ Subject, ncol = 5) +
  geom_vline(xintercept = 0, color = "red", size = 1.5)

But this doesn't seem correct since Subject 335 appears to have a negative
slope. Are we seeing some kind of shrinkage effect here or am I just doing
the bootstrapping wrong?



On Mon, Nov 16, 2015 at 7:58 AM, Ben Bolker <bbolker at gmail.com> wrote:

> On Mon, Nov 16, 2015 at 5:56 AM, Henry Travers
> <henry.travers at zoo.ox.ac.uk> wrote:
> > I have what I hope is a relatively straightforward question about how to
> interpret the results of a mixed effects model of the form:
> >
> > fm1 <- lmer(Reaction ~ Days + (Days | Subject))
> >
> > I am running an experiment such that I am most interested in the
> (equivalent of the) effect of Days for each Subject, rather than say fitted
> values. I understand how to derive the point estimates for this effect, but
> I am struggling to see how to calculate confidence intervals for these
> estimates that take account of both the standard error in the parameter
> estimate for Days and the uncertainty in the corresponding slope estimates
> for each Subject.
> >
> > I would be very grateful if someone could point me in the right
> direction or to a suitable reference.
>
>   This is a surprisingly difficult question to answer.
>   There have been extended discussions in the mailing list (which I
> don't have time to dig for now) about whether it's OK to add the
> conditional variances of the conditional modes to the variances of the
> fixed-effect predictions, and the circumstances under which this would
> be (in)accurate/(anti)conservative.  The other alternative is to use
> bootMer + predict to get confidence intervals ...
>
>   This should probably be added to the FAQ ...
>
> >
> > ------------------------------------------------
> > Henry Travers, PhD
> > Research Associate
> >
> > Interdisciplinary Centre for Conservation Science
> > Department of Zoology
> > University of Oxford
> >
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Nov 30 02:18:08 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 29 Nov 2015 20:18:08 -0500
Subject: [R-sig-ME] glmer: var-cov estimated from RX
In-Reply-To: <20151128220621.GA24492@hans>
References: <20151128220621.GA24492@hans>
Message-ID: <565BA3D0.40107@gmail.com>

On 15-11-28 05:06 PM, Hans Ekbrand wrote:
> Dear list,
> 
> I ran glmer() on a large dataset (16 million rows), and after some
> 6000 minutes, it converged.
> 
> However, there were two (related) warnings:
> 
> 1: In vcov.merMod(object, use.hessian = use.hessian) :
>   variance-covariance matrix computed from finite-difference Hessian is
> not positive definite: falling back to var-cov estimated from RX
> 2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
>   variance-covariance matrix computed from finite-difference Hessian is
> not positive definite: falling back to var-cov estimated from RX
> 
> I seek advice on where to go from here, and knowledge about the
> concepts "MX" and "finite-difference Hessian" which I am unfamiliar
> with.
> 
> Can I rely on the variance-covariance matrix I've got?

  Probably.  These variance-covariance matrices are all approximations
in any case, but should be pretty good in the large-data case.

> 
> Should I try get rid of warning? If so, what could possibly help (is
> it meaningful to try with a different optimizer?)? Since the
> convergence time was about 5 days, trying out difference optimizers is
> not very fun.

  I suspect you probably won't be able to get rid of the warning, but it
may be worth trying out control=glmerControl(optimizer="bobyqa") --
might speed up your convergence considerably.

  It may also be worth trying the (experimental!!!) glmmTMB package,
which you can find on github ...

  cheers
    Ben Bolker

> 
> If it helps, here is the output of summary:
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: deprived.of.education ~ (1 | country) + (1 | lowest.regional.level) +  
>     per.cent.muslim.in.country * sex + per.cent.hindu.in.country *  
>     sex + per.cent.muslim.in.subregional.level * sex + per.cent.hindu.in.subregional.level *  
>     sex + gdp.log + qog + wealth * sex * religion + mean.wealth.at.lowest.regional.level
>    Data: my.df
> 
>      AIC      BIC   logLik deviance df.resid 
>  4047602  4048056 -2023770  4047540 16959894 
> 
> Scaled residuals: 
>     Min      1Q  Median      3Q     Max 
> -40.490   0.000   0.079   0.149   4.654 
> 
> Random effects:
>  Groups                Name        Variance Std.Dev.
>  lowest.regional.level (Intercept)  0.6495  0.8059  
>  country               (Intercept) 39.2973  6.2688  
> Number of obs: 16959925, groups:  lowest.regional.level, 3962; country, 31
> 
> Fixed effects:
>                                                Estimate Std. Error z value Pr(>|z|)    
> (Intercept)                                  -2.076e+01  1.150e+01   -1.81   0.0709 .  
> per.cent.muslim.in.country                    9.057e-01  7.431e-01    1.22   0.2229    
> sexMale                                       4.297e-02  5.193e-03    8.27  < 2e-16 ***
> per.cent.hindu.in.country                    -4.599e-02  3.366e-02   -1.37   0.1718    
> per.cent.muslim.in.subregional.level         -1.306e-02  9.290e-03   -1.41   0.1597    
> per.cent.hindu.in.subregional.level          -1.234e-02  1.059e-03  -11.64  < 2e-16 ***
> gdp.log                                       3.941e+00  1.548e+00    2.55   0.0109 *  
> qog                                          -5.200e+00  3.048e+00   -1.71   0.0880 .  
> wealthMiddle                                  1.166e+00  1.176e-02   99.10  < 2e-16 ***
> wealthRichest                                 1.584e+00  1.752e-02   90.38  < 2e-16 ***
> religionHinduism                             -9.585e-01  1.233e-01   -7.77 7.57e-15 ***
> religionIslam                                -3.983e-01  6.893e-03  -57.78  < 2e-16 ***
> mean.wealth.at.lowest.regional.level          1.258e+00  1.410e-01    8.93  < 2e-16 ***
> per.cent.muslim. in.country:sexMale           -2.692e-01  5.185e-03  -51.93  < 2e-16 ***
> sexMale:per.cent.hindu.in.country             3.684e-03  1.363e-04   27.03  < 2e-16 ***
> sexMale:per.cent.muslim.in.subregional.level -1.504e-03  1.399e-03   -1.07   0.2826    
> sexMale:per.cent.hindu.in.subregional.level  -1.350e-04  1.484e-04   -0.91   0.3632    
> sexMale:wealthMiddle                         -6.542e-02  1.414e-02   -4.63 3.72e-06 ***
> sexMale:wealthRichest                         1.553e-01  2.527e-02    6.15 7.99e-10 ***
> wealthMiddle:religionHinduism                -2.468e-02  1.409e-01   -0.18   0.8609    
> wealthRichest:religionHinduism                7.348e-01  1.472e-01    4.99 5.97e-07 ***
> wealthMiddle:religionIslam                   -2.575e-01  1.434e-02  -17.96  < 2e-16 ***
> wealthRichest:religionIslam                   1.183e-01  1.775e-02    6.66 2.70e-11 ***
> sexMale:religionHinduism                      3.811e-01  1.816e-01    2.10   0.0358 *  
> sexMale:religionIslam                         4.565e-02  9.674e-03    4.72 2.38e-06 ***
> sexMale:wealthMiddle:religionHinduism        -1.038e-01  2.020e-01   -0.51   0.6074    
> sexMale:wealthRichest:religionHinduism       -4.167e-01  2.117e-01   -1.97   0.0491 *  
> sexMale:wealthMiddle:religionIslam            1.257e-01  1.789e-02    7.03 2.07e-12 ***
> sexMale:wealthRichest:religionIslam          -1.642e-01  2.610e-02   -6.29 3.10e-10 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> I can provide the data, it would help to understand the matter.
>


From bbolker at gmail.com  Mon Nov 30 06:43:58 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 30 Nov 2015 00:43:58 -0500
Subject: [R-sig-ME] calculation of confidence intervals for random slope
 model
In-Reply-To: <CAFUzXDP_ZcMJ9ERCD4wCG-xb_sHAwBiGwf=a-m6W5PUhOeWfLA@mail.gmail.com>
References: <ADCAD56B-DF62-44C2-81B1-6BDC16125789@zoo.ox.ac.uk>
	<CABghstRW92TYL1E3xZp7-jNqQtShzMVfekga_gza-XS9ov9oMQ@mail.gmail.com>
	<CAFUzXDP_ZcMJ9ERCD4wCG-xb_sHAwBiGwf=a-m6W5PUhOeWfLA@mail.gmail.com>
Message-ID: <565BE21E.7070903@gmail.com>

On 15-11-28 06:18 PM, W. Duncan Wadsworth wrote:
> Dr. Bolker,
> 
> Could you possibly expand on the statement "The other alternative is
> to use bootMer
> + predict to get confidence intervals ..."? In particular, what do you mean
> by using `predict` here?

  It took me a while to remember what the issue is here -- by default
`bootMer` *resamples* the random effects rather than conditioning on
them.  You need to use "use.u" or "re.form" to specify the
conditioning, as follows ...

sleepy = lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
## bootstrap summary function
sumfun = function(.) {
    coef(.)$Subject[,"Days"]
}
## where the fun happens
booty = as.data.frame(bootMer(sleepy, sumfun, nsim = 99,
       re.form=~Days|Subject))
## for plotting
rr <- ranef(sleepy)$Subject
colnames(booty) = rownames(rr)
slope_bs_distros = booty %>% tidyr::gather("Subject", "Value")
## bootstrap distributions of individual slope parameters (??)
## indiv_ests <- rr %>% add_rownames("Subject") %>%
##    mutate(Days=Days+fixef(sleepy)["Days"])
indiv_ests <- add_rownames(coef(sleepy)$Subject,"Subject")
ggplot(slope_bs_distros, aes(x = Value)) + geom_histogram() +
  facet_wrap(~ Subject, ncol = 5) +
  geom_vline(xintercept = 0, color = "red", size = 1.5)+
  geom_vline(aes(xintercept=Days),colour="blue",data=indiv_ests)


> 
> My first stab at this would look like:
> 
> library(lme4)
> library(ggplot2)
> library(dplyr)
> data("sleepstudy")
> ## visualize individual slopes
> ggplot(sleepstudy, aes(x = Days, y = Reaction, group = factor(Subject))) +
>   geom_smooth(aes(color = factor(Subject)), method = "lm", se = F) +
>   theme(legend.position = "none")
> sleepy = lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
> ## bootstrap summary function
> sumfun = function(.){
>   overall = fixef(.)
>   individuals = ranef(.)$Subject
>   return(c(overall["Days"] + individuals[,"Days"]))
> }
> ## where the fun happens
> booty = as.data.frame(bootMer(sleepy, sumfun, nsim = 99))
> ## for plotting
> colnames(booty) = rownames(ranef(sleepy)$Subject)
> slope_bs_distros = booty %>% tidyr::gather("Subject", "Value")
> ## bootstrap distributions of individual slope parameters (??)
> ggplot(slope_bs_distros, aes(x = Value)) + geom_histogram() +
>   facet_wrap(~ Subject, ncol = 5) +
>   geom_vline(xintercept = 0, color = "red", size = 1.5)
> 
> But this doesn't seem correct since Subject 335 appears to have a negative
> slope. Are we seeing some kind of shrinkage effect here or am I just doing
> the bootstrapping wrong?
> 
> 
> 
> On Mon, Nov 16, 2015 at 7:58 AM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> On Mon, Nov 16, 2015 at 5:56 AM, Henry Travers
>> <henry.travers at zoo.ox.ac.uk> wrote:
>>> I have what I hope is a relatively straightforward question about how to
>> interpret the results of a mixed effects model of the form:
>>>
>>> fm1 <- lmer(Reaction ~ Days + (Days | Subject))
>>>
>>> I am running an experiment such that I am most interested in the
>> (equivalent of the) effect of Days for each Subject, rather than say fitted
>> values. I understand how to derive the point estimates for this effect, but
>> I am struggling to see how to calculate confidence intervals for these
>> estimates that take account of both the standard error in the parameter
>> estimate for Days and the uncertainty in the corresponding slope estimates
>> for each Subject.
>>>
>>> I would be very grateful if someone could point me in the right
>> direction or to a suitable reference.
>>
>>   This is a surprisingly difficult question to answer.
>>   There have been extended discussions in the mailing list (which I
>> don't have time to dig for now) about whether it's OK to add the
>> conditional variances of the conditional modes to the variances of the
>> fixed-effect predictions, and the circumstances under which this would
>> be (in)accurate/(anti)conservative.  The other alternative is to use
>> bootMer + predict to get confidence intervals ...
>>
>>   This should probably be added to the FAQ ...
>>
>>>
>>> ------------------------------------------------
>>> Henry Travers, PhD
>>> Research Associate
>>>
>>> Interdisciplinary Centre for Conservation Science
>>> Department of Zoology
>>> University of Oxford
>>>
>>>
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From hans.ekbrand at gmail.com  Mon Nov 30 07:37:06 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Mon, 30 Nov 2015 07:37:06 +0100
Subject: [R-sig-ME] glmer: var-cov estimated from RX
In-Reply-To: <565BA3D0.40107@gmail.com>
References: <20151128220621.GA24492@hans>
 <565BA3D0.40107@gmail.com>
Message-ID: <20151130063706.GA2787@hans>

On Sun, Nov 29, 2015 at 08:18:08PM -0500, Ben Bolker wrote:
> On 15-11-28 05:06 PM, Hans Ekbrand wrote:
> > Can I rely on the variance-covariance matrix I've got?
> 
>   Probably.  These variance-covariance matrices are all approximations
> in any case, but should be pretty good in the large-data case.

I see.

> > Should I try get rid of warning? If so, what could possibly help (is
> > it meaningful to try with a different optimizer?)? Since the
> > convergence time was about 5 days, trying out difference optimizers is
> > not very fun.
> 
>   I suspect you probably won't be able to get rid of the warning, but it
> may be worth trying out control=glmerControl(optimizer="bobyqa") --
> might speed up your convergence considerably.

I'll try it.

>   It may also be worth trying the (experimental!!!) glmmTMB package,
> which you can find on github ...

Good to know, thanks again Ben!


From lotteanna at gmail.com  Mon Nov 30 10:55:57 2015
From: lotteanna at gmail.com (Lotte van Boheemen)
Date: Mon, 30 Nov 2015 20:55:57 +1100
Subject: [R-sig-ME] Plotting predicted values mcmcglmm
Message-ID: <CA+brd=mh4anHxxinMkTMKWx8ZRMLFHUE4KBwwZ2WympNnHyc8g@mail.gmail.com>

Hi,


Our goal is to plot the predicted values of an mcmcglmm model with
variables: NoFeeds ~  offset(ObsDuration) + Month + AnnualInsects +
TQc_Combined + NoOffspring + NoH*Status + Status*WatchType ,
random=~idh(Status):BirdID + NestID:NestWatchID + Obs

Predicted values are calculated as:
mpred0 <- predict(model,interval="confidence")
colnames(mpred0) <- paste("mpred0",c("fit","lwr","upr"),sep=".")
mpred1 <- predict(model,interval="confidence",marginal=~ BirdID + MateID +
NestID:NestWatchID + Year:Month + Obs)
colnames(mpred1) <- paste("mpred1",c("fit","lwr","upr"),sep=".")
dataf <- data.frame(data_UnID,mpred0,mpred1)

g0 <- ggplot(dataf,aes(x=NoH,y=FeedsPerHour))+
  stat_sum(aes(size=factor(..n..)),alpha=0.5)+
  facet_grid(~Status+WatchType)+
  scale_size_discrete(name="n",range=c(2,5))
g0 + geom_line(aes(x=as.numeric(NoH),y=mpred0.fit),colour="red")+
  geom_ribbon(aes(x=as.numeric(NoH),y=mpred0.fit,
                  ymin=mpred0.lwr,ymax=mpred0.upr),fill="red",
              alpha=0.3)


However, the plots this results in show 'jagged' predictions for the model,
e.g. it seems like at one particular value of NoH, the model predicts 2
different values, which is not the case (figure attached).

Are we predicting the values of the model incorrectly or are we
interpreting the mcmcglmm output wrong?

Secondly, we have done quite some reading and ran several models on dummy
variables, and we are unsure if we can use offset in mcmcglmm. The offset
variable is in this case duration of the observation, influencing the
response variable as a longer observation will result in higher
NoFeeds. Outputs
of models with and without the offset variable give very similar results,
and correcting for observation duration in different ways leads to
different results.

Thank you in advance,

Lotte van Boheemen

	[[alternative HTML version deleted]]


From forschack at cbs.mpg.de  Wed Nov 25 11:43:49 2015
From: forschack at cbs.mpg.de (Norman Forschack)
Date: Wed, 25 Nov 2015 11:43:49 +0100 (CET)
Subject: [R-sig-ME] how to test interaction correctly
In-Reply-To: <21482515.148.1448443235857.JavaMail.NF_2@NFs-XMG>
Message-ID: <21287820.173.1448448220374.JavaMail.NF_2@NFs-XMG>

Hello,

I modeled the relationship of two electrophysiological brain signals for two separate cognitive conditions from a balanced empirical dataset.
The formula was 
f = formula(PA ~ I(OsciPow^2) + OsciPow + (OsciPow + I(OsciPow^2) | Subject) )
where PA is a potential amplitude and OsciPow is oscillation power, the random effect term is grouped by individual participant.

The separate models are these:
mdlPA_att <- lmer(f,data=data[ data2Attention=="attend",],REML=F) and
mdlPA_ign <- lmer(f,data=data[ data2Attention=="ignore",],REML=F)
Both of them I tested with the pbkrtest toolbox against an intercept only model and a linear relationship only model.

As the quadratic (negative for the first model, positive for the second) and linear term (positive for the first model and negative for the second) for the fixed effects differ descriptively, I tried to model the interaction between the cognitive conditions and wonder whether this is the correct way and how to test it, i.e. against which reduced model.

So here's the interaction model:
mdlPA_ia = lmer(PA ~ 1 + OsciPow*Attention + I(OsciPow^2)*Attention + (1 + OsciPow + I(OsciPow^2) + Attention | Subject), data=data,REML=F)

and the reduced model I want to compare it to:
mdlPA_reduced = lmer(PA ~ 1 + OsciPow + I(OsciPow^2) + Attention + (1 + OsciPow + I(OsciPow^2) | Subject) + (1 + Attention | Subject), data=data,REML=F)

Do think this is reasonable? Especially for the reduced model, I'm unsure about the two uncorrelated random effect terms and whether it's necessary to have two random intercepts grouped by subject. When I leave out one Intercept, the model does not converge.
What about having just one random effects term with correlated predictors?

Thank you for you're time!
Norman
___________________________________________________________
Norman Forschack, Dipl.-Psych.
Max-Planck Institute for Human Cognitive and Brain Sciences
Stephanstra?e 1a
04103 Leipzig

mail: forschack at cbs.mpg.de
phone: +49341 9940171
web: http://www.cbs.mpg.de/~forschack


From lotte.van.boheemen at monash.edu  Mon Nov 23 23:58:48 2015
From: lotte.van.boheemen at monash.edu (Lotte van Boheemen)
Date: Tue, 24 Nov 2015 09:58:48 +1100
Subject: [R-sig-ME] Plotting predicted values mcmcglmm
Message-ID: <CAC42Ri04FRyga4OEYLJTBwxUogPWUdeh7MG9v9FswLf+C69tuQ@mail.gmail.com>

Hi,

My goal is to plot the predicted values of the mcmcglmm model with
variables: NoFeeds ~  offset(ObsDuration) + Month + AnnualInsects +
TQc_Combined + NoOffspring + NoH*Status + Status*WatchType ,
random=~idh(Status):BirdID + NestID:NestWatchID + Obs

Predicted values are calculated as:
mpred0 <- predict(model,interval="confidence")
colnames(mpred0) <- paste("mpred0",c("fit","lwr","upr"),sep=".")
mpred1 <- predict(model,interval="confidence",marginal=~ BirdID + MateID +
NestID:NestWatchID + Year:Month + Obs)
colnames(mpred1) <- paste("mpred1",c("fit","lwr","upr"),sep=".")
dataf <- data.frame(data_UnID,mpred0,mpred1)

g0 <- ggplot(dataf,aes(x=NoH,y=FeedsPerHour))+
  stat_sum(aes(size=factor(..n..)),alpha=0.5)+
  facet_grid(~Status+WatchType)+
  scale_size_discrete(name="n",range=c(2,5))
g0 + geom_line(aes(x=as.numeric(NoH),y=mpred0.fit),colour="red")+
  geom_ribbon(aes(x=as.numeric(NoH),y=mpred0.fit,
                  ymin=mpred0.lwr,ymax=mpred0.upr),fill="red",
              alpha=0.3)


However, the plots this results in show 'jagged' predictions for the model,
e.g. it seems like at one particular value of NoH, the model predicts 2
different values, which is not the case (figure attached).

Lotte Anna van Boheemen
PhD Research Candidate
School of Biological Sciences
Monash University

   -
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sel.pdf
Type: application/pdf
Size: 52439 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20151124/150647fd/attachment-0001.pdf>

From lsfarwell at mix.wvu.edu  Mon Nov 30 03:10:44 2015
From: lsfarwell at mix.wvu.edu (Laura Farwell)
Date: Sun, 29 Nov 2015 21:10:44 -0500
Subject: [R-sig-ME] (1) zero-inflation in glmmADMB; (2) issues with offsets
Message-ID: <CADLz31t4yxq6r37pYx1PfbcFbP_R470e2h6K61C9b=5hUjVMBA@mail.gmail.com>

Hello,

I am investigating impacts of forest fragmentation due to gas development
on songbirds, and have run mixed effects models using lme4.  My response
variables are species abundances (count data), fixed effects are landscape
metrics (forest edge density, percent gas cover, percent forest cover), and
random effects are year and survey point (repeated measures over an 8-yr
period).

However -- having recently realized that I need to better account for the
high numbers of zeros in my count data, I decided to try zero-inflated
poisson models in glmmADMB.

(1) Although many of the species I'm looking at have high numbers of zeros,
the results of my ordinary poisson models and zeroInflation=TRUE poisson
models appear to be identical, which seems odd:

*Ex.*:
CERW.pois <- glmmadmb(CERW.50m ~ Edge.100m + pGAS.100m + pFOR.500m
+ (1|Year) + (1|Point), family="poisson")

CERW.zipois <- glmmadmb(CERW.50m ~ Edge.100m + pGAS.100m + pFOR.500m
+ (1|Year) + (1|Point), zeroInflation=TRUE, family="poisson")

Am I doing something wrong here, or is it common for outputs to look nearly
identical, with or without zero-inflation?


(2)  I am also trying to incorporate offsets for detection probability
(calculated using the QPAD approach outlined in Solymos et al., 2013) --
but the offset term doesn't appear to be recognized ("unused argument"
error)

*Ex.*:
(.... family="poisson", offset=offset(CERW.offs))

*For what it's worth, here is the offset code that works in lme4 (doesn't
work in glmmADMB):
(.... family="poisson", offset=*corrections2offset*(CERW.offs))

Any suggestions or advice would be greatly appreciated.

Thanks,
Laura Farwell
West Virginia University

	[[alternative HTML version deleted]]


From romunov at gmail.com  Tue Dec  1 09:01:52 2015
From: romunov at gmail.com (romunov)
Date: Tue, 1 Dec 2015 09:01:52 +0100
Subject: [R-sig-ME] Plotting predicted values mcmcglmm
In-Reply-To: <CAC42Ri04FRyga4OEYLJTBwxUogPWUdeh7MG9v9FswLf+C69tuQ@mail.gmail.com>
References: <CAC42Ri04FRyga4OEYLJTBwxUogPWUdeh7MG9v9FswLf+C69tuQ@mail.gmail.com>
Message-ID: <CAHT1vpi1NJ=ppOL84_tVe8-DbBG0seywaFF_wKv5Ud0wM3EjuA@mail.gmail.com>

Can you share your data (dput())?

Cheers,
Roman

On Mon, Nov 23, 2015 at 11:58 PM, Lotte van Boheemen <
lotte.van.boheemen at monash.edu> wrote:

> Hi,
>
> My goal is to plot the predicted values of the mcmcglmm model with
> variables: NoFeeds ~  offset(ObsDuration) + Month + AnnualInsects +
> TQc_Combined + NoOffspring + NoH*Status + Status*WatchType ,
> random=~idh(Status):BirdID + NestID:NestWatchID + Obs
>
> Predicted values are calculated as:
> mpred0 <- predict(model,interval="confidence")
> colnames(mpred0) <- paste("mpred0",c("fit","lwr","upr"),sep=".")
> mpred1 <- predict(model,interval="confidence",marginal=~ BirdID + MateID +
> NestID:NestWatchID + Year:Month + Obs)
> colnames(mpred1) <- paste("mpred1",c("fit","lwr","upr"),sep=".")
> dataf <- data.frame(data_UnID,mpred0,mpred1)
>
> g0 <- ggplot(dataf,aes(x=NoH,y=FeedsPerHour))+
>   stat_sum(aes(size=factor(..n..)),alpha=0.5)+
>   facet_grid(~Status+WatchType)+
>   scale_size_discrete(name="n",range=c(2,5))
> g0 + geom_line(aes(x=as.numeric(NoH),y=mpred0.fit),colour="red")+
>   geom_ribbon(aes(x=as.numeric(NoH),y=mpred0.fit,
>                   ymin=mpred0.lwr,ymax=mpred0.upr),fill="red",
>               alpha=0.3)
>
>
> However, the plots this results in show 'jagged' predictions for the model,
> e.g. it seems like at one particular value of NoH, the model predicts 2
> different values, which is not the case (figure attached).
>
> Lotte Anna van Boheemen
> PhD Research Candidate
> School of Biological Sciences
> Monash University
>
>    -
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From gitumbui at gmail.com  Wed Dec  2 08:50:27 2015
From: gitumbui at gmail.com (Gitu wa Mbui)
Date: Wed, 2 Dec 2015 17:50:27 +1000
Subject: [R-sig-ME] gamm4 models memory intensive
Message-ID: <CAFPRYfDqfr9_rX_SgoTFE5euR=DhtG0CY9P=t7rj0TUeS6ZDDQ@mail.gmail.com>

Hi,

I am using gamm4 models in a model selection framework, where I have lined
up a few thousands of gamm4 models for running within this framework.
However, each gamm4 model object seems to enclose an environment of ~95MB,
even though the object size for each gamm4 model is ~1.5 MB.
i.e
> object_size(gamm4model)

92.1 MB


This makes it impractical to run more than a few models. Is there a way
around this large memory demand by gamm4?

gamm on the other hand doesnt seem to enclose such a large environment.
 However, given that gamm uses PQL, it doesn not make alot of sense to

	[[alternative HTML version deleted]]


From gitumbui at gmail.com  Wed Dec  2 08:54:58 2015
From: gitumbui at gmail.com (Gitu wa Mbui)
Date: Wed, 2 Dec 2015 17:54:58 +1000
Subject: [R-sig-ME] gamm4 models memory intensive
In-Reply-To: <CAFPRYfDqfr9_rX_SgoTFE5euR=DhtG0CY9P=t7rj0TUeS6ZDDQ@mail.gmail.com>
References: <CAFPRYfDqfr9_rX_SgoTFE5euR=DhtG0CY9P=t7rj0TUeS6ZDDQ@mail.gmail.com>
Message-ID: <CAFPRYfBRN2K-2sUg1n=abbxOmytqatwy787ccCcgsr1-RnVhOg@mail.gmail.com>

I am using gamm4 models in a model selection framework, where I have lined
up a few thousands of gamm4 models for running within this framework.
However, each gamm4 model object seems to enclose an environment of ~95MB,
even though the object size for each gamm4 model is ~1.5 MB.
i.e
> object_size(gamm4Model)

92.1 MB


This makes it impractical to run more than a few models. Is there a way
around this large memory demand by gamm4?

gamm on the other hand doesn't seem to enclose such a large environment.
 However, given that gamm uses PQL etc, it is of little importance in model
selection framework.

>object_size(gammModel)1.08 MB


Any ideas on a way around this?

~Gitu

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Wed Dec  2 18:49:29 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 02 Dec 2015 17:49:29 +0000
Subject: [R-sig-ME] Question to lme4: Higher Level Response
In-Reply-To: <c0c91a980b138789abca6a871f18a977239d9c4f1568708740@webmail.uni-jena.de>
References: <c0c91a980b138789abca6a871f18a977239d9c4f1568708740@webmail.uni-jena.de>
Message-ID: <CAO7JsnQrOz5+48pJZJdEjSmX3rv5G320kYwRBAVEiWA4THtPPg@mail.gmail.com>

It is better to send such questions to the R-SIG-Mixed-Models mailing list,
which I have taken the liberty of cc:ing on this response.  Many of the
readers of that list will be able to respond more quickly and knowledgeably
than I can.

On Tue, Dec 1, 2015 at 3:42 PM Elisabeth Schubach <
elisabeth.schubach at uni-jena.de> wrote:

>
> Dear Dr. Bates,
>
> I have got a question to lme4: Is it possible to fit a model with a
> response on a higher level by predictors of lower levels? Or do I then
> run into the problem of atomistic fallacy? And the only way is to turn
> the model around and fit the lower level response by higher level
> predictors? I understand that in that case, pinning avoids the
> ecological fallacy.
>
> Thank you and kind regards,
> Elisabeth Schubach
>

	[[alternative HTML version deleted]]


From jake987722 at hotmail.com  Wed Dec  2 20:11:18 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 2 Dec 2015 19:11:18 +0000
Subject: [R-sig-ME] Question to lme4: Higher Level Response
In-Reply-To: <CAO7JsnQrOz5+48pJZJdEjSmX3rv5G320kYwRBAVEiWA4THtPPg@mail.gmail.com>
References: <c0c91a980b138789abca6a871f18a977239d9c4f1568708740@webmail.uni-jena.de>,
	<CAO7JsnQrOz5+48pJZJdEjSmX3rv5G320kYwRBAVEiWA4THtPPg@mail.gmail.com>
Message-ID: <DM3PR19MB0522C34086372B7CC17F8A4CCB0E0@DM3PR19MB0522.namprd19.prod.outlook.com>

Elisabeth,


You might find this brief stats.stackexchange.com answer (and comments) that I wrote useful:

http://stats.stackexchange.com/questions/169512/multilevel-model-with-responses-only-at-level-2/169585#169585


Happy to hear other perspectives on this issue.


Jake

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Douglas Bates <bates at stat.wisc.edu>
Sent: Wednesday, December 2, 2015 11:49 AM
To: Elisabeth Schubach
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question to lme4: Higher Level Response

It is better to send such questions to the R-SIG-Mixed-Models mailing list,
which I have taken the liberty of cc:ing on this response.  Many of the
readers of that list will be able to respond more quickly and knowledgeably
than I can.

On Tue, Dec 1, 2015 at 3:42 PM Elisabeth Schubach <
elisabeth.schubach at uni-jena.de> wrote:

>
> Dear Dr. Bates,
>
> I have got a question to lme4: Is it possible to fit a model with a
> response on a higher level by predictors of lower levels? Or do I then
> run into the problem of atomistic fallacy? And the only way is to turn
> the model around and fit the lower level response by higher level
> predictors? I understand that in that case, pinning avoids the
> ecological fallacy.
>
> Thank you and kind regards,
> Elisabeth Schubach
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From highstat at highstat.com  Wed Dec  2 20:24:52 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 2 Dec 2015 20:24:52 +0100
Subject: [R-sig-ME] zero-inflation in glmmADMB
In-Reply-To: <mailman.1.1448967601.21026.r-sig-mixed-models@r-project.org>
References: <mailman.1.1448967601.21026.r-sig-mixed-models@r-project.org>
Message-ID: <565F4584.2030901@highstat.com>




> Hello,
>
> I am investigating impacts of forest fragmentation due to gas development
> on songbirds, and have run mixed effects models using lme4.  My response
> variables are species abundances (count data), fixed effects are landscape
> metrics (forest edge density, percent gas cover, percent forest cover), and
> random effects are year and survey point (repeated measures over an 8-yr
> period).
>
> However -- having recently realized that I need to better account for the
> high numbers of zeros in my count data, I decided to try zero-inflated
> poisson models in glmmADMB.
>
> (1) Although many of the species I'm looking at have high numbers of zeros,
> the results of my ordinary poisson models and zeroInflation=TRUE poisson
> models appear to be identical, which seems odd:
>
> *Ex.*:
> CERW.pois <- glmmadmb(CERW.50m ~ Edge.100m + pGAS.100m + pFOR.500m
> + (1|Year) + (1|Point), family="poisson")
>
> CERW.zipois <- glmmadmb(CERW.50m ~ Edge.100m + pGAS.100m + pFOR.500m
> + (1|Year) + (1|Point), zeroInflation=TRUE, family="poisson")
>
> Am I doing something wrong here, or is it common for outputs to look nearly
> identical, with or without zero-inflation?


I suggest that you write out the equations of both models. See where it 
differs. Then stick in the estimated parameters, and especially focus on 
the binary part. That will answer your question.


As to the second question...try using offset(Log(What Ever)) directly in 
the formula...that should work. Note the log!


Alain

>
> (2)  I am also trying to incorporate offsets for detection probability
> (calculated using the QPAD approach outlined in Solymos et al., 2013) --
> but the offset term doesn't appear to be recognized ("unused argument"
> error)
>
> *Ex.*:
> (.... family="poisson", offset=offset(CERW.offs))
>
> *For what it's worth, here is the offset code that works in lme4 (doesn't
> work in glmmADMB):
> (.... family="poisson", offset=*corrections2offset*(CERW.offs))
>
> Any suggestions or advice would be greatly appreciated.
>
> Thanks,
> Laura Farwell
> West Virginia University
>
> 	[[alternative HTML version deleted]]
>








-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From pierces1 at msu.edu  Thu Dec  3 14:21:35 2015
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Thu, 3 Dec 2015 08:21:35 -0500
Subject: [R-sig-ME] Question to lme4: Higher Level Response
In-Reply-To: <CAO7JsnQrOz5+48pJZJdEjSmX3rv5G320kYwRBAVEiWA4THtPPg@mail.gmail.com>
References: <c0c91a980b138789abca6a871f18a977239d9c4f1568708740@webmail.uni-jena.de>
	<CAO7JsnQrOz5+48pJZJdEjSmX3rv5G320kYwRBAVEiWA4THtPPg@mail.gmail.com>
Message-ID: <000001d12dcd$88b3ded0$9a1b9c70$@msu.edu>

Elisabeth,

That sort of model is more easily accomplished with structural equation modeling software. Check out the references below. 

Croon, M. A. (2007). Predicting group-level outcome variables from variables measured at the individual level: A latent variable multilevel model. Psychological Methods, 12(1), 45-57. doi:10.1037/1082-989X.12.1.45

L?dtke, O., Marsh, H. W., Robitzsch, A., Trautwein, U., Asparouhov, T., & Muth?n, B. (2008). The multilevel latent covariate model: A new, more reliable approach to group-level effects in contextual studies. Psychological Methods, 13(3), 203-229. doi:10.1037/a0012869

Marsh, H. W., L?dtke, O., Nagengast, B., Trautwein, U., Morin, A. J. S., Abduljabbar, A. S., & K?ller, O. (2012). Classroom climate and contextual effects: Conceptual and methodological issues in the evaluation of group-level effects. Educational Psychologist, 47(2), 106-124. doi:10.1080/00461520.2012.670488


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Douglas Bates [mailto:bates at stat.wisc.edu] 
Sent: Wednesday, December 02, 2015 12:49 PM
To: Elisabeth Schubach <elisabeth.schubach at uni-jena.de>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question to lme4: Higher Level Response

It is better to send such questions to the R-SIG-Mixed-Models mailing list,
which I have taken the liberty of cc:ing on this response.  Many of the
readers of that list will be able to respond more quickly and knowledgeably
than I can.

On Tue, Dec 1, 2015 at 3:42 PM Elisabeth Schubach <
elisabeth.schubach at uni-jena.de> wrote:

>
> Dear Dr. Bates,
>
> I have got a question to lme4: Is it possible to fit a model with a
> response on a higher level by predictors of lower levels? Or do I then
> run into the problem of atomistic fallacy? And the only way is to turn
> the model around and fit the lower level response by higher level
> predictors? I understand that in that case, pinning avoids the
> ecological fallacy.
>
> Thank you and kind regards,
> Elisabeth Schubach
>

	[[alternative HTML version deleted]]


From g.southon at sheffield.ac.uk  Thu Dec  3 18:01:05 2015
From: g.southon at sheffield.ac.uk (Georgina Southon)
Date: Thu, 3 Dec 2015 17:01:05 +0000
Subject: [R-sig-ME] A question about CLMM in R
Message-ID: <33B498B6-6F19-4997-91A9-4A7D83D2F8E8@sheffield.ac.uk>

Dear CLMM experts,

I have been using the ordinal package in R to model ordinal response data with CLMM, with the inclusion of categorical predictor variables and interaction terms. The model returns perfectly coherent results thankfully (a truncated example attached), however it does not provide an overall P value for each interaction term. Is this possible to obtain when modelling with clmm? 

Call:				
clmm2(location = preference ~ treatment + siteuse +treatment*siteuse,random+sample,Hess=TRUE
 

 random = sample, 
    data = plops, Hess = TRUE)		
Random effects:			
            Var  Std.Dev			
sample 1.660947 1.288777		
Location coefficients:			
                      Estimate Std. Error z value Pr(>|z|)  	
treatmentB             0.0736   1.4480     0.0508 0.95947987
treatmentC             0.8667   1.0871     0.7972 0.42531178
treatmentD             0.1548   1.1883     0.1303 0.89636709
treatmentE            -0.9512   1.3482    -0.7056 0.48046420
treatmentF             4.0151   1.2521     3.2066 0.00134313
treatmentG            -0.0489   1.0773    -0.0454 0.96376758
treatmentH             1.1422   1.2055     0.9474 0.34342605
treatmentI             0.2228   1.0840     0.2055 0.83716432
siteuse               -0.0004   0.0013    -0.3159 0.75211206




treatmentB:siteuse     0.0012   0.0019     0.6217 0.53413206
treatmentC:siteuse     0.0011   0.0015     0.7460 0.45565644
treatmentD:siteuse     0.0009   0.0016     0.5841 0.55913734
treatmentE:siteuse     0.0004   0.0016     0.2355 0.81378524
treatmentF:siteuse     0.0002   0.0016     0.1011 0.91943399
treatmentG:siteuse    -0.0006   0.0015    -0.4202 0.67432023
treatmentH:siteuse     0.0000   0.0018    -0.0278 0.97782476
treatmentI:siteuse    -0.0019   0.0016    -1.1369 0.25559690



Any insights would be most gratefully received.

Thank you,


Dr Georgina Southon
Post-doctoral Researcher
Department of Landscape
The University of Sheffield







	[[alternative HTML version deleted]]


From drmccloy at uw.edu  Thu Dec  3 19:12:51 2015
From: drmccloy at uw.edu (Dan McCloy)
Date: Thu, 3 Dec 2015 10:12:51 -0800
Subject: [R-sig-ME] A question about CLMM in R
In-Reply-To: <33B498B6-6F19-4997-91A9-4A7D83D2F8E8@sheffield.ac.uk>
References: <33B498B6-6F19-4997-91A9-4A7D83D2F8E8@sheffield.ac.uk>
Message-ID: <CAOE0pYko3dd393NGvL7R-0y4sKamTsY5zctDcAVgyB-VmBZ7=g@mail.gmail.com>

The column labeled Pr(>|z|) is the p-value provided by ordinal::clmm
(it is also labeled this way in lme4::glmer among others).

On Thu, Dec 3, 2015 at 9:01 AM, Georgina Southon
<g.southon at sheffield.ac.uk> wrote:
> Dear CLMM experts,
>
> I have been using the ordinal package in R to model ordinal response data with CLMM, with the inclusion of categorical predictor variables and interaction terms. The model returns perfectly coherent results thankfully (a truncated example attached), however it does not provide an overall P value for each interaction term. Is this possible to obtain when modelling with clmm?
>
> Call:
> clmm2(location = preference ~ treatment + siteuse +treatment*siteuse,random+sample,Hess=TRUE
>
>
>  random = sample,
>     data = plops, Hess = TRUE)
> Random effects:
>             Var  Std.Dev
> sample 1.660947 1.288777
> Location coefficients:
>                       Estimate Std. Error z value Pr(>|z|)
> treatmentB             0.0736   1.4480     0.0508 0.95947987
> treatmentC             0.8667   1.0871     0.7972 0.42531178
> treatmentD             0.1548   1.1883     0.1303 0.89636709
> treatmentE            -0.9512   1.3482    -0.7056 0.48046420
> treatmentF             4.0151   1.2521     3.2066 0.00134313
> treatmentG            -0.0489   1.0773    -0.0454 0.96376758
> treatmentH             1.1422   1.2055     0.9474 0.34342605
> treatmentI             0.2228   1.0840     0.2055 0.83716432
> siteuse               -0.0004   0.0013    -0.3159 0.75211206
>
>
>
>
> treatmentB:siteuse     0.0012   0.0019     0.6217 0.53413206
> treatmentC:siteuse     0.0011   0.0015     0.7460 0.45565644
> treatmentD:siteuse     0.0009   0.0016     0.5841 0.55913734
> treatmentE:siteuse     0.0004   0.0016     0.2355 0.81378524
> treatmentF:siteuse     0.0002   0.0016     0.1011 0.91943399
> treatmentG:siteuse    -0.0006   0.0015    -0.4202 0.67432023
> treatmentH:siteuse     0.0000   0.0018    -0.0278 0.97782476
> treatmentI:siteuse    -0.0019   0.0016    -1.1369 0.25559690
>
>
>
> Any insights would be most gratefully received.
>
> Thank you,
>
>
> Dr Georgina Southon
> Post-doctoral Researcher
> Department of Landscape
> The University of Sheffield
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Dec  3 20:05:58 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 Dec 2015 14:05:58 -0500
Subject: [R-sig-ME] A question about CLMM in R
In-Reply-To: <CAOE0pYko3dd393NGvL7R-0y4sKamTsY5zctDcAVgyB-VmBZ7=g@mail.gmail.com>
References: <33B498B6-6F19-4997-91A9-4A7D83D2F8E8@sheffield.ac.uk>
	<CAOE0pYko3dd393NGvL7R-0y4sKamTsY5zctDcAVgyB-VmBZ7=g@mail.gmail.com>
Message-ID: <CABghstSaMH0YjZkPC-N5o=budHOWxU-LQUrdoJ4fFx3kD=At5w@mail.gmail.com>

In general you want to use drop1() or anova() to get this.  If there
is an anova() method available,
then fit the model without the interaction:

reduced_model <- clmm2(location = preference ~ treatment + siteuse
,random+sample,Hess=TRUE

and do anova(full_model,reduced_model)


On Thu, Dec 3, 2015 at 1:12 PM, Dan McCloy <drmccloy at uw.edu> wrote:
> The column labeled Pr(>|z|) is the p-value provided by ordinal::clmm
> (it is also labeled this way in lme4::glmer among others).
>
> On Thu, Dec 3, 2015 at 9:01 AM, Georgina Southon
> <g.southon at sheffield.ac.uk> wrote:
>> Dear CLMM experts,
>>
>> I have been using the ordinal package in R to model ordinal response data with CLMM, with the inclusion of categorical predictor variables and interaction terms. The model returns perfectly coherent results thankfully (a truncated example attached), however it does not provide an overall P value for each interaction term. Is this possible to obtain when modelling with clmm?
>>
>> Call:
>> clmm2(location = preference ~ treatment + siteuse +treatment*siteuse,random+sample,Hess=TRUE
>>
>>
>>  random = sample,
>>     data = plops, Hess = TRUE)
>> Random effects:
>>             Var  Std.Dev
>> sample 1.660947 1.288777
>> Location coefficients:
>>                       Estimate Std. Error z value Pr(>|z|)
>> treatmentB             0.0736   1.4480     0.0508 0.95947987
>> treatmentC             0.8667   1.0871     0.7972 0.42531178
>> treatmentD             0.1548   1.1883     0.1303 0.89636709
>> treatmentE            -0.9512   1.3482    -0.7056 0.48046420
>> treatmentF             4.0151   1.2521     3.2066 0.00134313
>> treatmentG            -0.0489   1.0773    -0.0454 0.96376758
>> treatmentH             1.1422   1.2055     0.9474 0.34342605
>> treatmentI             0.2228   1.0840     0.2055 0.83716432
>> siteuse               -0.0004   0.0013    -0.3159 0.75211206
>>
>>
>>
>>
>> treatmentB:siteuse     0.0012   0.0019     0.6217 0.53413206
>> treatmentC:siteuse     0.0011   0.0015     0.7460 0.45565644
>> treatmentD:siteuse     0.0009   0.0016     0.5841 0.55913734
>> treatmentE:siteuse     0.0004   0.0016     0.2355 0.81378524
>> treatmentF:siteuse     0.0002   0.0016     0.1011 0.91943399
>> treatmentG:siteuse    -0.0006   0.0015    -0.4202 0.67432023
>> treatmentH:siteuse     0.0000   0.0018    -0.0278 0.97782476
>> treatmentI:siteuse    -0.0019   0.0016    -1.1369 0.25559690
>>
>>
>>
>> Any insights would be most gratefully received.
>>
>> Thank you,
>>
>>
>> Dr Georgina Southon
>> Post-doctoral Researcher
>> Department of Landscape
>> The University of Sheffield
>>
>>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From sophie.waegebaert at gmail.com  Mon Dec  7 12:02:36 2015
From: sophie.waegebaert at gmail.com (Sophie Waegebaert)
Date: Mon, 7 Dec 2015 12:02:36 +0100
Subject: [R-sig-ME] GLM: Difference between treatment groups for each colony
 (Tukey posthoc test)
Message-ID: <CAGH66HCePRSWq8t7LDm17k_BrzyZ+ZgOK-3dQkmEQ6J6YPiPug@mail.gmail.com>

Hi,

I'm still learning how to use R and I have some trouble making using Tukey
posthoc tests. I have a dataset with 3 colonies (A, B and C). Each colony
is divided into 2 treatments: control and DWV. I want to run a GLM to test
wether there is a difference in life expectancy (last.scan) between the
treatment groups for each of the colonies, but I do not know if I am using
the right strategy.

I have taken 'treatment' as a fixed factor and 'colony' as a random factor:

fit_life = lmer(last.scan~treatment + (1|colony), data =
data)Anova(fit_life, type = 3) # Type of treatment has a significant
effect on on the life expectancy.
    Response: last.scan
          Chisq Df Pr(>Chisq)
    (Intercept) 106.976  1  < 2.2e-16 ***
    treatment    25.373  1  4.724e-07 ***

And this is the code I use to do a Tukey posthoc test:

mcp = glht(fit_life, linfct = mcp(treatment = "Tukey"))
summary(mcp)# DWV treatment significantly changes life expectancy (z =
-9.734, p = < 2e-16)

Is it possible to find the difference for each colony?

Thanks a lot for an explanation or hint!

Cheers,

Sophie

	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Mon Dec  7 12:30:37 2015
From: paul.debes at utu.fi (paul debes)
Date: Mon, 07 Dec 2015 13:30:37 +0200
Subject: [R-sig-ME] GLM: Difference between treatment groups for each
 colony (Tukey posthoc test)
In-Reply-To: <CAGH66HCePRSWq8t7LDm17k_BrzyZ+ZgOK-3dQkmEQ6J6YPiPug@mail.gmail.com>
References: <CAGH66HCePRSWq8t7LDm17k_BrzyZ+ZgOK-3dQkmEQ6J6YPiPug@mail.gmail.com>
Message-ID: <op.x89t9bjja3mgvf@armadillo>

Hi Sophie and List,

If you are interested in the treatment contrasts for each level of the  
Colony factor (with three levels), it may be better to view your  
experiment as a factorial and specify a simple linear model rather than  
the presently specified linear mixed model. A random Colony term with only  
three levels may also not provide the best estimate for the correlation of  
colony data between treatments (i.e., as intraclass correlation) that is  
taken into account when testing the general treatment term.

Would this work for you?:

fit_life = lm(last.scan ~ 1 + treatment*colony, data = data)

In case the treatment:colony term is significant you could conduct the  
additional pairwise tests of interest.

Best,
Paul



On Mon, 07 Dec 2015 13:02:36 +0200, Sophie Waegebaert  
<sophie.waegebaert at gmail.com> wrote:

> Hi,
>
> I'm still learning how to use R and I have some trouble making using  
> Tukey
> posthoc tests. I have a dataset with 3 colonies (A, B and C). Each colony
> is divided into 2 treatments: control and DWV. I want to run a GLM to  
> test
> wether there is a difference in life expectancy (last.scan) between the
> treatment groups for each of the colonies, but I do not know if I am  
> using
> the right strategy.
>
> I have taken 'treatment' as a fixed factor and 'colony' as a random  
> factor:
>
> fit_life = lmer(last.scan~treatment + (1|colony), data =
> data)Anova(fit_life, type = 3) # Type of treatment has a significant
> effect on on the life expectancy.
>     Response: last.scan
>           Chisq Df Pr(>Chisq)
>     (Intercept) 106.976  1  < 2.2e-16 ***
>     treatment    25.373  1  4.724e-07 ***
>
> And this is the code I use to do a Tukey posthoc test:
>
> mcp = glht(fit_life, linfct = mcp(treatment = "Tukey"))
> summary(mcp)# DWV treatment significantly changes life expectancy (z =
> -9.734, p = < 2e-16)
>
> Is it possible to find the difference for each colony?
>
> Thanks a lot for an explanation or hint!
>
> Cheers,
>
> Sophie
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland


From sophie.waegebaert at gmail.com  Mon Dec  7 13:12:37 2015
From: sophie.waegebaert at gmail.com (Sophie Waegebaert)
Date: Mon, 7 Dec 2015 13:12:37 +0100
Subject: [R-sig-ME] GLM: Difference between treatment groups for each
 colony (Tukey posthoc test)
In-Reply-To: <op.x89t9bjja3mgvf@armadillo>
References: <CAGH66HCePRSWq8t7LDm17k_BrzyZ+ZgOK-3dQkmEQ6J6YPiPug@mail.gmail.com>
	<op.x89t9bjja3mgvf@armadillo>
Message-ID: <CAGH66HBoJtu8B-A_FeS54ObvwXch8+j7_Cy3Hkey8VZLpt8GSQ@mail.gmail.com>

Hi Paul,

Thank you very much for the hint!

The treatment:colony term is not significant, so I will not include it in
the model.

However, I get the same results for the Tukey posthoc test as I had before.
I am able to say that the DWV treatment significantly reduces the life
expectancy, but I do not know the difference between the colonies. With the
results of the Tukey test I want to make a figure (see attachment), but I
do not know how to do it. The asterisks are based on Tukey posthoc test.

Do you know a way to do this in R?

Thanks a lot!

Cheers,
Sophie



2015-12-07 12:30 GMT+01:00 paul debes <paul.debes at utu.fi>:

> Hi Sophie and List,
>
> If you are interested in the treatment contrasts for each level of the
> Colony factor (with three levels), it may be better to view your experiment
> as a factorial and specify a simple linear model rather than the presently
> specified linear mixed model. A random Colony term with only three levels
> may also not provide the best estimate for the correlation of colony data
> between treatments (i.e., as intraclass correlation) that is taken into
> account when testing the general treatment term.
>
> Would this work for you?:
>
> fit_life = lm(last.scan ~ 1 + treatment*colony, data = data)
>
> In case the treatment:colony term is significant you could conduct the
> additional pairwise tests of interest.
>
> Best,
> Paul
>
>
>
> On Mon, 07 Dec 2015 13:02:36 +0200, Sophie Waegebaert <
> sophie.waegebaert at gmail.com> wrote:
>
> Hi,
>>
>> I'm still learning how to use R and I have some trouble making using Tukey
>> posthoc tests. I have a dataset with 3 colonies (A, B and C). Each colony
>> is divided into 2 treatments: control and DWV. I want to run a GLM to test
>> wether there is a difference in life expectancy (last.scan) between the
>> treatment groups for each of the colonies, but I do not know if I am using
>> the right strategy.
>>
>> I have taken 'treatment' as a fixed factor and 'colony' as a random
>> factor:
>>
>> fit_life = lmer(last.scan~treatment + (1|colony), data =
>> data)Anova(fit_life, type = 3) # Type of treatment has a significant
>> effect on on the life expectancy.
>>     Response: last.scan
>>           Chisq Df Pr(>Chisq)
>>     (Intercept) 106.976  1  < 2.2e-16 ***
>>     treatment    25.373  1  4.724e-07 ***
>>
>> And this is the code I use to do a Tukey posthoc test:
>>
>> mcp = glht(fit_life, linfct = mcp(treatment = "Tukey"))
>> summary(mcp)# DWV treatment significantly changes life expectancy (z =
>> -9.734, p = < 2e-16)
>>
>> Is it possible to find the difference for each colony?
>>
>> Thanks a lot for an explanation or hint!
>>
>> Cheers,
>>
>> Sophie
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Paul Debes
> DFG Research Fellow
> University of Turku
> Department of Biology
> It?inen Pitk?katu 4
> 20520 Turku
> Finland
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

From paul.debes at utu.fi  Mon Dec  7 13:49:28 2015
From: paul.debes at utu.fi (paul debes)
Date: Mon, 07 Dec 2015 14:49:28 +0200
Subject: [R-sig-ME] GLM: Difference between treatment groups for each
 colony (Tukey posthoc test)
In-Reply-To: <CAGH66HBoJtu8B-A_FeS54ObvwXch8+j7_Cy3Hkey8VZLpt8GSQ@mail.gmail.com>
References: <CAGH66HCePRSWq8t7LDm17k_BrzyZ+ZgOK-3dQkmEQ6J6YPiPug@mail.gmail.com>
	<op.x89t9bjja3mgvf@armadillo>
	<CAGH66HBoJtu8B-A_FeS54ObvwXch8+j7_Cy3Hkey8VZLpt8GSQ@mail.gmail.com>
Message-ID: <op.x89xwqita3mgvf@armadillo>

Hi Sophie,

If the treatment:colony term is NS, what about the colony term?

If the colony term is NS, you could also remove the colony term from the  
model and only leave the treatment term in the model (no need for a  
post-hoc test for the treatment term: it has only two levels: F-test/LRT  
results are sufficient).

If the colony term is also important (but the interaction is NS), the  
treatment effects are the same for each level of colony, and the colony  
effects differ from each other similarly within each treatment level. To  
find what colony levels differ from each other you will need to specify  
the colony term for your post-hoc test.
You can plot the means in two ways, depending on what is your study focus:  
1) two means for the two treatments averaged across colonies AND/OR 3  
means for the three colonies averaged across treatments (in 2 figures). 2)  
six means of the three colonies within each treatment, or vice versa (1  
figure).

To predict model means for many model types, I personally like using the  
library "lsmeans".
This might work (use "summary" to facilitate getting the results as  
data.frame for easier plotting):

library(lsmeans)
model.means.treatment = data.frame(summary(lsmeans(model, ~ treatment)))
model.means.colony = data.frame(summary(lsmeans(model, ~ colony)))
model.means.inter = data.frame(summary(lsmeans(model, ~ treatment:colony)))

Hope this helps,
Paul


On Mon, 07 Dec 2015 14:12:37 +0200, Sophie Waegebaert  
<sophie.waegebaert at gmail.com> wrote:

> Hi Paul,
>
> Thank you very much for the hint!
>
> The treatment:colony term is not significant, so I will not include it in
> the model.
>
> However, I get the same results for the Tukey posthoc test as I had  
> before.
> I am able to say that the DWV treatment significantly reduces the life
> expectancy, but I do not know the difference between the colonies. With  
> the
> results of the Tukey test I want to make a figure (see attachment), but I
> do not know how to do it. The asterisks are based on Tukey posthoc test.
>
> Do you know a way to do this in R?
>
> Thanks a lot!
>
> Cheers,
> Sophie
>
>
>
> 2015-12-07 12:30 GMT+01:00 paul debes <paul.debes at utu.fi>:
>
>> Hi Sophie and List,
>>
>> If you are interested in the treatment contrasts for each level of the
>> Colony factor (with three levels), it may be better to view your  
>> experiment
>> as a factorial and specify a simple linear model rather than the  
>> presently
>> specified linear mixed model. A random Colony term with only three  
>> levels
>> may also not provide the best estimate for the correlation of colony  
>> data
>> between treatments (i.e., as intraclass correlation) that is taken into
>> account when testing the general treatment term.
>>
>> Would this work for you?:
>>
>> fit_life = lm(last.scan ~ 1 + treatment*colony, data = data)
>>
>> In case the treatment:colony term is significant you could conduct the
>> additional pairwise tests of interest.
>>
>> Best,
>> Paul
>>
>>
>>
>> On Mon, 07 Dec 2015 13:02:36 +0200, Sophie Waegebaert <
>> sophie.waegebaert at gmail.com> wrote:
>>
>> Hi,
>>>
>>> I'm still learning how to use R and I have some trouble making using  
>>> Tukey
>>> posthoc tests. I have a dataset with 3 colonies (A, B and C). Each  
>>> colony
>>> is divided into 2 treatments: control and DWV. I want to run a GLM to  
>>> test
>>> wether there is a difference in life expectancy (last.scan) between the
>>> treatment groups for each of the colonies, but I do not know if I am  
>>> using
>>> the right strategy.
>>>
>>> I have taken 'treatment' as a fixed factor and 'colony' as a random
>>> factor:
>>>
>>> fit_life = lmer(last.scan~treatment + (1|colony), data =
>>> data)Anova(fit_life, type = 3) # Type of treatment has a significant
>>> effect on on the life expectancy.
>>>     Response: last.scan
>>>           Chisq Df Pr(>Chisq)
>>>     (Intercept) 106.976  1  < 2.2e-16 ***
>>>     treatment    25.373  1  4.724e-07 ***
>>>
>>> And this is the code I use to do a Tukey posthoc test:
>>>
>>> mcp = glht(fit_life, linfct = mcp(treatment = "Tukey"))
>>> summary(mcp)# DWV treatment significantly changes life expectancy (z =
>>> -9.734, p = < 2e-16)
>>>
>>> Is it possible to find the difference for each colony?
>>>
>>> Thanks a lot for an explanation or hint!
>>>
>>> Cheers,
>>>
>>> Sophie
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Paul Debes
>> DFG Research Fellow
>> University of Turku
>> Department of Biology
>> It?inen Pitk?katu 4
>> 20520 Turku
>> Finland
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


-- 
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland


From dakotajudo at mac.com  Mon Dec  7 15:43:14 2015
From: dakotajudo at mac.com (Peter Claussen)
Date: Mon, 07 Dec 2015 08:43:14 -0600
Subject: [R-sig-ME] GLM: Difference between treatment groups for each
 colony (Tukey posthoc test)
In-Reply-To: <CAGH66HCePRSWq8t7LDm17k_BrzyZ+ZgOK-3dQkmEQ6J6YPiPug@mail.gmail.com>
References: <CAGH66HCePRSWq8t7LDm17k_BrzyZ+ZgOK-3dQkmEQ6J6YPiPug@mail.gmail.com>
Message-ID: <09825FAB-145F-4B88-B18A-EB86B6C6A961@mac.com>

Sophie,

As I read this, you are mixing analysis.

You?ve specified ?treatment? as fixed and ?colony? as random. In this analysis, it is reasonable to perform posthoc comparisons on treatment, but not on colony. Colony is a random variable and each colony is simply drawn from a larger pool, one just as likely as the other. 

The Anova table based on a mixed model only reports fixed effects, and that is proper. If you want to get an estimate of how much variation is associated with colonies, use 

summary(fit_life)
or
VarCorr(fit_life)

This will report the variance associated with colonies, and you might judge from the magnitude of this term how different are the colonies - how variable is your population of colonies. The caveat is that with only 3 colonies, you might not get an accurate estimate.

Peter

> On Dec 7, 2015, at 5:02 AM, Sophie Waegebaert <sophie.waegebaert at gmail.com> wrote:
> 
> Hi,
> 
> I'm still learning how to use R and I have some trouble making using Tukey
> posthoc tests. I have a dataset with 3 colonies (A, B and C). Each colony
> is divided into 2 treatments: control and DWV. I want to run a GLM to test
> wether there is a difference in life expectancy (last.scan) between the
> treatment groups for each of the colonies, but I do not know if I am using
> the right strategy.
> 
> I have taken 'treatment' as a fixed factor and 'colony' as a random factor:
> 
> fit_life = lmer(last.scan~treatment + (1|colony), data =
> data)Anova(fit_life, type = 3) # Type of treatment has a significant
> effect on on the life expectancy.
>    Response: last.scan
>          Chisq Df Pr(>Chisq)
>    (Intercept) 106.976  1  < 2.2e-16 ***
>    treatment    25.373  1  4.724e-07 ***
> 
> And this is the code I use to do a Tukey posthoc test:
> 
> mcp = glht(fit_life, linfct = mcp(treatment = "Tukey"))
> summary(mcp)# DWV treatment significantly changes life expectancy (z =
> -9.734, p = < 2e-16)
> 
> Is it possible to find the difference for each colony?
> 
> Thanks a lot for an explanation or hint!
> 
> Cheers,
> 
> Sophie
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From rehan101 at gmail.com  Sun Dec  6 11:08:41 2015
From: rehan101 at gmail.com (REHAN UL HAQ)
Date: Sun, 6 Dec 2015 17:08:41 +0700
Subject: [R-sig-ME] Random intercept and slope after model Averaging
Message-ID: <CAMMgeAA1esRHOpcvxp-sGz-LAJepyQG57Es+4pU8OiQ9m=RMDQ@mail.gmail.com>

Hello All,

I did model averaging for a mixed model, and now i want to find the
estimates of Random variable after model averaging,
my random variable is Dry and Wet season.
My models are
1)model1<- glmmadmb(Birds~DO+evap+precipitation+Turbidity
+(1|season),data=a,"nbinom")
2)model2<-glmmadmb(Birds~DO+temp+precipitation+Turbidity
+(1|season),data=a,"nbinom")
then i did model averaging as under
Avgmodel<-model.avg(model1,model2)

Here is the summary.
Component model call:
glmmadmb(formula = <2 unique values>, data = a, family = nbinom)

Component models:
df logLik AICc delta weight
1245 7 -539.36 1093.56 0.00 0.7
1345 7 -540.23 1095.30 1.74 0.3

Term codes:
DO evap temp preci Turb
1 2 3 4 5

Model-averaged coefficients:
(full average)
Estimate Std. Error Adjusted SE z value Pr(>|z|)
(Intercept) -3.2065 3.2864 3.2968 0.973 0.33075
DO 1.1228 0.4082 0.4119 2.726 0.00641 **
evap 0.9174 0.6821 0.6836 1.342 0.17961
preci -1.6303 0.5586 0.5636 2.893 0.00382 **
Turb 1.2183 0.4086 0.4122 2.955 0.00312 **
temp 0.3124 0.5135 0.5140 0.608 0.54335

(conditional average)
Estimate Std. Error Adjusted SE z value Pr(>|z|)
(Intercept) -3.2065 3.2864 3.2968 0.973 0.33075
DO 1.1228 0.4082 0.4119 2.726 0.00641 **
evap 1.3021 0.3994 0.4029 3.232 0.00123 **
preci -1.6303 0.5586 0.5636 2.893 0.00382 **
Turb 1.2183 0.4086 0.4122 2.955 0.00312 **
temp 1.0574 0.3236 0.3265 3.238 0.00120 **
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Relative variable importance:
DO preci Turb evap temp
Importance: 1.0 1.0 1.0 0.7 0.3
N containing models: 2 2 2 1 1


If i want to get random effects of model 1 or model 2 specifically i can
get them through
ranef(model1)
But how to get random effects after model averaging.
I can get the estimates of fixed parameters by summary(Avgmodel),
but how to get intercept and slopes for random variable?

any help will be appreciated.

Regards

	[[alternative HTML version deleted]]


From marprzyst at gmail.com  Mon Dec  7 10:42:51 2015
From: marprzyst at gmail.com (Marcin Przystalski)
Date: Mon, 7 Dec 2015 10:42:51 +0100
Subject: [R-sig-ME] questions on glmmADMB package
Message-ID: <CAAzdjeS-CuEPv6iAnmoAfGzmo-Rif2U9p_nPX7nLdq9RkhXF0g@mail.gmail.com>

Dear All,

I've got several questions related to the package glmmADMB.



First. Correct me if I'm wrong. To find the estimates of unknown parameters
You apply the maximum likelihood method via Laplace approximation with the
restriction \alpha_{1}=0, i.e. that general mean can treated as the effect
of first object?

The second question is related with testing the hypotheses H_{0}:
\alpha_{k}=0. Do You use the following test statistic



z=\frac{\hat{\alpha}_{k}-\alpha_{k}}/\hat{\sigma}_{k}?



Further, You say that this test statistic under the null hypothesis has
N(0,1)?



I would be grateful for answering the questions.



Best regards


Marcin

	[[alternative HTML version deleted]]


From davef at otter-rsch.com  Mon Dec  7 19:42:30 2015
From: davef at otter-rsch.com (dave fournier)
Date: Mon, 7 Dec 2015 10:42:30 -0800
Subject: [R-sig-ME] questions on glmmADMB package
In-Reply-To: <CAAzdjeS-CuEPv6iAnmoAfGzmo-Rif2U9p_nPX7nLdq9RkhXF0g@mail.gmail.com>
References: <CAAzdjeS-CuEPv6iAnmoAfGzmo-Rif2U9p_nPX7nLdq9RkhXF0g@mail.gmail.com>
Message-ID: <5665D316.1020903@otter-rsch.com>

The method is described in the (award winning) paper

http://www.tandfonline.com/doi/abs/10.1080/10556788.2011.597854#.VmXS3XpVLVM


From lorenz.gygax at agroscope.admin.ch  Tue Dec  8 13:42:48 2015
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Tue, 8 Dec 2015 12:42:48 +0000
Subject: [R-sig-ME] Vignettes RePsychLing
Message-ID: <7EC2E4DB4FC53A479711C3238C02EB83016EBA8E@sb00111a.adb.intra.admin.ch>

Dear all,

As a user of mixed-models - greatest thanks to all contributors to lme4 specifically! - I have read 
with interest the maybe not-so-recent-anymore discussion on how many random effects can reasonably be included in a mixed model for a given data set. I was intrigued by the use of pca to assess rank deficiency in mixed-models as suggested in "Parsimonous mixed models" by Doug Bates et al. (http://arxiv.org/abs/1506.04967). As suggested there, I wanted to check the vignette(s) for RePsychLing on how to use the rePCA function.

I have followed the instruction on Harald Baayen's site (http://www.sfs.uni-tuebingen.de/~hbaayen/publications.html):

library(devtools) 
devtools::install_github("dmbates/RePsychLing") 
vignette(package="RePsychLing")
vignette("PCA", package="RePsychLing")
vignette("KB", package="RePsychLing")

The installation runs without error and seems to be doing fine. When I try to call the vignettes, though, there is an error telling me that there is no pdf nor html version. Can you tell me what crucial point I am missing here?

Many thanks and regards, Lorenz
-
Lorenz Gygax
Federal Food Safety and Veterinary Office FFSVO
Centre for Proper Housing of Ruminants and Pigs
T?nikon, CH-8356 Ettenhausen, Switzerland


From h.wickham at gmail.com  Tue Dec  8 13:48:50 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 8 Dec 2015 06:48:50 -0600
Subject: [R-sig-ME] Vignettes RePsychLing
In-Reply-To: <7EC2E4DB4FC53A479711C3238C02EB83016EBA8E@sb00111a.adb.intra.admin.ch>
References: <7EC2E4DB4FC53A479711C3238C02EB83016EBA8E@sb00111a.adb.intra.admin.ch>
Message-ID: <CABdHhvHcK4OwG1_PUKfd+Sma4GOjz-b2ncqnzzgAs+uhQrPj0w@mail.gmail.com>

Try

devtools::install_github("dmbates/RePsychLing", build_vignettes = TRUE)

Hadley

On Tue, Dec 8, 2015 at 6:42 AM,  <lorenz.gygax at agroscope.admin.ch> wrote:
> Dear all,
>
> As a user of mixed-models - greatest thanks to all contributors to lme4 specifically! - I have read
> with interest the maybe not-so-recent-anymore discussion on how many random effects can reasonably be included in a mixed model for a given data set. I was intrigued by the use of pca to assess rank deficiency in mixed-models as suggested in "Parsimonous mixed models" by Doug Bates et al. (http://arxiv.org/abs/1506.04967). As suggested there, I wanted to check the vignette(s) for RePsychLing on how to use the rePCA function.
>
> I have followed the instruction on Harald Baayen's site (http://www.sfs.uni-tuebingen.de/~hbaayen/publications.html):
>
> library(devtools)
> devtools::install_github("dmbates/RePsychLing")
> vignette(package="RePsychLing")
> vignette("PCA", package="RePsychLing")
> vignette("KB", package="RePsychLing")
>
> The installation runs without error and seems to be doing fine. When I try to call the vignettes, though, there is an error telling me that there is no pdf nor html version. Can you tell me what crucial point I am missing here?
>
> Many thanks and regards, Lorenz
> -
> Lorenz Gygax
> Federal Food Safety and Veterinary Office FFSVO
> Centre for Proper Housing of Ruminants and Pigs
> T?nikon, CH-8356 Ettenhausen, Switzerland
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
http://had.co.nz/


From lorenz.gygax at agroscope.admin.ch  Wed Dec  9 07:34:00 2015
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Wed, 9 Dec 2015 06:34:00 +0000
Subject: [R-sig-ME] Vignettes RePsychLing
In-Reply-To: <CABdHhvHcK4OwG1_PUKfd+Sma4GOjz-b2ncqnzzgAs+uhQrPj0w@mail.gmail.com>
References: <7EC2E4DB4FC53A479711C3238C02EB83016EBA8E@sb00111a.adb.intra.admin.ch>
	<CABdHhvHcK4OwG1_PUKfd+Sma4GOjz-b2ncqnzzgAs+uhQrPj0w@mail.gmail.com>
Message-ID: <7EC2E4DB4FC53A479711C3238C02EB83016EC53A@sb00111a.adb.intra.admin.ch>

Dear all, dear Hadley,

thank you Hadley for proposing the (in hindsight) quite obvious

> devtools::install_github("dmbates/RePsychLing", build_vignettes = TRUE)

which brought me on the right track. After fiddling a bit with installing correctly all necessary R-packages in the latest versions (specifically stringi, curl) and some additional software (pandoc, LaTeX), the installation clearly went further:

R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)
...

> devtools::install_github("dmbates/RePsychLing", build_vignettes = 
> TRUE)
Downloading GitHub repo dmbates/RePsychLing at master Installing RePsychLing "C:/PROGRA~1/R/R-32~1.2/bin/x64/R" --no-site-file --no-environ --no-save --no-restore CMD build  \
  "C:\Users\lorenz\AppData\Local\Temp\RtmpuQICTP\devtools3058b542da6\dmbates-RePsychLing-aec0878" --no-resave-data --no-manual 

* checking for file 'C:\Users\lorenz\AppData\Local\Temp\RtmpuQICTP\devtools3058b542da6\dmbates-RePsychLing-aec0878/DESCRIPTION' ... OK
* preparing 'RePsychLing':
* checking DESCRIPTION meta-information ... OK
* installing the package to build vignettes
* creating vignettes ...Warnung: Ausf?hrung von Kommando '"C:/PROGRA~1/R/R-32~1.2/bin/x64/Rscript" --vanilla --default-packages= -e "tools::buildVignettes(dir = '.', tangle = TRUE)"' ergab Status 1  ERROR Quitting from lines 322-333 (KBStan.Rmd)
Fehler: Verarbeitung der Vignette 'KBStan.Rmd' mit folgender Diagnose fehlgeschlagen:
'mc.cores' > 1 is not supported on Windows Ausf?hrung angehalten
Fehler: Command failed (1)

Obviously, a multi-core request is made here which does not work on windows (I am sorry that I have no other platform available ...). Can I myself easily circumvent this problem? Or is an adjustment needed in the .Rmd file that catches windows systems and adjusts this request?

Many thanks again, Lorenz


> On Tue, Dec 8, 2015 at 6:42 AM,  <lorenz.gygax at agroscope.admin.ch> wrote:
> > Dear all,
> >
> > As a user of mixed-models - greatest thanks to all contributors to lme4
> specifically! - I have read
> > with interest the maybe not-so-recent-anymore discussion on how many random
> effects can reasonably be included in a mixed model for a given data set. I was
> intrigued by the use of pca to assess rank deficiency in mixed-models as suggested
> in "Parsimonous mixed models" by Doug Bates et al.
> (http://arxiv.org/abs/1506.04967). As suggested there, I wanted to check the
> vignette(s) for RePsychLing on how to use the rePCA function.
> >
> > I have followed the instruction on Harald Baayen's site (http://www.sfs.uni-
> tuebingen.de/~hbaayen/publications.html):
> >
> > library(devtools)
> > devtools::install_github("dmbates/RePsychLing")
> > vignette(package="RePsychLing")
> > vignette("PCA", package="RePsychLing")
> > vignette("KB", package="RePsychLing")
> >
> > The installation runs without error and seems to be doing fine. When I try to call
> the vignettes, though, there is an error telling me that there is no pdf nor html
> version. Can you tell me what crucial point I am missing here?
> >
> > Many thanks and regards, Lorenz
> > -
> > Lorenz Gygax
> > Federal Food Safety and Veterinary Office FFSVO
> > Centre for Proper Housing of Ruminants and Pigs
> > T?nikon, CH-8356 Ettenhausen, Switzerland
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> --
> http://had.co.nz/

From Tom.Wilding at sams.ac.uk  Wed Dec  9 11:18:49 2015
From: Tom.Wilding at sams.ac.uk (Tom Wilding)
Date: Wed, 9 Dec 2015 10:18:49 +0000
Subject: [R-sig-ME] Mixed model predictions using sim
Message-ID: <VI1PR02MB1102C21B86528335D5F00519C4E80@VI1PR02MB1102.eurprd02.prod.outlook.com>

Dear Mailing list

I'm using lme4 to conduct mixed models and then, in accordance with several authors I'm using the library 'arm' to simulate from that model to generate confidence intervals for my parameter estimates (see Korner-Nievergelt, F. et al ., 2015. Bayesian data analysis in ecology using linear models with R, BUGS and Stan. Elsevier).

I would like to know more about the relationship between the Credible Intervals (CrI) and the Confidence Intervals (2.5,50 and 97.5% quantiles) generated from model predictions.  I'm particularly interested to know why the Credible Intervals (given in 'CrI.MLexamp.9' below), for values of the intercept (i.e. when the predictor is zero) are reflected very accurately in the quantiles from the Predictions ('MLexamp.9.Pred' as below) yet there is a discrepancy between values predicted by the CrI and the 95% CI quantiles from the Predictions at, e.g., 60 units of 'open' in the example below.  How does one move between the CrI to the model predictions?  Why the difference?  (In my real example, the discrepancy is more meaningful).

The data (thanks) I've used in this example is from:

http://jaredknowles.com/journal/2013/11/25/getting-started-with-mixed-effect-models-in-r

Any pointers would be much appreciated.

Thanks

Tom
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

The following script might take 30 seconds to run...

library(lme4)
library(arm)
lmm.data=read.table("http://www.unt.edu/rss/class/Jon/R_SC/Module9/lmm.data.txt",
                       header = TRUE, sep = ",", na.strings = "NA", dec = ".", strip.white = TRUE)
MLexamp.9=lmer(extro ~ open  + (1 + open | school/class),
                  data = lmm.data)
#summary(MLexamp.9)
nsim=20000
MLexamp.9.sim=sim (MLexamp.9,n.sim=nsim); #
colnames(MLexamp.9.sim at fixef)=names(fixef(MLexamp.9))<mailto:MLexamp.9.sim at fixef)=names(fixef(MLexamp.9))>

#generate CrIs.
CrI.MLexamp.9=as.data.frame(signif(apply(MLexamp.9.sim at fixef,2,quantile,prob=c(0.025,0.5,0.975)),5))

MLexamp.9.Pred=data.frame(open=c(0,20,40,60))#realistic values and zero.
MLexamp.9.Pred.Matrix=model.matrix(~open,data=MLexamp.9.Pred)
MLexamp.9.Pred$fit=(MLexamp.9.Pred.Matrix%*%fixef(MLexamp.9))#

fitmat=matrix(nrow=nrow(MLexamp.9.Pred),ncol=nsim)#
for(i in 1:nsim) fitmat[,i]=(MLexamp.9.Pred.Matrix%*%MLexamp.9.sim at fixef[i,])#

MLexamp.9.Pred$LowerCI=apply(fitmat,1,quantile,prob=0.025)
MLexamp.9.Pred$Middle=apply(fitmat,1,quantile,prob=0.500)
MLexamp.9.Pred$UpperCI=apply(fitmat,1,quantile,prob=0.975)
CrI.MLexamp.9
MLexamp.9.Pred
The Scottish Association for Marine Science (SAMS) is registered in Scotland as a Company Limited by Guarantee (SC009292) and is a registered charity (9206). SAMS has two actively trading wholly owned subsidiary companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912). All Companies in the group are registered in Scotland and share a registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The content of this message may contain personal views which are not the views of SAMS unless specifically stated. Please note that all email traffic is monitored for purposes of security and spam filtering. As such individual emails may be examined in more detail.

	[[alternative HTML version deleted]]


From killver at gmail.com  Wed Dec  9 15:17:21 2015
From: killver at gmail.com (Philipp Singer)
Date: Wed, 9 Dec 2015 15:17:21 +0100
Subject: [R-sig-ME] Understanding different (residual) output for glmer.nb
	vs glmmPQL
Message-ID: <566837F1.4070108@gmail.com>

I am currently trying to understand the different output I receive when 
fitting a negative binomial mixed-effects model with both glmer.nb and 
glmmPQL.

I run the first via

glmer_nb = glmer.nb(outcome~1+x+y+(1|subject),data=data)

and the second via

glm_nb <- glm.nb(outcome~1+x+y, data = data)
theta = theta of glm_nb1 (e.g, in my case 0.97)
glmm_pql = glmmPQL(outcome~1+x+y, random=list(~1|subject),data=data, 
family = negative.binomial(theta = 0.97 , link = log))

For the glmer_nb model I receive multiple no convergence warnings:

In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, : 
Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, : 
Model failed to converge with max|grad| = 0.0010975 (tol = 0.001, 
component 1)Warning message:

The glmm_pql runs fine (much faster as well)

In general, the coefficients are very similar. However, when looking at 
the residuals I can identify vast differences.

The residual diagnostics can be seen here:

http://imgur.com/a/MhZRu

Please enlarge the pngs to properly see them.

http://imgur.com/pdtVumg shows fitted vs. residuals for glm_nb
http://imgur.com/B0Qp6g9 shows qqnorm residuals for glm_nb
http://imgur.com/OVObgCz shows a qqplot based on random variates for a 
nb distr derived as follows:

getME(glmer_nb, "glmer.nb.theta")
10.0560436934476
nbquant<-rnbinom(n=length(data$outcome), size=10, mu=mean(data$size))
qqplot(nbquant,resid(glmer_nb))

http://imgur.com/ByUKR5b shows fitted vs. residuals for glmm_pql
http://imgur.com/Bg6qpnR shows qqnorm for residuals for glmm_pql
http://imgur.com/kDta9j9 shows qqplot based on random variates as above

nbquant<-rnbinom(n=length(data$outcome), size=0.97, mu=mean(data$outcome))
qqplot(nbquant,resid(glmm_pql))

My main questions now are:

1.) Can someone explain to me the differences in residual distributions?
2.) How much impact should I give the no convergence
3.) What are some general guidelines for diagnosing residual plots in 
glmers (this is a more abstract and larger question).

Thanks!
Philipp


From vjd4 at nyu.edu  Wed Dec  9 22:06:28 2015
From: vjd4 at nyu.edu (Vincent Dorie)
Date: Wed, 9 Dec 2015 16:06:28 -0500
Subject: [R-sig-ME] Mixed model predictions using sim
In-Reply-To: <VI1PR02MB1102C21B86528335D5F00519C4E80@VI1PR02MB1102.eurprd02.prod.outlook.com>
References: <VI1PR02MB1102C21B86528335D5F00519C4E80@VI1PR02MB1102.eurprd02.prod.outlook.com>
Message-ID: <CAAQ+4boKGnSgKC-u+5Sd-i3H0zBfGY0V85u=ehQX+LSexAG7iw@mail.gmail.com>

Hi Tom,

If I'm following you correctly, the difference is due to the inclusion of
uncertainty in the slope term which is not present in the term for open !=
0. The quantiles are actually identical if you omit the signif call.

A more accurate representation of uncertain for new observations might be
to use the posterior predictive distribution. This can be obtained by
adding some rnorm using the sample of sigma (assuming that you were
interested in observations in a new group).

Vince

On Wed, Dec 9, 2015 at 5:18 AM, Tom Wilding <Tom.Wilding at sams.ac.uk> wrote:

> Dear Mailing list
>
> I'm using lme4 to conduct mixed models and then, in accordance with
> several authors I'm using the library 'arm' to simulate from that model to
> generate confidence intervals for my parameter estimates (see
> Korner-Nievergelt, F. et al ., 2015. Bayesian data analysis in ecology
> using linear models with R, BUGS and Stan. Elsevier).
>
> I would like to know more about the relationship between the Credible
> Intervals (CrI) and the Confidence Intervals (2.5,50 and 97.5% quantiles)
> generated from model predictions.  I'm particularly interested to know why
> the Credible Intervals (given in 'CrI.MLexamp.9' below), for values of the
> intercept (i.e. when the predictor is zero) are reflected very accurately
> in the quantiles from the Predictions ('MLexamp.9.Pred' as below) yet there
> is a discrepancy between values predicted by the CrI and the 95% CI
> quantiles from the Predictions at, e.g., 60 units of 'open' in the example
> below.  How does one move between the CrI to the model predictions?  Why
> the difference?  (In my real example, the discrepancy is more meaningful).
>
> The data (thanks) I've used in this example is from:
>
>
> http://jaredknowles.com/journal/2013/11/25/getting-started-with-mixed-effect-models-in-r
>
> Any pointers would be much appreciated.
>
> Thanks
>
> Tom
>
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> The following script might take 30 seconds to run...
>
> library(lme4)
> library(arm)
> lmm.data=read.table("
> http://www.unt.edu/rss/class/Jon/R_SC/Module9/lmm.data.txt",
>                        header = TRUE, sep = ",", na.strings = "NA", dec =
> ".", strip.white = TRUE)
> MLexamp.9=lmer(extro ~ open  + (1 + open | school/class),
>                   data = lmm.data)
> #summary(MLexamp.9)
> nsim=20000
> MLexamp.9.sim=sim (MLexamp.9,n.sim=nsim); #
> colnames(MLexamp.9.sim at fixef)=names(fixef(MLexamp.9))<mailto:
> MLexamp.9.sim at fixef)=names(fixef(MLexamp.9))>
>
> #generate CrIs.
> CrI.MLexamp.9=as.data.frame(signif(apply(MLexamp.9.sim at fixef
> ,2,quantile,prob=c(0.025,0.5,0.975)),5))
>
> MLexamp.9.Pred=data.frame(open=c(0,20,40,60))#realistic values and zero.
> MLexamp.9.Pred.Matrix=model.matrix(~open,data=MLexamp.9.Pred)
> MLexamp.9.Pred$fit=(MLexamp.9.Pred.Matrix%*%fixef(MLexamp.9))#
>
> fitmat=matrix(nrow=nrow(MLexamp.9.Pred),ncol=nsim)#
> for(i in 1:nsim) fitmat[,i]=(MLexamp.9.Pred.Matrix%*%MLexamp.9.sim at fixef
> [i,])#
>
> MLexamp.9.Pred$LowerCI=apply(fitmat,1,quantile,prob=0.025)
> MLexamp.9.Pred$Middle=apply(fitmat,1,quantile,prob=0.500)
> MLexamp.9.Pred$UpperCI=apply(fitmat,1,quantile,prob=0.975)
> CrI.MLexamp.9
> MLexamp.9.Pred
> The Scottish Association for Marine Science (SAMS) is registered in
> Scotland as a Company Limited by Guarantee (SC009292) and is a registered
> charity (9206). SAMS has two actively trading wholly owned subsidiary
> companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912).
> All Companies in the group are registered in Scotland and share a
> registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The
> content of this message may contain personal views which are not the views
> of SAMS unless specifically stated. Please note that all email traffic is
> monitored for purposes of security and spam filtering. As such individual
> emails may be examined in more detail.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Tom.Wilding at sams.ac.uk  Thu Dec 10 11:01:35 2015
From: Tom.Wilding at sams.ac.uk (Tom Wilding)
Date: Thu, 10 Dec 2015 10:01:35 +0000
Subject: [R-sig-ME] Mixed model predictions using sim
References: <VI1PR02MB1102C21B86528335D5F00519C4E80@VI1PR02MB1102.eurprd02.prod.outlook.com>
	<CAAQ+4boKGnSgKC-u+5Sd-i3H0zBfGY0V85u=ehQX+LSexAG7iw@mail.gmail.com> 
Message-ID: <VI1PR02MB110236DFEBD326876C77BDAAC4E90@VI1PR02MB1102.eurprd02.prod.outlook.com>

Hi Vince

Thanks for that.  I think I should expand on my question:

A ?snip? from a 20,000 simulation run is attached.

The intercept values quantiles for the intercepts (52.26827...67.6602) are repeated in the Predicted values (LowerCI, Middle and UpperCI) for ?0? units of ?Open?, as we?ve noted.  Taking 60 units as an example, how do you determine the UpperCI?  It could be 67.66602+(60*0.016412019) = 68.6507 which is slightly (and trivially in this example) different from the UpperCI given in here.  In my real example the difference is larger (and meaningful).  My real example is based on a more complex model (multiple predictors ? all bar one of which are centred (and set at zero in the predictions) so don?t enter the manual calculation as used above).  The difference does not seem to be related to the number of simulations (there are still differences, of the same-magnitude, with 200,000 simulations).   Could the difference be attributable to the line:

for(i in 1:nsim) fitmat[,i]=(MLexamp.9.Pred.Matrix%*%MLexamp.9.sim at fixef[i,])

Does this line indicate that model predictions are based on the fixed-effects only from the simulations?  Basically, I?m still uncertain about how the Credible Intervals, for individual parameters in the model, relate to the Confidence Intervals and why there is an apparent difference.

Many thanks

Tom.

From: Vincent Dorie [mailto:vjd4 at nyu.edu]
Sent: 09 December 2015 21:06
To: Tom Wilding
Cc: R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed model predictions using sim

Hi Tom,

If I'm following you correctly, the difference is due to the inclusion of uncertainty in the slope term which is not present in the term for open != 0. The quantiles are actually identical if you omit the signif call.

A more accurate representation of uncertain for new observations might be to use the posterior predictive distribution. This can be obtained by adding some rnorm using the sample of sigma (assuming that you were interested in observations in a new group).

Vince

On Wed, Dec 9, 2015 at 5:18 AM, Tom Wilding <Tom.Wilding at sams.ac.uk<mailto:Tom.Wilding at sams.ac.uk>> wrote:
Dear Mailing list

I'm using lme4 to conduct mixed models and then, in accordance with several authors I'm using the library 'arm' to simulate from that model to generate confidence intervals for my parameter estimates (see Korner-Nievergelt, F. et al ., 2015. Bayesian data analysis in ecology using linear models with R, BUGS and Stan. Elsevier).

I would like to know more about the relationship between the Credible Intervals (CrI) and the Confidence Intervals (2.5,50 and 97.5% quantiles) generated from model predictions.  I'm particularly interested to know why the Credible Intervals (given in 'CrI.MLexamp.9' below), for values of the intercept (i.e. when the predictor is zero) are reflected very accurately in the quantiles from the Predictions ('MLexamp.9.Pred' as below) yet there is a discrepancy between values predicted by the CrI and the 95% CI quantiles from the Predictions at, e.g., 60 units of 'open' in the example below.  How does one move between the CrI to the model predictions?  Why the difference?  (In my real example, the discrepancy is more meaningful).

The data (thanks) I've used in this example is from:

http://jaredknowles.com/journal/2013/11/25/getting-started-with-mixed-effect-models-in-r

Any pointers would be much appreciated.

Thanks

Tom
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

The following script might take 30 seconds to run...

library(lme4)
library(arm)
lmm.data=read.table("http://www.unt.edu/rss/class/Jon/R_SC/Module9/lmm.data.txt",
                       header = TRUE, sep = ",", na.strings = "NA", dec = ".", strip.white = TRUE)
MLexamp.9=lmer(extro ~ open  + (1 + open | school/class),
                  data = lmm.data)
#summary(MLexamp.9)
nsim=20000
MLexamp.9.sim=sim (MLexamp.9,n.sim=nsim); #
colnames(MLexamp.9.sim at fixef)=names(fixef(MLexamp.9))<mailto:MLexamp.9.sim at fixef<mailto:MLexamp.9.sim at fixef>)=names(fixef(MLexamp.9))>

#generate CrIs.
CrI.MLexamp.9=as.data.frame(signif(apply(MLexamp.9.sim at fixef,2,quantile,prob=c(0.025,0.5,0.975)),5))<mailto:MLexamp.9.sim at fixef,2,quantile,prob=c(0.025,0.5,0.975)),5))>

MLexamp.9.Pred=data.frame(open=c(0,20,40,60))#realistic values and zero.
MLexamp.9.Pred.Matrix=model.matrix(~open,data=MLexamp.9.Pred)
MLexamp.9.Pred$fit=(MLexamp.9.Pred.Matrix%*%fixef(MLexamp.9))#

fitmat=matrix(nrow=nrow(MLexamp.9.Pred),ncol=nsim)#
for(i in 1:nsim) fitmat[,i]=(MLexamp.9.Pred.Matrix%*%MLexamp.9.sim at fixef[i,])#<mailto:MLexamp.9.Pred.Matrix%25*%25MLexamp.9.sim at fixef[i,])>

MLexamp.9.Pred$LowerCI=apply(fitmat,1,quantile,prob=0.025)
MLexamp.9.Pred$Middle=apply(fitmat,1,quantile,prob=0.500)
MLexamp.9.Pred$UpperCI=apply(fitmat,1,quantile,prob=0.975)
CrI.MLexamp.9
MLexamp.9.Pred
The Scottish Association for Marine Science (SAMS) is registered in Scotland as a Company Limited by Guarantee (SC009292) and is a registered charity (9206). SAMS has two actively trading wholly owned subsidiary companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912). All Companies in the group are registered in Scotland and share a registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The content of this message may contain personal views which are not the views of SAMS unless specifically stated. Please note that all email traffic is monitored for purposes of security and spam filtering. As such individual emails may be examined in more detail.

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

The Scottish Association for Marine Science (SAMS) is registered in Scotland as a Company Limited by Guarantee (SC009292) and is a registered charity (9206). SAMS has two actively trading wholly owned subsidiary companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912). All Companies in the group are registered in Scotland and share a registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The content of this message may contain personal views which are not the views of SAMS unless specifically stated. Please note that all email traffic is monitored for purposes of security and spam filtering. As such individual emails may be examined in more detail.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Mixed Model CrI and CI examplar.PNG
Type: image/png
Size: 14666 bytes
Desc: Mixed Model CrI and CI examplar.PNG
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20151210/b27cc889/attachment-0001.png>

From katrin.luder at iee.unibe.ch  Wed Dec  9 11:32:22 2015
From: katrin.luder at iee.unibe.ch (katrin.luder at iee.unibe.ch)
Date: Wed, 9 Dec 2015 10:32:22 +0000
Subject: [R-sig-ME] Warning message
Message-ID: <43707D9DF8F00542B0D54A57FCC2E66D178B301D@aai-exch-mbx4.campus.unibe.ch>

Hello

I'm currently working on my master thesis and i'm using the lme4 package to do glmer models. To find the best model, i'm using the forward selection approach. After putting the former explanatory variables in, everything works fine, but after a while this error message is showing up:

Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00377805 (tol = 0.001, component 2)

I have found different reasons in Google but nothing really fitted my problem. At some forum, it was written that i can also just skip this error message and go on with what i was doing. But the more explanatory variable i put in, the more often this error message occurs.

I would be very happy if you could help me out with this problem. I already asked several ecologist and statisticians but no one was able to help me.

Your sincerely,
Katrin Luder

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Dec 11 02:57:04 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 10 Dec 2015 20:57:04 -0500
Subject: [R-sig-ME] Warning message
In-Reply-To: <43707D9DF8F00542B0D54A57FCC2E66D178B301D@aai-exch-mbx4.campus.unibe.ch>
References: <43707D9DF8F00542B0D54A57FCC2E66D178B301D@aai-exch-mbx4.campus.unibe.ch>
Message-ID: <CABghstTJC0PjSH5TL2PBsdASeKbPqkQ4ueCFQXgrf350Yqwn8A@mail.gmail.com>

As previously suggested/discussed elsewhere, especially under the
?convergence manual page, this is probably a false positive. The gold
standard is to choose a different optimizer to fit your model with and
convince yourself that the results are sufficiently close across
optimizers that the warning is indeed a false positive.  (The chances
of two separate optimizers misconverging to the same point are small
... they might or might not reach different local optima, but that's
not the kind of convergence failure that the tests are able to detect
...)

  Have you been warned about the dangers of stepwise model selection
<http://www.stata.com/support/faqs/statistics/stepwise-regression-problems/>
?


On Wed, Dec 9, 2015 at 5:32 AM,  <katrin.luder at iee.unibe.ch> wrote:
> Hello
>
> I'm currently working on my master thesis and i'm using the lme4 package to do glmer models. To find the best model, i'm using the forward selection approach. After putting the former explanatory variables in, everything works fine, but after a while this error message is showing up:
>
> Warning message:
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.00377805 (tol = 0.001, component 2)
>
> I have found different reasons in Google but nothing really fitted my problem. At some forum, it was written that i can also just skip this error message and go on with what i was doing. But the more explanatory variable i put in, the more often this error message occurs.
>
> I would be very happy if you could help me out with this problem. I already asked several ecologist and statisticians but no one was able to help me.
>
> Your sincerely,
> Katrin Luder
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From hannah.hlx at gmail.com  Fri Dec 11 04:16:36 2015
From: hannah.hlx at gmail.com (li li)
Date: Thu, 10 Dec 2015 22:16:36 -0500
Subject: [R-sig-ME] random effect model
Message-ID: <CAHLnndZg2VVUzUWG+52G7H9_HavDSBGHhck4xqi8yfBZ6PJmHA@mail.gmail.com>

Hi all,
  I have a very simple data set "data". Here both day and analysts are
considered as random.
I fit the mod1 and mod2 as below. The random effect in both models come out
to be zero and same results are returned from both models. It seems very
strange to me. Anyone have an explanation or suggestion?
  Thanks. Hanna



> data
               values day analyst
stat_d1p1 -0.06357455   1       1
stat_d1p2 -0.05564684   1       2
stat_d1p3  0.16145903   1       3
stat_d2p1  0.07763253   2       1
stat_d2p2 -0.02988389   2       2
stat_d2p3 -0.16899311   2       3
stat_d3p1 -0.13545138   3       1
stat_d3p2 -0.07537850   3       2
stat_d3p3 -0.01313345   3       3
> library(lme4)
> library(lmerTest)

> mod1 <- lmer(values ~ 1+(1|day),data=data)
> summary(mod1)
Linear mixed model fit by REML t-tests use Satterthwaite approximations to
  degrees of freedom [lmerMod]
Formula: values ~ 1 + (1 | day)
   Data: data
REML criterion at convergence: -11.7
Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.3311 -0.4103 -0.2162  0.2019  1.9192
Random effects:
 Groups   Name        Variance Std.Dev.
 day      (Intercept) 0.00000  0.0000
 Residual             0.01034  0.1017
Number of obs: 9, groups:  day, 3
Fixed effects:
            Estimate Std. Error       df t value Pr(>|t|)
(Intercept) -0.03366    0.03389  8.00000  -0.993     0.35
>

> mod2 <- lmer(values ~ 1+(1|analyst),data=data)
> summary(mod2)
Linear mixed model fit by REML t-tests use Satterthwaite approximations to
  degrees of freedom [lmerMod]
Formula: values ~ 1 + (1 | analyst)
   Data: data
REML criterion at convergence: -11.7
Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.3311 -0.4103 -0.2162  0.2019  1.9192
Random effects:
 Groups   Name        Variance Std.Dev.
 analyst  (Intercept) 0.00000  0.0000
 Residual             0.01034  0.1017
Number of obs: 9, groups:  analyst, 3
Fixed effects:
            Estimate Std. Error       df t value Pr(>|t|)
(Intercept) -0.03366    0.03389  8.00000  -0.993     0.35
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Dec 11 04:55:01 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 10 Dec 2015 22:55:01 -0500
Subject: [R-sig-ME] random effect model
In-Reply-To: <CAHLnndZg2VVUzUWG+52G7H9_HavDSBGHhck4xqi8yfBZ6PJmHA@mail.gmail.com>
References: <CAHLnndZg2VVUzUWG+52G7H9_HavDSBGHhck4xqi8yfBZ6PJmHA@mail.gmail.com>
Message-ID: <566A4915.8040106@gmail.com>

On 15-12-10 10:16 PM, li li wrote:
> Hi all,
>   I have a very simple data set "data". Here both day and analysts are
> considered as random.
> I fit the mod1 and mod2 as below. The random effect in both models come out
> to be zero and same results are returned from both models. It seems very
> strange to me. Anyone have an explanation or suggestion?
>   Thanks. Hanna
> 

This is very common when trying to fit random factors with small (e.g.
<6) numbers of levels of the grouping variable: see e.g.

http://glmm.wikidot.com/faq (search for "Why is my random effect
variance estimated as zero, or correlations estimated as +/- 1? What
should I do about it?")

or

https://rpubs.com/bbolker/4187

> 
> 
>> data
>                values day analyst
> stat_d1p1 -0.06357455   1       1
> stat_d1p2 -0.05564684   1       2
> stat_d1p3  0.16145903   1       3
> stat_d2p1  0.07763253   2       1
> stat_d2p2 -0.02988389   2       2
> stat_d2p3 -0.16899311   2       3
> stat_d3p1 -0.13545138   3       1
> stat_d3p2 -0.07537850   3       2
> stat_d3p3 -0.01313345   3       3
>> library(lme4)
>> library(lmerTest)
> 
>> mod1 <- lmer(values ~ 1+(1|day),data=data)
>> summary(mod1)
> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>   degrees of freedom [lmerMod]
> Formula: values ~ 1 + (1 | day)
>    Data: data
> REML criterion at convergence: -11.7
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.3311 -0.4103 -0.2162  0.2019  1.9192
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  day      (Intercept) 0.00000  0.0000
>  Residual             0.01034  0.1017
> Number of obs: 9, groups:  day, 3
> Fixed effects:
>             Estimate Std. Error       df t value Pr(>|t|)
> (Intercept) -0.03366    0.03389  8.00000  -0.993     0.35
>>
> 
>> mod2 <- lmer(values ~ 1+(1|analyst),data=data)
>> summary(mod2)
> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>   degrees of freedom [lmerMod]
> Formula: values ~ 1 + (1 | analyst)
>    Data: data
> REML criterion at convergence: -11.7
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.3311 -0.4103 -0.2162  0.2019  1.9192
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  analyst  (Intercept) 0.00000  0.0000
>  Residual             0.01034  0.1017
> Number of obs: 9, groups:  analyst, 3
> Fixed effects:
>             Estimate Std. Error       df t value Pr(>|t|)
> (Intercept) -0.03366    0.03389  8.00000  -0.993     0.35
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From diego.pavonjordan at gmail.com  Fri Dec 11 09:31:47 2015
From: diego.pavonjordan at gmail.com (Diego Pavon)
Date: Fri, 11 Dec 2015 10:31:47 +0200
Subject: [R-sig-ME] Error messages when running ZIP and ZINB in glmmadmb
Message-ID: <CAD93_FqWiL2wpk=dpQKe2iiubtwCBDHeAMxkWtydLLxf1M-ePA@mail.gmail.com>

Dear All

After working a bit with ZIP and ZANB models with glmmadmb I have encounter
couple of problems while running the models for some species.

I have count data for 11 species of waterbirds and I am fitting GLMM
poisson, GLMM NB, ZIP and ZINB to the data (each species separately) to
compare and look for the "best model" (lowest AIC). For
some species, all the models run nicely, but for other species, typically
those with a very large % of zeroes (e.g. > 75%), I get an error message:

"Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Mser ~ WT_DJF_std + ST_pre_std + fHabitat + Mser_pre_std +
:
   The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect output
files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\Windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5
-noinit -shess' had status 1"

After reading some of the posts here, the solution does not seem straight
forward to me.
Do you have an idea why the models run for some but not for other species?
Do you have an idea how to deal with it? The covariates are standardized.
When I write the noinit=TRUE and the Shess=TRUE, it says that "it cannot be
found". I have written the verbose = TRUE, but I do not understand what it
all means.

I would very much appreciate any kind of insight.

Thank you very much for your time and help!

Best regards

Diego

-- 
*Diego Pav?n Jord?n*

*Finnish Museum of Natural History*
*PO BOX 17 *

*Helsinki. Finland*



*0445061210https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html
<https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html>http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile
<http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile>https://helsinki.academia.edu/DiegoPavon
<https://helsinki.academia.edu/DiegoPavon>*

	[[alternative HTML version deleted]]


From drki.musa at gmail.com  Sat Dec 12 17:18:20 2015
From: drki.musa at gmail.com (K Imran M)
Date: Sun, 13 Dec 2015 00:18:20 +0800
Subject: [R-sig-ME] treating measurement occasions as a numerical or as a
	factor predictor
Message-ID: <CADop7+gTuaeysQHeGZts7WVwQzpt4YSWiDQk-MnX+xrvKg15cw@mail.gmail.com>

Hi all,

I am (almost) sure this question has been asked before but I am new
here and I have not found the best answer yet after some googling.

I would like to ask a question about treating measurement occasions in
a longitudinal analysis specifically when using linear mixed model. In
my study, I have taken data on 3 separate occasions (at baseline, at 1
month and at 3 months post baseline). I am not sure what is best
approach treat these measurement occasions in my analysis using lmer
or lme functions. Should I treat them as a numeric or as a factor
variable. My feeling says that I should treat such measurement
occasions as a factor but I do not have strong theoretical reasons for
that.

Treating them as a factor predictor will make my nlme::lme codes like these;

for random intercept:
lme(y~1+ covariateA+factor(occasion), random=~1|subject, data=data)
and for random slope:
lme(y~1+covariteA+factor(occasion),random=~1+factor(occasion)|subject,
data=data)

I appreciate someone can enlighten me on this issue or point to any
useful literature.

Thanks very much.

Best wishes,

Kamarul

-- 
Dr. Kamarul Imran Musa (MD MCommunityMed)
Dept of Community Medicine,
School of Medical Sciences,
Universiti Sains Malaysia,
16150 Kbg Kerian Kelantan
MALAYSIA

ResearcherID: http://www.researcherid.com/rid/N-3198-2015
Personal blog: http://designdataanalysis.wordpress.com
Email : drki.musa at gmail.com , k.musa at lancaster.ac.uk


From rshepard at appl-ecosys.com  Sat Dec 12 17:48:20 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sat, 12 Dec 2015 08:48:20 -0800 (PST)
Subject: [R-sig-ME] treating measurement occasions as a numerical or as
 a factor predictor
In-Reply-To: <CADop7+gTuaeysQHeGZts7WVwQzpt4YSWiDQk-MnX+xrvKg15cw@mail.gmail.com>
References: <CADop7+gTuaeysQHeGZts7WVwQzpt4YSWiDQk-MnX+xrvKg15cw@mail.gmail.com>
Message-ID: <alpine.LNX.2.11.1512120847080.23025@localhost>

On Sun, 13 Dec 2015, K Imran M wrote:

> I would like to ask a question about treating measurement occasions in a
> longitudinal analysis specifically when using linear mixed model. In my
> study, I have taken data on 3 separate occasions (at baseline, at 1 month
> and at 3 months post baseline). I am not sure what is best approach treat
> these measurement occasions in my analysis using lmer or lme functions.
> Should I treat them as a numeric or as a factor variable. My feeling says
> that I should treat such measurement occasions as a factor but I do not
> have strong theoretical reasons for that.

Kamarul,

   What question do you want to answer with your data?

Rich


From bbolker at gmail.com  Sat Dec 12 20:03:19 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 12 Dec 2015 14:03:19 -0500
Subject: [R-sig-ME] treating measurement occasions as a numerical or as
 a factor predictor
In-Reply-To: <alpine.LNX.2.11.1512120847080.23025@localhost>
References: <CADop7+gTuaeysQHeGZts7WVwQzpt4YSWiDQk-MnX+xrvKg15cw@mail.gmail.com>
	<alpine.LNX.2.11.1512120847080.23025@localhost>
Message-ID: <566C6F77.2070004@gmail.com>

On 15-12-12 11:48 AM, Rich Shepard wrote:
> On Sun, 13 Dec 2015, K Imran M wrote:
> 
>> I would like to ask a question about treating measurement occasions in a
>> longitudinal analysis specifically when using linear mixed model. In my
>> study, I have taken data on 3 separate occasions (at baseline, at 1 month
>> and at 3 months post baseline). I am not sure what is best approach treat
>> these measurement occasions in my analysis using lmer or lme functions.
>> Should I treat them as a numeric or as a factor variable. My feeling says
>> that I should treat such measurement occasions as a factor but I do not
>> have strong theoretical reasons for that.
> 
> Kamarul,
> 
>   What question do you want to answer with your data?
> 
> Rich
> 

   A few thoughts to consider:

* with only 3 measurement occasions you won't really be able to treat
them as a random effect (not enough distinct levels to estimate
among-occasion variance reliably)
* if you treat measurement occasion as numeric (i.e., a linear effect of
time) you will assume that the change per month is identical throughout
the observation period (i.e. you will expect 2 times as much change from
1 month to 3 months post baseline as from baseline to 1 month post baseline)
* if you treat measurement occasion as categorical (factor) you will
estimate 2 parameters for the effect of occasion rather than 1.  There
are various ways you can break this up, depending on the contrasts you
choose (default 'contr.treatment': baseline vs 1 month, baseline vs. 3
months.  MASS::contr.sdif() gives you successive differences, making the
variable an ordered factor gives you contr.poly() (linear, quadratic
contrasts) by default.

   I would *generally* say that you're not complicating the model
much/spending very many parameters(degrees of freedom) by using a
categorical rather than a numeric input for time, and otherwise you're
making a fairly strong assumption, so I would recommend categorical.

  Ben Bolker


From drki.musa at gmail.com  Sun Dec 13 14:35:08 2015
From: drki.musa at gmail.com (K Imran M)
Date: Sun, 13 Dec 2015 21:35:08 +0800
Subject: [R-sig-ME] treating measurement occasions as a numerical or as
 a factor predictor
In-Reply-To: <566C6F77.2070004@gmail.com>
References: <CADop7+gTuaeysQHeGZts7WVwQzpt4YSWiDQk-MnX+xrvKg15cw@mail.gmail.com>
	<alpine.LNX.2.11.1512120847080.23025@localhost>
	<566C6F77.2070004@gmail.com>
Message-ID: <CADop7+ig2Skzz+bb+FBdkWMsh4Mag_9c2PadkLkkLsn2TeLH-w@mail.gmail.com>

Dear Ben,

Your answer has given me a new perspective at looking at my data
analysis again. At least I am happy that I have treated the
measurement occasions as categorical. This is a small longitudinal
data on patients after acute stroke attacks. We would like to have
more measurement occasions (waves) but were limited by our resources.

Many thanks

Regards,

Kamarul



On Sun, Dec 13, 2015 at 3:03 AM, Ben Bolker <bbolker at gmail.com> wrote:
> On 15-12-12 11:48 AM, Rich Shepard wrote:
>> On Sun, 13 Dec 2015, K Imran M wrote:
>>
>>> I would like to ask a question about treating measurement occasions in a
>>> longitudinal analysis specifically when using linear mixed model. In my
>>> study, I have taken data on 3 separate occasions (at baseline, at 1 month
>>> and at 3 months post baseline). I am not sure what is best approach treat
>>> these measurement occasions in my analysis using lmer or lme functions.
>>> Should I treat them as a numeric or as a factor variable. My feeling says
>>> that I should treat such measurement occasions as a factor but I do not
>>> have strong theoretical reasons for that.
>>
>> Kamarul,
>>
>>   What question do you want to answer with your data?
>>
>> Rich
>>
>
>    A few thoughts to consider:
>
> * with only 3 measurement occasions you won't really be able to treat
> them as a random effect (not enough distinct levels to estimate
> among-occasion variance reliably)
> * if you treat measurement occasion as numeric (i.e., a linear effect of
> time) you will assume that the change per month is identical throughout
> the observation period (i.e. you will expect 2 times as much change from
> 1 month to 3 months post baseline as from baseline to 1 month post baseline)
> * if you treat measurement occasion as categorical (factor) you will
> estimate 2 parameters for the effect of occasion rather than 1.  There
> are various ways you can break this up, depending on the contrasts you
> choose (default 'contr.treatment': baseline vs 1 month, baseline vs. 3
> months.  MASS::contr.sdif() gives you successive differences, making the
> variable an ordered factor gives you contr.poly() (linear, quadratic
> contrasts) by default.
>
>    I would *generally* say that you're not complicating the model
> much/spending very many parameters(degrees of freedom) by using a
> categorical rather than a numeric input for time, and otherwise you're
> making a fairly strong assumption, so I would recommend categorical.
>
>   Ben Bolker
>
>



-- 
Dr. Kamarul Imran Musa (MD MCommunityMed)
Associate Professor (Epidemiology and Biostatistics) &
Public Health Physician,
Dept of Community Medicine,
School of Medical Sciences,
Universiti Sains Malaysia,
16150 Kbg Kerian Kelantan
MALAYSIA

ResearcherID: http://www.researcherid.com/rid/N-3198-2015
Google-scholar: 'Kamarul Imran Musa'  at https://goo.gl/D3o3y6
ORCID ID: orcid.org/0000-0002-3708-0628
ScopusID: 18634847200

Personal blog: http://designdataanalysis.wordpress.com
Email : drki.musa at gmail.com , k.musa at lancaster.ac.uk


From sophie.waegebaert at gmail.com  Mon Dec 14 11:45:24 2015
From: sophie.waegebaert at gmail.com (Sophie Waegebaert)
Date: Mon, 14 Dec 2015 11:45:24 +0100
Subject: [R-sig-ME] Testing overdispersion Gamma glmer
Message-ID: <CAGH66HCiv5jiad+_DM+HP91xP3GOHGa1jft8E=KYSJR=i_RYmQ@mail.gmail.com>

Hello,

I want to compare mean trip duration (length.in.hours) across treatment
conditions and colonies. I have 3 colonies and 2 treatments. So, one half
of a colony gets a DWV treatment and the other half a control treatment.

When a histogram is made, it is clear that the data is skewed to the rigth.
So, I am using a Gamma distribution.

This is the model: fit_length = glmer(length.in.hours~treatment*colony +
(1|RFID), family = Gamma(link = "log"), data = datashort)

I use the log link and not the identity link, because the AIC is lower.
RFID is the code used for each subject in the colonies.

I want to test for the overdispersion assumption by using the following
code:

> datashort$obs = factor(1:nrow(datashort))> fit_length_obs = glmer(length.in.hours~treatment*colony + (1|RFID) + (1|obs), family = Gamma(link = "log"), data = datashort)
> AIC(fit_length, fit_length_obs)                df        AIC
fit_length      8   5646.758
fit_length_obs  9 -74390.105


There is a clear difference between the AIC values, but I was wondering
wether -74390 is a realistic value? Is it not very low? Or am I using the
wrong method to control for overdispersion?

Thank you for some help!

Kind regards,

Sophie

	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon Dec 14 12:16:27 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 14 Dec 2015 07:16:27 -0400
Subject: [R-sig-ME] Testing overdispersion Gamma glmer
In-Reply-To: <mailman.3.1450090801.29164.r-sig-mixed-models@r-project.org>
References: <mailman.3.1450090801.29164.r-sig-mixed-models@r-project.org>
Message-ID: <566EA50B.3090801@highstat.com>



------------------------------

Message: 2
Date: Mon, 14 Dec 2015 11:45:24 +0100
From: Sophie Waegebaert <sophie.waegebaert at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Testing overdispersion Gamma glmer
Message-ID:
	<CAGH66HCiv5jiad+_DM+HP91xP3GOHGa1jft8E=KYSJR=i_RYmQ at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hello,

I want to compare mean trip duration (length.in.hours) across treatment
conditions and colonies. I have 3 colonies and 2 treatments. So, one half
of a colony gets a DWV treatment and the other half a control treatment.

When a histogram is made, it is clear that the data is skewed to the rigth.
So, I am using a Gamma distribution.

This is the model: fit_length = glmer(length.in.hours~treatment*colony +
(1|RFID), family = Gamma(link = "log"), data = datashort)

I use the log link and not the identity link, because the AIC is lower.
RFID is the code used for each subject in the colonies.

I want to test for the overdispersion assumption by using the following
code:

> datashort$obs = factor(1:nrow(datashort))> fit_length_obs = glmer(length.in.hours~treatment*colony + (1|RFID) + (1|obs), family = Gamma(link = "log"), data = datashort)
> AIC(fit_length, fit_length_obs)                df        AIC
fit_length      8   5646.758
fit_length_obs  9 -74390.105


There is a clear difference between the AIC values, but I was wondering
wether -74390 is a realistic value? Is it not very low? Or am I using the
wrong method to control for overdispersion?

Thank you for some help!

Kind regards,

Sophie




Sophie,
A Gamma GLM(M) cannot be overdispersed. The parameter r in the variance expression of a Gamma GLM acts
like the sigma parameter in linear regression.

A Poisson GLM can be overdispersed because the variance equals the mean. It has no extra parameter to correct for any
extra variation. Same holds for a binomial (as in binomial..not Bernoulli).

As to why the model with the observation level random effect is much better...well it acts like
a latent variable.

Kind regards,

Alain


From simonebianchi79 at gmail.com  Tue Dec 15 12:22:48 2015
From: simonebianchi79 at gmail.com (Simone Bianchi)
Date: Tue, 15 Dec 2015 11:22:48 +0000
Subject: [R-sig-ME] zero inflated mixed models
Message-ID: <CA+9NooucabBiB9CLiQVx2=zVingEokmT4=G08eT8c4iobqfwfg@mail.gmail.com>

Dear all,

I was suggested to use the package glmmADMB for zero-inflated or hurdle
mixed models. The packages is not available for R 3.2.2. Is there any other
resource I can use or I have to downgrade the installation?

Thanks
Simone

-- 
Simone Bianchi
www.simonebianchi.eu

	[[alternative HTML version deleted]]


From quentin.schorpp at ti.bund.de  Tue Dec 15 14:14:11 2015
From: quentin.schorpp at ti.bund.de (Quentin Schorpp)
Date: Tue, 15 Dec 2015 14:14:11 +0100
Subject: [R-sig-ME] Orthogonal Polynomial contrasts with ordered factors
Message-ID: <56701223.5010804@ti.bund.de>

Hello,

I would appreciate to get to know more about the use of polynomial 
contrasts in lme4::glmer.
Does anybody could give me an advice for literature about that subject.

In particular
A:  I read, that if a second order polynomial is significant in the 
summary output, then it is supposed to be significant AFTER the first 
order polynomial was                 taken into account. Is that right?

B1 : What happens if i use an ordered factor with another factor 
(ordered or not) in an itneraction term? What does a signficant 
interaction of the second                factor (any level) with the 
fourth power polynomial of the first ordered factor tell me?
B2: And waht does it tell me when the lower order polynomials are not 
significant in the interaction?


For more interested readers:

_The data_
My data is abundances of earthworms. I sampled 15 fields, three times 
(samcam) during two years, with 4 pseudoreplicates per field (N=180).
The factor age_class describes the stage of development of the field, it 
has 5 levels ((n = 3 replicates).
However, one of these levels A_Cm has n=6 since i had to switch the 
fields in the second year.
Field.ID is my random factor, to control for the pseudoreplication per 
field and the longitudinal character of the data.  For the sake of less 
complexity samcam stayed non-ordered.

Here is the design

  field.ID\samcam1 2 3 1 4 4 4 2 4 4 4 3 4 4 4 4 4 4 4 5 4 4 4 6 4 4 4 7 4 
4 4 8 4 4 4 9 4 4 4 10 4 4 4 11 4 4 4 _12 4 4 4_ 13 4 0 0 Fields had to 
be switched in the second year 14 4 0 0 15 4 0 0 16 0 4 4 17 0 4 4 18 0 4 4



Other continuous predictor variables were scaled before analysis.

data structure:
  $ abundance      : num  0 0 3 3 2 1 2 5 12 5 ...

  $ ID             : Factor w/ 180 levels "1","2","3","4",..: 1 2 3 4 5 
6 7 8 9 10 ...
  $ field.ID       : Factor w/ 18 levels "1","2","3","4",..: 1 1 1 1 2 2 
2 2 3 3 ...
  $ age_class      : Ord.factor w/ 5 levels "A_Cm"<"B_Sp_young"<..: 5 5 
5 5 5 5 5 5 5 5 ...
  $ samcam         : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
  $ hole           : Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1 2 3 4 
1 2 ...

  $ scl.pH         : num  -1.553 -1.553 -1.553 -1.553 0.715 ...
  $ scl.mc         : num  -1.072 -1.072 -1.072 -1.072 -0.429 ...
  $ scl.cn         : num  -0.703 -0.703 -0.703 -0.703 -0.474 ...
  $ scl.sand       : num  -0.245 -0.245 -0.245 -0.245 -0.0127 ...
  $ scl.silt       : num  -0.897 -0.897 -0.897 -0.897 -1.529 ...
  $ scl.clay       : num  1.19 1.19 1.19 1.19 1.66 ...
  $ scl.ata1       : num  1.6471 1.6471 1.6471 1.6471 0.0894 ...
  $ scl.atb1       : num  1.6658 1.6658 1.6658 1.6658 0.0659 ...
  $ scl.hum1       : num  -1.378 -1.378 -1.378 -1.378 0.429 ...

_my hyptheses are_
1. abundance increases with increasing age_class
2. If abundance increases over the age classes it will be observed by 
increasing abundance during the period of sampling
(3. Abundance increases during the period of sampling)

_The Model was :_
best.mod <- glmer(abundance~ age_class*samcam + scl.prec1 + 
scl.mc*scl.pH  + (1|field.ID)  ,data=data,family=poisson, 
control=glmerControl(optimizer="bobyqa"))

here is The Model output of one of the best models revealed by 
MuMIn::dredge:

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
  Family: poisson  ( log )
Formula: anc ~ age_class * samcam + I(scl.ats1^2) + scl.prec1 + (1 | field.ID)
    Data: data
Control: glmerControl(optimizer = "bobyqa")

      AIC      BIC   logLik deviance df.resid
      731      789     -348      695      162

Scaled residuals:
    Min     1Q Median     3Q    Max
-2.181 -0.696 -0.171  0.644  4.178

Random effects:
  Groups   Name        Variance Std.Dev.
  field.ID (Intercept) 0.263    0.513
Number of obs: 180, groups:  field.ID, 18

Fixed effects:
                     Estimate Std. Error z value Pr(>|z|)
(Intercept)           0.6457     0.2079    3.11   0.0019 **
age_class.L           1.9924     0.4416    4.51  6.4e-06 ***
age_class.Q          -0.8644     0.4204   -2.06   0.0398 *
age_class.C          -0.2373     0.4007   -0.59   0.5537
age_class^4           0.7026     0.3591    1.96   0.0504 .
samcam2               0.8549     0.2074    4.12  3.7e-05 ***
samcam3               0.3074     0.1852    1.66   0.0969 .
I(scl.ats1^2)        -0.3328     0.1038   -3.21   0.0013 **
scl.prec1             0.2241     0.0851    2.63   0.0085 **
age_class.L:samcam2  -0.3474     0.5463   -0.64   0.5248
age_class.Q:samcam2   0.1074     0.4766    0.23   0.8216
age_class.C:samcam2   0.8910     0.3644    2.44   0.0145 *
_age_class^4:samcam2 -1.0352 0.2601 -3.98 6.9e-05 *** _   # HERE is the significant interaction of interest!
age_class.L:samcam3   0.1274     0.5125    0.25   0.8038
age_class.Q:samcam3  -0.1801     0.4429   -0.41   0.6842
age_class.C:samcam3   0.5659     0.3615    1.57   0.1174
_age_class^4:samcam3 -0.6489 0.2617 -2.48 0.0131 * ___# HERE is the significant interaction of interest!


_Interpretation:_
I understood, that the relationship was linear in general, as indicated 
by the second line of the output, and this did not change between the 
sampling campaigns. However, during the second and third sampling 
campaign the relationship of abundances in the age_classes was 
characterised by a stronger slope in younger classes and reached a 
plateau afterwards, as indicated by the fourth power.
The missing of the interaction between age_class and samcam1 is very 
hard for me to understand

I'm thankful for any advices!

Quentin


-- 
Quentin Schorpp, M.Sc.
Th?nen-Institut f?r Biodiversit?t
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.

Quentin Schorpp, M.Sc.
Th?nen Institute of Biodiversity
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.


	[[alternative HTML version deleted]]


From nouri4 at yahoo.com  Tue Dec 15 17:27:24 2015
From: nouri4 at yahoo.com (knouri)
Date: Tue, 15 Dec 2015 16:27:24 +0000 (UTC)
Subject: [R-sig-ME] conditional logistic & weight
References: <134601723.1572156.1450196844832.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <134601723.1572156.1450196844832.JavaMail.yahoo@mail.yahoo.com>

Hi all,I have the following data (mydat) and would like to fit a conditional logistic regression model in R.
mydat:
id? case? exposure?? wt
1????? 1????????? 1????????? 2
1????? 0????????? 0????????? 2
2????? 1????????? 1????????? 2 
2????? 0????????? 0????????? 2 
3????? 1????????? 1????????? 1 
3????? 0????????? 0????????? 1 
4????? 1????????? 0???????? ?2 
4????? 0????????? 1????????? 2 
The R function "clogit" is for such purposes but as you might know it disregards?weight option.
I tried function "mclogit" which seems that it considers the weight option:
fit?= mclogit(cbind(case,id) ~ exposure, weights=wt, data=mydat)
summary(fit)
The answer, however,?doesn't seem to be?correct. Could anyone?please provides me with some information in this regards,
Best,Keramat Nourijelyani, PhD?

	[[alternative HTML version deleted]]


From karl at huftis.org  Tue Dec 15 18:40:16 2015
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Tue, 15 Dec 2015 18:40:16 +0100
Subject: [R-sig-ME] conditional logistic & weight
In-Reply-To: <134601723.1572156.1450196844832.JavaMail.yahoo@mail.yahoo.com>
References: <134601723.1572156.1450196844832.JavaMail.yahoo.ref@mail.yahoo.com>
	<134601723.1572156.1450196844832.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56705080.3000607@huftis.org>

Den 15. des. 2015 17:27, knouri via R-sig-mixed-models skreiv:
> The R function "clogit" is for such purposes but as you might know it disregards weight option.
> I tried function "mclogit" which seems that it considers the weight option:

Is this just a toy data set, and your real data set is *much* larger? If 
not, you could easily expand the data set to a complete data set, for 
example using

   mydat_expanded = mydat[rep(1:nrow(mydat), times=mydat$wt),]

and just fit the model on this data set, using clogit(). This will work 
fine even for moderately large data sets.

-- 
Karl Ove Hufthammer


From mbrooks at ufl.edu  Wed Dec 16 12:27:27 2015
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Wed, 16 Dec 2015 12:27:27 +0100
Subject: [R-sig-ME] zero inflated mixed models
In-Reply-To: <mailman.1.1450263601.16000.r-sig-mixed-models@r-project.org>
References: <mailman.1.1450263601.16000.r-sig-mixed-models@r-project.org>
Message-ID: <B1B825A1-E827-4646-8A3E-3458C7DC1708@ufl.edu>

Hi Simone,

There are a few things you can try including installing from source. The options are listed on this website http://glmmadmb.r-forge.r-project.org <http://glmmadmb.r-forge.r-project.org/>

cheers,
Mollie


> 
> Date: Tue, 15 Dec 2015 11:22:48 +0000
> From: Simone Bianchi <simonebianchi79 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] zero inflated mixed models
> Message-ID:
> 	<CA+9NooucabBiB9CLiQVx2=zVingEokmT4=G08eT8c4iobqfwfg at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> Dear all,
> 
> I was suggested to use the package glmmADMB for zero-inflated or hurdle
> mixed models. The packages is not available for R 3.2.2. Is there any other
> resource I can use or I have to downgrade the installation?
> 
> Thanks
> Simone
> 
> -- 
> Simone Bianchi
> www.simonebianchi.eu
> 
> 	[[alternative HTML version deleted]]
> 
> 

------------------------
Mollie Brooks, PhD
Postdoctoral Researcher, Population Ecology Research Group
Department of Evolutionary Biology & Environmental Studies, University of Z?rich
http://www.popecol.org/team/mollie-brooks/
	[[alternative HTML version deleted]]


From stevedrd at yahoo.com  Wed Dec 16 12:38:13 2015
From: stevedrd at yahoo.com (Steve Denham)
Date: Wed, 16 Dec 2015 11:38:13 +0000 (UTC)
Subject: [R-sig-ME] Orthogonal Polynomial contrasts with ordered factors
In-Reply-To: <56701223.5010804@ti.bund.de>
References: <56701223.5010804@ti.bund.de>
Message-ID: <1791342064.1923122.1450265893747.JavaMail.yahoo@mail.yahoo.com>

I'll take a crack at the B questions. ?Keep in mind that this is an opinion only. ?A significant fourth order by other factor interaction, especially when the lower order polynomial by factor interactions are not significant means that you have probably fit a polynomial to a non-polynomial effect. ?Your mention of a plateau tends to support this, at least to me. ?Some sort of non-linear effect (sigmoidal, four or five factor logistic) may make more sense from a biological perspective.?Steve Denham Director, Biostatistics MPI Research, Inc.
 
      From: Quentin Schorpp <quentin.schorpp at ti.bund.de>
 To: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Sent: Tuesday, December 15, 2015 8:14 AM
 Subject: [R-sig-ME] Orthogonal Polynomial contrasts with ordered factors
   
Hello,

I would appreciate to get to know more about the use of polynomial 
contrasts in lme4::glmer.
Does anybody could give me an advice for literature about that subject.

In particular
A:? I read, that if a second order polynomial is significant in the 
summary output, then it is supposed to be significant AFTER the first 
order polynomial was? ? ? ? ? ? ? ? taken into account. Is that right?

B1 : What happens if i use an ordered factor with another factor 
(ordered or not) in an itneraction term? What does a signficant 
interaction of the second? ? ? ? ? ? ? ? factor (any level) with the 
fourth power polynomial of the first ordered factor tell me?
B2: And waht does it tell me when the lower order polynomials are not 
significant in the interaction?


For more interested readers:

_The data_
My data is abundances of earthworms. I sampled 15 fields, three times 
(samcam) during two years, with 4 pseudoreplicates per field (N=180).
The factor age_class describes the stage of development of the field, it 
has 5 levels ((n = 3 replicates).
However, one of these levels A_Cm has n=6 since i had to switch the 
fields in the second year.
Field.ID is my random factor, to control for the pseudoreplication per 
field and the longitudinal character of the data.? For the sake of less 
complexity samcam stayed non-ordered.

Here is the design

? field.ID\samcam1 2 3 1 4 4 4 2 4 4 4 3 4 4 4 4 4 4 4 5 4 4 4 6 4 4 4 7 4 
4 4 8 4 4 4 9 4 4 4 10 4 4 4 11 4 4 4 _12 4 4 4_ 13 4 0 0 Fields had to 
be switched in the second year 14 4 0 0 15 4 0 0 16 0 4 4 17 0 4 4 18 0 4 4



Other continuous predictor variables were scaled before analysis.

data structure:
? $ abundance? ? ? : num? 0 0 3 3 2 1 2 5 12 5 ...

? $ ID? ? ? ? ? ? : Factor w/ 180 levels "1","2","3","4",..: 1 2 3 4 5 
6 7 8 9 10 ...
? $ field.ID? ? ? : Factor w/ 18 levels "1","2","3","4",..: 1 1 1 1 2 2 
2 2 3 3 ...
? $ age_class? ? ? : Ord.factor w/ 5 levels "A_Cm"<"B_Sp_young"<..: 5 5 
5 5 5 5 5 5 5 5 ...
? $ samcam? ? ? ? : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
? $ hole? ? ? ? ? : Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1 2 3 4 
1 2 ...

? $ scl.pH? ? ? ? : num? -1.553 -1.553 -1.553 -1.553 0.715 ...
? $ scl.mc? ? ? ? : num? -1.072 -1.072 -1.072 -1.072 -0.429 ...
? $ scl.cn? ? ? ? : num? -0.703 -0.703 -0.703 -0.703 -0.474 ...
? $ scl.sand? ? ? : num? -0.245 -0.245 -0.245 -0.245 -0.0127 ...
? $ scl.silt? ? ? : num? -0.897 -0.897 -0.897 -0.897 -1.529 ...
? $ scl.clay? ? ? : num? 1.19 1.19 1.19 1.19 1.66 ...
? $ scl.ata1? ? ? : num? 1.6471 1.6471 1.6471 1.6471 0.0894 ...
? $ scl.atb1? ? ? : num? 1.6658 1.6658 1.6658 1.6658 0.0659 ...
? $ scl.hum1? ? ? : num? -1.378 -1.378 -1.378 -1.378 0.429 ...

_my hyptheses are_
1. abundance increases with increasing age_class
2. If abundance increases over the age classes it will be observed by 
increasing abundance during the period of sampling
(3. Abundance increases during the period of sampling)

_The Model was :_
best.mod <- glmer(abundance~ age_class*samcam + scl.prec1 + 
scl.mc*scl.pH? + (1|field.ID)? ,data=data,family=poisson, 
control=glmerControl(optimizer="bobyqa"))

here is The Model output of one of the best models revealed by 
MuMIn::dredge:

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
? Family: poisson? ( log )
Formula: anc ~ age_class * samcam + I(scl.ats1^2) + scl.prec1 + (1 | field.ID)
? ? Data: data
Control: glmerControl(optimizer = "bobyqa")

? ? ? AIC? ? ? BIC? logLik deviance df.resid
? ? ? 731? ? ? 789? ? -348? ? ? 695? ? ? 162

Scaled residuals:
? ? Min? ? 1Q Median? ? 3Q? ? Max
-2.181 -0.696 -0.171? 0.644? 4.178

Random effects:
? Groups? Name? ? ? ? Variance Std.Dev.
? field.ID (Intercept) 0.263? ? 0.513
Number of obs: 180, groups:? field.ID, 18

Fixed effects:
? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
(Intercept)? ? ? ? ? 0.6457? ? 0.2079? ? 3.11? 0.0019 **
age_class.L? ? ? ? ? 1.9924? ? 0.4416? ? 4.51? 6.4e-06 ***
age_class.Q? ? ? ? ? -0.8644? ? 0.4204? -2.06? 0.0398 *
age_class.C? ? ? ? ? -0.2373? ? 0.4007? -0.59? 0.5537
age_class^4? ? ? ? ? 0.7026? ? 0.3591? ? 1.96? 0.0504 .
samcam2? ? ? ? ? ? ? 0.8549? ? 0.2074? ? 4.12? 3.7e-05 ***
samcam3? ? ? ? ? ? ? 0.3074? ? 0.1852? ? 1.66? 0.0969 .
I(scl.ats1^2)? ? ? ? -0.3328? ? 0.1038? -3.21? 0.0013 **
scl.prec1? ? ? ? ? ? 0.2241? ? 0.0851? ? 2.63? 0.0085 **
age_class.L:samcam2? -0.3474? ? 0.5463? -0.64? 0.5248
age_class.Q:samcam2? 0.1074? ? 0.4766? ? 0.23? 0.8216
age_class.C:samcam2? 0.8910? ? 0.3644? ? 2.44? 0.0145 *
_age_class^4:samcam2 -1.0352 0.2601 -3.98 6.9e-05 *** _? # HERE is the significant interaction of interest!
age_class.L:samcam3? 0.1274? ? 0.5125? ? 0.25? 0.8038
age_class.Q:samcam3? -0.1801? ? 0.4429? -0.41? 0.6842
age_class.C:samcam3? 0.5659? ? 0.3615? ? 1.57? 0.1174
_age_class^4:samcam3 -0.6489 0.2617 -2.48 0.0131 * ___# HERE is the significant interaction of interest!


_Interpretation:_
I understood, that the relationship was linear in general, as indicated 
by the second line of the output, and this did not change between the 
sampling campaigns. However, during the second and third sampling 
campaign the relationship of abundances in the age_classes was 
characterised by a stronger slope in younger classes and reached a 
plateau afterwards, as indicated by the fourth power.
The missing of the interaction between age_class and samcam1 is very 
hard for me to understand

I'm thankful for any advices!

Quentin


-- 
Quentin Schorpp, M.Sc.
Th?nen-Institut f?r Biodiversit?t
Bundesallee 50
38116 Braunschweig (Germany)

Tel:? +49 531 596-2524
Fax:? +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:? http://www.ti.bund.de

Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.

Quentin Schorpp, M.Sc.
Th?nen Institute of Biodiversity
Bundesallee 50
38116 Braunschweig (Germany)

Tel:? +49 531 596-2524
Fax:? +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:? http://www.ti.bund.de

The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.


??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

   

	[[alternative HTML version deleted]]


From sophie.waegebaert at gmail.com  Wed Dec 16 17:11:15 2015
From: sophie.waegebaert at gmail.com (Sophie Waegebaert)
Date: Wed, 16 Dec 2015 17:11:15 +0100
Subject: [R-sig-ME] Proportion data: calculation of significance difference
	in infection rate
Message-ID: <CAGH66HB0w19qpEEj-PEs+v6heg-dBWvArpphowzsM7DGJFO3sg@mail.gmail.com>

Dear all,

I have a dataset with a MLPA analysis of 4-daily (0, 4, 8, 12, 16) sets of
samples of 20 individuals per treatment (control and DWV). I want to test
how the proportion of infected bees changed over time across treatment
conditions.

So, I have day 0 until day 16 and the amount of infected individuals per
treatment for each time point. After testing AIC and overdispersion, I made
a quasibinomial model (overdispersion parameter = 1.91) with day as a
continuous covariate:
fit_MLPA_quasi = glm(cbind(infected, not_infected)~treatment*day, family =
quasibinomial(), data = data)

I was wondering how I can determine until when the difference in infection
rate remained significant between the two treatments based on the 95%
confidence limits? I used the following command:

df = as.data.frame(effect(fit_MLPA_quasi, term="treatment:day"))
df

#   treatment day       fit        se      lower     upper
# 1      CTRL   0 0.1441225 0.6446699 0.03360447 0.4491729
# 2       DWV   0 0.9847726 1.6624012 0.52536941 0.9997354
# 3      CTRL   5 0.4521756 0.3817471 0.24490268 0.6774805
# 4       DWV   5 0.9745927 1.0791910 0.73229485 0.9981444
# 5      CTRL  10 0.8018179 0.4851205 0.55246817 0.9298731
# 6       DWV  10 0.9578982 0.7205049 0.79602594 0.9925174
# 7      CTRL  15 0.9519959 0.8273043 0.72370885 0.9933839
# 8       DWV  15 0.9310107 0.9093951 0.59317575 0.9920573

Besides not knowing how to calculate the significance, I do not understand
why R uses day 0, 5, 10 and 15, while in the dataset days 0, 4, 8, 12 and
16 are used.

Anyone who can give me a hint?

Thank you in advance.

Kind regards,
Sophie

	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Thu Dec 17 01:12:50 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Thu, 17 Dec 2015 10:12:50 +1000
Subject: [R-sig-ME] zero inflated mixed models
In-Reply-To: <CA+9NooucabBiB9CLiQVx2=zVingEokmT4=G08eT8c4iobqfwfg@mail.gmail.com>
References: <CA+9NooucabBiB9CLiQVx2=zVingEokmT4=G08eT8c4iobqfwfg@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1512171012050.14875@orpheus.qimr.edu.au>

On Tue, 15 Dec 2015, Simone Bianchi wrote:

> I was suggested to use the package glmmADMB for zero-inflated or hurdle
> mixed models. The packages is not available for R 3.2.2. Is there any other
> resource I can use or I have to downgrade the installation?

Did you try the instructions at http://glmmadmb.r-forge.r-project.org/ ?


From quentin.schorpp at ti.bund.de  Thu Dec 17 09:08:37 2015
From: quentin.schorpp at ti.bund.de (Quentin Schorpp)
Date: Thu, 17 Dec 2015 09:08:37 +0100
Subject: [R-sig-ME] Orthogonal Polynomial contrasts with ordered factors
In-Reply-To: <1791342064.1923122.1450265893747.JavaMail.yahoo@mail.yahoo.com>
References: <56701223.5010804@ti.bund.de>
	<1791342064.1923122.1450265893747.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56726D85.2070007@ti.bund.de>

Hello,

Thank you for your answer. If I understood you right, you mean 
significant effects  of higher order polynomials could point to 
non-linear relationships between response and explanatory variable (also 
if the explanator is a categorial factor), under the condition, that  
lower order polynomials in between are "skipped" in the sense that 
theses are not significant? The significant effect of ("non successive") 
higher order polynomials could be either in interaction terms and 
without? However when thinking about fitting a non-linear model, i'm 
wondering if it would be justified in the case that significant ("non 
successive") higher order polynomials only occur in one interaction case 
(the discussed pattern is only observed in the interaction with one 
level of the second interaction factor).

p.S. Sorry for the worse formatting of the initial question, while 
writing the e-mail everything looked good, especially the factor by 
factor table to reveal the partly nested structure.

kind regards,
Quentin


Am 16.12.2015 um 12:38 schrieb Steve Denham:
> I'll take a crack at the B questions.  Keep in mind that this is an 
> opinion only.  A significant fourth order by other factor interaction, 
> especially when the lower order polynomial by factor interactions are 
> not significant means that you have probably fit a polynomial to a 
> non-polynomial effect.  Your mention of a plateau tends to support 
> this, at least to me.  Some sort of non-linear effect (sigmoidal, four 
> or five factor logistic) may make more sense from a biological 
> perspective.
> Steve Denham Director, Biostatistics MPI Research, Inc.
>
>     ------------------------------------------------------------------------
>     *From:* Quentin Schorpp <quentin.schorpp at ti.bund.de>
>     *To:* "r-sig-mixed-models at r-project.org"
>     <r-sig-mixed-models at r-project.org>
>     *Sent:* Tuesday, December 15, 2015 8:14 AM
>     *Subject:* [R-sig-ME] Orthogonal Polynomial contrasts with ordered
>     factors
>
>     Hello,
>
>     I would appreciate to get to know more about the use of polynomial
>     contrasts in lme4::glmer.
>     Does anybody could give me an advice for literature about that
>     subject.
>
>     In particular
>     A:  I read, that if a second order polynomial is significant in the
>     summary output, then it is supposed to be significant AFTER the first
>     order polynomial was                taken into account. Is that right?
>
>     B1 : What happens if i use an ordered factor with another factor
>     (ordered or not) in an itneraction term? What does a signficant
>     interaction of the second                factor (any level) with the
>     fourth power polynomial of the first ordered factor tell me?
>     B2: And waht does it tell me when the lower order polynomials are not
>     significant in the interaction?
>
>
>     For more interested readers:
>
>     _The data_
>     My data is abundances of earthworms. I sampled 15 fields, three times
>     (samcam) during two years, with 4 pseudoreplicates per field (N=180).
>     The factor age_class describes the stage of development of the
>     field, it
>     has 5 levels ((n = 3 replicates).
>     However, one of these levels A_Cm has n=6 since i had to switch the
>     fields in the second year.
>     Field.ID is my random factor, to control for the pseudoreplication
>     per
>     field and the longitudinal character of the data.  For the sake of
>     less
>     complexity samcam stayed non-ordered.
>
>     Here is the design
>
>       field.ID\samcam1 2 3 1 4 4 4 2 4 4 4 3 4 4 4 4 4 4 4 5 4 4 4 6 4
>     4 4 7 4
>     4 4 8 4 4 4 9 4 4 4 10 4 4 4 11 4 4 4 _12 4 4 4_ 13 4 0 0 Fields
>     had to
>     be switched in the second year 14 4 0 0 15 4 0 0 16 0 4 4 17 0 4 4
>     18 0 4 4
>
>
>
>     Other continuous predictor variables were scaled before analysis.
>
>     data structure:
>       $ abundance      : num  0 0 3 3 2 1 2 5 12 5 ...
>
>       $ ID            : Factor w/ 180 levels "1","2","3","4",..: 1 2 3
>     4 5
>     6 7 8 9 10 ...
>       $ field.ID      : Factor w/ 18 levels "1","2","3","4",..: 1 1 1
>     1 2 2
>     2 2 3 3 ...
>       $ age_class      : Ord.factor w/ 5 levels
>     "A_Cm"<"B_Sp_young"<..: 5 5
>     5 5 5 5 5 5 5 5 ...
>       $ samcam        : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1
>     1 1 1 ...
>       $ hole          : Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1
>     2 3 4
>     1 2 ...
>
>       $ scl.pH        : num  -1.553 -1.553 -1.553 -1.553 0.715 ...
>       $ scl.mc        : num  -1.072 -1.072 -1.072 -1.072 -0.429 ...
>       $ scl.cn        : num  -0.703 -0.703 -0.703 -0.703 -0.474 ...
>       $ scl.sand      : num  -0.245 -0.245 -0.245 -0.245 -0.0127 ...
>       $ scl.silt      : num  -0.897 -0.897 -0.897 -0.897 -1.529 ...
>       $ scl.clay      : num  1.19 1.19 1.19 1.19 1.66 ...
>       $ scl.ata1      : num  1.6471 1.6471 1.6471 1.6471 0.0894 ...
>       $ scl.atb1      : num  1.6658 1.6658 1.6658 1.6658 0.0659 ...
>       $ scl.hum1      : num  -1.378 -1.378 -1.378 -1.378 0.429 ...
>
>     _my hyptheses are_
>     1. abundance increases with increasing age_class
>     2. If abundance increases over the age classes it will be observed by
>     increasing abundance during the period of sampling
>     (3. Abundance increases during the period of sampling)
>
>     _The Model was :_
>     best.mod <- glmer(abundance~ age_class*samcam + scl.prec1 +
>     scl.mc*scl.pH  + (1|field.ID) ,data=data,family=poisson,
>     control=glmerControl(optimizer="bobyqa"))
>
>     here is The Model output of one of the best models revealed by
>     MuMIn::dredge:
>
>     Generalized linear mixed model fit by maximum likelihood (Laplace
>     Approximation) ['glmerMod']
>       Family: poisson  ( log )
>     Formula: anc ~ age_class * samcam + I(scl.ats1^2) + scl.prec1 + (1
>     | field.ID)
>         Data: data
>     Control: glmerControl(optimizer = "bobyqa")
>
>           AIC      BIC  logLik deviance df.resid
>           731      789    -348      695      162
>
>     Scaled residuals:
>         Min    1Q Median    3Q    Max
>     -2.181 -0.696 -0.171  0.644  4.178
>
>     Random effects:
>       Groups  Name        Variance Std.Dev.
>       field.ID (Intercept) 0.263    0.513
>     Number of obs: 180, groups:  field.ID, 18
>
>     Fixed effects:
>                         Estimate Std. Error z value Pr(>|z|)
>     (Intercept)          0.6457    0.2079    3.11  0.0019 **
>     age_class.L          1.9924    0.4416    4.51  6.4e-06 ***
>     age_class.Q          -0.8644    0.4204  -2.06  0.0398 *
>     age_class.C          -0.2373    0.4007  -0.59  0.5537
>     age_class^4          0.7026    0.3591    1.96  0.0504 .
>     samcam2              0.8549    0.2074    4.12  3.7e-05 ***
>     samcam3              0.3074    0.1852    1.66  0.0969 .
>     I(scl.ats1^2)        -0.3328    0.1038  -3.21  0.0013 **
>     scl.prec1            0.2241    0.0851    2.63  0.0085 **
>     age_class.L:samcam2  -0.3474    0.5463  -0.64  0.5248
>     age_class.Q:samcam2  0.1074    0.4766    0.23  0.8216
>     age_class.C:samcam2  0.8910    0.3644    2.44  0.0145 *
>     _age_class^4:samcam2 -1.0352 0.2601 -3.98 6.9e-05 *** _ # HERE is
>     the significant interaction of interest!
>     age_class.L:samcam3  0.1274    0.5125    0.25  0.8038
>     age_class.Q:samcam3  -0.1801    0.4429  -0.41  0.6842
>     age_class.C:samcam3  0.5659    0.3615    1.57  0.1174
>     _age_class^4:samcam3 -0.6489 0.2617 -2.48 0.0131 * ___# HERE is
>     the significant interaction of interest!
>
>
>     _Interpretation:_
>     I understood, that the relationship was linear in general, as
>     indicated
>     by the second line of the output, and this did not change between the
>     sampling campaigns. However, during the second and third sampling
>     campaign the relationship of abundances in the age_classes was
>     characterised by a stronger slope in younger classes and reached a
>     plateau afterwards, as indicated by the fourth power.
>     The missing of the interaction between age_class and samcam1 is very
>     hard for me to understand
>
>     I'm thankful for any advices!
>
>     Quentin
>
>
>     -- 
>     Quentin Schorpp, M.Sc.
>     Th?nen-Institut f?r Biodiversit?t
>     Bundesallee 50
>     38116 Braunschweig (Germany)
>
>     Tel:  +49 531 596-2524
>     Fax:  +49 531 596-2599
>     Mail: quentin.schorpp at ti.bund.de <mailto:quentin.schorpp at ti.bund.de>
>     Web: http://www.ti.bund.de <http://www.ti.bund.de/>
>
>     Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut
>     f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
>     besteht aus 15 Fachinstituten, die in den Bereichen ?konomie,
>     ?kologie und Technologie forschen und die Politik beraten.
>
>     Quentin Schorpp, M.Sc.
>     Th?nen Institute of Biodiversity
>     Bundesallee 50
>     38116 Braunschweig (Germany)
>
>     Tel:  +49 531 596-2524
>     Fax:  +49 531 596-2599
>     Mail: quentin.schorpp at ti.bund.de <mailto:quentin.schorpp at ti.bund.de>
>     Web: http://www.ti.bund.de <http://www.ti.bund.de/>
>
>     The Johann Heinrich von Th?nen Institute, Federal Research
>     Institute for Rural Areas, Forestry and Fisheries ? Th?nen
>     Institute in brief ?
>     consists of 15 specialized institutes that carry out research and
>     provide policy advice in the fields of economy, ecology and
>     technology.
>
>
>         [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Quentin Schorpp, M.Sc.
Th?nen-Institut f?r Biodiversit?t
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.

Quentin Schorpp, M.Sc.
Th?nen Institute of Biodiversity
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.


	[[alternative HTML version deleted]]


From stevedrd at yahoo.com  Thu Dec 17 12:28:34 2015
From: stevedrd at yahoo.com (Steve Denham)
Date: Thu, 17 Dec 2015 11:28:34 +0000 (UTC)
Subject: [R-sig-ME] Orthogonal Polynomial contrasts with ordered factors
In-Reply-To: <56726D85.2070007@ti.bund.de>
References: <56726D85.2070007@ti.bund.de>
Message-ID: <780147080.68665.1450351714822.JavaMail.yahoo@mail.yahoo.com>

My real fear about fourth order polynomial by categorical interaction is that you may just be fitting noise. ?The part about the plateau is what tipped me off to looking at a non-linear effect. ?If only one interaction showed this, it would seem to me that the others aren't showing the kind of biological process observed here.
Have you looked at the residual error with increasing order of the polynomials? ?If there is an inflation of this (or the other random effects), then it is likely an overfit equation.?Steve Denham Director, Biostatistics MPI Research, Inc.
 

 
      From: Quentin Schorpp <quentin.schorpp at ti.bund.de>
 To: Steve Denham <stevedrd at yahoo.com>; "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Sent: Thursday, December 17, 2015 3:08 AM
 Subject: Re: [R-sig-ME] Orthogonal Polynomial contrasts with ordered factors
   
 Hello,
 
 Thank you for your answer. If I understood you right, you mean significant effects? of higher order polynomials could point to non-linear relationships between response and explanatory variable (also if the explanator is a categorial factor), under the  condition, that? lower order polynomials in between are "skipped" in the sense that theses are not significant? The significant effect of ("non successive") higher order polynomials could be either in interaction terms and without? However when thinking about fitting a non-linear model, i'm wondering if it would be justified in the case that significant ("non successive") higher order polynomials only occur in one interaction case (the discussed pattern is only observed in the interaction with one level of the second interaction factor). 
 
 p.S. Sorry for the worse formatting of the initial question, while writing the e-mail everything looked good, especially the factor by factor table to reveal the partly nested structure.
 
 kind regards,
 Quentin
 
 
 Am 16.12.2015 um 12:38 schrieb Steve Denham:
  
  I'll take a crack at the B questions. ?Keep in mind that this is an opinion only. ?A significant fourth order by other factor interaction, especially when the lower order polynomial by factor interactions are not significant means that you have probably fit a polynomial to a non-polynomial effect. ?Your mention of a plateau tends to support this, at least to me. ?Some sort of non-linear effect (sigmoidal, four or five factor logistic) may make more sense from a biological perspective. ? Steve Denham Director, Biostatistics MPI Research, Inc. 
 
      From: Quentin Schorpp <quentin.schorpp at ti.bund.de>
 To: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Sent: Tuesday, December 15, 2015 8:14 AM
 Subject: [R-sig-ME] Orthogonal Polynomial contrasts with ordered factors
  
 Hello,
 
 I would appreciate to get to know more about the use of polynomial 
 contrasts in lme4::glmer.
 Does anybody could give me an advice for literature about that subject.
 
 In particular
 A:? I read, that if a second order polynomial is significant in the 
 summary output, then it is supposed to be significant AFTER the first 
 order polynomial was? ? ? ? ? ? ? ? taken into account. Is that right?
 
 B1 : What happens if i use an ordered factor with another factor 
 (ordered or not) in an itneraction term? What does a signficant 
 interaction of the second? ? ? ? ? ? ? ? factor (any level) with the 
 fourth power polynomial of the first ordered factor tell me?
 B2: And waht does it tell me when the lower order polynomials are not 
 significant in the interaction?
 
 
 For more interested readers:
 
 _The data_
 My data is abundances of earthworms. I sampled 15 fields, three times 
 (samcam) during two years, with 4 pseudoreplicates per field (N=180).
 The factor age_class describes the stage of development of the field, it 
 has 5 levels ((n = 3 replicates).
 However, one of these levels A_Cm has n=6 since i had to switch the 
 fields in the second year.
 Field.ID is my random factor, to control for the pseudoreplication per 
 field and the longitudinal character of the data.? For the sake of less 
 complexity samcam stayed non-ordered.
 
 Here is the design
 
 ? field.ID\samcam1 2 3 1 4 4 4 2 4 4 4 3 4 4 4 4 4 4 4 5 4 4 4 6 4 4 4 7 4 
 4 4 8 4 4 4 9 4 4 4 10 4 4 4 11 4 4 4 _12 4 4 4_ 13 4 0 0 Fields had to 
 be switched in the second year 14 4 0 0 15 4 0 0 16 0 4 4 17 0 4 4 18 0 4 4
 
 
 
 Other continuous predictor variables were scaled before analysis.
 
 data structure:
 ? $ abundance? ? ? : num? 0 0 3 3 2 1 2 5 12 5 ...
 
 ? $ ID? ? ? ? ? ? : Factor w/ 180 levels "1","2","3","4",..: 1 2 3 4 5 
 6 7 8 9 10 ...
 ? $ field.ID? ? ? : Factor w/ 18 levels "1","2","3","4",..: 1 1 1 1 2 2 
 2 2 3 3 ...
 ? $ age_class? ? ? : Ord.factor w/ 5 levels "A_Cm"<"B_Sp_young"<..: 5 5 
 5 5 5 5 5 5 5 5 ...
 ? $ samcam? ? ? ? : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
 ? $ hole? ? ? ? ? : Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1 2 3 4 
 1 2 ...
 
 ? $ scl.pH? ? ? ? : num? -1.553 -1.553 -1.553 -1.553 0.715 ...
 ? $ scl.mc? ? ? ? : num? -1.072 -1.072 -1.072 -1.072 -0.429 ...
 ? $ scl.cn? ? ? ? : num? -0.703 -0.703 -0.703 -0.703 -0.474 ...
 ? $ scl.sand? ? ? : num? -0.245 -0.245 -0.245 -0.245 -0.0127 ...
 ? $ scl.silt? ? ? : num? -0.897 -0.897 -0.897 -0.897 -1.529 ...
 ? $ scl.clay? ? ? : num? 1.19 1.19 1.19 1.19 1.66 ...
 ? $ scl.ata1? ? ? : num? 1.6471 1.6471 1.6471 1.6471 0.0894 ...
 ? $ scl.atb1? ? ? : num? 1.6658 1.6658 1.6658 1.6658 0.0659 ...
 ? $ scl.hum1? ? ? : num? -1.378 -1.378 -1.378 -1.378 0.429 ...
 
 _my hyptheses are_
 1. abundance increases with increasing age_class
 2. If abundance increases over the age classes it will be observed by 
 increasing abundance during the period of sampling
 (3. Abundance increases during the period of sampling)
 
 _The Model was :_
 best.mod <- glmer(abundance~ age_class*samcam + scl.prec1 + 
 scl.mc*scl.pH? + (1|field.ID)? ,data=data,family=poisson, 
 control=glmerControl(optimizer="bobyqa"))
 
 here is The Model output of one of the best models revealed by 
 MuMIn::dredge:
 
 Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 ? Family: poisson? ( log )
 Formula: anc ~ age_class * samcam + I(scl.ats1^2) + scl.prec1 + (1 | field.ID)
 ? ? Data: data
 Control: glmerControl(optimizer = "bobyqa")
 
 ? ? ? AIC? ? ? BIC? logLik deviance df.resid
 ? ? ? 731? ? ? 789? ? -348? ? ? 695? ? ? 162
 
 Scaled residuals:
 ? ? Min? ? 1Q Median? ? 3Q? ? Max
 -2.181 -0.696 -0.171? 0.644? 4.178
 
 Random effects:
 ? Groups? Name? ? ? ? Variance Std.Dev.
 ? field.ID (Intercept) 0.263? ? 0.513
 Number of obs: 180, groups:? field.ID, 18
 
 Fixed effects:
 ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
 (Intercept)? ? ? ? ? 0.6457? ? 0.2079? ? 3.11? 0.0019 **
 age_class.L? ? ? ? ? 1.9924? ? 0.4416? ? 4.51? 6.4e-06 ***
 age_class.Q? ? ? ? ? -0.8644? ? 0.4204? -2.06? 0.0398 *
 age_class.C? ? ? ? ? -0.2373? ? 0.4007? -0.59? 0.5537
 age_class^4? ? ? ? ? 0.7026? ? 0.3591? ? 1.96? 0.0504 .
 samcam2? ? ? ? ? ? ? 0.8549? ? 0.2074? ? 4.12? 3.7e-05 ***
 samcam3? ? ? ? ? ? ? 0.3074? ? 0.1852? ? 1.66? 0.0969 .
 I(scl.ats1^2)? ? ? ? -0.3328? ? 0.1038? -3.21? 0.0013 **
 scl.prec1? ? ? ? ? ? 0.2241? ? 0.0851? ? 2.63? 0.0085 **
 age_class.L:samcam2? -0.3474? ? 0.5463? -0.64? 0.5248
 age_class.Q:samcam2? 0.1074? ? 0.4766? ? 0.23? 0.8216
 age_class.C:samcam2? 0.8910? ? 0.3644? ? 2.44? 0.0145 *
 _age_class^4:samcam2 -1.0352 0.2601 -3.98 6.9e-05 *** _? # HERE is the significant interaction of interest!
 age_class.L:samcam3? 0.1274? ? 0.5125? ? 0.25? 0.8038
 age_class.Q:samcam3? -0.1801? ? 0.4429? -0.41? 0.6842
 age_class.C:samcam3? 0.5659? ? 0.3615? ? 1.57? 0.1174
 _age_class^4:samcam3 -0.6489 0.2617 -2.48 0.0131 * ___# HERE is the significant interaction of interest!
 
 
 _Interpretation:_
 I understood, that the relationship was linear in general, as indicated 
 by the second line of the output, and this did not change between the 
 sampling campaigns. However, during the second and third sampling 
 campaign the relationship of abundances in the age_classes was 
 characterised by a stronger slope in younger classes and reached a 
 plateau afterwards, as indicated by the fourth power.
 The missing of the interaction between age_class and samcam1 is very 
 hard for me to understand
 
 I'm thankful for any advices!
 
 Quentin
 
 
 -- 
 Quentin Schorpp, M.Sc.
 Th?nen-Institut f?r Biodiversit?t
 Bundesallee 50
 38116 Braunschweig (Germany)
 
 Tel:? +49 531 596-2524
 Fax:? +49 531 596-2599
 Mail: quentin.schorpp at ti.bund.de
 Web:? http://www.ti.bund.de
 
 Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
 besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.
 
 Quentin Schorpp, M.Sc.
 Th?nen Institute of Biodiversity
 Bundesallee 50
 38116 Braunschweig (Germany)
 
 Tel:? +49 531 596-2524
 Fax:? +49 531 596-2599
 Mail: quentin.schorpp at ti.bund.de
 Web:? http://www.ti.bund.de
 
 The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
 consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.
 
 
 ??? [[alternative HTML version deleted]]
 
 _______________________________________________
 R-sig-mixed-models at r-project.org mailing list
 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

    
  

 -- 
Quentin Schorpp, M.Sc.
Th?nen-Institut f?r Biodiversit?t
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ? 
besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.

Quentin Schorpp, M.Sc.
Th?nen Institute of Biodiversity
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ? 
consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.


   

	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Dec 17 13:24:51 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 17 Dec 2015 08:24:51 -0400
Subject: [R-sig-ME] Course: Introduction to GAM and GAMM
Message-ID: <5672A993.1030607@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to GAM and GAMM
Where:  University of Konstanz, Konstanz, Germany
When:   7-11 March 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://highstat.com/Courses/Flyer2016_03Konstanz.pdf



Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From nefuitphuangru at gmail.com  Mon Dec 14 05:20:12 2015
From: nefuitphuangru at gmail.com (=?UTF-8?B?6buE6Iy5?=)
Date: Mon, 14 Dec 2015 12:20:12 +0800
Subject: [R-sig-ME] Could we calculate the variance explained by each fixed
 variable when we use linear mixed model?
Message-ID: <CAGsewOASOkpd6m8+RoT0a3WRi1=RJsMAVz8WGL5hjf1oVzw70g@mail.gmail.com>

     Can we calaulate the respective variance explained by each fixed
variable when we use linear mixed model?

Namely, for R code of linear mixed model: model=lmer(y~x1+x2+(1/x3),data),
x1,x2 are fixed variables, and x3 is random effect. could we compute the
variance of y explained by x1,x2, respective?

	[[alternative HTML version deleted]]


From james_980 at hotmail.com  Fri Dec 18 10:15:49 2015
From: james_980 at hotmail.com (James Rudge)
Date: Fri, 18 Dec 2015 09:15:49 +0000
Subject: [R-sig-ME] priors for fixed-effect covariates using bglmer -
 centering the t-distribution?
Message-ID: <DUB111-W499B01F9ECB5CAAB598756D1E10@phx.gbl>

I'm trying to fit a mixed effects model with a pig Disease as the binary outcome, Water.Source as a categorical fixed effects predictor, and Herd as random effects.
However I have quasi-complete separation of the outcome, with no disease events in some categories of Water.Source, so a GLMM model will not converge.

So I'm now trying to define a weak prior for the fixed effects using bglmer, as suggested by Ben Bolker in this helpful post: http://stats.stackexchange.com/questions/132677/binomial-glmm-with-a-categorical-variable-with-full-successes

For choosing the prior for the fixed effects, I'd like to follow this reference:
Jos? Corti?as Abrahantes and Marc Aerts (2012) A solution to separation for clustered binary data Statistical Modelling 12(1):3?27  doi: 10.1177/1471082X1001200102 

They propose using a Cauchy (t1) distribution, centered around  the value of the beta coefficient (call it beta.f) estimated using Firth's penalized maximum likelihood method for the variable in question (i.e. ignoring the random effects), with scale equal to 2 times the variance (call it var.f) also estimated from the Firth logistic regression model.

So I have the following for my model so far, which scales the t-distribution by 2*var.f, how can I also center it around beta.f?

bglmer(Disease~Water.Source+(1|Herd), data=pigdat,
                  family=binomial,
                  fixef.prior=t(df=1, scale=2*var.f))

Thanks in advance!
 		 	   		  
	[[alternative HTML version deleted]]


From vjd4 at nyu.edu  Fri Dec 18 18:29:41 2015
From: vjd4 at nyu.edu (Vincent Dorie)
Date: Fri, 18 Dec 2015 12:29:41 -0500
Subject: [R-sig-ME] priors for fixed-effect covariates using bglmer -
 centering the t-distribution?
In-Reply-To: <DUB111-W499B01F9ECB5CAAB598756D1E10@phx.gbl>
References: <DUB111-W499B01F9ECB5CAAB598756D1E10@phx.gbl>
Message-ID: <CAAQ+4bpPc37Z6aM3Ed0dESA7gVdNyi9g5yuZdyXjSC25dYO-8w@mail.gmail.com>

I can't remember why I didn't add prior means for fixed effects - I think
it had to do with not breaking the profiling scheme of lme4 and the ability
to roughly achieve the same thing through linear transformations of the
covariates.

Regardless, I just added them to t priors in the source repository on
Github (https://github.com/vdorie/blme). It works as you might expect,
where the the specifying function takes a "mean" argument of length 1, 2,
or the number of fixed effects, where if it length 2 the first term applies
just to the intercept and the second is used for all the slopes.

Let me know if you end up using it and encountering any trouble. Before I
submit to CRAN I would have to think some more about the case of normal
priors and do some additional testing.

Vince

On Fri, Dec 18, 2015 at 4:15 AM, James Rudge <james_980 at hotmail.com> wrote:

> I'm trying to fit a mixed effects model with a pig Disease as the binary
> outcome, Water.Source as a categorical fixed effects predictor, and Herd as
> random effects.
> However I have quasi-complete separation of the outcome, with no disease
> events in some categories of Water.Source, so a GLMM model will not
> converge.
>
> So I'm now trying to define a weak prior for the fixed effects using
> bglmer, as suggested by Ben Bolker in this helpful post:
> http://stats.stackexchange.com/questions/132677/binomial-glmm-with-a-categorical-variable-with-full-successes
>
> For choosing the prior for the fixed effects, I'd like to follow this
> reference:
> Jos? Corti?as Abrahantes and Marc Aerts (2012) A solution to separation
> for clustered binary data Statistical Modelling 12(1):3?27  doi:
> 10.1177/1471082X1001200102
>
> They propose using a Cauchy (t1) distribution, centered around  the value
> of the beta coefficient (call it beta.f) estimated using Firth's penalized
> maximum likelihood method for the variable in question (i.e. ignoring the
> random effects), with scale equal to 2 times the variance (call it var.f)
> also estimated from the Firth logistic regression model.
>
> So I have the following for my model so far, which scales the
> t-distribution by 2*var.f, how can I also center it around beta.f?
>
> bglmer(Disease~Water.Source+(1|Herd), data=pigdat,
>                   family=binomial,
>                   fixef.prior=t(df=1, scale=2*var.f))
>
> Thanks in advance!
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From drmccloy at uw.edu  Fri Dec 18 19:33:22 2015
From: drmccloy at uw.edu (Dan McCloy)
Date: Fri, 18 Dec 2015 10:33:22 -0800
Subject: [R-sig-ME] Could we calculate the variance explained by each
 fixed variable when we use linear mixed model?
In-Reply-To: <CAGsewOASOkpd6m8+RoT0a3WRi1=RJsMAVz8WGL5hjf1oVzw70g@mail.gmail.com>
References: <CAGsewOASOkpd6m8+RoT0a3WRi1=RJsMAVz8WGL5hjf1oVzw70g@mail.gmail.com>
Message-ID: <CAOE0pYmNJYWwrT8QqMhZHtrgw6pWfp2iuAStbMSW-K-VtG_tvw@mail.gmail.com>

There is a discussion of variance explained on the Wiki:
http://glmm.wikidot.com/faq
See the section "How do I compute a coefficient of determination..."


On Sun, Dec 13, 2015 at 8:20 PM, ?? <nefuitphuangru at gmail.com> wrote:
>      Can we calaulate the respective variance explained by each fixed
> variable when we use linear mixed model?
>
> Namely, for R code of linear mixed model: model=lmer(y~x1+x2+(1/x3),data),
> x1,x2 are fixed variables, and x3 is random effect. could we compute the
> variance of y explained by x1,x2, respective?
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jake987722 at hotmail.com  Fri Dec 18 20:34:16 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Fri, 18 Dec 2015 19:34:16 +0000
Subject: [R-sig-ME] Could we calculate the variance explained by each
 fixed variable when we use linear mixed model?
In-Reply-To: <CAOE0pYmNJYWwrT8QqMhZHtrgw6pWfp2iuAStbMSW-K-VtG_tvw@mail.gmail.com>
References: <CAGsewOASOkpd6m8+RoT0a3WRi1=RJsMAVz8WGL5hjf1oVzw70g@mail.gmail.com>,
	<CAOE0pYmNJYWwrT8QqMhZHtrgw6pWfp2iuAStbMSW-K-VtG_tvw@mail.gmail.com>
Message-ID: <DM3PR19MB052287092DEB02FC1697B4CCCBE10@DM3PR19MB0522.namprd19.prod.outlook.com>

The discussion on the wiki is a little different, since it is about getting some global R^2 statistic for the whole model, whereas the OP here appears to want a separate variance explained statistic for each predictor, analogous to partial eta-squared in multiple regression.

Jake

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Dan McCloy <drmccloy at uw.edu>
Sent: Friday, December 18, 2015 12:33 PM
To: ??
Cc: R-SIG-Mixed-Models at r-project.org
Subject: Re: [R-sig-ME] Could we calculate the variance explained by each fixed variable when we use linear mixed model?

There is a discussion of variance explained on the Wiki:
http://glmm.wikidot.com/faq
See the section "How do I compute a coefficient of determination..."


On Sun, Dec 13, 2015 at 8:20 PM, ?? <nefuitphuangru at gmail.com> wrote:
>      Can we calaulate the respective variance explained by each fixed
> variable when we use linear mixed model?
>
> Namely, for R code of linear mixed model: model=lmer(y~x1+x2+(1/x3),data),
> x1,x2 are fixed variables, and x3 is random effect. could we compute the
> variance of y explained by x1,x2, respective?
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From james_980 at hotmail.com  Sat Dec 19 06:30:26 2015
From: james_980 at hotmail.com (James Rudge)
Date: Sat, 19 Dec 2015 05:30:26 +0000
Subject: [R-sig-ME] priors for fixed-effect covariates using bglmer -
 centering the t-distribution?
In-Reply-To: <CAAQ+4bpPc37Z6aM3Ed0dESA7gVdNyi9g5yuZdyXjSC25dYO-8w@mail.gmail.com>
References: <DUB111-W499B01F9ECB5CAAB598756D1E10@phx.gbl>,
	<CAAQ+4bpPc37Z6aM3Ed0dESA7gVdNyi9g5yuZdyXjSC25dYO-8w@mail.gmail.com>
Message-ID: <DUB111-W156A1A0CB5154718C9F10BD1E20@phx.gbl>

Dear Vince,

Great, it seems to be working well! Thanks so much.

James

Date: Fri, 18 Dec 2015 12:29:41 -0500
Subject: Re: [R-sig-ME] priors for fixed-effect covariates using bglmer - centering the t-distribution?
From: vjd4 at nyu.edu
To: james_980 at hotmail.com
CC: r-sig-mixed-models at r-project.org

I can't remember why I didn't add prior means for fixed effects - I think it had to do with not breaking the profiling scheme of lme4 and the ability to roughly achieve the same thing through linear transformations of the covariates.
Regardless, I just added them to t priors in the source repository on Github (https://github.com/vdorie/blme). It works as you might expect, where the the specifying function takes a "mean" argument of length 1, 2, or the number of fixed effects, where if it length 2 the first term applies just to the intercept and the second is used for all the slopes.
Let me know if you end up using it and encountering any trouble. Before I submit to CRAN I would have to think some more about the case of normal priors and do some additional testing.
Vince
On Fri, Dec 18, 2015 at 4:15 AM, James Rudge <james_980 at hotmail.com> wrote:
I'm trying to fit a mixed effects model with a pig Disease as the binary outcome, Water.Source as a categorical fixed effects predictor, and Herd as random effects.

However I have quasi-complete separation of the outcome, with no disease events in some categories of Water.Source, so a GLMM model will not converge.



So I'm now trying to define a weak prior for the fixed effects using bglmer, as suggested by Ben Bolker in this helpful post: http://stats.stackexchange.com/questions/132677/binomial-glmm-with-a-categorical-variable-with-full-successes



For choosing the prior for the fixed effects, I'd like to follow this reference:

Jos? Corti?as Abrahantes and Marc Aerts (2012) A solution to separation for clustered binary data Statistical Modelling 12(1):3?27  doi: 10.1177/1471082X1001200102



They propose using a Cauchy (t1) distribution, centered around  the value of the beta coefficient (call it beta.f) estimated using Firth's penalized maximum likelihood method for the variable in question (i.e. ignoring the random effects), with scale equal to 2 times the variance (call it var.f) also estimated from the Firth logistic regression model.



So I have the following for my model so far, which scales the t-distribution by 2*var.f, how can I also center it around beta.f?



bglmer(Disease~Water.Source+(1|Herd), data=pigdat,

                  family=binomial,

                  fixef.prior=t(df=1, scale=2*var.f))



Thanks in advance!



        [[alternative HTML version deleted]]




_______________________________________________

R-sig-mixed-models at r-project.org mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 		 	   		  
	[[alternative HTML version deleted]]


From gitumbui at gmail.com  Thu Dec 24 02:53:30 2015
From: gitumbui at gmail.com (Gitu wa Mbui)
Date: Thu, 24 Dec 2015 11:53:30 +1000
Subject: [R-sig-ME] Distribution family for non-negative lower and upper
	bound values
Message-ID: <CAFPRYfC4TJRX+jTsrNK4W+Hyo3ePisdw-9F3yJ-QR6oaFu2uZg@mail.gmail.com>

I am running generalized additive mixed models on two response variables
separately. Values in response 1 are non-negative and bounded between 1-2,
while response 2 is also non- negative and bounded between 1-3.

In choosing the distribution for response 1, I have subtracted 1 (to
rescale to between 0-1) and logit transformed before fitting the models
with gaussian family.

As for response 2 (non-negative values between 1-3), I have divided the
values by 3 so as to rescale to between 0-1, before logit transforming and
fitting with gaussian family.

Does this sound like a good approach? if not what are the alternatives,
considering:
- responses 1&2 are not proportions
- I am using lme4 version (gamm4) which is limited on the number of
families that can be fit
- histograms of both responses are pretty flat (non skewed and don't look
anywhere near normal distribution

~ Gitu

	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Dec 24 16:09:57 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 24 Dec 2015 11:09:57 -0400
Subject: [R-sig-ME] Distribution family for non-negative lower and,
 upper bound values
In-Reply-To: <mailman.1.1450954802.24975.r-sig-mixed-models@r-project.org>
References: <mailman.1.1450954802.24975.r-sig-mixed-models@r-project.org>
Message-ID: <567C0AC5.7050305@highstat.com>




Today's Topics:

    1. Distribution family for non-negative lower and upper	bound
       values (Gitu wa Mbui)


----------------------------------------------------------------------

Message: 1
Date: Thu, 24 Dec 2015 11:53:30 +1000
From: Gitu wa Mbui <gitumbui at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Distribution family for non-negative lower and
	upper	bound values
Message-ID:
	<CAFPRYfC4TJRX+jTsrNK4W+Hyo3ePisdw-9F3yJ-QR6oaFu2uZg at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

I am running generalized additive mixed models on two response variables
separately. Values in response 1 are non-negative and bounded between 1-2,
while response 2 is also non- negative and bounded between 1-3.

In choosing the distribution for response 1, I have subtracted 1 (to
rescale to between 0-1) and logit transformed before fitting the models
with gaussian family.

As for response 2 (non-negative values between 1-3), I have divided the
values by 3 so as to rescale to between 0-1, before logit transforming and
fitting with gaussian family.

Does this sound like a good approach? if not what are the alternatives,
considering:
- responses 1&2 are not proportions
- I am using lme4 version (gamm4) which is limited on the number of
families that can be fit
- histograms of both responses are pretty flat (non skewed and don't look
anywhere near normal distribution

~ Gitu




Not sure whether you want to hear my suggestion. Perhaps other people have easier approaches.
If both responses come from the same data then you should apply a multivariate model (with
multiple response variables).

You could try a beta distribution, which can be used when your data is between x1 and x2.

Making a histogram of the response variable is a waste of time. Why should it look normal
distributed?

All in all this sounds like an MCMC job. I haven't tried SabreR...maybe it can do a beta distribution.

Kind regards,


Alain Zuur


From pierces1 at msu.edu  Fri Dec 25 16:57:03 2015
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Fri, 25 Dec 2015 10:57:03 -0500
Subject: [R-sig-ME] Distribution family for non-negative lower and
	upper	bound values
In-Reply-To: <CAFPRYfC4TJRX+jTsrNK4W+Hyo3ePisdw-9F3yJ-QR6oaFu2uZg@mail.gmail.com>
References: <CAFPRYfC4TJRX+jTsrNK4W+Hyo3ePisdw-9F3yJ-QR6oaFu2uZg@mail.gmail.com>
Message-ID: <000001d13f2c$e5cb4570$b161d050$@msu.edu>

Gitu,

Consider a mixed effects variant of the beta regression model, as discussed in the papers below.

Smithson, M., & Verkuilen, J. (2006). A better lemon squeezer? Maximum likelihood regression with beta-distributed dependent variables. Psychological Methods, 11(1), 54-71. doi:10.1037/1082-989X.11.1.54

Zimprich, D. (2010). Modeling change in skewed variables using mixed beta regression models. Research in Human Development, 7(1), 9-26. doi:10.1080/15427600903578136

Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Gitu wa Mbui [mailto:gitumbui at gmail.com] 
Sent: Wednesday, December 23, 2015 8:54 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Distribution family for non-negative lower and upper bound values

I am running generalized additive mixed models on two response variables
separately. Values in response 1 are non-negative and bounded between 1-2,
while response 2 is also non- negative and bounded between 1-3.

In choosing the distribution for response 1, I have subtracted 1 (to
rescale to between 0-1) and logit transformed before fitting the models
with gaussian family.

As for response 2 (non-negative values between 1-3), I have divided the
values by 3 so as to rescale to between 0-1, before logit transforming and
fitting with gaussian family.

Does this sound like a good approach? if not what are the alternatives,
considering:
- responses 1&2 are not proportions
- I am using lme4 version (gamm4) which is limited on the number of
families that can be fit
- histograms of both responses are pretty flat (non skewed and don't look
anywhere near normal distribution

~ Gitu

	[[alternative HTML version deleted]]


From gitumbui at gmail.com  Fri Dec 25 23:54:19 2015
From: gitumbui at gmail.com (Gitu wa Mbui)
Date: Sat, 26 Dec 2015 08:54:19 +1000
Subject: [R-sig-ME] Distribution family for non-negative lower and upper
 bound values
In-Reply-To: <000001d13f2c$e5cb4570$b161d050$@msu.edu>
References: <CAFPRYfC4TJRX+jTsrNK4W+Hyo3ePisdw-9F3yJ-QR6oaFu2uZg@mail.gmail.com>
	<000001d13f2c$e5cb4570$b161d050$@msu.edu>
Message-ID: <CAFPRYfANEVctLaRPBc=Otit6VqXBbM3E5Pik=L1fBLKwj0ehRw@mail.gmail.com>

Alain, Steven,

Thanks both for the lead and for the papers. A few clarifications:

*1. SP>> Consider a mixed effects variant of the beta regression model, as
discussed in the papers below.*

I assume that you agree with the rescaling approach then? I should have
mentioned that I will be comparing several models  - the ideal package
would be gamm4, however it doesn't fit betar family. (gamm package does but
comparing models is compromised)

*2. AZ>>You could try a beta distribution, which can be used when your data
is between x1 and x2.*

Not sure I understand 'when your data is between x1 and x2'. What does x1
and x2 refer to?

In any case - as recommended in your book - beginners to GAMM, gamm4
package is ideal when comparing models (I have 500 models to compare). This
doesn't fit beta family - is there a workaround?

*3. AZ>>All in all this sounds like an MCMC job. I haven't tried
SabreR...maybe it can do a beta distribution.*

I haven't tried these two before

Kind regards,

Gitu











On Sat, Dec 26, 2015 at 1:57 AM, Steven J. Pierce <pierces1 at msu.edu> wrote:

> Gitu,
>
> Consider a mixed effects variant of the beta regression model, as
> discussed in the papers below.
>
> Smithson, M., & Verkuilen, J. (2006). A better lemon squeezer? Maximum
> likelihood regression with beta-distributed dependent variables.
> Psychological Methods, 11(1), 54-71. doi:10.1037/1082-989X.11.1.54
>
> Zimprich, D. (2010). Modeling change in skewed variables using mixed beta
> regression models. Research in Human Development, 7(1), 9-26.
> doi:10.1080/15427600903578136
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
>
> -----Original Message-----
> From: Gitu wa Mbui [mailto:gitumbui at gmail.com]
> Sent: Wednesday, December 23, 2015 8:54 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Distribution family for non-negative lower and upper
> bound values
>
> I am running generalized additive mixed models on two response variables
> separately. Values in response 1 are non-negative and bounded between 1-2,
> while response 2 is also non- negative and bounded between 1-3.
>
> In choosing the distribution for response 1, I have subtracted 1 (to
> rescale to between 0-1) and logit transformed before fitting the models
> with gaussian family.
>
> As for response 2 (non-negative values between 1-3), I have divided the
> values by 3 so as to rescale to between 0-1, before logit transforming and
> fitting with gaussian family.
>
> Does this sound like a good approach? if not what are the alternatives,
> considering:
> - responses 1&2 are not proportions
> - I am using lme4 version (gamm4) which is limited on the number of
> families that can be fit
> - histograms of both responses are pretty flat (non skewed and don't look
> anywhere near normal distribution
>
> ~ Gitu
>
>         [[alternative HTML version deleted]]
>
>
>
>

	[[alternative HTML version deleted]]


From pierces1 at msu.edu  Sat Dec 26 00:30:31 2015
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Fri, 25 Dec 2015 18:30:31 -0500
Subject: [R-sig-ME] Distribution family for non-negative lower and upper
	bound values
In-Reply-To: <CAFPRYfANEVctLaRPBc=Otit6VqXBbM3E5Pik=L1fBLKwj0ehRw@mail.gmail.com>
References: <CAFPRYfC4TJRX+jTsrNK4W+Hyo3ePisdw-9F3yJ-QR6oaFu2uZg@mail.gmail.com>	<000001d13f2c$e5cb4570$b161d050$@msu.edu>
	<CAFPRYfANEVctLaRPBc=Otit6VqXBbM3E5Pik=L1fBLKwj0ehRw@mail.gmail.com>
Message-ID: <000001d13f6c$3f655b40$be3011c0$@msu.edu>

1.       Yes, rescaling seems reasonable to me, though I would use the equations specified in the papers I cited rather than the one you described. 

2.       The short answer is that x1 and x2 are respectively the minimum and maximum possible values your variable can take on. Note that I am talking about possible values, not observed values. This is because the beta distribution can be applied when your variable has both theoretical lower and upper bounds, such that all observations must fall in the closed interval [x1, x2]. This is why the beta distribution works well for data values that are proportions. If your data do not fall in the open interval (0, 1), then you rescale them do so before running the analysis, and subsequently back-transform parameter estimates, predictions, and other quantities of interest to the original scale of the data. 

 

Steven J. Pierce, Ph.D.

Associate Director

Center for Statistical Training & Consulting (CSTAT)

Michigan State University

 

From: Gitu wa Mbui [mailto:gitumbui at gmail.com] 
Sent: Friday, December 25, 2015 5:54 PM
To: Steven J. Pierce <pierces1 at msu.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Distribution family for non-negative lower and upper bound values

 

Alain, Steven,

 

Thanks both for the lead and for the papers. A few clarifications:

 

1. SP>> Consider a mixed effects variant of the beta regression model, as discussed in the papers below.

 

I assume that you agree with the rescaling approach then? I should have mentioned that I will be comparing several models  - the ideal package would be gamm4, however it doesn't fit betar family. (gamm package does but comparing models is compromised)

 

2. AZ>>You could try a beta distribution, which can be used when your data is between x1 and x2.

 

Not sure I understand 'when your data is between x1 and x2'. What does x1 and x2 refer to?

 

In any case - as recommended in your book - beginners to GAMM, gamm4 package is ideal when comparing models (I have 500 models to compare). This doesn't fit beta family - is there a workaround? 

 

3. AZ>>All in all this sounds like an MCMC job. I haven't tried SabreR...maybe it can do a beta distribution.

 

I haven't tried these two before 

 

Kind regards,

 

Gitu

 

 

 

 

 

 

 

 

 

 

 

On Sat, Dec 26, 2015 at 1:57 AM, Steven J. Pierce <pierces1 at msu.edu <mailto:pierces1 at msu.edu> > wrote:

Gitu,

Consider a mixed effects variant of the beta regression model, as discussed in the papers below.

Smithson, M., & Verkuilen, J. (2006). A better lemon squeezer? Maximum likelihood regression with beta-distributed dependent variables. Psychological Methods, 11(1), 54-71. doi:10.1037/1082-989X.11.1.54

Zimprich, D. (2010). Modeling change in skewed variables using mixed beta regression models. Research in Human Development, 7(1), 9-26. doi:10.1080/15427600903578136

Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University


-----Original Message-----
From: Gitu wa Mbui [mailto:gitumbui at gmail.com <mailto:gitumbui at gmail.com> ]
Sent: Wednesday, December 23, 2015 8:54 PM
To: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> 
Subject: [R-sig-ME] Distribution family for non-negative lower and upper bound values

I am running generalized additive mixed models on two response variables
separately. Values in response 1 are non-negative and bounded between 1-2,
while response 2 is also non- negative and bounded between 1-3.

In choosing the distribution for response 1, I have subtracted 1 (to
rescale to between 0-1) and logit transformed before fitting the models
with gaussian family.

As for response 2 (non-negative values between 1-3), I have divided the
values by 3 so as to rescale to between 0-1, before logit transforming and
fitting with gaussian family.

Does this sound like a good approach? if not what are the alternatives,
considering:
- responses 1&2 are not proportions
- I am using lme4 version (gamm4) which is limited on the number of
families that can be fit
- histograms of both responses are pretty flat (non skewed and don't look
anywhere near normal distribution

~ Gitu

        [[alternative HTML version deleted]]




 


	[[alternative HTML version deleted]]


From adeela.uaf at gmail.com  Tue Dec 29 05:56:54 2015
From: adeela.uaf at gmail.com (Adeela Munawar)
Date: Tue, 29 Dec 2015 09:56:54 +0500
Subject: [R-sig-ME] different output in R and SAS for GLMM
Message-ID: <CABGg3O6Jf8bB8mXVYVEMQVkrGDEeTvaDEpg+ZTYd3uuvh+MkeQ@mail.gmail.com>

Dear all,

I am comparing the output of SAS and R for generalized linear mixed models
with gamma family. Code for SAS are

proc glimmix data=ch12_ex1 plot=residualpanel(ilink) noprofile;
 class block a b;
 model days=a|b / d=gamma;
 random intercept a/subject=block;
 lsmeans a*b / slicediff=(a b) ilink cl;
 covtest /cl(type=plr);

while I am fitting this using lme4 package as
a<-factor(a)
b<-factor(b)
block<-factor(block)

ModelGamma <- glmer(days~a*b+(1|block/a),family=Gamma(link = "log"))
 lsmeans(ModelGamma,~a*b)

but the results are altogether different. SAS gives 9 df while NA in R and
least sqaure means are also different.

a b   lsmean        SE      df   asymp.LCL asymp.UCL
 1 1 3.212923 0.5677001 NA  2.100251  4.325595
 2 1 3.229803 0.5662713 NA  2.119932  4.339675
 3 1 3.279271 0.5688496 NA  2.164346  4.394196
 1 2 2.499457 0.5679181 NA  1.386358  3.612556
 2 2 3.248968 0.5659105 NA  2.139804  4.358132
 3 2 3.563672 0.5689044 NA  2.448640  4.678705

Why this happens? Please suggest.

Thanks,
Adeela

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Dec 29 06:01:20 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 29 Dec 2015 00:01:20 -0500
Subject: [R-sig-ME] different output in R and SAS for GLMM
In-Reply-To: <CABGg3O6Jf8bB8mXVYVEMQVkrGDEeTvaDEpg+ZTYd3uuvh+MkeQ@mail.gmail.com>
References: <CABGg3O6Jf8bB8mXVYVEMQVkrGDEeTvaDEpg+ZTYd3uuvh+MkeQ@mail.gmail.com>
Message-ID: <CABghstTee9QhttiDP21gQoapNA1OoiM_H_dqeQTcrscpm5jfwA@mail.gmail.com>

May we have a *reproducible* example please?  (All of your R code,
plus either your data set or a similar (or smaller) data set with the
SAS results corresponding to it ...)

On Mon, Dec 28, 2015 at 11:56 PM, Adeela Munawar <adeela.uaf at gmail.com> wrote:
> Dear all,
>
> I am comparing the output of SAS and R for generalized linear mixed models
> with gamma family. Code for SAS are
>
> proc glimmix data=ch12_ex1 plot=residualpanel(ilink) noprofile;
>  class block a b;
>  model days=a|b / d=gamma;
>  random intercept a/subject=block;
>  lsmeans a*b / slicediff=(a b) ilink cl;
>  covtest /cl(type=plr);
>
> while I am fitting this using lme4 package as
> a<-factor(a)
> b<-factor(b)
> block<-factor(block)
>
> ModelGamma <- glmer(days~a*b+(1|block/a),family=Gamma(link = "log"))
>  lsmeans(ModelGamma,~a*b)
>
> but the results are altogether different. SAS gives 9 df while NA in R and
> least sqaure means are also different.
>
> a b   lsmean        SE      df   asymp.LCL asymp.UCL
>  1 1 3.212923 0.5677001 NA  2.100251  4.325595
>  2 1 3.229803 0.5662713 NA  2.119932  4.339675
>  3 1 3.279271 0.5688496 NA  2.164346  4.394196
>  1 2 2.499457 0.5679181 NA  1.386358  3.612556
>  2 2 3.248968 0.5659105 NA  2.139804  4.358132
>  3 2 3.563672 0.5689044 NA  2.448640  4.678705
>
> Why this happens? Please suggest.
>
> Thanks,
> Adeela
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Dec 29 06:04:54 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 29 Dec 2015 00:04:54 -0500
Subject: [R-sig-ME] different output in R and SAS for GLMM
In-Reply-To: <CABghstTee9QhttiDP21gQoapNA1OoiM_H_dqeQTcrscpm5jfwA@mail.gmail.com>
References: <CABGg3O6Jf8bB8mXVYVEMQVkrGDEeTvaDEpg+ZTYd3uuvh+MkeQ@mail.gmail.com>
	<CABghstTee9QhttiDP21gQoapNA1OoiM_H_dqeQTcrscpm5jfwA@mail.gmail.com>
Message-ID: <CABghstRFz9X0vAVevKcR1pzT0giA0JuOnFRtOgRzi5mp-D2Uvg@mail.gmail.com>

PS it looks like you're using this ... ?


On Tue, Dec 29, 2015 at 12:01 AM, Ben Bolker <bbolker at gmail.com> wrote:
> May we have a *reproducible* example please?  (All of your R code,
> plus either your data set or a similar (or smaller) data set with the
> SAS results corresponding to it ...)
>
> On Mon, Dec 28, 2015 at 11:56 PM, Adeela Munawar <adeela.uaf at gmail.com> wrote:
>> Dear all,
>>
>> I am comparing the output of SAS and R for generalized linear mixed models
>> with gamma family. Code for SAS are
>>
>> proc glimmix data=ch12_ex1 plot=residualpanel(ilink) noprofile;
>>  class block a b;
>>  model days=a|b / d=gamma;
>>  random intercept a/subject=block;
>>  lsmeans a*b / slicediff=(a b) ilink cl;
>>  covtest /cl(type=plr);
>>
>> while I am fitting this using lme4 package as
>> a<-factor(a)
>> b<-factor(b)
>> block<-factor(block)
>>
>> ModelGamma <- glmer(days~a*b+(1|block/a),family=Gamma(link = "log"))
>>  lsmeans(ModelGamma,~a*b)
>>
>> but the results are altogether different. SAS gives 9 df while NA in R and
>> least sqaure means are also different.
>>
>> a b   lsmean        SE      df   asymp.LCL asymp.UCL
>>  1 1 3.212923 0.5677001 NA  2.100251  4.325595
>>  2 1 3.229803 0.5662713 NA  2.119932  4.339675
>>  3 1 3.279271 0.5688496 NA  2.164346  4.394196
>>  1 2 2.499457 0.5679181 NA  1.386358  3.612556
>>  2 2 3.248968 0.5659105 NA  2.139804  4.358132
>>  3 2 3.563672 0.5689044 NA  2.448640  4.678705
>>
>> Why this happens? Please suggest.
>>
>> Thanks,
>> Adeela
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From stevedrd at yahoo.com  Tue Dec 29 12:14:33 2015
From: stevedrd at yahoo.com (Steve Denham)
Date: Tue, 29 Dec 2015 11:14:33 +0000 (UTC)
Subject: [R-sig-ME] different output in R and SAS for GLMM
In-Reply-To: <CABGg3O6Jf8bB8mXVYVEMQVkrGDEeTvaDEpg+ZTYd3uuvh+MkeQ@mail.gmail.com>
References: <CABGg3O6Jf8bB8mXVYVEMQVkrGDEeTvaDEpg+ZTYd3uuvh+MkeQ@mail.gmail.com>
Message-ID: <355234112.4314005.1451387673634.JavaMail.yahoo@mail.yahoo.com>

In your SAS code, try adding the option DDFM=none to the model statement to get the asymptotic estimates. ?Additionally, you probably need to change the method SAS is using to fit the model. ?Your current code uses the default pseudo-likelihood method. ?Try METHOD=laplace in the PROC GLIMMIX statement.?Steve Denham Director, Biostatistics MPI Research, Inc.
 

 
      From: Adeela Munawar <adeela.uaf at gmail.com>
 To: R-sig-mixed-models at r-project.org 
 Sent: Monday, December 28, 2015 11:56 PM
 Subject: [R-sig-ME] different output in R and SAS for GLMM
   
Dear all,

I am comparing the output of SAS and R for generalized linear mixed models
with gamma family. Code for SAS are

proc glimmix data=ch12_ex1 plot=residualpanel(ilink) noprofile;
 class block a b;
 model days=a|b / d=gamma;
 random intercept a/subject=block;
 lsmeans a*b / slicediff=(a b) ilink cl;
 covtest /cl(type=plr);

while I am fitting this using lme4 package as
a<-factor(a)
b<-factor(b)
block<-factor(block)

ModelGamma <- glmer(days~a*b+(1|block/a),family=Gamma(link = "log"))
 lsmeans(ModelGamma,~a*b)

but the results are altogether different. SAS gives 9 df while NA in R and
least sqaure means are also different.

a b? lsmean? ? ? ? SE? ? ? df? asymp.LCL asymp.UCL
 1 1 3.212923 0.5677001 NA? 2.100251? 4.325595
 2 1 3.229803 0.5662713 NA? 2.119932? 4.339675
 3 1 3.279271 0.5688496 NA? 2.164346? 4.394196
 1 2 2.499457 0.5679181 NA? 1.386358? 3.612556
 2 2 3.248968 0.5659105 NA? 2.139804? 4.358132
 3 2 3.563672 0.5689044 NA? 2.448640? 4.678705

Why this happens? Please suggest.

Thanks,
Adeela

??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


   

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Dec 30 21:21:58 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 30 Dec 2015 15:21:58 -0500
Subject: [R-sig-ME] different output in R and SAS for GLMM
In-Reply-To: <CABGg3O6Jf8bB8mXVYVEMQVkrGDEeTvaDEpg+ZTYd3uuvh+MkeQ@mail.gmail.com>
References: <CABGg3O6Jf8bB8mXVYVEMQVkrGDEeTvaDEpg+ZTYd3uuvh+MkeQ@mail.gmail.com>
Message-ID: <CABghstQTmWkWizoa_dAnHdshNrWF447V00oVfe07tJD+qXguPQ@mail.gmail.com>

On Mon, Dec 28, 2015 at 11:56 PM, Adeela Munawar <adeela.uaf at gmail.com> wrote:
> Dear all,
>
> I am comparing the output of SAS and R for generalized linear mixed models
> with gamma family. Code for SAS are
>
> proc glimmix data=ch12_ex1 plot=residualpanel(ilink) noprofile;
>  class block a b;
>  model days=a|b / d=gamma;
>  random intercept a/subject=block;
>  lsmeans a*b / slicediff=(a b) ilink cl;
>  covtest /cl(type=plr);
>
> while I am fitting this using lme4 package as
> a<-factor(a)
> b<-factor(b)
> block<-factor(block)
>
> ModelGamma <- glmer(days~a*b+(1|block/a),family=Gamma(link = "log"))
>  lsmeans(ModelGamma,~a*b)
>
> but the results are altogether different. SAS gives 9 df while NA in R and
> least sqaure means are also different.
>
> a b   lsmean        SE      df   asymp.LCL asymp.UCL
>  1 1 3.212923 0.5677001 NA  2.100251  4.325595
>  2 1 3.229803 0.5662713 NA  2.119932  4.339675
>  3 1 3.279271 0.5688496 NA  2.164346  4.394196
>  1 2 2.499457 0.5679181 NA  1.386358  3.612556
>  2 2 3.248968 0.5659105 NA  2.139804  4.358132
>  3 2 3.563672 0.5689044 NA  2.448640  4.678705
>
> Why this happens? Please suggest.


I'm assuming that your SAS results match p. 457 of Stroup's
presentation, which is where I'm guessing you took this from ...
<http://www.csulb.edu/HealthEquity/civicrm/file?reset=1&id=5&eid=26>

The first difference in the results is that R presents the results in
a *different order* (A=1,2,3,1,2,3; B=1,1,1,2,2,2).  Here are Stroup's
results (lsmean estimate only) compared with the glmer results and
from another package (glmmTMB).  There are some small differences, but
nothing that's large enough that I would worry about it much
(especially since the standard errors are much larger than the
differences betwen the different estimates).

       Stroup   glmer glmmTMB
est1 3.2565 3.2129  3.2767
est2 3.3475 3.2298  3.3680
est3 3.3100 3.2793  3.3302
est4 2.5512 2.4995  2.5716
est5 3.3603 3.2490  3.3807
est6 3.6033 3.5637  3.6237

For the second issue, about degrees of freedom -- there is a long,
long discussion about whether computing the degrees of freedom makes
much sense in the GLMM context ...


From alberto.gc8 at gmail.com  Tue Dec 29 22:09:53 2015
From: alberto.gc8 at gmail.com (Alberto Gallano)
Date: Tue, 29 Dec 2015 16:09:53 -0500
Subject: [R-sig-ME] MCMCglmm error-in-variables (total least squares) model?
Message-ID: <CAO+b4j91V-ji9Odt0MmohZMCG=saM3x9mM8uqH=SS+EkdUPdYA@mail.gmail.com>

I posted this question on Stack Overflow a week ago but received no answers:

http://stackoverflow.com/questions/34446618/bayesian-error-in-variables-total-least-squares-model-in-r-using-mcmcglmm

This may be a more appropriate venue.


I am fitting some Bayesian linear mixed models using the MCMCglmm package.
My data includes predictors that are measured with error. I'd therefore
like to build a model that takes this into account. My understanding is
that a basic mixed effects model in MCMCglmm will minimize error only for
the response variable (as in frequentist OLS regression). In other words,
vertical errors will be minimized. Instead, I'd like to minimize errors
orthogonal to the regression line/plane/hyperplane.

   1. Is it possible to fit an error-in-variables (aka total least squares)
   model using MCMCglmm or would I have to use JAGS / STAN to do this?
   2. Is it possible to do this with multiple predictors in the same model
   (I have some models with 3 or 4 predictors, each measured with error)?

	[[alternative HTML version deleted]]


From cloud.jesse7 at gmail.com  Tue Dec 29 23:03:48 2015
From: cloud.jesse7 at gmail.com (jesse cloud)
Date: Tue, 29 Dec 2015 17:03:48 -0500
Subject: [R-sig-ME] Question about lme4
Message-ID: <CAPD3YzZA+20x4_HofEO1KWty9+JKcHdY5t7urbVdiCimk11pGg@mail.gmail.com>

Hi, This is Jesse. I am very interested in your lme4 package. I hope to fit
the linear mixed model using your package. But I can only get the variance
estimates for the random effect from the output. Is that possible to get
the asymptotic variance estimates of these variance estimates?

Thank you very much.


Best,
Jesse

	[[alternative HTML version deleted]]


