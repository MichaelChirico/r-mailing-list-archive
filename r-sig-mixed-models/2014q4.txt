From ken.beath at mq.edu.au  Wed Oct  1 01:47:00 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 1 Oct 2014 09:47:00 +1000
Subject: [R-sig-ME] Fwd: [Lme4-authors] LME4 and Lmer model
In-Reply-To: <CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
Message-ID: <CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>

The BY statement in SAS has nothing to do with BLUP, it simply runs an
analysis separately for each group defined by BY. The empirical BLUP
predicts the values of the random effect for each group taking into
consideration all the data.

There is a command in SAS for extracting the random effect predictions
which I would hope gives the same results as ranef in R.

Ken

On 30 September 2014 07:19, Zhanyou Xu <zxuiowa at iastate.edu> wrote:

>  Dear Sir/Madam,
>
> We are running lmer to calculate Best Linear Unbiased prediction (BLUP),
> and we have 10 groups of data, each group has groupID and 42 individual.
> We want to get BLUP values for each individual material within each
> group. In SAS, there is a BY statement and we can get BLUP value for
> each individuals within a group. We are wondering whether there is a
> similar R code that we can calculate the BLUPs for each group similar
> like BY statement in SAS? Below is the R code we pare testing for your
> reference. Thank you very much in advance!
>
> Zhanyou
>
>
>
> ---------- Forwarded message ----------
> From: Ben Bolker <bbolker at gmail.com>
> Date: Mon, Sep 29, 2014 at 2:05 PM
> Subject: Re: [Lme4-authors] LME4 and Lmer model
> To: zhanyou.xu at syngenta.com,
> "lme4-authors at lists.r-forge.r-project.org"
> <lme4-authors at lists.r-forge.r-project.org>,
> marcia.almeida_de_macedo at syngenta.com, zxuiowa at iastate.edu,
> lme4-authors at r-forge.wu-wien.ac.at
>
>
> On 14-09-29 11:30 AM, zhanyou.xu at syngenta.com wrote:
> > Dear Ben and all LME4 authors,
> >
> > We are running lmer to calculate Best Linear Unbiased prediction (BLUP),
> > and we have 10 groups of data, each group has groupID and 42 individual.
> > We want to get BLUP values for each individual material within each
> > group. In SAS, there is a BY statement and we can get BLUP value for
> > each individuals within a group. We are wondering whether there is a
> > similar R code that we can calculate the BLUPs for each group similar
> > like by statement in SAS? Below is the R code we pare testing for your
> > reference. Thank you very much in advance!
> >
>
>
>     Take a look at ranef() and coef().  If you have further questions,
> could you please send them to r-sig-mixed-models at r-project.org ?
>
>   I can believe that "%in%" works as a nesting indicator, but it is more
> typical/I am more familiar with REPNO:HOSEID ...  (I'm also curious why
> you need to ignore the greater-than-1-level check ...)
>
>   thanks
>    Ben Bolker
>
>
> >
> > Zhanyou
> >
> >
> >
> >
> >
> > Milkvarcomp =  lmer(YGSMN~ (1|ANIMALID) + (1|HOSEID) +
> > (1|REPNO%in%HOSEID) + (1|MINRNG%in%HOSEID) +
> >
> >                 (1|MINROW%in%HOSEID)+
> > (1|ANIMALID:HOSEID),control=lmerControl(check.nlev.gtr.1="ignore"),
> > data=Stage3Data)
> >
> >
> > ------------------------------------------------------------------------
> > /This message may contain confidential information. If you are not the
> > designated recipient, please notify the sender immediately, and delete
> > the original and any copies. Any use of the message by you is
> prohibited./
> >
> >
> > _______________________________________________
> > Lme4-authors mailing list
> > Lme4-authors at lists.r-forge.r-project.org
> >
> https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/lme4-authors
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Wed Oct  1 02:15:19 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 1 Oct 2014 00:15:19 +0000 (UTC)
Subject: [R-sig-ME] Fwd: [Lme4-authors] LME4 and Lmer model
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
Message-ID: <loom.20141001T021328-466@post.gmane.org>

Ken Beath <ken.beath at ...> writes:

> 
> The BY statement in SAS has nothing to do with BLUP, it simply runs an
> analysis separately for each group defined by BY. The empirical BLUP
> predicts the values of the random effect for each group taking into
> consideration all the data.
> 
> There is a command in SAS for extracting the random effect predictions
> which I would hope gives the same results as ranef in R.
> 
> Ken
> 


  For what it's worth, in addition to the variety of different
packages that provide generic strategies for dealing with grouped data
in R (plyr::ddply, dplyr::group_by, data.table ...), lme4 has an
lmList() function (as does nlme -- they're almost but not quite
compatible/identical) for this specific task (fitting linear models
to each of a variety of groups).

  Ben Bolker


From b.pelzer at maw.ru.nl  Thu Oct  2 13:33:56 2014
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 02 Oct 2014 13:33:56 +0200
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <loom.20141001T021328-466@post.gmane.org>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>	<5429AD74.8060604@gmail.com>	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
	<loom.20141001T021328-466@post.gmane.org>
Message-ID: <542D3824.3030903@maw.ru.nl>

Dear list,

Is it possible to use the anova( ) function to compare the deviances of 
a model1 (fixed intercept) and a model2 (random intercept):

model1 <- lm (y ~ 1)
model2 <- lmer (y ~ (1|country), REML=FALSE)

In the above situation, one can use -2*LogLike(model1) and 
-2*LogLike(model2) to find both deviances, the difference of which then 
can tested. However, it would be nice if anova (model1, model2) could be 
used to this end. Is this possible somehow?

Ben.


From romunov at gmail.com  Thu Oct  2 13:38:58 2014
From: romunov at gmail.com (romunov)
Date: Thu, 2 Oct 2014 13:38:58 +0200
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <542D3824.3030903@maw.ru.nl>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
	<loom.20141001T021328-466@post.gmane.org> <542D3824.3030903@maw.ru.nl>
Message-ID: <CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>

FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.

How can I test whether a random effect is significant?

   - perhaps you shouldn't (if the random effect is part of the
   experimental design, this procedure may be considered 'sacrificial
   pseudoreplication' (Hurlburt 1984); using stepwise approaches to eliminate
   non-significant terms in order to squeeze more significance out of the
   remaining terms is dangerous in any case)
   - *do not* compare lmer models with the corresponding lm fits, or
   glmer/glm; the log-likelihoods are not commensurate (i.e., they include
   different additive terms)
   - consider using RLRsim for simple tests
   - parametric bootstrap
   - profile likelihood (using more recent versions of lme4?) to evaluate
   likelihood at ?2=0
   - keep in mind that LRT-based null hypothesis tests are conservative
   when the null value (such as ?2=0) is on the boundary of the feasible
   space; in the simplest case (single random effect variance), the p-value is
   approximately twice as large as it should be [23]



Cheers,
Roman

On Thu, Oct 2, 2014 at 1:33 PM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:

> Dear list,
>
> Is it possible to use the anova( ) function to compare the deviances of a
> model1 (fixed intercept) and a model2 (random intercept):
>
> model1 <- lm (y ~ 1)
> model2 <- lmer (y ~ (1|country), REML=FALSE)
>
> In the above situation, one can use -2*LogLike(model1) and
> -2*LogLike(model2) to find both deviances, the difference of which then can
> tested. However, it would be nice if anova (model1, model2) could be used
> to this end. Is this possible somehow?
>
> Ben.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From y.shinohara at aoni.waseda.jp  Fri Oct  3 06:22:21 2014
From: y.shinohara at aoni.waseda.jp (Yasuaki SHINOHARA)
Date: Fri, 03 Oct 2014 13:22:21 +0900
Subject: [R-sig-ME] Model comparisons
Message-ID: <web-46337392@besv05.spw.secure-premium.ne.jp>

Dear all,

Could I ask a very basic question about glmer?
I am wondering how important using the best-fitting model is.

(1)
Please imagine I have three fixed factors "A", "B" and "C" in a
logistic mixed effects model.
I want to test these main effects and their all possible interactions.
However, I can include another factor "D" (e.g., age) in which I am
not interested. If I include the fixed factor "D" in
the model, the model fits significantly better than the model
without the factor "D".
I know I should use the best-fitting model, and report all the results
including the factor "D", although the results are slightly different
from the model which does not include the factor "D".
However, I also think that including unnecessary factors would
distract readers from the main point, so it may be good to analyze
data without the factor "D".
Could I ask your opinions?

(2)
Also, I do not understand why the results are so different, if I
change the relation in one of the factors.
For example, the model including the fixed factors of "A","B","C" and
"log(age)" is significantly better than another model including the
fixed factors of "A","B","C" and "poly(age,2)".
This difference (log(age) vs. poly(age,2)) affects the results of
other factors of "A", "B" and "C" as below.
Could you please explain why?
In terms of AIC value, MODEL1 is better. However, the results of
MODEL1 do not look correct.
Why is it?

MODEL1<-glmer(binomial_response~A*B*log(age)+(1|X)+(1+B|Y)+(1+B|Z),
family=binomial, 
data=ALLDATA,control=glmerControl(optimizer="bobyqa"))
MODEL2<-glmer(binomial_response~A*B*poly(age,2)+(1|X)+(1+B|Y)+(1+B|Z),
family=binomial, 
data=ALLDATA,control=glmerControl(optimizer="bobyqa"))

> Anova(MODEL1,type=3)
Analysis of Deviance Table (Type III Wald chisquare tests)

Response: prod_corr
                        Chisq Df Pr(>Chisq)
(Intercept)           0.8155  1   0.366503
A                0.0059  1   0.938896
B                 0.7490  1   0.386791
log(age)              8.6887  1   0.003202 **
A:B          0.0044  1   0.947053
A:log(age)       0.2471  1   0.619110
B:log(age)        2.5704  1   0.108881
A:B:log(age) 0.4881  1   0.484767
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Anova(MODEL2, type=3)
Analysis of Deviance Table (Type III Wald chisquare tests)

Response: prod_corr
                             Chisq Df Pr(>Chisq)
(Intercept)               41.2696  1  1.326e-10 ***
A                     6.4384  1  0.0111677 *
B                     13.0042  1  0.0003108 ***
poly(age, 2)              14.2490  2  0.0008051 ***
A:B              14.2547  1  0.0001597 ***
A:poly(age, 2)        1.1039  2  0.5758358
B:poly(age, 2)         3.2066  2  0.2012318
A:B:poly(age, 2)  0.3203  2  0.8520201
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Best wishes,
Yasu


From Thierry.ONKELINX at inbo.be  Fri Oct  3 10:20:31 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 3 Oct 2014 08:20:31 +0000
Subject: [R-sig-ME] Model comparisons
In-Reply-To: <web-46337392@besv05.spw.secure-premium.ne.jp>
References: <web-46337392@besv05.spw.secure-premium.ne.jp>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AF9CDD@inbomail.inbo.be>

Dear Yasu,

It looks like your response is age dependent. Therefore you should include age into the model, so the model can take the age effect into account.

I prefer to take a look at the functional relationship between age and the response (in the logit scale). There is probabily some literature on the effect of age on the response. That will give you more information on which function to choose: log(age) or poly(age, 2).

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] namens Yasuaki SHINOHARA [y.shinohara at aoni.waseda.jp]
Verzonden: vrijdag 3 oktober 2014 6:22
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Model comparisons

Dear all,

Could I ask a very basic question about glmer?
I am wondering how important using the best-fitting model is.

(1)
Please imagine I have three fixed factors "A", "B" and "C" in a
logistic mixed effects model.
I want to test these main effects and their all possible interactions.
However, I can include another factor "D" (e.g., age) in which I am
not interested. If I include the fixed factor "D" in
the model, the model fits significantly better than the model
without the factor "D".
I know I should use the best-fitting model, and report all the results
including the factor "D", although the results are slightly different
from the model which does not include the factor "D".
However, I also think that including unnecessary factors would
distract readers from the main point, so it may be good to analyze
data without the factor "D".
Could I ask your opinions?

(2)
Also, I do not understand why the results are so different, if I
change the relation in one of the factors.
For example, the model including the fixed factors of "A","B","C" and
"log(age)" is significantly better than another model including the
fixed factors of "A","B","C" and "poly(age,2)".
This difference (log(age) vs. poly(age,2)) affects the results of
other factors of "A", "B" and "C" as below.
Could you please explain why?
In terms of AIC value, MODEL1 is better. However, the results of
MODEL1 do not look correct.
Why is it?

MODEL1<-glmer(binomial_response~A*B*log(age)+(1|X)+(1+B|Y)+(1+B|Z),
family=binomial,
data=ALLDATA,control=glmerControl(optimizer="bobyqa"))
MODEL2<-glmer(binomial_response~A*B*poly(age,2)+(1|X)+(1+B|Y)+(1+B|Z),
family=binomial,
data=ALLDATA,control=glmerControl(optimizer="bobyqa"))

> Anova(MODEL1,type=3)
Analysis of Deviance Table (Type III Wald chisquare tests)

Response: prod_corr
                        Chisq Df Pr(>Chisq)
(Intercept)           0.8155  1   0.366503
A                0.0059  1   0.938896
B                 0.7490  1   0.386791
log(age)              8.6887  1   0.003202 **
A:B          0.0044  1   0.947053
A:log(age)       0.2471  1   0.619110
B:log(age)        2.5704  1   0.108881
A:B:log(age) 0.4881  1   0.484767
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Anova(MODEL2, type=3)
Analysis of Deviance Table (Type III Wald chisquare tests)

Response: prod_corr
                             Chisq Df Pr(>Chisq)
(Intercept)               41.2696  1  1.326e-10 ***
A                     6.4384  1  0.0111677 *
B                     13.0042  1  0.0003108 ***
poly(age, 2)              14.2490  2  0.0008051 ***
A:B              14.2547  1  0.0001597 ***
A:poly(age, 2)        1.1039  2  0.5758358
B:poly(age, 2)         3.2066  2  0.2012318
A:B:poly(age, 2)  0.3203  2  0.8520201
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Best wishes,
Yasu

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bbolker at gmail.com  Sat Oct  4 01:06:18 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 3 Oct 2014 23:06:18 +0000 (UTC)
Subject: [R-sig-ME] anova (lm, lmer ) question
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
	<loom.20141001T021328-466@post.gmane.org>
	<542D3824.3030903@maw.ru.nl>
	<CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>
Message-ID: <loom.20141004T005909-719@post.gmane.org>

romunov <romunov at ...> writes:

> 
> FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.
> 
> How can I test whether a random effect is significant?
> 

  ...

>    - *do not* compare lmer models with the corresponding lm fits, or
>    glmer/glm; the log-likelihoods are not commensurate (i.e., they include
>    different additive terms)

  For what it's worth, I believe this is out of date, _except_ for 
glmer fits with nAGQ>1.  It should be possible to implement
anova(<merMod>,<lm>/<glm>) -- it's only a nuisance (sadly, if we
were still using S4 classes at this level it would be easier ...)

  Ben Bolker


From ken.beath at mq.edu.au  Sat Oct  4 02:38:12 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sat, 4 Oct 2014 10:38:12 +1000
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <loom.20141004T005909-719@post.gmane.org>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
	<loom.20141001T021328-466@post.gmane.org>
	<542D3824.3030903@maw.ru.nl>
	<CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>
	<loom.20141004T005909-719@post.gmane.org>
Message-ID: <CAF5_5cwm5FQ_qxLK9ZM2=RVVv9jMRTawzVhksycWGJ3uusrsyg@mail.gmail.com>

nAGQ=1 and greater than 1 give different results, and the nAGQ=1 matches
fairly closely the log likelihood from Stata for 3 quadrature points, so
presumably is correct. Stata's Laplace didn't converge with my data.


Ken



On 4 October 2014 09:06, Ben Bolker <bbolker at gmail.com> wrote:

> romunov <romunov at ...> writes:
>
> >
> > FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.
> >
> > How can I test whether a random effect is significant?
> >
>
>   ...
>
> >    - *do not* compare lmer models with the corresponding lm fits, or
> >    glmer/glm; the log-likelihoods are not commensurate (i.e., they
> include
> >    different additive terms)
>
>   For what it's worth, I believe this is out of date, _except_ for
> glmer fits with nAGQ>1.  It should be possible to implement
> anova(<merMod>,<lm>/<glm>) -- it's only a nuisance (sadly, if we
> were still using S4 classes at this level it would be easier ...)
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Sat Oct  4 02:48:27 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 3 Oct 2014 20:48:27 -0400
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <CAF5_5cwm5FQ_qxLK9ZM2=RVVv9jMRTawzVhksycWGJ3uusrsyg@mail.gmail.com>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
	<loom.20141001T021328-466@post.gmane.org>
	<542D3824.3030903@maw.ru.nl>
	<CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>
	<loom.20141004T005909-719@post.gmane.org>
	<CAF5_5cwm5FQ_qxLK9ZM2=RVVv9jMRTawzVhksycWGJ3uusrsyg@mail.gmail.com>
Message-ID: <CABghstQ=U+Y_9+wCEEDofvw0Mgj+KJ_GbmPG1oscDL1wOLryQA@mail.gmail.com>

Thanks for checking.  The comparison with Stata isn't necessarily relevant
though -- or question is whether `lm` and `lmer` (or `glm` and `glmer`)
include/exclude the same additive constants, so that their log-likelihoods
are directly comparable.

On Fri, Oct 3, 2014 at 8:38 PM, Ken Beath <ken.beath at mq.edu.au> wrote:

> nAGQ=1 and greater than 1 give different results, and the nAGQ=1 matches
> fairly closely the log likelihood from Stata for 3 quadrature points, so
> presumably is correct. Stata's Laplace didn't converge with my data.
>
>
> Ken
>
>
>
> On 4 October 2014 09:06, Ben Bolker <bbolker at gmail.com> wrote:
>
>> romunov <romunov at ...> writes:
>>
>> >
>> > FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.
>> >
>> > How can I test whether a random effect is significant?
>> >
>>
>>   ...
>>
>> >    - *do not* compare lmer models with the corresponding lm fits, or
>> >    glmer/glm; the log-likelihoods are not commensurate (i.e., they
>> include
>> >    different additive terms)
>>
>>   For what it's worth, I believe this is out of date, _except_ for
>> glmer fits with nAGQ>1.  It should be possible to implement
>> anova(<merMod>,<lm>/<glm>) -- it's only a nuisance (sadly, if we
>> were still using S4 classes at this level it would be easier ...)
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:11}}


From tina.wey at gmail.com  Sat Oct  4 09:39:05 2014
From: tina.wey at gmail.com (Tina Wey)
Date: Sat, 4 Oct 2014 07:39:05 +0000
Subject: [R-sig-ME] From: Tina Wey
Message-ID: <r8h9mfd1p7w4garky894znwf.14124083453587@email.android.com>


Hi


http://vsiversloparamoscentras.com/dry.php?pretty=rfvkcedqb3199zcpsdww


tina.wey at gmail.com


From zxuiowa at iastate.edu  Wed Oct  1 02:05:53 2014
From: zxuiowa at iastate.edu (Zhanyou Xu)
Date: Tue, 30 Sep 2014 19:05:53 -0500
Subject: [R-sig-ME] Fwd: [Lme4-authors] LME4 and Lmer model
In-Reply-To: <CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
Message-ID: <CAExDaCLxmEaMR4nxPvHFXRyta6vhwnBqioa8HLUhC5_CGXFq2Q@mail.gmail.com>

thanks for your quick response.

what we want to do is:
1: to calculate the BLUP for each individual within each group; and
2: to calculate the BLUP across  all groups.

Is there a way to do so just like the BY statement in SAS?

Thanks,

Zhanyou


On Tue, Sep 30, 2014 at 6:47 PM, Ken Beath <ken.beath at mq.edu.au> wrote:
> The BY statement in SAS has nothing to do with BLUP, it simply runs an
> analysis separately for each group defined by BY. The empirical BLUP
> predicts the values of the random effect for each group taking into
> consideration all the data.
>
> There is a command in SAS for extracting the random effect predictions which
> I would hope gives the same results as ranef in R.
>
> Ken
>
> On 30 September 2014 07:19, Zhanyou Xu <zxuiowa at iastate.edu> wrote:
>>
>>  Dear Sir/Madam,
>>
>> We are running lmer to calculate Best Linear Unbiased prediction (BLUP),
>> and we have 10 groups of data, each group has groupID and 42 individual.
>> We want to get BLUP values for each individual material within each
>> group. In SAS, there is a BY statement and we can get BLUP value for
>> each individuals within a group. We are wondering whether there is a
>> similar R code that we can calculate the BLUPs for each group similar
>> like BY statement in SAS? Below is the R code we pare testing for your
>> reference. Thank you very much in advance!
>>
>> Zhanyou
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Ben Bolker <bbolker at gmail.com>
>> Date: Mon, Sep 29, 2014 at 2:05 PM
>> Subject: Re: [Lme4-authors] LME4 and Lmer model
>> To: zhanyou.xu at syngenta.com,
>> "lme4-authors at lists.r-forge.r-project.org"
>> <lme4-authors at lists.r-forge.r-project.org>,
>> marcia.almeida_de_macedo at syngenta.com, zxuiowa at iastate.edu,
>> lme4-authors at r-forge.wu-wien.ac.at
>>
>>
>> On 14-09-29 11:30 AM, zhanyou.xu at syngenta.com wrote:
>> > Dear Ben and all LME4 authors,
>> >
>> > We are running lmer to calculate Best Linear Unbiased prediction (BLUP),
>> > and we have 10 groups of data, each group has groupID and 42 individual.
>> > We want to get BLUP values for each individual material within each
>> > group. In SAS, there is a BY statement and we can get BLUP value for
>> > each individuals within a group. We are wondering whether there is a
>> > similar R code that we can calculate the BLUPs for each group similar
>> > like by statement in SAS? Below is the R code we pare testing for your
>> > reference. Thank you very much in advance!
>> >
>>
>>
>>     Take a look at ranef() and coef().  If you have further questions,
>> could you please send them to r-sig-mixed-models at r-project.org ?
>>
>>   I can believe that "%in%" works as a nesting indicator, but it is more
>> typical/I am more familiar with REPNO:HOSEID ...  (I'm also curious why
>> you need to ignore the greater-than-1-level check ...)
>>
>>   thanks
>>    Ben Bolker
>>
>>
>> >
>> > Zhanyou
>> >
>> >
>> >
>> >
>> >
>> > Milkvarcomp =  lmer(YGSMN~ (1|ANIMALID) + (1|HOSEID) +
>> > (1|REPNO%in%HOSEID) + (1|MINRNG%in%HOSEID) +
>> >
>> >                 (1|MINROW%in%HOSEID)+
>> > (1|ANIMALID:HOSEID),control=lmerControl(check.nlev.gtr.1="ignore"),
>> > data=Stage3Data)
>> >
>> >
>> > ------------------------------------------------------------------------
>> > /This message may contain confidential information. If you are not the
>> > designated recipient, please notify the sender immediately, and delete
>> > the original and any copies. Any use of the message by you is
>> > prohibited./
>> >
>> >
>> > _______________________________________________
>> > Lme4-authors mailing list
>> > Lme4-authors at lists.r-forge.r-project.org
>> >
>> > https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/lme4-authors
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
>
> Ken Beath
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:8}}


From nvillasenor at gmail.com  Thu Oct  2 10:56:49 2014
From: nvillasenor at gmail.com (=?UTF-8?Q?Nelida_Villase=C3=B1or?=)
Date: Thu, 2 Oct 2014 18:56:49 +1000
Subject: [R-sig-ME] Model selection GLM vs. GLMMs
Message-ID: <CAEOdAtH7wEHre_tK+J5-gKKkp37PGtvmh-z-XcYOhsM3OBz4Uw@mail.gmail.com>

Thanks Ben.

On: "I think you would find a bit of disagreement among experts about
the best procedure -- whether it would be to drop random effects until
you got a sensible non-singular fit, or to keep them in even though
they're singular"

Could you please suggest me some references supporting each of these procedures?

Cheers,
Nelida.


> Message: 1
> Date: Mon, 21 Apr 2014 00:15:04 +0000 (UTC)
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Model selection GLM vs. GLMMs
> Message-ID: <loom.20140421T020951-335 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
>
> Nelida Villasenor <nelida.villasenor at ...> writes:
>
>>
>> Dear all,
>
>> I'm performing model selection based on AICc on a set of GLMMs that
>> only vary in their fixed effects. The data comes from 12 transects
>> (5 measures along each transect), then each transect is modelled as
>> a random effect "+(1|transect)". As the response variable was
>> proportions (presences/n), I fitted the models using binomial family
>> and the total number of points (n) as weights.
>
>> Given that some models had boundary problems
>
>   meaning singular fits (estimated zero variances and/or +/- 1 correlations
> and/or values of estimated theta=0) ?
>
>> I ran the model
>> selection on a set of GLMs instead of GLMMs. The results were almost
>> identical in terms of the list of models with the highest support
>> (for 7 response variables where model selection was performed
>> independently).
>
>> I'm wondering which approach is correct? Or, as my results show, it
>> does not really matter, because the random effect does not change in
>> my GLMMs?
>
>   I think you would find a bit of disagreement among experts about the
> best procedure -- whether it would be to drop random effects until you
> got a sensible non-singular fit, or to keep them in even though
> they're singular.  Keep in mind that you should get the same estimates
> with a GLM or a GLMM if the variance estimates are all zero ... Since
> it doesn't sound as though it affects your einference/model selection
> on the fixed effects, I would say you could choose either approach
> (and explain clearly what you did).
>
>   Ben Bolker


-- 
N?lida R. Villase?or
PhD Scholar
Fenner School of Environment and Society
The Australian National University


From b.pelzer at maw.ru.nl  Sat Oct  4 16:13:03 2014
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Sat, 04 Oct 2014 16:13:03 +0200
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <CABghstQ=U+Y_9+wCEEDofvw0Mgj+KJ_GbmPG1oscDL1wOLryQA@mail.gmail.com>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>	<5429AD74.8060604@gmail.com>	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>	<loom.20141001T021328-466@post.gmane.org>	<542D3824.3030903@maw.ru.nl>	<CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>	<loom.20141004T005909-719@post.gmane.org>	<CAF5_5cwm5FQ_qxLK9ZM2=RVVv9jMRTawzVhksycWGJ3uusrsyg@mail.gmail.com>
	<CABghstQ=U+Y_9+wCEEDofvw0Mgj+KJ_GbmPG1oscDL1wOLryQA@mail.gmail.com>
Message-ID: <5430006F.9010004@maw.ru.nl>

Dear romunov, Ben and Ken,

Thanks for your replies. From these I conclude that:
- for linear (lmer vs. lm) models there's no problem in using the 
deviance difference
- for generalized  linear models (glmer vs. glm) it's ok to use the 
deviance difference as long as nAGQ=1.
Would you agree with me? Best regards,

Ben.

On 4-10-2014 2:48, Ben Bolker wrote:
> Thanks for checking.  The comparison with Stata isn't necessarily relevant
> though -- or question is whether `lm` and `lmer` (or `glm` and `glmer`)
> include/exclude the same additive constants, so that their log-likelihoods
> are directly comparable.
>
> On Fri, Oct 3, 2014 at 8:38 PM, Ken Beath <ken.beath at mq.edu.au> wrote:
>
>> nAGQ=1 and greater than 1 give different results, and the nAGQ=1 matches
>> fairly closely the log likelihood from Stata for 3 quadrature points, so
>> presumably is correct. Stata's Laplace didn't converge with my data.
>>
>>
>> Ken
>>
>>
>>
>> On 4 October 2014 09:06, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> romunov <romunov at ...> writes:
>>>
>>>> FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.
>>>>
>>>> How can I test whether a random effect is significant?
>>>>
>>>    ...
>>>
>>>>     - *do not* compare lmer models with the corresponding lm fits, or
>>>>     glmer/glm; the log-likelihoods are not commensurate (i.e., they
>>> include
>>>>     different additive terms)
>>>    For what it's worth, I believe this is out of date, _except_ for
>>> glmer fits with nAGQ>1.  It should be possible to implement
>>> anova(<merMod>,<lm>/<glm>) -- it's only a nuisance (sadly, if we
>>> were still using S4 classes at this level it would be easier ...)
>>>
>>>    Ben Bolker
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and m...{{dropped:11}}
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From y.shinohara at aoni.waseda.jp  Sat Oct  4 16:54:15 2014
From: y.shinohara at aoni.waseda.jp (Yasuaki SHINOHARA)
Date: Sat, 04 Oct 2014 23:54:15 +0900
Subject: [R-sig-ME] Model comparisons
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AF9CDD@inbomail.inbo.be>
References: <web-46337392@besv05.spw.secure-premium.ne.jp>
	<AA818EAD2576BC488B4F623941DA7427F3AF9CDD@inbomail.inbo.be>
Message-ID: <web-46121929@besv02.spw.secure-premium.ne.jp>

Dear Thierry,

Thank you very much for your help.
Actually, the first and second questions were not talking about the 
same model.
For the first question, the fixed factor of age was just an example, 
and the results below are not related to the first question.
I was not sure whether I should include a fixed factor of which I am 
not reporting the results in a paper, if the model with the factor 
fits significantly better than the model without the factor.
Do you mean that I should include it, if it has a significant effect, 
although I am not reporting the result of the factor?

For the second question, the aim of my research is to investigate the 
age effects.
I wanted to test how training works for speaker's production, and 
whether there is an age effect on it.
So the factor A is "Group" (training group vs. control group), and the 
factor B is "Testing Block" (pre-training vs. post-training)
I am trying to find some literature about how the age related to the 
improvement made by training, but it is really hard to find.
I am not sure how I can send a figure of the relationship between age 
and the response through this emailing list. Sorry.

Anyway, thank you very much for your help.

Best wishes,
Yasu




  about whether I should include a fixed factor in a logistic mixed 
effects model or not,
On Fri, 3 Oct 2014 08:20:31 +0000
  "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:
> Dear Yasu,
> 
> It looks like your response is age dependent. Therefore you should 
>include age into the model, so the model can take the age effect into 
>account.
> 
> I prefer to take a look at the functional relationship between age 
>and the response (in the logit scale). There is probabily some 
>literature on the effect of age on the response. That will give you 
>more information on which function to choose: log(age) or poly(age, 
>2).
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for 
>Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
>Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> To call in the statistician after the experiment is done may be no 
>more than asking him to perform a post-mortem examination: he may be 
>able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
>not ensure that a reasonable answer can be extracted from a given 
>body of data. ~ John Tukey
> 
> ________________________________________
> Van: r-sig-mixed-models-bounces at r-project.org 
>[r-sig-mixed-models-bounces at r-project.org] namens Yasuaki SHINOHARA 
>[y.shinohara at aoni.waseda.jp]
> Verzonden: vrijdag 3 oktober 2014 6:22
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Model comparisons
> 
> Dear all,
> 
> Could I ask a very basic question about glmer?
> I am wondering how important using the best-fitting model is.
> 
> (1)
> Please imagine I have three fixed factors "A", "B" and "C" in a
> logistic mixed effects model.
> I want to test these main effects and their all possible 
>interactions.
> However, I can include another factor "D" (e.g., age) in which I am
> not interested. If I include the fixed factor "D" in
> the model, the model fits significantly better than the model
> without the factor "D".
> I know I should use the best-fitting model, and report all the 
>results
> including the factor "D", although the results are slightly 
>different
> from the model which does not include the factor "D".
> However, I also think that including unnecessary factors would
> distract readers from the main point, so it may be good to analyze
> data without the factor "D".
> Could I ask your opinions?
> 
> (2)
> Also, I do not understand why the results are so different, if I
> change the relation in one of the factors.
>For example, the model including the fixed factors of "A","B","C" and
> "log(age)" is significantly better than another model including the
> fixed factors of "A","B","C" and "poly(age,2)".
> This difference (log(age) vs. poly(age,2)) affects the results of
> other factors of "A", "B" and "C" as below.
> Could you please explain why?
> In terms of AIC value, MODEL1 is better. However, the results of
> MODEL1 do not look correct.
> Why is it?
> 
> MODEL1<-glmer(binomial_response~A*B*log(age)+(1|X)+(1+B|Y)+(1+B|Z),
> family=binomial,
> data=ALLDATA,control=glmerControl(optimizer="bobyqa"))
> MODEL2<-glmer(binomial_response~A*B*poly(age,2)+(1|X)+(1+B|Y)+(1+B|Z),
> family=binomial,
> data=ALLDATA,control=glmerControl(optimizer="bobyqa"))
> 
>> Anova(MODEL1,type=3)
> Analysis of Deviance Table (Type III Wald chisquare tests)
> 
> Response: prod_corr
>                        Chisq Df Pr(>Chisq)
> (Intercept)           0.8155  1   0.366503
> A                0.0059  1   0.938896
> B                 0.7490  1   0.386791
> log(age)              8.6887  1   0.003202 **
> A:B          0.0044  1   0.947053
> A:log(age)       0.2471  1   0.619110
> B:log(age)        2.5704  1   0.108881
> A:B:log(age) 0.4881  1   0.484767
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> Anova(MODEL2, type=3)
> Analysis of Deviance Table (Type III Wald chisquare tests)
> 
> Response: prod_corr
>                             Chisq Df Pr(>Chisq)
> (Intercept)               41.2696  1  1.326e-10 ***
> A                     6.4384  1  0.0111677 *
> B                     13.0042  1  0.0003108 ***
> poly(age, 2)              14.2490  2  0.0008051 ***
> A:B              14.2547  1  0.0001597 ***
> A:poly(age, 2)        1.1039  2  0.5758358
> B:poly(age, 2)         3.2066  2  0.2012318
> A:B:poly(age, 2)  0.3203  2  0.8520201
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> Best wishes,
> Yasu
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * 
>* *
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
>schrijver weer en binden het INBO onder geen enkel beding, zolang dit 
>bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those 
>of the writer and may not be regarded as stating an official position 
>of INBO, as long as the message is not confirmed by a duly signed 
>document.


************************************
Yasuaki SHINOHARA, Ph.D.
Assistant Professor
Center for English Language Education (CELESE)
Waseda University Faculty of Science and Engineering
3-4-1 Okubo, Shinjuku-ku, 169-8555, Tokyo JAPAN
email: y.shinohara at aoni.waseda.jp


From bbolker at gmail.com  Sun Oct  5 21:04:58 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 05 Oct 2014 15:04:58 -0400
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <5430006F.9010004@maw.ru.nl>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>	<5429AD74.8060604@gmail.com>	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>	<loom.20141001T021328-466@post.gmane.org>	<542D3824.3030903@maw.ru.nl>	<CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>	<loom.20141004T005909-719@post.gmane.org>	<CAF5_5cwm5FQ_qxLK9ZM2=RVVv9jMRTawzVhksycWGJ3uusrsyg@mail.gmail.com>	<CABghstQ=U+Y_9+wCEEDofvw0Mgj+KJ_GbmPG1oscDL1wOLryQA@mail.gmail.com>
	<5430006F.9010004@maw.ru.nl>
Message-ID: <5431965A.7010803@gmail.com>

On 14-10-04 10:13 AM, Ben Pelzer wrote:
> Dear romunov, Ben and Ken,
> 
> Thanks for your replies. From these I conclude that:
> - for linear (lmer vs. lm) models there's no problem in using the
> deviance difference
> - for generalized  linear models (glmer vs. glm) it's ok to use the
> deviance difference as long as nAGQ=1.
> Would you agree with me? Best regards,
> 
> Ben.


  Yes, I believe so, but you might want to check the archives.  I think
I've posted examples to this effect in the past.  (The way to
double-check this would either be to set up an example where the RE
variance was estimated as exactly zero (e.g. a small/noisy data set with
a small number of levels of the grouping variable), or to extract the
deviance function via devFunOnly=TRUE and force the random effects to
zero -- for lmer this is trivial since the fixed effects estimates are
profiled out; for glmer you would have to put the deviance function
inside a wrapper function that set the variance parameters to zero while
filling in specified values for the fixed effects, and optimize over
this function ...)

  Ben Bolker

> 
> On 4-10-2014 2:48, Ben Bolker wrote:
>> Thanks for checking.  The comparison with Stata isn't necessarily
>> relevant
>> though -- or question is whether `lm` and `lmer` (or `glm` and `glmer`)
>> include/exclude the same additive constants, so that their
>> log-likelihoods
>> are directly comparable.
>>
>> On Fri, Oct 3, 2014 at 8:38 PM, Ken Beath <ken.beath at mq.edu.au> wrote:
>>
>>> nAGQ=1 and greater than 1 give different results, and the nAGQ=1 matches
>>> fairly closely the log likelihood from Stata for 3 quadrature points, so
>>> presumably is correct. Stata's Laplace didn't converge with my data.
>>>
>>>
>>> Ken
>>>
>>>
>>>
>>> On 4 October 2014 09:06, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>> romunov <romunov at ...> writes:
>>>>
>>>>> FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.
>>>>>
>>>>> How can I test whether a random effect is significant?
>>>>>
>>>>    ...
>>>>
>>>>>     - *do not* compare lmer models with the corresponding lm fits, or
>>>>>     glmer/glm; the log-likelihoods are not commensurate (i.e., they
>>>> include
>>>>>     different additive terms)
>>>>    For what it's worth, I believe this is out of date, _except_ for
>>>> glmer fits with nAGQ>1.  It should be possible to implement
>>>> anova(<merMod>,<lm>/<glm>) -- it's only a nuisance (sadly, if we
>>>> were still using S4 classes at this level it would be easier ...)
>>>>
>>>>    Ben Bolker
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> -- 
>>>
>>> *Ken Beath*
>>> Lecturer
>>> Statistics Department
>>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>>
>>> Phone: +61 (0)2 9850 8516
>>>
>>> Building E4A, room 526
>>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>>
>>> CRICOS Provider No 00002J
>>> This message is intended for the addressee named and m...{{dropped:11}}
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Sun Oct  5 21:32:49 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 5 Oct 2014 19:32:49 +0000 (UTC)
Subject: [R-sig-ME] Model selection GLM vs. GLMMs
References: <CAEOdAtH7wEHre_tK+J5-gKKkp37PGtvmh-z-XcYOhsM3OBz4Uw@mail.gmail.com>
Message-ID: <loom.20141005T212425-683@post.gmane.org>

Nelida Villase?or <nvillasenor at ...> writes:

> 
> Thanks Ben.
> 
> On: "I think you would find a bit of disagreement among experts about
> the best procedure -- whether it would be to drop random effects until
> you got a sensible non-singular fit, or to keep them in even though
> they're singular"
> 
> Could you please suggest me some references supporting each of these
procedures?
> 
> Cheers,
> Nelida.
> 

  I believe Barr et al (2013) has become the canonical reference
for "put everything in the model".  Doug Bates has mentioned to
me that he was working on a response, with some co-authors,
that disagrees with Barr et al.; perhaps he will chime in on
its status.  I have a book chapter in press
(Fox, G. Negrete-Yankelevich, S. and Sosa, V. (Eds.) Ecological Statistics:
from principles to application. Oxford University Press) that discusses
this issue.  

  Suggestions from the rest of the community are welcome, as always.
 
  Ben Bolker


From bbolker at gmail.com  Mon Oct  6 00:11:00 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 5 Oct 2014 22:11:00 +0000 (UTC)
Subject: [R-sig-ME] Model selection GLM vs. GLMMs
References: <CAEOdAtH7wEHre_tK+J5-gKKkp37PGtvmh-z-XcYOhsM3OBz4Uw@mail.gmail.com>
	<loom.20141005T212425-683@post.gmane.org>
Message-ID: <loom.20141006T001004-703@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Nelida Villase?or <nvillasenor <at> ...> writes:
> 
> > On: "I think you would find a bit of disagreement among experts about
> > the best procedure -- whether it would be to drop random effects until
> > you got a sensible non-singular fit, or to keep them in even though
> > they're singular"
> > 
> > Could you please suggest me some references supporting each of these
> procedures?

  Some relevant recent discussion: http://andrewgelman.com/2014/10/05/
 anova-great-interpret-way-structuring-model-focus-f-tests/#comment-193691

[broken URL and snipped lots of context to make Gmane happy ...]


From Thierry.ONKELINX at inbo.be  Mon Oct  6 10:41:19 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 6 Oct 2014 08:41:19 +0000
Subject: [R-sig-ME] Model comparisons
In-Reply-To: <web-46121929@besv02.spw.secure-premium.ne.jp>
References: <web-46337392@besv05.spw.secure-premium.ne.jp>
	<AA818EAD2576BC488B4F623941DA7427F3AF9CDD@inbomail.inbo.be>
	<web-46121929@besv02.spw.secure-premium.ne.jp>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AFA332@inbomail.inbo.be>

Dear Yasu,

IMHO, a model must make sense. Assume you know a priori that a certain variable "D" has an important effect on the response, but your focus is on other variables. Then you have two options: A) use a design that tests everything at the same level of "D". Then the effect of "D" is constant in the design and can be ignored. B) Measure "D" and add it to the model. You will have to report the effect of "D", although not as elaborate as the variables you're focusing on.

If you don't find any literature on the relation with age, then try to thing what kind of relation could make sense. Is it monotone? Is there an optimum? Has adding 1 unit of age the same effect regardless the age? ... Bottom-line: rather choose a meaningful function, than the function which gives the lowest AIC.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Yasuaki SHINOHARA
Verzonden: zaterdag 4 oktober 2014 16:54
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Model comparisons

Dear Thierry,

Thank you very much for your help.
Actually, the first and second questions were not talking about the same model.
For the first question, the fixed factor of age was just an example, and the results below are not related to the first question.
I was not sure whether I should include a fixed factor of which I am not reporting the results in a paper, if the model with the factor fits significantly better than the model without the factor.
Do you mean that I should include it, if it has a significant effect, although I am not reporting the result of the factor?

For the second question, the aim of my research is to investigate the age effects.
I wanted to test how training works for speaker's production, and whether there is an age effect on it.
So the factor A is "Group" (training group vs. control group), and the factor B is "Testing Block" (pre-training vs. post-training) I am trying to find some literature about how the age related to the improvement made by training, but it is really hard to find.
I am not sure how I can send a figure of the relationship between age and the response through this emailing list. Sorry.

Anyway, thank you very much for your help.

Best wishes,
Yasu




  about whether I should include a fixed factor in a logistic mixed effects model or not, On Fri, 3 Oct 2014 08:20:31 +0000
  "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:
> Dear Yasu,
>
> It looks like your response is age dependent. Therefore you should
>include age into the model, so the model can take the age effect into
>account.
>
> I prefer to take a look at the functional relationship between age and
>the response (in the logit scale). There is probabily some literature
>on the effect of age on the response. That will give you more
>information on which function to choose: log(age) or poly(age, 2).
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>and Forest  team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>Assurance  Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> To call in the statistician after the experiment is done may be no
>more than asking him to perform a post-mortem examination: he may be
>able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>The plural of anecdote is not data. ~ Roger Brinner  The combination of
>some data and an aching desire for an answer does not ensure that a
>reasonable answer can be extracted from a given body of data. ~ John
>Tukey
>
> ________________________________________
> Van: r-sig-mixed-models-bounces at r-project.org
>[r-sig-mixed-models-bounces at r-project.org] namens Yasuaki SHINOHARA
>[y.shinohara at aoni.waseda.jp]
> Verzonden: vrijdag 3 oktober 2014 6:22
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Model comparisons
>
> Dear all,
>
> Could I ask a very basic question about glmer?
> I am wondering how important using the best-fitting model is.
>
> (1)
> Please imagine I have three fixed factors "A", "B" and "C" in a
>logistic mixed effects model.
> I want to test these main effects and their all possible interactions.
> However, I can include another factor "D" (e.g., age) in which I am
>not interested. If I include the fixed factor "D" in  the model, the
>model fits significantly better than the model  without the factor "D".
> I know I should use the best-fitting model, and report all the results
>including the factor "D", although the results are slightly different
>from the model which does not include the factor "D".
> However, I also think that including unnecessary factors would
>distract readers from the main point, so it may be good to analyze
>data without the factor "D".
> Could I ask your opinions?
>
> (2)
> Also, I do not understand why the results are so different, if I
>change the relation in one of the factors.
>For example, the model including the fixed factors of "A","B","C" and
>"log(age)" is significantly better than another model including the
>fixed factors of "A","B","C" and "poly(age,2)".
> This difference (log(age) vs. poly(age,2)) affects the results of
>other factors of "A", "B" and "C" as below.
> Could you please explain why?
> In terms of AIC value, MODEL1 is better. However, the results of
> MODEL1 do not look correct.
> Why is it?
>
> MODEL1<-glmer(binomial_response~A*B*log(age)+(1|X)+(1+B|Y)+(1+B|Z),
> family=binomial,
> data=ALLDATA,control=glmerControl(optimizer="bobyqa"))
> MODEL2<-glmer(binomial_response~A*B*poly(age,2)+(1|X)+(1+B|Y)+(1+B|Z),
> family=binomial,
> data=ALLDATA,control=glmerControl(optimizer="bobyqa"))
>
>> Anova(MODEL1,type=3)
> Analysis of Deviance Table (Type III Wald chisquare tests)
>
> Response: prod_corr
>                        Chisq Df Pr(>Chisq)
> (Intercept)           0.8155  1   0.366503
> A                0.0059  1   0.938896
> B                 0.7490  1   0.386791
> log(age)              8.6887  1   0.003202 **
> A:B          0.0044  1   0.947053
> A:log(age)       0.2471  1   0.619110
> B:log(age)        2.5704  1   0.108881
> A:B:log(age) 0.4881  1   0.484767
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> Anova(MODEL2, type=3)
> Analysis of Deviance Table (Type III Wald chisquare tests)
>
> Response: prod_corr
>                             Chisq Df Pr(>Chisq)
> (Intercept)               41.2696  1  1.326e-10 ***
> A                     6.4384  1  0.0111677 *
> B                     13.0042  1  0.0003108 ***
> poly(age, 2)              14.2490  2  0.0008051 ***
> A:B              14.2547  1  0.0001597 ***
> A:poly(age, 2)        1.1039  2  0.5758358
> B:poly(age, 2)         3.2066  2  0.2012318
> A:B:poly(age, 2)  0.3203  2  0.8520201
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
> Best wishes,
> Yasu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * *
>* *
> Dit bericht en eventuele bijlagen geven enkel de visie van de
>schrijver weer en binden het INBO onder geen enkel beding, zolang dit
>bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of
>the writer and may not be regarded as stating an official position of
>INBO, as long as the message is not confirmed by a duly signed
>document.


************************************
Yasuaki SHINOHARA, Ph.D.
Assistant Professor
Center for English Language Education (CELESE) Waseda University Faculty of Science and Engineering
3-4-1 Okubo, Shinjuku-ku, 169-8555, Tokyo JAPAN
email: y.shinohara at aoni.waseda.jp

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bates at stat.wisc.edu  Mon Oct  6 18:23:20 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 6 Oct 2014 11:23:20 -0500
Subject: [R-sig-ME] Model selection GLM vs. GLMMs
In-Reply-To: <loom.20141005T212425-683@post.gmane.org>
References: <CAEOdAtH7wEHre_tK+J5-gKKkp37PGtvmh-z-XcYOhsM3OBz4Uw@mail.gmail.com>
	<loom.20141005T212425-683@post.gmane.org>
Message-ID: <CAO7JsnRyLtC35bu_1yfA2jKrduGUmhzQGzXzcKq1QX+d2zoVHA@mail.gmail.com>

On Sun, Oct 5, 2014 at 2:32 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Nelida Villase?or <nvillasenor at ...> writes:
>
> >
> > Thanks Ben.
> >
> > On: "I think you would find a bit of disagreement among experts about
> > the best procedure -- whether it would be to drop random effects until
> > you got a sensible non-singular fit, or to keep them in even though
> > they're singular"
> >
> > Could you please suggest me some references supporting each of these
> procedures?
> >
> > Cheers,
> > Nelida.
> >
>
>   I believe Barr et al (2013) has become the canonical reference
> for "put everything in the model".  Doug Bates has mentioned to
> me that he was working on a response, with some co-authors,
> that disagrees with Barr et al.; perhaps he will chime in on
> its status.


I have both practical and theoretical problems with the advice to "keep it
maximal". These problems are related to the inevitable overparameterization
of the model.  Two examples of fits of such models using the MixedModels
package for Julia are shown at the end of

http://nbviewer.ipython.org/github/dmbates/slides/blob/master/2014-10-01-Ithaca/lmm%20Examples.ipynb

In the first case, "bs10" - the data from Barr & Seyfeddinipur (2011),
there are 12 distinct items and 10 of the 20 nonlinear covariance
parameters in the model are associated with the random effects for item.
In the second case, "kb07" - the data from Kronm?ller & Barr (2007), there
are 56 subjects and 32 items with 72 covariance matrix parameters overall,
36 for subject and 36 for item.  The data for each of these examples was
kindly provided by Dale Barr.

>From a display of standard deviations for the random effects and their
estimated correlations it is difficult to see that the estimated covariance
matrices are singular. However, if you look at the Cholesky factor, or a
singular value decomposition of the Cholesky factor, it is obvious that
these matrices are singular.

The practical difficulties are that there are so many highly nonlinear
parameters in these models that convergence to an optimum is difficult.
The log-likelihood function, even after profiling out the residual variance
and the fixed-effects parameters is very flat and the model will converge
on the boundary of the parameter space (the parameters on the diagonal of
the Cholesky factor are constrained to be non-negative and several of them
are exactly zero or very close to zero).  This is not unexpected - you can
tell before you start that this is going to happen because you are trying
to estimate so many highly nonlinear parameters from so few distinct levels
of the grouping factor.

In the Julia package I was able to code up the gradient of the
log-likelihood for these kinds of models, which helps considerably with the
reliability and the speed of convergence.  Even so, the second example
takes about 5 minutes to converge.  When I tried to fit this model in R
with lme4 it took a couple of hours and I needed to increase the number of
iterations allowed to 20,000.

So the question is, do you really expect to gain more information by
fitting a model that you can tell will be singular and that will take a
very long time to converge because of this singularity?  I can't see what
is gained.  Barr et al. have done simulations from which they conclude that
this is important but the model used in the simulations is not like
anything I have encountered in practice.  As a statistician I feel that
hypothesis tests should be done according to the "heredity principle" (i.e.
don't test for a main effect in the presence of a non-trivial interaction
involving that factor) unless there is a clear reason for violating the
principle.  As I understand the argument for "maximal" structure in the
model it says to put every possible interaction into the model before
testing for a main effect - advice that I find peculiar.  I don't know how
to make sense of the results of such a test.



> I have a book chapter in press
> (Fox, G. Negrete-Yankelevich, S. and Sosa, V. (Eds.) Ecological Statistics:
> from principles to application. Oxford University Press) that discusses
> this issue.
>
>   Suggestions from the rest of the community are welcome, as always.
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From luis.cayuela at urjc.es  Mon Oct  6 18:32:28 2014
From: luis.cayuela at urjc.es (Luis Cayuela Delgado)
Date: Mon, 6 Oct 2014 16:32:28 +0000
Subject: [R-sig-ME] correlation of random factors in mixed models
Message-ID: <bdc1bb56b9a14560ad2cc941a23c1d1c@AMSPR02MB245.eurprd02.prod.outlook.com>

Dear list,


I have three related questions about how to interpret the output of a mixed model. First, I am interested in understanding what is the meaning of the correlation for random factors. For example:


library(lme4)

mod0 <- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)

summary(mod0)


This gives a correlation for random effects of 0.07. From other posts in the list I understood that this was the correlation between the random intercepts and the random slopes, so it should be calculated as:


ran0 <- ranef(mod0)

ran0

cor(ran0$Subject[,1], ran0$Subject[,2])



But this gives a correlation of 0.26. So how is the correlation for random effects estimated?


Second, in case this correlation was high, what implications this might have? I have learned that the model could be refitted removing the correlation between random intercept and slope by specifying the model as follows:


mod1 <- lmer(Reaction ~ Days + (1|Subject) + (0 + Days|Subject), data = sleepstudy)

summary(mod1)


When it is advisable to do this? If correlation of random effects was such a major issue, shouldn't we always fit the model as 'mod1'?


And then a final question, I have seen that when specifying the model as 'mod1', the correlation of fixed effects change. I don't get this, since correlation of fixed effects -as far as I understood- is calculated from the estimated parameters of independent linear models for each of the levels of the random factor. So for the above-mentioned example:


a <- lmList(Reaction ~ Days | Subject, sleepstudy)

cor(coef(a)[,1], coef(a)[,2])


This results in a correlation coefficient of -0.138, which matches the correlation for fixed effects in 'mod0'. So where does the correlation for fixed effects in 'mod1' (r = -0.184) come from?


Sorry for such a long post and hope that the questions are interesting for some other list useRs.


I am working with R 3.1.0. under Ubuntu Saucy 13.10, with package 'nlme' version 3.1.117 and package 'lme4' version 1.1.-7.


Thanks in advance,


Luis Cayuela

Universidad Rey Juan Carlos

Spain


	[[alternative HTML version deleted]]


From Farrar.David at epa.gov  Mon Oct  6 18:36:15 2014
From: Farrar.David at epa.gov (Farrar, David)
Date: Mon, 6 Oct 2014 16:36:15 +0000
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <5430006F.9010004@maw.ru.nl>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
	<loom.20141001T021328-466@post.gmane.org>	<542D3824.3030903@maw.ru.nl>
	<CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>
	<loom.20141004T005909-719@post.gmane.org>
	<CAF5_5cwm5FQ_qxLK9ZM2=RVVv9jMRTawzVhksycWGJ3uusrsyg@mail.gmail.com>
	<CABghstQ=U+Y_9+wCEEDofvw0Mgj+KJ_GbmPG1oscDL1wOLryQA@mail.gmail.com>
	<5430006F.9010004@maw.ru.nl>
Message-ID: <f8637132aaa34660a6dff42b0ec558fe@BY1PR09MB0392.namprd09.prod.outlook.com>

If I understood, the following should have worked?

> m.ML <- lmer(
+ log10(TWA) ~ ns(Wind.Speed,3) + isLamar + isLime1p + isLime5p  + log10(TWAuw)
+ + (1|BiosolidSource) + (1|sample) + (1|sample.trial),
+ REML=F,
+ data=da.regr
+ )
> m.lm <- lm(
+ log10(TWA) ~ ns(Wind.Speed,3) + isLamar + isLime1p + isLime5p + log10(TWAuw),
+ data=da.regr
+ )
> anova(m.ML, m.lm)
Error in UseMethod("isREML") : 
  no applicable method for 'isREML' applied to an object of class "lm"



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Pelzer
Sent: Saturday, October 04, 2014 10:13 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] anova (lm, lmer ) question

Dear romunov, Ben and Ken,

Thanks for your replies. From these I conclude that:
- for linear (lmer vs. lm) models there's no problem in using the deviance difference
- for generalized  linear models (glmer vs. glm) it's ok to use the deviance difference as long as nAGQ=1.
Would you agree with me? Best regards,

Ben.

On 4-10-2014 2:48, Ben Bolker wrote:
> Thanks for checking.  The comparison with Stata isn't necessarily 
> relevant though -- or question is whether `lm` and `lmer` (or `glm` 
> and `glmer`) include/exclude the same additive constants, so that 
> their log-likelihoods are directly comparable.
>
> On Fri, Oct 3, 2014 at 8:38 PM, Ken Beath <ken.beath at mq.edu.au> wrote:
>
>> nAGQ=1 and greater than 1 give different results, and the nAGQ=1 
>> matches fairly closely the log likelihood from Stata for 3 quadrature 
>> points, so presumably is correct. Stata's Laplace didn't converge with my data.
>>
>>
>> Ken
>>
>>
>>
>> On 4 October 2014 09:06, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> romunov <romunov at ...> writes:
>>>
>>>> FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.
>>>>
>>>> How can I test whether a random effect is significant?
>>>>
>>>    ...
>>>
>>>>     - *do not* compare lmer models with the corresponding lm fits, or
>>>>     glmer/glm; the log-likelihoods are not commensurate (i.e., they
>>> include
>>>>     different additive terms)
>>>    For what it's worth, I believe this is out of date, _except_ for 
>>> glmer fits with nAGQ>1.  It should be possible to implement
>>> anova(<merMod>,<lm>/<glm>) -- it's only a nuisance (sadly, if we 
>>> were still using S4 classes at this level it would be easier ...)
>>>
>>>    Ben Bolker
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken
>> /
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and 
>> m...{{dropped:11}}
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Mon Oct  6 18:53:06 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 06 Oct 2014 12:53:06 -0400
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <f8637132aaa34660a6dff42b0ec558fe@BY1PR09MB0392.namprd09.prod.outlook.com>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>	<5429AD74.8060604@gmail.com>	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>	<loom.20141001T021328-466@post.gmane.org>	<542D3824.3030903@maw.ru.nl>	<CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>	<loom.20141004T005909-719@post.gmane.org>	<CAF5_5cwm5FQ_qxLK9ZM2=RVVv9jMRTawzVhksycWGJ3uusrsyg@mail.gmail.com>	<CABghstQ=U+Y_9+wCEEDofvw0Mgj+KJ_GbmPG1oscDL1wOLryQA@mail.gmail.com>	<5430006F.9010004@maw.ru.nl>
	<f8637132aaa34660a6dff42b0ec558fe@BY1PR09MB0392.namprd09.prod.outlook.com>
Message-ID: <5432C8F2.1000005@gmail.com>

On 14-10-06 12:36 PM, Farrar, David wrote:
> If I understood, the following should have worked?
> 
>> m.ML <- lmer(
> + log10(TWA) ~ ns(Wind.Speed,3) + isLamar + isLime1p + isLime5p  + log10(TWAuw)
> + + (1|BiosolidSource) + (1|sample) + (1|sample.trial),
> + REML=F,
> + data=da.regr
> + )
>> m.lm <- lm(
> + log10(TWA) ~ ns(Wind.Speed,3) + isLamar + isLime1p + isLime5p + log10(TWAuw),
> + data=da.regr
> + )
>> anova(m.ML, m.lm)
> Error in UseMethod("isREML") : 
>   no applicable method for 'isREML' applied to an object of class "lm"

  I didn't mean to imply that anova(m.ML,m.lm) would actually work, but
rather that the equivalent calculation would be appropriate, e.g.

    library(lme4)
    fm1 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy, REML=FALSE)
    fm0 <- lm(Reaction ~ Days, sleepstudy)
    NL1 <- -logLik(fm1)
    NL0 <- -logLik(fm0)
    devdiff <- 2*(NL0-NL1)
    dfdiff <- attr(NL1,"df")-attr(NL0,"df")
    pchisq(devdiff,dfdiff,lower.tail=FALSE)

The p-value is very small in this case, but that's consistent
with a large/well-determined variance estimate ...

    pp <- profile(fm1)
    library(lattice)
    xyplot(logProf(pp))

Keep in mind that the likelihood ratio test also has some theoretical
problems in this case, mainly with boundary issues (see
http://glmm.wikidot.com/faq for more info)

> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Pelzer
> Sent: Saturday, October 04, 2014 10:13 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] anova (lm, lmer ) question
> 
> Dear romunov, Ben and Ken,
> 
> Thanks for your replies. From these I conclude that:
> - for linear (lmer vs. lm) models there's no problem in using the deviance difference
> - for generalized  linear models (glmer vs. glm) it's ok to use the deviance difference as long as nAGQ=1.
> Would you agree with me? Best regards,
> 
> Ben.
> 
> On 4-10-2014 2:48, Ben Bolker wrote:
>> Thanks for checking.  The comparison with Stata isn't necessarily 
>> relevant though -- or question is whether `lm` and `lmer` (or `glm` 
>> and `glmer`) include/exclude the same additive constants, so that 
>> their log-likelihoods are directly comparable.
>>
>> On Fri, Oct 3, 2014 at 8:38 PM, Ken Beath <ken.beath at mq.edu.au> wrote:
>>
>>> nAGQ=1 and greater than 1 give different results, and the nAGQ=1 
>>> matches fairly closely the log likelihood from Stata for 3 quadrature 
>>> points, so presumably is correct. Stata's Laplace didn't converge with my data.
>>>
>>>
>>> Ken
>>>
>>>
>>>
>>> On 4 October 2014 09:06, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>> romunov <romunov at ...> writes:
>>>>
>>>>> FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.
>>>>>
>>>>> How can I test whether a random effect is significant?
>>>>>
>>>>    ...
>>>>
>>>>>     - *do not* compare lmer models with the corresponding lm fits, or
>>>>>     glmer/glm; the log-likelihoods are not commensurate (i.e., they
>>>> include
>>>>>     different additive terms)
>>>>    For what it's worth, I believe this is out of date, _except_ for 
>>>> glmer fits with nAGQ>1.  It should be possible to implement
>>>> anova(<merMod>,<lm>/<glm>) -- it's only a nuisance (sadly, if we 
>>>> were still using S4 classes at this level it would be easier ...)
>>>>
>>>>    Ben Bolker
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>>
>>> *Ken Beath*
>>> Lecturer
>>> Statistics Department
>>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>>
>>> Phone: +61 (0)2 9850 8516
>>>
>>> Building E4A, room 526
>>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken
>>> /
>>>
>>> CRICOS Provider No 00002J
>>> This message is intended for the addressee named and 
>>> m...{{dropped:11}}
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Farrar.David at epa.gov  Mon Oct  6 19:15:39 2014
From: Farrar.David at epa.gov (Farrar, David)
Date: Mon, 6 Oct 2014 17:15:39 +0000
Subject: [R-sig-ME] anova (lm, lmer ) question
In-Reply-To: <5432C8F2.1000005@gmail.com>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
	<CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>
	<CAF5_5cx-xOBndw2q9Sko=BBcx28sqM-SyLeeMAhkFu3FtVcLqw@mail.gmail.com>
	<loom.20141001T021328-466@post.gmane.org>	<542D3824.3030903@maw.ru.nl>
	<CAHT1vphaGayOXe2+HaNRJrS+wXM1ZLTidJkNaj-asL1JP+eUTA@mail.gmail.com>
	<loom.20141004T005909-719@post.gmane.org>
	<CAF5_5cwm5FQ_qxLK9ZM2=RVVv9jMRTawzVhksycWGJ3uusrsyg@mail.gmail.com>
	<CABghstQ=U+Y_9+wCEEDofvw0Mgj+KJ_GbmPG1oscDL1wOLryQA@mail.gmail.com>
	<5430006F.9010004@maw.ru.nl>
	<f8637132aaa34660a6dff42b0ec558fe@BY1PR09MB0392.namprd09.prod.outlook.com>
	<5432C8F2.1000005@gmail.com>
Message-ID: <e37415878afa4f7f93819c441051c96c@BY1PR09MB0392.namprd09.prod.outlook.com>


OK got it.  I had thought we might be saying a mixture-of-chi-square approach was implemented, for testing on a boundary. 

I have been led to believe the approach is conservative.  Anyway, will spend some time with the FAQ (thanks).

I acknowledge the point make previously, that variances may be included based on design and testing them obviated.  


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Monday, October 06, 2014 12:53 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] anova (lm, lmer ) question

On 14-10-06 12:36 PM, Farrar, David wrote:
> If I understood, the following should have worked?
> 
>> m.ML <- lmer(
> + log10(TWA) ~ ns(Wind.Speed,3) + isLamar + isLime1p + isLime5p  + 
> + log10(TWAuw)
> + + (1|BiosolidSource) + (1|sample) + (1|sample.trial),
> + REML=F,
> + data=da.regr
> + )
>> m.lm <- lm(
> + log10(TWA) ~ ns(Wind.Speed,3) + isLamar + isLime1p + isLime5p + 
> + log10(TWAuw), data=da.regr
> + )
>> anova(m.ML, m.lm)
> Error in UseMethod("isREML") : 
>   no applicable method for 'isREML' applied to an object of class "lm"

  I didn't mean to imply that anova(m.ML,m.lm) would actually work, but rather that the equivalent calculation would be appropriate, e.g.

    library(lme4)
    fm1 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy, REML=FALSE)
    fm0 <- lm(Reaction ~ Days, sleepstudy)
    NL1 <- -logLik(fm1)
    NL0 <- -logLik(fm0)
    devdiff <- 2*(NL0-NL1)
    dfdiff <- attr(NL1,"df")-attr(NL0,"df")
    pchisq(devdiff,dfdiff,lower.tail=FALSE)

The p-value is very small in this case, but that's consistent with a large/well-determined variance estimate ...

    pp <- profile(fm1)
    library(lattice)
    xyplot(logProf(pp))

Keep in mind that the likelihood ratio test also has some theoretical problems in this case, mainly with boundary issues (see http://glmm.wikidot.com/faq for more info)

> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben 
> Pelzer
> Sent: Saturday, October 04, 2014 10:13 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] anova (lm, lmer ) question
> 
> Dear romunov, Ben and Ken,
> 
> Thanks for your replies. From these I conclude that:
> - for linear (lmer vs. lm) models there's no problem in using the 
> deviance difference
> - for generalized  linear models (glmer vs. glm) it's ok to use the deviance difference as long as nAGQ=1.
> Would you agree with me? Best regards,
> 
> Ben.
> 
> On 4-10-2014 2:48, Ben Bolker wrote:
>> Thanks for checking.  The comparison with Stata isn't necessarily 
>> relevant though -- or question is whether `lm` and `lmer` (or `glm` 
>> and `glmer`) include/exclude the same additive constants, so that 
>> their log-likelihoods are directly comparable.
>>
>> On Fri, Oct 3, 2014 at 8:38 PM, Ken Beath <ken.beath at mq.edu.au> wrote:
>>
>>> nAGQ=1 and greater than 1 give different results, and the nAGQ=1 
>>> matches fairly closely the log likelihood from Stata for 3 
>>> quadrature points, so presumably is correct. Stata's Laplace didn't converge with my data.
>>>
>>>
>>> Ken
>>>
>>>
>>>
>>> On 4 October 2014 09:06, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>> romunov <romunov at ...> writes:
>>>>
>>>>> FWIW, this is from the glmm faq site <http://glmm.wikidot.com/faq>.
>>>>>
>>>>> How can I test whether a random effect is significant?
>>>>>
>>>>    ...
>>>>
>>>>>     - *do not* compare lmer models with the corresponding lm fits, or
>>>>>     glmer/glm; the log-likelihoods are not commensurate (i.e., 
>>>>> they
>>>> include
>>>>>     different additive terms)
>>>>    For what it's worth, I believe this is out of date, _except_ for 
>>>> glmer fits with nAGQ>1.  It should be possible to implement
>>>> anova(<merMod>,<lm>/<glm>) -- it's only a nuisance (sadly, if we 
>>>> were still using S4 classes at this level it would be easier ...)
>>>>
>>>>    Ben Bolker
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>>
>>> *Ken Beath*
>>> Lecturer
>>> Statistics Department
>>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>>
>>> Phone: +61 (0)2 9850 8516
>>>
>>> Building E4A, room 526
>>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ke
>>> n
>>> /
>>>
>>> CRICOS Provider No 00002J
>>> This message is intended for the addressee named and 
>>> m...{{dropped:11}}
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From y.shinohara at aoni.waseda.jp  Tue Oct  7 11:07:25 2014
From: y.shinohara at aoni.waseda.jp (Yasuaki SHINOHARA)
Date: Tue, 07 Oct 2014 18:07:25 +0900
Subject: [R-sig-ME] Model comparisons
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AFA332@inbomail.inbo.be>
References: <web-46337392@besv05.spw.secure-premium.ne.jp>
	<AA818EAD2576BC488B4F623941DA7427F3AF9CDD@inbomail.inbo.be>
	<web-46121929@besv02.spw.secure-premium.ne.jp>
	<AA818EAD2576BC488B4F623941DA7427F3AFA332@inbomail.inbo.be>
Message-ID: <web-46243052@besv01.spw.secure-premium.ne.jp>

Dear Thierry,

Thank you very much for your help.

The effect of "D" is not really strong but the interaction between "D" 
and another factor is still significant in some models.
I will include it as a fixed factor and briefly report the result of 
the effect of "D".

As for the age effect, both log and quadratic functions make sense.
However, in terms of the interaction between age and other factors 
(e.g., testing block), the quadratic function reflects the results 
more than the logarithmic function.
In addition, the results of the model with age in polynomial 
(poly(age,2)) function make more sense. So I will choose the model 
with quadratic function.

Thank you very much again.

Best wishes,
Yasu

   
On Mon, 6 Oct 2014 08:41:19 +0000
  "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:
> Dear Yasu,
> 
> IMHO, a model must make sense. Assume you know a priori that a 
>certain variable "D" has an important effect on the response, but 
>your focus is on other variables. Then you have two options: A) use a 
>design that tests everything at the same level of "D". Then the 
>effect of "D" is constant in the design and can be ignored. B) 
>Measure "D" and add it to the model. You will have to report the 
>effect of "D", although not as elaborate as the variables you're 
>focusing on.
> 
> If you don't find any literature on the relation with age, then try 
>to thing what kind of relation could make sense. Is it monotone? Is 
>there an optimum? Has adding 1 unit of age the same effect regardless 
>the age? ... Bottom-line: rather choose a meaningful function, than 
>the function which gives the lowest AIC.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for 
>Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
>Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no 
>more than asking him to perform a post-mortem examination: he may be 
>able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does 
>not ensure that a reasonable answer can be extracted from a given 
>body of data.
> ~ John Tukey
> 
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
>[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Yasuaki 
>SHINOHARA
> Verzonden: zaterdag 4 oktober 2014 16:54
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] Model comparisons
> 
> Dear Thierry,
> 
> Thank you very much for your help.
> Actually, the first and second questions were not talking about the 
>same model.
>For the first question, the fixed factor of age was just an example, 
>and the results below are not related to the first question.
> I was not sure whether I should include a fixed factor of which I am 
>not reporting the results in a paper, if the model with the factor 
>fits significantly better than the model without the factor.
> Do you mean that I should include it, if it has a significant 
>effect, although I am not reporting the result of the factor?
> 
>For the second question, the aim of my research is to investigate the 
>age effects.
> I wanted to test how training works for speaker's production, and 
>whether there is an age effect on it.
> So the factor A is "Group" (training group vs. control group), and 
>the factor B is "Testing Block" (pre-training vs. post-training) I am 
>trying to find some literature about how the age related to the 
>improvement made by training, but it is really hard to find.
> I am not sure how I can send a figure of the relationship between 
>age and the response through this emailing list. Sorry.
> 
> Anyway, thank you very much for your help.
> 
> Best wishes,
> Yasu
> 
> 
> 
> 
>  about whether I should include a fixed factor in a logistic mixed 
>effects model or not, On Fri, 3 Oct 2014 08:20:31 +0000
>  "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:
>> Dear Yasu,
>>
>> It looks like your response is age dependent. Therefore you should
>>include age into the model, so the model can take the age effect into
>>account.
>>
>> I prefer to take a look at the functional relationship between age 
>>and
>>the response (in the logit scale). There is probabily some literature
>>on the effect of age on the response. That will give you more
>>information on which function to choose: log(age) or poly(age, 2).
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for 
>>Nature
>>and Forest  team Biometrie & Kwaliteitszorg / team Biometrics & 
>>Quality
>>Assurance  Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> + 32 2 525 02 51
>> + 32 54 43 61 85
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>> To call in the statistician after the experiment is done may be no
>>more than asking him to perform a post-mortem examination: he may be
>>able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>The plural of anecdote is not data. ~ Roger Brinner  The combination 
>>of
>>some data and an aching desire for an answer does not ensure that a
>>reasonable answer can be extracted from a given body of data. ~ John
>>Tukey
>>
>> ________________________________________
>> Van: r-sig-mixed-models-bounces at r-project.org
>>[r-sig-mixed-models-bounces at r-project.org] namens Yasuaki SHINOHARA
>>[y.shinohara at aoni.waseda.jp]
>> Verzonden: vrijdag 3 oktober 2014 6:22
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] Model comparisons
>>
>> Dear all,
>>
>> Could I ask a very basic question about glmer?
>> I am wondering how important using the best-fitting model is.
>>
>> (1)
>> Please imagine I have three fixed factors "A", "B" and "C" in a
>>logistic mixed effects model.
>> I want to test these main effects and their all possible 
>>interactions.
>> However, I can include another factor "D" (e.g., age) in which I am
>>not interested. If I include the fixed factor "D" in  the model, the
>>model fits significantly better than the model  without the factor 
>>"D".
>> I know I should use the best-fitting model, and report all the 
>>results
>>including the factor "D", although the results are slightly different
>>from the model which does not include the factor "D".
>> However, I also think that including unnecessary factors would
>>distract readers from the main point, so it may be good to analyze
>>data without the factor "D".
>> Could I ask your opinions?
>>
>> (2)
>> Also, I do not understand why the results are so different, if I
>>change the relation in one of the factors.
>>For example, the model including the fixed factors of "A","B","C" and
>>"log(age)" is significantly better than another model including the
>>fixed factors of "A","B","C" and "poly(age,2)".
>> This difference (log(age) vs. poly(age,2)) affects the results of
>>other factors of "A", "B" and "C" as below.
>> Could you please explain why?
>> In terms of AIC value, MODEL1 is better. However, the results of
>> MODEL1 do not look correct.
>> Why is it?
>>
>> MODEL1<-glmer(binomial_response~A*B*log(age)+(1|X)+(1+B|Y)+(1+B|Z),
>> family=binomial,
>> data=ALLDATA,control=glmerControl(optimizer="bobyqa"))
>> MODEL2<-glmer(binomial_response~A*B*poly(age,2)+(1|X)+(1+B|Y)+(1+B|Z),
>> family=binomial,
>> data=ALLDATA,control=glmerControl(optimizer="bobyqa"))
>>
>>> Anova(MODEL1,type=3)
>> Analysis of Deviance Table (Type III Wald chisquare tests)
>>
>> Response: prod_corr
>>                        Chisq Df Pr(>Chisq)
>> (Intercept)           0.8155  1   0.366503
>> A                0.0059  1   0.938896
>> B                 0.7490  1   0.386791
>> log(age)              8.6887  1   0.003202 **
>> A:B          0.0044  1   0.947053
>> A:log(age)       0.2471  1   0.619110
>> B:log(age)        2.5704  1   0.108881
>> A:B:log(age) 0.4881  1   0.484767
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>> Anova(MODEL2, type=3)
>> Analysis of Deviance Table (Type III Wald chisquare tests)
>>
>> Response: prod_corr
>>                             Chisq Df Pr(>Chisq)
>> (Intercept)               41.2696  1  1.326e-10 ***
>> A                     6.4384  1  0.0111677 *
>> B                     13.0042  1  0.0003108 ***
>> poly(age, 2)              14.2490  2  0.0008051 ***
>> A:B              14.2547  1  0.0001597 ***
>> A:poly(age, 2)        1.1039  2  0.5758358
>> B:poly(age, 2)         3.2066  2  0.2012318
>> A:B:poly(age, 2)  0.3203  2  0.8520201
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>>
>> Best wishes,
>> Yasu
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * *
>>* *
>> Dit bericht en eventuele bijlagen geven enkel de visie van de
>>schrijver weer en binden het INBO onder geen enkel beding, zolang dit
>>bericht niet bevestigd is door een geldig ondertekend document.
>> The views expressed in this message and any annex are purely those 
>>of
>>the writer and may not be regarded as stating an official position of
>>INBO, as long as the message is not confirmed by a duly signed
>>document.
> 
> 
> ************************************
> Yasuaki SHINOHARA, Ph.D.
> Assistant Professor
> Center for English Language Education (CELESE) Waseda University 
>Faculty of Science and Engineering
> 3-4-1 Okubo, Shinjuku-ku, 169-8555, Tokyo JAPAN
> email: y.shinohara at aoni.waseda.jp
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * 
>* *
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
>schrijver weer en binden het INBO onder geen enkel beding, zolang dit 
>bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those 
>of the writer and may not be regarded as stating an official position 
>of INBO, as long as the message is not confirmed by a duly signed 
>document.


************************************
Yasuaki SHINOHARA, Ph.D.
Assistant Professor
Center for English Language Education (CELESE)
Waseda University Faculty of Science and Engineering
3-4-1 Okubo, Shinjuku-ku, 169-8555, Tokyo JAPAN
email: y.shinohara at aoni.waseda.jp


From ken.beath at mq.edu.au  Tue Oct  7 11:28:57 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Tue, 7 Oct 2014 20:28:57 +1100
Subject: [R-sig-ME] correlation of random factors in mixed models
In-Reply-To: <bdc1bb56b9a14560ad2cc941a23c1d1c@AMSPR02MB245.eurprd02.prod.outlook.com>
References: <bdc1bb56b9a14560ad2cc941a23c1d1c@AMSPR02MB245.eurprd02.prod.outlook.com>
Message-ID: <CAF5_5cxJ-Nkh7G33=W3BmBtX8Q62Lc9iLwFS_BSzXvZJf2uUZA@mail.gmail.com>

The correlation of the random effects comes from the model, that is it is
estimated from the data using maximum likelihood. The ranef are obtained as
predictions for each subject based on their observed data and the
distribution of the random effect. I think it is optimistic to expect that
you would end up with the same correlations  given that there is a fair
amount of error in the ranef predictions. Trying with simulated data for a
very large number of groups they should be similar.

With a random intercept slope model the random effects will almost always
be correlated, so it is always a good idea to include the correlation. You
can change the correlation simply by taking a linear transform of the
observations, for example just change the Days to Days2 by subtracting 5
and fit a model with that. Then you will have much higher correlation. All
it means is that higher values of slope random effect are associated with
higher values of intercept random effect.

You can have models where the random effects are not correlated, but I
think it is something that should be checked not assumed.

I don't know what is happening with the correlation of the fixed effects
and the lmList. It may be just spurious or their is something geometric
happening. I expect it wouldn't happen if the number of observations per
subject varied.

Ken



On 7 October 2014 03:32, Luis Cayuela Delgado <luis.cayuela at urjc.es> wrote:

> Dear list,
>
>
> I have three related questions about how to interpret the output of a
> mixed model. First, I am interested in understanding what is the meaning of
> the correlation for random factors. For example:
>
>
> library(lme4)
>
> mod0 <- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)
>
> summary(mod0)
>
>
> This gives a correlation for random effects of 0.07. From other posts in
> the list I understood that this was the correlation between the random
> intercepts and the random slopes, so it should be calculated as:
>
>
> ran0 <- ranef(mod0)
>
> ran0
>
> cor(ran0$Subject[,1], ran0$Subject[,2])
>
>
>
> But this gives a correlation of 0.26. So how is the correlation for random
> effects estimated?
>
>
> Second, in case this correlation was high, what implications this might
> have? I have learned that the model could be refitted removing the
> correlation between random intercept and slope by specifying the model as
> follows:
>
>
> mod1 <- lmer(Reaction ~ Days + (1|Subject) + (0 + Days|Subject), data =
> sleepstudy)
>
> summary(mod1)
>
>
> When it is advisable to do this? If correlation of random effects was such
> a major issue, shouldn't we always fit the model as 'mod1'?
>
>
> And then a final question, I have seen that when specifying the model as
> 'mod1', the correlation of fixed effects change. I don't get this, since
> correlation of fixed effects -as far as I understood- is calculated from
> the estimated parameters of independent linear models for each of the
> levels of the random factor. So for the above-mentioned example:
>
>
> a <- lmList(Reaction ~ Days | Subject, sleepstudy)
>
> cor(coef(a)[,1], coef(a)[,2])
>
>
> This results in a correlation coefficient of -0.138, which matches the
> correlation for fixed effects in 'mod0'. So where does the correlation for
> fixed effects in 'mod1' (r = -0.184) come from?
>
>
> Sorry for such a long post and hope that the questions are interesting for
> some other list useRs.
>
>
> I am working with R 3.1.0. under Ubuntu Saucy 13.10, with package 'nlme'
> version 3.1.117 and package 'lme4' version 1.1.-7.
>
>
> Thanks in advance,
>
>
> Luis Cayuela
>
> Universidad Rey Juan Carlos
>
> Spain
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From dominique.carval at cirad.fr  Tue Oct  7 23:42:32 2014
From: dominique.carval at cirad.fr (Dominique CARVAL)
Date: Tue, 7 Oct 2014 17:42:32 -0400 (AST)
Subject: [R-sig-ME] interpretation of covariate effect on traits in
 multinomial mixed model (MCMCglmm)
In-Reply-To: <1818011707.119796.1412715898562.JavaMail.root@cirad.fr>
Message-ID: <986186209.119865.1412718152084.JavaMail.root@cirad.fr>


Hi everybody,

I want to assess the possible effect of the density of 3 plants strata (herbaceous, ligneous, and banana plant; continuous variables) on the probability of 6 ant species to be the (numerically) dominant species.

The data come from samplings on 500 sites in plantain agrosystems in Cameroun, with 2 replicates per site.
The multinomial response variable is composed of the 6 following categories : DomSpecies1,DomSpecies2, DomSpecies3, DomSpecies4, DomSpecies5, DomSpecies6.

I used the DomSpecies5 as the baseline category.
I followed the instructions of J. Hadfield (MCMCglmm Course Notes)to specify covariance matrix and I specified the following random effect : siteid, which is the identification number of each of the 500 sampled sites. 

I suppose that each ant species may respond differently to the density of each stratum.
Therefore, I used the following model:

bayesId<-MCMCglmm(DomSpecies~trait + herbaceous:trait  + banana:trait + ligneous:trait - 1, rcov = ~idh(trait):units, random=~siteid, nitt=nbiterations, burnin=burning, prior=priors1, family="categorical", data=Dominance, pr = TRUE, pl = TRUE, saveX=TRUE, saveZ = TRUE,thin=10)

Here is the location effects part summary of the model: 

 Location effects: DomSpecies ~ trait + herbaceous:trait + banana:trait + ligneous:trait - 1 

                           post.mean l-95% CI u-95% CI eff.samp  pMCMC   
traitDomSpecies.1           -0.40504 -0.67616 -0.18239   32.804 <0.001 **
traitDomSpecies.2           -1.56674 -1.84566 -1.27239   18.023 <0.001 **
traitDomSpecies.3           -2.68457 -3.24824 -2.02872    4.320 <0.001 **
traitDomSpecies.4           -0.57887 -0.87424 -0.28980   21.054 <0.001 **
traitDomSpecies.6           -0.34739 -0.58999 -0.11550   28.079 <0.001 **
traitDomSpecies.1:herbaceous  -0.12314 -0.36278  0.08398   36.442 0.2300   
traitDomSpecies.2:herbaceous  -0.81781 -1.12423 -0.45659   13.293 <0.001 **
traitDomSpecies.3:herbaceous  -0.79766 -1.79822  0.20292    1.548 0.2225   
traitDomSpecies.4:herbaceous   0.06787 -0.17180  0.25493   18.361 0.5375   
traitDomSpecies.6:herbaceous  -0.38589 -0.67043 -0.10492   13.041 0.0050 **
traitDomSpecies.1:banana      -0.55612 -0.97868 -0.08495   20.617 0.0100 **
traitDomSpecies.2:banana      -0.35302 -0.74533  0.04908   19.673 0.0875 . 
traitDomSpecies.3:banana      -0.31290 -1.21542  0.57856    4.051 0.7075   
traitDomSpecies.4:banana       0.09981 -0.24120  0.47918   23.943 0.5850   
traitDomSpecies.6:banana      -0.36227 -0.76133 -0.02808   33.856 0.0350 * 
traitDomSpecies.1:ligneous    1.15269  0.79352  1.55125   32.402 <0.001 **
traitDomSpecies.2:ligneous    0.85504  0.26285  1.42060    9.794 0.0125 * 
traitDomSpecies.3:ligneous    1.30803  0.83209  1.92698   12.474 <0.001 **
traitDomSpecies.4:ligneous   -0.19435 -1.10642  0.42893    3.782 0.8575   
traitDomSpecies.6:ligneous    1.09109  0.68030  1.53037   20.792 <0.001 **

I understand that the probability of being in the categories 1,2,3,4 and 6 are significantly lower than the probability of being in the baseline category 5 (which is consistent with observed data).

I am more confused to interpret the effect of covariates. For instance, the 7th line of this summary dispalys:
                              post.mean l-95% CI u-95% CI eff.samp  pMCMC 
traitDomSpecies.2:herbaceous  -0.81781 -1.12423 -0.45659   13.293 <0.001 **

I understand that the hebaceous stratum affect negatively (and significantly) the probability of being in the trait category 2. 
If I look at the 6th line:
                              post.mean l-95% CI u-95% CI eff.samp  pMCMC 
traitDomSpecies.1:herbaceous  -0.12314 -0.36278  0.08398   36.442 0.2300  
 
I understand that the hebaceous stratum does not affect the probability of being in the trait category 1. 
My first question is then: Am I right?

My second question: where do I found the effect of covariates on the baseline category 5?

Third and fourth questions: Is it correct to select the best models using only difference in DIC (delta DIC)? How to decide if the delta DIC is sufficiently large to be considered?

Thanks for answering,

Cheers,

Dom

Dominique Carval (PhD) - Ecologue 
UR26 Syst?me de Culture ? base de Bananiers, Plantain et Ananas 
CIRAD 
Campus Agro-environnemental Cara?bes 
Quartier Petit Morne ? BP214 
97285 Le Lamentin Cedex 2 

Tel : (+596) 0596 42 30 28 

Fax : (+596) 0596 42 30 01 


From dieter.anseeuw at inagro.be  Wed Oct  8 16:37:49 2014
From: dieter.anseeuw at inagro.be (Dieter Anseeuw)
Date: Wed, 8 Oct 2014 14:37:49 +0000
Subject: [R-sig-ME] mixed zero-inflated Poisson regression model
Message-ID: <72E5B92E710560479A262E2C2C6443911F8FDEC5@BEXCPS01.inagrp.local>

Dear all,
I have only limited experience in processing count data and would like to improve my statistical skills by addressing to the r-sig-mixed mailing list to handle the challenge (to me it is) below.

We did an experiment in which we would like to look at the effect of six treatments (+ 1 control) on the presence of leaf miners in Hippocastanum tree leaves.  Unfortunately the data are unbalanced: for two treatments we looked at 10 trees; for the other 4 + the control we looked only at 5 trees. For each tree 100 leaves were collected for which the number of mines (created by the life miners) were counted. In total we had 47 trees, 100 leaves per tree, this brings up 4700 observations.

To analyse this dataset, I need to use a zero inflated Poisson regression model, but I also may need to include the factor 'tree' as a random effect.

According to what I found in the r-sig-mixed list for comparable problems, this is where I got with my current code:
(whereby tellingen=count observations on a leaf (4700 observations); boom=unique tree code (47 trees); behandeling=treatment (7 levels))

Poisson Regression:
summary(mod1<-glm(tellingen~behandeling, family="poisson", data=finalcounts))

Zero Inflated Poisson Regression:
summary(admod1<-glmmadmb(tellingen~behandeling, data=finalcounts, family="poisson", zeroInflation=TRUE))

Zero Inflated Poisson Regression, with tree as random effect:
summary(admixmod1<-glmmadmb(tellingen~behandeling, data=finalcounts, family="poisson", zeroInflation=TRUE, random=~(1|boom)))
The latter takes quite some computational time.

Any comments on my approach that may improve my insight are warmly welcomed.
Questions:

1.       Which test should I use to compare these three models (to decide whether or not I should use the simple or a more complex model)

2.       So far, I did not specifically take into account the difference in observed trees per treatment (10 versus 5 trees). Problematic? How can I address this?

3.       How should I perform pairwise comparisons among treatments?

Just for your information, the summaries of the above mentioned models:

Call: glm(formula = tellingen ~ behandeling, family = "poisson", data = finalcounts)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-4.6851  -2.0088  -0.9440   0.5938  18.5705

Coefficients:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                  2.33537    0.01270 183.889  < 2e-16 ***
behandeling2lijmbandenonder -0.18921    0.01988  -9.518  < 2e-16 ***
behandeling4lijmbandenboven  0.06025    0.01770   3.404 0.000663 ***
behandelingcontrole         -0.89223    0.02517 -35.445  < 2e-16 ***
behandelinglijm_feromoon    -0.82509    0.02456 -33.601  < 2e-16 ***
behandelingtextiel200       -0.96470    0.02038 -47.343  < 2e-16 ***
behandelingtextiel80        -0.96293    0.02037 -47.282  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 35144  on 4699  degrees of freedom
Residual deviance: 29089  on 4693  degrees of freedom
AIC: 42931

Number of Fisher Scoring iterations: 5


XXXXXXXXXXXXXXX


Call: glmmadmb(formula = tellingen ~ behandeling, data = finalcounts,
    family = "poisson", zeroInflation = TRUE)

AIC: 35565.4

Coefficients:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                  2.06844    0.01724  119.97   <2e-16 ***
behandeling2lijmbandenonder  0.00801    0.02503    0.32     0.75
behandeling4lijmbandenboven  0.17392    0.02309    7.53    5e-14 ***
behandelingcontrole         -0.48004    0.03054  -15.72   <2e-16 ***
behandelinglijm_feromoon    -0.43062    0.02998  -14.36   <2e-16 ***
behandelingtextiel200       -0.63398    0.02649  -23.93   <2e-16 ***
behandelingtextiel80        -0.60413    0.02519  -23.98   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Number of observations: total=4700
Zero-inflation: 0.12999  (std. err.:  0.0051909 )

Log-likelihood: -17774.7

XXXXXXXXXXXXXXXXXXXX

Call: glmmadmb(formula = tellingen ~ behandeling, data = finalcounts,
    family = "poisson", random = ~(1 | boom), zeroInflation = TRUE)

AIC: 32854.2

Coefficients:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                   2.0883     0.1844   11.32  < 2e-16 ***
behandeling2lijmbandenonder  -0.0238     0.2735   -0.09  0.93069
behandeling4lijmbandenboven   0.1715     0.2607    0.66  0.51059
behandelingcontrole          -0.8631     0.2749   -3.14  0.00169 **
behandelinglijm_feromoon     -0.5662     0.2743   -2.06  0.03901 *
behandelingtextiel200        -0.7800     0.2338   -3.34  0.00085 ***
behandelingtextiel80         -0.7402     0.2339   -3.16  0.00155 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Number of observations: total=4700, boom=47
Random effect variance(s):
Group=boom
            Variance StdDev
(Intercept)   0.2037 0.4514

Zero-inflation: 0.092011  (std. err.:  0.0051551 )

Log-likelihood: -16418.1

Dieter Anseeuw, PhD
Aquaculture Research Scientist

Inagro vzw
Ieperseweg 87
B-8800 Rumbeke
Belgium
Direct phone: +32(0)51 273 373
http://www.linkedin.com/in/dieteranseeuw


	[[alternative HTML version deleted]]


From medo_botany at hotmail.com  Thu Oct  9 08:47:06 2014
From: medo_botany at hotmail.com (Hamada Elsayed Ali)
Date: Thu, 9 Oct 2014 06:47:06 +0000
Subject: [R-sig-ME] Effect size for lmer and glmer
Message-ID: <DUB119-W2D4DF16DB6FF9470168B69CA00@phx.gbl>

Dear All,

I am trying to calculate the effect size from lmer and glmer models that looks like that:

q0100 <- lmer(q0 ~ Management + Width + NonCrop100 + 
                Management * NonCrop100 + (1 | Plot.No), Alpha)


Pres100<-glmer(Present ~ Management + 
                 Management : status + 
                 Management : NonCrop100 +
                 status + 
                 NonCrop100 : status + 
                 NonCrop100 +
                 Management : Dispersal + 
                 Dispersal +
                 NonCrop100 : Dispersal +
                 (1|Plot.No),
               family=binomial, data=Presence)

Can you help me to calculate the effect size of the fixed variables and the interactions from the above mentioned models. I do have many other models that I like to compare all of them according to the effect size of each of which on the diversity measures, abundance and p/a data.

Thanks,

Hamada Elsayed Ali
PhD Candidate in Biogeographical Modelling,
University of Bayreuth
Universitaetsstr. 30
95440 Bayreuth, Germany
Email: hamada.ali at uni-bayreuth.de
 		 	   		  
	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Thu Oct  9 12:17:10 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 9 Oct 2014 10:17:10 +0000
Subject: [R-sig-ME] mixed zero-inflated Poisson regression model
In-Reply-To: <72E5B92E710560479A262E2C2C6443911F8FDEC5@BEXCPS01.inagrp.local>
References: <72E5B92E710560479A262E2C2C6443911F8FDEC5@BEXCPS01.inagrp.local>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AFC8BB@inbomail.inbo.be>

Hi Dieter,

1. Since you have a design with repeated measures you should include the tree effect. Hence the first two models are not consistent with your design. Leaving only one model, so no need to model comparison ;-)
2. Treatments with more trees will have more observations, giving more precise estimates. You don't need to correct for the number of trees per observation.
3. Have a look at the multcomp package. I have used it to do multiple comparisons with several models (lm, glm, lmer, glmer). I haven't tried it with glmmadmb.

PS: I would recode the treatment factor so that the control is used as  reference.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Dieter Anseeuw
Verzonden: woensdag 8 oktober 2014 16:38
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] mixed zero-inflated Poisson regression model

Dear all,
I have only limited experience in processing count data and would like to improve my statistical skills by addressing to the r-sig-mixed mailing list to handle the challenge (to me it is) below.

We did an experiment in which we would like to look at the effect of six treatments (+ 1 control) on the presence of leaf miners in Hippocastanum tree leaves.  Unfortunately the data are unbalanced: for two treatments we looked at 10 trees; for the other 4 + the control we looked only at 5 trees. For each tree 100 leaves were collected for which the number of mines (created by the life miners) were counted. In total we had 47 trees, 100 leaves per tree, this brings up 4700 observations.

To analyse this dataset, I need to use a zero inflated Poisson regression model, but I also may need to include the factor 'tree' as a random effect.

According to what I found in the r-sig-mixed list for comparable problems, this is where I got with my current code:
(whereby tellingen=count observations on a leaf (4700 observations); boom=unique tree code (47 trees); behandeling=treatment (7 levels))

Poisson Regression:
summary(mod1<-glm(tellingen~behandeling, family="poisson", data=finalcounts))

Zero Inflated Poisson Regression:
summary(admod1<-glmmadmb(tellingen~behandeling, data=finalcounts, family="poisson", zeroInflation=TRUE))

Zero Inflated Poisson Regression, with tree as random effect:
summary(admixmod1<-glmmadmb(tellingen~behandeling, data=finalcounts, family="poisson", zeroInflation=TRUE, random=~(1|boom))) The latter takes quite some computational time.

Any comments on my approach that may improve my insight are warmly welcomed.
Questions:

1.       Which test should I use to compare these three models (to decide whether or not I should use the simple or a more complex model)

2.       So far, I did not specifically take into account the difference in observed trees per treatment (10 versus 5 trees). Problematic? How can I address this?

3.       How should I perform pairwise comparisons among treatments?

Just for your information, the summaries of the above mentioned models:

Call: glm(formula = tellingen ~ behandeling, family = "poisson", data = finalcounts)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-4.6851  -2.0088  -0.9440   0.5938  18.5705

Coefficients:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                  2.33537    0.01270 183.889  < 2e-16 ***
behandeling2lijmbandenonder -0.18921    0.01988  -9.518  < 2e-16 ***
behandeling4lijmbandenboven  0.06025    0.01770   3.404 0.000663 ***
behandelingcontrole         -0.89223    0.02517 -35.445  < 2e-16 ***
behandelinglijm_feromoon    -0.82509    0.02456 -33.601  < 2e-16 ***
behandelingtextiel200       -0.96470    0.02038 -47.343  < 2e-16 ***
behandelingtextiel80        -0.96293    0.02037 -47.282  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 35144  on 4699  degrees of freedom Residual deviance: 29089  on 4693  degrees of freedom
AIC: 42931

Number of Fisher Scoring iterations: 5


XXXXXXXXXXXXXXX


Call: glmmadmb(formula = tellingen ~ behandeling, data = finalcounts,
    family = "poisson", zeroInflation = TRUE)

AIC: 35565.4

Coefficients:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                  2.06844    0.01724  119.97   <2e-16 ***
behandeling2lijmbandenonder  0.00801    0.02503    0.32     0.75
behandeling4lijmbandenboven  0.17392    0.02309    7.53    5e-14 ***
behandelingcontrole         -0.48004    0.03054  -15.72   <2e-16 ***
behandelinglijm_feromoon    -0.43062    0.02998  -14.36   <2e-16 ***
behandelingtextiel200       -0.63398    0.02649  -23.93   <2e-16 ***
behandelingtextiel80        -0.60413    0.02519  -23.98   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Number of observations: total=4700
Zero-inflation: 0.12999  (std. err.:  0.0051909 )

Log-likelihood: -17774.7

XXXXXXXXXXXXXXXXXXXX

Call: glmmadmb(formula = tellingen ~ behandeling, data = finalcounts,
    family = "poisson", random = ~(1 | boom), zeroInflation = TRUE)

AIC: 32854.2

Coefficients:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                   2.0883     0.1844   11.32  < 2e-16 ***
behandeling2lijmbandenonder  -0.0238     0.2735   -0.09  0.93069
behandeling4lijmbandenboven   0.1715     0.2607    0.66  0.51059
behandelingcontrole          -0.8631     0.2749   -3.14  0.00169 **
behandelinglijm_feromoon     -0.5662     0.2743   -2.06  0.03901 *
behandelingtextiel200        -0.7800     0.2338   -3.34  0.00085 ***
behandelingtextiel80         -0.7402     0.2339   -3.16  0.00155 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Number of observations: total=4700, boom=47 Random effect variance(s):
Group=boom
            Variance StdDev
(Intercept)   0.2037 0.4514

Zero-inflation: 0.092011  (std. err.:  0.0051551 )

Log-likelihood: -16418.1

Dieter Anseeuw, PhD
Aquaculture Research Scientist

Inagro vzw
Ieperseweg 87
B-8800 Rumbeke
Belgium
Direct phone: +32(0)51 273 373
http://www.linkedin.com/in/dieteranseeuw


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From mark.gr.miller at gmail.com  Tue Oct  7 04:27:34 2014
From: mark.gr.miller at gmail.com (Mark Miller)
Date: Tue, 7 Oct 2014 02:27:34 +0000 (UTC)
Subject: [R-sig-ME] gamm4: predict to reflect random effects?
References: <5CF76FF0-7702-4007-A619-EF815125B3E1@ufl.edu>
Message-ID: <loom.20141007T041917-824@post.gmane.org>

Mollie Brooks <mbrooks at ...> writes:

> 
> Dear mixed modelers,
> 
> Can anyone confirm that there is no way to make predictions from a 
gamm4 model including the random effects?
> I assume it is the same issue as with mgcv:gamm as discussed here 
> http://r.789695.n4.nabble.com/mgcv-gamm-predict-to-reflect-random-s-
effects-td3622738.html
> 
> I believe predict.merMod would include the random effects by default, 
but it doesn?t recognize the
> variable names given by gamm4.
> 
> Here is code in case you want to try something
> x <- runif(100)
> fac <- sample(1:20,100,replace=TRUE)
> eta <- x^2*3 + fac/20; fac <- as.factor(fac)
> y <- rpois(100,exp(eta))
> dat=data.frame(x=x, fac=fac, eta=eta, y=y)
> ## fit model and examine it...
> bp <- gamm4(y~s(x),family=poisson,random=~(1|fac), data=dat)
> 
> pred=predict(bp$gam, newdata=dat, type="response")
> pred2=predict(bp$mer, newdata=dat, type="response")
> #Error in eval(expr, envir, enclos) : object 'X' not found
> 
> Is the best alternative still to use gam?
> bp2=gam(y~s(x)+s(fac, bs="re"), method="REML", family=poisson, 
data=dat)
> 
> Thanks,
> Mollie
> 
> ------------------------
> Mollie Brooks, PhD
> Postdoctoral Researcher, Population Ecology Research Group 
http://www.popecol.org
> Institute of Evolutionary Biology & Environmental Studies, University 
of Z?rich
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> Dear mixed modelers,
> 
> Can anyone confirm that there is no way to make predictions from a 
gamm4 model including the random effects?
> I assume it is the same issue as with mgcv:gamm as discussed here 
> http://r.789695.n4.nabble.com/mgcv-gamm-predict-to-reflect-random-s-
effects-td3622738.html
> 
> I believe predict.merMod would include the random effects by default, 
but it doesn?t recognize the
> variable names given by gamm4.
> 
> Here is code in case you want to try something
> x <- runif(100)
> fac <- sample(1:20,100,replace=TRUE)
> eta <- x^2*3 + fac/20; fac <- as.factor(fac)
> y <- rpois(100,exp(eta))
> dat=data.frame(x=x, fac=fac, eta=eta, y=y)
> ## fit model and examine it...
> bp <- gamm4(y~s(x),family=poisson,random=~(1|fac), data=dat)
> 
> pred=predict(bp$gam, newdata=dat, type="response")
> pred2=predict(bp$mer, newdata=dat, type="response")
> #Error in eval(expr, envir, enclos) : object 'X' not found
> 
> Is the best alternative still to use gam?
> bp2=gam(y~s(x)+s(fac, bs="re"), method="REML", family=poisson, 
data=dat)
> 
> Thanks,
> Mollie
> 
> ------------------------
> Mollie Brooks, PhD
> Postdoctoral Researcher, Population Ecology Research Group 
http://www.popecol.org
> Institute of Evolutionary Biology & Environmental Studies, University 
of Z?rich
> 
> 	[[alternative HTML version deleted]]
> 
> 
Hi Mollie, 

I am also in the same position as you (although a couple of months 
behind). Have you found a solution for predicting fixed and random 
effects from GAMMs? I am going to try manually adding the fixed and 
random effects from the gamm4$mer object using model.matrix. If anyone 
has any other suggestions I'd be very keen to know.

Cheers,

Mark


From highstat at highstat.com  Thu Oct  9 22:10:02 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 09 Oct 2014 21:10:02 +0100
Subject: [R-sig-ME] mixed zero-inflated Poisson regression model (Dieter
	Anseeuw)
In-Reply-To: <mailman.3.1412848802.9226.r-sig-mixed-models@r-project.org>
References: <mailman.3.1412848802.9226.r-sig-mixed-models@r-project.org>
Message-ID: <5436EB9A.50108@highstat.com>


On 09/10/2014 11:00, r-sig-mixed-models-request at r-project.org wrote:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>     1. mixed zero-inflated Poisson regression model (Dieter Anseeuw)
>     2. Effect size for lmer and glmer (Hamada Elsayed Ali)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Wed, 8 Oct 2014 14:37:49 +0000
> From: Dieter Anseeuw <dieter.anseeuw at inagro.be>
> To: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] mixed zero-inflated Poisson regression model
> Message-ID:
> 	<72E5B92E710560479A262E2C2C6443911F8FDEC5 at BEXCPS01.inagrp.local>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear all,
> I have only limited experience in processing count data and would like to improve my statistical skills by addressing to the r-sig-mixed mailing list to handle the challenge (to me it is) below.


>
> We did an experiment in which we would like to look at the effect of six treatments (+ 1 control) on the presence of leaf miners in Hippocastanum tree leaves.  Unfortunately the data are unbalanced: for two treatments we looked at 10 trees; for the other 4 + the control we looked only at 5 trees. For each tree 100 leaves were collected for which the number of mines (created by the life miners) were counted. In total we had 47 trees, 100 leaves per tree, this brings up 4700 observations.
>
> To analyse this dataset, I need to use a zero inflated Poisson regression model, but I also may need to include the factor 'tree' as a random effect.

Why do you think you need to do zero inflated models? So...just to make 
sure I understand it properly....you count the number of bugs on 100 
leaves (which is potentially  Poisson)...or are you counting how many 
leaves have bugs (this is potentially binomial).


> According to what I found in the r-sig-mixed list for comparable problems, this is where I got with my current code:
> (whereby tellingen=count observations on a leaf (4700 observations); boom=unique tree code (47 trees); behandeling=treatment (7 levels))

I would choose the random effect structure based on how/what/where you 
expect a dependency structure in your data. And refrain from testing 
whether you need the random effects. Start with the Poisson GLMM and see 
whether this model does the job. If it does, then you are finished.


> Poisson Regression:
> summary(mod1<-glm(tellingen~behandeling, family="poisson", data=finalcounts))
>
> Zero Inflated Poisson Regression:
> summary(admod1<-glmmadmb(tellingen~behandeling, data=finalcounts, family="poisson", zeroInflation=TRUE))
>
> Zero Inflated Poisson Regression, with tree as random effect:
> summary(admixmod1<-glmmadmb(tellingen~behandeling, data=finalcounts, family="poisson", zeroInflation=TRUE, random=~(1|boom)))
> The latter takes quite some computational time.
>
> Any comments on my approach that may improve my insight are warmly welcomed.
> Questions:
>
> 1.       Which test should I use to compare these three models (to decide whether or not I should use the simple or a more complex model)

See above. Start with a Poisson GLMM...check for 
overdispersion...patterns in residuals...etc.
>
> 2.       So far, I did not specifically take into account the difference in observed trees per treatment (10 versus 5 trees). Problematic? How can I address this?
>
> 3.       How should I perform pairwise comparisons among treatments?

Same way as in linear regression.

Alain

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From highstat at highstat.com  Thu Oct  9 22:17:36 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 09 Oct 2014 21:17:36 +0100
Subject: [R-sig-ME] Effect size for lmer and glmer
In-Reply-To: <mailman.3.1412848802.9226.r-sig-mixed-models@r-project.org>
References: <mailman.3.1412848802.9226.r-sig-mixed-models@r-project.org>
Message-ID: <5436ED60.7000207@highstat.com>


>
> ------------------------------
>
> Message: 2
> Date: Thu, 9 Oct 2014 06:47:06 +0000
> From: Hamada Elsayed Ali <medo_botany at hotmail.com>
> To: Mixed Models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Effect size for lmer and glmer
> Message-ID: <DUB119-W2D4DF16DB6FF9470168B69CA00 at phx.gbl>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear All,
>
> I am trying to calculate the effect size from lmer and glmer models that looks like that:
>
> q0100 <- lmer(q0 ~ Management + Width + NonCrop100 +
>                  Management * NonCrop100 + (1 | Plot.No), Alpha)
>
>
> Pres100<-glmer(Present ~ Management +
>                   Management : status +
>                   Management : NonCrop100 +
>                   status +
>                   NonCrop100 : status +
>                   NonCrop100 +
>                   Management : Dispersal +
>                   Dispersal +
>                   NonCrop100 : Dispersal +
>                   (1|Plot.No),
>                 family=binomial, data=Presence)
>
> Can you help me to calculate the effect size of the fixed variables and the interactions from the above mentioned models.

Dear Hamada,

A Google search on "effect size glmm" gives about 20 pdf files on the 
first 2 pages alone. I would start with:

http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00261.x/full

>   I do have many other models that I like to compare all of them according to the effect size of each of which on the diversity measures, abundance and p/a data.
You mean diversity measures, abundances and p/a data calculated from the 
same data? Have a look at:
www.uvm.edu/~ngotelli/Bio%20264/Hurlbert.pdf



Kind regards,

Alain



>
> Thanks,
>
> Hamada Elsayed Ali
> PhD Candidate in Biogeographical Modelling,
> University of Bayreuth
> Universitaetsstr. 30
> 95440 Bayreuth, Germany
> Email: hamada.ali at uni-bayreuth.de
>   		 	   		
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 94, Issue 9
> *************************************************
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From mbrooks at ufl.edu  Fri Oct 10 13:30:21 2014
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Fri, 10 Oct 2014 13:30:21 +0200
Subject: [R-sig-ME] gamm4: predict to reflect random effects?
Message-ID: <4411559A-1EC2-4EC0-A7C9-4F30B90282A6@ufl.edu>

Hi Mark,

Since no one replied to my question, I assume that the answer given by Simon Wood in 2011 is still current. 
http://r.789695.n4.nabble.com/mgcv-gamm-predict-to-reflect-random-s-effects-td3622738.html

As Wood suggests at the link (scroll down), my lab group is using gam() with a spline for the random effect like s(Subject,bs="re")

Cheers,
Mollie
------------------------
Mollie Brooks, PhD
Postdoctoral Researcher, Population Ecology Research Group
Institute of Evolutionary Biology & Environmental Studies, University of Z?rich
http://www.popecol.org/team/mollie-brooks/



	[[alternative HTML version deleted]]


From bagchi.r at gmail.com  Fri Oct 10 15:56:49 2014
From: bagchi.r at gmail.com (robert bagchi)
Date: Fri, 10 Oct 2014 15:56:49 +0200
Subject: [R-sig-ME] Extracting weights from an lme object
Message-ID: <CAFJ9WUDAdRct65HRK3VCEjFzfY2p6-cTwiVTkGFwWVUuiSg1xw@mail.gmail.com>

Dear list,

My apologies if this is an elementary problem, but I can't find a solution
and it's driving me crazy!

As part of a function that bootstraps from an lme model, I need to extract
the weights argument that was used during model fitting.

For example, if we make up some (simple) data

## covariates
n <-20
dat <- data.frame(x=runif(n),grp=sample(letters[1:10], n, replace=T),
                  wts=runif(n))
dat$wts <- dat$wts/mean(dat$wts)

## model matrices
xmat <- model.matrix(~x, data=dat)
zmat <- model.matrix(~0+grp, data=dat)
## effects
beta <- c(0, 0)
b <- rnorm(10)
## response
dat$y <- rnorm(n=n, mean=xmat %*% beta + zmat %*% b, sd=sqrt(1/dat$wts))

## we can then fit the model with
require(nlme)

mod <- lme(y~x, random=~1|grp, weights=varFixed(value=~I(1/wts)),
           data=dat)
## however, while we can extract the weights used during the model fitting
with
(getCovariate(mod$modelStruct$varStruct))

## They are in a *different order* from those in the original data
(1/dat$wts)


Does anyone know a fairly fool-proof way of getting the weights out in the
same format as went into the model?

Any help would be much appreciated.
Robi

-- 
-- 
Dr Robert Bagchi
Ecosystem Management
Department of Environmental Systems Science
ETH Z?rich
Universit?tstrasse 16
8092 Zurich
Switzerland

tel: +41 (0)44 63 26805
email: bagchi.r at gmail.com (preferred)
robert.bagchi at usys.ethz.ch
web: http://www.ecology.ethz.ch/people/obass/rbagchi

*Recent publications:*
Pathogens and insect herbivores drive rainforest plant diversity and
composition,
<http://www.nature.com/nature/journal/vaop/ncurrent/full/nature12911.html>
Nature.
Testing for enemy?mediated density?dependence in the mortality of
seedlings: field experiments with five Neotropical tree species
<http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0706.2013.00835.x/full>,
Oikos.
Shifting Baselines on a Tropical Forest Frontier: Extirpations Drive
Declines in Local Ecological Knowledge
<http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0086598#pone-0086598-g003>,
PLoS One

	[[alternative HTML version deleted]]


From drmasoodmohd at gmail.com  Fri Oct 10 18:01:42 2014
From: drmasoodmohd at gmail.com (Mohd Masood)
Date: Sat, 11 Oct 2014 00:01:42 +0800
Subject: [R-sig-ME] When to use random slop models
Message-ID: <CALho=DbW=xWYpaDLKmP36V+-QHaJNasR64y2DDcaqdWNrkb0-Q@mail.gmail.com>

Hi all
I am working on a research questions to see the effects of district
level variables on asthma. I am using individual level (level1)
variables are district level variables (level 2). I am using
individual level variables as control.
1) My question is do I need a random slop model in this case? or
random intercept models are appropriate.
2) If yes, then how to decide which individual level variables should
be used for random slop?

Thanks
Masood


From ep311508 at ohio.edu  Sun Oct 12 22:08:50 2014
From: ep311508 at ohio.edu (Price, Emily)
Date: Sun, 12 Oct 2014 16:08:50 -0400
Subject: [R-sig-ME] singular convergence warning
Message-ID: <21D4FC5FDE197F4D942D0CF404BE76A33CE4D4A01E@EXMAIL1.ohio.edu>

Dear R mixed models users,

I'm running a Monte Carlo simulation with 16 cells using four loops to determine how sample size influences treatment effectiveness in single case design.  I'm running 1,000 replications for each cell so I have a total of 16,000 simulated datasets.  In 50 of the 16,000 datasets I'm getting the following warning message: In mer_finalize(ans) : singular convergence (7).  I would like to determine where the errors are occurring (i.e., which cells) so that I can do some follow up analyses but  I don't know  how to program a statement to tell me.  To let me know when each sample is finished within a cell I'm using the command:  cat("Iteration",i1,i2,i3,i4,t,"successful","\n") where i1, i2, i3, and i4 are the counters for each for loop and t is the value for the replication number within each cell.  Therefore, does anyone know how to use command cat to print the values of the specific cell when the warning message occurs? Or alternatively if there is a different way I would welcome that as well.  If you would like additional information about the code I can supply that as well.

Thanks!
Emily

Emily A. Price, PhD
Educational Research and Evaluation
Patton College of Education
Ohio University


	[[alternative HTML version deleted]]


From romunov at gmail.com  Mon Oct 13 09:53:51 2014
From: romunov at gmail.com (romunov)
Date: Mon, 13 Oct 2014 09:53:51 +0200
Subject: [R-sig-ME] singular convergence warning
In-Reply-To: <21D4FC5FDE197F4D942D0CF404BE76A33CE4D4A01E@EXMAIL1.ohio.edu>
References: <21D4FC5FDE197F4D942D0CF404BE76A33CE4D4A01E@EXMAIL1.ohio.edu>
Message-ID: <CAHT1vpiPnQOY=esEwg45Zuv0puBfL00zZHLNaaF6LbQ9L0vEvw@mail.gmail.com>

This isn't exactly mixed-mo list material (try
http://stackoverflow.com/questions/tagged/r), but here goes.

R uses a mechanism to catch warnings and lets you print whatever you want
when this happens. For your convenience function `tryCatch` may be used.
With it, you evaluate an expression and should an error or a warning occur,
do something with it.
Here's an example of `tryCatch` in action. Notice the structure of `x` and
`y`, which you can use to extract the desired elements and handle the
situation further.
FWIW, you can have both, warning and error, in the same `tryCatch` call.

> x <- tryCatch(simpleError("this is a simple error"),  error = function(e)
e)
> y <- tryCatch(simpleWarning("this is a simple warning"),  warning =
function(w) w)
> x
<simpleError: this is a simple error>
> y
<simpleWarning: this is a simple warning>
> str(x)
List of 2
 $ message: chr "this is a simple error"
 $ call   : NULL
 - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"
> str(y)
List of 2
 $ message: chr "this is a simple warning"
 $ call   : NULL
 - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"

HTH,
Roman



On Sun, Oct 12, 2014 at 10:08 PM, Price, Emily <ep311508 at ohio.edu> wrote:

> Dear R mixed models users,
>
> I'm running a Monte Carlo simulation with 16 cells using four loops to
> determine how sample size influences treatment effectiveness in single case
> design.  I'm running 1,000 replications for each cell so I have a total of
> 16,000 simulated datasets.  In 50 of the 16,000 datasets I'm getting the
> following warning message: In mer_finalize(ans) : singular convergence
> (7).  I would like to determine where the errors are occurring (i.e., which
> cells) so that I can do some follow up analyses but  I don't know  how to
> program a statement to tell me.  To let me know when each sample is
> finished within a cell I'm using the command:
> cat("Iteration",i1,i2,i3,i4,t,"successful","\n") where i1, i2, i3, and i4
> are the counters for each for loop and t is the value for the replication
> number within each cell.  Therefore, does anyone know how to use command
> cat to print the values of the specific cell when the warning message
> occurs? Or alternatively if there is a different way I would welcom!
>  e that as well.  If you would like additional information about the code
> I can supply that as well.
>
> Thanks!
> Emily
>
> Emily A. Price, PhD
> Educational Research and Evaluation
> Patton College of Education
> Ohio University
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From henrik.singmann at psychologie.uni-freiburg.de  Mon Oct 13 15:23:18 2014
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Mon, 13 Oct 2014 15:23:18 +0200
Subject: [R-sig-ME] Announcing new version of afex (0.11-131)
Message-ID: <m1gjo7$7o5$1@ger.gmane.org>

Dear list,

The latest version of afex (0.11-131), package for fitting ANOVAs and obtaining p-values in mixed models, was accepted on CRAN yesterday: http://cran.r-project.org/web/packages/afex/index.html

As discussed previously on this list, afex does *not* change the global contrast anymore, although mixed() and the ANOVA functions still use "contr.sum" per default (by changing the contrasts of the factors in the data.frame passed). To set contrasts globally use functions set_sum_contrasts() or set_default_contrasts().

The main new functionality is:
- added the allFit() function written by Ben Bolker which fits an (g)lmer model with all possible optimizers (see ?allFit or https://github.com/lme4/lme4/blob/master/misc/issues/allFit.R).
- mixed objects as returned from mixed() are now fully supported by lsmeans for post-hoc tests or plotting (lsmip).
- the ANOVA functions (i.e., aov.car, ez.glm, & aov4) return the ANOVA fitted with aov when return = "aov" which can also be passed to lsmeans (be careful with unbalanced designs).

The full NEWS is below:

                     Changes in afex Version 0.11-x
                     Released October 2014

     Significant User Visible Changes and New Features

     o   added allFit() function (written by Ben Bolker).
     
     o   mixed() gives warning if nested model provides worse fit
         (logLik) than full model (when fitted with ML).
     
     o   print, summary, and anova method for mixed objects are now
         identical.
         
     o   description of returned object from mixed() extended (Thanks
         to Ben Bolker, see http://stackoverflow.com/a/25612960/289572)
         
     o   added return = "aov" to aov.car which returns the ANOVA
         fitted with aov (with correct Error strata) so that it can be
         passed to lsmeans for post-hoc tests or plotting (lsmip).
         
         
     Bugfixes
     
     o   all required functions are now correctly imported avoiding
         CRAN warnings and better functioning.
         
     o   data argument to lmer calls in mixed set correctly. Note that
         still contrasts added to the data in mixed may prohibit use of
         predict.merMod() or similar functions. It is recommended to
         set the contrasts globally to "contr.sum", e.g.,
         via set_sum_contrasts(), for correct functioning
         (disable via set.data.arg argument for mixed).


-- 
Dr. Henrik Singmann
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From bates at stat.wisc.edu  Mon Oct 13 17:12:44 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Oct 2014 10:12:44 -0500
Subject: [R-sig-ME] lme4 heteroscedasticity???
In-Reply-To: <4152C532A3804441A1228603786ADAE606B22489@MAIL-BF>
References: <4152C532A3804441A1228603786ADAE606B22489@MAIL-BF>
Message-ID: <CAO7JsnSbzP++fHY5ji+5KY26sY_U+WL-fSxq5EvsD6dd8D1GKg@mail.gmail.com>

It is best to send questions like this to the
R-SIG-Mixed-Models at R-Project.org mailing list, which I am cc:ing on this
reply.  Several of those who read that list can respond more quickly than I
am able to.

As far as I know there is not yet the capability in lme4 to model
heteroscedasticity in the distribution of the response given the random
effects.

On Mon, Oct 13, 2014 at 6:01 AM, Ko?melj, Katarina <
Katarina.Kosmelj at bf.uni-lj.si> wrote:

>  Hello,
>
> I am analyzing a mixed model with three crossed factors, two random
> (sample, laboratory) and one fixed (method); the response variable is the
> number of somatic cells in milk.  The main question is: is the precision of
> the means of the three method is comparable? Therefore, I would like to
> compare a model with different variances for the methods with the model
> considering the same variance for the methods.
>
>
>
> In nlme, this is feasible, however, two crossed random factors can not be
> tackled, this can be analyzed with lme4.
>
>
>
> In nlme, the problem of heteroscedasticity if solved. Is this problem
> solved in lme4 yet?
>
> Do you have any suggestion how to deal with this problem?
>
>
>
> Regards,
>
> Katarina
>
>
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Mon Oct 13 17:17:54 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Oct 2014 10:17:54 -0500
Subject: [R-sig-ME] varFixed function query in lme
In-Reply-To: <543BD7BC.7020000@cam.ac.uk>
References: <543BD7BC.7020000@cam.ac.uk>
Message-ID: <CAO7JsnQpZhGyfcTf+RDUT5mDoht8L=UtvXS7+vtF0DB3LMJaZA@mail.gmail.com>

It is best to send inquiries like this to the
R-SIG-Mixed-Models at R-project.org mailing list, which I am cc:ing on this
reply.  I am no longer the maintainer of the nlme package - I was pushed
aside by R Core many years ago and I really don't know what changes have
been made since they took over.

On Mon, Oct 13, 2014 at 8:46 AM, David Cox <dac64 at cam.ac.uk> wrote:

> Dear Professor Bates,
>
> I'm a neuroscience PhD student at Cambridge University. I saw that you
> maintain the 'varFixed' function for the 'weights' option in the nlme
> library. I have been reading the help manual but I'm a little stuck on a
> problem and wondered if you might have any quick suggestions.
>
> I'm using lme to model the peptide sequences of a set of proteins for
> cancer patients and healthy individuals. I want to use the weights function
> so that the peptide intensities are inversely weighted with the variance.
> The higher the variance, the lower the weighting etc. As the peptide
> intensities of cancer patients and healthy individuals will be different, I
> want to apply this weighting separately for each group.
>
> At the moment I've tried with a model like this for the 1st protein:
>  Peptide Intensities ~ Covariates + Peptide Sequences + Group, random =
> Sample Id, data = data, weights = ~ Group
>
> Group denotes whether each intensity is a cancer patient/healthy person.
> Sample id is the id of each cancer/healthy sample.
>
> This doesn't work though. I get an error saying: "Error in
> Math.factor(attr(object, "covariate")) :    abs not meaningful for factors."
>
> Many Thanks
>
> David Cox
>

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Mon Oct 13 17:24:44 2014
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Mon, 13 Oct 2014 15:24:44 +0000
Subject: [R-sig-ME] lme4 heteroscedasticity???
In-Reply-To: <CAO7JsnSbzP++fHY5ji+5KY26sY_U+WL-fSxq5EvsD6dd8D1GKg@mail.gmail.com>
References: <4152C532A3804441A1228603786ADAE606B22489@MAIL-BF>
	<CAO7JsnSbzP++fHY5ji+5KY26sY_U+WL-fSxq5EvsD6dd8D1GKg@mail.gmail.com>
Message-ID: <974F8095-C164-40FA-8AA8-A54BD35983AA@glasgow.ac.uk>

You can model both heteroscedasticity and crossed random effects in nlme. Crossed random effects can be handled in nlme using pdBlocked and pdIdent. See p163-6 of Pinheiro, J.C. & Bates, D.M. (2000). Mixed-Effects Models in S and S-PLUS. Springer, New York.
Paul

On 13 Oct 2014, at 16:12, Douglas Bates <bates at stat.wisc.edu> wrote:

> It is best to send questions like this to the
> R-SIG-Mixed-Models at R-Project.org mailing list, which I am cc:ing on this
> reply.  Several of those who read that list can respond more quickly than I
> am able to.
> 
> As far as I know there is not yet the capability in lme4 to model
> heteroscedasticity in the distribution of the response given the random
> effects.
> 
> On Mon, Oct 13, 2014 at 6:01 AM, Ko?melj, Katarina <
> Katarina.Kosmelj at bf.uni-lj.si> wrote:
> 
>> Hello,
>> 
>> I am analyzing a mixed model with three crossed factors, two random
>> (sample, laboratory) and one fixed (method); the response variable is the
>> number of somatic cells in milk.  The main question is: is the precision of
>> the means of the three method is comparable? Therefore, I would like to
>> compare a model with different variances for the methods with the model
>> considering the same variance for the methods.
>> 
>> 
>> 
>> In nlme, this is feasible, however, two crossed random factors can not be
>> tackled, this can be analyzed with lme4.
>> 
>> 
>> 
>> In nlme, the problem of heteroscedasticity if solved. Is this problem
>> solved in lme4 yet?
>> 
>> Do you have any suggestion how to deal with this problem?
>> 
>> 
>> 
>> Regards,
>> 
>> Katarina
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bates at stat.wisc.edu  Mon Oct 13 17:35:41 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Oct 2014 10:35:41 -0500
Subject: [R-sig-ME] lme4 heteroscedasticity???
In-Reply-To: <974F8095-C164-40FA-8AA8-A54BD35983AA@glasgow.ac.uk>
References: <4152C532A3804441A1228603786ADAE606B22489@MAIL-BF>
	<CAO7JsnSbzP++fHY5ji+5KY26sY_U+WL-fSxq5EvsD6dd8D1GKg@mail.gmail.com>
	<974F8095-C164-40FA-8AA8-A54BD35983AA@glasgow.ac.uk>
Message-ID: <CAO7JsnQMbb+NentaZ5Co9QAtG+bjb=HFehonmT052z2q8vTFiw@mail.gmail.com>

On Mon, Oct 13, 2014 at 10:24 AM, Paul Johnson <paul.johnson at glasgow.ac.uk>
wrote:

> You can model both heteroscedasticity and crossed random effects in nlme.
> Crossed random effects can be handled in nlme using pdBlocked and pdIdent.
> See p163-6 of Pinheiro, J.C. & Bates, D.M. (2000). Mixed-Effects Models in
> S and S-PLUS. Springer, New York.
>

But it will be a very slow and memory-intensive process unless one of the
grouping factors has very few levels.  The nlme package does not use sparse
matrix methods, nor does it use a profiled objective criterion.

In other words, yes it is possible but no, it is not easy to do so this way.


> On 13 Oct 2014, at 16:12, Douglas Bates <bates at stat.wisc.edu> wrote:
>
> > It is best to send questions like this to the
> > R-SIG-Mixed-Models at R-Project.org mailing list, which I am cc:ing on this
> > reply.  Several of those who read that list can respond more quickly
> than I
> > am able to.
> >
> > As far as I know there is not yet the capability in lme4 to model
> > heteroscedasticity in the distribution of the response given the random
> > effects.
> >
> > On Mon, Oct 13, 2014 at 6:01 AM, Ko?melj, Katarina <
> > Katarina.Kosmelj at bf.uni-lj.si> wrote:
> >
> >> Hello,
> >>
> >> I am analyzing a mixed model with three crossed factors, two random
> >> (sample, laboratory) and one fixed (method); the response variable is
> the
> >> number of somatic cells in milk.  The main question is: is the
> precision of
> >> the means of the three method is comparable? Therefore, I would like to
> >> compare a model with different variances for the methods with the model
> >> considering the same variance for the methods.
> >>
> >>
> >>
> >> In nlme, this is feasible, however, two crossed random factors can not
> be
> >> tackled, this can be analyzed with lme4.
> >>
> >>
> >>
> >> In nlme, the problem of heteroscedasticity if solved. Is this problem
> >> solved in lme4 yet?
> >>
> >> Do you have any suggestion how to deal with this problem?
> >>
> >>
> >>
> >> Regards,
> >>
> >> Katarina
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Mon Oct 13 18:13:24 2014
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Mon, 13 Oct 2014 16:13:24 +0000
Subject: [R-sig-ME] lme4 heteroscedasticity???
In-Reply-To: <CAO7JsnQMbb+NentaZ5Co9QAtG+bjb=HFehonmT052z2q8vTFiw@mail.gmail.com>
References: <4152C532A3804441A1228603786ADAE606B22489@MAIL-BF>
	<CAO7JsnSbzP++fHY5ji+5KY26sY_U+WL-fSxq5EvsD6dd8D1GKg@mail.gmail.com>
	<974F8095-C164-40FA-8AA8-A54BD35983AA@glasgow.ac.uk>
	<CAO7JsnQMbb+NentaZ5Co9QAtG+bjb=HFehonmT052z2q8vTFiw@mail.gmail.com>
Message-ID: <495DC286-41A0-4830-8CB4-B98676E8B6E4@glasgow.ac.uk>

I did this a few years ago for ~250 patients (nested within ~10 hospitals) being assessed by 7 adjudicators, so roughly a 250 x 6 table of crossed random effects. The aim was to look for differences in precision between clinicians rating patients on a symptoms scale. It did take a several minutes to fit on a server with 24 GB of RAM, and required a little fiddling with the control options, but was nevertheless worth the time and trouble. Looking back at my code (below), I find that your advice helped me to fit it, via a post of yours from 2004, for which thanks!

The model syntax is a little fiddly and easy to get wrong, so I?d advise anyone doing this for the first time to check that the results of the homoscedastic model match those from lme4, where the random effects syntax is straightforward, before fitting the heteroscedastic model.

       # fit models
  
        # extend number of iterations allowed
        
          control<-lmeControl(maxIter=500,msMaxIter=500,niterEM=250,msMaxEval=2000)
        
        # I want to fit three random effects, id crossed with adj and id nested within site
        # how to model this is  described by douglas bates here: http://tolstoy.newcastle.edu.au/R/help/04/02/0830.html
        # beware - lme takes several minutes to fit these models - lmer is much faster but doesn't allow heteroscedasticity to be modelled
    
          mod.sep.adj.rancrossed<-
            lme(mrs~1,random=list(Block=pdBlocked(list(pdIdent(~adj-1),pdIdent(~site-1),pdIdent(~id-1)))),
              data=cars.rep,control=control)
    
        # fit heteroscedastic model
    
          mod.sep.adj.rancrossed.w<-update(mod.sep.adj.rancrossed,weights=varIdent(form=~1|adj))

        # get p-value for heteroscedastic model vs homoscedastic model 
    
          (precision.p.val<-anova(mod.sep.adj.rancrossed.w,mod.sep.adj.rancrossed)[2,"p-value"])


On 13 Oct 2014, at 16:35, Douglas Bates <bates at stat.wisc.edu> wrote:

> On Mon, Oct 13, 2014 at 10:24 AM, Paul Johnson <paul.johnson at glasgow.ac.uk> wrote:
> You can model both heteroscedasticity and crossed random effects in nlme. Crossed random effects can be handled in nlme using pdBlocked and pdIdent. See p163-6 of Pinheiro, J.C. & Bates, D.M. (2000). Mixed-Effects Models in S and S-PLUS. Springer, New York.
> 
> But it will be a very slow and memory-intensive process unless one of the grouping factors has very few levels.  The nlme package does not use sparse matrix methods, nor does it use a profiled objective criterion.
> 
> In other words, yes it is possible but no, it is not easy to do so this way.
>  
> On 13 Oct 2014, at 16:12, Douglas Bates <bates at stat.wisc.edu> wrote:
> 
> > It is best to send questions like this to the
> > R-SIG-Mixed-Models at R-Project.org mailing list, which I am cc:ing on this
> > reply.  Several of those who read that list can respond more quickly than I
> > am able to.
> >
> > As far as I know there is not yet the capability in lme4 to model
> > heteroscedasticity in the distribution of the response given the random
> > effects.
> >
> > On Mon, Oct 13, 2014 at 6:01 AM, Ko?melj, Katarina <
> > Katarina.Kosmelj at bf.uni-lj.si> wrote:
> >
> >> Hello,
> >>
> >> I am analyzing a mixed model with three crossed factors, two random
> >> (sample, laboratory) and one fixed (method); the response variable is the
> >> number of somatic cells in milk.  The main question is: is the precision of
> >> the means of the three method is comparable? Therefore, I would like to
> >> compare a model with different variances for the methods with the model
> >> considering the same variance for the methods.
> >>
> >>
> >>
> >> In nlme, this is feasible, however, two crossed random factors can not be
> >> tackled, this can be analyzed with lme4.
> >>
> >>
> >>
> >> In nlme, the problem of heteroscedasticity if solved. Is this problem
> >> solved in lme4 yet?
> >>
> >> Do you have any suggestion how to deal with this problem?
> >>
> >>
> >>
> >> Regards,
> >>
> >> Katarina
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


From mark.gr.miller at gmail.com  Mon Oct 13 08:40:14 2014
From: mark.gr.miller at gmail.com (Mark Miller)
Date: Mon, 13 Oct 2014 16:40:14 +1000
Subject: [R-sig-ME] gamm4: predict to reflect random effects?
In-Reply-To: <4411559A-1EC2-4EC0-A7C9-4F30B90282A6@ufl.edu>
References: <4411559A-1EC2-4EC0-A7C9-4F30B90282A6@ufl.edu>
Message-ID: <CA+POB6E-qBAe5RU3NxJX5GacW5JSkhPfEdZ9idCyPe6VxDf-sg@mail.gmail.com>

Hi Mollie,

Thanks for the reply, yep I guess for now using gam is the best option of
simple random effects. I am trying to fit a more complex model with nested
random effects and want both slope and intercept to vary -  I'll try using
splines within a GLMM and seeing how that works out!

Cheers,

Mark

On Fri, Oct 10, 2014 at 9:30 PM, Mollie Brooks <mbrooks at ufl.edu> wrote:

> Hi Mark,
>
> Since no one replied to my question, I assume that the answer given by
> Simon Wood in 2011 is still current.
>
> http://r.789695.n4.nabble.com/mgcv-gamm-predict-to-reflect-random-s-effects-td3622738.html
>
> As Wood suggests at the link (scroll down), my lab group is using gam()
> with a spline for the random effect like s(Subject,bs="re")
>
> Cheers,
> Mollie
> ------------------------
> Mollie Brooks, PhD
> Postdoctoral Researcher, Population Ecology Research Group
> Institute of Evolutionary Biology & Environmental Studies, University of
> Z?rich
> http://www.popecol.org/team/mollie-brooks/
>
>
>

	[[alternative HTML version deleted]]


From martin.hecht at iqb.hu-berlin.de  Mon Oct 13 19:11:23 2014
From: martin.hecht at iqb.hu-berlin.de (Martin Hecht)
Date: Mon, 13 Oct 2014 19:11:23 +0200
Subject: [R-sig-ME] Problem with bootMer and models with offset
Message-ID: <543C07BB.50203@iqb.hu-berlin.de>


Hi,

I am using the latest version of R (3.1.1) and lme4 (1.1-7) .

I'm getting some weird implausible bootstrap results from bootMer for a
model with an offset (models without offset work fine).

I've attached an Rdata file with the returned object from lmer (lmerObj)
and the returned object from bootMer (booted)

Any help would be appreciated very much.


the syntax is:

booted <- bootMer ( x = lmerObj , FUN =
function(fit){return(c(fixef(fit),getME(fit,'theta')))} , nsim = 100 ,
seed = 65835 , verbose = TRUE )

> booted$t0[1]
(Intercept)
    2.606621

> mean(booted$t[,1])
[1] -78.21035

> boot::boot.ci ( booted , conf = 0.95 , type = "basic" , index = 1 )
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 100 bootstrap replicates

CALL :
boot::boot.ci(boot.out = booted, conf = 0.95, type = "basic",
    index = 1)

Intervals :
Level      Basic        
95%   (69.864, 95.425 ) 
Calculations and Intervals on Original Scale
Some basic intervals may be unstable


From bbolker at gmail.com  Tue Oct 14 04:16:22 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Oct 2014 02:16:22 +0000 (UTC)
Subject: [R-sig-ME] Problem with bootMer and models with offset
References: <543C07BB.50203@iqb.hu-berlin.de>
Message-ID: <loom.20141014T040507-42@post.gmane.org>

Martin Hecht <martin.hecht at ...> writes:

> 
> 
> Hi,
> 
> I am using the latest version of R (3.1.1) and lme4 (1.1-7) .
> 
> I'm getting some weird implausible bootstrap results from bootMer for a
> model with an offset (models without offset work fine).
> 
> I've attached an Rdata file with the returned object from lmer (lmerObj)
> and the returned object from bootMer (booted)

  Unfortunately, Rdata/RData files get stripped by the mailing list
software (there's a short list of attachments that get allowed --
I'm not sure how to find it -- probably includes txt and CSV files
but not much else).

> Any help would be appreciated very much.
> 
> the syntax is:
> 
> booted <- bootMer ( x = lmerObj , FUN =
> function(fit){return(c(fixef(fit),getME(fit,'theta')))} , nsim = 100 ,
> seed = 65835 , verbose = TRUE )
> 
> > booted$t0[1]
> (Intercept)
>     2.606621
> 
> > mean(booted$t[,1])
> [1] -78.21035
> 
> > boot::boot.ci ( booted , conf = 0.95 , type = "basic" , index = 1 )
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 100 bootstrap replicates
> 
> CALL :
> boot::boot.ci(boot.out = booted, conf = 0.95, type = "basic",
>     index = 1)
> 
> Intervals :
> Level      Basic        
> 95%   (69.864, 95.425 ) 
> Calculations and Intervals on Original Scale
> Some basic intervals may be unstable

  This does indeed seem weird.

  Does plot(booted,1) help at all?

  I wonder if a workaround for now is to add the offset manually;
that should be perfectly feasible (if not quite as convenient)
for a linear mixed model -- it's only really *necessary* for
a GLMM ...


From bbolker at gmail.com  Tue Oct 14 04:20:16 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Oct 2014 02:20:16 +0000 (UTC)
Subject: [R-sig-ME] varFixed function query in lme
References: <543BD7BC.7020000@cam.ac.uk>
	<CAO7JsnQpZhGyfcTf+RDUT5mDoht8L=UtvXS7+vtF0DB3LMJaZA@mail.gmail.com>
Message-ID: <loom.20141014T041719-70@post.gmane.org>

Douglas Bates <bates at ...> writes:

> 
> It is best to send inquiries like this to the
> R-SIG-Mixed-Models at ... mailing list ...

  [snip]

> On Mon, Oct 13, 2014 at 8:46 AM, David Cox <dac64 at ...> wrote:
> 
> > Dear Professor Bates,
>

[snip]

> > I'm using lme to model the peptide sequences of a set of proteins for
> > cancer patients and healthy individuals. I want to
>  use the weights function
> > so that the peptide intensities are inversely weighted
> with the variance.
> > The higher the variance, the lower the weighting etc. As the peptide
> > intensities of cancer patients and healthy individuals
>  will be different, I
> > want to apply this weighting separately for each group.
> >
> > At the moment I've tried with a model like this for the 1st protein:
> >  Peptide Intensities ~ Covariates + Peptide Sequences + Group, random =
> > Sample Id, data = data, weights = ~ Group

  Shouldn't this be something like

  weights= varIdent(~1|Group)

?

I don't see that a raw formula will work in the "weights" function.
Picking up a copy of Pinheiro and Bates 2000 might be a good idea ...

  Ben Bolker


From bbolker at gmail.com  Tue Oct 14 04:25:41 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Oct 2014 02:25:41 +0000 (UTC)
Subject: [R-sig-ME] lme4 heteroscedasticity???
References: <4152C532A3804441A1228603786ADAE606B22489@MAIL-BF>
	<CAO7JsnSbzP++fHY5ji+5KY26sY_U+WL-fSxq5EvsD6dd8D1GKg@mail.gmail.com>
	<974F8095-C164-40FA-8AA8-A54BD35983AA@glasgow.ac.uk>
	<CAO7JsnQMbb+NentaZ5Co9QAtG+bjb=HFehonmT052z2q8vTFiw@mail.gmail.com>
	<495DC286-41A0-4830-8CB4-B98676E8B6E4@glasgow.ac.uk>
Message-ID: <loom.20141014T042026-20@post.gmane.org>

Paul Johnson <paul.johnson at ...> writes:


> I did this a few years ago for ~250 patients (nested within ~10
> hospitals) being assessed by 7 adjudicators, so roughly a 250 x 6
> table of crossed random effects. The aim was to look for differences
> in precision between clinicians rating patients on a symptoms
> scale. It did take a several minutes to fit on a server with 24 GB
> of RAM, and required a little fiddling with the control options, but
> was nevertheless worth the time and trouble. Looking back at my code
> (below), I find that your advice helped me to fit it, via a post of
> yours from 2004, for which thanks!

 Lots of details snipped (sorry).

  I just want to point that I think that this model (crossed random
effects with fixed-categorical-predictor-dependent heteroscedasticity)
*is* probably do-able, albeit with a bit of a hassle, in lme4, by
combining the following two tricks:

  (1) setting up dummy variables for group, as in the last example
shown in ?lmer
  (2) use the trick shown by Steve Walker at
https://github.com/lme4/lme4/issues/224 (this is in the context
of the flexLambda branch, but you don't need the flexLambda branch
for this example) of using an individual-level random effect, and
setting the weights large to effectively suppress the residual
variance term

  (Not enough time to put together a worked example -- sorry)

  Ben Bolker


From bbolker at gmail.com  Tue Oct 14 04:30:45 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Oct 2014 02:30:45 +0000 (UTC)
Subject: [R-sig-ME] Extracting weights from an lme object
References: <CAFJ9WUDAdRct65HRK3VCEjFzfY2p6-cTwiVTkGFwWVUuiSg1xw@mail.gmail.com>
Message-ID: <loom.20141014T042832-39@post.gmane.org>

robert bagchi <bagchi.r at ...> writes:

> 
> Dear list,
> 
  
  [snip]

> For example, if we make up some (simple) data
> 
> ## covariates
> n <-20
> dat <- data.frame(x=runif(n),grp=sample(letters[1:10], n, replace=T),
>                   wts=runif(n))
> dat$wts <- dat$wts/mean(dat$wts)
> 
> ## model matrices
> xmat <- model.matrix(~x, data=dat)
> zmat <- model.matrix(~0+grp, data=dat)
> ## effects
> beta <- c(0, 0)
> b <- rnorm(10)
> ## response
> dat$y <- rnorm(n=n, mean=xmat %*% beta + zmat %*% b, sd=sqrt(1/dat$wts))
> 
> ## we can then fit the model with
> require(nlme)
> 
> mod <- lme(y~x, random=~1|grp, weights=varFixed(value=~I(1/wts)),
>            data=dat)
> ## however, while we can extract the weights used during the model fitting
> with
> (getCovariate(mod$modelStruct$varStruct))
> 
> ## They are in a *different order* from those in the original data
> (1/dat$wts)
> 
> Does anyone know a fairly fool-proof way of getting the weights out in the
> same format as went into the model?

  Don't know, but my guess is that lme is internally sorting the
weights by group (a way to test this would be to set up an example
with the data in group order and see if the order of the weights
remained unchanged).  If so, you could try to replicate the process
of ordering by group and figure out the inverse permutation required
to undo that ordering ...

  Ben Bolker


From bobyboby at gmail.com  Tue Oct 14 09:12:10 2014
From: bobyboby at gmail.com (Boby Mathew)
Date: Tue, 14 Oct 2014 09:12:10 +0200
Subject: [R-sig-ME] MCMCglmm user defined incidence matrix
Message-ID: <CAP-GiWbrgjXHiKCEFyEkCHFwMLBMr6epNW++vc1KQ4M5BRj8UQ@mail.gmail.com>

Dear MCMCglmm users,

Is it possible to pass a user specified incidence matrix in MCMCglmm.

thanks for the help.

regards,
Boby Mathew

-- 
Dr. Boby Mathew
INRES, University of Bonn
Katzenburgweg 5
Phone: 0228732031
53115, Bonn,Germany.

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue Oct 14 09:17:19 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 14 Oct 2014 10:17:19 +0300
Subject: [R-sig-ME] Fwd: lme4 heteroscedasticity???
In-Reply-To: <mailman.3757.1413216812.15062.r-sig-mixed-models@r-project.org>
References: <mailman.3757.1413216812.15062.r-sig-mixed-models@r-project.org>
Message-ID: <543CCDFF.2050909@highstat.com>







------------------------------

Message: 3
Date: Mon, 13 Oct 2014 10:17:54 -0500
From: Douglas Bates <bates at stat.wisc.edu>
To: David Cox <dac64 at cam.ac.uk>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] varFixed function query in lme
Message-ID:
	<CAO7JsnQpZhGyfcTf+RDUT5mDoht8L=UtvXS7+vtF0DB3LMJaZA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

It is best to send inquiries like this to the
R-SIG-Mixed-Models at R-project.org mailing list, which I am cc:ing on this
reply.  I am no longer the maintainer of the nlme package - I was pushed
aside by R Core many years ago and I really don't know what changes have
been made since they took over.

On Mon, Oct 13, 2014 at 8:46 AM, David Cox <dac64 at cam.ac.uk> wrote:

> Dear Professor Bates,
>
> I'm a neuroscience PhD student at Cambridge University. I saw that you
> maintain the 'varFixed' function for the 'weights' option in the nlme
> library. I have been reading the help manual but I'm a little stuck on a
> problem and wondered if you might have any quick suggestions.
>
> I'm using lme to model the peptide sequences of a set of proteins for
> cancer patients and healthy individuals. I want to use the weights function
> so that the peptide intensities are inversely weighted with the variance.
> The higher the variance, the lower the weighting etc. As the peptide
> intensities of cancer patients and healthy individuals will be different, I
> want to apply this weighting separately for each group.
>
> At the moment I've tried with a model like this for the 1st protein:
>  Peptide Intensities ~ Covariates + Peptide Sequences + Group, random =
> Sample Id, data = data, weights = ~ Group
>
> Group denotes whether each intensity is a cancer patient/healthy person.
> Sample id is the id of each cancer/healthy sample.
>
> This doesn't work though. I get an error saying: "Error in
> Math.factor(attr(object, "covariate")) :    abs not meaningful for factors."
>
> Many Thanks
>
> David Cox
>


This would be an easy exercise in JAGS or OpenBUGS. I believe there is a linear regression + multiple sigmas example (varIdent) in:

Introduction to WinBUGS for Ecologists: Bayesian approach to regression, ANOVA, mixed models and related analyses
Marc Kery

Adding two crossed random effects is not difficult neither.

Kind regards,

Alain


  





	[[alternative HTML version deleted]]


From martin.hecht at iqb.hu-berlin.de  Tue Oct 14 10:30:31 2014
From: martin.hecht at iqb.hu-berlin.de (Martin Hecht)
Date: Tue, 14 Oct 2014 10:30:31 +0200
Subject: [R-sig-ME] Problem with bootMer and models with offset
In-Reply-To: <loom.20141014T040507-42@post.gmane.org>
References: <543C07BB.50203@iqb.hu-berlin.de>
	<loom.20141014T040507-42@post.gmane.org>
Message-ID: <543CDF27.4090205@iqb.hu-berlin.de>

Am 14.10.2014 04:16, schrieb Ben Bolker:
> Martin Hecht <martin.hecht at ...> writes:
>
>>
>> Hi,
>>
>> I am using the latest version of R (3.1.1) and lme4 (1.1-7) .
>>
>> I'm getting some weird implausible bootstrap results from bootMer for a
>> model with an offset (models without offset work fine).
>>
>> I've attached an Rdata file with the returned object from lmer (lmerObj)
>> and the returned object from bootMer (booted)
>   Unfortunately, Rdata/RData files get stripped by the mailing list
> software (there's a short list of attachments that get allowed --
> I'm not sure how to find it -- probably includes txt and CSV files
> but not much else).
the data can be downloaded (for the next 28 days) here:
https://www3.hu-berlin.de/dateiaustausch?g=n2sqg2kpexkgv7n2n9uz
>
>> Any help would be appreciated very much.
>>
>> the syntax is:
>>
>> booted <- bootMer ( x = lmerObj , FUN =
>> function(fit){return(c(fixef(fit),getME(fit,'theta')))} , nsim = 100 ,
>> seed = 65835 , verbose = TRUE )
>>
>>> booted$t0[1]
>> (Intercept)
>>     2.606621
>>
>>> mean(booted$t[,1])
>> [1] -78.21035
>>
>>> boot::boot.ci ( booted , conf = 0.95 , type = "basic" , index = 1 )
>> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
>> Based on 100 bootstrap replicates
>>
>> CALL :
>> boot::boot.ci(boot.out = booted, conf = 0.95, type = "basic",
>>     index = 1)
>>
>> Intervals :
>> Level      Basic        
>> 95%   (69.864, 95.425 ) 
>> Calculations and Intervals on Original Scale
>> Some basic intervals may be unstable
>   This does indeed seem weird.
>
>   Does plot(booted,1) help at all?
the plot looks not that suspicious, except for the strange mean
>
>   I wonder if a workaround for now is to add the offset manually;
> that should be perfectly feasible (if not quite as convenient)
> for a linear mixed model -- it's only really *necessary* for
> a GLMM ...
adding the offset (43.8) manually won't work

thanks for your help!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Dipl.-Psych. Martin Hecht

Institut zur Qualit?tsentwicklung im Bildungswesen
Humboldt-Universit?t zu Berlin
Dienstsitz: Luisenstra?e 56
Postanschrift: Unter den Linden 6, 10099 Berlin

Tel: +49-(0)30 2093-46589
Fax: +49-(0)30 2093-5336
Email: martin.hecht at iqb.hu-berlin.de
www: http://www.iqb.hu-berlin.de

From martin.hecht at iqb.hu-berlin.de  Tue Oct 14 11:03:20 2014
From: martin.hecht at iqb.hu-berlin.de (Martin Hecht)
Date: Tue, 14 Oct 2014 11:03:20 +0200
Subject: [R-sig-ME] Problem with bootMer and models with offset
In-Reply-To: <543CDF27.4090205@iqb.hu-berlin.de>
References: <543C07BB.50203@iqb.hu-berlin.de>	<loom.20141014T040507-42@post.gmane.org>
	<543CDF27.4090205@iqb.hu-berlin.de>
Message-ID: <543CE6D8.6090405@iqb.hu-berlin.de>

Am 14.10.2014 10:30, schrieb Martin Hecht:
> Am 14.10.2014 04:16, schrieb Ben Bolker:
>> Martin Hecht <martin.hecht at ...> writes:
>>
>>> Hi,
>>>
>>> I am using the latest version of R (3.1.1) and lme4 (1.1-7) .
>>>
>>> I'm getting some weird implausible bootstrap results from bootMer for a
>>> model with an offset (models without offset work fine).
>>>
>>> I've attached an Rdata file with the returned object from lmer (lmerObj)
>>> and the returned object from bootMer (booted)
>>   Unfortunately, Rdata/RData files get stripped by the mailing list
>> software (there's a short list of attachments that get allowed --
>> I'm not sure how to find it -- probably includes txt and CSV files
>> but not much else).
> the data can be downloaded (for the next 28 days) here:
> https://www3.hu-berlin.de/dateiaustausch?g=n2sqg2kpexkgv7n2n9uz
>>> Any help would be appreciated very much.
>>>
>>> the syntax is:
>>>
>>> booted <- bootMer ( x = lmerObj , FUN =
>>> function(fit){return(c(fixef(fit),getME(fit,'theta')))} , nsim = 100 ,
>>> seed = 65835 , verbose = TRUE )
>>>
>>>> booted$t0[1]
>>> (Intercept)
>>>     2.606621
>>>
>>>> mean(booted$t[,1])
>>> [1] -78.21035
>>>
>>>> boot::boot.ci ( booted , conf = 0.95 , type = "basic" , index = 1 )
>>> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
>>> Based on 100 bootstrap replicates
>>>
>>> CALL :
>>> boot::boot.ci(boot.out = booted, conf = 0.95, type = "basic",
>>>     index = 1)
>>>
>>> Intervals :
>>> Level      Basic        
>>> 95%   (69.864, 95.425 ) 
>>> Calculations and Intervals on Original Scale
>>> Some basic intervals may be unstable
>>   This does indeed seem weird.
>>
>>   Does plot(booted,1) help at all?
> the plot looks not that suspicious, except for the strange mean
>>   I wonder if a workaround for now is to add the offset manually;
>> that should be perfectly feasible (if not quite as convenient)
>> for a linear mixed model -- it's only really *necessary* for
>> a GLMM ...
> adding the offset (43.8) manually won't work
I have now added the mean of the offset variable "Nitems.fixed" (81.7)
to the bootstrap values of the Intercept
booted2 <- booted
booted2$t[,1] <- booted2$t[,1] + mean(d2$Nitems.fixed)

this actually comes quite close the original model estimate of the
Intercept (and will probably converge with more runs)
booted2$t0[1]
(Intercept)
   2.606621

mean(booted2$t[,1])
  3.476917

still, now I am wondering how to manually correct the other fixed
effects (predictors)

for instance predictor "NAFmcC" has a model estimate of
booted2$t0[3]
   NAFmcC
  -24.41153

the mean from the bootstrap is
mean(booted2$t[,3])
  -67.93461

How can this be done?

>
> thanks for your help!
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Dipl.-Psych. Martin Hecht

Institut zur Qualit?tsentwicklung im Bildungswesen
Humboldt-Universit?t zu Berlin
Dienstsitz: Luisenstra?e 56
Postanschrift: Unter den Linden 6, 10099 Berlin

Tel: +49-(0)30 2093-46589
Fax: +49-(0)30 2093-5336
Email: martin.hecht at iqb.hu-berlin.de
www: http://www.iqb.hu-berlin.de


From bagchi.r at gmail.com  Tue Oct 14 14:51:29 2014
From: bagchi.r at gmail.com (robert bagchi)
Date: Tue, 14 Oct 2014 14:51:29 +0200
Subject: [R-sig-ME] Extracting weights from an lme object
Message-ID: <CAFJ9WUCpA9UAQa13=LNO3EFSwjiZy0ry2NZCJ8kaR8s0KAVMPg@mail.gmail.com>

Dear Dr Bolker,

Great - that worked perfectly. Thanks!

In case anyone needs to do this in the future, I am reliably getting the
weights in the correct order by doing

head(1/getCovariate(mod$modelStruct$varStruct)[order(order(getGroups(mod)))])

This seems to work fine for nested models too.

All the best,
Robi


>
> ---------- Forwarded message ----------
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Cc:
> Date: Tue, 14 Oct 2014 02:30:45 +0000 (UTC)
> Subject: Re: [R-sig-ME] Extracting weights from an lme object
> robert bagchi <bagchi.r at ...> writes:
>
> >
> > Dear list,
> >
>
>   [snip]
>
> > For example, if we make up some (simple) data
> >
> > ## covariates
> > n <-20
> > dat <- data.frame(x=runif(n),grp=sample(letters[1:10], n, replace=T),
> >                   wts=runif(n))
> > dat$wts <- dat$wts/mean(dat$wts)
> >
> > ## model matrices
> > xmat <- model.matrix(~x, data=dat)
> > zmat <- model.matrix(~0+grp, data=dat)
> > ## effects
> > beta <- c(0, 0)
> > b <- rnorm(10)
> > ## response
> > dat$y <- rnorm(n=n, mean=xmat %*% beta + zmat %*% b, sd=sqrt(1/dat$wts))
> >
> > ## we can then fit the model with
> > require(nlme)
> >
> > mod <- lme(y~x, random=~1|grp, weights=varFixed(value=~I(1/wts)),
> >            data=dat)
> > ## however, while we can extract the weights used during the model
> fitting
> > with
> > (getCovariate(mod$modelStruct$varStruct))
> >
> > ## They are in a *different order* from those in the original data
> > (1/dat$wts)
> >
> > Does anyone know a fairly fool-proof way of getting the weights out in
> the
> > same format as went into the model?
>
>   Don't know, but my guess is that lme is internally sorting the
> weights by group (a way to test this would be to set up an example
> with the data in group order and see if the order of the weights
> remained unchanged).  If so, you could try to replicate the process
> of ordering by group and figure out the inverse permutation required
> to undo that ordering ...
>
>   Ben Bolker
>
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Oct 14 16:05:52 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Oct 2014 14:05:52 +0000 (UTC)
Subject: [R-sig-ME] Problem with bootMer and models with offset
References: <543C07BB.50203@iqb.hu-berlin.de>	<loom.20141014T040507-42@post.gmane.org>
	<543CDF27.4090205@iqb.hu-berlin.de>
	<543CE6D8.6090405@iqb.hu-berlin.de>
Message-ID: <loom.20141014T155852-81@post.gmane.org>

Martin Hecht <martin.hecht at ...> writes:

> 
> Am 14.10.2014 10:30, schrieb Martin Hecht:
> > Am 14.10.2014 04:16, schrieb Ben Bolker:
> >> Martin Hecht <martin.hecht <at> ...> writes:
> >>
> >>> Hi,
> >>>
> >>> I am using the latest version of R (3.1.1) and lme4 (1.1-7) .
> >>>
> >>> I'm getting some weird implausible bootstrap results from bootMer for a
> >>> model with an offset (models without offset work fine).
> >>>

  OK, I think I see the problem here.  bootMer is able to handle
offsets correctly when they're written in the form

    y ~ x + (1|f) + offset(offset_term)

rather than

    y ~ x + (1|f) , offset=offset_term

(I so rarely use the second form that I forgot to check it -- I think
this is just a hole in bootMer).

  Can you see if that fixes your problem?

  Meanwhile, I will add a Github issue.


From martin.hecht at iqb.hu-berlin.de  Tue Oct 14 17:45:51 2014
From: martin.hecht at iqb.hu-berlin.de (Martin Hecht)
Date: Tue, 14 Oct 2014 17:45:51 +0200
Subject: [R-sig-ME] Problem with bootMer and models with offset
In-Reply-To: <loom.20141014T155852-81@post.gmane.org>
References: <543C07BB.50203@iqb.hu-berlin.de>	<loom.20141014T040507-42@post.gmane.org>	<543CDF27.4090205@iqb.hu-berlin.de>	<543CE6D8.6090405@iqb.hu-berlin.de>
	<loom.20141014T155852-81@post.gmane.org>
Message-ID: <543D452F.7050601@iqb.hu-berlin.de>


this resolved the issue
thanks a lot!!

Am 14.10.2014 16:05, schrieb Ben Bolker:
> Martin Hecht <martin.hecht at ...> writes:
>
>> Am 14.10.2014 10:30, schrieb Martin Hecht:
>>> Am 14.10.2014 04:16, schrieb Ben Bolker:
>>>> Martin Hecht <martin.hecht <at> ...> writes:
>>>>
>>>>> Hi,
>>>>>
>>>>> I am using the latest version of R (3.1.1) and lme4 (1.1-7) .
>>>>>
>>>>> I'm getting some weird implausible bootstrap results from bootMer for a
>>>>> model with an offset (models without offset work fine).
>>>>>
>   OK, I think I see the problem here.  bootMer is able to handle
> offsets correctly when they're written in the form
>
>     y ~ x + (1|f) + offset(offset_term)
>
> rather than
>
>     y ~ x + (1|f) , offset=offset_term
>
> (I so rarely use the second form that I forgot to check it -- I think
> this is just a hole in bootMer).
>
>   Can you see if that fixes your problem?
>
>   Meanwhile, I will add a Github issue.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Dipl.-Psych. Martin Hecht

Institut zur Qualit?tsentwicklung im Bildungswesen
Humboldt-Universit?t zu Berlin
Dienstsitz: Luisenstra?e 56
Postanschrift: Unter den Linden 6, 10099 Berlin

Tel: +49-(0)30 2093-46589
Fax: +49-(0)30 2093-5336
Email: martin.hecht at iqb.hu-berlin.de
www: http://www.iqb.hu-berlin.de


From mcasals at aspb.cat  Wed Oct 15 09:29:18 2014
From: mcasals at aspb.cat (=?UTF-8?Q?Mart=C3=AD_Casals?=)
Date: Wed, 15 Oct 2014 09:29:18 +0200
Subject: [R-sig-ME] Extract standard error of the variance component in lme4
	package (GLMM).
Message-ID: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>

Dear all,

I?ve fitted  a classical Poisson GLMM with lme4. I obtain the variance of
random effect (variance component) with the following script:


print(VarCorr(model),comp="Variance")


but I?d like to print the standard error of the variance component. I think
it is possible with the new version of the lme4 package. How it can be
obtain?



Thanks in advance,


Mart?



-- 
Mart? Casals Toquero

Centre d' Investigaci? Biom?dica d'Epidemiolog?a i Salut P?blica

Ag?ncia de Salut P?blica de Barcelona

Servei d' Epidemiologia

Tel. 932384545 extensi?: 365

mcasals at aspb.es

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Wed Oct 15 14:55:33 2014
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 15 Oct 2014 14:55:33 +0200
Subject: [R-sig-ME] comparing posterior means
In-Reply-To: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
Message-ID: <543E6EC5.6090106@maw.ru.nl>

Dear list,

Suppose we have the following two-level null-model, for data from 
respondents (lowest level 1) living in countries (highest level 2):

Y(ij) = b0j + eij = (b0 + u0j)  + eij

b0j is the country-mean for country j
b0 is the "grand mean"
u0j is the deviation from the grand mean for country j, or the level-2 
residual
eij is the level-1 residual

The model is estimated by :  lmer(Y ~ 1+(1|country))

My question is about comparing two particular posterior country-means. 
As for as I know, for a given country j, the posterior mean is equal to 
bb0 + uu0j, where bb0 is the estimate of b0 and uu0j is the posterior 
residual estimate of u0j.

Two compare two particular posterior country means and test whether they 
differ significantly, would it be necessary to know the variance of 
bb0+uu0j for each of the two countries, or would it be sufficient to 
only know the variance of uu0j?

The latter variance (of uu0j) can be extracted using

rr <- ranef(modela, condVar=TRUE)
attr(rr[[1]], "postVar")

However, the variance of bb0+uu0j also depends on the variance of bb0 
and the covariance of bb0 and uu0j (if this covariance is not equal to 
zero, of course, which I don't know...).

On the other hand, the difference between two posterior country means 
for country A and B say, would
equal bb0 + u0A -(bb0 + u0B) = u0A - u0B meaning that I wouldn't need to 
worry about the variance of bb0.

So my main question is about comparing and testing the difference 
between two posterior country means. Thanks for any help,

Ben.


From steve.walker at utoronto.ca  Wed Oct 15 15:49:22 2014
From: steve.walker at utoronto.ca (Steve Walker)
Date: Wed, 15 Oct 2014 09:49:22 -0400
Subject: [R-sig-ME] Extract standard error of the variance component in
 lme4 package (GLMM).
In-Reply-To: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
Message-ID: <543E7B62.2020609@utoronto.ca>

The standard approach is to bootstrap the standard errors with 
`bootMer`.  But this can take a long time.

Is there a reason you want standard errors instead of confidence 
intervals?  If not, you could try profile confidence intervals.  Here is 
an example:

library(lme4)
data(grouseticks)

form <- TICKS~YEAR+scale(HEIGHT)+(1|BROOD)+(1|INDEX)+(1|LOCATION)
(m <- glmer(form, family = "poisson", data = grouseticks))
(cim <- confint(m, oldNames = FALSE))

## ------------------------------------------------------------
## Bootstraping takes a _long_ time, but does give you
## standard errors:
## ------------------------------------------------------------
## (bt <- bootMer(m, function(mm) VarCorr(mm)$BROOD[,], 100))
## sd(bt$t, na.rm = TRUE)
## ------------------------------------------------------------

Cheers,
Steve


On 2014-10-15, 3:29 AM, Mart? Casals wrote:
> Dear all,
>
> I?ve fitted  a classical Poisson GLMM with lme4. I obtain the variance of
> random effect (variance component) with the following script:
>
>
> print(VarCorr(model),comp="Variance")
>
>
> but I?d like to print the standard error of the variance component. I think
> it is possible with the new version of the lme4 package. How it can be
> obtain?
>
>
>
> Thanks in advance,
>
>
> Mart?
>
>
>


From bbolker at gmail.com  Wed Oct 15 15:54:30 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 15 Oct 2014 09:54:30 -0400
Subject: [R-sig-ME] Extract standard error of the variance component in
 lme4 package (GLMM).
In-Reply-To: <543E7B62.2020609@utoronto.ca>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
	<543E7B62.2020609@utoronto.ca>
Message-ID: <543E7C96.2000100@gmail.com>

  If you really want them (with all the warnings about their often being
bad summaries of the uncertainty), http://rpubs.com/bbolker/varwald
gives a fairly straightforward recipe for getting the Wald standard
errors of the random effects standard deviations and correlations.

On 14-10-15 09:49 AM, Steve Walker wrote:
> The standard approach is to bootstrap the standard errors with
> `bootMer`.  But this can take a long time.
> 
> Is there a reason you want standard errors instead of confidence
> intervals?  If not, you could try profile confidence intervals.  Here is
> an example:
> 
> library(lme4)
> data(grouseticks)
> 
> form <- TICKS~YEAR+scale(HEIGHT)+(1|BROOD)+(1|INDEX)+(1|LOCATION)
> (m <- glmer(form, family = "poisson", data = grouseticks))
> (cim <- confint(m, oldNames = FALSE))
> 
> ## ------------------------------------------------------------
> ## Bootstraping takes a _long_ time, but does give you
> ## standard errors:
> ## ------------------------------------------------------------
> ## (bt <- bootMer(m, function(mm) VarCorr(mm)$BROOD[,], 100))
> ## sd(bt$t, na.rm = TRUE)
> ## ------------------------------------------------------------
> 
> Cheers,
> Steve
> 
> 
> On 2014-10-15, 3:29 AM, Mart? Casals wrote:
>> Dear all,
>>
>> I?ve fitted  a classical Poisson GLMM with lme4. I obtain the variance of
>> random effect (variance component) with the following script:
>>
>>
>> print(VarCorr(model),comp="Variance")
>>
>>
>> but I?d like to print the standard error of the variance component. I
>> think
>> it is possible with the new version of the lme4 package. How it can be
>> obtain?
>>
>>
>>
>> Thanks in advance,
>>
>>
>> Mart?
>>
>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j.hadfield at ed.ac.uk  Wed Oct 15 16:22:07 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 15 Oct 2014 15:22:07 +0100
Subject: [R-sig-ME] MCMCglmm user defined incidence matrix
In-Reply-To: <CAP-GiWbrgjXHiKCEFyEkCHFwMLBMr6epNW++vc1KQ4M5BRj8UQ@mail.gmail.com>
References: <CAP-GiWbrgjXHiKCEFyEkCHFwMLBMr6epNW++vc1KQ4M5BRj8UQ@mail.gmail.com>
Message-ID: <20141015152207.33592gmmy4zasydc@www.staffmail.ed.ac.uk>

Hi Boby,

Probably the easiest way is to create your incidence matrix Z and then  
put it into your data frame:

your_data$Z<-Z

and then have random=~idv(Z)

If its a large incidence matrix the start up might be slow.

Cheers,

Jarrod





Quoting Boby Mathew <bobyboby at gmail.com> on Tue, 14 Oct 2014 09:12:10 +0200:

> Dear MCMCglmm users,
>
> Is it possible to pass a user specified incidence matrix in MCMCglmm.
>
> thanks for the help.
>
> regards,
> Boby Mathew
>
> --
> Dr. Boby Mathew
> INRES, University of Bonn
> Katzenburgweg 5
> Phone: 0228732031
> 53115, Bonn,Germany.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From emmanuel.curis at parisdescartes.fr  Wed Oct 15 16:24:21 2014
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 15 Oct 2014 16:24:21 +0200
Subject: [R-sig-ME] comparing posterior means
In-Reply-To: <543E6EC5.6090106@maw.ru.nl>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
	<543E6EC5.6090106@maw.ru.nl>
Message-ID: <20141015142421.GB30165@info124.pharmacie.univ-paris5.fr>

Hello,

This is only a very partial answer...

As your difference between countries j and k would be (b0j - b0k) =
(bb0 + u0j) - (bb0 + u0k) = (uu0j - uu0k), I guess only variances of uu0j
is needed, but I have no idea for the correlation between uu0j and uu0k.

However, I wonder if this test means anything: assuming that random
effects are Gaussian, you're (almost) certain that b0j will be
differents for different countries; the non-significance of the test
would only mean a lack of power.

Wouldnt' the fact that some differences may have practical interest
and some not be better investigated using approaches similar to
equivalence tests, by
 1) defining what is the minimal difference of practical interest
 2) building the confidence intervals of these differences and see if
    it is comprised or completely outside the above region?

Hope this may help

On Wed, Oct 15, 2014 at 02:55:33PM +0200, Ben Pelzer wrote:
? Dear list,
? 
? Suppose we have the following two-level null-model, for data from
? respondents (lowest level 1) living in countries (highest level 2):
? 
? Y(ij) = b0j + eij = (b0 + u0j)  + eij
? 
? b0j is the country-mean for country j
? b0 is the "grand mean"
? u0j is the deviation from the grand mean for country j, or the
? level-2 residual
? eij is the level-1 residual
? 
? The model is estimated by :  lmer(Y ~ 1+(1|country))
? 
? My question is about comparing two particular posterior
? country-means. As for as I know, for a given country j, the
? posterior mean is equal to bb0 + uu0j, where bb0 is the estimate of
? b0 and uu0j is the posterior residual estimate of u0j.
? 
? Two compare two particular posterior country means and test whether
? they differ significantly, would it be necessary to know the
? variance of bb0+uu0j for each of the two countries, or would it be
? sufficient to only know the variance of uu0j?
? 
? The latter variance (of uu0j) can be extracted using
? 
? rr <- ranef(modela, condVar=TRUE)
? attr(rr[[1]], "postVar")
? 
? However, the variance of bb0+uu0j also depends on the variance of
? bb0 and the covariance of bb0 and uu0j (if this covariance is not
? equal to zero, of course, which I don't know...).
? 
? On the other hand, the difference between two posterior country
? means for country A and B say, would
? equal bb0 + u0A -(bb0 + u0B) = u0A - u0B meaning that I wouldn't
? need to worry about the variance of bb0.
? 
? So my main question is about comparing and testing the difference
? between two posterior country means. Thanks for any help,
? 
? Ben.
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From HDoran at air.org  Wed Oct 15 16:30:02 2014
From: HDoran at air.org (Doran, Harold)
Date: Wed, 15 Oct 2014 14:30:02 +0000
Subject: [R-sig-ME] comparing posterior means
In-Reply-To: <543E6EC5.6090106@maw.ru.nl>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
	<543E6EC5.6090106@maw.ru.nl>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF31F331@DC1VEX10MB001.air.org>

Ben

Yes, you can do this comparison of the conditional means using the variance of the linear combination AND there is in fact a covariance term between them. I do not believe that covariance term between BLUPs is available in lmer (I wrote my own mixed model function that does spit this out, however).

Just to be didactic for a moment. Take a look at Henderson's equation(say at the link below)

http://en.wikipedia.org/wiki/Mixed_model

The covariance term between the blups that you would need comes from the lower right block of the leftmost matrix at the final solution. Lmer is not parameterized this way, so the comparison is not intended to show how that term would be extracted from lmer. Only to show that is does exist in the likelihood and can (conceivably) be extracted or computed from the terms given by lmer.



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Pelzer
Sent: Wednesday, October 15, 2014 8:56 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] comparing posterior means

Dear list,

Suppose we have the following two-level null-model, for data from respondents (lowest level 1) living in countries (highest level 2):

Y(ij) = b0j + eij = (b0 + u0j)  + eij

b0j is the country-mean for country j
b0 is the "grand mean"
u0j is the deviation from the grand mean for country j, or the level-2 residual eij is the level-1 residual

The model is estimated by :  lmer(Y ~ 1+(1|country))

My question is about comparing two particular posterior country-means. 
As for as I know, for a given country j, the posterior mean is equal to
bb0 + uu0j, where bb0 is the estimate of b0 and uu0j is the posterior residual estimate of u0j.

Two compare two particular posterior country means and test whether they differ significantly, would it be necessary to know the variance of 
bb0+uu0j for each of the two countries, or would it be sufficient to
only know the variance of uu0j?

The latter variance (of uu0j) can be extracted using

rr <- ranef(modela, condVar=TRUE)
attr(rr[[1]], "postVar")

However, the variance of bb0+uu0j also depends on the variance of bb0 
and the covariance of bb0 and uu0j (if this covariance is not equal to 
zero, of course, which I don't know...).

On the other hand, the difference between two posterior country means 
for country A and B say, would
equal bb0 + u0A -(bb0 + u0B) = u0A - u0B meaning that I wouldn't need to 
worry about the variance of bb0.

So my main question is about comparing and testing the difference 
between two posterior country means. Thanks for any help,

Ben.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Oct 15 17:20:07 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 15 Oct 2014 15:20:07 +0000 (UTC)
Subject: [R-sig-ME] confidence intervals for random slopes
References: <1691693583.3097022.1407678920732.JavaMail.zimbra@agrar.mta.hu>
	<1547889392.3097072.1407680097073.JavaMail.zimbra@agrar.mta.hu>
	<loom.20140813T110813-314@post.gmane.org>
Message-ID: <loom.20141015T171607-810@post.gmane.org>

Veronika Bokony <bokony.veronika at ...> writes:

> 
> Dear all,
> thank you very much for the responses. With Ben Bolker's example I can now 
> calculate the SD for each of my random slopes. I have one remaining 
> question though: how do I turn these into SE? Do I use the sample size per 
> each level of random factor? (I have different sample size for 
> each "subject".) Or is it more tricky with these mixed models?
> Thanks and bests,
> Veronika

  Sorry this fell through the cracks.

  These standard deviations are standard deviations *of the estimates*,
or in other words they're more or less equivalent to SE already.  So you 
should just use +/- 1.96 SD (or whatever width you want).  One property
(that you could consider as a bug or a feature) of the mixed model 
estimation is that, unlike if you were to fit a linear regression to
the slopes individually (in which case you would get different SDs for
each slope, and they would indeed be inversely proportional to the
sample size for the subject), a pooled estimate of the uncertainty is
used, so all the slopes have the same SD.


From esafai at essex.ac.uk  Wed Oct 15 14:15:24 2014
From: esafai at essex.ac.uk (Safaie, Ebrahim)
Date: Wed, 15 Oct 2014 12:15:24 +0000
Subject: [R-sig-ME] lme4
Message-ID: <4F5053EADA10AC40AAE0180D0F46ED79012BCAE88D@mbx1-node1.essex.ac.uk>

Dear Ben Bolker,
Thanks for the quick answer. Yes, I admit that I did not mention  my problem clearly and do apologize for that. It was just because I came across the same error messages in the Qs & As that I did when my package was updated.
I was using the earlier version of lme4 and did not have any problems with it. For instance, for the following code I came to the following calculation without any error messages. (my dependent variable is binary and fixed factors are categorical)
summary(mod.15<-glmer(ErrorRate~1 +cgroup*cgrammaticality*cHeadNoun*cVerbType+(1|itemF)+(1+grammaticality*HeadNoun*VerbType|participantF),data =e3,+ family="binomial",na.action=na.exclude))

Fixed effects:
                                           Estimate Std. Error z value Pr(>|z|)
(Intercept)                                 -1.9745     0.1274 -15.494  < 2e-16 ***
cgroup                                       1.5843     0.1789   8.854  < 2e-16 ***
cgrammaticality                              0.5245     0.2182   2.404   0.0162 *
cHeadNoun                                   -0.2720     0.1853  -1.468   0.1422
cVerbType                                    0.7591     0.2326   3.263   0.0011 **
cgroup:cgrammaticality                       1.5796     0.3586   4.404 1.06e-05 ***
cgroup:cHeadNoun                             0.0475     0.3537   0.134   0.8932
cgrammaticality:cHeadNoun                    0.5368     0.4338   1.237   0.2159
cgroup:cVerbType                            -0.2441     0.3472  -0.703   0.4821
cgrammaticality:cVerbType                   -0.4861     0.4185  -1.162   0.2454
cHeadNoun:cVerbType                         -0.1563     0.3969  -0.394   0.6936
cgroup:cgrammaticality:cHeadNoun             0.2659     0.7161   0.371   0.7104
cgroup:cgrammaticality:cVerbType            -0.4691     0.6945  -0.675   0.4994
cgroup:cHeadNoun:cVerbType                   0.7661     0.6916   1.108   0.2679
cgrammaticality:cHeadNoun:cVerbType          0.9104     0.9147   0.995   0.3196
cgroup:cgrammaticality:cHeadNoun:cVerbType   3.1326     1.3994   2.239   0.0252 *




But as soon as I updated the package to a new version , for the same code I got the following error message and some calculations are not matched with the those with the earlier version (as shown below). I don't know exactly which version was the previous one, but I guess I was using 2013 packages

Warning messages:
1: In commonArgs(par, fn, control, environment()) :
  maxfun < 10 * length(par)^2 is not recommended.
2: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
3: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
  failure to converge in 10000 evaluations
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.0928109 (tol = 0.001, component 28)
5: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues




Fixed effects:
                                           Estimate Std. Error z value Pr(>|z|)
(Intercept)                                -1.97217    0.13810 -14.281  < 2e-16 ***
cgroup                                      1.58614    0.18262   8.686  < 2e-16 ***
cgrammaticality                             0.52725    0.24544   2.148   0.0317 *
cHeadNoun                                  -0.28061    0.21350  -1.314   0.1887
cVerbType                                   0.75503    0.25615   2.948   0.0032 **
cgroup:cgrammaticality                      1.57010    0.36695   4.279 1.88e-05 ***
cgroup:cHeadNoun                            0.05736    0.36138   0.159   0.8739
cgrammaticality:cHeadNoun                   0.55238    0.47616   1.160   0.2460
cgroup:cVerbType                           -0.24665    0.35618  -0.692   0.4886
cgrammaticality:cVerbType                  -0.49272    0.45732  -1.077   0.2813
cHeadNoun:cVerbType                        -0.14235    0.44553  -0.319   0.7493
cgroup:cgrammaticality:cHeadNoun            0.24468    0.73223   0.334   0.7383
cgroup:cgrammaticality:cVerbType           -0.45695    0.70627  -0.647   0.5176
cgroup:cHeadNoun:cVerbType                  0.75837    0.70763   1.072   0.2839
cgrammaticality:cHeadNoun:cVerbType         0.88375    0.98856   0.894   0.3713
cgroup:cgrammaticality:cHeadNoun:cVerbType  3.15344    1.42351   2.215   0.0267 *

My suggestion:
Because I am using Rstudio I have just two options when I want to install or to update packages. When I use CRAN and let Rstudio install lme4 automatically it  installs the most recent one. As such, it downloads the new package of lme4 which is problematic as I understand (sorry I might be wrong for that because I don't have any expertise but I'm talking from my observations)
So my suggestion is that let the earlier version of lme4 be on the CRAN such that when users are installing they automatically install the one which was not problematic.
Another option for me to download the earlier version and to install from my pc. But when I use this option from Rstudio, lme4 does not install and come with the following message.

install.packages("~/lme4_1.0-4.tar.gz", repos = NULL, type = "source")
Installing package into 'C:/Users/Azad/Documents/R/win-library/3.0'
(as 'lib' is unspecified)
* installing *source* package 'lme4' ...
** package 'lme4' successfully unpacked and MD5 sums checked
** libs


Sorry for the inconvenience and hope that  I've made things clear now.
Best wishes
Ebrahim


	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Wed Oct 15 18:36:57 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 15 Oct 2014 11:36:57 -0500
Subject: [R-sig-ME] comparing posterior means
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF31F331@DC1VEX10MB001.air.org>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
	<543E6EC5.6090106@maw.ru.nl>
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF31F331@DC1VEX10MB001.air.org>
Message-ID: <CAO7JsnT7BO0EufXYnbd=NkRwz5J38NnbC-isKQiRxdx_-Uoc-Q@mail.gmail.com>

On Wed, Oct 15, 2014 at 9:30 AM, Doran, Harold <HDoran at air.org> wrote:

> Ben
>
> Yes, you can do this comparison of the conditional means using the
> variance of the linear combination AND there is in fact a covariance term
> between them. I do not believe that covariance term between BLUPs is
> available in lmer (I wrote my own mixed model function that does spit this
> out, however).
>
> Just to be didactic for a moment. Take a look at Henderson's equation(say
> at the link below)
>
> http://en.wikipedia.org/wiki/Mixed_model
>
> The covariance term between the blups that you would need comes from the
> lower right block of the leftmost matrix at the final solution. Lmer is not
> parameterized this way, so the comparison is not intended to show how that
> term would be extracted from lmer. Only to show that is does exist in the
> likelihood and can (conceivably) be extracted or computed from the terms
> given by lmer.
>

I would disagree, Harold, about the relationship between the formulation
used in lmer and that in Henderson's mixed model equations.  There is a
strong relationship, which is explicitly shown in
http://arxiv.org/abs/1406.5823

Also shown there is why the modifications from Henderson's formulation to
that in lmer lead to flexibility in model formulation and much greater
speed and stability in fitting such models.  Reversing the positions of the
random effects and fixed effects in the penalized least squares problem and
using a relative covariance factor instead of the covariance matrix allows
for the profiled log-likelihood or profiled REML criterion to be evaluated.
Furthermore, they allow for the sparse Cholesky decomposition to be used
effectively.  (Henderson's formulation does do as good a job of preserving
sparsity.)

I believe you want the conditional variance-covariance matrix for the
random effects given the observed data and the parameter values.  The
sparse Cholesky factor L is the Cholesky factor of that
variance-covariance, up to the scale factor.  It is, in fact more stable to
work with the factor L than to try to evaluate the variance-covariance
matrix itself.

I'm happy to flesh this out in private correspondence if you wish.

>
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Pelzer
> Sent: Wednesday, October 15, 2014 8:56 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] comparing posterior means
>
> Dear list,
>
> Suppose we have the following two-level null-model, for data from
> respondents (lowest level 1) living in countries (highest level 2):
>
> Y(ij) = b0j + eij = (b0 + u0j)  + eij
>
> b0j is the country-mean for country j
> b0 is the "grand mean"
> u0j is the deviation from the grand mean for country j, or the level-2
> residual eij is the level-1 residual
>
> The model is estimated by :  lmer(Y ~ 1+(1|country))
>
> My question is about comparing two particular posterior country-means.
> As for as I know, for a given country j, the posterior mean is equal to
> bb0 + uu0j, where bb0 is the estimate of b0 and uu0j is the posterior
> residual estimate of u0j.
>
> Two compare two particular posterior country means and test whether they
> differ significantly, would it be necessary to know the variance of
> bb0+uu0j for each of the two countries, or would it be sufficient to
> only know the variance of uu0j?
>
> The latter variance (of uu0j) can be extracted using
>
> rr <- ranef(modela, condVar=TRUE)
> attr(rr[[1]], "postVar")
>
> However, the variance of bb0+uu0j also depends on the variance of bb0
> and the covariance of bb0 and uu0j (if this covariance is not equal to
> zero, of course, which I don't know...).
>
> On the other hand, the difference between two posterior country means
> for country A and B say, would
> equal bb0 + u0A -(bb0 + u0B) = u0A - u0B meaning that I wouldn't need to
> worry about the variance of bb0.
>
> So my main question is about comparing and testing the difference
> between two posterior country means. Thanks for any help,
>
> Ben.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From HDoran at air.org  Wed Oct 15 19:24:22 2014
From: HDoran at air.org (Doran, Harold)
Date: Wed, 15 Oct 2014 17:24:22 +0000
Subject: [R-sig-ME] comparing posterior means
In-Reply-To: <CAO7JsnT7BO0EufXYnbd=NkRwz5J38NnbC-isKQiRxdx_-Uoc-Q@mail.gmail.com>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
	<543E6EC5.6090106@maw.ru.nl>
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF31F331@DC1VEX10MB001.air.org>
	<CAO7JsnT7BO0EufXYnbd=NkRwz5J38NnbC-isKQiRxdx_-Uoc-Q@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF320744@DC1VEX10MB001.air.org>

Doug:

I grab the variance/covariance matrix of the random effects in a way that I think will make you cringe, but will share it here and am interested in learning how it can be done more efficiently. Keep in mind basically two principles. First, my lme.eiv function (which stands for linear mixed model error-in-variables) uses henderson?s equations as typically described and then stands on your shoulders and uses almost all of the functions in the Matrix package for sparse matrices.

BTW, though my function is not available in a package, I am happy to share it with you. It has complete technical documentation and is written using S3 methods with various common extractor functions typically used (and more). The function is intended to be used when the variables on the RHS are measured with error. Otherwise, my function simply matches lmer?s output.

So, let me use the following to represent the linear model as

Xb = y

Assume X is the leftmost matrix in henderson?s equation (so it is a big 2x2 blocked matrix), b is a vector holding both the fixed and random effects, and y is the outcome. The matrix X is big (and very sparse in my applications) and so I find its Cholesky decomposition and then simply solve the triangular systems until a solution is reached.

After a solution is reached (here is where you will cringe), I find the inverse of the big matrix X as

mat1.inv <- solve(L, I)

where L is the Cholesky factor of X and I is a conformable identity matrix. This, in essence, finds the inverse of the big matrix X, and then I can grab the variances and covariances of everything I need from this after the solution is reached.

Harold



From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Wednesday, October 15, 2014 12:37 PM
To: Doran, Harold
Cc: Ben Pelzer; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] comparing posterior means

On Wed, Oct 15, 2014 at 9:30 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
Ben

Yes, you can do this comparison of the conditional means using the variance of the linear combination AND there is in fact a covariance term between them. I do not believe that covariance term between BLUPs is available in lmer (I wrote my own mixed model function that does spit this out, however).

Just to be didactic for a moment. Take a look at Henderson's equation(say at the link below)

http://en.wikipedia.org/wiki/Mixed_model

The covariance term between the blups that you would need comes from the lower right block of the leftmost matrix at the final solution. Lmer is not parameterized this way, so the comparison is not intended to show how that term would be extracted from lmer. Only to show that is does exist in the likelihood and can (conceivably) be extracted or computed from the terms given by lmer.

I would disagree, Harold, about the relationship between the formulation used in lmer and that in Henderson's mixed model equations.  There is a strong relationship, which is explicitly shown in http://arxiv.org/abs/1406.5823

Also shown there is why the modifications from Henderson's formulation to that in lmer lead to flexibility in model formulation and much greater speed and stability in fitting such models.  Reversing the positions of the random effects and fixed effects in the penalized least squares problem and using a relative covariance factor instead of the covariance matrix allows for the profiled log-likelihood or profiled REML criterion to be evaluated. Furthermore, they allow for the sparse Cholesky decomposition to be used effectively.  (Henderson's formulation does do as good a job of preserving sparsity.)

I believe you want the conditional variance-covariance matrix for the random effects given the observed data and the parameter values.  The sparse Cholesky factor L is the Cholesky factor of that variance-covariance, up to the scale factor.  It is, in fact more stable to work with the factor L than to try to evaluate the variance-covariance matrix itself.

I'm happy to flesh this out in private correspondence if you wish.



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org> [mailto:r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>] On Behalf Of Ben Pelzer
Sent: Wednesday, October 15, 2014 8:56 AM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] comparing posterior means

Dear list,

Suppose we have the following two-level null-model, for data from respondents (lowest level 1) living in countries (highest level 2):

Y(ij) = b0j + eij = (b0 + u0j)  + eij

b0j is the country-mean for country j
b0 is the "grand mean"
u0j is the deviation from the grand mean for country j, or the level-2 residual eij is the level-1 residual

The model is estimated by :  lmer(Y ~ 1+(1|country))

My question is about comparing two particular posterior country-means.
As for as I know, for a given country j, the posterior mean is equal to
bb0 + uu0j, where bb0 is the estimate of b0 and uu0j is the posterior residual estimate of u0j.

Two compare two particular posterior country means and test whether they differ significantly, would it be necessary to know the variance of
bb0+uu0j for each of the two countries, or would it be sufficient to
only know the variance of uu0j?

The latter variance (of uu0j) can be extracted using

rr <- ranef(modela, condVar=TRUE)
attr(rr[[1]], "postVar")

However, the variance of bb0+uu0j also depends on the variance of bb0
and the covariance of bb0 and uu0j (if this covariance is not equal to
zero, of course, which I don't know...).

On the other hand, the difference between two posterior country means
for country A and B say, would
equal bb0 + u0A -(bb0 + u0B) = u0A - u0B meaning that I wouldn't need to
worry about the variance of bb0.

So my main question is about comparing and testing the difference
between two posterior country means. Thanks for any help,

Ben.

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Wed Oct 15 20:16:28 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 15 Oct 2014 13:16:28 -0500
Subject: [R-sig-ME] comparing posterior means
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF320744@DC1VEX10MB001.air.org>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
	<543E6EC5.6090106@maw.ru.nl>
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF31F331@DC1VEX10MB001.air.org>
	<CAO7JsnT7BO0EufXYnbd=NkRwz5J38NnbC-isKQiRxdx_-Uoc-Q@mail.gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF320744@DC1VEX10MB001.air.org>
Message-ID: <CAO7JsnQmW57_d0nwFTW3-Qm93JN=cDLZJJ5VO72j9m4jFsJXXw@mail.gmail.com>

On Wed, Oct 15, 2014 at 12:24 PM, Doran, Harold <HDoran at air.org> wrote:

>  Doug:
>
>
>
> I grab the variance/covariance matrix of the random effects in a way that
> I think will make you cringe, but will share it here and am interested in
> learning how it can be done more efficiently. Keep in mind basically two
> principles. First, my lme.eiv function (which stands for linear mixed model
> error-in-variables) uses henderson?s equations as typically described and
> then stands on your shoulders and uses almost all of the functions in the
> Matrix package for sparse matrices.
>
>
>
> BTW, though my function is not available in a package, I am happy to share
> it with you. It has complete technical documentation and is written using
> S3 methods with various common extractor functions typically used (and
> more). The function is intended to be used when the variables on the RHS
> are measured with error. Otherwise, my function simply matches lmer?s
> output.
>
>
>
> So, let me use the following to represent the linear model as
>
>
>
> Xb = y
>
>
>
> Assume X is the leftmost matrix in henderson?s equation (so it is a big
> 2x2 blocked matrix), b is a vector holding both the fixed and random
> effects, and y is the outcome. The matrix X is big (and very sparse in my
> applications) and so I find its Cholesky decomposition and then simply
> solve the triangular systems until a solution is reached.
>

I think I am missing a couple of steps here.  Henderson's mixed model
equations, as described, say, in the Wikipedia entry, are a set of
penalized normal equations.  That is, they look like

X'X b = X'y

but with a block structure and with a penalty on the random effects
crossproduct matrix.  In the Wikipedia article the lower right block is
written as Z'R^{-1}Z + G^{-1} and I would describe G^{-1} as the penalty
term in that it penalizes large values of the coefficients b.

In lmer a similar penalized least squares (PLS) problem is solved for each
evaluation of the profiled log-likelihood or profiled REML criterion.  The
difference is that instead of solving for the conditional means of the
random effects on the original scale we solve for the conditional means of
the "spherical" random effects.  Also, the order of the coefficients in the
PLS problem is switched so that the random effects come before the fixed
effects. Doing things this way allows for evaluation of the evaluation of
the profiled log-likelihood from the determinant of the sparse Cholesky
factor and the penalized residual sum-of-squares (equations 34 and 41, for
REML) in the paper on arxiv.org.

>
>
> After a solution is reached (here is where you will cringe), I find the
> inverse of the big matrix X as
>
>
>
> mat1.inv <- solve(L, I)
>
>
>
> where L is the Cholesky factor of X and I is a conformable identity
> matrix. This, in essence, finds the inverse of the big matrix X, and then I
> can grab the variances and covariances of everything I need from this after
> the solution is reached.
>

You're right.  I did cringe.  At the risk of sounding like a broken record
you really don't need to calculate the inverse of that large, sparse matrix
to get the information you want.  At most you have to solve block by block.

I'm currently doing something similar in the Julia implementation.  The
aforementioned arxiv.org paper gives expressions for the gradient of the
profiled log-likelihood.  It can be a big win to evaluate the analytic
gradient when optimizing the criterion.  The only problem is that you need
to do nearly as much work to evaluate the gradient as to invert the big
matrix.  Many years ago when Saikat and I derived those expressions I
thought it was great and coded up the optimization using that.  I fit a
model to a large, complex data set using only the function evaluation,
which took a couple of hours. Then I started it again using the gradient
evaluation, eagerly anticipating how fast it would be.  I watched and
watched and eventually went to bed because it was taking so long.  The next
morning I got up to find that it had completed one iteration in twelve
hours.

It is possible to do that evaluation for certain model types, but the
general evaluation by just pushing it into a sparse matrix calculation can
be formidable.  The Julia implementation does use the gradient but only for
models with nested grouping factors (and that is not yet complete) or for
models with two crossed or nearly crossed grouping factors.

So in terms of the original question, it would be reasonable to evaluate
the conditional covariance of the random effects under similar designs -
either nested grouping factors, which includes, as a trivial case, a single
grouping factor, or crossed grouping factors.  In the latter case, however,
the covariance matrix will be large and dense so you may question whether
it is really important to evaluate it.  I can make sense of 2 by 2
covariance matrices and maybe 3 by 3 but 85 by 85 dense covariance matrices
are difficult for me to interpret.




> *From:* dmbates at gmail.com [mailto:dmbates at gmail.com] *On Behalf Of *Douglas
> Bates
> *Sent:* Wednesday, October 15, 2014 12:37 PM
> *To:* Doran, Harold
> *Cc:* Ben Pelzer; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] comparing posterior means
>
>
>
> On Wed, Oct 15, 2014 at 9:30 AM, Doran, Harold <HDoran at air.org> wrote:
>
> Ben
>
> Yes, you can do this comparison of the conditional means using the
> variance of the linear combination AND there is in fact a covariance term
> between them. I do not believe that covariance term between BLUPs is
> available in lmer (I wrote my own mixed model function that does spit this
> out, however).
>
> Just to be didactic for a moment. Take a look at Henderson's equation(say
> at the link below)
>
> http://en.wikipedia.org/wiki/Mixed_model
>
> The covariance term between the blups that you would need comes from the
> lower right block of the leftmost matrix at the final solution. Lmer is not
> parameterized this way, so the comparison is not intended to show how that
> term would be extracted from lmer. Only to show that is does exist in the
> likelihood and can (conceivably) be extracted or computed from the terms
> given by lmer.
>
>
>
> I would disagree, Harold, about the relationship between the formulation
> used in lmer and that in Henderson's mixed model equations.  There is a
> strong relationship, which is explicitly shown in
> http://arxiv.org/abs/1406.5823
>
>
>
> Also shown there is why the modifications from Henderson's formulation to
> that in lmer lead to flexibility in model formulation and much greater
> speed and stability in fitting such models.  Reversing the positions of the
> random effects and fixed effects in the penalized least squares problem and
> using a relative covariance factor instead of the covariance matrix allows
> for the profiled log-likelihood or profiled REML criterion to be evaluated.
> Furthermore, they allow for the sparse Cholesky decomposition to be used
> effectively.  (Henderson's formulation does do as good a job of preserving
> sparsity.)
>
>
>
> I believe you want the conditional variance-covariance matrix for the
> random effects given the observed data and the parameter values.  The
> sparse Cholesky factor L is the Cholesky factor of that
> variance-covariance, up to the scale factor.  It is, in fact more stable to
> work with the factor L than to try to evaluate the variance-covariance
> matrix itself.
>
>
>
> I'm happy to flesh this out in private correspondence if you wish.
>
>
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Pelzer
> Sent: Wednesday, October 15, 2014 8:56 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] comparing posterior means
>
> Dear list,
>
> Suppose we have the following two-level null-model, for data from
> respondents (lowest level 1) living in countries (highest level 2):
>
> Y(ij) = b0j + eij = (b0 + u0j)  + eij
>
> b0j is the country-mean for country j
> b0 is the "grand mean"
> u0j is the deviation from the grand mean for country j, or the level-2
> residual eij is the level-1 residual
>
> The model is estimated by :  lmer(Y ~ 1+(1|country))
>
> My question is about comparing two particular posterior country-means.
> As for as I know, for a given country j, the posterior mean is equal to
> bb0 + uu0j, where bb0 is the estimate of b0 and uu0j is the posterior
> residual estimate of u0j.
>
> Two compare two particular posterior country means and test whether they
> differ significantly, would it be necessary to know the variance of
> bb0+uu0j for each of the two countries, or would it be sufficient to
> only know the variance of uu0j?
>
> The latter variance (of uu0j) can be extracted using
>
> rr <- ranef(modela, condVar=TRUE)
> attr(rr[[1]], "postVar")
>
> However, the variance of bb0+uu0j also depends on the variance of bb0
> and the covariance of bb0 and uu0j (if this covariance is not equal to
> zero, of course, which I don't know...).
>
> On the other hand, the difference between two posterior country means
> for country A and B say, would
> equal bb0 + u0A -(bb0 + u0B) = u0A - u0B meaning that I wouldn't need to
> worry about the variance of bb0.
>
> So my main question is about comparing and testing the difference
> between two posterior country means. Thanks for any help,
>
> Ben.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Wed Oct 15 21:05:16 2014
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 15 Oct 2014 21:05:16 +0200
Subject: [R-sig-ME] comparing posterior means
In-Reply-To: <CAO7JsnQmW57_d0nwFTW3-Qm93JN=cDLZJJ5VO72j9m4jFsJXXw@mail.gmail.com>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>	<543E6EC5.6090106@maw.ru.nl>	<B08B6AF0CF8CA44F81B9983EEBDCD686CF31F331@DC1VEX10MB001.air.org>	<CAO7JsnT7BO0EufXYnbd=NkRwz5J38NnbC-isKQiRxdx_-Uoc-Q@mail.gmail.com>	<B08B6AF0CF8CA44F81B9983EEBDCD686CF320744@DC1VEX10MB001.air.org>
	<CAO7JsnQmW57_d0nwFTW3-Qm93JN=cDLZJJ5VO72j9m4jFsJXXw@mail.gmail.com>
Message-ID: <543EC56C.3040309@maw.ru.nl>

Dear Douglas, Harold and Emmanuel,

The rather technical discussion is difficult to follow for me and I 
still feel unsure about what the right answer is to my question. To test 
the difference between the two posterior means, does it make sense to 
test for the difference of the two random effects , u0A-u0B, and use the 
(co)variances of both to test H0: u0A - u0B = 0? Or should the variance 
of the fixed effect b0 also be taken into account (which I now believe 
is not needed)? Please help me. Humble regards,

Ben.


On 15-10-2014 20:16, Douglas Bates wrote:
> On Wed, Oct 15, 2014 at 12:24 PM, Doran, Harold <HDoran at air.org 
> <mailto:HDoran at air.org>> wrote:
>
>     Doug:
>
>     I grab the variance/covariance matrix of the random effects in a
>     way that I think will make you cringe, but will share it here and
>     am interested in learning how it can be done more efficiently.
>     Keep in mind basically two principles. First, my lme.eiv function
>     (which stands for linear mixed model error-in-variables) uses
>     henderson's equations as typically described and then stands on
>     your shoulders and uses almost all of the functions in the Matrix
>     package for sparse matrices.
>
>     BTW, though my function is not available in a package, I am happy
>     to share it with you. It has complete technical documentation and
>     is written using S3 methods with various common extractor
>     functions typically used (and more). The function is intended to
>     be used when the variables on the RHS are measured with error.
>     Otherwise, my function simply matches lmer's output.
>
>     So, let me use the following to represent the linear model as
>
>     Xb = y
>
>     Assume X is the leftmost matrix in henderson's equation (so it is
>     a big 2x2 blocked matrix), b is a vector holding both the fixed
>     and random effects, and y is the outcome. The matrix X is big (and
>     very sparse in my applications) and so I find its Cholesky
>     decomposition and then simply solve the triangular systems until a
>     solution is reached.
>
>
> I think I am missing a couple of steps here. Henderson's mixed model 
> equations, as described, say, in the Wikipedia entry, are a set of 
> penalized normal equations.  That is, they look like
>
> X'X b = X'y
>
> but with a block structure and with a penalty on the random effects 
> crossproduct matrix.  In the Wikipedia article the lower right block 
> is written as Z'R^{-1}Z + G^{-1} and I would describe G^{-1} as the 
> penalty term in that it penalizes large values of the coefficients b.
>
> In lmer a similar penalized least squares (PLS) problem is solved for 
> each evaluation of the profiled log-likelihood or profiled REML 
> criterion.  The difference is that instead of solving for the 
> conditional means of the random effects on the original scale we solve 
> for the conditional means of the "spherical" random effects. Also, the 
> order of the coefficients in the PLS problem is switched so that the 
> random effects come before the fixed effects. Doing things this way 
> allows for evaluation of the evaluation of the profiled log-likelihood 
> from the determinant of the sparse Cholesky factor and the penalized 
> residual sum-of-squares (equations 34 and 41, for REML) in the paper 
> on arxiv.org <http://arxiv.org>.
>
>     After a solution is reached (here is where you will cringe), I
>     find the inverse of the big matrix X as
>
>     mat1.inv <- solve(L, I)
>
>     where L is the Cholesky factor of X and I is a conformable
>     identity matrix. This, in essence, finds the inverse of the big
>     matrix X, and then I can grab the variances and covariances of
>     everything I need from this after the solution is reached.
>
>
> You're right.  I did cringe.  At the risk of sounding like a broken 
> record you really don't need to calculate the inverse of that large, 
> sparse matrix to get the information you want.  At most you have to 
> solve block by block.
>
> I'm currently doing something similar in the Julia implementation.  
> The aforementioned arxiv.org <http://arxiv.org> paper gives 
> expressions for the gradient of the profiled log-likelihood.  It can 
> be a big win to evaluate the analytic gradient when optimizing the 
> criterion.  The only problem is that you need to do nearly as much 
> work to evaluate the gradient as to invert the big matrix.  Many years 
> ago when Saikat and I derived those expressions I thought it was great 
> and coded up the optimization using that.  I fit a model to a large, 
> complex data set using only the function evaluation, which took a 
> couple of hours. Then I started it again using the gradient 
> evaluation, eagerly anticipating how fast it would be.  I watched and 
> watched and eventually went to bed because it was taking so long.  The 
> next morning I got up to find that it had completed one iteration in 
> twelve hours.
>
> It is possible to do that evaluation for certain model types, but the 
> general evaluation by just pushing it into a sparse matrix calculation 
> can be formidable.  The Julia implementation does use the gradient but 
> only for models with nested grouping factors (and that is not yet 
> complete) or for models with two crossed or nearly crossed grouping 
> factors.
>
> So in terms of the original question, it would be reasonable to 
> evaluate the conditional covariance of the random effects under 
> similar designs - either nested grouping factors, which includes, as a 
> trivial case, a single grouping factor, or crossed grouping factors.  
> In the latter case, however, the covariance matrix will be large and 
> dense so you may question whether it is really important to evaluate 
> it.  I can make sense of 2 by 2 covariance matrices and maybe 3 by 3 
> but 85 by 85 dense covariance matrices are difficult for me to interpret.
>
>
>     *From:*dmbates at gmail.com <mailto:dmbates at gmail.com>
>     [mailto:dmbates at gmail.com <mailto:dmbates at gmail.com>] *On Behalf
>     Of *Douglas Bates
>     *Sent:* Wednesday, October 15, 2014 12:37 PM
>     *To:* Doran, Harold
>     *Cc:* Ben Pelzer; r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>     *Subject:* Re: [R-sig-ME] comparing posterior means
>
>     On Wed, Oct 15, 2014 at 9:30 AM, Doran, Harold <HDoran at air.org
>     <mailto:HDoran at air.org>> wrote:
>
>     Ben
>
>     Yes, you can do this comparison of the conditional means using the
>     variance of the linear combination AND there is in fact a
>     covariance term between them. I do not believe that covariance
>     term between BLUPs is available in lmer (I wrote my own mixed
>     model function that does spit this out, however).
>
>     Just to be didactic for a moment. Take a look at Henderson's
>     equation(say at the link below)
>
>     http://en.wikipedia.org/wiki/Mixed_model
>
>     The covariance term between the blups that you would need comes
>     from the lower right block of the leftmost matrix at the final
>     solution. Lmer is not parameterized this way, so the comparison is
>     not intended to show how that term would be extracted from lmer.
>     Only to show that is does exist in the likelihood and can
>     (conceivably) be extracted or computed from the terms given by lmer.
>
>     I would disagree, Harold, about the relationship between the
>     formulation used in lmer and that in Henderson's mixed model
>     equations.  There is a strong relationship, which is explicitly
>     shown in http://arxiv.org/abs/1406.5823
>
>     Also shown there is why the modifications from Henderson's
>     formulation to that in lmer lead to flexibility in model
>     formulation and much greater speed and stability in fitting such
>     models.  Reversing the positions of the random effects and fixed
>     effects in the penalized least squares problem and using a
>     relative covariance factor instead of the covariance matrix allows
>     for the profiled log-likelihood or profiled REML criterion to be
>     evaluated. Furthermore, they allow for the sparse Cholesky
>     decomposition to be used effectively.  (Henderson's formulation
>     does do as good a job of preserving sparsity.)
>
>     I believe you want the conditional variance-covariance matrix for
>     the random effects given the observed data and the parameter
>     values. The sparse Cholesky factor L is the Cholesky factor of
>     that variance-covariance, up to the scale factor.  It is, in fact
>     more stable to work with the factor L than to try to evaluate the
>     variance-covariance matrix itself.
>
>     I'm happy to flesh this out in private correspondence if you wish.
>
>
>
>
>         -----Original Message-----
>         From: r-sig-mixed-models-bounces at r-project.org
>         <mailto:r-sig-mixed-models-bounces at r-project.org>
>         [mailto:r-sig-mixed-models-bounces at r-project.org
>         <mailto:r-sig-mixed-models-bounces at r-project.org>] On Behalf
>         Of Ben Pelzer
>         Sent: Wednesday, October 15, 2014 8:56 AM
>         To: r-sig-mixed-models at r-project.org
>         <mailto:r-sig-mixed-models at r-project.org>
>         Subject: [R-sig-ME] comparing posterior means
>
>         Dear list,
>
>         Suppose we have the following two-level null-model, for data
>         from respondents (lowest level 1) living in countries (highest
>         level 2):
>
>         Y(ij) = b0j + eij = (b0 + u0j)  + eij
>
>         b0j is the country-mean for country j
>         b0 is the "grand mean"
>         u0j is the deviation from the grand mean for country j, or the
>         level-2 residual eij is the level-1 residual
>
>         The model is estimated by :  lmer(Y ~ 1+(1|country))
>
>         My question is about comparing two particular posterior
>         country-means.
>         As for as I know, for a given country j, the posterior mean is
>         equal to
>         bb0 + uu0j, where bb0 is the estimate of b0 and uu0j is the
>         posterior residual estimate of u0j.
>
>         Two compare two particular posterior country means and test
>         whether they differ significantly, would it be necessary to
>         know the variance of
>         bb0+uu0j for each of the two countries, or would it be
>         sufficient to
>         only know the variance of uu0j?
>
>         The latter variance (of uu0j) can be extracted using
>
>         rr <- ranef(modela, condVar=TRUE)
>         attr(rr[[1]], "postVar")
>
>         However, the variance of bb0+uu0j also depends on the variance
>         of bb0
>         and the covariance of bb0 and uu0j (if this covariance is not
>         equal to
>         zero, of course, which I don't know...).
>
>         On the other hand, the difference between two posterior
>         country means
>         for country A and B say, would
>         equal bb0 + u0A -(bb0 + u0B) = u0A - u0B meaning that I
>         wouldn't need to
>         worry about the variance of bb0.
>
>         So my main question is about comparing and testing the difference
>         between two posterior country means. Thanks for any help,
>
>         Ben.
>
>         _______________________________________________
>         R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         _______________________________________________
>         R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Oct 15 21:27:02 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 15 Oct 2014 15:27:02 -0400
Subject: [R-sig-ME]  lme4
Message-ID: <543ECA86.5050502@gmail.com>


> Dear Ben Bolker,
> 
> Thanks for the quick answer. Yes, I admit that I did not mention my
> problem clearly and do apologize for that. It was just because I came
> across the same error messages in the Qs & As that I did when my
> package was updated.  I was using the earlier version of lme4 and did
> not have any problems with it. For instance, for the following code I
> came to the following calculation without any error messages. (my
> dependent variable is binary and fixed factors are categorical)
> 
> summary(mod.15<-glmer(ErrorRate~1+
>    cgroup*cgrammaticality*cHeadNoun*cVerbType+(1|itemF)+
>     (1+grammaticality*HeadNoun*VerbType|participantF),data=e3,
>        family="binomial",na.action=na.exclude))

   Note that this is a very large (15*15) random-effects
variance-covariance matrix to estimate: I know that this is
recommended by Barr et al 2013, but see recent discussion
on this list, e.g.
http://article.gmane.org/gmane.comp.lang.r.lme4.devel/12492/

  It would be a good idea to check for a singular fit, i.e.

  t <- getME(mod.15,"theta")
  lwr <- getME(mod.15,"lower")
  any(t[lwr==0]< 1e-6)

> Fixed effects:
>                                            Estimate Std. Error z value Pr(>|z|)
> (Intercept)                                 -1.9745     0.1274 -15.494  < 2e-16 ***
> cgroup                                       1.5843     0.1789   8.854  < 2e-16 ***
> cgrammaticality                              0.5245     0.2182   2.404   0.0162 *
> cHeadNoun                                   -0.2720     0.1853  -1.468   0.1422
> cVerbType                                    0.7591     0.2326   3.263   0.0011 **
> cgroup:cgrammaticality                       1.5796     0.3586   4.404 1.06e-05 ***
> cgroup:cHeadNoun                             0.0475     0.3537   0.134   0.8932
> cgrammaticality:cHeadNoun                    0.5368     0.4338   1.237   0.2159
> cgroup:cVerbType                            -0.2441     0.3472  -0.703   0.4821
> cgrammaticality:cVerbType                   -0.4861     0.4185  -1.162   0.2454
> cHeadNoun:cVerbType                         -0.1563     0.3969  -0.394   0.6936
> cgroup:cgrammaticality:cHeadNoun             0.2659     0.7161   0.371   0.7104
> cgroup:cgrammaticality:cVerbType            -0.4691     0.6945  -0.675   0.4994
> cgroup:cHeadNoun:cVerbType                   0.7661     0.6916   1.108   0.2679
> cgrammaticality:cHeadNoun:cVerbType          0.9104     0.9147   0.995   0.3196
> cgroup:cgrammaticality:cHeadNoun:cVerbType   3.1326     1.3994   2.239   0.0252 *
> 
   These estimated effects look only very slightly different to me
than the ones below (i.e., only a few percent differences in point
estimates, always much smaller than the estimated standard error, and
no qualitative differences in Z/P values).  Can you specify whether
there are any differences that particularly concern you?

> 
> But as soon as I updated the package to a new version , for the same
> code I got the following error message and some calculations are not
> matched with the those with the earlier version (as shown below). I
> don't know exactly which version was the previous one, but I guess I
> was using 2013 packages
> 
> Warning messages:
> 1: In commonArgs(par, fn, control, environment()) :
>   maxfun < 10 * length(par)^2 is not recommended.
> 
>   Relatively harmless
> 
> 2: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :
>   convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
> 3: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
>   failure to converge in 10000 evaluations
> 
   You definitely need to increase the number of iterations: see
?lmerControl,
specifically the "optCtrl" setting (e.g.
control=lmerControl(optCtrl=list(maxfun=1e6)))

> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.0928109 (tol = 0.001, component 28)
> 5: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
> 
  These are convergence *warnings*.  They do not indicate that your fit
is actually any worse than previously, just that we have increased the
sensitivity of the tests.  Can you specify what version you are using?

   I wouldn't recommend moving back to an earlier version of lme4,
but you could check out https://github.com/lme4/lme4/blob/master/README.md
for instructions on how to install the lme4.0 package if you really
want ...

> Fixed effects:
>                                            Estimate Std. Error z value Pr(>|z|)
> (Intercept)                                -1.97217    0.13810 -14.281  < 2e-16 ***
> cgroup                                      1.58614    0.18262   8.686  < 2e-16 ***
> cgrammaticality                             0.52725    0.24544   2.148   0.0317 *
> cHeadNoun                                  -0.28061    0.21350  -1.314   0.1887
> cVerbType                                   0.75503    0.25615   2.948   0.0032 **
> cgroup:cgrammaticality                      1.57010    0.36695   4.279 1.88e-05 ***
> cgroup:cHeadNoun                            0.05736    0.36138   0.159   0.8739
> cgrammaticality:cHeadNoun                   0.55238    0.47616   1.160   0.2460
> cgroup:cVerbType                           -0.24665    0.35618  -0.692   0.4886
> cgrammaticality:cVerbType                  -0.49272    0.45732  -1.077   0.2813
> cHeadNoun:cVerbType                        -0.14235    0.44553  -0.319   0.7493
> cgroup:cgrammaticality:cHeadNoun            0.24468    0.73223   0.334   0.7383
> cgroup:cgrammaticality:cVerbType           -0.45695    0.70627  -0.647   0.5176
> cgroup:cHeadNoun:cVerbType                  0.75837    0.70763   1.072   0.2839
> cgrammaticality:cHeadNoun:cVerbType         0.88375    0.98856   0.894   0.3713
> cgroup:cgrammaticality:cHeadNoun:cVerbType  3.15344    1.42351   2.215   0.0267 *
> 
> Because I am using Rstudio I have just two options when I want to
> install or to update packages. When I use CRAN and let Rstudio install
> lme4 automatically it installs the most recent one. As such, it
> downloads the new package of lme4 which is problematic as I understand
> (sorry I might be wrong for that because I don't have any expertise
> but I'm talking from my observations) So my suggestion is that let the
> earlier version of lme4 be on the CRAN such that when users are
> installing they automatically install the one which was not
> problematic.  Another option for me to download the earlier version
> and to install from my pc. But when I use this option from Rstudio,
> lme4 does not install and come with the following message.
> 
> install.packages("~/lme4_1.0-4.tar.gz", repos = NULL, type = "source")
> Installing package into 'C:/Users/Azad/Documents/R/win-library/3.0'
> (as 'lib' is unspecified)
> * installing *source* package 'lme4' ...
> ** package 'lme4' successfully unpacked and MD5 sums checked
> ** libs

  If you want to install 1.0-4 you can either get the tarball from here:
http://cran.r-project.org/src/contrib/Archive/lme4/lme4_1.0-4.tar.gz

but you will either need to be able to install it from source (i.e.
have compilers etc. installed) or modify the DESCRIPTION file to
make yourself the maintainer and ship it off to
ftp://win-builder.r-project.org.

*OR* (possibly a better idea) you can retrieve a binary/.zip file from

http://lme4.r-forge.r-project.org/repos/bin/windows/contrib/3.0/lme4_1.0-4.zip

and install it.

  (You didn't specify your actual error messages from the attempted
lme4 installation.)

> Sorry for the inconvenience and hope that  I've made things clear now.
> Best wishes
> Ebrahim
>


From jake987722 at hotmail.com  Wed Oct 15 22:06:46 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 15 Oct 2014 14:06:46 -0600
Subject: [R-sig-ME] comparing posterior means
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF31F331@DC1VEX10MB001.air.org>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>,
	<543E6EC5.6090106@maw.ru.nl>,
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF31F331@DC1VEX10MB001.air.org>
Message-ID: <BAY172-W3697A097C6541E10103D4BCBAA0@phx.gbl>

Hi Ben,

It seems to me that if you are interested in the differences between particular countries then you should strongly reconsider whether it is really appropriate to be treating countries as random effects in the first place. And this is obviously a much easier kind of question to answer if countries are fixed. After reconsidering this you might still maintain that treating them as random is best, which is fine, I just want to make sure that you have at least considered the fixed possibility.

Jake

> From: HDoran at air.org
> To: b.pelzer at maw.ru.nl; r-sig-mixed-models at r-project.org
> Date: Wed, 15 Oct 2014 14:30:02 +0000
> Subject: Re: [R-sig-ME] comparing posterior means
> 
> Ben
> 
> Yes, you can do this comparison of the conditional means using the variance of the linear combination AND there is in fact a covariance term between them. I do not believe that covariance term between BLUPs is available in lmer (I wrote my own mixed model function that does spit this out, however).
> 
> Just to be didactic for a moment. Take a look at Henderson's equation(say at the link below)
> 
> http://en.wikipedia.org/wiki/Mixed_model
> 
> The covariance term between the blups that you would need comes from the lower right block of the leftmost matrix at the final solution. Lmer is not parameterized this way, so the comparison is not intended to show how that term would be extracted from lmer. Only to show that is does exist in the likelihood and can (conceivably) be extracted or computed from the terms given by lmer.
> 
> 
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Pelzer
> Sent: Wednesday, October 15, 2014 8:56 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] comparing posterior means
> 
> Dear list,
> 
> Suppose we have the following two-level null-model, for data from respondents (lowest level 1) living in countries (highest level 2):
> 
> Y(ij) = b0j + eij = (b0 + u0j)  + eij
> 
> b0j is the country-mean for country j
> b0 is the "grand mean"
> u0j is the deviation from the grand mean for country j, or the level-2 residual eij is the level-1 residual
> 
> The model is estimated by :  lmer(Y ~ 1+(1|country))
> 
> My question is about comparing two particular posterior country-means. 
> As for as I know, for a given country j, the posterior mean is equal to
> bb0 + uu0j, where bb0 is the estimate of b0 and uu0j is the posterior residual estimate of u0j.
> 
> Two compare two particular posterior country means and test whether they differ significantly, would it be necessary to know the variance of 
> bb0+uu0j for each of the two countries, or would it be sufficient to
> only know the variance of uu0j?
> 
> The latter variance (of uu0j) can be extracted using
> 
> rr <- ranef(modela, condVar=TRUE)
> attr(rr[[1]], "postVar")
> 
> However, the variance of bb0+uu0j also depends on the variance of bb0 
> and the covariance of bb0 and uu0j (if this covariance is not equal to 
> zero, of course, which I don't know...).
> 
> On the other hand, the difference between two posterior country means 
> for country A and B say, would
> equal bb0 + u0A -(bb0 + u0B) = u0A - u0B meaning that I wouldn't need to 
> worry about the variance of bb0.
> 
> So my main question is about comparing and testing the difference 
> between two posterior country means. Thanks for any help,
> 
> Ben.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From longrob604 at gmail.com  Thu Oct 16 10:31:35 2014
From: longrob604 at gmail.com (W Robert Long)
Date: Thu, 16 Oct 2014 09:31:35 +0100
Subject: [R-sig-ME] Julia vs nlme vs lme4 implementation of fitting linear
	mixed models
Message-ID: <543F8267.3000503@gmail.com>

What are the resources that compare how linear and generalised linear 
mixed models are fitted in julia, lme4 and nlme in terms of the how they 
differ in their implementation, and what advantages/disadvantages each 
has. I'm asking about the theoretical and computational issues rather 
than comparing speeds for any particular dataset/model.


From phillip.alday at staff.uni-marburg.de  Thu Oct 16 10:40:36 2014
From: phillip.alday at staff.uni-marburg.de (Phillip Alday)
Date: Thu, 16 Oct 2014 10:40:36 +0200
Subject: [R-sig-ME] Julia vs nlme vs lme4 implementation of fitting
 linear mixed models
In-Reply-To: <543F8267.3000503@gmail.com>
References: <543F8267.3000503@gmail.com>
Message-ID: <543F8484.1070402@staff.uni-marburg.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

There's a bit on the FAQ under "Which R packages (functions) fit GLMMs?":

http://glmm.wikidot.com/faq

whihc is fleshed out on this page:

http://glmm.wikidot.com/pkg-comparison

And check out this question on StackOverflow:

http://stats.stackexchange.com/questions/5344/how-to-choose-nlme-or-lme4-r-library-for-mixed-effects-models


Those pages only discuss R packages, for the Julia package(s), you
should check out the Julia package from Doug Bates, which has examples
worked as parallels to the lme4 examples:

https://github.com/dmbates/MixedModels.jl

If I recall correctly, he also has an iPython Notebook with a more
involved technical examination of mixed models in Julia, but I can't
find the link at the moment.

Best,
Phillip


On 16.10.2014 10:31, W Robert Long wrote:
> What are the resources that compare how linear and generalised
> linear mixed models are fitted in julia, lme4 and nlme in terms of
> the how they differ in their implementation, and what
> advantages/disadvantages each has. I'm asking about the theoretical
> and computational issues rather than comparing speeds for any
> particular dataset/model.
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (GNU/Linux)

iQEcBAEBAgAGBQJUP4SEAAoJEH6E4TigDpMcqbwH/jGQO84Dc5C5xZkWKPuoBqzu
THaoJnkacieeCMFt1FF2z8wlHVlYDWNqkIWzSuE0fzTASywH+AG5Dj/D5KPdT78/
1M6LAAN1HiEdKztC5wa1ceAzlE2EyOHoQFSvSxLtxl/PmEZj/BmODaMRBPJHUkeN
ZxwR4y0V9/DdEtRtFeddnETg6YzFnITZh6r3cqXSp83McSx6MAcI3NXfTKtjQVbW
/hrW1KKacngo1o48INDfocEddbuUNKx4bT3DzN0iwLSoHRhGKADQr8VEZjtbJXvK
SVk5PFu/en9szvcdPd2HV/2plAE0weepTmf1gvce8C7Oxn20369drqxsTZrrtgw=
=cuZ2
-----END PGP SIGNATURE-----


From longrob604 at gmail.com  Thu Oct 16 10:55:31 2014
From: longrob604 at gmail.com (W Robert Long)
Date: Thu, 16 Oct 2014 09:55:31 +0100
Subject: [R-sig-ME] Julia vs nlme vs lme4 implementation of fitting
 linear mixed models
In-Reply-To: <543F8484.1070402@staff.uni-marburg.de>
References: <543F8267.3000503@gmail.com>
	<543F8484.1070402@staff.uni-marburg.de>
Message-ID: <543F8803.2060902@gmail.com>

Thanks Phillip

I've seen the glmm wikidot pages. I've also seen some of the code 
comparisons between lme4 and julia on github.  I've also seen the book 
by Pinheiro and Bates about nlme and the recent paper on lme4 at
http://arxiv.org/abs/1406.5823
[this paper gives some hints about what is done differently in julia, 
but I would really like more detail if possible]

I'm interested in the differences in internal implementation, rather 
than the differences that a typical user of the packages would be 
concerned with.

Thanks
Rob



On 16/10/2014 09:40, Phillip Alday wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> There's a bit on the FAQ under "Which R packages (functions) fit GLMMs?":
>
> http://glmm.wikidot.com/faq
>
> whihc is fleshed out on this page:
>
> http://glmm.wikidot.com/pkg-comparison
>
> And check out this question on StackOverflow:
>
> http://stats.stackexchange.com/questions/5344/how-to-choose-nlme-or-lme4-r-library-for-mixed-effects-models
>
>
> Those pages only discuss R packages, for the Julia package(s), you
> should check out the Julia package from Doug Bates, which has examples
> worked as parallels to the lme4 examples:
>
> https://github.com/dmbates/MixedModels.jl
>
> If I recall correctly, he also has an iPython Notebook with a more
> involved technical examination of mixed models in Julia, but I can't
> find the link at the moment.
>
> Best,
> Phillip
>
>
> On 16.10.2014 10:31, W Robert Long wrote:
>> What are the resources that compare how linear and generalised
>> linear mixed models are fitted in julia, lme4 and nlme in terms of
>> the how they differ in their implementation, and what
>> advantages/disadvantages each has. I'm asking about the theoretical
>> and computational issues rather than comparing speeds for any
>> particular dataset/model.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (GNU/Linux)
>
> iQEcBAEBAgAGBQJUP4SEAAoJEH6E4TigDpMcqbwH/jGQO84Dc5C5xZkWKPuoBqzu
> THaoJnkacieeCMFt1FF2z8wlHVlYDWNqkIWzSuE0fzTASywH+AG5Dj/D5KPdT78/
> 1M6LAAN1HiEdKztC5wa1ceAzlE2EyOHoQFSvSxLtxl/PmEZj/BmODaMRBPJHUkeN
> ZxwR4y0V9/DdEtRtFeddnETg6YzFnITZh6r3cqXSp83McSx6MAcI3NXfTKtjQVbW
> /hrW1KKacngo1o48INDfocEddbuUNKx4bT3DzN0iwLSoHRhGKADQr8VEZjtbJXvK
> SVk5PFu/en9szvcdPd2HV/2plAE0weepTmf1gvce8C7Oxn20369drqxsTZrrtgw=
> =cuZ2
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip.alday at staff.uni-marburg.de  Thu Oct 16 11:23:10 2014
From: phillip.alday at staff.uni-marburg.de (Phillip Alday)
Date: Thu, 16 Oct 2014 11:23:10 +0200
Subject: [R-sig-ME] Julia vs nlme vs lme4 implementation of fitting
 linear mixed models
In-Reply-To: <543F8803.2060902@gmail.com>
References: <543F8267.3000503@gmail.com>	<543F8484.1070402@staff.uni-marburg.de>
	<543F8803.2060902@gmail.com>
Message-ID: <543F8E7E.3060906@staff.uni-marburg.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Then this might be more what you're looking for:

http://dmbates.github.io/MixedModels.jl/

although the mathematical discussion is largely restricted to the
introduction.

Doug will probably comment when it's a decent hour in Wisconsin, but
my understanding was that the Julia code was based on roughly the same
computational approach as lme4, but plays to Julia's strengths. The
standard reference for nlme is Pinherio and Bates, I'm still waiting
for my copy to be delivered, but the portions viewable on Google books
seem to suggest that the computational approach behind nlme is also
discussed in there. The approach in lme4 is based on sparse matrix
methods, so lme4 tends to be faster and more memory efficient (this
was recently hinted at on this list:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022752.html )

Some aspects of the computational approach behind lme4 were
tangentially discussed recently
(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022773.html), but
I suspect that discussion was part of the motivation for your question!

Cheers,
Phillip


On 16.10.2014 10:55, W Robert Long wrote:
> Thanks Phillip
> 
> I've seen the glmm wikidot pages. I've also seen some of the code 
> comparisons between lme4 and julia on github.  I've also seen the
> book by Pinheiro and Bates about nlme and the recent paper on lme4
> at http://arxiv.org/abs/1406.5823 [this paper gives some hints
> about what is done differently in julia, but I would really like
> more detail if possible]
> 
> I'm interested in the differences in internal implementation,
> rather than the differences that a typical user of the packages
> would be concerned with.
> 
> Thanks Rob
> 
> 
> 
> On 16/10/2014 09:40, Phillip Alday wrote: There's a bit on the FAQ
> under "Which R packages (functions) fit GLMMs?":
> 
> http://glmm.wikidot.com/faq
> 
> whihc is fleshed out on this page:
> 
> http://glmm.wikidot.com/pkg-comparison
> 
> And check out this question on StackOverflow:
> 
> http://stats.stackexchange.com/questions/5344/how-to-choose-nlme-or-lme4-r-library-for-mixed-effects-models
>
> 
> 
> 
> Those pages only discuss R packages, for the Julia package(s), you 
> should check out the Julia package from Doug Bates, which has
> examples worked as parallels to the lme4 examples:
> 
> https://github.com/dmbates/MixedModels.jl
> 
> If I recall correctly, he also has an iPython Notebook with a more 
> involved technical examination of mixed models in Julia, but I
> can't find the link at the moment.
> 
> Best, Phillip
> 
> 
> On 16.10.2014 10:31, W Robert Long wrote:
>>>> What are the resources that compare how linear and
>>>> generalised linear mixed models are fitted in julia, lme4 and
>>>> nlme in terms of the how they differ in their implementation,
>>>> and what advantages/disadvantages each has. I'm asking about
>>>> the theoretical and computational issues rather than
>>>> comparing speeds for any particular dataset/model.
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (GNU/Linux)

iQEcBAEBAgAGBQJUP45+AAoJEH6E4TigDpMcK4IH/2nzBi+ZPf7PuOkHrS+bVw5a
HI4lV+oQ85WqyRENy8TqdEr5IyU4LtONAPQ0Nx7R4+8oFOPkH5PgWnpyqH7UBkvT
PtPG/anZgrpSec0s4/lSeAbFmmO/z4FawwfuD/nS79t/JdCzoeKi4L0pZj70sXP7
URWd3ShiB6yddJ0Defuhhrw2qj3rIG1Jc5sS1cURncjSgsZbWQKJi791fC84gSiH
yOHYitDOliwkbRXRzpGTFQIjmYRzbZnDJOnNot4Tu3kpy91lWvOW7GYw9j+xOMjA
b+OdheNqkZwE5A0aDv2D3JXjefvIFxIA6FotArNw4U9aw9kXXFrAmachjJLMj6M=
=9lKp
-----END PGP SIGNATURE-----


From maren.rebke at avitec-research.de  Thu Oct 16 13:18:49 2014
From: maren.rebke at avitec-research.de (maren)
Date: Thu, 16 Oct 2014 13:18:49 +0200
Subject: [R-sig-ME] MCMC fitting in glmmADMB
Message-ID: <543FA999.80009@avitec-research.de>

Hi,

I fit a zero-inflated Poisson model with random effects using the 
package glmmADMB, which worked perfectly well. Now I am trying to get 
credible intervals by running a Markov chain using mcmc=TRUE, which also 
works fine in general.

The problem is, that I have many parameters as well as several random 
effects in my model and it seems that I need to run long chains to get 
proper estimates. Therefore the automatically stored file eventually 
gets very big and my computer cannot handle it anymore. Therefore I 
would like to store only the samples of the estimates for the fixed 
effects (only beta) and not the rest. Is that possible somehow?

I am not sure, but would it help to specify parameters via mcmcpars? I 
tried to include mcmcpars in the owl example in section 2.2 from the 
vignette of the package 
(http://glmmadmb.r-forge.r-project.org/glmmADMB.pdf):

fit_zinbinom1_bs_mcmc <- 
glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+BroodSize+(1|Nest),data=Owls,zeroInflation=TRUE,family="nbinom1",mcmc=TRUE,mcmc.opts=mcmcControl(mcmc=10,mcmcpars="beta"))

But unfortunately, I get an error message stating "unused argument 
(mcmcpars="beta")". As I wasn't sure if I have to state the fixed 
effects by using "beta" or the names of the parameters directly, I also 
tried including mcmcpars="BroodSize" but got the same error.

Is it not possible to define mcmcpars in glmmADMB? Is the definition of 
mcmcpars at all what I need and if so, how do I do it correctly?

Otherwise, is it possible to state that only the samples after a certain 
burnin period should be saved? Or can I play around with the jump sizes 
to reach faster convergence? As far as I understood those are rescaled 
depending on the acceptance rate at the moment. The automatic rescaling 
can be switched off by stating mcnoscale=TRUE, which is working. But I 
am not sure how I can then adjust the jump size and what the default is.

Thank you very much for taking the time to read this long email.

Best wishes,

Maren Rebke

	[[alternative HTML version deleted]]


From bobyboby at gmail.com  Thu Oct 16 16:06:13 2014
From: bobyboby at gmail.com (Boby Mathew)
Date: Thu, 16 Oct 2014 16:06:13 +0200
Subject: [R-sig-ME] MCMCglmm prior distributions
Message-ID: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>

Dear MCMCglmm users,

Is it possible to use double exponential priors(Laplace) in MCMCglmm?

Thanks for the helps.

regards,
Boby


-- 
Dr. Boby Mathew
INRES, University of Bonn
Katzenburgweg 5
Phone: 0228732031
53115, Bonn,Germany.

	[[alternative HTML version deleted]]


From longrob604 at gmail.com  Thu Oct 16 16:25:43 2014
From: longrob604 at gmail.com (W Robert Long)
Date: Thu, 16 Oct 2014 15:25:43 +0100
Subject: [R-sig-ME] Julia vs nlme vs lme4 implementation of fitting
 linear mixed models
In-Reply-To: <543F8E7E.3060906@staff.uni-marburg.de>
References: <543F8267.3000503@gmail.com>	<543F8484.1070402@staff.uni-marburg.de>	<543F8803.2060902@gmail.com>
	<543F8E7E.3060906@staff.uni-marburg.de>
Message-ID: <543FD567.1020008@gmail.com>

Thanks for those links Phillip - though the github.io link does not 
properly render the maths for me. Indeed my question was partly 
motivated by the discussion on here yesterday (I had wondered if the 
discussion ended, or went off-list; I hope it's not the latter).




On 16/10/2014 10:23, Phillip Alday wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Then this might be more what you're looking for:
>
> http://dmbates.github.io/MixedModels.jl/
>
> although the mathematical discussion is largely restricted to the
> introduction.
>
> Doug will probably comment when it's a decent hour in Wisconsin, but
> my understanding was that the Julia code was based on roughly the same
> computational approach as lme4, but plays to Julia's strengths. The
> standard reference for nlme is Pinherio and Bates, I'm still waiting
> for my copy to be delivered, but the portions viewable on Google books
> seem to suggest that the computational approach behind nlme is also
> discussed in there. The approach in lme4 is based on sparse matrix
> methods, so lme4 tends to be faster and more memory efficient (this
> was recently hinted at on this list:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022752.html )
>
> Some aspects of the computational approach behind lme4 were
> tangentially discussed recently
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022773.html), but
> I suspect that discussion was part of the motivation for your question!
>
> Cheers,
> Phillip
>
>
> On 16.10.2014 10:55, W Robert Long wrote:
>> Thanks Phillip
>>
>> I've seen the glmm wikidot pages. I've also seen some of the code
>> comparisons between lme4 and julia on github.  I've also seen the
>> book by Pinheiro and Bates about nlme and the recent paper on lme4
>> at http://arxiv.org/abs/1406.5823 [this paper gives some hints
>> about what is done differently in julia, but I would really like
>> more detail if possible]
>>
>> I'm interested in the differences in internal implementation,
>> rather than the differences that a typical user of the packages
>> would be concerned with.
>>
>> Thanks Rob
>>
>>
>>
>> On 16/10/2014 09:40, Phillip Alday wrote: There's a bit on the FAQ
>> under "Which R packages (functions) fit GLMMs?":
>>
>> http://glmm.wikidot.com/faq
>>
>> whihc is fleshed out on this page:
>>
>> http://glmm.wikidot.com/pkg-comparison
>>
>> And check out this question on StackOverflow:
>>
>> http://stats.stackexchange.com/questions/5344/how-to-choose-nlme-or-lme4-r-library-for-mixed-effects-models
>>
>>
>>
>>
>> Those pages only discuss R packages, for the Julia package(s), you
>> should check out the Julia package from Doug Bates, which has
>> examples worked as parallels to the lme4 examples:
>>
>> https://github.com/dmbates/MixedModels.jl
>>
>> If I recall correctly, he also has an iPython Notebook with a more
>> involved technical examination of mixed models in Julia, but I
>> can't find the link at the moment.
>>
>> Best, Phillip
>>
>>
>> On 16.10.2014 10:31, W Robert Long wrote:
>>>>> What are the resources that compare how linear and
>>>>> generalised linear mixed models are fitted in julia, lme4 and
>>>>> nlme in terms of the how they differ in their implementation,
>>>>> and what advantages/disadvantages each has. I'm asking about
>>>>> the theoretical and computational issues rather than
>>>>> comparing speeds for any particular dataset/model.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (GNU/Linux)
>
> iQEcBAEBAgAGBQJUP45+AAoJEH6E4TigDpMcK4IH/2nzBi+ZPf7PuOkHrS+bVw5a
> HI4lV+oQ85WqyRENy8TqdEr5IyU4LtONAPQ0Nx7R4+8oFOPkH5PgWnpyqH7UBkvT
> PtPG/anZgrpSec0s4/lSeAbFmmO/z4FawwfuD/nS79t/JdCzoeKi4L0pZj70sXP7
> URWd3ShiB6yddJ0Defuhhrw2qj3rIG1Jc5sS1cURncjSgsZbWQKJi791fC84gSiH
> yOHYitDOliwkbRXRzpGTFQIjmYRzbZnDJOnNot4Tu3kpy91lWvOW7GYw9j+xOMjA
> b+OdheNqkZwE5A0aDv2D3JXjefvIFxIA6FotArNw4U9aw9kXXFrAmachjJLMj6M=
> =9lKp
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From safaie124 at yahoo.com  Thu Oct 16 17:41:47 2014
From: safaie124 at yahoo.com (Ebi Safaie)
Date: Thu, 16 Oct 2014 08:41:47 -0700
Subject: [R-sig-ME] Fw:   lme4
In-Reply-To: <1413473614.65342.YahooMailNeo@web141205.mail.bf1.yahoo.com>
References: <543ECA86.5050502@gmail.com>
	<1413473614.65342.YahooMailNeo@web141205.mail.bf1.yahoo.com>
Message-ID: <1413474107.71092.YahooMailNeo@web141204.mail.bf1.yahoo.com>



Dear Ben Bolker, 
Thank you very much for your informative reply.
Yes, I followed Barr et al (2013).

I did what you kindly sent me. I'm not sure I've done it correctly but it came to false

It would be a good idea to check for a singular fit, i.e.

  t <- getME(mod.15,"theta")
  lwr <- getME(mod.15,"lower")
  any(t[lwr==0]< 1e-6)



t <- getME(mod.15,"theta") > lwr <- getME(mod.15,"lower") > any(t[lwr==0]< 1e-6) [1] FALSE


I increased the number of iterations as you suggested

summary(mod.15<-glmer(ErrorRate~1 +cgroup*cgrammaticality*cHeadNoun*cVerbType+(1|itemF)+(1+grammaticality*HeadNoun*VerbType|participantF),data =e3, + family="binomial",na.action=na.exclude,control=glmerControl(optCtrl=list(maxfun=1e6))))

but it came to the following message

Warning messages: 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  : Model failed to converge with max|grad| = 0.113924 (tol = 0.001, component 29) 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  : Model failed to converge: degenerate  Hessian with 1 negative eigenvalues   
> 
Actually the following two interactions are important for me
 because they are representing two hypothesis
2 way 

cgroup*cgrammaticality


4 way interaction
cgroup*cgrammaticality*cHeadNoun*cVerbType

Earlier, I used odds ratio to calculate the effect sizes (Table below) and I was able to
dissociate between these two interactions (i.e., two hypotheses) via their effect sizes. 
Due to wider range of the lower and upper limits of 95% CI I supported the 2 way interaction. 
Am I on the right track? 
Given that I want to use the newer version of lme4 (as you recommended) 
I would really appreciate your help to let me know what to do you with this really 
complex design.


Thanks for your help in advance
Kind regards,
Ebrahim




  
  Table 9.Experiment 1a: Fixed-effects from mixed-effects logistic regression model fit to data from both NSs and the NNSs for S-V agreement  Main analysis 
Fixed effects:           Odds Ratio (OR) 95% CI
For OR 
  Estimate Std. Error z value Pr(>|z|)  LL UL 
(Intercept) -1.9745 0.1274 -15.494 < 2e-16 *** 0.14 0.11 0.18 
Group (NNSs) 1.5843 0.1789 8.854 < 2e-16 *** 4.88 3.43 6.92 
Grammaticality (Ungrammatical) 0.5245 0.2182 2.404 0.0162 * 1.69 1.1 2.59 
Head Noun (SG) -0.272 0.1853 -1.468 0.1422   0.76 0.53 1.1 
Verb Type (THEMA)  0.7591 0.2326 3.263 0.0011 ** 2.14 1.35 3.37 
Group (NNSs)? Grammaticality (Ungrammatical) 1.5796 0.3586 4.404 1.06e-05 *** 4.85 2.4 9.8 
Group (NNSs)? Head Noun (SG) 0.0475 0.3537 0.134 0.8932   1.05 0.52 2.1 
Grammaticality (Ungrammatical)  ? Head Noun (SG) 0.5368 0.4338 1.237 0.2159   1.71 0.73 4 
Group (NNSs) ? Verb Type (THEMA) -0.2441 0.3472 -0.703 0.4821   0.78 0.4 1.55 
Grammaticality (Ungrammatical)  ? Verb Type (THEMA) -0.4861 0.4185 -1.162 0.2454   0.61 0.27 1.4 
 Head Noun (SG) ?Verb Type (THEMA) -0.1563 0.3969 -0.394 0.6936   0.86 0.39 1.86 
Group (NNSs) ?Grammaticality (Ungrammatical)  ? Head Noun (SG) 0.2659 0.7161 0.371 0.7104   1.3 0.32 5.31 
Group (NNSs)? Grammaticality (Ungrammatical) ? Verb Type (THEMA) -0.4691 0.6945 -0.675 0.4994   0.63 0.16 2.44 
Group (NNSs)? Head Noun (SG) ? Verb Type (THEMA) 0.7661 0.6916 1.108 0.2679   2.15 0.55 8.34 
Grammaticality (Ungrammatical)  ? Head Noun (SG) ? Verb Type (THEMA) 0.9104 0.9147 0.995 0.3196   2.49 0.41 14.93 
Group (NNSs)? Grammaticality (Ungrammatical)  ? Head Noun (SG) ? Verb Type (THEMA) 3.1326 1.3994 2.239 0.0252 * 22.93 1.48 356.16 
summary(mod.15<-glmer(ErrorRate~1 +cgroup*cgrammaticality*cHeadNoun*cVerbType+(1|itemF)+(1+grammaticality*HeadNoun*VerbType|participantF),data =e3,+ family="binomial",na.action=na.exclude)) 





 
On Wednesday, October 15, 2014 8:30 PM, Ben Bolker <bbolker at gmail.com> wrote:
  



> Dear Ben Bolker,
> 
> Thanks for the quick answer. Yes, I admit
 that I did not mention my
> problem clearly and do apologize for that. It was just because I came
> across the same error messages in the Qs & As that I did when my
> package was updated.  I was using the earlier version of lme4 and did
> not have any problems with it. For instance, for the following code I
> came to the following calculation without any error messages. (my
> dependent variable is binary and fixed factors are categorical)
> 
> summary(mod.15<-glmer(ErrorRate~1+
>    cgroup*cgrammaticality*cHeadNoun*cVerbType+(1|itemF)+
>     (1+grammaticality*HeadNoun*VerbType|participantF),data=e3,
>        family="binomial",na.action=na.exclude))

   Note
 that this is a very large (15*15) random-effects
variance-covariance matrix to estimate: I know that this is
recommended by Barr et al 2013, but see recent
 discussion
on this list, e.g.
http://article.gmane.org/gmane.comp.lang.r.lme4.devel/12492/

  It would be a good idea to check for a singular fit, i.e.

  t <- getME(mod.15,"theta")
  lwr <- getME(mod.15,"lower")
  any(t[lwr==0]< 1e-6)

> Fixed effects:
>                                            Estimate Std. Error z value Pr(>|z|)
> (Intercept)                                 -1.9745     0.1274 -15.494 
 < 2e-16 ***
> cgroup                                       1.5843    
 0.1789   8.854  < 2e-16 ***
> cgrammaticality                              0.5245     0.2182   2.404   0.0162 *
> cHeadNoun                                   -0.2720     0.1853  -1.468   0.1422
> cVerbType                                    0.7591     0.2326   3.263   0.0011 **
> cgroup:cgrammaticality                       1.5796     0.3586   4.404 1.06e-05 ***
> cgroup:cHeadNoun                         
    0.0475     0.3537   0.134   0.8932
>
 cgrammaticality:cHeadNoun                    0.5368     0.4338   1.237   0.2159
> cgroup:cVerbType                            -0.2441     0.3472  -0.703   0.4821
> cgrammaticality:cVerbType                   -0.4861     0.4185  -1.162   0.2454
> cHeadNoun:cVerbType                         -0.1563     0.3969  -0.394   0.6936
> cgroup:cgrammaticality:cHeadNoun             0.2659     0.7161   0.371   0.7104
> cgroup:cgrammaticality:cVerbType            -0.4691    
 0.6945  -0.675   0.4994
> cgroup:cHeadNoun:cVerbType 
                  0.7661     0.6916   1.108   0.2679
> cgrammaticality:cHeadNoun:cVerbType          0.9104     0.9147   0.995   0.3196
> cgroup:cgrammaticality:cHeadNoun:cVerbType   3.1326     1.3994   2.239   0.0252 *
> 
   These estimated effects look only very slightly different to me
than the ones below (i.e., only a few percent differences in point
estimates, always much smaller than the estimated standard error, and
no qualitative differences in Z/P values).  Can you specify whether
there are any differences that particularly concern you?

> 
> But as soon as I updated the package to a new version , for the same
> code I got the following error message and some calculations are not
> matched with the those with the earlier version (as shown below).
 I
> don't know exactly which version was the previous one, but I guess I
> was using 2013 packages
> 
> Warning messages:
> 1: In commonArgs(par, fn, control, environment()) :
>   maxfun < 10 * length(par)^2 is not recommended.
> 
>   Relatively harmless
> 
> 2: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :
>   convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
> 3: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
>   failure to converge in 10000 evaluations
> 
   You definitely need to increase the number of iterations: see
?lmerControl,
specifically the "optCtrl" setting (e.g.
control=lmerControl(optCtrl=list(maxfun=1e6)))

> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model
 failed to converge with max|grad| = 0.0928109 (tol = 0.001, component 28)
> 5: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
> 
  These are convergence *warnings*.  They do not indicate that your fit
is actually any worse than previously, just that we have increased the
sensitivity of the tests.  Can you specify what version you are using?

   I wouldn't recommend moving back to an earlier version of lme4,
but you could check out https://github.com/lme4/lme4/blob/master/README.md
for instructions on how to install the lme4.0 package if you
 really
want ...

> Fixed effects:
>                             
               Estimate Std. Error z value Pr(>|z|)
> (Intercept)                                -1.97217    0.13810 -14.281  < 2e-16 ***
> cgroup                                      1.58614    0.18262   8.686  < 2e-16 ***
> cgrammaticality                             0.52725    0.24544   2.148   0.0317 *
> cHeadNoun                                  -0.28061    0.21350  -1.314   0.1887
> cVerbType     
                  
            0.75503    0.25615   2.948   0.0032 **
> cgroup:cgrammaticality                      1.57010    0.36695   4.279 1.88e-05 ***
> cgroup:cHeadNoun                            0.05736    0.36138   0.159   0.8739
> cgrammaticality:cHeadNoun                   0.55238    0.47616   1.160   0.2460
> cgroup:cVerbType                           -0.24665    0.35618  -0.692   0.4886
> cgrammaticality:cVerbType                  -0.49272    0.45732 
 -1.077   0.2813
> cHeadNoun:cVerbType     
                   -0.14235    0.44553  -0.319   0.7493
> cgroup:cgrammaticality:cHeadNoun            0.24468    0.73223   0.334   0.7383
> cgroup:cgrammaticality:cVerbType           -0.45695    0.70627  -0.647   0.5176
> cgroup:cHeadNoun:cVerbType                  0.75837    0.70763   1.072   0.2839
> cgrammaticality:cHeadNoun:cVerbType         0.88375    0.98856   0.894   0.3713
> cgroup:cgrammaticality:cHeadNoun:cVerbType  3.15344    1.42351   2.215   0.0267 *
> 
> Because I am using Rstudio I have just two options when I want to
> install or to update packages. When I use CRAN and let Rstudio install
> lme4
 automatically it installs the most recent one. As such, it
> downloads the new package of lme4 which is problematic as I understand
> (sorry I might be wrong for that because I don't have any expertise
> but I'm talking from my observations) So my suggestion is that let the
> earlier version of lme4 be on the CRAN such that when users are
> installing they automatically install the one which was not
> problematic.  Another option for me to download the earlier version
> and to install from my pc. But when I use this option from Rstudio,
> lme4 does not install and come with the following message.
> 
> install.packages("~/lme4_1.0-4.tar.gz", repos = NULL, type = "source")
> Installing package into 'C:/Users/Azad/Documents/R/win-library/3.0'
> (as 'lib' is unspecified)
> * installing *source* package 'lme4' ...
> ** package 'lme4' successfully unpacked and MD5 sums
 checked
> ** libs

  If you want to install 1.0-4 you can either get the tarball from here:
http://cran.r-project.org/src/contrib/Archive/lme4/lme4_1.0-4.tar.gz

but you will either need to be able to install it from source (i.e.
have compilers etc. installed) or modify the DESCRIPTION file to
make yourself the maintainer and ship it off to
ftp://win-builder.r-project.org.

*OR* (possibly a better idea) you can retrieve a binary/.zip file from

http://lme4.r-forge.r-project.org/repos/bin/windows/contrib/3.0/lme4_1.0-4.zip

and install it.

  (You didn't specify your actual error messages from the attempted
lme4 installation.)

> Sorry for the inconvenience and hope
 that  I've made things clear now.
> Best wishes
> Ebrahim
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Oct 16 17:51:00 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 16 Oct 2014 16:51:00 +0100
Subject: [R-sig-ME] MCMCglmm prior distributions
In-Reply-To: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
References: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
Message-ID: <20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>

Hi Boby,

In short - no. I haven't tried this (or thought about it much), but  
you could treat each fixed effect as a single random effect with its  
own associated variance component. Presumably, you could then specify  
the prior for the variance component in a way that induces a prior  
t-distribution on the effect. Like the Laplace it has fatter tails  
than the Normal, but it lacks the peakiness and won't give some of the  
nice features of the LASSO.

Cheers,

Jarrod



Quoting Boby Mathew <bobyboby at gmail.com> on Thu, 16 Oct 2014 16:06:13 +0200:

> Dear MCMCglmm users,
>
> Is it possible to use double exponential priors(Laplace) in MCMCglmm?
>
> Thanks for the helps.
>
> regards,
> Boby
>
>
> --
> Dr. Boby Mathew
> INRES, University of Bonn
> Katzenburgweg 5
> Phone: 0228732031
> 53115, Bonn,Germany.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bates at stat.wisc.edu  Thu Oct 16 18:57:16 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 16 Oct 2014 11:57:16 -0500
Subject: [R-sig-ME] Julia vs nlme vs lme4 implementation of fitting
 linear mixed models
In-Reply-To: <543FD567.1020008@gmail.com>
References: <543F8267.3000503@gmail.com>
	<543F8484.1070402@staff.uni-marburg.de>
	<543F8803.2060902@gmail.com>
	<543F8E7E.3060906@staff.uni-marburg.de>
	<543FD567.1020008@gmail.com>
Message-ID: <CAO7JsnRcqbnwAoAo7SJBip0-g+K771RJ5tg3EmYz7JRVFSqzsw@mail.gmail.com>

Thanks for the question.  It is a good exercise for me to answer it so that
I can get things straight in my mind.  I am doing this off the top of my
head, relying on my all-too-faulty memory.  Corrections and clarifications
are welcome.  Ben, should we archive such information somewhere?

The basics:
nlme:
- developed in mid-1990's by Pinheiro and Bates
- documented in P & B (2000, Springer) and several papers
- implemented in R and C using the .Call interface and R's C API.
- fits linear mixed-effects models and nonlinear mixed-effects models
- allows for additional variance and or correlation structures in the
conditional     distribution of the response, given the random effects.
- multiple formula model specification with PDMat, VarCorr, ... classes.
- allows for multiple nested grouping factors.  There is a kludgy method
for fitting models with crossed grouping factors but I wouldn't push it too
hard.
- uses S3 methods and class tags (IMO "S3 classes" don't exist)
- optimization of parameter estimates via EM and Newton-Raphson
 algorithms, profiled w.r.t. residual variance only
- Internal representation uses relative precision factor and log-Cholesky
formulation.  Singular covariance matrices correspond to infinite parameter
values.
- no longer actively developed.  Maintained by R-Core primarily to adjust
to changing requirements on R packages
- no explicit methods for fitting GLMMs.
- lme with iterative reweighting is used in the glmmPQL function in the
MASS package.

lme4:
- development began in late 90's by Bates, Maechler, DebRoy, Sarkar and
others.  Current development is primarily by Bolker and Walker.
- documented in papers, vignettes.  Bates started writing a book but didn't
complete the project - some draft chapters still online.
- implemented in R, C and C++ using facilities provided by Rcpp and Eigen
- fits linear mixed-effects models and GLMMs.  Nominally has NLMM
capabilities but the implementation is not solid
- single formula model specification.  Grouping factors can be nested,
partially or fully crossed.
- uses S4 classes and methods, S3 methods, reference classes, Matrix
package.
- internal representation uses relative covariance factor and sparse
Cholesky factorization.  Optimization of profiled log-likelihood uses
general nonlinear optimizers that allow for box constraints (in practice
only require non-negativity of some of the parameters) for LMMs.  GLMMs use
PIRLS (penalized iteratively reweighted least squares) to determine the
conditional modes of the random effects with Laplace or adaptive
Gauss-Hermite approximation to the log-likelihood.  Settling on a single
robust and reliable optimizer has been difficult.
- all models use a sparse matrix representation to solve the penalized
least squares problem
- actively maintained and developed

MixedModels
- development started in 2012 by Bates
- little or no documentation outside of examples
- implemented exclusively in Julia (about 1600 lines of code)
- fits LMMs.  Development of GLMM capabilities is planned.
- single formula specification similar to lme4.  Because Julia is still a
young language not all lme4 formulas will work with MixedModels.  (Building
the formula language interpretation code from scratch is not easy.)
 Grouping factors can be nested or crossed (partially or completely).
- uses Julia methods and user-defined types.  Julia methods provide for
multiple dispatch like S4.
- internal representation (all at the Julia level) provides for several
different PLS (penalized least squares) solvers according to the
configuration of the grouping factors.
- Models with a nested sequence of grouping factors, including a single
grouping factor as a trivial special case, use dense matrix methods and
provide an analytic gradient of the profiled log-likelihood.  Similarly for
models with two crossed or nearly crossed grouping factors (think "subject"
and "item").
- Optimizers from Steven Johnson's NLopt Julia package that interfaces to
his C library, which is also used in the R packages nloptr and nloptwrap.
At present  LN_BOBYQA is used for derivative-free optimization and LD_MMA
for models that provide a gradient but switching optimizers within the
NLopt library is trivial.
- Considerable effort made to reuse storage and cut down on
allocation/garbage collection.
- Actively developed.  Maintenance hasn't been too much of an issue because
I don't think there are many users at present.

Examples of MixedModels fits are at

http://nbviewer.ipython.org/github/dmbates/slides/blob/master/2014-10-01-Ithaca/lmm%20Examples.ipynb

Because I was involved in the development of all three packages I will take
the liberty of commenting on the philosophy.

The purpose of developing nlme was for fitting nonlinear mixed-effects
models.  Linear mixed-effects models were incorporated mainly as an
iterative step in nlme.  Numerical methods used are not nearly as
sophisticated as those in lme4 and MixedModels.

lme4 was developed to provide a use-case for S4 classes and methods. The
Matrix package was initially part of lme4 then split off into a separate
package.  The numerical methods implemented in lme4 are, in my opinion,
superior to those in nlme, mainly through the use of the relative
covariance factor and the profiled log-likelihood.  These may seem like
details but to me they are very important.  The motiviation for
incorporating sparse matrix classes in the Matrix package and accessing the
CHOLMOD code was to provide a general method for fitting such models.
Using C++, Rcpp and RcppEigen was motivated by trying to provide generality
and speed.  The end result is confusing (my fault entirely) and fragile.

MixedModels was developed because I became interested in the Julia language
at the same time that I was disillusioned with at least some aspects of R.
As a new language Julia doesn't have the infrastructure of R (dataframes,
formula language, graphics, ...) but does have a clean implementation of
the parts that are available.  The most important aspect of Julia is "one
language".  You develop in the same language in which you optimize.  The
type system in Julia allows me to incorporate the different kinds of
penalized least squares solvers in what to me is a clean way, thereby
taking advantage of structural simplifications in simple, but common,
cases.  It is possible to do this in R/C++/Rcpp/EIgen but it would be a
massive headache and perhaps beyond my abilities to do it well.

Optimizing Julia code is often done at the expense of transparency.  It is
obvious what

 C = C - A*B

means when C, A and B are matrices (* means matrix multiplication in
Julia).  It is less obvious what

  BLAS.gemm!('N','N',-1.,A,B,1.,C)

means but the second form avoids taking two unnecessary copies of the
matrix C and running a couple of extra loops.  This isn't important if you
only do it once.  If you do it several dozen times in each function
evaluation in an optimization that requires tens of thousands function
evaluations, it is important.

Please let me know if this answers your question.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Oct 16 22:28:44 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 16 Oct 2014 16:28:44 -0400
Subject: [R-sig-ME] lme4 (your singularity check with getME())
In-Reply-To: <e89d400cd53b4669bd799a12f13dd1e2@BY1PR09MB0392.namprd09.prod.outlook.com>
References: <e89d400cd53b4669bd799a12f13dd1e2@BY1PR09MB0392.namprd09.prod.outlook.com>
Message-ID: <54402A7C.1000900@gmail.com>

On 14-10-16 09:37 AM, Farrar, David wrote:
> 

[I'm taking the liberty of cc'ing the r-sig-mixed-models list, as this
seems to me be a question of general interest]

> Ben, I translate your check as "for those variance parameters not
> bounded away from zero, one or more are below 1e-6."  I have no
> grounds to disagree.  I would very much appreciate if you have a
> moment to give me one or two sentences on why this works, or point me
> in some useful direction, assuming I know a little about linear
> algebra and optimization, e.g., that conditions for convergence can
> be different in constrained and unconstrained problems (1st and 2nd
> order conditions etc.), use of conditions numbers of X'X or nonlinear
> regression analogues, etc. regards, David

   For this check, we haven't (yet) even tried to test for convergence
in the singular case -- we're just checking whether we *are* in the
singular case or not.  The checks we have in place aren't necessarily
sensible in the singular case, although I've found surprisingly few
examples so far where the models are singular and we would deem them to
have converged properly but where the convergence tests fail.  In other
words, in most singular cases the surface appears to be flat and
(half-)convex at the optimum, even though I don't know of any
theoretical reason it would have to be.

  It's on our (long) to-do list to try to work out what the proper
convergence tests would be in a singular case.  Since our singularities
are always simple (i.e. we've hit x_i=0 for one or more parameters
independently/box constraints), we might get away with something as
simple as dropping the singular dimensions out of the gradient and
Hessian, rather than doing something more complicated with Lagrange
multipliers.

  Last bit of information: the reason we can get away with a simple
criterion for singularity (i.e. our variance-covariance matrix is
positive semidefinite but not positive definite, or equivalently some
eigenvalues are exactly zero), which isn't always easy, is that we
parameterize the variance-covariance matrix in terms of its Cholesky
factors; this means we have a singular variance-covariance matrix if and
only if the diagonal elements are equal to zero (we don't let them go
negative).  These parameterizations are nicely explained in Pinheiro and
Bates 1996 _Stat. Comput._  http://dx.doi.org/10.1007/BF00140873 ...

> 
> 
> 
> -----Original Message----- From:
> r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben
> Bolker Sent: Wednesday, October 15, 2014 3:27 PM To:
> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] lme4
> 
> 
>> Dear Ben Bolker,
>> 
>> Thanks for the quick answer. Yes, I admit that I did not mention my
>>  problem clearly and do apologize for that. It was just because I
>> came across the same error messages in the Qs & As that I did when
>> my package was updated.  I was using the earlier version of lme4
>> and did not have any problems with it. For instance, for the
>> following code I came to the following calculation without any
>> error messages. (my dependent variable is binary and fixed factors
>> are categorical)
>> 
>> summary(mod.15<-glmer(ErrorRate~1+ 
>> cgroup*cgrammaticality*cHeadNoun*cVerbType+(1|itemF)+ 
>> (1+grammaticality*HeadNoun*VerbType|participantF),data=e3, 
>> family="binomial",na.action=na.exclude))
> 
> Note that this is a very large (15*15) random-effects
> variance-covariance matrix to estimate: I know that this is
> recommended by Barr et al 2013, but see recent discussion on this
> list, e.g. 
> http://article.gmane.org/gmane.comp.lang.r.lme4.devel/12492/
> 
> It would be a good idea to check for a singular fit, i.e.
> 
> t <- getME(mod.15,"theta") lwr <- getME(mod.15,"lower") 
> any(t[lwr==0]< 1e-6)
> 
>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> -1.9745     0.1274 -15.494  < 2e-16 *** cgroup
>> 1.5843     0.1789   8.854  < 2e-16 *** cgrammaticality
>> 0.5245     0.2182   2.404   0.0162 * cHeadNoun
>> -0.2720     0.1853  -1.468   0.1422 cVerbType
>> 0.7591     0.2326   3.263   0.0011 ** cgroup:cgrammaticality
>> 1.5796     0.3586   4.404 1.06e-05 *** cgroup:cHeadNoun
>> 0.0475     0.3537   0.134   0.8932 cgrammaticality:cHeadNoun
>> 0.5368     0.4338   1.237   0.2159 cgroup:cVerbType
>> -0.2441     0.3472  -0.703   0.4821 cgrammaticality:cVerbType
>> -0.4861     0.4185  -1.162   0.2454 cHeadNoun:cVerbType
>> -0.1563     0.3969  -0.394   0.6936 
>> cgroup:cgrammaticality:cHeadNoun             0.2659     0.7161
>> 0.371   0.7104 cgroup:cgrammaticality:cVerbType            -0.4691
>> 0.6945  -0.675   0.4994 cgroup:cHeadNoun:cVerbType
>> 0.7661     0.6916   1.108   0.2679 
>> cgrammaticality:cHeadNoun:cVerbType          0.9104     0.9147
>> 0.995   0.3196 cgroup:cgrammaticality:cHeadNoun:cVerbType   3.1326
>> 1.3994   2.239   0.0252 *
>> 
> These estimated effects look only very slightly different to me than
> the ones below (i.e., only a few percent differences in point
> estimates, always much smaller than the estimated standard error, and
> no qualitative differences in Z/P values).  Can you specify whether
> there are any differences that particularly concern you?
> 
>> 
>> But as soon as I updated the package to a new version , for the
>> same code I got the following error message and some calculations
>> are not matched with the those with the earlier version (as shown
>> below). I don't know exactly which version was the previous one,
>> but I guess I was using 2013 packages
>> 
>> Warning messages: 1: In commonArgs(par, fn, control, environment())
>> : maxfun < 10 * length(par)^2 is not recommended.
>> 
>> Relatively harmless
>> 
>> 2: In optwrap(optimizer, devfun, start, rho$lower, control =
>> control,  : convergence code 1 from bobyqa: bobyqa -- maximum
>> number of function evaluations exceeded 3: In (function (fn, par,
>> lower = rep.int(-Inf, n), upper = rep.int(Inf,  : failure to
>> converge in 10000 evaluations
>> 
> You definitely need to increase the number of iterations: see
> ?lmerControl, specifically the "optCtrl" setting (e.g. 
> control=lmerControl(optCtrl=list(maxfun=1e6)))
> 
>> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  : Model failed to converge with max|grad| =
>> 0.0928109 (tol = 0.001, component 28) 5: In checkConv(attr(opt,
>> "derivs"), opt$par, ctrl = control$checkConv,  : Model failed to
>> converge: degenerate  Hessian with 1 negative eigenvalues
>> 
> These are convergence *warnings*.  They do not indicate that your fit
> is actually any worse than previously, just that we have increased
> the sensitivity of the tests.  Can you specify what version you are
> using?
> 
> I wouldn't recommend moving back to an earlier version of lme4, but
> you could check out
> https://github.com/lme4/lme4/blob/master/README.md for instructions
> on how to install the lme4.0 package if you really want ...
> 
>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> -1.97217    0.13810 -14.281  < 2e-16 *** cgroup
>> 1.58614    0.18262   8.686  < 2e-16 *** cgrammaticality
>> 0.52725    0.24544   2.148   0.0317 * cHeadNoun
>> -0.28061    0.21350  -1.314   0.1887 cVerbType
>> 0.75503    0.25615   2.948   0.0032 ** cgroup:cgrammaticality
>> 1.57010    0.36695   4.279 1.88e-05 *** cgroup:cHeadNoun
>> 0.05736    0.36138   0.159   0.8739 cgrammaticality:cHeadNoun
>> 0.55238    0.47616   1.160   0.2460 cgroup:cVerbType
>> -0.24665    0.35618  -0.692   0.4886 cgrammaticality:cVerbType
>> -0.49272    0.45732  -1.077   0.2813 cHeadNoun:cVerbType
>> -0.14235    0.44553  -0.319   0.7493 
>> cgroup:cgrammaticality:cHeadNoun            0.24468    0.73223
>> 0.334   0.7383 cgroup:cgrammaticality:cVerbType           -0.45695
>> 0.70627  -0.647   0.5176 cgroup:cHeadNoun:cVerbType
>> 0.75837    0.70763   1.072   0.2839 
>> cgrammaticality:cHeadNoun:cVerbType         0.88375    0.98856
>> 0.894   0.3713 cgroup:cgrammaticality:cHeadNoun:cVerbType  3.15344
>> 1.42351   2.215   0.0267 *
>> 
>> Because I am using Rstudio I have just two options when I want to 
>> install or to update packages. When I use CRAN and let Rstudio
>> install lme4 automatically it installs the most recent one. As
>> such, it downloads the new package of lme4 which is problematic as
>> I understand (sorry I might be wrong for that because I don't have
>> any expertise but I'm talking from my observations) So my
>> suggestion is that let the earlier version of lme4 be on the CRAN
>> such that when users are installing they automatically install the
>> one which was not problematic.  Another option for me to download
>> the earlier version and to install from my pc. But when I use this
>> option from Rstudio, lme4 does not install and come with the
>> following message.
>> 
>> install.packages("~/lme4_1.0-4.tar.gz", repos = NULL, type =
>> "source") Installing package into
>> 'C:/Users/Azad/Documents/R/win-library/3.0' (as 'lib' is
>> unspecified) * installing *source* package 'lme4' ... ** package
>> 'lme4' successfully unpacked and MD5 sums checked ** libs
> 
> If you want to install 1.0-4 you can either get the tarball from
> here: 
> http://cran.r-project.org/src/contrib/Archive/lme4/lme4_1.0-4.tar.gz
> 
> but you will either need to be able to install it from source (i.e. 
> have compilers etc. installed) or modify the DESCRIPTION file to make
> yourself the maintainer and ship it off to
> ftp://win-builder.r-project.org.
> 
> *OR* (possibly a better idea) you can retrieve a binary/.zip file
> from
> 
> http://lme4.r-forge.r-project.org/repos/bin/windows/contrib/3.0/lme4_1.0-4.zip
>
>  and install it.
> 
> (You didn't specify your actual error messages from the attempted 
> lme4 installation.)
> 
>> Sorry for the inconvenience and hope that  I've made things clear
>> now. Best wishes Ebrahim
>> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From T.Pennell at sussex.ac.uk  Thu Oct 16 11:22:15 2014
From: T.Pennell at sussex.ac.uk (Tanya Pennell)
Date: Thu, 16 Oct 2014 09:22:15 +0000
Subject: [R-sig-ME] MCMCglmm
Message-ID: <B911FCE5-46DE-4916-9E72-4D4D18A04B70@sussex.ac.uk>

Hi,

I have a query regarding an MCMCglmm output.

My prior and model is as follows:

prior.model.23<-list(R=list(V=diag(2)/84, nu=0.01),G=list     (  G1=list   (V=diag(2)/84, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)/84)))

model.23 <- MCMCglmm(S_relative_fec ~ sex*rep-1,random=~us(sex):line, rcov=~idh(sex):units, family="gaussian", nitt = 100000, burnin = 30000, thin=30, data = GES23newdata, prior = prior.model.23, verbose = FALSE)

I am looking at sex specific genetic variances and their covariance. I use point estimates of the sex specific variance and covariance to calculate the genetic correlation between the sexes. I have used this model with several different data sets, where the genetic correlation is vastly different between them. The problem is that the HPD interval for each of them is the same every time. I was wondering whether there is something wrong with my prior that would cause this problem to arise?

Many thanks,
Tanya


	[[alternative HTML version deleted]]


From longrob604 at gmail.com  Fri Oct 17 14:34:10 2014
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Oct 2014 13:34:10 +0100
Subject: [R-sig-ME] Julia vs nlme vs lme4 implementation of fitting
 linear mixed models
In-Reply-To: <CAO7JsnRcqbnwAoAo7SJBip0-g+K771RJ5tg3EmYz7JRVFSqzsw@mail.gmail.com>
References: <543F8267.3000503@gmail.com>	<543F8484.1070402@staff.uni-marburg.de>	<543F8803.2060902@gmail.com>	<543F8E7E.3060906@staff.uni-marburg.de>	<543FD567.1020008@gmail.com>
	<CAO7JsnRcqbnwAoAo7SJBip0-g+K771RJ5tg3EmYz7JRVFSqzsw@mail.gmail.com>
Message-ID: <54410CC2.5090604@gmail.com>

Dear Professor Bates

This is a great help - thank you. I may have some follow-on questions, 
in which case I shall reply to the list but your response below gives me 
plenty to occupy myself with for now.

Regards
Robert Long


On 16/10/2014 17:57, Douglas Bates wrote:
> Thanks for the question.  It is a good exercise for me to answer it so
> that I can get things straight in my mind.  I am doing this off the top
> of my head, relying on my all-too-faulty memory.  Corrections and
> clarifications are welcome.  Ben, should we archive such information
> somewhere?
>
> The basics:
> nlme:
> - developed in mid-1990's by Pinheiro and Bates
> - documented in P & B (2000, Springer) and several papers
> - implemented in R and C using the .Call interface and R's C API.
> - fits linear mixed-effects models and nonlinear mixed-effects models
> - allows for additional variance and or correlation structures in the
> conditional     distribution of the response, given the random effects.
> - multiple formula model specification with PDMat, VarCorr, ... classes.
> - allows for multiple nested grouping factors.  There is a kludgy method
> for fitting models with crossed grouping factors but I wouldn't push it
> too hard.
> - uses S3 methods and class tags (IMO "S3 classes" don't exist)
> - optimization of parameter estimates via EM and Newton-Raphson
>   algorithms, profiled w.r.t. residual variance only
> - Internal representation uses relative precision factor and
> log-Cholesky formulation.  Singular covariance matrices correspond to
> infinite parameter values.
> - no longer actively developed.  Maintained by R-Core primarily to
> adjust to changing requirements on R packages
> - no explicit methods for fitting GLMMs.
> - lme with iterative reweighting is used in the glmmPQL function in the
> MASS package.
>
> lme4:
> - development began in late 90's by Bates, Maechler, DebRoy, Sarkar and
> others.  Current development is primarily by Bolker and Walker.
> - documented in papers, vignettes.  Bates started writing a book but
> didn't complete the project - some draft chapters still online.
> - implemented in R, C and C++ using facilities provided by Rcpp and Eigen
> - fits linear mixed-effects models and GLMMs.  Nominally has NLMM
> capabilities but the implementation is not solid
> - single formula model specification.  Grouping factors can be nested,
> partially or fully crossed.
> - uses S4 classes and methods, S3 methods, reference classes, Matrix
> package.
> - internal representation uses relative covariance factor and sparse
> Cholesky factorization.  Optimization of profiled log-likelihood uses
> general nonlinear optimizers that allow for box constraints (in practice
> only require non-negativity of some of the parameters) for LMMs.  GLMMs
> use PIRLS (penalized iteratively reweighted least squares) to determine
> the conditional modes of the random effects with Laplace or adaptive
> Gauss-Hermite approximation to the log-likelihood.  Settling on a single
> robust and reliable optimizer has been difficult.
> - all models use a sparse matrix representation to solve the penalized
> least squares problem
> - actively maintained and developed
>
> MixedModels
> - development started in 2012 by Bates
> - little or no documentation outside of examples
> - implemented exclusively in Julia (about 1600 lines of code)
> - fits LMMs.  Development of GLMM capabilities is planned.
> - single formula specification similar to lme4.  Because Julia is still
> a young language not all lme4 formulas will work with MixedModels.
>   (Building the formula language interpretation code from scratch is not
> easy.)  Grouping factors can be nested or crossed (partially or completely).
> - uses Julia methods and user-defined types.  Julia methods provide for
> multiple dispatch like S4.
> - internal representation (all at the Julia level) provides for several
> different PLS (penalized least squares) solvers according to the
> configuration of the grouping factors.
> - Models with a nested sequence of grouping factors, including a single
> grouping factor as a trivial special case, use dense matrix methods and
> provide an analytic gradient of the profiled log-likelihood.  Similarly
> for models with two crossed or nearly crossed grouping factors (think
> "subject" and "item").
> - Optimizers from Steven Johnson's NLopt Julia package that interfaces
> to his C library, which is also used in the R packages nloptr and
> nloptwrap.  At present  LN_BOBYQA is used for derivative-free
> optimization and LD_MMA for models that provide a gradient but switching
> optimizers within the NLopt library is trivial.
> - Considerable effort made to reuse storage and cut down on
> allocation/garbage collection.
> - Actively developed.  Maintenance hasn't been too much of an issue
> because I don't think there are many users at present.
>
> Examples of MixedModels fits are at
>
> http://nbviewer.ipython.org/github/dmbates/slides/blob/master/2014-10-01-Ithaca/lmm%20Examples.ipynb
>
> Because I was involved in the development of all three packages I will
> take the liberty of commenting on the philosophy.
>
> The purpose of developing nlme was for fitting nonlinear mixed-effects
> models.  Linear mixed-effects models were incorporated mainly as an
> iterative step in nlme.  Numerical methods used are not nearly as
> sophisticated as those in lme4 and MixedModels.
>
> lme4 was developed to provide a use-case for S4 classes and methods. The
> Matrix package was initially part of lme4 then split off into a separate
> package.  The numerical methods implemented in lme4 are, in my opinion,
> superior to those in nlme, mainly through the use of the relative
> covariance factor and the profiled log-likelihood.  These may seem like
> details but to me they are very important.  The motiviation for
> incorporating sparse matrix classes in the Matrix package and accessing
> the CHOLMOD code was to provide a general method for fitting such
> models.  Using C++, Rcpp and RcppEigen was motivated by trying to
> provide generality and speed.  The end result is confusing (my fault
> entirely) and fragile.
>
> MixedModels was developed because I became interested in the Julia
> language at the same time that I was disillusioned with at least some
> aspects of R.  As a new language Julia doesn't have the infrastructure
> of R (dataframes, formula language, graphics, ...) but does have a clean
> implementation of the parts that are available.  The most important
> aspect of Julia is "one language".  You develop in the same language in
> which you optimize.  The type system in Julia allows me to incorporate
> the different kinds of penalized least squares solvers in what to me is
> a clean way, thereby taking advantage of structural simplifications in
> simple, but common, cases.  It is possible to do this in
> R/C++/Rcpp/EIgen but it would be a massive headache and perhaps beyond
> my abilities to do it well.
>
> Optimizing Julia code is often done at the expense of transparency.  It
> is obvious what
>
>   C = C - A*B
>
> means when C, A and B are matrices (* means matrix multiplication in
> Julia).  It is less obvious what
>
>    BLAS.gemm!('N','N',-1.,A,B,1.,C)
>
> means but the second form avoids taking two unnecessary copies of the
> matrix C and running a couple of extra loops.  This isn't important if
> you only do it once.  If you do it several dozen times in each function
> evaluation in an optimization that requires tens of thousands function
> evaluations, it is important.
>
> Please let me know if this answers your question.


From pauljohn32 at gmail.com  Fri Oct 17 17:38:54 2014
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 17 Oct 2014 10:38:54 -0500
Subject: [R-sig-ME] Survey weights. Suggestions?
Message-ID: <CAErODj9B85WOqJ6Y1zSs0pQFxyihU5Vf=Dz7j5SP1etVThMXMw@mail.gmail.com>

I'm still resisting the idea that we should incorporate survey weights
in regression analysis at all, and now it is suggested to me that a
mixed model with state & city random effects needs to incorporate
information about survey weights.  Could I hear your opinions?

In the past, I've always answered people who ask for survey weights
with this quotation:

Murray Aitkin, Brian Francis, John Hinde, and Ross Darnell,
Statistical Modeling in R (Oxford 2009), p. 112

"One point which often causes confusion is the use of 'sample weights'
in regression. Survey studies sometimes substantially over-sample
small strata or sub-populations to provide sample sizes similar to
those from (under-sampled) large sub-populations.  A 'sample weight'
is often provided for each observation in the sample data set to allow
the re-aggregation of the final model to provide population
predictions. The sample weight is the reciprocal of the probability of
inclusion in the sample of an observation from each sub-population.
The sample weight will be high for the large sub-populations, and low
for the small sub-populations.

These weights can be used formally to define a weighted or pseudo
likelihood for the sample wieght w_i for y_i, the weighted likelihood
is
[formula]
Then the weighted MLEs from the score equation satisfy
[formula]
If theta is the population mean and the model for Y is N(mu,
sigma-squared), the weighted MLE is [formula]. This correctly weights
for disproportionate sampling.

However, it is an important point that these sample weights should
*not* be used as formal weights in a regression analysis: the
observations should be equally weighted (i.e., unweighted) in the
analysis, and the model should always include the stratifying factor,
together with its interactions with other variables in the model....
"

It appears to me that is correct. I like the argument. It fits with my
understanding of

DuMouchel, W. H., & Duncan, G. J. (1983). Using Sample Survey Weights
in Multiple Regression Analyses of Stratified Samples. Journal of the
American Statistical Association, 78(383), 535. doi:10.2307/2288115.
Summary: If you have a model specified correctly, you don't need
sampling weights. If the usage of weights leads to a different answer,
your model is probably wrong to start with. They make a specification
test out of the difference.

And then there's the all time classic comment "Survey weighting is a
mess." (Gelman, A. (2007). Struggles with Survey Weighting and
Regression Modeling. Statistical Science, 22(2), 153?164.
doi:10.1214/088342306000000691.
http://www.stat.columbia.edu/~gelman/research/published/STS226.pdf)

I've read Thomas Lumley's book on using the R survey package, I
understand how I could estimate some GLM with survey weights.  But I
don't understand why I'd want to do that.  And I can't bring myself to
believe that weights can correct for non-response in panel studies
either.

I need to read something at the middle level, between a graduate
math-stats book on sampling theory, and a manual for SPSS users that
tells them which buttons to push.  Can you point me at some discussion
of where survey weights feed into a random effects framework, or good
reasons why we need to use survey weights at all?

Please note, I'm not reluctant about weights as an approach to
heteroskedasticity (WLS), I understand that part.  I believe I
understand the role of the weights argument in lmer as currently
presented.

pj
-- 
Paul E. Johnson
Professor, Political Science      Acting Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From mcasals at aspb.cat  Fri Oct 17 18:38:56 2014
From: mcasals at aspb.cat (=?UTF-8?Q?Mart=C3=AD_Casals?=)
Date: Fri, 17 Oct 2014 18:38:56 +0200
Subject: [R-sig-ME] Extract standard error of the variance component in
 lme4 package (GLMM).
In-Reply-To: <543E7C96.2000100@gmail.com>
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
	<543E7B62.2020609@utoronto.ca> <543E7C96.2000100@gmail.com>
Message-ID: <CADtmEn6R8bwKEuw7mCUKipJ9E=BFs1ErzkjSizZ2UfU+dJUqEg@mail.gmail.com>

Thank you Ben and Steve for your information and comments.

I appreciate it!

Best regards,

Mart?

2014-10-15 15:54 GMT+02:00 Ben Bolker <bbolker at gmail.com>:

>   If you really want them (with all the warnings about their often being
> bad summaries of the uncertainty), http://rpubs.com/bbolker/varwald
> gives a fairly straightforward recipe for getting the Wald standard
> errors of the random effects standard deviations and correlations.
>
> On 14-10-15 09:49 AM, Steve Walker wrote:
> > The standard approach is to bootstrap the standard errors with
> > `bootMer`.  But this can take a long time.
> >
> > Is there a reason you want standard errors instead of confidence
> > intervals?  If not, you could try profile confidence intervals.  Here is
> > an example:
> >
> > library(lme4)
> > data(grouseticks)
> >
> > form <- TICKS~YEAR+scale(HEIGHT)+(1|BROOD)+(1|INDEX)+(1|LOCATION)
> > (m <- glmer(form, family = "poisson", data = grouseticks))
> > (cim <- confint(m, oldNames = FALSE))
> >
> > ## ------------------------------------------------------------
> > ## Bootstraping takes a _long_ time, but does give you
> > ## standard errors:
> > ## ------------------------------------------------------------
> > ## (bt <- bootMer(m, function(mm) VarCorr(mm)$BROOD[,], 100))
> > ## sd(bt$t, na.rm = TRUE)
> > ## ------------------------------------------------------------
> >
> > Cheers,
> > Steve
> >
> >
> > On 2014-10-15, 3:29 AM, Mart? Casals wrote:
> >> Dear all,
> >>
> >> I?ve fitted  a classical Poisson GLMM with lme4. I obtain the variance
> of
> >> random effect (variance component) with the following script:
> >>
> >>
> >> print(VarCorr(model),comp="Variance")
> >>
> >>
> >> but I?d like to print the standard error of the variance component. I
> >> think
> >> it is possible with the new version of the lme4 package. How it can be
> >> obtain?
> >>
> >>
> >>
> >> Thanks in advance,
> >>
> >>
> >> Mart?
> >>
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mart? Casals Toquero

Centre d' Investigaci? Biom?dica d'Epidemiolog?a i Salut P?blica

Ag?ncia de Salut P?blica de Barcelona

Servei d' Epidemiologia

Tel. 932384545 extensi?: 365

mcasals at aspb.es

	[[alternative HTML version deleted]]


From longrob604 at gmail.com  Fri Oct 17 19:18:21 2014
From: longrob604 at gmail.com (W Robert Long)
Date: Fri, 17 Oct 2014 18:18:21 +0100
Subject: [R-sig-ME] Survey weights. Suggestions?
In-Reply-To: <CAErODj9B85WOqJ6Y1zSs0pQFxyihU5Vf=Dz7j5SP1etVThMXMw@mail.gmail.com>
References: <CAErODj9B85WOqJ6Y1zSs0pQFxyihU5Vf=Dz7j5SP1etVThMXMw@mail.gmail.com>
Message-ID: <54414F5D.3090206@gmail.com>

Perhaps one situation where survey weights could plausibly be used is 
where propensity scores are used as inverse probability weights to 
"create balance" when estimating a treatment effect in non-equivalent 
groups.

On 17/10/2014 16:38, Paul Johnson wrote:
> I'm still resisting the idea that we should incorporate survey weights
> in regression analysis at all, and now it is suggested to me that a
> mixed model with state & city random effects needs to incorporate
> information about survey weights.  Could I hear your opinions?
>
> In the past, I've always answered people who ask for survey weights
> with this quotation:
>
> Murray Aitkin, Brian Francis, John Hinde, and Ross Darnell,
> Statistical Modeling in R (Oxford 2009), p. 112
>
> "One point which often causes confusion is the use of 'sample weights'
> in regression. Survey studies sometimes substantially over-sample
> small strata or sub-populations to provide sample sizes similar to
> those from (under-sampled) large sub-populations.  A 'sample weight'
> is often provided for each observation in the sample data set to allow
> the re-aggregation of the final model to provide population
> predictions. The sample weight is the reciprocal of the probability of
> inclusion in the sample of an observation from each sub-population.
> The sample weight will be high for the large sub-populations, and low
> for the small sub-populations.
>
> These weights can be used formally to define a weighted or pseudo
> likelihood for the sample wieght w_i for y_i, the weighted likelihood
> is
> [formula]
> Then the weighted MLEs from the score equation satisfy
> [formula]
> If theta is the population mean and the model for Y is N(mu,
> sigma-squared), the weighted MLE is [formula]. This correctly weights
> for disproportionate sampling.
>
> However, it is an important point that these sample weights should
> *not* be used as formal weights in a regression analysis: the
> observations should be equally weighted (i.e., unweighted) in the
> analysis, and the model should always include the stratifying factor,
> together with its interactions with other variables in the model....
> "
>
> It appears to me that is correct. I like the argument. It fits with my
> understanding of
>
> DuMouchel, W. H., & Duncan, G. J. (1983). Using Sample Survey Weights
> in Multiple Regression Analyses of Stratified Samples. Journal of the
> American Statistical Association, 78(383), 535. doi:10.2307/2288115.
> Summary: If you have a model specified correctly, you don't need
> sampling weights. If the usage of weights leads to a different answer,
> your model is probably wrong to start with. They make a specification
> test out of the difference.
>
> And then there's the all time classic comment "Survey weighting is a
> mess." (Gelman, A. (2007). Struggles with Survey Weighting and
> Regression Modeling. Statistical Science, 22(2), 153?164.
> doi:10.1214/088342306000000691.
> http://www.stat.columbia.edu/~gelman/research/published/STS226.pdf)
>
> I've read Thomas Lumley's book on using the R survey package, I
> understand how I could estimate some GLM with survey weights.  But I
> don't understand why I'd want to do that.  And I can't bring myself to
> believe that weights can correct for non-response in panel studies
> either.
>
> I need to read something at the middle level, between a graduate
> math-stats book on sampling theory, and a manual for SPSS users that
> tells them which buttons to push.  Can you point me at some discussion
> of where survey weights feed into a random effects framework, or good
> reasons why we need to use survey weights at all?
>
> Please note, I'm not reluctant about weights as an approach to
> heteroskedasticity (WLS), I understand that part.  I believe I
> understand the role of the weights argument in lmer as currently
> presented.
>
> pj
>


From bbolker at gmail.com  Sat Oct 18 17:23:36 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 18 Oct 2014 11:23:36 -0400
Subject: [R-sig-ME] MCMC fitting in glmmADMB
In-Reply-To: <543FA999.80009@avitec-research.de>
References: <543FA999.80009@avitec-research.de>
Message-ID: <CABghstTrBpRvYNf=dmvcwbSTmp1NeLZxJgfs59boeQZnT3DcnQ@mail.gmail.com>

  You can use mcmcControl(mcsave=...), as illustrated below.

library("glmmADMB")

om <- glmmadmb(SiblingNegotiation~FoodTreatment*SexParent+
                (1|Nest)+offset(log(BroodSize)),
               zeroInflation=TRUE,family="nbinom",data=Owls,
               mcmc=TRUE,
               mcmc.opts=mcmcControl(mcmc=200))
nrow(om$mcmc) ## 20

om2 <- glmmadmb(SiblingNegotiation~FoodTreatment*SexParent+
                (1|Nest)+offset(log(BroodSize)),
               zeroInflation=TRUE,family="nbinom",data=Owls,
               mcmc=TRUE,
               mcmc.opts=mcmcControl(mcmc=200,mcsave=20))
nrow(om2$mcmc)  ## 10


On Thu, Oct 16, 2014 at 7:18 AM, maren <maren.rebke at avitec-research.de>
wrote:

> Hi,
>
> I fit a zero-inflated Poisson model with random effects using the
> package glmmADMB, which worked perfectly well. Now I am trying to get
> credible intervals by running a Markov chain using mcmc=TRUE, which also
> works fine in general.
>
> The problem is, that I have many parameters as well as several random
> effects in my model and it seems that I need to run long chains to get
> proper estimates. Therefore the automatically stored file eventually
> gets very big and my computer cannot handle it anymore. Therefore I
> would like to store only the samples of the estimates for the fixed
> effects (only beta) and not the rest. Is that possible somehow?
>
> I am not sure, but would it help to specify parameters via mcmcpars? I
> tried to include mcmcpars in the owl example in section 2.2 from the
> vignette of the package
> (http://glmmadmb.r-forge.r-project.org/glmmADMB.pdf):
>
> fit_zinbinom1_bs_mcmc <-
>
> glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+BroodSize+(1|Nest),data=Owls,zeroInflation=TRUE,family="nbinom1",mcmc=TRUE,mcmc.opts=mcmcControl(mcmc=10,mcmcpars="beta"))
>
> But unfortunately, I get an error message stating "unused argument
> (mcmcpars="beta")". As I wasn't sure if I have to state the fixed
> effects by using "beta" or the names of the parameters directly, I also
> tried including mcmcpars="BroodSize" but got the same error.
>
> Is it not possible to define mcmcpars in glmmADMB? Is the definition of
> mcmcpars at all what I need and if so, how do I do it correctly?
>
> Otherwise, is it possible to state that only the samples after a certain
> burnin period should be saved? Or can I play around with the jump sizes
> to reach faster convergence? As far as I understood those are rescaled
> depending on the acceptance rate at the moment. The automatic rescaling
> can be switched off by stating mcnoscale=TRUE, which is working. But I
> am not sure how I can then adjust the jump size and what the default is.
>
> Thank you very much for taking the time to read this long email.
>
> Best wishes,
>
> Maren Rebke
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Oct 18 18:04:24 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 18 Oct 2014 16:04:24 +0000 (UTC)
Subject: [R-sig-ME] Fw:   lme4
References: <543ECA86.5050502@gmail.com>
	<1413473614.65342.YahooMailNeo@web141205.mail.bf1.yahoo.com>
	<1413474107.71092.YahooMailNeo@web141204.mail.bf1.yahoo.com>
Message-ID: <loom.20141018T180412-581@post.gmane.org>

Ebi Safaie <safaie124 at ...> writes:

> Dear Ben Bolker, 
> Thank you very much for your informative reply.
> Yes, I followed Barr et al (2013).
> 
> I did what you kindly sent me. I'm not sure I've
> done it correctly but it came to false
> 
> It would be a good idea to check for a singular fit, i.e.
> 
>   t <- getME(mod.15,"theta")
>   lwr <- getME(mod.15,"lower")
>   any(t[lwr==0]< 1e-6)
> 
> t <- getME(mod.15,"theta") > lwr <- getME(mod.15,"lower") 
> any(t[lwr==0]< 1e-6) [1] FALSE

  that's good -- that means that your model is at least
bounded away from zero for constrained parameters.
 
> I increased the number of iterations as you suggested
> 
> summary(mod.15<-glmer(ErrorRate~1
> cgroup*cgrammaticality*cHeadNoun*cVerbType+(1|itemF)+
> (1+grammaticality*HeadNoun*VerbType|participantF),data=e3, 
> family="binomial",na.action=na.exclude,
> control=glmerControl(optCtrl=list(maxfun=1e6))))
> 
> but it came to the following message
> 
> Warning messages: 1: In checkConv(attr(opt, "derivs"), 
> opt$par, ctrl = control$checkConv,  : Model
> failed to converge with max|grad| = 0.113924 
> (tol = 0.001, component 29) 2: In checkConv(attr(opt,
> "derivs"), opt$par, ctrl = control$checkConv,  :
> Model failed to converge: degenerate  Hessian with 1
> negative eigenvalues   

  These warnings do suggest that your model is at the very least
unstably fitted. You could try some of the strategies listed
at 

http://rpubs.com/bbolker/lme4trouble1

to reassure yourself that the model fit is in fact OK.

I want to emphasize again that your model is **not** actually
fitting worse than it did before/with previous versions; rather,
the default warning level has been turned up so that you're
getting more warnings than before.

> Actually the following two interactions are important for me
>  because they are representing two hypothesis
> 2 way 
> 
> cgroup*cgrammaticality
> 
> 4 way interaction
> cgroup*cgrammaticality*cHeadNoun*cVerbType


Comparing previous results just for these terms --

previous
                                 est     stderr       Z        P
cgroup:cgrammaticality        1.5796     0.3586   4.404 1.06e-05 *** 
cgroup:cgrammaticality:       3.1326     1.3994   2.239   0.0252 *
  cHeadNoun:cVerbType

current

cgroup:cgrammaticality        1.57010    0.36695  4.279 1.88e-05 ***
cgroup:cgrammaticality:       3.15344    1.42351  2.215   0.0267 *
   cHeadNoun:cVerbType

As I said before, the new and old results
look the same to me for all practical
purposes.

> Earlier, I used odds ratio to calculate the effect sizes
> (Table below) and I was able to
> dissociate between these two interactions (i.e., two hypotheses) 
> via their effect sizes. 
> Due to wider range of the lower and upper limits of 95% CI 
> I supported the 2 way interaction. 

   Don't know what you mean here.  Are you trying to distinguish
which one has a larger effect?  Assuming all your predictors
are categorical (so that you don't have to worry about standardizing
units), the two-way interaction has a smaller _effect_ but also
smaller uncertainty, so it is more statistically significant.

> Am I on the right track? 
> Given that I want to use the newer version of lme4 (as you recommended) 
> I would really appreciate your help to let me know what to do 
>  with this really 
> complex design.
>   
>   Table 9.Experiment 1a: Fixed-effects from mixed-effects logistic 
> regression model fit to data from both
> NSs and the NNSs for S-V agreement  Main analysis 
> Fixed effects:           Odds Ratio (OR) 95% CI
> For OR 

Your table got somewhat mangled in transition to the mailing list,
but appears to be a slightly modified version of the summary() output,
with odds ratios and Wald confidence intervals on odds ratios (i.e.
based on exp(est +/- 1.96*std. err) appended).

   The questions about warning messages from lme4 and what to do
about them are on-topic for this list, but these questions about how to
interpret the fixed effects are pretty generic (e.g. they would
apply pretty much equivalently to a regular linear or generalized linear
model), and would be more appropriate for a more generic stats questions
venue such as CrossValidated <http://stats.stackexchange.com>

  sincerely
    Ben Bolker


From maren.rebke at avitec-research.de  Mon Oct 20 10:58:33 2014
From: maren.rebke at avitec-research.de (maren)
Date: Mon, 20 Oct 2014 10:58:33 +0200
Subject: [R-sig-ME] MCMC fitting in glmmADMB
In-Reply-To: <CABghstTrBpRvYNf=dmvcwbSTmp1NeLZxJgfs59boeQZnT3DcnQ@mail.gmail.com>
References: <543FA999.80009@avitec-research.de>
	<CABghstTrBpRvYNf=dmvcwbSTmp1NeLZxJgfs59boeQZnT3DcnQ@mail.gmail.com>
Message-ID: <5444CEB9.40506@avitec-research.de>


Thank you very much for your suggestion, Ben. Saving only a thinned 
sequence will of course reduce the size of the stored data file. I was 
using that option already in the analysis of my own data, but maybe I 
just have to choose larger intervals.

 From your reply I assume that it is not easily possible to store only 
the samples of the estimates for certain parameters (i.e. don?t save 
u.01-u.27 in the owl example), define a burn-in period or play around 
with the jump size. Or were my questions not clear enough?

Best wishes,

Maren


Am 18.10.2014 17:23, schrieb Ben Bolker:
>   You can use mcmcControl(mcsave=...), as illustrated below.
>
> library("glmmADMB")
>
> om <- glmmadmb(SiblingNegotiation~FoodTreatment*SexParent+
>                 (1|Nest)+offset(log(BroodSize)),
>                zeroInflation=TRUE,family="nbinom",data=Owls,
>                mcmc=TRUE,
>                mcmc.opts=mcmcControl(mcmc=200))
> nrow(om$mcmc) ## 20
>
> om2 <- glmmadmb(SiblingNegotiation~FoodTreatment*SexParent+
>                 (1|Nest)+offset(log(BroodSize)),
>                zeroInflation=TRUE,family="nbinom",data=Owls,
>                mcmc=TRUE,
>                mcmc.opts=mcmcControl(mcmc=200,mcsave=20))
> nrow(om2$mcmc)  ## 10
>
>
> On Thu, Oct 16, 2014 at 7:18 AM, maren <maren.rebke at avitec-research.de 
> <mailto:maren.rebke at avitec-research.de>> wrote:
>
>     Hi,
>
>     I fit a zero-inflated Poisson model with random effects using the
>     package glmmADMB, which worked perfectly well. Now I am trying to get
>     credible intervals by running a Markov chain using mcmc=TRUE,
>     which also
>     works fine in general.
>
>     The problem is, that I have many parameters as well as several random
>     effects in my model and it seems that I need to run long chains to get
>     proper estimates. Therefore the automatically stored file eventually
>     gets very big and my computer cannot handle it anymore. Therefore I
>     would like to store only the samples of the estimates for the fixed
>     effects (only beta) and not the rest. Is that possible somehow?
>
>     I am not sure, but would it help to specify parameters via mcmcpars? I
>     tried to include mcmcpars in the owl example in section 2.2 from the
>     vignette of the package
>     (http://glmmadmb.r-forge.r-project.org/glmmADMB.pdf):
>
>     fit_zinbinom1_bs_mcmc <-
>     glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+BroodSize+(1|Nest),data=Owls,zeroInflation=TRUE,family="nbinom1",mcmc=TRUE,mcmc.opts=mcmcControl(mcmc=10,mcmcpars="beta"))
>
>     But unfortunately, I get an error message stating "unused argument
>     (mcmcpars="beta")". As I wasn't sure if I have to state the fixed
>     effects by using "beta" or the names of the parameters directly, I
>     also
>     tried including mcmcpars="BroodSize" but got the same error.
>
>     Is it not possible to define mcmcpars in glmmADMB? Is the
>     definition of
>     mcmcpars at all what I need and if so, how do I do it correctly?
>
>     Otherwise, is it possible to state that only the samples after a
>     certain
>     burnin period should be saved? Or can I play around with the jump
>     sizes
>     to reach faster convergence? As far as I understood those are rescaled
>     depending on the acceptance rate at the moment. The automatic
>     rescaling
>     can be switched off by stating mcnoscale=TRUE, which is working. But I
>     am not sure how I can then adjust the jump size and what the
>     default is.
>
>     Thank you very much for taking the time to read this long email.
>
>     Best wishes,
>
>     Maren Rebke
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


	[[alternative HTML version deleted]]


From bobyboby at gmail.com  Mon Oct 20 14:42:02 2014
From: bobyboby at gmail.com (Boby Mathew)
Date: Mon, 20 Oct 2014 14:42:02 +0200
Subject: [R-sig-ME] MCMCglmm prior distributions
In-Reply-To: <20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>
References: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
	<20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>
Message-ID: <CAP-GiWZ7Kt_exATW=cjXRwA6g=JtsxrCS=0w8w=j9Aa0cfB=BA@mail.gmail.com>

Dear Jarrod Hadfield,

Here I have attached a small code with the simulation code. I want to
estimate the effect of 'b' here. As you suggested I treated fixed effect as
random and gave own variance. But I am not sure this is the right way.

Could you please check whether the implementation is right?

regards,
Boby

mark=100; line=150

x=round(matrix(runif(mark*line),nrow=mark))
b=rep(0,mark)
b[8]=3; b[80]=5;b[90]=5;

noise=rnorm(line,0,sqrt(1))



Line=1:line

y = b%*%x + noise

Z=t(x)

library(MCMCglmm)

data=data.frame(Phe=t(y),animal=Line)

data$animal=as.factor(data$animal)


prior2.2 <- list(G = list(G1 = list(V = 1, n = 0.002)), R = list(V = 1, n =
0.002))

mod_mcmc=MCMCglmm(Phe~1,random=~idv(Z),pr=T,data=data,nitt=50000,thin=500,burnin=10000,prior=prior2.2)

val=colMeans (mod_mcmc$Sol)




On Thu, Oct 16, 2014 at 5:51 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi Boby,
>
> In short - no. I haven't tried this (or thought about it much), but you
> could treat each fixed effect as a single random effect with its own
> associated variance component. Presumably, you could then specify the prior
> for the variance component in a way that induces a prior t-distribution on
> the effect. Like the Laplace it has fatter tails than the Normal, but it
> lacks the peakiness and won't give some of the nice features of the LASSO.
>
> Cheers,
>
> Jarrod
>
>
>
>
> Quoting Boby Mathew <bobyboby at gmail.com> on Thu, 16 Oct 2014 16:06:13
> +0200:
>
>  Dear MCMCglmm users,
>>
>> Is it possible to use double exponential priors(Laplace) in MCMCglmm?
>>
>> Thanks for the helps.
>>
>> regards,
>> Boby
>>
>>
>> --
>> Dr. Boby Mathew
>> INRES, University of Bonn
>> Katzenburgweg 5
>> Phone: 0228732031
>> 53115, Bonn,Germany.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
Dr. Boby Mathew
INRES, University of Bonn
Katzenburgweg 5
Phone: 0228732031
53115, Bonn,Germany.

	[[alternative HTML version deleted]]


From emmanuel.curis at parisdescartes.fr  Mon Oct 20 14:45:13 2014
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Mon, 20 Oct 2014 14:45:13 +0200
Subject: [R-sig-ME] Modeling variance heterogeneity in lme4 + meaning of
	VarCorr values
Message-ID: <20141020124513.GA25800@info124.pharmacie.univ-paris5.fr>

Hello,

I am currently working on estimating precision of artery diameter by
an imaging technique. Every 5 mm along one artery, diameter is
measured. This was done 10 times by the same reader, and another 10
times by a second reader, both on the same image. The aim is to have
an idea of the standard deviation of the diameter.

At first glance, it seems to be much higher at both ends of the
artery, probably because diameter changes quickly here hence a very
small shift in the origin may have great influence on the diameter ---
imagine a king of >----< shape.

To test this hypothesis, I built the following models in lme4, where
? Diametre ? is the diameter, ? Lecteur ? the reader, ? Lecture ? the
reading and ? Position ? the position along the artery (as a factor);
d is the data.frame with the data:

# Single variance model
md.simple <- lmer( Diametre ~ Lecteur + Position + ( 1|Lecture ),
                   data = d, REML = FALSE )

# Different variance for each position model
#  1) building indicator variables for each position
for ( i in 0:7 ) {
    d[ , paste0( 'I.', i ) ] <- ifelse( d$Position == i, 1, 0 )
}

# 2) fit the model
md.tout   <- lmer( as.formula( paste( "Diametre ~ Lecteur + Position +",
                                      paste0( "(0+I.", 0:7,"|Lecture)",
                                      collapse = "+" ) ) ),
                   data = d, REML = FALSE )

My questions are

1) does it seem a pertinent model to really have a different variance
at each position? 

2) I guess it may be partly undetermined, since variance at position
is is the sum of the residual variance sigma? and the grouping term (
I.i|Lecture ) variance si?, hence if variance at position i is for
instance 1 and is the smallest of all variances, we can have si? = 1,
sigma?=0, the otherr way round and any other combination such that the
sum is 1. Is it right?

   lmer seems to fit the model with several si? = 0, which seems to
mean that sigma? gets the "baseline" variance and terms are used only
if local variance is ? much ? higher, is it true?

   It gives a warning ? In checkZrank(reTrms$Zt, n = n, control,
nonSmall = 1e+06) : number of observations <= rank(Z);
variance-covariance matrix will be unidentifiable ?, I guess this is
the result of unidentifiability. How far does it affects the results,
especially fixed effects estimates [? Reader ? effect] and further
model comparisons?

2) When I try to reconstruct local variances using sigma( md.tout )
and VarCorr( md.tout ), to compare them to variances obtained by
tapply( d$Diametre, d$Position, var ), I've noticed that actual
standard deviations at position i are in attributes stddev of VarCorr.

This is indeed said in the documentation; however, I did not found
what are the actual values stocked directly in VarCorr list. I guess
it corresponds to variances in the rescaled model? If it is so, how is
determined the rescaling parameter? If not, can anyone explain or give
some reference to a technical doc what are these values, and the link
with actual variances?

Thanks in advance,

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From j.hadfield at ed.ac.uk  Mon Oct 20 14:58:35 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 20 Oct 2014 13:58:35 +0100
Subject: [R-sig-ME] MCMCglmm prior distributions
In-Reply-To: <CAP-GiWZ7Kt_exATW=cjXRwA6g=JtsxrCS=0w8w=j9Aa0cfB=BA@mail.gmail.com>
References: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
	<20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>
	<CAP-GiWZ7Kt_exATW=cjXRwA6g=JtsxrCS=0w8w=j9Aa0cfB=BA@mail.gmail.com>
Message-ID: <20141020135835.743465u5qkezn2g4@www.staffmail.ed.ac.uk>

Hi,

This gives the b's a common variance. There is no point giving them  
individual variances unless you want to treat them as `fixed' but  
place a t-prior rather than a normal prior on each effect.

Jarrod




Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 14:42:02 +0200:

> Dear Jarrod Hadfield,
>
> Here I have attached a small code with the simulation code. I want to
> estimate the effect of 'b' here. As you suggested I treated fixed effect as
> random and gave own variance. But I am not sure this is the right way.
>
> Could you please check whether the implementation is right?
>
> regards,
> Boby
>
> mark=100; line=150
>
> x=round(matrix(runif(mark*line),nrow=mark))
> b=rep(0,mark)
> b[8]=3; b[80]=5;b[90]=5;
>
> noise=rnorm(line,0,sqrt(1))
>
>
>
> Line=1:line
>
> y = b%*%x + noise
>
> Z=t(x)
>
> library(MCMCglmm)
>
> data=data.frame(Phe=t(y),animal=Line)
>
> data$animal=as.factor(data$animal)
>
>
> prior2.2 <- list(G = list(G1 = list(V = 1, n = 0.002)), R = list(V = 1, n =
> 0.002))
>
> mod_mcmc=MCMCglmm(Phe~1,random=~idv(Z),pr=T,data=data,nitt=50000,thin=500,burnin=10000,prior=prior2.2)
>
> val=colMeans (mod_mcmc$Sol)
>
>
>
>
> On Thu, Oct 16, 2014 at 5:51 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi Boby,
>>
>> In short - no. I haven't tried this (or thought about it much), but you
>> could treat each fixed effect as a single random effect with its own
>> associated variance component. Presumably, you could then specify the prior
>> for the variance component in a way that induces a prior t-distribution on
>> the effect. Like the Laplace it has fatter tails than the Normal, but it
>> lacks the peakiness and won't give some of the nice features of the LASSO.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Boby Mathew <bobyboby at gmail.com> on Thu, 16 Oct 2014 16:06:13
>> +0200:
>>
>>  Dear MCMCglmm users,
>>>
>>> Is it possible to use double exponential priors(Laplace) in MCMCglmm?
>>>
>>> Thanks for the helps.
>>>
>>> regards,
>>> Boby
>>>
>>>
>>> --
>>> Dr. Boby Mathew
>>> INRES, University of Bonn
>>> Katzenburgweg 5
>>> Phone: 0228732031
>>> 53115, Bonn,Germany.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> Dr. Boby Mathew
> INRES, University of Bonn
> Katzenburgweg 5
> Phone: 0228732031
> 53115, Bonn,Germany.
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bobyboby at gmail.com  Mon Oct 20 15:52:24 2014
From: bobyboby at gmail.com (Boby Mathew)
Date: Mon, 20 Oct 2014 15:52:24 +0200
Subject: [R-sig-ME] MCMCglmm prior distributions
In-Reply-To: <20141020135835.743465u5qkezn2g4@www.staffmail.ed.ac.uk>
References: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
	<20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>
	<CAP-GiWZ7Kt_exATW=cjXRwA6g=JtsxrCS=0w8w=j9Aa0cfB=BA@mail.gmail.com>
	<20141020135835.743465u5qkezn2g4@www.staffmail.ed.ac.uk>
Message-ID: <CAP-GiWa8Ah-tQZic5Hg+FZ_pwB_VaWwKGbrGZnA0z_RynkgMMg@mail.gmail.com>

Dear jarrod hadfield,

How can I pace  individual variances with a t-prior for the random effects?
Could you please provide me an example?

thanks for the help.

regards,
Boby

On Mon, Oct 20, 2014 at 2:58 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi,
>
> This gives the b's a common variance. There is no point giving them
> individual variances unless you want to treat them as `fixed' but place a
> t-prior rather than a normal prior on each effect.
>
> Jarrod
>
>
>
>
>
> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 14:42:02
> +0200:
>
>  Dear Jarrod Hadfield,
>>
>> Here I have attached a small code with the simulation code. I want to
>> estimate the effect of 'b' here. As you suggested I treated fixed effect
>> as
>> random and gave own variance. But I am not sure this is the right way.
>>
>> Could you please check whether the implementation is right?
>>
>> regards,
>> Boby
>>
>> mark=100; line=150
>>
>> x=round(matrix(runif(mark*line),nrow=mark))
>> b=rep(0,mark)
>> b[8]=3; b[80]=5;b[90]=5;
>>
>> noise=rnorm(line,0,sqrt(1))
>>
>>
>>
>> Line=1:line
>>
>> y = b%*%x + noise
>>
>> Z=t(x)
>>
>> library(MCMCglmm)
>>
>> data=data.frame(Phe=t(y),animal=Line)
>>
>> data$animal=as.factor(data$animal)
>>
>>
>> prior2.2 <- list(G = list(G1 = list(V = 1, n = 0.002)), R = list(V = 1, n
>> =
>> 0.002))
>>
>> mod_mcmc=MCMCglmm(Phe~1,random=~idv(Z),pr=T,data=data,
>> nitt=50000,thin=500,burnin=10000,prior=prior2.2)
>>
>> val=colMeans (mod_mcmc$Sol)
>>
>>
>>
>>
>> On Thu, Oct 16, 2014 at 5:51 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>  Hi Boby,
>>>
>>> In short - no. I haven't tried this (or thought about it much), but you
>>> could treat each fixed effect as a single random effect with its own
>>> associated variance component. Presumably, you could then specify the
>>> prior
>>> for the variance component in a way that induces a prior t-distribution
>>> on
>>> the effect. Like the Laplace it has fatter tails than the Normal, but it
>>> lacks the peakiness and won't give some of the nice features of the
>>> LASSO.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>> Quoting Boby Mathew <bobyboby at gmail.com> on Thu, 16 Oct 2014 16:06:13
>>> +0200:
>>>
>>>  Dear MCMCglmm users,
>>>
>>>>
>>>> Is it possible to use double exponential priors(Laplace) in MCMCglmm?
>>>>
>>>> Thanks for the helps.
>>>>
>>>> regards,
>>>> Boby
>>>>
>>>>
>>>> --
>>>> Dr. Boby Mathew
>>>> INRES, University of Bonn
>>>> Katzenburgweg 5
>>>> Phone: 0228732031
>>>> 53115, Bonn,Germany.
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>>
>>
>> --
>> Dr. Boby Mathew
>> INRES, University of Bonn
>> Katzenburgweg 5
>> Phone: 0228732031
>> 53115, Bonn,Germany.
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
Dr. Boby Mathew
INRES, University of Bonn
Katzenburgweg 5
Phone: 0228732031
53115, Bonn,Germany.

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Oct 20 16:17:59 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 20 Oct 2014 15:17:59 +0100
Subject: [R-sig-ME] MCMCglmm prior distributions
In-Reply-To: <CAP-GiWa8Ah-tQZic5Hg+FZ_pwB_VaWwKGbrGZnA0z_RynkgMMg@mail.gmail.com>
References: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
	<20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>
	<CAP-GiWZ7Kt_exATW=cjXRwA6g=JtsxrCS=0w8w=j9Aa0cfB=BA@mail.gmail.com>
	<20141020135835.743465u5qkezn2g4@www.staffmail.ed.ac.uk>
	<CAP-GiWa8Ah-tQZic5Hg+FZ_pwB_VaWwKGbrGZnA0z_RynkgMMg@mail.gmail.com>
Message-ID: <20141020151759.13000l1c3buraqw0@www.staffmail.ed.ac.uk>

Hi Boby,

If you mean a common t-prior (with estimated scale) for the random  
effects then you cannot. All that you can do is place a fixed t-prior  
on the `fixed' effects.

Cheers,

Jarrod




Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 15:52:24 +0200:

> Dear jarrod hadfield,
>
> How can I pace  individual variances with a t-prior for the random effects?
> Could you please provide me an example?
>
> thanks for the help.
>
> regards,
> Boby
>
> On Mon, Oct 20, 2014 at 2:58 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi,
>>
>> This gives the b's a common variance. There is no point giving them
>> individual variances unless you want to treat them as `fixed' but place a
>> t-prior rather than a normal prior on each effect.
>>
>> Jarrod
>>
>>
>>
>>
>>
>> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 14:42:02
>> +0200:
>>
>>  Dear Jarrod Hadfield,
>>>
>>> Here I have attached a small code with the simulation code. I want to
>>> estimate the effect of 'b' here. As you suggested I treated fixed effect
>>> as
>>> random and gave own variance. But I am not sure this is the right way.
>>>
>>> Could you please check whether the implementation is right?
>>>
>>> regards,
>>> Boby
>>>
>>> mark=100; line=150
>>>
>>> x=round(matrix(runif(mark*line),nrow=mark))
>>> b=rep(0,mark)
>>> b[8]=3; b[80]=5;b[90]=5;
>>>
>>> noise=rnorm(line,0,sqrt(1))
>>>
>>>
>>>
>>> Line=1:line
>>>
>>> y = b%*%x + noise
>>>
>>> Z=t(x)
>>>
>>> library(MCMCglmm)
>>>
>>> data=data.frame(Phe=t(y),animal=Line)
>>>
>>> data$animal=as.factor(data$animal)
>>>
>>>
>>> prior2.2 <- list(G = list(G1 = list(V = 1, n = 0.002)), R = list(V = 1, n
>>> =
>>> 0.002))
>>>
>>> mod_mcmc=MCMCglmm(Phe~1,random=~idv(Z),pr=T,data=data,
>>> nitt=50000,thin=500,burnin=10000,prior=prior2.2)
>>>
>>> val=colMeans (mod_mcmc$Sol)
>>>
>>>
>>>
>>>
>>> On Thu, Oct 16, 2014 at 5:51 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> wrote:
>>>
>>>  Hi Boby,
>>>>
>>>> In short - no. I haven't tried this (or thought about it much), but you
>>>> could treat each fixed effect as a single random effect with its own
>>>> associated variance component. Presumably, you could then specify the
>>>> prior
>>>> for the variance component in a way that induces a prior t-distribution
>>>> on
>>>> the effect. Like the Laplace it has fatter tails than the Normal, but it
>>>> lacks the peakiness and won't give some of the nice features of the
>>>> LASSO.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>> Quoting Boby Mathew <bobyboby at gmail.com> on Thu, 16 Oct 2014 16:06:13
>>>> +0200:
>>>>
>>>>  Dear MCMCglmm users,
>>>>
>>>>>
>>>>> Is it possible to use double exponential priors(Laplace) in MCMCglmm?
>>>>>
>>>>> Thanks for the helps.
>>>>>
>>>>> regards,
>>>>> Boby
>>>>>
>>>>>
>>>>> --
>>>>> Dr. Boby Mathew
>>>>> INRES, University of Bonn
>>>>> Katzenburgweg 5
>>>>> Phone: 0228732031
>>>>> 53115, Bonn,Germany.
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> Dr. Boby Mathew
>>> INRES, University of Bonn
>>> Katzenburgweg 5
>>> Phone: 0228732031
>>> 53115, Bonn,Germany.
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> Dr. Boby Mathew
> INRES, University of Bonn
> Katzenburgweg 5
> Phone: 0228732031
> 53115, Bonn,Germany.
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Thierry.ONKELINX at inbo.be  Mon Oct 20 16:49:34 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 20 Oct 2014 14:49:34 +0000
Subject: [R-sig-ME] Modeling variance heterogeneity in lme4 + meaning
	of	VarCorr values
In-Reply-To: <20141020124513.GA25800@info124.pharmacie.univ-paris5.fr>
References: <20141020124513.GA25800@info124.pharmacie.univ-paris5.fr>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B0795C@inbomail.inbo.be>

Dear Emmanuel,

You don't need to create the dummy variables. Just convert Position to a new factor variable. It makes your code much more readable.

d$fPosition <- factor(d$Position)
lmer( Diametre ~ Lecteur + Position + ( 0 + fPosition|Lecture ), data = d, REML = FALSE )

This allows for different variances of the random effect over Lecture, depending on the value of fPosition. This comes at the cost of estimating all covariances as well. So you need to estimate 36 parameters (8 variances and 28 covariances). That is a high number of parameters given the size of your dataset.

A more efficient solution would be to use lme() from the nlme() package and allow for heterogeneity in the variance of the residuals.

lme(Diametre ~ Lecteur + Position, random = ~1|Lecture, weights = varIdent(~ 1|fPosition), data = d, REML = FALSE)

Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Emmanuel Curis
Verzonden: maandag 20 oktober 2014 14:45
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Modeling variance heterogeneity in lme4 + meaning of VarCorr values

Hello,

I am currently working on estimating precision of artery diameter by an imaging technique. Every 5 mm along one artery, diameter is measured. This was done 10 times by the same reader, and another 10 times by a second reader, both on the same image. The aim is to have an idea of the standard deviation of the diameter.

At first glance, it seems to be much higher at both ends of the artery, probably because diameter changes quickly here hence a very small shift in the origin may have great influence on the diameter --- imagine a king of >----< shape.

To test this hypothesis, I built the following models in lme4, where ? Diametre ? is the diameter, ? Lecteur ? the reader, ? Lecture ? the reading and ? Position ? the position along the artery (as a factor); d is the data.frame with the data:

# Single variance model
md.simple <- lmer( Diametre ~ Lecteur + Position + ( 1|Lecture ),
                   data = d, REML = FALSE )

# Different variance for each position model #  1) building indicator variables for each position for ( i in 0:7 ) {
    d[ , paste0( 'I.', i ) ] <- ifelse( d$Position == i, 1, 0 ) }

# 2) fit the model
md.tout   <- lmer( as.formula( paste( "Diametre ~ Lecteur + Position +",
                                      paste0( "(0+I.", 0:7,"|Lecture)",
                                      collapse = "+" ) ) ),
                   data = d, REML = FALSE )

My questions are

1) does it seem a pertinent model to really have a different variance at each position?

2) I guess it may be partly undetermined, since variance at position is is the sum of the residual variance sigma? and the grouping term ( I.i|Lecture ) variance si?, hence if variance at position i is for instance 1 and is the smallest of all variances, we can have si? = 1, sigma?=0, the otherr way round and any other combination such that the sum is 1. Is it right?

   lmer seems to fit the model with several si? = 0, which seems to mean that sigma? gets the "baseline" variance and terms are used only if local variance is ? much ? higher, is it true?

   It gives a warning ? In checkZrank(reTrms$Zt, n = n, control, nonSmall = 1e+06) : number of observations <= rank(Z); variance-covariance matrix will be unidentifiable ?, I guess this is the result of unidentifiability. How far does it affects the results, especially fixed effects estimates [? Reader ? effect] and further model comparisons?

2) When I try to reconstruct local variances using sigma( md.tout ) and VarCorr( md.tout ), to compare them to variances obtained by tapply( d$Diametre, d$Position, var ), I've noticed that actual standard deviations at position i are in attributes stddev of VarCorr.

This is indeed said in the documentation; however, I did not found what are the actual values stocked directly in VarCorr list. I guess it corresponds to variances in the rescaled model? If it is so, how is determined the rescaling parameter? If not, can anyone explain or give some reference to a technical doc what are these values, and the link with actual variances?

Thanks in advance,

--
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bobyboby at gmail.com  Mon Oct 20 17:09:52 2014
From: bobyboby at gmail.com (Boby Mathew)
Date: Mon, 20 Oct 2014 17:09:52 +0200
Subject: [R-sig-ME] MCMCglmm prior distributions
In-Reply-To: <20141020151759.13000l1c3buraqw0@www.staffmail.ed.ac.uk>
References: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
	<20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>
	<CAP-GiWZ7Kt_exATW=cjXRwA6g=JtsxrCS=0w8w=j9Aa0cfB=BA@mail.gmail.com>
	<20141020135835.743465u5qkezn2g4@www.staffmail.ed.ac.uk>
	<CAP-GiWa8Ah-tQZic5Hg+FZ_pwB_VaWwKGbrGZnA0z_RynkgMMg@mail.gmail.com>
	<20141020151759.13000l1c3buraqw0@www.staffmail.ed.ac.uk>
Message-ID: <CAP-GiWYpmxRHboGdRSMo0yu5+e=+Om8M=H5FrAZ1PA8fv8Wmvw@mail.gmail.com>

Hello Jarrod Hadfield,

Thank you so much for your help.  I have the winbugs code for estimation of
my marker effect but the problem is winbugs is too slow and cannot handle
large datasets.

my models is "y(observation) =Z%*%beta + noise"

here 'Z is the markers matrix coded 0 and 1 and beta is marker effect  I
used MCMCglmm for this model and included the marker matrix(Z) as random
(random=~idv(Z)).

I simulated some data and MCMCglmm was giving good results when the number
of markers were less than the number of observation. Does MCMCglmm can
handle this type of models?



I have attached the winbugs code here  for the reference.


model{
for(i in 1:n){
    y[i]~dnorm(mu[i],prec)
    mu[i]<- inprod(x[i,], beta[])
        }
for (j in 1: p){
    beta[j]~dnorm(0,tau[j])
    tau[j]<-1/var[j]
    var[j]~dgamma(0.1,0.1)
    }
sd~dunif(0,10)
sigma2<-sd*sd
prec<-1/sigma2

    }

Once again thanks for the help

regards,
Boby

On Mon, Oct 20, 2014 at 4:17 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi Boby,
>
> If you mean a common t-prior (with estimated scale) for the random effects
> then you cannot. All that you can do is place a fixed t-prior on the
> `fixed' effects.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 15:52:24
> +0200:
>
>  Dear jarrod hadfield,
>>
>> How can I pace  individual variances with a t-prior for the random
>> effects?
>> Could you please provide me an example?
>>
>> thanks for the help.
>>
>> regards,
>> Boby
>>
>> On Mon, Oct 20, 2014 at 2:58 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>  Hi,
>>>
>>> This gives the b's a common variance. There is no point giving them
>>> individual variances unless you want to treat them as `fixed' but place a
>>> t-prior rather than a normal prior on each effect.
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 14:42:02
>>> +0200:
>>>
>>>  Dear Jarrod Hadfield,
>>>
>>>>
>>>> Here I have attached a small code with the simulation code. I want to
>>>> estimate the effect of 'b' here. As you suggested I treated fixed effect
>>>> as
>>>> random and gave own variance. But I am not sure this is the right way.
>>>>
>>>> Could you please check whether the implementation is right?
>>>>
>>>> regards,
>>>> Boby
>>>>
>>>> mark=100; line=150
>>>>
>>>> x=round(matrix(runif(mark*line),nrow=mark))
>>>> b=rep(0,mark)
>>>> b[8]=3; b[80]=5;b[90]=5;
>>>>
>>>> noise=rnorm(line,0,sqrt(1))
>>>>
>>>>
>>>>
>>>> Line=1:line
>>>>
>>>> y = b%*%x + noise
>>>>
>>>> Z=t(x)
>>>>
>>>> library(MCMCglmm)
>>>>
>>>> data=data.frame(Phe=t(y),animal=Line)
>>>>
>>>> data$animal=as.factor(data$animal)
>>>>
>>>>
>>>> prior2.2 <- list(G = list(G1 = list(V = 1, n = 0.002)), R = list(V = 1,
>>>> n
>>>> =
>>>> 0.002))
>>>>
>>>> mod_mcmc=MCMCglmm(Phe~1,random=~idv(Z),pr=T,data=data,
>>>> nitt=50000,thin=500,burnin=10000,prior=prior2.2)
>>>>
>>>> val=colMeans (mod_mcmc$Sol)
>>>>
>>>>
>>>>
>>>>
>>>> On Thu, Oct 16, 2014 at 5:51 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> wrote:
>>>>
>>>>  Hi Boby,
>>>>
>>>>>
>>>>> In short - no. I haven't tried this (or thought about it much), but you
>>>>> could treat each fixed effect as a single random effect with its own
>>>>> associated variance component. Presumably, you could then specify the
>>>>> prior
>>>>> for the variance component in a way that induces a prior t-distribution
>>>>> on
>>>>> the effect. Like the Laplace it has fatter tails than the Normal, but
>>>>> it
>>>>> lacks the peakiness and won't give some of the nice features of the
>>>>> LASSO.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Quoting Boby Mathew <bobyboby at gmail.com> on Thu, 16 Oct 2014 16:06:13
>>>>> +0200:
>>>>>
>>>>>  Dear MCMCglmm users,
>>>>>
>>>>>
>>>>>> Is it possible to use double exponential priors(Laplace) in MCMCglmm?
>>>>>>
>>>>>> Thanks for the helps.
>>>>>>
>>>>>> regards,
>>>>>> Boby
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Dr. Boby Mathew
>>>>>> INRES, University of Bonn
>>>>>> Katzenburgweg 5
>>>>>> Phone: 0228732031
>>>>>> 53115, Bonn,Germany.
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>> --
>>>> Dr. Boby Mathew
>>>> INRES, University of Bonn
>>>> Katzenburgweg 5
>>>> Phone: 0228732031
>>>> 53115, Bonn,Germany.
>>>>
>>>>
>>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>>
>>
>> --
>> Dr. Boby Mathew
>> INRES, University of Bonn
>> Katzenburgweg 5
>> Phone: 0228732031
>> 53115, Bonn,Germany.
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
Dr. Boby Mathew
INRES, University of Bonn
Katzenburgweg 5
Phone: 0228732031
53115, Bonn,Germany.

	[[alternative HTML version deleted]]


From emmanuel.curis at parisdescartes.fr  Mon Oct 20 17:15:51 2014
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Mon, 20 Oct 2014 17:15:51 +0200
Subject: [R-sig-ME] Modeling variance heterogeneity in lme4 + meaning of
 VarCorr values
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3B0795C@inbomail.inbo.be>
References: <20141020124513.GA25800@info124.pharmacie.univ-paris5.fr>
	<AA818EAD2576BC488B4F623941DA7427F3B0795C@inbomail.inbo.be>
Message-ID: <20141020151551.GB3947@info124.pharmacie.univ-paris5.fr>

Dear Thierry,

Thanks for the answer, and the hints.

I created the dummy variables first to avoid correlations between
random effects (sorry I forgot to mention it) to limit the number of
parameters and because I don't really see what they would mean
practically, and second (and more importantly) to try after some more
refinate models like ? is the variance at both ends higher that
variance all along other points ? (as suggested by the shape of the
artery and the possible explanation of higher variances at both ends),
with only two different variances in the model. Obviously, it asks the
question of the meaning of correlations or not between random effects,
for which I have no clear idea, especially for such a model: any help
for interpreting (the origin of) such correlations would be very
appreciated.

For the lme variant: thanks for clarifying the syntax. I was wondering
what tools would be available to compare the random effects/models in
such a case, since I think LRT is not appropriate in these cases ---
that is why I tried first with lme4 to use after that PBmodcomp
(which, incidentaly, fails with a message about different size in data
frames, but I'm not sure yet that I correctly understood its
usage). But I will try your suggestion, to see if I obtain similar
results.

Would the lme model with different variances in residuals be
equivalent to the model in lme4 without correlations between random
effects? Or does it induce a different variance-covariance structure
for the response?

Best regards,

On Mon, Oct 20, 2014 at 02:49:34PM +0000, ONKELINX, Thierry wrote:
? Dear Emmanuel,
? 
? You don't need to create the dummy variables. Just convert Position to a new factor variable. It makes your code much more readable.
? 
? d$fPosition <- factor(d$Position)
? lmer( Diametre ~ Lecteur + Position + ( 0 + fPosition|Lecture ), data = d, REML = FALSE )
? 
? This allows for different variances of the random effect over Lecture, depending on the value of fPosition. This comes at the cost of estimating all covariances as well. So you need to estimate 36 parameters (8 variances and 28 covariances). That is a high number of parameters given the size of your dataset.
? 
? A more efficient solution would be to use lme() from the nlme() package and allow for heterogeneity in the variance of the residuals.
? 
? lme(Diametre ~ Lecteur + Position, random = ~1|Lecture, weights = varIdent(~ 1|fPosition), data = d, REML = FALSE)
? 
? Best regards,
? 
? Thierry

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From j.hadfield at ed.ac.uk  Mon Oct 20 19:03:12 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 20 Oct 2014 18:03:12 +0100
Subject: [R-sig-ME] MCMCglmm prior distributions
In-Reply-To: <CAP-GiWYpmxRHboGdRSMo0yu5+e=+Om8M=H5FrAZ1PA8fv8Wmvw@mail.gmail.com>
References: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
	<20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>
	<CAP-GiWZ7Kt_exATW=cjXRwA6g=JtsxrCS=0w8w=j9Aa0cfB=BA@mail.gmail.com>
	<20141020135835.743465u5qkezn2g4@www.staffmail.ed.ac.uk>
	<CAP-GiWa8Ah-tQZic5Hg+FZ_pwB_VaWwKGbrGZnA0z_RynkgMMg@mail.gmail.com>
	<20141020151759.13000l1c3buraqw0@www.staffmail.ed.ac.uk>
	<CAP-GiWYpmxRHboGdRSMo0yu5+e=+Om8M=H5FrAZ1PA8fv8Wmvw@mail.gmail.com>
Message-ID: <20141020180312.108258t11z4l08gs@www.staffmail.ed.ac.uk>

Hi,

If the beta's are drawn from a normal distribution with the same  
variance then the idv(Z) model is appropriate. I thought you would get  
an error message with your code because Z was not in the data.frame.  
If this was not the case could you send me your sessionInfo()?

Cheers,

JArrod







Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 17:09:52 +0200:

> Hello Jarrod Hadfield,
>
> Thank you so much for your help.  I have the winbugs code for estimation of
> my marker effect but the problem is winbugs is too slow and cannot handle
> large datasets.
>
> my models is "y(observation) =Z%*%beta + noise"
>
> here 'Z is the markers matrix coded 0 and 1 and beta is marker effect  I
> used MCMCglmm for this model and included the marker matrix(Z) as random
> (random=~idv(Z)).
>
> I simulated some data and MCMCglmm was giving good results when the number
> of markers were less than the number of observation. Does MCMCglmm can
> handle this type of models?
>
>
>
> I have attached the winbugs code here  for the reference.
>
>
> model{
> for(i in 1:n){
>     y[i]~dnorm(mu[i],prec)
>     mu[i]<- inprod(x[i,], beta[])
>         }
> for (j in 1: p){
>     beta[j]~dnorm(0,tau[j])
>     tau[j]<-1/var[j]
>     var[j]~dgamma(0.1,0.1)
>     }
> sd~dunif(0,10)
> sigma2<-sd*sd
> prec<-1/sigma2
>
>     }
>
> Once again thanks for the help
>
> regards,
> Boby
>
> On Mon, Oct 20, 2014 at 4:17 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi Boby,
>>
>> If you mean a common t-prior (with estimated scale) for the random effects
>> then you cannot. All that you can do is place a fixed t-prior on the
>> `fixed' effects.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 15:52:24
>> +0200:
>>
>>  Dear jarrod hadfield,
>>>
>>> How can I pace  individual variances with a t-prior for the random
>>> effects?
>>> Could you please provide me an example?
>>>
>>> thanks for the help.
>>>
>>> regards,
>>> Boby
>>>
>>> On Mon, Oct 20, 2014 at 2:58 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> wrote:
>>>
>>>  Hi,
>>>>
>>>> This gives the b's a common variance. There is no point giving them
>>>> individual variances unless you want to treat them as `fixed' but place a
>>>> t-prior rather than a normal prior on each effect.
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 14:42:02
>>>> +0200:
>>>>
>>>>  Dear Jarrod Hadfield,
>>>>
>>>>>
>>>>> Here I have attached a small code with the simulation code. I want to
>>>>> estimate the effect of 'b' here. As you suggested I treated fixed effect
>>>>> as
>>>>> random and gave own variance. But I am not sure this is the right way.
>>>>>
>>>>> Could you please check whether the implementation is right?
>>>>>
>>>>> regards,
>>>>> Boby
>>>>>
>>>>> mark=100; line=150
>>>>>
>>>>> x=round(matrix(runif(mark*line),nrow=mark))
>>>>> b=rep(0,mark)
>>>>> b[8]=3; b[80]=5;b[90]=5;
>>>>>
>>>>> noise=rnorm(line,0,sqrt(1))
>>>>>
>>>>>
>>>>>
>>>>> Line=1:line
>>>>>
>>>>> y = b%*%x + noise
>>>>>
>>>>> Z=t(x)
>>>>>
>>>>> library(MCMCglmm)
>>>>>
>>>>> data=data.frame(Phe=t(y),animal=Line)
>>>>>
>>>>> data$animal=as.factor(data$animal)
>>>>>
>>>>>
>>>>> prior2.2 <- list(G = list(G1 = list(V = 1, n = 0.002)), R = list(V = 1,
>>>>> n
>>>>> =
>>>>> 0.002))
>>>>>
>>>>> mod_mcmc=MCMCglmm(Phe~1,random=~idv(Z),pr=T,data=data,
>>>>> nitt=50000,thin=500,burnin=10000,prior=prior2.2)
>>>>>
>>>>> val=colMeans (mod_mcmc$Sol)
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Thu, Oct 16, 2014 at 5:51 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>> wrote:
>>>>>
>>>>>  Hi Boby,
>>>>>
>>>>>>
>>>>>> In short - no. I haven't tried this (or thought about it much), but you
>>>>>> could treat each fixed effect as a single random effect with its own
>>>>>> associated variance component. Presumably, you could then specify the
>>>>>> prior
>>>>>> for the variance component in a way that induces a prior t-distribution
>>>>>> on
>>>>>> the effect. Like the Laplace it has fatter tails than the Normal, but
>>>>>> it
>>>>>> lacks the peakiness and won't give some of the nice features of the
>>>>>> LASSO.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Quoting Boby Mathew <bobyboby at gmail.com> on Thu, 16 Oct 2014 16:06:13
>>>>>> +0200:
>>>>>>
>>>>>>  Dear MCMCglmm users,
>>>>>>
>>>>>>
>>>>>>> Is it possible to use double exponential priors(Laplace) in MCMCglmm?
>>>>>>>
>>>>>>> Thanks for the helps.
>>>>>>>
>>>>>>> regards,
>>>>>>> Boby
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Dr. Boby Mathew
>>>>>>> INRES, University of Bonn
>>>>>>> Katzenburgweg 5
>>>>>>> Phone: 0228732031
>>>>>>> 53115, Bonn,Germany.
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>> --
>>>>> Dr. Boby Mathew
>>>>> INRES, University of Bonn
>>>>> Katzenburgweg 5
>>>>> Phone: 0228732031
>>>>> 53115, Bonn,Germany.
>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> Dr. Boby Mathew
>>> INRES, University of Bonn
>>> Katzenburgweg 5
>>> Phone: 0228732031
>>> 53115, Bonn,Germany.
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> Dr. Boby Mathew
> INRES, University of Bonn
> Katzenburgweg 5
> Phone: 0228732031
> 53115, Bonn,Germany.
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bobyboby at gmail.com  Tue Oct 21 08:52:29 2014
From: bobyboby at gmail.com (Boby Mathew)
Date: Tue, 21 Oct 2014 08:52:29 +0200
Subject: [R-sig-ME] MCMCglmm prior distributions
In-Reply-To: <20141020180312.108258t11z4l08gs@www.staffmail.ed.ac.uk>
References: <CAP-GiWY1axWbPsUkJcKk+C2FmwfgUEh+2SBy_isBfG6tVRpT-w@mail.gmail.com>
	<20141016165100.13477eh8mkb10rok@www.staffmail.ed.ac.uk>
	<CAP-GiWZ7Kt_exATW=cjXRwA6g=JtsxrCS=0w8w=j9Aa0cfB=BA@mail.gmail.com>
	<20141020135835.743465u5qkezn2g4@www.staffmail.ed.ac.uk>
	<CAP-GiWa8Ah-tQZic5Hg+FZ_pwB_VaWwKGbrGZnA0z_RynkgMMg@mail.gmail.com>
	<20141020151759.13000l1c3buraqw0@www.staffmail.ed.ac.uk>
	<CAP-GiWYpmxRHboGdRSMo0yu5+e=+Om8M=H5FrAZ1PA8fv8Wmvw@mail.gmail.com>
	<20141020180312.108258t11z4l08gs@www.staffmail.ed.ac.uk>
Message-ID: <CAP-GiWZ_NHoesPzNAcz6UMEx_qDoHChpAPtwQcHkgS_w=AvVrQ@mail.gmail.com>

Hello Jarrod Hadfield,

Below I have attached the sessionInfo().  So if  beta's~ N(0,sigma^2)  then
the G structure assign prior for sigma^2~Inv-Gamma(a,b). Is it right?.

Also is it possible to assign  beta's some other distributions?

Thanks for the help.

regards,
Boby



R version 3.1.0 (2014-04-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] INLA_0.0-1392038736 sp_1.0-15           MCMCglmm_2.21
[4] ape_3.1-4           coda_0.16-1         lattice_0.20-29
[7] Matrix_1.1-4

loaded via a namespace (and not attached):
[1] corpcor_1.6.7 grid_3.1.0    nlme_3.1-118  tcltk_3.1.0   tensorA_0.36
[6] tools_3.1.0


On Mon, Oct 20, 2014 at 7:03 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi,
>
> If the beta's are drawn from a normal distribution with the same variance
> then the idv(Z) model is appropriate. I thought you would get an error
> message with your code because Z was not in the data.frame. If this was not
> the case could you send me your sessionInfo()?
>
> Cheers,
>
> JArrod
>
>
>
>
>
>
>
>
> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 17:09:52
> +0200:
>
>  Hello Jarrod Hadfield,
>>
>> Thank you so much for your help.  I have the winbugs code for estimation
>> of
>> my marker effect but the problem is winbugs is too slow and cannot handle
>> large datasets.
>>
>> my models is "y(observation) =Z%*%beta + noise"
>>
>> here 'Z is the markers matrix coded 0 and 1 and beta is marker effect  I
>> used MCMCglmm for this model and included the marker matrix(Z) as random
>> (random=~idv(Z)).
>>
>> I simulated some data and MCMCglmm was giving good results when the number
>> of markers were less than the number of observation. Does MCMCglmm can
>> handle this type of models?
>>
>>
>>
>> I have attached the winbugs code here  for the reference.
>>
>>
>> model{
>> for(i in 1:n){
>>     y[i]~dnorm(mu[i],prec)
>>     mu[i]<- inprod(x[i,], beta[])
>>         }
>> for (j in 1: p){
>>     beta[j]~dnorm(0,tau[j])
>>     tau[j]<-1/var[j]
>>     var[j]~dgamma(0.1,0.1)
>>     }
>> sd~dunif(0,10)
>> sigma2<-sd*sd
>> prec<-1/sigma2
>>
>>     }
>>
>> Once again thanks for the help
>>
>> regards,
>> Boby
>>
>> On Mon, Oct 20, 2014 at 4:17 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>  Hi Boby,
>>>
>>> If you mean a common t-prior (with estimated scale) for the random
>>> effects
>>> then you cannot. All that you can do is place a fixed t-prior on the
>>> `fixed' effects.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 15:52:24
>>> +0200:
>>>
>>>  Dear jarrod hadfield,
>>>
>>>>
>>>> How can I pace  individual variances with a t-prior for the random
>>>> effects?
>>>> Could you please provide me an example?
>>>>
>>>> thanks for the help.
>>>>
>>>> regards,
>>>> Boby
>>>>
>>>> On Mon, Oct 20, 2014 at 2:58 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> wrote:
>>>>
>>>>  Hi,
>>>>
>>>>>
>>>>> This gives the b's a common variance. There is no point giving them
>>>>> individual variances unless you want to treat them as `fixed' but
>>>>> place a
>>>>> t-prior rather than a normal prior on each effect.
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Quoting Boby Mathew <bobyboby at gmail.com> on Mon, 20 Oct 2014 14:42:02
>>>>> +0200:
>>>>>
>>>>>  Dear Jarrod Hadfield,
>>>>>
>>>>>
>>>>>> Here I have attached a small code with the simulation code. I want to
>>>>>> estimate the effect of 'b' here. As you suggested I treated fixed
>>>>>> effect
>>>>>> as
>>>>>> random and gave own variance. But I am not sure this is the right way.
>>>>>>
>>>>>> Could you please check whether the implementation is right?
>>>>>>
>>>>>> regards,
>>>>>> Boby
>>>>>>
>>>>>> mark=100; line=150
>>>>>>
>>>>>> x=round(matrix(runif(mark*line),nrow=mark))
>>>>>> b=rep(0,mark)
>>>>>> b[8]=3; b[80]=5;b[90]=5;
>>>>>>
>>>>>> noise=rnorm(line,0,sqrt(1))
>>>>>>
>>>>>>
>>>>>>
>>>>>> Line=1:line
>>>>>>
>>>>>> y = b%*%x + noise
>>>>>>
>>>>>> Z=t(x)
>>>>>>
>>>>>> library(MCMCglmm)
>>>>>>
>>>>>> data=data.frame(Phe=t(y),animal=Line)
>>>>>>
>>>>>> data$animal=as.factor(data$animal)
>>>>>>
>>>>>>
>>>>>> prior2.2 <- list(G = list(G1 = list(V = 1, n = 0.002)), R = list(V =
>>>>>> 1,
>>>>>> n
>>>>>> =
>>>>>> 0.002))
>>>>>>
>>>>>> mod_mcmc=MCMCglmm(Phe~1,random=~idv(Z),pr=T,data=data,
>>>>>> nitt=50000,thin=500,burnin=10000,prior=prior2.2)
>>>>>>
>>>>>> val=colMeans (mod_mcmc$Sol)
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Thu, Oct 16, 2014 at 5:51 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk
>>>>>> >
>>>>>> wrote:
>>>>>>
>>>>>>  Hi Boby,
>>>>>>
>>>>>>
>>>>>>> In short - no. I haven't tried this (or thought about it much), but
>>>>>>> you
>>>>>>> could treat each fixed effect as a single random effect with its own
>>>>>>> associated variance component. Presumably, you could then specify the
>>>>>>> prior
>>>>>>> for the variance component in a way that induces a prior
>>>>>>> t-distribution
>>>>>>> on
>>>>>>> the effect. Like the Laplace it has fatter tails than the Normal, but
>>>>>>> it
>>>>>>> lacks the peakiness and won't give some of the nice features of the
>>>>>>> LASSO.
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>> Jarrod
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Quoting Boby Mathew <bobyboby at gmail.com> on Thu, 16 Oct 2014
>>>>>>> 16:06:13
>>>>>>> +0200:
>>>>>>>
>>>>>>>  Dear MCMCglmm users,
>>>>>>>
>>>>>>>
>>>>>>>  Is it possible to use double exponential priors(Laplace) in
>>>>>>>> MCMCglmm?
>>>>>>>>
>>>>>>>> Thanks for the helps.
>>>>>>>>
>>>>>>>> regards,
>>>>>>>> Boby
>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> Dr. Boby Mathew
>>>>>>>> INRES, University of Bonn
>>>>>>>> Katzenburgweg 5
>>>>>>>> Phone: 0228732031
>>>>>>>> 53115, Bonn,Germany.
>>>>>>>>
>>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>  --
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>  --
>>>>>> Dr. Boby Mathew
>>>>>> INRES, University of Bonn
>>>>>> Katzenburgweg 5
>>>>>> Phone: 0228732031
>>>>>> 53115, Bonn,Germany.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>> --
>>>> Dr. Boby Mathew
>>>> INRES, University of Bonn
>>>> Katzenburgweg 5
>>>> Phone: 0228732031
>>>> 53115, Bonn,Germany.
>>>>
>>>>
>>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>>
>>
>> --
>> Dr. Boby Mathew
>> INRES, University of Bonn
>> Katzenburgweg 5
>> Phone: 0228732031
>> 53115, Bonn,Germany.
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
Dr. Boby Mathew
INRES, University of Bonn
Katzenburgweg 5
Phone: 0228732031
53115, Bonn,Germany.

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Tue Oct 21 11:08:00 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 21 Oct 2014 09:08:00 +0000
Subject: [R-sig-ME] Modeling variance heterogeneity in lme4 + meaning of
 VarCorr values
In-Reply-To: <20141020151551.GB3947@info124.pharmacie.univ-paris5.fr>
References: <20141020124513.GA25800@info124.pharmacie.univ-paris5.fr>
	<AA818EAD2576BC488B4F623941DA7427F3B0795C@inbomail.inbo.be>
	<20141020151551.GB3947@info124.pharmacie.univ-paris5.fr>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B08148@inbomail.inbo.be>

Dear Emmanuel,

I think that the covariances between the random 'slopes' can be meaningful in your case. Suppose that the diameter changes over the length, the shapes are very similar, but the overall sizes different. In such a case the covariances would be high. Fixing the covariances at zero would be imply that the diameter at one position is independent of that of another position. Which is probably not what you want.

lme()  has several varClasses(). Something like varConstPower(form = ~abs(distanceToCenter)) might be relevant to your problem.

Lmer with the random 'slope' and lme with the varIdent tackle the shape of the object in different manners. Calling those models equivalent is too strong. I would suggest that you write down the mathematical equation of both models. It helps me to understand how a model works.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Emmanuel Curis [mailto:emmanuel.curis at parisdescartes.fr]
Verzonden: maandag 20 oktober 2014 17:16
Aan: ONKELINX, Thierry
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Modeling variance heterogeneity in lme4 + meaning of VarCorr values

Dear Thierry,

Thanks for the answer, and the hints.

I created the dummy variables first to avoid correlations between random effects (sorry I forgot to mention it) to limit the number of parameters and because I don't really see what they would mean practically, and second (and more importantly) to try after some more refinate models like < is the variance at both ends higher that variance all along other points > (as suggested by the shape of the artery and the possible explanation of higher variances at both ends), with only two different variances in the model. Obviously, it asks the question of the meaning of correlations or not between random effects, for which I have no clear idea, especially for such a model: any help for interpreting (the origin of) such correlations would be very appreciated.

For the lme variant: thanks for clarifying the syntax. I was wondering what tools would be available to compare the random effects/models in such a case, since I think LRT is not appropriate in these cases --- that is why I tried first with lme4 to use after that PBmodcomp (which, incidentaly, fails with a message about different size in data frames, but I'm not sure yet that I correctly understood its usage). But I will try your suggestion, to see if I obtain similar results.

Would the lme model with different variances in residuals be equivalent to the model in lme4 without correlations between random effects? Or does it induce a different variance-covariance structure for the response?

Best regards,

On Mon, Oct 20, 2014 at 02:49:34PM +0000, ONKELINX, Thierry wrote:
< Dear Emmanuel,
<
< You don't need to create the dummy variables. Just convert Position to a new factor variable. It makes your code much more readable.
<
< d$fPosition <- factor(d$Position)
< lmer( Diametre ~ Lecteur + Position + ( 0 + fPosition|Lecture ), data = d, REML = FALSE ) < < This allows for different variances of the random effect over Lecture, depending on the value of fPosition. This comes at the cost of estimating all covariances as well. So you need to estimate 36 parameters (8 variances and 28 covariances). That is a high number of parameters given the size of your dataset.
<
< A more efficient solution would be to use lme() from the nlme() package and allow for heterogeneity in the variance of the residuals.
<
< lme(Diametre ~ Lecteur + Position, random = ~1|Lecture, weights = varIdent(~ 1|fPosition), data = d, REML = FALSE) < < Best regards, < < Thierry

--
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From adam.hayward at ed.ac.uk  Tue Oct 21 15:21:03 2014
From: adam.hayward at ed.ac.uk (adam.hayward at ed.ac.uk)
Date: Tue, 21 Oct 2014 14:21:03 +0100
Subject: [R-sig-ME] Convergence warnings in lme4
Message-ID: <20141021142103.95023pyof3skxi2o@www.staffmail.ed.ac.uk>

Dear list users,

This is a general question, rather than a specific example of my data.  
I have recently upgraded my computer and to R ver 3.1.1 from 3.0.2.  
Models (glmer) which previously ran perfectly are now producing  
warning messages regarding failure to converge, for example:

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Model failed to converge with max|grad| = 0.0238312 (tol = 0.001,  
component 13)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

and this is true with a range of optimizers. Running identical models  
on my old and new versions of R produces identical output (estimates,  
AIC etc) but the new version of lme4 produces the warnings.

My questions are thus (1) has lme4 recently been updated with  
significant changes in what constitutes acceptable convergence, and  
(2) can my models now be trusted?

Many thanks for any comments or help,

Adam



-- 
Adam Hayward
Post-Doctoral Research Associate
adhayward.wordpress.com

Institute of Evolutionary Biology
Ashworth Laboratories
King's Buildings
University of Edinburgh
West Mains Road
Edinburgh
EH9 3JT





-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Tue Oct 21 15:39:49 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Oct 2014 09:39:49 -0400
Subject: [R-sig-ME] Convergence warnings in lme4
In-Reply-To: <20141021142103.95023pyof3skxi2o@www.staffmail.ed.ac.uk>
References: <20141021142103.95023pyof3skxi2o@www.staffmail.ed.ac.uk>
Message-ID: <54466225.8030002@gmail.com>

On 14-10-21 09:21 AM, adam.hayward at ed.ac.uk wrote:
> Dear list users,
> 
> This is a general question, rather than a specific example of my data. I
> have recently upgraded my computer and to R ver 3.1.1 from 3.0.2. Models
> (glmer) which previously ran perfectly are now producing warning
> messages regarding failure to converge, for example:
> 
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.0238312 (tol = 0.001,
> component 13)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
> 
> and this is true with a range of optimizers. Running identical models on
> my old and new versions of R produces identical output (estimates, AIC
> etc) but the new version of lme4 produces the warnings.
> 
> My questions are thus (1) has lme4 recently been updated with
> significant changes in what constitutes acceptable convergence, and (2)
> can my models now be trusted?
> 
> Many thanks for any comments or help,
> 
> Adam

  Presumably you're using version 1.1-7 (the latest version on CRAN); it
would be helpful to know that.  You can see changes to lme4 at
http://cran.r-project.org/web/packages/lme4/news.html . The significant
changes you're referring to started in version 1.1-3.

  We are still working to figure out how to get the right level of
sensitivity and specificity on these tests; we haven't come up with
anything definitive yet.  I've got an example of various attempts at
troubleshooting (restarting the fit from the same point, trying
different optimizers, etc.) posted at
http://rpubs.com/bbolker/lme4trouble1 .

The bottom line is that your models are no more nor less trustworthy
than they used to be.  If you have tried them with a variety of
optimizers, and if the results make sense, it's *probably* the case that
they're OK, and just a little unstable.

  Ben Bolker


From m.spronken at psych.ru.nl  Tue Oct 21 15:45:30 2014
From: m.spronken at psych.ru.nl (Spronken, M. (Maitta))
Date: Tue, 21 Oct 2014 15:45:30 +0200 (CEST)
Subject: [R-sig-ME] parallel option of the bootMer function: warnings for
 parallel=no, but not for parallel=snow
In-Reply-To: <1536672988.9471119.1413893564559.JavaMail.root@sculptor.zimbra.ru.nl>
Message-ID: <255026003.9473341.1413899130411.JavaMail.root@sculptor.zimbra.ru.nl>

Dear all,

I have a question about the parallel option of the bootMer function, I hope you can help me with this. I am using R 3.0.1.

I ran a mixed model with the lmer function of the package lme4_1.1-7 and tried to obtain confidence intervals with the bootMer function (in order to get the same results each time, I used set.seed(80)). 

In order to divide the bootstrapping calculations over several cores, I used the parallel option of the bootMer function: 'parallel=snow, ncpus=7'. However, I also bootstrapped the model using 'parallel=no', in order to see whether it led to the same results.

The bootstrapping results were the same for 'parallel=snow' and 'parallel=no'. However, when using 'parallel=no', I got the following warnings:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

When using 'parallel=snow', these warnings did not occur. Maybe also important, I do not get these warnings when running the original model.

This is a problem I have encountered with several models. Does someone know why using 'parallel=snow' does not lead to convergence warnings, while using 'parallel=no' does? Are these warnings problematic? Below you find the code I used.

Thanks in advance for your help!


Code:

model_1 <- lmer(DV_continuous ~ factor_threelevels + (1 + factor_threelevels|userId), data=combined_data, control = lmerControl(optCtrl = list(maxfun = 1000000)))

FUN_bootMer <- function(fit) {
  return(fixef(fit))
}

set.seed(80) 

boot_model_1a <- bootMer(model_1, FUN_bootMer, nsim = 1000, type = "parametric", parallel = "snow", ncpus =7)

set.seed(80)
 
boot_model_1b <- bootMer(model_1, FUN_bootMer, nsim = 1000, type = "parametric", parallel = "no")


From bbolker at gmail.com  Tue Oct 21 16:01:40 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Oct 2014 10:01:40 -0400
Subject: [R-sig-ME] parallel option of the bootMer function: warnings
 for parallel=no, but not for parallel=snow
In-Reply-To: <255026003.9473341.1413899130411.JavaMail.root@sculptor.zimbra.ru.nl>
References: <255026003.9473341.1413899130411.JavaMail.root@sculptor.zimbra.ru.nl>
Message-ID: <54466744.9040109@gmail.com>

On 14-10-21 09:45 AM, Spronken, M. (Maitta) wrote:
> Dear all,
> 
> I have a question about the parallel option of the bootMer function,
> I hope you can help me with this. I am using R 3.0.1.
> 
> I ran a mixed model with the lmer function of the package lme4_1.1-7
> and tried to obtain confidence intervals with the bootMer function
> (in order to get the same results each time, I used set.seed(80)).
> 
> In order to divide the bootstrapping calculations over several cores,
> I used the parallel option of the bootMer function: 'parallel=snow,
> ncpus=7'. However, I also bootstrapped the model using 'parallel=no',
> in order to see whether it led to the same results.
> 
> The bootstrapping results were the same for 'parallel=snow' and
> 'parallel=no'. However, when using 'parallel=no', I got the following
> warnings: 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  : Model failed to converge: degenerate  Hessian
> with 1 negative eigenvalues 2: In checkConv(attr(opt, "derivs"),
> opt$par, ctrl = control$checkConv,  : Model failed to converge:
> degenerate  Hessian with 1 negative eigenvalues
> 
> When using 'parallel=snow', these warnings did not occur. Maybe also
> important, I do not get these warnings when running the original
> model.
> 
> This is a problem I have encountered with several models. Does
> someone know why using 'parallel=snow' does not lead to convergence
> warnings, while using 'parallel=no' does? Are these warnings
> problematic? Below you find the code I used.
> 
> Thanks in advance for your help!
> 
> 
> Code:
> 
> model_1 <- lmer(DV_continuous ~ factor_threelevels + (1 +
> factor_threelevels|userId), data=combined_data, control =
> lmerControl(optCtrl = list(maxfun = 1000000)))
> 
> FUN_bootMer <- function(fit) { return(fixef(fit)) }
> 
> set.seed(80)
> 
> boot_model_1a <- bootMer(model_1, FUN_bootMer, nsim = 1000, type =
> "parametric", parallel = "snow", ncpus =7)
> 
> set.seed(80)
> 
> boot_model_1b <- bootMer(model_1, FUN_bootMer, nsim = 1000, type =
> "parametric", parallel = "no")
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

  Possibly related to https://github.com/lme4/lme4/issues/231

  Do you get warnings with parallel="multicore"?

  I have a suspicion that some of the internal structures of `lme4` may
not be getting reset properly when using refit() (which is used
internally by confint/bootMer), and that new copies are getting made
(and thus reset) with parallel="snow" but not with parallel="no" ... ?

  Ben Bolker


From ned.dochtermann at gmail.com  Tue Oct 21 21:44:19 2014
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Tue, 21 Oct 2014 14:44:19 -0500
Subject: [R-sig-ME] Binomial model variance and repeatability estimates with
	MCMCglmm
Message-ID: <5446B793.9050009@gmail.com>

List,
A colleague recently asked me some questions about issues with 
estimating repeatabilities for binomial/binary data. In trying to help 
out I started playing around with simulating some data and have been 
struggling to get decent effective sample sizes even when parameters are 
being well estimated. I suspect the problem is partly the priors 
(inverse-gamma) but have had issues with other priors too (priors as 
specified in MCMCglmm are still quite unclear to me in general, however).

While quite often repeatability gets estimated very well despite 
effective sample sizes of only a few dozen I also am getting poorly 
estimated repeatabilities (~0) with a population level repeatability of 
<.4 and sample sizes less than n=100 and reps=2, suggesting the 
inverse-gama being informative around zero. Is the poor mixing 
potentially due to using multinomial2 rather than categorical? I don't 
want to go the categorical route because repeatabilities are of 
particular interest.

I'm much less comfortable with generalized rather than standard linear 
models so I wonder if there are any glaring issues with the coding. Any 
thoughts on what might be going on?

Thanks for any help.
Ned



#make function to calculate inverse logit:
inv.log<- function(x){
   exp(x)/(1+exp(x))}

#specify some start conditions and bookkeeping stuff

#specify data distributions:
repeatability=0.3 #Change this for other repeatabilities (sampled 
population's repeatability, not sample's realized latent repeatability)
sigma2.e=6 #arbitrary, set repeatability above
sigma2.a=(repeatability*sigma2.e+repeatability*((pi^2)/3))/(1-repeatability)
B0=0 #could do different fixed effects with some more work...

#(n=number of individuals, i=number of replications per individual)
counter=0; n=150; i=4
ind.data=matrix(0,n*i,3) #make place to store data
tru.lat=matrix(0,n*i,2) #store sampled underlying scores

for(j in 1:n){
   alpha.j=rnorm(1,0,sigma2.a)
   for(rep in 1:i){
     counter=counter+1
     ind.data[counter,1]=j
     eij=rnorm(1,0,sigma2.e)
     pij=inv.log((B0+alpha.j+eij))
     ind.data[counter,3]=rbinom(1,1,pij)
     ind.data[counter,2]=1-ind.data[counter,3]
     tru.lat[counter,1]=alpha.j
     tru.lat[counter,2]=eij
   }}

ind.data=as.data.frame(ind.data)
names(ind.data)=c("Ind", "Fail", "Success")

prior1 = list(R = list(V = 1, nu=0.002),
               G = list(G1 = list(V = 1, nu = 0.002)))
sim.mcmc<-MCMCglmm(cbind(Fail,Success)~1, random= ~Ind,
                    family="multinomial2", prior=prior1,
                    nitt = 260000, thin = 200, burnin = 60000,
                    verbose=FALSE,data=ind.data)

#estimated repeatabilities
posterior.mode(sim.mcmc$VCV[,1]/(sim.mcmc$VCV[,1]+sim.mcmc$VCV[,2]+((pi^2)/3)))
HPDinterval(sim.mcmc$VCV[,1]/(sim.mcmc$VCV[,1]+sim.mcmc$VCV[,2]+((pi^2)/3)))
#effective sample sizes, tells you if model is mixing well
summary(sim.mcmc)[6]$Gcovariances[4]
summary(sim.mcmc)[8]$Rcovariances[4]

#sample repeatability, not sure this is quite right
tru.a2=var(tru.lat[1:(n/i)*i,1])
tru.e2=var(tru.lat[,2])
tru.a2/(tru.a2+tru.e2+((pi^2)/3))


-- 
Ned A. Dochtermann
Assistant Professor / Department of Biological Sciences
NORTH DAKOTA STATE UNIVERSITY
p: 701.231.7353 / f: 701.231.7149 / www.ndsu.edu

https://sites.google.com/site/neddochtermann/
ned.dochtermann at ndsu.edu


From j.hadfield at ed.ac.uk  Tue Oct 21 22:05:10 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 21 Oct 2014 21:05:10 +0100
Subject: [R-sig-ME] Binomial model variance and repeatability estimates
 with MCMCglmm
In-Reply-To: <5446B793.9050009@gmail.com>
References: <5446B793.9050009@gmail.com>
Message-ID: <20141021210510.62842gkiqjce9dwk@www.staffmail.ed.ac.uk>

Hi,

The residual variance of a binary response cannot be estimated, so use

prior1 = list(R = list(V = 1, fix=1),
               G = list(G1 = list(V = 1, nu = 0.002)))

In this example it is more efficient to aggregate success/failures of  
an individual into a multi-trial binomial response and use:

  prior2 = list(R = list(V = 1, nu=0.002))

sim.mcmc2<-MCMCglmm(cbind(Fail,Success)~1,
                     family="multinomial2", prior=prior2,
                     nitt = 260000, thin = 200, burnin = 60000,
                     verbose=FALSE,data=ind.data)

sim.mcmc2$VCV/(sim.mcmc2$VCV+pi^2/3)

Cheers,

Jarrod


Quoting Ned Dochtermann <ned.dochtermann at gmail.com> on Tue, 21 Oct  
2014 14:44:19 -0500:

> List,
> A colleague recently asked me some questions about issues with  
> estimating repeatabilities for binomial/binary data. In trying to  
> help out I started playing around with simulating some data and have  
> been struggling to get decent effective sample sizes even when  
> parameters are being well estimated. I suspect the problem is partly  
> the priors (inverse-gamma) but have had issues with other priors too  
> (priors as specified in MCMCglmm are still quite unclear to me in  
> general, however).
>
> While quite often repeatability gets estimated very well despite  
> effective sample sizes of only a few dozen I also am getting poorly  
> estimated repeatabilities (~0) with a population level repeatability  
> of <.4 and sample sizes less than n=100 and reps=2, suggesting the  
> inverse-gama being informative around zero. Is the poor mixing  
> potentially due to using multinomial2 rather than categorical? I  
> don't want to go the categorical route because repeatabilities are  
> of particular interest.
>
> I'm much less comfortable with generalized rather than standard  
> linear models so I wonder if there are any glaring issues with the  
> coding. Any thoughts on what might be going on?
>
> Thanks for any help.
> Ned
>
>
>
> #make function to calculate inverse logit:
> inv.log<- function(x){
>   exp(x)/(1+exp(x))}
>
> #specify some start conditions and bookkeeping stuff
>
> #specify data distributions:
> repeatability=0.3 #Change this for other repeatabilities (sampled  
> population's repeatability, not sample's realized latent  
> repeatability)
> sigma2.e=6 #arbitrary, set repeatability above
> sigma2.a=(repeatability*sigma2.e+repeatability*((pi^2)/3))/(1-repeatability)
> B0=0 #could do different fixed effects with some more work...
>
> #(n=number of individuals, i=number of replications per individual)
> counter=0; n=150; i=4
> ind.data=matrix(0,n*i,3) #make place to store data
> tru.lat=matrix(0,n*i,2) #store sampled underlying scores
>
> for(j in 1:n){
>   alpha.j=rnorm(1,0,sigma2.a)
>   for(rep in 1:i){
>     counter=counter+1
>     ind.data[counter,1]=j
>     eij=rnorm(1,0,sigma2.e)
>     pij=inv.log((B0+alpha.j+eij))
>     ind.data[counter,3]=rbinom(1,1,pij)
>     ind.data[counter,2]=1-ind.data[counter,3]
>     tru.lat[counter,1]=alpha.j
>     tru.lat[counter,2]=eij
>   }}
>
> ind.data=as.data.frame(ind.data)
> names(ind.data)=c("Ind", "Fail", "Success")
>
> prior1 = list(R = list(V = 1, nu=0.002),
>               G = list(G1 = list(V = 1, nu = 0.002)))
> sim.mcmc<-MCMCglmm(cbind(Fail,Success)~1, random= ~Ind,
>                    family="multinomial2", prior=prior1,
>                    nitt = 260000, thin = 200, burnin = 60000,
>                    verbose=FALSE,data=ind.data)
>
> #estimated repeatabilities
> posterior.mode(sim.mcmc$VCV[,1]/(sim.mcmc$VCV[,1]+sim.mcmc$VCV[,2]+((pi^2)/3)))
> HPDinterval(sim.mcmc$VCV[,1]/(sim.mcmc$VCV[,1]+sim.mcmc$VCV[,2]+((pi^2)/3)))
> #effective sample sizes, tells you if model is mixing well
> summary(sim.mcmc)[6]$Gcovariances[4]
> summary(sim.mcmc)[8]$Rcovariances[4]
>
> #sample repeatability, not sure this is quite right
> tru.a2=var(tru.lat[1:(n/i)*i,1])
> tru.e2=var(tru.lat[,2])
> tru.a2/(tru.a2+tru.e2+((pi^2)/3))
>
>
> -- 
> Ned A. Dochtermann
> Assistant Professor / Department of Biological Sciences
> NORTH DAKOTA STATE UNIVERSITY
> p: 701.231.7353 / f: 701.231.7149 / www.ndsu.edu
>
> https://sites.google.com/site/neddochtermann/
> ned.dochtermann at ndsu.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ned.dochtermann at gmail.com  Wed Oct 22 00:00:12 2014
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Tue, 21 Oct 2014 17:00:12 -0500
Subject: [R-sig-ME] Binomial model variance and repeatability estimates
 with MCMCglmm
In-Reply-To: <20141021210510.62842gkiqjce9dwk@www.staffmail.ed.ac.uk>
References: <5446B793.9050009@gmail.com>
	<20141021210510.62842gkiqjce9dwk@www.staffmail.ed.ac.uk>
Message-ID: <5446D76C.3040806@gmail.com>

Thanks, I was aware of that for categorical and some of the other 
families but thought I could get away with it here and I wasn't quite 
sure otherwise how to calculate the relevant ratio (thanks for providing 
that too).
With smaller sample sizes repeatability still seems to get misestimated 
and stuck close to zero even with long runs but running multiple chains 
seem to resolve that.

Thanks again,
Ned

On 10/21/2014 3:05 PM, Jarrod Hadfield wrote:
> Hi,
>
> The residual variance of a binary response cannot be estimated, so use
>
> prior1 = list(R = list(V = 1, fix=1),
>               G = list(G1 = list(V = 1, nu = 0.002)))
>
> In this example it is more efficient to aggregate success/failures of 
> an individual into a multi-trial binomial response and use:
>
>  prior2 = list(R = list(V = 1, nu=0.002))
>
> sim.mcmc2<-MCMCglmm(cbind(Fail,Success)~1,
>                     family="multinomial2", prior=prior2,
>                     nitt = 260000, thin = 200, burnin = 60000,
>                     verbose=FALSE,data=ind.data)
>
> sim.mcmc2$VCV/(sim.mcmc2$VCV+pi^2/3)
>
> Cheers,
>
> Jarrod


From maren.rebke at avitec-research.de  Wed Oct 22 00:23:07 2014
From: maren.rebke at avitec-research.de (- -)
Date: Wed, 22 Oct 2014 00:23:07 +0200 (CEST)
Subject: [R-sig-ME] MCMC fitting in glmmADMB
In-Reply-To: <5444CEB9.40506@avitec-research.de>
References: <543FA999.80009@avitec-research.de>
	<CABghstTrBpRvYNf=dmvcwbSTmp1NeLZxJgfs59boeQZnT3DcnQ@mail.gmail.com>
	<5444CEB9.40506@avitec-research.de>
Message-ID: <546892464.36018.1413930187362.open-xchange@patina.store>

I received some feedback that made me aware that I didn?t explain my problem
correctly in my original request due to translation issues. Sorry for that. It
is the RAM and not the hard drive space that is reaching its capacity. After
running the MCMC chain for 24 hours (approximately 2000 iterations for the model
of my own data) the allocated memory is already about 6 GB.

Therefore I am wondering if there is a way to reduce the used memory during the
calculation of the model, as I don?t need all the information in the output at
the end. Or can I divide the MCMC chain in smaller parts and define the end
values from the part before as starting values for each subsequent part?

Best wishes,
Maren



> maren <maren.rebke at avitec-research.de> hat am 20. Oktober 2014 um 10:58
> geschrieben:
>
>
> Thank you very much for your suggestion, Ben. Saving only a thinned
> sequence will of course reduce the size of the stored data file. I was
> using that option already in the analysis of my own data, but maybe I
> just have to choose larger intervals.
>
> From your reply I assume that it is not easily possible to store only
> the samples of the estimates for certain parameters (i.e. don?t save
> u.01-u.27 in the owl example), define a burn-in period or play around
> with the jump size. Or were my questions not clear enough?
>
> Best wishes,
>
> Maren
>
>
> Am 18.10.2014 17:23, schrieb Ben Bolker:
> > You can use mcmcControl(mcsave=...), as illustrated below.
> >
> > library("glmmADMB")
> >
> > om <- glmmadmb(SiblingNegotiation~FoodTreatment*SexParent+
> > (1|Nest)+offset(log(BroodSize)),
> > zeroInflation=TRUE,family="nbinom",data=Owls,
> > mcmc=TRUE,
> > mcmc.opts=mcmcControl(mcmc=200))
> > nrow(om$mcmc) ## 20
> >
> > om2 <- glmmadmb(SiblingNegotiation~FoodTreatment*SexParent+
> > (1|Nest)+offset(log(BroodSize)),
> > zeroInflation=TRUE,family="nbinom",data=Owls,
> > mcmc=TRUE,
> > mcmc.opts=mcmcControl(mcmc=200,mcsave=20))
> > nrow(om2$mcmc) ## 10
> >
> >
> > On Thu, Oct 16, 2014 at 7:18 AM, maren <maren.rebke at avitec-research.de
> > <mailto:maren.rebke at avitec-research.de>> wrote:
> >
> > Hi,
> >
> > I fit a zero-inflated Poisson model with random effects using the
> > package glmmADMB, which worked perfectly well. Now I am trying to get
> > credible intervals by running a Markov chain using mcmc=TRUE,
> > which also
> > works fine in general.
> >
> > The problem is, that I have many parameters as well as several random
> > effects in my model and it seems that I need to run long chains to get
> > proper estimates. Therefore the automatically stored file eventually
> > gets very big and my computer cannot handle it anymore. Therefore I
> > would like to store only the samples of the estimates for the fixed
> > effects (only beta) and not the rest. Is that possible somehow?
> >
> > I am not sure, but would it help to specify parameters via mcmcpars? I
> > tried to include mcmcpars in the owl example in section 2.2 from the
> > vignette of the package
> > (http://glmmadmb.r-forge.r-project.org/glmmADMB.pdf):
> >
> > fit_zinbinom1_bs_mcmc <-
> > glmmadmb(NCalls~(FoodTreatment+ArrivalTime)*SexParent+BroodSize+(1|Nest),data=Owls,zeroInflation=TRUE,family="nbinom1",mcmc=TRUE,mcmc.opts=mcmcControl(mcmc=10,mcmcpars="beta"))
> >
> > But unfortunately, I get an error message stating "unused argument
> > (mcmcpars="beta")". As I wasn't sure if I have to state the fixed
> > effects by using "beta" or the names of the parameters directly, I
> > also
> > tried including mcmcpars="BroodSize" but got the same error.
> >
> > Is it not possible to define mcmcpars in glmmADMB? Is the
> > definition of
> > mcmcpars at all what I need and if so, how do I do it correctly?
> >
> > Otherwise, is it possible to state that only the samples after a
> > certain
> > burnin period should be saved? Or can I play around with the jump
> > sizes
> > to reach faster convergence? As far as I understood those are rescaled
> > depending on the acceptance rate at the moment. The automatic
> > rescaling
> > can be switched off by stating mcnoscale=TRUE, which is working. But I
> > am not sure how I can then adjust the jump size and what the
> > default is.
> >
> > Thank you very much for taking the time to read this long email.
> >
> > Best wishes,
> >
> > Maren Rebke
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> > <mailto:R-sig-mixed-models at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Oct 22 08:15:38 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 22 Oct 2014 07:15:38 +0100
Subject: [R-sig-ME] Binomial model variance and repeatability estimates
 with MCMCglmm
In-Reply-To: <5446D76C.3040806@gmail.com>
References: <5446B793.9050009@gmail.com>
	<20141021210510.62842gkiqjce9dwk@www.staffmail.ed.ac.uk>
	<5446D76C.3040806@gmail.com>
Message-ID: <20141022071538.648529twxv06es2s@www.staffmail.ed.ac.uk>

Hi,

The simulation only had one trial so it was equivalent to categorical.  
If you up the number of trials then you can estimate the  
observation-level variance.

You might try parameter expanded priors to remedy the last problem.

Cheers,

Jarrod


Quoting Ned Dochtermann <ned.dochtermann at gmail.com> on Tue, 21 Oct  
2014 17:00:12 -0500:

> Thanks, I was aware of that for categorical and some of the other  
> families but thought I could get away with it here and I wasn't  
> quite sure otherwise how to calculate the relevant ratio (thanks for  
> providing that too).
> With smaller sample sizes repeatability still seems to get  
> misestimated and stuck close to zero even with long runs but running  
> multiple chains seem to resolve that.
>
> Thanks again,
> Ned
>
> On 10/21/2014 3:05 PM, Jarrod Hadfield wrote:
>> Hi,
>>
>> The residual variance of a binary response cannot be estimated, so use
>>
>> prior1 = list(R = list(V = 1, fix=1),
>>              G = list(G1 = list(V = 1, nu = 0.002)))
>>
>> In this example it is more efficient to aggregate success/failures  
>> of an individual into a multi-trial binomial response and use:
>>
>> prior2 = list(R = list(V = 1, nu=0.002))
>>
>> sim.mcmc2<-MCMCglmm(cbind(Fail,Success)~1,
>>                    family="multinomial2", prior=prior2,
>>                    nitt = 260000, thin = 200, burnin = 60000,
>>                    verbose=FALSE,data=ind.data)
>>
>> sim.mcmc2$VCV/(sim.mcmc2$VCV+pi^2/3)
>>
>> Cheers,
>>
>> Jarrod
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From m.spronken at psych.ru.nl  Wed Oct 22 13:57:58 2014
From: m.spronken at psych.ru.nl (Spronken, M. (Maitta))
Date: Wed, 22 Oct 2014 13:57:58 +0200 (CEST)
Subject: [R-sig-ME] parallel option of the bootMer function: warnings
 for parallel=no, but not for parallel=snow
In-Reply-To: <1307174910.9483419.1413977187381.JavaMail.root@sculptor.zimbra.ru.nl>
Message-ID: <1246688648.9483964.1413979078043.JavaMail.root@sculptor.zimbra.ru.nl>

Thanks for the quick response Ben!

When using parallel="multicore" I get the same warnings as when using parallel="no". However, as I am using Windows, I am not sure whether I can use multicore? (According to my task manager, all cores are used when using parallel="snow" but not when using parallel="multicore").

To check this, I also ran my code on a Mac. When running the code on a Mac, parallel="no" gives warnings as well, but parallel="multicore" and parallel="snow" do not.

For my model, warnings also seem to depend on the value chosen for set.seed(). When using set.seed(80) on Windows, parallel="no" gives warnings while parallel="snow" does not. When using set.seed(100) on Windows, neither parallel="no" nor parallel="snow" give warnings. When using a Mac, for both set.seed(80) and set.seed(100), parallel="no" gives warnings while parallel="multicore" and parallel="snow" do not.

Do you have an idea what this indicates? 

Thanks again!

Maitta


From lucianolasala at yahoo.com.ar  Wed Oct 22 23:19:50 2014
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 22 Oct 2014 18:19:50 -0300
Subject: [R-sig-ME] Error message
In-Reply-To: <40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>
	<40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>
Message-ID: <54481F76.8040802@yahoo.com.ar>

Hello,

A few years back I used to fit GLMM (binomial response) using lmer function in lme4. Back then I had to specify the family of response variable  (dead /alive)
as binomial. Now I have to refit those models using quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but things seem to have changed quite a bit.
  
My response variable is death (yes/no), and independent variables are Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching Order (ordered factor variable, namely
first, second, third). I need to control autocorrelation among siblings, so I use "Nest ID" to fit random intercepts for different nests.

My model is:

model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1|Nest_ID), family = binomial, data = Data)
summary(model.1)

But I get the error and warning messages below:

Error in eval(expr, envir, enclos) :
   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
In addition:Warning message:
In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID),  :
   calling lmer with 'family' is deprecated; please use glmer() instead

  
Question: how can I circumvent these two issues?

Thanks in advance.

Luciano


	[[alternative HTML version deleted]]


From Daniel.Wright at act.org  Wed Oct 22 23:35:26 2014
From: Daniel.Wright at act.org (Daniel Wright)
Date: Wed, 22 Oct 2014 21:35:26 +0000
Subject: [R-sig-ME] Error message
In-Reply-To: <54481F76.8040802@yahoo.com.ar>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>
	<40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>
	<54481F76.8040802@yahoo.com.ar>
Message-ID: <3027a659772447a49bf110b3f0e59f36@CO2PR04MB826.namprd04.prod.outlook.com>

The lme4 package has changed some. Details are in http://arxiv.org/pdf/1406.5823.pdf

For your problem, the first thing to note is glmer is now used instead of lmer for generalized linear models.  Glancing at your model the other bits look like they should work.

Dan

Daniel B. Wright, Ph.D.
Statistical Research Division 
8701 N. MoPac Expressway, Suite 200, Austin, TX 78759??
(preferred method of communication is email, use cell if urgent)
Office: 512.320.1827
Cell: 786 342 4656 






This email message is intended only for the personal use of the recipient(s) named above. If you are not an intended recipient, you may not review, copy, or distribute this message. If you have received this communication in error, please notify the sender immediately by email and delete the original?message.



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
Sent: Wednesday, October 22, 2014 4:20 PM
Cc: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Error message

Hello,

A few years back I used to fit GLMM (binomial response) using lmer function in lme4. Back then I had to specify the family of response variable  (dead /alive) as binomial. Now I have to refit those models using quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but things seem to have changed quite a bit.
  
My response variable is death (yes/no), and independent variables are Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching Order (ordered factor variable, namely first, second, third). I need to control autocorrelation among siblings, so I use "Nest ID" to fit random intercepts for different nests.

My model is:

model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1|Nest_ID), family = binomial, data = Data)
summary(model.1)

But I get the error and warning messages below:

Error in eval(expr, envir, enclos) :
   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate In addition:Warning message:
In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID),  :
   calling lmer with 'family' is deprecated; please use glmer() instead

  
Question: how can I circumvent these two issues?

Thanks in advance.

Luciano


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Oct 22 23:36:34 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Oct 2014 17:36:34 -0400
Subject: [R-sig-ME] Error message
In-Reply-To: <54481F76.8040802@yahoo.com.ar>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>	<40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>
	<54481F76.8040802@yahoo.com.ar>
Message-ID: <54482362.7090104@gmail.com>

On 14-10-22 05:19 PM, Luciano La Sala wrote:
> Hello,
> 
> A few years back I used to fit GLMM (binomial response) using lmer
> function in lme4. Back then I had to specify the family of response
> variable  (dead /alive) as binomial. Now I have to refit those models
> using quite newer versions of both R (R x64 3.1.1) and lme4
> (lme4_1.1-7), but things seem to have changed quite a bit.
> 
> My response variable is death (yes/no), and independent variables are
> Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and
> Hatching Order (ordered factor variable, namely first, second,
> third). I need to control autocorrelation among siblings, so I use
> "Nest ID" to fit random intercepts for different nests.
> 
> My model is:
> 
> model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
> (1|Nest_ID), family = binomial, data = Data) summary(model.1)
> 
> But I get the error and warning messages below:
> 
> Error in eval(expr, envir, enclos) : (maxstephalfit) PIRLS
> step-halvings failed to reduce deviance in pwrssUpdate In
> addition:Warning message: In lmer(Death_2 ~ Year + Sex + Egg_Volume +
> Hatch_Order + (1 | Nest_ID),  : calling lmer with 'family' is
> deprecated; please use glmer() instead
> 
> 
> Question: how can I circumvent these two issues?
>

  You can circumvent the second very easily (by using glmer() instead of
lmer()).  For the second, I'm a little surprised, as we don't see that
error message very often unless the data are quite badly behaved (or
using a non-standard link like cloglog).  Does it work in lme4.0?  Any
chance you can send data?


From mauritsvzb at gmail.com  Thu Oct 23 12:41:39 2014
From: mauritsvzb at gmail.com (Maurits Van Zinnicq Bergmann)
Date: Thu, 23 Oct 2014 12:41:39 +0200
Subject: [R-sig-ME] Binomial model R^2 and ICC calculation with lme4
Message-ID: <CD37152F-57B1-4A6A-B71E-8A5AD44DC2F7@gmail.com>

Dear list,

I?m trying to calculate the marginal and conditional R^2 for a binomial GLMM using the lme4 package. Some googling a while ago brought me to the site of Jonathan Lefcheck (http://jonlefcheck.net/2013/03/13/r2-for-linear-mixed-effects-models/) which offers exactly this. However, more recently I became aware of a recent paper by Dr. Paul Johnson (http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12225/abstract) that explains the calculation of R^2 for random slope models and points to the r.squaredGLMM function in the MuMIn package.

Unfortunately I experience some inconsistencies and problems when comparing R^2 values of three different GLMMs 1) random intercept mixed model, 2) mixed model with random covariance between intercept and slope, and 3) a mixed model without random covariance between intercept and slope, using the 2 methods:.

1) a comparison of marginal and conditional R^2 estimates between Lefcheck?s method and the MuMIn package showed consistent marginal R^2 estimates for the first and the second GLMM, whereas the marginal R^2 values were lower using Lefcheck?s method. The third mixed model showed both different conditional and marginal R^2. Could anyone explain why I obtain different R^2 estimates when comparing the 2 methods,

2) When I calculate R^2 values using the code from the supporting information with Dr. Johnsons paper (slightly modified to reflect a binomial GLMM instead of poison LMM) I obtain different values when compared to the values obtained from the MuMIn package. If I calculated the variance components correctly, they should return identical R^2 values. While I don?t have to bother with the mistake(s) I made in the code to obtain R^2 values (I can just use the package instead), I would like to know how to correctly calculate the variance components needed to calculate the ICC over the whole sample of all three models.

Thank you for any help.
Maurits van Zinnicq





# random intercept model
m1 <- glmer(cbind(df$Valid.detections, df$Missed.detections) ~ distance + 
              Habitat + Replicate + transmitter.depth + receiver.depth + 
              wind.speed + wtc + Transmitter + (1 | Unit) + 
              (1 | SUR.ID) + distance:Transmitter + 
              distance:Habitat + distance:transmitter.depth + distance:receiver.depth + 
              distance:wind.speed, data = df, family = binomial(link=logit),control=glmerControl(calc.derivs=F))

# random slope model
m2 <- glmer(cbind(df$Valid.detections, df$Missed.detections) ~ distance + 
                 Habitat + Replicate + transmitter.depth + receiver.depth + 
                 wind.speed + wtc + Transmitter + (1 | Unit) + 
                 (distance | SUR.ID) + distance:Transmitter + 
                 distance:Habitat + distance:transmitter.depth + distance:receiver.depth + 
                 distance:wind.speed, data = df, family = binomial(link=logit),control=glmerControl(calc.derivs=F))

# random slope model without random covariance between slope/intercept
m3 <- glmer(cbind(df$Valid.detections, df$Missed.detections) ~ distance + 
              Habitat + Replicate + transmitter.depth + receiver.depth + 
              wind.speed + wtc + Transmitter + (1 | Unit) + 
              (1 | SUR.ID) + (0 + distance | SUR.ID) + distance:Transmitter + 
              distance:Habitat + distance:transmitter.depth + distance:receiver.depth + 
              distance:wind.speed, data = df, family = binomial(link=logit),control=glmerControl(calc.derivs=F))





# adjusted code from Paul Johnson to reflect binomial GLMM

# Extract the variance components require for the R-squared statistics,
# starting with the better-fitting random slopes model.

# First we need the design matrix (X), the number of observations (n)
# and the fixed effect estimates (Beta)

X <- model.matrix(m1)
n <- nrow(X)
Beta <- fixef(m1)

# First the fixed effects variance (eqn 27 of Nakagawa & Schielzeth): 

Sf <- var(X %*% Beta)

# Second, the list of covariance matrices of the random effects.
# Here the list has only a single element because there is only
# one level of random effects.

(Sigma.list <- VarCorr(m1))

# Use equation 11 in the paper to estimate the random effects variance 
# component.
# Using sapply ensures that the same code will work when there are multiple
# random effects (i.e. where length(Sigma.list) > 1)

Sl <- 
  sum(
    sapply(Sigma.list,
           function(Sigma)
           {
             Z <-X[,rownames(Sigma)]
             sum(diag(Z %*% Sigma %*% t(Z)))/n
           }))


# As this model is an binomial GLMM, the additive dispersion variance, Se, is
# usually fixed to 1 for computational reasons, as additive disperson is not identifiable (Nakagawa & Schielzeth 2013)

Se <- 1

# Finally, the distribution-specific variance, Sd, is pi^2/3 for binomial GLMMs:

Sd <- pi^2/3

# Use eqns 29 and 30 from Nakagawa & Schielzeth to estimate marginal and
# conditional R-squared:

total.var <- Sf + Sl + Se + Sd
(Rsq.m <- Sf / total.var) 
(Rsq.c <- (Sf + Sl) / total.var) 
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Oct 24 01:10:44 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Oct 2014 19:10:44 -0400
Subject: [R-sig-ME] lme4
In-Reply-To: <CAAJcTECxARF+WhTDK_BzT9vUkBQQ9W2rohOSFSAJTTpLN9w-uA@mail.gmail.com>
References: <CAAJcTECxARF+WhTDK_BzT9vUkBQQ9W2rohOSFSAJTTpLN9w-uA@mail.gmail.com>
Message-ID: <54498AF4.6030108@gmail.com>

On 14-10-23 02:07 PM, Alejandra Tapia wrote:
> 
> Dear Prof. Ben,
> 
> I'm writing you because I have the following question.
> 
> For R package lme4 version 0.999999-2 the glmer function uses by default
> |bobyqa| for first phase and Nelder-Mead for second phase?
> 
> Sincerely,
> -- 
> Alejandra

  I believe that old versions of lme4 (pre 1.0) used the nlminb
optimizer for all optimizations (there was no choice of optimizer).

  I would suggest being extremely careful with versions of lme4 prior to
1.0 used on R 3.1.0 or greater -- people have reported problems, which
we haven't had the opportunity to track down.

  Ben Bolker


From drmasoodmohd at gmail.com  Sat Oct 25 12:02:25 2014
From: drmasoodmohd at gmail.com (Mohd Masood)
Date: Sat, 25 Oct 2014 18:02:25 +0800
Subject: [R-sig-ME] Estimation Methods in lme4
Message-ID: <CALho=DaqRS=697rG188S0_rLzMtL5W51qW8Av+RvYVdrm8ceVA@mail.gmail.com>

Dear All
I am looking for the methods used in the estimation in lme4 or for
lmer and glmer commands. Please also share some literature related to
this.
What fixed- and random-parameter estimation method does the lme4
package use for two-level linear and logistic regression models?

Thanks
Masood


From bbolker at gmail.com  Sun Oct 26 02:13:08 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 26 Oct 2014 00:13:08 +0000 (UTC)
Subject: [R-sig-ME] Estimation Methods in lme4
References: <CALho=DaqRS=697rG188S0_rLzMtL5W51qW8Av+RvYVdrm8ceVA@mail.gmail.com>
Message-ID: <loom.20141026T001341-167@post.gmane.org>

Mohd Masood <drmasoodmohd at ...> writes:

> 
> Dear All
> I am looking for the methods used in the estimation in lme4 or for
> lmer and glmer commands. Please also share some literature related to
> this.
> What fixed- and random-parameter estimation method does the lme4
> package use for two-level linear and logistic regression models?
> 
> Thanks
> Masood
> 

  For lmer, you can look at http://arxiv.org/abs/1406.5823 .

  For GLMMs, we have a paper in progress but it's still in the
draft stage.

  You can look at Chapter 6 of 
http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf , but it doesn't 
actually have too much on the estimation methods.

Slides from various of Doug Bates's presentations, e.g.

http://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/5GLMM.pdf


>


From TJouve at chu-grenoble.fr  Mon Oct 27 12:31:04 2014
From: TJouve at chu-grenoble.fr (Jouve, Thomas)
Date: Mon, 27 Oct 2014 11:31:04 +0000
Subject: [R-sig-ME] Estimating indirect contributions in a mixed-treatment
 comparison (a.k.a. network meta-analysis)
Message-ID: <45AEBBAEB335A744899279A2053EF4F0820EAA1F@proback17.exploitation.chug.alp>

Dear readers,
Several packages, including metafor, use the mixed model framework to adjust for mixed-treatment meta-analysis, also known as network meta-analysis.
These analyses combine direct (traditional) effects seen in direct treatment comparisons with indirect effects obtained by simultaneously considering studies with a common treatment arm.
These packages have several options to display their results and output a large number of matrices, such as treatment effects, variance of these effects...
However, I fail to extract the respective direct and indirect treatment contributions. The most recent GRADE recommendations indeed require both estimates.
Koenig et al. (Stat Med, 2013, Visualizing the flow of evidence...) released a paper with a derivation of direct and indirect effects for the case of fixed-effect models. Does anyone have a clue to help me derive indirect treatment effects in a random-effect model ? Possibly using metafor output of the rma.mv function ?
Thanks in advance for your help and comments.
Thomas JOUVE

--
Thomas JOUVE
Interne de n?phrologie - Centre d'Investigation Clinique
CHU Grenoble

	[[alternative HTML version deleted]]


From m.spronken at psych.ru.nl  Mon Oct 27 14:20:18 2014
From: m.spronken at psych.ru.nl (Spronken, M. (Maitta))
Date: Mon, 27 Oct 2014 14:20:18 +0100 (CET)
Subject: [R-sig-ME] parallel option of the bootMer function: warnings
 for parallel=no, but not for parallel=snow
In-Reply-To: <1972114678.9523203.1414410396646.JavaMail.root@sculptor.zimbra.ru.nl>
Message-ID: <1196415407.9525600.1414416018389.JavaMail.root@sculptor.zimbra.ru.nl>

Dear all,

Last week I asked two questions about the parallel option of the bootMer function. As I explained in my first post, when bootstrapping my model, I got warnings when using parallel="no", but not when using parallel="snow". Ben Bolker suggested that some of the internal structures of lme4 might be getting reset properly when using refit() with parallel="snow", but not with parallel="no".

As I explained in my second post, whether I get warnings when using parallel="no" also seems to depend on the set.seed() value chosen and whether I run my code on a Mac/Windows pc. I asked whether someone knows what this indicates, but maybe I should ask my question more specifically: 

Do you have an idea whether different set.seed() values and using Mac vs. Windows leads to differences in the occurrence of warnings because parallel="no" might not reset some internal structures properly, or could these differences also indicate that there is something 'wrong' with my data/model?

Thanks in advance for any suggestions!

Best,
Maitta


From henrik.singmann at psychologie.uni-freiburg.de  Mon Oct 27 15:23:48 2014
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Mon, 27 Oct 2014 15:23:48 +0100
Subject: [R-sig-ME] parallel option of the bootMer function: warnings
 for parallel=no, but not for parallel=snow
In-Reply-To: <1196415407.9525600.1414416018389.JavaMail.root@sculptor.zimbra.ru.nl>
References: <1972114678.9523203.1414410396646.JavaMail.root@sculptor.zimbra.ru.nl>
	<1196415407.9525600.1414416018389.JavaMail.root@sculptor.zimbra.ru.nl>
Message-ID: <544E5574.8020309@psychologie.uni-freiburg.de>

Hi Maitta,

Can you send a minimal reproducible example (http://stackoverflow.com/q/5963269/289572) showing this?

This would at least help me to see if I can reproduce this behavior.

Cheers,
Henrik

Am 27.10.2014 um 14:20 schrieb Spronken, M. (Maitta):
> Dear all,
>
> Last week I asked two questions about the parallel option of the bootMer function. As I explained in my first post, when bootstrapping my model, I got warnings when using parallel="no", but not when using parallel="snow". Ben Bolker suggested that some of the internal structures of lme4 might be getting reset properly when using refit() with parallel="snow", but not with parallel="no".
>
> As I explained in my second post, whether I get warnings when using parallel="no" also seems to depend on the set.seed() value chosen and whether I run my code on a Mac/Windows pc. I asked whether someone knows what this indicates, but maybe I should ask my question more specifically:
>
> Do you have an idea whether different set.seed() values and using Mac vs. Windows leads to differences in the occurrence of warnings because parallel="no" might not reset some internal structures properly, or could these differences also indicate that there is something 'wrong' with my data/model?
>
> Thanks in advance for any suggestions!
>
> Best,
> Maitta
>

-- 
Dr. Henrik Singmann
Universit?t Z?rich, Schweiz
http://singmann.org


From markl033 at umn.edu  Mon Oct 27 04:25:44 2014
From: markl033 at umn.edu (Tricia Markle)
Date: Sun, 26 Oct 2014 22:25:44 -0500
Subject: [R-sig-ME] Help request - MCMCglmm model with repeat measures and
	phylogenetic component
Message-ID: <CAO=0ZJVhpCtNErTiaFerBXNfppytnwQ6KaeQBtk0Y5R_KeXviw@mail.gmail.com>

Hello All,


I am a PhD student working on a project attempting to gauge the degree of
?acclimation ability? in salamanders. Specifically, I am looking to see if
wide-ranging species have a greater degree of plasticity in oxygen
consumption (i.e. metabolic rate) at different acclimation temperatures
than narrow-ranging species.


I have multiple species in the model and need to account for phylogenetic
relationships. In addition, the same individuals were used in multiple
trials so I need to account for repeat measures.


I have spent a considerable amount of time putting together a working
MCMCglmm model based on available literature. However, being somewhat of a
novice with this particular type of model, I am hoping to get some further
insight from anyone familiar with the script and model set-up.


I have included the R script and a few specific questions below.


Any help that you could provide would be immensely appreciated!

*R script:*


 library(MCMCglmm)
dataset<-read.csv(file="RData.csv", head=TRUE)
dataset$Range<-as.factor(dataset$Range)
str(dataset)

#Phylogeny Component
tree<-read.tree("Plethodontidae_comb61_PL.phy")
species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
"D._imitator_KHK05", "D._ochrophaeus_WKS05", "D._ocoee_B_KHK62",
"D._orestes_KHK129",  "D._monticola_A",  "D._santeetlah_11775",
"P_cinereus", "P_cylindraceus", "P_glutinosus", "P_hubrichti",
"P_montanus", "P_punctatus", "P_richmondi", "P_teyahalee", "P_virginia",
"P_wehrlei")
pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
tree$tip.label)])# Prune tree to just include species of interest
sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node") #rename
nodes to be unique
plot(sptree, show.node.label=TRUE)

treeAinv<-inverseA(sptree)$Ainv

prior<-list(G=list(G1=list(V=1, n=0.002), G2=list(V=1, n=0.002)),
R=list(V=1, n=0.002))

#For Repeat Measures
dataset$ID<-dataset$animal
head(dataset)
p.var<-var(dataset$LVO2, na.rm=TRUE)

#Model 1 with Range Size
model1<-MCMCglmm(LVO2~1+Acclm+Temp+LMass+Sex+Range+Acclm*Temp*Range,
random=~animal+ID, data=dataset, ginverse=list(species=treeAinv),
nodes="ALL", prior=prior, nitt=300000, burnin=25000, thin = 1000,
verbose=FALSE)


summary(model1)
plot(model1$Sol)
plot(model1$VCV)
autocorr(model1$VCV)
posterior.mode(model1$VCV)

*Questions:*

   1. *Relating to Repeat Measures. *Each salamander was used in 3
   acclimation treatments (randomly assigned order), so I need to account for
   repeat measures. Currently I have ?id? added as a random term, but is it
   instead more appropriate to use some sort of multi-response model?
   2. *The big question.* Where I am *really* stuck is how best to get
   results specific to my main question of interest - which is whether the
   slope of oxygen consumption (VO2) by test temperature varies as a
   consequence of acclimation temperature, and whether this relationship
   differs in wide versus narrow ranging species (or with latitudinal breadth).
   As a recap, salamanders were acclimated at 3 different temperatures (6, 14
   and 22C) and for each acclimation temperature, oxygen consumption was
   measured at 3 test temperatures (5, 15, 25C) (i.e. 9 measures for each
   individual). This creates a slope of test temperatures for each acclimation
   temp. I need some way of comparing differences in slopes between
   acclimation temperatures and plotting these results so that you can tell
   which one is which (i.e., whether wide ranging or narrow ranging species
   have greater plasticity). I currently have the model set up as a single
   response of oxygen consumption (VO2), with numerous fixed factors (and
   individual salamander as a random factor). I see the question I seek as
   potentially relating to a 3-way interaction of Acclm*Temp*Range ? but I
   don?t know how to interpret/view this?


   1. *Finally, any glaring omissions or mistakes in the R script as it
   stands?*



*Sincerely, *

*Tricia Markle*

*PhD Candidate, Conservation Biology Program*

*University of Minnesota*

	[[alternative HTML version deleted]]


From vcadavez at ipb.pt  Mon Oct 27 13:59:57 2014
From: vcadavez at ipb.pt (Vasco Cadavez)
Date: Mon, 27 Oct 2014 12:59:57 +0000
Subject: [R-sig-ME] nlme predict
In-Reply-To: <7125574.iRBDj1UYve@ID-99504.news.uni-berlin.de>
References: <7125574.iRBDj1UYve@ID-99504.news.uni-berlin.de>
Message-ID: <544E41CD.4050705@ipb.pt>

Hi,

I'm using nlme package and I have this error with the predict function:

newdat$pred <- predict(Nlme5, newdata=newdat)
Error in getParsNlme(plist, object$map$fmap, object$map$rmapRel, 
object$map$bmap, : number of items to replace is not a multiple of 
replacement length

Somebody can help?


Cheers,

Vasco

-- 
Vasco A. P. Cadavez, PhD
Departamento de Ci?ncia Animal & Centro de Investiga??o de Montanha (CIMO)
Escola Superior Agr?ria do Instituto Polit?cnico de Bragan?a
Campus de Santa Apol?nia, Apartado 1172
5301-854 Bragan?a Portugal
Telefone: (+351) 273 303 304
Fax: (+351) 273 325 405
e-mail: vcadavez at ipb.pt


From wzhmelly at gmail.com  Tue Oct 28 00:12:03 2014
From: wzhmelly at gmail.com (Zhaohong Wu)
Date: Mon, 27 Oct 2014 19:12:03 -0400
Subject: [R-sig-ME] lmer model converged before, but couldn't now
Message-ID: <C69B005A-A474-4E4B-B794-629D64DD6F58@gmail.com>

Dear All,

I fitted a linear mixed effects model using lmer() two weeks ago, and the model was able to converge. I rerun the model over the weekend (two days ago) and now there are warning messages about max|grad| and negative Herssian that the model failed to converge and the t values from the summary of the un-converged model are not the same as those I originally got from the originally converged one. Any idea why this could happen? Is it because of an update of the lme4 package or something?

I saw a post here, http://r.789695.n4.nabble.com/Why-have-my-glmms-stopped-converging-lme4-td4691786.html, where Dr. Ben Bolker suggested that the max|grad| warning are just false positives, but since the un-converged one gives different t-values, I do not know which results I should rely on.

E.maximal.model.RT<-lmer(RT~ 1+A*B*C+(1+A*C|Subject)+(1+A*B*C|Item), data=Edata, verbose=2,control=lmerControl(optCtrl=list(maxfun=50000)))

The DV is a continuous one, and all the three IVs are categorical and sum-coded.

Any suggestions would be greatly appreciated.

Best,
ZW
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Oct 28 03:41:16 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 27 Oct 2014 22:41:16 -0400
Subject: [R-sig-ME] lmer model converged before, but couldn't now
In-Reply-To: <C69B005A-A474-4E4B-B794-629D64DD6F58@gmail.com>
References: <C69B005A-A474-4E4B-B794-629D64DD6F58@gmail.com>
Message-ID: <544F024C.9040702@gmail.com>

On 14-10-27 07:12 PM, Zhaohong Wu wrote:
> Dear All,
> 
> I fitted a linear mixed effects model using lmer() two weeks ago, and
> the model was able to converge. I rerun the model over the weekend
> (two days ago) and now there are warning messages about max|grad| and
> negative Herssian that the model failed to converge and the t values
> from the summary of the un-converged model are not the same as those
> I originally got from the originally converged one. Any idea why this
> could happen? Is it because of an update of the lme4 package or
> something?
> 
> I saw a post here,
> http://r.789695.n4.nabble.com/Why-have-my-glmms-stopped-converging-lme4-td4691786.html,
> where Dr. Ben Bolker suggested that the max|grad| warning are just
> false positives, but since the un-converged one gives different
> t-values, I do not know which results I should rely on.

   Do you know what version you were using before?  What version are you
using now (packageVersion("lme4")) ?

  What are the AIC and log-likelihoods of your previous and current models?

  The standard error calculation

  We certainly haven't updated the version on CRAN in the last two
weeks, but perhaps you had an older version and just now updated it?

The standard error calculation did change in version 1.1-4
<http://cran.r-project.org/web/packages/lme4/news.html>; you can check
whether this affects your results by comparing

sqrt(diag(vcov(fitted,use.hessian=TRUE)))

and

sqrt(diag(vcov(fitted,use.hessian=FALSE)))

(although I think if you are getting a negative-Hessian warning that the
program will have fallen back on use.hessian=FALSE anyway)

> 
> E.maximal.model.RT<-lmer(RT~ 1+A*B*C+(1+A*C|Subject)+(1+A*B*C|Item),
> data=Edata,
> verbose=2,control=lmerControl(optCtrl=list(maxfun=50000)))
> 
> The DV is a continuous one, and all the three IVs are categorical and
> sum-coded.
> 
> Any suggestions would be greatly appreciated.
> 
> Best, ZW


From romunov at gmail.com  Tue Oct 28 10:03:27 2014
From: romunov at gmail.com (romunov)
Date: Tue, 28 Oct 2014 10:03:27 +0100
Subject: [R-sig-ME] nlme predict
In-Reply-To: <544E41CD.4050705@ipb.pt>
References: <7125574.iRBDj1UYve@ID-99504.news.uni-berlin.de>
	<544E41CD.4050705@ipb.pt>
Message-ID: <CAHT1vpiJKAAY_nvR+UOUMu4yacVBz8k6ykQY58viU5brs=fjGw@mail.gmail.com>

Have you including all the variables into `newdat` used in the model.

Cheers,
Roman


On Mon, Oct 27, 2014 at 1:59 PM, Vasco Cadavez <vcadavez at ipb.pt> wrote:

> Hi,
>
> I'm using nlme package and I have this error with the predict function:
>
> newdat$pred <- predict(Nlme5, newdata=newdat)
> Error in getParsNlme(plist, object$map$fmap, object$map$rmapRel,
> object$map$bmap, : number of items to replace is not a multiple of
> replacement length
>
> Somebody can help?
>
>
> Cheers,
>
> Vasco
>
> --
> Vasco A. P. Cadavez, PhD
> Departamento de Ci?ncia Animal & Centro de Investiga??o de Montanha (CIMO)
> Escola Superior Agr?ria do Instituto Polit?cnico de Bragan?a
> Campus de Santa Apol?nia, Apartado 1172
> 5301-854 Bragan?a Portugal
> Telefone: (+351) 273 303 304
> Fax: (+351) 273 325 405
> e-mail: vcadavez at ipb.pt
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Tue Oct 28 19:33:54 2014
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 28 Oct 2014 18:33:54 +0000
Subject: [R-sig-ME] Binomial model R^2 and ICC calculation with lme4
In-Reply-To: <CD37152F-57B1-4A6A-B71E-8A5AD44DC2F7@gmail.com>
References: <CD37152F-57B1-4A6A-B71E-8A5AD44DC2F7@gmail.com>
Message-ID: <2BFF68BE-A76E-45DF-A8CA-9EA1B47F0554@glasgow.ac.uk>

Hi Maurits,

I think you have answered your own question here:

?I got the answer myself, it appears that the different outcomes are due to the inclusion of a dispersion parameter in my model, introduced as a random effect."
http://jonlefcheck.net/2013/03/13/r2-for-linear-mixed-effects-models/comment-page-1/#comment-2424

?but for the sake of posterity I?ll reply to the list.

As you say,  the problem is the inclusion of the observation-level random effect (OLRE) in the denominator of conditional R-squared (Rsq.c). By default r.squaredGLMM in MuMIn will include all the random effects when calculating the total random effects variance from a binomial GLMM fitted with glmer. The OLRE is a residual variance, so represents unexplained variation and shouldn?t be included in the denominator of Rsq.c. Kamil Barto? (cc-ed), who wrote and maintains MuMIn solved this for glmer(?, family = poisson) but not for binomial models. Looking at getAnywhere(r.squaredGLMM.merMod), I think it would be straightforward to do this - what do you think, Kamil?

The OLRE variance should instead be included as Se, the additive dispersion variance. I?ve adapted your code to an example from ?glmer to illustrate this. You should be able to use these variance components to get the ICC you want following Table 1 of:
Nakagawa, S. & Schielzeth, H. (2010). Repeatability for Gaussian and non-Gaussian data: a practical guide for biologists. Biological Reviews of the Cambridge Philosophical Society, 85, 935?56.

As an aside, slopes and intercepts are almost certain to be correlated (unless you centre the x very carefully) so it?s unusual to include random intercepts and slopes but not allow them to be correlated. 

Good luck,
Paul



# adapt an example from ?glmer to make a random intercepts-and-slopes
# model

  library(lme4)
  library(MuMIn)

  cbpp$obs <- factor(1:nrow(cbpp))
  cbpp$period <- as.numeric(cbpp$period)
  (gm3 <- glmer(cbind(incidence, size - incidence) ~ period +
      (period | herd) +  (1|obs),
                family = binomial, data = cbpp))

# fixed effects variance component

  X <- model.matrix(gm3)
  n <- nrow(X)
  Beta <- fixef(gm3)
  Sf <- var(X %*% Beta)

# random effects variance components
# not that I've excluded the "obs" variance component

  (Sigma.list <- VarCorr(gm3))

  Sl <- 
    sum(
      sapply(Sigma.list[names(Sigma.list)  != "obs"],
             function(Sigma)
             {
               Z <-X[,rownames(Sigma)]
               sum(diag(Z %*% Sigma %*% t(Z)))/n
             }))

# The additive dispersion shouldn't be fixed at one, but rather should be attributed to Se,
# the residual variance which here is the variance of the observtion-level random effect

  Se <- c(Sigma.list$obs)

# Finally, the distribution-specific variance, Sd, is pi^2/3 for binomial GLMMs:

  Sd <- pi^2/3

# Use eqns 29 and 30 from Nakagawa & Schielzeth to estimate marginal and
# conditional R-squared:

  total.var <- Sf + Sl + Se + Sd
  (Rsq.m <- Sf / total.var) 
  (Rsq.c <- (Sf + Sl) / total.var) 

# r.squaredGLMM gives the same Rsq.m but higher Rsq.c

  r.squaredGLMM(gm3)

# the Rsq.c from r.squaredGLMM has Se in the numerator:

  (Sf + Sl + Se) / total.var



On 23 Oct 2014, at 11:41, Maurits Van Zinnicq Bergmann <mauritsvzb at gmail.com> wrote:

> Dear list,
> 
> I?m trying to calculate the marginal and conditional R^2 for a binomial GLMM using the lme4 package. Some googling a while ago brought me to the site of Jonathan Lefcheck (http://jonlefcheck.net/2013/03/13/r2-for-linear-mixed-effects-models/) which offers exactly this. However, more recently I became aware of a recent paper by Dr. Paul Johnson (http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12225/abstract) that explains the calculation of R^2 for random slope models and points to the r.squaredGLMM function in the MuMIn package.
> 
> Unfortunately I experience some inconsistencies and problems when comparing R^2 values of three different GLMMs 1) random intercept mixed model, 2) mixed model with random covariance between intercept and slope, and 3) a mixed model without random covariance between intercept and slope, using the 2 methods:.
> 
> 1) a comparison of marginal and conditional R^2 estimates between Lefcheck?s method and the MuMIn package showed consistent marginal R^2 estimates for the first and the second GLMM, whereas the marginal R^2 values were lower using Lefcheck?s method. The third mixed model showed both different conditional and marginal R^2. Could anyone explain why I obtain different R^2 estimates when comparing the 2 methods,
> 
> 2) When I calculate R^2 values using the code from the supporting information with Dr. Johnsons paper (slightly modified to reflect a binomial GLMM instead of poison LMM) I obtain different values when compared to the values obtained from the MuMIn package. If I calculated the variance components correctly, they should return identical R^2 values. While I don?t have to bother with the mistake(s) I made in the code to obtain R^2 values (I can just use the package instead), I would like to know how to correctly calculate the variance components needed to calculate the ICC over the whole sample of all three models.
> 
> Thank you for any help.
> Maurits van Zinnicq
> 
> 
> 
> 
> 
> # random intercept model
> m1 <- glmer(cbind(df$Valid.detections, df$Missed.detections) ~ distance + 
>               Habitat + Replicate + transmitter.depth + receiver.depth + 
>               wind.speed + wtc + Transmitter + (1 | Unit) + 
>               (1 | SUR.ID) + distance:Transmitter + 
>               distance:Habitat + distance:transmitter.depth + distance:receiver.depth + 
>               distance:wind.speed, data = df, family = binomial(link=logit),control=glmerControl(calc.derivs=F))
> 
> # random slope model
> m2 <- glmer(cbind(df$Valid.detections, df$Missed.detections) ~ distance + 
>                  Habitat + Replicate + transmitter.depth + receiver.depth + 
>                  wind.speed + wtc + Transmitter + (1 | Unit) + 
>                  (distance | SUR.ID) + distance:Transmitter + 
>                  distance:Habitat + distance:transmitter.depth + distance:receiver.depth + 
>                  distance:wind.speed, data = df, family = binomial(link=logit),control=glmerControl(calc.derivs=F))
> 
> # random slope model without random covariance between slope/intercept
> m3 <- glmer(cbind(df$Valid.detections, df$Missed.detections) ~ distance + 
>               Habitat + Replicate + transmitter.depth + receiver.depth + 
>               wind.speed + wtc + Transmitter + (1 | Unit) + 
>               (1 | SUR.ID) + (0 + distance | SUR.ID) + distance:Transmitter + 
>               distance:Habitat + distance:transmitter.depth + distance:receiver.depth + 
>               distance:wind.speed, data = df, family = binomial(link=logit),control=glmerControl(calc.derivs=F))
> 
> 
> 
> 
> 
> # adjusted code from Paul Johnson to reflect binomial GLMM
> 
> # Extract the variance components require for the R-squared statistics,
> # starting with the better-fitting random slopes model.
> 
> # First we need the design matrix (X), the number of observations (n)
> # and the fixed effect estimates (Beta)
> 
> X <- model.matrix(m1)
> n <- nrow(X)
> Beta <- fixef(m1)
> 
> # First the fixed effects variance (eqn 27 of Nakagawa & Schielzeth): 
> 
> Sf <- var(X %*% Beta)
> 
> # Second, the list of covariance matrices of the random effects.
> # Here the list has only a single element because there is only
> # one level of random effects.
> 
> (Sigma.list <- VarCorr(m1))
> 
> # Use equation 11 in the paper to estimate the random effects variance 
> # component.
> # Using sapply ensures that the same code will work when there are multiple
> # random effects (i.e. where length(Sigma.list) > 1)
> 
> Sl <- 
>   sum(
>     sapply(Sigma.list,
>            function(Sigma)
>            {
>              Z <-X[,rownames(Sigma)]
>              sum(diag(Z %*% Sigma %*% t(Z)))/n
>            }))
> 
> 
> # As this model is an binomial GLMM, the additive dispersion variance, Se, is
> # usually fixed to 1 for computational reasons, as additive disperson is not identifiable (Nakagawa & Schielzeth 2013)
> 
> Se <- 1
> 
> # Finally, the distribution-specific variance, Sd, is pi^2/3 for binomial GLMMs:
> 
> Sd <- pi^2/3
> 
> # Use eqns 29 and 30 from Nakagawa & Schielzeth to estimate marginal and
> # conditional R-squared:
> 
> total.var <- Sf + Sl + Se + Sd
> (Rsq.m <- Sf / total.var) 
> (Rsq.c <- (Sf + Sl) / total.var) 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From eoinduffy0000 at googlemail.com  Tue Oct 28 22:14:04 2014
From: eoinduffy0000 at googlemail.com (Eoin Duffy)
Date: Tue, 28 Oct 2014 22:14:04 +0100
Subject: [R-sig-ME] Testing interaction between fixed effect and random
 effect nested within another random effect
Message-ID: <CAPeV8wWPozKtvOyq3WVcAgLKTw4Fk+XUWZvto4v9ayrg4nE1RQ@mail.gmail.com>

Hello mixed model list


I am working on a mixed model using lmer in R and I am a bit stuck on some
coding. I have measured male and female fitness in Drosophila from 35
inbred lines (genotype) over three blocks.

My response variable is 'fitness' with n=10 individuals/sex/line/block
tested.

Sex is fixed, Block is random and Line nested within block is random. I
primarily interested in the interaction between sex and line. Therefore my
model looks like

m1<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Line),noNAdata)

If I wanted to tested the significance of the Sex:Line interaction my plan
is to just compare the above model to a model without the interaction and
use anova to compare the two models

e.g. m2<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block),noNAdata)
anova(m1,m2)

However what I am wondering is if I am testing the significance of the
Sex:Line interaction (included as a random effect) will R know Line is
nested within Block ???

How do I specify the interaction between Sex by Line nested within Block ??

Should it be something like

 m1T<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Block:Line)

Any thoughts would be appreciated. I have included a sample of my data below

     Block Line Sex FitnessInfected FitnessCured2        1    2   M
      1.4573       0.22153        1    2   M          1.1551
1.13794        1    2   M          1.4573       1.13797        1    2
 M          1.4573       0.41089        1    2   M         -1.5648
  1.137911       1    2   F         -0.2669      -1.247312       1
2   F          0.2785      -1.247313       1    2   F         -0.5396
    -1.247314       1    2   F         -0.5396       0.460215       1
  2   F          1.8237      -1.247316       1    2   F
0.7330       0.496517       1    2   F          1.5511      -1.247318
     1    2   F         -0.5396       1.477419       1    2   F
  1.0966       1.186820       1    2   F         -0.5396
-1.247321       1    3   M          1.2054       0.716222       1    3
  M          1.2585       0.314624       1    3   M         -1.5648
   0.267226       1    3   M         -0.8932      -0.861527       1
3   M          0.5047       1.137928       1    3   M          0.7704
     1.137929       1    3   M         -1.5648      -1.768931       1
  3   F         -0.5396       0.678232       1    3   F
-0.5396      -1.247333       1    3   F         -0.5396       1.077834
      1    3   F         -0.5396      -1.247335       1    3   F
  -0.5396      -1.247336       1    3   F         -0.5396
0.714537       1    3   F         -0.5396       0.7508

-- 
Eoin Duffy

PhD Researcher
Institute of Environmental Sciences
Jagiellonian University
Gronostajowa 7
30-387, Krakow
Poland

	[[alternative HTML version deleted]]


From manabu.sakamoto at gmail.com  Wed Oct 29 12:16:48 2014
From: manabu.sakamoto at gmail.com (Manabu Sakamoto)
Date: Wed, 29 Oct 2014 11:16:48 +0000
Subject: [R-sig-ME] Ordinal categorical variable as a random effect in
	MCMCglmm
Message-ID: <CAErHMT2nucT4G1C_YkKOtBoKhP1GLNVCJL5gt8pxYU35z4JfXQ@mail.gmail.com>

Dear list,

I'm using MCMCglmm with some random effects, including a phylogeny and a
categorical variable, scored along an ordinal scale, e.g., 1 < 2 < 3 <...

If my phylogenetic tip names are stored as a character string Taxon (and
there is an associated inverse A object), and my quality codes are stored
as an ordered factor variable Quality, then my questions are:

1) Can I specify the random effect formula simply as: random= ~ Taxon +
Quality --- i.e., without functions like us() or idh() around Quality?
2) What sort of prior should I assign for Quality? --- For the moment I am
using:

list(V=1, nu=1, alpha.mu = 0, alpha.V = 25^2)


I'd appreciate any advise.

Kind regards.
Manabu
-- 
Manabu Sakamoto, PhD
manabu.sakamoto at gmail.com

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Thu Oct 30 10:10:34 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 30 Oct 2014 09:10:34 +0000
Subject: [R-sig-ME] Testing interaction between fixed effect and random
 effect nested within another random effect
In-Reply-To: <CAPeV8wWPozKtvOyq3WVcAgLKTw4Fk+XUWZvto4v9ayrg4nE1RQ@mail.gmail.com>
References: <CAPeV8wWPozKtvOyq3WVcAgLKTw4Fk+XUWZvto4v9ayrg4nE1RQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B10AF2@inbomail.inbo.be>

Dear Eoin,

Much depends on how you code Line. If Each line has a unique code, thus each line ID occurs in only one block, then (1|Sex:Block:Line) is equal to (1|Sex:Line). If you have a crossed design and you reuse line ID among block (a line ID can occur in more than one block), then (1|Sex:Block:Line) is different from (1|Sex:Line). (1|Sex:Block:Line) is the most explicit way to write it and it does not depends on the coding of line ID.

A few more things:
- Although block is random from a philosophical standpoint, it is better to use it as a fixed effect because it has only 3 levels. More details on http://glmm.wikidot.com/faq
- I'd rather look at (0 + Sex|Line) than (1|Line:Sex). (0 + Sex|Line) allows for a different variance in line effect between male and female, and a correlation between male and female within the line

M1 <- lmer(FitnessCured ~ Sex + Block + (0 + Sex|Block:Line), noNAdata)
M2 <- lmer(FitnessCured ~ Sex + Block + (1|Block:Line), noNAdata)
anova(M1, M2)

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Eoin Duffy
Verzonden: dinsdag 28 oktober 2014 22:14
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Testing interaction between fixed effect and random effect nested within another random effect

Hello mixed model list


I am working on a mixed model using lmer in R and I am a bit stuck on some coding. I have measured male and female fitness in Drosophila from 35 inbred lines (genotype) over three blocks.

My response variable is 'fitness' with n=10 individuals/sex/line/block tested.

Sex is fixed, Block is random and Line nested within block is random. I primarily interested in the interaction between sex and line. Therefore my model looks like

m1<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Line),noNAdata)

If I wanted to tested the significance of the Sex:Line interaction my plan is to just compare the above model to a model without the interaction and use anova to compare the two models

e.g. m2<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block),noNAdata)
anova(m1,m2)

However what I am wondering is if I am testing the significance of the Sex:Line interaction (included as a random effect) will R know Line is nested within Block ???

How do I specify the interaction between Sex by Line nested within Block ??

Should it be something like

 m1T<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Block:Line)

Any thoughts would be appreciated. I have included a sample of my data below

     Block Line Sex FitnessInfected FitnessCured2        1    2   M
      1.4573       0.22153        1    2   M          1.1551
1.13794        1    2   M          1.4573       1.13797        1    2
 M          1.4573       0.41089        1    2   M         -1.5648
  1.137911       1    2   F         -0.2669      -1.247312       1
2   F          0.2785      -1.247313       1    2   F         -0.5396
    -1.247314       1    2   F         -0.5396       0.460215       1
  2   F          1.8237      -1.247316       1    2   F
0.7330       0.496517       1    2   F          1.5511      -1.247318
     1    2   F         -0.5396       1.477419       1    2   F
  1.0966       1.186820       1    2   F         -0.5396
-1.247321       1    3   M          1.2054       0.716222       1    3
  M          1.2585       0.314624       1    3   M         -1.5648
   0.267226       1    3   M         -0.8932      -0.861527       1
3   M          0.5047       1.137928       1    3   M          0.7704
     1.137929       1    3   M         -1.5648      -1.768931       1
  3   F         -0.5396       0.678232       1    3   F
-0.5396      -1.247333       1    3   F         -0.5396       1.077834
      1    3   F         -0.5396      -1.247335       1    3   F
  -0.5396      -1.247336       1    3   F         -0.5396
0.714537       1    3   F         -0.5396       0.7508

--
Eoin Duffy

PhD Researcher
Institute of Environmental Sciences
Jagiellonian University
Gronostajowa 7
30-387, Krakow
Poland

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bates at stat.wisc.edu  Thu Oct 30 15:25:07 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 30 Oct 2014 09:25:07 -0500
Subject: [R-sig-ME] "Multilevel Modeling Using R" and variance estimates
Message-ID: <CAO7JsnSeTrz+xk5mCWr6QXB7DCDkZudaeWX1MDrU-ZvHbQwxrg@mail.gmail.com>

I recently received an email advertisement from CRC Press which mentioned
the recently published book "Multilevel Modeling Using R".  In the errata
section of the web site for the book, http://www.mlminr.com/, the first
erratum concerns the concerns the calculation of the intraclass correlation
coefficient where the estimated standard deviations of the random effects
and residuals are used instead of the estimated variances.

The description of the erratum continues with the statements, "This error
of using the standard deviation instead of the variance continues for
several others examples. The lme4 package reports information on random
effects in terms of the standard deviations, not in terms of the variances."

I haven't looked at a copy of the book as it is not yet available at our
library.  However, these statements seem peculiar to me.  Does the first
sentence mean that the confusion of standard deviations and variances
continues throughout the book?  If so, that seems like a rather fundamental
mistake.

Also, with regard to the lme4 package reporting standard deviations, not
variances, I thought we reported both.  Is mistaking the column labelled
Std. Dev. for variance estimates a common problem?

Finally, most books with titles ending in "With R" or "Using R" provide an
R package with the data.  The data in http://www.mlminr.com/data-sets are
in CSV and SPSS formats.  Why SPSS?

	[[alternative HTML version deleted]]


From eoinduffy0000 at googlemail.com  Thu Oct 30 16:54:55 2014
From: eoinduffy0000 at googlemail.com (Eoin Duffy)
Date: Thu, 30 Oct 2014 16:54:55 +0100
Subject: [R-sig-ME] Follow up question testing three way interaction between
 two fixed effects and a random effect nested in a fixed
Message-ID: <CAPeV8wV6JqmvPQi53J_VwhUz3w-2EZ2Zj91ECx9JwGfAkwWM5w@mail.gmail.com>

Dear Thierry

Thank you very much for your insightful reply. I was a bit unsure about
specifying Block as a random effect so thanks for further clarifying that
for me.

I have a follow up question about a similar, separate analysis if yourself
or the mailing list have time to think about. I need to include an
additional fixed factor (2 levels) which block (3 levels) is nested in
which then has line (35 levels) nested in it.

So the background is. I am measuring male and female fitness in Drosophila
(n=10/sex)  from 35 lines over three blocks (same line ID  during each
block), all this was performed twice using different 'tester' flies from
two different populations that were or were not infected with a parasite
(i.e.parasite infection +/-: PI) in order to examine whether parasite
infection deferentially affected intersexual fitness across lines.

So I'm primarily interested in the three way interaction between sex x line
x parasite infection (PI), 'does intersexual fitness differ between lines
if their fitness was measured using flies that were or were not infected
with the parasite?'

My model looks like this, modifying from Thierry's suggested code below
with PI (2 levels), Block (3 levels), Sex as fixed factors and line as a
random factor nested within Block, nested with PI, which I think is right.

M1<-lmer(Fitness~Sex+Block+PI+(0+Sex|PI:Block:Line), noNAdata)
M2<-lmer(Fitness~Sex+Block+PI+(1+PI:Block:Line), noNAdata)
anova(M1,M2)

Which produces the below output

> anova(M1, M2)
refitting model(s) with ML (instead of REML)
Data: newdataWol
Models:
..1: Fitness ~ Sex + Block + WolInfection + (1 | WolInfection:Block:Line)
object: Fitness ~ Sex + Block + WolInfection + (0 + Sex |
WolInfection:Block:Line)
       Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
..1     6 11051 11089 -5519.6    11039
object  8 10986 11037 -5485.1    10970 69.012      2  1.033e-15 ***

My question is does it seem as through I have specified my models correctly
in order to check the significance of the 3 way sex x line x parasite
infection
interaction?

Any suggestions would be greatly appreciated.

Eoin



On Thu, Oct 30, 2014 at 10:10 AM, ONKELINX, Thierry <
Thierry.ONKELINX at inbo.be> wrote:

> Dear Eoin,
>
> Much depends on how you code Line. If Each line has a unique code, thus
> each line ID occurs in only one block, then (1|Sex:Block:Line) is equal to
> (1|Sex:Line). If you have a crossed design and you reuse line ID among
> block (a line ID can occur in more than one block), then (1|Sex:Block:Line)
> is different from (1|Sex:Line). (1|Sex:Block:Line) is the most explicit way
> to write it and it does not depends on the coding of line ID.
>
> A few more things:
> - Although block is random from a philosophical standpoint, it is better
> to use it as a fixed effect because it has only 3 levels. More details on
> http://glmm.wikidot.com/faq
> - I'd rather look at (0 + Sex|Line) than (1|Line:Sex). (0 + Sex|Line)
> allows for a different variance in line effect between male and female, and
> a correlation between male and female within the line
>
> M1 <- lmer(FitnessCured ~ Sex + Block + (0 + Sex|Block:Line), noNAdata)
> M2 <- lmer(FitnessCured ~ Sex + Block + (1|Block:Line), noNAdata)
> anova(M1, M2)
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] Namens Eoin Duffy
> Verzonden: dinsdag 28 oktober 2014 22:14
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Testing interaction between fixed effect and random
> effect nested within another random effect
>
> Hello mixed model list
>
>
> I am working on a mixed model using lmer in R and I am a bit stuck on some
> coding. I have measured male and female fitness in Drosophila from 35
> inbred lines (genotype) over three blocks.
>
> My response variable is 'fitness' with n=10 individuals/sex/line/block
> tested.
>
> Sex is fixed, Block is random and Line nested within block is random. I
> primarily interested in the interaction between sex and line. Therefore my
> model looks like
>
> m1<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Line),noNAdata)
>
> If I wanted to tested the significance of the Sex:Line interaction my plan
> is to just compare the above model to a model without the interaction and
> use anova to compare the two models
>
> e.g. m2<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block),noNAdata)
> anova(m1,m2)
>
> However what I am wondering is if I am testing the significance of the
> Sex:Line interaction (included as a random effect) will R know Line is
> nested within Block ???
>
> How do I specify the interaction between Sex by Line nested within Block ??
>
> Should it be something like
>
>  m1T<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Block:Line)
>
> Any thoughts would be appreciated. I have included a sample of my data
> below
>
>      Block Line Sex FitnessInfected FitnessCured2        1    2   M
>       1.4573       0.22153        1    2   M          1.1551
> 1.13794        1    2   M          1.4573       1.13797        1    2
>  M          1.4573       0.41089        1    2   M         -1.5648
>   1.137911       1    2   F         -0.2669      -1.247312       1
> 2   F          0.2785      -1.247313       1    2   F         -0.5396
>     -1.247314       1    2   F         -0.5396       0.460215       1
>   2   F          1.8237      -1.247316       1    2   F
> 0.7330       0.496517       1    2   F          1.5511      -1.247318
>      1    2   F         -0.5396       1.477419       1    2   F
>   1.0966       1.186820       1    2   F         -0.5396
> -1.247321       1    3   M          1.2054       0.716222       1    3
>   M          1.2585       0.314624       1    3   M         -1.5648
>    0.267226       1    3   M         -0.8932      -0.861527       1
> 3   M          0.5047       1.137928       1    3   M          0.7704
>      1.137929       1    3   M         -1.5648      -1.768931       1
>   3   F         -0.5396       0.678232       1    3   F
> -0.5396      -1.247333       1    3   F         -0.5396       1.077834
>       1    3   F         -0.5396      -1.247335       1    3   F
>   -0.5396      -1.247336       1    3   F         -0.5396
> 0.714537       1    3   F         -0.5396       0.7508
>
> --
> Eoin Duffy
>
> PhD Researcher
> Institute of Environmental Sciences
> Jagiellonian University
> Gronostajowa 7
> 30-387, Krakow
> Poland
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
>



-- 
Eoin Duffy

PhD Researcher
Institute of Environmental Sciences
Jagiellonian University
Gronostajowa 7
30-387, Krakow
Poland

	[[alternative HTML version deleted]]


From marko.bachl at uni-hohenheim.de  Thu Oct 30 18:02:32 2014
From: marko.bachl at uni-hohenheim.de (Marko Bachl)
Date: Thu, 30 Oct 2014 18:02:32 +0100
Subject: [R-sig-ME] "Multilevel Modeling Using R" and variance estimates
In-Reply-To: <CAO7JsnSeTrz+xk5mCWr6QXB7DCDkZudaeWX1MDrU-ZvHbQwxrg@mail.gmail.com>
References: <CAO7JsnSeTrz+xk5mCWr6QXB7DCDkZudaeWX1MDrU-ZvHbQwxrg@mail.gmail.com>
Message-ID: <CAE5vbrs44+xeWbvw2yBnHXA84WbHjiRO_rtg2jrKSoEjnYrLbA@mail.gmail.com>

I think there is some confusion on which packages the authors talking
about in their book and in the erratum. The example on pages 44-45 in
the book reports output of lme() from the nlme package which does in
fact only include SD of the random effects.

However, I cannot comment on whether this confusion continues in the
whole book, I have just looked up the one page...



2014-10-30 15:25 GMT+01:00 Douglas Bates <bates at stat.wisc.edu>:
> I recently received an email advertisement from CRC Press which mentioned
> the recently published book "Multilevel Modeling Using R".  In the errata
> section of the web site for the book, http://www.mlminr.com/, the first
> erratum concerns the concerns the calculation of the intraclass correlation
> coefficient where the estimated standard deviations of the random effects
> and residuals are used instead of the estimated variances.
>
> The description of the erratum continues with the statements, "This error
> of using the standard deviation instead of the variance continues for
> several others examples. The lme4 package reports information on random
> effects in terms of the standard deviations, not in terms of the variances."
>
> I haven't looked at a copy of the book as it is not yet available at our
> library.  However, these statements seem peculiar to me.  Does the first
> sentence mean that the confusion of standard deviations and variances
> continues throughout the book?  If so, that seems like a rather fundamental
> mistake.
>
> Also, with regard to the lme4 package reporting standard deviations, not
> variances, I thought we reported both.  Is mistaking the column labelled
> Std. Dev. for variance estimates a common problem?
>
> Finally, most books with titles ending in "With R" or "Using R" provide an
> R package with the data.  The data in http://www.mlminr.com/data-sets are
> in CSV and SPSS formats.  Why SPSS?
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
OUT NOW: Bachl, M. (2014). Analyse rezeptionsbegleitend gemessener
Kandidatenbewertungen in TV-Duellen. Erweiterung etablierter Verfahren
und Vorschlag einer Mehrebenenmodellierung. Berlin: epubli. Print:
http://uhoh.de/diss-bachl-print. Online: http://uhoh.de/diss-bachl
---
Dr. Marko Bachl
Universit?t Hohenheim
Institut f?r Kommunikationswissenschaft (540C)
T 0711 459 228 66
M marko.bachl at uni-hohenheim.de
W www.komm.uni-hohenheim.de/bachl


From bbolker at gmail.com  Thu Oct 30 18:09:14 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 30 Oct 2014 13:09:14 -0400
Subject: [R-sig-ME] "Multilevel Modeling Using R" and variance estimates
In-Reply-To: <CAE5vbrs44+xeWbvw2yBnHXA84WbHjiRO_rtg2jrKSoEjnYrLbA@mail.gmail.com>
References: <CAO7JsnSeTrz+xk5mCWr6QXB7DCDkZudaeWX1MDrU-ZvHbQwxrg@mail.gmail.com>
	<CAE5vbrs44+xeWbvw2yBnHXA84WbHjiRO_rtg2jrKSoEjnYrLbA@mail.gmail.com>
Message-ID: <545270BA.2090101@gmail.com>


>>
>> Also, with regard to the lme4 package reporting standard deviations, not
>> variances, I thought we reported both.  Is mistaking the column labelled
>> Std. Dev. for variance estimates a common problem?

  For what it's worth, print.merMod prints only standard deviations by
default; summary.merMod prints both SD and variance by default; this can
be adjusted by the ranef.comp argument.

  Ben Bolker


From bates at stat.wisc.edu  Thu Oct 30 18:21:38 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 30 Oct 2014 12:21:38 -0500
Subject: [R-sig-ME] "Multilevel Modeling Using R" and variance estimates
In-Reply-To: <545270BA.2090101@gmail.com>
References: <CAO7JsnSeTrz+xk5mCWr6QXB7DCDkZudaeWX1MDrU-ZvHbQwxrg@mail.gmail.com>
	<CAE5vbrs44+xeWbvw2yBnHXA84WbHjiRO_rtg2jrKSoEjnYrLbA@mail.gmail.com>
	<545270BA.2090101@gmail.com>
Message-ID: <CAO7JsnSp3bjxSBzWJdOLS-yno7MOH9FZ6dOY4_FYyPw4ye7yHw@mail.gmail.com>

On Thu, Oct 30, 2014 at 12:09 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
> >>
> >> Also, with regard to the lme4 package reporting standard deviations, not
> >> variances, I thought we reported both.  Is mistaking the column labelled
> >> Std. Dev. for variance estimates a common problem?
>
>   For what it's worth, print.merMod prints only standard deviations by
> default; summary.merMod prints both SD and variance by default; this can
> be adjusted by the ranef.comp argument.
>

Thanks for the reminder.  I had forgotten about the "let's cripple the
print method for the sake of consistency with the rather perverse behavior
of other model-fitting classes" decision. :-)

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Fri Oct 31 10:59:19 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 31 Oct 2014 09:59:19 +0000
Subject: [R-sig-ME] Follow up question testing three way interaction
 between two fixed effects and a random effect nested in a fixed
In-Reply-To: <CAPeV8wV6JqmvPQi53J_VwhUz3w-2EZ2Zj91ECx9JwGfAkwWM5w@mail.gmail.com>
References: <CAPeV8wV6JqmvPQi53J_VwhUz3w-2EZ2Zj91ECx9JwGfAkwWM5w@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B11D09@inbomail.inbo.be>

Dear Eoin,

I would add the interaction of sex and PI to the fixed effects as well. You can keep Block:Line as grouping factor of the random effects.
M1<-lmer(Fitness ~ Sex * PI + Block + (0 + Sex * PI|Block:Line), noNAdata)
M2<-lmer(Fitness ~ Sex * PI + Block + (0 + Sex + PI|Block:Line), noNAdata)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

Van: Eoin Duffy [mailto:eoinduffy0000 at googlemail.com]
Verzonden: donderdag 30 oktober 2014 16:55
Aan: ONKELINX, Thierry
CC: r-sig-mixed-models at r-project.org
Onderwerp: Follow up question testing three way interaction between two fixed effects and a random effect nested in a fixed

Dear Thierry

Thank you very much for your insightful reply. I was a bit unsure about specifying Block as a random effect so thanks for further clarifying that for me.

I have a follow up question about a similar, separate analysis if yourself or the mailing list have time to think about. I need to include an additional fixed factor (2 levels) which block (3 levels) is nested in which then has line (35 levels) nested in it.

So the background is. I am measuring male and female fitness in Drosophila (n=10/sex)  from 35 lines over three blocks (same line ID  during each block), all this was performed twice using different 'tester' flies from two different populations that were or were not infected with a parasite (i.e.parasite infection +/-: PI) in order to examine whether parasite infection deferentially affected intersexual fitness across lines.

So I'm primarily interested in the three way interaction between sex x line x parasite infection (PI), 'does intersexual fitness differ between lines if their fitness was measured using flies that were or were not infected with the parasite?'

My model looks like this, modifying from Thierry's suggested code below with PI (2 levels), Block (3 levels), Sex as fixed factors and line as a random factor nested within Block, nested with PI, which I think is right.

M1<-lmer(Fitness~Sex+Block+PI+(0+Sex|PI:Block:Line), noNAdata)
M2<-lmer(Fitness~Sex+Block+PI+(1+PI:Block:Line), noNAdata)
anova(M1,M2)

Which produces the below output

> anova(M1, M2)
refitting model(s) with ML (instead of REML)
Data: newdataWol
Models:
..1: Fitness ~ Sex + Block + WolInfection + (1 | WolInfection:Block:Line)
object: Fitness ~ Sex + Block + WolInfection + (0 + Sex | WolInfection:Block:Line)
       Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
..1     6 11051 11089 -5519.6    11039
object  8 10986 11037 -5485.1    10970 69.012      2  1.033e-15 ***

My question is does it seem as through I have specified my models correctly in order to check the significance of the 3 way sex x line x parasite infection
interaction?

Any suggestions would be greatly appreciated.

Eoin



On Thu, Oct 30, 2014 at 10:10 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
Dear Eoin,

Much depends on how you code Line. If Each line has a unique code, thus each line ID occurs in only one block, then (1|Sex:Block:Line) is equal to (1|Sex:Line). If you have a crossed design and you reuse line ID among block (a line ID can occur in more than one block), then (1|Sex:Block:Line) is different from (1|Sex:Line). (1|Sex:Block:Line) is the most explicit way to write it and it does not depends on the coding of line ID.

A few more things:
- Although block is random from a philosophical standpoint, it is better to use it as a fixed effect because it has only 3 levels. More details on http://glmm.wikidot.com/faq
- I'd rather look at (0 + Sex|Line) than (1|Line:Sex). (0 + Sex|Line) allows for a different variance in line effect between male and female, and a correlation between male and female within the line

M1 <- lmer(FitnessCured ~ Sex + Block + (0 + Sex|Block:Line), noNAdata)
M2 <- lmer(FitnessCured ~ Sex + Block + (1|Block:Line), noNAdata)
anova(M1, M2)

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Eoin Duffy
Verzonden: dinsdag 28 oktober 2014 22:14
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Testing interaction between fixed effect and random effect nested within another random effect

Hello mixed model list


I am working on a mixed model using lmer in R and I am a bit stuck on some coding. I have measured male and female fitness in Drosophila from 35 inbred lines (genotype) over three blocks.

My response variable is 'fitness' with n=10 individuals/sex/line/block tested.

Sex is fixed, Block is random and Line nested within block is random. I primarily interested in the interaction between sex and line. Therefore my model looks like

m1<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Line),noNAdata)

If I wanted to tested the significance of the Sex:Line interaction my plan is to just compare the above model to a model without the interaction and use anova to compare the two models

e.g. m2<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block),noNAdata)
anova(m1,m2)

However what I am wondering is if I am testing the significance of the Sex:Line interaction (included as a random effect) will R know Line is nested within Block ???

How do I specify the interaction between Sex by Line nested within Block ??

Should it be something like

 m1T<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Block:Line)

Any thoughts would be appreciated. I have included a sample of my data below

     Block Line Sex FitnessInfected FitnessCured2        1    2   M
      1.4573       0.22153        1    2   M          1.1551
1.13794        1    2   M          1.4573       1.13797        1    2
 M          1.4573       0.41089        1    2   M         -1.5648
  1.137911       1    2   F         -0.2669      -1.247312       1
2   F          0.2785      -1.247313       1    2   F         -0.5396
    -1.247314       1    2   F         -0.5396       0.460215       1
  2   F          1.8237      -1.247316       1    2   F
0.7330       0.496517       1    2   F          1.5511      -1.247318
     1    2   F         -0.5396       1.477419       1    2   F
  1.0966       1.186820       1    2   F         -0.5396
-1.247321       1    3   M          1.2054       0.716222       1    3
  M          1.2585       0.314624       1    3   M         -1.5648
   0.267226       1    3   M         -0.8932      -0.861527       1
3   M          0.5047       1.137928       1    3   M          0.7704
     1.137929       1    3   M         -1.5648      -1.768931       1
  3   F         -0.5396       0.678232       1    3   F
-0.5396      -1.247333       1    3   F         -0.5396       1.077834
      1    3   F         -0.5396      -1.247335       1    3   F
  -0.5396      -1.247336       1    3   F         -0.5396
0.714537       1    3   F         -0.5396       0.7508

--
Eoin Duffy

PhD Researcher
Institute of Environmental Sciences
Jagiellonian University
Gronostajowa 7
30-387, Krakow
Poland

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.




--
Eoin Duffy

PhD Researcher
Institute of Environmental Sciences
Jagiellonian University
Gronostajowa 7
30-387, Krakow
Poland
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From graham.b.mcnamara at gmail.com  Fri Oct 31 11:27:22 2014
From: graham.b.mcnamara at gmail.com (Graham B. McNamara)
Date: Fri, 31 Oct 2014 11:27:22 +0100
Subject: [R-sig-ME] How to calculate the level-1 variance of a GLMM (Poisson
 or Additive Over-dispersed Poisson) model?
Message-ID: <CAPoG4sj_jbZfcLkTa3x5k0JygLu_agmPcaBU8j07ccL=dZTuZg@mail.gmail.com>

Dear all,

I'm estimating a three-level GLMM model of Students nested in Classes
nested Schools: a random-intercept model with just one predictor
variable (no random slopes). The dependent variable is a count
variable, but has a much higher variance than its mean, indicating I
probably need to be thinking of an overdispersed Poisson /
Negative-binomial.

I am interested in the proportion of variance found on each level:
decomposing the total variance. In linear models, the variance of all
random effects is presented int he summary() statement. But for GLMM
models, this is not the case: only the Class and School level variance
are reported. I understand the reason for this, and I have also read
(and learned a lot from) the caveats on http://glmm.wikidot.com/faq.

However, there are also papers describing several methods to retrieve
the Level-1 (student) level variance anyway:
http://www.bristol.ac.uk/cmm/software/support/support-faqs/pval.html/#macros
deals with two-level binomial models and
http://onlinelibrary.wiley.com/doi/10.1111/j.1467-985X.2004.00365.x/abstract
deals with over-dispersed binomial models.

Is there such a method available for Poisson, Over-dispersed Poisson,
or Negative Binomial models? A piece of code, somewhere, perhaps?


To explain my models:

  # poisson
  fit.glmer <- glmer(y ~ x1 + (1 | class) + (1 | school), data =
mydata, verbose = TRUE, family = poisson)

I also created an additive overdispered poisson-lognormal model by
adding a per-observation (Student-level) random effect (as per Ben
Bolker's code found on
http://blogs.umass.edu/nrc697sa-finnj/2012/11/08/bolkers-reanalysis-of-owl-data/):

  # poisson-lognormal
  fit.glmer.1 <- glmer(y ~ x1 + (1 | class) + (1 | school) + (1 |
over), data = mydata, verbose = TRUE, family = poisson)

And fit.glmer.1 seems to have much better fit than fit.glmer.


FYI, I'm *actually* interested in how the variance proportion across
levels change over time. For example, in 2010 most of the outcome
variance may be found on the Student-level: say 70% of the variance is
found on the Student level, 20% on the Class level, and 10% on the
School level. In 2011, with the same students, 50% of the variance is
found on the Student level, 40% on the class level, and 10% on the
School level. Thus, the between-student variance has decreased from
70% to 50% from 2010 to 2011. This is what I'm actually trying to
figure out for my data.
(At the moment I'm stuck with doing log-transformed lmer models per
year, because that's the only way I know to get at least *some* idea
about the level-1 variance... Any help is appreciated.)

Thanks a bunch,

Graham


From laura.riggi at slu.se  Fri Oct 31 15:50:23 2014
From: laura.riggi at slu.se (Laura Riggi)
Date: Fri, 31 Oct 2014 14:50:23 +0000
Subject: [R-sig-ME] nlme : how to obtain confidence intervals of fitted
	values
Message-ID: <129789545FD9CA4C8A495D5B9A92F37F6FF37409@exchange2-1>

Hi

I used lme (from package nlme) to fit a model containing two fixed factors, one random factor and a variance function (weights=varIdent(form=~1|as.factor(year_collected)). This is my "best" model.

I would like to plot the confidence intervals for the predicted fitted values. Something similar to se.fit=True in predict.lm but for lme models containing random effects and variance function.

Does anybody knows how to do this with R ?

Thanks
Laura


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Oct 31 16:07:33 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 31 Oct 2014 11:07:33 -0400
Subject: [R-sig-ME] nlme : how to obtain confidence intervals of fitted
 values
In-Reply-To: <129789545FD9CA4C8A495D5B9A92F37F6FF37409@exchange2-1>
References: <129789545FD9CA4C8A495D5B9A92F37F6FF37409@exchange2-1>
Message-ID: <5453A5B5.7010205@gmail.com>

On 14-10-31 10:50 AM, Laura Riggi wrote:
> Hi
> 
> I used lme (from package nlme) to fit a model containing two fixed
> factors, one random factor and a variance function
> (weights=varIdent(form=~1|as.factor(year_collected)). This is my
> "best" model.
> 
> I would like to plot the confidence intervals for the predicted
> fitted values. Something similar to se.fit=True in predict.lm but for
> lme models containing random effects and variance function.
> 
> Does anybody knows how to do this with R ?
> 
> Thanks Laura
> 

   http://glmm.wikidot.com/faq#predconf has a recipe for doing this, as
does
http://stackoverflow.com/questions/14358811/extract-prediction-band-from-lme-fit
...

  Ben Bolker


From ukoether at uke.de  Fri Oct 31 19:42:57 2014
From: ukoether at uke.de (=?UTF-8?B?VWxmIEvDtnRoZXI=?=)
Date: Fri, 31 Oct 2014 19:42:57 +0100
Subject: [R-sig-ME] How to calculate the level-1 variance of a GLMM
 (Poisson or Additive Over-dispersed Poisson) model?
In-Reply-To: <CAPoG4sj_jbZfcLkTa3x5k0JygLu_agmPcaBU8j07ccL=dZTuZg@mail.gmail.com>
References: <CAPoG4sj_jbZfcLkTa3x5k0JygLu_agmPcaBU8j07ccL=dZTuZg@mail.gmail.com>
Message-ID: <5453D831.3050103@uke.de>

Dear Graham,

to provide some hints regarding your problem (as I also asked something
like that some weeks ago), here is the mailing list thread where my
question was answered:

https://mailman.stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022540.html

In general, you have to replace the "residual variance" of the binomial
distribution (pi^2/3) with that of the poisson distribution (ignoring
any overdispersion):

ln(1/ exp(?0) + 1)

where ?0 is the intercept on the link scale. (If I am wrong here, could
someone correct me, please?). Regarding the use of an observation-level
random intercept, this procedure should work accordingly (with one
additional variance term).

For the negative binomial, it seems a bit more tricky, and as a short
tip, I can only point you to this article:

http://www.springerplus.com/content/pdf/2193-1801-3-40.pdf

Because the variance of the negbin is not equal to the mean as in the
poisson, I would guess (I mean, really GUESS!!!), that ?0 from above
should be replaced by something like

?0 + alpha * ?0^2

where alpha = 1 / theta (which is the negbin-dispersion parameter as
given by glmer.nb or glm.nb for example, or glmmABMD, but I am not sure
for the latter...).

But bear in mind, that all this on the negbin is purely coming from a
non-statistician, and you should ask someone who acutally *knows* the
answer... ;-)

For the question on years: I do not know if there is a better
possibility than fitting several models (for each year of interest), but
you need enough data for this... using year as a random slope and
putting all data in one model to derive the icc will be more complicated
than fitting 3 or 4 models each without the random slope....I think...


Good luck.


Am 31.10.2014 um 11:27 schrieb Graham B. McNamara:
> Dear all,
>
> I'm estimating a three-level GLMM model of Students nested in Classes
> nested Schools: a random-intercept model with just one predictor
> variable (no random slopes). The dependent variable is a count
> variable, but has a much higher variance than its mean, indicating I
> probably need to be thinking of an overdispersed Poisson /
> Negative-binomial.
>
> I am interested in the proportion of variance found on each level:
> decomposing the total variance. In linear models, the variance of all
> random effects is presented int he summary() statement. But for GLMM
> models, this is not the case: only the Class and School level variance
> are reported. I understand the reason for this, and I have also read
> (and learned a lot from) the caveats on http://glmm.wikidot.com/faq.
>
> However, there are also papers describing several methods to retrieve
> the Level-1 (student) level variance anyway:
> http://www.bristol.ac.uk/cmm/software/support/support-faqs/pval.html/#macros
> deals with two-level binomial models and
> http://onlinelibrary.wiley.com/doi/10.1111/j.1467-985X.2004.00365.x/abstract
> deals with over-dispersed binomial models.
>
> Is there such a method available for Poisson, Over-dispersed Poisson,
> or Negative Binomial models? A piece of code, somewhere, perhaps?
>
>
> To explain my models:
>
>   # poisson
>   fit.glmer <- glmer(y ~ x1 + (1 | class) + (1 | school), data =
> mydata, verbose = TRUE, family = poisson)
>
> I also created an additive overdispered poisson-lognormal model by
> adding a per-observation (Student-level) random effect (as per Ben
> Bolker's code found on
> http://blogs.umass.edu/nrc697sa-finnj/2012/11/08/bolkers-reanalysis-of-owl-data/):
>
>   # poisson-lognormal
>   fit.glmer.1 <- glmer(y ~ x1 + (1 | class) + (1 | school) + (1 |
> over), data = mydata, verbose = TRUE, family = poisson)
>
> And fit.glmer.1 seems to have much better fit than fit.glmer.
>
>
> FYI, I'm *actually* interested in how the variance proportion across
> levels change over time. For example, in 2010 most of the outcome
> variance may be found on the Student-level: say 70% of the variance is
> found on the Student level, 20% on the Class level, and 10% on the
> School level. In 2011, with the same students, 50% of the variance is
> found on the Student level, 40% on the class level, and 10% on the
> School level. Thus, the between-student variance has decreased from
> 70% to 50% from 2010 to 2011. This is what I'm actually trying to
> figure out for my data.
> (At the moment I'm stuck with doing log-transformed lmer models per
> year, because that's the only way I know to get at least *some* idea
> about the level-1 variance... Any help is appreciated.)
>
> Thanks a bunch,
>
> Graham
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 

--

DANKE F?R 125 JAHRE ENGAGEMENT UND VERTRAUEN.
www.uke.de/125
_____________________________________________________________________

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From geralttee at gmail.com  Sat Nov  1 21:12:33 2014
From: geralttee at gmail.com (Szymek Drobniak)
Date: Sat, 1 Nov 2014 21:12:33 +0100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 94, Issue 38
In-Reply-To: <mailman.4924.1414749514.15062.r-sig-mixed-models@r-project.org>
References: <mailman.4924.1414749514.15062.r-sig-mixed-models@r-project.org>
Message-ID: <CANXb-o5Uaw8C2Ou3WJy-YteWy-dn=DMGsGYTfOBJOpLdUXZccw@mail.gmail.com>

Hi Eoin,

putting PI on the left site of "|" (e.g. 1|PI:...) does not allow for
correlation between parasite levels. I would test several versions with
both sex and parasite as generating heterogenuous (co)variance structure so
e.g. (Sex+PI-1|block:line), (Sex:PI-1|block:line). Also - although both
allow for non-zero covariances between sexes/parasites/sex:parasite
combinations, they do not allow for testing a likely hypothesis that these
correlations are different from unity. This could be done e.g. in asreml
using the corh() structure.

Cheers
Szymek



> Message: 2
> Date: Thu, 30 Oct 2014 16:54:55 +0100
> From: Eoin Duffy <eoinduffy0000 at googlemail.com>
> To: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> Cc: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Follow up question testing three way interaction
>         between two fixed effects and a random effect nested in a fixed
> Message-ID:
>         <
> CAPeV8wV6JqmvPQi53J_VwhUz3w-2EZ2Zj91ECx9JwGfAkwWM5w at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear Thierry
>
> Thank you very much for your insightful reply. I was a bit unsure about
> specifying Block as a random effect so thanks for further clarifying that
> for me.
>
> I have a follow up question about a similar, separate analysis if yourself
> or the mailing list have time to think about. I need to include an
> additional fixed factor (2 levels) which block (3 levels) is nested in
> which then has line (35 levels) nested in it.
>
> So the background is. I am measuring male and female fitness in Drosophila
> (n=10/sex)  from 35 lines over three blocks (same line ID  during each
> block), all this was performed twice using different 'tester' flies from
> two different populations that were or were not infected with a parasite
> (i.e.parasite infection +/-: PI) in order to examine whether parasite
> infection deferentially affected intersexual fitness across lines.
>
> So I'm primarily interested in the three way interaction between sex x line
> x parasite infection (PI), 'does intersexual fitness differ between lines
> if their fitness was measured using flies that were or were not infected
> with the parasite?'
>
> My model looks like this, modifying from Thierry's suggested code below
> with PI (2 levels), Block (3 levels), Sex as fixed factors and line as a
> random factor nested within Block, nested with PI, which I think is right.
>
> M1<-lmer(Fitness~Sex+Block+PI+(0+Sex|PI:Block:Line), noNAdata)
> M2<-lmer(Fitness~Sex+Block+PI+(1+PI:Block:Line), noNAdata)
> anova(M1,M2)
>
> Which produces the below output
>
> > anova(M1, M2)
> refitting model(s) with ML (instead of REML)
> Data: newdataWol
> Models:
> ..1: Fitness ~ Sex + Block + WolInfection + (1 | WolInfection:Block:Line)
> object: Fitness ~ Sex + Block + WolInfection + (0 + Sex |
> WolInfection:Block:Line)
>        Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> ..1     6 11051 11089 -5519.6    11039
> object  8 10986 11037 -5485.1    10970 69.012      2  1.033e-15 ***
>
> My question is does it seem as through I have specified my models correctly
> in order to check the significance of the 3 way sex x line x parasite
> infection
> interaction?
>
> Any suggestions would be greatly appreciated.
>
> Eoin
>
>
>
> On Thu, Oct 30, 2014 at 10:10 AM, ONKELINX, Thierry <
> Thierry.ONKELINX at inbo.be> wrote:
>
> > Dear Eoin,
> >
> > Much depends on how you code Line. If Each line has a unique code, thus
> > each line ID occurs in only one block, then (1|Sex:Block:Line) is equal
> to
> > (1|Sex:Line). If you have a crossed design and you reuse line ID among
> > block (a line ID can occur in more than one block), then
> (1|Sex:Block:Line)
> > is different from (1|Sex:Line). (1|Sex:Block:Line) is the most explicit
> way
> > to write it and it does not depends on the coding of line ID.
> >
> > A few more things:
> > - Although block is random from a philosophical standpoint, it is better
> > to use it as a fixed effect because it has only 3 levels. More details on
> > http://glmm.wikidot.com/faq
> > - I'd rather look at (0 + Sex|Line) than (1|Line:Sex). (0 + Sex|Line)
> > allows for a different variance in line effect between male and female,
> and
> > a correlation between male and female within the line
> >
> > M1 <- lmer(FitnessCured ~ Sex + Block + (0 + Sex|Block:Line), noNAdata)
> > M2 <- lmer(FitnessCured ~ Sex + Block + (1|Block:Line), noNAdata)
> > anova(M1, M2)
> >
> > Best regards,
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> > + 32 2 525 02 51
> > + 32 54 43 61 85
> > Thierry.Onkelinx at inbo.be
> > www.inbo.be
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of.
> > ~ Sir Ronald Aylmer Fisher
> >
> > The plural of anecdote is not data.
> > ~ Roger Brinner
> >
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > -----Oorspronkelijk bericht-----
> > Van: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-bounces at r-project.org] Namens Eoin Duffy
> > Verzonden: dinsdag 28 oktober 2014 22:14
> > Aan: r-sig-mixed-models at r-project.org
> > Onderwerp: [R-sig-ME] Testing interaction between fixed effect and random
> > effect nested within another random effect
> >
> > Hello mixed model list
> >
> >
> > I am working on a mixed model using lmer in R and I am a bit stuck on
> some
> > coding. I have measured male and female fitness in Drosophila from 35
> > inbred lines (genotype) over three blocks.
> >
> > My response variable is 'fitness' with n=10 individuals/sex/line/block
> > tested.
> >
> > Sex is fixed, Block is random and Line nested within block is random. I
> > primarily interested in the interaction between sex and line. Therefore
> my
> > model looks like
> >
> > m1<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Line),noNAdata)
> >
> > If I wanted to tested the significance of the Sex:Line interaction my
> plan
> > is to just compare the above model to a model without the interaction and
> > use anova to compare the two models
> >
> > e.g. m2<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block),noNAdata)
> > anova(m1,m2)
> >
> > However what I am wondering is if I am testing the significance of the
> > Sex:Line interaction (included as a random effect) will R know Line is
> > nested within Block ???
> >
> > How do I specify the interaction between Sex by Line nested within Block
> ??
> >
> > Should it be something like
> >
> >  m1T<-lmer(FitnessCured~Sex+(1|Block/Line)+(1|Block)+(1|Sex:Block:Line)
> >
> > Any thoughts would be appreciated. I have included a sample of my data
> > below
> >
> >      Block Line Sex FitnessInfected FitnessCured2        1    2   M
> >       1.4573       0.22153        1    2   M          1.1551
> > 1.13794        1    2   M          1.4573       1.13797        1    2
> >  M          1.4573       0.41089        1    2   M         -1.5648
> >   1.137911       1    2   F         -0.2669      -1.247312       1
> > 2   F          0.2785      -1.247313       1    2   F         -0.5396
> >     -1.247314       1    2   F         -0.5396       0.460215       1
> >   2   F          1.8237      -1.247316       1    2   F
> > 0.7330       0.496517       1    2   F          1.5511      -1.247318
> >      1    2   F         -0.5396       1.477419       1    2   F
> >   1.0966       1.186820       1    2   F         -0.5396
> > -1.247321       1    3   M          1.2054       0.716222       1    3
> >   M          1.2585       0.314624       1    3   M         -1.5648
> >    0.267226       1    3   M         -0.8932      -0.861527       1
> > 3   M          0.5047       1.137928       1    3   M          0.7704
> >      1.137929       1    3   M         -1.5648      -1.768931       1
> >   3   F         -0.5396       0.678232       1    3   F
> > -0.5396      -1.247333       1    3   F         -0.5396       1.077834
> >       1    3   F         -0.5396      -1.247335       1    3   F
> >   -0.5396      -1.247336       1    3   F         -0.5396
> > 0.714537       1    3   F         -0.5396       0.7508
> >
> > --
> > Eoin Duffy
> >
> > PhD Researcher
> > Institute of Environmental Sciences
> > Jagiellonian University
> > Gronostajowa 7
> > 30-387, Krakow
> > Poland
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> > Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> > weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> > bevestigd is door een geldig ondertekend document.
> > The views expressed in this message and any annex are purely those of the
> > writer and may not be regarded as stating an official position of INBO,
> as
> > long as the message is not confirmed by a duly signed document.
> >
>
>
>
> --
> Eoin Duffy
>
> PhD Researcher
> Institute of Environmental Sciences
> Jagiellonian University
> Gronostajowa 7
> 30-387, Krakow
> Poland
>
>         [[alternative HTML version deleted]]
>
>
> --

*^^^~~~~~~
szdrobniak.pl
www.eko.uj.edu.pl/drobniak

	[[alternative HTML version deleted]]


From jonas at cnru.dk  Sun Nov  2 13:28:53 2014
From: jonas at cnru.dk (=?UTF-8?Q?Jonas_Lindel=C3=B8v?=)
Date: Sun, 2 Nov 2014 13:28:53 +0100
Subject: [R-sig-ME] predict.MCMCglmm() does not use random effects?
Message-ID: <CALxiaDRe9H72pDGVrSgT7MWtWmxf35k31-Yj2R7rU51OS7xgDw@mail.gmail.com>

Hi all

I have behavioral data from a classical time (2 levels,
within-subject) x treatment (2 level between-subject) trial on human
subjects. A simple LME model with a random intercept per subject is

fit.lm = lmer(wi ~ session * treatment + (1 | id), data)
plot(na.omit(data$wi), predict(fit.lm))

This produces a nice almost-diagonal plot - the predictions fit the
data. However, fitting the same with MCCMglmm seem to ignore the
random part, just predicting from the 4 possible fixed effect
combinations. Is there a way include random effects in the prediction?
I can see that the random part does increase model fit (DIC=656.7467
vs. DIC 836.5622 without random=~id), so is it specific to the way
that predict.MCMCglmm() works? I did:

fit.mc = MCMCglmm(wi ~ treat * session, random= ~ id, data=data)
plot(data$wi, predict(fit.mc))

Background info: My primary motivation for using MCMCglmm instead of
lmer is that I have missing values on some outcome of the multiple
outcome measures per subject. Conditioning on observed outcome
measures should narrow the posterior over the missing values resulting
in less bias in the fixed effect estimates than removing incomplete
cases. So the model will be extended to be multivariate later.

Best,
Jonas


From j.hadfield at ed.ac.uk  Sun Nov  2 14:04:50 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 02 Nov 2014 13:04:50 +0000
Subject: [R-sig-ME] predict.MCMCglmm() does not use random effects?
In-Reply-To: <CALxiaDRe9H72pDGVrSgT7MWtWmxf35k31-Yj2R7rU51OS7xgDw@mail.gmail.com>
References: <CALxiaDRe9H72pDGVrSgT7MWtWmxf35k31-Yj2R7rU51OS7xgDw@mail.gmail.com>
Message-ID: <20141102130450.59285molgrrcysg0@www.staffmail.ed.ac.uk>

Hi Jonas,

predict(fit.mc, marginal=NULL)

Jarrod



Quoting Jonas Lindel?v <jonas at cnru.dk> on Sun, 2 Nov 2014 13:28:53 +0100:

> Hi all
>
> I have behavioral data from a classical time (2 levels,
> within-subject) x treatment (2 level between-subject) trial on human
> subjects. A simple LME model with a random intercept per subject is
>
> fit.lm = lmer(wi ~ session * treatment + (1 | id), data)
> plot(na.omit(data$wi), predict(fit.lm))
>
> This produces a nice almost-diagonal plot - the predictions fit the
> data. However, fitting the same with MCCMglmm seem to ignore the
> random part, just predicting from the 4 possible fixed effect
> combinations. Is there a way include random effects in the prediction?
> I can see that the random part does increase model fit (DIC=656.7467
> vs. DIC 836.5622 without random=~id), so is it specific to the way
> that predict.MCMCglmm() works? I did:
>
> fit.mc = MCMCglmm(wi ~ treat * session, random= ~ id, data=data)
> plot(data$wi, predict(fit.mc))
>
> Background info: My primary motivation for using MCMCglmm instead of
> lmer is that I have missing values on some outcome of the multiple
> outcome measures per subject. Conditioning on observed outcome
> measures should narrow the posterior over the missing values resulting
> in less bias in the fixed effect estimates than removing incomplete
> cases. So the model will be extended to be multivariate later.
>
> Best,
> Jonas
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From atarca at med.wayne.edu  Sun Nov  2 18:00:18 2014
From: atarca at med.wayne.edu (Tarca, Adi)
Date: Sun, 2 Nov 2014 17:00:18 +0000
Subject: [R-sig-ME] subject level predictions with lme4 from incomplete
 longitudinal profile
Message-ID: <6DE578F501A8B2489DBD4893CEC996BA1EFA57CC@MED-CORE07B.med.wayne.edu>

Dear all,

I am interested in using lme4 to make subject level predictions from longitudinal data. I have 7 longitudinal observations for over 100 subjects to fit the model (Call it z1), and the goal would be to use info from the first 2 observations of a new subject to make predictions for the remaining 5 time points. One way seems to be to add the first 2 time points of the new subject to the dataset of the other subjects with full longitudinal sets and refit the model to get the required random coefficients for the new subject in order to make predictions. My question is whether refitting the model could be avoided and use info from fitted model z1 as well as the design matrix and response values for the first 2 time points of the new subject to compute its random coefficients so that subject level predictions can be obtained.




See below an illustration using a subset of the entire dataset:



> #get file http://bioinformaticsprb.med.wayne.edu/shares/uspar.zip and unzip it
> load("uspar.RData")
> str(dat)
'data.frame':  94 obs. of  5 variables:
$ ID: int  1 1 1 1 1 1 1 2 2 2 ...
$ t : num  12.6 15.2 18.5 21.7 25.7 ...
$ X : num  2.53 2.72 2.92 3.08 3.25 ...
$ X2: num  31.8 41.2 53.8 66.6 83.3 ...
$ Y : num  2.67 2.88 3.06 3.23 3.38 ...
> head(dat)
  ID        t        X       X2        Y
1  1 12.56409 2.530843 31.79774 2.674149
2  1 15.16409 2.718930 41.23011 2.884801
3  1 18.46409 2.915828 53.83811 3.063391
4  1 21.66409 3.075656 66.63130 3.226844
5  1 25.66409 3.245093 83.28236 3.380995
6  1 28.56409 3.352150 95.75113 3.462606
>
> library(lme4)
> library(lattice)
> print(xyplot(Y ~ t | ID, dat, aspect = "xy",
+              layout = c(4,4), type = c("g", "p", "r"),
+              xlab = "t",
+              ylab = "Y"))
>
> #so straight lines are not good enough, therefore will try some transformations of the time t
> dat$X=log(dat$t)
> dat$X2=dat$t*log(dat$t)
>
> #fit a mixed model without subject 14
> z1=lmer(Y~X+X2+(1+X|ID),data=dat[1:87,])
> coef(z1)
$ID
   (Intercept)        X           X2
1  -0.53171325 1.326889 -0.004786795
2  -0.47307768 1.298678 -0.004786795
3  -0.94360603 1.426778 -0.004786795
4  -0.96673528 1.419102 -0.004786795
5  -0.17684352 1.223741 -0.004786795
6  -0.25485719 1.244443 -0.004786795
7  -0.43006443 1.292671 -0.004786795
8  -0.16374444 1.236175 -0.004786795
9  -0.56353815 1.327487 -0.004786795
10 -0.03938627 1.199694 -0.004786795
11 -0.88569466 1.420670 -0.004786795
12 -0.98283470 1.428146 -0.004786795
13 -0.17773363 1.214458 -0.004786795

attr(,"class")
[1] "coef.mer"
>
> #Question:
> #Say I only had the first 2 time points for subject 14 and wanted to make
> #subject level predictions for it for all time points.
> #One way seems to be to fit a new model z2 with by including the first 2 points
> # of this subject.
>
> z2=lmer(Y~X+X2+(1+X|ID),data=dat[1:89,])
> coef(z2)
$ID
   (Intercept)        X           X2
1  -0.52677880 1.324643 -0.004759445
2  -0.46715932 1.296103 -0.004759445
3  -0.93644456 1.423830 -0.004759445
4  -0.95853280 1.415826 -0.004759445
5  -0.17203704 1.221526 -0.004759445
6  -0.24932519 1.241990 -0.004759445
7  -0.42432616 1.290164 -0.004759445
8  -0.15979241 1.234259 -0.004759445
9  -0.55790691 1.325007 -0.004759445
10 -0.03503148 1.197623 -0.004759445
11 -0.87957274 1.418050 -0.004759445
12 -0.97501533 1.424990 -0.004759445
13 -0.17154433 1.211794 -0.004759445
14 -0.65875042 1.348014 -0.004759445

attr(,"class")
[1] "coef.mer"
>
> dat$Ypred=predict(z2,dat)
> print(xyplot(Ypred ~ Y | ID, dat, aspect = "xy",
+              layout = c(4,4), type = c("g", "p", "r"),
+              xlab = "Y",
+              ylab = "Ypred"))
>
> #Q1, Is there another way that would not require fitting model z2 but simply use
> # info form z1 and
> dat[88:89,c("X","X2","Y")]
          X       X2        Y
88 2.706981 40.56130 2.803360
89 2.843977 48.87079 2.933857






Thanks,
Adi Tarca


________________________________

This document may include proprietary and confidential information. This document may not be reproduced, copied, distributed, published, modified or furnished to third parties, without prior written consent. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. If you are not the intended recipient you are notified that disclosing, copying, distributing or taking any action in reliance on the contents of this information is strictly prohibited.

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Nov  3 15:22:41 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Nov 2014 14:22:41 +0000
Subject: [R-sig-ME] Ordinal categorical variable as a random effect in
 MCMCglmm
In-Reply-To: <CAErHMT2nucT4G1C_YkKOtBoKhP1GLNVCJL5gt8pxYU35z4JfXQ@mail.gmail.com>
References: <CAErHMT2nucT4G1C_YkKOtBoKhP1GLNVCJL5gt8pxYU35z4JfXQ@mail.gmail.com>
Message-ID: <20141103142241.19366rcwvz03oqkg@www.staffmail.ed.ac.uk>

Dear Manabu,

Could you explain what Quality is? If it is ordered it is hard to see  
why you would be fitting it as random effect? Is this really your  
response variable?

Cheers,

Jarrod



Quoting Manabu Sakamoto <manabu.sakamoto at gmail.com> on Wed, 29 Oct  
2014 11:16:48 +0000:

> Dear list,
>
> I'm using MCMCglmm with some random effects, including a phylogeny and a
> categorical variable, scored along an ordinal scale, e.g., 1 < 2 < 3 <...
>
> If my phylogenetic tip names are stored as a character string Taxon (and
> there is an associated inverse A object), and my quality codes are stored
> as an ordered factor variable Quality, then my questions are:
>
> 1) Can I specify the random effect formula simply as: random= ~ Taxon +
> Quality --- i.e., without functions like us() or idh() around Quality?
> 2) What sort of prior should I assign for Quality? --- For the moment I am
> using:
>
> list(V=1, nu=1, alpha.mu = 0, alpha.V = 25^2)
>
>
> I'd appreciate any advise.
>
> Kind regards.
> Manabu
> --
> Manabu Sakamoto, PhD
> manabu.sakamoto at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From manabu.sakamoto at gmail.com  Mon Nov  3 15:35:40 2014
From: manabu.sakamoto at gmail.com (Manabu Sakamoto)
Date: Mon, 3 Nov 2014 14:35:40 +0000
Subject: [R-sig-ME] Ordinal categorical variable as a random effect in
	MCMCglmm
In-Reply-To: <20141103142241.19366rcwvz03oqkg@www.staffmail.ed.ac.uk>
References: <CAErHMT2nucT4G1C_YkKOtBoKhP1GLNVCJL5gt8pxYU35z4JfXQ@mail.gmail.com>
	<20141103142241.19366rcwvz03oqkg@www.staffmail.ed.ac.uk>
Message-ID: <CAErHMT1D_SNkS9-Vy2veUbzEXU-RLKDSHozthoAL0tQv+TeQmw@mail.gmail.com>

Dear Jarrod,

Thanks for your response. Quality is a ranking in the
completeness/missingness of the data; a higher quality data point is scored
higher. This is an attempt to control for potential missing information
from the response variable. The response is a count (hence the family being
Poisson), and the idea is that for each taxon on a phylogeny, there is a
count variable, but that count could potentially be under-estimated based
on the Quality of the data associated with each taxon. But in reality, this
potential under-estimation is unknown and unmeasurable so Quality is just
one attempt to control for this somewhat-known uncertainty.

many thanks,
Manabu

On 3 November 2014 14:22, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Dear Manabu,
>
> Could you explain what Quality is? If it is ordered it is hard to see why
> you would be fitting it as random effect? Is this really your response
> variable?
>
> Cheers,
>
> Jarrod
>
>
>
>
> Quoting Manabu Sakamoto <manabu.sakamoto at gmail.com> on Wed, 29 Oct 2014
> 11:16:48 +0000:
>
>  Dear list,
>>
>> I'm using MCMCglmm with some random effects, including a phylogeny and a
>> categorical variable, scored along an ordinal scale, e.g., 1 < 2 < 3 <...
>>
>> If my phylogenetic tip names are stored as a character string Taxon (and
>> there is an associated inverse A object), and my quality codes are stored
>> as an ordered factor variable Quality, then my questions are:
>>
>> 1) Can I specify the random effect formula simply as: random= ~ Taxon +
>> Quality --- i.e., without functions like us() or idh() around Quality?
>> 2) What sort of prior should I assign for Quality? --- For the moment I am
>> using:
>>
>> list(V=1, nu=1, alpha.mu = 0, alpha.V = 25^2)
>>
>>
>> I'd appreciate any advise.
>>
>> Kind regards.
>> Manabu
>> --
>> Manabu Sakamoto, PhD
>> manabu.sakamoto at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
Manabu Sakamoto, PhD
manabu.sakamoto at gmail.com

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Nov  3 20:49:27 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Nov 2014 19:49:27 +0000
Subject: [R-sig-ME] Ordinal categorical variable as a random effect in
 MCMCglmm
In-Reply-To: <CAErHMT1D_SNkS9-Vy2veUbzEXU-RLKDSHozthoAL0tQv+TeQmw@mail.gmail.com>
References: <CAErHMT2nucT4G1C_YkKOtBoKhP1GLNVCJL5gt8pxYU35z4JfXQ@mail.gmail.com>
	<20141103142241.19366rcwvz03oqkg@www.staffmail.ed.ac.uk>
	<CAErHMT1D_SNkS9-Vy2veUbzEXU-RLKDSHozthoAL0tQv+TeQmw@mail.gmail.com>
Message-ID: <20141103194927.14401j7qprcwfvb4@www.staffmail.ed.ac.uk>

Dear Manabu,


I suggest

prior<-list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=1, alpha.mu  
= 0, alpha.V = 25^2)))

m1<-MCMCglmm(counts~Quality, random=~Taxon, ginverse=list(Taxon=Ainv),  
family="poisson", prior=prior, ....)

as a first stab.  MCMCglmm can't handle ordered predictors, so you  
could try just fitting Quality as a standard factor, or fitting it as  
continuous?

Cheers,

Jarrod


Quoting Manabu Sakamoto <manabu.sakamoto at gmail.com> on Mon, 3 Nov 2014  
14:35:40 +0000:

> Dear Jarrod,
>
> Thanks for your response. Quality is a ranking in the
> completeness/missingness of the data; a higher quality data point is scored
> higher. This is an attempt to control for potential missing information
> from the response variable. The response is a count (hence the family being
> Poisson), and the idea is that for each taxon on a phylogeny, there is a
> count variable, but that count could potentially be under-estimated based
> on the Quality of the data associated with each taxon. But in reality, this
> potential under-estimation is unknown and unmeasurable so Quality is just
> one attempt to control for this somewhat-known uncertainty.
>
> many thanks,
> Manabu
>
> On 3 November 2014 14:22, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Dear Manabu,
>>
>> Could you explain what Quality is? If it is ordered it is hard to see why
>> you would be fitting it as random effect? Is this really your response
>> variable?
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Manabu Sakamoto <manabu.sakamoto at gmail.com> on Wed, 29 Oct 2014
>> 11:16:48 +0000:
>>
>>  Dear list,
>>>
>>> I'm using MCMCglmm with some random effects, including a phylogeny and a
>>> categorical variable, scored along an ordinal scale, e.g., 1 < 2 < 3 <...
>>>
>>> If my phylogenetic tip names are stored as a character string Taxon (and
>>> there is an associated inverse A object), and my quality codes are stored
>>> as an ordered factor variable Quality, then my questions are:
>>>
>>> 1) Can I specify the random effect formula simply as: random= ~ Taxon +
>>> Quality --- i.e., without functions like us() or idh() around Quality?
>>> 2) What sort of prior should I assign for Quality? --- For the moment I am
>>> using:
>>>
>>> list(V=1, nu=1, alpha.mu = 0, alpha.V = 25^2)
>>>
>>>
>>> I'd appreciate any advise.
>>>
>>> Kind regards.
>>> Manabu
>>> --
>>> Manabu Sakamoto, PhD
>>> manabu.sakamoto at gmail.com
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> Manabu Sakamoto, PhD
> manabu.sakamoto at gmail.com
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Mon Nov  3 23:47:54 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 3 Nov 2014 22:47:54 +0000 (UTC)
Subject: [R-sig-ME] subject level predictions with lme4 from incomplete
	longitudinal profile
References: <6DE578F501A8B2489DBD4893CEC996BA1EFA57CC@MED-CORE07B.med.wayne.edu>
Message-ID: <loom.20141103T233559-431@post.gmane.org>

Tarca, Adi <atarca at ...> writes:

> 
> Dear all,
 
> I am interested in using lme4 to make subject level predictions from
> longitudinal data. I have 7 longitudinal observations for over 100
> subjects to fit the model (Call it z1), and the goal would be to use
> info from the first 2 observations of a new subject to make
> predictions for the remaining 5 time points. One way seems to be to
> add the first 2 time points of the new subject to the dataset of the
> other subjects with full longitudinal sets and refit the model to
> get the required random coefficients for the new subject in order to
> make predictions. My question is whether refitting the model could
> be avoided and use info from fitted model z1 as well as the design
> matrix and response values for the first 2 time points of the new
> subject to compute its random coefficients so that subject leve l
> predictions can be obtained.

  This is an interesting (= not completely easy!) question.

  In theory, you should be able to work out the conditional mode
of a new value, conditional on the estimated random effects variance-cov.
matrix for the model.

  For a scalar random effect (e.g. an intercept-only random effect),
this would just be a variance-weighted average, e.g. if you have
information from a new data set with mean xbar_i and variance v_i,
and the overall model mean is Xbar with an among-groups variance of
V, then your predicted value should be  

(xbar_i/v_i+Xbar/V)/(1/v_i+1/V)


Off the top of my head, I'm not sure how this would work for
a multivariate random effect (i.e., random-slopes model).  In
principle, even from two data points you can get an estimate
of the intercept and slope and their variance-covariance matrix
(although the variance-covariance matrix will be very poorly
estimated -- I'm not sure what to do about the fact that the
estimated of sigma-squared, RSS/(n-2), is NA ... do you just
use RSS/n instead??)

  Once (if??) you get this information for the new observations,
you have to figure out how to do the multivariate analogue of
the scalar variance-weighted average shown above.

   Further ideas welcome ...


> See below an illustration using a subset of the entire dataset:
> 
> #get file http://bioinformaticsprb.med.wayne.edu/shares/uspar.zip and unzip it
> > load("uspar.RData")

## snip

> >
> > library(lme4)
> > library(lattice)
> > print(xyplot(Y ~ t | ID, dat, aspect = "xy",
> +              layout = c(4,4), type = c("g", "p", "r"),
> +              xlab = "t",
> +              ylab = "Y"))
> >
> > #so straight lines are not good enough, therefore will try some
transformations of the time t
> > dat$X=log(dat$t)
> > dat$X2=dat$t*log(dat$t)
> >
> > #fit a mixed model without subject 14
> > z1=lmer(Y~X+X2+(1+X|ID),data=dat[1:87,])
> > coef(z1)

## snip

> > #Question:
> > #Say I only had the first 2 time points for subject 14 and wanted to make
> > #subject level predictions for it for all time points.
> > #One way seems to be to fit a new model z2 with by including the first 2
points
> > # of this subject.
> >
> > z2=lmer(Y~X+X2+(1+X|ID),data=dat[1:89,])
> > coef(z2)
> $ID
>    (Intercept)        X           X2
> 1  -0.52677880 1.324643 -0.004759445
> 2  -0.46715932 1.296103 -0.004759445
> 3  -0.93644456 1.423830 -0.004759445
> 4  -0.95853280 1.415826 -0.004759445
> 5  -0.17203704 1.221526 -0.004759445
> 6  -0.24932519 1.241990 -0.004759445
> 7  -0.42432616 1.290164 -0.004759445
> 8  -0.15979241 1.234259 -0.004759445
> 9  -0.55790691 1.325007 -0.004759445
> 10 -0.03503148 1.197623 -0.004759445
> 11 -0.87957274 1.418050 -0.004759445
> 12 -0.97501533 1.424990 -0.004759445
> 13 -0.17154433 1.211794 -0.004759445
> 14 -0.65875042 1.348014 -0.004759445
> 
> attr(,"class")
> [1] "coef.mer"
> >
> > dat$Ypred=predict(z2,dat)
> > print(xyplot(Ypred ~ Y | ID, dat, aspect = "xy",
> +              layout = c(4,4), type = c("g", "p", "r"),
> +              xlab = "Y",
> +              ylab = "Ypred"))
> >
> > #Q1, Is there another way that would not require fitting model z2 but
simply use
> > # info form z1 and
> > dat[88:89,c("X","X2","Y")]
>           X       X2        Y
> 88 2.706981 40.56130 2.803360
> 89 2.843977 48.87079 2.933857
> 
> Thanks,
> Adi Tarca
>


From daniela at uoregon.edu  Tue Nov  4 22:14:52 2014
From: daniela at uoregon.edu (Daniel Anderson)
Date: Tue, 4 Nov 2014 13:14:52 -0800
Subject: [R-sig-ME] DIC with multiple MCMCglmm chains
Message-ID: <69125811-C3F0-491D-81F2-68627FFFA073@uoregon.edu>

Hi all,

I have what I hope is a relatively straightforward question. I?m running a model with MCMCglmm in which I have multiple chains. I?m able to combine estimates across chains for all the values I?m interested in via mcmc.list, but am having a hard time figuring out how to combine DIC values. I can get a DIC value for each chain, but would prefer a single value across chains, similar to what jags reports. Is this possible? Below is a quick example of obtaining separate, rather than a combined DIC value across chains.

#####
library(MCMCglmm)
data(Traffic,package="MASS")
Traffic$year<-as.factor(Traffic$year)

prior<-list(R=list(V=1,nu=0.002))

set.seed(1)
m2a.5.1<-MCMCglmm(y ~ limit + year + day, family = "poisson",
				data = Traffic, prior = prior)
set.seed(2)
m2a.5.2<-MCMCglmm(y ~ limit + year + day, family = "poisson",
				data = Traffic, prior = prior)

m2a.5.1$DIC;m2a.5.2$DIC #Separate DIC values

Thanks,
--
Daniel Anderson
Research Assistant
Behavioral Research and Teaching
University of Oregon

From lucianolasala at yahoo.com.ar  Wed Nov  5 12:55:27 2014
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 05 Nov 2014 08:55:27 -0300
Subject: [R-sig-ME] Error message
In-Reply-To: <3027a659772447a49bf110b3f0e59f36@CO2PR04MB826.namprd04.prod.outlook.com>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>	<40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>
	<54481F76.8040802@yahoo.com.ar>
	<3027a659772447a49bf110b3f0e59f36@CO2PR04MB826.namprd04.prod.outlook.com>
Message-ID: <545A102F.3030407@yahoo.com.ar>

Thank you Dan,

According to the new version of lme4 I refited my model as follows:

model <- glmer(Death ~ Year + Sex + Egg Volume + Hatch Order + (1|Nest 
ID), family = binomial, data = Data)
summary(model)

However, the same error message keeps showing up:


Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate


Interestingly, if I reduce the model to contain only one main effect 
(whichever), say Hatch_Order, things look better:

model2 <- glmer(Death 2 ~ Hatch Order + (1|Nest_ID), family = binomial, 
data = Data) summary(model2)


Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
Family: binomial  ( logit )
Formula: Death_2 ~ Hatch_Order + (1 | Nest_ID)
    Data: surv.2

      AIC      BIC   logLik deviance df.resid
    118.5    131.8    -55.2    110.5      205

Scaled residuals:
     Min      1Q  Median      3Q     Max
-0.7390 -0.1714 -0.1682 -0.1506  3.7689

Random effects:
  Groups  Name        Variance Std.Dev.
  Nest_ID (Intercept) 1.586    1.259
Number of obs: 209, groups:  Nest ID, 115

Fixed effects:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)        -3.4824     1.1274  -3.089  0.00201 **
Hatch_OrderSecond  -0.1266     0.7576  -0.167  0.86729
Hatch_OrderThird    2.0486     0.7572   2.705  0.00682 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
             (Intr) Htc_OS
Htch_OrdrSc -0.111
Htch_OrdrTh -0.709  0.276


Any pointers please? Best. Luciano



El 10/22/2014 6:35 PM, Daniel Wright escribi?:
> The lme4 package has changed some. Details are inhttp://arxiv.org/pdf/1406.5823.pdf
>
> For your problem, the first thing to note is glmer is now used instead of lmer for generalized linear models.  Glancing at your model the other bits look like they should work.
>
> Dan
>
> Daniel B. Wright, Ph.D.
> Statistical Research Division
> 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
> (preferred method of communication is email, use cell if urgent)
> Office: 512.320.1827
> Cell: 786 342 4656
>
>
>
>
>
>
> This email message is intended only for the personal use of the recipient(s) named above. If you are not an intended recipient, you may not review, copy, or distribute this message. If you have received this communication in error, please notify the sender immediately by email and delete the original message.
>
>
>
> -----Original Message-----
> From:r-sig-mixed-models-bounces at r-project.org  [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
> Sent: Wednesday, October 22, 2014 4:20 PM
> Cc:r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Error message
>
> Hello,
>
> A few years back I used to fit GLMM (binomial response) using lmer function in lme4. Back then I had to specify the family of response variable  (dead /alive) as binomial. Now I have to refit those models using quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but things seem to have changed quite a bit.
>    
> My response variable is death (yes/no), and independent variables are Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching Order (ordered factor variable, namely first, second, third). I need to control autocorrelation among siblings, so I use "Nest ID" to fit random intercepts for different nests.
>
> My model is:
>
> model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1|Nest_ID), family = binomial, data = Data)
> summary(model.1)
>
> But I get the error and warning messages below:
>
> Error in eval(expr, envir, enclos) :
>     (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate In addition:Warning message:
> In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID),  :
>     calling lmer with 'family' is deprecated; please use glmer() instead
>
>    
> Question: how can I circumvent these two issues?
>
> Thanks in advance.
>
> Luciano
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org  mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Luciano F. La Sala
Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
C?tedra de Epidemiolog?a
Departamento de Biolog?a, Bioqu?mica y Farmacia
Universidad Nacional del Sur
San Juan 670
Bah?a Blanca (8000)
Argentina


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Nov  5 13:09:08 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 05 Nov 2014 07:09:08 -0500
Subject: [R-sig-ME] Error message
In-Reply-To: <545A102F.3030407@yahoo.com.ar>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>	<40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>	<54481F76.8040802@yahoo.com.ar>	<3027a659772447a49bf110b3f0e59f36@CO2PR04MB826.namprd04.prod.outlook.com>
	<545A102F.3030407@yahoo.com.ar>
Message-ID: <545A1364.6040407@gmail.com>

  I don't remember if I responded to this before or not, but this looks
interesting/annoying: could you send or post the data?  Just to confirm,
any single-fixed-effect model works?  How about two-effect combinations
(I know, that's a bit of a nuisance)?

On 14-11-05 06:55 AM, Luciano La Sala wrote:
> Thank you Dan,
> 
> According to the new version of lme4 I refited my model as follows:
> 
> model <- glmer(Death ~ Year + Sex + Egg Volume + Hatch Order + (1|Nest 
> ID), family = binomial, data = Data)
> summary(model)
> 
> However, the same error message keeps showing up:
> 
> 
> Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
> 
> 
> Interestingly, if I reduce the model to contain only one main effect 
> (whichever), say Hatch_Order, things look better:
> 
> model2 <- glmer(Death 2 ~ Hatch Order + (1|Nest_ID), family = binomial, 
> data = Data) summary(model2)
> 
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
> Family: binomial  ( logit )
> Formula: Death_2 ~ Hatch_Order + (1 | Nest_ID)
>     Data: surv.2
> 
>       AIC      BIC   logLik deviance df.resid
>     118.5    131.8    -55.2    110.5      205
> 
> Scaled residuals:
>      Min      1Q  Median      3Q     Max
> -0.7390 -0.1714 -0.1682 -0.1506  3.7689
> 
> Random effects:
>   Groups  Name        Variance Std.Dev.
>   Nest_ID (Intercept) 1.586    1.259
> Number of obs: 209, groups:  Nest ID, 115
> 
> Fixed effects:
>                    Estimate Std. Error z value Pr(>|z|)
> (Intercept)        -3.4824     1.1274  -3.089  0.00201 **
> Hatch_OrderSecond  -0.1266     0.7576  -0.167  0.86729
> Hatch_OrderThird    2.0486     0.7572   2.705  0.00682 **
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Correlation of Fixed Effects:
>              (Intr) Htc_OS
> Htch_OrdrSc -0.111
> Htch_OrdrTh -0.709  0.276
> 
> 
> Any pointers please? Best. Luciano
> 
> 
> 
> El 10/22/2014 6:35 PM, Daniel Wright escribi?:
>> The lme4 package has changed some. Details are inhttp://arxiv.org/pdf/1406.5823.pdf
>>
>> For your problem, the first thing to note is glmer is now used instead of lmer for generalized linear models.  Glancing at your model the other bits look like they should work.
>>
>> Dan
>>
>> Daniel B. Wright, Ph.D.
>> Statistical Research Division
>> 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
>> (preferred method of communication is email, use cell if urgent)
>> Office: 512.320.1827
>> Cell: 786 342 4656
>>
>>
>>
>>
>>
>>
>> This email message is intended only for the personal use of the recipient(s) named above. If you are not an intended recipient, you may not review, copy, or distribute this message. If you have received this communication in error, please notify the sender immediately by email and delete the original message.
>>
>>
>>
>> -----Original Message-----
>> From:r-sig-mixed-models-bounces at r-project.org  [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
>> Sent: Wednesday, October 22, 2014 4:20 PM
>> Cc:r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Error message
>>
>> Hello,
>>
>> A few years back I used to fit GLMM (binomial response) using lmer function in lme4. Back then I had to specify the family of response variable  (dead /alive) as binomial. Now I have to refit those models using quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but things seem to have changed quite a bit.
>>    
>> My response variable is death (yes/no), and independent variables are Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching Order (ordered factor variable, namely first, second, third). I need to control autocorrelation among siblings, so I use "Nest ID" to fit random intercepts for different nests.
>>
>> My model is:
>>
>> model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1|Nest_ID), family = binomial, data = Data)
>> summary(model.1)
>>
>> But I get the error and warning messages below:
>>
>> Error in eval(expr, envir, enclos) :
>>     (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate In addition:Warning message:
>> In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID),  :
>>     calling lmer with 'family' is deprecated; please use glmer() instead
>>
>>    
>> Question: how can I circumvent these two issues?
>>
>> Thanks in advance.
>>
>> Luciano
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From atarca at med.wayne.edu  Wed Nov  5 15:09:30 2014
From: atarca at med.wayne.edu (Tarca, Adi)
Date: Wed, 5 Nov 2014 14:09:30 +0000
Subject: [R-sig-ME] subject level predictions with lme4 from
	incomplete	longitudinal profile
In-Reply-To: <loom.20141103T233559-431@post.gmane.org>
References: <6DE578F501A8B2489DBD4893CEC996BA1EFA57CC@MED-CORE07B.med.wayne.edu>
	<loom.20141103T233559-431@post.gmane.org>
Message-ID: <6DE578F501A8B2489DBD4893CEC996BA1EFA686A@MED-CORE07B.med.wayne.edu>

Dear Ben,
Thank you for the kind response. I realized it might not be easy, but does the data balance simplify things in any way. That is if all subjects used to fit model z1 would have the same number of observations taken for the exact same values of the predictors?
Regards,
Adi 


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Monday, November 03, 2014 5:48 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] subject level predictions with lme4 from incomplete longitudinal profile

Tarca, Adi <atarca at ...> writes:

> 
> Dear all,
 
> I am interested in using lme4 to make subject level predictions from 
> longitudinal data. I have 7 longitudinal observations for over 100 
> subjects to fit the model (Call it z1), and the goal would be to use 
> info from the first 2 observations of a new subject to make 
> predictions for the remaining 5 time points. One way seems to be to 
> add the first 2 time points of the new subject to the dataset of the 
> other subjects with full longitudinal sets and refit the model to get 
> the required random coefficients for the new subject in order to make 
> predictions. My question is whether refitting the model could be 
> avoided and use info from fitted model z1 as well as the design matrix 
> and response values for the first 2 time points of the new subject to 
> compute its random coefficients so that subject leve l predictions can 
> be obtained.

  This is an interesting (= not completely easy!) question.

  In theory, you should be able to work out the conditional mode of a new value, conditional on the estimated random effects variance-cov.
matrix for the model.

  For a scalar random effect (e.g. an intercept-only random effect), this would just be a variance-weighted average, e.g. if you have information from a new data set with mean xbar_i and variance v_i, and the overall model mean is Xbar with an among-groups variance of V, then your predicted value should be  

(xbar_i/v_i+Xbar/V)/(1/v_i+1/V)


Off the top of my head, I'm not sure how this would work for a multivariate random effect (i.e., random-slopes model).  In principle, even from two data points you can get an estimate of the intercept and slope and their variance-covariance matrix (although the variance-covariance matrix will be very poorly estimated -- I'm not sure what to do about the fact that the estimated of sigma-squared, RSS/(n-2), is NA ... do you just use RSS/n instead??)

  Once (if??) you get this information for the new observations, you have to figure out how to do the multivariate analogue of the scalar variance-weighted average shown above.

   Further ideas welcome ...


> See below an illustration using a subset of the entire dataset:
> 
> #get file http://bioinformaticsprb.med.wayne.edu/shares/uspar.zip and 
> unzip it
> > load("uspar.RData")

## snip

> >
> > library(lme4)
> > library(lattice)
> > print(xyplot(Y ~ t | ID, dat, aspect = "xy",
> +              layout = c(4,4), type = c("g", "p", "r"),
> +              xlab = "t",
> +              ylab = "Y"))
> >
> > #so straight lines are not good enough, therefore will try some
transformations of the time t
> > dat$X=log(dat$t)
> > dat$X2=dat$t*log(dat$t)
> >
> > #fit a mixed model without subject 14
> > z1=lmer(Y~X+X2+(1+X|ID),data=dat[1:87,])
> > coef(z1)

## snip

> > #Question:
> > #Say I only had the first 2 time points for subject 14 and wanted to 
> > make #subject level predictions for it for all time points.
> > #One way seems to be to fit a new model z2 with by including the 
> > first 2
points
> > # of this subject.
> >
> > z2=lmer(Y~X+X2+(1+X|ID),data=dat[1:89,])
> > coef(z2)
> $ID
>    (Intercept)        X           X2
> 1  -0.52677880 1.324643 -0.004759445
> 2  -0.46715932 1.296103 -0.004759445
> 3  -0.93644456 1.423830 -0.004759445
> 4  -0.95853280 1.415826 -0.004759445
> 5  -0.17203704 1.221526 -0.004759445
> 6  -0.24932519 1.241990 -0.004759445
> 7  -0.42432616 1.290164 -0.004759445
> 8  -0.15979241 1.234259 -0.004759445
> 9  -0.55790691 1.325007 -0.004759445
> 10 -0.03503148 1.197623 -0.004759445
> 11 -0.87957274 1.418050 -0.004759445
> 12 -0.97501533 1.424990 -0.004759445
> 13 -0.17154433 1.211794 -0.004759445
> 14 -0.65875042 1.348014 -0.004759445
> 
> attr(,"class")
> [1] "coef.mer"
> >
> > dat$Ypred=predict(z2,dat)
> > print(xyplot(Ypred ~ Y | ID, dat, aspect = "xy",
> +              layout = c(4,4), type = c("g", "p", "r"),
> +              xlab = "Y",
> +              ylab = "Ypred"))
> >
> > #Q1, Is there another way that would not require fitting model z2 
> > but
simply use
> > # info form z1 and
> > dat[88:89,c("X","X2","Y")]
>           X       X2        Y
> 88 2.706981 40.56130 2.803360
> 89 2.843977 48.87079 2.933857
> 
> Thanks,
> Adi Tarca
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ken.beath at mq.edu.au  Wed Nov  5 22:37:59 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 6 Nov 2014 08:37:59 +1100
Subject: [R-sig-ME] Error message
In-Reply-To: <545A102F.3030407@yahoo.com.ar>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>
	<40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>
	<54481F76.8040802@yahoo.com.ar>
	<3027a659772447a49bf110b3f0e59f36@CO2PR04MB826.namprd04.prod.outlook.com>
	<545A102F.3030407@yahoo.com.ar>
Message-ID: <CAF5_5cxPaUoaStq3cZ4YKmR25oBO=mJXR0XxsPd=e60EVVEqvg@mail.gmail.com>

I would try it using adaptive Gauss-Hermite, by setting nAgQ=3 or more and
seeing how that works. It really should be your first option when fitting a
GLMM, and something that should be checked anyway. In your case with binary
data and approx 2 per group the Laplace approximation is almost certainly
poor.

On 5 November 2014 22:55, Luciano La Sala <lucianolasala at yahoo.com.ar>
wrote:

> Thank you Dan,
>
> According to the new version of lme4 I refited my model as follows:
>
> model <- glmer(Death ~ Year + Sex + Egg Volume + Hatch Order + (1|Nest
> ID), family = binomial, data = Data)
> summary(model)
>
> However, the same error message keeps showing up:
>
>
> Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
>
>
> Interestingly, if I reduce the model to contain only one main effect
> (whichever), say Hatch_Order, things look better:
>
> model2 <- glmer(Death 2 ~ Hatch Order + (1|Nest_ID), family = binomial,
> data = Data) summary(model2)
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> Family: binomial  ( logit )
> Formula: Death_2 ~ Hatch_Order + (1 | Nest_ID)
>     Data: surv.2
>
>       AIC      BIC   logLik deviance df.resid
>     118.5    131.8    -55.2    110.5      205
>
> Scaled residuals:
>      Min      1Q  Median      3Q     Max
> -0.7390 -0.1714 -0.1682 -0.1506  3.7689
>
> Random effects:
>   Groups  Name        Variance Std.Dev.
>   Nest_ID (Intercept) 1.586    1.259
> Number of obs: 209, groups:  Nest ID, 115
>
> Fixed effects:
>                    Estimate Std. Error z value Pr(>|z|)
> (Intercept)        -3.4824     1.1274  -3.089  0.00201 **
> Hatch_OrderSecond  -0.1266     0.7576  -0.167  0.86729
> Hatch_OrderThird    2.0486     0.7572   2.705  0.00682 **
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>              (Intr) Htc_OS
> Htch_OrdrSc -0.111
> Htch_OrdrTh -0.709  0.276
>
>
> Any pointers please? Best. Luciano
>
>
>
> El 10/22/2014 6:35 PM, Daniel Wright escribi?:
> > The lme4 package has changed some. Details are inhttp://
> arxiv.org/pdf/1406.5823.pdf
> >
> > For your problem, the first thing to note is glmer is now used instead
> of lmer for generalized linear models.  Glancing at your model the other
> bits look like they should work.
> >
> > Dan
> >
> > Daniel B. Wright, Ph.D.
> > Statistical Research Division
> > 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
> > (preferred method of communication is email, use cell if urgent)
> > Office: 512.320.1827
> > Cell: 786 342 4656
> >
> >
> >
> >
> >
> >
> > This email message is intended only for the personal use of the
> recipient(s) named above. If you are not an intended recipient, you may not
> review, copy, or distribute this message. If you have received this
> communication in error, please notify the sender immediately by email and
> delete the original message.
> >
> >
> >
> > -----Original Message-----
> > From:r-sig-mixed-models-bounces at r-project.org  [mailto:
> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
> > Sent: Wednesday, October 22, 2014 4:20 PM
> > Cc:r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Error message
> >
> > Hello,
> >
> > A few years back I used to fit GLMM (binomial response) using lmer
> function in lme4. Back then I had to specify the family of response
> variable  (dead /alive) as binomial. Now I have to refit those models using
> quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but
> things seem to have changed quite a bit.
> >
> > My response variable is death (yes/no), and independent variables are
> Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching
> Order (ordered factor variable, namely first, second, third). I need to
> control autocorrelation among siblings, so I use "Nest ID" to fit random
> intercepts for different nests.
> >
> > My model is:
> >
> > model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
> (1|Nest_ID), family = binomial, data = Data)
> > summary(model.1)
> >
> > But I get the error and warning messages below:
> >
> > Error in eval(expr, envir, enclos) :
> >     (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate In addition:Warning message:
> > In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 |
> Nest_ID),  :
> >     calling lmer with 'family' is deprecated; please use glmer() instead
> >
> >
> > Question: how can I circumvent these two issues?
> >
> > Thanks in advance.
> >
> > Luciano
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org  mailing listhttps://
> stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Luciano F. La Sala
> Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
> C?tedra de Epidemiolog?a
> Departamento de Biolog?a, Bioqu?mica y Farmacia
> Universidad Nacional del Sur
> San Juan 670
> Bah?a Blanca (8000)
> Argentina
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Wed Nov  5 22:42:12 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 05 Nov 2014 16:42:12 -0500
Subject: [R-sig-ME] Error message
In-Reply-To: <CAF5_5cxPaUoaStq3cZ4YKmR25oBO=mJXR0XxsPd=e60EVVEqvg@mail.gmail.com>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>	<40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>	<54481F76.8040802@yahoo.com.ar>	<3027a659772447a49bf110b3f0e59f36@CO2PR04MB826.namprd04.prod.outlook.com>	<545A102F.3030407@yahoo.com.ar>
	<CAF5_5cxPaUoaStq3cZ4YKmR25oBO=mJXR0XxsPd=e60EVVEqvg@mail.gmail.com>
Message-ID: <545A99B4.1070704@gmail.com>

On 14-11-05 04:37 PM, Ken Beath wrote:
> I would try it using adaptive Gauss-Hermite, by setting nAgQ=3 or more and
> seeing how that works. It really should be your first option when fitting a
> GLMM, and something that should be checked anyway. In your case with binary
> data and approx 2 per group the Laplace approximation is almost certainly
> poor.

  Ken, can you point me to heuristic and/or anecdotal and/or
(preferably) official or peer-reviewed discussions of when Laplace
approximation is most likely to fail?  (I know it fails when the
sampling distribution of the conditional modes is non-Normal, it makes
sense that that would occur esp. for binary data and small samples per
group, but I'm trying to get a more precise handle on it ...)

  cheers
    Ben Bolker

> 
> On 5 November 2014 22:55, Luciano La Sala <lucianolasala at yahoo.com.ar>
> wrote:
> 
>> Thank you Dan,
>>
>> According to the new version of lme4 I refited my model as follows:
>>
>> model <- glmer(Death ~ Year + Sex + Egg Volume + Hatch Order + (1|Nest
>> ID), family = binomial, data = Data)
>> summary(model)
>>
>> However, the same error message keeps showing up:
>>
>>
>> Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>> pwrssUpdate
>>
>>
>> Interestingly, if I reduce the model to contain only one main effect
>> (whichever), say Hatch_Order, things look better:
>>
>> model2 <- glmer(Death 2 ~ Hatch Order + (1|Nest_ID), family = binomial,
>> data = Data) summary(model2)
>>
>>
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>> Family: binomial  ( logit )
>> Formula: Death_2 ~ Hatch_Order + (1 | Nest_ID)
>>     Data: surv.2
>>
>>       AIC      BIC   logLik deviance df.resid
>>     118.5    131.8    -55.2    110.5      205
>>
>> Scaled residuals:
>>      Min      1Q  Median      3Q     Max
>> -0.7390 -0.1714 -0.1682 -0.1506  3.7689
>>
>> Random effects:
>>   Groups  Name        Variance Std.Dev.
>>   Nest_ID (Intercept) 1.586    1.259
>> Number of obs: 209, groups:  Nest ID, 115
>>
>> Fixed effects:
>>                    Estimate Std. Error z value Pr(>|z|)
>> (Intercept)        -3.4824     1.1274  -3.089  0.00201 **
>> Hatch_OrderSecond  -0.1266     0.7576  -0.167  0.86729
>> Hatch_OrderThird    2.0486     0.7572   2.705  0.00682 **
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Correlation of Fixed Effects:
>>              (Intr) Htc_OS
>> Htch_OrdrSc -0.111
>> Htch_OrdrTh -0.709  0.276
>>
>>
>> Any pointers please? Best. Luciano
>>
>>
>>
>> El 10/22/2014 6:35 PM, Daniel Wright escribi?:
>>> The lme4 package has changed some. Details are inhttp://
>> arxiv.org/pdf/1406.5823.pdf
>>>
>>> For your problem, the first thing to note is glmer is now used instead
>> of lmer for generalized linear models.  Glancing at your model the other
>> bits look like they should work.
>>>
>>> Dan
>>>
>>> Daniel B. Wright, Ph.D.
>>> Statistical Research Division
>>> 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
>>> (preferred method of communication is email, use cell if urgent)
>>> Office: 512.320.1827
>>> Cell: 786 342 4656
>>>
>>>
>>>
>>>
>>>
>>>
>>> This email message is intended only for the personal use of the
>> recipient(s) named above. If you are not an intended recipient, you may not
>> review, copy, or distribute this message. If you have received this
>> communication in error, please notify the sender immediately by email and
>> delete the original message.
>>>
>>>
>>>
>>> -----Original Message-----
>>> From:r-sig-mixed-models-bounces at r-project.org  [mailto:
>> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
>>> Sent: Wednesday, October 22, 2014 4:20 PM
>>> Cc:r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] Error message
>>>
>>> Hello,
>>>
>>> A few years back I used to fit GLMM (binomial response) using lmer
>> function in lme4. Back then I had to specify the family of response
>> variable  (dead /alive) as binomial. Now I have to refit those models using
>> quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but
>> things seem to have changed quite a bit.
>>>
>>> My response variable is death (yes/no), and independent variables are
>> Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching
>> Order (ordered factor variable, namely first, second, third). I need to
>> control autocorrelation among siblings, so I use "Nest ID" to fit random
>> intercepts for different nests.
>>>
>>> My model is:
>>>
>>> model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
>> (1|Nest_ID), family = binomial, data = Data)
>>> summary(model.1)
>>>
>>> But I get the error and warning messages below:
>>>
>>> Error in eval(expr, envir, enclos) :
>>>     (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>> pwrssUpdate In addition:Warning message:
>>> In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 |
>> Nest_ID),  :
>>>     calling lmer with 'family' is deprecated; please use glmer() instead
>>>
>>>
>>> Question: how can I circumvent these two issues?
>>>
>>> Thanks in advance.
>>>
>>> Luciano
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org  mailing listhttps://
>> stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> --
>> Luciano F. La Sala
>> Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
>> C?tedra de Epidemiolog?a
>> Departamento de Biolog?a, Bioqu?mica y Farmacia
>> Universidad Nacional del Sur
>> San Juan 670
>> Bah?a Blanca (8000)
>> Argentina
>>
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> 
>


From ken.beath at mq.edu.au  Thu Nov  6 00:02:31 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 6 Nov 2014 10:02:31 +1100
Subject: [R-sig-ME] Error message
In-Reply-To: <545A99B4.1070704@gmail.com>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>
	<40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>
	<54481F76.8040802@yahoo.com.ar>
	<3027a659772447a49bf110b3f0e59f36@CO2PR04MB826.namprd04.prod.outlook.com>
	<545A102F.3030407@yahoo.com.ar>
	<CAF5_5cxPaUoaStq3cZ4YKmR25oBO=mJXR0XxsPd=e60EVVEqvg@mail.gmail.com>
	<545A99B4.1070704@gmail.com>
Message-ID: <CAF5_5cyVjhxHJPDvv4S-8HGVtL98cht0tTMdB1enB1Vs6B0=uQ@mail.gmail.com>

There is nothing I know of, which I find surprising. If you look
at Rabe-Hesketh, S., Skrondal, A., & Pickles, A. (2005). Maximum likelihood
estimation of limited and discrete dependent variable models with nested
random effects. Journal of Econometrics, 128(2), 301?323 they compare
different number of quadrature points starting at 5, and find that they
need more in situations where the clusters are small and random effects
variance high. In Rabe-Hesketh and Skrondal's  book "Multilevel and
Longitudinal Modeling Using Stata" they recommend a minimum of 5 adaptive
quadrature points for binary data. Obviously not peer reviewed but this
entry from Andrew Gelmans blog is interesting
http://andrewgelman.com/2010/09/10/r_vs_stata_or_d/ The best strategy is
what I was taught with non-adaptive Gauss_Hermite and that is to increase
the quadrature points and see if it makes a difference. If it doesn't then
you have the right number of quadrature points.

One of my experience with this was fitting some unusual random effects
models to binary data using adaptive Gauss-Hermite, using routines I wrote.
I wondered why I needed 21 points, so I plotted the log-likelihood for a
cluster and one side was very steep (almost cliff-like) compared to the
other, so it just wasn't going to work.

On 6 November 2014 08:42, Ben Bolker <bbolker at gmail.com> wrote:

> On 14-11-05 04:37 PM, Ken Beath wrote:
> > I would try it using adaptive Gauss-Hermite, by setting nAgQ=3 or more
> and
> > seeing how that works. It really should be your first option when
> fitting a
> > GLMM, and something that should be checked anyway. In your case with
> binary
> > data and approx 2 per group the Laplace approximation is almost certainly
> > poor.
>
>   Ken, can you point me to heuristic and/or anecdotal and/or
> (preferably) official or peer-reviewed discussions of when Laplace
> approximation is most likely to fail?  (I know it fails when the
> sampling distribution of the conditional modes is non-Normal, it makes
> sense that that would occur esp. for binary data and small samples per
> group, but I'm trying to get a more precise handle on it ...)
>
>   cheers
>     Ben Bolker
>
> >
> > On 5 November 2014 22:55, Luciano La Sala <lucianolasala at yahoo.com.ar>
> > wrote:
> >
> >> Thank you Dan,
> >>
> >> According to the new version of lme4 I refited my model as follows:
> >>
> >> model <- glmer(Death ~ Year + Sex + Egg Volume + Hatch Order + (1|Nest
> >> ID), family = binomial, data = Data)
> >> summary(model)
> >>
> >> However, the same error message keeps showing up:
> >>
> >>
> >> Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> >> pwrssUpdate
> >>
> >>
> >> Interestingly, if I reduce the model to contain only one main effect
> >> (whichever), say Hatch_Order, things look better:
> >>
> >> model2 <- glmer(Death 2 ~ Hatch Order + (1|Nest_ID), family = binomial,
> >> data = Data) summary(model2)
> >>
> >>
> >> Generalized linear mixed model fit by maximum likelihood (Laplace
> >> Approximation) ['glmerMod']
> >> Family: binomial  ( logit )
> >> Formula: Death_2 ~ Hatch_Order + (1 | Nest_ID)
> >>     Data: surv.2
> >>
> >>       AIC      BIC   logLik deviance df.resid
> >>     118.5    131.8    -55.2    110.5      205
> >>
> >> Scaled residuals:
> >>      Min      1Q  Median      3Q     Max
> >> -0.7390 -0.1714 -0.1682 -0.1506  3.7689
> >>
> >> Random effects:
> >>   Groups  Name        Variance Std.Dev.
> >>   Nest_ID (Intercept) 1.586    1.259
> >> Number of obs: 209, groups:  Nest ID, 115
> >>
> >> Fixed effects:
> >>                    Estimate Std. Error z value Pr(>|z|)
> >> (Intercept)        -3.4824     1.1274  -3.089  0.00201 **
> >> Hatch_OrderSecond  -0.1266     0.7576  -0.167  0.86729
> >> Hatch_OrderThird    2.0486     0.7572   2.705  0.00682 **
> >> ---
> >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>
> >> Correlation of Fixed Effects:
> >>              (Intr) Htc_OS
> >> Htch_OrdrSc -0.111
> >> Htch_OrdrTh -0.709  0.276
> >>
> >>
> >> Any pointers please? Best. Luciano
> >>
> >>
> >>
> >> El 10/22/2014 6:35 PM, Daniel Wright escribi?:
> >>> The lme4 package has changed some. Details are inhttp://
> >> arxiv.org/pdf/1406.5823.pdf
> >>>
> >>> For your problem, the first thing to note is glmer is now used instead
> >> of lmer for generalized linear models.  Glancing at your model the other
> >> bits look like they should work.
> >>>
> >>> Dan
> >>>
> >>> Daniel B. Wright, Ph.D.
> >>> Statistical Research Division
> >>> 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
> >>> (preferred method of communication is email, use cell if urgent)
> >>> Office: 512.320.1827
> >>> Cell: 786 342 4656
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> This email message is intended only for the personal use of the
> >> recipient(s) named above. If you are not an intended recipient, you may
> not
> >> review, copy, or distribute this message. If you have received this
> >> communication in error, please notify the sender immediately by email
> and
> >> delete the original message.
> >>>
> >>>
> >>>
> >>> -----Original Message-----
> >>> From:r-sig-mixed-models-bounces at r-project.org  [mailto:
> >> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
> >>> Sent: Wednesday, October 22, 2014 4:20 PM
> >>> Cc:r-sig-mixed-models at r-project.org
> >>> Subject: [R-sig-ME] Error message
> >>>
> >>> Hello,
> >>>
> >>> A few years back I used to fit GLMM (binomial response) using lmer
> >> function in lme4. Back then I had to specify the family of response
> >> variable  (dead /alive) as binomial. Now I have to refit those models
> using
> >> quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but
> >> things seem to have changed quite a bit.
> >>>
> >>> My response variable is death (yes/no), and independent variables are
> >> Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching
> >> Order (ordered factor variable, namely first, second, third). I need to
> >> control autocorrelation among siblings, so I use "Nest ID" to fit random
> >> intercepts for different nests.
> >>>
> >>> My model is:
> >>>
> >>> model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
> >> (1|Nest_ID), family = binomial, data = Data)
> >>> summary(model.1)
> >>>
> >>> But I get the error and warning messages below:
> >>>
> >>> Error in eval(expr, envir, enclos) :
> >>>     (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> >> pwrssUpdate In addition:Warning message:
> >>> In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 |
> >> Nest_ID),  :
> >>>     calling lmer with 'family' is deprecated; please use glmer()
> instead
> >>>
> >>>
> >>> Question: how can I circumvent these two issues?
> >>>
> >>> Thanks in advance.
> >>>
> >>> Luciano
> >>>
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org  mailing listhttps://
> >> stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> --
> >> Luciano F. La Sala
> >> Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
> >> C?tedra de Epidemiolog?a
> >> Departamento de Biolog?a, Bioqu?mica y Farmacia
> >> Universidad Nacional del Sur
> >> San Juan 670
> >> Bah?a Blanca (8000)
> >> Argentina
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From lucianolasala at yahoo.com.ar  Thu Nov  6 03:27:22 2014
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 05 Nov 2014 23:27:22 -0300
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 95, Issue 6
In-Reply-To: <mailman.5253.1415223489.15062.r-sig-mixed-models@r-project.org>
References: <mailman.5253.1415223489.15062.r-sig-mixed-models@r-project.org>
Message-ID: <545ADC8A.5010608@yahoo.com.ar>

Dear Ken and Ben,

Thank you so much for your prompt responses. This is more frustrating 
than interesting to me. Weird, but the model runs "smoothly" if I use 
nAGQ=0 (output below). Any value other than that yields the mentioned 
error. I have no idea how this Gauss-Hermite Quadrature stuff works, or 
if setting nAGQ to 0 makes my model building strategy (AIC criterion) a 
poor choice. Should I stick with nAGQ=0 then?

 > model.1 <- glmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + 
(1|Nest_ID), nAGQ=0, family = binomial, data = surv.2)
 > summary(model.1)

Generalized linear mixed model fit by maximum likelihood (Adaptive 
Gauss-Hermite Quadrature, nAGQ =  0)
  [glmerMod]
  Family: binomial  ( logit )
Formula: Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID)
    Data: surv.2

      AIC      BIC   logLik deviance df.resid
     22.0     44.7     -4.0      8.0      182

Scaled residuals:
     Min      1Q  Median      3Q     Max
-0.2291  0.0000  0.0000  0.0000  4.4713

Random effects:
  Groups  Name        Variance Std.Dev.
  Nest_ID (Intercept) 0        0
Number of obs: 189, groups:  Nest_ID, 111

Fixed effects:
                     Estimate Std. Error z value Pr(>|z|)
(Intercept)       -4.185e+01  1.538e+04  -0.003    0.998
Year2007           1.933e+01  1.096e+04   0.002    0.999
Sex               -1.878e+01  1.139e+04  -0.002    0.999
Egg_Volume        -5.620e-03  2.077e-01  -0.027    0.978
Hatch_OrderSecond  1.997e+01  1.079e+04   0.002    0.999
Hatch_OrderThird  -3.482e-01  2.544e+04   0.000    1.000

Correlation of Fixed Effects:
             (Intr) Yr2007 Sex    Egg_Vl Htc_OS
Year2007    -0.713
Sex          0.000  0.000
Egg_Volume  -0.001  0.000  0.000
Htch_OrdrSc -0.701  0.000  0.000  0.000
Htch_OrdrTh -0.298  0.000  0.000  0.000  0.424

El 11/5/2014 6:38 PM, r-sig-mixed-models-request at r-project.org escribi?:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>     1. Re: Error message (Luciano La Sala)
>     2. Re: Error message (Ben Bolker)
>     3. Re: subject level predictions with lme4 from	incomplete
>        longitudinal profile (Tarca, Adi)
>     4. Re: Error message (Ken Beath)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Wed, 05 Nov 2014 08:55:27 -0300
> From: Luciano La Sala <lucianolasala at yahoo.com.ar>
> To: Daniel Wright <Daniel.Wright at act.org>
> Cc: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Error message
> Message-ID: <545A102F.3030407 at yahoo.com.ar>
> Content-Type: text/plain; charset="UTF-8"
>
> Thank you Dan,
>
> According to the new version of lme4 I refited my model as follows:
>
> model <- glmer(Death ~ Year + Sex + Egg Volume + Hatch Order + (1|Nest
> ID), family = binomial, data = Data)
> summary(model)
>
> However, the same error message keeps showing up:
>
>
> Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
>
>
> Interestingly, if I reduce the model to contain only one main effect
> (whichever), say Hatch_Order, things look better:
>
> model2 <- glmer(Death 2 ~ Hatch Order + (1|Nest_ID), family = binomial,
> data = Data) summary(model2)
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
> Family: binomial  ( logit )
> Formula: Death_2 ~ Hatch_Order + (1 | Nest_ID)
>      Data: surv.2
>
>        AIC      BIC   logLik deviance df.resid
>      118.5    131.8    -55.2    110.5      205
>
> Scaled residuals:
>       Min      1Q  Median      3Q     Max
> -0.7390 -0.1714 -0.1682 -0.1506  3.7689
>
> Random effects:
>    Groups  Name        Variance Std.Dev.
>    Nest_ID (Intercept) 1.586    1.259
> Number of obs: 209, groups:  Nest ID, 115
>
> Fixed effects:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)        -3.4824     1.1274  -3.089  0.00201 **
> Hatch_OrderSecond  -0.1266     0.7576  -0.167  0.86729
> Hatch_OrderThird    2.0486     0.7572   2.705  0.00682 **
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>               (Intr) Htc_OS
> Htch_OrdrSc -0.111
> Htch_OrdrTh -0.709  0.276
>
>
> Any pointers please? Best. Luciano
>
>
>
> El 10/22/2014 6:35 PM, Daniel Wright escribi? The lme4 package has changed some. Details are inhttp://arxiv.org/pdf/1406.5823.pdf
>>
>> For your problem, the first thing to note is glmer is now used instead of lmer for generalized linear models.  Glancing at your model the other bits look like they should work.
>>
>> Dan
>>
>> Daniel B. Wright, Ph.D.
>> Statistical Research Division
>> 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
>> (preferred method of communication is email, use cell if urgent)
>> Office: 512.320.1827
>> Cell: 786 342 4656
>>
>>
>>
>>
>>
>>
>> This email message is intended only for the personal use of the recipient(s) named above. If you are not an intended recipient, you may not review, copy, or distribute this message. If you have received this communication in error, please notify the sender immediately by email and delete the original message.
>>
>>
>>
>> -----Original Message-----
>> From:r-sig-mixed-models-bounces at r-project.org  [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
>> Sent: Wednesday, October 22, 2014 4:20 PM
>> Cc:r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Error message
>>
>> Hello,
>>
>> A few years back I used to fit GLMM (binomial response) using lmer function in lme4. Back then I had to specify the family of response variable  (dead /alive) as binomial. Now I have to refit those models using quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but things seem to have changed quite a bit.
>>
>> My response variable is death (yes/no), and independent variables are Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching Order (ordered factor variable, namely first, second, third). I need to control autocorrelation among siblings, so I use "Nest ID" to fit random intercepts for different nests.
>>
>> My model is:
>>
>> model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1|Nest_ID), family = binomial, data = Data)
>> summary(model.1)
>>
>> But I get the error and warning messages below:
>>
>> Error in eval(expr, envir, enclos) :
>>      (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate In addition:Warning message:
>> In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID),  :
>>      calling lmer with 'family' is deprecated; please use glmer() instead
>>
>>
>> Question: how can I circumvent these two issues?
>>
>> Thanks in advance.
>>
>> Luciano
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

-- 
Luciano F. La Sala
Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
C?tedra de Epidemiolog?a
Departamento de Biolog?a, Bioqu?mica y Farmacia
Universidad Nacional del Sur
San Juan 670
Bah?a Blanca (8000)
Argentina


From ken.beath at mq.edu.au  Thu Nov  6 03:38:38 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 6 Nov 2014 13:38:38 +1100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 95, Issue 6
In-Reply-To: <545ADC8A.5010608@yahoo.com.ar>
References: <mailman.5253.1415223489.15062.r-sig-mixed-models@r-project.org>
	<545ADC8A.5010608@yahoo.com.ar>
Message-ID: <CAF5_5czUsT9DFLtntAe5SOkfuqEmXhYQ7Xgfx5n4JQF_i2Or7g@mail.gmail.com>

nAGQ=0 uses an even more approximate method, so probably isn't advised.
Looking at your output something has gone seriously wrong. The standard
errors are all very large and the random effect variance is zero.

Have you checked whether there is a collinearity problem between your fixed
effects. Start with a model with all the fixed effects and no random and
see how that works.

On 6 November 2014 13:27, Luciano La Sala <lucianolasala at yahoo.com.ar>
wrote:

> Dear Ken and Ben,
>
> Thank you so much for your prompt responses. This is more frustrating than
> interesting to me. Weird, but the model runs "smoothly" if I use nAGQ=0
> (output below). Any value other than that yields the mentioned error. I
> have no idea how this Gauss-Hermite Quadrature stuff works, or if setting
> nAGQ to 0 makes my model building strategy (AIC criterion) a poor choice.
> Should I stick with nAGQ=0 then?
>
> > model.1 <- glmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
> (1|Nest_ID), nAGQ=0, family = binomial, data = surv.2)
> > summary(model.1)
>
> Generalized linear mixed model fit by maximum likelihood (Adaptive
> Gauss-Hermite Quadrature, nAGQ =  0)
>  [glmerMod]
>  Family: binomial  ( logit )
> Formula: Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID)
>    Data: surv.2
>
>      AIC      BIC   logLik deviance df.resid
>     22.0     44.7     -4.0      8.0      182
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -0.2291  0.0000  0.0000  0.0000  4.4713
>
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  Nest_ID (Intercept) 0        0
> Number of obs: 189, groups:  Nest_ID, 111
>
> Fixed effects:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)       -4.185e+01  1.538e+04  -0.003    0.998
> Year2007           1.933e+01  1.096e+04   0.002    0.999
> Sex               -1.878e+01  1.139e+04  -0.002    0.999
> Egg_Volume        -5.620e-03  2.077e-01  -0.027    0.978
> Hatch_OrderSecond  1.997e+01  1.079e+04   0.002    0.999
> Hatch_OrderThird  -3.482e-01  2.544e+04   0.000    1.000
>
> Correlation of Fixed Effects:
>             (Intr) Yr2007 Sex    Egg_Vl Htc_OS
> Year2007    -0.713
> Sex          0.000  0.000
> Egg_Volume  -0.001  0.000  0.000
> Htch_OrdrSc -0.701  0.000  0.000  0.000
> Htch_OrdrTh -0.298  0.000  0.000  0.000  0.424
>
> El 11/5/2014 6:38 PM, r-sig-mixed-models-request at r-project.org escribi?:
>
>> Send R-sig-mixed-models mailing list submissions to
>>         r-sig-mixed-models at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> or, via email, send a message with subject or body 'help' to
>>         r-sig-mixed-models-request at r-project.org
>>
>> You can reach the person managing the list at
>>         r-sig-mixed-models-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of R-sig-mixed-models digest..."
>>
>>
>> Today's Topics:
>>
>>     1. Re: Error message (Luciano La Sala)
>>     2. Re: Error message (Ben Bolker)
>>     3. Re: subject level predictions with lme4 from     incomplete
>>        longitudinal profile (Tarca, Adi)
>>     4. Re: Error message (Ken Beath)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Wed, 05 Nov 2014 08:55:27 -0300
>> From: Luciano La Sala <lucianolasala at yahoo.com.ar>
>> To: Daniel Wright <Daniel.Wright at act.org>
>> Cc: "r-sig-mixed-models at r-project.org"
>>         <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Error message
>> Message-ID: <545A102F.3030407 at yahoo.com.ar>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> Thank you Dan,
>>
>> According to the new version of lme4 I refited my model as follows:
>>
>> model <- glmer(Death ~ Year + Sex + Egg Volume + Hatch Order + (1|Nest
>> ID), family = binomial, data = Data)
>> summary(model)
>>
>> However, the same error message keeps showing up:
>>
>>
>> Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>> pwrssUpdate
>>
>>
>> Interestingly, if I reduce the model to contain only one main effect
>> (whichever), say Hatch_Order, things look better:
>>
>> model2 <- glmer(Death 2 ~ Hatch Order + (1|Nest_ID), family = binomial,
>> data = Data) summary(model2)
>>
>>
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>> Family: binomial  ( logit )
>> Formula: Death_2 ~ Hatch_Order + (1 | Nest_ID)
>>      Data: surv.2
>>
>>        AIC      BIC   logLik deviance df.resid
>>      118.5    131.8    -55.2    110.5      205
>>
>> Scaled residuals:
>>       Min      1Q  Median      3Q     Max
>> -0.7390 -0.1714 -0.1682 -0.1506  3.7689
>>
>> Random effects:
>>    Groups  Name        Variance Std.Dev.
>>    Nest_ID (Intercept) 1.586    1.259
>> Number of obs: 209, groups:  Nest ID, 115
>>
>> Fixed effects:
>>                     Estimate Std. Error z value Pr(>|z|)
>> (Intercept)        -3.4824     1.1274  -3.089 0.00201 **
>> Hatch_OrderSecond  -0.1266     0.7576  -0.167  0.86729
>> Hatch_OrderThird    2.0486     0.7572   2.705  0.00682 **
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Correlation of Fixed Effects:
>>               (Intr) Htc_OS
>> Htch_OrdrSc -0.111
>> Htch_OrdrTh -0.709  0.276
>>
>>
>> Any pointers please? Best. Luciano
>>
>>
>>
>> El 10/22/2014 6:35 PM, Daniel Wright escribi? The lme4 package has
>> changed some. Details are inhttp://arxiv.org/pdf/1406.5823.pdf
>>
>>>
>>> For your problem, the first thing to note is glmer is now used instead
>>> of lmer for generalized linear models.  Glancing at your model the other
>>> bits look like they should work.
>>>
>>> Dan
>>>
>>> Daniel B. Wright, Ph.D.
>>> Statistical Research Division
>>> 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
>>> (preferred method of communication is email, use cell if urgent)
>>> Office: 512.320.1827
>>> Cell: 786 342 4656
>>>
>>>
>>>
>>>
>>>
>>>
>>> This email message is intended only for the personal use of the
>>> recipient(s) named above. If you are not an intended recipient, you may not
>>> review, copy, or distribute this message. If you have received this
>>> communication in error, please notify the sender immediately by email and
>>> delete the original message.
>>>
>>>
>>>
>>> -----Original Message-----
>>> From:r-sig-mixed-models-bounces at r-project.org  [mailto:
>>> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
>>> Sent: Wednesday, October 22, 2014 4:20 PM
>>> Cc:r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] Error message
>>>
>>> Hello,
>>>
>>> A few years back I used to fit GLMM (binomial response) using lmer
>>> function in lme4. Back then I had to specify the family of response
>>> variable  (dead /alive) as binomial. Now I have to refit those models using
>>> quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but
>>> things seem to have changed quite a bit.
>>>
>>> My response variable is death (yes/no), and independent variables are
>>> Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching
>>> Order (ordered factor variable, namely first, second, third). I need to
>>> control autocorrelation among siblings, so I use "Nest ID" to fit random
>>> intercepts for different nests.
>>>
>>> My model is:
>>>
>>> model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
>>> (1|Nest_ID), family = binomial, data = Data)
>>> summary(model.1)
>>>
>>> But I get the error and warning messages below:
>>>
>>> Error in eval(expr, envir, enclos) :
>>>      (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>>> pwrssUpdate In addition:Warning message:
>>> In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 |
>>> Nest_ID),  :
>>>      calling lmer with 'family' is deprecated; please use glmer() instead
>>>
>>>
>>> Question: how can I circumvent these two issues?
>>>
>>> Thanks in advance.
>>>
>>> Luciano
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org  mailing listhttps://stat.ethz.ch/
>>> mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
> --
> Luciano F. La Sala
> Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
> C?tedra de Epidemiolog?a
> Departamento de Biolog?a, Bioqu?mica y Farmacia
> Universidad Nacional del Sur
> San Juan 670
> Bah?a Blanca (8000)
> Argentina
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Thu Nov  6 04:33:01 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 6 Nov 2014 03:33:01 +0000 (UTC)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 95, Issue 6
References: <mailman.5253.1415223489.15062.r-sig-mixed-models@r-project.org>
	<545ADC8A.5010608@yahoo.com.ar>
	<CAF5_5czUsT9DFLtntAe5SOkfuqEmXhYQ7Xgfx5n4JQF_i2Or7g@mail.gmail.com>
Message-ID: <loom.20141106T042818-304@post.gmane.org>

Ken Beath <ken.beath at ...> writes:

> 
> nAGQ=0 uses an even more approximate method, so probably isn't advised.
> Looking at your output something has gone seriously wrong. The standard
> errors are all very large and the random effect variance is zero.
> 
> Have you checked whether there is a collinearity problem 
> between your fixed
> effects. Start with a model with all the fixed effects and no random and
> see how that works.

  And/or check for *complete separation*; whenever you have fixed effects
in a GLMM that are large (e.g. |beta|>10) you can suspect that you have
a category that is all-zero or all-one, and bad things will happen as
a result.

Here's your coefficient table:

(Intercept)       -4.185e+01  1.538e+04  -0.003    0.998
Year2007           1.933e+01  1.096e+04   0.002    0.999
Sex               -1.878e+01  1.139e+04  -0.002    0.999
Egg_Volume        -5.620e-03  2.077e-01  -0.027    0.978
Hatch_OrderSecond  1.997e+01  1.079e+04   0.002    0.999
Hatch_OrderThird  -3.482e-01  2.544e+04   0.000    1.000

  So that says that the predicted probability of a 1 in your baseline
condition (first hatch, egg volume zero, sex=0, first year) is
plogis(-41) approx. 1e-18 (!).

  If this does turn out to be the problem, you can solve it
by adding a small prior (e.g. using blmer); see
http://rpubs.com/bbolker/glmmchapter and search for "complete separation".

  I'm just a little surprised that it worked (i.e., ran *and* you
got sensible answers) before ...
 
> On 6 November 2014 13:27, Luciano La Sala <lucianolasala <at> yahoo.com.ar>
> wrote:
> 
> > Dear Ken and Ben,
> >
> > > model.1 <- glmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
> > (1|Nest_ID), nAGQ=0, family = binomial, data = surv.2)
> > > summary(model.1)
> >
> > Generalized linear mixed model fit by maximum likelihood (Adaptive
> > Gauss-Hermite Quadrature, nAGQ =  0)
> >  [glmerMod]
> >  Family: binomial  ( logit )
> > Formula: Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID)
> >    Data: surv.2
> >
> >      AIC      BIC   logLik deviance df.resid
> >     22.0     44.7     -4.0      8.0      182
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -0.2291  0.0000  0.0000  0.0000  4.4713
> >
> > Random effects:
> >  Groups  Name        Variance Std.Dev.
> >  Nest_ID (Intercept) 0        0
> > Number of obs: 189, groups:  Nest_ID, 111
> >
> > Fixed effects:
> >                     Estimate Std. Error z value Pr(>|z|)
> > (Intercept)       -4.185e+01  1.538e+04  -0.003    0.998
> > Year2007           1.933e+01  1.096e+04   0.002    0.999
> > Sex               -1.878e+01  1.139e+04  -0.002    0.999
> > Egg_Volume        -5.620e-03  2.077e-01  -0.027    0.978
> > Hatch_OrderSecond  1.997e+01  1.079e+04   0.002    0.999
> > Hatch_OrderThird  -3.482e-01  2.544e+04   0.000    1.000
> >


From mizuho19901116 at yahoo.co.jp  Thu Nov  6 09:06:01 2014
From: mizuho19901116 at yahoo.co.jp (Nagata Mizuho)
Date: Thu, 6 Nov 2014 17:06:01 +0900 (JST)
Subject: [R-sig-ME] error message using glmmADMB
Message-ID: <613168.5940.qm@web100719.mail.kks.yahoo.co.jp>

Dear members,

I am trying to fit a glmmADMB model on my data, but altough I tried to fix
it after reading many tutorials and forums, I couldn't do it.
I use R version 3.0.2 and glmmADMB version 0.8.0.

?The model looks like this:

modelA<-glmmadmb(F_sumtime~posi+(1|No),family="gamma",link="log",data=act,zeroInflation=TRUE)

This is my data.
'data.frame':????5354 obs. of??3 variables:?
$ No?????? : Factor w/ 8 levels "B22","B36","B41",..: 1 1 1 1 1 1 1 1 1 1 ...?
$ posi???? : Factor w/ 6 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...?
$ F_sumtime: num??70 60 60.5 60 170.5 ...

This is the error messege.
glmmadmb(f_sumtime_h ~ posi + (1 | No), family = "gamma", link = "log",??: 
The function maximizer failed (couldn't find STD file) Troubleshooting steps include?
(1) run with 'save.dir' set and inspect output files;?
(2) change run parameters: see '?admbControl'
-maxfn 500 -maxph 5 -noinit -shess' had status 1 
Incompatible bounds in dvar_vector& dvar_vector::operator = (const dvar_vector& t)

So, I run with?'save.dir' like this:
modelA<-glmmadmb( F_sumtime~posi+(1|No),family="gamma",link="log",data=act,zeroInflation=TRUE,save.dir="act3",admb.opts=admbControl(run=FALSE))


The error message is here:
'run=FALSE' specified, STD file not found: stopping


I got a act3?directory?and run ADMB from terminal.

But I couldn't get the result.

Any idea of what is wrong?
Thanks in advance!



From bbolker at gmail.com  Thu Nov  6 17:11:33 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 6 Nov 2014 11:11:33 -0500
Subject: [R-sig-ME] default optimizer in lmer 1.1-7?
In-Reply-To: <3beefbe428da4be8939e8ec60a4c60e6@ex1.eeza.csic.es>
References: <3beefbe428da4be8939e8ec60a4c60e6@ex1.eeza.csic.es>
Message-ID: <CABghstSVPGZwGqP+VUK7j0kp5SqNDJgtFno8qmqUonJqrzK9mQ@mail.gmail.com>

[cc'ing to r-sig-mixed-models]

You can see the default optimizer for GLMMs by running

 > glmerControl()$optimizer
[1] "bobyqa"      "Nelder_Mead"

This means that bobyqa is used for the first (nAGQ=0) stage of
optimization, whereas Nelder-Mead is used for the second (nAGQ>0).  If
optimizer is a length-1 vector, the same optimizer is used for both stages
of optimization (I *think* this is explained in the documentation, but it
might not be ...)

If you read the NEWS file <
http://cran.r-project.org/web/packages/lme4/news.html> slightly more
carefully, you'll see that the default was only changed for `lmer` fits,
not `glmer` fits -- from 1.1-4,

* The default optimizer for lmer fits has been switched from "Nelder_Mead"
to "bobyqa" because we have generally found the latter to be more reliable.
To switch back to the old behaviour, use
control=lmerControl(optimizer="Nelder_Mead").

  We are very seriously considering making bobyqa, or nloptwrap, the
default for GLMMs as well (for both stages of optimization) in the next
release.

 I haven't looked at your results in too much detail otherwise -- it's a
little bit puzzling that all the AICs seem to be about the same, but I was
in a hurry (and I want to send this off before the problem gets buried in
my inbox).


On Thu, Nov 6, 2014 at 10:16 AM, Jordi Moya Lara?o <jordi at eeza.csic.es>
wrote:

>  Dear Ben,
> We have been going crazy about replicating previous analyses with glmer
> and I think that what may be happening is that when you copiled the last
> version you left in unadvertedly "Nelder_Mead" by default instead of
> "bobyqa" as it is claimed to be done in the last version of the manual. Is
> that a possibility? My analyses give the results by default as those
> obtained if you were using "Nelder_Mead". I am also wondering whether
> Nelder_Mead results should be trusted whatsoever.
>
> Here are my codes and results (the results using "bobyqa" are the once
> qualitatively very similar to those using previous versions of lme4):
> >
> TELA_MANIP1<-glmer(ABUNDANCE~RAIN*TRAT+(1|SITE)+(1|caso),data=tela2013,poisson)
> > summary(TELA_MANIP1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: poisson  ( log )
> Formula: ABUNDANCE ~ RAIN * TRAT + (1 | SITE) + (1 | caso)
>    Data: tela2013
>
>      AIC      BIC   logLik deviance df.resid
>    265.8    282.2   -124.9    249.8       49
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -1.67352 -0.56382  0.04347  0.63915  1.61069
>
> Random effects:
>  Groups Name        Variance  Std.Dev.
>  caso   (Intercept) 0.0815360 0.28555
>  SITE   (Intercept) 0.0001355 0.01164
> Number of obs: 57, groups:  caso, 57; SITE, 7
>
> Fixed effects:
>                           Estimate Std. Error z value Pr(>|z|)
> (Intercept)               1.515432   0.004537   334.0  < 2e-16 ***
> RAINLOW                   0.013886   0.004533     3.1  0.00219 **
> TRATNO_PREDATORS         -0.621030   0.004532  -137.0  < 2e-16 ***
> TRATPREDATORS             0.238772   0.004534    52.7  < 2e-16 ***
> RAINLOW:TRATNO_PREDATORS -0.251747   0.004531   -55.6  < 2e-16 ***
> RAINLOW:TRATPREDATORS     0.046884   0.004532    10.3  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>               (Intr) RAINLOW TRATNO TRATPR RAINLOW:TRATN
> RAINLOW       0.000
> TRATNO_PRED   0.000  0.000
> TRATPREDATO   0.000  0.000   0.001
> RAINLOW:TRATN 0.000  0.000   0.000  0.000
> RAINLOW:TRATP 0.000  0.000   0.001  0.000  0.000
> > library(car)
> > Anova(TELA_MANIP1,type="III",test="Chisq")
> Analysis of Deviance Table (Type III Wald chisquare tests)
>
> Response: ABUNDANCE
>                  Chisq Df Pr(>Chisq)
> (Intercept) 1.1158e+05  1    < 2e-16 ***
> RAIN        9.3829e+00  1    0.00219 **
> TRAT        2.1559e+04  2    < 2e-16 ***
> RAIN:TRAT   3.1937e+03  2    < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> >
> TELA_MANIP1<-glmer(ABUNDANCE~RAIN*TRAT+(1|SITE)+(1|caso),data=tela2013,poisson,glmerControl(optimizer
> = c("bobyqa")))
> > summary(TELA_MANIP1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: poisson  ( log )
> Formula: ABUNDANCE ~ RAIN * TRAT + (1 | SITE) + (1 | caso)
>    Data: tela2013
> Control: glmerControl(optimizer = c("bobyqa"))
>
>      AIC      BIC   logLik deviance df.resid
>    265.8    282.2   -124.9    249.8       49
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -1.67891 -0.56610  0.04277  0.63769  1.61159
>
> Random effects:
>  Groups Name        Variance Std.Dev.
>  caso   (Intercept) 0.08089  0.2844
>  SITE   (Intercept) 0.00000  0.0000
> Number of obs: 57, groups:  caso, 57; SITE, 7
>
> Fixed effects:
>                          Estimate Std. Error z value Pr(>|z|)
> (Intercept)               1.51734    0.19288   7.867 3.64e-15 ***
> RAINLOW                   0.01200    0.30771   0.039   0.9689
> TRATNO_PREDATORS         -0.62228    0.27051  -2.300   0.0214 *
> TRATPREDATORS             0.23893    0.23320   1.025   0.3056
> RAINLOW:TRATNO_PREDATORS -0.24897    0.46286  -0.538   0.5907
> RAINLOW:TRATPREDATORS     0.04942    0.36944   0.134   0.8936
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>               (Intr) RAINLOW TRATNO TRATPR RAINLOW:TRATN
> RAINLOW       -0.617
> TRATNO_PRED   -0.703  0.440
> TRATPREDATO   -0.817  0.510   0.581
> RAINLOW:TRATN  0.410 -0.665  -0.584 -0.339
> RAINLOW:TRATP  0.519 -0.833  -0.367 -0.632  0.554
> > library(car)
> > Anova(TELA_MANIP1,type="III",test="Chisq")
> Analysis of Deviance Table (Type III Wald chisquare tests)
>
> Response: ABUNDANCE
>               Chisq Df Pr(>Chisq)
> (Intercept) 61.8859  1  3.639e-15 ***
> RAIN         0.0015  1   0.968899
> TRAT        13.6932  2   0.001063 **
> RAIN:TRAT    0.5580  2   0.756552
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> >
> >
> TELA_MANIP1<-glmer(ABUNDANCE~RAIN*TRAT+(1|SITE)+(1|caso),data=tela2013,poisson,glmerControl(optimizer
> = c("Nelder_Mead")))
> > summary(TELA_MANIP1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: poisson  ( log )
> Formula: ABUNDANCE ~ RAIN * TRAT + (1 | SITE) + (1 | caso)
>    Data: tela2013
> Control: glmerControl(optimizer = c("Nelder_Mead"))
>
>      AIC      BIC   logLik deviance df.resid
>    265.8    282.2   -124.9    249.8       49
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -1.67425 -0.55993  0.04442  0.63968  1.61151
>
> Random effects:
>  Groups Name        Variance  Std.Dev.
>  caso   (Intercept) 8.144e-02 0.285378
>  SITE   (Intercept) 6.202e-05 0.007875
> Number of obs: 57, groups:  caso, 57; SITE, 7
>
> Fixed effects:
>                           Estimate Std. Error z value Pr(>|z|)
> (Intercept)               1.512854   0.004555   332.1  < 2e-16 ***
> RAINLOW                   0.016625   0.004551     3.7 0.000259 ***
> TRATNO_PREDATORS         -0.619082   0.004550  -136.1  < 2e-16 ***
> TRATPREDATORS             0.243134   0.004552    53.4  < 2e-16 ***
> RAINLOW:TRATNO_PREDATORS -0.254128   0.004549   -55.9  < 2e-16 ***
> RAINLOW:TRATPREDATORS     0.042442   0.004551     9.3  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>               (Intr) RAINLOW TRATNO TRATPR RAINLOW:TRATN
> RAINLOW       0.000
> TRATNO_PRED   0.000  0.000
> TRATPREDATO   0.000  0.000   0.001
> RAINLOW:TRATN 0.000  0.000   0.000  0.000
> RAINLOW:TRATP 0.000  0.000   0.001  0.000  0.000
> > library(car)
> > Anova(TELA_MANIP1,type="III",test="Chisq")
> Analysis of Deviance Table (Type III Wald chisquare tests)
>
> Response: ABUNDANCE
>                  Chisq Df Pr(>Chisq)
> (Intercept) 110319.413  1  < 2.2e-16 ***
> RAIN            13.343  1  0.0002594 ***
> TRAT         21372.929  2  < 2.2e-16 ***
> RAIN:TRAT     3207.377  2  < 2.2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> >
> TELA_MANIP1<-glmer(ABUNDANCE~RAIN*TRAT+(1|SITE)+(1|caso),data=tela2013,poisson,glmerControl(optimizer
> = c("Nelder_Mead")))
> > summary(TELA_MANIP1)
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: poisson  ( log )
> Formula: ABUNDANCE ~ RAIN * TRAT + (1 | SITE) + (1 | caso)
>    Data: tela2013
> Control: glmerControl(optimizer = c("Nelder_Mead"))
>
>      AIC      BIC   logLik deviance df.resid
>    265.8    282.2   -124.9    249.8       49
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -1.67425 -0.55993  0.04442  0.63968  1.61151
>
> Random effects:
>  Groups Name        Variance  Std.Dev.
>  caso   (Intercept) 8.144e-02 0.285378
>  SITE   (Intercept) 6.202e-05 0.007875
> Number of obs: 57, groups:  caso, 57; SITE, 7
>
> Fixed effects:
>                           Estimate Std. Error z value Pr(>|z|)
> (Intercept)               1.512854   0.004555   332.1  < 2e-16 ***
> RAINLOW                   0.016625   0.004551     3.7 0.000259 ***
> TRATNO_PREDATORS         -0.619082   0.004550  -136.1  < 2e-16 ***
> TRATPREDATORS             0.243134   0.004552    53.4  < 2e-16 ***
> RAINLOW:TRATNO_PREDATORS -0.254128   0.004549   -55.9  < 2e-16 ***
> RAINLOW:TRATPREDATORS     0.042442   0.004551     9.3  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>               (Intr) RAINLOW TRATNO TRATPR RAINLOW:TRATN
> RAINLOW       0.000
> TRATNO_PRED   0.000  0.000
> TRATPREDATO   0.000  0.000   0.001
> RAINLOW:TRATN 0.000  0.000   0.000  0.000
> RAINLOW:TRATP 0.000  0.000   0.001  0.000  0.000
> > library(car)
> > Anova(TELA_MANIP1,type="III",test="Chisq")
> Analysis of Deviance Table (Type III Wald chisquare tests)
>
> Response: ABUNDANCE
>                  Chisq Df Pr(>Chisq)
> (Intercept) 110319.413  1  < 2.2e-16 ***
> RAIN            13.343  1  0.0002594 ***
> TRAT         21372.929  2  < 2.2e-16 ***
> RAIN:TRAT     3207.377  2  < 2.2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> best wishes,
> Jordi
>
>   Jordi Moya-Lara?o
> Functional and Evolutionary Ecology
> Estaci?n Experimental de Zonas ?ridas - CSIC
> Carretera de Sacramento s/n
> La Ca?ada de San Urbano
> 04120-Almer?a
> Spain
>
> phone:+34 950281045 ext. 419
> email: jordi at eeza.csic.es
> www.eeza.csic.es/foodweb
>
>

	[[alternative HTML version deleted]]


From ahnate at gmail.com  Wed Nov  5 23:49:33 2014
From: ahnate at gmail.com (Ahnate Lim)
Date: Wed, 5 Nov 2014 12:49:33 -1000
Subject: [R-sig-ME] Multiple comparison correction?
Message-ID: <CAJuw=B7RfEAtGptbK8SS0tnyF11FUy8rMFOgGbqzcNLfXjFJmA@mail.gmail.com>

Hello,

I have a question related to mixed effect modeling and how to do multiple
comparisons.

We have a longitudinal study with different groups and many dependent
variables such as of brain cortical volume in different areas, etc.

I am using lme, and remember reading somewhere that multiple comparison
corrections do not actually apply to linear mixed effects models, due to
the statistics involved.

For example, if I run the same model on 100 dependent variables,
traditionally I would need to correct for multiple comparisons by dividing
the alpha level (0.05) by 100 to get the proper criterion of 0.0005,
adjusting for the increased likelihood of getting type I errors. I am
wondering however, if this process is the same, or even necessary at all
for lme models?

Thank you,

Ahnate

	[[alternative HTML version deleted]]


From goren1206 at gmail.com  Thu Nov  6 17:00:02 2014
From: goren1206 at gmail.com (Jason Paul)
Date: Thu, 6 Nov 2014 09:00:02 -0700
Subject: [R-sig-ME] Model correlated responses in interval-censored data
Message-ID: <CAANHfU=Yt5ucyVaV9XZ4txbn_qAO6OJkbYe5vvuTqosDCEO7CQ@mail.gmail.com>

Dear members,


Actually this question is an extention to this one:
http://stackoverflow.com/questions/26670267/want-to-convert-sas-code-using-proc-nlmixed-to-r-code-using-nlme

Dr. Ben Bolker has suggested the ADMB system. I am not sure whether I can
understand this system, but I will definitely try it. Besides this
recommendation, I am wondering if any one has analyzed such data before, or
can give me further suggestions. I really appreciate it.

	[[alternative HTML version deleted]]


From fezzet at aycerpc.com  Thu Nov  6 22:17:31 2014
From: fezzet at aycerpc.com (Farkad Ezzet)
Date: Thu, 6 Nov 2014 16:17:31 -0500
Subject: [R-sig-ME] Proportional Error model in nlme using weights
Message-ID: <07a501cffa07$13d3dac0$3b7b9040$@aycerpc.com>

Hi,

 

I am wondering if the mixed-models community have suggestions for the
following problem: 

nlme in R fails when specifying an error model as in "weights= varPower()".
Other error specifications, e.g. varExp and varConstPower also fail. It
seems that implementation of nlme in R is the culprit, since these error
models work perfectly fine using nlme in Splus. Here is a simple example
that attempts to model Pharmacokinetic data generated by simulation using a
one compartment intravenous dose. The code runs and estimates parameters
correctly in Splus (see below), but fails in R producing the error message
"Error in nlme.formula(conc ~ comp1.iv(ke * exp(eta.ke), v * exp(eta.v),  :
step halving factor reduced below minimum in PNLS step". 

Any suggestions are appreciated.

Thanks.

Farkad

Farkad Ezzet, MSc, PhD

Office  973 665-1447

Mobile 201 738-3826

 <mailto:fezzet at aycerpc.com> fezzet at aycerpc.com

 <http://www.aycerpc.com/> www.aycerpc.com

 <http://www.linkedin.com/pub/farkad-ezzet/11/28b/93a>
http://www.linkedin.com/pub/farkad-ezzet/11/28b/93a

 

####

 

library(nlme)

 

comp1.iv =

  function(ke, v, dose, time)

  {

    (dose/v) * exp(- ( ke * time ) ) 

  }

 

# function to simulate data

comp1.iv.Data = function(nsub, ke, v, cv.ke, cv.v, cv.error, d1, d2, time,
dose)

{

  set.seed(123)

  

  nsub0 <- nsub

  sub0   <- 1:nsub0

  time0 <- time

  dose0 <- dose

  

  eta.ke <- rnorm(nsub0,0,cv.ke)

  eta.v  <- rnorm(nsub0,0,cv.v)

  

  ke0 <- ke * exp(eta.ke)

  v0  <- v  * exp(eta.v)

  

  nobsid <- length(time0)*length(dose0)

  sub <- rep(sub0, each=nobsid)

  nobs   <- nobsid*nsub0

  time <- rep(time0,length(dose0)*nsub0)

  dose <- rep(rep(dose0, each=length(time0)),nsub0)

  

  ke <- rep(ke0, each=nobsid)

  v  <- rep(v0 , each=nobsid)

  

  x0 <- comp1.iv(ke,v,dose,time)

  

  conc <- x0 + (d1 + d2*x0) * rnorm(length(x0),0,cv.error)

  

  D = data.frame(id=sub, dose=dose, time= time, ke=ke, v=v, x0=x0,conc=conc)


  D = groupedData(conc~time| id, data =D)

  return(D)

} # end of comp1.iv.Data

 

# create data set with different error models

time = c(0,1,2,3,4,6,8,10, 12,18, 24)

dose = c(5)

 

iv.D1   = comp1.iv.Data(nsub=24,ke=.1, v=4,cv.ke=.1, cv.v=.1,
cv.error=0.1,d1=1, d2=0, time, dose) # additive

iv.D2   = comp1.iv.Data(nsub=24,ke=.1, v=4,cv.ke=.1, cv.v=.1,
cv.error=0.1,d1=0, d2=1, time, dose) # proportional

iv.D3   = comp1.iv.Data(nsub=24,ke=.1, v=4,cv.ke=.1, cv.v=.1,
cv.error=0.1,d1=1, d2=1, time, dose) # additive & proportional 

 

mean(iv.D1$conc)

mean(iv.D2$conc)

mean(iv.D3$conc)

 

# Run nlme with additive error using iv.D1

M1 = nlme(conc ~ 

            comp1.iv(ke*exp(eta.ke), v*exp(eta.v), dose=5, time) ,

          data=iv.D1, 

          random = pdDiag(list(eta.ke + eta.v ~ 1)),

          fixed = list(ke+v~ 1),

          start = c(.1, 4), verbose = T)

summary(M1)

 

# Run nlme with proportional error using iv.D2

M2 = nlme(conc ~ 

            comp1.iv(ke*exp(eta.ke), v*exp(eta.v), dose=5, time) ,

          data=iv.D2, 

          random = pdDiag(list(eta.ke + eta.v ~ 1)),

          fixed = list(ke+v~ 1),

          start = c(.1, 4), verbose = T, weights=varPower(1))

 

# Run nlme with additive & proportional error using iv.D3

M3 = nlme(conc ~ 

            comp1.iv(ke*exp(eta.ke), v*exp(eta.v), dose=5, time) ,

          data=iv.D3, 

          random = pdDiag(list(eta.ke + eta.v ~ 1)),

          fixed = list(ke+v~ 1),

          start = c(.1, 4), verbose = T, weights=varConstPower(const=1,
fixed=list(power=1)))

 

#===========================================================================
=======================

Results from splus are as follows:

 

>
#===========================================================================
=======================

summary(M1)

Nonlinear mixed-effects model fit by maximum likelihood

  Model: conc ~ comp1.iv(ke * exp(eta.ke), v * exp(eta.v), dose = 5, time) 

 Data: iv.D1 

        AIC      BIC   logLik 

  -421.5128 -403.633 215.7564

 

Random effects:

Formula: list(`eta.ke ~ 1` , `eta.v ~ 1` )

Level: id

Structure: Diagonal

            eta.ke      eta.v   Residual 

StdDev: 0.09409439 0.07256055 0.09725547

 

Fixed effects: list(ke + v ~ 1) 

      Value  Std.Error  DF  t-value p-value 

ke 0.103901 0.00320402 239 32.42816  <.0001

v 4.050623 0.07383155 239 54.86304  <.0001

 

Standardized Within-Group Residuals:

       Min         Q1        Med        Q3      Max 

 -2.740537 -0.6628803 0.01227503 0.6353222 2.767461

 

Number of Observations: 264

Number of Groups: 24 

>
#===========================================================================
=======================

summary(M2)

Nonlinear mixed-effects model fit by maximum likelihood

  Model: conc ~ comp1.iv(ke * exp(eta.ke), v * exp(eta.v), dose = 5, time) 

 Data: iv.D2 

        AIC       BIC   logLik 

  -712.0261 -690.5704 362.0131

 

Random effects:

Formula: list(`eta.ke ~ 1` , `eta.v ~ 1` )

Level: id

Structure: Diagonal

           eta.ke      eta.v   Residual 

StdDev: 0.1018449 0.07602354 0.09800981

 

Variance function:

Structure: Power of variance covariate

Formula:  ~ fitted(.) 

 Parameter estimates:

    power 

 1.086727

Fixed effects: list(ke + v ~ 1) 

      Value  Std.Error  DF  t-value p-value 

ke 0.101080 0.00224133 239 45.09815  <.0001

v 4.110736 0.07360580 239 55.84799  <.0001

 

Standardized Within-Group Residuals:

       Min         Q1         Med        Q3      Max 

 -3.181923 -0.5558349 -0.05090066 0.6356355 2.650502

 

Number of Observations: 264

Number of Groups: 24 

>
#===========================================================================
=======================

summary(M3)

Nonlinear mixed-effects model fit by maximum likelihood

  Model: conc ~ comp1.iv(ke * exp(eta.ke), v * exp(eta.v), dose = 5, time) 

 Data: iv.D3 

        AIC       BIC   logLik 

  -192.1091 -170.6534 102.0546

 

Random effects:

Formula: list(`eta.ke ~ 1` , `eta.v ~ 1` )

Level: id

Structure: Diagonal

           eta.ke      eta.v   Residual 

StdDev: 0.1361807 0.05127604 0.08516098

 

Variance function:

Structure: Constant plus power of variance covariate

Formula:  ~ fitted(.) 

 Parameter estimates:

    const power 

 1.206157     1

Fixed effects: list(ke + v ~ 1) 

      Value  Std.Error  DF  t-value p-value 

ke 0.104314 0.00480831 239 21.69463  <.0001

v 4.043718 0.09246226 239 43.73371  <.0001

 

Standardized Within-Group Residuals:

       Min         Q1          Med        Q3      Max 

 -2.694926 -0.6616733 -0.001634472 0.6529347 2.617859

 

Number of Observations: 264

Number of Groups: 24 

>
#===========================================================================
=======================

 

 

 


	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Thu Nov  6 23:39:20 2014
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 6 Nov 2014 22:39:20 +0000
Subject: [R-sig-ME] Multiple comparison correction?
Message-ID: <CAAH-yP__JU4iOXGF5RoWvMvg6PxXVMrvbMhFjG-=g6VedYgAyA@mail.gmail.com>

Dear Ahnate,

I'm not a particular expert on this topic, but I found Gelman et al.'s
views quite interesting:

http://www.stat.wisc.edu/~larget/Stat998/Fall2013/GelmanMultipleComparisons.pdf

>From the sounds of it you'll find the paper useful too.

Cheers,
Malcolm



> Date: Wed, 5 Nov 2014 12:49:33 -1000
> From: Ahnate Lim <ahnate at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Multiple comparison correction?
>
> Hello,
>
> I have a question related to mixed effect modeling and how to do multiple
> comparisons.
>
> We have a longitudinal study with different groups and many dependent
> variables such as of brain cortical volume in different areas, etc.
>
> I am using lme, and remember reading somewhere that multiple comparison
> corrections do not actually apply to linear mixed effects models, due to
> the statistics involved.
>
> For example, if I run the same model on 100 dependent variables,
> traditionally I would need to correct for multiple comparisons by dividing
> the alpha level (0.05) by 100 to get the proper criterion of 0.0005,
> adjusting for the increased likelihood of getting type I errors. I am
> wondering however, if this process is the same, or even necessary at all
> for lme models?
>
> Thank you,
>
> Ahnate
>

	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Fri Nov  7 00:50:25 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 6 Nov 2014 23:50:25 +0000
Subject: [R-sig-ME] Multiple comparison correction?
Message-ID: <51F0C7C54B032A42A23B74A088E7141C2E6CD569@itsnt443.iowa.uiowa.edu>

> Hello,
>
> I have a question related to mixed effect modeling and how to do multiple comparisons.
>
> We have a longitudinal study with different groups and many dependent variables such as of brain cortical volume in different areas, etc.
>
> I am using lme, and remember reading somewhere that multiple comparison corrections do not actually apply to linear mixed effects models, due to the statistics involved.

YIKES! I hope that advice isn't in print, like in a textbook! There are times when you should use corrections, and times when it is acceptable not to. But that doesn't depend on the modeling method, it depends on the character of the inferences needed.

> For example, if I run the same model on 100 dependent variables, traditionally I would need to correct for multiple comparisons by dividing the alpha level (0.05) by 100 to get the proper criterion of 0.0005, adjusting for the increased likelihood of getting type I errors. I am wondering however, if this process is the same, or even necessary at all for lme models?

What's true is that the usual Tukey critical values and such become unreliable when you have vastly different standard errors. But the multcomp package (see especially the glht function) is built to handle that, and it can support lme objects. When several factors are involved, it may be easier to construct them using the lsmeans function (lsmeans package), then use as.glht and you can summarize them like you would the glht results.

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017


From Daniel.Wright at act.org  Fri Nov  7 15:38:56 2014
From: Daniel.Wright at act.org (Daniel Wright)
Date: Fri, 7 Nov 2014 14:38:56 +0000
Subject: [R-sig-ME] Multiple comparison correction?
In-Reply-To: <CAAH-yP__JU4iOXGF5RoWvMvg6PxXVMrvbMhFjG-=g6VedYgAyA@mail.gmail.com>
References: <CAAH-yP__JU4iOXGF5RoWvMvg6PxXVMrvbMhFjG-=g6VedYgAyA@mail.gmail.com>
Message-ID: <c34ebef670d4412fb3e0e9bd6f0f0c61@CO2PR04MB826.namprd04.prod.outlook.com>

Here (http://andrewgelman.com/2014/10/14/one-lifes-horrible-ironies-wrote-paper-usually-dont-worry-multiple-comparisons-now-spend-lots-time-worrying-multiple-comparisons/) is a more recent discussion of Gelman's view on topic.

Daniel B. Wright, Ph.D.
Statistical Research Division 
8701 N. MoPac Expressway, Suite 200, Austin, TX 78759??
(preferred method of communication is email, use cell if urgent)
Office: 512.320.1827
Cell: 786 342 4656 






This email message is intended only for the personal use of the recipient(s) named above. If you are not an intended recipient, you may not review, copy, or distribute this message. If you have received this communication in error, please notify the sender immediately by email and delete the original?message.




-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Malcolm Fairbrother
Sent: Thursday, November 06, 2014 4:39 PM
To: ahnate at gmail.com
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Multiple comparison correction?

Dear Ahnate,

I'm not a particular expert on this topic, but I found Gelman et al.'s views quite interesting:

http://www.stat.wisc.edu/~larget/Stat998/Fall2013/GelmanMultipleComparisons.pdf

>From the sounds of it you'll find the paper useful too.

Cheers,
Malcolm



> Date: Wed, 5 Nov 2014 12:49:33 -1000
> From: Ahnate Lim <ahnate at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Multiple comparison correction?
>
> Hello,
>
> I have a question related to mixed effect modeling and how to do 
> multiple comparisons.
>
> We have a longitudinal study with different groups and many dependent 
> variables such as of brain cortical volume in different areas, etc.
>
> I am using lme, and remember reading somewhere that multiple 
> comparison corrections do not actually apply to linear mixed effects 
> models, due to the statistics involved.
>
> For example, if I run the same model on 100 dependent variables, 
> traditionally I would need to correct for multiple comparisons by 
> dividing the alpha level (0.05) by 100 to get the proper criterion of 
> 0.0005, adjusting for the increased likelihood of getting type I 
> errors. I am wondering however, if this process is the same, or even 
> necessary at all for lme models?
>
> Thank you,
>
> Ahnate
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From s1049258 at sms.ed.ac.uk  Fri Nov  7 12:18:04 2014
From: s1049258 at sms.ed.ac.uk (FERNANDEZ Ana maria)
Date: Fri, 7 Nov 2014 11:18:04 +0000
Subject: [R-sig-ME] MCMCglmm Heterogenous Residual Variance in a Categorial
	Model
Message-ID: <93CBC95C-6C8A-4234-B6BA-347BA18204BF@sms.ed.ac.uk>

Dear List,

I was wondering what the recommendation is for structuring residual variances in the context of a categorial model when you have a sex interaction in the random term of the model (where animal is the pedigree structure).

MCMCglmm course notes have a brief recommendation about sex interaction and allowing the sexes to have different residual variances: "3.4 Heterogenous Residual Variance To be started... In short - if you?ve fitted a sex by dam interaction I would always allow the sexes to have different residual variances. Use rcov=?idh(sex):units.?

But the conflict that I am coming across is another recommendation about how the residual term should be- or needs to be- fixed in a categorical model.

I have a case-control binary response variable and I want to look at the sex effect interaction.

Let me know if you need more detail.

Thanks!
Maria



Ana Maria Fern?ndez Pujals
A.Fernandez-2 at sms.ed.ac.uk<mailto:A.Fernandez-2 at sms.ed.ac.uk>




-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20141107/30b4525e/attachment.pl>

From Greg.Hacker at cdph.ca.gov  Fri Nov  7 19:01:34 2014
From: Greg.Hacker at cdph.ca.gov (Hacker, Greg (CDPH-CID-DCDC))
Date: Fri, 7 Nov 2014 18:01:34 +0000
Subject: [R-sig-ME] glmmadmb random effects help
Message-ID: <CF43A319ADEA8F4C8A3D29B418DC65D4A54A48@057-SN2MPN2-101.057d.mgd.msft.net>

Hello all,

I am hoping to get some expert guidance on an analysis I am attempting.  At the very least I hope you can tell me if I'm on the right track.  If I'm not, maybe you can nudge me in the right direction.

I have data that consists of repeated counts of ticks that were collected at 110 different sites around a portion of a reservoir. These 110 sites were grouped into 11 transects (I'm thinking nesting here).  The counts were collected monthly (although some months were missed) over 3 years (years = Oct-Sept to account for tick biology).  Along with this I have several continuous and categorical ecological variables (e.g., canopy coverage, dominant overstory/understory veg, average temp, relative humidity, aspect, etc...).  I'm hoping to create a candidate set of models that I can then use AIC (or something related) to determine the best fit.  In the end I'm hoping to have a model that can reasonably predict abundance of ticks based on a subset of environmental variables.

>From what I've read I have too few seasons to use as a random effect.  I believe the month, site, and transect variables should all be considered random effects, with site nested in transect.  However, site/transect is also crossed with month and season(fixed effect).  Below I have provided the output (minus the coefs for fixef) from the summary of my global model (at least the most complex model I could use without getting errors).

Call:
glmmadmb(formula = Tot_I_pac ~ SWave.max.temp + ave.rh + SWave.max.temp:ave.rh +
    Perc_Canopy + Dom.Overstory + Perc_Canopy * Dom.Overstory +
    Dom.Midstory + Dom.Understory + Aspect + Soil.Type + fSeason +
    (1 | Month) + (1 | fSite/fTrans), data = Ticks, family = "nbinom")

AIC: 7589

Number of observations: total=3190, Month=11, fSite=110, fSite:fTrans=110
Random effect variance(s):
Group=Month
            Variance StdDev
(Intercept)     18.8  4.336
Group=fSite
            Variance StdDev
(Intercept)   0.1429  0.378
Group=fSite:fTrans
            Variance StdDev
(Intercept)   0.1061 0.3257

Negative binomial dispersion parameter: 1.4 (std. err.: 0.096)

Log-likelihood: -3762

Does everything seem reasonable here? Does the way I wrote the random effects portion of the model relate to the description of the data?  Does this model take into account that month and the site/transect combination are crossed with season?  Finally, is the AIC score provided in the summary what should be used to rank the models or should it be ignored and calculated by hand (does the AICtab function utilize this score)?

Forgive me, I am only a wildlife biologist who knows only enough to get myself into trouble!  Thank you in advance for any advice folks can provide!

Cheers!

Greg

Greg Hacker
Biologist

Public Health Foundation Enterprises
California Department of Public Health
Vector-Borne Disease Section
8633 Bond Rd.,
Elk Grove, CA 95624





	[[alternative HTML version deleted]]


From lucianolasala at yahoo.com.ar  Fri Nov  7 20:06:47 2014
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Fri, 07 Nov 2014 16:06:47 -0300
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 95, Issue 8
In-Reply-To: <mailman.5.1415271602.891.r-sig-mixed-models@r-project.org>
References: <mailman.5.1415271602.891.r-sig-mixed-models@r-project.org>
Message-ID: <545D1847.4000808@yahoo.com.ar>

Hi there,

There was a complete separation issue in my data. Sex was undetermined 
for chicks that died (NAs), so that caused the problem when including 
the variable as a predictor of Survival at day2. Removed Sex and things 
look way better. Thank you guys!

L


El 11/6/2014 8:00 AM, r-sig-mixed-models-request at r-project.org escribi?:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>     1. Re: R-sig-mixed-models Digest, Vol 95, Issue 6 (Ken Beath)
>     2. Re: R-sig-mixed-models Digest, Vol 95, Issue 6 (Ben Bolker)
>     3. error message using glmmADMB (Nagata Mizuho)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 6 Nov 2014 13:38:38 +1100
> From: Ken Beath <ken.beath at mq.edu.au>
> To: Luciano La Sala <lucianolasala at yahoo.com.ar>
> Cc: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 95, Issue 6
> Message-ID:
> 	<CAF5_5czUsT9DFLtntAe5SOkfuqEmXhYQ7Xgfx5n4JQF_i2Or7g at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> nAGQ=0 uses an even more approximate method, so probably isn't advised.
> Looking at your output something has gone seriously wrong. The standard
> errors are all very large and the random effect variance is zero.
>
> Have you checked whether there is a collinearity problem between your fixed
> effects. Start with a model with all the fixed effects and no random and
> see how that works.
>
> On 6 November 2014 13:27, Luciano La Sala <lucianolasala at yahoo.com.ar>
> wrote:
>
>> Dear Ken and Ben,
>>
>> Thank you so much for your prompt responses. This is more frustrating than
>> interesting to me. Weird, but the model runs "smoothly" if I use nAGQ=0
>> (output below). Any value other than that yields the mentioned error. I
>> have no idea how this Gauss-Hermite Quadrature stuff works, or if setting
>> nAGQ to 0 makes my model building strategy (AIC criterion) a poor choice.
>> Should I stick with nAGQ=0 then?
>>
>>> model.1 <- glmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
>> (1|Nest_ID), nAGQ=0, family = binomial, data = surv.2)
>>> summary(model.1)
>>
>> Generalized linear mixed model fit by maximum likelihood (Adaptive
>> Gauss-Hermite Quadrature, nAGQ =  0)
>>   [glmerMod]
>>   Family: binomial  ( logit )
>> Formula: Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 | Nest_ID)
>>     Data: surv.2
>>
>>       AIC      BIC   logLik deviance df.resid
>>      22.0     44.7     -4.0      8.0      182
>>
>> Scaled residuals:
>>      Min      1Q  Median      3Q     Max
>> -0.2291  0.0000  0.0000  0.0000  4.4713
>>
>> Random effects:
>>   Groups  Name        Variance Std.Dev.
>>   Nest_ID (Intercept) 0        0
>> Number of obs: 189, groups:  Nest_ID, 111
>>
>> Fixed effects:
>>                      Estimate Std. Error z value Pr(>|z|)
>> (Intercept)       -4.185e+01  1.538e+04  -0.003    0.998
>> Year2007           1.933e+01  1.096e+04   0.002    0.999
>> Sex               -1.878e+01  1.139e+04  -0.002    0.999
>> Egg_Volume        -5.620e-03  2.077e-01  -0.027    0.978
>> Hatch_OrderSecond  1.997e+01  1.079e+04   0.002    0.999
>> Hatch_OrderThird  -3.482e-01  2.544e+04   0.000    1.000
>>
>> Correlation of Fixed Effects:
>>              (Intr) Yr2007 Sex    Egg_Vl Htc_OS
>> Year2007    -0.713
>> Sex          0.000  0.000
>> Egg_Volume  -0.001  0.000  0.000
>> Htch_OrdrSc -0.701  0.000  0.000  0.000
>> Htch_OrdrTh -0.298  0.000  0.000  0.000  0.424
>>
>> El 11/5/2014 6:38 PM, r-sig-mixed-models-request at r-project.org escribi?:
>>
>>> Send R-sig-mixed-models mailing list submissions to
>>>          r-sig-mixed-models at r-project.org
>>>
>>> To subscribe or unsubscribe via the World Wide Web, visit
>>>          https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> or, via email, send a message with subject or body 'help' to
>>>          r-sig-mixed-models-request at r-project.org
>>>
>>> You can reach the person managing the list at
>>>          r-sig-mixed-models-owner at r-project.org
>>>
>>> When replying, please edit your Subject line so it is more specific
>>> than "Re: Contents of R-sig-mixed-models digest..."
>>>
>>>
>>> Today's Topics:
>>>
>>>      1. Re: Error message (Luciano La Sala)
>>>      2. Re: Error message (Ben Bolker)
>>>      3. Re: subject level predictions with lme4 from     incomplete
>>>         longitudinal profile (Tarca, Adi)
>>>      4. Re: Error message (Ken Beath)
>>>
>>>
>>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Wed, 05 Nov 2014 08:55:27 -0300
>>> From: Luciano La Sala <lucianolasala at yahoo.com.ar>
>>> To: Daniel Wright <Daniel.Wright at act.org>
>>> Cc: "r-sig-mixed-models at r-project.org"
>>>          <r-sig-mixed-models at r-project.org>
>>> Subject: Re: [R-sig-ME] Error message
>>> Message-ID: <545A102F.3030407 at yahoo.com.ar>
>>> Content-Type: text/plain; charset="UTF-8"
>>>
>>> Thank you Dan,
>>>
>>> According to the new version of lme4 I refited my model as follows:
>>>
>>> model <- glmer(Death ~ Year + Sex + Egg Volume + Hatch Order + (1|Nest
>>> ID), family = binomial, data = Data)
>>> summary(model)
>>>
>>> However, the same error message keeps showing up:
>>>
>>>
>>> Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>>> pwrssUpdate
>>>
>>>
>>> Interestingly, if I reduce the model to contain only one main effect
>>> (whichever), say Hatch_Order, things look better:
>>>
>>> model2 <- glmer(Death 2 ~ Hatch Order + (1|Nest_ID), family = binomial,
>>> data = Data) summary(model2)
>>>
>>>
>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>> Approximation) ['glmerMod']
>>> Family: binomial  ( logit )
>>> Formula: Death_2 ~ Hatch_Order + (1 | Nest_ID)
>>>       Data: surv.2
>>>
>>>         AIC      BIC   logLik deviance df.resid
>>>       118.5    131.8    -55.2    110.5      205
>>>
>>> Scaled residuals:
>>>        Min      1Q  Median      3Q     Max
>>> -0.7390 -0.1714 -0.1682 -0.1506  3.7689
>>>
>>> Random effects:
>>>     Groups  Name        Variance Std.Dev.
>>>     Nest_ID (Intercept) 1.586    1.259
>>> Number of obs: 209, groups:  Nest ID, 115
>>>
>>> Fixed effects:
>>>                      Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)        -3.4824     1.1274  -3.089 0.00201 **
>>> Hatch_OrderSecond  -0.1266     0.7576  -0.167  0.86729
>>> Hatch_OrderThird    2.0486     0.7572   2.705  0.00682 **
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> Correlation of Fixed Effects:
>>>                (Intr) Htc_OS
>>> Htch_OrdrSc -0.111
>>> Htch_OrdrTh -0.709  0.276
>>>
>>>
>>> Any pointers please? Best. Luciano
>>>
>>>
>>>
>>> El 10/22/2014 6:35 PM, Daniel Wright escribi? The lme4 package has
>>> changed some. Details are inhttp://arxiv.org/pdf/1406.5823.pdf
>>>
>>>>
>>>> For your problem, the first thing to note is glmer is now used instead
>>>> of lmer for generalized linear models.  Glancing at your model the other
>>>> bits look like they should work.
>>>>
>>>> Dan
>>>>
>>>> Daniel B. Wright, Ph.D.
>>>> Statistical Research Division
>>>> 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
>>>> (preferred method of communication is email, use cell if urgent)
>>>> Office: 512.320.1827
>>>> Cell: 786 342 4656
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> This email message is intended only for the personal use of the
>>>> recipient(s) named above. If you are not an intended recipient, you may not
>>>> review, copy, or distribute this message. If you have received this
>>>> communication in error, please notify the sender immediately by email and
>>>> delete the original message.
>>>>
>>>>
>>>>
>>>> -----Original Message-----
>>>> From:r-sig-mixed-models-bounces at r-project.org  [mailto:
>>>> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luciano La Sala
>>>> Sent: Wednesday, October 22, 2014 4:20 PM
>>>> Cc:r-sig-mixed-models at r-project.org
>>>> Subject: [R-sig-ME] Error message
>>>>
>>>> Hello,
>>>>
>>>> A few years back I used to fit GLMM (binomial response) using lmer
>>>> function in lme4. Back then I had to specify the family of response
>>>> variable  (dead /alive) as binomial. Now I have to refit those models using
>>>> quite newer versions of both R (R x64 3.1.1) and lme4 (lme4_1.1-7), but
>>>> things seem to have changed quite a bit.
>>>>
>>>> My response variable is death (yes/no), and independent variables are
>>>> Year (2006 / 2007), Sex (M / F), Egg volume (continuous), and Hatching
>>>> Order (ordered factor variable, namely first, second, third). I need to
>>>> control autocorrelation among siblings, so I use "Nest ID" to fit random
>>>> intercepts for different nests.
>>>>
>>>> My model is:
>>>>
>>>> model.1 <- lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order +
>>>> (1|Nest_ID), family = binomial, data = Data)
>>>> summary(model.1)
>>>>
>>>> But I get the error and warning messages below:
>>>>
>>>> Error in eval(expr, envir, enclos) :
>>>>       (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>>>> pwrssUpdate In addition:Warning message:
>>>> In lmer(Death_2 ~ Year + Sex + Egg_Volume + Hatch_Order + (1 |
>>>> Nest_ID),  :
>>>>       calling lmer with 'family' is deprecated; please use glmer() instead
>>>>
>>>>
>>>> Question: how can I circumvent these two issues?
>>>>
>>>> Thanks in advance.
>>>>
>>>> Luciano
>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org  mailing listhttps://stat.ethz.ch/
>>>> mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>> --
>> Luciano F. La Sala
>> Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
>> C?tedra de Epidemiolog?a
>> Departamento de Biolog?a, Bioqu?mica y Farmacia
>> Universidad Nacional del Sur
>> San Juan 670
>> Bah?a Blanca (8000)
>> Argentina
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>

-- 
Luciano F. La Sala
Consejo Nacional de Investigaciones Cient?ficas y T?cnicas (CONICET)
C?tedra de Epidemiolog?a
Departamento de Biolog?a, Bioqu?mica y Farmacia
Universidad Nacional del Sur
San Juan 670
Bah?a Blanca (8000)
Argentina


From j.hadfield at ed.ac.uk  Fri Nov  7 21:38:09 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 07 Nov 2014 20:38:09 +0000
Subject: [R-sig-ME] MCMCglmm Heterogenous Residual Variance in a
 Categorial Model
In-Reply-To: <93CBC95C-6C8A-4234-B6BA-347BA18204BF@sms.ed.ac.uk>
References: <93CBC95C-6C8A-4234-B6BA-347BA18204BF@sms.ed.ac.uk>
Message-ID: <20141107203809.17832zk2s5vc7o4k@www.staffmail.ed.ac.uk>

Hi Maria,

You are right - for a categorical variable the units variance cannot  
be estimated for either sex. You can safely use rcov=~units and set  
the variance to one in the prior.

Cheers,

Jarrod

Quoting FERNANDEZ Ana maria <s1049258 at sms.ed.ac.uk> on Fri, 7 Nov 2014  
11:18:04 +0000:

> Dear List,
>
> I was wondering what the recommendation is for structuring residual  
> variances in the context of a categorial model when you have a sex  
> interaction in the random term of the model (where animal is the  
> pedigree structure).
>
> MCMCglmm course notes have a brief recommendation about sex  
> interaction and allowing the sexes to have different residual  
> variances: "3.4 Heterogenous Residual Variance To be started... In  
> short - if you?ve fitted a sex by dam interaction I would always  
> allow the sexes to have different residual variances. Use  
> rcov=?idh(sex):units.?
>
> But the conflict that I am coming across is another recommendation  
> about how the residual term should be- or needs to be- fixed in a  
> categorical model.
>
> I have a case-control binary response variable and I want to look at  
> the sex effect interaction.
>
> Let me know if you need more detail.
>
> Thanks!
> Maria
>
>
>
> Ana Maria Fern?ndez Pujals
> A.Fernandez-2 at sms.ed.ac.uk<mailto:A.Fernandez-2 at sms.ed.ac.uk>
>
>
>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ahnate at gmail.com  Sat Nov  8 00:44:37 2014
From: ahnate at gmail.com (Ahnate Lim)
Date: Fri, 7 Nov 2014 13:44:37 -1000
Subject: [R-sig-ME] Multiple comparison correction?
In-Reply-To: <c34ebef670d4412fb3e0e9bd6f0f0c61@CO2PR04MB826.namprd04.prod.outlook.com>
References: <CAAH-yP__JU4iOXGF5RoWvMvg6PxXVMrvbMhFjG-=g6VedYgAyA@mail.gmail.com>
	<c34ebef670d4412fb3e0e9bd6f0f0c61@CO2PR04MB826.namprd04.prod.outlook.com>
Message-ID: <CAJuw=B72MP3vWsEc-x1v+5JgB=kRtAiAbhTjwVhDpf+Wt=hBcw@mail.gmail.com>

Hello,

Thank you for your replies. Gelman's 2012 paper is the one I had come
across earlier. I guess I'm wondering whether our situation would be one
where it would be acceptable not to use multiple comparison correction? Or
perhaps some rule of thumb to use to evaluate when it would be acceptable?
I haven't worked through the entirety of Gelman's papers yet. I have used
lsmeans on lme objects before, but am not as familiar with glht.

Our dataset involves repeated measures (at variable time points) of
cortical brain measurements for children over several years. We are
interested in effects of gender and prenatal drug exposure on these regions
of interest measurements (~200 indices of brain thickness, area, and
volume). Of the 200 measurements, there are about 8 with significant group
results, p-values between .05 and .001, hence the concern about multiple
comparisons.

Much aloha,
Ahnate


On Fri, Nov 7, 2014 at 4:38 AM, Daniel Wright <Daniel.Wright at act.org> wrote:

> Here (
> http://andrewgelman.com/2014/10/14/one-lifes-horrible-ironies-wrote-paper-usually-dont-worry-multiple-comparisons-now-spend-lots-time-worrying-multiple-comparisons/)
> is a more recent discussion of Gelman's view on topic.
>
> Daniel B. Wright, Ph.D.
> Statistical Research Division
> 8701 N. MoPac Expressway, Suite 200, Austin, TX 78759
> (preferred method of communication is email, use cell if urgent)
> Office: 512.320.1827
> Cell: 786 342 4656
>
>
>
>
>
>
> This email message is intended only for the personal use of the
> recipient(s) named above. If you are not an intended recipient, you may not
> review, copy, or distribute this message. If you have received this
> communication in error, please notify the sender immediately by email and
> delete the original message.
>
>
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Malcolm Fairbrother
> Sent: Thursday, November 06, 2014 4:39 PM
> To: ahnate at gmail.com
> Cc: r-sig-mixed-models
> Subject: Re: [R-sig-ME] Multiple comparison correction?
>
> Dear Ahnate,
>
> I'm not a particular expert on this topic, but I found Gelman et al.'s
> views quite interesting:
>
>
> http://www.stat.wisc.edu/~larget/Stat998/Fall2013/GelmanMultipleComparisons.pdf
>
> >From the sounds of it you'll find the paper useful too.
>
> Cheers,
> Malcolm
>
>
>
> > Date: Wed, 5 Nov 2014 12:49:33 -1000
> > From: Ahnate Lim <ahnate at gmail.com>
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Multiple comparison correction?
> >
> > Hello,
> >
> > I have a question related to mixed effect modeling and how to do
> > multiple comparisons.
> >
> > We have a longitudinal study with different groups and many dependent
> > variables such as of brain cortical volume in different areas, etc.
> >
> > I am using lme, and remember reading somewhere that multiple
> > comparison corrections do not actually apply to linear mixed effects
> > models, due to the statistics involved.
> >
> > For example, if I run the same model on 100 dependent variables,
> > traditionally I would need to correct for multiple comparisons by
> > dividing the alpha level (0.05) by 100 to get the proper criterion of
> > 0.0005, adjusting for the increased likelihood of getting type I
> > errors. I am wondering however, if this process is the same, or even
> > necessary at all for lme models?
> >
> > Thank you,
> >
> > Ahnate
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Mon Nov 10 09:10:35 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 10 Nov 2014 08:10:35 +0000
Subject: [R-sig-ME] glmmadmb random effects help
In-Reply-To: <CF43A319ADEA8F4C8A3D29B418DC65D4A54A48@057-SN2MPN2-101.057d.mgd.msft.net>
References: <CF43A319ADEA8F4C8A3D29B418DC65D4A54A48@057-SN2MPN2-101.057d.mgd.msft.net>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B36419@inbomail.inbo.be>

Dear Greg,

You need to use (1|fTrans/fSite). This is site nested in transect. Note that the random effect of transect should have 11 observation and not 110 as in your current summary.

Month will be crossed with site (and transect).

You could calculate the AIC by hand to check if the AIC in the summary is correct.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] namens Hacker, Greg (CDPH-CID-DCDC) [Greg.Hacker at cdph.ca.gov]
Verzonden: vrijdag 7 november 2014 19:01
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] glmmadmb random effects help

Hello all,

I am hoping to get some expert guidance on an analysis I am attempting.  At the very least I hope you can tell me if I'm on the right track.  If I'm not, maybe you can nudge me in the right direction.

I have data that consists of repeated counts of ticks that were collected at 110 different sites around a portion of a reservoir. These 110 sites were grouped into 11 transects (I'm thinking nesting here).  The counts were collected monthly (although some months were missed) over 3 years (years = Oct-Sept to account for tick biology).  Along with this I have several continuous and categorical ecological variables (e.g., canopy coverage, dominant overstory/understory veg, average temp, relative humidity, aspect, etc...).  I'm hoping to create a candidate set of models that I can then use AIC (or something related) to determine the best fit.  In the end I'm hoping to have a model that can reasonably predict abundance of ticks based on a subset of environmental variables.

>From what I've read I have too few seasons to use as a random effect.  I believe the month, site, and transect variables should all be considered random effects, with site nested in transect.  However, site/transect is also crossed with month and season(fixed effect).  Below I have provided the output (minus the coefs for fixef) from the summary of my global model (at least the most complex model I could use without getting errors).

Call:
glmmadmb(formula = Tot_I_pac ~ SWave.max.temp + ave.rh + SWave.max.temp:ave.rh +
    Perc_Canopy + Dom.Overstory + Perc_Canopy * Dom.Overstory +
    Dom.Midstory + Dom.Understory + Aspect + Soil.Type + fSeason +
    (1 | Month) + (1 | fSite/fTrans), data = Ticks, family = "nbinom")

AIC: 7589

Number of observations: total=3190, Month=11, fSite=110, fSite:fTrans=110
Random effect variance(s):
Group=Month
            Variance StdDev
(Intercept)     18.8  4.336
Group=fSite
            Variance StdDev
(Intercept)   0.1429  0.378
Group=fSite:fTrans
            Variance StdDev
(Intercept)   0.1061 0.3257

Negative binomial dispersion parameter: 1.4 (std. err.: 0.096)

Log-likelihood: -3762

Does everything seem reasonable here? Does the way I wrote the random effects portion of the model relate to the description of the data?  Does this model take into account that month and the site/transect combination are crossed with season?  Finally, is the AIC score provided in the summary what should be used to rank the models or should it be ignored and calculated by hand (does the AICtab function utilize this score)?

Forgive me, I am only a wildlife biologist who knows only enough to get myself into trouble!  Thank you in advance for any advice folks can provide!

Cheers!

Greg

Greg Hacker
Biologist

Public Health Foundation Enterprises
California Department of Public Health
Vector-Borne Disease Section
8633 Bond Rd.,
Elk Grove, CA 95624





        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From m.spronken at psych.ru.nl  Tue Nov 11 11:48:30 2014
From: m.spronken at psych.ru.nl (Spronken, M. (Maitta))
Date: Tue, 11 Nov 2014 11:48:30 +0100 (CET)
Subject: [R-sig-ME] parallel option of the bootMer function: warnings for
 parallel=no, but not for parallel=snow
In-Reply-To: <1533102227.9672219.1415626862665.JavaMail.root@sculptor.zimbra.ru.nl>
Message-ID: <1305125606.9682315.1415702910011.JavaMail.root@sculptor.zimbra.ru.nl>

Hi Henrik,

Thank you very much for your reply! (and sorry for my very late response). I tried to make a minimal reproducible example by using a subset of my data, but I did not manage to replicate the exact same pattern of warnings. However, I am happy to email the original dataset and the script to whomever is interested in this problem and willing to help solve it. 

To summarize the problem, when bootstrapping my model, I get the following pattern of warnings:
- When using set.seed(80) on Windows, parallel="no" and parallel="multicore" give warnings while parallel="snow" does not. When using set.seed(100) on Windows, neither parallel="no" and parallel="multicore" nor parallel="snow" give warnings. 
- When using a Mac, for both set.seed(80) and set.seed(100), parallel="no" gives warnings while parallel="multicore" and parallel="snow" do not.

Thank you very much in advance for any suggestions!
Maitta


From markpayneatwork at gmail.com  Tue Nov 11 13:22:33 2014
From: markpayneatwork at gmail.com (Mark Payne)
Date: Wed, 12 Nov 2014 01:22:33 +1300
Subject: [R-sig-ME] Offset() in gls() in nlme
Message-ID: <CAGBzUO9pFA3hZSTOUb_CLwwyY06jgGWOqGo=Si1ta+zPWd15zQ@mail.gmail.com>

Hi,

I am trying to use the following model formula in gls() in the nlme package:

R ~ Turb + offset(ssb)

Unfortunately, gls() seems to ignore the offset argument and give results
that are identical to

R ~ Turb

This is not the case when I use lm() - however, I would like to include a
corAR1() term as well, which is why I am using gls().

Is this known and intended behaviour? If so, is there a recommended
workaround/alternative?

Best wishes,

Mark

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Nov 11 14:38:44 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 11 Nov 2014 13:38:44 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Extract_standard_error_of_the_variance_compo?=
	=?utf-8?q?nent_in_lme4=09package_=28GLMM=29=2E?=
References: <CADtmEn5oEa+ghBxZkNf2vedmXAgkNCqBZthuOnjhAQaEpXUWUQ@mail.gmail.com>
Message-ID: <loom.20141111T143716-876@post.gmane.org>

Mart? Casals <mcasals at ...> writes:

> 
> Dear all,
> 
> I?ve fitted  a classical Poisson GLMM with lme4. I obtain the variance of
> random effect (variance component) with the following script:
> 
> print(VarCorr(model),comp="Variance")
> 
> but I?d like to print the standard error of the variance component. I think
> it is possible with the new version of the lme4 package. How it can be
> obtain?
> 
> Thanks in advance,
> 
> Mart?
> 


  See e.g. http://www.rpubs.com/bbolker/varwald ... keeping in mind
that the standard error is not necessarily reliable for computing
confidence intervals (e.g. the sampling distribution of the 
standard error can be far from Normal)


From ezzet001 at gmail.com  Tue Nov 11 15:02:33 2014
From: ezzet001 at gmail.com (Farkad Ezzet)
Date: Tue, 11 Nov 2014 09:02:33 -0500
Subject: [R-sig-ME] Proportional Error model in nlme using weights
Message-ID: <083d01cffdb8$248353f0$6d89fbd0$@gmail.com>

Hi,

 

I am wondering if the mixed-model community have suggestions to solve the
following problem: 

nlme in R fails when specifying an error model using "weights= varPower()".
Other error specifications, e.g. varExp and varConstPower also fail. It
seems that implementation of nlme in R is the culprit, since these error
models work perfectly fine using nlme in Splus. Here is a simple example
that attempts to model Pharmacokinetic data generated by simulation using a
one compartment intravenous dose. The code runs and estimates parameters
correctly in Splus, but it fails in R producing the error message "Error in
nlme.formula(conc ~ comp1.iv(ke * exp(eta.ke), v * exp(eta.v),  : step
halving factor reduced below minimum in PNLS step". 

 

Here is the code in R:

 

library(nlme)

 

comp1.iv =

  function(ke, v, dose, time)

  {

    (dose/v) * exp(- ( ke * time ) ) 

  }

 

# function to simulate data

comp1.iv.Data = function(nsub, ke, v, cv.ke, cv.v, cv.error, d1, d2, time,
dose)

{

  set.seed(123)

  

  nsub0 <- nsub

  sub0   <- 1:nsub0

  time0 <- time

  dose0 <- dose

  

  eta.ke <- rnorm(nsub0,0,cv.ke)

  eta.v  <- rnorm(nsub0,0,cv.v)

  

  ke0 <- ke * exp(eta.ke)

  v0  <- v  * exp(eta.v)

  

  nobsid <- length(time0)*length(dose0)

  sub <- rep(sub0, each=nobsid)

  nobs   <- nobsid*nsub0

  time <- rep(time0,length(dose0)*nsub0)

  dose <- rep(rep(dose0, each=length(time0)),nsub0)

  

  ke <- rep(ke0, each=nobsid)

  v  <- rep(v0 , each=nobsid)

  

  x0 <- comp1.iv(ke,v,dose,time)

  

  conc <- x0 + (d1 + d2*x0) * rnorm(length(x0),0,cv.error)

  

  D = data.frame(id=sub, dose=dose, time= time, ke=ke, v=v, x0=x0,conc=conc)


  D = groupedData(conc~time| id, data =D)

  return(D)

} # end of comp1.iv.Data

 

# create data set with different error models

time = c(0,1,2,3,4,6,8,10, 12,18, 24)

dose = c(5)

 

iv.D1   = comp1.iv.Data(nsub=24,ke=.1, v=4,cv.ke=.1, cv.v=.1,
cv.error=0.1,d1=1, d2=0, time, dose) # additive

iv.D2   = comp1.iv.Data(nsub=24,ke=.1, v=4,cv.ke=.1, cv.v=.1,
cv.error=0.1,d1=0, d2=1, time, dose) # proportional

iv.D3   = comp1.iv.Data(nsub=24,ke=.1, v=4,cv.ke=.1, cv.v=.1,
cv.error=0.1,d1=1, d2=1, time, dose) # additive & proportional 

 

mean(iv.D1$conc)

mean(iv.D2$conc)

mean(iv.D3$conc)

 

# Run nlme with additive error using iv.D1

M1 = nlme(conc ~ 

            comp1.iv(ke*exp(eta.ke), v*exp(eta.v), dose=5, time) ,

          data=iv.D1, 

          random = pdDiag(list(eta.ke + eta.v ~ 1)),

          fixed = list(ke+v~ 1),

          start = c(.1, 4), verbose = T)

summary(M1)

 

# Run nlme with proportional error using iv.D2

M2 = nlme(conc ~ 

            comp1.iv(ke*exp(eta.ke), v*exp(eta.v), dose=5, time) ,

          data=iv.D2, 

          random = pdDiag(list(eta.ke + eta.v ~ 1)),

          fixed = list(ke+v~ 1),

          start = c(.1, 4), verbose = T, weights=varPower(1))

 

# Run nlme with additive & proportional error using iv.D3

M3 = nlme(conc ~ 

            comp1.iv(ke*exp(eta.ke), v*exp(eta.v), dose=5, time) ,

          data=iv.D3, 

          random = pdDiag(list(eta.ke + eta.v ~ 1)),

          fixed = list(ke+v~ 1),

          start = c(.1, 4), verbose = T, weights=varConstPower(const=1,
fixed=list(power=1)))

 

#===========================================================================
=======================

Results from the splus output are as follows:

 

 

Farkad Ezzet, MSc, PhD

Office  973 665-1447

Mobile 201 738-3826

 <mailto:fezzet at aycerpc.com> fezzet at aycerpc.com

 <http://www.aycerpc.com/> www.aycerpc.com

 <http://www.linkedin.com/pub/farkad-ezzet/11/28b/93a>
http://www.linkedin.com/pub/farkad-ezzet/11/28b/93a

 

 

 

 


	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Wed Nov 12 09:52:11 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 12 Nov 2014 08:52:11 +0000
Subject: [R-sig-ME] Offset() in gls() in nlme
In-Reply-To: <CAGBzUO9pFA3hZSTOUb_CLwwyY06jgGWOqGo=Si1ta+zPWd15zQ@mail.gmail.com>
References: <CAGBzUO9pFA3hZSTOUb_CLwwyY06jgGWOqGo=Si1ta+zPWd15zQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B38DF0@inbomail.inbo.be>

Dear Mark,

In case of a linear model you can create a new variable Y = R - ssb and model Y without offset instead of R with ssb as offset. That should give the same parameter estimates.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Mark Payne
Verzonden: dinsdag 11 november 2014 13:23
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Offset() in gls() in nlme

Hi,

I am trying to use the following model formula in gls() in the nlme package:

R ~ Turb + offset(ssb)

Unfortunately, gls() seems to ignore the offset argument and give results that are identical to

R ~ Turb

This is not the case when I use lm() - however, I would like to include a
corAR1() term as well, which is why I am using gls().

Is this known and intended behaviour? If so, is there a recommended workaround/alternative?

Best wishes,

Mark

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From rafael.wueest at gmail.com  Wed Nov 12 11:57:47 2014
From: rafael.wueest at gmail.com (=?UTF-8?B?UmFmYWVsIFfDvGVzdA==?=)
Date: Wed, 12 Nov 2014 11:57:47 +0100
Subject: [R-sig-ME] response correlated among groups
Message-ID: <54633D2B.4070006@gmail.com>

Dear list members

I would like to fit a model relating a gaussian response variable y to some continuous predictor variables (p1 and p2). 
The response is correlated among the classes of a factor (p3).

Is it possible to set up a mixed model that accounts for the correlations among classes of p3 in the response?

I would appreciate help on how to code such a model, if possible.

Many thanks in advance,
Rafael

-- 
Rafael W?est
rafael.wueest at gmail.com
http://www.rowueest.net


From bbolker at gmail.com  Wed Nov 12 14:09:34 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 12 Nov 2014 08:09:34 -0500
Subject: [R-sig-ME] response correlated among groups
In-Reply-To: <54633D2B.4070006@gmail.com>
References: <54633D2B.4070006@gmail.com>
Message-ID: <CABghstRyB-wjhX87ngz86_dwRAU-K_yCRAycUJCBd2YBg4mgSQ@mail.gmail.com>

I think I would handle this as a stacked multivariate model:
http://www.rpubs.com/bbolker/3336 gives some examples.

On Wed, Nov 12, 2014 at 5:57 AM, Rafael W?est <rafael.wueest at gmail.com>
wrote:

> Dear list members
>
> I would like to fit a model relating a gaussian response variable y to
> some continuous predictor variables (p1 and p2). The response is correlated
> among the classes of a factor (p3).
>
> Is it possible to set up a mixed model that accounts for the correlations
> among classes of p3 in the response?
>
> I would appreciate help on how to code such a model, if possible.
>
> Many thanks in advance,
> Rafael
>
> --
> Rafael W?est
> rafael.wueest at gmail.com
> http://www.rowueest.net
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Wed Nov 12 16:54:42 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 12 Nov 2014 15:54:42 +0000
Subject: [R-sig-ME] Offset() in gls() in nlme
References: <CAGBzUO9pFA3hZSTOUb_CLwwyY06jgGWOqGo=Si1ta+zPWd15zQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B38DF0@inbomail.inbo.be>
Message-ID: <CAO7JsnQRGRLLEcs8x3u7baPv27d3Gm8zWrzKMGWvWs8fR7ywqw@mail.gmail.com>

It may work if  you use the offset argument instead of putting an offset
term in the formula.  The model-fitting code in R (and S before it)
sometimes has the "there's more than one way to do it" approach of Perl.
This is convenient for users but not for those writing the code.  I believe
we implemented the offset argument form.

On Wed Nov 12 2014 at 2:52:30 AM ONKELINX, Thierry <Thierry.ONKELINX at inbo.be>
wrote:

> Dear Mark,
>
> In case of a linear model you can create a new variable Y = R - ssb and
> model Y without offset instead of R with ssb as offset. That should give
> the same parameter estimates.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] Namens Mark Payne
> Verzonden: dinsdag 11 november 2014 13:23
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Offset() in gls() in nlme
>
> Hi,
>
> I am trying to use the following model formula in gls() in the nlme
> package:
>
> R ~ Turb + offset(ssb)
>
> Unfortunately, gls() seems to ignore the offset argument and give results
> that are identical to
>
> R ~ Turb
>
> This is not the case when I use lm() - however, I would like to include a
> corAR1() term as well, which is why I am using gls().
>
> Is this known and intended behaviour? If so, is there a recommended
> workaround/alternative?
>
> Best wishes,
>
> Mark
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From aneta871 at yahoo.com  Wed Nov 12 19:06:18 2014
From: aneta871 at yahoo.com (Aneta)
Date: Wed, 12 Nov 2014 18:06:18 +0000 (UTC)
Subject: [R-sig-ME] ANOVA for large data sets
Message-ID: <1584432005.141445.1415815578729.JavaMail.yahoo@jws100144.mail.ne1.yahoo.com>

 Hi Everyone,
I am very new to R programming and I need your help regarding two way ANOVA model.
I have one variable?(response) and three factors (Source, Batch and Time). I am always going to have a difference within time so probably I do not want to include it (??) in the analysis. 
I need to identify if there is a difference between the Source. I know how to run the test for one sample. However I do not know how to process multiple samples (large data sets) with multiple variables sharing the same three factors.
Please help me out! Please let me know if you need more clarification and I will be happy to provide it to you.
I am looking forward to your response.
Best!
Aneta
	[[alternative HTML version deleted]]


From abedimail at gmail.com  Fri Nov 14 11:21:45 2014
From: abedimail at gmail.com (Mehdi Abedi)
Date: Fri, 14 Nov 2014 13:51:45 +0330
Subject: [R-sig-ME] Crossed and nested factors in experimental designs: Are
 there any flowcharts for decision making?
Message-ID: <CADGhaghBEVKNYyRrhgStopbFTJxx4zNV+fG417jmGrAk-jwSBA@mail.gmail.com>

Dear all,

I am following your nice discussion in this group. Considering your high
level discussion in this group i was not sure to ask basic problems in the
mailing list!, therefore, i asked this question in researchgate.

I think several researchers have this kind of question which your guidance
can also help them using mixed models in their researches. I can imagine
that teaching advanced statistic with simple language is not easy. However
in addition to advanced statistic books and codes, introducing experimental
design and their link to mixed models using simple codes would be valuable
as well.

It would be my pleasure to have your suggestion here or in this link:

Warm regards

Mehdi:

https://www.researchgate.net/post/With_regards_to_crossed_and_nested_factors_in_experimental_designs_Are_there_any_flowcharts_for_decision_making

Ecological researches mainly have complicated statistical design. Mixed
models can test complicated designs with different crossed or nested
factors. For instance lme4 and nlme could be used in R. However, still
decision about statistical design is complicated for most researchers.

Mixed models are quit an advanced method for most researchers and recent
publications still use simple statistical designs. For instance most
publications in high ranked journals related to plant ecophysiology and
seed researches still apply only factorial design for the statistical
analysis and not mixed models including random and fixed factors.

Could you recommend some references or lectures introducing nested, crossed
design with simple examples and simple codes in R?. I mean some simple
explanation without details which start from simple design to complicated
design like http://conjugateprior.org/2013/01/formulae-in-r-anova/
<https://www.researchgate.net/go.Deref.html?url=http%3A%2F%2Fconjugateprior.org%2F2013%2F01%2Fformulae-in-r-anova%2F>

Graphical designs showing these crossed and nested would also be useful.
This information would be very helpful for both teachers and researchers
for application correct statistical analysis.

-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Nov 14 14:10:57 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 14 Nov 2014 08:10:57 -0500
Subject: [R-sig-ME] Crossed and nested factors in experimental designs:
 Are there any flowcharts for decision making?
In-Reply-To: <CADGhaghBEVKNYyRrhgStopbFTJxx4zNV+fG417jmGrAk-jwSBA@mail.gmail.com>
References: <CADGhaghBEVKNYyRrhgStopbFTJxx4zNV+fG417jmGrAk-jwSBA@mail.gmail.com>
Message-ID: <5465FF61.9090607@gmail.com>

On 14-11-14 05:21 AM, Mehdi Abedi wrote:
> Dear all,
> 
> I am following your nice discussion in this group. Considering your high
> level discussion in this group i was not sure to ask basic problems in the
> mailing list!, therefore, i asked this question in researchgate.
> 
> I think several researchers have this kind of question which your guidance
> can also help them using mixed models in their researches. I can imagine
> that teaching advanced statistic with simple language is not easy. However
> in addition to advanced statistic books and codes, introducing experimental
> design and their link to mixed models using simple codes would be valuable
> as well.
> 
> It would be my pleasure to have your suggestion here or in this link:
> 
> Warm regards
> 
> Mehdi:
> 
> https://www.researchgate.net/post/With_regards_to_crossed_and_nested_factors_in_experimental_designs_Are_there_any_flowcharts_for_decision_making
> 
> Ecological researches mainly have complicated statistical design. Mixed
> models can test complicated designs with different crossed or nested
> factors. For instance lme4 and nlme could be used in R. However, still
> decision about statistical design is complicated for most researchers.
> 
> Mixed models are quit an advanced method for most researchers and recent
> publications still use simple statistical designs. For instance most
> publications in high ranked journals related to plant ecophysiology and
> seed researches still apply only factorial design for the statistical
> analysis and not mixed models including random and fixed factors.
> 
> Could you recommend some references or lectures introducing nested, crossed
> design with simple examples and simple codes in R?. I mean some simple
> explanation without details which start from simple design to complicated
> design like http://conjugateprior.org/2013/01/formulae-in-r-anova/
> <https://www.researchgate.net/go.Deref.html?url=http%3A%2F%2Fconjugateprior.org%2F2013%2F01%2Fformulae-in-r-anova%2F>
> 
> Graphical designs showing these crossed and nested would also be useful.
> This information would be very helpful for both teachers and researchers
> for application correct statistical analysis.

  It's pretty basic, but I like the section in Gotelli and Ellison's
_Primer of Ecological Statistics_.  They don't really get as far as
crossed random effects, but they do discuss nested, randomized block,
split-plot, and factorial (i.e. _crossed fixed effect_) designs.

  Ben Bolker



>


From dstr7320 at uni.sydney.edu.au  Fri Nov 14 01:00:17 2014
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Fri, 14 Nov 2014 00:00:17 +0000
Subject: [R-sig-ME] Formula Explanation in lme4 Vignette
Message-ID: <1415923216344.19605@uni.sydney.edu.au>

Hello,

In the software article vignette, it says that

resp ~ FEexpr + (REexpr1|factor1)

is the general format of mixed models. However, there's a sleep study example which has

fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)

When I look at those two formulae, I see that Days matches both FEexpr and REexpr1. I thought that a factor could be a fixed effect or random effect, but not both. In lectures, I remember fixed and random effects as being exclusive, depending on if all the levels were measured, or just a subset of them.

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia


From emmanuel.curis at parisdescartes.fr  Fri Nov 14 14:38:19 2014
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Fri, 14 Nov 2014 14:38:19 +0100
Subject: [R-sig-ME] Formula Explanation in lme4 Vignette
In-Reply-To: <1415923216344.19605@uni.sydney.edu.au>
References: <1415923216344.19605@uni.sydney.edu.au>
Message-ID: <20141114133819.GA4228@info124.pharmacie.univ-paris5.fr>

Hello,

In lme4 formula syntax, random effects factors are on the right side
of the pipe (|). On the left side, you can have only 1 or other fixed
effects factors to include interactions between fixed effects and
random effects factors.

So this example does not violate your lecture, saying that a factor
can be with random or fixed effects, not both : Subject is the random
effect factor, Days the fixed effects, and Days | Subject introduces
an interaction between them --- that is, the Subject random effect is
different for each Days level.

Hope this helps,
Best regards,

On Fri, Nov 14, 2014 at 12:00:17AM +0000, Dario Strbenac wrote:
? Hello,
? 
? In the software article vignette, it says that
? 
? resp ~ FEexpr + (REexpr1|factor1)
? 
? is the general format of mixed models. However, there's a sleep study example which has
? 
? fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
? 
? When I look at those two formulae, I see that Days matches both FEexpr and REexpr1. I thought that a factor could be a fixed effect or random effect, but not both. In lectures, I remember fixed and random effects as being exclusive, depending on if all the levels were measured, or just a subset of them.
? 
? --------------------------------------
? Dario Strbenac
? PhD Student
? University of Sydney
? Camperdown NSW 2050
? Australia
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From abedimail at gmail.com  Fri Nov 14 14:41:06 2014
From: abedimail at gmail.com (Mehdi Abedi)
Date: Fri, 14 Nov 2014 17:11:06 +0330
Subject: [R-sig-ME] Crossed and nested factors in experimental designs:
 Are there any flowcharts for decision making?
In-Reply-To: <5465FF61.9090607@gmail.com>
References: <CADGhaghBEVKNYyRrhgStopbFTJxx4zNV+fG417jmGrAk-jwSBA@mail.gmail.com>
	<5465FF61.9090607@gmail.com>
Message-ID: <CADGhagh3AQU5bDd3zxzf1qC6oZkHd58phgNR3KWj2qeNr9XWYw@mail.gmail.com>

Dear Ben,
Thanks for your kind introducing this reference. I also read
"Biostatistical Design and Analysis Using R
A Practical Guide" by Logan which was very useful for statistical design.

Linking classical ANOVAs with mixed model is still confusing for me because
i have to collect information from different books (design from classic
book and mixed model from new books). Due to importance of random effects
in mixed model, misunderstanding designs can fully affect on analysis. I
worry to wrongly connect the basic experimental designs with mixed models.
Therefore, i asked group to introduce references talking about both
experimental design and mixed model in the same book or text avoiding this
mistake.
Warm regards
Mehdi

On Fri, Nov 14, 2014 at 4:40 PM, Ben Bolker <bbolker at gmail.com> wrote:

> On 14-11-14 05:21 AM, Mehdi Abedi wrote:
> > Dear all,
> >
> > I am following your nice discussion in this group. Considering your high
> > level discussion in this group i was not sure to ask basic problems in
> the
> > mailing list!, therefore, i asked this question in researchgate.
> >
> > I think several researchers have this kind of question which your
> guidance
> > can also help them using mixed models in their researches. I can imagine
> > that teaching advanced statistic with simple language is not easy.
> However
> > in addition to advanced statistic books and codes, introducing
> experimental
> > design and their link to mixed models using simple codes would be
> valuable
> > as well.
> >
> > It would be my pleasure to have your suggestion here or in this link:
> >
> > Warm regards
> >
> > Mehdi:
> >
> >
> https://www.researchgate.net/post/With_regards_to_crossed_and_nested_factors_in_experimental_designs_Are_there_any_flowcharts_for_decision_making
> >
> > Ecological researches mainly have complicated statistical design. Mixed
> > models can test complicated designs with different crossed or nested
> > factors. For instance lme4 and nlme could be used in R. However, still
> > decision about statistical design is complicated for most researchers.
> >
> > Mixed models are quit an advanced method for most researchers and recent
> > publications still use simple statistical designs. For instance most
> > publications in high ranked journals related to plant ecophysiology and
> > seed researches still apply only factorial design for the statistical
> > analysis and not mixed models including random and fixed factors.
> >
> > Could you recommend some references or lectures introducing nested,
> crossed
> > design with simple examples and simple codes in R?. I mean some simple
> > explanation without details which start from simple design to complicated
> > design like http://conjugateprior.org/2013/01/formulae-in-r-anova/
> > <
> https://www.researchgate.net/go.Deref.html?url=http%3A%2F%2Fconjugateprior.org%2F2013%2F01%2Fformulae-in-r-anova%2F
> >
> >
> > Graphical designs showing these crossed and nested would also be useful.
> > This information would be very helpful for both teachers and researchers
> > for application correct statistical analysis.
>
>   It's pretty basic, but I like the section in Gotelli and Ellison's
> _Primer of Ecological Statistics_.  They don't really get as far as
> crossed random effects, but they do discuss nested, randomized block,
> split-plot, and factorial (i.e. _crossed fixed effect_) designs.
>
>   Ben Bolker
>
>
>
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

	[[alternative HTML version deleted]]


From jashander at ucdavis.edu  Fri Nov 14 17:09:36 2014
From: jashander at ucdavis.edu (Jaime Ashander)
Date: Fri, 14 Nov 2014 08:09:36 -0800
Subject: [R-sig-ME] Crossed and nested factors in experimental designs: Are
 there any flowcharts for decision making?
Message-ID: <CANZiT8qE2qRJVHy8D01fPJp6x3VEFzEf1ZQAsgq3fempapvgiw@mail.gmail.com>

It's not a stand-alone resource, but Schielzeth and Nakagawa (2013) walks
through nested vs crossed. The paper has some nice graphics illustrating
the designs, and tables breaking down what is estimated in each, but no
example R code.


H Schielzeth, S Nakagawa (2013)  *Nested by design:model fitting and
interpretation in a mixed model era* *Methods in Ecology and Evolution*
 4:14-24. http://dx.doi.org/10.1111/j.2041-210x.2012.00251.x

- Jaime

On Fri, Nov 14, 2014 at 3:00 AM, <r-sig-mixed-models-request at r-project.org>
wrote:

> Date: Fri, 14 Nov 2014 13:51:45 +0330
> From: Mehdi Abedi <abedimail at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Crossed and nested factors in experimental
>         designs: Are there any flowcharts for decision making?
> Message-ID:
>         <
> CADGhaghBEVKNYyRrhgStopbFTJxx4zNV+fG417jmGrAk-jwSBA at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear all,
>
> I am following your nice discussion in this group. Considering your high
> level discussion in this group i was not sure to ask basic problems in the
> mailing list!, therefore, i asked this question in researchgate.
>
> I think several researchers have this kind of question which your guidance
> can also help them using mixed models in their researches. I can imagine
> that teaching advanced statistic with simple language is not easy. However
> in addition to advanced statistic books and codes, introducing experimental
> design and their link to mixed models using simple codes would be valuable
> as well.
>
> It would be my pleasure to have your suggestion here or in this link:
>
> Warm regards
>
> Mehdi:
>
>
> https://www.researchgate.net/post/With_regards_to_crossed_and_nested_factors_in_experimental_designs_Are_there_any_flowcharts_for_decision_making
>
> Ecological researches mainly have complicated statistical design. Mixed
> models can test complicated designs with different crossed or nested
> factors. For instance lme4 and nlme could be used in R. However, still
> decision about statistical design is complicated for most researchers.
>
> Mixed models are quit an advanced method for most researchers and recent
> publications still use simple statistical designs. For instance most
> publications in high ranked journals related to plant ecophysiology and
> seed researches still apply only factorial design for the statistical
> analysis and not mixed models including random and fixed factors.
>
> Could you recommend some references or lectures introducing nested, crossed
> design with simple examples and simple codes in R?. I mean some simple
> explanation without details which start from simple design to complicated
> design like http://conjugateprior.org/2013/01/formulae-in-r-anova/
> <
> https://www.researchgate.net/go.Deref.html?url=http%3A%2F%2Fconjugateprior.org%2F2013%2F01%2Fformulae-in-r-anova%2F
> >
>
> Graphical designs showing these crossed and nested would also be useful.
> This information would be very helpful for both teachers and researchers
> for application correct statistical analysis.
>
> --
>
>
> *Mehdi Abedi Department of Range Management*
>
> *Faculty of Natural Resources & Marine Sciences *
>
> *Tarbiat Modares University (TMU) *
>
> *46417-76489, Noor*
>
> *Mazandaran, IRAN *
>
> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>
> *Homepage
> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>
> *Tel: +98-122-6253101 *
>
> *Fax: +98-122-6253499*
>
>         [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 95, Issue 18
> **************************************************
>

	[[alternative HTML version deleted]]


From jake987722 at hotmail.com  Fri Nov 14 18:23:02 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Fri, 14 Nov 2014 10:23:02 -0700
Subject: [R-sig-ME] Crossed and nested factors in experimental designs:
 Are there any flowcharts for decision making?
In-Reply-To: <CADGhagh3AQU5bDd3zxzf1qC6oZkHd58phgNR3KWj2qeNr9XWYw@mail.gmail.com>
References: <CADGhaghBEVKNYyRrhgStopbFTJxx4zNV+fG417jmGrAk-jwSBA@mail.gmail.com>,
	<5465FF61.9090607@gmail.com>,
	<CADGhagh3AQU5bDd3zxzf1qC6oZkHd58phgNR3KWj2qeNr9XWYw@mail.gmail.com>
Message-ID: <BAY172-W440D44117F17C141767E51CB8C0@phx.gbl>

Hi Mehdi,

I'm not sure if it's quite what you have in mind, but we have a recent paper on power / optimal experimental design for mixed models, which has some diagrams of different designs and discussion of when one might want to use one design vs. another. We focus very much on crossed random effects (specifically we talk about human subjects responding to random stimulus materials, but you can substitute in any other crossed random factors you like), but there is some discussion toward the end on nested and "partially crossed" designs. Could be useful perhaps.
http://jakewestfall.org/publications/crossed_power_JEPG.pdf

Also there is a very nice chapter by Raudenbush that takes about similarities and difference between classical mixed models (from ANOVA framework) and "modern" mixed models. It's been a while since I read it but I believe he focuses more on designs with nested random effects. I remember it being really useful and informative. Hopefully it will be for you too.
http://jakewestfall.org/misc/Raudenbush_1993.pdf

Jake

> From: abedimail at gmail.com
> Date: Fri, 14 Nov 2014 17:11:06 +0330
> To: bbolker at gmail.com; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Crossed and nested factors in experimental designs: Are there any flowcharts for decision making?
> 
> Dear Ben,
> Thanks for your kind introducing this reference. I also read
> "Biostatistical Design and Analysis Using R
> A Practical Guide" by Logan which was very useful for statistical design.
> 
> Linking classical ANOVAs with mixed model is still confusing for me because
> i have to collect information from different books (design from classic
> book and mixed model from new books). Due to importance of random effects
> in mixed model, misunderstanding designs can fully affect on analysis. I
> worry to wrongly connect the basic experimental designs with mixed models.
> Therefore, i asked group to introduce references talking about both
> experimental design and mixed model in the same book or text avoiding this
> mistake.
> Warm regards
> Mehdi
> 
> On Fri, Nov 14, 2014 at 4:40 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
> > On 14-11-14 05:21 AM, Mehdi Abedi wrote:
> > > Dear all,
> > >
> > > I am following your nice discussion in this group. Considering your high
> > > level discussion in this group i was not sure to ask basic problems in
> > the
> > > mailing list!, therefore, i asked this question in researchgate.
> > >
> > > I think several researchers have this kind of question which your
> > guidance
> > > can also help them using mixed models in their researches. I can imagine
> > > that teaching advanced statistic with simple language is not easy.
> > However
> > > in addition to advanced statistic books and codes, introducing
> > experimental
> > > design and their link to mixed models using simple codes would be
> > valuable
> > > as well.
> > >
> > > It would be my pleasure to have your suggestion here or in this link:
> > >
> > > Warm regards
> > >
> > > Mehdi:
> > >
> > >
> > https://www.researchgate.net/post/With_regards_to_crossed_and_nested_factors_in_experimental_designs_Are_there_any_flowcharts_for_decision_making
> > >
> > > Ecological researches mainly have complicated statistical design. Mixed
> > > models can test complicated designs with different crossed or nested
> > > factors. For instance lme4 and nlme could be used in R. However, still
> > > decision about statistical design is complicated for most researchers.
> > >
> > > Mixed models are quit an advanced method for most researchers and recent
> > > publications still use simple statistical designs. For instance most
> > > publications in high ranked journals related to plant ecophysiology and
> > > seed researches still apply only factorial design for the statistical
> > > analysis and not mixed models including random and fixed factors.
> > >
> > > Could you recommend some references or lectures introducing nested,
> > crossed
> > > design with simple examples and simple codes in R?. I mean some simple
> > > explanation without details which start from simple design to complicated
> > > design like http://conjugateprior.org/2013/01/formulae-in-r-anova/
> > > <
> > https://www.researchgate.net/go.Deref.html?url=http%3A%2F%2Fconjugateprior.org%2F2013%2F01%2Fformulae-in-r-anova%2F
> > >
> > >
> > > Graphical designs showing these crossed and nested would also be useful.
> > > This information would be very helpful for both teachers and researchers
> > > for application correct statistical analysis.
> >
> >   It's pretty basic, but I like the section in Gotelli and Ellison's
> > _Primer of Ecological Statistics_.  They don't really get as far as
> > crossed random effects, but they do discuss nested, randomized block,
> > split-plot, and factorial (i.e. _crossed fixed effect_) designs.
> >
> >   Ben Bolker
> >
> >
> >
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> -- 
> 
> 
> *Mehdi Abedi Department of Range Management*
> 
> *Faculty of Natural Resources & Marine Sciences *
> 
> *Tarbiat Modares University (TMU) *
> 
> *46417-76489, Noor*
> 
> *Mazandaran, IRAN *
> 
> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
> 
> *Homepage
> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
> 
> *Tel: +98-122-6253101 *
> 
> *Fax: +98-122-6253499*
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From abedimail at gmail.com  Fri Nov 14 18:26:13 2014
From: abedimail at gmail.com (Mehdi Abedi)
Date: Fri, 14 Nov 2014 20:56:13 +0330
Subject: [R-sig-ME] Crossed and nested factors in experimental designs:
 Are there any flowcharts for decision making?
In-Reply-To: <CANZiT8qE2qRJVHy8D01fPJp6x3VEFzEf1ZQAsgq3fempapvgiw@mail.gmail.com>
References: <CANZiT8qE2qRJVHy8D01fPJp6x3VEFzEf1ZQAsgq3fempapvgiw@mail.gmail.com>
Message-ID: <CADGhagg+auVfOxH6ziYbYH8TOXgFoPns0P7ALqX7MRhaUMT+RQ@mail.gmail.com>

Dear Jaime,
Thanks for this nice article. In appendix authors suggested some R code as
well.
Warm regards,
Mehdi

On Fri, Nov 14, 2014 at 7:39 PM, Jaime Ashander <jashander at ucdavis.edu>
wrote:

> It's not a stand-alone resource, but Schielzeth and Nakagawa (2013) walks
> through nested vs crossed. The paper has some nice graphics illustrating
> the designs, and tables breaking down what is estimated in each, but no
> example R code.
>
>
> H Schielzeth, S Nakagawa (2013)  *Nested by design:model fitting and
> interpretation in a mixed model era* *Methods in Ecology and Evolution*
>  4:14-24. http://dx.doi.org/10.1111/j.2041-210x.2012.00251.x
>
> - Jaime
>
> On Fri, Nov 14, 2014 at 3:00 AM, <r-sig-mixed-models-request at r-project.org
> > wrote:
>
>> Date: Fri, 14 Nov 2014 13:51:45 +0330
>> From: Mehdi Abedi <abedimail at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Crossed and nested factors in experimental
>>         designs: Are there any flowcharts for decision making?
>> Message-ID:
>>         <
>> CADGhaghBEVKNYyRrhgStopbFTJxx4zNV+fG417jmGrAk-jwSBA at mail.gmail.com>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> Dear all,
>>
>> I am following your nice discussion in this group. Considering your high
>> level discussion in this group i was not sure to ask basic problems in the
>> mailing list!, therefore, i asked this question in researchgate.
>>
>> I think several researchers have this kind of question which your guidance
>> can also help them using mixed models in their researches. I can imagine
>> that teaching advanced statistic with simple language is not easy. However
>> in addition to advanced statistic books and codes, introducing
>> experimental
>> design and their link to mixed models using simple codes would be valuable
>> as well.
>>
>> It would be my pleasure to have your suggestion here or in this link:
>>
>> Warm regards
>>
>> Mehdi:
>>
>>
>> https://www.researchgate.net/post/With_regards_to_crossed_and_nested_factors_in_experimental_designs_Are_there_any_flowcharts_for_decision_making
>>
>> Ecological researches mainly have complicated statistical design. Mixed
>> models can test complicated designs with different crossed or nested
>> factors. For instance lme4 and nlme could be used in R. However, still
>> decision about statistical design is complicated for most researchers.
>>
>> Mixed models are quit an advanced method for most researchers and recent
>> publications still use simple statistical designs. For instance most
>> publications in high ranked journals related to plant ecophysiology and
>> seed researches still apply only factorial design for the statistical
>> analysis and not mixed models including random and fixed factors.
>>
>> Could you recommend some references or lectures introducing nested,
>> crossed
>> design with simple examples and simple codes in R?. I mean some simple
>> explanation without details which start from simple design to complicated
>> design like http://conjugateprior.org/2013/01/formulae-in-r-anova/
>> <
>> https://www.researchgate.net/go.Deref.html?url=http%3A%2F%2Fconjugateprior.org%2F2013%2F01%2Fformulae-in-r-anova%2F
>> >
>>
>> Graphical designs showing these crossed and nested would also be useful.
>> This information would be very helpful for both teachers and researchers
>> for application correct statistical analysis.
>>
>> --
>>
>>
>> *Mehdi Abedi Department of Range Management*
>>
>> *Faculty of Natural Resources & Marine Sciences *
>>
>> *Tarbiat Modares University (TMU) *
>>
>> *46417-76489, Noor*
>>
>> *Mazandaran, IRAN *
>>
>> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>>
>> *Homepage
>> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>>
>> *Tel: +98-122-6253101 *
>>
>> *Fax: +98-122-6253499*
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> End of R-sig-mixed-models Digest, Vol 95, Issue 18
>> **************************************************
>>
>
>


-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

	[[alternative HTML version deleted]]


From emichel at CFR.MsState.Edu  Fri Nov 14 20:02:24 2014
From: emichel at CFR.MsState.Edu (Eric Michel)
Date: Fri, 14 Nov 2014 19:02:24 +0000
Subject: [R-sig-ME] Multiple post hoc comparisons in MCMCglmm
Message-ID: <64A896247C49CC498AC6502597321B2E278110AA@mail2.cfr.msstate.edu>

Hello,
I am running a full animal model in MCMCglmm and am able to get the model to run; however, I am having issues with outputting some post hoc comparisons. My data is organized the following way: I have two generations of animals (F1 and F2) from three populations (a, b and c) and animals fall into five age categories (birth, weaning, 1, 2 and 3-year-olds). I need to compare morphometrics such as body mass among the three populations within a generation at a specific age (e.g., body mass of an F1 animal from population a at age 1 vs body mass of an F1 animal from population b at age 1) as well as make comparisons within regions between generations at specific ages (e.g., body mass of an F1 animal from population a at age 1 vs body mass of an F2 animal from population a at age 1).

I have been trying to find information on whether I can run a Tukey's HSD post hoc test or a Wald test with MCMCglmm although I am not certain whether a Wald test is appropriate. Any information would be great!

Thanks,
Eric





	[[alternative HTML version deleted]]


From may.amescua at gmail.com  Sat Nov 15 00:41:19 2014
From: may.amescua at gmail.com (Mayara Amescua)
Date: Fri, 14 Nov 2014 21:41:19 -0200
Subject: [R-sig-ME] Zero-inflated and proportional data
Message-ID: <CA+AVZMvYBS0CH5QhLbR_4S+xeQZ8b7fpRnt+tnm1dfak8jdbVA@mail.gmail.com>

 I need to apply a zero-inflated regression to a proportional (percentage)
data and I can't find a way to do that. Is there anyone who knows if it's
possible?

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Sat Nov 15 01:40:30 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 14 Nov 2014 18:40:30 -0600
Subject: [R-sig-ME] Zero-inflated and proportional data
In-Reply-To: <CA+AVZMvYBS0CH5QhLbR_4S+xeQZ8b7fpRnt+tnm1dfak8jdbVA@mail.gmail.com>
References: <CA+AVZMvYBS0CH5QhLbR_4S+xeQZ8b7fpRnt+tnm1dfak8jdbVA@mail.gmail.com>
Message-ID: <73B2ECFE-0BEA-480E-B660-E9E10AD241CE@me.com>


> On Nov 14, 2014, at 5:41 PM, Mayara Amescua <may.amescua at gmail.com> wrote:
> 
> I need to apply a zero-inflated regression to a proportional (percentage)
> data and I can't find a way to do that. Is there anyone who knows if it's
> possible?


Hi,

What you seem to essentially want is "zero inflated beta regression", since standard beta regression operates on the unit interval (0, 1) and thus, cannot handle 0's and 1's. 

A Google search using the above term brings up various references.

I have not used them, but take a look at the GAMLSS package:

  http://cran.r-project.org/web/packages/gamlss/

and the zoib package:

  http://cran.r-project.org/web/packages/zoib/

Both have reference materials available via the CRAN pages and/or the author's web sites.

Also, it is not clear from your query that this is the correct list, which concerns mixed (random and fixed effects) models. If not, post any follow ups to the regular R-Help list or perhaps one of the other SIG lists as may be apropos for the subject matter domain:

  http://www.r-project.org/mail.html

Regards,

Marc Schwartz


From highstat at highstat.com  Sat Nov 15 12:33:27 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Sat, 15 Nov 2014 11:33:27 +0000
Subject: [R-sig-ME] Zero-inflated and proportional data
Message-ID: <54673A07.7020105@highstat.com>




Yes..it is possible. You can do this in JAGS (or OpenBUGS). You can find 
JAGS code
for a beta GLM(M) in our 'Beginner's Guide to GLM and GLMM with R". 
Extension
to a zero inflated beta binomial can be done via the zero trick in JAGS. 
And you
will need to find the mean and variance of a zero inflated beta GLM.



Kind regards,

Alain Zuur


From christianvanbrauner at gmail.com  Sat Nov 15 15:09:35 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Sat, 15 Nov 2014 15:09:35 +0100
Subject: [R-sig-ME] Openblas and lme4
Message-ID: <20141115140934.GA746@gmail.com>

Hello,

For testing/research purposes I compiled R from source with blas as a
shared library. I then went on to compile openblas from source, tuned it
to Sandybridge and linked R against. The crucial step being:

    cd /usr/local/lib/R/lib \
    && mv libRblas.so libRblas.so.old \
    && ln -s /usr/local/lib/libopenblas_sandybridgep-r0.2.12.so libRblas.so

It worked perfectly and I see as output from /cat/pid/status:
    Name:   R
    State:  S (sleeping)
    [?]
    Threads:        4
    [?]

Tests with the Matrix library confirm that threading works and the
increase in speed is significant for linear algebra operations such as
solve(), chol() etc.

I was wondering if lmer can make any use of this? I couldn't find a lot
on the internet. Just some posts from R-bloggers vaguely referencing
lme4 and some comments by Doug but I couldn't come to a conclusion
whether lme4 will see improvements in speed at least for larger models.
So far all my calls to lmer() on R with openblas run on a single core.
To pinpoint whether I did something wrong during compilation or if lme4
cannot reall profit from openblas I thought asking here might be a good
idea.

Best,
Christian




(For the sake of completeness: The exact compilation instructions I used
can also be found here
https://github.com/brauner/dockR/blob/master/r-patched-ivy-openblas/Dockerfile.
Someone who runs an ivy- or sandybridge cpu and uses docker can also
pull a docker image with "docker pull brauner/rblas" and check for
himself if I did something wrong.)


From bates at stat.wisc.edu  Sat Nov 15 17:12:20 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 15 Nov 2014 16:12:20 +0000
Subject: [R-sig-ME] Openblas and lme4
References: <20141115140934.GA746@gmail.com>
Message-ID: <CAO7JsnQ_PaT7HZbUr4A_ASuk2xWA5sTUeoqSw0V9+2FPt-r_dA@mail.gmail.com>

The bulk of the linear algebra calculations in lme4 are done using the
Eigen C++ library which does not rely on the BLAS.  Thus a multi-threaded
BLAS will not affect lme4 speed to any great extent.  I believe that Eigen
has its own multi-thread capabilities but it has been a while since I
checked.

On Sat Nov 15 2014 at 8:05:00 AM Christian Brauner <
christianvanbrauner at gmail.com> wrote:

> Hello,
>
> For testing/research purposes I compiled R from source with blas as a
> shared library. I then went on to compile openblas from source, tuned it
> to Sandybridge and linked R against. The crucial step being:
>
>     cd /usr/local/lib/R/lib \
>     && mv libRblas.so libRblas.so.old \
>     && ln -s /usr/local/lib/libopenblas_sandybridgep-r0.2.12.so
> libRblas.so
>
> It worked perfectly and I see as output from /cat/pid/status:
>     Name:   R
>     State:  S (sleeping)
>     [?]
>     Threads:        4
>     [?]
>
> Tests with the Matrix library confirm that threading works and the
> increase in speed is significant for linear algebra operations such as
> solve(), chol() etc.
>
> I was wondering if lmer can make any use of this? I couldn't find a lot
> on the internet. Just some posts from R-bloggers vaguely referencing
> lme4 and some comments by Doug but I couldn't come to a conclusion
> whether lme4 will see improvements in speed at least for larger models.
> So far all my calls to lmer() on R with openblas run on a single core.
> To pinpoint whether I did something wrong during compilation or if lme4
> cannot reall profit from openblas I thought asking here might be a good
> idea.
>
> Best,
> Christian
>
>
>
>
> (For the sake of completeness: The exact compilation instructions I used
> can also be found here
> https://github.com/brauner/dockR/blob/master/r-patched-
> ivy-openblas/Dockerfile.
> Someone who runs an ivy- or sandybridge cpu and uses docker can also
> pull a docker image with "docker pull brauner/rblas" and check for
> himself if I did something wrong.)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Nov 16 14:20:37 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 16 Nov 2014 13:20:37 +0000 (UTC)
Subject: [R-sig-ME] ANOVA for large data sets
References: <1584432005.141445.1415815578729.JavaMail.yahoo@jws100144.mail.ne1.yahoo.com>
Message-ID: <loom.20141116T141444-787@post.gmane.org>

Aneta <aneta871 at ...> writes:


>  Hi Everyone, I am very new to R programming and I need your help
> regarding two way ANOVA model.  I have one variable?(response) and
> three factors (Source, Batch and Time). I am always going to have a
> difference within time so probably I do not want to include it (??)
> in the analysis.  I need to identify if there is a difference
> between the Source. I know how to run the test for one sample.
> However I do not know how to process multiple samples (large data
> sets) with multiple variables sharing the same three factors.
> Please help me out! Please let me know if you need more
> clarification and I will be happy to provide it to you.  I am
> looking forward to your response.  Best!  Aneta

  There is indeed probably not enough detail here for us to help
you.  Consider looking at http://tinyurl.com/reproducible-000
for more information about writing good reproducible examples in R.
It's not clear whether you're looking for information about how
to use for loops to automate separate analyses over different data
sets, or to use the multiple samples as random effects in a mixed
model.  As far as being very new to R programming, there are many,
many resources available online (and lots of good books) -- it's
probably best to read some things that are relevant to your subject
area, and to browse the [r] tag on StackOverflow.


From may.amescua at gmail.com  Sun Nov 16 19:23:41 2014
From: may.amescua at gmail.com (Mayara Amescua)
Date: Sun, 16 Nov 2014 16:23:41 -0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 95, Issue 21
In-Reply-To: <mailman.5.1416135601.13229.r-sig-mixed-models@r-project.org>
References: <mailman.5.1416135601.13229.r-sig-mixed-models@r-project.org>
Message-ID: <CA+AVZMuz=U=vyrzrFEy+mFCi8DLve25uguDGyV3Qfjb2iLQLSQ@mail.gmail.com>

Thank you Zuur,

I'll check it all. Everything is quite new for me.

By the way, I've been reading your book, Mixed Effect Models...(2009).
It's really nice!

Regards,
Mayara

2014-11-16 9:00 GMT-02:00 <r-sig-mixed-models-request at r-project.org>:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Re: Zero-inflated and proportional data (Highland Statistics Ltd)
>    2. Openblas and lme4 (Christian Brauner)
>    3. Re: Openblas and lme4 (Douglas Bates)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 15 Nov 2014 11:33:27 +0000
> From: Highland Statistics Ltd <highstat at highstat.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Zero-inflated and proportional data
> Message-ID: <54673A07.7020105 at highstat.com>
> Content-Type: text/plain; charset=utf-8; format=flowed
>
>
>
>
> Yes..it is possible. You can do this in JAGS (or OpenBUGS). You can find
> JAGS code
> for a beta GLM(M) in our 'Beginner's Guide to GLM and GLMM with R".
> Extension
> to a zero inflated beta binomial can be done via the zero trick in JAGS.
> And you
> will need to find the mean and variance of a zero inflated beta GLM.
>
>
>
> Kind regards,
>
> Alain Zuur
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 15 Nov 2014 15:09:35 +0100
> From: Christian Brauner <christianvanbrauner at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Openblas and lme4
> Message-ID: <20141115140934.GA746 at gmail.com>
> Content-Type: text/plain; charset=utf-8
>
> Hello,
>
> For testing/research purposes I compiled R from source with blas as a
> shared library. I then went on to compile openblas from source, tuned it
> to Sandybridge and linked R against. The crucial step being:
>
>     cd /usr/local/lib/R/lib \
>     && mv libRblas.so libRblas.so.old \
>     && ln -s /usr/local/lib/libopenblas_sandybridgep-r0.2.12.so
> libRblas.so
>
> It worked perfectly and I see as output from /cat/pid/status:
>     Name:   R
>     State:  S (sleeping)
>     [?]
>     Threads:        4
>     [?]
>
> Tests with the Matrix library confirm that threading works and the
> increase in speed is significant for linear algebra operations such as
> solve(), chol() etc.
>
> I was wondering if lmer can make any use of this? I couldn't find a lot
> on the internet. Just some posts from R-bloggers vaguely referencing
> lme4 and some comments by Doug but I couldn't come to a conclusion
> whether lme4 will see improvements in speed at least for larger models.
> So far all my calls to lmer() on R with openblas run on a single core.
> To pinpoint whether I did something wrong during compilation or if lme4
> cannot reall profit from openblas I thought asking here might be a good
> idea.
>
> Best,
> Christian
>
>
>
>
> (For the sake of completeness: The exact compilation instructions I used
> can also be found here
>
> https://github.com/brauner/dockR/blob/master/r-patched-ivy-openblas/Dockerfile
> .
> Someone who runs an ivy- or sandybridge cpu and uses docker can also
> pull a docker image with "docker pull brauner/rblas" and check for
> himself if I did something wrong.)
>
>
>
> ------------------------------
>
> Message: 3
> Date: Sat, 15 Nov 2014 16:12:20 +0000
> From: Douglas Bates <bates at stat.wisc.edu>
> To: Christian Brauner <christianvanbrauner at gmail.com>,
>         r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Openblas and lme4
> Message-ID:
>         <
> CAO7JsnQ_PaT7HZbUr4A_ASuk2xWA5sTUeoqSw0V9+2FPt-r_dA at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> The bulk of the linear algebra calculations in lme4 are done using the
> Eigen C++ library which does not rely on the BLAS.  Thus a multi-threaded
> BLAS will not affect lme4 speed to any great extent.  I believe that Eigen
> has its own multi-thread capabilities but it has been a while since I
> checked.
>
> On Sat Nov 15 2014 at 8:05:00 AM Christian Brauner <
> christianvanbrauner at gmail.com> wrote:
>
> > Hello,
> >
> > For testing/research purposes I compiled R from source with blas as a
> > shared library. I then went on to compile openblas from source, tuned it
> > to Sandybridge and linked R against. The crucial step being:
> >
> >     cd /usr/local/lib/R/lib \
> >     && mv libRblas.so libRblas.so.old \
> >     && ln -s /usr/local/lib/libopenblas_sandybridgep-r0.2.12.so
> > libRblas.so
> >
> > It worked perfectly and I see as output from /cat/pid/status:
> >     Name:   R
> >     State:  S (sleeping)
> >     [?]
> >     Threads:        4
> >     [?]
> >
> > Tests with the Matrix library confirm that threading works and the
> > increase in speed is significant for linear algebra operations such as
> > solve(), chol() etc.
> >
> > I was wondering if lmer can make any use of this? I couldn't find a lot
> > on the internet. Just some posts from R-bloggers vaguely referencing
> > lme4 and some comments by Doug but I couldn't come to a conclusion
> > whether lme4 will see improvements in speed at least for larger models.
> > So far all my calls to lmer() on R with openblas run on a single core.
> > To pinpoint whether I did something wrong during compilation or if lme4
> > cannot reall profit from openblas I thought asking here might be a good
> > idea.
> >
> > Best,
> > Christian
> >
> >
> >
> >
> > (For the sake of completeness: The exact compilation instructions I used
> > can also be found here
> > https://github.com/brauner/dockR/blob/master/r-patched-
> > ivy-openblas/Dockerfile.
> > Someone who runs an ivy- or sandybridge cpu and uses docker can also
> > pull a docker image with "docker pull brauner/rblas" and check for
> > himself if I did something wrong.)
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>         [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 95, Issue 21
> **************************************************
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Nov 16 21:22:07 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 16 Nov 2014 15:22:07 -0500
Subject: [R-sig-ME] Fwd: Re:  ANOVA for large data sets
In-Reply-To: <987895460.814673.1416165023435.JavaMail.yahoo@jws100108.mail.ne1.yahoo.com>
References: <987895460.814673.1416165023435.JavaMail.yahoo@jws100108.mail.ne1.yahoo.com>
Message-ID: <5469076F.8010105@gmail.com>


  cc'ing to r-sig-mixed-models -- I really can't have offline
conversations about statistical advice ...

-------- Forwarded Message --------
Subject: 	Re: [R-sig-ME] ANOVA for large data sets
Date: 	Sun, 16 Nov 2014 19:10:23 +0000 (UTC)
From: 	Aneta <aneta871 at yahoo.com>
Reply-To: 	Aneta <aneta871 at yahoo.com>
To: 	Ben Bolker <bbolker at gmail.com>



Hi Ben,

Thank you very much for your response. Yes I need to automate separate
analysis.

*The outline of the experiment:*

10 replicates of reference and 10 replicates of test samples are tested
under 5 independent conditions. 6 time points per condition are collected.

All samples at each condition and at each time point are tested by
multiple methods (five of them). One method has from 3 to 12 different
attributes.

I need to compare reference and test sample at each attribute level per
each condition I need to determine if there is a difference or not
between reference and test material.

I believe I need to use loops as you suggested.

I also need to address one more thing in ANOVA. Some of my attributes
that I am testing start at different level and I need to account for it
in ANOVA. There is a few % difference in the starting material
(reference versus testing material). Would you please help me out how to
address it in ANOVA using R?

Thank you very much for your help,

Aneta




On Sunday, November 16, 2014 8:22 AM, Ben Bolker <bbolker at gmail.com> wrote:


Aneta <aneta871 at ... <mailto:aneta871 at ...>> writes:


>  Hi Everyone, I am very new to R programming and I need your help
> regarding two way ANOVA model.  I have one variable (response) and
> three factors (Source, Batch and Time). I am always going to have a
> difference within time so probably I do not want to include it (??)
> in the analysis.  I need to identify if there is a difference
> between the Source. I know how to run the test for one sample.
> However I do not know how to process multiple samples (large data
> sets) with multiple variables sharing the same three factors.
> Please help me out! Please let me know if you need more
> clarification and I will be happy to provide it to you.  I am
> looking forward to your response.  Best!  Aneta

  There is indeed probably not enough detail here for us to help
you.  Consider looking at http://tinyurl.com/reproducible-000
for more information about writing good reproducible examples in R.
It's not clear whether you're looking for information about how
to use for loops to automate separate analyses over different data
sets, or to use the multiple samples as random effects in a mixed
model.  As far as being very new to R programming, there are many,
many resources available online (and lots of good books) -- it's
probably best to read some things that are relevant to your subject
area, and to browse the [r] tag on StackOverflow.

_______________________________________________
R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From asafw.at.wharton at gmail.com  Mon Nov 17 01:04:30 2014
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Sun, 16 Nov 2014 19:04:30 -0500
Subject: [R-sig-ME] Non-diagonal sampling covariance with lme4
Message-ID: <CAGG0PdAB4TF5iNB-EeRNp_e_FhNwFz8Aaopr5N6RgXYW0fd7uQ@mail.gmail.com>

Hi all,

I would like to obtain ML (or REML) estimates for theta, beta, sigsq in

Y|B=b ~ N( Zb + Xbeta, sigsq*V )
B ~ N( 0,Sigma(theta) )

where V is a known covariance matrix. lmer() does exactly that for V=I_n
(the n-by-n identity matrix); I wonder if there is a way to specify an
arbitrary covariance matrix.

Thanks so much,

Asaf

	[[alternative HTML version deleted]]


From mpay at aqua.dtu.dk  Sun Nov 16 22:40:37 2014
From: mpay at aqua.dtu.dk (Mark Payne)
Date: Mon, 17 Nov 2014 10:40:37 +1300
Subject: [R-sig-ME] Offset() in gls() in nlme
In-Reply-To: <CAO7JsnQRGRLLEcs8x3u7baPv27d3Gm8zWrzKMGWvWs8fR7ywqw@mail.gmail.com>
References: <CAGBzUO9pFA3hZSTOUb_CLwwyY06jgGWOqGo=Si1ta+zPWd15zQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B38DF0@inbomail.inbo.be>
	<CAO7JsnQRGRLLEcs8x3u7baPv27d3Gm8zWrzKMGWvWs8fR7ywqw@mail.gmail.com>
Message-ID: <546919D5.2070904@aqua.dtu.dk>

Hi Douglas,

Thanks for the reply - unfortunately there doesn't seem to be an offset 
argument either in the latest version of nlme... :-(

 > gls
function (model, data = sys.frame(sys.parent()), correlation = NULL,
     weights = NULL, subset, method = c("REML", "ML"), na.action = na.fail,
     control = list(), verbose = FALSE)

 > packageDescription("nlme")
Package: nlme
Version: 3.1-118
Date: 2014-10-07

Mark


On 13/11/14 04:54, Douglas Bates wrote:
> It may work if  you use the offset argument instead of putting an offset
> term in the formula.  The model-fitting code in R (and S before it)
> sometimes has the "there's more than one way to do it" approach of
> Perl.  This is convenient for users but not for those writing the code.
> I believe we implemented the offset argument form.
>
> On Wed Nov 12 2014 at 2:52:30 AM ONKELINX, Thierry
> <Thierry.ONKELINX at inbo.be <mailto:Thierry.ONKELINX at inbo.be>> wrote:
>
>     Dear Mark,
>
>     In case of a linear model you can create a new variable Y = R - ssb
>     and model Y without offset instead of R with ssb as offset. That
>     should give the same parameter estimates.
>
>     Best regards,
>
>     ir. Thierry Onkelinx
>     Instituut voor natuur- en bosonderzoek / Research Institute for
>     Nature and Forest
>     team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>     Kliniekstraat 25
>     1070 Anderlecht
>     Belgium
>     + 32 2 525 02 51
>     + 32 54 43 61 85
>     Thierry.Onkelinx at inbo.be <mailto:Thierry.Onkelinx at inbo.be>
>     www.inbo.be <http://www.inbo.be>
>
>     To call in the statistician after the experiment is done may be no
>     more than asking him to perform a post-mortem examination: he may be
>     able to say what the experiment died of.
>     ~ Sir Ronald Aylmer Fisher
>
>     The plural of anecdote is not data.
>     ~ Roger Brinner
>
>     The combination of some data and an aching desire for an answer does
>     not ensure that a reasonable answer can be extracted from a given
>     body of data.
>     ~ John Tukey
>
>     -----Oorspronkelijk bericht-----
>     Van: r-sig-mixed-models-bounces at r-__project.org
>     <mailto:r-sig-mixed-models-bounces at r-project.org>
>     [mailto:r-sig-mixed-models-__bounces at r-project.org
>     <mailto:r-sig-mixed-models-bounces at r-project.org>] Namens Mark Payne
>     Verzonden: dinsdag 11 november 2014 13:23
>     Aan: r-sig-mixed-models at r-project.__org
>     <mailto:r-sig-mixed-models at r-project.org>
>     Onderwerp: [R-sig-ME] Offset() in gls() in nlme
>
>     Hi,
>
>     I am trying to use the following model formula in gls() in the nlme
>     package:
>
>     R ~ Turb + offset(ssb)
>
>     Unfortunately, gls() seems to ignore the offset argument and give
>     results that are identical to
>
>     R ~ Turb
>
>     This is not the case when I use lm() - however, I would like to
>     include a
>     corAR1() term as well, which is why I am using gls().
>
>     Is this known and intended behaviour? If so, is there a recommended
>     workaround/alternative?
>
>     Best wishes,
>
>     Mark
>
>              [[alternative HTML version deleted]]
>
>     _________________________________________________
>     R-sig-mixed-models at r-project.__org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
>     Dit bericht en eventuele bijlagen geven enkel de visie van de
>     schrijver weer en binden het INBO onder geen enkel beding, zolang
>     dit bericht niet bevestigd is door een geldig ondertekend document.
>     The views expressed in this message and any annex are purely those
>     of the writer and may not be regarded as stating an official
>     position of INBO, as long as the message is not confirmed by a duly
>     signed document.
>
>     _________________________________________________
>     R-sig-mixed-models at r-project.__org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>


From napovarj at gmail.com  Sun Nov 16 03:53:12 2014
From: napovarj at gmail.com (Napoleon Vargas)
Date: Sat, 15 Nov 2014 20:53:12 -0600
Subject: [R-sig-ME] Bivariate (or multivariate) model in MCMCglmm
Message-ID: <CAC4AauRjbvj0-MkT1K2dWCgNX0yW5X9ibowegM4HJpyC8W3Cfw@mail.gmail.com>

Dear everyone,

I've been playing with MCMCglmm for a while, and I've found it very useful.
I wanted to know if its possible to restrict specific residual variances in
a bivariate or multivarate model. The model in question would have one (or
two) Gaussian traits, and one (or two) "Threshold" or Ordinal traits.I
would like to restrict the residual variances for the threshold traits to
1. Would that be feasible (or a sensible thing to do)?.

I'd appreciate any information.


Cheers,

-- 
*Napo Vargas J.*
*Ph.D. Student*
*Breeding and Genetics*
*Department of Animal Science*
*University of Nebraska - Lincoln*

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Mon Nov 17 17:07:57 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 17 Nov 2014 16:07:57 +0000
Subject: [R-sig-ME] Non-diagonal sampling covariance with lme4
References: <CAGG0PdAB4TF5iNB-EeRNp_e_FhNwFz8Aaopr5N6RgXYW0fd7uQ@mail.gmail.com>
Message-ID: <CAO7JsnQdu1ZWUXp8bf9ZfzZ1J+S_G4v+_f_fLY2HLo0gb7-HgQ@mail.gmail.com>

You can "pre-whiten" the response and the model matrices by multiplying by
either the right or left inverse Cholesky factor of V.  (I always need to
write out the equations before i can determine if I should use the left or
the right factor.)

On Mon Nov 17 2014 at 9:11:45 AM Asaf Weinstein <asafw.at.wharton at gmail.com>
wrote:

> Hi all,
>
> I would like to obtain ML (or REML) estimates for theta, beta, sigsq in
>
> Y|B=b ~ N( Zb + Xbeta, sigsq*V )
> B ~ N( 0,Sigma(theta) )
>
> where V is a known covariance matrix. lmer() does exactly that for V=I_n
> (the n-by-n identity matrix); I wonder if there is a way to specify an
> arbitrary covariance matrix.
>
> Thanks so much,
>
> Asaf
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Nov 17 17:27:18 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 17 Nov 2014 11:27:18 -0500
Subject: [R-sig-ME] Offset() in gls() in nlme
In-Reply-To: <546919D5.2070904@aqua.dtu.dk>
References: <CAGBzUO9pFA3hZSTOUb_CLwwyY06jgGWOqGo=Si1ta+zPWd15zQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B38DF0@inbomail.inbo.be>
	<CAO7JsnQRGRLLEcs8x3u7baPv27d3Gm8zWrzKMGWvWs8fR7ywqw@mail.gmail.com>
	<546919D5.2070904@aqua.dtu.dk>
Message-ID: <CABghstQ+aX6o-yG8nZ4hKyEuKx53uHma=QxLd0WW5OEGD_Nv0A@mail.gmail.com>

In that case, I believe Thierry's solution is correct.  For linear models,
offsets are a convenience rather than a necessity.

On Sun, Nov 16, 2014 at 4:40 PM, Mark Payne <mpay at aqua.dtu.dk> wrote:

> Hi Douglas,
>
> Thanks for the reply - unfortunately there doesn't seem to be an offset
> argument either in the latest version of nlme... :-(
>
> > gls
> function (model, data = sys.frame(sys.parent()), correlation = NULL,
>     weights = NULL, subset, method = c("REML", "ML"), na.action = na.fail,
>     control = list(), verbose = FALSE)
>
> > packageDescription("nlme")
> Package: nlme
> Version: 3.1-118
> Date: 2014-10-07
>
> Mark
>
>
> On 13/11/14 04:54, Douglas Bates wrote:
>
>> It may work if  you use the offset argument instead of putting an offset
>> term in the formula.  The model-fitting code in R (and S before it)
>> sometimes has the "there's more than one way to do it" approach of
>> Perl.  This is convenient for users but not for those writing the code.
>> I believe we implemented the offset argument form.
>>
>> On Wed Nov 12 2014 at 2:52:30 AM ONKELINX, Thierry
>> <Thierry.ONKELINX at inbo.be <mailto:Thierry.ONKELINX at inbo.be>> wrote:
>>
>>     Dear Mark,
>>
>>     In case of a linear model you can create a new variable Y = R - ssb
>>     and model Y without offset instead of R with ssb as offset. That
>>     should give the same parameter estimates.
>>
>>     Best regards,
>>
>>     ir. Thierry Onkelinx
>>     Instituut voor natuur- en bosonderzoek / Research Institute for
>>     Nature and Forest
>>     team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>     Kliniekstraat 25
>>     1070 Anderlecht
>>     Belgium
>>     + 32 2 525 02 51
>>     + 32 54 43 61 85
>>     Thierry.Onkelinx at inbo.be <mailto:Thierry.Onkelinx at inbo.be>
>>     www.inbo.be <http://www.inbo.be>
>>
>>     To call in the statistician after the experiment is done may be no
>>     more than asking him to perform a post-mortem examination: he may be
>>     able to say what the experiment died of.
>>     ~ Sir Ronald Aylmer Fisher
>>
>>     The plural of anecdote is not data.
>>     ~ Roger Brinner
>>
>>     The combination of some data and an aching desire for an answer does
>>     not ensure that a reasonable answer can be extracted from a given
>>     body of data.
>>     ~ John Tukey
>>
>>     -----Oorspronkelijk bericht-----
>>     Van: r-sig-mixed-models-bounces at r-__project.org
>>     <mailto:r-sig-mixed-models-bounces at r-project.org>
>>     [mailto:r-sig-mixed-models-__bounces at r-project.org
>>     <mailto:r-sig-mixed-models-bounces at r-project.org>] Namens Mark Payne
>>     Verzonden: dinsdag 11 november 2014 13:23
>>     Aan: r-sig-mixed-models at r-project.__org
>>     <mailto:r-sig-mixed-models at r-project.org>
>>     Onderwerp: [R-sig-ME] Offset() in gls() in nlme
>>
>>     Hi,
>>
>>     I am trying to use the following model formula in gls() in the nlme
>>     package:
>>
>>     R ~ Turb + offset(ssb)
>>
>>     Unfortunately, gls() seems to ignore the offset argument and give
>>     results that are identical to
>>
>>     R ~ Turb
>>
>>     This is not the case when I use lm() - however, I would like to
>>     include a
>>     corAR1() term as well, which is why I am using gls().
>>
>>     Is this known and intended behaviour? If so, is there a recommended
>>     workaround/alternative?
>>
>>     Best wishes,
>>
>>     Mark
>>
>>              [[alternative HTML version deleted]]
>>
>>     _________________________________________________
>>     R-sig-mixed-models at r-project.__org
>>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>     * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * *
>> *
>>     Dit bericht en eventuele bijlagen geven enkel de visie van de
>>     schrijver weer en binden het INBO onder geen enkel beding, zolang
>>     dit bericht niet bevestigd is door een geldig ondertekend document.
>>     The views expressed in this message and any annex are purely those
>>     of the writer and may not be regarded as stating an official
>>     position of INBO, as long as the message is not confirmed by a duly
>>     signed document.
>>
>>     _________________________________________________
>>     R-sig-mixed-models at r-project.__org
>>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Nov 17 17:41:28 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 17 Nov 2014 11:41:28 -0500
Subject: [R-sig-ME] Non-diagonal sampling covariance with lme4
In-Reply-To: <CAO7JsnQdu1ZWUXp8bf9ZfzZ1J+S_G4v+_f_fLY2HLo0gb7-HgQ@mail.gmail.com>
References: <CAGG0PdAB4TF5iNB-EeRNp_e_FhNwFz8Aaopr5N6RgXYW0fd7uQ@mail.gmail.com>
	<CAO7JsnQdu1ZWUXp8bf9ZfzZ1J+S_G4v+_f_fLY2HLo0gb7-HgQ@mail.gmail.com>
Message-ID: <CABghstSRpvCGG1C7B7L384fyGpz50PR8bB9b96_cQk=fBeZ+Zg@mail.gmail.com>

... and for more nuts and bolts about how to modify X (and possibly Z?) and
feed it back into the lme4 machinery, see ?modular ...

On Mon, Nov 17, 2014 at 11:07 AM, Douglas Bates <bates at stat.wisc.edu> wrote:

> You can "pre-whiten" the response and the model matrices by multiplying by
> either the right or left inverse Cholesky factor of V.  (I always need to
> write out the equations before i can determine if I should use the left or
> the right factor.)
>
> On Mon Nov 17 2014 at 9:11:45 AM Asaf Weinstein <
> asafw.at.wharton at gmail.com>
> wrote:
>
> > Hi all,
> >
> > I would like to obtain ML (or REML) estimates for theta, beta, sigsq in
> >
> > Y|B=b ~ N( Zb + Xbeta, sigsq*V )
> > B ~ N( 0,Sigma(theta) )
> >
> > where V is a known covariance matrix. lmer() does exactly that for V=I_n
> > (the n-by-n identity matrix); I wonder if there is a way to specify an
> > arbitrary covariance matrix.
> >
> > Thanks so much,
> >
> > Asaf
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From e.sharps at gmail.com  Tue Nov 18 13:35:25 2014
From: e.sharps at gmail.com (Elwyn Sharps)
Date: Tue, 18 Nov 2014 12:35:25 +0000
Subject: [R-sig-ME] glmmADMB error messages with percentage cover data
In-Reply-To: <DUB126-W901F049C8660271E10BFF8BE880@phx.gbl>
References: <DUB126-W901F049C8660271E10BFF8BE880@phx.gbl>
Message-ID: <DUB126-W10E6987F330229AFB107A5BE880@phx.gbl>


Hi,


I have collected data on % cover of a variety of
plant species on heathland (in relation to nesting birds) and am interested in
testing the effect of density of grazing ponies, the proximity to nest site
(%cover measured at 1 and 10m from the nest) and the age of the nest (as a
control for vegetation being measured at nests of different ages). The
response is percentage cover and contains many zeros (see attached
data for an example).


I have tried using glmmADMB, with family=
binomial and zero inflation=T. The response was created using cbind e.g.
y<-(cbind(Data$Plant_cover, Data$Plant_empty)), where Plant cover = % cover
and Plant empty = 100-Plant cover.


Example model: 

Fit1<-glmmadmb(y~Grazing*proximity+Age+(1|site),data=Heath,zeroInflation=TRUE,family="binomial")


The majority of the models for Species
1 have been running fine, however I have been getting the occasional error
message and for Species 2, all models give an error message. 


Example error messages:

Parameters were estimated, but not standard errors
were not: the most likely problem is that the curvature at MLE was zero or
negative

Error in glmmadmb(w ~ Grazing * proximity + Age + (1 | site), data =
heathland,  : 

  The function maximizer failed (couldn't find STD file) Troubleshooting
steps include (1) run with 'save.dir' set and inspect output files; (2) change
run parameters: see '?admbControl'

Warning message:

In glmmadmb(w ~ 1 + (1 | site), data = heathland, zeroInflation = T,  :

  Convergence failed:log-likelihood of gradient= -0.269018



I just wanted to check that this is a sensible
way to deal with these data and if there is anything that I should be doing to
remedy the error messages? I've tried some other options, e.g. Arc sine
transformation couldn't deal with the excess zeros. I've also considered
quasibinomial in lme4, but have seen Doug Bates comments on the unreliability
of the model output. 

 

Any advice would be very much appreciated.
All the best
Elwyn 		 	   		   		 	   		  

From llbergamini at gmail.com  Wed Nov 19 13:44:03 2014
From: llbergamini at gmail.com (Leonardo Bergamini)
Date: Wed, 19 Nov 2014 10:44:03 -0200
Subject: [R-sig-ME] Longitudinal Model
Message-ID: <CAB+KSw4OF=dV2ifNrOdCfSVdnE8zX7_FMfjq6Ey3Rvh9pe9zMg@mail.gmail.com>

Hi fellows,
I would like some help at adjusting a mixed model as follows:
I have collected data on the abundance of caterpillars (NC) on trees at
three sites over 48 monthly samplings. I am interested in understanding how
the three environmental variables I have for the region (namely mean
temperature (Temp) in that month, total precipitation (R) and mean relative
humidity (H)) correlate with the number of caterpillars, and whether this
relationship is different at the three sites.
So far I've been thinking about a lme model, in order to include the
temporal autocorrelation structure, but I'm not sure how to specify the
random effects and the error structure. I also would like to test at which
temporal lag (same month, last month or two months earlier) the
relationship is stronger.

Example:

## simulating the data
set.seed(1)
df<-data.frame(
  Temp=rep(26+sin(seq(0,2*pi,(2*pi+1)/13))+rnorm(48,0,0.3),3),
  P=rep(500+100*(1-sin(seq(0,2*pi,(2*pi+1)/13)))+rnorm(48,100,30),3),
  H=rep(((2+(1-sin(seq(0,2*pi,(2*pi+1)/13))))/4)+rnorm(48,0,0.05),3),
  site=rep(c("A","B","C"),each=48),
  NC=round(4*(1-sin(seq(0,2*pi,(2*pi+1)/13)))+rnorm(144,10,4)),
  month=rep(1:48,3)
)
## model
library(nlme)
model1<-lme(NC~Temp+P+H,
random=~1|site,correlation=corAR1(form=~month|site),data=df)



Any help on this specific problem or pointings towards introductory
literature would be great
Thanks,

Leonardo

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Wed Nov 19 14:13:50 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 19 Nov 2014 13:13:50 +0000
Subject: [R-sig-ME] Longitudinal Model
In-Reply-To: <CAB+KSw4OF=dV2ifNrOdCfSVdnE8zX7_FMfjq6Ey3Rvh9pe9zMg@mail.gmail.com>
References: <CAB+KSw4OF=dV2ifNrOdCfSVdnE8zX7_FMfjq6Ey3Rvh9pe9zMg@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B4934B@inbomail.inbo.be>

Dear Leonardo,

Your model seems reasonable in case of many sites and a continuous response. However, 3 levels is too low to get sensible estimates of the random effect variance (see http://glmm.wikidot.com/faq). Furthermore your response seem to be counts, for which the Gaussian distribution in not correct. You 'll need a Poisson or negative binomial distribution. nlme handles only the Gaussian distribution.

I'm afraid that you will have to go for some more complicated tools like the INLA package or JAGS.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Leonardo Bergamini
Verzonden: woensdag 19 november 2014 13:44
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Longitudinal Model

Hi fellows,
I would like some help at adjusting a mixed model as follows:
I have collected data on the abundance of caterpillars (NC) on trees at three sites over 48 monthly samplings. I am interested in understanding how the three environmental variables I have for the region (namely mean temperature (Temp) in that month, total precipitation (R) and mean relative humidity (H)) correlate with the number of caterpillars, and whether this relationship is different at the three sites.
So far I've been thinking about a lme model, in order to include the temporal autocorrelation structure, but I'm not sure how to specify the random effects and the error structure. I also would like to test at which temporal lag (same month, last month or two months earlier) the relationship is stronger.

Example:

## simulating the data
set.seed(1)
df<-data.frame(
  Temp=rep(26+sin(seq(0,2*pi,(2*pi+1)/13))+rnorm(48,0,0.3),3),
  P=rep(500+100*(1-sin(seq(0,2*pi,(2*pi+1)/13)))+rnorm(48,100,30),3),
  H=rep(((2+(1-sin(seq(0,2*pi,(2*pi+1)/13))))/4)+rnorm(48,0,0.05),3),
  site=rep(c("A","B","C"),each=48),
  NC=round(4*(1-sin(seq(0,2*pi,(2*pi+1)/13)))+rnorm(144,10,4)),
  month=rep(1:48,3)
)
## model
library(nlme)
model1<-lme(NC~Temp+P+H,
random=~1|site,correlation=corAR1(form=~month|site),data=df)



Any help on this specific problem or pointings towards introductory literature would be great Thanks,

Leonardo

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From friso.muijsers at uni-oldenburg.de  Wed Nov 19 15:17:58 2014
From: friso.muijsers at uni-oldenburg.de (Friso Muijsers)
Date: Wed, 19 Nov 2014 15:17:58 +0100
Subject: [R-sig-ME] weights = varIdent - differences even if "weighted
 factor" is not in the model
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3B4934B@inbomail.inbo.be>
References: <CAB+KSw4OF=dV2ifNrOdCfSVdnE8zX7_FMfjq6Ey3Rvh9pe9zMg@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B4934B@inbomail.inbo.be>
Message-ID: <546CA696.5050307@uni-oldenburg.de>

Dear mixed-models mailing list users,

I have come across a strange behaviour of the "varIdent" function in the 
nlme package, that makes me wonder if my understanding of this function 
is completely wrong:

By accident I found the following: if I have a model using a varIdent 
function for a certain factor, that is not included in the final model 
(for whatever reason) then it still changes the model estimates. I 
thought that, if a model does not contain a factor, than leaving it in a 
weights-argument should not change the fitting process.

Small example:

fm1 = lme(distance~Sex, data = Orthodont, random = ~1, weights = 
varIdent(form = ~1|age))
fm2 = lme(distance~Sex, data = Orthodont, random = ~1)

anova(fm1,fm2)
summary(fm1)
summary(fm2)

I have the feeling that I should simply remove the weights argument of 
factors that are not in the model, but I am now un-shure if that is the 
right thing to do, and if there is something important here, that I am 
missing!?

Can someone help me back on course? I have to admit that I am not very 
firm with the whole theory of the different weights-methods, allthough I 
have read the respective chapter of Pinheiro & Bates  book


Thanks for reading!

Friso

-- 
Friso Muijsers

Institute for Chemistry and Biology of the Marine Environment (ICBM)
Carl-von-Ossietzky University Oldenburg
Schleusenstrasse 1
26382 Wilhemshaven


From highstat at highstat.com  Wed Nov 19 17:38:40 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 19 Nov 2014 17:38:40 +0100
Subject: [R-sig-ME] glmmADMB error messages with percentage cover data
	(Elwyn Sharps)
In-Reply-To: <mailman.3.1416394802.5720.r-sig-mixed-models@r-project.org>
References: <mailman.3.1416394802.5720.r-sig-mixed-models@r-project.org>
Message-ID: <546CC790.80004@highstat.com>



>
> I have collected data on % cover of a variety of
> plant species on heathland (in relation to nesting birds) and am interested in
> testing the effect of density of grazing ponies, the proximity to nest site
> (%cover measured at 1 and 10m from the nest) and the age of the nest (as a
> control for vegetation being measured at nests of different ages). The
> response is percentage cover and contains many zeros (see attached
> data for an example).
>
>
> I have tried using glmmADMB, with family=
> binomial and zero inflation=T. The response was created using cbind e.g.
> y<-(cbind(Data$Plant_cover, Data$Plant_empty)), where Plant cover = % cover
> and Plant empty = 100-Plant cover.
>
>
> Example model:
>
> Fit1<-glmmadmb(y~Grazing*proximity+Age+(1|site),data=Heath,zeroInflation=TRUE,family="binomial")
>


See the help file of glmmadmb:

zeroInflation:   whether a zero-inflated model should be fitted (only 
"poisson" and "nbinom" families).

With emphasis on the last part in this sentence.

Kind regards,


Alain


> The majority of the models for Species
> 1 have been running fine, however I have been getting the occasional error
> message and for Species 2, all models give an error message.
>
>
> Example error messages:
>
> Parameters were estimated, but not standard errors
> were not: the most likely problem is that the curvature at MLE was zero or
> negative
>
> Error in glmmadmb(w ~ Grazing * proximity + Age + (1 | site), data =
> heathland,  :
>
>    The function maximizer failed (couldn't find STD file) Troubleshooting
> steps include (1) run with 'save.dir' set and inspect output files; (2) change
> run parameters: see '?admbControl'
>
> Warning message:
>
> In glmmadmb(w ~ 1 + (1 | site), data = heathland, zeroInflation = T,  :
>
>    Convergence failed:log-likelihood of gradient= -0.269018
>
>
>
> I just wanted to check that this is a sensible
> way to deal with these data and if there is anything that I should be doing to
> remedy the error messages? I've tried some other options, e.g. Arc sine
> transformation couldn't deal with the excess zeros. I've also considered
> quasibinomial in lme4, but have seen Doug Bates comments on the unreliability
> of the model output.
>
>   
>
> Any advice would be very much appreciated.
> All the best
> Elwyn 		 	   		   		 	   		
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 95, Issue 24
> **************************************************
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From e.sharps at gmail.com  Wed Nov 19 18:16:10 2014
From: e.sharps at gmail.com (Elwyn Sharps)
Date: Wed, 19 Nov 2014 17:16:10 +0000
Subject: [R-sig-ME] glmmADMB error messages with percentage cover data
 (Elwyn Sharps)
In-Reply-To: <546CC790.80004@highstat.com>
References: <mailman.3.1416394802.5720.r-sig-mixed-models@r-project.org>,
	<546CC790.80004@highstat.com>
Message-ID: <DUB126-W8474E884D1EE022B745FF1BE890@phx.gbl>

Hi Alain, Thanks for your reply. Sorry I hadn't noticed this section of the glmmADMB help file and as some of the models were running fine, I assumed there wasn't a problem with the family. Have you got any other ideas on how I can deal with the very large number of zeros in the data? As it's percentage cover rather than count data, I don't think I can use Poisson or Neg Binomial. Thanks again
Elwyn

> Date: Wed, 19 Nov 2014 17:38:40 +0100
> From: highstat at highstat.com
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] glmmADMB error messages with percentage cover data	(Elwyn Sharps)
> 
> 
> 
> >
> > I have collected data on % cover of a variety of
> > plant species on heathland (in relation to nesting birds) and am interested in
> > testing the effect of density of grazing ponies, the proximity to nest site
> > (%cover measured at 1 and 10m from the nest) and the age of the nest (as a
> > control for vegetation being measured at nests of different ages). The
> > response is percentage cover and contains many zeros (see attached
> > data for an example).
> >
> >
> > I have tried using glmmADMB, with family=
> > binomial and zero inflation=T. The response was created using cbind e.g.
> > y<-(cbind(Data$Plant_cover, Data$Plant_empty)), where Plant cover = % cover
> > and Plant empty = 100-Plant cover.
> >
> >
> > Example model:
> >
> > Fit1<-glmmadmb(y~Grazing*proximity+Age+(1|site),data=Heath,zeroInflation=TRUE,family="binomial")
> >
> 
> 
> See the help file of glmmadmb:
> 
> zeroInflation:   whether a zero-inflated model should be fitted (only 
> "poisson" and "nbinom" families).
> 
> With emphasis on the last part in this sentence.
> 
> Kind regards,
> 
> 
> Alain
> 
> 
> > The majority of the models for Species
> > 1 have been running fine, however I have been getting the occasional error
> > message and for Species 2, all models give an error message.
> >
> >
> > Example error messages:
> >
> > Parameters were estimated, but not standard errors
> > were not: the most likely problem is that the curvature at MLE was zero or
> > negative
> >
> > Error in glmmadmb(w ~ Grazing * proximity + Age + (1 | site), data =
> > heathland,  :
> >
> >    The function maximizer failed (couldn't find STD file) Troubleshooting
> > steps include (1) run with 'save.dir' set and inspect output files; (2) change
> > run parameters: see '?admbControl'
> >
> > Warning message:
> >
> > In glmmadmb(w ~ 1 + (1 | site), data = heathland, zeroInflation = T,  :
> >
> >    Convergence failed:log-likelihood of gradient= -0.269018
> >
> >
> >
> > I just wanted to check that this is a sensible
> > way to deal with these data and if there is anything that I should be doing to
> > remedy the error messages? I've tried some other options, e.g. Arc sine
> > transformation couldn't deal with the excess zeros. I've also considered
> > quasibinomial in lme4, but have seen Doug Bates comments on the unreliability
> > of the model output.
> >
> >   
> >
> > Any advice would be very much appreciated.
> > All the best
> > Elwyn 		 	   		   		 	   		
> >
> > ------------------------------
> >
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > End of R-sig-mixed-models Digest, Vol 95, Issue 24
> > **************************************************
> >
> 
> -- 
> Dr. Alain F. Zuur
> 
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
> 
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Nov 19 22:04:03 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 19 Nov 2014 16:04:03 -0500
Subject: [R-sig-ME] glmmADMB error messages with percentage cover data
 (Elwyn Sharps)
In-Reply-To: <DUB126-W8474E884D1EE022B745FF1BE890@phx.gbl>
References: <mailman.3.1416394802.5720.r-sig-mixed-models@r-project.org>,
	<546CC790.80004@highstat.com>
	<DUB126-W8474E884D1EE022B745FF1BE890@phx.gbl>
Message-ID: <546D05C3.2000204@gmail.com>

On 14-11-19 12:16 PM, Elwyn Sharps wrote:
> Hi Alain, Thanks for your reply. Sorry I hadn't noticed this section
> of the glmmADMB help file and as some of the models were running
> fine, I assumed there wasn't a problem with the family. Have you got
> any other ideas on how I can deal with the very large number of zeros
> in the data? As it's percentage cover rather than count data, I don't
> think I can use Poisson or Neg Binomial. Thanks again Elwyn

   A couple of thoughts:

 + I believe glmmADMB *can* handle zero-inflated binomials (I would try
testing with a simple made-up data set to check that the results are
sensible).

 + does your plant cover variable have a meaningful denominator?  (e.g.,
if you had point-count data with 100 points, or with a known number of
points)  If you're just taking a percentage that's assessed from a
visual impression, or e.g. a measure of area from remote sensing, then
you probably don't have a variable that's actually binomial (or
zero-inflated binomial).  A beta distribution might be more appropriate,
but it too would have to be zero-inflated.

  + errors of the sort you're seeing are due to some sort of an
instability in the model -- might be fixable with a more recent version
of the glmmADMB binary files, which are available but I haven't gotten
around to packaging in a new version yet.


> 
>> Date: Wed, 19 Nov 2014 17:38:40 +0100 From: highstat at highstat.com 
>> To: r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME]
>> glmmADMB error messages with percentage cover data	(Elwyn Sharps)
>> 
>> 
>> 
>>> 
>>> I have collected data on % cover of a variety of plant species on
>>> heathland (in relation to nesting birds) and am interested in 
>>> testing the effect of density of grazing ponies, the proximity to
>>> nest site (%cover measured at 1 and 10m from the nest) and the
>>> age of the nest (as a control for vegetation being measured at
>>> nests of different ages). The response is percentage cover and
>>> contains many zeros (see attached data for an example).
>>> 
>>> 
>>> I have tried using glmmADMB, with family= binomial and zero
>>> inflation=T. The response was created using cbind e.g. 
>>> y<-(cbind(Data$Plant_cover, Data$Plant_empty)), where Plant cover
>>> = % cover and Plant empty = 100-Plant cover.
>>> 
>>> 
>>> Example model:
>>> 
>>> Fit1<-glmmadmb(y~Grazing*proximity+Age+(1|site),data=Heath,zeroInflation=TRUE,family="binomial")
>>>
>>
>>
>>
>>> 
See the help file of glmmadmb:
>> 
>> zeroInflation:   whether a zero-inflated model should be fitted
>> (only "poisson" and "nbinom" families).
>> 
>> With emphasis on the last part in this sentence.
>> 
>> Kind regards,
>> 
>> 
>> Alain
>> 
>> 
>>> The majority of the models for Species 1 have been running fine,
>>> however I have been getting the occasional error message and for
>>> Species 2, all models give an error message.
>>> 
>>> 
>>> Example error messages:
>>> 
>>> Parameters were estimated, but not standard errors were not: the
>>> most likely problem is that the curvature at MLE was zero or 
>>> negative
>>> 
>>> Error in glmmadmb(w ~ Grazing * proximity + Age + (1 | site),
>>> data = heathland,  :
>>> 
>>> The function maximizer failed (couldn't find STD file)
>>> Troubleshooting steps include (1) run with 'save.dir' set and
>>> inspect output files; (2) change run parameters: see
>>> '?admbControl'
>>> 
>>> Warning message:
>>> 
>>> In glmmadmb(w ~ 1 + (1 | site), data = heathland, zeroInflation =
>>> T,  :
>>> 
>>> Convergence failed:log-likelihood of gradient= -0.269018
>>> 
>>> 
>>> 
>>> I just wanted to check that this is a sensible way to deal with
>>> these data and if there is anything that I should be doing to 
>>> remedy the error messages? I've tried some other options, e.g.
>>> Arc sine transformation couldn't deal with the excess zeros. I've
>>> also considered quasibinomial in lme4, but have seen Doug Bates
>>> comments on the unreliability of the model output.
>>> 
>>> 
>>> 
>>> Any advice would be very much appreciated. All the best Elwyn
>>> 
>>> 
>>> ------------------------------
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models mailing list R-sig-mixed-models at r-project.org 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> End of R-sig-mixed-models Digest, Vol 95, Issue 24 
>>> **************************************************
>>> 
>> 
>> -- Dr. Alain F. Zuur
>> 
>> First author of: 1. Beginner's Guide to GAMM with R (2014). 2.
>> Beginner's Guide to GLM and GLMM with R (2013). 3. Beginner's Guide
>> to GAM with R (2012). 4. Zero Inflated Models and GLMM with R
>> (2012). 5. A Beginner's Guide to R (2009). 6. Mixed effects models
>> and extensions in ecology with R (2009). 7. Analysing Ecological
>> Data (2007).
>> 
>> Highland Statistics Ltd. 9 St Clair Wynd UK - AB41 6DZ Newburgh 
>> Tel:   0044 1358 788177 Email: highstat at highstat.com URL:
>> www.highstat.com
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From francescobryanromano at gmail.com  Thu Nov 20 00:48:40 2014
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Thu, 20 Nov 2014 00:48:40 +0100
Subject: [R-sig-ME] Help with mosaic plot
Message-ID: <CABZN5+E+=obSQrR_pDoaAod2+VWruzCAH0SjO9t6dEQCaHfvnw@mail.gmail.com>

I'm not sure which list to post this help request to but I thought I'd
start from here since the model is based on a glmer analysis.

I have a 2x2x2 table with two factors, prime and syntax-semantics, and a
dependent categorical dependent, response. Syntax-semantics has two levels,
+AN's+AN and +AN of +AN, Prime also has to levels, primed and non-primed,
and Response can be either correct or inversion.  I attach a copy of the
data below but I'm not sure it will display properly in the message. If
not, the data is Correct [ Prime (+AN 's +AN = 50, +AN of +AN = 36) &
Non-primed (+AN 's +AN = 52, +AN of +AN = 54)] and Inversion [ Prime (+AN
's +AN = 5, +AN of +AN = 10) & Non-primed (+AN 's +AN = 1, +AN of +AN =
3)].

I'm having a very hard time finding any instructions anywhere on how to get
the mosaic plot to display Prime and Syntax-semantics on the vertical axis
(left side) where the latter is nested in the former, and Response on the
top horizontal axis. This should generate four rows of boxes, alternating
+AN's+AN and +AN of +AN vertically twice, with each row split into correct
and inversion boxes.

I'm also looking for other cosmetics:(1) if the factors can't be nested,
Syntax-semantics must be on the left side; (2) a split and not just change
of shading between the correct and inversion boxes in each row as in
stacked bars; (3) the width of the correct and inversion boxes to be the
same across the row (the length of the box should express differences in
counts); (4) lighter grey shading for the correct box in each row; (5) no
borders on the boxes.

It is in keeping with other mosaic plots I've used where the priming factor
was irrelevant that I'm trying to stick to the above. A sample command line
I've been using is:

>mosaic(~Response|Syntax.Semantics, data = X, gp = gpar(fill =
grey.colors(2)[2:1]))

Many thanks in advance for any advice.

Frank


  Response

Primed

Non-primed



+AN 's +AN

+AN of +AN

+AN 's +AN

+AN of +AN

Correct

50

36

52

54

Inversion

5

10

1

3

	[[alternative HTML version deleted]]


From joanmolibo at gmail.com  Thu Nov 20 17:00:54 2014
From: joanmolibo at gmail.com (Joan Molibo)
Date: Thu, 20 Nov 2014 17:00:54 +0100
Subject: [R-sig-ME] Partial R2 in mixed models
Message-ID: <CAFtNk-sshw65G3m4_svOtaFOLzjdzTB-wVu=_j75XYUKdwpO_w@mail.gmail.com>

Good afternoon;

First, I am not a statistician although I am in the way (I am a medical
doctor studying the grade in statistic, still in the first course). I would
like to compute de partial R-squared of the fixed effects of a model. I
have found a function from the LMERConvenienceFunctions package, but it
computes these from the lme4 anova extraction function, which gives a
sequential anova.

I have created an ad hoc function to compute the R-squared for each term
conditionally to the other terms in the model (based on the pamer.fnc). For
other hand, I have done something similar based with the recommedations
given by Snijders in his book (2nd edition, pages 111-113) to compute de R2
in two levels models.

I am not very sure of what I have done, but I think that the function works
so I would appreciate some light. For other hand, could I call the
calculated value as partial R-squared value of the fixed effects of a mixed
model?

Thank you very much.

As example:

partialR2 <- function(model){
  # Based on SS

  term <- attr(terms(model), "term.labels")
  dv <- gsub(" ", "", gsub("(.*)~.*", "\\1", as.character(model at call)[2]))
  ss.tot <- sum((model at frame[, dv] - mean(model at frame[, dv]))^2)
  n <- length(term)
  ss.var <- numeric(n)
  form <- unlist(lapply(term, function(x) paste(paste(".~. -", x, sep =
""), x, sep = "+")))
  for (i in 1:(n - 1)){
    ss.var[i] <- as.data.frame(anova(update(model,
as.formula(form[i]))))[n, 2]
  }
  ss.var[n] <- as.data.frame(anova(model))[n, 2]
  names(ss.var[n]) <- term[n]
  out <- cbind(round(100 * ss.var/ss.tot, 5))
  rownames(out) <- term
  colnames(out) <- "Partial R2"

  #Snijder
  form <- paste(paste(".~ 1 + (1 |", names(ngrps(model)), sep = ""), ")",
sep = "")
  m.null <- update(model, as.formula(form))
  var.g.null <- VarCorr(m.null)[[1]][1]
  var.r.null <- sigma(m.null)^2
  var.null <- var.g.null + var.r.null

  var.g.full <- VarCorr(model)[[1]][1]
  var.r.full <- sigma(model)^2
  var.full <- var.g.full + var.r.full

  form <- unlist(lapply(term, function(x) paste(".~. -", x, sep = " ")))
  var.red <- numeric(n)
  for (i in n:1){
    var.g.red  <- VarCorr(update(model, as.formula(form[i])))[[1]][1]
    var.r.red <- sigma(update(model, as.formula(form[i])))^2
    var.red[i] <- var.g.red + var.r.red
  }

  out2 <- round(100 * (var.red - var.full)/var.null, 5)
  return(cbind(out, Partial_R2_Snijders = out2))
}


##################################################
##################################################


library(LMERConvenienceFunctions)
library(foreign)
library(lme4)
dd <- read.dta("
http://www.ats.ucla.edu/stat/stata/examples/mlm_ma_snijders/mlbook1.dta")
str(dd)
m1 <- lmer(langpost ~ sex + ses + iq_perf + langpret + (1|schoolnr), data =
dd)
summary(m1)
anova(m1)
pamer.fnc(m1)
partialR2(m1)

	[[alternative HTML version deleted]]


From asafw.at.wharton at gmail.com  Thu Nov 20 16:44:09 2014
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Thu, 20 Nov 2014 10:44:09 -0500
Subject: [R-sig-ME] Non-diagonal sampling covariance with lme4
In-Reply-To: <CAO7JsnQdu1ZWUXp8bf9ZfzZ1J+S_G4v+_f_fLY2HLo0gb7-HgQ@mail.gmail.com>
References: <CAGG0PdAB4TF5iNB-EeRNp_e_FhNwFz8Aaopr5N6RgXYW0fd7uQ@mail.gmail.com>
	<CAO7JsnQdu1ZWUXp8bf9ZfzZ1J+S_G4v+_f_fLY2HLo0gb7-HgQ@mail.gmail.com>
Message-ID: <CAGG0PdC2Nefi4sYe==Abc4W3=WjV7wffMN0_w48ZfLcjRtV-PA@mail.gmail.com>

Thanks a lot, Douglas and Ben. Right, pre-whitening will give me what I'm
looking for!

Asaf

On 17 November 2014 11:07, Douglas Bates <bates at stat.wisc.edu> wrote:

> You can "pre-whiten" the response and the model matrices by multiplying by
> either the right or left inverse Cholesky factor of V.  (I always need to
> write out the equations before i can determine if I should use the left or
> the right factor.)
>
> On Mon Nov 17 2014 at 9:11:45 AM Asaf Weinstein <
> asafw.at.wharton at gmail.com> wrote:
>
>> Hi all,
>>
>> I would like to obtain ML (or REML) estimates for theta, beta, sigsq in
>>
>> Y|B=b ~ N( Zb + Xbeta, sigsq*V )
>> B ~ N( 0,Sigma(theta) )
>>
>> where V is a known covariance matrix. lmer() does exactly that for V=I_n
>> (the n-by-n identity matrix); I wonder if there is a way to specify an
>> arbitrary covariance matrix.
>>
>> Thanks so much,
>>
>> Asaf
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From janeemwilkinson at gmail.com  Thu Nov 20 05:53:20 2014
From: janeemwilkinson at gmail.com (Janee Wilkinson)
Date: Thu, 20 Nov 2014 15:23:20 +1030
Subject: [R-sig-ME] interpretation of range value from lme model with
 exponential correlation structure
Message-ID: <CAH33qZjG_zrsMekhbzbrppRgXuAUFp+Nxd_wZnwrPSxejwKbww@mail.gmail.com>

Hi there,

I am fitting a model using the lme function with an exponential correlation
structure, e.g.
lme(y~fixed1+fixed2, random =~1|subject,
        cor=corExp(form=~distance|subject,nugget=TRUE))

How do I interpret the range value?

In a paper I described the range as the distance at which observations are
uncorrelated but a reviewer has said this is incorrect and that the range
specifies the rate at which the correlation tends to zero.

I thought that the usual interpretation of the range was that observations
separated by less than the range are spatially autocorrelated, whereas
observations further apart than the range are not.

>From the help file for corExp, letting d denote the range and n denote the
nugget effect, the correlation between two observations a distance r apart
is (1-n)*exp(-r/d). So when the distance=range, the correlation will be
(1-n)*exp(-1), which will not be zero.

Any help would be much appreciated.

Thanks,

Janee.

	[[alternative HTML version deleted]]


From webbsjulie at gmail.com  Wed Nov 19 23:54:29 2014
From: webbsjulie at gmail.com (Julie Webbs)
Date: Wed, 19 Nov 2014 22:54:29 +0000
Subject: [R-sig-ME] Advice
Message-ID: <CAOQbByhag9vyf73j6gysMvV7JAE=dYpgUG_sp82uBc5K578d5A@mail.gmail.com>

Dear lme4 Authors


My model  is:  persons are crossed with an item  and nested with job
interviewers. P ? (Items: interviewers)


I would like to compute var. Com.  using lme4 ( with all random effects) ,
but I do not know how to write codes using lme4, specially when factors are
nested.


The matrix is :


p     interviewers    item

1         1                 10

1          2                11

2          1                 13

2          2                 14

.           .                   .

.           .                   .


I really appreciate for your advise, Looking forward to hearing from you


Many thanks

Julie

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Thu Nov 20 17:49:37 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 20 Nov 2014 10:49:37 -0600
Subject: [R-sig-ME] interpretation of range value from lme model with
 exponential correlation structure
In-Reply-To: <CAH33qZjG_zrsMekhbzbrppRgXuAUFp+Nxd_wZnwrPSxejwKbww@mail.gmail.com>
References: <CAH33qZjG_zrsMekhbzbrppRgXuAUFp+Nxd_wZnwrPSxejwKbww@mail.gmail.com>
Message-ID: <CAKFxdiRB6K3mHHp3tHrttghajgDgrNeQpSVWV99L1oC9kBdGOA@mail.gmail.com>

I have an example in the agridat package you might find useful.  First
the code and then a bit of interpretation.

require(agridat)
dat <- harris.wateruse
dat <- subset(dat, day!=268)
# Rescale day for nicer output, and convergence issues, add quadratic term
dat <- transform(dat, ti=day/100)
dat <- transform(dat, ti2=ti*ti)
require(nlme)
m3l <- lme(water ~ 0 + age:species + age:species:ti + age:species:ti2,
          data=dat, na.action=na.omit,
          random = list(tree=pdDiag(~1+ti)),
          cor = corExp(form=~ day|tree),
          )
print(m3l)

Linear mixed-effects model fit by REML
  Data: dat
  Log-restricted-likelihood: -497.8969
  Fixed: water ~ 0 + age:species + age:species:ti + age:species:ti2

ageA1:speciesS1     ageA2:speciesS1     ageA1:speciesS2     ageA2:speciesS2
         -14.569534          -12.305968           -6.749603          -11.362943
 ageA1:speciesS1:ti  ageA2:speciesS1:ti  ageA1:speciesS2:ti  ageA2:speciesS2:ti
          14.408342           13.538021            7.920372           12.837023
ageA1:speciesS1:ti2 ageA2:speciesS1:ti2 ageA1:speciesS2:ti2 ageA2:speciesS2:ti2
          -2.980521           -2.856673           -1.844861           -2.940303

Random effects:
 Formula: ~1 + ti | tree
 Structure: Diagonal
        (Intercept)        ti  Residual
StdDev:   0.3935732 0.1668882 0.4000106

Correlation Structure: Exponential spatial correlation
 Formula: ~day | tree
 Parameter estimate(s):
   range
4.721752
Number of Observations: 953
Number of Groups: 40


This example comes from a book by Schabenberger & Pierce. See:
http://books.google.com/books?id=c2Rr_J7geGQC&pg=PA518#v=onepage&q&f=false

They say "since the measurement times are coded in days, this estimate
of phi=4.721752 implies that water usage exhibits temporal correlation
over 3*phi = 14.16 days."

They did not justify this...it looks like a rule-of-thumb.  Note that
exp(-14.16/4.7217) = .05.

Kevin


On Wed, Nov 19, 2014 at 10:53 PM, Janee Wilkinson
<janeemwilkinson at gmail.com> wrote:
> Hi there,
>
> I am fitting a model using the lme function with an exponential correlation
> structure, e.g.
> lme(y~fixed1+fixed2, random =~1|subject,
>         cor=corExp(form=~distance|subject,nugget=TRUE))
>
> How do I interpret the range value?
>
> In a paper I described the range as the distance at which observations are
> uncorrelated but a reviewer has said this is incorrect and that the range
> specifies the rate at which the correlation tends to zero.
>
> I thought that the usual interpretation of the range was that observations
> separated by less than the range are spatially autocorrelated, whereas
> observations further apart than the range are not.
>
> >From the help file for corExp, letting d denote the range and n denote the
> nugget effect, the correlation between two observations a distance r apart
> is (1-n)*exp(-r/d). So when the distance=range, the correlation will be
> (1-n)*exp(-1), which will not be zero.
>
> Any help would be much appreciated.
>
> Thanks,
>
> Janee.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Kevin Wright


From tina.wey at gmail.com  Thu Nov 20 22:18:17 2014
From: tina.wey at gmail.com (Tina Wey)
Date: Thu, 20 Nov 2014 22:18:17 +0100
Subject: [R-sig-ME] from: Tina Wey
Message-ID: <E22DE52F-351B-42EA-D0B6-97EAD53E7078@sasktel.net>

Hi

http://associ.jp/within.php?wrong=muke35v7pf7g





Tina Wey

Sent from my iPhone


From bbolker at gmail.com  Thu Nov 20 22:35:09 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 20 Nov 2014 16:35:09 -0500
Subject: [R-sig-ME] glmmADMB error messages with percentage cover data
 (Elwyn Sharps)
In-Reply-To: <DUB126-W10F87732CE6B5EE4394DD1BE760@phx.gbl>
References: <mailman.3.1416394802.5720.r-sig-mixed-models@r-project.org>, ,
	<546CC790.80004@highstat.com>,
	<DUB126-W8474E884D1EE022B745FF1BE890@phx.gbl>,
	<546D05C3.2000204@gmail.com>
	<DUB126-W10F87732CE6B5EE4394DD1BE760@phx.gbl>
Message-ID: <546E5E8D.4050609@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-11-20 01:45 PM, Elwyn Sharps wrote:
> Hi Ben, Thank you very much for your reply. The plant cover data
> was assessed by eye so I should probably be trying a
> (zero-inflated) beta distribution as you suggested. Do you have any
> tips for which R package to use? I've seen that this is possible 
> using gamlss. However, I was wondering if it is straightforward to
> add a random effect when using these models? Thanks again
> 
> Elwyn

  I think you're going to have some difficulty finding an approach
that will easily handle this combination (beta regression,
zero-inflation, random effects).  Alain Zuur is correct that you can
learn how to do this in JAGS/WinBUGS; you could also try Richard
McElreath's "rethinking" package
(https://github.com/rmcelreath/rethinking), which is the same sort of
front end for the Stan package. Or you could use AD Model Builder or
Template Model Builder.  All of these approaches will have some
startup cost, though.  Another possibility would be to use a
zero-inflated beta regression approach and try to find a way to get
robust standard error estimates for the parameters.


> 
> 
> 
>> Date: Wed, 19 Nov 2014 16:04:03 -0500 From: bbolker at gmail.com To:
>> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] glmmADMB
>> error messages with percentage cover data (Elwyn Sharps)
>> 
>> On 14-11-19 12:16 PM, Elwyn Sharps wrote:
>>> Hi Alain, Thanks for your reply. Sorry I hadn't noticed this
>>> section of the glmmADMB help file and as some of the models
>>> were running fine, I assumed there wasn't a problem with the
>>> family. Have you got any other ideas on how I can deal with the
>>> very large number of zeros in the data? As it's percentage
>>> cover rather than count data, I don't think I can use Poisson
>>> or Neg Binomial. Thanks again Elwyn
>> 
>> A couple of thoughts:
>> 
>> + I believe glmmADMB *can* handle zero-inflated binomials (I
>> would try testing with a simple made-up data set to check that
>> the results are sensible).
>> 
>> + does your plant cover variable have a meaningful denominator?
>> (e.g., if you had point-count data with 100 points, or with a
>> known number of points)  If you're just taking a percentage
>> that's assessed from a visual impression, or e.g. a measure of
>> area from remote sensing, then you probably don't have a variable
>> that's actually binomial (or zero-inflated binomial).  A beta
>> distribution might be more appropriate, but it too would have to
>> be zero-inflated.
>> 
>> + errors of the sort you're seeing are due to some sort of an 
>> instability in the model -- might be fixable with a more recent
>> version of the glmmADMB binary files, which are available but I
>> haven't gotten around to packaging in a new version yet.
>> 
>> 
>>> 
>>>> Date: Wed, 19 Nov 2014 17:38:40 +0100 From:
>>>> highstat at highstat.com To: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] glmmADMB error messages with
>>>> percentage cover data	(Elwyn Sharps)
>>>> 
>>>> 
>>>> 
>>>>> 
>>>>> I have collected data on % cover of a variety of plant
>>>>> species on heathland (in relation to nesting birds) and am
>>>>> interested in testing the effect of density of grazing
>>>>> ponies, the proximity to nest site (%cover measured at 1
>>>>> and 10m from the nest) and the age of the nest (as a
>>>>> control for vegetation being measured at nests of different
>>>>> ages). The response is percentage cover and contains many
>>>>> zeros (see attached data for an example).
>>>>> 
>>>>> 
>>>>> I have tried using glmmADMB, with family= binomial and
>>>>> zero inflation=T. The response was created using cbind e.g.
>>>>>  y<-(cbind(Data$Plant_cover, Data$Plant_empty)), where
>>>>> Plant cover = % cover and Plant empty = 100-Plant cover.
>>>>> 
>>>>> 
>>>>> Example model:
>>>>> 
>>>>> Fit1<-glmmadmb(y~Grazing*proximity+Age+(1|site),data=Heath,zeroInflation=TRUE,family="binomial")
>>>>>
>>>>
>>>>
>>>>
>>>>>
>>
>>>>> 
See the help file of glmmadmb:
>>>> 
>>>> zeroInflation:   whether a zero-inflated model should be
>>>> fitted (only "poisson" and "nbinom" families).
>>>> 
>>>> With emphasis on the last part in this sentence.
>>>> 
>>>> Kind regards,
>>>> 
>>>> 
>>>> Alain
>>>> 
>>>> 
>>>>> The majority of the models for Species 1 have been running
>>>>> fine, however I have been getting the occasional error
>>>>> message and for Species 2, all models give an error
>>>>> message.
>>>>> 
>>>>> 
>>>>> Example error messages:
>>>>> 
>>>>> Parameters were estimated, but not standard errors were
>>>>> not: the most likely problem is that the curvature at MLE
>>>>> was zero or negative
>>>>> 
>>>>> Error in glmmadmb(w ~ Grazing * proximity + Age + (1 |
>>>>> site), data = heathland,  :
>>>>> 
>>>>> The function maximizer failed (couldn't find STD file) 
>>>>> Troubleshooting steps include (1) run with 'save.dir' set
>>>>> and inspect output files; (2) change run parameters: see 
>>>>> '?admbControl'
>>>>> 
>>>>> Warning message:
>>>>> 
>>>>> In glmmadmb(w ~ 1 + (1 | site), data = heathland,
>>>>> zeroInflation = T,  :
>>>>> 
>>>>> Convergence failed:log-likelihood of gradient= -0.269018
>>>>> 
>>>>> 
>>>>> 
>>>>> I just wanted to check that this is a sensible way to deal
>>>>> with these data and if there is anything that I should be
>>>>> doing to remedy the error messages? I've tried some other
>>>>> options, e.g. Arc sine transformation couldn't deal with
>>>>> the excess zeros. I've also considered quasibinomial in
>>>>> lme4, but have seen Doug Bates comments on the
>>>>> unreliability of the model output.
>>>>> 
>>>>> 
>>>>> 
>>>>> Any advice would be very much appreciated. All the best
>>>>> Elwyn
>>>>> 
>>>>> 
>>>>> ------------------------------
>>>>> 
>>>>> _______________________________________________ 
>>>>> R-sig-mixed-models mailing list
>>>>> R-sig-mixed-models at r-project.org 
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> 
>>>>> 
>>>>> End of R-sig-mixed-models Digest, Vol 95, Issue 24 
>>>>> **************************************************
>>>>> 
>>>> 
>>>> -- Dr. Alain F. Zuur
>>>> 
>>>> First author of: 1. Beginner's Guide to GAMM with R (2014).
>>>> 2. Beginner's Guide to GLM and GLMM with R (2013). 3.
>>>> Beginner's Guide to GAM with R (2012). 4. Zero Inflated
>>>> Models and GLMM with R (2012). 5. A Beginner's Guide to R
>>>> (2009). 6. Mixed effects models and extensions in ecology
>>>> with R (2009). 7. Analysing Ecological Data (2007).
>>>> 
>>>> Highland Statistics Ltd. 9 St Clair Wynd UK - AB41 6DZ
>>>> Newburgh Tel:   0044 1358 788177 Email: highstat at highstat.com
>>>> URL: www.highstat.com
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUbl6NAAoJEOCV5YRblxUHA+AH/RtYzua6i3nq5MdmhoLp6D9a
5S574wdgl/OrTeEUrGv0zgIe8OT2TQJWl3ahHWxhHhjpt1mfJ+vIAINlFlJtwooA
XUxK6aFzGXbS3Xi25hJWug+Bf3q7oTZ2DA9SwmCA6OQ7L74i3FGaUn2xT5tbTaJU
Qv2GSkg77Qs39AHfIrjiWiBOKc6FrtMv95cLsqcpHShcWs4gUfZrHFhl6N8g7JSx
5W6oV8JeZYVRNhRnIJpftOPxb7c7pq+OG6OYTj3XDTRE/EoNT22KCUSQ4A2A3tif
d4laFsjOGA4C8hSRXAurKX9Z9O7RKPBVP77uMFQaq6bWAsE6870Bl6zxAbtkH6c=
=Q5AC
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Fri Nov 21 04:28:06 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 20 Nov 2014 22:28:06 -0500
Subject: [R-sig-ME] glmmadmb function
In-Reply-To: <26202_1416520377_sAKLqrEJ032215_CA+RzyNDNT+br7NE4EWXS2jTxKB0CucuiAWmXx-LvuRWF8xWDAA@mail.gmail.com>
References: <26202_1416520377_sAKLqrEJ032215_CA+RzyNDNT+br7NE4EWXS2jTxKB0CucuiAWmXx-LvuRWF8xWDAA@mail.gmail.com>
Message-ID: <546EB146.5080003@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  [taking the liberty of cc'ing to r-sig-mixed-models]

  How badly/why do you need to use glmmadmb?  So far I don't see
anything in the model that requires it (you've got binary data, so
zero-inflation won't be relevant ...)  I'd recommend glmer (which
takes about a minute even with all of the fastest settings I know
about, so glmmadmb is likely to be much slower).  I might even
recommend gamm4, which would allow you to fit smooth responses to
ResDist ...

  There are some updated binaries of glmmadmb that might fix the
problem -- I haven't gotten around to putting them into the package
yet, but if you say why you need glmmadmb I can post some information
about how to update the binaries on your system ...

L <- load("CoyoteAllData.RData")
library("ggplot2"); theme_set(theme_bw())
library("mgcv")
ggplot(all.data,aes(x=ResDist,y=Used,colour=Sex,shape=Status,linetype=Status))+
    geom_point(position=position_jitter(height=0.05),alpha=0.2)+
        facet_wrap(~LandCover)+
        geom_smooth(method="gam",family=binomial)

nrow(all.data)
library("lme4")
system.time(g1 <- glmer(Used~Sex+Status+LandCover+ResDist+(1 |ID),
            data=all.data, family=binomial(link="logit"),
            control=glmerControl(optimizer=nloptwrap)))

table(all.data$Used)

On 14-11-20 04:52 PM, Sharon Poessel wrote:
> Dr. Bolker,
> 
> I'm attempting to use the glmmadmb function to run the following
> model:
> 
> globmod5 = glmmadmb(Used~Sex+Status+LandCover+ResDist+(1 | 
> ID),data=all.data, family="binomial", link="logit")
> 
> I'm attaching the dataset.  "Used" is a 0,1 response variable,
> "ResDist" is a continuous variable, and all other variables are
> categorical.  Each row represents a location of a coyote (1 =
> actual locations, 0 = random locations).
> 
> I'm using glmmADMB version 0.8.0, R version 3.1.0, and Windows 7
> 64-bit OS.
> 
> I'm getting the following error message when I run the model, which
> is similar to what others have received:
> 
> Error in glmmadmb(Used ~ Sex + Status + LandCover + ResDist + (1 |
> ID),  : The function maximizer failed (couldn't find STD file)
> Troubleshooting steps include (1) run with 'save.dir' set and
> inspect output files; (2) change run parameters: see
> '?admbControl' In addition: Warning message: running command
> 'C:\Windows\system32\cmd.exe /c 
> "C:/.../R/win-library/3.1/glmmADMB/bin/windows64/glmmadmb.exe"
> -maxfn 500 -maxph 5' had status 1
> 
> As previously suggested, I also tried
> admb.opts=admbControl(shess=FALSE,noinit=FALSE) and
> save.dir="tmp", but I get the same error messages.  Previous posts
> have indicated that older versions of the package may not give this
> message.  Is there anything else I can try using the current,
> newest version of the package?
> 
> Also, if I run this same model in glmer, I get no error messages,
> so I don't think it's the structure of my model.
> 
> Thank you for your help.
> 
> Sharon Poessel
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUbrFGAAoJEOCV5YRblxUHrA4H/iJtibQCxd0rjirwJaYWzckd
fHdG21VVvtI9d/D4mmkDaGJmX6529aru9vvGVRAI7JreEIwrqNBD9+mXycAwpSm2
+QFCP5TzAEgHDbidueXoiY1swDug9TJ9sySGnLbNK/v85M0wd3ddrj6uTJjQsRK9
VTz4TaZml8XNTDLSx21LRUvLx73y4ZGIoc+2gOOWI+jjrBCIyV6cC5aBGyT5+Qz3
PjGv1FefPx4pk1hD1QrX/x+U9VepjQGZo0NEOJt6Uk/q8+zQDBIRCKu6aw4NB6te
ODEEwA0latJheYOTcMr0TFL4MRs3MOrp07h/Tk/2MgcLdOK93BWMjGWJfa4mCKw=
=m35N
-----END PGP SIGNATURE-----


From joanmolibo at gmail.com  Fri Nov 21 12:06:35 2014
From: joanmolibo at gmail.com (Joan Molibo)
Date: Fri, 21 Nov 2014 12:06:35 +0100
Subject: [R-sig-ME] Partial R2 in mixed models
In-Reply-To: <CAFtNk-sshw65G3m4_svOtaFOLzjdzTB-wVu=_j75XYUKdwpO_w@mail.gmail.com>
References: <CAFtNk-sshw65G3m4_svOtaFOLzjdzTB-wVu=_j75XYUKdwpO_w@mail.gmail.com>
Message-ID: <CAFtNk-s-q1FW3a-X-9-7K7+s_K7SyoNrf_KBmMVmOm+nU==2+g@mail.gmail.com>

Sorry, yesterday I tried to generalize the function without get it
completely, so I have corrected some mistakes.

Below there is a corrected version.

And, please, apologize my audacity.

=======================================

partialR2 <- function(model){
  # Based on SS
  term <- attr(terms(model), "term.labels")
  dv <- gsub(" ", "", gsub("(.*)~.*", "\\1", as.character(model at call)[2]))
  ss.tot <- sum((model at frame[, dv] - mean(model at frame[, dv]))^2)
  n <- length(term)
  ss.var <- numeric(n)
  form <- unlist(lapply(term, function(x) paste(paste(".~. -", x, sep =
""), x, sep = "+")))

  inter.term <- FALSE

  if (sum(unlist(sapply(term, function(x) grep(":", x)))) >= 1 |
        sum(unlist(sapply(term, function(x) grep("*", x)))) >= 1)
inter.term = TRUE

  if (inter.term == TRUE){
    for (i in 1:(n-1)){
      sub.model <- update(model, as.formula(form[i]))
      ss.var[i] <- as.data.frame(anova(sub.model))[n-1, 2]
    }
    ss.var[n] <- as.data.frame(anova(sub.model))[n, 2]
  }else{
    for (i in 1:(n)){
      sub.model <- update(model, as.formula(form[i]))
      ss.var[i] <- as.data.frame(anova(sub.model))[n, 2]
    }
  }

  names(ss.var[n]) <- term[n]
  out <- cbind(round(100 * ss.var/ss.tot, 5))
  rownames(out) <- term
  colnames(out) <- "Partial R2"

  #Snijder (it gives zero for the interaction components, to find the
values
  #update the models without them.

  form <- paste(paste(".~ 1 + (1 |", names(ngrps(model)), sep = ""), ")",
sep = "")
  m.null <- update(model, as.formula(form))
  var.g.null <- VarCorr(m.null)[[1]][1]
  var.r.null <- sigma(m.null)^2
  var.null <- var.g.null + var.r.null

  var.g.full <- VarCorr(model)[[1]][1]
  var.r.full <- sigma(model)^2
  var.full <- var.g.full + var.r.full

  form <- unlist(lapply(term, function(x) paste(".~. -", x, sep = " ")))
  var.red <- numeric(n)
  for (i in n:1){
    var.g.red  <- VarCorr(update(model, as.formula(form[i])))[[1]][1]
    var.r.red <- sigma(update(model, as.formula(form[i])))^2
    var.red[i] <- var.g.red + var.r.red
  }

  out2 <- round(100 * (var.red - var.full)/var.null, 5)
  return(cbind(out, Partial_R2_Snijders = out2))
}



2014-11-20 17:00 GMT+01:00 Joan Molibo <joanmolibo at gmail.com>:

>
> Good afternoon;
>
> First, I am not a statistician although I am in the way (I am a medical
> doctor studying the grade in statistic, still in the first course). I would
> like to compute de partial R-squared of the fixed effects of a model. I
> have found a function from the LMERConvenienceFunctions package, but it
> computes these from the lme4 anova extraction function, which gives a
> sequential anova.
>
> I have created an ad hoc function to compute the R-squared for each term
> conditionally to the other terms in the model (based on the pamer.fnc). For
> other hand, I have done something similar based with the recommedations
> given by Snijders in his book (2nd edition, pages 111-113) to compute de R2
> in two levels models.
>
> I am not very sure of what I have done, but I think that the function
> works so I would appreciate some light. For other hand, could I call the
> calculated value as partial R-squared value of the fixed effects of a mixed
> model?
>
> Thank you very much.
>
> As example:
>
> partialR2 <- function(model){
>   # Based on SS
>
>   term <- attr(terms(model), "term.labels")
>   dv <- gsub(" ", "", gsub("(.*)~.*", "\\1", as.character(model at call)[2]))
>   ss.tot <- sum((model at frame[, dv] - mean(model at frame[, dv]))^2)
>   n <- length(term)
>   ss.var <- numeric(n)
>   form <- unlist(lapply(term, function(x) paste(paste(".~. -", x, sep =
> ""), x, sep = "+")))
>   for (i in 1:(n - 1)){
>     ss.var[i] <- as.data.frame(anova(update(model,
> as.formula(form[i]))))[n, 2]
>   }
>   ss.var[n] <- as.data.frame(anova(model))[n, 2]
>   names(ss.var[n]) <- term[n]
>   out <- cbind(round(100 * ss.var/ss.tot, 5))
>   rownames(out) <- term
>   colnames(out) <- "Partial R2"
>
>   #Snijder
>   form <- paste(paste(".~ 1 + (1 |", names(ngrps(model)), sep = ""), ")",
> sep = "")
>   m.null <- update(model, as.formula(form))
>   var.g.null <- VarCorr(m.null)[[1]][1]
>   var.r.null <- sigma(m.null)^2
>   var.null <- var.g.null + var.r.null
>
>   var.g.full <- VarCorr(model)[[1]][1]
>   var.r.full <- sigma(model)^2
>   var.full <- var.g.full + var.r.full
>
>   form <- unlist(lapply(term, function(x) paste(".~. -", x, sep = " ")))
>   var.red <- numeric(n)
>   for (i in n:1){
>     var.g.red  <- VarCorr(update(model, as.formula(form[i])))[[1]][1]
>     var.r.red <- sigma(update(model, as.formula(form[i])))^2
>     var.red[i] <- var.g.red + var.r.red
>   }
>
>   out2 <- round(100 * (var.red - var.full)/var.null, 5)
>   return(cbind(out, Partial_R2_Snijders = out2))
> }
>
>
> ##################################################
> ##################################################
>
>
> library(LMERConvenienceFunctions)
> library(foreign)
> library(lme4)
> dd <- read.dta("
> http://www.ats.ucla.edu/stat/stata/examples/mlm_ma_snijders/mlbook1.dta")
> str(dd)
> m1 <- lmer(langpost ~ sex + ses + iq_perf + langpret + (1|schoolnr), data
> = dd)
> summary(m1)
> anova(m1)
> pamer.fnc(m1)
> partialR2(m1)
>
>
>

	[[alternative HTML version deleted]]


From m.tasallizadeh at modares.ac.ir  Sat Nov 22 07:57:37 2014
From: m.tasallizadeh at modares.ac.ir (m.tasallizadeh)
Date: Sat, 22 Nov 2014 10:27:37 +0330
Subject: [R-sig-ME] Error in predict a linear mixed model with predict
Message-ID: <WC20141122065737.590B7B@modares.ac.ir>

Hi Dear Dr bolker.
Hope you are in good health. I amMeysam Tasallizadeh, a MSc. student in 
statistics at Tarbiat Modares University, Tehran, Iran. I plan to work on 
longitudinal data in my thesis.
I want to predict a linear mixed model with predict function that is below:

predict(f1,full.data)
Error in (function (x, n)  : new levels detected in newdata

full.data is dataframe that the has dimension 3600x6 and f1 is beloow:
            f1 
<-lmer(y~time+time|indiv,data=comp.data[comp.data$weight!=0,],REML=REML,weights=NULL) 
# lme fit.

I would highly appreciate it if you consider my question in error in predict 
linear mixed model.
meysam tasallazadeh khemes
MSc. student of    Statistics
Department of Statistics
Faculty of Mathematical Sciences
Tarbiat Modares University
Tehran -  Islamic republic of Iran
	[[alternative HTML version deleted]]


From whitworth.alex at gmail.com  Sat Nov 22 17:45:01 2014
From: whitworth.alex at gmail.com (Alex Whitworth)
Date: Sat, 22 Nov 2014 08:45:01 -0800
Subject: [R-sig-ME] MLM / HLM diagnostics
Message-ID: <CA+8zgH+CyXo_izEJe767LRGYgn0sDPWtctpYfAXNauA+emNEiQ@mail.gmail.com>

Hello,

Is anyone aware of any R packages for doing MLM diganostics, such as those
suggested by Hilden-Minton (1995), Snijders & Berkhof (2007), or  Zewotir &
Galpin (2005)? I'm curious if an implementation already exists or if I'll
need to write my own.

Thanks for your time and help!

Alex Whitworth
whitworth.alex at gmail.com

	[[alternative HTML version deleted]]


From joanmolibo at gmail.com  Mon Nov 24 15:12:11 2014
From: joanmolibo at gmail.com (Joan Molibo)
Date: Mon, 24 Nov 2014 15:12:11 +0100
Subject: [R-sig-ME] Partial R2 in mixed models
In-Reply-To: <CAFtNk-s-q1FW3a-X-9-7K7+s_K7SyoNrf_KBmMVmOm+nU==2+g@mail.gmail.com>
References: <CAFtNk-sshw65G3m4_svOtaFOLzjdzTB-wVu=_j75XYUKdwpO_w@mail.gmail.com>
	<CAFtNk-s-q1FW3a-X-9-7K7+s_K7SyoNrf_KBmMVmOm+nU==2+g@mail.gmail.com>
Message-ID: <CAFtNk-tU94jgJufO72-L7ona9SpKMg9m88_jpzrwZ+vxrGJhjg@mail.gmail.com>

Finally, I have found this work An R^2 statistics for fixed effects in the
linear mixed model. Stat Med 2008 28: 6137, which has been of great help.

R2.mmixed <- function(model, d = 5){
  require(pbkrtest)
  term <- attr(terms(model), "term.labels")
  n.term <- length(term)
  form <- paste(paste(".~ 1 + (1 |", names(ngrps(model)), sep = ""), ")",
sep = "")
  m.null <- update(model, as.formula(form))
  kr <- KRmodcomp(model, m.null)[[1]]
  R2 <- kr[1, 1] * kr[1, 3]^(-1) * length(term)/(1 + kr[1, 1] * kr[1,
3]^(-1) * n.term)
  R2 <- round(R2 * 100, d)

  aov.model <- Anova(model, test.statistic = "F", type = 3)
  p.R2 <- numeric(n.term)
  for (i in 1:n.term){
    p.R2[i] <- aov.model[i+1, 1] * (aov.model[i+1, 3])^(-1) *
aov.model[i+1, 2]/(1 + aov.model[i+1, 1] * (aov.model[i+1, 3])^(-1) *
aov.model[i+1, 2])
  }
  p.R2 <- matrix(round(p.R2*100, d), ncol = 1);
  rownames(p.R2) <- term
  colnames(p.R2) <- "Estimate"
  l <- list("Model R-squared (fix effects)" = R2, "Partial R-squared" =
p.R2)
  return(l)
}

2014-11-21 12:06 GMT+01:00 Joan Molibo <joanmolibo at gmail.com>:

> Sorry, yesterday I tried to generalize the function without get it
> completely, so I have corrected some mistakes.
>
> Below there is a corrected version.
>
> And, please, apologize my audacity.
>
> =======================================
>
> partialR2 <- function(model){
>   # Based on SS
>   term <- attr(terms(model), "term.labels")
>   dv <- gsub(" ", "", gsub("(.*)~.*", "\\1", as.character(model at call)[2]))
>   ss.tot <- sum((model at frame[, dv] - mean(model at frame[, dv]))^2)
>   n <- length(term)
>   ss.var <- numeric(n)
>   form <- unlist(lapply(term, function(x) paste(paste(".~. -", x, sep =
> ""), x, sep = "+")))
>
>   inter.term <- FALSE
>
>   if (sum(unlist(sapply(term, function(x) grep(":", x)))) >= 1 |
>         sum(unlist(sapply(term, function(x) grep("*", x)))) >= 1)
> inter.term = TRUE
>
>   if (inter.term == TRUE){
>     for (i in 1:(n-1)){
>       sub.model <- update(model, as.formula(form[i]))
>       ss.var[i] <- as.data.frame(anova(sub.model))[n-1, 2]
>     }
>     ss.var[n] <- as.data.frame(anova(sub.model))[n, 2]
>   }else{
>     for (i in 1:(n)){
>       sub.model <- update(model, as.formula(form[i]))
>       ss.var[i] <- as.data.frame(anova(sub.model))[n, 2]
>     }
>   }
>
>   names(ss.var[n]) <- term[n]
>   out <- cbind(round(100 * ss.var/ss.tot, 5))
>   rownames(out) <- term
>   colnames(out) <- "Partial R2"
>
>   #Snijder (it gives zero for the interaction components, to find the
> values
>   #update the models without them.
>
>   form <- paste(paste(".~ 1 + (1 |", names(ngrps(model)), sep = ""), ")",
> sep = "")
>   m.null <- update(model, as.formula(form))
>   var.g.null <- VarCorr(m.null)[[1]][1]
>   var.r.null <- sigma(m.null)^2
>   var.null <- var.g.null + var.r.null
>
>   var.g.full <- VarCorr(model)[[1]][1]
>   var.r.full <- sigma(model)^2
>   var.full <- var.g.full + var.r.full
>
>   form <- unlist(lapply(term, function(x) paste(".~. -", x, sep = " ")))
>   var.red <- numeric(n)
>   for (i in n:1){
>     var.g.red  <- VarCorr(update(model, as.formula(form[i])))[[1]][1]
>     var.r.red <- sigma(update(model, as.formula(form[i])))^2
>     var.red[i] <- var.g.red + var.r.red
>   }
>
>   out2 <- round(100 * (var.red - var.full)/var.null, 5)
>   return(cbind(out, Partial_R2_Snijders = out2))
> }
>
>
>
> 2014-11-20 17:00 GMT+01:00 Joan Molibo <joanmolibo at gmail.com>:
>
>>
>> Good afternoon;
>>
>> First, I am not a statistician although I am in the way (I am a medical
>> doctor studying the grade in statistic, still in the first course). I would
>> like to compute de partial R-squared of the fixed effects of a model. I
>> have found a function from the LMERConvenienceFunctions package, but it
>> computes these from the lme4 anova extraction function, which gives a
>> sequential anova.
>>
>> I have created an ad hoc function to compute the R-squared for each term
>> conditionally to the other terms in the model (based on the pamer.fnc). For
>> other hand, I have done something similar based with the recommedations
>> given by Snijders in his book (2nd edition, pages 111-113) to compute de R2
>> in two levels models.
>>
>> I am not very sure of what I have done, but I think that the function
>> works so I would appreciate some light. For other hand, could I call the
>> calculated value as partial R-squared value of the fixed effects of a mixed
>> model?
>>
>> Thank you very much.
>>
>> As example:
>>
>> partialR2 <- function(model){
>>   # Based on SS
>>
>>   term <- attr(terms(model), "term.labels")
>>   dv <- gsub(" ", "", gsub("(.*)~.*", "\\1", as.character(model at call
>> )[2]))
>>   ss.tot <- sum((model at frame[, dv] - mean(model at frame[, dv]))^2)
>>   n <- length(term)
>>   ss.var <- numeric(n)
>>   form <- unlist(lapply(term, function(x) paste(paste(".~. -", x, sep =
>> ""), x, sep = "+")))
>>   for (i in 1:(n - 1)){
>>     ss.var[i] <- as.data.frame(anova(update(model,
>> as.formula(form[i]))))[n, 2]
>>   }
>>   ss.var[n] <- as.data.frame(anova(model))[n, 2]
>>   names(ss.var[n]) <- term[n]
>>   out <- cbind(round(100 * ss.var/ss.tot, 5))
>>   rownames(out) <- term
>>   colnames(out) <- "Partial R2"
>>
>>   #Snijder
>>   form <- paste(paste(".~ 1 + (1 |", names(ngrps(model)), sep = ""), ")",
>> sep = "")
>>   m.null <- update(model, as.formula(form))
>>   var.g.null <- VarCorr(m.null)[[1]][1]
>>   var.r.null <- sigma(m.null)^2
>>   var.null <- var.g.null + var.r.null
>>
>>   var.g.full <- VarCorr(model)[[1]][1]
>>   var.r.full <- sigma(model)^2
>>   var.full <- var.g.full + var.r.full
>>
>>   form <- unlist(lapply(term, function(x) paste(".~. -", x, sep = " ")))
>>   var.red <- numeric(n)
>>   for (i in n:1){
>>     var.g.red  <- VarCorr(update(model, as.formula(form[i])))[[1]][1]
>>     var.r.red <- sigma(update(model, as.formula(form[i])))^2
>>     var.red[i] <- var.g.red + var.r.red
>>   }
>>
>>   out2 <- round(100 * (var.red - var.full)/var.null, 5)
>>   return(cbind(out, Partial_R2_Snijders = out2))
>> }
>>
>>
>> ##################################################
>> ##################################################
>>
>>
>> library(LMERConvenienceFunctions)
>> library(foreign)
>> library(lme4)
>> dd <- read.dta("
>> http://www.ats.ucla.edu/stat/stata/examples/mlm_ma_snijders/mlbook1.dta")
>> str(dd)
>> m1 <- lmer(langpost ~ sex + ses + iq_perf + langpret + (1|schoolnr), data
>> = dd)
>> summary(m1)
>> anova(m1)
>> pamer.fnc(m1)
>> partialR2(m1)
>>
>>
>>
>

	[[alternative HTML version deleted]]


From marko.bachl at uni-hohenheim.de  Mon Nov 24 15:46:21 2014
From: marko.bachl at uni-hohenheim.de (Marko Bachl)
Date: Mon, 24 Nov 2014 15:46:21 +0100
Subject: [R-sig-ME] MLM / HLM diagnostics
In-Reply-To: <CA+8zgH+CyXo_izEJe767LRGYgn0sDPWtctpYfAXNauA+emNEiQ@mail.gmail.com>
References: <CA+8zgH+CyXo_izEJe767LRGYgn0sDPWtctpYfAXNauA+emNEiQ@mail.gmail.com>
Message-ID: <CAE5vbrtD3=Gy9OWQTPGjEEUSynoc03O7=gpEgXpYDCJUgd+s5g@mail.gmail.com>

Hi Alex,
there is the HLMdiag package
(http://cran.r-project.org/web/packages/HLMdiag/index.html). It is
described in JSS: http://www.jstatsoft.org/v56/i05.
I have not used it myself, but it looks very promising.
Best regards
Marko



2014-11-22 17:45 GMT+01:00 Alex Whitworth <whitworth.alex at gmail.com>:
> Hello,
>
> Is anyone aware of any R packages for doing MLM diganostics, such as those
> suggested by Hilden-Minton (1995), Snijders & Berkhof (2007), or  Zewotir &
> Galpin (2005)? I'm curious if an implementation already exists or if I'll
> need to write my own.
>
> Thanks for your time and help!
>
> Alex Whitworth
> whitworth.alex at gmail.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Dr. Marko Bachl
Universit?t Hohenheim
Institut f?r Kommunikationswissenschaft (540C)
T 0711 459 228 66
M marko.bachl at uni-hohenheim.de
W www.komm.uni-hohenheim.de/bachl


From yanlianglee at live.com  Mon Nov 24 16:24:43 2014
From: yanlianglee at live.com (Lee Yan Liang)
Date: Mon, 24 Nov 2014 15:24:43 +0000
Subject: [R-sig-ME] =?windows-1256?q?Approximation_to_Marginal_Likelihood_?=
 =?windows-1256?q?of_GLMM_in_lme4=FE?=
Message-ID: <BAY176-W30DB59D99363384642BE8DD4720@phx.gbl>

Hi Ben,

I suppose lme4 assumes the random effects has a multivariate normal distribution with mean vector 0 and
a variance-covariance matrix. In that case, the marginal likelihood (obtained by integrating out the likelihood
and random effect distributions) cannot be obtained in closed-form. 

I am not sure what type of approximations (quadrature, laplace, PQL etc.) do you use in lme4 for generalised 
linear mixed effects model? And do you have any good advice in choosing optimisers available in the package 
optimx? 

Thank you.
 		 	   		  
	[[alternative HTML version deleted]]


From holtermann at hwwi.org  Mon Nov 24 16:21:53 2014
From: holtermann at hwwi.org (Linus Holtermann)
Date: Mon, 24 Nov 2014 16:21:53 +0100
Subject: [R-sig-ME] Need help with Random Effect specification: nested
 Random Effects and a_priori known regimes (MCMCglmm)
Message-ID: <AD0050057515F54084E7D5B93478C8481FC6620731@winxbede39.exchange.xchg>

Dear list members,

I need some advices with the specification of the Random Effects in my Mixed model.
I got Panel data from 500 (i) district nested in 50 (j) towns over 10 (t) years.
There are 3 ex-ante known regimes (r) that are district specific and vary with t. So every district is in regime 1 or 2 or 3 and that might change over 
time. I know a priori in which regime the districts are at time point t.
My goal is to analyse asymetric impacts of covariates X on y. y is growth of Output. I apply a simple dummy specification, which uses regime 1 as reference.
I estimated a mixed model via MCMCglmm (pooled mixed model):

prior_1 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V = diag(1), nu = 0.002)))
model1 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X ,random=~town,prior=prior_1)
int = intercept
D2 and D3 are dummy-variables indicating that district i is in regime 2 or 3

The random intercept for towns controls for the town specific impacts on growth of districts. But in the specification above, only "int" posseses a random intercept. So only the town specific impact on growth in the reference regime 1 is captured by the random intercept. If i assume that the town specific influence is different between the 3 regimes, can I fit the model as:

prior_2 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V = diag(1), nu = 0.002),G2 = list(V = diag(1), nu = 0.002),G3 = list(V = diag(1), nu = 0.002)))))
model2 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X ,random=~town + D2:town + D3:town, prior=prior_2)

Or are there better solutions to take care of the different town specific influence on district growth during the 3 regimes? 
Alternatively:

prior_3 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V = diag(3), nu = 0.002)))
model3 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X ,random=~ idh(as.factor(regime)):town, prior=prior_3)

This time the Random Effects are correlated, which is not the case in model2, right?


Thanks in advance,


Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org
 
Amtsgericht Hamburg HRB 94303
Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
Prokura: Dipl. Kauffrau Alexis Malchin
Umsatzsteuer-ID: DE 241849425

From ken.beath at mq.edu.au  Mon Nov 24 22:55:04 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Tue, 25 Nov 2014 08:55:04 +1100
Subject: [R-sig-ME]
	=?utf-8?q?Approximation_to_Marginal_Likelihood_of_GLMM?=
	=?utf-8?b?IGluIGxtZTTigI8=?=
In-Reply-To: <BAY176-W30DB59D99363384642BE8DD4720@phx.gbl>
References: <BAY176-W30DB59D99363384642BE8DD4720@phx.gbl>
Message-ID: <CAF5_5cz2ruztreu4d9EnXSAsQbVdHm57Z_RUTKfM+LOM63VG8Q@mail.gmail.com>

It is in the package documentation, either Laplace or adaptive
Gauss-Hermite is available.

For optimization methods use a quasi-Newton (BFGS) if it works, Nelder-Mead
otherwise, I would avoid the others.

These are questions you should have been able to answer yourself.


On 25 November 2014 at 02:24, Lee Yan Liang <yanlianglee at live.com> wrote:

> Hi Ben,
>
> I suppose lme4 assumes the random effects has a multivariate normal
> distribution with mean vector 0 and
> a variance-covariance matrix. In that case, the marginal likelihood
> (obtained by integrating out the likelihood
> and random effect distributions) cannot be obtained in closed-form.
>
> I am not sure what type of approximations (quadrature, laplace, PQL etc.)
> do you use in lme4 for generalised
> linear mixed effects model? And do you have any good advice in choosing
> optimisers available in the package
> optimx?
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From j.hadfield at ed.ac.uk  Tue Nov 25 10:31:00 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 25 Nov 2014 09:31:00 +0000
Subject: [R-sig-ME] Need help with Random Effect specification: nested
 Random Effects and a_priori known regimes (MCMCglmm)
In-Reply-To: <AD0050057515F54084E7D5B93478C8481FC6620731@winxbede39.exchange.xchg>
References: <AD0050057515F54084E7D5B93478C8481FC6620731@winxbede39.exchange.xchg>
Message-ID: <20141125093100.19071gbrv1q2ungg@www.staffmail.ed.ac.uk>

Hi Linus,

In model 2 they are correlated, but its a bit weird. The 3x3  
covariance matrix looks like

V1   V1   V1
V1 V1+V2  V1
V1   V1  V1+V3

where V1, V2 and V3 are the variances associated with town, D2:town  
and D3:town. Amongst other things this model does not allow the  
influence of town under regimes 2 and 3 to be less than that in regime  
1.

In model 3 the effects are not correlated (because an idh structure is  
used) and the 3x3 covariance matrix looks like:

V1 0  0
0  V2 0
0  0  V3

model 1 has constant variance and perfect correlation:

V1   V1  V1
V1   V1  V1
V1   V1  V1

Perhaps better options would be

a) us(regime):town which is a completely unstructured covariance  
matrix with 6 parameters (3 variances and 3 covariances)

or

b) town+regime:town which has covariance matrix:

V1+V2  V1    V1
   V1  V1+V2  V1
   V1   V1   V1+V2

giving constant variance and constant (non-zero) correlation.

Cheers,

Jarrod

Quoting Linus Holtermann <holtermann at hwwi.org> on Mon, 24 Nov 2014  
16:21:53 +0100:

> Dear list members,
>
> I need some advices with the specification of the Random Effects in  
> my Mixed model.
> I got Panel data from 500 (i) district nested in 50 (j) towns over  
> 10 (t) years.
> There are 3 ex-ante known regimes (r) that are district specific and  
> vary with t. So every district is in regime 1 or 2 or 3 and that  
> might change over
> time. I know a priori in which regime the districts are at time point t.
> My goal is to analyse asymetric impacts of covariates X on y. y is  
> growth of Output. I apply a simple dummy specification, which uses  
> regime 1 as reference.
> I estimated a mixed model via MCMCglmm (pooled mixed model):
>
> prior_1 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V =  
> diag(1), nu = 0.002)))
> model1 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X  
> ,random=~town,prior=prior_1)
> int = intercept
> D2 and D3 are dummy-variables indicating that district i is in regime 2 or 3
>
> The random intercept for towns controls for the town specific  
> impacts on growth of districts. But in the specification above, only  
> "int" posseses a random intercept. So only the town specific impact  
> on growth in the reference regime 1 is captured by the random  
> intercept. If i assume that the town specific influence is different  
> between the 3 regimes, can I fit the model as:
>
> prior_2 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V =  
> diag(1), nu = 0.002),G2 = list(V = diag(1), nu = 0.002),G3 = list(V  
> = diag(1), nu = 0.002)))))
> model2 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X  
> ,random=~town + D2:town + D3:town, prior=prior_2)
>
> Or are there better solutions to take care of the different town  
> specific influence on district growth during the 3 regimes?
> Alternatively:
>
> prior_3 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V =  
> diag(3), nu = 0.002)))
> model3 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X  
> ,random=~ idh(as.factor(regime)):town, prior=prior_3)
>
> This time the Random Effects are correlated, which is not the case  
> in model2, right?
>
>
> Thanks in advance,
>
>
> Linus Holtermann
> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
> Heimhuder Stra?e 71
> 20148 Hamburg
> Tel +49-(0)40-340576-336
> Fax+49-(0)40-340576-776
> Internet: www.hwwi.org
> Email: holtermann at hwwi.org
>
> Amtsgericht Hamburg HRB 94303
> Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
> Prokura: Dipl. Kauffrau Alexis Malchin
> Umsatzsteuer-ID: DE 241849425
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Thierry.ONKELINX at inbo.be  Tue Nov 25 12:12:05 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 25 Nov 2014 11:12:05 +0000
Subject: [R-sig-ME] glmmadmb random effects help
In-Reply-To: <CF43A319ADEA8F4C8A3D29B418DC65D4A58E54@057-SN2MPN2-101.057d.mgd.msft.net>
References: <CF43A319ADEA8F4C8A3D29B418DC65D4A54A48@057-SN2MPN2-101.057d.mgd.msft.net>
	<AA818EAD2576BC488B4F623941DA7427F3B36419@inbomail.inbo.be>
	<CF43A319ADEA8F4C8A3D29B418DC65D4A58E54@057-SN2MPN2-101.057d.mgd.msft.net>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B4FE6C@inbomail.inbo.be>

Dear Greg,

1) Residuals versus fit don't make that much sense in case of a glm. I'd rather look at the residuals versus the covariates.
2) It looks like you are interpreting the main effects. Don't forget that you have included interactions with temp. You cannot interpret main effects without the interaction terms. Make plots to inspect their combined effect.
3) centering should not affect the parameter estimates, scaling will do that.

PS releveling the factors prior to the analysis gives cleaner output

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

Van: Hacker, Greg (CDPH-CID-DCDC) [mailto:Greg.Hacker at cdph.ca.gov]
Verzonden: maandag 24 november 2014 21:08
Aan: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
Onderwerp: RE: glmmadmb random effects help

Thank you for your response!  I finally got back to looking at the data and after adjusting my models like you said I get a top model like this:

Call:
glmmadmb(formula = Tot_I_pac ~ temp + hum + temp:hum + fSeason +
    temp:fSeason + relevel(Dom.Overstory, ref = "None") + relevel(Dom.Understory,
    ref = "Sage") + relevel(Aspect, ref = "S") + (1 | Month) +
    (1 | fTrans/fSite), data = Ticks, family = "nbinom")

AIC: 7538.9

Coefficients:
                                                Estimate Std. Error z value Pr(>|z|)
(Intercept)                                      -3.0600     1.5585   -1.96  0.04960 *
temp                                              1.1624     0.3052    3.81  0.00014 ***
hum                                              -0.0300     0.0918   -0.33  0.74418
fSeason2                                         -0.4756     0.1494   -3.18  0.00146 **
fSeason3                                         -0.6348     0.1422   -4.46  8.1e-06 ***
relevel(Dom.Overstory, ref = "None")Gray Pine     1.2139     0.2796    4.34  1.4e-05 ***
relevel(Dom.Overstory, ref = "None")Oak           0.9111     0.1638    5.56  2.7e-08 ***
relevel(Dom.Understory, ref = "Sage")Fern         0.4565     0.3350    1.36  0.17300
relevel(Dom.Understory, ref = "Sage")Grass       -0.0842     0.2387   -0.35  0.72427
relevel(Dom.Understory, ref = "Sage")Poison Oak   0.0232     0.2706    0.09  0.93166
relevel(Dom.Understory, ref = "Sage")Woody Forb  -0.3829     0.2826   -1.36  0.17541
relevel(Aspect, ref = "S")E                      -0.3922     0.2562   -1.53  0.12574
relevel(Aspect, ref = "S")N                      -0.5272     0.3459   -1.52  0.12742
relevel(Aspect, ref = "S")NW                     -0.4281     0.3530   -1.21  0.22519
relevel(Aspect, ref = "S")SE                     -0.0537     0.3322   -0.16  0.87160
relevel(Aspect, ref = "S")SSW                    -0.1702     0.2886   -0.59  0.55534
relevel(Aspect, ref = "S")SW                      0.2673     0.3304    0.81  0.41866
relevel(Aspect, ref = "S")W                       0.2274     0.2780    0.82  0.41337
temp:hum                                         -0.7485     0.1365   -5.49  4.1e-08 ***
temp:fSeason2                                     0.3925     0.2863    1.37  0.17042
temp:fSeason3                                    -0.5624     0.2435   -2.31  0.02091 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Number of observations: total=3190, Month=11, fTrans=11, fTrans:fSite=110
Random effect variance(s):
Group=Month
            Variance StdDev
(Intercept)    23.46  4.844
Group=fTrans
            Variance StdDev
(Intercept)   0.3047  0.552
Group=fTrans:fSite
            Variance StdDev
(Intercept)   0.1431 0.3783

Negative binomial dispersion parameter: 1.3755 (std. err.: 0.096618)

Log-likelihood: -3744.43




I have some additional questions I was hoping you could answer.

1) I don't quite understand how to interpret the plot of fitted vs. residuals generated from this model.  Can anyone lend a hand here?
2) The temp, hum, and fseason coefficients don't seems to reflect what the raw data shows.  Generally, tick numbers should decrease with increased temp, increase with increased humidity, and my data show that seasons 1 and 3 had similar numbers of ticks and season two was drastically lower.  Is this all a result of poor model fit?  If so, what other model types or families can I try?
3) I'm getting different coefficient estimates of the top model with scaled and centered parameters and the same model without.  For example, the model with scaled params results in a coef for temp=1.1624, but the same model with just raw numbers results in temp=0.351.  Is this just a function of the scaling?

Thank you again!

Greg


-----Original Message-----
From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
Sent: Monday, November 10, 2014 12:11 AM
To: Hacker, Greg (CDPH-CID-DCDC); r-sig-mixed-models at r-project.org
Subject: RE: glmmadmb random effects help

Dear Greg,

You need to use (1|fTrans/fSite). This is site nested in transect. Note that the random effect of transect should have 11 observation and not 110 as in your current summary.

Month will be crossed with site (and transect).

You could calculate the AIC by hand to check if the AIC in the summary is correct.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] namens Hacker, Greg (CDPH-CID-DCDC) [Greg.Hacker at cdph.ca.gov]
Verzonden: vrijdag 7 november 2014 19:01
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] glmmadmb random effects help

Hello all,

I am hoping to get some expert guidance on an analysis I am attempting.  At the very least I hope you can tell me if I'm on the right track.  If I'm not, maybe you can nudge me in the right direction.

I have data that consists of repeated counts of ticks that were collected at 110 different sites around a portion of a reservoir. These 110 sites were grouped into 11 transects (I'm thinking nesting here).  The counts were collected monthly (although some months were missed) over 3 years (years = Oct-Sept to account for tick biology).  Along with this I have several continuous and categorical ecological variables (e.g., canopy coverage, dominant overstory/understory veg, average temp, relative humidity, aspect, etc...).  I'm hoping to create a candidate set of models that I can then use AIC (or something related) to determine the best fit.  In the end I'm hoping to have a model that can reasonably predict abundance of ticks based on a subset of environmental variables.

>From what I've read I have too few seasons to use as a random effect.  I believe the month, site, and transect variables should all be considered random effects, with site nested in transect.  However, site/transect is also crossed with month and season(fixed effect).  Below I have provided the output (minus the coefs for fixef) from the summary of my global model (at least the most complex model I could use without getting errors).

Call:
glmmadmb(formula = Tot_I_pac ~ SWave.max.temp + ave.rh + SWave.max.temp:ave.rh +
    Perc_Canopy + Dom.Overstory + Perc_Canopy * Dom.Overstory +
    Dom.Midstory + Dom.Understory + Aspect + Soil.Type + fSeason +
    (1 | Month) + (1 | fSite/fTrans), data = Ticks, family = "nbinom")

AIC: 7589

Number of observations: total=3190, Month=11, fSite=110, fSite:fTrans=110 Random effect variance(s):
Group=Month
            Variance StdDev
(Intercept)     18.8  4.336
Group=fSite
            Variance StdDev
(Intercept)   0.1429  0.378
Group=fSite:fTrans
            Variance StdDev
(Intercept)   0.1061 0.3257

Negative binomial dispersion parameter: 1.4 (std. err.: 0.096)

Log-likelihood: -3762

Does everything seem reasonable here? Does the way I wrote the random effects portion of the model relate to the description of the data?  Does this model take into account that month and the site/transect combination are crossed with season?  Finally, is the AIC score provided in the summary what should be used to rank the models or should it be ignored and calculated by hand (does the AICtab function utilize this score)?

Forgive me, I am only a wildlife biologist who knows only enough to get myself into trouble!  Thank you in advance for any advice folks can provide!

Cheers!

Greg

Greg Hacker
Biologist

Public Health Foundation Enterprises
California Department of Public Health
Vector-Borne Disease Section
8633 Bond Rd.,
Elk Grove, CA 95624





        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From pierces1 at msu.edu  Tue Nov 25 14:26:41 2014
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 25 Nov 2014 08:26:41 -0500
Subject: [R-sig-ME] MLM / HLM diagnostics
In-Reply-To: <CAE5vbrtD3=Gy9OWQTPGjEEUSynoc03O7=gpEgXpYDCJUgd+s5g@mail.gmail.com>
References: <CA+8zgH+CyXo_izEJe767LRGYgn0sDPWtctpYfAXNauA+emNEiQ@mail.gmail.com>
	<CAE5vbrtD3=Gy9OWQTPGjEEUSynoc03O7=gpEgXpYDCJUgd+s5g@mail.gmail.com>
Message-ID: <000001d008b3$73950aa0$5abf1fe0$@msu.edu>

The influence.ME package may be useful as well. 


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Marko Bachl [mailto:marko.bachl at uni-hohenheim.de] 
Sent: Monday, November 24, 2014 9:46 AM
To: Alex Whitworth
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MLM / HLM diagnostics

Hi Alex,
there is the HLMdiag package
(http://cran.r-project.org/web/packages/HLMdiag/index.html). It is
described in JSS: http://www.jstatsoft.org/v56/i05.
I have not used it myself, but it looks very promising.
Best regards
Marko



2014-11-22 17:45 GMT+01:00 Alex Whitworth <whitworth.alex at gmail.com>:
> Hello,
>
> Is anyone aware of any R packages for doing MLM diganostics, such as those
> suggested by Hilden-Minton (1995), Snijders & Berkhof (2007), or  Zewotir &
> Galpin (2005)? I'm curious if an implementation already exists or if I'll
> need to write my own.
>
> Thanks for your time and help!
>
> Alex Whitworth
> whitworth.alex at gmail.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Dr. Marko Bachl
Universit?t Hohenheim
Institut f?r Kommunikationswissenschaft (540C)
T 0711 459 228 66
M marko.bachl at uni-hohenheim.de
W www.komm.uni-hohenheim.de/bachl


From sharpoes at gmail.com  Sun Nov 23 22:04:53 2014
From: sharpoes at gmail.com (Sharon Poessel)
Date: Sun, 23 Nov 2014 14:04:53 -0700
Subject: [R-sig-ME] Robust SEs in GLMMs
Message-ID: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>

When computing resource selection functions for animal telemetry data with
a binary response variable, where the 1s represent animal location data,
which are spatially and temporally correlated, and the 0s represent random
locations, which are not correlated, it is recommended to calculate robust,
or empirical, standard errors instead of using the model-based standard
errors to account for this differing correlation structure.  As far as I
can tell, none of the glmm packages in R calculate these robust SEs.  Does
anyone know of a way to use glmms that calculate these?  Thanks.

Sharon

	[[alternative HTML version deleted]]


From holtermann at hwwi.org  Tue Nov 25 17:52:25 2014
From: holtermann at hwwi.org (Linus Holtermann)
Date: Tue, 25 Nov 2014 17:52:25 +0100
Subject: [R-sig-ME] Need help with Random Effect specification: nested
 Random Effects and a_priori known regimes (MCMCglmm)
In-Reply-To: <20141125093100.19071gbrv1q2ungg@www.staffmail.ed.ac.uk>
References: <AD0050057515F54084E7D5B93478C8481FC6620731@winxbede39.exchange.xchg>,
	<20141125093100.19071gbrv1q2ungg@www.staffmail.ed.ac.uk>
Message-ID: <AD0050057515F54084E7D5B93478C8481FC6620734@winxbede39.exchange.xchg>

Hello Jarrod,

I guess, that your suggestion a) might be the best choice for my model:

 prior_a <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V =diag(3), nu = 0.002)))
model_a <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X,random=~us(regime):town, prior=prior_1a

int = intercept
D2 and D3 are dummy-variables indicating that district i is in regime 2 or 3

in this specification, we have random intercepts for int, D2:int and D3:int. So we can show the difference in town sepficic impact on district growth between the 3 regimes. The covariances give further Iiformation about the correlation between these impacts.

Is it possible to estimate an addidtional idependent random effect, that captures the unobservable county specific time-invariant effect? That is similiar to a classical random effect in Panel data models. It is important that both types of random effects are independent of each other and among themselves.

Bests,


Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org

Amtsgericht Hamburg HRB 94303
Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
Prokura: Dipl. Kauffrau Alexis Malchin
Umsatzsteuer-ID: DE 241849425
________________________________________
Von: Jarrod Hadfield [j.hadfield at ed.ac.uk]
Gesendet: Dienstag, 25. November 2014 10:31
An: Linus Holtermann
Cc: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Need help with Random Effect specification: nested Random Effects and a_priori known regimes (MCMCglmm)

Hi Linus,

In model 2 they are correlated, but its a bit weird. The 3x3
covariance matrix looks like

V1   V1   V1
V1 V1+V2  V1
V1   V1  V1+V3

where V1, V2 and V3 are the variances associated with town, D2:town
and D3:town. Amongst other things this model does not allow the
influence of town under regimes 2 and 3 to be less than that in regime
1.

In model 3 the effects are not correlated (because an idh structure is
used) and the 3x3 covariance matrix looks like:

V1 0  0
0  V2 0
0  0  V3

model 1 has constant variance and perfect correlation:

V1   V1  V1
V1   V1  V1
V1   V1  V1

Perhaps better options would be

a) us(regime):town which is a completely unstructured covariance
matrix with 6 parameters (3 variances and 3 covariances)

or

b) town+regime:town which has covariance matrix:

V1+V2  V1    V1
   V1  V1+V2  V1
   V1   V1   V1+V2

giving constant variance and constant (non-zero) correlation.

Cheers,

Jarrod

Quoting Linus Holtermann <holtermann at hwwi.org> on Mon, 24 Nov 2014
16:21:53 +0100:

> Dear list members,
>
> I need some advices with the specification of the Random Effects in
> my Mixed model.
> I got Panel data from 500 (i) district nested in 50 (j) towns over
> 10 (t) years.
> There are 3 ex-ante known regimes (r) that are district specific and
> vary with t. So every district is in regime 1 or 2 or 3 and that
> might change over
> time. I know a priori in which regime the districts are at time point t.
> My goal is to analyse asymetric impacts of covariates X on y. y is
> growth of Output. I apply a simple dummy specification, which uses
> regime 1 as reference.
> I estimated a mixed model via MCMCglmm (pooled mixed model):
>
> prior_1 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V =
> diag(1), nu = 0.002)))
> model1 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X
> ,random=~town,prior=prior_1)
> int = intercept
> D2 and D3 are dummy-variables indicating that district i is in regime 2 or 3
>
> The random intercept for towns controls for the town specific
> impacts on growth of districts. But in the specification above, only
> "int" posseses a random intercept. So only the town specific impact
> on growth in the reference regime 1 is captured by the random
> intercept. If i assume that the town specific influence is different
> between the 3 regimes, can I fit the model as:
>
> prior_2 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V =
> diag(1), nu = 0.002),G2 = list(V = diag(1), nu = 0.002),G3 = list(V
> = diag(1), nu = 0.002)))))
> model2 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X
> ,random=~town + D2:town + D3:town, prior=prior_2)
>
> Or are there better solutions to take care of the different town
> specific influence on district growth during the 3 regimes?
> Alternatively:
>
> prior_3 <- list(R = list(V = 1, nu=0.002), G = list(G1 = list(V =
> diag(3), nu = 0.002)))
> model3 <- MCMCglmm(y~ int + D2:int + D3:int + X + D2:X + D3:X
> ,random=~ idh(as.factor(regime)):town, prior=prior_3)
>
> This time the Random Effects are correlated, which is not the case
> in model2, right?
>
>
> Thanks in advance,
>
>
> Linus Holtermann
> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
> Heimhuder Stra?e 71
> 20148 Hamburg
> Tel +49-(0)40-340576-336
> Fax+49-(0)40-340576-776
> Internet: www.hwwi.org
> Email: holtermann at hwwi.org
>
> Amtsgericht Hamburg HRB 94303
> Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
> Prokura: Dipl. Kauffrau Alexis Malchin
> Umsatzsteuer-ID: DE 241849425
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From tmeeha at gmail.com  Tue Nov 25 18:19:38 2014
From: tmeeha at gmail.com (Tim Meehan)
Date: Tue, 25 Nov 2014 10:19:38 -0700
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
Message-ID: <CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>

Hi Sharon,

Take a look at glmmPQL in the MASS package.  This function allows you to
model a binary response, with random effects, and temporally and spatially
correlated errors.  If you model the correlations, there is less of a need
for adjusting standard errors.

Best,
Tim


On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com> wrote:

> When computing resource selection functions for animal telemetry data with
> a binary response variable, where the 1s represent animal location data,
> which are spatially and temporally correlated, and the 0s represent random
> locations, which are not correlated, it is recommended to calculate robust,
> or empirical, standard errors instead of using the model-based standard
> errors to account for this differing correlation structure.  As far as I
> can tell, none of the glmm packages in R calculate these robust SEs.  Does
> anyone know of a way to use glmms that calculate these?  Thanks.
>
> Sharon
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From tmeeha at gmail.com  Tue Nov 25 18:56:49 2014
From: tmeeha at gmail.com (Tim Meehan)
Date: Tue, 25 Nov 2014 10:56:49 -0700
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
Message-ID: <CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com>

Hi Sharon,

I just looked over a paper by Bolker et al. (2008. GLMMs: a practical guide
for ecology and evolution. TREE).  Turns out that while it is possible to
model binary data with glmmPQL, it's not really recommended.  Nonetheless,
you might look for other options that involve modeling autocorrelation
rather than correcting for it after the fact.

Best,
Tim


On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com> wrote:

> Hi Sharon,
>
> Take a look at glmmPQL in the MASS package.  This function allows you to
> model a binary response, with random effects, and temporally and spatially
> correlated errors.  If you model the correlations, there is less of a need
> for adjusting standard errors.
>
> Best,
> Tim
>
>
> On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com>
> wrote:
>
>> When computing resource selection functions for animal telemetry data with
>> a binary response variable, where the 1s represent animal location data,
>> which are spatially and temporally correlated, and the 0s represent random
>> locations, which are not correlated, it is recommended to calculate
>> robust,
>> or empirical, standard errors instead of using the model-based standard
>> errors to account for this differing correlation structure.  As far as I
>> can tell, none of the glmm packages in R calculate these robust SEs.  Does
>> anyone know of a way to use glmms that calculate these?  Thanks.
>>
>> Sharon
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From sharpoes at gmail.com  Tue Nov 25 18:55:56 2014
From: sharpoes at gmail.com (Sharon Poessel)
Date: Tue, 25 Nov 2014 10:55:56 -0700
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
Message-ID: <CA+RzyNDGWuGT8oHYMrq4DNTW+jWSn8HYvTuVftQ2aq3rSLL2DQ@mail.gmail.com>

Thanks Tim.  I've only briefly looked at that function, so I'll check it
out in more detail.

Sharon

On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com> wrote:

> Hi Sharon,
>
> Take a look at glmmPQL in the MASS package.  This function allows you to
> model a binary response, with random effects, and temporally and spatially
> correlated errors.  If you model the correlations, there is less of a need
> for adjusting standard errors.
>
> Best,
> Tim
>
>
> On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com>
> wrote:
>
>> When computing resource selection functions for animal telemetry data with
>> a binary response variable, where the 1s represent animal location data,
>> which are spatially and temporally correlated, and the 0s represent random
>> locations, which are not correlated, it is recommended to calculate
>> robust,
>> or empirical, standard errors instead of using the model-based standard
>> errors to account for this differing correlation structure.  As far as I
>> can tell, none of the glmm packages in R calculate these robust SEs.  Does
>> anyone know of a way to use glmms that calculate these?  Thanks.
>>
>> Sharon
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Tue Nov 25 19:16:05 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 25 Nov 2014 18:16:05 +0000
Subject: [R-sig-ME] Robust SEs in GLMMs
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
	<CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com>
Message-ID: <CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com>

You have to be careful when modeling auto-correlation in a binary
response.  When using a Gaussian distribution it is possible to model the
variance and correlation separately from the mean.  No so for a Bernoulli
distribution (or binomial or Poisson).  In some sense the whole purpose of
generalized linear models is to take into account that the variance of each
response is determined by its mean in these distributions.

glmmPQL is a wrapper around the lme function from the nlme package. But
lme, which provides for modelling correlations, was not intended for this
purpose.  I personally don't think it would make sense to use a correlation
function with a binary response.

A preferred approach is to incorporate Gaussian-distributed random effects
that have the desired auto-correlation pattern.

On Tue Nov 25 2014 at 11:58:08 AM Tim Meehan <tmeeha at gmail.com> wrote:

> Hi Sharon,
>
> I just looked over a paper by Bolker et al. (2008. GLMMs: a practical guide
> for ecology and evolution. TREE).  Turns out that while it is possible to
> model binary data with glmmPQL, it's not really recommended.  Nonetheless,
> you might look for other options that involve modeling autocorrelation
> rather than correcting for it after the fact.
>
> Best,
> Tim
>
>
> On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com> wrote:
>
> > Hi Sharon,
> >
> > Take a look at glmmPQL in the MASS package.  This function allows you to
> > model a binary response, with random effects, and temporally and
> spatially
> > correlated errors.  If you model the correlations, there is less of a
> need
> > for adjusting standard errors.
> >
> > Best,
> > Tim
> >
> >
> > On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com>
> > wrote:
> >
> >> When computing resource selection functions for animal telemetry data
> with
> >> a binary response variable, where the 1s represent animal location data,
> >> which are spatially and temporally correlated, and the 0s represent
> random
> >> locations, which are not correlated, it is recommended to calculate
> >> robust,
> >> or empirical, standard errors instead of using the model-based standard
> >> errors to account for this differing correlation structure.  As far as I
> >> can tell, none of the glmm packages in R calculate these robust SEs.
> Does
> >> anyone know of a way to use glmms that calculate these?  Thanks.
> >>
> >> Sharon
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From tmeeha at gmail.com  Tue Nov 25 20:11:22 2014
From: tmeeha at gmail.com (Tim Meehan)
Date: Tue, 25 Nov 2014 12:11:22 -0700
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
	<CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com>
	<CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com>
Message-ID: <CAMTWOzovOHF=3hgG+MvcRQaw=tNjY8WiNpKBC+6qP1eTMM8vGg@mail.gmail.com>

Thanks for clarifying the problem with correlation functions and binary
responses, Doug.  Regarding the random effects approach, how would one set
that up?  Would you divide the data into spatial or temporal blocks, and
use the blocks in the random statement, for example?

On Tue, Nov 25, 2014 at 11:16 AM, Douglas Bates <bates at stat.wisc.edu> wrote:

> You have to be careful when modeling auto-correlation in a binary
> response.  When using a Gaussian distribution it is possible to model the
> variance and correlation separately from the mean.  No so for a Bernoulli
> distribution (or binomial or Poisson).  In some sense the whole purpose of
> generalized linear models is to take into account that the variance of each
> response is determined by its mean in these distributions.
>
> glmmPQL is a wrapper around the lme function from the nlme package. But
> lme, which provides for modelling correlations, was not intended for this
> purpose.  I personally don't think it would make sense to use a correlation
> function with a binary response.
>
> A preferred approach is to incorporate Gaussian-distributed random effects
> that have the desired auto-correlation pattern.
>
>
> On Tue Nov 25 2014 at 11:58:08 AM Tim Meehan <tmeeha at gmail.com> wrote:
>
>> Hi Sharon,
>>
>> I just looked over a paper by Bolker et al. (2008. GLMMs: a practical
>> guide
>> for ecology and evolution. TREE).  Turns out that while it is possible to
>> model binary data with glmmPQL, it's not really recommended.  Nonetheless,
>> you might look for other options that involve modeling autocorrelation
>> rather than correcting for it after the fact.
>>
>> Best,
>> Tim
>>
>>
>> On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com> wrote:
>>
>> > Hi Sharon,
>> >
>> > Take a look at glmmPQL in the MASS package.  This function allows you to
>> > model a binary response, with random effects, and temporally and
>> spatially
>> > correlated errors.  If you model the correlations, there is less of a
>> need
>> > for adjusting standard errors.
>> >
>> > Best,
>> > Tim
>> >
>> >
>> > On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com>
>> > wrote:
>> >
>> >> When computing resource selection functions for animal telemetry data
>> with
>> >> a binary response variable, where the 1s represent animal location
>> data,
>> >> which are spatially and temporally correlated, and the 0s represent
>> random
>> >> locations, which are not correlated, it is recommended to calculate
>> >> robust,
>> >> or empirical, standard errors instead of using the model-based standard
>> >> errors to account for this differing correlation structure.  As far as
>> I
>> >> can tell, none of the glmm packages in R calculate these robust SEs.
>> Does
>> >> anyone know of a way to use glmms that calculate these?  Thanks.
>> >>
>> >> Sharon
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Tue Nov 25 20:29:48 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 25 Nov 2014 19:29:48 +0000
Subject: [R-sig-ME] Robust SEs in GLMMs
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
	<CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com>
	<CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com>
	<CAMTWOzovOHF=3hgG+MvcRQaw=tNjY8WiNpKBC+6qP1eTMM8vGg@mail.gmail.com>
Message-ID: <CAO7JsnRQEfZ8B6KBD4Ey7-Pf_yn2KxYe6BVpPAqY-AneXv2v8g@mail.gmail.com>

Ben is better able to respond on this than I am.  For GLMMs it is possible
to use a random effect that has one component per observation.  This is
where the spatial or temporal correlation would be incorporated.

On Tue Nov 25 2014 at 1:12:45 PM Tim Meehan <tmeeha at gmail.com> wrote:

> Thanks for clarifying the problem with correlation functions and binary
> responses, Doug.  Regarding the random effects approach, how would one set
> that up?  Would you divide the data into spatial or temporal blocks, and
> use the blocks in the random statement, for example?
>
> On Tue, Nov 25, 2014 at 11:16 AM, Douglas Bates <bates at stat.wisc.edu>
> wrote:
>
>> You have to be careful when modeling auto-correlation in a binary
>> response.  When using a Gaussian distribution it is possible to model the
>> variance and correlation separately from the mean.  No so for a Bernoulli
>> distribution (or binomial or Poisson).  In some sense the whole purpose of
>> generalized linear models is to take into account that the variance of each
>> response is determined by its mean in these distributions.
>>
>> glmmPQL is a wrapper around the lme function from the nlme package. But
>> lme, which provides for modelling correlations, was not intended for this
>> purpose.  I personally don't think it would make sense to use a correlation
>> function with a binary response.
>>
>> A preferred approach is to incorporate Gaussian-distributed random
>> effects that have the desired auto-correlation pattern.
>>
>>
>> On Tue Nov 25 2014 at 11:58:08 AM Tim Meehan <tmeeha at gmail.com> wrote:
>>
>>> Hi Sharon,
>>>
>>> I just looked over a paper by Bolker et al. (2008. GLMMs: a practical
>>> guide
>>> for ecology and evolution. TREE).  Turns out that while it is possible to
>>> model binary data with glmmPQL, it's not really recommended.
>>> Nonetheless,
>>> you might look for other options that involve modeling autocorrelation
>>> rather than correcting for it after the fact.
>>>
>>> Best,
>>> Tim
>>>
>>>
>>> On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com> wrote:
>>>
>>> > Hi Sharon,
>>> >
>>> > Take a look at glmmPQL in the MASS package.  This function allows you
>>> to
>>> > model a binary response, with random effects, and temporally and
>>> spatially
>>> > correlated errors.  If you model the correlations, there is less of a
>>> need
>>> > for adjusting standard errors.
>>> >
>>> > Best,
>>> > Tim
>>> >
>>> >
>>> > On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com>
>>> > wrote:
>>> >
>>> >> When computing resource selection functions for animal telemetry data
>>> with
>>> >> a binary response variable, where the 1s represent animal location
>>> data,
>>> >> which are spatially and temporally correlated, and the 0s represent
>>> random
>>> >> locations, which are not correlated, it is recommended to calculate
>>> >> robust,
>>> >> or empirical, standard errors instead of using the model-based
>>> standard
>>> >> errors to account for this differing correlation structure.  As far
>>> as I
>>> >> can tell, none of the glmm packages in R calculate these robust SEs.
>>> Does
>>> >> anyone know of a way to use glmms that calculate these?  Thanks.
>>> >>
>>> >> Sharon
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> _______________________________________________
>>> >> R-sig-mixed-models at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Nov 25 23:10:11 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 25 Nov 2014 17:10:11 -0500
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CAMTWOzovOHF=3hgG+MvcRQaw=tNjY8WiNpKBC+6qP1eTMM8vGg@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
	<CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com>
	<CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com>
	<CAMTWOzovOHF=3hgG+MvcRQaw=tNjY8WiNpKBC+6qP1eTMM8vGg@mail.gmail.com>
Message-ID: <CABghstT=xsU1AeoDKY-gbi06YZOJvUMF16SjDs7PdaeoiFxwfA@mail.gmail.com>

I hate to sound contrary, but ... I actually think that implementing
the robust standard errors would be the best way to go here.  I don't
have time to work on it myself right now, but someone reasonably
experienced in R should be able to look at the `sandwich` package and
figure out how to write "bread" and "meat" methods for `merMod`
objects ...

On Tue, Nov 25, 2014 at 2:11 PM, Tim Meehan <tmeeha at gmail.com> wrote:
> Thanks for clarifying the problem with correlation functions and binary
> responses, Doug.  Regarding the random effects approach, how would one set
> that up?  Would you divide the data into spatial or temporal blocks, and
> use the blocks in the random statement, for example?
>
> On Tue, Nov 25, 2014 at 11:16 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>
>> You have to be careful when modeling auto-correlation in a binary
>> response.  When using a Gaussian distribution it is possible to model the
>> variance and correlation separately from the mean.  No so for a Bernoulli
>> distribution (or binomial or Poisson).  In some sense the whole purpose of
>> generalized linear models is to take into account that the variance of each
>> response is determined by its mean in these distributions.
>>
>> glmmPQL is a wrapper around the lme function from the nlme package. But
>> lme, which provides for modelling correlations, was not intended for this
>> purpose.  I personally don't think it would make sense to use a correlation
>> function with a binary response.
>>
>> A preferred approach is to incorporate Gaussian-distributed random effects
>> that have the desired auto-correlation pattern.
>>
>>
>> On Tue Nov 25 2014 at 11:58:08 AM Tim Meehan <tmeeha at gmail.com> wrote:
>>
>>> Hi Sharon,
>>>
>>> I just looked over a paper by Bolker et al. (2008. GLMMs: a practical
>>> guide
>>> for ecology and evolution. TREE).  Turns out that while it is possible to
>>> model binary data with glmmPQL, it's not really recommended.  Nonetheless,
>>> you might look for other options that involve modeling autocorrelation
>>> rather than correcting for it after the fact.
>>>
>>> Best,
>>> Tim
>>>
>>>
>>> On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com> wrote:
>>>
>>> > Hi Sharon,
>>> >
>>> > Take a look at glmmPQL in the MASS package.  This function allows you to
>>> > model a binary response, with random effects, and temporally and
>>> spatially
>>> > correlated errors.  If you model the correlations, there is less of a
>>> need
>>> > for adjusting standard errors.
>>> >
>>> > Best,
>>> > Tim
>>> >
>>> >
>>> > On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com>
>>> > wrote:
>>> >
>>> >> When computing resource selection functions for animal telemetry data
>>> with
>>> >> a binary response variable, where the 1s represent animal location
>>> data,
>>> >> which are spatially and temporally correlated, and the 0s represent
>>> random
>>> >> locations, which are not correlated, it is recommended to calculate
>>> >> robust,
>>> >> or empirical, standard errors instead of using the model-based standard
>>> >> errors to account for this differing correlation structure.  As far as
>>> I
>>> >> can tell, none of the glmm packages in R calculate these robust SEs.
>>> Does
>>> >> anyone know of a way to use glmms that calculate these?  Thanks.
>>> >>
>>> >> Sharon
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> _______________________________________________
>>> >> R-sig-mixed-models at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From tmeeha at gmail.com  Tue Nov 25 23:52:33 2014
From: tmeeha at gmail.com (Tim Meehan)
Date: Tue, 25 Nov 2014 15:52:33 -0700
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CABghstT=xsU1AeoDKY-gbi06YZOJvUMF16SjDs7PdaeoiFxwfA@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
	<CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com>
	<CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com>
	<CAMTWOzovOHF=3hgG+MvcRQaw=tNjY8WiNpKBC+6qP1eTMM8vGg@mail.gmail.com>
	<CABghstT=xsU1AeoDKY-gbi06YZOJvUMF16SjDs7PdaeoiFxwfA@mail.gmail.com>
Message-ID: <CAMTWOzpmegZBM7hnv17id88M-Homb4wa1+i75y80GcCBzUTgnQ@mail.gmail.com>

No contrariness taken.  You know this stuff better than most, and we really
appreciate the time you take answering peoples questions.

On Tue, Nov 25, 2014 at 3:10 PM, Ben Bolker <bbolker at gmail.com> wrote:

> I hate to sound contrary, but ... I actually think that implementing
> the robust standard errors would be the best way to go here.  I don't
> have time to work on it myself right now, but someone reasonably
> experienced in R should be able to look at the `sandwich` package and
> figure out how to write "bread" and "meat" methods for `merMod`
> objects ...
>
> On Tue, Nov 25, 2014 at 2:11 PM, Tim Meehan <tmeeha at gmail.com> wrote:
> > Thanks for clarifying the problem with correlation functions and binary
> > responses, Doug.  Regarding the random effects approach, how would one
> set
> > that up?  Would you divide the data into spatial or temporal blocks, and
> > use the blocks in the random statement, for example?
> >
> > On Tue, Nov 25, 2014 at 11:16 AM, Douglas Bates <bates at stat.wisc.edu>
> wrote:
> >
> >> You have to be careful when modeling auto-correlation in a binary
> >> response.  When using a Gaussian distribution it is possible to model
> the
> >> variance and correlation separately from the mean.  No so for a
> Bernoulli
> >> distribution (or binomial or Poisson).  In some sense the whole purpose
> of
> >> generalized linear models is to take into account that the variance of
> each
> >> response is determined by its mean in these distributions.
> >>
> >> glmmPQL is a wrapper around the lme function from the nlme package. But
> >> lme, which provides for modelling correlations, was not intended for
> this
> >> purpose.  I personally don't think it would make sense to use a
> correlation
> >> function with a binary response.
> >>
> >> A preferred approach is to incorporate Gaussian-distributed random
> effects
> >> that have the desired auto-correlation pattern.
> >>
> >>
> >> On Tue Nov 25 2014 at 11:58:08 AM Tim Meehan <tmeeha at gmail.com> wrote:
> >>
> >>> Hi Sharon,
> >>>
> >>> I just looked over a paper by Bolker et al. (2008. GLMMs: a practical
> >>> guide
> >>> for ecology and evolution. TREE).  Turns out that while it is possible
> to
> >>> model binary data with glmmPQL, it's not really recommended.
> Nonetheless,
> >>> you might look for other options that involve modeling autocorrelation
> >>> rather than correcting for it after the fact.
> >>>
> >>> Best,
> >>> Tim
> >>>
> >>>
> >>> On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com> wrote:
> >>>
> >>> > Hi Sharon,
> >>> >
> >>> > Take a look at glmmPQL in the MASS package.  This function allows
> you to
> >>> > model a binary response, with random effects, and temporally and
> >>> spatially
> >>> > correlated errors.  If you model the correlations, there is less of a
> >>> need
> >>> > for adjusting standard errors.
> >>> >
> >>> > Best,
> >>> > Tim
> >>> >
> >>> >
> >>> > On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com>
> >>> > wrote:
> >>> >
> >>> >> When computing resource selection functions for animal telemetry
> data
> >>> with
> >>> >> a binary response variable, where the 1s represent animal location
> >>> data,
> >>> >> which are spatially and temporally correlated, and the 0s represent
> >>> random
> >>> >> locations, which are not correlated, it is recommended to calculate
> >>> >> robust,
> >>> >> or empirical, standard errors instead of using the model-based
> standard
> >>> >> errors to account for this differing correlation structure.  As far
> as
> >>> I
> >>> >> can tell, none of the glmm packages in R calculate these robust SEs.
> >>> Does
> >>> >> anyone know of a way to use glmms that calculate these?  Thanks.
> >>> >>
> >>> >> Sharon
> >>> >>
> >>> >>         [[alternative HTML version deleted]]
> >>> >>
> >>> >> _______________________________________________
> >>> >> R-sig-mixed-models at r-project.org mailing list
> >>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>> >>
> >>> >
> >>> >
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Wed Nov 26 00:08:05 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 26 Nov 2014 10:08:05 +1100
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CABghstT=xsU1AeoDKY-gbi06YZOJvUMF16SjDs7PdaeoiFxwfA@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
	<CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com>
	<CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com>
	<CAMTWOzovOHF=3hgG+MvcRQaw=tNjY8WiNpKBC+6qP1eTMM8vGg@mail.gmail.com>
	<CABghstT=xsU1AeoDKY-gbi06YZOJvUMF16SjDs7PdaeoiFxwfA@mail.gmail.com>
Message-ID: <CAF5_5cxKDJFCTa8w+Dxv7Bbq+n7-rDaOYrGYGdsx6RFv9ua65Q@mail.gmail.com>

It is not too hard to set up a cluster bootstrap (i.e. clusters are
sampled) for clustered data, although I'm not certain what happens with
spatial data. It then takes a bit of time to run.

I've used it where I had additional possible random effects and was
concerned about fitting models with that many random effects. Nicely,
results for models with 5 random effects fitted with nlme gave the same
results for the fixed effects as the 3 random effect models with nlme with
the clustered bootstrap.

On 26 November 2014 at 09:10, Ben Bolker <bbolker at gmail.com> wrote:

> I hate to sound contrary, but ... I actually think that implementing
> the robust standard errors would be the best way to go here.  I don't
> have time to work on it myself right now, but someone reasonably
> experienced in R should be able to look at the `sandwich` package and
> figure out how to write "bread" and "meat" methods for `merMod`
> objects ...
>
> On Tue, Nov 25, 2014 at 2:11 PM, Tim Meehan <tmeeha at gmail.com> wrote:
> > Thanks for clarifying the problem with correlation functions and binary
> > responses, Doug.  Regarding the random effects approach, how would one
> set
> > that up?  Would you divide the data into spatial or temporal blocks, and
> > use the blocks in the random statement, for example?
> >
> > On Tue, Nov 25, 2014 at 11:16 AM, Douglas Bates <bates at stat.wisc.edu>
> wrote:
> >
> >> You have to be careful when modeling auto-correlation in a binary
> >> response.  When using a Gaussian distribution it is possible to model
> the
> >> variance and correlation separately from the mean.  No so for a
> Bernoulli
> >> distribution (or binomial or Poisson).  In some sense the whole purpose
> of
> >> generalized linear models is to take into account that the variance of
> each
> >> response is determined by its mean in these distributions.
> >>
> >> glmmPQL is a wrapper around the lme function from the nlme package. But
> >> lme, which provides for modelling correlations, was not intended for
> this
> >> purpose.  I personally don't think it would make sense to use a
> correlation
> >> function with a binary response.
> >>
> >> A preferred approach is to incorporate Gaussian-distributed random
> effects
> >> that have the desired auto-correlation pattern.
> >>
> >>
> >> On Tue Nov 25 2014 at 11:58:08 AM Tim Meehan <tmeeha at gmail.com> wrote:
> >>
> >>> Hi Sharon,
> >>>
> >>> I just looked over a paper by Bolker et al. (2008. GLMMs: a practical
> >>> guide
> >>> for ecology and evolution. TREE).  Turns out that while it is possible
> to
> >>> model binary data with glmmPQL, it's not really recommended.
> Nonetheless,
> >>> you might look for other options that involve modeling autocorrelation
> >>> rather than correcting for it after the fact.
> >>>
> >>> Best,
> >>> Tim
> >>>
> >>>
> >>> On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com> wrote:
> >>>
> >>> > Hi Sharon,
> >>> >
> >>> > Take a look at glmmPQL in the MASS package.  This function allows
> you to
> >>> > model a binary response, with random effects, and temporally and
> >>> spatially
> >>> > correlated errors.  If you model the correlations, there is less of a
> >>> need
> >>> > for adjusting standard errors.
> >>> >
> >>> > Best,
> >>> > Tim
> >>> >
> >>> >
> >>> > On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com>
> >>> > wrote:
> >>> >
> >>> >> When computing resource selection functions for animal telemetry
> data
> >>> with
> >>> >> a binary response variable, where the 1s represent animal location
> >>> data,
> >>> >> which are spatially and temporally correlated, and the 0s represent
> >>> random
> >>> >> locations, which are not correlated, it is recommended to calculate
> >>> >> robust,
> >>> >> or empirical, standard errors instead of using the model-based
> standard
> >>> >> errors to account for this differing correlation structure.  As far
> as
> >>> I
> >>> >> can tell, none of the glmm packages in R calculate these robust SEs.
> >>> Does
> >>> >> anyone know of a way to use glmms that calculate these?  Thanks.
> >>> >>
> >>> >> Sharon
> >>> >>
> >>> >>         [[alternative HTML version deleted]]
> >>> >>
> >>> >> _______________________________________________
> >>> >> R-sig-mixed-models at r-project.org mailing list
> >>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>> >>
> >>> >
> >>> >
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From rafael.wueest at gmail.com  Wed Nov 26 11:17:54 2014
From: rafael.wueest at gmail.com (=?UTF-8?B?UmFmYWVsIFfDvGVzdA==?=)
Date: Wed, 26 Nov 2014 11:17:54 +0100
Subject: [R-sig-ME] predict GAMM
Message-ID: <5475A8D2.8010609@gmail.com>

Dear ME experts

I'm trying to use GAMMs in order to allow for a correlation structure in a GAM. (A simplified version of) My model looks 
as follows:

m1 <- gamm(y ~ s(p1) + s(p2), correlation = corSymm(form = ~ 1 | p3), data = data.me)

I have two related questions:

1) How do I get the fitted values of this model? I suspect I have to use predict(m1$lme) or fitted(m1$lme)...

2) Is it possible to predict with new data? predict(m1$gam) allows this via a newdata argument, but I suspect the 
correlation structure wouldn't be included then...

Many thanks for any hints,
Rafael

-- 
Rafael W?est
rafael.wueest at gmail.com
http://www.rowueest.net


From David.Duffy at qimr.edu.au  Thu Nov 27 02:10:16 2014
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 27 Nov 2014 11:10:16 +1000
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CAF5_5cxKDJFCTa8w+Dxv7Bbq+n7-rDaOYrGYGdsx6RFv9ua65Q@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com><CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com><CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com><CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com><CAMTWOzovOHF=3hgG+MvcRQaw=tNjY8WiNpKBC+6qP1eTMM8vGg@mail.gmail.com><CABghstT=xsU1AeoDKY-gbi06YZOJvUMF16SjDs7PdaeoiFxwfA@mail.gmail.com>
	<CAF5_5cxKDJFCTa8w+Dxv7Bbq+n7-rDaOYrGYGdsx6RFv9ua65Q@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1411260936130.16593@orpheus.qimr.edu.au>

On Wed, 26 Nov 2014, Ken Beath wrote:

> It is not too hard to set up a cluster bootstrap (i.e. clusters are
> sampled) for clustered data, although I'm not certain what happens with
> spatial data. It then takes a bit of time to run.

delete-d jackknife and other subsampling approaches are good for more 
complex correlation structures.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From chris at trickysolutions.com.au  Thu Nov 27 03:18:18 2014
From: chris at trickysolutions.com.au (Chris Howden)
Date: Thu, 27 Nov 2014 13:18:18 +1100
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
Message-ID: <b40e3e77f96ed475de9bd41afaf1e294@mail.gmail.com>

Hi Sharon,

I faced the same problems a few years ago and tried using one of R's GAM
packages to calculate robust SE's. At the time we couldn?t get it to work
and I believe it was because we had too much data, so R ran into memory
problems.

Some other references you might like to have a look at are below. I
haven?t looked at them in detail myself yet, but as I've got a big data
set I intend to do this type of analysis on one day I've got a bit of "To
Read" list going

Pang (2010) Modeling Heterogeneity and Serial Correlation in Binary
Timeseries Crosssectional data. A Bayesian multilevel model with ARp
errors

Jay Ver Hoef's package glmmLDTS .  I think it deals with all your issues
(binomial, random effects, temporal autocorrelation...but not GAMM). It
may only run on < R.3.0):
https://sites.google.com/site/jayverhoef/
*Ver Hoef, J.M.*, London, J.M., and Boveng, P.L.  2010.  Fast computing of
some generalized linear mixed pseudo-models with temporal autocorrelation.
*Computational Statistics **25*(1)*: *39 - 55*. * DOI:
10.1007/s00180-009-0160-1
London, J.M., *Ver Hoef, J.M.*, Jeffries, S.J., Lance, M.M., and Boveng,
P.L. 2012. Haul-out behavior of harbor seals (Phoca vitulina) in Hood
Canal, Washington.  *PLoS ONE **7*(6):e38180.
doi:10.1371/journal.pone.0038180



Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Data Analysis, Modelling and Training
Evidence Based Strategy/Policy Development, IP Commercialisation and
Innovation
(mobile) +61 (0) 410 689 945
(skype) chris.howden
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Sharon
Poessel
Sent: Monday, 24 November 2014 8:05 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Robust SEs in GLMMs

When computing resource selection functions for animal telemetry data with
a binary response variable, where the 1s represent animal location data,
which are spatially and temporally correlated, and the 0s represent random
locations, which are not correlated, it is recommended to calculate
robust, or empirical, standard errors instead of using the model-based
standard errors to account for this differing correlation structure.  As
far as I can tell, none of the glmm packages in R calculate these robust
SEs.  Does anyone know of a way to use glmms that calculate these?
Thanks.

Sharon

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From stefan.vandongen at uantwerpen.be  Thu Nov 27 11:45:09 2014
From: stefan.vandongen at uantwerpen.be (Van Dongen Stefan)
Date: Thu, 27 Nov 2014 10:45:09 +0000
Subject: [R-sig-ME] interpretation variance-covariance estimates with
 gaussian and censored exponential
Message-ID: <B4D4B84E4C26984690619D21577874EAA6240C16@xmail33.ad.ua.ac.be>

Hi All,

I am currently running a multivariate animal model which has 3 normally distributed responses and one time-to-event (longevity) response. For the fixed effects part, the estimated slopes for associations with longevity reflects changes or ratio's in hazards (i.e., positive estimate = shorter longevity), but how should I interpret the covariances/correlations in the variance covariance matrices (genetic and environmental)? Correlations with hazards or survival-times?

many thanks

Stefan

-------------------------------------------------------------------------------------------------------------------------
Prof. Dr. Stefan Van Dongen
Evolutionary Ecology - Department of Biology - University of Antwerp (http://www.ua.ac.be/eveco)
StatUA Statistics Center, University of Antwerp (http://www.ua.ac.be/statua)
Groenenborgerlaan 171 - B-2020 Antwerp - Belgium

room V324b, building V, campus Groenenborger
Tel: + 32 3 265 33 36
Fax: + 32 3 265 34 74
http://www.ua.ac.be/stefan.vandongen
--------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Nov 27 13:04:42 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 27 Nov 2014 12:04:42 +0000
Subject: [R-sig-ME] interpretation variance-covariance estimates with
 gaussian and censored exponential
In-Reply-To: <B4D4B84E4C26984690619D21577874EAA6240C16@xmail33.ad.ua.ac.be>
References: <B4D4B84E4C26984690619D21577874EAA6240C16@xmail33.ad.ua.ac.be>
Message-ID: <20141127120442.20791bfma54oejq0@www.staffmail.ed.ac.uk>

Hi,

The linear model is applied on the same link scale for both fixed and  
random effects so it will be hazards also.

Cheers,

Jarrod

Quoting Van Dongen Stefan <stefan.vandongen at uantwerpen.be> on Thu, 27  
Nov 2014 10:45:09 +0000:

> Hi All,
>
> I am currently running a multivariate animal model which has 3  
> normally distributed responses and one time-to-event (longevity)  
> response. For the fixed effects part, the estimated slopes for  
> associations with longevity reflects changes or ratio's in hazards  
> (i.e., positive estimate = shorter longevity), but how should I  
> interpret the covariances/correlations in the variance covariance  
> matrices (genetic and environmental)? Correlations with hazards or  
> survival-times?
>
> many thanks
>
> Stefan
>
> -------------------------------------------------------------------------------------------------------------------------
> Prof. Dr. Stefan Van Dongen
> Evolutionary Ecology - Department of Biology - University of Antwerp  
> (http://www.ua.ac.be/eveco)
> StatUA Statistics Center, University of Antwerp (http://www.ua.ac.be/statua)
> Groenenborgerlaan 171 - B-2020 Antwerp - Belgium
>
> room V324b, building V, campus Groenenborger
> Tel: + 32 3 265 33 36
> Fax: + 32 3 265 34 74
> http://www.ua.ac.be/stefan.vandongen
> --------------------------------------------------------------------------------------------------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From marie.devaine at gmail.com  Thu Nov 27 16:03:04 2014
From: marie.devaine at gmail.com (marie devaine)
Date: Thu, 27 Nov 2014 16:03:04 +0100
Subject: [R-sig-ME] lmertest F-test anova(fullm) and anova(fullm,reducedm)
Message-ID: <CAMHk4vyK+Vvy3cMoT+G27Vz9wGHQTx3T27bDC1f52qKqMwy01g@mail.gmail.com>

Dear mixed-model list,

I am sorry if my questions sound trivial: I am all new to R and mixed model.

My data set is the following : I try to model scores  of primates from
different species in different conditions of a task. Each individual
repeats each condition a certain number of time ( most of the time 4 times
but with some exceptions).
I have only few individuals by specie (from 4 to 7), 3 conditions and 7
species

As dependent variables, I am mostly interested in the condition and the
Specie, but I want to correct for learning effect at the individual level
(parametric effect on repetition -'Order').

I wrote the following model (letting Subject be a random effect and 'Order'
a random slope) :
fullm = lmer(Scores ~ Condition*Specie+(1+Order|Subject))
1) Is it a sensible way to model my data?

Then, I want to test for the interaction between Species and condition. I
found two ways to do so with the lmerTest :
*computing the p-value of the F-test corresponding to Specie:Condition as
given by anova(fullm).
*constructing the reduced model without the interaction
reducedm= lmer(Scores ~ Condition+Specie+(1+Order|Subject))
and performing the Likelihood ratio test : anova(reducedm,fullm).

2) What is the conceptual difference between the two methods?

3) The numerical results are different in my case (pvalues around .05,
below in the reduced model manner, above in the F-test manner), why is it
the case? Is one better than the other one?

4) This point is not directly related to my title, but on the same data and
still on the lmerTest pasckage : the Species for now are categorical, but I
could instead take a numerical value such as the encephalization quotient
for each specie. In this case how could I evaluate the significance of the
parametric effect? lsmeans seems to care only about categorical factors.

It is very likely that I miss here very simple points, and would be very
thankful if you could help me with it.

Thank you in advance,

Marie Devaine

	[[alternative HTML version deleted]]


From hughes.dupond at gmx.de  Thu Nov 27 18:52:14 2014
From: hughes.dupond at gmx.de (Lionel)
Date: Thu, 27 Nov 2014 18:52:14 +0100
Subject: [R-sig-ME] lmertest F-test anova(fullm) and anova(fullm,
	reducedm)
In-Reply-To: <CAMHk4vyK+Vvy3cMoT+G27Vz9wGHQTx3T27bDC1f52qKqMwy01g@mail.gmail.com>
References: <CAMHk4vyK+Vvy3cMoT+G27Vz9wGHQTx3T27bDC1f52qKqMwy01g@mail.gmail.com>
Message-ID: <547764CE.2080805@gmx.de>

Dear Marie Devaine,

1) The way you account for the order effects is not the way I would go, 
I can see various options:
  - The effect of Order on Scores is not changing the relationships 
between your fixed effects part and the Scores, and each individuals is 
"learning" the task differently I would then use a nested random part: 
Scores~Condition*Specie+(1|Subject/Order), you would then get an 
estimation of much variation there is in the Scores between subject and 
also how much variation there is within subject between Order levels.
- Order is changing the relationship between your fixed effect part and 
the Score, ie the Condition effect on the Scores is different whether a 
primate is in its first trials or in its fourth one. You would then need 
random slopes, and then one way to go would be: 
Scores~Condition*Species+(1+Condition|Subject/Order), you would then get 
the same estimate as in the previous options plus how much the Condition 
slope vary between the Subject and within the Subject, between the 
Order. Seeing your number of levels I guess that the estimation will be 
rather tricky ...
You can see the wiki for more infomation on this: 
http://glmm.wikidot.com/faq#modelspec
I guess that your are misinterpreting the random slope part, you can see 
it as an interaction term between one fixed effect term and one random 
term, for example if you were to measure the weights of your primates 
and made the hypothesis that the weights affect the scores but that this 
effect (direction+strength ie slope) might vary between your subject 
then you would have a random slope of weight depending on the subject 
(weight|subject).

2-3) The first method identify if the interaction term explain a big 
enough portion of the total sum of square, it is a measure of how 
important is this term at explaining the variation in your data. The 
second method compare the likelihood (ie the probability to find this 
dataset with this particular set of parameter) between the model with 
and the model without the interaction term, if the removal of the 
interaction term leads to a big decline in the likelihood of the model 
then the p-value should score significant and you should keep the full 
model, in the other case the parcimony approach would lead you to choose 
the reduced model. So the difference come from the fact that the two 
methods are computing a different thing. As to which one is better this 
is a tricky question, the way I would go would be to compute confidence 
intervals around the main effect plus interaction term using bootMer for 
example and then interpreting them. You may have a look at ?pvalues for 
more options/suggestions.

As I am not familiar with lmerTest package I will not comment on your 
last question.

Hoping that I clarified some points,
Lionel


On 27/11/2014 16:03, marie devaine wrote:
> Dear mixed-model list,
>
> I am sorry if my questions sound trivial: I am all new to R and mixed model.
>
> My data set is the following : I try to model scores  of primates from
> different species in different conditions of a task. Each individual
> repeats each condition a certain number of time ( most of the time 4 times
> but with some exceptions).
> I have only few individuals by specie (from 4 to 7), 3 conditions and 7
> species
>
> As dependent variables, I am mostly interested in the condition and the
> Specie, but I want to correct for learning effect at the individual level
> (parametric effect on repetition -'Order').
>
> I wrote the following model (letting Subject be a random effect and 'Order'
> a random slope) :
> fullm = lmer(Scores ~ Condition*Specie+(1+Order|Subject))
> 1) Is it a sensible way to model my data?
>
> Then, I want to test for the interaction between Species and condition. I
> found two ways to do so with the lmerTest :
> *computing the p-value of the F-test corresponding to Specie:Condition as
> given by anova(fullm).
> *constructing the reduced model without the interaction
> reducedm= lmer(Scores ~ Condition+Specie+(1+Order|Subject))
> and performing the Likelihood ratio test : anova(reducedm,fullm).
>
> 2) What is the conceptual difference between the two methods?
>
> 3) The numerical results are different in my case (pvalues around .05,
> below in the reduced model manner, above in the F-test manner), why is it
> the case? Is one better than the other one?
>
> 4) This point is not directly related to my title, but on the same data and
> still on the lmerTest pasckage : the Species for now are categorical, but I
> could instead take a numerical value such as the encephalization quotient
> for each specie. In this case how could I evaluate the significance of the
> parametric effect? lsmeans seems to care only about categorical factors.
>
> It is very likely that I miss here very simple points, and would be very
> thankful if you could help me with it.
>
> Thank you in advance,
>
> Marie Devaine
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From marie.devaine at gmail.com  Fri Nov 28 10:51:59 2014
From: marie.devaine at gmail.com (marie devaine)
Date: Fri, 28 Nov 2014 10:51:59 +0100
Subject: [R-sig-ME] lmertest F-test anova(fullm) and anova(fullm,
	reducedm)
In-Reply-To: <547764CE.2080805@gmx.de>
References: <CAMHk4vyK+Vvy3cMoT+G27Vz9wGHQTx3T27bDC1f52qKqMwy01g@mail.gmail.com>
	<547764CE.2080805@gmx.de>
Message-ID: <CAMHk4vwfijK7d9MvwFyy_9HasgAHRoqPw1q0aM_sKrgYa1gE-A@mail.gmail.com>

Dear Lionel,

Thanks a lot for your input.

1) I am still not sure to get how to write things down, and I am sorry that
my description of data and model was not clear enough.
I place me in the first of the two cases that you describe, i.e. the Order
effect is a parametrical effect, Subject specific but independent of
levels. In fact, the Order variable is just a count of the number of time
the task has been performed, irrespectively of which Condition has been
performed. This is not a categorical variable and is just suppose to
capture how well the primate is learning general features about the task
(independent of Condition).
As it is, Scores~Condition*Specie+(1|Subject/Order) gives me an error since
Order values are interpreted as level, but there are as many levels as
observations by subjects.

In fact, in your example, I don't really see the difference between
(weight|subject) and (1|subject) since in both cases, the model evaluate
one coefficient by subject.


2)3) This is very clear, thank you again.

Marie


2014-11-27 18:52 GMT+01:00 Lionel <hughes.dupond at gmx.de>:

> Dear Marie Devaine,
>
> 1) The way you account for the order effects is not the way I would go, I
> can see various options:
>  - The effect of Order on Scores is not changing the relationships between
> your fixed effects part and the Scores, and each individuals is "learning"
> the task differently I would then use a nested random part:
> Scores~Condition*Specie+(1|Subject/Order), you would then get an
> estimation of much variation there is in the Scores between subject and
> also how much variation there is within subject between Order levels.
> - Order is changing the relationship between your fixed effect part and
> the Score, ie the Condition effect on the Scores is different whether a
> primate is in its first trials or in its fourth one. You would then need
> random slopes, and then one way to go would be: Scores~Condition*Species+(1+Condition|Subject/Order),
> you would then get the same estimate as in the previous options plus how
> much the Condition slope vary between the Subject and within the Subject,
> between the Order. Seeing your number of levels I guess that the estimation
> will be rather tricky ...
> You can see the wiki for more infomation on this:
> http://glmm.wikidot.com/faq#modelspec
> I guess that your are misinterpreting the random slope part, you can see
> it as an interaction term between one fixed effect term and one random
> term, for example if you were to measure the weights of your primates and
> made the hypothesis that the weights affect the scores but that this effect
> (direction+strength ie slope) might vary between your subject then you
> would have a random slope of weight depending on the subject
> (weight|subject).
>
> 2-3) The first method identify if the interaction term explain a big
> enough portion of the total sum of square, it is a measure of how important
> is this term at explaining the variation in your data. The second method
> compare the likelihood (ie the probability to find this dataset with this
> particular set of parameter) between the model with and the model without
> the interaction term, if the removal of the interaction term leads to a big
> decline in the likelihood of the model then the p-value should score
> significant and you should keep the full model, in the other case the
> parcimony approach would lead you to choose the reduced model. So the
> difference come from the fact that the two methods are computing a
> different thing. As to which one is better this is a tricky question, the
> way I would go would be to compute confidence intervals around the main
> effect plus interaction term using bootMer for example and then
> interpreting them. You may have a look at ?pvalues for more
> options/suggestions.
>
> As I am not familiar with lmerTest package I will not comment on your last
> question.
>
> Hoping that I clarified some points,
> Lionel
>
>
>
> On 27/11/2014 16:03, marie devaine wrote:
>
>> Dear mixed-model list,
>>
>> I am sorry if my questions sound trivial: I am all new to R and mixed
>> model.
>>
>> My data set is the following : I try to model scores  of primates from
>> different species in different conditions of a task. Each individual
>> repeats each condition a certain number of time ( most of the time 4 times
>> but with some exceptions).
>> I have only few individuals by specie (from 4 to 7), 3 conditions and 7
>> species
>>
>> As dependent variables, I am mostly interested in the condition and the
>> Specie, but I want to correct for learning effect at the individual level
>> (parametric effect on repetition -'Order').
>>
>> I wrote the following model (letting Subject be a random effect and
>> 'Order'
>> a random slope) :
>> fullm = lmer(Scores ~ Condition*Specie+(1+Order|Subject))
>> 1) Is it a sensible way to model my data?
>>
>> Then, I want to test for the interaction between Species and condition. I
>> found two ways to do so with the lmerTest :
>> *computing the p-value of the F-test corresponding to Specie:Condition as
>> given by anova(fullm).
>> *constructing the reduced model without the interaction
>> reducedm= lmer(Scores ~ Condition+Specie+(1+Order|Subject))
>> and performing the Likelihood ratio test : anova(reducedm,fullm).
>>
>> 2) What is the conceptual difference between the two methods?
>>
>> 3) The numerical results are different in my case (pvalues around .05,
>> below in the reduced model manner, above in the F-test manner), why is it
>> the case? Is one better than the other one?
>>
>> 4) This point is not directly related to my title, but on the same data
>> and
>> still on the lmerTest pasckage : the Species for now are categorical, but
>> I
>> could instead take a numerical value such as the encephalization quotient
>> for each specie. In this case how could I evaluate the significance of the
>> parametric effect? lsmeans seems to care only about categorical factors.
>>
>> It is very likely that I miss here very simple points, and would be very
>> thankful if you could help me with it.
>>
>> Thank you in advance,
>>
>> Marie Devaine
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Marie Devaine
PhD Student at the Brain and Spine Institute (France)
Personal Page (
https://sites.google.com/site/motivationbrainbehavior/the-team/marie-devaine
)
MBB (https://sites.google.com/site/motivationbrainbehavior)
ICM (http://icm-institute.org/menu/actualites)
[+33(0)1 57 27 47 19]

	[[alternative HTML version deleted]]


From ajaeggi at anth.ucsb.edu  Fri Nov 28 15:19:40 2014
From: ajaeggi at anth.ucsb.edu (Adrian Jaeggi)
Date: Fri, 28 Nov 2014 06:19:40 -0800
Subject: [R-sig-ME] Estimating/fixing covariances in multi-response model
 with several zero-inflated variables?
Message-ID: <20141128061940.862446am4xou2bgc@services.lsit.ucsb.edu>

Dear list,

I am trying to model exchanges of different commodities among  
individuals. There are five commodities (meat, produce, labor,  
childcare and sick care), each of which can be given and received.  
Each row is a unique combination of individuals A and B but each  
individual appears multiple times hence A and B are random effects.  
Three of the variables are heavily zero-inflated count variables, two  
of them are binary.

E.g. meat given from A to B

summary(data$MeatAToB)
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
    0.00    0.00    0.00   12.23    0.00 1534.00

table(data$MeatAToB == 0)
FALSE  TRUE
   264  2360

ppois(0, mean(data$MeatAToB))
[1] 4.866032e-06

So far my approach has been to model giving one commodity (e.g.  
MeatAToB) as a function of receiving any of the other commodities  
using zipoisson, with the zi intercept capturing all the excess 0's,  
the variance of the zero-inflation intercept fixed using the fix=2  
argument and no covariances estimated between zi and count units, i.e.  
idh(trait):units (cf. MCMCglmm Course Notes 5.2.):

prior1<- list(R=list(V=diag(2),nu=0.002,fix=2),  
G=list(G1=list(V=1,nu=0.002), G2=list(V=1,nu=0.002)))

model1<- MCMCglmm(MeatAToB~trait-1 + at.level(trait,1):MeatBToA +  
at.level(trait,1):ProdBToA + at.level(trait,1):LaborBToA +  
at.level(trait,1):ChhildCareBToA + at.level(trait,1):SickCareBToA,  
rcov=~idh(trait):units,  
random=~idh(at.level(trait,1)):A+idh(at.level(trait,1)):B,  
family='zipoisson', prior=prior1, data=data)

For the binary variables I've used family="categorical", slice=TRUE  
and priors as suggested in the Course Notes. All of these models show  
reasonable mixing and biologically meaningful results and can be  
extended to include random slopes etc. So far so good.

However, as it is I have to fit five seperate models for giving the  
five different commodities. It is unreasonable to think that giving  
one commodity is unrelated to giving another. This got me thinking of  
multi-response models in which I can estimate the covariance between  
the different response variables.

My idea was this:

prior2<- list(R=list(V=diag(8)*0.002,nu=9,fix=c(2,4,6)),  
G=list(G1=list(V=1,nu=0.002), G2=list(V=1,nu=0.002)

model2<- MCMCglmm(cbind(MeatAToB, ProdAToB, LaborAToB, ChildCareAToB,  
SickCareAToB)~trait-1 + at.level(trait,c(1,3,5,7,8)):MeatBToA +  
at.level(trait,c(1,3,5,7,8)):ProdBToA +  
at.level(trait,c(1,3,5,7,8)):LaborBToA +  
at.level(trait,c(1,3,5,7,8)):ChildCareBToA +  
at.level(trait,c(1,3,5,7,8)):SickCareBToA, rcov=us(trait):units,  
random=~idh(at.level(trait,c(1,3,5,7,8))):A +  
idh(at.level(trait,c(1,3,5,7,8))):B,  
family=c('zipoisson','zipoisson','zipoisson','categorical','categorical'),  
prior=prior2, data=data)

Trait then contains 8 columns, in the following order: 1  
MeatAToB_CountPart, 2 MeatAToB_ZIPart, 3 ProdAToB_CountPart, 4  
ProdAToB_ZIPart, 5 LaborAToB_CountPart, 6 LaborAToB_ZIPart, 7  
ChildCareAToB, 8 SickCareAToB. I want all the fixed effects to only  
interact with the count / binary parts but not with the ZI part, for  
which I'm only estimating intercepts (the excess 0's); hence the  
at.level(trait,c(1,3,5,7,8)) interactions

In the 8x8 variance covariance matrix of this model, I would like to  
estimate covariances between the count and binary columns only and fix  
the ZI parts (similar to the simple model above). My naive approach  
based on the simple model was to use rcov=us(trait):units, which  
estimates the full variance covariance matrix including the ZI parts,  
but try to somehow fix the latter, i.e. columns 2,4,6 using the fix  
argument in the prior.

However, the above code gives the following ProdAToBmessages:
Error in MCMCglmm(cbind(MeatAToB, HortCalsAToBPerDay6round,  :
   fix term in priorG/priorR must be at least one less than the dimension of V
In addition: Warning messages:
1: In if (prior$fix != 0) { :
   the condition has length > 1 and only the first element will be used
2: In prior$fix:nrow(prior$V) :
   numerical expression has 3 elements: only the first used
3: In prior$fix:nrow(prior$V) :
   numerical expression has 3 elements: only the first used
4: In if (sum(CM != 0) > nrow(prior$V) & prior$fix > 1) { :
   the condition has length > 1 and only the first element will be used
5: In if (prior$fix != 1) { :
   the condition has length > 1 and only the first element will be used
6: In if (det(prior$V) < 1e-08 & prior$fix != 0) { :
   the condition has length > 1 and only the first element will be used
7: In if ((prior$fix > y | prior$fix < x) & prior$fix != 0) { :
   the condition has length > 1 and only the first element will be used
8: In split > nfl :
   longer object length is not a multiple of shorter object length

So it seems like the fix argument cannot be used to do what I'm trying  
to do. Running the model without fixing the ZI parts will estimate the  
full 8x8 VCV matrix, which I don't think makes sense (or does it??)  
because the any given data point cannot contribute information to both  
the ZI and the count process (cf. Course Notes).

My question to the list is therefore if anyone can tell me how to best  
specify the variance - covariance structure in this multi-response  
model with several zero-inflated variables? Should I go for the full  
8x8 matrix using us(trait):units or should (and can?) the ZI parts  
somehow be fixed?

Many thanks in advance,
Adrian




-- 
Adrian Jaeggi, PhD
Postdoctoral Researcher and Lecturer
Department of Anthropology
University of California Santa Barbara
Santa Barbara, CA 93106-3210
Phone: 805-455-8587
www.adrianjaeggi.com


From sharpoes at gmail.com  Wed Nov 26 04:41:52 2014
From: sharpoes at gmail.com (Sharon Poessel)
Date: Tue, 25 Nov 2014 20:41:52 -0700
Subject: [R-sig-ME] Robust SEs in GLMMs
In-Reply-To: <CAF5_5cxKDJFCTa8w+Dxv7Bbq+n7-rDaOYrGYGdsx6RFv9ua65Q@mail.gmail.com>
References: <CA+RzyNATDcNNSDTZ5dHzYMuRH9n9ew5Tw9ieT1wGDoN4dMO2kw@mail.gmail.com>
	<CAMTWOzqFEacUPNOJYCKiE3JQk6X+D3xxbxtnJG9gLyYyi+nS=Q@mail.gmail.com>
	<CAMTWOzrKNuuRAsc96BuXCPDooSkssJZRbfZbLnNvahZy8NvC-A@mail.gmail.com>
	<CAO7JsnTBwre68VTj=20q=Fus0dSe2h52jSrR7r2CEb0dfsxKmw@mail.gmail.com>
	<CAMTWOzovOHF=3hgG+MvcRQaw=tNjY8WiNpKBC+6qP1eTMM8vGg@mail.gmail.com>
	<CABghstT=xsU1AeoDKY-gbi06YZOJvUMF16SjDs7PdaeoiFxwfA@mail.gmail.com>
	<CAF5_5cxKDJFCTa8w+Dxv7Bbq+n7-rDaOYrGYGdsx6RFv9ua65Q@mail.gmail.com>
Message-ID: <CA+RzyNAzCYCLyibPYYF-Y6WrSmXGPRvA665cgDoxbBpcsg_hyQ@mail.gmail.com>

Thank you to all of you who have responded.  I will consider your
suggestions.  The information is very much appreciated!

Sharon

On Tue, Nov 25, 2014 at 4:08 PM, Ken Beath <ken.beath at mq.edu.au> wrote:

> It is not too hard to set up a cluster bootstrap (i.e. clusters are
> sampled) for clustered data, although I'm not certain what happens with
> spatial data. It then takes a bit of time to run.
>
> I've used it where I had additional possible random effects and was
> concerned about fitting models with that many random effects. Nicely,
> results for models with 5 random effects fitted with nlme gave the same
> results for the fixed effects as the 3 random effect models with nlme with
> the clustered bootstrap.
>
> On 26 November 2014 at 09:10, Ben Bolker <bbolker at gmail.com> wrote:
>
>> I hate to sound contrary, but ... I actually think that implementing
>> the robust standard errors would be the best way to go here.  I don't
>> have time to work on it myself right now, but someone reasonably
>> experienced in R should be able to look at the `sandwich` package and
>> figure out how to write "bread" and "meat" methods for `merMod`
>> objects ...
>>
>> On Tue, Nov 25, 2014 at 2:11 PM, Tim Meehan <tmeeha at gmail.com> wrote:
>> > Thanks for clarifying the problem with correlation functions and binary
>> > responses, Doug.  Regarding the random effects approach, how would one
>> set
>> > that up?  Would you divide the data into spatial or temporal blocks, and
>> > use the blocks in the random statement, for example?
>> >
>> > On Tue, Nov 25, 2014 at 11:16 AM, Douglas Bates <bates at stat.wisc.edu>
>> wrote:
>> >
>> >> You have to be careful when modeling auto-correlation in a binary
>> >> response.  When using a Gaussian distribution it is possible to model
>> the
>> >> variance and correlation separately from the mean.  No so for a
>> Bernoulli
>> >> distribution (or binomial or Poisson).  In some sense the whole
>> purpose of
>> >> generalized linear models is to take into account that the variance of
>> each
>> >> response is determined by its mean in these distributions.
>> >>
>> >> glmmPQL is a wrapper around the lme function from the nlme package. But
>> >> lme, which provides for modelling correlations, was not intended for
>> this
>> >> purpose.  I personally don't think it would make sense to use a
>> correlation
>> >> function with a binary response.
>> >>
>> >> A preferred approach is to incorporate Gaussian-distributed random
>> effects
>> >> that have the desired auto-correlation pattern.
>> >>
>> >>
>> >> On Tue Nov 25 2014 at 11:58:08 AM Tim Meehan <tmeeha at gmail.com> wrote:
>> >>
>> >>> Hi Sharon,
>> >>>
>> >>> I just looked over a paper by Bolker et al. (2008. GLMMs: a practical
>> >>> guide
>> >>> for ecology and evolution. TREE).  Turns out that while it is
>> possible to
>> >>> model binary data with glmmPQL, it's not really recommended.
>> Nonetheless,
>> >>> you might look for other options that involve modeling autocorrelation
>> >>> rather than correcting for it after the fact.
>> >>>
>> >>> Best,
>> >>> Tim
>> >>>
>> >>>
>> >>> On Tue, Nov 25, 2014 at 10:19 AM, Tim Meehan <tmeeha at gmail.com>
>> wrote:
>> >>>
>> >>> > Hi Sharon,
>> >>> >
>> >>> > Take a look at glmmPQL in the MASS package.  This function allows
>> you to
>> >>> > model a binary response, with random effects, and temporally and
>> >>> spatially
>> >>> > correlated errors.  If you model the correlations, there is less of
>> a
>> >>> need
>> >>> > for adjusting standard errors.
>> >>> >
>> >>> > Best,
>> >>> > Tim
>> >>> >
>> >>> >
>> >>> > On Sun, Nov 23, 2014 at 2:04 PM, Sharon Poessel <sharpoes at gmail.com
>> >
>> >>> > wrote:
>> >>> >
>> >>> >> When computing resource selection functions for animal telemetry
>> data
>> >>> with
>> >>> >> a binary response variable, where the 1s represent animal location
>> >>> data,
>> >>> >> which are spatially and temporally correlated, and the 0s represent
>> >>> random
>> >>> >> locations, which are not correlated, it is recommended to calculate
>> >>> >> robust,
>> >>> >> or empirical, standard errors instead of using the model-based
>> standard
>> >>> >> errors to account for this differing correlation structure.  As
>> far as
>> >>> I
>> >>> >> can tell, none of the glmm packages in R calculate these robust
>> SEs.
>> >>> Does
>> >>> >> anyone know of a way to use glmms that calculate these?  Thanks.
>> >>> >>
>> >>> >> Sharon
>> >>> >>
>> >>> >>         [[alternative HTML version deleted]]
>> >>> >>
>> >>> >> _______________________________________________
>> >>> >> R-sig-mixed-models at r-project.org mailing list
>> >>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>> >>
>> >>> >
>> >>> >
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:11}}


From hughes.dupond at gmx.de  Fri Nov 28 18:29:51 2014
From: hughes.dupond at gmx.de (Lionel)
Date: Fri, 28 Nov 2014 18:29:51 +0100
Subject: [R-sig-ME] lmertest F-test anova(fullm) and anova(fullm,
	reducedm)
In-Reply-To: <CAMHk4vwfijK7d9MvwFyy_9HasgAHRoqPw1q0aM_sKrgYa1gE-A@mail.gmail.com>
References: <CAMHk4vyK+Vvy3cMoT+G27Vz9wGHQTx3T27bDC1f52qKqMwy01g@mail.gmail.com>	<547764CE.2080805@gmx.de>
	<CAMHk4vwfijK7d9MvwFyy_9HasgAHRoqPw1q0aM_sKrgYa1gE-A@mail.gmail.com>
Message-ID: <5478B10F.1000302@gmx.de>

Dear Marie,

Ok, it makes things easier, I would then go for:
Scores~Condition*Specie+Order+(1+Order|Subject), you would then get an 
estimation of how variable is the intercept between the Subject, plus 
how variable the slope Scores vs Order between the Subject is, in this 
context having one value per subject and order will not be a problem. I 
guess the discussion between this model and the one you wrote is similar 
to the one about having an interaction term without having a main effect 
in the first place, I am not sure if it is also an issue in mixed models 
but just for safety I would then include Order as a main effect.

In my example the model with (1|subject) will estimate the variation of 
the intercept, you could actually get the estimated variation for each 
subject to the average but this is usually not so much of interest. So 
if you do ranef(model) you would get one column, one 'coefficient' per 
subject (actually these are the deviations from the overall coefficient, 
they are not coefficient per se as the model did not estimate them 
individually).
However if your model is (weight|subject), this is equivalent to 
(1+weight|subject), then you would get again the variation of the 
intercept PLUS the variation of the slope response vs weight, if you do 
ranef(model) you would then get two columns so two 'coefficient' per 
subject.

Cordialement,
Lionel

On 28/11/2014 10:51, marie devaine wrote:
> Dear Lionel,
>
> Thanks a lot for your input.
>
> 1) I am still not sure to get how to write things down, and I am sorry 
> that my description of data and model was not clear enough.
> I place me in the first of the two cases that you describe, i.e. the 
> Order effect is a parametrical effect, Subject specific but 
> independent of levels. In fact, the Order variable is just a count of 
> the number of time the task has been performed, irrespectively of 
> which Condition has been performed. This is not a categorical variable 
> and is just suppose to capture how well the primate is learning 
> general features about the task (independent of Condition).
> As it is, Scores~Condition*Specie+(1|Subject/Order) gives me an error 
> since Order values are interpreted as level, but there are as many 
> levels as observations by subjects.
>
> In fact, in your example, I don't really see the difference between 
> (weight|subject) and (1|subject) since in both cases, the model 
> evaluate one coefficient by subject.
>
>
> 2)3) This is very clear, thank you again.
>
> Marie
>
>
> 2014-11-27 18:52 GMT+01:00 Lionel <hughes.dupond at gmx.de 
> <mailto:hughes.dupond at gmx.de>>:
>
>     Dear Marie Devaine,
>
>     1) The way you account for the order effects is not the way I
>     would go, I can see various options:
>      - The effect of Order on Scores is not changing the relationships
>     between your fixed effects part and the Scores, and each
>     individuals is "learning" the task differently I would then use a
>     nested random part: Scores~Condition*Specie+(1|Subject/Order), you
>     would then get an estimation of much variation there is in the
>     Scores between subject and also how much variation there is within
>     subject between Order levels.
>     - Order is changing the relationship between your fixed effect
>     part and the Score, ie the Condition effect on the Scores is
>     different whether a primate is in its first trials or in its
>     fourth one. You would then need random slopes, and then one way to
>     go would be: Scores~Condition*Species+(1+Condition|Subject/Order),
>     you would then get the same estimate as in the previous options
>     plus how much the Condition slope vary between the Subject and
>     within the Subject, between the Order. Seeing your number of
>     levels I guess that the estimation will be rather tricky ...
>     You can see the wiki for more infomation on this:
>     http://glmm.wikidot.com/faq#modelspec
>     I guess that your are misinterpreting the random slope part, you
>     can see it as an interaction term between one fixed effect term
>     and one random term, for example if you were to measure the
>     weights of your primates and made the hypothesis that the weights
>     affect the scores but that this effect (direction+strength ie
>     slope) might vary between your subject then you would have a
>     random slope of weight depending on the subject (weight|subject).
>
>     2-3) The first method identify if the interaction term explain a
>     big enough portion of the total sum of square, it is a measure of
>     how important is this term at explaining the variation in your
>     data. The second method compare the likelihood (ie the probability
>     to find this dataset with this particular set of parameter)
>     between the model with and the model without the interaction term,
>     if the removal of the interaction term leads to a big decline in
>     the likelihood of the model then the p-value should score
>     significant and you should keep the full model, in the other case
>     the parcimony approach would lead you to choose the reduced model.
>     So the difference come from the fact that the two methods are
>     computing a different thing. As to which one is better this is a
>     tricky question, the way I would go would be to compute confidence
>     intervals around the main effect plus interaction term using
>     bootMer for example and then interpreting them. You may have a
>     look at ?pvalues for more options/suggestions.
>
>     As I am not familiar with lmerTest package I will not comment on
>     your last question.
>
>     Hoping that I clarified some points,
>     Lionel
>
>
>
>     On 27/11/2014 16:03, marie devaine wrote:
>
>         Dear mixed-model list,
>
>         I am sorry if my questions sound trivial: I am all new to R
>         and mixed model.
>
>         My data set is the following : I try to model scores of
>         primates from
>         different species in different conditions of a task. Each
>         individual
>         repeats each condition a certain number of time ( most of the
>         time 4 times
>         but with some exceptions).
>         I have only few individuals by specie (from 4 to 7), 3
>         conditions and 7
>         species
>
>         As dependent variables, I am mostly interested in the
>         condition and the
>         Specie, but I want to correct for learning effect at the
>         individual level
>         (parametric effect on repetition -'Order').
>
>         I wrote the following model (letting Subject be a random
>         effect and 'Order'
>         a random slope) :
>         fullm = lmer(Scores ~ Condition*Specie+(1+Order|Subject))
>         1) Is it a sensible way to model my data?
>
>         Then, I want to test for the interaction between Species and
>         condition. I
>         found two ways to do so with the lmerTest :
>         *computing the p-value of the F-test corresponding to
>         Specie:Condition as
>         given by anova(fullm).
>         *constructing the reduced model without the interaction
>         reducedm= lmer(Scores ~ Condition+Specie+(1+Order|Subject))
>         and performing the Likelihood ratio test : anova(reducedm,fullm).
>
>         2) What is the conceptual difference between the two methods?
>
>         3) The numerical results are different in my case (pvalues
>         around .05,
>         below in the reduced model manner, above in the F-test
>         manner), why is it
>         the case? Is one better than the other one?
>
>         4) This point is not directly related to my title, but on the
>         same data and
>         still on the lmerTest pasckage : the Species for now are
>         categorical, but I
>         could instead take a numerical value such as the
>         encephalization quotient
>         for each specie. In this case how could I evaluate the
>         significance of the
>         parametric effect? lsmeans seems to care only about
>         categorical factors.
>
>         It is very likely that I miss here very simple points, and
>         would be very
>         thankful if you could help me with it.
>
>         Thank you in advance,
>
>         Marie Devaine
>
>                 [[alternative HTML version deleted]]
>
>         _______________________________________________
>         R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> -- 
> Marie Devaine
> PhD Student at the Brain and Spine Institute (France)
> Personal Page 
> (https://sites.google.com/site/motivationbrainbehavior/the-team/marie-devaine)
> MBB (https://sites.google.com/site/motivationbrainbehavior)
> ICM (http://icm-institute.org/menu/actualites)
> [+33(0)1 57 27 47 19]
>


	[[alternative HTML version deleted]]


From manabu.sakamoto at gmail.com  Sun Nov 30 09:13:55 2014
From: manabu.sakamoto at gmail.com (Manabu Sakamoto)
Date: Sun, 30 Nov 2014 08:13:55 +0000
Subject: [R-sig-ME] error when looping many MCMCglmm runs
Message-ID: <CAErHMT29UnKyybHYaMUi7Tyx7XT+TUaoZgQAEBb=s=Api00Ggg@mail.gmail.com>

Dear list,

I'm not quite sure if this is the right list for this, but I only get this
issue when I am running MCMCglmm, so I post it here.

I am wondering if anyone has come across this issue: I am experiencing some
errors when running MCMCglmm in nested loops.

I have three datasets and a set of model formulations for each. So I loop
through the datasets (i) with nested loops (j) for each model formulation,
and I store the results in a list for each dataset. I then save the
workspace, and move onto the second dataset (i+1).

The first time I noticed something strange was after the workspace is saved
at the end of the ith iteration, and I read in the data for the i+1th
dataset. Normally, I'd read in the names of the files using list.files()
and do some regular expressions to select the right filename to read in,
but in this case, the vector of filenames somehow became empty. If I do
this manually, then there's nothing wrong. I thought maybe R was jumping
ahead of itself so at the end of the ith loop I set it so that R sleeps for
1 second, which for some reason resolved this issue.

Today, I noticed something different. I get an error with MCMCglmm stating
that the mixed model was singular. I never get this when I run the same
model on its own or even if inside a loop, if within a single dataset. It
happened when I looped through different datasets. Is there some known
issue about too many loops, and maybe something to do with memory use that
corrupts MCMCglmm runs?

Would setting R to sleep or removing R objects more frequently help resolve
this issue?
I can try these but every loop takes hours so debugging errors that only
occur over multiple nested loops is painstakingly time consuming.

Any suggestions or thoughts would be most appreciated.

Many thanks,
Manabu

-- 
Manabu Sakamoto, PhD
manabu.sakamoto at gmail.com

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sun Nov 30 10:29:32 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 30 Nov 2014 09:29:32 +0000
Subject: [R-sig-ME] error when looping many MCMCglmm runs
In-Reply-To: <CAErHMT29UnKyybHYaMUi7Tyx7XT+TUaoZgQAEBb=s=Api00Ggg@mail.gmail.com>
References: <CAErHMT29UnKyybHYaMUi7Tyx7XT+TUaoZgQAEBb=s=Api00Ggg@mail.gmail.com>
Message-ID: <20141130092932.151249ookloplaww@www.staffmail.ed.ac.uk>

Hi Manabu,

Can you post your code so we can take a look?

Cheers,

Jarrod

Quoting Manabu Sakamoto <manabu.sakamoto at gmail.com> on Sun, 30 Nov  
2014 08:13:55 +0000:

> Dear list,
>
> I'm not quite sure if this is the right list for this, but I only get this
> issue when I am running MCMCglmm, so I post it here.
>
> I am wondering if anyone has come across this issue: I am experiencing some
> errors when running MCMCglmm in nested loops.
>
> I have three datasets and a set of model formulations for each. So I loop
> through the datasets (i) with nested loops (j) for each model formulation,
> and I store the results in a list for each dataset. I then save the
> workspace, and move onto the second dataset (i+1).
>
> The first time I noticed something strange was after the workspace is saved
> at the end of the ith iteration, and I read in the data for the i+1th
> dataset. Normally, I'd read in the names of the files using list.files()
> and do some regular expressions to select the right filename to read in,
> but in this case, the vector of filenames somehow became empty. If I do
> this manually, then there's nothing wrong. I thought maybe R was jumping
> ahead of itself so at the end of the ith loop I set it so that R sleeps for
> 1 second, which for some reason resolved this issue.
>
> Today, I noticed something different. I get an error with MCMCglmm stating
> that the mixed model was singular. I never get this when I run the same
> model on its own or even if inside a loop, if within a single dataset. It
> happened when I looped through different datasets. Is there some known
> issue about too many loops, and maybe something to do with memory use that
> corrupts MCMCglmm runs?
>
> Would setting R to sleep or removing R objects more frequently help resolve
> this issue?
> I can try these but every loop takes hours so debugging errors that only
> occur over multiple nested loops is painstakingly time consuming.
>
> Any suggestions or thoughts would be most appreciated.
>
> Many thanks,
> Manabu
>
> --
> Manabu Sakamoto, PhD
> manabu.sakamoto at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Thierry.ONKELINX at inbo.be  Mon Dec  1 09:29:28 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 1 Dec 2014 08:29:28 +0000
Subject: [R-sig-ME] Estimating/fixing covariances in multi-response
 model with several zero-inflated variables?
In-Reply-To: <20141128061940.862446am4xou2bgc@services.lsit.ucsb.edu>
References: <20141128061940.862446am4xou2bgc@services.lsit.ucsb.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B581B3@inbomail.inbo.be>

Dear Adrian,

Have a look at the BradleyTerry2 package. Bradley Terry models are designed the handle data where several individuals/teams 'compete' with each other.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens Adrian Jaeggi [ajaeggi at anth.ucsb.edu]
Verzonden: vrijdag 28 november 2014 15:19
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Estimating/fixing covariances in multi-response model with several zero-inflated variables?

Dear list,

I am trying to model exchanges of different commodities among
individuals. There are five commodities (meat, produce, labor,
childcare and sick care), each of which can be given and received.
Each row is a unique combination of individuals A and B but each
individual appears multiple times hence A and B are random effects.
Three of the variables are heavily zero-inflated count variables, two
of them are binary.

E.g. meat given from A to B

summary(data$MeatAToB)
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
    0.00    0.00    0.00   12.23    0.00 1534.00

table(data$MeatAToB == 0)
FALSE  TRUE
   264  2360

ppois(0, mean(data$MeatAToB))
[1] 4.866032e-06

So far my approach has been to model giving one commodity (e.g.
MeatAToB) as a function of receiving any of the other commodities
using zipoisson, with the zi intercept capturing all the excess 0's,
the variance of the zero-inflation intercept fixed using the fix=2
argument and no covariances estimated between zi and count units, i.e.
idh(trait):units (cf. MCMCglmm Course Notes 5.2.):

prior1<- list(R=list(V=diag(2),nu=0.002,fix=2),
G=list(G1=list(V=1,nu=0.002), G2=list(V=1,nu=0.002)))

model1<- MCMCglmm(MeatAToB~trait-1 + at.level(trait,1):MeatBToA +
at.level(trait,1):ProdBToA + at.level(trait,1):LaborBToA +
at.level(trait,1):ChhildCareBToA + at.level(trait,1):SickCareBToA,
rcov=~idh(trait):units,
random=~idh(at.level(trait,1)):A+idh(at.level(trait,1)):B,
family='zipoisson', prior=prior1, data=data)

For the binary variables I've used family="categorical", slice=TRUE
and priors as suggested in the Course Notes. All of these models show
reasonable mixing and biologically meaningful results and can be
extended to include random slopes etc. So far so good.

However, as it is I have to fit five seperate models for giving the
five different commodities. It is unreasonable to think that giving
one commodity is unrelated to giving another. This got me thinking of
multi-response models in which I can estimate the covariance between
the different response variables.

My idea was this:

prior2<- list(R=list(V=diag(8)*0.002,nu=9,fix=c(2,4,6)),
G=list(G1=list(V=1,nu=0.002), G2=list(V=1,nu=0.002)

model2<- MCMCglmm(cbind(MeatAToB, ProdAToB, LaborAToB, ChildCareAToB,
SickCareAToB)~trait-1 + at.level(trait,c(1,3,5,7,8)):MeatBToA +
at.level(trait,c(1,3,5,7,8)):ProdBToA +
at.level(trait,c(1,3,5,7,8)):LaborBToA +
at.level(trait,c(1,3,5,7,8)):ChildCareBToA +
at.level(trait,c(1,3,5,7,8)):SickCareBToA, rcov=us(trait):units,
random=~idh(at.level(trait,c(1,3,5,7,8))):A +
idh(at.level(trait,c(1,3,5,7,8))):B,
family=c('zipoisson','zipoisson','zipoisson','categorical','categorical'),
prior=prior2, data=data)

Trait then contains 8 columns, in the following order: 1
MeatAToB_CountPart, 2 MeatAToB_ZIPart, 3 ProdAToB_CountPart, 4
ProdAToB_ZIPart, 5 LaborAToB_CountPart, 6 LaborAToB_ZIPart, 7
ChildCareAToB, 8 SickCareAToB. I want all the fixed effects to only
interact with the count / binary parts but not with the ZI part, for
which I'm only estimating intercepts (the excess 0's); hence the
at.level(trait,c(1,3,5,7,8)) interactions

In the 8x8 variance covariance matrix of this model, I would like to
estimate covariances between the count and binary columns only and fix
the ZI parts (similar to the simple model above). My naive approach
based on the simple model was to use rcov=us(trait):units, which
estimates the full variance covariance matrix including the ZI parts,
but try to somehow fix the latter, i.e. columns 2,4,6 using the fix
argument in the prior.

However, the above code gives the following ProdAToBmessages:
Error in MCMCglmm(cbind(MeatAToB, HortCalsAToBPerDay6round,  :
   fix term in priorG/priorR must be at least one less than the dimension of V
In addition: Warning messages:
1: In if (prior$fix != 0) { :
   the condition has length > 1 and only the first element will be used
2: In prior$fix:nrow(prior$V) :
   numerical expression has 3 elements: only the first used
3: In prior$fix:nrow(prior$V) :
   numerical expression has 3 elements: only the first used
4: In if (sum(CM != 0) > nrow(prior$V) & prior$fix > 1) { :
   the condition has length > 1 and only the first element will be used
5: In if (prior$fix != 1) { :
   the condition has length > 1 and only the first element will be used
6: In if (det(prior$V) < 1e-08 & prior$fix != 0) { :
   the condition has length > 1 and only the first element will be used
7: In if ((prior$fix > y | prior$fix < x) & prior$fix != 0) { :
   the condition has length > 1 and only the first element will be used
8: In split > nfl :
   longer object length is not a multiple of shorter object length

So it seems like the fix argument cannot be used to do what I'm trying
to do. Running the model without fixing the ZI parts will estimate the
full 8x8 VCV matrix, which I don't think makes sense (or does it??)
because the any given data point cannot contribute information to both
the ZI and the count process (cf. Course Notes).

My question to the list is therefore if anyone can tell me how to best
specify the variance - covariance structure in this multi-response
model with several zero-inflated variables? Should I go for the full
8x8 matrix using us(trait):units or should (and can?) the ZI parts
somehow be fixed?

Many thanks in advance,
Adrian




--
Adrian Jaeggi, PhD
Postdoctoral Researcher and Lecturer
Department of Anthropology
University of California Santa Barbara
Santa Barbara, CA 93106-3210
Phone: 805-455-8587
www.adrianjaeggi.com

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From j.hadfield at ed.ac.uk  Tue Dec  2 23:10:53 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 02 Dec 2014 22:10:53 +0000
Subject: [R-sig-ME] Estimating/fixing covariances in multi-response
 model with several zero-inflated variables?
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3B581B3@inbomail.inbo.be>
References: <20141128061940.862446am4xou2bgc@services.lsit.ucsb.edu>
	<AA818EAD2576BC488B4F623941DA7427F3B581B3@inbomail.inbo.be>
Message-ID: <20141202221053.69985jc6tx8mz4rs@www.staffmail.ed.ac.uk>

Hi Adrian,

The fix argument only takes an integer which fixes the submatrix  
indexed by [fix:n,fix:n]. The latest version also allows the submatrix  
to be constrained to be a correlation matrix, with the correlations  
estimated, if a "cors" variance structure is used (this is currently  
undocumented).

The latter would be most appropriate for your analysis, but for  
multiparamater distributions like the zero-inflated Poisson it is not  
possible to set up the model directly so all the zi parts are in the  
sub-matrix. Its a bit annoying because it should be easy to implement,  
but because of the way I wrote the C-code its actually quite hard.   
Sorry.

Jarrod






Quoting "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> on Mon, 1 Dec  
2014 08:29:28 +0000:

> Dear Adrian,
>
> Have a look at the BradleyTerry2 package. Bradley Terry models are  
> designed the handle data where several individuals/teams 'compete'  
> with each other.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for  
> Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> To call in the statistician after the experiment is done may be no  
> more than asking him to perform a post-mortem examination: he may be  
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does  
> not ensure that a reasonable answer can be extracted from a given  
> body of data. ~ John Tukey
>
> ________________________________________
> Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org]  
> namens Adrian Jaeggi [ajaeggi at anth.ucsb.edu]
> Verzonden: vrijdag 28 november 2014 15:19
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Estimating/fixing covariances in  
> multi-response model with several zero-inflated variables?
>
> Dear list,
>
> I am trying to model exchanges of different commodities among
> individuals. There are five commodities (meat, produce, labor,
> childcare and sick care), each of which can be given and received.
> Each row is a unique combination of individuals A and B but each
> individual appears multiple times hence A and B are random effects.
> Three of the variables are heavily zero-inflated count variables, two
> of them are binary.
>
> E.g. meat given from A to B
>
> summary(data$MeatAToB)
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>     0.00    0.00    0.00   12.23    0.00 1534.00
>
> table(data$MeatAToB == 0)
> FALSE  TRUE
>    264  2360
>
> ppois(0, mean(data$MeatAToB))
> [1] 4.866032e-06
>
> So far my approach has been to model giving one commodity (e.g.
> MeatAToB) as a function of receiving any of the other commodities
> using zipoisson, with the zi intercept capturing all the excess 0's,
> the variance of the zero-inflation intercept fixed using the fix=2
> argument and no covariances estimated between zi and count units, i.e.
> idh(trait):units (cf. MCMCglmm Course Notes 5.2.):
>
> prior1<- list(R=list(V=diag(2),nu=0.002,fix=2),
> G=list(G1=list(V=1,nu=0.002), G2=list(V=1,nu=0.002)))
>
> model1<- MCMCglmm(MeatAToB~trait-1 + at.level(trait,1):MeatBToA +
> at.level(trait,1):ProdBToA + at.level(trait,1):LaborBToA +
> at.level(trait,1):ChhildCareBToA + at.level(trait,1):SickCareBToA,
> rcov=~idh(trait):units,
> random=~idh(at.level(trait,1)):A+idh(at.level(trait,1)):B,
> family='zipoisson', prior=prior1, data=data)
>
> For the binary variables I've used family="categorical", slice=TRUE
> and priors as suggested in the Course Notes. All of these models show
> reasonable mixing and biologically meaningful results and can be
> extended to include random slopes etc. So far so good.
>
> However, as it is I have to fit five seperate models for giving the
> five different commodities. It is unreasonable to think that giving
> one commodity is unrelated to giving another. This got me thinking of
> multi-response models in which I can estimate the covariance between
> the different response variables.
>
> My idea was this:
>
> prior2<- list(R=list(V=diag(8)*0.002,nu=9,fix=c(2,4,6)),
> G=list(G1=list(V=1,nu=0.002), G2=list(V=1,nu=0.002)
>
> model2<- MCMCglmm(cbind(MeatAToB, ProdAToB, LaborAToB, ChildCareAToB,
> SickCareAToB)~trait-1 + at.level(trait,c(1,3,5,7,8)):MeatBToA +
> at.level(trait,c(1,3,5,7,8)):ProdBToA +
> at.level(trait,c(1,3,5,7,8)):LaborBToA +
> at.level(trait,c(1,3,5,7,8)):ChildCareBToA +
> at.level(trait,c(1,3,5,7,8)):SickCareBToA, rcov=us(trait):units,
> random=~idh(at.level(trait,c(1,3,5,7,8))):A +
> idh(at.level(trait,c(1,3,5,7,8))):B,
> family=c('zipoisson','zipoisson','zipoisson','categorical','categorical'),
> prior=prior2, data=data)
>
> Trait then contains 8 columns, in the following order: 1
> MeatAToB_CountPart, 2 MeatAToB_ZIPart, 3 ProdAToB_CountPart, 4
> ProdAToB_ZIPart, 5 LaborAToB_CountPart, 6 LaborAToB_ZIPart, 7
> ChildCareAToB, 8 SickCareAToB. I want all the fixed effects to only
> interact with the count / binary parts but not with the ZI part, for
> which I'm only estimating intercepts (the excess 0's); hence the
> at.level(trait,c(1,3,5,7,8)) interactions
>
> In the 8x8 variance covariance matrix of this model, I would like to
> estimate covariances between the count and binary columns only and fix
> the ZI parts (similar to the simple model above). My naive approach
> based on the simple model was to use rcov=us(trait):units, which
> estimates the full variance covariance matrix including the ZI parts,
> but try to somehow fix the latter, i.e. columns 2,4,6 using the fix
> argument in the prior.
>
> However, the above code gives the following ProdAToBmessages:
> Error in MCMCglmm(cbind(MeatAToB, HortCalsAToBPerDay6round,  :
>    fix term in priorG/priorR must be at least one less than the  
> dimension of V
> In addition: Warning messages:
> 1: In if (prior$fix != 0) { :
>    the condition has length > 1 and only the first element will be used
> 2: In prior$fix:nrow(prior$V) :
>    numerical expression has 3 elements: only the first used
> 3: In prior$fix:nrow(prior$V) :
>    numerical expression has 3 elements: only the first used
> 4: In if (sum(CM != 0) > nrow(prior$V) & prior$fix > 1) { :
>    the condition has length > 1 and only the first element will be used
> 5: In if (prior$fix != 1) { :
>    the condition has length > 1 and only the first element will be used
> 6: In if (det(prior$V) < 1e-08 & prior$fix != 0) { :
>    the condition has length > 1 and only the first element will be used
> 7: In if ((prior$fix > y | prior$fix < x) & prior$fix != 0) { :
>    the condition has length > 1 and only the first element will be used
> 8: In split > nfl :
>    longer object length is not a multiple of shorter object length
>
> So it seems like the fix argument cannot be used to do what I'm trying
> to do. Running the model without fixing the ZI parts will estimate the
> full 8x8 VCV matrix, which I don't think makes sense (or does it??)
> because the any given data point cannot contribute information to both
> the ZI and the count process (cf. Course Notes).
>
> My question to the list is therefore if anyone can tell me how to best
> specify the variance - covariance structure in this multi-response
> model with several zero-inflated variables? Should I go for the full
> 8x8 matrix using us(trait):units or should (and can?) the ZI parts
> somehow be fixed?
>
> Many thanks in advance,
> Adrian
>
>
>
>
> --
> Adrian Jaeggi, PhD
> Postdoctoral Researcher and Lecturer
> Department of Anthropology
> University of California Santa Barbara
> Santa Barbara, CA 93106-3210
> Phone: 805-455-8587
> www.adrianjaeggi.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de  
> schrijver weer en binden het INBO onder geen enkel beding, zolang  
> dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those  
> of the writer and may not be regarded as stating an official  
> position of INBO, as long as the message is not confirmed by a duly  
> signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Wed Dec  3 02:45:59 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 02 Dec 2014 20:45:59 -0500
Subject: [R-sig-ME] lme4 Question
In-Reply-To: <14816_1417565344_sB3093RR031964_CAGg1ksSLddc9Rzy8m_M-ty=m0p8EuwX90PxqsaOu_9uJUpP62A@mail.gmail.com>
References: <14816_1417565344_sB3093RR031964_CAGg1ksSLddc9Rzy8m_M-ty=m0p8EuwX90PxqsaOu_9uJUpP62A@mail.gmail.com>
Message-ID: <547E6B57.8080309@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  [forwarding to r-sig-mixed-models]

On 14-12-02 07:08 PM, Aimee Tallian wrote:
> Hello Ben,
> 
> My name is Aimee Tallian and I am a Ph.D. student at Utah State
> University. I have a question about you package, 'lme4'.
> 
> I have ran a bunch of analyses a while back in version 1.0-6, and
> have since updated to version 1.1-7. I have gone back to the
> initial analyses since I updated the package, and the results have
> changed. Everything is mostly the same except for the standard
> errors and p-values. What was significant is not anymore in several
> cases, even though the code and data are the exact same. See output
> below:
> 
> *Output (lme4_1.0-6) *
> 
> [image: Inline image 1]
> 
> 
> *Output (lme4_1.1-7) Same output in versions 1.1-6 / 1.1-5* [image:
> Inline image 2]
> 
> 
> This statement is the only real change associated with SE that I
> found between the versions that I have been using:
> 
> *From the news for version 1.1-4*: Standard errors of fixed effects
> are now computed from the approximate Hessian by default (see the
> use.hessian argument in vcov.merMod); this gives better (correct)
> answers when the estimates of the random- and fixed-effect
> parameters are correlated (Github #47)
> 
> I dug into the subject and it appears that this is the cause of my
> inflated SE and p-values. I tried: summary(a1fit1,
> use.hessian=FALSE), and as you suggested in the pdf manual, this
> returned my results from before.
> 
> So, this is suggesting that my previous results are incorrect and
> that I should use the estimates from the newer version (which means
> a full start over)? Or is there justification for using my previous
> results and using the hessian = FALSE command? I.e., how do I know
> if my fixed and random effect parameters are correlated?
> 
> I really appreciate any advice you might have on the subject!
> 
> Thanks,
> 
> Aimee
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUfmtXAAoJEOCV5YRblxUHKhQIAImLH9rLUZMJbMa88s5Z3ncd
mtcLdZ+1Nee9GJTuNcUscmOmC9D9kUXA3ofJgpdtq4UFkxIq0oBM3ukpsw/4sIMR
pCSa2GEeX6YpKg/L4o4Cfze9DOUGbAiBpZAGsRRBfxaHFOEUQYQc48NVBFtWmjnX
Fez3CR9H0P49rYmiMmCKw1fSpa3hX7QiaWMn4WtN8SLjiBRgncidH1v8sFdFP5y4
4NM/6ojasg08nV9bnVZMKheVOwebHB6lCZgJQioR3QHmiyGRA9tisHg0og4CUPB7
k446AfrHsDVa5yHklKsPjd79fSvVgH51WU07CSPDDJf6qQc/PwCwGoqs6EONHAM=
=8XFs
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Wed Dec  3 02:55:29 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 02 Dec 2014 20:55:29 -0500
Subject: [R-sig-ME] Fwd: lme4 Question
In-Reply-To: <14816_1417565344_sB3093RR031964_CAGg1ksSLddc9Rzy8m_M-ty=m0p8EuwX90PxqsaOu_9uJUpP62A@mail.gmail.com>
References: <14816_1417565344_sB3093RR031964_CAGg1ksSLddc9Rzy8m_M-ty=m0p8EuwX90PxqsaOu_9uJUpP62A@mail.gmail.com>
Message-ID: <547E6D91.70905@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

[cc'ing to r-sig-mixed-models.  Sorry about previous accidental e-mail.]

- -------- Forwarded Message --------
Subject: lme4 Question
Resent-Date: Tue, 02 Dec 2014 19:09:03 -0500
Date: Tue, 2 Dec 2014 17:08:54 -0700
To: bolker at mcmaster.ca

[snip]

I have ran a bunch of analyses a while back in version 1.0-6, and have
since updated to version 1.1-7. I have gone back to the initial analyses
since I updated the package, and the results have changed. Everything is
mostly the same except for the standard errors and p-values. What was
significant is not anymore in several cases, even though the code and data
are the exact same. See output below:

*Output (lme4_1.0-6) *

[image: Inline image 1]

*Output (lme4_1.1-7) Same output in versions 1.1-6 / 1.1-5*
[image: Inline image 2]

BMB> Summary from image:

> standard errors of first two estimates change a fair amount; 
> Z-statistics shrink from {2.6,-2.1,2.9,-1.2,0.9 } to 
> {1.3,-1.8,2.5,-1.2,0.88}

[for future reference, it works better on the mailing list if you cut
and paste text]


This statement is the only real change associated with SE that I found
between the versions that I have been using:

*From the news for version 1.1-4*: Standard errors of fixed effects
are now computed from the approximate Hessian by default (see the
use.hessian argument in vcov.merMod); this gives better (correct)
answers when the estimates of the random- and fixed-effect parameters
are correlated (Github #47)

I dug into the subject and it appears that this is the cause of my
inflated SE and p-values. I tried: summary(a1fit1, use.hessian=FALSE),
and as you suggested in the pdf manual, this returned my results from
before.

So, this is suggesting that my previous results are incorrect and that
I should use the estimates from the newer version (which means a full
start over)? Or is there justification for using my previous results
and using the hessian = FALSE command? I.e., how do I know if my fixed
and random effect parameters are correlated?

BMB> Sadly, I believe that the new results are correct.  I can't
see any particular justification for using the old results.  However,
I would certainly recommend that you try computing confidence intervals
by profile likelihood -- that will be more accurate than the Wald
confidence intervals given by summary() in any case (and independent
of the decision about how to compute the variance-covariance matrix
of the parameters).

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUfm2RAAoJEOCV5YRblxUHhHcH/iCSlX1LJ2TdQkMjO2z8ztBX
1Yo3fnza4O3X+11PSWtLGb6aXCwvjC1HImbXgNmWnKli3lCyNYn4HTzvTwqss7U2
M807hc2RJy+0LADITHi5KQaGkMcma8AZFzx02L2JkAc20BURI39G/NODKX+kTsHk
AR5lunwt9JY9TwbSv3qVO/HccK7NgdTdjHV3Yqyp0NZQR8XhxOE7yoKAsJRTGvMg
yChjXClidKW3Bno/Hc6mIhCamWB05y9P2llS3VHcooIXxS5f9SM6K/Sj5Ilw6JF6
Fps+aCjMdqCbVi8/Y+DmOB30Mp+WQrirnoykxiUVJkzgVAr8PSUyeg5oIJOTs38=
=5JoD
-----END PGP SIGNATURE-----


From highstat at highstat.com  Thu Dec  4 15:48:14 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 04 Dec 2014 14:48:14 +0000
Subject: [R-sig-ME] 8 statistics course; January - June 2015
Message-ID: <5480742E.8030509@highstat.com>

Apologies for cross-posting

We would like to announce the following 8 statistics course covering 
topics such as R, data exploration (using lattice and ggplot2), multiple 
linear regression, GLM, GAM, mixed modelling, GLMM, GAMM, Bayesian 
analysis and MCMC. For further information, registration, prices, course 
flyers, etc., see:

http://www.highstat.com/statscourse.htm



List of open courses in January - June 2015:

Data exploration, regression, GLM & GAM with introduction to R.
2 - 6 February 2015. Coimbra, Portugal

Introduction to Linear mixed effects models,  GLMM and MCMC with R
9-13 February 2015. Lisbon

Data exploration, regression, GLM & GAM with introduction to R.
23-27 March 2015. University of Southampton, Southampton, UK

Introduction to Bayesian statistics and MCMC
8-10 April 2015. University of Southampton, Southampton, UK

Introduction to Linear Mixed Effects Models and GLMM with R
3-17 April 2015. University of Southampton, Southampton, UK

Data exploration, regression, GLM & GAM with introduction to R.
4-8 May 2015. University of Palermo, Italy

Introduction to GAM and GAMM with R
1-15 May 2015. University of Genua, Italy

Data exploration, regression, GLM & GAM with introduction to R
6-10 July 2015. Leamington, Ontario, Canada





-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From wafic.el.assi at gmail.com  Wed Dec  3 23:10:02 2014
From: wafic.el.assi at gmail.com (Wafic El - Assi)
Date: Wed, 3 Dec 2014 17:10:02 -0500
Subject: [R-sig-ME] Setting parameters to 0
Message-ID: <CALzdbRskxVgpmo7yyEG-PaUJ6zkcY=DCpFLcy0gy=JDLSWjoqA@mail.gmail.com>

Hello,

Is there a function like constpar (mixed logit package) that allows me to
set a parameter result to 0?

For example, if i have the following linear mixed effects model:

 trips ~ (var1) + (var2) + (1+var3|season)

And my var3 is "Snow Fall". I would like to set the parameter equal to 0
during the summer season. Is that possible?

Thank you for your time.

Regards,

Wafic

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Dec  4 17:12:32 2014
From: bbolker at gmail.com (lme4 maintainer)
Date: Thu, 04 Dec 2014 11:12:32 -0500
Subject: [R-sig-ME] [Lme4-authors] Mixed effect models with user-defined
 links in R
In-Reply-To: <9246fdcdb0564938855c6eb382ef3187@DM2PR0101MB0928.prod.exchangelabs.com>
References: <9246fdcdb0564938855c6eb382ef3187@DM2PR0101MB0928.prod.exchangelabs.com>
Message-ID: <548087F0.8060708@lists.r-forge.r-project.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-04 10:56 AM, Jennifer Malpass wrote:
> Hi lme4 authors,
> 
> I am trying to update some glm code to a format that would allow
> for mixed effects modeling in R. However, I need to use a custom
> link function for part of my data analysis, which I believe isn't 
> currently supported in lme4 (e.g. 
> http://comments.gmane.org/gmane.comp.lang.r.lme4.devel/1480).
> 
> Mine doesn't seem to be a unique problem and I was wondering if
> any of you know of alternative packages that would allow me to run
> mixed effects modeling with a custom link function.
> 
> Any guidance would be greatly appreciated! Thanks, Jenn
> 

  [cc'ing to r-sig-mixed-models, which is more appropriate for general
questions]

  This mailing list post is quite old (2008), it's not accurate any
more.  glmer should handle custom link functions perfectly well.  See
for example http://www.rpubs.com/bbolker/logregexp

 cheers
  Ben Bolker
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUgIfwAAoJEOCV5YRblxUHqocH/2s+EHjDrixLzcaLu+oVvfl7
252MHshg2tKBK0fbkBZCmxyfeUhJ9TESsH/cva8qMJ7miCvZyxI3B4XzODx0LEA5
iwOyGYfG0RIhthbGH1w51u6hO2HBKnjt+MJLtQIFV4xCDynJsy3RZO/740C8srFI
aktF8a49KLG1w84YDIt8ZJLPdJZBvZ9XE9rbPQ1YtN1AdICEZNmkUXdNJgQuiubs
XBN47vUueB5z6MpKb8mcRQkfCVjID/Tn3HyM/mefq/lPncZJM9n8w/WhvdovDN9N
HTnVngaDWk8pV1KOttYRyLksWYDMVBzDNqvlMjhbnuTQcGJeG5X+blltr88TZE4=
=rwxj
-----END PGP SIGNATURE-----


From kristina.noreikiene at helsinki.fi  Fri Dec  5 12:18:14 2014
From: kristina.noreikiene at helsinki.fi (Kristina Noreikiene)
Date: Fri, 5 Dec 2014 13:18:14 +0200
Subject: [R-sig-ME] trait specific fixed effects for bivariate model in
	MCMCglmm
Message-ID: <CACF2Qc7D31VvY_v2FmA7n7b-u4NfF9j6m1pyWmhb_V-AS_muqg@mail.gmail.com>

Dear All,
I would like to run a bivariate model in MCMCglmm where the two traits have
their own specific fixed effects but am not sure about how to code this and
would appreciate some advice.  Is there any corresponding function for
allowing trait specific fixed effects in MCMCglmm?
Kind regards,
Kristina Noreikiene

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Fri Dec  5 12:23:23 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 05 Dec 2014 11:23:23 +0000
Subject: [R-sig-ME] trait specific fixed effects for bivariate model in
 MCMCglmm
In-Reply-To: <CACF2Qc7D31VvY_v2FmA7n7b-u4NfF9j6m1pyWmhb_V-AS_muqg@mail.gmail.com>
References: <CACF2Qc7D31VvY_v2FmA7n7b-u4NfF9j6m1pyWmhb_V-AS_muqg@mail.gmail.com>
Message-ID: <20141205112323.36045ditjjd8h30g@www.staffmail.ed.ac.uk>

Hi,

Just interact you terms with trait. For example

cbind(x,y)~ trait-1+trait:age

allows trait specific intercepts, and trait specific regressions on age.

Jarrod



Quoting Kristina Noreikiene <kristina.noreikiene at helsinki.fi> on Fri,  
5 Dec 2014 13:18:14 +0200:

> Dear All,
> I would like to run a bivariate model in MCMCglmm where the two traits have
> their own specific fixed effects but am not sure about how to code this and
> would appreciate some advice.  Is there any corresponding function for
> allowing trait specific fixed effects in MCMCglmm?
> Kind regards,
> Kristina Noreikiene
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Thierry.ONKELINX at inbo.be  Fri Dec  5 15:31:10 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 5 Dec 2014 14:31:10 +0000
Subject: [R-sig-ME] Setting parameters to 0
In-Reply-To: <CALzdbRskxVgpmo7yyEG-PaUJ6zkcY=DCpFLcy0gy=JDLSWjoqA@mail.gmail.com>
References: <CALzdbRskxVgpmo7yyEG-PaUJ6zkcY=DCpFLcy0gy=JDLSWjoqA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3C756C1@inbomail.inbo.be>

Dear Wafic,

I think that the easiest way to get the same effect is to simple set var3 to 0 during summer.

Your model is trips = beta_0 + beta_1 * var1 + beta_2 * var2 + b_i0 + b_i3 * var3

You want b_i3 = 0 during summer. So during summer b_i3 * var3 = 0 * var3 = 0. If var3 = 0, then b_i3 * var3 = 0. I expect the estimate of b_i3 to be very close to zero.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Wafic El - Assi
Verzonden: woensdag 3 december 2014 23:10
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Setting parameters to 0

Hello,

Is there a function like constpar (mixed logit package) that allows me to set a parameter result to 0?

For example, if i have the following linear mixed effects model:

 trips ~ (var1) + (var2) + (1+var3|season)

And my var3 is "Snow Fall". I would like to set the parameter equal to 0 during the summer season. Is that possible?

Thank you for your time.

Regards,

Wafic

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From kriste.noreikiene at gmail.com  Fri Dec  5 12:17:16 2014
From: kriste.noreikiene at gmail.com (Kristina Noreikiene)
Date: Fri, 5 Dec 2014 13:17:16 +0200
Subject: [R-sig-ME] trait specific fixed effects for bivariate model in
	MCMCglmm
Message-ID: <CACF2Qc63su_J=-nR9uTc+zWFL0_KUr37JvLe_FZMv06QX59y3g@mail.gmail.com>

Dear All,
I would like to run a bivariate model in MCMCglmm where the two traits have
their own specific fixed effects but am not sure about how to code this and
would appreciate some advice.  Is there any corresponding function for
allowing trait specific fixed effects in MCMCglmm?
Kind regards,
Kristina

	[[alternative HTML version deleted]]


From andrew.mcaleavey at gmail.com  Sat Dec  6 16:12:28 2014
From: andrew.mcaleavey at gmail.com (Andrew McAleavey)
Date: Sat, 6 Dec 2014 10:12:28 -0500
Subject: [R-sig-ME] interpretation of categorical crossed effect in lme4
Message-ID: <CANgPp9nKWF_pfNE=giBF3hiNipcqys-+PNB_Tajxv=1_UhJH8Q@mail.gmail.com>

Hi,

I have a lmer model of the form:
y ~ x1 + x2 + (1 | group) + (0 +x2 | group) ;
where x1 is continuous, x2 is dichotomous and dummy-coded, and group has
about 250 levels (each with minimum 3 observations in each x2 level, but
the average is more like 7 per x2 level, and over 15 observations per group
on average, ignoring x2). My understanding is that this model separately
estimates variance components for each level of x2 across groups, and does
not model any correlation between them.

This was a better fit to the data than  the structure:
y ~ x1 + x2 + (x2 | group) ;
and I came to this model based on a series of threads on this list. Note
that under this model the correlation between random effects for x2 and the
intercept was .67, and as far as I can tell convergence was not a problem
in either model as it might be in some cases with smaller group numbers.

However, I would like to interpret, at least tentatively, the random
effects, and especially the relationship between them. My central
substantive question is whether groups vary with respect to differential
effectiveness with x2 levels (e.g., some groups were effective with x2=0
but not x2=1 while others were highly effective with both). Extracting the
random effects and plotting them suggests that even though the model does
not explicitly include correlations, the two random effects are correlated
at about r = .56.

My questions are these:
a) is a significant correlation like r = .56 common under conditions of my
model in which these effects were not modeled?
b) to interpret the random effects, I think I may need to treat them as
additive and correlate u1 with (u1 + u2), which leads to an even higher
correlation (r > .8). Am I correct in this? My thinking is that u2, as a
dummy coded variable, represents the deviation for x2 = 1 from x2 = 0, but
is that incorrect?

Thanks very much,
Andrew

-- 
Andrew McAleavey, M.S.
Department of Psychology
The Pennsylvania State University
346 Moore Building
University Park, PA 16802
aam239 at psu.edu

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Sat Dec  6 21:23:38 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sun, 7 Dec 2014 07:23:38 +1100
Subject: [R-sig-ME] interpretation of categorical crossed effect in lme4
In-Reply-To: <CANgPp9nKWF_pfNE=giBF3hiNipcqys-+PNB_Tajxv=1_UhJH8Q@mail.gmail.com>
References: <CANgPp9nKWF_pfNE=giBF3hiNipcqys-+PNB_Tajxv=1_UhJH8Q@mail.gmail.com>
Message-ID: <CAF5_5cxRU2+AB0tOiS7UxUT-MeRBX657HG_63fw=gZ+SFiVQcg@mail.gmail.com>

The random effect for x2 is giving the variation in the effect of x2, that
is the difference in levels (from x2=0 to x2=1), with id.

I would first try the model, and see if it improves AIC.

y ~ x1 + x2 +  (1 +x2 | group)

This now allows for the random effects for the intercept and x2 to be
correlated

On 7 December 2014 at 02:12, Andrew McAleavey <andrew.mcaleavey at gmail.com>
wrote:

> Hi,
>
> I have a lmer model of the form:
> y ~ x1 + x2 + (1 | group) + (0 +x2 | group) ;
> where x1 is continuous, x2 is dichotomous and dummy-coded, and group has
> about 250 levels (each with minimum 3 observations in each x2 level, but
> the average is more like 7 per x2 level, and over 15 observations per group
> on average, ignoring x2). My understanding is that this model separately
> estimates variance components for each level of x2 across groups, and does
> not model any correlation between them.
>
> This was a better fit to the data than  the structure:
> y ~ x1 + x2 + (x2 | group) ;
> and I came to this model based on a series of threads on this list. Note
> that under this model the correlation between random effects for x2 and the
> intercept was .67, and as far as I can tell convergence was not a problem
> in either model as it might be in some cases with smaller group numbers.
>
> However, I would like to interpret, at least tentatively, the random
> effects, and especially the relationship between them. My central
> substantive question is whether groups vary with respect to differential
> effectiveness with x2 levels (e.g., some groups were effective with x2=0
> but not x2=1 while others were highly effective with both). Extracting the
> random effects and plotting them suggests that even though the model does
> not explicitly include correlations, the two random effects are correlated
> at about r = .56.
>
> My questions are these:
> a) is a significant correlation like r = .56 common under conditions of my
> model in which these effects were not modeled?
> b) to interpret the random effects, I think I may need to treat them as
> additive and correlate u1 with (u1 + u2), which leads to an even higher
> correlation (r > .8). Am I correct in this? My thinking is that u2, as a
> dummy coded variable, represents the deviation for x2 = 1 from x2 = 0, but
> is that incorrect?
>
> Thanks very much,
> Andrew
>
> --
> Andrew McAleavey, M.S.
> Department of Psychology
> The Pennsylvania State University
> 346 Moore Building
> University Park, PA 16802
> aam239 at psu.edu
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From andrew.mcaleavey at gmail.com  Sat Dec  6 22:04:04 2014
From: andrew.mcaleavey at gmail.com (Andrew McAleavey)
Date: Sat, 6 Dec 2014 16:04:04 -0500
Subject: [R-sig-ME] interpretation of categorical crossed effect in lme4
In-Reply-To: <CAF5_5cxRU2+AB0tOiS7UxUT-MeRBX657HG_63fw=gZ+SFiVQcg@mail.gmail.com>
References: <CANgPp9nKWF_pfNE=giBF3hiNipcqys-+PNB_Tajxv=1_UhJH8Q@mail.gmail.com>
	<CAF5_5cxRU2+AB0tOiS7UxUT-MeRBX657HG_63fw=gZ+SFiVQcg@mail.gmail.com>
Message-ID: <CANgPp9n=ADRt-kCGEnK4drK10=xKgnRbVwdAPAPRouYTVV30cg@mail.gmail.com>

Thanks for the reply,

I take from your message that my interpretation of the x2 random effect is
correct - it is the variance of the deviation from the group mean with x2=1
compared with x2=0. So the total effect of group when x2=1 would be the sum
of both random effects, yes?

The model you suggest:
y ~ x1 + x2 +  (1 +x2 | group);
is identical to:
y ~ x1 + x2 +  (x2 | group),
right? It seems to be based on my testing and understanding of lmer
defaults. In any case that model does not improve model fit according to
AIC/BIC and LRT, so I went with the one I described in my first email.

My problem is that these variances should not be correlated (because there
is no covariance between them, right?), though the estimates (pulled from
ranef() ) seem to be meaningfully correlated. Is this just a chance
occurrence or artifact, like when factor scores from uncorrelated factors
are highly correlated? Should I not interpret the high observed correlation
due to the lack of formal modeling and nonsignificant improvement? Am I
just capitalizing on chance?

Thanks!
Andrew

On Sat, Dec 6, 2014 at 3:23 PM, Ken Beath <ken.beath at mq.edu.au> wrote:

> The random effect for x2 is giving the variation in the effect of x2, that
> is the difference in levels (from x2=0 to x2=1), with id.
>
> I would first try the model, and see if it improves AIC.
>
> y ~ x1 + x2 +  (1 +x2 | group)
>
> This now allows for the random effects for the intercept and x2 to be
> correlated
>
> On 7 December 2014 at 02:12, Andrew McAleavey <andrew.mcaleavey at gmail.com>
> wrote:
>
>> Hi,
>>
>> I have a lmer model of the form:
>> y ~ x1 + x2 + (1 | group) + (0 +x2 | group) ;
>> where x1 is continuous, x2 is dichotomous and dummy-coded, and group has
>> about 250 levels (each with minimum 3 observations in each x2 level, but
>> the average is more like 7 per x2 level, and over 15 observations per
>> group
>> on average, ignoring x2). My understanding is that this model separately
>> estimates variance components for each level of x2 across groups, and does
>> not model any correlation between them.
>>
>> This was a better fit to the data than  the structure:
>> y ~ x1 + x2 + (x2 | group) ;
>> and I came to this model based on a series of threads on this list. Note
>> that under this model the correlation between random effects for x2 and
>> the
>> intercept was .67, and as far as I can tell convergence was not a problem
>> in either model as it might be in some cases with smaller group numbers.
>>
>> However, I would like to interpret, at least tentatively, the random
>> effects, and especially the relationship between them. My central
>> substantive question is whether groups vary with respect to differential
>> effectiveness with x2 levels (e.g., some groups were effective with x2=0
>> but not x2=1 while others were highly effective with both). Extracting the
>> random effects and plotting them suggests that even though the model does
>> not explicitly include correlations, the two random effects are correlated
>> at about r = .56.
>>
>> My questions are these:
>> a) is a significant correlation like r = .56 common under conditions of my
>> model in which these effects were not modeled?
>> b) to interpret the random effects, I think I may need to treat them as
>> additive and correlate u1 with (u1 + u2), which leads to an even higher
>> correlation (r > .8). Am I correct in this? My thinking is that u2, as a
>> dummy coded variable, represents the deviation for x2 = 1 from x2 = 0, but
>> is that incorrect?
>>
>> Thanks very much,
>> Andrew
>>
>> --
>> Andrew McAleavey, M.S.
>> Department of Psychology
>> The Pennsylvania State University
>> 346 Moore Building
>> University Park, PA 16802
>> aam239 at psu.edu
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:20}}


From ken.beath at mq.edu.au  Sat Dec  6 23:57:25 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sun, 7 Dec 2014 09:57:25 +1100
Subject: [R-sig-ME] interpretation of categorical crossed effect in lme4
In-Reply-To: <CANgPp9n=ADRt-kCGEnK4drK10=xKgnRbVwdAPAPRouYTVV30cg@mail.gmail.com>
References: <CANgPp9nKWF_pfNE=giBF3hiNipcqys-+PNB_Tajxv=1_UhJH8Q@mail.gmail.com>
	<CAF5_5cxRU2+AB0tOiS7UxUT-MeRBX657HG_63fw=gZ+SFiVQcg@mail.gmail.com>
	<CANgPp9n=ADRt-kCGEnK4drK10=xKgnRbVwdAPAPRouYTVV30cg@mail.gmail.com>
Message-ID: <CAF5_5cwmCMjE-9w+b48m6BPmbY9HMjemqoPFBqb1ps0KCDuw0Q@mail.gmail.com>

Interpretation of x2 random effect is correct,   and the models  are
identical.

These models can do some strange things. I would try coding x2 as -0.5,0.5
and see what happens, and possibly also centering x1.

If all else fails simulating some data sets and seeing what happens can be
very illuminating.

On 7 December 2014 at 08:04, Andrew McAleavey <andrew.mcaleavey at gmail.com>
wrote:

> Thanks for the reply,
>
> I take from your message that my interpretation of the x2 random effect is
> correct - it is the variance of the deviation from the group mean with x2=1
> compared with x2=0. So the total effect of group when x2=1 would be the sum
> of both random effects, yes?
>
> The model you suggest:
> y ~ x1 + x2 +  (1 +x2 | group);
> is identical to:
> y ~ x1 + x2 +  (x2 | group),
> right? It seems to be based on my testing and understanding of lmer
> defaults. In any case that model does not improve model fit according to
> AIC/BIC and LRT, so I went with the one I described in my first email.
>
> My problem is that these variances should not be correlated (because there
> is no covariance between them, right?), though the estimates (pulled from
> ranef() ) seem to be meaningfully correlated. Is this just a chance
> occurrence or artifact, like when factor scores from uncorrelated factors
> are highly correlated? Should I not interpret the high observed correlation
> due to the lack of formal modeling and nonsignificant improvement? Am I
> just capitalizing on chance?
>
> Thanks!
> Andrew
>
> On Sat, Dec 6, 2014 at 3:23 PM, Ken Beath <ken.beath at mq.edu.au> wrote:
>
>> The random effect for x2 is giving the variation in the effect of x2,
>> that is the difference in levels (from x2=0 to x2=1), with id.
>>
>> I would first try the model, and see if it improves AIC.
>>
>> y ~ x1 + x2 +  (1 +x2 | group)
>>
>> This now allows for the random effects for the intercept and x2 to be
>> correlated
>>
>> On 7 December 2014 at 02:12, Andrew McAleavey <andrew.mcaleavey at gmail.com
>> > wrote:
>>
>>> Hi,
>>>
>>> I have a lmer model of the form:
>>> y ~ x1 + x2 + (1 | group) + (0 +x2 | group) ;
>>> where x1 is continuous, x2 is dichotomous and dummy-coded, and group has
>>> about 250 levels (each with minimum 3 observations in each x2 level, but
>>> the average is more like 7 per x2 level, and over 15 observations per
>>> group
>>> on average, ignoring x2). My understanding is that this model separately
>>> estimates variance components for each level of x2 across groups, and
>>> does
>>> not model any correlation between them.
>>>
>>> This was a better fit to the data than  the structure:
>>> y ~ x1 + x2 + (x2 | group) ;
>>> and I came to this model based on a series of threads on this list. Note
>>> that under this model the correlation between random effects for x2 and
>>> the
>>> intercept was .67, and as far as I can tell convergence was not a problem
>>> in either model as it might be in some cases with smaller group numbers.
>>>
>>> However, I would like to interpret, at least tentatively, the random
>>> effects, and especially the relationship between them. My central
>>> substantive question is whether groups vary with respect to differential
>>> effectiveness with x2 levels (e.g., some groups were effective with x2=0
>>> but not x2=1 while others were highly effective with both). Extracting
>>> the
>>> random effects and plotting them suggests that even though the model does
>>> not explicitly include correlations, the two random effects are
>>> correlated
>>> at about r = .56.
>>>
>>> My questions are these:
>>> a) is a significant correlation like r = .56 common under conditions of
>>> my
>>> model in which these effects were not modeled?
>>> b) to interpret the random effects, I think I may need to treat them as
>>> additive and correlate u1 with (u1 + u2), which leads to an even higher
>>> correlation (r > .8). Am I correct in this? My thinking is that u2, as a
>>> dummy coded variable, represents the deviation for x2 = 1 from x2 = 0,
>>> but
>>> is that incorrect?
>>>
>>> Thanks very much,
>>> Andrew
>>>
>>> --
>>> Andrew McAleavey, M.S.
>>> Department of Psychology
>>> The Pennsylvania State University
>>> 346 Moore Building
>>> University Park, PA 16802
>>> aam239 at psu.edu
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may contain
>> confidential information.  If you are not the intended recipient, please
>> delete it and notify the sender.  Views expressed in this message are those
>> of the individual sender, and are not necessarily the views of the Faculty
>> of Science, Department of Statistics or Macquarie University.
>>
>>
>
>
> --
> Andrew McAleavey, M.S.
> Department of Psychology
> The Pennsylvania State University
> 346 Moore Building
> University Park, PA 16802
> aam239 at psu.edu
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From Ross.Boylan at ucsf.edu  Wed Dec 10 00:21:41 2014
From: Ross.Boylan at ucsf.edu (Boylan, Ross)
Date: Tue, 9 Dec 2014 23:21:41 +0000
Subject: [R-sig-ME] GLMM's with quadrature
Message-ID: <F1F13E14A610474196571953929C020964A512@ex08.net.ucsf.edu>

I am interested in evaluating mixed models with
* non-normal errors (binary and count outcomes)
* random slopes and intercepts, possibly correlated (slopes and intercepts are over the same clusters)
* quadrature

The documentation for lme4 indicates no restrictions on combining these that I see, though I think in the past there were.  So, can I freely combine all 3 of the dimensions listed above?  Is there some other package worth considering?

There will also be some conventional LMM's.

Thanks.
Ross Boylan

P.S. What's up with the FAQ?  The old one seems to have gone, though there is something identified as a draft at http://glmm.wikidot.com/faq.

From bbolker at gmail.com  Wed Dec 10 01:15:55 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 09 Dec 2014 19:15:55 -0500
Subject: [R-sig-ME] GLMM's with quadrature
In-Reply-To: <F1F13E14A610474196571953929C020964A512@ex08.net.ucsf.edu>
References: <F1F13E14A610474196571953929C020964A512@ex08.net.ucsf.edu>
Message-ID: <548790BB.1090000@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-09 06:21 PM, Boylan, Ross wrote:
> I am interested in evaluating mixed models with * non-normal
> errors (binary and count outcomes) * random slopes and intercepts,
> possibly correlated (slopes and intercepts are over the same
> clusters) * quadrature
> 
> The documentation for lme4 indicates no restrictions on combining 
> these that I see, though I think in the past there were.  So, can
> I freely combine all 3 of the dimensions listed above?  Is there
> some other package worth considering?
> 
> There will also be some conventional LMM's.

  Yes, there is a restriction.  In previous (pre-1.0) versions of lme4
vector-valued random effects could be fitted by quadrature (but only
models with a single grouping variable could be used).  We still
haven't managed to get around to doing this for the modern version of
lme4: https://github.com/lme4/lme4/issues/123

  For LMMs, quadrature is not necessary; the integrals can be reduced
analytically to a single penalized, weighted residual sums of squares
computation that can be done without numerical integration or
approximations thereof.

> 
> Thanks. Ross Boylan
> 
> P.S. What's up with the FAQ?  The old one seems to have gone,
> though there is something identified as a draft at 
> http://glmm.wikidot.com/faq.

  Where was the old one?  That's the only one I'm aware of.

> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUh5C7AAoJEOCV5YRblxUHkqQH/1mmz3GswBeQKFHTiqXP3cKZ
8IYjm6lJY3UGaH4Tu60BjbLIlg8gIjdkPater1yY92xfS9e6A6IOcVy2L7JWRwJ4
1PsdnISvovouFW1q/3nFg0Keo6FD+0JI7s2iSZ/u1pMf9KyHC9veQXpRAXolj3Zr
KsmRDr7v9bJIAJSO4NMQHsrDJ51png9boQmR7Gg+/x/EEXY+3DIAHDAxTsXG7rrp
DYkz0Tce8Gl5931HtliMXtB08v3Re23pZkNdlc8yLYTPj44xQ9MdNCnOtwMdEooV
lcrlcIrJwpTcK6pnE9lqxmipBoAEhoDETAHqtVu2Ea6rjiiFvkTv/0sg7jlm9nI=
=r5pO
-----END PGP SIGNATURE-----


From Ross.Boylan at ucsf.edu  Wed Dec 10 01:42:56 2014
From: Ross.Boylan at ucsf.edu (Boylan, Ross)
Date: Wed, 10 Dec 2014 00:42:56 +0000
Subject: [R-sig-ME] GLMM's with quadrature
In-Reply-To: <548790BB.1090000@gmail.com>
References: <F1F13E14A610474196571953929C020964A512@ex08.net.ucsf.edu>,
	<548790BB.1090000@gmail.com>
Message-ID: <F1F13E14A610474196571953929C020964A5C1@ex08.net.ucsf.edu>

Thanks for the info on quadrature; I think that would be worth noting in the documentation, if I didn't just overlook it.

The old FAQ may have been on the sourceforge site, but I'm not sure.  It had a lot of stuff about the different versions of lme4, which I gather is not so relevant now that it's "released".

Is the current FAQ a draft in the sense that it contains info that is wrong, or just in the "still working on it" sense?
Ross
________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Ben Bolker [bbolker at gmail.com]
Sent: Tuesday, December 09, 2014 4:15 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMM's with quadrature
.....
>
> P.S. What's up with the FAQ?  The old one seems to have gone,
> though there is something identified as a draft at
> http://glmm.wikidot.com/faq.

  Where was the old one?  That's the only one I'm aware of.



From bbolker at gmail.com  Wed Dec 10 02:12:24 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 09 Dec 2014 20:12:24 -0500
Subject: [R-sig-ME] GLMM's with quadrature
In-Reply-To: <F1F13E14A610474196571953929C020964A5C1@ex08.net.ucsf.edu>
References: <F1F13E14A610474196571953929C020964A512@ex08.net.ucsf.edu>,
	<548790BB.1090000@gmail.com>
	<F1F13E14A610474196571953929C020964A5C1@ex08.net.ucsf.edu>
Message-ID: <54879DF8.7020703@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-09 07:42 PM, Boylan, Ross wrote:
> Thanks for the info on quadrature; I think that would be worth
> noting in the documentation, if I didn't just overlook it.

  Agree.

> The old FAQ may have been on the sourceforge site, but I'm not
> sure. It had a lot of stuff about the different versions of lme4,
> which I gather is not so relevant now that it's "released".
> 
> Is the current FAQ a draft in the sense that it contains info that
> is wrong, or just in the "still working on it" sense?

  "still working on it" (although it could probably use a
going-through looking for out-of-date info ...)

 Ross
> ________________________________________ From: R-sig-mixed-models 
> [r-sig-mixed-models-bounces at r-project.org] on behalf of Ben Bolker 
> [bbolker at gmail.com] Sent: Tuesday, December 09, 2014 4:15 PM To: 
> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] GLMM's
> with quadrature .....
>> 
>> P.S. What's up with the FAQ?  The old one seems to have gone, 
>> though there is something identified as a draft at 
>> http://glmm.wikidot.com/faq.
> 
> Where was the old one?  That's the only one I'm aware of.
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUh534AAoJEOCV5YRblxUHFpgIAK7IpzogO/5SDhJa956WpfDW
mtOURcuE8NyYg03DYMT+BCy5bs6VqekrjLJpm8ci56I0+asZAgq0K2lz1qWG2+lz
BqGfKmxR/3uoysCq+mYjbfGg6EMfUWZksWA5cuv1+jwhTaPDl09KW3YO4xMgrE62
B98mcExCcoPYLcbwANMObYBggiSRxhJppXN2fHhUehkUYQj/ybHHT533+BlyeI74
dCNsaK9h4jw3A4frymrRiaazjCyH4mrv/4kBwNCWwgiJvi604aGNGl82gGFO+0Z7
VWviKxu0D9z7aalpvpigkDn4N+Gax6P/JZ0rh00rzTBGP+CRdOjz5j1ItKmYSCI=
=5UfQ
-----END PGP SIGNATURE-----


From Ross.Boylan at ucsf.edu  Wed Dec 10 21:58:56 2014
From: Ross.Boylan at ucsf.edu (Boylan, Ross)
Date: Wed, 10 Dec 2014 20:58:56 +0000
Subject: [R-sig-ME] GLMM's with quadrature
In-Reply-To: <54886360.3040505@otter-rsch.com>
References: <F1F13E14A610474196571953929C020964A512@ex08.net.ucsf.edu>,
	<54886360.3040505@otter-rsch.com>
Message-ID: <F1F13E14A610474196571953929C020964AB8E@ex08.net.ucsf.edu>

There seems to be a pattern here of the quadrature, or at least the >1d quadrature being dropped.  Is it that the previous implementations were deemed unreliable?  Quadrature can be important in getting accurate results.

Ross Boylan
________________________________________
From: dave fournier [davef at otter-rsch.com]
Sent: Wednesday, December 10, 2014 7:14 AM
To: Boylan, Ross
Subject: Re: [R-sig-ME] GLMM's with quadrature

You can do that with ADMB. Unfortunatly the glmmadmb package lost the
ability
to do gauss-hermite integration when it was rewritten, but the
underlying software has that ability for multiple
grouping factors.


From bbolker at gmail.com  Thu Dec 11 03:28:39 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Dec 2014 21:28:39 -0500
Subject: [R-sig-ME] GLMM's with quadrature
In-Reply-To: <F1F13E14A610474196571953929C020964AB8E@ex08.net.ucsf.edu>
References: <F1F13E14A610474196571953929C020964A512@ex08.net.ucsf.edu>,
	<54886360.3040505@otter-rsch.com>
	<F1F13E14A610474196571953929C020964AB8E@ex08.net.ucsf.edu>
Message-ID: <54890157.2020904@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-10 03:58 PM, Boylan, Ross wrote:
> There seems to be a pattern here of the quadrature, or at least
> the
>> 1d quadrature being dropped.  Is it that the previous
> implementations were deemed unreliable?  Quadrature can be
> important in getting accurate results.

  In the case of lme4 it wasn't unreliability, it was just the hassle
of reimplementing the general case.  It's not out of the question,
it's just a matter of time and effort.  Pull requests are welcome!

I have a few notes on vector-valued GH at:

 http://htmlpreview.github.com/?https://github.com/lme4/lme4/blob/master/misc/notes/laplDiag.html

  Dave, can ADMB do G-H with vector-valued random effects?
http://otter-rsch.com/admbre/admbre.pdf says GH applies:

In the situation where the model is separable of type ?block diagonal
Hessian? with only a single random effect in each block (see Section 2.4)

  it sounds to me like this excludes vector-value random effects, but
I could be mistaken ...


> 
> Ross Boylan ________________________________________ From: dave 
> fournier [davef at otter-rsch.com] Sent: Wednesday, December 10, 2014 
> 7:14 AM To: Boylan, Ross Subject: Re: [R-sig-ME] GLMM's with 
> quadrature
> 
> You can do that with ADMB. Unfortunatly the glmmadmb package lost 
> the ability to do gauss-hermite integration when it was rewritten, 
> but the underlying software has that ability for multiple grouping 
> factors.
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUiQFXAAoJEOCV5YRblxUHkhoH/A8qPdHhRGbNFQLjBRv04o/8
fQztMvn+GQ7f3rm9Dux/uxZ7Qq0KkTSUNrRggumy97DG8irMrPuskXOi9C9Xt4E+
6Sc5t7aEct/Q34XBf3Pr9dvyMGJQuhvnoZUY1zFmiVXyw1xLpz8EhWmupoCglVlw
r5JQcFqF3IIzvcsFiQBFWmGA5HxOC73uYw0Gmso6O1nEpJ2gTMnKqHAcUKHIqeqf
7rO/1NrUhkHnER2ETbcav/aCzLWb388KXnJx7IsQn4z2GVMeUYAIMLittcnmTC5z
KtRaQDcw1oiIpib4zvA3bZKbDmbZVN2LtZoR5r2u9/AVCWNaMHYxx0+4yeb4ZpE=
=1LRH
-----END PGP SIGNATURE-----


From Emily.DeStigter at humboldt.edu  Thu Dec 11 08:37:43 2014
From: Emily.DeStigter at humboldt.edu (Emily L. De Stigter)
Date: Wed, 10 Dec 2014 23:37:43 -0800
Subject: [R-sig-ME] (no subject)
Message-ID: <CAF9iywh91rr0G9FnhwjKh8XWBNu68wMQSP0FkT=vg9F=0zfz6Q@mail.gmail.com>

Hello,

I'm just out of undergrad and working in an ecology lab as the leading
statistical investigator for a project studying conifers in Northern
California. I'm using lme4 to do a GLMM. My response variable is binary:
status of the trees (live vs dead). I also have two fixed effects: diameter
at breast height (DBH) and elevation, plus the interaction of the two. My
random effect is plot.

Here are my questions:

   1.

   Do the fixed effects (DBH and elevation) need to be normally
   distributed? Both DBH and elevation are not normally distributed and the
   basic transformations I've tried did not correct the issue.
   2.

   The random effect I have (plot) is not normally distributed as I know
   that it needs to be. I have tried a couple different transformations (log,
   sqrt...) but, again, nothing the corrected the issue. What should I try
   next to fix it?
   3.

   How should I best check that my model is fitting the data appropriately?
   4.

   How do I interpret the deviance of the model?

Here's some of my R code:

PSME stands for Psuedotsuga menziesii, one of the species of interest.

stat<-read.csv("/Users/emilydestigter/Documents/Sawyer/status.csv")

head(stat)

dim(stat)

psme<-glmer(Status~DBH+Elevation+(DBH*Elevation)+(1|Plot),data=stat,family=
"binomial")

summary(psme)

Thanks for reading and let me know if anyone has any follow-up questions. I
appreciate greatly any and all advice I get. I realize these questions are
not exactly related to this forum, so I would also be glad for some
suggestions on resources to check out.

Thanks again,

Emily

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Thu Dec 11 10:00:29 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 11 Dec 2014 09:00:29 +0000
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAF9iywh91rr0G9FnhwjKh8XWBNu68wMQSP0FkT=vg9F=0zfz6Q@mail.gmail.com>
References: <CAF9iywh91rr0G9FnhwjKh8XWBNu68wMQSP0FkT=vg9F=0zfz6Q@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3C83365@inbomail.inbo.be>

Dear Emily,

It sounds like you could use some reading on this topic. I would recommend Zuur et al (2009), Bolker (2008) and Pinheiro & Bates (2000).

1. No. The assumption of normality is only for the **residuals** of a **linear** (mixed) model. So neither the fixed effects nor the response has to be normally distributed. Note that the residuals of a **generalized** linear (mixed) model don't have the assumption of normality.
2. Yes, these are assumed to be normally distributed. Small deviations from normality are not problematic. Strong deviations usually indicate that you are missing an important covariate. Maybe the assumption of i.i.d. is not valid due to the spatial structure of the plots (spatial autocorrelation).
3. Plot the residuals against available covariates. There shouldn't be a pattern in the residuals.
4. The deviance of a single model is not that informative. It is mainly used to compare models.

Note that DBH+Elevation+(DBH*Elevation) can be written as DBH * Elevation. Andaddingspacestocodemakesitmuchmorereadable.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Emily L. De Stigter
Verzonden: donderdag 11 december 2014 8:38
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] (no subject)

Hello,

I'm just out of undergrad and working in an ecology lab as the leading statistical investigator for a project studying conifers in Northern California. I'm using lme4 to do a GLMM. My response variable is binary:
status of the trees (live vs dead). I also have two fixed effects: diameter at breast height (DBH) and elevation, plus the interaction of the two. My random effect is plot.

Here are my questions:

   1.

   Do the fixed effects (DBH and elevation) need to be normally
   distributed? Both DBH and elevation are not normally distributed and the
   basic transformations I've tried did not correct the issue.
   2.

   The random effect I have (plot) is not normally distributed as I know
   that it needs to be. I have tried a couple different transformations (log,
   sqrt...) but, again, nothing the corrected the issue. What should I try
   next to fix it?
   3.

   How should I best check that my model is fitting the data appropriately?
   4.

   How do I interpret the deviance of the model?

Here's some of my R code:

PSME stands for Psuedotsuga menziesii, one of the species of interest.

stat<-read.csv("/Users/emilydestigter/Documents/Sawyer/status.csv")

head(stat)

dim(stat)

psme<-glmer(Status~DBH+Elevation+(DBH*Elevation)+(1|Plot),data=stat,family=
"binomial")

summary(psme)

Thanks for reading and let me know if anyone has any follow-up questions. I appreciate greatly any and all advice I get. I realize these questions are not exactly related to this forum, so I would also be glad for some suggestions on resources to check out.

Thanks again,

Emily

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From john.maindonald at anu.edu.au  Thu Dec 11 11:21:52 2014
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 11 Dec 2014 10:21:52 +0000
Subject: [R-sig-ME] (no subject)
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3C83365@inbomail.inbo.be>
References: <CAF9iywh91rr0G9FnhwjKh8XWBNu68wMQSP0FkT=vg9F=0zfz6Q@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3C83365@inbomail.inbo.be>
Message-ID: <5E5EDFE3-CFF1-4609-B02D-222D846548DC@anu.edu.au>

On point 2, it is the random effects that are assumed to be normally
distributed.   You can use ranef() to get estimates of these.  Unless
however the design is pretty much balanced, the estimates can be
highly non-normal, because of the interplay between effects at
different levels of the design, or in a crossed design, different random
factors.  Also, think which random effects matter for purposes of the 
model estimates in which you are interested. 

In a classical design where one set of treatments are applied at the 
level of plots, with perhaps another at the level of subplots, it is the plot
random effects that likely mainly matter for inference wrt treatments
applied to plots (and in that classical context, you probably have a
balanced design, i.e., all treatment differences estimated with similar
accuracy).

In severely unbalanced designs, maybe one can get somewhere by
simulating from the fitted model, plotting ordered simulated plot
effects agains the estimated effects, and hoping for a roughly linear
scatter.   Others may be able to comment ? what literature is there 
addressing this general issue?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 11 Dec 2014, at 20:00, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:

> Dear Emily,
> 
> It sounds like you could use some reading on this topic. I would recommend Zuur et al (2009), Bolker (2008) and Pinheiro & Bates (2000).
> 
> 1. No. The assumption of normality is only for the **residuals** of a **linear** (mixed) model. So neither the fixed effects nor the response has to be normally distributed. Note that the residuals of a **generalized** linear (mixed) model don't have the assumption of normality.
> 2. Yes, these are assumed to be normally distributed. Small deviations from normality are not problematic. Strong deviations usually indicate that you are missing an important covariate. Maybe the assumption of i.i.d. is not valid due to the spatial structure of the plots (spatial autocorrelation).
> 3. Plot the residuals against available covariates. There shouldn't be a pattern in the residuals.
> 4. The deviance of a single model is not that informative. It is mainly used to compare models.
> 
> Note that DBH+Elevation+(DBH*Elevation) can be written as DBH * Elevation. Andaddingspacestocodemakesitmuchmorereadable.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Emily L. De Stigter
> Verzonden: donderdag 11 december 2014 8:38
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] (no subject)
> 
> Hello,
> 
> I'm just out of undergrad and working in an ecology lab as the leading statistical investigator for a project studying conifers in Northern California. I'm using lme4 to do a GLMM. My response variable is binary:
> status of the trees (live vs dead). I also have two fixed effects: diameter at breast height (DBH) and elevation, plus the interaction of the two. My random effect is plot.
> 
> Here are my questions:
> 
>   1.
> 
>   Do the fixed effects (DBH and elevation) need to be normally
>   distributed? Both DBH and elevation are not normally distributed and the
>   basic transformations I've tried did not correct the issue.
>   2.
> 
>   The random effect I have (plot) is not normally distributed as I know
>   that it needs to be. I have tried a couple different transformations (log,
>   sqrt...) but, again, nothing the corrected the issue. What should I try
>   next to fix it?
>   3.
> 
>   How should I best check that my model is fitting the data appropriately?
>   4.
> 
>   How do I interpret the deviance of the model?
> 
> Here's some of my R code:
> 
> PSME stands for Psuedotsuga menziesii, one of the species of interest.
> 
> stat<-read.csv("/Users/emilydestigter/Documents/Sawyer/status.csv")
> 
> head(stat)
> 
> dim(stat)
> 
> psme<-glmer(Status~DBH+Elevation+(DBH*Elevation)+(1|Plot),data=stat,family=
> "binomial")
> 
> summary(psme)
> 
> Thanks for reading and let me know if anyone has any follow-up questions. I appreciate greatly any and all advice I get. I realize these questions are not exactly related to this forum, so I would also be glad for some suggestions on resources to check out.
> 
> Thanks again,
> 
> Emily
> 
>        [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jeffrey.stratford at wilkes.edu  Thu Dec 11 22:13:00 2014
From: jeffrey.stratford at wilkes.edu (Stratford, Jeffrey)
Date: Thu, 11 Dec 2014 16:13:00 -0500
Subject: [R-sig-ME] glmmADMB: "Error in Z * sweep"
Message-ID: <CAP5kizT9OA3+pjRgQ-AkGano+kxUFGbMJRB683cUw3d3xMpeSA@mail.gmail.com>

Hi everyone,

I have a design with a negative binomial distribution (possibly ZINB),
repeated measures (TRIAL), and clusters (three samples of different
treatments together) and many clusters.

The experiment is this: they put 200 sunflower seeds in a tray and counted
the seeds remaining after a week and this is the giving up density (GUD).
Three trays (=TYPE, either near a log, a random location, or near a seed
cache) were set out at 16 SITEs and) and this was repeated 5 or 6 times
(=TRIALS). Not my design but I was asked the analyze the data. Data are
below.

The central question is how TYPE affects GUDs and if this changes over
TRIALS.

I tried two different models (below) but I couldn't get either to work. I
would greatly appreciate any insight on how to get this to run.

Thanks,

Jeff

R 3.1.2 in Windows


# just seeing if I could get any results

>  temp <- glmmadmb(gud2~type2 + (1|trial2), data=gud, family="nbinom")

# and the result:

Error in Z * sweep(allU, 2, sdvals, "*") : non-conformable arrays
In addition: Warning message:
In glmmadmb(gud2 ~ type2 + (1 | trial2), data = gud, family = "nbinom") :
  NAs removed in constructing fixed-effect model frame: you should probably
remove them manually, e.g. with na.omit()

# attempting to include site effect... not sure if this is correct though

>  temp <- glmmadmb(gud2~type2 + (site|trial2), data=gud, family="nbinom")

Parameters were estimated, but not standard errors were not: the most
likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(gud2 ~ type2 + (site | trial2), data = gud, family =
"nbinom") :
  The function maximizer failed (couldn't find STD file) Troubleshooting
steps include (1) run with 'save.dir' set and inspect output files; (2)
change run parameters: see '?admbControl'
In addition: Warning messages:
1: In glmmadmb(gud2 ~ type2 + (site | trial2), data = gud, family =
"nbinom") :
  NAs removed in constructing fixed-effect model frame: you should probably
remove them manually, e.g. with na.omit()
2: running command 'C:\Windows\system32\cmd.exe /c "C:/Program
Files/R/R-3.1.2/library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500
-maxph 5 -noinit -shess' had status 1



The data:

structure(c(7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,
10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,
10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11,
11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,
11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,
11, 11, 11, 11, 11, 11, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,
6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
6, 6, 6, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,
8, 8, 8, 9, 9, 9, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14,
14, 15, 15, 15, 16, 16, 16, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5,
5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 11, 11, 11, 12, 12, 12,
13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 2, 2, 2, 3, 3,
3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 11,
11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16,
16, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8,
8, 8, 9, 9, 9, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14,
15, 15, 15, 16, 16, 16, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6,
6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 11, 11, 11, 12, 12, 12, 13,
13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 1, 1, 1, 2, 2, 2,
3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9,
10, 10, 10, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 17,
17, 17, 19, 19, 19, 1, 1, 1, 2, 2, 2, 4, 4, 4, 5, 5, 5, 6, 6,
6, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 13, 13, 13, 14,
14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19,
19, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 9,
9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14,
14, 16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 2, 2, 2,
3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9,
10, 10, 10, 11, 11, 11, 13, 13, 13, 15, 15, 15, 16, 16, 16, 17,
17, 17, 18, 18, 18, 19, 19, 19, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4,
4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 10, 10, 10, 12, 12,
12, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18, 18, 18,
19, 19, 19, 3, 3, 3, 4, 4, 4, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9,
9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14,
15, 15, 15, 16, 16, 16, 18, 18, 18, 19, 19, 19, 17, 17, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,
1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 2, 1, 124, 72, 32, 112, 98, 138,
95, 153, 80, 163, 154, 78, 136, 92, 179, 113, 77, 96, 120, 170,
81, 10, 106, 149, 83, 88, 71, 97, 110, 140, 59, 76, 48, 98, 153,
58, 178, 137, 129, 146, 101, 158, 16, 180, 20, 122, 183, 184,
177, 169, 122, 61, 154, 0, 118, 178, 118, 191, 185, 170, 53,
165, 164, 113, 147, 163, 141, 124, 138, 156, 186, 154, 57, 0,
136, 50, 152, 119, 173, 191, 193, 10, 183, 140, 74, 124, 99,
182, 191, 183, 161, 189, 111, 174, 165, 40, 40, 171, 171, 82,
179, 182, 185, 194, 193, 91, 161, 68, 92, 163, 179, 24, 60, 101,
35, 154, 155, 21, 130, 44, 151, 194, 193, 6, 118, 178, 176, 171,
190, 176, 169, 196, 187, 176, 183, 7, 162, 49, 158, 99, 32, 177,
193, 178, 88, 113, 178, 53, 159, 163, 124, 164, 116, 131, 171,
14, 92, 180, 133, 9, 146, 93, 152, 117, 197, 147, 188, 137, 130,
192, 170, 52, 197, 150, 191, 184, 186, 127, 196, 146, 165, 163,
164, 176, 169, 160, 147, 164, 175, 132, 184, 171, 191, 181, 164,
83, 166, 173, 189, 196, 194, 184, 139, 167, 193, 191, 176, 147,
184, 124, 0, 48, 4, 42, 79, 46, 7, 0, 56, 5, 15, 15, 0, 40, 1,
24, 30, 23, 75, 134, 66, 15, 35, 0, 29, 26, 5, 10, 5, 37, 8,
5, 12, 41, 34, 40, 11, 8, 0, 67, 7, 6, 50, 86, 17, 0, 5, 0, 1,
6, 7, 21, 0, 69, 21, 13, 3, 75, 126, 2, 0, 85, 27, 63, 42, 8,
0, 33, 16, 3, 33, 0, 0, 46, 3, 88, 64, 3, 15, 6, 29, 0, 20, 4,
25, 11, 4, 22, 76, 4, 22, 1, 7, 3, 26, 5, 10, 22, 0, 9, 0, 32,
2, 9, 1, 1, 36, 24, 18, 27, 17, 23, 22, 1, 0, 0, 2, 4, 2, 10,
13, 13, 18, 7, 0, 22, 8, 15, 17, 2, 23, 22, 7, 45, 4, 5, 31,
16, 0, 10, 6, 0, 2, 0, 5, 7, 40, 3, 30, 2, 4, 3, 2, 1, 63, 31,
4, 0, 2, 7, 11, 3, 0, 11, 8, 7, 10, 0, 10, 50, 6, 1, 137, 6,
2, 21, 24, 1, 0, 1, 1, 3, 2, 4, 95, 1, 3, 7, 6, 0, 4, 4, 121,
136, 3, 3, 137, 117, 95, 8, 22, 125, 97, 48, 2, 5, 27, 7, 42,
5, 69, 45, 30, 0, 66, 117, 2, 0, 9, 4, 30, 0, 31, 107, 21, 0,
4, 33, 3, 4, 0, 51, 182, 13, 0, 6, 0, 1, 2, 0, 104, 52, 37, 21,
136, 86, 42, 5, 122, 156, 93, 67, 7, 144, 136, 69, 169, 55, 6,
0, 3, 6, 27, 1, 1, 61, 109, 18, 29, 165, 66, 179, 8, 67, 30,
26, 22, 134, 10, 7, 40, 0, 0, 1, 2, 185, 121), .Dim = c(497L,
4L), .Dimnames = list(NULL, c("trial2", "site2", "type2", "gud2"
)))



-- 
********************************************************
Jeffrey A. Stratford, PhD
Department of Biology and Health Sciences
Wilkes University, PA 18766 USA
570-332-2942
http://web.wilkes.edu/jeffrey.stratford/
********************************************************

	[[alternative HTML version deleted]]


From vmitov at gmail.com  Thu Dec 11 22:25:33 2014
From: vmitov at gmail.com (Mitov Venelin)
Date: Thu, 11 Dec 2014 22:25:33 +0100
Subject: [R-sig-ME] lme with a known correlation matrix for the random
	effects
Message-ID: <878C7D3D-CB94-4BDE-8F9A-37B80E79E693@gmail.com>

Dear R-sig mailing list, 

Currently, I'm trying to use the function lme from the nlme package to model epidemiological data. My question seems to be a specific one and I couldn?t find any similar model formulation using the lme function. That?s why I?m writing you. 

The data I have is as follows:

1. y: a numeric response vector consisting of one phenotype measurement for each of N patients.

2. A known known correlation matrix, Psi, between the patients. 

I would like to model this data as a linear mixed effects model as follows:

y_i = beta + g_i + e_i, 

i=1,?,N

Here are the model assumptions:

beta is a fixed population grand-mean (i.e. intercept); 

g_i is the pathogen-specific contribution to y_i and is considered as a random effect that is correlated along patients (explained in more detail below); 

e_i is a patient-specific random effect including the effects of patient?s immune system, any possible interaction between the patient?s immune system and the pathogen, and measurement error for y_i. 

In matrix-notation the model can be written as follows

y = 1*beta + I_NxN*g + I_NxN*e

In the formula above 1 denotes a N-dimensional vector of ones, I_NxN denotes the NxN identity matrix. 
The random N-dimensional vector g is assumed to be normally distributed with mean 0 and a known correlation matrix, Psi. 
The random N-dimensional vector e is assumed to be normally distributed with mean 0 and and identity correlation matrix I_NxN.

The model has three parameters: 
- beta; 
- sigma_g, such that covariance matrix of g is equal to Psi*sigma_g^2 (Psi is known and fixed);
- sigma_e such that the covariance matrix of e is I_NxN*sigma_e^2;

Note that in the lme terminology each of the patients represents a group by itself and there is 1 observation per group.
I?m able to fit the model using maximum likelihood, but I?m trying to use the lme function mostly because of its REML fitting method. 

So far, I?ve tried to use the lme function but I?m getting errors and I don?t know how to formulate my model in the lme syntax. 

N=5
y <- c(7.38, 7.25, 7.34, 7.30, 7.06)
names(y) <- c("t4", "t2", "t5", "t1", "t3")
g <- factor(names(y))
data <- data.frame(y=y, g=g)

Psi <- matrix(c(1, 0.00, 0.00, 0.00, 0.00,
                0, 1.00, 0.28, 0.25, 0.78,
                0, 0.28, 1.00, 0.83, 0.26,
                0, 0.25, 0.83, 1.00, 0.23,
                0, 0.78, 0.26, 0.23, 1.00), nrow=N, ncol=N)
rownames(Psi)<-colnames(Psi)<-names(y)

pdMatPsi <- pdMat(Psi, form=~1|g, pdClass='pdSymm') # Not sure if the formula is correct and if pdSymm is the right pdMat class to use.


> lme(y~1, data, random=pdMatPsi)
Error in getGroups.data.frame(dataMix, groups) : 
  invalid formula for groups

For this error I guess the problem is that lme tries to look for a formula in the data.frame data which, as I?ve read in a vignette, is normally used only for plotting the data, so I?d rather keep the data.frame and not extend it to a groupedData.

> lme(y~1, data, random=list(g=pdMatPsi))
Error in matrix(unlist(value), nrow = nrow(data), dimnames = list(row.names(data),  : 
  length of 'dimnames' [2] not equal to array extent
In addition: Warning message:
In Ops.factor(1, g) : | not meaningful for factors

Here I don?t understand what am I doing wrong. I?ve tried other formulas in the call to pdMat but I?m still getting errors. 
Is it possible to use lme to fit the above model to the data? Also, is it possible to use the more recent lme4 package as it is supposed to be much faster?

Thank you and best regards,
MV

From fjuretig at yahoo.com  Fri Dec 12 03:48:04 2014
From: fjuretig at yahoo.com (Francisco Juretig)
Date: Fri, 12 Dec 2014 02:48:04 +0000 (UTC)
Subject: [R-sig-ME] question regarding multiple subjects in lmer
Message-ID: <812077211.1683.1418352484751.JavaMail.yahoo@jws100200.mail.ne1.yahoo.com>

I am trying to understand how to handle random effects that come from multiple subjects in R for nonlinear models. I am able to formulate a simple linear model, integrate it via Gaussian Quadrature and compare it against lmer using just one subject. This works perfectly, since I can replicate the log-likelihood that lmer reports perfectly. But when I have a model that contains two subjects (non-nested) I observe a discrepancy. In particular, for the following example I use 54 points and get a log-likelihood of -420.6831 while lmer reports?-419.8. I suspect I am not formulating correctly the likelihood. Of course I know that lmer does not maximize the log-likelihood like this, but understanding why I have this discrepancy helps me understand what I am doing.
This is the code

########reading datapoliteness ? ? ? = read.csv("http://www.bodowinter.com/tutorial/politeness_data.csv")politeness=politeness[-39,]politeness = politeness[,-1]politeness = politeness[,-3]politeness = politeness[order(politeness$gender,politeness$scenario),]library(lme4)
summary(lmer(frequency ~ 1+ (1|gender) + (1|scenario) ,REML=F, data=politeness))
#######quadrature points and weightsquadrature_weights=c(9.616569769829950237E-41,1.2653200760169131064E-35,1.2587808691128592114E-31,2.9626275871495619963E-28,2.59233715574559135377E-25,1.07064905864221394747E-22,2.41469199997268789E-20,3.27825196978982733433E-18,2.8709892632049633876E-16,1.70734067334684107569E-14,7.1713449978551800189E-13,2.19439846768108755285E-11,5.0147398704734680389E-10,8.7334448358337263426E-9,1.1786188465819040326E-7,1.24981002841129022132E-6,1.05354444418257434272E-5,7.1294347272484865949E-5,3.90516172663158571989E-4,0.00174352542196549101376,0.0063820594170464546055,0.0192464413705395102212,0.04801030616129549637501,0.099382787160472611675,0.17114652799601409275,0.2456424705042445872716,0.294199084527291925209,0.2941990845272919252086,0.245642470504244587272,0.17114652799601409275,0.09938278716047261167547,0.048010306161295496375,0.0192464413705395102212,0.0063820594170464546055,0.00174352542196549101376,3.9051617266315857199E-4,7.12943472724848659488E-5,1.05354444418257434272E-5,1.24981002841129022132E-6,1.1786188465819040326E-7,8.7334448358337263426E-9,5.0147398704734680389E-10,2.19439846768108755285E-11,7.1713449978551800189E-13,1.7073406733468410757E-14,2.87098926320496338764E-16,3.27825196978982733433E-18,2.41469199997268789E-20,1.07064905864221394747E-22,2.5923371557455913538E-25,2.96262758714956199629E-28,1.2587808691128592114E-31,1.2653200760169131064E-35,9.616569769829950237E-41)
quadrature_points=c(-9.58416554752346979315,-8.93368833209619334348,-8.39452562332720216575,-7.912775297812494749828,-7.467875283483621332888,-7.04923709867837791084,-6.65050917856649298516,-6.2675031293697518237,-5.897270957641121499901,-5.5376356924033013317,-5.18692897959288955054,-4.843833634581987470744,-4.507283811819901067553,-4.17639883047848521271,-3.850437668366106474864,-3.528766681491085761193,-3.210836082528293830418,-2.89616239045714748026,-2.584315051873627521821,-2.274906037541697572368,-1.967581597392067095654,-1.662015602658996821714,-1.357904066244222484384,-1.054960541873898933872,-0.7529121774748870925153,-0.4514962498062427320625,-0.150457042920862972965,0.150457042920862972965,0.451496249806242732062,0.752912177474887092515,1.054960541873898933872,1.357904066244222484384,1.662015602658996821714,1.967581597392067095654,2.274906037541697572368,2.584315051873627521821,2.896162390457147480258,3.210836082528293830418,3.52876668149108576119,3.85043766836610647486,4.176398830478485212713,4.507283811819901067553,4.84383363458198747074,5.186928979592889550535,5.537635692403301331704,5.897270957641121499901,6.2675031293697518237,6.650509178566492985164,7.04923709867837791084,7.467875283483621332888,7.912775297812494749828,8.39452562332720216575,8.93368833209619334348,9.58416554752346979315)
##Gaussian Quadratureqz <- unique(politeness$gender)mu ? ? ? ? ? ?= 192.53sdx1 ? ? ? ? ?= 54.43sdx2 ? ? ? ? ?= 13.4sdx3 ? ? ? ? ?= 35.06loop ? ? ? ? ?= 0;f_likelihood ?= 0;obs_used ? ? ?= 0;loop ? ? ? ? ?= 0;qpoints ? ? ? = 54;for (obs in 1:2){ level_1 = qz[obs] xl ? ? ?= subset(politeness,politeness$gender == level_1); lev2unique = unique(politeness$scenario)
 total_integral= 0;  for (simulation2 in 1:qpoints){  xx1=quadrature_points[simulation2] likelihood=numeric(length(lev2unique)) for (simulation1 in 1:qpoints){  for(j in 1:length(lev2unique)){ x ? = subset(xl,xl$scenario == lev2unique[j]); integral ?= 1;  xx2=quadrature_points[simulation1] for (i in 1:nrow(x)){ integral = integral * dnorm(x$frequency[i]-mu-(sqrt(2)*sdx1*xx1)-(sqrt(2)*sdx2*xx2),0,sdx3); } likelihood[j] = likelihood[j] + quadrature_weights[simulation1]*integral/sqrt(pi); } } multiplic=1; for (m in 1:length(likelihood)){ multiplic = multiplic * (likelihood[m]); } total_integral ?= total_integral + quadrature_weights[simulation2]*multiplic /sqrt(pi); } f_likelihood = f_likelihood + log(total_integral); }print(f_likelihood)?
	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Fri Dec 12 09:54:11 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 12 Dec 2014 08:54:11 +0000
Subject: [R-sig-ME] lme with a known correlation matrix for the
	random	effects
In-Reply-To: <878C7D3D-CB94-4BDE-8F9A-37B80E79E693@gmail.com>
References: <878C7D3D-CB94-4BDE-8F9A-37B80E79E693@gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3C8656F@inbomail.inbo.be>

Dear Mitov,

The nlme package allows only for correlated residuals within the lowest level of random effects. If you have the patient id as random effect, then only the correlation of the residuals within each patient can be modeled (or set to a predefined value with fixed = TRUE). Residuals among patients are assumed to be independent.

The INLA packages allows for correlated random effects.

Best regards

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Mitov Venelin
Verzonden: donderdag 11 december 2014 22:26
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] lme with a known correlation matrix for the random effects

Dear R-sig mailing list,

Currently, I'm trying to use the function lme from the nlme package to model epidemiological data. My question seems to be a specific one and I couldn't find any similar model formulation using the lme function. That's why I'm writing you.

The data I have is as follows:

1. y: a numeric response vector consisting of one phenotype measurement for each of N patients.

2. A known known correlation matrix, Psi, between the patients.

I would like to model this data as a linear mixed effects model as follows:

y_i = beta + g_i + e_i,

i=1,...,N

Here are the model assumptions:

beta is a fixed population grand-mean (i.e. intercept);

g_i is the pathogen-specific contribution to y_i and is considered as a random effect that is correlated along patients (explained in more detail below);

e_i is a patient-specific random effect including the effects of patient's immune system, any possible interaction between the patient's immune system and the pathogen, and measurement error for y_i.

In matrix-notation the model can be written as follows

y = 1*beta + I_NxN*g + I_NxN*e

In the formula above 1 denotes a N-dimensional vector of ones, I_NxN denotes the NxN identity matrix.
The random N-dimensional vector g is assumed to be normally distributed with mean 0 and a known correlation matrix, Psi.
The random N-dimensional vector e is assumed to be normally distributed with mean 0 and and identity correlation matrix I_NxN.

The model has three parameters:
- beta;
- sigma_g, such that covariance matrix of g is equal to Psi*sigma_g^2 (Psi is known and fixed);
- sigma_e such that the covariance matrix of e is I_NxN*sigma_e^2;

Note that in the lme terminology each of the patients represents a group by itself and there is 1 observation per group.
I'm able to fit the model using maximum likelihood, but I'm trying to use the lme function mostly because of its REML fitting method.

So far, I've tried to use the lme function but I'm getting errors and I don't know how to formulate my model in the lme syntax.

N=5
y <- c(7.38, 7.25, 7.34, 7.30, 7.06)
names(y) <- c("t4", "t2", "t5", "t1", "t3") g <- factor(names(y)) data <- data.frame(y=y, g=g)

Psi <- matrix(c(1, 0.00, 0.00, 0.00, 0.00,
                0, 1.00, 0.28, 0.25, 0.78,
                0, 0.28, 1.00, 0.83, 0.26,
                0, 0.25, 0.83, 1.00, 0.23,
                0, 0.78, 0.26, 0.23, 1.00), nrow=N, ncol=N)
rownames(Psi)<-colnames(Psi)<-names(y)

pdMatPsi <- pdMat(Psi, form=~1|g, pdClass='pdSymm') # Not sure if the formula is correct and if pdSymm is the right pdMat class to use.


> lme(y~1, data, random=pdMatPsi)
Error in getGroups.data.frame(dataMix, groups) :
  invalid formula for groups

For this error I guess the problem is that lme tries to look for a formula in the data.frame data which, as I've read in a vignette, is normally used only for plotting the data, so I'd rather keep the data.frame and not extend it to a groupedData.

> lme(y~1, data, random=list(g=pdMatPsi))
Error in matrix(unlist(value), nrow = nrow(data), dimnames = list(row.names(data),  :
  length of 'dimnames' [2] not equal to array extent In addition: Warning message:
In Ops.factor(1, g) : | not meaningful for factors

Here I don't understand what am I doing wrong. I've tried other formulas in the call to pdMat but I'm still getting errors.
Is it possible to use lme to fit the above model to the data? Also, is it possible to use the more recent lme4 package as it is supposed to be much faster?

Thank you and best regards,
MV
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From scoyoc at gmail.com  Fri Dec 12 18:23:04 2014
From: scoyoc at gmail.com (Matthew Van Scoyoc)
Date: Fri, 12 Dec 2014 10:23:04 -0700
Subject: [R-sig-ME] How do I interpret linear mixed model contrast estimates
	from multcomp::glht()?
Message-ID: <CALx9ERUt6vnNPczCTdLq=KR_FxS0C_-KFA+0yMTkFvbzkKDkkg@mail.gmail.com>

How do the rows in the summary (e.g. "1 == 0") correspond to the model? The
answer is buried *contrast::contrast()*, but I can't figure it out.
Consider this modified example I stole from here
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003061.html>...

> options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
> library("mlmRev")
> library("lme4")
> library("lmerTest")
> library("contrast")
> library("multcomp")
>
> data("egsingle")
> # Linear mixed model
> math.lmm <- lmer(math ~ year * size + female + (1|childid) +
(1|schoolid), egsingle)
> # Linear model
> math.lm <- lm(math ~ year * size + female, data = egsingle)
> # Calculate contrast matrix
> cc<-contrast(math.lm, a = list(year = c(0.5, 1.5, 2.5), size = 380,
female = levels(egsingle$female)), +
                                                b = list(year = c(0.5, 1.5,
2.5), size = 800, female = levels(egsingle$female)))
> # Calculate estimates
> summary(glht(math.lmm, linfct = cc$X))

 Simultaneous Tests for General Linear Hypotheses

Fit: lme4::lmer(formula = math ~ year * size + female + (1 | childid) +
    (1 | schoolid), data = egsingle)

Linear Hypotheses:
              Estimate   Std. Error   z value   Pr(>|z|)
1 == 0  0.12774    0.08020     1.593     0.1272
2 == 0  0.15322    0.08066     1.900    0.0669 .
3 == 0  0.17870    0.08178     2.185    0.0341 *
4 == 0  0.12774    0.08020     1.593    0.1273
5 == 0  0.15322    0.08066     1.900    0.0669 .
6 == 0  0.17870    0.08178     2.185    0.0342 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
(Adjusted p values reported -- single-step method)

The row names correspond to the levels of *year* and *female,* and are
probably Female:0.5, Female:1.5, Female:2.5, and so on. But how do I pull
that out of the contrast() object *cc?* It might be simple with 3 main
effects, but my current project has 5 main effects, four 2-way
interactions, and one 3-way interaction, and the summary table has 24 rows.
Ultimately I would like to create a dataframe so I can plot the contrasts,
something like this...

> x = summary(glht(math.lmm, linfct = cc$X))
> # Contrast data frame
> math.contr = data.frame(Effect.Interaction = reference.something.in.cc,
                                                    Estimate =
x[["test"]]$coefficients, Std.Error = x[["test"]]$sigma)

Thanks for the help!
Cheers,
MVS
=====
Matthew Van Scoyoc

<https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=mvanscoyoc at aggiemail.usu.edu>
https://sites.google.com/site/scoyoc/
=====
Think SNOW!

	[[alternative HTML version deleted]]


From s.smith.7 at research.gla.ac.uk  Mon Dec 15 18:03:28 2014
From: s.smith.7 at research.gla.ac.uk (Shona Smith)
Date: Mon, 15 Dec 2014 17:03:28 +0000
Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DCA27C28F@UM-MAIL4112.unimaas.nl>
References: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C088@UM-MAIL4112.unimaas.nl>
	<A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D66@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C1C9@UM-MAIL4112.unimaas.nl>
	<A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D67@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C28F@UM-MAIL4112.unimaas.nl>
Message-ID: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C08778DA3B3E8@CMS04.campus.gla.ac.uk>

Dear Wolfgang,

Sorry to contact you again after so long, I had completed one part of my meta-analysis and moved on to writing another chapter of my thesis.  Now that I begin the second part of my meta-analysis I have come across a problem.  For the response variable I can either use the absolute change in growth (whether studies increased or decreased growth) or I can use the growth change relative to oxidative stress (this was positive if both growth and oxidative stress were increased/decreased; but negative if they changed in opposite directions).  Ideally I'd like to use the latter but when I do so, the profile plot for rho is flat (it looks fine for the abolute values).  The only difference between the two are the signs and when plotting the data as histograms, both show a similar spread.  Oddly, if I split the data into 3 groups based on the marker of oxidative stress, the plots look better too.

Any ideas as to why this might be happening are extremely welcome.

Kind regards,
Shona

Shona Smith
PhD Researcher

Room 321
Institute of Biodiversity, Animal Health and Comparative Medicine
Graham Kerr Building
University of Glasgow
Glasgow G12 8QQ
________________________________________
From: Viechtbauer Wolfgang (STAT) [wolfgang.viechtbauer at maastrichtuniversity.nl]
Sent: 03 September 2014 18:40
To: Shona Smith; r-sig-mixed-models at r-project.org
Subject: RE: Post model fitting checks in Metafor (rma.mv)

By default (check options("contrasts")), R should use treatment contrasts (see help(contr.treatment)). So, one level of each factor is chosen as the reference level and you get coefficients that indicate the contrasts with this reference level. So, if you use 'mods = ~ Age + Treatment + Biomarker' and Age has 3 levels, Treatment has 5 levels, and Biomarker has 3 levels, then you should get 2+4+2=8 coefficients. So:

predict(res, newmods=c(1,0, 0,0,0,0, 0,0))

would give you the predicted effect for the second level of Age, reference level for Treatment, and reference level for Biomarker. And

predict(res, newmods=c(0,1, 0,0,1,0, 1,0))

would be for the third level of Age, fourth level of Treatment, and second level of Biomarker. And so on ...

You may also want to take a look at this tutorial:

http://www.metafor-project.org/doku.php/tips:testing_factors_lincoms

It doesn't cover multiple factors (I'll add one to the website soon), but should help to clarify things a bit. Also, some things won't work for 'rma.mv' models at this point (e.g., the anova() function or permutation tests). But you can use predict(), linearHypothesis() from the 'car' package, and glht() from the 'multcomp' package.

Best,
Wolfgang

> -----Original Message-----
> From: Shona Smith [mailto:s.smith.7 at research.gla.ac.uk]
> Sent: Wednesday, September 03, 2014 19:24
> To: Viechtbauer Wolfgang (STAT); r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
>
> Hi Wolfgang,
>
> This definitely makes sense thanks - to look at an 'overall effect'
> without the moderators sort of defeats the purpose of putting them there
> in the first place.  I was able to download your paper so I can have a
> wee look at that too, thanks.  I think I shall stick with extracting
> predicted values for specific levels of moderators.  I tried the predict
> function and realise I need to code the factor levels myself, but am a
> little confused about how to do so.  To see how the factors were coded in
> the model, I used:
>
> predict(res, addx=TRUE)
>
> Then I know I can use 'newmods' to put in the codes for the factor levels
> I would like a predicted value for.  There were a lot of '1's and '0's
> (one for each observation and level of factor) so how can I use this to
> code my factor levels?
>
> As for the profile plot for sigma2, I suppose it peaks at ~0.05 but it is
> just a straight line, declining from an REML value of ~ -71 (at Sigma2 =
> ~0.05) to an REML value of ~ -72.5 (at Sigma2 = 1).
>
> Of course missing values were the problem with the residual against
> fitted plot, it was silly of me to miss this.  Thanks!
>
> Kind regards,
> Shona
>
>
> Shona Smith
> PhD Researcher
>
> Room 321
> Institute of Biodiversity, Animal Health and Comparative Medicine
> Graham Kerr Building
> University of Glasgow
> Glasgow G12 8QQ
> ________________________________________
> From: Viechtbauer Wolfgang (STAT)
> [wolfgang.viechtbauer at maastrichtuniversity.nl]
> Sent: 03 September 2014 14:32
> To: Shona Smith; r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
>
> Regarding the profile plot for sigma2: I am not quite sure I understand.
> Does it 'peak' at zero? So, is the estimate (essentially) zero then? That
> would be okay (essentially means that the variability due to 'Study' is
> no larger than what would be expected due to the other variance
> components and/or sampling variability). The issue of zero variance
> components was also recently (and also in past) discussed on this list
> (not with respect to meta-analysis, but it's the same issue).
>
> Regarding the resid-fitted plot: So, looks like you have some missings,
> so the two vectors end up being of different length. This should do it:
>
> options(na.action = "na.pass")
> plot(fitted(res), rstandard(res)$z, pch=19)
>
> Also explained here: http://www.metafor-
> project.org/doku.php/tips:handling_missing_data
>
> Regarding overall effects: I personally don't think an 'overall' effect
> makes much sense when the effect size appears to be related to a number
> of moderators/covariates. Take the simplest situation, where the true
> effect is of size theta_1 for level 1 of a dichotomous covariate and
> theta_2 for level 2. Now suppose we ignore that covariate and fit a
> random-effects model. Essentially, that is a misfitted model, because the
> model assumes normally distributed true effects (and not two point
> massess). Also, where the 'average' effect then falls depends on how many
> studies in the sample are at level 1 and at level 2 of that covariate.
> That doesn't seem that sensible to me. So, instead, we can fit the model
> with the covariate and then compute predicted values, for example, for
> level 1 or level 2. Or, if you really want an 'overall' effect, we could
> use a sort of 'lsmeans' approach and say: Let's assume that in the
> population of studies, 50% are at level 1 and 50% at level 2, so let's
> compute the predicted effect for such a population (essentially fill in
> 0.5 for the 'dummy' variable when computing the predicted value). But I
> would then describe explicitly that this is what was done (as it makes
> clear what the assumption is about the population of studies).
>
> I discuss this issue a bit in this article:
>
> Viechtbauer, W. (2007). Accounting for heterogeneity via random-effects
> models and moderator analyses in meta-analysis. Zeitschrift f?r
> Psychologie / Journal of Psychology, 215(2), 104-121.
>
> (not the 'lsmeans' idea, but the problem of fitting random-effects models
> when there is a relevant moderators/covariate). If you can't access the
> article, let me know and I'll send you a copy if you are interested.
>
> Best,
> Wolfgang
>
> > -----Original Message-----
> > From: Shona Smith [mailto:s.smith.7 at research.gla.ac.uk]
> > Sent: Wednesday, September 03, 2014 13:39
> > To: Viechtbauer Wolfgang (STAT); r-sig-mixed-models at r-project.org
> > Subject: RE: Post model fitting checks in Metafor (rma.mv)
> >
> > Hi Wolfgang,
> >
> > Thanks for such a useful and quick reply.  The sigma2 profile plot does
> > not have a peak - but it's not flat, it seems to just decline (even
> when
> > I expand the x axis values) - I wondered what this meant?  The other
> two
> > look fine, although tau2 drops off much more gradually than rho (which
> is
> > quite a steep drop) after the parameter estimate.  What would be the
> > ideal plot?
> >
> > I can now plot the standardised residuals but fitted against residuals
> > gives me an error:
> >
> > plot(fitted(res), rstandard(res)$z, pch=19)
> > Error in xy.coords(x, y, xlabel, ylabel, log) :
> >   'x' and 'y' lengths differ
> >
> > The fitted values seem to have the row number alongside each value,
> > whiles the standardised residuals don't - so perhaps this is the
> problem?
> >
> > Finally, I also wondered if it is possible to get an overall effect
> size
> > estimate for my response variable?  I notice other studies have carried
> > out a separate meta-analysis to obtain this, before looking at
> > moderators, but I wasn't sure if this was correct.
> >
> > Thanks again,
> > Shona
> >
> >
> > Shona Smith
> > PhD Researcher
> >
> > Room 321
> > Institute of Biodiversity, Animal Health and Comparative Medicine
> > Graham Kerr Building
> > University of Glasgow
> > Glasgow G12 8QQ
> > ________________________________________
> > From: Viechtbauer Wolfgang (STAT)
> > [wolfgang.viechtbauer at maastrichtuniversity.nl]
> > Sent: 03 September 2014 10:28
> > To: Shona Smith; r-sig-mixed-models at r-project.org
> > Subject: RE: Post model fitting checks in Metafor (rma.mv)
> >
> > Dear Shona,
> >
> > The profile() function in metafor allows you to examine the profiled
> > (restricted) log-likelihood for a particular parameter. So, ideally,
> you
> > should do this for each variance component and correlation in the model
> > (in your case, sigma2, tau2 and rho). I am not sure what you mean by: "
> > how I know which value to specify for each?" After you have fitted your
> > model and stored the results in, let's say, 'res', then just do:
> >
> > par(mfrow=c(3,1))
> > profile(res, sigma2=1)
> > profile(res, tau2=1)
> > profile(res, rho=1)
> >
> > to get all three profile plots. And yes, the functions should peak at
> the
> > parameter estimates. If a function is flat, then this suggests that the
> > model is overparameterized.
> >
> > You could also look at how quickly the log-likelihood drops off as you
> > move away from the parameter estimate. The bounds of a 95% profile
> > likelihood CI for a particular parameter would be those two values from
> > the x-axis where the log-likelihood has dropped by 3.84/2. You could
> add
> >
> > abline(h = logLik(res) - qchisq(.95, df=1)/2, lty="dotted")
> >
> > to the figures to see that cutoff. Depending on how much data you have,
> > you may find that those CIs are quite wide. You may have to increase
> the
> > x-axis range, in case the cutoff isn't reached within the range chosen
> by
> > default by the profile function (use the 'xlim' argument).
> >
> > Indeed, you could also look at the (standardized) residuals. Use
> >
> > rstandard(res)$z
> >
> > to get those values. Or:
> >
> > plot(fitted(res), rstandard(res)$z, pch=19)
> >
> > to create a fitted values versus standardized residuals plot.
> >
> > As for the interpretation of the results when you exclude the intercept
> > (i.e., mods = ~ Age + Treatment + Biomarker - 1), you will get the
> > estimated (average) effect for each level of 'Age', but the
> coefficients
> > for 'Treatment' and 'Biomarker' are still going to be contrasts that
> > indicate how much higher/lower the (average) effect is for the levels
> > indicated, relative to the reference level.
> >
> > I hope this helps!
> >
> > Best,
> > Wolfgang
> >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > > models-bounces at r-project.org] On Behalf Of Shona Smith
> > > Sent: Tuesday, September 02, 2014 18:37
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
> > >
> > > Hi all,
> > >
> > > I am currently conducting a meta-analysis using rma.mv in metafor.
> My
> > > model uses Hedges' d (converted to g) and includes 3 moderators (age-
> 3
> > > levels; treatment-5 levels; biomarker-3 levels).  I have included 3
> > > random effects: species nested within taxonomic class (since I have
> > more
> > > than one study for some species, and species are spread over 7
> > taxonomic
> > > classes) and study separately.  So my code is as follows:
> > >
> > > rma.mv(yi, vi, mods = ~ Age + Treatment + Biomarker, random = list(~
> 1
> > |
> > > Study, ~ Species | Taxonomic.class), data=mydata)
> > >
> > > I was wondering what the best method for post model fitting checks
> was
> > in
> > > rma.mv?  I know in the reference manual it mentions profile.rma to
> > create
> > > a plot of the restricted log likelihood and I have done so.  However,
> I
> > > wondered if I need to plot all 3 variables (sigma2, tau2 and rho) and
> > > also how I know which value to specify for each?  Am I correct in
> that
> > I
> > > should see a clear peak in each graph?  Is there anything else I
> should
> > > be looking for?
> > >
> > > For post model fitting checks should I also look at residual
> normality
> > > and residual against fitted values, as would be done for a typical
> > mixed
> > > model?  I think the standardised residuals are best for this - I can
> > get
> > > them with rstandard.rma.mv, but it does not allow me to plot them.
> > >
> > > Finally, when I include the intercept in the model, I can see if
> there
> > > are significant differences among moderator levels.  However, I was
> > > wondering what the output includes when the intercept is not
> included:
> > is
> > > this the overall effect size estimates for each moderator level?
> > >
> > > Kind regards,
> > > Shona
> > >
> > >
> > > Shona Smith
> > > PhD Student
> > >
> > > Room 321
> > > Institute of Biodiversity, Animal Health and Comparative Medicine
> > > Graham Kerr Building
> > > University of Glasgow
> > > Glasgow G12 8QQ
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Thierry.ONKELINX at inbo.be  Tue Dec 16 09:28:02 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 16 Dec 2014 08:28:02 +0000
Subject: [R-sig-ME] How do I interpret linear mixed model contrast
 estimates	from multcomp::glht()?
In-Reply-To: <CALx9ERUt6vnNPczCTdLq=KR_FxS0C_-KFA+0yMTkFvbzkKDkkg@mail.gmail.com>
References: <CALx9ERUt6vnNPczCTdLq=KR_FxS0C_-KFA+0yMTkFvbzkKDkkg@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3C8BCC6@inbomail.inbo.be>

Matthew,

Just reposting exactly the same question on a other list is not very polite. I answered it on r-sig-ecology http://r-sig-ecology.471788.n2.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-td7579236.html#a7579237 If the answer is not clear enough, then let us know what you don't understand about it. Have you look at the examples in ?glht

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Matthew Van Scoyoc
Verzonden: vrijdag 12 december 2014 18:23
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] How do I interpret linear mixed model contrast estimates from multcomp::glht()?

How do the rows in the summary (e.g. "1 == 0") correspond to the model? The answer is buried *contrast::contrast()*, but I can't figure it out.
Consider this modified example I stole from here <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003061.html>...

> options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
> library("mlmRev")
> library("lme4")
> library("lmerTest")
> library("contrast")
> library("multcomp")
>
> data("egsingle")
> # Linear mixed model
> math.lmm <- lmer(math ~ year * size + female + (1|childid) +
(1|schoolid), egsingle)
> # Linear model
> math.lm <- lm(math ~ year * size + female, data = egsingle) #
> Calculate contrast matrix cc<-contrast(math.lm, a = list(year = c(0.5,
> 1.5, 2.5), size = 380,
female = levels(egsingle$female)), +
                                                b = list(year = c(0.5, 1.5, 2.5), size = 800, female = levels(egsingle$female)))
> # Calculate estimates
> summary(glht(math.lmm, linfct = cc$X))

 Simultaneous Tests for General Linear Hypotheses

Fit: lme4::lmer(formula = math ~ year * size + female + (1 | childid) +
    (1 | schoolid), data = egsingle)

Linear Hypotheses:
              Estimate   Std. Error   z value   Pr(>|z|)
1 == 0  0.12774    0.08020     1.593     0.1272
2 == 0  0.15322    0.08066     1.900    0.0669 .
3 == 0  0.17870    0.08178     2.185    0.0341 *
4 == 0  0.12774    0.08020     1.593    0.1273
5 == 0  0.15322    0.08066     1.900    0.0669 .
6 == 0  0.17870    0.08178     2.185    0.0342 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 (Adjusted p values reported -- single-step method)

The row names correspond to the levels of *year* and *female,* and are probably Female:0.5, Female:1.5, Female:2.5, and so on. But how do I pull that out of the contrast() object *cc?* It might be simple with 3 main effects, but my current project has 5 main effects, four 2-way interactions, and one 3-way interaction, and the summary table has 24 rows.
Ultimately I would like to create a dataframe so I can plot the contrasts, something like this...

> x = summary(glht(math.lmm, linfct = cc$X)) # Contrast data frame
> math.contr = data.frame(Effect.Interaction =
> reference.something.in.cc,
                                                    Estimate = x[["test"]]$coefficients, Std.Error = x[["test"]]$sigma)

Thanks for the help!
Cheers,
MVS
=====
Matthew Van Scoyoc

<https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=mvanscoyoc at aggiemail.usu.edu>
https://sites.google.com/site/scoyoc/
=====
Think SNOW!

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

From scoyoc at gmail.com  Tue Dec 16 17:28:29 2014
From: scoyoc at gmail.com (Matthew Van Scoyoc)
Date: Tue, 16 Dec 2014 09:28:29 -0700
Subject: [R-sig-ME] How do I interpret linear mixed model contrast
 estimates from multcomp::glht()?
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3C8BCC6@inbomail.inbo.be>
References: <CALx9ERUt6vnNPczCTdLq=KR_FxS0C_-KFA+0yMTkFvbzkKDkkg@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3C8BCC6@inbomail.inbo.be>
Message-ID: <CALx9ERUYQV++pjrgwfdEkSr9KJVe1YXbfQLXNj0drZrHNK+Odg@mail.gmail.com>

Sorry, I meant no disrespect. I just thought that by posting the question
on a more appropriate list, someone who has come across the same problem
would answer. The problem is actually with contrast::contrast(). The
function does not produce row names that correspond to the fixed effects or
the interactions in the model. So how do I figure out which row corresponds
to what, and  how do I pull that out of the contrast() object *cc?*

MVS
=====
Matthew Van Scoyoc

<mvanscoyoc at aggiemail.usu.edu>https://sites.google.com/site/scoyoc/
=====
Think SNOW!

On Tue, Dec 16, 2014 at 1:28 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be
> wrote:
>
> Matthew,
>
> Just reposting exactly the same question on a other list is not very
> polite. I answered it on r-sig-ecology
> http://r-sig-ecology.471788.n2.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-td7579236.html#a7579237
> If the answer is not clear enough, then let us know what you don't
> understand about it. Have you look at the examples in ?glht
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> Namens Matthew Van Scoyoc
> Verzonden: vrijdag 12 december 2014 18:23
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] How do I interpret linear mixed model contrast
> estimates from multcomp::glht()?
>
> How do the rows in the summary (e.g. "1 == 0") correspond to the model?
> The answer is buried *contrast::contrast()*, but I can't figure it out.
> Consider this modified example I stole from here <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003061.html>...
>
> > options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
> > library("mlmRev")
> > library("lme4")
> > library("lmerTest")
> > library("contrast")
> > library("multcomp")
> >
> > data("egsingle")
> > # Linear mixed model
> > math.lmm <- lmer(math ~ year * size + female + (1|childid) +
> (1|schoolid), egsingle)
> > # Linear model
> > math.lm <- lm(math ~ year * size + female, data = egsingle) #
> > Calculate contrast matrix cc<-contrast(math.lm, a = list(year = c(0.5,
> > 1.5, 2.5), size = 380,
> female = levels(egsingle$female)), +
>                                                 b = list(year = c(0.5,
> 1.5, 2.5), size = 800, female = levels(egsingle$female)))
> > # Calculate estimates
> > summary(glht(math.lmm, linfct = cc$X))
>
>  Simultaneous Tests for General Linear Hypotheses
>
> Fit: lme4::lmer(formula = math ~ year * size + female + (1 | childid) +
>     (1 | schoolid), data = egsingle)
>
> Linear Hypotheses:
>               Estimate   Std. Error   z value   Pr(>|z|)
> 1 == 0  0.12774    0.08020     1.593     0.1272
> 2 == 0  0.15322    0.08066     1.900    0.0669 .
> 3 == 0  0.17870    0.08178     2.185    0.0341 *
> 4 == 0  0.12774    0.08020     1.593    0.1273
> 5 == 0  0.15322    0.08066     1.900    0.0669 .
> 6 == 0  0.17870    0.08178     2.185    0.0342 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 (Adjusted p
> values reported -- single-step method)
>
> The row names correspond to the levels of *year* and *female,* and are
> probably Female:0.5, Female:1.5, Female:2.5, and so on. But how do I pull
> that out of the contrast() object *cc?* It might be simple with 3 main
> effects, but my current project has 5 main effects, four 2-way
> interactions, and one 3-way interaction, and the summary table has 24 rows.
> Ultimately I would like to create a dataframe so I can plot the contrasts,
> something like this...
>
> > x = summary(glht(math.lmm, linfct = cc$X)) # Contrast data frame
> > math.contr = data.frame(Effect.Interaction =
> > reference.something.in.cc,
>                                                     Estimate =
> x[["test"]]$coefficients, Std.Error = x[["test"]]$sigma)
>
> Thanks for the help!
> Cheers,
> MVS
> =====
> Matthew Van Scoyoc
>
> <
> https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=mvanscoyoc at aggiemail.usu.edu
> >
> https://sites.google.com/site/scoyoc/
> =====
> Think SNOW!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> Disclaimer Bezoek onze website / Visit our website<
> https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Dec 16 20:26:34 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 16 Dec 2014 20:26:34 +0100
Subject: [R-sig-ME] lme with a known correlation matrix for the random
 effects
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F027B64A3@UM-MAIL4112.unimaas.nl>

While this is not a meta-analysis, this model can be easily fitted with the metafor package. So-called phylogenetic meta-analyses require the specification of a known correlation matrix for a random effect term. The same principle can be used here:

library(metafor)

N <- 5
y <- c(7.38, 7.25, 7.34, 7.30, 7.06)
names(y) <- c("t4", "t2", "t5", "t1", "t3")
g <- e <- names(y)
data <- data.frame(y=y, g=g, e=e)

Psi <- matrix(c(1, 0.00, 0.00, 0.00, 0.00,
                0, 1.00, 0.28, 0.25, 0.78,
                0, 0.28, 1.00, 0.83, 0.26,
                0, 0.25, 0.83, 1.00, 0.23,
                0, 0.78, 0.26, 0.23, 1.00), nrow=N, ncol=N)

rownames(Psi) <-colnames(Psi) <- names(y)

res <- rma.mv(y, V=0, random = list(~ 1 | g, ~ 1 | e), R = list(g = Psi), data=data)
res

Note that you will get two warnings, one about non-positive sampling variances and the other about V being not positive definite. In meta-analyses, you typically have a known var-cov matrix of the sampling variances/covariances of the observed outcomes. Here, I am just setting that part of the model to 0, so it drops out. So you can ignore those warnings. The rest specifies exactly the requested model. Via the 'R' argument, one can specify a known correlation matrix for one (or more) terms. The default is REML estimation, but method="ML" will give you ML estimation.

The results look like this:

Multivariate Meta-Analysis Model (k = 5; method: REML)

Variance Components: 

            estim    sqrt  nlvls  fixed  factor    R
sigma^2.1  0.0135  0.1161      5     no       g  yes
sigma^2.2  0.0059  0.0771      5     no       e   no

Model Results:

estimate       se     zval     pval    ci.lb    ci.ub          
  7.2815   0.0792  91.8996   <.0001   7.1262   7.4368      *** 

---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

So, sigma^2.1 is sigma^2_g and sigma^2.2 is sigma^2_e. To make sure that these are really good estimates of these variance components, one can profile the restricted log likelihood for each component with:

par(mfrow=c(1,2))
profile(res, sigma2=1)
profile(res, sigma2=2)

(this will generate a lot of the same warnings as mentioned above, since the model is being refitted repeatedly and each time the same issue comes up; you can ignore those again)

I hope this helps!

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Mitov Venelin
> Sent: Thursday, December 11, 2014 22:26
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme with a known correlation matrix for the random
> effects
> 
> Dear R-sig mailing list,
> 
> Currently, I'm trying to use the function lme from the nlme package to
> model epidemiological data. My question seems to be a specific one and I
> couldn't find any similar model formulation using the lme function.
> That's why I'm writing you.
> 
> The data I have is as follows:
> 
> 1. y: a numeric response vector consisting of one phenotype measurement
> for each of N patients.
> 
> 2. A known known correlation matrix, Psi, between the patients.
> 
> I would like to model this data as a linear mixed effects model as
> follows:
> 
> y_i = beta + g_i + e_i,
> 
> i=1,...,N
> 
> Here are the model assumptions:
> 
> beta is a fixed population grand-mean (i.e. intercept);
> 
> g_i is the pathogen-specific contribution to y_i and is considered as a
> random effect that is correlated along patients (explained in more detail
> below);
> 
> e_i is a patient-specific random effect including the effects of
> patient's immune system, any possible interaction between the patient's
> immune system and the pathogen, and measurement error for y_i.
> 
> In matrix-notation the model can be written as follows
> 
> y = 1*beta + I_NxN*g + I_NxN*e
> 
> In the formula above 1 denotes a N-dimensional vector of ones, I_NxN
> denotes the NxN identity matrix.
> The random N-dimensional vector g is assumed to be normally distributed
> with mean 0 and a known correlation matrix, Psi.
> The random N-dimensional vector e is assumed to be normally distributed
> with mean 0 and and identity correlation matrix I_NxN.
> 
> The model has three parameters:
> - beta;
> - sigma_g, such that covariance matrix of g is equal to Psi*sigma_g^2
> (Psi is known and fixed);
> - sigma_e such that the covariance matrix of e is I_NxN*sigma_e^2;
> 
> Note that in the lme terminology each of the patients represents a group
> by itself and there is 1 observation per group.
> I'm able to fit the model using maximum likelihood, but I'm trying to use
> the lme function mostly because of its REML fitting method.
> 
> So far, I've tried to use the lme function but I'm getting errors and I
> don't know how to formulate my model in the lme syntax.
> 
> N=5
> y <- c(7.38, 7.25, 7.34, 7.30, 7.06)
> names(y) <- c("t4", "t2", "t5", "t1", "t3")
> g <- factor(names(y))
> data <- data.frame(y=y, g=g)
> 
> Psi <- matrix(c(1, 0.00, 0.00, 0.00, 0.00,
>                 0, 1.00, 0.28, 0.25, 0.78,
>                 0, 0.28, 1.00, 0.83, 0.26,
>                 0, 0.25, 0.83, 1.00, 0.23,
>                 0, 0.78, 0.26, 0.23, 1.00), nrow=N, ncol=N)
> rownames(Psi)<-colnames(Psi)<-names(y)
> 
> pdMatPsi <- pdMat(Psi, form=~1|g, pdClass='pdSymm') # Not sure if the
> formula is correct and if pdSymm is the right pdMat class to use.
> 
> 
> > lme(y~1, data, random=pdMatPsi)
> Error in getGroups.data.frame(dataMix, groups) :
>   invalid formula for groups
> 
> For this error I guess the problem is that lme tries to look for a
> formula in the data.frame data which, as I've read in a vignette, is
> normally used only for plotting the data, so I'd rather keep the
> data.frame and not extend it to a groupedData.
> 
> > lme(y~1, data, random=list(g=pdMatPsi))
> Error in matrix(unlist(value), nrow = nrow(data), dimnames =
> list(row.names(data),  :
>   length of 'dimnames' [2] not equal to array extent
> In addition: Warning message:
> In Ops.factor(1, g) : | not meaningful for factors
> 
> Here I don't understand what am I doing wrong. I've tried other formulas
> in the call to pdMat but I'm still getting errors.
> Is it possible to use lme to fit the above model to the data? Also, is it
> possible to use the more recent lme4 package as it is supposed to be much
> faster?
> 
> Thank you and best regards,
> MV
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ken.beath at mq.edu.au  Tue Dec 16 22:24:03 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 17 Dec 2014 08:24:03 +1100
Subject: [R-sig-ME] How do I interpret linear mixed model contrast
 estimates from multcomp::glht()?
In-Reply-To: <CALx9ERUYQV++pjrgwfdEkSr9KJVe1YXbfQLXNj0drZrHNK+Odg@mail.gmail.com>
References: <CALx9ERUt6vnNPczCTdLq=KR_FxS0C_-KFA+0yMTkFvbzkKDkkg@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3C8BCC6@inbomail.inbo.be>
	<CALx9ERUYQV++pjrgwfdEkSr9KJVe1YXbfQLXNj0drZrHNK+Odg@mail.gmail.com>
Message-ID: <CAF5_5cz_jCJFM_64Q7EYrEYxN-QsqqigdLA1wngHJ+m-C-13Sw@mail.gmail.com>

You first need to work out what contrasts you want to calculate (and
possibly find out what a contrast is). Then find out what the appropriate
contrast matrix is, or the routines that will give you one a predefine one.
Then if you use glht it will probably be fairly easy to interpret what
results it is producing.

On 17 December 2014 at 03:28, Matthew Van Scoyoc <scoyoc at gmail.com> wrote:
>
> Sorry, I meant no disrespect. I just thought that by posting the question
> on a more appropriate list, someone who has come across the same problem
> would answer. The problem is actually with contrast::contrast(). The
> function does not produce row names that correspond to the fixed effects or
> the interactions in the model. So how do I figure out which row corresponds
> to what, and  how do I pull that out of the contrast() object *cc?*
>
> MVS
> =====
> Matthew Van Scoyoc
>
> <mvanscoyoc at aggiemail.usu.edu>https://sites.google.com/site/scoyoc/
> =====
> Think SNOW!
>
> On Tue, Dec 16, 2014 at 1:28 AM, ONKELINX, Thierry <
> Thierry.ONKELINX at inbo.be
> > wrote:
> >
> > Matthew,
> >
> > Just reposting exactly the same question on a other list is not very
> > polite. I answered it on r-sig-ecology
> >
> http://r-sig-ecology.471788.n2.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-td7579236.html#a7579237
> > If the answer is not clear enough, then let us know what you don't
> > understand about it. Have you look at the examples in ?glht
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> > + 32 2 525 02 51
> > + 32 54 43 61 85
> > Thierry.Onkelinx at inbo.be
> > www.inbo.be
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of.
> > ~ Sir Ronald Aylmer Fisher
> >
> > The plural of anecdote is not data.
> > ~ Roger Brinner
> >
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > -----Oorspronkelijk bericht-----
> > Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org
> ]
> > Namens Matthew Van Scoyoc
> > Verzonden: vrijdag 12 december 2014 18:23
> > Aan: r-sig-mixed-models at r-project.org
> > Onderwerp: [R-sig-ME] How do I interpret linear mixed model contrast
> > estimates from multcomp::glht()?
> >
> > How do the rows in the summary (e.g. "1 == 0") correspond to the model?
> > The answer is buried *contrast::contrast()*, but I can't figure it out.
> > Consider this modified example I stole from here <
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003061.html>...
> >
> > > options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
> > > library("mlmRev")
> > > library("lme4")
> > > library("lmerTest")
> > > library("contrast")
> > > library("multcomp")
> > >
> > > data("egsingle")
> > > # Linear mixed model
> > > math.lmm <- lmer(math ~ year * size + female + (1|childid) +
> > (1|schoolid), egsingle)
> > > # Linear model
> > > math.lm <- lm(math ~ year * size + female, data = egsingle) #
> > > Calculate contrast matrix cc<-contrast(math.lm, a = list(year = c(0.5,
> > > 1.5, 2.5), size = 380,
> > female = levels(egsingle$female)), +
> >                                                 b = list(year = c(0.5,
> > 1.5, 2.5), size = 800, female = levels(egsingle$female)))
> > > # Calculate estimates
> > > summary(glht(math.lmm, linfct = cc$X))
> >
> >  Simultaneous Tests for General Linear Hypotheses
> >
> > Fit: lme4::lmer(formula = math ~ year * size + female + (1 | childid) +
> >     (1 | schoolid), data = egsingle)
> >
> > Linear Hypotheses:
> >               Estimate   Std. Error   z value   Pr(>|z|)
> > 1 == 0  0.12774    0.08020     1.593     0.1272
> > 2 == 0  0.15322    0.08066     1.900    0.0669 .
> > 3 == 0  0.17870    0.08178     2.185    0.0341 *
> > 4 == 0  0.12774    0.08020     1.593    0.1273
> > 5 == 0  0.15322    0.08066     1.900    0.0669 .
> > 6 == 0  0.17870    0.08178     2.185    0.0342 *
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 (Adjusted
> p
> > values reported -- single-step method)
> >
> > The row names correspond to the levels of *year* and *female,* and are
> > probably Female:0.5, Female:1.5, Female:2.5, and so on. But how do I pull
> > that out of the contrast() object *cc?* It might be simple with 3 main
> > effects, but my current project has 5 main effects, four 2-way
> > interactions, and one 3-way interaction, and the summary table has 24
> rows.
> > Ultimately I would like to create a dataframe so I can plot the
> contrasts,
> > something like this...
> >
> > > x = summary(glht(math.lmm, linfct = cc$X)) # Contrast data frame
> > > math.contr = data.frame(Effect.Interaction =
> > > reference.something.in.cc,
> >                                                     Estimate =
> > x[["test"]]$coefficients, Std.Error = x[["test"]]$sigma)
> >
> > Thanks for the help!
> > Cheers,
> > MVS
> > =====
> > Matthew Van Scoyoc
> >
> > <
> >
> https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=mvanscoyoc at aggiemail.usu.edu
> > >
> > https://sites.google.com/site/scoyoc/
> > =====
> > Think SNOW!
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > Disclaimer Bezoek onze website / Visit our website<
> > https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From manabu.sakamoto at gmail.com  Tue Dec 16 22:48:44 2014
From: manabu.sakamoto at gmail.com (Manabu Sakamoto)
Date: Tue, 16 Dec 2014 21:48:44 +0000
Subject: [R-sig-ME] Fixing phylogenetic heritability in MCMCglmm
Message-ID: <CAErHMT26X6J=kXCYe8juVEs1E3SQ3ShzA8LyxkeJaXR=23Wf=g@mail.gmail.com>

Dear list,

Does anyone know how to fix the heritability of the phylogenetic random
effect in MCMCglmm in a way that is the equivalent to fixing the
phylogenetic signal lambda to 1?

I want all the variance attributed to phylogeny to remain fixed and
unaffected by additional random effects, i.e., I want the additional random
effects to work on the residual variance once phylogeny is accounted for.

many thanks,
Manabu

-- 
Manabu Sakamoto, PhD
manabu.sakamoto at gmail.com

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Dec 17 01:04:33 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 16 Dec 2014 19:04:33 -0500
Subject: [R-sig-ME] lme4 troubles
In-Reply-To: <908401771FA6A946A26C2A43892795451A83EBD8@CSGMBX204W.pu.win.princeton.edu>
References: <908401771FA6A946A26C2A43892795451A83EBD8@CSGMBX204W.pu.win.princeton.edu>
Message-ID: <5490C891.8020108@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-16 05:49 PM, Andrew C. Shaver wrote:
> Hi Ben!
> 
> I hope this note finds you well.

  [I'm fine, but cc'ing to r-sig-mixed-models at r-project.org]
> 
> I hate to trouble you, but I've having some troubles with the lme4 
> package that I'm hoping you might be able to help me quick
> resolve.
> 
> Using an earlier version of the package, I was running the
> following type of model without problem:
> 
> output <- glmer(Y ~ X + Z + (1 | Province) + (1 | Year), data =
> data, family = "binomial", verbose = TRUE, control =
> list(maxIter=1000))
> 
> I've since upgraded, and attempting to run this model now results
> in the following message:
> 
> Error: PIRLS step failed In addition: Warning message: In 
> checkArgs("glmer", sparseX, ...) : extra argument(s) ?control?, 
> ?verbose? disregarded

  What version of lme4 are you now using (results of sessionInfo(),
or packageVersion("lme4") ?)

  Is there any chance you can provide a reproducible example?
Using one of the built-in examples from lme4 with the latest
(development) version of lme4 (although I think it should be identical
for these purposes to the CRAN version of lme4, 1.1-7):

library("lme4")
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial,
                  verbose=TRUE, control=list(maxIter=1000))

gives

Warning in glmer(cbind(incidence, size - incidence) ~ period + (1 |
herd),  :
  Use control=glmerControl(..) instead of passing a list of class ?list?
Error in (function (optimizer = c("bobyqa", "Nelder_Mead"),
restart_edge = FALSE,  :
  unused argument (maxIter = 1000)

If I use

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial,
                  verbose=TRUE,
                 control=glmerControl(optCtrl=list(maxfun=20000)))

it works (I don't get the specified error) -- but of course it would
be likely to work with this well-behaved example.

> If I run something like: output <- glmer(Y ~ X + Z + (1 | Province)
> + (1 | Year), data = data, family = "binomial"), i get: "Error: 
> pwrssUpdate did not converge in 30 iterations". And if I attempt
> to increase the number of iterations by including 
> "control=glmerControl(optCtrl=list(maxfun=20000)", I get:
> 
> Error in checkArgs("glmer", sparseX, ...) : could not find
> function "glmerControl"

  That's surprising.

  FWIW the max number of PIRLS iterations is hard-coded in the current
version of lme4, although you can adjust the tolerance (tolPwrss).
However, usually when this goes wrong there's some other problem
that has to/can be fixed in another way.  Again, a reproducible example
would be really useful ...

> I am also no longer able to load the "blme" package. Before the 
> update, had no problems running, for instance, bglmer(). Now, when
> I attempt to load the package, I get the following messages:
> 
> Error : class "mer" is not exported by 'namespace:lme4' Error: 
> package/namespace load failed for ?blme?

  I'm a little surprised/confused by this one.
  Make sure you're running a clean R session and (re)install lme4
and blme from scratch?

> Any hints on how to get back to running the model??
> 
> Thank you very much in advance!
> 
> Very best,
> 
> Andrew

> --- Andrew Shaver PhD Candidate Woodrow Wilson School Princeton 
> University scholar.princeton.edu/ashaver ---
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEbBAEBAgAGBQJUkMiRAAoJEOCV5YRblxUH0ooH+Iw/dnfWtjDwO97X8aILcB9E
8rcS1i4QrpN5rAEWa5SnuQDNYNCzduYMxpxMsfUu1uMreTq7hG7axxP0vC4rZJxL
onyg1wGY2JIzvwpjSHm7sEEyokFIz/EGyeruptCTdCGvLDBIVr2bwA0SXa+AGSpk
Ase7quPY6RBra7K4a+OJqsj0IZXqocf+HQIMAqdIfqdaBhsuAMXXAeaCRNbxcdnT
yQlYyHUVDH/uyfeRBhSaQn+wAu7guBYRUjcuyBRYP0bhd1RjSxMov8WkoRpef60S
b0en8Nb03e+cGjQaxpXEZv1hxnsQPPOVUqCC041qIjshi9UppZpxKq47eQij6w==
=Mu75
-----END PGP SIGNATURE-----


From scoyoc at gmail.com  Wed Dec 17 06:24:57 2014
From: scoyoc at gmail.com (Matthew Van Scoyoc)
Date: Tue, 16 Dec 2014 22:24:57 -0700
Subject: [R-sig-ME] How do I interpret linear mixed model contrast
 estimates from multcomp::glht()?
In-Reply-To: <CAF5_5cz_jCJFM_64Q7EYrEYxN-QsqqigdLA1wngHJ+m-C-13Sw@mail.gmail.com>
References: <CALx9ERUt6vnNPczCTdLq=KR_FxS0C_-KFA+0yMTkFvbzkKDkkg@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3C8BCC6@inbomail.inbo.be>
	<CALx9ERUYQV++pjrgwfdEkSr9KJVe1YXbfQLXNj0drZrHNK+Odg@mail.gmail.com>
	<CAF5_5cz_jCJFM_64Q7EYrEYxN-QsqqigdLA1wngHJ+m-C-13Sw@mail.gmail.com>
Message-ID: <CALx9ERU6pvc79a-aZbE8B=rOzn6h650HyftE989Q=CDPq2DUFw@mail.gmail.com>

Thanks Ken and Thierry,

The rows in summary.glht() correspond to the row names of the contrast
matrix given in the linfct argument as Thierry stated in my post on
r-sig-ecology
<http://r-sig-ecology.471788.n2.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-td7579236.html#a7579237>
(thanks
again Thierry). I'm using the contrast function in the contrast package to
help compute the contrast matrix. The contrast function from the contrast
package produces this...

> # Calculate the contrasts
> cc<-contrast(math.lm, a = list(year = c(.5, 1.5, 2.5), size = 380, female
= levels(egsingle$female)),
+                       b = list(year = c(.5, 1.5, 2.5), size = 800, female
= levels(egsingle$female)))
> cc
lm model parameter contrast

  Contrast       S.E.                  Lower            Upper
 t        df      Pr(>|t|)
 0.1671791    0.01739038    0.1330889   0.2012694    9.61  7225        0
 0.2148280   0.02235506   0.1710055    0.2586504    9.61  7225        0
 0.2624768   0.03167964    0.2003754   0.3245781    8.29  7225        0
 0.1671791    0.01739038    0.1330889   0.2012694    9.61  7225        0
 0.2148280   0.02235506   0.1710055    0.2586504    9.61  7225        0
 0.2624768   0.03167964    0.2003754   0.3245781    8.29  7225        0

So, how do the rows of the contrast object relate to the coefficients of
the mixed or linear model? The summary of *math.lm* produces 5 rows of
coefficients...
> summary(math.lm)

Call:
lm(formula = math ~ year * size + female, data = egsingle)

Residuals:
    Min      1Q  Median      3Q     Max
-3.5631 -0.7775 -0.0523  0.7183  5.0195

Coefficients:
                            Estimate      Std. Error    t value
 Pr(>|t|)
(Intercept)       -5.590e-01  3.687e-02   -15.163    < 2e-16 ***
year                    8.521e-01   2.391e-02    35.644    < 2e-16 ***
size                   -3.413e-04   4.251e-05    -8.030    1.13e-15 ***
femaleFemale -2.232e-02  2.576e-02    -0.867     0.38624
year:size           -1.135e-04  2.948e-05    -3.849     0.00012 ***

I keep looking at cc$X (what I'm passing to glht() as the contrast matrix
in the linfct argument), but my brain starts to melt at this point...
> cc$X
  (Intercept) year size femaleFemale year:size
1           0           0  -420            0                -210
2           0           0  -420            0               -630
3           0           0  -420            0               -1050
4           0           0  -420            0               -210
5           0           0  -420            0               -630
6           0           0  -420            0               -1050
attr(,"assign")
[1] 0 1 2 3 4
attr(,"contrasts")
attr(,"contrasts")$female
[1] "contr.SAS"

This is my first try at mixed models, and it's been several years since my
linear regression course that was taught in SAS, so any help is appreciated.

Cheers,


MVS
=====
Matthew Van Scoyoc

<mvanscoyoc at aggiemail.usu.edu>https://sites.google.com/site/scoyoc/
=====
Think SNOW!

On Tue, Dec 16, 2014 at 2:24 PM, Ken Beath <ken.beath at mq.edu.au> wrote:
>
> You first need to work out what contrasts you want to calculate (and
> possibly find out what a contrast is). Then find out what the appropriate
> contrast matrix is, or the routines that will give you one a predefine one.
> Then if you use glht it will probably be fairly easy to interpret what
> results it is producing.
>
> On 17 December 2014 at 03:28, Matthew Van Scoyoc <scoyoc at gmail.com> wrote:
>>
>> Sorry, I meant no disrespect. I just thought that by posting the question
>> on a more appropriate list, someone who has come across the same problem
>> would answer. The problem is actually with contrast::contrast(). The
>> function does not produce row names that correspond to the fixed effects
>> or
>> the interactions in the model. So how do I figure out which row
>> corresponds
>> to what, and  how do I pull that out of the contrast() object *cc?*
>>
>> MVS
>> =====
>> Matthew Van Scoyoc
>>
>> <mvanscoyoc at aggiemail.usu.edu>https://sites.google.com/site/scoyoc/
>> =====
>> Think SNOW!
>>
>> On Tue, Dec 16, 2014 at 1:28 AM, ONKELINX, Thierry <
>> Thierry.ONKELINX at inbo.be
>> > wrote:
>> >
>> > Matthew,
>> >
>> > Just reposting exactly the same question on a other list is not very
>> > polite. I answered it on r-sig-ecology
>> >
>> http://r-sig-ecology.471788.n2.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-td7579236.html#a7579237
>> > If the answer is not clear enough, then let us know what you don't
>> > understand about it. Have you look at the examples in ?glht
>> >
>> > ir. Thierry Onkelinx
>> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and
>> > Forest
>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> > Kliniekstraat 25
>> > 1070 Anderlecht
>> > Belgium
>> > + 32 2 525 02 51
>> > + 32 54 43 61 85
>> > Thierry.Onkelinx at inbo.be
>> > www.inbo.be
>> >
>> > To call in the statistician after the experiment is done may be no more
>> > than asking him to perform a post-mortem examination: he may be able to
>> say
>> > what the experiment died of.
>> > ~ Sir Ronald Aylmer Fisher
>> >
>> > The plural of anecdote is not data.
>> > ~ Roger Brinner
>> >
>> > The combination of some data and an aching desire for an answer does not
>> > ensure that a reasonable answer can be extracted from a given body of
>> data.
>> > ~ John Tukey
>> >
>> > -----Oorspronkelijk bericht-----
>> > Van: R-sig-mixed-models [mailto:
>> r-sig-mixed-models-bounces at r-project.org]
>> > Namens Matthew Van Scoyoc
>> > Verzonden: vrijdag 12 december 2014 18:23
>> > Aan: r-sig-mixed-models at r-project.org
>> > Onderwerp: [R-sig-ME] How do I interpret linear mixed model contrast
>> > estimates from multcomp::glht()?
>> >
>> > How do the rows in the summary (e.g. "1 == 0") correspond to the model?
>> > The answer is buried *contrast::contrast()*, but I can't figure it out.
>> > Consider this modified example I stole from here <
>> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003061.html
>> >...
>> >
>> > > options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
>> > > library("mlmRev")
>> > > library("lme4")
>> > > library("lmerTest")
>> > > library("contrast")
>> > > library("multcomp")
>> > >
>> > > data("egsingle")
>> > > # Linear mixed model
>> > > math.lmm <- lmer(math ~ year * size + female + (1|childid) +
>> > (1|schoolid), egsingle)
>> > > # Linear model
>> > > math.lm <- lm(math ~ year * size + female, data = egsingle) #
>> > > Calculate contrast matrix cc<-contrast(math.lm, a = list(year = c(0.5,
>> > > 1.5, 2.5), size = 380,
>> > female = levels(egsingle$female)), +
>> >                                                 b = list(year = c(0.5,
>> > 1.5, 2.5), size = 800, female = levels(egsingle$female)))
>> > > # Calculate estimates
>> > > summary(glht(math.lmm, linfct = cc$X))
>> >
>> >  Simultaneous Tests for General Linear Hypotheses
>> >
>> > Fit: lme4::lmer(formula = math ~ year * size + female + (1 | childid) +
>> >     (1 | schoolid), data = egsingle)
>> >
>> > Linear Hypotheses:
>> >               Estimate   Std. Error   z value   Pr(>|z|)
>> > 1 == 0  0.12774    0.08020     1.593     0.1272
>> > 2 == 0  0.15322    0.08066     1.900    0.0669 .
>> > 3 == 0  0.17870    0.08178     2.185    0.0341 *
>> > 4 == 0  0.12774    0.08020     1.593    0.1273
>> > 5 == 0  0.15322    0.08066     1.900    0.0669 .
>> > 6 == 0  0.17870    0.08178     2.185    0.0342 *
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> (Adjusted p
>> > values reported -- single-step method)
>> >
>> > The row names correspond to the levels of *year* and *female,* and are
>> > probably Female:0.5, Female:1.5, Female:2.5, and so on. But how do I
>> pull
>> > that out of the contrast() object *cc?* It might be simple with 3 main
>> > effects, but my current project has 5 main effects, four 2-way
>> > interactions, and one 3-way interaction, and the summary table has 24
>> rows.
>> > Ultimately I would like to create a dataframe so I can plot the
>> contrasts,
>> > something like this...
>> >
>> > > x = summary(glht(math.lmm, linfct = cc$X)) # Contrast data frame
>> > > math.contr = data.frame(Effect.Interaction =
>> > > reference.something.in.cc,
>> >                                                     Estimate =
>> > x[["test"]]$coefficients, Std.Error = x[["test"]]$sigma)
>> >
>> > Thanks for the help!
>> > Cheers,
>> > MVS
>> > =====
>> > Matthew Van Scoyoc
>> >
>> > <
>> >
>> https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=mvanscoyoc at aggiemail.usu.edu
>> > >
>> > https://sites.google.com/site/scoyoc/
>> > =====
>> > Think SNOW!
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > Disclaimer Bezoek onze website / Visit our website<
>> > https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:12}}


From Thierry.ONKELINX at inbo.be  Wed Dec 17 10:11:15 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 17 Dec 2014 09:11:15 +0000
Subject: [R-sig-ME] How do I interpret linear mixed model contrast
 estimates from multcomp::glht()?
In-Reply-To: <CALx9ERU6pvc79a-aZbE8B=rOzn6h650HyftE989Q=CDPq2DUFw@mail.gmail.com>
References: <CALx9ERUt6vnNPczCTdLq=KR_FxS0C_-KFA+0yMTkFvbzkKDkkg@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3C8BCC6@inbomail.inbo.be>
	<CALx9ERUYQV++pjrgwfdEkSr9KJVe1YXbfQLXNj0drZrHNK+Odg@mail.gmail.com>
	<CAF5_5cz_jCJFM_64Q7EYrEYxN-QsqqigdLA1wngHJ+m-C-13Sw@mail.gmail.com>
	<CALx9ERU6pvc79a-aZbE8B=rOzn6h650HyftE989Q=CDPq2DUFw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3C8D250@inbomail.inbo.be>

Matthew,

After scanning the helpfile of contrast, I get the feeling that you can vary only one variable and not two like you did. Make sure that you understand what contrast does. I prefer to use glht() directly. You have to specify more complex contrasts yourself, but then you know exactly what contrasts you are comparing.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be<mailto:Thierry.Onkelinx at inbo.be>
www.inbo.be<http://www.inbo.be/>

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

Van: Matthew Van Scoyoc [mailto:scoyoc at gmail.com]
Verzonden: woensdag 17 december 2014 6:25
Aan: Ken Beath
CC: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] How do I interpret linear mixed model contrast estimates from multcomp::glht()?

Thanks Ken and Thierry,

The rows in summary.glht() correspond to the row names of the contrast matrix given in the linfct argument as Thierry stated in my post on r-sig-ecology<http://r-sig-ecology.471788.n2.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-td7579236.html#a7579237> (thanks again Thierry). I'm using the contrast function in the contrast package to help compute the contrast matrix. The contrast function from the contrast package produces this...

> # Calculate the contrasts
> cc<-contrast(math.lm, a = list(year = c(.5, 1.5, 2.5), size = 380, female = levels(egsingle$female)),
+                       b = list(year = c(.5, 1.5, 2.5), size = 800, female = levels(egsingle$female)))
> cc
lm model parameter contrast

  Contrast       S.E.                  Lower            Upper                t        df      Pr(>|t|)
 0.1671791    0.01739038    0.1330889   0.2012694    9.61  7225        0
 0.2148280   0.02235506   0.1710055    0.2586504    9.61  7225        0
 0.2624768   0.03167964    0.2003754   0.3245781    8.29  7225        0
 0.1671791    0.01739038    0.1330889   0.2012694    9.61  7225        0
 0.2148280   0.02235506   0.1710055    0.2586504    9.61  7225        0
 0.2624768   0.03167964    0.2003754   0.3245781    8.29  7225        0

So, how do the rows of the contrast object relate to the coefficients of the mixed or linear model? The summary of math.lm produces 5 rows of coefficients...
> summary(math.lm)

Call:
lm(formula = math ~ year * size + female, data = egsingle)

Residuals:
    Min      1Q  Median      3Q     Max
-3.5631 -0.7775 -0.0523  0.7183  5.0195

Coefficients:
                            Estimate      Std. Error    t value      Pr(>|t|)
(Intercept)       -5.590e-01  3.687e-02   -15.163    < 2e-16 ***
year                    8.521e-01   2.391e-02    35.644    < 2e-16 ***
size                   -3.413e-04   4.251e-05    -8.030    1.13e-15 ***
femaleFemale -2.232e-02  2.576e-02    -0.867     0.38624
year:size           -1.135e-04  2.948e-05    -3.849     0.00012 ***

I keep looking at cc$X (what I'm passing to glht() as the contrast matrix in the linfct argument), but my brain starts to melt at this point...
> cc$X
  (Intercept) year size femaleFemale year:size
1           0           0  -420            0                -210
2           0           0  -420            0               -630
3           0           0  -420            0               -1050
4           0           0  -420            0               -210
5           0           0  -420            0               -630
6           0           0  -420            0               -1050
attr(,"assign")
[1] 0 1 2 3 4
attr(,"contrasts")
attr(,"contrasts")$female
[1] "contr.SAS"

This is my first try at mixed models, and it's been several years since my linear regression course that was taught in SAS, so any help is appreciated.

Cheers,


MVS
=====
Matthew Van Scoyoc

https://sites.google.com/site/scoyoc/
=====
Think SNOW!

On Tue, Dec 16, 2014 at 2:24 PM, Ken Beath <ken.beath at mq.edu.au<mailto:ken.beath at mq.edu.au>> wrote:
You first need to work out what contrasts you want to calculate (and possibly find out what a contrast is). Then find out what the appropriate contrast matrix is, or the routines that will give you one a predefine one. Then if you use glht it will probably be fairly easy to interpret what results it is producing.

On 17 December 2014 at 03:28, Matthew Van Scoyoc <scoyoc at gmail.com<mailto:scoyoc at gmail.com>> wrote:
Sorry, I meant no disrespect. I just thought that by posting the question
on a more appropriate list, someone who has come across the same problem
would answer. The problem is actually with contrast::contrast(). The
function does not produce row names that correspond to the fixed effects or
the interactions in the model. So how do I figure out which row corresponds
to what, and  how do I pull that out of the contrast() object *cc?*

MVS
=====
Matthew Van Scoyoc

<mvanscoyoc at aggiemail.usu.edu<mailto:mvanscoyoc at aggiemail.usu.edu>>https://sites.google.com/site/scoyoc/
=====
Think SNOW!
On Tue, Dec 16, 2014 at 1:28 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be<mailto:Thierry.ONKELINX at inbo.be>
> wrote:
>
> Matthew,
>
> Just reposting exactly the same question on a other list is not very
> polite. I answered it on r-sig-ecology
> http://r-sig-ecology.471788.n2.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-td7579236.html#a7579237
> If the answer is not clear enough, then let us know what you don't
> understand about it. Have you look at the examples in ?glht
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51<tel:%2B%2032%202%20525%2002%2051>
> + 32 54 43 61 85<tel:%2B%2032%2054%2043%2061%2085>
> Thierry.Onkelinx at inbo.be<mailto:Thierry.Onkelinx at inbo.be>
> www.inbo.be<http://www.inbo.be>
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>]
> Namens Matthew Van Scoyoc
> Verzonden: vrijdag 12 december 2014 18:23
> Aan: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Onderwerp: [R-sig-ME] How do I interpret linear mixed model contrast
> estimates from multcomp::glht()?
>
> How do the rows in the summary (e.g. "1 == 0") correspond to the model?
> The answer is buried *contrast::contrast()*, but I can't figure it out.
> Consider this modified example I stole from here <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003061.html>...
>
> > options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
> > library("mlmRev")
> > library("lme4")
> > library("lmerTest")
> > library("contrast")
> > library("multcomp")
> >
> > data("egsingle")
> > # Linear mixed model
> > math.lmm <- lmer(math ~ year * size + female + (1|childid) +
> (1|schoolid), egsingle)
> > # Linear model
> > math.lm <- lm(math ~ year * size + female, data = egsingle) #
> > Calculate contrast matrix cc<-contrast(math.lm, a = list(year = c(0.5,
> > 1.5, 2.5), size = 380,
> female = levels(egsingle$female)), +
>                                                 b = list(year = c(0.5,
> 1.5, 2.5), size = 800, female = levels(egsingle$female)))
> > # Calculate estimates
> > summary(glht(math.lmm, linfct = cc$X))
>
>  Simultaneous Tests for General Linear Hypotheses
>
> Fit: lme4::lmer(formula = math ~ year * size + female + (1 | childid) +
>     (1 | schoolid), data = egsingle)
>
> Linear Hypotheses:
>               Estimate   Std. Error   z value   Pr(>|z|)
> 1 == 0  0.12774    0.08020     1.593     0.1272
> 2 == 0  0.15322    0.08066     1.900    0.0669 .
> 3 == 0  0.17870    0.08178     2.185    0.0341 *
> 4 == 0  0.12774    0.08020     1.593    0.1273
> 5 == 0  0.15322    0.08066     1.900    0.0669 .
> 6 == 0  0.17870    0.08178     2.185    0.0342 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 (Adjusted p
> values reported -- single-step method)
>
> The row names correspond to the levels of *year* and *female,* and are
> probably Female:0.5, Female:1.5, Female:2.5, and so on. But how do I pull
> that out of the contrast() object *cc?* It might be simple with 3 main
> effects, but my current project has 5 main effects, four 2-way
> interactions, and one 3-way interaction, and the summary table has 24 rows.
> Ultimately I would like to create a dataframe so I can plot the contrasts,
> something like this...
>
> > x = summary(glht(math.lmm, linfct = cc$X)) # Contrast data frame
> > math.contr = data.frame(Effect.Interaction =
> > reference.something.in.cc<http://reference.something.in.cc>,
>                                                     Estimate =
> x[["test"]]$coefficients, Std.Error = x[["test"]]$sigma)
>
> Thanks for the help!
> Cheers,
> MVS
> =====
> Matthew Van Scoyoc
>
> <
> https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=mvanscoyoc at aggiemail.usu.edu
> >
> https://sites.google.com/site/scoyoc/
> =====
> Think SNOW!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> Disclaimer Bezoek onze website / Visit our website<
> https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--

Ken Beath
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may contain confidential information.  If you are not the intended recipient, please delete it and notify the sender.  Views expressed in this message are those of the individual sender, and are not necessarily the views of the Faculty of Science, Department of Statistics or Macquarie University.

Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

	[[alternative HTML version deleted]]


From vmitov at gmail.com  Wed Dec 17 12:07:05 2014
From: vmitov at gmail.com (Vmitov@gmail.com)
Date: Wed, 17 Dec 2014 13:07:05 +0200
Subject: [R-sig-ME] lme with a known correlation matrix for the random
	effects
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3C8656F@inbomail.inbo.be>
References: <878C7D3D-CB94-4BDE-8F9A-37B80E79E693@gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3C8656F@inbomail.inbo.be>
Message-ID: <E32AAE6E-A13F-46E4-A0C2-4CCE0A502597@gmail.com>

Dear Thierry,

Thanks a lot for letting me know this!

Venelin

> On 12.12.2014, at 10:54, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> 
> Dear Mitov,
> 
> The nlme package allows only for correlated residuals within the lowest level of random effects. If you have the patient id as random effect, then only the correlation of the residuals within each patient can be modeled (or set to a predefined value with fixed = TRUE). Residuals among patients are assumed to be independent.
> 
> The INLA packages allows for correlated random effects.
> 
> Best regards
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 
> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Mitov Venelin
> Verzonden: donderdag 11 december 2014 22:26
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] lme with a known correlation matrix for the random effects
> 
> Dear R-sig mailing list,
> 
> Currently, I'm trying to use the function lme from the nlme package to model epidemiological data. My question seems to be a specific one and I couldn't find any similar model formulation using the lme function. That's why I'm writing you.
> 
> The data I have is as follows:
> 
> 1. y: a numeric response vector consisting of one phenotype measurement for each of N patients.
> 
> 2. A known known correlation matrix, Psi, between the patients.
> 
> I would like to model this data as a linear mixed effects model as follows:
> 
> y_i = beta + g_i + e_i,
> 
> i=1,...,N
> 
> Here are the model assumptions:
> 
> beta is a fixed population grand-mean (i.e. intercept);
> 
> g_i is the pathogen-specific contribution to y_i and is considered as a random effect that is correlated along patients (explained in more detail below);
> 
> e_i is a patient-specific random effect including the effects of patient's immune system, any possible interaction between the patient's immune system and the pathogen, and measurement error for y_i.
> 
> In matrix-notation the model can be written as follows
> 
> y = 1*beta + I_NxN*g + I_NxN*e
> 
> In the formula above 1 denotes a N-dimensional vector of ones, I_NxN denotes the NxN identity matrix.
> The random N-dimensional vector g is assumed to be normally distributed with mean 0 and a known correlation matrix, Psi.
> The random N-dimensional vector e is assumed to be normally distributed with mean 0 and and identity correlation matrix I_NxN.
> 
> The model has three parameters:
> - beta;
> - sigma_g, such that covariance matrix of g is equal to Psi*sigma_g^2 (Psi is known and fixed);
> - sigma_e such that the covariance matrix of e is I_NxN*sigma_e^2;
> 
> Note that in the lme terminology each of the patients represents a group by itself and there is 1 observation per group.
> I'm able to fit the model using maximum likelihood, but I'm trying to use the lme function mostly because of its REML fitting method.
> 
> So far, I've tried to use the lme function but I'm getting errors and I don't know how to formulate my model in the lme syntax.
> 
> N=5
> y <- c(7.38, 7.25, 7.34, 7.30, 7.06)
> names(y) <- c("t4", "t2", "t5", "t1", "t3") g <- factor(names(y)) data <- data.frame(y=y, g=g)
> 
> Psi <- matrix(c(1, 0.00, 0.00, 0.00, 0.00,
>                0, 1.00, 0.28, 0.25, 0.78,
>                0, 0.28, 1.00, 0.83, 0.26,
>                0, 0.25, 0.83, 1.00, 0.23,
>                0, 0.78, 0.26, 0.23, 1.00), nrow=N, ncol=N)
> rownames(Psi)<-colnames(Psi)<-names(y)
> 
> pdMatPsi <- pdMat(Psi, form=~1|g, pdClass='pdSymm') # Not sure if the formula is correct and if pdSymm is the right pdMat class to use.
> 
> 
>> lme(y~1, data, random=pdMatPsi)
> Error in getGroups.data.frame(dataMix, groups) :
>  invalid formula for groups
> 
> For this error I guess the problem is that lme tries to look for a formula in the data.frame data which, as I've read in a vignette, is normally used only for plotting the data, so I'd rather keep the data.frame and not extend it to a groupedData.
> 
>> lme(y~1, data, random=list(g=pdMatPsi))
> Error in matrix(unlist(value), nrow = nrow(data), dimnames = list(row.names(data),  :
>  length of 'dimnames' [2] not equal to array extent In addition: Warning message:
> In Ops.factor(1, g) : | not meaningful for factors
> 
> Here I don't understand what am I doing wrong. I've tried other formulas in the call to pdMat but I'm still getting errors.
> Is it possible to use lme to fit the above model to the data? Also, is it possible to use the more recent lme4 package as it is supposed to be much faster?
> 
> Thank you and best regards,
> MV
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From vmitov at gmail.com  Wed Dec 17 12:09:46 2014
From: vmitov at gmail.com (Vmitov@gmail.com)
Date: Wed, 17 Dec 2014 13:09:46 +0200
Subject: [R-sig-ME] lme with a known correlation matrix for the random
	effects
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F027B64A3@UM-MAIL4112.unimaas.nl>
References: <077E31A57DA26E46AB0D493C9966AC730F027B64A3@UM-MAIL4112.unimaas.nl>
Message-ID: <E501E31E-3D2A-4E9D-8468-66EADC01CD56@gmail.com>

Dear Wolfgang,

Thanks a lot for letting me know about the "metafor" package and your example of code. I'm going to test it after the Christmas break.

Regards and merry Christmas to all the list!

Venelin

> On 16.12.2014, at 21:26, Viechtbauer Wolfgang (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> 
> While this is not a meta-analysis, this model can be easily fitted with the metafor package. So-called phylogenetic meta-analyses require the specification of a known correlation matrix for a random effect term. The same principle can be used here:
> 
> library(metafor)
> 
> N <- 5
> y <- c(7.38, 7.25, 7.34, 7.30, 7.06)
> names(y) <- c("t4", "t2", "t5", "t1", "t3")
> g <- e <- names(y)
> data <- data.frame(y=y, g=g, e=e)
> 
> Psi <- matrix(c(1, 0.00, 0.00, 0.00, 0.00,
>                0, 1.00, 0.28, 0.25, 0.78,
>                0, 0.28, 1.00, 0.83, 0.26,
>                0, 0.25, 0.83, 1.00, 0.23,
>                0, 0.78, 0.26, 0.23, 1.00), nrow=N, ncol=N)
> 
> rownames(Psi) <-colnames(Psi) <- names(y)
> 
> res <- rma.mv(y, V=0, random = list(~ 1 | g, ~ 1 | e), R = list(g = Psi), data=data)
> res
> 
> Note that you will get two warnings, one about non-positive sampling variances and the other about V being not positive definite. In meta-analyses, you typically have a known var-cov matrix of the sampling variances/covariances of the observed outcomes. Here, I am just setting that part of the model to 0, so it drops out. So you can ignore those warnings. The rest specifies exactly the requested model. Via the 'R' argument, one can specify a known correlation matrix for one (or more) terms. The default is REML estimation, but method="ML" will give you ML estimation.
> 
> The results look like this:
> 
> Multivariate Meta-Analysis Model (k = 5; method: REML)
> 
> Variance Components: 
> 
>            estim    sqrt  nlvls  fixed  factor    R
> sigma^2.1  0.0135  0.1161      5     no       g  yes
> sigma^2.2  0.0059  0.0771      5     no       e   no
> 
> Model Results:
> 
> estimate       se     zval     pval    ci.lb    ci.ub          
>  7.2815   0.0792  91.8996   <.0001   7.1262   7.4368      *** 
> 
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> So, sigma^2.1 is sigma^2_g and sigma^2.2 is sigma^2_e. To make sure that these are really good estimates of these variance components, one can profile the restricted log likelihood for each component with:
> 
> par(mfrow=c(1,2))
> profile(res, sigma2=1)
> profile(res, sigma2=2)
> 
> (this will generate a lot of the same warnings as mentioned above, since the model is being refitted repeatedly and each time the same issue comes up; you can ignore those again)
> 
> I hope this helps!
> 
> Best,
> Wolfgang
> 
> --   
> Wolfgang Viechtbauer, Ph.D., Statistician   
> Department of Psychiatry and Psychology   
> School for Mental Health and Neuroscience   
> Faculty of Health, Medicine, and Life Sciences   
> Maastricht University, P.O. Box 616 (VIJV1)   
> 6200 MD Maastricht, The Netherlands   
> +31 (43) 388-4170 | http://www.wvbauer.com   
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Mitov Venelin
>> Sent: Thursday, December 11, 2014 22:26
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] lme with a known correlation matrix for the random
>> effects
>> 
>> Dear R-sig mailing list,
>> 
>> Currently, I'm trying to use the function lme from the nlme package to
>> model epidemiological data. My question seems to be a specific one and I
>> couldn't find any similar model formulation using the lme function.
>> That's why I'm writing you.
>> 
>> The data I have is as follows:
>> 
>> 1. y: a numeric response vector consisting of one phenotype measurement
>> for each of N patients.
>> 
>> 2. A known known correlation matrix, Psi, between the patients.
>> 
>> I would like to model this data as a linear mixed effects model as
>> follows:
>> 
>> y_i = beta + g_i + e_i,
>> 
>> i=1,...,N
>> 
>> Here are the model assumptions:
>> 
>> beta is a fixed population grand-mean (i.e. intercept);
>> 
>> g_i is the pathogen-specific contribution to y_i and is considered as a
>> random effect that is correlated along patients (explained in more detail
>> below);
>> 
>> e_i is a patient-specific random effect including the effects of
>> patient's immune system, any possible interaction between the patient's
>> immune system and the pathogen, and measurement error for y_i.
>> 
>> In matrix-notation the model can be written as follows
>> 
>> y = 1*beta + I_NxN*g + I_NxN*e
>> 
>> In the formula above 1 denotes a N-dimensional vector of ones, I_NxN
>> denotes the NxN identity matrix.
>> The random N-dimensional vector g is assumed to be normally distributed
>> with mean 0 and a known correlation matrix, Psi.
>> The random N-dimensional vector e is assumed to be normally distributed
>> with mean 0 and and identity correlation matrix I_NxN.
>> 
>> The model has three parameters:
>> - beta;
>> - sigma_g, such that covariance matrix of g is equal to Psi*sigma_g^2
>> (Psi is known and fixed);
>> - sigma_e such that the covariance matrix of e is I_NxN*sigma_e^2;
>> 
>> Note that in the lme terminology each of the patients represents a group
>> by itself and there is 1 observation per group.
>> I'm able to fit the model using maximum likelihood, but I'm trying to use
>> the lme function mostly because of its REML fitting method.
>> 
>> So far, I've tried to use the lme function but I'm getting errors and I
>> don't know how to formulate my model in the lme syntax.
>> 
>> N=5
>> y <- c(7.38, 7.25, 7.34, 7.30, 7.06)
>> names(y) <- c("t4", "t2", "t5", "t1", "t3")
>> g <- factor(names(y))
>> data <- data.frame(y=y, g=g)
>> 
>> Psi <- matrix(c(1, 0.00, 0.00, 0.00, 0.00,
>>                0, 1.00, 0.28, 0.25, 0.78,
>>                0, 0.28, 1.00, 0.83, 0.26,
>>                0, 0.25, 0.83, 1.00, 0.23,
>>                0, 0.78, 0.26, 0.23, 1.00), nrow=N, ncol=N)
>> rownames(Psi)<-colnames(Psi)<-names(y)
>> 
>> pdMatPsi <- pdMat(Psi, form=~1|g, pdClass='pdSymm') # Not sure if the
>> formula is correct and if pdSymm is the right pdMat class to use.
>> 
>> 
>>> lme(y~1, data, random=pdMatPsi)
>> Error in getGroups.data.frame(dataMix, groups) :
>>  invalid formula for groups
>> 
>> For this error I guess the problem is that lme tries to look for a
>> formula in the data.frame data which, as I've read in a vignette, is
>> normally used only for plotting the data, so I'd rather keep the
>> data.frame and not extend it to a groupedData.
>> 
>>> lme(y~1, data, random=list(g=pdMatPsi))
>> Error in matrix(unlist(value), nrow = nrow(data), dimnames =
>> list(row.names(data),  :
>>  length of 'dimnames' [2] not equal to array extent
>> In addition: Warning message:
>> In Ops.factor(1, g) : | not meaningful for factors
>> 
>> Here I don't understand what am I doing wrong. I've tried other formulas
>> in the call to pdMat but I'm still getting errors.
>> Is it possible to use lme to fit the above model to the data? Also, is it
>> possible to use the more recent lme4 package as it is supposed to be much
>> faster?
>> 
>> Thank you and best regards,
>> MV
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From fbda005 at uni-hamburg.de  Wed Dec 17 16:18:13 2014
From: fbda005 at uni-hamburg.de (Jens Oldeland)
Date: Wed, 17 Dec 2014 16:18:13 +0100
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
Message-ID: <54919EB5.9020908@uni-hamburg.de>

Dear List-members,

recently, the R2 calculations for GLMMs invented by Schielzieth and 
Nakagawa 2012 [1] were implemented into the MuMIn package. This is 
incredibly good news, as many colleagues still require R2 to understand 
a model output. I invested 2 weeks in lengthy calculations of about 20 
negative binomial GLMMs using the glmmADMB package. Now, my colleagues 
want the R2 (me too), however, sadly, the MuMIn functions do only work 
for binomial and poisson GLMMS. Further, it seems that the functions do 
not recognize the glmmADMB package but prefer (g)lmer output.

Now my question: Does anybody of you know if this is "easy" to implement 
and if so "how"? I tried to redo the code provided here (actually posing 
the same question) but failed...:
http://stats.stackexchange.com/questions/109215/r%C2%B2-squared-from-a-generalized-linear-mixed-effects-models-glmm-using-a-negat

Or does anybody know if in the near future (this year?) it will be 
implemented somewhere?

Is it possible to transform a GLMMADMB object into an lmer object?

Any hints are most welcome,

merry Xmas
Jens


[1] Nakagawa, S., & Schielzeth, H. (2013). A general and simple method 
for obtaining R2 from generalized linear mixed-effects models./Methods 
in Ecology and Evolution/,/4/(2), 133-142.

-- 
+++++++++++++++++++++++++++++++++++++++++
Dr. Jens Oldeland

Post-Doc Researcher & Lecturer @ BEE
Managing Editor - Biodiversity & Ecology

Biodiversity, Ecology and Evolution of Plants (BEE)
Biocentre Klein Flottbek and Botanical Garden
University of Hamburg
Ohnhorststr. 18
22609 Hamburg,
Germany

Tel:    0049-(0)40-42816-407
Fax:    0049-(0)40-42816-543
Mail: 	jens.oldeland at uni-hamburg.de
         Oldeland at gmx.de 	
Skype:	jens.oldeland
http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
+++++++++++++++++++++++++++++++++++++++++


	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Wed Dec 17 17:26:09 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Dec 2014 16:26:09 +0000
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
References: <54919EB5.9020908@uni-hamburg.de>
Message-ID: <CAO7JsnR_pQ++Vk10xVBcva0AqZW8Ws5nDTCVASiaeRJqf-1rLQ@mail.gmail.com>

<sermon>
I must admit to getting a little twitchy when people speak of the "R2 for
GLMMs".  R2 for a linear model is well-defined and has many desirable
properties.  For other models one can define different quantities that
reflect some but not all of these properties.  But this is not calculating
an R2 in the sense of obtaining a number having all the properties that the
R2 for linear models does.  Usually there are several different ways that
such a quantity could be defined.  Especially for GLMs and GLMMs before you
can define "proportion of response variance explained" you first need to
define what you mean by "response variance".  The whole point of GLMs and
GLMMs is that a simple sum of squares of deviations does not meaningfully
reflect the variability in the response because the variance of an
individual response depends on its mean.

Confusion about what constitutes R2 or degrees of freedom of any of the
other quantities associated with linear models as applied to other models
comes from confusing the formula with the concept.  Although formulas are
derived from models the derivation often involves quite sophisticated
mathematics.  To avoid a potentially confusing derivation and just "cut to
the chase" it is easier to present the formulas.  But the formula is not
the concept.  Generalizing a formula is not equivalent to generalizing the
concept.  And those formulas are almost never used in practice, especially
for generalized linear models, analysis of variance and random effects.  I
have a "meta-theorem" that the only quantity actually calculated according
to the formulas given in introductory texts is the sample mean.

It may seem that I am being a grumpy old man about this, and perhaps I am,
but the danger is that people expect an "R2-like" quantity to have all the
properties of an R2 for linear models.  It can't.  There is no way to
generalize all the properties to a much more complicated model like a GLMM.

I was once on the committee reviewing a thesis proposal for Ph.D.
candidacy.  The proposal was to examine I think 9 different formulas that
could be considered ways of computing an R2 for a nonlinear regression
model to decide which one was "best".  Of course, this would be done
through a simulation study with only a couple of different models and only
a few different sets of parameter values for each. My suggestion that this
was an entirely meaningless exercise was not greeted warmly.
</sermon>

On Wed Dec 17 2014 at 9:49:28 AM Jens Oldeland <fbda005 at uni-hamburg.de>
wrote:

> Dear List-members,
>
> recently, the R2 calculations for GLMMs invented by Schielzieth and
> Nakagawa 2012 [1] were implemented into the MuMIn package. This is
> incredibly good news, as many colleagues still require R2 to understand
> a model output. I invested 2 weeks in lengthy calculations of about 20
> negative binomial GLMMs using the glmmADMB package. Now, my colleagues
> want the R2 (me too), however, sadly, the MuMIn functions do only work
> for binomial and poisson GLMMS. Further, it seems that the functions do
> not recognize the glmmADMB package but prefer (g)lmer output.
>
> Now my question: Does anybody of you know if this is "easy" to implement
> and if so "how"? I tried to redo the code provided here (actually posing
> the same question) but failed...:
> http://stats.stackexchange.com/questions/109215/r%C2%B2-
> squared-from-a-generalized-linear-mixed-effects-models-glmm-using-a-negat
>
> Or does anybody know if in the near future (this year?) it will be
> implemented somewhere?
>
> Is it possible to transform a GLMMADMB object into an lmer object?
>
> Any hints are most welcome,
>
> merry Xmas
> Jens
>
>
> [1] Nakagawa, S., & Schielzeth, H. (2013). A general and simple method
> for obtaining R2 from generalized linear mixed-effects models./Methods
> in Ecology and Evolution/,/4/(2), 133-142.
>
> --
> +++++++++++++++++++++++++++++++++++++++++
> Dr. Jens Oldeland
>
> Post-Doc Researcher & Lecturer @ BEE
> Managing Editor - Biodiversity & Ecology
>
> Biodiversity, Ecology and Evolution of Plants (BEE)
> Biocentre Klein Flottbek and Botanical Garden
> University of Hamburg
> Ohnhorststr. 18
> 22609 Hamburg,
> Germany
>
> Tel:    0049-(0)40-42816-407
> Fax:    0049-(0)40-42816-543
> Mail:   jens.oldeland at uni-hamburg.de
>          Oldeland at gmx.de
> Skype:  jens.oldeland
> http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
> http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
> +++++++++++++++++++++++++++++++++++++++++
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Wed Dec 17 17:58:00 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 17 Dec 2014 10:58:00 -0600
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
In-Reply-To: <CAO7JsnR_pQ++Vk10xVBcva0AqZW8Ws5nDTCVASiaeRJqf-1rLQ@mail.gmail.com>
References: <54919EB5.9020908@uni-hamburg.de>
	<CAO7JsnR_pQ++Vk10xVBcva0AqZW8Ws5nDTCVASiaeRJqf-1rLQ@mail.gmail.com>
Message-ID: <CAKFxdiSRdg=XK54sckTNwnKtuJJHEsy_BtSFt5Wq6YFO4ft_gw@mail.gmail.com>

Doug wrote:

> I have a "meta-theorem" that the only quantity actually calculated according
> to the formulas given in introductory texts is the sample mean.

R> x <- c(1e-20, 1, -1)
R> (x[1] + x[2] + x[3])/3
[1] 0
R> (x[3] + x[2] + x[1])/3
[1] 3.333333e-21
R> mean(x)
[1] 0

Looks like he's right!

Kevin


From russell-lenth at uiowa.edu  Wed Dec 17 19:29:11 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Wed, 17 Dec 2014 18:29:11 +0000
Subject: [R-sig-ME] How do I interpret linear mixed model contrast
 estimates from multcomp::glht()?
Message-ID: <51F0C7C54B032A42A23B74A088E7141C2E7299A3@itsnt443.iowa.uiowa.edu>

What concerns me about this question is that I don't see it expressed what contrasts you WANT. Rather, the focus is on discovering what contrasts are being produced. Surely you have some particular objectives in mind.

I don't know much about the contrast package, but this sort of thing is easy to do in lsmeans. With the model you fitted (by the way there is a warning message when fitting it), suppose you want to see predictions for each 'female' (I'd have named the variable 'sex') for each of the years, when size is 380:

R> library(lsmeans)
R> female.year <- lsmeans(math.lmm, ~ female | year, 
+     at = list(year = c(0.5, 1.5, 2.5), size = 380))

Loading required namespace: pbkrtest

R> female.year
year = 0.5:
 female     lsmean         SE    df   lower.CL   upper.CL
 Female -0.3177517 0.08298837 72.58 -0.4831633 -0.1523400
 Male   -0.3224042 0.08328416 73.30 -0.4883778 -0.1564306

year = 1.5:
 female     lsmean         SE    df   lower.CL   upper.CL
 Female  0.4508660 0.08363388 74.80  0.2842516  0.6174805
 Male    0.4462135 0.08390500 75.43  0.2790818  0.6133452

year = 2.5:
 female     lsmean         SE    df   lower.CL   upper.CL
 Female  1.2194837 0.08510503 80.13  1.0501235  1.3888440
 Male    1.2148312 0.08534946 80.67  1.0450019  1.3846605

Confidence level used: 0.95 


### Then if you want to compare the sexes in each year...

R> pairs(female.year)

year = 0.5:
 contrast         estimate         SE      df t.ratio p.value
 Female - Male 0.004652517 0.04245527 1675.57    0.11  0.9128

year = 1.5:
 contrast         estimate         SE      df t.ratio p.value
 Female - Male 0.004652517 0.04245527 1675.57    0.11  0.9128

year = 2.5:
 contrast         estimate         SE      df t.ratio p.value
 Female - Male 0.004652517 0.04245527 1675.57    0.11  0.9128

(same result each year since year doesn't interact with female)


### Or if you prefer using glht to do the testing:

R> summary(as.glht(female.year))

Note: df set to 76
$`year = 0.5`

	 Simultaneous Tests for General Linear Hypotheses

Linear Hypotheses:
            Estimate Std. Error t value Pr(>|t|)
Female == 0 -0.31775    0.08299  -3.829 0.000440
Male == 0   -0.32240    0.08328  -3.871 0.000381
(Adjusted p values reported -- single-step method)


$`year = 1.5`

	 Simultaneous Tests for General Linear Hypotheses

Linear Hypotheses:
            Estimate Std. Error t value Pr(>|t|)
Female == 0  0.45087    0.08363   5.391 1.36e-06
Male == 0    0.44621    0.08390   5.318 1.81e-06
(Adjusted p values reported -- single-step method)


$`year = 2.5`

	 Simultaneous Tests for General Linear Hypotheses

Linear Hypotheses:
            Estimate Std. Error t value Pr(>|t|)
Female == 0  1.21948    0.08511   14.33   <1e-10
Male == 0    1.21483    0.08535   14.23   <1e-10
(Adjusted p values reported -- single-step method)


### Or if you want to see the slope of the 'size' trend for each of those years:

R> lstrends(math.lmm, ~ year, var = "size", 
+    at = list(year = c(0.5,1.5,2.5), size = 380))

 year    size.trend           SE    df      lower.CL      upper.CL
  0.5 -0.0003041466 0.0001910213 57.49 -0.0006865890  7.829584e-05
  1.5 -0.0003648159 0.0001921332 58.82 -0.0007492979  1.966618e-05
  2.5 -0.0004254852 0.0001947970 62.12 -0.0008148634 -3.610690e-05

Results are averaged over the levels of: female 
Confidence level used: 0.95


At any rate, the main thing is to figure out what contrasts you want first.

Russ

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017



Message: 2
Date: Tue, 16 Dec 2014 22:24:57 -0700
From: Matthew Van Scoyoc <scoyoc at gmail.com>
To: Ken Beath <ken.beath at mq.edu.au>
Cc: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] How do I interpret linear mixed model contrast
	estimates from multcomp::glht()?
Message-ID:
	<CALx9ERU6pvc79a-aZbE8B=rOzn6h650HyftE989Q=CDPq2DUFw at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Thanks Ken and Thierry,

The rows in summary.glht() correspond to the row names of the contrast matrix given in the linfct argument as Thierry stated in my post on r-sig-ecology <http://r-sig-ecology.471788.n2.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-td7579236.html#a7579237>
(thanks
again Thierry). I'm using the contrast function in the contrast package to help compute the contrast matrix. The contrast function from the contrast package produces this...

> # Calculate the contrasts
> cc<-contrast(math.lm, a = list(year = c(.5, 1.5, 2.5), size = 380, 
> female
= levels(egsingle$female)),
+                       b = list(year = c(.5, 1.5, 2.5), size = 800, 
+ female
= levels(egsingle$female)))
> cc
lm model parameter contrast

  Contrast       S.E.                  Lower            Upper
 t        df      Pr(>|t|)
 0.1671791    0.01739038    0.1330889   0.2012694    9.61  7225        0
 0.2148280   0.02235506   0.1710055    0.2586504    9.61  7225        0
 0.2624768   0.03167964    0.2003754   0.3245781    8.29  7225        0
 0.1671791    0.01739038    0.1330889   0.2012694    9.61  7225        0
 0.2148280   0.02235506   0.1710055    0.2586504    9.61  7225        0
 0.2624768   0.03167964    0.2003754   0.3245781    8.29  7225        0

So, how do the rows of the contrast object relate to the coefficients of the mixed or linear model? The summary of *math.lm* produces 5 rows of coefficients...
> summary(math.lm)

Call:
lm(formula = math ~ year * size + female, data = egsingle)

Residuals:
    Min      1Q  Median      3Q     Max
-3.5631 -0.7775 -0.0523  0.7183  5.0195

Coefficients:
                            Estimate      Std. Error    t value
 Pr(>|t|)
(Intercept)       -5.590e-01  3.687e-02   -15.163    < 2e-16 ***
year                    8.521e-01   2.391e-02    35.644    < 2e-16 ***
size                   -3.413e-04   4.251e-05    -8.030    1.13e-15 ***
femaleFemale -2.232e-02  2.576e-02    -0.867     0.38624
year:size           -1.135e-04  2.948e-05    -3.849     0.00012 ***

I keep looking at cc$X (what I'm passing to glht() as the contrast matrix in the linfct argument), but my brain starts to melt at this point...
> cc$X
  (Intercept) year size femaleFemale year:size
1           0           0  -420            0                -210
2           0           0  -420            0               -630
3           0           0  -420            0               -1050
4           0           0  -420            0               -210
5           0           0  -420            0               -630
6           0           0  -420            0               -1050
attr(,"assign")
[1] 0 1 2 3 4
attr(,"contrasts")
attr(,"contrasts")$female
[1] "contr.SAS"

This is my first try at mixed models, and it's been several years since my linear regression course that was taught in SAS, so any help is appreciated.

Cheers,


MVS
=====
Matthew Van Scoyoc

<mvanscoyoc at aggiemail.usu.edu>https://sites.google.com/site/scoyoc/
=====
Think SNOW!


From r.turner at auckland.ac.nz  Wed Dec 17 21:14:49 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 18 Dec 2014 09:14:49 +1300
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
In-Reply-To: <54919EB5.9020908@uni-hamburg.de>
References: <54919EB5.9020908@uni-hamburg.de>
Message-ID: <5491E439.8050900@auckland.ac.nz>

On 18/12/14 04:18, Jens Oldeland wrote:
> Dear List-members,
>
> recently, the R2 calculations for GLMMs invented by Schielzieth and
> Nakagawa 2012 [1] were implemented into the MuMIn package. This is
> incredibly good news, as many colleagues still require R2 to understand
> a model output.

I would suggest that if your colleagues require R2 to "understand" the 
output from a glmm model, then they neither understand glmm models nor R2.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From bbolker at gmail.com  Thu Dec 18 01:51:08 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 17 Dec 2014 19:51:08 -0500
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
In-Reply-To: <5491E439.8050900@auckland.ac.nz>
References: <54919EB5.9020908@uni-hamburg.de> <5491E439.8050900@auckland.ac.nz>
Message-ID: <549224FC.7010004@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-17 03:14 PM, Rolf Turner wrote:
> On 18/12/14 04:18, Jens Oldeland wrote:
>> Dear List-members,
>> 
>> recently, the R2 calculations for GLMMs invented by Schielzieth
>> and Nakagawa 2012 [1] were implemented into the MuMIn package.
>> This is incredibly good news, as many colleagues still require R2
>> to understand a model output.
> 
> I would suggest that if your colleagues require R2 to "understand"
> the output from a glmm model, then they neither understand glmm
> models nor R2.
> 
> cheers,
> 
> Rolf Turner
> 

  I had a brief look at Schielzeth & Nakagawa 2012; they don't give
any immediately useful expression for the 'distribution-specific
variance' term sigma^2_d, and going back to Nakagawa and Schielzeth
2010 ("Repeatability for Gaussian and non-Gaussian data ...", cited by
SN2012 for distribution-specific variances) points further into the
weeds   as they say "There are other options, like negative binomial
models, that could also be considered (but are not treated here" and
refer the reader to papers by Carrasco 2009 and Carrasco and Jover
2005 ...  (Presumably the problem here is that the overdispersion in
the standard NB2 parameterization is neither additive nor
multiplicative.)  This probably wouldn't be too hard to work out in a
few hours of thought, but ...

  If you just need to make reviewers/colleagues happy, you could
always use the squared correlation coefficient between fitted and
observed values (I think Doug Bates has suggested this in the past).
This is certainly "an" R^2 measure, if not "the" R^2 measure.


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUkiT8AAoJEOCV5YRblxUHkrgIAJTV8Q4SA1c3qoYTg226y/im
ic55jODIjb+Sz4vwlYdV48LenzbMaJQ7pdTyERMRsqRXNiDhY72M+G9M2YoeHmso
wF6THLB6rAy3VqHHgIezYCvnsImwyD2fT8DH6Pn54qEb1y+HBw2ZPFUuJqTkfag+
RfoZBxHLEUNUlbiUtTcYOgumFwPTWA1bLdjiu4p3asbDHTvsBzilHcLNicFSV2fZ
7Cu2nocV2bVhTQlTEKtpnyilpqfRZ0FFA845Vrf7qgyisYBz9vMIxeIt6YbSEzQ+
nGRI9SUrr3O+LwPmUqQvYsffXyBN+GmA524UgfkuTa4myf0IVGqdVbKM2zdRh4M=
=fJWt
-----END PGP SIGNATURE-----


From markl033 at umn.edu  Thu Dec 18 06:41:58 2014
From: markl033 at umn.edu (Tricia Markle)
Date: Wed, 17 Dec 2014 23:41:58 -0600
Subject: [R-sig-ME] Repeated Measures in MCMCglmm model
Message-ID: <CAO=0ZJUEJ4d53ZFNgXgtwBfam29Q-ZzXv2evtZab39X5YGQjMg@mail.gmail.com>

Hello,



I am hoping to find someone familiar with the R code for taking repeated
measures into account in a MCMCglmm model. I have put together a working
code (see below) based on a couple of examples that I found (adding ?ID? as
a random term), but remain unsure if it is the best approach.


My study is investigating whether wide-ranging species of salamander have a
greater degree of plasticity in oxygen consumption (i.e. metabolic rate) at
different acclimation temperatures than narrow-ranging species. The same
individuals were tested at each of three acclimation temperatures (6, 14,
and 22C). Each acclimation temperature had 3 separate respirometry tests to
measure oxygen consumption (5, 15, and 25C) for a total of 9 tests per
individual.


*R script:*

library(MCMCglmm)
dataset<-read.csv(file="RData.csv", head=TRUE)
dataset$Range<-as.factor(dataset$Range)
str(dataset)

#Phylogeny Component
tree<-read.tree("Plethodontidae_comb61_PL.phy")
species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
"D._imitator_KHK05", "D._ochrophaeus_WKS05", "D._ocoee_B_KHK62",
"D._orestes_KHK129",  "D._monticola_A",  "D._santeetlah_11775",
"P_cinereus", "P_cylindraceus", "P_glutinosus", "P_hubrichti",
"P_montanus", "P_punctatus", "P_richmondi", "P_teyahalee", "P_virginia",
"P_wehrlei")
pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
tree$tip.label)])# Prune tree to just include species of interest
sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node") #rename
nodes to be unique
plot(sptree, show.node.label=TRUE)

treeAinv<-inverseA(sptree)$Ainv

#For Repeated Measures
dataset$ID<-dataset$animal
head(dataset)
p.var<-var(dataset$LVO2, na.rm=TRUE)


#Prior

prior<-list(G=list(G1=list(V=1, n=0.002), G2=list(V=1, n=0.002)),
R=list(V=1, n=0.002))

#Model 1 with Range Size
model1<-MCMCglmm(LVO2~1+Acclm+Temp+LMass+Sex+Range+Acclm*Temp*Range,
random=~animal+ID, data=dataset, ginverse=list(species=treeAinv),
nodes="ALL", prior=prior, nitt=300000, burnin=25000, thin = 1000,
verbose=FALSE)




*Sincerely, *


 *Tricia Markle*

*PhD Candidate, **University of Minnesota*

	[[alternative HTML version deleted]]


From shinichi.nakagawa at otago.ac.nz  Thu Dec 18 10:32:53 2014
From: shinichi.nakagawa at otago.ac.nz (Shinichi Nakagawa)
Date: Thu, 18 Dec 2014 09:32:53 +0000
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
In-Reply-To: <54919EB5.9020908@uni-hamburg.de>
References: <54919EB5.9020908@uni-hamburg.de>
Message-ID: <BAF63987945CB347B547CBB8451EDE7E38F6724F@ITS-EXM-P07.registry.otago.ac.nz>

Dear Jens

Our proposed R2 is not 'the' R2 but is also an R2 for mixed models that has several of the useful properties of traditional R2 - actually first proposed by Snijders & Bosker (1994).

Let?s say NB(lambda, theta) with the log link ? the mean = lambda, and the variance = lambda+ lambda^2/theta

The level 1 variance (on the link scale) should be ln(1+1/lambda+1/theta): see the Appendix of our paper, Nakagawa & Schielzeth (2013)

For lambda, it is good to use mean(Y) (Y is the response; counts) and the package should give you the value of theta (also, one should use mean(Y) for Possion models). 

Here the level 1 variance, sigma^2_1= sigma^2_e (additive over-dispersion)+sigma^2_d (distribution specific) = sigma^2_epsilon (residual variance) as in our paper (2013).

But Holger and I are doing some simulation study to check this first before its use, and we think we can extend the proposed R2 to other distributions although we need to test a few things first (we should be ready in one month or so). 

Best wishes,

Shinichi

Shinichi Nakagawa, PhD
(Associate Professor of Behavioural Ecology)
Department of Zoology
University of Otago
340 Great King Street
P. O. Box 56
Dunedin, New Zealand
Tel:  +64-3-479-5046
Fax: +64-3-479-7584
http://sparrow.otago.ac.nz/

________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jens Oldeland [fbda005 at uni-hamburg.de]
Sent: Thursday, December 18, 2014 4:18 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB

Dear List-members,

recently, the R2 calculations for GLMMs invented by Schielzieth and
Nakagawa 2012 [1] were implemented into the MuMIn package. This is
incredibly good news, as many colleagues still require R2 to understand
a model output. I invested 2 weeks in lengthy calculations of about 20
negative binomial GLMMs using the glmmADMB package. Now, my colleagues
want the R2 (me too), however, sadly, the MuMIn functions do only work
for binomial and poisson GLMMS. Further, it seems that the functions do
not recognize the glmmADMB package but prefer (g)lmer output.

Now my question: Does anybody of you know if this is "easy" to implement
and if so "how"? I tried to redo the code provided here (actually posing
the same question) but failed...:
http://stats.stackexchange.com/questions/109215/r%C2%B2-squared-from-a-generalized-linear-mixed-effects-models-glmm-using-a-negat

Or does anybody know if in the near future (this year?) it will be
implemented somewhere?

Is it possible to transform a GLMMADMB object into an lmer object?

Any hints are most welcome,

merry Xmas
Jens


[1] Nakagawa, S., & Schielzeth, H. (2013). A general and simple method
for obtaining R2 from generalized linear mixed-effects models./Methods
in Ecology and Evolution/,/4/(2), 133-142.

--
+++++++++++++++++++++++++++++++++++++++++
Dr. Jens Oldeland

Post-Doc Researcher & Lecturer @ BEE
Managing Editor - Biodiversity & Ecology

Biodiversity, Ecology and Evolution of Plants (BEE)
Biocentre Klein Flottbek and Botanical Garden
University of Hamburg
Ohnhorststr. 18
22609 Hamburg,
Germany

Tel:    0049-(0)40-42816-407
Fax:    0049-(0)40-42816-543
Mail:   jens.oldeland at uni-hamburg.de
         Oldeland at gmx.de
Skype:  jens.oldeland
http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
+++++++++++++++++++++++++++++++++++++++++


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From fbda005 at uni-hamburg.de  Wed Dec 17 21:17:33 2014
From: fbda005 at uni-hamburg.de (Jens Oldeland)
Date: Wed, 17 Dec 2014 21:17:33 +0100
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
In-Reply-To: <CAO7JsnR_pQ++Vk10xVBcva0AqZW8Ws5nDTCVASiaeRJqf-1rLQ@mail.gmail.com>
References: <54919EB5.9020908@uni-hamburg.de>
	<CAO7JsnR_pQ++Vk10xVBcva0AqZW8Ws5nDTCVASiaeRJqf-1rLQ@mail.gmail.com>
Message-ID: <20141217211733.17006y7qr381dsyl@webmail.rrz.uni-hamburg.de>

Dear Douglas,

many thanks for your thoughts. I understand that R2 is not perfectly  
correct for GLMs or anything more complicated. But still...

In my example, I calculated now these 20 negbin GLMMs and if anybody  
asks me how reliable they are, I cannot tell. According to the AIC  
thinking, I found the best of my candidate models, i.e. for each model  
I checked all possible parameter combinations in order to identify the  
"best" model (yes, there is no best model, and yes, searching a model  
using this procedure is for sure not optimal). I can calculate AIC  
weights which tell me how different my models are but not if the model  
is any good.

How can I know? Are there any possibilities to check this? Plotting  
observed versus predicted?

I mean, can I publish something without knowing this? I am an  
ecologist, so I am not perfectly trained in statistics and also not in  
assessing the quality of GLMMs.

Don?t worry, I am not in a bad mood while writing. just curious how  
this can be solved.

best regards from Hamburg, Germany
jens


Zitat von Douglas Bates <bates at stat.wisc.edu>:

> <sermon>
> I must admit to getting a little twitchy when people speak of the "R2 for
> GLMMs".  R2 for a linear model is well-defined and has many desirable
> properties.  For other models one can define different quantities that
> reflect some but not all of these properties.  But this is not calculating
> an R2 in the sense of obtaining a number having all the properties that the
> R2 for linear models does.  Usually there are several different ways that
> such a quantity could be defined.  Especially for GLMs and GLMMs before you
> can define "proportion of response variance explained" you first need to
> define what you mean by "response variance".  The whole point of GLMs and
> GLMMs is that a simple sum of squares of deviations does not meaningfully
> reflect the variability in the response because the variance of an
> individual response depends on its mean.
>
> Confusion about what constitutes R2 or degrees of freedom of any of the
> other quantities associated with linear models as applied to other models
> comes from confusing the formula with the concept.  Although formulas are
> derived from models the derivation often involves quite sophisticated
> mathematics.  To avoid a potentially confusing derivation and just "cut to
> the chase" it is easier to present the formulas.  But the formula is not
> the concept.  Generalizing a formula is not equivalent to generalizing the
> concept.  And those formulas are almost never used in practice, especially
> for generalized linear models, analysis of variance and random effects.  I
> have a "meta-theorem" that the only quantity actually calculated according
> to the formulas given in introductory texts is the sample mean.
>
> It may seem that I am being a grumpy old man about this, and perhaps I am,
> but the danger is that people expect an "R2-like" quantity to have all the
> properties of an R2 for linear models.  It can't.  There is no way to
> generalize all the properties to a much more complicated model like a GLMM.
>
> I was once on the committee reviewing a thesis proposal for Ph.D.
> candidacy.  The proposal was to examine I think 9 different formulas that
> could be considered ways of computing an R2 for a nonlinear regression
> model to decide which one was "best".  Of course, this would be done
> through a simulation study with only a couple of different models and only
> a few different sets of parameter values for each. My suggestion that this
> was an entirely meaningless exercise was not greeted warmly.
> </sermon>
>
> On Wed Dec 17 2014 at 9:49:28 AM Jens Oldeland <fbda005 at uni-hamburg.de>
> wrote:
>
>> Dear List-members,
>>
>> recently, the R2 calculations for GLMMs invented by Schielzieth and
>> Nakagawa 2012 [1] were implemented into the MuMIn package. This is
>> incredibly good news, as many colleagues still require R2 to understand
>> a model output. I invested 2 weeks in lengthy calculations of about 20
>> negative binomial GLMMs using the glmmADMB package. Now, my colleagues
>> want the R2 (me too), however, sadly, the MuMIn functions do only work
>> for binomial and poisson GLMMS. Further, it seems that the functions do
>> not recognize the glmmADMB package but prefer (g)lmer output.
>>
>> Now my question: Does anybody of you know if this is "easy" to implement
>> and if so "how"? I tried to redo the code provided here (actually posing
>> the same question) but failed...:
>> http://stats.stackexchange.com/questions/109215/r%C2%B2-
>> squared-from-a-generalized-linear-mixed-effects-models-glmm-using-a-negat
>>
>> Or does anybody know if in the near future (this year?) it will be
>> implemented somewhere?
>>
>> Is it possible to transform a GLMMADMB object into an lmer object?
>>
>> Any hints are most welcome,
>>
>> merry Xmas
>> Jens
>>
>>
>> [1] Nakagawa, S., & Schielzeth, H. (2013). A general and simple method
>> for obtaining R2 from generalized linear mixed-effects models./Methods
>> in Ecology and Evolution/,/4/(2), 133-142.
>>
>> --
>> +++++++++++++++++++++++++++++++++++++++++
>> Dr. Jens Oldeland
>>
>> Post-Doc Researcher & Lecturer @ BEE
>> Managing Editor - Biodiversity & Ecology
>>
>> Biodiversity, Ecology and Evolution of Plants (BEE)
>> Biocentre Klein Flottbek and Botanical Garden
>> University of Hamburg
>> Ohnhorststr. 18
>> 22609 Hamburg,
>> Germany
>>
>> Tel:    0049-(0)40-42816-407
>> Fax:    0049-(0)40-42816-543
>> Mail:   jens.oldeland at uni-hamburg.de
>>          Oldeland at gmx.de
>> Skype:  jens.oldeland
>> http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
>> http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
>> +++++++++++++++++++++++++++++++++++++++++
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



-- 
+++++++++++++++++++++++++++++++++++++++++
Dr. Jens Oldeland

Post-Doc Researcher & Lecturer @ BEE
Managing Editor - Biodiversity & Ecology

Biodiversity, Ecology and Evolution of Plants (BEE)
Biocentre Klein Flottbek and Botanical Garden
University of Hamburg
Ohnhorststr. 18
22609 Hamburg,
Germany

Tel:    0049-(0)40-42816-407
Fax:    0049-(0)40-42816-543
Mail: 	jens.oldeland at uni-hamburg.de
         Oldeland at gmx.de
Skype:	jens.oldeland
http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
+++++++++++++++++++++++++++++++++++++++++


From bill.shipley at usherbrooke.ca  Thu Dec 18 18:37:22 2014
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Thu, 18 Dec 2014 12:37:22 -0500
Subject: [R-sig-ME] testing for a significant correlation between random
	slopes
Message-ID: <00af01d01ae9$47d11010$d7733030$@usherbrooke.ca>

Hello.  I am fitting a 2-level mixed model using the lme() function
involving two independent variables (?t? and ?starchR?) in which the
intercept, both slopes and the interaction of the two slopes is also random:

 

fit.rgr2<- lme(log(TotalDM)~t+starchR +
t:starchR,random=(~t+t:starchR|Sp),data=dianna)

 

The model converges normally without any warning messages.  All of the fixed
terms are clearly different from zero. Mmy working hypothesis requires that
there also be a negative between?group correlation between the slope of ?t?
and the interaction term (i.e. groups whose slope for ?t? is high at low
values of ?starchR? have this slope decrease more rapidly as ?starchR?
increases).  When I fit the above mixed model using the lme() function, I
indeed find a strong negative correlation of -0.867; here is the relevant
part of the output from summary:

 

StdDev Corr 

(Intercept) 1.650783941 (Intr) t 

t 0.055870605 -0.124 

t:starchR 0.000309582 -0.340 -0.867 

Residual 0.337147863

 

However, there are only 20 groups and I know that large absolute
correlations between parameters can arise if the model is overparameterized.

 

Question: how can I determine if the value of -0.867 is really different
from zero?

 

Intuitively, I would fit another model in which the covariance between the
random components of ?t? and ?t:starchR? is constrained to be zero and then
compare the two models via their likelihoods, but I don?t know how to fit
such a constrained model in either lme() or lmer(). 

Any help or pointers to relevant literature would be appreciated.

Thanks.

 

Bill Shipley

Laboratoire d??cologie Fonctionnelle

D?partement de biologie, Universit? de Sherbrooke, Sherbrooke (Qc) Canada
J1K 2R1

(819) 821-8000, poste 62079

Fax: (819) 821-8049

 <http://www.billshipley.recherche.usherbrooke.ca/>
http://www.billshipley.recherche.usherbrooke.ca/

 


	[[alternative HTML version deleted]]


From ashaver at princeton.edu  Thu Dec 18 20:24:50 2014
From: ashaver at princeton.edu (Andrew C. Shaver)
Date: Thu, 18 Dec 2014 19:24:50 +0000
Subject: [R-sig-ME] lme4 troubles
In-Reply-To: <5490C891.8020108@gmail.com>
References: <908401771FA6A946A26C2A43892795451A83EBD8@CSGMBX204W.pu.win.princeton.edu>,
	<5490C891.8020108@gmail.com>
Message-ID: <908401771FA6A946A26C2A43892795451BAC86AC@CSGMBX204W.pu.win.princeton.edu>

Hi Ben, 

Problems all down to me not having updated version of R running. Reinstalled and everything working perfectly now! 

Thanks, and sorry to bother you with this. 

Very best, 

Andrew

________________________________________
From: Ben Bolker [bbolker at gmail.com]
Sent: Tuesday, December 16, 2014 7:04 PM
To: Andrew C. Shaver
Cc: lme4-authors at lists.r-forge.r-project.org; r-sig-mixed-models at r-project.org
Subject: Re: lme4 troubles

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-16 05:49 PM, Andrew C. Shaver wrote:
> Hi Ben!
>
> I hope this note finds you well.

  [I'm fine, but cc'ing to r-sig-mixed-models at r-project.org]
>
> I hate to trouble you, but I've having some troubles with the lme4
> package that I'm hoping you might be able to help me quick
> resolve.
>
> Using an earlier version of the package, I was running the
> following type of model without problem:
>
> output <- glmer(Y ~ X + Z + (1 | Province) + (1 | Year), data =
> data, family = "binomial", verbose = TRUE, control =
> list(maxIter=1000))
>
> I've since upgraded, and attempting to run this model now results
> in the following message:
>
> Error: PIRLS step failed In addition: Warning message: In
> checkArgs("glmer", sparseX, ...) : extra argument(s) ?control?,
> ?verbose? disregarded

  What version of lme4 are you now using (results of sessionInfo(),
or packageVersion("lme4") ?)

  Is there any chance you can provide a reproducible example?
Using one of the built-in examples from lme4 with the latest
(development) version of lme4 (although I think it should be identical
for these purposes to the CRAN version of lme4, 1.1-7):

library("lme4")
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial,
                  verbose=TRUE, control=list(maxIter=1000))

gives

Warning in glmer(cbind(incidence, size - incidence) ~ period + (1 |
herd),  :
  Use control=glmerControl(..) instead of passing a list of class ?list?
Error in (function (optimizer = c("bobyqa", "Nelder_Mead"),
restart_edge = FALSE,  :
  unused argument (maxIter = 1000)

If I use

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial,
                  verbose=TRUE,
                 control=glmerControl(optCtrl=list(maxfun=20000)))

it works (I don't get the specified error) -- but of course it would
be likely to work with this well-behaved example.

> If I run something like: output <- glmer(Y ~ X + Z + (1 | Province)
> + (1 | Year), data = data, family = "binomial"), i get: "Error:
> pwrssUpdate did not converge in 30 iterations". And if I attempt
> to increase the number of iterations by including
> "control=glmerControl(optCtrl=list(maxfun=20000)", I get:
>
> Error in checkArgs("glmer", sparseX, ...) : could not find
> function "glmerControl"

  That's surprising.

  FWIW the max number of PIRLS iterations is hard-coded in the current
version of lme4, although you can adjust the tolerance (tolPwrss).
However, usually when this goes wrong there's some other problem
that has to/can be fixed in another way.  Again, a reproducible example
would be really useful ...

> I am also no longer able to load the "blme" package. Before the
> update, had no problems running, for instance, bglmer(). Now, when
> I attempt to load the package, I get the following messages:
>
> Error : class "mer" is not exported by 'namespace:lme4' Error:
> package/namespace load failed for ?blme?

  I'm a little surprised/confused by this one.
  Make sure you're running a clean R session and (re)install lme4
and blme from scratch?

> Any hints on how to get back to running the model??
>
> Thank you very much in advance!
>
> Very best,
>
> Andrew

> --- Andrew Shaver PhD Candidate Woodrow Wilson School Princeton
> University scholar.princeton.edu/ashaver ---
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEbBAEBAgAGBQJUkMiRAAoJEOCV5YRblxUH0ooH+Iw/dnfWtjDwO97X8aILcB9E
8rcS1i4QrpN5rAEWa5SnuQDNYNCzduYMxpxMsfUu1uMreTq7hG7axxP0vC4rZJxL
onyg1wGY2JIzvwpjSHm7sEEyokFIz/EGyeruptCTdCGvLDBIVr2bwA0SXa+AGSpk
Ase7quPY6RBra7K4a+OJqsj0IZXqocf+HQIMAqdIfqdaBhsuAMXXAeaCRNbxcdnT
yQlYyHUVDH/uyfeRBhSaQn+wAu7guBYRUjcuyBRYP0bhd1RjSxMov8WkoRpef60S
b0en8Nb03e+cGjQaxpXEZv1hxnsQPPOVUqCC041qIjshi9UppZpxKq47eQij6w==
=Mu75
-----END PGP SIGNATURE-----


From s.blomberg1 at uq.edu.au  Thu Dec 18 22:48:34 2014
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Thu, 18 Dec 2014 21:48:34 +0000
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
In-Reply-To: <20141217211733.17006y7qr381dsyl@webmail.rrz.uni-hamburg.de>
References: <54919EB5.9020908@uni-hamburg.de>
	<CAO7JsnR_pQ++Vk10xVBcva0AqZW8Ws5nDTCVASiaeRJqf-1rLQ@mail.gmail.com>,
	<20141217211733.17006y7qr381dsyl@webmail.rrz.uni-hamburg.de>
Message-ID: <B5C07A26-A905-475C-AF0B-5373D9102683@uq.edu.au>

I agree with Doug. R2 for anything other than an ordinary linear model is rearranging deck chair on the Titanic. GLMs and GLMMs are complicated. They can be wrong in a variety of ways and expecting a single number like R2 (however defined) is a poor way to assess the relative fit of a model. Pseudo R2s don't answer the same question as R2 for an OLS model anyway, as Doug pointed out. My approach would be to use posterior predictive tests in a Bayesian context, or perhaps cross-validation.

Cheers,

Simon.

Sent from my iPhone

> On 19 Dec 2014, at 1:36 am, Jens Oldeland <fbda005 at uni-hamburg.de> wrote:
> 
> Dear Douglas,
> 
> many thanks for your thoughts. I understand that R2 is not perfectly correct for GLMs or anything more complicated. But still...
> 
> In my example, I calculated now these 20 negbin GLMMs and if anybody asks me how reliable they are, I cannot tell. According to the AIC thinking, I found the best of my candidate models, i.e. for each model I checked all possible parameter combinations in order to identify the "best" model (yes, there is no best model, and yes, searching a model using this procedure is for sure not optimal). I can calculate AIC weights which tell me how different my models are but not if the model is any good.
> 
> How can I know? Are there any possibilities to check this? Plotting observed versus predicted?
> 
> I mean, can I publish something without knowing this? I am an ecologist, so I am not perfectly trained in statistics and also not in assessing the quality of GLMMs.
> 
> Don?t worry, I am not in a bad mood while writing. just curious how this can be solved.
> 
> best regards from Hamburg, Germany
> jens
> 
> 
> Zitat von Douglas Bates <bates at stat.wisc.edu>:
> 
>> <sermon>
>> I must admit to getting a little twitchy when people speak of the "R2 for
>> GLMMs".  R2 for a linear model is well-defined and has many desirable
>> properties.  For other models one can define different quantities that
>> reflect some but not all of these properties.  But this is not calculating
>> an R2 in the sense of obtaining a number having all the properties that the
>> R2 for linear models does.  Usually there are several different ways that
>> such a quantity could be defined.  Especially for GLMs and GLMMs before you
>> can define "proportion of response variance explained" you first need to
>> define what you mean by "response variance".  The whole point of GLMs and
>> GLMMs is that a simple sum of squares of deviations does not meaningfully
>> reflect the variability in the response because the variance of an
>> individual response depends on its mean.
>> 
>> Confusion about what constitutes R2 or degrees of freedom of any of the
>> other quantities associated with linear models as applied to other models
>> comes from confusing the formula with the concept.  Although formulas are
>> derived from models the derivation often involves quite sophisticated
>> mathematics.  To avoid a potentially confusing derivation and just "cut to
>> the chase" it is easier to present the formulas.  But the formula is not
>> the concept.  Generalizing a formula is not equivalent to generalizing the
>> concept.  And those formulas are almost never used in practice, especially
>> for generalized linear models, analysis of variance and random effects.  I
>> have a "meta-theorem" that the only quantity actually calculated according
>> to the formulas given in introductory texts is the sample mean.
>> 
>> It may seem that I am being a grumpy old man about this, and perhaps I am,
>> but the danger is that people expect an "R2-like" quantity to have all the
>> properties of an R2 for linear models.  It can't.  There is no way to
>> generalize all the properties to a much more complicated model like a GLMM.
>> 
>> I was once on the committee reviewing a thesis proposal for Ph.D.
>> candidacy.  The proposal was to examine I think 9 different formulas that
>> could be considered ways of computing an R2 for a nonlinear regression
>> model to decide which one was "best".  Of course, this would be done
>> through a simulation study with only a couple of different models and only
>> a few different sets of parameter values for each. My suggestion that this
>> was an entirely meaningless exercise was not greeted warmly.
>> </sermon>
>> 
>> On Wed Dec 17 2014 at 9:49:28 AM Jens Oldeland <fbda005 at uni-hamburg.de>
>> wrote:
>> 
>>> Dear List-members,
>>> 
>>> recently, the R2 calculations for GLMMs invented by Schielzieth and
>>> Nakagawa 2012 [1] were implemented into the MuMIn package. This is
>>> incredibly good news, as many colleagues still require R2 to understand
>>> a model output. I invested 2 weeks in lengthy calculations of about 20
>>> negative binomial GLMMs using the glmmADMB package. Now, my colleagues
>>> want the R2 (me too), however, sadly, the MuMIn functions do only work
>>> for binomial and poisson GLMMS. Further, it seems that the functions do
>>> not recognize the glmmADMB package but prefer (g)lmer output.
>>> 
>>> Now my question: Does anybody of you know if this is "easy" to implement
>>> and if so "how"? I tried to redo the code provided here (actually posing
>>> the same question) but failed...:
>>> http://stats.stackexchange.com/questions/109215/r%C2%B2-
>>> squared-from-a-generalized-linear-mixed-effects-models-glmm-using-a-negat
>>> 
>>> Or does anybody know if in the near future (this year?) it will be
>>> implemented somewhere?
>>> 
>>> Is it possible to transform a GLMMADMB object into an lmer object?
>>> 
>>> Any hints are most welcome,
>>> 
>>> merry Xmas
>>> Jens
>>> 
>>> 
>>> [1] Nakagawa, S., & Schielzeth, H. (2013). A general and simple method
>>> for obtaining R2 from generalized linear mixed-effects models./Methods
>>> in Ecology and Evolution/,/4/(2), 133-142.
>>> 
>>> --
>>> +++++++++++++++++++++++++++++++++++++++++
>>> Dr. Jens Oldeland
>>> 
>>> Post-Doc Researcher & Lecturer @ BEE
>>> Managing Editor - Biodiversity & Ecology
>>> 
>>> Biodiversity, Ecology and Evolution of Plants (BEE)
>>> Biocentre Klein Flottbek and Botanical Garden
>>> University of Hamburg
>>> Ohnhorststr. 18
>>> 22609 Hamburg,
>>> Germany
>>> 
>>> Tel:    0049-(0)40-42816-407
>>> Fax:    0049-(0)40-42816-543
>>> Mail:   jens.oldeland at uni-hamburg.de
>>>         Oldeland at gmx.de
>>> Skype:  jens.oldeland
>>> http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
>>> http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
>>> +++++++++++++++++++++++++++++++++++++++++
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> -- 
> +++++++++++++++++++++++++++++++++++++++++
> Dr. Jens Oldeland
> 
> Post-Doc Researcher & Lecturer @ BEE
> Managing Editor - Biodiversity & Ecology
> 
> Biodiversity, Ecology and Evolution of Plants (BEE)
> Biocentre Klein Flottbek and Botanical Garden
> University of Hamburg
> Ohnhorststr. 18
> 22609 Hamburg,
> Germany
> 
> Tel:    0049-(0)40-42816-407
> Fax:    0049-(0)40-42816-543
> Mail:    jens.oldeland at uni-hamburg.de
>        Oldeland at gmx.de
> Skype:    jens.oldeland
> http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
> http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
> +++++++++++++++++++++++++++++++++++++++++
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jashander at ucdavis.edu  Thu Dec 18 23:31:03 2014
From: jashander at ucdavis.edu (Jaime Ashander)
Date: Thu, 18 Dec 2014 14:31:03 -0800
Subject: [R-sig-ME] testing for a significant correlation between random
	slopes
Message-ID: <CANZiT8qxdThPSLpu3+EO=285T5JmbvD8qLeB1DB-ofK=iLY9nw@mail.gmail.com>

Hi Bill,

The intuitive approach you propose makes sense to me. I'd think one could
specify such a model along the same lines as random effects on both slope
and intercept but with no correlation. In lme4 (see 3.2.2 of Bates's lme4
book) this would be:

library(lme4)
#don't use REML when comparing models
fit.rgr2_corr <- lmer(log(TotalDM) ~ t + starchR + t:starchR + ( t +
t:starchR | Sp),
 data=dianna, REML=FALSE)
fit.rgr2_nocorr <- lmer(log(TotalDM) ~ t + starchR + t:starchR + ( t | Sp)
+ (0 + t:starchR | Sp),
   data=dianna, REML=FALSE)
anova(fit_rgr2_corr, fit.rgr2_nocorr)

Note this also specifies zero correlation for the interaction term with the
intercept, but estimates a correlation between t and the intercept. I'm not
sure of a way to get around 'giving' the intercept to one of these terms
but maybe someone will chime in with an alternative.

Cheers,

- Jaime

------------------------------
>
> Message: 2
> Date: Thu, 18 Dec 2014 12:37:22 -0500
> From: "Bill Shipley" <bill.shipley at usherbrooke.ca>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] testing for a significant correlation between
>         random  slopes
> Message-ID: <00af01d01ae9$47d11010$d7733030$@usherbrooke.ca>
> Content-Type: text/plain; charset="UTF-8"
>
> Hello.  I am fitting a 2-level mixed model using the lme() function
> involving two independent variables (?t? and ?starchR?) in which the
> intercept, both slopes and the interaction of the two slopes is also
> random:
>
>
>
> fit.rgr2<- lme(log(TotalDM)~t+starchR +
> t:starchR,random=(~t+t:starchR|Sp),data=dianna)
>
>
>
> The model converges normally without any warning messages.  All of the
> fixed
> terms are clearly different from zero. Mmy working hypothesis requires that
> there also be a negative between?group correlation between the slope of ?t?
> and the interaction term (i.e. groups whose slope for ?t? is high at low
> values of ?starchR? have this slope decrease more rapidly as ?starchR?
> increases).  When I fit the above mixed model using the lme() function, I
> indeed find a strong negative correlation of -0.867; here is the relevant
> part of the output from summary:
>
>
>
> StdDev Corr
>
> (Intercept) 1.650783941 (Intr) t
>
> t 0.055870605 -0.124
>
> t:starchR 0.000309582 -0.340 -0.867
>
> Residual 0.337147863
>
>
>
> However, there are only 20 groups and I know that large absolute
> correlations between parameters can arise if the model is
> overparameterized.
>
>
>
> Question: how can I determine if the value of -0.867 is really different
> from zero?
>
>
>
> Intuitively, I would fit another model in which the covariance between the
> random components of ?t? and ?t:starchR? is constrained to be zero and then
> compare the two models via their likelihoods, but I don?t know how to fit
> such a constrained model in either lme() or lmer().
>
> Any help or pointers to relevant literature would be appreciated.
>
> Thanks.
>
>
>
> Bill Shipley
>
> Laboratoire d??ologie Fonctionnelle
>
> D?rtement de biologie, Universit?e Sherbrooke, Sherbrooke (Qc) Canada
> J1K 2R1
>
> (819) 821-8000, poste 62079
>
> Fax: (819) 821-8049
>
>  <http://www.billshipley.recherche.usherbrooke.ca/>
> http://www.billshipley.recherche.usherbrooke.ca/
>
>
>
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Dec 19 03:05:15 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 18 Dec 2014 21:05:15 -0500
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
In-Reply-To: <B5C07A26-A905-475C-AF0B-5373D9102683@uq.edu.au>
References: <54919EB5.9020908@uni-hamburg.de>	<CAO7JsnR_pQ++Vk10xVBcva0AqZW8Ws5nDTCVASiaeRJqf-1rLQ@mail.gmail.com>,
	<20141217211733.17006y7qr381dsyl@webmail.rrz.uni-hamburg.de>
	<B5C07A26-A905-475C-AF0B-5373D9102683@uq.edu.au>
Message-ID: <549387DB.3010604@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-18 04:48 PM, Simon Blomberg wrote:
> I agree with Doug. R2 for anything other than an ordinary linear 
> model is rearranging deck chair on the Titanic. GLMs and GLMMs are 
> complicated. They can be wrong in a variety of ways and expecting
> a single number like R2 (however defined) is a poor way to assess
> the relative fit of a model. Pseudo R2s don't answer the same
> question as R2 for an OLS model anyway, as Doug pointed out. My
> approach would be to use posterior predictive tests in a Bayesian
> context, or perhaps cross-validation.
> 
> Cheers,
> 
> Simon.

  I agree with this position, *but* I will say that if this is going
to be the case then we (the expert-y people) need to provide more
worked examples of how to do this.  There's at least one example of a
posterior predictive simulation at
http://www.rpubs.com/bbolker/glmmchapter ...

> 
> Sent from my iPhone
> 
>> On 19 Dec 2014, at 1:36 am, Jens Oldeland
>> <fbda005 at uni-hamburg.de> wrote:
>> 
>> Dear Douglas,
>> 
>> many thanks for your thoughts. I understand that R2 is not 
>> perfectly correct for GLMs or anything more complicated. But 
>> still...
>> 
>> In my example, I calculated now these 20 negbin GLMMs and if 
>> anybody asks me how reliable they are, I cannot tell. According
>> to the AIC thinking, I found the best of my candidate models,
>> i.e. for each model I checked all possible parameter combinations
>> in order to identify the "best" model (yes, there is no best
>> model, and yes, searching a model using this procedure is for
>> sure not optimal). I can calculate AIC weights which tell me how
>> different my models are but not if the model is any good.
>> 
>> How can I know? Are there any possibilities to check this?
>> Plotting observed versus predicted?
>> 
>> I mean, can I publish something without knowing this? I am an 
>> ecologist, so I am not perfectly trained in statistics and also
>> not in assessing the quality of GLMMs.
>> 
>> Don?t worry, I am not in a bad mood while writing. just curious
>> how this can be solved.
>> 
>> best regards from Hamburg, Germany jens
>> 
>> 
>> Zitat von Douglas Bates <bates at stat.wisc.edu>:
>> 
>>> <sermon> I must admit to getting a little twitchy when people 
>>> speak of the "R2 for GLMMs".  R2 for a linear model is 
>>> well-defined and has many desirable properties.  For other
>>> models one can define different quantities that reflect some
>>> but not all of these properties.  But this is not calculating
>>> an R2 in the sense of obtaining a number having all the
>>> properties that the R2 for linear models does.  Usually there
>>> are several different ways that such a quantity could be
>>> defined.  Especially for GLMs and GLMMs before you can define
>>> "proportion of response variance explained" you first need to
>>> define what you mean by "response variance".  The whole point
>>> of GLMs and GLMMs is that a simple sum of squares of deviations
>>> does not meaningfully reflect the variability in the response
>>> because the variance of an individual response depends on its
>>> mean.
>>> 
>>> Confusion about what constitutes R2 or degrees of freedom of
>>> any of the other quantities associated with linear models as
>>> applied to other models comes from confusing the formula with
>>> the concept.  Although formulas are derived from models the 
>>> derivation often involves quite sophisticated mathematics.  To 
>>> avoid a potentially confusing derivation and just "cut to the 
>>> chase" it is easier to present the formulas.  But the formula
>>> is not the concept.  Generalizing a formula is not equivalent
>>> to generalizing the concept.  And those formulas are almost
>>> never used in practice, especially for generalized linear
>>> models, analysis of variance and random effects.  I have a
>>> "meta-theorem" that the only quantity actually calculated
>>> according to the formulas given in introductory texts is the
>>> sample mean.
>>> 
>>> It may seem that I am being a grumpy old man about this, and 
>>> perhaps I am, but the danger is that people expect an
>>> "R2-like" quantity to have all the properties of an R2 for
>>> linear models. It can't.  There is no way to generalize all the
>>> properties to a much more complicated model like a GLMM.
>>> 
>>> I was once on the committee reviewing a thesis proposal for 
>>> Ph.D. candidacy.  The proposal was to examine I think 9
>>> different formulas that could be considered ways of computing
>>> an R2 for a nonlinear regression model to decide which one was
>>> "best".  Of course, this would be done through a simulation
>>> study with only a couple of different models and only a few
>>> different sets of parameter values for each. My suggestion that
>>> this was an entirely meaningless exercise was not greeted
>>> warmly. </sermon>
>>> 
>>> On Wed Dec 17 2014 at 9:49:28 AM Jens Oldeland 
>>> <fbda005 at uni-hamburg.de> wrote:
>>> 
>>>> Dear List-members,
>>>> 
>>>> recently, the R2 calculations for GLMMs invented by
>>>> Schielzieth and Nakagawa 2012 [1] were implemented into the
>>>> MuMIn package. This is incredibly good news, as many
>>>> colleagues still require R2 to understand a model output. I
>>>> invested 2 weeks in lengthy calculations of about 20 negative
>>>> binomial GLMMs using the glmmADMB package. Now, my colleagues
>>>> want the R2 (me too), however, sadly, the MuMIn functions do
>>>> only work for binomial and poisson GLMMS. Further, it seems
>>>> that the functions do not recognize the glmmADMB package but
>>>> prefer (g)lmer output.
>>>> 
>>>> Now my question: Does anybody of you know if this is "easy"
>>>> to implement and if so "how"? I tried to redo the code
>>>> provided here (actually posing the same question) but
>>>> failed...: 
>>>> http://stats.stackexchange.com/questions/109215/r%C2%B2- 
>>>> squared-from-a-generalized-linear-mixed-effects-models-glmm-using-a-negat
>>>>
>>>>
>>>>
>>>> 
Or does anybody know if in the near future (this year?) it will be
>>>> implemented somewhere?
>>>> 
>>>> Is it possible to transform a GLMMADMB object into an lmer 
>>>> object?
>>>> 
>>>> Any hints are most welcome,
>>>> 
>>>> merry Xmas Jens
>>>> 
>>>> 
>>>> [1] Nakagawa, S., & Schielzeth, H. (2013). A general and
>>>> simple method for obtaining R2 from generalized linear
>>>> mixed-effects models./Methods in Ecology and
>>>> Evolution/,/4/(2), 133-142.
>>>> 
>>>> -- +++++++++++++++++++++++++++++++++++++++++ Dr. Jens
>>>> Oldeland
>>>> 
>>>> Post-Doc Researcher & Lecturer @ BEE Managing Editor - 
>>>> Biodiversity & Ecology
>>>> 
>>>> Biodiversity, Ecology and Evolution of Plants (BEE)
>>>> Biocentre Klein Flottbek and Botanical Garden University of
>>>> Hamburg Ohnhorststr. 18 22609 Hamburg, Germany
>>>> 
>>>> Tel:    0049-(0)40-42816-407 Fax:    0049-(0)40-42816-543
>>>> Mail: jens.oldeland at uni-hamburg.de Oldeland at gmx.de Skype: 
>>>> jens.oldeland 
>>>> http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm 
>>>> http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
>>>>
>>>>
>>>> 
+++++++++++++++++++++++++++++++++++++++++
>>>> 
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
>> -- +++++++++++++++++++++++++++++++++++++++++ Dr. Jens Oldeland
>> 
>> Post-Doc Researcher & Lecturer @ BEE Managing Editor -
>> Biodiversity & Ecology
>> 
>> Biodiversity, Ecology and Evolution of Plants (BEE) Biocentre
>> Klein Flottbek and Botanical Garden University of Hamburg
>> Ohnhorststr. 18 22609 Hamburg, Germany
>> 
>> Tel:    0049-(0)40-42816-407 Fax:    0049-(0)40-42816-543 Mail: 
>> jens.oldeland at uni-hamburg.de Oldeland at gmx.de Skype: jens.oldeland
>>  http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm 
>> http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
>>
>>
>> 
+++++++++++++++++++++++++++++++++++++++++
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUk4fbAAoJEOCV5YRblxUHTEAH/jFKDykJtgnX1KCG576jI9RR
X3ZzvSJ94jABqknWEuYxT7RY25RixDsqAD0D7fet9hCwS7Pv9AZMcmRbGOa3twrW
OUFrBYEURt6Gk+WvyFEcffRFRRnktYDXjXzYiPyOOp22fmziCy6XvbkcMa8qc8M7
dG6HcJpygjGcpZBa+eBRBh7Oha3OTOaLIdjCRMk2b9OxmwivIO7YiHTmAYuLodo+
JjVuQJGi6TF+J/FUL3XGwfCECUtHu2+zJ3ch/NKzVv6OI0QZz72VMyViUrlIi/LJ
9S6AjGIdLhh7lndV/tq4qqKMw6jIVFqjJetYi1yr6fvju9v1Vc+KIu56T+rh6CA=
=uOST
-----END PGP SIGNATURE-----


From tove.jansson at gmail.com  Fri Dec 19 15:04:53 2014
From: tove.jansson at gmail.com (Tove Jansson)
Date: Fri, 19 Dec 2014 15:04:53 +0100
Subject: [R-sig-ME] testing for a significant correlation between random
	slopes (Jaime Ashander)
In-Reply-To: <mailman.5.1418986802.25142.r-sig-mixed-models@r-project.org>
References: <mailman.5.1418986802.25142.r-sig-mixed-models@r-project.org>
Message-ID: <1664BA83-270D-4A89-A850-29FA5184DE52@gmail.com>

HI,

Correct me if I am wrong, but shouldn?t REML be used when comparing random effects (ML will supposedly produce overly conservative estimates and should only be used when comparing models with differences in fixed effects).

best,

DT


On Dec 19, 2014, at 12:00 PM, r-sig-mixed-models-request at r-project.org wrote:

> Re: testing for a significant correlation between random
>      slopes (Jaime Ashander)


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Dec 19 16:15:50 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 19 Dec 2014 15:15:50 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?testing_for_a_significant_correlation_betwee?=
	=?utf-8?q?n_random=09slopes?=
References: <CANZiT8qxdThPSLpu3+EO=285T5JmbvD8qLeB1DB-ofK=iLY9nw@mail.gmail.com>
Message-ID: <loom.20141219T155705-245@post.gmane.org>

Jaime Ashander <jashander at ...> writes:

> 
> Hi Bill,
> 
> The intuitive approach you propose makes sense to me. I'd think one could
> specify such a model along the same lines as random effects on both slope
> and intercept but with no correlation. In lme4 (see 3.2.2 of Bates's lme4
> book) this would be:
> 
> library(lme4)
> #don't use REML when comparing models
> fit.rgr2_corr <- lmer(log(TotalDM) ~ t + starchR + t:starchR + ( t +
> t:starchR | Sp),
>  data=dianna, REML=FALSE)
> fit.rgr2_nocorr <- lmer(log(TotalDM) ~ t + starchR + t:starchR + ( t | Sp)
> + (0 + t:starchR | Sp),
>    data=dianna, REML=FALSE)
> anova(fit_rgr2_corr, fit.rgr2_nocorr)
> 
> Note this also specifies zero correlation for the interaction term with the
> intercept, but estimates a correlation between t and the intercept. I'm not
> sure of a way to get around 'giving' the intercept to one of these terms
> but maybe someone will chime in with an alternative.
> 
> Cheers,
> 
> - Jaime

  I suppose you could use

(1|Sp) + (0+t|Sp) + (0+t:starchR|Sp)

It's important to distinguish between categorical and continuous
predictors here: if t and starchR are both continuous (as suggested
by the use of the word 'slopes' below), this should work.  If either
is categorical this will be a bit trickier (I believe the ?lmer
page gives an example -- basically, you have to set up your own
dummy variables).

  As far as using REML vs ML for contrasts -- Tove is true that
REML generally gives less-biased estimates of the RE variances,
and it should be OK to do a (restricted) likelihood ratio test
between REML-fitted models that differ only in their random effects.
I don't actually know of any explicit comparisons that explore
the power/type I error of REML vs ML-based tests of this type.

Alternatively,

* You could probably use the nlme package's "pdDiag" class
to set up your own diagonal variance-covariance matrix.
* You could look at the 95% profile confidence intervals on the
correlation (?confint.merMod) and see if they overlap zero or not.


> > Message: 2
> > Date: Thu, 18 Dec 2014 12:37:22 -0500
> > From: "Bill Shipley" <bill.shipley at ...>

[snip]

> >
> > Hello.  I am fitting a 2-level mixed model using the lme() function
> > involving two independent variables (?t? and ?starchR?) in which the
> > intercept, both slopes and the interaction of the two slopes is also
> > random:
> >
> >
> >
> > fit.rgr2<- lme(log(TotalDM)~t+starchR +
> > t:starchR,random=(~t+t:starchR|Sp),data=dianna)

> > The model converges normally without any warning messages.  All of the
> > fixed
> > terms are clearly different from zero. Mmy working hypothesis requires that
> > there also be a negative between?group correlation between the slope of ?t?
> > and the interaction term (i.e. groups whose slope for ?t? is high at low
> > values of ?starchR? have this slope decrease more rapidly as ?starchR?
> > increases).  When I fit the above mixed model using the lme() function, I
> > indeed find a strong negative correlation of -0.867; here is the relevant
> > part of the output from summary:
> >
> > StdDev Corr
> >
> > (Intercept) 1.650783941 (Intr) t
> > t 0.055870605 -0.124
> > t:starchR 0.000309582 -0.340 -0.867
> >
> > Residual 0.337147863
> >
> > However, there are only 20 groups and I know that large absolute
> > correlations between parameters can arise if the model is
> > overparameterized.
> >
> > Question: how can I determine if the value of -0.867 is really different
> > from zero?
> >
> > Intuitively, I would fit another model in which the covariance between the
> > random components of ?t? and ?t:starchR? is constrained to be zero and then
> > compare the two models via their likelihoods, but I don?t know how to fit
> > such a constrained model in either lme() or lmer().
> >
> > Any help or pointers to relevant literature would be appreciated.

 [snip]


From fbda005 at uni-hamburg.de  Fri Dec 19 12:19:09 2014
From: fbda005 at uni-hamburg.de (Jens Oldeland)
Date: Fri, 19 Dec 2014 12:19:09 +0100
Subject: [R-sig-ME] R2 for Negative Binomial calculated with GLMMADMB
In-Reply-To: <B5C07A26-A905-475C-AF0B-5373D9102683@uq.edu.au>
References: <54919EB5.9020908@uni-hamburg.de>	<CAO7JsnR_pQ++Vk10xVBcva0AqZW8Ws5nDTCVASiaeRJqf-1rLQ@mail.gmail.com>,
	<20141217211733.17006y7qr381dsyl@webmail.rrz.uni-hamburg.de>
	<B5C07A26-A905-475C-AF0B-5373D9102683@uq.edu.au>
Message-ID: <549409AD.5020901@uni-hamburg.de>

Thanks to all the repliers so far, and in particular thanks to Ben 
Bolker for the posterior predictive test example on RPubs! I did not 
work with Baysian stats so far, but I see that it is necessary, not only 
in the case of complex models but mostly there. Just yesterday, I dug 
through the 4 first chapters of the Introduction to WinBUGS... :)

Simple questions often provoke the most interesting discussions, isn?t 
it? :)
I learned something.

Thanks again and merry Xmas to all of you,

Jens


Am 18.12.2014 22:48, schrieb Simon Blomberg:
> I agree with Doug. R2 for anything other than an ordinary linear model is rearranging deck chair on the Titanic. GLMs and GLMMs are complicated. They can be wrong in a variety of ways and expecting a single number like R2 (however defined) is a poor way to assess the relative fit of a model. Pseudo R2s don't answer the same question as R2 for an OLS model anyway, as Doug pointed out. My approach would be to use posterior predictive tests in a Bayesian context, or perhaps cross-validation.
>
> Cheers,
>
> Simon.
>
> Sent from my iPhone
>
>> On 19 Dec 2014, at 1:36 am, Jens Oldeland <fbda005 at uni-hamburg.de> wrote:
>>
>> Dear Douglas,
>>
>> many thanks for your thoughts. I understand that R2 is not perfectly correct for GLMs or anything more complicated. But still...
>>
>> In my example, I calculated now these 20 negbin GLMMs and if anybody asks me how reliable they are, I cannot tell. According to the AIC thinking, I found the best of my candidate models, i.e. for each model I checked all possible parameter combinations in order to identify the "best" model (yes, there is no best model, and yes, searching a model using this procedure is for sure not optimal). I can calculate AIC weights which tell me how different my models are but not if the model is any good.
>>
>> How can I know? Are there any possibilities to check this? Plotting observed versus predicted?
>>
>> I mean, can I publish something without knowing this? I am an ecologist, so I am not perfectly trained in statistics and also not in assessing the quality of GLMMs.
>>
>> Don?t worry, I am not in a bad mood while writing. just curious how this can be solved.
>>
>> best regards from Hamburg, Germany
>> jens
>>
>>
>> Zitat von Douglas Bates <bates at stat.wisc.edu>:
>>
>>> <sermon>
>>> I must admit to getting a little twitchy when people speak of the "R2 for
>>> GLMMs".  R2 for a linear model is well-defined and has many desirable
>>> properties.  For other models one can define different quantities that
>>> reflect some but not all of these properties.  But this is not calculating
>>> an R2 in the sense of obtaining a number having all the properties that the
>>> R2 for linear models does.  Usually there are several different ways that
>>> such a quantity could be defined.  Especially for GLMs and GLMMs before you
>>> can define "proportion of response variance explained" you first need to
>>> define what you mean by "response variance".  The whole point of GLMs and
>>> GLMMs is that a simple sum of squares of deviations does not meaningfully
>>> reflect the variability in the response because the variance of an
>>> individual response depends on its mean.
>>>
>>> Confusion about what constitutes R2 or degrees of freedom of any of the
>>> other quantities associated with linear models as applied to other models
>>> comes from confusing the formula with the concept.  Although formulas are
>>> derived from models the derivation often involves quite sophisticated
>>> mathematics.  To avoid a potentially confusing derivation and just "cut to
>>> the chase" it is easier to present the formulas.  But the formula is not
>>> the concept.  Generalizing a formula is not equivalent to generalizing the
>>> concept.  And those formulas are almost never used in practice, especially
>>> for generalized linear models, analysis of variance and random effects.  I
>>> have a "meta-theorem" that the only quantity actually calculated according
>>> to the formulas given in introductory texts is the sample mean.
>>>
>>> It may seem that I am being a grumpy old man about this, and perhaps I am,
>>> but the danger is that people expect an "R2-like" quantity to have all the
>>> properties of an R2 for linear models.  It can't.  There is no way to
>>> generalize all the properties to a much more complicated model like a GLMM.
>>>
>>> I was once on the committee reviewing a thesis proposal for Ph.D.
>>> candidacy.  The proposal was to examine I think 9 different formulas that
>>> could be considered ways of computing an R2 for a nonlinear regression
>>> model to decide which one was "best".  Of course, this would be done
>>> through a simulation study with only a couple of different models and only
>>> a few different sets of parameter values for each. My suggestion that this
>>> was an entirely meaningless exercise was not greeted warmly.
>>> </sermon>
>>>
>>> On Wed Dec 17 2014 at 9:49:28 AM Jens Oldeland <fbda005 at uni-hamburg.de>
>>> wrote:
>>>
>>>> Dear List-members,
>>>>
>>>> recently, the R2 calculations for GLMMs invented by Schielzieth and
>>>> Nakagawa 2012 [1] were implemented into the MuMIn package. This is
>>>> incredibly good news, as many colleagues still require R2 to understand
>>>> a model output. I invested 2 weeks in lengthy calculations of about 20
>>>> negative binomial GLMMs using the glmmADMB package. Now, my colleagues
>>>> want the R2 (me too), however, sadly, the MuMIn functions do only work
>>>> for binomial and poisson GLMMS. Further, it seems that the functions do
>>>> not recognize the glmmADMB package but prefer (g)lmer output.
>>>>
>>>> Now my question: Does anybody of you know if this is "easy" to implement
>>>> and if so "how"? I tried to redo the code provided here (actually posing
>>>> the same question) but failed...:
>>>> http://stats.stackexchange.com/questions/109215/r%C2%B2-
>>>> squared-from-a-generalized-linear-mixed-effects-models-glmm-using-a-negat
>>>>
>>>> Or does anybody know if in the near future (this year?) it will be
>>>> implemented somewhere?
>>>>
>>>> Is it possible to transform a GLMMADMB object into an lmer object?
>>>>
>>>> Any hints are most welcome,
>>>>
>>>> merry Xmas
>>>> Jens
>>>>
>>>>
>>>> [1] Nakagawa, S., & Schielzeth, H. (2013). A general and simple method
>>>> for obtaining R2 from generalized linear mixed-effects models./Methods
>>>> in Ecology and Evolution/,/4/(2), 133-142.
>>>>
>>>> --
>>>> +++++++++++++++++++++++++++++++++++++++++
>>>> Dr. Jens Oldeland
>>>>
>>>> Post-Doc Researcher & Lecturer @ BEE
>>>> Managing Editor - Biodiversity & Ecology
>>>>
>>>> Biodiversity, Ecology and Evolution of Plants (BEE)
>>>> Biocentre Klein Flottbek and Botanical Garden
>>>> University of Hamburg
>>>> Ohnhorststr. 18
>>>> 22609 Hamburg,
>>>> Germany
>>>>
>>>> Tel:    0049-(0)40-42816-407
>>>> Fax:    0049-(0)40-42816-543
>>>> Mail:   jens.oldeland at uni-hamburg.de
>>>>          Oldeland at gmx.de
>>>> Skype:  jens.oldeland
>>>> http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
>>>> http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
>>>> +++++++++++++++++++++++++++++++++++++++++
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> -- 
>> +++++++++++++++++++++++++++++++++++++++++
>> Dr. Jens Oldeland
>>
>> Post-Doc Researcher & Lecturer @ BEE
>> Managing Editor - Biodiversity & Ecology
>>
>> Biodiversity, Ecology and Evolution of Plants (BEE)
>> Biocentre Klein Flottbek and Botanical Garden
>> University of Hamburg
>> Ohnhorststr. 18
>> 22609 Hamburg,
>> Germany
>>
>> Tel:    0049-(0)40-42816-407
>> Fax:    0049-(0)40-42816-543
>> Mail:    jens.oldeland at uni-hamburg.de
>>         Oldeland at gmx.de
>> Skype:    jens.oldeland
>> http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
>> http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
>> +++++++++++++++++++++++++++++++++++++++++
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
+++++++++++++++++++++++++++++++++++++++++
Dr. Jens Oldeland

Post-Doc Researcher & Lecturer @ BEE
Managing Editor - Biodiversity & Ecology

Biodiversity, Ecology and Evolution of Plants (BEE)
Biocentre Klein Flottbek and Botanical Garden
University of Hamburg
Ohnhorststr. 18
22609 Hamburg,
Germany

Tel:    0049-(0)40-42816-407
Fax:    0049-(0)40-42816-543
Mail: 	jens.oldeland at uni-hamburg.de
         Oldeland at gmx.de 	
Skype:	jens.oldeland
http://www.biologie.uni-hamburg.de/bzf/fbda005/fbda005.htm
http://www.biodiversity-plants.de/biodivers_ecol/biodivers_ecol.php
+++++++++++++++++++++++++++++++++++++++++


	[[alternative HTML version deleted]]


From vincenzoaellis at gmail.com  Fri Dec 19 18:45:43 2014
From: vincenzoaellis at gmail.com (Vincenzo Ellis)
Date: Fri, 19 Dec 2014 15:45:43 -0200
Subject: [R-sig-ME] very different model estimates in GLM vs. GLMM
Message-ID: <CAGekO=2AEv4=w88tYPX=u8LXfopeRsrkK27+1j4iwoPGY6q-WA@mail.gmail.com>

Dear all,

I'm trying to model parasite prevalence in bird species as a function of
the nest height (factor) of those species. When I run a binomial GLM I get
estimates for each nest height level that are rather similar to the mean
observed prevalence at each level. However when I run a binomial GLMM with
taxonomic family as a random effect (intercept) one of the level estimates
differs greatly from the GLM estimates. I suspect the problem is that the
random effect has only one or two replicates per level (i.e., species), but
I want to confirm that I haven't made a mistake in coding. Data and code
follow. Thanks for any insights and for taking the time to help.

Vincenzo

*# the data*
data <- structure(list(Species_Code =
        structure(1:20, .Label = c("AMGO", "AMRO", "BGGN", "BHCO", "BRTH",
"CARW", "COYE", "EABL", "EAPH",
        "FISP", "HOFI", "HOSP", "INBU", "NOBO", "NOCA", "NOMO", "SOSP",
"TRES", "WEVI", "YBCH"), class =
          "factor"), n = c(19L, 5L, 5L, 6L, 8L, 16L, 32L, 4L, 4L, 27L, 4L,
12L, 50L, 4L, 36L, 9L, 5L,
        8L, 8L, 29L), taxonomic.family = structure(c(3L, 12L, 10L, 5L, 6L,
11L, 8L, 12L, 13L, 2L, 3L, 9L,
        1L, 7L, 1L, 6L, 2L, 4L, 14L, 8L), .Label = c("Cardinalidae",
"Emberizidae", "Fringillidae",
        "Hirundinidae", "Icteridae", "Mimidae", "Odontophoridae",
"Parulidae", "Passeridae", "Polioptilidae",
        "Troglodytidae", "Turdidae", "Tyrannidae", "Vireonidae"), class =
"factor"), Total.pos = c(1L, 3L, 2L, 2L,
        4L, 1L, 7L, 3L, 0L, 13L, 1L, 1L, 29L, 0L, 32L, 6L, 5L, 0L, 1L,
18L), Total.neg = c(18L, 2L, 3L, 4L, 4L, 15L,
        25L, 1L, 4L, 14L, 3L, 11L, 21L, 4L, 4L, 3L, 0L, 8L, 7L, 11L),
nest_ht2 = structure(c(3L, 2L, 3L, 3L, 2L, 2L,
        1L, 2L, 2L, 1L, 3L, 2L, 1L, 1L, 2L, 2L, 2L, 3L, 1L, 1L), .Label =
c("1", "2", "3"), class = "factor")),
        .Names = c("Species_Code", "n", "taxonomic.family", "Total.pos",
"Total.neg", "nest_ht2"),
        class = "data.frame", row.names = c(3L, 5L, 7L, 8L, 11L, 13L, 17L,
19L, 20L, 23L, 25L, 26L, 27L, 28L, 29L,
        30L, 34L, 37L, 40L, 43L))



*# when we look at the total prevalence across nest heights (i.e.,
nest_ht2) we see:*

require(plyr)
(observed <- ddply(data, "nest_ht2",
                  summarize, mean.prevalence =
                    mean(Total.pos/n)))


*# if we run a normal binomial GLM the estimates for each of the nest
heights are*

    # quick function to convert logit scale values to probabilities
probs <- function(x){
  exp(x)/(exp(x)+1)
}

model.basic <- glm(cbind(Total.pos, Total.neg) ~ 0 + nest_ht2,
family=binomial, data=data)
probs(coef(model.basic))


*# if we run a binomial GLMM with taxonomic.family as a random effect
(intercept), the estimates*
*# for each of the nest heights are*

require(lme4)
model.mixed <- glmer(cbind(Total.pos, Total.neg) ~ 0 + nest_ht2 +
(1|taxonomic.family),
                     family=binomial, data=data)
probs(fixef(model.mixed))


*# if we put all of these together we can see that the model.basic is
closer to the observed mean prevalence across*
*# nest heights than the model.mixed is. In particular, in the model.mixed
the estimate for the first level of nest *
*# height is much lower (0.14) than in the model.basic (0.45).*

data.frame(observed, model.basic = probs(coef(model.basic)), model.mixed =
probs(fixef(model.mixed)))


*# Could this difference between the GLM and the GLMM have to do with the
low number of replicates in each of the*
*# levels of the random effect (taxonomic.family)? Or is there a problem
with coding?*

arrange(ddply(data, "taxonomic.family", summarize,
taxonomic.family_sample_size = length(taxonomic.family)),
        desc(taxonomic.family_sample_size))

*# You can see that only six of the families have more than one species
sampled and none of those have more than two. If the*
*# problem really is the mixed effect model not having enough data, how
should one respond to reviewers who insist that*
*# taxonomy must be controlled for in such an analysis?*

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Fri Dec 19 23:33:54 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 19 Dec 2014 22:33:54 +0000
Subject: [R-sig-ME] very different model estimates in GLM vs. GLMM
In-Reply-To: <CAGekO=2AEv4=w88tYPX=u8LXfopeRsrkK27+1j4iwoPGY6q-WA@mail.gmail.com>
References: <CAGekO=2AEv4=w88tYPX=u8LXfopeRsrkK27+1j4iwoPGY6q-WA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427FD634EB8@inbomail.inbo.be>

Dear Vincenzo,

You are getting confused by the difference between a marginal and conditinal distribution. The glm returns the marginal distribution, while the glmm returns the conditional distribution. These distributions coindice with the gaussian distribution, but they don't with the binomial distribution.

I've put a example together to illustrate the difference between the marginal and conditional distribution in the binomial case. https://gist.github.com/anonymous/b1188a5cd3213132267a

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens Vincenzo Ellis [vincenzoaellis at gmail.com]
Verzonden: vrijdag 19 december 2014 18:45
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] very different model estimates in GLM vs. GLMM

Dear all,

I'm trying to model parasite prevalence in bird species as a function of
the nest height (factor) of those species. When I run a binomial GLM I get
estimates for each nest height level that are rather similar to the mean
observed prevalence at each level. However when I run a binomial GLMM with
taxonomic family as a random effect (intercept) one of the level estimates
differs greatly from the GLM estimates. I suspect the problem is that the
random effect has only one or two replicates per level (i.e., species), but
I want to confirm that I haven't made a mistake in coding. Data and code
follow. Thanks for any insights and for taking the time to help.

Vincenzo

*# the data*
data <- structure(list(Species_Code =
        structure(1:20, .Label = c("AMGO", "AMRO", "BGGN", "BHCO", "BRTH",
"CARW", "COYE", "EABL", "EAPH",
        "FISP", "HOFI", "HOSP", "INBU", "NOBO", "NOCA", "NOMO", "SOSP",
"TRES", "WEVI", "YBCH"), class =
          "factor"), n = c(19L, 5L, 5L, 6L, 8L, 16L, 32L, 4L, 4L, 27L, 4L,
12L, 50L, 4L, 36L, 9L, 5L,
        8L, 8L, 29L), taxonomic.family = structure(c(3L, 12L, 10L, 5L, 6L,
11L, 8L, 12L, 13L, 2L, 3L, 9L,
        1L, 7L, 1L, 6L, 2L, 4L, 14L, 8L), .Label = c("Cardinalidae",
"Emberizidae", "Fringillidae",
        "Hirundinidae", "Icteridae", "Mimidae", "Odontophoridae",
"Parulidae", "Passeridae", "Polioptilidae",
        "Troglodytidae", "Turdidae", "Tyrannidae", "Vireonidae"), class =
"factor"), Total.pos = c(1L, 3L, 2L, 2L,
        4L, 1L, 7L, 3L, 0L, 13L, 1L, 1L, 29L, 0L, 32L, 6L, 5L, 0L, 1L,
18L), Total.neg = c(18L, 2L, 3L, 4L, 4L, 15L,
        25L, 1L, 4L, 14L, 3L, 11L, 21L, 4L, 4L, 3L, 0L, 8L, 7L, 11L),
nest_ht2 = structure(c(3L, 2L, 3L, 3L, 2L, 2L,
        1L, 2L, 2L, 1L, 3L, 2L, 1L, 1L, 2L, 2L, 2L, 3L, 1L, 1L), .Label =
c("1", "2", "3"), class = "factor")),
        .Names = c("Species_Code", "n", "taxonomic.family", "Total.pos",
"Total.neg", "nest_ht2"),
        class = "data.frame", row.names = c(3L, 5L, 7L, 8L, 11L, 13L, 17L,
19L, 20L, 23L, 25L, 26L, 27L, 28L, 29L,
        30L, 34L, 37L, 40L, 43L))



*# when we look at the total prevalence across nest heights (i.e.,
nest_ht2) we see:*

require(plyr)
(observed <- ddply(data, "nest_ht2",
                  summarize, mean.prevalence =
                    mean(Total.pos/n)))


*# if we run a normal binomial GLM the estimates for each of the nest
heights are*

    # quick function to convert logit scale values to probabilities
probs <- function(x){
  exp(x)/(exp(x)+1)
}

model.basic <- glm(cbind(Total.pos, Total.neg) ~ 0 + nest_ht2,
family=binomial, data=data)
probs(coef(model.basic))


*# if we run a binomial GLMM with taxonomic.family as a random effect
(intercept), the estimates*
*# for each of the nest heights are*

require(lme4)
model.mixed <- glmer(cbind(Total.pos, Total.neg) ~ 0 + nest_ht2 +
(1|taxonomic.family),
                     family=binomial, data=data)
probs(fixef(model.mixed))


*# if we put all of these together we can see that the model.basic is
closer to the observed mean prevalence across*
*# nest heights than the model.mixed is. In particular, in the model.mixed
the estimate for the first level of nest *
*# height is much lower (0.14) than in the model.basic (0.45).*

data.frame(observed, model.basic = probs(coef(model.basic)), model.mixed =
probs(fixef(model.mixed)))


*# Could this difference between the GLM and the GLMM have to do with the
low number of replicates in each of the*
*# levels of the random effect (taxonomic.family)? Or is there a problem
with coding?*

arrange(ddply(data, "taxonomic.family", summarize,
taxonomic.family_sample_size = length(taxonomic.family)),
        desc(taxonomic.family_sample_size))

*# You can see that only six of the families have more than one species
sampled and none of those have more than two. If the*
*# problem really is the mixed effect model not having enough data, how
should one respond to reviewers who insist that*
*# taxonomy must be controlled for in such an analysis?*

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From vincenzoaellis at gmail.com  Sat Dec 20 16:25:44 2014
From: vincenzoaellis at gmail.com (Vincenzo Ellis)
Date: Sat, 20 Dec 2014 13:25:44 -0200
Subject: [R-sig-ME] very different model estimates in GLM vs. GLMM
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427FD634EB8@inbomail.inbo.be>
References: <CAGekO=2AEv4=w88tYPX=u8LXfopeRsrkK27+1j4iwoPGY6q-WA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427FD634EB8@inbomail.inbo.be>
Message-ID: <CAGekO=2cLOPdBzaKzTFooP3e-9p+K237ML45nmyS+9KTrgcyKQ@mail.gmail.com>

Dear Thierry,

Thank you so much for the example and explanation. I have just a few
follow-up questions for you or anyone else in the group if you have time.
Or if there is a good reference that I could be directed to, that would
also be great, as I clearly have some reading to do.

1. On what are the conditional distributions conditional? I noticed that in
the predict function in your code for the glmer model you set re.form equal
to ~0, which the help file for predict.merMod leads me to believe means
that the random effect in the model was not accounted for. So what is going
on there, i.e., what is the conditional distribution based on there?  And
are the fixed effects estimates from the glmer model conditional on the
random effect of the model?

2. If you had let the predict function for the glmer model use the random
effect from that model (e.g., re.form = NULL), how would it have worked?
Would it have compared observations that are in different levels of the
random effect somehow?

3. This last one has been asked before on this listserv (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q2/022258.html), and
that is how to make glmer give marginal probabilities instead of
conditional probabilities. The suggested answers apparently all ignore
random effects in the model. If you ignore the random effects in the glmer
model would the marginal probabilities be equivalent to those from a glm
model with no random effects?


Thanks again for all your help.

Vincenzo

On Fri, Dec 19, 2014 at 8:33 PM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be
> wrote:

> Dear Vincenzo,
>
> You are getting confused by the difference between a marginal and
> conditinal distribution. The glm returns the marginal distribution, while
> the glmm returns the conditional distribution. These distributions coindice
> with the gaussian distribution, but they don't with the binomial
> distribution.
>
> I've put a example together to illustrate the difference between the
> marginal and conditional distribution in the binomial case.
> https://gist.github.com/anonymous/b1188a5cd3213132267a
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ________________________________________
> Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens
> Vincenzo Ellis [vincenzoaellis at gmail.com]
> Verzonden: vrijdag 19 december 2014 18:45
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] very different model estimates in GLM vs. GLMM
>
> Dear all,
>
> I'm trying to model parasite prevalence in bird species as a function of
> the nest height (factor) of those species. When I run a binomial GLM I get
> estimates for each nest height level that are rather similar to the mean
> observed prevalence at each level. However when I run a binomial GLMM with
> taxonomic family as a random effect (intercept) one of the level estimates
> differs greatly from the GLM estimates. I suspect the problem is that the
> random effect has only one or two replicates per level (i.e., species), but
> I want to confirm that I haven't made a mistake in coding. Data and code
> follow. Thanks for any insights and for taking the time to help.
>
> Vincenzo
>
> *# the data*
> data <- structure(list(Species_Code =
>         structure(1:20, .Label = c("AMGO", "AMRO", "BGGN", "BHCO", "BRTH",
> "CARW", "COYE", "EABL", "EAPH",
>         "FISP", "HOFI", "HOSP", "INBU", "NOBO", "NOCA", "NOMO", "SOSP",
> "TRES", "WEVI", "YBCH"), class =
>           "factor"), n = c(19L, 5L, 5L, 6L, 8L, 16L, 32L, 4L, 4L, 27L, 4L,
> 12L, 50L, 4L, 36L, 9L, 5L,
>         8L, 8L, 29L), taxonomic.family = structure(c(3L, 12L, 10L, 5L, 6L,
> 11L, 8L, 12L, 13L, 2L, 3L, 9L,
>         1L, 7L, 1L, 6L, 2L, 4L, 14L, 8L), .Label = c("Cardinalidae",
> "Emberizidae", "Fringillidae",
>         "Hirundinidae", "Icteridae", "Mimidae", "Odontophoridae",
> "Parulidae", "Passeridae", "Polioptilidae",
>         "Troglodytidae", "Turdidae", "Tyrannidae", "Vireonidae"), class =
> "factor"), Total.pos = c(1L, 3L, 2L, 2L,
>         4L, 1L, 7L, 3L, 0L, 13L, 1L, 1L, 29L, 0L, 32L, 6L, 5L, 0L, 1L,
> 18L), Total.neg = c(18L, 2L, 3L, 4L, 4L, 15L,
>         25L, 1L, 4L, 14L, 3L, 11L, 21L, 4L, 4L, 3L, 0L, 8L, 7L, 11L),
> nest_ht2 = structure(c(3L, 2L, 3L, 3L, 2L, 2L,
>         1L, 2L, 2L, 1L, 3L, 2L, 1L, 1L, 2L, 2L, 2L, 3L, 1L, 1L), .Label =
> c("1", "2", "3"), class = "factor")),
>         .Names = c("Species_Code", "n", "taxonomic.family", "Total.pos",
> "Total.neg", "nest_ht2"),
>         class = "data.frame", row.names = c(3L, 5L, 7L, 8L, 11L, 13L, 17L,
> 19L, 20L, 23L, 25L, 26L, 27L, 28L, 29L,
>         30L, 34L, 37L, 40L, 43L))
>
>
>
> *# when we look at the total prevalence across nest heights (i.e.,
> nest_ht2) we see:*
>
> require(plyr)
> (observed <- ddply(data, "nest_ht2",
>                   summarize, mean.prevalence =
>                     mean(Total.pos/n)))
>
>
> *# if we run a normal binomial GLM the estimates for each of the nest
> heights are*
>
>     # quick function to convert logit scale values to probabilities
> probs <- function(x){
>   exp(x)/(exp(x)+1)
> }
>
> model.basic <- glm(cbind(Total.pos, Total.neg) ~ 0 + nest_ht2,
> family=binomial, data=data)
> probs(coef(model.basic))
>
>
> *# if we run a binomial GLMM with taxonomic.family as a random effect
> (intercept), the estimates*
> *# for each of the nest heights are*
>
> require(lme4)
> model.mixed <- glmer(cbind(Total.pos, Total.neg) ~ 0 + nest_ht2 +
> (1|taxonomic.family),
>                      family=binomial, data=data)
> probs(fixef(model.mixed))
>
>
> *# if we put all of these together we can see that the model.basic is
> closer to the observed mean prevalence across*
> *# nest heights than the model.mixed is. In particular, in the model.mixed
> the estimate for the first level of nest *
> *# height is much lower (0.14) than in the model.basic (0.45).*
>
> data.frame(observed, model.basic = probs(coef(model.basic)), model.mixed =
> probs(fixef(model.mixed)))
>
>
> *# Could this difference between the GLM and the GLMM have to do with the
> low number of replicates in each of the*
> *# levels of the random effect (taxonomic.family)? Or is there a problem
> with coding?*
>
> arrange(ddply(data, "taxonomic.family", summarize,
> taxonomic.family_sample_size = length(taxonomic.family)),
>         desc(taxonomic.family_sample_size))
>
> *# You can see that only six of the families have more than one species
> sampled and none of those have more than two. If the*
> *# problem really is the mixed effect model not having enough data, how
> should one respond to reviewers who insist that*
> *# taxonomy must be controlled for in such an analysis?*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> Disclaimer Bezoek onze website / Visit our website<
> https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
>

	[[alternative HTML version deleted]]


From may.amescua at gmail.com  Sun Dec 21 00:07:24 2014
From: may.amescua at gmail.com (Mayara Amescua)
Date: Sat, 20 Dec 2014 21:07:24 -0200
Subject: [R-sig-ME] Multiple comparisons with interaction
Message-ID: <CA+AVZMv0p-uByiCAjr9iy8xJC5+o3k9g2mZpFcNHxjTgdLAWYg@mail.gmail.com>

Hi everyone,

I'd like to do a multiple comparisons for a interaction between variables
and I tried to
create a new variable to use in the glmer model.

rec.m?s<-interaction(aag$rec,aag$m?s,data=aag,drop=TRUE)

But I got this message. I've tried to follow some texthelpers but
nothing worked.

Error in sort.list(y) : 'x' must be atomic for 'sort.list'

Have you called 'sort' on a list?

Does someone could help me how to solve it?

Let me know if you need more information.

Thanks,

Mayara

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Mon Dec 22 09:06:54 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 22 Dec 2014 08:06:54 +0000
Subject: [R-sig-ME] Multiple comparisons with interaction
In-Reply-To: <CA+AVZMv0p-uByiCAjr9iy8xJC5+o3k9g2mZpFcNHxjTgdLAWYg@mail.gmail.com>
References: <CA+AVZMv0p-uByiCAjr9iy8xJC5+o3k9g2mZpFcNHxjTgdLAWYg@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427FD63ADFB@inbomail.inbo.be>

Interaction() has no data argument. Try interaction(aag$rec, aag$m?s, drop = TRUE) or with(aag(interaction(rec, m?s, drop = TRUE))

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Mayara Amescua
Verzonden: zondag 21 december 2014 0:07
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Multiple comparisons with interaction

Hi everyone,

I'd like to do a multiple comparisons for a interaction between variables and I tried to create a new variable to use in the glmer model.

rec.m?s<-interaction(aag$rec,aag$m?s,data=aag,drop=TRUE)

But I got this message. I've tried to follow some texthelpers but nothing worked.

Error in sort.list(y) : 'x' must be atomic for 'sort.list'

Have you called 'sort' on a list?

Does someone could help me how to solve it?

Let me know if you need more information.

Thanks,

Mayara

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

From Thierry.ONKELINX at inbo.be  Mon Dec 22 09:22:58 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 22 Dec 2014 08:22:58 +0000
Subject: [R-sig-ME] very different model estimates in GLM vs. GLMM
In-Reply-To: <CAGekO=2cLOPdBzaKzTFooP3e-9p+K237ML45nmyS+9KTrgcyKQ@mail.gmail.com>
References: <CAGekO=2AEv4=w88tYPX=u8LXfopeRsrkK27+1j4iwoPGY6q-WA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427FD634EB8@inbomail.inbo.be>
	<CAGekO=2cLOPdBzaKzTFooP3e-9p+K237ML45nmyS+9KTrgcyKQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427FD63AEB1@inbomail.inbo.be>

Dear Vincenzo,

1. They are conditional on the random effects. Using re.form = ~ 0 gives predictions for the ?average? item, that is the item with random intercept = 0. It is NOT the average over all items. It only takes the fixed effects into account to make the **predictions**. Note that the fixed effects were fitted conditional on the random effects.
2. Re.form = NULL in my example would give a bunch of parallel curves. It would give predictions for the **observed** items.
3. No, that would still be conditional. If you need the marginal distribution, you need to integrate over the random effects. As Henrik pointed out in https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q2/022258.html.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

Van: Vincenzo Ellis [mailto:vincenzoaellis at gmail.com]
Verzonden: zaterdag 20 december 2014 16:26
Aan: ONKELINX, Thierry
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] very different model estimates in GLM vs. GLMM

Dear Thierry,

Thank you so much for the example and explanation. I have just a few follow-up questions for you or anyone else in the group if you have time. Or if there is a good reference that I could be directed to, that would also be great, as I clearly have some reading to do.

1. On what are the conditional distributions conditional? I noticed that in the predict function in your code for the glmer model you set re.form equal to ~0, which the help file for predict.merMod leads me to believe means that the random effect in the model was not accounted for. So what is going on there, i.e., what is the conditional distribution based on there?  And are the fixed effects estimates from the glmer model conditional on the random effect of the model?

2. If you had let the predict function for the glmer model use the random effect from that model (e.g., re.form = NULL), how would it have worked? Would it have compared observations that are in different levels of the random effect somehow?

3. This last one has been asked before on this listserv (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q2/022258.html), and that is how to make glmer give marginal probabilities instead of conditional probabilities. The suggested answers apparently all ignore random effects in the model. If you ignore the random effects in the glmer model would the marginal probabilities be equivalent to those from a glm model with no random effects?


Thanks again for all your help.

Vincenzo

On Fri, Dec 19, 2014 at 8:33 PM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
Dear Vincenzo,

You are getting confused by the difference between a marginal and conditinal distribution. The glm returns the marginal distribution, while the glmm returns the conditional distribution. These distributions coindice with the gaussian distribution, but they don't with the binomial distribution.

I've put a example together to illustrate the difference between the marginal and conditional distribution in the binomial case. https://gist.github.com/anonymous/b1188a5cd3213132267a

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens Vincenzo Ellis [vincenzoaellis at gmail.com]
Verzonden: vrijdag 19 december 2014 18:45
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] very different model estimates in GLM vs. GLMM

Dear all,

I'm trying to model parasite prevalence in bird species as a function of
the nest height (factor) of those species. When I run a binomial GLM I get
estimates for each nest height level that are rather similar to the mean
observed prevalence at each level. However when I run a binomial GLMM with
taxonomic family as a random effect (intercept) one of the level estimates
differs greatly from the GLM estimates. I suspect the problem is that the
random effect has only one or two replicates per level (i.e., species), but
I want to confirm that I haven't made a mistake in coding. Data and code
follow. Thanks for any insights and for taking the time to help.

Vincenzo

*# the data*
data <- structure(list(Species_Code =
        structure(1:20, .Label = c("AMGO", "AMRO", "BGGN", "BHCO", "BRTH",
"CARW", "COYE", "EABL", "EAPH",
        "FISP", "HOFI", "HOSP", "INBU", "NOBO", "NOCA", "NOMO", "SOSP",
"TRES", "WEVI", "YBCH"), class =
          "factor"), n = c(19L, 5L, 5L, 6L, 8L, 16L, 32L, 4L, 4L, 27L, 4L,
12L, 50L, 4L, 36L, 9L, 5L,
        8L, 8L, 29L), taxonomic.family = structure(c(3L, 12L, 10L, 5L, 6L,
11L, 8L, 12L, 13L, 2L, 3L, 9L,
        1L, 7L, 1L, 6L, 2L, 4L, 14L, 8L), .Label = c("Cardinalidae",
"Emberizidae", "Fringillidae",
        "Hirundinidae", "Icteridae", "Mimidae", "Odontophoridae",
"Parulidae", "Passeridae", "Polioptilidae",
        "Troglodytidae", "Turdidae", "Tyrannidae", "Vireonidae"), class =
"factor"), Total.pos = c(1L, 3L, 2L, 2L,
        4L, 1L, 7L, 3L, 0L, 13L, 1L, 1L, 29L, 0L, 32L, 6L, 5L, 0L, 1L,
18L), Total.neg = c(18L, 2L, 3L, 4L, 4L, 15L,
        25L, 1L, 4L, 14L, 3L, 11L, 21L, 4L, 4L, 3L, 0L, 8L, 7L, 11L),
nest_ht2 = structure(c(3L, 2L, 3L, 3L, 2L, 2L,
        1L, 2L, 2L, 1L, 3L, 2L, 1L, 1L, 2L, 2L, 2L, 3L, 1L, 1L), .Label =
c("1", "2", "3"), class = "factor")),
        .Names = c("Species_Code", "n", "taxonomic.family", "Total.pos",
"Total.neg", "nest_ht2"),
        class = "data.frame", row.names = c(3L, 5L, 7L, 8L, 11L, 13L, 17L,
19L, 20L, 23L, 25L, 26L, 27L, 28L, 29L,
        30L, 34L, 37L, 40L, 43L))


*# when we look at the total prevalence across nest heights (i.e.,
nest_ht2) we see:*

require(plyr)
(observed <- ddply(data, "nest_ht2",
                  summarize, mean.prevalence =
                    mean(Total.pos/n)))


*# if we run a normal binomial GLM the estimates for each of the nest
heights are*

    # quick function to convert logit scale values to probabilities
probs <- function(x){
  exp(x)/(exp(x)+1)
}

model.basic <- glm(cbind(Total.pos, Total.neg) ~ 0 + nest_ht2,
family=binomial, data=data)
probs(coef(model.basic))


*# if we run a binomial GLMM with taxonomic.family as a random effect
(intercept), the estimates*
*# for each of the nest heights are*

require(lme4)
model.mixed <- glmer(cbind(Total.pos, Total.neg) ~ 0 + nest_ht2 +
(1|taxonomic.family),
                     family=binomial, data=data)
probs(fixef(model.mixed))


*# if we put all of these together we can see that the model.basic is
closer to the observed mean prevalence across*
*# nest heights than the model.mixed is. In particular, in the model.mixed
the estimate for the first level of nest *
*# height is much lower (0.14) than in the model.basic (0.45).*

data.frame(observed, model.basic = probs(coef(model.basic)), model.mixed =
probs(fixef(model.mixed)))


*# Could this difference between the GLM and the GLMM have to do with the
low number of replicates in each of the*
*# levels of the random effect (taxonomic.family)? Or is there a problem
with coding?*

arrange(ddply(data, "taxonomic.family", summarize,
taxonomic.family_sample_size = length(taxonomic.family)),
        desc(taxonomic.family_sample_size))

*# You can see that only six of the families have more than one species
sampled and none of those have more than two. If the*
*# problem really is the mixed effect model not having enough data, how
should one respond to reviewers who insist that*
*# taxonomy must be controlled for in such an analysis?*

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

From alberto.gc8 at gmail.com  Sun Dec 21 23:59:09 2014
From: alberto.gc8 at gmail.com (Alberto Gallano)
Date: Sun, 21 Dec 2014 17:59:09 -0500
Subject: [R-sig-ME] MCMCglmm priors and random effects for phylogenetic
	mixed model
Message-ID: <CAO+b4j8ubheLUabLmvUXgHuHY8OvS4e3wKoN74w-6VsPqJq5Rw@mail.gmail.com>

I have a question about prior and random effects specification for a
phylogenetic mixed model. I am fitting a linear mixed model using MCMCglmm,
accounting for phylogenetic dependence in the residuals. My fixed effects
are two continuous variables (ratios of central and lateral incisor width
to first molar length) in various species of animals (n = 106). I have
measurements for multiple individuals within each species (ranging from n=3
to n=110). I am mainly interested in the among-species slope and intercept.
Therefore, I have used the methods outlined in (van der Pol & Wright, 2009)
to split the explanatory variable into two: one with species means, the
other within-species centered. This disentangles effects for within- and
between species. For random effects, I am fitting random intercepts for the
species level phylogenetic random effect (called "phylo"), random
intercepts for the species level non-phylogenetic random effect (called
"species"), and random slopes for the within-species centered variable.

I have two questions:

1) I want to a model that allows random slopes to vary for each species,
but i'm not sure if I have this specified correctly? Also, should the
random slopes be coupled with the "species" or "phylo" random effect?

2) What is a good prior for the random slope / random intercept (here G2)?
I'm not sure whether this is specified correctly (e.g., should I used
parameter expanded priors)?

Here are the priors and model:

priors1 <- list(
    B = list(mu = rep(0, 3), V = diag(9, 3)),
    G = list(G1 = list(V = 1, nu = 0.002), G2 = list(V = diag(2)/2, nu =
0.002)),
    R = list(V = 1, nu = 0.002)
    )

# parameter expanded version
priors2 <- list(
    B = list(mu = rep(0, 3), V = diag(9, 3)),
    G = list(G1 = list(V = 1, nu = 0.002),
             G2 = list(V = diag(2)/2, nu = 2, alpha.mu = rep(0, 2), alpha.V
= diag(500, 2, 2))),
    R = list(V = 1, nu = 0.002)
    )

# inverse of sigma matrix of phylogenetic correlation
inv_phylo_mat <- inverseA(tree, nodes = "TIPS", scale = TRUE)

fit <- MCMCglmm(
    fixed = I1.M1 ~ I2.M1.species.mean + I2.M1.within.species,
    rcov = ~ units,
    random = ~ phylo + idh(1+I2.M1.within.species):species,
    data = incisor.dat,
    family = "gaussian",
    ginverse = list(phylo = inv_phylo_mat$Ainv),
    prior = priors1,
    pr = TRUE,
    pl = TRUE,
    nitt = 1.1e+6, thin = 10, burnin = 1e+5,
    verbose = FALSE
    )


best,
Alberto

	[[alternative HTML version deleted]]


From alberto.gc8 at gmail.com  Mon Dec 22 01:27:17 2014
From: alberto.gc8 at gmail.com (Alberto Gallano)
Date: Sun, 21 Dec 2014 19:27:17 -0500
Subject: [R-sig-ME] Bayesian hypothesis testing using MCMCglmm
Message-ID: <CAO+b4j-66TG_=FtpPoMG8xDnXM=zdb9zyxH6gz5QDpCBT5=Ghw@mail.gmail.com>

I'm fitting a linear mixed model using MCMCglmm and I want to determine the
probability that some a prior hypotheses I have about the slope and
intercept of the fixed effects are true. The slope estimate from my fitted
model is 1.21 (HDI 1.04, 1.38), while the intercept is -0.68 (HDI -0.46,
-0.93). I want to calculate the probability of getting a slope of 1 and an
intercept of -0.5.

One of the often touted main differences between frequentist and Bayesian
frameworks is the latter's ability to quantify the probability of a
hypothesis, given data. From what i've read, there seems to be two main
approaches to operationalizing this:

1) model comparison, where one model is fitted with a very narrow,
"spiked", prior for the hypothesis under consideration and another model
fitted with a much broader prior. The DICs from each model are presumably
then compared to determine which is better. I don't really understand where
the probability for the hypothesis comes from here.

2) determine a Region of Practical Equivalence (ROPE) around the hypothesis
to be tested, then see if the 95% HDI is encompassed within this region or
vice versa. Again, I don't really understand where the probability for the
hypothesis comes from here.

If I were doing this in a frequentist framework, i'd see if the 95% CI of
my estimates encompassed the hypothesized slope/intercept, and use that as
a hypothesis test. In a Bayesian framework, I should (I think) be able to
do better than that and actually get a probability for the hypothesized
slope/intercept, given the data.

My question is, how would I do this in practice, using MCMCglmm?

My model is below:

priors1 <- list(
    B = list(mu = rep(0, 3), V = diag(9, 3)),
    G = list(G1 = list(V = 1, nu = 0.002), G2 = list(V = diag(2)/2, nu =
0.002)),
    R = list(V = 1, nu = 0.002)
    )

# inverse of sigma matrix of phylogenetic correlation
inv_phylo_mat <- inverseA(tree, nodes = "TIPS", scale = TRUE)

fit <- MCMCglmm(
    fixed = I1.M1 ~ I2.M1.species.mean + I2.M1.within.species,
    rcov = ~ units,
    random = ~ phylo + idh(1+I2.M1.within.species):species,
    data = incisor.dat,
    family = "gaussian",
    ginverse = list(phylo = inv_phylo_mat$Ainv),
    prior = priors1,
    pr = TRUE,
    pl = TRUE,
    nitt = 1.1e+6, thin = 10, burnin = 1e+5,
    verbose = FALSE
    )

best,
Alberto

	[[alternative HTML version deleted]]


From jackiewood7 at gmail.com  Tue Dec 23 21:17:47 2014
From: jackiewood7 at gmail.com (Jackie Wood)
Date: Tue, 23 Dec 2014 15:17:47 -0500
Subject: [R-sig-ME] Meta-analysis for heritability using MCMCglmm?
Message-ID: <CAOxxGR=8rvPJTiHPjVYJNaCDZcUH0medNnk+fba2bONrX8kS2Q@mail.gmail.com>

Dear R-users,

I am attempting to conduct a meta-analysis to investigate the relationship
of narrow-sense heritability with population size. In previous work, I have
used MCMCglmm to conduct a formal meta-analysis which allowed me to account
for the effect of sampling error through the argument "mev". This was
relatively easy to do for a continuous response variable, however,
heritability is presented as a proportion and is therefore bounded by 0 and
1 which clearly changes the situation.

In fact, I am not actually certain if it possible to conduct a formal
weighted meta-analysis on the heritability data using MCMCglmm. I have seen
elsewhere where data presented as a proportion (survival, yolk-conversion
efficiency for example) has been logit transformed and fitted using a
Gaussian error distribution (though this was done using REML rather than
Bayesian modelling) but I don't know if this is a legitimate strategy for a
formal meta-analysis using heritability as a response variable since any
transformation applied to the heritability data would also need to be
applied to the standard errors?

I would greatly appreciate any advice on this matter!

Cheers,
Jackie

-- 
Jacquelyn L.A. Wood, PhD.
Biology Department
Concordia University
7141 Sherbrooke St. West
Montreal, QC
H4B 1R6
Phone: (514) 293-7255

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Wed Dec 24 02:30:03 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 24 Dec 2014 12:30:03 +1100
Subject: [R-sig-ME] Meta-analysis for heritability using MCMCglmm?
In-Reply-To: <CAOxxGR=8rvPJTiHPjVYJNaCDZcUH0medNnk+fba2bONrX8kS2Q@mail.gmail.com>
References: <CAOxxGR=8rvPJTiHPjVYJNaCDZcUH0medNnk+fba2bONrX8kS2Q@mail.gmail.com>
Message-ID: <CAF5_5cyX-HYrnrO1qDvP2+CsRWTaRpVU8BgpGe9sR+bf8LRiRg@mail.gmail.com>

If you have the original data giving the numerator and denominator for the
proportion then it is binomial data, and can be modelled in a met-analysis.
I don't know if this can be done with MCMCglmm but should be possible with
STAN, JAGS or BUGS. All will require a bit of effort in setting up the
model.

On 24 December 2014 at 07:17, Jackie Wood <jackiewood7 at gmail.com> wrote:

> Dear R-users,
>
> I am attempting to conduct a meta-analysis to investigate the relationship
> of narrow-sense heritability with population size. In previous work, I have
> used MCMCglmm to conduct a formal meta-analysis which allowed me to account
> for the effect of sampling error through the argument "mev". This was
> relatively easy to do for a continuous response variable, however,
> heritability is presented as a proportion and is therefore bounded by 0 and
> 1 which clearly changes the situation.
>
> In fact, I am not actually certain if it possible to conduct a formal
> weighted meta-analysis on the heritability data using MCMCglmm. I have seen
> elsewhere where data presented as a proportion (survival, yolk-conversion
> efficiency for example) has been logit transformed and fitted using a
> Gaussian error distribution (though this was done using REML rather than
> Bayesian modelling) but I don't know if this is a legitimate strategy for a
> formal meta-analysis using heritability as a response variable since any
> transformation applied to the heritability data would also need to be
> applied to the standard errors?
>
> I would greatly appreciate any advice on this matter!
>
> Cheers,
> Jackie
>
> --
> Jacquelyn L.A. Wood, PhD.
> Biology Department
> Concordia University
> 7141 Sherbrooke St. West
> Montreal, QC
> H4B 1R6
> Phone: (514) 293-7255
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From Thierry.ONKELINX at inbo.be  Wed Dec 24 08:26:31 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 24 Dec 2014 07:26:31 +0000
Subject: [R-sig-ME] [R] nlme package: changing reference for varIdent
 parameter estimates in summary.gls
In-Reply-To: <428E87A3-54D5-4D33-B9B3-B0ECA41EE877@ucsf.edu>
References: <428E87A3-54D5-4D33-B9B3-B0ECA41EE877@ucsf.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA7427FD63D655@inbomail.inbo.be>

Dear John,

R-sig-mixed-models is more suited for this kind of questions. All follow-up mail should be posted only to that mailing list.

It seems like varIdent() by default relevels the grouping factor and that the user cannot control this.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-help [mailto:r-help-bounces at r-project.org] Namens Kornak, John
Verzonden: dinsdag 23 december 2014 22:29
Aan: r-help at R-project.org
Onderwerp: [R] nlme package: changing reference for varIdent parameter estimates in summary.gls


Dear R experts,

I am running gls models with heterogeneous group variances using the glm function in the nlme package with varIdent weights. I am interested in controlling the baseline level for the group variance function standard deviation estimates by applying the relevel function to the group variable. When I use relevel, the baseline level in the coefficient table changes as expected, but the baseline level does not change for the variance function table; for example, see the fitted models gls1 vs. gls2 in the contrived example below. Does anyone have a suggestion as to how I can change the baseline level for the variance function output please? In addition to the example below, I have tried specifying the value argument as per the varIdent help page, e.g. variIdent(c(no=0.5), form = ~1|group) and have google searched / checked help pages for solutions without success.

I am running R version 3.1.0 on an iMac OSX v. 10.9.5

Thank you in advance

John Kornak

> library(nlme)
> group <- factor(c(rep("no",20),rep("yes",20)))
> set.seed(2)
> outcome <- c(rnorm(20,0,2),rnorm(20,5,4)) dataTest <-
> data.frame(outcome,group)

# Original model fit before releveling
> gls1 <- gls(outcome ~ group, weights=varIdent(form = ~1|group),
> data=dataTest)
> summary(gls1)

  snip

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
     no     yes
1.00000 2.23034

Coefficients:
               Value Std.Error  t-value p-value
(Intercept) 0.390922 0.4734001 0.825775  0.4141
groupyes    4.607951 1.1571140 3.982279  0.0003

  snip

Residual standard error: 2.11711
Degrees of freedom: 40 total; 38 residual


# relevel the group so that  yes  is the reference
> dataTest$group <- relevel(dataTest$group,"yes")
> gls2 <- gls(outcome ~ group, weights=varIdent(form = ~1|group),
> data=dataTest)
> summary(gls2)

  snip

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
     no     yes
1.00000 2.23034                 ###  no" is still the reference group here for the variance function

Coefficients:
                Value Std.Error   t-value p-value
(Intercept)  4.998873  1.055843  4.734484   0e+00
groupno     -4.607951  1.157114 -3.982279   3e-04  #  yes  has become the reference for the coefficients

   snip

Residual standard error: 2.11711
Degrees of freedom: 40 total; 38 residual
>

---------------------------------------------------
John Kornak, PhD
Associate Professor in Residence
Department of Epidemiology and Biostatistics University of California, San Francisco Mission Hall: Global Health & Clinical Sciences Building
550 16th St, 2nd floor, Box #0560
San Francisco, CA 94158-2549
Tel: 415-514-8028
Fax: 415-514-8150
Email: john.kornak at ucsf.edu<mailto:john.kornak at ucsf.edu>




        [[alternative HTML version deleted]]

Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

From may.amescua at gmail.com  Wed Dec 24 14:24:40 2014
From: may.amescua at gmail.com (Mayara Amescua)
Date: Wed, 24 Dec 2014 11:24:40 -0200
Subject: [R-sig-ME] Multivariate analysis for proportional data
Message-ID: <CA+AVZMvFFAiNb9DShFtgC64NHrxiqLqgm5teVny6Ch7y7Af8=g@mail.gmail.com>

Dear List-members,

I have a data set owing some response variables with proportional values
and independent variables of mixed effect.  How it is possible performing a
multivariate analysis of this type once the MCMCglmm package doesn't allow
for binomial family?

Any help would be greatly appreciated.

Mayara Amescua

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Dec 24 16:00:00 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 24 Dec 2014 10:00:00 -0500
Subject: [R-sig-ME] Multivariate analysis for proportional data
In-Reply-To: <CA+AVZMvFFAiNb9DShFtgC64NHrxiqLqgm5teVny6Ch7y7Af8=g@mail.gmail.com>
References: <CA+AVZMvFFAiNb9DShFtgC64NHrxiqLqgm5teVny6Ch7y7Af8=g@mail.gmail.com>
Message-ID: <549AD4F0.3040607@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-24 08:24 AM, Mayara Amescua wrote:
> Dear List-members,
> 
> I have a data set owing some response variables with proportional
> values and independent variables of mixed effect.  How it is
> possible performing a multivariate analysis of this type once the
> MCMCglmm package doesn't allow for binomial family?
> 
> Any help would be greatly appreciated.
> 
> Mayara Amescua
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

  MCMCglmm does allow for the binomial family, it's just called
family="categorical" (for binary responses) or family="multinomial2"
(for N>1)
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUmtTwAAoJEOCV5YRblxUH2CEH/3Q5oyu6IT8lxD2zjcg7PBXE
N8hinIB7UWIxNSGIOkSDzh7W8o7VsuDZJI3rSRvzRSlwwkPN65TvdeVCzsHC0JkA
s3l6j3+7spTe8o738gi6077UyjTITYLGYyDuuF0RnAx7eQaBIeF5EQ+q+TlzPS4E
KfscB/ujnBo2ojnDj7xVQaXTJIQ2kpQAyFmE7tDlUQ+fkPaetvf3fPJNSN2c4Ffe
ZU6j6nN5qCyP+eY7hKe+T67jfeyhndBsOprOEaxxxtbaU2L9N+Nt0E1NwZ8dzSNN
PBK0uxgQWuA4h43imumastondeqa5IbcuTF6Wh9cLxLlv1jt70SUqRSLZgaCNlU=
=3ZPH
-----END PGP SIGNATURE-----


From rshepard at appl-ecosys.com  Wed Dec 24 16:05:36 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 24 Dec 2014 07:05:36 -0800 (PST)
Subject: [R-sig-ME] Multivariate analysis for proportional data
In-Reply-To: <CA+AVZMvFFAiNb9DShFtgC64NHrxiqLqgm5teVny6Ch7y7Af8=g@mail.gmail.com>
References: <CA+AVZMvFFAiNb9DShFtgC64NHrxiqLqgm5teVny6Ch7y7Af8=g@mail.gmail.com>
Message-ID: <alpine.LNX.2.11.1412240656360.3835@localhost>

On Wed, 24 Dec 2014, Mayara Amescua wrote:

> I have a data set owing some response variables with proportional values
> and independent variables of mixed effect. How it is possible performing a
> multivariate analysis of this type once the MCMCglmm package doesn't allow
> for binomial family?

Mayara,

   If your data are proportions you should look carefully at compositional
data analysis (CoDA). There are seveal R packages for this, including
'compositions', 'robCompositions' (robust compositions), and
'zCompositions'. For documention and lerning there are the 'Lecture Notes on
Compositoinsl Data Anayis' by Pawlowsky-Glahn, V., Egozcue, J. J., and
Tolosana-Delgado, R. (available as a PDF but I don't recall the URL
off-hand); 'Analyzing Compositional Data with R' by van den Boogaart, K.G.
and Tolosana-Delgado, R.; and 'A Concise Guide to Compositional Data
Analysis' by John Aitchison, also available as a PDF.

Happy learning,

Rich


From r.turner at auckland.ac.nz  Wed Dec 24 22:14:34 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 25 Dec 2014 10:14:34 +1300
Subject: [R-sig-ME] Multivariate analysis for proportional data
In-Reply-To: <alpine.LNX.2.11.1412240656360.3835@localhost>
References: <CA+AVZMvFFAiNb9DShFtgC64NHrxiqLqgm5teVny6Ch7y7Af8=g@mail.gmail.com>
	<alpine.LNX.2.11.1412240656360.3835@localhost>
Message-ID: <549B2CBA.20801@auckland.ac.nz>

On 25/12/14 04:05, Rich Shepard wrote:
> On Wed, 24 Dec 2014, Mayara Amescua wrote:
>
>> I have a data set owing some response variables with proportional values
>> and independent variables of mixed effect. How it is possible
>> performing a
>> multivariate analysis of this type once the MCMCglmm package doesn't
>> allow
>> for binomial family?
>
> Mayara,
>
>    If your data are proportions you should look carefully at compositional
> data analysis (CoDA). There are seveal R packages for this, including
> 'compositions', 'robCompositions' (robust compositions), and
> 'zCompositions'. For documention and lerning there are the 'Lecture
> Notes on
> Compositoinsl Data Anayis' by Pawlowsky-Glahn, V., Egozcue, J. J., and
> Tolosana-Delgado, R. (available as a PDF but I don't recall the URL
> off-hand); 'Analyzing Compositional Data with R' by van den Boogaart, K.G.
> and Tolosana-Delgado, R.; and 'A Concise Guide to Compositional Data
> Analysis' by John Aitchison, also available as a PDF.

I am of course prejudiced, but I think that in respect of compositional 
data analysis one would be well-advised to have a read of "Colours and
Cocktails:  Compositional Data Analysis.  2013 Lancaster Lecture" by
J. L. Sealy and A. H. Welsh, Aust. & N. Z. J. Statist., vol. 56, 2014,
pp. 145 -- 169.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From john.kornak at ucsf.edu  Wed Dec 24 23:34:09 2014
From: john.kornak at ucsf.edu (Kornak, John)
Date: Wed, 24 Dec 2014 22:34:09 +0000
Subject: [R-sig-ME] nlme package: changing reference for varIdent parameter
 estimates in summary.gls
Message-ID: <5D011804-2D94-49DE-AC5A-48DB9578DE0A@ucsf.edu>


Dear R mixed-effects modeling experts,

I am running gls models with heterogeneous group variances using the glm function in the nlme package with varIdent weights. I am interested in controlling the baseline level for the group variance function standard deviation estimates by applying the relevel function to the group variable. When I use relevel, the baseline level in the coefficient table changes as expected, but the baseline level does not change for the variance function table; for example, see the fitted models gls1 vs. gls2 in the contrived example below. Does anyone have a suggested hack as to how I can change the baseline level for the variance function output please? One hack I have made work is to change the order of the rows in the data (see final part of example), but that seems rather ugly and will get painful for the real data I am working with for which I need to reset many different reference levels.

I have google searched / checked help pages for other solutions without success.

I am running R version 3.1.0 on an iMac OSX v. 10.9.5

Thank you in advance and happy holidays!

John Kornak

> library(nlme)
> group <- factor(c(rep("no",20),rep("yes",20)))
> set.seed(2)
> outcome <- c(rnorm(20,0,2),rnorm(20,5,4))
> dataTest <- data.frame(outcome,group)

# Original model fit before releveling
> gls1 <- gls(outcome ~ group, weights=varIdent(form = ~1|group), data=dataTest)
> summary(gls1)

? snip ?

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
     no     yes
1.00000 2.23034

Coefficients:
               Value Std.Error  t-value p-value
(Intercept) 0.390922 0.4734001 0.825775  0.4141
groupyes    4.607951 1.1571140 3.982279  0.0003

 ?snip ?

Residual standard error: 2.11711
Degrees of freedom: 40 total; 38 residual


# relevel the group so that ?yes? is the reference
> dataTest$group <- relevel(dataTest$group,"yes")
> gls2 <- gls(outcome ~ group, weights=varIdent(form = ~1|group), data=dataTest)
> summary(gls2)

? snip ?

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
     no     yes
1.00000 2.23034                 ### ?no" is still the reference group here for the variance function

Coefficients:
                Value Std.Error   t-value p-value
(Intercept)  4.998873  1.055843  4.734484   0e+00
groupno     -4.607951  1.157114 -3.982279   3e-04  # ?yes? has become the reference for the coefficients

 ? snip ?

Residual standard error: 2.11711
Degrees of freedom: 40 total; 38 residual
>


# Reorganize the data so that the group == ?yes" entries come first
> dataTest2 <- dataTest[c(21:40,1:20), ]
> gls3 <- gls(outcome ~ group, weights=varIdent(value = c(yes = 0.5), form = ~1|group), data=dataTest2)
> summary(gls3)

? snip ?

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
      yes        no
1.0000000 0.4483626           ## now I have the desired ?yes? as reference level

Coefficients:
                Value Std.Error   t-value p-value
(Intercept)  4.998873  1.055843  4.734487   0e+00
groupno     -4.607951  1.157113 -3.982281   3e-04   # and ?yes? also reference level here

? snip ?

Residual standard error: 4.721872
Degrees of freedom: 40 total; 38 residual
>

---------------------------------------------------
John Kornak, PhD
Associate Professor in Residence
Department of Epidemiology and Biostatistics
University of California, San Francisco
Mission Hall: Global Health & Clinical Sciences Building
550 16th St, 2nd floor, Box #0560
San Francisco, CA 94158-2549
Tel: 415-514-8028
Fax: 415-514-8150
Email: john.kornak at ucsf.edu<mailto:john.kornak at ucsf.edu>



	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Fri Dec 26 07:12:39 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 26 Dec 2014 06:12:39 +0000
Subject: [R-sig-ME] Fixing phylogenetic heritability in MCMCglmm
In-Reply-To: <CAErHMT26X6J=kXCYe8juVEs1E3SQ3ShzA8LyxkeJaXR=23Wf=g@mail.gmail.com>
References: <CAErHMT26X6J=kXCYe8juVEs1E3SQ3ShzA8LyxkeJaXR=23Wf=g@mail.gmail.com>
Message-ID: <20141226061239.15704j869tg2ww4k@www.staffmail.ed.ac.uk>

Hi Manabu,

In the CRAN version it is not possible, but I have a version I can  
share that allows you to do this using a reduced mixed model  
parameterisation. What distribution is the response?

Cheers,

Jarrod




Quoting Manabu Sakamoto <manabu.sakamoto at gmail.com> on Tue, 16 Dec  
2014 21:48:44 +0000:

> Dear list,
>
> Does anyone know how to fix the heritability of the phylogenetic random
> effect in MCMCglmm in a way that is the equivalent to fixing the
> phylogenetic signal lambda to 1?
>
> I want all the variance attributed to phylogeny to remain fixed and
> unaffected by additional random effects, i.e., I want the additional random
> effects to work on the residual variance once phylogeny is accounted for.
>
> many thanks,
> Manabu
>
> --
> Manabu Sakamoto, PhD
> manabu.sakamoto at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Dec 26 07:36:16 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 26 Dec 2014 06:36:16 +0000
Subject: [R-sig-ME] Repeated Measures in MCMCglmm model
In-Reply-To: <CAO=0ZJUEJ4d53ZFNgXgtwBfam29Q-ZzXv2evtZab39X5YGQjMg@mail.gmail.com>
References: <CAO=0ZJUEJ4d53ZFNgXgtwBfam29Q-ZzXv2evtZab39X5YGQjMg@mail.gmail.com>
Message-ID: <20141226063616.18293aw785lp8ji8@www.staffmail.ed.ac.uk>

Hi Tricia,

How do you define plasticity, as the slope of the regression of oxygen  
consumption on temperature, acclimation temperature or some aspect of  
both?


If it was temperature I would fit the random effect term  
us(1+temp):species which allows different species to have different  
levels of plasticity which is phylogentically correlated. However,  
with 18 (?) species it is going to be hard to get precise estimates of  
how variable plasticity is across different species.

Its not clear whether you have multiple individuals per species? If  
there is only one individual per species then us(1+temp):ID models  
between-species variation in plasticity not determined by phylogeny  
and any between individual (within-species) variation in plasticity.  
If you have multiple individuals per species then you could separate  
these two effects.

Also, does your code work?  You have associated the A inverse with  
species but then fitted animal in your random model  - you should have  
species in the random model rather than animal.

Cheers,

Jarrod




Quoting Tricia Markle <markl033 at umn.edu> on Wed, 17 Dec 2014 23:41:58 -0600:

> Hello,
>
>
>
> I am hoping to find someone familiar with the R code for taking repeated
> measures into account in a MCMCglmm model. I have put together a working
> code (see below) based on a couple of examples that I found (adding ?ID? as
> a random term), but remain unsure if it is the best approach.
>
>
> My study is investigating whether wide-ranging species of salamander have a
> greater degree of plasticity in oxygen consumption (i.e. metabolic rate) at
> different acclimation temperatures than narrow-ranging species. The same
> individuals were tested at each of three acclimation temperatures (6, 14,
> and 22C). Each acclimation temperature had 3 separate respirometry tests to
> measure oxygen consumption (5, 15, and 25C) for a total of 9 tests per
> individual.
>
>
> *R script:*
>
> library(MCMCglmm)
> dataset<-read.csv(file="RData.csv", head=TRUE)
> dataset$Range<-as.factor(dataset$Range)
> str(dataset)
>
> #Phylogeny Component
> tree<-read.tree("Plethodontidae_comb61_PL.phy")
> species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
> "D._imitator_KHK05", "D._ochrophaeus_WKS05", "D._ocoee_B_KHK62",
> "D._orestes_KHK129",  "D._monticola_A",  "D._santeetlah_11775",
> "P_cinereus", "P_cylindraceus", "P_glutinosus", "P_hubrichti",
> "P_montanus", "P_punctatus", "P_richmondi", "P_teyahalee", "P_virginia",
> "P_wehrlei")
> pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
> tree$tip.label)])# Prune tree to just include species of interest
> sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node") #rename
> nodes to be unique
> plot(sptree, show.node.label=TRUE)
>
> treeAinv<-inverseA(sptree)$Ainv
>
> #For Repeated Measures
> dataset$ID<-dataset$animal
> head(dataset)
> p.var<-var(dataset$LVO2, na.rm=TRUE)
>
>
> #Prior
>
> prior<-list(G=list(G1=list(V=1, n=0.002), G2=list(V=1, n=0.002)),
> R=list(V=1, n=0.002))
>
> #Model 1 with Range Size
> model1<-MCMCglmm(LVO2~1+Acclm+Temp+LMass+Sex+Range+Acclm*Temp*Range,
> random=~animal+ID, data=dataset, ginverse=list(species=treeAinv),
> nodes="ALL", prior=prior, nitt=300000, burnin=25000, thin = 1000,
> verbose=FALSE)
>
>
>
>
> *Sincerely, *
>
>
>  *Tricia Markle*
>
> *PhD Candidate, **University of Minnesota*
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Dec 26 07:50:15 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 26 Dec 2014 06:50:15 +0000
Subject: [R-sig-ME] MCMCglmm priors and random effects for phylogenetic
 mixed model
In-Reply-To: <CAO+b4j8ubheLUabLmvUXgHuHY8OvS4e3wKoN74w-6VsPqJq5Rw@mail.gmail.com>
References: <CAO+b4j8ubheLUabLmvUXgHuHY8OvS4e3wKoN74w-6VsPqJq5Rw@mail.gmail.com>
Message-ID: <20141226065015.124611gwbjfox0kg@www.staffmail.ed.ac.uk>

Hi Alberto,

1/ You can fit it at both levels if you like:

us(1+I2.M1.within.species):phylo + us(1+I2.M1.within.species):species

where the first term models between-species phylogentically correlated  
variation in intercepts and slopes  and the second term models  
between-species variation in intercepts and slopes that is not  
phylogenetically correlated. However, you have to be quite careful  
with the van der Pol & Wright method because measurement error in the  
species means (which will be high when n=3) can appear as random  
variation in slopes. The section "Within-Population Slope  
Heterogeneity" in this paper:

http://www.pnas.org/content/107/18/8292.full

discusses the problem, but unfortunately without a good resolution.

2/ I generally use parameter expanded priors of the form:

G2 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V= diag(500, 2, 2))

note V is an identity matrix rather than I*0.5. However, you should  
check to make sure you don't get big changes when you use other types  
of prior.

Cheers,

Jarrod







Quoting Alberto Gallano <alberto.gc8 at gmail.com> on Sun, 21 Dec 2014  
17:59:09 -0500:

> I have a question about prior and random effects specification for a
> phylogenetic mixed model. I am fitting a linear mixed model using MCMCglmm,
> accounting for phylogenetic dependence in the residuals. My fixed effects
> are two continuous variables (ratios of central and lateral incisor width
> to first molar length) in various species of animals (n = 106). I have
> measurements for multiple individuals within each species (ranging from n=3
> to n=110). I am mainly interested in the among-species slope and intercept.
> Therefore, I have used the methods outlined in (van der Pol & Wright, 2009)
> to split the explanatory variable into two: one with species means, the
> other within-species centered. This disentangles effects for within- and
> between species. For random effects, I am fitting random intercepts for the
> species level phylogenetic random effect (called "phylo"), random
> intercepts for the species level non-phylogenetic random effect (called
> "species"), and random slopes for the within-species centered variable.
>
> I have two questions:
>
> 1) I want to a model that allows random slopes to vary for each species,
> but i'm not sure if I have this specified correctly? Also, should the
> random slopes be coupled with the "species" or "phylo" random effect?
>
> 2) What is a good prior for the random slope / random intercept (here G2)?
> I'm not sure whether this is specified correctly (e.g., should I used
> parameter expanded priors)?
>
> Here are the priors and model:
>
> priors1 <- list(
>     B = list(mu = rep(0, 3), V = diag(9, 3)),
>     G = list(G1 = list(V = 1, nu = 0.002), G2 = list(V = diag(2)/2, nu =
> 0.002)),
>     R = list(V = 1, nu = 0.002)
>     )
>
> # parameter expanded version
> priors2 <- list(
>     B = list(mu = rep(0, 3), V = diag(9, 3)),
>     G = list(G1 = list(V = 1, nu = 0.002),
>              G2 = list(V = diag(2)/2, nu = 2, alpha.mu = rep(0, 2), alpha.V
> = diag(500, 2, 2))),
>     R = list(V = 1, nu = 0.002)
>     )
>
> # inverse of sigma matrix of phylogenetic correlation
> inv_phylo_mat <- inverseA(tree, nodes = "TIPS", scale = TRUE)
>
> fit <- MCMCglmm(
>     fixed = I1.M1 ~ I2.M1.species.mean + I2.M1.within.species,
>     rcov = ~ units,
>     random = ~ phylo + idh(1+I2.M1.within.species):species,
>     data = incisor.dat,
>     family = "gaussian",
>     ginverse = list(phylo = inv_phylo_mat$Ainv),
>     prior = priors1,
>     pr = TRUE,
>     pl = TRUE,
>     nitt = 1.1e+6, thin = 10, burnin = 1e+5,
>     verbose = FALSE
>     )
>
>
> best,
> Alberto
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Dec 26 07:58:13 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 26 Dec 2014 06:58:13 +0000
Subject: [R-sig-ME] Meta-analysis for heritability using MCMCglmm?
In-Reply-To: <CAF5_5cyX-HYrnrO1qDvP2+CsRWTaRpVU8BgpGe9sR+bf8LRiRg@mail.gmail.com>
References: <CAOxxGR=8rvPJTiHPjVYJNaCDZcUH0medNnk+fba2bONrX8kS2Q@mail.gmail.com>
	<CAF5_5cyX-HYrnrO1qDvP2+CsRWTaRpVU8BgpGe9sR+bf8LRiRg@mail.gmail.com>
Message-ID: <20141226065813.21424g2r4lweojk0@www.staffmail.ed.ac.uk>

Hi Jackie,

The data are not binomial they are continuous: a beta distribution is  
probably most appropriate for continuos observations bounded by 0 and  
1. However, although heritabilities are bounded by 0 and 1,  
heritability estimates are not necessarily so, depending on the method  
of inference (for example it would be possible to get a negative  
parent-offspring regression, either by chance or through certain types  
of maternal effect).

We have just finished a meta-analysis of h2 estimates and just treated  
them as Gaussian. The distribution of the residuals wasn't far off and  
I think the conclusions are robust to the distributional assumptions.  
Have you checked your residuals - do they look badly non-normal?


Cheers,

Jarrod




Quoting Ken Beath <ken.beath at mq.edu.au> on Wed, 24 Dec 2014 12:30:03 +1100:

> If you have the original data giving the numerator and denominator for the
> proportion then it is binomial data, and can be modelled in a met-analysis.
> I don't know if this can be done with MCMCglmm but should be possible with
> STAN, JAGS or BUGS. All will require a bit of effort in setting up the
> model.
>
> On 24 December 2014 at 07:17, Jackie Wood <jackiewood7 at gmail.com> wrote:
>
>> Dear R-users,
>>
>> I am attempting to conduct a meta-analysis to investigate the relationship
>> of narrow-sense heritability with population size. In previous work, I have
>> used MCMCglmm to conduct a formal meta-analysis which allowed me to account
>> for the effect of sampling error through the argument "mev". This was
>> relatively easy to do for a continuous response variable, however,
>> heritability is presented as a proportion and is therefore bounded by 0 and
>> 1 which clearly changes the situation.
>>
>> In fact, I am not actually certain if it possible to conduct a formal
>> weighted meta-analysis on the heritability data using MCMCglmm. I have seen
>> elsewhere where data presented as a proportion (survival, yolk-conversion
>> efficiency for example) has been logit transformed and fitted using a
>> Gaussian error distribution (though this was done using REML rather than
>> Bayesian modelling) but I don't know if this is a legitimate strategy for a
>> formal meta-analysis using heritability as a response variable since any
>> transformation applied to the heritability data would also need to be
>> applied to the standard errors?
>>
>> I would greatly appreciate any advice on this matter!
>>
>> Cheers,
>> Jackie
>>
>> --
>> Jacquelyn L.A. Wood, PhD.
>> Biology Department
>> Concordia University
>> 7141 Sherbrooke St. West
>> Montreal, QC
>> H4B 1R6
>> Phone: (514) 293-7255
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:15}}


From vlagani at ics.forth.gr  Fri Dec 26 20:11:27 2014
From: vlagani at ics.forth.gr (Vincenzo Lagani)
Date: Fri, 26 Dec 2014 20:11:27 +0100
Subject: [R-sig-ME] standard error and statistical significance in lmer
	versus lm
Message-ID: <549DB2DF.9040009@ics.forth.gr>

Dear all,

I am modelling gene expression data with mixed models using lme4. My 
goal is to assess whether gene expression globally decreases or 
increases with time.

Specifically, the data consist in whole expression profiles measured at 
five different time points in two different strains of mice. For each 
time point and each strain there are three replicates. The data are not 
longitudinal, i.e., different mice are used at each time point. We had 
to remove one profile from a time point because it was not matching our 
quality criteria, so the data became not properly balanced.

On these data I am fitting the following model:

lme4Model.full <- lmer(values ~ week * genotype + (week | probesets), 
data = dataset, REML = FALSE)

where 'values' stands for the gene expression, 'week' is a scaled 
numeric reporting the age of the mice in weeks, and 'genotype' is a 
factor with two levels representing the two different genetic 
backgrounds. Each single gene is let having its own random intercept and 
slope.

What puzzles me is that when I compare this model with its simpler, 
non-mixed version:

lmModel.full <- lm(values ~ week * genotype, data = dataset)

I obtain the same coefficients but different standard errors (see 
below). Furthermore, while the interaction coefficient is not 
significant in the simple linear model, it becomes highly significant in 
the mixed model, at least according to these ANOVA tests:

lmModel <- lm(values ~ week + genotype, data = dataset)
lme4Model <- lmer(values ~ week + genotype + (week | probesets), data = 
dataset, REML = FALSE)

>anova(lmModel.full, lmModel)
Analysis of Variance Table

Model 1: values ~ week * genotype
Model 2: values ~ week + genotype
   Res.Df     RSS Df Sum of Sq      F Pr(>F)
1 414341 2162664
2 414342 2162666 -1   -2.4697 0.4732 0.4915

>anova(lme4Model.full, lme4Model)
Data: dataset
Models:
lme4Model: values ~ week + genotype + (week | probesets)
lme4Model.full: values ~ week * genotype + (week | probesets)
                Df   AIC   BIC logLik deviance  Chisq Chi Df Pr(>Chisq)
lme4Model       7 72376 72452 -36181    72362
lme4Model.full  8 72325 72413 -36155    72309 52.472      1  4.364e-13 ***



Assessing whether the interaction coefficient is significant is actually 
the aim of my study, and having two totally different answers confuses 
me. My understanding is that the mixed model better catches the variance 
structure of the data and thus it is able to better estimate the 
standard errors and p-values of the coefficients. Is this correct? In 
other words, can I confidently claim that the p-values obtained from the 
mixed models are "the correct ones" and that the interaction term is 
actually significant?

My apologies if this issue has been already posted on this list. Despite 
having seen multiple posts here on similar topics, I have not been able 
to find an answer to these questions.

Thanks in advance for your help. Any suggestion is very welcome.

Regards,

Vincenzo


>summary(lme4Model.full)
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: values ~ week * genotype + (week | probesets)
    Data: dataset

      AIC      BIC   logLik deviance df.resid
  72325.3  72412.8 -36154.7  72309.3   414337

Scaled residuals:
      Min       1Q   Median       3Q      Max
-13.2622  -0.5246   0.0128   0.5270  23.3456

Random effects:
  Groups    Name        Variance Std.Dev. Corr
  probesets (Intercept) 5.167338 2.27318
            week        0.005029 0.07092  -0.23
  Residual              0.047063 0.21694
Number of obs: 414345, groups:  probesets, 18015

Fixed effects:
                    Estimate Std. Error t value
(Intercept)       6.5727983  0.0169414   388.0
week             -0.0151336  0.0006823   -22.2
genotypeCSB       0.2405300  0.0007121   337.8
week:genotypeCSB  0.0050430  0.0006962     7.2

Correlation of Fixed Effects:
             (Intr) week   gntCSB
week        -0.177
genotypeCSB -0.015 -0.028
wk:gntypCSB -0.001 -0.392 -0.054


>summary(lmModel.full)

Call:
lm(formula = values ~ week * genotype, data = dataset)

Residuals:
     Min      1Q  Median      3Q     Max
-5.7560 -1.9881  0.0083  1.6823  7.6407

Coefficients:
                   Estimate Std. Error  t value Pr(>|t|)
(Intercept)       6.572798   0.004407 1491.384  < 2e-16 ***
week             -0.015134   0.004547   -3.329 0.000873 ***
genotypeCSB       0.240530   0.007500   32.072  < 2e-16 ***
week:genotypeCSB  0.005043   0.007331    0.688 0.491537
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 2.285 on 414341 degrees of freedom
Multiple R-squared:  0.002491,	Adjusted R-squared:  0.002484
F-statistic: 344.9 on 3 and 414341 DF,  p-value: < 2.2e-16



	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Dec 27 04:33:27 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 26 Dec 2014 22:33:27 -0500
Subject: [R-sig-ME] standard error and statistical significance in lmer
 versus lm
In-Reply-To: <549DB2DF.9040009@ics.forth.gr>
References: <549DB2DF.9040009@ics.forth.gr>
Message-ID: <549E2887.3060108@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-12-26 02:11 PM, Vincenzo Lagani wrote:
> Dear all,
> 
> I am modelling gene expression data with mixed models using lme4.
> My goal is to assess whether gene expression globally decreases or
>  increases with time.
> 
> Specifically, the data consist in whole expression profiles
> measured at five different time points in two different strains of
> mice. For each time point and each strain there are three
> replicates. The data are not longitudinal, i.e., different mice are
> used at each time point. We had to remove one profile from a time
> point because it was not matching our quality criteria, so the data
> became not properly balanced.
> 
> On these data I am fitting the following model:
> 
> lme4Model.full <- lmer(values ~ week * genotype + (week |
> probesets), data = dataset, REML = FALSE)
> 
> where 'values' stands for the gene expression, 'week' is a scaled 
> numeric reporting the age of the mice in weeks, and 'genotype' is a
>  factor with two levels representing the two different genetic 
> backgrounds. Each single gene is let having its own random
> intercept and slope.
> 
> What puzzles me is that when I compare this model with its simpler,
>  non-mixed version:
> 
> lmModel.full <- lm(values ~ week * genotype, data = dataset)
> 
> I obtain the same coefficients but different standard errors (see 
> below). Furthermore, while the interaction coefficient is not 
> significant in the simple linear model, it becomes highly
> significant in the mixed model, at least according to these ANOVA
> tests:
> 
> lmModel <- lm(values ~ week + genotype, data = dataset) lme4Model
> <- lmer(values ~ week + genotype + (week | probesets), data = 
> dataset, REML = FALSE)
> 
>> anova(lmModel.full, lmModel)
> Analysis of Variance Table
> 
> Model 1: values ~ week * genotype Model 2: values ~ week +
> genotype Res.Df     RSS Df Sum of Sq      F Pr(>F) 1 414341
> 2162664 2 414342 2162666 -1   -2.4697 0.4732 0.4915
> 
>> anova(lme4Model.full, lme4Model)
> Data: dataset Models: lme4Model: values ~ week + genotype + (week |
> probesets) lme4Model.full: values ~ week * genotype + (week |
> probesets) Df   AIC   BIC logLik deviance  Chisq Chi Df Pr(>Chisq) 
> lme4Model       7 72376 72452 -36181    72362 lme4Model.full  8
> 72325 72413 -36155    72309 52.472      1  4.364e-13 ***
> 
> Assessing whether the interaction coefficient is significant is
> actually the aim of my study, and having two totally different
> answers confuses me. My understanding is that the mixed model
> better catches the variance structure of the data and thus it is
> able to better estimate the standard errors and p-values of the
> coefficients. Is this correct? In other words, can I confidently
> claim that the p-values obtained from the mixed models are "the
> correct ones" and that the interaction term is actually
> significant?

   As far as I can tell from what you've posted, the result given by
lme4 is indeed (or certainly could be/I have no reason to believe it
is not) correct. I'm not sure of the best way to explain the result to
you, though.  Adding the variation among probesets to the model does
indeed explain a lot of variation that would otherwise end up being
modeled as error and filtering into the standard errors.  It would be
nice to understand the differences by visualizing the different
models, but with such a large data set it could be challenging ...
One thing that might be interesting would be plotting the residuals from
a model of only probeset variation (i.e., values ~ (week|probeset))
and seeing how the week*genotype pattern was (hopefully) clarified.

> My apologies if this issue has been already posted on this list.
> Despite having seen multiple posts here on similar topics, I have
> not been able to find an answer to these questions.
> 
> Thanks in advance for your help. Any suggestion is very welcome.
> 
> Regards,
> 
> Vincenzo
> 
> 
>> summary(lme4Model.full)
> Linear mixed model fit by maximum likelihood  ['lmerMod'] Formula:
> values ~ week * genotype + (week | probesets) Data: dataset
> 
> AIC      BIC   logLik deviance df.resid 72325.3  72412.8 -36154.7
> 72309.3   414337
> 
> Scaled residuals: Min       1Q   Median       3Q      Max -13.2622
> -0.5246   0.0128   0.5270  23.3456
> 
> Random effects: Groups    Name        Variance Std.Dev. Corr 
> probesets (Intercept) 5.167338 2.27318 week        0.005029 0.07092
> -0.23 Residual              0.047063 0.21694 Number of obs: 414345,
> groups:  probesets, 18015
> 
> Fixed effects: Estimate Std. Error t value (Intercept)
> 6.5727983  0.0169414   388.0 week             -0.0151336  0.0006823
> -22.2 genotypeCSB       0.2405300  0.0007121   337.8 
> week:genotypeCSB  0.0050430  0.0006962     7.2
> 
> Correlation of Fixed Effects: (Intr) week   gntCSB week
> -0.177 genotypeCSB -0.015 -0.028 wk:gntypCSB -0.001 -0.392 -0.054
> 
> 
>> summary(lmModel.full)
> 
> Call: lm(formula = values ~ week * genotype, data = dataset)
> 
> Residuals: Min      1Q  Median      3Q     Max -5.7560 -1.9881
> 0.0083  1.6823  7.6407
> 
> Coefficients: Estimate Std. Error  t value Pr(>|t|) (Intercept)
> 6.572798   0.004407 1491.384  < 2e-16 *** week
> -0.015134   0.004547   -3.329 0.000873 *** genotypeCSB
> 0.240530   0.007500   32.072  < 2e-16 *** week:genotypeCSB
> 0.005043   0.007331    0.688 0.491537 --- Signif. codes:  0 ?***?
> 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 2.285 on 414341 degrees of freedom 
> Multiple R-squared:  0.002491,	Adjusted R-squared:  0.002484 
> F-statistic: 344.9 on 3 and 414341 DF,  p-value: < 2.2e-16

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUniiHAAoJEOCV5YRblxUH5GEH/R57rvnCi7OYj0HEV+1dQ9sv
awXYPd9/q7t2ZPVyrJ8OdVL2+ntVe7KYKFy28D2uRa5eyyH6/jaoy9nSlGI4Gvd0
dslGQYlIpSw9LmOHY1BPcQYZuqEoJoHlbonbX+00AwgANdanP0CpSWNzNVRmbcUL
ftPAErAaJecb7yu56+I2Yz5ugN3NYrqNdWvTV/HYxt5emjx45gQdQd4cQRTfKw3n
JkcM8DMRrOjvN6w2H8Pgps/yE3W+nx5VsgBaSdmagwTIfke6aZ90+55jMhjbDXNJ
xsbFzPc3CUA5SUO7qQHwoteMz8QlfRp3D8SgfmdfaPixskWCdMHjxAws+0ePAhw=
=0jkf
-----END PGP SIGNATURE-----


From markl033 at umn.edu  Mon Dec 29 06:53:53 2014
From: markl033 at umn.edu (Tricia Markle)
Date: Sun, 28 Dec 2014 21:53:53 -0800
Subject: [R-sig-ME] Repeated Measures in MCMCglmm model
In-Reply-To: <20141226063616.18293aw785lp8ji8@www.staffmail.ed.ac.uk>
References: <CAO=0ZJUEJ4d53ZFNgXgtwBfam29Q-ZzXv2evtZab39X5YGQjMg@mail.gmail.com>
	<20141226063616.18293aw785lp8ji8@www.staffmail.ed.ac.uk>
Message-ID: <CAO=0ZJWjsokWmpJewuFU0Bcete7SfNzGpU6tubNdR9PbJczLWA@mail.gmail.com>

Hi Jarrod,

Thank you for the reply. We are defining plasticity as the difference in
slope for oxygen consumption on temperature at different acclimations. So
essentially asking if wide-ranging species have a greater change in slope
between acclimation temperatures than narrow-ranging species. Since there
are three acclimation temps, one thought is to break it up and look at the
difference in slope between acclimation at 15C vs. 22C and then 15C vs. 6C
(so that 15C is somewhat of a reference point).

I like the idea of allowing different species to have different levels of
plasticity, but agree that for 19 species it's going to be hard to
interpret the results. I also have the species broken into 2 groups based
on range size  (large vs. small) and since this gets at the heart of what
I'd like to test perhaps it is the best way to go for now?

I do have multiple individuals per species (and each individual is tested
at each acclimation temp). If I break the data into 2 groups based on range
size, would the random term then be us(1+temp):Range? Since the same
individuals are used in multiple trials would I need to also include ID
somewhere?

The code did work despite the odd script with A inverse associated with
species (I was basing it on an example that I found). I tried some of your
random effect suggestions and now I get the error message  "prior$G has the
wrong number of structures".

Here is my code as it stands now (I would also love your thoughts on the
phylogeny component and if the code for that looks right):

library(MCMCglmm)
dataset<-read.csv(file="RespDataID.csv", head=TRUE)
dataset$Range<-as.factor(dataset$Range)
str(dataset)

#Phylogeny Component
tree<-read.tree("Plethodontidae_comb61_PL.phy")
species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
"D._imitator_KHK05", "D._ochrophaeus_WKS05", "D._ocoee_B_KHK62",
"D._orestes_KHK129",  "D._monticola_A",  "D._santeetlah_11775",
"P_cinereus", "P_cylindraceus", "P_glutinosus", "P_hubrichti",
"P_montanus", "P_punctatus", "P_richmondi", "P_teyahalee", "P_virginia",
"P_wehrlei")
pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
tree$tip.label)])# Prune tree to just include species of interest
sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node") #rename
nodes to be unique
plot(sptree, show.node.label=TRUE)

treeAinv<-inverseA(sptree)$Ainv

prior<-list(G=list(G1=list(V=1, n=0.002), R=list(V=1, n=0.002))

#Model 1  with Range Size - Small (1) versus Large (2)
model1<-MCMCglmm(LVO2~1+Acclm+Temp+LMass+Sex+Range+Acclm*Temp*Range,
random=~us(1+Temp):species, data=dataset, family="gaussian",
ginverse=list(species=treeAinv), nodes="ALL", prior=prior, nitt=300000,
burnin=25000, thin = 1000, verbose=FALSE)

summary(model1)

best,
Tricia


On Thu, Dec 25, 2014 at 10:36 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi Tricia,
>
> How do you define plasticity, as the slope of the regression of oxygen
> consumption on temperature, acclimation temperature or some aspect of both?
>
>
> If it was temperature I would fit the random effect term
> us(1+temp):species which allows different species to have different levels
> of plasticity which is phylogentically correlated. However, with 18 (?)
> species it is going to be hard to get precise estimates of how variable
> plasticity is across different species.
>
> Its not clear whether you have multiple individuals per species? If there
> is only one individual per species then us(1+temp):ID models
> between-species variation in plasticity not determined by phylogeny and any
> between individual (within-species) variation in plasticity. If you have
> multiple individuals per species then you could separate these two effects.
>
> Also, does your code work?  You have associated the A inverse with species
> but then fitted animal in your random model  - you should have species in
> the random model rather than animal.
>
> Cheers,
>
> Jarrod
>
>
>
>
> Quoting Tricia Markle <markl033 at umn.edu> on Wed, 17 Dec 2014 23:41:58
> -0600:
>
>  Hello,
>>
>>
>>
>> I am hoping to find someone familiar with the R code for taking repeated
>> measures into account in a MCMCglmm model. I have put together a working
>> code (see below) based on a couple of examples that I found (adding ?ID?
>> as
>> a random term), but remain unsure if it is the best approach.
>>
>>
>> My study is investigating whether wide-ranging species of salamander have
>> a
>> greater degree of plasticity in oxygen consumption (i.e. metabolic rate)
>> at
>> different acclimation temperatures than narrow-ranging species. The same
>> individuals were tested at each of three acclimation temperatures (6, 14,
>> and 22C). Each acclimation temperature had 3 separate respirometry tests
>> to
>> measure oxygen consumption (5, 15, and 25C) for a total of 9 tests per
>> individual.
>>
>>
>> *R script:*
>>
>>
>> library(MCMCglmm)
>> dataset<-read.csv(file="RData.csv", head=TRUE)
>> dataset$Range<-as.factor(dataset$Range)
>> str(dataset)
>>
>> #Phylogeny Component
>> tree<-read.tree("Plethodontidae_comb61_PL.phy")
>> species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
>> "D._imitator_KHK05", "D._ochrophaeus_WKS05", "D._ocoee_B_KHK62",
>> "D._orestes_KHK129",  "D._monticola_A",  "D._santeetlah_11775",
>> "P_cinereus", "P_cylindraceus", "P_glutinosus", "P_hubrichti",
>> "P_montanus", "P_punctatus", "P_richmondi", "P_teyahalee", "P_virginia",
>> "P_wehrlei")
>> pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
>> tree$tip.label)])# Prune tree to just include species of interest
>> sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node")
>> #rename
>> nodes to be unique
>> plot(sptree, show.node.label=TRUE)
>>
>> treeAinv<-inverseA(sptree)$Ainv
>>
>> #For Repeated Measures
>> dataset$ID<-dataset$animal
>> head(dataset)
>> p.var<-var(dataset$LVO2, na.rm=TRUE)
>>
>>
>> #Prior
>>
>> prior<-list(G=list(G1=list(V=1, n=0.002), G2=list(V=1, n=0.002)),
>> R=list(V=1, n=0.002))
>>
>> #Model 1 with Range Size
>> model1<-MCMCglmm(LVO2~1+Acclm+Temp+LMass+Sex+Range+Acclm*Temp*Range,
>> random=~animal+ID, data=dataset, ginverse=list(species=treeAinv),
>> nodes="ALL", prior=prior, nitt=300000, burnin=25000, thin = 1000,
>> verbose=FALSE)
>>
>>
>>
>>
>> *Sincerely, *
>>
>>
>>  *Tricia Markle*
>>
>> *PhD Candidate, **University of Minnesota*
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>

	[[alternative HTML version deleted]]


