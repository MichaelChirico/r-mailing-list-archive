From vmuggeo at dssm.unipa.it  Fri Jan 26 10:10:42 2007
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Fri, 26 Jan 2007 10:10:42 +0100
Subject: [R-sig-ME] heterogeneity in random effects variance
Message-ID: <45B9C592.1020908@dssm.unipa.it>

Dear *all*,
(how many.. seeing that this appears to be the first message? :-))

My question concerns LMM and it is not strictly related to developments 
   of the lme4 package.

In a LMM framework is it possible to set a heterogeneity model for the 
random effects? More precisely I am interested in fitting a LMM where 
the random effects:

u~N(0,D(a,b))

where the covariance matrix D is diagonal and depends on two, say, 
parameters a and b to be estimated: D=diag(s1,s2,..,sj,..) and 
sj=exp(a+bxj) with some known values x1,x2,.xj

Is it possible with lmer() (in lme4 package) or even lme() (in nlme 
package)?

I hope to find an answer in this new promising mailing list

Many thanks in advance,

vito


-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612



From A.Robinson at ms.unimelb.edu.au  Fri Jan 26 22:14:16 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 27 Jan 2007 08:14:16 +1100
Subject: [R-sig-ME] heterogeneity in random effects variance
In-Reply-To: <45B9C592.1020908@dssm.unipa.it>
References: <45B9C592.1020908@dssm.unipa.it>
Message-ID: <20070126211416.GS13602@ms.unimelb.edu.au>

Hi Vito,

I don't think that this functionality exists in lme or lmer right now.
What you describe looks to me as though you'd like to use the varExp
class of functions at the random effects level, instead of at the
within-group level.  The random-effects level has a set of classes for
patterned covariance matrices; the pdMat classes, but this set doesn't
seem to include anything like the varExp class.

So, one thing is that you could write a new pdMat class that provides
the varExp functionality.  I only know vaguely how a person might do
that.  I did a bit of research on writing new varFunc classes but
didn't get enough detail, or have enough time, to start hacking. 
I am happy to share the little that I know if that would be helpful.  

You might also try an EM approach, fitting simpler models within a
loop, using gls and lme alternately, and hoping that it converges.  I
am not sure how that would work right now, but the problem is
interesting, and I'll ponder on it further.  If anyone can suggest how
it might work off the cuff, that would be great!

It is possible that other packages or programs might be able to fit
such models.

Cheers

Andrew

On Fri, Jan 26, 2007 at 10:10:42AM +0100, vito muggeo wrote:
> Dear *all*,
> (how many.. seeing that this appears to be the first message? :-))
> 
> My question concerns LMM and it is not strictly related to developments 
>    of the lme4 package.
> 
> In a LMM framework is it possible to set a heterogeneity model for the 
> random effects? More precisely I am interested in fitting a LMM where 
> the random effects:
> 
> u~N(0,D(a,b))
> 
> where the covariance matrix D is diagonal and depends on two, say, 
> parameters a and b to be estimated: D=diag(s1,s2,..,sj,..) and 
> sj=exp(a+bxj) with some known values x1,x2,.xj
> 
> Is it possible with lmer() (in lme4 package) or even lme() (in nlme 
> package)?
> 
> I hope to find an answer in this new promising mailing list
> 
> Many thanks in advance,
> 
> vito
> 
> 
> -- 
> ====================================
> Vito M.R. Muggeo
> Dip.to Sc Statist e Matem `Vianelli'
> Universit? di Palermo
> viale delle Scienze, edificio 13
> 90128 Palermo - ITALY
> tel: 091 6626240
> fax: 091 485726/485612
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From A.Robinson at ms.unimelb.edu.au  Sat Jan 27 00:27:14 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 27 Jan 2007 10:27:14 +1100
Subject: [R-sig-ME] New version of lme4 - memory error
In-Reply-To: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
References: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
Message-ID: <20070126232714.GW13602@ms.unimelb.edu.au>

Hi Doug,

sorry, it's me having problems again :(

I can install and load the new lme4 package with no trouble, but when
I try to run the examples, I get:



>  require(lme4)
Loading required package: lme4
Loading required package: Matrix
Loading required package: lattice
[1] TRUE
> sessionInfo()
R version 2.4.1 Patched (2007-01-25 r40572) 
i386-unknown-freebsd6.1 

locale:
C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
"methods"  
[7] "base"     

other attached packages:
       lme4      Matrix     lattice 
"0.9975-11"  "0.9975-8"   "0.14-16" 
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fm1 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy)
Error in as.double(start) : Calloc could not allocate (169499040 of 4)
       memory






Does anyone else find this?  Please let me know what else I can do to
help.

Cheers,

Andrew



On Thu, Jan 25, 2007 at 05:12:00PM -0600, Douglas Bates wrote:
> Version 0.9975-11 of the lme4 package has been uploaded to CRAN.  The
> source package should be available on the mirrors in a day or two and
> binary packages should follow soon after.
> 
> There are several changes in this release of the package.  The most
> important is the availability of a development version of lmer called,
> for the time being, lmer2.  At present lmer2 only fits linear mixed
> models.  Generalized linear mixed models will be added "soon".
> Furthermore there is no mcmcsamp method for a model fit by lmer2.
> This deficiency will also be rectified "soon".  Once I have all the
> capabilities and methods currently available for lmer also available
> for the new representation I will remove the old representation and
> rename lmer2 as lmer.
> 
> The current version of lmer will continue to be available throughout
> the migration process.  You don't have to change anything about your
> use of that function unless you want to try the new one.  It would be
> a good idea, however, to save the data and the call to lmer in
> addition to saving an lmer object, if you so choose, so that you can
> recreate the fitted model when the development version becomes the
> release version.
> 
> The package contains a vignette giving the details of the new implementation.
> 
> The reason I am releasing a development version in parallel with the
> production version is because I would like feedback from useR's
> regarding the development version.  In my experience, testing it
> myself and with colleagues whom I visited recently, I have found that
> lmer2 is faster and more reliable than the current lmer.  In
> particular, on some difficult model fits I have been able to get
> substantially better parameter estimates (i.e. the deviance at the
> lmer2 estimates is perhaps 4 or 5 lower than that at the lmer
> estimates) with lmer2 than I could with lmer.
> 
> If you have fit a linear mixed model using lmer and are willing to try
> it with lmer2 I would appreciate your telling me if the parameter
> estimates are comparable and which fit was faster (use system.time()
> to check).  I'm primarily interested in models fit to large data sets
> or "difficult" fits.
> 
> We have established a new mailing list, R-SIG-mixed-models, for
> discussion of R software to fit mixed-effects models, especially lmer.
>  See https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models for
> information or to subscribe.
> 
> I know that I have said this before but this is the last time that I
> am going to change the underlying representation.  Really - trust me -
> this is the last time.  My theory of software development is expressed
> in a line from an old blues song, "you just keep doing it wrong till
> you do it right".  I'm convinced that this time I have it right.  That
> statement sounds like "famous last words", doesn't it?  :-)
> 
> _______________________________________________
> R-packages mailing list
> R-packages at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-packages
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From maechler at stat.math.ethz.ch  Sat Jan 27 16:20:30 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 27 Jan 2007 16:20:30 +0100
Subject: [R-sig-ME] New version of lme4 - memory error
In-Reply-To: <20070126232714.GW13602@ms.unimelb.edu.au>
References: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
	<20070126232714.GW13602@ms.unimelb.edu.au>
Message-ID: <17851.28094.984581.79456@stat.math.ethz.ch>

>>>>> "Andrew" == Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
>>>>>     on Sat, 27 Jan 2007 10:27:14 +1100 writes:

    Andrew> Hi Doug, sorry, it's me having problems again :(

    Andrew> I can install and load the new lme4 package with no
    Andrew> trouble, but when I try to run the examples, I get:

    >> require(lme4)
    Andrew> Loading required package: lme4
    Andrew> Loading required package: Matrix
    Andrew> Loading required package: lattice
    Andrew> [1] TRUE
    >> sessionInfo()
    Andrew> R version 2.4.1 Patched (2007-01-25 r40572) 
    Andrew> i386-unknown-freebsd6.1 

    Andrew> locale:
    Andrew> C

    Andrew> attached base packages:
    Andrew> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
    Andrew> "methods"  
    Andrew> [7] "base"     

    Andrew> other attached packages:
    Andrew> lme4      Matrix     lattice 
    Andrew> "0.9975-11"  "0.9975-8"   "0.14-16" 
    >> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
    >> fm1 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy)
    Andrew> Error in as.double(start) : Calloc could not allocate (169499040 of 4)
    Andrew> memory

Hmm, I can't replicate your problem.  I get

 > system.time( fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
 [1] 0.112 0.001 0.124 0.000 0.000
 > system.time( fm1.2 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy))
 [1] 0.056 0.000 0.056 0.000 0.000
 > summary(fm1.2)
 Linear mixed-effects model fit by REML 
   AIC  BIC logLik MLdeviance REMLdeviance
  1754 1770 -871.8       1752         1744
 Random effects:
  Groups   Name        Variance Std.Dev. Corr  
  Subject  (Intercept) 612.114  24.7409        
	   Days         35.072   5.9222  0.066 
  Residual             654.937  25.5917        
 Number of obs: 180, groups: Subject, 18

 Fixed effects:
	     Estimate Std. Error t value
 (Intercept)  251.405      6.825   36.84
 Days          10.467      1.546    6.77

 Correlation of Fixed Effects:
      (Intr)
 Days -0.138
 > 



    Andrew> Does anyone else find this?  Please let me know what else I can do to
    Andrew> help.

You can type  
        traceback()

after the error (which you should get a habit of doing ;-)
which might be revealing though I doubt it a bit in this case.

Are you sure that you started R as "R --vanilla", i.e.
that you have *not* loaded an .RData of a previous session
accidentally?

Regards,
Martin

    Andrew> Cheers,
    Andrew> Andrew



From bates at stat.wisc.edu  Sat Jan 27 18:50:16 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 27 Jan 2007 11:50:16 -0600
Subject: [R-sig-ME] Fwd: lmer2 slower?
In-Reply-To: <40e66e0b0701261338r3898b2a6ubd0af8662bcad96e@mail.gmail.com>
References: <45BA646E.9030700@edmeasure.com>
	<40e66e0b0701261253r4dc7adfsd3f2b04ecbfa5b23@mail.gmail.com>
	<45BA6C52.6020008@edmeasure.com>
	<40e66e0b0701261338r3898b2a6ubd0af8662bcad96e@mail.gmail.com>
Message-ID: <40e66e0b0701270950q566d9894k69263fc4c82c9b45@mail.gmail.com>

I am forwarding (with permission) a conversation with Bill Auty who
discovered that in one of his examples lmer2 is considerably slower
than lmer, although they get to the same estimates.  This can happen.

As I mentioned in one reply I hope that forcing a supernodal Cholesky
decomposition for models with crossed or partially crossed grouping
factors for the random effects will help but I haven't had time to
explore this yet.

I'll post some other timing results in another message.

---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Jan 26, 2007 3:38 PM
Subject: Re: lmer2 slower?
To: Bill Auty <bill at edmeasure.com>


On 1/26/07, Bill Auty <bill at edmeasure.com> wrote:
>  > class(xq2 at L)
>
> [1] "dCHMsimpl"
>
> attr(,"package")
>
> [1] "Matrix"

Ah, good.  That 's the answer that I wanted.

Briefly, the CHOLMOD sparse matrix code allows for two types of
Cholesky decompositions of sparse, symmetric matrices.  These are
called "simplicial" and "supernodal".  In the lmer code I forced the
supernodal decomposition.  In the lmer2 code I allow the sparse matrix
manipulation code to choose one or the other based on some criteria
which I can "tune".  I think that the default values that are
currently being used are too conservative about switching to the
supernodal decomposition so I may be able to gain back some of the
loss of speed.

Thanks again for checking this.

May I send a copy of this reply to the R-SIG-mixed-models list?

>
>  >
>
> I don't have the math chops to stay with you on the theory of this, but
> I'm glad to help by trying things on my data.
>
> Douglas Bates wrote:
> > Thanks.  That's valuable information.
> >
> > Could you check something for me?  If you still have the object fit by
> > lmer2 could you send me the result of
> >
> > class(xq2 at L)
> >
> > The response should be either "dCHMsimpl" or "dCHMsuper"
> >
> > On 1/26/07, Bill Auty <bill at edmeasure.com> wrote:
> >> I've attached the output from running lmer and lmer2 on the same model.
> >> The variables are:
> >>
> >> rit = scale score on a math test
> >> gr = grade (range 0 - 2)
> >> stu = student ID
> >> sch = school ID
> >> dist = district ID
> >>
> >> The students are partially crossed in school and district.
> >>
> >>
> >> >
> >> system.time(xq2<-lmer2(rit~gr+I(gr^2)+(gr|stu)+(gr|sch)+(gr|dist),e2math,
> >>
> >> + control = list(niterEM =0, gradient = FALSE),method="ML"))
> >> [1] 428.223  30.569 458.986   0.000   0.000
> >> > xq2
> >> Linear mixed-effects model fit by maximum likelihood
> >> Formula: rit ~ gr + I(gr^2) + (gr | stu) + (gr | sch) + (gr | dist)
> >>    Data: e2math
> >>     AIC    BIC  logLik MLdeviance REMLdeviance
> >>  977133 977251 -488554     977109       977117
> >> Random effects:
> >>  Groups   Name        Variance Std.Dev. Corr
> >>  stu      (Intercept) 78.60373 8.86587
> >>           gr           1.88712 1.37373  -0.227
> >>  sch      (Intercept)  7.24479 2.69161
> >>           gr           0.75162 0.86696  -0.512
> >>  dist     (Intercept)  4.30657 2.07523
> >>           gr           0.37241 0.61026  0.139
> >>  Residual             26.61534 5.15901
> >> Number of obs: 136484, groups: stu, 80224; sch, 182; dist, 63
> >>
> >> Fixed effects:
> >>              Estimate Std. Error t value
> >> (Intercept) 209.65220    0.38078   550.6
> >> gr            7.67870    0.13085    58.7
> >> I(gr^2)      -0.76376    0.01931   -39.6
> >>
> >> Correlation of Fixed Effects:
> >>         (Intr) gr
> >> gr      -0.188
> >> I(gr^2)  0.049 -0.411
> >> >
> >> system.time(q2<-lmer(rit~gr+I(gr^2)+(gr|stu)+(gr|sch)+(gr|dist),e2math,
> >> + control = list(niterEM =0, gradient = FALSE),method="ML"))
> >> [1] 241.323  24.070 265.412   0.000   0.000
> >> > q2
> >> Linear mixed-effects model fit by maximum likelihood
> >> Formula: rit ~ gr + I(gr^2) + (gr | stu) + (gr | sch) + (gr | dist)
> >>    Data: e2math
> >>     AIC    BIC  logLik MLdeviance REMLdeviance
> >>  977133 977251 -488554     977109       977117
> >> Random effects:
> >>  Groups   Name        Variance Std.Dev. Corr
> >>  stu      (Intercept) 78.60255 8.86581
> >>           gr           1.88767 1.37393  -0.227
> >>  sch      (Intercept)  7.24380 2.69143
> >>           gr           0.75110 0.86666  -0.512
> >>  dist     (Intercept)  4.30710 2.07536
> >>           gr           0.37265 0.61045  0.139
> >>  Residual             26.61352 5.15883
> >> number of obs: 136484, groups: stu, 80224; sch, 182; dist, 63
> >>
> >> Fixed effects:
> >>              Estimate Std. Error t value
> >> (Intercept) 209.65218    0.38079   550.6
> >> gr            7.67867    0.13086    58.7
> >> I(gr^2)      -0.76376    0.01931   -39.6
> >>
> >> Correlation of Fixed Effects:
> >>         (Intr) gr
> >> gr      -0.188
> >> I(gr^2)  0.049 -0.411
> >> >
> >>
> >>
> >>
> >>
> >
>



From bates at stat.wisc.edu  Sat Jan 27 20:41:42 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 27 Jan 2007 13:41:42 -0600
Subject: [R-sig-ME] Some timings for lmer2 versus lmer
Message-ID: <40e66e0b0701271141s6361e0a7lac673f329eeb60db@mail.gmail.com>

I enclose an R source file to do some comparative timings on lmer2
fits versus lmer fits and the output generated on the machine
R-forge.R-project.org (Opteron 280 dual-core processors, R internal
BLAS, 13 GB of memory).  You can try running the script on your
computer to get an idea of the timings.

On some machines the lmer fit to the "star" data set will converge in
considerably fewer iterations than on this machine.  There is one
point in the optimization where very small differences in the floating
point operation orders cause a much better step to be taken.

If you look at the verbose output you will see that the
parameterization for lmer2 uses the relative standard deviation (as
described in the Implementation vignette from the lme4 package)
whereas lmer used the relative variance.  Generally the relative
standard deviation is more stable for the optimization.

The other big difference in the optimization, shown in the last
example, is that lmer evaluates the relative precision matrix (the
inverse of the relative variance matrix) and therefore cannot allow
variance components to go to zero.  The value of a variance component
is bounded below at 5e-10, which is why that particular number shows
up in the verbose iterations.  As described in the vignette, the
relative variance matrix is used in lmer2 hence the lower bound on the
variance component is at zero.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lmer2_test.R
Type: application/octet-stream
Size: 2967 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070127/1ad3cb3d/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lmer2_test.Rout
Type: application/octet-stream
Size: 45018 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070127/1ad3cb3d/attachment-0001.obj>

From A.Robinson at ms.unimelb.edu.au  Sat Jan 27 23:30:19 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 28 Jan 2007 09:30:19 +1100
Subject: [R-sig-ME] New version of lme4 - memory error
In-Reply-To: <17851.28094.984581.79456@stat.math.ethz.ch>
References: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
	<20070126232714.GW13602@ms.unimelb.edu.au>
	<17851.28094.984581.79456@stat.math.ethz.ch>
Message-ID: <20070127223019.GE13602@ms.unimelb.edu.au>

Thanks, Martin.  It was vanilla.


> traceback()
4: .Call(mer2_getPars, mer)
3: as.double(start)
2: nlminb(.Call(mer2_getPars, mer), function(x) .Call(mer2_deviance, 
       .Call(mer2_setPars, mer, x), as.integer(0)), lower = ifelse(const, 
       0, -Inf), control = list(trace = cv$msVerbose, iter.max = cv$msMaxIter, 
       rel.tol = abs(0.001/.Call(mer2_deviance, mer, 0))))
1: lmer2(Reaction ~ Days + (Days | Subject), sleepstudy)


(I will add it to my list of New Year's Resolutions!)



Andrew



On Sat, Jan 27, 2007 at 04:20:30PM +0100, Martin Maechler wrote:
> >>>>> "Andrew" == Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
> >>>>>     on Sat, 27 Jan 2007 10:27:14 +1100 writes:
> 
>     Andrew> Hi Doug, sorry, it's me having problems again :(
> 
>     Andrew> I can install and load the new lme4 package with no
>     Andrew> trouble, but when I try to run the examples, I get:
> 
>     >> require(lme4)
>     Andrew> Loading required package: lme4
>     Andrew> Loading required package: Matrix
>     Andrew> Loading required package: lattice
>     Andrew> [1] TRUE
>     >> sessionInfo()
>     Andrew> R version 2.4.1 Patched (2007-01-25 r40572) 
>     Andrew> i386-unknown-freebsd6.1 
> 
>     Andrew> locale:
>     Andrew> C
> 
>     Andrew> attached base packages:
>     Andrew> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
>     Andrew> "methods"  
>     Andrew> [7] "base"     
> 
>     Andrew> other attached packages:
>     Andrew> lme4      Matrix     lattice 
>     Andrew> "0.9975-11"  "0.9975-8"   "0.14-16" 
>     >> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>     >> fm1 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy)
>     Andrew> Error in as.double(start) : Calloc could not allocate (169499040 of 4)
>     Andrew> memory
> 
> Hmm, I can't replicate your problem.  I get
> 
>  > system.time( fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>  [1] 0.112 0.001 0.124 0.000 0.000
>  > system.time( fm1.2 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy))
>  [1] 0.056 0.000 0.056 0.000 0.000
>  > summary(fm1.2)
>  Linear mixed-effects model fit by REML 
>    AIC  BIC logLik MLdeviance REMLdeviance
>   1754 1770 -871.8       1752         1744
>  Random effects:
>   Groups   Name        Variance Std.Dev. Corr  
>   Subject  (Intercept) 612.114  24.7409        
> 	   Days         35.072   5.9222  0.066 
>   Residual             654.937  25.5917        
>  Number of obs: 180, groups: Subject, 18
> 
>  Fixed effects:
> 	     Estimate Std. Error t value
>  (Intercept)  251.405      6.825   36.84
>  Days          10.467      1.546    6.77
> 
>  Correlation of Fixed Effects:
>       (Intr)
>  Days -0.138
>  > 
> 
> 
> 
>     Andrew> Does anyone else find this?  Please let me know what else I can do to
>     Andrew> help.
> 
> You can type  
>         traceback()
> 
> after the error (which you should get a habit of doing ;-)
> which might be revealing though I doubt it a bit in this case.
> 
> Are you sure that you started R as "R --vanilla", i.e.
> that you have *not* loaded an .RData of a previous session
> accidentally?
> 
> Regards,
> Martin
> 
>     Andrew> Cheers,
>     Andrew> Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From reinhold.kliegl at gmail.com  Sun Jan 28 11:22:55 2007
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sun, 28 Jan 2007 11:22:55 +0100
Subject: [R-sig-ME] Some timings for lmer2 versus lmer
Message-ID: <96349DE9-3CD0-4113-9AA8-1A10A93BBCA6@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070128/5b1fef81/attachment.ksh>

From bates at stat.wisc.edu  Sun Jan 28 18:18:56 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 28 Jan 2007 11:18:56 -0600
Subject: [R-sig-ME] New version of lme4 - memory error
In-Reply-To: <20070127223019.GE13602@ms.unimelb.edu.au>
References: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
	<20070126232714.GW13602@ms.unimelb.edu.au>
	<17851.28094.984581.79456@stat.math.ethz.ch>
	<20070127223019.GE13602@ms.unimelb.edu.au>
Message-ID: <40e66e0b0701280918i47ab5713y7ba388d65e698841@mail.gmail.com>

On 1/27/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> Thanks, Martin.  It was vanilla.
>
>
> > traceback()
> 4: .Call(mer2_getPars, mer)
> 3: as.double(start)
> 2: nlminb(.Call(mer2_getPars, mer), function(x) .Call(mer2_deviance,
>        .Call(mer2_setPars, mer, x), as.integer(0)), lower = ifelse(const,
>        0, -Inf), control = list(trace = cv$msVerbose, iter.max = cv$msMaxIter,
>        rel.tol = abs(0.001/.Call(mer2_deviance, mer, 0))))
> 1: lmer2(Reaction ~ Days + (Days | Subject), sleepstudy)

Thanks for including that traceback, Andrew.  As Martin indicated, it
is difficult for us to diagnose the problem because we are unable to
reproduce it.

I can tell you what should be happening at that point in the lmer2
function.  Perhaps you could use

debug(lmer2)

and check under your system what is happening for you.

As I'm sure you can determine just be looking at this traceback, this
is the point in lmer2 where the REML or ML criterion is to be
optimized using the optimizer nlminb.  The object 'mer', of class
'mer2', is the internal representation of a mixed-effects model.  It
is described in the Implementation vignette.

The ST slot is a list whose number of components is equal to the
number of random effects expressions in the model formula.  In this
case it should have one component and that component should be a 2x2
matrix (it's a matrix, not a Matrix from the Matrix package).  The C
code for mer2_getPars allocates a numeric vector of the correct length
and fills it out with elements of the lower triangles of these
matrices starting with the diagonal elements of each matrix.  (The
diagonal elements are the elements of the scale matrices S and the
elements of the strict lower triangle are the non-trivial elements of
the unit triangular matrices T.)

I enclose some of the debugger output from my system.  Once the mer
object is created I check that the 'dims' slot has the expected
entries.  In particular the element labeled 'nf' (number of grouping
factors) should be 1 and the nc slot should be an integer vector of
length 1 and the first element should be 2.

If the 'dims', 'nc' and 'ST' slots all have the expected contents then
it would be very mysterious how mer2_getPars managed to fail.  I
suspect that the problem originates one step back in the call to
mer2_create.  In either case it may be necessary to go in and examine
the execution of the compiled code using a symbolic debugger in order
to exactly what's going on.









>
>
> (I will add it to my list of New Year's Resolutions!)
>
>
>
> Andrew
>
>
>
> On Sat, Jan 27, 2007 at 04:20:30PM +0100, Martin Maechler wrote:
> > >>>>> "Andrew" == Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
> > >>>>>     on Sat, 27 Jan 2007 10:27:14 +1100 writes:
> >
> >     Andrew> Hi Doug, sorry, it's me having problems again :(
> >
> >     Andrew> I can install and load the new lme4 package with no
> >     Andrew> trouble, but when I try to run the examples, I get:
> >
> >     >> require(lme4)
> >     Andrew> Loading required package: lme4
> >     Andrew> Loading required package: Matrix
> >     Andrew> Loading required package: lattice
> >     Andrew> [1] TRUE
> >     >> sessionInfo()
> >     Andrew> R version 2.4.1 Patched (2007-01-25 r40572)
> >     Andrew> i386-unknown-freebsd6.1
> >
> >     Andrew> locale:
> >     Andrew> C
> >
> >     Andrew> attached base packages:
> >     Andrew> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> >     Andrew> "methods"
> >     Andrew> [7] "base"
> >
> >     Andrew> other attached packages:
> >     Andrew> lme4      Matrix     lattice
> >     Andrew> "0.9975-11"  "0.9975-8"   "0.14-16"
> >     >> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> >     >> fm1 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy)
> >     Andrew> Error in as.double(start) : Calloc could not allocate (169499040 of 4)
> >     Andrew> memory
> >
> > Hmm, I can't replicate your problem.  I get
> >
> >  > system.time( fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> >  [1] 0.112 0.001 0.124 0.000 0.000
> >  > system.time( fm1.2 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy))
> >  [1] 0.056 0.000 0.056 0.000 0.000
> >  > summary(fm1.2)
> >  Linear mixed-effects model fit by REML
> >    AIC  BIC logLik MLdeviance REMLdeviance
> >   1754 1770 -871.8       1752         1744
> >  Random effects:
> >   Groups   Name        Variance Std.Dev. Corr
> >   Subject  (Intercept) 612.114  24.7409
> >          Days         35.072   5.9222  0.066
> >   Residual             654.937  25.5917
> >  Number of obs: 180, groups: Subject, 18
> >
> >  Fixed effects:
> >            Estimate Std. Error t value
> >  (Intercept)  251.405      6.825   36.84
> >  Days          10.467      1.546    6.77
> >
> >  Correlation of Fixed Effects:
> >       (Intr)
> >  Days -0.138
> >  >
> >
> >
> >
> >     Andrew> Does anyone else find this?  Please let me know what else I can do to
> >     Andrew> help.
> >
> > You can type
> >         traceback()
> >
> > after the error (which you should get a habit of doing ;-)
> > which might be revealing though I doubt it a bit in this case.
> >
> > Are you sure that you started R as "R --vanilla", i.e.
> > that you have *not* loaded an .RData of a previous session
> > accidentally?
> >
> > Regards,
> > Martin
> >
> >     Andrew> Cheers,
> >     Andrew> Andrew
>
> --
> Andrew Robinson
> Department of Mathematics and Statistics            Tel: +61-3-8344-9763
> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>
-------------- next part --------------
Browse[1]> 
debug: mer <- .Call(mer2_create, fl, Zt, t(X), as.double(Y), method == 
    "REML", nc, cnames, fr$offset, fr$weights)
Browse[1]> 
debug: const <- unlist(lapply(mer at nc, function(n) rep(1:0, c(n, (n * 
    (n - 1))/2))))
Browse[1]> mer at ST
$Subject
          [,1]       [,2]
[1,] 0.5163978 0.00000000
[2,] 0.0000000 0.09673017
Browse[1]> mer at dims
  nf    n    p    q REML glmm 
   1  180    2   36    1    0 
Browse[1]> mer at nc
Subject 
      2 
Browse[1]> .Call("mer2_getPars", mer, PACKAGE = "lme4")
[1] 0.51639778 0.09673017 0.00000000

From A.Robinson at ms.unimelb.edu.au  Sun Jan 28 19:15:14 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 29 Jan 2007 05:15:14 +1100
Subject: [R-sig-ME] New version of lme4 - memory error
In-Reply-To: <40e66e0b0701280918i47ab5713y7ba388d65e698841@mail.gmail.com>
References: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
	<20070126232714.GW13602@ms.unimelb.edu.au>
	<17851.28094.984581.79456@stat.math.ethz.ch>
	<20070127223019.GE13602@ms.unimelb.edu.au>
	<40e66e0b0701280918i47ab5713y7ba388d65e698841@mail.gmail.com>
Message-ID: <20070128181514.GF13602@ms.unimelb.edu.au>

On Sun, Jan 28, 2007 at 11:18:56AM -0600, Douglas Bates wrote:
> On 1/27/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> >Thanks, Martin.  It was vanilla.
> >
> >
> >> traceback()
> >4: .Call(mer2_getPars, mer)
> >3: as.double(start)
> >2: nlminb(.Call(mer2_getPars, mer), function(x) .Call(mer2_deviance,
> >       .Call(mer2_setPars, mer, x), as.integer(0)), lower = ifelse(const,
> >       0, -Inf), control = list(trace = cv$msVerbose, iter.max = 
> >       cv$msMaxIter,
> >       rel.tol = abs(0.001/.Call(mer2_deviance, mer, 0))))
> >1: lmer2(Reaction ~ Days + (Days | Subject), sleepstudy)
> 
> Thanks for including that traceback, Andrew.  As Martin indicated, it
> is difficult for us to diagnose the problem because we are unable to
> reproduce it.
> 
> I can tell you what should be happening at that point in the lmer2
> function.  Perhaps you could use
> 
> debug(lmer2)
> 
> and check under your system what is happening for you.
> 
> As I'm sure you can determine just be looking at this traceback, this
> is the point in lmer2 where the REML or ML criterion is to be
> optimized using the optimizer nlminb.  The object 'mer', of class
> 'mer2', is the internal representation of a mixed-effects model.  It
> is described in the Implementation vignette.
> 
> The ST slot is a list whose number of components is equal to the
> number of random effects expressions in the model formula.  In this
> case it should have one component and that component should be a 2x2
> matrix (it's a matrix, not a Matrix from the Matrix package).  The C
> code for mer2_getPars allocates a numeric vector of the correct length
> and fills it out with elements of the lower triangles of these
> matrices starting with the diagonal elements of each matrix.  (The
> diagonal elements are the elements of the scale matrices S and the
> elements of the strict lower triangle are the non-trivial elements of
> the unit triangular matrices T.)
> 
> I enclose some of the debugger output from my system.  Once the mer
> object is created I check that the 'dims' slot has the expected
> entries.  In particular the element labeled 'nf' (number of grouping
> factors) should be 1 and the nc slot should be an integer vector of
> length 1 and the first element should be 2.
> 
> If the 'dims', 'nc' and 'ST' slots all have the expected contents then
> it would be very mysterious how mer2_getPars managed to fail.  I
> suspect that the problem originates one step back in the call to
> mer2_create.  In either case it may be necessary to go in and examine
> the execution of the compiled code using a symbolic debugger in order
> to exactly what's going on.

Thanks for your detailed response, Doug.  I ran debug(lmer2) as you
suggested, and as you expected, I got the same results as you did.  Of
course I would like to dig further into this problem.  I have limited
experience using gdb, but I have used it.  If you don't mind providing
a brief set of instructions, I will carry them out.

Andrew
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Sun Jan 28 19:29:29 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 28 Jan 2007 12:29:29 -0600
Subject: [R-sig-ME] New version of lme4 - memory error
In-Reply-To: <20070128181514.GF13602@ms.unimelb.edu.au>
References: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
	<20070126232714.GW13602@ms.unimelb.edu.au>
	<17851.28094.984581.79456@stat.math.ethz.ch>
	<20070127223019.GE13602@ms.unimelb.edu.au>
	<40e66e0b0701280918i47ab5713y7ba388d65e698841@mail.gmail.com>
	<20070128181514.GF13602@ms.unimelb.edu.au>
Message-ID: <40e66e0b0701281029i59c71005g9990d304a0cda6dd@mail.gmail.com>

On 1/28/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> On Sun, Jan 28, 2007 at 11:18:56AM -0600, Douglas Bates wrote:
> > On 1/27/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> > >Thanks, Martin.  It was vanilla.
> > >
> > >
> > >> traceback()
> > >4: .Call(mer2_getPars, mer)
> > >3: as.double(start)
> > >2: nlminb(.Call(mer2_getPars, mer), function(x) .Call(mer2_deviance,
> > >       .Call(mer2_setPars, mer, x), as.integer(0)), lower = ifelse(const,
> > >       0, -Inf), control = list(trace = cv$msVerbose, iter.max =
> > >       cv$msMaxIter,
> > >       rel.tol = abs(0.001/.Call(mer2_deviance, mer, 0))))
> > >1: lmer2(Reaction ~ Days + (Days | Subject), sleepstudy)
> >
> > Thanks for including that traceback, Andrew.  As Martin indicated, it
> > is difficult for us to diagnose the problem because we are unable to
> > reproduce it.
> >
> > I can tell you what should be happening at that point in the lmer2
> > function.  Perhaps you could use
> >
> > debug(lmer2)
> >
> > and check under your system what is happening for you.
> >
> > As I'm sure you can determine just be looking at this traceback, this
> > is the point in lmer2 where the REML or ML criterion is to be
> > optimized using the optimizer nlminb.  The object 'mer', of class
> > 'mer2', is the internal representation of a mixed-effects model.  It
> > is described in the Implementation vignette.
> >
> > The ST slot is a list whose number of components is equal to the
> > number of random effects expressions in the model formula.  In this
> > case it should have one component and that component should be a 2x2
> > matrix (it's a matrix, not a Matrix from the Matrix package).  The C
> > code for mer2_getPars allocates a numeric vector of the correct length
> > and fills it out with elements of the lower triangles of these
> > matrices starting with the diagonal elements of each matrix.  (The
> > diagonal elements are the elements of the scale matrices S and the
> > elements of the strict lower triangle are the non-trivial elements of
> > the unit triangular matrices T.)
> >
> > I enclose some of the debugger output from my system.  Once the mer
> > object is created I check that the 'dims' slot has the expected
> > entries.  In particular the element labeled 'nf' (number of grouping
> > factors) should be 1 and the nc slot should be an integer vector of
> > length 1 and the first element should be 2.
> >
> > If the 'dims', 'nc' and 'ST' slots all have the expected contents then
> > it would be very mysterious how mer2_getPars managed to fail.  I
> > suspect that the problem originates one step back in the call to
> > mer2_create.  In either case it may be necessary to go in and examine
> > the execution of the compiled code using a symbolic debugger in order
> > to exactly what's going on.
>
> Thanks for your detailed response, Doug.  I ran debug(lmer2) as you
> suggested, and as you expected, I got the same results as you did.  Of
> course I would like to dig further into this problem.  I have limited
> experience using gdb, but I have used it.  If you don't mind providing
> a brief set of instructions, I will carry them out.

Well, actually, that wasn't what I was expecting.  I thought that
something would look wrong in those slots.

Can you be more specific about getting the same results as I did?  In
particular, did you get the same response to

.Call("mer2_getPars", mer, PACKAGE = "lme4")

If so, I'm not quite sure how it would fail in the same call
immediately afterwards.

I'll respond about how I use gdb in a susequent message.

>
> Andrew
> --
> Andrew Robinson
> Department of Mathematics and Statistics            Tel: +61-3-8344-9763
> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>



From A.Robinson at ms.unimelb.edu.au  Sun Jan 28 20:01:25 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 29 Jan 2007 06:01:25 +1100
Subject: [R-sig-ME] Timing for lmer2 versus lmer for chocolate cake data
	(WinXP)
In-Reply-To: <40e66e0b0701271141s6361e0a7lac673f329eeb60db@mail.gmail.com>
References: <40e66e0b0701271141s6361e0a7lac673f329eeb60db@mail.gmail.com>
Message-ID: <20070128190125.GG13602@ms.unimelb.edu.au>

I've switched from FreeBSD to WinXP temporarily :)

I've attached a comparison of lmer and lmer2 upon the analysis of
Cochran and Cox's chocolate cake data.  Here, it seems that lmer2 is
faster (0.08 vs. 0.15) but the AIC of the fitted model for lmer2 is
higher (1643 vs 1635).  The models are quite different in the random
effects.

The data, script, and output are attached.

Cheers,

Andrew
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/ 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cake.csv
Type: text/csv
Size: 11115 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070129/f3fd9ff6/attachment.bin>
-------------- next part --------------
# The chocolate cake breakage data are referred to in section 5.5 of
# \citet{lee+nelder+pawitan-2006} as an example of a normal-normal
# hiearchical generalized linear model. The data are originally from
# \citet{cochran+cox-1957}.

require(lme4)

cake <- read.csv("cake.csv")
names(cake) <- c("replicate","batch","recipe","temperature","angle")
cake$recipe <- factor(cake$recipe)
cake$replicate <- factor(cake$replicate)
cake$batch <- factor(cake$batch)
cake$temperature <- factor(cake$temperature)
dim(cake)
head(cake)

system.time(cake.lmer <- lmer(angle ~ recipe * temperature + 
                  (1 | replicate/batch),
                  data = cake))
summary(cake.lmer)
system.time(cake.lmer2 <- lmer2(angle ~ recipe * temperature + 
                  (1 | replicate/batch),
                  data = cake))
summary(cake.lmer2)

sessionInfo()

-------------- next part --------------

> require(lme4)
[1] TRUE

> cake <- read.csv("cake.csv")

> names(cake) <- c("replicate", "batch", "recipe", "temperature", 
    "angle")

> cake$recipe <- factor(cake$recipe)

> cake$replicate <- factor(cake$replicate)

> cake$batch <- factor(cake$batch)

> cake$temperature <- factor(cake$temperature)

> dim(cake)
[1] 270   5

> head(cake)
  replicate batch recipe temperature angle
1         1     1      1         175    42
2         1     1      1         185    46
3         1     1      1         195    47
4         1     1      1         205    39
5         1     1      1         215    53
6         1     1      1         225    42

> system.time(cake.lmer <- lmer(angle ~ recipe * temperature + 
    (1 | replicate/batch), data = cake))
[1] 0.15 0.00 0.16   NA   NA

> summary(cake.lmer)
Linear mixed-effects model fit by REML 
Formula: angle ~ recipe * temperature + (1 | replicate/batch) 
   Data: cake 
  AIC  BIC logLik MLdeviance REMLdeviance
 1635 1707 -797.7       1638         1595
Random effects:
 Groups          Name        Variance Std.Dev.
 batch:replicate (Intercept)  3.7384  1.9335  
 replicate       (Intercept) 38.2278  6.1829  
 Residual                    20.4613  4.5234  
number of obs: 270, groups: batch:replicate, 45; replicate, 15

Fixed effects:
                       Estimate Std. Error t value
(Intercept)             29.1333     2.0401  14.281
recipe2                 -2.2667     1.7963  -1.262
recipe3                 -1.2000     1.7963  -0.668
temperature185           2.4000     1.6517   1.453
temperature195           1.6667     1.6517   1.009
temperature205           4.4000     1.6517   2.664
temperature215           9.5333     1.6517   5.772
temperature225           5.9333     1.6517   3.592
recipe2:temperature185   0.1333     2.3359   0.057
recipe3:temperature185  -1.4000     2.3359  -0.599
recipe2:temperature195   3.2000     2.3359   1.370
recipe3:temperature195   2.1333     2.3359   0.913
recipe2:temperature205   0.8667     2.3359   0.371
recipe3:temperature205  -1.4667     2.3359  -0.628
recipe2:temperature215  -1.9333     2.3359  -0.828
recipe3:temperature215  -3.0667     2.3359  -1.313
recipe2:temperature225   2.4667     2.3359   1.056
recipe3:temperature225   1.8667     2.3359   0.799

Correlation of Fixed Effects:
            (Intr) recip2 recip3 tmp185 tmp195 tmp205 tmp215 tmp225 r2:185
recipe2     -0.440                                                        
recipe3     -0.440  0.500                                                 
tempertr185 -0.405  0.460  0.460                                          
tempertr195 -0.405  0.460  0.460  0.500                                   
tempertr205 -0.405  0.460  0.460  0.500  0.500                            
tempertr215 -0.405  0.460  0.460  0.500  0.500  0.500                     
tempertr225 -0.405  0.460  0.460  0.500  0.500  0.500  0.500              
rcp2:tmp185  0.286 -0.650 -0.325 -0.707 -0.354 -0.354 -0.354 -0.354       
rcp3:tmp185  0.286 -0.325 -0.650 -0.707 -0.354 -0.354 -0.354 -0.354  0.500
rcp2:tmp195  0.286 -0.650 -0.325 -0.354 -0.707 -0.354 -0.354 -0.354  0.500
rcp3:tmp195  0.286 -0.325 -0.650 -0.354 -0.707 -0.354 -0.354 -0.354  0.250
rcp2:tmp205  0.286 -0.650 -0.325 -0.354 -0.354 -0.707 -0.354 -0.354  0.500
rcp3:tmp205  0.286 -0.325 -0.650 -0.354 -0.354 -0.707 -0.354 -0.354  0.250
rcp2:tmp215  0.286 -0.650 -0.325 -0.354 -0.354 -0.354 -0.707 -0.354  0.500
rcp3:tmp215  0.286 -0.325 -0.650 -0.354 -0.354 -0.354 -0.707 -0.354  0.250
rcp2:tmp225  0.286 -0.650 -0.325 -0.354 -0.354 -0.354 -0.354 -0.707  0.500
rcp3:tmp225  0.286 -0.325 -0.650 -0.354 -0.354 -0.354 -0.354 -0.707  0.250
            r3:185 r2:195 r3:195 r2:205 r3:205 r2:215 r3:215 r2:225
recipe2                                                            
recipe3                                                            
tempertr185                                                        
tempertr195                                                        
tempertr205                                                        
tempertr215                                                        
tempertr225                                                        
rcp2:tmp185                                                        
rcp3:tmp185                                                        
rcp2:tmp195  0.250                                                 
rcp3:tmp195  0.500  0.500                                          
rcp2:tmp205  0.250  0.500  0.250                                   
rcp3:tmp205  0.500  0.250  0.500  0.500                            
rcp2:tmp215  0.250  0.500  0.250  0.500  0.250                     
rcp3:tmp215  0.500  0.250  0.500  0.250  0.500  0.500              
rcp2:tmp225  0.250  0.500  0.250  0.500  0.250  0.500  0.250       
rcp3:tmp225  0.500  0.250  0.500  0.250  0.500  0.250  0.500  0.500

> system.time(cake.lmer2 <- lmer2(angle ~ recipe * temperature + 
    (1 | replicate/batch), data = cake))
[1] 0.08 0.00 0.06   NA   NA

> summary(cake.lmer2)
Linear mixed-effects model fit by REML 
  AIC  BIC logLik MLdeviance REMLdeviance
 1643 1715 -801.7       1647         1603
Random effects:
 Groups          Name        Variance   Std.Dev. 
 batch:replicate (Intercept) 2.2454e-06 0.0014985
 replicate       (Intercept) 3.9195e+01 6.2605709
 Residual                    2.3099e+01 4.8061038
Number of obs: 270, groups: batch:replicate, 45; replicate, 15

Fixed effects:
                       Estimate Std. Error t value
(Intercept)             29.1333     2.0379  14.296
recipe2                 -2.2667     1.7549  -1.292
recipe3                 -1.2000     1.7549  -0.684
temperature185           2.4000     1.7549   1.368
temperature195           1.6667     1.7549   0.950
temperature205           4.4000     1.7549   2.507
temperature215           9.5333     1.7549   5.432
temperature225           5.9333     1.7549   3.381
recipe2:temperature185   0.1333     2.4819   0.054
recipe3:temperature185  -1.4000     2.4819  -0.564
recipe2:temperature195   3.2000     2.4819   1.289
recipe3:temperature195   2.1333     2.4819   0.860
recipe2:temperature205   0.8667     2.4819   0.349
recipe3:temperature205  -1.4667     2.4819  -0.591
recipe2:temperature215  -1.9333     2.4819  -0.779
recipe3:temperature215  -3.0667     2.4819  -1.236
recipe2:temperature225   2.4667     2.4819   0.994
recipe3:temperature225   1.8667     2.4819   0.752

Correlation of Fixed Effects:
            (Intr) recip2 recip3 tmp185 tmp195 tmp205 tmp215 tmp225 r2:185
recipe2     -0.431                                                        
recipe3     -0.431  0.500                                                 
tempertr185 -0.431  0.500  0.500                                          
tempertr195 -0.431  0.500  0.500  0.500                                   
tempertr205 -0.431  0.500  0.500  0.500  0.500                            
tempertr215 -0.431  0.500  0.500  0.500  0.500  0.500                     
tempertr225 -0.431  0.500  0.500  0.500  0.500  0.500  0.500              
rcp2:tmp185  0.304 -0.707 -0.354 -0.707 -0.354 -0.354 -0.354 -0.354       
rcp3:tmp185  0.304 -0.354 -0.707 -0.707 -0.354 -0.354 -0.354 -0.354  0.500
rcp2:tmp195  0.304 -0.707 -0.354 -0.354 -0.707 -0.354 -0.354 -0.354  0.500
rcp3:tmp195  0.304 -0.354 -0.707 -0.354 -0.707 -0.354 -0.354 -0.354  0.250
rcp2:tmp205  0.304 -0.707 -0.354 -0.354 -0.354 -0.707 -0.354 -0.354  0.500
rcp3:tmp205  0.304 -0.354 -0.707 -0.354 -0.354 -0.707 -0.354 -0.354  0.250
rcp2:tmp215  0.304 -0.707 -0.354 -0.354 -0.354 -0.354 -0.707 -0.354  0.500
rcp3:tmp215  0.304 -0.354 -0.707 -0.354 -0.354 -0.354 -0.707 -0.354  0.250
rcp2:tmp225  0.304 -0.707 -0.354 -0.354 -0.354 -0.354 -0.354 -0.707  0.500
rcp3:tmp225  0.304 -0.354 -0.707 -0.354 -0.354 -0.354 -0.354 -0.707  0.250
            r3:185 r2:195 r3:195 r2:205 r3:205 r2:215 r3:215 r2:225
recipe2                                                            
recipe3                                                            
tempertr185                                                        
tempertr195                                                        
tempertr205                                                        
tempertr215                                                        
tempertr225                                                        
rcp2:tmp185                                                        
rcp3:tmp185                                                        
rcp2:tmp195  0.250                                                 
rcp3:tmp195  0.500  0.500                                          
rcp2:tmp205  0.250  0.500  0.250                                   
rcp3:tmp205  0.500  0.250  0.500  0.500                            
rcp2:tmp215  0.250  0.500  0.250  0.500  0.250                     
rcp3:tmp215  0.500  0.250  0.500  0.250  0.500  0.500              
rcp2:tmp225  0.250  0.500  0.250  0.500  0.250  0.500  0.250       
rcp3:tmp225  0.500  0.250  0.500  0.250  0.500  0.250  0.500  0.500

> sessionInfo()
R version 2.4.1 (2006-12-18) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[7] "base"     

other attached packages:
       lme4      Matrix     lattice 
"0.9975-11"  "0.9975-8"   "0.14-16" 

From bates at stat.wisc.edu  Sun Jan 28 20:18:10 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 28 Jan 2007 13:18:10 -0600
Subject: [R-sig-ME] Using gdb to debug memory errors
Message-ID: <40e66e0b0701281118g145df496pe83e9baa5600fa89@mail.gmail.com>

Some of these instructions are given in section 4.4 of the manual
"Writing R Extensions", which you should also read.

It is best to recompile and reinstall the lme4 package removing any
optimization settings before trying to invoke the debugger on the
compiled code.  It is possible to run the debugger on optimized code
but it can be very confusing to do so.

I define two versions of the CFLAGS macro, one with a -O setting and
one without, in the file ~/.R/Makevars and comment out the one that I
don't want to use.  The R CMD INSTALL process automatically looks for
this file.  My version is

bates at gchq:~$ cat /home/bates/.R/Makevars
CFLAGS = -g -O3 -std=gnu99 -Wall -pedantic
#CFLAGS = -g -std=gnu99 -Wall -pedantic

so I am currently set for optimization.  Switching the position of the
'#' character to the other line sets you up for debugging.

I generally run both R and gdb inside emacs so my sequence is to start
R (using ESS) and attach the lme4 package then start gdb (using M-x
gdb<RET>).  This prompts you for the name of the executable file which
is $R_HOME/bin/exec/R for whatever your value of $R_HOME is.  You need
to attach the debugger to the already running R process for which you
need the process number.  One way to get that is to examine the output
from "ps ux".  You can sometimes use "pgrep R" to list the processes
and grep for 'R' in one step.  Typically that will produce two
numbers, the first of which is the shell script called R and the
second of which is the actual process.

Go to the gdb buffer which will be called *gud-<something>* (that's
not a typo - 'gud' is the grand unified debugger interface) and enter

attach <process number>

If things are going well at this point you will get a lot of output
about the symbols that gdb has read.  When that finishes you can set
breakpoints in the code if you wish.  Typically you set a breakpoint
at the beginning of a function such as

break mer2_getPars

Whether or not you set breakpoints you need to restart the R process
to be able to return control to it.  I do this by sending the 0 signal
from within gdb

signal 0

At that point you can return to the ess buffer and use R again.  There
may be peculiarites in refreshing this window inside ESS (perhaps
Martin will be able to provide more detail on what happens in ESS at
this point).  If the process seems to have hung then use C-c C-c to
see if it is just waiting for an echo.  Once it goes into a function
where you have a breakpoint you can return to the *gud-<whatever>*
window and step through the execution using 'n' (next line) or 's'
(single step).  You can also print out the values of variables with 'p
<name>'.  For vectors there is a convenient notion of an artificial
array produced with the '@' sign so you could ask for

p dims[0]@6

to get 6 elements from an array called dims.

An alternative is to run your R code that causes the memory fault and
let the debugger catch the signal.  That is, attach the debugger to
the process but don't set any breakpoints.  Just let it run until the
problem crops up.  Frequently the problem is detected long after it
has occurred so you need to look at the output of

where

(which could be long indeed) and move up several frames to get to a
place where you recognize the code.



From bates at stat.wisc.edu  Sun Jan 28 20:49:51 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 28 Jan 2007 13:49:51 -0600
Subject: [R-sig-ME] Timing for lmer2 versus lmer for chocolate cake data
	(WinXP)
In-Reply-To: <20070128190125.GG13602@ms.unimelb.edu.au>
References: <40e66e0b0701271141s6361e0a7lac673f329eeb60db@mail.gmail.com>
	<20070128190125.GG13602@ms.unimelb.edu.au>
Message-ID: <40e66e0b0701281149o4ea41f59v46a9c0226d0aee38@mail.gmail.com>

On 1/28/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> I've switched from FreeBSD to WinXP temporarily :)
>
> I've attached a comparison of lmer and lmer2 upon the analysis of
> Cochran and Cox's chocolate cake data.  Here, it seems that lmer2 is
> faster (0.08 vs. 0.15) but the AIC of the fitted model for lmer2 is
> higher (1643 vs 1635).  The models are quite different in the random
> effects.

Thanks for including that example Andrew.  If you turn on the
msVerbose control setting you will see that it is a problem in the
optimizer behavior near the boundary for the new parameterization
(script and output attached).

It is a good thing to have such an example.  I had only observed the
opposite behavior where the optimizer had boundary problems in the
relative variance scale but not in the relative standard deviation
scale.  I'm not quite sure what I am going to do about it though.
-------------- next part --------------
# The chocolate cake breakage data are referred to in section 5.5 of
# \citet{lee+nelder+pawitan-2006} as an example of a normal-normal
# hiearchical generalized linear model. The data are originally from
# \citet{cochran+cox-1957}.

require(lme4)
load("~/tmp/cake.rda")
str(cake)
head(cake)

system.time(cake.lmer <- lmer(angle ~ recipe * temperature + 
                  (1 | replicate/batch),
                  data = cake,
                  control = list(msV = 1, niterEM = 0, grad = FALSE)))
system.time(cake.lmer2 <- lmer2(angle ~ recipe * temperature + 
                  (1 | replicate/batch),
                  data = cake, control = list(msV = 1)))
c(0.666667, 0.384900)^2
print(cake.lmer, corr = FALSE)
print(cake.lmer2, corr = FALSE)

sessionInfo()
-------------- next part --------------

R version 2.5.0 Under development (unstable) (2007-01-28 r40596)
Copyright (C) 2007 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # The chocolate cake breakage data are referred to in section 5.5 of
> # \citet{lee+nelder+pawitan-2006} as an example of a normal-normal
> # hiearchical generalized linear model. The data are originally from
> # \citet{cochran+cox-1957}.
> 
> require(lme4)
Loading required package: lme4
Loading required package: Matrix
Loading required package: lattice
[1] TRUE
> load("~/tmp/cake.rda")
> str(cake)
'data.frame':	270 obs. of  5 variables:
 $ replicate  : Factor w/ 15 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ batch      : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 2 2 2 2 ...
 $ recipe     : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 2 2 2 2 ...
 $ temperature: Factor w/ 6 levels "175","185","195",..: 1 2 3 4 5 6 1 2 3 4 ...
 $ angle      : int  42 46 47 39 53 42 39 46 51 49 ...
> head(cake)
  replicate batch recipe temperature angle
1         1     1      1         175    42
2         1     1      1         185    46
3         1     1      1         195    47
4         1     1      1         205    39
5         1     1      1         215    53
6         1     1      1         225    42
> 
> system.time(cake.lmer <- lmer(angle ~ recipe * temperature + 
+                   (1 | replicate/batch),
+                   data = cake,
+                   control = list(msV = 1, niterEM = 0, grad = FALSE)))
  0      1634.73: 0.444444 0.148148
  1      1603.11: 0.608821  1.13455
  2      1597.79: 0.320190  1.21276
  3      1596.71: 0.240022  1.23799
  4      1596.28: 0.164550  1.27497
  5      1596.15: 0.173446  1.30522
  6      1595.82: 0.199696  1.42855
  7      1595.57: 0.196701  1.55461
  8      1595.37: 0.182251  1.75435
  9      1595.35: 0.180630  1.83013
 10      1595.35: 0.181575  1.85835
 11      1595.35: 0.181800  1.86184
   user  system elapsed 
  0.084   0.000   0.085 
> system.time(cake.lmer2 <- lmer2(angle ~ recipe * temperature + 
+                   (1 | replicate/batch),
+                   data = cake, control = list(msV = 1)))
  0      1634.73: 0.666667 0.384900
  1      1606.88: 0.943988  1.34568
  2      1603.44:  0.00000  1.32963
  3      1603.43: 2.67531e-05  1.30813
  4      1603.43: 0.000311112  1.30263
   user  system elapsed 
  0.036   0.004   0.040 
> c(0.666667, 0.384900)^2
[1] 0.4444449 0.1481480
> print(cake.lmer, corr = FALSE)
Linear mixed-effects model fit by REML 
Formula: angle ~ recipe * temperature + (1 | replicate/batch) 
   Data: cake 
  AIC  BIC logLik MLdeviance REMLdeviance
 1635 1707 -797.7       1638         1595
Random effects:
 Groups          Name        Variance Std.Dev.
 batch:replicate (Intercept)  3.7216  1.9292  
 replicate       (Intercept) 38.1137  6.1736  
 Residual                    20.4710  4.5245  
number of obs: 270, groups: batch:replicate, 45; replicate, 15

Fixed effects:
                       Estimate Std. Error t value
(Intercept)             29.1333     2.0381  14.295
recipe2                 -2.2667     1.7960  -1.262
recipe3                 -1.2000     1.7960  -0.668
temperature185           2.4000     1.6521   1.453
temperature195           1.6667     1.6521   1.009
temperature205           4.4000     1.6521   2.663
temperature215           9.5333     1.6521   5.770
temperature225           5.9333     1.6521   3.591
recipe2:temperature185   0.1333     2.3364   0.057
recipe3:temperature185  -1.4000     2.3364  -0.599
recipe2:temperature195   3.2000     2.3364   1.370
recipe3:temperature195   2.1333     2.3364   0.913
recipe2:temperature205   0.8667     2.3364   0.371
recipe3:temperature205  -1.4667     2.3364  -0.628
recipe2:temperature215  -1.9333     2.3364  -0.827
recipe3:temperature215  -3.0667     2.3364  -1.313
recipe2:temperature225   2.4667     2.3364   1.056
recipe3:temperature225   1.8667     2.3364   0.799
> print(cake.lmer2, corr = FALSE)
Linear mixed-effects model fit by REML 
Formula: angle ~ recipe * temperature + (1 | replicate/batch) 
   Data: cake 
  AIC  BIC logLik MLdeviance REMLdeviance
 1643 1715 -801.7       1647         1603
Random effects:
 Groups          Name        Variance   Std.Dev. 
 batch:replicate (Intercept) 2.2357e-06 0.0014952
 replicate       (Intercept) 3.9195e+01 6.2605706
 Residual                    2.3099e+01 4.8061039
Number of obs: 270, groups: batch:replicate, 45; replicate, 15

Fixed effects:
                       Estimate Std. Error t value
(Intercept)             29.1333     2.0379  14.296
recipe2                 -2.2667     1.7549  -1.292
recipe3                 -1.2000     1.7549  -0.684
temperature185           2.4000     1.7549   1.368
temperature195           1.6667     1.7549   0.950
temperature205           4.4000     1.7549   2.507
temperature215           9.5333     1.7549   5.432
temperature225           5.9333     1.7549   3.381
recipe2:temperature185   0.1333     2.4819   0.054
recipe3:temperature185  -1.4000     2.4819  -0.564
recipe2:temperature195   3.2000     2.4819   1.289
recipe3:temperature195   2.1333     2.4819   0.860
recipe2:temperature205   0.8667     2.4819   0.349
recipe3:temperature205  -1.4667     2.4819  -0.591
recipe2:temperature215  -1.9333     2.4819  -0.779
recipe3:temperature215  -3.0667     2.4819  -1.236
recipe2:temperature225   2.4667     2.4819   0.994
recipe3:temperature225   1.8667     2.4819   0.752
> 
> sessionInfo()
R version 2.5.0 Under development (unstable) (2007-01-28 r40596) 
x86_64-unknown-linux-gnu 

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[7] "base"     

other attached packages:
       lme4      Matrix     lattice 
"0.9975-10"  "0.9975-9"   "0.14-16" 
> 
> 
> proc.time()
   user  system elapsed 
  7.524   0.180   7.749 
> 

From A.Robinson at ms.unimelb.edu.au  Mon Jan 29 09:39:28 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 29 Jan 2007 19:39:28 +1100
Subject: [R-sig-ME] New version of lme4 - memory error
In-Reply-To: <40e66e0b0701281029i59c71005g9990d304a0cda6dd@mail.gmail.com>
References: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
	<20070126232714.GW13602@ms.unimelb.edu.au>
	<17851.28094.984581.79456@stat.math.ethz.ch>
	<20070127223019.GE13602@ms.unimelb.edu.au>
	<40e66e0b0701280918i47ab5713y7ba388d65e698841@mail.gmail.com>
	<20070128181514.GF13602@ms.unimelb.edu.au>
	<40e66e0b0701281029i59c71005g9990d304a0cda6dd@mail.gmail.com>
Message-ID: <20070129083928.GN13602@ms.unimelb.edu.au>

On Sun, Jan 28, 2007 at 12:29:29PM -0600, Douglas Bates wrote:
> On 1/28/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> >On Sun, Jan 28, 2007 at 11:18:56AM -0600, Douglas Bates wrote:
> >> On 1/27/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> >> >Thanks, Martin.  It was vanilla.
> >> >
> >> >
> >> >> traceback()
> >> >4: .Call(mer2_getPars, mer)
> >> >3: as.double(start)
> >> >2: nlminb(.Call(mer2_getPars, mer), function(x) .Call(mer2_deviance,
> >> >       .Call(mer2_setPars, mer, x), as.integer(0)), lower = 
> >ifelse(const,
> >> >       0, -Inf), control = list(trace = cv$msVerbose, iter.max =
> >> >       cv$msMaxIter,
> >> >       rel.tol = abs(0.001/.Call(mer2_deviance, mer, 0))))
> >> >1: lmer2(Reaction ~ Days + (Days | Subject), sleepstudy)
> >>
> >> Thanks for including that traceback, Andrew.  As Martin indicated, it
> >> is difficult for us to diagnose the problem because we are unable to
> >> reproduce it.
> >>
> >> I can tell you what should be happening at that point in the lmer2
> >> function.  Perhaps you could use
> >>
> >> debug(lmer2)
> >>
> >> and check under your system what is happening for you.
> >>
> >> As I'm sure you can determine just be looking at this traceback, this
> >> is the point in lmer2 where the REML or ML criterion is to be
> >> optimized using the optimizer nlminb.  The object 'mer', of class
> >> 'mer2', is the internal representation of a mixed-effects model.  It
> >> is described in the Implementation vignette.
> >>
> >> The ST slot is a list whose number of components is equal to the
> >> number of random effects expressions in the model formula.  In this
> >> case it should have one component and that component should be a 2x2
> >> matrix (it's a matrix, not a Matrix from the Matrix package).  The C
> >> code for mer2_getPars allocates a numeric vector of the correct length
> >> and fills it out with elements of the lower triangles of these
> >> matrices starting with the diagonal elements of each matrix.  (The
> >> diagonal elements are the elements of the scale matrices S and the
> >> elements of the strict lower triangle are the non-trivial elements of
> >> the unit triangular matrices T.)
> >>
> >> I enclose some of the debugger output from my system.  Once the mer
> >> object is created I check that the 'dims' slot has the expected
> >> entries.  In particular the element labeled 'nf' (number of grouping
> >> factors) should be 1 and the nc slot should be an integer vector of
> >> length 1 and the first element should be 2.
> >>
> >> If the 'dims', 'nc' and 'ST' slots all have the expected contents then
> >> it would be very mysterious how mer2_getPars managed to fail.  I
> >> suspect that the problem originates one step back in the call to
> >> mer2_create.  In either case it may be necessary to go in and examine
> >> the execution of the compiled code using a symbolic debugger in order
> >> to exactly what's going on.
> >
> >Thanks for your detailed response, Doug.  I ran debug(lmer2) as you
> >suggested, and as you expected, I got the same results as you did.  Of
> >course I would like to dig further into this problem.  I have limited
> >experience using gdb, but I have used it.  If you don't mind providing
> >a brief set of instructions, I will carry them out.
> 
> Well, actually, that wasn't what I was expecting.  I thought that
> something would look wrong in those slots.
> 
> Can you be more specific about getting the same results as I did?  In
> particular, did you get the same response to
> 
> .Call("mer2_getPars", mer, PACKAGE = "lme4")
> 
> If so, I'm not quite sure how it would fail in the same call
> immediately afterwards.

I'm sorry, what I told you was wrong.  I get:

Browse[1]> 
debug: mer <- .Call(mer2_create, fl, Zt, t(X), as.double(Y), method == 
    "REML", nc, cnames, fr$offset, fr$weights)
Browse[1]> 
debug: const <- unlist(lapply(mer at nc, function(n) rep(1:0, c(n, (n * 
    (n - 1))/2))))
Browse[1]> mer at ST
$Subject
          [,1]       [,2]
[1,] 0.5163978 0.00000000
[2,] 0.0000000 0.09673017

Browse[1]> mer at dims
  nf    n    p    q REML glmm 
   1  180    2   36    1    0 
Browse[1]> mer at nc
Subject 
      2 
Browse[1]> .Call("mer2_getPars", mer, PACKAGE = "lme4")
Error: Calloc could not allocate (164788288 of 4) memory




the last of which is clearly different than you got :)

Andrew
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Mon Jan 29 15:37:42 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 29 Jan 2007 08:37:42 -0600
Subject: [R-sig-ME] Timing for lmer2 versus lmer for chocolate cake data
	(WinXP)
In-Reply-To: <40e66e0b0701281149o4ea41f59v46a9c0226d0aee38@mail.gmail.com>
References: <40e66e0b0701271141s6361e0a7lac673f329eeb60db@mail.gmail.com>
	<20070128190125.GG13602@ms.unimelb.edu.au>
	<40e66e0b0701281149o4ea41f59v46a9c0226d0aee38@mail.gmail.com>
Message-ID: <40e66e0b0701290637v5f478ce7m3b9f2c6aa977f993@mail.gmail.com>

On 1/28/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 1/28/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> > I've switched from FreeBSD to WinXP temporarily :)
> >
> > I've attached a comparison of lmer and lmer2 upon the analysis of
> > Cochran and Cox's chocolate cake data.  Here, it seems that lmer2 is
> > faster (0.08 vs. 0.15) but the AIC of the fitted model for lmer2 is
> > higher (1643 vs 1635).  The models are quite different in the random
> > effects.
>
> Thanks for including that example Andrew.  If you turn on the
> msVerbose control setting you will see that it is a problem in the
> optimizer behavior near the boundary for the new parameterization
> (script and output attached).
>
> It is a good thing to have such an example.  I had only observed the
> opposite behavior where the optimizer had boundary problems in the
> relative variance scale but not in the relative standard deviation
> scale.  I'm not quite sure what I am going to do about it though.

I have just committed a couple of changes to the SVN archive for the
lme4 package

https://svn.r-project.org/R-packages/trunk/lme4

that allow lmer2 to fit this model to these data and obtain the same
estimates as lmer did.

One approach is to fit a simpler model with additive fixed effects
first and use the fitted variance components from that model as the
starting estimates for the model that allows for interaction of the
fixed effects.  The version of lmer2 on the SVN archive allows you to
specify a start argument that should be in the form of the ST slot for
the model.  If you fit two models with the same random effects
specification then you can use the ST slot from the first as the
starting estimate for the second.

The other thing that I did was to change the call in lmer2 to the
nlminb optimizer so that it uses the default setting of the rel.tol
convergence criterion.  In the currently released version of lme4 the
this criterion is reset so that convergence is declared if the
deviance apparently has been determined to an accuracy of 0.001.  I
made this change because we observed that in many cases a substantial
portion of the iterations of the optimizer were spent at the optimum
making very small changes in parameter values that did not have a
substantial impact on the value of the deviance.

It looks like changing that criterion was too risky.  I would rather
have slower optimization with a higher degree of confidence that the
declared optimum is indeed the optimum.

I enclose R code and output for fitting these models with the modified
(and, as yet, unreleased) version of lmer2.  I also modified the cake
data so that the temperature is an ordered factor.  This results in
slightly different values of the REML criterion but you can still see
the pattern of convergence.  My purpose in using an ordered factor is
to see if the linear contrast in the temperature is dominant, which it
is.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: cake_R.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070129/cce70675/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: cake_Rout.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070129/cce70675/attachment-0001.txt>

From bates at stat.wisc.edu  Mon Jan 29 15:47:36 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 29 Jan 2007 08:47:36 -0600
Subject: [R-sig-ME] New version of lme4 - memory error
In-Reply-To: <20070129083928.GN13602@ms.unimelb.edu.au>
References: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>
	<20070126232714.GW13602@ms.unimelb.edu.au>
	<17851.28094.984581.79456@stat.math.ethz.ch>
	<20070127223019.GE13602@ms.unimelb.edu.au>
	<40e66e0b0701280918i47ab5713y7ba388d65e698841@mail.gmail.com>
	<20070128181514.GF13602@ms.unimelb.edu.au>
	<40e66e0b0701281029i59c71005g9990d304a0cda6dd@mail.gmail.com>
	<20070129083928.GN13602@ms.unimelb.edu.au>
Message-ID: <40e66e0b0701290647k34d9bc18mc0d933f3338259cc@mail.gmail.com>

On 1/29/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> On Sun, Jan 28, 2007 at 12:29:29PM -0600, Douglas Bates wrote:
> > On 1/28/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> > >On Sun, Jan 28, 2007 at 11:18:56AM -0600, Douglas Bates wrote:
> > >> On 1/27/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> > >> >Thanks, Martin.  It was vanilla.
> > >> >
> > >> >
> > >> >> traceback()
> > >> >4: .Call(mer2_getPars, mer)
> > >> >3: as.double(start)
> > >> >2: nlminb(.Call(mer2_getPars, mer), function(x) .Call(mer2_deviance,
> > >> >       .Call(mer2_setPars, mer, x), as.integer(0)), lower =
> > >ifelse(const,
> > >> >       0, -Inf), control = list(trace = cv$msVerbose, iter.max =
> > >> >       cv$msMaxIter,
> > >> >       rel.tol = abs(0.001/.Call(mer2_deviance, mer, 0))))
> > >> >1: lmer2(Reaction ~ Days + (Days | Subject), sleepstudy)
> > >>
> > >> Thanks for including that traceback, Andrew.  As Martin indicated, it
> > >> is difficult for us to diagnose the problem because we are unable to
> > >> reproduce it.
> > >>
> > >> I can tell you what should be happening at that point in the lmer2
> > >> function.  Perhaps you could use
> > >>
> > >> debug(lmer2)
> > >>
> > >> and check under your system what is happening for you.
> > >>
> > >> As I'm sure you can determine just be looking at this traceback, this
> > >> is the point in lmer2 where the REML or ML criterion is to be
> > >> optimized using the optimizer nlminb.  The object 'mer', of class
> > >> 'mer2', is the internal representation of a mixed-effects model.  It
> > >> is described in the Implementation vignette.
> > >>
> > >> The ST slot is a list whose number of components is equal to the
> > >> number of random effects expressions in the model formula.  In this
> > >> case it should have one component and that component should be a 2x2
> > >> matrix (it's a matrix, not a Matrix from the Matrix package).  The C
> > >> code for mer2_getPars allocates a numeric vector of the correct length
> > >> and fills it out with elements of the lower triangles of these
> > >> matrices starting with the diagonal elements of each matrix.  (The
> > >> diagonal elements are the elements of the scale matrices S and the
> > >> elements of the strict lower triangle are the non-trivial elements of
> > >> the unit triangular matrices T.)
> > >>
> > >> I enclose some of the debugger output from my system.  Once the mer
> > >> object is created I check that the 'dims' slot has the expected
> > >> entries.  In particular the element labeled 'nf' (number of grouping
> > >> factors) should be 1 and the nc slot should be an integer vector of
> > >> length 1 and the first element should be 2.
> > >>
> > >> If the 'dims', 'nc' and 'ST' slots all have the expected contents then
> > >> it would be very mysterious how mer2_getPars managed to fail.  I
> > >> suspect that the problem originates one step back in the call to
> > >> mer2_create.  In either case it may be necessary to go in and examine
> > >> the execution of the compiled code using a symbolic debugger in order
> > >> to exactly what's going on.
> > >
> > >Thanks for your detailed response, Doug.  I ran debug(lmer2) as you
> > >suggested, and as you expected, I got the same results as you did.  Of
> > >course I would like to dig further into this problem.  I have limited
> > >experience using gdb, but I have used it.  If you don't mind providing
> > >a brief set of instructions, I will carry them out.
> >
> > Well, actually, that wasn't what I was expecting.  I thought that
> > something would look wrong in those slots.
> >
> > Can you be more specific about getting the same results as I did?  In
> > particular, did you get the same response to
> >
> > .Call("mer2_getPars", mer, PACKAGE = "lme4")
> >
> > If so, I'm not quite sure how it would fail in the same call
> > immediately afterwards.
>
> I'm sorry, what I told you was wrong.  I get:
>
> Browse[1]>
> debug: mer <- .Call(mer2_create, fl, Zt, t(X), as.double(Y), method ==
>     "REML", nc, cnames, fr$offset, fr$weights)
> Browse[1]>
> debug: const <- unlist(lapply(mer at nc, function(n) rep(1:0, c(n, (n *
>     (n - 1))/2))))
> Browse[1]> mer at ST
> $Subject
>           [,1]       [,2]
> [1,] 0.5163978 0.00000000
> [2,] 0.0000000 0.09673017
>
> Browse[1]> mer at dims
>   nf    n    p    q REML glmm
>    1  180    2   36    1    0
> Browse[1]> mer at nc
> Subject
>       2
> Browse[1]> .Call("mer2_getPars", mer, PACKAGE = "lme4")
> Error: Calloc could not allocate (164788288 of 4) memory

> the last of which is clearly different than you got :)

Congratulations, you get to go in with the symbolic debugger.
Fortunately the C function mer2_getPars is very short and (relatively)
simple.  My guess is that somehow the value of ntot is not being
calculated correctly and the failure is occurring in the call to
allocVector after the first 'for' loop.  For this example the value of
ntot should be 3 at that point.  Other values of importance are nf,
which should be 1, and nc[0] (recall that indexing in C is 0-based)
which should be 2.

Can you check those things for me please?



From dbp at uiuc.edu  Wed Jan 31 00:16:52 2007
From: dbp at uiuc.edu (Dan Pemstein)
Date: Tue, 30 Jan 2007 17:16:52 -0600
Subject: [R-sig-ME] large dataset
Message-ID: <20070130231652.GG11005@aurelius.lcws.org>

Hi all,

I'm attempting to fit a crossed random effects model to a rather large
data set.  This is EU parliament voting data (the response variable is
binary) from 574 legislators over 2123 votes.  EU parliamentarians
miss a lot of votes so there are ~700,000 total observations.  The
model also includes quite a few covariates---on the order of 30-50
(mostly fixed effects for country, party, etc), depending on the
particular specification.  I'm having some serious issues fitting a
crossed effects logit model to this data with lme4 without exhausting
system memory.  I have a quad-core intel linux machine with 8 gigs of
ram and a lot of swap to play with, but I'm still falling short.
Interestingly, I've successfully fit this model using HLM6 on a
machine with substantially less RAM.

My question is largely about feasibility.  I would like to use lme4 to
analyze this dataset because it provides a much better set of features
for checking model fit and generating predictions than HLM (one can't
even get the fixed effects variance-covariance matrix out of HLM6's
crossed effects routine).  Is this impossible?  Are there any ways to
reduce lmer's memory footprint that I might try?  Would one expect a
cross-classified logit model with 700,000 observations to require
upwards of 12 gigs of memory or have I uncovered a small memory leak
that isn't visible with smaller datasets?  The memory use creeps up
slowly over the course of a run which is at least consistent with a
memory leak, but, not knowing anything about the implementation, I'm
just speculating wildly here.  Obviously, I could sub-sample, but this
is already a sample of a larger dataset, so I'm loathe to do that if I
can avoid it.

thanks,

Dan

-- 
Daniel Pemstein
Department of Political Science
University of Illinois at Urbana-Champaign
702 S. Wright St.
Urbana, IL 61801

Email: dbp at uiuc.edu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 191 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070130/10955047/attachment.bin>

From bates at stat.wisc.edu  Wed Jan 31 01:25:58 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 30 Jan 2007 18:25:58 -0600
Subject: [R-sig-ME] large dataset
In-Reply-To: <20070130231652.GG11005@aurelius.lcws.org>
References: <20070130231652.GG11005@aurelius.lcws.org>
Message-ID: <40e66e0b0701301625h197e4819vd4368077be5b2e67@mail.gmail.com>

On 1/30/07, Dan Pemstein <dbp at uiuc.edu> wrote:

> I'm attempting to fit a crossed random effects model to a rather large
> data set.  This is EU parliament voting data (the response variable is
> binary) from 574 legislators over 2123 votes.  EU parliamentarians
> miss a lot of votes so there are ~700,000 total observations.  The
> model also includes quite a few covariates---on the order of 30-50
> (mostly fixed effects for country, party, etc), depending on the
> particular specification.  I'm having some serious issues fitting a
> crossed effects logit model to this data with lme4 without exhausting
> system memory.  I have a quad-core intel linux machine with 8 gigs of
> ram and a lot of swap to play with, but I'm still falling short.
> Interestingly, I've successfully fit this model using HLM6 on a
> machine with substantially less RAM.

> My question is largely about feasibility.  I would like to use lme4 to
> analyze this dataset because it provides a much better set of features
> for checking model fit and generating predictions than HLM (one can't
> even get the fixed effects variance-covariance matrix out of HLM6's
> crossed effects routine).  Is this impossible?  Are there any ways to
> reduce lmer's memory footprint that I might try?  Would one expect a
> cross-classified logit model with 700,000 observations to require
> upwards of 12 gigs of memory or have I uncovered a small memory leak
> that isn't visible with smaller datasets?  The memory use creeps up
> slowly over the course of a run which is at least consistent with a
> memory leak, but, not knowing anything about the implementation, I'm
> just speculating wildly here.  Obviously, I could sub-sample, but this
> is already a sample of a larger dataset, so I'm loathe to do that if I
> can avoid it.

Could you try to fit the response with a linear mixed model using the
lmer2 function that is in versions 0.9975-11 and later of the lme4
package?  I know the model is inappropriate but I just want to get a
handle on whether the mer2 representation saves enough storage to make
working with such a data set and model feasible.

I shouldn't speculate without actually examining the model fit myself
but I think the memory hog may be the fixed-effects model matrix.
Currently that model matrix must be created as  a dense matrix and it
must be created using all the rows.  When you say that you have 30-50
covariates (and I assume that some of them may be factors) then that
matrix could be the one that is breaking the bank.  In lmer2 the
fixed-effects model matrix is stored as a sparse matrix (although it
is initially created as a dense matrix).  The random-effects model
matrix is created as a sparse matrix and it usually isn't the problem
with memory usage.

If you do succeed in fitting a linear mixed model to these data using
lmer2 I would be interested in the sizes of some of the slots in the
fitted model.  I enclose a short transcript showing one way of
checking these sizes on an S4 object.

Regarding the possibility of a memory leak - I wouldn't be shocked if
I had managed to create a memory leak but the behavior that you
mention is consistent with the garbage collection.  At present the
optimization of the deviance for generalized linear mixed models goes
through the nlminb function in R which means that the deviance
evaluation must be an R function.  Thus there are R objects created
within the optimization that must be garbage collected.  I think I
know a way around this and it is on my "To Do" list to check it out
but that list is pretty long these days so I can't promise anything.

Thanks for writing to the list.  I'll be interested in whether it is
possible to work with such large data sets effectively.
-------------- next part --------------
> fm <- lmer2(math~sx*eth+gr+cltype+(yrs|id)+(1|tch)+(yrs|sch), star)
> nms <- slotNames(fm)
> names(nms) <- nms
> object.size(fm)
[1] 16820760
> sort(sapply(nms, function(nm) object.size(slot(fm, nm))))
      Gp    fixef       nc deviance     dims       ST   cnames     call 
      72      176      384      528      560     1072     1928     3744 
   terms    ranef  weights   offset    flist    frame     ZXyt        A 
    6168   184024   196664   196664   978952  3191264  3547072  3594864 
       L 
 4914248 

From bates at stat.wisc.edu  Wed Jan 31 01:38:09 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 30 Jan 2007 18:38:09 -0600
Subject: [R-sig-ME] large dataset
In-Reply-To: <40e66e0b0701301625h197e4819vd4368077be5b2e67@mail.gmail.com>
References: <20070130231652.GG11005@aurelius.lcws.org>
	<40e66e0b0701301625h197e4819vd4368077be5b2e67@mail.gmail.com>
Message-ID: <40e66e0b0701301638l3c031533lfcb901678cb0f120@mail.gmail.com>

I should have mentioned this in my earlier reply - please use version
0.9975-12 of lme4 when checking with lmer2.  I just uploaded this
version to CRAN and it should appear on the main site and the mirrors
in a day or two.  You can get it now from the SVN archive

https://svn.r-project.org/R-packages/trunk/lme4

In an earlier thread on this list Andrew Robinson described how he was
unable to run even the simplest examples of lmer2 on a FreeBSD system.
 With his help we finally tracked down the dumb error that I had made
in the C function mer2_getPars and fixed it for the -12 release.
Under Linux the bug was not causing a memory error but it certainly
would use up much more memory than necessary during the iterations.


On 1/30/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 1/30/07, Dan Pemstein <dbp at uiuc.edu> wrote:
>
> > I'm attempting to fit a crossed random effects model to a rather large
> > data set.  This is EU parliament voting data (the response variable is
> > binary) from 574 legislators over 2123 votes.  EU parliamentarians
> > miss a lot of votes so there are ~700,000 total observations.  The
> > model also includes quite a few covariates---on the order of 30-50
> > (mostly fixed effects for country, party, etc), depending on the
> > particular specification.  I'm having some serious issues fitting a
> > crossed effects logit model to this data with lme4 without exhausting
> > system memory.  I have a quad-core intel linux machine with 8 gigs of
> > ram and a lot of swap to play with, but I'm still falling short.
> > Interestingly, I've successfully fit this model using HLM6 on a
> > machine with substantially less RAM.
>
> > My question is largely about feasibility.  I would like to use lme4 to
> > analyze this dataset because it provides a much better set of features
> > for checking model fit and generating predictions than HLM (one can't
> > even get the fixed effects variance-covariance matrix out of HLM6's
> > crossed effects routine).  Is this impossible?  Are there any ways to
> > reduce lmer's memory footprint that I might try?  Would one expect a
> > cross-classified logit model with 700,000 observations to require
> > upwards of 12 gigs of memory or have I uncovered a small memory leak
> > that isn't visible with smaller datasets?  The memory use creeps up
> > slowly over the course of a run which is at least consistent with a
> > memory leak, but, not knowing anything about the implementation, I'm
> > just speculating wildly here.  Obviously, I could sub-sample, but this
> > is already a sample of a larger dataset, so I'm loathe to do that if I
> > can avoid it.
>
> Could you try to fit the response with a linear mixed model using the
> lmer2 function that is in versions 0.9975-11 and later of the lme4
> package?  I know the model is inappropriate but I just want to get a
> handle on whether the mer2 representation saves enough storage to make
> working with such a data set and model feasible.
>
> I shouldn't speculate without actually examining the model fit myself
> but I think the memory hog may be the fixed-effects model matrix.
> Currently that model matrix must be created as  a dense matrix and it
> must be created using all the rows.  When you say that you have 30-50
> covariates (and I assume that some of them may be factors) then that
> matrix could be the one that is breaking the bank.  In lmer2 the
> fixed-effects model matrix is stored as a sparse matrix (although it
> is initially created as a dense matrix).  The random-effects model
> matrix is created as a sparse matrix and it usually isn't the problem
> with memory usage.
>
> If you do succeed in fitting a linear mixed model to these data using
> lmer2 I would be interested in the sizes of some of the slots in the
> fitted model.  I enclose a short transcript showing one way of
> checking these sizes on an S4 object.
>
> Regarding the possibility of a memory leak - I wouldn't be shocked if
> I had managed to create a memory leak but the behavior that you
> mention is consistent with the garbage collection.  At present the
> optimization of the deviance for generalized linear mixed models goes
> through the nlminb function in R which means that the deviance
> evaluation must be an R function.  Thus there are R objects created
> within the optimization that must be garbage collected.  I think I
> know a way around this and it is on my "To Do" list to check it out
> but that list is pretty long these days so I can't promise anything.
>
> Thanks for writing to the list.  I'll be interested in whether it is
> possible to work with such large data sets effectively.
>
>
>



From dbp at uiuc.edu  Wed Jan 31 22:03:01 2007
From: dbp at uiuc.edu (Dan Pemstein)
Date: Wed, 31 Jan 2007 15:03:01 -0600
Subject: [R-sig-ME] large dataset
In-Reply-To: <40e66e0b0701301638l3c031533lfcb901678cb0f120@mail.gmail.com>
References: <20070130231652.GG11005@aurelius.lcws.org>
	<40e66e0b0701301625h197e4819vd4368077be5b2e67@mail.gmail.com>
	<40e66e0b0701301638l3c031533lfcb901678cb0f120@mail.gmail.com>
Message-ID: <20070131210301.GK11005@aurelius.lcws.org>

Thanks for replying so quickly.

It may take me a couple of days to get the new version of lme4
installed and to run the tests you're interested in.  In the
mean-time, I ran (using lmer in 0.9975-11):

A fixed intercept + crossed random intercepts only model 
  - Ran out of memory + swap.
A votes intercept only model with all the covariates
  - Completed.  Topped out at around 6 gigs of memory and this topping
    out occurred at the end of the run, after verbose iteration output
    had completed.  I'm not sure if my earlier full model runs crashed
    at this point as well, but it is a distinct possibility.  

Both these runs were fit using PQL.  One of my full runs used laplace
and ran out of memory after 20-odd iterations and 12+ hours of
processor time.

Here are the sizes for the single random intercept model:

> nms<-slotNames(mod1)
> object.size(mod1)
[1] 748925256
> sort(sapply(nms, function(nm) object.size(slot(mod1, nm))))
       Gp        nc  deviance    status  gradComp   devComp       Xty       rXy
       48       256       320       384       496       728       960       960
    fixef     Omega      call    cnames       Zty       rZy     ranef     terms
      960      3552      6528      7776     17032     17032     17032     17096
     bVar    family       ZtZ         L       XtX       RXX       ZtX       RZX
    17456     31448     35616     69880    121824    121880   1962544   1962544
   RZXinv     flist         y       wts    wrkres        Zt   weights     frame
  1962544   2602096   4965032   4965032   4965032   9931408  39720128  69657216
        X
605738248

I'll post the results of an lmer2 run to the list once I have a
chance.

On Tue, Jan 30, 2007 at 06:38:09PM -0600, Douglas Bates wrote:
> I should have mentioned this in my earlier reply - please use version
> 0.9975-12 of lme4 when checking with lmer2.  I just uploaded this
> version to CRAN and it should appear on the main site and the mirrors
> in a day or two.  You can get it now from the SVN archive
> 
> https://svn.r-project.org/R-packages/trunk/lme4
> 
> In an earlier thread on this list Andrew Robinson described how he was
> unable to run even the simplest examples of lmer2 on a FreeBSD system.
> With his help we finally tracked down the dumb error that I had made
> in the C function mer2_getPars and fixed it for the -12 release.
> Under Linux the bug was not causing a memory error but it certainly
> would use up much more memory than necessary during the iterations.
> 
> 
> On 1/30/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> >On 1/30/07, Dan Pemstein <dbp at uiuc.edu> wrote:
> >
> >> I'm attempting to fit a crossed random effects model to a rather large
> >> data set.  This is EU parliament voting data (the response variable is
> >> binary) from 574 legislators over 2123 votes.  EU parliamentarians
> >> miss a lot of votes so there are ~700,000 total observations.  The
> >> model also includes quite a few covariates---on the order of 30-50
> >> (mostly fixed effects for country, party, etc), depending on the
> >> particular specification.  I'm having some serious issues fitting a
> >> crossed effects logit model to this data with lme4 without exhausting
> >> system memory.  I have a quad-core intel linux machine with 8 gigs of
> >> ram and a lot of swap to play with, but I'm still falling short.
> >> Interestingly, I've successfully fit this model using HLM6 on a
> >> machine with substantially less RAM.
> >
> >> My question is largely about feasibility.  I would like to use lme4 to
> >> analyze this dataset because it provides a much better set of features
> >> for checking model fit and generating predictions than HLM (one can't
> >> even get the fixed effects variance-covariance matrix out of HLM6's
> >> crossed effects routine).  Is this impossible?  Are there any ways to
> >> reduce lmer's memory footprint that I might try?  Would one expect a
> >> cross-classified logit model with 700,000 observations to require
> >> upwards of 12 gigs of memory or have I uncovered a small memory leak
> >> that isn't visible with smaller datasets?  The memory use creeps up
> >> slowly over the course of a run which is at least consistent with a
> >> memory leak, but, not knowing anything about the implementation, I'm
> >> just speculating wildly here.  Obviously, I could sub-sample, but this
> >> is already a sample of a larger dataset, so I'm loathe to do that if I
> >> can avoid it.
> >
> >Could you try to fit the response with a linear mixed model using the
> >lmer2 function that is in versions 0.9975-11 and later of the lme4
> >package?  I know the model is inappropriate but I just want to get a
> >handle on whether the mer2 representation saves enough storage to make
> >working with such a data set and model feasible.
> >
> >I shouldn't speculate without actually examining the model fit myself
> >but I think the memory hog may be the fixed-effects model matrix.
> >Currently that model matrix must be created as  a dense matrix and it
> >must be created using all the rows.  When you say that you have 30-50
> >covariates (and I assume that some of them may be factors) then that
> >matrix could be the one that is breaking the bank.  In lmer2 the
> >fixed-effects model matrix is stored as a sparse matrix (although it
> >is initially created as a dense matrix).  The random-effects model
> >matrix is created as a sparse matrix and it usually isn't the problem
> >with memory usage.
> >
> >If you do succeed in fitting a linear mixed model to these data using
> >lmer2 I would be interested in the sizes of some of the slots in the
> >fitted model.  I enclose a short transcript showing one way of
> >checking these sizes on an S4 object.
> >
> >Regarding the possibility of a memory leak - I wouldn't be shocked if
> >I had managed to create a memory leak but the behavior that you
> >mention is consistent with the garbage collection.  At present the
> >optimization of the deviance for generalized linear mixed models goes
> >through the nlminb function in R which means that the deviance
> >evaluation must be an R function.  Thus there are R objects created
> >within the optimization that must be garbage collected.  I think I
> >know a way around this and it is on my "To Do" list to check it out
> >but that list is pretty long these days so I can't promise anything.
> >
> >Thanks for writing to the list.  I'll be interested in whether it is
> >possible to work with such large data sets effectively.
> >
> >
> >
> 

-- 
Daniel Pemstein
Department of Political Science
University of Illinois at Urbana-Champaign
702 S. Wright St.
Urbana, IL 61801

Email: dbp at uiuc.edu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 191 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070131/2b972e1a/attachment.bin>

From bates at stat.wisc.edu  Wed Jan 31 23:02:59 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 31 Jan 2007 16:02:59 -0600
Subject: [R-sig-ME] large dataset
In-Reply-To: <20070131210301.GK11005@aurelius.lcws.org>
References: <20070130231652.GG11005@aurelius.lcws.org>
	<40e66e0b0701301625h197e4819vd4368077be5b2e67@mail.gmail.com>
	<40e66e0b0701301638l3c031533lfcb901678cb0f120@mail.gmail.com>
	<20070131210301.GK11005@aurelius.lcws.org>
Message-ID: <40e66e0b0701311402y351b2412nfa0a29adf76e18ee@mail.gmail.com>

On 1/31/07, Dan Pemstein <dbp at uiuc.edu> wrote:
> Thanks for replying so quickly.
>
> It may take me a couple of days to get the new version of lme4
> installed and to run the tests you're interested in.  In the
> mean-time, I ran (using lmer in 0.9975-11):
>
> A fixed intercept + crossed random intercepts only model
>   - Ran out of memory + swap.
> A votes intercept only model with all the covariates
>   - Completed.  Topped out at around 6 gigs of memory and this topping
>     out occurred at the end of the run, after verbose iteration output
>     had completed.  I'm not sure if my earlier full model runs crashed
>     at this point as well, but it is a distinct possibility.
>
> Both these runs were fit using PQL.  One of my full runs used laplace
> and ran out of memory after 20-odd iterations and 12+ hours of
> processor time.
>
> Here are the sizes for the single random intercept model:
>
> > nms<-slotNames(mod1)
> > object.size(mod1)
> [1] 748925256
> > sort(sapply(nms, function(nm) object.size(slot(mod1, nm))))
>        Gp        nc  deviance    status  gradComp   devComp       Xty       rXy
>        48       256       320       384       496       728       960       960
>     fixef     Omega      call    cnames       Zty       rZy     ranef     terms
>       960      3552      6528      7776     17032     17032     17032     17096
>      bVar    family       ZtZ         L       XtX       RXX       ZtX       RZX
>     17456     31448     35616     69880    121824    121880   1962544   1962544
>    RZXinv     flist         y       wts    wrkres        Zt   weights     frame
>   1962544   2602096   4965032   4965032   4965032   9931408  39720128  69657216
>         X
> 605738248
>
> I'll post the results of an lmer2 run to the list once I have a
> chance.

Thanks.  That result by itself can tell us where the problem lies.
Notice that the size of the X slot is about 600MB out of the total of
about 750 MB.  By comparison, the other slots like XtX, ZtZ and ZtX
are much smaller.

If you still have that model fit available could you check

library(Matrix)
object.size(as(mod1$X, "sparseMatrix"))

The good news from this example is that it gives us hope for fitting
mixed models to large data sets.  The bad news is that doing so will
require a considerable amount of development.

> On Tue, Jan 30, 2007 at 06:38:09PM -0600, Douglas Bates wrote:
> > I should have mentioned this in my earlier reply - please use version
> > 0.9975-12 of lme4 when checking with lmer2.  I just uploaded this
> > version to CRAN and it should appear on the main site and the mirrors
> > in a day or two.  You can get it now from the SVN archive
> >
> > https://svn.r-project.org/R-packages/trunk/lme4
> >
> > In an earlier thread on this list Andrew Robinson described how he was
> > unable to run even the simplest examples of lmer2 on a FreeBSD system.
> > With his help we finally tracked down the dumb error that I had made
> > in the C function mer2_getPars and fixed it for the -12 release.
> > Under Linux the bug was not causing a memory error but it certainly
> > would use up much more memory than necessary during the iterations.
> >
> >
> > On 1/30/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> > >On 1/30/07, Dan Pemstein <dbp at uiuc.edu> wrote:
> > >
> > >> I'm attempting to fit a crossed random effects model to a rather large
> > >> data set.  This is EU parliament voting data (the response variable is
> > >> binary) from 574 legislators over 2123 votes.  EU parliamentarians
> > >> miss a lot of votes so there are ~700,000 total observations.  The
> > >> model also includes quite a few covariates---on the order of 30-50
> > >> (mostly fixed effects for country, party, etc), depending on the
> > >> particular specification.  I'm having some serious issues fitting a
> > >> crossed effects logit model to this data with lme4 without exhausting
> > >> system memory.  I have a quad-core intel linux machine with 8 gigs of
> > >> ram and a lot of swap to play with, but I'm still falling short.
> > >> Interestingly, I've successfully fit this model using HLM6 on a
> > >> machine with substantially less RAM.
> > >
> > >> My question is largely about feasibility.  I would like to use lme4 to
> > >> analyze this dataset because it provides a much better set of features
> > >> for checking model fit and generating predictions than HLM (one can't
> > >> even get the fixed effects variance-covariance matrix out of HLM6's
> > >> crossed effects routine).  Is this impossible?  Are there any ways to
> > >> reduce lmer's memory footprint that I might try?  Would one expect a
> > >> cross-classified logit model with 700,000 observations to require
> > >> upwards of 12 gigs of memory or have I uncovered a small memory leak
> > >> that isn't visible with smaller datasets?  The memory use creeps up
> > >> slowly over the course of a run which is at least consistent with a
> > >> memory leak, but, not knowing anything about the implementation, I'm
> > >> just speculating wildly here.  Obviously, I could sub-sample, but this
> > >> is already a sample of a larger dataset, so I'm loathe to do that if I
> > >> can avoid it.
> > >
> > >Could you try to fit the response with a linear mixed model using the
> > >lmer2 function that is in versions 0.9975-11 and later of the lme4
> > >package?  I know the model is inappropriate but I just want to get a
> > >handle on whether the mer2 representation saves enough storage to make
> > >working with such a data set and model feasible.
> > >
> > >I shouldn't speculate without actually examining the model fit myself
> > >but I think the memory hog may be the fixed-effects model matrix.
> > >Currently that model matrix must be created as  a dense matrix and it
> > >must be created using all the rows.  When you say that you have 30-50
> > >covariates (and I assume that some of them may be factors) then that
> > >matrix could be the one that is breaking the bank.  In lmer2 the
> > >fixed-effects model matrix is stored as a sparse matrix (although it
> > >is initially created as a dense matrix).  The random-effects model
> > >matrix is created as a sparse matrix and it usually isn't the problem
> > >with memory usage.
> > >
> > >If you do succeed in fitting a linear mixed model to these data using
> > >lmer2 I would be interested in the sizes of some of the slots in the
> > >fitted model.  I enclose a short transcript showing one way of
> > >checking these sizes on an S4 object.
> > >
> > >Regarding the possibility of a memory leak - I wouldn't be shocked if
> > >I had managed to create a memory leak but the behavior that you
> > >mention is consistent with the garbage collection.  At present the
> > >optimization of the deviance for generalized linear mixed models goes
> > >through the nlminb function in R which means that the deviance
> > >evaluation must be an R function.  Thus there are R objects created
> > >within the optimization that must be garbage collected.  I think I
> > >know a way around this and it is on my "To Do" list to check it out
> > >but that list is pretty long these days so I can't promise anything.
> > >
> > >Thanks for writing to the list.  I'll be interested in whether it is
> > >possible to work with such large data sets effectively.
> > >
> > >
> > >
> >
>
> --
> Daniel Pemstein
> Department of Political Science
> University of Illinois at Urbana-Champaign
> 702 S. Wright St.
> Urbana, IL 61801
>
> Email: dbp at uiuc.edu
>
>
>



From kw.statr at gmail.com  Thu Feb  1 16:24:42 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Thu, 1 Feb 2007 09:24:42 -0600
Subject: [R-sig-ME] Timings with SAMM, lme4, nlme
Message-ID: <c968588d0702010724k25c079fdo5eb8baa6770f3ecf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070201/ab7c7e40/attachment.pl>

From HDoran at air.org  Thu Feb  1 17:24:54 2007
From: HDoran at air.org (Doran, Harold)
Date: Thu, 1 Feb 2007 11:24:54 -0500
Subject: [R-sig-ME] Timings with SAMM, lme4, nlme
Message-ID: <2323A6D37908A847A7C32F1E3662C80E8D4798@dc1ex01.air.org>

Try adding this portion of code to your lmer model

control=list(gradient = FALSE, niterEM = 0)

This will change what you have below from 

lmer(math~ gr + sx + eth + cltype + (1+yrs|id) + (1+yrs|sch), data=star)

To

lmer(math~ gr + sx + eth + cltype + (1+yrs|id) + (1+yrs|sch), data=star,
control=list(gradient = FALSE, niterEM = 0))

BTW, you don't need (1+yrs) you can reduce this to just (yrs|id).

This should make a huge difference.

Harold


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Kevin Wright
> Sent: Thursday, February 01, 2007 10:25 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Timings with SAMM, lme4, nlme
> 
> About a year and a half ago I did some comparison of model 
> fitting with SAMM, lme4, and nlme.  Since Doug Bates put out 
> a request for some recent timings, I am repeating/extending 
> my comparisons.  In the interim, I have switched computers, 
> so the timings of the samm function facilitate comparing the 
> speed across the two computers.
> 
> First, the results (view with fixed-width font)
> 
>            Setup   T30   D620    T30   D620     D620    D620
> Model \ Function  samm   samm   lmer   lmer    lmer2     lme
> ----------------  ----   ----   ----   ----    -----   -----
> yrs|id + yrs|sch     f      f   30.0   kill     65
> yrs|id +   1|sch  10.5    7.8   13.7   kill     23
>   1|id + yrs|sch   9.4    9.5   11.5   kill      7.3
>   1|id +   1|sch   6.5    5.7    5.6   kill      5.4      60
>          yrs|sch   4.8    4.0      f   kill      0.5
>            1|sch   3.4    2.2    0.4    0.7      0.3       4
> yrs|id             5.7    5.7    8.2   kill     15       150
>   1|id             4.1    3.4    2.4   kill      4.2      14
> 
> In the table above, "Setup" refers to the following two computer
> configurations:
> 
> T30:  IBM Thinkpad T30, 1 GB ram, 1.8 Ghz processor, Windows 2000
>       SAMM version 1.1, lme4 & nlme current on 5.24.2005
> 
> D620: Dell Latitude D620, 2 GB ram, 1.8 Ghz duo core processor, WinXP
>       SAMM version 1.1 lme4 & nlme current as of 1.30.2007
> 
> I timed most model fits only once.  I did a quick inspection 
> of the results from the different modelling functions to 
> persuade myself that I was fitting the same model (i.e. that 
> estimates were similar).
> 
> Here are the full models I used:
> 
> lmer(math~ gr + sx + eth + cltype + (1+yrs|id) + (1+yrs|sch), 
> data=star)
> 
> samm(math ~ gr + sx + eth + cltype, random=~ us(link(~1+yrs)):id +
>      us(link(~1+yrs)):sch, data=star, na.method.X="omit")
> 
> Starting with these full models, I tried reduced models with 
> simpler random effects structures.  These are the different 
> rows in the table above.
> 
> Observations:
> (1) The performance of the common version of SAMM on the two 
> computers suggests the Dell is slightly faster than the IBM.
> 
> (2) On 24 May 2005, lmer and samm has roughly similar 
> timings.  On 31 Jan 2007, lmer is nearly unusable for this 
> data (I killed the job after 5-10 minutes of waiting).
> 
> (3) The current version of lmer2 is the only function that 
> appears to fit all models.
> 
> (4) The current version of lme is slower than sammm/lmer2 for
>     those models I tried to fit.
> 
> FYI.  SAMM is officially available at
> http://www.vsni.co.uk/products/samm/(but seems not to be 
> there now, perhaps in preparation for release of a new 
> version). Unofficially it is available here: ftp://ftp.dpi.nsw.gov.au/
> 
> I hope this information is useful.  Thanks for the progress 
> evident in the
> lme4 package.
> 
> Kevin Wright
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kw.statr at gmail.com  Thu Feb  1 19:36:20 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Thu, 1 Feb 2007 12:36:20 -0600
Subject: [R-sig-ME] Timings with SAMM, lme4, nlme
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E8D4798@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E8D4798@dc1ex01.air.org>
Message-ID: <c968588d0702011036m151539ceu4809eedcf621650@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070201/1f1f85f5/attachment.pl>

From c.beale at macaulay.ac.uk  Thu Feb  1 18:10:44 2007
From: c.beale at macaulay.ac.uk (Colin Beale)
Date: Thu, 01 Feb 2007 17:10:44 +0000
Subject: [R-sig-ME] extracting coefficients from lmer2 model
Message-ID: <45C21F14.1E3C.0035.0@macaulay.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070201/20b41eec/attachment.pl>

From ian.dworkin at gmail.com  Thu Feb  1 23:59:54 2007
From: ian.dworkin at gmail.com (Ian Dworkin)
Date: Thu, 1 Feb 2007 17:59:54 -0500
Subject: [R-sig-ME] Is there any chance of development of multivariate
	linear mixed models for lme4
Message-ID: <14a74d330702011459p1562e195h49f843d75c6ff27d@mail.gmail.com>

Hi,

  From what I gather this is a list primarily dedicated to the
development of mixed model libraries for R. So I apologize if this is
not the appropriate place for this.

  I am in the process of making the transition from SAS to R. One of
the major procedures I use(d) in SAS was PROC MIXED, and I am slowly
getting familiar with lmer.

 I was wondering if there is any discussion of working on the
development of multivariate mixed models? Most of the data I am
interested with is multivariate in nature, and univariate methods tend
to be less useful. Not that PROC MIXED does this very effectively, but
you can trick MIXED to do some multivariate models using the repeated
statement and specifying an unstructured covariance matrix etc..
However the code is ugly and not very intuitive.

  Anyways, I am asking in the vain hope that something is being
developed in lme4 for multivariate models.

Thanks

Ian



From A.Robinson at ms.unimelb.edu.au  Fri Feb  2 00:31:28 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 2 Feb 2007 10:31:28 +1100
Subject: [R-sig-ME] Is there any chance of development of
	multivariate	linear mixed models for lme4
In-Reply-To: <14a74d330702011459p1562e195h49f843d75c6ff27d@mail.gmail.com>
References: <14a74d330702011459p1562e195h49f843d75c6ff27d@mail.gmail.com>
Message-ID: <20070201233128.GV34088@ms.unimelb.edu.au>

Hi Ian,

I've been able to trick lme() into fitting multivariate mixed-effects
models, and I don't think that I relied on any functionality that is
not available within lmer at the present.  I can send you what I did
if you're interested.  I wrote it up in:

Robinson, A.P., 2004. Preserving correlation while modelling diameter
  distributions. Canadian Journal of Forest Research 34, 221--232.

Mind you, the code was ugly and not terribly intuitive!

Cheers

Andrew

On Thu, Feb 01, 2007 at 05:59:54PM -0500, Ian Dworkin wrote:
> Hi,
> 
>   From what I gather this is a list primarily dedicated to the
> development of mixed model libraries for R. So I apologize if this is
> not the appropriate place for this.
> 
>   I am in the process of making the transition from SAS to R. One of
> the major procedures I use(d) in SAS was PROC MIXED, and I am slowly
> getting familiar with lmer.
> 
>  I was wondering if there is any discussion of working on the
> development of multivariate mixed models? Most of the data I am
> interested with is multivariate in nature, and univariate methods tend
> to be less useful. Not that PROC MIXED does this very effectively, but
> you can trick MIXED to do some multivariate models using the repeated
> statement and specifying an unstructured covariance matrix etc..
> However the code is ugly and not very intuitive.
> 
>   Anyways, I am asking in the vain hope that something is being
> developed in lme4 for multivariate models.
> 
> Thanks
> 
> Ian
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From HDoran at air.org  Fri Feb  2 13:47:52 2007
From: HDoran at air.org (Doran, Harold)
Date: Fri, 2 Feb 2007 07:47:52 -0500
Subject: [R-sig-ME] Is there any chance of development
	ofmultivariate	linear mixed models for lme4
Message-ID: <2323A6D37908A847A7C32F1E3662C80E8D47DB@dc1ex01.air.org>

I'm interested in seeing this as well. I too have a paper showing how to
estimate multivariate mixed models. But, I think it is necessary to
construct a patterned covariance matrix for the residual error and this
is not available in lmer.

@article{dora:lock:2006,
year			={2006},
author		={Harold C. Doran and J.R. Lockwood},
title			={Fitting value-added models in {R}},
volume		={31}.
number		={2},
journal		={Journal of Educational and Behavioral Statistics}
} 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Andrew Robinson
> Sent: Thursday, February 01, 2007 6:31 PM
> To: Ian Dworkin
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Is there any chance of development 
> ofmultivariate linear mixed models for lme4
> 
> Hi Ian,
> 
> I've been able to trick lme() into fitting multivariate 
> mixed-effects models, and I don't think that I relied on any 
> functionality that is not available within lmer at the 
> present.  I can send you what I did if you're interested.  I 
> wrote it up in:
> 
> Robinson, A.P., 2004. Preserving correlation while modelling diameter
>   distributions. Canadian Journal of Forest Research 34, 221--232.
> 
> Mind you, the code was ugly and not terribly intuitive!
> 
> Cheers
> 
> Andrew
> 
> On Thu, Feb 01, 2007 at 05:59:54PM -0500, Ian Dworkin wrote:
> > Hi,
> > 
> >   From what I gather this is a list primarily dedicated to the 
> > development of mixed model libraries for R. So I apologize 
> if this is 
> > not the appropriate place for this.
> > 
> >   I am in the process of making the transition from SAS to 
> R. One of 
> > the major procedures I use(d) in SAS was PROC MIXED, and I 
> am slowly 
> > getting familiar with lmer.
> > 
> >  I was wondering if there is any discussion of working on the 
> > development of multivariate mixed models? Most of the data I am 
> > interested with is multivariate in nature, and univariate 
> methods tend 
> > to be less useful. Not that PROC MIXED does this very 
> effectively, but 
> > you can trick MIXED to do some multivariate models using 
> the repeated 
> > statement and specifying an unstructured covariance matrix etc..
> > However the code is ugly and not very intuitive.
> > 
> >   Anyways, I am asking in the vain hope that something is being 
> > developed in lme4 for multivariate models.
> > 
> > Thanks
> > 
> > Ian
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> Andrew Robinson  
> Department of Mathematics and Statistics            Tel: 
> +61-3-8344-9763
> University of Melbourne, VIC 3010 Australia         Fax: 
> +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From upsattar at yahoo.com  Fri Feb  2 07:21:37 2007
From: upsattar at yahoo.com (Abdus Sattar)
Date: Thu, 1 Feb 2007 22:21:37 -0800 (PST)
Subject: [R-sig-ME] Fitting Weighted Estimating Equations (WEE)
Message-ID: <848196.79154.qm@web58106.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070201/78e2ba9c/attachment.pl>

From bates at stat.wisc.edu  Fri Feb  2 14:44:09 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 Feb 2007 07:44:09 -0600
Subject: [R-sig-ME] Fwd:  extracting coefficients from lmer2 model
In-Reply-To: <40e66e0b0702011144k1a5661ebo26921af59753458f@mail.gmail.com>
References: <45C21F14.1E3C.0035.0@macaulay.ac.uk>
	<40e66e0b0702011144k1a5661ebo26921af59753458f@mail.gmail.com>
Message-ID: <40e66e0b0702020544g84e666dmfb691a5005235106@mail.gmail.com>

I meant to cc: the list on this reply

---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Feb 1, 2007 1:44 PM
Subject: Re: [R-sig-ME] extracting coefficients from lmer2 model
To: Colin Beale <c.beale at macaulay.ac.uk>


On 2/1/07, Colin Beale <c.beale at macaulay.ac.uk> wrote:
> Hi all,
>
> Some of you may have seen my recent message to the r-help list
> concerning a modification to lmer code that caused R to crash. Happily,
> the same modifications to the lmer2 code do not cause this crash so as
> far as I am concerned this is a major improvement to the original. Now,
> however, I'm not sure how to get at the bits of the fitted object that I
> want to play with to post-process the results as the methods aren't yet
> implemented for this structure - I need, for example, the coefficients
> of the fixed and random effects and the full variance-covariance matrix
> of fixed _and_ random effects (together!). I'm sure there must be ways
> around this issue, since I can see that there are slots with names that
> look very suitable at least to hold the fixed and random effects - but I
> can't work out how to get them. And I'm not sure if the full
> variance-covariance matrix is going to be in there anyway (looks like it
> might be for lmer objects).

I recommend the vignette in the lme4 package that describes the lmer2
representation.

In answer to some of your specific questions:

fixef is straightforward for the mer2 representation

The ranef slot is currently populated when you call for fixef but the
values in that slot are the random effects with the "spherical" prior
density (independent, constant-variance).  These are named b* in the
vignette.   I need to add code to undo the permutation and to undo the
orthogonalization transformation defined by S and T.  It is not
incredibly difficult but I will need some quiet time to consider
exactly what sequence of operations needs to be performed and then to
write and debug the code.

The variance-covariance matrix for the random effects and the fixed
effects can be derived from the inverse of L but do you really want to
create that object?  It has the potential of being very large and very
slow to calculate.  Earlier today there was discussion of the need to
set control = list(niterEM = 0, gradient = FALSE) in a call to lmer
that fits a complicated model to a large data set.  This reason that
the ECME iterations and the gradient calculations are so slow (on the
order of hundreds or thousands of evaluations of the deviance) is
because those calculations require part of the inverse of L.  It's
even simpler than that, all you need to do is to calculate some groups
of columns in the inverse and store some values derived from them.
You don't ever need to store the inverse itself - just these values
that are derived from groups of columns in the inverse.

Calculating the inverse of L won't be a problem for simple models and
small data sets but it will be a problem for multiple, non-nested
grouping factors with many levels.  Furthermore the sparse matrix
methods take care to minimize the amount of storage in L.  That's what
the fill-reducing permutation is designed to do.  However, the inverse
of L can be a mess.

You should consider carefully exactly what you need from that
variance-covariance matrix.  For example, if you are going to evaluate
a quadratic form using this matrix then don't calculate the matrix.
Write the quadratic form using the factorization and solve the system
involving L or L-transpose then collect an inner product.

> For example:
>
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fm2 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy)
>
> using:
>
>  slotNames(fm1)
>  slotNames(fm2)
>
> shows me that there are slots with the ranef and fixef in both classes
> of object - I can use fixef() on both objects to get the fixed effects,
> but ranef() only works on fm1 at the moment - how else can I get these
> objects directly? And there are obviously many more slots in the fm1
> object than the fm2 object - can anyone point out if any of these slots
> are the full variance-covariance matrix I need, containing both fixed
> and random effects and if so, how I can get at it (or if not, how I
> might go about creating it?).
>
> Thanks in advance,
>
> Colin
>
>
> Dr. Colin Beale
> Spatial Ecologist
> The Macaulay Institute
> Craigiebuckler
> Aberdeen
> AB15 8QH
> UK
>
> Tel: 01224 498245 ext. 2427
> Fax: 01224 311556
> Email: c.beale at macaulay.ac.uk
>
>
> --
> Please note that the views expressed in this e-mail are those of the
> sender and do not necessarily represent the views of the Macaulay
> Institute. This email and any attachments are confidential and are
> intended solely for the use of the recipient(s) to whom they are
> addressed. If you are not the intended recipient, you should not read,
> copy, disclose or rely on any information contained in this e-mail, and
> we would ask you to contact the sender immediately and delete the email
> from your system. Thank you.
> Macaulay Institute and Associated Companies, Macaulay Drive,
> Craigiebuckler, Aberdeen, AB15 8QH.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Fri Feb  2 14:45:28 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 Feb 2007 07:45:28 -0600
Subject: [R-sig-ME] Fwd:  Timings with SAMM, lme4, nlme
In-Reply-To: <40e66e0b0702011039p42add396t5d04c1a3efe73b8c@mail.gmail.com>
References: <c968588d0702010724k25c079fdo5eb8baa6770f3ecf@mail.gmail.com>
	<40e66e0b0702011039p42add396t5d04c1a3efe73b8c@mail.gmail.com>
Message-ID: <40e66e0b0702020545k70f87c12j3aba64866645034c@mail.gmail.com>

I also meant to cc: the list on this response.  Obviously I need to
work on my email skills.

---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Feb 1, 2007 12:39 PM
Subject: Re: [R-sig-ME] Timings with SAMM, lme4, nlme
To: Kevin Wright <kw.statr at gmail.com>


On 2/1/07, Kevin Wright <kw.statr at gmail.com> wrote:
> About a year and a half ago I did some comparison of model fitting with
> SAMM, lme4, and nlme.  Since Doug Bates put out a request for some recent
> timings, I am repeating/extending my comparisons.  In the interim, I have
> switched computers, so the timings of the samm function facilitate comparing
> the speed across the two computers.
>
> First, the results (view with fixed-width font)
>
>            Setup   T30   D620    T30   D620     D620    D620
> Model \ Function  samm   samm   lmer   lmer    lmer2     lme
> ----------------  ----   ----   ----   ----    -----   -----
> yrs|id + yrs|sch     f      f   30.0   kill     65
> yrs|id +   1|sch  10.5    7.8   13.7   kill     23
>   1|id + yrs|sch   9.4    9.5   11.5   kill      7.3
>   1|id +   1|sch   6.5    5.7    5.6   kill      5.4      60
>          yrs|sch   4.8    4.0      f   kill      0.5
>            1|sch   3.4    2.2    0.4    0.7      0.3       4
> yrs|id             5.7    5.7    8.2   kill     15       150
>   1|id             4.1    3.4    2.4   kill      4.2      14
>
> In the table above, "Setup" refers to the following two computer
> configurations:
>
> T30:  IBM Thinkpad T30, 1 GB ram, 1.8 Ghz processor, Windows 2000
>       SAMM version 1.1, lme4 & nlme current on 5.24.2005
>
> D620: Dell Latitude D620, 2 GB ram, 1.8 Ghz duo core processor, WinXP
>       SAMM version 1.1 lme4 & nlme current as of 1.30.2007
>
> I timed most model fits only once.  I did a quick inspection of the results
> from the different modelling functions to persuade myself that I was fitting
> the same model (i.e. that estimates were similar).

Thanks for sending the timings, Kevin.  As Harold Doran mentioned in
his reply to you, it is best to use the control options niterEM = 0
and gradient = FALSE when fitting lmer models to large data sets. The
theory of how to calculate the gradient and how to create the ECME
step for a linear mixed model is some of the most beautiful
mathematics that I have ever done.  Unfortunately it is not very
practical mathematics because one of those calculations is the
equivalent of several hundred function evaluations on models with
large data sets.  It is much better to just let the optimizer work out
an approximation to the gradient and to skip the EM or ECME iterations
altogether.

I repeated your timings on R-forge.R-project.org, an Opteron-based
server running Debian Linux.  I enclose the results.  Once you get rid
of the ECME iterations and the gradient calculations lmer and lmer2
are in the same ballpark with a slight advantage to lmer on most of
the models.  Both functions took about a minute or less to fit models
with up to 20000 random effects to about 25000 observations, which is
not bad at all.

As you know, not all these models can be fit by lme and, as the
timings show, lme is much slower on the models that it can fit.  This
is not surprising, there has been close to a decade's worth of
development of the computational methods since lme was initially
designed.



> Here are the full models I used:
>
> lmer(math~ gr + sx + eth + cltype + (1+yrs|id) + (1+yrs|sch), data=star)
>
> samm(math ~ gr + sx + eth + cltype, random=~ us(link(~1+yrs)):id +
>      us(link(~1+yrs)):sch, data=star, na.method.X="omit")
>
> Starting with these full models, I tried reduced models with simpler random
> effects structures.  These are the different rows in the table above.
>
> Observations:
> (1) The performance of the common version of SAMM on the two computers suggests
> the Dell is slightly faster than the IBM.
>
> (2) On 24 May 2005, lmer and samm has roughly similar timings.  On 31 Jan
> 2007, lmer is nearly unusable for this data (I killed the job after 5-10
> minutes of waiting).
>
> (3) The current version of lmer2 is the only function that appears to fit
> all models.
>
> (4) The current version of lme is slower than sammm/lmer2 for
>     those models I tried to fit.
>
> FYI.  SAMM is officially available at
> http://www.vsni.co.uk/products/samm/(but seems not to be there now,
> perhaps in preparation for release of a new
> version). Unofficially it is available here: ftp://ftp.dpi.nsw.gov.au/

I'm not sure if I have access to SAMM to check the timings.  Is SAMM
proprietary?  My recollection is that it is proprietary and that it is
Windows-only.  Either one of those characteristics is the kiss of
death for my wanting to use it.

Are you sure that SAMM is fitting a model with partially-crossed
random effects?  If you are only considering students and schools as
grouping factors for the random effects there will be little
difference between assuming nested random effects and correcting for
the partial crossing.  This is because there are very few students in
this study who attend more than one school.  If you considered
teachers as well as students and schools as grouping factors then you
could more easily discern the difference in model fits taking into
account the crossing or assuming that each student:teacher:school
combination is unique.

>
> I hope this information is useful.  Thanks for the progress evident in the
> lme4 package.
>
> Kevin Wright
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------
Random.effects        lmer   lmer2   lme
(yrs|id)+(yrs|sch)   51.203 62.640   NA
(yrs|id)+(1|sch)     14.497 22.533   NA
(1|id)+(yrs|sch)     13.449  5.188   NA
(1|id)+(1|sch)        2.540  2.056   NA
(yrs|id)              6.409  9.992 84.037
(1|id)                0.628  1.020  5.637
(yrs|sch)             0.860  0.533  3.544
(1|sch)               0.544  0.472  2.404
-------------- next part --------------
library(lme4)
data(star, package = 'mlmRev')
system.time(lmer(math ~ gr + sx + eth + cltype + (yrs|id) + (yrs|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer(math ~ gr + sx + eth + cltype + (yrs|id) + (1|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer(math ~ gr + sx + eth + cltype + (1|id) + (yrs|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer(math ~ gr + sx + eth + cltype + (1|id) + (1|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer(math ~ gr + sx + eth + cltype + (yrs|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer(math ~ gr + sx + eth + cltype + (1|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer(math ~ gr + sx + eth + cltype + (yrs|id),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer(math ~ gr + sx + eth + cltype + (1|id),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer2(math ~ gr + sx + eth + cltype + (yrs|id) + (yrs|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer2(math ~ gr + sx + eth + cltype + (yrs|id) + (1|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer2(math ~ gr + sx + eth + cltype + (1|id) + (yrs|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer2(math ~ gr + sx + eth + cltype + (1|id) + (1|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer2(math ~ gr + sx + eth + cltype + (yrs|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer2(math ~ gr + sx + eth + cltype + (1|sch),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer2(math ~ gr + sx + eth + cltype + (yrs|id),
                 star, control = list(niterEM = 0, gradient = FALSE)))
system.time(lmer2(math ~ gr + sx + eth + cltype + (1|id),
                 star, control = list(niterEM = 0, gradient = FALSE)))
-------------- next part --------------
library(nlme)
data(star, package = 'mlmRev')
system.time(lme(math ~ gr + sx + eth + cltype, star, random = ~yrs|sch, na.action = na.omit))
system.time(lme(math ~ gr + sx + eth + cltype, star, random = ~1|sch, na.action = na.omit))
system.time(lme(math ~ gr + sx + eth + cltype, star, random = ~yrs|id, na.action = na.omit))
system.time(lme(math ~ gr + sx + eth + cltype, star, random = ~1|id, na.action = na.omit))
-------------- next part --------------

R version 2.5.0 Under development (unstable) (2007-01-31 r40628)
Copyright (C) 2007 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> library(nlme)
> data(star, package = 'mlmRev')
> system.time(lme(math ~ gr + sx + eth + cltype, star, random = ~yrs|sch, na.action = na.omit))
   user  system elapsed 
  3.544   0.168   3.713 
> system.time(lme(math ~ gr + sx + eth + cltype, star, random = ~1|sch, na.action = na.omit))
   user  system elapsed 
  2.404   0.128   2.532 
> system.time(lme(math ~ gr + sx + eth + cltype, star, random = ~yrs|id, na.action = na.omit))
   user  system elapsed 
 84.037   1.588  85.672 
> system.time(lme(math ~ gr + sx + eth + cltype, star, random = ~1|id, na.action = na.omit))
   user  system elapsed 
  5.637   0.124   5.759 
> 
> proc.time()
   user  system elapsed 
 97.006   2.064  99.109 
-------------- next part --------------

R version 2.5.0 Under development (unstable) (2007-01-31 r40628)
Copyright (C) 2007 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> library(lme4)
Loading required package: Matrix
Loading required package: lattice
> data(star, package = 'mlmRev')
> system.time(lmer(math ~ gr + sx + eth + cltype + (yrs|id) + (yrs|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
 51.203   6.944  58.218 
> system.time(lmer(math ~ gr + sx + eth + cltype + (yrs|id) + (1|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
 14.497   0.172  14.669 
> system.time(lmer(math ~ gr + sx + eth + cltype + (1|id) + (yrs|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
 13.449   0.140  13.624 
> system.time(lmer(math ~ gr + sx + eth + cltype + (1|id) + (1|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  2.540   0.080   2.623 
> system.time(lmer(math ~ gr + sx + eth + cltype + (yrs|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  0.860   0.064   0.925 
> system.time(lmer(math ~ gr + sx + eth + cltype + (1|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  0.544   0.060   0.606 
> system.time(lmer(math ~ gr + sx + eth + cltype + (yrs|id),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  6.409   0.392   6.802 
> system.time(lmer(math ~ gr + sx + eth + cltype + (1|id),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  0.628   0.084   0.711 
> system.time(lmer2(math ~ gr + sx + eth + cltype + (yrs|id) + (yrs|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
 62.640   4.204  66.843 
> system.time(lmer2(math ~ gr + sx + eth + cltype + (yrs|id) + (1|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
 22.533   0.944  23.492 
> system.time(lmer2(math ~ gr + sx + eth + cltype + (1|id) + (yrs|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  5.188   0.216   5.406 
> system.time(lmer2(math ~ gr + sx + eth + cltype + (1|id) + (1|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  2.056   0.032   2.089 
> system.time(lmer2(math ~ gr + sx + eth + cltype + (yrs|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  0.533   0.032   0.565 
> system.time(lmer2(math ~ gr + sx + eth + cltype + (1|sch),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  0.472   0.016   0.486 
> system.time(lmer2(math ~ gr + sx + eth + cltype + (yrs|id),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  9.992   0.348  10.364 
> system.time(lmer2(math ~ gr + sx + eth + cltype + (1|id),
+                  star, control = list(niterEM = 0, gradient = FALSE)))
   user  system elapsed 
  1.020   0.024   1.046 
> 
> proc.time()
   user  system elapsed 
204.576  13.948 218.748 

From bates at stat.wisc.edu  Fri Feb  2 15:13:12 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 Feb 2007 08:13:12 -0600
Subject: [R-sig-ME] Is there any chance of development ofmultivariate
	linear mixed models for lme4
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E8D47DB@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E8D47DB@dc1ex01.air.org>
Message-ID: <40e66e0b0702020613q19a588ek8a5665aced1767c9@mail.gmail.com>

The way that I would like to approach this kind of model is to
incorporate the variance-covariance of the multivariate response as a
"pre-whitening" transformation.  In the "Implemenentation" vignette in
the lme4 package I describe the representation of a positive
semi-definite matrix (i.e. a general variance-covariance matrix) as
the product of a diagonal matrix and a unit lower-triangular matrix.
That parameterization could be used for the variance-covariance of the
multivariate response.  (It may be necessary to constrain one of the
diagonal elements of the diagonal matrix to 1 because of the profiling
out of the scalar variance parameter.)

Conditional on those parameters the model matrices and responses could
be "pre-whitened" to a set of independent, constant-variance response
and the corresponding model matrices.  These would then update the
ZXyt slot in the mer2 representation and the optimization could
proceed from there.  In lme we used a "nested" optimization.  I think
I would not recommend doing that here.  I would try to do the
optimization jointly.

I imagine there would need to be another factor in the deviance that
takes into account the variance-covariance structure of the responses.

Generally I would like to regard the what I am now calling the mer2
representation (it will become the mer class later when I have all the
necessary methods programmed) as a building block for models that
extend the univariate linear mixed effects model.  These include the
generalized linear mixed effects model, the nonlinear mixed effects
model, the multivariate linear mixed effects model, ...

On 2/2/07, Doran, Harold <HDoran at air.org> wrote:
> I'm interested in seeing this as well. I too have a paper showing how to
> estimate multivariate mixed models. But, I think it is necessary to
> construct a patterned covariance matrix for the residual error and this
> is not available in lmer.
>
> @article{dora:lock:2006,
> year                    ={2006},
> author          ={Harold C. Doran and J.R. Lockwood},
> title                   ={Fitting value-added models in {R}},
> volume          ={31}.
> number          ={2},
> journal         ={Journal of Educational and Behavioral Statistics}
> }
>
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
> > Of Andrew Robinson
> > Sent: Thursday, February 01, 2007 6:31 PM
> > To: Ian Dworkin
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Is there any chance of development
> > ofmultivariate linear mixed models for lme4
> >
> > Hi Ian,
> >
> > I've been able to trick lme() into fitting multivariate
> > mixed-effects models, and I don't think that I relied on any
> > functionality that is not available within lmer at the
> > present.  I can send you what I did if you're interested.  I
> > wrote it up in:
> >
> > Robinson, A.P., 2004. Preserving correlation while modelling diameter
> >   distributions. Canadian Journal of Forest Research 34, 221--232.
> >
> > Mind you, the code was ugly and not terribly intuitive!
> >
> > Cheers
> >
> > Andrew
> >
> > On Thu, Feb 01, 2007 at 05:59:54PM -0500, Ian Dworkin wrote:
> > > Hi,
> > >
> > >   From what I gather this is a list primarily dedicated to the
> > > development of mixed model libraries for R. So I apologize
> > if this is
> > > not the appropriate place for this.
> > >
> > >   I am in the process of making the transition from SAS to
> > R. One of
> > > the major procedures I use(d) in SAS was PROC MIXED, and I
> > am slowly
> > > getting familiar with lmer.
> > >
> > >  I was wondering if there is any discussion of working on the
> > > development of multivariate mixed models? Most of the data I am
> > > interested with is multivariate in nature, and univariate
> > methods tend
> > > to be less useful. Not that PROC MIXED does this very
> > effectively, but
> > > you can trick MIXED to do some multivariate models using
> > the repeated
> > > statement and specifying an unstructured covariance matrix etc..
> > > However the code is ugly and not very intuitive.
> > >
> > >   Anyways, I am asking in the vain hope that something is being
> > > developed in lme4 for multivariate models.
> > >
> > > Thanks
> > >
> > > Ian
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > --
> > Andrew Robinson
> > Department of Mathematics and Statistics            Tel:
> > +61-3-8344-9763
> > University of Melbourne, VIC 3010 Australia         Fax:
> > +61-3-8344-4599
> > http://www.ms.unimelb.edu.au/~andrewpr
> > http://blogs.mbs.edu/fishing-in-the-bay/
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kw.statr at gmail.com  Fri Feb  2 17:33:12 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Fri, 2 Feb 2007 10:33:12 -0600
Subject: [R-sig-ME] Timings with SAMM, lme4, nlme
In-Reply-To: <40e66e0b0702011039p42add396t5d04c1a3efe73b8c@mail.gmail.com>
References: <c968588d0702010724k25c079fdo5eb8baa6770f3ecf@mail.gmail.com>
	<40e66e0b0702011039p42add396t5d04c1a3efe73b8c@mail.gmail.com>
Message-ID: <c968588d0702020833u41c297e6ta1741cb6794a9dd1@mail.gmail.com>

(1) In short, I can find essentially no difference in the results of the
samm and lmer models (the most complex one that both functions could
handle):

lmer: math~ gr + sx + eth + cltype + (1+yrs|id) + (1|sch)
samm: math ~ gr + sx + eth + cltype, random=~ us(link(~1+yrs)):id + sch

After several hours searching through the return values of the two functions
(slots, S3 methods, S4 methods, extractors and all that) and identifying
unique approaches (lmer uses polynomial contrasts for ordered factors and
samm uses treatment contrasts; missing values in the data are handled
slightly differently in the way the random effects return values are
presented), I find the two functions have nearly identical variance
components and essentially identical fixed effects and random effects.  An R
transcript is attached for reference.

(2) Yes, SAMM is proprietary.  It is available on Windows and Linux, S-Plus
and R.  The developer has told me that version 2 is very near completion.
If you ever want to try it out, there is a 30-day free trial before it stops
working.

I use lme4 because it is open-source and has a good community of users,
published examples, etc.  I use samm to analyze data from plant breeding
experiments (current literature methods use large data sets, crossed random
effects, heteroskedasticity, spatial correlation, etc.).  SAMM also has
convenient reporting of linear predictions of BLUEs/BLUPs (Welham , Cullis,
Gogel, Gilmour, & Thompson 2004, Stroup & Mulitze 1991) for
decision-making.  I also use both because fitting the same model using two
different software packages (when the software capabilities allow for it)
really helps me think carefully and hard about what I'm asking the software
to do, what it actually does, and what the results actually mean.

Thanks for the challenging question...I learned more because of it.


Kevin

(thread edited below for brevity)

Doug Bates wrote:

I'm not sure if I have access to SAMM to check the timings.  Is SAMM
> proprietary?  My recollection is that it is proprietary and that it is
> Windows-only.  Either one of those characteristics is the kiss of
> death for my wanting to use it.
>
> Are you sure that SAMM is fitting a model with partially-crossed
> random effects?  If you are only considering students and schools as
> grouping factors for the random effects there will be little
> difference between assuming nested random effects and correcting for
> the partial crossing.  This is because there are very few students in
> this study who attend more than one school.  If you considered
> teachers as well as students and schools as grouping factors then you
> could more easily discern the difference in model fits taking into
> account the crossing or assuming that each student:teacher:school
> combination is unique.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070202/36df8a8d/attachment.html>
-------------- next part --------------

R> library(mlmRev)
Loading required package: lme4
Loading required package: Matrix
R> library(samm)
Attaching package: 'samm'
R> library(kw)  # For ranef.samm, fixef.samm, VarCorr.samm

# samm and lmer treat missings slightly differently in the return value,
# so level the playing field by removing all observations with missing values
R> star2 <- subset(star, !(is.na(math) | is.na(gr) | is.na(sx) | is.na(eth) |
+                         is.na(cltype) | is.na(yrs) | is.na(id) | is.na(sch)))

# In the 'star' data, gr is an "ordered factor"
# lmer uses polynomial contrasts for ordered factors by default
# samm uses treatment contrasts for ordered factors
# Make 'gr' into an unordered factor
R> star2$gr <- as.factor(as.character(star2$gr))

# Fit the models.  lmer: 10.4 seconds lmer2: 11.3  samm: 6.0
R> system.time(f.lmer <- lmer(math~ gr + sx + eth + cltype +
+                            (1+yrs|id) + (1|sch), data=star2,
+                            control=list(gradient = FALSE, niterEM = 0)))
[1] 16.13  0.40 18.22    NA    NA

R> system.time(f.lmer2 <- lmer2(math~ gr + sx + eth + cltype +
+                            (1+yrs|id) + (1|sch), data=star2))
[1] 17.00  0.53 18.50    NA    NA

R> system.time(f.samm <- samm(math ~ gr + sx + eth + cltype,
+                          random=~ us(link(~1+yrs)):id + sch ,
+                          data=star2))
+-----------------------------------------------------------------+
Spatial Analysis <> Mixed Models   Version: VSN 1.10
AIsamm license expires: 65535 days
SAMM Convergence Monitoring: Thu Feb 01 17:08:08 2007
+-----------------------------------------------------------------+

Seq  Component 
  1  link("~1 + yrs"):id!Intercept:Intercept
  2  link("~1 + yrs"):id!yrs:Intercept
  3  link("~1 + yrs"):id!yrs:yrs
  4  sch
  5  R!variance

Equations:  21560 (17 dense)
Initial update shrinkage factor: 0.316
Singularities: 4 (more)

     LogLik         S2      DF          1          2          3          4          5

-101615.5560    898.1042 24566      0.150      0.100      0.150      0.100      1.000  17:08:09
-100808.5510    796.0875 24566      0.435      0.071      0.118      0.125      1.000  17:08:10
-100144.8784    689.3688 24566      0.966     -0.005      0.101      0.167      1.000  17:08:10
 -99855.8696    603.4995 24566      1.786     -0.155      0.113      0.214      1.000  17:08:11
 -99838.3681    584.1043 24566      2.086     -0.228      0.128      0.212      1.000  17:08:11
 -99838.0609    583.0869 24566      2.119     -0.240      0.130      0.209      1.000  17:08:12
 -99838.0569    583.1879 24566      2.121     -0.241      0.130      0.209      1.000  17:08:12
FINAL   parameter values:           2.121     -0.241      0.130      0.209      1.000
Constraint codes:                       U          U          U          P          P

Exit status: 0 - LogLikelihood Converged
Finished on: Thu Feb 01 17:08:12 2007
 
Convergence monitoring: LogLikelihood Converged 
[1] 5.70 0.02 6.38   NA   NA

# Use results of lmer, since extractor functions seem easier to use

# Variance components for samm
R> kw::VarCorr(f.samm)
Response:  math 
                                        Component Std Err Z Ratio    Constraint
link("~1 + yrs"):id!Intercept:Intercept 1236.8585 30.3504  40.753 Unconstrained
link("~1 + yrs"):id!yrs:Intercept       -140.5416 10.4943 -13.392 Unconstrained
link("~1 + yrs"):id!yrs:yrs               75.8448  5.0346  15.065 Unconstrained
sch                                      121.6656 21.1143   5.762      Positive
R!variance                               583.1879  8.6846  67.152      Positive

# Variance components for lmer
R> VarCorr(f.lmer)$id
2 x 2 Matrix of class "dpoMatrix"
            (Intercept)        yrs
(Intercept)   1236.9322 -140.56470
yrs           -140.5647   75.85085

R> VarCorr(f.lmer)$sch
1 x 1 Matrix of class "dpoMatrix"
            (Intercept)
(Intercept)    121.6565

R> attr(VarCorr(f.lmer),"sc")^2
   scale 
583.2067 

# Fixed effects for samm
R> kw::fixef(f.samm)
cltype_small   cltype_reg cltype_reg+A        eth_W        eth_B        eth_A 
    0.000000    -7.340255    -6.054712     0.000000   -22.934383     2.554495 
       eth_H        eth_I        eth_O         sx_M         sx_F         gr_1 
    1.410943   -34.301117     3.402846     0.000000     2.797615     0.000000 
        gr_2         gr_3         gr_K  (Intercept) 
   47.993067    83.587681   -44.421802   539.051085 

# Fixed effects for lmer
R> fixef(f.lmer)
(Intercept)         gr2         gr3         grK         sxF        ethB 
 539.051209   47.993546   83.588789  -44.421994    2.797348  -22.934191 
       ethA        ethH        ethI        ethO   cltypereg cltypereg+A 
   2.556208    1.411219  -34.300729    3.405428   -7.340299   -6.054774 

# Correlation of fixed effects for samm/lmer
R> fs <- kw::fixef(f.samm)
R> fs <- fs[abs(fs)>.001]
R> cor(sort(fs), sort(fixef(f.lmer)))
[1] 1

R> # samm random intercept for each school
R> as.vector(tail(kw::ranef(f.samm),80))
 [1]   1.3143717 -20.5348662   3.2968950  -1.0183895 -21.1174158 -17.1111596
 [7]   8.1185468  -3.5960209   1.9353613  21.5313533  19.7123450  13.1381558
[13]   5.1417748   6.4959617  -4.9180225  -9.1269814  -8.5555231  -8.0622654
[19] -12.9893362   7.3534878  -8.7966736   0.1812109  20.5266225  11.7676528
[25]  -8.8642947 -19.4369518  11.1248498  -4.7711922  17.2450765   8.9582622
[31]  -2.9094668 -13.8162709  -9.0721915  -7.1982139 -10.0674440   4.3567975
[37]   2.9597060  -7.9531537   3.9690027  -2.6906443  25.1882796  -6.8958274
[43]   3.0637880  -9.1939666   5.5059775  -1.9412242  -7.6311463 -11.8170561
[49]  -7.0021395  -5.6523660   4.6034859   6.9618590  -9.6490649   2.2870641
[55] -12.6429433 -16.4871068 -10.5297346  -0.6011866  -0.3508403 -13.0738001
[61]   9.2144515  -3.0903109   9.7637953   0.4114071   9.0939491   1.9779132
[67]  -3.2119299  12.8595955  17.8323498   0.8572007  -8.1456880  15.8826757
[73]   5.1027719  23.8611109   1.9011668  -6.3425222   5.6704674  -2.2273366
[79]   9.7215416  -1.7956171

# lmer random intercept for each school
R> lme4:::ranef(f.lmer)[[2]][,1]
 [1]   1.3133874 -20.5335295   3.2956710  -1.0160289 -21.1169777 -17.1095972
 [7]   8.1168346  -3.5945118   1.9352882  21.5310053  19.7115966  13.1401330
[13]   5.1383739   6.4961299  -4.9184228  -9.1255942  -8.5557981  -8.0617211
[19] -12.9903605   7.3527759  -8.7991525   0.1799393  20.5243880  11.7679624
[25]  -8.8640390 -19.4362049  11.1219601  -4.7703302  17.2445306   8.9532094
[31]  -2.9119062 -13.8155380  -9.0719066  -7.1963657 -10.0661642   4.3582431
[37]   2.9599896  -7.9522175   3.9701887  -2.6930150  25.1871108  -6.8951564
[43]   3.0654065  -9.1979970   5.5086618  -1.9394761  -7.6314905 -11.8180674
[49]  -7.0025942  -5.6537153   4.6030342   6.9599747  -9.6486151   2.2865630
[55] -12.6427040 -16.4839846 -10.5288129  -0.6033224  -0.3515562 -13.0727761
[61]   9.2167562  -3.0882666   9.7630371   0.4125758   9.0944709   1.9818962
[67]  -3.2120202  12.8576685  17.8320933   0.8574842  -8.1447511  15.8819324
[73]   5.1012380  23.8613070   1.9013746  -6.3435578   5.6695532  -2.2235653
[79]   9.7241380  -1.7960726

# Correlation of samm/lmer random intercepts for school
R> cor(lme4:::ranef(f.lmer)[[2]][,1], as.vector(tail(kw::ranef(f.samm),80)))
[1] 1

# lmer Random slope/intercept for each 'id'
R> head(lme4:::ranef(f.lmer)[[1]])
       (Intercept)          yrs
100017   89.893617 -10.21549112
100028  -36.049228   4.09662647
100045    6.318275  -0.00364208
100064   -9.404819   1.06876159
100070   62.249604  -6.72732399
100096   26.410811   0.76421193

# samm 
R> data.frame(int=kw::ranef(f.samm)[1:6],
+            yrs=kw::ranef(f.samm)[10733:10738])
                 int           yrs
id_100017  89.890923 -10.209949210
id_100028 -36.049490   4.094556472
id_100045   6.317053  -0.003151222
id_100064  -9.403919   1.068111606
id_100070  62.244643  -6.723240707
id_100096  26.408558   0.766162668

# The tail of the random effects from lme
R> tail(lme4:::ranef(f.lmer)[[1]])
      (Intercept)        yrs
99912    5.695326 -3.6083994
99937   13.972907  4.4756514
99942   13.718499 -1.5589673
99967    7.085396 -3.8997280
99979    5.132715 -0.5832806
99992   -4.265711 -5.6205076

# The tail of the random effects from samm
R> data.frame(int=kw::ranef(f.samm)[10727:10732],
+            yrs=kw::ranef(f.samm)[21459:21464])
               int        yrs
id_99912  5.693616 -3.6080847
id_99937 13.973628  4.4767916
id_99942 13.716419 -1.5579320
id_99967  7.082693 -3.8993951
id_99979  5.131698 -0.5828662
id_99992 -4.265344 -5.6211783

# Correlation of samm/lmer 'id' random effects
R> cor(lme4:::ranef(f.lmer)[[1]][,1], kw::ranef(f.samm)[1:10732])
[1] 1
R> cor(lme4:::ranef(f.lmer)[[1]][,2], kw::ranef(f.samm)[10733:21464])
[1] 1

From bates at stat.wisc.edu  Fri Feb  2 18:55:34 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 Feb 2007 11:55:34 -0600
Subject: [R-sig-ME] Timings with SAMM, lme4, nlme
In-Reply-To: <c968588d0702020833u41c297e6ta1741cb6794a9dd1@mail.gmail.com>
References: <c968588d0702010724k25c079fdo5eb8baa6770f3ecf@mail.gmail.com>
	<40e66e0b0702011039p42add396t5d04c1a3efe73b8c@mail.gmail.com>
	<c968588d0702020833u41c297e6ta1741cb6794a9dd1@mail.gmail.com>
Message-ID: <40e66e0b0702020955u10c4df3fyaef6f819ce512c12@mail.gmail.com>

On 2/2/07, Kevin Wright <kw.statr at gmail.com> wrote:
>
> (1) In short, I can find essentially no difference in the results of the
> samm and lmer models (the most complex one that both functions could
> handle):
>
> lmer: math~ gr + sx + eth + cltype + (1+yrs|id) + (1|sch)
>  samm: math ~ gr + sx + eth + cltype, random=~ us(link(~1+yrs)):id + sch
>
> After several hours searching through the return values of the two functions
> (slots, S3 methods, S4 methods, extractors and all that) and identifying
> unique approaches (lmer uses polynomial contrasts for ordered factors and
> samm uses treatment contrasts; missing values in the data are handled
> slightly differently in the way the random effects return values are
> presented), I find the two functions have nearly identical variance
> components and essentially identical fixed effects and random effects.  An R
> transcript is attached for reference.
>
> (2) Yes, SAMM is proprietary.  It is available on Windows and Linux, S-Plus
> and R.  The developer has told me that version 2 is very near completion.
> If you ever want to try it out, there is a 30-day free trial before it stops
> working.
>
> I use lme4 because it is open-source and has a good community of users,
> published examples, etc.  I use samm to analyze data from plant breeding
> experiments (current literature methods use large data sets, crossed random
> effects, heteroskedasticity, spatial correlation, etc.).  SAMM also has
> convenient reporting of linear predictions of BLUEs/BLUPs (Welham , Cullis,
> Gogel, Gilmour, & Thompson 2004, Stroup & Mulitze 1991) for decision-making.
>  I also use both because fitting the same model using two different software
> packages (when the software capabilities allow for it) really helps me think
> carefully and hard about what I'm asking the software to do, what it
> actually does, and what the results actually mean.
>
> Thanks for the challenging question...I learned more because of it.

Thanks for the response, Kevin.  The reason that I suggested comparing
models with random effects for students, teachers and schools in the
star data is because incorporating random effects for teachers will
more clearly expose differences between partially crossed random
effects and implicitly nested random effects.  I would try to fit
something like the enclosed model fit then check for consistency in
the estimates of the variance-covariance matrices of the random
effects, the log-likelihood, etc.



From bates at stat.wisc.edu  Fri Feb  2 19:06:01 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 Feb 2007 12:06:01 -0600
Subject: [R-sig-ME] Timings with SAMM, lme4, nlme
In-Reply-To: <40e66e0b0702020955u10c4df3fyaef6f819ce512c12@mail.gmail.com>
References: <c968588d0702010724k25c079fdo5eb8baa6770f3ecf@mail.gmail.com>
	<40e66e0b0702011039p42add396t5d04c1a3efe73b8c@mail.gmail.com>
	<c968588d0702020833u41c297e6ta1741cb6794a9dd1@mail.gmail.com>
	<40e66e0b0702020955u10c4df3fyaef6f819ce512c12@mail.gmail.com>
Message-ID: <40e66e0b0702021006s7039fab3h1642dc016b002f3b@mail.gmail.com>

I enclose the attachment that I forgot to add to my earlier response.



From bernd.weiss at uni-koeln.de  Mon Feb  5 16:36:43 2007
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Mon, 05 Feb 2007 16:36:43 +0100
Subject: [R-sig-ME] Heterogeneous compound symmetry in R?
Message-ID: <45C75D1B.12355.1CD2B43@bernd.weiss.uni-koeln.de>

Dear all,

I wonder if lmer/lme are capable of dealing with "heterogeneous 
compound symmetry". I found this term in a book that mainly refers to 
SAS and SPSS. 

Thanks for your help,

Bernd



From Jerome.Goudet at unil.ch  Mon Feb  5 16:26:26 2007
From: Jerome.Goudet at unil.ch (Jerome Goudet)
Date: Mon, 05 Feb 2007 16:26:26 +0100
Subject: [R-sig-ME] extracting variance components in lme4?
Message-ID: <45C74CA2.2070707@unil.ch>

I was wondering whether anyone knew of a quick way to extract variance 
component from an lmer (or lmer2) model.  I have a random effect nested 
design (with fact2 nested in fact1) that I call as follow

model1<-lmer(resp~1+(1|fact1)+(1|fact2),data=data)

I can obtain the variance components from VarCorr (actually, the 
variance components of fact1 and fact2 only, and the standard deviation 
of the residuals):

vc<-VarCorr(model1)

but then, I can't extract the variance components and store them in a 
simple R object (I could with lme of package nlme).  I need to do that 
for further processing.

Any clues on how I could do it )


Many thanks in advance.

-- 
J?r?me GOUDET
Dep. Ecology & Evolution
Biophore, UNIL-Sorge
UNIL-CH-1015 Lausanne
Switzerland
http://www.unil.ch/dee
http://www.unil.ch/popgen
Tel: +41 21 692 42 42    Fax: +41 21 692 42 65
Secr:+41 21 692 42 60
jerome.goudet-at-unil.ch



From Jerome.Goudet at unil.ch  Mon Feb  5 17:11:39 2007
From: Jerome.Goudet at unil.ch (Jerome Goudet)
Date: Mon, 05 Feb 2007 17:11:39 +0100
Subject: [R-sig-ME] extracting variance components in lme4?
Message-ID: <45C7573B.1050200@unil.ch>

I was wondering whether anyone knew of a quick way to extract variance
component from an lmer (or lmer2) model.  I have a random effect nested
design (with fact2 nested in fact1) that I call as follow

model1<-lmer(resp~1+(1|fact1)+(1|fact2),data=data)

I can obtain the variance components from VarCorr (actually, the
variance components of fact1 and fact2 only, and the standard deviation
of the residuals):

vc<-VarCorr(model1)

but then, I can't extract the variance components and store them in a
simple R object (I could with lme of package nlme).  I need to do that
for further processing.

Any clues on how I could do it )


Many thanks in advance.

-- 
J?r?me GOUDET
Dep. Ecology & Evolution
Biophore, UNIL-Sorge
UNIL-CH-1015 Lausanne
Switzerland
http://www.unil.ch/dee
http://www.unil.ch/popgen
Tel: +41 21 692 42 42    Fax: +41 21 692 42 65
Secr:+41 21 692 42 60
jerome.goudet-at-unil.ch



From A.Robinson at ms.unimelb.edu.au  Mon Feb  5 19:40:35 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 6 Feb 2007 05:40:35 +1100
Subject: [R-sig-ME] Heterogeneous compound symmetry in R?
In-Reply-To: <45C75D1B.12355.1CD2B43@bernd.weiss.uni-koeln.de>
References: <45C75D1B.12355.1CD2B43@bernd.weiss.uni-koeln.de>
Message-ID: <20070205184035.GK34088@ms.unimelb.edu.au>

Dear Bernd,

probably, depending on what you mean by "heterogeneous compound
symmetry".  lme can certainly fit some models that could be described
that way, but not others.  I suggest that you buy and read a book that
mainly refers to R: Pinheiro and Bates, 2002, "Mixed Effects Models in
S and S-Plus"  :) 

Cheers

Andrew

On Mon, Feb 05, 2007 at 04:36:43PM +0100, Bernd Weiss wrote:
> Dear all,
> 
> I wonder if lmer/lme are capable of dealing with "heterogeneous 
> compound symmetry". I found this term in a book that mainly refers to 
> SAS and SPSS. 
> 
> Thanks for your help,
> 
> Bernd
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Mon Feb  5 20:27:15 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 5 Feb 2007 13:27:15 -0600
Subject: [R-sig-ME] extracting variance components in lme4?
In-Reply-To: <45C74CA2.2070707@unil.ch>
References: <45C74CA2.2070707@unil.ch>
Message-ID: <40e66e0b0702051127q4af5e48dj6d73bc7be8502c23@mail.gmail.com>

On 2/5/07, Jerome Goudet <Jerome.Goudet at unil.ch> wrote:
> I was wondering whether anyone knew of a quick way to extract variance
> component from an lmer (or lmer2) model.  I have a random effect nested
> design (with fact2 nested in fact1) that I call as follow
>
> model1<-lmer(resp~1+(1|fact1)+(1|fact2),data=data)
>
> I can obtain the variance components from VarCorr (actually, the
> variance components of fact1 and fact2 only, and the standard deviation
> of the residuals):

> vc<-VarCorr(model1)

> but then, I can't extract the variance components and store them in a
> simple R object (I could with lme of package nlme).  I need to do that
> for further processing.

> Any clues on how I could do it )

Well vc is a list with two components named fact1 and fact2 and each
of those components is a matrix of class dpoMatrix.  If you have only
variance components (i.e. if the random effects terms in your model
formula always have the form (1|factx)) then you can extract the x
slot from those matrices.

Try

sapply(vc, slot, "x")

Be aware that this will give nonsense results if your model has random
effects for a slope as well as for an intercept.



From Jon.Hallander at genfys.slu.se  Tue Feb  6 13:06:32 2007
From: Jon.Hallander at genfys.slu.se (Jon Hallander)
Date: Tue, 6 Feb 2007 13:06:32 +0100
Subject: [R-sig-ME] incorporate pedigree into lmer
Message-ID: <CA871298CD1882459F7859BD08DC06E4036C9088@slumail.ad.slu.se>

Hello,

I am a novice using the lme4 library and would like some help regarding the function lmer. I would like to solve the animal model using several random effects (e.g. individual (animal) and dominance effects). Also, I would like to infer the additive and dominance relationship matrices (covariance matrices). The function pedigree can set up the pedigree structure, but how do I use it in the lmer function? I have not found any convenient example.
Thanks in advance.

Best regards,
Jon Hallander

____________________________________________

Jon Hallander
Department of Forest Genetics and Plant Physiology
Swedish University of Agricultural Sciences
SE-901 83 UME?
SWEDEN
Phone: +46 90 786 82 80
Mobile: +46 70 220 08 79
Fax: +46 90 786 81 65
E-mail: jon.hallander at genfys.slu.se
____________________________________________
###########################################

This message has been scanned by F-Secure Anti-Virus for Mic...{{dropped}}



From HDoran at air.org  Tue Feb  6 13:50:52 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 6 Feb 2007 07:50:52 -0500
Subject: [R-sig-ME] incorporate pedigree into lmer
Message-ID: <2323A6D37908A847A7C32F1E3662C80E8D48A7@dc1ex01.air.org>

Jon

I think you will find the members of this list helpful, but you have given zero information that we can use to help you with your problem. Please provide a representation of your model and a description of your data. Or better yet, some sample data. I don't have any idea what an "animal model" is (maybe others do), but if you can provide a statistical representation, maybe we can walk you through this.

Harold 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Jon Hallander
> Sent: Tuesday, February 06, 2007 7:07 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] incorporate pedigree into lmer
> 
> Hello,
> 
> I am a novice using the lme4 library and would like some help 
> regarding the function lmer. I would like to solve the animal 
> model using several random effects (e.g. individual (animal) 
> and dominance effects). Also, I would like to infer the 
> additive and dominance relationship matrices (covariance 
> matrices). The function pedigree can set up the pedigree 
> structure, but how do I use it in the lmer function? I have 
> not found any convenient example.
> Thanks in advance.
> 
> Best regards,
> Jon Hallander
> 
> ____________________________________________
> 
> Jon Hallander
> Department of Forest Genetics and Plant Physiology Swedish 
> University of Agricultural Sciences
> SE-901 83 UME?
> SWEDEN
> Phone: +46 90 786 82 80
> Mobile: +46 70 220 08 79
> Fax: +46 90 786 81 65
> E-mail: jon.hallander at genfys.slu.se
> ____________________________________________
> ###########################################
> 
> This message has been scanned by F-Secure Anti-Virus for 
> Mic...{{dropped}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From f.abian at gmx.net  Tue Feb  6 14:08:32 2007
From: f.abian at gmx.net (Fabian Scheipl)
Date: Tue, 06 Feb 2007 14:08:32 +0100
Subject: [R-sig-ME] extracting variance components in lme4?
Message-ID: <20070206130832.10060@gmx.net>

try

vc      <-VarCorr( model1 )
varcomps<-c(unlist( lapply(vc, diag) ), # random intercept variances
            attr(vc,"sc")^2)            # residual variance

also works if you have multiple random terms (intercept and slope, e.g.) for a given grouping factor.
Extracts the respective variances without the covariances.

HTH,
Fabian Scheipl
-- 
"Feel free" - 5 GB Mailbox, 50 FreeSMS/Monat ...



From Jon.Hallander at genfys.slu.se  Tue Feb  6 14:26:01 2007
From: Jon.Hallander at genfys.slu.se (Jon Hallander)
Date: Tue, 6 Feb 2007 14:26:01 +0100
Subject: [R-sig-ME] incorporate pedigree into lmer
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E8D48A7@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E8D48A7@dc1ex01.air.org>
Message-ID: <CA871298CD1882459F7859BD08DC06E4036C90F2@slumail.ad.slu.se>

Oh, sorry for being unclear. I am using a mixed linear model including both random and fixed effects:
y = Xb + Za + e
where the vector y are observed individual data, b is a vector of fixed effects, a is an individual additive random effect that are normally distributed vectors with (co)variance A*var(a). X and Z are incidence matrices relating the fixed and random effects (b and a) with the observations y. Furthermore, e is the error term, w normally distributed with mean zero and variance var(e). A is the additive genetic relationship matrix which is computed using the pedigree information (given below). A typical data might look like this:
Id Sire Dam y (i.e. weight in kg)
1  Na   Na  4.3 	
2  Na   Na  4.7
3  1    2   4.4
4  1    Na  4.1 
5  4    2   4.3
6  4    2   4.2

Thanks for the help. 

Best regards,
Jon

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: den 6 februari 2007 13:51
To: Jon Hallander; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] incorporate pedigree into lmer

Jon

I think you will find the members of this list helpful, but you have given zero information that we can use to help you with your problem. Please provide a representation of your model and a description of your data. Or better yet, some sample data. I don't have any idea what an "animal model" is (maybe others do), but if you can provide a statistical representation, maybe we can walk you through this.

Harold 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Jon Hallander
> Sent: Tuesday, February 06, 2007 7:07 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] incorporate pedigree into lmer
> 
> Hello,
> 
> I am a novice using the lme4 library and would like some help 
> regarding the function lmer. I would like to solve the animal 
> model using several random effects (e.g. individual (animal) 
> and dominance effects). Also, I would like to infer the 
> additive and dominance relationship matrices (covariance 
> matrices). The function pedigree can set up the pedigree 
> structure, but how do I use it in the lmer function? I have 
> not found any convenient example.
> Thanks in advance.
> 
> Best regards,
> Jon Hallander
> 
> ____________________________________________
> 
> Jon Hallander
> Department of Forest Genetics and Plant Physiology Swedish 
> University of Agricultural Sciences
> SE-901 83 UME?
> SWEDEN
> Phone: +46 90 786 82 80
> Mobile: +46 70 220 08 79
> Fax: +46 90 786 81 65
> E-mail: jon.hallander at genfys.slu.se
> ____________________________________________
> ###########################################
> 
> This message has been scanned by F-Secure Anti-Virus for 
> Mic...{{dropped}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
###########################################

This message has been scanned by F-Secure Anti-Virus for Mic...{{dropped}}



From bates at stat.wisc.edu  Tue Feb  6 14:42:33 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 6 Feb 2007 07:42:33 -0600
Subject: [R-sig-ME] extracting variance components in lme4?
In-Reply-To: <20070206130832.10060@gmx.net>
References: <20070206130832.10060@gmx.net>
Message-ID: <40e66e0b0702060542n74b15484i608f4853b8514530@mail.gmail.com>

On 2/6/07, Fabian Scheipl <f.abian at gmx.net> wrote:
> try
>
> vc      <-VarCorr( model1 )
> varcomps<-c(unlist( lapply(vc, diag) ), # random intercept variances
>             attr(vc,"sc")^2)            # residual variance
>
> also works if you have multiple random terms (intercept and slope, e.g.) for a given grouping factor.
> Extracts the respective variances without the covariances.

Yes, indeed.  That is better than the version that I suggested.  Thanks.

If a good name for such an extractor can be suggested I will
incorporate it in the lme4 package.  Any suggestions for a name?



From HDoran at air.org  Tue Feb  6 15:02:48 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 6 Feb 2007 09:02:48 -0500
Subject: [R-sig-ME] incorporate pedigree into lmer
Message-ID: <2323A6D37908A847A7C32F1E3662C80E8D48B4@dc1ex01.air.org>

Well, I'm still guessing at what you want as a fixed effect and what will be random, but here is a shot

(fm1 <- lmer(weight ~ 1 +(1|Sire) + (1|Dam), data))

 

> -----Original Message-----
> From: Jon Hallander [mailto:Jon.Hallander at genfys.slu.se] 
> Sent: Tuesday, February 06, 2007 8:26 AM
> To: Doran, Harold; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] incorporate pedigree into lmer
> 
> Oh, sorry for being unclear. I am using a mixed linear model 
> including both random and fixed effects:
> y = Xb + Za + e
> where the vector y are observed individual data, b is a 
> vector of fixed effects, a is an individual additive random 
> effect that are normally distributed vectors with 
> (co)variance A*var(a). X and Z are incidence matrices 
> relating the fixed and random effects (b and a) with the 
> observations y. Furthermore, e is the error term, w normally 
> distributed with mean zero and variance var(e). A is the 
> additive genetic relationship matrix which is computed using 
> the pedigree information (given below). A typical data might 
> look like this:
> Id Sire Dam y (i.e. weight in kg)
> 1  Na   Na  4.3 	
> 2  Na   Na  4.7
> 3  1    2   4.4
> 4  1    Na  4.1 
> 5  4    2   4.3
> 6  4    2   4.2
> 
> Thanks for the help. 
> 
> Best regards,
> Jon
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Doran, Harold
> Sent: den 6 februari 2007 13:51
> To: Jon Hallander; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] incorporate pedigree into lmer
> 
> Jon
> 
> I think you will find the members of this list helpful, but 
> you have given zero information that we can use to help you 
> with your problem. Please provide a representation of your 
> model and a description of your data. Or better yet, some 
> sample data. I don't have any idea what an "animal model" is 
> (maybe others do), but if you can provide a statistical 
> representation, maybe we can walk you through this.
> 
> Harold 
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Jon 
> > Hallander
> > Sent: Tuesday, February 06, 2007 7:07 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] incorporate pedigree into lmer
> > 
> > Hello,
> > 
> > I am a novice using the lme4 library and would like some help 
> > regarding the function lmer. I would like to solve the animal model 
> > using several random effects (e.g. individual (animal) and 
> dominance 
> > effects). Also, I would like to infer the additive and dominance 
> > relationship matrices (covariance matrices). The function 
> pedigree can 
> > set up the pedigree structure, but how do I use it in the lmer 
> > function? I have not found any convenient example.
> > Thanks in advance.
> > 
> > Best regards,
> > Jon Hallander
> > 
> > ____________________________________________
> > 
> > Jon Hallander
> > Department of Forest Genetics and Plant Physiology Swedish 
> University 
> > of Agricultural Sciences
> > SE-901 83 UME?
> > SWEDEN
> > Phone: +46 90 786 82 80
> > Mobile: +46 70 220 08 79
> > Fax: +46 90 786 81 65
> > E-mail: jon.hallander at genfys.slu.se
> > ____________________________________________
> > ###########################################
> > 
> > This message has been scanned by F-Secure Anti-Virus for 
> > Mic...{{dropped}}
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ###########################################
> 
> This message has been scanned by F-Secure Anti-Virus for 
> Microsoft Exchange.
> For more information, connect to http://www.f-secure.com/
>



From f.abian at gmx.net  Tue Feb  6 15:09:37 2007
From: f.abian at gmx.net (Fabian Scheipl)
Date: Tue, 06 Feb 2007 15:09:37 +0100
Subject: [R-sig-ME] extracting variance components in lme4?
In-Reply-To: <40e66e0b0702060542n74b15484i608f4853b8514530@mail.gmail.com>
References: <20070206130832.10060@gmx.net>
	<40e66e0b0702060542n74b15484i608f4853b8514530@mail.gmail.com>
Message-ID: <20070206140937.119600@gmx.net>

I'd suggest getVarComps() for its close analogy to nlme::getVarCov()...

> On 2/6/07, Fabian Scheipl <f.abian at gmx.net> wrote:
> > try
> >
> > vc      <-VarCorr( model1 )
> > varcomps<-c(unlist( lapply(vc, diag) ), # random intercept variances
> >             attr(vc,"sc")^2)            # residual variance
> >
> > also works if you have multiple random terms (intercept and slope, e.g.)
> for a given grouping factor.
> > Extracts the respective variances without the covariances.
> 
> Yes, indeed.  That is better than the version that I suggested.  Thanks.
> 
> If a good name for such an extractor can be suggested I will
> incorporate it in the lme4 package.  Any suggestions for a name?

--



From Jerome.Goudet at unil.ch  Tue Feb  6 15:23:05 2007
From: Jerome.Goudet at unil.ch (Jerome Goudet)
Date: Tue, 06 Feb 2007 15:23:05 +0100
Subject: [R-sig-ME] extracting variance components in lme4?
In-Reply-To: <40e66e0b0702060542n74b15484i608f4853b8514530@mail.gmail.com>
References: <20070206130832.10060@gmx.net>
	<40e66e0b0702060542n74b15484i608f4853b8514530@mail.gmail.com>
Message-ID: <45C88F49.2080403@unil.ch>


Douglas Bates wrote:
> On 2/6/07, Fabian Scheipl <f.abian at gmx.net> wrote:
>> try
>>
>> vc      <-VarCorr( model1 )
>> varcomps<-c(unlist( lapply(vc, diag) ), # random intercept variances
>>             attr(vc,"sc")^2)            # residual variance
>>
>> also works if you have multiple random terms (intercept and slope, e.g.) for a given grouping factor.
>> Extracts the respective variances without the covariances.
> 
> Yes, indeed.  That is better than the version that I suggested.  Thanks.
> 
> If a good name for such an extractor can be suggested I will
> incorporate it in the lme4 package.  Any suggestions for a name?

How about VarComp (for Variance Components)?



> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
J?r?me GOUDET
Dep. Ecology & Evolution
Biophore, UNIL-Sorge
UNIL-CH-1015 Lausanne
Switzerland
http://www.unil.ch/dee
http://www.unil.ch/popgen
Tel: +41 21 692 42 42    Fax: +41 21 692 42 65
Secr:+41 21 692 42 60
jerome.goudet at unil.ch



From Ulrich.Halekoh at agrsci.dk  Tue Feb  6 14:58:18 2007
From: Ulrich.Halekoh at agrsci.dk (Ulrich Halekoh)
Date: Tue, 6 Feb 2007 14:58:18 +0100
Subject: [R-sig-ME] lme4- lmer2: wrong fixed effect estimate for some
	parameterization
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D01E3D9EA@DJFPOST01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070206/d99c02f9/attachment.pl>

From Ulrich.Halekoh at agrsci.dk  Tue Feb  6 15:14:10 2007
From: Ulrich.Halekoh at agrsci.dk (Ulrich Halekoh)
Date: Tue, 6 Feb 2007 15:14:10 +0100
Subject: [R-sig-ME] lmer: covariance of variance components
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D01E3D9EB@DJFPOST01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070206/97a64e55/attachment.pl>

From HDoran at air.org  Tue Feb  6 16:55:59 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 6 Feb 2007 10:55:59 -0500
Subject: [R-sig-ME] incorporate pedigree into lmer
Message-ID: <2323A6D37908A847A7C32F1E3662C80E8D48FA@dc1ex01.air.org>

It's good to keep this on list for others to chime in and for reference. You need the ranef extractor

ranef(fm1)$sire 

> -----Original Message-----
> From: Jon Hallander [mailto:Jon.Hallander at genfys.slu.se] 
> Sent: Tuesday, February 06, 2007 10:41 AM
> To: Doran, Harold
> Subject: RE: [R-sig-ME] incorporate pedigree into lmer
> 
> Ok, thanks! This seems to work, but does it utilize the 
> pedigree information? When I type the command summary(fm1) I 
> do not get individual random effect values (breeding values), 
> but variances of the random effects:
> 
> > fm1 <- lmer(y ~ 1 +(1|sire) + (1|dam), data)
> > summary(fm1)
> Linear mixed-effects model fit by REML
> Formula: y ~ 1 + (1 | sire) + (1 | dam) 
>    Data: data1 
>    AIC   BIC logLik MLdeviance REMLdeviance
>  28.24 27.62 -11.12      23.45        22.24
> Random effects:
>  Groups   Name        Variance Std.Dev.  
>  sire     (Intercept) 1.75e-09 4.1833e-05
>  dam      (Intercept) 1.75e-09 4.1833e-05
>  Residual             3.50e+00 1.8708e+00
> number of obs: 6, groups: sire, 4; dam, 3
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   3.5000     0.7638   4.583
> 
> 
> 
> /Jon
> 
> -----Original Message-----
> From: Doran, Harold [mailto:HDoran at air.org]
> Sent: den 6 februari 2007 15:03
> To: Jon Hallander; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] incorporate pedigree into lmer
> 
> Well, I'm still guessing at what you want as a fixed effect 
> and what will be random, but here is a shot
> 
> (fm1 <- lmer(weight ~ 1 +(1|Sire) + (1|Dam), data))
> 
>  
> 
> > -----Original Message-----
> > From: Jon Hallander [mailto:Jon.Hallander at genfys.slu.se]
> > Sent: Tuesday, February 06, 2007 8:26 AM
> > To: Doran, Harold; r-sig-mixed-models at r-project.org
> > Subject: RE: [R-sig-ME] incorporate pedigree into lmer
> > 
> > Oh, sorry for being unclear. I am using a mixed linear 
> model including 
> > both random and fixed effects:
> > y = Xb + Za + e
> > where the vector y are observed individual data, b is a vector of 
> > fixed effects, a is an individual additive random effect that are 
> > normally distributed vectors with (co)variance A*var(a). X 
> and Z are 
> > incidence matrices relating the fixed and random effects (b and a) 
> > with the observations y. Furthermore, e is the error term, 
> w normally 
> > distributed with mean zero and variance var(e). A is the additive 
> > genetic relationship matrix which is computed using the pedigree 
> > information (given below). A typical data might look like this:
> > Id Sire Dam y (i.e. weight in kg)
> > 1  Na   Na  4.3 	
> > 2  Na   Na  4.7
> > 3  1    2   4.4
> > 4  1    Na  4.1 
> > 5  4    2   4.3
> > 6  4    2   4.2
> > 
> > Thanks for the help. 
> > 
> > Best regards,
> > Jon
> > 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Doran, 
> > Harold
> > Sent: den 6 februari 2007 13:51
> > To: Jon Hallander; r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] incorporate pedigree into lmer
> > 
> > Jon
> > 
> > I think you will find the members of this list helpful, but 
> you have 
> > given zero information that we can use to help you with 
> your problem. 
> > Please provide a representation of your model and a description of 
> > your data. Or better yet, some sample data. I don't have 
> any idea what 
> > an "animal model" is (maybe others do), but if you can provide a 
> > statistical representation, maybe we can walk you through this.
> > 
> > Harold
> > 
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org
> > > [mailto:r-sig-mixed-models-bounces at r-project.org] On 
> Behalf Of Jon 
> > > Hallander
> > > Sent: Tuesday, February 06, 2007 7:07 AM
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] incorporate pedigree into lmer
> > > 
> > > Hello,
> > > 
> > > I am a novice using the lme4 library and would like some help 
> > > regarding the function lmer. I would like to solve the 
> animal model 
> > > using several random effects (e.g. individual (animal) and
> > dominance
> > > effects). Also, I would like to infer the additive and dominance 
> > > relationship matrices (covariance matrices). The function
> > pedigree can
> > > set up the pedigree structure, but how do I use it in the lmer 
> > > function? I have not found any convenient example.
> > > Thanks in advance.
> > > 
> > > Best regards,
> > > Jon Hallander
> > > 
> > > ____________________________________________
> > > 
> > > Jon Hallander
> > > Department of Forest Genetics and Plant Physiology Swedish
> > University
> > > of Agricultural Sciences
> > > SE-901 83 UME?
> > > SWEDEN
> > > Phone: +46 90 786 82 80
> > > Mobile: +46 70 220 08 79
> > > Fax: +46 90 786 81 65
> > > E-mail: jon.hallander at genfys.slu.se
> > > ____________________________________________
> > > ###########################################
> > > 
> > > This message has been scanned by F-Secure Anti-Virus for 
> > > Mic...{{dropped}}
> > > 
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > ###########################################
> > 
> > This message has been scanned by F-Secure Anti-Virus for Microsoft 
> > Exchange.
> > For more information, connect to http://www.f-secure.com/
> > 
> ###########################################
> 
> This message has been scanned by F-Secure Anti-Virus for 
> Microsoft Exchange.
> For more information, connect to http://www.f-secure.com/
>



From bates at stat.wisc.edu  Tue Feb  6 18:42:22 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 6 Feb 2007 11:42:22 -0600
Subject: [R-sig-ME] lme4- lmer2: wrong fixed effect estimate for some
	parameterization
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D01E3D9EA@DJFPOST01.djf.agrsci.dk>
References: <EA09C4B2B0F16E44B8F3311629493C0D01E3D9EA@DJFPOST01.djf.agrsci.dk>
Message-ID: <40e66e0b0702060942s60adeeb4gcdaea13f90917ff2@mail.gmail.com>

On 2/6/07, Ulrich Halekoh <Ulrich.Halekoh at agrsci.dk> wrote:
> Hej,
>
> The lmer2-version (not the lmer)  calculates wrong fixed effect
> estimates if
> a model is fitted  with a factor-effects in the mean-value
> parameterization:

Yes, you are correct.  Thank you for sending a bug report with a
reproducible example.

The CHOLMOD sparse matrix library has managed to outsmart me and
produce a permutation that does not follow the pattern that I require.
 I enclose a bit of output with the Cholesky decomposition at the
parameter estimates for the g2.withOutIntercept fit.  The permutation
chosen by CHOLMOD intermingles columns from the random effects with
those from the fixed effects and that shouldn't happen.  I thought I
had prevented that from happening but apparently I didn't.  I should
be able to upload a patched version of the lme4 package later today.


>
>
> Example
> library(lme4)
>
> set.seed(98)
>
> ### data set generation of a hiearchial model with
> #  one random components sub
> ####
> #  y_ijk= a_i + delta_j(i) +   e_ijk
>
>
> n.treat<-2
> n.sub<-3
> n.rep<-4
>
> d<-expand.grid(rep=1:n.rep,sub=1:n.sub,treat=1:n.treat)
>
> treat<-d$treat
> d$treat<-factor(d$treat)
> d$treat<-relevel(d$treat,1)
> d$sub<-factor(d$sub)
> d$sub<-relevel(d$sub,1)
> d$rep<-factor(d$rep)
> d$rep<-relevel(d$rep,1)
>
>
> e.sub<-rnorm(n.treat*n.sub,sd=3)[d$treat:d$sub]
> e.rep<-rnorm(n.treat*n.sub*n.rep)
>
>
> d$y<- treat + e.sub + e.rep
>
> #parameterization with intecept
> g.withIntercept<-  lmer(y~treat+(1|treat:sub),data=d,method='REML')
> g2.withIntercept<-lmer2(y~treat+(1|treat:sub),data=d,method='REML')
>
> #parameterization without intecept
> g.withOutIntercept<-  lmer(y~0+treat+(1|treat:sub),data=d,method='REML')
> g2.withOutIntercept<-lmer2(y~0+treat+(1|treat:sub),data=d,method='REML')
>
>
> print('with intecept -all OK')
> print(g.withIntercept)
> print(g2.withIntercept)
>
>
>
> print('without intecept- in the lmer2 fit wrong estiimate for treat1
> (and STDERR)')
> print(g.withOutIntercept)
> print(g2.withOutIntercept)
>
>
> Ulrich
>
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          4.1
> year           2006
> month          12
> day            18
> svn rev        40228
> language       R
> version.string R version 2.4.1 (2006-12-18)
>
>
> lme4: [Package lme4 version 0.9975-11
>
>
>
>
> Ulrich Halekoh, Ph.D
> UNIVERSITY OF AARHUS
> Faculty of Agricultural Sciences
> Dept. of Genetics and Biotechnology
> E-mail: Ulrich.Halekoh at agrsci.dk <mailto:Ulrich.Halekoh at agrsci.dk>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------
> as(g2.withOutIntercept at L, "sparseMatrix")
9 x 9 sparse Matrix of class "dtCMatrix"
                                                                          
 [1,]  6.9183964 .         .        .         .         .         .       
 [2,]  .         6.9183964 .        .         .         .         .       
 [3,]  .         .         6.918396 .         .         .         .       
 [4,]  1.9789973 1.9789973 1.978997 0.5007087 .         .         .       
 [5,]  .         .         .        .         6.918396  .         .       
 [6,]  .         .         .        .         .         6.918396  .       
 [7,]  .         .         .        .         .         .         6.918396
 [8,]  .         .         .        .         1.978997  1.978997  1.978997
 [9,] -0.9793224 0.3366513 2.006967 0.1150608 6.897771 -5.165302 -9.247812
                         
 [1,]  .         .       
 [2,]  .         .       
 [3,]  .         .       
 [4,]  .         .       
 [5,]  .         .       
 [6,]  .         .       
 [7,]  .         .       
 [8,]  0.5007087 .       
 [9,] -0.6338222 4.131376
> str(g2.withOutIntercept at L)
Formal class 'dCHMsimpl' [package "Matrix"] with 10 slots
  ..@ x       : num [1:23] 47.864  0.286 -0.142 47.864  0.286 ...
  ..@ p       : int [1:10] 0 3 6 9 11 14 17 20 22 23
  ..@ i       : int [1:23] 0 3 8 1 3 8 2 3 8 3 ...
  ..@ nz      : int [1:9] 3 3 3 2 3 3 3 2 1
  ..@ nxt     : int [1:11] 1 2 3 4 5 6 7 8 9 -1 ...
  ..@ prv     : int [1:11] 10 0 1 2 3 4 5 6 7 8 ...
  ..@ colcount: int [1:9] 3 3 3 2 3 3 3 2 1
  ..@ perm    : int [1:9] 0 1 2 6 3 4 5 7 8
  ..@ type    : int [1:4] 1 0 0 1
  ..@ Dim     : int [1:2] 9 9

From bates at stat.wisc.edu  Tue Feb  6 19:04:37 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 6 Feb 2007 12:04:37 -0600
Subject: [R-sig-ME] incorporate pedigree into lmer
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E8D48FA@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E8D48FA@dc1ex01.air.org>
Message-ID: <40e66e0b0702061004i43503f43w8fd4a56797b8653@mail.gmail.com>

Sorry that I haven't been part of this conversation until now.  We had
a weather-related telephone failure in our city that knocked out voice
and Internet communications to our home for a few days.  I have only
been able to respond to email from the office and what with meetings,
classes, etc. I have fallen behind.

The questions that Jon is asking relate to the particular form of
random effects models that animal scientists use taking into account
the pedigree of the animals.  These are an example of a model with
"carry-over" in the random effects.  The random effect for an animal
enters into the model for that animal's responses and for all of that
animal's progeny's responses.

The current form of lmer does not allow for such carry-over.  The
models that can be fit are restricted to what might be called
contemporaneous random effects.  In particular, only one level of a
grouping factor can be involved in the model for a given response.

That's the bad news.  The good news is that there is nothing in the
computational methods that precludes carry-over in the model.  It is
"simply" a matter of modifying the model matrix for the random effects
before creating the mer objects.  The pedigree class was defined
exactly for this purpose.  If you look at

example("pedigree-class")

you will see that there are methods for creating the matrices to be
used for the transformation but that work is not complete.


On 2/6/07, Doran, Harold <HDoran at air.org> wrote:
> It's good to keep this on list for others to chime in and for reference. You need the ranef extractor
>
> ranef(fm1)$sire
>
> > -----Original Message-----
> > From: Jon Hallander [mailto:Jon.Hallander at genfys.slu.se]
> > Sent: Tuesday, February 06, 2007 10:41 AM
> > To: Doran, Harold
> > Subject: RE: [R-sig-ME] incorporate pedigree into lmer
> >
> > Ok, thanks! This seems to work, but does it utilize the
> > pedigree information? When I type the command summary(fm1) I
> > do not get individual random effect values (breeding values),
> > but variances of the random effects:
> >
> > > fm1 <- lmer(y ~ 1 +(1|sire) + (1|dam), data)
> > > summary(fm1)
> > Linear mixed-effects model fit by REML
> > Formula: y ~ 1 + (1 | sire) + (1 | dam)
> >    Data: data1
> >    AIC   BIC logLik MLdeviance REMLdeviance
> >  28.24 27.62 -11.12      23.45        22.24
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  sire     (Intercept) 1.75e-09 4.1833e-05
> >  dam      (Intercept) 1.75e-09 4.1833e-05
> >  Residual             3.50e+00 1.8708e+00
> > number of obs: 6, groups: sire, 4; dam, 3
> >
> > Fixed effects:
> >             Estimate Std. Error t value
> > (Intercept)   3.5000     0.7638   4.583
> >
> >
> >
> > /Jon
> >
> > -----Original Message-----
> > From: Doran, Harold [mailto:HDoran at air.org]
> > Sent: den 6 februari 2007 15:03
> > To: Jon Hallander; r-sig-mixed-models at r-project.org
> > Subject: RE: [R-sig-ME] incorporate pedigree into lmer
> >
> > Well, I'm still guessing at what you want as a fixed effect
> > and what will be random, but here is a shot
> >
> > (fm1 <- lmer(weight ~ 1 +(1|Sire) + (1|Dam), data))
> >
> >
> >
> > > -----Original Message-----
> > > From: Jon Hallander [mailto:Jon.Hallander at genfys.slu.se]
> > > Sent: Tuesday, February 06, 2007 8:26 AM
> > > To: Doran, Harold; r-sig-mixed-models at r-project.org
> > > Subject: RE: [R-sig-ME] incorporate pedigree into lmer
> > >
> > > Oh, sorry for being unclear. I am using a mixed linear
> > model including
> > > both random and fixed effects:
> > > y = Xb + Za + e
> > > where the vector y are observed individual data, b is a vector of
> > > fixed effects, a is an individual additive random effect that are
> > > normally distributed vectors with (co)variance A*var(a). X
> > and Z are
> > > incidence matrices relating the fixed and random effects (b and a)
> > > with the observations y. Furthermore, e is the error term,
> > w normally
> > > distributed with mean zero and variance var(e). A is the additive
> > > genetic relationship matrix which is computed using the pedigree
> > > information (given below). A typical data might look like this:
> > > Id Sire Dam y (i.e. weight in kg)
> > > 1  Na   Na  4.3
> > > 2  Na   Na  4.7
> > > 3  1    2   4.4
> > > 4  1    Na  4.1
> > > 5  4    2   4.3
> > > 6  4    2   4.2
> > >
> > > Thanks for the help.
> > >
> > > Best regards,
> > > Jon
> > >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org
> > > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
> > Of Doran,
> > > Harold
> > > Sent: den 6 februari 2007 13:51
> > > To: Jon Hallander; r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] incorporate pedigree into lmer
> > >
> > > Jon
> > >
> > > I think you will find the members of this list helpful, but
> > you have
> > > given zero information that we can use to help you with
> > your problem.
> > > Please provide a representation of your model and a description of
> > > your data. Or better yet, some sample data. I don't have
> > any idea what
> > > an "animal model" is (maybe others do), but if you can provide a
> > > statistical representation, maybe we can walk you through this.
> > >
> > > Harold
> > >
> > > > -----Original Message-----
> > > > From: r-sig-mixed-models-bounces at r-project.org
> > > > [mailto:r-sig-mixed-models-bounces at r-project.org] On
> > Behalf Of Jon
> > > > Hallander
> > > > Sent: Tuesday, February 06, 2007 7:07 AM
> > > > To: r-sig-mixed-models at r-project.org
> > > > Subject: [R-sig-ME] incorporate pedigree into lmer
> > > >
> > > > Hello,
> > > >
> > > > I am a novice using the lme4 library and would like some help
> > > > regarding the function lmer. I would like to solve the
> > animal model
> > > > using several random effects (e.g. individual (animal) and
> > > dominance
> > > > effects). Also, I would like to infer the additive and dominance
> > > > relationship matrices (covariance matrices). The function
> > > pedigree can
> > > > set up the pedigree structure, but how do I use it in the lmer
> > > > function? I have not found any convenient example.
> > > > Thanks in advance.
> > > >
> > > > Best regards,
> > > > Jon Hallander
> > > >
> > > > ____________________________________________
> > > >
> > > > Jon Hallander
> > > > Department of Forest Genetics and Plant Physiology Swedish
> > > University
> > > > of Agricultural Sciences
> > > > SE-901 83 UME?
> > > > SWEDEN
> > > > Phone: +46 90 786 82 80
> > > > Mobile: +46 70 220 08 79
> > > > Fax: +46 90 786 81 65
> > > > E-mail: jon.hallander at genfys.slu.se
> > > > ____________________________________________
> > > > ###########################################
> > > >
> > > > This message has been scanned by F-Secure Anti-Virus for
> > > > Mic...{{dropped}}
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > ###########################################
> > >
> > > This message has been scanned by F-Secure Anti-Virus for Microsoft
> > > Exchange.
> > > For more information, connect to http://www.f-secure.com/
> > >
> > ###########################################
> >
> > This message has been scanned by F-Secure Anti-Virus for
> > Microsoft Exchange.
> > For more information, connect to http://www.f-secure.com/
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From David.Duffy at qimr.edu.au  Tue Feb  6 23:19:11 2007
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 7 Feb 2007 08:19:11 +1000 (EST)
Subject: [R-sig-ME] incorporate pedigree into lmer
In-Reply-To: <CA871298CD1882459F7859BD08DC06E4036C9088@slumail.ad.slu.se>
References: <CA871298CD1882459F7859BD08DC06E4036C9088@slumail.ad.slu.se>
Message-ID: <Pine.LNX.4.64.0702070808460.13909@orpheus.qimr.edu.au>

On Tue, 6 Feb 2007, Jon Hallander wrote:

> Hello,
>
> I am a novice using the lme4 library and would like some help regarding 
> the function lmer. I would like to solve the animal model using several 
> random effects (e.g. individual (animal) and dominance effects). Also, I 
> would like to infer the additive and dominance relationship matrices 
> (covariance matrices). The function pedigree can set up the pedigree 
> structure, but how do I use it in the lmer function? I have not found 
> any convenient example. Thanks in advance.
>

It is not yet possible to fit biometrical genetic type models in lmer. 
You can use the kinship package (which calls lme), but that can be slow 
for big animal breeding type datasets.  I haven't done timings on some of 
the other R mixed model packages such as lmm.

Have you tried Wombat? That's Karin Meyer's successor for DFREML.  In one 
comparison I did, it took 3 seconds where kinship's lmekin took over an 
hour ;) See http://agbu.une.edu.au/kmeyer/wombat.html.  If you are 
specifically interested in generalized linear mixed models eg binomial, 
then your best bet currently, I think, is to write the model in BUGS.


David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From blomsp at ozemail.com.au  Wed Feb  7 00:05:35 2007
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Wed, 07 Feb 2007 10:05:35 +1100
Subject: [R-sig-ME] incorporate pedigree into lmer
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E8D48B4@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E8D48B4@dc1ex01.air.org>
Message-ID: <45C909BF.5050505@ozemail.com.au>

No,

The animal model requires specification of the variance-covariance 
matrix of the random effects, according to the pedigree (kinship) 
information. lmer and lmer2 currently do not allow this, as far as I 
know. (There is the pedigree constructor function in package lme4, as 
you noticed, so presumably this functionality is on the way.) You could 
perhaps use lme (package nlme) to fit the model, but specifying the 
var-covar matrix for such complex data will be painful. There is lmekin 
in the kinship package, which may be more useful to you. However, I 
haven't used it so I can't be of further help. I don't know how to 
estimate separate additive and dominance matrices. Maybe someone more 
experienced than me will reply.

I think there is a need for a quantitative genetics package for R, 
although some qtl mapping methods seem to be implemented (See the 
Genetics task view on CRAN). So much statistics, so little time. *sigh*

Simon.

There is Doran, Harold wrote:
> Well, I'm still guessing at what you want as a fixed effect and what will be random, but here is a shot
> 
> (fm1 <- lmer(weight ~ 1 +(1|Sire) + (1|Dam), data))
> 
>  
> 
>> -----Original Message-----
>> From: Jon Hallander [mailto:Jon.Hallander at genfys.slu.se] 
>> Sent: Tuesday, February 06, 2007 8:26 AM
>> To: Doran, Harold; r-sig-mixed-models at r-project.org
>> Subject: RE: [R-sig-ME] incorporate pedigree into lmer
>>
>> Oh, sorry for being unclear. I am using a mixed linear model 
>> including both random and fixed effects:
>> y = Xb + Za + e
>> where the vector y are observed individual data, b is a 
>> vector of fixed effects, a is an individual additive random 
>> effect that are normally distributed vectors with 
>> (co)variance A*var(a). X and Z are incidence matrices 
>> relating the fixed and random effects (b and a) with the 
>> observations y. Furthermore, e is the error term, w normally 
>> distributed with mean zero and variance var(e). A is the 
>> additive genetic relationship matrix which is computed using 
>> the pedigree information (given below). A typical data might 
>> look like this:
>> Id Sire Dam y (i.e. weight in kg)
>> 1  Na   Na  4.3 	
>> 2  Na   Na  4.7
>> 3  1    2   4.4
>> 4  1    Na  4.1 
>> 5  4    2   4.3
>> 6  4    2   4.2
>>
>> Thanks for the help. 
>>
>> Best regards,
>> Jon
>>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org 
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
>> Of Doran, Harold
>> Sent: den 6 februari 2007 13:51
>> To: Jon Hallander; r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] incorporate pedigree into lmer
>>
>> Jon
>>
>> I think you will find the members of this list helpful, but 
>> you have given zero information that we can use to help you 
>> with your problem. Please provide a representation of your 
>> model and a description of your data. Or better yet, some 
>> sample data. I don't have any idea what an "animal model" is 
>> (maybe others do), but if you can provide a statistical 
>> representation, maybe we can walk you through this.
>>
>> Harold 
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Jon 
>>> Hallander
>>> Sent: Tuesday, February 06, 2007 7:07 AM
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] incorporate pedigree into lmer
>>>
>>> Hello,
>>>
>>> I am a novice using the lme4 library and would like some help 
>>> regarding the function lmer. I would like to solve the animal model 
>>> using several random effects (e.g. individual (animal) and 
>> dominance 
>>> effects). Also, I would like to infer the additive and dominance 
>>> relationship matrices (covariance matrices). The function 
>> pedigree can 
>>> set up the pedigree structure, but how do I use it in the lmer 
>>> function? I have not found any convenient example.
>>> Thanks in advance.
>>>
>>> Best regards,
>>> Jon Hallander
>>>
>>> ____________________________________________
>>>
>>> Jon Hallander
>>> Department of Forest Genetics and Plant Physiology Swedish 
>> University 
>>> of Agricultural Sciences
>>> SE-901 83 UME?
>>> SWEDEN
>>> Phone: +46 90 786 82 80
>>> Mobile: +46 70 220 08 79
>>> Fax: +46 90 786 81 65
>>> E-mail: jon.hallander at genfys.slu.se
>>> ____________________________________________
>>> ###########################################
>>>
>>> This message has been scanned by F-Secure Anti-Virus for 
>>> Mic...{{dropped}}
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> ###########################################
>>
>> This message has been scanned by F-Secure Anti-Virus for 
>> Microsoft Exchange.
>> For more information, connect to http://www.f-secure.com/
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C

The combination of some data and an aching desire for
an answer does not ensure that a reasonable answer
can be extracted from a given body of data.
- John Tukey.



From bates at stat.wisc.edu  Wed Feb  7 04:51:08 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 6 Feb 2007 21:51:08 -0600
Subject: [R-sig-ME] uploaded lme4_0.9975-13.tar.gz to CRAN/incoming
Message-ID: <40e66e0b0702061951x171702dai1afbb1072bc0c815@mail.gmail.com>

I have uploaded a new version of the lme4 package to CRAN/incoming.
This version adds a ranef extractor (including the optional posterior
variances) for the lmer2 model formulation and fixes a problem with
the lmer2 fixed-effects calculation reported by Ulrich Halekoh.



From Jon.Hallander at genfys.slu.se  Wed Feb  7 08:23:51 2007
From: Jon.Hallander at genfys.slu.se (Jon Hallander)
Date: Wed, 7 Feb 2007 08:23:51 +0100
Subject: [R-sig-ME] incorporate pedigree into lmer
In-Reply-To: <45C909BF.5050505@ozemail.com.au>
References: <2323A6D37908A847A7C32F1E3662C80E8D48B4@dc1ex01.air.org>
	<45C909BF.5050505@ozemail.com.au>
Message-ID: <CA871298CD1882459F7859BD08DC06E4036C921B@slumail.ad.slu.se>

Thanks a lot for your informative answers. I will have a closer look at the kinship package then.

Regards,
Jon

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Simon Blomberg
Sent: den 7 februari 2007 00:06
To: Doran, Harold
Cc: r-sig-mixed-models at r-project.org; Jon Hallander
Subject: Re: [R-sig-ME] incorporate pedigree into lmer

No,

The animal model requires specification of the variance-covariance 
matrix of the random effects, according to the pedigree (kinship) 
information. lmer and lmer2 currently do not allow this, as far as I 
know. (There is the pedigree constructor function in package lme4, as 
you noticed, so presumably this functionality is on the way.) You could 
perhaps use lme (package nlme) to fit the model, but specifying the 
var-covar matrix for such complex data will be painful. There is lmekin 
in the kinship package, which may be more useful to you. However, I 
haven't used it so I can't be of further help. I don't know how to 
estimate separate additive and dominance matrices. Maybe someone more 
experienced than me will reply.

I think there is a need for a quantitative genetics package for R, 
although some qtl mapping methods seem to be implemented (See the 
Genetics task view on CRAN). So much statistics, so little time. *sigh*

Simon.

There is Doran, Harold wrote:
> Well, I'm still guessing at what you want as a fixed effect and what will be random, but here is a shot
> 
> (fm1 <- lmer(weight ~ 1 +(1|Sire) + (1|Dam), data))
> 
>  
> 
>> -----Original Message-----
>> From: Jon Hallander [mailto:Jon.Hallander at genfys.slu.se] 
>> Sent: Tuesday, February 06, 2007 8:26 AM
>> To: Doran, Harold; r-sig-mixed-models at r-project.org
>> Subject: RE: [R-sig-ME] incorporate pedigree into lmer
>>
>> Oh, sorry for being unclear. I am using a mixed linear model 
>> including both random and fixed effects:
>> y = Xb + Za + e
>> where the vector y are observed individual data, b is a 
>> vector of fixed effects, a is an individual additive random 
>> effect that are normally distributed vectors with 
>> (co)variance A*var(a). X and Z are incidence matrices 
>> relating the fixed and random effects (b and a) with the 
>> observations y. Furthermore, e is the error term, w normally 
>> distributed with mean zero and variance var(e). A is the 
>> additive genetic relationship matrix which is computed using 
>> the pedigree information (given below). A typical data might 
>> look like this:
>> Id Sire Dam y (i.e. weight in kg)
>> 1  Na   Na  4.3 	
>> 2  Na   Na  4.7
>> 3  1    2   4.4
>> 4  1    Na  4.1 
>> 5  4    2   4.3
>> 6  4    2   4.2
>>
>> Thanks for the help. 
>>
>> Best regards,
>> Jon
>>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org 
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
>> Of Doran, Harold
>> Sent: den 6 februari 2007 13:51
>> To: Jon Hallander; r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] incorporate pedigree into lmer
>>
>> Jon
>>
>> I think you will find the members of this list helpful, but 
>> you have given zero information that we can use to help you 
>> with your problem. Please provide a representation of your 
>> model and a description of your data. Or better yet, some 
>> sample data. I don't have any idea what an "animal model" is 
>> (maybe others do), but if you can provide a statistical 
>> representation, maybe we can walk you through this.
>>
>> Harold 
>>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Jon 
>>> Hallander
>>> Sent: Tuesday, February 06, 2007 7:07 AM
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] incorporate pedigree into lmer
>>>
>>> Hello,
>>>
>>> I am a novice using the lme4 library and would like some help 
>>> regarding the function lmer. I would like to solve the animal model 
>>> using several random effects (e.g. individual (animal) and 
>> dominance 
>>> effects). Also, I would like to infer the additive and dominance 
>>> relationship matrices (covariance matrices). The function 
>> pedigree can 
>>> set up the pedigree structure, but how do I use it in the lmer 
>>> function? I have not found any convenient example.
>>> Thanks in advance.
>>>
>>> Best regards,
>>> Jon Hallander
>>>
>>> ____________________________________________
>>>
>>> Jon Hallander
>>> Department of Forest Genetics and Plant Physiology Swedish 
>> University 
>>> of Agricultural Sciences
>>> SE-901 83 UME?
>>> SWEDEN
>>> Phone: +46 90 786 82 80
>>> Mobile: +46 70 220 08 79
>>> Fax: +46 90 786 81 65
>>> E-mail: jon.hallander at genfys.slu.se
>>> ____________________________________________
>>> ###########################################
>>>
>>> This message has been scanned by F-Secure Anti-Virus for 
>>> Mic...{{dropped}}
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> ###########################################
>>
>> This message has been scanned by F-Secure Anti-Virus for 
>> Microsoft Exchange.
>> For more information, connect to http://www.f-secure.com/
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C

The combination of some data and an aching desire for
an answer does not ensure that a reasonable answer
can be extracted from a given body of data.
- John Tukey.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
###########################################

This message has been scanned by F-Secure Anti-Virus for Mic...{{dropped}}



From afs417 at bangor.ac.uk  Wed Feb  7 16:29:06 2007
From: afs417 at bangor.ac.uk (Gibbons,James)
Date: Wed, 07 Feb 2007 15:29:06 +0000
Subject: [R-sig-ME] naive question about output from mcmcsamp v. lmer
	estimates
Message-ID: <45C9F042.7010000@bangor.ac.uk>

Dear List,

I am  attempting to estimate the quantitative trait statistic Qst for a 
colleague. Essentially I am fitting the model

X[ijk] = mu + alpha[i] + beta[ij] + gamma[k] + epsilon[ijk]

to data from measured from trees planted in an unbalanced, incomplete 
block experiment, where X[ijk] = individual observation in the ith 
provenance, ijth family and kth block; mu, alpha[i], beta[ij], and 
gamma[k] are the effects of population mean, provenance, family within 
provenance and block respectively. Qst is estimated using variance 
components for provenance and family within provenance. Because of the 
problems inherent in using point estimates to estimate Qst I would like 
to use a Bayesian approach as proposed by Waldmann et al. (Heredity 
(2005) 94, 623?629). I have implemented this model in winBugs and get 
similar summary output to fitting the following lmer model (from lme4, 
using R 2.4.1 on windows):

 >summary(lme.HT02)

Linear mixed-effects model fit by REML
Formula: HT02 ~ (1 | Block) + (1 | Provenance/Family)
    Data: quant
    AIC   BIC logLik MLdeviance REMLdeviance
  12615 12636  -6303      12611        12607
Random effects:
  Groups            Name        Variance Std.Dev.
  Family:Provenance (Intercept)   3.0350  1.7421
  Provenance        (Intercept) 191.7605 13.8478
  Block             (Intercept)  16.1534  4.0191
  Residual                      593.3983 24.3598
number of obs: 1359, groups: Family:Provenance, 335; Provenance, 18; 
Block, 14

Fixed effects:
             Estimate Std. Error t value
(Intercept)  123.497      3.549    34.8

As winBugs is very slow for this problem I was hoping to use mcmcsamp 
instead. I am being naive in thinking that I can use mcmcsamp to 
estimate posterior variance components densities? E.g.

 >colMeans(mcmcsamp(lme.HT02,10000,trans=FALSE))
(Intercept)     sigma^2   Fm:P.(In)   Prvn.(In)   Blck.(In)
   122.57740   571.59628    60.77002    61.59250    17.56870

I was expecting these numbers to be similar, although not identical, to 
the lmer output. This is all quite new ground for me so, I readily 
accept I have probably gone wrong somewhere. But where?

Thanks,

James

-- 
Dr James Gibbons
Research Lecturer in Ecological Modelling
School of the Environment & Natural Resources
University of Wales, Bangor
phone: 01248 382461
email: j.gibbons at bangor.ac.uk


-- 
Gall y neges e-bost hon, ac unrhyw atodiadau a anfonwyd gyda hi,
gynnwys deunydd cyfrinachol ac wedi eu bwriadu i'w defnyddio'n unig
gan y sawl y cawsant eu cyfeirio ato (atynt). Os ydych wedi derbyn y
neges e-bost hon trwy gamgymeriad, rhowch wybod i'r anfonwr ar
unwaith a dil?wch y neges. Os na fwriadwyd anfon y neges atoch chi,
rhaid i chi beidio ? defnyddio, cadw neu ddatgelu unrhyw wybodaeth a
gynhwysir ynddi. Mae unrhyw farn neu safbwynt yn eiddo i'r sawl a'i
hanfonodd yn unig  ac nid yw o anghenraid yn cynrychioli barn
Prifysgol Cymru, Bangor. Nid yw Prifysgol Cymru, Bangor yn gwarantu
bod y neges e-bost hon neu unrhyw atodiadau yn rhydd rhag firysau neu
100% yn ddiogel. Oni bai fod hyn wedi ei ddatgan yn uniongyrchol yn
nhestun yr e-bost, nid bwriad y neges e-bost hon yw ffurfio contract
rhwymol - mae rhestr o lofnodwyr awdurdodedig ar gael o Swyddfa
Cyllid Prifysgol Cymru, Bangor.  www.bangor.ac.uk

This email and any attachments may contain confidential mate...{{dropped}}



From ivar.herfindal at bio.ntnu.no  Wed Feb  7 17:24:36 2007
From: ivar.herfindal at bio.ntnu.no (Ivar Herfindal)
Date: Wed, 07 Feb 2007 17:24:36 +0100
Subject: [R-sig-ME] lmer, poisson family and offset variable
Message-ID: <45C9FD44.7040306@bio.ntnu.no>

Dear Mixed-Models-list

In poisson models, it can often be convenient with an offset variable, 
in order to account for known linear relationships that influence the 
counts (number of occurrences), e.g. observation time or patch size. In 
glm, (and, I hope, lmer), this is simply added as e.g. 
offset(log(exposure.time)) in the formula. This seems to work fine for 
me, and the parameter estimates, se and z-statistics seems reasonable. 
However, when I try the mcmcsamp to look at the distribution of the 
estimates, it looks horrible. Adding exposure time as fixed factor (i.e. 
log(exposure.time)) in the model instead of as an offset gives 
distributions that are reasonable and as expected. Do anyone know if 
offset is compatible with lmer and/or mcmcsamp, or can explain why the 
distribution become so weird when using exposure time as offset variable 
compared to as a fixed variable? Am I doing something completely wrong 
here?

I provide a short example below (the data is perhaps not very realistic 
in terms of values, but provide a a design close to the one I am using. 
It works as an example to show you how the distribution looks like with 
exposure time as offset or fixed variable).

Otherwise, the lme4 package works wonderful and is the package I use 
most frequent in R. Thanks a lot to the developer(s).

Sincerely

Ivar Herfindal

##
set.seed(100)
testdata <- cbind.data.frame(
    Obs=rpois(50, 20),
    gr=rep(1:10, 5),
    fixed=rnorm(50))
testdata$exp.time <- testdata$Obs - (rnorm(50, 1,1))
mod.offset <- lmer(Obs ~ offset(log(exp.time)) + fixed + (1|gr), 
data=testdata, family=poisson)
mod.offset.mcmcsamp <- mcmcsamp(mod.offset, 10000)
mod.no.offset <- lmer(Obs ~ (log(exp.time)) + fixed + (1|gr), 
data=testdata, family=poisson)
mod.no.offset.mcmcsamp <- mcmcsamp(mod.no.offset, 10000)

# histogram of parameter distribution with offset
windows()
par(mfrow=c(2,2))
for(i in 1:3)
hist(mod.offset.mcmcsamp[,i], col="gray", 
main=colnames(mod.offset.mcmcsamp)[i])

# histogram of parameter distribution without offset
windows()
par(mfrow=c(2,2))
for(i in 1:4)
hist(mod.no.offset.mcmcsamp[,i], col="gray", 
main=colnames(mod.no.offset.mcmcsamp)[i])

##
sessionInfo()
R version 2.4.1 (2006-12-18)
i386-pc-mingw32
attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  
"methods"   "base"    

other attached packages:
       lme4      Matrix     lattice
"0.9975-11"  "0.9975-8"   "0.14-16"



From bates at stat.wisc.edu  Wed Feb  7 17:26:27 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Feb 2007 10:26:27 -0600
Subject: [R-sig-ME] naive question about output from mcmcsamp v. lmer
	estimates
In-Reply-To: <45C9F042.7010000@bangor.ac.uk>
References: <45C9F042.7010000@bangor.ac.uk>
Message-ID: <40e66e0b0702070826l1e64e733ycd5633704269400b@mail.gmail.com>

On 2/7/07, Gibbons,James <afs417 at bangor.ac.uk> wrote:
> Dear List,
>
> I am  attempting to estimate the quantitative trait statistic Qst for a
> colleague. Essentially I am fitting the model
>
> X[ijk] = mu + alpha[i] + beta[ij] + gamma[k] + epsilon[ijk]
>
> to data from measured from trees planted in an unbalanced, incomplete
> block experiment, where X[ijk] = individual observation in the ith
> provenance, ijth family and kth block; mu, alpha[i], beta[ij], and
> gamma[k] are the effects of population mean, provenance, family within
> provenance and block respectively. Qst is estimated using variance
> components for provenance and family within provenance. Because of the
> problems inherent in using point estimates to estimate Qst I would like
> to use a Bayesian approach as proposed by Waldmann et al. (Heredity
> (2005) 94, 623?629). I have implemented this model in winBugs and get
> similar summary output to fitting the following lmer model (from lme4,
> using R 2.4.1 on windows):
>
>  >summary(lme.HT02)
>
> Linear mixed-effects model fit by REML
> Formula: HT02 ~ (1 | Block) + (1 | Provenance/Family)
>     Data: quant
>     AIC   BIC logLik MLdeviance REMLdeviance
>   12615 12636  -6303      12611        12607
> Random effects:
>   Groups            Name        Variance Std.Dev.
>   Family:Provenance (Intercept)   3.0350  1.7421
>   Provenance        (Intercept) 191.7605 13.8478
>   Block             (Intercept)  16.1534  4.0191
>   Residual                      593.3983 24.3598
> number of obs: 1359, groups: Family:Provenance, 335; Provenance, 18;
> Block, 14
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  123.497      3.549    34.8
>
> As winBugs is very slow for this problem I was hoping to use mcmcsamp
> instead. I am being naive in thinking that I can use mcmcsamp to
> estimate posterior variance components densities? E.g.
>
>  >colMeans(mcmcsamp(lme.HT02,10000,trans=FALSE))
> (Intercept)     sigma^2   Fm:P.(In)   Prvn.(In)   Blck.(In)
>    122.57740   571.59628    60.77002    61.59250    17.56870
>
> I was expecting these numbers to be similar, although not identical, to
> the lmer output. This is all quite new ground for me so, I readily
> accept I have probably gone wrong somewhere. But where?

As a first step I would suggest that you examine the mcmcsamp result
to see if the chains are stable.  Save the output from mcmcsamp as,
say, samp.HT02 and plot the chains as parallel time series

library(coda)
xyplot(samp.HT02)

You might also want to examine empirical density estimates derived
from the chains

densityplot(samp.HT02, plot.points = FALSE)

or normal probability plots

qqmath(samp.HT02, type = c("g", "p"))

If the distribution of the MCMC sample for a parameter is badly skewed
or otherwise unstable then  the sample mean will not be near to the
estimate.



From bates at stat.wisc.edu  Wed Feb  7 17:41:18 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Feb 2007 10:41:18 -0600
Subject: [R-sig-ME] lmer, poisson family and offset variable
In-Reply-To: <45C9FD44.7040306@bio.ntnu.no>
References: <45C9FD44.7040306@bio.ntnu.no>
Message-ID: <40e66e0b0702070841w3ab545c4kc4c65226c35841fc@mail.gmail.com>

On 2/7/07, Ivar Herfindal <ivar.herfindal at bio.ntnu.no> wrote:
> Dear Mixed-Models-list

> In poisson models, it can often be convenient with an offset variable,
> in order to account for known linear relationships that influence the
> counts (number of occurrences), e.g. observation time or patch size. In
> glm, (and, I hope, lmer), this is simply added as e.g.
> offset(log(exposure.time)) in the formula. This seems to work fine for
> me, and the parameter estimates, se and z-statistics seems reasonable.
> However, when I try the mcmcsamp to look at the distribution of the
> estimates, it looks horrible. Adding exposure time as fixed factor (i.e.
> log(exposure.time)) in the model instead of as an offset gives
> distributions that are reasonable and as expected. Do anyone know if
> offset is compatible with lmer and/or mcmcsamp, or can explain why the
> distribution become so weird when using exposure time as offset variable
> compared to as a fixed variable? Am I doing something completely wrong
> here?

> I provide a short example below (the data is perhaps not very realistic
> in terms of values, but provide a a design close to the one I am using.
> It works as an example to show you how the distribution looks like with
> exposure time as offset or fixed variable).

Thank you for providing the example.

I am not surprised that there is a problem with such an example.  I
can think of two possible causes - either I forgot to take into
account the offset when formulating the mcmcsamp or this could be
related to a generic problem with mcmcsamp for generalized linear
mixed models in which it gets stuck at particular values of the fixed
effects.  The mcmcsamp function applied to linear mixed models uses
exact sampling for three subsets of the parameters (\sigma^2, the
relative variance-covariance matrix for the random effects, and the
fixed effects and random effects sampled jointly).  I have used the
same approach in mcmcsamp applied to a generalized linear mixed model
but there is no exact sampling for the last group of parameters.  I
use a Metropolis-Hastings  method for those and sometimes it is
unsuccessful in moving the values of these parameters.

I would suggest looking at the time series plot of the MCMC sample
(see an earlier response on this list today for doing this with
library(coda); xyplot(...))  to see if the problem is the series
getting stuck.

> Otherwise, the lme4 package works wonderful and is the package I use
> most frequent in R. Thanks a lot to the developer(s).
>
> Sincerely
>
> Ivar Herfindal
>
> ##
> set.seed(100)
> testdata <- cbind.data.frame(
>     Obs=rpois(50, 20),
>     gr=rep(1:10, 5),
>     fixed=rnorm(50))
> testdata$exp.time <- testdata$Obs - (rnorm(50, 1,1))
> mod.offset <- lmer(Obs ~ offset(log(exp.time)) + fixed + (1|gr),
> data=testdata, family=poisson)
> mod.offset.mcmcsamp <- mcmcsamp(mod.offset, 10000)
> mod.no.offset <- lmer(Obs ~ (log(exp.time)) + fixed + (1|gr),
> data=testdata, family=poisson)
> mod.no.offset.mcmcsamp <- mcmcsamp(mod.no.offset, 10000)
>
> # histogram of parameter distribution with offset
> windows()
> par(mfrow=c(2,2))
> for(i in 1:3)
> hist(mod.offset.mcmcsamp[,i], col="gray",
> main=colnames(mod.offset.mcmcsamp)[i])
>
> # histogram of parameter distribution without offset
> windows()
> par(mfrow=c(2,2))
> for(i in 1:4)
> hist(mod.no.offset.mcmcsamp[,i], col="gray",
> main=colnames(mod.no.offset.mcmcsamp)[i])
>
> ##
> sessionInfo()
> R version 2.4.1 (2006-12-18)
> i386-pc-mingw32
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> "methods"   "base"
>
> other attached packages:
>        lme4      Matrix     lattice
> "0.9975-11"  "0.9975-8"   "0.14-16"
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From afs417 at bangor.ac.uk  Wed Feb  7 18:20:01 2007
From: afs417 at bangor.ac.uk (Gibbons,James)
Date: Wed, 07 Feb 2007 17:20:01 +0000
Subject: [R-sig-ME] naive question about output from mcmcsamp v. lmer
 estimates
In-Reply-To: <40e66e0b0702070826l1e64e733ycd5633704269400b@mail.gmail.com>
References: <45C9F042.7010000@bangor.ac.uk>
	<40e66e0b0702070826l1e64e733ycd5633704269400b@mail.gmail.com>
Message-ID: <45CA0A41.5020403@bangor.ac.uk>

Douglas Bates wrote:

>>
>> I was expecting these numbers to be similar, although not identical, to
>> the lmer output. This is all quite new ground for me so, I readily
>> accept I have probably gone wrong somewhere. But where?
> 
> As a first step I would suggest that you examine the mcmcsamp result
> to see if the chains are stable.  Save the output from mcmcsamp as,
> say, samp.HT02 and plot the chains as parallel time series
> 
> library(coda)
> xyplot(samp.HT02)
> 
> You might also want to examine empirical density estimates derived
> from the chains
> 
> densityplot(samp.HT02, plot.points = FALSE)
> 
> or normal probability plots
> 
> qqmath(samp.HT02, type = c("g", "p"))
> 
> If the distribution of the MCMC sample for a parameter is badly skewed
> or otherwise unstable then  the sample mean will not be near to the
> estimate.

Thanks for the quick reply. I did as you suggested, the xyplots don't 
look unusual (at least to my eyes) and

 > summary(HT02.mcmc)

Iterations = 1:10000
Thinning interval = 1
Number of chains = 1
Sample size per chain = 10000

1. Empirical mean and standard deviation for each variable,
    plus standard error of the mean:

               Mean    SD Naive SE Time-series SE
(Intercept) 122.55  2.42   0.0242        0.02434
sigma^2     570.51 25.13   0.2513        0.45181
Fm:P.(In)    61.39 12.36   0.1236        0.45281
Prvn.(In)    61.97 34.94   0.3494        0.58404
Blck.(In)    17.65 11.28   0.1128        0.27032

2. Quantiles for each variable:

                2.5%    25%    50%    75%  97.5%
(Intercept) 117.953 120.92 122.48 124.10 127.54
sigma^2     523.706 553.22 569.79 586.78 622.33
Fm:P.(In)    40.139  52.95  60.40  68.71  88.91
Prvn.(In)    19.185  38.20  53.86  76.79 150.31
Blck.(In)     3.441  10.09  15.22  22.30  46.02

doesn't suggest much skew. Running 100,000 samples also makes little 
difference.

By way of comparison some output from my winBugs implementation (100,000 
iterations, 10,000 burnin):

node	 mean	 sd	 MC error	2.5%	median	97.5%
intercept	126.6	7.819	0.4338	110.9	128.4	139.8
v.blocks	18.92	12.02	0.08299	4.772	16.16	49.36	
v.fam	3.056	6.032	0.2949	9.606E-4	0.1622	21.77
v.prov	174.9	74.91	1.05	78.63	159.1	361.7

the family posterior does look very skewed. These are with gamma priors 
for the variances and without a centering parameterization (i.e. very 
naive),

James
-- 
Dr James Gibbons
Research Lecturer in Ecological Modelling
School of the Environment & Natural Resources
University of Wales, Bangor
phone: 01248 382461
email: j.gibbons at bangor.ac.uk


-- 
Gall y neges e-bost hon, ac unrhyw atodiadau a anfonwyd gyda hi,
gynnwys deunydd cyfrinachol ac wedi eu bwriadu i'w defnyddio'n unig
gan y sawl y cawsant eu cyfeirio ato (atynt). Os ydych wedi derbyn y
neges e-bost hon trwy gamgymeriad, rhowch wybod i'r anfonwr ar
unwaith a dil?wch y neges. Os na fwriadwyd anfon y neges atoch chi,
rhaid i chi beidio ? defnyddio, cadw neu ddatgelu unrhyw wybodaeth a
gynhwysir ynddi. Mae unrhyw farn neu safbwynt yn eiddo i'r sawl a'i
hanfonodd yn unig  ac nid yw o anghenraid yn cynrychioli barn
Prifysgol Cymru, Bangor. Nid yw Prifysgol Cymru, Bangor yn gwarantu
bod y neges e-bost hon neu unrhyw atodiadau yn rhydd rhag firysau neu
100% yn ddiogel. Oni bai fod hyn wedi ei ddatgan yn uniongyrchol yn
nhestun yr e-bost, nid bwriad y neges e-bost hon yw ffurfio contract
rhwymol - mae rhestr o lofnodwyr awdurdodedig ar gael o Swyddfa
Cyllid Prifysgol Cymru, Bangor.  www.bangor.ac.uk

This email and any attachments may contain confidential mate...{{dropped}}



From Kurt.Hornik at wu-wien.ac.at  Sun Feb 11 12:46:12 2007
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Sun, 11 Feb 2007 12:46:12 +0100
Subject: [R-sig-ME] uploaded lme4_0.9975-13.tar.gz to CRAN/incoming
In-Reply-To: <40e66e0b0702061951x171702dai1afbb1072bc0c815@mail.gmail.com>
References: <40e66e0b0702061951x171702dai1afbb1072bc0c815@mail.gmail.com>
Message-ID: <17871.516.585571.756769@mithrandir.hornik.net>

>>>>> Douglas Bates writes:

> I have uploaded a new version of the lme4 package to CRAN/incoming.
> This version adds a ranef extractor (including the optional posterior
> variances) for the lmer2 model formulation and fixes a problem with
> the lmer2 fixed-effects calculation reported by Ulrich Halekoh.


Thanks, on CRAN now.

Best
-k



From c.beale at macaulay.ac.uk  Tue Feb 13 18:15:36 2007
From: c.beale at macaulay.ac.uk (Colin Beale)
Date: Tue, 13 Feb 2007 17:15:36 +0000
Subject: [R-sig-ME] modified lmer2 code problem
Message-ID: <45D1F238.1E3C.0035.0@macaulay.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070213/8d679783/attachment.pl>

From bates at stat.wisc.edu  Tue Feb 13 19:54:14 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 Feb 2007 12:54:14 -0600
Subject: [R-sig-ME] modified lmer2 code problem
In-Reply-To: <45D1F238.1E3C.0035.0@macaulay.ac.uk>
References: <45D1F238.1E3C.0035.0@macaulay.ac.uk>
Message-ID: <40e66e0b0702131054i254615d2of4188f10399fdcaf@mail.gmail.com>

On 2/13/07, Colin Beale <c.beale at macaulay.ac.uk> wrote:

> I'm trying to replicate some code I have that works in GenStat
> (http://www.vsni.co.uk/products/genstat/) using a modification of the
> lmer2 function. This modification allows a matrix to be passed directly
> to the random effects, rather than being built up from the factor
> levels. I've written a little wrapper that passes things to the modified
> version of lmer2 and called it lmerWrap (code for both the modified
> lmer2 and lmerWrap functions are at the end). I've tested it by passing
> model matrices to the function and comparing this to the lmer2 output
> and all works well. For example:

> fm1 <- lmer(Reaction ~ 1 + (1|Days) + (1|Subject), data = sleepstudy)
> fm2 <- lmerWrap(Reaction ~ 1 + (1|Days) , data = sleepstudy, mat =
> model.matrix ( ~ -1 + sleepstudy$Subject ))
> give apparently identical parameter estimates, as they should do. I've
> then added a small random number to model.matrix(~ -1 +
> sleepstudy$Subject ):

lmer or lmer2?  You mentioned lmer2 above but seem to be calling lmer here

> mat2 <- model.matrix ( ~ -1 + sleepstudy$Subject ) + runif (length
> (prod (dim (model.matrix ( ~ -1 + sleepstudy$Subject)))))
>
> and fitted a third model:
>
> fm3 <- lmerWrap (Reaction ~ 1 + (1|Days), data = sleepstudy,
>        mat = mat2)
>
> I export this "smudged" dataset to GenStat and run the code I have
> there and I get results identical to 4 significant figures, so all seems
> to be working well.
>
> However, I then try to run the code using the real dataset for which I
> want to replicate the analysis, and I get completely different results
> to that when run in GenStat, as the variance is estimated to be 0 in R:
> here's my code and output (if anyone wants the data too let me know).
>
> try2 <- lmerWrap(BirthWeight ~ m_sum + Motherrs + MotherAge
>          + MotherAge2 + Sex + birthday +  (1|Mother)
>          + (1|BirthYear), data = deer, mat = rand_mat, control =
> list(msVerbose = T,
>          niterEM = 0, gradient = FALSE))
>   0      3564.56: 0.916339 0.235294 0.436794
>   1      3563.77: 0.823463 0.263738 0.435422
>   2      3563.44: 0.838527 0.253850 0.434686
>   3      3563.39: 0.844450 0.232247 0.406417
>   4      3563.31: 0.852666 0.247116 0.405113
>   5      3563.31: 0.853871 0.244576 0.403450
>   6      3563.31: 0.852928 0.245936 0.400634
>   7      3563.30: 0.854648 0.244316 0.394544
>   8      3563.24: 0.871616 0.260905 0.198572
>   9      3562.99: 0.859845 0.253159 0.00167238
>  10      3562.96: 0.852482 0.245837 0.00164461
>  11      3562.96: 0.853410 0.247334  0.00000
>  12      3562.96: 0.853197 0.246962  0.00000
>  13      3562.96: 0.853194 0.246967  0.00000

> As I know the GenStat code recovers the correct parameters for
> simulated data, and I get similar results in the sleepstudy example
> above, I am at a loss as to what is happening here. Does anyone have any
> suggestions as to where I go from here? Is lmer struggling to find
> sensible starting values or does anyone have any other suggestions?

I'm not sure I understand the model.  As I see it there are two
variance components in the model, (1|Mother) and (1|BirthYear) so I
don't understand the 3 parameters in the optimization.

> Thanks very much,
>
> Colin
>
>
> lmerWrap <- function (formula, data = NULL, mat, ...)
> {
>     colsums <- colSums(mat)
>     matAdd <- as.factor(rep(1:(dim(mat)[2]), length = dim(mat)[1]))
>     formula <- as.formula(formula)
>     formula <- update(formula, .~. +  (1|matAdd))
>     if (!is.null(data)) dat <- as.data.frame(cbind(data, matAdd))
>     smoothMat <- Matrix(mat, sparse = T)
>     run <- lmer2a(formula = formula, data = dat, matDimI = dim(mat),
>                  rand_matI = smoothMat, ...)
> }
>
>
> lmer2a <- function (formula, data, family = gaussian, method =
> c("REML",
>     "ML", "PQL", "Laplace", "AGQ"), control = list(), start = NULL,
>     subset, weights, na.action, offset, contrasts = NULL, model =
> TRUE,
>     rand_matI, ...)
> {
>     print(t(rand_matI))
>     method <- match.arg(method)
>     formula <- as.formula(formula)
>     if (length(formula) < 3)
>         stop("formula must be a two-sided formula")
>     cv <- do.call("lmerControl", control)
>     mc <- match.call()
>     fr <- lmerFrames(mc, formula, data, contrasts)
>     Y <- fr$Y
>     X <- fr$X
>     weights <- fr$weights
>     offset <- fr$offset
>     mf <- fr$mf
>     mt <- fr$mt
>     if (is.character(family))
>         family <- get(family, mode = "function", envir =
> parent.frame())
>     if (is.function(family))
>         family <- family()
>     if (is.null(family$family)) {
>         print(family)
>         stop("'family' not recognized")
>     }
>     fltype <- mkFltype(family)
>     FL <- lmerFactorList(formula, mf, fltype)
>     cnames <- with(FL, c(lapply(Ztl, rownames), list(.fixed =
> colnames(X))))
>     nc <- with(FL, sapply(Ztl, nrow))
>     Ztl <- with(FL, .Call(Ztl_sparse, fl, Ztl))
>     nFacs <- list(length(Ztl))                 #My insert
>     for (i in 1:length(Ztl)) {                  #My insert
>       nFacs[[i]] <- dim(Ztl[[i]])              #My insert
>     }                                         #My insert
>     id <- unlist(lapply (nFacs, all.equal, dim(t(rand_matI))))    #My
> insert
>     id <- which(id == "TRUE")                                   #My
> insert
>     Ztl[[id]] <- t(rand_matI)                                  #My
> insert
>     Zt <- if (length(Ztl) == 1)
>         Ztl[[1]]
>     else do.call("rbind", Ztl)
>     fl <- FL$fl
>     if (fltype < 0) {
>         mer <- .Call(mer2_create, fl, Zt, t(X), as.double(Y),
>             method == "REML", nc, cnames, fr$offset, fr$weights)
>         if (!is.null(start))
>             mer <- setST(mer, start)
>         const <- unlist(lapply(mer at nc, function(n) rep(1:0, c(n,
>             (n * (n - 1))/2))))
>         optimRes <- nlminb(.Call(mer2_getPars, mer), function(x)
> .Call(mer2_deviance,
>             .Call(mer2_setPars, mer, x), as.integer(0)), lower =
> ifelse(const,
>             0, -Inf), control = list(trace = cv$msVerbose, iter.max =
> cv$msMaxIter))
>         if (optimRes$convergence)
>             warning(paste("nlminb failed to converge:",
> optimRes$message))
>         .Call(mer2_setPars, mer, optimRes$par)
>         .Call(mer2_update_effects, mer)
>         return(new("lmer2", mer, frame = if (model) fr$mf else
> data.frame(),
>             terms = mt, call = mc))
>     }
>     mer
> }
> environment(lmer2a) <- environment(lmer2)
>
>
> --
> Please note that the views expressed in this e-mail are those of the
> sender and do not necessarily represent the views of the Macaulay
> Institute. This email and any attachments are confidential and are
> intended solely for the use of the recipient(s) to whom they are
> addressed. If you are not the intended recipient, you should not read,
> copy, disclose or rely on any information contained in this e-mail, and
> we would ask you to contact the sender immediately and delete the email
> from your system. Thank you.
> Macaulay Institute and Associated Companies, Macaulay Drive,
> Craigiebuckler, Aberdeen, AB15 8QH.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From estrain at postoffice.utas.edu.au  Wed Feb 14 00:14:21 2007
From: estrain at postoffice.utas.edu.au (estrain at postoffice.utas.edu.au)
Date: Wed, 14 Feb 2007 10:14:21 +1100
Subject: [R-sig-ME] lmer residuals
Message-ID: <200702132314.l1DNELgs004890@corinna.its.utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070214/7e9c6e46/attachment.pl>

From c.beale at macaulay.ac.uk  Wed Feb 14 12:18:50 2007
From: c.beale at macaulay.ac.uk (Colin Beale)
Date: Wed, 14 Feb 2007 11:18:50 +0000
Subject: [R-sig-ME] modified lmer2 code problem
In-Reply-To: <40e66e0b0702131054i254615d2of4188f10399fdcaf@mail.gmail.com>
References: <45D1F238.1E3C.0035.0@macaulay.ac.uk>
	<40e66e0b0702131054i254615d2of4188f10399fdcaf@mail.gmail.com>
Message-ID: <45D2F01A.1E3C.0035.0@macaulay.ac.uk>

I meant to send this to the list too.

>>>> "Douglas Bates" <bates at stat.wisc.edu> 13/02/2007 18:54 >>>
>On 2/13/07, Colin Beale <c.beale at macaulay.ac.uk> wrote:
>
>> I'm trying to replicate some code I have that works in GenStat
>> (http://www.vsni.co.uk/products/genstat/) using a modification of
the
>> lmer2 function. This modification allows a matrix to be passed
directly
>> to the random effects, rather than being built up from the factor
>> levels. I've written a little wrapper that passes things to the
modified
>> version of lmer2 and called it lmerWrap (code for both the modified
>> lmer2 and lmerWrap functions are at the end). I've tested it by
passing
>> model matrices to the function and comparing this to the lmer2
output
>> and all works well. For example:

>> fm1 <- lmer(Reaction ~ 1 + (1|Days) + (1|Subject), data =
sleepstudy)
>> fm2 <- lmerWrap(Reaction ~ 1 + (1|Days) , data = sleepstudy, mat =
>> model.matrix ( ~ -1 + sleepstudy$Subject ))
>> give apparently identical parameter estimates, as they should do.
I've
>> then added a small random number to model.matrix(~ -1 +
>> sleepstudy$Subject ):

>lmer or lmer2?  You mentioned lmer2 above but seem to be calling lmer
here

Sorry, the modified code adapts lmer2, so:

 fm1 <- lmer2(Reaction ~ 1 + (1|Days) + (1|Subject), data =
sleepstudy)

is indeed the appropriate model to fit - it makes no practical
difference though (identical parameter estimates).

>> mat2 <- model.matrix ( ~ -1 + sleepstudy$Subject ) + runif (length
>> (prod (dim (model.matrix ( ~ -1 + sleepstudy$Subject)))))
>>
>> and fitted a third model:
>>
>> fm3 <- lmerWrap (Reaction ~ 1 + (1|Days), data = sleepstudy,
>>        mat = mat2)
>>
>> I export this "smudged" dataset to GenStat and run the code I have
>> there and I get results identical to 4 significant figures, so all
seems
>> to be working well.
>>
>> However, I then try to run the code using the real dataset for which
I
>> want to replicate the analysis, and I get completely different
results
>> to that when run in GenStat, as the variance is estimated to be 0 in
R:
>> here's my code and output (if anyone wants the data too let me
know).
>>
>> try2 <- lmerWrap(BirthWeight ~ m_sum + Motherrs + MotherAge
>>          + MotherAge2 + Sex + birthday +  (1|Mother)
>>          + (1|BirthYear), data = deer, mat = rand_mat, control =
>> list(msVerbose = T,
>>          niterEM = 0, gradient = FALSE))
>>   0      3564.56: 0.916339 0.235294 0.436794
>>   1      3563.77: 0.823463 0.263738 0.435422
>>   2      3563.44: 0.838527 0.253850 0.434686
>>   3      3563.39: 0.844450 0.232247 0.406417
>>   4      3563.31: 0.852666 0.247116 0.405113
>>   5      3563.31: 0.853871 0.244576 0.403450
>>   6      3563.31: 0.852928 0.245936 0.400634
>>   7      3563.30: 0.854648 0.244316 0.394544
>>   8      3563.24: 0.871616 0.260905 0.198572
>>   9      3562.99: 0.859845 0.253159 0.00167238
>>  10      3562.96: 0.852482 0.245837 0.00164461
>>  11      3562.96: 0.853410 0.247334  0.00000
>>  12      3562.96: 0.853197 0.246962  0.00000
>>  13      3562.96: 0.853194 0.246967  0.00000

>> As I know the GenStat code recovers the correct parameters for
>> simulated data, and I get similar results in the sleepstudy example
>> above, I am at a loss as to what is happening here. Does anyone have
any
>> suggestions as to where I go from here? Is lmer struggling to find
>> sensible starting values or does anyone have any other suggestions?

>I'm not sure I understand the model.  As I see it there are two
>variance components in the model, (1|Mother) and (1|BirthYear) so I
>don't understand the 3 parameters in the optimization.

The purpose of the modified code is to be able to pass directly a
matrix to the lmer function as a random effect. In this model there are
two 'standard' variance components and one matrix I want to use directly
- rand_mat - hence three variance components. In the working examples I
gave, fm1 is the unmodified version of lmer2 with two variance
components ((1|Days) and (1|Subject)); fm2 has one 'standard' variance
component (1|Days) and one matrix to replace the Subject one in fm1
(given by model.matrix ( ~ -1 + sleepstudy$Subject)), thus the model
fitted by the adapted lmer2 code has two variance components and is (as
it should be) identical to fm1.

In my function lmerWrap, the code 'tricks' the modified lmer2 code into
fitting a model with one extra variance component that generates a
matrix of the right dimensions in Ztl, which is then switched with the
matrix I actually want to use.

Hope that makes it clearer,

Colin

>>> "Douglas Bates" <bates at stat.wisc.edu> 13/02/2007 18:54 >>>
On 2/13/07, Colin Beale <c.beale at macaulay.ac.uk> wrote:

> I'm trying to replicate some code I have that works in GenStat
> (http://www.vsni.co.uk/products/genstat/) using a modification of
the
> lmer2 function. This modification allows a matrix to be passed
directly
> to the random effects, rather than being built up from the factor
> levels. I've written a little wrapper that passes things to the
modified
> version of lmer2 and called it lmerWrap (code for both the modified
> lmer2 and lmerWrap functions are at the end). I've tested it by
passing
> model matrices to the function and comparing this to the lmer2
output
> and all works well. For example:

> fm1 <- lmer(Reaction ~ 1 + (1|Days) + (1|Subject), data =
sleepstudy)
> fm2 <- lmerWrap(Reaction ~ 1 + (1|Days) , data = sleepstudy, mat =
> model.matrix ( ~ -1 + sleepstudy$Subject ))
> give apparently identical parameter estimates, as they should do.
I've
> then added a small random number to model.matrix(~ -1 +
> sleepstudy$Subject ):

lmer or lmer2?  You mentioned lmer2 above but seem to be calling lmer
here

> mat2 <- model.matrix ( ~ -1 + sleepstudy$Subject ) + runif (length
> (prod (dim (model.matrix ( ~ -1 + sleepstudy$Subject)))))
>
> and fitted a third model:
>
> fm3 <- lmerWrap (Reaction ~ 1 + (1|Days), data = sleepstudy,
>        mat = mat2)
>
> I export this "smudged" dataset to GenStat and run the code I have
> there and I get results identical to 4 significant figures, so all
seems
> to be working well.
>
> However, I then try to run the code using the real dataset for which
I
> want to replicate the analysis, and I get completely different
results
> to that when run in GenStat, as the variance is estimated to be 0 in
R:
> here's my code and output (if anyone wants the data too let me
know).
>
> try2 <- lmerWrap(BirthWeight ~ m_sum + Motherrs + MotherAge
>          + MotherAge2 + Sex + birthday +  (1|Mother)
>          + (1|BirthYear), data = deer, mat = rand_mat, control =
> list(msVerbose = T,
>          niterEM = 0, gradient = FALSE))
>   0      3564.56: 0.916339 0.235294 0.436794
>   1      3563.77: 0.823463 0.263738 0.435422
>   2      3563.44: 0.838527 0.253850 0.434686
>   3      3563.39: 0.844450 0.232247 0.406417
>   4      3563.31: 0.852666 0.247116 0.405113
>   5      3563.31: 0.853871 0.244576 0.403450
>   6      3563.31: 0.852928 0.245936 0.400634
>   7      3563.30: 0.854648 0.244316 0.394544
>   8      3563.24: 0.871616 0.260905 0.198572
>   9      3562.99: 0.859845 0.253159 0.00167238
>  10      3562.96: 0.852482 0.245837 0.00164461
>  11      3562.96: 0.853410 0.247334  0.00000
>  12      3562.96: 0.853197 0.246962  0.00000
>  13      3562.96: 0.853194 0.246967  0.00000

> As I know the GenStat code recovers the correct parameters for
> simulated data, and I get similar results in the sleepstudy example
> above, I am at a loss as to what is happening here. Does anyone have
any
> suggestions as to where I go from here? Is lmer struggling to find
> sensible starting values or does anyone have any other suggestions?

I'm not sure I understand the model.  As I see it there are two
variance components in the model, (1|Mother) and (1|BirthYear) so I
don't understand the 3 parameters in the optimization.

> Thanks very much,
>
> Colin
>
>
> lmerWrap <- function (formula, data = NULL, mat, ...)
> {
>     colsums <- colSums(mat)
>     matAdd <- as.factor(rep(1:(dim(mat)[2]), length = dim(mat)[1]))
>     formula <- as.formula(formula)
>     formula <- update(formula, .~. +  (1|matAdd))
>     if (!is.null(data)) dat <- as.data.frame(cbind(data, matAdd))
>     smoothMat <- Matrix(mat, sparse = T)
>     run <- lmer2a(formula = formula, data = dat, matDimI = dim(mat),
>                  rand_matI = smoothMat, ...)
> }
>
>
> lmer2a <- function (formula, data, family = gaussian, method =
> c("REML",
>     "ML", "PQL", "Laplace", "AGQ"), control = list(), start = NULL,
>     subset, weights, na.action, offset, contrasts = NULL, model =
> TRUE,
>     rand_matI, ...)
> {
>     print(t(rand_matI))
>     method <- match.arg(method)
>     formula <- as.formula(formula)
>     if (length(formula) < 3)
>         stop("formula must be a two-sided formula")
>     cv <- do.call("lmerControl", control)
>     mc <- match.call()
>     fr <- lmerFrames(mc, formula, data, contrasts)
>     Y <- fr$Y
>     X <- fr$X
>     weights <- fr$weights
>     offset <- fr$offset
>     mf <- fr$mf
>     mt <- fr$mt
>     if (is.character(family))
>         family <- get(family, mode = "function", envir =
> parent.frame())
>     if (is.function(family))
>         family <- family()
>     if (is.null(family$family)) {
>         print(family)
>         stop("'family' not recognized")
>     }
>     fltype <- mkFltype(family)
>     FL <- lmerFactorList(formula, mf, fltype)
>     cnames <- with(FL, c(lapply(Ztl, rownames), list(.fixed =
> colnames(X))))
>     nc <- with(FL, sapply(Ztl, nrow))
>     Ztl <- with(FL, .Call(Ztl_sparse, fl, Ztl))
>     nFacs <- list(length(Ztl))                 #My insert
>     for (i in 1:length(Ztl)) {                  #My insert
>       nFacs[[i]] <- dim(Ztl[[i]])              #My insert
>     }                                         #My insert
>     id <- unlist(lapply (nFacs, all.equal, dim(t(rand_matI))))   
#My
> insert
>     id <- which(id == "TRUE")                                   #My
> insert
>     Ztl[[id]] <- t(rand_matI)                                  #My
> insert
>     Zt <- if (length(Ztl) == 1)
>         Ztl[[1]]
>     else do.call("rbind", Ztl)
>     fl <- FL$fl
>     if (fltype < 0) {
>         mer <- .Call(mer2_create, fl, Zt, t(X), as.double(Y),
>             method == "REML", nc, cnames, fr$offset, fr$weights)
>         if (!is.null(start))
>             mer <- setST(mer, start)
>         const <- unlist(lapply(mer at nc, function(n) rep(1:0, c(n,
>             (n * (n - 1))/2))))
>         optimRes <- nlminb(.Call(mer2_getPars, mer), function(x)
> .Call(mer2_deviance,
>             .Call(mer2_setPars, mer, x), as.integer(0)), lower =
> ifelse(const,
>             0, -Inf), control = list(trace = cv$msVerbose, iter.max
=
> cv$msMaxIter))
>         if (optimRes$convergence)
>             warning(paste("nlminb failed to converge:",
> optimRes$message))
>         .Call(mer2_setPars, mer, optimRes$par)
>         .Call(mer2_update_effects, mer)
>         return(new("lmer2", mer, frame = if (model) fr$mf else
> data.frame(),
>             terms = mt, call = mc))
>     }
>     mer
> }
> environment(lmer2a) <- environment(lmer2)
>
>
> --
> Please note that the views expressed in this e-mail are those of the
> sender and do not necessarily represent the views of the Macaulay
> Institute. This email and any attachments are confidential and are
> intended solely for the use of the recipient(s) to whom they are
> addressed. If you are not the intended recipient, you should not
read,
> copy, disclose or rely on any information contained in this e-mail,
and
> we would ask you to contact the sender immediately and delete the
email
> from your system. Thank you.
> Macaulay Institute and Associated Companies, Macaulay Drive,
> Craigiebuckler, Aberdeen, AB15 8QH.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>

-- 
Please note that the views expressed in this e-mail are those of the
sender and do not necessarily represent the views of the Macaulay
Institute. This email and any attachments are confidential and are
intended solely for the use of the recipient(s) to whom they are
addressed. If you are not the intended recipient, you should not read,
copy, disclose or rely on any information contained in this e-mail, and
we would ask you to contact the sender immediately and delete the email
from your system. Thank you.
Macaulay Institute and Associated Companies, Macaulay Drive,
Craigiebuckler, Aberdeen, AB15 8QH.



From Wayne.Hallstrom at WorleyParsons.com  Thu Feb 15 22:55:10 2007
From: Wayne.Hallstrom at WorleyParsons.com (Hallstrom, Wayne (Calgary))
Date: Thu, 15 Feb 2007 14:55:10 -0700
Subject: [R-sig-ME] multilevel nested data in lmer models
Message-ID: <C672AABF34CB964A95F5E12A801349960FF005@cacalwpexm01.WorleyParsons.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070215/18b3dc48/attachment.pl>

From bates at stat.wisc.edu  Thu Feb 15 23:32:32 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Feb 2007 16:32:32 -0600
Subject: [R-sig-ME] multilevel nested data in lmer models
In-Reply-To: <C672AABF34CB964A95F5E12A801349960FF005@cacalwpexm01.WorleyParsons.com>
References: <C672AABF34CB964A95F5E12A801349960FF005@cacalwpexm01.WorleyParsons.com>
Message-ID: <40e66e0b0702151432x5897ddf4t694ea3b97de01f6b@mail.gmail.com>

On 2/15/07, Hallstrom, Wayne (Calgary)
<Wayne.Hallstrom at worleyparsons.com> wrote:
> I have what should be a simple question about structure of the formula
> for an lmer model. However, I can find no detailed description of how to
> write multilevel nested formulas for lmer though so I need some advice.
>
> Count data were collected at 10 subsample locations nested within each
> of 7 general locations over a 20 year period of repeated measures. At
> each of the 7 general locations there was a treatment applied partway
> through the 20 year period to 1/2 of the subsample locations.
>
> I thought running the lmer routine with the following general formula
> setup would account for the fixed effects of the treatment and the
> random effects of the nesting structure. A Quasipoisson distribution was
> used to account for over/underdispersed data.
>
> model1 <- lmer(count ~ a + (1 | b / c), dataset)
>
> This model returns an error message though - "too many groups, only the
> first is used".  I thought this formula should account for the grouped
> and nested data structure. I have used this model structure with a
> different dataset and a similar lmer model and it worked fine, nesting
> the one explanatory variable within the other in the proper arrangement
> and producing reasonable results. This time it does not work. Is there a
> different way the formula should be set up?

Could you show us the structure of the data set (use

str(dataset)

and a transcript of your attempt to fit the model?  The reason I ask
is because I don't think that error message occurs in the lme4
package.  I just did a quick check on both the R and the C sources and
I can't find it.

Also please include the output of

sessionInfo()

in your message so we know what versions of various packages you are using.

> Someone with more background in this method must have had a similar
> problem before while using this lmer routine, so hopefully another
> perosn on the list can describe/advise how to deal with this kind of
> nested data and what may be the problem here...
>
>
>
> Thank you,
>
> Wayne Hallstrom
>
> *** WORLEYPARSONS GROUP NOTICE ***
> "This email is confidential.  If you are not the intended recipient, you must not disclose  or  use the  information  contained in it.  If you have received this email in error,  please notify us immediately by return email and delete the email and any attachments. Any personal views or opinions expressed by the writer may not necessarily reflect the views or opinions of any company in the WorleyParsons Group of Companies."
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From reinhold.kliegl at gmail.com  Mon Feb 19 20:24:24 2007
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 19 Feb 2007 20:24:24 +0100
Subject: [R-sig-ME] lmer/lmer2 timing results
Message-ID: <B287E4FB-C748-436B-ADDA-2CB253F1D489@gmail.com>

Not sure whether this is still of interest. There was some interest  
about speed of lmer and lmer2. Attached are comparisons for seven  
rather complex models estimated from a set of eye fixations measured  
during reading isolated sentences  (N=29114 reading fixations; 3  
random partially crossed groups of 109 subjects, 144 sentences, and  
550 words. Note that most words occur only in one sentence but some  
words (e.g., articles) can also occur more than once per sentence.  
Also, for all subjects some of the sentences are missing. In addition  
to the three intercept variances, I always estimated subject  
variances  for three slopes with their covariances forced to zero.  
The models all use the same predictors; they differ in what subset of  
fixed effects of the full factorial is estimated. The number of model  
parameters (fixed and random effects) varies from 406 to 158.  I am  
quite amazed that there were absolutely no problems with convergence,  
etc.. (It is also nice that the results make a lot of sense, too.)

lmer2 was faster than lmer on the largest model (588 vs. 642). For  
the smaller models lmer was typically faster than lmer2  but not  
always. Given its overall speed even for such complex models, the  
timing differences are not important for these data. Most  
importantly, the estimates are incredibly similiar for all seven  
models. Details (fit statistcs and random effects for lmer and lmer2,  
but not fixed-effect estimates) are given in the attachment.

R version 2.4.1 Patched (2007-01-26 r40579)
i386-apple-darwin8.8.1, lme4 0.9975-13.

Best
Reinhold
?----
Reinhold Kliegl, Dept. of Psychology, University of Potsdam,
Karl-Liebknecht-Strasse 24-25, 14476 Potsdam, Germany
phone: +493319772868, fax: +493319772793
http://www.psych.uni-potsdam.de/people/kliegl/



----
Reinhold Kliegl, Dept. of Psychology, University of Potsdam,
Karl-Liebknecht-Strasse 24-25, 14476 Potsdam, Germany
phone: +493319772868, fax: +493319772793
http://www.psych.uni-potsdam.de/people/kliegl/





From Karl-Oskar.Lindgren at statsvet.uu.se  Tue Feb 20 06:00:37 2007
From: Karl-Oskar.Lindgren at statsvet.uu.se (Karl-Oskar Lindgren)
Date: Tue, 20 Feb 2007 06:00:37 +0100
Subject: [R-sig-ME] Estimate correlated non-nested RE?
Message-ID: <20070220060037.q4gcbl0nwwcwcw4k@webmail3.uu.se>

Dear listusers,

I have a newbie question on lmer. Currently I'm working on a  
networklike problem involving dyadic data. I would like to estimate a  
crossed-random effects model in which I take account of  the fact that  
observations are most likely correlated both across rows and columns  
of my dataset (the rows are elite representatives and the columns are  
ordinary citizens, and the dependent variable is elite-mass policy  
congruence). If I specify my model like this:

m2<-lmer(y~1+x1+x2+(1|column_id)+(1|row_id), family=binomial(link="probit"))

(where x1 and x2 are the fixed effects of interest) I get uncorrelated  
crossed-random effects. But I would want to relax the assumption  that  
the unobserved heterogeneity across rows and columns are uncorrelated.  
How do I do that? I guess this is really simple but I have failed to  
accomplish this. All examples that I have come across on the web  
either have correlation between slopes and intercepts or involves  
nested random effects. But I would like to estimate a correlation  
coefficient  between two non-nested random effects. How do I do that?

Thanks in advance (and sorry if the answer is readily available in  
some document that I have missed)

Best
Karl



From T.C.Cameron at leeds.ac.uk  Thu Feb 22 12:00:42 2007
From: T.C.Cameron at leeds.ac.uk (T.C. Cameron)
Date: Thu, 22 Feb 2007 11:00:42 -0000
Subject: [R-sig-ME] Extraordinary accuracy of mcmcsamp?
Message-ID: <A3D44A75D69AB347B6AA220F0939096566FC1C@HERMES4.ds.leeds.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070222/a54aef2c/attachment.pl>

From bates at stat.wisc.edu  Thu Feb 22 14:13:20 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 22 Feb 2007 07:13:20 -0600
Subject: [R-sig-ME] Extraordinary accuracy of mcmcsamp?
In-Reply-To: <A3D44A75D69AB347B6AA220F0939096566FC1C@HERMES4.ds.leeds.ac.uk>
References: <A3D44A75D69AB347B6AA220F0939096566FC1C@HERMES4.ds.leeds.ac.uk>
Message-ID: <40e66e0b0702220513h348ff5a2yde4c5109e9ef1289@mail.gmail.com>

On 2/22/07, T.C. Cameron <T.C.Cameron at leeds.ac.uk> wrote:
> Dear Mixed models List

> Thanks to the R help pages and contributors I have built a Generalised
> Linear mixed model with Gamma errors for a block experiment testing the
> effects of environment, food availability and harvesting strategie on
> the age at maturity in soil mite populations

> The model is

> m3<-lmer(dev~env*har*treat+dens + (1|pop/rep), family = Gamma)

> The output of the mcmcsamp function gives estimates for the fixed factor
> coefficients that are similar or identical to the model output, but
> without any SE or deviation!

The MCMC chain is stuck, which can happen with generalized linear
mixed models.  The Metropolis-Hastings algorithm that I had concocted
for MCMC sampling from GLMMs worked well on the examples that I tried
but does not work as well as I had hoped in general.

You will need to formulate your own sampler or use the z statistics.

> As I think I am performing this task to test in the coefficients are
> significantly different from zero this makes the job easy but for now,
> untrustworthy!
>
> Iterations = 1:10000
> Thinning interval = 1
> Number of chains = 1
> Sample size per chain = 10000
>
> 1. Empirical mean and standard deviation for each variable,
>    plus standard error of the mean:
>
>                        Mean            SD  Naive SE Time-series SE
> (Intercept)       2.054e-01     0.000e+00 0.000e+00      0.000e+00
> envL             -4.141e-02     0.000e+00 0.000e+00      0.000e+00
> harA              4.613e-03     0.000e+00 0.000e+00      0.000e+00
> harJ              6.227e-03     0.000e+00 0.000e+00      0.000e+00
> treatP           -5.690e-03     0.000e+00 0.000e+00      0.000e+00
> treatV           -4.232e-03     0.000e+00 0.000e+00      0.000e+00
> dens             -4.647e-01     0.000e+00 0.000e+00      0.000e+00
> envL:harA         8.621e-03     0.000e+00 0.000e+00      0.000e+00
> envL:harJ         2.384e-02     0.000e+00 0.000e+00      0.000e+00
> envL:treatP       3.398e-02     0.000e+00 0.000e+00      0.000e+00
> envL:treatV       3.414e-02     0.000e+00 0.000e+00      0.000e+00
> harA:treatP      -7.164e-03     0.000e+00 0.000e+00      0.000e+00
> harJ:treatP      -3.926e-02     0.000e+00 0.000e+00      0.000e+00
> harA:treatV       7.309e-03     0.000e+00 0.000e+00      0.000e+00
> harJ:treatV      -2.751e-03     0.000e+00 0.000e+00      0.000e+00
> envL:harA:treatP  1.845e-02     0.000e+00 0.000e+00      0.000e+00
> envL:harJ:treatP  3.589e-02     0.000e+00 0.000e+00      0.000e+00
> envL:harA:treatV -7.708e-03     0.000e+00 0.000e+00      0.000e+00
> envL:harJ:treatV -5.037e-03     0.000e+00 0.000e+00      0.000e+00
> rp:p.(In)         2.987e+01     3.800e+00 3.800e-02      3.247e-02
> pop.(In)          2.133e-13     8.073e-14 8.073e-16      1.054e-09
>
> 2. Quantiles for each variable:
>
>                        2.5%        25%        50%        75%      97.5%
> (Intercept)       2.054e-01  2.054e-01  2.054e-01  2.054e-01  2.054e-01
> envL             -4.141e-02 -4.141e-02 -4.141e-02 -4.141e-02 -4.141e-02
> harA              4.613e-03  4.613e-03  4.613e-03  4.613e-03  4.613e-03
> harJ              6.227e-03  6.227e-03  6.227e-03  6.227e-03  6.227e-03
> treatP           -5.690e-03 -5.690e-03 -5.690e-03 -5.690e-03 -5.690e-03
> treatV           -4.232e-03 -4.232e-03 -4.232e-03 -4.232e-03 -4.232e-03
> dens             -4.647e-01 -4.647e-01 -4.647e-01 -4.647e-01 -4.647e-01
> envL:harA         8.621e-03  8.621e-03  8.621e-03  8.621e-03  8.621e-03
> envL:harJ         2.384e-02  2.384e-02  2.384e-02  2.384e-02  2.384e-02
> envL:treatP       3.398e-02  3.398e-02  3.398e-02  3.398e-02  3.398e-02
> envL:treatV       3.414e-02  3.414e-02  3.414e-02  3.414e-02  3.414e-02
> harA:treatP      -7.164e-03 -7.164e-03 -7.164e-03 -7.164e-03 -7.164e-03
> harJ:treatP      -3.926e-02 -3.926e-02 -3.926e-02 -3.926e-02 -3.926e-02
> harA:treatV       7.309e-03  7.309e-03  7.309e-03  7.309e-03  7.309e-03
> harJ:treatV      -2.751e-03 -2.751e-03 -2.751e-03 -2.751e-03 -2.751e-03
> envL:harA:treatP  1.845e-02  1.845e-02  1.845e-02  1.845e-02  1.845e-02
> envL:harJ:treatP  3.589e-02  3.589e-02  3.589e-02  3.589e-02  3.589e-02
> envL:harA:treatV -7.708e-03 -7.708e-03 -7.708e-03 -7.708e-03 -7.708e-03
> envL:harJ:treatV -5.037e-03 -5.037e-03 -5.037e-03 -5.037e-03 -5.037e-03
> rp:p.(In)         2.327e+01  2.723e+01  2.959e+01  3.219e+01  3.816e+01
> pop.(In)          1.082e-13  1.585e-13  1.962e-13  2.486e-13  4.205e-13
>
>
> There does not appear to be any significant degree of skew as the
> quantiles for the fixed factors are also identical!
>
> Am I doing something wrong or is this result genuine?
>
> Data  and script below
>
> Thankyou and best wishes
>
> pop treat har rep env dev fed dens
> 4 C 0 3 H 4 1 9
> 4 C 0 3 H 4 1 9
> 4 C 0 3 H 4 1 9
> 4 C 0 3 H 4 1 9
> 4 C 0 3 H 4 1 9
> 4 C 0 4 H 4 1 8
> 4 C 0 4 H 4 1 8
> 4 C 0 4 H 4 1 8
> 4 C 0 4 H 4 1 8
> 4 C 0 4 H 4 1 8
> 4 C 0 4 H 4 1 8
> 4 C 0 4 H 4 1 8
> 4 C 0 5 H 4 1 5
> 4 C 0 5 H 4 1 5
> 4 C 0 5 H 4 1 5
> 4 C 0 6 H 4 1 9
> 4 C 0 6 H 4 1 9
> 4 C 0 6 H 4 1 9
> 4 C 0 6 H 4 1 9
> 4 C 0 6 H 4 1 9
> 4 C 0 6 H 4 1 9
> 4 C 0 7 H 4 1 4
> 4 C 0 7 H 4 1 4
> 4 C 0 7 H 4 1 4
> 4 C 0 7 H 4 1 4
> 4 C 0 1 H 5 1 9
> 4 C 0 1 H 5 1 9
> 4 C 0 1 H 5 1 9
> 4 C 0 1 H 5 1 9
> 4 C 0 1 H 5 1 9
> 4 C 0 1 H 5 1 9
> 4 C 0 2 H 5 1 4
> 4 C 0 2 H 5 1 4
> 4 C 0 2 H 5 1 4
> 4 C 0 3 H 5 1 6
> 4 C 0 3 H 5 1 6
> 4 C 0 3 H 5 1 6
> 4 C 0 3 H 5 1 6
> 4 C 0 3 H 5 1 6
> 4 C 0 4 H 5 1 13
> 4 C 0 4 H 5 1 13
> 4 C 0 4 H 5 1 13
> 4 C 0 4 H 5 1 13
> 4 C 0 4 H 5 1 13
> 4 C 0 5 H 5 1 9
> 4 C 0 5 H 5 1 9
> 4 C 0 5 H 5 1 9
> 4 C 0 6 H 5 1 10
> 4 C 0 6 H 5 1 10
> 4 C 0 6 H 5 1 10
> 4 C 0 6 H 5 1 10
> 4 C 0 6 H 5 1 10
> 4 C 0 6 H 5 1 10
> 4 C 0 6 H 5 1 10
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 7 H 5 1 16
> 4 C 0 1 H 6 1 2
> 4 C 0 1 H 6 1 2
> 4 C 0 2 H 6 1 9
> 4 C 0 2 H 6 1 9
> 4 C 0 2 H 6 1 9
> 4 C 0 2 H 6 1 9
> 4 C 0 2 H 6 1 9
> 4 C 0 2 H 6 1 9
> 4 C 0 3 H 7 1 2
> 4 C 0 3 H 7 1 2
> 4 C 0 5 H 7 1 2
> 4 C 0 5 H 7 1 2
> 4 C 0 6 L 7 0 1
> 4 C 0 7 L 7 0 1
> 4 C 0 1 L 8 1 1
> 4 C 0 3 L 8 1 2
> 4 C 0 5 L 8 1 1
> 4 C 0 2 L 9 0 1
> 4 C 0 3 L 9 0 1
> 4 C 0 5 L 9 0 2
> 4 C 0 6 L 9 0 1
> 4 C 0 2 L 10 1 2
> 4 C 0 2 L 10 1 2
> 4 C 0 3 L 10 1 4
> 4 C 0 3 L 10 1 4
> 4 C 0 4 L 10 1 3
> 4 C 0 6 L 10 1 2
> 4 C 0 1 L 11 0 3
> 4 C 0 1 L 11 0 3
> 4 C 0 2 L 11 0 1
> 4 C 0 7 L 11 0 1
> 4 C 0 5 L 12 1 5
> 4 C 0 7 L 12 1 2
> 4 C 0 4 L 13 0 1
> 4 C 0 1 L 14 1 1
> 4 C 0 1 L 15 0 1
> 4 C 0 4 L 15 0 2
> 4 C 0 1 L 16 1 3
> 4 C 0 2 L 16 1 1
> 4 C 0 5 L 16 1 1
> 4 C 0 2 L 17 0 5
> 4 C 0 2 L 17 0 5
> 4 C 0 2 L 17 0 5
> 4 C 0 2 L 17 0 5
> 4 C 0 2 L 17 0 5
> 4 C 0 2 L 18 1 2
> 4 C 0 2 L 18 1 2
> 5 C 0 3 H 4 1 9
> 5 C 0 3 H 4 1 9
> 5 C 0 3 H 4 1 9
> 5 C 0 3 H 4 1 9
> 5 C 0 4 H 4 1 11
> 5 C 0 4 H 4 1 11
> 5 C 0 4 H 4 1 11
> 5 C 0 4 H 4 1 11
> 5 C 0 4 H 4 1 11
> 5 C 0 4 H 4 1 11
> 5 C 0 4 H 4 1 11
> 5 C 0 4 H 4 1 11
> 5 C 0 1 H 5 1 16
> 5 C 0 1 H 5 1 16
> 5 C 0 1 H 5 1 16
> 5 C 0 1 H 5 1 16
> 5 C 0 1 H 5 1 16
> 5 C 0 1 H 5 1 16
> 5 C 0 2 H 5 1 5
> 5 C 0 2 H 5 1 5
> 5 C 0 2 H 5 1 5
> 5 C 0 2 H 5 1 5
> 5 C 0 3 H 5 1 6
> 5 C 0 3 H 5 1 6
> 5 C 0 3 H 5 1 6
> 5 C 0 3 H 5 1 6
> 5 C 0 4 H 5 1 7
> 5 C 0 4 H 5 1 7
> 5 C 0 4 H 5 1 7
> 5 C 0 4 H 5 1 7
> 5 C 0 4 H 5 1 7
> 5 C 0 4 H 5 1 7
> 5 C 0 4 H 5 1 7
> 5 C 0 5 H 5 1 10
> 5 C 0 5 H 5 1 10
> 5 C 0 5 H 5 1 10
> 5 C 0 5 H 5 1 10
> 5 C 0 5 H 5 1 10
> 5 C 0 6 H 5 1 18
> 5 C 0 6 H 5 1 18
> 5 C 0 6 H 5 1 18
> 5 C 0 6 H 5 1 18
> 5 C 0 6 H 5 1 18
> 5 C 0 6 H 5 1 18
> 5 C 0 6 H 5 1 18
> 5 C 0 7 H 5 1 10
> 5 C 0 7 H 5 1 10
> 5 C 0 7 H 5 1 10
> 5 C 0 7 H 5 1 10
> 5 C 0 7 H 5 1 10
> 5 C 0 4 L 6 1 3
> 5 C 0 4 L 6 1 3
> 5 C 0 4 H 7 1 1
> 5 C 0 2 L 8 1 1
> 5 C 0 5 L 8 1 1
> 5 C 0 7 L 8 1 1
> 5 C 0 3 L 9 0 1
> 5 C 0 1 L 10 1 2
> 5 C 0 2 L 10 1 3
> 5 C 0 2 L 10 1 3
> 5 C 0 2 L 10 1 3
> 5 C 0 3 L 10 1 4
> 5 C 0 3 L 10 1 4
> 5 C 0 3 L 10 1 4
> 5 C 0 4 L 10 1 1
> 5 C 0 5 L 10 1 5
> 5 C 0 5 L 10 1 5
> 5 C 0 7 L 10 1 2
> 5 C 0 1 L 11 0 1
> 5 C 0 2 L 11 0 2
> 5 C 0 3 L 11 0 2
> 5 C 0 4 L 11 0 1
> 5 C 0 6 L 11 0 2
> 5 C 0 7 L 11 0 2
> 5 C 0 1 L 12 1 6
> 5 C 0 1 L 12 1 6
> 5 C 0 1 L 12 1 6
> 5 C 0 1 L 12 1 6
> 5 C 0 1 L 12 1 6
> 5 C 0 2 L 12 1 2
> 5 C 0 2 L 12 1 2
> 5 C 0 3 L 12 1 1
> 5 C 0 4 L 12 1 3
> 5 C 0 6 L 12 1 3
> 5 C 0 7 L 12 1 1
> 5 C 0 1 L 14 1 1
> 5 C 0 3 L 14 1 1
> 5 C 0 6 L 14 1 1
> 5 C 0 1 L 15 0 2
> 5 C 0 6 L 15 0 1
> 5 C 0 7 L 16 1 1
> 10 C A 1 L 4 1 18
> 10 C A 1 H 4 1 18
> 10 C A 2 H 4 1 20
> 10 C A 2 H 4 1 20
> 10 C A 2 H 4 1 20
> 10 C A 5 H 4 1 17
> 10 C A 5 H 4 1 17
> 10 C A 6 H 4 1 20
> 10 C A 6 H 4 1 20
> 10 C A 6 H 4 1 20
> 10 C A 1 H 5 1 13
> 10 C A 1 H 5 1 13
> 10 C A 1 H 5 1 13
> 10 C A 1 H 5 1 13
> 10 C A 2 H 5 1 11
> 10 C A 2 H 5 1 11
> 10 C A 2 H 5 1 11
> 10 C A 2 H 5 1 11
> 10 C A 2 H 5 1 11
> 10 C A 2 H 5 1 11
> 10 C A 2 H 5 1 11
> 10 C A 2 H 5 1 11
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 3 H 5 1 14
> 10 C A 4 H 5 1 16
> 10 C A 4 H 5 1 16
> 10 C A 4 H 5 1 16
> 10 C A 4 H 5 1 16
> 10 C A 4 H 5 1 16
> 10 C A 4 H 5 1 16
> 10 C A 5 H 5 1 12
> 10 C A 5 H 5 1 12
> 10 C A 5 H 5 1 12
> 10 C A 5 H 5 1 12
> 10 C A 5 H 5 1 12
> 10 C A 5 H 5 1 12
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 6 H 5 1 14
> 10 C A 7 H 5 1 18
> 10 C A 7 H 5 1 18
> 10 C A 7 H 5 1 18
> 10 C A 7 H 5 1 18
> 10 C A 7 H 5 1 18
> 10 C A 7 H 5 1 18
> 10 C A 7 H 5 1 18
> 10 C A 7 H 5 1 18
> 10 C A 1 H 6 1 5
> 10 C A 1 H 6 1 5
> 10 C A 2 L 10 1 2
> 10 C A 2 L 10 1 2
> 10 C A 4 L 10 1 1
> 10 C A 5 L 10 1 3
> 10 C A 5 L 10 1 3
> 10 C A 5 L 11 0 2
> 10 C A 5 L 12 1 2
> 10 C A 5 L 13 1 2
> 10 C A 7 L 13 1 2
> 10 C A 3 L 14 0 9
> 10 C A 3 L 14 0 9
> 10 C A 4 L 14 0 6
> 10 C A 4 L 14 0 6
> 10 C A 4 L 14 0 6
> 10 C A 6 L 14 0 1
> 10 C A 7 L 14 0 6
> 10 C A 7 L 14 0 6
> 10 C A 7 L 14 0 6
> 10 C A 7 L 14 0 6
> 10 C A 4 L 15 1 3
> 10 C A 4 L 15 1 3
> 10 C A 4 L 15 1 3
> 10 C A 3 L 15 1 5
> 10 C A 3 L 15 1 5
> 10 C A 3 L 15 1 5
> 10 C A 3 L 15 1 5
> 10 C A 2 L 15 1 4
> 10 C A 2 L 15 1 4
> 10 C A 6 L 15 1 3
> 10 C A 7 L 15 1 8
> 10 C A 7 L 15 1 8
> 10 C A 6 L 16 0 2
> 10 C A 2 L 17 1 3
> 10 C A 2 L 17 1 3
> 10 C A 2 L 17 1 3
> 10 C A 3 L 17 1 1
> 10 C A 5 L 17 1 1
> 10 C A 6 L 17 1 3
> 10 C A 4 L 18 0 1
> 10 C A 4 L 19 1 3
> 10 C A 4 L 19 1 3
> 10 C A 4 L 19 1 3
> 10 C A 2 L 20 0 1
> 11 C A 3 H 4 1 19
> 11 C A 3 H 4 1 19
> 11 C A 3 H 4 1 19
> 11 C A 3 H 4 1 19
> 11 C A 3 H 4 1 19
> 11 C A 3 H 4 1 19
> 11 C A 3 H 4 1 19
> 11 C A 3 H 4 1 19
> 11 C A 4 H 4 1 5
> 11 C A 4 H 4 1 5
> 11 C A 5 H 4 1 14
> 11 C A 5 H 4 1 14
> 11 C A 5 H 4 1 14
> 11 C A 5 H 4 1 14
> 11 C A 5 H 4 1 14
> 11 C A 5 H 4 1 14
> 11 C A 6 H 4 1 16
> 11 C A 6 H 4 1 16
> 11 C A 6 H 4 1 16
> 11 C A 6 H 4 1 16
> 11 C A 6 H 4 1 16
> 11 C A 6 H 4 1 16
> 11 C A 6 H 4 1 16
> 11 C A 6 H 4 1 16
> 11 C A 7 H 4 1 20
> 11 C A 7 H 4 1 20
> 11 C A 7 H 4 1 20
> 11 C A 7 H 4 1 20
> 11 C A 1 H 5 1 12
> 11 C A 1 H 5 1 12
> 11 C A 1 H 5 1 12
> 11 C A 1 H 5 1 12
> 11 C A 1 H 5 1 12
> 11 C A 1 H 5 1 12
> 11 C A 1 H 5 1 12
> 11 C A 1 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 2 H 5 1 12
> 11 C A 3 H 5 1 4
> 11 C A 3 H 5 1 4
> 11 C A 3 H 5 1 4
> 11 C A 3 H 5 1 4
> 11 C A 4 H 5 1 9
> 11 C A 4 H 5 1 9
> 11 C A 4 H 5 1 9
> 11 C A 4 H 5 1 9
> 11 C A 4 H 5 1 9
> 11 C A 5 H 5 1 3
> 11 C A 6 H 5 1 1
> 11 C A 7 H 5 1 10
> 11 C A 7 H 5 1 10
> 11 C A 7 H 5 1 10
> 11 C A 7 H 5 1 10
> 11 C A 7 H 5 1 10
> 11 C A 7 H 5 1 10
> 11 C A 7 H 5 1 10
> 11 C A 7 H 5 1 10
> 11 C A 2 L 8 1 2
> 11 C A 3 L 8 1 1
> 11 C A 4 L 8 1 2
> 11 C A 2 L 9 0 2
> 11 C A 2 L 9 0 2
> 11 C A 3 L 9 0 1
> 11 C A 2 L 10 1 4
> 11 C A 2 L 10 1 4
> 11 C A 3 L 10 1 3
> 11 C A 3 L 10 1 3
> 11 C A 6 L 10 1 3
> 11 C A 6 L 10 1 3
> 11 C A 6 L 10 1 3
> 11 C A 1 L 11 0 3
> 11 C A 1 L 11 0 3
> 11 C A 3 L 11 0 1
> 11 C A 7 L 11 0 3
> 11 C A 7 L 11 0 3
> 11 C A 2 L 12 1 4
> 11 C A 2 L 12 1 4
> 11 C A 2 L 12 1 4
> 11 C A 2 L 12 1 4
> 11 C A 3 L 12 1 2
> 11 C A 3 L 12 1 2
> 11 C A 6 L 12 1 6
> 11 C A 6 L 12 1 6
> 11 C A 6 L 12 1 6
> 11 C A 6 L 12 1 6
> 11 C A 6 L 12 1 6
> 11 C A 4 L 13 1 1
> 11 C A 5 L 13 1 2
> 11 C A 6 L 13 1 2
> 11 C A 1 L 14 0 3
> 11 C A 1 L 14 0 3
> 11 C A 3 L 14 0 1
> 11 C A 4 L 14 0 4
> 11 C A 5 L 14 0 7
> 11 C A 5 L 14 0 7
> 11 C A 5 L 14 0 7
> 11 C A 5 L 14 0 7
> 11 C A 5 L 14 0 7
> 11 C A 5 L 14 0 7
> 11 C A 1 L 15 1 4
> 11 C A 1 L 15 1 4
> 11 C A 3 L 15 1 3
> 11 C A 3 L 15 1 3
> 11 C A 3 L 15 1 3
> 11 C A 4 L 15 1 4
> 11 C A 4 L 15 1 4
> 11 C A 4 L 15 1 4
> 11 C A 5 L 15 1 5
> 11 C A 5 L 15 1 5
> 11 C A 5 L 15 1 5
> 11 C A 5 L 15 1 5
> 11 C A 5 L 15 1 5
> 11 C A 6 L 16 0 1
> 11 C A 4 L 17 1 1
> 11 C A 5 L 17 1 1
> 11 C A 5 L 18 0 2
> 11 C A 4 L 18 0 1
> 16 C J 1 H 4 1 4
> 16 C J 1 H 4 1 4
> 16 C J 3 H 4 1 7
> 16 C J 3 H 4 1 7
> 16 C J 3 H 4 1 7
> 16 C J 3 H 4 1 7
> 16 C J 7 H 4 1 3
> 16 C J 7 H 4 1 3
> 16 C J 1 H 5 1 7
> 16 C J 1 H 5 1 7
> 16 C J 2 H 5 1 10
> 16 C J 2 H 5 1 10
> 16 C J 2 H 5 1 10
> 16 C J 2 H 5 1 10
> 16 C J 2 H 5 1 10
> 16 C J 2 H 5 1 10
> 16 C J 2 H 5 1 10
> 16 C J 2 H 5 1 10
> 16 C J 2 H 5 1 10
> 16 C J 3 H 5 1 1
> 16 C J 4 H 5 1 14
> 16 C J 4 H 5 1 14
> 16 C J 4 H 5 1 14
> 16 C J 4 H 5 1 14
> 16 C J 4 H 5 1 14
> 16 C J 4 H 5 1 14
> 16 C J 4 H 5 1 14
> 16 C J 5 H 5 1 12
> 16 C J 5 H 5 1 12
> 16 C J 5 H 5 1 12
> 16 C J 5 H 5 1 12
> 16 C J 5 H 5 1 12
> 16 C J 5 H 5 1 12
> 16 C J 6 H 5 1 10
> 16 C J 6 H 5 1 10
> 16 C J 6 H 5 1 10
> 16 C J 7 H 5 1 7
> 16 C J 7 H 5 1 7
> 16 C J 7 H 5 1 7
> 16 C J 1 L 7 0 3
> 16 C J 1 L 7 0 3
> 16 C J 2 L 7 0 1
> 16 C J 3 L 7 0 2
> 16 C J 4 L 7 0 2
> 16 C J 4 L 7 0 2
> 16 C J 2 L 8 1 3
> 16 C J 2 L 8 1 3
> 16 C J 3 L 8 1 3
> 16 C J 3 L 8 1 3
> 16 C J 4 L 8 1 2
> 16 C J 4 L 8 1 2
> 16 C J 5 L 8 1 2
> 16 C J 7 L 8 1 1
> 16 C J 5 L 9 0 1
> 16 C J 1 L 10 1 3
> 16 C J 2 L 10 1 1
> 16 C J 3 L 10 1 1
> 16 C J 5 L 10 1 5
> 16 C J 5 L 10 1 5
> 16 C J 5 L 10 1 5
> 16 C J 5 L 10 1 5
> 16 C J 6 L 10 1 5
> 16 C J 6 L 10 1 5
> 16 C J 7 L 10 1 4
> 16 C J 7 L 10 1 4
> 16 C J 1 L 12 1 4
> 16 C J 4 L 12 1 3
> 16 C J 4 L 12 1 3
> 16 C J 7 L 12 1 3
> 16 C J 7 L 12 1 3
> 16 C J 4 L 13 0 5
> 16 C J 4 L 13 0 5
> 16 C J 5 L 13 0 2
> 16 C J 6 L 13 0 5
> 16 C J 6 L 13 0 5
> 16 C J 6 L 13 0 5
> 16 C J 1 L 14 1 1
> 16 C J 2 L 14 1 4
> 16 C J 2 L 14 1 4
> 16 C J 3 L 14 1 3
> 16 C J 3 L 14 1 3
> 16 C J 4 L 14 1 2
> 16 C J 6 L 14 1 1
> 16 C J 7 L 14 1 5
> 16 C J 7 L 14 1 5
> 16 C J 7 L 14 1 5
> 16 C J 7 L 14 1 5
> 16 C J 1 L 15 0 1
> 16 C J 2 L 15 0 1
> 16 C J 6 L 15 0 1
> 16 C J 7 L 15 0 2
> 16 C J 1 L 16 1 1
> 16 C J 2 L 16 1 3
> 16 C J 2 L 16 1 3
> 16 C J 2 L 16 1 3
> 17 C J 2 H 4 1 17
> 17 C J 2 H 4 1 17
> 17 C J 2 H 4 1 17
> 17 C J 2 H 4 1 17
> 17 C J 2 H 4 1 17
> 17 C J 2 H 4 1 17
> 17 C J 2 H 4 1 17
> 17 C J 2 H 4 1 17
> 17 C J 3 H 4 1 4
> 17 C J 3 H 4 1 4
> 17 C J 3 H 4 1 4
> 17 C J 3 H 4 1 4
> 17 C J 5 H 4 1 4
> 17 C J 5 H 4 1 4
> 17 C J 5 H 4 1 4
> 17 C J 6 H 4 1 4
> 17 C J 1 H 5 1 10
> 17 C J 1 H 5 1 10
> 17 C J 1 H 5 1 10
> 17 C J 1 H 5 1 10
> 17 C J 1 H 5 1 10
> 17 C J 1 H 5 1 10
> 17 C J 1 H 5 1 10
> 17 C J 3 H 5 1 9
> 17 C J 3 H 5 1 9
> 17 C J 3 H 5 1 9
> 17 C J 3 H 5 1 9
> 17 C J 3 H 5 1 9
> 17 C J 3 H 5 1 9
> 17 C J 5 H 5 1 4
> 17 C J 5 H 5 1 4
> 17 C J 5 H 5 1 4
> 17 C J 6 H 5 1 11
> 17 C J 6 H 5 1 11
> 17 C J 6 H 5 1 11
> 17 C J 6 H 5 1 11
> 17 C J 7 H 5 1 5
> 17 C J 7 H 5 1 5
> 17 C J 7 H 5 1 5
> 17 C J 7 H 5 1 5
> 17 C J 1 L 5 0 2
> 17 C J 1 L 5 0 2
> 17 C J 1 H 6 1 1
> 17 C J 3 H 6 1 1
> 17 C J 2 L 6 1 1
> 17 C J 6 L 6 1 3
> 17 C J 6 L 6 1 3
> 17 C J 1 L 8 1 1
> 17 C J 2 L 8 1 4
> 17 C J 2 L 8 1 4
> 17 C J 3 L 8 1 3
> 17 C J 3 L 8 1 3
> 17 C J 6 L 8 1 2
> 17 C J 7 L 8 1 5
> 17 C J 7 L 8 1 5
> 17 C J 1 L 9 0 3
> 17 C J 1 L 9 0 3
> 17 C J 2 L 9 0 1
> 17 C J 5 L 9 0 3
> 17 C J 5 L 9 0 3
> 17 C J 1 L 10 1 4
> 17 C J 1 L 10 1 4
> 17 C J 1 L 10 1 4
> 17 C J 3 L 10 1 4
> 17 C J 3 L 10 1 4
> 17 C J 4 L 10 1 3
> 17 C J 7 L 10 1 1
> 17 C J 1 L 11 0 1
> 17 C J 5 L 12 1 3
> 17 C J 7 L 12 1 3
> 17 C J 7 L 12 1 3
> 17 C J 7 L 12 1 3
> 17 C J 3 L 13 0 6
> 17 C J 3 L 13 0 6
> 17 C J 5 L 13 0 3
> 17 C J 5 L 13 0 3
> 17 C J 5 L 14 1 2
> 17 C J 7 L 14 1 3
> 17 C J 7 L 14 1 3
> 22 V 0 1 H 4 1 1
> 22 V 0 3 H 4 1 1
> 22 V 0 4 H 4 1 1
> 22 V 0 1 H 5 1 6
> 22 V 0 1 H 5 1 6
> 22 V 0 1 H 5 1 6
> 22 V 0 1 H 5 1 6
> 22 V 0 2 H 5 1 5
> 22 V 0 2 H 5 1 5
> 22 V 0 3 H 5 1 13
> 22 V 0 4 H 5 1 3
> 22 V 0 4 H 5 1 3
> 22 V 0 4 H 5 1 3
> 22 V 0 5 H 5 1 10
> 22 V 0 5 H 5 1 10
> 22 V 0 5 H 5 1 10
> 22 V 0 5 H 5 1 10
> 22 V 0 5 H 5 1 10
> 22 V 0 5 H 5 1 10
> 22 V 0 6 H 5 1 16
> 22 V 0 6 H 5 1 16
> 22 V 0 6 H 5 1 16
> 22 V 0 6 H 5 1 16
> 22 V 0 6 H 5 1 16
> 22 V 0 6 H 5 1 16
> 22 V 0 6 H 5 1 16
> 22 V 0 6 H 5 1 16
> 22 V 0 6 H 5 1 16
> 22 V 0 2 H 6 1 3
> 22 V 0 2 H 6 1 3
> 22 V 0 3 H 6 1 5
> 22 V 0 3 H 6 1 5
> 22 V 0 3 H 6 1 5
> 22 V 0 3 H 6 1 5
> 22 V 0 4 L 6 1 3
> 22 V 0 4 L 6 1 3
> 22 V 0 5 L 6 1 1
> 22 V 0 2 H 7 1 2
> 22 V 0 6 L 7 0 1
> 22 V 0 2 H 8 1 1
> 22 V 0 3 L 8 0 2
> 22 V 0 3 L 8 0 2
> 22 V 0 5 L 8 0 2
> 22 V 0 6 L 8 0 1
> 22 V 0 1 L 9 1 1
> 22 V 0 1 L 10 0 1
> 22 V 0 2 L 10 0 1
> 22 V 0 3 L 10 0 5
> 22 V 0 3 L 10 0 5
> 22 V 0 5 L 10 0 3
> 22 V 0 6 L 10 0 3
> 22 V 0 6 L 10 0 3
> 22 V 0 1 L 11 1 5
> 22 V 0 1 L 11 1 5
> 22 V 0 1 L 11 1 5
> 22 V 0 2 L 11 1 1
> 22 V 0 3 L 11 1 3
> 22 V 0 3 L 11 1 3
> 22 V 0 5 L 11 1 2
> 22 V 0 6 L 11 1 2
> 22 V 0 1 L 13 1 5
> 22 V 0 1 L 13 1 5
> 22 V 0 1 L 13 1 5
> 22 V 0 1 L 13 1 5
> 22 V 0 2 L 13 1 2
> 22 V 0 2 L 13 1 2
> 22 V 0 3 L 13 1 1
> 22 V 0 2 L 14 0 1
> 22 V 0 6 L 14 0 2
> 22 V 0 2 L 15 1 3
> 22 V 0 3 L 16 0 4
> 22 V 0 3 L 16 0 4
> 23 V 0 2 H 4 1 5
> 23 V 0 2 H 4 1 5
> 23 V 0 2 H 4 1 5
> 23 V 0 2 H 4 1 5
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 4 H 4 1 13
> 23 V 0 5 H 4 1 2
> 23 V 0 1 H 5 1 11
> 23 V 0 1 H 5 1 11
> 23 V 0 1 H 5 1 11
> 23 V 0 1 H 5 1 11
> 23 V 0 1 H 5 1 11
> 23 V 0 1 H 5 1 11
> 23 V 0 1 H 5 1 11
> 23 V 0 1 H 5 1 11
> 23 V 0 2 H 5 1 10
> 23 V 0 2 H 5 1 10
> 23 V 0 2 H 5 1 10
> 23 V 0 3 H 5 1 9
> 23 V 0 3 H 5 1 9
> 23 V 0 3 H 5 1 9
> 23 V 0 3 H 5 1 9
> 23 V 0 3 H 5 1 9
> 23 V 0 5 H 5 1 14
> 23 V 0 5 H 5 1 14
> 23 V 0 5 H 5 1 14
> 23 V 0 5 H 5 1 14
> 23 V 0 5 H 5 1 14
> 23 V 0 5 H 5 1 14
> 23 V 0 5 H 5 1 14
> 23 V 0 5 H 5 1 14
> 23 V 0 6 H 5 1 9
> 23 V 0 6 H 5 1 9
> 23 V 0 6 H 5 1 9
> 23 V 0 6 H 5 1 9
> 23 V 0 6 H 5 1 9
> 23 V 0 6 H 5 1 9
> 23 V 0 7 H 5 1 14
> 23 V 0 7 H 5 1 14
> 23 V 0 7 H 5 1 14
> 23 V 0 7 H 5 1 14
> 23 V 0 7 H 5 1 14
> 23 V 0 7 H 5 1 14
> 23 V 0 7 H 5 1 14
> 23 V 0 7 H 5 1 14
> 23 V 0 1 H 6 1 1
> 23 V 0 2 H 6 1 4
> 23 V 0 2 H 6 1 4
> 23 V 0 2 H 6 1 4
> 23 V 0 6 L 6 1 1
> 23 V 0 7 L 6 1 4
> 23 V 0 7 L 6 1 4
> 23 V 0 7 L 6 1 4
> 23 V 0 2 L 7 0 2
> 23 V 0 5 L 7 0 2
> 23 V 0 7 L 7 0 3
> 23 V 0 7 L 7 0 3
> 23 V 0 7 L 7 0 3
> 23 V 0 1 L 8 0 1
> 23 V 0 2 L 8 0 3
> 23 V 0 2 L 8 0 3
> 23 V 0 3 L 8 0 2
> 23 V 0 3 L 8 0 2
> 23 V 0 7 L 8 0 1
> 23 V 0 3 L 9 1 1
> 23 V 0 4 L 9 1 2
> 23 V 0 4 L 9 1 2
> 23 V 0 1 L 10 0 3
> 23 V 0 1 L 10 0 3
> 23 V 0 1 L 10 0 3
> 23 V 0 3 L 10 0 4
> 23 V 0 6 L 10 0 2
> 23 V 0 6 L 10 0 2
> 23 V 0 7 L 10 0 1
> 23 V 0 1 L 11 1 7
> 23 V 0 1 L 11 1 7
> 23 V 0 1 L 11 1 7
> 23 V 0 2 L 11 1 4
> 23 V 0 2 L 11 1 4
> 23 V 0 2 L 11 1 4
> 23 V 0 4 L 11 1 2
> 23 V 0 5 L 11 1 2
> 23 V 0 6 L 11 1 8
> 23 V 0 6 L 11 1 8
> 23 V 0 6 L 11 1 8
> 23 V 0 6 L 11 1 8
> 23 V 0 7 L 11 1 1
> 23 V 0 1 L 12 0 1
> 23 V 0 3 L 12 0 1
> 23 V 0 5 L 12 0 2
> 23 V 0 5 L 12 0 2
> 23 V 0 1 L 13 1 3
> 23 V 0 4 L 13 1 4
> 23 V 0 4 L 13 1 4
> 23 V 0 4 L 13 1 4
> 23 V 0 5 L 13 1 7
> 23 V 0 5 L 13 1 7
> 23 V 0 5 L 13 1 7
> 23 V 0 5 L 13 1 7
> 23 V 0 5 L 13 1 7
> 23 V 0 5 L 13 1 7
> 23 V 0 6 L 13 1 3
> 23 V 0 6 L 13 1 3
> 23 V 0 7 L 15 1 2
> 23 V 0 7 L 15 1 2
> 23 V 0 5 L 16 0 1
> 28 V A 1 H 4 1 20
> 28 V A 2 H 4 1 17
> 28 V A 2 H 4 1 17
> 28 V A 2 H 4 1 17
> 28 V A 2 H 4 1 17
> 28 V A 2 H 4 1 17
> 28 V A 2 H 4 1 17
> 28 V A 2 H 4 1 17
> 28 V A 2 H 4 1 17
> 28 V A 3 H 4 1 19
> 28 V A 4 H 4 1 19
> 28 V A 4 H 4 1 19
> 28 V A 4 H 4 1 19
> 28 V A 4 H 4 1 19
> 28 V A 4 H 4 1 19
> 28 V A 4 H 4 1 19
> 28 V A 4 H 4 1 19
> 28 V A 5 H 4 1 17
> 28 V A 5 H 4 1 17
> 28 V A 5 H 4 1 17
> 28 V A 5 H 4 1 17
> 28 V A 5 H 4 1 17
> 28 V A 5 H 4 1 17
> 28 V A 7 H 4 1 16
> 28 V A 1 H 5 1 19
> 28 V A 1 H 5 1 19
> 28 V A 1 H 5 1 19
> 28 V A 1 H 5 1 19
> 28 V A 1 H 5 1 19
> 28 V A 1 H 5 1 19
> 28 V A 3 H 5 1 18
> 28 V A 3 H 5 1 18
> 28 V A 3 H 5 1 18
> 28 V A 3 H 5 1 18
> 28 V A 3 H 5 1 18
> 28 V A 3 H 5 1 18
> 28 V A 3 H 5 1 18
> 28 V A 3 H 5 1 18
> 28 V A 4 H 5 1 3
> 28 V A 5 H 5 1 4
> 28 V A 5 H 5 1 4
> 28 V A 5 H 5 1 4
> 28 V A 6 H 5 1 18
> 28 V A 6 H 5 1 18
> 28 V A 6 H 5 1 18
> 28 V A 6 H 5 1 18
> 28 V A 6 H 5 1 18
> 28 V A 6 H 5 1 18
> 28 V A 6 H 5 1 18
> 28 V A 6 H 5 1 18
> 28 V A 7 H 5 1 14
> 28 V A 7 H 5 1 14
> 28 V A 7 H 5 1 14
> 28 V A 7 H 5 1 14
> 28 V A 1 H 6 1 7
> 28 V A 1 H 6 1 7
> 28 V A 1 H 6 1 7
> 28 V A 3 H 6 1 4
> 28 V A 4 H 6 1 2
> 28 V A 6 H 6 1 4
> 28 V A 7 H 6 1 5
> 28 V A 7 H 6 1 5
> 28 V A 1 H 7 1 2
> 28 V A 3 H 7 1 2
> 28 V A 4 H 8 1 1
> 28 V A 1 L 9 0 1
> 28 V A 3 L 9 0 3
> 28 V A 3 L 9 0 3
> 28 V A 3 L 9 0 3
> 28 V A 4 L 9 0 3
> 28 V A 4 L 9 0 3
> 28 V A 6 L 9 0 2
> 28 V A 6 L 9 0 2
> 28 V A 7 L 9 0 2
> 28 V A 1 L 10 1 3
> 28 V A 2 L 10 1 3
> 28 V A 2 L 10 1 3
> 28 V A 3 L 10 1 1
> 28 V A 3 L 10 1 1
> 28 V A 4 L 10 1 1
> 28 V A 5 L 10 1 1
> 28 V A 6 L 10 1 1
> 28 V A 6 L 10 1 1
> 28 V A 6 L 10 1 1
> 28 V A 6 L 10 1 1
> 28 V A 7 L 10 1 2
> 28 V A 7 L 10 1 2
> 28 V A 3 L 11 0 1
> 28 V A 1 L 12 0 1
> 28 V A 4 L 12 0 1
> 28 V A 6 L 12 0 4
> 28 V A 6 L 12 0 4
> 28 V A 7 L 12 0 3
> 28 V A 7 L 12 0 3
> 28 V A 1 L 13 1 4
> 28 V A 1 L 13 1 4
> 28 V A 3 L 13 1 1
> 28 V A 4 L 13 1 6
> 28 V A 4 L 13 1 6
> 28 V A 5 L 13 1 1
> 28 V A 7 L 13 1 3
> 28 V A 7 L 13 1 3
> 28 V A 3 L 14 0 1
> 28 V A 1 L 15 1 1
> 28 V A 2 L 15 1 2
> 28 V A 3 L 15 1 4
> 28 V A 4 L 15 1 3
> 28 V A 4 L 15 1 3
> 28 V A 6 L 15 1 1
> 28 V A 7 L 15 1 2
> 28 V A 1 L 16 0 3
> 28 V A 3 L 16 0 1
> 28 V A 4 L 16 0 2
> 28 V A 7 L 16 0 2
> 28 V A 2 L 17 0 5
> 28 V A 2 L 17 0 5
> 28 V A 2 L 17 0 5
> 28 V A 4 L 17 0 2
> 28 V A 5 L 17 0 4
> 28 V A 2 L 18 0 1
> 28 V A 4 L 18 0 1
> 28 V A 5 L 18 0 3
> 28 V A 5 L 18 0 3
> 28 V A 5 L 18 0 3
> 28 V A 5 L 19 1 2
> 28 V A 2 L 20 0 1
> 29 V A 3 H 3 0 17
> 29 V A 1 H 4 1 13
> 29 V A 1 H 4 1 13
> 29 V A 1 H 4 1 13
> 29 V A 2 H 4 1 20
> 29 V A 2 H 4 1 20
> 29 V A 3 H 4 1 14
> 29 V A 3 H 4 1 14
> 29 V A 3 H 4 1 14
> 29 V A 3 H 4 1 14
> 29 V A 3 H 4 1 14
> 29 V A 3 H 4 1 14
> 29 V A 4 H 4 1 18
> 29 V A 4 H 4 1 18
> 29 V A 4 H 4 1 18
> 29 V A 4 H 4 1 18
> 29 V A 4 H 4 1 18
> 29 V A 5 H 4 1 13
> 29 V A 5 H 4 1 13
> 29 V A 5 H 4 1 13
> 29 V A 5 H 4 1 13
> 29 V A 5 H 4 1 13
> 29 V A 5 H 4 1 13
> 29 V A 5 H 4 1 13
> 29 V A 6 H 4 1 16
> 29 V A 6 H 4 1 16
> 29 V A 6 H 4 1 16
> 29 V A 6 H 4 1 16
> 29 V A 7 H 4 1 18
> 29 V A 7 H 4 1 18
> 29 V A 7 H 4 1 18
> 29 V A 7 H 4 1 18
> 29 V A 7 H 4 1 18
> 29 V A 7 H 4 1 18
> 29 V A 7 H 4 1 18
> 29 V A 1 H 5 1 9
> 29 V A 1 H 5 1 9
> 29 V A 1 H 5 1 9
> 29 V A 1 H 5 1 9
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 2 H 5 1 15
> 29 V A 4 H 5 1 5
> 29 V A 4 H 5 1 5
> 29 V A 4 H 5 1 5
> 29 V A 5 H 5 1 2
> 29 V A 6 H 5 1 7
> 29 V A 6 H 5 1 7
> 29 V A 6 H 5 1 7
> 29 V A 7 H 5 1 2
> 29 V A 7 H 5 1 2
> 29 V A 4 H 7 1 1
> 29 V A 2 L 7 0 1
> 29 V A 5 L 7 0 4
> 29 V A 5 L 7 0 4
> 29 V A 5 L 7 0 4
> 29 V A 4 H 8 1 1
> 29 V A 1 L 9 0 1
> 29 V A 1 L 10 1 6
> 29 V A 1 L 10 1 6
> 29 V A 1 L 10 1 6
> 29 V A 3 L 10 1 1
> 29 V A 5 L 10 1 3
> 29 V A 5 L 10 1 3
> 29 V A 6 L 10 1 5
> 29 V A 6 L 10 1 5
> 29 V A 6 L 10 1 5
> 29 V A 4 L 11 0 1
> 29 V A 2 L 12 0 2
> 29 V A 2 L 12 0 2
> 29 V A 6 L 12 0 2
> 29 V A 7 L 12 0 1
> 29 V A 1 L 13 1 2
> 29 V A 1 L 13 1 2
> 29 V A 4 L 13 1 1
> 29 V A 6 L 14 0 1
> 29 V A 4 L 15 1 2
> 29 V A 1 L 15 1 1
> 29 V A 2 L 15 1 2
> 29 V A 6 L 15 1 4
> 29 V A 6 L 15 1 4
> 29 V A 6 L 15 1 4
> 29 V A 1 L 16 0 1
> 29 V A 2 L 16 0 3
> 29 V A 3 L 16 0 4
> 29 V A 6 L 16 0 1
> 29 V A 7 L 16 0 1
> 29 V A 1 L 17 0 1
> 29 V A 7 L 17 0 8
> 29 V A 7 L 17 0 8
> 29 V A 7 L 17 0 8
> 29 V A 7 L 17 0 8
> 29 V A 7 L 17 0 8
> 29 V A 1 L 18 0 3
> 29 V A 1 L 18 0 3
> 29 V A 1 L 18 0 3
> 29 V A 3 L 18 0 5
> 29 V A 3 L 18 0 5
> 29 V A 3 L 18 0 5
> 29 V A 3 L 18 0 5
> 29 V A 3 L 18 0 5
> 29 V A 4 L 18 0 1
> 29 V A 7 L 18 0 3
> 29 V A 7 L 18 0 3
> 29 V A 3 L 19 1 2
> 29 V A 3 L 19 1 2
> 29 V A 4 L 19 1 1
> 34 V J 2 H 4 1 5
> 34 V J 2 H 4 1 5
> 34 V J 2 H 4 1 5
> 34 V J 2 H 4 1 5
> 34 V J 4 H 4 1 2
> 34 V J 4 H 4 1 2
> 34 V J 6 H 4 1 5
> 34 V J 6 H 4 1 5
> 34 V J 6 H 4 1 5
> 34 V J 1 H 5 1 11
> 34 V J 1 H 5 1 11
> 34 V J 1 H 5 1 11
> 34 V J 1 H 5 1 11
> 34 V J 1 H 5 1 11
> 34 V J 1 H 5 1 11
> 34 V J 1 H 5 1 11
> 34 V J 1 H 5 1 11
> 34 V J 2 H 5 1 10
> 34 V J 2 H 5 1 10
> 34 V J 4 H 5 1 12
> 34 V J 4 H 5 1 12
> 34 V J 4 H 5 1 12
> 34 V J 4 H 5 1 12
> 34 V J 4 H 5 1 12
> 34 V J 4 H 5 1 12
> 34 V J 4 H 5 1 12
> 34 V J 5 H 5 1 13
> 34 V J 5 H 5 1 13
> 34 V J 5 H 5 1 13
> 34 V J 5 H 5 1 13
> 34 V J 5 H 5 1 13
> 34 V J 5 H 5 1 13
> 34 V J 6 H 5 1 7
> 34 V J 6 H 5 1 7
> 34 V J 6 H 5 1 7
> 34 V J 6 H 5 1 7
> 34 V J 6 H 5 1 7
> 34 V J 6 H 5 1 7
> 34 V J 7 H 5 1 11
> 34 V J 7 H 5 1 11
> 34 V J 7 H 5 1 11
> 34 V J 7 H 5 1 11
> 34 V J 7 H 5 1 11
> 34 V J 7 H 5 1 11
> 34 V J 7 H 5 1 11
> 34 V J 2 H 6 1 1
> 34 V J 5 H 6 1 2
> 34 V J 4 L 6 1 1
> 34 V J 4 L 7 1 5
> 34 V J 4 L 7 1 5
> 34 V J 4 L 7 1 5
> 34 V J 2 L 8 1 1
> 34 V J 4 L 8 1 2
> 34 V J 5 L 8 1 1
> 34 V J 7 L 8 1 3
> 34 V J 7 L 8 1 3
> 34 V J 5 L 10 0 3
> 34 V J 5 L 10 0 3
> 34 V J 6 L 10 0 1
> 34 V J 7 L 10 0 2
> 34 V J 7 L 10 0 2
> 34 V J 1 L 11 1 4
> 34 V J 1 L 11 1 4
> 34 V J 2 L 11 1 1
> 34 V J 4 L 11 1 2
> 34 V J 4 L 11 1 2
> 34 V J 5 L 11 1 2
> 34 V J 5 L 11 1 2
> 34 V J 7 L 11 1 6
> 34 V J 7 L 11 1 6
> 34 V J 5 L 12 0 2
> 34 V J 1 L 13 1 2
> 34 V J 4 L 13 1 2
> 34 V J 4 L 13 1 2
> 34 V J 7 L 13 1 3
> 34 V J 7 L 13 1 3
> 34 V J 5 L 13 1 3
> 34 V J 2 L 14 0 2
> 34 V J 2 L 14 0 2
> 34 V J 1 L 14 0 1
> 34 V J 1 L 15 1 1
> 34 V J 2 L 15 1 6
> 34 V J 2 L 15 1 6
> 34 V J 5 L 15 1 2
> 34 V J 5 L 15 1 2
> 34 V J 6 L 15 1 1
> 34 V J 7 L 15 1 2
> 34 V J 7 L 15 1 2
> 34 V J 1 L 16 0 1
> 34 V J 5 L 16 0 1
> 34 V J 6 L 16 0 1
> 34 V J 1 L 17 1 3
> 34 V J 1 L 17 1 3
> 34 V J 2 L 17 1 3
> 34 V J 2 L 17 1 3
> 34 V J 6 L 17 1 1
> 35 V J 1 H 4 1 2
> 35 V J 2 H 4 1 2
> 35 V J 2 H 4 1 2
> 35 V J 4 H 4 1 4
> 35 V J 4 H 4 1 4
> 35 V J 4 H 4 1 4
> 35 V J 4 H 4 1 4
> 35 V J 5 H 4 1 1
> 35 V J 7 H 4 1 1
> 35 V J 1 H 5 1 11
> 35 V J 1 H 5 1 11
> 35 V J 1 H 5 1 11
> 35 V J 1 H 5 1 11
> 35 V J 1 H 5 1 11
> 35 V J 2 H 5 1 15
> 35 V J 2 H 5 1 15
> 35 V J 2 H 5 1 15
> 35 V J 2 H 5 1 15
> 35 V J 2 H 5 1 15
> 35 V J 2 H 5 1 15
> 35 V J 2 H 5 1 15
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 3 H 5 1 20
> 35 V J 4 H 5 1 10
> 35 V J 4 H 5 1 10
> 35 V J 4 H 5 1 10
> 35 V J 4 H 5 1 10
> 35 V J 4 H 5 1 10
> 35 V J 4 H 5 1 10
> 35 V J 4 H 5 1 10
> 35 V J 4 H 5 1 10
> 35 V J 5 H 5 1 6
> 35 V J 5 H 5 1 6
> 35 V J 5 H 5 1 6
> 35 V J 5 H 5 1 6
> 35 V J 5 H 5 1 6
> 35 V J 6 H 5 1 10
> 35 V J 6 H 5 1 10
> 35 V J 6 H 5 1 10
> 35 V J 6 H 5 1 10
> 35 V J 6 H 5 1 10
> 35 V J 6 H 5 1 10
> 35 V J 6 H 5 1 10
> 35 V J 7 H 5 1 14
> 35 V J 7 H 5 1 14
> 35 V J 7 H 5 1 14
> 35 V J 7 H 5 1 14
> 35 V J 7 H 5 1 14
> 35 V J 7 H 5 1 14
> 35 V J 7 H 5 1 14
> 35 V J 7 H 5 1 14
> 35 V J 1 H 6 1 1
> 35 V J 5 H 6 1 1
> 35 V J 6 H 6 1 3
> 35 V J 6 H 6 1 3
> 35 V J 6 H 6 1 3
> 35 V J 1 L 7 1 2
> 35 V J 6 L 7 1 3
> 35 V J 6 L 7 1 3
> 35 V J 2 L 8 1 2
> 35 V J 3 L 8 1 2
> 35 V J 5 L 8 1 2
> 35 V J 7 L 8 1 2
> 35 V J 1 L 10 0 3
> 35 V J 3 L 10 0 3
> 35 V J 3 L 10 0 3
> 35 V J 3 L 10 0 3
> 35 V J 2 L 10 0 3
> 35 V J 2 L 10 0 3
> 35 V J 2 L 10 0 3
> 35 V J 4 L 10 0 1
> 35 V J 5 L 10 0 2
> 35 V J 5 L 10 0 2
> 35 V J 6 L 10 0 3
> 35 V J 6 L 10 0 3
> 35 V J 4 L 11 1 4
> 35 V J 6 L 11 1 7
> 35 V J 6 L 11 1 7
> 35 V J 6 L 11 1 7
> 35 V J 6 L 11 1 7
> 35 V J 7 L 11 1 5
> 35 V J 7 L 11 1 5
> 35 V J 7 L 11 1 5
> 35 V J 4 L 12 0 1
> 35 V J 2 L 13 1 2
> 35 V J 2 L 13 1 2
> 35 V J 3 L 13 1 5
> 35 V J 3 L 13 1 5
> 35 V J 3 L 13 1 5
> 35 V J 4 L 13 1 5
> 35 V J 4 L 13 1 5
> 35 V J 4 L 13 1 5
> 35 V J 4 L 13 1 5
> 35 V J 4 L 13 1 5
> 35 V J 6 L 13 1 1
> 35 V J 2 L 14 0 2
> 35 V J 3 L 16 0 2
> 35 V J 3 L 16 0 2
> 35 V J 4 L 16 0 1
> 40 P 0 5 H 4 1 8
> 40 P 0 5 H 4 1 8
> 40 P 0 5 H 4 1 8
> 40 P 0 5 H 4 1 8
> 40 P 0 5 H 4 1 8
> 40 P 0 5 H 4 1 8
> 40 P 0 1 H 5 1 10
> 40 P 0 1 H 5 1 10
> 40 P 0 1 H 5 1 10
> 40 P 0 1 H 5 1 10
> 40 P 0 1 H 5 1 10
> 40 P 0 1 H 5 1 10
> 40 P 0 1 H 5 1 10
> 40 P 0 2 H 5 1 12
> 40 P 0 2 H 5 1 12
> 40 P 0 2 H 5 1 12
> 40 P 0 2 H 5 1 12
> 40 P 0 2 H 5 1 12
> 40 P 0 2 H 5 1 12
> 40 P 0 3 H 5 1 14
> 40 P 0 3 H 5 1 14
> 40 P 0 3 H 5 1 14
> 40 P 0 3 H 5 1 14
> 40 P 0 3 H 5 1 14
> 40 P 0 3 H 5 1 14
> 40 P 0 3 H 5 1 14
> 40 P 0 3 H 5 1 14
> 40 P 0 4 H 5 1 3
> 40 P 0 5 H 5 1 12
> 40 P 0 5 H 5 1 12
> 40 P 0 5 H 5 1 12
> 40 P 0 5 H 5 1 12
> 40 P 0 5 H 5 1 12
> 40 P 0 5 H 5 1 12
> 40 P 0 6 H 5 1 14
> 40 P 0 6 H 5 1 14
> 40 P 0 6 H 5 1 14
> 40 P 0 6 H 5 1 14
> 40 P 0 6 H 5 1 14
> 40 P 0 6 H 5 1 14
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 7 H 5 1 16
> 40 P 0 1 H 6 1 4
> 40 P 0 1 H 6 1 4
> 40 P 0 1 H 6 1 4
> 40 P 0 2 H 6 1 2
> 40 P 0 2 H 6 1 2
> 40 P 0 3 H 6 1 2
> 40 P 0 4 H 6 1 5
> 40 P 0 4 H 6 1 5
> 40 P 0 1 L 6 1 2
> 40 P 0 7 L 6 1 3
> 40 P 0 7 L 6 1 3
> 40 P 0 7 L 6 1 3
> 40 P 0 1 L 7 0 2
> 40 P 0 1 L 7 0 2
> 40 P 0 4 H 7 0 5
> 40 P 0 3 L 8 1 3
> 40 P 0 3 L 8 1 3
> 40 P 0 6 L 8 1 2
> 40 P 0 6 L 8 1 2
> 40 P 0 7 L 8 1 1
> 40 P 0 2 L 9 0 1
> 40 P 0 3 L 9 0 1
> 40 P 0 7 L 9 0 1
> 40 P 0 1 L 10 0 3
> 40 P 0 1 L 10 1 3
> 40 P 0 2 L 10 1 6
> 40 P 0 2 L 10 1 6
> 40 P 0 2 L 10 1 6
> 40 P 0 3 L 10 1 2
> 40 P 0 4 L 10 1 1
> 40 P 0 5 L 10 1 4
> 40 P 0 5 L 10 1 4
> 40 P 0 6 L 10 1 3
> 40 P 0 6 L 10 1 3
> 40 P 0 7 L 10 1 2
> 40 P 0 4 L 11 0 1
> 40 P 0 1 L 12 1 2
> 40 P 0 2 L 12 1 1
> 40 P 0 3 L 12 1 6
> 40 P 0 3 L 12 1 6
> 40 P 0 3 L 12 1 6
> 40 P 0 3 L 12 1 6
> 40 P 0 3 L 12 1 6
> 40 P 0 4 L 12 1 3
> 40 P 0 6 L 12 1 3
> 40 P 0 7 L 12 1 5
> 40 P 0 7 L 12 1 5
> 40 P 0 4 L 13 0 6
> 40 P 0 4 L 13 0 6
> 40 P 0 4 L 13 0 6
> 40 P 0 5 L 13 0 4
> 40 P 0 5 L 13 0 4
> 40 P 0 5 L 13 0 4
> 40 P 0 5 L 13 0 4
> 40 P 0 4 L 14 1 2
> 40 P 0 4 L 14 1 2
> 40 P 0 7 L 15 0 1
> 41 P 0 3 H 4 1 6
> 41 P 0 3 H 4 1 6
> 41 P 0 3 H 4 1 6
> 41 P 0 3 H 4 1 6
> 41 P 0 6 H 4 1 3
> 41 P 0 7 H 4 1 1
> 41 P 0 3 H 5 1 8
> 41 P 0 3 H 5 1 8
> 41 P 0 3 H 5 1 8
> 41 P 0 3 H 5 1 8
> 41 P 0 3 H 5 1 8
> 41 P 0 4 H 5 1 15
> 41 P 0 4 H 5 1 15
> 41 P 0 4 H 5 1 15
> 41 P 0 4 H 5 1 15
> 41 P 0 4 H 5 1 15
> 41 P 0 5 H 5 1 12
> 41 P 0 5 H 5 1 12
> 41 P 0 5 H 5 1 12
> 41 P 0 5 H 5 1 12
> 41 P 0 5 H 5 1 12
> 41 P 0 5 H 5 1 12
> 41 P 0 5 H 5 1 12
> 41 P 0 6 H 5 1 17
> 41 P 0 6 H 5 1 17
> 41 P 0 6 H 5 1 17
> 41 P 0 6 H 5 1 17
> 41 P 0 6 H 5 1 17
> 41 P 0 6 H 5 1 17
> 41 P 0 6 H 5 1 17
> 41 P 0 6 H 5 1 17
> 41 P 0 6 H 5 1 17
> 41 P 0 7 H 5 1 15
> 41 P 0 7 H 5 1 15
> 41 P 0 7 H 5 1 15
> 41 P 0 7 H 5 1 15
> 41 P 0 7 H 5 1 15
> 41 P 0 7 H 5 1 15
> 41 P 0 7 H 5 1 15
> 41 P 0 7 H 5 1 15
> 41 P 0 7 H 5 1 15
> 41 P 0 4 H 6 1 2
> 41 P 0 1 L 6 1 2
> 41 P 0 6 L 7 0 1
> 41 P 0 5 L 9 0 1
> 41 P 0 1 L 10 1 2
> 41 P 0 5 L 10 1 6
> 41 P 0 5 L 10 1 6
> 41 P 0 6 L 10 1 6
> 41 P 0 6 L 10 1 6
> 41 P 0 2 L 11 0 1
> 41 P 0 5 L 11 0 1
> 41 P 0 6 L 11 0 2
> 41 P 0 7 L 11 0 1
> 41 P 0 3 L 12 1 1
> 41 P 0 4 L 12 1 1
> 41 P 0 5 L 12 1 2
> 41 P 0 6 L 12 1 1
> 41 P 0 7 L 12 1 10
> 41 P 0 7 L 12 1 10
> 41 P 0 7 L 12 1 10
> 41 P 0 7 L 12 1 10
> 41 P 0 7 L 12 1 10
> 41 P 0 2 L 13 0 1
> 41 P 0 4 L 13 0 5
> 41 P 0 4 L 13 0 5
> 41 P 0 4 L 13 0 5
> 41 P 0 4 L 13 0 5
> 41 P 0 4 L 13 0 5
> 41 P 0 5 L 13 0 2
> 41 P 0 6 L 13 0 1
> 41 P 0 4 L 14 1 3
> 41 P 0 7 L 14 1 2
> 41 P 0 7 L 14 1 2
> 41 P 0 3 L 15 0 1
> 41 P 0 2 L 16 1 2
> 41 P 0 2 L 16 1 2
> 41 P 0 3 L 16 1 1
> 41 P 0 2 L 17 0 3
> 41 P 0 2 L 17 0 3
> 46 P A 6 H 4 1 3
> 46 P A 6 H 4 1 3
> 46 P A 6 H 4 1 3
> 46 P A 1 H 5 1 10
> 46 P A 1 H 5 1 10
> 46 P A 1 H 5 1 10
> 46 P A 1 H 5 1 10
> 46 P A 1 H 5 1 10
> 46 P A 1 H 5 1 10
> 46 P A 1 H 5 1 10
> 46 P A 1 H 5 1 10
> 46 P A 2 H 5 1 2
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 3 H 5 1 17
> 46 P A 4 H 5 1 14
> 46 P A 4 H 5 1 14
> 46 P A 4 H 5 1 14
> 46 P A 4 H 5 1 14
> 46 P A 4 H 5 1 14
> 46 P A 4 H 5 1 14
> 46 P A 4 H 5 1 14
> 46 P A 4 H 5 1 14
> 46 P A 4 H 5 1 14
> 46 P A 5 H 5 1 8
> 46 P A 5 H 5 1 8
> 46 P A 5 H 5 1 8
> 46 P A 5 H 5 1 8
> 46 P A 5 H 5 1 8
> 46 P A 5 H 5 1 8
> 46 P A 6 H 5 1 10
> 46 P A 6 H 5 1 10
> 46 P A 6 H 5 1 10
> 46 P A 6 H 5 1 10
> 46 P A 6 H 5 1 10
> 46 P A 6 H 5 1 10
> 46 P A 6 H 5 1 10
> 46 P A 6 H 5 1 10
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 7 H 5 1 16
> 46 P A 2 H 6 1 15
> 46 P A 2 H 6 1 15
> 46 P A 2 H 6 1 15
> 46 P A 2 H 6 1 15
> 46 P A 2 H 6 1 15
> 46 P A 2 H 6 1 15
> 46 P A 2 H 6 1 15
> 46 P A 2 H 6 1 15
> 46 P A 2 H 6 1 15
> 46 P A 4 H 6 1 1
> 46 P A 5 H 6 1 1
> 46 P A 7 H 6 1 1
> 46 P A 2 H 7 1 2
> 46 P A 2 H 7 1 2
> 46 P A 1 L 8 1 1
> 46 P A 5 L 8 1 3
> 46 P A 5 L 8 1 3
> 46 P A 1 L 9 0 1
> 46 P A 4 L 9 0 2
> 46 P A 4 L 9 0 2
> 46 P A 6 L 9 0 1
> 46 P A 7 L 9 0 1
> 46 P A 4 L 10 1 1
> 46 P A 5 L 10 1 1
> 46 P A 1 L 12 1 4
> 46 P A 1 L 12 1 4
> 46 P A 1 L 12 1 4
> 46 P A 1 L 12 1 4
> 46 P A 2 L 12 1 7
> 46 P A 2 L 12 1 7
> 46 P A 2 L 12 1 7
> 46 P A 2 L 12 1 7
> 46 P A 2 L 12 1 7
> 46 P A 3 L 12 1 2
> 46 P A 3 L 12 1 2
> 46 P A 4 L 12 1 6
> 46 P A 4 L 12 1 6
> 46 P A 4 L 12 1 6
> 46 P A 4 L 12 1 6
> 46 P A 6 L 12 1 2
> 46 P A 6 L 12 1 2
> 46 P A 7 L 12 1 3
> 46 P A 7 L 12 1 3
> 46 P A 7 L 12 1 3
> 46 P A 2 L 13 0 2
> 46 P A 2 L 13 0 2
> 46 P A 2 L 14 1 2
> 46 P A 3 L 14 1 3
> 46 P A 3 L 14 1 3
> 46 P A 3 L 14 1 3
> 46 P A 6 L 14 1 2
> 46 P A 1 L 15 0 3
> 46 P A 7 L 15 0 2
> 46 P A 3 L 16 1 2
> 46 P A 7 L 16 1 7
> 46 P A 7 L 16 1 7
> 46 P A 7 L 16 1 7
> 46 P A 7 L 16 1 7
> 46 P A 7 L 16 1 7
> 46 P A 3 L 17 0 1
> 47 P A 2 H 4 1 2
> 47 P A 2 H 4 1 2
> 47 P A 5 H 4 1 5
> 47 P A 5 H 4 1 5
> 47 P A 5 H 4 1 5
> 47 P A 5 H 4 1 5
> 47 P A 1 H 5 1 10
> 47 P A 1 H 5 1 10
> 47 P A 1 H 5 1 10
> 47 P A 1 H 5 1 10
> 47 P A 1 H 5 1 10
> 47 P A 1 H 5 1 10
> 47 P A 1 H 5 1 10
> 47 P A 2 H 5 1 18
> 47 P A 2 H 5 1 18
> 47 P A 2 H 5 1 18
> 47 P A 2 H 5 1 18
> 47 P A 2 H 5 1 18
> 47 P A 2 H 5 1 18
> 47 P A 2 H 5 1 18
> 47 P A 2 H 5 1 18
> 47 P A 2 H 5 1 18
> 47 P A 3 H 5 1 14
> 47 P A 3 H 5 1 14
> 47 P A 3 H 5 1 14
> 47 P A 3 H 5 1 14
> 47 P A 3 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 4 H 5 1 14
> 47 P A 5 H 5 1 10
> 47 P A 5 H 5 1 10
> 47 P A 5 H 5 1 10
> 47 P A 5 H 5 1 10
> 47 P A 5 H 5 1 10
> 47 P A 6 H 5 1 4
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 7 H 5 1 18
> 47 P A 3 H 6 1 1
> 47 P A 4 H 6 1 1
> 47 P A 3 L 7 0 1
> 47 P A 3 L 8 1 4
> 47 P A 5 L 8 1 1
> 47 P A 6 L 8 1 1
> 47 P A 2 L 9 0 1
> 47 P A 5 L 9 0 2
> 47 P A 3 L 10 1 3
> 47 P A 3 L 10 1 3
> 47 P A 5 L 10 1 4
> 47 P A 5 L 10 1 4
> 47 P A 5 L 10 1 4
> 47 P A 2 L 11 0 4
> 47 P A 2 L 11 0 4
> 47 P A 6 L 11 0 4
> 47 P A 6 L 11 0 4
> 47 P A 4 L 12 1 2
> 47 P A 5 L 12 1 3
> 47 P A 6 L 12 1 4
> 47 P A 6 L 12 1 4
> 47 P A 7 L 12 1 2
> 47 P A 4 L 13 0 1
> 47 P A 6 L 13 0 1
> 47 P A 7 L 13 0 3
> 47 P A 2 L 14 1 3
> 47 P A 4 L 14 1 2
> 47 P A 6 L 14 1 3
> 47 P A 6 L 14 1 3
> 47 P A 7 L 14 1 1
> 47 P A 7 L 15 0 5
> 47 P A 7 L 15 0 5
> 47 P A 7 L 15 0 5
> 47 P A 1 L 16 1 1
> 47 P A 2 L 16 1 2
> 47 P A 4 L 16 1 5
> 47 P A 4 L 16 1 5
> 47 P A 4 L 16 1 5
> 47 P A 4 L 16 1 5
> 47 P A 7 L 16 1 3
> 47 P A 7 L 16 1 3
> 47 P A 1 L 17 0 2
> 47 P A 1 L 17 0 2
> 47 P A 4 L 17 0 1
> 47 P A 7 L 17 0 1
> 47 P A 4 L 18 1 2
> 47 P A 7 L 19 0 1
> 47 P A 1 L 20 1 1
> 52 P J 4 H 5 1 2
> 52 P J 4 H 5 1 2
> 52 P J 6 H 5 1 3
> 52 P J 6 H 5 1 3
> 52 P J 7 H 5 1 3
> 52 P J 1 H 6 1 6
> 52 P J 1 H 6 1 6
> 52 P J 1 H 6 1 6
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 2 H 6 1 17
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 3 H 6 1 13
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 4 H 6 1 16
> 52 P J 5 H 6 1 12
> 52 P J 5 H 6 1 12
> 52 P J 5 H 6 1 12
> 52 P J 6 H 6 1 10
> 52 P J 6 H 6 1 10
> 52 P J 6 H 6 1 10
> 52 P J 6 H 6 1 10
> 52 P J 6 H 6 1 10
> 52 P J 6 H 6 1 10
> 52 P J 6 H 6 1 10
> 52 P J 7 H 6 1 8
> 52 P J 7 H 6 1 8
> 52 P J 7 H 6 1 8
> 52 P J 7 H 6 1 8
> 52 P J 7 H 6 1 8
> 52 P J 7 H 6 1 8
> 52 P J 7 H 6 1 8
> 52 P J 3 H 7 1 1
> 52 P J 6 H 7 1 1
> 52 P J 5 L 7 1 2
> 52 P J 5 L 7 1 2
> 52 P J 7 L 7 1 1
> 52 P J 1 L 8 0 1
> 52 P J 2 L 9 1 1
> 52 P J 5 L 9 1 1
> 52 P J 7 L 9 1 2
> 52 P J 3 L 10 0 2
> 52 P J 3 L 10 0 2
> 52 P J 4 L 10 0 3
> 52 P J 7 L 10 0 1
> 52 P J 1 L 11 1 2
> 52 P J 3 L 11 1 2
> 52 P J 3 L 11 1 2
> 52 P J 4 L 11 1 2
> 52 P J 5 L 11 1 4
> 52 P J 5 L 11 1 4
> 52 P J 5 L 11 1 4
> 52 P J 5 L 11 1 4
> 52 P J 6 L 11 1 2
> 52 P J 6 L 11 1 2
> 52 P J 7 L 11 1 2
> 52 P J 2 L 12 0 1
> 52 P J 3 L 12 0 2
> 52 P J 3 L 12 0 2
> 52 P J 5 L 12 0 1
> 52 P J 6 L 12 0 1
> 52 P J 1 L 13 1 2
> 52 P J 2 L 13 1 1
> 52 P J 4 L 13 1 1
> 52 P J 5 L 13 1 6
> 52 P J 5 L 13 1 6
> 52 P J 6 L 13 1 2
> 52 P J 6 L 13 1 2
> 52 P J 1 L 14 0 3
> 52 P J 2 L 14 0 3
> 52 P J 4 L 14 0 1
> 52 P J 1 L 15 1 1
> 52 P J 2 L 15 1 2
> 52 P J 2 L 15 1 2
> 52 P J 3 L 15 1 1
> 52 P J 6 L 15 1 4
> 52 P J 6 L 15 1 4
> 52 P J 6 L 15 1 4
> 52 P J 1 L 16 0 1
> 52 P J 4 L 16 0 1
> 52 P J 2 L 17 1 1
> 53 P J 7 H 5 1 1
> 53 P J 1 H 6 1 11
> 53 P J 1 H 6 1 11
> 53 P J 1 H 6 1 11
> 53 P J 1 H 6 1 11
> 53 P J 1 H 6 1 11
> 53 P J 1 H 6 1 11
> 53 P J 1 H 6 1 11
> 53 P J 2 H 6 1 10
> 53 P J 2 H 6 1 10
> 53 P J 2 H 6 1 10
> 53 P J 2 H 6 1 10
> 53 P J 2 H 6 1 10
> 53 P J 2 H 6 1 10
> 53 P J 2 H 6 1 10
> 53 P J 3 H 6 1 14
> 53 P J 3 H 6 1 14
> 53 P J 3 H 6 1 14
> 53 P J 3 H 6 1 14
> 53 P J 3 H 6 1 14
> 53 P J 3 H 6 1 14
> 53 P J 4 H 6 1 18
> 53 P J 4 H 6 1 18
> 53 P J 4 H 6 1 18
> 53 P J 4 H 6 1 18
> 53 P J 4 H 6 1 18
> 53 P J 4 H 6 1 18
> 53 P J 4 H 6 1 18
> 53 P J 4 H 6 1 18
> 53 P J 4 H 6 1 18
> 53 P J 5 H 6 1 17
> 53 P J 5 H 6 1 17
> 53 P J 5 H 6 1 17
> 53 P J 5 H 6 1 17
> 53 P J 6 H 6 1 11
> 53 P J 6 H 6 1 11
> 53 P J 6 H 6 1 11
> 53 P J 6 H 6 1 11
> 53 P J 6 H 6 1 11
> 53 P J 6 H 6 1 11
> 53 P J 7 H 6 1 9
> 53 P J 7 H 6 1 9
> 53 P J 7 H 6 1 9
> 53 P J 7 H 6 1 9
> 53 P J 7 H 6 1 9
> 53 P J 7 H 6 1 9
> 53 P J 1 H 7 1 2
> 53 P J 2 H 7 1 4
> 53 P J 2 H 7 1 4
> 53 P J 3 H 7 1 1
> 53 P J 4 H 7 1 1
> 53 P J 1 L 7 1 4
> 53 P J 1 L 7 1 4
> 53 P J 2 L 7 1 1
> 53 P J 1 L 9 1 2
> 53 P J 2 L 9 1 3
> 53 P J 2 L 9 1 3
> 53 P J 2 L 9 1 3
> 53 P J 4 L 9 1 2
> 53 P J 7 L 9 1 4
> 53 P J 7 L 9 1 4
> 53 P J 7 L 9 1 4
> 53 P J 2 L 10 0 2
> 53 P J 3 L 10 0 1
> 53 P J 1 L 11 1 4
> 53 P J 3 L 11 1 6
> 53 P J 3 L 11 1 6
> 53 P J 5 L 11 1 2
> 53 P J 7 L 11 1 6
> 53 P J 7 L 11 1 6
> 53 P J 7 L 11 1 6
> 53 P J 4 L 12 0 3
> 53 P J 5 L 12 0 4
> 53 P J 5 L 12 0 4
> 53 P J 1 L 13 1 3
> 53 P J 3 L 13 1 1
> 53 P J 4 L 13 1 3
> 53 P J 4 L 13 1 3
> 53 P J 1 L 14 0 2
> 53 P J 3 L 14 0 5
> 53 P J 3 L 14 0 5
> 53 P J 3 L 14 0 5
> 53 P J 3 L 14 0 5
> 53 P J 5 L 14 0 4
> 53 P J 5 L 14 0 4
> 53 P J 5 L 14 0 4
> 53 P J 6 L 14 0 4
> 53 P J 6 L 14 0 4
> 53 P J 6 L 14 0 4
> 53 P J 6 L 14 0 4
> 53 P J 3 L 15 1 1
> 53 P J 5 L 15 1 3
> 53 P J 5 L 15 1 3
> 53 P J 6 L 15 1 4
> 53 P J 6 L 17 1 6
> 53 P J 6 L 18 0 1
>
>
> library(MASS)
> library(repeated)
> library(rmutil)
> library(lme4)
> test<-read.table("...........\\test.txt",header=T)
> attach(test)
> names(test)
> sapply(test, class)
> test$pop <- factor(test$pop)
> test$rep <- factor(test$rep)
>
> m3<-lmer(dev~env*har*treat+dens + (1|pop/rep), family = Gamma)
>
> summary(m3)
> anova(m3)
>
> m3.means<-colMeans(mcmcsamp(m3,10000,trans=FALSE))
> m3.mcmc<-mcmcsamp(m3,10000,trans=FALSE)
> qqmath(m3.mcmc)
> library(coda)
> summary(m3.mcmc)
>
>
>
> ........................................................................
> ............
> Dr Tom C Cameron
> Genetics, Ecology and Evolution
> IICB, University of Leeds
> Leeds, UK
> Office: +44 (0)113 343 2837
> Lab:    +44 (0)113 343 2854
> Fax:    +44 (0)113 343 2835
>
>
> Email: t.c.cameron at leeds.ac.uk
> Webpage: click here
> <http://www.fbs.leeds.ac.uk/staff/profile.php?tag=Cameron_TC>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Wayne.Hallstrom at WorleyParsons.com  Fri Feb 23 03:14:14 2007
From: Wayne.Hallstrom at WorleyParsons.com (Hallstrom, Wayne (Calgary))
Date: Thu, 22 Feb 2007 19:14:14 -0700
Subject: [R-sig-ME] multilevel nested data in lmer models
Message-ID: <C672AABF34CB964A95F5E12A801349961326FF@cacalwpexm01.WorleyParsons.com>

OK finally back to work on this.
I am using:

R-2.4.0-win32.exe

Package: lme4
Version: 0.9975-10
Date: 2006-12-01

I was having trouble with the program not recognizing the appropriate
structure in the dataset, and claiming that there were 'too many
groups'. I followed the advice of D M Bates to assess the dataset
structure, and found the following:
> str(FEall)
'data.frame':   1230 obs. of  20 variables:
 $ InOut      : Factor w/ 2 levels "in","out": 1 1 1 1 1 1 1 1 1 1 ...
 $ FenceEnd   : Factor w/ 7 levels "1e","1w","de",..: 1 1 1 1 1 1 1 1 1
1 ...
 $ FEsectn    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ MIT_UNMIT  : Factor w/ 2 levels "mit","unmit": 1 1 1 1 1 1 1 1 1 1
...
 $ YEAR       : int  1985 1986 1987 1988 1989 1990 1991 1992 1993 1994
...
 $ BLAC       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ COUG       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ COYO       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ deer       : int  NA NA NA NA NA NA NA 1 NA NA ...
 $ ELK        : int  NA NA NA NA NA NA 1 NA NA NA ...
 $ GRIZ       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ LYNX       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ MOOS       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ SHEE       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ WOLF       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ WOLV       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ carn.coyo  : int  0 0 0 0 0 0 0 0 0 0 ...
 $ carn       : int  0 0 0 0 0 0 0 0 0 0 ...
 $ ung        : int  0 0 0 0 0 0 1 1 0 0 ...
 $ Grand.Total: int  0 0 0 0 0 0 1 1 0 0 ...

>From this I noted that FEsectn was not registered as a factor and so I
changed it into one, after which the model structure worked fine. Seems
that problem is solved.
> FEsection<-factor(FEsectn)
> m0 <- lmer(carn ~ 1 + (1|FenceEnd/FEsection/MIT_UNMIT),
family=quasipoisson(link = "log"))
> m00 <- lmer(ung ~ 1 + (1|FenceEnd/FEsection/MIT_UNMIT),
family=quasipoisson(link = "log"))
> summary(m0)@AICtab
     AIC      BIC   logLik deviance
 313.374 333.8330 -152.687  305.374


However, I now have the problem that some of the groups in this model
definition are formed by the treatment variable MIT_UNMIT (fencing or no
fencing on highway to exclude wildlife). I need some advice on how to
deal with this in the model, for example is this model m1 valid? I have
the idea maybe it is not, but how else do I go about finding the effect
coefficient for the MIT_UNMIT variable, or the FEsection variable?

m1 <- lmer(carn ~ MIT_UNMIT + (1|FenceEnd/FEsection/MIT_UNMIT),
family=quasipoisson(link = "log"))

To give some context, 5 segments of wildlife exclusion fencing were
built over a period of 25 years, some contiguous and some not, resulting
in 7 different fence ends existing at different times. All roadkill was
recorded both before and after the fencing. Yearly wildlife roadkills
counts were assigned by UTM map location to each of 10 500m long
segments around each fence end, with 5 of these 'inside' the fence and 5
'outside'. I am trying to determine whether fence ends constitute a
significant source of wildlife mortality postfencing by examining
intersegment and pre/post treatment distribution of roadkill at each
fence end versus that afterwards.

I had examined this using an MSExcel-based G-test with STP since that
method allowed exact definition of how wildlife mortality differs
between highway segments, and it allowed me to subsequently match the
results to the local topography etc. I had run tests for each fence end
individually, but then it was suggested that I try this method in order
to generalize the results of overall FenceEnd effect(it was 4 with a FE
effect and 3 without...). As I am not very familiar with the LMER
procedure and am a bit stuck here I could use some advice.

Thank you for your time,
Wayne Hallstrom



======================================

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Thursday, February 15, 2007 3:33 PM
To: Hallstrom, Wayne (Calgary)
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] multilevel nested data in lmer models

On 2/15/07, Hallstrom, Wayne (Calgary)
<Wayne.Hallstrom at worleyparsons.com> wrote:
> I have what should be a simple question about structure of the formula

> for an lmer model. However, I can find no detailed description of how 
> to write multilevel nested formulas for lmer though so I need some
advice.
>
> Count data were collected at 10 subsample locations nested within each

> of 7 general locations over a 20 year period of repeated measures. At 
> each of the 7 general locations there was a treatment applied partway 
> through the 20 year period to 1/2 of the subsample locations.
>
> I thought running the lmer routine with the following general formula 
> setup would account for the fixed effects of the treatment and the 
> random effects of the nesting structure. A Quasipoisson distribution 
> was used to account for over/underdispersed data.
>
> model1 <- lmer(count ~ a + (1 | b / c), dataset)
>
> This model returns an error message though - "too many groups, only 
> the first is used".  I thought this formula should account for the 
> grouped and nested data structure. I have used this model structure 
> with a different dataset and a similar lmer model and it worked fine, 
> nesting the one explanatory variable within the other in the proper 
> arrangement and producing reasonable results. This time it does not 
> work. Is there a different way the formula should be set up?

Could you show us the structure of the data set (use

str(dataset)

and a transcript of your attempt to fit the model?  The reason I ask is
because I don't think that error message occurs in the lme4 package.  I
just did a quick check on both the R and the C sources and I can't find
it.

Also please include the output of

sessionInfo()

in your message so we know what versions of various packages you are
using.

> Someone with more background in this method must have had a similar 
> problem before while using this lmer routine, so hopefully another 
> perosn on the list can describe/advise how to deal with this kind of 
> nested data and what may be the problem here...
>
>
>
> Thank you,
>
> Wayne Hallstrom
>
> *** WORLEYPARSONS GROUP NOTICE ***
> "This email is confidential.  If you are not the intended recipient,
you must not disclose  or  use the  information  contained in it.  If
you have received this email in error,  please notify us immediately by
return email and delete the email and any attachments. Any personal
views or opinions expressed by the writer may not necessarily reflect
the views or opinions of any company in the WorleyParsons Group of
Companies."
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
*** WORLEYPARSONS GROUP NOTICE ***
"This email is confidential.  If you are not the intended recipient, you must not disclose  or  use the  information  contained in it.  If you have received this email in error,  please notify us immediately by return email and delete the email and any attachments. Any personal views or opinions expressed by the writer may not necessarily reflect the views or opinions of any company in the WorleyParsons Group of Companies."



From ahimsa at camposarceiz.com  Thu Mar  1 10:18:06 2007
From: ahimsa at camposarceiz.com (ahimsa campos-arceiz)
Date: Thu, 1 Mar 2007 18:18:06 +0900
Subject: [R-sig-ME] no df of freedom to test the effect of an interaction in
	(lmer) mixed-model
Message-ID: <45e920ef0703010118g569fab06q34a39eb7907b9aba@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070301/80d44895/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Thu Mar  1 22:00:22 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 2 Mar 2007 08:00:22 +1100
Subject: [R-sig-ME] no df of freedom to test the effect of an
	interaction in (lmer) mixed-model
In-Reply-To: <45e920ef0703010118g569fab06q34a39eb7907b9aba@mail.gmail.com>
References: <45e920ef0703010118g569fab06q34a39eb7907b9aba@mail.gmail.com>
Message-ID: <20070301210022.GM19982@ms.unimelb.edu.au>

Hi Ahimsa,

I think that the problem is that model red1, as you have expressed it,
doesn't resepct heredity (in the context of linear models).  It
contains a three-way interaction term (S:C:t) but omits one of the
underlying two-way interaction terms (S:t).

Generally, bad things can happen when you do this, including a lack of
invariance to location and scale transformations.

In this case I'm guessing that lmer is just changing the
parameterization.  Here's an analogy.  (S:t) previously played the
role of one of the margins for (S:C:t), so lmer only reported one
level of (S:C:t), as the other level is aliased with the margin.  If
you eliminate the margin then lmer has to report two levels.  It's
like the difference between:

> x <- factor(c(1,1,2,2))
> y <- 1:4     
> lm(y ~ x)

Call:
lm(formula = y ~ x)

Coefficients:
(Intercept)           x2  
        1.5          2.0  

> lm(y ~ x - 1)

Call:
lm(formula = y ~ x - 1)

Coefficients:
 x1   x2  
1.5  3.5  

> 

Notice that even though we removed the intercept, R still used two
degrees of freedom to express the model.

I hope that this helps,

Andrew




On Thu, Mar 01, 2007 at 06:18:06PM +0900, ahimsa campos-arceiz wrote:
> Dear sig-mixed-models list-members,
> 
> I placed this question before on R-help main list, but I think this forum is
> more appropriate. I will reformulate the question though:
> 
> I have a model such as:
> full <- lmer(y ~ S*C*t + (S*t | id), method="ML")   # both S and C are
> factors with two levels each
> 
> First I want to test the effect of the interaction S:t. I fit the following
> reduced models:
> red1 <- lmer(y ~ S*C*t - S:t + (S*t | id), method="ML")   # excluding S:t
> from the fixed effects, and
> red2 <- lmer(y ~ S*C*t + (S + t | id), method="ML")   # excluding S:t:id
> from the random effects
> 
> then:
> anova(full, red1, red2)
> 
>             Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
> red2     14 10525.0 10614.5 -5248.5
> full       18 10493.7 10608.8 -5228.8 39.346  4  5.908e-08 ***
> red1     18 10493.7 10608.8 -5228.8  0.000   0
> 
> The problem is that there is no degree of freedom to see differences between
> full and red1
> 
> When looking at the fixed effects of both models:
> 
> 1. full model
> Fixed effects:
>                                   Estimate Std. Error t value
> (Intercept)                6.7822267  0.1475245   45.97
> S                           -0.4902659  0.0814779   -6.02
> C                           -0.2428243  0.2142228   -1.13
> t                             0.0122836  0.0015711    7.82
> S:C                         0.3716986   0.1232596    3.02
> S:t                         -0.0001985  0.0028627   -0.07
> C:t                         -0.0056198  0.0023020   -2.44
> S:C:t                      0.0022598  0.0040779    0.55
> 
> 2. red1 model
> Fixed effects:
>                               Estimate Std. Error t value
> (Intercept)              6.7822722  0.1483886   45.71
> S                         -0.4902454  0.0816564   -6.00
> C                         - 0.2428498  0.2154232   -1.13
> t                           0.0122829  0.0015684    7.83
> S:C                      0.3716582  0.1235135    3.01
> C:t                       -0.0056161  0.0022982   -2.44
> S:C1:t                  - 0.0001986  0.0028619   -0.07
> S:C2:t                   0.0020583  0.0029032    0.71
> 
> red1 model is analyzing the interaction S:C:t using both levels of C so that
> the result is one more factor, and therefore no degree of freedom left to
> compare with the full model.
> 
> Can anybody suggest how should I test the effect of S:t??
> 
> 
> Thank you very much for any feedback!!
> 
> Ahimsa
> 
> 
> For a more comprehensible explanation of the data you can check my previous
> post ( http://tolstoy.newcastle.edu.au/R/e2/help/07/03/11468.html). Below
> there is toi data and script.
> 
> **********************************************************************************************************
> 
> library(lme4)
> 
> # dataset
> A <- as.factor(rep(1:2, each=600))
> id <- as.factor(rep(1:6, each=200))
> S <- as.factor(rep(1:2, each=100, times=6))
> R <- as.factor(rep(1:10, each = 10, times = 12))
> t <- rep(c(2,4,6,8,10,12,14,16,18,20), times=120)
> y <- rnorm(1200, mean=100, sd=25)
> dummy.df <- data.frame(A,id,S,R,t,y)
> summary(dummy.df)
> str(dummy.df)
> 
> full.model <- lmer(y ~ A*S*t + (S*t|id), dummy.df, method="ML")
> summary(full.model)
> 
> red.model1 <- lmer(y ~ A*S*t - S:t + (S*t|id), dummy.df, method="ML")
> summary(red.model1)
> 
> red.model2 <- lmer(y ~ A*S*t + (S+t|id), dummy.df , method="ML")
> summary(red.model2)
> anova (full.model, red.model1, red.model2)
> 
> -- 
> ahimsa campos-arceiz
> www.camposarceiz.com
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From florian.bw at gmail.com  Fri Mar  2 01:20:43 2007
From: florian.bw at gmail.com (florian bw)
Date: Fri, 2 Mar 2007 11:20:43 +1100
Subject: [R-sig-ME] large dataset - lmer2 vector size specified is too large
Message-ID: <9098b3c70703011620m66f09219ra1804663256f05e4@mail.gmail.com>

Hi,

I want to fit mRNA expression data to sex.

I have the following values:
  expr:     expression value (for gene/person)
  affyID:   gene ID
  cephID: person ID
  sex

with 224 genes and 195 persons, therefore 43,680 data points. Both
with the nlme and the lme4 package i get errors. I tried it with R 2.4
and 2.5, and the newest package versions.

I have a 64-machine with 8GB RAM. Is the dataset simply too large? I
already cut it down and would actually be glad if I could do the
calculation with ~ 8000x250 data points.

Thank you for your help.

Florian Breitwieser
UNSW Sydney
Systems Biolgy

---------------------------------------------------

> sessionInfo()
R version 2.5.0 Under development (unstable) (2007-02-26 r40806)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"

other attached packages:
       lme4      Matrix     lattice        nlme
"0.9975-13" "0.9975-11"   "0.14-16"    "3.1-79"


-----------------------------------------------------

> library(lme4)
> sex.lme <- lmer2(expr ~ affyID*sex + affyID|cephID,data=ds.n)
Error in vector("double", length) : vector size specified is too large


------------------------------------------------------

> library(nlme)
> sex.lme <- lme(expr ~ affyID*sex,random=~affyID|cephID,data=ds.n)
Error: cannot allocate vector of size 4.7 Gb
> gc()
          used (Mb) gc trigger   (Mb)   max used   (Mb)
Ncells  829281 44.3    5714627  305.2   10890793  581.7
Vcells 1881820 14.4 1034019068 7889.0 1103035467 8415.5


Another time I got the following message:
> sex.lme <- lme(expr ~ affyID*sex,random=~affyID|cephID,data=ds.n)

 *** caught segfault ***
address (nil), cause 'unknown'

Traceback:
 1: lme.formula(expr ~ affyID * sex, random = ~affyID | cephID, data = ds.n)
 2: lme(expr ~ affyID * sex, random = ~affyID | cephID, data = ds.n)



From bates at stat.wisc.edu  Fri Mar  2 15:36:05 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 Mar 2007 08:36:05 -0600
Subject: [R-sig-ME] large dataset - lmer2 vector size specified is too
	large
In-Reply-To: <9098b3c70703011620m66f09219ra1804663256f05e4@mail.gmail.com>
References: <9098b3c70703011620m66f09219ra1804663256f05e4@mail.gmail.com>
Message-ID: <40e66e0b0703020636p7cc52164oa81f85affab517c0@mail.gmail.com>

On 3/1/07, florian bw <florian.bw at gmail.com> wrote:
> Hi,
>
> I want to fit mRNA expression data to sex.
>
> I have the following values:
>   expr:     expression value (for gene/person)
>   affyID:   gene ID
>   cephID: person ID
>   sex
>
> with 224 genes and 195 persons, therefore 43,680 data points. Both
> with the nlme and the lme4 package i get errors. I tried it with R 2.4
> and 2.5, and the newest package versions.
>
> I have a 64-machine with 8GB RAM. Is the dataset simply too large? I
> already cut it down and would actually be glad if I could do the
> calculation with ~ 8000x250 data points.
>
> Thank you for your help.
>
> Florian Breitwieser
> UNSW Sydney
> Systems Biolgy
>
> ---------------------------------------------------
>
> > sessionInfo()
> R version 2.5.0 Under development (unstable) (2007-02-26 r40806)
> x86_64-unknown-linux-gnu
>
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
>
> other attached packages:
>        lme4      Matrix     lattice        nlme
> "0.9975-13" "0.9975-11"   "0.14-16"    "3.1-79"
>
>
> -----------------------------------------------------
>
> > library(lme4)
> > sex.lme <- lmer2(expr ~ affyID*sex + affyID|cephID,data=ds.n)
> Error in vector("double", length) : vector size specified is too large
>

Do you know that this formula is equivalent to

expr ~ 1 + (affyID*sex|cephID)

I think you meant

expr ~ affyID * sex + (affyID|cephID)

but even that formula means that you are estimating 448 fixed effects
for which the model matrix is of size 448 * 43680 * 8 bytes (about 150
MB).  In addition you are attempting to estimate

(224 * (224 + 1))/2 = 25200

variance-covariance components from 43680 observations.

I suggest that you reconsider the model specification.  The readers of
this list will be able to help with the interpretation of the model
specification if you want to discuss it.

>
> ------------------------------------------------------
>
> > library(nlme)
> > sex.lme <- lme(expr ~ affyID*sex,random=~affyID|cephID,data=ds.n)
> Error: cannot allocate vector of size 4.7 Gb
> > gc()
>           used (Mb) gc trigger   (Mb)   max used   (Mb)
> Ncells  829281 44.3    5714627  305.2   10890793  581.7
> Vcells 1881820 14.4 1034019068 7889.0 1103035467 8415.5
>
>
> Another time I got the following message:
> > sex.lme <- lme(expr ~ affyID*sex,random=~affyID|cephID,data=ds.n)
>
>  *** caught segfault ***
> address (nil), cause 'unknown'
>
> Traceback:
>  1: lme.formula(expr ~ affyID * sex, random = ~affyID | cephID, data = ds.n)
>  2: lme(expr ~ affyID * sex, random = ~affyID | cephID, data = ds.n)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From gregor.gorjanc at bfro.uni-lj.si  Fri Mar  2 16:07:20 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Fri, 2 Mar 2007 15:07:20 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?large_dataset_-_lmer2_vector_size_specified_?=
	=?utf-8?q?is_too=09large?=
References: <9098b3c70703011620m66f09219ra1804663256f05e4@mail.gmail.com>
	<40e66e0b0703020636p7cc52164oa81f85affab517c0@mail.gmail.com>
Message-ID: <loom.20070302T160517-105@post.gmane.org>

Douglas Bates <bates at ...> writes:
...
> but even that formula means that you are estimating 448 fixed effects
> for which the model matrix is of size 448 * 43680 * 8 bytes (about 150
> MB).  In addition you are attempting to estimate

Not directly related. Is it really necessary to build model matrix i.e. X. 
Building X'X directly would be more efficient i.e. only 448 * 448 * 8 bytes.

Gregor



From bates at stat.wisc.edu  Fri Mar  2 18:13:54 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 Mar 2007 11:13:54 -0600
Subject: [R-sig-ME] large dataset - lmer2 vector size specified is too
	large
In-Reply-To: <loom.20070302T160517-105@post.gmane.org>
References: <9098b3c70703011620m66f09219ra1804663256f05e4@mail.gmail.com>
	<40e66e0b0703020636p7cc52164oa81f85affab517c0@mail.gmail.com>
	<loom.20070302T160517-105@post.gmane.org>
Message-ID: <40e66e0b0703020913y21cccd05rcc94805337399b08@mail.gmail.com>

On 3/2/07, Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si> wrote:
> Douglas Bates <bates at ...> writes:
> ...
> > but even that formula means that you are estimating 448 fixed effects
> > for which the model matrix is of size 448 * 43680 * 8 bytes (about 150
> > MB).  In addition you are attempting to estimate
>
> Not directly related. Is it really necessary to build model matrix i.e. X.

Necessary? For linear mixed models no - for generalized linear mixed
models yes (think of how the IRLS algorithm works).

Easy to change?  Regretably, no.

> Building X'X directly would be more efficient i.e. only 448 * 448 * 8 bytes.

That wouldn't be sufficient.  As described in the "Implementation"
vignette in the lme4 package, the calculations in lmer2 are based on
the matrix A which is [Z X -y]'[Z X -y].  You can't use just X'X - you
need the crossproducts of all the columns of Z, X and y.

The matrix A is potentially huge but sparse.  Assuming that Florian
really does want to try to estimate a model with (affyID|cephID) then
Z has 224 * 195 = 43680 columns.

In lmer Z'Z is stored as a sparse matrix.  In lmer2 A is stored as a
sparse matrix.

Generating A as a sparse matrix directly from the data or directly
from a model.frame object would result in considerable savings in
memory usage but doing so is far from trivial.  Most useRs are not
aware (nor need they be aware) of the complexity of the operations
involved in taking a linear model formula and a data specification
(and all the arguments like subset, na.action, offset, weights, ...
that are expected to be available in model-fitting functions) and
creating first a model.frame then a model.matrix.  It is one of those
things that "just works" but is incredibly complicated beneath the
surface.

Even the first stage (producing a model frame) is complicated - to the
extent that Thomas Lumley has a report on "The Standard Non-standard
Evaluation in R" dealing with how arguments are evaluated in the
model.frame function.

There are various approaches that could be taken to building A as a
sparse matrix directly from the model specification and a model frame.
 Probably the easiest to implement would be to use the existing
model.matrix code to produce horizontal sections of [Z X -y] and
accumulate A from these sections.  This is still far from trivial
because you either need two passes (one to determine the positions of
the nonzeros and one to evaluate them) or you have to somehow update
the structure of A on the fly.  The other thing that gets tricky is
that the columns of X may change from section to section because not
all levels of a factor may be used in a given section.  It would be
necessary to ensure that the columns from all sections are aligned.



From josh.wills at gmail.com  Fri Mar  2 18:39:10 2007
From: josh.wills at gmail.com (Josh Wills)
Date: Fri, 2 Mar 2007 11:39:10 -0600
Subject: [R-sig-ME] large dataset - lmer2 vector size specified is too
	large
In-Reply-To: <40e66e0b0703020913y21cccd05rcc94805337399b08@mail.gmail.com>
References: <9098b3c70703011620m66f09219ra1804663256f05e4@mail.gmail.com>
	<40e66e0b0703020636p7cc52164oa81f85affab517c0@mail.gmail.com>
	<loom.20070302T160517-105@post.gmane.org>
	<40e66e0b0703020913y21cccd05rcc94805337399b08@mail.gmail.com>
Message-ID: <93c55bfe0703020939x582ebe00od9508e93cc3b005@mail.gmail.com>

I can tell you the general approach I took when I worked on it a
couple of years ago-- admittedly, I think my application was
relatively simple, I'm not sure that my impl supported all of the
possible formula expressions, but I did my best.

I started with the SparseM package, which defines a matrix.csc class
(column-oriented storage) which is made up of three vectors- one of
length V ("values") containing the actual non-zero values for the
matrix, another of length V ("indices") containing the row indices of
the non-zero values, and another equal to the number of columns in the
original (non-sparse) matrix (plus 1, IIRC) which specified the
offsets for where the different columns started in the indices vector.
 This is a pretty common sparse matrix format, I can give an example
if it helps clarify the notion.

My general problem was one where I needed to solve a logistic
regression with millions of rows and one numerical variable (usually
representing a price) and a number of categorical variables (stored as
factors) that could potentially have thousands of distinct level
values.  The real challenge came when model.matrix would blow out the
factors into sets of 0/1 columns, the vast majority of which were
equal to zero.  Figuring out a way to get the factors directly into
the (sparse) representation of the model.matrix w/o blowing them out
into 0s and 1s first was the real trick, and I used two R functions to
do it- tapply to get the counts for the different levels of the factor
(so I knew how many 0/1 columns were to be generated for that factor)
and order to sort get back the indices that would sort the factor.  At
that point (at least for a simple example) I was essentially done--
the order command gave me back the indices of the rows that would need
to be non-zero for the 0/1 column corresponding to each level of the
factor, and the tapply gave me the counts so I would know how many
non-zeros were in each column.  Assuming an intercept term was
present, I ignored the first level of the factor, and inserted the
indices from order and the counts for tapply into the sparse matrix
structure for the rest.  That was essentially it- the running time was
O(n log n) due to the order call, but I only used storage space
proportional to twice the size of the original data frame, instead of
1000s of times larger than the original data frame, and once I could
hand the finished sparse model.matrix structure to the Cholesky
algorithm in SparseM, it ran very quickly.

Now there are a number of simplifications here- first, I did a call to
model.frame to use the matrix structure it created to parse the
formulas, and while I did incorporate features to handle interaction
terms between factors or numerics and factors or if the formula
omitted the intercept for some reason, I'm sure my implementation was
not robust enough for every expression that could be made with
formulas, but that was why I wanted to work with you guys in the first
place.  But I did write it entirely in R (leveraging the fortran impls
from SparseM) and it generated the correct results on the test sets I
compared it to (generally ones that regular glm could handle.)

Best,
Josh

On 3/2/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 3/2/07, Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si> wrote:
> > Douglas Bates <bates at ...> writes:
> > ...
> > > but even that formula means that you are estimating 448 fixed effects
> > > for which the model matrix is of size 448 * 43680 * 8 bytes (about 150
> > > MB).  In addition you are attempting to estimate
> >
> > Not directly related. Is it really necessary to build model matrix i.e. X.
>
> Necessary? For linear mixed models no - for generalized linear mixed
> models yes (think of how the IRLS algorithm works).
>
> Easy to change?  Regretably, no.
>
> > Building X'X directly would be more efficient i.e. only 448 * 448 * 8 bytes.
>
> That wouldn't be sufficient.  As described in the "Implementation"
> vignette in the lme4 package, the calculations in lmer2 are based on
> the matrix A which is [Z X -y]'[Z X -y].  You can't use just X'X - you
> need the crossproducts of all the columns of Z, X and y.
>
> The matrix A is potentially huge but sparse.  Assuming that Florian
> really does want to try to estimate a model with (affyID|cephID) then
> Z has 224 * 195 = 43680 columns.
>
> In lmer Z'Z is stored as a sparse matrix.  In lmer2 A is stored as a
> sparse matrix.
>
> Generating A as a sparse matrix directly from the data or directly
> from a model.frame object would result in considerable savings in
> memory usage but doing so is far from trivial.  Most useRs are not
> aware (nor need they be aware) of the complexity of the operations
> involved in taking a linear model formula and a data specification
> (and all the arguments like subset, na.action, offset, weights, ...
> that are expected to be available in model-fitting functions) and
> creating first a model.frame then a model.matrix.  It is one of those
> things that "just works" but is incredibly complicated beneath the
> surface.
>
> Even the first stage (producing a model frame) is complicated - to the
> extent that Thomas Lumley has a report on "The Standard Non-standard
> Evaluation in R" dealing with how arguments are evaluated in the
> model.frame function.
>
> There are various approaches that could be taken to building A as a
> sparse matrix directly from the model specification and a model frame.
>  Probably the easiest to implement would be to use the existing
> model.matrix code to produce horizontal sections of [Z X -y] and
> accumulate A from these sections.  This is still far from trivial
> because you either need two passes (one to determine the positions of
> the nonzeros and one to evaluate them) or you have to somehow update
> the structure of A on the fly.  The other thing that gets tricky is
> that the columns of X may change from section to section because not
> all levels of a factor may be used in a given section.  It would be
> necessary to ensure that the columns from all sections are aligned.
>



From gregor.gorjanc at bfro.uni-lj.si  Fri Mar  2 19:15:18 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Fri, 02 Mar 2007 19:15:18 +0100
Subject: [R-sig-ME] large dataset - lmer2 vector size specified is too
 large
In-Reply-To: <40e66e0b0703020913y21cccd05rcc94805337399b08@mail.gmail.com>
References: <9098b3c70703011620m66f09219ra1804663256f05e4@mail.gmail.com>	
	<40e66e0b0703020636p7cc52164oa81f85affab517c0@mail.gmail.com>	
	<loom.20070302T160517-105@post.gmane.org>
	<40e66e0b0703020913y21cccd05rcc94805337399b08@mail.gmail.com>
Message-ID: <45E869B6.4090302@bfro.uni-lj.si>

Hi,

Douglas Bates wrote:
> On 3/2/07, Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si> wrote:
>> Douglas Bates <bates at ...> writes:
>> ...
>> > but even that formula means that you are estimating 448 fixed effects
>> > for which the model matrix is of size 448 * 43680 * 8 bytes (about 150
>> > MB).  In addition you are attempting to estimate
>>
>> Not directly related. Is it really necessary to build model matrix
>> i.e. X.
> 
> Necessary? For linear mixed models no - for generalized linear mixed
> models yes (think of how the IRLS algorithm works).

hmm, I will need to learn IRLS first :(

>> Building X'X directly would be more efficient i.e. only 448 * 448 * 8
>> bytes.
...
> Generating A as a sparse matrix directly from the data or directly
> from a model.frame object would result in considerable savings in
> memory usage but doing so is far from trivial.  Most useRs are not
> aware (nor need they be aware) of the complexity of the operations
...

You are right! I am far from being aware how complex this things are and
I am very grateful to you for providing us with such a great software
for nothing. However, I know that in animal breeding (AB) settings A can
really be huge, mainly due to hugeness of Z matrix. And I know that
some packages used in AB area setup MME directly from the data.
Unfortunately, I am also not up to the task to tell the details. I am
providing list of packages that are used in AB and whose authors might
be as generous as you to show the light. Additionally, these packages
can also deal with many response variables i.e. multi-trait/multivariate
models with different effects so their implementations are surely
general. Though, they are mainly for linear mixed models, but some also
cope with generalized mixed model.

Thank you again!

ASReml
http://www.vsni.co.uk/products/asreml/

BGF90
http://nce.ads.uga.edu/%7Eignacy/numpub/

DMU
http://www.dmu.agrsci.dk/
http://www.wcgalp8.org.br/wcgalp8/articles/paper/27_302-413.pdf

PEST/VCE
http://w3.tzv.fal.de/%7Eeg/
http://vce.tzv.fal.de/index.pl

MATVEC
http://statistics.unl.edu/faculty/steve/software/matvec/

WOMBAT
http://agbu.une.edu.au/~kmeyer/wombat.html

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc
----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty        www: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department     blog: http://ggorjan.blogspot.com
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si
SI-1230 Domzale             fax: +386 (0)1 72 17 888
Slovenia, Europe            tel: +386 (0)1 72 17 861



From Wayne.Hallstrom at WorleyParsons.com  Fri Mar  2 19:44:01 2007
From: Wayne.Hallstrom at WorleyParsons.com (Hallstrom, Wayne (Calgary))
Date: Fri, 2 Mar 2007 11:44:01 -0700
Subject: [R-sig-ME] models with fixed effets nested in random effects
Message-ID: <C672AABF34CB964A95F5E12A8013499618C3A8@cacalwpexm01.WorleyParsons.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070302/dcbf7e12/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Sat Mar  3 21:26:24 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 4 Mar 2007 07:26:24 +1100
Subject: [R-sig-ME] models with fixed effets nested in random effects
In-Reply-To: <C672AABF34CB964A95F5E12A8013499618C3A8@cacalwpexm01.WorleyParsons.com>
References: <C672AABF34CB964A95F5E12A8013499618C3A8@cacalwpexm01.WorleyParsons.com>
Message-ID: <20070303202624.GU19982@ms.unimelb.edu.au>

Hi Wayne,

your question points to a broader problem with the specification of
fixed and random effects.  It is often true that fixed effects are
aliased with elements of the underlying experimental design - such as
in split plot designs - and then it makes sense to declare the effect
as both fixed and random.  (Actually I think that it makes more sense
to create a new variable identical to the first and use one for fixed
and the other for random, but that is neither here nor there.)  I'm
not sure whether this is true in your case.

Anyway, I'm confused that you write "The treatment was applied:
Location/Subsite/TREATMENT/year" and then in your model statement you
have only three levels: FenceEnd/FEsection/MIT_UNMIT. Also, it seems
that two treatment effects appear in the random statement.  I can't
reconcile that with your earlier description.  Can you try to clarify
these - perhaps by giving a more complete description of the design?

Cheers,

Andrew



On Fri, Mar 02, 2007 at 11:44:01AM -0700, Hallstrom, Wayne (Calgary) wrote:
> I am having trouble defining a model that accounts for the data
> structure but also allows the treatment effect to be estimated as a
> fixed effect. I think I have it figured out but I would like to see what
> some other opinions are regarding placement of a fixed effect in both
> the random and fixed sections of a model formula.
>  
> There is 20 years of records at a variety of locations and subsites
> within each location, with treatments for 1/2 of the years of records at
> each location and subsite. The general structure to the data is:
>     Location/Subsite/year
> The treatment was applied:
>     Location/Subsite/TREATMENT/year
>  
> The model format is:
>     u5 <- lmer(ung ~ FEsection + MIT_UNMIT +
> (1|FenceEnd/FEsection/MIT_UNMIT), family=quasipoisson(link =
> 
>         "log"))
> 
>  
> 
> Model output is:
> 
>     > summary(u5)
> 
>     Generalized linear mixed model fit using Laplace 
> 
>     Formula: ung ~ FEsection + MIT_UNMIT + (1 |
> FenceEnd/FEsection/MIT_UNMIT) 
> 
>      Family: quasipoisson(log link)
> 
>       AIC  BIC logLik deviance
> 
>      1661 1733 -816.7     1633
> 
>     Random effects:
> 
>      Groups                         Name        Variance Std.Dev.
> 
>      MIT_UNMIT:(FEsection:FenceEnd) (Intercept) 0.268713 0.51838 
> 
>      FEsection:FenceEnd             (Intercept) 0.066643 0.25815 
> 
>      FenceEnd                       (Intercept) 0.213373 0.46192 
> 
>      Residual                                   1.371364 1.17105 
> 
>     number of obs: 1230, groups: MIT_UNMIT:(FEsection:FenceEnd), 93;
> FEsection:FenceEnd, 58; FenceEnd, 7
> 
>      
> 
>     Fixed effects:
> 
>                     Estimate Std. Error t value
> 
>     (Intercept)    -1.808774   0.340329  -5.315
> 
>     FEsection2     -0.148425   0.349608  -0.425
> 
>     FEsection3     -0.066525   0.344542  -0.193
> 
>     FEsection4     -0.021216   0.346025  -0.061
> 
>     FEsection5      0.470120   0.333193   1.411
> 
>     FEsection6      0.459920   0.329556   1.396
> 
>     FEsection7      0.455736   0.381993   1.193
> 
>     FEsection8      0.006034   0.399353   0.015
> 
>     FEsection9      0.423509   0.383930   1.103
> 
>     FEsection10     0.062848   0.393176   0.160
> 
>     MIT_UNMITunmit  1.572822   0.188382   8.349
> 
>  
> 
> This seems fine to me, there are the propoer number of groups in the
> data structure. The problem I have yet to wrap my head around is the
> fact that the fixed effects are still in the random effects category as
> well. Is that a problem? Should I be adding all terms with fixed effect
> variable, including interaction terms, into the 'fixed effects' part of
> the model equation? Since I am new to this LMER routine it is a bit
> confusing to write.
>  
> Wayne Hallstrom
> *** WORLEYPARSONS GROUP NOTICE ***
> "This email is confidential.  If you are not the intended recipient, you must not disclose  or  use the  information  contained in it.  If you have received this email in error,  please notify us immediately by return email and delete the email and any attachments. Any personal views or opinions expressed by the writer may not necessarily reflect the views or opinions of any company in the WorleyParsons Group of Companies."
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From Wayne.Hallstrom at WorleyParsons.com  Mon Mar  5 20:10:16 2007
From: Wayne.Hallstrom at WorleyParsons.com (Hallstrom, Wayne (Calgary))
Date: Mon, 5 Mar 2007 12:10:16 -0700
Subject: [R-sig-ME] models with fixed effets nested in random effects
Message-ID: <C672AABF34CB964A95F5E12A8013499618C81A@cacalwpexm01.WorleyParsons.com>

Hi Andrew,

The reason I did not include year in the random effects part of the
model was since in terms of the actual data those are the individual
observations. Putting year into the model made the groups messed up. The
model statement "FenceEnd/FEsection/MIT_UNMIT" thus had the proper
number of groups to match the physical chatacteristics of the design
setup, 
[number of obs: 1230, groups: MIT_UNMIT:(FEsection:FenceEnd), 93;
FEsection:FenceEnd, 58; FenceEnd, 7] 
and then there are the count data from each year within each of these
groups.  It made sense to me when I was writing the formula but maybe
this is not right?
As well, I have the treatment effects in the random part of the formula
since without doing this there would not be the proper structure to fit
the data, and would I not then have pseudoreplication? It is not
entirely clear to me what should be done with fixed/random effects in
this case where the treatmetn effects need to be used to define the
grouping of the data. Maybe as you say I could define a new variable
with the same characterisitces as 'FEsection' and 'MIT_UNMIT' in order
to have one for the random section to account for data structure, and
another in the fixed section to account for the fixed effects. Wouldn't
that just produce the same results by a different name?

In terms of the study layout:
-Parts of the highway were fenced at different intervals
(treatment=MIT_UNMIT), creating fence ends (location=FenceEnd).
Subsequent fencing extended the fence, removing some fence ends but
creating new ends. Generally, fence ends are far apart from the previous
fence end since most phases of fencing are ~20km long.
-roadkill count data were collected, and summed on a yearly basis
(year).
-roadkill location data were then processed and categorized by UTM
coordinates into five 1km segments inside each fence end and five 1km
segments outdside, centered on the fence end (subsite=FEsection). This
sort of like having 10 different levels of the 2 treatments at each
fence end. The treatment effects being accounted for by the MIT_UNMIT
variable that defines whether the sample had fencing or not, and the
FEsection variable defining how far from the fence end the mortalities
occurred. Of course there could be many ways to look at this, I tried to
keep things as simple as possible. Feel free to make suggestions if you
can think of alternatives...

A variety of models were fit to the data with the intention of
determining how fencing affected the distribution of mortality at a
fence end. Questions asked were - Does mitigation cause a shift in
mortality locations to the unfenced area beyond the fence end (segments
1-5->outside versus 6-10->inside)? This would imply the fence end should
perhaps be relocated elsewhere. Is there a notable difference in
mortality among the segments inside and the segments outside the fence
end? Higher mortality inside the fence could show whether animals are
getting inside at the fence end and then being killed, in which case
deterrents to keep them out and mitigations to allow trapped animals to
escape should be considered. If there is a concentration of mortality in
the 1km FEsections nearest the fence end this would support the idea
that substantial numbers of animals are rounding the fence end and being
killed at that location, implying the fence is not located properly
relative to animal migrations in the area and needs to be extended,
and/or perhaps more crossing structures are needed. Mainly elk are the
animal killed in this area.

The model I pasted into the last email was best of the the 3 best-fit
models. The others were similar in structure but with different form,
such as:
  u0 <- lmer(ung ~ 1 + (1|FenceEnd/FEsection/MIT_UNMIT),
family=quasipoisson(link ="log")
  u01<- lmer(ung ~ year + (1|FenceEnd/FEsection/MIT_UNMIT),
family=quasipoisson(link ="log")
  u1 <- lmer(ung ~ FEsection + (1|FenceEnd/FEsection/MIT_UNMIT),
family=quasipoisson(link ="log"))
  u2 <- lmer(ung ~ MIT_UNMIT + (1|FenceEnd/FEsection/MIT_UNMIT),
family=quasipoisson(link ="log"))
	.
	.
	.
  u5 <- lmer(ung ~ FEsection + MIT_UNMIT +
(1|FenceEnd/FEsection/MIT_UNMIT), family=quasipoisson(link ="log"))


Anyway I really appreciate the help since it is a new and confusing
issue to me. This is for some work I do on my own time, with data from a
pproject I worked on in the past. The data are for one of the larger
highway wildlife fencing studies out there, and since roadkill is an
issue growing with the growing traffic volumes, these results will
probably be used as reference for how to design other fencing projects.

Wayne


-----Original Message-----
From: Andrew Robinson [mailto:A.Robinson at ms.unimelb.edu.au] 
Sent: Saturday, March 03, 2007 1:26 PM
To: Hallstrom, Wayne (Calgary)
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] models with fixed effets nested in random
effects

Hi Wayne,

your question points to a broader problem with the specification of
fixed and random effects.  It is often true that fixed effects are
aliased with elements of the underlying experimental design - such as in
split plot designs - and then it makes sense to declare the effect as
both fixed and random.  (Actually I think that it makes more sense to
create a new variable identical to the first and use one for fixed and
the other for random, but that is neither here nor there.)  I'm not sure
whether this is true in your case.

Anyway, I'm confused that you write "The treatment was applied:
Location/Subsite/TREATMENT/year" and then in your model statement you
have only three levels: FenceEnd/FEsection/MIT_UNMIT. Also, it seems
that two treatment effects appear in the random statement.  I can't
reconcile that with your earlier description.  Can you try to clarify
these - perhaps by giving a more complete description of the design?

Cheers,

Andrew



On Fri, Mar 02, 2007 at 11:44:01AM -0700, Hallstrom, Wayne (Calgary)
wrote:
> I am having trouble defining a model that accounts for the data 
> structure but also allows the treatment effect to be estimated as a 
> fixed effect. I think I have it figured out but I would like to see 
> what some other opinions are regarding placement of a fixed effect in 
> both the random and fixed sections of a model formula.
>  
> There is 20 years of records at a variety of locations and subsites 
> within each location, with treatments for 1/2 of the years of records 
> at each location and subsite. The general structure to the data is:
>     Location/Subsite/year
> The treatment was applied:
>     Location/Subsite/TREATMENT/year
>  
> The model format is:
>     u5 <- lmer(ung ~ FEsection + MIT_UNMIT + 
> (1|FenceEnd/FEsection/MIT_UNMIT), family=quasipoisson(link =
> 
>         "log"))
> 
>  
> 
> Model output is:
> 
>     > summary(u5)
> 
>     Generalized linear mixed model fit using Laplace
> 
>     Formula: ung ~ FEsection + MIT_UNMIT + (1 |
> FenceEnd/FEsection/MIT_UNMIT)
> 
>      Family: quasipoisson(log link)
> 
>       AIC  BIC logLik deviance
> 
>      1661 1733 -816.7     1633
> 
>     Random effects:
> 
>      Groups                         Name        Variance Std.Dev.
> 
>      MIT_UNMIT:(FEsection:FenceEnd) (Intercept) 0.268713 0.51838
> 
>      FEsection:FenceEnd             (Intercept) 0.066643 0.25815 
> 
>      FenceEnd                       (Intercept) 0.213373 0.46192 
> 
>      Residual                                   1.371364 1.17105 
> 
>     number of obs: 1230, groups: MIT_UNMIT:(FEsection:FenceEnd), 93; 
> FEsection:FenceEnd, 58; FenceEnd, 7
> 
>      
> 
>     Fixed effects:
> 
>                     Estimate Std. Error t value
> 
>     (Intercept)    -1.808774   0.340329  -5.315
> 
>     FEsection2     -0.148425   0.349608  -0.425
> 
>     FEsection3     -0.066525   0.344542  -0.193
> 
>     FEsection4     -0.021216   0.346025  -0.061
> 
>     FEsection5      0.470120   0.333193   1.411
> 
>     FEsection6      0.459920   0.329556   1.396
> 
>     FEsection7      0.455736   0.381993   1.193
> 
>     FEsection8      0.006034   0.399353   0.015
> 
>     FEsection9      0.423509   0.383930   1.103
> 
>     FEsection10     0.062848   0.393176   0.160
> 
>     MIT_UNMITunmit  1.572822   0.188382   8.349
> 
>  
> 
> This seems fine to me, there are the propoer number of groups in the 
> data structure. The problem I have yet to wrap my head around is the 
> fact that the fixed effects are still in the random effects category 
> as well. Is that a problem? Should I be adding all terms with fixed 
> effect variable, including interaction terms, into the 'fixed effects'

> part of the model equation? Since I am new to this LMER routine it is 
> a bit confusing to write.
>  
> Wayne Hallstrom
> *** WORLEYPARSONS GROUP NOTICE ***
> "This email is confidential.  If you are not the intended recipient,
you must not disclose  or  use the  information  contained in it.  If
you have received this email in error,  please notify us immediately by
return email and delete the email and any attachments. Any personal
views or opinions expressed by the writer may not necessarily reflect
the views or opinions of any company in the WorleyParsons Group of
Companies."
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/ 
*** WORLEYPARSONS GROUP NOTICE ***
"This email is confidential.  If you are not the intended recipient, you must not disclose  or  use the  information  contained in it.  If you have received this email in error,  please notify us immediately by return email and delete the email and any attachments. Any personal views or opinions expressed by the writer may not necessarily reflect the views or opinions of any company in the WorleyParsons Group of Companies."



From A.Robinson at ms.unimelb.edu.au  Tue Mar  6 11:12:32 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 6 Mar 2007 21:12:32 +1100
Subject: [R-sig-ME] models with fixed effets nested in random effects
In-Reply-To: <C672AABF34CB964A95F5E12A8013499618C81A@cacalwpexm01.WorleyParsons.com>
References: <C672AABF34CB964A95F5E12A8013499618C81A@cacalwpexm01.WorleyParsons.com>
Message-ID: <20070306101232.GE19982@ms.unimelb.edu.au>

Hi Wayne,

On Mon, Mar 05, 2007 at 12:10:16PM -0700, Hallstrom, Wayne (Calgary) wrote:
> Hi Andrew,
> 
> The reason I did not include year in the random effects part of the
> model was since in terms of the actual data those are the individual
> observations. Putting year into the model made the groups messed up. The
> model statement "FenceEnd/FEsection/MIT_UNMIT" thus had the proper
> number of groups to match the physical chatacteristics of the design
> setup, 
> [number of obs: 1230, groups: MIT_UNMIT:(FEsection:FenceEnd), 93;
> FEsection:FenceEnd, 58; FenceEnd, 7] 
> and then there are the count data from each year within each of these
> groups.  It made sense to me when I was writing the formula but maybe
> this is not right?

The decision about year looks good to me, based on your description
above.

There may well be a temporal correlation structure to watch out for
within the lowest- level random effects.  If that be the case then you
might want to move to using lme(), which has well-configured helper
functions for fitting the more complicated models.

> As well, I have the treatment effects in the random part of the formula
> since without doing this there would not be the proper structure to fit
> the data, and would I not then have pseudoreplication? It is not
> entirely clear to me what should be done with fixed/random effects in
> this case where the treatmetn effects need to be used to define the
> grouping of the data. Maybe as you say I could define a new variable
> with the same characterisitces as 'FEsection' and 'MIT_UNMIT' in order
> to have one for the random section to account for data structure, and
> another in the fixed section to account for the fixed effects. Wouldn't
> that just produce the same results by a different name?

Yes, it would.  I hope that my addition of that text wasn't confusing.
I merely meant to include it as a possiblity to deal with concerns
about the same effects being fixed and random.  I do think that it
would be clearler in some cases.

> In terms of the study layout:
> -Parts of the highway were fenced at different intervals
> (treatment=MIT_UNMIT), creating fence ends (location=FenceEnd).

Ok, this implies to me that MIT_UNMIT represents the intervals
somehow, and that each interval has one or more FenceEnd associated
with it.  What exactly does MIT_UNMIT mean?  I assume that it's
mitigation vs no mitigation.  

> Subsequent fencing extended the fence, removing some fence ends but
> creating new ends. Generally, fence ends are far apart from the previous
> fence end since most phases of fencing are ~20km long.
> -roadkill count data were collected, and summed on a yearly basis
> (year).
> -roadkill location data were then processed and categorized by UTM
> coordinates into five 1km segments inside each fence end and five 1km
> segments outdside, centered on the fence end (subsite=FEsection). This
> sort of like having 10 different levels of the 2 treatments at each
> fence end. The treatment effects being accounted for by the MIT_UNMIT
> variable that defines whether the sample had fencing or not, and the
> FEsection variable defining how far from the fence end the mortalities
> occurred. Of course there could be many ways to look at this, I tried to
> keep things as simple as possible. Feel free to make suggestions if you
> can think of alternatives...

I'm a bit confused by the nesting of MIT_UNMIT inside FEsection.  Your
earlier text implies to me that the MIT_UNMIT treatment differed at
the FenceEnd level.  Nesting it inside FEsection implies that every
level of FEsection has all the MIT_UNMIT levels nested within them.
That seems like a contradiction to me.

Also, based on your description I wonder if FEsection should be
recoded to have a continuous basis as well as a categorical one - for
the purposes of representing an underlying distance?  I note from your
earlier email that FEsection appears as a 10-level factor, and that
seems (prima facie) more difficult to interpret.

Cheers,

Andrew

> A variety of models were fit to the data with the intention of
> determining how fencing affected the distribution of mortality at a
> fence end. Questions asked were - Does mitigation cause a shift in
> mortality locations to the unfenced area beyond the fence end (segments
> 1-5->outside versus 6-10->inside)? This would imply the fence end should
> perhaps be relocated elsewhere. Is there a notable difference in
> mortality among the segments inside and the segments outside the fence
> end? Higher mortality inside the fence could show whether animals are
> getting inside at the fence end and then being killed, in which case
> deterrents to keep them out and mitigations to allow trapped animals to
> escape should be considered. If there is a concentration of mortality in
> the 1km FEsections nearest the fence end this would support the idea
> that substantial numbers of animals are rounding the fence end and being
> killed at that location, implying the fence is not located properly
> relative to animal migrations in the area and needs to be extended,
> and/or perhaps more crossing structures are needed. Mainly elk are the
> animal killed in this area.
> 
> The model I pasted into the last email was best of the the 3 best-fit
> models. The others were similar in structure but with different form,
> such as:
>   u0 <- lmer(ung ~ 1 + (1|FenceEnd/FEsection/MIT_UNMIT),
> family=quasipoisson(link ="log")
>   u01<- lmer(ung ~ year + (1|FenceEnd/FEsection/MIT_UNMIT),
> family=quasipoisson(link ="log")
>   u1 <- lmer(ung ~ FEsection + (1|FenceEnd/FEsection/MIT_UNMIT),
> family=quasipoisson(link ="log"))
>   u2 <- lmer(ung ~ MIT_UNMIT + (1|FenceEnd/FEsection/MIT_UNMIT),
> family=quasipoisson(link ="log"))
> 	.
> 	.
> 	.
>   u5 <- lmer(ung ~ FEsection + MIT_UNMIT +
> (1|FenceEnd/FEsection/MIT_UNMIT), family=quasipoisson(link ="log"))
> 
> 
> Anyway I really appreciate the help since it is a new and confusing
> issue to me. This is for some work I do on my own time, with data from a
> pproject I worked on in the past. The data are for one of the larger
> highway wildlife fencing studies out there, and since roadkill is an
> issue growing with the growing traffic volumes, these results will
> probably be used as reference for how to design other fencing projects.
> 
> Wayne
> 

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From Wayne.Hallstrom at WorleyParsons.com  Wed Mar  7 00:04:02 2007
From: Wayne.Hallstrom at WorleyParsons.com (Hallstrom, Wayne (Calgary))
Date: Tue, 6 Mar 2007 16:04:02 -0700
Subject: [R-sig-ME] models with fixed effets nested in random effects
Message-ID: <C672AABF34CB964A95F5E12A8013499618CDC9@cacalwpexm01.WorleyParsons.com>


Hi Andrew,
Note comments interted below...
---------------
++Hi Wayne,

On Mon, Mar 05, 2007 at 12:10:16PM -0700, Hallstrom, Wayne (Calgary)
wrote:
> Hi Andrew,
> 
> The reason I did not include year in the random effects part of the 
> model was since in terms of the actual data those are the individual 
> observations. Putting year into the model made the groups messed up. 
> The model statement "FenceEnd/FEsection/MIT_UNMIT" thus had the proper

> number of groups to match the physical chatacteristics of the design 
> setup, [number of obs: 1230, groups: MIT_UNMIT:(FEsection:FenceEnd), 
> 93; FEsection:FenceEnd, 58; FenceEnd, 7] and then there are the count 
> data from each year within each of these groups.  It made sense to me 
> when I was writing the formula but maybe this is not right?

++ The decision about year looks good to me, based on your description
above.

++ There may well be a temporal correlation structure to watch out for
within the lowest- level random effects.  ++ If that be the case then
you might want to move to using lme(), which has well-configured helper
functions for
++ fitting the more complicated models.

I considered using lme(), but I have overdispersed count data and need
to use the more flexible glm structure of LMER. I could be wrong, but
the way I the model set up should allow me to note any substantaial
effect of year in one of the candidate models. That was not the case,
models with year were not anywhere near as good fit.

> As well, I have the treatment effects in the random part of the 
> formula since without doing this there would not be the proper 
> structure to fit the data, and would I not then have 
> pseudoreplication? It is not entirely clear to me what should be done 
> with fixed/random effects in this case where the treatmetn effects 
> need to be used to define the grouping of the data. Maybe as you say I

> could define a new variable with the same characterisitces as 
> 'FEsection' and 'MIT_UNMIT' in order to have one for the random 
> section to account for data structure, and another in the fixed 
> section to account for the fixed effects. Wouldn't that just produce
the same results by a different name?

++ Yes, it would.  I hope that my addition of that text wasn't
confusing.
++ I merely meant to include it as a possiblity to deal with concerns
about the same effects being fixed and 
++ random.  I do think that it would be clearler in some cases.

I can see what you mean though since it makes the formula 'cleaner'.

> In terms of the study layout:
> -Parts of the highway were fenced at different intervals 
> (treatment=MIT_UNMIT), creating fence ends (location=FenceEnd).

++ Ok, this implies to me that MIT_UNMIT represents the intervals
somehow, and that each interval has one or more
++ FenceEnd associated with it.  What exactly does MIT_UNMIT mean?  I
assume that it's mitigation vs no
++ mitigation.  

MIT_UNMIT is the fencing treatment. Yes, each fence has one or two ends.

> Subsequent fencing extended the fence, removing some fence ends but 
> creating new ends. Generally, fence ends are far apart from the 
> previous fence end since most phases of fencing are ~20km long.
> -roadkill count data were collected, and summed on a yearly basis 
> (year).
> -roadkill location data were then processed and categorized by UTM 
> coordinates into five 1km segments inside each fence end and five 1km 
> segments outdside, centered on the fence end (subsite=FEsection). This

> sort of like having 10 different levels of the 2 treatments at each 
> fence end. The treatment effects being accounted for by the MIT_UNMIT 
> variable that defines whether the sample had fencing or not, and the 
> FEsection variable defining how far from the fence end the mortalities

> occurred. Of course there could be many ways to look at this, I tried 
> to keep things as simple as possible. Feel free to make suggestions if

> you can think of alternatives...

++ I'm a bit confused by the nesting of MIT_UNMIT inside FEsection.
Your earlier text implies to me that the
++ MIT_UNMIT treatment differed at the FenceEnd level.  Nesting it
inside FEsection implies that every level of
++ FEsection has all the MIT_UNMIT levels nested within them. That seems
like a contradiction to me.

++ Also, based on your description I wonder if FEsection should be
recoded to have a continuous basis as well as
++ a categorical one - for the purposes of representing an underlying
distance?  I note from your earlier email
++ that FEsection appears as a 10-level factor, and that seems (prima
facie) more difficult to interpret.

++ Cheers,
++ Andrew

Well, that is sort of true about the nesting of MIT_UNMIT inside
FEsection. Most do, but not all fence end sections will have both
MIT_UNMIT treatments. I am not sure however that this is a major concern
since all that means is there are never records for MITIGATED for
FEsections 1-5 outside the fence. I was thinking of it as explaining the
locations, then add in treatment effects at each location last. I
suppose I could have tried FenceEnd/MIT_UNMIT/FEsection instead but I
don't think that works since then you have FEsections inside MIT_UNMIT
which does not always occur either. There is no way around this issue
because using a distance measure also has the same problem (no roadkill
distance-mitigated combination exists outside the fence end). I suppose
maybe I could add something in about NA records to cover that though?

I did not use distance since many of the records are from before a given
fence ends exists, so a distance measure is sort of meaningless for that
time period. I chose 1km sections since those are not tied to one
particular location in the same way, and because there is some error in
the mortality record locations which is partially removed by lumping the
data into sections.


> A variety of models were fit to the data with the intention of 
> determining how fencing affected the distribution of mortality at a 
> fence end. Questions asked were - Does mitigation cause a shift in 
> mortality locations to the unfenced area beyond the fence end 
> (segments
> 1-5->outside versus 6-10->inside)? This would imply the fence end 
> 1-5->should
> perhaps be relocated elsewhere. Is there a notable difference in 
> mortality among the segments inside and the segments outside the fence

> end? Higher mortality inside the fence could show whether animals are 
> getting inside at the fence end and then being killed, in which case 
> deterrents to keep them out and mitigations to allow trapped animals 
> to escape should be considered. If there is a concentration of 
> mortality in the 1km FEsections nearest the fence end this would 
> support the idea that substantial numbers of animals are rounding the 
> fence end and being killed at that location, implying the fence is not

> located properly relative to animal migrations in the area and needs 
> to be extended, and/or perhaps more crossing structures are needed. 
> Mainly elk are the animal killed in this area.
> 
> The model I pasted into the last email was best of the the 3 best-fit 
> models. The others were similar in structure but with different form, 
> such as:
>   u0 <- lmer(ung ~ 1 + (1|FenceEnd/FEsection/MIT_UNMIT), 
> family=quasipoisson(link ="log")
>   u01<- lmer(ung ~ year + (1|FenceEnd/FEsection/MIT_UNMIT), 
> family=quasipoisson(link ="log")
>   u1 <- lmer(ung ~ FEsection + (1|FenceEnd/FEsection/MIT_UNMIT), 
> family=quasipoisson(link ="log"))
>   u2 <- lmer(ung ~ MIT_UNMIT + (1|FenceEnd/FEsection/MIT_UNMIT), 
> family=quasipoisson(link ="log"))
> 	.
> 	.
> 	.
>   u5 <- lmer(ung ~ FEsection + MIT_UNMIT + 
> (1|FenceEnd/FEsection/MIT_UNMIT), family=quasipoisson(link ="log"))
> 
> 
> Anyway I really appreciate the help since it is a new and confusing 
> issue to me. This is for some work I do on my own time, with data from

> a pproject I worked on in the past. The data are for one of the larger

> highway wildlife fencing studies out there, and since roadkill is an 
> issue growing with the growing traffic volumes, these results will 
> probably be used as reference for how to design other fencing
projects.
> 
> Wayne
> 



I guess what I really am trying to get at here is:
  - do wildlife roadkill counts differ between FEsections 1-10
pre-fencing, or are they uniformly distributed?
  - post-fencing, does the distribution of roadkill counts change
compared to pre-fencing? 
  - where do any observed differences crop up realtive to the fence end?

These questions seem to have been answered by looking at the various
models, including interactions. Best fit model was FEsection +
MIT_UNMIT. A significant effect from FEsection shows that roadkill
differs between the sections, and MIT_UNMIT shows that mortality
distribution before after fencing differs. There was no interaction in
the best model which shows that the effect of MIT_UNMIT is consistent
across all the fence end sections where mitigation occurred. If there
were an interaction and no main effects that would demonstrate that
mitigation only changed roadkill distribution in some cases (but this
did not happen).

Compared to the multivariate G-test (like a chi-test) method I used
initially, this sometimes has seemed to be trying to fit a square peg of
data into a round hole of a statistical method. That method allowed me
to define exact locations of differences in counts and go back to see
what was there on the ground. I guess that is still useful info for the
discussion anyway.




--
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/ 
*** WORLEYPARSONS GROUP NOTICE ***
"This email is confidential.  If you are not the intended recipient, you must not disclose  or  use the  information  contained in it.  If you have received this email in error,  please notify us immediately by return email and delete the email and any attachments. Any personal views or opinions expressed by the writer may not necessarily reflect the views or opinions of any company in the WorleyParsons Group of Companies."



From clists at perrin.socsci.unc.edu  Thu Mar  8 21:50:00 2007
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Thu, 8 Mar 2007 15:50:00 -0500 (EST)
Subject: [R-sig-ME] Model specification help
Message-ID: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>

Greetings-

I am trying to estimate a large mixed-effects model. The data consist of 
all grades issued to all undergraduates at UNC in the last ten years -- as 
you can imagine, a fairly large set! What I want to estimate is the 
relative effects of student performance, instructor practices, and 
departmental practices.  Here's what I tried:

grades.lmer<-lmer(formula   = grade.pt ~ cour.dep + section +
                   (stud.id + instr.id | section/instr.id/cour.dep),
                   na.action = na.omit,
                   data = newgrades.stripped.df)


I get the following:

Error in array(0, c(n, n), list(levs, levs)) :
         'dim' specifies too large an array




My *intention* in this is that grade.pt (the numerical grade issued) is 
modeled as a function of course.dep (the department, a fixed effect); 
section (the specific course section taken, a fixed effect); and random 
effects for stud.id (individual student) and instr.id (individual 
instructor), where grades are nested within sections, nested in turn 
within instructors, nested in turn within departments.

I would welcome both substantive and technical advice here. If the problem 
is simply that the dataset is too big, I'd be OK with taking a random 
sample of it; but if there's something else wrong I'd be grateful for your 
thoughts.

Thanks,
Andy Perrin

----------------------------------------------------------------------
Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
Assistant Professor of Sociology; Book Review Editor, _Social Forces_
University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl



From bates at stat.wisc.edu  Thu Mar  8 23:36:38 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 8 Mar 2007 16:36:38 -0600
Subject: [R-sig-ME] Model specification help
In-Reply-To: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
Message-ID: <40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com>

On 3/8/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
> Greetings-
>
> I am trying to estimate a large mixed-effects model. The data consist of
> all grades issued to all undergraduates at UNC in the last ten years -- as
> you can imagine, a fairly large set! What I want to estimate is the
> relative effects of student performance, instructor practices, and
> departmental practices.  Here's what I tried:
>
> grades.lmer<-lmer(formula   = grade.pt ~ cour.dep + section +
>                    (stud.id + instr.id | section/instr.id/cour.dep),
>                    na.action = na.omit,
>                    data = newgrades.stripped.df)
>
>
> I get the following:
>
> Error in array(0, c(n, n), list(levs, levs)) :
>          'dim' specifies too large an array

Indeed. The number of random effects in the model that you have
specified is probably greater than the population of the entire planet
:-)

We should go at this in stages.  You may still run out of memory but
at least we will know where things break down.

The first question is whether the stud.id, instr.id, cour.dep and,
most importantly, the section variables are coded so that every
distinct level of the factor corresponds to a distinct label in the
factor.  I would expect this to be true for stud.id, instr.id and
cour.dep but is it also true for section?  That is does each separate
section of each course in each year correspond to a separate label in
the section variable.  If not, you will need to create a factor like
that.

Once you have the factors defined this way then you don't need to
worry about nesting, etc.  This will be detected automatically. It
probably doesn't matter anyway because nesting only provides a
simplification of the computing methods when all the factors form a
nested sequence.  If nesting fails at any point then the computational
methods revert to the general case.  If I understand the situation
then stud.id and inst.id will not be nested so nesting of other
factors doesn't matter.

So start with a simple model such as

lmer(grade.pt ~ (1|stud.id) + (1|inst.id) + 1(cour.dep), newgrades.stripped.df,
      control = list(gradient = FALSE, niterEM = 0, msVerbose = 1))

This model has additive random effects for student, for instructor and
for department.  I know that you consider department as a fixed effect
but my guess is that there are on the order of a hundred departments.
Estimating effects for a factor with this number of levels as random
effects is much more stable than estimating them as fixed effects,
because of the shrinkage of random effects estimates.  In lmer it is
also saves storage.  In lmer and in the experimental lmer2 the model
matrix for the fixed effects is created as a dense matrix.  If you
have, say, millions of observations and hundreds of departments then
this matrix alone has a size of hundreds of millions of
double-precision storage locations, meaning that it is on the order of
gigabytes.

If you run out of memory on that model, see if lmer2 can fit it.  If
both calls fail on the amount of memory needed (which is likely) then
it will be necessary to step through the lmer2 function using the
debugger to see at what point they fail.

We do have plans for a "large data set" version of lmer that builds up
the model matrices in (horizontal) sections, similar to the method in
the biglm package so there is hope even if this doesn't work.
However, it will be some time before that is available.

By the way, what type of computer are you using and how much memory
does it have?  You definitely want to be working on a 64-bit computer
(probably and Opteron-based server) with as much memory as your budget
allows.  8 GB and 16 GB servers are common, though expensive compared
to desktop machines.



>
>
>
>
> My *intention* in this is that grade.pt (the numerical grade issued) is
> modeled as a function of course.dep (the department, a fixed effect);
> section (the specific course section taken, a fixed effect); and random
> effects for stud.id (individual student) and instr.id (individual
> instructor), where grades are nested within sections, nested in turn
> within instructors, nested in turn within departments.
>
> I would welcome both substantive and technical advice here. If the problem
> is simply that the dataset is too big, I'd be OK with taking a random
> sample of it; but if there's something else wrong I'd be grateful for your
> thoughts.
>
> Thanks,
> Andy Perrin
>
> ----------------------------------------------------------------------
> Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
> Assistant Professor of Sociology; Book Review Editor, _Social Forces_
> University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
> New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Mar  8 23:52:47 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 8 Mar 2007 16:52:47 -0600
Subject: [R-sig-ME] [R] augPred in lmer
In-Reply-To: <20070308213124.GC92002@ms.unimelb.edu.au>
References: <3FC0430478C30B4A9AF0AFF7863418F130F085@BCMEVS6.ad.bcm.edu>
	<20070308213124.GC92002@ms.unimelb.edu.au>
Message-ID: <40e66e0b0703081452r6a2ee705p89031e377eb1e269@mail.gmail.com>

On 3/8/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> Hi Kyle,
>
> not yet!  At least not as far as I know.

Not as far as I know either.

> On Thu, Mar 08, 2007 at 03:08:19PM -0600, Roberts, J. Kyle wrote:
> > I read the posts about augPred with lme, but does anyone know if there is a correlate for augPred for lmer?  Specifically, I want to be able to use it to plot projections for all groups in an lmer class object using plot(augPred(lmer.object)).

Can you give us a bit more detail on the model that you have fit?  It
may be possible to get the plot that you want without having to build
all the infrastructure that Jose and I built in lme.  Deepayan has
quietly added so many wonderful capabilities to lattice relative to
earlier versions of trellis that a more direct approach often works.

Also, I think we should move the discussion to the R-sig-mixed-models
mailing list, which I am cc:ing on this reply.



From clists at perrin.socsci.unc.edu  Fri Mar  9 02:40:05 2007
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Thu, 8 Mar 2007 20:40:05 -0500 (EST)
Subject: [R-sig-ME] Model specification help
In-Reply-To: <40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu>

Thank you for this. I will return to it tomorrow and let you know how it 
goes. As for the machine it's running on: it's a dual-Xeon 2.8Ghz IBM 
eseries server with 6GB RAM, running debian Linux, kernel 2.6.18.  So the 
3GB per-process memory limit applies. I also have access to a shared 
server with "twenty-four 1.05 GHz Ultra-Sparc III+ processors and 40 GB of 
main memory" running solaris, if that's better.

----------------------------------------------------------------------
Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
Assistant Professor of Sociology; Book Review Editor, _Social Forces_
University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl



From elw at stderr.org  Fri Mar  9 04:55:29 2007
From: elw at stderr.org (elw at stderr.org)
Date: Thu, 8 Mar 2007 21:55:29 -0600 (CST)
Subject: [R-sig-ME] Model specification help
In-Reply-To: <Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com>
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu>
Message-ID: <Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org>


> Thank you for this. I will return to it tomorrow and let you know how it 
> goes. As for the machine it's running on: it's a dual-Xeon 2.8Ghz IBM 
> eseries server with 6GB RAM, running debian Linux, kernel 2.6.18.  So 
> the 3GB per-process memory limit applies. I also have access to a shared 
> server with "twenty-four 1.05 GHz Ultra-Sparc III+ processors and 40 GB 
> of main memory" running solaris, if that's better.

Andrew,

That gets you onto a 64-bit platform, beyond the 32-bit-Intel 4GB memory 
(3G for user process, 1G for OS kernel) limit, and beyond a bunch of other 
data size limits.  The memory bandwidth available to you on the Solaris 
machine is also likely to be much more significant - something that you 
will find quite pleasant for even some more trivial analyses.  :)

Much better, certainly!  [And very much like what 'beefy' R code is most 
frequently run on...]

W.r.t. the eSeries server you're commonly running on now - if you can have 
your systems people check to make sure that you have a PAE-enabled linux 
kernel running, you might be able to muscle past the 3GB mark with a 
single R process.... with some work.

[If the machine can actually "see" all 6GB of memory, you probably have a 
PAE kernel.]

--e



From clists at perrin.socsci.unc.edu  Fri Mar  9 03:41:07 2007
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Thu, 8 Mar 2007 21:41:07 -0500 (EST)
Subject: [R-sig-ME] Model specification help
In-Reply-To: <Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com>
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu>
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org>
Message-ID: <Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu>

On Thu, 8 Mar 2007, elw at stderr.org wrote:

>
>> Thank you for this. I will return to it tomorrow and let you know how it 
>> goes. As for the machine it's running on: it's a dual-Xeon 2.8Ghz IBM 
>> eseries server with 6GB RAM, running debian Linux, kernel 2.6.18.  So the 
>> 3GB per-process memory limit applies. I also have access to a shared server 
>> with "twenty-four 1.05 GHz Ultra-Sparc III+ processors and 40 GB of main 
>> memory" running solaris, if that's better.
>
> Andrew,
>
> That gets you onto a 64-bit platform, beyond the 32-bit-Intel 4GB memory (3G 
> for user process, 1G for OS kernel) limit, and beyond a bunch of other data 
> size limits.  The memory bandwidth available to you on the Solaris machine is 
> also likely to be much more significant - something that you will find quite 
> pleasant for even some more trivial analyses.  :)
>
> Much better, certainly!  [And very much like what 'beefy' R code is most 
> frequently run on...]
>
> W.r.t. the eSeries server you're commonly running on now - if you can have 
> your systems people check to make sure that you have a PAE-enabled linux 
> kernel running, you might be able to muscle past the 3GB mark with a single R 
> process.... with some work.
>
> [If the machine can actually "see" all 6GB of memory, you probably have a PAE 
> kernel.]
>
> --e
>

Ironically enough, I *am* the systems people for the eSeries.... having 
been a unix sysadmin and perl programmer before cutting and running for 
social science :).. The kernel is PAE enabled, but that only helps with 
seeing 6G altogether, not over 3G for a single process. I toyed with the 
idea of whether I could break down the process into several threaded ones, 
but that's way above my head.

(The Solaris cluster is university-run, though.)

Thanks,
Andy

----------------------------------------------------------------------
Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
Assistant Professor of Sociology; Book Review Editor, _Social Forces_
University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl



From bates at stat.wisc.edu  Fri Mar  9 14:45:27 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 9 Mar 2007 07:45:27 -0600
Subject: [R-sig-ME] Model specification help
In-Reply-To: <Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com>
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu>
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org>
	<Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu>
Message-ID: <40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com>

On 3/8/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
> On Thu, 8 Mar 2007, elw at stderr.org wrote:
>
> >
> >> Thank you for this. I will return to it tomorrow and let you know how it
> >> goes. As for the machine it's running on: it's a dual-Xeon 2.8Ghz IBM
> >> eseries server with 6GB RAM, running debian Linux, kernel 2.6.18.  So the
> >> 3GB per-process memory limit applies. I also have access to a shared server
> >> with "twenty-four 1.05 GHz Ultra-Sparc III+ processors and 40 GB of main
> >> memory" running solaris, if that's better.
> >
> > Andrew,
> >
> > That gets you onto a 64-bit platform, beyond the 32-bit-Intel 4GB memory (3G
> > for user process, 1G for OS kernel) limit, and beyond a bunch of other data
> > size limits.  The memory bandwidth available to you on the Solaris machine is
> > also likely to be much more significant - something that you will find quite
> > pleasant for even some more trivial analyses.  :)
> >
> > Much better, certainly!  [And very much like what 'beefy' R code is most
> > frequently run on...]
> >
> > W.r.t. the eSeries server you're commonly running on now - if you can have
> > your systems people check to make sure that you have a PAE-enabled linux
> > kernel running, you might be able to muscle past the 3GB mark with a single R
> > process.... with some work.
> >
> > [If the machine can actually "see" all 6GB of memory, you probably have a PAE
> > kernel.]
> >
> > --e
> >
>
> Ironically enough, I *am* the systems people for the eSeries.... having
> been a unix sysadmin and perl programmer before cutting and running for
> social science :).. The kernel is PAE enabled, but that only helps with
> seeing 6G altogether, not over 3G for a single process. I toyed with the
> idea of whether I could break down the process into several threaded ones,
> but that's way above my head.
>
> (The Solaris cluster is university-run, though.)

I haven't done a thorough analysis of the memory usage in lmer but I
can make some informed guesses as to where memory can be saved.  The
details of the implementation and the slots in the internal
representation of the model are given in the "Implementation" vignette
in the lme4 package.  At present there is only one small example shown
in there but I will add others.

For the model fitting process itself the largest object needed is the
symmetric sparse matrix in the A slot and the Cholesky factor of the
updated A*.  The dimension of that square matrix is the sum of the
sizes of the random effects vector and the fixed effects vector plus 1
(for the response).  Generally the Cholesky factor will be slightly
larger than the A but care is taken to make the Cholesky factor as
small as possible.

I enclose an example from fitting a model with two random effects per
student, one random effect per teacher and two random effects per
school to the star (Tennessee's Student-Teacher Achievement Ratio
study) data.  The dimension of the random effects will be 2*10732 +
1374 + 2 * 80 so that easily dominates the dimension of A.

In this case the sizes of the slots L, A, ZXyt and frame are
comparable.  However, if we strip things down to the bare essentials
we don't need ZXyt, frame, flist, offset and weights after the matrix
A has been constructed.

The dimension of the matrices L and A is dominated by the dimension of
the random effects vector.  The dimension of ZXyt, etc. involves the
number of observations.  This might be good news in your case in that
the sizes of the parts that must be preserved are dominated by the
number of students and not the number of grades recorded.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: andrew.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070309/cd340b55/attachment.txt>

From clists at perrin.socsci.unc.edu  Fri Mar  9 17:39:01 2007
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Fri, 9 Mar 2007 11:39:01 -0500 (EST)
Subject: [R-sig-ME] Model specification help
In-Reply-To: <40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu> 
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com> 
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu> 
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org> 
	<Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu>
	<40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703091136270.21287@perrin.socsci.unc.edu>

Update: I decided to run the lmer and lmer2 versions of the code you 
suggested simultaneously, on two machines:

> grades.lmer<-lmer(grade.pt ~ (1|stud.id) + (1|instr.id) + (1|cour.dep),
+                   newgrades.stripped.df,
+                   control =
+                   list(gradient = FALSE, niterEM = 0, msVerbose = 1)
+                   )


They are still working their way through, but I thought it was interesting 
that (a) lmer2 seems to be using less RAM, by roughly 0.3G; (b) even lmer 
seems well within the 3G limit, maxing out at about 1.6G so far; and (c) 
for the first iteration, there are both similarities and differences:

lmer:    0  3.66128e+06: 0.0865649 0.0125233 0.000161387
lmer2:   0  3.66128e+06: 0.294219 0.111907 0.0127038

(since I don't know what that diagnostic means, I can't determine whether 
to be worried about the difference or not!)

More when the models finish.

Andy

----------------------------------------------------------------------
Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
Assistant Professor of Sociology; Book Review Editor, _Social Forces_
University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl



On Fri, 9 Mar 2007, Douglas Bates wrote:

> On 3/8/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
>> On Thu, 8 Mar 2007, elw at stderr.org wrote:
>> 
>> >
>> >> Thank you for this. I will return to it tomorrow and let you know how it
>> >> goes. As for the machine it's running on: it's a dual-Xeon 2.8Ghz IBM
>> >> eseries server with 6GB RAM, running debian Linux, kernel 2.6.18.  So 
>> the
>> >> 3GB per-process memory limit applies. I also have access to a shared 
>> server
>> >> with "twenty-four 1.05 GHz Ultra-Sparc III+ processors and 40 GB of main
>> >> memory" running solaris, if that's better.
>> >
>> > Andrew,
>> >
>> > That gets you onto a 64-bit platform, beyond the 32-bit-Intel 4GB memory 
>> (3G
>> > for user process, 1G for OS kernel) limit, and beyond a bunch of other 
>> data
>> > size limits.  The memory bandwidth available to you on the Solaris 
>> machine is
>> > also likely to be much more significant - something that you will find 
>> quite
>> > pleasant for even some more trivial analyses.  :)
>> >
>> > Much better, certainly!  [And very much like what 'beefy' R code is most
>> > frequently run on...]
>> >
>> > W.r.t. the eSeries server you're commonly running on now - if you can 
>> have
>> > your systems people check to make sure that you have a PAE-enabled linux
>> > kernel running, you might be able to muscle past the 3GB mark with a 
>> single R
>> > process.... with some work.
>> >
>> > [If the machine can actually "see" all 6GB of memory, you probably have a 
>> PAE
>> > kernel.]
>> >
>> > --e
>> >
>> 
>> Ironically enough, I *am* the systems people for the eSeries.... having
>> been a unix sysadmin and perl programmer before cutting and running for
>> social science :).. The kernel is PAE enabled, but that only helps with
>> seeing 6G altogether, not over 3G for a single process. I toyed with the
>> idea of whether I could break down the process into several threaded ones,
>> but that's way above my head.
>> 
>> (The Solaris cluster is university-run, though.)
>
> I haven't done a thorough analysis of the memory usage in lmer but I
> can make some informed guesses as to where memory can be saved.  The
> details of the implementation and the slots in the internal
> representation of the model are given in the "Implementation" vignette
> in the lme4 package.  At present there is only one small example shown
> in there but I will add others.
>
> For the model fitting process itself the largest object needed is the
> symmetric sparse matrix in the A slot and the Cholesky factor of the
> updated A*.  The dimension of that square matrix is the sum of the
> sizes of the random effects vector and the fixed effects vector plus 1
> (for the response).  Generally the Cholesky factor will be slightly
> larger than the A but care is taken to make the Cholesky factor as
> small as possible.
>
> I enclose an example from fitting a model with two random effects per
> student, one random effect per teacher and two random effects per
> school to the star (Tennessee's Student-Teacher Achievement Ratio
> study) data.  The dimension of the random effects will be 2*10732 +
> 1374 + 2 * 80 so that easily dominates the dimension of A.
>
> In this case the sizes of the slots L, A, ZXyt and frame are
> comparable.  However, if we strip things down to the bare essentials
> we don't need ZXyt, frame, flist, offset and weights after the matrix
> A has been constructed.
>
> The dimension of the matrices L and A is dominated by the dimension of
> the random effects vector.  The dimension of ZXyt, etc. involves the
> number of observations.  This might be good news in your case in that
> the sizes of the parts that must be preserved are dominated by the
> number of students and not the number of grades recorded.
>



From bates at stat.wisc.edu  Fri Mar  9 18:25:02 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 9 Mar 2007 11:25:02 -0600
Subject: [R-sig-ME] Model specification help
In-Reply-To: <Pine.LNX.4.64.0703091136270.21287@perrin.socsci.unc.edu>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com>
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu>
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org>
	<Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu>
	<40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com>
	<Pine.LNX.4.64.0703091136270.21287@perrin.socsci.unc.edu>
Message-ID: <40e66e0b0703090925i6f7faa2bife4c6e7f3c35ea75@mail.gmail.com>

On 3/9/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
> Update: I decided to run the lmer and lmer2 versions of the code you
> suggested simultaneously, on two machines:
>
> > grades.lmer<-lmer(grade.pt ~ (1|stud.id) + (1|instr.id) + (1|cour.dep),
> +                   newgrades.stripped.df,
> +                   control =
> +                   list(gradient = FALSE, niterEM = 0, msVerbose = 1)
> +                   )
>
>
> They are still working their way through, but I thought it was interesting
> that (a) lmer2 seems to be using less RAM, by roughly 0.3G; (b) even lmer
> seems well within the 3G limit, maxing out at about 1.6G so far; and (c)
> for the first iteration, there are both similarities and differences:

That's great news.  Would you be willing to give us an idea of the
number of observations and the number of levels for each of the
groups?  I don't imagine that this would violate confidentiality but
if you have misgivings it would be helpful even to have ballpark
estimates of the size of the problem.

> lmer:    0  3.66128e+06: 0.0865649 0.0125233 0.000161387
> lmer2:   0  3.66128e+06: 0.294219 0.111907 0.0127038

That's to be expected.  For a problem like this the parameters
optimized in lmer2 are on the scale of the relative standard deviation
of the random effects (relative to the standard deviation of the
residual noise component) whereas the parameters optimized in lmer are
on the scale of the relative  variance.  The starting values are
calculated the same way so at the first iteration the lmer values are
simply the squares of the lmer2 values

>  c(0.294219, 0.111907, 0.0127038)^2
[1] 0.0865648200 0.0125231766 0.0001613865

After the first iteration they will no longer correspond because the
iteration trajectories will be affected by the scaling.  I hope it
will be the case that lmer2 converges in fewer iterations than does
lmer.  I would appreciate knowing what the results are.

>
> (since I don't know what that diagnostic means, I can't determine whether
> to be worried about the difference or not!)
>
> More when the models finish.
>
> Andy
>
> ----------------------------------------------------------------------
> Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
> Assistant Professor of Sociology; Book Review Editor, _Social Forces_
> University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
> New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl
>
>
>
> On Fri, 9 Mar 2007, Douglas Bates wrote:
>
> > On 3/8/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
> >> On Thu, 8 Mar 2007, elw at stderr.org wrote:
> >>
> >> >
> >> >> Thank you for this. I will return to it tomorrow and let you know how it
> >> >> goes. As for the machine it's running on: it's a dual-Xeon 2.8Ghz IBM
> >> >> eseries server with 6GB RAM, running debian Linux, kernel 2.6.18.  So
> >> the
> >> >> 3GB per-process memory limit applies. I also have access to a shared
> >> server
> >> >> with "twenty-four 1.05 GHz Ultra-Sparc III+ processors and 40 GB of main
> >> >> memory" running solaris, if that's better.
> >> >
> >> > Andrew,
> >> >
> >> > That gets you onto a 64-bit platform, beyond the 32-bit-Intel 4GB memory
> >> (3G
> >> > for user process, 1G for OS kernel) limit, and beyond a bunch of other
> >> data
> >> > size limits.  The memory bandwidth available to you on the Solaris
> >> machine is
> >> > also likely to be much more significant - something that you will find
> >> quite
> >> > pleasant for even some more trivial analyses.  :)
> >> >
> >> > Much better, certainly!  [And very much like what 'beefy' R code is most
> >> > frequently run on...]
> >> >
> >> > W.r.t. the eSeries server you're commonly running on now - if you can
> >> have
> >> > your systems people check to make sure that you have a PAE-enabled linux
> >> > kernel running, you might be able to muscle past the 3GB mark with a
> >> single R
> >> > process.... with some work.
> >> >
> >> > [If the machine can actually "see" all 6GB of memory, you probably have a
> >> PAE
> >> > kernel.]
> >> >
> >> > --e
> >> >
> >>
> >> Ironically enough, I *am* the systems people for the eSeries.... having
> >> been a unix sysadmin and perl programmer before cutting and running for
> >> social science :).. The kernel is PAE enabled, but that only helps with
> >> seeing 6G altogether, not over 3G for a single process. I toyed with the
> >> idea of whether I could break down the process into several threaded ones,
> >> but that's way above my head.
> >>
> >> (The Solaris cluster is university-run, though.)
> >
> > I haven't done a thorough analysis of the memory usage in lmer but I
> > can make some informed guesses as to where memory can be saved.  The
> > details of the implementation and the slots in the internal
> > representation of the model are given in the "Implementation" vignette
> > in the lme4 package.  At present there is only one small example shown
> > in there but I will add others.
> >
> > For the model fitting process itself the largest object needed is the
> > symmetric sparse matrix in the A slot and the Cholesky factor of the
> > updated A*.  The dimension of that square matrix is the sum of the
> > sizes of the random effects vector and the fixed effects vector plus 1
> > (for the response).  Generally the Cholesky factor will be slightly
> > larger than the A but care is taken to make the Cholesky factor as
> > small as possible.
> >
> > I enclose an example from fitting a model with two random effects per
> > student, one random effect per teacher and two random effects per
> > school to the star (Tennessee's Student-Teacher Achievement Ratio
> > study) data.  The dimension of the random effects will be 2*10732 +
> > 1374 + 2 * 80 so that easily dominates the dimension of A.
> >
> > In this case the sizes of the slots L, A, ZXyt and frame are
> > comparable.  However, if we strip things down to the bare essentials
> > we don't need ZXyt, frame, flist, offset and weights after the matrix
> > A has been constructed.
> >
> > The dimension of the matrices L and A is dominated by the dimension of
> > the random effects vector.  The dimension of ZXyt, etc. involves the
> > number of observations.  This might be good news in your case in that
> > the sizes of the parts that must be preserved are dominated by the
> > number of students and not the number of grades recorded.
> >
>



From clists at perrin.socsci.unc.edu  Fri Mar  9 18:46:46 2007
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Fri, 9 Mar 2007 12:46:46 -0500 (EST)
Subject: [R-sig-ME] Model specification help
In-Reply-To: <40e66e0b0703090925i6f7faa2bife4c6e7f3c35ea75@mail.gmail.com>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu> 
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com> 
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu> 
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org> 
	<Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu> 
	<40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com> 
	<Pine.LNX.4.64.0703091136270.21287@perrin.socsci.unc.edu>
	<40e66e0b0703090925i6f7faa2bife4c6e7f3c35ea75@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703091243530.24431@perrin.socsci.unc.edu>

On Fri, 9 Mar 2007, Douglas Bates wrote:

> On 3/9/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
>> Update: I decided to run the lmer and lmer2 versions of the code you
>> suggested simultaneously, on two machines:
>> 
>> > grades.lmer<-lmer(grade.pt ~ (1|stud.id) + (1|instr.id) + (1|cour.dep),
>> +                   newgrades.stripped.df,
>> +                   control =
>> +                   list(gradient = FALSE, niterEM = 0, msVerbose = 1)
>> +                   )
>> 
>> 
>> They are still working their way through, but I thought it was interesting
>> that (a) lmer2 seems to be using less RAM, by roughly 0.3G; (b) even lmer
>> seems well within the 3G limit, maxing out at about 1.6G so far; and (c)
>> for the first iteration, there are both similarities and differences:
>
> That's great news.  Would you be willing to give us an idea of the
> number of observations and the number of levels for each of the
> groups?  I don't imagine that this would violate confidentiality but
> if you have misgivings it would be helpful even to have ballpark
> estimates of the size of the problem.


Sure, I don't think there's any confidentiality issue at this level of 
abstraction.  It's about 1.7 million observations on 54,711 unique 
students in 70,366 unique course sections. These are in 106 different 
departments taught by 7,964 unique instructors.

I will post comparative results whenever they're complete and I'm back in 
the office - likely Monday.

Thanks,
Andy

> length(newgrades.stripped.df$stud.id)
[1] 1721024
> length(levels(as.factor(newgrades.stripped.df$stud.id)))
[1] 54711
> length(levels(as.factor(newgrades.stripped.df$section)))
[1] 70366
> length(levels(as.factor(newgrades.stripped.df$instr.id)))
[1] 7964
> length(levels(as.factor(newgrades.stripped.df$cour.dep)))
[1] 106
>


----------------------------------------------------------------------
Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
Assistant Professor of Sociology; Book Review Editor, _Social Forces_
University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl

>
>> lmer:    0  3.66128e+06: 0.0865649 0.0125233 0.000161387
>> lmer2:   0  3.66128e+06: 0.294219 0.111907 0.0127038
>
> That's to be expected.  For a problem like this the parameters
> optimized in lmer2 are on the scale of the relative standard deviation
> of the random effects (relative to the standard deviation of the
> residual noise component) whereas the parameters optimized in lmer are
> on the scale of the relative  variance.  The starting values are
> calculated the same way so at the first iteration the lmer values are
> simply the squares of the lmer2 values
>
>>  c(0.294219, 0.111907, 0.0127038)^2
> [1] 0.0865648200 0.0125231766 0.0001613865
>
> After the first iteration they will no longer correspond because the
> iteration trajectories will be affected by the scaling.  I hope it
> will be the case that lmer2 converges in fewer iterations than does
> lmer.  I would appreciate knowing what the results are.
>
>> 
>> (since I don't know what that diagnostic means, I can't determine whether
>> to be worried about the difference or not!)
>> 
>> More when the models finish.
>> 
>> Andy
>> 
>> ----------------------------------------------------------------------
>> Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
>> Assistant Professor of Sociology; Book Review Editor, _Social Forces_
>> University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
>> New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl
>> 
>> 
>> 
>> On Fri, 9 Mar 2007, Douglas Bates wrote:
>> 
>> > On 3/8/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
>> >> On Thu, 8 Mar 2007, elw at stderr.org wrote:
>> >>
>> >> >
>> >> >> Thank you for this. I will return to it tomorrow and let you know how 
>> it
>> >> >> goes. As for the machine it's running on: it's a dual-Xeon 2.8Ghz IBM
>> >> >> eseries server with 6GB RAM, running debian Linux, kernel 2.6.18.  So
>> >> the
>> >> >> 3GB per-process memory limit applies. I also have access to a shared
>> >> server
>> >> >> with "twenty-four 1.05 GHz Ultra-Sparc III+ processors and 40 GB of 
>> main
>> >> >> memory" running solaris, if that's better.
>> >> >
>> >> > Andrew,
>> >> >
>> >> > That gets you onto a 64-bit platform, beyond the 32-bit-Intel 4GB 
>> memory
>> >> (3G
>> >> > for user process, 1G for OS kernel) limit, and beyond a bunch of other
>> >> data
>> >> > size limits.  The memory bandwidth available to you on the Solaris
>> >> machine is
>> >> > also likely to be much more significant - something that you will find
>> >> quite
>> >> > pleasant for even some more trivial analyses.  :)
>> >> >
>> >> > Much better, certainly!  [And very much like what 'beefy' R code is 
>> most
>> >> > frequently run on...]
>> >> >
>> >> > W.r.t. the eSeries server you're commonly running on now - if you can
>> >> have
>> >> > your systems people check to make sure that you have a PAE-enabled 
>> linux
>> >> > kernel running, you might be able to muscle past the 3GB mark with a
>> >> single R
>> >> > process.... with some work.
>> >> >
>> >> > [If the machine can actually "see" all 6GB of memory, you probably 
>> have a
>> >> PAE
>> >> > kernel.]
>> >> >
>> >> > --e
>> >> >
>> >>
>> >> Ironically enough, I *am* the systems people for the eSeries.... having
>> >> been a unix sysadmin and perl programmer before cutting and running for
>> >> social science :).. The kernel is PAE enabled, but that only helps with
>> >> seeing 6G altogether, not over 3G for a single process. I toyed with the
>> >> idea of whether I could break down the process into several threaded 
>> ones,
>> >> but that's way above my head.
>> >>
>> >> (The Solaris cluster is university-run, though.)
>> >
>> > I haven't done a thorough analysis of the memory usage in lmer but I
>> > can make some informed guesses as to where memory can be saved.  The
>> > details of the implementation and the slots in the internal
>> > representation of the model are given in the "Implementation" vignette
>> > in the lme4 package.  At present there is only one small example shown
>> > in there but I will add others.
>> >
>> > For the model fitting process itself the largest object needed is the
>> > symmetric sparse matrix in the A slot and the Cholesky factor of the
>> > updated A*.  The dimension of that square matrix is the sum of the
>> > sizes of the random effects vector and the fixed effects vector plus 1
>> > (for the response).  Generally the Cholesky factor will be slightly
>> > larger than the A but care is taken to make the Cholesky factor as
>> > small as possible.
>> >
>> > I enclose an example from fitting a model with two random effects per
>> > student, one random effect per teacher and two random effects per
>> > school to the star (Tennessee's Student-Teacher Achievement Ratio
>> > study) data.  The dimension of the random effects will be 2*10732 +
>> > 1374 + 2 * 80 so that easily dominates the dimension of A.
>> >
>> > In this case the sizes of the slots L, A, ZXyt and frame are
>> > comparable.  However, if we strip things down to the bare essentials
>> > we don't need ZXyt, frame, flist, offset and weights after the matrix
>> > A has been constructed.
>> >
>> > The dimension of the matrices L and A is dominated by the dimension of
>> > the random effects vector.  The dimension of ZXyt, etc. involves the
>> > number of observations.  This might be good news in your case in that
>> > the sizes of the parts that must be preserved are dominated by the
>> > number of students and not the number of grades recorded.
>> >
>> 
>



From otter at otter-rsch.com  Fri Mar  9 18:47:29 2007
From: otter at otter-rsch.com (dave fournier)
Date: Fri, 09 Mar 2007 09:47:29 -0800
Subject: [R-sig-ME]  heterogeneity in random effects variance
Message-ID: <45F19DB1.1050000@otter-rsch.com>

Hi Vito,

If you can't get satisfaction within R you should be able to do this 
easily with AD Model Builders random effects module.

    Dave
-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3S3
Canada
Phone/FAX 250-655-3364
http://otter-rsch.com



From clists at perrin.socsci.unc.edu  Mon Mar 12 13:53:16 2007
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Mon, 12 Mar 2007 08:53:16 -0400 (EDT)
Subject: [R-sig-ME] Model specification help
In-Reply-To: <40e66e0b0703090925i6f7faa2bife4c6e7f3c35ea75@mail.gmail.com>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu> 
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com> 
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu> 
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org> 
	<Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu> 
	<40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com> 
	<Pine.LNX.4.64.0703091136270.21287@perrin.socsci.unc.edu>
	<40e66e0b0703090925i6f7faa2bife4c6e7f3c35ea75@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703120851380.21116@perrin.socsci.unc.edu>

Sadly, the parsimonious model seems to have overwhelmed memory, both using 
lmer and lmer2:

> grades.lmer<-lmer(grade.pt ~ (1|stud.id) + (1|instr.id) + (1|cour.dep),
+                   newgrades.stripped.df,
+                   control =
+                   list(gradient = FALSE, niterEM = 0, msVerbose = 1)
+                   )
   0  3.66128e+06: 0.0865649 0.0125233 0.000161387
   1  3.57932e+06: 0.110177 0.0457235 0.999331
   2  3.44933e+06: 0.603073 0.129709 0.999302
   3  3.44882e+06: 0.604352 0.206648 0.997351
   4  3.44777e+06: 0.681062 0.200279 0.997066
   5  3.44748e+06: 0.736691 0.200143 0.989167
   6  3.44746e+06: 0.744199 0.198462 0.988935
   7  3.44744e+06: 0.759364 0.195889 0.988278
   8  3.44744e+06: 0.762290 0.196680 0.987739
   9  3.44744e+06: 0.764978 0.196422 0.986260
  10  3.44744e+06: 0.764321 0.197399 0.983415
  11  3.44744e+06: 0.763853 0.196192 0.980621
  12  3.44744e+06: 0.758416 0.196809 0.946310
  13  3.44744e+06: 0.758501 0.196269 0.911570
  14  3.44739e+06: 0.756907 0.193748 0.355670
  15  3.44738e+06: 0.761644 0.197153 0.320580
  16  3.44738e+06: 0.762348 0.195416 0.202269
  17  3.44738e+06: 0.765301 0.195340 0.219071
  18  3.44738e+06: 0.762698 0.197282 0.235819
  19  3.44738e+06: 0.764292 0.196909 0.226505
  20  3.44738e+06: 0.764221 0.196833 0.226059
Error: cannot allocate vector of size 505003 Kb




> grades.lmer2<-lmer2(grade.pt ~ (1|stud.id) + (1|instr.id) + 
(1|cour.dep),
+ newgrades.stripped.df,
+ control =
+ list(gradient = FALSE, niterEM = 0, msVerbose = 1))
   0  3.66128e+06: 0.294219 0.111907 0.0127038
   1  3.44990e+06: 0.759028 0.360622 0.862465
   2  3.44785e+06: 0.933722 0.418394 0.797191
   3  3.44743e+06: 0.872076 0.462189 0.792549
   4  3.44742e+06: 0.876257 0.448197 0.791479
   5  3.44741e+06: 0.873351 0.445076 0.790576
   6  3.44741e+06: 0.874786 0.443924 0.789611
   7  3.44741e+06: 0.873415 0.443482 0.788113
   8  3.44741e+06: 0.874736 0.443449 0.786510
   9  3.44741e+06: 0.873514 0.443352 0.782539
  10  3.44740e+06: 0.874955 0.434554 0.666426
  11  3.44738e+06: 0.874233 0.446203 0.550557
  12  3.44738e+06: 0.876339 0.439541 0.434311
  13  3.44738e+06: 0.872474 0.444317 0.481580
  14  3.44738e+06: 0.875574 0.444679 0.485606
  15  3.44738e+06: 0.874206 0.444010 0.483564
  16  3.44738e+06: 0.874194 0.443919 0.478097
  17  3.44738e+06: 0.874232 0.443418 0.475652
  18  3.44738e+06: 0.874182 0.443707 0.474796
  19  3.44738e+06: 0.874195 0.443675 0.475530
  20  3.44738e+06: 0.874195 0.443669 0.475407
Error: cannot allocate vector of size 538066 Kb




I'm going to try to start the same job on the solaris machine, but expect 
to have some problems because I don't have root access there.  Will let 
you know how it goes.

Thanks,
Andy

----------------------------------------------------------------------
Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
Assistant Professor of Sociology; Book Review Editor, _Social Forces_
University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl



From bates at stat.wisc.edu  Mon Mar 12 14:26:43 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 Mar 2007 08:26:43 -0500
Subject: [R-sig-ME] Model specification help
In-Reply-To: <Pine.LNX.4.64.0703120851380.21116@perrin.socsci.unc.edu>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com>
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu>
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org>
	<Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu>
	<40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com>
	<Pine.LNX.4.64.0703091136270.21287@perrin.socsci.unc.edu>
	<40e66e0b0703090925i6f7faa2bife4c6e7f3c35ea75@mail.gmail.com>
	<Pine.LNX.4.64.0703120851380.21116@perrin.socsci.unc.edu>
Message-ID: <40e66e0b0703120626j4772f53jcbb60ef69d3e584f@mail.gmail.com>

I am experimenting with a version of lmer2 that should not use more
memory after the initial setup. This version requires a recent
development version of R-2.5.0.  I'll check the sources for the
package into the SVN archive.

https://svn.r-project.org/R-packages/trunk/lme4

The SVN archive for the development version of R is

https://svn.r-project.org/R/trunk

Please be warned that I may need to make an adjustment in the way that
lme4 gets its header files.  If so I will announce on this list that
you need to update both lme4 and R-devel.


On 3/12/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
> Sadly, the parsimonious model seems to have overwhelmed memory, both using
> lmer and lmer2:
>
> > grades.lmer<-lmer(grade.pt ~ (1|stud.id) + (1|instr.id) + (1|cour.dep),
> +                   newgrades.stripped.df,
> +                   control =
> +                   list(gradient = FALSE, niterEM = 0, msVerbose = 1)
> +                   )
>    0  3.66128e+06: 0.0865649 0.0125233 0.000161387
>    1  3.57932e+06: 0.110177 0.0457235 0.999331
>    2  3.44933e+06: 0.603073 0.129709 0.999302
>    3  3.44882e+06: 0.604352 0.206648 0.997351
>    4  3.44777e+06: 0.681062 0.200279 0.997066
>    5  3.44748e+06: 0.736691 0.200143 0.989167
>    6  3.44746e+06: 0.744199 0.198462 0.988935
>    7  3.44744e+06: 0.759364 0.195889 0.988278
>    8  3.44744e+06: 0.762290 0.196680 0.987739
>    9  3.44744e+06: 0.764978 0.196422 0.986260
>   10  3.44744e+06: 0.764321 0.197399 0.983415
>   11  3.44744e+06: 0.763853 0.196192 0.980621
>   12  3.44744e+06: 0.758416 0.196809 0.946310
>   13  3.44744e+06: 0.758501 0.196269 0.911570
>   14  3.44739e+06: 0.756907 0.193748 0.355670
>   15  3.44738e+06: 0.761644 0.197153 0.320580
>   16  3.44738e+06: 0.762348 0.195416 0.202269
>   17  3.44738e+06: 0.765301 0.195340 0.219071
>   18  3.44738e+06: 0.762698 0.197282 0.235819
>   19  3.44738e+06: 0.764292 0.196909 0.226505
>   20  3.44738e+06: 0.764221 0.196833 0.226059
> Error: cannot allocate vector of size 505003 Kb
>
>
>
>
> > grades.lmer2<-lmer2(grade.pt ~ (1|stud.id) + (1|instr.id) +
> (1|cour.dep),
> + newgrades.stripped.df,
> + control =
> + list(gradient = FALSE, niterEM = 0, msVerbose = 1))
>    0  3.66128e+06: 0.294219 0.111907 0.0127038
>    1  3.44990e+06: 0.759028 0.360622 0.862465
>    2  3.44785e+06: 0.933722 0.418394 0.797191
>    3  3.44743e+06: 0.872076 0.462189 0.792549
>    4  3.44742e+06: 0.876257 0.448197 0.791479
>    5  3.44741e+06: 0.873351 0.445076 0.790576
>    6  3.44741e+06: 0.874786 0.443924 0.789611
>    7  3.44741e+06: 0.873415 0.443482 0.788113
>    8  3.44741e+06: 0.874736 0.443449 0.786510
>    9  3.44741e+06: 0.873514 0.443352 0.782539
>   10  3.44740e+06: 0.874955 0.434554 0.666426
>   11  3.44738e+06: 0.874233 0.446203 0.550557
>   12  3.44738e+06: 0.876339 0.439541 0.434311
>   13  3.44738e+06: 0.872474 0.444317 0.481580
>   14  3.44738e+06: 0.875574 0.444679 0.485606
>   15  3.44738e+06: 0.874206 0.444010 0.483564
>   16  3.44738e+06: 0.874194 0.443919 0.478097
>   17  3.44738e+06: 0.874232 0.443418 0.475652
>   18  3.44738e+06: 0.874182 0.443707 0.474796
>   19  3.44738e+06: 0.874195 0.443675 0.475530
>   20  3.44738e+06: 0.874195 0.443669 0.475407
> Error: cannot allocate vector of size 538066 Kb
>
>
>
>
> I'm going to try to start the same job on the solaris machine, but expect
> to have some problems because I don't have root access there.  Will let
> you know how it goes.
>
> Thanks,
> Andy
>
> ----------------------------------------------------------------------
> Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
> Assistant Professor of Sociology; Book Review Editor, _Social Forces_
> University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
> New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl
>
>
>
>



From clists at perrin.socsci.unc.edu  Mon Mar 12 15:36:10 2007
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Mon, 12 Mar 2007 10:36:10 -0400 (EDT)
Subject: [R-sig-ME] Model specification help
In-Reply-To: <40e66e0b0703120626j4772f53jcbb60ef69d3e584f@mail.gmail.com>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu> 
	<40e66e0b0703081436y30590e48v44b941aa6222b1a@mail.gmail.com> 
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu> 
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org> 
	<Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu> 
	<40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com> 
	<Pine.LNX.4.64.0703091136270.21287@perrin.socsci.unc.edu> 
	<40e66e0b0703090925i6f7faa2bife4c6e7f3c35ea75@mail.gmail.com> 
	<Pine.LNX.4.64.0703120851380.21116@perrin.socsci.unc.edu>
	<40e66e0b0703120626j4772f53jcbb60ef69d3e584f@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703121035220.21116@perrin.socsci.unc.edu>

Update: I tried the same model on a 10-percent random sample and it 
completed fine:

> grades.10pct.lmer<-lmer(grade.pt ~ (1|stud.id) + (1|instr.id) + 
(1|cour.dep),n
ewgrades.10pct,control=list(gradient = FALSE, niterEM = 0, msVerbose = 1))
   0      368526.: 0.114490 0.0870205 0.00154286
   1      353650.: 0.125362 0.292639 0.980115
   2      351398.: 0.222252 0.783158 0.978312
   3      351303.: 0.186460 0.779040 0.977594
   4      351290.: 0.151424 0.770734 0.976153
   5      351274.: 0.168863 0.739213 0.975204
   6      351273.: 0.161381 0.726354 0.973485
   7      351273.: 0.166878 0.716955 0.963202
   8      351269.: 0.167807 0.742046 0.904732
   9      351269.: 0.162145 0.739476 0.903375
  10      351268.: 0.165429 0.737807 0.898187
  11      351238.: 0.165235 0.751137 0.505946
  12      351233.: 0.158653 0.728281 0.461245
  13      351223.: 0.162827 0.729269 0.360067
  14      351221.: 0.165015 0.728947 0.324127
  15      351219.: 0.158737 0.728858 0.252385
  16      351218.: 0.169401 0.730054 0.229288
  17      351217.: 0.164054 0.726687 0.217478
  18      351217.: 0.163587 0.723005 0.242674
  19      351217.: 0.164458 0.725164 0.235951
  20      351217.: 0.164303 0.725227 0.234643
  21      351217.: 0.164319 0.725163 0.234738
> summary(grades.10pct.lmer)
Linear mixed-effects model fit by REML
Formula: grade.pt ~ (1 | stud.id) + (1 | instr.id) + (1 | cour.dep)
    Data: newgrades.10pct
     AIC    BIC  logLik MLdeviance REMLdeviance
  351225 351265 -175608     351212       351217
Random effects:
  Groups   Name        Variance Std.Dev.
  instr.id (Intercept) 0.067380 0.25958
  stud.id  (Intercept) 0.297357 0.54530
  cour.dep (Intercept) 0.096256 0.31025
  Residual             0.410055 0.64036
number of obs: 167654, groups: instr.id, 7198; stud.id, 5471; cour.dep, 97

Fixed effects:
             Estimate Std. Error t value
(Intercept)  3.19796    0.03476   92.01


----------------------------------------------------------------------
Andrew J Perrin - andrew_perrin (at) unc.edu - http://perrin.socsci.unc.edu
Assistant Professor of Sociology; Book Review Editor, _Social Forces_
University of North Carolina - CB#3210, Chapel Hill, NC 27599-3210 USA
New Book: http://www.press.uchicago.edu/cgi-bin/hfs.cgi/00/178592.ctl



From bates at stat.wisc.edu  Mon Mar 12 16:32:57 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 Mar 2007 10:32:57 -0500
Subject: [R-sig-ME] Model specification help
In-Reply-To: <Pine.LNX.4.64.0703121035220.21116@perrin.socsci.unc.edu>
References: <Pine.LNX.4.64.0703081546180.6222@perrin.socsci.unc.edu>
	<Pine.LNX.4.64.0703082036460.18207@perrin.socsci.unc.edu>
	<Pine.LNX.4.64.0703082148360.467@illuminati.stderr.org>
	<Pine.LNX.4.64.0703082139380.18207@perrin.socsci.unc.edu>
	<40e66e0b0703090545n4ff3901k736d77efe2f6e549@mail.gmail.com>
	<Pine.LNX.4.64.0703091136270.21287@perrin.socsci.unc.edu>
	<40e66e0b0703090925i6f7faa2bife4c6e7f3c35ea75@mail.gmail.com>
	<Pine.LNX.4.64.0703120851380.21116@perrin.socsci.unc.edu>
	<40e66e0b0703120626j4772f53jcbb60ef69d3e584f@mail.gmail.com>
	<Pine.LNX.4.64.0703121035220.21116@perrin.socsci.unc.edu>
Message-ID: <40e66e0b0703120832l68229b07xade8ef99d2e9076@mail.gmail.com>

On 3/12/07, Andrew Perrin <clists at perrin.socsci.unc.edu> wrote:
> Update: I tried the same model on a 10-percent random sample and it
> completed fine:
>
> > grades.10pct.lmer<-lmer(grade.pt ~ (1|stud.id) + (1|instr.id) +
> (1|cour.dep),n
> ewgrades.10pct,control=list(gradient = FALSE, niterEM = 0, msVerbose = 1))
>    0      368526.: 0.114490 0.0870205 0.00154286
>    1      353650.: 0.125362 0.292639 0.980115
>    2      351398.: 0.222252 0.783158 0.978312
>    3      351303.: 0.186460 0.779040 0.977594
>    4      351290.: 0.151424 0.770734 0.976153
>    5      351274.: 0.168863 0.739213 0.975204
>    6      351273.: 0.161381 0.726354 0.973485
>    7      351273.: 0.166878 0.716955 0.963202
>    8      351269.: 0.167807 0.742046 0.904732
>    9      351269.: 0.162145 0.739476 0.903375
>   10      351268.: 0.165429 0.737807 0.898187
>   11      351238.: 0.165235 0.751137 0.505946
>   12      351233.: 0.158653 0.728281 0.461245
>   13      351223.: 0.162827 0.729269 0.360067
>   14      351221.: 0.165015 0.728947 0.324127
>   15      351219.: 0.158737 0.728858 0.252385
>   16      351218.: 0.169401 0.730054 0.229288
>   17      351217.: 0.164054 0.726687 0.217478
>   18      351217.: 0.163587 0.723005 0.242674
>   19      351217.: 0.164458 0.725164 0.235951
>   20      351217.: 0.164303 0.725227 0.234643
>   21      351217.: 0.164319 0.725163 0.234738
> > summary(grades.10pct.lmer)
> Linear mixed-effects model fit by REML
> Formula: grade.pt ~ (1 | stud.id) + (1 | instr.id) + (1 | cour.dep)
>     Data: newgrades.10pct
>      AIC    BIC  logLik MLdeviance REMLdeviance
>   351225 351265 -175608     351212       351217
> Random effects:
>   Groups   Name        Variance Std.Dev.
>   instr.id (Intercept) 0.067380 0.25958
>   stud.id  (Intercept) 0.297357 0.54530
>   cour.dep (Intercept) 0.096256 0.31025
>   Residual             0.410055 0.64036
> number of obs: 167654, groups: instr.id, 7198; stud.id, 5471; cour.dep, 97
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  3.19796    0.03476   92.01

The fact that this fit converged in 21 iterations and the earlier fits
to the full data set ran out of memory after 20 iterations makes me
suspect that the memory problem is not in the convergence but in the
construction of the object to be returned.  Right now the only way to
cut down on the size of that object is to use the optional argument
frame = FALSE in the call to lmer or lmer2.

If you have a chance to do a traceback on a fit that runs out of
memory, it would be very valuable to know if the insufficient memory
condition occurred within the call to nlminb (lmer or old version of
lmer2) or .Call(mer2_optimize, mer, cv$msVerbose) (new version of
lmer2) versus within a call to new.  I suspect it is the latter.



From imendoza at ugr.es  Mon Mar 12 21:29:03 2007
From: imendoza at ugr.es (Irene Mendoza Sagrera)
Date: Mon, 12 Mar 2007 21:29:03 +0100
Subject: [R-sig-ME] interpretation of split-plot design with results from
	lmer
Message-ID: <45F5B80F.1000304@ugr.es>

Dear lmer-users:

After having reading as many documents as I could about the lmer 
function and the lack of p-values, I need to recognize that I haven?t 
understood the right way of extracting conclusions when using the lmer 
function. Maybe I would need more statistical knowledge or read any 
other book (please, any suggestion?), but if you give me any help, I 
would be very grateful.

I?m trying to analyze a field experiment with a split-plot design. We 
have selected 9 plots of similar area in field: 3 of them were woodland, 
3 were shrubland, and the other 3 were open areas. In each plot, we set 
up 20 subplots: 10 of them were regularly watered and the other 10 were 
control. In each subplot, we sowed seeds of 5 species, each species 
protected by a mesh cage. The number of seeds sowed in each cage was 
different for each species, ranging from 5 to 15 seeds. So, there are 
three fixed factors (habitat, species, and watering) and two random 
factors (plot, subplot). I have labelled each plot (n=9) and each 
subplot (n=180) with a different number per each variable. I consider 
that the seeds sowed in the same cage are not independent, so I used the 
counts of emerged/survived seeds per cage as response variable.



>  str(data)

'data.frame': 900 obs. of 7 variables:

$ plot : Factor w/ 9 levels "B1","B2","B3",..: 1 1 1 1 1 1 1 1 1 1 ...

$ habitat : Factor w/ 3 levels "Open","Shrubland",..: 1 1 1 1 1 1 1 1 1 
1 ...

$ watering : Factor w/ 2 levels "C","W": 2 2 2 2 2 2 2 2 2 2 ...

$ subplot : Factor w/ 180 levels "1","2","3","4",..: 1 1 1 1 1 2 2 2 2 2 ...

$ species : Factor w/ 5 levels "arce","encina",..: 1 2 3 4 5 1 2 3 4 5 ...

$ emerged : int 3 2 6 1 3 0 3 1 2 2 ...

$ nonemerged: int 12 3 9 4 12 15 2 14 3 13 ...

>



Both types of response variables I am interested in (emergence and 
surviva) follow a binomial distribution. My question is: is there any 
effect of the habitat, the watering treatment and the species identity 
for the emergence/survival of seedlings? To answer this question, I 
think the best way is using lmer as follows:



>  emerg1<-lmer(cbind(data$emerged,data$nonemerg)~ habitat * species *
>  watering + (1|plot) + (1|subplot), data = data, family = binomial)

>  summary (emerg1)
Generalized linear mixed model fit using Laplace
Formula: cbind(data$emerged, data$nonemerg) ~ habitat * species * 
watering + (1 | plot) + (1 | subplot)
Data: data
Family: binomial(logit link)
AIC BIC logLik deviance
2048 2202 -992.2 1984
Random effects:
Groups Name Variance Std.Dev.
subplot (Intercept) 0.08740 0.29564
plot (Intercept) 0.15162 0.38939
number of obs: 900, groups: subplot, 180; plot, 9

Estimated scale (compare to 1 ) 1.341165

Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -2.2724 0.2811 -8.084 6.25e-16 ***
habitatShrubland -0.2837 0.4050 -0.700 0.48363
habitatWoodland -0.1464 0.4005 -0.365 0.71479
speciesencina 2.2170 0.2302 9.630 < 2e-16 ***
speciespino 2.6165 0.1872 13.976 < 2e-16 ***
speciesroble 1.9082 0.2318 8.231 < 2e-16 ***
speciessorbus 0.4327 0.2093 2.068 0.03865 *
wateringW -0.2848 0.2513 -1.133 0.25702
habitatShrubland:speciesencina -0.2105 0.3383 -0.622 0.53371
habitatWoodland:speciesencina 0.1260 0.3302 0.382 0.70272
habitatShrubland:speciespino 0.7979 0.2792 2.858 0.00427 **
habitatWoodland:speciespino -0.7454 0.2698 -2.763 0.00573 **
habitatShrubland:speciesroble 0.2184 0.3383 0.645 0.51868
habitatWoodland:speciesroble 0.1152 0.3331 0.346 0.72954
habitatShrubland:speciessorbus 0.4873 0.3016 1.616 0.10612
habitatWoodland:speciessorbus 0.7417 0.2902 2.556 0.01059 *
habitatShrubland:wateringW 0.4320 0.3588 1.204 0.22866
habitatWoodland:wateringW 0.4770 0.3477 1.372 0.17011
speciesencina:wateringW 0.6484 0.3364 1.927 0.05392 .
speciespino:wateringW 0.2311 0.2762 0.837 0.40277
speciesroble:wateringW 0.1911 0.3383 0.565 0.57220
speciessorbus:wateringW 0.4430 0.3032 1.461 0.14397
habitatShrubland:speciesencina:wateringW -0.5240 0.4806 -1.090 0.27551
habitatWoodland:speciesencina:wateringW -0.6012 0.4703 -1.278 0.20120
habitatShrubland:speciespino:wateringW -0.2279 0.3988 -0.572 0.56764
habitatWoodland:speciespino:wateringW -0.2531 0.3842 -0.659 0.50999
habitatShrubland:speciesroble:wateringW -0.1877 0.4811 -0.390 0.69640
habitatWoodland:speciesroble:wateringW -1.0787 0.4813 -2.241 0.02502 *
habitatShrubland:speciessorbus:wateringW -0.5306 0.4276 -1.241 0.21459
habitatWoodland:speciessorbus:wateringW -0.1205 0.4083 -0.295 0.76791
---
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

.....



 > library(coda)
 > A<-mcmcsamp(emerg1,50000)
 > summary(A)


Iterations = 1:50000
Thinning interval = 1
Number of chains = 1
Sample size per chain = 50000

1. Empirical mean and standard deviation for each variable,
plus standard error of the mean:

Mean SD Naive SE Time-series SE
(Intercept) -2.2730 0.3903 0.0017456 0.003199
habitatShrubland -0.3034 0.5584 0.0024972 0.003928
habitatWoodland -0.1641 0.5554 0.0024839 0.005055
speciesencina 2.2197 0.2319 0.0010373 0.001756
speciespino 2.6208 0.1879 0.0008401 0.001669
speciesroble 1.9081 0.2323 0.0010390 0.001778
speciessorbus 0.4299 0.2092 0.0009355 0.001784
wateringW -0.2991 0.2504 0.0011199 0.002122
habitatShrubland:speciesencina -0.1947 0.3387 0.0015145 0.002391
habitatWoodland:speciesencina 0.1405 0.3329 0.0014886 0.002777
habitatShrubland:speciespino 0.8186 0.2821 0.0012618 0.002427
habitatWoodland:speciespino -0.7339 0.2710 0.0012118 0.002166
habitatShrubland:speciesroble 0.2349 0.3413 0.0015264 0.002496
habitatWoodland:speciesroble 0.1314 0.3341 0.0014942 0.002882
habitatShrubland:speciessorbus 0.5014 0.3041 0.0013601 0.002638
habitatWoodland:speciessorbus 0.7566 0.2914 0.0013032 0.002556
habitatShrubland:wateringW 0.4585 0.3603 0.0016115 0.003373
habitatWoodland:wateringW 0.5003 0.3461 0.0015480 0.003174
speciesencina:wateringW 0.6698 0.3382 0.0015127 0.002629
speciespino:wateringW 0.2466 0.2746 0.0012283 0.002280
speciesroble:wateringW 0.2063 0.3367 0.0015059 0.002922
speciessorbus:wateringW 0.4587 0.3028 0.0013541 0.002368
habitatShrubland:speciesencina:wateringW -0.5593 0.4800 0.0021466 0.004227
habitatWoodland:speciesencina:wateringW -0.6300 0.4727 0.0021138 0.003775
habitatShrubland:speciespino:wateringW -0.2546 0.3986 0.0017826 0.003616
habitatWoodland:speciespino:wateringW -0.2791 0.3831 0.0017135 0.003225
habitatShrubland:speciesroble:wateringW -0.2116 0.4841 0.0021648 0.004105
habitatWoodland:speciesroble:wateringW -1.1116 0.4825 0.0021577 0.004582
habitatShrubland:speciessorbus:wateringW -0.5540 0.4278 0.0019133 0.003664
habitatWoodland:speciessorbus:wateringW -0.1416 0.4077 0.0018232 0.003570
log(sbpl.(In)) -2.4073 0.2585 0.0011562 0.005921
log(plot.(In)) -1.2932 0.6567 0.0029369 0.006396

2. Quantiles for each variable:

2.5% 25% 50% 75% 97.5%
(Intercept) -3.04171 -2.506810 -2.2708 -2.03446 -1.5193
habitatShrubland -1.38115 -0.646627 -0.3015 0.02902 0.7991
habitatWoodland -1.26227 -0.501688 -0.1663 0.16544 0.9489
speciesencina 1.77105 2.060916 2.2197 2.37579 2.6798
speciespino 2.26105 2.495121 2.6158 2.74363 3.0019
speciesroble 1.45680 1.751212 1.9071 2.06305 2.3624
speciessorbus 0.02693 0.287434 0.4281 0.56880 0.8456
wateringW -0.79641 -0.469682 -0.2973 -0.12805 0.1822
habitatShrubland:speciesencina -0.85631 -0.424483 -0.1910 0.03690 0.4640
habitatWoodland:speciesencina -0.51369 -0.081558 0.1417 0.36531 0.7943
habitatShrubland:speciespino 0.26948 0.628067 0.8161 1.00870 1.3755
habitatWoodland:speciespino -1.26446 -0.916398 -0.7333 -0.55441 -0.2018
habitatShrubland:speciesroble -0.43404 0.002914 0.2329 0.46687 0.9052
habitatWoodland:speciesroble -0.51401 -0.098191 0.1332 0.35979 0.7730
habitatShrubland:speciessorbus -0.09194 0.295077 0.5010 0.70509 1.0973
habitatWoodland:speciessorbus 0.18432 0.558907 0.7553 0.95078 1.3234
habitatShrubland:wateringW -0.25126 0.218858 0.4567 0.69857 1.1727
habitatWoodland:wateringW -0.17991 0.264459 0.5001 0.72907 1.1924
speciesencina:wateringW 0.01156 0.437409 0.6705 0.89904 1.3409
speciespino:wateringW -0.28788 0.059775 0.2445 0.43289 0.7807
speciesroble:wateringW -0.44262 -0.021072 0.2011 0.42942 0.8769
speciessorbus:wateringW -0.12375 0.248090 0.4556 0.66512 1.0558
habitatShrubland:speciesencina:wateringW -1.50154 -0.886472 -0.5554 
-0.23413 0.3715
habitatWoodland:speciesencina:wateringW -1.55928 -0.942517 -0.6263 
-0.31732 0.2906
habitatShrubland:speciespino:wateringW -1.02972 -0.524534 -0.2583 
0.01483 0.5318
habitatWoodland:speciespino:wateringW -1.03432 -0.536075 -0.2782 
-0.02089 0.4624
habitatShrubland:speciesroble:wateringW -1.16509 -0.538283 -0.2073 
0.10929 0.7355
habitatWoodland:speciesroble:wateringW -2.05038 -1.439554 -1.1132 
-0.78493 -0.1720
habitatShrubland:speciessorbus:wateringW -1.39134 -0.841315 -0.5548 
-0.26179 0.2815
habitatWoodland:speciessorbus:wateringW -0.94322 -0.415447 -0.1360 
0.13537 0.6568
log(sbpl.(In)) -2.95653 -2.567736 -2.3935 -2.22955 -1.9423
log(plot.(In)) -2.41148 -1.753486 -1.3534 -0.89638 0.1613


 > HPDinterval(A)
lower upper
(Intercept) -3.02693912 -1.50685625
habitatShrubland -1.37402561 0.80185848
habitatWoodland -1.28262371 0.92217838
speciesencina 1.77588054 2.68156075
speciespino 2.24528494 2.98347131
speciesroble 1.45458293 2.35890008
speciessorbus 0.02277444 0.83992583
wateringW -0.79840382 0.17786065
habitatShrubland:speciesencina -0.87303659 0.44080390
habitatWoodland:speciesencina -0.47325939 0.82869813
habitatShrubland:speciespino 0.26283252 1.36579201
habitatWoodland:speciespino -1.26969655 -0.20969532
habitatShrubland:speciesroble -0.44787916 0.89012541
habitatWoodland:speciesroble -0.50423916 0.78148583
habitatShrubland:speciessorbus -0.09267742 1.09603954
habitatWoodland:speciessorbus 0.18433471 1.32351169
habitatShrubland:wateringW -0.26481667 1.15194682
habitatWoodland:wateringW -0.15799665 1.20945912
speciesencina:wateringW 0.02501399 1.34820459
speciespino:wateringW -0.29087519 0.77543688
speciesroble:wateringW -0.44362264 0.87502474
speciessorbus:wateringW -0.11402239 1.06217002
habitatShrubland:speciesencina:wateringW -1.48872380 0.38175569
habitatWoodland:speciesencina:wateringW -1.54261721 0.30557576
habitatShrubland:speciespino:wateringW -1.01824049 0.53687967
habitatWoodland:speciespino:wateringW -1.03432105 0.46236822
habitatShrubland:speciesroble:wateringW -1.17560521 0.72330469
habitatWoodland:speciesroble:wateringW -2.05138457 -0.17460151
habitatShrubland:speciessorbus:wateringW -1.39314261 0.27800441
habitatWoodland:speciessorbus:wateringW -0.93252386 0.66400031
log(sbpl.(In)) -2.92059137 -1.91602692
log(plot.(In)) -2.49817299 0.03793472
attr(,"Probability")
[1] 0.95
 >



Sincerely, for me now is the great deal. Without any p-value, how can I 
know if a fixed factor is significant for the response variable? What is 
the interpretation of these results? How I should present the 
information in a correct way to editors and referees (and for me, to 
understanding the effects)?

I am afraid you maybe have answered this a thousand times, but I have 
read the wiki about lmer 
(http://wiki.r-project.org/rwiki/doku.php?id=guides:lmer-tests&s=lme%20and%20aov) 
and the discussion about the p-values, and I still feel confused with 
the interpretation of results. Do you still think that it is correct the 
mcmcpvalue function written by Douglas Bates? Any help is welcome.

Thanks a lot!

Greetings,

Irene


-- 
Irene Mendoza Sagrera
PhD Student
Terrestrial Ecology Group.
University of Granada (Spain)

Departamento de Ecolog?a
Facultad de Ciencias.
Campus de Fuentenueva, s/n.
Universidad de Granada, 18071.
Granada, Spain

Phone: +34 958 243242
Fax: +34 958 243238

website www.ugr.es/~rnm220
website www.ugr.es/~redbome



From austin.frank at gmail.com  Tue Mar 13 01:17:00 2007
From: austin.frank at gmail.com (Austin Frank)
Date: Mon, 12 Mar 2007 20:17:00 -0400
Subject: [R-sig-ME] interpretation of split-plot design with results
	from lmer
References: <45F5B80F.1000304@ugr.es>
Message-ID: <m0fy8akner.fsf@gmail.com>

On Mon, Mar 12 2007, Irene Mendoza Sagrera wrote:

> After having reading as many documents as I could about the lmer
> function and the lack of p-values, I need to recognize that I
> haven?t understood the right way of extracting conclusions when
> using the lmer function. Maybe I would need more statistical
> knowledge or read any other book (please, any suggestion?), but if
> you give me any help, I would be very grateful.

> I?m trying to analyze a field experiment with a split-plot design.
> ...
>
> Sincerely, for me now is the great deal. Without any p-value, how
> can I know if a fixed factor is significant for the response
> variable? What is the interpretation of these results? How I should
> present the information in a correct way to editors and referees
> (and for me, to understanding the effects)?

Irene--

While the examples won't be directly related to your field, I have
found that a paper by Baayen, Davidson, and Bates has a very clear
presentation of the analysis of a split-plot design with lme4.  In
addition, the article has a corresponding R package called languageR
that provides some functionality that would be useful in answering
your main question.  Taken together, I think the paper and the R
package are a very useful addition to the available materials on mixed
effects models.  I'm grateful to the authors for putting both
together!

You can find the submitted pdf on Baayen's publications page, at
http://www.mpi.nl/world/persons/private/baayen/publications/baayenDavidsonBates.pdf.

Good luck with your analysis!
/au

-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From kw.statr at gmail.com  Tue Mar 13 19:51:53 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Tue, 13 Mar 2007 13:51:53 -0500
Subject: [R-sig-ME] Crossed random effects
Message-ID: <c968588d0703131151m2ef5fbbfx7292d32b62273375@mail.gmail.com>

I am confused by some apparent contradictions about fitting crossed
random effects in software.  Consider this quote from
http://www.mpi.nl/world/persons/private/baayen/publications/baayenDavidsonBates.pdf
"To our knowledge, the only software currently available for fitting
mixed-effects models with crossed random effects is the lme4 package"

Yet, nlme and GLIMMIX appear to claim that crossed-random effects can
be fit by those respective tools:

In Mixed Effects Models in S and S-Plus:
"The crossed random-effects structure is represented in lme by a
combination of pdBlocke3d and pdIdent objects" (page 163)

http://support.sas.com/rnd/app/papers/glimmix.pdf
"The GLIMMIX procedure, on the other hand, determines by default the
marginal log likelihood as that of an approximate linear mixed model.
This allows multiple random effects, nested and crossed random
effects, multiple cluster types, and R-side random components."  [and]
 "Example 2. Mating Experiment with Crossed Random Effects"

Are these three quotes using different definitions of "crossed random
effects"?  Have I taken the quotes out of context?  Any clarifications
would be appreciated.

Thanks,

K Wright



From bates at stat.wisc.edu  Tue Mar 13 20:31:56 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 Mar 2007 14:31:56 -0500
Subject: [R-sig-ME] Crossed random effects
In-Reply-To: <c968588d0703131151m2ef5fbbfx7292d32b62273375@mail.gmail.com>
References: <c968588d0703131151m2ef5fbbfx7292d32b62273375@mail.gmail.com>
Message-ID: <40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>

On 3/13/07, Kevin Wright <kw.statr at gmail.com> wrote:
> I am confused by some apparent contradictions about fitting crossed
> random effects in software.  Consider this quote from
> http://www.mpi.nl/world/persons/private/baayen/publications/baayenDavidsonBates.pdf
> "To our knowledge, the only software currently available for fitting
> mixed-effects models with crossed random effects is the lme4 package"

That statement should have been more carefully worded.  It is in
reference to the types of experimental situations described in that
paper where random effects are associated with subject and item,
subjects are crossed with item and the numbers of both the subjects
and the items can be very large.

> Yet, nlme and GLIMMIX appear to claim that crossed-random effects can
> be fit by those respective tools:
>
> In Mixed Effects Models in S and S-Plus:
> "The crossed random-effects structure is represented in lme by a
> combination of pdBlocke3d and pdIdent objects" (page 163)

It is possible to fit a model with crossed random effects with lme
provided that the number of levels of both of the crossed factors is
small.  Otherwise you end up with huge, sparse model matrices that are
being treated as dense matrices and you quickly run out of memory or
time or both.

Really, doesn't a random effects specification like
pdBlocked(list(pdIdent(~ rows - 1), pdIdent(~ columns - 1))) smell
like a kludge to you?

> http://support.sas.com/rnd/app/papers/glimmix.pdf
> "The GLIMMIX procedure, on the other hand, determines by default the
> marginal log likelihood as that of an approximate linear mixed model.
> This allows multiple random effects, nested and crossed random
> effects, multiple cluster types, and R-side random components."  [and]
>  "Example 2. Mating Experiment with Crossed Random Effects"

I think that several readers of this list could tell you war stories
of trying to fit models with crossed random effects using SAS PROC
MIXED or SAS PROC NLMIXED versus fitting the same model in lmer or
lmer2.  You are correct that one can specify a model with crossed
random effects in SAS PROC MIXED and that we overstated the uniqueness
of the capabilities of lmer to fit such models.  However, if you want
to try to fit such a model in SAS PROC MIXED when you have large
numbers of subjects and large numbers of items you had better be
prepared to wait for a long time.


> Are these three quotes using different definitions of "crossed random
> effects"?  Have I taken the quotes out of context?  Any clarifications
> would be appreciated.
>
> Thanks,
>
> K Wright
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From HStevens at muohio.edu  Tue Mar 13 22:14:27 2007
From: HStevens at muohio.edu (MHH Stevens)
Date: Tue, 13 Mar 2007 17:14:27 -0400
Subject: [R-sig-ME] Crossed random effects
In-Reply-To: <40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>
References: <c968588d0703131151m2ef5fbbfx7292d32b62273375@mail.gmail.com>
	<40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>
Message-ID: <E5D760E5-7A21-42BA-84AE-07ABC5665D7A@muohio.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070313/a4c05978/attachment.pl>

From kw.statr at gmail.com  Tue Mar 13 22:39:53 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Tue, 13 Mar 2007 16:39:53 -0500
Subject: [R-sig-ME] Crossed random effects
In-Reply-To: <40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>
References: <c968588d0703131151m2ef5fbbfx7292d32b62273375@mail.gmail.com>
	<40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>
Message-ID: <c968588d0703131439s510b70ddg48d26e6857ead2e@mail.gmail.com>

Thanks for the clarification.  It is no secret that large
plant-breeding programs (both corporate and governmental--see
http://www.dpi.nsw.gov.au/__data/assets/pdf_file/113474/annual_report_part_3.pdf)
have adopted ASREML, probably due to the "war stories" with crossed
random effects that you mention.  I have heard several people say that
ASREML is often orders of magnitude (100-1000) times better than SAS
for handling large datasets with crossed random effects.  My limited
experience suggests ASREML/Genstat/SAMM and lme4 are in the same
order-of-magnitude performance-wise.

P.S.  I offer sincere appreciation for the "Mixed-effects modeling
with crossed random effects for subjects and items" paper,
particularly the MCMC approach and the corresponding interpretations
and discussions.  Very nice.

K Wright


On 3/13/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 3/13/07, Kevin Wright <kw.statr at gmail.com> wrote:
> > I am confused by some apparent contradictions about fitting crossed
> > random effects in software.  Consider this quote from
> > http://www.mpi.nl/world/persons/private/baayen/publications/baayenDavidsonBates.pdf
> > "To our knowledge, the only software currently available for fitting
> > mixed-effects models with crossed random effects is the lme4 package"
>
> That statement should have been more carefully worded.  It is in
> reference to the types of experimental situations described in that
> paper where random effects are associated with subject and item,
> subjects are crossed with item and the numbers of both the subjects
> and the items can be very large.
>
> > Yet, nlme and GLIMMIX appear to claim that crossed-random effects can
> > be fit by those respective tools:
> >
> > In Mixed Effects Models in S and S-Plus:
> > "The crossed random-effects structure is represented in lme by a
> > combination of pdBlocke3d and pdIdent objects" (page 163)
>
> It is possible to fit a model with crossed random effects with lme
> provided that the number of levels of both of the crossed factors is
> small.  Otherwise you end up with huge, sparse model matrices that are
> being treated as dense matrices and you quickly run out of memory or
> time or both.
>
> Really, doesn't a random effects specification like
> pdBlocked(list(pdIdent(~ rows - 1), pdIdent(~ columns - 1))) smell
> like a kludge to you?
>
> > http://support.sas.com/rnd/app/papers/glimmix.pdf
> > "The GLIMMIX procedure, on the other hand, determines by default the
> > marginal log likelihood as that of an approximate linear mixed model.
> > This allows multiple random effects, nested and crossed random
> > effects, multiple cluster types, and R-side random components."  [and]
> >  "Example 2. Mating Experiment with Crossed Random Effects"
>
> I think that several readers of this list could tell you war stories
> of trying to fit models with crossed random effects using SAS PROC
> MIXED or SAS PROC NLMIXED versus fitting the same model in lmer or
> lmer2.  You are correct that one can specify a model with crossed
> random effects in SAS PROC MIXED and that we overstated the uniqueness
> of the capabilities of lmer to fit such models.  However, if you want
> to try to fit such a model in SAS PROC MIXED when you have large
> numbers of subjects and large numbers of items you had better be
> prepared to wait for a long time.
>
>
> > Are these three quotes using different definitions of "crossed random
> > effects"?  Have I taken the quotes out of context?  Any clarifications
> > would be appreciated.
> >
> > Thanks,
> >
> > K Wright
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>



From A.Robinson at ms.unimelb.edu.au  Tue Mar 13 22:53:02 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 14 Mar 2007 08:53:02 +1100
Subject: [R-sig-ME] Crossed random effects
In-Reply-To: <40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>
References: <c968588d0703131151m2ef5fbbfx7292d32b62273375@mail.gmail.com>
	<40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>
Message-ID: <20070313215302.GA92002@ms.unimelb.edu.au>

On Tue, Mar 13, 2007 at 02:31:56PM -0500, Douglas Bates wrote:
> On 3/13/07, Kevin Wright <kw.statr at gmail.com> wrote:
> > I am confused by some apparent contradictions about fitting crossed
> > random effects in software.  Consider this quote from
> > http://www.mpi.nl/world/persons/private/baayen/publications/baayenDavidsonBates.pdf
> > "To our knowledge, the only software currently available for fitting
> > mixed-effects models with crossed random effects is the lme4 package"
> 
> That statement should have been more carefully worded.  It is in
> reference to the types of experimental situations described in that
> paper where random effects are associated with subject and item,
> subjects are crossed with item and the numbers of both the subjects
> and the items can be very large.
> 
> > Yet, nlme and GLIMMIX appear to claim that crossed-random effects can
> > be fit by those respective tools:
> >
> > In Mixed Effects Models in S and S-Plus:
> > "The crossed random-effects structure is represented in lme by a
> > combination of pdBlocke3d and pdIdent objects" (page 163)
> 
> It is possible to fit a model with crossed random effects with lme
> provided that the number of levels of both of the crossed factors is
> small.  Otherwise you end up with huge, sparse model matrices that are
> being treated as dense matrices and you quickly run out of memory or
> time or both.
> 
> Really, doesn't a random effects specification like
> pdBlocked(list(pdIdent(~ rows - 1), pdIdent(~ columns - 1))) smell
> like a kludge to you?

You must have one of those fancy new monitors.

Cheers,

Andrew
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From HDoran at air.org  Tue Mar 13 23:49:45 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 13 Mar 2007 18:49:45 -0400
Subject: [R-sig-ME] Crossed random effects
References: <c968588d0703131151m2ef5fbbfx7292d32b62273375@mail.gmail.com><40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>
	<E5D760E5-7A21-42BA-84AE-07ABC5665D7A@muohio.edu>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E04E71F@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070313/0f2f6e4c/attachment.pl>

From mchaudhari at deltadentalwa.com  Tue Mar 13 23:57:15 2007
From: mchaudhari at deltadentalwa.com (Chaudhari, Monica)
Date: Tue, 13 Mar 2007 15:57:15 -0700
Subject: [R-sig-ME] Crossed random effects
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E04E71F@dc1ex01.air.org>
References: <c968588d0703131151m2ef5fbbfx7292d32b62273375@mail.gmail.com><40e66e0b0703131231t7447d57egc3d8d6ecd70b68fd@mail.gmail.com>
	<E5D760E5-7A21-42BA-84AE-07ABC5665D7A@muohio.edu>
	<2323A6D37908A847A7C32F1E3662C80E04E71F@dc1ex01.air.org>
Message-ID: <06C1E76E03FE9C4B85BFA9C75365D9DA077DB887@tiger.deltadentalwa.com>

Do try glmm.admb() from library(glmmADMB)in R. It is in the development
phase with limited functionality for now. However, the results are very
fast with large data sets. One can try the base software ADMB
implemented in C which is claimed to be very fast.

Monica

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Doran,
Harold
Sent: Tuesday, March 13, 2007 3:50 PM
To: MHH Stevens; Douglas Bates
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Crossed random effects

I've missed some prior threads on this, please accept my apologies if
what I say below has already been noted. It is true that lme in the nlme
package and that HLM (stand-alone) can fit models with crossed random
effects. Now, I just dare you to try it. mlWin uses an MCMC
implementation for crossed random effects (if you want to go down that
road). 

I have some recent experiences fitting models in Stata and in R. Models
that took less than 2 minutes in R would take overnight in Stata. A few
years back, I also did some comparisons with HLM. For a small data set,
a model in lmer that could be fit in less than 1 minute took something
like 3 to 4 hours in HLM.

In the JSS special edition on psychometrics (forthcoming) Doug, Paul
Bliese, Maritza dowling and I estimate the 1PL for items and students
that are fully crossed using lmer. The estimates were resolved extremely
fast and the data set was rather large.  

I have simply not found another package that competes with lmer wrt to
computational speed for linear or generalized linear mixed models.

Harold



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org on behalf of MHH Stevens
Sent: Tue 3/13/2007 5:14 PM
To: Douglas Bates
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Crossed random effects
 
Dear Folks,
What about specialized stand alone mixed model software, such as HLM?
-Hank
On Mar 13, 2007, at 3:31 PM, Douglas Bates wrote:

> On 3/13/07, Kevin Wright <kw.statr at gmail.com> wrote:
>> I am confused by some apparent contradictions about fitting crossed
>> random effects in software.  Consider this quote from
>> http://www.mpi.nl/world/persons/private/baayen/publications/ 
>> baayenDavidsonBates.pdf
>> "To our knowledge, the only software currently available for fitting
>> mixed-effects models with crossed random effects is the lme4 package"
>
> That statement should have been more carefully worded.  It is in
> reference to the types of experimental situations described in that
> paper where random effects are associated with subject and item,
> subjects are crossed with item and the numbers of both the subjects
> and the items can be very large.
>
>> Yet, nlme and GLIMMIX appear to claim that crossed-random effects can
>> be fit by those respective tools:
>>
>> In Mixed Effects Models in S and S-Plus:
>> "The crossed random-effects structure is represented in lme by a
>> combination of pdBlocke3d and pdIdent objects" (page 163)
>
> It is possible to fit a model with crossed random effects with lme
> provided that the number of levels of both of the crossed factors is
> small.  Otherwise you end up with huge, sparse model matrices that are
> being treated as dense matrices and you quickly run out of memory or
> time or both.
>
> Really, doesn't a random effects specification like
> pdBlocked(list(pdIdent(~ rows - 1), pdIdent(~ columns - 1))) smell
> like a kludge to you?
>
>> http://support.sas.com/rnd/app/papers/glimmix.pdf
>> "The GLIMMIX procedure, on the other hand, determines by default the
>> marginal log likelihood as that of an approximate linear mixed model.
>> This allows multiple random effects, nested and crossed random
>> effects, multiple cluster types, and R-side random  
>> components."  [and]
>>  "Example 2. Mating Experiment with Crossed Random Effects"
>
> I think that several readers of this list could tell you war stories
> of trying to fit models with crossed random effects using SAS PROC
> MIXED or SAS PROC NLMIXED versus fitting the same model in lmer or
> lmer2.  You are correct that one can specify a model with crossed
> random effects in SAS PROC MIXED and that we overstated the uniqueness
> of the capabilities of lmer to fit such models.  However, if you want
> to try to fit such a model in SAS PROC MIXED when you have large
> numbers of subjects and large numbers of items you had better be
> prepared to wait for a long time.
>
>
>> Are these three quotes using different definitions of "crossed random
>> effects"?  Have I taken the quotes out of context?  Any  
>> clarifications
>> would be appreciated.
>>
>> Thanks,
>>
>> K Wright
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"If the stars should appear one night in a thousand years, how would men
believe and adore." -Ralph Waldo Emerson, writer and philosopher  
(1803-1882)






	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


#########################################################
The information contained in this e-mail and subsequent attachments may be privileged, 
confidential and protected from disclosure.  This transmission is intended for the sole 
use of the individual and entity to whom it is addressed.  If you are not the intended 
recipient, any dissemination, distribution or copying is strictly prohibited.  If you 
think that you have received this message in error, please e-mail the sender at the above 
e-mail address.
#########################################################



From Weigand.Stephen at mayo.edu  Wed Mar 14 22:28:40 2007
From: Weigand.Stephen at mayo.edu (Weigand, Stephen D.)
Date: Wed, 14 Mar 2007 16:28:40 -0500
Subject: [R-sig-ME] lme question: separate serial correlation parameters by
	strata
Message-ID: <45F86908.2020003@mayo.edu>

I'm not sure if this is appropriate for this list since this may 
be a very elementary question, but here it is:

I am working with data similar to the BodyWeight data set in the 
nlme package (Appendix A3 and pages 104 and 245 of Pinheiro & Bates)

I'd like to fit a model such as this

fit <- lme(weight ~ Time * Diet,
            data = BodyWeight,
            random = ~ Time,
            correlation = corCAR1(form = ~ Time))

but with a separate phi for each level of Diet.

My reasoning is that the autocorrelation may decay over time at 
different rates for the three diets.  (When I fit a separate 
model for each diet, I get estimates for phi of 0.85 for diet 1, 
0.83 for diet 2, and 0.53 for diet 3. I take this as some 
empirical support for this approach)

Can I do this using lme? (I'm using R 2.4.1 on 
sparc-sun-solaris2.10 with nlme version 3.1-78.)

Thank you,

Stephen


-- 
::::::::::::::::::::::::::::::::::
Stephen Weigand
Division of Biostatistics
Mayo Clinic Rochester, Minn., USA
Phone (507) 266-1650, fax 284-9542



From Weigand.Stephen at mayo.edu  Fri Mar 16 22:09:52 2007
From: Weigand.Stephen at mayo.edu (Weigand, Stephen D.)
Date: Fri, 16 Mar 2007 16:09:52 -0500
Subject: [R-sig-ME] Poor fits with corCAR1 in lme and phi estimate near 1
Message-ID: <45FB07A0.5000909@mayo.edu>

I'm trying to understand why I get poor fits with a lme model
using CAR1 autocorrelation structure.

I'm modeling the volume of a part of a person's brain over time 
using lme. The volume depends on head size, sex, age, and age^2.
I give each person a random intercept.

To give you an idea of my sample sizes here is

table(table(mydata$group))

  3  4  5  6  7  8
16 16  4  7  1  2

My lme call is like this

   ccc <- list(returnObject = TRUE,
               msVerbose = TRUE,
               maxIter = 200,
               msMaxIter = 200,
               msMaxEval = 500)

   fit <-
     lme(vol ~ size + sex + age + I(age^2),
         random = ~ 1 | id,
         correlation = corCAR1(form = ~ age | id),
         data = dG1,
         control = ccc)

I get convergence in 49 iterations with no warnings.

My first indication of a problem is that I get an estimate of phi 
to be 0.996. What's happening is that the fitted values are all 
above or below the observed values. Here's the data for four 
people with a call to xyplot() below to illustrate.

mydata <- structure( list( y = c(101.513696992828,
108.67123416, 121.77207312, 121.364514, 122.44394352,
126.28247856, 66.4450535719635, 71.06907726, 73.34944657,
77.73755495, 73.712, 77.188, 77.802, 22.6576319594522,
24.08128381, 23.3368159, 25.57910501, 26.39909865,
27.52373389 ), age = c(81.4784394250513, 83.4469541409993,
86.7405886379192, 89.0184804928131, 90.3655030800821,
92.413415468857, 73.1663244353183, 76.0602327173169,
78.1629021218344, 79.7125256673511, 80.807665982204,
82.9075975359343, 84.1697467488022, 84.3997262149213,
85.719370294319, 87.0581793292266, 88.558521560575,
91.419575633128, 93.5277207392197 ), g = structure(c(4, 4,
4, 4, 4, 4, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3), .Label =
c("1", "2", "3", "4"), class = "factor"), yhat =
c(58.5700637637191, 61.2504094310121, 65.7874577250516,
68.9636770643335, 70.8566873027208, 73.7557021229065,
55.8860711627563, 59.8790531221204, 62.8120620013217,
64.9907426560824, 71.0988108284064, 74.0280180708455,
75.8014293467406, 50.2485578022043, 52.0817661160286,
53.9523602784579, 56.0615306867955, 60.1213127021499,
63.1444086154206 )), .Names = c("y", "age", "g", "yhat"),
row.names = c(NA, 19), class = "data.frame")

### plot illustrating the "missed fits":
require(lattice)
xyplot(y + yhat ~ age | g, data = mydata,
        xlab = "Age",
        ylab = "Volume",
        lwd = 2,
        type = "b",
        col.symbol = c("black", "transparent"),
        col.line = c("transparent", "black"))


When I use Gaussian-decay autocorrelation, things look fine. I'm 
wondering if anybody has insight into this. I'd be happy to stay 
away from the CAR1 autocorrelation but in similar models the 
likelihood is higher with CAR1 than with Gaussian decay (even 
when there are no problems with the CAR1 model).

Thanks for any thoughts,

Stephen


-- 
::::::::::::::::::::::::::::::::::
Stephen Weigand
Division of Biostatistics
Mayo Clinic Rochester, Minn., USA
Phone (507) 266-1650, fax 284-9542



From bates at stat.wisc.edu  Sat Mar 17 18:21:53 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 17 Mar 2007 12:21:53 -0500
Subject: [R-sig-ME] New version of lmer2 on SVN archive
Message-ID: <40e66e0b0703171021m35cc200ct330aba77b7b10a68@mail.gmail.com>

I have committed a new version of the lme4 package to the SVN archive.
 It must be compiled for a recent version of R-devel (SVN r40844 or
later).  The lmer2 function in this version should use less memory.
In particular if you add the optional argument model = FALSE (poor
choice of name but it was chosen for compatibility with lm) then the
model.frame is not stored in the returned object, making it smaller.
The optimization of the deviance is performed internally in C code
resulting in fewer memory allocations.



From jkrobert at bcm.tmc.edu  Mon Mar 19 21:37:44 2007
From: jkrobert at bcm.tmc.edu (Roberts, J. Kyle)
Date: Mon, 19 Mar 2007 15:37:44 -0500
Subject: [R-sig-ME] augPred in lmer
Message-ID: <3FC0430478C30B4A9AF0AFF7863418F130F091@BCMEVS6.ad.bcm.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070319/efce5753/attachment.pl>

From bates at stat.wisc.edu  Tue Mar 20 01:24:19 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 19 Mar 2007 19:24:19 -0500
Subject: [R-sig-ME] augPred in lmer
In-Reply-To: <3FC0430478C30B4A9AF0AFF7863418F130F091@BCMEVS6.ad.bcm.edu>
References: <3FC0430478C30B4A9AF0AFF7863418F130F091@BCMEVS6.ad.bcm.edu>
Message-ID: <40e66e0b0703191724g15ada65esff0496585bc50162@mail.gmail.com>

Thanks for sending the example, Kyle.

On 3/19/07, Roberts, J. Kyle <jkrobert at bcm.tmc.edu> wrote:
> Below is a discussion that was on R-help that Doug moved here.  Here's my code that Doug requested:
> set.seed(100)
>
> myRands2 <- lapply((lapply(rep(10, 30), rnorm, n=30, mean=50)), sort)
>
> myIV2 <- lapply((lapply(seq(1, 10, length = 30), rnorm, n = 30, mean = 50)), sort)
>
> depend2 <-data.frame(index=rep(1:length(myRands2), each=30), dv = unlist(myRands2), iv = unlist(myIV2))
>
>
>
> dep2.lme2<-lmer(dv ~ iv + (iv|index), depend2)
>
>
>
> ### Here's the part I want, but can't produce.  lme would produce this in S-Plus as 30 separate fitted lines (for 30 groups)
>
> ### based on the "dv" and "iv"
>
> plot(augPred(dep2.lme))

One possible way to get a similar plot is to use the with()
construction on the fitted model.  I enclose some code to plot the
per-subject fits along with the mixed-model fits for the sleepstudy
data.

The technique being used is to extract the per-group coefficients and
within the panel function determine which group is being plotted and
hence what coefficients should be used in the plot.

This could definitely be done more cleanly.  The problem I have when
trying to design functions like this is to be able to define the
method for cases with non-nested random effects.


>
>
>
> Thanks for the help,
>
> Kyle
>
>
> > Hi Kyle,
> >
> > not yet!  At least not as far as I know.
>
> Not as far as I know either.
>
> > On Thu, Mar 08, 2007 at 03:08:19PM -0600, Roberts, J. Kyle wrote:
> > > I read the posts about augPred with lme, but does anyone know if there is a correlate for augPred for lmer?  Specifically, I want to be able to use it to plot projections for all groups in an lmer class object using plot(augPred(lmer.object)).
>
> Can you give us a bit more detail on the model that you have fit?  It
> may be possible to get the plot that you want without having to build
> all the infrastructure that Jose and I built in lme.  Deepayan has
> quietly added so many wonderful capabilities to lattice relative to
> earlier versions of trellis that a more direct approach often works.
>
> Also, I think we should move the discussion to the R-sig-mixed-models
> mailing list, which I am cc:ing on this reply.
>
>
> ***************************************
> J. Kyle Roberts, Ph.D.
> Baylor College of Medicine
> Center for Educational Outreach
> One Baylor Plaza, MS:  BCM411
> Houston, TX   77030-3411
> 713-798-6672 - 713-798-8201 Fax
> jkrobert at bcm.edu
> ***************************************
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
with(fm1, {
    cc <- coef(.)$Subject
    xyplot(Reaction ~ Days | Subject, 
                 index.cond = function(x, y) coef(lm(y ~ x))[1],
                 panel = function(x, y, groups, subscripts, ...) {
                     panel.grid(h = -1, v = -1)
                     panel.points(x, y, ...)
                     subj <- as.character(Subject[subscripts][1])
                     panel.abline(cc[subj,1], cc[subj, 2])
                     panel.lmline(x, y, ...)
                 })
})

From bates at stat.wisc.edu  Tue Mar 20 01:28:47 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 19 Mar 2007 19:28:47 -0500
Subject: [R-sig-ME] [OT] Harold Doran in congressional committee testimony
	on "No Child Left Behind"
Message-ID: <40e66e0b0703191728k7b70cd85h994f3171c0152233@mail.gmail.com>

Harold Doran, a frequent contributor to this list, mentioned to me
that he will be testifying before a congressional committee regarding
the "No Child Left Behind" Act on Wednesday, March 21.  The testimony
should be carried on CSPAN.



From jkrobert at bcm.tmc.edu  Tue Mar 20 15:46:44 2007
From: jkrobert at bcm.tmc.edu (Roberts, J. Kyle)
Date: Tue, 20 Mar 2007 09:46:44 -0500
Subject: [R-sig-ME] [OT] Harold Doran in congressional committee
	testimonyon "No Child Left Behind"
In-Reply-To: <40e66e0b0703191728k7b70cd85h994f3171c0152233@mail.gmail.com>
Message-ID: <3FC0430478C30B4A9AF0AFF7863418F130F094@BCMEVS6.ad.bcm.edu>

Doug and Harold,

Do you know the time?

Kyle


***************************************
J. Kyle Roberts, Ph.D.
Baylor College of Medicine
Center for Educational Outreach
One Baylor Plaza, MS:  BCM411
Houston, TX   77030-3411
713-798-6672 - 713-798-8201 Fax
jkrobert at bcm.edu
***************************************

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Douglas Bates
Sent: Monday, March 19, 2007 7:29 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] [OT] Harold Doran in congressional committee testimonyon "No Child Left Behind"

Harold Doran, a frequent contributor to this list, mentioned to me that he will be testifying before a congressional committee regarding the "No Child Left Behind" Act on Wednesday, March 21.  The testimony should be carried on CSPAN.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From austin.frank at gmail.com  Tue Mar 20 16:53:04 2007
From: austin.frank at gmail.com (Austin Frank)
Date: Tue, 20 Mar 2007 11:53:04 -0400
Subject: [R-sig-ME] factor elimination for lmer models
Message-ID: <m0hcsfvrmn.fsf@gmail.com>

Hello!

I'll preface this by saying that this question may reveal some
fundamental misunderstanding on my part.  Thanks in advance for
clarification if there are things that I'm obviously not getting.
That said...

The Design library provides a function fastbw that does fast backwards
elimination of factors in a model.  This is a very useful function,
and I'm wondering what it would take to make it work with lmer or
lmer2-fitted models.

The function works on any model, m, where Varcov(m) is defined.
Varcov is a function from Hmisc that extracts the variance-covariance
matrix from certain kinds of fitted models.  Currently it works for
lm, glm, and multinom fitted models.

So, five questions:

1) Is there already a way to do automated factor elimination on an
   lmer-fitted model?

2) Would it be possible to write a function Varcov.lmer to extract the
   variance-covariance matrix from an lmer-fitted model?

3) Would it be possible to port the fastbw function from the Design
   library so that it would work on lmer models (without relying on
   Varcov from Hmisc)?

4) If both 2 and 3 are possible, which is the path of least
   resistance?

5) If neither 2 nor 3 is possible (the algorithm used in Design's
   fastbw is unsuitable for lmer models), is there an approach to
   factor elimination that is appropriate for these models?

If you folks get me started in the right direction, I'd be happy to
submit a patch to lme4 or languageR.
   
Thanks for your responses,
/au

-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From bates at stat.wisc.edu  Tue Mar 20 17:19:10 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 20 Mar 2007 11:19:10 -0500
Subject: [R-sig-ME] factor elimination for lmer models
In-Reply-To: <m0hcsfvrmn.fsf@gmail.com>
References: <m0hcsfvrmn.fsf@gmail.com>
Message-ID: <40e66e0b0703200919i48e36257o9650af955a568832@mail.gmail.com>

On 3/20/07, Austin Frank <austin.frank at gmail.com> wrote:

> I'll preface this by saying that this question may reveal some
> fundamental misunderstanding on my part.  Thanks in advance for
> clarification if there are things that I'm obviously not getting.
> That said...

> The Design library provides a function fastbw that does fast backwards
> elimination of factors in a model.  This is a very useful function,
> and I'm wondering what it would take to make it work with lmer or
> lmer2-fitted models.

> The function works on any model, m, where Varcov(m) is defined.
> Varcov is a function from Hmisc that extracts the variance-covariance
> matrix from certain kinds of fitted models.  Currently it works for
> lm, glm, and multinom fitted models.

> So, five questions:

> 1) Is there already a way to do automated factor elimination on an
>    lmer-fitted model?

Not that I know of.

> 2) Would it be possible to write a function Varcov.lmer to extract the
>    variance-covariance matrix from an lmer-fitted model?

I didn't go through the documentation for Varcov, which is part of a
large file related to transcan, in detail but it appears on simple
examples that Varcov produces the same result as vcov and there is a
vcov method for the lmer class.

> 3) Would it be possible to port the fastbw function from the Design
>    library so that it would work on lmer models (without relying on
>    Varcov from Hmisc)?

It depends on what fastbw does.  That name seems to imply that it will
create the results from refitting a model omitting certain terms in
the model specification and it will do so without needing to refit.  I
don't think that would be possible for lmer models because when you
omit a term in the fixed-effects specification you will change the
estimates of the variance components.  The results from the vcov
method are conditional on the values of the variance components.

> 4) If both 2 and 3 are possible, which is the path of least
>    resistance?
>
> 5) If neither 2 nor 3 is possible (the algorithm used in Design's
>    fastbw is unsuitable for lmer models), is there an approach to
>    factor elimination that is appropriate for these models?
>
> If you folks get me started in the right direction, I'd be happy to
> submit a patch to lme4 or languageR.



From HDoran at air.org  Tue Mar 20 18:37:38 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 20 Mar 2007 13:37:38 -0400
Subject: [R-sig-ME] [OT] Harold Doran in congressional
	committeetestimonyon "No Child Left Behind"
In-Reply-To: <3FC0430478C30B4A9AF0AFF7863418F130F094@BCMEVS6.ad.bcm.edu>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E8D5153@dc1ex01.air.org>

Kyle:

The hearing begins at 10:30 and is before the house subcommittee on
education and labor and the issue is whether AYP can be measured in
different ways (e.g., growth models, etc). I don't know when cspan will
broadcast. Education hearings tend to get less play time than fired
attorneys.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Roberts, J. Kyle
> Sent: Tuesday, March 20, 2007 9:47 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] [OT] Harold Doran in congressional 
> committeetestimonyon "No Child Left Behind"
> 
> Doug and Harold,
> 
> Do you know the time?
> 
> Kyle
> 
> 
> ***************************************
> J. Kyle Roberts, Ph.D.
> Baylor College of Medicine
> Center for Educational Outreach
> One Baylor Plaza, MS:  BCM411
> Houston, TX   77030-3411
> 713-798-6672 - 713-798-8201 Fax
> jkrobert at bcm.edu
> ***************************************
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Douglas Bates
> Sent: Monday, March 19, 2007 7:29 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] [OT] Harold Doran in congressional 
> committee testimonyon "No Child Left Behind"
> 
> Harold Doran, a frequent contributor to this list, mentioned 
> to me that he will be testifying before a congressional 
> committee regarding the "No Child Left Behind" Act on 
> Wednesday, March 21.  The testimony should be carried on CSPAN.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From srjafarzadeh at gmail.com  Fri Mar 23 00:26:58 2007
From: srjafarzadeh at gmail.com (Seyed Reza Jafarzadeh)
Date: Thu, 22 Mar 2007 16:26:58 -0700
Subject: [R-sig-ME] comparing models with quasipoisson family
Message-ID: <83217d00703221626g33c5d822l3db1e14c802d1785@mail.gmail.com>

Hi,

I am using 'lmer' to fit generalized linear mixed-effects models. I
was just wondering how I can compare two models with identical
fixed-effect terms but different random effects specifications  when I
am using the 'quasipoisson' family.

Can I still use 'anova' to compare them? Should a model with
'quasipoisson' family specification produce a logLik value or AIC?

How about the estimate of dispersion parameter as we can get by 'glm'?


Thanks,
Reza



From olivier.martin at avignon.inra.fr  Fri Mar 23 16:29:31 2007
From: olivier.martin at avignon.inra.fr (Olivier MARTIN)
Date: Fri, 23 Mar 2007 16:29:31 +0100
Subject: [R-sig-ME] BLUP in lmer
Message-ID: <4603F25B.7050603@avignon.inra.fr>

Hi all,

I am using 'lmer' to fit generalized linear mixed-effects models. 
I would like to know if there is a function to estimate the random effects.
And, is there a way to compare the observed values vs. fitted 
values or fitted values vs. residuals ?

Thanks,
olivier



From jkrobert at bcm.tmc.edu  Fri Mar 23 17:30:15 2007
From: jkrobert at bcm.tmc.edu (Roberts, J. Kyle)
Date: Fri, 23 Mar 2007 11:30:15 -0500
Subject: [R-sig-ME] BLUP in lmer
In-Reply-To: <4603F25B.7050603@avignon.inra.fr>
Message-ID: <3FC0430478C30B4A9AF0AFF7863418F130F0A4@BCMEVS6.ad.bcm.edu>

Olivier,

Do you mean something like this?
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
with(fm1, xyplot(resid(.) ~ fitted(.))) 

This gives you a plot of the residual versus the fitted.  "sleepstudy" is included in the package.

Hope this helps,
Kyle

***************************************
J. Kyle Roberts, Ph.D.
Baylor College of Medicine
Center for Educational Outreach
One Baylor Plaza, MS:  BCM411
Houston, TX   77030-3411
713-798-6672 - 713-798-8201 Fax
jkrobert at bcm.edu
***************************************

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Olivier MARTIN
Sent: Friday, March 23, 2007 10:30 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] BLUP in lmer

Hi all,

I am using 'lmer' to fit generalized linear mixed-effects models. 
I would like to know if there is a function to estimate the random effects.
And, is there a way to compare the observed values vs. fitted values or fitted values vs. residuals ?

Thanks,
olivier

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Mar 23 18:42:52 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 23 Mar 2007 12:42:52 -0500
Subject: [R-sig-ME] BLUP in lmer
In-Reply-To: <3FC0430478C30B4A9AF0AFF7863418F130F0A4@BCMEVS6.ad.bcm.edu>
References: <4603F25B.7050603@avignon.inra.fr>
	<3FC0430478C30B4A9AF0AFF7863418F130F0A4@BCMEVS6.ad.bcm.edu>
Message-ID: <40e66e0b0703231042r5a134016sc6dde6213ea5e7d8@mail.gmail.com>

On 3/23/07, Roberts, J. Kyle <jkrobert at bcm.tmc.edu> wrote:
> Olivier,
>
> Do you mean something like this?
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> with(fm1, xyplot(resid(.) ~ fitted(.)))
>
> This gives you a plot of the residual versus the fitted.  "sleepstudy" is included in the package.

Thanks for the reply, Kyle.  The original question was about
generalized linear mixed models and the resid function doesn't work
for them at present.  The reason is that it is not clear which
residuals should be returned.  A generalized linear model has several
different types of residuals that can be defined for it and I haven't
gotten around to determining which ones would be appropriate for
generalized linear mixed models.

The original also asked about BLUPs from a generalized linear mixed model.

ranef(fm1)

provides what some would call the BLUPs of the random effects.  I call
them the "conditional modes" of the random effects rather than the
BLUPs or Best Linear Unbiased Predictors.  They are the modes in that
they maximize the density of the random effects conditional on the
variance-covariance parameters and the data.  For a linear mixed model
they are also the BLUPs.  For a generalized linear mixed model or a
nonlinear mixed model they aren't.  As Alan James once described the
situation, "They aren't linear (i.e. linear functions of the
observations) and they aren't unbiased and there is no clear sense in
which they are "best" but, other than than, they're exactly like the
BLUPs".

> Hope this helps,
> Kyle
>
> ***************************************
> J. Kyle Roberts, Ph.D.
> Baylor College of Medicine
> Center for Educational Outreach
> One Baylor Plaza, MS:  BCM411
> Houston, TX   77030-3411
> 713-798-6672 - 713-798-8201 Fax
> jkrobert at bcm.edu
> ***************************************
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Olivier MARTIN
> Sent: Friday, March 23, 2007 10:30 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] BLUP in lmer
>
> Hi all,
>
> I am using 'lmer' to fit generalized linear mixed-effects models.
> I would like to know if there is a function to estimate the random effects.
> And, is there a way to compare the observed values vs. fitted values or fitted values vs. residuals ?
>
> Thanks,
> olivier
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From austin.frank at gmail.com  Fri Mar 23 19:59:22 2007
From: austin.frank at gmail.com (Austin Frank)
Date: Fri, 23 Mar 2007 14:59:22 -0400
Subject: [R-sig-ME] working with log-transformed data
Message-ID: <m0d52zwzud.fsf@gmail.com>

Hello!

If this question belongs on another list like R-help, please let me
know.  Thanks in advance for any responses.

I'm fitting a model of the form

m <- lmer( log(latency) ~ factor1 + factor2 +
                          cov1 + cov2 +
                          (1 | subject) + (1 | item) )

lmer reports a coefficient for factor1level1 of .04 and for
factor2level1 of -.10.  I'd like to convert these coefficients back
into the original units of the dependent variable, milliseconds.  Is
the following transformation appropriate for showing the expected
change in the dependent variable in its original units for each of the
fixed effects?

sapply(fixef(m), function (x) ((exp(x) - 1) * mean(latency)))

I also wondered whether I should use different transformations for the
balanced factors and the continuous covariates.  Do you think this is
an issue?  If so, any suggestions on an appropriate conversion for the
covariates?

Thanks for your time,
/au

-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From austin.frank at gmail.com  Fri Mar 23 20:07:01 2007
From: austin.frank at gmail.com (Austin Frank)
Date: Fri, 23 Mar 2007 15:07:01 -0400
Subject: [R-sig-ME] fixed effects correlated with the intercept
Message-ID: <m0aby3wzhm.fsf@gmail.com>

And hello again!

I'm getting a result that is very confusing to me and I'm hoping for
some advice or clarification.  I have two covariates that I consider
to be controls in my model.  When I include either in the model, the
fixed effect shows a strong correlation ( > .85 ) with the intercept.
The result of including these factors is that the estimated intercept
is much lower than I would expect.  Is there any conclusion to be
drawn from these correlations?  Normally when I see correlations among
fixed effects I worry about collinearity.  I'm absolutely confused
about what it would mean for a covariate to be collinear with the
estimated population mean.  Any help is appreciated in clearing this
up.

It's possible that the appropriate conclusion is that I'm overfitting.
I'm not sure this is the case.  The degrees of freedom in the model is
still relatively low compared to the number of data points (12 df on
~2500 observations).  Is overfitting still the most likely culprit?

One attempt at dealing with the above problem was to remove the
intercept from the model.  This causes lmer to estimate a coefficient
for each of the levels in the first factor in the model.  I think that
this treatment did not resolve whatever problem there is with these
two covariates-- now instead of being correlated with the intercept,
they are correlated with both levels of the split factor.

While this approach didn't resolve my original issue, it did bring up
a few others.  First of all, the coef() method fails on a model with
no intercept for the fixed effects, giving the error "unable to align
random and fixed effects".  Is this a known issue?  Is there a
workaround?

Second, while the estimates for both levels of the split factor are
shown to be significantly different from zero using mcmcsamp, I'm
still interested in whether there is a difference between the two
levels.  What's the appropriate test to check the null hypothesis that
the difference between the two parameter estimates is zero?

Thanks again,
/au

-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From mchaudhari at deltadentalwa.com  Fri Mar 23 20:11:57 2007
From: mchaudhari at deltadentalwa.com (Chaudhari, Monica)
Date: Fri, 23 Mar 2007 12:11:57 -0700
Subject: [R-sig-ME] BLUP in lmer
References: <4603F25B.7050603@avignon.inra.fr>
	<3FC0430478C30B4A9AF0AFF7863418F130F0A4@BCMEVS6.ad.bcm.edu>
	<40e66e0b0703231042r5a134016sc6dde6213ea5e7d8@mail.gmail.com>
Message-ID: <06C1E76E03FE9C4B85BFA9C75365D9DA07A4C03A@tiger.deltadentalwa.com>


To see how well the model has accomplished, would it be wrong to observe
the following:
1) response residuals to be close to zero by computing [model at y -
exp(fitted(model))] assuming the link is a log function. Can this not
help in at least identifying the outliers...those that lie far from 0?
2) Since the GLMMs are linear in their link function, can we get close
to assessing the linearity by:
	* first,  computing the means in each of the categories defined
by predictors (assuming the predictors are categorical variables)
	* second, assigning that mean to each of the observations that
fall in the category defined by the set of predictors.
	* third, wrapping the link function around the mean. Example,
log(mu)
	* lastly, computing log(mu)-fitted(model) to give link
residuals.
	* plotting link residuals against fitted(model) should give a
linear pattern with constant variance (sigma2_b + segma2_e).
Any insight on this would be very much appreciated.

Also, is there any way to assess the dispersion parameter in negative
binomial family before giving it in lmer for GLMM? Presently, I am using
the dispersion parameter estimate computed from glm.nb with random
effects of GLMM as fixed effects with treatment contrasts. However, I
suspect it to be biased due to no structural information taken in
account, which leaves lot of variation uncaptured by the model. Can you
please suggest any nicer way?

Last question, would it make any sense to use predictors with sum
contrast in GLMs when the link function is log, if I want to know how
much the effect of each of the categories of a predictor is away from
the overall average?

Thanks in advance,
Monica 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Douglas
Bates
Sent: Friday, March 23, 2007 10:43 AM
To: Roberts, J. Kyle
Cc: r-sig-mixed-models at r-project.org; Olivier MARTIN
Subject: Re: [R-sig-ME] BLUP in lmer

On 3/23/07, Roberts, J. Kyle <jkrobert at bcm.tmc.edu> wrote:
> Olivier,
>
> Do you mean something like this?
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> with(fm1, xyplot(resid(.) ~ fitted(.)))
>
> This gives you a plot of the residual versus the fitted.  "sleepstudy"
is included in the package.

Thanks for the reply, Kyle.  The original question was about
generalized linear mixed models and the resid function doesn't work
for them at present.  The reason is that it is not clear which
residuals should be returned.  A generalized linear model has several
different types of residuals that can be defined for it and I haven't
gotten around to determining which ones would be appropriate for
generalized linear mixed models.

The original also asked about BLUPs from a generalized linear mixed
model.

ranef(fm1)

provides what some would call the BLUPs of the random effects.  I call
them the "conditional modes" of the random effects rather than the
BLUPs or Best Linear Unbiased Predictors.  They are the modes in that
they maximize the density of the random effects conditional on the
variance-covariance parameters and the data.  For a linear mixed model
they are also the BLUPs.  For a generalized linear mixed model or a
nonlinear mixed model they aren't.  As Alan James once described the
situation, "They aren't linear (i.e. linear functions of the
observations) and they aren't unbiased and there is no clear sense in
which they are "best" but, other than than, they're exactly like the
BLUPs".

> Hope this helps,
> Kyle
>
> ***************************************
> J. Kyle Roberts, Ph.D.
> Baylor College of Medicine
> Center for Educational Outreach
> One Baylor Plaza, MS:  BCM411
> Houston, TX   77030-3411
> 713-798-6672 - 713-798-8201 Fax
> jkrobert at bcm.edu
> ***************************************
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Olivier
MARTIN
> Sent: Friday, March 23, 2007 10:30 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] BLUP in lmer
>
> Hi all,
>
> I am using 'lmer' to fit generalized linear mixed-effects models.
> I would like to know if there is a function to estimate the random
effects.
> And, is there a way to compare the observed values vs. fitted values
or fitted values vs. residuals ?
>
> Thanks,
> olivier
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


#########################################################
The information contained in this e-mail and subsequent attachments may be privileged, 
confidential and protected from disclosure.  This transmission is intended for the sole 
use of the individual and entity to whom it is addressed.  If you are not the intended 
recipient, any dissemination, distribution or copying is strictly prohibited.  If you 
think that you have received this message in error, please e-mail the sender at the above 
e-mail address.
#########################################################



From john.maindonald at anu.edu.au  Fri Mar 23 23:54:58 2007
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 24 Mar 2007 09:54:58 +1100
Subject: [R-sig-ME] fixed effects correlated with the intercept
In-Reply-To: <m0aby3wzhm.fsf@gmail.com>
References: <m0aby3wzhm.fsf@gmail.com>
Message-ID: <104AEDA1-8DA5-4ED3-9A10-1113B03A25CF@anu.edu.au>

Is'nt this what might be expected.  Center the covariate about
its mean and, depending on the detailed variance-covariance
structure, the correlation may well reduce to zero.

Check this out with a model created using lm(), where it is
easier to follow the detail.  If you write the model  y = a + b(x -  
mean(x)),
the estimates of a and b are uncorrelated.  If x is not centered,
then you have
y = a - b mean(x))] + bx = adash + bx.

Then
adash = a - b mean(x)
involves b, and is clearly correlated with b. By making mean(x)
large enough or small enough, the correlation can be made
arbitrarily close to -1 or 1, respectively.

What do you mean when you say "I have two covariates that I
consider to be controls in my model." Do you mean that these
code for observations that you are treating as controls?  Or
what?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 24 Mar 2007, at 6:07 AM, Austin Frank wrote:

> And hello again!
>
> I'm getting a result that is very confusing to me and I'm hoping for
> some advice or clarification.  I have two covariates that I consider
> to be controls in my model.  When I include either in the model, the
> fixed effect shows a strong correlation ( > .85 ) with the intercept.
> The result of including these factors is that the estimated intercept
> is much lower than I would expect.  Is there any conclusion to be
> drawn from these correlations?  Normally when I see correlations among
> fixed effects I worry about collinearity.  I'm absolutely confused
> about what it would mean for a covariate to be collinear with the
> estimated population mean.  Any help is appreciated in clearing this
> up.
>
> It's possible that the appropriate conclusion is that I'm overfitting.
> I'm not sure this is the case.  The degrees of freedom in the model is
> still relatively low compared to the number of data points (12 df on
> ~2500 observations).  Is overfitting still the most likely culprit?
>
> One attempt at dealing with the above problem was to remove the
> intercept from the model.  This causes lmer to estimate a coefficient
> for each of the levels in the first factor in the model.  I think that
> this treatment did not resolve whatever problem there is with these
> two covariates-- now instead of being correlated with the intercept,
> they are correlated with both levels of the split factor.
>
> While this approach didn't resolve my original issue, it did bring up
> a few others.  First of all, the coef() method fails on a model with
> no intercept for the fixed effects, giving the error "unable to align
> random and fixed effects".  Is this a known issue?  Is there a
> workaround?
>
> Second, while the estimates for both levels of the split factor are
> shown to be significantly different from zero using mcmcsamp, I'm
> still interested in whether there is a difference between the two
> levels.  What's the appropriate test to check the null hypothesis that
> the difference between the two parameter estimates is zero?
>
> Thanks again,
> /au
>
> -- 
> Austin Frank
> http://aufrank.net
> GPG Public Key (D7398C2F): http://aufrank.net/personal.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From austin.frank at gmail.com  Sat Mar 24 19:58:15 2007
From: austin.frank at gmail.com (Austin Frank)
Date: Sat, 24 Mar 2007 14:58:15 -0400
Subject: [R-sig-ME] fixed effects correlated with the intercept
References: <m0aby3wzhm.fsf@gmail.com>
	<104AEDA1-8DA5-4ED3-9A10-1113B03A25CF@anu.edu.au>
Message-ID: <m07it6ii48.fsf@dhcp111.internal>

On Fri, Mar 23 2007, John Maindonald wrote:

> Is'nt this what might be expected.  Center the covariate about
> its mean and, depending on the detailed variance-covariance
> structure, the correlation may well reduce to zero.
> ...
> [snip useful demonstration]
> ...
> the correlation can be made arbitrarily close to -1 or 1,
> respectively.

Thanks, this explains a lot.  I also appreciate the general point
about thinking in terms of lm when trying to reason about the fixed
effects in a model.

> What do you mean when you say "I have two covariates that I consider
> to be controls in my model." Do you mean that these code for
> observations that you are treating as controls?  Or what?

I guess more precise terms might be "post-hoc controls" or "possible
confounds".  Our stimulus selection process did not take into account
certain properties of the stimuli that may have influenced the
observed behavior.  By adding these properties into the model as
post-hoc controls we can test whether the factors of interest have a
significant effect on the observed behavior even when these other
properties of the stimuli are accounted for.

Thanks again,
/au

-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From john.maindonald at anu.edu.au  Sun Mar 25 03:22:06 2007
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 25 Mar 2007 11:22:06 +1000
Subject: [R-sig-ME] fixed effects correlated with the intercept
In-Reply-To: <m07it6ii48.fsf@dhcp111.internal>
References: <m0aby3wzhm.fsf@gmail.com>
	<104AEDA1-8DA5-4ED3-9A10-1113B03A25CF@anu.edu.au>
	<m07it6ii48.fsf@dhcp111.internal>
Message-ID: <58022B8E-7490-4041-A921-01DFC32458B7@anu.edu.au>

Used in this manner, the word "control" is surely confusing
and misleading.  What you have are surely post-hoc covariate
adjustments.


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 25 Mar 2007, at 4:58 AM, Austin Frank wrote:

> On Fri, Mar 23 2007, John Maindonald wrote:
>
>> Is'nt this what might be expected.  Center the covariate about
>> its mean and, depending on the detailed variance-covariance
>> structure, the correlation may well reduce to zero.
>> ...
>> [snip useful demonstration]
>> ...
>> the correlation can be made arbitrarily close to -1 or 1,
>> respectively.
>
> Thanks, this explains a lot.  I also appreciate the general point
> about thinking in terms of lm when trying to reason about the fixed
> effects in a model.
>
>> What do you mean when you say "I have two covariates that I consider
>> to be controls in my model." Do you mean that these code for
>> observations that you are treating as controls?  Or what?
>
> I guess more precise terms might be "post-hoc controls" or "possible
> confounds".  Our stimulus selection process did not take into account
> certain properties of the stimuli that may have influenced the
> observed behavior.  By adding these properties into the model as
> post-hoc controls we can test whether the factors of interest have a
> significant effect on the observed behavior even when these other
> properties of the stimuli are accounted for.
>
> Thanks again,
> /au
>
> -- 
> Austin Frank
> http://aufrank.net
> GPG Public Key (D7398C2F): http://aufrank.net/personal.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From A.Robinson at ms.unimelb.edu.au  Sun Mar 25 07:00:41 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 25 Mar 2007 15:00:41 +1000
Subject: [R-sig-ME] Simple explanation of the lme Algorithms?
Message-ID: <20070325050041.GG39176@ms.unimelb.edu.au>

Hi everyone,

I'm trying to figure out how the loops work together in lme().  I
understand that we start with some EM iterations to get close to the
optimum, and then switch to Newton-Raphson (eg Pinheiro and Bates
2000, p. 80).  However, I can't reconcile that understanding with my
reading of the lmeControl switches.  There, I see

maxIter: maximum number of iterations for the 'lme' optimization
          algorithm. Default is 50.

msMaxIter: maximum number of iterations for the 'nlm' optimization
          step inside the 'lme' optimization. Default is 50.

niterEM: number of iterations for the EM algorithm used to refine the
          initial estimates of the random effects variance-covariance
          coefficients. Default is 25.

Clearly, niterEM covers the initial EM portion, and I guess that
msMaxIter refers to the invocation of nlm, which performs the Newton
Raphson optimization, but then what role does maxIter play, and what
is 'lme' optimization doing?

If I've missed the obvious page in P&B 2000, or the obvious paper,
then I apologize: please let me know!  I tried to find a copy of 

Bates, D.M. and Pinheiro, J.C. (1998) "Computational methods for
multilevel models" available in PostScript or PDF formats at
http://franz.stat.wisc.edu/pub/NLME/

but franz appears to be down.

Cheers,

Andrew
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Sun Mar 25 19:31:12 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 25 Mar 2007 12:31:12 -0500
Subject: [R-sig-ME] Simple explanation of the lme Algorithms?
In-Reply-To: <20070325050041.GG39176@ms.unimelb.edu.au>
References: <20070325050041.GG39176@ms.unimelb.edu.au>
Message-ID: <40e66e0b0703251031l214d7cb1n1b76cc8d938690d4@mail.gmail.com>

On 3/25/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> Hi everyone,
>
> I'm trying to figure out how the loops work together in lme().  I
> understand that we start with some EM iterations to get close to the
> optimum, and then switch to Newton-Raphson (eg Pinheiro and Bates
> 2000, p. 80).  However, I can't reconcile that understanding with my
> reading of the lmeControl switches.  There, I see
>
> maxIter: maximum number of iterations for the 'lme' optimization
>           algorithm. Default is 50.
>
> msMaxIter: maximum number of iterations for the 'nlm' optimization
>           step inside the 'lme' optimization. Default is 50.
>
> niterEM: number of iterations for the EM algorithm used to refine the
>           initial estimates of the random effects variance-covariance
>           coefficients. Default is 25.
>
> Clearly, niterEM covers the initial EM portion, and I guess that
> msMaxIter refers to the invocation of nlm, which performs the Newton
> Raphson optimization, but then what role does maxIter play, and what
> is 'lme' optimization

IIRC the maxiter setting is for cases where there is a variance
function or a correlation function in the model specification.
Conditional on parameters for the variance function or the correlation
function or both, the parameters in the mixed-effects specification
are optimized, then the parameters in the variance or correlation
function are updated then ...

> If I've missed the obvious page in P&B 2000, or the obvious paper,
> then I apologize: please let me know!  I tried to find a copy of
>
> Bates, D.M. and Pinheiro, J.C. (1998) "Computational methods for
> multilevel models" available in PostScript or PDF formats at
> http://franz.stat.wisc.edu/pub/NLME/
>
> but franz appears to be down.
>
> Cheers,
>
> Andrew
> --
> Andrew Robinson
> Department of Mathematics and Statistics            Tel: +61-3-8344-9763
> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>



From A.Robinson at ms.unimelb.edu.au  Sun Mar 25 21:44:02 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 26 Mar 2007 05:44:02 +1000
Subject: [R-sig-ME] Simple explanation of the lme Algorithms?
In-Reply-To: <40e66e0b0703251031l214d7cb1n1b76cc8d938690d4@mail.gmail.com>
References: <20070325050041.GG39176@ms.unimelb.edu.au>
	<40e66e0b0703251031l214d7cb1n1b76cc8d938690d4@mail.gmail.com>
Message-ID: <20070325194402.GI39176@ms.unimelb.edu.au>

On Sun, Mar 25, 2007 at 12:31:12PM -0500, Douglas Bates wrote:
> On 3/25/07, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> >Hi everyone,
> >
> >I'm trying to figure out how the loops work together in lme().  I
> >understand that we start with some EM iterations to get close to the
> >optimum, and then switch to Newton-Raphson (eg Pinheiro and Bates
> >2000, p. 80).  However, I can't reconcile that understanding with my
> >reading of the lmeControl switches.  There, I see
> >
> >maxIter: maximum number of iterations for the 'lme' optimization
> >          algorithm. Default is 50.
> >
> >msMaxIter: maximum number of iterations for the 'nlm' optimization
> >          step inside the 'lme' optimization. Default is 50.
> >
> >niterEM: number of iterations for the EM algorithm used to refine the
> >          initial estimates of the random effects variance-covariance
> >          coefficients. Default is 25.
> >
> >Clearly, niterEM covers the initial EM portion, and I guess that
> >msMaxIter refers to the invocation of nlm, which performs the Newton
> >Raphson optimization, but then what role does maxIter play, and what
> >is 'lme' optimization
> 
> IIRC the maxiter setting is for cases where there is a variance
> function or a correlation function in the model specification.
> Conditional on parameters for the variance function or the correlation
> function or both, the parameters in the mixed-effects specification
> are optimized, then the parameters in the variance or correlation
> function are updated then ...

Thanks for your response, Doug.  So, if I may paraphrase, does maxIter
refer to the maximum number of Newton-Raphson steps allowed for the
updating (by which I guess that you mean estimation) of the parameters
in the variance or correlation function, having conditioned on the
other fixed and random effects?  If my interpretation is correct then
I'm afraid that I'm still confused.  For example, if I compare the
output of 

> fm1 <- lme(distance ~ age, data = Orthodont, random=~1|Subject, 
+ control=list(msVerbose=TRUE))
  0      320.256: -0.390137
  1      320.256: -0.390137

with 

> fm1 <- lme(distance ~ age, random=~1|Subject, data = Orthodont,
+ weights=varPower(), control=list(msVerbose=TRUE))
  0      320.256: -0.390137  0.00000
  1      320.254: -0.390137 0.00377348
  2      320.251: -0.402940 0.00405120
  3      320.109: -0.793763 0.127338
  4      319.381: -4.39127  1.26259
  5      319.359: -5.08632  1.48580
  6      319.359: -5.08547  1.48633
  7      319.359: -5.08607  1.48651
  0      319.985: -5.08607  1.48651
  1      319.984: -5.08517  1.48796
  2      319.984: -5.07930  1.48451
  3      319.966: -4.93970  1.43987
  4      319.874: -3.63622  1.02756
  5      319.872: -3.44497 0.967633
  6      319.872: -3.44235 0.966866
  7      319.872: -3.44233 0.966860
  0      319.721: -3.44233 0.966860
  1      319.721: -3.44261 0.966623
... etc


then I see that there are indeed an inner and outer loop with the
addition of the variance function, but both parameters appear to be
continuously updating.  So I guess that my interpretation is
incorrect.  Can you please help me clarify?

Andrew

 
> >If I've missed the obvious page in P&B 2000, or the obvious paper,
> >then I apologize: please let me know!  I tried to find a copy of
> >
> >Bates, D.M. and Pinheiro, J.C. (1998) "Computational methods for
> >multilevel models" available in PostScript or PDF formats at
> >http://franz.stat.wisc.edu/pub/NLME/
> >
> >but franz appears to be down.
> >
> >Cheers,
> >
> >Andrew
> >--
> >Andrew Robinson
> >Department of Mathematics and Statistics            Tel: +61-3-8344-9763
> >University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> >http://www.ms.unimelb.edu.au/~andrewpr
> >http://blogs.mbs.edu/fishing-in-the-bay/
> >

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Mon Mar 26 15:48:38 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 26 Mar 2007 08:48:38 -0500
Subject: [R-sig-ME] SVN version of lme4 has a space-saving version of lmer2
Message-ID: <40e66e0b0703260648jbfb40fdq76e9ca487b7469d1@mail.gmail.com>

The SVN version of lme4, available at

https://svn.r-project.org/R-packages/trunk/lme4

has a new version of lmer2 that should require less memory on large
model fits.  It creates the entire lmer2 object at once rather than
creating the mer2 object then later creating the lmer2 object from
that.  This should avoid a copy operation involving potentially large
objects.

If you have a very large model fit to create please try out the new
version.  It does require R-2.5.0 so you will need to build that
first.  If that is not feasible and you can allow me access to the
data then I would be pleased to run the tests.

The largest test for which I have real data is a model fit to the star
data (about 25000 observations and approximately the same number of
random effects) and that ends up taking too little memory (12 MB) to
be a real test of the memory growth.

The optional argument frame = FALSE (don't save the model frame) cuts
down on the size of the returned object, sometimes dramatically.



From farewelld at cf.ac.uk  Tue Mar 27 17:19:17 2007
From: farewelld at cf.ac.uk (Daniel Farewell)
Date: Tue, 27 Mar 2007 15:19:17 +0000 (GMT)
Subject: [R-sig-ME] lmer, intercepts and offsets
Message-ID: <20070327151917.16556.qmail@web27103.mail.ukl.yahoo.com>

I've run into difficulties trying to completely specify the fixed effects part of an lmer model. For instance,

fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)

gives fixed effects estimates of around 250 (intercept) and 10 (slope). Suppose that you wanted to evaluate the likelihood (or some other function of the parameters) at specific parameter values. For instance, you might be interested in a profile likelihood holding the fixed effects at _exactly_ 250 and 10.

It is reasonably straightforward to specify variance components via the "start" argument, and to ask lmer not to update these estimates via the various "control" arguments. This kind of profiling, holding the variance components fixed, is not too tricky.

The reverse is harder, but one possibility would be to use an offset.

lmer(Reaction ~ 0 + (1|Subject) + (0+Days|Subject), sleepstudy, offset = fm2 at X %*% c(250, 10))

However, this gives the following error:

Error in lmer(Reaction ~ 0 + (1 | Subject) + (0 + Days | Subject), sleepstudy,  :
        Xp must be a real matrix

It seems that lmer does not allow the fitting of a model with no fixed effects terms. Is this restriction necessary? I can think of other situations where it would be useful to have a variance-components-only model.

Setting this issue aside, does lmer notice the offset at all? This fit

lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy, offset = fm2 at X %*% c(250, 10))

is identical to fm2. An alternative specification

update(fm2, offset = fm2 at X %*% c(250, 10))

gives the error

Error in eval(expr, envir, enclos) : ..1 used in an incorrect context, no ... to look in

while this

update(fm2, formula = I(Reaction - fm2 at X %*% c(250, 10)) ~ .)

is the fit I was expecting.

To summarise this rather rambling request for help:

1. (Why can't/how can) you fit an lmer model with no fixed effects terms?
2. Is the offset argument working correctly and, if so, how should it be used?

As ever, I'd be most grateful for any advice.

Daniel

P.S. How to specify the residual variance is another question entirely;
since I mostly work with GLMMs this isn't usually an issue for me.



From bates at stat.wisc.edu  Tue Mar 27 18:42:55 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 27 Mar 2007 11:42:55 -0500
Subject: [R-sig-ME] SVN version of lme4 has a space-saving version of
	lmer2
In-Reply-To: <06C1E76E03FE9C4B85BFA9C75365D9DA07B39741@tiger.deltadentalwa.com>
References: <40e66e0b0703260648jbfb40fdq76e9ca487b7469d1@mail.gmail.com>
	<06C1E76E03FE9C4B85BFA9C75365D9DA07B3942C@tiger.deltadentalwa.com>
	<40e66e0b0703270538m743d52ap2128f2cd87d0d9d2@mail.gmail.com>
	<06C1E76E03FE9C4B85BFA9C75365D9DA07B39741@tiger.deltadentalwa.com>
Message-ID: <40e66e0b0703270942k63d15b96vdbffc2ded980f962@mail.gmail.com>

On 3/27/07, Chaudhari, Monica <mchaudhari at deltadentalwa.com> wrote:
> Thank you very much, Doug. Unfortunately, I am running R on Windows
> platform. I'll check the instructions and try to perform the same. If I
> run into problems, I might get back to you for help.

I'm afraid I wouldn't be of much help.  I know almost nothing about
compiling R and R packages under Windows and plan to keep it that way.
 (I'm one of those Linux/Mac users who has "Death before Microsoft"
tatooed on his shoulder.)

> Thanks in advance,
> Monica
>
> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
> Bates
> Sent: Tuesday, March 27, 2007 5:39 AM
> To: Chaudhari, Monica
> Cc: r-sig-mixed-models-bounces at r-project.org
> Subject: Re: [R-sig-ME] SVN version of lme4 has a space-saving version
> of lmer2
>
> On 3/26/07, Chaudhari, Monica <mchaudhari at deltadentalwa.com> wrote:
> > Could you please suggest instructions on how to install this package?
>
> You need to install the development version of R-2.5.0 first.  I
> usually do this under Linux.  There are instructions in the "R
> Installation and Administration" manual on how to do this under
> Windows and on the web site for Mac OS X and R for installation there.
>
> For Linux/Unix I sent the following instructions
>
> You need an SVN client to be able to do the checkout.  The home web
> site for the project is http://subversion.tigris.org and you can get
> the sources and compile if you wish.  However, most distributions of
> Linux provide pre-compiled packages.  Under Debian and related
> distributions (Ubuntu, Kubuntu, etc.) it is called the "subversion"
> package.  I imagine it is similar for Red Hat and other RPM-based
> distributions.
>
> To check out R sources for the devel branch use
>
> svn co https://svn.r-project.org/R/trunk/ ./R-2.5.0
>
> After you have a copy of the sources you need to get copies of the
> most recent versions of the recommended packages.  Use
>
> <name_of_source_directory>/tools/rsync-recommended
>
> to get copies of those then do the configure - make - make check -
> make install sequence.
>
> You will be asked about a certificate when you first contact that
> https URL.  Accept it.  We don't have externally signed certificates
> yet.
>
> Checking out development sources for the lme4 package is very similar
>
> svn co https://svn.r-project.org/R-packages/trunk/lme4 ./lme4
>
> Once you have the sources checked out you can update to the current
> version with
>
> svn up <name_of_source_directory>
>
> Install the package with
>
> r-devel CMD INSTALL <name_of_package_source_directory>
>
> >
> > Thanks,
> > Monica
> >
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Douglas
> > Bates
> > Sent: Monday, March 26, 2007 6:49 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] SVN version of lme4 has a space-saving version of
> > lmer2
> >
> > The SVN version of lme4, available at
> >
> > https://svn.r-project.org/R-packages/trunk/lme4
> >
> > has a new version of lmer2 that should require less memory on large
> > model fits.  It creates the entire lmer2 object at once rather than
> > creating the mer2 object then later creating the lmer2 object from
> > that.  This should avoid a copy operation involving potentially large
> > objects.
> >
> > If you have a very large model fit to create please try out the new
> > version.  It does require R-2.5.0 so you will need to build that
> > first.  If that is not feasible and you can allow me access to the
> > data then I would be pleased to run the tests.
> >
> > The largest test for which I have real data is a model fit to the star
> > data (about 25000 observations and approximately the same number of
> > random effects) and that ends up taking too little memory (12 MB) to
> > be a real test of the memory growth.
> >
> > The optional argument frame = FALSE (don't save the model frame) cuts
> > down on the size of the returned object, sometimes dramatically.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > #########################################################
> > The information contained in this e-mail and subsequent attachments
> may be privileged,
> > confidential and protected from disclosure.  This transmission is
> intended for the sole
> > use of the individual and entity to whom it is addressed.  If you are
> not the intended
> > recipient, any dissemination, distribution or copying is strictly
> prohibited.  If you
> > think that you have received this message in error, please e-mail the
> sender at the above
> > e-mail address.
> > #########################################################
> >
> >
>
>
>



From bates at stat.wisc.edu  Tue Mar 27 19:28:32 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 27 Mar 2007 12:28:32 -0500
Subject: [R-sig-ME] lmer, intercepts and offsets
In-Reply-To: <20070327151917.16556.qmail@web27103.mail.ukl.yahoo.com>
References: <20070327151917.16556.qmail@web27103.mail.ukl.yahoo.com>
Message-ID: <40e66e0b0703271028v52a89945n86a66dbc38611451@mail.gmail.com>

On 3/27/07, Daniel Farewell <farewelld at cf.ac.uk> wrote:
> I've run into difficulties trying to completely specify the fixed effects part of an lmer model. For instance,
>
> fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
>
> gives fixed effects estimates of around 250 (intercept) and 10 (slope). Suppose that you wanted to evaluate the likelihood (or some other function of the parameters) at specific parameter values. For instance, you might be interested in a profile likelihood holding the fixed effects at _exactly_ 250 and 10.
>
> It is reasonably straightforward to specify variance components via the "start" argument, and to ask lmer not to update these estimates via the various "control" arguments. This kind of profiling, holding the variance components fixed, is not too tricky.
>
> The reverse is harder, but one possibility would be to use an offset.
>
> lmer(Reaction ~ 0 + (1|Subject) + (0+Days|Subject), sleepstudy, offset = fm2 at X %*% c(250, 10))

I'll need to look at what happens inside of lmer to an offset.
Motivated by your example I looked at the code for handling an offset
in lmer2 and found 2 errors, which I have fixed.

However, this doesn't solve your original problem of how you can
profile the log-likelihood or, equivalently, the deviance.  The lmer
and lmer2 structures are constructed to allow for simple evaluation of
the profiled deviance.  This is a function of the relative
variance-covariance of the random effects only.  (See the
"Implementation" vignette.)  The contribution of the fixed-effects
parameters and, if used, the scale parameter in the distribution of
the response given the linear predictor has been removed.

It would be possible to reintroduce these parameters and evaluate the
deviance but it isn't trivial.  First you need to write out the
explicit expression for the deviance and then decide how to evaluate
all the terms in that expression.  Especially for a GLMM doing this is
complicated.


> However, this gives the following error:
>
> Error in lmer(Reaction ~ 0 + (1 | Subject) + (0 + Days | Subject), sleepstudy,  :
>         Xp must be a real matrix
>
> It seems that lmer does not allow the fitting of a model with no fixed effects terms. Is this restriction necessary? I can think of other situations where it would be useful to have a variance-components-only model.
>
> Setting this issue aside, does lmer notice the offset at all? This fit
>
> lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy, offset = fm2 at X %*% c(250, 10))
>
> is identical to fm2. An alternative specification
>
> update(fm2, offset = fm2 at X %*% c(250, 10))
>
> gives the error
>
> Error in eval(expr, envir, enclos) : ..1 used in an incorrect context, no ... to look in
>
> while this
>
> update(fm2, formula = I(Reaction - fm2 at X %*% c(250, 10)) ~ .)
>
> is the fit I was expecting.
>
> To summarise this rather rambling request for help:
>
> 1. (Why can't/how can) you fit an lmer model with no fixed effects terms?
> 2. Is the offset argument working correctly and, if so, how should it be used?
>
> As ever, I'd be most grateful for any advice.
>
> Daniel
>
> P.S. How to specify the residual variance is another question entirely;
> since I mostly work with GLMMs this isn't usually an issue for me.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Mar 29 01:37:30 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 28 Mar 2007 18:37:30 -0500
Subject: [R-sig-ME] Parametric bootstrap for mixed models
Message-ID: <40e66e0b0703281637m41c9b3at95285f2b6b6ecde5@mail.gmail.com>

I have been considering how to provide functions for the parametric
bootstrap applied to mixed models.  That is, take an lmer model,
simulate new responses for a model with this specification and the
parameters at the estimated parameter values, then obtain the value of
some statistic for a model fit to the new data.

It occurs to me that it would be best to split this operation into two
stages, one to simulate data from a fitted model and a second which
takes a fitted model, new data and a function to apply to the updated
model.  The reason it seems best to split write this as two functions
or methods is because you may want to simulate from one model (the
null model) and fit another model (the alternative) to get the value
of the statistic.

Does this seem a reasonable approach or am I likely to paint myself
into a corner doing this?  Is anyone sufficiently familiar with some
of the packages that do bootstrapping to offer an alternative model?

If I do things this way, the first function can be a method for the
simulate generic.  Any suggestions of what to call the second one?



From A.Robinson at ms.unimelb.edu.au  Thu Mar 29 02:21:49 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 29 Mar 2007 10:21:49 +1000
Subject: [R-sig-ME] Parametric bootstrap for mixed models
In-Reply-To: <40e66e0b0703281637m41c9b3at95285f2b6b6ecde5@mail.gmail.com>
References: <40e66e0b0703281637m41c9b3at95285f2b6b6ecde5@mail.gmail.com>
Message-ID: <20070329002149.GP47923@ms.unimelb.edu.au>

On Wed, Mar 28, 2007 at 06:37:30PM -0500, Douglas Bates wrote:
> I have been considering how to provide functions for the parametric
> bootstrap applied to mixed models.  That is, take an lmer model,
> simulate new responses for a model with this specification and the
> parameters at the estimated parameter values, then obtain the value of
> some statistic for a model fit to the new data.
> 
> It occurs to me that it would be best to split this operation into two
> stages, one to simulate data from a fitted model and a second which
> takes a fitted model, new data and a function to apply to the updated
> model.  The reason it seems best to split write this as two functions
> or methods is because you may want to simulate from one model (the
> null model) and fit another model (the alternative) to get the value
> of the statistic.
>  
> Does this seem a reasonable approach or am I likely to paint myself
> into a corner doing this?  Is anyone sufficiently familiar with some
> of the packages that do bootstrapping to offer an alternative model?
> 
> If I do things this way, the first function can be a method for the
> simulate generic.  Any suggestions of what to call the second one?

Doug, this would be just great.

If it's not too much work, could you extend the update() function from
nlme?

First, provide a function to simulate from a fitted model.  Second,
provide an update function as you did in nlme, and which is a favorite
of mine.  The update function takes a fitted model, a new argument (eg
new data), and updates the fitted model, and a final argument which is
the the user-supplied function to extract whatever statistics they
want.

Cheers,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From jkrobert at bcm.tmc.edu  Fri Mar 30 17:55:51 2007
From: jkrobert at bcm.tmc.edu (Roberts, J. Kyle)
Date: Fri, 30 Mar 2007 10:55:51 -0500
Subject: [R-sig-ME] qqnorm question
Message-ID: <3FC0430478C30B4A9AF0AFF7863418F130F0C0@BCMEVS6.ad.bcm.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070330/649ce406/attachment.pl>

From mchaudhari at deltadentalwa.com  Fri Mar 30 18:30:46 2007
From: mchaudhari at deltadentalwa.com (Chaudhari, Monica)
Date: Fri, 30 Mar 2007 09:30:46 -0700
Subject: [R-sig-ME] qqnorm question
In-Reply-To: <3FC0430478C30B4A9AF0AFF7863418F130F0C0@BCMEVS6.ad.bcm.edu>
References: <3FC0430478C30B4A9AF0AFF7863418F130F0C0@BCMEVS6.ad.bcm.edu>
Message-ID: <06C1E76E03FE9C4B85BFA9C75365D9DA07BF14E9@tiger.deltadentalwa.com>

Hello Kyle,

Are you trying to test the normality of random effects? If yes, then
below is the way to go:
str(re<-ranef(modl,postVar = TRUE))
qqmath(re)
or qqmath(~re[[1]]); qqmath(~re[[2]]);

Hope this helps.

Thanks,
Monica


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Roberts,
J. Kyle
Sent: Friday, March 30, 2007 8:56 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] qqnorm question

Dear All,
 
Forgive my lack of knowledge, but I can't get qqnorm to work with lmer.
I get the following error (dep.lmer is a lmer class object):
 
> qqnorm(dep.lmer)
Error in min(..., na.rm = na.rm) : invalid 'type' (list) of argument
In addition: Warning message:
is.na() applied to non-(list or vector) in: is.na(y)
 
Any ideas?
 
Kyle
 
***************************************
J. Kyle Roberts, Ph.D.
Baylor College of Medicine
Center for Educational Outreach
One Baylor Plaza, MS:  BCM411
Houston, TX   77030-3411
713-798-6672 - 713-798-8201 Fax
jkrobert at bcm.edu
***************************************
 

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


#########################################################
The information contained in this e-mail and subsequent attachments may be privileged, 
confidential and protected from disclosure.  This transmission is intended for the sole 
use of the individual and entity to whom it is addressed.  If you are not the intended 
recipient, any dissemination, distribution or copying is strictly prohibited.  If you 
think that you have received this message in error, please e-mail the sender at the above 
e-mail address.
#########################################################



From jkrobert at bcm.tmc.edu  Fri Mar 30 20:28:42 2007
From: jkrobert at bcm.tmc.edu (Roberts, J. Kyle)
Date: Fri, 30 Mar 2007 13:28:42 -0500
Subject: [R-sig-ME] qqnorm question
In-Reply-To: <06C1E76E03FE9C4B85BFA9C75365D9DA07BF14E9@tiger.deltadentalwa.com>
Message-ID: <3FC0430478C30B4A9AF0AFF7863418F130F0C2@BCMEVS6.ad.bcm.edu>

That's what I want. Thanks!

So the attached picture would be bad, right?!?!? ;)

Kyle


***************************************
J. Kyle Roberts, Ph.D.
Baylor College of Medicine
Center for Educational Outreach
One Baylor Plaza, MS:  BCM411
Houston, TX   77030-3411
713-798-6672 - 713-798-8201 Fax
jkrobert at bcm.edu
***************************************

-----Original Message-----
From: Chaudhari, Monica [mailto:mchaudhari at deltadentalwa.com] 
Sent: Friday, March 30, 2007 11:31 AM
To: Roberts, J. Kyle; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] qqnorm question

Hello Kyle,

Are you trying to test the normality of random effects? If yes, then below is the way to go:
str(re<-ranef(modl,postVar = TRUE))
qqmath(re)
or qqmath(~re[[1]]); qqmath(~re[[2]]);

Hope this helps.

Thanks,
Monica


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Roberts, J. Kyle
Sent: Friday, March 30, 2007 8:56 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] qqnorm question

Dear All,
 
Forgive my lack of knowledge, but I can't get qqnorm to work with lmer.
I get the following error (dep.lmer is a lmer class object):
 
> qqnorm(dep.lmer)
Error in min(..., na.rm = na.rm) : invalid 'type' (list) of argument In addition: Warning message:
is.na() applied to non-(list or vector) in: is.na(y)
 
Any ideas?
 
Kyle
 
***************************************
J. Kyle Roberts, Ph.D.
Baylor College of Medicine
Center for Educational Outreach
One Baylor Plaza, MS:  BCM411
Houston, TX   77030-3411
713-798-6672 - 713-798-8201 Fax
jkrobert at bcm.edu
***************************************
 

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


#########################################################
The information contained in this e-mail and subsequent attachments may be privileged, confidential and protected from disclosure.  This transmission is intended for the sole use of the individual and entity to whom it is addressed.  If you are not the intended recipient, any dissemination,
distribution or copying is strictly prohibited.  If you think that you have received this message in error, please e-mail the sender at the above e-mail address.
#########################################################


From HDoran at air.org  Fri Mar 30 20:53:18 2007
From: HDoran at air.org (Doran, Harold)
Date: Fri, 30 Mar 2007 14:53:18 -0400
Subject: [R-sig-ME] qqnorm question
In-Reply-To: <3FC0430478C30B4A9AF0AFF7863418F130F0C2@BCMEVS6.ad.bcm.edu>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EB9F940@dc1ex01.air.org>

Here is another way to get the qqplot to evaluate the random effects

data(star, package='mlmRev')
fm <- lmer2(math ~ yrs + (yrs|sch), star)

qqmath(~ranef(fm)$sch$'(Intercept)')
qqmath(~ranef(fm)$sch$yrs)

Don't forget about mcmcsamp() and the ancillary functions in coda for
also evaluating distributional assumptions.

Harold


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Roberts, J. Kyle
> Sent: Friday, March 30, 2007 1:29 PM
> To: Chaudhari, Monica; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] qqnorm question
> 
> That's what I want. Thanks!
> 
> So the attached picture would be bad, right?!?!? ;)
> 
> Kyle
> 
> 
> ***************************************
> J. Kyle Roberts, Ph.D.
> Baylor College of Medicine
> Center for Educational Outreach
> One Baylor Plaza, MS:  BCM411
> Houston, TX   77030-3411
> 713-798-6672 - 713-798-8201 Fax
> jkrobert at bcm.edu
> ***************************************
> 
> -----Original Message-----
> From: Chaudhari, Monica [mailto:mchaudhari at deltadentalwa.com]
> Sent: Friday, March 30, 2007 11:31 AM
> To: Roberts, J. Kyle; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] qqnorm question
> 
> Hello Kyle,
> 
> Are you trying to test the normality of random effects? If 
> yes, then below is the way to go:
> str(re<-ranef(modl,postVar = TRUE))
> qqmath(re)
> or qqmath(~re[[1]]); qqmath(~re[[2]]);
> 
> Hope this helps.
> 
> Thanks,
> Monica
> 
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Roberts, J. Kyle
> Sent: Friday, March 30, 2007 8:56 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] qqnorm question
> 
> Dear All,
>  
> Forgive my lack of knowledge, but I can't get qqnorm to work 
> with lmer.
> I get the following error (dep.lmer is a lmer class object):
>  
> > qqnorm(dep.lmer)
> Error in min(..., na.rm = na.rm) : invalid 'type' (list) of 
> argument In addition: Warning message:
> is.na() applied to non-(list or vector) in: is.na(y)
>  
> Any ideas?
>  
> Kyle
>  
> ***************************************
> J. Kyle Roberts, Ph.D.
> Baylor College of Medicine
> Center for Educational Outreach
> One Baylor Plaza, MS:  BCM411
> Houston, TX   77030-3411
> 713-798-6672 - 713-798-8201 Fax
> jkrobert at bcm.edu
> ***************************************
>  
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> #########################################################
> The information contained in this e-mail and subsequent 
> attachments may be privileged, confidential and protected 
> from disclosure.  This transmission is intended for the sole 
> use of the individual and entity to whom it is addressed.  If 
> you are not the intended recipient, any dissemination, 
> distribution or copying is strictly prohibited.  If you think 
> that you have received this message in error, please e-mail 
> the sender at the above e-mail address.
> #########################################################
> 
>



